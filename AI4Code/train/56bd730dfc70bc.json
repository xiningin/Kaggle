{"cell_type":{"2b7853bf":"code","3106fd7a":"code","ec5d0882":"code","06ed8eeb":"code","50917048":"code","71b63aa6":"code","0fcaf56b":"code","86c4f2c0":"code","93bcf6b0":"code","3acd86c3":"code","afd4ffab":"code","3f42bfc2":"code","2d3e6369":"code","40aba6d5":"code","f79a2c4e":"code","fb652226":"code","e25f9ede":"code","dd76345b":"code","a0c66496":"code","9bff34ca":"code","58d98676":"code","ebca000e":"code","3ac8fad4":"code","99216f78":"code","fd7248d8":"markdown","6728a312":"markdown","00c24588":"markdown","72485344":"markdown","7c4e403c":"markdown","6d6ec1d1":"markdown","7a6d11e1":"markdown","c05729a0":"markdown","7c5974c4":"markdown","9fc51fb7":"markdown","f767a0a9":"markdown","0b13aa24":"markdown","e21a50ff":"markdown","40c4d4e0":"markdown","b5be0229":"markdown","c48b9d30":"markdown","fe2aa119":"markdown","6c816c74":"markdown","156f535c":"markdown","e2055af5":"markdown","e28d43ca":"markdown","87d270ee":"markdown","5dbaee87":"markdown","948c0d42":"markdown","bc420d6f":"markdown","cc7ed99e":"markdown","3b11ee30":"markdown","03ec5bd0":"markdown"},"source":{"2b7853bf":"# =============================================================================\n# 1. Libraries\n# =============================================================================\n# General purpose\nimport pandas as pd\nimport numpy as np\nimport sklearn as sk\nimport scipy\nfrom collections import Counter\nimport re\nimport warnings\nimport itertools\npd.set_option('mode.chained_assignment', None)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Clustering and networks\nimport igraph\nimport networkx as nx\nfrom networkx.algorithms import community\nfrom sklearn import preprocessing\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import MinMaxScaler\nfrom community import community_louvain\nfrom kmodes.kmodes import KModes\n\n# Vizualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom matplotlib.pyplot import figure\nfrom matplotlib.colors import ListedColormap\nfrom wordcloud import WordCloud\n\n# Confidence interval\nimport scipy.stats\ndef mean_confidence_interval(data, confidence=0.95):\n    a = 1.0 * np.array(data)\n    n = len(a)\n    m, se = np.mean(a), scipy.stats.sem(a)\n    h = se * scipy.stats.t.ppf((1 + confidence) \/ 2., n-1)\n    return np.round(m, 2), np.round(m-h), np.round(m+h, 2)\n\n\n# Colors\nCOLORS_SET_B_G_R = [sns.color_palette('muted')[0], sns.color_palette('muted')[2], sns.color_palette('muted')[3]]","3106fd7a":"# Load survey data\nsurvey_schema = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/survey_schema.csv')\ndf_responses = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/multiple_choice_responses.csv')\n\n# Dataframe with question code and description\nqs = df_responses.iloc[0].T.to_frame()\nqs.index.name = \"name\"\nqs.columns = [\"description\"]\n\n# Remove question labels from the dataset\ndf_responses.drop(0, inplace=True)\ndf_responses.reset_index(inplace=True)","ec5d0882":"# Create dataframe for visualization of Q4\nQ4_distrib = pd.DataFrame(df_responses['Q4'].value_counts())\nQ4_distrib.reset_index(inplace=True)\nQ4_distrib_grey = Q4_distrib.copy() \nQ4_distrib_grey = Q4_distrib_grey.replace(to_replace=2767, value=0)","06ed8eeb":"# Visualization of Q4\nsns.set(style=\"whitegrid\")\nf,ax = plt.subplots(figsize=(6, 4))\n\n# Plot first layer\nsns.barplot(x=\"Q4\", y=\"index\", data=Q4_distrib,\n            color=COLORS_SET_B_G_R[2], edgecolor='black')\nsns.despine(left=True, bottom=True)\n\n# Plot second layer\nsns.set(style=\"whitegrid\")\nsns.barplot(x=\"Q4\", y=\"index\", data=Q4_distrib_grey,\n            color='lightgrey')\nsns.despine(left=True, bottom=True)\n\n# Add number of PhD holders\n_ = plt.text(2850, 2.1, '2767', fontsize=12)\n\n# Set title\n_ = ax.set_title('PhD holders in the Survey', fontsize=20)\n\n# Remove redundant labels and borders\nax.xaxis.grid(False)\nax.yaxis.grid(False)\nax.set_xticks([])\nax.xaxis.set_label_text(\"\")\nax.yaxis.set_label_text(\"\")\n\n# Options setup\n_ = plt.setp(f.patches, linewidth=0.5) ","50917048":"# Create subsets of variable dedicated to skills, activities, programming languages etc.\nide_usage = [\"Q16_Part_1\", \"Q16_Part_2\", \"Q16_Part_3\", \"Q16_Part_4\", \"Q16_Part_5\", \"Q16_Part_6\", \"Q16_Part_7\", \"Q16_Part_8\", \"Q16_Part_9\", \"Q16_Part_10\"]\nnotebook_usage = [\"Q17_Part_1\", \"Q17_Part_2\", \"Q17_Part_3\", \"Q17_Part_4\", \"Q17_Part_5\", \"Q17_Part_6\", \"Q17_Part_7\", \"Q17_Part_8\", \"Q17_Part_9\", \"Q17_Part_10\"]\nlanguage_usage = [\"Q18_Part_1\", \"Q18_Part_2\", \"Q18_Part_3\", \"Q18_Part_4\", \"Q18_Part_5\", \"Q18_Part_6\", \"Q18_Part_7\", \"Q18_Part_8\", \"Q18_Part_9\", \"Q18_Part_10\"]\nvisual_usage = [\"Q20_Part_1\", \"Q20_Part_2\", \"Q20_Part_3\", \"Q20_Part_4\", \"Q20_Part_5\", \"Q20_Part_6\", \"Q20_Part_7\", \"Q20_Part_8\", \"Q20_Part_9\", \"Q20_Part_10\"]\nalgo_usage = [\"Q24_Part_1\", \"Q24_Part_2\", \"Q24_Part_3\", \"Q24_Part_4\", \"Q24_Part_5\", \"Q24_Part_6\", \"Q24_Part_7\", \"Q24_Part_8\", \"Q24_Part_9\", \"Q24_Part_10\"]\nml_tools_usage = [\"Q25_Part_1\", \"Q25_Part_2\", \"Q25_Part_3\", \"Q25_Part_4\", \"Q25_Part_5\", \"Q25_Part_6\"]\ncv_usage = [\"Q26_Part_1\", \"Q26_Part_2\", \"Q26_Part_3\", \"Q26_Part_4\", \"Q26_Part_5\"]\nnlp_usage = [\"Q27_Part_1\", \"Q27_Part_2\", \"Q27_Part_3\", \"Q27_Part_4\"]\nml_frameworks_usage = [\"Q28_Part_1\", \"Q28_Part_2\", \"Q28_Part_3\", \"Q28_Part_4\", \"Q28_Part_5\", \"Q28_Part_6\", \"Q28_Part_7\", \"Q28_Part_8\", \"Q28_Part_9\", \"Q28_Part_10\"]\ncloud_platforms_usage = [\"Q29_Part_1\", \"Q29_Part_2\", \"Q29_Part_3\", \"Q29_Part_4\", \"Q29_Part_5\", \"Q29_Part_6\", \"Q29_Part_7\", \"Q29_Part_8\", \"Q29_Part_9\", \"Q29_Part_10\"]\ncloud_products_usage = [\"Q30_Part_1\", \"Q30_Part_2\", \"Q30_Part_3\", \"Q30_Part_4\", \"Q30_Part_5\", \"Q30_Part_6\", \"Q30_Part_7\", \"Q30_Part_8\", \"Q30_Part_9\", \"Q30_Part_10\"]\nbig_data_products_usage = [\"Q31_Part_1\", \"Q31_Part_2\", \"Q31_Part_3\", \"Q31_Part_4\", \"Q31_Part_5\", \"Q31_Part_6\", \"Q31_Part_7\", \"Q31_Part_8\", \"Q31_Part_9\", \"Q31_Part_10\"]\nml_products_usage = [\"Q32_Part_1\", \"Q32_Part_2\", \"Q32_Part_3\", \"Q32_Part_4\", \"Q32_Part_5\", \"Q32_Part_6\", \"Q32_Part_7\", \"Q32_Part_8\", \"Q32_Part_9\", \"Q32_Part_10\"]\nautoml_tools = [\"Q33_Part_1\", \"Q33_Part_2\", \"Q33_Part_3\", \"Q33_Part_4\", \"Q33_Part_5\", \"Q33_Part_6\", \"Q33_Part_7\", \"Q33_Part_8\", \"Q33_Part_9\", \"Q33_Part_10\"]\ndb_tools = [\"Q34_Part_1\", \"Q34_Part_2\", \"Q34_Part_3\", \"Q34_Part_4\", \"Q34_Part_5\", \"Q34_Part_6\", \"Q34_Part_7\", \"Q34_Part_8\", \"Q34_Part_9\", \"Q34_Part_10\"]\n\n# Get separate dataframe with skills related questions\nskills_questions = [ide_usage, notebook_usage, language_usage, visual_usage, algo_usage,\n                    ml_tools_usage, cv_usage, nlp_usage, ml_frameworks_usage, cloud_platforms_usage, big_data_products_usage,\n                   ml_products_usage, automl_tools, db_tools]\nskills_questions = np.concatenate(skills_questions)\ndf_skills = df_responses[skills_questions]\n\n# Recode to binary\ndf_skills[~df_skills.isnull()] = 1\ndf_skills[df_skills.isnull()] = 0\n\n# Remove participant who did not mentioned any skills\ndf_skills = df_skills[df_skills.sum(1) > 0]\n\n# Get proper labels for skills\nlabels = pd.DataFrame(df_skills.columns).merge(qs, left_on='name', right_on='name')\n# Preprocess lables\nlabels['description'] = labels['description'].apply(lambda string: string.strip())\ndef fixMatlab(string):\n    if 'MATLAB' in string:\n        if 'IDE' in string:\n            string = string + ' IDE'\n        else:\n            string = string + ' language'\n    return string\nlabels['description'] = labels['description'].apply(fixMatlab)\nlabels['description'] = labels['description'].apply(\n    lambda d: re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", d.split('Selected Choice - ')[-1]).strip())\ndf_skills.columns = labels['description']\n\n# Remove rare skills\nSELECTED_SKILLS = df_skills.sum(0).sort_values(ascending=False)[df_skills.sum(0) > 500].index\ndf_skills = df_skills.loc[:,SELECTED_SKILLS]\n# Remove participant who did not mentioned any skills\ndf_skills = df_skills[df_skills.sum(1) > 0]\n\n# Create final dataframe with socio-demographic parameters and skills\ndf_socdem = df_responses.loc[:,['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q10', 'Q15', 'Q23']]\ndf_fin = df_socdem.merge(df_skills, left_index=True, right_index=True)\n\n# Change names of countries\ndf_fin['Q3'] = df_fin['Q3'].replace({'Iran, Islamic Republic of...':'Iran',\n                                     'Republic of Korea':'South Korea',\n                                     'United Kingdom of Great Britain and Northern Ireland':'United Kingdom',\n                                     'United States of America':'USA'})\n\n# Drop respondents who did't indicate their country\ndf_fin = df_fin.dropna(subset=['Q3'])\n\n# PhD or Not PhD\ndf_fin['Q4_phd'] = list(map(lambda e: 'PhD' if e == 'Doctoral degree' else 'not PhD', df_fin['Q4']))\ndf_fin['Q4_phd'] = df_fin['Q4_phd'].astype('category')\n\n# Student or Not Student\ndf_fin['student'] = ['Student' if p == 'Student' else 'Not Student' for p in df_fin['Q5']]\ndf_fin['student'] = df_fin['student'].astype('category')\n\n# Salary to ordinal\ndf_fin['Q10'] = df_fin['Q10'].astype('category')\ndf_fin['Q10'].cat.reorder_categories([\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\",\n                                      \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \"15,000-19,999\",\n                                      \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\",\n                                      \"50,000-59,999\", \"60,000-69,999\", \"70,000-79,999\", \"80,000-89,999\",\n                                      \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\",\n                                      \"200,000-249,999\", \"250,000-299,999\", \"300,000-500,000\", \"> $500,000\"]\n                                      , inplace=True)\n\n# Experience to ordinal\ndf_fin['Q15'] = df_fin['Q15'].astype('category')\ndf_fin['Q15'].cat.reorder_categories(['< 1 years', '1-2 years', '3-5 years', '5-10 years', '10-20 years', '20+ years']\n                                      , inplace=True)\n\n# Age to ordinal\ndf_fin['Q1'] = df_fin['Q1'].astype('category')\ndf_fin['Q1'].cat.reorder_categories(['18-21', '22-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-69', '70+'], inplace=True)\n\n# Varible with Top 20 countries\ntop_countries = list(df_fin.Q3.value_counts().head(21).index)\ntop_countries.remove('Other')\ndf_fin['Q3_top'] = list(map(lambda c: c if c in top_countries else np.nan, df_fin['Q3']))","71b63aa6":"# Create dataframe for visualization of Q4\ndf_phd_viz = df_fin[df_fin['Q4_phd'] == 'PhD']\ndf_phd_viz_country = pd.DataFrame(df_phd_viz['Q3_top'].value_counts())\ndf_phd_viz_country.reset_index(inplace=True)\ndf_phd_viz_country_grey = df_phd_viz_country.copy()\ndf_phd_viz_country_grey['Q3_top'] = [0] * 4 + list(df_phd_viz_country_grey['Q3_top'])[4:]\n\n# Create dataframe for visualization of Q5\ndf_phd_viz_role = pd.DataFrame(df_phd_viz['Q5'].value_counts())\ndf_phd_viz_role.reset_index(inplace=True)\ndf_phd_viz_role_grey = df_phd_viz_role.copy()\ndf_phd_viz_role_grey['Q5'] = [0] * 2 + list(df_phd_viz_role_grey['Q5'])[2:]\n\n# Create dataframe for visualization of Q2\ndf_phd_viz_gender = pd.DataFrame(df_phd_viz['Q2'].value_counts())\ndf_phd_viz_gender.reset_index(inplace=True)\ndf_phd_viz_gender_grey = df_phd_viz_gender.copy()\ndf_phd_viz_gender_grey['Q2'] = [0] + list(df_phd_viz_gender_grey['Q2'])[1:]\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(22, 10))\n# Plot first layer\nsns.barplot(x=\"Q2\", y=\"index\", data=df_phd_viz_gender,\n            label=\"Total\",ax=axes[0], color=COLORS_SET_B_G_R[2], edgecolor='black')\n# Plot second layer\nsns.barplot(x=\"Q2\", y=\"index\", data=df_phd_viz_gender_grey,\n            label=\"Total\",ax=axes[0], color='lightgrey')\n\n# Remove redundant labels and borders\naxes[0].xaxis.grid(False)\naxes[0].yaxis.grid(False)\naxes[0].xaxis.set_label_text(\"\")\naxes[0].yaxis.set_label_text(\"\")\n\n# Set title\n_ = axes[0].set_title('Gender distribution', fontsize=16)\n\n# Set xticks labels\naxes[0].tick_params(axis='y', which='major', labelsize=20)\n\n# Plot first layer\nsns.barplot(x=\"Q3_top\", y=\"index\", data=df_phd_viz_country,\n            label=\"Total\", ax=axes[1], color=COLORS_SET_B_G_R[2], edgecolor='black')\n# Plot second layer\nsns.barplot(x=\"Q3_top\", y=\"index\", data=df_phd_viz_country_grey,\n            label=\"Total\",ax=axes[1], color='lightgrey')\naxes[1].xaxis.grid(False)\naxes[1].yaxis.grid(False)\naxes[1].xaxis.set_label_text(\"\")\naxes[1].yaxis.set_label_text(\"\")\n_ = axes[1].set_title('Country distribution', fontsize=16)\naxes[1].tick_params(axis='y', which='major', labelsize=16)\n\n# Plot first layer\nsns.barplot(x=\"Q5\", y=\"index\", data=df_phd_viz_role,\n            label=\"Total\", ax=axes[2], color=COLORS_SET_B_G_R[2], edgecolor='black')\n# Plot second layer\nsns.barplot(x=\"Q5\", y=\"index\", data=df_phd_viz_role_grey,\n            label=\"Total\",ax=axes[2], color='lightgrey')\naxes[2].xaxis.grid(False)\naxes[2].yaxis.grid(False)\naxes[2].xaxis.set_label_text(\"\")\naxes[2].yaxis.set_label_text(\"\")\n_ = axes[2].set_title('Job title distribution', fontsize=16)\naxes[2].tick_params(axis='y', which='major', labelsize=16)\nsns.despine(left=False, bottom=False)\n\n# Add title\nst = fig.suptitle(\"Kagglers with a PhD\", fontsize=24, x =0.5, y=1)\n\n# Additional setup\nfig.subplots_adjust(wspace=1)\n_ = plt.setp(fig.patches, linewidth=0.5)","0fcaf56b":"# Create dataframe for visualization of Q1\ndf_phd_viz_age = df_phd_viz.copy()\ndf_phd_viz_age = df_phd_viz_age.query(\"Q1 != '30-34' and Q1 != '35-39'\")\n\n# Create dataframe for visualization of Q15\ndf_phd_viz_exp = df_phd_viz.copy()\ndf_phd_viz_exp = df_phd_viz_exp.query(\"Q15 != '3-5 years' and Q15 != '5-10 years'\")\n\n# Create dataframe for visualization of Q10\ndf_phd_viz_salary = df_phd_viz.copy()\ndf_phd_viz_salary = df_phd_viz_salary.query(\"Q10 != '100,000-124,999' and Q10 != '125,000-149,999' and Q10 != '150,000-199,999'\")\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(22, 5))\n# Plot first layer\ng = sns.countplot(x=\"Q1\", color=COLORS_SET_B_G_R[2], data=df_phd_viz, ax=axes[0], edgecolor='black')\ng = g.set_xticklabels(g.get_xticklabels(), rotation=90, horizontalalignment=\"right\")\n# Plot second layer\ng = sns.countplot(x=\"Q1\", color=\"lightgrey\", data=df_phd_viz_age, ax=axes[0])\ng = g.set_xticklabels(g.get_xticklabels(), rotation=90, horizontalalignment=\"right\")\naxes[0].xaxis.grid(False)\naxes[0].yaxis.grid(False)\naxes[0].xaxis.set_label_text(\"\")\naxes[0].yaxis.set_label_text(\"\")\n_ = axes[0].set_title('Age distribution', fontsize=16)\naxes[0].tick_params(axis='x', which='major', labelsize=16)\n\n# Plot first layer\ng = sns.countplot(x=\"Q15\", color=COLORS_SET_B_G_R[2], data=df_phd_viz, ax=axes[1], edgecolor='black')\ng = g.set_xticklabels(g.get_xticklabels(), rotation=90, horizontalalignment=\"right\")\n# Plot second layer\ng = sns.countplot(x=\"Q15\", color=\"lightgrey\", data=df_phd_viz_exp, ax=axes[1])\ng = g.set_xticklabels(g.get_xticklabels(), rotation=90, horizontalalignment=\"right\")\naxes[1].xaxis.grid(False)\naxes[1].yaxis.grid(False)\naxes[1].xaxis.set_label_text(\"\")\naxes[1].yaxis.set_label_text(\"\")\n_ = axes[1].set_title('Experience distribution', fontsize=16)\naxes[1].tick_params(axis='x', which='major', labelsize=16)\n\n# Plot first layer\ng = sns.countplot(x=\"Q10\", color=COLORS_SET_B_G_R[2], data=df_phd_viz, ax=axes[2], edgecolor='black')\ng = g.set_xticklabels(g.get_xticklabels(), rotation=90)\n# Plot second layer\ng = sns.countplot(x=\"Q10\", color=\"lightgrey\", data=df_phd_viz_salary, ax=axes[2])\ng = g.set_xticklabels(g.get_xticklabels(), rotation=90)\naxes[2].xaxis.grid(False)\naxes[2].yaxis.grid(False)\naxes[2].xaxis.set_label_text(\"\")\naxes[2].yaxis.set_label_text(\"\")\n_ = axes[2].set_title('Salary distribution', fontsize=16)\naxes[2].tick_params(axis='x', which='major', labelsize=12)\n\n# Add title\nst = fig.suptitle(\"Kagglers with a PhD\", fontsize=24, x =0.5, y=1.1)\n\n# Additional setup\nsns.despine(left=False, bottom=False)\nfig.subplots_adjust(wspace=0.3)\n_ = plt.setp(fig.patches, linewidth=0.5)","86c4f2c0":"def participantsGraphObj(df, q_threshold=0.95, SELECTED_SKILLS=SELECTED_SKILLS, only_phd=True, removeDisconnected=True):\n    \n    # Select only PhD participants\n    if only_phd:\n        df = df.query(\"Q4 == 'Doctoral degree'\")\n    df.reset_index(inplace=True, drop=True)\n    # Create similarity matrix\n    similarity_matrix = cosine_similarity(df.loc[:,SELECTED_SKILLS])\n    threshold = np.quantile(np.concatenate(similarity_matrix), q_threshold)\n    # threshold = np.median(np.concatenate(similarity_matrix))\n    similarity_matrix[similarity_matrix < threshold] = 0\n    similarity_matrix[similarity_matrix >= threshold] = 1\n    np.fill_diagonal(similarity_matrix, 0)\n    # Create Graph structure\n    G = igraph.Graph.Adjacency((similarity_matrix > 0).tolist())\n    G.to_undirected()\n    G.simplify()\n    # Add vertex objects and connected indicator to intial dataframe\n    df['vertex'] = list(G.vs)\n    df['connected'] = pd.Series(G.components().membership) == 0\n    if removeDisconnected:\n        df = df[df['connected'] == True]\n        G = G.induced_subgraph(list(df['vertex']))\n        \n    return df, G, similarity_matrix\n\ndf_phd, G, similarity_matrix = participantsGraphObj(df_fin, q_threshold=0.99)\n\n# Community detection\nfg = G.community_fastgreedy()\nfg = fg.as_clustering()\n\n# Add community label to the dataframe\ndf_phd['community'] = fg.membership\n\n# Select only large communities\ndf_phd['community'] = [com if com <= 2  else np.nan for com in df_phd['community']]\n\n# Creating layout\nlayout = G.layout(\"lgl\")\n\n# Rename communities according to the skills of participants\ncommunity_name_dict = {0:'Python and Deep Learning', 1:'R and Classical ML', 2:'Python and Classical ML'}\ndf_phd['community'] = df_phd['community'].map(community_name_dict)\ndf_phd['community'] = df_phd['community'].astype('category')\n\n# Recode degree to binary\ndegree_list = list(G.degree())\nmodifed_degree_list = list(map(lambda x: 10 if x >= np.quantile(degree_list, 0.95) else 5, degree_list))\ndf_phd['degree'] = list(G.degree())\nG.vs['size'] = modifed_degree_list\n\n# Get appropriate colors for communities\ncommunity_colors = pd.Series(fg.membership).map({0:COLORS_SET_B_G_R[0],\n                                                 1:COLORS_SET_B_G_R[1],\n                                                 2:COLORS_SET_B_G_R[2]})\ncommunity_colors = list(community_colors.fillna('lightgrey'))\n\n# To plot the bellow Graph without Text you need to execute following line:\n# igraph.plot(G, layout=layout, edge_width=0.2, vertex_frame_width=0.5, vertex_color=community_colors, bbox=(800, 800))\n\n# igraph doesnt support addition of titles or legend","93bcf6b0":"# Skills in each community\ncommunity_skills = pd.DataFrame({'R and Classical ML':df_phd[df_phd['community'] == 'R and Classical ML'].loc[:,SELECTED_SKILLS].sum(),\n                                 'Python and Classical ML':df_phd[df_phd['community'] == 'Python and Classical ML'].loc[:,SELECTED_SKILLS].sum(),\n                                 'Python and Deep Learning':df_phd[df_phd['community'] == 'Python and Deep Learning'].loc[:,SELECTED_SKILLS].sum()})\n\nfig = plt.figure()\nfig.set_size_inches(30, 10)\n\n# Set of colors\ncolors_set = ['forestgreen', 'indianred', 'royalblue']\nfor i in range(community_skills.shape[1]):\n    \n    # Generate string with proportional words \n    top_skills = community_skills[community_skills.columns[i]].sort_values(ascending=True)\n    top_skills = top_skills.rank()\n    skills_string = []\n    for skill_i in range(len(top_skills)):\n        skills_string.extend([top_skills.index[skill_i]] * int(top_skills.values[skill_i]))\n    ax = fig.add_subplot(1,3,i+1)\n    word_could_dict=Counter(skills_string)\n    # Create wordcloud object\n    wordcloud = WordCloud(width = 1200, height = 1200, background_color=\"white\",\n                          color_func=lambda *args, **kwargs: colors_set[i], relative_scaling = 1).generate_from_frequencies(word_could_dict)\n    \n\n    ax.imshow(wordcloud, interpolation = 'bilinear')\n    ax.axis('off')\n    ax.set_title(community_skills.columns[i], size=48, pad=50)\n    \nplt.tight_layout(pad=0)\nplt.show()","3acd86c3":"# Create dataframe for visualization\ncommunties_students = pd.crosstab(df_phd['community'], df_phd['student'], normalize='index')\ncommunties_students = pd.DataFrame(communties_students['Student'].sort_values(ascending=False))\ncommunties_students.reset_index(inplace=True)\ncommunties_students['community'] = communties_students['community'].astype('category')\ncommunties_students['community'].cat.reorder_categories(['Python and Deep Learning', 'Python and Classical ML', 'R and Classical ML']\n                                      , inplace=True)\ncommunties_students_viz = communties_students.copy()\ncommunties_students_viz['Student'] = list(communties_students_viz['Student'])[:2] + [0]\n\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n\nsns.set(style=\"whitegrid\")\n# First layer\nsns.barplot(x=\"community\", y=\"Student\", data=communties_students,\n            label=\"Total\", color='lightgrey', ax=axes[0])\n# Second layer\nsns.barplot(x=\"community\", y=\"Student\", data=communties_students_viz,\n            label=\"Total\", color=COLORS_SET_B_G_R[2], ax=axes[0], edgecolor='black')\n\n# Remove redundant borders\nsns.despine(left=False, bottom=False)\naxes[0].xaxis.grid(False)\naxes[0].yaxis.grid(False)\naxes[0].xaxis.set_label_text(\"\")\naxes[0].yaxis.set_label_text(\"\")\n# Set title\n_ = axes[0].set_title('Students proportion\\n in the skillset communities', fontsize=16, pad=25)\n# Set x ticks\naxes[0].tick_params(axis='x', which='major', labelsize=12)\naxes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45, horizontalalignment='right')\n\n# Create dataframe for visualization\ndf_phd_viz_degree_com = df_phd.copy()\ndf_phd_viz_degree_com = df_phd_viz_degree_com.query(\"community != 'Python and Classical ML'\")\n# First layer\ng = sns.barplot(x=\"community\", y=\"degree\",\n                data=df_phd, color=COLORS_SET_B_G_R[2],\n                dodge=True, ci=90, capsize=0.1, errwidth =1, ax=axes[1], edgecolor='black')\n# Second layer\ng = sns.barplot(x=\"community\", y=\"degree\",\n                data=df_phd_viz_degree_com, color='lightgrey',\n                dodge=True, ci=None, capsize=0.1, ax=axes[1])\n# Remove redundant borders\naxes[1].xaxis.grid(False)\naxes[1].yaxis.grid(False)\naxes[1].xaxis.set_label_text(\"\")\naxes[1].yaxis.set_label_text(\"\")\nsns.despine(left=False, bottom=False)\n# Set tile\n_ = axes[1].set_title('Mean degree\\n for the skillset communities', fontsize=16, pad=25)\naxes[1].tick_params(axis='x', which='major', labelsize=12)\naxes[1].set_xticklabels(axes[0].get_xticklabels(), rotation=45, horizontalalignment='right')\n\n# Additional options\nfig.subplots_adjust(wspace=0.5)\n_ = plt.setp(fig.patches, linewidth=0.5)","afd4ffab":"# Create dataframes for visualization\ndf_phd_viz_degree_exp = df_phd.copy()\ndf_phd_viz_degree_exp = df_phd_viz_degree_exp.query(\"Q15 != '< 1 years' and Q15 != '1-2 years' and Q15 != '3-5 years'\")\ndf_phd_viz_degree_student = df_phd.copy()\ndf_phd_viz_degree_student = df_phd_viz_degree_student.query(\"student != 'Student'\")\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\nsns.set(font_scale=1, style=\"whitegrid\")\n\n# First layer\ng = sns.barplot(x=\"Q15\", y=\"degree\",\n                data=df_phd, color=COLORS_SET_B_G_R[0],\n                dodge=True, ci=90, capsize=0.1, ax=axes[0], errwidth =1, edgecolor='black')\n# Second layer\ng = sns.barplot(x=\"Q15\", y=\"degree\",\n                data=df_phd_viz_degree_exp, color=COLORS_SET_B_G_R[2],\n                dodge=True, ci=None, capsize=0.1, ax=axes[0], edgecolor='black')\n# Remove redundant labels and borders\naxes[0].xaxis.grid(False)\naxes[0].yaxis.grid(False)\naxes[0].xaxis.set_label_text(\"\")\naxes[0].yaxis.set_label_text(\"\")\nsns.despine(left=False, bottom=False)\n# Set title\n_ = axes[0].set_title('Mean degree by levels of experience', fontsize=16, pad=25)\n# Set x ticks\naxes[0].tick_params(axis='x', which='major', labelsize=12)\n\ng = g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')\n\n# First layer\ng = sns.barplot(x=\"student\", y=\"degree\",\n                data=df_phd, color=COLORS_SET_B_G_R[2],\n                dodge=True, ci=90, capsize=0.1, ax=axes[1], errwidth =1, edgecolor='black')\n# Second layer\ng = sns.barplot(x=\"student\", y=\"degree\",\n                data=df_phd_viz_degree_student, color='lightgrey',\n                dodge=True, ci=None, capsize=0.1, ax=axes[1])\n# Remove redundant labels and borders\naxes[1].xaxis.grid(False)\naxes[1].yaxis.grid(False)\naxes[1].xaxis.set_label_text(\"\")\naxes[1].yaxis.set_label_text(\"\")\nsns.despine(left=False, bottom=False)\n# Set title\n_ = axes[1].set_title('Mean degree for students', fontsize=16, pad=25)\n# Set x ticks params\naxes[1].tick_params(axis='x', which='major', labelsize=12)\n_ = axes[1].xaxis.set_ticklabels([\"non-Student\", \"Student\"])\n\n# Additional options\nfig.subplots_adjust(wspace=0.5)\n_ = plt.setp(fig.patches, linewidth=0.5)","3f42bfc2":"# Create list of top 20 countries in survey\ntop_countries = list(df_fin.Q3.value_counts().head(21).index)\ntop_countries.remove('Other')\n# Create dataframe with only these countries\ndf_fin['Q3_top'] = list(map(lambda c: c if c in top_countries else np.nan, df_fin['Q3']))\ntop_countries = df_fin['Q3_top'].value_counts().index\ndf_top15 = df_fin[df_fin['Q3'].apply(lambda country: True if country in top_countries else False)]\n\n# Get matrix of skill similarities between respondents from Top 20 countries\ndf_phd_temp, G, similarity_matrix = participantsGraphObj(df_top15, q_threshold=0.95, removeDisconnected=False,\n                                                    only_phd=False)\nsimilarity_matrix = pd.DataFrame(similarity_matrix)\n\n# Get list of countries coresponding to each respondent\nvertex_category = list(df_phd_temp['Q3_top'])\n\n\ndef proportionCategories(column):\n    '''Calculate average proportion of connections from each country for one respondent'''\n    temp_df = pd.DataFrame({'title':vertex_category,\n                            'weight':column})\n    return list(temp_df.groupby('title')['weight'].mean())\n\n# Calculate dataframe of respondents and similarity for each countries\ndf_stats = pd.DataFrame({'vertex_category':vertex_category,\n                         'edges_proportion':similarity_matrix.apply(proportionCategories)})\ndf_stats = pd.concat([df_stats, pd.DataFrame(df_stats.edges_proportion.values.tolist())], 1)\ndf_stats.drop(columns='edges_proportion', inplace=True)\ndf_stats.columns = ['vertex_category'] + list(np.sort(df_stats.vertex_category.unique()))\n\n# Grouping respondents from previous dataframe by their countries to obtain matrix of similarities between each country\nsimilarity_stats = df_stats.groupby('vertex_category')[df_stats.columns[1:]].mean()\nsimilarity_stats = (similarity_stats > np.mean(similarity_stats).mean()) + 0\n\n# Load graph from similarity matrix\nG = nx.from_numpy_matrix(np.matrix(similarity_stats))\n\n# Remove selfloops\nG.remove_edges_from(nx.selfloop_edges(G))\n\n# Add weight to edges\nedges = G.edges()\nweights = [G[u][v]['weight'] for u,v in edges]\nweights = [w for w in weights]\n\n# Create kamada-kawai layout\npos_kkl = nx.kamada_kawai_layout(G)\n\n\nlabels = {}\nfor i, label in enumerate(similarity_stats.columns):\n    labels[i] = label\n        \n# Community detection\npartition = list(community.greedy_modularity_communities(G, weight='weight'))\ndict_node_community = dict()\nfor community_i in range(len(partition)):\n    for node in partition[community_i]:\n        dict_node_community[node] = community_i\npartition = pd.DataFrame(pd.Series(dict_node_community)).reset_index().sort_values(by='index')[0].values\n\n# Coloring\ncommunity_colors = dict({0:COLORS_SET_B_G_R[0], 1:COLORS_SET_B_G_R[1], 2:COLORS_SET_B_G_R[2], 3:'lightgrey'})\ncommunity_colors = list(map(lambda p: community_colors[p], partition))\ncountries_size = []\nfor country in similarity_stats.columns:\n    countries_size.append(sum(df_phd_temp['Q3_top'] == country))","2d3e6369":"# Plotting the Graph\nfig, ax = plt.subplots(figsize=(13, 13))\nnx.draw(G, pos_kkl, node_size=list(pd.Series(countries_size)*5),\n        edges=edges, width=weights, edge_color='grey', node_color=community_colors)\nnode_labels = nx.draw_networkx_labels(G, pos_kkl, labels, font_size=14)\n\n# Set the title\n_ = ax.set_title('Network of countries', fontsize=30, pad=30)\n# Set edge color\nplt.gca().collections[0].set_edgecolor(\"#000000\")","40aba6d5":"# Create dataframe with countries network statistics\ncountry_network_stats = pd.DataFrame({'country':similarity_stats.columns,\n                                      'community':partition})\n\n# Drop Mexico\ncountry_network_stats = country_network_stats[country_network_stats['community'] <= 2]\n# Rename them\ncountry_network_stats['community'] = country_network_stats['community'].map({0:'Western countries', 1:'Eastern countries', 2:'Developing countries'})\n# Create dictionary with country and community\ncountry_community_dict = dict(zip(country_network_stats['country'], country_network_stats['community']))\n\n# Add countries community to dataframe with PhD participants\ndf_phd['country_community'] = [country_community_dict[country] if country in country_community_dict else np.nan for country in df_phd['Q3']]\n\n# Add countries community to the full dataframe\ndf_fin['country_community'] = [country_community_dict[country] if country in country_community_dict else np.nan for country in df_fin['Q3']]\n\n# Number of PhD in each country\nstats_phd_total = pd.DataFrame({'PhD':df_phd['country_community'].value_counts(),\n                                'Total':df_fin['country_community'].value_counts()})\nstats_phd_total.reset_index(inplace=True)\n\nsns.set(style=\"whitegrid\")\n# Initialize the matplotlib figure\nf, ax = plt.subplots(figsize=(5, 3))\nsns.barplot(x=\"Total\", y=\"index\", data=stats_phd_total,\n            label=\"Total\", color=\"lightgrey\")\nsns.barplot(x=\"PhD\", y=\"index\", data=stats_phd_total,\n            label=\"PhD\", color=COLORS_SET_B_G_R[2], edgecolor='black')\n# Add a legend and informative axis label\nax.legend(ncol=2, loc=\"lower right\", frameon=True, prop={'size': 10})\nax.set(xlim=(0, 5000), ylabel=\"\", xlabel=\"PhD and Total\")\n\n# Remove reduntant borders and labels\nax.xaxis.grid(False)\nax.yaxis.grid(False)\nax.xaxis.set_label_text(\"\")\nax.yaxis.set_label_text(\"\")\nsns.despine(left=False, bottom=False)\n\n# Set title and labels size\n_ = ax.set_title('Number of PhD holders\\n for the country communities', fontsize=20, pad=25)\nax.tick_params(axis='y', which='major', labelsize=12)\n_ = plt.setp(fig.patches, linewidth=0.5)","f79a2c4e":"fig, ax = plt.subplots(figsize=(3.5, 3.5))\nsns.heatmap(pd.crosstab(df_phd['country_community'], df_phd['community'], normalize='index'),\n            annot=True, fmt='.0%', linecolor ='black',linewidths=.01, cmap=ListedColormap(sns.light_palette(COLORS_SET_B_G_R[2]).as_hex()),\n            cbar=False, annot_kws={\"size\": 14}, robust=True, vmin=0.05, vmax=0.55)\n\n# Set title\nax.set_title('Eastern-Western difference')\n\n# Set x ticks\nax.tick_params(axis='both', which='major', labelsize=12)\nax.xaxis.tick_top()\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation = 45, horizontalalignment='left')\n\n# Remove reduntant labels\nax.xaxis.set_label_text(\"\")\nax.yaxis.set_label_text(\"\")\n\n# Set title\n_ = ax.set_title('Skillsets and regions', fontsize=20, pad=30)","fb652226":"def createSkillsNetwork(df, countries=False):\n    \n    # Select subset of countries\n    if countries:\n        df = df[df['country_community'] == countries]\n    \n    # Creating similarity matrix\n    similarity_matrix = cosine_similarity(df.loc[:,SELECTED_SKILLS].T)\n    np.fill_diagonal(similarity_matrix, 0)\n    # Transform weighted network to binary via threshold\n    threshold = np.median(similarity_matrix)\n    similarity_matrix[similarity_matrix < threshold] = 0\n    similarity_matrix[similarity_matrix >= threshold] = 1\n    # Create Graph structure\n    G = nx.from_numpy_matrix(similarity_matrix)\n    G.remove_edges_from(nx.selfloop_edges(G))\n    # Set weights for edges\n    edges = G.edges()\n    weights = [G[u][v]['weight'] for u,v in edges]\n    weights = [w*0.25 for w in weights]\n    # Set node sizes\n    node_sizes = df.loc[:,SELECTED_SKILLS].sum().values \/ 10\n    \n    # Add labels\n    labels = {}\n    for i, label in enumerate(df.loc[:,SELECTED_SKILLS].columns):\n        labels[i] = label\n    # Total skills frequency\n    total_skills_freq = df.loc[:,SELECTED_SKILLS].sum()\n    # Proportion of PhDs per skill\n    phd_skills_freq = df[df['Q4_phd'] == 'PhD'].loc[:,SELECTED_SKILLS].sum()\n    phd_skills_proportion = phd_skills_freq \/ total_skills_freq\n    # Proportion of PhD-students per skill\n    phd_student_skills_freq = df.query(\"Q4_phd == 'PhD' and student == 'student'\").loc[:,SELECTED_SKILLS].sum()\n    phd_student_skills_proportion = phd_student_skills_freq \/ total_skills_freq\n\n    # Create dataframe with skills statistics: avg. salary, core number, PhD proportion\n    df_skills_stats = pd.DataFrame({'skill':SELECTED_SKILLS,\n                                    'core_number':list(nx.algorithms.core.core_number(G).values()),\n                                    'phd_proportion':phd_skills_proportion.values,\n                                    'phd_student_proportion':phd_student_skills_proportion.values,\n                                    'node_size':node_sizes})\n    \n    # Create binary version of phd proportion and core number\n    df_skills_stats['core_bin'] = df_skills_stats['core_number'].apply(\n        lambda x: 1 if x == max(df_skills_stats['core_number']) else 0)\n    df_skills_stats['phd_bin'] = df_skills_stats['phd_proportion'].apply(\n        lambda x: 1 if x >= np.mean(df_skills_stats['phd_proportion']) else 0)\n    df_skills_stats['phd_student_bin'] = df_skills_stats['phd_student_proportion'].apply(\n        lambda x: 1 if x >= np.mean(df_skills_stats['phd_student_proportion']) else 0)\n\n    return G, labels, df_skills_stats\n\n# Obtain skillsnetwork\nG, labels, df_skills_stats = createSkillsNetwork(df_fin)\n\n# Plot the Graph with PhD proportion\n# Create kamada-kawai layout\npos_kkl = nx.kamada_kawai_layout(G)\nf, ax = plt.subplots(figsize=(16, 16))\nnx.draw(G, pos_kkl, node_size=list(map(lambda x: 1000 if x >= df_skills_stats['phd_proportion'].mean() else 200, list(df_skills_stats['phd_proportion']))), \n        width=0.15, edge_color='grey', node_color=list(df_skills_stats['core_number']), cmap=\"coolwarm_r\", alpha=0.9)\nnode_labels = nx.draw_networkx_labels(G, pos_kkl, labels, font_size=10)\n# Set title\n_ = ax.set_title('Network of skills', fontsize=36, pad=30)\n# Set edge color\nplt.gca().collections[0].set_edgecolor(\"#000000\")","e25f9ede":"# Core PhD skills\ncore_phd_list = list(df_skills_stats.query(\"phd_bin == 1 and core_bin == 1\").skill)\ncore_phd_list = df_fin.query(\"Q4 == 'Doctoral degree'\").loc[:,core_phd_list].sum()\n\n# Perephiery PhD skills\nperephiery_phd_list = list(df_skills_stats.query(\"phd_bin == 1 and core_bin == 0\").skill)\nperephiery_phd_list = df_fin.query(\"Q4 == 'Doctoral degree'\").loc[:,perephiery_phd_list].sum()\n\nfig = plt.figure()\nfig.set_size_inches(20, 10)\ncolors_set = ['royalblue', 'indianred']\nskills_list = [core_phd_list,\n               perephiery_phd_list]\ntitles_list = ['Core PhD skills', 'Periphery PhD skills']\n\nfor i in range(2):\n    \n    # Generate string with proportional words \n    top_skills = skills_list[i].sort_values(ascending=False)\n    top_skills = top_skills.rank()\n    skills_string = []\n    for skill_i in range(len(top_skills)):\n        skills_string.extend([top_skills.index[skill_i]] * int(top_skills.values[skill_i]))\n    \n    ax = fig.add_subplot(1,2,i+1)\n    word_could_dict=Counter(skills_string)\n    # Create wordcloud object\n    wordcloud = WordCloud(width = 1200, height = 1200, background_color=\"white\",\n                          color_func=lambda *args, **kwargs: colors_set[i], relative_scaling = 0.5).generate_from_frequencies(word_could_dict)\n    \n    ax.imshow(wordcloud, interpolation = 'bilinear')\n    ax.axis('off')\n    # Set title\n    ax.set_title(titles_list[i], size=48, pad=50)\n    \nplt.tight_layout(pad=0)\nplt.show()","dd76345b":"# Create grahs for each region\nG_west, labels_west, df_skills_stats_west = createSkillsNetwork(df_fin, 'Western countries')\nG_east, labels_east, df_skills_stats_east = createSkillsNetwork(df_fin, 'Eastern countries')\nG_develop, labels_develop, df_skills_stats_develop = createSkillsNetwork(df_fin, 'Developing countries')\n\ngraphs = [G_west, G_east, G_develop]\ndf_skills_stats_list = [df_skills_stats_west, df_skills_stats_east, df_skills_stats_develop]\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(30, 10))\nax = axes.flatten()\nsize_multip = 1\n\nfor i in range(3):\n    # Create kamada-kawai layout\n    pos_kkl = nx.kamada_kawai_layout(graphs[i])\n    if i == 1:\n        size_multip = 3\n    # Draw network\n    nx.draw_networkx(graphs[i], ax=ax[i], pos=pos_kkl,\n                     node_size=list(map(lambda x: 600 if x >= df_skills_stats_list[i]['phd_proportion'].mean() else 60, list(df_skills_stats_list[i]['phd_proportion']))),\n                     width=0.15,\n                     edge_color='grey',node_color=list(df_skills_stats['core_number']), cmap=\"coolwarm_r\", alpha=0.9,\n                     with_labels=False)\n    ax[i].set_axis_off()\n    ax[i].collections[0].set_edgecolor(\"#000000\")\n\n# Set titles and correlation between coreness and PhD proportion\n_ = axes[0].set_title('Western countries,\\n r=0.29', fontsize=24, pad=30)\n_ = axes[1].set_title('Eastern countries,\\n r=-0.31', fontsize=24, pad=30)\n_ = axes[2].set_title('Developing countries,\\n r=-0.38', fontsize=24, pad=30)\n# Set general title\nst = fig.suptitle(\"Networks of skills by regions\", fontsize=32, x =0.5, y=1.1)\n\nplt.show()","a0c66496":"# Remove students from the dataframe\ndf_fin = df_fin[df_fin['Q5'] != 'Student']\n\n# # Drop respondents who did't indicate their salary\ndf_fin = df_fin.dropna(subset=['Q10'])\n\n# Change salary from interval to numeric scale\ndef transformSalary(string):\n    if string == \"> $500,000\":\n        mean_salary = 750000.\n    else:\n        mean_salary = np.round(np.mean([np.float(string.split('-')[0].replace('$', '').replace(',', '')),\n                                        np.float(string.split('-')[1].replace(',', ''))]))\n    return mean_salary\ndf_fin['Q10'] = df_fin['Q10'].apply(transformSalary)\ndf_fin['Q10'] = df_fin['Q10'].astype('float')\n\n# Add binary variable USA-not USA\ndf_fin['Q3_USA'] = ['USA' if country == 'USA' else 'not USA' for country in df_fin['Q3']]\n\n# Recode experience\nexp_order = ['< 1 years', '1-2 years', '3-5 years', '5-10 years', '10-20 years', '20+ years']\nexp_level = ['Low experience', 'Low experience', 'Middle experience', 'Middle experience', 'High experience', 'High experience']\ndf_fin['Q15_level'] = df_fin['Q15'].map(dict(zip(exp_order, exp_level)))\ndf_fin['Q15_level'] = df_fin['Q15_level'].astype('category')\ndf_fin['Q15_level'].cat.reorder_categories(['Low experience', 'Middle experience', 'High experience'], inplace=True)\n\n# Distribution of salary for PhD and distribution for Experience\ndf_fin_viz_phd_1 = df_fin.copy()\ndf_fin_viz_phd_1 = df_fin_viz_phd_1.query(\"Q4_phd != 'PhD'\")","9bff34ca":"fig, ax = plt.subplots(figsize=(5, 5))\n# First layer\ng = sns.barplot(x=\"Q4_phd\", y=\"Q10\",\n                data=df_fin, color=COLORS_SET_B_G_R[2],\n                dodge=True, ci=90, capsize=0.1, errwidth =1, edgecolor='black')\n# Second layer\ng = sns.barplot(x=\"Q4_phd\", y=\"Q10\",\n                data=df_fin_viz_phd_1, color='lightgrey',\n                dodge=True, ci=None, capsize=0.1)\n\n# Remove redundant labels and borders\nsns.despine(left=False, bottom=False)\nax.xaxis.grid(False)\nax.yaxis.grid(False)\nax.xaxis.set_label_text(\"\")\nax.yaxis.set_label_text(\"\")\n# Set title\n_ = ax.set_title('Salary for PhD kagglers', fontsize=20, pad=25)\n# Set x ticks\nax.tick_params(axis='x', which='major', labelsize=12)\n_ = ax.xaxis.set_ticklabels([\"PhD\", \"non-PhD\"])\n_ = plt.setp(g.patches, linewidth=0.5) ","58d98676":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 4))\nsns.set(font_scale=1, style=\"whitegrid\")\n\n# First layer\ng = sns.barplot(x=\"Q4_phd\", y=\"Q10\",\n                data=df_fin[df_fin['country_community'] == 'Western countries'], color=COLORS_SET_B_G_R[2],\n                dodge=True, ci=90, capsize=0.1, ax=axes[0], errwidth =1, edgecolor='black')\n# Second layer\ng = sns.barplot(x=\"Q4_phd\", y=\"Q10\",\n                data=df_fin_viz_phd_1[df_fin_viz_phd_1['country_community'] == 'Western countries'], color='lightgrey',\n                dodge=True, ci=None, capsize=0.1, ax=axes[0])\n# Set y lim\n_ = axes[0].set_ylim((0, 130000))\n# Remove redundant labels and borders\nsns.despine(left=False, bottom=False)\naxes[0].xaxis.grid(False)\naxes[0].yaxis.grid(False)\naxes[0].xaxis.set_label_text(\"\")\naxes[0].yaxis.set_label_text(\"\")\n# Set title\n_ = axes[0].set_title('Western countries', fontsize=16, pad=10)\n# Set x ticks params\naxes[0].tick_params(axis='x', which='major', labelsize=12)\n_ = axes[0].xaxis.set_ticklabels([\"PhD\", \"non-PhD\"])\n\ng = sns.barplot(x=\"Q4_phd\", y=\"Q10\",\n                data=df_fin[df_fin['country_community'] == 'Eastern countries'], color='lightgrey',\n                dodge=True, ci=90, capsize=0.1, ax=axes[1], errwidth =1)\ng = sns.barplot(x=\"Q4_phd\", y=\"Q10\",\n                data=df_fin_viz_phd_1[df_fin_viz_phd_1['country_community'] == 'Eastern countries'], color='lightgrey',\n                dodge=True, ci=None, capsize=0.1, ax=axes[1])\n# Set y limits\n_ = axes[1].set_ylim((0, 130000))\n# Remove redundant labels and borders\nsns.despine(left=False, bottom=False)\naxes[1].xaxis.grid(False)\naxes[1].yaxis.grid(False)\naxes[1].xaxis.set_label_text(\"\")\naxes[1].yaxis.set_label_text(\"\")\n# Set title\n_ = axes[1].set_title('Eastern countries', fontsize=16, pad=10)\n# Set x ticks\naxes[1].tick_params(axis='x', which='major', labelsize=12)\naxes[1].set_yticks([])\n_ = axes[1].xaxis.set_ticklabels([\"PhD\", \"non-PhD\"])\n\n# First layer\ng = sns.barplot(x=\"Q4_phd\", y=\"Q10\",\n                data=df_fin[df_fin['country_community'] == 'Developing countries'], color='lightgrey',\n                dodge=True, ci=90, capsize=0.1, ax=axes[2], errwidth =1)\n# Second layer\ng = sns.barplot(x=\"Q4_phd\", y=\"Q10\",\n                data=df_fin_viz_phd_1[df_fin_viz_phd_1['country_community'] == 'Developing countries'], color='lightgrey',\n                dodge=True, ci=None, capsize=0.1, ax=axes[2])\n# Set y lim\n_ = axes[2].set_ylim((0, 130000))\n# Remove redundant labels and borders\nsns.despine(left=False, bottom=False)\naxes[2].xaxis.grid(False)\naxes[2].yaxis.grid(False)\naxes[2].xaxis.set_label_text(\"\")\naxes[2].yaxis.set_label_text(\"\")\n_ = axes[2].set_title('Developing countries', fontsize=16, pad=10)\naxes[2].tick_params(axis='x', which='major', labelsize=12)\naxes[2].set_yticks([])\n_ = axes[2].xaxis.set_ticklabels([\"PhD\", \"non-PhD\"])\n\n# Additional options\nfig.subplots_adjust(wspace=0.2)\nplt.setp(g.patches, linewidth=0.5) \n\n# Set general title\nst = fig.suptitle(\"Salary for PhD kagglers by regions\", fontsize=20, x =0.5, y=1.1)","ebca000e":"def salariesDifferencePhd(df, exp_level,  countries_community, q_threshold=0.95, SELECTED_SKILLS=SELECTED_SKILLS):\n    '< 1 years', '1-2 years', '3-5 years', '5-10 years', '10-20 years', '20+ years'\n    # Select subgroup of interest\n    df = df.query(\"Q15_level == '{}' and country_community == '{}'\".format(exp_level, countries_community))\n        \n    df.reset_index(inplace=True, drop=True)\n    # Create similarity matrix\n    similarity_matrix = cosine_similarity(df.loc[:,SELECTED_SKILLS])\n    threshold = np.quantile(np.concatenate(similarity_matrix), q_threshold)\n    similarity_matrix[similarity_matrix < threshold] = 0\n    similarity_matrix[similarity_matrix >= threshold] = 1\n    np.fill_diagonal(similarity_matrix, 0)\n    # Create dictionaries with index number and PhD status\/Salary\n    dict_index_phd = dict(zip(df.index, df['Q4_phd']))\n    dict_index_salary = dict(zip(df.index, df['Q10']))\n    # Transform adjency matrix to edge list\n    similarity_matrix = pd.DataFrame(similarity_matrix)\n    similarity_matrix.values[[np.arange(len(similarity_matrix))]*2] = np.nan\n    edge_list = similarity_matrix.stack().reset_index()\n    # Select only edges with high similarity\n    edge_list = edge_list[edge_list[0] == 1]\n    edge_list = edge_list.drop(columns=0)\n    # Label status of participants\n    edge_list['level_0_phd'] = edge_list['level_0'].apply(lambda x: dict_index_phd[x], 1)\n    edge_list['level_1_phd'] = edge_list['level_1'].apply(lambda x: dict_index_phd[x], 1)\n    # Select only PhD\/not-PhD pairs\n    edge_list = edge_list[edge_list.loc[:,['level_0_phd', 'level_1_phd']].apply(lambda nodes: True if nodes[0] != nodes[1] else False, 1)]\n    # Get salaries of participants\n    edge_list['level_0_salary'] = edge_list['level_0'].apply(lambda x: dict_index_salary[x], 1)\n    edge_list['level_1_salary'] = edge_list['level_1'].apply(lambda x: dict_index_salary[x], 1)\n    edge_list = edge_list[edge_list['level_0_phd'] == 'PhD']\n    # Calculate salaries difference\n    salary_diff = edge_list.groupby('level_0')['level_0_salary'].mean() - edge_list.groupby('level_0')['level_1_salary'].mean()\n    # Resulting dataframe\n    result_df = pd.DataFrame({'Salary difference':salary_diff,\n                'Experience level':len(salary_diff) * [exp_level],\n                'Countries':len(salary_diff) * [countries_community]}).reset_index(drop=True)\n    return result_df\n\n# Calculate salary diff\nsalary_diff_df = pd.DataFrame()\nfor exp in ['Low experience', 'Middle experience', 'High experience']:\n    for countries in ['Western countries', 'Eastern countries', 'Developing countries']:       \n        salary_diff_df = salary_diff_df.append(salariesDifferencePhd(df_fin, exp, countries))\nsalary_diff_df.reset_index(inplace=True, drop=True)\n\n# Order experience level for visualization\nsalary_diff_df['Experience level'] = salary_diff_df['Experience level'].astype('category')\nsalary_diff_df['Experience level'].cat.reorder_categories(['Low experience', 'Middle experience', 'High experience'], inplace=True)\n\n# Create dataframes for visualization\nsalary_diff_df_viz_1 = salary_diff_df[salary_diff_df['Countries'] == 'Western countries'].copy()\nsalary_diff_df_viz_1 = salary_diff_df_viz_1[salary_diff_df_viz_1['Experience level'] != 'Low experience']\n\nsalary_diff_df_viz_2 = salary_diff_df[salary_diff_df['Countries'] == 'Eastern countries'].copy()\nsalary_diff_df_viz_2 = salary_diff_df_viz_2[salary_diff_df_viz_2['Experience level'] != 'Low experience']\n\nsalary_diff_df_viz_3 = salary_diff_df[salary_diff_df['Countries'] == 'Developing countries'].copy()\nsalary_diff_df_viz_3 = salary_diff_df_viz_3[salary_diff_df_viz_3['Experience level'] != 'High experience']","3ac8fad4":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\nsns.set(font_scale=1, style=\"whitegrid\")\n\n### FIRST GRAPH\n# Plot first layer\ng = sns.barplot(x=\"Experience level\", y=\"Salary difference\", data=salary_diff_df[salary_diff_df['Countries'] == 'Western countries'],\n                dodge=True, errwidth =1, ci=90, capsize=.05, color=COLORS_SET_B_G_R[1], ax=axes[0], edgecolor='black')\n# Plot second layer\ng = sns.barplot(x=\"Experience level\", y=\"Salary difference\", data=salary_diff_df_viz_1,\n                dodge=True, errwidth =2, ci=None, capsize=.05, color='lightgrey', ax=axes[0])\n# Set y limit\n_ = axes[0].set_ylim((-100000,50000))\n# Remove redundant borderes\nsns.despine(left=False, bottom=False)\naxes[0].xaxis.grid(False)\naxes[0].yaxis.set_label_text(\"\")\n# Set title\n_ = axes[0].set_title('Western countries', fontsize=16, pad=25)\n# Set x and y ticks\naxes[0].tick_params(axis='y', which='major', labelsize=10)\naxes[0].tick_params(axis='x', which='major', labelsize=16)\naxes[0].xaxis.set_ticklabels([\"Low\", \"Middle\", \"High\"])\n\n### SECOND GRAPH\n# Plot first layer\ng = sns.barplot(x=\"Experience level\", y=\"Salary difference\", data=salary_diff_df[salary_diff_df['Countries'] == 'Eastern countries'],\n                dodge=True, errwidth =1, ci=90, capsize=.05, color=COLORS_SET_B_G_R[2], ax=axes[1], edgecolor='black')\n# Plot second layer\ng = sns.barplot(x=\"Experience level\", y=\"Salary difference\", data=salary_diff_df_viz_2,\n                dodge=True, errwidth =2, ci=None, capsize=.05, color='lightgrey', ax=axes[1])\n# Set y limit\n_ = axes[1].set_ylim((-100000,50000))\n# Remove redundant borderes\nsns.despine(left=False, bottom=False)\naxes[1].xaxis.grid(False)\naxes[1].yaxis.set_label_text(\"\")\n# Set title\n_ = axes[1].set_title('Eastern countries', fontsize=16, pad=25)\n# Set x and y ticks\naxes[1].tick_params(axis='y', which='major', labelsize=10)\naxes[1].tick_params(axis='x', which='major', labelsize=16)\naxes[1].yaxis.set_ticklabels([])\naxes[1].xaxis.set_ticklabels([\"Low\", \"Middle\", \"High\"])\n\n### THIRD GRAPH\n# Plot first layer\ng = sns.barplot(x=\"Experience level\", y=\"Salary difference\", data=salary_diff_df[salary_diff_df['Countries'] == 'Developing countries'],\n                dodge=True, errwidth =1, ci=90, capsize=.05, color=COLORS_SET_B_G_R[2], ax=axes[2], edgecolor='black')\n# Plot second layer\ng = sns.barplot(x=\"Experience level\", y=\"Salary difference\", data=salary_diff_df_viz_3,\n                dodge=True, errwidth =2, ci=None, capsize=.05, color='lightgrey', ax=axes[2])\n# Set y limit\n_ = axes[2].set_ylim((-100000,50000))\n# Remove redundant borderes\nsns.despine(left=False, bottom=False)\naxes[2].xaxis.grid(False)\naxes[2].yaxis.set_label_text(\"\")\n# Set title\n_ = axes[2].set_title('Developing countries', fontsize=16, pad=25)\n# Set x and y ticks\naxes[2].tick_params(axis='y', which='major', labelsize=10)\naxes[2].tick_params(axis='x', which='major', labelsize=16)\n_ = axes[2].yaxis.set_ticklabels([])\naxes[2].xaxis.set_ticklabels([\"Low\", \"Middle\", \"High\"])\n\n# Additional options\nplt.setp(g.patches, linewidth=0.5)\n\n# Set general title\nst = fig.suptitle(\"Salary difference between PhD and non-PhD holders by regions\", fontsize=20, x =0.5, y=1.15)","99216f78":"def salariesDifferenceGender(df, countries_community, q_threshold=0.95,\n                             SELECTED_SKILLS=SELECTED_SKILLS, only_phd=True):\n    \n    # Select only male and female respondents\n    df = df.query(\"Q2 == 'Male' or Q2 == 'Female'\")\n    \n    # Select subgroup of interest\n    df = df.query(\"country_community == '{}'\".format(countries_community))\n    \n    if only_phd:\n        df = df.query(\"Q4 == 'Doctoral degree'\")\n        \n    df.reset_index(inplace=True, drop=True)\n    # Create similarity matrix\n    similarity_matrix = cosine_similarity(df.loc[:,SELECTED_SKILLS])\n    threshold = np.quantile(np.concatenate(similarity_matrix), q_threshold)\n    similarity_matrix[similarity_matrix < threshold] = 0\n    similarity_matrix[similarity_matrix >= threshold] = 1\n    np.fill_diagonal(similarity_matrix, 0)\n    # Create dictionaries with index number and PhD status\/Salary\n    dict_index_phd = dict(zip(df.index, df['Q2']))\n    dict_index_salary = dict(zip(df.index, df['Q10']))\n    # Transform adjency matrix to edge list\n    similarity_matrix = pd.DataFrame(similarity_matrix)\n    similarity_matrix.values[[np.arange(len(similarity_matrix))]*2] = np.nan\n    edge_list = similarity_matrix.stack().reset_index()\n    # Select only edges with high similarity\n    edge_list = edge_list[edge_list[0] == 1]\n    edge_list = edge_list.drop(columns=0)\n    # Label status of participants\n    edge_list['level_0_phd'] = edge_list['level_0'].apply(lambda x: dict_index_phd[x], 1)\n    edge_list['level_1_phd'] = edge_list['level_1'].apply(lambda x: dict_index_phd[x], 1)\n    # Select only PhD\/not-PhD pairs\n    edge_list = edge_list[edge_list.loc[:,['level_0_phd', 'level_1_phd']].apply(lambda nodes: True if nodes[0] != nodes[1] else False, 1)]\n    # Get salaries of participants\n    edge_list['level_0_salary'] = edge_list['level_0'].apply(lambda x: dict_index_salary[x], 1)\n    edge_list['level_1_salary'] = edge_list['level_1'].apply(lambda x: dict_index_salary[x], 1)\n    edge_list = edge_list[edge_list['level_0_phd'] == 'Female']\n    \n    # Calculate salaries difference\n    salary_diff = edge_list.groupby('level_0')['level_0_salary'].mean() - edge_list.groupby('level_0')['level_1_salary'].mean()\n\n    # Resulting dataframe\n    if only_phd:\n        result_df = pd.DataFrame({'Salary difference':salary_diff,\n                                  'Countries':len(salary_diff) * [countries_community],\n                                  'Subset':len(salary_diff) * ['PhD']}).reset_index(drop=True)\n    else:\n        result_df = pd.DataFrame({'Salary difference':salary_diff,\n                          'Countries':len(salary_diff) * [countries_community],\n                          'Subset':len(salary_diff) * ['Total']}).reset_index(drop=True)\n    \n    return result_df\n\nsalary_diff_df_gender = pd.DataFrame()\nfor countries in ['Western countries', 'Eastern countries', 'Developing countries']:       \n    salary_diff_df_gender = salary_diff_df_gender.append(salariesDifferenceGender(df_fin, countries, q_threshold=0.95))\nsalary_diff_df_gender.reset_index(inplace=True, drop=True)\n\n# Take only PhD differences\nsalary_diff_df_gender_phd = salary_diff_df_gender[salary_diff_df_gender['Subset'] == 'PhD']\n\n# Obtain mean salary for each region\ndict_country_salary = {'Western countries':np.mean(df_fin[df_fin['country_community'] == 'Western countries']['Q10']),\n                       'Eastern countries':np.mean(df_fin[df_fin['country_community'] == 'Eastern countries']['Q10']),\n                       'Developing countries':np.mean(df_fin[df_fin['country_community'] == 'Developing countries']['Q10'])}\nsalary_diff_df_gender_phd['Mean salary'] = salary_diff_df_gender_phd['Countries'].map(dict_country_salary)\n# Calculate proportional difference\nsalary_diff_df_gender_phd['Salary difference, proportional to the regional mean salary'] = salary_diff_df_gender_phd['Salary difference'] \/ salary_diff_df_gender_phd['Mean salary']\n\n# Order countries for plot\nsalary_diff_df_gender_phd['Countries'] = salary_diff_df_gender_phd['Countries'].astype('category')\nsalary_diff_df_gender_phd['Countries'].cat.reorder_categories([\"Western countries\", \"Eastern countries\", \"Developing countries\"], inplace=True)\n\n# Create dataframe for visualization\nsalary_diff_df_gender_phd_viz = salary_diff_df_gender_phd.copy()\nsalary_diff_df_gender_phd_viz = salary_diff_df_gender_phd_viz[salary_diff_df_gender_phd_viz['Countries'] == 'Eastern countries']\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\nsns.set(font_scale=1, style=\"whitegrid\")\n# Plot first layer\ng = sns.barplot(x=\"Countries\", y=\"Salary difference\", data=salary_diff_df_gender_phd,\n                dodge=True, errwidth =1, ci=90, capsize=.05, color=COLORS_SET_B_G_R[2], ax=axes[0], edgecolor='black')\n# Plot second layer\ng = sns.barplot(x=\"Countries\", y=\"Salary difference\", data=salary_diff_df_gender_phd_viz,\n                dodge=True, errwidth =1, ci=None, capsize=.05, color='lightgrey', ax=axes[0])\n# Remove redundant borders\nsns.despine(left=False, bottom=False)\naxes[0].xaxis.grid(False)\naxes[0].yaxis.set_label_text(\"\")\n# Set title\n_ = axes[0].set_title('Absolute values', fontsize=14, pad=25)\n# Set ticks\naxes[0].tick_params(axis='y', which='major', labelsize=10)\naxes[0].tick_params(axis='x', which='major', labelsize=16)\n_ = axes[0].xaxis.set_ticklabels([\"Western\", \"Eastern\", \"Developing\"])\n\n# Plot first layer\ng = sns.barplot(x=\"Countries\", y=\"Salary difference, proportional to the regional mean salary\", data=salary_diff_df_gender_phd,\n                dodge=True, errwidth =1, ci=90, capsize=.05, color=COLORS_SET_B_G_R[2], ax=axes[1], edgecolor='black')\n# Plot second layer\ng = sns.barplot(x=\"Countries\", y=\"Salary difference, proportional to the regional mean salary\", data=salary_diff_df_gender_phd_viz,\n                dodge=True, errwidth =1, ci=None, capsize=.05, color='lightgrey', ax=axes[1])\n# Remove redundant borders\nsns.despine(left=False, bottom=False)\naxes[1].xaxis.grid(False)\naxes[1].yaxis.set_label_text(\"\")\n# Set title\n_ = axes[1].set_title('Proportional to the regional mean salary', fontsize=14, pad=25)\n# Set ticks\naxes[1].tick_params(axis='y', which='major', labelsize=10)\naxes[1].tick_params(axis='x', which='major', labelsize=16)\n_ = axes[1].xaxis.set_ticklabels([\"Western\", \"Eastern\", \"Developing\"])\n\n# Additional options\n_ = plt.setp(g.patches, linewidth=0.5) \n\n# Set general title\nst = fig.suptitle('Salary difference between men and women with PhD', fontsize=20, x =0.5, y=1.15)","fd7248d8":"Graphs above show that the number of males with PhD achievement is roughly 5 times as high as women, meaning that even a highly academic environment retains this drastically pronounced gender-related disproportion. \n \nIn absolute terms, the US tangibly outperforms other countries by the amount PhD specialists released. The second place is occupied by India, followed by Germany and the UK that are on a comparable level.\n \nResearch scientists and data scientists are the most frequent job titles among doctoral holders. The sample also includes 246 PhD students who have not received their degree yet.","6728a312":"Overall, we figured out what the central and periphery competencies that describe a Kaggle PhD holder are. It would be intriguing to investigate national differences in the way this core-periphery continuum is manifested!\n\nThe following series of networks maps the coreness structure and the blocks of countries created earlier. Numbers in the titles of the respective graphs are correlation coefficients between the \u201ccoreness\u201d of skills and the proportion of doctorates in them. ","00c24588":"The graph above shows that, sadly, the previous statement applies only to Western countries: earnings of PhD and non-PhD professionals in Eastern and Developing regions do not diverge statistically.\n\nBut we wouldn\u2019t be us if we wouldn\u2019t add a curious piece of complexity to the current analytical section: we accounted for the similarity in skillsets and experience levels in addition to the country-wise division. Concretely, we divided a labor market experience variable into the respective categories \u2013 low (less that 3 years of experience), middle (from 3 to 10 years), and high (more than 10 years) \u2013 and for each category computed a salary difference for PhD and non-PhD holders with a similar set of skills (cosine similarity was again leveraged here). \n\nThe graph below is a visual representation of the conducted procedure. Positive and significant confidence intervals (excluding zero) favor guys with PhD (they get paid highlier), while negative and significant intervals \u2013 non-PhD specialists. Zero in a confidence interval means the difference is absent.","72485344":"Two additional degree-related tables are curious. An inverse U-shaped pattern with the experience variable informs us that as experience goes up, PhD holders incrementally broaden the scope of skills that they have until they reach some middle point of around 3-5 years. This is then followed by the growth in a skillset \u201cuniqueness\u201d as PhD people become more experienced. \n\nDegree centrality allocated between PhD students and non-students poses evidence that students are more dispersed in their data science competencies. Graduating from a PhD program narrows down a skillset held, leading to a sharpening of one\u2019s specialization.","7c4e403c":"# <a>Introduction<\/a>\n\nMany of us have ever thought of pursuing an academic career and gaining a doctoral degree. This is not surprising given an amplified need for highly trained and qualified employees in data science and experts in AI. PhD programs allow to conceivably enrich the existing corpus of knowledge and upgrade one\u2019s skillset in a structured and systematic manner, which seems notoriously hard to do elsewhere. Amongst other things, the PhD achievement is an entry to an academic elite. However, lots of doctoral AI specialists may not get a chance to enjoy the benefits of their expertise [1].\n\nOne reason is that in recent years, the importance of a PhD degree in data science has been questioned due to a stark growth in the number of doctoral degree graduates involved in labor markets outside the university, bringing about the question of PhD training relevance. Past empirical evidence suggests that doctoral education may contribute to overeducation and credential inflation [2]. Another striking indicator of a PhD\u2019s seeming value loss is a drop in the share of chief executives with doctorates coupled with PhD holders\u2019 income fall [3].\n\nFurthermore, these days, there are fewer incentives to complete a lengthy PhD program, and not everyone succeeds. People strive to occupy a job position in the industry, which does not require a doctoral degree and can be more lucrative than the research work not requesting a PhD level. The area of data science and software engineering is one of the most vulnerable in that respect: universities are lagging far behind their practice-oriented counterparts in terms of knowledge generation. Therefore, the qualification of doctorates in AI might seem dated or too specific at the applied space.\n","6d6ec1d1":"The next intriguing observation here refers to the proportion of students in the uncovered communities (see the left panel of the graph below): the upcoming generation of doctorates tends to utilize Python and Deep Learning tools to a greater extent compared to R and Classical statistical instruments. This is essential to know since it is people from the younger and higher educated generation who are usually considered trendsetters.\n\nA unique opportunity that the network-based statistics offers is related to the analysis of centrality measures. In this mini-research, we focus on the degree centrality, which shows a number of ties a certain node has. The right panel of the graph below demonstrates how our **degree centrality, representing the extent of the skill-based similarity between people**, is manifested within the clusters on average (upper bounds of the colored boxes reflect mean degree values with a 95% confidence interval). An important inference here is that representatives of the \u201cPython and Classical ML\u201d cluster are much more similar to other PhD holders (the degree is large). This signifies the erosion of boundaries in a skillset that identifies this community, whereas 2 other clusters seem to be more specific in their professional capabilities.","7a6d11e1":"![](https:\/\/i.imgur.com\/NUXaMYi.jpg)","c05729a0":"The above picture shows how the network of Kaggle doctoral graduates looks like. Colors depict homogeneous groups of AI professionals with PhD derived on the basis of network links determined. In the Network Analysis, this is termed as a community detection technique, which is somewhat similar to a traditional clustering procedure, except for complex relational parameters that the latter does not allow to capture and visualize.\n\nOverall, we were able to find 3 robust communities: **R and Classical ML, Python and Classical ML,** and **Python and Deep Learning**. These titles vividly express the specificity of PhD holders that fell in the respective category; the wordclouds below demonstrate skills that are most attributable to each group. \n","7c5974c4":"# <a>What are the Core and the Periphery Skills for Doctorates Overall and Across Regional Communities?<\/a>\n\nAt this point, let us dive deeper into the analysis of the skills network and look closer at its relational properties. You can check [this short illustrative story](http:\/\/matt.might.net\/articles\/phd-school-in-pictures\/) before proceed.\n\nThe connection in the skill-based web below demonstrates the average proportion of Kaggle survey participants, possessing the respective pair of the attached skills. Large nodes symbolize a high (above average) share of professionals with PhD attainments within a given skill. ","9fc51fb7":"From this moment forward, we approximated one's wage as a middle value of the respective wage interval and also removed students from the sample. It looks like wages of PhD graduates outweigh those of non-PhD guys. But hold on! Let us drill further.","f767a0a9":"The plots, as well as the numbers, inform us that PhD guys in Western countries prefer to concentrate on the core expertise. In contrast, AI professionals in Eastern and Developing regions are more periphery-oriented and, hence, selective in the scope of skills that they utilize. \n\nWhat does this tell us about? Perhaps, due to funding restrictions, PhD in Eastern and Developing countries tend to the less abounding but more advanced ML level with recent achievements. In contrast, wealthier Western nations can leave room for versatility. Again, this is in line with the **leapfrog effect**: a lack of (primarily) financial resources induces countries to follow the new standards more effectively but prohibiting from the less innovative practices.\n","0b13aa24":"The picture is stunningly surprising! Despite a popular globalized view on data science and AI as a field, the skill-based communities that are seen depict the existing cultural, economic, and geographical division: developing, western, and eastern countries. Interestingly, Japan and South Korea were categorized to eastern nations, albeit to a tangible extent resembling the USA in terms of IT advancement level. In turn, Turkey and Russia, although they were classified to the eastern alliance, are still close to the western cluster, which corresponds to the idea of geographical segregation in the area of AI. Mexico appeared to be beyond the erected categorization.\n\nThis piece of analysis tells us that cultural, economic, and geographical commonalities in their integrity determine the skill-based diversity in AI that exists in the world.\n\nConcerning the amount of PhD graduates, from the graph below, we can notice a severe disproportion favoring western nations.","e21a50ff":"# <a>General Socio-Demographic Portrait of a PhD Kaggler<\/a>\n\nTo give an overall understanding of who PhD holders, working in the field of data science and Al, are, we first start with their socio-demographic description.","40c4d4e0":"What can be noticed? If we account for the skill similarity, the three interesting observations are as follows:\n\n* Western countries: only low-experienced doctorates \u201cwin the race\u201d.\n* Eastern countries: low-experienced PhD specialists are evaluated lower in terms of money.\n* Developing countries: these are high-experienced PhD professionals whose remuneration substantially lags behind their non-academic counterparts.\n\nWhat does that mean? For Western countries, it means that PhD seems to work only as a **\u201csignal\u201d** paving the way for better-paid jobs at the beginning of one\u2019s career. As the level of experience rises, non-PhD people can catch up using achievements that are thanks to their experience. Doctoral degree in the East does not seem to work even as a signal. In Developing countries, the situation is alarming: PhD status can significantly downgrade your salary later on as you gain more experience in the area.\n","b5be0229":"# <a>How Does the Skill-Related Environment of Kaggle PhD Holders in Data Science Differ Between Nations?<\/a>\n\nFrom a micro-level perspective on Kaggle PhD guys, we proceed to a global view remaining within a network-oriented paradigm.\n\nThe links in the network below depict a measure that was obtained by averaging the skill similarity on a respondent level for each country (we selected only well-represented countries). The connection was constructed if the skill similarity between the two countries was above a mean value. Interested readers can check the code for more details. Further, a community detection procedure was realized.\n","c48b9d30":"# <a>References<\/a>\n1.\tCyranoski, D., Gilbert, N., Ledford, H., Nayar, A., & Yahia, M. (2011). Education: the PhD factory. Nature news, 472(7343), 276-279.\n2.\tGaeta, G. L. (2015). Was it worth it? An empirical analysis of over-education among PhD recipients in Italy. International Journal of Social Economics, 42(3), 222-238.\n3.\tLeimeister, J. M., Becker, J., Heinzl, A., Winter, R., & Gefen, D. (2019). Doing a Doctorate in BISE in Germany, Austria and Switzerland? A Debate on the Why, What and How. Business & Information Systems Engineering, 61(6), 759-766.\n4.\tWikipedia, https:\/\/en.wikipedia.org\/wiki\/Leapfrogging\n5.\tGiatsidis, C., Malliaros, F. D., Tziortziotis, N., Dhanjal, C., Kiagias, E., Thilikos, D. M., & Vazirgiannis, M. (2016). A k-core decomposition framework for graph clustering.\n","fe2aa119":"# <a>Does Gender Discrimination Also Apply to Women with a PhD Degree?<\/a>\n\nWe are all aware of the fact that women are discriminated against in the labor market, and occupations in the field of AI are not an exception. How does this situation look like amongst PhD holders?\n\nWe did the same computational trick for gender as for PhD vs. non-PhD kagglers in the previous section: we calculated a wage difference (absolute and normed by a mean salary in the region) for men and women with similar skillsets by country communities and only for PhD holders. The results are depicted by the graphs below.\n","6c816c74":"People with a doctoral degree are mostly older than 30. As for the data science experience, Kagglers with PhD on average have worked for 3-10 years.\n \nSalaries of doctorates vary substantially, nevertheless are quite high in general. The observed variation might be caused by differences in average wage levels across nations, but this issue will be further discussed more thoroughly.","156f535c":"Now it begs the question: how do the individual- and global-level communities correspond to each other? The following heatmap is the answer.","e2055af5":"# <a>Deep Dive into Science: Exploring PhD Community with Network Analysis<\/a>\n*This notebook was prepared by Ekaterina Melianova and Artem Volgin*","e28d43ca":"Given this context, several critical research questions come to the fore. \n* *What are the skillset types that describe a PhD person?*\n* *Are there signs of a skillset erosion in the data science field among doctorates?*\n* *How does the skill-related environment of PhD holders in data science differ between nations?*\n* *What are the core and the periphery skills for doctorates overall and across regional communities?*\n* *Do people in the data science field earn more with a PhD status?* \n* *Does gender discrimination also apply to women with a PhD degree? *\n* *Finally, is a PhD degree really worth it in the data science area?*\n\nThe current project unfolds a coherent story that attempts to answer these questions using 2019 Kaggle ML & DS Survey data. Importantly, all the inferences that are stated in this notebook can describe only Kaggle users and should not be extrapolated to the broader population of data analysts.\n\nThe study leverages potent techniques of **Network Analysis** which has become exceptionally frequent in a growing body of multidisciplinary research.\n","87d270ee":"We then computed **\u201ccoreness\u201d** of each node \u2013 a parameter representing a skill\u2019s closure to the core of the network. To learn more about k-core decomposition, look here [5]. The more bluish colors are indicative of a pronounced \u201ccoreness,\u201d while the more reddish ones point on the network\u2019s periphery. The picture enables to uncover an attractive finding: popular DL techniques and the respective software libraries *(Convolutional Neural Networks, Bayesian Approaches, Recurrent Neural Network, TensorFlow, Keras, etc.)* are widespread among the core PhD skills, whereas the periphery PhD skills seem to be rather specific, more academy-oriented, and in some sense constitute a more advanced DL expertise *(e.g., MATLAB, C++, Generative Adversarial Networks, Evolutionary Approaches, Generative Networks, Transformer Networks, etc.)*. This information, in a concise manner, also appears in the following wordclouds.","5dbaee87":"# <a>Conclusions<\/a>\n\nIn a nutshell, our mini-study attempted to explore an array of questions associated with PhD kagglers. We were striving to conduct a holistic analytical work with attractive methodological solutions that would deepen our knowledge about socially important issues related to our group of interest. Overall, the critical findings that we found are as follows.\n\n1. There are 3 consistent skillset types that characterize data analysts with a doctoral degree: **R and Classical ML, Python and Classical ML,** and **Python and Deep Learning**. PhD guys that belong to Python and Classical ML category are vulnerable to a **skillset erosion**, meaning that the competencies they have are less delineated and unique compared to the ones possessed by doctorates from other clusters. Likewise, PhD students and low-experienced doctorates displayed more blurred boundaries in their skillsets.\n \n2. Cultural, economic, and geographical commonalities in their integrity determine the skill-based diversity in AI that exists in the world. Ph.D. holders are disproportionally concentrated in the West compared to other regions. Python and Deep Learning community is attributable to a greater extent to Eastern countries, which can be explained by the **leapfrog effect**, or the tendency to adopt the best practices due to the power of disrupting innovations.\n\n3. Western nations embrace the core PhD skills, i.e., diverse ML techniques, while Eastern and Developing nations are more periphery-oriented in terms of skills, i.e., embrace less abounding but more advanced ML techniques.\n\n4. In the West, PhD status works as a **signal** helping low-experienced employees get a better-paid job, whereas, in other regions, it does not. Having a PhD level is redundant with regard to wages for middle- and higher-experienced workers. Besides, developing countries are in a dangerous position: PhD for a top data science experience may even deteriorate one's skills value and lead to lower earnings.\n\n5. Doctoral women in Developing countries seem to be discriminated against the most. A sizable level of discrimination is also present in the West, while Eastern countries appeared to be more egalitarian regarding women's salaries in the labor market.\n\n\nWe hope that our story was enjoyable to a reader and helped unveil several curious insights about PhD kagglers and their skillsets. Furthermore, we sincerely hope to attract people\u2019s attention to the troubles that doctorates might go through. Notably, geographical and economic segregation in the data science skills is still strong: we need to dissolve those regional borders to make knowledge in data science unconditional to the national barriers. \n\nMoreover, no doubt, academic aspirations should be widely encouraged everywhere since favorable social payoffs from that are indisputable. However, a fly in the ointment is that these days, the answer to the question **\u201cIs PhD really worth it?\u201d** seems to be heavily susceptible to gender and regional peculiarities. Governments and policy leaders should put more effort into ensuring a sufficient level of equality and financial support to AI professionals who strive for PhD, especially to the discriminated groups. This is how the status of data science as **\u201cthe sexiest job of the 21st century\u201d** can be retained in the long run!","948c0d42":"# <a>Do People in the Data Science Field Earn More with a PhD Status?<\/a>\n\nOur story has reached a much-anticipated topic. Assume you have decided to pursue PhD, what remuneration should you expect? Is it really worth it?","bc420d6f":"A remarkable finding is that discrimination of females exists in Western and Developing countries, while in the East women do not seem to be discriminated: the respective wage difference is not statistically significant (straddle zero). In absolute numbers, Western nations might look like the most discriminated, but that is because, on average, people there are paid higher. Therefore, relative figures are more informative, and they suggest that the most pronounced underestimation of PhD women with regard to their earnings happens in the Developing World.","cc7ed99e":"One vivid feature here is that Deep Learning professionals with PhD are concentrated to a significantly greater extent in Eastern cluster, than in the rest two. This is largely unexpected given that expertise in deep learning algorithms seems to be associated with a decent PhD training, which, for example, is offered by the top US universities. Such an observation might be explained by the so-called **leapfrog effect**: less advanced in terms of educational quality regions may adopt and proliferate the best practices sooner than their more developed counterparts due to radical rather than incremental innovations [4].","3b11ee30":"# <a>What are the Skillset Types that Describe a PhD Kaggler? Specialization or Erosion of Boundaries?<\/a>\nThe traditional statistics rely on premises that observations in the data are independent. However, this is rarely the case in a real social world where people are dependent with regard to a variety of characteristics. Network Analysis is a field in statistics that intentionally erects and comprehensively models those connections. Friendship network in social media is one of the most widespread examples of how social dependencies can be represented. \n\nIn the current analysis, we take a step further and build a network of PhD holders based on the similarity of their **skillsets \u2013 binary variables, reflecting the possession of a particular skill or the presence of proficiency in software**. The following questions were used to compute the skillset similarity (skills that appeared less than 500 times in the sample were excluded from the analysis):\n\n* *Q16: Which of the following integrated development environments (IDE's) do you use on a regular basis?*\n* *Q17: Which of the following hosted notebook products do you use on a regular basis?*\n* *Q18: What programming languages do you use on a regular basis?*\n* *Q20: What data visualization libraries or tools do you use on a regular basis?*\n* *Q24: Which of the following ML algorithms do you use on a regular basis?*\n* *Q25: Which categories of ML tools do you use on a regular basis?*\n* *Q26: Which categories of computer vision methods do you use on a regular basis?*\n* *Q27: Which of the following natural language processing (NLP) methods do you use on a regular basis?*\n* *Q28: Which of the following machine learning frameworks do you use on a regular basis?*\n* *Q29: Which of the following cloud computing platforms do you use on a regular basis?*\n* *Q30: Which specific cloud computing products do you use on a regular basis?*\n* *Q31: Which specific big data \/ analytics products do you use on a regular basis?*\n* *Q32: Which of the following machine learning products do you use on a regular basis?*\n* *Q33: Which automated machine learning tools (or partial AutoML tools) do you use on a regular basis?*\n* *Q34: Which of the following relational database products do you use on a regular basis?*\n\nTo model network connections such metric as cosine similarity was leveraged: we formed a tie between a pair of nodes if the respective value of cosine similarity was above the 99th quantile of its distribution. To our best knowledge, this is the first attempt to approach the issue of relationship representation in such a manner.","03ec5bd0":"![](https:\/\/policyoptions.irpp.org\/wp-content\/uploads\/sites\/2\/2019\/08\/Twitter-End-the-PhD-bashing-to-end-the-PhD-problem.jpg)\nThe image was taken from [this article](https:\/\/policyoptions.irpp.org\/magazines\/august-2019\/end-the-phd-bashing-to-end-the-phd-problem\/) "}}