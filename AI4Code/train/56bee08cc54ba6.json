{"cell_type":{"cc20ed39":"code","a10fc050":"code","527a9587":"code","88c656b1":"code","c064010f":"code","6f0e309a":"code","a929bf8d":"code","94669f24":"code","74156460":"code","9c7ecfe8":"markdown","6e1628c9":"markdown","c5160541":"markdown","cf36bac1":"markdown","7c559b0f":"markdown","cae06d05":"markdown"},"source":{"cc20ed39":"import os, gc\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr as p\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nos.environ['TF_CPP_MIN_LOG_LEVEL']='3'\ntf.random.set_seed(2022)","a10fc050":"nsamples = 2500000\nnfeatures = 300\nnfolds = 5\nlr = 0.001\nepochs = 20\nbatch_size = 1024\n\nfeatures = [f'f_{i}' for i in range(nfeatures)]","527a9587":"train = pd.read_pickle('..\/input\/ump195gb\/train.pkl')[-nsamples:]\ntrain.head(3)","88c656b1":"max_tokens = len(train.investment_id.unique()) + 1\ninvestment_id_lookup_layer = layers.IntegerLookup(max_tokens=max_tokens)\ninvestment_id_lookup_layer.adapt(train.investment_id)","c064010f":"max_tokens2 = len(train.time_id.unique()) + 1\ntime_id_lookup_layer = layers.IntegerLookup(max_tokens=max_tokens2)\ntime_id_lookup_layer.adapt(train.time_id)","6f0e309a":"def get_model():\n    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n    time_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n    \n    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n    investment_id_x = layers.Embedding(max_tokens, 32, input_length=1)(investment_id_x)\n    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    \n    time_id_x = time_id_lookup_layer(time_id_inputs)\n    time_id_x = layers.Embedding(max_tokens2, 32, input_length=1)(time_id_x)\n    time_id_x = layers.Reshape((-1, ))(time_id_x)\n    time_id_x = layers.Dense(64, activation='swish')(time_id_x)\n    time_id_x = layers.Dense(64, activation='swish')(time_id_x)\n    time_id_x = layers.Dense(64, activation='swish')(time_id_x)\n    \n    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    \n    x = layers.Concatenate(axis=1)([investment_id_x, time_id_x, feature_x])\n    x = layers.Dense(512, activation='swish', kernel_regularizer='l2')(x)\n    x = layers.Dense(128, activation='swish', kernel_regularizer='l2')(x)\n    x = layers.Dense(32, activation='swish', kernel_regularizer='l2')(x)\n    output = layers.Dense(1)(x)\n    rmse = keras.metrics.RootMeanSquaredError(name='rmse')\n    model = tf.keras.Model(inputs=[investment_id_inputs, time_id_inputs, features_inputs], outputs=[output])\n    model.compile(optimizer=tf.optimizers.Adam(learning_rate=lr), loss='mse', metrics=[rmse])\n    \n    gc.collect()\n    return model\n\n#keras.utils.plot_model(get_model(), show_shapes=True)","a929bf8d":"def run(train):\n    kfold = StratifiedKFold(nfolds, shuffle=True, random_state=42)\n    for index, (train_indices, valid_indices) in enumerate(kfold.split(train, train.investment_id)):\n        print(f'Fold {index}')\n        print('_'*50)\n        X_train, X_val = train[features].iloc[train_indices].astype('float16'), train[features].iloc[valid_indices].astype('float16')\n        y_train, y_val = train.target.iloc[train_indices], train.target.iloc[valid_indices]\n        investment_id_train, investment_id_val = train.investment_id.iloc[train_indices], train.investment_id.iloc[valid_indices]\n        time_id_train, time_id_val = train.time_id.iloc[train_indices], train.time_id.iloc[valid_indices]\n\n        model = get_model()\n        checkpoint = keras.callbacks.ModelCheckpoint(f\"model_{index}.tf\", save_best_only=True, save_weights_only=True)\n        early_stop = keras.callbacks.EarlyStopping(patience=5)\n        history = model.fit([investment_id_train, time_id_train, X_train], y_train, \n                            epochs=epochs,\n                            batch_size=batch_size,\n                            validation_data=([investment_id_val, time_id_val, X_val], y_val), \n                            callbacks=[checkpoint, early_stop], verbose=1)\n        models.append(model)\n        \n        # Evaluation\n        y_pred = model.predict([investment_id_val, time_id_val, X_val])\n        print(f'Pearson correlation: {p(y_pred.reshape(-1), y_val)[0]}')\n        print(f'Root mean squared error: {np.sqrt(mean_squared_error(y_pred.reshape(-1), y_val))}')\n        \n        del investment_id_train, investment_id_val, X_train, X_val, y_train, y_val\n        gc.collect()","94669f24":"models = []\nrun(train)\n\ndel train\ngc.collect()","74156460":"import ubiquant\nenv = ubiquant.make_env()\niter_test = env.iter_test() \nfor (test_df, sample_prediction_df) in iter_test:\n    preds=[]\n    for model in models:\n        test_df['time_id'] = test_df['row_id'].apply(lambda x: int(x.split('_')[0]) )\n        preds.append(model.predict([test_df.investment_id, test_df.time_id, test_df[features]]))\n    \n    sample_prediction_df['target'] = np.mean(preds, axis=0)\n    env.predict(sample_prediction_df) \n    display(sample_prediction_df)","9c7ecfe8":"## Inference\/submission","6e1628c9":"Credit: this kernel provides some experiments starting from a great notebook https:\/\/www.kaggle.com\/lonnieqin\/ubiquant-market-prediction-with-dnn","c5160541":"## Model","cf36bac1":"## Data","7c559b0f":"## Parameters","cae06d05":"## Training"}}