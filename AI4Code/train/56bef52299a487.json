{"cell_type":{"3cd2c7e4":"code","64ca65d2":"code","0fadc556":"code","7fbcee7f":"code","3fce0efe":"code","eff7ee69":"code","4b81f0be":"code","81ef8783":"code","e18da4ce":"code","24509044":"code","0a21e5a4":"code","78f6ee83":"markdown","2bc31b9f":"markdown","9143b1d1":"markdown","884676a9":"markdown","772cad04":"markdown","726ab5d0":"markdown","89e9cec4":"markdown","5a363830":"markdown","23f9b56d":"markdown"},"source":{"3cd2c7e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","64ca65d2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout","0fadc556":"df = pd.read_csv('\/kaggle\/input\/google-stock-data\/GOOG.csv')\nplt.plot(df['Open'])\nplt.show()","7fbcee7f":"ds_open = df[['Open']]\ntrain = ds_open [ : 3500 ]\ntest = ds_open [ 3500 : ]\ntest = test.reset_index(drop=True)\nsteps = 50","3fce0efe":"scale = MinMaxScaler(feature_range = (0, 1))\ntrain_set = scale.fit_transform(train)\ntest_set = scale.fit_transform(test)","eff7ee69":"def prepDS(data, steps):\n    X = []\n    y = []\n    for i in range( len(data) - steps ):\n        X.append(data[ i : i+steps])\n        y.append(data[ i + steps, 0 ])\n    return np.array(X), np.array(y)","4b81f0be":"X_train, y_train = prepDS(train_set, steps)\nX_test, y_test = prepDS(test_set, steps)","81ef8783":"model = Sequential()\nmodel.add(LSTM(units = 50, return_sequences = True, input_shape = (steps,1)))\nmodel.add(Dropout(0.2)) \nmodel.add(LSTM(units = 50, return_sequences = True))\nmodel.add(Dropout(0.2)) \nmodel.add(LSTM(units = 50))\nmodel.add(Dropout(0.2)) \nmodel.add(Dense(units = 1, activation = 'linear'))\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\nmodel.fit(X_train, y_train, epochs = 200, batch_size=80, validation_data=(X_test,y_test))","e18da4ce":"inputs = ds_open[len(ds_open)-len(test_set)-steps:].values\ninputs = inputs.reshape(-1,1)\ninputs = scale.transform(inputs)","24509044":"x_test = []\nfor x in range(steps,len(inputs)):\n    x_test.append(inputs[x-steps:x,0])\n\nx_test = np.array(x_test)\nx_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))\n\npred = model.predict(x_test)\npred = scale.inverse_transform(pred)","0a21e5a4":"plt.plot(test, color='red', label=f\"Actual\")\nplt.plot(pred, color= 'blue', label=f\"Predicted\")\n\nplt.xlabel(\"Days\")\nplt.ylabel(\"Price\")\nplt.legend()\nplt.show()","78f6ee83":"**Import necessary libraries**","2bc31b9f":"**Plotting Actual Price against Predicted Price**","9143b1d1":"**Reorganizing into appropriate inputs and outputs for test**","884676a9":"**Build the LSTM model**","772cad04":"**Split dataset into train-test; also set strides**","726ab5d0":"**Load CSV and plot it out**","89e9cec4":"**Preprocessing function to transform test and train splits into LSTM-appropriate inputs and outputs**","5a363830":"**Scale the prices down (0,1)**","23f9b56d":"**Reshape, transform test dataset for prediction**"}}