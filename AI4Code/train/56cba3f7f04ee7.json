{"cell_type":{"32e102fc":"code","7bbdf1d2":"code","44af184a":"code","a39d073b":"code","64e01968":"code","0209ba25":"code","9256127b":"code","5bf71d5e":"code","32fb8116":"code","fdc1d6cf":"code","2ed791de":"code","f0ca7c8e":"code","500c5dc0":"code","52f1cb17":"code","bc387449":"code","38da621c":"code","8befab3d":"code","f1ccaa7f":"code","80b31eee":"code","1642bf18":"code","2c42fce0":"code","15b4bf35":"code","8307a8e1":"code","2df4a106":"code","f68c013b":"code","a77aa1c0":"code","b1397bb2":"code","b20fcf0d":"code","4fe9f2b1":"code","5fd0f360":"code","04b9d0e9":"code","ed04def7":"code","a43d4ca8":"code","6daf283e":"code","256e1964":"code","884cc8f8":"code","454dd8c9":"code","6387127b":"code","43895f29":"code","cb3659b2":"code","31d4ae0e":"code","9600bf30":"code","b9bb3f2f":"code","41e20901":"code","6d2135b5":"code","f32d8065":"code","29bcbc5a":"code","48fb5743":"code","d1895d2a":"markdown","60804f15":"markdown","a14bd27d":"markdown","964908fb":"markdown","93d23be4":"markdown","92814289":"markdown","e97cd1ad":"markdown","ead17989":"markdown","44ad7ae7":"markdown","f9505abd":"markdown","d6a3dc65":"markdown","92a3f333":"markdown","3f1a1ce8":"markdown","4830a10d":"markdown","aadf7ccd":"markdown","eea9c930":"markdown","6c82bcd2":"markdown","e70d85bc":"markdown","440fde5f":"markdown"},"source":{"32e102fc":"# Import required Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\n","7bbdf1d2":"LE = LabelEncoder()\nOE= OneHotEncoder()\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nsns.set_theme(style=\"whitegrid\")\n\ndata_train=pd.read_csv('..\/input\/titanic\/train.csv')\ndata_test=pd.read_csv('..\/input\/titanic\/test.csv')\ndata = pd.concat([data_train, data_test], axis=0)","44af184a":"data.dtypes","a39d073b":"data.shape","64e01968":"data.info()","0209ba25":"data.describe()","9256127b":"data.isnull().sum()","5bf71d5e":"sns.heatmap(data.isnull(), yticklabels=False,\\\n            cbar=False,cmap='viridis')\nplt.show()","32fb8116":"pd.crosstab(data.Pclass,data.Survived,margins=True)","fdc1d6cf":"pd.crosstab([data.Sex,data.Survived],data.Pclass,margins=True)","2ed791de":"\nfig,ax=plt.subplots(1,3,figsize=(20,10))\nsns.countplot('Survived',data=data,ax=ax[0])\nax[0].set_title('Survival Count')\nsns.countplot(x='Sex',hue='Survived',data=data,ax=ax[1])\nax[1].set_title('Survival Count by Sex')\nsns.countplot(x='Pclass',hue='Survived',data=data,ax=ax[2])\nax[2].set_title('Survival Count by Passenger Class')\nax[0].set_yticks(range(0,600,50))\nax[1].set_yticks(range(0,600,50))\nax[2].set_yticks(range(0,600,50))\nplt.show()","f0ca7c8e":"fig,ax=plt.subplots(1,2,figsize=(20,10))\nsns.violinplot('Pclass','Age',hue='Survived',data=data,split=True,ax=ax[0])\nax[0].set_title('PClass + Age vs Survived')\nsns.violinplot(\"Sex\",\"Age\", hue=\"Survived\", data=data,split=True,ax=ax[1])\nax[1].set_title('Sex + Age vs Survived')\nax[0].set_yticks(range(0,110,10))\nax[1].set_yticks(range(0,110,10))\nplt.show()","500c5dc0":"data['Salut']=0\nfor i in data:\n    data['Salut']=data.Name.str.extract('([A-Za-z]+)\\.')","52f1cb17":"pd.crosstab(data.Salut,data.Sex).T","bc387449":"# find the mean age for each Saultation\nage_mean=data.groupby('Salut')['Age'].mean()\nage_mean","38da621c":"def impute_age(rec):\n    for index, age in zip(age_mean.index, age_mean.values):\n        if rec['Salut'] == index:\n            return age","8befab3d":"data['Age'] = data.apply(lambda x: impute_age(x) if np.isnan(x['Age']) else x['Age'], axis=1)","f1ccaa7f":"pd.crosstab([data.SibSp],data.Survived)","80b31eee":"pd.crosstab([data.SibSp,data.Pclass],data.Survived)","1642bf18":"pd.crosstab([data.Parch],data.Survived)","2c42fce0":"pd.crosstab([data.Parch,data.Pclass],data.Survived)","15b4bf35":"data['Family']=data['SibSp']+data['Parch']+1\nfamily_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\ndata['Family'] = data['Family'].map(family_map)\n\ndata.head()","8307a8e1":"sns.barplot(x=data['Family'].value_counts().index,y=data['Family'].value_counts().values)","2df4a106":"sns.countplot(x='Family',hue='Survived',data=data)","f68c013b":"c1=['S','C','Q']\ndata[~data.Embarked.isin(['S','C','Q'])]","a77aa1c0":"data['Embarked'].value_counts()","b1397bb2":"pd.crosstab([data.Sex,data.Embarked],data.Pclass,margins=True)","b20fcf0d":"data['Embarked'].fillna('S',inplace=True)","4fe9f2b1":"data['Cabin'] = data['Cabin'].fillna('U')","5fd0f360":"data['Cabin'] = data['Cabin'].apply(lambda x: x[0])","04b9d0e9":"data.head()","ed04def7":"data.isnull().sum()","a43d4ca8":"sns.heatmap(data.isnull(), yticklabels=False,\\\n            cbar=False,cmap='viridis')","6daf283e":"data.dtypes","256e1964":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndata['Sex'] = le.fit_transform(data['Sex'])","884cc8f8":"data_Embarked = pd.get_dummies(data.Embarked, drop_first=True,prefix='Embarked')\ndata_Pclass = pd.get_dummies(data.Pclass, drop_first=True,prefix='Pclass')\ndata_Cabin = pd.get_dummies(data.Cabin, drop_first=True,prefix='Cabin')\ndata_Family = pd.get_dummies(data.Family, drop_first=True,prefix='Family')\ndata = pd.concat([data, data_Embarked,data_Pclass,data_Cabin,data_Family], axis=1)","454dd8c9":"data.head()","6387127b":"df=data.drop(['PassengerId','Name','SibSp','Parch','Ticket','Fare',\\\n              'Cabin','Embarked','Salut','Pclass','Family'],axis='columns')","43895f29":"df.head()","cb3659b2":"df_train = df.iloc[:891,:]\ndf_test = df.iloc[891:,:]","31d4ae0e":"X = df_train.drop(columns='Survived')\ny = df_train['Survived']","9600bf30":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state =42)","b9bb3f2f":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\n\ngnb.fit(X_train, y_train)\n\ny_pred = gnb.predict(X_test)\n","41e20901":"from sklearn import metrics\nfrom sklearn.metrics import  confusion_matrix\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\ncm=np.array(confusion_matrix(y_test,y_pred))\n\ncm","6d2135b5":"df_test.drop(columns='Survived',inplace=True)","f32d8065":"data_test.head()","29bcbc5a":"df_pred = gnb.predict(df_test)\ndf_pred","48fb5743":"df_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\ndf_submission[\"Survived\"] = df_pred\ndf_submission.to_csv(\"submission.csv\", index=False)","d1895d2a":"Feature: SibSp and Parch","60804f15":"Lets take a look at the data","a14bd27d":"From the info we come to know that the Age column has some null values, Embarked has a couple of null values and Cabin has a lot of null values. this can also be visualized.","964908fb":"##Cabin","93d23be4":"Lets fill up the values in Cabin with U for Unknown and we can extract and keep only the first letter for the rest","92814289":"Now lets visualize this data","e97cd1ad":"##Feature: Age","ead17989":"This is showing us that the chances of survival for a single person is less. Also we see here that the larger families with 5-8 people have died. This is the case specifically since they were from Class 3!!. So, the larger families (SibSp>3) in Class 3 had almost no chance of survival. What about Parch??","44ad7ae7":"Sib Sp tells us whether Siblings or Spouse are present and Parch tells us if parents and children are present","f9505abd":"Here again we see that the Class 3 survival rate is low for families. So we can group the Family size in ['Alone','Small','Medium','Large']","d6a3dc65":"EDA: lets use a heatmap to visualize the missing values","92a3f333":"We need to deal with the null values in the age colun but we cannot fill up all the missing values by a mean. we could engineer a feature based on the name. names have salutations and we can classify them ","3f1a1ce8":"Here we see that very few people have survived, and that women were the ones who were given preference while evacuation. We also see that as per the class the people from class one had a higher rate of survival as compared to the people in class 3. We could make these inferences based on the graphical representation of data or graphical analysis.","4830a10d":"here we see maximum females travelling to S have survived! so we can fill the above missing Embarked values with 'S'","aadf7ccd":"Now lets do some analysis of the columns with respect to the variables we have. lets see the survival count, count based on sex and count based on passenger class","eea9c930":"Lets find the missing values of Embarked column","6c82bcd2":"From these violin plots we can see that the children also had a higher rate of survival. and that too irrespective of the class. Survival of women in 20-30 years range is also better","e70d85bc":"create a function impute_age(). This rec parameter basically just represents every row (record) in our data frame.","440fde5f":"Now we need to replace the mising age values with the mean of salutations. So, we use lambda function to apply "}}