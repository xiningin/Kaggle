{"cell_type":{"22d4d151":"code","49496d31":"code","95d0abc1":"code","0c97170d":"code","e9ca5b9e":"code","01c41f9c":"code","b47d4c6a":"code","6b764096":"code","8140dd5c":"code","ede3bebf":"code","9186a954":"code","e80db823":"code","61487add":"code","ae938050":"code","035d193b":"code","196a6542":"code","6a007d24":"code","50a497e1":"code","e5cac77d":"code","b5731f25":"code","939eb7ba":"code","69aaa1d9":"code","785a9bc5":"code","ce54159b":"code","f600c294":"code","1ac28b6c":"code","90a6a325":"code","375d8ae5":"code","af122f44":"code","1763790c":"code","4cee87c1":"markdown","e0a1099b":"markdown","e32e2314":"markdown","efed09c5":"markdown","51dcc302":"markdown","9144c7a7":"markdown"},"source":{"22d4d151":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport os\nimport plotly.express as px\nfrom sklearn.metrics import classification_report,accuracy_score,average_precision_score,balanced_accuracy_score,precision_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n%matplotlib inline","49496d31":"df = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","95d0abc1":"px.histogram(df, \"age\", nbins=25, title='Patients age')","0c97170d":"df_anaemia = df['anaemia'].value_counts().reset_index()\ndf_anaemia.columns = ['anaemia', 'count']\npx.bar(df_anaemia, x='anaemia', y=\"count\", title='Anaemia bar chart')","e9ca5b9e":"df_diabetes = df['diabetes'].value_counts().reset_index()\ndf_diabetes.columns = ['diabetes', 'count']\npx.bar(df_diabetes, x='diabetes', y=\"count\", title='Diabetes bar chart')","01c41f9c":"df_smoking = df['smoking'].value_counts().reset_index()\ndf_smoking.columns = ['smoking', 'count']\npx.bar(df_smoking, x='smoking', y=\"count\", title='Smoking bar chart')","b47d4c6a":"px.histogram(df, \"ejection_fraction\", nbins=15, title='Ejection_fraction distribution')","6b764096":"for col in df.columns:\n    if abs(df[col].corr(df.DEATH_EVENT)) < 0.05:\n        df = df.drop([col], axis=1)\n        ","8140dd5c":"sns.heatmap(df.corr(),cmap='viridis')","ede3bebf":"Score=[]\nforest = RandomForestClassifier(random_state=0)\nfor a in range(1000):\n    X_train,X_test,y_train,y_test = train_test_split(df.drop(['DEATH_EVENT'],axis=1),df['DEATH_EVENT'],test_size=0.25,random_state=a)\n    forest.fit(X_train,y_train)\n    pred = forest.predict(X_test)\n    b = accuracy_score(y_test,pred)\n    Score.append(b) ","9186a954":"X_train,X_test,y_train,y_test = train_test_split(df.drop(['DEATH_EVENT'],axis=1),df['DEATH_EVENT'],test_size=0.25,random_state=Score.index(np.array(Score).max()))","e80db823":"\nScore1=[]\nX_train,X_test,y_train,y_test = train_test_split(df.drop(['DEATH_EVENT'],axis=1),df['DEATH_EVENT'],test_size=0.25,random_state=476)\nfor a in range(1000):\n    forest = RandomForestClassifier(random_state=a)\n    forest.fit(X_train,y_train)\n    pred = forest.predict(X_test)\n    b = accuracy_score(y_test,pred)\n    Score1.append(b) ","61487add":"np.array(Score).max()","ae938050":"plt.plot(range(500),Score1[500:])","035d193b":"plt.plot(range(500),Score[500:])","196a6542":"np.array(Score1).max()","6a007d24":"np.array(Score).max()","50a497e1":"Score1.index(np.array(Score1).max())","e5cac77d":"nn = MLPClassifier(random_state=Score1.index(np.array(Score1).max()))\ndtree = DecisionTreeClassifier(random_state=Score1.index(np.array(Score1).max()))\nlog = LogisticRegression(random_state=Score1.index(np.array(Score1).max()))\nknn = KNeighborsClassifier()\nforest = RandomForestClassifier(random_state=Score1.index(np.array(Score1).max()))","b5731f25":"log.fit(X_train,y_train)\nknn.fit(X_train,y_train)\ndtree.fit(X_train,y_train)\nforest.fit(X_train,y_train)\nnn.fit(X_train,y_train)","939eb7ba":"prediction = log.predict(X_test)\nprint('                    Logistic Regression')\nprint(classification_report(y_test,prediction))","69aaa1d9":"prediction1 = forest.predict(X_test)\nprint('                    Random Forest Classifier')\nprint(classification_report(y_test,prediction1))","785a9bc5":"prediction2 = knn.predict(X_test)\nprint('                    K Nearest Neighbor Classifier')\nprint(classification_report(y_test,prediction2))","ce54159b":"prediction3 = dtree.predict(X_test)\nprint('                    Decision Tree Classifier')\nprint(classification_report(y_test,prediction3))","f600c294":"prediction4 = nn.predict(X_test)\nprint('                    Neural Network')\nprint(classification_report(y_test,prediction4))","1ac28b6c":"models = pd.Series(['Random Forest Classifier','Logistic Regression','Neural Network','Decision Tree Classifier','K Nearest Neighbor'])","90a6a325":"Accuracy = pd.Series([accuracy_score(y_test,prediction1),accuracy_score(y_test,prediction),accuracy_score(y_test,prediction4),accuracy_score(y_test,prediction3),accuracy_score(y_test,prediction2)])","375d8ae5":"Leaderboard = pd.DataFrame({'Models':models,'Accuracy':Accuracy})","af122f44":"Leaderboard.index=['Gold','Silver','Bronze','Bronze','Consolation Prize']","1763790c":"Leaderboard","4cee87c1":"Finding best possible Random State for train test split based on Accuracy\nScore","e0a1099b":"<html>\n    <h1><i><font face='Courier' size = 10>Prediction<\/font><\/i><\/h1>","e32e2314":"<html>\n    <h1><i><font face='Courier' size = 10>Model<\/font><\/i><\/h1>","efed09c5":"Finding best possible Random State for Our models based on their Accuracy Score","51dcc302":"\n<font face='Courier' size = 5>Best Model for Heart failure Prediction is Random Forest Classifier, but the random state optimizaton was done on Random Forest Classifier so it had to Win, try forking the notebook and doing the optimization for any other model<\/font>","9144c7a7":"<html>\n    <h1><i><font face='Courier' size = 10>Basic Visualisations and Exploratory Data Analysis<\/font><\/i><\/h1>"}}