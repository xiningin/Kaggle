{"cell_type":{"9460c5d7":"code","10c7cf60":"code","6a938a53":"code","4ca05a85":"code","11b9e45b":"code","510f8b87":"code","6fdacdda":"code","a13ef52c":"code","4a61105a":"code","97887e6b":"code","b6fd0c13":"code","5c2f578f":"code","172bc9bf":"code","02464c29":"code","fc0e9204":"code","9992e50e":"code","8004ef8a":"code","553384e6":"code","115fe79b":"code","fa2a6d6b":"code","0c8033eb":"code","d4e72a05":"code","2bd65e3f":"code","e8a4479d":"code","230d8c92":"code","6374e99b":"code","66f8c07b":"code","f0b31d4a":"code","988beb8c":"code","219b54d1":"code","81bd5759":"code","e48cbc54":"code","c9d5d6ec":"code","b73d3fb1":"code","fc75ecde":"code","32106aee":"code","b6459206":"code","a0b5841e":"code","e695de85":"code","0734d67f":"code","94201179":"code","74a2a6a6":"code","d8320edc":"code","e41f7615":"code","2d3a4760":"code","d2cae921":"code","cf4774bf":"code","8cd05e60":"code","c64270de":"code","95231bd8":"code","4fe4b591":"code","8b600f50":"code","044384d1":"code","44db89aa":"code","7511afa3":"code","72230fe1":"code","d2515142":"code","caec3be0":"code","33456c80":"code","7eb62a11":"code","c3c23037":"code","84298b5a":"code","a133194a":"code","132f01c4":"code","18d7ce24":"code","40288b10":"code","27143cae":"code","b55d80e0":"code","bc46cad4":"code","180084a7":"code","37f47101":"code","3d3bb108":"code","a5391c15":"code","434fffa9":"code","fb437f32":"code","fb3c77aa":"code","3f209ba6":"code","526a4cff":"code","dfa516ad":"code","290fd67e":"code","710d2358":"code","c959047f":"code","44d94c12":"markdown","c14360b9":"markdown","a73f714e":"markdown","51037ac4":"markdown"},"source":{"9460c5d7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","10c7cf60":"import seaborn as sns\nimport matplotlib.pyplot as plt","6a938a53":"raw_train=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')","4ca05a85":"raw_test=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","11b9e45b":"raw_train.shape","510f8b87":"raw_train.dtypes","6fdacdda":"raw_train.isnull().sum()\n","a13ef52c":"# to allow output cell to display all columns and rows\npd.set_option('max_columns',None)\npd.set_option('max_rows',None)","4a61105a":"raw_train.head()\n","97887e6b":"#outlier\nvar = 'GrLivArea'\ndata = pd.concat([raw_train['SalePrice'], raw_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,1000000));","b6fd0c13":"#box plot overallqual\/saleprice\nvar = 'OverallQual'\ndata = pd.concat([raw_train['SalePrice'], raw_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);","5c2f578f":"# Remove outliers\nraw_train.drop(raw_train[(raw_train['OverallQual']<5) & (raw_train['SalePrice']>200000)].index, inplace=True)\nraw_train.drop(raw_train[(raw_train['GrLivArea']>4500) & (raw_train['SalePrice']<300000)].index, inplace=True)\nraw_train.reset_index(drop=True, inplace=True)","172bc9bf":"raw_train.shape","02464c29":"raw_test.shape","fc0e9204":"raw_train['Condition2'].value_counts() # majority same value, can be considered to be taken off","9992e50e":"corrmat=raw_train.corr()\ntopknot = corrmat[corrmat>=.8]\nplt.figure(figsize=(12,8))\nsns.heatmap(topknot, cmap=\"Greens\")\nplt.show()","8004ef8a":"#dropping redundant\/highly corelated features\nraw_train.drop(['MiscFeature','Fence','PoolQC','FireplaceQu','Alley','MSSubClass','Id','GarageYrBlt','Condition2','GarageArea'],axis=1,inplace=True)","553384e6":"raw_test.drop(['MiscFeature','Fence','PoolQC','FireplaceQu','Alley','MSSubClass','Id','GarageYrBlt','Condition2','GarageArea'],axis=1,inplace=True)","115fe79b":"raw_train['SalePrice'].hist()","fa2a6d6b":"# Handling null values, \nnullvalues={'GarageType':'NA','GarageFinish':'NA','GarageQual':'NA','GarageCond':'NA','BsmtQual':'NA','BsmtCond':'NA','BsmtExposure':'NA','BsmtFinType1':'NA','BsmtFinType2':'NA','MasVnrType':'None','MasVnrArea':0,'BsmtFinSF2':0,'BsmtFinSF1':0,'BsmtUnfSF':0,'TotalBsmtSF':0,'BsmtFullBath':0,'BsmtHalfBath':0,'Functional':raw_train['Functional'].mode()[0],'KitchenQual':raw_train['KitchenQual'].mode()[0],'Utilities':raw_train['Utilities'].mode()[0],'MSZoning':raw_train['MSZoning'].mode()[0],'SaleType':raw_train['SaleType'].mode()[0],'LotFrontage':raw_train['LotFrontage'].mean()}\nraw_train=raw_train.fillna(value=nullvalues)","0c8033eb":"raw_train ['Electrical']=raw_train['Electrical'].fillna(raw_train['Electrical'].mode()[0])","d4e72a05":"nullvalues={'GarageType':'NA','GarageFinish':'NA','GarageQual':'NA','GarageCond':'NA','BsmtQual':'NA','BsmtCond':'NA','BsmtExposure':'NA','BsmtFinType1':'NA','BsmtFinType2':'NA','MasVnrType':'None','MasVnrArea':0,'BsmtFinSF2':0,'BsmtFinSF1':0,'BsmtUnfSF':0,'TotalBsmtSF':0,'BsmtFullBath':0,'BsmtHalfBath':0,'Functional':raw_test['Functional'].mode()[0],'KitchenQual':raw_test['KitchenQual'].mode()[0],'Utilities':raw_test['Utilities'].mode()[0],'MSZoning':raw_test['MSZoning'].mode()[0],'SaleType':raw_test['SaleType'].mode()[0],'LotFrontage':raw_test['LotFrontage'].mean()}\nraw_test=raw_test.fillna(value=nullvalues)","2bd65e3f":"nullvalues={'GarageCars':raw_test['GarageCars'].mean(),'Exterior1st':raw_test['Exterior1st'].mode()[0],'Exterior2nd':raw_test['Exterior2nd'].mode()[0]}\nraw_test=raw_test.fillna(value=nullvalues)","e8a4479d":"raw_train.isnull().sum()","230d8c92":"raw_test.isnull().sum()","6374e99b":"train=raw_train.drop(['SalePrice'],axis=1)","66f8c07b":"train.shape","f0b31d4a":"from scipy.stats import skew, norm\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nskew_features = train.select_dtypes(exclude='object').apply(lambda x: skew(x)).sort_values(ascending=False)\n\n\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nprint(\"There are {} numerical features with Skew > 0.5 :\".format(high_skew.shape[0]))\nskewness = pd.DataFrame({'Skew' :high_skew})\nskew_features.head(10)","988beb8c":"for i in skew_index:\n    train[i] = boxcox1p(train[i], boxcox_normmax(train[i] + 1))","219b54d1":"skew_features = raw_test.select_dtypes(exclude='object').apply(lambda x: skew(x)).sort_values(ascending=False)\n\n\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nprint(\"There are {} numerical features with Skew > 0.5 :\".format(high_skew.shape[0]))\nskewness = pd.DataFrame({'Skew' :high_skew})\nskew_features.head(10)","81bd5759":"for i in skew_index:\n    raw_test[i] = boxcox1p(raw_test[i], boxcox_normmax(raw_test[i] + 1))","e48cbc54":"minustarget=pd.concat([train, raw_test]).reset_index(drop=True)\nminustarget.shape","c9d5d6ec":"# handling categorical entries\nminustarget = pd.get_dummies(minustarget).reset_index(drop=True)","b73d3fb1":"minustarget.shape","fc75ecde":"minustarget = minustarget.loc[:,~minustarget.columns.duplicated()]","32106aee":"# log(1+x) transform\nimport numpy as np\nraw_train['SalePrice'] = np.log1p(raw_train['SalePrice'])","b6459206":"train_label=raw_train['SalePrice']","a0b5841e":"X = minustarget.iloc[:len(train_label), :]\nfinal_test = minustarget.iloc[len(train_label):, :]\nX.shape, train_label.shape, final_test.shape","e695de85":"final_test.isnull().sum()","0734d67f":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,train_label,test_size=0.2,random_state=0)","94201179":"X_test.head()","74a2a6a6":"y_test.head()","d8320edc":"from sklearn.linear_model import LinearRegression\nregressor=LinearRegression()\n","e41f7615":"regressor.fit(X_train,y_train)","2d3a4760":"y_pred=regressor.predict(X_test)","d2cae921":"from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n# The coefficients\n#print('Coefficients: \\n',regressor.coef_)\n# The mean squared error\nprint('Root Mean squared error: %.2f'\n      % np.sqrt(mean_squared_error(y_test, y_pred)))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_test, y_pred))","cf4774bf":"#yt_pred=np.floor(np.expm1(regressor.predict(final_test)))","8cd05e60":"from sklearn.linear_model import Ridge\nridgeReg = Ridge(alpha=0.05, normalize=True)\n","c64270de":"ridgeReg.fit(X_train,y_train)","95231bd8":" \npred = ridgeReg.predict(X_test)                                                                                                              ","4fe4b591":"from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n# The coefficients\n#print('Coefficients: \\n',regressor.coef_)\n# The mean squared error\nprint('Root Mean squared error: %.2f'\n      % np.sqrt(mean_squared_error(y_test, pred)))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_test, pred))","8b600f50":"from sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n\n\nalphas = np.logspace(-4, -0.5, 30)\n\ntuned_parameters = [{'alpha': alphas}]\nn_folds = 5\n\n\nlasso_cv = LassoCV(alphas=alphas, random_state=0, max_iter=10000)\nk_fold = KFold(3)\n\n\n","044384d1":"lasso_cv.fit(X_train,y_train)","44db89aa":"lpred = lasso_cv.predict(X_test) ","7511afa3":"from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n# The coefficients\n#print('Coefficients: \\n',regressor.coef_)\n# The mean squared error\nprint('Root Mean squared error: %.2f'\n      % np.sqrt(mean_squared_error(y_test, lpred)))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_test, lpred))","72230fe1":"from sklearn.linear_model import ElasticNetCV\nregr = ElasticNetCV(cv=5, random_state=0)\n\n","d2515142":"regr.fit(X_train, y_train)","caec3be0":"print(regr.alpha_)","33456c80":"pred_enet = regr.predict(X_test)","7eb62a11":"from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n# The coefficients\n#print('Coefficients: \\n',regressor.coef_)\n# The mean squared error\nprint('Root Mean squared error: %.2f'\n      % np.sqrt(mean_squared_error(y_test, pred_enet)))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_test, pred_enet))","c3c23037":"from sklearn.ensemble import RandomForestRegressor","84298b5a":"rfmodel=RandomForestRegressor()","a133194a":"rfmodel.fit(X_train,y_train)","132f01c4":"rfmodel.predict(X_test)","18d7ce24":"rfmodel.score(X_test,y_test)","40288b10":"rfmodel.get_params()","27143cae":"feat_importances = pd.Series(rfmodel.feature_importances_, index=X_test.columns)\nfeat_importances.nlargest(25).plot(kind='barh')","b55d80e0":"\n#using hyperparameter tuning\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint as sp_randint","bc46cad4":"param_dist = {\"max_depth\": [3, None],\"max_features\": sp_randint(1, X_train.shape[1]),\"min_samples_split\": sp_randint(2, 11),\"bootstrap\": [True, False],\"n_estimators\": sp_randint(100, 500)}","180084a7":"\nrandom_search = RandomizedSearchCV(rfmodel, param_distributions=param_dist,\n                                   n_iter=10, cv=5, iid=False, random_state=42)\nrandom_search.fit(X_train, y_train)","37f47101":"random_search.best_params_","3d3bb108":"y_preds = random_search.predict(X_test)","a5391c15":"random_search.score(X_test,y_test)","434fffa9":"from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n# The coefficients\n#print('Coefficients: \\n',regressor.coef_)\n# The mean squared error\nprint('Root Mean squared error: %.2f'\n      % np.sqrt(mean_squared_error(y_test, y_preds)))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_test, y_preds))","fb437f32":"from sklearn import svm\n#Create a svm Classifier\nclf = svm.SVR(kernel='poly') \n#Train the model using the training sets\nclf.fit(X_train, y_train)\n\n","fb3c77aa":"y_pred = clf.predict(X_test)","3f209ba6":"from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n# The coefficients\n#print('Coefficients: \\n',regressor.coef_)\n# The mean squared error\nprint('Root Mean squared error: %.2f'\n      % np.sqrt(mean_squared_error(y_test, y_pred)))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_test, y_pred))","526a4cff":"#using a voting regressor\nfrom sklearn.ensemble import VotingRegressor\nereg = VotingRegressor([('lr', regressor), ('ridge', ridgeReg), ('lasso', lasso_cv),('elasticnet', regr),('rf', rfmodel),('svm', clf)])","dfa516ad":"ereg.fit(X_train, y_train)","290fd67e":"y_pred=ereg.predict(X_test)","710d2358":"from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n# The coefficients\n#print('Coefficients: \\n',regressor.coef_)\n# The mean squared error\nprint('Root Mean squared error: %.2f'\n      % np.sqrt(mean_squared_error(y_test, y_pred)))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_test, y_pred))","c959047f":"ereg.score(X_test,y_test)","44d94c12":"Random forest","c14360b9":"![sales%20%281%29.png](attachment:sales%20%281%29.png)(http:\/\/)","a73f714e":"https:\/\/stackoverflow.com\/questions\/14984119\/python-pandas-remove-duplicate-columns\n\ndf = df.loc[:,~df.columns.duplicated()]\nHow it works:\n\ndf.columns.duplicated() returns a boolean array: a True or False for each column. If it is False then the column name is unique up to that point, if it is True then the column name is duplicated earlier. \nPandas allows one to index using boolean values whereby it selects only the True values. Since we want to keep the unduplicated columns, we need the above boolean array to be flipped (ie [True, True, False] = ~[False,False,True])\n\nFinally, df.loc[:,[True,True,False]] selects only the non-duplicated columns using the aforementioned indexing capability.\n\nNote: the above only checks columns names, not column values.","51037ac4":"cost function for ridge regression has an alpha term\ncost function= sum(y-yhat)**2+alpha(slope)**2\n\n\n\n"}}