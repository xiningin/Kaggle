{"cell_type":{"0a19ef7f":"code","1f6fc442":"code","48e15d67":"code","567f117b":"code","861ed58d":"code","aac7783a":"code","8ca3a387":"code","d66cf853":"code","b02ca426":"code","58f93601":"code","7cfe8e04":"code","6519d473":"code","5871cb83":"markdown","890af882":"markdown","a675ed7e":"markdown","f56838d1":"markdown","10894d64":"markdown","791aa67d":"markdown","b48dfc75":"markdown","72cbb077":"markdown","1a9d549d":"markdown","52b9fe38":"markdown","f0c42ae3":"markdown","8bf512bf":"markdown","aa825edc":"markdown","8eac099b":"markdown"},"source":{"0a19ef7f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        path=os.path.join(dirname, filename)\n        if 'train' in path:\n            __training_path=path\n        elif 'test' in path:\n            __test_path=path","1f6fc442":"#loaded files\nprint(f'Training path:{__training_path}\\nTest path:{__test_path}')","48e15d67":"# Kaggle Environment Prepration\n#update kaggle env\nimport sys\n#you may update the environment that allow you to run the whole code\n!{sys.executable} -m pip install --upgrade scikit-learn==\"0.24.2\"","567f117b":"#record this information if you need to run the Kernel internally\nimport sklearn; sklearn.show_versions() ","861ed58d":"def __load__data(__training_path, __test_path, concat=False):\n\t\"\"\"load data as input dataset\n\tparams: __training_path: the training path of input dataset\n\tparams: __test_path: the path of test dataset\n\tparams: if it is True, then it will concatinate the training and test dataset as output\n\treturns: generate final loaded dataset as dataset, input and test\n\t\"\"\"\n\t# LOAD DATA\n\timport pandas as pd\n\t__train_dataset = pd.read_csv(__training_path, delimiter=',')\n\t__test_dataset = pd.read_csv(__test_path, delimiter=',')\n\treturn __train_dataset, __test_dataset\n__train_dataset, __test_dataset = __load__data(__training_path, __test_path, concat=True)\n__train_dataset.head()","aac7783a":"# STORE SUBMISSION RELEVANT COLUMNS\n__test_dataset_submission_columns = __test_dataset['ID']","8ca3a387":"# DISCARD IRRELEVANT COLUMNS\n__train_dataset.drop(['ID'], axis=1, inplace=True)\n__test_dataset.drop(['ID'], axis=1, inplace=True)","d66cf853":"# PREPROCESSING-1\nfrom sklearn.preprocessing import OrdinalEncoder\n_CATEGORICAL_COLS = ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8']\n_ohe = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n__train_dataset[_CATEGORICAL_COLS] = pd.DataFrame(_ohe.fit_transform(__train_dataset[_CATEGORICAL_COLS]), columns=_CATEGORICAL_COLS)\n__test_dataset[_CATEGORICAL_COLS] = pd.DataFrame(_ohe.transform(__test_dataset[_CATEGORICAL_COLS]), columns=_CATEGORICAL_COLS)","b02ca426":"# DETACH TARGET\n__feature_train = __train_dataset.drop(['y'], axis=1)\n__target_train =__train_dataset['y']\n__feature_test = __test_dataset","58f93601":"# MODEL\nimport numpy as np\nfrom catboost import CatBoostRegressor\n__model = CatBoostRegressor()\n__model.fit(__feature_train, __target_train)\n__y_pred = __model.predict(__feature_test)","7cfe8e04":"# SUBMISSION\nsubmission = pd.DataFrame(columns=['ID'], data=__test_dataset_submission_columns)\nsubmission['y'] = __y_pred\nsubmission.head()","6519d473":"# save submission file\nsubmission.to_csv(\"kaggle_submission.csv\", index=False)","5871cb83":"## Check training and test path","890af882":"### DISCARD IRRELEVANT COLUMNS\nIn the given input dataset there are <b>1<\/b> column that can be removed as follows:* ID *.","a675ed7e":"## Encoding Ordinal Categorical Features\nLet's transfer categorical features as an integer array.\nWe will use Ordinal Encoder as explained [here](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.OrdinalEncoder.html).\n\nIn the given input dataset there are <b>8<\/b> columns that can be transfered to integer and it includes:* X0,X1,X2,X3,X4,X5,X6,X8 *.","f56838d1":"# Finding Intresting Datapoints\nLet's process each field by their histogram frequency and check if there is any intresting data point.\n\nThere are 4 number of intresting values in the following columns, where: \n\nThe below table shows each <b>Value<\/b> of each <b>Field<\/b> with their total frequencies, <b>Lower<\/b> shows the lower frequency of normal distribution, <b>Upper<\/b> shows the upper bound frequency of normal distribution, and <b>Criteria<\/b> shows if the frequnecy passed <b>Upper bound<\/b> or <b>Lower bound<\/b>.\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>Field<\/th>\n      <th>Value<\/th>\n      <th>Frequency<\/th>\n      <th>Lower<\/th>\n      <th>Upper<\/th>\n      <th>Criteria<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>X1<\/td>\n      <td>aa<\/td>\n      <td>833<\/td>\n      <td>3.0000<\/td>\n      <td>832.3890<\/td>\n      <td>Upper<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>X2<\/td>\n      <td>as<\/td>\n      <td>1659<\/td>\n      <td>1.0000<\/td>\n      <td>1653.9991<\/td>\n      <td>Upper<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>X3<\/td>\n      <td>c<\/td>\n      <td>1942<\/td>\n      <td>57.0636<\/td>\n      <td>1941.4804<\/td>\n      <td>Upper<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>X4<\/td>\n      <td>d<\/td>\n      <td>4205<\/td>\n      <td>1.0000<\/td>\n      <td>4203.7391<\/td>\n      <td>Upper<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>","10894d64":"Competition dataset located in \"\/kaggle\/input\"; This path defined by Kaggle to access the competition file. We will list two files from this path as input files.","791aa67d":"### Target Column\nThe target column is the value which we need to predict.\nTherefore, we need to detach the target columns in prediction.\nNote that if we don't drop this fields, it will generate a model with high accuracy on training and worst accuracy on test (because the value in test dataset is Null).\nTarget column: \"y\"","b48dfc75":"# Training Model and Prediction\nFirst, we will train a model based on preprocessed values of training data set.\nSecond, let's predict test values based on the trained model.","72cbb077":"# Load Competition Dataset","1a9d549d":"# Submission File\nWe have to maintain the target columns in \"submission.csv\" which will be submitted as our prediction results.","52b9fe38":"<img src=\"https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/6565\/media\/daimler-mercedes%20V02.jpg\"\/>","f0c42ae3":"## CatBoostRegressor\nWe will use CatBoostRegressor which is a fast, scalable, high performance gradient boosting on decision trees library. Used for ranking, classification, regression and other ML tasks.\n*CatBoostRegressor* detail can be found [here](https:\/\/catboost.ai\/docs\/installation\/python-installation-method-pip-install).","8bf512bf":"# Competition Summary\nDaimler\u2019s engineers have developed a robust testing system to ensure the safety and reliability of each and every unique car configuration. But optimizing the speed of their testing system for so many possible feature combinations is complex and time-consuming.","aa825edc":"# Exploratory Data Analysis (EDA)\n## General Structure\nMercedes-Benz Greener Manufacturing includes <b>4209<\/b> columns and <b>378<\/b> rows.\nThere are <b>3<\/b> different data types as follows: int64,float64,object","8eac099b":"# Input Dataset"}}