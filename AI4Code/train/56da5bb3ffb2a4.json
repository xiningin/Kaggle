{"cell_type":{"e9cde99c":"code","68dc14e3":"code","d4500cf9":"code","babb09c7":"code","9d09071c":"code","fce766dc":"code","10952f2f":"code","61b6ca43":"code","10d6ec21":"code","4056dc67":"code","2db2f132":"code","642195ff":"code","9ed12ec5":"code","9d39a24e":"code","06cdd913":"code","cfe205f9":"code","e928e7cd":"code","f387c0b8":"code","1f25e41d":"code","725f13a8":"code","2b90eae0":"code","5372ae03":"code","655037b4":"code","d740f806":"code","91264ba4":"code","26d0e274":"code","e4695391":"code","230b49de":"code","7ecefedb":"code","24d73e10":"code","62a402d8":"code","ebfe8da7":"code","2482e17a":"code","4bb0a1f5":"code","37c494ba":"code","ae8ddf11":"code","7bdac958":"code","37782fbc":"code","d7b2ed81":"code","3ece6a04":"code","0a950a23":"code","d258c61e":"code","85c1a594":"code","3b50abc2":"code","81c9e03b":"code","f85f2516":"code","cbc37a72":"code","a3856ec7":"code","bc05a730":"code","24b60822":"code","48452ec2":"code","ada0808b":"code","463f3b09":"code","cf789a38":"code","f6f5c689":"code","a55d66c9":"code","30f9fdc6":"code","c6ea700a":"code","1f4980db":"code","d1eb89cf":"code","6e9f84f0":"code","291bb997":"code","1cd48d30":"code","bbfd5a2d":"code","06ff78b6":"code","6b2aae66":"code","7baf5274":"code","88f9c263":"code","712454e1":"code","3e3a115f":"code","e6496648":"code","bfda10d1":"code","84e956e1":"markdown","b9dd95d3":"markdown","9ee3f17d":"markdown","171b2999":"markdown","9c874bd0":"markdown","19a2b746":"markdown","574a697b":"markdown","84d3db83":"markdown","4bbe5493":"markdown","5efd5c71":"markdown","d0356261":"markdown","1b482b2b":"markdown","6c3619b1":"markdown","bc57ce94":"markdown","d4baddac":"markdown","41acb86d":"markdown","840c9c3b":"markdown","bb556a51":"markdown","2f8279ac":"markdown","dc4b5653":"markdown","ca161ed3":"markdown","17dca799":"markdown","ff7be2f7":"markdown","f6c14884":"markdown","23a09373":"markdown","53e90d03":"markdown","c71c8dbf":"markdown","0f5c7caf":"markdown","8047fd6f":"markdown","8300abe7":"markdown","7e9e1b35":"markdown","7a3c4417":"markdown","03c441ef":"markdown","2355e06c":"markdown","cd9f2389":"markdown","afe34b83":"markdown","3faa0785":"markdown","d39aef69":"markdown","92dd30f4":"markdown","196e488c":"markdown","00797323":"markdown","e439235f":"markdown","b7bb7952":"markdown","e9073688":"markdown","93d7a86f":"markdown","3779f4d8":"markdown","fcd2b446":"markdown","30e2290c":"markdown","dc700ed3":"markdown","b4f9c201":"markdown","56633f2a":"markdown","f9b0ce8f":"markdown","55941aa3":"markdown","2b530a6c":"markdown","1de63dd8":"markdown","3405e1db":"markdown","467517bf":"markdown","1450f528":"markdown","3821d272":"markdown","004aed59":"markdown","b37ef12f":"markdown","31f925e6":"markdown","f8a4c7d5":"markdown","c9722d94":"markdown","082560cf":"markdown","2ecd3dfa":"markdown","b6cfe354":"markdown","7199ca26":"markdown","cde49f32":"markdown","b23d0780":"markdown","24ac3de6":"markdown","ce17dd38":"markdown","16d4de64":"markdown"},"source":{"e9cde99c":"#import necessary package>\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nfrom matplotlib import patches\nimport plotly.express as px\nimport seaborn as sns\nimport glob\nimport re\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"Libraries imported!\")","68dc14e3":"#datasets\npath=\"..\/input\/learnplatform-covid19-impact-on-digital-learning\"","d4500cf9":"#reading the products data into data frame df_prod\ndf_prod = pd.read_csv(path+'\/products_info.csv')\ndf_prod.head()  # printing the first 5 entries of dataframe ","babb09c7":"df_prod.shape","9d09071c":"# how many unique provider are there\n\nprint('total unique products ', df_prod['LP ID'].unique().size)\nprint('total unique provider in top 372 products are ',df_prod['Provider\/Company Name'].unique().size)\nprint('total unique sector are ',df_prod['Sector(s)'].unique().size)\na=list(df_prod['Sector(s)'].unique())\nfor i in a:\n    print(i)\n# some of the products are used in multiple sectors for example entries like 'PreK-12; Higher Ed'\n# only three sectors are concerned here, prek-12, higher Ed and corporate\n","fce766dc":"#loading districts data into dataframe\ndf_dist = pd.read_csv(path+'\/districts_info.csv')\ndf_dist.head() ","10952f2f":"df_dist.shape","61b6ca43":"#engagement data\nfiles = glob.glob(path+'\/engagement_data\/*.csv')\nengagement = []\n\nfor filename in files:\n    df_engage = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split('\/')[4].split('.')[0]\n    df_engage['district_id'] = district_id\n    engagement.append(df_engage)\n    \ndf_engagement = pd.concat(engagement)\ndf_engagement = df_engagement.reset_index(drop=True)\n\ndf_engagement.head()","10d6ec21":"df_engagement.shape","4056dc67":"def missing_values(df):\n    ''' This function takes a data frame as input \n    prints the fraction of entries with missing values (NaN)\n    prints the list of columns with corresponding number of missing values\n    '''\n    # Total number of entries (rows X columns) in the dataset\n    total= df.size\n    #Number of missing values per column\n    missingCount = df.isnull().sum()\n    #Total number of missing values\n    missing_tot = missingCount.sum()\n    # Calculate percentage of missing values\n    print('Total number of missing values for each column of dataframe: \\n \\b \\b \\b',missingCount)\n    print(\"The dataset contains\", round(((missing_tot\/total) * 100), 2), \"%\", \"missing values\")\n    print('Total number of rows with at least one missing value column are ',df[df.isnull().any(axis=1)].shape[0])\n    print('% of rows with missing data ',round(((df[df.isnull().any(axis=1)].shape[0]\/df.shape[0])*100),2),'%\\n\\n')\n    \n    \ndef column_missingdata(df):\n    ''' This function takes a data frame as input \n    prints the list of columns with corresponding % of missing values\n    '''\n    #check for missing values per column\n    values=df.isnull().sum()#.sort_values(ascending=False)\n    total= df.size\n    #percentage of missing values per column\n    percentage=(values\/total) * 100\n    print('% of missing values for each column of dataframe: \\n \\b \\b \\b',percentage,'\\n\\n\\n')\n\ndef plot_missingdata(df:pd.DataFrame, title:str, xlabel:str, ylabel:str):\n    ''' This function takes a data frame as input \n    plots the list of columns with corresponding total number of missing values\n    '''\n    # Let us see what columns have missing values\n    # total number of missing values for each dataframe column\n    missing = df.isnull().sum() \n    # keeping only the columns with missing values>0 \n    missing = missing[missing > 0] \n    # sorting in order of missing values and making the change to original missing series\n    missing.sort_values(inplace=True) \n    missing.plot.bar()\n    plt.title(title, size=15,loc='left')\n    plt.xticks(fontsize=11,rotation=45)\n    plt.yticks(fontsize=11)\n    plt.xlabel(xlabel, fontsize=13)\n    plt.ylabel(ylabel, fontsize=13)\n    plt.show()\n    \n    \ndef fix_missing_mean(df,col):\n    ''' This function takes a data frame and column name as input \n    replaces the missing values of a particular column with it's mean value\n    '''\n    #replace missing values with mean \n    df[col].fillna(df[col].mean(), inplace = True)    \n\ndef fix_missing_mode(df,col):\n    ''' This function takes a data frame and column name as input \n    replaces the missing values of a particular column with it's mode value\n    '''\n    #replace missing values with mean \n    df[col].fillna(df[col].mode(), inplace = True)    \n\n    \ndef fix_missing_ffill(df, col):\n    ''' This function takes a data frame and column name as input \n    replaces the missing values of a particular column with the value from the previous row\n    '''\n    df[col] = df[col].fillna(method='ffill')  \n    \ndef fix_missing_bfill(df, col):\n    ''' This function takes a data frame as input \n    replaces the missing values of a particular column with the value from the next row\n    '''\n    df[col] = df[col].fillna(method='bfill')     ","2db2f132":"# python library to study missing data\nimport missingno as msno","642195ff":"# explicitly printing the rows of products dataset with at least one missing value column\ndf_prod[df_prod.isnull().any(axis=1)].head()","9ed12ec5":"#products\nmissing_values(df_prod)\ncolumn_missingdata(df_prod)\nplot_missingdata(df_prod,'products dataset columns with missing values','Column Name','No. of Missing values')","9d39a24e":"#heat map of missing value , it will show the corrrelation between different columns for missing values\nax = msno.heatmap(df_prod,figsize=(6,6))\nplt.show()","06cdd913":"# dropping all the rows with any missing values \ndf_prod_x=df_prod\ndf_prod_x.dropna(axis=0,how='any',inplace=True)\n\n#check missing columns in product dataset\ncolumn_missingdata(df_prod_x)","cfe205f9":"df_prod_x.shape","e928e7cd":"#district\nmissing_values(df_dist)\ncolumn_missingdata(df_dist)\nplot_missingdata(df_dist,'districts dataset columns with missing values','Column Name','No. of Missing values')","f387c0b8":"#heat map of missing value , it will show the corrrelation between different columns for missing values\nax = msno.heatmap(df_dist,figsize=(6,6))\nplt.show()","1f25e41d":"#district\n#drop nan values in state column\ndf_dist_x = df_dist[df_dist[\"locale\"].notna()].reset_index(drop=True)\n#check missing columns in district dataset\ncolumn_missingdata(df_dist_x)\n","725f13a8":"missing_values(df_dist_x)","2b90eae0":"fix_missing_ffill(df_dist_x,'pct_free\/reduced')\nfix_missing_ffill(df_dist_x,'county_connections_ratio')\nfix_missing_ffill(df_dist_x,'pp_total_raw') ","5372ae03":"df_dist_x.head()","655037b4":"df_dist_x.shape","d740f806":"#engagement\nmissing_values(df_engagement)\ncolumn_missingdata(df_engagement)\nplot_missingdata(df_engagement,'engagement dataset columns with missing values\\n\\n','Column Name','No. of Missing values')","91264ba4":"#heat map of missing value , it will show the corrrelation between different columns for missing values\nax = msno.heatmap(df_engagement,figsize=(6,6))\nplt.show()","26d0e274":"#drop nan values in lp_id column\ndf_engagement_x = df_engagement[df_engagement[\"lp_id\"].notna()].reset_index(drop=True)\n\n# fill the missing values with mean value of the column in the engagement dataset\nfix_missing_mean(df_engagement_x,'pct_access')\nfix_missing_mean(df_engagement_x,'engagement_index')","e4695391":"df_engagement.head()","230b49de":"#check missing columns in enagement dataset\ncolumn_missingdata(df_engagement_x)","7ecefedb":"#defining functions for plots\n#countplot\ndef plot_count(df:pd.DataFrame, y_col:str, title:str, xlabel:str, ylabel:str):\n    fig, ax = plt.subplots(1, 1, figsize=(10,6), sharey=True)\n    sns.countplot(data=df, y=y_col,edgecolor=\"white\",palette=\"viridis\",order=df[y_col].value_counts().index)\n    total = df[y_col].value_counts().sum()\n    for i, v in enumerate(df[y_col].value_counts().sort_values(ascending=False).values): \n        frac1 = (v\/total)*100\n        frac = \"{:.2f}\".format(frac1)\n        v1 = str(v)+' ('+str(frac)+'%)'\n        ax.text(v*1.01, i, v1,fontsize=10,color='black',weight='bold')\n   \n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(xlabel, fontsize=16)\n    plt.ylabel(ylabel, fontsize=16)\n    plt.show()\n    \n#pieplot_for locale\ndef plot_pie(df:pd.DataFrame,column:str, title:str):\n    fig, ax  = plt.subplots(figsize=(16, 8))\n    fig.suptitle(column+' Distribution', font=\"Serif\",fontsize=20)\n    explode = (0.01, 0.01, 0.01, 0.01) \n    labels = list(df[column].value_counts().index)\n    sizes = df[column].value_counts().values\n    ax.pie(sizes, \n           explode=explode,\n           startangle=60, \n           labels=labels,\n           autopct='%1.0f%%', \n           pctdistance=0.7)\n    ax.add_artist(plt.Circle((0,0),0.5,fc='white'))\nplt.show()\n    \n#barplot   \ndef plot_bar(df:pd.DataFrame,minimum:str,maximum:str,y_col:str, title:str, xlabel:str, ylabel:str):\n    df1 = df.groupby(y_col)[minimum, maximum].mean().sort_values([minimum, maximum],ascending=False)\n    df1.plot(kind = 'bar',color=['blue','darkblue'])\n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(xlabel, fontsize=16)\n    plt.ylabel(ylabel, fontsize=16)\n    plt.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0)\n    plt.show()\n\n\ndef plot_barh(df:pd.DataFrame, x_col:pd.DataFrame,y_col:pd.DataFrame, title:str, xlabel:str,ylabel:str):\n    fig, ax  = plt.subplots(figsize=(10,6))    \n    sns.barplot(data = df,y=y_col,x=x_col,palette=\"viridis\")\n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(xlabel, fontsize=16)\n    plt.ylabel(ylabel, fontsize=16)\n    plt.show()\n    \ndef plot_bar1(df:pd.DataFrame, x_col:pd.DataFrame,y_col:pd.DataFrame, title:str, xlabel:str,ylabel:str):\n    fig, ax  = plt.subplots(figsize=(10,6)) \n    sns.barplot(data = df,y=y_col,x=x_col,palette=\"viridis\",order=df.groupby(y_col).mean()[x_col].sort_values(ascending=False).index,ci=None)\n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(xlabel, fontsize=16)\n    plt.ylabel(ylabel, fontsize=16)\n    plt.show()\n    \n    \ndef plot_bar2(df1:pd.DataFrame, x_col:str,y_col1:str, ax1_title:str, xlabel1:str,ylabel1:str,df2:pd.DataFrame,y_col2:str,ax2_title:str, xlabel2:str,ylabel2:str):\n    fig, ax = plt.subplots(1, 2, figsize=(12,5))\n    sns.barplot(data = df1,y=y_col1,x=x_col,palette=\"viridis\", ax=ax[0])\n    ax[0].set_title(ax1_title)\n    ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=90)\n    ax[0].set_xlabel(xlabel1)\n    ax[0].set_ylabel(ylabel1)\n\n    sns.barplot(data = df2,y=y_col2,x=x_col,palette=\"viridis\", ax=ax[1])\n    ax[1].set_title(ax2_title)\n    ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=90)\n    ax[1].set_xlabel(xlabel2)\n    ax[1].set_ylabel(ylabel2)\n    plt.show()    \n    \ndef plot_scatter(df: pd.DataFrame, x_col: str, y_col: str, title: str, hue: str):\n    plt.figure(figsize=(10, 5))\n    sns.scatterplot(data = df, x=x_col, y=y_col, hue=hue, size=hue,sizes=(20, 200))\n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks( fontsize=14)\n    plt.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0)\n    plt.show() \n    \ndef plot_pairplot(df: pd.DataFrame):#, hue:str, diag_kind:str\n    sns.pairplot(df)\n    #pd.plotting.scatter_matrix(df, alpha=0.2)\n    plt.show() \n    \n    \ndef plot_line(df: pd.DataFrame,x_col: str, y_col: str, hue: str, title:str, xlabel:str, ylabel:str, text1:int, text2:int):#, hue:str, diag_kind:str\n    fig, ax  = plt.subplots(figsize=(15,7))    \n    sns.lineplot(data=df, x=x_col, y=y_col, hue=hue,lw=2)\n    plt.title(title, size=30)\n    plt.xticks(fontsize=20)#,rotation=45)\n    plt.yticks(fontsize=20)\n    plt.xlabel(xlabel, fontsize=30)\n    plt.ylabel(ylabel, fontsize=30)\n    plt.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0)\n    plt.axvline(pd.Timestamp('2020-03-11'),color='black')\n    ax.text(pd.Timestamp(\"2020-03-11\"), text1, \"  WHO has declared Covid-19 a pandemic\",size=20,fontname = 'monospace',color='black')\n    xy = datetime(2020,6,1,0,0,0), ax.get_ylim()[0]\n    w, h = timedelta(days=92), ax.get_ylim()[1] - ax.get_ylim()[0]\n    ax.add_patch(patches.Rectangle(xy, w, h,color ='black',alpha=0.1))\n    ax.text(pd.Timestamp(\"2020-06-17\"), text2, \"Summer Break\",size=20,fontname = 'monospace',color='black')\n    plt.show() \n    \ndef plot_line_day(df: pd.DataFrame,x_col: str, y_col: str, hue: str, title:str, xlabel:str, ylabel:str, text1:int, text2:int):#, hue:str, diag_kind:str\n    fig, ax  = plt.subplots(figsize=(15,7))    \n    sns.lineplot(data=df, x=x_col, y=y_col, hue=hue,style=hue,ci=None,markers=False, dashes=False, lw=2)\n    plt.title(title, size=30)\n    plt.xticks(fontsize=20)#,rotation=45)\n    plt.yticks(fontsize=20)\n    plt.xlabel(xlabel, fontsize=30)\n    plt.ylabel(ylabel, fontsize=30)\n    plt.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0)\n    plt.show()     ","24d73e10":"plot_count(df_dist_x,'state','Number of districts per state','Districts Count','State')","62a402d8":"#barplot\nplot_count(df_dist_x,'locale','Number of districts per locale type','Districts count for locale type','Locale')","ebfe8da7":"#pie plot\nplot_pie(df_dist_x,'locale','Number of districts per locale')","2482e17a":"#we have spiltted columns like 'pct_black\/hispanic', 'pct_free\/reduced', 'county_connections_ratio' and 'pp_total_raw' into 2 different columns based on their maximum and minimum value\ndf_dist1=df_dist_x\n#'pct_black\/hispanic'\ndf_dist1[['min_pct_black\/hispanic','max_pct_black\/hispanic']] = df_dist1['pct_black\/hispanic'].str.split(\",\",expand=True)\ndf_dist1['min_pct_black\/hispanic'] = df_dist1['min_pct_black\/hispanic'].str.strip('[')\ndf_dist1['max_pct_black\/hispanic'] = df_dist1['max_pct_black\/hispanic'].str.strip('[')\n\n#'pct_free\/reduced'\ndf_dist1[['min_pct_free\/reduced','max_pct_free\/reduced']] = df_dist1['pct_free\/reduced'].str.split(\",\",expand=True)\ndf_dist1['min_pct_free\/reduced'] = df_dist1['min_pct_free\/reduced'].str.strip('[')\ndf_dist1['max_pct_free\/reduced'] = df_dist1['max_pct_free\/reduced'].str.strip('[')\n\n#'county_connections_ratio'\ndf_dist1[['min_county_connections_ratio','max_county_connections_ratio']] = df_dist1['county_connections_ratio'].str.split(\",\",expand=True)\ndf_dist1['min_county_connections_ratio'] = df_dist1['min_county_connections_ratio'].str.strip('[')\ndf_dist1['max_county_connections_ratio'] = df_dist1['max_county_connections_ratio'].str.strip('[')\n\n#'pp_total_raw'\ndf_dist1[['min_pp_total_raw','max_pp_total_raw']] = df_dist1['pp_total_raw'].str.split(\",\",expand=True)\ndf_dist1['min_pp_total_raw'] = df_dist1['min_pp_total_raw'].str.strip('[')\ndf_dist1['max_pp_total_raw'] = df_dist1['max_pp_total_raw'].str.strip('[')\n\n#import the original columns\ndf_dist1.drop(['pct_black\/hispanic', 'pct_free\/reduced', 'county_connections_ratio', 'pp_total_raw'], axis = 1, inplace = True)","4bb0a1f5":"df_dist1.dtypes","37c494ba":"#convert object to numbers\ncols = df_dist1.columns.drop(['state', 'locale'])\ndf_dist1[cols] = df_dist1[cols].apply(pd.to_numeric, errors = 'coerce')","ae8ddf11":"#except state and locale we have converted all others object columns to numeric columns\ndf_dist.dtypes","7bdac958":"plot_bar(df_dist1,'min_pct_black\/hispanic','max_pct_black\/hispanic','locale','Mean % of black or hispanic students by locale','Locale','Mean')\nplot_bar(df_dist1,'min_pct_free\/reduced','max_pct_free\/reduced','locale','Mean % of students eligible for free\/reduced lunch by locale','Locale','Mean')\nplot_bar(df_dist1,'min_pp_total_raw','max_pp_total_raw','locale','Mean total expenditure in USD per student by locale','Locale','Mean')\nplot_bar(df_dist1,'min_county_connections_ratio','max_county_connections_ratio','locale','mean connection ratio by locale','Locale','Mean')","37782fbc":"df_dist1[\"avg_pct_black\/hispanic\"] = df_dist1[[\"min_pct_black\/hispanic\", \"max_pct_black\/hispanic\"]].mean(axis=1)\ndf_dist1[\"avg_pct_free\/reduced\"] = df_dist1[[\"min_pct_free\/reduced\", \"max_pct_free\/reduced\"]].mean(axis=1)\ndf_dist1[\"avg_pp_total_raw\"] = df_dist1[[\"min_pp_total_raw\", \"max_pp_total_raw\"]].mean(axis=1)\ndf_dist1[\"avg_county_connections_ratio\"] = df_dist1[[\"min_county_connections_ratio\", \"max_county_connections_ratio\"]].mean(axis=1)","d7b2ed81":"df_dist1[df_dist1['state']=='North Dakota']","3ece6a04":"df_dist[df_dist['state']=='North Dakota']","0a950a23":"plot_bar1(df_dist1,'avg_pct_black\/hispanic','state','Mean % of black or hispanic students per State','Mean Student Expenditure','State')\nplot_bar1(df_dist1,'avg_pct_free\/reduced','state','Mean % of students eligible for free\/reduced lunch per State','Mean Student Expenditure','State')\nplot_bar1(df_dist1,'avg_pp_total_raw','state','Mean Student Expenditure per State','Mean Student Expenditure','State')\nplot_bar1(df_dist1,'avg_county_connections_ratio','state','Mean Connection Ratio per State','Mean Connection Ratio','State')","d258c61e":"fig, ax = plt.subplots(1, 1, figsize=(7,5), sharey=True)\nsns.countplot(y = 'Provider\/Company Name', \n              data = df_prod_x, \n              edgecolor=\"white\",\n              palette=\"viridis\",#\"rocket_r\",\n              order = df_prod['Provider\/Company Name'].value_counts().index[:5])\n\nfor rect in ax.patches:\n    ax.text (rect.get_width(), rect.get_y() + rect.get_height() \/ 2,\"%.1f\"% rect.get_width(), weight='bold' )\n \n ###\nplt.xticks(size=10)\nplt.yticks(size=10)\nplt.ylabel(\"Provider\/Company Name\",size=15)\nplt.xlabel(\"products counts\",size=15)\nplt.title('Number of products per Provider\/Company Names (Top 5)',size=15)\n\nplt.show()","85c1a594":"print('Provider\/Company Names ')\ncloud = WordCloud(max_words=500,background_color=\"white\").generate(\" \".join(df_prod_x['Provider\/Company Name'].astype(str)))\nplt.figure(figsize=(9,20))\nplt.imshow(cloud)\nplt.axis('off')\nplt.show()\n\nprint('\\n\\n\\n\\n Product Names ')\ncloud = WordCloud(max_words=1000,background_color=\"white\").generate(\" \".join(df_prod_x['Product Name'].astype(str)))\nplt.figure(figsize=(9,20))\nplt.imshow(cloud)\nplt.axis('off')\nplt.show()","3b50abc2":"s1=0\ns2=0\ns3=0\nfor s in df_prod[\"Sector(s)\"]:\n    if(not pd.isnull(s)):\n        s = s.split(\";\")\n        for i in range(len(s)):\n            sub = s[i].strip()\n            if(sub == 'PreK-12'): \n                s1=s1+1\n            if(sub == 'Higher Ed'): \n                s2=s2+1\n            if(sub == 'Corporate'): \n                s3=s3+1\n\nfig, ax  = plt.subplots(figsize=(14, 8))\nfig.suptitle('Sector Distribution', font=\"Serif\",fontsize=20)\nexplode = (0.01, 0.01, 0.01)#,0.01,0.01)\n#labels = list(df_prod[\"Sector(s)\"].value_counts().index)\n#sizes = df_prod[\"Sector(s)\"].value_counts().values\nlabels = ['PreK-12','Higher Ed','Corporate']\nsizes = [s1,s2,s3]\nax.pie(sizes,\n       startangle=60,\n       explode=explode, \n       labels=['PreK-12','Higher Ed','Corporate'],\n       autopct='%1.2f%%', \n       pctdistance=0.7)\nax.add_artist(plt.Circle((0,0),0.5,fc='white'))\nplt.show()","81c9e03b":"fig, ax = plt.subplots(1, 1, figsize=(10,20), sharey=True)\nsns.countplot(y = 'Primary Essential Function', \n              data = df_prod_x, \n              edgecolor=\"white\",\n              palette=\"viridis\",\n              order = df_prod['Primary Essential Function'].value_counts().index)\n \n\ntotal = df_prod_x[\"Primary Essential Function\"].value_counts().sum()\nfor i, v in enumerate(df_prod_x[\"Primary Essential Function\"].value_counts().sort_values(ascending=False).values): \n    frac1 = (v\/total)*100\n    frac = \"{:.2f}\".format(frac1)\n    v1 = str(v)+' ('+str(frac)+'%)'\n    ax.text(v*1.01, i, v1,fontsize=10,color='black',weight='bold')\n    \nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.ylabel(\"Primary Essential Function\",size=20)\nplt.xlabel(\"products count\",size=20)\nplt.title('Number of products used by Primary Essential Function',size=25)\n\nplt.show()","f85f2516":"s1=0\ns2=0\ns3=0\nfor s in df_prod_x[\"Primary Essential Function\"]:\n    if(not pd.isnull(s)):\n        s1 = s.count(\"CM\")+1\n        s2 = s.count(\"LC\")+1\n        s3 = s.count(\"SDO\")+1\n\nfig, ax  = plt.subplots(figsize=(16, 10))\nfig.suptitle('% Distribution of primary essential function', font=\"Serif\",fontsize=20)\nexplode = (0.01, 0.01, 0.01)#,0.01,0.01)\nlabels = ['CM','LC','SDO']\nsizes = [s1,s2,s3]\nax.pie(sizes,\n       startangle=60,\n       explode=explode, \n       labels=labels,\n       autopct='%1.2f%%', \n       pctdistance=0.7)\nax.add_artist(plt.Circle((0,0),0.5,fc='white'))\nsubgroup_names_legs=['CM:Classroom Management', 'LC:Learning & Curriculum', 'SDO:School & District Operations']\nplt.legend(subgroup_names_legs,loc='best')\nplt.show()","cbc37a72":"#Subdivide primary essential function\ndf_prod_y=df_prod_x\ndf_prod_y['primary_function_main'] = df_prod_y['Primary Essential Function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\ndf_prod_y['primary_function_sub'] = df_prod_y['Primary Essential Function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\ndf_prod_y['primary_function_sub'] = df_prod_y['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\n# Deleting the 'Primary Essential Function' column from the product dataset as it is no longer needed since we already have split it into two sub-columns.\ndf_prod_y.drop(\"Primary Essential Function\", axis=1, inplace=True)","a3856ec7":"df_engagement['time'] = pd.to_datetime(df_engagement['time'])\ndf_engagement['month'] = df_engagement['time'].dt.month\n\nfig, ax = plt.subplots(1, 1, figsize=(7,5), sharey=True)\nsns.barplot(x = 'month',y='engagement_index', \n              data = df_engagement.groupby(df_engagement['month']).mean().reset_index(), \n              edgecolor=\"white\",\n              palette=\"viridis\")\n\n\nplt.title('Mean engagement index vs month',size=15)\nplt.xlabel(\"Month\",size=15)\nplt.ylabel(\"Mean engagement index\",size=15)\nplt.show()","bc05a730":"#combine three tables together based on common column identifiers\ndf_engagement_x['lp_id'] = df_engagement_x['lp_id'].astype('int')\ndf_engagement_x['district_id'] = df_engagement_x['district_id'].astype('int')\n\n# merging engagement and district data based on district id \nData = pd.merge(df_engagement_x,df_dist_x,how='left',on='district_id')\n\n# merging above data with prod data based on LP ID (unique product identifier)\nData = pd.merge(Data,df_prod_y,how='left',left_on='lp_id',right_on='LP ID')","24b60822":"#dropping missing values from the dataset\n#Data.dropna(axis=0,how='any',inplace=True)\nData = Data[Data[\"LP ID\"].notna()].reset_index(drop=True)","48452ec2":"Data.head()","ada0808b":"plt.figure(figsize=(7,4))\nsns.histplot(Data.groupby('district_id').time.nunique(), bins=40, color = 'blue')\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.xlabel('Number of days', fontsize=10)\nplt.ylabel('Number of districts', fontsize=10)\nplt.title('Districts with unique days of engagement ', fontsize = 15)\n\nplt.show()","463f3b09":"plt.figure(figsize=(7,4))\nsns.histplot(Data.groupby('district_id').time.nunique(), bins=40, color = 'blue')\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.xlabel('Number of days', fontsize=10)\nplt.ylabel('Number of districts', fontsize=10)\nplt.title('Districts with unique days of engagement ', fontsize = 15)\nplt.yscale('log')\nplt.show()","cf789a38":"# selecting data set including entries for only primary function as LC (most student engagement expected here)\nDatax=Data.loc[((Data[\"Sector(s)\"]==\"PreK-12\")|(Data[\"Sector(s)\"]==\"PreK-12; Higher Ed\")|(Data[\"Sector(s)\"]==\"PreK-12; Higher Ed; Corporate\"))&(Data[\"primary_function_main\"]==\"LC\")]\n\n# grouping data state wise and storing the mean of certain columns \nstate_eng=pd.DataFrame(Datax.groupby('state')[['engagement_index','avg_pp_total_raw','avg_pct_black\/hispanic','avg_pct_free\/reduced']].mean().sort_values(['engagement_index','avg_pp_total_raw','avg_pct_black\/hispanic','avg_pct_free\/reduced'],ascending=False))\nstate_eng=state_eng.reset_index()\nplot_barh(state_eng,'engagement_index','state','Mean Engagement Index per State','Engagement','State')\n\nstate_access=pd.DataFrame(Datax.groupby('state')[['pct_access','avg_pp_total_raw','avg_pct_black\/hispanic','avg_pct_free\/reduced']].mean().sort_values(['pct_access','avg_pp_total_raw','avg_pct_black\/hispanic','avg_pct_free\/reduced'],ascending=False))\nstate_access=state_access.reset_index()\nplot_barh(state_access,'pct_access','state','Mean pct_access per State','Access','State')","f6f5c689":"# for our plot we only need following columns: time, engagement_index, primary_function_main \nData['time'] = pd.to_datetime(Data['time'])\nData['month'] = Data['time'].dt.month\n\nsns.catplot(x = 'month',y='engagement_index', \n              data = Data.groupby(by=['month','primary_function_main']).mean().reset_index(), \n              edgecolor=\"white\",kind='bar',\n              palette=\"viridis\",col='primary_function_main',col_wrap=2,height=4)\n\n\nplt.show()","a55d66c9":"# lets check the correlation between different features of data or variables , \n# pct access, expenditure, black\/hispanic, free\/reduced lunch eligibility %\ng = sns.pairplot(state_access)\n\n# let's show pearson correlation coefficient (https:\/\/en.wikipedia.org\/wiki\/Pearson_correlation_coefficient) \n#above each pair plot \nfrom scipy.stats import pearsonr\ndef corrfunc(x, y, ax=None, **kws):\n    \"\"\"Plot the correlation coefficient in the top left hand corner of a plot.\"\"\"\n    r, _ = pearsonr(x, y)\n    ax = ax or plt.gca()\n    ax.annotate(f'\u03c1 = {r:.2f}', xy=(.6, .9), xycoords=ax.transAxes)\n\ng.map_offdiag(corrfunc)\nplt.show()","30f9fdc6":"# lets study the engagement correlation with \ng=sns.pairplot(state_eng)\ng.map_offdiag(corrfunc)\nplt.show()","c6ea700a":"sns.relplot(x=\"avg_pp_total_raw\", y=\"engagement_index\", kind=\"line\", data=state_eng,ci=None)\nsns.relplot(x=\"avg_pct_black\/hispanic\", y=\"engagement_index\", kind=\"line\", data=state_eng,ci=None)\nsns.relplot(x=\"avg_pct_free\/reduced\", y=\"engagement_index\", kind=\"line\", data=state_eng,ci=None)\nsns.relplot(x=\"avg_pct_black\/hispanic\", y=\"avg_pct_free\/reduced\", kind=\"line\", data=state_eng,ci=None)","1f4980db":"locale_eng=pd.DataFrame(Datax.groupby('locale')['engagement_index'].mean().sort_values(ascending=False))\nlocale_eng=locale_eng.reset_index()\nlocale_access=pd.DataFrame(Datax.groupby('locale')['pct_access'].mean().sort_values(ascending=False))\nlocale_access=locale_access.reset_index()\n\nplot_bar2(locale_eng,'locale','engagement_index','Mean Engagement Index per locale','locale','Mean engagement index',locale_access,'pct_access','Mean pct_access per locale','locale','Mean pct access')","d1eb89cf":"product_eng=pd.DataFrame(Datax.groupby('Product Name')['engagement_index'].mean().sort_values(ascending=False))\nproduct_eng=product_eng.reset_index()\nproduct_eng_large=product_eng[[\"engagement_index\",\"Product Name\"]].head(10)\nproduct_eng_least=product_eng[[\"engagement_index\",\"Product Name\"]].tail(10)\n#plot_barh(product_eng_large,'engagement_index','Product Name','Most engaged products','Product Name','Engagement')\n#plot_barh(product_eng_least,'engagement_index','Product Name','Least engaged products','Product Name','Engagement')\nplot_bar2(product_eng_least,'Product Name','engagement_index','Least engaged products','Product Name','Engagement index',product_eng_large,'engagement_index','Most engaged products','Product Name','Engagement index')","6e9f84f0":"product_access=pd.DataFrame(Datax.groupby('Product Name')['pct_access'].mean().sort_values(ascending=False))\nproduct_access=product_access.reset_index()\nproduct_access_large=product_access[[\"pct_access\",\"Product Name\"]].head(10)\nproduct_access_least=product_access[[\"pct_access\",\"Product Name\"]].tail(10)\n\nplot_bar2(product_access_least,'Product Name','pct_access','Least accessed products','Product Name','PCT Access',product_access_large,'pct_access','Most accessed products','Product Name','PCT Access')","291bb997":"st_ac\u0441ess = Data.groupby(['state', 'time']).agg({'pct_access': 'mean'}).sort_values(['pct_access'],ascending=False).reset_index()\nst_eng = Data.groupby(['state', 'time']).agg({'engagement_index': 'mean'}).sort_values(['engagement_index'],ascending=False).reset_index()\nloc_ac\u0441ess = Data.groupby(['locale', 'time']).agg({'pct_access': 'mean'}).sort_values(['pct_access'],ascending=False).reset_index()\nloc_eng = Data.groupby(['locale', 'time']).agg({'engagement_index': 'mean'}).sort_values(['engagement_index'],ascending=False).reset_index()\ncat_ac\u0441ess = Data.groupby(['primary_function_main', 'time']).agg({'pct_access': 'mean'}).sort_values(['pct_access'],ascending=False).reset_index()\ncat_eng = Data.groupby(['primary_function_main', 'time']).agg({'engagement_index': 'mean'}).sort_values(['engagement_index'],ascending=False).reset_index()\n\n\nfor i in [st_ac\u0441ess, st_eng, loc_ac\u0441ess, loc_eng, cat_ac\u0441ess, cat_eng]:\n    i['time'] = pd.to_datetime(i['time'], errors='coerce')\n    i['day_of_week'] = i['time'].dt.dayofweek\n    i['month'] = i['time'].dt.month","1cd48d30":"plot_line(st_ac\u0441ess,\"time\",\"pct_access\",\"state\",\"Dynamics of pct_access of all products by states\",\"Month\",\"pct_access\",6,3)\nplot_line(st_eng,\"time\",\"engagement_index\",\"state\",\"Dynamics of engagement_index of all products by states\",\"Month\",\"engagement_index\",2000,1000)\n\n#plot_line_day(st_ac\u0441ess,\"month\",\"pct_access\",\"state\",\"Dynamics of pct_access of all products by states\",\"Month\",\"pct_access\",6,3)\n#plot_line_day(st_eng,\"month\",\"engagement_index\",\"state\",\"Dynamics of engagement_index of all products by states\",\"Month\",\"engagement_index\",2000,1000)\n\nplot_line_day(st_ac\u0441ess,\"day_of_week\",\"pct_access\",\"state\",\"Dynamics of pct_access of all products by states\",\"weekday\",\"pct_access\",6,3)\nplot_line_day(st_eng,\"day_of_week\",\"engagement_index\",\"state\",\"Dynamics of engagement_index of all products by states\",\"weekday\",\"engagement_index\",2000,1000)\n\n#plot_line_day(st_ac\u0441ess,\"month\",\"pct_access\",\"day_of_week\",\"Dynamics of pct_access of all products by day\",\"Month\",\"pct_access\",6,3)\n#plot_line_day(st_eng,\"month\",\"engagement_index\",\"day_of_week\",\"Dynamics of engagement_index of all products by day\",\"Month\",\"engagement_index\",2000,1000)","bbfd5a2d":"plot_line(loc_ac\u0441ess,\"time\",\"pct_access\",\"locale\",\"Dynamics of pct_access of all products by locale\",\"Month\",\"pct_access\",1.6,1)\nplot_line(loc_eng,\"time\",\"engagement_index\",\"locale\",\"Dynamics of engagement_index of all products by locale\",\"Month\",\"engagement_index\",500,400)\n\n#plot_line_day(loc_ac\u0441ess,\"month\",\"pct_access\",\"locale\",\"Dynamics of pct_access of all products by locale\",\"Month\",\"pct_access\",1.6,1)\n#plot_line_day(loc_eng,\"month\",\"engagement_index\",\"locale\",\"Dynamics of engagement_index of all products by locale\",\"Month\",\"engagement_index\",500,400)\n\nplot_line_day(loc_ac\u0441ess,\"day_of_week\",\"pct_access\",\"locale\",\"Dynamics of pct_access of all products by locale\",\"weekday\",\"pct_access\",6,3)\nplot_line_day(loc_eng,\"day_of_week\",\"engagement_index\",\"locale\",\"Dynamics of engagement_index of all products by locale\",\"weekday\",\"engagement_index\",2000,1000)\n\n#plot_line_day(loc_ac\u0441ess,\"month\",\"pct_access\",\"day_of_week\",\"Dynamics of pct_access of all products by day\",\"Month\",\"pct_access\",6,3)\n#plot_line_day(loc_eng,\"month\",\"engagement_index\",\"day_of_week\",\"Dynamics of engagement_index of all products by day\",\"Month\",\"engagement_index\",2000,1000)","06ff78b6":"plot_line(cat_ac\u0441ess,\"time\",\"pct_access\",\"primary_function_main\",\"Dynamics of pct_access of all products by primary function catagory\",\"Month\",\"pct_access\",4,3)\nplot_line(cat_eng,\"time\",\"engagement_index\",\"primary_function_main\",\"Dynamics of engagement_index of all products by primay function catagory\",\"Month\",\"engagement_index\",1200,1000)\n\n#plot_line_day(cat_ac\u0441ess,\"month\",\"pct_access\",\"primary_function_main\",\"Dynamics of pct_access of all products by primary function catagory\",\"Month\",\"pct_access\",4,3)\n#plot_line_day(cat_eng,\"month\",\"engagement_index\",\"primary_function_main\",\"Dynamics of engagement_index of all products by primay function catagory\",\"Month\",\"engagement_index\",1200,1000)\n\nplot_line_day(cat_ac\u0441ess,\"day_of_week\",\"pct_access\",\"primary_function_main\",\"Dynamics of pct_access of all products by primary function catagory\",\"weekday\",\"pct_access\",4,3)\nplot_line_day(cat_eng,\"day_of_week\",\"engagement_index\",\"primary_function_main\",\"Dynamics of engagement_index of all products by primay function catagory\",\"weekday\",\"engagement_index\",1200,1000)\n\n#plot_line_day(cat_ac\u0441ess,\"month\",\"pct_access\",\"day_of_week\",\"Dynamics of pct_access of all products by day\",\"Month\",\"pct_access\",4,3)\n#plot_line_day(cat_eng,\"month\",\"engagement_index\",\"day_of_week\",\"Dynamics of engagement_index of all products by day\",\"Month\",\"engagement_index\",1200,1000)","6b2aae66":"plot_bar1(Data,'pct_access','primary_function_sub','Mean pct_access per sub primary function','Access','Sub-catagories')","7baf5274":"plot_bar1(Data,'engagement_index','primary_function_sub','Mean engagement_index per sub primary function','Engagement','Sub-catagories')","88f9c263":"Data_sub=Data.loc[(Data[\"primary_function_sub\"]==\"Learning Management Systems (LMS)\")]\npvd_ac\u0441ess = Data_sub.groupby(['Product Name','time']).agg({'pct_access': 'mean'}).sort_values(['pct_access'],ascending=False).reset_index()\npvd_eng = Data_sub.groupby(['Product Name', 'time']).agg({'engagement_index': 'mean'}).sort_values(['engagement_index'],ascending=False).reset_index()\n\nData_sub=Data.loc[(Data[\"primary_function_sub\"]==\"Virtual Classroom\")]\npvd1_ac\u0441ess = Data_sub.groupby(['Product Name','time']).agg({'pct_access': 'mean'}).sort_values(['pct_access'],ascending=False).reset_index()\npvd1_eng = Data_sub.groupby(['Product Name', 'time']).agg({'engagement_index': 'mean'}).sort_values(['engagement_index'],ascending=False).reset_index()\n\nData_sub=Data.loc[(Data[\"primary_function_sub\"]==\"School Management Software\")]\npvd2_ac\u0441ess = Data_sub.groupby(['Product Name','time']).agg({'pct_access': 'mean'}).sort_values(['pct_access'],ascending=False).reset_index()\npvd2_eng = Data_sub.groupby(['Product Name', 'time']).agg({'engagement_index': 'mean'}).sort_values(['engagement_index'],ascending=False).reset_index()\n\nfor i in [pvd_ac\u0441ess, pvd_eng, pvd1_ac\u0441ess, pvd1_eng, pvd2_ac\u0441ess, pvd2_eng]:\n    i['time'] = pd.to_datetime(i['time'], errors='coerce')\n    i['day_of_week'] = i['time'].dt.dayofweek\n    i['month'] = i['time'].dt.month\n    i = i[i.day_of_week < 5]\n","712454e1":"plot_line(pvd_ac\u0441ess,\"time\",\"pct_access\",\"Product Name\",\"Dynamics of pct_access of all products\",\"Month\",\"pct_access\",25,20)\nplot_line(pvd_eng,\"time\",\"engagement_index\",\"Product Name\",\"Dynamics of engagement_index of all products\",\"Month\",\"engagement_index\",15000,10000)","3e3a115f":"plot_line(pvd2_ac\u0441ess,\"time\",\"pct_access\",\"Product Name\",\"Dynamics of pct_access of all products\",\"Month\",\"pct_access\",14,10)\nplot_line(pvd2_eng,\"time\",\"engagement_index\",\"Product Name\",\"Dynamics of engagement_index of all products\",\"Month\",\"engagement_index\",1300,1000)","e6496648":"plot_line(pvd1_ac\u0441ess,\"time\",\"pct_access\",\"Product Name\",\"Dynamics of pct_access of all products\",\"Month\",\"pct_access\",16,10)\nplot_line(pvd1_eng,\"time\",\"engagement_index\",\"Product Name\",\"Dynamics of engagement_index of all products\",\"Month\",\"engagement_index\",6000,4000)","bfda10d1":"fig, ax = plt.subplots(1, 1, figsize=(7,5))\nsns.countplot(data=Data, \n              x='primary_function_main', \n              edgecolor=\"white\",\n              palette=\"viridis\")\nplt.title('Main Categories in Primary Functions')\n\nplt.show()\n\n\nfig, ax = plt.subplots(1, 3, figsize=(20,4))\nsns.countplot(data=Data[Data.primary_function_main == 'LC'], \n              x='primary_function_sub', \n              edgecolor=\"white\",\n              palette=\"viridis\", ax=ax[0])\nax[0].set_title('Sub-Categories in Primary Function LC')\nax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=90)\n\nsns.countplot(data=Data[Data.primary_function_main == 'CM'], \n              x='primary_function_sub', \n              edgecolor=\"white\",\n              palette=\"viridis\", ax=ax[1])\nax[1].set_title('Sub-Categories in Primary Function CM')\nax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=90)\n\nsns.countplot(data=Data[Data.primary_function_main == 'SDO'], \n              x='primary_function_sub', \n              edgecolor=\"white\",\n              palette=\"viridis\", ax=ax[2])\nax[2].set_title('Sub-Categories in Primary Function SDO')\nax[2].set_xticklabels(ax[2].get_xticklabels(), rotation=90)\nplt.show()","84e956e1":"# **Exploratory Data Analysis**\n\nThe analysis will be performed in the following order:\n* Product Data\n* District Data\n* Engagement Data.","b9dd95d3":"* Plotting below Mean engagement index and pct access per state.\n* We only make the plot for engagement with primary function as LC (Learning and curriculum).\n* LC is the primary function type where we expect mostly student engagement ","9ee3f17d":"### **Handling missing values for each dataframe**\nWhether we like it or not, real world data is messy. Data cleaning is a major part of every data science project and every dataset can possibly have missing values for multiple columns corresponding to a data entry. Before starting to analyse the data and draw conclusions, it is necessary to understand the presence of missing values in our dataset.\n\nWe notice values like **NaN** are present in several columns of our dataset. This represent the missing values. We have used **isnull().sum()** to summarize total number of missing values per column. \n\nNow we need to decide how do we wish to handle them $!$\n\n* **Remove rows with missing values:** The most elementary strategy is to remove all rows that contain missing values or, in extreme cases, entire columns that contain missing values.\n* **Imputing Missing Values in our Dataset:** Removing rows is a good option when missing values are small. But this is not always practical. We need to replace these NaNs with intelligent guesses.\nThere are many options to pick from when replacing a missing value:\n> * Replacing NaNs with a single constant value .\n> * Replacing NaNs with the value from the previous row or the next row (using ffill or bfill method).\n> * Replacing NaNs using Mean\/Median\/Mode of the column.\n> * Using the replace method.\n\nThe details of the missing data and how to deal with those values for each datasets are described below.","171b2999":"### Studying the engagement as function of school districts locale type \n(only for primary function type as LC)","9c874bd0":"* Google LLC is the top provider with a significantly large margin compared to other product providers. This is understandable because it provides a large number of leading products that encourage digital learning.","19a2b746":"**Missing values in districts data:**\n* There are 6 columns with missing values which are **\"state\"**, **\"locale\"**, **\"pct_black\/hispanic\"**, **\"county_connections_ratio\"**, **\"pct_free\/reduced\"** and **\"pp_total_raw\"** in order of increasing number of missing values\n* In this dataset we have a large fraction of missing values (27.1%) and dropping all the rows (39%) is not a good approach.\n* Steps:\n> * First, we can try to drop the rows for which a specific column (onw with minimum number of total missing values) has missing values. In this dataset we have **\"state\"**, **\"locale\"** and **\"pct_black\/hispanic\"** with same fraction of missing values (3.49%) and are fully correlated. We can drop any of these column. Let's say we dropped **\"locale\"**. Now see how many columns are left with missing values! ","574a697b":"**Conclusion:**\n> * Meet and Zoom are the two most prevalent software for online classes.\n> * Work from Home or Virtual schooling started at the beginning after WHO declared the pandemic.\n> * Summer break is during July and August, thus there are almost no activities.\n> * The noticeable increase in use of Zoom and Meet products after summer break due to the new wave of pandemic.\n> * There are a few drop points throughout the year. These might be the national holidays.\n\n","84d3db83":"* This distribution shows the number of districts in each locale. \n* Let's plot a pie chart for a better visualization.","4bbe5493":"### Conclusion\n* Arizona, North Dakota, New York and New Hampshire were the top 4 states in terms of mean engagement index.\n*  North Dakota,Arizona, New York and District of columbia were the top 4 states in terms of mean pct access.","5efd5c71":"### Let's study the engagement for specific products , so we will plot mean engagement and pct access for top10 most popular and least popular product names\n\n(only for LC product type)","d0356261":"* The data include a total of 233 school districts from across the US.\n* For the columns pct_black\/hispanic, pct_free\/reduced, county_connections ratio and pp_total_raw a range is provided","1b482b2b":"> * After dropping minimum number of missing values, we are left with 3 more columns which are \n  > > * pct_free\/reduced=2.27$\\%$\n  > > * county_connections_ratio=1.14$\\%$\n  > > * pp_total_raw= 4.71$\\%$\n  \n> * Now let's replace the **NaN** values of the column with **ffill** method.","6c3619b1":"## **Districts Data:**","bc57ce94":"### District information data\n\n>The district file ```districts_info.csv``` includes information about the **characteristics of school districts**, including data from \n>- NCES (2018-19), https:\/\/nces.ed.gov\/\n>- FCC (Dec 2018), and https:\/\/www.fcc.gov\/\n>- Edunomics Lab. https:\/\/edunomicslab.org\/\n\nSteps taken to preserve Privacy  \n* Identifiable information about the school districts has been removed. \n* An open source tool ARX (Prasser et al. 2020) was used to transform several data fields and reduce the risks of re-identification. \n\n**For data generalization purposes some data points are released with a range where the actual value falls under. Additionally, there are many missing data marked as 'NaN' indicating that the data was suppressed to maximize anonymization of the dataset.**\n\n| Name                   | Description                                                                                                                                                                                                                                                                              |\n|------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| district_id            | The unique identifier of the school district                                                                                                                                                                                                                                             |\n| state                  | The state where the district resides in                                                                                                                                                                                                                                                  |\n| locale                 | NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See Locale Boundaries User's Manual for more information.                                                                                                          |\n| pct_black\/hispanic     | Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data                                                                                                                                                                                       |\n| pct_free\/reduced       | Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data                                                                                                                                                                              |\n| countyconnectionsratio | ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version). See FCC data for more information.                                                                         |\n| pptotalraw             | Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district. |\n                                                         ","d4baddac":"**Primary Essential Function**","41acb86d":"**Learning Management Systems(LMS) Sub-catagory:**","840c9c3b":"To see the ones with very small statistics lets remake above plot with y axis in log scale","bb556a51":"****Q: How does student engagement with different types of education technology change over the course of the pandemic? ****\n\nTo answer this let's look at  three categories of primary function type main i.e\n* LC : Learning and curriculum\n* SDO : school and district operations\n* CM : classroom management","2f8279ac":"**Summary:**\n\nGeneral Insights through out 2020:\n\n**Engagement level of products:**\n> * There is a steady increase in engagement levels from January to March 2020. This is because even before COVID-19, there was already high growth and adoption in education technology.\n> * Issues such as prolonged closure, uncertainty about the timing of reopening, likely constriction in the academic calendar and the resultant learning discontinuity among students forced the states and educational institutions to find alternative options to assuage the varied impacts. This is where the digital\/online learning played a vital role.\n> * The engagement index had improved over the course of 2020, fall engagement index was higher than spring. This well understood because schools,institutions and even corporates started using online platforms for learning and working from home.\n> * The data clearly shows the sharp drop in engagement index durring summer holidays as expected\n\n> * There is more engagment at the begining of the week then it slowly drops as it gets to the weekend. Tuesday has the highest average engagment.\n\n\n* **By State:**\n> * top most access of products: North Dakota, Arizona, New York and Districts of Coulombia.\n> * top most engagement of products: Arizona, North Dakota, New York and New Hampshire.\n\n* **By Locale:**\n> * top most access of products: Rural, town, Suburb and City.\n> * top most engagement of products: Rural,town, Suburb and City.\n\n* **By Functionality:**\n> * top most access of products: SDO, CM, LC\/CM\/SDO and LC.\n> * top most engagement of products: SDO, CM, LC\/CM\/SDO and LC.\n\n**Accessed products:**\n> * Highest: Google Docs, Youtube and ccanvas.\n\n\n**Engaged products:**\n> * Highest: Google Docs, Youtube and ccanvas.","dc4b5653":"## Google is the leader here. No surprises !!","ca161ed3":"**Conclusion**\n* From the above histogram, we can see that majority of districts have engagement data for 366 days (2020) while some of them have data for less than 10 days.","17dca799":"* From all types of different learning tools, around 50% of the total products used by students are for **LC**. ","ff7be2f7":"*** Google Docs, You Tube and Canvas had the highest engagement index and pct access for LC function**","f6c14884":"### Conclusion\n* Engagement index for Primary function type SDO: School and district operations was significantly higher then other function type\n* Monthly pattern is similar for all primary function types: Fall 2020 engagement was higher than spring 2020\n* Drop in engagement during summer break as expected \n* For category LC , which is where students engagement is most showed a higher engagement during Fall 2020 compared to spring 2020.","23a09373":"**Engagement Data**","53e90d03":"**Group by state**","c71c8dbf":"**Group by Provider\/Company Name**","0f5c7caf":"* 'Sector' and 'Primary Essential Function' column have almost all missing values.\n* Lets check if the occurrence of missing values among these two columns is correlated.\n* For this we are using python library **missingno**","8047fd6f":"### Conclusion:\n* **Interesting !** , If communities are dominantly black\/hispanic i.e. if there percentage is greater than 50% or 60%, the trends are opposite to when its below 50 % for example\n* In free\/rreduced lunch vs % black and hispanic plot , there is positive trend until 50% black\/hispanic population and if it above 60% they no more need free\/reduced lunch.\n* Same is the trend for engagement index vs avg_pct_black\/hispanic plot , if the community is dominantly black then the engagement is much higher compared to when they are minority \n\n**Reasons for this , are above conlusions correct ???**","8300abe7":"Let's visualize the product names in the word cloud. The bigger and bolder the word appears, more is its frequency in top 352 products","7e9e1b35":"## List of tasks :\n* Analyze the state of digital learning in 2020\n* Relation of engagement in digital learning with district demographics (black, hispanic ...), broadband access, and \nstate\/national level policies and events.\n* What is the effect of the COVID-19 pandemic on online and distance learning, and how might this also evolve in the future?\n* How does student engagement with different types of education technology change over the course of the pandemic?\n* How does student engagement with online learning platforms relate to different geography? Demographic context (e.g., race\/ethnicity, ESL, learning disability)? Learning context? Socioeconomic status?\n* Do certain state interventions, practices or policies (e.g., stimulus, reopening, eviction moratorium) correlate with the increase or decrease online engagement?","7a3c4417":"# **Missing Data**","03c441ef":"* This distribution shows the number of school districts for each state.\n* In this dataset, <span style='color:red'> Connecticut <\/span> has the most number of school districts (17%) while <span style='color:blue'> Minnesota <\/span>\n,<span style='color:blue'> Arizona <\/span>,<span style='color:blue'> Florida <\/span> and <span style='color:blue'> North Dakota<\/span> has the least number of school districts (1%).\n","2355e06c":"* There are a total of 233 School Districts available within the data, all around USA. A school district is a geographical unit for the local administration of elementary or secondary schools in various nations.\n* There are a total of 372 distinct Educational Technology Products, such as tools like Meet, Zoom, Canva, educational apps like Duolingo, reading sites, or social pages like Instagram.\n* The data was collected between 01.01.2020 (a few months before Covid-19) until 31.12.2020. This will give a full year overview of a before the pandemic and after usage.\n* Engagement data was collected for all the districts with ~ 22.3M datapoints. ","cd9f2389":" **Preprocessing some of the columns in the districts datasets**\n * for the columns 'pct_black\/hispanic', 'pct_free\/reduced', 'county_connections_ratio' and 'pp_total_raw' we have a range of values, we will split them into two separate columns each with min and max values in the range ","afe34b83":"## Missing values in Products dataset","3faa0785":"# **Loading Libraries!**","d39aef69":"Above distributions could be significantly affected by the outliers. What we had in dataset was min and max and here we have plotted the average of two for all the above plots.  But we don't know the distribution between the ranges and hence any outlier can affect the above plots and the conclusions significantly.","92dd30f4":"**Missing values in engagement data:**\n* There are 3 columns with missing values which are **\"lp_id\"**, **\"pct_access\"** and **\"engagement_index\"**.\n* In this dataset we have around 4.83% fraction of missing values and we will follow the similar approach as we did in district data.\n* Steps:\n> * Firstly, we drop the column with minimum number of missing values which is **\"lp_id\"**. \n> * Secoundly, we will replace the **NaN** values in the remaining columns with it's mean value.\n","196e488c":"Since, the primary essential function column of the product dataset has two layers of labels here. Products are first labeled as one of these three categories: **LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations**. Each of these categories have multiple sub-categories with which the products were labeled. So, we will split this column into primary_function_main and primary_function_sub columns respectively to understand the distribution of products.","00797323":"### It will be better to make some summary tables and visualization to study the missing values","e439235f":"## Missing Values in District Dataset","b7bb7952":"In this study, we are going to do a data analysis to see about how the engagement with digital learning relates to factors like district demographics, broadband access, and state\/national level policies and events as a better understanding of digital learning trends. \n\n\nUsed dataset: [kaggle](https:\/\/www.kaggle.com\/c\/learnplatform-covid19-impact-on-digital-learning\/data)\n\n\n**If you like this EDA, then please upvote the notebook.**","e9073688":"## **Products Data:**","93d7a86f":"* There is a steady increase in engagement levels from January to April 2020. This might be due to stricter lockdowns thrroughout USA as we advanced forward in 2020.\n\n* The engagement index had improved over the course of 2020, with a significant dip in June and July before picking up again in August. \n\n* This might be due to the 12 weeks summer break in USA beginning between Mid May - Mid August. September was the month with the highest mean engagement index.\n\n* From August onwards, the level of engagement is seen to be going up and even higher than spring of 2020. This makes sense because schools,institutions and even corporates started using online platforms for learning and started working from home more consistently.","3779f4d8":"### Product information data\n> The product file ```products_info.csv``` includes information about the characteristics of the top 372 products with most users in 2020. The categories listed in this file are part of LearnPlatform's product taxonomy. \n\n**Some products may not have labels due to being duplicate, lack of accurate url or other reasons.**\n\n\n| Name                       | Description                                                                                                         |\n|----------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| LP ID                      | The unique identifier of the product                                                                                                                                                                                                                                                                                           |\n| URL                        | Web Link to the specific product                                                                                                                                                                                                                                                                                               |\n| Product Name               | Name of the specific product                                                                                                                                                                                                                                                                                                   |\n| Provider\/Company Name      | Name of the product provider                                                                                                                                                                                                                                                                                                   |\n| Sector(s)                  | Sector of education where the product is used                                                                                                                                                                                                                                                                                  |\n| Primary Essential Function | The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled |\n|                            |                                                                                                                                                                                ","fcd2b446":"# **Analysis**","30e2290c":"* Important part of analyzing a data, is to study the missing values.\n* Below cell defines a couple of function that will be used for missing values study","dc700ed3":"**Sectors Distribution**","b4f9c201":"**Summary for missing values in products data:**\n* There are 3 columns with missing values which are **\"Provider\/Company Name\"**, **\"Sector(s)\"** and **\"Primary Essential Function\"**.\n* In this dataset we have very small fraction of missing values (1.84%) \n* The missing values in **\"Sector(s)\"** and **\"Primary Essential Function\"**. columns are 100% correlated.\n* <span style=\"color:red\"> We can drop all the rows with Nan values.<\/span>","56633f2a":"# **Datasets**","f9b0ce8f":"**School Management Software Sub-catagory:**","55941aa3":"### Engagement data\n> The engagement data are aggregated at school district level, and each file in the folder ```engagement_data``` represents data from **one school district***. \n\n* The 4-digit file name represents ```district_id``` which can be used to link to district information in ```district_info.csv```. \n\n* The ```lp_id``` can be used to link to product information in ```product_info.csv```.\n\n| Name             | Description                                                                                                    |\n|------------------|----------------------------------------------------------------------------------------------------------------|\n| time             | date in \"YYYY-MM-DD\"                                                                                           |\n| lp_id            | The unique identifier of the product                                                                           |\n| pct_access       | Percentage of students in the district have at least one page-load event of a given product and on a given day |\n| engagement_index | Total page-load events per one thousand students of a given product and on a given day                         |","2b530a6c":"**Summary:**\n\nGeneral Insights:\n* Dataset contains most number of school districts for <span style='color:red'> Connecticut <\/span> state (17%).\n* <span style='color:red'>Suburbs<\/span> is the most common (59%) locale type for the districts in the dataset.\n* <span style='color:red'>Arizona <\/span> has the highest percentage of black\/hispanic students.\n* The percentage of students receiving free\/reduceed lunch is highest in <span style='color:red'>Minnesota<\/span>, and lowest in <span style='color:blue'>New Jersey<\/span>,<span style='color:blue'>Arizona<\/span>, <span style='color:blue'>North Dakota<\/span>.\n* The expenditure per student is highest in <span style='color:red'>New York<\/span> state and lowest in <span style='color:blue'>Florida<\/span>.\n* <span style='color:red'>North Dakota<\/span> and <span style='color:blue'>Massacheusetts<\/span> have a significantly higher connectivity ratio compared to other states. \n","1de63dd8":"We have dropped all the **Nan** values and our dataset is cleaned now. The data include a total of 176 school districts from across the US.\n","3405e1db":"* Total 59% of the districts are in the <span style='color:red'> suburbs <\/span> while the <span style='color:blue'> towns <\/span> have the least number of districts (5.68%).","467517bf":"### Conclusion:\n* The top three states with the highest number of black\/hispanic students are Arizona, District of Columbia,Texas. The least number of black\/hispanic students are in Wisconsin,Missouri,New Jersey,North Dakota, New Hampshire.\n* A high percentage of students in Minnesota, Indiana,Michigan are eligible to receive free or reduced lunch.\n* The top three states in average expenditure per student are in the following states: New York, District of Columbia and New Jersey while the lowest expenditure is in Florida and Utah.\n* North Dakota a significantly higher average speed of connection compared to the other states followed by Massachussets. The average speed of connection in all the other states is the same.\n","1450f528":"We have dropped all the **Nan** values and our dataset is cleaned now. ","3821d272":"* The largest count of students who identified themselves as Black or Hispanic are in locale type cities. The smallest count is in the town and rural areas.\n* The maximum and minimum percentage of students in the districts eligible for free or reduced-price lunch is the highest in the **town**, followed by city, suburb and rural.\n* The highest total expenses per student is in rural area.\n* The data for county connections ratio has similar range for all locales.","004aed59":"* The engagement with digital learning is higher for rural followed by town, suburb and then city \n* opposite of expected as cities are expected to have better infrastructure??\n* but the most money was spend in rural areas  ??","b37ef12f":"## Conclusion\n* Engagement Index has a positive correlation with avg_pp_total_raw (total expenditure per pupil). Make sense if the expenditure is aimed at increasing digital learning we expect the engagement to increase with expenditure.\n* There is a strong negative correlation between engagement index and avg_pct_free\/reduced i.e. as more people qualify for free\/reduced lunch in a school district the average index drops. Free\/reduced lunch qualification depends on poor economic status. So this might be due to poor people can't afford the infrastructure required for engagement in digital learning \n\n* avg students that indentify as black\/hispanic increases as the number of people qualifying for free lunch increases. This is probably due to black and hispanic communities being financial poor compared to other communities in USA. \n\n* We can also conclude that black\/hispanic communities also have lower engagement index","31f925e6":"* Top three catagories are **Digital learning platforms**, **Site, Resources and References** and **Content creation and curation**.\n* The LC (learning curriculum) category has the highest percentage of products.","f8a4c7d5":"* PreK-12 Sector use highest number of products (54%) followed by Higher Ed sector (28%).","c9722d94":"## **Combined Data**\n* combining the three datasets, product data , district data and engagement data ","082560cf":"* **As we saw from the output of cell 45, and above heat map if there is a missing value in 'Primary Essential Function column' then there is also a missing value in the Sector column**","2ecd3dfa":"Let's analyse top 3 sub-catagories of primary function and remove weekends as well from the dataset as there are no classes on weekends to avoid confusions.","b6cfe354":"## **Engagement Data:**","7199ca26":"**Conclusion:**\n> * Classlink and Clever are the two most used softwares for school management.","cde49f32":"#### We have dropped all the **Nan** values and our dataset is cleaned now. There are 352 distinct educational technology products.","b23d0780":"**Virtual Classroom Sub-catagoy:**","24ac3de6":"**Conclusion:**\n> * Most of the schools use Google Classroom for digital learning during the pandemic. ","ce17dd38":"* Amongst the different learning tools, Learning & Curriculum (LC) had achieved the highest adoption. \n\n* **\"Sites, Resources and Reference\"** and **\"Digital Learning Platform\"** take the top spots in the list of primary essential sub-category.","16d4de64":"**Group by locale**"}}