{"cell_type":{"d4f65175":"code","a64907e9":"code","d422e7dd":"code","248a04de":"code","7377753f":"code","728da748":"code","48b702cd":"code","30b50c2f":"code","8d3b9bb3":"code","37c08d59":"code","f04a1ae2":"code","58007473":"code","eb06794f":"code","691d99c1":"code","bb8e6900":"code","68d82044":"code","2b3dd6c9":"code","c0df8d4f":"code","0408f62c":"code","6a697ec9":"code","f8615019":"code","a6408add":"code","81a914d4":"markdown","4d493ba1":"markdown","8c339a1b":"markdown","74b910f3":"markdown","b59e8e6f":"markdown","57528fca":"markdown","dd75d1f6":"markdown","2780de4e":"markdown","d683d50d":"markdown","a81c94f9":"markdown","d8c7940b":"markdown","7e099b9d":"markdown","15e37e9e":"markdown","39740af7":"markdown","ba0b2248":"markdown","0cd4a035":"markdown","31590a86":"markdown"},"source":{"d4f65175":"import skimage.io \nimport skimage.segmentation","a64907e9":"print(\"Image to be read\")\nXi = skimage.io.imread(\"https:\/\/www.data-imaginist.com\/assets\/images\/kitten.jpg\") #link for image to be read\nXi = skimage.transform.resize(Xi, (299,299)) # resizing image\nskimage.io.imshow(Xi)# Show image \nXi = (Xi - 0.5)*2 #Inception pre-processing of image","d422e7dd":"import keras","248a04de":"inceptionV3_model = keras.applications.inception_v3.InceptionV3() #Load pretrained model","7377753f":"import numpy as np\nfrom keras.applications.imagenet_utils import decode_predictions","728da748":"print(\"The top 5 classes of predictions are - \")\npreds = inceptionV3_model.predict(Xi[np.newaxis,:,:,:]) #np.newaxis is used to increase the dimension of the existing array by one. Here,Input should be 4D\nprint(decode_predictions(preds)) #top = 5 by default","48b702cd":"preds.shape","30b50c2f":"top_pred_classes = preds[0].argsort()[-5:][::-1]\nprint(\"The indices of the top 5 classes \")\ntop_pred_classes               ","8d3b9bb3":"superpixels = skimage.segmentation.quickshift(Xi, kernel_size=4,max_dist=200, ratio=0.2) #the higher the kernel size,max_dist, the fewer are the clusters\n#Segments image using quickshift clustering\nnum_superpixels = np.unique(superpixels).shape[0]\nprint(\"The number of super pixels generated\")\nnum_superpixels","37c08d59":"skimage.io.imshow(skimage.segmentation.mark_boundaries(Xi\/2+0.5, superpixels))","f04a1ae2":"np.random.seed(222)\nnum_perturb = 150 \n#150 perturbations\nperturbations = np.random.binomial(1, 0.5, size=(num_perturb, num_superpixels))# The size corresponds to the (no. of perturbations x no. of superpixels) in the image.\nprint(\" Here, '1' represent ON(active) superpixel and '0' represents OFF.\")\nperturbations[0]","58007473":"import copy","eb06794f":"def perturb_image(img,perturbation,segments): #takes in the parameters : raw image, perturbation vector and superpixels generated\n  active_pixels = np.where(perturbation == 1)[0]\n  mask = np.zeros(segments.shape)\n  for active in active_pixels:\n      mask[segments == active] = 1 \n  perturbed_image = copy.deepcopy(img)\n  perturbed_image = perturbed_image*mask[:,:,np.newaxis]\n  return perturbed_image #returns the perturbed image","691d99c1":"print(\"The perturbed image\")\nskimage.io.imshow(perturb_image(Xi\/2+0.5,perturbations[0],superpixels)) ","bb8e6900":"predictions = []\nfor pert in perturbations:\n  perturbed_img = perturb_image(Xi,pert,superpixels)\n  pred = inceptionV3_model.predict(perturbed_img[np.newaxis,:,:,:])\n  predictions.append(pred)\n\npredictions = np.array(predictions)","68d82044":"import sklearn.metrics","2b3dd6c9":"original_image = np.ones(num_superpixels)[np.newaxis,:] #Perturbation with all superpixels enabled \n#The distance between each randomly generated perturnation and the image being explained is computed using the cosine distance. \ndistances = sklearn.metrics.pairwise_distances(perturbations,original_image, metric='cosine').ravel()#ravel() function is used to create a contiguous flattened array.\n#distances","c0df8d4f":"kernel_width = 0.25\nweights = np.sqrt(np.exp(-(distances**2)\/kernel_width**2)) #Kernel function\nweights.shape","0408f62c":"from sklearn.linear_model import LinearRegression","6a697ec9":"simpler_model = LinearRegression()\nsimpler_model.fit(X=perturbations, y=predictions[:,:,top_pred_classes[0]], sample_weight=weights) # the top predicted class is to be explained\ncoeff = simpler_model.coef_[0] \ncoeff.shape # Each coefficient in the linear model corresponds to one superpixel in the segmented image.","f8615019":"num_top_features = 4\ntop_features = np.argsort(coeff)[-num_top_features:] \n#Now we need to sort the coefficients to figure out which are the superpixels that have larger coefficients (magnitude) for the prediction of egyptian cat. \ntop_features","a6408add":"mask = np.zeros(num_superpixels) #The less relevant pixels are black and only the top superpixels are activated.\nmask[top_features]= True \nskimage.io.imshow(perturb_image(Xi\/2+0.5,mask,superpixels) )","81a914d4":"## LIME ON IMAGE","4d493ba1":"Step 8 - Compute weights (importance) of each perturbed image using kernel.\nThe distances are then mapped to a value between zero and one (weight). ","8c339a1b":"Step 7 - Compute distances between the original image and each of the perturbed images.","74b910f3":"Step 5 - Random perturbations","b59e8e6f":"The superpixels of the top 4 features are shown.","57528fca":"The description of these classes is shown and it can be seen that the \"Egyptian cat\" is the top class for the given image with the max probability of 0.465.","dd75d1f6":"Step 9 - Use 'perturbations', 'predictions' and 'weights' to fit an explainable (linear) model","2780de4e":"Step 2 - InceptionV3 initialization\n\nThe pre-trained InceptionV3 model is available in Keras, which is a widely-used image recognition model and has been shown to have more than 78.1% accuracy on the ImageNet dataset.","d683d50d":"Conclusion -\n\nThis is the area of the image that produced the prediction of Egyptian cat. ","a81c94f9":"The generated superpixels are shown in the image below using mark_boundaries.","d8c7940b":"Step 1 - Read and pre-process image\nThe image is resized, displayed and pre-processed for Inception V3. The variable 'Xi' contains the image. ","7e099b9d":"The predicted output(preds) is a vector of 1000 proabilities for each class available in Inception V3. ","15e37e9e":"Step 3 - Predict class of input image using Inception V3 model.","39740af7":"Step 6 - Predict classes of new generated images ","ba0b2248":"Step 10 - Compute top features (superpixels)","0cd4a035":"Last Step - Show image with top features","31590a86":"Step 4 - Extract super-pixels from image"}}