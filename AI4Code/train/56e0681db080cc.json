{"cell_type":{"6416d7b8":"code","eb15e0a3":"code","1dc2c0fc":"code","2b1412b5":"code","260302d8":"code","ceb8bc5e":"code","2b0b61b4":"code","8af5652b":"code","f2000ba9":"code","ee19c1e2":"code","b5bb5516":"markdown","89e6a978":"markdown","7244247e":"markdown","94ef2a82":"markdown","ea5e11a0":"markdown","1f7b3169":"markdown"},"source":{"6416d7b8":"import numpy as np\nfrom numpy import asarray\nimport pandas as pd\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam","eb15e0a3":"path = '..\/input\/california-housing-prices\/housing.csv'\ndf = pd.read_csv(path)\ndf = shuffle(df)\nvalues = df.values\ndf.head()","1dc2c0fc":"# replace ocean proximity with values\nocean_proximity = {v:k for k,v in enumerate(df['ocean_proximity'].unique())}\ndf.replace(ocean_proximity, inplace=True)\n\n# replace NaN with mean\ndf = df.apply(lambda x: x.fillna(x.mean()))\n\nfeatures = df.drop(columns=['median_house_value'])\nlabels = df['median_house_value']","2b1412b5":"houses_mean = labels.mean()\nhouses_std = labels.std()\n\n# normalize prices\nlabels = (labels - houses_mean) \/ houses_std","260302d8":"# normalize the features\nscaler = MinMaxScaler()\nscaler.fit(features)\nfeatures = scaler.transform(features)","ceb8bc5e":"X_train, X_test, y_train, y_test = train_test_split(features, labels, train_size=0.67)","2b0b61b4":"def fit_model(X_train, y_train):\n    # define neural network model\n    features = X_train.shape[1]\n    model = Sequential()\n    model.add(Dense(20, kernel_initializer='he_normal', activation='relu', input_dim=features))\n    model.add(Dense(5, kernel_initializer='he_normal', activation='relu'))\n    model.add(Dense(1))\n    # compile the model and specify loss and optimizer\n    opt = Adam(learning_rate=0.01, beta_1=0.85, beta_2=0.999)\n    model.compile(optimizer=opt, loss='mse')\n    # fit the model on the training dataset\n    model.fit(X_train, y_train, verbose=0, epochs=300, batch_size=16)\n    return model","8af5652b":"def fit_ensemble(n_members, X_train, X_test, y_train, y_test):\n    ensemble = list()\n    for i in range(n_members):\n        # define and fit the model on the training set\n        model = fit_model(X_train, y_train)\n        # evaluate model on the test set\n        yhat = model.predict(X_test, verbose=0)\n        mae = mean_absolute_error(y_test, yhat)\n        print('>%d, MAE: %.3f' % (i+1, mae))\n        # store the model\n        ensemble.append(model)\n    return ensemble","f2000ba9":"def predict_with_pi(ensemble, X):\n    # make predictions\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\n    yhat = asarray(yhat)\n    # calculate 95% gaussian prediction interval\n    interval = 1.96 * yhat.std()\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\n    return lower, yhat.mean(), upper","ee19c1e2":"# fit ensemble\nn_members = 10\nensemble = fit_ensemble(n_members, X_train, X_test, y_train, y_test)\n# make predictions with prediction interval\nnewX = asarray([X_test[0, :]])\nlower, mean, upper = predict_with_pi(ensemble, newX)\nprint('Point prediction: %.3f' % mean)\nprint('95%% prediction interval: [%.3f, %.3f]' % (lower, upper))\nprint('Actual result:', y_test.iloc[0])","b5bb5516":"<h1 id=\"model\" style=\"color:#2a200b; background:#fcc688;\"> \n    <center>Model\n        <a class=\"anchor-link\" href=\"#model\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","89e6a978":"<h1 id=\"predict\" style=\"color:#2a200b; background:#fcc688;\"> \n    <center>Interval Predictions\n        <a class=\"anchor-link\" href=\"#predict\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","7244247e":"<div>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/5227\/7876\/3d18388d350d2791f4121a232acce097\/dataset-cover.jpg\" \/>\n<\/div>","94ef2a82":"<h1 id=\"dataset\" style=\"color:#2a200b; background:#fcc688;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","ea5e11a0":"<h1 id=\"ensemble\" style=\"color:#2a200b; background:#fcc688;\"> \n    <center>Ensemble\n        <a class=\"anchor-link\" href=\"#ensemble\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","1f7b3169":"<h1 id=\"training\" style=\"color:#2a200b; background:#fcc688;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#training\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>"}}