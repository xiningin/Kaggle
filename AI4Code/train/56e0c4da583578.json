{"cell_type":{"179656ed":"code","ae9161c2":"code","32f50e36":"code","4eaa8bf3":"code","cad171f2":"code","d0beb3db":"code","380c1c9e":"code","61bfbac1":"code","637b5355":"code","7d586a9e":"code","9172f7b2":"code","9caa6731":"code","145ed616":"code","53d2ae28":"code","d98404b8":"code","12c8af16":"code","39b11bb1":"code","f4e614bf":"code","f923c1d6":"code","6af5a415":"markdown","f5d03db9":"markdown","b22a0791":"markdown","55bd1e7e":"markdown","d2a76f55":"markdown","8f669c38":"markdown","ff8c9d3e":"markdown","55e70e58":"markdown","c5f6d445":"markdown","7c363933":"markdown","a147e5bc":"markdown","ddd6847c":"markdown","83026fad":"markdown","dceb0afc":"markdown","52d45c20":"markdown","d23d6c80":"markdown","466ecaba":"markdown"},"source":{"179656ed":"#required imports\n\nimport json\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pymc3 as pm\nimport scipy\nimport scipy.stats as stats\nimport statsmodels.api as sm\nimport theano.tensor as tt\nimport seaborn as sns\nfrom datetime import datetime\n\n## Get the data:\npd.core.common.is_list_like = pd.api.types.is_list_like # resolves datareader error\nfrom pandas_datareader import data\nfrom IPython.display import Image\nfrom datetime import datetime\n%matplotlib inline","ae9161c2":"\n# if you wish to use attached 'data.csv' uncomment the line below\ndata = pd.read_csv('..\/input\/stock-return-analysis\/assignment5data.csv')\n\nreturns=data['Adj. Close'].pct_change()\n\nreturns = returns.dropna()*100","32f50e36":"returns.head()","4eaa8bf3":"returns.describe()","cad171f2":"returns.plot(figsize=(10,10),title='Apple Adjusted Closing Price')","d0beb3db":"returns.hist(color = \"red\", edgecolor = \"white\")\nplt.xlabel('Return'); plt.ylabel('Count');\nplt.title('Distribution of Return');","380c1c9e":"with pm.Model() as model_n:\n    #Prior\n    \n\n    mu = pm.Uniform(\"mu\", lower=-10, upper=10, testval=0)\n    sigma = pm.Uniform(\"sigma\", lower=0, upper=6, testval=0.0001)\n    \n    #Likelihood\n    likelihood = pm.Normal(\"likelihood\", mu=mu, sd=sigma, observed = returns.values)\n    \n    #Posterior\n    start = pm.find_MAP()\n    step  = pm.Metropolis()\n    trace = pm.sample(10000, chains=3, step=step, start=start, progressbar=True)\n    burned_trace = trace[3000::]","61bfbac1":"pm.autocorrplot(trace)","637b5355":"pm.traceplot(burned_trace)","7d586a9e":"pm.plot_posterior(burned_trace)","9172f7b2":"with pm.Model() as model_g:\n    mu1 = pm.Uniform(\"mu1\", lower=-8, upper=7, testval=0)\n    sigma1 = pm.HalfNormal(\"sigma1\", sigma =1.5)\n    \n    #Likelihood\n    likelihood1 = pm.Normal(\"likelihood1\", mu=mu1, sd=sigma1, observed = returns.values)\n    \n    #Posterior\n    start = pm.find_MAP()\n    step  = pm.Metropolis()\n    trace_1 = pm.sample(20000, chains=3, step=step, start=start, progressbar=True)\n    burned_trace1 = trace_1[3000::20]","9caa6731":"pm.traceplot(burned_trace1)","145ed616":"pm.summary(burned_trace1)","53d2ae28":"pm.autocorrplot(trace_1)","d98404b8":"pm.autocorrplot(burned_trace1)","12c8af16":"pm.plot_posterior(burned_trace1)","39b11bb1":"pm.plot_joint(burned_trace1, kind='kde', fill_last=False);","f4e614bf":"ppc = pm.sample_posterior_predictive(burned_trace1, samples=500, model=model_g)\nnp.asarray(ppc['likelihood1']).shape","f923c1d6":"_, ax = plt.subplots(figsize=(12.5, 15))\n\nax = plt.subplot(312)\nax.hist([y.mean() for y in ppc['likelihood1']], histtype='stepfilled', \n        label=\"posterior predictive of mean\", color=\"#A60628\")\nax.axvline(returns.values.mean(), linestyle=\"--\", label=\"true mean\")\nax.legend(loc=\"upper right\")\nax.set(title='Posterior predictive of the mean', xlabel='mean(x)', ylabel='Frequency');\n\nax = plt.subplot(313)\nax.hist(returns, color=\"#7A68A6\")\nax.axvline(returns.values.mean(), linestyle=\"--\", label= \"true mean\", color= \"black\")\nax.set(title='Original Distribution of Return', xlabel='Return', ylabel='Count');","6af5a415":"\n### 1. In the above code, our model is implemented with :\n#### For prior:\n#### a. Uniform distribution for mu.\n#### b. Half Normal distribution for sigma.\n\n#### For Likelihood: The Normal distribution is used.\n\n\n### 2. The step specifies what sampling method is used for guidance towards the most likely parameter values. Here we have used METROPOLIS.\n\n### 3. The PyMC3 function sample() gathers the samples (20,000 samples in this case) by traversing over the areas of the most likely parameter values. There were 503 samples in original data.\n\n### 4. We have also used autocorrelation to look at the lags = 20 and we used them  in our burned_trace as (3000::20)  to make our model look more smooth.\n","f5d03db9":"#### As a validation check of model performance, predicting the distribution of daily returns from the obtained posterior distributions. \n\n#### Presenting results of predicted distribution graphically as a histogram.","b22a0791":"- Bayesian analysis for stock return data\n- Build models for different distributions of data\n- Compare models","55bd1e7e":"Required imports for this project are given below.  Make sure you have all libraries required for this project installed.  You may use _conda_ or _pip_ based on your set up.\n","d2a76f55":"In the cell below, the model for daily return simulations is shown. Since the daily returns histogram shows bell-shaped distribution, the normal distribution is used for likelihood computation.\n\nThis model uses un-informative priors - Uniform distribution for both parameters of the notmal distribution (\"mu\" and 'sigma\").","8f669c38":"We will use the Baysesian approach for analysis of stock return data.\nIn particular, we will model the data as a normal distribution and will estimate distribution parameters using Markov chain Monte Carlo technique (MCMC).\n","ff8c9d3e":"#### Improve the model for daily returns given above.\n\nChoose different prior distributions for parameters of the likelihood distribution - Mean $\\mu$ and Standard Deviation $\\sigma$.\n\nTo tune the model, trying  several different distributions with various spread\/dispersion values (for example, Uniform, Normal, HalfNormal) for priors, and different numbers of samples.\nBy inspecting posterior distribution of parameters, picking the value that produces the smoothest, most convergent chains. \n\n#### Presenting posterior distribution graphically. ","55e70e58":"## Bayesian statistics to carry out Stock return analysis.","c5f6d445":"### We can compare the two graphs showing us the original distribution and the posterior predictive mean. Both of them are showing us similar results and there is no significant deviation.","7c363933":"### 1. For mu - we got 94% HDI in the range -0.097 to 0.17 with mean = 0.033\n### 2. For sigma - we got 94% HDI in the range 1.5 to 1.7 with mean = 1.6\n\n### We took 20000 samples with (3000::20) for burned_trace to reach this conclusion.\n\n### Here we can interpret as such that there is 94% probability the belief is between -0.097 and 0.17 for the mean return value. 94% probability the belief is between 1.5 and 1.7 for the sigma return value.","a147e5bc":"### Here we can interpret as such that there is 94% probability the belief is between -0.097 and 0.17 for the mean return value. 94% probability the belief is between 1.5 and 1.7 for the sigma return value.","ddd6847c":"\n\n####  Plot the returns to see the distribution\n","83026fad":"## Learning outcomes","dceb0afc":"### We can also see the values which we got for mean and standard deviation:\n\n### 1. Mean:\n#### Original mean = 0.031662\n#### Estimated mean = 0.033\n\n### 2. Standard Deviation:\n#### Original Std. = 1.579874\n#### Estimated Std. = 1.6\n\n## These values are very close to each other so there  is no significant deviation in the data.","52d45c20":"### We can see that the data generated when predicting daily returns from posterior distribution is similar to the true distribution.\n### It is visually been observed looking at the histograms we got and they look very smilar to each other.\n","d23d6c80":"### The inferred mean is very close to the actual price mean.","466ecaba":"The code and values which were provided:"}}