{"cell_type":{"00447827":"code","9123d516":"code","4ed81e02":"code","c3436ca0":"code","999fcd57":"code","e2596496":"markdown","f90155aa":"markdown","9f7176d1":"markdown","7013927c":"markdown","8edca3a3":"markdown","245a303c":"markdown","c3e8fa37":"markdown","7d83b034":"markdown","e01281c0":"markdown","6910fdb7":"markdown","14be539a":"markdown","bae8fb88":"markdown","1f430269":"markdown","84bcf8af":"markdown","14095b73":"markdown","46566831":"markdown","a049451e":"markdown","8d374036":"markdown","26049d3f":"markdown","95e24cbe":"markdown","40a9234e":"markdown","a93e5f4c":"markdown","f1d1ac62":"markdown","95e0c8cb":"markdown","7ded8305":"markdown","077c4e28":"markdown","2f895b7b":"markdown"},"source":{"00447827":"import numpy as np\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\nfrom keras.datasets import mnist\nimport matplotlib.pyplot as plt","9123d516":"encoding_dim = 32\ninput_img = Input(shape=(784,))\nencoded = Dense(encoding_dim, activation='relu')(input_img)\ndecoded = Dense(784, activation='sigmoid')(encoded)\nautoencoder = Model(input_img, decoded)\nencoder = Model(input_img, encoded)\nencoded_input = Input(shape=(encoding_dim,))\ndecoder_layer = autoencoder.layers[-1]\ndecoder = Model(encoded_input, decoder_layer(encoded_input))\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n","4ed81e02":"(x_train, _), (x_test, _) = mnist.load_data()\nx_train = x_train.astype('float32') \/ 255.\nx_test = x_test.astype('float32') \/ 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\nprint(x_train.shape) \nprint(x_test.shape) ","c3436ca0":"autoencoder.fit(x_train, x_train,\nepochs=50,\nbatch_size=256,\nshuffle=True,\nvalidation_data=(x_test, x_test))\n# encode and decode some digits\n# note that we take them from the *test* set\nencoded_imgs = encoder.predict(x_test)\ndecoded_imgs = decoder.predict(encoded_imgs)","999fcd57":"n = 20 # how many digits we will display\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n# display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n# display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","e2596496":"**4. Architecture of Autoencoders**","f90155aa":"First, the network compresses image into latent space representation using the Encoder, then the network searches to decode this representation of input called \u201cCode\u201d using Decoder in the end. \n\nThe layer between the Encoder and Decoder: \u201cCode\u201d is also known as \u201cbottleneck.\u201d\n\n\n![image.png](attachment:image.png)\n","9f7176d1":"After introducing our model, let\u2019s talk about the different proprieties and hyperparameters involved during training AE.","7013927c":"**Image Coloring :** any black and white image can be revived with colors using Autoencoders.\n\n\n![image.png](attachment:image.png)","8edca3a3":"**Preparing the input data (MNIST Dataset) :**","245a303c":"After that explanation, let\u2019s see some different applications of the Autoencoders : \n\n\n","c3e8fa37":"        1. Properties of Autoencoders:\n            \n            1. Data: the Autoencoders are used to reconstruct the same data in the input.\n            \n            2. Lossy: The constructed outputs will degraded compared to original inputs. \n            \n            3. Automatic learning from example: it\u2019s easy to specialize learning with AE. \n            \n            \n        \n        ","7d83b034":"Declaration of Hidden Layers and Variables : ","e01281c0":"**Dimensionality reduction:**  the reconstructed image in output is the same image of the input but with reduced pixel values.\n\n![image.png](attachment:image.png)","6910fdb7":"As we said, the Autoencoders(AE) are used to reduce the size of our inputs, but why we use them even if we already have algorithms such as principal component analysis (PCA)?   \nFirst, AE is preferred over PCA because that AE can learn no-linear transformation quickly with a non-linear activation function and multiples layers.\n\n![image.png](attachment:image.png)","14be539a":"![image.png](attachment:image.png)\n","bae8fb88":"        2.Hyperparameters of Autoencoders:\n        \n        There are four hyperparameters for Autoencoder :\n        \n            - Code size \n            - Number of layers \n            - Number of nodes per layers \n            - Loss function \n\n        ","1f430269":"  ****Applied Deep Learning : Autoencoders****","84bcf8af":"**6. Types of Autoencoders**","14095b73":"First, we import all the libraries in need:","46566831":"1. Convolution Autoencoders\n2. Sparse Autoencoders\n3. Deep Autoencoders\n4. Contractive Autoencoders","a049451e":"6. **Application : **","8d374036":"1. **What are Autoencoders?**\n\nAn autoencoder **Neural network** is an **Unsupervised Machine learning Algorithm** that applies** Backpropagation**, setting the target values to be equal to the inputs. Autoencoders are used to reduce the size of our inputs into a smaller representation. If anyone needs the original data, they can reconstruct it from the compressed data.","26049d3f":"**Visualizing the reconstructed inputs and the encoded representations using Matplotlib :**","95e24cbe":"An AE consists of three layers :  \n\n        1.\tEncoder \n        2.\tCode (hidden layers ) \n        3.\tDecoder \n","40a9234e":"![image.png](attachment:image.png)","a93e5f4c":"Technically, the AE can use a convolutional layer to learn it is more efficient then learn massive transformation with PCA.\nAlso, we can use a pre-trained layer from a different model to apply the transfer learning with encoder\/ decoder architecture.  \n","f1d1ac62":"3. **Applications of Autoencoders :**","95e0c8cb":"**Training Autoencoders for 50 epochs :**","7ded8305":"**5. Properties and Hyperparameters**","077c4e28":"**Denoising Image:**  the AE can denoise the image corrupted in input to the original image in the output.\n\n![image.png](attachment:image.png)","2f895b7b":"**2. The need for Autoencoders :**"}}