{"cell_type":{"2880df2f":"code","304a320a":"code","3c804aa4":"code","7898893f":"code","ce277e43":"code","a4971a59":"code","1a365b18":"code","93eaa803":"code","53639a2a":"code","c1db64d6":"code","d20f5c06":"code","314943de":"code","92af452a":"code","2a4223e9":"code","6bdf7127":"code","d660010a":"code","acd2a52b":"code","dc53bb9c":"code","7f15ed22":"code","d5583ef4":"code","7a7fd388":"code","c7ce73a4":"code","ae5a5858":"code","d19c87a7":"code","2aa08075":"code","1bb7a3c5":"code","fda4aa81":"code","f02388e2":"code","208e14d4":"code","802e4c66":"code","21b19d15":"code","1a8de92e":"code","1169fcfe":"code","a951fafe":"code","8d3b812b":"code","2a9c5ce9":"code","016f6dd8":"code","2f2bbf78":"markdown","3cf7d14a":"markdown","fd026fb8":"markdown","2b6cb8da":"markdown","b0c89b76":"markdown"},"source":{"2880df2f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","304a320a":"import warnings\nimport numpy as np\nimport pandas as pd\nimport copy\nfrom pathlib import Path\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf\nfrom tensorflow.keras.layers import LSTM, Dropout, Dense\nfrom tensorflow.keras import optimizers, Sequential, Model\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","3c804aa4":"train=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nitem_cat=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nitems=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nss=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\nshops=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ntest=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')","7898893f":"train.head()","ce277e43":"items.head()","a4971a59":"ss.head()","1a365b18":"test.tail()           ","93eaa803":"print(test.ID.nunique())\nprint(test.shape)","53639a2a":"test.info()","c1db64d6":"print(train.item_id.nunique())\nprint(train.shop_id.nunique())\ntrain.head()","d20f5c06":"train.shape","314943de":"import seaborn as sns\nsns.heatmap(train.isnull())","92af452a":"print(test[~test.item_id.isin(train.item_id)].shape)\nprint(test[~test.shop_id.isin(train.shop_id)].shape)\nprint(test.ID.nunique())\nprint(test.shop_id.nunique())\nprint(test.item_id.nunique())\ntest.head()","2a4223e9":"print(items.item_id.nunique())\nprint(items.item_category_id.nunique())\nprint(test[~test.item_id.isin(items.item_id)].shape)\nitems.head()","6bdf7127":"print(train[~train.item_id.isin(items.item_id)]['item_id'].nunique())\nprint(test[~test.item_id.isin(train.item_id)]['item_id'].nunique())","d660010a":"train = train[train['shop_id'].isin(test['shop_id'])]\ntrain = train[train['item_id'].isin(test['item_id'].unique())]","acd2a52b":"train_data=pd.merge(train,items,on='item_id',how='inner')\ntrain_data.drop('item_name',axis=1,inplace=True)\ntrain_data.head()","dc53bb9c":"train_data['item_cnt_month']=train_data.groupby(['shop_id','item_id','date_block_num'])['item_cnt_day'].transform('sum')\ntrain_data['monthly_sales']=train_data.groupby('date_block_num')['item_cnt_day'].transform('sum')\ntrain_data.head()","7f15ed22":"sns.lineplot(x='date_block_num', y='monthly_sales', data=train_data)","d5583ef4":"print(train_data['item_cnt_month'].min())\nprint(train_data['item_cnt_month'].max())\nprint(train_data['item_cnt_month'].mean())\nprint(train_data['item_cnt_month'].median())","7a7fd388":"train_data=train_data[(train_data.item_cnt_month>=0) & (train_data.item_cnt_month<=15)]","c7ce73a4":"print(train_data['item_cnt_month'].min())\nprint(train_data['item_cnt_month'].max())\nprint(train_data['item_cnt_month'].mean())\nprint(train_data['item_cnt_month'].median())","ae5a5858":"mat= train_data.pivot_table(index=['shop_id', 'item_id'], columns='date_block_num',values='item_cnt_month', fill_value=0).reset_index()\nmat.head()","d19c87a7":"first = 20\nlast = 33\nsub_series = 12\nl = []\n\nfor index, row in mat.iterrows():\n    for i in range((last - (first + sub_series)) + 1):\n        x = [row['shop_id'], row['item_id']]\n        for j in range(sub_series + 1):\n            x.append(row[i + first + j])\n        l.append(x)\n\ncolumns = ['shop_id', 'item_id']\n[columns.append(i) for i in range(sub_series)]\ncolumns.append('label')\n\nmat1 = pd.DataFrame(l, columns=columns)\nmat1.head()","2aa08075":"mat1[(mat1['shop_id']==2) & (mat1['item_id']==31)]","1bb7a3c5":"y = mat1['label']\nmat1.drop(['label','shop_id','item_id'], axis=1, inplace=True)","fda4aa81":"X_train, X_valid, y_train, y_valid = train_test_split(mat1, y.values, test_size=0.1, random_state=0)","f02388e2":"print(X_train.shape)\nprint(X_valid.shape)","208e14d4":"# from sklearn.preprocessing import StandardScaler\n# scale=StandardScaler()\n# X_train=scale.fit_transform(X_train)\n# X_valid=scale.transform(X_valid)","802e4c66":"X_train1 = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\nX_valid1 = X_valid.values.reshape((X_valid.shape[0], X_valid.shape[1], 1))","21b19d15":"lstm_model = Sequential()\nlstm_model.add(LSTM(X_train1.shape[1], input_shape=(X_train1.shape[1], X_train1.shape[2]), return_sequences=True))\nlstm_model.add(LSTM(6, activation='relu', return_sequences=True))\nlstm_model.add(LSTM(1, activation='relu'))\nlstm_model.add(Dense(10, kernel_initializer='glorot_normal', activation='relu'))\nlstm_model.add(Dense(10, kernel_initializer='glorot_normal', activation='relu'))\nlstm_model.add(Dense(1))\nlstm_model.summary()\n\nadam = optimizers.Adam(0.0001)\nlstm_model.compile(loss='mse', optimizer=adam)","1a8de92e":"lstm_model.fit(X_train1, y_train, validation_data=(X_valid1, y_valid), batch_size=128, epochs=10, verbose=1)","1169fcfe":"from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score, r2_score\npreds=lstm_model.predict(X_valid1)\nprint('MAE',mean_absolute_error(y_valid, preds))\nprint('MSE',mean_squared_error(y_valid, preds))","a951fafe":"final = mat.drop_duplicates(subset=['shop_id', 'item_id'])\nX_test = pd.merge(test, final, on=['shop_id', 'item_id'], how='left', suffixes=['', '_'])\nX_test.fillna(0, inplace=True)\nX_test.drop(['ID', 'item_id', 'shop_id'], axis=1, inplace=True)\nX_test = X_test[[(i + (34 - sub_series )) for i in range(sub_series )]]\nX_test.head()","8d3b812b":"#X_test=scale.transform(X_test)\nX_test1 = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\npreds=lstm_model.predict(X_test1)","2a9c5ce9":"sub=pd.DataFrame(test['ID'])\nsub['item_cnt_month']=preds\nsub","016f6dd8":"sub.to_csv('subm.csv', index=False)","2f2bbf78":"# Data Loading","3cf7d14a":"# LSTM\nWe implement a demand forecasting method based on multi-layer LSTM networks. LSTM has strong ability to capture nonlinear patterns in time series data. It is a type of recurrent neural network, specifically designed to learn long term dependencies, overcoming the problems of vanishing and exploding gradient. The current model works on the Many-In-Many-Out mechanism, that is it predicts multiple forecast outputs using multiple inputs (lag variables).","fd026fb8":"# EDA","2b6cb8da":"# Sequence Modelling\nThe model takes a sequence as input and returns a sequence as output, therefore the flat dataframe we have must be converted into sequences.\nOur data consists of monthly frequencies. Since monthly data have less number of data points, LSTM trains ineffectively on this set and poses the issue of overfitting. Hence, we forecast on last one year time series only, broken into two steps.","b0c89b76":"# Overview\nDemand forecasting is the estimation of a probable future demand for a product or service. The term is often used interchangeably with demand planning, yet the latter is a broader process that commences with forecasting but is not limited to it. It is proportional to sales forecasting and can be achieved in the same way.\n\n"}}