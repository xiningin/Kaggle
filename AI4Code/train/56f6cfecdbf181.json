{"cell_type":{"594ab0a7":"code","633dca7d":"code","472ecb2b":"code","3743d2d0":"code","7789eb29":"code","d7b2fcb9":"code","532b2f24":"code","227350e4":"code","57924891":"code","1760049c":"code","e73d9625":"code","73bedf57":"code","98de84a3":"code","6536c640":"code","5f84340a":"code","347c0323":"markdown","ae9b6882":"markdown","63d97265":"markdown","e0718a13":"markdown","ff58893c":"markdown","e440ab3a":"markdown","0159f2ba":"markdown","632d32e4":"markdown","caf27eb6":"markdown","ef5d71ce":"markdown","44dc8946":"markdown","4240905e":"markdown"},"source":{"594ab0a7":"%matplotlib inline\n\nimport tensorflow as tf\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\n\nlr = 23\nsize = 360\niterations = 250\nstyle_wt = 0.0008\ncontent_wt = 0.8\n\ncontent_image_path = \"..\/input\/tamil-nst\/TamilContentImages\/C_image7.jpg\"\nstyle_image_path = \"..\/input\/tamil-nst\/TamilStyleImages\/S_image1.jpg\"\n\nstyle_layer_wts = [0.8,0.9,1.0,0.9,0.8]","633dca7d":"model = tf.keras.applications.vgg19.VGG19(include_top=False, weights=\"imagenet\", input_shape=(size, size, 3))\nmodel.trainable = False\nmodel.summary()","472ecb2b":"def preprocess_image(image_path):\n    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(size, size))\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    img = tf.keras.applications.vgg19.preprocess_input(img)\n    return np.expand_dims(img, axis = 0)","3743d2d0":"def deprocess(x):\n    x[:, :, 0] += 103.939\n    x[:, :, 1] += 116.779\n    x[:, :, 2] += 123.68\n    x = x[:, :, ::-1]\n\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x\n\ndef display_image(image):\n    if len(image.shape) == 4:\n        image = image[0,:,:,:]\n\n    img = deprocess(image)\n    \n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(img)\n    plt.show()","7789eb29":"display_image(preprocess_image(style_image_path))","d7b2fcb9":"display_image(preprocess_image(content_image_path))","532b2f24":"content_layer = 'block3_conv4'\n\ncontent_model = tf.keras.models.Model(\n    inputs=model.input,\n    outputs=model.get_layer(content_layer).output\n)","227350e4":"style_layers = [\n    'block1_conv1', 'block2_conv2',\n    'block3_conv3', 'block4_conv4',\n    'block5_conv2'\n    ]\n\nstyle_models = [\n    tf.keras.models.Model(inputs=model.input, outputs=model.get_layer(layer).output)\n    for layer in style_layers\n]","57924891":"def content_cost(content_img, generated_img):\n    C = content_model(content_img)\n    G = content_model(generated_img)\n    cost = tf.reduce_mean(tf.square(C - G))\/(4*G.shape[0]*G.shape[1]*3)\n    return cost","1760049c":"def gram_matrix(M):\n    num_channels = tf.shape(M)[-1]\n    M = tf.reshape(M, shape=(-1, num_channels))\n    n = tf.shape(M)[0]\n    G = tf.matmul(tf.transpose(M), M)\n    return G ","e73d9625":"def style_cost(style_img, generated_img):\n    total_cost = 0\n    \n    for i, style_model in enumerate(style_models):\n        S = style_model(style_img)\n        G = style_model(generated_img)\n        GS = gram_matrix(S)\n        GG = gram_matrix(G)\n        current_cost = style_layer_wts[i] * tf.reduce_mean(tf.square(GS - GG))\/(2*GS.shape[0]*GS.shape[0]*3)**2\n        total_cost += current_cost\n    return total_cost","73bedf57":"content_image_preprocessed = preprocess_image(content_image_path)\nstyle_image_preprocessed = preprocess_image(style_image_path)\ngenerated_image = tf.Variable(content_image_preprocessed, dtype=tf.float32)\n\ngenerated_images = []\ncosts = []\n\nmin_cost=1*10**12\noptimizer = tf.optimizers.Adam(learning_rate=lr)\n\nfor i in range(iterations):\n    \n    with tf.GradientTape() as tape:\n        J_content = content_cost(content_img=content_image_preprocessed, generated_img=generated_image)\n        J_style = style_cost(style_img=style_image_preprocessed, generated_img=generated_image)\n        J_total = content_wt * J_content + style_wt * J_style\n    \n    gradients = tape.gradient(J_total, generated_image)\n    optimizer.apply_gradients([(gradients, generated_image)])\n    \n    costs.append(J_total.numpy())\n    \n    if i % 10 == 0:\n        if(J_total<min_cost):\n            generated_images.append(generated_image.numpy())\n            min_cost=J_total\n        print(\"Iteration:{}\/{}, Total Cost:{}, Style Cost: {}, Content Cost: {}\".format(i+1, iterations, J_total, J_style, J_content))","98de84a3":"plt.plot(range(iterations), costs)\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Total Cost\")\nplt.show()","6536c640":"image = Image.fromarray(deprocess(generated_images[-1][0]))","5f84340a":"plt.figure(figsize=(24,8))\ndict_title={1:\"Content_image\",2:\"Generated_image\",3:\"Style_image\"}\nimages={1:tf.keras.preprocessing.image.load_img(content_image_path),2:image,3:tf.keras.preprocessing.image.load_img(style_image_path)}\nfor i in range(1,4):\n    plt.subplot(2,4,i)\n    plt.imshow(images[i])\n    plt.xticks([])\n    plt.yticks([])\n    plt.tight_layout()\n    plt.title(dict_title[i])\nplt.savefig('out.png')\nplt.show","347c0323":"# Style Part","ae9b6882":"# Deprocessing for Visualization","63d97265":"# Loss Plot","e0718a13":"# Preprocessing","ff58893c":"# Generation of Style Transferred Content Image","e440ab3a":"Thank You!","0159f2ba":"# Visualization of Final Image","632d32e4":"# Importing the essentials and declaring the Hyperparameters","caf27eb6":"# Style Cost","ef5d71ce":"# Content Part","44dc8946":"# Loading the Pre-Trained Model","4240905e":"# Content Cost"}}