{"cell_type":{"5254fd9b":"code","099e5e1a":"code","9f510386":"code","68955f18":"code","068d0e14":"code","5ac1ce67":"code","4bdac368":"code","c5d66687":"code","eca1c626":"code","b27a9186":"code","d4b8b7f1":"code","59e874dd":"code","12dfeb58":"code","5c72d3cb":"code","9df2b988":"code","e0d004d2":"code","b78d847a":"code","77c5d8a2":"code","fb33de8d":"markdown","c5875557":"markdown","3135406b":"markdown","d3097335":"markdown"},"source":{"5254fd9b":"!pip -q install vit_pytorch linformer","099e5e1a":"from __future__ import print_function\n\nimport glob\nfrom itertools import chain\nimport os\nimport random\nimport zipfile\nimport copy\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom linformer import Linformer\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms\nfrom tqdm.notebook import tqdm\n\nfrom vit_pytorch.efficient import ViT\n\n%config InlineBackend.figure_format = 'retina'","9f510386":"print(f\"Torch: {torch.__version__}\")","68955f18":"# Training settings\nbatch_size = 64\nepochs = 50\nlr = 3e-5\ngamma = 0.7\nseed = 42","068d0e14":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(seed)","5ac1ce67":"import torchvision\nfrom torchvision.transforms import ToTensor\n\ntrain_data = torchvision.datasets.ImageFolder('..\/input\/battlefront-2-maps-small\/train', transform=ToTensor())\nvalid_data = torchvision.datasets.ImageFolder('..\/input\/battlefront-2-maps-small\/valid', transform=ToTensor())\ntest_data = torchvision.datasets.ImageFolder('..\/input\/battlefront-2-maps-small\/test', transform=ToTensor())","4bdac368":"import torch.utils.data as data\nfrom torch.autograd import Variable\nimport numpy as np\n\ntrain_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\nvalid_loader = data.DataLoader(valid_data, batch_size=batch_size, shuffle=True)\ntest_loader  = data.DataLoader(test_data, batch_size=batch_size, shuffle=True) ","c5d66687":"print(len(train_data), len(train_loader))\nprint(len(valid_data), len(valid_loader))\nprint(len(test_data), len(test_loader))","eca1c626":"efficient_transformer = Linformer(\n    dim=128,\n    seq_len=49+1,  # 7x7 patches + 1 cls-token\n    depth=12,\n    heads=8,\n    k=64\n)","b27a9186":"device = 'cuda'\n\nmodel = ViT(\n    dim=128,\n    image_size=224,\n    patch_size=32,\n    num_classes=10,\n    transformer=efficient_transformer,\n    channels=3\n).to(device)","d4b8b7f1":"# loss function\ncriterion = nn.CrossEntropyLoss()\n# optimizer\noptimizer = optim.Adam(model.parameters(), lr=lr)\n# scheduler\nscheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n\nn_epochs_stop = 10\n\nmin_val_loss = 10","59e874dd":"for epoch in range(epochs):\n    epoch_loss = 0\n    epoch_accuracy = 0\n\n    for data, label in tqdm(train_loader):\n        data = data.to(device)\n        label = label.to(device)\n\n        output = model(data)\n        loss = criterion(output, label)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        acc = (output.argmax(dim=1) == label).float().mean()\n        epoch_accuracy += acc \/ len(train_loader)\n        epoch_loss += loss \/ len(train_loader)\n\n    with torch.no_grad():\n        epoch_val_accuracy = 0\n        epoch_val_loss = 0\n        for data, label in valid_loader:\n            data = data.to(device)\n            label = label.to(device)\n\n            val_output = model(data)\n            val_loss = criterion(val_output, label)\n\n            acc = (val_output.argmax(dim=1) == label).float().mean()\n            epoch_val_accuracy += acc \/ len(valid_loader)\n            epoch_val_loss += val_loss \/ len(valid_loader)\n            \n        print(f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\")\n        \n        if epoch_val_loss < min_val_loss:\n            #Saving the model\n            best_model = copy.deepcopy(model.state_dict())\n            epochs_no_improve = 0\n            min_val_loss = epoch_val_loss\n            early_stoped = False\n\n        else:\n            epochs_no_improve += 1\n            # Check early stopping condition\n            if epochs_no_improve == n_epochs_stop:\n                print('Early stopping!' )\n                model.load_state_dict(best_model)\n                early_stoped = True\n                break\n    if early_stoped:\n        break\n\n    ","12dfeb58":"torch.save(model, '.\/vit_model_3.pt')","5c72d3cb":"y_pred_list = []\ny_true_list = []\nwith torch.no_grad():\n    for x_batch, y_batch in tqdm(test_loader):\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n        y_test_pred = model(x_batch)\n        _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n        y_pred_list.append(y_pred_tag.cpu().numpy())\n        y_true_list.append(y_batch.cpu().numpy())","9df2b988":"def flatten(new:list, target:list):\n    for li in target:\n        for value in list(li):\n            new.append(value)\n\ny_pred = []\ny_true = []\nflatten(y_pred, y_pred_list)\nflatten(y_true, y_true_list)","e0d004d2":"from sklearn.metrics import accuracy_score, f1_score\nprint(\"Overall accuracy:\", accuracy_score(y_true, y_pred))\nprint(\"Overall F1:\", f1_score(y_true, y_pred, average='weighted'))","b78d847a":"from sklearn.metrics import precision_recall_fscore_support as score\n\nprecision, recall, fscore, support = score(y_true, y_pred)\n\nprint('precision: {}'.format(precision))\nprint('recall: {}'.format(recall))\nprint('fscore: {}'.format(fscore))\nprint('support: {}'.format(support))","77c5d8a2":"from sklearn.metrics import confusion_matrix\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\ndef plot_cm(y_true, y_pred, figsize=(10,9)):\n    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n    cm_sum = np.sum(cm, axis=1, keepdims=True)\n    cm_perc = cm \/ cm_sum.astype(float) * 100\n    annot = np.empty_like(cm).astype(str)\n    nrows, ncols = cm.shape\n    for i in range(nrows):\n        for j in range(ncols):\n            c = cm[i, j]\n            p = cm_perc[i, j]\n            if i == j:\n                s = cm_sum[i]\n                annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n            elif c == 0:\n                annot[i, j] = ''\n            else:\n                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n    cm.index.name = 'Actual'\n    cm.columns.name = 'Predicted'\n    fig, ax = plt.subplots(figsize=figsize)\n    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)\n\nplot_cm(y_true, y_pred)\n\ndisplay()","fb33de8d":"## Effecient Attention","c5875557":"### Training","3135406b":"### Linformer","d3097335":"### Visual Transformer"}}