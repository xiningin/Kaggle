{"cell_type":{"af22ad6d":"code","cc8db288":"code","e4fa3482":"code","0016dacf":"code","33938622":"code","41192399":"code","302424d2":"code","6f9a214f":"code","0ca0982c":"code","b225d34f":"code","91edd45e":"code","3d6ad214":"code","9ad5770a":"code","22e5ea1b":"code","aa09c8cc":"code","a3f698fb":"code","d3a51b46":"code","4373c2d9":"code","6058c618":"code","7dfa116f":"code","0118c34a":"code","1ee107a0":"code","ed2d6fb6":"code","cb50bbb1":"code","03790e0d":"code","583d94b7":"code","312ffe6b":"code","1e5ef13f":"code","c45147a3":"code","75074e7d":"code","a31d6bd4":"code","69fe7f8d":"code","e0a4806b":"code","0371dfe1":"code","cef403be":"code","92444c47":"code","8e1ccb5b":"code","f2ab614a":"code","aa69ccbf":"code","4bd284fb":"code","e639d24a":"code","7b04fc54":"code","f228b726":"code","375ce1d7":"code","06f88e7e":"code","d25bf609":"code","1db2fe3b":"code","66f29f47":"code","0fc3730f":"code","d1850f2a":"code","854c4606":"code","037f588c":"markdown","ea48c6e1":"markdown","4639a68e":"markdown","59ba34aa":"markdown","50e40f1a":"markdown","6d9ccff1":"markdown","ca4b976d":"markdown","5c8b9daf":"markdown","2cfa2832":"markdown","bb105932":"markdown","77764ea1":"markdown","d9c5c564":"markdown","680011d6":"markdown","3fa5181a":"markdown","23bd4762":"markdown","7db84a92":"markdown","ffd748b7":"markdown","d788c627":"markdown","935961bd":"markdown","87a4dc83":"markdown","130fc2f5":"markdown","ffa27da5":"markdown","8a0af346":"markdown","e4708e51":"markdown","f80b3475":"markdown","6f2fae4a":"markdown","873fecbd":"markdown","aabf9a91":"markdown","2ee9d7a9":"markdown","2973eedc":"markdown","fd598feb":"markdown"},"source":{"af22ad6d":"!pip install sweetviz","cc8db288":"import pandas as pd\nimport sweetviz\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn import model_selection, preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestClassifier","e4fa3482":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","0016dacf":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","33938622":"train.head()","41192399":"test.head()","302424d2":"train.info()","6f9a214f":"test.info()","0ca0982c":"report = sweetviz.compare([train, 'Train'], [test, 'Test'], 'Survived')","b225d34f":"report.show_html('Report.html')","91edd45e":"numerical_features = train[['Age', 'Fare']]","3d6ad214":"numerical_features","9ad5770a":"sns.set(style = 'whitegrid')\nfig = plt.figure(figsize = (10,5))\nfor i in range(len(numerical_features.columns)):\n    fig.add_subplot(1, 2, i+1)\n    sns.boxplot(y = numerical_features.iloc[:,i])\nplt.tight_layout()\nplt.show()","22e5ea1b":"fig = plt.figure(figsize = (10,5))\nfor i in range(len(numerical_features.columns)):\n    fig.add_subplot(1, 2, i+1)\n    sns.scatterplot(x = numerical_features.iloc[:,i], y = train.Survived)\nplt.tight_layout()\nplt.show()","aa09c8cc":"train.drop(train[train.Fare > 300].index, inplace = True)","a3f698fb":"train.Age = train.groupby('Pclass').Age.apply(lambda x : x.fillna(x.median()))","d3a51b46":"test.Age = test.groupby('Pclass').Age.apply(lambda x : x.fillna(x.median()))","4373c2d9":"train.Age.isna().sum()","6058c618":"test.Age.isna().sum()","7dfa116f":"test.Fare.fillna(test.Fare.mean(), inplace = True)","0118c34a":"test.Fare.isna().sum()","1ee107a0":"train.drop(columns = 'Cabin', inplace = True)","ed2d6fb6":"test.drop(columns = 'Cabin', inplace = True)","cb50bbb1":"train.Embarked.fillna(train.Embarked.mode().iloc[0], inplace = True)","03790e0d":"train.Embarked.isna().sum()","583d94b7":"train.isna().sum()","312ffe6b":"test.isna().sum()","1e5ef13f":"train.set_index('PassengerId', inplace = True)","c45147a3":"test.set_index('PassengerId', inplace = True)","75074e7d":"train.head()","a31d6bd4":"test.head()","69fe7f8d":"report = sweetviz.compare([train, 'Train'], [test, 'Test'], 'Survived')","e0a4806b":"report.show_html('Report_after_EDA.html')","0371dfe1":"train.drop(columns = ['Name', 'Ticket'], inplace = True)\ntest.drop(columns = ['Name', 'Ticket'], inplace = True)","cef403be":"train.head()","92444c47":"test.head()","8e1ccb5b":"cat_columns = ['Sex', 'Embarked']","f2ab614a":"train = pd.get_dummies(train, columns = cat_columns)","aa69ccbf":"train.head().T","4bd284fb":"test = pd.get_dummies(test, columns = cat_columns)","e639d24a":"test.head().T","7b04fc54":"x = np.array(train.drop(columns = 'Survived'))\nx = preprocessing.scale(x)","f228b726":"y = np.array(train.Survived)","375ce1d7":"x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size = 0.2)","06f88e7e":"model = RandomForestClassifier(n_estimators = 100)\nmodel.fit(x_train, y_train)","d25bf609":"accuracy = model.score(x_test, y_test)\nprint('Model accuracy:', accuracy)","1db2fe3b":"y_predict = model.predict(x_test)\nmse = mean_squared_error(y_test, y_predict)\nprint('Mean Square error:', mse)","66f29f47":"x_predict = np.array(test)\nx_predict = preprocessing.scale(x_predict)","0fc3730f":"y_predict = model.predict(x_predict)","d1850f2a":"submission = pd.DataFrame(data = {'PassengerID':np.array(test.index.values), 'Survived':y_predict})","854c4606":"submission.to_csv('my_submission.csv', index = False)\nprint('Submission file saved')","037f588c":"- Before starting I would recommend all of you to try out the Sweetviz library. \n- I have done the entire analysis part with the help of Sweetviz, a novel EDA oriented library which reduces the time and effort needed for EDA by automatting the visualizing part to an extent. \n- Have fun :)","ea48c6e1":"## Using Random Forest Classifier","4639a68e":"## Missing values in Categorical features","59ba34aa":"- There are 2 missing values in Embarked\n- We can replace it by the mode of the feature.","50e40f1a":"- Since there are 77% missing values in Cabin, we will be dropping it from both Train and Test data.","6d9ccff1":"## Getting basic insights","ca4b976d":"## Analysing missing values in numerical features","5c8b9daf":"- All missing values in training and test data have been replaced.","2cfa2832":"- There are no missing values in Fare feature anymore.","bb105932":"## Dropping outliers","77764ea1":"- Since PassengerID is unique for each passenger, it can be set as the index for the dataframe.","d9c5c564":"- There are no missing values in Age anymore","680011d6":"- The train dataset has 11 features with 891 training examples.\n- The test dataset has 11 features with 418 entries.\n- Survived is target variable.","3fa5181a":"## Predicting the test data","23bd4762":"## Importing dataset","7db84a92":"- Doing the same in test data.","ffd748b7":"## Analysing numerical features","d788c627":"- Since Age is associated with Pclass, I will be grouping Age by Pclass and fill the missing values with the median age of that Pclass","935961bd":"## Importing libraries","87a4dc83":"- Since there is only 1 missing value in the test data, I will be filling it with the mean of the entire Fare feature.","130fc2f5":"- We have scaled all the features before inputing them as the model was not converging under the default max_iter without scaling.\n- test_size is set to be 20% of the whole data.\n- The model testing accuracy was found to be 82%.\n- The model testing mse was found to be 0.174","ffa27da5":"- Now that we converted the categorical variables to one-hot encoded features, we are ready to feed them to the model\n- I will be using a logsitic regression model.","8a0af346":"- There are no more missing values in Embarked.","e4708e51":"## Box plot","f80b3475":"## Scatter plot","6f2fae4a":"- There are no outliers in Age\n- Training examples having fare above 500 can be treated as outliers.","873fecbd":"## Encoding categorical variables","aabf9a91":"- All the assumptions made hereafter will be largely based on the report generated above.","2ee9d7a9":"- I am usig one-hot encoding to convert the cateorical variables to numerical ones.","2973eedc":"- Since Name & Ticket is not correlated to Survived and is a text feature, I am removing it.","fd598feb":"- There are 20% missing values in Age feature in both training and test data.\n- There is only 1 missing value in Fare in test data."}}