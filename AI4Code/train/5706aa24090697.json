{"cell_type":{"fc1727bf":"code","28731058":"code","598aaa79":"code","151a7103":"code","b87bfbba":"code","b29e340e":"code","afd8b89f":"code","0c86e489":"code","be1b5858":"code","1efdbc31":"code","90a7976b":"code","b04ea0ff":"code","1c37ba6b":"code","4d0e26a5":"code","e366fa7e":"code","2d0ddde7":"code","7d139881":"code","1b8b7213":"code","ad287429":"code","3c5c7342":"code","7472f9f2":"code","835e6546":"code","88aaee47":"code","7736880a":"code","7ac62470":"code","62b40207":"code","58054115":"markdown","9055a0d2":"markdown"},"source":{"fc1727bf":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u306eimport\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\n%matplotlib inline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMClassifier\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom pylab import rcParams\nfrom matplotlib import rc\nfrom pandas.plotting import register_matplotlib_converters\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nregister_matplotlib_converters()\nsns.set(style='whitegrid', palette='muted', font_scale=1.5)\n\nrcParams['figure.figsize'] = 10, 5\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)","28731058":"ROOT_TRAIN = '..\/input\/data-science-spring-osaka-2021'\n# \u4e00\u89a7\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\u307e\u3059\ndf_train = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/test.csv')\ndf_action = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/actions.csv')","598aaa79":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\ndf_train.head()","151a7103":"# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\uff08\u30c6\u30b9\u30c8\u306a\u306e\u3067\u7b54\u3048\u306f\u4ed8\u4e0e\u3055\u308c\u3066\u3044\u306a\u3044\u306e\u304c\u308f\u304b\u308a\u307e\u3059\uff09\ndf_test.head()","b87bfbba":"df_train_len = pd.DataFrame(index=[], columns=['file_path', 'len'])\nfor path in df_train.file_path:\n    df_sensor = pd.read_csv('..\/input\/data-science-spring-osaka-2021'+path)\n    df_train_len = df_train_len.append({'file_path': path, 'len': len(df_sensor)}, ignore_index=True)\ndf_train_len.len = df_train_len.len.astype('int')\n\ndf_test_len = pd.DataFrame(index=[], columns=['file_path', 'len'])\nfor path in df_test.file_path:\n    df_sensor = pd.read_csv('..\/input\/data-science-spring-osaka-2021'+path)\n    df_test_len = df_test_len.append({'file_path': path, 'len': len(df_sensor)}, ignore_index=True)\ndf_test_len.len = df_test_len.len.astype('int')","b29e340e":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306eTime\u306e\u9577\u3055\u3092\u78ba\u8a8d\ndf_train_len.describe()","afd8b89f":"# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306eTime\u306e\u9577\u3055\u3092\u78ba\u8a8d\ndf_test_len.describe()","0c86e489":"# \u7279\u5fb4\u91cf\uff08=\u8aac\u660e\u5909\u6570\uff09\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\uff08\u88ab\u8aac\u660e\u5909\u6570\uff09\u306b\u5206\u5272\u3057\u3066\u304a\u304d\u307e\u3059\ny_train = df_train.action_seq\nX_train = df_train.drop(['action_seq'], axis=1)\nX_test = df_test","be1b5858":"# \u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u30a8\u30f3\u30b3\u30fc\u30c9\uff08\u6570\u5024\u306b\u5909\u63db\uff09\u3057\u3066\u304a\u304d\u307e\u3059\nle = LabelEncoder()\ny_train = le.fit_transform(y_train)","1efdbc31":"# \u30bf\u30fc\u30b2\u30c3\u30c8\u3092one-hot-encoding\ny_train = y_train.reshape(-1, 1)\nenc = OneHotEncoder(handle_unknown='ignore', sparse=False)\nenc = enc.fit(y_train)\ny_train = enc.transform(y_train)","90a7976b":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u4e00\u90e8\u3092\u691c\u5b9a\uff08\u7cbe\u5ea6\u8a55\u4fa1\uff09\u7528\u306b\u5207\u308a\u51fa\u3057\u307e\u3059\nX_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=RANDOM_SEED, stratify=y_train)","b04ea0ff":"# Time\u304c600\u884c\u3067\u63c3\u3046\u3088\u3046\u306b\u6700\u521d\u306e\u884c\u306e\u5024\u3067\u30d1\u30c7\u30a3\u30f3\u30b0\ndef padding(df):\n    col_list = df.columns\n    add_len = 600-len(df)\n    list_data = df.to_numpy().tolist()\n    row_to_add = df[:1].to_numpy().tolist()\n    for i in range(add_len):\n        list_data.insert(0, row_to_add[0])\n    df = pd.DataFrame(list_data, columns=col_list)\n    return df\n\n# \u5168\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092\u7e26\u306b\u7d50\u5408\ndef create_dataset(df):\n    list_dataset = []\n    for path in df.file_path:\n        df_sensor = pd.read_csv('..\/input\/data-science-spring-osaka-2021'+path)\n        df_sensor = df_sensor.drop(['Time'], axis=1)\n        # \u30d5\u30a1\u30a4\u30eb\u6bce\u306b\u6a19\u6e96\u5316\u3059\u308b\u5834\u5408\u306f\u3001\u4ee5\u4e0b, \u4e0b\u306e\u307b\u3046\u306e\u6a19\u6e96\u5316\u51e6\u7406\u306f\u9006\u306b\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\n        #scaler = StandardScaler()\n        #df_sensor.iloc[:] = scaler.fit_transform(df_sensor)\n        df_sensor = padding(df_sensor)\n        list_dataset.append(df_sensor.to_numpy().tolist())\n    return np.array(list_dataset)\n\n# \u4e0a\u8a18\u51e6\u7406\u3092\u9069\u7528\nX_train = create_dataset(X_train)\nX_train_ = create_dataset(X_train_)\nX_val = create_dataset(X_val)\nX_test = create_dataset(X_test)\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3067\u6a19\u6e96\u5316fit\nshape0 = X_train_.shape[0]\nshape1 = X_train_.shape[1]\nX_train_ = X_train_.reshape(-1,20)\nscaler = StandardScaler()\nX_train_ = scaler.fit_transform(X_train_)\nX_train_ = X_train_.reshape(shape0,shape1,20)\n\n# \u691c\u8a3c\u30c7\u30fc\u30bf\u306b\u6a19\u6e96\u5316\u3092\u9069\u7528\nshape0 = X_val.shape[0]\nshape1 = X_val.shape[1]\nX_val = X_val.reshape(-1,20)\nX_val = scaler.transform(X_val)\nX_val = X_val.reshape(shape0,shape1,20)\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u6a19\u6e96\u5316\u3092\u9069\u7528\nshape0 = X_test.shape[0]\nshape1 = X_test.shape[1]\nX_test = X_test.reshape(-1,20)\nX_test = scaler.transform(X_test)\nX_test = X_test.reshape(shape0,shape1,20)\n\nprint(X_train.shape, X_train_.shape, X_val.shape, X_test.shape)","1c37ba6b":"# LSTM \u5b66\u7fd2\u6642\u9593\u304b\u304b\u308b\u306e\u3067GPU\u3092ON\u306b\u3059\u308b\u3088\u3046\u306b\uff01\n\n# \u30bb\u30f3\u30b5\u306e\u6b21\u5143\u6570\ndata_dim = X_train.shape[2]\n# Time\u306e\u9577\u3055\ntimesteps = X_train.shape[1]\n# \u30af\u30e9\u30b9\u6570(unseen label\u306f\u3053\u306e\u6642\u70b9\u3067\u672a\u5bfe\u5fdc)\nnum_classes = y_train.shape[1]\n\n# batch_size,optimizer\nbatch_size = 16\nopt = keras.optimizers.Adamax(lr=0.00005, beta_1=0.9, beta_2=0.999,epsilon=1e-08, decay=1e-4)\n\n# \u30e2\u30c7\u30eb\u5b9a\u7fa9\nmodel = Sequential()\nmodel.add(LSTM(1200, return_sequences=True,input_shape=(timesteps, data_dim)))\nmodel.add(LSTM(1200, return_sequences=True))\nmodel.add(LSTM(1200))\nmodel.add(Dense(units=128, activation='relu'))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n\n# EaelyStopping\u306e\u8a2d\u5b9a\nearly_stopping =  EarlyStopping(monitor='val_loss', min_delta=0.0, patience=10, restore_best_weights=True)\n\n# \u5b66\u7fd2\nhistory = model.fit(\n                    tf.cast(X_train_, tf.float32),\n                    tf.cast(y_train_, tf.float32),\n                    epochs=1000,\n                    batch_size=batch_size,\n                    validation_data=(tf.cast(X_val, tf.float32), tf.cast(y_val, tf.float32)),\n                    callbacks=[early_stopping]\n            )","4d0e26a5":"def plot_cm(y_true, y_pred, class_names):\n    cm = confusion_matrix(y_true, y_pred)\n    fig, ax = plt.subplots(figsize=(9, 8)) \n    ax = sns.heatmap(\n        cm, \n        annot=True, \n        fmt=\"d\", \n        cmap=sns.diverging_palette(220, 20, n=7),\n        ax=ax\n    )\n\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    ax.set_xticklabels(class_names)\n    ax.set_yticklabels(class_names)\n    b, t = plt.ylim() # discover the values for bottom and top\n    b += 0.5 # Add 0.5 to the bottom\n    t -= 0.5 # Subtract 0.5 from the top\n    plt.ylim(b, t) # update the ylim(bottom, top) values\n    plt.show() ","e366fa7e":"y_pred = model.predict(X_val)\nplot_cm(\n  enc.inverse_transform(y_val),\n  enc.inverse_transform(y_pred),\n  enc.categories_[0]\n)","2d0ddde7":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u5404\u4e88\u6e2c\u5024\u306e\u6700\u5927\u3068\u5206\u6563\ntrain_pred = model.predict(X_train_)\ntrain_pred_max = np.amax(train_pred, axis=1)\ntrain_pred_var = np.var(train_pred, axis=1)","7d139881":"# \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u5404\u4e88\u6e2c\u5024\u306e\u6700\u5927\u3068\u5206\u6563\nval_pred = model.predict(X_val)\nval_pred_max = np.amax(val_pred, axis=1)\nval_pred_var = np.var(val_pred, axis=1)","1b8b7213":"# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u5404\u4e88\u6e2c\u5024\u306e\u6700\u5927\u3068\u5206\u6563\ntest_pred = model.predict(X_test)\ntest_pred_max = np.amax(test_pred, axis=1)\ntest_pred_var = np.var(test_pred, axis=1)\ntest_pred_label = le.inverse_transform(np.argmax(test_pred, axis=1))","ad287429":"plt.figure()\nplt.hist(train_pred_max, bins=100, alpha=0.5, histtype='stepfilled', density=True, color='r',label=\"train\")\nplt.hist(val_pred_max, bins=100, alpha=0.5, histtype='stepfilled', density=True, color='b',label=\"val\")\nplt.hist(test_pred_max, bins=100, alpha=0.5, histtype='stepfilled', density=True, color='g',label=\"test\")\nplt.show()","3c5c7342":"plt.figure()\nplt.hist(train_pred_var, bins=100, alpha=0.5, histtype='stepfilled', density=True, color='r',label=\"train\")\nplt.hist(val_pred_var, bins=100, alpha=0.5, histtype='stepfilled', density=True, color='b',label=\"val\")\nplt.hist(test_pred_var, bins=100, alpha=0.5, histtype='stepfilled', density=True, color='g',label=\"test\")\nplt.show()","7472f9f2":"train_pred_max_min = np.amin(train_pred_max)\ntrain_pred_var_min = np.amin(train_pred_var)\nval_pred_max_min = np.amin(val_pred_max)\nval_pred_var_min = np.amin(val_pred_var)","835e6546":"# \u5b66\u7fd2\u6642\u306e\u4e88\u6e2c\u5024\u306e\u6700\u5927\u5024\u3001\u5206\u6563\u3001\u3069\u3061\u3089\u304b\u4e00\u65b9\u3088\u308a\u5c0f\u3055\u3044\u5024\u306e\u5834\u5408\u306f\u3001\u81ea\u4fe1\u306e\u306a\u3044\u4e88\u6e2c\u3068\u307f\u306a\u3059\ntest_preds_label_list = []\nfor l,m,n in zip(test_pred_max, test_pred_var, test_pred_label):\n    #if l > val_pred_max_min and m > val_pred_var_min:\n    if l > train_pred_max_min and m > train_pred_var_min:\n        test_preds_label_list.append(n)\n    else:\n        #unseen\n        test_preds_label_list.append(\"jab-jab-bodyhook\")","88aaee47":"df_sub = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/sample_submission.csv')\ndf_sub['action_seq'] = test_preds_label_list\ndf_sub","7736880a":"df_sub[\"action_seq\"].value_counts()","7ac62470":"# \u51fa\u529b\u3057\u3066\u63d0\u51fa\u3057\u307e\u3059\ndf_sub.to_csv('submission.csv', index=False)","62b40207":"# jab-jab-bodyhook","58054115":"* \u30b7\u30f3\u30d7\u30eb\u306aLSTM\u306b\u305d\u306e\u307e\u307e\u5165\u529b\u3067\u304d\u308b\u3088\u3046\u306bTime\u3092\u56fa\u5b9a\u9577\u306b\u3059\u308b \u4eca\u56de\u306f600\u306b\n* LSTM\u306f\u7cfb\u5217\u30c7\u30fc\u30bf\u3092\u6700\u521d\u304b\u3089\u6700\u5f8c\u307e\u3067\u9806\u306b\u51e6\u7406\u3092\u3057\u3066\u3044\u304f\u305f\u3081\u3001\u56fa\u5b9a\u9577\u306b\u8abf\u6574(\u30d1\u30c7\u30a3\u30f3\u30b0)\u3059\u308b\u969b\u306b\u306f\u6700\u5f8c\u3067\u306f\u306a\u304f\u3001\u6700\u521d\u306b\u5165\u308c\u308b\u65b9\u91dd\u3067\u3002\n* \u6a19\u6e96\u5316\u306f\u3001\u4e00\u65e6\u5b66\u7fd2\u30c7\u30fc\u30bf\u5168\u4f53\u3067(not \u30d5\u30a1\u30a4\u30eb\u6bce\u306b)","9055a0d2":"# \u6a19\u6e96\u5316\uff1a\u5168\u30d5\u30a1\u30a4\u30eb\u30ab\u30e9\u30e0\u6bce\u306b_\u30d1\u30c7\u30a3\u30f3\u30b0\uff1a\u5148\u982d\u884c\u306e\u5024\u3092\u5f8c\u308d\u306b"}}