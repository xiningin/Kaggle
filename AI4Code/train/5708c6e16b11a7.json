{"cell_type":{"9a975634":"code","a1bda244":"code","e6a430d5":"code","d997a5c7":"code","70ecb47e":"code","de40744b":"code","ad177b17":"code","5f9cf8d0":"code","c26b3f16":"code","41a949bb":"code","9551c818":"code","4e86033b":"code","7a597748":"code","23fbe7d7":"code","00201a1b":"code","437128de":"code","4e15f25a":"code","7ce63cf8":"code","78703d98":"code","4446e285":"code","f524a115":"code","98443f27":"code","6e8390c6":"code","5a765d0a":"code","a35c0374":"code","d4c8a006":"code","541950b3":"code","754942b9":"code","5ae8170b":"code","58e68297":"code","b140cf7c":"code","95955467":"code","91ae904a":"code","7e36ca95":"code","8e8b0aa9":"code","c7ee19ed":"code","26aaebf9":"code","7ab55acc":"code","70b9b10f":"code","794ba707":"code","24ab288f":"code","2031e79b":"code","b2ffe3a0":"code","e83daea9":"code","82d8fd93":"code","2a6b1f23":"code","52a0ff74":"markdown","64a0db2b":"markdown","011b64e6":"markdown","cf036db2":"markdown","40d97356":"markdown","b801af4d":"markdown","467a27f9":"markdown","6706cf8d":"markdown","93eb603f":"markdown","185f7787":"markdown","06d2b8db":"markdown","4c621c9c":"markdown","944d7b99":"markdown","454bae5b":"markdown","b6d5a405":"markdown","f8912556":"markdown","261959a5":"markdown","085639d6":"markdown","cc831694":"markdown"},"source":{"9a975634":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom numpy import argmax\nimport warnings\nwarnings.filterwarnings('ignore')","a1bda244":"#data_sample = pd.read_csv(\"..\/input\/sample_submission.csv\")\ndata_train = pd.read_csv(\"..\/input\/train.csv\")\ndata_test = pd.read_csv(\"..\/input\/test.csv\")","e6a430d5":"data_train.head()","d997a5c7":"y_train = data_train.label.values\nx_train = data_train.drop([\"label\"], axis = 1)\nx_train = x_train\/255 # normalization\n\nx_test = data_test\/255","70ecb47e":"print(\"y_train: \", y_train.shape)\nprint(\"x_train: \", x_train.shape)\nprint(\"x_test: \", x_test.shape)","de40744b":"image1 = x_train.values[0].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(image1)","ad177b17":"image2 = x_train.values[300].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(image2)","5f9cf8d0":"image3 = x_train.values[600].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(image3)","c26b3f16":"# Split the train and the validation set for the fitting\nfrom sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state=46)\nprint(\"x_train: \",x_train.shape)\nprint(\"x_val: \",x_val.shape)\nprint(\"y_train: \",y_train.shape)\nprint(\"y_val: \",y_val.shape)","41a949bb":"# Store accuracies of the machine learning methods for comparison at the end\nlist_names = []\nlist_accuracy = []","9551c818":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(x_train, y_train)\nLR_accuracy = lr.score(x_val, y_val)*100\nLR_accuracy = round(LR_accuracy, 2)\n\nprint(\"LR_accuracy is %\", LR_accuracy)\nlist_names.append(\"Logistic Regression\")\nlist_accuracy.append(LR_accuracy)","4e86033b":"y_pred_LR = lr.predict(x_test)","7a597748":"N = 210\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_LR[N])","23fbe7d7":"N = 27000\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_LR[N])","00201a1b":"N = 4000\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_LR[N])","437128de":"from sklearn.neighbors import KNeighborsClassifier\n\nKnn_accuracies = []\nnumber_of_neighbors = []\nfor neighbors in range(1,20):\n    Knn = KNeighborsClassifier(n_neighbors = neighbors)\n    Knn.fit(x_train, y_train)\n    Knn_accuracy = round(Knn.score(x_val, y_val)*100,2)\n    Knn_accuracies.append(Knn_accuracy)\n    number_of_neighbors.append(neighbors)\n    \n## Visualization\n# Accuracy vs n_estimators\ntrace1 = go.Scatter(\n                    y = Knn_accuracies,\n                    x = number_of_neighbors,\n                    mode = \"lines\",\n                    name = \"K-NN Classifier\",\n                   )\n\ndata = [trace1]\nlayout = dict(title = 'KNN Accuracy',\n              autosize=False,\n              width=800,\n              height=500,\n              yaxis= dict(title= 'Validation Accuracy (%)',gridwidth=2, gridcolor='#bdbdbd'),\n              xaxis= dict(title= 'Number of Neighbors',gridwidth=2, gridcolor='#bdbdbd'),\n              font=dict(size=14)\n             )\nfig = dict(data = data, layout = layout)\npy.iplot(fig)    \n    \nKnn_accuracy = max(Knn_accuracies)\nprint(\"Knn_accuracy is %\", Knn_accuracy)\nlist_names.append(\"K-nn\")\nlist_accuracy.append(Knn_accuracy)","4e15f25a":"y_pred_KNN = Knn.predict(x_test)","7ce63cf8":"N = 4500\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_KNN[N])","78703d98":"N = 7700\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_KNN[N])","4446e285":"N = 21851\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_KNN[N])","f524a115":"from sklearn.svm import SVC\n\nsvm = SVC(random_state=1)\nsvm.fit(x_train, y_train)\nSVM_accuracy = svm.score(x_val, y_val)*100\nSVM_accuracy = round(SVM_accuracy, 2)\n\nprint(\"SVM_accuracy is %\", SVM_accuracy)\n\nlist_names.append(\"SVM\")\nlist_accuracy.append(SVM_accuracy)","98443f27":"y_pred_SVM = svm.predict(x_test)","6e8390c6":"N = 8\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_SVM[N])","5a765d0a":"N = 1142\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_SVM[N])","a35c0374":"N = 6548\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_SVM[N])","d4c8a006":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(x_train, y_train)\nDecisionTree_accuracy = dt.score(x_val, y_val)*100\nDecisionTree_accuracy = round(DecisionTree_accuracy,2)\n\nprint(\"DecisionTree_accuracy is %\", DecisionTree_accuracy)\n\nlist_names.append(\"Decision Tree\")\nlist_accuracy.append(DecisionTree_accuracy)","541950b3":"y_pred_DT = dt.predict(x_test)","754942b9":"N = 180\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_DT[N])","5ae8170b":"N = 17520\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_DT[N])","58e68297":"N = 23150\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_DT[N])","b140cf7c":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nRF_accuracies = []\nnumber_of_estimators = []\nfor num_of_estimators in range(5,405,20):\n    rf = RandomForestClassifier(n_estimators = num_of_estimators, random_state = 1)\n    rf.fit(x_train, y_train)\n    RandomForest_accuracy = rf.score(x_val, y_val)*100\n    RF_accuracies.append(RandomForest_accuracy)\n    number_of_estimators.append(num_of_estimators)\n\n# Accuracy vs n_estimators\ntrace1 = go.Scatter(\n                    y = RF_accuracies,\n                    x = number_of_estimators,\n                    mode = \"lines\",\n                    name = \"Random Forest Classifier\",\n                   )\n\ndata = [trace1]\nlayout = dict(title = 'Random Forest Accuracy',\n              autosize=False,\n              width=800,\n              height=500,\n              yaxis= dict(title= 'Validation Accuracy (%)',gridwidth=2, gridcolor='#bdbdbd'),\n              xaxis= dict(title= 'Number of Estimators',gridwidth=2, gridcolor='#bdbdbd'),\n              font=dict(size=14)\n             )\nfig = dict(data = data, layout = layout)\npy.iplot(fig)\n\nRandomForest_accuracy = round(max(RF_accuracies),2)\nprint(\"Random Forest accuracy is \", RandomForest_accuracy)\nlist_names.append(\"Random Forest\")\nlist_accuracy.append(RandomForest_accuracy)","95955467":"y_pred_RF = rf.predict(x_test)","91ae904a":"N = 7000\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_RF[N])","7e36ca95":"N = 24000\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_RF[N])","8e8b0aa9":"N = 18000\nimg = x_test.values[N].reshape(28,28) # reshape 1*784 raw data to 28*28 image\nimgplot = plt.imshow(img)\nprint(\"The digit in the following image is \",y_pred_RF[N])","c7ee19ed":"# Reshape\nx_train = x_train.values.reshape(-1,28,28,1)\nx_val = x_val.values.reshape(-1,28,28,1)\nx_test = x_test.values.reshape(-1,28,28,1)\nprint(\"x_train shape: \",x_train.shape)\nprint(\"x_val shape: \",x_val.shape)\nprint(\"x_test shape: \",x_test.shape)","26aaebf9":"# Label Encoding \nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\ny_train = to_categorical(y_train, num_classes = 10)\ny_val = to_categorical(y_val, num_classes = 10)","7ab55acc":"import itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n#\nmodel.add(Conv2D(filters = 12, kernel_size = (5,5),padding = 'Same', \n                 activation ='tanh', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters = 20, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n# fully connected\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","70b9b10f":"# Define the optimizer\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","794ba707":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","24ab288f":"epochs = 201  # for better result increase the epochs\nbatch_size = 250","2031e79b":"# data augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=0.5,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.5, # Randomly zoom image 5%\n        width_shift_range=0.5,  # randomly shift images horizontally 5%\n        height_shift_range=0.5,  # randomly shift images vertically 5%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(x_train)","b2ffe3a0":"# Fit the model\nhistory = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_val,y_val), \n                              steps_per_epoch=x_train.shape[0] \/\/ batch_size)\n\nval_accuracy = history.history['val_acc']\nCNN_accuracy = round(max(val_accuracy)*100,2)\nprint(\"CNN accuracy is \", CNN_accuracy)\nlist_names.append(\"CNN\")\nlist_accuracy.append(CNN_accuracy)","e83daea9":"# Plot the loss and accuracy curves for training and validation \naccuracy = []\nnum_of_epochs = []\nfor i in range(1,201,10):\n    accuracy.append(round(100*val_accuracy[i],3))\n    num_of_epochs.append(i)\n\ntrace1 = go.Scatter(y = accuracy, x = num_of_epochs, mode = \"lines\")\ndata = [trace1]\nlayout = dict(title = 'CNN Accuracy',\n              autosize=False,\n              width=800,\n              height=500,\n              yaxis= dict(title= 'Accuracy (%)',gridwidth=2, gridcolor='#bdbdbd'),\n              xaxis= dict(title= 'Number of Epochs',gridwidth=2, gridcolor='#bdbdbd'),\n              font=dict(size=14)\n             )\nfig = dict(data = data, layout = layout)\npy.iplot(fig)","82d8fd93":"df = pd.DataFrame({'METHOD': list_names, 'ACCURACY (%)': list_accuracy})\ndf = df.sort_values(by=['ACCURACY (%)'])\ndf = df.reset_index(drop=True)\ndf.head()","2a6b1f23":"trace1 = go.Bar(x = df.iloc[:,0].tolist(), y = df.iloc[:,1].tolist())\n\ndata1 = [trace1]\nlayout1 = go.Layout(\n    margin=dict(b=150),\n    title='Comparison of the Learning Methods',\n    xaxis=dict(titlefont=dict(size=16), tickangle=-60),\n    yaxis=dict(title='ACCURACY (%)',gridwidth=2, gridcolor='#bdbdbd', range=[80, 100]),\n    font=dict(size=16),\n    bargap = 0.6,\n    barmode='group')\n\nfig = go.Figure(data=data1, layout=layout1)\npy.iplot(fig, filename='grouped-bar')","52a0ff74":"## SVM Classifier Predictions","64a0db2b":"## Sample Images from Data","011b64e6":"## K-nn Classifier Predictions","cf036db2":"## CONVOLUTIONAL NEURAL NETWORK (CNN)","40d97356":"# DATA IMPORT, REVIEW and PREPROCESSING","b801af4d":"## Import data","467a27f9":"## 5-RANDOM FOREST CLASSIFIER","6706cf8d":"## Split Data for Train and Validation Purposes","93eb603f":"## Comparison of the Learning Methods","185f7787":"## Random Forest Classifier Predictions","06d2b8db":"## 4-DECISION TREE CLASSIFIER","4c621c9c":"## 3-SUPPORT VECTOR MACHINE (SVM)","944d7b99":"## Data review","454bae5b":"## Logistic Regression Predictions","b6d5a405":"## 2-KNN CLASSIFIER","f8912556":"# LEARNING ALGORITHMS","261959a5":"## Import necessary libraries","085639d6":"## Decision Tree Classifier Predictions","cc831694":"## 1- LOGISTIC REGRESSION"}}