{"cell_type":{"5be88cd3":"code","35a125cf":"code","b6dcdc25":"code","09b78370":"code","5e4a8a52":"code","9f576c50":"code","b82d2f3b":"code","0e5e5967":"code","db2df9e3":"code","08a8b37a":"code","45f4b49a":"code","02071c8a":"code","373ae9be":"markdown","a0d2fd7f":"markdown","fa1e17ec":"markdown","e3b4b8dc":"markdown","0b0a7ad0":"markdown","89cd2580":"markdown","01beb128":"markdown"},"source":{"5be88cd3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # data visualization\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport warnings\nwarnings.filterwarnings(action='ignore')\nwarnings.filterwarnings(action='ignore', category=DeprecationWarning)\nwarnings.filterwarnings(action='ignore', category=FutureWarning)\n\n# Library for Learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\nfrom keras.optimizers import SGD\nimport math\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","35a125cf":"# Any results you write to the current directory are saved as output.\nfor i in os.listdir(\"..\/input\/\"):\n    print(i)\n\n\ncoinbase = pd.read_csv(\"..\/input\/bitcoin-historical-data\/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv\")\ncb_index = coinbase.index.ravel()\n\nprint(list(coinbase.columns), \"\\nSHAPE ::\", coinbase.shape)\nfor i in coinbase.columns:\n    print(i, \"::\", coinbase[i].dtype)\n\n# Declaring number for random state for reproducibility\nrstate=123\n    \ncoinbase.describe()","b6dcdc25":"a = coinbase[\"Close\"][1200000:].fillna(method=\"backfill\")","09b78370":"close_price = np.array(a).reshape(-1,1)\nplt.figure(figsize=(14,6))\nplt.title(\"Bitcoin Closing Price\")\nplt.grid()\nplt.plot(close_price)\n\nsc = MinMaxScaler()\nclose_priceSC = sc.fit_transform(close_price)\nplt.figure(figsize=(14,6))\nplt.title(\"Scaled\")\nplt.grid()\nplt.plot(close_priceSC)","5e4a8a52":"X = []\ny = []\nfor i in range(60, len(close_priceSC)):\n    X.append(close_priceSC[i-60:i, 0])\n    y.append(close_priceSC[i,0])\nX, y = np.array(X), np.array(y)\nprint(X.shape, y.shape)","9f576c50":"X_train = X[:700000,:]\nX_test = X[700000:,:]\n\ny_train = y[:700000]\ny_test = y[700000:]","b82d2f3b":"plt.figure(figsize=(14,4))\nplt.plot(range(700000),y_train)\nplt.plot(range(700000, len(y)), y_test)\nplt.legend([\"Training\", \"Test\"])\nplt.grid()","0e5e5967":"X_train = X_train.reshape(-1,60,1)\nX_test = X_test.reshape(-1,60,1)\nprint(X_test)","db2df9e3":"\n# %%time\n# # The LSTM architecture\n# regressor = Sequential()\n# # First LSTM layer with Dropout regularisation\n# regressor.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1)))\n# regressor.add(Dropout(0.2))\n# # Second LSTM layer\n# regressor.add(LSTM(units=50, return_sequences=True))\n# regressor.add(Dropout(0.2))\n# # Third LSTM layer\n# regressor.add(LSTM(units=50, return_sequences=True))\n# regressor.add(Dropout(0.5))\n# # Fourth LSTM layer\n# regressor.add(LSTM(units=50))\n# regressor.add(Dropout(0.5))\n# # The output layer\n# regressor.add(Dense(units=1))\n\n# # Compiling the RNN\n# regressor.compile(optimizer='adam', loss='mean_absolute_error')\n# # Fitting to the training set\n# regressor.fit(X_train, y_train, epochs=1, batch_size=500)\n\n","08a8b37a":"\nimport pickle\nfilename = '..\/input\/finalized-model\/finalized_model.sav'\n# pickle.dump(regressor, open(filename, 'wb'))\nregressor = pickle.load(open(filename, 'rb'))\n# regressor = regresso.score(X_train, y_train)\n\n","45f4b49a":"# print(X_test)\ny_pred = regressor.predict(X_test)\nprint(y_pred)\nMSE = mean_absolute_error(y_test, y_pred)","02071c8a":"print(X_test)\nplt.figure(figsize=(t14,6))\nplt.plot(sc.inverse_transform(y_test.reshape(-1,1)))\nplt.plot(sc.inverse_transform(y_pred.reshape(-1,1)))\nplt.title(\"Comparison with MAE {0:0.10f}\".format(MSE))\nplt.legend([\"Y\", \"Prediction\"])\nplt.xlabel(\"Timeframe\")\nplt.ylabel(\"Price\")","373ae9be":"Splitting train and test","a0d2fd7f":"This is clearly overfitting","fa1e17ec":"Train using LSTM ","e3b4b8dc":"Plotting train and test data","0b0a7ad0":"Preparing X for LSTM","89cd2580":"We choose Bitcoin price after 1.200.000 because this is the time where people starts to recongnize Bitcoin.  We map the `Close` and its changes in percentage.","01beb128":"Transforming time series data to trainable data"}}