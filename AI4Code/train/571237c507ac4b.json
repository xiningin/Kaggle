{"cell_type":{"0e4e6418":"code","c26716de":"code","c4eaf823":"code","30d73f60":"code","a029b0b9":"code","17f62503":"code","fb37c3b5":"code","22642594":"code","3ac7a249":"code","8235c4fb":"code","78c1d7f2":"code","5ff26efa":"code","1a51954b":"code","0c5cc830":"code","4e1cf4d0":"code","3590cf47":"code","85b01cf9":"code","68d251d3":"code","5169fb3f":"code","2f8f47ca":"code","700ab598":"code","a3f2121e":"code","bd3acbd7":"code","555e35a2":"code","f819621a":"code","6e6306f3":"code","e942c0f4":"code","0220967d":"code","08d30b6b":"code","d86ef91e":"code","a17afbe3":"code","7c58caee":"code","7d85e88f":"code","4a324883":"code","b1b55642":"code","d8d89009":"code","4456e5c6":"code","ef618d94":"code","2ddf8266":"code","2253922f":"code","cddb1700":"code","615e5599":"code","92f55149":"code","37919db2":"code","23ba6f8d":"code","6cd41202":"code","0c2f2d92":"code","bd80052b":"code","a3cc075f":"code","a8384e0d":"code","2acc5256":"code","582de8ae":"code","5856196a":"code","b7037975":"code","dc7e8001":"code","3c764a01":"code","091e3039":"code","55ad15a7":"code","71cf98d9":"code","8dbe7f35":"code","4ad25d97":"code","a8d78cd0":"code","7069a36c":"code","bc0df5d5":"code","f07b161c":"code","a4c45dac":"code","b5681492":"code","b0b2e61a":"code","e4476e4b":"code","654ce75a":"code","cdd28545":"code","9d1c663d":"code","1f6a2d0e":"code","37e67793":"code","23378371":"code","6ece762b":"code","39ee1dad":"code","56d52566":"code","1a92ca54":"code","e2fbc006":"code","be481cc2":"code","b1f818be":"code","5c228db1":"code","ab302d88":"code","0d6ab2b5":"code","4406273e":"code","84cbbaff":"code","6c1c9fa0":"markdown","6bbcf30a":"markdown","d3dd0bbc":"markdown","471b1652":"markdown","6818faec":"markdown","ade2f232":"markdown","d9208f3f":"markdown","3c62d8c4":"markdown","1cbcc306":"markdown","6e113df3":"markdown","3f07aaa6":"markdown","08adebd3":"markdown","89f8b866":"markdown","9c5143ab":"markdown","beb77ff2":"markdown","dbb331b9":"markdown","15591a9d":"markdown","470ae749":"markdown","5c466e1e":"markdown","bd0f9029":"markdown","f997d96e":"markdown","aa516237":"markdown","172e3f06":"markdown","218fc078":"markdown","14d031b0":"markdown","1ce32fb0":"markdown","52432174":"markdown","c879541c":"markdown","170fd9a5":"markdown","f06d7a09":"markdown","a2a83a2e":"markdown","6f886a92":"markdown","e4639a6f":"markdown","6482d38c":"markdown","a717f128":"markdown","1ea6e79a":"markdown","929b9b17":"markdown","ad05e846":"markdown","46b48ce4":"markdown","5a2287a6":"markdown","a36d80cb":"markdown","d7dc7802":"markdown","d24d995d":"markdown","73c5f5f0":"markdown","e07eb9a2":"markdown"},"source":{"0e4e6418":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c26716de":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","c4eaf823":"# Import the numpy and pandas packages\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import linear_model\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\n\npd.set_option('display.max_columns', 200)","30d73f60":"applData = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\", encoding= 'unicode_escape')\ntestData = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\", encoding= 'unicode_escape')","a029b0b9":"applData.head()","17f62503":"print(applData.shape)\nprint(applData.info())","fb37c3b5":"pctDF = (applData.isnull().sum()\/len(applData) * 100).reset_index()\npctDF.columns = ['Columns','Missing Value Percentage']\npctDF = pctDF[pctDF['Missing Value Percentage'] > 45]\npctDF","22642594":"columns = list(map(lambda x: x, pctDF['Columns']))\napplData.drop(columns = columns, inplace=True)\napplData.head()","3ac7a249":"#Remove the id Columns\napplData.drop(columns = ['Id'], inplace=True)","8235c4fb":"from scipy.special import boxcox1p\n\ntransformedColumns = []\ndroppedColumns = []\nfor i in enumerate(applData.columns):\n    column = i[1]\n    valueDF = ((applData[column].value_counts() \/ len(applData[column]))*100).reset_index()\n    valueDF.columns = ['column','Value Percentage']\n    skewDF = valueDF[valueDF['Value Percentage'] >= 75]\n    if(len(skewDF) > 0):\n        applData.drop(columns = [column], inplace=True)\n        droppedColumns.append(column)\n            \nprint(\"Dropped Highly skewed columns:\", droppedColumns)","78c1d7f2":"applData.head()","5ff26efa":"# 44 Features are remaining after removing the highly skewed columns.\napplData.shape","1a51954b":"pctDF = (applData.isnull().sum()\/len(applData) * 100).reset_index()\npctDF.columns = ['Columns','Missing Value Percentage']\npctDF = pctDF[pctDF['Missing Value Percentage'] > 0]\npctDF","0c5cc830":"print(applData['LotFrontage'].value_counts())\nprint(\"Median: \", applData[\"LotFrontage\"].median())\nprint(\"Mean: \", applData[\"LotFrontage\"].mean())","4e1cf4d0":"plt.figure(figsize  = (20, 5))\nplt.subplot(1, 2, 1)\nsns.distplot(applData['LotFrontage'].fillna(applData[\"LotFrontage\"].median()))\nplt.subplot(1, 2, 2)\nsns.distplot(applData['LotFrontage'].fillna(applData[\"LotFrontage\"].mean()))","3590cf47":"print(\"Missing Values Before: \", applData['LotFrontage'].isnull().sum())\napplData['LotFrontage'].fillna(applData[\"LotFrontage\"].median(), inplace=True)\nprint(\"Missing Values After: \", applData['LotFrontage'].isnull().sum())","85b01cf9":"print(applData['MasVnrType'].value_counts())\nprint(\"Mode: \", applData[\"MasVnrType\"].mode())","68d251d3":"print(\"Missing Values Before: \", applData['MasVnrType'].isnull().sum())\napplData['MasVnrType'].fillna('None', inplace=True)\nprint(\"Missing Values After: \", applData['MasVnrType'].isnull().sum())","5169fb3f":"print(applData['MasVnrArea'].value_counts())","2f8f47ca":"print(\"Missing Values Before: \", applData['MasVnrArea'].isnull().sum())\napplData['MasVnrArea'].fillna(0, inplace=True)\nprint(\"Missing Values After: \", applData['MasVnrArea'].isnull().sum())","700ab598":"print(applData['BsmtQual'].value_counts())","a3f2121e":"print(\"Missing Values Before: \", applData['BsmtQual'].isnull().sum())\napplData['BsmtQual'].fillna('NA', inplace=True)\nprint(\"Missing Values After: \", applData['BsmtQual'].isnull().sum())\n\n#For BsmtExposure and BsmtFinType1 apply the same rule as BsmtQual\napplData['BsmtExposure'].fillna('NA', inplace=True)\napplData['BsmtFinType1'].fillna('NA', inplace=True)\n","bd3acbd7":"print(applData['GarageType'].value_counts())","555e35a2":"print(\"Missing Values Before: \", applData['GarageType'].isnull().sum())\napplData['GarageType'].fillna('NA', inplace=True)\napplData['GarageFinish'].fillna('NA', inplace=True)\nprint(\"Missing Values After: \", applData['GarageType'].isnull().sum())\n\n","f819621a":"print(applData['GarageYrBlt'].value_counts())","6e6306f3":"import datetime\n\ntoday = datetime.datetime.now()\nprint(\"Missing Values Before: \", applData['GarageYrBlt'].isnull().sum())\napplData['GarageYrBlt'].fillna(today.year+1, inplace=True) #Set to future date\nprint(\"Missing Values After: \", applData['GarageYrBlt'].isnull().sum())\n","e942c0f4":"pctDF = (applData.isnull().sum()\/len(applData) * 100).reset_index()\npctDF.columns = ['Columns','Missing Value Percentage']\npctDF = pctDF[pctDF['Missing Value Percentage'] > 0]\npctDF","0220967d":"applData.head()","08d30b6b":"columns = ['LotArea','LotFrontage','MasVnrArea','WoodDeckSF','OpenPorchSF','GrLivArea','TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'BsmtFinSF1']\n\nplt.figure(figsize  = (15,30))\nfor i in enumerate(columns):\n    plt.subplot(10, 3, i[0]+1)\n    sns.boxplot(data=applData, x=i[1])","d86ef91e":"def treatOutliers(col, df):\n    q4 = df[col].quantile(0.99)\n    df[col][df[col] >=  q4] = q4\n    \n    q1 = df[col].quantile(0.01)\n    df[col][df[col] <=  q1] = q1\n    \n    return df","a17afbe3":"columns = ['LotArea','LotFrontage','MasVnrArea','WoodDeckSF','OpenPorchSF','GrLivArea','TotalBsmtSF', 'BsmtFinSF1', '1stFlrSF']\nfor col in columns:\n    applData = treatOutliers(col, applData)","7c58caee":"plt.figure(figsize  = (15,30))\nfor i in enumerate(columns):\n    plt.subplot(10, 3, i[0]+1)\n    sns.boxplot(data=applData, x=i[1])","7d85e88f":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumdf = applData.select_dtypes(include=numerics)\n\nplt.figure(figsize  = (15,30))\nfor i in enumerate(numdf.columns.drop('SalePrice')):\n    plt.subplot(15, 3, i[0]+1)\n    sns.distplot(applData[i[1]])","4a324883":"applData.head()","b1b55642":"cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nplt.figure(figsize  = (15,30))\nsns.pairplot(applData[cols], size = 2.5)\nplt.show();","d8d89009":"plt.figure(figsize  = (15,50))\nfor i in enumerate(numdf.columns.drop('SalePrice')):\n    plt.subplot(15, 3, i[0]+1)\n    sns.scatterplot(x = applData[i[1]], y = applData['SalePrice'])\n","4456e5c6":"from scipy.stats import probplot\n\nplt.figure(figsize  = (15, 10))\nplt.subplot(2, 2, 1)\nsns.distplot(applData['SalePrice'])\nplt.subplot(2, 2, 2)\nres = probplot(applData['SalePrice'], plot=plt)","ef618d94":"plt.figure(figsize  = (15, 10))\nplt.subplot(2, 2, 1)\nsns.distplot(applData['SalePrice'])\nplt.subplot(2, 2, 2)\nres = probplot(np.log(applData['SalePrice']), plot=plt)","2ddf8266":"def makeValuesAsOther(df, col, percent):\n    print('Before')\n    print(df[col].value_counts()\/len(df)*100)\n    \n    values = (df[col].value_counts()\/len(df)*100).reset_index()\n    values = values[values[col] < percent][\"index\"]\n\n    for i in values:\n        df[col].replace(i, 'Other', inplace=True)\n        \n    print('After')\n    print(df[col].value_counts()\/len(df)*100)    ","2253922f":"makeValuesAsOther(applData, \"Neighborhood\", 2)","cddb1700":"makeValuesAsOther(applData, \"HouseStyle\", 10)","615e5599":"makeValuesAsOther(applData, \"Exterior1st\", 6)","92f55149":"makeValuesAsOther(applData, \"Exterior2nd\", 6)","37919db2":"applData.head()","23ba6f8d":"today = datetime.datetime.now()\n\ncolumns = ['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold']\n\nfor col in columns:\n    applData[col+'Age'] = today.year - applData[col]\n\napplData.drop(columns = columns, inplace=True)","6cd41202":"applData.head()","0c2f2d92":"valMap1 = {\"NA\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}\napplData['ExterQual'] = applData['ExterQual'].map(valMap1)\napplData['BsmtQual'] = applData['BsmtQual'].map(valMap1)\napplData['HeatingQC'] = applData['HeatingQC'].map(valMap1)\napplData['KitchenQual'] = applData['KitchenQual'].map(valMap1)\n\nvalMap2 = {\"NA\": 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4}\napplData['BsmtExposure'] = applData['BsmtExposure'].map(valMap2)","bd80052b":"applData.head()","a3cc075f":"corr = applData.corr()\ncorr = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\ncorr_df = corr.unstack().reset_index()\ncorr_df.columns = ['Variable1', 'Variable2', 'Correlation']\ncorr_df.dropna(subset = ['Correlation'], inplace=True)\ncorr_df['Correlation'] = round(corr_df['Correlation'].abs(), 2)\ncorr_df.sort_values(by = 'Correlation', ascending=False).head(10)","a8384e0d":"plt.figure(figsize  = (30,20))\nsns.heatmap(applData.corr(), annot=True, cmap='RdYlGn')","2acc5256":"columns = ['LotShape', 'LotConfig', 'Neighborhood', 'HouseStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'BsmtFinType1', 'GarageType', 'GarageFinish']\n\napplData = pd.get_dummies(data=applData, columns=columns, drop_first=True)\n\napplData.head()","582de8ae":"stdScaler = StandardScaler()\n\ncolumns = ['MSSubClass','LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtUnfSF',\n           'TotalBsmtSF','1stFlrSF','2ndFlrSF','GrLivArea','GarageArea','WoodDeckSF','OpenPorchSF', \n           'MoSold','YearBuiltAge','YearRemodAddAge','GarageYrBltAge','YrSoldAge','OverallQual','OverallCond',\n           'ExterQual','BsmtQual','BsmtExposure','HeatingQC','FullBath','BedroomAbvGr','KitchenQual','TotRmsAbvGrd',\n           'BsmtFullBath','HalfBath','Fireplaces','GarageCars']\napplData[columns] = stdScaler.fit_transform(applData[columns])\n\napplData.head()","5856196a":"# Futher divide the dataset in X_train and y_train\ny_train = applData.pop('SalePrice')\nX_train = applData","b7037975":"linreg = LinearRegression()\nrfe = RFE(linreg, n_features_to_select=25 )\nrfe = rfe.fit(X_train, y_train)","dc7e8001":"#useful columns according to rfe\nuseful_cols = X_train.columns[rfe.support_]\nuseful_cols","3c764a01":"# Not useful columns according to rfe\nX_train.columns[~rfe.support_]","091e3039":"X_train_rfe = X_train[useful_cols]\nX_train_rfe.head()","55ad15a7":"params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0,9.0,10.0,20.0,30.0,50.0,100.0 ]}\n\nridge = Ridge()\n\nfolds = 5\nmodel_cv = GridSearchCV(estimator = ridge, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \nmodel_cv.fit(X_train_rfe, y_train)","71cf98d9":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results = cv_results[cv_results['param_alpha']<=200]\ncv_results.head()","8dbe7f35":"cv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\n\n# plotting\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper right')\nplt.show()","4ad25d97":"model_cv.best_estimator_","a8d78cd0":"alpha = model_cv.best_estimator_.alpha\nridge = Ridge(alpha=alpha)\n\nridge.fit(X_train_rfe, y_train)\nridge.coef_","7069a36c":"def score(y_pred, y_true):\n    error = np.square(np.log10(y_pred +1) - np.log10(y_true +1)).mean() ** 0.5\n    score = 1 - error\n    return score","bc0df5d5":"y_pred = ridge.predict(X_train_rfe)\nprint(\"Ridge Score: \", round(score(y_pred, y_train)*100, 2), \"%\")","f07b161c":"ridgeCoefDF = pd.DataFrame()\nridgeCoefDF['Column'] = X_train_rfe.columns\nridgeCoefDF['Coef'] = ridge.coef_\nridgeCoefDF['Coef_Absolute'] = abs(ridgeCoefDF['Coef'])\nridgeCoefDF = ridgeCoefDF.sort_values(by = 'Coef_Absolute', ascending=False)\nridgeCoefDF.head(10)","a4c45dac":"params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600, 700 ]}\n\nlasso = Lasso()\n\nmodel_cv = GridSearchCV(estimator = lasso, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \n\nmodel_cv.fit(X_train_rfe, y_train) ","b5681492":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results = cv_results[cv_results['param_alpha'] <= 1000]\ncv_results.head()","b0b2e61a":"cv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\n\n# plotting\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper right')\nplt.show()","e4476e4b":"model_cv.best_estimator_","654ce75a":"alpha = model_cv.best_estimator_.alpha\nlasso = Lasso(alpha=alpha)\n\nlasso.fit(X_train_rfe, y_train)\nlasso.coef_","cdd28545":"y_pred = lasso.predict(X_train_rfe)\nprint(\"Lasso Score: \", round(score(y_pred, y_train)*100, 2), \"%\")","9d1c663d":"lassoCoefDF = pd.DataFrame()\nlassoCoefDF['Column'] = X_train_rfe.columns\nlassoCoefDF['Coef'] = lasso.coef_\nlassoCoefDF['Coef_Abs'] = abs(lassoCoefDF['Coef'])\nlassoCoefDF = lassoCoefDF.sort_values(by = 'Coef_Abs', ascending=False)\nlassoCoefDF.head(10)","1f6a2d0e":"testData.head()","37e67793":"#Apply same rules in Test Data\ntestData['LotFrontage'].fillna(testData[\"LotFrontage\"].median(), inplace=True)\n\ntestData['MasVnrType'].fillna('None', inplace=True)\n\ntestData['MasVnrArea'].fillna(0, inplace=True)\n\ntestData['BsmtQual'].fillna('NA', inplace=True)\ntestData['BsmtExposure'].fillna('NA', inplace=True)\ntestData['BsmtFinType1'].fillna('NA', inplace=True)\n\ntestData['GarageType'].fillna('NA', inplace=True)\ntestData['GarageFinish'].fillna('NA', inplace=True)\n\ntestData['GarageYrBlt'].fillna(today.year+1, inplace=True) #Set to future date","23378371":"makeValuesAsOther(testData, \"Neighborhood\", 2)\nmakeValuesAsOther(testData, \"HouseStyle\", 10)\nmakeValuesAsOther(testData, \"Exterior1st\", 6)\nmakeValuesAsOther(testData, \"Exterior2nd\", 6)","6ece762b":"today = datetime.datetime.now()\n\ncolumns = ['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold']\n\nfor col in columns:\n    testData[col+'Age'] = today.year - testData[col]\n\ntestData.drop(columns = columns, inplace=True)","39ee1dad":"valMap1 = {\"NA\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}\ntestData['ExterQual'] = testData['ExterQual'].map(valMap1)\ntestData['BsmtQual'] = testData['BsmtQual'].map(valMap1)\ntestData['HeatingQC'] = testData['HeatingQC'].map(valMap1)\ntestData['KitchenQual'] = testData['KitchenQual'].map(valMap1)\n\nvalMap2 = {\"NA\": 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4}\ntestData['BsmtExposure'] = applData['BsmtExposure'].map(valMap2)","56d52566":"columns = ['LotShape', 'LotConfig', 'Neighborhood', 'HouseStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'BsmtFinType1', 'GarageType', 'GarageFinish']\n\ntestData = pd.get_dummies(data=testData, columns=columns, drop_first=True)","1a92ca54":"columns = ['MSSubClass','LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtUnfSF',\n           'TotalBsmtSF','1stFlrSF','2ndFlrSF','GrLivArea','GarageArea','WoodDeckSF','OpenPorchSF', \n           'MoSold','YearBuiltAge','YearRemodAddAge','GarageYrBltAge','YrSoldAge','OverallQual','OverallCond',\n           'ExterQual','BsmtQual','BsmtExposure','HeatingQC','FullBath','BedroomAbvGr','KitchenQual','TotRmsAbvGrd',\n           'BsmtFullBath','HalfBath','Fireplaces','GarageCars']\ntestData[columns] = stdScaler.fit_transform(testData[columns])\n","e2fbc006":"X_test = testData[X_train_rfe.columns]","be481cc2":"X_test.head()","b1f818be":"X_test['KitchenQual'].fillna(X_test['KitchenQual'].mean(), inplace=True)\nX_test['BsmtFinSF1'].fillna(X_test['BsmtFinSF1'].median(), inplace=True)\nX_test['TotalBsmtSF'].fillna(X_test['TotalBsmtSF'].median(), inplace=True)","5c228db1":"y_test_pred_ridge = ridge.predict(X_test)\ntestData['Predicted House Price Ridge'] = y_test_pred_ridge","ab302d88":"y_test_pred_lasso = lasso.predict(X_test)\ntestData['Predicted House Price Lasso'] = y_test_pred_lasso","0d6ab2b5":"testData.head()","4406273e":"submissionDF = testData[['Id','Predicted House Price Lasso']]\nsubmissionDF.columns = ['Id', 'SalePrice']\nsubmissionDF.head()","84cbbaff":"submission.head()","6c1c9fa0":"## Finding Outliers\n### check for only continuous variables","6bbcf30a":"## Ridge Regression \n#### Hyperparameter tuning for Alpha value","d3dd0bbc":"## Check for missing values again\n- No missing values found","471b1652":"# Final Conclusion","6818faec":"## Reducing the number of categories for categorical variables\n#### Find out the columns which have low percentage for some values and merge them to create new category called 'Others'\n#### This we will do only for those columns which have lot of categories, not required to do for all the categorical columns","ade2f232":"### Drop the Id column as it is not significant in explaining the House Price","d9208f3f":"## Calculate Age for Year related columns","3c62d8c4":"### Not much difference in imputing with Median on Mean\n- Lets go with median to avoid float values","1cbcc306":"## Evaluate Model on Test Data","6e113df3":"### Top 10 highly corelated variables","3f07aaa6":"## Converting Text categories to weight based based Categories","08adebd3":"## Conclusion:\n- Accuracy of the Ridge Model is 91.9%\n- Above Top 10 feature are the deciding factor for House Sale Price","89f8b866":"# Exploratory Data Analysis","9c5143ab":"- Intereshing to see 'TotalBsmtSF' vs 'GrLiveArea'. This plot tell that the dots drawing a linear line, which almost looks like a border and most of the dots are below that line. This tells that Basement areas is equal to the ground living area, but it is not expected a basement area bigger than the above ground living area unless you are building a GIZAs pyramid ","beb77ff2":"## Bivariate Analysis\n### Generate the Pairplot for Some of the variable to understand the linear relationship\n- The plot 'SalePrice' vs 'YearBuilt' shows how Yearbuilt can explain the house prices. In the left bottom corner, the scatter plot 'dots cloud' can tell us that Sale prices are rising exponentially as the YearBuilt comes closer to present","dbb331b9":"### MasVnrArea is numerical variable\n#### Replace null values with 0 because MasVnrType is None for these rows, so its meaningful missing.","15591a9d":"## Generate dummy columns for categorical variables","470ae749":"## Most Important Features based on Ridge Regression","5c466e1e":"### Co-relation between variables\n- More redish means highly negatively co-related variables (one of them could play role in explaining the house prices)\n- More greenish means higly positively co-related variables (one of them could play role in explaining the house prices)\n- yellowish means less co-related (so highly significant variables and may play major role together in explaining the house prices)","bd0f9029":"## Conclusion:\n- Accuracy of the Ridge Model is 91.35%\n- Above Top 10 feature are the deciding factor for House Sale Price","f997d96e":"# Model Building and Evaluation","aa516237":"## Check the distribution of Log transformation on target variable and normally distribute the data.","172e3f06":"##  Check the distribution of data for all the columns in comparion to Target Variable SalePrice","218fc078":"# Check Target Variable distribution","14d031b0":"### MasVnrType is categorical variable\n#### Replace null values with Mode or \"None\" value, both of them are None","1ce32fb0":"### GarageYrBlt is Numerical Variable\n#### Missing values are \"meaningful\" missing, lets impute the value as future date (2021)\n#### Later we can create age of the Garage and bin them. For -ve values we can create \"NA\" bin later","52432174":"## Univariate Analysis","c879541c":"### Find the columns for which more than 45% the values are missing, they will not be able to explain the housing prices correctly ","170fd9a5":"## Select only useful columns","f06d7a09":"### Best Alpha Value for Ridge Regression is 20\n\n### Accuracy Score\n- Ridge Accuracy Score: 91.35\n- Lasso Accuracy Score: 91.90\n\n### Features which are the deciding factor for House Sale price are\n- BsmtFinType1 (No Basement)\n- 2ndFlrSF\n- Neighborhood (North Ridge)\n- 1stFlrSF\n- Neighborhood (Northridge Heights)\n- Neighborhood (Crawford)\n- GrLivArea\n- OverallQual\n- GarageType (BuiltIn)\n- LotConfig (Cul-de-sac)","a2a83a2e":"## Imputing the Missing values\n- Find the features for which we have some missing values\n- Impute the Numerical column values with either mean or median","6f886a92":"### GarageType, GarageFinish are Categorical Variable\n#### Missing values are \"meaningful\" missing so replace n\/a with NA (No Basement)","e4639a6f":"## Treating the outliers\n- There are two ways to treat the outliers\n    - Delete those rows\n    - Impute the values based on inter quartile range (IQR)\n- I will use soft outlier treatment to avoid any information loss.","6482d38c":"### BsmtQual, BsmtExposure, BsmtFinType1 are Categorical Variables\n#### Missing values are \"meaningful\" missing so replace n\/a with NA (No Basement)","a717f128":"## From the graph above Optimal Alpha value seems to be 20\n- Train score is improving till alpha=20 and suddenly dropping bigger alpha values\n- Test score is improving till alpha=20 and dropping for bigger values later\n- So we will choose alpha=20 as optimal value\n\n### Compute the accuracy score of Ridge Model using alpha=20","1ea6e79a":"## Lasso Regression","929b9b17":"#### Few Important observation using this Scatter plot\n- As the Living Area grade is increasing SalePrice is also increasing\n- As the ","ad05e846":"## From Above alpha vs NMAE plot, it seems optimal alpha value is 200\n- Train score is almost flat till alpha=200 and suddenly dropping bigger alpha values\n- Test score is improving till alpha=200 and suddenly dropping for bigger values later\n- So we will choose alpha=200 as optimal value\n\n### Compute the accuracy score of Lasso Model using alpha=200","46b48ce4":"## Check Skewness in the data\n- Drop highly skewed categorical variables where one value has more than 75% share of the values\n- These kind of variables are not ideal in building the model and will not be able to explain the house prices because anyways these feautre will be removed during Recursive feature elimination","5a2287a6":"# Data Cleaning","a36d80cb":"### Check the distribution of data for numerical columns","d7dc7802":"# Data Preparation","d24d995d":"## Feature selection using RFE","73c5f5f0":"- The plot 'TotalBsmntSF' vs 'SalesPrices' can also explain the house prices, that Sale prices are rising linearly as Basement Area is increasing","e07eb9a2":"## Scale the Numerical variables"}}