{"cell_type":{"efaac6f2":"code","70929e69":"code","b1c2931d":"code","8f6b61ae":"code","ba80d24a":"code","0586c575":"code","cd69ee61":"code","6d7309f3":"code","a8c3f9c6":"code","0597d8c1":"code","701a2402":"code","a9f25641":"code","b1b069ad":"code","26d1ffbf":"code","e68f6cb7":"code","cf97c360":"code","6cfd368f":"code","d210e258":"code","062af787":"code","923e5a0b":"markdown","e105ea87":"markdown","afb5983d":"markdown","8e254f01":"markdown","12dbe789":"markdown","22389b81":"markdown","9c5cfb76":"markdown","8d9888d1":"markdown","594ab665":"markdown","55ef2104":"markdown","6e55e269":"markdown","6c31eed1":"markdown"},"source":{"efaac6f2":"import pydicom\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport pandas as pd\nimport PIL\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport glob\nimport os\nimport cv2\nfrom skimage import measure\nimport scipy\nfrom plotly.tools import FigureFactory as FF\nfrom plotly.graph_objs import *\nfrom scipy.ndimage import zoom\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.express as px\n","70929e69":"def load_scan(path):\n    slices = [pydicom.read_file(path+\"\/\"+s) for s in os.listdir(path) ]\n    slices.sort(key = lambda x: int(x.AcquisitionNumber))\n    try:\n        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n    except:\n        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n        \n    for s in slices:\n        s.SliceThickness = slice_thickness\n        s.SamplesPerPixel = 1\n        \n    return slices\n\ndef get_pixels_hu(scans):\n    image = np.stack([s.pixel_array for s in scans[:100]])\n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16)\n    # Set outside-of-scan pixels to 1\n    # The intercept is usually -1024, so air is approximately 0\n    image[image == -2000] = 0\n    # Convert to Hounsfield units (HU)\n    intercept = scans[0].RescaleIntercept\n    slope = scans[0].RescaleSlope\n    \n    if slope != 1:\n        image = slope * image.astype(np.float64)\n        image = image.astype(np.int16)\n        \n    image += np.int16(intercept)\n    \n    return np.array(image, dtype=np.int16)\ndef make_mesh(image,threshold=100):\n    print( \"Transposing surface\")\n    p = image.transpose(2,1,0)\n    print( \"Calculating surface\")\n    verts, faces, norm, val = measure.marching_cubes_lewiner(p, threshold) \n    return verts, faces\n\ndef plotly_3d(verts, faces):\n    x,y,z = zip(*verts)   \n    print(\"Drawing\")\n    # Make the colormap single color since the axes are positional not intensity. \n    colormap=['rgb(255,105,180)','rgb(255,255,51)','rgb(0,191,255)']\n    #colormap = ['rgb(100,149,237)','rgb(100,149,237)']\n    #mesh.set_facecolor(face_color)\n    fig = FF.create_trisurf(x=x,\n                        y=y, \n                        z=z, \n                        plot_edges=False,\n                        colormap=colormap,\n                        simplices=faces,\n                        backgroundcolor='rgb(64, 64, 64)',\n                        title=\"Interactive Visualization\")\n    iplot(fig)\ndef get_y(df):\n    dic = {True:1,False:0}\n    df['Contrast'] = df['Contrast'].map(dic)\n    y =df['Contrast'].values\n    return y\n\npath =  \"\/kaggle\/input\/siim-medical-images\/dicom_dir\/\"\n#id=0\npatient = load_scan(path)\nimgs = get_pixels_hu(patient)","b1c2931d":"fig = plt.figure(figsize=(20,20))\nfor num,image in enumerate(imgs[:12]):\n    ax = fig.add_subplot(3,4,num+1)\n    ax.imshow(image, cmap=plt.cm.bone)\n    ax.set_title(f\"The age of this patient:{patient[num].PatientAge}\\nAnd is a {patient[num].PatientSex}\")\nplt.show()","8f6b61ae":"img = np.copy(imgs[0])\nfig = px.histogram(x=img.flatten())\nfig.show()","ba80d24a":"seg1 = (img<-2000)\nseg2 = (img>-2000) & (img<-1000)\nseg3 = (img>-1000) & (img<-500)\nseg4 = (img>-500)\nall_seg = np.zeros((img.shape[0],img.shape[1],3))\nall_seg[seg1] = (1,0,0)\nall_seg[seg2] = (0,1,0)\nall_seg[seg3] = (0,0,1)\nall_seg[seg4] = (1,1,0)\n#plt.imshow(all_seg)\n#plt.show()\nfig = px.imshow(all_seg)\nfig.show()","0586c575":"all_seg[seg1] = (1,1,1)\nall_seg[seg2] = (1,1,1)\nall_seg[seg3] = (0,0,1)\nall_seg[seg4] = (1,1,1)\nkernel = np.ones((2,2),np.uint8)\nerosion = cv2.erode(all_seg,kernel,iterations = 1)\ndilation = cv2.dilate(all_seg,kernel,iterations = 1)\nfig = px.imshow(all_seg,color_continuous_scale='gray')\nfig.show()","cd69ee61":"img = cv2.rectangle(all_seg,(50,80),(446,389),(0,0,255),2)\nplt.imshow(img,cmap=plt.cm.bone)\nplt.show()","6d7309f3":"img1 = np.copy(imgs[0])\nimg1[img1>=-500] = 255\nimg1[img1<=-1000]=255\nkernel = np.ones((2,2),np.uint16)\nerosion = cv2.erode(img1,kernel,iterations = 2)\nplt.imshow(erosion,cmap=plt.cm.gray)\nplt.show()","a8c3f9c6":"edged=cv2.Canny(erosion.astype(np.uint8),30,200)\nplt.imshow(edged,plt.cm.bone)\nplt.show()","0597d8c1":"kernel = np.ones((5,5),np.uint8)\nx,y,w,h =  50,80,446,389\nROI = erosion[y:h, x:w]\n#plt.imshow(ROI,plt.cm.bone)\n# Iterate thorugh contours and filter for ROI\nfig = px.imshow(ROI,color_continuous_scale=\"gray\")\nfig.show()","701a2402":"zoomed = zoom(imgs.astype(np.float32), 0.25)\nv, f = make_mesh(zoomed,threshold=-350)\nplotly_3d(v, f)\nvolume=zoomed","a9f25641":"r, c = volume[6].shape\n# Define frames\nimport plotly.graph_objects as go\nnb_frames = 25\nfig = go.Figure(frames=[go.Frame(data=go.Surface(\n    z=(6.7 - k * 0.1) * np.ones((r, c)),\n    surfacecolor=np.flipud(volume[24 - k]),\n    cmin=0, cmax=200\n    ),\n    name=str(k) \n    )\n    for k in range(nb_frames)])\n\n# Add data to be displayed before animation starts\nfig.add_trace(go.Surface(\n    z=6.7 * np.ones((r, c)),\n    surfacecolor=np.flipud(volume[24]),\n    colorscale=\"gray\",\n    cmin=0, cmax=200,\n    colorbar=dict(thickness=20, ticklen=4)\n    ))\n\n\ndef frame_args(duration):\n    return {\n            \"frame\": {\"duration\": 1500},\n            \"mode\": \"immediate\",\n            \"fromcurrent\": True,\n            \"transition\": {\"duration\": 1500, \"easing\": \"linear\"},\n        }\n\nsliders = [\n            {\n                \"pad\": {\"b\": 10, \"t\": 60},\n                \"len\": 0.9,\n                \"x\": 0.1,\n                \"y\": 0,\n                \"steps\": [\n                    {\n                        \"args\": [[f.name], frame_args(0)],\n                        \"label\": str(k),\n                        \"method\": \"animate\",\n                    }\n                    for k, f in enumerate(fig.frames)\n                ],\n            }\n        ]\n\nfig.update_layout(\n         title='Slices in volumetric ',\n         width=600,\n         height=600,\n         scene=dict(\n                    zaxis=dict(range=[-0.1, 6.8], autorange=False),\n                    aspectratio=dict(x=1, y=1, z=1),\n                    ),\n         updatemenus = [\n            {\n                \"buttons\": [\n                    {\n                        \"args\": [None, frame_args(50)],\n                        \"label\": \"&#9654;\", \n                        \"method\": \"animate\",\n                    },\n                    {\n                        \"args\": [[None], frame_args(0)],\n                        \"label\": \"&#9724;\", # pause symbol\n                        \"method\": \"animate\",\n                    },\n                ],\n                \"direction\": \"left\",\n                \"pad\": {\"r\": 10, \"t\": 70},\n                \"type\": \"buttons\",\n                \"x\": 0.1,\n                \"y\": 0,\n            }\n         ],\n         sliders=sliders\n)\nfig.show()","b1b069ad":"df = pd.read_csv('\/kaggle\/input\/siim-medical-images\/overview.csv')\ndf.head()","26d1ffbf":"y = get_y(df)","e68f6cb7":"model = tf.keras.models.Sequential()\nmodel.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(512, 512, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(2))","cf97c360":"model.summary()","6cfd368f":"X = imgs.reshape([-1,512, 512,1])\ntrain_ds = tf.data.Dataset.from_tensor_slices(\n    (X, y)).shuffle(10000).batch(100)\nXtrain,ytrain = [],[]\nfor i ,g in train_ds:\n    Xtrain.append(i)\n    ytrain.append(g)","d210e258":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.sparse_categorical_crossentropy,\n              metrics=['accuracy'])\n\nhistory = model.fit(Xtrain,ytrain, epochs=10, \n                    validation_split=0.1)","062af787":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=history.epoch, y=history.history['accuracy'],line_color='rgb(231,107,243)',\n    name='Accuracy',fill='tonexty'))\nfig.add_trace(go.Scatter(x=history.epoch, y=history.history['val_accuracy'],line_color='yellow',opacity=0.1,\n    name='val_accuracy',fill='tozeroy'))\nfig.update_layout(\nLayout(\n    paper_bgcolor='black',\n    plot_bgcolor='black'),title_text=' Ops! The Sise of the data is so tiny  ')\n\nfig.update_traces(mode='lines')\nfig.show()","923e5a0b":"\nAnother way to do this is manualy fransform the image to gray and apply morphological transformation (erosion) to move white pixels from the Lung.","e105ea87":"> ***Loading the data and defining helper  functions***","afb5983d":"And finally extract the ROI","8e254f01":"Lat's visualize some images so we can have an idea on what we are dealing with.","12dbe789":">Surface randering\n\nUsing Marching Cubes algorithm we can represent the 2D into 3D surface","22389b81":"Each peak on this histogram depict an object. To better understand let's visualize the image by setting different color to each element base on the histograme.    ","9c5cfb76":"This DICOM files is subset of images from the cancer imaging archive. They consist of slice of all CT images taken where valid age, modality, and contrast tags could be found. The scope of this kernel is demostrate how to use some python libraries for medical imaaging tasks such segmentation 3D visualisation, volume rendering......\n> Imporing required libraries","8d9888d1":">Segmentation\n\nNow let's say that we are intrested at the Lung which s reprsented with blue color, there are many way to extract it such as passband filter by attenuating all frequancies out of the range [-1000 ,-500] likewise we can merely set the rest white ","594ab665":"Look at the edged","55ef2104":"This CT scans contain a lot of information such as Air, Fat,Lug... that can be extract using Hounsfield unit (HU) values. For if we are intrestd at the Lug is it easy to performe segmentation base on the histograme below. ","6e55e269":"And Draw a rectangle to the region of interest ","6c31eed1":"**Let's try to Classify this images using contrast as labels**"}}