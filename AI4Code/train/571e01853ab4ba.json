{"cell_type":{"161ce0d0":"code","8be92819":"code","c1e4e1c2":"code","254bd02e":"code","0a3af248":"code","3a07d43f":"code","126ed2c0":"code","0e1e0ca4":"code","996f3f3d":"code","f95b6763":"code","24780d79":"code","3701c549":"code","8a8b4b7e":"code","8357cfe2":"code","d9bb5781":"code","962368e0":"code","e3127104":"code","733d3784":"code","86bd9d70":"code","fe875760":"code","84bf950f":"code","65051b29":"code","97f6fbe7":"code","723ba1d5":"code","ac046e5a":"code","83a5dbd3":"code","85cacf65":"code","22d99e5a":"code","b417e267":"code","063b41a5":"code","a4f4d051":"markdown","0769cc8f":"markdown","f299fe17":"markdown","6dbfdc54":"markdown"},"source":{"161ce0d0":"# Importing libraries \n\nimport pandas as pd\nimport numpy as np","8be92819":"df = pd.read_csv('..\/input\/melbourne-housing-snapshot\/melb_data.csv')\n# Displaying first five records of datset\n\ndf.head()","c1e4e1c2":"# Displays dimension of the dataset i.e no. of rows and columns\n\ndf.shape","254bd02e":"df.info()","0a3af248":"# Describe the dataset\n\ndf.describe()","3a07d43f":"num_col = df.select_dtypes(include=np.number).columns\nprint(\"Numerical columns: \\n\",num_col)\n\ncat_col = df.select_dtypes(exclude=np.number).columns\nprint(\"Categorical columns: \\n\",cat_col)","126ed2c0":"# Visualize missing values\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfig, ax = plt.subplots(figsize=(15,7))\nsns.set(font_scale=1.2)\nsns.heatmap(df.isnull(),yticklabels = False, cbar = False, cmap = 'Greys_r')\nplt.show()","0e1e0ca4":"\ndf.isnull().sum()","996f3f3d":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(4,4))\nplt.title('Price Distribution Plot')\nsns.distplot(df['Price'])\n\n# Let's check the distribution of y variable\nplt.figure(figsize=(4,4), dpi= 80)\nsns.boxplot(df['Price'])\nplt.title('Price')\nplt.show()","f95b6763":"#separate the numeric columns from the categorical columns\n\n# select numerical columns\ndata_numeric = df.select_dtypes(include=[np.number])\nnumeric_cols = data_numeric.columns.values\n# select non-numeric columns\ndata_non_numeric = df.select_dtypes(exclude=[np.number])\nnon_numeric_cols = data_non_numeric.columns.values","24780d79":"data_numeric = data_numeric.drop(columns='Postcode')\ndata_numeric = data_numeric.drop(columns='BuildingArea')\ndata_numeric = data_numeric.drop(columns='YearBuilt')\ndata_numeric.head()\n","3701c549":"from sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=5)\ndata_numeric = pd.DataFrame(imputer.fit_transform(data_numeric),columns = data_numeric.columns)","8a8b4b7e":"data_numeric.isna().any()","8357cfe2":"# Importing\nimport sklearn\nimport pandas as pd\n\n\n''' Detection '''\n# IQR\nQ1 = np.percentile(data_numeric ['Price'], 25, interpolation = 'midpoint')\n\nQ3 = np.percentile(data_numeric ['Price'], 75, interpolation = 'midpoint')\nIQR = Q3 - Q1\nprint (IQR)\nprint(\"Old Shape: \", data_numeric.shape)\n\n# Upper bound\nupper = np.where(data_numeric['Price'] >= (Q3+1.5*IQR))\n# Lower bound\nlower = np.where(data_numeric['Price'] <= (Q1-1.5*IQR))\n\n''' Removing the Outliers '''\ndata_numeric.drop(upper[0], inplace = True)\ndata_numeric.drop(lower[0], inplace = True)\n\nprint(\"New Shape: \", data_numeric.shape)\n","d9bb5781":"data_numeric.head()","962368e0":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(4,4))\nplt.title('Price Distribution Plot')\nsns.distplot(data_numeric['Price'])\n\n# Let's check the distribution of y variable\nplt.figure(figsize=(4,4), dpi= 80)\nsns.boxplot(data_numeric['Price'])\nplt.title('Price')\nplt.show()","e3127104":"plt.figure(figsize=(10,6))\nsns.heatmap(data_numeric.corr(),cmap = 'coolwarm',linewidth = 1,annot= True, annot_kws={\"size\": 9})\nplt.title('Variable Correlation')\nplt.show()","733d3784":"dl = df[['Regionname', 'Suburb', 'Price', 'Lattitude', 'Longtitude']].groupby(by=['Regionname', 'Suburb']).mean()\ndl_region = [i for i, j in dl.index]\ndl_suburb = [j for i, j in dl.index]\n\ndl['Region'] = dl_region\ndl['Suburb'] = dl_suburb\ndl = dl.reset_index(drop=True)\n\nfig, ax = plt.subplots(2, 1, figsize=(12, 16))\nsns.scatterplot(data=df, x='Lattitude', y='Longtitude', hue='Type', size='Rooms', ax=ax[0])\nax[0].set_title('The House Location')\nsns.scatterplot(data=dl, x='Lattitude', y='Longtitude', hue='Region', ax=ax[1])\nax[1].set_title('The Suburb Location')\nplt.tight_layout()","86bd9d70":"\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nmelb_target = data_numeric.Price\nmelb_predictors = data_numeric.drop(['Price'], axis=1)\n\n","fe875760":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(melb_predictors, \n                                                    melb_target,\n                                                    train_size=0.7, \n                                                    test_size=0.3, \n                                                    random_state=0)","84bf950f":"print (len(X_train))\nprint (len(X_test))","65051b29":"from sklearn.preprocessing import StandardScaler\n\n# Scale the data to be between -1 and 1\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","97f6fbe7":"model = RandomForestRegressor(n_jobs=-1)","723ba1d5":"estimators = np.arange(10, 200, 10)\n#scores = []\ndef score_dataset(X_train, X_test, y_train, y_test):\n    model = RandomForestRegressor()\n   #model.set_params(n_estimators=n)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    #scores.append(model.score(X_test, y_test))\n    return mean_absolute_error(y_test, preds)","ac046e5a":"print(\"Mean Absolute Error from Imputation while Track What Was Imputed:\")\nprint(score_dataset(X_train, X_test, y_train, y_test))","83a5dbd3":"# Try different numbers of n_estimators - this will take a minute or so\nestimators = np.arange(10, 200, 10)\nscores = []\nfor n in estimators:\n    model.set_params(n_estimators=n)\n    model.fit(X_train, y_train)\n    scores.append(model.score(X_test, y_test))\nplt.title(\"Effect of n_estimators\")\nplt.xlabel(\"n_estimator\")\nplt.ylabel(\"score\")\nplt.plot(estimators, scores)","85cacf65":"model.score(X_train,y_train)","22d99e5a":"model.score(X_test,y_test)","b417e267":"import pickle\nfilename = 'finalized_model.sav'\npickle.dump(model, open(filename, 'wb'))","063b41a5":"loaded_model = pickle.load(open(filename, 'rb'))\nresult = loaded_model.score(X_test, y_test)\nprint(result)","a4f4d051":"# Removing Outliers","0769cc8f":"# 4.Data Pre-processing","f299fe17":"Cleaning \/ Filling Missing Data\nPandas provides various methods for cleaning the missing values.\nThe fillna function can \u201cfill in\u201d NA values with non-null data in a couple of ways\n\n\n\n*   Replace NaN with a Scalar Value\n\n*   Replacing \"NaN\" with \"0\".","6dbfdc54":"# Removing Null values"}}