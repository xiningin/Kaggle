{"cell_type":{"0430881e":"code","12190ef0":"code","231e9b2c":"code","e5240734":"code","2caf5f99":"code","999d83f0":"code","563c3cab":"code","0a85b538":"code","3a389884":"code","4d3866a7":"code","f321daac":"code","21308d22":"markdown","7a417f26":"markdown"},"source":{"0430881e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom tensorflow.keras.applications import VGG16, InceptionResNetV2\nfrom keras import regularizers\nfrom tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax","12190ef0":"train_dir = \"..\/input\/emotion-detection-fer\/train\" \ntest_dir = \"..\/input\/emotion-detection-fer\/test\"   ","231e9b2c":"import tensorflow as tf\nimport keras\nfrom keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\nmodel= tf.keras.models.Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48,1)))\nmodel.add(Conv2D(64,(3,3), padding='same', activation='relu' ))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128,(5,5), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n    \nmodel.add(Conv2D(512,(3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(512,(3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten()) \nmodel.add(Dense(256,activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n    \nmodel.add(Dense(512,activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(7, activation='softmax'))","e5240734":"img_size=48","2caf5f99":"train_datagen = ImageDataGenerator(width_shift_range = 0.1,\n                                         height_shift_range = 0.1,\n                                         horizontal_flip = True,\n                                         rescale = 1.\/255,\n                                         validation_split = 0.2\n                                        )\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                         validation_split = 0.2)","999d83f0":"train_generator = train_datagen.flow_from_directory(directory = train_dir,\n                                                    target_size = (img_size,img_size),\n                                                    batch_size = 64,\n                                                    color_mode = \"grayscale\",\n                                                    class_mode = \"categorical\",\n                                                    subset = \"training\"\n                                                   )\nvalidation_generator = validation_datagen.flow_from_directory( directory = test_dir,\n                                                              target_size = (img_size,img_size),\n                                                              batch_size = 64,\n                                                              color_mode = \"grayscale\",\n                                                              class_mode = \"categorical\",\n                                                              subset = \"validation\"\n                                                             )","563c3cab":"model.compile(\n    optimizer = Adam(lr=0.001), \n    loss='categorical_crossentropy', \n    metrics=['accuracy']\n  )","0a85b538":"epochs = 45\nbatch_size = 64","3a389884":"history = model.fit(x = train_generator,epochs = epochs,validation_data = validation_generator)","4d3866a7":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","f321daac":"model.save_weights('model_weights_FER.h5')","21308d22":"The dataset contain 35,685 examples of 48x48 pixel gray scale images of faces divided into train and test dataset. Images are categorized based on the emotion shown in the facial expressions (happiness, neutral, sadness, anger, surprise, disgust, fear).","7a417f26":"If found useful,Please Upvote!!"}}