{"cell_type":{"d88d1479":"code","bde8bf41":"code","109bb72e":"code","3fff2f27":"code","80176a1f":"code","5087933b":"code","a4bbc911":"code","22137cd0":"code","ad1a603c":"code","b249fbe8":"code","2f6bf04b":"code","13922fa0":"code","c8109907":"code","a7173859":"code","1485cd21":"code","73ba01bd":"code","ecb8c98e":"code","d373bcb5":"code","a8ab69b1":"code","1615d2d6":"code","227891cd":"code","b645ac81":"code","e23bee97":"code","9b2bd7be":"code","8106d866":"code","c5ae298f":"code","65101855":"code","15cd7b48":"code","8d1f3498":"code","ecc46b67":"code","befd974c":"code","e132451e":"code","a2ad4533":"code","831dff91":"code","ea39bd91":"code","4ae8123f":"code","ce68c015":"code","ba5256a0":"code","91bc9c15":"code","6982bc7f":"code","93b305a5":"code","7fbc65f7":"code","8f44ac72":"code","90aab6ea":"code","b700960a":"code","bb690e4e":"code","2479ed12":"code","1dec9aba":"code","f3b1fdc1":"code","1d38f9cc":"code","232d6c50":"code","fde24854":"code","34d27847":"code","a7149a47":"code","74c8da8e":"code","7e92d66e":"code","f1a6df22":"code","28bf1ed6":"code","ee9de03c":"code","71f92428":"code","0bc3b22b":"code","7b05725d":"code","343096b3":"code","b8ccc4aa":"code","2d300791":"code","f749a141":"code","fbd8c3a5":"code","83264ce1":"code","8ace65d2":"code","35f5b20d":"code","16f23661":"code","4a3942fb":"code","3f050b88":"code","0281b8ae":"code","120f823f":"code","2dac4375":"code","95aed945":"code","19ecaff9":"code","0f1c9981":"code","fbfb9fef":"code","f181736f":"markdown","cdb863aa":"markdown","de70d55f":"markdown"},"source":{"d88d1479":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","bde8bf41":"train=pd.read_csv('..\/input\/forest-cover-type-prediction\/train.csv')\ntest=pd.read_csv('..\/input\/forest-cover-type-prediction\/test.csv')","109bb72e":"train.info()","3fff2f27":"train['Elevation'].min()","80176a1f":"sns.distplot(train.Elevation,rug=True)\nplt.grid()","5087933b":"train['Elevation'].describe()","a4bbc911":"sns.boxplot(train['Elevation'])","22137cd0":"sns.violinplot(x=train['Cover_Type'],y=train['Elevation'])\nplt.grid()","ad1a603c":"train.Aspect.describe()","b249fbe8":"sns.distplot(train.Aspect)\nplt.grid()","2f6bf04b":"sns.violinplot(x=train['Cover_Type'],y=train['Aspect'])\nplt.grid()","13922fa0":"train['Slope'].describe()","c8109907":"sns.distplot(train['Slope'])\nprint(train.Slope.skew())","a7173859":"# apply the sqrt transformation to reduce the skewness \nsns.distplot(np.sqrt(train['Slope']+1))\nprint(np.sqrt(train['Slope']+1).skew())","1485cd21":"train.Slope=np.sqrt(train.Slope+1)","73ba01bd":"test.Slope=np.sqrt(test.Slope+1)","ecb8c98e":"sns.distplot(test['Slope'],color='red')\nplt.title('test.slope')","d373bcb5":"train.Horizontal_Distance_To_Hydrology.describe()","a8ab69b1":"train['dist_hydr']=np.sqrt(train['Vertical_Distance_To_Hydrology']**2 + train['Horizontal_Distance_To_Hydrology']**2)\ntest['dist_hydr']=np.sqrt(test['Vertical_Distance_To_Hydrology']**2 + test['Horizontal_Distance_To_Hydrology']**2)","1615d2d6":"sns.distplot(train['dist_hydr'])","227891cd":"sns.distplot(np.sqrt(1+train['dist_hydr']))","b645ac81":"train['dist_hydr']=np.sqrt(1+train['dist_hydr'])\ntest['dist_hydr']=np.sqrt(1+test['dist_hydr'])\n\n","e23bee97":"sns.distplot(train.Horizontal_Distance_To_Hydrology,color='orange')","9b2bd7be":"sns.distplot(np.sqrt(train.Horizontal_Distance_To_Hydrology),color='orange')","8106d866":"# apply the sqrt transformation\ntrain.Horizontal_Distance_To_Hydrology=np.sqrt(1+train.Horizontal_Distance_To_Hydrology)\ntest.Horizontal_Distance_To_Hydrology=np.sqrt(1+test.Horizontal_Distance_To_Hydrology)","c5ae298f":"# vertical distance to the hydrology column\nsns.violinplot(x=train.Cover_Type,y=train.Vertical_Distance_To_Hydrology)","65101855":"sns.distplot(train.Vertical_Distance_To_Hydrology)","15cd7b48":"# It is clearly an indication that there are some outliers\n# By looking at the violin plot they may produce some good results   \nsns.boxplot(train.Vertical_Distance_To_Hydrology)\nplt.title('train.Vertical_Distance_To_Hydrology')","8d1f3498":"# It is better to not remove outliers by looking at the both training and test plot  \nsns.boxplot(test.Vertical_Distance_To_Hydrology)","ecc46b67":"print(train.Hillshade_9am.describe())","befd974c":"sns.distplot(train.Hillshade_9am)","e132451e":"sns.boxplot(train.Hillshade_9am)\nplt.grid()","a2ad4533":"# to find the impact of  of outliers consider the violinplot\nsns.violinplot(x=train.Cover_Type,y=train.Hillshade_9am)","831dff91":"# both train and test datasets have points below the (Q1-1.5IQR)\n# so let us assume that outliers have some significant impact on prediction \nsns.boxplot(train.Hillshade_9am,color='red')\nplt.title('test_Hillshade')","ea39bd91":"sns.boxplot(train.Hillshade_Noon)","4ae8123f":"sns.violinplot(y=train.Hillshade_Noon,x=train.Cover_Type)","ce68c015":"sns.boxplot(test.Hillshade_Noon)","ba5256a0":"sns.distplot(train.Hillshade_Noon)\nplt.grid()\nplt.title('train_Hillshae_Noon')","91bc9c15":"sns.boxplot(train.Hillshade_3pm)","6982bc7f":"sns.distplot(train.Hillshade_3pm,color='green')\nplt.grid()","93b305a5":"sns.violinplot(x=train.Cover_Type,y=train.Hillshade_3pm)","7fbc65f7":"train.head()","8f44ac72":"#all the remaining columns Wilderness_Area and soil type are binary variables\n# checking whethere they contain other than zero or one\ncol=list(train.columns)\n\nfor i in range(11,55):\n    filter=(train.iloc[:,i]!=0) & (train.iloc[:,i]!=1)\n    if (filter.sum()!=0):\n        print(col[i])\n    \n","90aab6ea":"train['Horizontal_Distance_To_Fire_Points'].describe()","b700960a":"sns.boxplot(train['Horizontal_Distance_To_Fire_Points'])","bb690e4e":"sns.violinplot(x=train.Cover_Type,y=train.Horizontal_Distance_To_Fire_Points)","2479ed12":"# there has been a matchin of patter in train and test sets \nsns.boxplot(test.Horizontal_Distance_To_Fire_Points)","1dec9aba":"sns.distplot(train.Horizontal_Distance_To_Fire_Points)\nplt.grid()\nprint(train.Horizontal_Distance_To_Fire_Points.skew())","f3b1fdc1":"# After applying the log transformation there has been decrease in the skewness\nsns.distplot(np.log(1+train.Horizontal_Distance_To_Fire_Points))\nplt.grid()\nprint(np.log(1+train.Horizontal_Distance_To_Fire_Points.skew()))","1d38f9cc":"train['Horizontal_Distance_To_Fire_Points']=np.log(1+train.Horizontal_Distance_To_Fire_Points)\ntest['Horizontal_Distance_To_Fire_Points']=np.log(1+test.Horizontal_Distance_To_Fire_Points)\n","232d6c50":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nsd=StandardScaler()","fde24854":"# standardizing the columns except 'soil type and wilderness_area since they are binary  \n\ndf_train=train.iloc[:,1:11]\ndf_train['dist_hydr']=train['dist_hydr']\ndf_train.info()","34d27847":"# similarly slice the columns for the test datset\n\ndf_test=test.iloc[:,1:11]\ndf_test['dist_hydr']=test['dist_hydr']\ndf_test.info()","a7149a47":"sd.fit(df_train)\ndf_train=sd.transform(df_train)","74c8da8e":"df_train[:10,1]","7e92d66e":"train.iloc[:,1:11]=df_train[:,0:10]","f1a6df22":"train['dist_hydr']=df_train[:,10]","28bf1ed6":"df_test=sd.transform(df_test)\ntest.iloc[:,1:11]=df_test[:,0:10]\ntest['dist_hydr']=df_test[:,10]","ee9de03c":"# drop id both from train and test columns\ntrain.drop(columns=['Id'],axis=1,inplace=True)","71f92428":"Id=test['Id']\ntest.drop(columns=['Id'],axis=1,inplace=True)","0bc3b22b":"train_corr=train.corr()","7b05725d":"# correlated columsn with target lable are plotted in descending order\n# we can eliminate least correlated columns when we have hign dimmensional data which in not inour case \ntrain_corr['Cover_Type'].abs().sort_values(ascending=False)","343096b3":"sns.heatmap(train_corr)","b8ccc4aa":"# Creating a new features by adding higlhy correlated features with target \n# also independent variables should not correlate with each other\n\nprint(train_corr.loc['Soil_Type38','Soil_Type39'])\nprint(train_corr.loc['Soil_Type38','Wilderness_Area1'])\nprint(train_corr.loc['Soil_Type39','Wilderness_Area1'])","2d300791":"train['soil_type38,39']=train['Soil_Type38']+train['Soil_Type39']\ntrain['soil_38_Wilde_area_1']=train['Soil_Type38']+train['Wilderness_Area1']\ntrain['soil_39_Wilde_area_1']=train['Soil_Type39']+train['Wilderness_Area1']\n\ntest['soil_type38,39']=test['Soil_Type38']+test['Soil_Type39']\ntest['soil_38_Wilde_area_1']=test['Soil_Type38']+test['Wilderness_Area1']\ntest['soil_39_Wilde_area_1']=test['Soil_Type39']+test['Wilderness_Area1']","f749a141":"#seperating the target\n\nX=train.drop(columns='Cover_Type',axis=1)\ny=train['Cover_Type']","fbd8c3a5":"X.info()","83264ce1":"from sklearn.model_selection import train_test_split\nx_train,x_valid,y_train,y_valid=train_test_split(X,y,test_size=0.25)","8ace65d2":"from sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import GaussianNB","35f5b20d":"clf_accuracy=[]","16f23661":"# Logistic Regression\nlg=LogisticRegression(max_iter=1000)\nlg.fit(x_train,y_train)\npred=lg.predict(x_valid)\nclf_accuracy.append(accuracy_score(y_valid,pred))\nprint(accuracy_score(y_valid,pred))","4a3942fb":"#plot the accuracy for different values of neighbor\n# from the below plot take n_neighnors=4 as it gives the optimal value\n\nfrom sklearn.neighbors import KNeighborsClassifier\nmodel=KNeighborsClassifier()\n\n\nl=[i for i in range(1,11)]\naccuracy=[]\n\nfor i in l:\n    model=KNeighborsClassifier(n_neighbors=i,weights='distance')\n    model.fit(x_train,y_train)\n    pred=model.predict(x_valid)\n    accuracy.append(accuracy_score(y_valid,pred))\n    \nplt.plot(l,accuracy)\nplt.title('knn_accuracy plot')\nplt.xlabel('neighbors')\nplt.ylabel('accuracy')\nplt.grid()\n\nprint(max(accuracy))\n\nclf_accuracy.append(max(accuracy))","3f050b88":"# Support Vector Machines\nfrom sklearn.svm import SVC\nmodel=SVC(kernel='rbf')\nmodel.fit(x_train,y_train)\npred=(model.predict(x_valid))\nclf_accuracy.append(accuracy_score(y_valid,pred))\nprint(accuracy_score(y_valid,pred))","0281b8ae":"# Random Forest Classfier\nrand=RandomForestClassifier()\nrand.fit(x_train,y_train)\npred=rand.predict(x_valid)\nclf_accuracy.append(accuracy_score(y_valid,pred))\nprint(accuracy_score(y_valid,pred))","120f823f":"# xgboost\nxgb=XGBClassifier(max_depth=7)\nxgb.fit(x_train,y_train)\npred=xgb.predict(x_valid)\nclf_accuracy.append(accuracy_score(y_valid,pred))\nprint(accuracy_score(y_valid,pred))","2dac4375":"# Naive Bayes Classifier\nnb=GaussianNB()\nnb.fit(x_train,y_train)\npred=nb.predict(x_valid)\nclf_accuracy.append(accuracy_score(y_valid,pred))\nprint(accuracy_score(y_valid,pred))\n","95aed945":"classifier_list=['log_regression','knn','svm','rforest','xgboost','nbayes']","19ecaff9":"sns.barplot(x=clf_accuracy,y=classifier_list)\nplt.grid()\nplt.xlabel('accuracy')\nplt.ylabel('classifier')\nplt.title('classifier vs accuracy plot')\n\n#leela_submission=pd.DataFrame({'Id': Id,'Cover_Type':stack_res})","0f1c9981":"# we use random forest for us final prediction\n# We fit the whole training data given to us \nrand=RandomForestClassifier()\nrand.fit(X,y)\npred=rand.predict(test)","fbfb9fef":"leela_submission=pd.DataFrame({'Id': Id,'Cover_Type':pred})\nleela_submission.to_csv('leela_submision.csv',index=False)","f181736f":"### EDA Column wise","cdb863aa":"##please upvote the kernle if you have found it useful. It motivates me a lot","de70d55f":"### Preprocessing and Feature Engineering"}}