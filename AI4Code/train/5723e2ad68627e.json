{"cell_type":{"b9e61371":"code","f7fc53fc":"code","19ee2f6d":"code","0eb46e62":"code","23017022":"code","82bfd5f7":"code","1eb8cc66":"code","06eb00bd":"code","e0a3caf1":"code","302de035":"code","44103bf6":"code","efd32e5b":"code","a897c216":"code","888df884":"code","e5c0546d":"markdown"},"source":{"b9e61371":"import numpy as np\nimport pandas as pd\nimport os\nimport random\nimport time\nfrom datetime import datetime\nimport gc\nimport warnings\n\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomTreesEmbedding\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler, QuantileTransformer\n\nimport tensorflow as tf\nfrom keras import Sequential\nfrom keras import backend as K\nfrom keras.layers import Dense,Dropout,BatchNormalization,LeakyReLU,Activation\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\nimport tensorflow_addons as tfa\n\nwarnings.filterwarnings(\"ignore\")","f7fc53fc":"SEED = 0\nos.environ['PYTHONHASHSEED']=str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","19ee2f6d":"def read_data():\n    train = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\n    test = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')\n    sub = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')\n    return train,test,sub","0eb46e62":"def preprocess_data(X_train,X_test):\n    \n    df = pd.concat([X_train,X_test],axis=0,copy=False)\n    \n    #random trees embeddings\n    rf_embedder = RandomTreesEmbedding(\n        n_estimators=5, random_state=SEED, max_depth=1).fit(df)\n    \n    X_sparse_embedding = rf_embedder.transform(df)\n    \n    #scaling\n    scaler = StandardScaler()\n    df = scaler.fit_transform(df)\n    \n    #quantile transformation\n    qt = QuantileTransformer(random_state=SEED, output_distribution='normal')\n    df = qt.fit_transform(df)\n    \n    #PCA features\n    pca = PCA(n_components=10, random_state=SEED)\n    pca.fit(df)\n    \n    df = np.hstack([df, X_sparse_embedding.toarray(), pca.transform(df)])\n    \n    X_train = df[:len(X_train),:]\n    X_test = df[len(X_train):,:]\n    del df\n    gc.collect()\n    \n    return X_train,X_test","23017022":"def train_nn(X,X_test,y,folds): \n     \n    oof = np.zeros(len(X)) \n    prediction = np.zeros(len(X_test)) \n    scores = [] \n     \n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)): \n        print('Fold', fold_n, 'started at', time.ctime()) \n        X_train, X_valid = X[train_index], X[valid_index] \n        y_train, y_valid = y.loc[train_index], y.loc[valid_index] \n         \n        checkpoint_path = f'repeat:Fold:{fold_n}.hdf5' \n         \n        cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True, \n                                     save_weights_only = True, mode = 'min') \n         \n        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min') \n        #opt = tf.keras.optimizers.Adam(learning_rate = 0.001) \n        #opt = tfa.optimizers.SWA(opt) \n         \n        early_stop = EarlyStopping(monitor='val_loss', patience=5) \n        model = Sequential()\n        model.add(tfa.layers.WeightNormalization(Dense(256, activation='elu')))\n        model.add(Dropout(0.1))\n        model.add(tfa.layers.WeightNormalization(Dense(128, activation='elu'))) \n        model.add(Dropout(0.1)) \n        model.add(tfa.layers.WeightNormalization(Dense(64, activation='elu'))) \n        model.add(Dropout(0.1))\n        model.add(Dense(16, activation='elu')) \n        model.add(Dense(1, activation='linear')) \n        model.compile(optimizer='Adam', loss='mse') \n         \n     \n        model.fit(X_train, y_train,  \n                  validation_data = (X_valid, y_valid), \n                  epochs=200, verbose=2,callbacks = [early_stop,reduce_lr_loss,cb_checkpt]) \n         \n        model.load_weights(checkpoint_path) \n         \n        y_pred_valid = model.predict(X_valid) \n        y_pred = model.predict(X_test) \n         \n        oof[valid_index] = y_pred_valid.reshape(-1,) \n        scores.append(np.sqrt(mean_squared_error(y_valid, y_pred_valid)))\n        print('RMSE: {}'.format(np.sqrt(mean_squared_error(y_valid,y_pred_valid))))\n         \n        del X_train,X_valid,y_train,y_valid \n        gc.collect() \n         \n        prediction += y_pred.reshape(-1,) \n         \n    prediction \/= N_FOLDS \n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores))) \n     \n    return oof,prediction","82bfd5f7":"N_FOLDS = 10\nkf = StratifiedKFold(n_splits = N_FOLDS, random_state = SEED, shuffle = True)","1eb8cc66":"%%time\n\ntrain,test,sub = read_data()","06eb00bd":"y = train['loss']\n\nX_train = train.drop(['id', 'loss'],axis=1)\nX_test = test.drop(['id'],axis=1)","e0a3caf1":"%%time\n\nX_train,X_test = preprocess_data(X_train,X_test)","302de035":"X_train.shape","44103bf6":"%%time\n\noof, preds = train_nn(X_train,X_test,y,folds=kf)","efd32e5b":"# clipping negative values\n\noof_postprocessed = np.where(oof<0, 0, oof)\npreds_postprocessed = np.where(preds<0, 0, preds)","a897c216":"# RMSE of clipped and notclipped predictions\n\nprint(f'Not clipped OOF RMSE: {np.sqrt(mean_squared_error(y,oof))}')\nprint(f'Clipped OOF RMSE: {np.sqrt(mean_squared_error(y,oof_postprocessed))}')","888df884":"pd.DataFrame(oof).to_csv('oof.csv', index = 0)\npd.DataFrame(oof_postprocessed).to_csv('oof_postprocessed.csv', index = 0)\n\nsub['loss'] = preds_postprocessed\nsub.to_csv('sub_postprocessed.csv', index = 0)","e5c0546d":"## Updates:\n\n1. Version 3. Kfold CV -> StratifiedKFold Cv. Increased number of folds (5 -> 10).\n   CV: 7.8805\n2. Version 4. Added RandomTreesEmbeddings as input features to Neural Net\n   CV: 7.8781\n3. Version 5. Changed RandomTreesEmbeddings parameters\n   CV: 7.8784\n4. Version 6. Added count features for ['f1', 'f86']\n   CV: 7.8779\n5. Version 7. Added PCA features + clipping negative predictions"}}