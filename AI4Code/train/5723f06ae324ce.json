{"cell_type":{"42843c3e":"code","ca0b9fb0":"code","d331d031":"code","0dac5e92":"code","5c1e8fde":"code","914d70f2":"code","0e08d080":"code","5a0ea1f6":"code","8368ebf1":"code","0cc337aa":"code","430f26cf":"code","d9ca9506":"code","41f77dad":"code","c5595cc8":"code","d2932281":"code","ddc216b2":"code","a5afab4f":"code","d5e604c7":"code","67e42202":"code","30c7fb8e":"code","13a787b6":"code","e30f651d":"code","c38b05c5":"code","26efefd5":"code","c605d1a6":"code","8fabae68":"code","0b3a3835":"code","f36dcff1":"code","67daf6c5":"code","2795cfd5":"code","61b73e0c":"code","64e53dc6":"markdown","4e3a3ef0":"markdown","80c7de83":"markdown","53e07be5":"markdown","87cc55d8":"markdown","fa612108":"markdown","c3e52fe2":"markdown","5b0bbdad":"markdown","aff1ea56":"markdown","ffe49a2b":"markdown"},"source":{"42843c3e":"!pip install nlp","ca0b9fb0":"%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport nlp\nimport random\nprint('Using TensorFlow version', tf.__version__)","d331d031":"def show_history(h):\n    epochs_trained = len(h.history['loss'])\n    plt.figure(figsize=(16, 6))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(range(0, epochs_trained), h.history.get('accuracy'), label='Training')\n    plt.plot(range(0, epochs_trained), h.history.get('val_accuracy'), label='Validation')\n    plt.ylim([0., 1.])\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(range(0, epochs_trained), h.history.get('loss'), label='Training')\n    plt.plot(range(0, epochs_trained), h.history.get('val_loss'), label='Validation')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n    \ndef show_confusion_matrix(y_true, y_pred, classes):\n    from sklearn.metrics import confusion_matrix\n    \n    cm = confusion_matrix(y_true, y_pred, normalize='true')\n\n    plt.figure(figsize=(8, 8))\n    sp = plt.subplot(1, 1, 1)\n    ctx = sp.matshow(cm)\n    plt.xticks(list(range(0, 6)), labels=classes)\n    plt.yticks(list(range(0, 6)), labels=classes)\n    plt.colorbar(ctx)\n    plt.show()","0dac5e92":"dataset = nlp.load_dataset('emotion')","5c1e8fde":"dataset","914d70f2":"train = dataset['train']\nval = dataset['validation']\ntest = dataset['test']","0e08d080":"def get_tweets(data):\n    tweets = [x['text'] for x in data]\n    labels = [x['label'] for x in data]\n    return tweets, labels","5a0ea1f6":"tweets, labels = get_tweets(train)","8368ebf1":"tweets[0], labels[0]","0cc337aa":"tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000, oov_token='<OOV>')\n\ntokenizer.fit_on_texts(tweets)\n\nprint(tokenizer.texts_to_sequences([tweets[3]]))","430f26cf":"lengths = [len(t.split(' ')) for t in tweets]\n\nplt.hist(lengths, bins=len(set(lengths)))\nplt.show()","d9ca9506":"def get_sequences(tokenizer, tweets):\n    sequences = tokenizer.texts_to_sequences(tweets)\n    padded_sequences = pad_sequences(sequences, truncating='post', maxlen=50, padding='post')\n    return padded_sequences","41f77dad":"padded_train_sequences = get_sequences(tokenizer, tweets)","c5595cc8":"padded_train_sequences[0]","d2932281":"classes = set(labels)\nprint(classes)","ddc216b2":"plt.hist(labels, bins=11)\nplt.show()","a5afab4f":"classes_to_index = dict((c, i) for i, c in enumerate(classes))\nindex_to_classes = dict((v, k) for k, v in classes_to_index.items())","d5e604c7":"classes_to_index","67e42202":"index_to_classes","30c7fb8e":"names_to_ids = lambda labels: np.array([classes_to_index.get(x) for x in labels])","13a787b6":"train_labels = names_to_ids(labels)\nprint(train_labels[0])","e30f651d":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(10000, 16, input_length=50),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n    tf.keras.layers.Dense(6, activation='softmax')\n])\n\nmodel.compile(\n    loss='sparse_categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nmodel.summary()","c38b05c5":"val_tweets, val_labels = get_tweets(val)\nval_sequences = get_sequences(tokenizer, val_tweets)\nval_labels = names_to_ids(val_labels)","26efefd5":"val_tweets[0], val_labels[0]","c605d1a6":"history = model.fit(\n    padded_train_sequences, train_labels,\n    validation_data=(val_sequences, val_labels),\n    epochs=50,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)\n    ]\n)","8fabae68":"show_history(history)","0b3a3835":"test_tweets, test_labels = get_tweets(test)\ntest_sequences = get_sequences(tokenizer, test_tweets)\ntest_labels = names_to_ids(test_labels)","f36dcff1":"_ = model.evaluate(test_sequences, test_labels)","67daf6c5":"i = random.randint(0, len(test_labels) - 1)\n\nprint('Sentence:', test_tweets[i])\nprint('Emotion:', index_to_classes[test_labels[i]])\n\np = model.predict_classes(np.expand_dims(test_sequences[i], axis=0))[0]\nprint('Predicted Emotion:', index_to_classes.get(p))","2795cfd5":"preds = model.predict_classes(test_sequences)\npreds.shape, test_labels.shape","61b73e0c":"show_confusion_matrix(test_labels, preds, list(classes))","64e53dc6":"### Reference\n- [Tweet Emotion Dataset](https:\/\/github.com\/dair-ai\/emotion_dataset)\n- [Tweet Emotion Recognition with TensorFlow](https:\/\/www.coursera.org\/learn\/tweet-emotion-tensorflow)","4e3a3ef0":"## Training the Model\n\n1. Preparing a validation set\n2. Training the model","80c7de83":"## Padding and Truncating Sequences\n\n1. Checking length of the tweets\n2. Creating padded sequences","53e07be5":"## Tokenizing the tweets","87cc55d8":"## Evaluating the Model\n\n1. Visualizing training history\n2. Prepraring a test set\n3. A look at individual predictions on the test set\n4. A look at all predictions on the test set","fa612108":"## Creating and Compiling the Model","c3e52fe2":"## Tweet Emotion Recognition with TensorFlow\n","5b0bbdad":"## Setup and Imports\n\n1. Installing Hugging Face's nlp package\n2. Importing libraries","aff1ea56":"## Importing Data\n\n1. Importing the Tweet Emotion dataset\n2. Creating train, validation and test sets\n3. Extracting tweets and labels from the examples","ffe49a2b":"## Preparing the Labels\n\n1. Creating classes to index and index to classes dictionaries\n2. Converting text labels to numeric labels"}}