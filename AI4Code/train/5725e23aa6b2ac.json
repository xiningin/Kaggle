{"cell_type":{"3f566e53":"code","b373fd32":"code","0168aa6c":"code","6e54cc9d":"code","cab3c6e6":"code","f16f4abd":"code","6c7cd930":"code","e7d844d6":"code","e29fe341":"code","9d47fb8e":"code","8bb0f0f3":"code","923cd89e":"code","38a7436c":"code","7bc39a82":"code","01337324":"code","8956c77f":"code","32d64b1b":"code","cd047137":"code","fad52930":"code","123b0125":"code","bce99f51":"code","9cb078ac":"code","1920b8f5":"code","ef7f8fe3":"code","99ae0aa6":"code","212e5d7a":"code","c7890806":"markdown","6a44981c":"markdown","cc6d57aa":"markdown","8c673920":"markdown","8b43048b":"markdown"},"source":{"3f566e53":"import numpy as np \nimport pandas as pd \nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization, MaxPooling2D, Activation\nfrom keras.utils import to_categorical\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport cv2\nfrom PIL import Image\nimport itertools\nimport random as rn\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n","b373fd32":"train_dir='..\/input\/boat-types-recognition\/boats'\nbuoy_dir='..\/input\/boat-types-recognition\/buoy'\ncruise_ship_dir='..\/input\/boat-types-recognition\/cruise ship'\nferry_boat_dir='..\/input\/boat-types-recognition\/ferry boat'\nfreight_boat_dir='..\/input\/boat-types-recognition\/freight boat'\ngondola_dir='..\/input\/boat-types-recognition\/gondola'\ninflatable_boat_dir='..\/input\/boat-types-recognition\/inflatable boat'\nkayak_dir='..\/input\/boat-types-recognition\/kayak'\npaper_boat_dir='..\/input\/boat-types-recognition\/paper boat'\nsailboat_dir='..\/input\/boat-types-recognition\/sailboat'","0168aa6c":"def fetchfiles(directory):\n    file_list = []\n    for image_name in os.listdir(directory):\n        filename,extension = os.path.splitext(image_name)\n        file_list.append(image_name)\n    return file_list\n","6e54cc9d":"labels = {\"buoy\" : 0,\n             \"cruise\" : 1,\n             \"ferry\" : 2,\n             \"freight\": 3,\n             \"gondola\" : 4,\n             \"inflatable\" : 5,\n             \"kayak\" : 6,\n             \"paper\" : 7,\n             \"sail\" : 8}\nlabels_list = list(labels)\n\n\ndef fetchlabels(file_list, boat_type):\n    label_list = []\n    for image_name in file_list:\n        label_list.append(boat_type)\n    return label_list","cab3c6e6":"allfiles =[]\nalllabels = []\nimages_all =[]\nx=[]\n\nfiledirectories = [buoy_dir,cruise_ship_dir,ferry_boat_dir,freight_boat_dir,gondola_dir,inflatable_boat_dir,kayak_dir, paper_boat_dir, sailboat_dir]\n\nfor directory, key in zip(filedirectories,labels):\n    newfiles = fetchfiles(directory)   \n    newlabels = fetchlabels(newfiles,key)\n\n    for i, j in tqdm(zip(newfiles,newlabels)):\n        allfiles.append(i)\n        alllabels.append(j)\n        path = os.path.join(directory,i)\n        img = cv2.imread(path,cv2.IMREAD_COLOR) \n        img = cv2.resize(img, (150,150))\n        x.append(np.array(img))\n        images_all.append(str(j))\n    \n    print(\"The length of the current image array is:\")\n    print(len(x))\n","f16f4abd":"print(\"the length of final files are:\", len(allfiles))\nprint(\"the length of final labels are:\", len(alllabels))\n\nalldata = {\"image\" : allfiles, \"label\" : alllabels}\ndf_alldata = pd.DataFrame(alldata)\nprint(\"the last 5 entries are: \") \nprint(df_alldata.tail())\nprint(\"The columns are:\")\nprint(df_alldata.columns)\nprint(\"The summary\")\ndf_alldata.describe(include=\"all\")","6c7cd930":"df_alldata.label.value_counts()\ndf_alldata['label'].unique()\ndf_alldata['label'] = df_alldata['label'].astype(str)\n\nplt.figure(figsize=(8,5))\nsns.countplot(data=df_alldata,y=\"label\")","e7d844d6":"fig,ax=plt.subplots(5,5)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (5):\n        index=rn.randint(0,len(alllabels))\n        ax[i,j].imshow(x[index])\n        ax[i,j].set_title(alllabels[index])\nplt.tight_layout()","e29fe341":"le=LabelEncoder()\nprint(\"original all_labels \")\nprint(alllabels[100])\ny=le.fit_transform(alllabels)\nprint(\"after transforming to 0-8\")\nprint(y[100])\ny=to_categorical(y,len(labels_list))\nprint(\"after converting to binary vectors\")\nprint(y[100])\nx=np.array(x)\n","9d47fb8e":"train_ratio = 0.80\nvalidation_ratio = 0.10\ntest_ratio = 0.10\n\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=(1 - train_ratio),stratify=y,random_state=42)\n\nx_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio\/(test_ratio + validation_ratio),stratify=y_test,random_state=42) \n\n\nprint(len(x_train))\nprint(len(x_test))\nprint(len(x_val))\n\nx_test = x_test\/255.0\nx_val = x_val\/255.0","8bb0f0f3":"batch_size=36\nepochs=100\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n\nred_lr= ReduceLROnPlateau(monitor='val_accuracy',patience=5,verbose=1,factor=0.5,min_lr=.0001)\nES_monitor=EarlyStopping(monitor='val_loss',\n                          patience=20,verbose=1)\n\nfilepath = 'my_best_model.hd5'\ncheckpoint = ModelCheckpoint(filepath=filepath, monitor='val_accuracy',verbose=1, save_best_only=True,save_weights_only=True,mode='max')","923cd89e":"np.random.seed(42)\nrn.seed(42)\ntf.random.set_seed(42)","38a7436c":"NUM_CATEGORIES = len(os.listdir(train_dir))\n","7bc39a82":"from sklearn.utils import class_weight\n\ny_ints = [y.argmax() for y in y_train]\n\ny_list = list(np.unique(y_ints))\n\nclass_weights = class_weight.compute_class_weight('balanced',np.unique(y_ints),y_ints)\n\nfor i in range(len(class_weights)):\n    weights = {y_list[i]:class_weights[i] for i in range(len(y_list))}\n\nprint(weights)","01337324":"NUM_CATEGORIES","8956c77f":"#model = Sequential()\n\n# First Convolutional Layer\n#model.add(Conv2D(filters=1024, kernel_size=3, activation='relu', input_shape=(150,150,3)))\n#model.add(MaxPool2D(pool_size=(2, 2)))\n#model.add(Dropout(rate=0.25))\n\n# Second Convolutional Layer\n#model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n#model.add(MaxPool2D(pool_size=(2, 2)))\n#model.add(Dropout(rate=0.25))\n\n# Third Convolutional Layer\n#model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n\n#model.add(Flatten())\n#model.add(Dense(units=64, activation='relu'))\n#model.add(Dense(NUM_CATEGORIES, activation='softmax'))\n\n# Compiling the model\n\n\n#epochs = 30\n#model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n\n#model.summary()","32d64b1b":"from tensorflow.keras.layers import GlobalAveragePooling2D\npre_trained_model = InceptionV3(input_shape = (150, 150, 3), include_top = False, weights = 'imagenet')\n\nx = pre_trained_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = BatchNormalization(axis=-1,center=True,scale=False)(x)\nx = Dropout(0.25)(x)\n\nx = Dense(512, activation='relu')(x)\nx = BatchNormalization(axis=-1,center=True,scale=False)(x)\nx = Dropout(0.25)(x)\n\npredictions = Dense(len(labels_list), activation='softmax')(x)\nmodel = Model(inputs=pre_trained_model.input, outputs=predictions)\n\nfor layer in pre_trained_model.layers:\n  layer.trainable = False","cd047137":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.02, # Randomly zoom image \n        width_shift_range=0.05,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.05,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,\n        fill_mode='nearest',\n        brightness_range=[1.0,1.0],\n        rescale=1\/255.0\n        #shear_range=0.25,\n        )  # randomly flip images\n\ndatagen.fit(x_train)","fad52930":"model.compile(optimizer = Adam(lr=0.0001), \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])","123b0125":"History = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=x_train.shape[0] \/\/ batch_size, \n                    epochs=100, validation_data = (x_test,y_test), verbose = 1,callbacks=[red_lr,ES_monitor,checkpoint], class_weight=weights)","bce99f51":"plt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","9cb078ac":"plt.plot(History.history['accuracy'])\nplt.plot(History.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","1920b8f5":"model.evaluate(x_test,y_test)","ef7f8fe3":"model.evaluate(x_val,y_val)","99ae0aa6":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\nY_pred = model.predict(x_test)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(y_test,axis = 1) \n\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","212e5d7a":"from sklearn.metrics import classification_report\n\nprint(classification_report(Y_true, Y_pred_classes))","c7890806":"**Importing the InceptionV3 pre-trained model, adding additional lower layers and freezing all other layers in the InceptionV3 model.**","6a44981c":"**Plotting the train and test model loss**","cc6d57aa":"**Inspecting the data using a pandas DataFrame**","8c673920":"**Plotting the train and test model accuracy**","8b43048b":"**Plotting the incorrectly classified images**"}}