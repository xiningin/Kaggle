{"cell_type":{"71f98c0f":"code","1651f8de":"code","7ed0ac6a":"code","f921c52b":"code","b727d479":"code","c2f78b2c":"code","bd6c37fa":"code","481a21f5":"code","9183ad30":"code","5d7f724b":"markdown","2372902d":"markdown","83c101bf":"markdown","2a19837f":"markdown"},"source":{"71f98c0f":"import pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nimport nltk","1651f8de":"from os import listdir\nfrom os.path import isfile, join\nonlyfiles = [f for f in listdir('..\/input\/feedback-prize-2021\/train') if isfile(join('..\/input\/feedback-prize-2021\/train', f))]","7ed0ac6a":"text = \"\"\ncount = 0\nfor i in onlyfiles:\n    count+=1\n    tmp = '..\/input\/feedback-prize-2021\/train\/' + i\n    data = \"\"\n    with open(tmp, 'r') as file:\n        data = file.read().replace('\\n', ' ')\n    text = text + ' ' + data","f921c52b":"import re\nfrom nltk.tokenize import word_tokenize\nimport nltk\nnltk.download('punkt')\ntext = re.sub(r'[^A-Za-z0-9 ]+', '', text.lower()).split(' ')\nstop_words = set(stopwords.words('english'))","b727d479":"import nltk\nnltk.download('words')\nreal = []\nenglish_vocab = set(w.lower() for w in nltk.corpus.words.words())\nfor i in text:\n    if i in english_vocab and i not in stop_words:\n        real.append(i)","c2f78b2c":"real = list(set(real))","bd6c37fa":"import pandas as pd\nimport re\ndf = pd.read_csv(\"..\/input\/feedback-prize-2021\/train.csv\")\ntypes = [\"Claim\",\t\"Concluding Statement\",\t\"Counterclaim\",\t\"Evidence\",\t\"Lead\",\t\"Position\",\"Rebuttal\"]\n","481a21f5":"vals = []\ntype1 = []\ncount = 0\nfor index, values in df.iterrows():\n    t = []\n    string = re.sub(r'[^A-Za-z0-9 ]+', '', values[\"discourse_text\"].lower())\n    for i in real:\n        if i not in string:\n            t.append(0)\n        else:\n            t.append(string.count(i))\n    vals.append(t)\n    type1.append(values[\"discourse_type\"])","9183ad30":"df = pd.DataFrame.from_records(vals,columns=real)\ndf[\"type1\"] = type1\ndf.to_csv(\"BOW_train.csv\")","5d7f724b":"Getting all of the data for the bag of words dataset","2372902d":"This is just getting all of the text into 1 string. Basically just doing this to get every unique word that has been written in the data set","83c101bf":"## Bag of Words\nThe objective of this is to create a dataframe containing the Bag of Words for the Data Set \\\nThis file takes a lot of ram to run so that's why I am saving and opening frequently","2a19837f":"Removing words that aren't in the english dictionary & stop words"}}