{"cell_type":{"aa53918f":"code","52bfe0d8":"code","9f33011c":"code","cfc53b46":"code","0973830d":"code","3e5f0de8":"code","f60165bc":"code","1cef487b":"code","fe780f82":"code","9f038a73":"code","6745a03a":"code","cb59cec9":"code","a655a48b":"code","82206cc2":"code","1311dbe2":"code","7de9ad20":"code","5e7b47d1":"code","85e35051":"code","2b52eefd":"code","994804c7":"code","68ce2b25":"code","dfc0bdbe":"code","f3bae476":"code","6aa49607":"code","8b8ea29b":"code","d4a365a1":"code","e0dd0551":"code","058a64de":"markdown","6ee2d6c7":"markdown","e8e27ed2":"markdown"},"source":{"aa53918f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","52bfe0d8":"data = pd.read_csv(\"..\/input\/merged-data\/noFinal.csv\")","9f33011c":"data.drop('Unnamed: 0',inplace = True, axis = 1)","cfc53b46":"data","0973830d":"data.info()","3e5f0de8":"remove_features = ['order_id','customer_id','customer_unique_id','order_purchase_timestamp','order_approved_at', 'order_delivered_carrier_date','order_delivered_customer_date',\n                   'review_id','review_comment_title','review_comment_message','review_creation_date','review_answer_timestamp','order_estimated_delivery_date',\n                   'order_item_id','product_id','seller_id','shipping_limit_date','product_category_name','seller_zip_code_prefix','customer_city',\n'seller_city']","f60165bc":"data.drop(remove_features,inplace = True, axis = 1)\ndata","1cef487b":"data.info()","fe780f82":"data.isnull().sum()","9f038a73":"data.describe()","6745a03a":"#droping rows where order_status is 2bb9fa7ec912785d8e0c8643e67a9e9e ,62037ba2a9202de60df343187da90a76 \ndata.drop([18525,18527,56136],axis=0,inplace = True)","cb59cec9":"data['payment_sequential'] = data['payment_sequential'].astype('float64')","a655a48b":"# from sklearn import preprocessing\n# le = preprocessing.LabelEncoder()\n# for col in data.columns:\n#     if data[col].dtype =='object':\n#         print(col)\n#         #data[col] = le.fit_transform(data[col])","82206cc2":"data['order_status'].value_counts()\ndata['order_status'] = data['order_status'].replace({'delivered':0,'shipped':1,'voucher':2,'canceled': 3,\n'unavailable': 4,\n'invoiced': 5,'processing': 6,\n'created': 7, \n'approved':8})","1311dbe2":"\ndata['payment_type'] = data['payment_type'].replace({'credit_card':0,'boleto':1,'voucher':2,'debit_card':3,\n'not_defined':4})","7de9ad20":"data['customer_state'] = data['customer_state'].replace({'SP':0,'RJ':1,'MG':2,'RS':3,'PR':4\n,'SC':5\n,'BA':6\n,'DF':7\n,'GO':8\n,'ES':9\n,'PE':10\n,'CE':11\n,'MT':12\n,'PA':13\n,'MS':14\n,'MA':15\n,'PB':16\n,'PI':17\n,'RN':18\n,'AL':19\n,'SE':20\n,'TO':21\n,'RO':22\n,'AM':23\n,'AC':24\n,'AP':25,'RR':26})","5e7b47d1":"data['seller_state'] = data['seller_state'].replace({'SP':0,'RJ':1,'MG':2,'RS':3,'PR':4\n,'SC':5\n,'BA':6\n,'DF':7\n,'GO':8\n,'ES':9\n,'PE':10\n,'CE':11\n,'MT':12\n,'PA':13\n,'MS':14\n,'MA':15\n,'PB':16\n,'PI':17\n,'RN':18\n,'AL':19\n,'SE':20\n,'TO':21\n,'RO':22\n,'AM':23\n,'AC':24\n,'AP':25,'RR':26})","85e35051":"data.isnull().sum()","2b52eefd":"data.dropna(inplace = True)","994804c7":"data","68ce2b25":"# birch clustering\nfrom numpy import unique\nfrom numpy import where\nfrom sklearn.cluster import KMeans\nfrom matplotlib import pyplot\nX = data \nfor i  in range(20,50):\n    model = KMeans(n_clusters=i)\n# fit the model\n    model.fit(X)\n# assign a cluster to each example\n    yhat = model.predict(X)\n# retrieve unique clusters\n    clusters = unique(yhat)\n# create scatter plot for samples from each cluster\n    print(model.score(X))\n#     for cluster in clusters:\n# # get row indexes for samples with this cluster\n#         row_ix = where(yhat == cluster)\n#         print(row_ix)","dfc0bdbe":"# from sklearn.decomposition import PCA\n# pca = PCA(n_components=2)\n# Z = pca.fit_transform(X)\n# print(pca.explained_variance_ratio_)\n# print(pca.singular_values_)\n# pyplot.scatter(Z[:,0], Z[:,1])\n# # show the plot\n# pyplot.show()","f3bae476":"data.drop('customer_zip_code_prefix',axis = 1, inplace = True)","6aa49607":"# birch clustering\nfrom numpy import unique\nfrom numpy import where\nfrom sklearn.cluster import KMeans\nfrom matplotlib import pyplot\nX = data \nfor i  in range(20,50):\n    model = KMeans(n_clusters=i)\n# fit the model\n    model.fit(X)\n# assign a cluster to each example\n    yhat = model.predict(X)\n# retrieve unique clusters\n    clusters = unique(yhat)\n# create scatter plot for samples from each cluster\n    print(model.score(X))\n#     for cluster in clusters:\n# # get row indexes for samples with this cluster\n#         row_ix = where(yhat == cluster)\n#         print(row_ix)","8b8ea29b":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\ndata  = pd.DataFrame(ss.fit_transform(data))","d4a365a1":"data","e0dd0551":"# birch clustering\nfrom numpy import unique\nfrom numpy import where\nfrom sklearn.cluster import KMeans\nfrom matplotlib import pyplot\nX = data\nfor i  in range(20,50):\n    model = KMeans(n_clusters=i)\n# fit the model\n    model.fit(X)\n# assign a cluster to each example\n    yhat = model.predict(X)\n# retrieve unique clusters\n    clusters = unique(yhat)\n# create scatter plot for samples from each cluster\n    print(model.score(X))\n#     for cluster in clusters:\n# # get row indexes for samples with this cluster\n#         row_ix = where(yhat == cluster)\n#         print(row_ix)","058a64de":"This are some features, I am removing initially, but we can add\/remove features using our own discretion.","6ee2d6c7":"Just removing 'customer_zip_code_prefix' has led us significant improvement in the objective score","e8e27ed2":"For simplicity i am removing all null values from dataset"}}