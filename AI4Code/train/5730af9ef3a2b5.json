{"cell_type":{"c1ff7adc":"code","6b3d50ae":"code","291e1c6f":"code","b0b4ef30":"code","8dec27af":"code","7e67ab7f":"code","bb19b24b":"code","8e739ab5":"code","32c8b04f":"code","3963ceeb":"code","065098ff":"code","fecb6a9c":"code","6b8aa453":"code","e4f68f01":"code","7190ef39":"code","b4e91c7f":"code","05ecded9":"code","28e5936a":"code","42613861":"code","42a59081":"code","56409e84":"code","b7b6e5b5":"code","93f99cd9":"code","18cdc6c2":"code","98244e32":"code","edd2792f":"code","2638f6de":"code","4939b7ec":"code","f51254b9":"code","32fd25e0":"code","43662bd8":"markdown","9fb20af7":"markdown","f85cd984":"markdown","b5616571":"markdown","be3223a5":"markdown","06ba0e62":"markdown","cb2ab76e":"markdown","0811df8f":"markdown","720f1763":"markdown","78c2a844":"markdown","a80e8be1":"markdown","a5e37b16":"markdown","111905ed":"markdown","b6d5a74a":"markdown","79c66c0d":"markdown","6ef4a860":"markdown","c5e7f51b":"markdown","9ff0175a":"markdown","0356169b":"markdown","966a5d33":"markdown","918e3533":"markdown"},"source":{"c1ff7adc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6b3d50ae":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom seaborn import heatmap\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nimport plotly.express as px\nfrom matplotlib import rcParams\nimport seaborn as sns\nfrom sklearn.model_selection import KFold","291e1c6f":"#Read all the Excel Files which have Report Data from 2016 to 2020\n\ndf_2020=pd.read_csv('..\/input\/world-happiness-report\/2020.csv')\n\ndf_2020['Happiness Rank'] =  range(1, len(df_2020.index)+1)\n\ndf_2020 = df_2020.rename(columns = {'Country name' : 'Country', 'Ladder score' : 'Happiness Score', \n                        'Explained by: Log GDP per capita' : 'Economy (GDP per Capita)', 'Social support' : 'Family', \n                                    'Healthy life expectancy' : 'Health (Life Expectancy)',\n                        'Freedom to make life choices' : 'Freedom', \n                                    'Perceptions of corruption' : 'Trust (Government Corruption)'})\n\ndf_2020['Year']=2020\n\n\ndf_2019 = pd.read_csv('..\/input\/world-happiness-report\/2019.csv')\ndf_2019['Year']=2019\ndf_2019 = df_2019.rename(columns = {'Overall rank':'Happiness Rank', 'Country or region' : 'Country', 'Score' : 'Happiness Score',\n                                      'GDP per capita' : 'Economy (GDP per Capita)', 'Social support' : 'Family',\n                                      'Healthy life expectancy' : 'Health (Life Expectancy)','Freedom to make life choices' : 'Freedom'\n                                     , 'Perceptions of corruption' : 'Trust (Government Corruption)'})\n\n\n\ndf_2018 = pd.read_csv('..\/input\/world-happiness-report\/2018.csv')\ndf_2018['Year']=2018\ndf_2018 = df_2018.rename(columns = {'Overall rank':'Happiness Rank', 'Country or region' : 'Country', 'Score' : 'Happiness Score',\n                                      'GDP per capita' : 'Economy (GDP per Capita)', 'Social support' : 'Family',\n                                      'Healthy life expectancy' : 'Health (Life Expectancy)',\n                                      'Freedom to make life choices' : 'Freedom',\n                                      'Perceptions of corruption' : 'Trust (Government Corruption)'})\n\n\ndf_2017 = pd.read_csv('..\/input\/world-happiness-report\/2017.csv')\ndf_2017 = df_2017.rename(columns = {'Happiness.Rank':'Happiness Rank', 'Happiness.Score' : 'Happiness Score', \n                                      'Economy..GDP.per.Capita.' : 'Economy (GDP per Capita)', 'Health..Life.Expectancy.' : 'Health (Life Expectancy)',\n                                      'Trust..Government.Corruption.' : 'Trust (Government Corruption)', 'Dystopia.Residual' : 'Dystopia Residual'})\ndf_2017['Year']=2017\n\n\ndf_2016= pd.read_csv('..\/input\/world-happiness-report\/2016.csv')\ndf_2016['Year']=2016\n\n\ndf_2015 = pd.read_csv('..\/input\/world-happiness-report\/2015.csv')\ndf_2015['Year']=2015\n\n\ndf_all = pd.concat([df_2020,df_2019,df_2018,df_2017,df_2016,df_2015])\n\ndf_all=df_all[['Country', 'Happiness Rank', 'Happiness Score', 'Economy (GDP per Capita)',\n                                   'Family', 'Health (Life Expectancy)', 'Freedom','Trust (Government Corruption)',\n                                   'Generosity', 'Year']]\n\ndf_all.head()","b0b4ef30":"df_2020.info()","8dec27af":"df_2020.describe()","7e67ab7f":"plt.figure(figsize=(20,10))\ndf_2020.head(20).groupby('Regional indicator').agg({'Country':'count'}).sort_values(by='Country',ascending=True).plot(kind='bar',color='b',title='TOP HAPINESS')\nplt.show()\n\nplt.figure(figsize=(20,10))\ndf_2020.tail(20).groupby('Regional indicator').agg({'Country':'count'}).sort_values(by='Country',ascending=True).plot(kind='bar',color='r',title='LEAST HAPINESS')\nplt.show()","bb19b24b":"plt.rcParams['figure.figsize'] = (16,16)\ndf_2020[['Happiness Score',\n        'upperwhisker', 'lowerwhisker',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Generosity', 'Trust (Government Corruption)',\n       'Explained by: Social support', 'Explained by: Healthy life expectancy',\n       'Explained by: Freedom to make life choices',\n       'Explained by: Generosity', 'Explained by: Perceptions of corruption',\n       'Dystopia + residual']].hist(color=\"pink\");\n\ndf_2020.columns","8e739ab5":"df_least = df_2020[-10:].sort_values('Happiness Score', ascending = True)\npx.bar(df_least, x='Happiness Score', y='Country',orientation='h',title=\"Least 10 happiest countries\",color_discrete_sequence =['pink']*len(df_least))","32c8b04f":"df_top=df_2020.head(10).sort_values('Happiness Score', ascending = True)\n\npx.bar(df_top, x='Happiness Score', y='Country',orientation='h',title=\"Top 10 happiest countries\",color_discrete_sequence =['pink']*len(df_top))","3963ceeb":"plt.figure(figsize=(10,7))\ncol=df_all[['Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)','Freedom', 'Trust (Government Corruption)', 'Generosity','Happiness Score']].corr()\nsns.heatmap(col,annot=True,fmt='.2f',cmap=\"Blues\");\nplt.title(\"Correlation of Past 5 years\")\nplt.show()","065098ff":"col=df_2020[['Logged GDP per capita', 'Explained by: Social support',\n       'Explained by: Healthy life expectancy',\n       'Explained by: Freedom to make life choices',\n       'Explained by: Generosity', 'Explained by: Perceptions of corruption',\n       'Dystopia + residual','Happiness Score']].corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(col,annot=True,cmap=\"Greens\")\nplt.title('Correlattion of 2020 Dataset')\nplt.show()","fecb6a9c":"df_all.fillna((df_all.mean()), inplace = True)\ndf_2020.fillna((df_2020.mean()), inplace = True)\nsns.heatmap(df_2020.isnull(),yticklabels = False, cbar = False, cmap = 'viridis')","6b8aa453":"fig, axes = plt.subplots(nrows=3, ncols=2,constrained_layout=True,figsize=(10,10))\nsns.barplot(x='Economy (GDP per Capita)',y='Country',\n                        data=df_all.nlargest(10,'Economy (GDP per Capita)'),\n                        ax=axes[0,1],palette=\"rocket\")\nsns.barplot(x='Health (Life Expectancy)' ,y='Country',\n                        data=df_all.nlargest(10,'Health (Life Expectancy)'),\n                        ax=axes[0,0],palette=\"rocket\")\nsns.barplot(x='Happiness Score' ,y='Country',\n                        data=df_all.nlargest(10,'Happiness Score'),\n                        ax=axes[1,1],palette=\"rocket\")\nsns.barplot(x='Generosity' ,y='Country',\n                        data=df_all.nlargest(10,'Generosity'),\n                        ax=axes[1,0],palette=\"rocket\")\nsns.barplot(x='Freedom' ,y='Country',\n                        data=df_all.nlargest(10,'Freedom'),\n                        ax=axes[2,1],palette=\"rocket\")\nsns.barplot(x='Trust (Government Corruption)' ,y='Country',\n                        data=df_all.nlargest(10,'Trust (Government Corruption)'),\n                        ax=axes[2,0],palette=\"rocket\")","e4f68f01":"countries=['India','United States','United Kingdom','Russia','China','Canada','Germany','France','Switzerland', 'Iceland', 'Denmark', 'Norway', 'Finland',\n       'Netherlands','Japan', 'South Korea','Italy']\ndf_i=df_all[df_all['Country'].isin(countries)]\nfig=px.line(df_i,x='Year',y='Happiness Score',color='Country',title='Countries Trend with Happiness Score')\nfig.show()\n\nfig=px.line(df_i,x='Year',y='Economy (GDP per Capita)',color='Country',title='Countries Trend with Economy (GDP per Capita)')\nfig.show()\n\nfig=px.line(df_i,x='Year',y='Freedom',color='Country',title='Countries Trend with Freedom')\nfig.show()","7190ef39":"def lmmodel(df):\n    '''\n    INPUT - DataFrame\n    OUTPUT - Returns \n    r2 score for Test Dataset \n    Length of Test Datset\n    r2 score for Train Dataset\n    Length of Train Dataset\n    '''\n    #Choosing X and Y columns Y- Happiness Score which needs to be Predicted X - Features to Train Model\n    y=df['Happiness Score']\n    X=df[['Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)','Freedom', 'Generosity',\n           'Trust (Government Corruption)']]\n    \n    #Splitting Test and Train Dataset\n    X_train,X_test,Y_train,Y_test= train_test_split(X,y,test_size=0.2, shuffle=True, random_state=1000)\n    \n    #Initiating Linear Regression Model\n    lin_reg = LinearRegression()\n    \n    #Fit the Model\n    lin_reg.fit(X_train,Y_train)\n    \n    #Predict the Happiness Score for Test and Train Dataset\n    y_test_preds = lin_reg.predict(X_test)\n    y_train_preds = lin_reg.predict(X_train)\n    \n    #Finding Score, Mean Squared Error and Mean Absolute Error\n    score = lin_reg.score(X_test, Y_test)\n    mse = mean_squared_error(Y_test, y_test_preds)\n    mae = mean_absolute_error(Y_test, y_test_preds)\n    \n    #R2 Score for Model\n    r2_test = r2_score(Y_test, y_test_preds)\n    r2_train = r2_score(Y_train, y_train_preds) \n    \n    #Length of Test and Train Dataset\n    len_ytest = len(y_test_preds)\n    len_ytrain = len(y_train_preds)\n     \n    \n    \n    return r2_test, len_ytest, r2_train, len_ytrain\n    #return score, mse, mae","b4e91c7f":"#Predicting Happiness Score for 2020 Dataset by using lmmodel Function\n\nr2_test, len_ytest, r2_train, len_ytrain = lmmodel(df_2020)\nprint(\"2020 The r-squared score for the Test model using only quantitative variables was {} on {} values.\".format(r2_test, len_ytest))\nprint(\"2020 The r-squared score for the Train model using only quantitative variables was {} on {} values.\".format(r2_train, len_ytrain))\n\n#Predicting Happiness Score for total Dataset by using lmmodel Function\n\nr2_test, len_ytest, r2_train,len_ytrain = lmmodel(df_all)\nprint(\"All The r-squared score for the Test model using only quantitative variables was {} on {} values.\".format(r2_test,len_ytest))\nprint(\"All The r-squared score for the Train model using only quantitative variables was {} on {} values.\".format(r2_train,len_ytrain))","05ecded9":"y=df_all['Happiness Score']\nX=df_all[['Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Generosity', \n          'Trust (Government Corruption)']] \n\n\n#Splitting Test and Train Dataset\nX_train,X_test,Y_train,Y_test= train_test_split(X,y,test_size=0.2, shuffle=True, random_state=13579)","28e5936a":"scaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","42613861":"lin_reg = LinearRegression()\nlin_reg.fit(X_train,Y_train)\ny_hat = lin_reg.predict(X_test)\nscore=lin_reg.score(X_test, Y_test)\nmse = mean_squared_error(Y_test, y_hat)\nmae = mean_absolute_error(Y_test, y_hat)\nr2 = r2_score(Y_test, y_hat)\nr2, mse","42a59081":"dtr= DecisionTreeRegressor()\ndtr.fit(X_train,Y_train)\ny_pred = dtr.predict(X_test)\ntest_mse = mean_squared_error(Y_test, y_pred)\ny_pred_train = dtr.predict(X_train)\ntrain_mse = mean_squared_error(Y_train, y_pred_train)\nd=dtr.score(X_test, Y_test)\nd, test_mse ","56409e84":"rf = RandomForestRegressor(n_estimators = 13579)\nrf.fit(X_train, Y_train)\ny_hat = rf.predict(X_test)\nerrors = abs(y_hat - Y_test)\nacc = 1 - errors\nc=rf.score(X_test, Y_test)\nc, np.mean(acc)","b7b6e5b5":"from sklearn.preprocessing import PolynomialFeatures\nsns.set_style('darkgrid')\nscores_list = []\npRange = range(2,6)\nfor i in pRange :\n    poly_reg = PolynomialFeatures(degree=i)\n    x_poly = poly_reg.fit_transform(X_train)\n    poly_regressor = LinearRegression()\n    poly_regressor.fit(x_poly,Y_train)\n    y_pred = poly_regressor.predict(poly_reg.fit_transform(X_test))\n    scores_list.append(r2_score(Y_test,y_pred))\nplt.plot(pRange,scores_list,linewidth=2)\nplt.xlabel('Degree of polynomial')\nplt.ylabel('r2 score with varying degrees')\nplt.show()","93f99cd9":"from sklearn.neighbors import KNeighborsRegressor\nknnRange = range(1,11,1)\nscore_list=[]\nfor i in knnRange:\n    regressor_knn = KNeighborsRegressor(n_neighbors=i)\n    regressor_knn.fit(X_train,Y_train)\n    y_pred=regressor_knn.predict(X_test)\n    score_list.append(r2_score(Y_test,y_pred))\nplt.plot(knnRange,score_list,linewidth=2,color='red')\nplt.xticks(knnRange)\nplt.xlabel('no of neighbors')\nplt.ylabel('r2 knn')\nplt.show()","18cdc6c2":"regressor_knn= KNeighborsRegressor (n_neighbors=5)\nregressor_knn.fit(X_train,Y_train)\ny_pred=regressor_knn.predict(X_test)\nr2_sc=r2_score(Y_test,y_pred)\nprint(r2_sc)","98244e32":"folds = KFold(n_splits=5, shuffle=True, random_state=13579)\nscore = 0\nY_train = pd.DataFrame(data=Y_train, columns = {\"Happiness Score\"})\nX_train = pd.DataFrame(data=X_train, columns = {'Economy (GDP per Capita)', 'Family','Health (Life Expectancy)', 'Freedom', 'Generosity', \n                                                'Trust (Government Corruption)'})\nfor i, (x_index, y_index) in enumerate(folds.split(X_train, Y_train['Happiness Score'])):\n    print('-' * 22, i, '-' * 22)\n    dtr= DecisionTreeRegressor()\n    dtr.fit(X_train.iloc[x_index], Y_train['Happiness Score'].iloc[x_index])\n    score += dtr.score(X_train.iloc[y_index], Y_train['Happiness Score'].iloc[y_index])\n    print('score ', dtr.score(X_train.iloc[y_index], Y_train['Happiness Score'].iloc[y_index]))\n    \nb = score \/ folds.n_splits    \nprint('Average Accuracy', score \/ folds.n_splits)","edd2792f":"folds = KFold(n_splits=5, shuffle=True, random_state=13579)\nscore = 0\n#Y_train = pd.DataFrame(data=Y_train, columns = {\"Happiness Score\"})\n#X_train = pd.DataFrame(data=X_train, columns = {'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)','Freedom', 'Generosity',\n#'Trust (Government Corruption)'})\nfor i, (x_index, y_index) in enumerate(folds.split(X_train, Y_train['Happiness Score'])):\n    print('-' * 22, i, '-' * 22)\n    rfr = RandomForestRegressor(n_estimators=200, n_jobs=-1)\n    rfr.fit(X_train.iloc[x_index], Y_train['Happiness Score'].iloc[x_index])\n    score += rfr.score(X_train.iloc[y_index], Y_train['Happiness Score'].iloc[y_index])\n    print('score ', rfr.score(X_train.iloc[y_index], Y_train['Happiness Score'].iloc[y_index]))\n    \na = score \/ folds.n_splits\nprint('Average Accuracy', a)","2638f6de":"labelList = ['RandomForest', 'Decision Tree']\nmylist2 = [a, b]\nfor i in range(0,len(mylist2)):\n    mylist2[i]=np.round(mylist2[i]*100,decimals=3)\nprint(mylist2)","4939b7ec":"plt.figure(figsize=(14,8))\nax = sns.barplot(x=labelList,y=mylist2)\nplt.yticks(np.arange(0, 101, step=10))\nplt.title('r2 score comparison among different regression models',fontweight='bold')\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate('{:.3f}%'.format(height), (x +0.25, y + height + 0.8))\nplt.show()","f51254b9":"labelList = ['Linear Regression','K-Neigbors Regression', 'Random Forest', 'Random Forest with K-fold','Decision Tree','Decision Tree with K-fold']\nmylist = [r2, r2_sc, c, a, d, b]\nfor i in range(0,len(mylist)):\n    mylist[i]=np.round(mylist[i]*100,decimals=3)\nprint(mylist)","32fd25e0":"plt.figure(figsize=(14,8))\nax = sns.barplot(x=labelList,y=mylist)\nplt.yticks(np.arange(0, 101, step=10))\nplt.title('r2 score comparison among different regression models',fontweight='bold')\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate('{:.3f}%'.format(height), (x +0.25, y + height + 0.8))\nplt.show()","43662bd8":"**Correlation Map for Features in df_all(past 5 years)**","9fb20af7":"**Top 10 Happiest Countries in df_2020**","f85cd984":"*Information of 2020*","b5616571":"**Desicion Tree with K-Fold**","be3223a5":"**Plot and Visulaize Top 10 Countries for Each Feature**","06ba0e62":"**Top and Least Happiness Regions in df_2020**","cb2ab76e":"**Fill Na values with Mean**","0811df8f":"**K-Nearest Neigbours**","720f1763":"**Designing Linear Regression Model to Predict Happiness Score**","78c2a844":"**Correlation Map for Features in df_2020**","a80e8be1":"**Predicting Happiness Score**","a5e37b16":"**Desicion Tree Regression**","111905ed":"**Least 10 Happiest Countries in df_2020**","b6d5a74a":"**Random Forest Regression**","79c66c0d":"**Polynomial Regression**","6ef4a860":"**Random Forest with K-Fold**","c5e7f51b":"**Desicion Tree vs Random Forest Regression**","9ff0175a":"**Trend of Different Features over the Years against the Happiness Score - Analysed for Few Countries**\n","0356169b":"**Variablity of Each Metric**","966a5d33":"**Score Comparison Among Different Regression Models**","918e3533":"**Linear Regression**"}}