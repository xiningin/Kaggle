{"cell_type":{"81826fd1":"code","29a9c49c":"code","26fe5e35":"code","d4a0bf73":"code","b00ca1b5":"code","d62f1f2a":"code","904eabb3":"code","ff2347b7":"code","c6e9ec1e":"code","44ec2099":"code","b55e7e1a":"code","07bad9cc":"code","7b70a72a":"code","595f3dbf":"code","7285ec18":"code","69927a64":"code","2e3faff7":"code","53555750":"code","c3ad346b":"code","f5ef70e6":"code","cee42db6":"code","b613a914":"code","0ae50d6e":"code","c193efda":"code","528c0242":"code","ff0e619b":"code","caeaaeb5":"code","33266beb":"code","80886174":"code","08b99a5c":"markdown","78b29625":"markdown","443be225":"markdown","f03dc431":"markdown","ec9f2487":"markdown","e18d4baa":"markdown","75d61b35":"markdown","20413146":"markdown","bb5a20b4":"markdown","b890b76e":"markdown","2dc9fb1e":"markdown","e911e412":"markdown","b6e7da3b":"markdown","4817eb84":"markdown","64193fbf":"markdown","83d5853d":"markdown","c477e436":"markdown","f833df2a":"markdown","c95fdad7":"markdown","aaa58bac":"markdown"},"source":{"81826fd1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport keras\nfrom keras import regularizers\nfrom keras.layers import Dropout\n# TensorFlow and tf.keras\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom keras.datasets import fashion_mnist\nimport os\n\n\n\n\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","29a9c49c":"filedttrain = \"..\/input\/fashion-mnist_train.csv\"\nfiledttest  = \"..\/input\/fashion-mnist_test.csv\"\ndftr = pd.read_csv(filedttrain)\ndfte = pd.read_csv(filedttest)","26fe5e35":"print(dftr.info())\nprint(dfte.info())","d4a0bf73":"print(dftr.head(3))\nprint(dftr.tail(3))","b00ca1b5":"print(dfte.head(3))\nprint(dfte.tail(3))","d62f1f2a":"def interpretar(dataframe):\n    # Select all columns but the first\n    caract = dataframe.values[:, 1:]\/255\n    # The first column is the label. Conveniently called 'label'\n    etiqueta = dataframe['label'].values\n    return caract, etiqueta ","904eabb3":"car_entr,etiq_entr =interpretar(dftr)\ncar_pru,etiq_pru =interpretar(dfte)\nm_train = car_entr.shape[0]\nm_test = car_pru.shape[0]\n","ff2347b7":"print(\"X_train shape: \" + str(car_entr.shape))\nprint(\"y_train shape: \" + str(etiq_entr.shape))\nprint(\"X_test shape: \" + str(car_pru.shape))\nprint(\"y_test shape: \" + str(etiq_pru.shape))\nprint (\"# de registros de entrenamiento: m_train = \" + str(m_train))\nprint (\"# de registros de prueba: m_test = \" + str(m_test))","c6e9ec1e":"PruebaIndice = 49999\nplt.figure()\n_ = plt.imshow(np.reshape(car_entr[PruebaIndice, :], (28,28)), 'gray')","44ec2099":"PruebaIndice = 10\nplt.figure()\n_ = plt.imshow(np.reshape(car_pru[PruebaIndice, :], (28,28)), 'gray')","b55e7e1a":"np.random.seed(0);\nPruebaIndice = list(np.random.randint(m_train,size=9))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    plt.imshow(car_entr[PruebaIndice[i]].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Index {} Class {}\".format(PruebaIndice[i], etiq_entr[PruebaIndice[i]]))\n    plt.tight_layout()","07bad9cc":"etiq_entr.shape","7b70a72a":"etiq_entr[PruebaIndice]","595f3dbf":"etiq_entr = tf.keras.utils.to_categorical(etiq_entr)\netiq_pru = tf.keras.utils.to_categorical(etiq_pru)","7285ec18":"etiq_entr[PruebaIndice]","69927a64":"var_iteracion=2\nvar_size=128\nvar_iteracionV2=15\nvar_sizeV2=128","2e3faff7":"##VERSION 1\nmodelV1 = tf.keras.Sequential()\nmodelV1.add(tf.keras.layers.Dense(30, activation=tf.nn.relu, input_shape=(784,)))\nmodelV1.add(tf.keras.layers.Dense(20, activation=tf.nn.relu))\nmodelV1.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))","53555750":"##VERSION 2\nmodelV2 = tf.keras.Sequential()\nmodelV2.add(tf.keras.layers.Dense(60, activation=tf.nn.relu, input_shape=(784,)))\nmodelV2.add(tf.keras.layers.Dense(50, activation=tf.nn.sigmoid))\nmodelV2.add(tf.keras.layers.Dense(40, activation=tf.nn.tanh))\n#modelV2.add(tf.keras.layers.Dense(20, activation=tf.nn.tanh,kernel_regularizer=regularizers.l2(0.01),\n#                activity_regularizer=regularizers.l1(0.01)))\nmodelV2.add(tf.keras.layers.Dense(30,Dropout(0.4)))\nmodelV2.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))","c3ad346b":"P_lossV1='categorical_crossentropy'","f5ef70e6":"P_optimizerV1 = tf.train.RMSPropOptimizer(learning_rate=0.005)","cee42db6":"P_optimizerV2 = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)","b613a914":"modelV1.compile(loss=P_lossV1,\n              optimizer=P_optimizerV1,\n              metrics=['accuracy'])","0ae50d6e":"modelV2.compile(loss=P_lossV1,\n              optimizer=P_optimizerV2,\n              metrics=['accuracy'])","c193efda":"modelV1.summary()","528c0242":"modelV2.summary()","ff0e619b":"Hist1=modelV1.fit(car_entr,etiq_entr, epochs=var_iteracion, batch_size=var_size)","caeaaeb5":"modelV2.fit(car_entr,etiq_entr, epochs=var_iteracionV2, batch_size=var_sizeV2)","33266beb":"# evaluamos el modelo\nscores = modelV1.evaluate(car_pru, etiq_pru)\n \nprint(\"\\n%s: %.2f%%\" % (modelV1.metrics_names[1], scores[1]*100))\nprint (modelV1.predict(car_pru).round())","80886174":"scores = modelV2.evaluate(car_pru, etiq_pru)\n \nprint(\"\\n%s: %.2f%%\" % (modelV2.metrics_names[1], scores[1]*100))\nprint (modelV2.predict(car_pru).round())","08b99a5c":"Funcion para separar las etiquetas de las imagenes","78b29625":"Comparacion de los modelos ","443be225":"Optimizador ADAM\n\n\nParametros por defecto\n\nlr: float >= 0. Learning rate.\nbeta_1: float, 0 < beta < 1. Generally close to 1.\nbeta_2: float, 0 < beta < 1. Generally close to 1.\nepsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\ndecay: float >= 0. Learning rate decay over each update.\namsgrad: boolean. Whether to apply the AMSGrad variant of this algorithm from the paper \"On the Convergence of Adam and Beyond\".","f03dc431":"Verificacion de las imagenes cargadas","ec9f2487":"**Manejo de funcion de perdida**","e18d4baa":"Se definio un segunda topologia de red agrgando 2 layers con funciones de activacion diferente y un layer adicionar que servira como un regularizador \"Dropout\" para evitar el sobreajuste ","75d61b35":"RMSprop\n\nOpcion recomendada para redes neuronales recurrentes \n\nArgumentos por Defecto\n\nlr: float >= 0. Learning rate.\nrho: float >= 0.\nepsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\ndecay: float >= 0. Learning rate decay over each update.","20413146":"Desarrollar a red neuronal con una arquitectura de hiperparametros que mejor clasifique elementos de ropa, para lo cual trabajaremos con el set de datis Fashion MNIST\nUna de las condiciones para el desarrollo del ejercicio es que la topologia de la red todos los nodos deben ser densos.","bb5a20b4":"## Conclusiones ","b890b76e":"**Tpologia de la red**","2dc9fb1e":"\nCon el objetivo de poder utilizar la funcion de perdida categorical_crossentropy , se convierten las categorias y las etiquetas de enteros a matrices binarias (1,0) ","e911e412":"## Carga de informaci\u00f3n ","b6e7da3b":"**Datos de Configuracion**\nSe presenta una red neuronal de secuencial de varias capas densas que era una de las exigencias del taller.\n\nEn este c\u00f3digo expresamos expl\u00edcitamente en el argumento input_shape  de la primera capa c\u00f3mo son los datos de entrada: un tensor que indica que tenemos 784 features del modelo (en realidad el tensor que se est\u00e1 definiendo es de (None, 784,).\n\nLa \u00faltima capa es una capa softmax de 10 neuronas, lo que significa que devolver\u00e1 una matriz de 10 valores de probabilidad que representan a los 10 art\u00edculos de vestir posibles.\nLa capa de salida de una red de clasificaci\u00f3n tendr\u00e1 tantas neuronas como clases. Cada valor ser\u00e1 la probabilidad de que la imagen pertenezca a cada una de ellas.\n","4817eb84":"Definicion de Iteraciones y Tamano","64193fbf":"## Tratamiento de Informaci\u00f3n","83d5853d":"## Objetivo","c477e436":"**Compilacion del modelo**","f833df2a":"**Entrenamiento del modelo**","c95fdad7":"** Manejo de optimizadores **","aaa58bac":"Se trabajo con 2 topologias de redes diferentes, ajustando los hiperparametros con el fin de obtener resultados mas exitosos en la red neuronal mas robusta.\n\nAl finalizar el ejercicio despu\u00e9s de varias ejecuciones y modificaciones en los hiperparametros la red neuronal con mayor robustez presento un mejor desempe\u00f1o, se debe trabajar de manera m\u00e1s certera en la identificaci\u00f3n de los hiperpar\u00e1metros para alcanzar el m\u00e1ximo rendimiento de las redes neuronales.\n\nAunque en las ejecuciones de entrenamiento se supero el 90% en las pruebas el maximo valor alcanzodo en el accuracy fue del 87%"}}