{"cell_type":{"4fab3d99":"code","d87265fa":"code","e4076da8":"code","0aecc934":"code","291ab77a":"code","3389bf13":"code","a7a225cc":"code","fade34e7":"code","a9c42f55":"code","48572064":"code","66db31f5":"code","58e33e2d":"code","866711a8":"code","4e854a29":"code","3d71ed74":"code","13948e45":"code","20f762a5":"code","03fcefce":"code","149a5430":"code","03815168":"code","4523b4f5":"code","eaa55a20":"code","7b9702e4":"code","d171966a":"code","96b3d2fa":"code","5a5e9587":"markdown","7bdf00c3":"markdown","da0aed87":"markdown","0b030be9":"markdown","c4f68c64":"markdown","6297d471":"markdown","89aab96f":"markdown","fad8bb60":"markdown","00f5d18e":"markdown","a593ae5d":"markdown","ba4319a1":"markdown","389ea71c":"markdown"},"source":{"4fab3d99":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","d87265fa":"# . ,(),[]","e4076da8":"#bring in the six packs\ndf_train = pd.read_csv(r'..\\data_eda.csv')","0aecc934":"#check the decoration\ndf_train.columns","291ab77a":"#descriptive statistics summary\ndf_train['SalePrice'].describe()","3389bf13":"#'Very well... It seems that your minimum price is larger than zero. Excellent!","a7a225cc":"#histogram\nsns.distplot(df_train['SalePrice']);","fade34e7":"#skewness and kurtosis\nprint(\"Skewness: %f\" % df_train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())","a9c42f55":"# Task to do - Formulae and acceptable values of kurtosis","48572064":"#scatter plot grlivarea\/saleprice\nvar = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n#print(data)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","66db31f5":"#scatter plot totalbsmtsf\/saleprice\nvar = 'TotalBsmtSF'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","58e33e2d":"#box plot overallqual\/saleprice\nvar = 'OverallQual'\ndata_boxplot = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data_boxplot)\nfig.axis(ymin=0, ymax=800000);","866711a8":"var = 'YearBuilt'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);\nplt.xticks(rotation=90);\n","4e854a29":"corrmat = df_train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","3d71ed74":"#saleprice correlation matrix\nk = 10 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n#print(cols)\ncm = np.corrcoef(df_train[cols].values.T)\n#print(cm)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","13948e45":"#scatterplot\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(df_train[cols], size = 2.5)\nplt.show();","20f762a5":"df_train['TotalBsmtSF'].describe()","03fcefce":"df_train['GrLivArea'].describe()","149a5430":"#missing data\ntotal = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","03815168":"#(missing_data[missing_data['Total'] > 1]).index\ndf_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index,axis=1)\ndf_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\ndf_train.isnull().sum().max() #just checking that there's no missing data missing...","4523b4f5":"#standardizing data\nsaleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);\nlow_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\nhigh_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\nprint('outer range (low) of the distribution:')\nprint(low_range)\nprint('\\nouter range (high) of the distribution:')\nprint(high_range)","eaa55a20":"#Bivariate analysis\u00b6\nvar = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","7b9702e4":"#deleting points\ndf_train.sort_values(by = 'GrLivArea', ascending = False)[:2]","d171966a":"df_train = df_train.drop(df_train[df_train['Id'] == 1299].index)\ndf_train = df_train.drop(df_train[df_train['Id'] == 524].index)","96b3d2fa":"var = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","5a5e9587":"In order to have some discipline in our analysis, we can create an Excel spreadsheet with the following columns:\n\nVariable - Variable name.\nType - Identification of the variables' type. There are two possible values for this field: 'numerical' or 'categorical'. By 'numerical' we mean variables for which the values are numbers, and by 'categorical' we mean variables for which the values are categories.\n\nSegment - Identification of the variables' segment. We can define three possible segments: building, space or location. When we say 'building', we mean a variable that relates to the physical characteristics of the building (e.g. 'OverallQual'). When we say 'space', we mean a variable that reports space properties of the house (e.g. 'TotalBsmtSF'). Finally, when we say a 'location', we mean a variable that gives information about the place where the house is located (e.g. 'Neighborhood').\n\nExpectation - Our expectation about the variable influence in 'SalePrice'. We can use a categorical scale with 'High', 'Medium' and 'Low' as possible values.\nConclusion - Our conclusions about the importance of the variable, after we give a quick look at the data. We can keep with the same categorical scale as in 'Expectation'.\n","7bdf00c3":"## First things first: analysing 'SalePrice'\n'SalePrice' is the reason of our quest. It's like when we're going to a party. We always have a reason to be there. Usually, women are that reason. (disclaimer: adapt it to men, dancing or alcohol, according to your preferences)","da0aed87":"Out liars!\nOutliers is also something that we should be aware of. Why? Because outliers can markedly affect our models and can be a valuable source of information, providing us insights about specific behaviours.\n\nOutliers is a complex subject and it deserves more attention. Here, we'll just do a quick analysis through the standard deviation of 'SalePrice' and a set of scatter plots.\n\nUnivariate analysis\nThe primary concern here is to establish a threshold that defines an observation as an outlier. To do so, we'll standardize the data. In this context, data standardization means converting data values to have mean of 0 and a standard deviation of 1.","0b030be9":"## Missing data\u00b6\nImportant questions when thinking about missing data:\n\nHow prevalent is the missing data?\nIs missing data random or does it have a pattern?\nThe answer to these questions is important for practical reasons because missing data can imply a reduction of the sample size. This can prevent us from proceeding with the analysis. Moreover, from a substantive perspective, we need to ensure that the missing data process is not biased and hidding an inconvenient truth.","c4f68c64":"'Ah! I see you that you use seaborn makeup when you're going out... That's so elegant! I also see that you:\n\nDeviate from the normal distribution.\nHave appreciable positive skewness.\nShow peakedness.\nThis is getting interesting! 'SalePrice', could you give me your body measures?'","6297d471":"1) Understand the problem. We'll look at each variable and do a philosophical analysis about their meaning and importance for this problem.\n2) Univariable study. We'll just focus on the dependent variable ('SalePrice') and try to know a little bit more about it.\n3) Multivariate study. We'll try to understand how the dependent variable and independent variables relate.\n4) Basic cleaning. We'll clean the dataset and handle the missing data, outliers and categorical variables.\n5) Test assumptions. We'll check if our data meets the assumptions required by most multivariate techniques.","89aab96f":"# How box plot was built\n\nIQR = P75-P25\nEdges = P75+1.5IQR , P25-1.5IQR [Beyond these are your outliers]\n\n","fad8bb60":"#Skewness is a measure of symmetry, or more precisely, the lack of symmetry. A distribution, or data set, is symmetric if it looks the same to the left and right of the center point. Kurtosis is a measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution.\n\nAcceptable value of Skewness +\/-2 [normal distribution]\nSkew = 3 * (Mean \u2013 Median) \/ Standard Deviation\nkurtosis = 3[ideal value for normal distribution]","00f5d18e":"## EDA - It's all about applying the logical mind","a593ae5d":"Let's analyse this to understand how to handle the missing data.\n\nWe'll consider that when more than 15% of the data is missing, we should delete the corresponding variable and pretend it never existed. This means that we will not try any trick to fill the missing data in these cases. According to this, there is a set of variables (e.g. 'PoolQC', 'MiscFeature', 'Alley', etc.) that we should delete. The point is: will we miss this data? I don't think so. None of these variables seem to be very important, since most of them are not aspects in which we think about when buying a house (maybe that's the reason why data is missing?). Moreover, looking closer at the variables, we could say that variables like 'PoolQC', 'MiscFeature' and 'FireplaceQu' are strong candidates for outliers, so we'll be happy to delete them.","ba4319a1":"#### fill missing values with mean column values\n-->  dataset.fillna(dataset.mean(), inplace=True)","389ea71c":"### Relationship with numerical variables"}}