{"cell_type":{"d9e7a9c4":"code","beb60ebb":"code","c4ee5f4e":"code","b4aaf976":"code","a7abf2d7":"code","6e05edf7":"code","40887638":"code","49674087":"code","e4a4bd13":"code","4baf1b69":"code","43cb63b9":"code","cf08e9c1":"code","77a6a759":"code","abed7182":"code","f9a60ab6":"code","b2877a01":"code","b190eae9":"code","86f55da4":"code","6699d742":"code","60321b23":"code","d812d7a1":"code","2f9ae8f7":"code","8c5642ec":"code","4d80a304":"code","0d09b86d":"code","90be6161":"code","1d2dd679":"code","26a15765":"code","8265aedd":"code","5585f27a":"code","29231f7c":"markdown","eac03c05":"markdown","9236962a":"markdown","c095354c":"markdown","d1cad304":"markdown","d0161aa2":"markdown","bcf5729b":"markdown","1a41414b":"markdown","c897d9f3":"markdown","fd14dce4":"markdown","3669e031":"markdown","0e42de3b":"markdown"},"source":{"d9e7a9c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","beb60ebb":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go","c4ee5f4e":"df = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')","b4aaf976":"df.head()","a7abf2d7":"df.shape","6e05edf7":"columns = df.columns.tolist()\ncolumns","40887638":"df.isna().sum()","49674087":"sns.pairplot(df)","e4a4bd13":"corr_mat = df.corr()\ncorr_mat = corr_mat.to_numpy()\ncorr_mat = np.round(corr_mat,2)","4baf1b69":"import plotly.figure_factory as ff\n\nz = corr_mat\n\nfig = ff.create_annotated_heatmap(z, colorscale='Viridis', x=columns, y=columns, showscale=True)\nfig['layout']['xaxis']['side'] = 'bottom'\nfig.show()","43cb63b9":"positive = len(df.loc[df['Outcome'] == 1])\nnegative = len(df.loc[df['Outcome'] == 0])","cf08e9c1":"print('Number of Positive result: ' + str(positive))\nprint('Number of Negative result: ' + str(negative))","77a6a759":"colors = ['lightslategray',] * 2\ncolors[1] = 'crimson'\nfig = go.Figure(go.Bar(x=['Positive', 'Negative'], \n                       y=[positive, negative],\n                       text=[positive, negative],\n                       textposition='auto', \n                       marker_color=colors))\n\nfig.update_layout(title_text='Number of Positive and Negative cases')\n\nfig.show()","abed7182":"from sklearn.model_selection import train_test_split","f9a60ab6":"# Spilliting dataset into dependent and independent dataset\n\nX = df.drop(['Outcome'], axis=1)\ny = df['Outcome']","b2877a01":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nsc_X = pd.DataFrame(scaler.fit_transform(X.copy()))","b190eae9":"X_train, X_test, y_train, y_test = train_test_split(sc_X, y, test_size=0.33, random_state=1)","86f55da4":"from sklearn.neighbors import KNeighborsClassifier\n\n\ntest_scores = []\ntrain_scores = []\n\nfor i in range(1,15):\n\n    knn = KNeighborsClassifier(i)\n    knn.fit(X_train,y_train)\n    \n    train_scores.append(knn.score(X_train,y_train))\n    test_scores.append(knn.score(X_test,y_test))","6699d742":"x = []\nfor i in range(1,15):\n    x.append(i)","60321b23":"# Create traces\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=x, y=train_scores,\n                    mode='lines+markers',\n                    name='train'))\n\nfig.add_trace(go.Scatter(x=x, y=test_scores,\n                    mode='lines+markers',\n                    name='test'))\n\nfig.update_layout(title='k vs score (train and test)',\n                   xaxis_title='k',\n                   yaxis_title='score')\n\nfig.show()","d812d7a1":"print(f'Max train score: {max(train_scores)*100}% with k values: {train_scores.index(max(train_scores))+1}')\n\nprint(f'Max test score: {round(max(test_scores)*100,2)}% with k values: {test_scores.index(max(test_scores))+1}')","2f9ae8f7":"k = test_scores.index(max(test_scores))+1\nknn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(X_train, y_train)\n\npredictions = knn.predict(X_test)","8c5642ec":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score","4d80a304":"print(classification_report(y_test, predictions))","0d09b86d":"accuracy = round(accuracy_score(y_test, predictions),4)\nprint(f\"\\033[94m Accuracy: {accuracy*100}%\\033[00m\")","90be6161":"cm = confusion_matrix(y_test, predictions)\nprint(f\"\\033[92m{cm}\\033[00m\")","1d2dd679":"import plotly.figure_factory as ff\n\nl = []\nl.append(cm[1])\nl.append(cm[0])\nz = l\n\nfig = ff.create_annotated_heatmap(z, colorscale='darkmint')\n\n# add title\nfig.update_layout(title_text='<i><b>Confusion matrix<\/b><\/i>')\n\n# add custom xaxis title\nfig.add_annotation(dict(font=dict(color=\"black\",size=14),\n                        x=0.5,\n                        y=-0.15,\n                        showarrow=False,\n                        text=\"Predicted value\",\n                        xref=\"paper\",\n                        yref=\"paper\"))\n\n# add custom yaxis title\nfig.add_annotation(dict(font=dict(color=\"black\",size=14),\n                        x=-0.05,\n                        y=0.5,\n                        showarrow=False,\n                        text=\"Actual value\",\n                        textangle=-90,\n                        xref=\"paper\",\n                        yref=\"paper\"))\n\n# adjust margins to make room for yaxis title\nfig.update_layout(margin=dict(t=50, l=80))\n\n# add colorbar\nfig.show()","26a15765":"from sklearn.model_selection import RandomizedSearchCV","8265aedd":"param_grid = {'n_neighbors':np.arange(1,50)}\nknn = KNeighborsClassifier()\nknn_cv= RandomizedSearchCV(knn,param_grid,cv=5)\nknn_cv.fit(X,y)\n\nprint(\"Best Score:\" + str(knn_cv.best_score_))\nprint(\"Best Parameters: \" + str(knn_cv.best_params_))","5585f27a":"res = pd.DataFrame({'Actual': y_test, 'Predictions': predictions})\nres","29231f7c":"<font size=3.7><strong>Checking for null values<\/strong><\/font>","eac03c05":"<font size=3.7 color='green'>As you can see there are no null values present in the whole dataset.<\/font>","9236962a":"Here, I am not going to apply the result I get from RandomizedSearchCV as it's score value is less than our own trained model. ","c095354c":"# Importing Dependencies","d1cad304":"# Applying RandomizedSearchCV","d0161aa2":"# Reading Data","bcf5729b":"# Final Result","1a41414b":"# Scaling the data","c897d9f3":"<font size=3.7><strong>Correlation matrix<\/strong><\/font>","fd14dce4":"# Splitting data into Training and Testing dataset","3669e031":"<font size=5><strong>Pima Indians Diabetes Database<\/strong><\/font>\n\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\n<font size=5><strong>Content<\/strong><\/font>\n\nThe datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n\n<font size=5><strong>Acknowledgements<\/strong><\/font>\n\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press.\n\n## Columns in given Dataset\n\n<font size=3.7><strong>Pregnancies<\/strong><\/font>\n - Number of times pregnant\n \n<font size=3.7><strong>Glucose<\/strong><\/font>\n - Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n\n<font size=3.7><strong>BloodPressure<\/strong><\/font>\n - Diastolic blood pressure (mm Hg)\n\n<font size=3.7><strong>SkinThickness<\/strong><\/font>\n - Triceps skin fold thickness (mm)\n\n<font size=3.7><strong>Insulin<\/strong><\/font>\n - 2-Hour serum insulin (mu U\/ml)\n\n<font size=3.7><strong>BMI<\/strong><\/font>\n - Body mass index (weight in kg\/(height in m)^2)\n\n<font size=3.7><strong>DiabetesPedigreeFunction<\/strong><\/font>\n - Diabetes pedigree function\n\n<font size=3.7><strong>Age<\/strong><\/font>\n - Age (years)\n\n<font size=3.7><strong>Outcome<\/strong><\/font>\n - Class variable (0 or 1) 268 of 768 are 1, the others are 0","0e42de3b":"<font size=4><strong>Pairplot for data<\/strong><\/font>"}}