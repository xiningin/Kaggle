{"cell_type":{"fc72be7f":"code","0552f363":"code","ce02a85c":"code","8016e19b":"code","b57325ca":"code","085b348d":"code","9147a1c4":"code","8ede488b":"code","7aa6ccd6":"code","232816a1":"code","76173e1a":"code","48d032ce":"code","6c511fe0":"code","eef55e58":"code","64db5584":"code","83797495":"code","4bf169de":"code","afa97fb0":"code","40ba9fa0":"code","de9e1aed":"code","3366cfa3":"code","f92f2aa7":"code","071ef41b":"code","e7ae08d4":"code","df44a44e":"code","789e5217":"code","4842542a":"code","77331942":"code","45a9ac79":"code","57083caf":"code","474bc017":"code","f8a05c86":"code","1bba9388":"code","4fc07a00":"code","28e481bc":"code","d847d29c":"code","68ae45b9":"code","24facff2":"code","a196e221":"code","3081da6d":"code","34b6030e":"code","b26aa338":"code","6fd18dae":"code","41adb1c0":"code","e20f5d79":"code","bdf67fc7":"code","0e3e7a3d":"code","5853cb14":"code","9aa7bba4":"code","4a88dc4b":"code","e9b79129":"code","c64e1844":"code","1ebbbbe4":"code","6426e9a4":"code","a1d3d1f7":"code","37ba1d8a":"code","94f84702":"code","ac035812":"code","32a6117c":"code","79475a27":"code","53dcbfa2":"code","3b906f27":"code","c5ee28d7":"code","b506f96f":"code","cdbe2bc9":"code","4517cb80":"code","085d42e9":"code","f2ff9a0a":"code","fe8327c7":"code","1c099daa":"code","ecad25e7":"code","76abbf33":"code","c11b1536":"code","50ac0ef2":"code","fbca28ff":"code","ebb8c5f2":"code","3b47af86":"code","cd7dbaa1":"code","898ad122":"code","8d252a9d":"code","d0483bfc":"code","9057cbca":"code","4bec6a12":"code","cccd2bea":"code","01cea086":"code","78e0bb5c":"code","f496ede0":"code","e1e5cf54":"code","4de59323":"code","3edec833":"code","964e66c7":"code","a2a0be11":"code","585c579c":"code","7082558e":"code","cd5d1a7d":"code","57783599":"code","4caa7d02":"code","f38a4669":"code","8b497865":"code","91caf6f0":"code","d6341b3a":"code","175db6a5":"code","f0652ca7":"code","cb06bada":"code","23a0a048":"code","c3d75f55":"code","5a7834a6":"code","2ae88367":"code","63e75e06":"code","4302f91d":"code","eb13a986":"code","4bece7e1":"code","88bd1b2f":"code","ee1d27a8":"code","bfcd7bd8":"code","7e9f3e6f":"code","5f79c45d":"code","b942e196":"code","d7bfb0e4":"markdown","9e742e23":"markdown","5f6eb66a":"markdown","0818c6a0":"markdown","c8a8d6b0":"markdown","7480a6b7":"markdown","6f77c889":"markdown","ae1792df":"markdown","d1a8303c":"markdown","f84bae89":"markdown","9dd330ed":"markdown","0641a035":"markdown","4f018c00":"markdown","ed8863c7":"markdown","aa78b4d2":"markdown","407f8117":"markdown","f87f9ed2":"markdown","ee3e3975":"markdown","8fafc4b1":"markdown","d280455b":"markdown","f74233cb":"markdown","77146d13":"markdown","796881cc":"markdown","bb7c5163":"markdown","fe6414ab":"markdown","d070d138":"markdown","a1173479":"markdown","77592424":"markdown","b2be819c":"markdown","3fd6eef9":"markdown","8c10c65a":"markdown","65f46660":"markdown","eb9500a1":"markdown","5f0a0589":"markdown"},"source":{"fc72be7f":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0552f363":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","ce02a85c":"df_train = pd.read_excel('..\/input\/flipr-hiring-challenge\/Train_dataset.xlsx')\ndf_test = pd.read_excel('..\/input\/flipr-hiring-challenge\/Test_dataset.xlsx')\ndf_train.head(14)","8016e19b":"df_train.describe()","b57325ca":"df_train.info()","085b348d":"df_train.isna().sum()","9147a1c4":"for col in df_train.columns:\n    print(\"col-name: \", col, \" | no_of_unique_values: \", df_train[col].nunique(dropna=True))","8ede488b":"df_train = df_train.drop(['Designation', 'Name'], axis = 1)\ndf_train.head(10)","7aa6ccd6":"# import pandas_profiling\n# df_train.profile_report()","232816a1":"df_train.Infect_Prob[(df_train['Infect_Prob']>45.0) & (df_train['Infect_Prob']<55.0)].count()","76173e1a":"from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n\nlb = LabelBinarizer()\ndf_train['Gender'] = lb.fit_transform(df_train.Gender)\ndf_train['Married'] = lb.fit_transform(df_train.Married)\n\n\ndf_train.head(5)","48d032ce":"import missingno as msno\nmsno.matrix(df_train)","6c511fe0":"msno.heatmap(df_train)","eef55e58":"df_train.Children.isna().sum()","64db5584":"df_train.Married[(df_train['Married']==0.0) & (df_train['Children'].isna()==1)].count()","83797495":"def impute_children(cols):\n    children = cols[0]\n    married = cols[1]\n    \n    if np.isnan(children):\n        if married == 0.0:\n            return 0\n        else:\n            return children\n    else:\n        return children\n\ndf_train['Children'] = df_train[['Children', 'Married']].apply(impute_children, axis=1)          \n    ","4bf169de":"df_train.Children.isna().sum()","afa97fb0":"df_train.salary[df_train['Occupation'].isna()].head()","40ba9fa0":"sns.boxplot(x = \"Occupation\", y = \"salary\", hue='Gender', data = df_train)","de9e1aed":"sns.countplot(x = \"Occupation\", hue = \"Gender\", data = df_train)","3366cfa3":"sns.countplot(x = \"Occupation\", data = df_train)","f92f2aa7":"sns.boxplot(x='Occupation', y='salary', data=df_train)","071ef41b":"sns.scatterplot(x='Occupation', y='salary', data=df_train)","e7ae08d4":"sns.boxplot(x='Occupation', y='Infect_Prob', data=df_train)","df44a44e":"sns.boxplot(x='Occupation', y='Charlson Index',hue='Gender', data=df_train)","789e5217":"sns.boxplot(x='Occupation', y='HDL cholesterol',hue='Gender', data=df_train)","4842542a":"df_train[df_train.Mode_transport.isna()].head()","77331942":"sns.countplot(x='Mode_transport', data=df_train)","45a9ac79":"df_train['Mode_transport'] = df_train.Mode_transport.fillna('Public')\ndf_train.Mode_transport.isna().sum()","57083caf":"sns.countplot(x='comorbidity', data=df_train)","474bc017":"# sns.catplot(x=\"comorbidity\", y='salary', hue=\"Gender\", kind='swarm', data=df_train)","f8a05c86":"df_train['comorbidity'] = df_train.comorbidity.fillna('None')\ndf_train.comorbidity.isna().sum()","1bba9388":"sns.countplot(x='cardiological pressure', data=df_train)","4fc07a00":"sns.boxplot(x='cardiological pressure', y='HDL cholesterol',hue='Gender', data=df_train)","28e481bc":"sns.boxenplot(x='Gender', y='Age',hue='cardiological pressure', data=df_train)","d847d29c":"sns.boxplot(x='cardiological pressure', y='Infect_Prob', data=df_train)","68ae45b9":"df_train['cardiological pressure'] = df_train['cardiological pressure'].fillna('Normal')\ndf_train['cardiological pressure'].isna().sum()","24facff2":"df_train['Diuresis'] = df_train['Diuresis'].fillna(df_train['Diuresis'].mean())\ndf_train['Diuresis'].isna().sum()","a196e221":"df_train['Platelets'] = df_train['Platelets'].fillna(df_train['Platelets'].mean())\ndf_train['Platelets'].isna().sum()","3081da6d":"df_train['HBB'] = df_train['HBB'].fillna(df_train['HBB'].mean())\ndf_train['HBB'].isna().sum()","34b6030e":"df_train['d-dimer'] = df_train['d-dimer'].fillna(df_train['d-dimer'].mean())\ndf_train['d-dimer'].isna().sum()","b26aa338":"df_train['Heart rate'] = df_train['Heart rate'].fillna(df_train['Heart rate'].mean())\ndf_train['Heart rate'].isna().sum()","6fd18dae":"df_train['HDL cholesterol'] = df_train['HDL cholesterol'].fillna(df_train['HDL cholesterol'].mean())\ndf_train['HDL cholesterol'].isna().sum()","41adb1c0":"df_train.head()","e20f5d79":"df_train[(df_train.Occupation.isna()) & (df_train.Insurance.isna())].count()","bdf67fc7":"df_train[~(df_train.Occupation.isna()) & (df_train.Insurance.isna())].count()","0e3e7a3d":"means_ins = df_train.groupby('Occupation')['Insurance'].mean()\nmean_ins = df_train.Insurance.mean()\nprint(mean_ins)\nmeans_ins\n","5853cb14":"means_ins['Cleaner']","9aa7bba4":"def impute_insurance(cols):\n    occ = cols[0]\n    ins = cols[1]\n\n    if pd.isnull(ins):\n        if not pd.isnull(occ):\n            ins = means_ins[str(occ)]\n            return ins \n        else:\n            return mean_ins\n    else:\n        return ins\n\n    \ndf_train['Insurance'] = df_train[['Occupation', 'Insurance']].apply(impute_insurance, axis=1)\ndf_train.Insurance.isna().sum()","4a88dc4b":"sns.boxenplot(x='FT\/month', y='salary', data=df_train)","e9b79129":"df_train['FT\/month'] = df_train['FT\/month'].fillna(df_train['FT\/month'].median())\ndf_train['FT\/month'].isna().sum()","c64e1844":"sns.countplot(x='Region', data=df_train)","1ebbbbe4":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf_train['Region']= le.fit_transform(df_train['Region'])\n# df_train['Occupation']= le.fit_transform(df_train['Occupation'])\ndf_train['Mode_transport']= le.fit_transform(df_train['Mode_transport'])\ndf_train['comorbidity']= le.fit_transform(df_train['comorbidity'])\n\ndf_train.head()","6426e9a4":"sns.boxenplot(x='Diuresis', y='Infect_Prob', hue='Gender', data=df_train)","a1d3d1f7":"sns.boxenplot(x='Region', y='Infect_Prob', data=df_train)","37ba1d8a":"sns.boxenplot(x='Occupation', y='Mode_transport', data=df_train)","94f84702":"sns.countplot(x='Occupation', hue='Region', data=df_train)","ac035812":"sns.countplot(x='Occupation', hue='Mode_transport', data=df_train)","32a6117c":"# sns.pairplot(df_train)","79475a27":"# for i, col in enumerate(df_train.columns):\n#     if not col in ['Occupation', 'people_ID','Pulmonary score','cardiological pressure','Diuresis','Platelets','HBB','d-dimer','Heart rate','HDL cholesterol','Charlson Index','Blood Glucose', 'Infect_Prob']:\n#         plt.figure(i)\n#         sns.countplot(x=col, hue='Occupation', data=df_train)","53dcbfa2":"df_train = df_train.drop(['Occupation'], axis=1)\ndf_train.head()","3b906f27":"df_train['Pulmonary score'] = df_train['Pulmonary score'].str.replace('<', '')\ndf_train['Pulmonary score'].head()","c5ee28d7":"df_train.head()","b506f96f":"df_train.drop(['Region', 'Deaths\/1M'],axis=1, inplace=True)","cdbe2bc9":"df_train = pd.concat([df_train,pd.get_dummies(df_train['Mode_transport'], prefix='Mode_transport')],axis=1)\ndf_train = pd.concat([df_train,pd.get_dummies(df_train['comorbidity'], prefix='comorbidity')],axis=1)\ndf_train.drop(['Mode_transport', 'comorbidity'],axis=1, inplace=True)\ndf_train.head()","4517cb80":"col_list = df_train.columns\ncol_list = ['people_ID','Mode_transport_0','Mode_transport_1','Mode_transport_2', 'Gender', 'Married', 'Children',\n       'cases\/1M','comorbidity_0','comorbidity_1','comorbidity_2','comorbidity_3', 'Age',\n       'Coma score', 'Pulmonary score', 'cardiological pressure', 'Diuresis',\n       'Platelets', 'HBB', 'd-dimer', 'Heart rate', 'HDL cholesterol',\n       'Charlson Index', 'Blood Glucose', 'Insurance', 'salary', 'FT\/month',\n       'Infect_Prob']\ndf_train = df_train[col_list]\ndf_train.head()","085d42e9":"df_train = pd.concat([df_train,pd.get_dummies(df_train['cardiological pressure'], prefix='cardiological pressure')],axis=1)\ndf_train.drop(['cardiological pressure'],axis=1, inplace=True)\ndf_train.head()","f2ff9a0a":"col_list = df_train.columns\ncol_list = ['people_ID','Mode_transport_0','Mode_transport_1','Mode_transport_2', 'Gender', 'Married', 'Children',\n       'cases\/1M','comorbidity_0','comorbidity_1','comorbidity_2','comorbidity_3', 'Age',\n       'Coma score', 'Pulmonary score', 'cardiological pressure_Elevated','cardiological pressure_Normal','cardiological pressure_Stage-01',\n       'cardiological pressure_Stage-02', 'Diuresis',\n       'Platelets', 'HBB', 'd-dimer', 'Heart rate', 'HDL cholesterol',\n       'Charlson Index', 'Blood Glucose', 'Insurance', 'salary', 'FT\/month',\n       'Infect_Prob']\ndf_train = df_train[col_list]\ndf_train.head()","fe8327c7":"from sklearn.preprocessing import MinMaxScaler\ncolumn_names_to_normalize = ['Age','Coma score', 'Pulmonary score', 'Diuresis',\n       'Platelets', 'HBB', 'd-dimer', 'Heart rate', 'HDL cholesterol',\n       'Charlson Index', 'Blood Glucose', 'Insurance', 'salary']\nx = df_train[column_names_to_normalize].values\nmin_max_scaler=MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ndf_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df_train.index)\ndf_train[column_names_to_normalize] = df_temp\n\ndf_train.head()","1c099daa":"df_train['Target_norm'] = df_train[\"Infect_Prob\"]\/100.0\ndf_train.head()","ecad25e7":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor ","76abbf33":"X = df_train.iloc[:, 1:-2]\nY = df_train.iloc[:, -2]\nY_norm = df_train.iloc[:, -1]\nY.count()","c11b1536":"X.head()","50ac0ef2":"Y_norm.dtype","fbca28ff":"sns.distplot(Y)","ebb8c5f2":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.02, random_state = 42)","3b47af86":"X_train, X_test, Y_n_train, Y_n_test = train_test_split(X, Y_norm, test_size = 0.02, random_state = 42)","cd7dbaa1":"rf = RandomForestRegressor(criterion='mse', \n                             n_estimators=500,\n                             min_samples_split=10,\n                             min_samples_leaf=1,\n                             max_features='auto',\n                             oob_score=True,\n                             random_state=1,\n                             n_jobs=-1)\nrf.fit(X_train, Y_n_train)\nprint(\"%.4f\" % rf.oob_score_)","898ad122":"pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n          axis = 1).sort_values(by='importance', ascending = False)","8d252a9d":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train,Y_train)","d0483bfc":"regressor.predict(X_test)\nregressor.score(X_test,Y_test)","9057cbca":"import statsmodels.api as sm\nX_opt = X.iloc[:,:]\nregressor_OLS = sm.OLS(endog=Y, exog=X_opt).fit()\nregressor_OLS.summary()","4bec6a12":"X_train = df_train.iloc[:,1:-2]\nX_train.head()","cccd2bea":"Y_n_train = df_train.iloc[:,-1]\nY_n_train.head()","01cea086":"# def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n#                        model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n#                        do_probabilities = False):\n#     gs = GridSearchCV(\n#         estimator=model,\n#         param_grid=param_grid, \n#         cv=cv, \n#         n_jobs=-1, \n#         scoring=scoring_fit,\n#         verbose=2\n#     )\n#     fitted_model = gs.fit(X_train_data, y_train_data)\n    \n#     if do_probabilities:\n#       pred = fitted_model.predict_proba(X_test_data)\n#     else:\n#       pred = fitted_model.predict(X_test_data)\n    \n#     return fitted_model, pred","78e0bb5c":"import xgboost\nfrom sklearn.model_selection import GridSearchCV\n\n# # Let's try XGboost algorithm to see if we can get better results\n# xgb = xgboost.XGBRegressor()\n# param_grid = {\n#     'n_estimators': [400, 500, 600,700,800],\n#     'learning_rate': [0.002,0.008, 0.02, 0.4, 0.2],\n#     'colsample_bytree': [0.3, 0.4,0.5,0.6,0.7],\n#     'max_depth': [30,40,50,70,100],\n#     'reg_alpha': [1.1, 1.2, 1.3],\n#     'reg_lambda': [1.1, 1.2, 1.3],\n#     'subsample': [0.7, 0.8, 0.9]\n# }","f496ede0":"xgb = xgboost.XGBRegressor(n_estimators=500, learning_rate=0.02, gamma=0, subsample=0.75,alpha=10,\n                           colsample_bytree=0.3, max_depth=100)","e1e5cf54":"# xgb, pred = algorithm_pipeline(X_train, X_test, Y_n_train, Y_n_test, xgb, \n#                                  param_grid, cv=5)","4de59323":"# print(np.sqrt(-xgb.best_score_))\n# print(xgb.best_params_)","3edec833":"xgb.fit(X_train,Y_n_train,eval_metric='rmsle')","964e66c7":"from sklearn.metrics import mean_squared_error\npredictions = xgb.predict(X_test)\nmse = mean_squared_error(predictions,Y_n_test)\nprint(np.sqrt(mse))","a2a0be11":"predictions = predictions*100.0","585c579c":"sns.distplot(predictions)","7082558e":"predictions","cd5d1a7d":"df_test = pd.read_excel('..\/input\/flipr-hiring-challenge\/Test_dataset.xlsx')\ndf_test.head(14)","57783599":"df_test.describe()","4caa7d02":"df_test.info()","f38a4669":"df_test.isna().sum()","8b497865":"for col in df_test.columns:\n    print(\"col-name: \", col, \" | no_of_unique_values: \", df_test[col].nunique(dropna=True))","91caf6f0":"df_test = df_test.drop(['Designation', 'Name'], axis = 1)\ndf_test.head(10)","d6341b3a":"from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n\nlb = LabelBinarizer()\ndf_test['Gender'] = lb.fit_transform(df_test.Gender)\ndf_test['Married'] = lb.fit_transform(df_test.Married)\n\ndf_test.head(5)","175db6a5":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf_test['Region']= le.fit_transform(df_test['Region'])\n# df_train['Occupation']= le.fit_transform(df_train['Occupation'])\ndf_test['Mode_transport']= le.fit_transform(df_test['Mode_transport'])\ndf_test['comorbidity']= le.fit_transform(df_test['comorbidity'])\n\ndf_test.head()","f0652ca7":"df_test = df_test.drop(['Occupation'], axis=1)\ndf_test.head()","cb06bada":"df_test['Pulmonary score'] = df_test['Pulmonary score'].str.replace('<', '')\ndf_test['Pulmonary score'].head()","23a0a048":"df_test.drop(['Region', 'Deaths\/1M'],axis=1, inplace=True)","c3d75f55":"df_test = pd.concat([df_test,pd.get_dummies(df_test['Mode_transport'], prefix='Mode_transport')],axis=1)\ndf_test = pd.concat([df_test,pd.get_dummies(df_test['comorbidity'], prefix='comorbidity')],axis=1)\ndf_test.drop(['Mode_transport', 'comorbidity'],axis=1, inplace=True)\ndf_test.head()","5a7834a6":"col_list = df_test.columns\ncol_list = ['people_ID','Mode_transport_0','Mode_transport_1','Mode_transport_2', 'Gender', 'Married', 'Children',\n       'cases\/1M','comorbidity_0','comorbidity_1','comorbidity_2','comorbidity_3', 'Age',\n       'Coma score', 'Pulmonary score', 'cardiological pressure', 'Diuresis',\n       'Platelets', 'HBB', 'd-dimer', 'Heart rate', 'HDL cholesterol',\n       'Charlson Index', 'Blood Glucose', 'Insurance', 'salary', 'FT\/month']\ndf_test = df_test[col_list]\ndf_test.head()","2ae88367":"df_test = pd.concat([df_test,pd.get_dummies(df_test['cardiological pressure'], prefix='cardiological pressure')],axis=1)\ndf_test.drop(['cardiological pressure'],axis=1, inplace=True)\ndf_test.head()","63e75e06":"col_list = df_test.columns\ncol_list = ['people_ID','Mode_transport_0','Mode_transport_1','Mode_transport_2', 'Gender', 'Married', 'Children',\n       'cases\/1M','comorbidity_0','comorbidity_1','comorbidity_2','comorbidity_3', 'Age',\n       'Coma score', 'Pulmonary score', 'cardiological pressure_Elevated','cardiological pressure_Normal','cardiological pressure_Stage-01',\n       'cardiological pressure_Stage-02', 'Diuresis',\n       'Platelets', 'HBB', 'd-dimer', 'Heart rate', 'HDL cholesterol',\n       'Charlson Index', 'Blood Glucose', 'Insurance', 'salary', 'FT\/month']\ndf_test = df_test[col_list]\ndf_test.head()","4302f91d":"from sklearn.preprocessing import MinMaxScaler\ncolumn_names_to_normalize = ['Age','Coma score', 'Pulmonary score', 'Diuresis',\n       'Platelets', 'HBB', 'd-dimer', 'Heart rate', 'HDL cholesterol',\n       'Charlson Index', 'Blood Glucose', 'Insurance', 'salary']\nx = df_test[column_names_to_normalize].values\nmin_max_scaler=MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ndf_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df_test.index)\ndf_test[column_names_to_normalize] = df_temp\n\ndf_test.head()","eb13a986":"test = df_test.iloc[:,1:]\ntest.head()","4bece7e1":"pred = xgb.predict(test)","88bd1b2f":"pred = pred*100.0","ee1d27a8":"pred","bfcd7bd8":"sns.distplot(pred)","7e9f3e6f":"submission = pd.read_excel('..\/input\/flipr-hiring-challenge\/Test_dataset.xlsx')\nsubmission['infect_prob_20'] = pd.Series(pred)\nsubmission.head()","5f79c45d":"pd.DataFrame(submission, columns=['people_ID', 'infect_prob_20']).to_csv('submission.csv', index = False)\n","b942e196":"sns.scatterplot(x='Diuresis', y='Infect_Prob', data=df_train)","d7bfb0e4":"Implementing XG_Boost","9e742e23":"### Imputing feature 'children'","5f6eb66a":"It seems that both occupation and insurance are not null at the same time. So, we can impute insurance with the mean of each ocuupation","0818c6a0":"### Imputing Insurance","c8a8d6b0":"But first lets drop some unneccessary columns that we know will not contribute to our model selection like name, etc. The followings columns are removed: name, designation because irrespective of the values, it just cannot decide the infection probability","7480a6b7":"## Benchmark Model","6f77c889":"### Normalizing or Standardizing the features","ae1792df":"# prediction time ","d1a8303c":"This is map showing nullity correlation:\n\nIt can be seen that individuals having children have some affinity towards having an insurance and have an occupation.\nThere is high relation between d-dimer and heart-rate, and also platelets and d-dimer | heart-rate.\n\nSo, we will use certain viz for imputations","f84bae89":"All Occupations have moraless equal number of males and females.\nEncoding the occupation feature.","9dd330ed":"It seems that all occupation have been eually affected and no particular occupation is contributing to the prediction","0641a035":"There are many columns having empty values, so we will impute them accordingly. These columns are - name, children, occupation, mode_transport, comorbidity, cardiological pressure, Diuresis, Platelets, HBB, d-dimer, Heart rate, HDL_cholesterol, Insurance, FT\/month","4f018c00":"imputings are done Lets vizualize correlation and do hypothesis testing","ed8863c7":"### Imputing feature 'Occupation'","aa78b4d2":"### Imputing mode_transport","407f8117":"since public transport is the mode of the class, we fill 3 empty cells with Public","f87f9ed2":"### Imputing Diuresis, Platelets, HBB, d-dimer,\tHeart rate,\tHDL cholesterol\n","ee3e3975":"### Imputing feature FT\/month","8fafc4b1":"## Categorical encoding\nencoding region, occupation, mode_transport, comorbidity","d280455b":"Processing pulmonary score","f74233cb":"So there are persons whose occupation is not known but salary is non-empty.","77146d13":"Now, we have to impute the missing values in several columns.\n\nThe method of imputation will vary according to the feature. So we need to visualize how the ","796881cc":"Dropping Occupation column","bb7c5163":"## Imputing missing values","fe6414ab":"### Imputing feature comorbidity","d070d138":"### Imputing feature 'cardiological-pressure'","a1173479":"80% of probability resides between 45 and 55 probability","77592424":"It means that there is no row such that married column is 1 for missing values of Children. Therefore we can atleast place value in children as 0 for the individuals who are no married ","b2be819c":"## Encoding non-null categorical features before imputation\n\nFor gender, married and region- gender and married have binary values, we will encode with LabelEncoder, while one-hot encoding for region","3fd6eef9":"It seems that all four comorbidity equally contribute to the infection probability. Replacing with Normal","8c10c65a":"All occupations have same range of income","65f46660":"Unknown comorbidity means that they didn't know about their illness. Replacing with None","eb9500a1":"Since Region has high collinearity with cases\/1M and Deaths\/1M and cases and death is too linearly related (conclusion drawn from paiwise plot), we will drop Region and Deaths\/1M","5f0a0589":"Since they are continuous values we will replace them by their mean"}}