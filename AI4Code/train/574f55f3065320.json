{"cell_type":{"668cfcd2":"code","a50e8587":"code","6dd740e9":"code","730cbd08":"code","2c04ae98":"code","859d05d2":"code","9dbeb8dc":"code","f4dfd83a":"code","58e22f4a":"code","469d0bc5":"code","33f99bf7":"code","87a75eee":"code","45b92867":"code","ae8d0edd":"code","4167c00b":"code","5403a0a9":"code","c210e2b2":"code","ebefe47b":"code","c6c6773b":"code","e2306847":"code","dc318e86":"code","a419aa86":"code","6de95721":"code","b2f1625d":"code","d32e6e75":"code","0ec2d062":"code","d32850ec":"code","e4156061":"code","e44a935e":"code","ee66e6f9":"code","ce5a18fa":"code","612ba51d":"code","ad4f90c7":"markdown"},"source":{"668cfcd2":"use_own_text = True #for testing set\nuse_train_data = False #use train data for testing","a50e8587":"import os\nDATASET_PATH = '..\/input\/bert-model-weights\/'\nos.listdir(DATASET_PATH)","6dd740e9":"BERT_MODEL_PATHS = [\n 'bert_bert_sb_0.93405_out_1_cpa.pt',\n 'bert_wss_boosted2_cpa_nlabels31_0.93774.pt', #LB 0.935 \n 'bert_wss_aux_ot_rt_0.93803.pt', #LB 0.936\n 'bert_sb1t9_no_identity_ot_rt_cont_rand_sb1t9_0.93574_out_13_cpa.pt',\n 'bert_base_cont_boosted3_sge6_0.93672_out_12_cpa.pt',\n 'bert_base_last_year_competition_cont_pp_no_identity_cont__0.94643_out_1_cpa.pt',  #LB 0.93525\n 'bert_sb_mini_epoch_0.93451_out_8_cpa.pt',\n 'bert_wss_aux_ot_0.93722.pt',\n 'bert_public_0.93373.pt',\n 'bert_subgroup_balanced_20p_target_ist_bert_ga2_0.93370.pt', \n 'bert_yuval_baseline_bert_model_cont_boost_0.93352.pt',\n 'bert_base_0.93327_out_1_cpa.pt',\n]\n\nBERT_MODEL_PATHS = [DATASET_PATH+bmp for bmp in BERT_MODEL_PATHS]","730cbd08":"DATASET_PATH2 = '..\/input\/bertlstm-weights\/'\nos.listdir(DATASET_PATH2)","2c04ae98":"BERT_MODEL_PATHS.append(DATASET_PATH2+'bert_beLSTM_sb2t8_0.91725.pt')\nBERT_MODEL_PATHS.append(DATASET_PATH2+'bert_beLSTM_aux_wss_bad_minor_0.91675.pt')\nBERT_MODEL_PATHS.append(DATASET_PATH2+'bert_beLSTM_aux_wss_0.92162.pt')","859d05d2":"import sys\n#package_dir = \"..\/input\/ppbert\/pytorch-pretrained-bert\/pytorch-pretrained-BERT\"\npackage_dir = '..\/input\/pytorch-pretrained-bert-master\/pytorch-pretrained-bert-master\/pytorch-pretrained-BERT-master\/'\n#custom_weight_dir = '..\/input\/bert model weights\/'\nsys.path.append(package_dir)","9dbeb8dc":"args = {\n    'device' : 'cuda',\n    'learning_rate' : 25e-6,\n    'warmup_proportion': 0.2, #0.1,\n    'batch_size' : 32,\n    'ebbs_epoch_samples' : 25e3,\n    'num_eebs_epochs' : 15e6\/\/100e3,\n    'ebbs_test_multipl' : 1, # ebbs_epoch_samples*(mulitpl+1) = samples that get evaluated\/tested \n    'eval_sample_size' : 10e3,\n    'num_labels' : 1,\n    'max_seq_length' : 250,\n    'gradient_accumulation_steps' : 2,\n    'fp16' : False, #apex #https:\/\/github.com\/NVIDIA\/apex\/issues\/131\n    'seed' : 70135\n}","f4dfd83a":"label_clms = ['target','severe_toxicity', 'obscene','identity_attack', \n              'insult', 'threat','funny', 'wow','sad','sexual_explicit','rating']\n\nidentity_columns = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n                    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n\n#target_columns = ['severe_toxicity', 'obscene','identity_attack', 'insult', 'threat']\n#offtarget_columns = ['funny', 'wow','sad', 'likes', 'disagree', 'sexual_explicit']\n\ntarget_clms = [*label_clms,*identity_columns]","58e22f4a":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport torch.utils.data\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\nimport warnings\nfrom pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam, BertModel\nfrom pytorch_pretrained_bert import BertConfig\n\nwarnings.filterwarnings(action='once')\ndevice = torch.device('cuda')","469d0bc5":"def replace_underscore_with_backspace(txt):\n    \"\"\" does what function name is ;) \"\"\"\n    return re.sub('_+',' ',txt)\n\ndef replace_newline_with_dot(txt):\n    \"\"\" does what function name is ;) \"\"\"\n    return re.sub('\\n+','. ',txt)\ndef replace_newline_with_space(txt):\n    \"\"\" does what function name is ;) \"\"\"\n    return re.sub('\\n+',' ',txt)\n\nimport re\ndef remove_urls(txt):\n    \"\"\" Removal of HTTP links\/URLs mixed up in any text: \"\"\"\n    return re.sub(r\"(http|ftp|https):\/\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\/~+#-]*[\\w@?^=%&\/~+#-])?\", \" \", txt)\nimport string\ndef remove_multi_symbols(txt,symbols=string.punctuation):\n    \"\"\" reduces symbols that occure multiple times to one symbol\n    by default goes over those symbols: '!\"#$%&\\'()*+,-.\/:;<=>?@[\\\\]^_`{|}~'\n    Note: call this after calling remove_urls\n    \"\"\"\n    for symbol in symbols:\n        txt = re.sub('\\\\'+symbol+'+',symbol,txt)\n    return txt","33f99bf7":"test_df = pd.read_csv(\"..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/test.csv\")\nif use_train_data:\n    test_df = pd.read_csv(\"..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/train.csv\").sample(10000)","87a75eee":"if use_own_text:\n    my_text = [\n        'asdf',\n        'feck-you',\n        'trolling the nation',\n        'I am proud to be gay',\n        'Nothing to do here',\n        'Hey, keep your Islamophobia out of public domains.', #should be 0\n        'Well, the money the education system spent on you was wasted', #should be 0.5\n        'This clown confuses the word \"substance\" with \"abuse\".', #should be 0\n        '\"Two things are infinite: the universe and human stupidity; and I\u00b4m not sure about the universe.\" - Albert Einstein', #should be 0\n        'I have epilepsy',\n        'I am a woman with epilepsy',\n        'I am a person who uses a wheelchair',\n        'I use a wheelchair',\n        'I am gay and have to use a wheelchair',\n        'I am blind',\n        'I am a person who is deaf',\n        'I am a woman who is deaf',\n        'I am a non-binary-gender person who is deaf',\n        'I am a black person who is deaf',\n        'I am pround to be gay',\n        'I am a proud homo',\n        'I am a proud lesbian',\n        'I am a proud to be black',\n        'KKK',\n        'a55hle',\n        'a$$hole',\n        'I am a very proud lesbian',\n        'I am a blind homosexual.',\n        \"I don't feel ashamed for beeing lesbian\",\n        \"Proud to be a fu**ing gay person\",\n        \"Totally wrong to think that this wouldn't be gay as shit\",\n         ' ',\n         '!',\n         '',\n         '???',\n        'I hate trump',\n        'I hate obama',\n        'Trump',\n        'I like that you are gay',\n    ]\n    test_df = pd.DataFrame({\n        'id': range(len(my_text)),\n        'comment_text': my_text\n    })","45b92867":"test_df['comment_text_orig'] = test_df['comment_text']","ae8d0edd":"functions = [\n    remove_urls,\n    replace_underscore_with_backspace,\n    replace_newline_with_dot, #replace with dot like in prepro\n    lambda k: remove_multi_symbols(k,symbols=['.','-','=']) # backspace should have also been added\n    ]\nfor func in functions:\n    print(func.__name__)\n    test_df['comment_text'] = test_df['comment_text'].apply(func)","4167c00b":"pd.set_option('max_colwidth', 500)\ntest_df[['comment_text','comment_text_orig']].sample(10)","5403a0a9":"def convert_lines(example, max_seq_length,tokenizer):\n    max_seq_length -=2\n    all_tokens = np.zeros((len(example),max_seq_length+2))\n    token_len = np.zeros(len(example))\n    for i,text in enumerate(example):\n        tokens_a = tokenizer.tokenize(text)\n        if len(tokens_a)>max_seq_length:\n            tokens_a = tokens_a[:max_seq_length]\n        #test_df.loc[i,'tokens']=str(tokens_a)\n        tokens = tokenizer.convert_tokens_to_ids(tokens_a)\n        tokens = [101, *tokens, 102]\n        token_len[i] = len(tokens)\n        all_tokens[i,:len(tokens)] = np.asarray(tokens)\n    return all_tokens, token_len","c210e2b2":"SEED = 1234\nTOKENIZER_PATH = '..\/input\/berttokenizer\/uncased_l-12_h-768_a-12\/uncased_L-12_H-768_A-12\/'\n\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\ntokenizer = BertTokenizer.from_pretrained(TOKENIZER_PATH, cache_dir=None,do_lower_case=True)","ebefe47b":"test_df['comment_text'] = test_df['comment_text'].astype(str)\nX_test, token_len = convert_lines(test_df[\"comment_text\"], args['max_seq_length'], tokenizer)","c6c6773b":"test_df['token_len'] = token_len","e2306847":"#X_test","dc318e86":"import torch\nfrom torch import Tensor\nimport torch.nn.functional as F\nfrom torch.nn import BCEWithLogitsLoss\n\ndevice = torch.device('cuda')\n\nclass BertForMultiLabelSequenceClassification(BertForSequenceClassification):\n    \"\"\"BERT model for classification.\n    This module is composed of the BERT model with a linear layer on top of\n    the pooled output.\n    Params:\n        `config`: a BertConfig class instance with the configuration to build a new model.\n        `num_labels`: the number of classes for the classifier. Default = 2.\n    Inputs:\n        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n            a `sentence B` token (see BERT paper for more details).\n        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n            input sequence length in the current batch. It's the mask that we typically use for attention when\n            a batch has varying length sentences.\n        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n            with indices selected in [0, ..., num_labels].\n    Outputs:\n        if `labels` is not `None`:\n            Outputs the CrossEntropy classification loss of the output with the labels.\n        if `labels` is `None`:\n            Outputs the classification logits of shape [batch_size, num_labels].\n    Example usage:\n    ```python\n    # Already been converted into WordPiece token ids\n    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n    num_labels = 2\n    model = BertForSequenceClassification(config, num_labels)\n    logits = model(input_ids, token_type_ids, input_mask)\n    ```\n    \"\"\"\n\n    def __init__(self, config, num_labels=2):\n        super(BertForMultiLabelSequenceClassification,\n              self).__init__(config, num_labels)\n        self.num_labels = num_labels\n        self.bert = BertModel(config)\n        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n        self.apply(self.init_bert_weights)\n    \n    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None, return_pooled_output=False, return_last_unpooled_layer=False):\n      full_output, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n      #pooled_output = self.dropout(pooled_output)\n      logits = self.classifier(pooled_output)\n      \n      if labels is not None:\n        #BCE: class has to be binary!\n        #CE: choose one of n-classes\n          loss_fct = BCEWithLogitsLoss() #weight=loss_weight\n          #weight=loss_weight.view(1,-1)\n          # The size of tensor a (32) must match the size of tensor b (19) at non-singleton dimension 1\n\n          mask = (labels != -1).to(dtype=torch.float)\n          logits = logits * mask\n          label_tensor = labels * mask\n\n          loss = loss_fct(logits, labels) #output, target\n          return loss, logits\n      elif return_pooled_output: return logits, pooled_output\n      elif return_last_unpooled_layer: return logits, full_output\n      return logits\n\n    def forward_old(self, input_ids, token_type_ids=None, attention_mask=None, labels=None, loss_weight=None):\n        _, pooled_output = self.bert(\n            input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n\n        if labels is not None:\n          #BCE: class has to be binary!\n          #CE: choose one of n-classes\n            loss_fct = BCEWithLogitsLoss() #weight=loss_weight\n            #weight=loss_weight.view(1,-1)\n            # The size of tensor a (32) must match the size of tensor b (19) at non-singleton dimension 1\n\n            mask = (labels != -1).to(dtype=torch.float)\n            logits = logits * mask\n            labels = labels * mask\n            \n            loss = loss_fct(logits.view(-1, self.num_labels), #output, \n                            labels.view(-1, self.num_labels)) #target\n            return loss\n        else:\n            return logits\n\n    def freeze_bert_encoder(self):\n        for param in self.bert.parameters():\n            param.requires_grad = False\n\n    def unfreeze_bert_encoder(self):\n        for param in self.bert.parameters():\n            param.requires_grad = True\n            \nfrom torch import nn\nclass SpatialDropout(nn.Dropout2d):\n    def forward(self, x):\n        x = x.unsqueeze(2)    # (N, T, 1, K)\n        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n        x = x.squeeze(2)  # (N, T, K)\n        return x\n      \nclass BertLSTM1(nn.Module):\n    \"\"\"#TODO\"\"\"\n    #https:\/\/www.kaggle.com\/bminixhofer\/simple-lstm-pytorch-version\n    def __init__(self, embedding_matrix, num_labels, n_aux_units = 7, max_features=args['max_seq_length'],LSTM_UNITS=128,DENSE_HIDDEN_UNITS=4*128):\n        super(BertLSTM1, self).__init__()\n        self.num_labels = num_labels\n        embed_size = embedding_matrix.shape[1]\n\n        #self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=0)\n        self.embedding = nn.Embedding(max_features, embed_size)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n        #self.embedding.weight.requires_grad = False #may set to true!!\n        self.embedding_dropout = SpatialDropout(0.3)\n\n        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\n        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n\n        self.linear1 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n        self.linear2 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n\n        self.linear_out = nn.Linear(DENSE_HIDDEN_UNITS, 1)\n        self.linear_aux_out = nn.Linear(DENSE_HIDDEN_UNITS, n_aux_units)\n\n\n    def forward(self, input_ids, attention_mask=None, labels=None, loss_weight=None, return_pooled_output=False):\n        h_embedding = self.embedding(input_ids)\n        h_embedding = self.embedding_dropout(h_embedding)\n\n        h_lstm1, _ = self.lstm1(h_embedding)\n        h_lstm2, _ = self.lstm2(h_lstm1)\n\n        # global average pooling\n        avg_pool = torch.mean(h_lstm2, 1)\n        # global max pooling\n        max_pool, _ = torch.max(h_lstm2, 1)\n\n        h_conc = torch.cat((max_pool, avg_pool), 1)\n        h_conc_linear1  = F.relu(self.linear1(h_conc))\n        h_conc_linear2  = F.relu(self.linear2(h_conc))\n\n        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n\n        result = self.linear_out(hidden)\n        #aux_result = self.linear_aux_out(hidden)\n        #out = torch.cat([result, aux_result], 1)\n\n        return result#out.view(-1, self.num_labels) \n    \nclass BertLSTM2(nn.Module):\n    \"\"\"#TODO\"\"\"\n    #https:\/\/www.kaggle.com\/bminixhofer\/simple-lstm-pytorch-version\n    def __init__(self, embedding_matrix, num_labels, n_aux_units = 7, max_features=args['max_seq_length'],LSTM_UNITS=128,DENSE_HIDDEN_UNITS=4*128):\n        super(BertLSTM2, self).__init__()\n        self.num_labels = num_labels\n        embed_size = embedding_matrix.shape[1]\n\n        #self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=0)\n        self.embedding = nn.Embedding(max_features, embed_size)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n        #self.embedding.weight.requires_grad = False #may set to true!!\n        self.embedding_dropout = SpatialDropout(0.3)\n\n        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\n        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n\n        self.linear1 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n        self.linear2 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n\n        self.linear_out = nn.Linear(DENSE_HIDDEN_UNITS, num_labels)\n        #self.linear_aux_out = nn.Linear(DENSE_HIDDEN_UNITS, n_aux_units)\n\n\n    def forward(self, input_ids, attention_mask=None, labels=None, loss_weight=None, return_pooled_output=False):\n        h_embedding = self.embedding(input_ids)\n        h_embedding = self.embedding_dropout(h_embedding)\n\n        h_lstm1, _ = self.lstm1(h_embedding)\n        h_lstm2, _ = self.lstm2(h_lstm1)\n\n        # global average pooling\n        avg_pool = torch.mean(h_lstm2, 1)\n        # global max pooling\n        max_pool, _ = torch.max(h_lstm2, 1)\n\n        h_conc = torch.cat((max_pool, avg_pool), 1)\n        h_conc_linear1  = F.relu(self.linear1(h_conc))\n        h_conc_linear2  = F.relu(self.linear2(h_conc))\n\n        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n\n        result = self.linear_out(hidden)\n\n        return result#out.view(-1, self.num_labels) ","a419aa86":"def load_bert_model(path, num_labels=args['num_labels']):\n    state_dict = torch.load(path)\n    if path.find('..\/input\/bertlstm-weights\/')==0:\n        print('loading bertLSTM model')\n        if num_labels is None:\n            num_labels = int(state_dict[list(state_dict.keys())[-1]].shape[0])\n            print('Number of Labels set to',num_labels)\n        try:\n            model = BertLSTM1(np.zeros((30522, 768)),num_labels)\n            print(model.load_state_dict(state_dict))\n        except:\n            print('trying BertLSTM2')\n            model = BertLSTM2(np.zeros((30522, 768)),num_labels)\n            print(model.load_state_dict(state_dict))\n        model = model.to('cuda')\n        del state_dict\n        return model\n    \n    config = BertConfig(30522)\n    if num_labels is None:\n        if 'classifier.bias' in state_dict.keys():\n            num_labels = int(state_dict['classifier.bias'].shape[0])\n        else: \n            print('No classifier.bias in state_dict --> assuming num_labels = 1')\n            num_labels = 1\n\n    model = BertForMultiLabelSequenceClassification(config,num_labels=num_labels)\n    model.load_state_dict(state_dict)\n    model.to(device)\n    del state_dict\n    return model","6de95721":"out_clms = []\nfor ii, BERT_MODEL_PATH in  enumerate(BERT_MODEL_PATHS):\n    print('\\nusing model',BERT_MODEL_PATH)\n    model = load_bert_model(BERT_MODEL_PATH,num_labels=None)\n    for param in model.parameters():\n        param.requires_grad = False\n    model.eval()\n    \n    buckets = 30\n    old_thld = -1\n    for b in range(buckets):\n        thld = int(np.percentile(test_df.token_len,(b+1)*100\/\/buckets))\n        mask = (test_df.token_len>old_thld) & (test_df.token_len<=thld)\n        if mask.sum()>0:\n            batch_size = args['batch_size'] if thld<=220 else 16\n            old_thld = thld\n            print('\\rBucketNr',b,'thld:',thld,'samples:',mask.sum(),end='')\n\n            preds = None\n            test = torch.utils.data.TensorDataset(torch.tensor(X_test[mask,:thld], dtype=torch.long))\n            test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n            for i, (x_batch,) in enumerate(test_loader):\n                logits = model(x_batch.to(device), attention_mask=(x_batch > 0).to(device), labels=None)\n                #pred2 = model2(x_batch.to(device), attention_mask=(x_batch > 0).to(device), labels=None)\n\n                y_pred = logits.sigmoid().detach().cpu().numpy()\n                if preds is None: preds = y_pred\n                else: preds = np.concatenate((preds,y_pred),axis=0)\n            test_df.loc[mask,'bo'+str(ii)] = preds[:,0]\n    out_clms.append('bo'+str(ii))","b2f1625d":"weights = np.ones(len(out_clms))\n\n#overweight model nr2\n#if len(weights)>=0: weights[0] = 0.4\n#if len(weights)>=1: weights[1] = 1.1\n#if len(weights)>=2: weights[2] = 1.2\n#if len(weights)>=4: weights[4] = 1.0\n#if len(weights)>=10: weights[9] = 1.0\n#if len(weights)>=11: weights[10] = 0.2\n#if len(weights)>=12: weights[11] = 0.2\n#if len(weights)>=13: weights[12] = 0.3\n    \nprint([(BERT_MODEL_PATHS[i].split('\/')[-1],weights[i]) for i in range(len(weights))])\ntest_df.fillna(0,inplace=True)\ntest_df['prediction'] = np.average(test_df[out_clms].values, weights=weights, axis=1)","d32e6e75":"use_ranked_sum = False # was worse on test data by 0.02\nif use_ranked_sum:\n    for key in out_clms:\n        test_df[key + '_rank'] = test_df[key].rank()\n    test_df['rank_sum'] = np.sum(\n            test_df[col] for col in test_df.columns if '_rank' in col)\n    test_df['rank_sum_prediction'] = test_df['rank_sum']\/(len(out_clms) *\n            test_df.shape[0])","0ec2d062":"if use_train_data:\n    from sklearn import metrics\n    import numpy as np\n    import pandas as pd\n    # List all identities\n    identity_columns = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n                        'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n    target_columns = ['severe_toxicity', 'obscene','identity_attack', 'insult', 'threat']\n    offtarget_columns = ['funny', 'wow','sad', 'likes', 'disagree', 'sexual_explicit']\n\n    TOXICITY_COLUMN = 'target'\n    SUBGROUP_AUC = 'subgroup_auc'\n    BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n    BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\n    # Convert taget and identity columns to booleans\n    def convert_to_bool(df, col_name):\n        df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n\n    def convert_dataframe_to_bool(df):\n        bool_df = df.copy()\n        for col in ['target'] + identity_columns: #+target_columns+offtarget_columns\n            convert_to_bool(bool_df, col)\n        return bool_df\n\n    def compute_auc(y_true, y_pred):\n        try:\n            return metrics.roc_auc_score(y_true, y_pred)\n        except ValueError:\n            return np.nan\n\n    def compute_subgroup_auc(df, subgroup, label, model_name):\n        subgroup_examples = df[df[subgroup]]\n        return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n\n    def compute_bpsn_auc(df, subgroup, label, model_name):\n        \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n        subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n        non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n        examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n        return compute_auc(examples[label], examples[model_name])\n\n    def compute_bnsp_auc(df, subgroup, label, model_name):\n        \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n        subgroup_positive_examples = df[df[subgroup] & df[label]]\n        non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n        examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n        return compute_auc(examples[label], examples[model_name])\n\n    def compute_bias_metrics_for_model(dataset,subgroups,model,label_col,include_asegs=False):\n        \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n        dataset = convert_dataframe_to_bool(dataset)\n        records = []\n        for subgroup in subgroups:\n            record = {\n                'subgroup': subgroup,\n                'subgroup_size': len(dataset[dataset[subgroup]])\n            }\n            record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n            record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n            record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n            records.append(record)\n        return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n\n    def calculate_overall_auc(df, model_name, TOXICITY_COLUMN):\n        true_labels = df[TOXICITY_COLUMN]>=0.5\n        predicted_labels = df[model_name]\n        return metrics.roc_auc_score(true_labels, predicted_labels)\n\n    def power_mean(series, p):\n        total = sum(np.power(series, p))\n        return np.power(total \/ len(series), 1 \/ p)\n\n    def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n        bias_score = np.average([\n            power_mean(bias_df[SUBGROUP_AUC], POWER),\n            power_mean(bias_df[BPSN_AUC], POWER),\n            power_mean(bias_df[BNSP_AUC], POWER)\n        ])\n        #print(bias_score)\n        return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score), bias_score\n\n    def get_scores(in_df, model_name,TOXICITY_COLUMN='target',fillna=True,consolidation_method='mean'):\n        # groupby ID to remove dublicates --> merge splitted data\n        df = in_df[[model_name,'id',*identity_columns, TOXICITY_COLUMN]].groupby('id')\n        if consolidation_method=='mean': df = df.mean()\n        if consolidation_method=='max': df = df.max()  \n        if consolidation_method=='min': df = df.min() \n\n        bias_metrics_df = compute_bias_metrics_for_model(df, identity_columns, model_name, TOXICITY_COLUMN)\n        if fillna: bias_metrics_df.fillna(0.5,inplace=True)\n        try:\n          overall_auc = calculate_overall_auc(df, model_name, TOXICITY_COLUMN)\n        except ValueError:\n          print('Error - only one class present in df')\n          overall_auc = np.nan\n        final_metric, bias_score = get_final_metric(bias_metrics_df, overall_auc)\n        bias_metrics_df['overall_auc']=overall_auc\n        bias_metrics_df['final_bias_score'] = bias_score\n        bias_metrics_df['final_metric'] = final_metric\n        bias_metrics_df.index = bias_metrics_df.subgroup\n        return bias_metrics_df","d32850ec":"if use_train_data:\n    score = get_scores(test_df,'prediction')","e4156061":"if use_train_data:\n    for i,clm in enumerate(out_clms):\n        print(i, str(get_scores(test_df,clm).final_metric.mean())[:5],weights[i],BERT_MODEL_PATHS[i].split('\/')[-1],sep='\\t')","e44a935e":"for out_clm in ['prediction',*out_clms]:\n    submission = pd.DataFrame.from_dict({\n        'id': test_df['id'],\n        'prediction': test_df[out_clm]\n    })\n    if out_clm=='prediction': out_clm = 'blend'\n    submission.to_csv('submission_'+out_clm+'.csv', index=False)","ee66e6f9":"submission.head()","ce5a18fa":"test_df.to_csv('test_df.csv', index=False)","612ba51d":"pd.concat((test_df['comment_text'],(test_df[[*out_clms,'prediction']]*100).astype(np.int)),axis=1)","ad4f90c7":"This is the inference kernel for BERT pytorch. Check out the amazing Kernel for finetuning BERT by Yuval: https:\/\/www.kaggle.com\/yuval6967\/toxic-bert-plain-vanila"}}