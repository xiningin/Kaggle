{"cell_type":{"5af84ecb":"code","d1baa2a4":"code","ab805410":"code","26637669":"code","f6542a18":"code","c0f1de8b":"code","45d8ab79":"code","84cb424b":"code","7c17fd1b":"code","50fafa99":"code","b030482b":"code","914cd18d":"code","16d9659b":"code","e4a80bd4":"markdown","9c7a391a":"markdown","d8d00c46":"markdown","35a7761f":"markdown","9a2fe631":"markdown","4df46afb":"markdown","4fc6ebfe":"markdown","e15de15a":"markdown","cec5b46e":"markdown","13859d09":"markdown","ae556c59":"markdown","96479e7a":"markdown"},"source":{"5af84ecb":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\nplt.style.use('ggplot')\nimport warnings\nwarnings.filterwarnings('ignore')","d1baa2a4":"df=pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\nprint('Shape of dataset : ',df.shape)\ndf.head()","ab805410":"#check for null values\ndf.isna().sum()","26637669":"print(\"Class counts : \")\ndf.DEATH_EVENT.value_counts()","f6542a18":"plt.figure(figsize=(10,6))\nplt.title(\"Correlation Heatmap\")\nsns.heatmap(abs(df.corr()), annot=True, cmap='coolwarm')\n#plt.tight_layout()\nplt.show()","c0f1de8b":"# Scaling numeric features\ncol_num=['age', 'creatinine_phosphokinase','ejection_fraction', 'platelets',\n         'serum_creatinine', 'serum_sodium','time']\nscalar=MinMaxScaler()\nfor col in col_num:\n    df[col]=scalar.fit_transform(np.array(df[col]).reshape(-1,1))\n\n# Converting categorical features from type object to category\ncols_cat=['anaemia', 'diabetes','high_blood_pressure', 'sex', 'smoking','DEATH_EVENT']\nfor col in cols_cat:\n    df[col]=df[col].astype('category')\ndf.head()","45d8ab79":"X=df.drop('DEATH_EVENT', axis=1)\ny=df.DEATH_EVENT\n\nX_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.2,random_state=1)","84cb424b":"model=RandomForestClassifier(class_weight='balanced', random_state=0)\nmodel.fit(X_train,y_train)\n\ny_pred=model.predict(X_test)\ny_proba=model.predict_proba(X_test)\ny_proba=[p[1] for p in y_proba]\n\nprint(\"Accuracy Score : {}\".format(accuracy_score(y_test,y_pred)))\nprint(\"Confusion Matrix : \\n\", confusion_matrix(y_test,y_pred))\nprint(\"ROC AUC Score : {}\".format(roc_auc_score(y_test,y_proba)))\nprint(classification_report(y_test,y_pred))","7c17fd1b":"df_feat=pd.DataFrame({'Feature':X.columns,\n                      'Importance':model.feature_importances_})\ndf_feat.sort_values(by='Importance', ascending=False, inplace=True)\ndf_feat.reset_index(inplace=True)\n\nsns.barplot(x='Importance',y='Feature', data=df_feat, orient='h')\nplt.show()","50fafa99":"acc=[]\nrocauc=[]\nfeat=[]\nfor i in range(1,13):\n    cols=df_feat.Feature[:i]\n    X_tr=X_train[cols]\n    X_ts=X_test[cols]\n    \n    model=RandomForestClassifier(class_weight='balanced', random_state=0)\n    model.fit(X_tr,y_train)\n\n    y_pred=model.predict(X_ts)\n    y_proba=model.predict_proba(X_ts)\n    y_proba=[p[1] for p in y_proba]\n    \n    print(\"Number of Columns : \",i)\n    print(cols)\n    print(\"Accuracy Score : {}\".format(accuracy_score(y_test,y_pred)))\n    print(\"Confusion Matrix : \\n\", confusion_matrix(y_test,y_pred))\n    print(\"ROC AUC Score : {}\".format(roc_auc_score(y_test,y_proba)))\n    print(classification_report(y_test,y_pred))\n    feat.append(i)\n    acc.append(accuracy_score(y_test,y_pred))\n    rocauc.append(roc_auc_score(y_test,y_proba))","b030482b":"sns.lineplot(feat,acc, label='Accuracy')    \nsns.lineplot(feat,rocauc, label='ROC AUC Score')\n#plt.ylim(0,1)\nplt.legend()\nplt.show()","914cd18d":"# Columns used for final model\nprint(\"Features considered for final prediction\")\nx_cols=df_feat.Feature[:7]\nx_cols","16d9659b":"X=df[x_cols]\ny=df.DEATH_EVENT\n\nX_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.2,random_state=1)\n\nmodel=RandomForestClassifier(class_weight='balanced', random_state=0)\nmodel.fit(X_train,y_train)\n\ny_pred=model.predict(X_test)\ny_proba=model.predict_proba(X_test)\ny_proba=[p[1] for p in y_proba]\n\nprint(\"Accuracy Score : {}\".format(accuracy_score(y_test,y_pred)))\nprint(\"Confusion Matrix : \\n\", confusion_matrix(y_test,y_pred))\nprint(\"ROC AUC Score : {}\".format(roc_auc_score(y_test,y_proba)))\nprint(classification_report(y_test,y_pred))","e4a80bd4":"# Fitting model and evaluation","9c7a391a":"Observation:\n* Using 7 features seems to provide the best accuracy and ROC-AUC score","d8d00c46":"# Find the ideal number of features","35a7761f":"# Correlation Heat Map","9a2fe631":"# Please Upvote if you find this kernel useful\n# Suggestions and Doubts welcomed as comment","4df46afb":"Observation:\n* The target variable is imbalanced","4fc6ebfe":"# Ordering features by importance","e15de15a":"# Selecting features and target and train and test datasets","cec5b46e":"# Preprocessing the data","13859d09":"# Read Data and Exploration","ae556c59":"# Import Libraries","96479e7a":"# Fitting\/predicting and evaluating using model with ideal number of features"}}