{"cell_type":{"a7a36aa1":"code","2ae5e6b2":"code","638cdfae":"code","d8983c95":"code","4877552f":"code","162181c3":"code","6ecc7d08":"code","9b1044c5":"code","d1196ca7":"code","8443d5b4":"code","f9652b58":"code","f7fa80fd":"code","4f813c56":"code","00a94ff8":"code","fe22a64a":"code","27fd203e":"code","7d5d87bd":"code","d2d824fd":"code","25bb4795":"code","21b16a00":"code","f1a68f0a":"code","cf2ad748":"code","e4742991":"code","571aca22":"code","d1b2fac9":"code","0fc837f6":"code","b47dec58":"code","45e53eff":"code","c5b8d3d4":"code","c0eb0725":"code","b7671e37":"code","b6fa020b":"code","30d75110":"code","3c52dea4":"code","55ee38f2":"code","4014705d":"code","560694ab":"code","b396292b":"code","6bb26971":"code","53baec55":"code","e0961432":"code","cdd55cbf":"code","61c3bbb2":"code","b3ea6cb3":"code","b0b0faee":"code","144cb33d":"code","0d855aed":"code","19645f15":"code","dab0cac3":"code","459d16b9":"code","d6d9729a":"code","8033243c":"markdown","c45d7392":"markdown","2f5120bf":"markdown","d6bf36cb":"markdown","a8eb1768":"markdown","4e54deea":"markdown","a9e1b49e":"markdown","720fb492":"markdown","a2283e2e":"markdown","e588f4c9":"markdown","a86c4836":"markdown","7c0cf374":"markdown","a4bb2319":"markdown","ff528cb2":"markdown","33e7eff9":"markdown","88cab208":"markdown","4af16920":"markdown","34d3c6d1":"markdown","bcba6390":"markdown","c2884a35":"markdown","b9d7c114":"markdown","e3d68434":"markdown","99d02756":"markdown","6c52c484":"markdown","9dff168f":"markdown","2cf4476f":"markdown","6390f7aa":"markdown","e6a9cd1d":"markdown","1a0433a9":"markdown","fe25d4f2":"markdown","c982262b":"markdown","d4e610de":"markdown","54690614":"markdown","7bb87159":"markdown","60883c48":"markdown","3c41e0c3":"markdown","4494bca5":"markdown","0be5eb3b":"markdown","d5e8ae61":"markdown","d3e53627":"markdown","0a63edc2":"markdown","72440256":"markdown","19f934b5":"markdown","9e4fab7d":"markdown","2d88a003":"markdown","fb823155":"markdown","e92a4c7c":"markdown","428cfed3":"markdown","a52e4a4f":"markdown","642990f0":"markdown","20db2ab0":"markdown","b03b8232":"markdown","c5d5ff19":"markdown","b8c206ae":"markdown","050d84f8":"markdown","191224ac":"markdown","831fd4ae":"markdown","a66d9c6b":"markdown","79f8a616":"markdown","b9aa8650":"markdown","ca7632da":"markdown","0cbf2cf5":"markdown","a7e785c8":"markdown"},"source":{"a7a36aa1":"# import libraries\nimport pandas as pd # for data manupulation or analysis\nimport numpy as np # for numeric calculation\nimport matplotlib.pyplot as plt # for data visualization\nimport seaborn as sns # for data visualization","2ae5e6b2":"#Load breast cancer dataset\nfrom sklearn.datasets import load_breast_cancer\ncancer_dataset = load_breast_cancer()","638cdfae":"# keys in dataset\ncancer_dataset.keys()","d8983c95":"# featurs of each cells in numeric format\ncancer_dataset['data']","4877552f":"# malignant or benign value\ncancer_dataset['target']","162181c3":"# target value name malignant or benign tumor\ncancer_dataset['target_names']\n\n","6ecc7d08":"# description of data\nprint(cancer_dataset['DESCR'])","9b1044c5":"# name of features\nprint(cancer_dataset['feature_names'])\n\n","d1196ca7":"# location\/path of data file\nprint(cancer_dataset['filename'])","8443d5b4":"# create datafrmae\ncancer_df = pd.DataFrame(np.c_[cancer_dataset['data'],cancer_dataset['target']],\n             columns = np.append(cancer_dataset['feature_names'], ['target']))","f9652b58":"# Head of cancer DataFrame\ncancer_df.head(6)","f7fa80fd":"# Tail of cancer DataFrame\ncancer_df.tail(6) \n\n","4f813c56":"# Information of cancer Dataframe\ncancer_df.info()\n\n","00a94ff8":"# Numerical distribution of data\ncancer_df.describe()","fe22a64a":"# Paiplot of cancer dataframe\nsns.pairplot(cancer_df, hue = 'target')","27fd203e":"# pair plot of sample feature\nsns.pairplot(cancer_df, hue = 'target', \n             vars = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness'] )","7d5d87bd":"# Count the target class\nsns.countplot(cancer_df['target'])","d2d824fd":"# counter plot of feature mean radius\nplt.figure(figsize = (20,8))\nsns.countplot(cancer_df['mean radius'])","25bb4795":"# heatmap of DataFrame\nplt.figure(figsize=(7,8))\nsns.heatmap(cancer_df)","21b16a00":"# Heatmap of Correlation matrix of breast cancer DataFrame\nplt.figure(figsize=(10,10))\nsns.heatmap(cancer_df.corr(), annot = True, cmap ='coolwarm', linewidths=2)\n\n","f1a68f0a":"# create second DataFrame by droping target\ncancer_df2 = cancer_df.drop(['target'], axis = 1)\nprint(\"The shape of 'cancer_df2' is : \", cancer_df2.shape)","cf2ad748":"# visualize correlation barplot\nplt.figure(figsize = (16,5))\nax = sns.barplot(cancer_df2.corrwith(cancer_df.target).index, cancer_df2.corrwith(cancer_df.target))\nax.tick_params(labelrotation = 90)","e4742991":"# input variable\nX = cancer_df.drop(['target'], axis = 1)\nX.head(6)","571aca22":"# output variable\ny = cancer_df['target']\ny.head(6)","d1b2fac9":"# split dataset into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 5)","0fc837f6":"# Feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train)\nX_test_sc = sc.transform(X_test)","b47dec58":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","45e53eff":"# Support vector classifier\nfrom sklearn.svm import SVC\nsvc_classifier = SVC()\nsvc_classifier.fit(X_train, y_train)\ny_pred_scv = svc_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_scv)\n\n","c5b8d3d4":"# Train with Standard scaled Data\nsvc_classifier2 = SVC()\nsvc_classifier2.fit(X_train_sc, y_train)\ny_pred_svc_sc = svc_classifier2.predict(X_test_sc)\naccuracy_score(y_test, y_pred_svc_sc)","c0eb0725":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(penalty='l1',solver=\"saga\",random_state=51)\nlr.fit(X_train, y_train)\n\n#accuracy_score(y_test, y_pred_lr)\n","b7671e37":"# Train with Standard scaled Data\nlr2 = LogisticRegression(random_state = 51,solver=\"saga\", penalty = 'l1')\nlr2.fit(X_train_sc, y_train)\n\n#accuracy_score(y_test, y_pred_lr  )\n\n","b6fa020b":"# K \u2013 Nearest Neighbor Classifier\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nknn_classifier.fit(X_train, y_train)\ny_pred_knn = knn_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_knn)","30d75110":"# Train with Standard scaled Data\nknn_classifier2 = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nknn_classifier2.fit(X_train_sc, y_train)\ny_pred_knn_sc = knn_classifier.predict(X_test_sc)\naccuracy_score(y_test, y_pred_knn_sc)","3c52dea4":"# Naive Bayes Classifier\nfrom sklearn.naive_bayes import GaussianNB\nnb_classifier = GaussianNB()\nnb_classifier.fit(X_train, y_train)\ny_pred_nb = nb_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_nb)\n\n","55ee38f2":"# Train with Standard scaled Data\nnb_classifier2 = GaussianNB()\nnb_classifier2.fit(X_train_sc, y_train)\ny_pred_nb_sc = nb_classifier2.predict(X_test_sc)\naccuracy_score(y_test, y_pred_nb_sc)","4014705d":"# Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier\ndt_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 51)\ndt_classifier.fit(X_train, y_train)\ny_pred_dt = dt_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_dt)","560694ab":"# Train with Standard scaled Data\ndt_classifier2 = DecisionTreeClassifier(criterion = 'entropy', random_state = 51)\ndt_classifier2.fit(X_train_sc, y_train)\ny_pred_dt_sc = dt_classifier.predict(X_test_sc)\naccuracy_score(y_test, y_pred_dt_sc)","b396292b":"# Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nrf_classifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 51)\nrf_classifier.fit(X_train, y_train)\ny_pred_rf = rf_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_rf)","6bb26971":"# Train with Standard scaled Data\nrf_classifier2 = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 51)\nrf_classifier2.fit(X_train_sc, y_train)\ny_pred_rf_sc = rf_classifier.predict(X_test_sc)\naccuracy_score(y_test, y_pred_rf_sc)","53baec55":"# Adaboost Classifier\nfrom sklearn.ensemble import AdaBoostClassifier\nadb_classifier = AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy', random_state = 200),\n                                    n_estimators=2000,\n                                    learning_rate=0.1,\n                                    algorithm='SAMME.R',\n                                    random_state=1,)\nadb_classifier.fit(X_train, y_train)\ny_pred_adb = adb_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_adb)","e0961432":"# Train with Standard scaled Data\nadb_classifier2 = AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy', random_state = 200),\n                                    n_estimators=2000,\n                                    learning_rate=0.1,\n                                    algorithm='SAMME.R',\n                                    random_state=1,)\nadb_classifier2.fit(X_train_sc, y_train)\ny_pred_adb_sc = adb_classifier2.predict(X_test_sc)\naccuracy_score(y_test, y_pred_adb_sc)","cdd55cbf":"# XGBoost Classifier\nfrom xgboost import XGBClassifier\nxgb_classifier = XGBClassifier()\nxgb_classifier.fit(X_train, y_train)\ny_pred_xgb = xgb_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_xgb)","61c3bbb2":"# Train with Standard scaled Data\nxgb_classifier2 = XGBClassifier()\nxgb_classifier2.fit(X_train_sc, y_train)\ny_pred_xgb_sc = xgb_classifier2.predict(X_test_sc)\naccuracy_score(y_test, y_pred_xgb_sc)","b3ea6cb3":"params={\n    \"learning_rate\"   :[0.05,0.10,0.20,0.25,0.30],\n    \"max_depth\"       :[3,4,5,6,8,10,12,15],\n    \"min_child_weight\":[1,3,5,7],\n    \"gamma\"           :[0.0,0.1,0.2,0.3,0.4],\n    \"colsample_bytree\":[0.3,0.4,0.5,0.7] \n}","b0b0faee":"# Randomized Search\nfrom sklearn.model_selection import RandomizedSearchCV\nrandom_search = RandomizedSearchCV(xgb_classifier, param_distributions=params, scoring= 'roc_auc', n_jobs= -1, verbose= 3)\nrandom_search.fit(X_train, y_train)","144cb33d":"{'min_child_weight': 1,\n 'max_depth': 3,\n 'learning_rate': 0.3,\n 'gamma': 0.4,\n 'colsample_bytree': 0.3}","0d855aed":"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n       colsample_bynode=1, colsample_bytree=0.3, gamma=0.4,\n       learning_rate=0.3, max_delta_step=0, max_depth=3,\n       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n       nthread=None, objective='binary:logistic', random_state=0,\n       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n       silent=None, subsample=1, verbosity=1)","19645f15":"# training XGBoost classifier with best parameters\nxgb_classifier_pt = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n       colsample_bynode=1, colsample_bytree=0.4, gamma=0.2,\n       learning_rate=0.1, max_delta_step=0, max_depth=15,\n       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n       nthread=None, objective='binary:logistic', random_state=0,\n       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n       silent=None, subsample=1, verbosity=1)\n \nxgb_classifier_pt.fit(X_train, y_train)\ny_pred_xgb_pt = xgb_classifier_pt.predict(X_test)","dab0cac3":"cm = confusion_matrix(y_test, y_pred_xgb_pt)\nplt.title('Heatmap of Confusion Matrix', fontsize = 15)\nsns.heatmap(cm, annot = True)\nplt.show()","459d16b9":"print(classification_report(y_test, y_pred_xgb_pt))","d6d9729a":"## Pickle\nimport pickle\n \n# save model\npickle.dump(xgb_classifier_pt, open('breast_cancer_detector.pickle', 'wb'))\n \n# load model\nbreast_cancer_detector_model = pickle.load(open('breast_cancer_detector.pickle', 'rb'))\n \n# predict the output\ny_pred = breast_cancer_detector_model.predict(X_test)\n \n# confusion matrix\nprint('Confusion matrix of XGBoost model: \\n',confusion_matrix(y_test, y_pred),'\\n')\n \n# show the accuracy\nprint('Accuracy of XGBoost model = ',accuracy_score(y_test, y_pred))\n\n","8033243c":"# Breast Cancer Detection Using Machine Learning Classifier","c45d7392":"When we call load_breast_cancer() class it downloads ","2f5120bf":"breast_cancer.csv file and you can see file location.","d6bf36cb":"Taking the correlation of each feature with the target and the visualize barplot.","a8eb1768":"XGBoost Parameter Tuning Randomized Search ","4e54deea":"In the above correlation barplot only feature 'smoothness error' is strongly positively correlated with the target than others. The features 'mean factor dimension', 'texture error', and 'symmetry error' are very less positive correlated and others remaining are strongly negatively correlated.","a9e1b49e":"# Support Vector Classifier","720fb492":"We are loading breast cancer data using a scikit-learn load_brast_cancer class.","a2283e2e":"We have a total of non-null 569 patients information with 31 features. All feature data types in the float. The size of the DataFrame is 137.9 KB.\n\nNumerical distribution of data. We can know to mean, standard deviation, min, max, 25%,50% and 75% value of each feature.","e588f4c9":"We have clean data to build the Ml model. But which Machine learning algorithm is best for the data we have to find. The output is a categorical format so we will use supervised classification machine learning algorithms.\n\nTo build the best model, we have to train and test the dataset with multiple Machine Learning algorithms then we can find the best ML model. So let\u2019s try.\n\nFirst, we need to import the required packages.\n1\n\t\n","a86c4836":"Breast Cancer Detection Machine Learning Model Building","7c0cf374":"# Data Preprocessing","a4bb2319":"Basically, the pair plot is used to show the numeric distribution in the scatter plot.","ff528cb2":"Pair plot of breast cancer data","33e7eff9":"Breast Cancer Detection Machine Learning ","88cab208":"Showing the total count of malignant and benign tumor patients in counterplot.","4af16920":"# Confusion Matrix","34d3c6d1":"Heatmap of breast cancer DataFrame","bcba6390":"# K \u2013 Nearest Neighbor Classifier","c2884a35":"We have clean and well formated DataFrame, so DtaFrame is ready to visualize.","b9d7c114":"# Classification Report of Model","e3d68434":"Split DataFrame in train and test","99d02756":"In the below counterplot max samples mean radius is equal to 1.","6c52c484":"Pair plot of sample feature of DataFrame","9dff168f":"# Naive Bayes Classifier","2cf4476f":"accuracy_score(y_test, y_pred_xgb_pt)","6390f7aa":"These numeric values are extracted features of each cell.","e6a9cd1d":"The pair plot showing malignant and benign tumor data distributed in two classes. It is easy to differentiate in the pair plot.","1a0433a9":"Now, we are creating DataFrame by concate 'data'and 'target' together and give columns name.","fe25d4f2":"The tail of cancer DataFrame","c982262b":"# Adaboost Classifier","d4e610de":"Save the Machine Learning model","54690614":"# Feature Scaling","7bb87159":"# Congratulation!!!!!!!","60883c48":"# Correlation barplot","3c41e0c3":"# Logistic Regression","4494bca5":"We have extracted features of breast cancer patient cells and normal person cells. As a Machine learning Data Scientist has to create an ML model to classify malignant and benign tumor. To complete this ML project we are using the supervised machine learning classifier algorithm.","0be5eb3b":"# Heatmap","d5e8ae61":"Head of cancer DataFrame","d3e53627":"# Data Visualization ","0a63edc2":"# Random Forest Classifier","72440256":"Here, we will use pickle, Use anyone which is better for you.","19f934b5":"# IMPORT ESSENTIAL LIBRARIES","9e4fab7d":"# Counterplot","2d88a003":"# XGBoost Classifier","fb823155":"The doctors do not identify each and every breast cancer patient. So let\u2019s start...","e92a4c7c":"I have completed the Machine learning Project successfully with 98.24% accuracy which is great for \u2018Breast Cancer Detection using Machine learning\u2019 project. Now, we are ready to deploy our ML model in the healthcare project.","428cfed3":"# Heatmap of a correlation matrix ","a52e4a4f":"# Decision Tree Classifier","642990f0":"Getting information of cancer DataFrame using '.info()' method.","20db2ab0":"Breast cancer is a dangerous disease for women. If it does not identify in the early-stage then the result will be the death of the patient. It is a common cancer in women worldwide. Worldwide near about 12% of women affected by breast cancer and the number is still increasing.","b03b8232":"After completion of the Machine Learning project or building the ML model need to deploy in an application. To deploy the ML model need to save it first. To save the Machine Learning project we can use the pickle or joblib package.\n\n","c5d5ff19":"In the below heatmap we can see the variety of different feature\u2019s value. The value of feature 'mean area' and 'worst area' are greater than other and 'mean perimeter', 'area error', and 'worst perimeter' value slightly less but greater than remaining features.","b8c206ae":"0 means malignant tumor,\n1 mean benign tumor","050d84f8":"# Create DataFrame","191224ac":"The model is giving 0% type II error and it is best.","831fd4ae":"To find a correlation between each feature and target we visualize heatmap using the correlation matrix.","a66d9c6b":"Load breast cancer dataset & explore","79f8a616":"Features name of malignant & benign tumor.","b9aa8650":"The cancer_dataset[\u2018DESCR\u2019] store the description of breast cancer dataset.","ca7632da":"The target stores the values of malignant or benign tumors.","0cbf2cf5":"Converting different units and magnitude data in one unit.","a7e785c8":"To get more accuracy, we trained all supervised classification algorithms but you can try out a few of them which are always popular. After training all algorithms, we found that Logistic Regression, Random Forest and XGBoost classifiers are given high accuracy than remain but we have chosen XGBoost.\n\nAs ML Engineer, we always retrain the deployed model after some period of time to sustain the accuracy of the model. We hope our efforts will save the life of breast cancer patients."}}