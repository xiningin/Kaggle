{"cell_type":{"84a40e09":"code","b645cc6a":"code","779dd02d":"code","579cf1bd":"code","74a83c53":"code","d8ccf89d":"code","347b7ea7":"code","c69e597c":"code","7c12f5d0":"code","f231160f":"code","e88a57e7":"code","af567a18":"code","645e74b7":"code","00ea6f17":"code","d68d94b7":"code","9b552cdf":"code","f31d5732":"code","dcdde9a0":"code","ae824acf":"code","7d03c7b8":"code","b82bb585":"code","5234916f":"code","182dae4d":"code","fc7de2c4":"code","9c98e838":"code","d75e5450":"code","7a69d959":"code","54e8b6df":"code","89f6a8c8":"code","c4b45f48":"code","970503fb":"code","279d920e":"code","4bf2378c":"code","c9b406e6":"code","9c3004e9":"markdown","cce1bf32":"markdown","b603a66d":"markdown","77411cde":"markdown","10cb2fa3":"markdown","c5ac0e1f":"markdown","637e0196":"markdown","7fe10816":"markdown","435721cb":"markdown","a9099809":"markdown"},"source":{"84a40e09":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b645cc6a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score","779dd02d":"#loading data\ndata=pd.read_csv('..\/input\/customer-personality-analysis\/marketing_campaign.csv',sep='\\t')\nprint('Total datapoints:',len(data))\ndata.head()","579cf1bd":"data.info()","74a83c53":"data.isnull().sum()","d8ccf89d":"data=data.dropna(subset=['Income'])\ndata.shape","347b7ea7":"#to Create a column Enrolled_days\ndata['Dt_Customer']=pd.to_datetime(data['Dt_Customer']) #to revise datatype to datetime\n    \nmax_date=max(data['Dt_Customer'])\n    \ndata['Enrolled_days']=max_date-data['Dt_Customer']\ndata['Enrolled_days']=data['Enrolled_days'].dt.days","c69e597c":"print(data['Education'].value_counts())\nprint(data['Marital_Status'].value_counts())","7c12f5d0":"#Engneering figures\n\ndata['Education']=data['Education'].replace({'Graduation':'Graduate','PhD':'Postgraduate','Master':'Postgraduate','2nd Cycle':'Undergraduate','Basic':'Undergraduate'})\ndata['Marital_Status']=data['Marital_Status'].replace({'Married':'Partner','Together':'Partner','Single':'Single','Divorced':'Single','Widow':'Single','Alone':'Single','Absurd':'Single','YOLO':'Single'})\ndata['Marital_Status']=data['Marital_Status'].replace({'Partner':2,'Single':1})\n\n#client's age\ndata['Age']=2021-data['Year_Birth']\n\n#Total_Spend\ndata['Total_Spend']=data['MntWines']+data['MntFruits']+data['MntMeatProducts']+data['MntFishProducts']+data['MntSweetProducts']+data['MntGoldProds']\n\n#family status\ndata['Children']=data['Kidhome']+data['Teenhome']\ndata['Family_size']=data['Marital_Status']+data['Children']\ndata['Parent']=np.where(data['Children']>0,1,0)\n\n#for clarity\ndata=data.rename(columns={'NumWebPurchases':'Web','NumCatalogPurchases':'Catalogue','NumStorePurchases':'Store'})\ndata=data.rename(columns={'MntMeatProducts':'Meat','MntWines':'Wine','MntFishProducts':'Fish','MntSweetProducts':'Sweet','MntGoldProds':'Gold'})\n\ndata.head()","f231160f":"data['ID']=data['ID'].astype(str)","e88a57e7":"to_drop=['Year_Birth','Dt_Customer','Z_Revenue','Z_CostContact']\ndata=data.drop(to_drop, axis=1)\ndata.head()","af567a18":"To_Plot=['Income','Total_Spend','Age','Enrolled_days','Parent']\nplt.figure()\nsns.pairplot(data[To_Plot],hue='Parent')","645e74b7":"#Remove outliers\ndata=data[(data['Age']<100)]\ndata=data[(data['Income']<600000)]\n\nprint('Total datapoints after removing outliers',len(data))","00ea6f17":"To_plot=[]\ncorr_data=data.corr()\nplt.figure(figsize=(16,16))\nsns.heatmap(corr_data,annot=True,annot_kws={'size':7})","d68d94b7":"#Create new attribute Recency\nrfm_m=data['Total_Spend']\nrfm_m=data.groupby('ID')['Total_Spend'].sum()\nrfm_m=rfm_m.reset_index()\nrfm_m.head()\n","9b552cdf":"#Create new attribute Frequency\ndata['Total_Times']=data['Web']+data['Catalogue']+data['Store']\nrfm_f=data.groupby('ID')['Total_Times'].sum()\nrfm_f=rfm_f.reset_index()\nrfm_f.columns=['ID','Frequency']\nrfm_f.head()","f31d5732":"#Merge two dfs\nrfm=pd.merge(rfm_m,rfm_f, on='ID', how='inner')\nrfm.head()","dcdde9a0":"rfm_r=data.groupby('ID')['Recency'].sum()\nrfm_r=rfm_r.reset_index()\nrfm_r.head()","ae824acf":"rfm=pd.merge(rfm,rfm_r, on='ID', how='inner')\nrfm.head()","7d03c7b8":"attributes=['Total_Spend','Frequency','Recency']\n#plt.rcParams['figure.figzise']=[10,8]\nplt.figure(figsize=(10,8))\nsns.boxplot(data=rfm[attributes])\nplt.title('Outliers Variable Distribution',fontsize=14, fontweight='bold')\nplt.ylabel('Range',fontweight='bold')\nplt.xlabel('Attributes',fontweight='bold')","b82bb585":"rfm.head()","5234916f":"#Removing outliers\n\nQ1 = rfm.Total_Spend.quantile(0.05)\nQ3 = rfm.Total_Spend.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Total_Spend >= Q1 - 1.5*IQR) & (rfm.Total_Spend <= Q3 + 1.5*IQR)]\n\nQ1=rfm.Frequency.quantile(0.05)\nQ3=rfm.Frequency.quantile(0.95)\nIQR=Q3-Q1\nrfm=rfm[(rfm.Frequency>=Q1-1.5*IQR) & (rfm.Frequency<=Q3+1.5*IQR)]\n\nQ1=rfm.Recency.quantile(0.05)\nQ3=rfm.Recency.quantile(0.95)\nIQR=Q3-Q1\nrfm=rfm[(rfm.Recency>=Q1-1.5*IQR)& (rfm.Recency<=Q3+1.5*IQR)]\nrfm.head()\n\n\n","182dae4d":"rfm_df=rfm[['Total_Spend','Frequency','Recency']]\nscaler=StandardScaler()\nrfm_df_scaled=scaler.fit_transform(rfm_df)\nrfm_df_scaled.shape","fc7de2c4":"rfm_df_scaled=pd.DataFrame(rfm_df_scaled)\nrfm_df_scaled.columns=['Total_Amount','Frequency','Recency']\nrfm_df_scaled.head()","9c98e838":"kmeans=KMeans(n_clusters=4,max_iter=50)\nkmeans.fit(rfm_df_scaled)","d75e5450":"kmeans.labels_","7a69d959":"#Elbow-curve\/SSD\nssd=[]\nrange_n_clusters=[2,3,4,5,6,7,8]\nfor num_clusters in range_n_clusters:\n    kmeans=KMeans(n_clusters=num_clusters, max_iter=50)\n    kmeans.fit(rfm_df_scaled)\n    \n    ssd.append(kmeans.inertia_)\n    \n# plot the SSDs for each n_clusters\nplt.plot(ssd)","54e8b6df":"#Silhouette analysis\n\nrange_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n\nfor num_clusters in range_n_clusters:\n    \n    #initialise kmeans\n    kmeans=KMeans(n_clusters=num_clusters, max_iter=50)\n    kmeans.fit(rfm_df_scaled)\n    \n    cluster_labels=kmeans.labels_\n\n    #silhouette score\n    silhouette_avg = silhouette_score(rfm_df_scaled, cluster_labels)\n    print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))","89f6a8c8":"# Final model with k=3\nkmeans = KMeans(n_clusters=3, max_iter=50)\nkmeans.fit(rfm_df_scaled)","c4b45f48":"kmeans.labels_","970503fb":"#assign the label\nrfm['Cluster_ID']=kmeans.labels_\nrfm.head()","279d920e":"#Boxplot to visualise the Cluster_ID vs Total_Spend\n\nsns.boxplot(x='Cluster_ID',y='Total_Spend',data=rfm)","4bf2378c":"#Boxplot to visualise the Cluster_ID vs Frequency\n\nsns.boxplot(x='Cluster_ID',y='Frequency',data=rfm)","c9b406e6":"#Boxplot to visualise the Cluster_ID vs Recency\n\nsns.boxplot(x='Cluster_ID',y='Recency',data=rfm)","9c3004e9":"[](http:\/\/)","cce1bf32":"Finding the optimal number of cluster","b603a66d":"# **Final Analysis**","77411cde":"# **Data Preparation**","10cb2fa3":"# **Data Importing**","c5ac0e1f":"# **Data Preparation**","637e0196":"# **Data Cleanning**","7fe10816":"Data Preprocessing","435721cb":"# **Building the Module**","a9099809":"Kmeans clustering with 3 Cluster IDs:\n\nCustomers with the Cluster ID 1 has the most spend amount in store.\nCustomers with the Cluster ID 1 also has the relatively higher frequency than other groups.\nCustomers with the Cluster ID 2 have the lower recency ans spend less amount, hereby Customers in Cluster ID 2 have the less importance in business point of view."}}