{"cell_type":{"2a4f6687":"code","0e390c98":"code","c38ce03a":"code","f3d1f902":"code","11feb5bd":"code","6ba646bd":"code","6362c04a":"code","2f54c2c6":"code","a41b61d4":"code","76289d2e":"code","a50f28a9":"code","13bd7a00":"code","a9c2f537":"code","305e99d3":"code","b11e1187":"code","6fae3309":"code","4960c093":"code","a553ff58":"code","46443bd1":"code","f4ce1cb4":"code","b8b8e94f":"code","e3f8120f":"code","4dc67b84":"code","f3aa293b":"code","405e5c1d":"code","fb3091a5":"code","9e775831":"code","22c3698b":"code","35e92edc":"code","edf6f2b0":"code","5e91f139":"code","4df57ce8":"code","1514b29a":"code","6b83a917":"code","cd70a7a5":"code","8850f438":"code","98b5473f":"code","4dfeff5f":"code","cc1f69a6":"code","c01d634f":"code","7f1d1dc5":"code","b87f6e8a":"code","cf62d264":"code","9afc1f63":"code","776bf650":"code","d77eb1a3":"code","0e2fa1c9":"code","1e02df23":"code","6308d73b":"code","b1963392":"code","42997c30":"code","1ec2f107":"code","eb169433":"code","76d0c48e":"code","89d8ec18":"code","f1a7537e":"code","2b9261eb":"code","a6e4ab71":"code","07697b5e":"code","6da158f0":"code","4cdad5f5":"code","5321f2b5":"code","93f2b65e":"code","60f65fb7":"code","a460b8f4":"code","71150f6a":"code","d8951377":"code","cda4faa1":"code","a459286e":"code","5e3771f4":"code","9888641f":"code","c3ebe907":"code","37d0ec8a":"code","3da5006b":"code","749c980d":"code","93cae4ed":"code","b61376c8":"code","cb596a7e":"code","79bf72bf":"code","a276d778":"code","ffaf7b23":"code","f84bb019":"code","6e8ef385":"code","1925aa1c":"code","db95d42b":"code","fabb388e":"code","6661fe7d":"code","0cf0034d":"code","ffddda01":"code","fff8e425":"code","8cccce7c":"code","53a8cb40":"code","bb839818":"code","134d54c7":"code","aa492340":"code","df39aad0":"code","eaa8bd51":"code","b81b02bc":"code","bcd700ec":"code","ce915623":"code","750bdeae":"code","1c80be77":"code","b24c4e70":"code","fd000668":"code","4659d5a4":"code","c2824744":"code","421e1cd2":"code","1928be8e":"code","93e483e1":"code","c471f21c":"code","ae6ef979":"code","6ca04981":"code","3d2fbf56":"code","bfdd75bb":"code","c47c8547":"code","9716e9de":"code","5fba64f2":"code","e47d3a14":"code","49a5a869":"code","44475b43":"code","db4a86c3":"code","d0f0f5cd":"code","ff03c3e9":"code","bb39176d":"code","361efa94":"code","56a60b4a":"code","c447803e":"code","91f71b8a":"code","8e90e309":"code","acda97df":"code","ff339483":"code","5948a357":"code","6b415b65":"code","4659d810":"code","120d192b":"code","5c89e85c":"code","f86903c7":"code","1da1fc50":"code","f01859f4":"code","7626c30c":"code","168d2d51":"code","1f0b04a6":"code","1329461c":"code","480ace90":"code","4adeb1df":"code","d395e64d":"code","ac0c6a93":"code","96d1dc21":"code","ca1860f4":"code","639a9c7b":"code","1d85df65":"code","2e6d2cb6":"code","7ab62ad5":"code","9cdbae4a":"code","3a09a47a":"code","b218c082":"code","f834d30a":"code","c760c766":"code","0a46d332":"code","a8490459":"markdown","85b03044":"markdown","5f790b43":"markdown","f305f0a3":"markdown","efb2fdc4":"markdown","653482db":"markdown","91034949":"markdown","fd0f602b":"markdown","86636f56":"markdown","e88eb06e":"markdown","ead883a2":"markdown","df6a88ef":"markdown","a53ebccd":"markdown","c437a654":"markdown","8e02899c":"markdown","c8fcc47c":"markdown","07faa7f9":"markdown","06e472d6":"markdown","ce40dc0d":"markdown","9c79e5c5":"markdown","25f95715":"markdown","835bf642":"markdown","61abdddb":"markdown","97300692":"markdown","5db0ba54":"markdown","606138e4":"markdown","ccabe551":"markdown","58712b7b":"markdown","d1cedeb4":"markdown","b133a743":"markdown","96c49ede":"markdown","29d10a33":"markdown","725204b4":"markdown","0c2ac518":"markdown","e1bdfafe":"markdown","85c6403f":"markdown","f383c072":"markdown","390a1bff":"markdown","db5b9c83":"markdown","564a5133":"markdown","cca42371":"markdown","daf22e9e":"markdown","cf9c8c1a":"markdown","bfb0ad99":"markdown","c14c9461":"markdown","1eb327d3":"markdown","2e8c8a68":"markdown","aebcf02e":"markdown","eb886997":"markdown","85bf5c7c":"markdown","279a847e":"markdown","bf4d658f":"markdown","9a2267ba":"markdown","f3de3603":"markdown","abc32644":"markdown","63578200":"markdown","ebe0e40a":"markdown","57a1325b":"markdown","626f4c0a":"markdown","e2f0edac":"markdown","90105c2c":"markdown","55647c7a":"markdown","0873f8ca":"markdown","2673d294":"markdown","494c3739":"markdown","1a7927d6":"markdown","5fe52097":"markdown","30ebd757":"markdown","e3e39a85":"markdown","117d634f":"markdown","1a4570dd":"markdown","2bf55f2e":"markdown","5c31c0c2":"markdown","d804ac23":"markdown","38134b74":"markdown","7a257584":"markdown","1df3d8b0":"markdown","1a7b9afd":"markdown","a36cc21b":"markdown","0ac8cb04":"markdown","7499ebc9":"markdown","a74709e0":"markdown","94e0f1f6":"markdown","b62aa489":"markdown","871768cb":"markdown","83136ef5":"markdown","97faa58b":"markdown","b30cd87c":"markdown","ea033632":"markdown","1e0b8370":"markdown","9eec299b":"markdown","01f1de66":"markdown","41e4fc34":"markdown","9c7de1c9":"markdown","16b90bc0":"markdown","19b22e86":"markdown","537a6a92":"markdown","3bbe9da7":"markdown","13cfcfda":"markdown","5303ebe4":"markdown","8abe1688":"markdown","40fc8236":"markdown","51964b29":"markdown","547d8ac5":"markdown","15cadd11":"markdown","9b68e56f":"markdown","82ff5dd6":"markdown","12010fdb":"markdown","2c9feeb5":"markdown","daaf78b9":"markdown","5ac800b2":"markdown","b8486f1b":"markdown","ca4f6d4f":"markdown","b17c5e11":"markdown","7d1cd40d":"markdown","f3763f7f":"markdown","a8c80854":"markdown","a7d9c0ae":"markdown","a75ddeb2":"markdown","753a9ada":"markdown","a0a292a1":"markdown","a9d31322":"markdown","6eb3e89a":"markdown","a0926795":"markdown","60a27306":"markdown","dcb01727":"markdown","afb88d9a":"markdown","a7b32d41":"markdown","b3d2bdfe":"markdown","ca8b7961":"markdown","f27f8913":"markdown","8531b75f":"markdown","0e3d33a5":"markdown","4afc8083":"markdown","ed7b3906":"markdown","6c8a541d":"markdown","12fcda7b":"markdown","fadf9ea6":"markdown","9814c9ef":"markdown","792a820c":"markdown","47e3aa8a":"markdown","14cd6a81":"markdown","d578dd0c":"markdown","ffafe2fa":"markdown","3880c2ca":"markdown","6ae02c76":"markdown","00ffd21c":"markdown","272f2aa0":"markdown","9873a5f4":"markdown","e1a21245":"markdown","ba899ae0":"markdown","797692ea":"markdown","119b8ba6":"markdown","62d80dc0":"markdown","eb9393ce":"markdown","60b5d4c2":"markdown","fa105c78":"markdown","2042af8a":"markdown","7b3f5245":"markdown","f557e5b7":"markdown","a0cd0124":"markdown","335d15e9":"markdown","82496054":"markdown","2811a38c":"markdown","9c9529ac":"markdown","010bb1c8":"markdown"},"source":{"2a4f6687":"#Data Analysis & Data wrangling\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\n\n#Visualization\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\n%matplotlib inline\n\n# Plot Style\nsns.set_context(\"paper\")\nstyle.use('fivethirtyeight')\n\n# Machine Learning Libraries\n\n#Sci-kit learn libraries\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\n\n#statmodel libraries\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport statsmodels.api as sm","0e390c98":"import warnings\nwarnings.filterwarnings('ignore')","c38ce03a":"pd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)","f3d1f902":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","11feb5bd":"lead = pd.read_csv(\"\/kaggle\/input\/lead-scoring-dataset\/Lead Scoring.csv\")\nlead.head()","6ba646bd":"lead.tail()","6362c04a":"#database dimension\nprint(\"Database dimension     :\",lead.shape)\nprint(\"Database size          :\",lead.size)\nprint(\"Number of Row          :\",len(lead.index))\nprint(\"Number of Columns      :\",len(lead.columns))","2f54c2c6":"#checking numerical columns statistics\nlead.describe()","a41b61d4":"#info about the column types etc. \nlead.info()","76289d2e":"lead = lead.replace('Select', np.nan)","a50f28a9":"plt.figure(figsize = (18,8))\nsns.heatmap(lead.isnull(),cbar = False)\nplt.show()","13bd7a00":"#Column wise null values in train data set \nnull_perc = pd.DataFrame(round((lead.isnull().sum())*100\/lead.shape[0],2)).reset_index()\nnull_perc.columns = ['Column Name', 'Null Values Percentage']\nnull_value = pd.DataFrame(lead.isnull().sum()).reset_index()\nnull_value.columns = ['Column Name', 'Null Values']\nnull_lead = pd.merge(null_value, null_perc, on='Column Name')\nnull_lead.sort_values(\"Null Values\", ascending = False)","a9c2f537":"#plotting the null value percentage\nsns.set_style(\"white\")\nfig = plt.figure(figsize=(12,5))\nnull_lead = pd.DataFrame((lead.isnull().sum())*100\/lead.shape[0]).reset_index()\nax = sns.pointplot(\"index\",0,data=null_lead)\nplt.xticks(rotation =90,fontsize =9)\nax.axhline(45, ls='--',color='red')\nplt.title(\"Percentage of Missing values\")\nplt.ylabel(\"PERCENTAGE\")\nplt.xlabel(\"COLUMNS\")\nplt.show()","305e99d3":"Row_Null50_Count = len(lead[lead.isnull().sum(axis=1)\/lead.shape[1]>0.5])\nprint( 'Total number of rows with more than 50% null values are : ', Row_Null50_Count)","b11e1187":"print(\"Total number of duplicate values in Prospect ID column :\" , lead.duplicated(subset = 'Prospect ID').sum())\nprint(\"Total number of duplicate values in Lead Number column :\" , lead.duplicated(subset = 'Lead Number').sum())","6fae3309":"cols_to_drop = ['Prospect ID','Lead Number','How did you hear about X Education','Lead Profile',\n                'Lead Quality','Asymmetrique Profile Score','Asymmetrique Activity Score',\n               'Asymmetrique Activity Index','Asymmetrique Profile Index','Tags','Last Notable Activity']","4960c093":"#dropping unnecessary columns\n\nlead.drop(cols_to_drop, 1, inplace = True)\nlen(lead.columns)","a553ff58":"categorical_col = lead.select_dtypes(exclude =[\"number\"]).columns.values\nnumerical_col = lead.select_dtypes(include =[\"number\"]).columns.values\nprint(\"CATEGORICAL FEATURES : \\n {} \\n\\n\".format(categorical_col))\nprint(\"NUMERICAL FEATURES : \\n {} \".format(numerical_col))","46443bd1":"# Checking unique values and null values for the categorical columns\ndef Cat_info(df, categorical_column):\n    df_result = pd.DataFrame(columns=[\"columns\",\"values\",\"unique_values\",\"null_values\",\"null_percent\"])\n    \n    df_temp=pd.DataFrame()\n    for value in categorical_column:\n        df_temp[\"columns\"] = [value]\n        df_temp[\"values\"] = [df[value].unique()]\n        df_temp[\"unique_values\"] = df[value].nunique()\n        df_temp[\"null_values\"] = df[value].isna().sum()\n        df_temp[\"null_percent\"] = (df[value].isna().sum()\/len(df)*100).round(1)\n        df_result = df_result.append(df_temp)\n    \n    df_result.sort_values(\"null_values\", ascending =False, inplace=True)\n    df_result.set_index(\"columns\", inplace=True)\n    return df_result","f4ce1cb4":"df_cat = Cat_info(lead, categorical_col)\ndf_cat","b8b8e94f":"# Appending the columns to col_to_drop where only 1 category value is present\n\ncols_to_drop = df_cat[df_cat['unique_values']==1].index.values.tolist() \ncols_to_drop","e3f8120f":"#dropping unnecessary columns\n\nlead.drop(cols_to_drop, 1, inplace = True)\nlen(lead.columns)","4dc67b84":"categorical_col = lead.select_dtypes(exclude =[\"number\"]).columns.values\nnew_cat = Cat_info(lead, categorical_col)\nnew_cat","f3aa293b":"lead['City'].value_counts(normalize=True)*100","405e5c1d":"# Let's check how City and Country are connected with each other\nlead.groupby(['Country','City'])['Country'].count()","fb3091a5":"style.use('fivethirtyeight')\nax = sns.countplot(lead['City'],palette = 'Set2')\nplt.xticks(rotation = 90)\nplt.show()","9e775831":"lead.drop(\"City\",axis=1, inplace = True)\nlen(lead.columns)","22c3698b":"lead['Specialization'].value_counts(normalize = True)*100","35e92edc":"plt.figure(figsize=(12,6))\nax = sns.countplot(lead['Specialization'],palette = 'Set2')\nplt.xticks(rotation = 90)\nplt.show()","edf6f2b0":"lead['Specialization'] = lead['Specialization'].replace(np.nan, 'Others')\nplt.figure(figsize=(12,6))\nax = sns.countplot(lead['Specialization'],palette = 'Set2')\nplt.xticks(rotation = 90)\nplt.show()","5e91f139":"lead['What matters most to you in choosing a course'].value_counts(normalize = True)*100","4df57ce8":"lead.drop('What matters most to you in choosing a course', axis = 1, inplace=True)\nlen(lead.columns)","1514b29a":"lead['What is your current occupation'].value_counts(normalize=True)*100","6b83a917":"#lead['What is your current occupation'] = lead['What is your current occupation'].replace(np.nan, 'Unemployed')\nlead['What is your current occupation'] = lead['What is your current occupation'].replace(np.nan, 'Unknown')\nlead['What is your current occupation'].value_counts(normalize = True)*100","cd70a7a5":"#Let's check how is the Country data distributed\nlead['Country'].value_counts(normalize=True)","8850f438":"lead.drop('Country', axis = 1, inplace = True)\nlen(lead.columns)","98b5473f":"print(\"Number of null values in Last Activity column is : \", lead['Last Activity'].isnull().sum())\nprint(\"Percentage of null values in Last Activity column is : \", round(lead['Last Activity'].isnull().sum()\/lead.shape[0]*100,2))","4dfeff5f":"lead['Last Activity'].value_counts(normalize = True)*100","cc1f69a6":"lead['Last Activity'] = lead['Last Activity'].replace(np.nan, 'Email Opened')\nprint(\"Number of null values in Last Activity column is : \", lead['Last Activity'].isnull().sum())","c01d634f":"print(\"Number of null values in Lead Source column is : \", lead['Lead Source'].isnull().sum())\nprint(\"Percentage of null values in Lead Source column is : \", round(lead['Lead Source'].isnull().sum()\/lead.shape[0]*100,2))","7f1d1dc5":"lead['Lead Source'].value_counts(normalize = True)*100","b87f6e8a":"lead['Lead Source'] = lead['Lead Source'].replace(np.nan, 'Google')\nlead['Lead Source'] = lead['Lead Source'].replace(['google'], 'Google')\nprint(\"Number of null values in Lead Source column is : \", lead['Lead Source'].isnull().sum())","cf62d264":"# Checking unique values and null values for the categorical columns\ndef Num_info(df, numeric_column):\n    df_result = pd.DataFrame(columns=[\"columns\",\"null_values\",\"null_percent\"])\n    \n    df_temp=pd.DataFrame()\n    for value in numeric_column:\n        df_temp[\"columns\"] = [value]\n        df_temp[\"null_values\"] = df[value].isna().sum()\n        df_temp[\"null_percent\"] = (df[value].isna().sum()\/len(df)*100).round(1)\n        df_result = df_result.append(df_temp)\n    \n    df_result.sort_values(\"null_values\", ascending =False, inplace=True)\n    df_result.set_index(\"columns\", inplace=True)\n    return df_result","9afc1f63":"df_num = Num_info(lead,numerical_col)\ndf_num","776bf650":"plt.figure(figsize = (12,6))\nplt.subplot(1,2,1)\nsns.distplot(lead['TotalVisits'])\nplt.subplot(1,2,2)\nsns.boxplot(lead['TotalVisits'])\nplt.show()","d77eb1a3":"lead['TotalVisits'].fillna(lead['TotalVisits'].median(), inplace=True)\nlead['TotalVisits'].isnull().sum()","0e2fa1c9":"plt.figure(figsize = (12,6))\nplt.subplot(1,2,1)\nsns.distplot(lead['Page Views Per Visit'])\nplt.subplot(1,2,2)\nsns.boxplot(lead['Page Views Per Visit'])\nplt.show()","1e02df23":"lead['Page Views Per Visit'].fillna(lead['Page Views Per Visit'].median(), inplace=True)\nlead['Page Views Per Visit'].isnull().sum()","6308d73b":"converted = lead['Converted'].value_counts().rename_axis('unique_values').to_frame('counts')\nconverted","b1963392":"\nmy_circle=plt.Circle( (0,0), 0.7, color='white')\nplt.pie(converted.counts, labels = ['No','Yes'],colors = ['red','green'],autopct='%1.1f%%')\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()\n","42997c30":"# function for plotting repetitive countplots in univariate categorical analysis on the lead dataset\n# This function will create two subplots: \n# 1. Count plot of categorical column w.r.t Converted; \n# 2. Percentage of converted leads within column\n\ndef univariate_categorical(feature,label_rotation=False,horizontal_layout=True):\n    temp_count = lead[feature].value_counts()\n    temp_perc = lead[feature].value_counts(normalize = True)\n    df1 = pd.DataFrame({feature: temp_count.index,'Total Leads': temp_count.values,'% Values': temp_perc.values * 100})\n    print(df1)\n    \n    # Calculate the percentage of Converted=1 per category value\n    cat_perc = lead[[feature, 'Converted']].groupby([feature],as_index=False).mean()\n    cat_perc[\"Converted\"] = cat_perc[\"Converted\"]*100\n    cat_perc.sort_values(by='Converted', ascending=False, inplace=True)\n    \n    if(horizontal_layout):\n        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\n    else:\n        fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(20,24))   \n    # 1. Subplot 1: Count plot of categorical column\n    sns.set_palette(\"Set2\")\n    s = sns.countplot(ax=ax1, \n                    x = feature, \n                    data=lead,\n                    hue =\"Converted\",\n                    order=cat_perc[feature],\n                    palette=['r','g'])\n\n    # Define common styling\n    ax1.set_title(feature, fontdict={'fontsize' : 15, 'fontweight' : 5, 'color' : 'Blue'}) \n    ax1.legend(['Not Converted','Converted'])\n    \n    \n    if(label_rotation):\n        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n    \n    # 2. Subplot 2: Percentage of defaulters within the categorical column\n    s = sns.barplot(ax=ax2, \n                    x = feature, \n                    y='Converted', \n                    order=cat_perc[feature], \n                    data=cat_perc,\n                    palette='Set2')\n    \n    if(label_rotation):\n        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n    plt.ylabel('Percent of Converted leads [%]', fontsize=15)\n    plt.xlabel(feature,fontsize=15) \n    plt.tick_params(axis='both', which='major', labelsize=10)\n    ax2.set_title(feature + \"( Converted % )\", fontdict={'fontsize' : 15, 'fontweight' : 5, 'color' : 'Blue'}) \n\n    plt.show();","1ec2f107":"lead.columns","eb169433":"# Renaming some of the column headers which has long header\n\nlead.rename(columns={'What is your current occupation': 'Occupation', \n                     'Through Recommendations': 'Recommendation',\n                     'A free copy of Mastering The Interview': 'Free Copy'                   \n                    },inplace = True)\nlead.columns","76d0c48e":"#Run the function to get plot categorical plots \nunivariate_categorical(\"Lead Origin\",label_rotation=True)","89d8ec18":"#Run the function to get plot categorical plots\nunivariate_categorical(\"Lead Source\",label_rotation=True)","f1a7537e":"lead['Lead Source'] = lead['Lead Source'].replace(['Click2call', 'Live Chat', 'NC_EDM', 'Pay per Click Ads', 'Press_Release',\n  'Social Media', 'WeLearn', 'bing', 'blog', 'testone', 'welearnblog_Home', 'youtubechannel'], 'Other Sources')","2b9261eb":"#Running the function again to check the updated statistics\nunivariate_categorical(\"Lead Source\",label_rotation=True)","a6e4ab71":"#Run the function to get plot categorical plots\nunivariate_categorical(\"Do Not Email\")","07697b5e":"#Run the function to get plot categorical plots\nunivariate_categorical(\"Last Activity\",label_rotation=True)","6da158f0":"# Let's keep considerable last activities as such and club all others to \"Other_Activity\"\nlead['Last Activity'] = lead['Last Activity'].replace(['Had a Phone Conversation', 'View in browser link Clicked', \n                                                       'Visited Booth in Tradeshow', 'Approached upfront',\n                                                       'Resubscribed to emails','Email Received', 'Email Marked Spam'], 'Other Activity')","4cdad5f5":"#Run the function to get plot categorical plots\nunivariate_categorical(\"Last Activity\",label_rotation=True)","5321f2b5":"#Run the function to get plot categorical plots\nunivariate_categorical(\"Specialization\",label_rotation=True)","93f2b65e":"#Run the function to get plot categorical plots\nunivariate_categorical(\"Occupation\",label_rotation=True)","60f65fb7":"def pieplot(col):\n    my_circle=plt.Circle( (0,0), 0.7, color='white')\n    converted = lead[col].value_counts().rename_axis('unique_values').to_frame('counts')\n    plt.pie(converted.counts, labels = [\"No\",\"Yes\"],colors = ['red','green'],autopct='%1.1f%%')\n    p=plt.gcf()\n    p.gca().add_artist(my_circle)\n    plt.title(col)","a460b8f4":"# Lets lookinto the data distribution of the following columns\ncol = ['Do Not Call','Search', 'Newspaper', 'Newspaper Article', 'Digital Advertisement', 'X Education Forums', 'Free Copy','Recommendation']\nplt.figure(figsize = (12,8))\ni=1\nfor each_col in col:\n    plt.subplot(2,4,i)\n    pieplot(each_col)\n    i+=1","71150f6a":"#Run the function to get plot categorical plots\nunivariate_categorical(\"Free Copy\",label_rotation=True)","d8951377":"lead.drop(col,axis = 1, inplace = True)\nlen(lead.columns)","cda4faa1":"lead.columns","a459286e":"numerical_cols = ['TotalVisits', 'Total Time Spent on Website', 'Page Views Per Visit']\nplt.figure(figsize=(12,12))\n\ni=1\nfor col in numerical_cols:\n    plt.subplot(2,3,i)\n    sns.distplot(lead[col])\n    plt.subplot(2,3,3+i)\n    sns.boxplot(y=lead[col], x = lead['Converted'])\n    i+=1","5e3771f4":"plt.figure(figsize =(20,20))\nsns.pairplot(lead[numerical_col],hue=\"Converted\",kind='scatter', plot_kws={'alpha':0.4},palette = 'Dark2')                                  \nplt.show()","9888641f":"#Checking the detailed percentile values\nlead.describe(percentiles=[.1,.5,.25,.75,.90,.95,.99])","c3ebe907":"numerical_col","37d0ec8a":"#Plotting the numerical columns for outlier values\ni=1\nplt.figure(figsize=[16,8])\nfor col in numerical_col:\n    plt.subplot(2,2,i)\n    sns.boxplot(y=lead[col])\n    plt.title(col)\n    plt.ylabel('')\n    i+=1","3da5006b":"#Capping the data at 95% percetile value\nQ4 = lead['TotalVisits'].quantile(0.95) # Get 95th quantile\nprint(\"Total number of rows getting capped for TotalVisits column : \",len(lead[lead['TotalVisits'] >= Q4]))\nlead.loc[lead['TotalVisits'] >= Q4, 'TotalVisits'] = Q4 # outlier capping\n\nQ4 = lead['Page Views Per Visit'].quantile(0.95) # Get 95th quantile\nprint(\"Total number of rows getting capped for Page Views Per Visit column : \",len(lead[lead['Page Views Per Visit'] >= Q4]))\nlead.loc[lead['Page Views Per Visit'] >= Q4, 'Page Views Per Visit'] = Q4 # outlier capping","749c980d":"#replotting the graphs to check for outlier treatment\ni=1\nplt.figure(figsize=[16,8])\nfor col in numerical_col:\n    plt.subplot(2,2,i)\n    sns.boxplot(y=lead[col])\n    plt.title(col)\n    plt.ylabel('')\n    i+=1","93cae4ed":"# Checking the percentile values again \nlead.describe(percentiles=[.1,.5,.25,.75,.90,.95,.99])","b61376c8":"# Checking the unique value counts for categorcial columns\nlead.nunique().sort_values()","cb596a7e":"# Checking the categorical values for 'Do Not Email' feature\nlead['Do Not Email'].value_counts()","79bf72bf":"# List of variables to map\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})\n\n# Applying the function to the lead YES\/NO variable list\nlead['Do Not Email'] = lead[['Do Not Email']].apply(binary_map)","a276d778":"# rechecking the categorical values for 'Do Not Email' feature\nlead['Do Not Email'].value_counts()","ffaf7b23":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(lead[['Lead Origin', 'Lead Source', 'Occupation', 'Last Activity', 'Specialization']], drop_first=True)\n\n# Adding the results to the master dataframe\nlead = pd.concat([lead, dummy1], axis=1)\n\nlead.head()","f84bb019":"# We have created dummies for the below variables, so we can drop them\nlead = lead.drop(['Lead Origin', 'Lead Source', 'Occupation', 'Last Activity', 'Specialization'], axis=1)\nlead.info()","6e8ef385":"# Visualizing the data using heatmap\nplt.figure(figsize=[15,15])\nsns.heatmap(lead.corr(), cmap=\"RdYlGn\",linewidth =1)\nplt.show()","1925aa1c":"print('Total number of columns after One-Hot Encoding : ',len(lead.columns))","db95d42b":"corr_lead = lead.corr()\ncorr_lead = corr_lead.where(np.triu(np.ones(corr_lead.shape),k=1).astype(np.bool))\ncorr_df = corr_lead.unstack().reset_index()\ncorr_df.columns =['VAR1','VAR2','Correlation']\ncorr_df.dropna(subset = [\"Correlation\"], inplace = True) \ncorr_df.sort_values(by='Correlation', ascending=False, inplace=True)\n\n# Top 5 Positive correlated variables\ncorr_df.head(5)","fabb388e":"corr_df.sort_values(by='Correlation', ascending=True, inplace=True)\n\n# Top 5 Negatively correlated variables\ncorr_df.head(5)","6661fe7d":"# target variable\nY = lead['Converted']\nX = lead.drop(['Converted'], axis=1)\n\n# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, test_size=0.3, random_state=100)","0cf0034d":"#Checking the shape of the created Train & Test DFs\nprint(\" Shape of X_train is : \",X_train.shape)\nprint(\" Shape of y_train is : \",y_train.shape)\nprint(\" Shape of X_test is  : \",X_test.shape)\nprint(\" Shape of y_test is  : \",y_test.shape)","ffddda01":"scaler = StandardScaler()\n\nX_train[['Total Time Spent on Website','Page Views Per Visit','TotalVisits']] = scaler.fit_transform(X_train[['Total Time Spent on Website','Page Views Per Visit','TotalVisits']])\nX_train.head()","fff8e425":"# Using RFE to reduce the feature count from 54 to 20\nlogreg = LogisticRegression()\nrfe = RFE(logreg, 20)           \nrfe = rfe.fit(X_train, y_train)\n","8cccce7c":"#checking the output of RFE\nlist(zip(X_train.columns, rfe.support_, rfe.ranking_))","53a8cb40":"#checking which columns remained after RFE\nrfe_col = X_train.columns[rfe.support_]\nrfe_col","bb839818":"#Columns which have been removed after RFE\nX_train.columns[~rfe.support_]","134d54c7":"# Functions to repeat Logictis regression model and VIF calculation repeatedly\n\n# function to build logistic regression model\ndef build_logistic_model(feature_list):\n    X_train_local = X_train[feature_list] # get feature list for VIF\n    X_train_sm = sm.add_constant(X_train_local) # required by statsmodels   \n    log_model = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial()).fit() # build model and learn coefficients  \n    return(log_model, X_train_sm) # return the model and the X_train fitted with constant \n\n#function to calculate VIF\ndef calculate_VIF(X_train):  # Calculate VIF for features\n    vif = pd.DataFrame()\n    vif['Features'] = X_train.columns # Read the feature names\n    vif['VIF'] = [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])] # calculate VIF\n    vif['VIF'] = round(vif['VIF'],2)\n    vif.sort_values(by='VIF', ascending = False, inplace=True)  \n    return(vif) # returns the calculated VIFs for all the features","aa492340":"features = list(rfe_col) #  Use RFE selected variables\nlog_model1, X_train_sm1 = build_logistic_model(features) # Call the function and get the model and the X_train_sm for prediction\nlog_model1.summary()","df39aad0":"#Checking VIF values\ncalculate_VIF(X_train)","eaa8bd51":"features.remove('Occupation_Housewife') # Remove 'Occupation_Housewife number' from RFE features list\nlog_model2, X_train_sm2 = build_logistic_model(features) # Call the function and get the model and the X_train_sm for prediction\nlog_model2.summary()","b81b02bc":"#Checking VIF Values\ncalculate_VIF(X_train[features])","bcd700ec":"features.remove('Specialization_Retail Management')\nlog_model3, X_train_sm3 = build_logistic_model(features) # Call the function and get the model and the X_train_sm for prediction\nlog_model3.summary()","ce915623":"#Checking VIF Values\ncalculate_VIF(X_train[features])","750bdeae":"features.remove('Lead Source_Facebook')\nlog_model4, X_train_sm4 = build_logistic_model(features) # Call the function and get the model and the X_train_sm for prediction\nlog_model4.summary()","1c80be77":"#Checking VIF Values\ncalculate_VIF(X_train[features])","b24c4e70":"features.remove('Specialization_Rural and Agribusiness')\nlog_model5, X_train_sm5 = build_logistic_model(features) # Call the function and get the model and the X_train_sm for prediction\nlog_model5.summary()","fd000668":"#Checking VIF Values\ncalculate_VIF(X_train[features])","4659d5a4":"def calculate_woe_iv(dataset, feature, target):\n    lst = []\n    for i in range(dataset[feature].nunique()):\n        val = list(dataset[feature].unique())[i]\n        lst.append({\n            'Value': val,\n            'All': dataset[dataset[feature] == val].count()[feature],\n            'Good': dataset[(dataset[feature] == val) & (dataset[target] == 0)].count()[feature],\n            'Bad': dataset[(dataset[feature] == val) & (dataset[target] == 1)].count()[feature]\n        })\n        \n    dset = pd.DataFrame(lst)\n    dset['Distr_Good'] = dset['Good'] \/ dset['Good'].sum()\n    dset['Distr_Bad'] = dset['Bad'] \/ dset['Bad'].sum()\n    dset['WoE'] = np.log(dset['Distr_Good'] \/ dset['Distr_Bad'])\n    dset = dset.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n    dset['IV'] = (dset['Distr_Good'] - dset['Distr_Bad']) * dset['WoE']\n    iv = dset['IV'].sum()\n    \n    dset = dset.sort_values(by='WoE')\n    \n    return dset, iv","c2824744":"for col in lead.columns:\n    if col in features:\n        df, iv = calculate_woe_iv(lead, col, 'Converted')\n        print('IV score of column : ',col, \" is \", round(iv,4))","421e1cd2":"features.remove('Occupation_Unknown')\nlog_model6, X_train_sm6 = build_logistic_model(features) # Call the function and get the model and the X_train_sm for prediction\nlog_model6.summary()","1928be8e":"#Checking VIF Values\ncalculate_VIF(X_train[features])","93e483e1":"for col in lead.columns:\n    if col in features:\n        df, iv = calculate_woe_iv(lead, col, 'Converted')\n        print('IV score of column : ',col, \" is \", round(iv,4))","c471f21c":"features.remove('Specialization_Others')\nlog_model7, X_train_sm7 = build_logistic_model(features) # Call the function and get the model and the X_train_sm for prediction\nlog_model7.summary()","ae6ef979":"#Checking VIF Values\ncalculate_VIF(X_train[features])","6ca04981":"for col in lead.columns:\n    if col in features:\n        df, iv = calculate_woe_iv(lead, col, 'Converted')\n        print('IV score of column : ',col, \" is \", round(iv,4))","3d2fbf56":"features.remove('Specialization_Hospitality Management')\nlog_model8, X_train_sm8 = build_logistic_model(features) # Call the function and get the model and the X_train_sm for prediction\nlog_model8.summary()","bfdd75bb":"#Checking VIF Values\ncalculate_VIF(X_train[features])","c47c8547":"features.remove('Last Activity_Other Activity')\nlog_model9, X_train_sm9 = build_logistic_model(features) # Call the function and get the model and the X_train_sm for prediction\nlog_model9.summary()","9716e9de":"# How many features in the model ?\nlen(features)","5fba64f2":"# Create a matrix to Print the Accuracy, Sensitivity and Specificity\ndef lg_metrics(confusion_matrix):\n    TN =confusion_matrix[0,0]\n    TP =confusion_matrix[1,1]\n    FP =confusion_matrix[0,1]\n    FN =confusion_matrix[1,0]\n    accuracy = (TP+TN)\/(TP+TN+FP+FN)\n    speci = TN\/(TN+FP)\n    sensi = TP\/(TP+FN)\n    precision = TP\/(TP+FP)\n    recall = TP\/(TP+FN)\n    TPR = TP\/(TP + FN)\n    TNR = TN\/(TN + FP)\n    FPR = FP\/(TN + FP)\n    FNR = FN\/(TP + FN)\n    pos_pred_val = TP \/(TP+FP)\n    neg_pred_val = TN \/(TN+FN)\n    \n    print (\"Model Accuracy value is              : \", round(accuracy*100,2),\"%\")\n    print (\"Model Sensitivity value is           : \", round(sensi*100,2),\"%\")\n    print (\"Model Specificity value is           : \", round(speci*100,2),\"%\")\n    print (\"Model Precision value is             : \", round(precision*100,2),\"%\")\n    print (\"Model Recall value is                : \", round(recall*100,2),\"%\")\n    print (\"Model True Positive Rate (TPR)       : \", round(TPR*100,2),\"%\")\n    print (\"Model False Positive Rate (FPR)      : \", round(FPR*100,2),\"%\")\n    print (\"Model Poitive Prediction Value is    : \", round(pos_pred_val*100,2),\"%\")\n    print (\"Model Negative Prediction value is   : \", round(neg_pred_val*100,2),\"%\")","e47d3a14":"# Getting the predicted values on the train set\ny_train_pred = log_model9.predict(X_train_sm9)\ny_train_pred[:10]","49a5a869":"y_train_pred = y_train_pred.values.reshape(-1)\ny_train_pred[:10]","44475b43":"#Creating a dataframe with the actual Converted flag and the Predicted probabilities\ny_train_pred_final = pd.DataFrame({'Converted_IND':y_train.values, 'Converted_Prob':y_train_pred})\ny_train_pred_final['Prospect_IND'] = y_train.index\ny_train_pred_final.head()","db4a86c3":"#Finding Optimal Cutoff Point\n# Let's create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred_final[i]= y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > i else 0)\ny_train_pred_final.head()","d0f0f5cd":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci','Precision','Recall'])\nfrom sklearn.metrics import confusion_matrix\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final['Converted_IND'], y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    prec, rec, thresholds = precision_recall_curve(y_train_pred_final['Converted_IND'], y_train_pred_final[i])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci, prec[1], rec[1]]\ncutoff_df","ff03c3e9":"# Let's plot accuracy sensitivity and specificity for various probabilities.\nplt.figure(figsize=(18,8))\nsns.set_style(\"whitegrid\")\ncutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\nplt.xticks(np.arange(0,1,step=0.05),size=8)\nplt.axvline(x=0.335, color='r', linestyle='--') # additing axline\nplt.yticks(size=12)\nplt.show()","bb39176d":"y_train_pred_final['final_predicted_1'] = y_train_pred_final['Converted_Prob'].map( lambda x: 1 if x > 0.335 else 0)\ny_train_pred_final.drop([0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],axis = 1, inplace = True) # deleting the unnecessary columns\ny_train_pred_final.head()","361efa94":"# Let's assign Lead_score for the leads in Train Data Set\ny_train_pred_final['lead_score_1']=(y_train_pred_final['Converted_Prob']*100).astype(\"int64\")\ny_train_pred_final.sort_values(by='Converted_Prob',ascending=False)","56a60b4a":"# Function for Confusion Matrix :\ndef draw_cm( actual, predicted, cmap ): \n    cm = metrics.confusion_matrix( actual, predicted, [0,1] ) \n    sns.heatmap(cm, annot=True, fmt='.0f', cmap=cmap,\n    xticklabels = [\"Not Converted\", \"Converted\"] ,\n    yticklabels = [\"Not Converted\", \"Converted\"] ) \n    plt.ylabel('True labels')\n    plt.xlabel('Predicted labels') \n    plt.show()","c447803e":"#Plotting the Confusion Matrix\ndraw_cm( y_train_pred_final['Converted_IND'], y_train_pred_final['final_predicted_1'], \"GnBu\")","91f71b8a":"conf_matrix = confusion_matrix(y_train_pred_final['Converted_IND'], y_train_pred_final['final_predicted_1'] )\n\nlg_metrics(conf_matrix)","8e90e309":"# Classification Record : Precision, Recall and F1 Score\nprint( metrics.classification_report( y_train_pred_final['Converted_IND'], y_train_pred_final['final_predicted_1'] ) )","acda97df":"print(\"F1 Score: {}\".format(f1_score(y_train_pred_final['Converted_IND'], y_train_pred_final['final_predicted_1'])))","ff339483":"# Function to plot ROC Curve\ndef draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","5948a357":"# recoring the values FPR, TPR and Thresholds:\nfpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final['Converted_IND'], y_train_pred_final['Converted_Prob'] , drop_intermediate = False )","6b415b65":"#plotting the ROC curve \ndraw_roc(y_train_pred_final['Converted_IND'], y_train_pred_final['Converted_Prob'])","4659d810":"p, r, thresholds = precision_recall_curve(y_train_pred_final['Converted_IND'], y_train_pred_final['Converted_Prob'])","120d192b":"# Plotting the Precision-Recall Trade off Curve\nplt.figure(figsize=(15,8))\nsns.set_style(\"whitegrid\")\nsns.set_context(\"paper\")\nplt.plot(thresholds, p[:-1], \"g-\")\nplt.plot(thresholds, r[:-1], \"r-\")\nplt.axvline(x=0.404, color='b', linestyle='--') # additing axline\nplt.xticks(np.arange(0,1,step=0.02),size=8)\nplt.yticks(size=12)\n\nplt.show()","5c89e85c":"# plotting the Train dataset again with 0.42 as cutoff\ny_train_pred_final['final_predicted_2'] = y_train_pred_final['Converted_Prob'].map( lambda x: 1 if x > 0.404 else 0)\ny_train_pred_final.head()","f86903c7":"#Plotting the Confusion Matrix\ndraw_cm( y_train_pred_final['Converted_IND'], y_train_pred_final['final_predicted_2'], \"GnBu\")","1da1fc50":"#Data based on cutoff received from Precision-Recall Trade off\nconf_matrix = confusion_matrix(y_train_pred_final['Converted_IND'], y_train_pred_final['final_predicted_2'] )\nlg_metrics(conf_matrix)","f01859f4":"# Classification Record : Precision, Recall and F1 Score\nprint( metrics.classification_report( y_train_pred_final['Converted_IND'], y_train_pred_final['final_predicted_2'] ) )","7626c30c":"# Scaling the test dataset :\nX_test[['Total Time Spent on Website','Page Views Per Visit','TotalVisits']] = scaler.transform(X_test[['Total Time Spent on Website','Page Views Per Visit','TotalVisits']])\nX_test.head()","168d2d51":"# Selecting only the columns used in final model of Train Dataset\nX_test = X_test[features]\nX_test.head()","1f0b04a6":"#adding contant value\nX_test_sm = sm.add_constant(X_test)\nX_test_sm.columns","1329461c":"# Predicting the final test model \ny_test_pred = log_model9.predict(X_test_sm)","480ace90":"#checking the top 10 rows\ny_test_pred[:10]","4adeb1df":"# Converting y_pred to a dataframe which is an array\ny_test_pred = pd.DataFrame(y_test_pred)\ny_test_pred.head()","d395e64d":"# Converting y_test to dataframe\ny_test_df = pd.DataFrame(y_test)\ny_test_df.head()","ac0c6a93":"# Putting CustID to index\ny_test_df['Prospect_IND'] = y_test_df.index\n\n# Removing index for both dataframes to append them side by side \ny_test_pred.reset_index(drop=True, inplace=True)\ny_test_df.reset_index(drop=True, inplace=True)\n\n# Appending y_test_df and y_pred_1\ny_pred_final = pd.concat([y_test_df, y_test_pred],axis=1)\ny_pred_final.head()","96d1dc21":"# Renaming the column \ny_pred_final= y_pred_final.rename(columns={ 0 : 'Converted_Prob'})\ny_pred_final= y_pred_final.rename(columns={ 'Converted' : 'Converted_IND'})\n\n# Rearranging the columns\ny_pred_final = y_pred_final.reindex(['Prospect_IND','Converted_IND','Converted_Prob'], axis=1)\ny_pred_final.head()","ca1860f4":"y_pred_final['final_predicted'] = y_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.335 else 0)\ny_pred_final.head()","639a9c7b":"#Plotting the Confusion Matrix\ndraw_cm( y_pred_final['Converted_IND'], y_pred_final['final_predicted'], \"GnBu\")","1d85df65":"conf_matrix = confusion_matrix(y_pred_final['Converted_IND'], y_pred_final['final_predicted'])\n\nlg_metrics(conf_matrix)","2e6d2cb6":"# Invoking the functio to draw ROC curve\n\ndraw_roc( y_pred_final['Converted_IND'], y_pred_final['Converted_Prob'])","7ab62ad5":"# Classification Record : Precision, Recall and F1 Score\nprint( metrics.classification_report( y_pred_final['Converted_IND'], y_pred_final['final_predicted'] ) )","9cdbae4a":"# Let's assign Lead_score for the leads in Test Data Set : \ny_pred_final['lead_score']=(y_pred_final['Converted_Prob']*100).astype(\"int64\")\ny_pred_final.sort_values(by='Converted_Prob',ascending=False)","3a09a47a":"# checking the data from top \ny_pred_final.head(5)","b218c082":"# checking the data from bottom \ny_pred_final.tail(5)","f834d30a":"# Let's look into final model features and coefficients \npd.options.display.float_format = '{:.2f}'.format\nfinal_parameters = log_model9.params[1:]\nfinal_parameters","c760c766":"#Getting a relative coeffient value for all the features wrt the feature with the highest coefficient\n\ntop_predictors = final_parameters\ntop_predictors = 100.0 * (top_predictors \/ top_predictors.max())\ntop_predictors","0a46d332":"# Plotting the predictors based on their relative importance\ntop_predictors_sort = np.argsort(top_predictors,kind='quicksort',order='list of str')\nfig = plt.figure(figsize = (12,8))\npos = np.arange(top_predictors_sort.shape[0]) + .5\n\nfig1 = plt.figure(figsize=(10,6))\nax = fig1.add_subplot(1, 1, 1)\nax.barh(pos, top_predictors[top_predictors_sort])\nax.set_yticks(pos)\nax.set_yticklabels(np.array(X_train[features].columns)[top_predictors_sort], fontsize=13)\nax.set_xlabel('Top Predictors Relative Importance', fontsize=15)\nplt.show()","a8490459":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          In the lead conversion ration, 38.5% has converted to leads where as 61.5% did not convert to a lead. So it seems like a balanced dataset. \n    <\/span>    \n<\/div>","85b03044":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Inferences: <\/b><br>\n        Model 9 with cut off value at 0.335 is providing an Accuracy of 80.55%, Sensitivity of 80.29%. Sensitivity in this case indicates how many leads the model identify correctly out of all potential leads which are converting. More than 80% is what the CEO has requested in this case study. \n        F1 Score and precision value in the model has higher number for 0's than 1's. This indicates that the model predicts leads which will not convert ( i.e. filtering leads who will not convert) than the leads which will convert. This indirectly improved the model's performance to identify correct leads to be contacted\n    <\/span>   \n<\/div>","5f790b43":"<a id=\"predprob\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n           8.2 Predicted Probability Calculation\n            <\/span>   \n        <\/font>    \n<\/h2>","f305f0a3":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n           7.2.6 Model 6\n            <\/span>   \n        <\/font>    \n<\/h3>","efb2fdc4":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n         Both the Prospect ID and Lead number are unique columns and hence we wont need for prediction\n    <\/span>    \n<\/div>","653482db":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n        We will remove <b> 'Specialization_Hospitality Management '<\/b> due to lowest WoE value and it also has negative coefficient value. \n    <\/span>   \n<\/div>","91034949":"<p>\n    <span style='font-family:Georgia'>\n          Checking the new null value and column details for Categorical columns\n    <\/span> \n<\/p>","fd0f602b":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Inferences: <\/b><br>\n        The sensitivity value on Test data is 80.09% vs 80.29% in Train data. The accuracy values is 80.48%. It shows that model is performing well in test data set also and is not over-trained. \n    <\/span>   \n<\/div>","86636f56":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          <ul>\n              <li>The source of most leads was Google, and 40% of the leads converted, followed by Direct Traffic,Organic search and Olark chat where around 35%, 38% and 30% converted respectively.<\/li>\n              <li>A lead that came from a reference has over 90% conversion from the total of 534. <\/li>\n              <li> Welingak Website has almost 100% lead conversion rate. This option should be explored more to increase lead conversion<\/li>\n        <\/ul>\n        <b> To increase lead count, initiatives should be taken so already exitsing members increase their referrals. <\/b>\n    <\/span>    \n<\/div>","e88eb06e":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n        We will remove <b>'Occupation_Housewife'<\/b> feature due to high P-value of 0.999\n    <\/span>   \n<\/div>","ead883a2":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","df6a88ef":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n           7.2.7 Model 7\n            <\/span>   \n        <\/font>    \n<\/h3>","a53ebccd":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","c437a654":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          Though outliers in TotalVisits and Page Views Per Visit shows valid values, this will misclassify the outcomes and consequently create problems when making inferences with the wrong model. Logistic Regression is heavily influenced by outliers. So lets cap the TotalVisits and Page Views Per Visit to their 95 th percentile due to following reasons: \n    <\/span>\n    <br>\n    <span style='font-family:Georgia'>\n        <ul>\n            <li> Data set is fairly high number <\/li>\n            <li> 95th percentile and 99th percentile of these columns are very close and hence impact of capping to 95th or 99th percentile will be the same <\/li>\n        <\/ul>\n    <\/span>\n<\/div>","8e02899c":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","c8fcc47c":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            4.4.2  Page Views Per Visit\n            <\/span>   \n        <\/font>    \n<\/h3>","07faa7f9":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Inferences: <\/b><br>\n        ROC Curve aread is 0.88, which indicates that the model is good. \n    <\/span>   \n<\/div>","06e472d6":"<a id=\"tradeoff\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n           8.5 Precision - Recall Trade off\n            <\/span>   \n        <\/font>    \n<\/h2>","ce40dc0d":"![](https:\/\/slidebazaar.com\/wp-content\/uploads\/2020\/07\/thank-you-slide-presentation-t6.jpg)","9c79e5c5":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n          For Manual Feature Reduction, the following methods will be followed in order to reduce the features until we reach reasonable amount of feature count and maintain Sensitivity of the modeal =>80%\n    <\/span>\n    <p><\/p>\n    <span style='font-family:Georgia'>\n        <ol>\n            <li> High P-Value <\/li>\n            <li> High VIF <\/li>\n            <li> High negative GLM coeeficient <\/li>\n            <li> Low Information Value (IV) generated based on WoE (Weight of Evidence)<\/li>\n        <\/ol>\n    <\/span>    \n<\/div>","25f95715":"<a id=\"inspect\"><\/a>\n<h2 name='libraries'>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            3.2 Inspect Dataframe\n            <\/span>   \n        <\/font>    \n<\/h2>","835bf642":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          As we are unsure what could be the Last activity, we will replace it with the most frequent activity \"Email Opened\".\n    <\/span>    \n<\/div>","61abdddb":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          <ul>\n              <li>Most of the leads have not mentioned a specialization and around 28% of those converted<\/li>\n              <li>Leads with Finance management and Marketing Management - Over 45% Converted <\/li>\n        <\/ul>\n    <\/span>    \n<\/div>","97300692":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          Now that we have capped the outliers, let's proceed to data preparation for model building.  \n    <\/span>\n<\/div>","5db0ba54":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Inferences: <\/b><br>\n        ROC value of 0.88 shows the model is performing well in Test dataset.  \n    <\/span>   \n<\/div>","606138e4":"<a id=\"datadict\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            1.3 Data Dictionary :\n            <\/span>   \n        <\/font>    \n<\/h2>\n<div>\n    <span style='font-family:Georgia'>\n        <table style=\"border:1px solid black;border-collapse:collapse;\">\n            <tr><th style=\"border:1px solid black;\">Variables<\/th><th style=\"border:1px solid black;\">Description<\/th><\/tr>\n            <tr><td style=\"border:1px solid black;\">Prospect ID<\/td><td style=\"border:1px solid black;\">A unique ID with which the customer is identified<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Lead Number<\/td><td style=\"border:1px solid black;\">A lead number assigned to each lead procured.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Lead Origin<\/td><td style=\"border:1px solid black;\" style=\"border:1px solid black;\">The origin identifier with which the customer was identified to be a lead. Includes API, Landing Page Submission, etc.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Lead Source<\/td><td style=\"border:1px solid black;\">The source of the lead. Includes Google, Organic Search, Olark Chat, etc.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Do Not Email<\/td><td style=\"border:1px solid black;\">An indicator variable selected by the customer wherein they select whether of not they want to be emailed about the course or not.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Do Not Call<\/td><td style=\"border:1px solid black;\">An indicator variable selected by the customer wherein they select whether of not they want to be called about the course or not.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Converted<\/td><td style=\"border:1px solid black;\">The target variable. Indicates whether a lead has been successfully converted or not.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">TotalVisits<\/td><td style=\"border:1px solid black;\">The total number of visits made by the customer on the website.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Total Time Spent on Website<\/td><td style=\"border:1px solid black;\">The total time spent by the customer on the website.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Page Views Per Visit<\/td><td style=\"border:1px solid black;\">Average number of pages on the website viewed during the visits.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Last Activity<\/td><td style=\"border:1px solid black;\">Last activity performed by the customer. Includes Email Opened, Olark Chat Conversation, etc.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Country<\/td><td style=\"border:1px solid black;\">The country of the customer.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Specialization<\/td><td style=\"border:1px solid black;\">The industry domain in which the customer worked before. Includes the level 'Select Specialization' which means the customer had not selected this option while filling the form.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">How did you hear about X Education<\/td><td style=\"border:1px solid black;\">The source from which the customer heard about X Education.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">What is your current occupation<\/td><td style=\"border:1px solid black;\">Indicates whether the customer is a student, umemployed or employed.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">What matters most to you in choosing this course<\/td><td style=\"border:1px solid black;\">An option selected by the customer indicating what is their main motto behind doing this course.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Search<\/td><td rowspan=\"6\">Indicating whether the customer had seen the ad in any of the listed items.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Magazine<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Newspaper Article<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">X Education Forums<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Newspaper<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Digital Advertisement<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Through Recommendations<\/td><td style=\"border:1px solid black;\">Indicates whether the customer came in through recommendations.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Receive More Updates About Our Courses<\/td><td style=\"border:1px solid black;\">Indicates whether the customer chose to receive more updates about the courses.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Tags<\/td><td style=\"border:1px solid black;\">Tags assigned to customers indicating the current status of the lead.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Lead Quality<\/td><td style=\"border:1px solid black;\">Indicates the quality of lead based on the data and intuition the the employee who has been assigned to the lead.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Update me on Supply Chain Content<\/td><td style=\"border:1px solid black;\">Indicates whether the customer wants updates on the Supply Chain Content.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Get updates on DM Content<\/td><td style=\"border:1px solid black;\">Indicates whether the customer wants updates on the DM Content.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Lead Profile<\/td><td style=\"border:1px solid black;\">A lead level assigned to each customer based on their profile.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">City<\/td><td style=\"border:1px solid black;\">The city of the customer.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Asymmetrique Activity Index<\/td><td rowspan=\"4\">An index and score assigned to each customer based on their activity and their profile<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Asymmetrique Profile Index<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Asymmetrique Activity Score<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Asymmetrique Profile Score<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">I agree to pay the amount through cheque<\/td><td style=\"border:1px solid black;\">Indicates whether the customer has agreed to pay the amount through cheque or not.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">a free copy of Mastering The Interview<\/td><td style=\"border:1px solid black;\">Indicates whether the customer wants a free copy of 'Mastering the Interview' or not.<\/td><\/tr>\n            <tr><td style=\"border:1px solid black;\">Last Notable Activity<\/td><td style=\"border:1px solid black;\">The last notable acitivity performed by the student.<\/td><\/tr>\n        <\/table>\n    <\/span>\n<\/div>","ccabe551":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n           7.2.5 Model 5\n            <\/span>   \n        <\/font>    \n<\/h3>","58712b7b":"<a id=\"setup\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            2.3 Setting up Jupyter View\n            <\/span>   \n        <\/font>    \n<\/h2>","d1cedeb4":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n          Clearly Prospect ID & Lead Number are two variables that are just indicative of the ID number of the Contacted People & can be dropped. We will also remove the columns which has more than 45% Null Values. <br>\n        Also, some of the variables like Lead Quality, Tags, Asymmetrique scores and profile etc. are created by the sales team once they contact the potential lead. These variables will not be available for the model building as these features would not be available before the lead is being contacted.<br>\n        Last Notable Activity is an intermediate column which is an update while the sales team representative is in touch with the lead.<br>\n        <b>Thus, we can drop these columns too.<\/b> \n    <\/span>    \n<\/div>","b133a743":"<a id=\"summary\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n                10.2 Model Summary\n            <\/span>   \n        <\/font>    \n<\/h2>","96c49ede":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","29d10a33":"<div>\n    <span style='font-family:Georgia'>\n        <h3><b>Odds ratios<\/b><\/h3>\n        <p>Sometimes, marketing team may need to get odds rather than probabilities as the concept of odds ratios is of sociological rather than logical importance.<br><br>\n            To understand odds ratios we first need a definition of odds, which is the ratio of the probabilities of two mutually exclusive outcomes. Consider our prediction of the probability of lead conversion of 10% from the earlier section on probabilities. As the probability of lead conversion is 10%, the probability of non-conversion is 100% - 10% = 90%, and thus the odds are 10% versus 90%. Dividing both sides by 90% gives us 0.11 versus 1, which we can just write as 0.11. So, the odds of 0.11 is just a different way of saying a probability of lead conversion of 10%.<br><br>\n            Similarly We can interpret from the model that, holding all categorical and numerical variables at a fixed value, the odds of a lead being converted for a Working Professional (Working Professional = 1)over the odds of lead being converted for non-working professionals (Working Professional = 0) is exp(.2.84) = 17.11 <br><br>\n            This means log(p\/(1-p)) = 17.11 when all other variables are at fixed value<br><br>\n            We can use this odds ratios method to identify the potential lead conversions on comparing the individuals profile.\n        <\/p>\n    <\/span>\n<\/div>","725204b4":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          Country data is heavily skewed as 95% of the data is mapped as India. Similar to City, Country data is not required for Model building as X-Education is online platform. We will drop the country columns too. \n    <\/span>    \n<\/div>","0c2ac518":"<a id=\"goal\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            1.2 Business Goal :\n            <\/span>   \n        <\/font>    \n<\/h2>\n<p style=\"text-indent: 25px;\">\n    <span style='font-family:Georgia'>\n        X Education want to develop a model to select the most promising leads, i.e. the leads that are most likely to convert into paying customers. The company requires you to build a model wherein you need to assign a lead score to each of the leads such that the customers with higher lead score have a higher conversion chance and the customers with lower lead score have a lower conversion chance. The CEO, in particular, has given a ballpark of the target lead conversion rate to be around 80%. <br><br>\n        Goal of the Case Study is :\n    <\/span>\n<\/p>\n<span style='font-family:Georgia'>\n    <ol>\n        <li>Build a logistic regression model to assign a lead score between 0 and 100 to each of the leads which can be used by the company to target potential leads. A higher score would mean that the lead is hot, i.e. is most likely to convert whereas a lower score would mean that the lead is cold and will mostly not get converted.<\/li>\n        <li>There are some more problems presented by the company which your model should be able to adjust to if the company's requirement changes in the future so you will need to handle these as well. These problems are provided in a separate doc file. Please fill it based on the logistic regression model you got in the first step. Also, make sure you include this in your final PPT where you'll make recommendations.<\/li>\n    <\/ol>\n<\/span>","e1bdfafe":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","85c6403f":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","f383c072":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Inferences: <\/b><br>\n        We have a stable model as Model No. 9 where all P-values of features are significant and VIF values are below 3, signifiying that there is negligible multi-colinearity. Most of the feature coefficients are positive. We will select Model 8 as our final model and evaluate the model on Train and Test Data Set. \n    <\/span>   \n<\/div>","390a1bff":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","db5b9c83":"<a id=\"eda\"><\/a>\n<h1>   \n      <font color = blue >\n            <span style='font-family:Georgia'>\n            5. Exploratory Data Analysis\n            <\/span>   \n        <\/font>    \n<\/h1>","564a5133":"<span style='font-family:Georgia'>\n    <font color = green>\n        <h3> Confusion Matrix : <\/h3>\n    <\/font>\n    <table>\n    <thead>\n    <tr><th><\/th><th>Predicted Negative(0)<\/th><th>Predicted Positive(1)<\/th><\/tr>\n    <\/thead>\n    <tbody>\n        <tr><td><b>Actual Negative(0)<\/b><\/td><td><font color = blue>True Negative (TN)<\/font> <\/td><td><font color = blue>False Postive (FP)<\/font><\/td><\/tr>\n        <tr><td><b>Actual Positive(1)<\/b><\/td><td><font color = blue>False Negative (FN)<\/font><\/td><td><font color = blue>True Positive (TP)<\/font><\/td><\/tr>\n    <\/tbody>\n<\/table>\n<\/span>\n<hr>\n<div>\n    <span style=\"font-size:18\" >\n        <span style ='font-family:Georgia'>\n            <font color = blue >\n                <math> Accuracy = <\/math>\n                <span style=\"display: inline-block;vertical-align: middle;\">\n                    <div style=\"text-align: center;border-bottom: 1px solid black;\">(TP + TN)<\/div>\n                    <div style=\"text-align: center;\">(TP + TN + FP + FN)<\/div>\n                <\/span>\n            <\/font>\n        <\/span>\n    <\/span>\n<\/div>\n<hr>\n<div>\n    <span style=\"font-size:18\" >\n        <span style ='font-family:Georgia'>\n            <font color = blue >\n                <math> Sensitivity = <\/math>\n                <span style=\"display: inline-block;vertical-align: middle;\">\n                    <div style=\"text-align: center;border-bottom: 1px solid black;\">TP<\/div>\n                    <div style=\"text-align: center;\">(TP + FN)<\/div>\n                <\/span>\n            <\/font>\n        <\/span>\n    <\/span>\n<\/div>\n<hr>\n<div>\n    <span style=\"font-size:18\" >\n        <span style ='font-family:Georgia'>\n            <font color = blue >\n                <math> Specificity = <\/math>\n                <span style=\"display: inline-block;vertical-align: middle;\">\n                    <div style=\"text-align: center;border-bottom: 1px solid black;\">TN<\/div>\n                    <div style=\"text-align: center;\">(TN + FP)<\/div>\n                <\/span>\n            <\/font>\n        <\/span>\n    <\/span>\n<\/div>\n<hr>\n<div>\n    <span style=\"font-size:18\" >\n        <span style ='font-family:Georgia'>\n            <font color = blue >\n                <math> Precision = <\/math>\n                <span style=\"display: inline-block;vertical-align: middle;\">\n                    <div style=\"text-align: center;border-bottom: 1px solid black;\">TP<\/div>\n                    <div style=\"text-align: center;\">(TP + FP)<\/div>\n                <\/span>\n            <\/font>\n        <\/span>\n    <\/span>\n<\/div>    \n<hr>\n<div>\n    <span style=\"font-size:18\" >\n        <span style ='font-family:Georgia'>\n            <font color = blue >\n                <math> Recall = <\/math>\n                <span style=\"display: inline-block;vertical-align: middle;\">\n                    <div style=\"text-align: center;border-bottom: 1px solid black;\">TP<\/div>\n                    <div style=\"text-align: center;\">(TP + FN)<\/div>\n                <\/span>\n            <\/font>\n        <\/span>\n    <\/span>\n<\/div>\n<hr>\n<div>\n    <span style=\"font-size:18\" >\n        <span style ='font-family:Georgia'>\n            <font color = blue >\n                <math> F Measure (F1) = 2 * <\/math>\n                <span style=\"display: inline-block;vertical-align: middle;\">\n                    <div style=\"text-align: center;border-bottom: 1px solid black;\"> Precision * Recall <\/div>\n                    <div style=\"text-align: center;\">(Precision + Recall)<\/div>\n                <\/span>\n            <\/font>\n        <\/span>\n    <\/span>\n<\/div>\n<hr>\n<div>\n    <span style=\"font-size:18\" >\n        <span style ='font-family:Georgia'>\n            <font color = blue >\n                <ul>\n                    <li><b>TPR (True Positive Rate)<\/b> = TP\/(TP + FN)<\/li>\n                    <li><b>TNR (True Negative Rate)<\/b> = TN\/(TN + FP)<\/li>\n                    <li><b>FPR (False Positive Rate)<\/b> = FP\/(TN + FP)<\/li>\n                    <li><b>FNR (False Negative Rate)<\/b> = FN\/(TP + FN)<\/li>\n                <\/ul>\n            <\/font>\n        <\/span>\n    <\/span>\n<\/div>    \n    ","cca42371":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n        We will remove <b>'Lead Source_Facebook'<\/b> feature due to high P-Value of 0.204\n    <\/span>   \n<\/div>","daf22e9e":"<a id=\"dummy\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n           6.3 Dummy Variables\n            <\/span>   \n        <\/font>    \n<\/h2>","cf9c8c1a":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          We have successfully imputed all Categorical Columns. Now let's look into numerical columns. \n    <\/span>    \n<\/div>","bfb0ad99":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n          We will combine smaller lead sources as 'Other Sources'. \n    <\/span>    \n<\/div>","c14c9461":"<a id=\"python\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            2.1 Import Python Libraries:\n            <\/span>   \n        <\/font>    \n<\/h2>","1eb327d3":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            4.3.6 Last Activity\n            <\/span>   \n        <\/font>    \n<\/h3>","2e8c8a68":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          There are 17 columns with null values. 7 columns have more than 45% unknowns which we should drop as imputing these columns will introduce bias. No rows whcih have more than 50% null values.  \n    <\/span>    \n<\/div>","aebcf02e":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n          We will combine smaller Last Activity values as 'Other Activity'. \n    <\/span>    \n<\/div>","eb886997":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            4.4.1  Total Visits\n            <\/span>   \n        <\/font>    \n<\/h3>","85bf5c7c":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n         The data types of the columns are float, integer and object type. We can see there are some null values in the column. Let's inspect the null values first \n    <\/span>    \n<\/div>","279a847e":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Inferences: <\/b><br>\n        Based on Precision- Recall Trade off curve, the cutoff point seems to 0.404. We will use this threshold value for Test Data Evaluation\n    <\/span>   \n<\/div>","bf4d658f":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          Now that we have our Train and Test data bases ready and Train database standardized, let's try building some model using Logistic Regression.\n    <\/span>\n<\/div>","9a2267ba":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n        We will remove <b>'Specialization_Rural and Agribusiness'<\/b> feature due to high P-Value of 0.174. All the parameters have VIF values below 3, which indicates that features are not Multi-colinear in nature. \n    <\/span>   \n<\/div>","f3de3603":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            5.3.5 Specialization\n            <\/span>   \n        <\/font>    \n<\/h3>","abc32644":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          It may be possible that the lead has no specialization or may be a student and has no work experience yet , thus he\/she has not entered any value. We will create a new category called 'Others' to replace the null values. \n    <\/span>    \n<\/div>","63578200":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          The number of rows getting capped are quite high. This is also the reason that we are capping the data instead of deleting it.  \n    <\/span>\n<\/div>","ebe0e40a":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","57a1325b":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","626f4c0a":"<a id=\"fconvert\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n           6.2 Convert Binary Categories\n            <\/span>   \n        <\/font>    \n<\/h2>","e2f0edac":"<a id=\"modeleval1\"><\/a>\n<h1>   \n      <font color = blue >\n            <span style='font-family:Georgia'>\n            8. Model Evalution : Train Dataset\n            <\/span>   \n        <\/font>    \n<\/h1>","90105c2c":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","55647c7a":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","0873f8ca":"<a id=\"outlier\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n           6.1 Outliers Treatment\n            <\/span>   \n        <\/font>    \n<\/h2>","2673d294":"<a id=\"warning\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            2.2 Suppress Warnings:\n            <\/span>   \n        <\/font>    \n<\/h2>","494c3739":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          As we see there are some outliers in the data, we will impute with median and not mean value. \n    <\/span>    \n<\/div>","1a7927d6":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          Data is not normally distributed.  \n    <\/span>    \n<\/div>","5fe52097":"<div>\n    <span style ='font-family:Georgia'>\n        An ROC curve demonstrates several things: <br><br>\n    <\/span>\n    <span style ='font-family:Georgia'>\n        <ul>\n            <li>It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity)<\/li>\n            <li>The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.<\/li>\n            <li>The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.<\/li>\n        <\/ul>       \n    <\/span>\n<\/div> ","30ebd757":"<a id=\"import\"><\/a>\n<h1>   \n      <font color = blue >\n            <span style='font-family:Georgia'>\n            3. Reading & Understanding the data\n            <\/span>   \n        <\/font>    \n<\/h1>","e3e39a85":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","117d634f":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          <ul>\n              <li>Some of the columns have only 1 category.Example - Magazine,I agree to pay the amount through cheque etc. These columns will not add any value to the model and can be deleted.<\/li>\n              <li>Some of the columns have one of the value as \"Select\" These should be considered as null values. Data Value needs to be updated for these columns<\/li>\n        <\/ul>\n    <\/span>    \n<\/div>","1a4570dd":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","2bf55f2e":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n        Now we will use Cutoff point of 0.335 from Sentivity - Specificity - Accuracy cut-off points\n    <\/span>   \n<\/div>","5c31c0c2":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          <ul>\n              <li>Most of the lead have their Email opened as their last activity<\/li>\n              <li> After combining smaller Last Activity types as Other Activity, the lead conversion is very high (~70%) <\/li>\n              <li>Conversion rate for leads with last activity as SMS Sent is almost 60%<\/li>\n        <\/ul>\n    <\/span>    \n<\/div>","d804ac23":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          As the data is skewed, we can delete the column.\n    <\/span>    \n<\/div>","38134b74":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","7a257584":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          Most of the features in the dataset are categorical. Let us begin our analysis by performing segmented univariate analysis on each categorical feature. We will view bar plots that will show the total count of converted and non-converted leads in every category. \n    <\/span>    \n<\/div>","1df3d8b0":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          <ul>\n              <li> Majority of the people are ok with receiving email (~92%) <\/li>\n              <li> People who are ok with email has conversion rate of 40%<\/li>\n              <li> People who have opted out of receive email has lower rate of conversion (only 15%) <\/li>\n        <\/ul>\n    <\/span>    \n<\/div>","1a7b9afd":"<div>\n    <span style='font-family:Georgia'>\n        <h3><b>Predicting Probabilities<\/b><\/h3>\n        <p>We can make predictions from the estimates. We do this by computing the effects for all of the predictors for a particular scenario, adding them up, and applying a logistic transformation.<br><br>\n            Consider the scenario of a lead who is a working professional and who was identified from Welingak website and who had chatted on Olark Chat and who spent no time on the website and wanted to be contacted by E-mail.<br><br>\n            Then we can calculate his conversion probability as 3.41 * 0 + 2.82 * 1 + 2.34 * 0 + 2.01 * 1 + 1.86 * 0 + 1.32 * 0 + 1.09 * 0 + 0.97 * 0 + 0.93 * 0 + 0.76 * 0 - 0.26 * 0 -0.77 * 1 - 1.24 * 0 -1.86<br>\n            which is 2.82 + 2.01 - 0.77 - 1.86 = 2.2 which is log(p\/(1-p))<br><br>\n            The logistic transformation is: <br>\n            <font color = blue >\n                Probability = 1 \/ (1 + exp(-x)) = 1 \/(1 + exp(- -2.2)) = 1 \/(1 + exp(2.2)) = 0.143 = 14.3%\n            <\/font>\n        <\/p>\n    <\/span>\n<\/div>","a36cc21b":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            3.3.2 Row wise Null Value calculation\n            <\/span>   \n        <\/font>    \n<\/h3>","0ac8cb04":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Inferences: <\/b><br>\n        By using the Precision - Recall trade off chart cut-off points, the model output has changed the following way : \n        <ul>\n            <li> True Positive number has decreased. <\/li>\n            <li> True Negative number has increase <\/li>\n            <li> False Negative number has increase <\/li>\n            <li> False Positive number has decreased <\/li>\n        <\/ul>\n    <\/span>\n    <br><br>\n    <span style='font-family:Georgia'>\n        For our purpose CEO wants to identify the people correctly who will convert to leads. Thus, we cannot use Precision-Recall trade-off method as it reduced True Positive. We have to increase Sensitivity \/ Recall value to increase True Positives. Thus we will use 0.335 as cutoff point.\n    <\/span>\n<\/div>","7499ebc9":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            4.3.1 City\n            <\/span>   \n        <\/font>    \n<\/h3>","a74709e0":"<a id=\"params\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n                10.1 Model Features \/ Predictors\n            <\/span>   \n        <\/font>    \n<\/h2>","94e0f1f6":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            4.3.5 Country\n            <\/span>   \n        <\/font>    \n<\/h3>","b62aa489":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            4.3.7 Lead Source\n            <\/span>   \n        <\/font>    \n<\/h3>","871768cb":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","83136ef5":"<a id=\"datacleaning\"><\/a>\n<h1>   \n      <font color = blue >\n            <span style='font-family:Georgia'>\n            4. Data Cleaning\n            <\/span>   \n        <\/font>    \n<\/h1>","97faa58b":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n           7.2.3 Model 3\n            <\/span>   \n        <\/font>    \n<\/h3>","b30cd87c":"Feature Scaling: We standardized the numeric attributes so they have a common mean of zero, if they were measured on different scales","ea033632":"<div>\n    <span style='font-family:Georgia'>\n        <h3><b>Interpretation Logistic regression model with multiple predictor variables<\/b><\/h3>\n        <p>In general, we can have multiple predictor variables in a logistic regression model as below:<\/p>\n        <p>\n            <font color = blue >\n                logit(p) = log(p\/(1-p))= \u03b2<sub>0<\/sub> + \u03b2<sub>1<\/sub>* X<sub>1<\/sub> + \u2026 + \u03b2<sub>n<\/sub> * X<sub>n<\/sub>\n            <\/font>\n        <\/p>\n        <p>Applying such a model to our example dataset, each estimated coefficient is the expected change in the log odds of being a  potential lead for a unit increase in the corresponding predictor variable holding the other predictor variables constant at a certain value.  Each exponentiated coefficient is the ratio of two odds, or the change in odds in the multiplicative scale for a unit increase in the corresponding predictor variable holding other variables at a certain value.<\/p>\n    <\/span>\n<\/div>\n    ","1e0b8370":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          TotalVisits and Page Views per Visit has some outliers which needs to be treated. \n    <\/span>    \n<\/div>","9eec299b":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n          Search, Newspaper, Newspaper Article, Digital Advertisement, ,X Education Forums, Recommendation data are very skewed and can be deleted as they will not add any value to the model. <br>\n        Distributing Free-Copy of Mastering Interview doesn't seem to add much value as the coenversion rate is almost same. We will drop all these columns.\n    <\/span>    \n<\/div>","01f1de66":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          85.5% values are \"Unemployed\". If we impute the data as \"Unemployed\" then data will become more skewed. Thus, we will impute the value as \"Unknown\".\n    <\/span>    \n<\/div>","41e4fc34":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n           7.2.4 Model 4\n            <\/span>   \n        <\/font>    \n<\/h3>","9c7de1c9":"<a id=\"graphfunc\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            5.2 Graph Functions\n            <\/span>   \n        <\/font>    \n<\/h2>","16b90bc0":"<a id=\"uninumvar\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            5.4 Univariate Analysis - Numerical\n            <\/span>   \n        <\/font>    \n<\/h2>","19b22e86":"<a id=\"conclusion\"><\/a>\n<h1>   \n      <font color = blue >\n            <span style='font-family:Georgia'>\n            10. Conclusion:\n            <\/span>   \n        <\/font>    \n<\/h1>","537a6a92":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            5.3.6 Occupation\n            <\/span>   \n        <\/font>    \n<\/h3>","3bbe9da7":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n           7.2.9 Model 9\n            <\/span>   \n        <\/font>    \n<\/h3>","13cfcfda":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n        We will remove <b> 'Last Activity_Other Activity'<\/b> because this is a parameter created by combining multiple smaller categories of Last Activity and % of these data in whole database is less than 0.03%\n    <\/span>   \n<\/div>","5303ebe4":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          As we see there are some outliers in the data, we will impute with median and not mean value. \n    <\/span>    \n<\/div>","8abe1688":"<a id=\"RFE\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n           7.1 RFE for Feature Reduction\n            <\/span>   \n        <\/font>    \n<\/h2>","40fc8236":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            3.3.1 Column wise Null Value calculation\n            <\/span>   \n        <\/font>    \n<\/h3>","51964b29":"**<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            5.3.4 Last Activity\n            <\/span>   \n        <\/font>    \n<\/h3>","547d8ac5":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Inferences: <\/b><br>\n        We can use the lead_score column to identify which potential leads to prioritize first. The higher the score, the higher chances are there for the lead to convert. If there are limited sales representatives, then score cut-off should be higher to ensure a higher conversion probability people are contacted further to turn them into a potential customer. It is the same as increasing the precision value of the model by adjusting the cut-off point to a higher value. In case there are more resources available in the sales team (i.e., interns, etc. ), then the score cut-off can be lowered. As there are more human resources, the company can afford a higher rate of False positives as it will increase the customer outreach and, in turn, increase the potential customer who will take the online courses.  \n    <\/span>   \n<\/div>","15cadd11":"<span style='font-family:Georgia'>\n    The following features have two categories only. We are going to evaluate the skewness of the data and decide whether to exclude them from model building. \n<\/span>    ","9b68e56f":"<a id=\"dataprep\"><\/a>\n<h1>   \n      <font color = blue >\n            <span style='font-family:Georgia'>\n            6. Data Preparation\n            <\/span>   \n        <\/font>    \n<\/h1>","82ff5dd6":"<a id=\"catnull\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            4.3 Categorical Columns Null Value Treatment\n            <\/span>   \n        <\/font>    \n<\/h2>","12010fdb":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","2c9feeb5":"<div>\n    <span style='font-family:Georgia'>\n        We can make predictions from the estimates. We do this by computing the effects for all of the predictors for a particular scenario, adding them up, and applying a logistic transformation. <br>\n        Consider the scenario of a lead who is a working professional and who was identified from Welingak website and who had chatted on Olark Chat and who spent no time on the website and wanted to be contacted by E-mail.<br><br>\n        Then we can calculate his conversion probability as  3.42 * 0 + 2.84 * 1 + 1.99 * 1 + 1.78 * 0 + 1.25 * 0 + 1.09 * 0 + 0.98 * 0 + 0.84 * 0 + 0.66 * 0 - 0.25 * 0 -0.87 * 1 - 1.26 * 0 -1.77 = 2.84 + 1.99 - 0.87 - 1.77 = 2.19 which is log(p\/(1-p)).<br>\n        <hr>\n        The logistic transformation is: <br>\n        Probability = 1 \/ (1 + exp(-x)) = 1 \/(1 + exp(- -2.19)) = 1 \/(1 + exp(2.2)) = 0.10 = 10%\n    <\/span>\n<\/div>","daaf78b9":"<a id=\"scaling\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n           6.5 Feature Scaling\n            <\/span>   \n        <\/font>    \n<\/h2>","5ac800b2":"<a id=\"univar\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            5.3 Univariate Analysis - Categorical\n            <\/span>   \n        <\/font>    \n<\/h2>","b8486f1b":"<a id=\"toc\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">\n    <span style='font-family:Georgia'>\n    Table of Content\n    <\/span>\n<\/h1>\n<span style='font-family:Georgia'>\n    <ul>\n        <li><a href='#intro'>1. Introduction<\/a><\/li>\n        <ul>\n            <li><a href='#background'>1.1 Problem Statement<\/a><\/li>\n            <li><a href='#goal'>1.2 Business Goal<\/a><\/li>\n            <li><a href='#datadict'>1.3 Data Dictionary<\/a><\/li>\n        <\/ul>\n        <li><a href='#libraries'>2. Python Libraries<\/a><\/li>\n        <ul>\n            <li><a href='#python'>2.1 Import Python Libraries<\/a><\/li>\n            <li><a href='#warning'>2.2 Suppress Warnings<\/a><\/li>\n            <li><a href='#setup'>2.3 Setting up Jupyter View<\/a><\/li>   \n        <\/ul>\n        <li><a href='#import'>3. Reading & Understanding the data<\/a><\/li>\n        <ul>\n            <li><a href='#input'>3.1 Importing the input file<\/a><\/li>\n            <li><a href='#inspect'>3.2 Inspecting the dataframe<\/a><\/li>\n            <li><a href='#nullcal'>3.3 Null Value Calculation<\/a><\/li>\n            <li><a href='#duplicate'>3.4 Duplicate Analysis #duplicate<\/a><\/li>\n        <\/ul>      \n        <li><a href='#datacleaning'>4. Data Cleaning<\/a><\/li>\n        <ul>\n            <li><a href='#delcol'>4.1 Delete High Null Columns<\/a><\/li>\n            <li><a href='#colseg'>4.2 Segregating Categorical & Numerical Value<\/a><\/li>\n            <li><a href='#catnull'>4.3 Categorical Columns Null Value Treatment<\/a><\/li>\n            <li><a href='#numnull'>4.4 Numerical Columns Null Value Treatment<\/a><\/li>\n        <\/ul>\n        <li><a href='#eda'>5. Exploratoray Data Analysis<\/a><\/li>\n        <ul>\n            <li><a href='#imbalance'>5.1 Data Imbalance<\/a><\/li>\n            <li><a href='#graphfunc'>5.2 Graph Functions<\/a><\/li>\n            <li><a href='#univar'>5.3 Univariate Analysis<\/a><\/li>\n            <li><a href='#uninumvar'>5.4 Univariate Analysis<\/a><\/li>\n            <li><a href='#bivar'>5.5 Bivariate Analysis<\/a><\/li>\n        <\/ul>\n        <li><a href='#dataprep'>6. Data Preparation<\/a><\/li>\n        <ul>\n            <li><a href='#outlier'>6.1 Outliers Treatment<\/a><\/li>\n            <li><a href='#fconvert'>6.2 Convert Binary Categories<\/a><\/li>\n            <li><a href='#dummy'>6.3 Dummy Variables<\/a><\/li>\n            <li><a href='#split'>6.4 Train - Test Split<\/a><\/li>\n            <li><a href='#scaling'>6.5 Feature Scaling<\/a><\/li>\n        <\/ul>\n        <li><a href='#modelbuild'>7. Model Building<\/a><\/li>\n        <ul>\n            <li><a href='#RFE'>7.1 RFE for Feature Reduction<\/a><\/li>\n            <li><a href='#manual'>7.2 Manual Feature Reduction<\/a><\/li>\n        <\/ul>\n        <li><a href='#modeleval1'>8. Model Evalution : Train Dataset<\/a><\/li>\n        <ul>\n            <li><a href='#matrixdef'>8.1 Evaluation Matrix Definitions<\/a><\/li>\n            <li><a href='#predprob'>8.2 Predicted Probability Calculation<\/a><\/li>\n            <li><a href='#confusion'>8.3 Confusion Matrix<\/a><\/li>\n            <li><a href='#ROC'>8.4 ROC Curve <\/a><\/li>\n            <li><a href='#tradeoff'>8.5 Precision - Recall Trade off<\/a><\/li>\n        <\/ul>\n        <li><a href='#modeleval2'>9. Model Evalution : Test Dataset<\/a><\/li>\n        <li><a href='#conclusion'>10. Conclusion<\/a><\/li>\n        <ul>\n            <li><a href='#params'>10.1 Model Features \/ Predictors<\/a><\/li>\n\t\t\t<li><a href='#summary'>10.2 Model Summary<\/a><\/li>\n        <\/ul>\n    <\/ul>\n<\/span>","ca4f6d4f":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n         We have suceessfully deleted 10 columns where the columns had high null values or they are information which will not be available for models when it ran as they are calculated \/ selected by sales personnel when they contact potential leads.\n    <\/span>    \n<\/div>","b17c5e11":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","7d1cd40d":"<a id=\"intro\"><\/a>\n<h1>   \n      <font color = blue >\n            <span style='font-family:Georgia'>\n            1. Introduction:\n            <\/span>   \n        <\/font>    \n<\/h1>","f3763f7f":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","a8c80854":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Inferences: <\/b><br>\n        From the above graph, 0.335 seems to be ideal cut-off points\n    <\/span>   \n<\/div>","a7d9c0ae":"<a id=\"libraries\"><\/a>\n<h1>   \n      <font color = blue >\n            <span style='font-family:Georgia'>\n            2. Python Libraries:\n            <\/span>   \n        <\/font>    \n<\/h1>","a75ddeb2":"<h1 style=\"text-align:center\">   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n                Lead Scoring : A Logistric Regression Case Study \n            <\/span>   \n        <\/font>    \n<\/h1>\n<h3 style=\"text-align:right\">   \n      <font color = gray >\n            <span style='font-family:Georgia'>\n                By : Amrita Chatterjee, Padma A , Suchitra Bhat\n            <\/span>   \n        <\/font>    \n<\/h3>\n<hr style=\"width:100%;height:5px;border-width:0;color:gray;background-color:gray\">\n<center><img src=\"https:\/\/c1.sfdcstatic.com\/content\/dam\/web\/en_us\/www\/images\/marketing-cloud\/hub\/basic-science-behind-lead-scoring\/the-basic-science-behind-lead-scoring-header.jpg\"><\/center>","753a9ada":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          There are 51 columns in Heatmap which makes it difficult to interpret. Let's review top 5 positively and negatively correlated features.\n    <\/span>    \n<\/div>","a0a292a1":"<p>\n    <span style='font-family:Georgia'>\n          Now we can proceed with addressing individual columns for null values\n    <\/span> \n<\/p>","a9d31322":"<div>\n    <span style ='font-family:Georgia'>\n        Next we will look into Precision- Recall trade off to see if balancing these values provides better output. <br>\n        Precision means out of all leads which are predicted at 1, how many have truly converted. <br>\n        Recall means out of all leads that have converted, how many of them were correctly identifies as 1. This is the same value as sensitivity.<br><br>\n        Precision-Recall trade-off point is used to decide the cut-off point especially when there is huge imbalance in data. In our case the data distribution is 62% vs 38%. So imbalance of data is not a big factor. \n    <\/span>\n<\/div> ","6eb3e89a":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            5.3.1 Lead Origin\n            <\/span>   \n        <\/font>    \n<\/h3>","a0926795":"<a id=\"background\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            1.1 Problem Statement :\n            <\/span>   \n        <\/font>    \n<\/h2>\n<p style=\"text-indent: 25px;\">\n    <span style='font-family:Georgia'>\n        An education company named X Education sells online courses to industry professionals. On any given day, many professionals who are interested in the courses land on their website and browse for courses. \n        <\/span>\n<\/p>\n<p style=\"text-indent: 25px;\">\n    <span style='font-family:Georgia'>\n        The company markets its courses on several websites and search engines like Google. Once these people land on the website, they might browse the courses or fill up a form for the course or watch some videos. When these people fill up a form providing their email address or phone number, they are classified to be a lead. Moreover, the company also gets leads through past referrals. Once these leads are acquired, employees from the sales team start making calls, writing emails, etc. Through this process, some of the leads get converted while most do not. The typical lead conversion rate at X education is around 30%.  \n        <\/span>\n<\/p>\n<p style=\"text-indent: 25px;\">\n    <span style='font-family:Georgia'>\n        Now, although X Education gets a lot of leads, its lead conversion rate is very poor. For example, if, say, they acquire 100 leads in a day, only about 30 of them are converted. To make this process more efficient, the company wishes to identify the most potential leads, also known as \u2018Hot Leads\u2019. If they successfully identify this set of leads, the lead conversion rate should go up as the sales team will now be focusing more on communicating with the potential leads rather than making calls to everyone.\n        <\/span>\n<\/p>","60a27306":"<a id=\"ROC\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n           8.4 ROC Curve\n            <\/span>   \n        <\/font>    \n<\/h2>","dcb01727":"<a id=\"delcol\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            4.1 Delete High Null Columns\n            <\/span>   \n        <\/font>    \n<\/h2>","afb88d9a":"<a id=\"bivar\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            5.5 Bivariate Analysis\n            <\/span>   \n        <\/font>    \n<\/h2>","a7b32d41":"<a id=\"manual\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n           7.2 Manual Feature Reduction\n            <\/span>   \n        <\/font>    \n<\/h2>","b3d2bdfe":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          As there is almost 40% unknown values, we cannot impute with mode as it is make the whole data skewed. Also, X-Education is online teaching platform. The city information will not be much useful as potential students can available any courses online despite their city. We will drop the column from analysis.  \n    <\/span>    \n<\/div>","ca8b7961":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","f27f8913":"<div class=\"alert alert-block alert-success\">\n    <span style='font-family:Times New Roman'>\n        <h3><b>The magnitude and sign of the coefficients loaded in the logit function:<\/b><\/h3>\n        <p style=\"font-size:18px\">\n        logit(p) = log(p\/(1-p)) =  (3.42 * Lead Origin_Lead Add Form) + (2.84 * Occupation_Working Professional) + (1.99 * Lead Source_Welingak Website) + (1.78 * Last Activity_SMS Sent) + (1.25 * Last Activity_Unsubscribed) + (1.09 * Total Time Spent on Website) + (0.98 * Lead Source_Olark Chat) + (0.84 * Last Activity_Unreachable) + (0.66 * Last Activity_Email Opened) - (0.25 * Lead Origin_Landing Page Submission) -(0.87 * Last Activity_Olark Chat Conversation) - (1.26 * Do Not Email) -1.77\n        <\/p>\n    <\/span>\n<\/div>","8531b75f":"<a id=\"split\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n           6.4 Train - Test Split\n            <\/span>   \n        <\/font>    \n<\/h2>","0e3d33a5":"<a id=\"modeleval2\"><\/a>\n<h1>   \n      <font color = blue >\n            <span style='font-family:Georgia'>\n            9. Model Evalution : Test Dataset\n            <\/span>   \n        <\/font>    \n<\/h1>","4afc8083":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","ed7b3906":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n           7.2.2 Model 2\n            <\/span>   \n        <\/font>    \n<\/h3>","6c8a541d":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          <ul>\n              <li>Most Leads originated from submissions on the landing page and around 38% of those are converted followed by API, where around 30% are converted.<\/li>\n              <li>Even though Lead Origins from Quick Add Form are 100% Converted, there was just 1 lead from that category. Leads from the Lead Add Form are the next highest conversions in this category at around 90% of 718 leads.<\/li>\n              <li> Lead Import are very less in count and conversion rate is also the lowest \n        <\/ul>\n        <b> To improve overall lead conversion rate, we need to focus more on improving lead converion of API and Landing Page Submission origin and generate more leads from Lead Add Form.<\/b>\n    <\/span>    \n<\/div>","12fcda7b":"<a id=\"matrixdef\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n           8.1 Evaluation Matrix Definitions\n            <\/span>   \n        <\/font>    \n<\/h2>","fadf9ea6":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n        We will remove <b>'Specialization_Retail Management'<\/b> feature due to high P-value of 0.209\n    <\/span>   \n<\/div>","9814c9ef":"<a id=\"imbalance\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            5.1 Data Imbalance\n            <\/span>   \n        <\/font>    \n<\/h2>","792a820c":"<a id=\"nullcal\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            3.3 Null Value Calculation\n            <\/span>   \n        <\/font>    \n<\/h2>","47e3aa8a":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n        We will remove <b>'Occupation_Unknown'<\/b> feature due high negative coefficient. Additionally, Occupation_Unknown is imputed data by treating the null values. It means that the this feature indicates that some leads have not filled this Occupation column. It is difficult to interpret and take action on this feature in future. Thus we will remove this feature first. \n    <\/span>   \n<\/div>","14cd6a81":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","d578dd0c":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n        All the features have significant P Values and VIF under 5. So next, we will look into WoE and Coefficient value to remove parameters. For coefficient, we will concentrate on negative coefficeints to remove, as we want more positive feature which can indicate identifying right candidate for lead conversion or how to improve further leads. \n    <\/span>   \n<\/div>","ffafe2fa":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n         There are quite a few columns which has 'Select' as one of the category. This is most probably because the person has not filled that field. We will replace this field with NaN \n    <\/span>    \n<\/div>","3880c2ca":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","6ae02c76":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","00ffd21c":"<a id=\"colseg\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            4.2 Segregating Categorical & Numerical Values\n            <\/span>   \n        <\/font>    \n<\/h2>","272f2aa0":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            4.3.3 What matters most to you in choosing a course\n            <\/span>   \n        <\/font>    \n<\/h3>","9873a5f4":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","e1a21245":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","ba899ae0":"<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","797692ea":"<a id=\"input\"><\/a>\n<h2 name='libraries'>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            3.1 Importing the Input file\n            <\/span>   \n        <\/font>    \n<\/h2>","119b8ba6":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            5.3.7 Search, Newspaper, Newspaper Article, Digital Advertisement, ,X Education Forums, Free Copy\n            <\/span>   \n        <\/font>    \n<\/h3>","62d80dc0":"<a id=\"confusion\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n           8.3 Confusion Matrix\n            <\/span>   \n        <\/font>    \n<\/h2>","eb9393ce":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n           7.2.8 Model 8\n            <\/span>   \n        <\/font>    \n<\/h3>","60b5d4c2":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          As Google seems to be most used Lead Source, we will replace null values with Google. There is a category 'google' which is same as 'Google' We will replace the values\n    <\/span>    \n<\/div>","fa105c78":"<a id=\"duplicate\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            3.4 Duplicate Analysis\n            <\/span>   \n        <\/font>    \n<\/h2>","2042af8a":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            5.3.2 Lead Source\n            <\/span>   \n        <\/font>    \n<\/h3>","7b3f5245":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            4.3.2 Specialization\n            <\/span>   \n        <\/font>    \n<\/h3>","f557e5b7":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight: <\/b><br>\n          <ul>\n              <li>Though Housewives are less in numbers, they have 100% conversion rate <\/li>\n              <li> Working professionals, Businessmen and Other category have high conversion rate <\/li>\n              <li> Though Unemployed people have been contacted in the highest number, the conversion rate is low (~40%)<\/li>\n        <\/ul>\n        <b> We cannot combine smalled value categories as their conversion rate is very different. Combing them may provide wrong predictions. <\/b>\n    <\/span>    \n<\/div>","a0cd0124":"<a id=\"modelbuild\"><\/a>\n<h1>   \n      <font color = blue >\n            <span style='font-family:Georgia'>\n            7. Model Building\n            <\/span>   \n        <\/font>    \n<\/h1>","335d15e9":"<a id=\"numnull\"><\/a>\n<h2>   \n      <font color = purple >\n            <span style='font-family:Georgia'>\n            4.4 Numerical Columns Null Value Treatment\n            <\/span>   \n        <\/font>    \n<\/h2>","82496054":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            5.3.3 Do not Email\n            <\/span>   \n        <\/font>    \n<\/h3>","2811a38c":"<div class=\"alert alert-block alert-warning\">\n    <span style='font-family:Georgia'>\n        <b>Strategy: <\/b><br>\n        We will remove <b> 'Specialization_Others'<\/b> due to difficulty of interpretability of the data as againg this \"Other\" category is combination of various specialization which has been comined in smaller chunks. \n    <\/span>   \n<\/div>","9c9529ac":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n            4.3.4 What is your current occupation\n            <\/span>   \n        <\/font>    \n<\/h3>","010bb1c8":"<h3>   \n      <font color = darkgreen >\n            <span style='font-family:Georgia'>\n           7.2.1 Model 1\n            <\/span>   \n        <\/font>    \n<\/h3>"}}