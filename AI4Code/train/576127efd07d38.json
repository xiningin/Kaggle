{"cell_type":{"2ad00d48":"code","61e4d8b7":"code","2a2123ac":"code","a4dabd83":"code","e461b413":"code","61f49a64":"code","1c368ca5":"code","b881e0b9":"code","509c2068":"code","da453f08":"code","84990e2a":"code","38949295":"code","6c1babb9":"code","9d92fec9":"code","75105cca":"code","92f6d433":"code","d3d4281b":"code","b0d386bf":"code","8f7cd522":"code","5f282392":"code","2501fbc2":"code","de0911b8":"code","e3113b18":"code","1fd59ce1":"code","66575574":"code","c842ab70":"code","6c7d5ace":"code","1d00cec6":"code","fd35ec93":"code","2c2676e8":"code","6606588e":"code","6615b2cd":"code","57612c57":"code","e49697ba":"code","2a5cd1c6":"code","549d4dbb":"markdown"},"source":{"2ad00d48":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","61e4d8b7":"data=pd.read_csv('..\/input\/vgsales.csv')\ndata.head(10)","2a2123ac":"data.columns","a4dabd83":"data.info()","e461b413":"data.corr()","61f49a64":"data.plot(kind='scatter',x='EU_Sales',y='Global_Sales',alpha=0.5,color='blue')\nplt.xlabel(\"NA Sales-\") ## label of x\nplt.ylabel(\"Global Sales-\")  ## label of y                            \nplt.show()           ## EU Sales-Global Sales Correlation\n","1c368ca5":"data.NA_Sales.plot(color='g',label='NA Sales',linewidth=2,alpha=0.5,grid=True,linestyle=\":\")\ndata.Global_Sales.plot(color='r',label='Global Sales',linewidth=2,alpha=0.5,grid=True,linestyle=\"-.\")\nplt.legend()\nplt.xlabel(\"X\") \nplt.ylabel(\"Y\")       ## What should I do ? Bad data istatistices. learn the purpose :) \nplt.show()","b881e0b9":"data[data['Publisher']==\"Nintendo\"].head(10)","509c2068":"print(\"Global -- \",data.Global_Sales.mean(),\"NA --\",data.NA_Sales.mean())\n## Na Sales is almost half of Global sales\n","da453f08":"filter1=data.Year>2016\ndata[filter1]\n## Sales very low after 2016 year","84990e2a":"filter1=data.Global_Sales>30             ## very few data in global sales greater than 30\ndata[filter1]","38949295":"data.Year.plot(kind='hist',bins=40,grid=True,label='Years')\nplt.legend()                                        ## Distribution of years\nplt.show()","6c1babb9":"for index,value in data[[\"Global_Sales\"]][0:2].iterrows():\n    print(index,\":\",value)","9d92fec9":"f,ax = plt.subplots(figsize=(15, 15))\nsns.heatmap(data.corr(), annot=True, linewidths=.4, fmt= '.1f',ax=ax)\nplt.show()","75105cca":"data['H_or_S']=[\"High Sales\" if i>20  else \"Low Sales\" for i in data.Global_Sales]\ndata[\"Old_or_New\"]=[\"New\" if i>2012 else \"Old\" for i in data.Year] ## List comprehension\ndata.head(10) ","92f6d433":"data_new=data.head()\nmelted=pd.melt(frame=data_new,id_vars='Name',value_vars=[\"NA_Sales\",\"Global_Sales\"])\nmelted           ##First 10 sample group by Name with NA and Global Sales","d3d4281b":"dataconcat=pd.concat([data.head(),data.tail()],axis=0,ignore_index=True) \ndataconcat                ## vertical concat(axis=0)\n","b0d386bf":"dataconcat=pd.concat([data.NA_Sales.head(),data.EU_Sales.head()],axis=1)\ndataconcat        ### Na Sales and Eu Sales horizontal concat (axis=1)","8f7cd522":"data.dtypes","5f282392":"data[\"Publisher\"]=data[\"Publisher\"].astype('category') \ndata.dtypes   ## convert object to category data type\n","2501fbc2":"data.info()","de0911b8":"data[\"Year\"].value_counts(dropna=False) ## Numbers of years (dropna=False) NaN is showed (271)","e3113b18":"data2=data.copy()\ndata2[\"Publisher\"].dropna(inplace=True) ## Dropped NaN values of Publisher","1fd59ce1":"assert data2[\"Publisher\"].notnull().all() ## No error so we dropped nan values of publisher ","66575574":"data3=data.loc[:,[\"NA_Sales\",\"Global_Sales\",\"EU_Sales\"]] ## Na,Global,Eu Sales in subplots\ndata3.plot(subplots=True,grid=True,figsize=(10,10))\nplt.show()","c842ab70":"data.Year.fillna('1970',inplace=True) # if Year is NaN. Fill 1970\ntime_list=list(data.Year)        \nfor i in range(0,data.Year.count()):    # Year  converted to int \n    time_list[i]=int(time_list[i])      # because float values can not be converted to datetimes \n    time_list[i]=str(time_list[i])\n\nnewdate=pd.to_datetime(time_list)     ## timelist converted to datetimes\ndata[\"Date\"]=newdate\ndata2=data.head()\ndata2=data2.set_index(\"Date\")\ndata2","6c7d5ace":"data2.resample(\"A\").mean().interpolate('linear') # Average over the  years with interpolate linear","1d00cec6":"data=data.set_index(\"Rank\") ## index rank was made\ndata.head()","fd35ec93":"data[[\"NA_Sales\",\"Global_Sales\"]].head()","2c2676e8":"print(type(data[[\"Publisher\"]]))  ## dataframe\nprint(type(data[\"Publisher\"]))    ## series","6606588e":"## Names of games with Global Sales greater than 30\ndata.Name[data.Global_Sales>30] ","6615b2cd":"print(data.shape)           # tuple,column\nprint(data.index.name)      # name of data index \ndata2=data.copy()\ndata2.index=range(100,16698,1) ## index start 100 end 16698\ndata2.head()","57612c57":"data3=pd.read_csv('..\/input\/vgsales.csv')\ndata3=data3.set_index([\"Publisher\",\"Genre\"]) #Publisher and Genre indexing\ndata3.head(100)","e49697ba":" # averages Global Sales and Na Sales of genres\ndata3.groupby(\"Genre\")[\"Global_Sales\",\"NA_Sales\"].mean()","2a5cd1c6":"# max Global Sales of genres\ndata.groupby(\"Genre\").Global_Sales.max() ","549d4dbb":"My first basic kernel is completed.Waiting for your suggestions and comments :)"}}