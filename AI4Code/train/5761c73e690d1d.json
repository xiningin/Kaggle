{"cell_type":{"e66887c0":"code","d6cfbe70":"code","aa99c2fb":"code","9b340d74":"code","42afcaad":"code","f113bb06":"code","01730f7c":"code","cc4dc4c5":"code","c4d90bbd":"code","f3aa64b9":"code","4503447b":"code","b6168d24":"code","00adb8de":"code","795151f7":"code","5925f47b":"code","01ec7803":"code","c84b9b0d":"code","7c01e191":"code","b4055a5d":"code","62f5fd3b":"code","8242e506":"code","857f6f4d":"code","332939b2":"code","8276452c":"code","c1df0bd0":"code","05bed529":"code","59bdac6f":"code","c83ecc3e":"code","c2f3d089":"code","69c915c9":"code","6f8b9969":"code","4ed0ec74":"code","2bc5140f":"code","0de5eb2e":"code","d0b24410":"code","446d131c":"code","ed37a125":"code","574a7ae2":"code","8eb083ae":"code","fcecaeb1":"code","ac0f42aa":"code","174e48fb":"code","7188fa52":"code","0f19acfe":"code","56eb6e00":"code","717ea53f":"code","e38dc66c":"code","a69c5275":"code","175b9dfb":"code","18ac1b84":"code","c0da9920":"code","0e137e51":"code","4e316f07":"code","16c5b9ac":"code","f2c7231e":"code","ce3c4059":"code","8cf295af":"code","d2b7f1ca":"code","6bc88433":"code","568e8779":"code","ddbaf753":"code","0e70c6f0":"code","0457b61d":"code","21997b2a":"code","df0f7ddb":"code","bb1bc6a2":"code","37cfe886":"code","1e83154a":"code","64a16bf0":"code","a57ae4b0":"code","ce4adf27":"code","716e9feb":"code","21340e8e":"code","9997f686":"code","8c386f64":"code","8b50edbb":"code","8bab391e":"code","176e32c4":"code","a4074fbc":"code","de82a7b4":"code","761a6d08":"code","f2e3bdfa":"code","366b67ef":"code","4c7eddac":"code","44ddc087":"code","8e9dea3a":"code","ee04596a":"code","25f843ac":"code","b11ed270":"code","640037e6":"code","6fe91778":"code","3409b598":"code","f1c03d3e":"code","6e392689":"code","2aad889f":"code","de2ba2f0":"code","b34c489c":"code","60019f78":"code","f74ca851":"code","9f5c0c02":"code","451202cc":"code","8d618db4":"code","c319df90":"code","3837df1d":"code","3b32d283":"code","ef04fd39":"code","8e40d2cf":"code","bd4824db":"code","333a4389":"code","a05ead74":"code","4b71b115":"code","86d160b4":"code","66d0d1a3":"code","b9d70368":"code","58303d4a":"code","222c5b7e":"code","f84a5cf0":"code","8760d975":"code","6debba62":"code","c5a4959a":"code","db5eb614":"code","3877e784":"code","8c2808f8":"code","dd0982c0":"code","43e75f9a":"code","1feb4388":"code","1fe4a137":"code","aa4dc710":"code","a907eada":"code","0698a2ef":"code","5faef338":"code","14b65e6d":"code","3c230748":"code","ae7deb4f":"code","8bc08f71":"code","e715cb21":"code","1d6593a3":"code","9fa2a73b":"code","205464af":"code","2263082d":"code","3f294a2f":"code","75d689db":"code","028e0968":"code","a2e2c077":"code","5501546a":"code","018b6b7d":"markdown","743fe73f":"markdown","4ff20c20":"markdown","209af32f":"markdown","5cf63040":"markdown","78d3a55d":"markdown","5afa51d7":"markdown","2561e92e":"markdown","69ed7dca":"markdown","9a883c0a":"markdown","db51c208":"markdown","b48ba7c3":"markdown","09679852":"markdown","59e0f826":"markdown","1543547f":"markdown","cbff5188":"markdown","c890033c":"markdown","bca320f7":"markdown","476b8ac1":"markdown","053ee7cb":"markdown","792dbf6d":"markdown","303dc110":"markdown","f2c2c0f0":"markdown","8127a6b5":"markdown","1f0791bd":"markdown","7d3c3e4f":"markdown","69d07d2e":"markdown","b4f41efe":"markdown","8fbec65b":"markdown","a0f2821a":"markdown","f9b52048":"markdown","14ee7f6c":"markdown","edb4cc27":"markdown","10af0e82":"markdown","c1f2ed80":"markdown","9621fbf7":"markdown","29812f3b":"markdown","10850aed":"markdown","a22d53d5":"markdown","22f545de":"markdown","b5a158ac":"markdown","f848b9c3":"markdown","1024528e":"markdown","cebed456":"markdown","062358db":"markdown","5d6820ef":"markdown","0c7ebaf9":"markdown","d1a2dd60":"markdown","0fa86a73":"markdown","d2502973":"markdown","46111455":"markdown","67435008":"markdown","e416f0c9":"markdown","99aab1c3":"markdown","8ce1501e":"markdown","d1367962":"markdown","ec34cd3e":"markdown","94a53287":"markdown","5d2e3690":"markdown","38572663":"markdown"},"source":{"e66887c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datatable as dt\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport shap\nfrom sklearn import manifold\n\nimport warnings\nimport pickle\nimport gc\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d6cfbe70":"from hyperopt import Trials, STATUS_OK, hp, tpe, fmin\nimport catboost\nfrom catboost import *\nimport lightgbm as lgb\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\nfrom sklearn.metrics import confusion_matrix, log_loss, precision_recall_curve, auc, roc_curve","aa99c2fb":"experiment_name = 'janestreet_v1_new_wc'","9b340d74":"sns.set_style(\"darkgrid\")\n\nplt.rcParams['figure.figsize'] = (15, 5)\nplt.rcParams['figure.titlesize'] = 20\nplt.rcParams['axes.titlesize'] = 20\nplt.rcParams['font.size'] = 20","42afcaad":"pickle_dir = '\/kaggle\/working\/pickle_files\/'\nif os.path.isdir(pickle_dir) == False:\n    os.mkdir(pickle_dir)","f113bb06":"# Memory saving function credit to https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype.name\n\n        if col_type not in ['object', 'category', 'datetime64[ns, UTC]']:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            c_sum = df[col].sum()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_sum < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int16).min and c_sum < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_sum < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_sum < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_sum < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_sum < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return df\n","01730f7c":"df_train = (\n    dt.fread('..\/input\/jane-street-market-prediction\/train.csv')\n      .to_pandas()\n      .query('weight > 0')\n      .pipe(reduce_mem_usage)\n)\n\nfeature_names = df_train.columns[df_train.columns.str.contains('feature')]","cc4dc4c5":"# Dataset shape\nprint(\"Train Dataset Shape: \" + str(df_train.shape))","c4d90bbd":"# Dataset columns\ndf_train.columns","f3aa64b9":"# Dataset fields and types\ndf_train.info()","4503447b":"df_train.dtypes[df_train.dtypes=='int32']","b6168d24":"# Dataset head\ndf_train.head()","00adb8de":"# Checking for duplicates\ndf_train.duplicated().sum() # 0 - no duplicated rows","795151f7":"df_train.describe(include=[np.number]).transpose()","5925f47b":"id_field = 'ts_id'\ndate_field = 'date'","01ec7803":"# Description of the no. of potential transactions per day (mean, std, quantiles etc.), by date\ndf_train.groupby(date_field).count()[id_field].describe()","c84b9b0d":"dft = df_train.set_index(df_train[date_field]).sort_index()\ncount = pd.DataFrame(dft.groupby(dft.index)[id_field].count())\ncount.columns = ['Number of daily entries']\n\nax = count.plot(title = str(len(df_train[id_field].unique())-1) + ' total observations')\nax.set_xlabel(\"Date\")\nax.set_ylabel(\"Number of entries\")\nax.legend(loc=\"upper right\")\n\nax.axvline(x=85, linestyle='--', alpha=0.3, c='red', lw=1)\nax.axvspan(0, 85 , color=sns.xkcd_rgb['grey'], alpha=0.1)\n\ndel dft\ndel count\n\nplt.show()","7c01e191":"dft = df_train.set_index(df_train[date_field]).sort_index()\ncount = pd.DataFrame(dft.groupby(dft.index)[id_field].count())\n\nfig, ax = plt.subplots(figsize=(15, 5))\nplt.plot(6.5 * 60 * 60 \/ count)\nax.set_xlabel (\"Day\")\nax.set_ylabel (\"Av. time between trades (s)\", fontsize=18)\nax.set_title (\"Average time between trades for each day (assuming a 6.5h daily trading interval)\")\nax.axvline(x=85, linestyle='--', alpha=0.3, c='red', lw=1)\nax.axvspan(0, 85 , color=sns.xkcd_rgb['grey'], alpha=0.1)\nax.set_xlim(xmin=0)\nax.set_xlim(xmax=500)\nax.set_ylim(ymin=0)\n# ax.set_ylim(ymax=12)\nplt.show()","b4055a5d":"df_seas = df_train.groupby(date_field)[[id_field]].count()\ndf_seas.hist(bins=100)\n\nplt.xlabel(\"No. of days\")\nplt.ylabel(\"No. of daily entries\")\nplt.title(\"Histogram of the no. of daily entries\")\nplt.show()","62f5fd3b":"# Considering a 'rolling' 30-days window and displaying the evolution over time of the no. of observations covered every day\ndft = df_train.set_index(df_train[date_field]).sort_index()\ncount = pd.DataFrame(dft.groupby(dft.index)[id_field].count().rolling(30, min_periods=1).mean())\ncount.columns = ['30-day rolling mean of number of observations per day']\n\nax = count.plot(title = str(len(df_train[id_field].unique())-1) + ' total observations')\nax.set_xlabel(\"Date\")\nax.set_ylabel(\"Number of entries\")\nax.legend(loc=\"upper right\", prop={'size': 18})\nax.axvline(x=85, linestyle='--', alpha=0.3, c='red', lw=1)\nax.axvspan(0, 85 , color=sns.xkcd_rgb['grey'], alpha=0.1)\n\nplt.show()","8242e506":"del dft\ndel count\ndel df_seas\ngc.collect()","857f6f4d":"# Entries no. autocorrelation\n\nfrom statsmodels.graphics.tsaplots import plot_acf\nplot_acf(df_train.groupby(date_field)[id_field].count().values, lags=21) # monthly\nplot_acf(df_train.groupby(date_field)[id_field].count().values, lags=252) # yearly\nplt.show()","332939b2":"# Checking the missing entries per field\n\nmissings_df = df_train.isna().sum() * 100 \/ len(df_train)\nax = missings_df.plot(kind='bar', title='% of data points with missing values')\nax.set_xlabel(\"Data fields\")\nax.set_ylabel('% of missing entries')\n\nax.set_xticklabels([], rotation=30, horizontalalignment='right')\n\ndisplay()","8276452c":"del missings_df\ngc.collect()","c1df0bd0":"plt.rcParams['figure.figsize'] = (15, 5)\n\nax = sns.distplot(df_train['resp'], \n             bins=3000, \n             kde_kws={\"clip\":(-0.05,0.05)}, \n             hist_kws={\"range\":(-0.05,0.05)},\n             color='darkcyan', \n             kde=False);\nvalues = np.array([rec.get_height() for rec in ax.patches])\nnorm = plt.Normalize(values.min(), values.max())\ncolors = plt.cm.jet(norm(values))\nfor rec, col in zip(ax.patches, colors):\n    rec.set_color(col)\nplt.xlabel(\"Histogram of the 'resp' values\")\nplt.title(\"'resp' Distribution\")\nplt.show()\n\nprint(\"Minimum value: \" + str(np.round(df_train['resp'].min(), 2)))\nprint(\"Maximum value: \" + str(np.round(df_train['resp'].max(), 2)))\n\n\nplt.rcParams['figure.figsize'] = (15, 5)\nfig, ax = plt.subplots(2, 2, sharex=True, sharey=True)\n\nvar_list = ['resp_1', 'resp_2', 'resp_3', 'resp_4']\nax_list = [ax[0,0], ax[0,1], ax[1,0], ax[1,1]]\n\nfor var, ax in zip(var_list, ax_list):\n    ax = sns.distplot(df_train[var],\n                 label = \"'\" + str(var) + \"' distn\",\n                 ax = ax,\n                 bins = 3000, \n                 kde_kws = {\"clip\":(-0.05,0.05)}, \n                 hist_kws = {\"range\":(-0.05,0.05)},\n                 color = 'darkcyan', \n                 kde = False);\n    values = np.array([rec.get_height() for rec in ax.patches])\n    norm = plt.Normalize(values.min(), values.max())\n    colors = plt.cm.jet(norm(values))\n    for rec, col in zip(ax.patches, colors):\n        rec.set_color(col)\n\nplt.show()","05bed529":"fig, ax = plt.subplots(figsize=(15, 5))\n\ndf = df_train.copy()\n\nbalance= pd.Series(df['resp']).cumsum()\n\n# Normalizing the longer horizons returns\nresp_1= pd.Series(np.power(df['resp_1'] + 1, 1) - 1).cumsum()\nresp_2= pd.Series(np.power(df['resp_2'] + 1, 1\/2) - 1).cumsum()\nresp_3= pd.Series(np.power(df['resp_3'] + 1, 1\/3) - 1).cumsum()\nresp_4= pd.Series(np.power(df['resp_4'] + 1, 1\/4) - 1).cumsum()\nax.set_xlabel (\"Trade\", fontsize=18)\nax.set_title (\"Cumulative resp and time horizons 1, 2, 3, and 4 (500 days)\")\n\nbalance.plot(lw=3)\nresp_1.plot(lw=3)\nresp_2.plot(lw=3)\nresp_3.plot(lw=3)\nresp_4.plot(lw=3)\nplt.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5));\n\ndel resp_1\ndel resp_2\ndel resp_3\ndel resp_4\n\ndel df\ngc.collect()","59bdac6f":"plt.rcParams['figure.figsize'] = (15, 5)\n\nax = sns.distplot(df_train['weight'], \n             bins=3000, \n             color='darkcyan', \n             kde=False);\n# ax.set(xscale='log')\nax.set(yscale='log')\n\nvalues = np.array([rec.get_height() for rec in ax.patches])\nnorm = plt.Normalize(values.min(), values.max())\ncolors = plt.cm.jet(norm(values))\nfor rec, col in zip(ax.patches, colors):\n    rec.set_color(col)\nplt.xlabel(\"Histogram of the 'weight' values\")\nplt.title(\"'weight' Distribution\")\nplt.show()\n\nprint(\"Minimum value: \" + str(np.round(df_train['weight'].min(), 2)))\nprint(\"Maximum value: \" + str(np.round(df_train['weight'].max(), 2)))\n\nprint(\"% of 0.0 values: \" + \n      str(np.round((df_train['weight'].values == 0).sum() \/ len(df_train) * 100, 2)) + \"%\")","c83ecc3e":"dft = df_train.set_index(df_train[date_field]).sort_index()\ncount = pd.DataFrame(dft.groupby(dft.index)[id_field].count())\ncount.columns = ['Number of daily entries']\n\nfrom scipy.stats import pearsonr\n\ndf_corr = df_train.groupby(date_field)[['weight']].sum().merge(count, on='date')\ndf_corr['ratio'] = df_corr['weight'] \/ df_corr['Number of daily entries']\n\ncorr, _ = pearsonr(df_corr['weight'], df_corr['Number of daily entries'])\nprint('Pearsons correlation: %.3f' % corr)\n\nplt.rcParams['figure.figsize'] = (7, 7)\n\nplt.scatter(df_corr['weight'], df_corr['Number of daily entries'])\nplt.xlabel('cummulative weight')\nplt.ylabel('no. of daily entries')\nplt.show()\n\ndel dft\ndel count","c2f3d089":"plt.rcParams['figure.figsize'] = (15, 5)\ndf_corr['ratio'].plot(title=\"Daily ration between cummulative weight and # potential trades\")\nplt.show()","69c915c9":"plt.figure(figsize = (15,5))\nax = sns.distplot(df_train['weight'], \n             bins=1400, \n             kde_kws={\"clip\":(0.001,1.4)}, \n             hist_kws={\"range\":(0.001,1.4)},\n             color='darkcyan', \n             kde=False);\nvalues = np.array([rec.get_height() for rec in ax.patches])\nnorm = plt.Normalize(values.min(), values.max())\ncolors = plt.cm.jet(norm(values))\nfor rec, col in zip(ax.patches, colors):\n    rec.set_color(col)\nplt.xlabel(\"Histogram of non-zero weights (up to 1.4)\")\nplt.show();\n\ndel values\ndel df_corr\ngc.collect()","6f8b9969":"df_train_nonZero = df_train.query('weight > 0').reset_index(drop = True)\nplt.figure(figsize = (10,4))\nax = sns.distplot(np.log(df_train_nonZero['weight']), \n             bins=1000, \n             kde_kws={\"clip\":(-4,5)}, \n             hist_kws={\"range\":(-4,5)},\n             color='darkcyan', \n             kde=False);\nvalues = np.array([rec.get_height() for rec in ax.patches])\nnorm = plt.Normalize(values.min(), values.max())\ncolors = plt.cm.jet(norm(values))\nfor rec, col in zip(ax.patches, colors):\n    rec.set_color(col)\nplt.xlabel(\"Histogram of the logarithm of the non-zero weights\")\nplt.show()\n\ndel df_train_nonZero\ngc.collect()","4ed0ec74":"df_train.groupby(date_field)['weight'].sum().plot(title='Cummulative daily weight')\nplt.show()","2bc5140f":"df = df_train.copy()\ndf = df[df['weight'] > 0]\ndf['wr'] = df['weight'] * df['resp']\n\nplt.rcParams['figure.figsize'] = (15, 5)\n\nax = sns.distplot(df['wr'], \n             bins=2000, \n             kde_kws={\"clip\":(-0.02,0.02)}, \n             hist_kws={\"range\":(-0.02,0.02)},\n             color='darkcyan', \n             kde=False);\n# ax.set(yscale='log')\nvalues = np.array([rec.get_height() for rec in ax.patches])\nnorm = plt.Normalize(values.min(), values.max())\ncolors = plt.cm.jet(norm(values))\nfor rec, col in zip(ax.patches, colors):\n    rec.set_color(col)\nplt.xlabel(\"Histogram of the 'weight' * 'resp' values\")\nplt.title(\"'weight' * 'resp' Distribution\")\nplt.show()\n\nprint(\"Minimum value: \" + str(np.round(df['wr'].min(), 2)))\nprint(\"Maximum value: \" + str(np.round(df['wr'].max(), 2)))\n\ndel df\ngc.collect()","0de5eb2e":"df = df_train.copy()\n\ndf['weight_resp']   = df['weight'] * df['resp']\ndf['weight_resp_1'] = df['weight'] * (np.power(df['resp_1'] + 1, 1) - 1)\ndf['weight_resp_2'] = df['weight'] * (np.power(df['resp_2'] + 1, 1\/2) - 1)\ndf['weight_resp_3'] = df['weight'] * (np.power(df['resp_3'] + 1, 1\/3) - 1)\ndf['weight_resp_4'] = df['weight'] * (np.power(df['resp_4'] + 1, 1\/4) - 1) \n\nfig, ax = plt.subplots(figsize=(15, 5))\n\nresp    = pd.Series(1 + df.groupby('date')['weight_resp'].mean()).cumprod()\nresp_1  = pd.Series(1 + df.groupby('date')['weight_resp_1'].mean()).cumprod()\nresp_2  = pd.Series(1 + df.groupby('date')['weight_resp_2'].mean()).cumprod()\nresp_3  = pd.Series(1 + df.groupby('date')['weight_resp_3'].mean()).cumprod()\nresp_4  = pd.Series(1 + df.groupby('date')['weight_resp_4'].mean()).cumprod()\n\nax.set_xlabel (\"Day\", fontsize=18)\nax.set_title (\"Cumulative daily return for resp and time horizons 1, 2, 3, and 4 (500 days)\", fontsize=18)\nresp.plot(lw=3, label='resp x weight')\nresp_1.plot(lw=3, label='resp_1 x weight')\nresp_2.plot(lw=3, label='resp_2 x weight')\nresp_3.plot(lw=3, label='resp_3 x weight')\nresp_4.plot(lw=3, label='resp_4 x weight')\n# day 85 marker\nax.axvline(x=85, linestyle='--', alpha=0.3, c='red', lw=1)\nax.axvspan(0, 85 , color=sns.xkcd_rgb['grey'], alpha=0.1)\nplt.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5));\n\ndel df\ngc.collect()","d0b24410":"df_train['feature_0'].value_counts()","446d131c":"feature_0_is_plus_one  = df_train.query('feature_0 ==  1').reset_index(drop = True)\nfeature_0_is_minus_one = df_train.query('feature_0 == -1').reset_index(drop = True)\n# the plot\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 4))\nax1.plot((pd.Series(feature_0_is_plus_one['resp']).cumsum()), lw=3, label='resp')\nax1.plot((pd.Series(feature_0_is_plus_one['resp']*feature_0_is_plus_one['weight']).cumsum()), lw=3, label='return')\nax2.plot((pd.Series(feature_0_is_minus_one['resp']).cumsum()), lw=3, label='resp')\nax2.plot((pd.Series(feature_0_is_minus_one['resp']*feature_0_is_minus_one['weight']).cumsum()), lw=3, label='return')\nax1.set_title (\"feature 0 = 1\", fontsize=18)\nax2.set_title (\"feature 0 = -1\", fontsize=18)\nax1.legend(loc=\"lower left\")\nax2.legend(loc=\"upper left\")\n\ndel feature_0_is_plus_one\ndel feature_0_is_minus_one\ngc.collect()","ed37a125":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20,10))\n\nax1.plot((pd.Series(df_train['feature_1']).cumsum()), lw=3, color='red')\nax1.set_title (\"Linear\", fontsize=20);\nax1.axvline(x=514052, linestyle='--', alpha=0.3, c='green', lw=2)\nax1.axvspan(0, 514052 , color=sns.xkcd_rgb['grey'], alpha=0.1)\nax1.set_xlim(xmin=0)\nax1.set_ylabel (\"feature_1\", fontsize=14);\n\nax2.plot((pd.Series(df_train['feature_3']).cumsum()), lw=3, color='green')\nax2.set_title (\"Noisy\", fontsize=20);\nax2.axvline(x=514052, linestyle='--', alpha=0.3, c='red', lw=2)\nax2.axvspan(0, 514052 , color=sns.xkcd_rgb['grey'], alpha=0.1)\nax2.set_xlim(xmin=0)\nax2.set_ylabel (\"feature_3\", fontsize=14);\n\nax3.plot((pd.Series(df_train['feature_55']).cumsum()), lw=3, color='darkorange')\nax3.set_title (\"Hybrid (Tag 21)\", fontsize=20);\nax3.set_xlabel (\"Trade\", fontsize=18)\nax3.axvline(x=514052, linestyle='--', alpha=0.3, c='green', lw=2)\nax3.axvspan(0, 514052 , color=sns.xkcd_rgb['grey'], alpha=0.1)\nax3.set_xlim(xmin=0)\nax3.set_ylabel (\"feature_55\", fontsize=14);\n\nax4.plot((pd.Series(df_train['feature_73']).cumsum()), lw=3, color='blue')\nax4.set_title (\"Negative\", fontsize=20)\nax4.set_xlabel (\"Trade\", fontsize=18)\nax4.set_ylabel (\"feature_73\", fontsize=14);\ngc.collect();","574a7ae2":"day_0 = df_train.loc[df_train['date'] == 0]\nday_1 = df_train.loc[df_train['date'] == 1]\nday_3 = df_train.loc[df_train['date'] == 3]\nthree_days = pd.concat([day_0, day_1, day_3])\nthree_days.plot.scatter(x='ts_id', y='feature_41', s=0.5, figsize=(15,3));\nthree_days.plot.scatter(x='ts_id', y='feature_42', s=0.5, figsize=(15,3));\nthree_days.plot.scatter(x='ts_id', y='feature_43', s=0.5, figsize=(15,3));\n\ndel day_0\ndel day_1\ndel day_3\ngc.collect();","8eb083ae":"featstr = [i for i in df_train.columns if 'feature_' in i]","fcecaeb1":"import matplotlib.gridspec as gridspec\n\nplt.rcParams['font.size'] = 14\nfig = plt.figure(figsize=(20,80))\nfig.suptitle('Features Box plot with 0.1% 99.9% whiskers',fontsize=20, y=.89)\ngrid =  gridspec.GridSpec(33,4,figure=fig,hspace=.5,wspace=.05)\ncounter = 0\nfor i in range(33):\n    for j in range(4):\n        if counter < 130:\n            subf = fig.add_subplot(grid[i, j]);\n            sns.boxplot(x= df_train[featstr[counter]],saturation=.5,color= 'blue', ax= subf,width=.5,whis=(.1,99.9));\n            subf.axvline(df_train[featstr[counter]].mean(),color= 'darkorange', label='Mean', linestyle=':',linewidth=3)\n            subf.set_xlabel('')\n            subf.set_title('{}'.format(featstr[counter]),fontsize=16)\n            counter += 1\n            gc.collect()\nplt.show()","ac0f42aa":"plt.rcParams['font.size'] = 14\nfeatstr = [i for i in df_train.columns if 'feature_' in i]\ndf_train.groupby('date')[featstr].mean().cumsum().plot(layout=(33,4),subplots=True,figsize=(20,82),xlabel='')\nfig = plt.gcf()\nfig.text(0.5, 0.19, 'Date', ha='center', fontsize=12)\nfig.suptitle('Cumulative features means per day', fontsize=20, y=.886);","174e48fb":"%%time\ncorr = df_train.sample(100000).loc[:, [c for c in df_train.columns if 'feature_' in str(c)]] \\\n                 .rank().corr(method='pearson')","7188fa52":"plt.figure(figsize=(20, 16))\n\nsns.heatmap(corr,\n            cmap='RdBu_r', vmin=-1, vmax=1, square=True)\nplt.show()","0f19acfe":"del corr\ngc.collect()","56eb6e00":"%%time \n\nall_features    = [i for i in range(0,130)]\ntrain_features  = [x+7 for x in all_features]\n\ntsne    = manifold.TSNE(n_components=2, perplexity=50, learning_rate=20)\ntsne_2D = tsne.fit_transform(df_train.iloc[:, train_features].fillna(0).sample(10000)) # increase the sample size","717ea53f":"x, y = pd.DataFrame(tsne_2D).values.T\nfig, ax = plt.subplots(figsize=(15, 15))\nax.scatter(x, y, s=3, c=x, cmap=plt.cm.plasma)\nax.set_title('t-SNE plot for all 130 features', fontsize=18)\nplt.show();","e38dc66c":"del tsne\ndel tsne_2D\n\ngc.collect()","a69c5275":"df_train['action'] = np.where(df_train['resp'] > 0,1,0)\ndf_train['action'] = df_train['action'].astype('int')","175b9dfb":"daily_action_sum   = df_train['action'].groupby(df_train['date']).sum()\ndaily_action_count = df_train['action'].groupby(df_train['date']).count()\ndaily_ratio        = daily_action_sum \/ daily_action_count\n\nfig, ax = plt.subplots(figsize=(15, 5))\nplt.plot(daily_ratio)\nax.set_xlabel (\"Day\", fontsize=18)\nax.set_ylabel (\"ratio\", fontsize=18)\nax.set_title (\"Daily ratio of action to inaction\", fontsize=18)\nplt.axhline(0.5, linestyle='--', alpha=0.85, c='r');\nax.set_xlim(xmin=0)\nax.set_xlim(xmax=500)\nplt.show();","18ac1b84":"daily_ratio_mean = daily_ratio.mean()\nprint('The mean daily ratio is %.3f' % daily_ratio_mean)","c0da9920":"daily_ratio_max = daily_ratio.max()\nprint('The maximum daily ratio is %.3f' % daily_ratio_max)","0e137e51":"del daily_action_sum\ndel daily_action_count\ndel daily_ratio\ngc.collect()","4e316f07":"def show_values_on_bars(axs):\n    def _show_on_single_plot(ax):\n        for p in ax.patches:\n            _x = p.get_x() + p.get_width() \/ 2\n            _y = p.get_y() + p.get_height() + 2000\n            value = '{:.0f}'.format(p.get_height())\n            ax.text(_x, _y, value, ha=\"center\", fontsize=12, color='black', fontweight='bold') \n        \n        for p in ax.patches:\n            _x = p.get_x() + p.get_width() \/ 2\n            _y = p.get_y() + p.get_height() \/ 2\n            value = '{:.1f}%'.format(100 * p.get_height()\/len(df_train[['action']].dropna()))\n            ax.text(_x, _y, value, ha=\"center\", fontsize=12, color='white', fontweight='bold') \n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)","16c5b9ac":"plt.rcParams['axes.titlesize'] = 20\nplt.rcParams['font.size'] = 20\nax = df_train['action'].value_counts().sort_index().plot(kind='bar', \n                                            title= \"Data imbalance - action\")\nplt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\nax.set_xticklabels(ax.get_xticklabels(), rotation=0, horizontalalignment='center')\nshow_values_on_bars(ax)\n\nplt.show()","f2c7231e":"df_train.fillna(df_train.mean(axis=0), inplace=True)","ce3c4059":"%%time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.gridspec as gridspec\n\nplt.rcParams['axes.titlesize'] = 12\nplt.rcParams['font.size'] = 16\nfig = plt.figure(figsize=(20,80))\n\nfig.suptitle('KDE plot of Features', fontsize=24, transform=fig.transFigure, y=.89)\ngrid = gridspec.GridSpec(33,4,figure=fig,hspace=.5,wspace=.01)\nprops = dict(boxstyle='round', facecolor='white', alpha=0.5)\ncounter = 0\n\nfeatstr = [i for i in df_train.columns if 'feature_' in i]\n\nfor i in range(33):\n    for j in range(4):\n        if counter < 130:\n            subf = fig.add_subplot(grid[i, j]);\n            sns.distplot(df_train[df_train.action==0][featstr[counter]],bins= 100,label='Negative',\n                         color='darkorange', kde_kws={'linewidth':4},ax=subf)\n            sns.distplot(df_train[df_train.action!=0][featstr[counter]],bins= 100,label='Positive',\n                         color='blue', kde_kws={'alpha':.9,'linewidth':2},hist_kws={'alpha':.3},ax=subf)\n            subf.axvline(np.percentile(df_train[featstr[counter]],99.5),\n                         color= 'darkblue', label='99.5%', linestyle=':',linewidth=2)\n            subf.axvline(np.percentile(df_train[featstr[counter]],.5),\n                         color= 'red', label='0.5%', linestyle=':',linewidth=2)\n            subf.legend().set_visible(False)\n            subf.set_xlabel('')\n            subf.set_title('{}'.format(featstr[counter]),fontsize=16)\n            try:\n                kurt=round(df_train[featstr[counter]].kurt(),2)\n                skew=round(df_train[featstr[counter]].skew(),2)\n                subf.text(.6,.92,'Kurt = {:.2f}\\nSkew = {:.2f}'.format(kurt ,skew),\n                      transform=subf.transAxes, verticalalignment='top', bbox=props, fontsize=10)\n            except:\n                pass\n            counter += 1\n\ngc.collect()\nhandles, labels = subf.get_legend_handles_labels()\nfig.legend(handles, labels,ncol=4, bbox_to_anchor=(0.86, 0.893),fontsize=10,\n           title= 'Resp',title_fontsize=14,bbox_transform=fig.transFigure);\n\nplt.show()","8cf295af":"respcorr =  pd.DataFrame([df_train.resp.corr(df_train[i]) for i in featstr], index=featstr).reset_index()\nrespcorr.columns = ['feature', 'coeff']\n\nfig, ax = plt.subplots()\nsns.barplot(data=respcorr, x='feature', y='coeff', ax=ax)\n\nax.set_xticklabels(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\nfor i, label in zip(range(130), ax.get_xticklabels()[:]):\n    if i % 5 != 0:\n        label.set_visible(False)\n\nplt.show()","d2b7f1ca":"del respcorr\ngc.collect()","6bc88433":"# Memory saving function credit to https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage_more(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype.name\n\n        if col_type not in ['object', 'category', 'datetime64[ns, UTC]']:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return df\n\ndf_train = reduce_mem_usage_more(df_train)","568e8779":"df_train.set_index(['ts_id', 'date'], inplace=True)","ddbaf753":"mean_resp = np.mean(df_train['resp'])\nstd_resp = np.std(df_train['resp'])","0e70c6f0":"target = 'action'","0457b61d":"features_list = ['weight'] + [feat for feat in df_train.columns if 'feature_' in str(feat)]\n# features_list","21997b2a":"fillna_dict = df_train.mean(axis=0).to_dict()","df0f7ddb":"# assign the indices of the full dataset to do multiple subsets later\nsplit_buckets = pd.Series(pd.qcut(x=df_train[target], q=100, duplicates='drop'), index=df_train.index.values)\nprint('The number of distinct target buckets:', split_buckets.nunique())","bb1bc6a2":"from sklearn.model_selection import train_test_split\n\ntrainval_limit = 300\nvaltest_limit = 400\n\nX_train = df_train[df_train.index.get_level_values(1) <= trainval_limit][features_list]\ny_train = df_train[df_train.index.get_level_values(1) <= trainval_limit][target]\n\nX_val = df_train[(df_train.index.get_level_values(1) > trainval_limit) & (df_train.index.get_level_values(1) <= valtest_limit)][features_list]\ny_val = df_train[(df_train.index.get_level_values(1) > trainval_limit) & (df_train.index.get_level_values(1) <= valtest_limit)][target]\n\nX_test = df_train[df_train.index.get_level_values(1) > valtest_limit][features_list]\ny_test = df_train[df_train.index.get_level_values(1) > valtest_limit][target]","37cfe886":"print('Train shape:')\nprint(X_train.shape)\nprint(y_train.value_counts())\nprint('Validation shape:')\nprint(X_val.shape)\nprint(y_val.value_counts())\nprint('Test shape:')\nprint(X_test.shape)\nprint(y_test.value_counts())","1e83154a":"%%time\n\nfrom sklearn.linear_model import LogisticRegression\n\nbaseline_model = LogisticRegression(penalty='none', solver='sag')\nbaseline_model.fit(X_train, y_train)","64a16bf0":"def utility_function(X, model):\n    data = X.copy()\n    data = data.reset_index().set_index('ts_id')\n\n    data['action'] = np.round(model.predict_proba(X)[:, 1])\n    \n    data = data.reset_index().merge(df_train.reset_index()[['ts_id','resp']], how='left', on='ts_id').set_index('ts_id')\n    if 'weight' not in list(data.columns):\n        data = data.reset_index().merge(df_train.reset_index()[['ts_id','weight']], how='left', on='ts_id').set_index('ts_id')\n\n    data['prod'] = data['weight'] * data['resp'] * data['action']\n    data_agg = data.groupby('date')['prod'].sum()\n\n    t = data_agg.sum() \/ np.sqrt(np.power(data_agg, 2).sum()) * np.sqrt(250 \/ len(data_agg))\n\n    u = min(max(t, 0), 6) * data_agg.sum()\n    \n    return u ","a57ae4b0":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix, log_loss, precision_recall_curve\n\nprint(\"Train: \")\nbenchmark_proba = baseline_model.predict_proba(X_train)[:, 1]\nprint(\"   ROC-AUC score: \" + str(roc_auc_score(y_train, benchmark_proba)))\nprint(\"   Utility function: \" + str(utility_function(X_train, baseline_model)))\n\nprint(\"Validation: \")\nbenchmark_proba = baseline_model.predict_proba(X_val)[:, 1]\nprint(\"   ROC-AUC score: \" + str(roc_auc_score(y_val, benchmark_proba)))\nprint(\"   Utility function: \" + str(utility_function(X_val, baseline_model)))\n\nprint(\"Test: \")\nbenchmark_proba = baseline_model.predict_proba(X_test)[:, 1]\nprint(\"   ROC-AUC score: \" + str(roc_auc_score(y_test, benchmark_proba)))\nprint(\"   Utility function: \" + str(utility_function(X_test, baseline_model)))","ce4adf27":"lgb_default_device = 'gpu' # must be lowercase\ncatboost_default_device = 'GPU' # must be uppercase","716e9feb":"X_train_hyperopt = X_train.copy()\ny_train_hyperopt = y_train.copy()\nX_test_hyperopt = X_val.copy()\ny_test_hyperopt = y_val.copy()","21340e8e":"categ_vars = []","9997f686":"def objective(params):\n    print(\"Fitting \" + str(params['model']))\n    model = params['model'](**params['param'])\n\n    if params['model'] == CatBoostClassifier:\n        print(str(params['param']['iterations']) + ' boosting iterations')\n        model.fit(X_train_hyperopt, y_train_hyperopt, cat_features = categ_vars)\n    elif params['model'] == lgb.LGBMClassifier:\n        print(str(params['param']['n_estimators']) + ' boosting iterations')\n        print('Boosting type ' + str(params['param']['boosting_type']))\n        model.fit(X_train_hyperopt, y_train_hyperopt, categorical_feature = categ_vars)\n    elif params['model'] == RandomForestClassifier:\n        print(str(params['param']['n_estimators']) + ' trees')\n        model.fit(X_train_hyperopt, y_train_hyperopt)\n    else:\n        model.fit(X_train_hyperopt, y_train_hyperopt)\n\n    loss = 0 - utility_function(X_test_hyperopt, model)\n    hyperparameter_set[loss] = params\n\n    print('Loss = ' + str(loss) + '\\n')\n    loss_list.append(loss)\n\n    return {'loss': loss, 'params': params, 'status': STATUS_OK}","8c386f64":"def run_trials(pickling_freq, initial_max_trials, filename):\n    # pickling_freq -> how many additional trials to do after loading saved trials. 1 = save after each iteration\n    # initial_max_trials -> how many iterations should be run in the beginning before the first pickle save\n    max_trials = initial_max_trials\n    warnings.warn(\"UserWarning\", UserWarning) #disable UserWarnings while running hyperopt in the run_trials() function\n  \n\n    ############################## This is where you can change the optimization space ##############################\n        \n    dictionar_lgbm = {'model':lgb.LGBMClassifier, \n                      'param': {\n                            'class_weight': {0:1, 1:hp.uniform('class_weight_1', 2, 50)},\n                            'min_sum_hessian_in_leaf': hp.uniform('min_sum_hessian_in_leaf', 0.0, 1.0),\n                            'max_bin': hp.choice('max_bin', np.arange(50, 750, 25, dtype=int)),\n                            'num_leaves': hp.choice('num_leaves', np.arange(4, 256, dtype=int)),\n                            'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.3)),\n                            'subsample_for_bin': hp.choice('subsample_for_bin', np.arange(1000, X_train_hyperopt.shape[0], dtype=int)),\n                            'min_child_samples': hp.choice('min_child_samples', np.arange(20, 500,5, dtype=int)),\n                            'is_unbalance': hp.choice('is_unbalance', np.array([True, False], dtype = bool)), \n                            'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n                            'feature_fraction': hp.uniform('feature_fraction', 1\/X_train_hyperopt.shape[1], 1.0),        \n                            'max_depth': hp.choice('max_depth', np.arange(2, 21,1, dtype=int)),    \n                            'lambda_l1': hp.uniform('lambda_l1', 0.0, 10.0),\n                            'lambda_l2': hp.uniform('lambda_l2', 0.0, 10.0),\n                            'bagging_fraction': hp.uniform('bagging_fraction',1\/X_train_hyperopt.shape[0]*10,1.0),\n                            'bagging_freq': hp.choice('bagging_freq', np.arange(1, 11,1, dtype=int)),\n                            'objective' : 'binary',\n                            # 'boost_from_average': False ,\n                            'boost_from_average': hp.choice('boost_from_average', np.array([True, False], dtype=bool)),\n                            'boosting_type': hp.choice('boosting_type', np.array(['gbdt','dart'], dtype = str)),\n                            'n_estimators' : hp.choice('n_estimators', np.arange(50, 5000, 25, dtype=int)),\n                            'device_type': lgb_default_device,\n                        }}\n    \n    dictionar_catboost = {'model':CatBoostClassifier, \n                          'param':{\n                                'iterations': hp.choice('iterations', np.arange(50, 3000, 25, dtype=int)),\n                                'depth': hp.choice('depth', np.arange(2, 11, 1, dtype=int)),\n                                'learning_rate': hp.loguniform('learning_rate_2', np.log(0.001), np.log(0.2)),\n                                'class_weights': [1, hp.uniform('class_weight_3',0.1,4)],\n                                'border_count': hp.choice('border_count', np.arange(1, 255, 1, dtype=int)),\n                                'l2_leaf_reg': hp.uniform('l2_leaf_reg',0,100),\n                                'logging_level': 'Silent',\n                                'task_type': catboost_default_device\n                            }} \n    \n\n    dictionar_sgd = {'model':SGDClassifier, \n                     'param':{\n                                 'loss': hp.choice('loss_5', np.array(['hinge', 'modified_huber', 'squared_hinge', 'perceptron'], dtype = str)),\n                                 'penalty': hp.choice('penalty_5', np.array(['l1', 'l2', 'none', 'elasticnet'], dtype = str)),\n                                 # 'alpha': hp.uniform('alpha', 0, 0.001),\n                                 'l1_ratio': hp.uniform('l1_ratio_5', 0, 1),\n                                 'max_iter': hp.choice('max_iter_7', np.arange(5, 100, 5, dtype=int)),\n                                 'learning_rate': hp.choice('learning_rate_7', np.array(['constant', 'optimal', 'invscaling', 'adaptive'], dtype = str)),\n                                 'eta0': hp.uniform('eta0', 0, 0.1),\n                                 'power_t': hp.uniform('power_t', 0, 1),\n                                 'class_weight': {0:1, 1:hp.uniform('class_weight_8', 2, 50)},\n                                 'n_jobs': -1\n                    }} \n    \n    #############################################################################################################################\n        \n        ######### Comment out the models which you do not want to use #########\n    \n    tested_models =[]\n    # tested_models.append(dictionar_lgbm)\n    tested_models.append(dictionar_catboost)\n    # tested_models.append(dictionar_sgd)\n    \n    space = hp.choice('classifier', tested_models)\n    \n        \n        \n        ############################## Checking if there are any existing Trials to reload ##############################\n    try: \n        # try to load an already saved trials object, and increase the max\n        trials = pickle.load(open(filename, \"rb\"))\n        # print(\"Found saved Trials! Loading...\")\n        max_trials = len(trials.trials) + pickling_freq\n        print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, pickling_freq))\n    except:\n        # if no existing object was found, create a new one\n        trials = Trials()\n        #################################################################################################################\n        \n        \n        \n        ###################################### Hyperopt optimization ######################################\n    space = hp.choice('classifier', tested_models)\n    fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = max_trials, trials = trials)\n    best = hyperparameter_set[sorted(hyperparameter_set)[0]]\n    print(\"Best model so far:\", best, \"\\n\")\n        ###################################################################################################\n        \n        \n        \n        ######### Saving the Trials object once optimization is finished #########\n    with open(filename, \"wb\") as f:\n        pickle.dump(trials, f)\n    print(\"Saved Trials! \\n\")  \n        #########################################################################","8b50edbb":"%%time\nhyperparameter_set = {}\nloss_list = []\ni = 0  \nsave_frequency = 5   # How often do you want your trials to be backed-up?\ninitial_trials = 1    # How many Hyperopt iterations do you want to run before the first back up, if none exists?\nhyperopt_iters = 270   # How many optimization iterations do you want to run (on top of the backe-up ones, if they exist)? Will be a multiple of save_frequency\nsave_path = \"\/kaggle\/working\/my_optimization_prod_\" + experiment_name + \".hyperopt\"\n\nwhile i <= hyperopt_iters\/save_frequency:\n    i += 1\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")  # Do not show any UserWarnings, see def run_trials; they can become annoying if you run many iterations :)\n        run_trials(pickling_freq = save_frequency, initial_max_trials = initial_trials, filename = save_path)","8bab391e":"save_path = \"\/kaggle\/working\/my_optimization_prod_\" + experiment_name + \".hyperopt\"\ntrials = pickle.load(open(save_path, 'rb'))\nloss = trials.best_trial['result']['loss']\n\n# model = CatBoostClassifier(border_count=145, \n#                            class_weights=(1, 0.8763763487405303),\n#                            depth=5,\n#                            iterations=2325,\n#                            l2_leaf_reg=19.8650097679303,\n#                            learning_rate=0.020187221403617027,\n#                            logging_level='Silent',\n#                            task_type='GPU')\n\n# best_loss = -956.9680483209429\n\n# display(model.get_params())\n# display(best_loss)\ndisplay(loss)","176e32c4":"for i in range(len(trials.trials)):    \n    if trials.trials[i]['result']['loss'] == loss:\n        print(\"Loss: \" + str(trials.trials[i]['result']['loss']))\n        # print(trials.trials[i]['result']['params'])\n        itera = i\n        print(itera)\nbest = trials.trials[itera]['result']['params']\nbest","a4074fbc":"# test = hyperparameter_set[sorted(hyperparameter_set)[0]]\n# test","de82a7b4":"# Plotting the losses of each hyperopt iteration\nplt.figure(figsize=(15, 5))\nplt.plot(trials.losses())\nplt.title(\"Hyperopt loss evolution\")\nplt.show()","761a6d08":"%%time\nmodel = best['model'](**best['param'])\n\nmodel.fit(X_train_hyperopt, \n          y_train_hyperopt, \n          # eval_set = (X_test_hyperopt, np.ravel(y_test_hyperopt)), \n          # early_stopping_rounds=60,\n          cat_features = categ_vars) ","f2e3bdfa":"# Check\nutility_function(X_test_hyperopt, model)","366b67ef":"del X_train_hyperopt\ndel y_train_hyperopt\ndel X_test_hyperopt\ndel y_test_hyperopt\ngc.collect()","4c7eddac":"def predict_compute_metrics(X, y, model):\n    \n    predictions = model.predict_proba(X)[:, 1]\n    predictions_l = model.predict(X)\n\n    print(\"ROC-AUC score: \" + str(np.round(roc_auc_score(y, predictions), decimals=4)))\n    print(\"Precision score: \" + str(np.round(precision_score(y, predictions_l), decimals=4)))\n    print(\"Utility function: \" + str(np.round(utility_function(X, model), decimals=4)))\n    \n    return predictions","44ddc087":"pred_train = predict_compute_metrics(X_train, y_train, model)\n# identical with predict_compute_metrics(X_train, y_train, model) - same data","8e9dea3a":"pred_val = predict_compute_metrics(X_val, y_val, model)\n# identical with predict_compute_metrics(X_test_hyperopt, y_test_hyperopt, model) - same data","ee04596a":"pred_test = predict_compute_metrics(X_test, y_test, model)","25f843ac":"def confusion_matrix_plot(X, y, model):\n    sns.set(rc={'figure.figsize': (15, 5)})\n    \n    predictions_l = model.predict(X)\n    cm = confusion_matrix(y, predictions_l)\n\n    ax1 = plt.subplot(1, 2, 1)\n    sns.heatmap(cm, annot=True, ax=ax1, fmt='.0f', cmap='Blues')\n\n    # labels, title and ticks\n    ax1.set_xlabel('Predicted labels')\n    ax1.set_ylabel('True labels')\n    ax1.set_title('Confusion Matrix')\n\n    cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    ax2 = plt.subplot(1, 2, 2)\n    sns.heatmap(cm, annot=True, ax=ax2, fmt='.2f', cmap='Blues')\n\n    # labels, title and ticks\n    ax2.set_xlabel('Predicted labels')\n    ax2.set_ylabel('True labels')\n    ax2.set_title('Confusion Matrix %')","b11ed270":"confusion_matrix_plot(X_train, y_train, model)","640037e6":"confusion_matrix_plot(X_val, y_val, model)","6fe91778":"confusion_matrix_plot(X_test, y_test, model)","3409b598":"def roc_curve_plot(X, y, model):\n    sns.set(rc={'figure.figsize': (10, 5)})\n    \n    predictions = model.predict_proba(X)[:, 1]\n    fpr, tpr, thresholds = roc_curve(y, predictions)\n    \n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(15, 5))\n    # Plot ROC\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(fpr, tpr, 'b', label='AUC = %0.3f' % roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0, 1], [0, 1], 'r--')\n    plt.xlim([0, 1.0])\n    plt.ylim([0, 1.00])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()","f1c03d3e":"roc_curve_plot(X_train, y_train, model)","6e392689":"roc_curve_plot(X_val, y_val, model)","2aad889f":"roc_curve_plot(X_test, y_test, model)","de2ba2f0":"def prob_histogram(X, y, model):\n    X_1 = X.loc[y == 0]\n    X_2 = X.loc[y == 1]\n\n    Zero = model.predict_proba(X_1)[:, 1]\n    One = model.predict_proba(X_2)[:, 1]\n\n    x_locs = [i\/20 for i in range(21)]\n    x_labs = [str(i\/20) for i in range(21)]\n\n    y_locs = [i for i in range(20) if i%2 ==0]\n    y_labs = [str(i) +'%' for i in range(20) if i%2 ==0]\n\n    bins = np.linspace(0, 1, 20)\n\n    plt.figure(figsize=(15, 5))\n    plt.hist(Zero, bins, weights=np.zeros_like(Zero) + 100. \/ Zero.size, \n             alpha=0.5, label='Zero', color = 'r')\n    plt.hist(One, bins, weights=np.zeros_like(One) + 100. \/One.size, \n             alpha=0.5, label='One', color = 'b')\n    plt.axvline(x=0.5, color = 'black')\n    plt.xlabel('Zero Probability')\n    plt.ylabel('Percentage in group')\n    plt.xticks(x_locs, x_labs)\n    plt.yticks(y_locs, y_labs)\n    plt.xlim(0,1)\n    plt.legend(loc='upper right')\n    plt.show()","b34c489c":"prob_histogram(X_train, y_train, model)","60019f78":"prob_histogram(X_val, y_val, model)","f74ca851":"prob_histogram(X_test, y_test, model)","9f5c0c02":"def precision_recall_curve_plot(X, y, model):\n   \n    predictions = model.predict_proba(X)[:, 1]\n    precision, recall, thresholds = precision_recall_curve(y, predictions)\n\n    f1_scores = 2 * precision * recall \/ (precision + recall)\n    f1_scores = np.nan_to_num(f1_scores)\n    f1_max = np.max(f1_scores)\n    f1_max_which = np.argmax(f1_scores)\n\n    threshold_optim = thresholds[f1_max_which]\n\n    plt.figure(figsize=(10, 10))\n\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision Recall Curve - Optimal probability threshold = ' +str(np.round(threshold_optim, 3)) + ', Maximal F1-score = ' + str(np.round(f1_max, 3) ))\n    plt.xticks(ticks = [0.05*i for i in range(21)], labels = [str(round(0.05*i, 2)) for i in range(21)])\n    plt.yticks(ticks = [0.05*i for i in range(21)], labels = [str(round(0.05*i, 2)) for i in range(21)])\n    sns.set_context('notebook', font_scale=1)\n    f1_scores_list_plot=np.array([i*0.05 for i in range(20)])\n    recall_array = np.array([i*0.01 for i in range(101)])\n    for f1_score in f1_scores_list_plot:\n        num = 1000\n        x = np.linspace(0.0001, 1, num=num)\n        y = f1_score * x \/ (2 * x - f1_score)\n        l, = plt.plot(x[(y >= 0) & (y<=1)], y[(y >= 0) & (y<=1)], alpha=0.3, color = 'grey')\n        plt.annotate('f1={0:0.2f}'.format(f1_score), xy=(0.95, y[num-10]))\n\n    plt.plot(recall, precision, color='red', alpha=0.6)\n\n    plt.show()","451202cc":"precision_recall_curve_plot(X_train, y_train, model)","8d618db4":"precision_recall_curve_plot(X_val, y_val, model)","c319df90":"precision_recall_curve_plot(X_test, y_test, model)","3837df1d":"def tsne_plot(X):\n    tsne    = manifold.TSNE(n_components=2, perplexity=50, learning_rate=20)\n    tsne_2D = tsne.fit_transform(X_train.sample(5000))\n    \n    x, y = pd.DataFrame(tsne_2D).values.T\n    fig, ax = plt.subplots(figsize=(7, 7))\n    ax.scatter(x, y, s=2, c=x, cmap = plt.cm.plasma)\n    ax.set_title('t-SNE plot', fontsize=18)\n    plt.show();","3b32d283":"%%time \ntsne_plot(X_train)","ef04fd39":"%%time \ntsne_plot(X_val)","8e40d2cf":"%%time \ntsne_plot(X_test)","bd4824db":"def permutation_importances_f1(X, y, model):\n    X = X.sample(100000)\n    y = y[X.index]\n    \n    y_pred = model.predict(X)\n    cm = confusion_matrix(y, y_pred)\n    cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    baseline = (cm[0, 0] + cm[1, 1]) \/ 2\n    imp = []\n    \n    for col in X.columns:\n        save = X[col].copy()\n        X[col] = np.random.permutation(X[col])\n        cm_2 = confusion_matrix(y, model.predict(X))\n        cm_2 = cm_2.astype('float') \/ cm_2.sum(axis=1)[:, np.newaxis]\n        m = (cm_2[0, 0] + cm_2[1, 1]) \/ 2\n        X[col] = save\n        imp.append(baseline - m)\n        \n    return np.array(imp)","333a4389":"%%time\nimp_perm = permutation_importances_f1(X_train, y_train, model)\n\nimp_df = pd.DataFrame()\nimp_df[\"feature\"] = list(X_train)\nimp_df[\"permutation_importance\"] = imp_perm.copy()\nimp_df.sort_values(['permutation_importance'], ascending=False).head(10)","a05ead74":"%%time\nimp_df_2 = imp_df.sort_values(['permutation_importance'], ascending=False)\nsns.set(rc={'figure.figsize': (20, 20)})\nsns.set_context(\"paper\", font_scale=1)    \nsns.barplot(x = 'permutation_importance',\n            y = 'feature',\n            data = imp_df_2)\nplt.show()","4b71b115":"def permutation_importances_ut(X, y, model):\n    X = X.sample(100000)\n    y = y[X.index]\n    \n    y_pred = model.predict(X)\n    baseline = utility_function(X, model)\n    imp = []\n    \n    for col in X.columns:\n        save = X[col].copy()\n        X[col] = np.random.permutation(X[col])\n        m = utility_function(X, model)\n        X[col] = save\n        imp.append(baseline - m)\n        \n    return np.array(imp)","86d160b4":"%%time\nimp_perm_ut = permutation_importances_ut(X_train, y_train, model)\n\nimp_df_ut = pd.DataFrame()\nimp_df_ut[\"feature\"] = list(X_train)\nimp_df_ut[\"permutation_importance\"] = imp_perm_ut.copy()\nimp_df_ut.sort_values(['permutation_importance'], ascending=False).head(10)","66d0d1a3":"%%time\nimp_df_2_ut = imp_df_ut.sort_values(['permutation_importance'], ascending=False)\nsns.set(rc={'figure.figsize': (20, 20)})\nsns.set_context(\"paper\", font_scale=1)    \nsns.barplot(x = 'permutation_importance',\n            y = 'feature',\n            data = imp_df_2_ut)\nplt.show()","b9d70368":"ut_pos_features = imp_df_ut.loc[imp_df_ut.permutation_importance > 0, 'feature']","58303d4a":"from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\nfrom sklearn.utils.validation import _deprecate_positional_args\n\n# https:\/\/github.com\/getgaurav2\/scikit-learn\/blob\/d4a3af5cc9da3a76f0266932644b884c99724c57\/sklearn\/model_selection\/_split.py#L2243\nclass GroupTimeSeriesSplit(_BaseKFold):\n    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n    Provides train\/test indices to split time series data samples\n    that are observed at fixed time intervals according to a\n    third-party provided group.\n    In each split, test indices must be higher than before, and thus shuffling\n    in cross validator is inappropriate.\n    This cross-validation object is a variation of :class:`KFold`.\n    In the kth split, it returns first k folds as train set and the\n    (k+1)th fold as test set.\n    The same group will not appear in two different folds (the number of\n    distinct groups has to be at least equal to the number of folds).\n    Note that unlike standard cross-validation methods, successive\n    training sets are supersets of those that come before them.\n    Read more in the :ref:`User Guide <cross_validation>`.\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of splits. Must be at least 2.\n    max_train_size : int, default=None\n        Maximum size for a single training set.\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.model_selection import GroupTimeSeriesSplit\n    >>> groups = np.array(['a', 'a', 'a', 'a', 'a', 'a',\\\n                           'b', 'b', 'b', 'b', 'b',\\\n                           'c', 'c', 'c', 'c',\\\n                           'd', 'd', 'd'])\n    >>> gtss = GroupTimeSeriesSplit(n_splits=3)\n    >>> for train_idx, test_idx in gtss.split(groups, groups=groups):\n    ...     print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n    ...     print(\"TRAIN GROUP:\", groups[train_idx],\\\n                  \"TEST GROUP:\", groups[test_idx])\n    TRAIN: [0, 1, 2, 3, 4, 5] TEST: [6, 7, 8, 9, 10]\n    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a']\\\n    TEST GROUP: ['b' 'b' 'b' 'b' 'b']\n    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] TEST: [11, 12, 13, 14]\n    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b']\\\n    TEST GROUP: ['c' 'c' 'c' 'c']\n    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\\\n    TEST: [15, 16, 17]\n    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b' 'c' 'c' 'c' 'c']\\\n    TEST GROUP: ['d' 'd' 'd']\n    \"\"\"\n    @_deprecate_positional_args\n    def __init__(self,\n                 n_splits=5,\n                 *,\n                 max_train_size=None\n                 ):\n        super().__init__(n_splits, shuffle=False, random_state=None)\n        self.max_train_size = max_train_size\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n        y : array-like of shape (n_samples,)\n            Always ignored, exists for compatibility.\n        groups : array-like of shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train\/test set.\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        if groups is None:\n            raise ValueError(\n                \"The 'groups' parameter should not be None\")\n        X, y, groups = indexable(X, y, groups)\n        n_samples = _num_samples(X)\n        n_splits = self.n_splits\n        n_folds = n_splits + 1\n        group_dict = {}\n        u, ind = np.unique(groups, return_index=True)\n        unique_groups = u[np.argsort(ind)]\n        n_samples = _num_samples(X)\n        n_groups = _num_samples(unique_groups)\n        for idx in np.arange(n_samples):\n            if (groups[idx] in group_dict):\n                group_dict[groups[idx]].append(idx)\n            else:\n                group_dict[groups[idx]] = [idx]\n        if n_folds > n_groups:\n            raise ValueError(\n                (\"Cannot have number of folds={0} greater than\"\n                 \" the number of groups={1}\").format(n_folds,\n                                                     n_groups))\n        group_test_size = n_groups \/\/ n_folds\n        group_test_starts = range(n_groups - n_splits * group_test_size,\n                                  n_groups, group_test_size)\n        for group_test_start in group_test_starts:\n            train_array = []\n            test_array = []\n            for train_group_idx in unique_groups[:group_test_start]:\n                train_array_tmp = group_dict[train_group_idx]\n                train_array = np.sort(np.unique(\n                                      np.concatenate((train_array,\n                                                      train_array_tmp)),\n                                      axis=None), axis=None)\n            train_end = train_array.size\n            if self.max_train_size and self.max_train_size < train_end:\n                train_array = train_array[train_end -\n                                          self.max_train_size:train_end]\n            for test_group_idx in unique_groups[group_test_start:\n                                                group_test_start +\n                                                group_test_size]:\n                test_array_tmp = group_dict[test_group_idx]\n                test_array = np.sort(np.unique(\n                                              np.concatenate((test_array,\n                                                              test_array_tmp)),\n                                     axis=None), axis=None)\n            yield [int(i) for i in train_array], [int(i) for i in test_array]","222c5b7e":"def classification_kfold(X, y, model):\n    X_ttv = X.reset_index()[['ts_id','date']]\n    X_ttv = X_ttv.sort_values(by=['date','ts_id'])\n    \n    i = 1\n    for train_index, valid_index in GroupTimeSeriesSplit().split(X_ttv, groups=X_ttv['date']):\n        print('Fold {}'.format(i))\n        train_index_list = X_ttv.loc[train_index, 'date'].unique()\n        valid_index_list = X_ttv.loc[valid_index, 'date'].unique()\n        print(\"      [Train dates: \" + str(np.min(train_index_list)) + \" ---- \" + str(np.max(train_index_list)) + \"]\")\n        print(\"      [Validation dates: \" + str(np.min(valid_index_list)) + \" ---- \" + str(np.max(valid_index_list)) + \"]\")\n\n        train_cv = X[X.index.get_level_values(1).isin(train_index_list)]\n        y_train_cv = y[X.index.get_level_values(1).isin(train_index_list)]\n        valid_cv = X[X.index.get_level_values(1).isin(list(valid_index_list))]\n        y_valid_cv = y[X.index.get_level_values(1).isin(list(valid_index_list))]\n\n        model.fit(train_cv, \n                  y_train_cv, \n                  # eval_set = (valid_cv, np.ravel(y_valid_cv)), \n                  # early_stopping_rounds=60,\n                  cat_features = categ_vars) \n\n        print(\"   Train: \")\n        pred_trainval = predict_compute_metrics(train_cv, y_train_cv, model)\n        print(\"   Validation: \")\n        pred_test = predict_compute_metrics(valid_cv, y_valid_cv, model)\n        print('')\n\n        i += 1\n        \n    return model","f84a5cf0":"%%time\nmodel_k = classification_kfold(X_train, y_train, model)","8760d975":"print(\"Train: \")\npred_train = predict_compute_metrics(X_train, y_train, model_k)\nprint(\"Validation: \")\npred_val = predict_compute_metrics(X_val, y_val, model_k)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test, y_test, model_k)","6debba62":"%%time\n\nmodel_pos = best['model'](**best['param'])\n# model_pos = CatBoostClassifier(border_count=145, \n#                            class_weights=(1, 0.8763763487405303),\n#                            depth=5,\n#                            iterations=2325,\n#                            l2_leaf_reg=19.8650097679303,\n#                            learning_rate=0.020187221403617027,\n#                            logging_level='Silent',\n#                            task_type='GPU')\n\n\nmodel_pos.fit(X_train.loc[:,ut_pos_features], \n              y_train, \n              # eval_set = (X_val, np.ravel(y_val)), \n              # early_stopping_rounds=60,\n              cat_features = categ_vars) ","c5a4959a":"print(\"Train: \")\npred_train = predict_compute_metrics(X_train.loc[:,ut_pos_features], y_train, model_pos)\nprint(\"Validation: \")\npred_val = predict_compute_metrics(X_val.loc[:,ut_pos_features], y_val, model_pos)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test.loc[:,ut_pos_features], y_test, model_pos)","db5eb614":"%%time\nmodel_k_pos = classification_kfold(X_train.loc[:,ut_pos_features], y_train, model_pos)","3877e784":"print(\"Train: \")\npred_train = predict_compute_metrics(X_train.loc[:,ut_pos_features], y_train, model_k_pos)\nprint(\"Validation: \")\npred_val = predict_compute_metrics(X_val.loc[:,ut_pos_features], y_val, model_k_pos)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test.loc[:,ut_pos_features], y_test, model_k_pos)","8c2808f8":"%%time\nmodel = best['model'](**best['param'])\n# model = CatBoostClassifier(border_count=145, \n#                            class_weights=(1, 0.8763763487405303),\n#                            depth=5,\n#                            iterations=2325,\n#                            l2_leaf_reg=19.8650097679303,\n#                            learning_rate=0.020187221403617027,\n#                            logging_level='Silent',\n#                            task_type='GPU')\n\nmodel.fit(X_train, \n          y_train, \n          # eval_set = (X_test_hyperopt, np.ravel(y_test_hyperopt)), \n          # early_stopping_rounds=60,\n          cat_features = categ_vars) ","dd0982c0":"from pdpbox import pdp\n\nfeatures_for_pdp = list(imp_df_2_ut.sort_values(['permutation_importance'], ascending=False).iloc[:10,0])\nfeatures_for_pdp = [x for x in list(features_for_pdp)]\nfeatures_for_pdp","43e75f9a":"%%time\n\nsns.set_context(\"paper\", font_scale=1)    \n\ntemp = X_val.iloc[:10000, :]\n\ndef partial_dependence_plots(df, feats, model):\n    for f in pdp_features:\n        if df[f].nunique() <= 25: \n            pdp_response = pdp.pdp_isolate(model=model, dataset=df, model_features=df.columns, feature=f, grid_type='equal',\n                                           cust_grid_points=np.sort(df[f].unique()))\n        else:\n            pdp_response = pdp.pdp_isolate(model=model, dataset=df, model_features=df.columns, feature=f, grid_type='equal',\n                                           cust_grid_points=np.arange(df[f].min(), df[f].max(), (df[f].max()-df[f].min())\/25))\n    \n        pdp.pdp_plot(pdp_response, f, figsize=(10, 7))\n        plt.show()\n        \npdp_features = features_for_pdp\npartial_dependence_plots(temp, pdp_features, model)","1feb4388":"%%time\n\ndef shap_plot(X, y, model):\n    X = X.sample(5000)\n    y = y[X.index]\n    \n    no_of_features = 20\n    \n    pool1 = Pool(data=X, label=y, cat_features=categ_vars)\n    shap_values = model.get_feature_importance(pool1, type='ShapValues')\n    cols_for_shap = list(X.columns)\n    index_for_shap = [X[cols_for_shap].columns.get_loc(c) for c in cols_for_shap]\n\n    plt.figure(figsize=(20, 5))\n\n    shap.summary_plot(shap_values[:, index_for_shap],\n                      X[cols_for_shap],\n                      max_display = no_of_features)","1fe4a137":"%time\nshap_plot(X_train, y_train, model)","aa4dc710":"X_trainval = df_train[df_train.index.get_level_values(1) <= valtest_limit][features_list]\ny_trainval = df_train[df_train.index.get_level_values(1) <= valtest_limit][target]","a907eada":"# Free memory\n\ndel X_train\ndel y_train\ndel X_val\ndel y_val\n\ngc.collect()","0698a2ef":"%%time\nmodel_tv = best['model'](**best['param'])\n# model_tv = CatBoostClassifier(border_count=145, \n#                            class_weights=(1, 0.8763763487405303),\n#                            depth=5,\n#                            iterations=2325,\n#                            l2_leaf_reg=19.8650097679303,\n#                            learning_rate=0.020187221403617027,\n#                            logging_level='Silent',\n#                            task_type='GPU')\n\nmodel_tv.fit(X_trainval, \n          y_trainval, \n          # eval_set = (X_test, np.ravel(y_test)), \n          # early_stopping_rounds=60,\n          cat_features = categ_vars) ","5faef338":"print(\"Train & val: \")\npred_trainval = predict_compute_metrics(X_trainval, y_trainval, model_tv)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test, y_test, model_tv)","14b65e6d":"print(\"Train & val: \")\nconfusion_matrix_plot(X_trainval, y_trainval, model_tv)","3c230748":"print(\"Test: \")\nconfusion_matrix_plot(X_test, y_test, model_tv)","ae7deb4f":"print(\"Train & val: \")\nroc_curve_plot(X_trainval, y_trainval, model_tv)\nprint(\"Test: \")\nroc_curve_plot(X_test, y_test, model_tv)","8bc08f71":"print(\"Train & val: \")\nprob_histogram(X_trainval, y_trainval, model_tv)\nprint(\"Test: \")\nprob_histogram(X_test, y_test, model_tv)","e715cb21":"print(\"Train & val: \")\nprecision_recall_curve_plot(X_trainval, y_trainval, model_tv)\nprint(\"Test: \")\nprecision_recall_curve_plot(X_test, y_test, model_tv)","1d6593a3":"def utility_function(X, model):\n    data = X.copy()\n    data = data.reset_index().set_index('ts_id')\n\n    data['action'] = np.round(model.predict_proba(X)[:, 1])\n    \n    data = data.reset_index().merge(df_train.reset_index()[['ts_id','resp']], how='left', on='ts_id').set_index('ts_id')\n    if 'weight' not in list(data.columns):\n        data = data.reset_index().merge(df_train.reset_index()[['ts_id','weight']], how='left', on='ts_id').set_index('ts_id')\n\n    data['prod'] = data['weight'] * data['resp'] * data['action']\n    data_agg = data.groupby('date')['prod'].sum()\n\n    t = data_agg.sum() \/ np.sqrt(np.power(data_agg, 2).sum()) * np.sqrt(250 \/ len(data_agg))\n\n    u = min(max(t, 0), 6) * data_agg.sum()\n    \n    return u \n\n\ndef predict_compute_metrics(X, y, model):\n    \n    predictions = model.predict_proba(X)[:, 1]\n    predictions_l = model.predict(X)\n\n    print(\"ROC-AUC score: \" + str(np.round(roc_auc_score(y, predictions), decimals=4)))\n    print(\"Precision score: \" + str(np.round(precision_score(y, predictions_l), decimals=4)))\n    print(\"Utility function: \" + str(np.round(utility_function(X, model), decimals=4)))\n    \n    return predictions\n\n\ndef classification_kfold(X, y, model):\n    X_ttv = X.reset_index()[['ts_id','date']]\n    X_ttv = X_ttv.sort_values(by=['date','ts_id'])\n    \n    i = 1\n    for train_index, valid_index in GroupTimeSeriesSplit().split(X_ttv, groups=X_ttv['date']):\n        print('Fold {}'.format(i))\n        train_index_list = X_ttv.loc[train_index, 'date'].unique()\n        valid_index_list = X_ttv.loc[valid_index, 'date'].unique()\n        print(\"      [Train dates: \" + str(np.min(train_index_list)) + \" ---- \" + str(np.max(train_index_list)) + \"]\")\n        print(\"      [Validation dates: \" + str(np.min(valid_index_list)) + \" ---- \" + str(np.max(valid_index_list)) + \"]\")\n\n        train_cv = X[X.index.get_level_values(1).isin(train_index_list)]\n        y_train_cv = y[X.index.get_level_values(1).isin(train_index_list)]\n        valid_cv = X[X.index.get_level_values(1).isin(list(valid_index_list))]\n        y_valid_cv = y[X.index.get_level_values(1).isin(list(valid_index_list))]\n\n        model.fit(train_cv, \n                  y_train_cv, \n                  # eval_set = (valid_cv, np.ravel(y_valid_cv)), \n                  # early_stopping_rounds=60,\n                  cat_features = categ_vars) \n\n        i += 1\n        \n    return model","9fa2a73b":"%%time\nmodel_tvk = classification_kfold(X_trainval, y_trainval, model_tv)","205464af":"print(\"Train & val: \")\npred_trainval = predict_compute_metrics(X_trainval, y_trainval, model_tvk)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test, y_test, model_tvk)","2263082d":"%%time\nmodel_tv_pos = best['model'](**best['param'])\n# model_tv_pos = CatBoostClassifier(border_count=145, \n#                            class_weights=(1, 0.8763763487405303),\n#                            depth=5,\n#                            iterations=2325,\n#                            l2_leaf_reg=19.8650097679303,\n#                            learning_rate=0.020187221403617027,\n#                            logging_level='Silent',\n#                            task_type='GPU')\n    \nmodel_tv_pos.fit(X_trainval.loc[:,ut_pos_features], \n              y_trainval, \n              # eval_set = (X_val, np.ravel(y_val)), \n              # early_stopping_rounds=60,\n              cat_features = categ_vars) ","3f294a2f":"print(\"Train & val: \")\npred_train = predict_compute_metrics(X_trainval.loc[:,ut_pos_features], y_trainval, model_tv_pos)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test.loc[:,ut_pos_features], y_test, model_tv_pos)","75d689db":"%%time\nmodel_tvk_pos = classification_kfold(X_trainval.loc[:,ut_pos_features], y_trainval, model_tv_pos)","028e0968":"print(\"Train & val: \")\npred_train = predict_compute_metrics(X_trainval.loc[:,ut_pos_features], y_trainval, model_tvk_pos)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test.loc[:,ut_pos_features], y_test, model_tvk_pos)","a2e2c077":"import janestreet\nfrom tqdm.notebook import tqdm\n\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set\n\nfor (test_df, sample_prediction_df) in tqdm(iter_test):\n    sample_prediction_df.action = model_tvk_pos.predict(test_df.loc[:,ut_pos_features]) # make your 0\/1 prediction here\n    env.predict(sample_prediction_df)","5501546a":"!rm -r \/kaggle\/working\/catboost_info\n!rm -r \/kaggle\/working\/pickle_files\/","018b6b7d":"So far, the best model (considering the utility function) seems the initial one fitted on the 'train' data.","743fe73f":"*Confusion matrices*","4ff20c20":"In order to perform a cross-validation on the data, one must be certain that there is no forward bias that cannot be achieved using a standard KFold split (or even a Group KFold) from sklearn for example. Moreover, even the TimeSeriesSplit can cause problems as it does not ensure a separation following the last trade of the day (we may end up with some trades as part of train data and the rest part of the test data, all occurring on the same date).\n\nTherefore, the following implementation of the GroupTimeSeriesSplit forces the chronologically selection of data, while splitting trades exactly at the end of the day. ","209af32f":"There seem to exist 4 different features types by their value structure.","5cf63040":"## Initial Setup","78d3a55d":"**Partial dependence plots**","5afa51d7":"*Correlation matrix*","2561e92e":"**Load the best model with the best hyparameters**","69ed7dca":"# II. Model Development","9a883c0a":"**Missing Rates**","db51c208":"*Features distributions*","b48ba7c3":"# <u>Jane Street Market Prediction Competition<\/u>\n*Lucian Craciun,*\n*February 7th, 2021*","09679852":"It seems that this feature clearly differentiates the type of trades, as they represent distinct return dynamics. One assumption is that it labels a 'long' trade vs a 'short' one.","59e0f826":"### Model fitting on train & validation, then evaluated on test set","1543547f":"Stochasting Neighbourhood Embedding is a non-linear dimensionality reduction technique which we can use to visualiwe high-dimensional data. In this way we can visualise what the model sees in the data.","cbff5188":"*Probabilities histograms*","c890033c":"**2. 'weight'**","bca320f7":"**Data Quantity**","476b8ac1":"**3. Cummulative return: 'weight' * 'resp'**","053ee7cb":"*ROC curves*","792dbf6d":"## Validation & Cleaning","303dc110":"**K-fold cross-validation grouping the data chronologically**","f2c2c0f0":"We will define a function that creates a back-up for the hyperopt trials after a set number of Bayesian search iterations. This is helpful for situations when the kernel crashes, or when more iterations are required at a later point in time. Given the at least partially deterministic nature of the Bayesian search process, this back-up will essentially act as a warm start.","8127a6b5":"*K-fold cross-validation grouping the data chronologically*","1f0791bd":"Since the majority of feature values are heavily centerd around the mean, the null values are filled using the mean.","7d3c3e4f":"### Predictions submission","69d07d2e":"### Model performance","b4f41efe":"## Data Overview","8fbec65b":"**Fitting the model**","a0f2821a":"Using the `datatable` library, very suitable for large datasets (as the train data adds up to `~5.77GB`), the data import is done in less than 15 seconds (vs more than 2 minutes using the pandas `read_csv` usual way).","f9b52048":"In the Permutation Importance (model agnostic feature importance method) we determine what are the most useful features, the \"drivers\" of the target. \n\nThe procedure is as follows:\n1.  Fix a metric (e.g. AUC \/ F1-score)\n2.  For each predictor column, shuffle the values. Train a new model on the database with the shuffled column and record the metric delta. Sort the features in the descending  order of the delta.\n\nThe idea behind the method is that features that are important to the prediction, when shuffled, will worsen the performance of the model. The degree of worsening is proportional to the importance of the feature.","14ee7f6c":"**5. Action**","edb4cc27":"**Data adjustments**","10af0e82":"*> features_{1...129}*","c1f2ed80":"*> feature_0*","9621fbf7":"*Precision-recall curve*","29812f3b":"*T-SNE*","10850aed":"**Shap values**","a22d53d5":"The sum of daily weights looks very correlated with the no. of daily potential trades, with a pearsonr coefficient of 0.877.","22f545de":"# I. Explanatory Data Analysis\n(section based on the following notebook: https:\/\/www.kaggle.com\/carlmcbrideellis\/jane-street-eda-of-day-0-and-feature-importance)","b5a158ac":"This is another interpretation technique inspired by cooperative game theory.","f848b9c3":"*Features growth*","1024528e":"After we determined which features are important, we also want to assess how these features influence the outcome. This can be realized using Partial Dependency Plots (PDPs for short).\nIn a PDP, each curve represents a model point, the x-axis denote the feature and the y-axis the Delta in Probability.","cebed456":"Considering a cumulative sum of daily returns, it seems that best returns are achieved for shorter horizons.","062358db":"### CatBoost Classification","5d6820ef":"**'Resp'-features correlation**","0c7ebaf9":"The target of the competition is represented by the 'action' binary variable:\n* 1 if the trade is taken\n* 0 if the trade is not performed\n\nFrom the objective function it is easily observed that for a positive return ('resp' > 0), then the action should be 1, else action is 0.","d1a2dd60":"**Permutation importance**","0fa86a73":"### Benchmark model","d2502973":"**4. Features**","46111455":"### Model interpretability","67435008":"Features 41, 42 and 43 (tag 14) look 'stratified':","e416f0c9":"### Train-validation-test split","99aab1c3":"There are 500 days in the data (equivalently, 2 years of data considering ~250 trading days per year for NYSE). Moreover, some patterns seem to change after the 85th day, potentially a change in the Jane Street trading models, fact emphasized in the following sections.","8ce1501e":"## Data Import","d1367962":"**1. 'resp' fields**","ec34cd3e":"**Start the optimization**","94a53287":"## Profiling","5d2e3690":"We are now ready to make the optimization step.\nHyperopt is a Python library for hyperparameter optimization (http:\/\/hyperopt.github.io\/hyperopt\/). In this way we can let an algorithm detect the best model and the best hyperparameter values for the task.\nAbove, we subseted the base for this task. \nThe steps required are:\n\n1. Define an objective function. That is, at each step, we compute the loss of each model. This loss is left for us to define; we can define it in terms of precision, recall, AUC or a combination of these. The algorithm will try to minimize the loss.\n2. Define the search space. We need to define the arrays of models and hyperparameters. We are also required to specify the a priori distribution of each hyperparameter\n3. Choose an optimization algorithm and perform the run.\n\nThe algorithm we choose is TPE (Tree Parzen of Estimators), a Bayesian optimization algorithm; for more details see https:\/\/www.google.com\/url?sa=t&rct=j&q=&esrc=s&source=web&cd=4&ved=2ahUKEwiq097G1cbnAhWSXsAKHTbpCI0QFjADegQIARAB&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4443-algorithms-for-hyper-parameter-optimization.pdf&usg=AOvVaw2WRbRoJUBJ8FU1S3vKmmGM","38572663":"**t-SNE**"}}