{"cell_type":{"026cb150":"code","da4e9b77":"code","fd6f8a0a":"code","f68871f8":"code","2d4d2e10":"code","cc7b465c":"code","8e58785b":"code","71297a8e":"code","eb375583":"code","fc317299":"code","75da6e67":"code","1fa3f830":"code","e23044ca":"code","6da2e080":"code","e6acc8f7":"code","60c065ed":"code","750bb4d3":"code","c61d41d9":"code","72d3aa21":"code","51ce1f77":"code","5bf317e0":"code","81029300":"code","c5704762":"code","bb6164b9":"code","54dc97bc":"code","49e8bc44":"code","cb1f2b36":"code","67b8b413":"code","4495575e":"code","23e37c24":"code","9aaf21dd":"code","19988517":"code","d7dd2d03":"code","7365d3ce":"code","bffe0b85":"code","8da49e7a":"code","ae4a18b6":"code","da89ce73":"code","53905c3b":"code","e55a6a01":"code","14cd5f45":"code","8970bb85":"code","0ba84776":"code","4c8b3cd0":"code","c22d2ea2":"code","c58aa969":"code","99d908be":"code","bc9e6be6":"code","d9a11b88":"code","2148180b":"code","36e5ec6c":"code","4d38101d":"markdown","508ea1ba":"markdown","37f1a7ab":"markdown","70b8df7e":"markdown","cb89c425":"markdown","c69ea778":"markdown","e6e8143e":"markdown","5f4b9b54":"markdown","ef822a4f":"markdown","a49c231a":"markdown","9a32fa9a":"markdown","1de8db69":"markdown","6475dae5":"markdown","0738e6d6":"markdown","ac9c9653":"markdown","1003a03d":"markdown","6c050def":"markdown","28c51552":"markdown","60b161e0":"markdown","e98eb0dc":"markdown","cc3cef2b":"markdown","9019a7d1":"markdown","3815235c":"markdown","4092d7d8":"markdown","46181fc0":"markdown","d2a36cac":"markdown","d3f57eff":"markdown","2d452e11":"markdown","02bb620f":"markdown","40e58065":"markdown","cd492d95":"markdown","7fac656b":"markdown","a8365700":"markdown","74e2a9cc":"markdown","32c65907":"markdown","37904837":"markdown","ffaaaad1":"markdown","93a04132":"markdown","496da436":"markdown","4fac63dd":"markdown"},"source":{"026cb150":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline","da4e9b77":"!wget -O loan_train.csv https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/ML0101ENv3\/labs\/loan_train.csv","fd6f8a0a":"df = pd.read_csv('loan_train.csv')\ndf.head()","f68871f8":"df.shape","2d4d2e10":"df['due_date'] = pd.to_datetime(df['due_date'])\ndf['effective_date'] = pd.to_datetime(df['effective_date'])\ndf.head()","cc7b465c":"df['loan_status'].value_counts()","8e58785b":"# notice: installing seaborn might takes a few minutes\n!conda install -c anaconda seaborn -y","71297a8e":"import seaborn as sns\n\nbins = np.linspace(df.Principal.min(), df.Principal.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'Principal', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()","eb375583":"bins = np.linspace(df.age.min(), df.age.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'age', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()","fc317299":"df['dayofweek'] = df['effective_date'].dt.dayofweek\nbins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\ng.axes[-1].legend()\nplt.show()\n","75da6e67":"df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ndf.head()","1fa3f830":"df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)","e23044ca":"df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ndf.head()","6da2e080":"df.groupby(['education'])['loan_status'].value_counts(normalize=True)","e6acc8f7":"df[['Principal','terms','age','Gender','education']].head()","60c065ed":"Feature = df[['Principal','terms','age','Gender','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)\nFeature.head()\n","750bb4d3":"from sklearn.preprocessing import LabelEncoder \nle = LabelEncoder() \n  \ndf['loan_status']= le.fit_transform(df['loan_status']) ","c61d41d9":"X = Feature\nX[0:5]","72d3aa21":"y = df['loan_status'].values\ny[0:5]","51ce1f77":"X= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]","5bf317e0":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","81029300":"from sklearn.neighbors import KNeighborsClassifier\nimport sklearn.metrics as metrics\nKs = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test)\/np.sqrt(yhat.shape[0])\n\nmean_acc","c5704762":"plt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+\/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()","bb6164b9":"print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) ","54dc97bc":"k=7\nab=KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\nab","49e8bc44":"yhat=ab.predict(X_test)\nyhat[0:5]","cb1f2b36":"from sklearn.metrics import accuracy_score\nmetrics.accuracy_score(yhat,y_test)","67b8b413":"from sklearn.tree import DecisionTreeClassifier","4495575e":"dtree=DecisionTreeClassifier(criterion='entropy',max_depth=4)\ndtree","23e37c24":"dtree.fit(X_train,y_train)\nypred=dtree.predict(X_test)","9aaf21dd":"metrics.accuracy_score(ypred,y_test)","19988517":"from sklearn import svm","d7dd2d03":"loan_df=pd.read_csv('loan_train.csv')\nloan_df.head()\nax = loan_df[loan_df['loan_status'] == 'PAIDOFF'][0:50].plot(kind='scatter', x='age', y='Principal', color='DarkBlue', label='Paidoff');\nloan_df[loan_df['loan_status'] == 'COLLECTION'][0:50].plot(kind='scatter', x='age', y='Principal', color='Yellow', label='Collection', ax=ax);\nplt.show()\nloan_df.dtypes\nimport pandas as pd \nfile_handler = open(\"loan_train.csv\", 'r')\nmydata = pd.read_csv(file_handler, sep = \",\") \nfile_handler.close() \ngender = {'male': 1,'female': 2} \nmydata.Gender = [gender[item] for item in mydata.Gender] \nloanstatus = {'PAIDOFF': 1,'COLLECTION': 2} \nmydata.loan_status = [loanstatus[item] for item in mydata.loan_status] \neducation1 = {'High School or Below': 1, 'college': 2, 'Bechalor': 3, 'Master or Above': 4}\nmydata.education = [education1[item] for item in mydata.education]\n","7365d3ce":"clf=svm.SVC(kernel='rbf')\nclf.fit(X_train,y_train)","bffe0b85":"fab=clf.predict(X_test)\nfab[0:5]","8da49e7a":"metrics.accuracy_score(fab,y_test)","ae4a18b6":"from sklearn.linear_model import LogisticRegression","da89ce73":"LR=LogisticRegression(C=0.01,solver='liblinear').fit(X_train,y_train)\nLR","53905c3b":"yhat1=LR.predict(X_test)","e55a6a01":"metrics.accuracy_score(yhat1,y_test)","14cd5f45":"yhat1_prob=LR.predict_proba(X_test)\nyhat1_prob[0:5]","8970bb85":"\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss","0ba84776":"!wget -O loan_test.csv https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/ML0101ENv3\/labs\/loan_test.csv","4c8b3cd0":"test_df = pd.read_csv('loan_test.csv')\ntest_df.head()","c22d2ea2":"\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss","c58aa969":"test_df = pd.read_csv('loan_test.csv')\ntest_df['due_date'] = pd.to_datetime(test_df['due_date'])\ntest_df['effective_date'] = pd.to_datetime(test_df['effective_date'])\ntest_df['dayofweek'] = test_df['effective_date'].dt.dayofweek\ntest_df['weekend'] = test_df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ntest_df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ntest_df['loan_status'].replace(to_replace=['PAIDOFF','COLLECTION'], value=[1,0],inplace=True)\nFeature = test_df[['Principal','terms','age','Gender','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(test_df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)\nX_test1 = Feature\ny_test1 = test_df['loan_status'].values\nX_test1 = preprocessing.StandardScaler().fit(X_test1).transform(X_test1)","99d908be":"from sklearn.metrics import classification_report\ncr = classification_report(y_test, yhat)\nprint(cr)","bc9e6be6":"predTree = dtree.predict(X_test1)\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test1, predTree))","d9a11b88":"ydtc= dtree.predict(X_test1)\n\nf1_tree = f1_score(y_test1,ydtc)\n\nprint(f\"F1 Score Decision Tree: {f1_tree:.2f}\")","2148180b":"ysvm = clf.predict(X_test1)\nf1_svm = f1_score(y_test1, ysvm)\nprint(f\"F1 Score for SVM: {f1_svm:.2f}\")","36e5ec6c":"ylog = LR.predict(X_test)\ny_prob = LR.predict_proba(X_test)\nf1_logistic = f1_score(y_test, ylog)\nlogloss = log_loss(y_test, y_prob)\nprint(f\"F1 Score for Logistic Regression: {f1_logistic:.2f}\")\nprint(f\"Logloss for Logistic Regression: {logloss:.2f}\")","4d38101d":"### Lets look at the day of the week people get the loan ","508ea1ba":"# Report\nYou should be able to report the accuracy of the built model using different evaluation metrics:","37f1a7ab":"<h1>For KNN<\/h1>","70b8df7e":"## Normalize Data ","cb89c425":"# K Nearest Neighbor(KNN)\nNotice: You should find the best k to build the model with the best accuracy.  \n**warning:** You should not use the __loan_test.csv__ for finding the best k, however, you can split your train_loan.csv into train and test to find the best __k__.","c69ea778":"Lets defind feature sets, X:","e6e8143e":"Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model\nYou should use the following algorithm:\n- K Nearest Neighbor(KNN)\n- Decision Tree\n- Support Vector Machine\n- Logistic Regression\n\n\n\n__ Notice:__ \n- You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.\n- You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n- You should include the code of the algorithm in the following cells.","5f4b9b54":"## One Hot Encoding  \n#### How about education?","ef822a4f":"### Load Data From CSV File  ","a49c231a":"# Pre-processing:  Feature selection\/extraction","9a32fa9a":"### Load Test set for evaluation ","1de8db69":"This dataset is about past loans. The __Loan_train.csv__ data set includes details of 346 customers whose loan are already paid off or defaulted. It includes following fields:\n\n| Field          | Description                                                                           |\n|----------------|---------------------------------------------------------------------------------------|\n| Loan_status    | Whether a loan is paid off on in collection                                           |\n| Principal      | Basic principal loan amount at the                                                    |\n| Terms          | Origination terms which can be weekly (7 days), biweekly, and monthly payoff schedule |\n| Effective_date | When the loan got originated and took effects                                         |\n| Due_date       | Since it\u2019s one-time payoff schedule, each loan has one single due date                |\n| Age            | Age of applicant                                                                      |\n| Education      | Education of applicant                                                                |\n| Gender         | The gender of applicant                                                               |","6475dae5":"# Decision Tree","0738e6d6":"Lets look at gender:","ac9c9653":"First, download and load the test set:","1003a03d":"# Support Vector Machine","6c050def":"We see that people who get the loan at the end of the week dont pay it off, so lets use Feature binarization to set a threshold values less then day 4 ","28c51552":"### Feature selection","60b161e0":"Lets download the dataset","e98eb0dc":"260 people have paid off the loan on time while 86 have gone into collection \n","cc3cef2b":"What are our lables?","9019a7d1":"# Data visualization and pre-processing\n\n","3815235c":"Let\u2019s see how many of each class is in our data set ","4092d7d8":"### About dataset","46181fc0":"# Model Evaluation using Test set","d2a36cac":"<h1>For LR<\/h1>","d3f57eff":"### Convert to date time object ","2d452e11":"# Logistic Regression","02bb620f":"Data Standardization give data zero mean and unit variance (technically should be done after train test split )","40e58065":"Lets plot some columns to underestand data better:","cd492d95":"## Convert Categorical features to numerical values","7fac656b":"86 % of female pay there loans while only 73 % of males pay there loan\n","a8365700":"\n\n<h1 align=\"center\"><font size=\"5\">Classification Algorithms with Python<\/font><\/h1>","74e2a9cc":"# Classification ","32c65907":"#### Use one hot encoding technique to conver categorical varables to binary variables and append them to the feature Data Frame ","37904837":"#### Feature befor One Hot Encoding","ffaaaad1":"Lets convert male to 0 and female to 1:\n","93a04132":"<h1>For SVM<\/h1>","496da436":"<h1>For Decision tree<\/h1>","4fac63dd":"In this notebook we try to practice all the classification algorithms that we learned in this course.\n\nWe load a dataset using Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n\nLets first load required libraries:"}}