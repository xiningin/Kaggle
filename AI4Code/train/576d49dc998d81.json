{"cell_type":{"577fca63":"code","a6cb1a5e":"code","97c30520":"code","0b5efdf1":"code","5d93e620":"code","0ba032e8":"code","2375922b":"code","63665205":"code","67ba5a95":"code","015bcc78":"code","0df9d226":"code","91f43226":"code","b70528af":"code","dbe8375c":"code","cd5cf6d2":"code","ae93d5f5":"code","1599fc3a":"code","4c0592b0":"code","7ebcca48":"code","3d744ea8":"code","f8620727":"code","0d3d7de7":"code","09e78f53":"code","a3c3e797":"code","56abc0bd":"code","0124757a":"code","fb643b8d":"code","e3feeedb":"code","6153ca99":"code","63141ab9":"code","9e55ab91":"code","d6bfccc6":"code","4790c8ab":"code","f76174b5":"code","177a17d7":"code","ea2002f1":"code","e366851f":"code","f37498e4":"code","ab4f6416":"code","8a4354b2":"code","80838a99":"code","84cb92dc":"code","25783b61":"code","2de509c0":"code","3dfb4e32":"code","57d18690":"code","7d71dca9":"code","6550920c":"code","df576c9d":"code","37679c63":"code","3e08bea1":"code","63c3da51":"code","e465332f":"code","0d55e5bf":"code","5558de91":"code","29803927":"code","defb6635":"code","38c06438":"code","5a6a4d76":"code","f07003cb":"code","66cf5339":"code","4b6f3882":"markdown","e3430fd1":"markdown","bf121c1a":"markdown","ba4c9b5e":"markdown","5bda63e8":"markdown","0a09ca17":"markdown","e938dbff":"markdown","998e5eea":"markdown","21d5efc1":"markdown","103b974c":"markdown","6e3b5d01":"markdown","09516d0c":"markdown","47e8cc35":"markdown"},"source":{"577fca63":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n%matplotlib inline\nimport matplotlib.pyplot as plt  # Matlab-style plotting\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a6cb1a5e":"train=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","97c30520":"train.head(3)","0b5efdf1":"train.info()","5d93e620":"for label,content in train.items():\n    if  pd.api.types.is_string_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","0ba032e8":"train.tail(3)","2375922b":"train.shape","63665205":"train.SalePrice.hist();","67ba5a95":"plt.style.use('ggplot')\nplt.figure(figsize=(10, 5))\nsns.countplot(train['YrSold'], palette = 'pink')\nplt.title('Comparison of each Year Total Houses Sold ', fontweight = 30, fontsize = 20)\nplt.xlabel('Years')\nplt.ylabel('Houses Sold');","015bcc78":"\nplt.style.use('ggplot')\nplt.figure(figsize=(10, 5))\nsns.countplot(train['MoSold'], palette = 'pink')\nplt.title('Comparison of each Month Total Houses Sold ', fontweight = 30, fontsize = 20)\nplt.xlabel('Month')\nplt.ylabel('Houses Sold');","0df9d226":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(15, 5))\n\nsns.countplot(train.SaleCondition, palette = 'Blues')\nplt.title('Comparison of Sales Condition', fontweight = 30, fontsize = 20)\nplt.xlabel('Sale Condition')\nplt.ylabel('Count');","91f43226":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(15, 5))\n\nsns.countplot(train.SaleType, palette = 'Blues')\nplt.title('Comparison of Sales Type', fontweight = 30, fontsize = 20)\nplt.xlabel('Sale Type')\nplt.ylabel('Count');","b70528af":"# Sort DataFrame in Year order\ntrain.sort_values(by=[\"YrSold\"], inplace=True, ascending=True)\ntrain.YrSold.head(5)","dbe8375c":"train.YrSold.tail(5)","cd5cf6d2":"# make a copy of our data\ndf_temp=train.copy()","ae93d5f5":"df_temp.T","1599fc3a":"pd.api.types.is_string_dtype(df_temp[\"SaleType\"])","4c0592b0":"# Find the columns which contain strings\nfor label, content in df_temp.items():\n    if pd.api.types.is_string_dtype(content):\n        print(label)","7ebcca48":"# This will turn all of the string value into category values\nfor label, content in df_temp.items():\n    if pd.api.types.is_string_dtype(content):\n        df_temp[label] = content.astype(\"category\").cat.as_ordered()","3d744ea8":"df_temp.info()","f8620727":"df_temp.SaleCondition.cat.categories","0d3d7de7":"df_temp.SaleCondition.cat.categories.value_counts()","09e78f53":"# This will turn all of the string values into category values\nfor label,content in df_temp.items():\n    if pd.api.types.is_string_dtype(content):\n        df_temp[label]=content.astype(\"category\").cat.as_ordered()","a3c3e797":"df_temp.info()","56abc0bd":"df_temp.SaleType.cat.categories","0124757a":"df_temp.LotShape.cat.codes","fb643b8d":"# Check missing data\ndf_temp.isnull().sum()\/len(df_temp)","e3feeedb":"df_temp.isna().sum()","6153ca99":"# Check for which numeric columns have null values\nfor label,content in train.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n           print(label)","63141ab9":"# Fill numeric rows with the median\nfor label, content in df_temp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n             \n            # Fill missing numeric values with median\n            df_temp[label] = content.fillna(content.median())","9e55ab91":"# Check for which numeric columns have null values\nfor label,content in df_temp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n           print(label)","d6bfccc6":"# Check for columns which aren't numeric\nfor label, content in df_temp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        print(label)","4790c8ab":"# Turn categorical variables into numbers and fill missing\n\nfor label,content in df_temp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        df_temp[label]=pd.Categorical(content).codes+1","f76174b5":"df_temp.info()","177a17d7":"df_temp.isna().sum()","ea2002f1":"len(df_temp)","e366851f":"from sklearn.ensemble import RandomForestRegressor\n\n# Instantiate model\nmodel = RandomForestRegressor(n_jobs=-1,\n                              random_state=42)\n\n# Fit the model\nmodel.fit(df_temp.drop(\"SalePrice\", axis=1), df_temp[\"SalePrice\"])","f37498e4":"# Score the model\nmodel.score(df_temp.drop(\"SalePrice\", axis=1), df_temp[\"SalePrice\"])","ab4f6416":"df_temp.head(2)","8a4354b2":"# Split data into training and validation\ndf_val = df_temp[df_temp.YrSold == 2010]\ndf_train = df_temp[df_temp.YrSold != 2010]\n\nlen(df_val), len(df_train)","80838a99":"# Split data into X & y\nX_train, y_train = df_train.drop(\"SalePrice\", axis=1), df_train.SalePrice\nX_valid, y_valid = df_val.drop(\"SalePrice\", axis=1), df_val.SalePrice\n\nX_train.shape, y_train.shape, X_valid.shape, y_valid.shape","84cb92dc":"# Create evaluation function (RMSLE)\n\ndef rmsle(y_test, y_preds):\n    \"\"\"\n    Caculates root mean squared log error between predictions and\n    true labels.\n    \"\"\"\n    return np.sqrt(mean_squared_log_error(y_test, y_preds))\n\n\n# Create function to evaluate model on a few different levels\ndef show_scores(model):\n    \n    train_preds = model.predict(X_train)\n    val_preds = model.predict(X_valid)\n    scores = {\"Training MAE\": mean_absolute_error(y_train, train_preds),\n              \"Valid MAE\": mean_absolute_error(y_valid, val_preds),\n              \"Training RMSLE\": rmsle(y_train, train_preds),\n              \"Valid RMSLE\": rmsle(y_valid, val_preds),\n              \"Training R^2\": r2_score(y_train, train_preds),\n              \"Valid R^2\": r2_score(y_valid, val_preds)}\n    return scores","25783b61":"# Change max_samples value\nmodel = RandomForestRegressor(n_jobs=-1,\n                              random_state=42)","2de509c0":"model.fit(X_train,y_train)","3dfb4e32":"show_scores(model)","57d18690":"%%time\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Different RandomForestRegressor hyperparameters\nrf_grid = {\"n_estimators\": np.arange(10, 100, 10),\n           \"max_depth\": [None, 3, 5, 10],\n           \"min_samples_split\": np.arange(2, 20, 2),\n           \"min_samples_leaf\": np.arange(1, 20, 2),\n           \"max_features\": [0.5, 1, \"sqrt\", \"auto\"]\n          }\n\n# Instantiate RandomizedSearchCV model\nrs_model = RandomizedSearchCV(RandomForestRegressor(n_jobs=-1,\n                                                    random_state=42),\n                              param_distributions=rf_grid,\n                              n_iter=2,\n                              cv=5,\n                              verbose=True)\n\n# Fit the RandomizedSearchCV model\nrs_model.fit(X_train, y_train)","7d71dca9":"# Find the best model hyperparameters\nrs_model.best_params_","6550920c":"show_scores(rs_model)","df576c9d":"%%time\n\n# Most ideal hyperparamters\nideal_model = RandomForestRegressor(n_estimators=50,\n                                    min_samples_leaf=1,\n                                    min_samples_split=2,\n                                    max_features='sqrt',\n                                    max_depth=3,\n                                    n_jobs=-1,\n                                    max_samples=None,\n                                    random_state=42) # random state so our results are reproducible\n\n# Fit the ideal model\nideal_model.fit(X_train, y_train)","37679c63":"show_scores(ideal_model)","3e08bea1":"test.shape","63c3da51":"test.head(4)","e465332f":"def preprocess_data(df):\n    \"\"\"\n    Performs transformations on df and returns transformed df.\n    \"\"\"\n    # Fill the numeric rows with median\n    for label, content in df.items():\n        if pd.api.types.is_numeric_dtype(content):\n            if pd.isnull(content).sum():\n                  \n                # Fill missing numeric values with median\n                df[label] = content.fillna(content.median())\n    \n        # Filled categorical missing data and turn categories into numbers\n        if not pd.api.types.is_numeric_dtype(content):\n            # We add +1 to the category code because pandas encodes missing categories as -1\n            df[label] = pd.Categorical(content).codes+1\n    return df        \n            ","0d55e5bf":"# Process the test data \ndf_test = preprocess_data(test)\ndf_test.head()","5558de91":"# Make predictions on updated test data\ntest_preds = ideal_model.predict(df_test)","29803927":"test_preds","defb6635":"# Format predictions into the same format Kaggle is after\ndf_preds = pd.DataFrame()\ndf_preds[\"Id\"] = df_test[\"Id\"]\ndf_preds[\"SalePrice\"] = test_preds\ndf_preds","38c06438":"df_preds.to_csv(\"submission.csv\", index=False)","5a6a4d76":"ideal_model.feature_importances_","f07003cb":"# Helper function for plotting feature importance\ndef plot_features(columns, importances, n=20):\n    plt.style.use('ggplot')\n\n    df = (pd.DataFrame({\"features\": columns,\n                        \"feature_importances\": importances})\n          .sort_values(\"feature_importances\", ascending=False)\n          .reset_index(drop=True))\n    \n    # Plot the dataframe\n    fig, ax = plt.subplots(figsize=(15,10))\n    ax.barh(df[\"features\"][:n], df[\"feature_importances\"][:20])\n    ax.set_ylabel(\"Features\")\n    ax.set_xlabel(\"Feature importance\")\n    ax.invert_yaxis()","66cf5339":"plot_features(X_train.columns, ideal_model.feature_importances_)","4b6f3882":"### Convert string to categories\n\nOne way we can turn all of our data into numbers is by converting them into pandas catgories.\n\nWe can check the different datatypes compatible with pandas here: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/general_utility_functions.html#data-types-related-functionality","e3430fd1":"### Hyerparameter tuning with RandomizedSearchCV","bf121c1a":"## Make predictions on test data","ba4c9b5e":"### Filling and turning categorical variables into numbers","5bda63e8":"Now that all of data is numeric as well as our dataframe has no missing values, we should be able to build a machine learning model.","0a09ca17":"### Preprocessing the data (getting the test dataset in the same format as our training dataset)","e938dbff":"## 5. Modelling \n We've done enough EDA (we could always do more) but let's start to do some model-driven EDA.","998e5eea":"## Fill missing values \n\n### Fill numerical missing values first\n","21d5efc1":"### Null string values","103b974c":"### Train a model with the best hyperparamters","6e3b5d01":"Turn all objects to categorical","09516d0c":"### Feature Importance\n\nFeature importance seeks to figure out which different attributes of the data were most importance when it comes to predicting the **target variable** (SalePrice).","47e8cc35":"### Splitting data into train\/validation sets"}}