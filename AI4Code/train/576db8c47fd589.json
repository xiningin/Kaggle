{"cell_type":{"db5ce514":"code","c179dfdd":"code","7b9a4b06":"code","0b8e45d7":"code","6d81efad":"code","270b12cb":"code","0e6a9737":"code","ca80b36b":"code","e5252bd5":"code","3db14951":"code","601e5088":"code","607085a4":"code","976f4df9":"code","38f808f6":"code","e906d009":"markdown","d5723727":"markdown","9830bc02":"markdown","f28ef6bb":"markdown","904ceb95":"markdown","a3b21ea1":"markdown"},"source":{"db5ce514":"import  pandas as pd\nimport numpy as np\nimport missingno\nfrom sklearn import feature_selection, linear_model, model_selection, preprocessing, feature_extraction","c179dfdd":"train_df = pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/nlp-getting-started\/test.csv\")","7b9a4b06":"missingno.matrix(train_df)","0b8e45d7":"train_df[train_df[\"target\"] == 1][\"text\"][0]","6d81efad":"train_df[train_df[\"target\"] == 0][\"text\"][15]","270b12cb":"train_df[\"target\"].value_counts()","0e6a9737":"cv = feature_extraction.text.CountVectorizer()\ntrain_vector = cv.fit_transform(train_df[\"text\"])\ntest_vector = cv.transform(test_df[\"text\"])","ca80b36b":"train_vector.shape, test_vector.shape","e5252bd5":"clf = linear_model.RidgeClassifier()","3db14951":"scores = model_selection.cross_val_score(clf, train_vector, train_df[\"target\"], cv=3, scoring=\"f1\")\nscores","601e5088":"clf.fit(train_vector, train_df[\"target\"])","607085a4":"submission_df = pd.read_csv(\"..\/input\/nlp-getting-started\/sample_submission.csv\")\nsubmission_df.head()","976f4df9":"submission_df[\"target\"] = clf.predict(test_vector)","38f808f6":"submission_df.to_csv(\"submission.csv\", index=False)","e906d009":"## 1. Reading data and importing libraries","d5723727":"## 2. EDA","9830bc02":"## 5. Predicting Test and Creating Submissions","f28ef6bb":"## 3. Feature Engineering","904ceb95":"## 4. Model Building\n\nHere we are assuming the words present on the tweet have a direct correlation as to wheather it will be a disaster or not. Hence, we will go ahead in using a linear model","a3b21ea1":"# Natural Language Processing with Disaster Tweets"}}