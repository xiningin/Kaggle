{"cell_type":{"d6a2e12c":"code","f9cb333a":"code","04bbee01":"code","ad39414a":"code","5d5ff307":"code","282ba8fd":"code","2bf9bd6b":"code","db0e9a36":"code","34832a57":"code","4a9b2aad":"code","41112b64":"code","8e034677":"code","12ca519a":"code","362a8b85":"code","14acf246":"code","e7102a23":"code","07e60ecc":"code","a64b15a2":"code","238df40f":"markdown","ec0a585a":"markdown","eff11f6f":"markdown"},"source":{"d6a2e12c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n\nprint('Keras version: %s' % keras.__version__)\nprint('Tensorflow version: %s' % tf.__version__)\n\n\n# Any results you write to the current directory are saved as output.","f9cb333a":"width = 28\nheight = 28\nchannels = 1\nclasses = {0: 'T-shirt\/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat',\n          5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot' }\nnum_classes = len(classes)\n\n# Model parameters\ngen_data = False\nepochs = 40\nbatch_size = 64","04bbee01":"def read_file(filename):\n    df = pd.read_csv(f'..\/input\/{filename}')\n    y = keras.utils.to_categorical(df['label'].values, num_classes=num_classes)\n    X = df.drop('label', axis=1).values\n    X = X.astype('float32') \/ 255\n    if (keras.backend.image_data_format() == 'channels_last'):\n        X = X.reshape(X.shape[0], width, height, channels)\n    else:\n        X = X.reshape(X.shape[0], channels, width, height)\n    return (X, y)","ad39414a":"X_train, y_train = read_file('fashion-mnist_train.csv')\nX_test, y_test = read_file('fashion-mnist_test.csv')","5d5ff307":"def show_images(X, locs, y, preds=None):\n    if isinstance(locs, int):\n        locs = [locs]\n    fig=plt.figure(figsize=(15, 10))\n    for i, val in enumerate(locs):\n        fig.add_subplot(1, len(locs), i+1)\n        plt.imshow(X[val].reshape((28, 28)))\n        plt.text(0, 32, \"Class: %s\" % classes[np.argmax(y[val])])\n        if preds is not None:\n            plt.text(0, 35, \"Predicted: %s\" % classes[np.argmax(preds[val])])\n    plt.show()","282ba8fd":"show_images(X_test, [100, 200, 300], y_test)","2bf9bd6b":"def create_model(conv_nodes, dense_nodes, loss='categorical_crossentropy',\n                 optimizer='adam', dropout=0.2):\n    model = Sequential()\n    for i in range(len(conv_nodes)):\n        model.add(Conv2D(conv_nodes[i], (3, 3), input_shape=(width, height, 1)))\n        model.add(BatchNormalization())\n        model.add(Activation('relu'))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(dropout))\n\n    model.add(Flatten())\n    \n    for i in range(len(dense_nodes)):\n        model.add(Dense(dense_nodes[i]))\n        model.add(BatchNormalization())\n        model.add(Activation('relu'))\n        model.add(Dropout(dropout))\n\n    model.add(Dense(10))\n    model.add(BatchNormalization())\n    model.add(Activation('softmax'))\n    \n    #adam = Adam(lr=0.01, decay=1e-6)\n    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n\n    return model","db0e9a36":"model = create_model(conv_nodes=[64, 32], dense_nodes=[256, 512])\nmodel.summary()","34832a57":"def execute_model(X, y, batch_size=batch_size, epochs=epochs):\n    es = EarlyStopping(monitor='loss', min_delta=0.001, patience=5, verbose=1)\n    checkpoint = ModelCheckpoint('model.hdf5', verbose=1)\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n    \n    if gen_data:\n        im_gen = ImageDataGenerator(rotation_range=5, width_shift_range=0.05, height_shift_range=0.05, \n                                    brightness_range=(-0.05, 0.05), shear_range=2, zoom_range=0.05, validation_split=0.05)\n        return model.fit_generator(im_gen.flow(X_train, y_train, batch_size=32), epochs=epochs, \n                                   callbacks=[es, checkpoint], validation_data=(X_val, y_val), verbose=1)\n    else:\n        return model.fit(X_train, y_train, batch_size=32, epochs=epochs, \n                         callbacks=[es, checkpoint], validation_data=(X_val, y_val), verbose=1)\n\nhistory = execute_model(X_train, y_train)","4a9b2aad":"fig, axes = plt.subplots(1, 2)\nfor ax, label in zip(axes, ['loss', 'acc']):\n    ax.plot(history.history[label], label='Training')\n    ax.plot(history.history['val_'+label], label='Validation')\n    ax.legend()\n    ax.set_xlabel('epochs')\n    ax.set_ylabel(label)\n    ax.set_title(label.upper())\nfig.set_size_inches(12, 5)","41112b64":"score = model.evaluate(X_test, y_test, batch_size=64)\nprint(f\"Final score is {score}\")","8e034677":"preds = model.predict_classes(X_test)\nexpected = [x.argmax() for x in y_test]","12ca519a":"results = pd.DataFrame({'preds':preds, 'expected':expected})\nresults['wrong_ones'] = results['preds'] != results['expected']\nresults.head()","362a8b85":"wrong_results = results[results['wrong_ones']]\nwrong_locs = wrong_results.index.values","14acf246":"def compare(locs, size=5):\n    show_images(X_test, locs[np.random.randint(0, len(locs), size=size)], y_test, preds)","e7102a23":"compare(wrong_locs)","07e60ecc":"most_wrong_class = wrong_results['expected'].value_counts().index[0]\nmost_wrong_results = wrong_results[wrong_results['expected'] == most_wrong_class]\nmost_wrong_locs = most_wrong_results.index\ncompare(most_wrong_locs)","a64b15a2":"model.predict_proba(X_test)","238df40f":"The validation loss & accuracy stop improving much after epochs 15 even though the training loss & accuracy improve. Hence, the later epochs show an overfitting model but at least the validation loss doesn't shoot up.","ec0a585a":"## CNN model using Keras\n\nWe'll build a CNN model using Keras to solve the Fashion MNIST problem. Then, we find the accuracy of the model on the test dataset, project it's loss & accuracy curves while training & look at some incorrect predictions.\n\nSome of the modelling techniques used are :\n* Multiple convolutional layers\n* Batch Normalization for every later before Activation\n* Applying the standard RELU Activation for hidden layers\n* Dropouts for every layer for better generalization\n* ADAM optimizer\n\nWe'll also add an option to generate images by applying random transformations & use them for training to create a more generalized model.","eff11f6f":"You can set the gen_data flag to True which adds some random transformations to the training set of images.\nI was hoping that it would help generalize the model & hence, improve the score on the test set, but it actually makes the test score worse. I would have to experiment more with that."}}