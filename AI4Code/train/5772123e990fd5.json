{"cell_type":{"036e1b9a":"code","3b1116d9":"code","0a2169a2":"code","c4563fde":"code","109f6d91":"code","70f835d1":"code","6146300b":"code","4e7a9635":"code","05b0786e":"code","4a5decf5":"code","6388d74f":"code","6eb2ad66":"code","f3b47727":"code","7e2c84c4":"code","14d52e35":"code","4aecdcf1":"code","75dc8e27":"code","848a71e0":"code","2e6c7efe":"code","40669c46":"code","a2e65ba4":"code","9e5b06d0":"code","377b52b3":"code","f50d0f88":"code","3a06fda6":"code","2bfb55e7":"code","a3a6ad20":"code","86d6b146":"code","bf70f710":"code","8c02a286":"code","3d7fbef2":"code","3d481cf1":"code","60a6ea9d":"code","69f5c7b8":"code","165f1d09":"code","073a1a4a":"code","62c57504":"code","a2d8072d":"code","83398087":"code","075ddb08":"code","88c226e5":"code","9cc4f024":"code","1ad77ae8":"code","964d0ce6":"code","ac5ebeb8":"code","e824c927":"code","1ee5390c":"code","f4288e8e":"code","effc907a":"code","e581ddb3":"code","bdb58183":"code","f05e1f30":"code","73140830":"markdown","505b5618":"markdown","ad502369":"markdown","da3381d6":"markdown","88fccbd1":"markdown","5c9d70a1":"markdown","90b29846":"markdown","07d1c5d4":"markdown","2daf2832":"markdown","30a45dec":"markdown","380bcd02":"markdown","51865d27":"markdown","9a5e69a0":"markdown","10613fd4":"markdown","0468eee7":"markdown","97847367":"markdown","090449d5":"markdown","beb0a0c7":"markdown","329e5a9b":"markdown","1b3c69b6":"markdown","2bd248e8":"markdown","899362c7":"markdown","08edd4f8":"markdown"},"source":{"036e1b9a":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\nimport matplotlib.pyplot as plt\nwarnings.simplefilter(\"ignore\", category=DeprecationWarning)","3b1116d9":"data = pd.read_csv(\"..\/input\/bigmart-sales-data\/Train.csv\")","0a2169a2":"data.info()","c4563fde":"data.head()","109f6d91":"data.describe()","70f835d1":"data['Item_Type'].unique()","6146300b":"data.isnull().sum()","4e7a9635":"data['Outlet_Size'] = data['Outlet_Size'].fillna(data['Outlet_Size'].mode())","05b0786e":"data['Item_Weight'] = data['Item_Weight'].fillna(data['Item_Weight'].mean())","4a5decf5":"for column in data.columns:\n    print(column, \":\",len(data[column].unique()))","6388d74f":"categorical_columns = [\"Item_Fat_Content\", \"Item_Type\", \"Outlet_Size\", \"Outlet_Location_Type\", \"Outlet_Type\"]\nfor col in categorical_columns:\n    print(data[col].value_counts(), \"\\n\")","6eb2ad66":"data.isnull().sum()","f3b47727":"data.describe()","7e2c84c4":"sum(data['Item_Visibility'] == 0)","14d52e35":"plt.hist(data['Item_Visibility'])","4aecdcf1":"data['Item_Visibility'] = data['Item_Visibility'].replace(0, data['Item_Visibility'].median())","75dc8e27":"data['Item_Fat_Content'].unique()","848a71e0":"data['Item_Fat_Content'].replace(\"LF\", \"Low Fat\", inplace = True)\ndata['Item_Fat_Content'].replace(\"low fat\", \"Low Fat\", inplace = True)\ndata['Item_Fat_Content'].replace(\"reg\", \"Regular\", inplace = True)\ndata['Item_Fat_Content'].replace(\"Regular\", \"Regular Fat\", inplace = True)\ndata['Item_Fat_Content'].value_counts()","2e6c7efe":"data.drop(['Outlet_Establishment_Year'], axis = 1, inplace = True)","40669c46":"data.sample(5)","a2e65ba4":"data['Item_Class'] = data['Item_Identifier'].apply(lambda x: x[:2])\ndata['Item_Class'].replace(\"FD\", \"Food\", inplace = True)\ndata['Item_Class'].replace(\"NC\", \"Non-consumeable\", inplace = True)\ndata['Item_Class'].replace(\"DR\", \"Drink\", inplace = True)","9e5b06d0":"data['Item_Class']","377b52b3":"data.loc[data['Item_Class'] == \"Non-consumeable\", \"Item_Fat_Content\"] = \"Non-consumeable\"\ndata['Item_Fat_Content'].value_counts()","f50d0f88":"for column in data.columns:\n    if data[column].dtype == \"O\":\n        plt.figure(figsize=(20, 10))\n        if column not in ['Item_Identifier', 'Outlet_Identifier']:\n            print(column)\n            sns.countplot(data[column])\n            plt.show()\n    else:\n        plt.figure(figsize=(15, 8))\n        print(column)\n        plt.hist(data[column])\n        plt.title(column)\n        plt.show()","3a06fda6":"plt.figure(figsize = (20, 10))\nsns.heatmap(data.corr(), annot = True, cmap = \"RdBu\")","2bfb55e7":"columns_to_encode = [\"Outlet_Size\", \"Outlet_Location_Type\", \"Outlet_Type\"]\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor column in columns_to_encode:\n        data[column] = le.fit_transform(data[column].astype(str))","a3a6ad20":"data.head()","86d6b146":"data = pd.get_dummies(data, columns=['Item_Fat_Content', 'Item_Class'])\ndata.head()","bf70f710":"data.drop(['Item_Fat_Content_Non-consumeable', 'Item_Class_Non-consumeable'], axis = 1, inplace = True)","8c02a286":"data.head()","3d7fbef2":"X = data.drop(['Item_Identifier', 'Outlet_Identifier', 'Item_Type', 'Item_Outlet_Sales'], axis = 1)\ny = data['Item_Outlet_Sales']\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=51)\n\nfrom sklearn.preprocessing import power_transform\n# Scaling the Item_MRP feature in test split\nscaled_features = X_test.copy()\ncol_names = ['Item_MRP']\nfeatures = scaled_features[col_names]\nnew_data = power_transform(features, method='box-cox')\nX_test['Item_MRP'] = new_data\n\n# Scaling the Item_MRP feature in training split\nscaled_features = X_train.copy()\ncol_names = ['Item_MRP']\nfeatures = scaled_features[col_names]\nnew_data = power_transform(features, method='box-cox')\nX_train['Item_MRP'] = new_data","3d481cf1":"# Transforming the Item_Visibility feature by power transformation\nX_train['Item_Visibility'] = X_train['Item_Visibility'] ** (1 \/ 3)\nX_test['Item_Visibility'] = X_test['Item_Visibility'] ** (1 \/ 3)","60a6ea9d":"plt.figure(figsize = (20, 10))\nsns.heatmap(data.corr(), annot = True)","69f5c7b8":"y_test = power_transform(y_test.copy().values.reshape(-1, 1), method='box-cox')\ny_train = power_transform(y_train.copy().values.reshape(-1, 1), method='box-cox')","165f1d09":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","073a1a4a":"from sklearn.tree import DecisionTreeRegressor\nmodel2 = DecisionTreeRegressor()\nmodel2.fit(X_train, y_train)\nmodel2.score(X_test, y_test)","62c57504":"from sklearn.linear_model import SGDRegressor\nmodel3 = SGDRegressor()\nmodel3.fit(X_train, y_train)\nmodel3.score(X_test, y_test)","a2d8072d":"from sklearn.linear_model import Lasso\nmodel4 = Lasso()\nmodel4.fit(X_train, y_train)\nmodel4.score(X_test, y_test)","83398087":"from sklearn import svm\nmodel5 = svm.SVR()\nmodel5.fit(X_train, y_train)\nmodel5.score(X_test, y_test)","075ddb08":"from sklearn.linear_model import Ridge\nmodel6 = Ridge()\nmodel6.fit(X_train, y_train)\nmodel6.score(X_test, y_test)","88c226e5":"from sklearn.linear_model import ElasticNet\nmodel7 = ElasticNet()\nmodel7.fit(X_train, y_train)\nmodel7.score(X_test, y_test)","9cc4f024":"from sklearn.ensemble import RandomForestRegressor\nmodel8 = RandomForestRegressor()\nmodel8.fit(X_train, y_train)\nmodel8.score(X_test, y_test)","1ad77ae8":"print(\"Model1\", model.score(X_test, y_test))\nprint(\"Model2\", model2.score(X_test, y_test))\nprint(\"Model3\", model3.score(X_test, y_test))\nprint(\"Model4\", model4.score(X_test, y_test))\nprint(\"Model5\", model5.score(X_test, y_test))\nprint(\"Model6\", model6.score(X_test, y_test))\nprint(\"Model7\", model7.score(X_test, y_test))\nprint(\"Model8\", model8.score(X_test, y_test))","964d0ce6":"print(\"Model8\", model8.score(X_train, y_train))","ac5ebeb8":"print(y_train.mean())\nplt.hist(y_train)\nplt.show()","e824c927":"print(y_test.mean())\nplt.hist(y_test)\nplt.show()","1ee5390c":"plt.barh(X_train.columns, model8.feature_importances_)","f4288e8e":"print(model8.get_params())","effc907a":"from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\nrandom_grid = {\n                'n_estimators': [10, 20, 40, 50, 100, 150, 200, 500],\n                'max_features': ['auto', 'sqrt'],\n                'max_depth': [3, 5, 7, 9, 11, 15],\n                'bootstrap': [True, False]\n                }\nrf = RandomForestRegressor()\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\nrf_random.fit(X_train, y_train.ravel())","e581ddb3":"rf_random.score(X_train, y_train)","bdb58183":"rf_random.score(X_test, y_test)","f05e1f30":"plt.barh(X_train.columns, rf_random.best_estimator_.feature_importances_)","73140830":"# Feature Transformation","505b5618":"Looks like there isn't much correlation between the independent continues variables and output values except Item_MRP","ad502369":"Looks like parameter tuning helped us little bit and improved accuracy by .04. Our best algorithm now is Random forest regressor with .69 R^2 score!","da3381d6":"# Data proccesing","88fccbd1":"With some Google research I found that the first 2 character of the Item_Identifer values only have 3 unique values: FD(Food), DR(Drink) and NC(Non consumable, other). Lets try to use information in this column instead of dropping it.","5c9d70a1":"Looks like the only columns with null values are Item_Weight and Outlet_Size","90b29846":"Lets see the distribution in our features! I excluded Item_Identifier and Outlet_Identifier since they are ID values.","07d1c5d4":"Have a quick look at our new correlation matrix!","2daf2832":"Since we changed some of the values in our Item_Class column to non consumable and non consumable products don't have any fat content we should change those specific rows' Item_Fat_Content to be more accurate.","30a45dec":"Seems like our model has overfit the data, parameter tuning may fix this issue.","380bcd02":"# Model Fitting","51865d27":"Lets investigate the RandomForestRegressor.","9a5e69a0":"Seems like some of the items in the store have 0 visibility. Lets have close look to our date if this is an error.","10613fd4":"Our Item_Fat_Content column has multiple values that are actually same but written differently, lets fix this before feature engineering.","0468eee7":"We should drop one column each feature we applied one hot encoding to escape dummy variable trap.","97847367":"Lets not forget that our Item_MRP value has a uniform distribution and  Item_Outlet_Sales and Item_Visibility has a exponential distribution, we need to scale them after splitting the training and testing data.","090449d5":"Big Mart is a supermarket operating on Nepal. The data presented here is the 2013 total sales of 1559 different products in the 10 Big Mart supermarkets in all different cities. The aim in this notebook predict total sales given the features bellow. \n\n**Item_Identifier**: It is a unique product ID assigned to every distinct item. It consists of an alphanumeric string of length 5\n\n**Item_Weight**: This field includes the weight of the product\n\n**Item_Fat_Content**: This attribute is categorical and describes whether the product is low fat or not. There are 2 categories of this attribute: ['Low Fat', 'Regular']. However, it is important to note that 'Low Fat' has also been written as 'low fat' and 'LF' in dataset, whereas, 'Regular' has been referred as 'reg' as well\n\n**Item_Visibility**: This field mentions the percentage of total display area of all products in a store allocated to the particular product\n\n**Item_Type**: This is a categorical attribute and describes the food category to which the item belongs. There are 16 different categories listed as follows: ['Dairy', 'Soft Drinks', 'Meat', 'Fruits and Vegetables', 'Household', 'Baking Goods', 'Snack Foods', 'Frozen Foods', 'Breakfast', 'Health and Hygiene', 'Hard Drinks', 'Canned', 'Breads', 'Starchy Foods', 'Others', 'Seafood']\n\n**Item_MRP**: This is the Maximum Retail Price (list price) of the product\n\n**Outlet_Identifier**: It is a unique store ID assigned. It consists of an alphanumeric string of length 6\n\n**Outlet_Establishment_Year**: This attribute mentions the year in which store was established\n\n**Outlet_Size**: The attribute tells the size of the store in terms of ground area covered. It is a categorical value and described in 3 categories: ['High', 'Medium', 'Small']\n\n**Outlet_Location_Type**: This field has categorical data and tells about the size of the city in which the store is located through 3 categories: ['Tier 1', 'Tier 2', 'Tier 3']\n\n**Outlet_Type**: This field contains categorical value and tells whether the outlet is just a grocery store or some sort of supermarket. Following are the 4 categories in which the data is divided: ['Supermarket Type1', 'Supermarket Type2', 'Grocery Store','Supermarket Type3']\n\n**Item_Outlet_Sales**: This is the outcome variable to be predicted. It contains the sales of the product in the particulat store","beb0a0c7":"# Explorary Data Analysis","329e5a9b":"# Feature Engineering","1b3c69b6":"Lets see the distribution in our categorical values! I excluded the ones the columns with high unique values since we can't use those effectively.","2bd248e8":"It appears that our data has a right skewed distribution. Lets replace the null values with median! We also may need to normalize this data later to fit gaussian distribution and prevent data leakage.","899362c7":"Lets transform our Item_Fat_Content and Item_Class features with One hot encoding since they are ordinal and the remaining with Label encoder","08edd4f8":"Lets use Box Cox transformation for Item_MRP since it has a uniform distribution and cubic root transformation since it has a right skewed distribution."}}