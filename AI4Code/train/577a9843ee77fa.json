{"cell_type":{"65ecb172":"code","5f9992fe":"code","7a00f1f6":"code","f76de436":"code","3c4861e2":"code","e8c2bd59":"code","9df379b9":"code","9a1e11cf":"code","e0ec37a0":"code","0fa317f4":"code","ed231872":"code","f5a48a6a":"code","85b1f57b":"code","2799f969":"code","6e2d0bea":"code","743d4d78":"code","c8242e38":"code","e8a2d57d":"code","9383060c":"code","fa3959b0":"code","e15c468f":"code","6141b95d":"code","c7eddd0a":"code","907d32cf":"code","92524c61":"code","0fe463a0":"code","3f5b27da":"code","a10f01ed":"code","0ece4b47":"code","0d6cf9ee":"code","96c17025":"code","dc95b9fb":"code","c169005e":"code","6a127d93":"code","c6f87b10":"code","a2e1aac6":"code","5518e7c4":"code","791e3d29":"code","deecc06d":"code","c3b9558b":"code","fc0e4a77":"code","fc1e2a57":"code","811ccbd7":"code","8b766c2e":"code","e524a5bb":"code","a0e1f5f1":"code","f161c083":"code","da751c0a":"code","26a07aad":"code","53ed63ce":"code","166245a8":"code","038ba49b":"code","9cacdccc":"code","cb93acf1":"code","3d5c13b8":"code","0fe99ed2":"code","3c9b57a2":"code","0f9521bf":"code","20453534":"code","6decaeb7":"code","e02ecf06":"code","aedaf9f9":"code","f9289817":"code","af182c8b":"code","cfba822e":"code","9508afca":"code","66b359ca":"code","876e68b3":"code","9d572b04":"code","68108520":"code","4a92f51b":"code","1943b228":"code","b62a3fcd":"code","63172b0c":"code","e1abae85":"code","7bd16e15":"code","2c42e907":"code","b17f3fd2":"code","6d2d1527":"code","a6148165":"code","5ac94223":"code","97d46da5":"code","711b2931":"code","a17f0688":"code","7d9a3437":"code","b3a05609":"markdown","7678a69a":"markdown","f2d17a78":"markdown","581dd18c":"markdown","e1b5b0a0":"markdown","98b30c18":"markdown","2222fa13":"markdown","32746db7":"markdown","d93af599":"markdown","fbe7250e":"markdown","9966441c":"markdown","5eea0e4e":"markdown","7c6e2063":"markdown","fa6a0745":"markdown","2066b19d":"markdown","9acc7394":"markdown","cb845782":"markdown","65226e51":"markdown","0f2c84c2":"markdown","126febc4":"markdown","50e6a76f":"markdown","b2387293":"markdown","67d1bf00":"markdown","4501dc10":"markdown","9f8d97b6":"markdown","c1451fa7":"markdown","fade1d9a":"markdown","7f03b70e":"markdown"},"source":{"65ecb172":"import pandas as pd\nimport numpy as np\nimport re\nimport time\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\npd.set_option('max_columns', 15)\npd.set_option('chained_assignment', None)","5f9992fe":"!wget https:\/\/gitlab.com\/cheevahagadog\/talks-demos-n-such\/-\/raw\/master\/PyGotham2019\/sample_data_pygotham2019.csv","7a00f1f6":"df = pd.read_csv('sample_data_pygotham2019.csv', \n                 parse_dates=['Date Created', 'Original Record: Date Created'])","f76de436":"df.shape\ndf.head(5)","3c4861e2":"df.dtypes","e8c2bd59":"def set_lead_status(row):\n    if row['Current Status'] == '- None -':\n        return row['Status at Time of Lead']\n    else:\n        return row['Current Status']","9df379b9":"%%timeit -r 3 -o -q -n 1\ntest = df.apply(set_lead_status, axis=1)","9a1e11cf":"baseline_time = np.mean(_.all_runs) \/ _.loops","e0ec37a0":"# Or another way to do it...\nstart = time.time()\n\ntest = df.apply(set_lead_status, axis=1)\n\nend = time.time()\nprint(round(end - start, 2))","0fa317f4":"def set_lead_status(col1, col2):\n    if col1 == '- None -':\n        return col2\n    else:\n        return col1","ed231872":"try:\n    test1 = set_lead_status(df['Current Status'], df['Status at Time of Lead'])\nexcept ValueError as e:\n    print(\"Error:\", e)","f5a48a6a":"%%timeit -o -r 3 -q\n# Pandas Series Vectorized baby!!\n\n# you can pass the output directly into a pandas Series\n\ndf['normalized_status'] = np.where(\n    df['Status at Time of Lead'] == '- None -',   # <-- condition\n    df['Current Status'],                         # <-- return if true\n    df['Status at Time of Lead']                  # <-- return if false\n)","85b1f57b":"npwhere_time = np.mean(_.all_runs) \/ _.loops\nnpwhere_time","2799f969":"print(f\"`np.where` is {round(baseline_time \/ npwhere_time, 1)}x faster than `.apply`\")","6e2d0bea":"%%timeit -o -r 3 -q \n# NumPy Vectorized baby!!\n\ndf['normalized_status'] = np.where(\n    df['Status at Time of Lead'].values == '- None -',\n    df['Current Status'].values, \n    df['Status at Time of Lead'].values\n)","743d4d78":"npwhere2_time = np.mean(_.all_runs) \/ _.loops","c8242e38":"print(f\"`np.where` w\/ numpy vectorization is {round(baseline_time \/ npwhere2_time, 1)}x faster than `.apply`\")","e8a2d57d":"# %%timeit\n# test = df.apply(works_but_slow, axis=1, raw=True)  # There is a significant speed improvement from using raw=True \n# # with pd.DataFrame.apply versus without. This option feeds NumPy arrays to the custom function instead of pd.Series objects.\n# # https:\/\/stackoverflow.com\/questions\/52673285\/performance-of-pandas-apply-vs-np-vectorize-to-create-new-column-from-existing-c","9383060c":"# Here is our previous function that I tried to vectorize but couldn't due to the ValueError. \ndef works_fast_maybe(col1, col2):\n    if col1 == '- None -':\n        return col2\n    else:\n        return col1","fa3959b0":"# with the np.vectorize method --> returns a vectorized callable\nvectfunc = np.vectorize(works_fast_maybe) #otypes=[np.float],cache=False)","e15c468f":"%%timeit -o -r 3 -q\ntest3 = list(vectfunc(df['Status at Time of Lead'], df['Current Status']))","6141b95d":"def can_I_go_any_faster(status_at_time, current_status):\n    # this works fine if you're setting static values\n    df['test'] = 'test'# status_at_time\n    df.loc[status_at_time == '- None -', 'test'] = current_status  # <-- ValueError, indexes don't match!\n    df.loc[status_at_time != '- None -', 'test'] = status_at_time","c7eddd0a":"%%timeit -r 3 -q -o\ntest4 = can_I_go_any_faster(df['Status at Time of Lead'], df['Current Status'])","907d32cf":"def can_I_go_any_faster2(status_at_time, current_status):\n    # this works fine if you're setting static values\n    df['test'] = 'test'# status_at_time\n    df.loc[status_at_time == '- None -', 'test'] = 'statys1_isNone' \n    df.loc[status_at_time != '- None -', 'test'] = 'statys2_notNone'","92524c61":"%%timeit\ntest5 = can_I_go_any_faster2(df['Status at Time of Lead'], df['Current Status'])","0fe463a0":"list1 = ['LEAD-3 Flame No Contact', 'LEAD-Campaign', 'LEAD-Claim', 'LEAD-Contact Program', \n         'LEAD-General Pool', 'LEAD-No Contact', 'LEAD-Nurture', 'LEAD-Unqualified', 'PROSPECT-LOST']\n\nlist2 = ['- None -', 'CLIENT-Closed-Sold', 'CLIENT-Handoff', 'CLIENT-Implementation', 'CLIENT-Implementation (EMR)',\n         'CLIENT-Live', 'CLIENT-Partner', 'CLIENT-Referring Consultant', 'CLIENT-Transferred', 'LEAD-Engaged', \n         'LEAD-Long-Term Opportunity', 'PROSPECT-CURRENT', 'PROSPECT-LONG TERM', 'PROSPECT-NO DECISION']\n\n# apply version\ndef lead_category(row):\n    if row['Original Record: Date Created'] == row['Date Created']:\n        return 'New Lead'\n    elif row['normalized_status'].startswith('CLI'):\n        return 'Client Lead'\n    elif row['normalized_status'] in list1:\n        return 'MTouch Lead'\n    elif row['normalized_status'] in list2:\n        return 'EMTouch Lead'\n    return 'NA'","3f5b27da":"%%timeit -r 3 -o -q\ndf['lead_category0'] = df.apply(lead_category, axis=1)","a10f01ed":"baseline_time = np.mean(_.all_runs) \/ _.loops","0ece4b47":"%%timeit -r 3 -o -q\ndf['lead_category'] = \\\n    np.where(df['Original Record: Date Created'].values == df['Date Created'].values, 'New Lead', \n            np.where(df['normalized_status'].str.startswith('CLI').values, 'Client Lead', \n                    np.where(df['normalized_status'].isin(list1).values, 'MTouch Lead', \n                            np.where(df['normalized_status'].isin(list2).values, 'EMTouch Lead', \n                                     'NA') \n                                  )\n                         )\n                )","0d6cf9ee":"%%timeit -r 3 -o -q\nconditions = [\n    df['Original Record: Date Created'].values == df['Date Created'].values,\n    df['normalized_status'].str.startswith('CLI').values,\n    df['normalized_status'].isin(list1).values,\n    df['normalized_status'].isin(list2).values\n]\n\nchoices = [\n    'New Lead', \n    'Client Lead', \n    'MTouch Lead',\n    'EMTouch Lead'\n]\n\n\ndf['lead_category1'] = np.select(conditions, choices, default='NA')  # Order of operations matter!","96c17025":"npselect_time = np.mean(_.all_runs) \/ _.loops","dc95b9fb":"# Their output logic is the same\n(df.lead_category == df.lead_category1).all()","c169005e":"print(f\"`np.select` w\/ numpy vectorization is {round(baseline_time \/ npselect_time, 2)}x faster than nested .apply()\")","6a127d93":"# This is something you might think you can't vectorize, but you sure can!\ndef sub_conditional(row):\n    if row['Inactive'] == 'No':\n        if row['Providers'] == 0:\n            return 'active_no_providers'\n        elif row['Providers'] < 5:\n            return 'active_small'\n        else:\n            return 'active_normal'\n    elif row['duplicate_leads']:\n        return 'is_dup'\n    else:\n        if row['bad_leads']:\n            return 'active_bad'\n        else:\n            return 'active_good'","c6f87b10":"%%timeit -r 3 -q -o\n# Let's time how long it takes to apply a nested multiple condition func\ndf['lead_type'] = df.apply(sub_conditional, axis=1)","a2e1aac6":"baseline_time = np.mean(_.all_runs) \/ _.loops","5518e7c4":"%%timeit -r 3 -o -q\n\n# With np.select, could do .values here for additional speed, but left out to avoid too much text\nconditions = [\n    ((df['Inactive'] == 'No') & (df['Providers'] == 0)),\n    ((df['Inactive'] == 'No') & (df['Providers'] < 5)),\n    df['Inactive'] == 'No',\n    df['duplicate_leads'],  # <-- you can also just evaluate boolean arrays\n    df['bad_leads'],\n]\n\nchoices = [\n    'active_no_providers',\n    'active_small',\n    'active_normal',\n    'is_dup',\n    'active_bad',\n]\n\ndf['lead_type_vec'] = np.select(conditions, choices, default='NA')","791e3d29":"npselect_time = np.mean(_.all_runs) \/ _.loops","deecc06d":"mask = (\n    ((df['Inactive'] == 'No') & (df['Providers'] == 0))\n    & ((df['Inactive'] == 'No') & (df['Providers'] < 5))\n    & (df['Inactive'] == 'No')\n    & (df['duplicate_leads'])  # <-- you can also just evaluate boolean arrays\n    & df['bad_leads']\n)","c3b9558b":"print(f\"`np.select` is {round(baseline_time \/ npselect_time, 2)} faster than nested .apply()\")","fc0e4a77":"%%timeit -r 3 -o -q\n\n# With np.select\nconditions = [\n    ((df['Inactive'].values == 'No') & (df['Providers'].values == 0)),\n    ((df['Inactive'].values == 'No') & (df['Providers'].values < 5)),\n    df['Inactive'].values == 'No',\n    df['duplicate_leads'].values,  # <-- you can also just evaluate boolean arrays\n    df['bad_leads'].values,\n]\n\nchoices = [\n    'active_no_providers',\n    'active_small',\n    'active_normal',\n    'is_dup',\n    'active_bad',\n]\n\ndf['lead_type_vec'] = np.select(conditions, choices, default='NA')","fc1e2a57":"npselect2_time = np.mean(_.all_runs) \/ _.loops","811ccbd7":"print(f\"`np.select` w\/ vectorization is {round(baseline_time \/ npselect2_time, 2)} faster than nested .apply()\")","8b766c2e":"df.head(2)","e524a5bb":"# Doing a regex search to find string patterns\n\ndef find_paid_nonpaid(s):\n    if re.search(r'non.*?paid', s, re.I):\n        return 'non-paid'\n    elif re.search(r'Buyerzone|^paid\\s+', s, re.I):\n        return 'paid'\n    else:\n        return 'unknown'","a0e1f5f1":"%%timeit -r 3 -o -q\n# our old friend .apply()\ndf['lead_source_paid_unpaid'] = df['Lead Source'].apply(find_paid_nonpaid)","f161c083":"baseline_time = np.mean(_.all_runs) \/ _.loops","da751c0a":"%%timeit -r 3 -o -q\n\nvect_str = np.vectorize(find_paid_nonpaid)\n\ndf['lead_source_paid_unpaid1'] = vect_str(df['Lead Source'])","26a07aad":"%%timeit -r 3 -o -q\n# How does a list comprehension do?\ndf['lead_source_paid_unpaid2'] = ['non-paid' if re.search(r'non.*?paid', s, re.I) \n                                  else 'paid' if re.search(r'Buyerzone|^paid\\s+', s, re.I) \n                                  else 'unknown' for s in df['Lead Source']]","53ed63ce":"%%timeit -r 3 -o -q\n# How does this compare?\nconditions = [\n    df['Lead Source'].str.contains(r'non.*?paid', case=False, na=False),\n    df['Lead Source'].str.contains(r'Buyerzone|^paid\\s+', case=False, na=False),\n]\n\nchoices = [\n    'non-paid',\n    'paid'\n]\n\ndf['lead_source_paid_unpaid1'] = np.select(conditions, choices, default='unknown')","166245a8":"%%timeit -r 3 -o -q\ndf['lowerls'] = df['Lead Source'].apply(lambda x: x.lower())","038ba49b":"%%timeit -r 3 -o -q\ndf['lowerls1'] = df['Lead Source'].str.lower()","9cacdccc":"channel_dict = {\n    'Billing Service': 'BS', 'Consultant': 'PD', 'Educational': 'PD', \n    'Enterprise': 'PD', 'Hospital': 'PD', 'IPA': 'PD', 'MBS': 'RCM', \n    'MSO': 'PD', 'Medical practice': 'PD', 'Other': 'PD', 'Partner': 'PD',\n    'PhyBillers': 'BS', 'Practice': 'PD', 'Purchasing Group': 'PD',\n    'Reseller': 'BS', 'Vendor': 'PD', '_Other': 'PD', 'RCM': 'RCM'\n}\n\ndef a_dict_lookup(row):\n    if row['Providers'] > 7:\n        return 'Upmarket'\n    else:\n        channel = channel_dict.get(row['Category'])\n        return channel","cb93acf1":"%%timeit -o -r 3 -q -n 1\ndf['dict_lookup'] = df.apply(a_dict_lookup, axis=1)","3d5c13b8":"baseline_time = np.mean(_.all_runs) \/ _.loops","0fe99ed2":"%%timeit -r 3 -o -q\ndf['dict_lookup1'] = np.where(\n    df['Providers'].values > 7, \n    'Upmarket',\n    df['Category'].map(channel_dict)\n)","3c9b57a2":"npwhere_time = np.mean(_.all_runs) \/ _.loops","0f9521bf":"baseline_time \/ npwhere_time","20453534":"%%timeit -r 3 -o -q\nchannel_values = df['Category'].map(channel_dict)\ndf['dict_lookup1'] = np.where(\n    df['Providers'] > 7, \n    'Upmarket',\n    channel_values\n)","6decaeb7":"%%timeit -r 3 -o -q\n# Using np.vectorize to vectorize a dictionary .get() method works, but is slower than .map()\nchannel_values = np.vectorize(channel_dict.get)(df['Category'].values)\ndf['dict_lookup2'] = np.where(\n    df['Providers'] > 7, \n    'Upmarket',\n    channel_values\n)","e02ecf06":"print((df['dict_lookup'] == df['dict_lookup1']).all())\nprint((df['dict_lookup'] == df['dict_lookup2']).all())","aedaf9f9":"df.head(2)","f9289817":"# make a new column called 'Start Date' for dummy testing\n# ONly do a fraction so we have some NaN values\ndf['Start Date'] = df['Date Created'].sample(frac=0.8)","af182c8b":"def weeks_to_complete(row) -> float:\n    \"\"\"Calculate the number of weeks between two dates\"\"\"\n    if pd.isnull(row['Start Date']):\n        return (row['Original Record: Date Created'] -  row['Date Created']).days \/ 7\n    else:\n        return (row['Date Created'] - row['Start Date']).days \/ 7","cfba822e":"%%timeit -r 3 -o -q -n 1\nwtc1 = df.apply(weeks_to_complete, axis=1)","9508afca":"baseline_time = np.mean(_.all_runs) \/ _.loops","66b359ca":"%%timeit -r 3 -o -q\nwtc2 = np.where(\n    df['Start Date'].isnull().values,\n    (df['Original Record: Date Created'].values - df['Date Created']).dt.days \/ 7,\n    (df['Date Created'].values - df['Start Date']).dt.days \/ 7\n)","876e68b3":"npwhere_time = np.mean(_.all_runs) \/ _.loops","9d572b04":"%%timeit -r 3 -o -q\nwtc3 = np.where(\n    df['Start Date'].isnull().values,\n    ((df['Original Record: Date Created'].values - df['Date Created'].values).astype('timedelta64[D]') \/ np.timedelta64(1, 'D')) \/ 7,\n    ((df['Date Created'].values - df['Start Date'].values).astype('timedelta64[D]') \/ np.timedelta64(1, 'D')) \/ 7\n)","68108520":"npwhere2_time = np.mean(_.all_runs) \/ _.loops","4a92f51b":"# How much faster is our last way over .apply()?\nbaseline_time \/ npwhere2_time","1943b228":"def time_looper(df):\n    \"\"\" Using a plain Python for loop\"\"\"\n    output = []\n    for i, row in enumerate(range(0, len(df))):\n        if i > 0:\n            \n            # compare the current id to the row above\n            if df.iloc[i]['Internal ID'] == df.iloc[i-1]['Internal ID']:\n                \n                # compare the current date to the row above\n                if (df.iloc[i]['Date Created'] - df.iloc[i-1]['Original Record: Date Created']).days < 5:\n                    output.append(0)\n                else:\n                    output.append(1)\n            else:\n                output.append(1)\n        else:\n            output.append(np.nan)\n    return output","b62a3fcd":"def time_looper2(df):\n    \"\"\"Using pandas dataframe `.iterrows()` method for iterating over rows\"\"\"\n    output = []\n    for i, row in df.iterrows():\n        if i > 0:\n            if df.iloc[i]['Internal ID'] == df.iloc[i-1]['Internal ID']:\n                if (df.iloc[i]['Date Created'] - df.iloc[i-1]['Original Record: Date Created']).days < 5:\n                    output.append(0)\n                else:\n                    output.append(1)\n            else:\n                output.append(1)\n        else:\n            output.append(np.nan)\n    return output","63172b0c":"df.sort_values(['Internal ID', 'Date Created'], inplace=True)","e1abae85":"%%timeit -r 3 -o -q -n 1\ndf['time_col_raw_for'] = time_looper(df)","7bd16e15":"baseline_time = np.mean(_.all_runs) \/ _.loops","2c42e907":"%%timeit -r 3 -o -q -n 1\ndf['time_col_iterrows'] = time_looper2(df)","b17f3fd2":"iterrows_time =  np.mean(_.all_runs) \/ _.loops","6d2d1527":"%%timeit -o -r 3 -q\nprevious_id = df['Internal ID'].shift(1).fillna(0).astype(int)\nprevious_date = df['Original Record: Date Created'].shift(1).fillna(pd.Timestamp('1900'))\n\nconditions = [\n    ((df['Internal ID'].values ==  previous_id) & \n     (df['Date Created'] - previous_date).astype('timedelta64[D]') < 5),\n    df['Internal ID'].values ==  previous_id\n]\nchoices = [0, 1]\ndf['time_col1'] = np.select(conditions, choices, default=1)","a6148165":"shift_time = np.mean(_.all_runs) \/ _.loops","5ac94223":"baseline_time \/ shift_time","97d46da5":"# TODO: figure out what's going on here\n(df['time_col1'] == df['time_col_iterrows']).all()","711b2931":"from multiprocessing import Pool","a17f0688":"def p_apply(df, func, cores=4):\n    \"\"\"Pass in your dataframe and the func to apply to it\"\"\"\n    df_split = np.array_split(df, cores)\n    pool = Pool(n_cores)\n    df = pd.concat(pool.map(func, df_split))\n    pool.close()\n    pool.join()\n    return df","7d9a3437":"# df = p_apply(df, func=some_big_function)","b3a05609":"#### Dictionary lookups","7678a69a":"How does `np.vectorize()` do for strings?","f2d17a78":"#### Needing values on other rows for the logic\nThis example comes from a task I had to recreate a function like this in Excel:\n```excel\n=IF(A2=A1, IF(L2-L1 < 5, 0, 1), 1))\n```\nWhere the `A` column is for ids, and the `L` column is for dates.","581dd18c":"Another approach is to do ndarray type casting, converting our series into numpy timedelta arrays. This way is faster, but more verbose and kinda more code for basically the samething.","e1b5b0a0":"#### Strings","98b30c18":"# First attempt at vectorizing with conditionals","2222fa13":"## What about nested multiple conditionals? Can we vectorize that?\nYes!","32746db7":"You can call a `np.where` for every condition, and it will run fine. But it gets a little hard to read after a while.","d93af599":"# Enter `numpy.where()`\n[Documentation](https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.where.html)\nSimilar to Excel 'IF' function, you give it a condition, except this condition can handle the truthiness for the entire array\/column. Then give it what to return if elements on that boolean array are true or false.","fbe7250e":"# 1000x faster data manipulation!\n\n**Disclaimer: this is not my(ceshine'e) original work. I just took the notebook by Nathan Cheever from [here](https:\/\/gitlab.com\/cheevahagadog\/talks-demos-n-such\/-\/blob\/master\/PyGotham2019\/PyGotham-updated.ipynb) and made it run on Kaggle.**\n\nUpdate: programatically compare the execution times. \n\n## Vectorizing with pandas and NumPy\n\nThis talk was originally given at PyGotham 2019. Original video [here](https:\/\/youtu.be\/nxWginnBklU).\n\nSlides [here](https:\/\/docs.google.com\/presentation\/d\/1X7CheRfv0n4_I21z4bivvsHt6IDxkuaiAuCclSzia1E\/edit?usp=sharing)","9966441c":"# What about `numpy.vectorize()`?\n\nThis is a function that will take a Python function and turn it into a NumPy ufunc, so it can handle vectorized approaches. It _vectorizes_ your function, not necessarily how that function applies to your data. Big difference there.\n\nResources:\n - https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.vectorize.html\n - https:\/\/www.experfy.com\/blog\/why-you-should-forget-loops-and-embrace-vectorization-for-data-science\n","5eea0e4e":"Sofia mentions in her talk that you can go even faster by accessing the underlying NumPy arrays from your pandas series. This makes it faster b\/c now there's only a NumPy array of your data to pass to C, with no need for handling all the stuff attached to a pandas Series that makes them so convenient to work with.","7c6e2063":"# Other alternatives","fa6a0745":"#### Dates","2066b19d":"# Multiple conditions","9acc7394":"Our approach to vectorizing this unfortunate situation was two-fold:\n 1. Using the pandas `.shift()` function, we moved previous values down so they're on the same axis as what we're comparing them to \n 2. `np.select()` for the vectorized conditional logic check\n ","cb845782":"One approach to vectorization is to use pandas `.dt` datetime accessors. They have lots of goodies..","65226e51":"# Enter `numpy.select()`\nCleaner (and even faster!) and doing multiple nested `np.where` calls for each conditions.\nOrder of operations matter!\n\n[Documentation](https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.select.html)","0f2c84c2":"## Read in and setup the data \nThis CSV is an example of the data I worked on while practicing learning how to vectorize former `.apply` functoins. The data here have been scrubbed and scrambled to not relate to any real-life data.","126febc4":"pandas provides the `.str()` methods for working with strings.","50e6a76f":"### lead_category","b2387293":"Kinda slow. So I thought I could vectorize by taking what Sofia Hiesler said in her talk: just pass in the columns and operate on them at the same time....","67d1bf00":"*what about not searching strings?*","4501dc10":"### Data inspection ","9f8d97b6":"# What about more complicated things?\nOf course this is just a tiny sample of things you might encounter, but I thought they could be useful to see how vectorization can still apply even with otherwise difficult cases.","c1451fa7":"## Dask\nhttps:\/\/docs.dask.org","fade1d9a":"## A _parallel_ apply func\nSource: https:\/\/towardsdatascience.com\/make-your-own-super-pandas-using-multiproc-1c04f41944a1","7f03b70e":"Some guy on Medium thought this was faster -- using index setting -- but it turns out it's actually not vectorizing"}}