{"cell_type":{"8938a1fb":"code","7d50007f":"code","7c5b2d5f":"code","1068f7ca":"code","b4b3c235":"code","eb44aa4f":"code","9da5fcda":"code","ec0006f7":"code","12772568":"code","d0e4aa6f":"code","1a55e687":"markdown","0730a42b":"markdown","237e4afa":"markdown","3f6c2ce5":"markdown"},"source":{"8938a1fb":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\n\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dense, Activation, Dropout, Flatten \nfrom keras.preprocessing.image import load_img, ImageDataGenerator","7d50007f":"train_path = '\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train'\ntest_path = '\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test'\nIMAGE_SIZE = (224, 224)","7c5b2d5f":"def load_data(train_path, test_path, shuffle=True):\n    \"\"\"\n        Load the data\n        Output: Train and Test Datasets\n        Return: Tuple\n    \"\"\"\n    \n    datasets = [train_path, test_path]\n    output = []\n    class_names = os.listdir(train_path)\n    print(f'Class Names: {\", \".join(class_names)}')\n    print('====='*15)\n\n    # Iterate through training and test sets\n    for i, dataset in enumerate(datasets):\n        \n        images = []\n        labels = []\n        \n        sets = 'Training' if i==0 else 'Test'\n        \n        print(f\"{sets} set Loading ... .. .\")\n        print('====='*15)\n        \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            label = class_names.index(folder)\n            folder_path = os.path.join(dataset, folder)\n            print(folder)\n            print('-----'*3)\n            \n            # Iterate through each image in our folder\n            for file in tqdm(os.listdir(folder_path)):\n                \n                # Get the path name of the image\n                file_path = os.path.join(folder_path, file)\n                \n                # Open and resize the img\n                image = cv2.resize(cv2.cvtColor(cv2.imread(file_path), cv2.COLOR_BGR2RGB),IMAGE_SIZE)\n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n            print('-----'*15)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')\n        \n        output.append((images, labels))\n        print(f'{sets} labels unique values: {np.unique(labels)}')\n        print(f'{sets} images array shape: {images.shape}\\n{sets} labels shape: {labels.shape}')\n        print('*****'*15)\n\n    return output","1068f7ca":"(X_train, y_train), (X_test, y_test) = load_data(train_path, test_path)","b4b3c235":"X_train, y_train = shuffle(X_train, y_train, random_state=42)\n# X_val, y_val = X_train[:len(X_train)\/\/5], y_train[:len(y_train)\/\/5]\n# X_train, y_train = X_train[len(X_train)\/\/5: ], y_train[len(y_train)\/\/5: ]\nX_train = X_train\/255.\nX_test = X_test\/255.","eb44aa4f":"model = Sequential()\n\n# 1st Convolutional Layer\nmodel.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11),\\\n strides=(4,4), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling \nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n# Batch Normalisation before passing it to the next layer\nmodel.add(BatchNormalization())\n\n# 2nd Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 4th Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 5th Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# Passing it to a dense layer\nmodel.add(Flatten())\n# 1st Dense Layer\nmodel.add(Dense(4096, input_shape=(224*224*3,)))\nmodel.add(Activation('relu'))\n# Add Dropout to prevent overfitting\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 2nd Dense Layer\nmodel.add(Dense(4096))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Dense Layer\nmodel.add(Dense(1000))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# Output Layer\nmodel.add(Dense(17))\nmodel.add(Activation('softmax'))\n\nmodel.summary()","9da5fcda":"# (4) Compile \nmodel.compile(\n    loss='sparse_categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)","ec0006f7":"history = model.fit(\n                X_train,\n                y_train,\n                epochs=10,\n                validation_split=0.2,\n                verbose=1\n            )","12772568":"plt.plot(pd.DataFrame(history.history))","d0e4aa6f":"test_results = model.evaluate(X_test, y_test)","1a55e687":"# Intel Image Classification\n![Intel-image-classification](https:\/\/miro.medium.com\/max\/1000\/1*tyGmirZbPUJMAYP2RkdrkQ.png)","0730a42b":"# (1) Define Augmentation\ntrain_augmentation = ImageDataGenerator(\n    rescale=1\/255.,\n    rotation_range = 40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n    )\n\nval_augmentation = ImageDataGenerator(rescale=1\/255.)\n\n# (2) Generate Augmented Data\ntrain = train_augmentation.flow_from_directory(\n                                    directory = train_path,\n                                    class_mode = \"categorical\",\n                                    target_size = IMAGE_SIZE,\n                                    batch_size = 32,\n                                    shuffle = True\n                                )\n\ntest = val_augmentation.flow_from_directory(\n                                        directory = test_path,\n                                        class_mode = \"input\",\n                                        target_size = IMAGE_SIZE,\n                                        batch_size = 128,\n                                        shuffle = True\n                                    )\n","237e4afa":"# (3) Create a sequential model\nmodel = Sequential()\n\n# 1st Convolutional Layer\nmodel.add(Conv2D(filters=8, input_shape=(150,150,3), kernel_size=(3,3),\\\n strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation before passing it to the next layer\nmodel.add(BatchNormalization())\n\n# 2nd Convolutional Layer\nmodel.add(Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Convolutional Layer\nmodel.add(Conv2D(filters=32, kernel_size=(7,7), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 4th Convolutional Layer\nmodel.add(Conv2D(filters=32, kernel_size=(7,7), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling \nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 5th Convolutional Layer\nmodel.add(Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 6th Convolutional Layer\nmodel.add(Conv2D(filters=8, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# Passing it to a dense layer\n# 1st Dense Layer\nmodel.add(Flatten(input_shape=(150,150,3)))\nmodel.add(Activation('relu'))\n# Add Dropout to prevent overfitting\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 2nd Dense Layer\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Dense Layer\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Dense Layer\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# Output Layer\nmodel.add(Dense(6))\nmodel.add(Activation('softmax'))\n\nmodel.summary()\n\n\n","3f6c2ce5":"img_train = []\nlbl_train = []\n\nimg_test = []\nlbl_test = []\n\nimg_pred = []\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(f'1. {dirname}\\n2. {_}')\n    for filename in filenames:\n        filepath = os.path.join(dirname, filename)\n        if 'seg_train\/seg_train' in dirname:\n            img_train.append(cv2.resize(cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB),IMAGE_SIZE))\n            lbl_train.append(dirname.split('\/')[-1])\n        elif 'seg_test\/seg_test' in dirname:\n            img_test.append(cv2.resize(cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB),IMAGE_SIZE))\n            lbl_test.append(dirname.split('\/')[-1])\n        elif 'seg_pred\/seg_pred' in dirname:\n            img_pred.append(cv2.resize(cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB),IMAGE_SIZE))\n\n            \nX_train, X_test, X_pred = tuple(map(lambda x: np.array(x, dtype='float32'), [img_train, img_test, img_pred]))\ny_train, y_test = tuple(map(lambda x: np.array(x), [lbl_train, lbl_test]))\nX_train, y_train = shuffle(X_train, y_train, random_state=42)\nX_test, y_test = shuffle(X_train, y_train, random_state=42)\n\nlabels = list(set(lbl_train))\nprint(labels)\nprint('-----'*10)\n\nlabel_map = dict(map(lambda x: x[::-1], enumerate(labels)))\nprint(label_map)\nprint('-----'*10)\n\ny_train, y_test = tuple(map(lambda x: np.vectorize(label_map.get)(x), [y_train, y_test]))\nprint(f'y_train unique: {np.unique(y_train)}\\ny_test unique: {np.unique(y_test)}')\nprint('====='*10)\n\nprint(f'X_train shape: {X_train.shape}\\ny_train shape: {y_train.shape}')\nprint('-----'*10)\nprint(f'X_test shape: {X_test.shape}\\ny_test shape: {y_test.shape}')\nprint('-----'*10)\nprint(f'X_pred shape: {X_pred.shape}')"}}