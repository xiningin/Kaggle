{"cell_type":{"c8cb0f95":"code","16f3f64a":"code","698b0ce1":"code","d0bbb714":"code","fbba710e":"code","90c48410":"code","a624dca9":"code","5d402ab1":"code","b234be9f":"code","b5c22add":"code","68793dff":"code","3fa33864":"code","107e6df7":"code","25f75065":"code","30b64938":"code","24f9309b":"code","5274f9e2":"code","6f740b6c":"code","547f8c38":"code","d1e3eedf":"code","ee2dae39":"code","aa897be0":"code","278369bd":"code","74207ed5":"code","d5e9514b":"code","fb2792ef":"code","008b856a":"code","1540996d":"code","2ee186f1":"code","01210f02":"code","850c1b0b":"code","b4d3b91e":"code","ab43c844":"code","8924422b":"code","ed196cfc":"code","8cabafab":"code","adfa680a":"code","3cc9b251":"code","853e8dde":"code","a8de1e56":"code","e335ada7":"code","011e1231":"code","855d310c":"code","9466d3ba":"code","b0ab0ec0":"code","d8637685":"markdown","27e2653d":"markdown","57b5a6b5":"markdown","782803c2":"markdown","b9e63664":"markdown","26c2a485":"markdown","d30d7845":"markdown"},"source":{"c8cb0f95":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tqdm.notebook import tqdm\nimport gc\nimport matplotlib.pyplot as plt","16f3f64a":"from sklearn.inspection import permutation_importance\n\nfrom eli5.sklearn import PermutationImportance\nimport eli5\n\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom mlxtend.plotting import plot_sequential_feature_selection as plot_sfs","698b0ce1":"from bayes_opt import BayesianOptimization\nimport warnings","d0bbb714":"import catboost\n\ncatboost.__version__","fbba710e":"# \/kaggle\/input\/ef-msu-2021-autumn-inclass\/sample_submission.csv\n# \/kaggle\/input\/ef-msu-2021-autumn-inclass\/train.csv\n# \/kaggle\/input\/ef-msu-2021-autumn-inclass\/test.csv","90c48410":"train = pd.read_csv(\"\/kaggle\/input\/ef-msu-2021-autumn-inclass\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/ef-msu-2021-autumn-inclass\/test.csv\")\n\ntrain_y = train['many_orders']\n\ntest_ids = test[\"id\"]","a624dca9":"train['train'] = 1\ntest['train'] = 0\n\ntrain_test = pd.concat([train, test]).reset_index(drop=True)\ntrain_test = train_test.drop(['many_orders'], axis=1)","5d402ab1":"train_test","b234be9f":"model_adv = CatBoostClassifier(\n    learning_rate=0.9,\n    random_state=1337,\n    thread_count=-1,\n    iterations=100,\n    cat_features=[\"city_code\", \"region_code\", \"center_type\", \"category\", \"cuisine\"],\n    verbose=25,\n    eval_metric=\"AUC\",\n    od_type=\"Iter\",\n    od_wait=50,\n#     use_best_model=True,\n)","b5c22add":"X_train, X_test, y_train, y_test = train_test_split(\n    train_test.drop(['id', 'train'], axis=1), train_test['train'], test_size=0.25, random_state=42)","68793dff":"model_adv.fit(X_train, y_train)","3fa33864":"fe = pd.DataFrame()\nfe['importance'] = model_adv.feature_importances_\nfe['feature_name'] = model_adv.feature_names_","107e6df7":"fe","25f75065":"pred_adv = model_adv.predict_proba(X_test)[:,1]","30b64938":"roc_auc_score(y_test, pred_adv)","24f9309b":"train['rating'].hist(bins=150);","5274f9e2":"test['rating'].hist(bins=150);","6f740b6c":"train = train.drop(['train'], axis=1)\ntest = test.drop(['train'], axis=1)","547f8c38":"%%time\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    train.drop(['id', 'many_orders', 'rating'], axis=1), train_y, random_state=1, test_size=0.25\n)\n\ncat_features = [\"city_code\", \"region_code\", \"center_type\", \"category\", \"cuisine\"]\n\ntrain_encoded = train.drop(['id', 'many_orders', 'rating'], axis=1).copy()\nfor col in cat_features:\n    le = LabelEncoder()\n    train_encoded[col] = le.fit_transform(train_encoded[col])\n    train_encoded[col] = train_encoded[col].astype(int)","d1e3eedf":"model_cbs_enc = CatBoostClassifier(\n    learning_rate=0.9,\n    random_state=1337,\n    thread_count=-1,\n    iterations=100,\n#     cat_features=cat_features,\n    verbose=0,\n    eval_metric=\"AUC\",\n    od_type=\"Iter\",\n    od_wait=50,\n#     use_best_model=True,\n)","ee2dae39":"%%time\n\nsfs = SFS(estimator=model_cbs_enc,\n           k_features=(1, len(train_encoded.columns)),\n           forward=False,\n           scoring='roc_auc',\n           n_jobs=-1,\n           verbose=1,\n           cv=2)\n\nsfs.fit(train_encoded, train_y)","aa897be0":"print('best combination (AUC: %.6f): %s\\n' % (sfs.k_score_, list(pd.Series(sfs.k_feature_names_))))\n#print('all subsets:\\n', sfs.subsets_)\nplot_sfs(sfs.get_metric_dict(), kind='std_err');","278369bd":"X_valid.isnull().sum()","74207ed5":"model_cbs = CatBoostClassifier(\n    learning_rate=0.9,\n    random_state=1337,\n    thread_count=-1,\n    iterations=100,\n    cat_features=cat_features,\n    verbose=0,\n    eval_metric=\"AUC\",\n    od_type=\"Iter\",\n    od_wait=50,\n#     use_best_model=True,\n)","d5e9514b":"%%time\n\nmodel_cbs.fit(X_train, y_train)","fb2792ef":"%%time\n\nresult = permutation_importance(model_cbs, X_valid, y_valid, n_repeats=10, random_state=1)\nresult_df = pd.DataFrame()\nresult_df['feature'] = X_valid.columns\nresult_df['importances_mean'] = result['importances_mean']\nresult_df['importances_std'] = result['importances_std']\nresult_df = result_df.sort_values(by='importances_mean', ascending=False).reset_index(drop=True)\n\nresult_df","008b856a":"%%time\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    train.drop(['id', 'many_orders', 'rating'], axis=1), train_y, random_state=1, test_size=0.25\n)\n\nnp.random.seed(1)\n\nX_train['bad_feature'] = np.random.normal(loc=0.0, scale=0.05, size=X_train.shape[0])\nX_valid['bad_feature'] = np.random.normal(loc=0.0, scale=0.05, size=X_valid.shape[0])\n\nmodel_cbs.fit(X_train, y_train)\n\nresult = permutation_importance(model_cbs, X_valid, y_valid, n_repeats=10, random_state=0)\n\nresult_df = pd.DataFrame()\nresult_df['feature'] = X_valid.columns\nresult_df['importances_mean'] = result['importances_mean']\nresult_df['importances_std'] = result['importances_std']\nresult_df = result_df.sort_values(by='importances_mean', ascending=False).reset_index(drop=True)\n\nif 'bad_feature' in X_train.columns:\n    X_train = X_train.drop(['bad_feature'], axis=1)\n    X_valid = X_valid.drop(['bad_feature'], axis=1)\n\nresult_df","1540996d":"fe = pd.DataFrame()\nfe['importance'] = model_cbs.feature_importances_\nfe['feature_name'] = model_cbs.feature_names_\nfe","2ee186f1":"%%time\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    train.drop(['id', 'many_orders', 'rating'], axis=1), train_y, random_state=1, test_size=0.25\n)\n\nfor i in range(5):\n    X_train[f'constant_{i+1}'] = i\n    X_valid[f'constant_{i+1}'] = i\n\nmodel_cbs.fit(X_train, y_train)\n\nresult = permutation_importance(model_cbs, X_valid, y_valid, n_repeats=10, random_state=0)\n\nresult_df = pd.DataFrame()\nresult_df['feature'] = X_valid.columns\nresult_df['importances_mean'] = result['importances_mean']\nresult_df['importances_std'] = result['importances_std']\nresult_df = result_df.sort_values(by='importances_mean', ascending=False).reset_index(drop=True)\n\nif 'constant_1' in X_train.columns:\n    for i in range(5):\n        X_train = X_train.drop([f'constant_{i+1}'], axis=1)\n        X_valid = X_valid.drop([f'constant_{i+1}'], axis=1)\n\nresult_df","01210f02":"%%time\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    train.drop(['id', 'many_orders', 'rating'], axis=1), train_y, random_state=1, test_size=0.25\n)\n\nfor i in range(10):\n    X_train[f'checkout_price_double_{i+1}'] = X_train['checkout_price']\n    X_valid[f'checkout_price_double_{i+1}'] = X_valid['checkout_price']\n\nmodel_cbs.fit(X_train, y_train)\n\nresult = permutation_importance(model_cbs, X_valid, y_valid, n_repeats=10, random_state=0)\n\nresult_df = pd.DataFrame()\nresult_df['feature'] = X_valid.columns\nresult_df['importances_mean'] = result['importances_mean']\nresult_df['importances_std'] = result['importances_std']\nresult_df = result_df.sort_values(by='importances_mean', ascending=False).reset_index(drop=True)\n\nif 'checkout_price_double_1' in X_train.columns:\n    for i in range(10):\n        X_train = X_train.drop([f'checkout_price_double_{i+1}'], axis=1)\n        X_valid = X_valid.drop([f'checkout_price_double_{i+1}'], axis=1)\n\nresult_df","850c1b0b":"%%time\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    train.drop(['id', 'many_orders', 'rating'], axis=1), train_y, random_state=1, test_size=0.25\n)\n\nX_valid['checkout_price'] = np.random.normal(loc=0.0, scale=0.05, size=X_valid.shape[0])\n\nmodel_cbs.fit(X_train, y_train)\n\nresult = permutation_importance(model_cbs, X_valid, y_valid, n_repeats=10, random_state=0)\n\nresult_df = pd.DataFrame()\nresult_df['feature'] = X_valid.columns\nresult_df['importances_mean'] = result['importances_mean']\nresult_df['importances_std'] = result['importances_std']\nresult_df = result_df.sort_values(by='importances_mean', ascending=False).reset_index(drop=True)\n\n\nresult_df","b4d3b91e":"fe = pd.DataFrame()\nfe['importance'] = model_cbs.feature_importances_\nfe['feature_name'] = model_cbs.feature_names_\nfe","ab43c844":"def _do_permutation_for_one_column(col, X_val, y_val, model, results_base, n_iter=10, seed=1337, scoring=roc_auc_score):\n    cur_X_val = X_val.copy()\n    col_results = list()\n\n    for i in range(n_iter):\n        cur_seed = (seed * (n_iter + 1)) % 2**32\n        np.random.seed(cur_seed)\n\n        cur_X_val[col] = np.random.permutation(cur_X_val[col])\n        preds = model.predict_proba(cur_X_val)[:,1]\n        col_results.append(results_base - scoring(y_val, preds))\n\n    results = [np.mean(col_results), np.std(col_results)]\n    return results\n\ndef own_permutation_importance(model, X_val, y_val, n_iter=10, seed=1337, scoring=roc_auc_score):\n    y_pred = model.predict_proba(X_val)[:,1]\n    results_base = scoring(y_val, y_pred)\n\n    weights_dict = dict()\n\n    for i in range(len(X_val.columns)):\n        col = X_val.columns[i]\n        cur_seed = (seed * (i + 1)) % 2**32\n        cur_results = _do_permutation_for_one_column(col, X_val, y_val, model, results_base, n_iter=n_iter, seed=cur_seed, scoring=scoring)\n        weights_dict[col] = cur_results\n\n    weights_df = pd.DataFrame()\n    weights_df['features'] = weights_dict.keys()\n    weights_df['importances_mean'] = np.asarray(list(weights_dict.values()))[:,0]\n    weights_df['importances_std'] = np.asarray(list(weights_dict.values()))[:,1]\n    weights_df = weights_df.sort_values(['importances_mean'], ascending=False).reset_index(drop=True)\n\n    return weights_df","8924422b":"X_train, X_valid, y_train, y_valid = train_test_split(\n    train.drop(['id', 'many_orders', 'rating'], axis=1), train_y, random_state=1, test_size=0.25\n)","ed196cfc":"model_cbs.fit(X_train, y_train)","8cabafab":"%%time\n\nown_permutation_importance(model=model_cbs, X_val=X_valid, y_val=y_valid, n_iter=10, seed=1337, scoring=roc_auc_score)","adfa680a":"def int_params(params):\n    for p in params:\n        if p in ['num_leaves', 'max_depth', 'n_estimators', 'min_child_samples', 'random_state']:\n            params[p] = int(np.round(params[p], decimals = 0))\n    return params\n\n\n\ndef get_best_params(df_train_, seed_cv_, seed_bo_, target_name='many_orders', init_points=5, n_iter=5):\n\n    def auc_evaluate(**params):\n        warnings.simplefilter('ignore')\n    \n        params = int_params(params)\n\n        clf = CatBoostClassifier(**params, n_estimators=10000, thread_count=-1, random_state=seed_cv_, eval_metric=\"AUC\",\n                                 cat_features=[\"city_code\", \"region_code\", \"center_type\", \"category\", \"cuisine\"])\n\n        folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed_cv_)\n\n        test_pred_proba = np.zeros(df_train_.shape[0])\n\n        feats = df_train_.drop([target_name], axis=1).columns\n\n        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df_train_[feats], df_train_[target_name])):\n\n            train_x, train_y = df_train_[feats].iloc[train_idx], df_train_[target_name].iloc[train_idx]\n            valid_x, valid_y = df_train_[feats].iloc[valid_idx], df_train_[target_name].iloc[valid_idx]\n\n            clf.fit(train_x, train_y, \n                    eval_set=(valid_x, valid_y),\n                    verbose=False, early_stopping_rounds=50)\n\n            test_pred_proba[valid_idx] = clf.predict_proba(valid_x)[:,1]        \n\n        metric_test = roc_auc_score(df_train_[target_name], test_pred_proba)\n\n        return metric_test\n\n    params = {\n          'learning_rate': (.001, .5), \n          'colsample_bylevel': (0.3, 1),\n          'subsample': (0.3, 1), \n          'max_depth': (3, 15), \n          'reg_lambda': (.0, 1.), \n          'min_child_samples': (10, 1000),\n    }\n    \n    bo = BayesianOptimization(auc_evaluate, params, random_state=seed_bo_)\n    bo.maximize(init_points=init_points, n_iter=n_iter)\n\n    return bo.max","3cc9b251":"%%time\n\n# init_points \u0438 n_iter \u0441\u0442\u043e\u0438\u0442 \u0434\u0435\u043b\u0430\u0442\u044c \u043f\u043e\u0431\u043e\u043b\u044c\u0448\u0435, \u0437\u0434\u0435\u0441\u044c \u043c\u0430\u043b\u0435\u043d\u044c\u043a\u0438\u0435 \u0447\u0438\u0441\u043b\u0430 \u0434\u043b\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e\u0431\u044b \u043d\u0435 \u0434\u043e\u043b\u0433\u043e \u0441\u0447\u0438\u0442\u0430\u043b\u043e\u0441\u044c\nbo = get_best_params(df_train_=train.drop(['id', 'rating'], axis=1), seed_cv_=42, seed_bo_=42, init_points=5, n_iter=2) ","853e8dde":"bo","a8de1e56":"train[\"many_orders\"].value_counts()","e335ada7":"def cv_and_predict(\n    df_train,\n    df_test,\n    train_y,\n    model_kf,\n    n_splits=5,\n    random_state=42,\n    verbose=True,\n    model_type=None,\n):\n    \"\"\"\n    \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u0438 \u043f\u0440\u0435\u0434\u0438\u043a\u0442\u0430 \u043d\u0430 \u0442\u0435\u0441\u0442\n\n    :param df_train: \u0422\u0440\u0435\u0439\u043d-\u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\n    :param df_test: \u0422\u0435\u0441\u0442-\u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\n    :param train_y: \u041e\u0442\u0432\u0435\u0442\u044b \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\n    :param model_kf: \u041c\u043e\u0434\u0435\u043b\u044c, \u043a\u043e\u0442\u043e\u0440\u0443\u044e \u043c\u044b \u0445\u043e\u0442\u0438\u043c \u0443\u0447\u0438\u0442\u044c\n    :param n_splits: \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u043f\u043b\u0438\u0442\u043e\u0432 \u0434\u043b\u044f KFold\n    :param random_state: random_state \u0434\u043b\u044f KFold\n    :param verbose: \u0414\u0435\u043b\u0430\u0435\u043c \u043b\u0438 print'\u044b\n    :param model_type: \u0422\u0438\u043f \u043c\u043e\u0434\u0435\u043b\u0438\n\n    :return: pred_test: \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0442\u0435\u0441\u0442; oof_df: OOF \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f; metric_OOF: \u043c\u0435\u0442\u0440\u0438\u043a\u0430 OOF \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\u0435\n    \"\"\"\n\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n\n    # \u0412 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u0435 oof_df \u0431\u0443\u0434\u0443\u0442 \u0445\u0440\u0430\u043d\u0438\u0442\u044c\u0441\u044f \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0439 \u0442\u0430\u0440\u0433\u0435\u0442 \u0442\u0440\u0435\u0439\u043d\u0430 \u0438 OOF \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0442\u0440\u0435\u0439\u043d.\n    # \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c prediction_oof \u043d\u0443\u043b\u044f\u043c\u0438 \u0438 \u0431\u0443\u0434\u0435\u043c \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438 \u0432 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0435 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438\n    oof_df = pd.DataFrame()\n    oof_df[\"target\"] = train_y\n    oof_df[\"prediction_oof\"] = np.zeros(oof_df.shape[0])\n\n    # \u0421\u043f\u0438\u0441\u043e\u043a \u0441 \u043c\u0435\u0442\u0440\u0438\u043a\u0430\u043c\u0438 \u043f\u043e \u0444\u043e\u043b\u0434\u0430\u043c\n    metrics = list()\n\n    # \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0442\u0435\u0441\u0442. \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043d\u0443\u043b\u044f\u043c\u0438 \u0438 \u0431\u0443\u0434\u0435\u043c \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438 \u0432 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0435 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438.\n    # \u041d\u0430\u0448\u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0431\u0443\u0434\u0443\u0442 \u0443\u0441\u0440\u0435\u0434\u043d\u0435\u043d\u0438\u0435\u043c n_splits \u043c\u043e\u0434\u0435\u043b\u0435\u0439\n    pred_test = np.zeros(df_test.shape[0])\n\n    # \u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f\n    for i, (train_index, valid_index) in enumerate(kf.split(df_train, train_y)):\n        if verbose:\n            print(f\"fold_{i} started\")\n\n        X_train = df_train.loc[train_index]\n        y_train = train_y.loc[train_index].values\n\n        X_valid = df_train.loc[valid_index]\n        y_valid = train_y.loc[valid_index].values\n\n        if model_type == \"cbs\":\n            model_kf.fit(\n                X_train,\n                y_train,\n                eval_set=(X_valid, y_valid),\n                plot=True,\n            )\n        else:\n            model_kf.fit(X_train, y_train)\n\n        prediction = model_kf.predict_proba(df_test)[:, 1]\n        pred_test += prediction \/ n_splits\n\n        prediction_kf = model_kf.predict_proba(X_valid)[:, 1]\n        oof_df.loc[valid_index, \"prediction_oof\"] = prediction_kf\n\n        cur_metric = roc_auc_score(y_valid, prediction_kf)\n        metrics.append(cur_metric)\n\n        if verbose:\n            print(f\"metric_{i}: {cur_metric}\")\n            print()\n            print(\"_\" * 90)\n            print()\n\n    metric_OOF = roc_auc_score(train_y, oof_df[\"prediction_oof\"])\n\n    if verbose:\n        print(f\"metric_OOF: {metric_OOF}\")\n        print(f\"metric_AVG: {np.mean(metrics)}\")\n        print(f\"metric_std: {np.std(metrics)}\")\n        print()\n        print(\"*\" * 90)\n        print()\n\n    return pred_test, oof_df, metric_OOF","011e1231":"model_cbs = CatBoostClassifier(\n    learning_rate=0.9,\n    random_state=1337,\n    thread_count=-1,\n    iterations=100,\n    cat_features=[\"city_code\", \"region_code\", \"center_type\", \"category\", \"cuisine\"],\n    verbose=25,\n    eval_metric=\"AUC\",\n    od_type=\"Iter\",\n    od_wait=50,\n    use_best_model=True,\n)","855d310c":"%%time\n\npred_test, oof_df, metric_OOF = cv_and_predict(train.drop(['many_orders', 'id', 'rating'], axis=1),\n                                               test.drop(['id', 'rating'], axis=1), \n                                               train_y=train['many_orders'], model_kf=model_cbs, model_type='cbs')","9466d3ba":"# metric_OOF: 0.9616348966386759\n# metric_AVG: 0.9616367775410708\n# metric_std: 0.0005566095007401832","b0ab0ec0":"submission = pd.DataFrame()\nsubmission[\"id\"] = test_ids\nsubmission[\"many_orders\"] = pred_test\nsubmission.to_csv(\"submission.csv\", index=False)","d8637685":"## SequentialFeatureSelector","27e2653d":"# Feature Selection","57b5a6b5":"# Adversarial Validation","782803c2":"## Permutation Importance","b9e63664":"## Target Permutation\n\nhttps:\/\/www.kaggle.com\/ogrellier\/feature-selection-target-permutations","26c2a485":"# Modeling","d30d7845":"# BayesOpt\n\nhttps:\/\/github.com\/fmfn\/BayesianOptimization"}}