{"cell_type":{"49cec4e7":"code","c03e4f6b":"code","b6591f9b":"code","980efe52":"code","ef0eacce":"code","0b77c15e":"code","739f25d8":"markdown","5d45b173":"markdown","1fdaf582":"markdown","4a053742":"markdown","51a8a85b":"markdown","89338824":"markdown","16acbf92":"markdown"},"source":{"49cec4e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c03e4f6b":"import torch, torchvision\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n#Helpers for visualization\n\ndef torch_imshow(img):\n    img = img[0]\n    plt.imshow(img.cpu().numpy())\n    plt.show()\n    \n\nclass GANVisualizer:\n    '''\n    This class is a utility for visualizing\n    generator samples using fixed latent vector to\n    track the training of a GAN.\n    '''\n    def __init__(self):\n        self.z = torch.randn(16, 100).cuda()\n    \n    def visualize(self, generator):\n        with torch.no_grad():\n            imgs = generator(self.z)\n            fig, axes = plt.subplots(4, 4, figsize=(15, 15))\n            for n in range(16):\n                axis_row = n \/\/ 4\n                axis_col = n % 4\n                \n                subplot = axes[axis_row, axis_col] \n                subplot.axis('off')\n                img = subplot.imshow(imgs[n].cpu().reshape(28, 28))\n                img.set_cmap('gray')\n        plt.show()\n\nvisualizer = GANVisualizer() ","b6591f9b":"#Create dataset and dataloader\nBATCH_SIZE = 16\n\nmnist = torchvision.datasets.MNIST('.\/', train=True, download=True, transform=torchvision.transforms.ToTensor())\ntrain_dataloader = DataLoader(dataset=mnist, batch_size=BATCH_SIZE, shuffle=True)","980efe52":"class FCNet(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.layers =  torch.nn.Sequential(\n            torch.nn.Linear(input_dim,hidden_dim),\n            torch.nn.ReLU(),\n            torch.nn.Linear(hidden_dim,output_dim),\n            torch.nn.Sigmoid()\n            \n        )\n    def forward(self, x):\n        x = self.layers(x)\n        return x\n        \n        \ngenerator     = FCNet(100, 256, 784)\ndiscriminator = FCNet(784, 256, 1)\n\n\nprint('--Generator--')\ndummy_input_g = torch.randn(16, 100)\ndummy_output_g = generator(dummy_input_g)\nprint(generator)\nprint(f'Dummy input shape: {dummy_input_g.shape}')\nprint(f'Dummy output shape: {dummy_output_g.shape}')\n\n\nprint('--Discriminator--')\nprint(discriminator)\ndummy_input_d = torch.randn(16, 784)\ndummy_output_d = discriminator(dummy_input_d)\nprint(f'Dummy input shape: {dummy_input_d.shape}')\nprint(f'Dummy output shape: {dummy_output_d.shape}')\n\n","ef0eacce":"# Define an optimizer for both generator and discriminator\n\nlr = 0.001\n\n######################1\ng_optimizer = torch.optim.Adam(generator.parameters(), lr)\nd_optimizer = torch.optim.Adam(discriminator.parameters(), lr)\n\nloss_fn = torch.nn.MSELoss()\n#####################2","0b77c15e":"generator = generator.to(\"cuda\")\ndiscriminator = discriminator.to(\"cuda\")\n\nfor epoch in range(10): \n    print(f'Epoch: {epoch + 1}')\n    \n    for iteration, (real_imgs, labels) in enumerate(train_dataloader):\n        real_imgs = real_imgs.reshape(-1, 784).cuda()\n        z = torch.randn(BATCH_SIZE, 100).cuda()\n        \n        ones = torch.ones(BATCH_SIZE,1).cuda()\n        zeros = torch.zeros(BATCH_SIZE,1).cuda()\n\n        ## train generator 1 step       \n\n        generator.zero_grad()\n\n        generator_output = generator(z) #output of generator\n\n        discriminator_output = discriminator(generator_output)\n\n        g_loss = loss_fn(discriminator_output, ones)\n        \n        g_loss.backward()\n\n        g_optimizer.step()\n  \n\n        #train discriminator 1 step\n        \n        discriminator.zero_grad()\n\n        # train on real images (loss(real,ones))\n        \n        x_real = real_imgs\n\n        d_out_real = discriminator(x_real).cuda()\n        \n        d_real_loss = loss_fn(d_out_real, ones)\n\n        # train on fake images (loss(fake,zeros)) \n        z = torch.randn(BATCH_SIZE, 100).cuda() \n\n        x_fake = generator(z)\n\n        D_output_fake = discriminator(x_fake)\n\n        d_fake_loss = loss_fn(D_output_fake, zeros)\n\n        # sum real+fake losses \n\n        d_loss = d_real_loss + d_fake_loss\n\n        d_loss.backward()\n\n        d_optimizer.step()\n    \n    # Visualize generator samples after the epoch\n    visualizer.visualize(generator)\n\n    print(d_loss, g_loss)\n","739f25d8":"**GAN for MNIST Dataset to Generate Digits**","5d45b173":"**Helper Functions for Visualization**","1fdaf582":"When we look at the results, it can be seen that both generator and discriminator converged very well.  Both of networks losses are low, around 0.2 and 0.5. \n\nAdditionally, after 4th epoch, we can see that network produces realistic images.\n\nHowever, we still see mode-collapse error because even for the last epoch, usually 9, 8, 1 and 3 are generated.","4a053742":"**Optimizers and Loss Function**","51a8a85b":"**Training and Results**","89338824":"**Generator and Discriminator Networks**","16acbf92":"In this work, I download and create popular hand writing digits dataset MNIST. Using this dataset, I built a custom generative adversarial network, to generate non-existing images of hand writing digits.\n\nMain difficulty was preventing mode-collapse risk, which is generator generates same class data to trick discriminator.\n\nAnother difficulty was that discriminator or generator always overpowered against another, which prevents architecture to convergence."}}