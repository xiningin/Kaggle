{"cell_type":{"b1930fda":"code","4a7b0efd":"code","b2b5fa16":"code","035b8cdc":"code","1ec784f1":"code","1f68517f":"code","623bac1a":"code","c5c72d9a":"code","0a1a2fc2":"markdown","8155f2ce":"markdown","b16c481e":"markdown","c594dd9a":"markdown","917f9a0a":"markdown","362f32a3":"markdown","7905ab93":"markdown"},"source":{"b1930fda":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport datetime\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer","4a7b0efd":"df=pd.read_csv('..\/input\/covidglobalcompetition\/covid-global-forcast.csv',parse_dates=[\"Date\"])\ndf[\"Province\/State\"]=df[\"Province\/State\"].fillna(\"\")\ndf=df.sort_values(by=[\"Date\",\"Country\/Region\",\"Province\/State\"])\ndf[\"Location\"]=df[\"Country\/Region\"] +\"\/\"+ df[\"Province\/State\"]\nindex=pd.MultiIndex.from_frame(df[[\"Location\",\"Date\"]])\ndf=df.set_index(index,drop=False)\ndf=df.drop(columns=[\"Country\/Region\",\"Province\/State\",\"Lat\",\"Long\"])\n# Active Case = confirmed - deaths - recovered\ndf['Active'] = df['# ConfirmedCases'] - df['# Fatalities'] - df['# Recovered_cases']\n","b2b5fa16":"df[\"Day\"]=df[\"Date\"].dt.day\ndf[\"Day of the week\"]= df[\"Date\"].dt.weekday\ndays =[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \n                         \"Friday\", \"Saturday\", \"Sunday\"] \ndays_dict={x:days[x] for x in range(len(days))}\ndf[\"Day of the week\"]=df[\"Day of the week\"].map(days_dict)\npandemic_date=datetime.datetime.strptime(\"11 March 2020\",\"%d %B %Y\")\ndf[\"Days after\/before the pandemic\"]=df[\"Date\"] - pandemic_date\ndf.head(10)\n","035b8cdc":"#https:\/\/machinelearningmastery.com\/gentle-introduction-autocorrelation-partial-autocorrelation\/\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf\nplot_acf(df[\"# Fatalities\"], lags=10)\nplot_pacf(df[\"# Fatalities\"], lags=10)\nplot_acf(df[\"# ConfirmedCases\"], lags=10)\nplot_pacf(df[\"# ConfirmedCases\"], lags=10)\ndf[\"Lag_1_fatalities\"]=df.groupby(level=0)[\"# Fatalities\"].shift(1)\ndf[\"Lag_1_confirmed_cases\"]=df.groupby(level=0)[\"# ConfirmedCases\"].shift(1)\ndf=df.dropna()","1ec784f1":"from category_encoders.hashing import HashingEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\ny=df[\"# Fatalities\"].values\n\n\ndf=df.drop(columns=[\"# Fatalities\",\"Date\"])\n\n\nce_hash=HashingEncoder(cols = [\"Location\"])\ntransformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), [\"Day of the week\"]),(\"label\",ce_hash,[\"Location\"])])\nX=transformer.fit_transform(df)\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=21)\n\n","1f68517f":"\ndef RMSLE(predictions,actual_values):\n    # root mean squared logarithmic error.\n    number_of_predictions=np.shape(predictions)[0]\n    predictions=np.log(predictions+1)\n    actual_values=np.log(actual_values+1)\n    squared_differences=np.power(np.subtract(predictions,actual_values),2)\n    total_sum=np.sum(squared_differences)\n    avg_squared_diff=total_sum\/number_of_predictions\n    rmsle=np.sqrt(avg_squared_diff)\n    return rmsle","623bac1a":"from sklearn.linear_model import Lasso,Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import * \n\nmodels = []\nmodels.append(('LASSO', Lasso()))\nmodels.append(('DF', DecisionTreeRegressor()))\nmodels.append(('RF', RandomForestRegressor())) # Ensemble method - collection of many decision trees\nmodels.append(('SVR', SVR(gamma='auto'))) # kernel = linear\n\n# Evaluate each model in turn\nRMSLE_results = []\nMAE_results=[]\nMSE_results=[]\nnames = []\nfor name, model in models:\n    names.append(name)\n    model.fit(X_train,y_train)\n    predictions=model.predict(X_test)\n    RMSLE_results.append(RMSLE(predictions,y_test))\n    MAE_results.append(mean_absolute_error(predictions,y_test))\n    MSE_results.append(mean_squared_error(predictions,y_test))","c5c72d9a":"print(\"Models Performance:\")\nfor name,rsmle,mae,mse in zip(names,RMSLE_results,MAE_results,MSE_results):\n    print(f\"Model Name:{name}\\n RMSLE:{rmsle}\\n MAE:{mae} \\n MSE:{mse}\\n\")","0a1a2fc2":"## Feature Engineering with Time Seris data\n\n\n**What's the purpose of feature engineering?**\nThe goal of feature engineering is to provide strong and ideally simple relationships between new input features and the output feature for the supervised learning algorithm to model.\n\nIn effect, we are are moving complexity.\n\nComplexity exists in the relationships between the input and output data. In the case of time series, there is no concept of input and output variables; we must invent these too and frame the supervised learning problem from scratch.\n\n\n\nDate Time Features: these are components of the time step itself for each observation.\nLag Features: these are values at prior time steps.\nWindow Features: these are a summary of values over a fixed window of prior time steps.\n\n\nFeature Engineering is different when you're are dealing with time seris data.Netherless we can still generate features that can prove indcative for our models . Such as indicating days of the week , the month that it happen and allso year . Deciding what features you want to generate will depend on the dataset and common knowledge is . It doesn't make sense if your data only happens in one year span to generate year as a feature or months but maybe on certain weekdays the event that you're trying to predict happens more often than the others \n\nSimilarly, we can extract a number of features from the date column. Here\u2019s a complete list of features that we can generate:\n![](https:\/\/cdn.analyticsvidhya.com\/wp-content\/uploads\/2019\/11\/time-features.png)\n\n\n\n","8155f2ce":"## <a >Autocorrelation and Partial Autocorrelation<\/a>\n* Autocorrelation - The autocorrelation function (ACF) measures how a series is correlated with itself at different lags.\n* Partial Autocorrelation - The partial autocorrelation function can be interpreted as a regression of the series against its past lags.  The terms can be interpreted the same way as a standard  linear regression, that is the contribution of a change in that particular lag while holding others constant. \n\n*  As all lags are either close to 1 or at least greater than the confidence interval, they are statistically significant.\n\nSource: [Quora](https:\/\/www.quora.com\/What-is-the-difference-among-auto-correlation-partial-auto-correlation-and-inverse-auto-correlation-while-modelling-an-ARIMA-series)\n\n","b16c481e":"# Lag features\n\nThe simplest approach is to predict the value at the next time (t+1) given the value at the previous time (t-1). The supervised learning problem with shifted values looks as follows:\n\nThe Pandas library provides the shift() function to help create these shifted or lag features from a time series dataset. Shifting the dataset by 1 creates the t-1 column, adding a NaN (unknown) value for the first row. The time series dataset without a shift represents the t+1.\n\nshow exemples\n\nHere, we were able to generate lag one feature for our series. But why lag one? Why not five or seven? To answer this let us understand it better below.\n\nThe lag value we choose will depend on the correlation of individual values with its past values.\n\nIf the series has a weekly trend, which means the value last Monday can be used to predict the value for this Monday, you should create lag features for seven days. Getting the drift?","c594dd9a":"## Selecting a Performance Measure \nI'll be using the following three metrics to evaluate models:\n* Root Mean Squared Logarithmic Error(RMSLE)\n* Mean Square Error (MSE)\n* Mean Absolute Error (MAE)","917f9a0a":"![image.png](attachment:image.png)","362f32a3":"https:\/\/pyflux.readthedocs.io\/en\/latest\/dyn_lin.html\nhttps:\/\/alkaline-ml.com\/pmdarima\/auto_examples\/index.html#id1\nhttps:\/\/www.quora.com\/What-is-the-most-useful-Python-library-for-time-series-and-forecasting","7905ab93":"# Project set up \n\n\n## Training , Testing data split\n\nWe need a way to split the data into training and testing data . Training data is used for our machine learning models so that they can learn the right paramters for the task at hand.Testing data will be used to test how well our model can perform in data it hasn't seen before. In essence how well the model generalize to new data.\n\nNormally any machine learning engineer\/data scientist would use some sort of model valdation techinque . Typically it would be cross valdation that is usually [k fold](https:\/\/www.youtube.com\/watch?v=TIgfjmp-4BA).\n\nBut dealing with time seris data is different and shouldn't use a method that select training, validation, and testing data sets by selecting randomly selected samples of the data for each of these categories in a time-agnostic way\n\n\nReferences:\n\nhttps:\/\/towardsdatascience.com\/time-series-nested-cross-validation-76adba623eb9\nhttps:\/\/hub.packtpub.com\/cross-validation-strategies-for-time-series-forecasting-tutorial\/\nhttps:\/\/medium.com\/@samuel.monnier\/cross-validation-tools-for-time-series-ffa1a5a09bf9"}}