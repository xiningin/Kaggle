{"cell_type":{"c561d5eb":"code","7a367a0e":"code","b93d725a":"code","fe93ce77":"code","4f3b3374":"code","bac66cd6":"code","85cf97ea":"code","919bae05":"code","40166217":"markdown","d62d5753":"markdown","ac4ffee7":"markdown","1a83b3aa":"markdown","3d23a643":"markdown","4a3d19d0":"markdown","91c7bdcf":"markdown"},"source":{"c561d5eb":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7a367a0e":"# import our bq_helper package\nimport bq_helper\n# create a helper object for our bigquery dataset\nhacker_news = bq_helper.BigQueryHelper(active_project= \"bigquery-public-data\", \n                                       dataset_name = \"hacker_news\")","b93d725a":"# print a list of all the tables in the hacker_news dataset\nhacker_news.list_tables()","fe93ce77":"hacker_news.table_schema(\"full\") ","4f3b3374":"# this query looks in the full table in the hacker_news\n# dataset, then gets the score column from every row where \n# the type column has \"job\" in it.\nquery = \"\"\"SELECT score\n            FROM `bigquery-public-data.hacker_news.full`\n            WHERE type = \"job\" \"\"\"\n\n# check how big this query will be\nhacker_news.estimate_query_size(query)","bac66cd6":"\n# only run this query if it's less than 100 MB\nhacker_news.query_to_pandas_safe(query, max_gb_scanned=0.1)","85cf97ea":"# check out the scores of job postings (if the \n# query is smaller than 1 gig)\n#ob_post_scores = hacker_news.query_to_pandas_safe(query)","919bae05":"#Since this has returned a dataframe, we can work with it as\n#we would any other dataframe. For example, we can get the mean of the column:\n\n# average score for job posts\n#job_post_scores.score.mean()","40166217":"Credits : #https:\/\/www.kaggle.com\/rtatman\/sql-scavenger-hunt-handbook\/notebook ","d62d5753":"Running this query will take around 225 MB. (The query size is returned in gigabytes.)","ac4ffee7":"Now we want to check out hte way the data is structured. we will look at the schema which is the description of how data is organized  within a dataset. \nwe can use the BigQueryHelper.list_tables() method to list all the files in the hacker news dataset. ","1a83b3aa":"Now that we've created our helper object, we can get started actually interacting with the dataset!","3d23a643":"**SQL**, or Structured Query Language, is a language designed to allow both technical and non-technical users query, manipulate, and transform data from a relational database. And due to its simplicity, SQL databases provide safe and scalable storage for millions of websites and mobile applications.\n\n**Did you know?**\nThere are many popular SQL databases including SQLite, MySQL, Postgres, Oracle and Microsoft SQL Server.* All of them support the common SQL language standard, which is what this site will be teaching, but each implementation can differ in the additional features and storage types it supports.*","4a3d19d0":"Check the size of your query before you run it : \nBigQuery datasets are, true to their name, BIG. The biggest dataset we've got on Kaggle so far is 3 terabytes. Since the monthly quota for BigQuery queries is 5 terabytes, you can easily go past your 30-day quota by running just a couple of queries!\n\nWhat's a query? A query is small piece of SQL code that specifies what data would you like to scan from a databases, and how much of that data you would like returned. (Note that your quota is on data scanned, not the amount of data returned.)\n\nOne way to help avoid this is to estimate how big your query will be before you actually execute it. You can do this with the BigQueryHelper.estimate_query_size() method. For the rest of this notebook, I'll be using an example query that finding the scores for every Hacker News post of the type \"job\". Let's see how much data it will scan if we actually ran it.","91c7bdcf":"1- SQL is an important skill for every data scientist , it comes in third place as most popular software tool for data science. \n2-BigQuery is a Google Cloud product for storing and accessing very large databases very quickly "}}