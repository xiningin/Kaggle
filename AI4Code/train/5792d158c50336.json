{"cell_type":{"f4e1b23d":"code","c9f6d093":"code","cef1643a":"code","ffbed533":"code","7c17dc09":"code","3faf3090":"code","f478955c":"code","4d2188c2":"code","7c1586f2":"code","10649daf":"code","5466e74a":"code","e2c215d5":"code","5d6eed5c":"markdown","8c7d43f7":"markdown","b6c54719":"markdown","c449f54c":"markdown","60c7512f":"markdown","ee5ded50":"markdown","30ee2643":"markdown","d3453198":"markdown"},"source":{"f4e1b23d":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\n# geospatial libraries\nimport geopandas as gpd\nimport rasterio as rs\nfrom rasterio import features as feat\nfrom rasterio.plot import show\n\n# polygon creation\nfrom shapely.geometry import Point, Polygon\n\n# plotting\nimport matplotlib.pyplot as plt","c9f6d093":"SPLIT_SET = np.load('..\/input\/spacenet-6-image-splits\/SN6_10_splits.npy', allow_pickle=True)\nprint(f'num of splits: {len(SPLIT_SET)}')","cef1643a":"# global params\nROOT_DIR = '..\/input\/spacenet-6-multisensor-allweather-mapping\/AOI_11_Rotterdam\/'\nMODE = 'PS-RGB'\nIMAGE_SIZE = (768,768)\nIMAGE_CH = 3\n\nSAR_CH = [1,4,3]  # choose which SAR channel to extract, here I take HH,VV,VH","ffbed533":"def get_image_path(image_id):\n    return f'{ROOT_DIR}{MODE}\/SN6_Train_AOI_11_Rotterdam_{MODE}_{image_id}.tif'\n\ndef norm(plane):\n    \"\"\"make sure if max val exceeds given 92.88, it won't result in value >255\n    and making it become 0 when converted to uint8 bcz of overflow\n    \n    used only for sar images since their values are floats\n    \n    Parameters:\n    -----------\n    plane: numpy array of any size and dimension\n    \"\"\"\n    max_val = plane.max() if plane.max()>92.88 else 92.88\n    plane = plane \/ max_val * 255\n    return plane.astype(np.uint8)","7c17dc09":"def get_binary_mask(image_id, raster):\n    # get geojson file for a given tile\n    geo_path = f'{ROOT_DIR}geojson_buildings\/SN6_Train_AOI_11_Rotterdam_Buildings_{image_id}.geojson'\n    gdf = gpd.read_file(geo_path)\n    num_buildings = gdf.shape[0]\n    \n    # handle error when no buildings are present in a tile\n    if num_buildings==0:\n        mask = np.zeros(IMAGE_SIZE)\n    else:\n        # create binary mask, convert to uint8, resize\n        mask = feat.geometry_mask(\n            gdf.geometry,\n            out_shape=(raster.height, raster.width), # original wxh (900,900)\n            transform=raster.transform,\n            invert=True  # makes pixel buildings == 1\n        )\n\n    return mask, num_buildings","3faf3090":"def get_mask_string(mask):\n    # encode mask to png\n    mask = mask.astype(np.uint8)\n    mask = np.expand_dims(mask, axis=2)  # result: (w,h,1)\n    mask = tf.image.resize(mask, size=IMAGE_SIZE, method='nearest')\n    return tf.io.encode_png(mask)\n\ndef get_image_mask(image_id):\n    \"\"\"Takes an image id, ex: '20190822065725_20190822065959_tile_7283'\n\n    returns:\n        image (string), mask (string), num_building\n    \"\"\"\n    # read image with rasterio\n    raster = rs.open(get_image_path(image_id))\n\n    # grab binary mask\n    mask, num_building = get_binary_mask(image_id, raster)\n    mask = get_mask_string(mask)\n\n    # convert to np array, change to uint8 (encoding doesn't support float), encode to jpeg\n    if MODE == 'SAR-Intensity':\n        # read desired channels and size, then normalize\n        image = norm(raster.read(indexes=SAR_CH, out_shape=IMAGE_SIZE))\n\n    # if non sar image, convert to uint8 when reading\n    else:\n        image = raster.read(out_dtype='uint8', out_shape=IMAGE_SIZE) \n\n    img = rs.plot.reshape_as_image(image)  # fix dimension order, res (w,h,ch)\n    img = tf.io.encode_png(img)\n\n    return img, mask, num_building","f478955c":"image, mask, num_building = get_image_mask('20190822065725_20190822065959_tile_7283')\n\nf,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\nax1.imshow(tf.io.decode_png(image))\nax2.imshow(tf.io.decode_png(mask))\nax2.set_title(f'buildings: {num_building}')\nplt.show()","4d2188c2":"# TFRecord data type\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor. intended for the image data\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))","7c1586f2":"def create_tfrecord():\n    print(f'using {IMAGE_SIZE[0]}x{IMAGE_SIZE[0]} resolution on {MODE} images')\n\n    # create tfrecords for each split\n    for n, image_ids in enumerate(SPLIT_SET):\n        print(f'writing split {n+1} of {len(SPLIT_SET)}')\n        fn = f'{MODE}{n+1}-{len(image_ids)}.tfrec'\n\n        with tf.io.TFRecordWriter(fn) as writer:\n            for k,image_id in enumerate(image_ids):\n                image_str, mask_str, num_building = get_image_mask(image_id)\n\n                feature = {\n                    'image': _bytes_feature(image_str),\n                    'mask': _bytes_feature(mask_str),\n                    'file_name': _bytes_feature(tf.compat.as_bytes(image_id)),\n                    'building': _int64_feature([num_building]),  # single value needs to be arrayed\n                }\n                \n                # write tfrecords\n                example = tf.train.Example(features=tf.train.Features(feature=feature))\n                writer.write(example.SerializeToString())\n                \n                # report each 50th image\n                if k%50==0:\n                    print(k)","10649daf":"# create tf records for optical RGB\nMODE = 'PS-RGB'\ncreate_tfrecord()\n\n# create tf records for SAR\nMODE = 'SAR-Intensity'\ncreate_tfrecord()","5466e74a":"tfrec_format = {\n    'image': tf.io.FixedLenFeature([], tf.string),\n    'mask': tf.io.FixedLenFeature([], tf.string),\n    'file_name': tf.io.FixedLenFeature([], tf.string),\n    'building': tf.io.FixedLenFeature([], tf.int64),\n}\n\ndef parse_example(feature):\n    features = tf.io.parse_single_example(feature, tfrec_format)\n    \n    # decode image and mask\n    image = tf.image.decode_png(features['image'])\n    mask = tf.image.decode_png(features['mask'])\n    \n    data = {}  # dict with file name and building count\n    data['file_name'] = tf.cast(features['file_name'], tf.string)\n    data['num_building'] = tf.cast(features['building'], tf.int32)\n\n    return image, mask, data","e2c215d5":"filenames = tf.io.gfile.glob('.\/*.tfrec')\n\n# load 1 file as TF Dataset\ndataset = tf.data.TFRecordDataset(filenames[0])\n\n# take 1 example and parse\nfor example in dataset.take(1):\n    image, mask, data = parse_example(example)\n    \n    # plot example\n    f,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n    ax1.imshow(image)\n    ax1.set_title(data['file_name'].numpy())\n    ax2.imshow(mask)\n    ax2.set_title(f'buildings: {data[\"num_building\"]}')\n    plt.show()","5d6eed5c":"# Preview image-mask","8c7d43f7":"## Load image with mask\n- both image and mask are encoded with png\n- you could use jpeg to get smaller file size for image but note it only supports 3 channel\n- you can add any preprocessing in this stage, but during training (using TPU), you can only do preprocessing with numpy or tensorflow","b6c54719":"# TFRecords\n- a tfrecord file contains some examples. examples are data features and additional labels that we want to integrate\n- in this notebook, for every example we'll integrate the optical PS-RGB image, annotation mask, image id and total number of building\n- the raster and mask will be stored as BytesList, therefore we need to encode both image as strings","c449f54c":"# Load TFRecord\nHere's how you load and preview data from TFRecord","60c7512f":"# Create TFRecord","ee5ded50":"# Why Use TFRecords?\n- to use TPUs more efficiently\n- seperate data preparation from model crafting\n- prepare data once then focus on optimizing training workflow","30ee2643":"# Loading split\n- read more on image tiling of this dataset [here](https:\/\/www.kaggle.com\/sandhiwangiyana\/sn6-splitting-image-tiles\/)\n- you can't create a validation split by choosing random image_id since most tiles are overlaping -> data leak\n- the best way is to choose an area in the map and grab some tiles that have minimum overlaping with other tiles\n- in my notebook above, I split the region into 10 area and group tiles that are >50% inside each area. Some data leak might happen but we should also consider that some portion of the image is the `no-data` region (black part)","d3453198":"## Load binary mask\n- 1: buildings, 0: background\n- annotations are obtained from respective geojson files"}}