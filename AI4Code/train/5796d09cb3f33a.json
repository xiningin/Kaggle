{"cell_type":{"bed99566":"code","fd7f1a7e":"code","f00a6559":"code","f4c6388d":"code","46285819":"code","457df590":"code","146f9fa1":"code","343b47f1":"code","6ed84e2b":"code","49016cec":"code","bf253e94":"code","922b77b0":"code","3c5f682b":"code","4eca53b3":"code","186079e0":"code","23bebbff":"code","fe78da0d":"code","1d3aa188":"code","8ab1fe9a":"code","5006c259":"markdown","84b658a7":"markdown","41a042b0":"markdown","a2c67b6b":"markdown","7173d942":"markdown","6ca7ad7a":"markdown","ab01ba46":"markdown","b373e6a1":"markdown"},"source":{"bed99566":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\n\nimport tensorflow as tf","fd7f1a7e":"tf.random.set_seed(4445444)","f00a6559":"train_df = pd.read_csv('..\/input\/human-activity-recognition-with-smartphones\/train.csv')\ntest_df = pd.read_csv('..\/input\/human-activity-recognition-with-smartphones\/test.csv')","f4c6388d":"train_df.info()","46285819":"print(\"Train set missing values:\", train_df.isna().sum().sum())","457df590":"test_df.info()","146f9fa1":"print(\"Test set missing values:\", test_df.isna().sum().sum())","343b47f1":"train_df","6ed84e2b":"y_train = train_df['Activity'].copy()\nX_train = train_df.drop('Activity', axis=1).copy()\n\ny_test = test_df['Activity'].copy()\nX_test = test_df.drop('Activity', axis=1).copy()","49016cec":"y_train.value_counts()","bf253e94":"num_classes = 6","922b77b0":"label_encoder = LabelEncoder()\nlabel_encoder.fit(y_train)\n\ny_train = label_encoder.transform(y_train)\ny_test = label_encoder.transform(y_test)","3c5f682b":"scaler = MinMaxScaler()\nscaler.fit(X_train)\n\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","4eca53b3":"inputs = tf.keras.Input(shape=(X_train.shape[1],))\nx = tf.keras.layers.Dense(64, activation='relu')(inputs)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\noutputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)","186079e0":"model.summary()","23bebbff":"batch_size = 32\nepochs = 25\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[\n        tf.keras.callbacks.ModelCheckpoint('.\/model.h5', save_best_only=True),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.1,\n            patience=1\n        )\n    ]\n)","fe78da0d":"plt.figure(figsize=(16, 10))\n\nepochs_range = range(epochs)\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(\n    epochs_range,\n    train_loss,\n    label=\"Training Loss\"\n)\n\nplt.plot(\n    epochs_range,\n    val_loss,\n    label=\"Validation Loss\"\n)\n\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\n\nplt.legend()\nplt.title(\"Loss Over Time\")\n\nplt.show()","1d3aa188":"model.load_weights('.\/model.h5')","8ab1fe9a":"model.evaluate(X_test, y_test)","5006c259":"# Encoding Labels","84b658a7":"# Splitting Data","41a042b0":"# Task for Today  \n\n***\n\n## Human Activity Recognition  \n\nGiven *data about human movement and activity*, let's try to predict the **activity** that a given human is performing.\n\nWe will use a TensorFlow ANN to make our predictions.","a2c67b6b":"# Results","7173d942":"# Scaling Data","6ca7ad7a":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/hbdcJO9CEZs","ab01ba46":"# Modeling\/Training","b373e6a1":"# Getting Started"}}