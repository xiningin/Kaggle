{"cell_type":{"d3d67ec6":"code","414960db":"code","20ba8a98":"code","a1f875d0":"code","e62a203f":"code","9dd88e87":"code","343bb368":"code","8707760f":"code","459a846e":"code","e3e53ee5":"code","b2e4386b":"code","cfde6dc4":"code","25d83f04":"code","291ff55e":"code","525cb12f":"code","7e98ad7d":"code","cbfbfb6e":"markdown","dd1ba09e":"markdown"},"source":{"d3d67ec6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","414960db":"dataset = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ndataset_test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ny = dataset.iloc[:,0].values.astype('int32')\nX = dataset.iloc[:,1:].values.astype('float32')\ntest_X = dataset_test.values.astype('float32')","20ba8a98":"# import matplotlib.pyplot as plt\n# #Convert train datset to (num_images, img_rows, img_cols) format \n# X = X.reshape(X.shape[0], 28, 28)\n\n# for i in range(6, 9):\n#     plt.subplot(330 + (i+1))\n#     plt.imshow(X[i], cmap=plt.get_cmap('gray'))\n#     plt.title(y[i]);","a1f875d0":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 40)","e62a203f":"import keras \nfrom keras.models import Sequential\nfrom keras.layers import Dense","9dd88e87":"from keras.utils import to_categorical\n# X_train = to_categorical(X_train)\ny_train = to_categorical(y_train)\n#y_test = to_categorical(y_test)","343bb368":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout\nfrom keras.activations import relu, sigmoid\nfrom keras.layers import LeakyReLU","8707760f":"# def create_model(layers, activation):\n#     model = Sequential()\n#     for i, nodes in enumerate(layers):\n#         if i==0:\n#             model.add(Dense(nodes,input_dim=X_train.shape[1]))\n#             model.add(Activation(\"relu\"))\n#         elif i==enumerate(layers):\n#             model.add(Dense(nodes,input_dim=X_train.shape[1]))\n#             model.add(Activation(\"softmax\"))\n#         else:\n#             model.add(Dense(nodes))\n#             model.add(Activation(\"relu\"))\n#     model.add(Dense(1)) # Note: no activation beyond this point\n    \n#     model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n#     return model\n    \n# model = KerasClassifier(build_fn=create_model, verbose=0)","459a846e":"# layers = [[397, 397], [784,784, 10], [397, 397, 10],[784,784,784, 10], [397, 397, 397, 10]]\n# activations = ['relu','softmax']\n# param_grid = dict(layers=layers, activation=activations, batch_size = [50, 100, 128, 256], epochs=[30, 100])\n# grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=50)","e3e53ee5":"# grid_result = grid.fit(X_train, y_train)","b2e4386b":"# [grid_result.best_score_,grid_result.best_params_]","cfde6dc4":"#Initialising the ANN\nclassifier = Sequential()\n#adding 1st layer\nclassifier.add(Dense(output_dim = 784, init = \"uniform\", activation = \"relu\", input_dim = 784))\n#adding more layer\nclassifier.add(Dense(output_dim = 397, init = \"uniform\", activation = \"relu\"))\nclassifier.add(Dense(output_dim = 397, init = \"uniform\", activation = \"relu\"))\nclassifier.add(Dense(output_dim = 397, init = \"uniform\", activation = \"relu\"))\nclassifier.add(Dense(output_dim = 397, init = \"uniform\", activation = \"relu\"))\n#adding final layer\nclassifier.add(Dense(output_dim = 10, init = \"uniform\", activation = \"softmax\"))\n#Compiling ANN\nclassifier.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\" )\n#fitting\nclassifier.fit(X_train, y_train, batch_size = 150, nb_epoch = 100)","25d83f04":"y_pred = classifier.predict(X_test)\ny_pred = np.argmax(y_pred,axis = 1)\ny_pred = pd.Series(y_pred,name=\"Label\")","291ff55e":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","525cb12f":"y_pred = classifier.predict(test_X)\ny_pred = np.argmax(y_pred,axis = 1)\ny_pred = pd.Series(y_pred,name=\"Label\")","7e98ad7d":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),y_pred],axis = 1)\n\nsubmission.to_csv('sample_submission1.csv', index=False)","cbfbfb6e":"> They chossing everything for me","dd1ba09e":"1. adam = sofisticated gradient descent -> adam\n2. catagrocal_crossentropy = for more then 2 out come(for two use \"binary_crossentropy\")\n3. softmax = for more then 2 out come(for two use \"sigmoid\")\n4. relu = for ractifire activation.used without for final layer\n"}}