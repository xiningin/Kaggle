{"cell_type":{"1fd6dd94":"code","258e0737":"code","cb93a456":"code","fdcb0e07":"code","6dde323d":"code","5780331f":"code","c402437f":"code","c842176b":"code","1d4f9baf":"code","9588a5e4":"code","80d80bc8":"code","b661ca29":"code","c3f804af":"code","35573bb9":"code","6fb2c1a5":"code","37857b03":"code","b4fadd02":"code","c325903a":"code","e23353b2":"code","c6016084":"code","78353ea9":"code","234965d2":"code","a12d6e03":"code","0400b171":"code","9299b5d8":"code","de8b59d4":"code","b49ce22d":"code","414a51e6":"code","3c05a6b6":"code","266cab60":"code","dac861b4":"code","3dd4eecb":"code","06ebb127":"code","57579182":"code","d9c699b7":"code","e74e46e6":"code","1d02512e":"code","cc97f321":"code","4387e7fa":"code","1d9071ec":"code","5f0a9647":"code","55f49e4c":"code","1ce48d10":"code","058b4eff":"code","140f750f":"code","81fafb91":"code","4d0e4c2a":"code","62b4f973":"code","c709c757":"code","52654822":"code","3c886408":"code","85830985":"code","491c97b0":"code","294b30a7":"code","6f481694":"code","69a599dd":"code","3c7ddabf":"code","5e8c00f8":"code","f97b69b9":"code","cc34bbba":"code","d9315212":"code","4bb6cfe0":"code","73f91335":"code","93aaee46":"code","03f1c6b6":"code","beb2e164":"code","0926d2b2":"code","d12c8a75":"code","3a2b12ab":"code","35c10e41":"code","0dca076f":"code","14c0cb4a":"code","1112dea4":"code","f771e230":"code","240689a1":"code","6332f782":"code","9f7c6c9d":"code","f93c89a1":"code","182ccca3":"code","7d997c0c":"code","7777f81b":"code","05827288":"code","90dabe25":"code","d46d5311":"code","a67841b8":"code","8905d5b3":"code","a25a21ca":"code","7ba0d3a5":"code","4629f29a":"code","f53e7539":"code","4650f560":"markdown","70064658":"markdown","e4a4f3a2":"markdown","e4faa755":"markdown","984078fa":"markdown","87d188b3":"markdown","ca69d980":"markdown","e86f8b44":"markdown","18bde386":"markdown","d7744ef4":"markdown","70cce8c8":"markdown","aba1a98d":"markdown","2ed6d723":"markdown","2d1c203e":"markdown","4786824c":"markdown","d13d6a10":"markdown","02ee06c8":"markdown","169b42f4":"markdown","16a026dd":"markdown","7cc77a6d":"markdown","bf795086":"markdown","e764c5a7":"markdown","73e0ccac":"markdown","319ea4eb":"markdown","88554800":"markdown","0e99f2f2":"markdown","a133d10f":"markdown","7bd2dbae":"markdown","e89082e0":"markdown","24979e39":"markdown","7baf2862":"markdown","f1826bea":"markdown","2f20f236":"markdown","2580618e":"markdown","32eab3e2":"markdown","46f62e02":"markdown","a62ecb83":"markdown","694d3e7c":"markdown","a364794a":"markdown","772c4afe":"markdown","ad26b8b2":"markdown","eda11158":"markdown","2d885839":"markdown","bf7126ae":"markdown","4de0d55b":"markdown","1a8363f3":"markdown","167ddbfe":"markdown","0bcbbe98":"markdown","2986b397":"markdown","508d7dd8":"markdown","2e71b73c":"markdown","ee2a5b6c":"markdown","89510360":"markdown","31429115":"markdown","431ad1b7":"markdown","85142ee9":"markdown","f78699f9":"markdown","cfb4d1cc":"markdown","5a7ef629":"markdown","a6e63d46":"markdown","a664d1f4":"markdown","ad447f0c":"markdown","f35e05eb":"markdown","24cb5175":"markdown","b150d5c0":"markdown","21895e0e":"markdown","d0ae0091":"markdown","97b5d39d":"markdown","ebec5902":"markdown","9d001d42":"markdown","d6a80db4":"markdown","97afceb2":"markdown","2fac183f":"markdown","9d0f5bd3":"markdown","bada45f1":"markdown","9c8794d3":"markdown","e1f92dc6":"markdown","c1081bfe":"markdown","a984615a":"markdown","4c61ec49":"markdown","2957c255":"markdown","0a8831e4":"markdown","d18eade8":"markdown","27e581f5":"markdown","f146c9f5":"markdown","9d6a61e1":"markdown","55091b0a":"markdown","622c24ce":"markdown","c1bc792c":"markdown","3bc8ffec":"markdown","4d7f8824":"markdown","b95203f3":"markdown","1a9cb094":"markdown","2702e0df":"markdown","8c30e36c":"markdown","80e96b2c":"markdown","5166b1ff":"markdown","610cc83c":"markdown","5b46d709":"markdown","9fe253c2":"markdown","99214cfa":"markdown","30f85983":"markdown","0d0a887d":"markdown","c284b087":"markdown","a5034819":"markdown","23cdf333":"markdown","39206dae":"markdown","c8121001":"markdown","77e61981":"markdown","b4ce7ec6":"markdown","5bbbfbf4":"markdown","aeec2923":"markdown","824fe775":"markdown","2b4ba5f5":"markdown","4ac66cfc":"markdown","71a906a3":"markdown","bac8e203":"markdown","338e8d83":"markdown","6b253f65":"markdown","362bf87c":"markdown","dd9d0efb":"markdown","fb05413f":"markdown","80dd578d":"markdown","2bca0a25":"markdown","ec0a09c9":"markdown","5defa1d8":"markdown","0e883e99":"markdown","2b7cd616":"markdown","8bc09903":"markdown","05e30fca":"markdown","3b7fca68":"markdown","7875daed":"markdown","5d564509":"markdown","38086a82":"markdown","7f80f49b":"markdown","47c18f58":"markdown","1c3538ac":"markdown"},"source":{"1fd6dd94":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","258e0737":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\n\n","cb93a456":"# Read the given CSV file, and view some sample records\nretail= pd.read_csv('..\/input\/global-superstore\/GlobalSuperstoreData.csv')\nretail.head()","fdcb0e07":"#Determine the number of rows and columns\nretail.shape","6dde323d":"#Checking the datatypes\nretail.info()","5780331f":"#summary of all the numeric columns in the dataset\nretail.describe()","c402437f":"retail['Market_Segment']= retail['Market']+'_' +retail['Segment']\nretail.head()","c842176b":"retail.nunique().sort_values()","1d4f9baf":"plt.figure(figsize=(12,5))\nprint(retail.Market.value_counts())\nsns.countplot(retail['Market'], palette='rocket')\nplt.title('7 Geographical Market Segments', fontweight='bold', size=20)\nplt.show()","9588a5e4":"plt.figure(figsize=(12,6))\nprint(retail.Segment.value_counts())\nsns.countplot(retail['Segment'], palette='husl')\nplt.title('3 Major Customer Segments',fontweight='bold', size=20)\nplt.show()","80d80bc8":"plt.figure(figsize=(18,6))\nprint(retail.Market_Segment.value_counts())\nsns.countplot(retail['Market_Segment'], palette='ocean')\nplt.title('21 Unique Market-Segments',fontweight='bold', size=20)\nplt.xticks(rotation = 90,fontweight=\"bold\")\nplt.show()","b661ca29":"plt.figure(figsize=(15,6))\nsns.barplot(x='Market', y= 'Profit', hue='Segment', data=retail, palette='Paired')\nplt.title('Market vs Profit', fontweight='bold')\nplt.xticks(rotation = 90,fontweight=\"bold\")\nplt.show()","c3f804af":"plt.figure(figsize=(15,6))\nsns.barplot(x='Market', y= 'Sales', hue='Segment', data=retail, palette='husl')\nplt.title('Market vs Sales', fontweight='bold')\nplt.xticks(rotation = 90,fontweight=\"bold\")\nplt.show()","35573bb9":"retail=retail.drop(['Market','Segment'],axis=1)\nretail.head()","6fb2c1a5":"#convert the order-date into a date-time format for getting it into the Month-year format\nretail['Order Date'] = pd.to_datetime(retail['Order Date']).dt.to_period('m')\nretail= retail.sort_values(by=['Order Date'])\nretail.head()","37857b03":"retail.info()","b4fadd02":"retail_profit= retail.pivot_table( index='Order Date',values='Profit', columns='Market_Segment' ,aggfunc='sum')\nretail_profit.head()","c325903a":"retail_profit.shape","e23353b2":"# perform the train-test split such that you take the 42 months as the train data and the 6 months as the test data.\ntrain_len = 42\ntrain = retail_profit[0:train_len] # first 42 months as training set\ntest = retail_profit[train_len:] # last 6 months as test set","c6016084":"train.shape","78353ea9":"train.head()","234965d2":"mean=np.mean(train)\nstd= np.std(train)\n\nCoV_df= pd.DataFrame(mean)\nCoV_df['std']= std\nCoV_df['CoV'] = std\/mean\nCoV_df= CoV_df.reset_index()\nCoV_df.columns= ['Market_Segment', 'Mean', 'Std', 'CoV']\nCoV_df.sort_values(by='CoV', ascending= True, inplace = True)\nCoV_df","a12d6e03":"Lowest_CoV_value =min(CoV_df[\"CoV\"])\nLowest_CoV_value","0400b171":"sns.barplot(x='Market_Segment', y= 'CoV', data=CoV_df, palette='magma')\nplt.xticks(rotation = 90,fontweight=\"bold\")\nplt.show()","9299b5d8":"retail['Order Date'].dtype","de8b59d4":"retail['Order Date'] = retail['Order Date'].astype(str)\nretail['Order Date']=pd.to_datetime(retail['Order Date'])","b49ce22d":"retail['Order Date'].dtype","414a51e6":"#Drop the data for the rest 20 market segments and keep only the one for the market segment \n#that you found to be the most consistently profitable.\nretail_df= retail[(retail.Market_Segment=='APAC_Consumer')]\nretail_df.head()","3c05a6b6":"retail_df.shape","266cab60":"data=pd.DataFrame(retail_df.groupby(\"Order Date\")['Sales'].sum())\ndata.head()\n#df=retail.groupby('Order Date')\n#df=pd.DataFrame(df['Sales'].sum())\n#df","dac861b4":"data.shape","3dd4eecb":"data.plot(figsize=(12, 4))\nplt.legend(loc='best')\nplt.title('Retail Giant Sales', fontweight='bold', size=20)\nplt.show(block=False)","06ebb127":"data.isnull().sum()","57579182":"#Perform the train-test split for that market segment that takes the 42 months data as the train data and \n#the 6 months data as the test data.\ntrain_len = 42\ntrain = data[0:train_len] # first 120 months as training set\ntest = data[train_len:] # last 24 months as out-of-time test set","d9c699b7":"from pylab import rcParams\nimport statsmodels.api as sm\nrcParams['figure.figsize'] = 12, 8\ndecomposition = sm.tsa.seasonal_decompose(train.Sales, model='additive') # additive seasonal index\n\nfig = decomposition.plot()\nplt.show()","e74e46e6":"decomposition = sm.tsa.seasonal_decompose(train.Sales, model='multiplicative') # multiplicative seasonal index\nfig = decomposition.plot()\nplt.show()","1d02512e":"#Perform the train-test split for that market segment that takes the 42 months data as the train data and \n#the 6 months data as the test data.\ntrain_len = 42\ntrain = data[0:train_len] # first 120 months as training set\ntest = data[train_len:] # last 24 months as out-of-time test set","cc97f321":"y_hat_naive = test.copy()\ny_hat_naive['naive_forecast'] = train['Sales'][train_len-1] #Last observation in the train data","4387e7fa":"plt.figure(figsize=(12,4))\nplt.plot(train['Sales'], label='Train')\nplt.plot(test['Sales'], label='Test')\nplt.plot(y_hat_naive['naive_forecast'], label='Naive forecast')\nplt.legend(loc='best')\nplt.title('Naive Method', fontweight= 'bold')\nplt.show()","1d9071ec":"from sklearn.metrics import mean_squared_error\nrmse = np.sqrt(mean_squared_error(test['Sales'], y_hat_naive['naive_forecast'])).round(2)\nmape = np.round(np.mean(np.abs(test['Sales']-y_hat_naive['naive_forecast'])\/test['Sales'])*100,2)\n\nresults = pd.DataFrame({'Method':['Naive method'], 'MAPE': [mape], 'RMSE': [rmse]})\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","5f0a9647":"y_hat_avg = test.copy()\ny_hat_avg['avg_forecast'] = train['Sales'].mean()# Average of past months sales","55f49e4c":"plt.figure(figsize=(12,4))\nplt.plot(train['Sales'], label='Train')\nplt.plot(test['Sales'], label='Test')\nplt.plot(y_hat_avg['avg_forecast'], label='Simple average forecast')\nplt.legend(loc='best')\nplt.title('Simple Average Method', fontweight='bold')\nplt.show()","1ce48d10":"rmse = np.sqrt(mean_squared_error(test['Sales'], y_hat_avg['avg_forecast'])).round(2)\nmape = np.round(np.mean(np.abs(test['Sales']-y_hat_avg['avg_forecast'])\/test['Sales'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Simple average method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","058b4eff":"y_hat_sma = data.copy()\nma_window = 3  # Considered 3 month window\ny_hat_sma['sma_forecast'] = data['Sales'].rolling(ma_window).mean()\ny_hat_sma['sma_forecast'][train_len:] = y_hat_sma['sma_forecast'][train_len-1]","140f750f":" plt.figure(figsize=(12,4))\nplt.plot(train['Sales'], label='Train')\nplt.plot(test['Sales'], label='Test')\nplt.plot(y_hat_sma['sma_forecast'], label='Simple moving average forecast')\nplt.legend(loc='best')\nplt.title('Simple Moving Average Method', fontweight= 'bold')\nplt.show()","81fafb91":"rmse = np.sqrt(mean_squared_error(test['Sales'], y_hat_sma['sma_forecast'][train_len:])).round(2)\nmape = np.round(np.mean(np.abs(test['Sales']-y_hat_sma['sma_forecast'][train_len:])\/test['Sales'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Simple moving average forecast'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","4d0e4c2a":"from statsmodels.tsa.holtwinters import SimpleExpSmoothing\nmodel = SimpleExpSmoothing(train['Sales'])\nmodel_fit = model.fit(optimized=True)\nmodel_fit.params\ny_hat_ses = test.copy()\ny_hat_ses['ses_forecast'] = model_fit.forecast(6)","62b4f973":"plt.figure(figsize=(12,4))\nplt.plot(train['Sales'], label='Train')\nplt.plot(test['Sales'], label='Test')\nplt.plot(y_hat_ses['ses_forecast'], label='Simple exponential smoothing forecast')\nplt.legend(loc='best')\nplt.title('Simple Exponential Smoothing Method')\nplt.show()","c709c757":"rmse = np.sqrt(mean_squared_error(test['Sales'], y_hat_ses['ses_forecast'])).round(2)\nmape = np.round(np.mean(np.abs(test['Sales']-y_hat_ses['ses_forecast'])\/test['Sales'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Simple exponential smoothing forecast'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults","52654822":"from statsmodels.tsa.holtwinters import ExponentialSmoothing\nmodel = ExponentialSmoothing(np.asarray(train['Sales']) ,seasonal_periods=12 ,trend='additive', seasonal=None)\nmodel_fit = model.fit(smoothing_level=0.2, smoothing_slope=0.01, optimized=False)\nprint(model_fit.params)\ny_hat_holt = test.copy()\ny_hat_holt['holt_forecast'] = model_fit.forecast(len(test))","3c886408":"plt.figure(figsize=(12,4))\nplt.plot( train['Sales'], label='Train')\nplt.plot(test['Sales'], label='Test')\nplt.plot(y_hat_holt['holt_forecast'], label='Holt\\'s exponential smoothing forecast')\nplt.legend(loc='best')\nplt.title('Holt\\'s Exponential Smoothing Method', fontweight='bold')\nplt.show()","85830985":"rmse = np.sqrt(mean_squared_error(test['Sales'], y_hat_holt['holt_forecast'])).round(2)\nmape = np.round(np.mean(np.abs(test['Sales']-y_hat_holt['holt_forecast'])\/test['Sales'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Holt\\'s exponential smoothing method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","491c97b0":"y_hat_hwa = test.copy()\nmodel = ExponentialSmoothing(np.asarray(train['Sales']) ,seasonal_periods=12 ,trend='add', seasonal='add')\nmodel_fit = model.fit(optimized=True)\nprint(model_fit.params)\ny_hat_hwa['hw_forecast'] = model_fit.forecast(6)","294b30a7":"plt.figure(figsize=(12,4))\nplt.plot( train['Sales'], label='Train')\nplt.plot(test['Sales'], label='Test')\nplt.plot(y_hat_hwa['hw_forecast'], label='Holt Winters\\'s additive forecast')\nplt.legend(loc='best')\nplt.title('Holt Winters\\' Additive Method')\nplt.show()","6f481694":"rmse = np.sqrt(mean_squared_error(test['Sales'], y_hat_hwa['hw_forecast'])).round(2)\nmape = np.round(np.mean(np.abs(test['Sales']-y_hat_hwa['hw_forecast'])\/test['Sales'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Holt Winters\\' additive method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","69a599dd":"y_hat_hwm = test.copy()\nmodel = ExponentialSmoothing(np.asarray(train['Sales']) ,seasonal_periods=12 ,trend='add', seasonal='mul')\nmodel_fit = model.fit(optimized=True)\nprint(model_fit.params)\ny_hat_hwm['hw_forecast'] = model_fit.forecast(6)","3c7ddabf":"plt.figure(figsize=(12,4))\nplt.plot( train['Sales'], label='Train')\nplt.plot(test['Sales'], label='Test')\nplt.plot(y_hat_hwm['hw_forecast'], label='Holt Winters\\'s mulitplicative forecast')\nplt.legend(loc='best')\nplt.title('Holt Winters\\' Mulitplicative Method', fontweight='bold')\nplt.show()","5e8c00f8":"rmse = np.sqrt(mean_squared_error(test['Sales'], y_hat_hwm['hw_forecast'])).round(2)\nmape = np.round(np.mean(np.abs(test['Sales']-y_hat_hwm['hw_forecast'])\/test['Sales'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Holt Winters\\' multiplicative method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","f97b69b9":"data['Sales'].plot(figsize=(12, 4))\nplt.legend(loc='best')\nplt.title('Retail Giant Sales', fontweight='bold')\nplt.show(block=False)","cc34bbba":"from statsmodels.tsa.stattools import adfuller\nadf_test = adfuller(data['Sales'])\n\nprint('ADF Statistic: %f' % adf_test[0])\nprint('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\nprint('p-value: %f' % adf_test[1])","d9315212":"from statsmodels.tsa.stattools import kpss\nkpss_test = kpss(data['Sales'])\n\nprint('KPSS Statistic: %f' % kpss_test[0])\nprint('Critical Values @ 0.05: %.2f' % kpss_test[3]['5%'])\nprint('p-value: %f' % kpss_test[1])","4bb6cfe0":"from scipy.stats import boxcox\ndata_boxcox = pd.Series(boxcox(data['Sales'], lmbda=0), index = data.index)\n\nplt.figure(figsize=(12,4))\nplt.plot(data_boxcox, label='After Box Cox tranformation')\nplt.legend(loc='best')\nplt.title('After Box Cox transform', fontweight= 'bold')\nplt.show()","73f91335":"data_boxcox_diff = pd.Series(data_boxcox - data_boxcox.shift(), data.index)\nplt.figure(figsize=(12,4))\nplt.plot(data_boxcox_diff, label='After Box Cox tranformation and differencing')\nplt.legend(loc='best')\nplt.title('After Box Cox transform and differencing', fontweight='bold')\nplt.show()","93aaee46":"data_boxcox_diff.dropna(inplace=True)","03f1c6b6":"data_boxcox_diff.tail()","beb2e164":"adf_test = adfuller(data_boxcox_diff)\n\nprint('ADF Statistic: %f' % adf_test[0])\nprint('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\nprint('p-value: %f' % adf_test[1])","0926d2b2":"kpss_test = kpss(data_boxcox_diff)\n\nprint('KPSS Statistic: %f' % kpss_test[0])\nprint('Critical Values @ 0.05: %.2f' % kpss_test[3]['5%'])\nprint('p-value: %f' % kpss_test[1])","d12c8a75":"from statsmodels.graphics.tsaplots import plot_acf\nplt.figure(figsize=(12,4))\nplot_acf(data_boxcox_diff, ax=plt.gca(), lags = 30)\nplt.show()","3a2b12ab":"from statsmodels.graphics.tsaplots import plot_pacf\nplt.figure(figsize=(12,4))\nplot_pacf(data_boxcox_diff, ax=plt.gca(), lags = 30)\nplt.show()","35c10e41":"train_data_boxcox = data_boxcox[:train_len]\ntest_data_boxcox = data_boxcox[train_len:]\ntrain_data_boxcox_diff = data_boxcox_diff[:train_len-1]\ntest_data_boxcox_diff = data_boxcox_diff[train_len-1:]","0dca076f":"from statsmodels.tsa.arima_model import ARIMA\nmodel = ARIMA(train_data_boxcox_diff, order=(1, 0, 0)) \nmodel_fit = model.fit()\nprint(model_fit.params)","14c0cb4a":"y_hat_ar = data_boxcox_diff.copy()\ny_hat_ar['ar_forecast_boxcox_diff'] = model_fit.predict(data_boxcox_diff.index.min(), data_boxcox_diff.index.max())\ny_hat_ar['ar_forecast_boxcox'] = y_hat_ar['ar_forecast_boxcox_diff'].cumsum()\ny_hat_ar['ar_forecast_boxcox'] = y_hat_ar['ar_forecast_boxcox'].add(data_boxcox[0])\ny_hat_ar['ar_forecast'] = np.exp(y_hat_ar['ar_forecast_boxcox'])","1112dea4":"plt.figure(figsize=(12,4))\nplt.plot(train['Sales'], label='Train')\nplt.plot(test['Sales'], label='Test')\nplt.plot(y_hat_ar['ar_forecast'][test.index.min():], label='Auto regression forecast')\nplt.legend(loc='best')\nplt.title('Auto Regression Method')\nplt.show()","f771e230":"rmse = np.sqrt(mean_squared_error(test['Sales'], y_hat_ar['ar_forecast'][test.index.min():])).round(2)\nmape = np.round(np.mean(np.abs(test['Sales']-y_hat_ar['ar_forecast'][test.index.min():])\/test['Sales'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Autoregressive (AR) method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","240689a1":"model = ARIMA(train_data_boxcox_diff, order=(0, 0, 1)) \nmodel_fit = model.fit()\nprint(model_fit.params)","6332f782":"y_hat_ma = data_boxcox_diff.copy()\ny_hat_ma['ma_forecast_boxcox_diff'] = model_fit.predict(data_boxcox_diff.index.min(), data_boxcox_diff.index.max())\ny_hat_ma['ma_forecast_boxcox'] = y_hat_ma['ma_forecast_boxcox_diff'].cumsum()\ny_hat_ma['ma_forecast_boxcox'] = y_hat_ma['ma_forecast_boxcox'].add(data_boxcox[0])\ny_hat_ma['ma_forecast'] = np.exp(y_hat_ma['ma_forecast_boxcox'])","9f7c6c9d":"plt.figure(figsize=(12,4))\nplt.plot(data['Sales'][:train_len], label='Train')\nplt.plot(data['Sales'][train_len:], label='Test')\nplt.plot(y_hat_ma['ma_forecast'][test.index.min():], label='Moving average forecast')\nplt.legend(loc='best')\nplt.title('Moving Average Method', fontweight='bold')\nplt.show()","f93c89a1":"rmse = np.sqrt(mean_squared_error(test['Sales'], y_hat_ma['ma_forecast'][test.index.min():])).round(2)\nmape = np.round(np.mean(np.abs(test['Sales']-y_hat_ma['ma_forecast'][test.index.min():])\/test['Sales'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Moving Average (MA) method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","182ccca3":"model = ARIMA(train_data_boxcox_diff, order=(1, 0, 1))\nmodel_fit = model.fit()\nprint(model_fit.params)","7d997c0c":"y_hat_arma = data_boxcox_diff.copy()\ny_hat_arma['arma_forecast_boxcox_diff'] = model_fit.predict(data_boxcox_diff.index.min(), data_boxcox_diff.index.max())\ny_hat_arma['arma_forecast_boxcox'] = y_hat_arma['arma_forecast_boxcox_diff'].cumsum()\ny_hat_arma['arma_forecast_boxcox'] = y_hat_arma['arma_forecast_boxcox'].add(data_boxcox[0])\ny_hat_arma['arma_forecast'] = np.exp(y_hat_arma['arma_forecast_boxcox'])","7777f81b":"plt.figure(figsize=(12,4))\nplt.plot( data['Sales'][:train_len-1], label='Train')\nplt.plot(data['Sales'][train_len-1:], label='Test')\nplt.plot(y_hat_arma['arma_forecast'][test.index.min():], label='ARMA forecast')\nplt.legend(loc='best')\nplt.title('ARMA Method')\nplt.show()","05827288":"rmse = np.sqrt(mean_squared_error(test['Sales'], y_hat_arma['arma_forecast'][train_len-1:])).round(2)\nmape = np.round(np.mean(np.abs(test['Sales']-y_hat_arma['arma_forecast'][train_len-1:])\/test['Sales'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Autoregressive moving average (ARMA) method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","90dabe25":"model = ARIMA(train_data_boxcox, order=(1, 1, 1))# p,d,q\nmodel_fit = model.fit()\nprint(model_fit.params)","d46d5311":"y_hat_arima = data_boxcox_diff.copy()\ny_hat_arima['arima_forecast_boxcox_diff'] = model_fit.predict(data_boxcox_diff.index.min(), data_boxcox_diff.index.max())\ny_hat_arima['arima_forecast_boxcox'] = y_hat_arima['arima_forecast_boxcox_diff'].cumsum()\ny_hat_arima['arima_forecast_boxcox'] = y_hat_arima['arima_forecast_boxcox'].add(data_boxcox[0])\ny_hat_arima['arima_forecast'] = np.exp(y_hat_arima['arima_forecast_boxcox'])","a67841b8":"plt.figure(figsize=(12,4))\nplt.plot(train['Sales'], label='Train')\nplt.plot(test['Sales'], label='Test')\nplt.plot(y_hat_arima['arima_forecast'][test.index.min():], label='ARIMA forecast')\nplt.legend(loc='best')\nplt.title('Autoregressive integrated moving average (ARIMA) method', fontweight='bold')\nplt.show()","8905d5b3":"rmse = np.sqrt(mean_squared_error(test['Sales'], y_hat_arima['arima_forecast'][test.index.min():])).round(2)\nmape = np.round(np.mean(np.abs(test['Sales']-y_hat_arima['arima_forecast'][test.index.min():])\/test['Sales'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Autoregressive integrated moving average (ARIMA) method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","a25a21ca":"from statsmodels.tsa.statespace.sarimax import SARIMAX\n\nmodel = SARIMAX(train_data_boxcox, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12)) \nmodel_fit = model.fit()\nprint(model_fit.params)","7ba0d3a5":"y_hat_sarima = data_boxcox_diff.copy()\ny_hat_sarima['sarima_forecast_boxcox'] = model_fit.predict(data_boxcox_diff.index.min(), data_boxcox_diff.index.max())\ny_hat_sarima['sarima_forecast'] = np.exp(y_hat_sarima['sarima_forecast_boxcox'])","4629f29a":"plt.figure(figsize=(12,4))\nplt.plot(train['Sales'], label='Train')\nplt.plot(test['Sales'], label='Test')\nplt.plot(y_hat_sarima['sarima_forecast'][test.index.min():], label='SARIMA forecast')\nplt.legend(loc='best')\nplt.title('Seasonal autoregressive integrated moving average (SARIMA) method',fontweight='bold')\nplt.show()","f53e7539":"rmse = np.sqrt(mean_squared_error(test['Sales'], y_hat_sarima['sarima_forecast'][test.index.min():])).round(2)\nmape = np.round(np.mean(np.abs(test['Sales']-y_hat_sarima['sarima_forecast'][test.index.min():])\/test['Sales'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['(SARIMA) Seasonal autoregressive integrated moving average method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","4650f560":"### <font color=blue>Holt's Exponential Smoothing ","70064658":"\n![data1.JPG](attachment:data1.JPG)","e4a4f3a2":"- ### From the Smoothing Techniques performed we can conclude that Holt Winter's Additive Method is giving the better forecast to of the sales for the 6 months, since the predicted sales are closer to the actual sales.\n- ### We could also see that the RMSE and MAPE values is the least among all the methods done above.","e4faa755":"- #### <font color=green> APAC marketis having higher Sales in all the three segments\n- #### <font color=green> EMEA and Africa have less sales    ","984078fa":"#### <font color=green> The RMSE and MAPE values are slightly high again. ","87d188b3":"In an autoregressive model, the regression technique is used to formulate a time series problem. In order to implement autoregressive models, we forecast future observations using a linear combination of past observations of the same variable ","ca69d980":"### <font color=blue>Simple exponential smoothing","e86f8b44":"#### <font color=green> The forecast captured both trend and seasonality","18bde386":"### Plot train, test and forecast","d7744ef4":"- ### <font color=blue> Naive Method\n    \n    **Forecast = Last month\u2019s sales**","70cce8c8":"### Plot train, test and forecast","aba1a98d":"### Calculate RMSE and MAPE","2ed6d723":"- ARIMA model has three parameters\n- p: Highest lag included in the regression model\n- d: Degree of differencing to make the series stationary\n- q: Number of past error terms included in the regression model","2d1c203e":"- ###  <font color=blue>3.5. Monthly aggregated transaction data","4786824c":"- #### <font color=brown> p-value is 0.024 < 0.05\n- #### <font color=brown>  Which means the series is not Stationary                                                ","d13d6a10":"### Recover original time series forecast","02ee06c8":"### <font color=blue> Augmented Dickey-Fuller (ADF) test","169b42f4":"- #### <font color=green>Forecast of months from 2014-07 to 2015-01 = Average of all past months\u2019 sales\n- #### <font color=green> Green line is the average of all the 42 months sales data \n- #### <font color=green>The green line we forecasted is not showing any trend or seasonality while our train and test data had both trend and seasonality     ","16a026dd":"## <font color=purple> 3.7. Calculate the CoV on the profit for each of the 21 market segments on the train data.","7cc77a6d":"- #### <font color=green>The series looks Stationary \n- #### <font color=green> The fluctuations are under constant limits\n- #### <font color=green>The mean is also centered around zero","bf795086":"### Plot train, test and forecast","e764c5a7":"Lets understand how a time series can be split into its various components that is the Trend, Seasonality, and residuals\n","73e0ccac":"- ### <font color=blue>Simple average method","319ea4eb":"**Forecast = Average of all past months\u2019 sales**","88554800":"## <font color=blue>5.2. Auto Regressive methods","0e99f2f2":"# <font color=purple> 4. Time series analysis","a133d10f":"- ### Plot train, test and forecast","7bd2dbae":"### <font color=blue>Market- Segment vs Sales","e89082e0":"### Calculate RMSE and MAPE","24979e39":"### <font color=blue>Holt Winters' additive method with trend and seasonality","7baf2862":"#### <font color=green> We can see Holt Winter's Additive methid has the lowest  RMSE and MAPE values. Which means error measures are very less in this model","f1826bea":"### <font color=blue>Seasonal auto regressive integrated moving average (SARIMA)","2f20f236":"- ### Additive seasonal decomposition","2580618e":"### <font color=blue>Moving average method (MA)","32eab3e2":"## <font color=purple> 3.9.  Filter the Data for Best Market Segment- APAC Consumer","46f62e02":"- #### <font color=green>We can see that the store caters to 7 different geographical market segments and 3 major customer segments\n- #### <font color=green>There are 21 unique \"Market-Segments\"  ","a62ecb83":"#### <font color=green> We can see that we are able to capture good amount of seasonal variation and even the trend","694d3e7c":"- #### <font color=green> Among all the methods done in the ARIMA above, we can conclude that forecast done using SARIMA method  is able to predict the sales closer to the actual values \n- #### <font color=green> RMSE and  MAPE values for this method is the least among all the methods done    ","a364794a":"### <font color=blue>Market- Segment vs Profit","772c4afe":"- ## <font color=blue>5.1. Simple time series methods","ad26b8b2":"### Calculate RMSE and MAPE","eda11158":"- Captures both level and trend of a time series in the forecast.","2d885839":"### Recover original time series","bf7126ae":"Null Hypothesis $(H0)$: The series is stationary      $p-value > 0.05 $\n\nAlternate Hypothesis:$(H1)$ The series is not stationary   $p-value <= 0.05 $","4de0d55b":"## <font color=purple> 3. Data Preparation","1a8363f3":"### Plot train, test and forecast","167ddbfe":"- The correlation of the time series observations with values of the same series at previous times(lags) is called autocorrelation.\n- ACF describes the autocorrelation between observation and another observation at a prior time step that includes direct and indirect dependence information.","0bcbbe98":"## <font color=purple>3.8. Convert the Order-Date column from \"DateTime\" to \"timestamp\" ","2986b397":"The individual components can be added to get the time-series data","508d7dd8":"#### <font color=green>We can see that The simple exponential model captured the level of a time series.","2e71b73c":"- #### <font color=green>Thus, you will get a timestamp for each order date now as well.","ee2a5b6c":"### Plot train, test and forecast","89510360":"#### <font color=green>We got the data for 48 months now for the 21 Market_Segments\n","31429115":"### Plot train, test and forecast","431ad1b7":"- #### <font color=brown> p-value is 0.0001 < 0.05, Reject the null hypothesis $(H0)$\n- #### <font color=brown> The series is stationary                                            ","85142ee9":"### Calculate RMSE and MAPE","f78699f9":"- **Box-Cox Transformation makes the variance constant in a Time series.**","cfb4d1cc":"The individual components can be multiplied to get the time-series data","5a7ef629":"- ### Multiplicative seasonal decomposition","a6e63d46":"### <font color=blue>Auto regressive integrated moving average (ARIMA)","a664d1f4":"- ### <font color=blue>4.2. Split time series data into training and test set","ad447f0c":"Null Hypothesis $(H0)$: The series is not stationary      $p-value > 0.05 $\n\nAlternate Hypothesis:$(H1)$ The series is stationary   $p-value <= 0.05 $","f35e05eb":"### Recover original time series forecast","24cb5175":"### Plot train, test and forecast","b150d5c0":"### <font color=blue>Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test","21895e0e":"#### <font color=green> We can see high values of MAPE and RMSE\n    ","d0ae0091":"### Calculate RMSE and MAPE","97b5d39d":"- The Moving Average Model models the future forecasts using past forecast errors in a regression-like model.\n- This model has a parameter \u2018q\u2019 called window size over which linear combination of errors are calculated.\n- q is calculated from the Autocorrelation function plot. Select q as the highest lag beyond which autocorrelation dies down","ebec5902":"### <font color=blue>Holt Winter's multiplicative method with trend and seasonality","9d001d42":"- 'd' is the differencing parameter. If d is 1, that means the series now has slope 0 and thus will have no trend. That means, the time series initially had trend.","d6a80db4":"- #### <font color=brown> We can see that p-value is 0.011, which is less than 0.05\n-  #### <font color=brown> So The series is stationary. And Reject the null hypothesis $(H0)$","97afceb2":"- ### <font color=blue>3.3.  Lets drop columns 'Market' and 'Segment'","2fac183f":"#### <font color=green> From the plot we can see that we are able to capture trend in the forecast but could not cature the seasonality","9d0f5bd3":"#### <font color=green> We are able to capture trend but not seasonality in the forecast","bada45f1":"### <font color=blue>Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test","9c8794d3":"**Forecast= Average of only the last few observations to forecast the future**\n - Reduces unsystematic noise in the data","e1f92dc6":"## <font color=blue>Auto regression method (AR)","c1081bfe":"### Plot train, test and forecast","a984615a":"### <font color=blue>Partial autocorrelation function (PACF)","4c61ec49":"### <font color=blue>Auto regression moving average method (ARMA)","2957c255":"- **Differencing is performed by subtracting the previous observation from the current observation.**\n- **Differencing can remove both Trend and seasonality in a Time series.**","0a8831e4":"- ### Plot train, test and forecast","d18eade8":"### Calculate RMSE and MAPE","27e581f5":"- ### <font color=blue> Thus we can conclude that, <font color=brown> Holt Winters additive method <font color=blue>is the best forecasting method in the smoothing technique\n- ### <font color=blue> And  <font color=brown>SARIMA - Seasonal Autoregressive Integrated moving average <font color=blue>is the best method in  ARIMA set of techniques.  ","f146c9f5":"#### <font color=green> There are no misssing values","9d6a61e1":"### Recover original time series","55091b0a":"- ### <font color=blue>4.1. Plot time series data","622c24ce":"### Calculate RMSE and MAPE","c1bc792c":"- It models the future observation as a linear regression of one or more past observations.\n- The parameter of the autoregressive model 'p' is calculated from the Partial Autocorrelation Function plot.\n- Select p as the highest lag where partial autocorrelation is significantly high","3bc8ffec":"Global Mart is an online supergiant store that has worldwide operations. This store takes orders and delivers across the globe and deals with all the major product categories \u2014 consumer, corporate & home office.\n\n \n\nAs a sales manager for this store, you have to forecast the sales of the products for the next 6 months, so that you have a proper estimate and can plan your inventory and business processes accordingly.","4d7f8824":"- SARIMA Model has both non seasonal elements and seasonal elements.\n- SARIMA brings all the features of an ARIMA model with an extra feature - seasonality. \n- SARIMA has six parameters along with seasonality.","b95203f3":"train_data_boxcox_diff","1a9cb094":"- The PACF only describes the direct relationship between an observation and its lag.","2702e0df":"**The two tools to convert a non-stationary series into stationary series are as follows:**\n\n- Differencing\n- Transformation","8c30e36c":"**Forecast= Multiplies the trended forecast by the seasonality**","80e96b2c":"#### <font color=green>We can see that the forecast is a straight line, sloping upwards as Holt's method captured both level and trend","5166b1ff":"### Calculate RMSE and MAPE","610cc83c":"- ### <font color=blue>4.3. Time series Decomposition","5b46d709":"## <font color=purple>1.  Import necessary libraries<\/font>","9fe253c2":"### Plot train, test and forecast","99214cfa":"###  <font color=black>We will directly use p=1, q=1 and d=1 as the forecasts are relatively better for these values.","30f85983":"- ### <font color=green>We can see that Lowest CoV is 0.52272 \n- ### <font color=green>We can infer that the corresponding Marget Segment is \"APAC_Consumer\"\n### The most profitable Market Segment is APAC_Consumer ","0d0a887d":"# <font color=purple>Problem Statement","c284b087":"- ### <font color=blue> Simple moving average method","a5034819":"## <font color=purple> 2. Import time series data: Global Superstore Data","23cdf333":"- **The most recent period's demand multiplied by the smoothing factor.**\n- It is a time series forecasting method for univariate data without a trend or seasonality.\n- The simple exponetial model captures the level of a time series.","39206dae":"### <font color=purple>Differencing to remove trend","c8121001":"### Calculate RMSE and MAPE","77e61981":"# <font color=purple>6. Conclusion","b4ce7ec6":"- #### <font color=green> We can see that Canada and APAC markets with the segments Consumer, Corporate and Home office have more profit\n- #### <font color=green>    Africa and EMEA markets have less profit","5bbbfbf4":"## <font color=purple> 3.6 Test-Train Split","aeec2923":"#### <font color=green> There are 51290 rows and 5 columns in the data set","824fe775":"#### <font color=green> We can see from the plot APAC_Consumer has the highest count","2b4ba5f5":"- ### <font color=blue> 3.4. Convert the order-date into a date-time format","4ac66cfc":"Split time series data into training and test set","71a906a3":"#### <font color=green> The RMSE and MAPE values are high which means too many errors","bac8e203":"### <font color=black>Thus after performing the Stationarity Tests we can see that we are able to convert a non-stationary series into a stationary series to build an Auto Regressive model.","338e8d83":"### <font color=blue>Box Cox transformation to make variance constant","6b253f65":"#### <font color=green>ARMA model captured Trend but no seasonality","362bf87c":"- #### <font color=brown> p-value is 0.100 >= 0.05,  Fail to reject the null hypothesis  $(H0)$\n- #### <font color=brown> The series is stationary                                            ","dd9d0efb":"- ### <font color=blue>3.2. Lets see which are the unique market segments, customer segments and Market-Segments","fb05413f":"### <font color=blue>Augmented Dickey-Fuller (ADF) test","80dd578d":"- We compare the variance between the segments using the coefficient of variation which will normalise the standard deviation with the mean and give a comparative figure on the basis of which we can identify the most profitable market segment.\n- We want to forecast the sales where the market segment is reliable or in other words, there is less variation in the profits.","2bca0a25":"**Forecasts based on level, trend and seasonality of a time series**","ec0a09c9":"- ### Calculate RMSE and MAPE","5defa1d8":"### Stationarity vs non-stationary time series","0e883e99":"### Recover original time series","2b7cd616":"## <font color=blue> Exponential smoothing methods","8bc09903":"## <font color=purple> 3.9. Grouping data based on Order date and finding sales","05e30fca":"### Calculate RMSE and MAPE","3b7fca68":"### <font color=blue>Autocorrelation function (ACF)","7875daed":"### Calculate RMSE and MAPE","5d564509":"# <font color=purple>5. Build and evaluate time series forecast","38086a82":"- #### <font color=green>As we can see in the plot,in order to forecast the sales from month 2014-07 to  2015-01 we we the last or previous month data which is 2014-06\n- #### <font color=green> We can see that the forecast for the next six months is the same value(green line) as the last observation of the blue line    ","7f80f49b":"### Plot train, test and forecast","47c18f58":"- ### <font color=blue> 3.1 Creating a new column Market_Segment","1c3538ac":"- A time series that exhibits the characteristics of an $AR(p)$ and\/or $MA(q)$ process can be modelled using an $ARMA(p,q)$ model\n- It models the future observation as linear regression of one or more past observations and past forecast errors.\n\n"}}