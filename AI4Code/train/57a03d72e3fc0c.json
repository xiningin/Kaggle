{"cell_type":{"1c40d210":"code","3f3e3c84":"code","e568b873":"code","6f41860c":"code","315df07c":"code","2d4c2ccf":"code","ae851940":"code","5d6eaef3":"code","9597b8fc":"code","228c7540":"code","38741c04":"code","f97c5726":"code","acaf0820":"code","6a2e2631":"code","4e68c5a7":"code","862ca385":"code","1f7babef":"code","703ce74d":"code","cafbf4e9":"code","907463cc":"code","b20e0d90":"code","4eb598e3":"code","a5ddb568":"markdown","7f9379a8":"markdown","a578f06e":"markdown","4bebb50f":"markdown","5ab77f68":"markdown","e65b7796":"markdown","3124b244":"markdown","45f403f7":"markdown","89058795":"markdown","b77889bd":"markdown","3f88c380":"markdown","64cb8c65":"markdown","66622bfa":"markdown"},"source":{"1c40d210":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder\nimport tensorflow as tf\nimport numpy as np\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report        ","3f3e3c84":"FILE_PATH = '\/kaggle\/input\/utensils\/utensils_train.csv'","e568b873":"df = pd.read_csv(FILE_PATH)\ndf.head()","6f41860c":"y = df['Label'].values\ny[:5]\n\ndf['Label'].value_counts()","315df07c":"df.isnull().any().describe()","2d4c2ccf":"y_encoder = OneHotEncoder(sparse=False)\ny_encoded = y_encoder.fit_transform(y.reshape(-1, 1))\ny_encoded[:5]","ae851940":"y_encoder.categories_","5d6eaef3":"X = df.drop('Label', axis=1).values\nX = X.reshape(-1, 28, 28, 1)","9597b8fc":"for i in range(10):\n    plt.imshow(X[i].reshape(28, 28))\n    plt.show()\n    print('Label:', y[i])","228c7540":"### Model Training\n###Used Average Pooling since first letter of first name starts with V\n###Used Convolutional Layer with 4 x 4 filter since N = 3 (vowels in surname) + 1\n###Used at least 2 dense layers","38741c04":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, Dropout\nfrom tensorflow import keras \nfrom tensorflow.keras import regularizers\n\nfrom keras.layers import Convolution2D, AvgPool2D\n#create model\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (4,4), activation='relu', input_shape=(28,28,1), kernel_regularizer=regularizers.l2(0.0001)))\nmodel.add(Conv2D(32, (4, 4), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\nmodel.add(AvgPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (4, 4), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\nmodel.add(Conv2D(64, (4, 4), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\nmodel.add(AvgPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.summary()\n\nmodel.compile('adam', 'categorical_crossentropy')\n\ncallbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n\nMODEL_PATH = 'checkpoints\/model_at_{epoch:02d}.mdl'\nos.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(MODEL_PATH)\n\nmodel.fit(X, y_encoded, batch_size=20, epochs=100, validation_split=0.1)","f97c5726":"#### Get the test data \n\ntestdata = pd.read_csv(\"\/kaggle\/input\/utensils\/utensils_test.csv\")\n\nX_test = testdata.drop('Label', axis=1).values\nY_test = testdata['Label'].values\n\ntestdata['Label'].value_counts()","acaf0820":"predictions = model.predict(X_test.reshape(-1,28,28,1))\n","6a2e2631":"roc_auc_score(Y_test, predictions, multi_class=\"ovr\", average=\"macro\")","4e68c5a7":"for i in range(10):\n    plt.imshow(X_test[i].reshape(28,28))\n    plt.show()\n    print('Prediction:', (predictions[i]))","862ca385":"predictions[:5]","1f7babef":"predictions = np.argmax(predictions, axis=1)\npredictions[:15]\n","703ce74d":"print (Y_test[:15])","cafbf4e9":"print(\"The accuracy of the model is\", (accuracy_score(Y_test, predictions)*100), \"%\")","907463cc":"print(classification_report(Y_test, predictions, labels=[0, 1, 2]))","b20e0d90":"cf_matrix = confusion_matrix(Y_test, predictions)\nprint(cf_matrix)","4eb598e3":"import seaborn as sns\nsns.heatmap(cf_matrix, annot=True)","a5ddb568":"### Convert the probabilities to labels\n\nGet the index of the largest probability per row","7f9379a8":"### Verify the images\n\nShow the data to make sure converted the csv rows to their proper images.","a578f06e":"### Precision, Recall and Confusion Matrix","4bebb50f":"## Architecture requirements","5ab77f68":"### Import all the needed modules","e65b7796":"### Convert the labels to one-hot encoding\n\nThis is needed when working with a multi-label problem since the network will predict the probability for each label","3124b244":"# Convolutional Network\n\nThis notebook shows how to apply convolutional networks to image processing problems","45f403f7":"### Try out some predictions\n\nIt's up to you to try the model performance on a separate training set. The prediction is only done to validate the training operation","89058795":"### Define the path of the data source for convenience\n","b77889bd":"### Accuracy","3f88c380":"### Load the dataset and view the first few rows","64cb8c65":"### Fit the model using the training data\n\nIt's better to use the callbacks used in the previous notebook to better training results","66622bfa":"### Remove the labels in the set of our input features\n\nThe data is reshaped with a fourth dimension. This is because the fourth dimension represents the color bands. For example, a normal image has 3 bands (RGB) and this monochromatic data set only has one"}}