{"cell_type":{"2d415a13":"code","07959ca1":"code","2fc7f945":"code","eb6fb47e":"code","b135da8a":"code","aee1c99d":"code","5e8b7c98":"code","465bb848":"code","d626f33c":"code","851a7e02":"code","ab00de46":"markdown","4c4cc86c":"markdown","941c97a4":"markdown","9c3026da":"markdown","50b5a91e":"markdown","cf788f54":"markdown","51d9abf3":"markdown","92e74a28":"markdown","1ff35c91":"markdown","11944bce":"markdown"},"source":{"2d415a13":"# imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as se\nimport warnings\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report,plot_confusion_matrix\nwarnings.filterwarnings('ignore')\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.svm import LinearSVC\n","07959ca1":"# Data Fetch\nfile='..\/input\/customer-personality-analysis\/marketing_campaign.csv'\ndf=pd.read_csv(file, delimiter=\"\\t\")\ndf.head()\n","2fc7f945":"# Selected Columns\nfeatures=['Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Education', 'Marital_Status']\ntarget='Response'\n# X & Y\nX=df[features]\nY=df[target]\n","eb6fb47e":"# Data Cleaning\ndef NullClearner(value):\n\tif(isinstance(value, pd.Series) and (value.dtype in ['float64','int64'])):\n\t\tvalue.fillna(value.mean(),inplace=True)\n\t\treturn value\n\telif(isinstance(value, pd.Series)):\n\t\tvalue.fillna(value.mode()[0],inplace=True)\n\t\treturn value\n\telse:return value\nx=X.columns.to_list()\nfor i in x:\n\tX[i]=NullClearner(X[i])\nY=NullClearner(Y)\n","b135da8a":"# Handling AlphaNumeric Features\nX=pd.get_dummies(X)\n","aee1c99d":"f,ax = plt.subplots(figsize=(18, 18))\nmatrix = np.triu(X.corr())\nse.heatmap(X.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax, mask=matrix)\nplt.show()\n","5e8b7c98":"columns=X.columns\nX=MinMaxScaler().fit_transform(X)\nX=pd.DataFrame(data = X,columns = columns)\nX.head()\n","465bb848":"# Data split for training and testing\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=123)\n","d626f33c":"#Model Parameters\nparam={'C': 1, 'loss': 'squared_hinge', 'tol': 0.05092207964551096, 'penalty': 'l2'}\n# Model Initialization\nmodel=LinearSVC(**param)\nmodel.fit(X_train,Y_train)\n","851a7e02":"# Confusion Matrix\nplot_confusion_matrix(model,X_test,Y_test,cmap=plt.cm.Blues)\n# Classification Report\nprint(classification_report(Y_test,model.predict(X_test)))\n","ab00de46":"### Data Fetch\n Pandas is an open-source, BSD-licensed library providing high-performance,easy-to-use data manipulation and data analysis tools.","4c4cc86c":"# Offer Accept Prediction using BlobCity AutoAI\n\nThis source code is automatically generated using [BlobCity AutoAI](https:\/\/github.com\/blobcity\/autoai)\n\nThe program trains a model to figure if a given customer would accept \/ decline the offer. Supervised learning is used with the `Response` column being considered as the target. \n","941c97a4":"### Data Preprocessing\n Since the majority of the machine learning models in the Sklearn library doesn't handle string category data and Null value,we have to explicitly remove or replace null values.The below snippet have functions, which removes the null value if any exists.","9c3026da":"### Correlation Matrix\n In order to check the correlation between the features, we will plot a correlation matrix. It is effective in summarizing a large amount of data where the goal is to see patterns.","50b5a91e":"### Accuracy Metrics\n Performance metrics are a part of every machine learning pipeline. They tell you if you're making progress, and put a number on it. All machine learning models,whether it's linear regression, or a SOTA technique like BERT, need a metric to judge performance.","cf788f54":"### Model\nSupport vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n\nA Support Vector Machine is a discriminative classifier formally defined by a separating hyperplane. In other terms, for a given known\/labelled data points, the SVM outputs an appropriate hyperplane that classifies the inputted new cases based on the hyperplane. In 2-Dimensional space, this hyperplane is a line separating a plane into two segments where each class or group occupied on either side.\n\nLinearSVC is similar to SVC with kernel='linear'. It has more flexibility in the choice of tuning parameters and is suited for large samples.\n\n* #### Model Tuning Parameters\n1. * penalty -> Specifies the norm used in the penalization.\n   \n2. * Loss -> Specifies the loss function.\n   \n3. * C -> Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive.\n   \n4. * tolerance -> Tolerance for stopping criteria.\n   \n5. * dual -> Select the algorithm to either solve the dual or primal optimization problem. Prefer dual=False when n_samples > n_features.","51d9abf3":"### Feature Selection\n It is the process of reducing the number of input variables when developing a predictive model.Used to reduce the number of input variables to reduce the computational cost of modelling and,in some cases,to improve the performance of the model.","92e74a28":"### Data Rescaling\n Feature scaling or Data scaling is a method used to normalize the range of independent variables or features of data. In data processing, it is also known as data normalization","1ff35c91":"### Train & Test\n The train-test split is a procedure for evaluating the performance of an algorithm.The procedure involves taking a dataset and dividing it into two subsets.The first subset is utilized to fit\/train the model.The second subset is used for prediction.The main motive is to estimate the performance of the model on new data.","11944bce":"### Data Encoding\n Converting the string classes data in the datasets by encoding them to integer either using OneHotEncoding or LabelEncoding"}}