{"cell_type":{"47593433":"code","ae1d3687":"code","e6060b08":"code","b45915e0":"code","9a924dcb":"code","0891a805":"code","e17d10b0":"code","4e2a21c9":"code","896f9f6e":"code","c1d25e4b":"code","16624391":"code","e2555176":"code","65dcd247":"code","08120fba":"code","271a5294":"code","923a3e4b":"code","81b3e36a":"code","e77a4569":"code","d0469c32":"code","2964a9e5":"code","6eb8e2c4":"code","68b51f70":"markdown","8239ab44":"markdown","767e7ef8":"markdown","cf94c4f2":"markdown","e9fef936":"markdown","45bb189a":"markdown","52f2110f":"markdown","9ce1632a":"markdown","fe3911b0":"markdown","3bc23ded":"markdown","12b6ac5e":"markdown","6bf6bf68":"markdown","2baf5e29":"markdown","c2990fd8":"markdown","50b8fc2c":"markdown","51703cae":"markdown","bf4ee89d":"markdown","3091f621":"markdown","9dd32d85":"markdown","699f1594":"markdown","f9a49f66":"markdown","8b6d9492":"markdown","f955e410":"markdown","3b8c0c49":"markdown"},"source":{"47593433":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom wordcloud import WordCloud","ae1d3687":"dataset = pd.read_csv(\"\/kaggle\/input\/all-trumps-twitter-insults-20152021\/trump_insult_tweets_2014_to_2021.csv\")","e6060b08":"tweets_raw = []\ndate = []\n\nfor i in range(len(dataset)-2):\n    tweets_raw.append(dataset[\"tweet\"][i+2])\n    date.append(dataset[\"date\"][i+2][:4])","b45915e0":"tokenizer = tf.keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(tweets_raw)\ntweets = tokenizer.texts_to_sequences(tweets_raw)","9a924dcb":"print(len(tokenizer.word_index))","0891a805":"years = {2015:0, 2016:0, 2017:0, 2018:0, 2019:0, 2020:0, 2021:0}\n\nfor i in date:\n    years[int(i)] += 1\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nyear = ['2015', '2016', '2017', '2018', '2019', '2020', '2021']\nnums = [years[2015], years[2016], years[2017], years[2018], years[2019], years[2020], years[2021]]\nax.bar(year,nums)\nplt.show()","e17d10b0":"def plot_cloud(wordcloud):\n    plt.figure(figsize=(40, 30))\n    plt.imshow(wordcloud) \n    plt.axis(\"off\")","4e2a21c9":"total_tweets=0\n\nfor i in years:\n    total_tweets+=years[i]\n\noverallfreqs={}\n    \nfor word, index in tokenizer.word_index.items():\n      overallfreqs[word] = 0\n    \nfor i in tweets:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            overallfreqs[word] += 1\n            break\n    \n    \nfor word, index in tokenizer.word_index.items():\n      overallfreqs[word] \/= total_tweets\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(overallfreqs)\n\nplot_cloud(wordcloud)","896f9f6e":"total_tweets=years[2015]\n\ntweets2015 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2015[word] = 0\n    \nfor i in tweets[:years[2015]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2015[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2015[word] \/= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2015[word] != 0 and overallfreqs[word] != 0:\n        tweets2015[word] \/= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2015)\n\nplot_cloud(wordcloud)","c1d25e4b":"total_tweets=years[2016]\n\ntweets2016 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2016[word] = 0\n    \nfor i in tweets[years[2015]:years[2015]+years[2016]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2016[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2016[word] \/= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2016[word] != 0 and overallfreqs[word] != 0:\n        tweets2016[word] \/= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2016)\n\nplot_cloud(wordcloud)","16624391":"total_tweets=years[2017]\n\ntweets2017 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2017[word] = 0\n    \nfor i in tweets[years[2015]+years[2016]:years[2015]+years[2016]+years[2017]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2017[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2017[word] \/= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2017[word] != 0 and overallfreqs[word] != 0:\n        tweets2017[word] \/= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2017)\n\nplot_cloud(wordcloud)","e2555176":"total_tweets=years[2018]\n\ntweets2018 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2018[word] = 0\n    \nfor i in tweets[years[2015]+years[2016]+years[2017]:years[2015]+years[2016]+years[2017]+years[2018]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2018[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2018[word] \/= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2018[word] != 0 and overallfreqs[word] != 0:\n        tweets2018[word] \/= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2018)\n\nplot_cloud(wordcloud)","65dcd247":"total_tweets=years[2019]\n\ntweets2019 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2019[word] = 0\n    \nfor i in tweets[years[2015]+years[2016]+years[2017]+years[2018]:years[2015]+years[2016]+years[2017]+years[2018]+years[2019]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2019[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2019[word] \/= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2019[word] != 0 and overallfreqs[word] != 0:\n        tweets2019[word] \/= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2019)\n\nplot_cloud(wordcloud)","08120fba":"total_tweets=years[2020]\n\ntweets2020 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2020[word] = 0\n    \nfor i in tweets[years[2015]+years[2016]+years[2017]+years[2018]+years[2019]:years[2015]+years[2016]+years[2017]+years[2018]+years[2019]+years[2020]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2020[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2020[word] \/= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2020[word] != 0 and overallfreqs[word] != 0:\n        tweets2020[word] \/= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2020)\n\nplot_cloud(wordcloud)","271a5294":"total_tweets=years[2021]\n\ntweets2021 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2021[word] = 0\n    \nfor i in tweets[years[2015]+years[2016]+years[2017]+years[2018]+years[2019]+years[2020]:years[2015]+years[2016]+years[2017]+years[2018]+years[2019]+years[2020]+years[2021]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2021[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2021[word] \/= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2021[word] != 0 and overallfreqs[word] != 0:\n        tweets2021[word] \/= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2021)\n\nplot_cloud(wordcloud)","923a3e4b":"format_date = [[0 for col in range(7)] for row in range(len(date))]\nfor i in range(len(date)):\n    format_date[i][int(date[i])-2015] = 1","81b3e36a":"tweets_train = []\ndate_train = []\ntweets_test = []\ndate_test = []\ntweets_val = []\ndate_val = []\n\nfor i in range(len(tweets_raw)):\n    if i % 10 == 1:\n        tweets_test.append(tweets_raw[i])\n        date_test.append(format_date[i])\n    elif i % 10 == 2:\n        tweets_val.append(tweets_raw[i])\n        date_val.append(format_date[i])\n    else:\n        tweets_train.append(tweets_raw[i])\n        date_train.append(format_date[i])","e77a4569":"encoder = tf.keras.layers.experimental.preprocessing.TextVectorization()\n\nencoder.adapt(tweets_raw)\n\nmodel = tf.keras.Sequential([\n    encoder,\n    tf.keras.layers.Embedding(\n        input_dim=len(encoder.get_vocabulary()),\n        output_dim=64,\n        # Use masking to handle the variable sequence lengths\n        mask_zero=True),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(7)\n])\n\nmodel.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=['accuracy'])\n\nhistory = model.fit(x=tweets_train, y=date_train, batch_size=5, epochs=10,\n                    validation_data=(tweets_val, date_val), callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True\n))","d0469c32":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","2964a9e5":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","6eb8e2c4":"model.evaluate(\n    x=tweets_test, y=date_test, use_multiprocessing=True)","68b51f70":"model and training","8239ab44":"data","767e7ef8":"put it into 2 arrays","cf94c4f2":"words more proportionally common in 2019","e9fef936":"# conclusion","45bb189a":"# can a machine learning model tell what year they are from","52f2110f":"# number of tweets per year","9ce1632a":"words more proportionally common in 2020","fe3911b0":"words more proportionally common in 2016","3bc23ded":"words more proportionally common in 2021","12b6ac5e":"### test results","6bf6bf68":"accuracy history","2baf5e29":"words more proportionally common in 2017","c2990fd8":"# imports","50b8fc2c":"wordcloud for most common words overall, they have alot of simple words like \"I\" and \"and\", but this is expected","51703cae":"number of unique words in all tweets","bf4ee89d":"74.5% accuracy is a high percentage. This could be compared to under what would be under 15% accuracy over the 7 years if it was random. This goes to show that onald Trumps tweets change in strong correlation to the times, focussing on words and phrases more to do with the times, perhaps more controversial in  2020 and 2021.\n\nOverall some words like fake news were particularly common which is interesting too.\n\nIf you have feedback please leave it as a comment.","3091f621":"# wordclouds","9dd32d85":"words more proportionally common in 2018","699f1594":"# data","f9a49f66":"tokenisation","8b6d9492":"get the dataset","f955e410":"loss history","3b8c0c49":"words more proportionally common in 2015"}}