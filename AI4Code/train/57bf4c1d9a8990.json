{"cell_type":{"bf312fab":"code","f081fa8e":"code","ce474c94":"code","4f5bb908":"code","6a5e6295":"code","ca9e8a19":"code","7470f777":"code","0581850b":"code","ae3d66ef":"code","887765a7":"code","5a9d237f":"code","db2dbbb7":"code","45f4bbfe":"code","460ca57d":"code","d39e39c8":"code","aa8b2322":"code","73308e11":"code","b74e38ea":"code","c6bb8b6c":"code","ab467a8b":"code","0e8cafac":"code","5a1f54b0":"code","9f372684":"code","871e1b74":"code","4d166f69":"markdown","4f4d238c":"markdown","5b4555c5":"markdown","95a65a81":"markdown"},"source":{"bf312fab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f081fa8e":"# Importing the libraries.\n\n# Basic libraries.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\n\n# Other base libraries\nimport cv2\nimport os\n\n\n# Train test split.\nfrom sklearn.model_selection import train_test_split\n\n# Image Preprocessing\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Models.\nfrom keras.models import Sequential\n# Models layers.\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n\n# Reduce rate on plateau\nfrom keras.callbacks import ReduceLROnPlateau\n\n# Confusion Matrix from sklearn.\nfrom sklearn.metrics import classification_report,confusion_matrix\n","ce474c94":"# Labels. (Please leave them in caps. As in data these folders are named the same.)\nlabels = ['PNEUMONIA', 'NORMAL']\n# Working size of the image.\nimage_size = 150\n\n# Working on the dataset.\ndef get_training_data(data_dir):\n    data = []\n    for label in labels:\n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        i = 0\n        for img in os.listdir(path):\n            img_arr = cv2.imread(os.path.join(path,img))#cv2.IMREAD_GRAYSCALE)\n            resized_arr = cv2.resize(img_arr, (image_size, image_size))\n            data.append([resized_arr, class_num])\n            i+=1\n            if(i%100==0):\n                print(\"Processing \",i,\" image.\")\n    return np.array(data)","4f5bb908":"train = get_training_data('..\/input\/chest-xray-pneumonia\/chest_xray\/train')\ntest = get_training_data('..\/input\/chest-xray-pneumonia\/chest_xray\/test')\nval = get_training_data('..\/input\/chest-xray-pneumonia\/chest_xray\/val')","6a5e6295":"l=[]\nfor i in train:\n    if(i[1]==0):\n        l.append('PNEUMONIA')\n    else:\n        l.append('NORMAL')\nsns.countplot(l)","ca9e8a19":"plt.figure(figsize = (5,5))\nplt.imshow(train[0][0])\nplt.title(labels[train[0][1]])\n\nplt.figure(figsize= (5,5))\nplt.imshow(train[-1][0])\nplt.title(labels[train[-1][1]])\n","7470f777":"x_train = []\ny_train = []\n\nx_val = []\ny_val = []\n\nx_test = []\ny_test = []\n\n\nfor feature, label in train:\n    x_train.append(feature)\n    y_train.append(label)\n    \nfor feature, label in val:\n    x_val.append(feature)\n    y_val.append(label)\n    \nfor feature, label in test:\n    x_test.append(feature)\n    y_test.append(label)","0581850b":"x_train = np.array(x_train) \/ 255\nx_val = np.array(x_val) \/255\nx_test = np.array(x_test) \/ 255","ae3d66ef":"x_train = x_train.reshape(-1, image_size, image_size, 3)\nx_val = x_val.reshape(-1, image_size, image_size, 3)\nx_test = x_test.reshape(-1, image_size, image_size,3)\n\ny_train = np.array(y_train)\ny_val = np.array(y_val)\ny_test = np.array(y_test)","887765a7":"x_train.shape","5a9d237f":"datagen = ImageDataGenerator(\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    rotation_range=30,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True, vertical_flip=False\n)\n\ndatagen.fit(x_train)\nx_train.shape","db2dbbb7":"import tensorflow as tf\nfrom tensorflow.keras.applications.vgg16 import VGG16\nmodel2 = VGG16(input_shape=(150,150,3), weights = 'imagenet', include_top = False)\nmodel2.trainable = False\nmodel = tf.keras.Sequential([\n    model2,\n    Flatten(),\n    Dense(1024, activation = 'relu'),\n    Dense(1, activation = 'sigmoid')\n])\nmodel.compile(optimizer = 'rmsprop' , loss='binary_crossentropy', metrics = ['accuracy'])\nmodel.summary()","45f4bbfe":"history=model.fit(x_train, y_train, epochs = 12, validation_data = (x_val, y_val))","460ca57d":"print(\"Loss of the model is \", model.evaluate(x_test, y_test)[0])\nprint(\"Accuracy of the model is \", model.evaluate(x_test, y_test)[1]*100, \"%\")","d39e39c8":"epochs = [i for i in range(12)]\nfig, ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nfig.set_size_inches(20, 10)\n\nax[0].plot(epochs, train_acc, 'go-', label = 'Training Accuracy')\nax[0].plot(epochs, val_acc, 'ro-', label = 'Validation Accuracy')\nax[0].set_title('Training & Validation Accuracy')\nax[0].legend()\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Accuracy')\n\nax[1].plot(epochs, train_loss, 'g-o', label ='Training Loss')\nax[1].plot(epochs, val_loss, 'r-o', label = 'Validation Loss')\nax[1].set_title('Testing Accuracy & Loss')\nax[1].legend()\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Training & Validation Loss')\nplt.show()","aa8b2322":"predictions = model.predict_classes(x_test)\npredictions = predictions.reshape(1, -1 )[0]\npredictions[:15]","73308e11":"print(classification_report(y_test, predictions, target_names= ['Pneumonia (class 0)', 'Normal (class 1)']))\n","b74e38ea":"cm = confusion_matrix(y_test, predictions)\ncm","c6bb8b6c":"cm = pd.DataFrame(cm, index = ['0', '1'],  columns=['0','1'])","ab467a8b":"plt.figure(figsize = (10,10))\nsns.heatmap(cm, cmap = 'Blues', linewidth = 1, annot = True, xticklabels=labels, yticklabels=labels)","0e8cafac":"correct = np.nonzero(predictions == y_test)[0]\nincorrect = np.nonzero(predictions != y_test)[0]","5a1f54b0":"i = 0\nfor c in correct[:6]:\n    plt.subplot(3,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(x_test[c].reshape(150,150), cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted Class {},Actual Class {}\".format(predictions[c], y_test[c]))\n    plt.tight_layout()\n    i += 1\n","9f372684":"i = 0\nfor c in incorrect[:6]:\n    plt.subplot(3,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(x_test[c].reshape(150,150), cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted Class {},Actual Class {}\".format(predictions[c], y_test[c]))\n    plt.tight_layout()\n    i += 1","871e1b74":"# File browsing function\n\ndirectory = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train'\nfor image in os.listdir(directory):\n    print(os.path.join(directory, image))","4d166f69":"A grayscale normalization reduces the effect of illumination differences. ","4f4d238c":"# Post-modeling analysis","5b4555c5":"Data Augmentation","95a65a81":"A CNN converges faster on 0 to 1 than on 0 to 255."}}