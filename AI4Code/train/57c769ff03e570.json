{"cell_type":{"0311f0f7":"code","4d187d30":"code","a6c945f1":"code","a1aef60f":"code","2c54c2ef":"code","56ef692e":"code","be812148":"code","91355719":"code","d8fbf5e1":"code","c422f2fd":"code","88f6e361":"code","f1a511ed":"code","d6bf7b8d":"code","73eba0df":"code","342f1963":"code","5ea35e48":"code","7273ef34":"code","82e8d7c2":"code","7e130ae8":"code","fca824dc":"code","802c677e":"code","bb5a5bda":"code","66a62ba6":"code","f21f18dc":"code","cdfc0a0e":"code","4adf435b":"code","a0c28889":"code","6cd841f2":"code","a4c277cc":"markdown","09d4659b":"markdown","04dfc3e6":"markdown","1d66dea6":"markdown","cd1a66f5":"markdown","5dca177e":"markdown","1a029e76":"markdown"},"source":{"0311f0f7":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import preprocessing as p\n\nfrom tensorflow.keras.applications import vgg16\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)","4d187d30":"import warnings\nwarnings.filterwarnings('ignore')","a6c945f1":"data_augmentation = tf.keras.Sequential([\n                        p.RandomFlip(\"horizontal\"),\n                        p.RandomRotation(0.2),\n                        p.RandomZoom(0.2),\n                        p.RandomHeight(0.2),\n                        p.RandomWidth(0.2),\n                        ], name =\"data_augmentation\")","a1aef60f":"IMAGE_SHAPE = (224, 224)\n\ntrain_dir = \"..\/input\/d\/undersc0re\/fake-vs-real-face-classification\/traing_set\/traing_set\/train\"\nvalid_dir = \"..\/input\/d\/undersc0re\/fake-vs-real-face-classification\/traing_set\/traing_set\/Validation\"\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\n\n\ntrain_data = train_datagen.flow_from_directory(directory=train_dir,\n                                                                 target_size = IMAGE_SHAPE,\n                                                                 class_mode=\"categorical\",\n                                                                 batch_size=32)\n\nvalid_data = validation_datagen.flow_from_directory(directory=valid_dir,\n                                                                 target_size = IMAGE_SHAPE,\n                                                                 class_mode=\"categorical\")","2c54c2ef":"vgg_conv = vgg16.VGG16(weights=\"imagenet\", include_top=False, input_shape= (224, 224, 3))","56ef692e":"for layer in vgg_conv.layers[:]:\n    layer.trainable = False","be812148":"input_shape = (224, 224, 3)\nbase_model = vgg_conv\n\ninputs = tf.keras.layers.Input(shape=input_shape, name=\"input_layer\")\nx = data_augmentation(inputs)\nx = base_model(x, training=False)\n\nx =  tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\noutputs = tf.keras.layers.Dense(2, activation=\"sigmoid\", name=\"output_layer\")(x)\n\nmodel1_vgg = tf.keras.Model(inputs, outputs)","91355719":"model2_vgg = tf.keras.Sequential()\nmodel2_vgg.add(vgg_conv)\n\nmodel2_vgg.add(tf.keras.layers.Flatten())\nmodel2_vgg.add(tf.keras.layers.Dense(1024, activation='relu'))\nmodel2_vgg.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel2_vgg.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel2_vgg.add(tf.keras.layers.Dropout(0.5))\nmodel2_vgg.add(tf.keras.layers.Dense(2, activation='sigmoid'))","d8fbf5e1":"model1_vgg.compile(loss=\"binary_crossentropy\",\n                  optimizer=tf.keras.optimizers.Adam(lr=0.001),\n                  metrics=[\"accuracy\"]\n                  \n)\n\n\nhistory = model1_vgg.fit(train_data,\n                        steps_per_epoch=train_data.samples\/train_data.batch_size,\n                        epochs=100,\n                        validation_data=valid_data,\n                        validation_steps=valid_data.samples\/valid_data.batch_size,\n                        verbose=1                    \n)","c422f2fd":"model1_vgg.evaluate(valid_data)","88f6e361":"model2_vgg.compile(loss=\"binary_crossentropy\",\n                  optimizer=tf.keras.optimizers.Adam(lr=0.001),\n                  metrics=[\"accuracy\"]\n                  \n)\n\n\nhistory = model2_vgg.fit(train_data,\n                        steps_per_epoch=train_data.samples\/train_data.batch_size,\n                        epochs=100,\n                        validation_data=valid_data,\n                        validation_steps=valid_data.samples\/valid_data.batch_size,\n                        verbose=1                    \n)","f1a511ed":"model2_vgg.evaluate(valid_data)","d6bf7b8d":"import matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","73eba0df":"model2_vgg.summary()","342f1963":"model2_vgg.save(\"model_vgg.h5\")","5ea35e48":"for i, layer in enumerate(vgg_conv.layers):\n    print(i, layer.name, layer.trainable)","7273ef34":"for layer in vgg_conv.layers[15:]:\n    layer.trainable = True","82e8d7c2":"model3_vgg = tf.keras.Sequential()\nmodel3_vgg.add(vgg_conv)\n\nmodel3_vgg.add(tf.keras.layers.Flatten())\nmodel3_vgg.add(tf.keras.layers.Dense(1024, activation='relu'))\nmodel3_vgg.add(tf.keras.layers.Dropout(0.5))\nmodel3_vgg.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n\nmodel3_vgg.summary()","7e130ae8":"model3_vgg.compile(loss=\"binary_crossentropy\",\n                  optimizer=tf.keras.optimizers.Adam(lr=0.001),\n                  metrics=[\"accuracy\"]\n                  \n)\n\nhistory = model3_vgg.fit(train_data,\n                        steps_per_epoch=train_data.samples\/train_data.batch_size,\n                        epochs=100,\n                        validation_data=valid_data,\n                        validation_steps=valid_data.samples\/valid_data.batch_size,\n                        verbose=1                    \n)","fca824dc":"model3_vgg.evaluate(valid_data)","802c677e":"img = \"..\/input\/d\/undersc0re\/fake-vs-real-face-classification\/test\/test\/264.jpg\"","bb5a5bda":"import cv2\nimport matplotlib.pyplot as plt\n\n# cv2.imread(img)\nplt.imshow(cv2.imread(img)[...,::-1])\nplt.show()","66a62ba6":"image = cv2.imread(img)[...,::-1]\nimage = cv2.resize(image, (224, 224),  interpolation = cv2.INTER_AREA)\nimage = image.astype('float32')\nimage \/= 255","f21f18dc":"print(model2_vgg.predict_generator(image.reshape(1, 224, 224, 3)))\nprint(np.argmax(model2_vgg.predict_generator(image.reshape(1, 224, 224, 3))))","cdfc0a0e":"import os\n\n\npred_files = \"..\/input\/d\/undersc0re\/fake-vs-real-face-classification\/test\/test\"\nimage_list = sorted(list(os.listdir(pred_files)))\n\ns = pd.DataFrame(image_list, columns=['ff'])\ns[['num','jj']] = s.ff.str.split(\".\",expand=True)\ns = s.astype({\"num\": int})\ns = s.sort_values(by='num')\ns = s.astype({\"num\": object})\ns['jj'] = '.' + s['jj'].astype(str)\ns['final'] = s['num'].astype(str) + s['jj']\n\nimagelist= s['final'].tolist()","4adf435b":"import numpy as np\n\nscore_pred = []\n\nfor i in imagelist:\n    \n    img =  cv2.imread(os.path.join(pred_files ,i))[...,::-1]\n    img = cv2.resize(img, (224, 224),  interpolation = cv2.INTER_AREA)\n    img = img.astype('float32')\n    img \/= 255\n    \n    result = np.argmax(model2_vgg.predict(img.reshape(1, 224, 224, 3)))\n    score_pred.append(result)","a0c28889":"pred_submission = pd.DataFrame(list(zip(list(range(0,332)), score_pred)),\n             columns =['file_id','label'])","6cd841f2":"pred_submission.to_csv(\"submit_vgg_1X60.csv\", index=False)","a4c277cc":"**Making Predictions**","09d4659b":"**Using Sequential API**","04dfc3e6":"### VGG16 ","1d66dea6":"**Compiling and Fitting Both model**","cd1a66f5":"**Making predictions on all the data**","5dca177e":"**Using Function API and Data Augmentation**","1a029e76":"**Training with Last few layers of Vgg**"}}