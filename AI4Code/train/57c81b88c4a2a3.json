{"cell_type":{"80ec85a4":"code","579ee4bf":"code","3b7375a9":"code","bd89552b":"code","c2927473":"code","04742b1b":"code","e116bdca":"code","3e6f6d50":"code","998b4677":"code","d0a4870c":"code","ad033519":"code","fef960f5":"code","c039fdd0":"code","5de5e368":"code","f6f823f1":"code","5bb555ba":"markdown","ea905259":"markdown","e59d6ed6":"markdown"},"source":{"80ec85a4":"from __future__ import print_function, division\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils, models\nimport torch.nn.functional as F\nfrom tqdm import tqdm, tqdm_notebook\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport time\nimport os\n\nplt.ion()   # interactive mode\nmultiGPU = False\n\n%matplotlib inline","579ee4bf":"TRAIN_IMG_PATH = \"..\/input\/train\/train\/\"\nTEST_IMG_PATH = \"..\/input\/test\/test\/\"\nLABELS_CSV_PATH = \"..\/input\/train.csv\"\nSAMPLE_SUB_PATH = \"..\/input\/sample_submission.csv\"","3b7375a9":"class CactusDataset(Dataset):\n    \"\"\"Cactus identification dataset.\"\"\"\n\n    def __init__(self, img_dir, dataframe, transform=None):\n        \"\"\"\n        Args:\n            img_dir (string): Directory with all the images.        \n            dataframe (pandas.core.frame.DataFrame): Pandas dataframe obtained\n                by read_csv().\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.labels_frame = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels_frame)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.img_dir, self.labels_frame.id[idx]) \n        image = Image.open(img_name)\n        label = self.labels_frame.has_cactus[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return [image, label] \n","bd89552b":"dframe = pd.read_csv(LABELS_CSV_PATH)\ncut = int(len(dframe)*0.95)\ntrain, test = np.split(dframe, [cut], axis=0)\ntest = test.reset_index(drop=True)\n\ntrain_ds = CactusDataset(TRAIN_IMG_PATH, train)\ntest_ds = CactusDataset(TRAIN_IMG_PATH, test)\nidx = 1\nplt.imshow(train_ds[idx][0])\nprint(train_ds[idx][1])\nprint(\"Shape of the image is: \", train_ds[idx][0].size)\n","c2927473":"data_transform = transforms.Compose([\n        transforms.RandomResizedCrop(32),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ToTensor(),\n    ])","04742b1b":"train_ds = CactusDataset(TRAIN_IMG_PATH, train, data_transform)\ntest_ds = CactusDataset(TRAIN_IMG_PATH, test, data_transform)\ndatasets = {\"train\": train_ds, \"val\": test_ds}\n\nidx = 29\nprint(train_ds[idx][1])\nprint(\"Shape of the image is: \", train_ds[idx][0].shape)","e116bdca":"trainloader = DataLoader(train_ds, batch_size=32,\n                        shuffle=True, num_workers=0)\n\ntestloader = DataLoader(test_ds, batch_size=4,\n                        shuffle=True, num_workers=0)\n\ndataloaders = {\"train\": trainloader, \"val\": testloader}","3e6f6d50":"num_epochs = 25\nnum_classes = 2\nbatch_size = 128\nlearning_rate = 0.002\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\ndevice","998b4677":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n\n    for epoch in tqdm_notebook(range(num_epochs)):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        \n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:     \n            since_epoch = time.time()\n            if phase == 'train':\n                scheduler.step()\n                model.train(True)  # Set model to training mode\n            else:\n                model.train(False)  # Set model to evaluate mode\n    \n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for data in tqdm_notebook(dataloaders[phase]):\n                # get the inputs\n                inputs, labels = data\n\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                # zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    \n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                    \n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ len(datasets[phase])\n            epoch_acc = running_corrects.double() \/ len(datasets[phase])\n\n            time_elapsed_epoch = time.time() - since_epoch\n            print('{} Loss: {:.4f} Acc: {:.4f} in {:.0f}m {:.0f}s'.format(\n                phase, epoch_loss, epoch_acc, time_elapsed_epoch \/\/ 60, time_elapsed_epoch % 60))\n            \n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = model.state_dict()\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    return model","d0a4870c":"class CactiCNN(nn.Module):\n    def __init__(self):\n        # ancestor constructor call\n        super(CactiCNN, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2)\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2)\n        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2)\n        self.conv6 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=2)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.bn4 = nn.BatchNorm2d(256)\n        self.bn5 = nn.BatchNorm2d(512)\n        self.bn6 = nn.BatchNorm2d(1024)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=1)\n        self.avg = nn.AvgPool2d(4)\n        self.fc = nn.Linear(1024 * 9 * 9, 2) # !!!\n   \n    def forward(self, x):\n        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x)))) # first convolutional layer then batchnorm, then activation then pooling layer.\n        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))\n        x = self.pool(F.leaky_relu(self.bn4(self.conv4(x))))\n        x = self.pool(F.leaky_relu(self.bn5(self.conv5(x))))\n        x = self.pool(F.relu(self.bn6(self.conv6(x))))\n        x = self.avg(x)\n        #print(x.shape) # lifehack to find out the correct dimension for the Linear Layer\n        x = x.view(-1, 1024 * 9 * 9) # !!!\n        x = self.fc(x)\n        return x","ad033519":"model = CactiCNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)","fef960f5":"model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler,\n                           num_epochs=num_epochs)","c039fdd0":"submission_df = pd.read_csv(SAMPLE_SUB_PATH)\noutput_df = pd.DataFrame(index=submission_df.index, columns=submission_df.keys() )\noutput_df['id'] = submission_df['id']\nsubmission_df['target'] =  [0] * len(submission_df)\n\ntdata_transform = transforms.Compose([\n        transforms.CenterCrop(32),\n        transforms.ToTensor(),\n])\n\nsubmission_ds = CactusDataset(TEST_IMG_PATH, submission_df, tdata_transform)\n\nsub_loader = DataLoader(submission_ds, batch_size=1,\n                        shuffle=False, num_workers=0)\n\n\ndef test_sumission(model):\n    since = time.time()\n    sub_outputs = []\n    model.train(False)  # Set model to evaluate mode\n    # Iterate over data.\n    prediction = []\n    for data in sub_loader:\n        # get the inputs\n        inputs, labels = data\n\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # forward\n        outputs = model(inputs)\n        _, pred = torch.max(outputs.data, 1)\n        prediction.append(int(pred))\n      \n    time_elapsed = time.time() - since\n    print('Run complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n\n    return prediction","5de5e368":"sub = pd.read_csv('..\/input\/sample_submission.csv')\nsub['has_cactus'] = test_sumission(model_ft)\nsub.to_csv('submission1.csv', index= False)","f6f823f1":"sub.head()","5bb555ba":"## Training","ea905259":"## Submission","e59d6ed6":"## Preparing Dataset"}}