{"cell_type":{"1e675132":"code","55dbfe9d":"code","f3f8defb":"code","1b88928b":"code","58cf01e7":"code","735d3ca1":"code","cd71fffb":"code","da915aa1":"code","1772d518":"code","1634c996":"code","15e3e9e3":"code","978fbbf1":"code","c7280b76":"code","a76604bd":"code","5b187e39":"code","36b017bd":"code","f4763542":"code","99602336":"code","a8a74fd9":"code","069d245b":"markdown","382b3370":"markdown","df042284":"markdown","49f0b71f":"markdown","e8287055":"markdown","c6e873d4":"markdown"},"source":{"1e675132":"import os\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport zipfile\nimport cv2\nimport tqdm\nimport matplotlib.pyplot as plt","55dbfe9d":"home = str(Path.home())\nprint(\"HOME_FOLDER is \", home)\n\nif not os.path.exists(home+\"\/.deepface\"):\n    os.mkdir(home+\"\/.deepface\")\n    \nif not os.path.exists(home+\"\/.deepface\/weights\"):    \n    os.mkdir(home+\"\/.deepface\/weights\")\n\n#os.listdir('..\/input\/pretrained-models')\n\nimport shutil\n\nshutil.copy(\"..\/input\/pretrained-models\/vgg_face_weights.h5\", home+\"\/.deepface\/weights\")\nshutil.copy(\"..\/input\/pretrained-models\/facenet_weights.h5\", home+\"\/.deepface\/weights\")\nshutil.copy(\"..\/input\/pretrained-models\/arcface_weights.h5\", home+\"\/.deepface\/weights\")","f3f8defb":"pd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","1b88928b":"TRAIN_ZIP = '..\/input\/recognizing-faces-in-the-wild\/train.zip'\nTEST_ZIP='..\/input\/recognizing-faces-in-the-wild\/test.zip'","58cf01e7":"print(\"unzipping train set\")\nwith zipfile.ZipFile(TRAIN_ZIP, 'r') as zip_ref:\n    zip_ref.extractall(\"..\/output\/kaggle\/working\/train\")\n\nprint(\"unzipping test set\")\nwith zipfile.ZipFile(TEST_ZIP, 'r') as zip_ref:\n    zip_ref.extractall(\"..\/output\/kaggle\/working\/test\")","735d3ca1":"df = pd.read_csv(\"..\/input\/recognizing-faces-in-the-wild\/train_relationships.csv\")","cd71fffb":"df.head()","da915aa1":"def findCustomImages(path):\n    images = []\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            images.append(os.path.join(dirname, filename))\n    \n    return images","1772d518":"root = \"..\/output\/kaggle\/working\/train\/\"\n\nsamples = []\nfor index, instance in df.iterrows():\n    person1 = root+instance.p1\n    person2 = root+instance.p2\n    \n    person1_images = findCustomImages(person1)\n    person2_images = findCustomImages(person2)\n    \n    for i in person1_images:\n        for j in person2_images:\n            sample = []\n            sample.append(i)\n            sample.append(j)\n            samples.append(sample)","1634c996":"df = pd.DataFrame(samples, columns = [\"p1\", \"p2\"])","15e3e9e3":"df.head()","978fbbf1":"print(\"There are \",df.shape[0],\" image pairs existing as a relative\")","c7280b76":"!pip install gdown==3.10.1 --no-deps\n!pip install mtcnn==0.1.0 --no-deps\n!pip install deepface==0.0.51 --no-deps","a76604bd":"from deepface import DeepFace","5b187e39":"model_names = [\"VGG-Face\", \"Facenet\", \"ArcFace\"]\nmetrics = [\"cosine\", \"euclidean\"]","36b017bd":"df = df.sample(100)","f4763542":"for model_name in model_names:\n    \n    model = DeepFace.build_model(model_name)\n    \n    for metric in metrics:\n    \n        obj = DeepFace.verify(df[['p1', 'p2']].values.tolist(), model_name = model_name, model = model\n                                           , distance_metric = metric, enforce_detection = False)\n    \n        distances = []\n        for key in obj.keys():\n            distance = obj[key][\"distance\"]\n            distances.append(distance)\n\n        df[\"%s_%s\" % (model_name, metric)] = distances","99602336":"df.head()","a8a74fd9":"for model in model_names:\n    for metric in metrics:\n        print(\"Distribution for \",model,\" and \", metric,\" pair\")\n        df['%s_%s' % (model, metric)].plot.kde()\n        plt.show()\n        print(\"-----------------------------------------\")","069d245b":"## DeepFace\n\n[**DeepFace**](https:\/\/github.com\/serengil\/deepface) is a lightweight face recognition and facial attribute analysis package for Python. You can apply facial analysis with just a few lines of code. It is fully open source and available on PyPI. All you need is to call **pip install deepface** command.\n\nIt supports the most popular face recognition models including **VGG-Face**, **Google FaceNet**, **OpenFace**, **Facebook DeepFace**,**DeepID**, **Dlib** and **ArcFace**. Besides, it can analyze facial attributes such as **emotion**, **age**, **gender** and **race** prediction as well in its facial attribute analysis module.\n\nGitHub repo: https:\/\/github.com\/serengil\/deepface\n\nThere are many ways to support a project - starring\u2b50\ufe0f it is just one.","382b3370":"# Face Recognition","df042284":"Deepface will download pre-trained weights from Google Drive source but I copied weights in the inputs to skip downloading step","49f0b71f":"# DeepFace Framework for Python","e8287055":"Train relationships file show folders for related ones. A folder might contain multiple photos.","c6e873d4":"Now, data frame has unique photos of related ones."}}