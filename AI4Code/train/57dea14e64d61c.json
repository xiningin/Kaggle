{"cell_type":{"a7f55710":"code","871dcd98":"code","ca7eeb31":"code","c7eead07":"code","6d3a5d80":"code","a26976d8":"code","c2641826":"code","8fdc1813":"code","9c4d108d":"code","b6b8f522":"code","37a0aaed":"code","64533a98":"code","03dab572":"code","74db7788":"code","5c886d6c":"code","9edf90b4":"code","e5aa14ea":"code","15c151c6":"code","5de8f125":"code","1c3f34de":"code","b3eb26f6":"code","47a8b4c9":"code","8108665d":"code","428125d4":"code","7c6d9489":"code","1def789d":"code","acef983f":"markdown","bc51ac52":"markdown","be0995f1":"markdown","17dd3e01":"markdown","9f34923e":"markdown","aa0b1e92":"markdown","b9ebd1df":"markdown","74e5e145":"markdown","c855dd6f":"markdown","fc35f7c8":"markdown","4dce3021":"markdown","852bc63b":"markdown","deda8b6c":"markdown","4661da65":"markdown","ed448ad8":"markdown","caa04c81":"markdown","d27daa77":"markdown","7fdcfcec":"markdown","1880bf0c":"markdown","7f16db81":"markdown","bbcae905":"markdown","9b8dda3b":"markdown","c3d6bc4e":"markdown","ce1223c4":"markdown","706eb12f":"markdown","064eba27":"markdown","9ad57268":"markdown","d9ffcf4d":"markdown","b5037483":"markdown"},"source":{"a7f55710":"# import\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import spearmanr\nfrom scipy.cluster import hierarchy\nfrom collections import defaultdict\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier","871dcd98":"# csv to pd frame \n\ncsv_path = '..\/input\/student-demographics-online-education-dataoulad\/'\ndata_dicts = {csv_name[:-4]: pd.read_csv(csv_path+csv_name) for csv_name in os.listdir(csv_path)}","ca7eeb31":"data_dicts['courses'].groupby(['code_module','code_presentation']).agg(['min','max'])","c7eead07":"df = data_dicts['assessments']\ndf.drop(['date','weight'],axis = 1).groupby(['code_module','assessment_type','code_presentation']).count()","6d3a5d80":"df.drop(['id_assessment'],axis = 1).groupby(['code_module','assessment_type','code_presentation']).agg(['min','max'])","a26976d8":"df = data_dicts['vle']\ndf.head()\n#sum(df['week_from'].isnull())\/df.shape[0]","c2641826":"df = data_dicts['studentInfo']\ndf.head()\n# df['imd_band'].isnull().sum()\n# columns = df.columns[3:]\n# for column in columns:\n#     print(df[column].value_counts(),'\\n')","8fdc1813":"print('Number of missing entries per column:')\ndf.isnull().sum()","9c4d108d":"sns.set_theme(style=\"darkgrid\")\nfor i, column in enumerate(df.columns):\n    if i>2 and i != 9:\n        sns.countplot(y = column, data = df)\n        plt.show()\n    elif i == 9: \n        sns.displot(x = column, data = df, kind=\"kde\")\n        plt.show()","b6b8f522":"df = data_dicts['studentRegistration']\ndf.head()","37a0aaed":"sns.displot(x = 'date_unregistration', data = df, kind=\"kde\")\nplt.show()","64533a98":"df = data_dicts['studentAssessment']\ndf.head()","03dab572":"print('Number of missing entries per column:')\ndf.isnull().sum()","74db7788":"# function for merging 2 pandas dataframes\n\ndef inner_merge(left_df,right_df,right_cols,on_cols):\n    right_df = right_df[right_cols]\n    left_df = left_df.merge(right_df, on = on_cols)\n    return left_df.drop_duplicates()","5c886d6c":"score_deadline = 90\nclick_deadline = 90\nwithdraw_deadline = 90","9edf90b4":"# score data\n\ndef create_score_df(score_deadline):\n\n    df1 = data_dicts['assessments']\n    df2 = data_dicts['studentAssessment']\n\n    score_df = inner_merge(df1,\n                           df2,\n                           df2.columns,\n                           ['id_assessment'],\n                          )\n\n    score_df = score_df[score_df['date'] < score_deadline]\n\n    score_df = score_df[score_df['assessment_type'] != 'Exam']\n\n    score_df = score_df.dropna(subset = ['score']) \n\n    score_df.isnull().sum()\n\n    score_df['assessment_type'].value_counts()\n\n    score_df = score_df.groupby(['code_module', 'code_presentation', 'id_student']).mean().reset_index()\n    score_df = score_df.rename(columns = {'score': f'mean_score_day{score_deadline}'})\n    score_df = score_df.drop(['date', 'weight', \n                              'date_submitted', 'is_banked',\n                              'id_assessment'],\n                             axis = 1)\n    return score_df","e5aa14ea":"# click data\n\ndef create_click_df(click_deadline):\n\n    clicks = data_dicts['studentVle']\n\n    clicks = inner_merge(clicks,\n                         data_dicts['vle'],\n                         ['id_site','code_module','code_presentation','activity_type'],\n                         ['id_site','code_module','code_presentation'],\n                        )\n\n    clicks = clicks.drop('id_site', axis = 1)\n\n    def clicks_xx(clicks,xx):\n        temp = clicks[clicks['date'] <= xx]\n        temp = temp.drop('date', axis = 1)\n        temp = temp.groupby(['code_module','code_presentation','id_student','activity_type']).mean()\n        temp = temp.rename(columns = {'sum_click': f'sum_click{xx} mean'})\n        temp = temp.reset_index() # this fills out the missing columns for merging later \n        return temp\n\n    click_data = pd.pivot_table(data = clicks_xx(clicks,click_deadline), \n                                index = ['code_module','code_presentation','id_student'],\n                                columns = 'activity_type', \n                                values = [f'sum_click{click_deadline} mean'],\n                                fill_value = 0,\n                               ).reset_index()\n\n    # get rid of multi index\n    click_data = pd.concat([click_data['code_module'],\n                            click_data['code_presentation'],\n                            click_data['id_student'], \n                            click_data[f'sum_click{click_deadline} mean']], axis=1)\n    return click_data","15c151c6":"# merge score_df and click_df\ndef create_final_df(withdraw_deadline, score_df, click_df):\n\n    final_df = inner_merge(click_df, # merge with StudentInfo\n                           data_dicts['studentInfo'],\n                           data_dicts['studentInfo'].columns,\n                           ['code_module', 'code_presentation', 'id_student'],\n                          )\n\n    final_df = final_df.replace('Distinction','Pass') # merge Pass and Distinction\n\n    final_df = inner_merge(final_df, \n                           data_dicts['studentRegistration'],\n                           ['code_module', 'code_presentation', 'id_student', 'date_unregistration'],\n                           ['code_module', 'code_presentation', 'id_student'],\n                          )\n\n    final_df = final_df[(final_df['final_result'] != 'Withdrawn') | # remove people who withdrew before withdraw_deadline\n                       (final_df['date_unregistration'] > withdraw_deadline)]\n\n    final_df = final_df.reset_index()\n\n    final_df = final_df.drop(['date_unregistration','index'],axis = 1)\n\n    final_df = inner_merge(final_df,\n                           score_df,\n                           score_df.columns,\n                           ['code_module', 'code_presentation', 'id_student'])\n    \n    final_df = final_df.replace('Withdrawn','Fail') # merge Withdrawn to Fail\n\n    return final_df","5de8f125":"score_df = create_score_df(score_deadline)\nclick_df = create_click_df(click_deadline)\nfinal_df = create_final_df(withdraw_deadline, score_df, click_df)\nfinal_df.head()","1c3f34de":"def create_Xy(final_df):\n\n    X = final_df.drop(['final_result','id_student','imd_band'],axis = 1)\n    column_names = X.columns\n    y = final_df['final_result']\n\n    le = LabelEncoder()\n    encode_dict = {}\n    Xcat_features = ['code_module', 'code_presentation',\n                    'gender', 'region',\n                    'highest_education',  \n                    'age_band','disability',\n                   ]\n\n    for cat_feature in Xcat_features: \n        X[cat_feature] = le.fit_transform(X[cat_feature])\n        encode_dict[cat_feature] = le.classes_\n\n    y = le.fit_transform(y)\n    encode_dict['final_result'] = le.classes_\n\n    X = X.to_numpy()\n    \n    return X,y,column_names,encode_dict","b3eb26f6":"X,y,column_names,encode_dict = create_Xy(final_df)","47a8b4c9":"corr = spearmanr(X).correlation\ncorr_linkage = hierarchy.ward(corr)\ncluster_ids = hierarchy.fcluster(corr_linkage, 1, criterion='distance')\ncluster_id_to_feature_ids = defaultdict(list)\nfor idx, cluster_id in enumerate(cluster_ids):\n    cluster_id_to_feature_ids[cluster_id].append(idx)\nselected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n\nX = X[:, selected_features]\ncolumn_names = column_names[selected_features]","8108665d":"reg = RandomForestClassifier(n_estimators = 200,\n                             max_features = 'sqrt', \n                             min_samples_split = 10, \n                            )\n\nkf = KFold(n_splits=5, shuffle = True)\n\ndef train(X,y,reg,kf):\n    if kf == False: \n        reg.fit(X,y)\n    else:\n        for train_index, test_index in kf.split(X):\n            X_train, X_test = X[train_index], X[test_index]\n            y_train, y_test = y[train_index], y[test_index]\n            reg.fit(X_train,y_train)\n            print(f'evaluate score: {reg.score(X_test,y_test)}')","428125d4":"train(X,y,reg,kf)","7c6d9489":"days_list = [120,150,180,210]\n\nfor days in days_list:\n    score_deadline = days\n    click_deadline = days\n    \n    score_df = create_score_df(score_deadline)\n    click_df = create_click_df(click_deadline)\n    final_df = create_final_df(withdraw_deadline, score_df, click_df)\n    \n#     score_df.to_csv(f'score_df{days}.csv',index = False)\n#     click_df.to_csv(f'click_df{days}.csv',index = False)\n#     final_df.to_csv(f'final_df{days}.csv',index = False)\n    \n    X,y,column_names,encode_dict = create_Xy(final_df)\n    \n    print(f'Number of days in data: {days}')\n    train(X,y,reg,kf)\n    print('\\n')","1def789d":"# feature importance\n\nfrom sklearn.inspection import permutation_importance\n\ntrain(X,y,reg,kf = False)\nimportance = permutation_importance(reg, X, y, n_repeats=10, random_state = 0)\nimportance_mean = np.round(importance['importances_mean'],3)\nimportance_table = pd.DataFrame({'importance': importance_mean,\n                                 'column': column_names,\n                                })\nimportance_table.sort_values(by = 'importance', ascending = False)","acef983f":"First let's take a look at each dataset separately. ","bc51ac52":"## studentAssessment.csv","be0995f1":"`week_from` and `week_to` tell us the timeframe certain contents are supposed to be used. Unfortunately, over 82% of this content is missing from the dataset.","17dd3e01":"According to data's documentation, exams have weight 100, and all the other assignments have weights adding up to 100. However, this is not true for all courses. In course G, only exams have weight. Additionally, course G has all CMAs on the same date. Course G is also abnormal in term of assignment date: all the other courses have first assignment within the first 30 days, but first assignment for course G is on day 61. Finally, final exam dates are missing, but this can be collected from the `courses.csv` dataset. ","9f34923e":"## vle.csv","aa0b1e92":"Here we use Random Forest simply because it's a good model for classification on tabular data. It's also good out-of-the-box, i.e. not a lot of fussing over hyperparameters. Moreover, there is a straight-forward implementation for permutation feature importance.  ","b9ebd1df":"As expected, the most important feature is the average score for each student. ","74e5e145":"# Goals\n\nThe purpose of this analysis is to provide a method for early identification of students at risk of failing. This is vital for any learning platforms, especially online ones. The data used is the [Open University Learning Analytics dataset (OULAD)](https:\/\/analyse.kmi.open.ac.uk\/open_dataset).  ","c855dd6f":"We also want to handle potential collinearity in the data. While collinearity does not impact Random Forest model per se, it might negatively affect the feature importance analysis we do after. ","fc35f7c8":"## assessments.csv","4dce3021":"# Prepping the Data for Analysis","852bc63b":"Below we have a function that creates a dataset that contains each student's average assignment score within the first `score_deadline` days. Another function to create a dataset that contains each student's average number of clicks for each resource category within the first `click_deadline` days. Then a function to merge the two datasets together, as well as remove students who withdrew before `withdraw_deadline`. Since our analysis only concerns with Pass\/Fail, we merge Distinction final results into Pass, and merge Withdrawn into Fail. The idea is that after a certain amount of time, the only people who withdraw are the people who are concerned with their performance, and are less likely to withdraw due to non-academic related reasons. ","deda8b6c":"Our evaluation score is around 75%. Not terribly impressive. Let's try again with more days. ","4661da65":"According to the data's documentation, there are 8 courses (modules) recorded, from A to G (AAA in dataset, henceforth shortened to A). There are 2 semesters recorded, February (B) and October (J). February semesters are typically 20 days shorter then October ones. Some courses (C,E,G) don't have data for both 2013 and 2014. ","ed448ad8":"Finally, we check the importance of each feature via permutation. ","caa04c81":"As we can expect, more data means higher accuracy, though it also means later intervention if we decide to reach out to the students based on their performance. The sweet spot for our data seems to be 180 days, which would leave 60-80 days before final exam. This might be enough time to help failing students, considering the courses are structured so that majority of the grade depends on the final exam. ","d27daa77":"From the plot, we can see that there are a decent amount of students who withdrew from a course before it started. We will remove these students from our dataset later, since we don't have any academic performance data for them.  ","7fdcfcec":"Course C have 2 final exams. Course A doesn't have any Computer Marked Assessment (CMA). Each course has at least 3 TMAs.","1880bf0c":"Certain features such as `studied_credits`, `num_of_prev_attempts`, `age_band`, `highest_education` contain some extreme observations. It's not really a problem for our analysis, since we are going to use Random Forest.  ","7f16db81":"We want to predict a student's final result based on their early performance. By performance, we mean 2 things: academic performance, measured via the students' scores, and academic engagement, measured via the number of times the students click on course content. The three variables below control how many days into a semester we want to include for our analysis.  ","bbcae905":"According to the data's documentation, score ranges from 0 to 100. Score lower than 40 is interpreted as a Fail. If the student does not submit the assessment, no result is recorded. Most of the missing scores are from final exams, which does not impact our analysis, since we are only concern with students' performance early in the semester.","9b8dda3b":"# Modeling ","c3d6bc4e":"## studentInfo.csv","ce1223c4":"# Data Exploration","706eb12f":"## studentRegistration.csv","064eba27":"There are 1000 observations with `imd_band` (Index of Multiple Depravation, an index for living condition) missing. Something we might want to consider when building model later. ","9ad57268":"## courses.csv\n","d9ffcf4d":"# Discussion\n\nIn this notebook, we went over building a Random Forest model to predict students' final results based on their early performance. The model works decently well, with cross-validated acuracy of 80%. We would recommend future courses' instructors to run the model at around day 180, and reach out to students who are likely to fail. For the students who are predicted to pass, we recommend the instructor to do a sanity check by checking on students who score on average below a certain threshold. This threshold should be picked by the instructor based on past experience. We don't recommend any universal threshold: since every course has different structure, we would have to recommend a threshold so low it would be counterproductive. \n\nFor future version of this analysis, we would like to use the provided score data with more finesse than just averaging them together. We would also like to explore more into the misclassified students and see if we can maybe engineer more features that can help improve the current model. Finally, we want to rewrite our analysis with CatBoost so we can train faster on GPU.    ","b5037483":"Finally we do some touch-ups to the dataframe before feeding it to our model. First we want to encode all the categorical variables. Here we do label encoding instead of one-hot encoding, simply because it works for tree-based algorithms, and it's easier to read if later we want to visually inspect individual trees. "}}