{"cell_type":{"4fd6ae7b":"code","e718804e":"code","78fa87ae":"code","a76723c6":"code","5dd6698d":"code","a686310e":"code","d65fe3a5":"code","b912e6b1":"code","438daff1":"code","bb90fca3":"code","5aa1adf4":"code","e2f1903c":"code","10ea76f2":"code","9b36946e":"code","83e66709":"code","31bfcb3b":"code","6db10270":"code","659816c9":"code","66648a04":"code","c5d1b062":"code","fe6e4a9f":"code","f7ac1263":"code","8ad84b08":"code","985baa75":"code","633291cd":"code","9d7ea7ee":"code","0d6a212f":"code","7239060e":"code","991bf225":"code","05d6a334":"code","e9cdede5":"code","1d7ab14e":"code","84ebe3d8":"code","c5cd5b0b":"code","a149895e":"code","dd3168a8":"code","0976dd0b":"code","b18e0032":"code","292a7eec":"code","9a46a210":"code","6302d6db":"code","261f09d1":"code","876863ab":"code","52456e40":"code","9d6e5932":"code","d540d46b":"markdown","5b73ed08":"markdown","2de92d81":"markdown","6a8a57b5":"markdown","4277b2d9":"markdown","5fa54b0d":"markdown","e23d167f":"markdown","e3d20302":"markdown","53476867":"markdown","c16552fe":"markdown","6c6a0acc":"markdown","07cdd9da":"markdown","bc89821f":"markdown","863b6f25":"markdown","83f26cda":"markdown","c0e417d4":"markdown","7dc67b99":"markdown","5082a7a3":"markdown","fc4d4973":"markdown","0ad96b0f":"markdown","1e6032b1":"markdown","888882b4":"markdown","fbb09dae":"markdown","21d2a5d7":"markdown","474b8a22":"markdown","e8efaf90":"markdown","57824fe4":"markdown"},"source":{"4fd6ae7b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom os import listdir\nfrom PIL import Image\n\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Conv2D, Dense, Flatten, Input, BatchNormalization, Activation, Dropout\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.initializers import glorot_uniform\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\nfrom keras.optimizers import Adam\n\nfrom sklearn.model_selection import train_test_split","e718804e":"from keras.preprocessing.image import load_img, img_to_array\nfrom os import listdir\nimport pandas as pd\nimport numpy as np","78fa87ae":"def loadImages(path):\n    count = 1\n    images = []\n    imageList = sorted(listdir(path))\n    for i in imageList:\n        image = load_img(path + i)\n        image = img_to_array(image)\n        images.append(image)\n        if (count % 1000 == 0):\n            print(\"Processing image\", count)\n        count += 1\n    print(\"Done.\")\n    return np.asarray(images, dtype='float')\n    ","a76723c6":"path = \"..\/input\/aerial-cactus-identification\/train\/train\/\"\nX_train = loadImages(path)","5dd6698d":"X_train.shape","a686310e":"path = \"..\/input\/aerial-cactus-identification\/test\/test\/\"\nX_test = loadImages(path)","d65fe3a5":"X_test.shape","b912e6b1":"Y_train = pd.read_csv(\"..\/input\/aerial-cactus-identification\/train.csv\")","438daff1":"Y_train.head(5)","bb90fca3":"Y_train = Y_train.sort_values(\"id\", ascending=True).has_cactus","5aa1adf4":"Y_train.value_counts().plot.bar()","e2f1903c":"epochs = 3\nbatch_size = 32","10ea76f2":"plt.figure(figsize=(8, 8))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    j = np.random.randint(0, Y_train.shape[0])\n    plt.imshow(X_train[j][:, :, 0])\nplt.tight_layout()\nplt.show()","9b36946e":"# Note that for errors occur when trying Inception models due to dimension errors.\n\nfrom keras.applications.xception import Xception\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.densenet import DenseNet201\nfrom keras.applications.nasnet import NASNetLarge","83e66709":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, \\\n                                            factor=0.7, min_lr=0.00001)","31bfcb3b":"datagen = ImageDataGenerator(rotation_range=30, width_shift_range=0.2, \n                             height_shift_range=0.2, zoom_range=0.2, \n                             horizontal_flip=True, vertical_flip=True, \n                             validation_split=0.1)","6db10270":"train_generator = datagen.flow(X_train, Y_train, batch_size=batch_size, subset='training')\nval_generator = datagen.flow(X_train, Y_train, batch_size=batch_size, subset='validation')","659816c9":"def buildModel(base_model, freeze=0.8):\n    \n    # Freeze 80% layers, if freeze not specified\n    threshold = int(len(base_model.layers) * freeze)\n    for i in base_model.layers[:threshold]:\n        i.trainable = False\n    for i in base_model.layers[threshold:]:\n        i.trainable = True\n\n    X = base_model.output\n    X = Flatten()(X)\n    X = Dense(512, activation='relu', kernel_regularizer='l2')(X)\n    X = Dense(1, activation='sigmoid')(X)\n    \n    model = Model(inputs=base_model.input, outputs=X)\n    \n    return model","66648a04":"def fitModel(model, lr=0.0005, cp=False):\n\n    # Compile model\n    model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Train model\n    cb = [learning_rate_reduction, checkpoint] if cp else [learning_rate_reduction]\n    history.append(model.fit_generator(generator=train_generator, epochs=epochs,\n                                       steps_per_epoch=int(X_train.shape[0] \/\/ batch_size * 1.5),\n                                       validation_data=val_generator, \n                                       validation_steps=int(X_train.shape[0] \/\/ batch_size * 0.4),\n                                       callbacks=cb, verbose=2))\n    return model","c5d1b062":"# To store history of training\nhistory = []","fe6e4a9f":"# Build model\nX_input = Input((32, 32, 3))\nbase_model = Xception(weights=\"..\/input\/pretrained-models\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n                      include_top=False, input_tensor=X_input)\nmodel = buildModel(base_model)\n\n# Train model\nfitModel(model)","f7ac1263":"# Build model\nX_input = Input((32, 32, 3))\nbase_model = VGG16(weights=\"..\/input\/pretrained-models\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n                   include_top=False, input_tensor=X_input)\nmodel = buildModel(base_model)\n\n# Train model\nfitModel(model)","8ad84b08":"# Build model\nX_input = Input((32, 32, 3))\nbase_model = VGG19(weights=\"..\/input\/pretrained-models\/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n                   include_top=False, input_tensor=X_input)\nmodel = buildModel(base_model)\n\n# Train model\nfitModel(model)","985baa75":"# # Build model\n# X_input = Input((32, 32, 3))\n# base_model = ResNet50(weights=\"..\/input\/pretrained-models\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n#                       include_top=False, input_tensor=X_input)\n# model = buildModel(base_model)\n\n# # Train model\n# fitModel(model)","633291cd":"# Build model\nX_input = Input((32, 32, 3))\nbase_model = DenseNet201(weights=\"..\/input\/pretrained-models\/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n                         include_top=False, input_tensor=X_input)\nmodel = buildModel(base_model)\n\n# Train model\nfitModel(model)","9d7ea7ee":"# Build model\nX_input = Input((32, 32, 3))\nbase_model = NASNetLarge(weights=\"..\/input\/pretrained-models\/NASNet-large-no-top.h5\",\n                         include_top=False, input_tensor=X_input)\nmodel = buildModel(base_model)\n\n# Train model\nfitModel(model)","0d6a212f":"plt.figure(figsize=(10, 7))\nfor i, j in enumerate(history):\n    plt.plot(j.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend([\"Xception val\", \"VGG16 val\", \n            \"VGG19 val\", \"DenseNet201 val\",\n            \"NASNetLarge val\"], loc='lower right')\nplt.show()","7239060e":"plt.figure(figsize=(10, 7))\nfor i, j in enumerate(history):\n    plt.plot(j.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend([\"Xception val\", \"VGG16 val\", \n            \"VGG19 val\", \"DenseNet201 val\",\n            \"NASNetLarge val\"], loc='lower right')\nplt.show()","991bf225":"epochs = 5\nhistory = []","05d6a334":"# Turn off learning rate decay\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=100, verbose=1, \\\n                                            factor=0.7, min_lr=0.00001)","e9cdede5":"# Build model\nX_input = Input((32, 32, 3))\nlrs = [0.00001, 0.00003, 0.0001, 0.0003, 0.001, 0.003, 0.01]\nfor lr in lrs:\n    print(\"=============================\")\n    print(\"Fitting model with learning_rate =\", lr)\n    base_model = VGG19(weights=\"..\/input\/pretrained-models\/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n                       include_top=False, input_tensor=X_input)\n    model = buildModel(base_model)\n\n    # Train model\n    fitModel(model, lr=lr)","1d7ab14e":"plt.figure(figsize=(10, 7))\nval_loss = []\nfor i, j in enumerate(history):\n    val_loss.append(sum(j.history['val_loss']) \/ 5)\nplt.plot(lrs, val_loss)\nplt.title('model loss')\nplt.ylabel('val loss')\nplt.xlabel('learning rate')\nplt.show()","84ebe3d8":"epochs = 5\nhistory = []","c5cd5b0b":"# Turn on learning rate decay\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, \\\n                                            factor=0.5, min_lr=1e-5)","a149895e":"# Build model\nX_input = Input((32, 32, 3))\nfrs = [0, 0.25, 0.5, 0.75, 1]\nfor fr in frs:\n    print(\"=============================\")\n    print(\"Fitting model with freeze fraction =\", fr, \"and learning_rate = 1e-4\")\n    base_model = VGG19(weights=\"..\/input\/pretrained-models\/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n                       include_top=False, input_tensor=X_input)\n    model = buildModel(base_model, freeze=fr)\n\n    # Train model\n    fitModel(model, lr=1e-4)","dd3168a8":"plt.figure(figsize=(10, 7))\nval_loss = []\nfor i, j in enumerate(history):\n    val_loss.append(sum(j.history['val_loss']) \/ 5)\nplt.plot(frs, val_loss)\nplt.title('model loss')\nplt.ylabel('average val loss')\nplt.xlabel('freeze fraction')\nplt.show()","0976dd0b":"plt.figure(figsize=(10, 7))\nval_loss = []\nfor i, j in enumerate(history):\n    val_loss.append(min(j.history['val_loss']))\nplt.plot(frs, val_loss)\nplt.title('model loss')\nplt.ylabel('min val loss')\nplt.xlabel('freeze fraction')\nplt.show()","b18e0032":"def buildModel(base_model, freeze=0.8):\n    \n    # Freeze 80% layers, if freeze not specified\n    threshold = int(len(base_model.layers) * freeze)\n    for i in base_model.layers[:threshold]:\n        i.trainable = False\n    for i in base_model.layers[threshold:]:\n        i.trainable = True\n    \n    X = base_model.output\n    X = Flatten()(X)\n    \n    X = Dense(512, use_bias=True)(X)\n    X = BatchNormalization()(X)\n    X = Activation('relu')(X)\n    X = Dropout(0.3)(X)\n    \n    X = Dense(256, use_bias=True)(X)\n    X = BatchNormalization()(X)\n    X = Activation('relu')(X)\n    X = Dropout(0.3)(X)\n    \n    X = Dense(1, activation='sigmoid')(X)\n    \n    model = Model(inputs=base_model.input, outputs=X)\n    \n    return model","292a7eec":"checkpoint = ModelCheckpoint(\"vgg19.h5\",monitor=\"val_acc\", \n                             verbose=1, save_best_only=True,\n                             mode='max')","9a46a210":"epochs = 30","6302d6db":"# Build model\nX_input = Input((32, 32, 3))\nbase_model = VGG19(weights=\"..\/input\/pretrained-models\/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n                   include_top=False, input_tensor=X_input)\nmodel = buildModel(base_model, freeze=0.25)\n# Train model\nmodel = fitModel(model, lr=1e-4, cp=True)","261f09d1":"submission = test_images = pd.read_csv(\"..\/input\/aerial-cactus-identification\/sample_submission.csv\")\nsubmission = pd.DataFrame(test_images.iloc[:, 0], columns=[\"id\"])","876863ab":"pred = model.predict(X_test).reshape(-1)","52456e40":"submission[\"has_cactus\"] = pd.Series(pred, index=None)","9d6e5932":"submission.to_csv(\"submission.csv\", index=False)","d540d46b":"***VGG19***","5b73ed08":"***Define functions for building models***","2de92d81":"***Load training images***","6a8a57b5":"***ResNet50***\n> Note that importing ResNet50 from Keras causes problem. \nI encourage you to include ResNet50 in your model benchmarking by following [this link](https:\/\/github.com\/fchollet\/deep-learning-models\/tree\/8d8f54a9e1482c3642a55a694c2cde8f26562a06)","4277b2d9":"***See how the classes are distributed***","5fa54b0d":"# Great! \n> As we can see from the benchmark, VGG19 gives us the best performance. Now we will do benmarking again to choose the best learning rate.","e23d167f":"**Load test images****","e3d20302":"***Define a function for loading images***","53476867":"***VGG16***","c16552fe":"***Split train\/dev set***","6c6a0acc":"***Ensure that Y_train is ordered properly, and then extract all the labels***","07cdd9da":"***Making predictions and submission***","bc89821f":"# Basic Parameters for Benchmarking\n> To keep it simple and to prevent errors when trying to commit the notebook, I will do the benmarking on only 3 epochs","863b6f25":"# Read inputs","83f26cda":"***Xception***","c0e417d4":"***NASNetLarge***","7dc67b99":">** If you have more time, you can try benchmarking and implementing DenseNet201-based model yourself**","5082a7a3":"***VGG19***","fc4d4973":"***VGG16***","0ad96b0f":"***Load labels for training set***","1e6032b1":"# Great! Now we are ready to benchmark all the pre-trained models and pick the best model.","888882b4":"***DenseNet201***","fbb09dae":"# Great! The optimal learning rate should be 1e-4. Now we will do benchmarking again to choose the fraction of layers to be frozen","21d2a5d7":"***Plot only validation set info***","474b8a22":"***Training model***","e8efaf90":"# It seems that with fraction = 0.25, we obtain the best validation set loss.","57824fe4":"# See how our I\/O works"}}