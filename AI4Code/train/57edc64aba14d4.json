{"cell_type":{"5c33295d":"code","daf41b6a":"code","aad7025c":"code","cc34718a":"code","978ad7da":"code","50f948ac":"code","c1fd7408":"markdown"},"source":{"5c33295d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom random import random\n","daf41b6a":"PATH_WEEK2='\/kaggle\/input\/covid19-global-forecasting-week-3'\ndf_train = pd.read_csv(f'{PATH_WEEK2}\/train.csv')\ndf_test = pd.read_csv(f'{PATH_WEEK2}\/test.csv')\ndf_train.head()\ndf_test.head()\ndf_train.rename(columns={'Country_Region':'Country'}, inplace=True)\ndf_test.rename(columns={'Country_Region':'Country'}, inplace=True)\n\ndf_train.rename(columns={'Province_State':'State'}, inplace=True)\ndf_test.rename(columns={'Province_State':'State'}, inplace=True)\n\ndf_train['Date'] = pd.to_datetime(df_train['Date'], infer_datetime_format=True)\ndf_test['Date'] = pd.to_datetime(df_test['Date'], infer_datetime_format=True)\n\ndf_train.info()\ndf_test.info()\n\ny1_Train = df_train.iloc[:, -2]\ny1_Train.head()\ny2_Train = df_train.iloc[:, -1]\ny2_Train.head()\n\nEMPTY_VAL = \"EMPTY_VAL\"\n\ndef fillState(state, country):\n    if state == EMPTY_VAL: return country\n    return state","aad7025c":"#X_Train = df_train.loc[:, ['State', 'Country', 'Date']]\nX_Train = df_train.copy()\n\nX_Train['State'].fillna(EMPTY_VAL, inplace=True)\nX_Train['State'] = X_Train.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\nX_Train.loc[:, 'Date'] = X_Train.Date.dt.strftime(\"%m%d\")\nX_Train[\"Date\"]  = X_Train[\"Date\"].astype(int)\n\nX_Train.head()\n\n#X_Test = df_test.loc[:, ['State', 'Country', 'Date']]\nX_Test = df_test.copy()\n\nX_Test['State'].fillna(EMPTY_VAL, inplace=True)\nX_Test['State'] = X_Test.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\nX_Test.loc[:, 'Date'] = X_Test.Date.dt.strftime(\"%m%d\")\nX_Test[\"Date\"]  = X_Test[\"Date\"].astype(int)\n\nX_Test.head()","cc34718a":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\n\nX_Train.Country = le.fit_transform(X_Train.Country)\nX_Train['State'] = le.fit_transform(X_Train['State'])\n\nX_Train.head()\n\nX_Test.Country = le.fit_transform(X_Test.Country)\nX_Test['State'] = le.fit_transform(X_Test['State'])\n\nX_Test.head()\n\ndf_train.head()\ndf_train.loc[df_train.Country == 'Afghanistan', :]\ndf_test.tail()","978ad7da":"from warnings import filterwarnings\nfilterwarnings('ignore')\n\nfrom sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\n\nfrom xgboost import XGBRegressor\n\ncountries = X_Train.Country.unique()\n\n#models_C = {}\n#models_F = {}\n\ndf_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n\nfor country in countries:\n    states = X_Train.loc[X_Train.Country == country, :].State.unique()\n    #print(country, states)\n    # check whether string is nan or not\n    for state in states:\n        X_Train_CS = X_Train.loc[(X_Train.Country == country) & (X_Train.State == state), ['State', 'Country', 'Date', 'ConfirmedCases', 'Fatalities']]\n        \n        y1_Train_CS = X_Train_CS.loc[:, 'ConfirmedCases']\n        y2_Train_CS = X_Train_CS.loc[:, 'Fatalities']\n        \n        X_Train_CS = X_Train_CS.loc[:, ['State', 'Country', 'Date']]\n        \n        X_Train_CS.Country = le.fit_transform(X_Train_CS.Country)\n        X_Train_CS['State'] = le.fit_transform(X_Train_CS['State'])\n        \n        X_Test_CS = X_Test.loc[(X_Test.Country == country) & (X_Test.State == state), ['State', 'Country', 'Date', 'ForecastId']]\n        \n        X_Test_CS_Id = X_Test_CS.loc[:, 'ForecastId']\n        X_Test_CS = X_Test_CS.loc[:, ['State', 'Country', 'Date']]\n        \n        X_Test_CS.Country = le.fit_transform(X_Test_CS.Country)\n        X_Test_CS['State'] = le.fit_transform(X_Test_CS['State'])\n        \n        #models_C[country] = gridSearchCV(model, X_Train_CS, y1_Train_CS, param_grid, 10, 'neg_mean_squared_error')\n        #models_F[country] = gridSearchCV(model, X_Train_CS, y2_Train_CS, param_grid, 10, 'neg_mean_squared_error')\n        \n        model1 = XGBRegressor(n_estimators=1000)\n        model1.fit(X_Train_CS, y1_Train_CS)\n        y1_pred = model1.predict(X_Test_CS)\n        \n        model2 = XGBRegressor(n_estimators=1000)\n        model2.fit(X_Train_CS, y2_Train_CS)\n        y2_pred = model2.predict(X_Test_CS)\n        \n        df = pd.DataFrame({'ForecastId': X_Test_CS_Id, 'ConfirmedCases': y1_pred, 'Fatalities': y2_pred})\n        df_out = pd.concat([df_out, df], axis=0)\n    # Done for state loop\n# Done for country Loop","50f948ac":"df_out.ForecastId = df_out.ForecastId.astype('int')\ndf_out.tail()\ndf_out.to_csv('submission.csv', index=False)","c1fd7408":"* xgboost,simple but powerful, keep top 10% in private leaderboard in week2,\nreference fromhttps:\/\/www.kaggle.com\/varalakshmia\/kernel60368d2f6f\n* also, credit for Basic Model with this notebook fork from\n* if this notebook help you,pls upvote,that will really help me,thank you!\n\n* add an new kernel for BCG vaccine helping against COVID19,fyi https:\/\/www.kaggle.com\/ashora\/bcg-vaccine-is-helping-the-fight-against-covid19 "}}