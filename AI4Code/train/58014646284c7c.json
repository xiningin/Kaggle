{"cell_type":{"a6c8c26c":"code","06246386":"code","f9b0ea40":"code","3dfc2186":"code","93e3a0e4":"code","30ea7af0":"code","a37356c9":"code","d7e31c2f":"code","c950949f":"code","6d39a97f":"code","12fd106d":"code","0d32a7cf":"code","c722f5e9":"code","14a1ec83":"code","9d0dd312":"code","7fe720a4":"code","27ae31c7":"code","9b529a19":"code","4649de22":"code","a63b945d":"code","1365dbe3":"code","29ec10f3":"code","6ec48097":"code","deb3464d":"code","deede107":"code","03ff2fbd":"code","604bec09":"code","b5d35767":"code","978cacf1":"code","2d5e1ddf":"code","2983a38a":"code","df280d36":"code","1399f04d":"code","a818fb50":"code","a095195f":"code","31162909":"code","c744dd6e":"code","753521ce":"code","1c3a020e":"code","5421847c":"code","58f06b8c":"code","0619327f":"code","d8da8c19":"markdown"},"source":{"a6c8c26c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","06246386":"train=pd.read_csv('\/kaggle\/input\/Train.csv')\ntest=pd.read_csv('\/kaggle\/input\/Test.csv')","f9b0ea40":"test['Age'].fillna(test['Age'].median(), inplace=True)\ntest['Time_of_service'].fillna(test['Time_of_service'].median(), inplace=True)\ntest['Work_Life_balance'].fillna(test['Work_Life_balance'].median(), inplace=True)\ntest['VAR2'].fillna(test['VAR2'].median(), inplace=True)\ntest['VAR4'].fillna(test['VAR4'].median(), inplace=True)\ntest['Pay_Scale'].fillna(test['Pay_Scale'].median(), inplace=True)","3dfc2186":"train['Decision_skill_possess'].fillna('Conceptual', inplace=True)","93e3a0e4":"train['Age'].fillna(train['Age'].median(), inplace=True)\ntrain['Time_of_service'].fillna(train['Time_of_service'].median(), inplace=True)\ntrain['Work_Life_balance'].fillna(train['Work_Life_balance'].median(), inplace=True)\ntrain['VAR2'].fillna(train['VAR2'].median(), inplace=True)\ntrain['VAR4'].fillna(train['VAR4'].median(), inplace=True)\ntrain['Pay_Scale'].fillna(train['Pay_Scale'].median(), inplace=True)","30ea7af0":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()","a37356c9":"train['Gender']=le.fit_transform(train['Gender'])","d7e31c2f":"test['Gender']=le.transform(test['Gender'])","c950949f":"le1=LabelEncoder()\ntrain['Relationship_Status']=le1.fit_transform(train['Relationship_Status'])\ntest['Relationship_Status']=le1.transform(test['Relationship_Status'])","6d39a97f":"le4=LabelEncoder()\ntrain['Hometown']=le4.fit_transform(train['Hometown'])\ntest['Hometown']=le4.transform(test['Hometown'])","12fd106d":"le5=LabelEncoder()\ntrain['Pay_Scale']=le5.fit_transform(train['Pay_Scale'])\ntest['Pay_Scale']=le5.transform(test['Pay_Scale'])","0d32a7cf":"le2=LabelEncoder()\ntrain['Unit']=le2.fit_transform(train['Unit'])\ntest['Unit']=le2.transform(test['Unit'])","c722f5e9":"\nle3=LabelEncoder()\ntrain['Decision_skill_possess']=le3.fit_transform(train['Decision_skill_possess'])\ntest['Decision_skill_possess']=le3.transform(test['Decision_skill_possess'])","14a1ec83":"le6=LabelEncoder()\ntrain['Compensation_and_Benefits']=le6.fit_transform(train['Compensation_and_Benefits'])\ntest['Compensation_and_Benefits']=le6.transform(test['Compensation_and_Benefits'])","9d0dd312":"#le11=LabelEncoder()\n#train['Attrition_rate']=le11.fit_transform(train['Attrition_rate'])","7fe720a4":"X=train.iloc[0:,1:23].values","27ae31c7":"y=train['Attrition_rate'].values","9b529a19":"testx=test.iloc[0:, 1:].values","4649de22":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(random_state = 42)","a63b945d":"from pprint import pprint","1365dbe3":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n#n_jobs = [-1, 1]\n#random_state=  [int(x) for x in np.linspace(start = 0, stop = 10000, num = 10000)]\n#criterion=['gini','entropy']\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt','log2']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 20, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 12, 14, 15,16, 17,18]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4,6, 8,9]\nmax_leaf_nodes=[5, 8,9,10, 12,15 , None]\n#random_state=[int(x) for x in np.linspace(start=0, stop=100, num = 1)]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'max_leaf_nodes' : max_leaf_nodes,\n               #'n_jobs':n_jobs,\n               'bootstrap': bootstrap,\n                #'random_state':random_state,\n               #'criterion':criterion,\n              }\npprint(random_grid)","29ec10f3":"from sklearn.model_selection import GridSearchCV","6ec48097":"param_grid = {\n    'bootstrap': [True],\n    'max_depth': [80, 85,90, 100],\n    'max_features': [1,2],\n    'min_samples_leaf': [4, 5,6],\n    'min_samples_split': [5,8, 10],\n    'n_estimators': [100,120,140]\n}","deb3464d":"# Create a based model\nrf = RandomForestRegressor()\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)","deede107":"# Fit the grid search to the data\ngrid_search.fit(X, y)","03ff2fbd":"grid_search.best_params_","604bec09":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestRegressor()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100,random_state=0, cv = 3,  verbose=2, n_jobs = -1)\n                               #random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X, y)","b5d35767":"rf_random.best_params_\n","978cacf1":"base_model = RandomForestRegressor(n_estimators = 220, min_samples_split=12,  min_samples_leaf=11, max_depth=120, max_features=1,\n                                   bootstrap=True,\n                                   random_state = 42)","2d5e1ddf":"base_model.fit(X,y)","2983a38a":"z=base_model.predict(testx)","df280d36":"z","1399f04d":"'''from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2, random_state=42)'''","a818fb50":"'''from sklearn.ensemble import RandomForestClassifie\nclf1=RandomForestClassifier(n_estimators=10,random_state=0)'''","a095195f":"#clf1.fit(X, y)","31162909":"#p=clf1.predict(testx)","c744dd6e":"#du=le11.inverse_transform(p)","753521ce":"#du","1c3a020e":"id=test['Employee_ID'].values","5421847c":"data=pd.DataFrame({'Employee_ID':id,'Attrition_rate':z})","58f06b8c":"data.to_csv('submission.csv',index=False)","0619327f":"data","d8da8c19":"## data Loading with pandas "}}