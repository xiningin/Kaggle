{"cell_type":{"46562ff8":"code","1267ff50":"code","078979b1":"code","2bce824a":"code","251c71c9":"code","8a129285":"code","aaa6debd":"code","f8d9ac8d":"code","c419ebb5":"code","1f0e404e":"code","8bf75699":"code","1d05a0b1":"code","d2d43b33":"code","bbec8349":"code","741654f6":"code","41ec10e6":"code","96700ec2":"code","8559239d":"code","2427ba3b":"code","d1e1d190":"code","60eda9e0":"code","5ca1a43a":"code","493f85ce":"code","af973041":"code","98114693":"code","7b0ca6e4":"code","298a077b":"code","6eb1d964":"code","4e9d9781":"code","fa60fa35":"code","9f585a39":"code","bdebcc2b":"code","9c7f3cd2":"code","1a4c7e5b":"code","dd36d340":"code","1b02c3ed":"code","07efc62b":"code","aa0044be":"code","cbcaf0e0":"markdown","b846d5fc":"markdown","72edcdb0":"markdown","a27f5626":"markdown","783317fe":"markdown","c3bd7df3":"markdown","3a0ac88d":"markdown"},"source":{"46562ff8":"!wget https:\/\/www.dropbox.com\/s\/xmopr2altgp8f0a\/dataset.zip?dl=0 -O dataset.zip","1267ff50":"!unzip dataset","078979b1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras import losses\nimport os\nimport shutil","2bce824a":"folder = os.listdir(\"Train\")\nprint(folder)","251c71c9":"if not os.path.isdir(\"Val\"):\n  os.mkdir(\"Val\")\n!ls","8a129285":"for c in folder:\n  p=os.path.join(\"Val\",c)\n  if not os.path.isdir(p):\n    os.mkdir(p)","aaa6debd":"for f in folder:\n  path=\"Train\/\"+f\n  print(f+ \" \"+ str(len(os.listdir(path))))","f8d9ac8d":"split = 0.9\nfor f in os.listdir(\"Train\"):\n    path = \"Train\/\"+f\n    imgs=os.listdir(path)\n    split_size= int(split*len(imgs))\n    file_to_move=imgs[split_size:]\n  \n    for img_f in file_to_move:\n        src=os.path.join(path,img_f)\n        dest=os.path.join(\"Val\/\"+f,img_f)\n        #print(src)\n        #print(dest)\n        shutil.move(src,dest)","c419ebb5":"print(\"For training data:- \")\nfor f in folder:\n    path=\"Train\/\"+f\n    print(f+ \" \"+ str(len(os.listdir(path))))\n\nprint(\"\\n For vaidation data:- \")\nfor f in folder:\n    path=\"Val\/\"+f\n    print(f+ \" \"+ str(len(os.listdir(path))))","1f0e404e":"# Image visualisation\ndef ImgVis(Path):\n    img=image.load_img(Path)\n    x=image.img_to_array(img)\/255.0\n    print(x.shape)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    plt.show()","8bf75699":"path=\"Train\/Charmander\/00000002.jpg\"\nImgVis(path)","1d05a0b1":"path = \"Train\/Bulbasaur\/00000013.png\"\nImgVis(path)","d2d43b33":"train_gen = image.ImageDataGenerator(rescale=1.0\/255,\n                                    horizontal_flip=True,\n                                    shear_range=0.2,\n                                    zoom_range=0.2,)\n\nval_gen = image.ImageDataGenerator(rescale=1\/255.0)\n\ntrain_generator = train_gen.flow_from_directory(\"Train\/\",\n                                               target_size=(224,224),\n                                               batch_size=32,\n                                               class_mode='categorical')\n\nval_generator = val_gen.flow_from_directory(\"Val\/\",\n                                            target_size=(224,224),\n                                            batch_size=32,\n                                            class_mode='categorical')","bbec8349":"for x,y in train_generator:\n    print(x.shape)\n    print(y.shape)\n    break","741654f6":"print(train_generator.class_indices)\nprint(\"-\"*15)\nprint(val_generator.class_indices)","41ec10e6":"model = Sequential()","96700ec2":"model.add(Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)))\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10,activation='softmax'))","8559239d":"model.summary()","2427ba3b":"model.compile(loss=losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy'])","d1e1d190":"hist = model.fit(train_generator,\n                          steps_per_epoch=47,\n                          epochs=20,\n                          validation_data=val_generator,\n                          validation_steps=6)","60eda9e0":"# Visualising the accuracy\nplt.style.use(\"seaborn\")\n\nplt.plot(hist.history['accuracy'],label=\"training acc\",c='red')\nplt.plot(hist.history['val_accuracy'],label=\"validation acc\",c='blue')\nplt.legend()\nplt.show()","5ca1a43a":"path=\"Test\/\"\ny_df=pd.read_csv(path+\"sample_submission.csv\")\ny_df.shape","493f85ce":"y_df.head(7)","af973041":"y_df.drop(['Class'],inplace=True,axis=1)","98114693":"y_df.head(7)","7b0ca6e4":"y_df=y_df.values.reshape((-1,))\nprint(y_df.shape)","298a077b":"from pathlib import Path\npi_test=Path(\"Test\/images\/\")\n\nimage_data_test=[]\nlabel_test=[]\n\nfor image_path in pi_test.glob(\"*\"):\n  #label=(str(image_path).split(\"\\\\\")[-1]) this is not woring in goole colab\n  label=(str(image_path).split(\"\/\")[-1])\n\n  img=image.load_img(image_path,target_size=(224,224,3))\n  image_array=image.img_to_array(img)\/255.0\n  image_data_test.append(image_array)\n  label_test.append(label)","6eb1d964":"image_data_test=np.array(image_data_test)\nprint(label_test[:5])\nprint(label_test[0])","4e9d9781":"print(image_data_test.shape)\nprint(len(label_test))","fa60fa35":"y_predicted=model.predict_classes(image_data_test)","9f585a39":"y_predicted","bdebcc2b":"y_pre=[]\nfor i in range(image_data_test.shape[0]):\n  index=label_test.index(y_df[i])\n  y=y_predicted[index]\n  y_pre.append((y_df[i],y))","9c7f3cd2":"y_pre=np.array(y_pre)","1a4c7e5b":"df_pred=pd.DataFrame(data=y_pre,columns=['Name','Class'])\ndf_pred.head(7)","dd36d340":"dict_pred = dict(df_pred.values.tolist())\nprint(dict_pred)","1b02c3ed":"label_pok = {\n    0 : \"Aerodactyl\",  \n    1 : \"Bulbasaur\",  \n    2 : \"Charmander\", \n    3 : \"Dratini\",  \n    4 : \"Fearow\",  \n    5 : \"Mewtwo\",  \n    6 : \"Pikachu\",  \n    7 : \"Psyduck\",  \n    8 : \"Spearow\",  \n    9 : \"Squirtle\"\n}","07efc62b":"path = \"\/kaggle\/working\/Test\/images\/test_32.jpg\"\nImgVis(path)\nprint(dict_pred['test_32.jpg'])\nprint(label_pok[int(dict_pred['test_32.jpg'])])","aa0044be":"path = \"\/kaggle\/working\/Test\/images\/test_9.jpg\"\nImgVis(path)\nprint(dict_pred['test_9.jpg'])\nprint(label_pok[int(dict_pred['test_9.jpg'])])","cbcaf0e0":"# Importing the dataset","b846d5fc":"# Model generation, compilation & training","72edcdb0":"Above we can see that the validation accuracy is increasing as the epochs are increasing but after certain epochs we can see it dipping. This may happened due to the overfitting of data hence we stop the epochs. Also we can try out certain others methods to reduce overfitting!","a27f5626":"# Prediction","783317fe":"# Motive of notebook:\n- Identification of pokemon with CNN\n- Used a dataset similar to the Pokemon Generation One in kaggle but smaller\n- Utilise the concepts of Convolution, MaxPooling, Flatten\n- Role of ImageDataGenerator and analysing the validation accuracy\n\nPokemon are represented with 0-9 representing the following :-\n\n    0 : \"Aerodactyl\",  \n    1 : \"Bulbasaur\",  \n    2 : \"Charmander\", \n    3 : \"Dratini\",  \n    4 : \"Fearow\",  \n    5 : \"Mewtwo\",  \n    6 : \"Pikachu\",  \n    7 : \"Psyduck\",  \n    8 : \"Spearow\",  \n    9 : \"Squirtle\"  ","c3bd7df3":"# Constructing the image data generator","3a0ac88d":"# Making seperate training and validation folder"}}