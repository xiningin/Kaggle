{"cell_type":{"fc881c57":"code","821ae610":"code","27120244":"code","acb2a6a0":"code","fb09f538":"code","a24b62ae":"code","b6bd6d94":"code","6a629442":"code","e86344bc":"code","354755a4":"code","98cd40a3":"code","4771cd59":"markdown","48caacf2":"markdown"},"source":{"fc881c57":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import SelectFromModel, RFE\nimport lightgbm as lgb\nfrom xgboost import XGBClassifier\nfrom eli5 import show_weights\nfrom eli5.sklearn import PermutationImportance","821ae610":"train = pd.read_csv(\"..\/input\/census.csv\")\ntest = pd.read_csv(\"..\/input\/test_census.csv\")","27120244":"# numerical\nnum_cols = ['age', 'education-num', 'hours-per-week']\n\n# categorical\ncat_cols = ['workclass', 'education_level', \n            'marital-status', 'occupation', \n            'relationship', 'race', \n            'sex', 'native-country']\n\n# need log transform\nlog_transform_cols = ['capital-loss', 'capital-gain']","acb2a6a0":"minmax = MinMaxScaler()\nsimp = SimpleImputer()\nX_train = pd.get_dummies(train[cat_cols])\nX_test = pd.get_dummies(test[cat_cols])\nprint(X_train.shape, X_test.shape)","fb09f538":"X_num = simp.fit_transform(train[num_cols].values)\nX_log = simp.fit_transform(train[log_transform_cols].values)\nX_log = np.log1p(X_log)\nX_num = minmax.fit_transform(X_num)\nX_log = minmax.fit_transform(X_log)\n\ntest_num = simp.fit_transform(test[num_cols].values)\ntest_log = simp.fit_transform(test[log_transform_cols].values)\ntest_log = np.log1p(test_log)\ntest_num = minmax.fit_transform(test_num)\ntest_log = minmax.fit_transform(test_log)","a24b62ae":"X = np.concatenate((X_num,X_log,X_train.values), axis=1)\ntest = np.concatenate((test_num, test_log, X_test.values), axis=1)\ny = train['income'].map({'<=50K': 0, '>50K': 1})","b6bd6d94":"#Settings found by previous grid search.\nlog_reg = LogisticRegression(class_weight=\"balanced\", C=1, penalty='l1', solver='liblinear', n_jobs=-1, max_iter=1000)\nrf = RandomForestClassifier(class_weight='balanced', n_estimators=300, criterion='entropy', n_jobs=-1, min_samples_split=4, min_weight_fraction_leaf=0.0, max_depth=21, max_leaf_nodes=512)\nxgb = XGBClassifier(n_estimators=300, objective='binary:logistic', silent=True, nthread=-1, colsample_bytree=0.75, gamma=1.5, learning_rate=0.1, max_depth=6, min_child_weight=1, subsample=1.0)\nlgbm = lgb.LGBMClassifier(boosting_type='gbdt', n_estimators=300, objective='binary', n_jobs=-1, silent=True, max_depth=-1, max_bin = 510, subsample_for_bin=200,min_child_weight=1,colsample_bytree=0.65,lambda_l1=3, lambda_l2=3, learning_rate=0.1, min_child_samples=2,min_split_gain=0.2,num_leaves=128, subsample=0.75)","6a629442":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nlog_reg.fit(X_train,y_train)\nrf.fit(X_train,y_train)\nxgb.fit(X_train,y_train)\nlgbm.fit(X_train,y_train)\n\nlog_reg_predictions = log_reg.predict_proba(test)[:,-1]\nrf_predictions = rf.predict_proba(test)[:,-1]\nxgb_predictions = xgb.predict_proba(test)[:,-1]\nlgbm_predictions = lgbm.predict_proba(test)[:,-1]\n\nlog_reg_predictions_train = log_reg.predict_proba(X)[:,-1]\nrf_predictions_train = rf.predict_proba(X)[:,-1]\nxgb_predictions_train = xgb.predict_proba(X)[:,-1]\nlgbm_predictions_train = lgbm.predict_proba(X)[:,-1]\n\nlog_reg_rfe = RFE(log_reg,n_features_to_select=5,step=0.1)\nlog_reg_rfe.fit(X,y)\nlog_reg_rfe_predictions = log_reg_rfe.predict_proba(test)[:,-1]\nlog_reg_rfe_predictions_train = log_reg_rfe.predict_proba(X)[:,-1]\n\nrf_rfe = RFE(rf,n_features_to_select=5,step=0.1)\nrf_rfe.fit(X,y)\nrf_rfe_predictions = rf_rfe.predict_proba(test)[:,-1]\nrf_rfe_predictions_train = rf_rfe.predict_proba(X)[:,-1]\n\nxgb_rfe = RFE(xgb,n_features_to_select=5,step=0.1)\nxgb_rfe.fit(X,y)\nxgb_rfe_predictions = xgb_rfe.predict_proba(test)[:,-1]\nxgb_rfe_predictions_train = xgb_rfe.predict_proba(X)[:,-1]\n\nlgbm_rfe = RFE(lgbm,n_features_to_select=5,step=0.1)\nlgbm_rfe.fit(X,y)\nlgbm_rfe_predictions = lgbm_rfe.predict_proba(test)[:,-1]\nlgbm_rfe_predictions_train = lgbm_rfe.predict_proba(X)[:,-1]\n\nperm_log_reg = PermutationImportance(log_reg).fit(X_test,y_test)\nperm_rf = PermutationImportance(rf).fit(X_test,y_test)\nperm_xgb = PermutationImportance(xgb).fit(X_test,y_test)\nperm_lgbm = PermutationImportance(lgbm).fit(X_test,y_test)\n\nsel_log_reg = SelectFromModel(perm_log_reg, threshold=0.0001, prefit=True)\nX_trans = sel_log_reg.transform(X)\nX_trans_test = sel_log_reg.transform(test)\nlog_reg.fit(X_trans,y)\nlog_reg_perm_predictions = log_reg.predict_proba(X_trans_test)[:,-1]\nlog_reg_perm_predictions_train = log_reg.predict_proba(X_trans)[:,-1]\n\nsel_rf = SelectFromModel(perm_rf, threshold=0.0001, prefit=True)\nX_trans = sel_rf.transform(X)\nX_trans_test = sel_rf.transform(test)\nrf.fit(X_trans,y)\nrf_perm_predictions = rf.predict_proba(X_trans_test)[:,-1]\nrf_perm_predictions_train = rf.predict_proba(X_trans)[:,-1]\n\nsel_xgb = SelectFromModel(perm_xgb, threshold=0.0001, prefit=True)\nX_trans = sel_xgb.transform(X)\nX_trans_test = sel_xgb.transform(test)\nxgb.fit(X_trans,y)\nxgb_perm_predictions = xgb.predict_proba(X_trans_test)[:,-1]\nxgb_perm_predictions_train = xgb.predict_proba(X_trans)[:,-1]\n\nsel_lgbm = SelectFromModel(perm_lgbm, threshold=0.0001, prefit=True)\nX_trans = sel_lgbm.transform(X)\nX_trans_test = sel_lgbm.transform(test)\nlgbm.fit(X_trans,y)\nlgbm_perm_predictions = lgbm.predict_proba(X_trans_test)[:,-1]\nlgbm_perm_predictions_train = lgbm.predict_proba(X_trans)[:,-1]","e86344bc":"fo_train = {\"log\":log_reg_predictions_train,\n            \"rf\":rf_predictions_train,\n            \"xgb\":xgb_predictions_train,\n            \"lgbm\":lgbm_predictions_train,\n            \"log_rfe\":log_reg_rfe_predictions_train,\n            \"rf_rfe\":rf_rfe_predictions_train,\n            \"xgb_rfe\":xgb_rfe_predictions_train,\n            \"lgbm_rfe\":lgbm_rfe_predictions_train,\n            \"log_reg_perm\":log_reg_perm_predictions_train,\n            \"rf_perm\":rf_perm_predictions_train,\n            \"xgb_perm\":xgb_perm_predictions_train,\n            \"lgbm_perm\":lgbm_perm_predictions_train} \nfo_test = {\"log\":log_reg_predictions,\n            \"rf\":rf_predictions,\n            \"xgb\":xgb_predictions,\n            \"lgbm\":lgbm_predictions,\n            \"log_rfe\":log_reg_rfe_predictions,\n            \"rf_rfe\":rf_rfe_predictions,\n            \"xgb_rfe\":xgb_rfe_predictions,\n            \"lgbm_rfe\":lgbm_rfe_predictions,\n            \"log_reg_perm\":log_reg_perm_predictions,\n            \"rf_perm\":rf_perm_predictions,\n            \"xgb_perm\":xgb_perm_predictions,\n            \"lgbm_perm\":lgbm_perm_predictions}\nX_train = pd.DataFrame(fo_train)\nX_test = pd.DataFrame.from_dict(fo_test)\n#print(fo_train)","354755a4":"param_grid = {\n    \"C\": [0.1, 0.3, 0.5, 0.7, 0.9, 1, 2, 3, 4, 5, 10],\n    \"penalty\": ['l1', 'l2'],\n    \"solver\": [\"liblinear\", \"saga\"]\n}\nlinear = LogisticRegression(class_weight=\"balanced\", n_jobs=-1, max_iter=1000)\nsearch = GridSearchCV(estimator=linear, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\nsearch.fit(X_train,y)","98cd40a3":"predictions = search.best_estimator_.predict(X_test)","4771cd59":"# Pre-Processing\nWe start by splitting our columns into numerical columns, further dividing by those that need log-scale transform before min-max scaling, and categorical columns, in need on one-hot encoding.","48caacf2":"# Predict Pipeline\nI now have six estimator strategies. I will make each a probability prediction and run a Logistic Regression on top of it. Three columns for Recursive Feature Elimination, down to top 5. Three for Permutation Importance."}}