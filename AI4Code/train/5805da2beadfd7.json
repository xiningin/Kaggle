{"cell_type":{"082d98e4":"code","b53173f2":"code","1b8d616e":"code","0484518c":"code","40b39306":"code","1685ca27":"code","4456dd7b":"code","590d545b":"code","10643474":"code","7269c409":"code","9ce5fcdc":"code","d323e8a0":"code","b3fb56d7":"code","d0b3286b":"code","842218af":"code","1eb544e5":"code","a7fe36c1":"code","b43149e2":"code","5711d0c3":"markdown"},"source":{"082d98e4":"#This notebook was entirely writen by Rodrigo Ram\u00edrez\n#The purpose of this notebook is to create an Artificial Neural Network in order to predict if a person is vulnerable to suffer a heart stroke\n\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","b53173f2":"#Reading and overview of Healthcare stroke dataset\n\ndataset  = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\ndataset.dropna()\ndataset.head(6)","1b8d616e":"#Dataset info.\ndataset.info","0484518c":"#Splitting the dataframe: X\n\nX = dataset.iloc[:,1:-1]\nX.head()","40b39306":"#Splitting the dataframe: Y (label)\n\nY = dataset.iloc[:,-1]\nY.head()","1685ca27":"# Encoding of Gender column using the Label Encoder from SKLearn\n\nfrom sklearn.preprocessing import LabelEncoder\nlabelEncoder = LabelEncoder()\nX.iloc[:,0]  = labelEncoder.fit_transform(X.iloc[:,0])\nX.head()","4456dd7b":"# Encoding of Ever_married column using the Label Encoder from SKLearn\n\nX.iloc[:,4]  = labelEncoder.fit_transform(X.iloc[:,4])\nX.head()","590d545b":"# Encoding of Residence_type column using the Label Encoder from SKLearn\n\nX.iloc[:,6].unique()\nX.iloc[:,6]  = labelEncoder.fit_transform(X.iloc[:,6])\nX.head()","10643474":"#For columns 'work_type' and 'smoking_status' we weill use OneHotEncoder from SKLearn\n\n\n#from sklearn.compose import ColumnTransformer\n#from sklearn.preprocessing import OneHotEncoder\n\n#columnTransformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [5])], remainder='passthrough')\n#X = columnTransformer.fit_transform(X)\n\n\n#columnTransformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [-1])], remainder='passthrough')\n#X = columnTransformer.fit_transform(X)\n\n#X\n\nX  = X.drop(['work_type', 'smoking_status'], axis=1) #Drop columns: only momentarily","7269c409":"#Splitting dataframe into X_train, X_test, y_train and y_test\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)","9ce5fcdc":"#Delete any outliers in the data using StandardScaler from SKLearn\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","d323e8a0":"#Import Tensorflow and create a Sequential Model to add layer for the ANN\n\nimport tensorflow as tf\nann = tf.keras.models.Sequential()","b3fb56d7":"# Add the first layer with 6 units and the activation function ReLU\n\nann.add(tf.keras.layers.Dense(units=6, activation='relu'))","d0b3286b":"# Add the second and last layer with 1 unit and the activation function Sigmoid\n# I use the a Sigmoid Function because I want my prediction to be classified into 0 an 1 (Yes and No)\n\nann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","842218af":"#Compiling the ANN using ADAM optimizer.\n\nann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","1eb544e5":"#Train the ANN with 100 epochs.\n\nann.fit(X_train, y_train, batch_size = 32, epochs = 100)","a7fe36c1":"#I set the threshold for the predictions. In this case, my threshold is 0.5 (this value can be modified).\n\ny_pred = ann.predict(X_test)\ny_pred = (y_pred > 0.5)\n","b43149e2":"# A confusion matrix helps to evaluate the accuracy of the predictions made. \n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","5711d0c3":"**\nThis Notebook is not finished yet.**\n\n"}}