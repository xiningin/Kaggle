{"cell_type":{"b084e75a":"code","fde13cb4":"code","ee0537f3":"code","a73c592b":"code","ba591b77":"code","73412d6e":"code","ccb052d9":"code","3c151da6":"code","6c9f1bfd":"code","e017a1c8":"code","3325181b":"code","3c890df4":"code","bfa7e7ec":"code","e1d6cc48":"code","4855d9fa":"code","dff5f4fa":"code","90b79dbb":"code","65a1537c":"code","f5f2d24a":"code","168e2e3e":"code","09171f4e":"code","015e753e":"code","d8a13d75":"code","eb80798b":"code","54bd150b":"code","a497e13a":"code","7e270d3f":"code","92403a12":"code","49bd68ec":"code","30fa28cb":"code","fc8c9f6c":"code","f00c6dfd":"markdown","a24168c9":"markdown","1b5ee628":"markdown","eb942e43":"markdown","a799dd83":"markdown","9b6ef26f":"markdown"},"source":{"b084e75a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fde13cb4":"import warnings\nwarnings.filterwarnings('ignore')","ee0537f3":"data = pd.read_csv('\/kaggle\/input\/heart-failure-prediction\/heart.csv')\ndata.head()","a73c592b":"data.info()","ba591b77":"data.isnull().sum()","73412d6e":"def one_sex_encoder(df):\n    df_copy = df.copy()\n    df_copy['Man'] = df_copy['Sex'].map({'M': 1,'F': 0})\n    df_copy['Woman'] = df_copy['Sex'].map({'M': 0,'F': 1})\n    df_copy = df_copy.drop('Sex', axis=1)\n    return df_copy","ccb052d9":"data_ = one_sex_encoder(data)","3c151da6":"def one_chestpain_encoder(df):\n    df_copy = df.copy()\n    df_copy['ATA'] = df_copy['ChestPainType'].map({'ATA': 1, 'NAP': 0, 'ASY': 0, 'TA': 0})\n    df_copy['NAP'] = df_copy['ChestPainType'].map({'ATA': 0, 'NAP': 1, 'ASY': 0, 'TA': 0})\n    df_copy['ASY'] = df_copy['ChestPainType'].map({'ATA': 0, 'NAP': 0, 'ASY': 1, 'TA': 0})\n    df_copy['TA'] = df_copy['ChestPainType'].map({'ATA':0, 'NAP': 0, 'ASY': 0, 'TA': 1})\n    df_copy = df_copy.drop('ChestPainType', axis=1)\n    return df_copy","6c9f1bfd":"data_1 = one_chestpain_encoder(data_)","e017a1c8":"def one_resting_encoder(df):\n    df_copy = df.copy()\n    df_copy['Normal'] = df_copy['RestingECG'].map({'Normal': 1, 'ST': 0, 'LVH': 0})\n    df_copy['ST'] = df_copy['RestingECG'].map({'Normal': 0, 'ST': 1, 'LVH': 0})\n    df_copy['LVH'] = df_copy['RestingECG'].map({'Normal': 0, 'ST': 0, 'LVH': 1})\n    df_copy = df_copy.drop('RestingECG', axis=1)\n    return df_copy","3325181b":"data_2 = one_resting_encoder(data_1)","3c890df4":"def one_angina_encoder(df):\n    df_copy = df.copy()\n    df_copy['No_Angina'] = df_copy['ExerciseAngina'].map({'N': 1, 'Y': 0})\n    df_copy['Ys_Angina'] = df_copy['ExerciseAngina'].map({'N': 0, 'Y': 1})\n    df_copy = df_copy.drop('ExerciseAngina', axis=1)\n    return df_copy","bfa7e7ec":"data_3 = one_angina_encoder(data_2)","e1d6cc48":"def one_slope_encoder(df):\n    df_copy = df.copy()\n    df_copy['Up'] = df_copy['ST_Slope'].map({'Up': 1, 'Flat': 0, 'Down': 0})\n    df_copy['Flat'] = df_copy['ST_Slope'].map({'Up': 0, 'Flat': 1, 'Down': 0})\n    df_copy['Down'] = df_copy['ST_Slope'].map({'Up': 0, 'Flat': 0, 'Down': 1})\n    df_copy = df_copy.drop('ST_Slope', axis=1)\n    return df_copy","4855d9fa":"data_4= one_slope_encoder(data_3)","dff5f4fa":"df = data_4.astype('float64')","90b79dbb":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf.RestingBP = scaler.fit_transform(df.RestingBP[...,np.newaxis])\ndf.Cholesterol = scaler.fit_transform(df.Cholesterol[...,np.newaxis])\ndf.MaxHR = scaler.fit_transform(df.MaxHR[...,np.newaxis])","65a1537c":"# for Training\ntrain = df.sample(frac=.8, random_state=42)\ntrain_x = train.drop('HeartDisease', axis=1)\ntrain_y = train['HeartDisease']\n\n# for Testing\ntest = df.drop(train.index)\ntest_x = test.drop('HeartDisease', axis=1)\ntest_y = test['HeartDisease']","f5f2d24a":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nimport tensorflow as tf\n\n!pip install -q git+https:\/\/github.com\/tensorflow\/docs\nimport tensorflow_docs as tfdocs\nimport tensorflow_docs.plots\nimport tensorflow_docs.modeling","168e2e3e":"from tensorflow.keras.layers import Flatten","09171f4e":"# Creatin a Sequential Model\nmodel = Sequential([\n    Dense(64,activation=tf.nn.relu, input_shape=[train_x.shape[1]]),    \n    Dense(1, activation=tf.nn.sigmoid)\n]\n)","015e753e":"tf.keras.utils.plot_model(model, show_shapes=True)","d8a13d75":"model.summary()","eb80798b":"model.compile(optimizer='adam',\n             loss='mae',\n             metrics=['accuracy'])","54bd150b":"early_stop=tf.keras.callbacks.EarlyStopping( monitor=\n                                            'val_loss', patience=50)","a497e13a":"history = model.fit(x=train_x,\n                   y= train_y,\n                   epochs=1000,validation_split=.2,verbose=0, callbacks=[early_stop,tfdocs.modeling.EpochDots()])","7e270d3f":"import matplotlib.pyplot as plt","92403a12":"loss,acc=model.evaluate(test_x, test_y,verbose=2)","49bd68ec":"plot_obj=tfdocs.plots.HistoryPlotter(smoothing_std=2)","30fa28cb":"plot_obj.plot({'Heart disease': history}, metric = 'accuracy')\nplt.ylim([0, 1])\nplt.ylabel('Heart disease')","fc8c9f6c":"print(\"Testing set Accuracy: {:5.2f} \".format(acc))","f00c6dfd":"# Model NN","a24168c9":"### Preprocessing data","1b5ee628":"# Evaluating the results","eb942e43":"### Analyzing data","a799dd83":"# Splitting for Training and Testing","9b6ef26f":"### Importing data"}}