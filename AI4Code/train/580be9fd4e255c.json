{"cell_type":{"7b52d735":"code","72cc8df7":"code","67f6505a":"code","e9f89ae0":"code","543c08dc":"code","7144b302":"code","f0ce2392":"code","2c1bf27a":"code","8b458c60":"code","0591f2b4":"code","29ee1f18":"code","7c738776":"code","04bfacbe":"code","51cc7e53":"code","a555b4f1":"code","546da283":"code","d7f23e05":"code","33559c12":"code","9a303eba":"code","093af2b3":"code","663a3906":"code","1ef383c7":"code","54f35be1":"code","bcfeb9c5":"code","4c4fc39e":"code","f1bc53e6":"code","ec76e4bb":"code","837c6c68":"code","6a1faea8":"code","129591b8":"code","28473eda":"code","b84c1888":"code","0d4b0760":"code","1aff1b95":"code","74b6f748":"code","9b9c19c3":"code","e3e2af64":"code","85d69c81":"code","8154eb90":"code","7e12c466":"code","eafee60f":"code","3f56a57b":"code","d22c7810":"code","90251a7f":"code","1b0cf54d":"code","1c7c4680":"code","4baaeafd":"code","3c048177":"code","fb7b166e":"code","7d187279":"code","6ceebbbe":"code","406908f5":"code","9fa0f3c3":"code","04b22d94":"code","3fa08172":"code","6f529a8e":"code","d4795f65":"code","b0cf3c16":"code","bbe60b94":"code","9921cf12":"code","07e6a069":"code","76106f89":"code","c51c19ca":"code","e4ea9b63":"code","5d345969":"code","eea34167":"code","0dbcc2c2":"code","1cab6f46":"code","a82f9646":"code","d08ed516":"code","66ec11b1":"code","19bbce1f":"markdown","b90ef537":"markdown","e6ab5417":"markdown","3dc00460":"markdown","9e8b80a2":"markdown","3a7d66c5":"markdown","b544261a":"markdown","2135a451":"markdown","bbc30809":"markdown","8fcda30e":"markdown","8237bd28":"markdown","9cc2dbeb":"markdown","5e81eafb":"markdown","611c5f5a":"markdown","3e798d64":"markdown","ad6a2371":"markdown","9f1740ca":"markdown","0c41e41a":"markdown","40158a58":"markdown","d92f5ca5":"markdown","5fba07de":"markdown","89430a36":"markdown","b828a15d":"markdown","0ce56e8c":"markdown","18fb994c":"markdown","b5698e39":"markdown","ae089b91":"markdown","819cc3fd":"markdown","b87c01a5":"markdown","fe9e62ba":"markdown","5412ab1e":"markdown","45612f52":"markdown","666b0464":"markdown","39e2a230":"markdown","9de41bb1":"markdown","2d6d27d8":"markdown","6625067d":"markdown","e4398fc1":"markdown","356b34af":"markdown","2c4e89e8":"markdown","552cf78a":"markdown","7dc46aec":"markdown","5a32e73b":"markdown","90af6934":"markdown","7d8074dc":"markdown","64833bcc":"markdown","3a896fe8":"markdown","507fef9d":"markdown","c7a85943":"markdown","65feba0b":"markdown","508d1779":"markdown","b97668e9":"markdown","f58d1e0d":"markdown","87c588ab":"markdown","9af448ef":"markdown","16701b35":"markdown","f7f36383":"markdown","803fb85d":"markdown","7d35120c":"markdown","dc745737":"markdown"},"source":{"7b52d735":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\nfrom ast import literal_eval\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom surprise import SVD, Reader, Dataset \nfrom surprise.model_selection import cross_validate","72cc8df7":"df_credits=pd.read_csv('..\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv')","67f6505a":"df_credits.head(2)","e9f89ae0":"df_movies=pd.read_csv('..\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv')","543c08dc":"df_movies.head(2)","7144b302":"df_credits.columns=['id', 'title', 'cast', 'crew']","f0ce2392":"df_movies.drop(['title'], axis=1, inplace=True)","2c1bf27a":"df_movielens=pd.merge(df_credits,df_movies,on='id')","8b458c60":"df_movielens.head(2)","0591f2b4":"df_movielens.shape","29ee1f18":"df_movielens['vote_average'].mean()","7c738776":"df_movielens['vote_count'].quantile(q=0.9)","04bfacbe":"df_filtered=df_movielens[df_movielens['vote_count']>df_movielens['vote_count'].quantile(q=0.9)]","51cc7e53":"df_filtered.shape","a555b4f1":"def movie_score(x):\n    v=x['vote_count']\n    m=df_movielens['vote_count'].quantile(q=0.9)\n    R=x['vote_average']\n    C=df_movielens['vote_average'].mean()\n    return ((R*v)\/(v+m))+((C*m)\/(v+m))","546da283":"df_filtered['score']=df_filtered.apply(movie_score, axis=1)","d7f23e05":"df_highscore=df_filtered.sort_values(by='score', ascending=False).head(10)","33559c12":"df_highscore[['title', 'vote_count', 'vote_average', 'popularity', 'score']]","9a303eba":"df_popular= df_movielens.sort_values('popularity', ascending=False).head(10)","093af2b3":"df_popular[['title', 'vote_count', 'vote_average', 'popularity']]","663a3906":"plt.figure(figsize=(8,6))\nsns.barplot(y='title',x='popularity', data=df_popular, palette='viridis')\nplt.xlabel(\"Popularity\", fontsize=12)\nplt.ylabel(\"Title\", fontsize=12)\nplt.title(\"Popular Movies\", fontsize=15)\nplt.show()","1ef383c7":"df_movielens['overview'].head()","54f35be1":"df_movielens['overview'].isnull().sum()","bcfeb9c5":"df_movielens['overview'].fillna(' ', inplace=True)","4c4fc39e":"tfidfv=TfidfVectorizer(analyzer='word', stop_words='english')\ntfidfv_matrix=tfidfv.fit_transform(df_movielens['overview'])\nprint(tfidfv_matrix.todense())\ntfidfv_matrix.todense().shape","f1bc53e6":"cosine_sim1 = linear_kernel(tfidfv_matrix, tfidfv_matrix)","ec76e4bb":"cosine_sim1.shape ","837c6c68":"indices=pd.Series(data=list(df_movielens.index), index= df_movielens['title'] )","6a1faea8":"indices.head()","129591b8":"# Function that takes in movie title as input and outputs most similar movies\ndef content_recommendations(title, cosine_sim):\n    \n    # Get the index of the movie that matches the title\n    idx = indices[title]\n    \n    # Get the pairwsie similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    \n    # Sort the movies based on the similarity scores\n    sim_scores.sort(key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores=sim_scores[1:11]\n    \n    # Get the movie indices\n    ind=[]\n    for (x,y) in sim_scores:\n        ind.append(x)\n        \n    # Return the top 10 most similar movies\n    tit=[]\n    for x in ind:\n        tit.append(df_movielens.iloc[x]['title'])\n    return pd.Series(data=tit, index=ind)","28473eda":"content_recommendations('The Dark Knight Rises',cosine_sim1)","b84c1888":"content_recommendations('The Avengers',cosine_sim1)","0d4b0760":"type(df_movielens['cast'].iloc[0])","1aff1b95":"features = ['cast', 'crew', 'keywords', 'genres']\nfor feature in features:\n    df_movielens[feature] = df_movielens[feature].apply(literal_eval)","74b6f748":"type(df_movielens['cast'].iloc[0])","9b9c19c3":"# Get the director's name from the crew feature. If director is not listed, return NaN\ndef get_director(x):\n    for a in x:\n        if a['job']=='Director':\n            return a['name'] \n    return 'NaN'","e3e2af64":"# Get the list top 3 elements or entire list; whichever is more in cast, genres and keywords columns.\ndef get_top3(x):\n    new=[]\n    for a in x[:3]:\n        new.append(a['name']) \n    return new\n#Return empty list in case of missing\/malformed data\n    return []","85d69c81":"df_movielens['director']=df_movielens['crew'].apply(lambda x: get_director(x))","8154eb90":"df_movielens['actor']=df_movielens['cast'].apply(lambda x:get_top3(x))","7e12c466":"df_movielens['genres']=df_movielens['genres'].apply(lambda x:get_top3(x))","eafee60f":"df_movielens['keywords']=df_movielens['keywords'].apply(lambda x:get_top3(x))","3f56a57b":"df_movielens[['title', 'actor', 'director', 'keywords', 'genres']].head(3)","d22c7810":"def clean_director(x):\n    return x.lower().replace(' ','')","90251a7f":"def clean_top3(x):\n    new=[]\n    for a in x:\n        new.append(a.lower().replace(' ',''))\n    return new","1b0cf54d":"df_movielens['director']=df_movielens['director'].apply(lambda x: clean_director(x))","1c7c4680":"df_movielens['actor']=df_movielens['actor'].apply(lambda x:clean_top3(x))","4baaeafd":"df_movielens['keywords']=df_movielens['keywords'].apply(lambda x:clean_top3(x))","3c048177":"df_movielens['genres']=df_movielens['genres'].apply(lambda x:clean_top3(x))","fb7b166e":"df_movielens[['title', 'actor', 'director', 'keywords', 'genres']].head(3)","7d187279":"def create_soup(x):\n    return ' '.join(x['keywords']) + ' ' + ' '.join(x['actor']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])","6ceebbbe":"df_movielens['soup'] = df_movielens.apply(create_soup, axis=1)","406908f5":"cv = CountVectorizer(stop_words='english')\ncv_matrix = cv.fit_transform(df_movielens['soup'])","9fa0f3c3":"cosine_sim2 = cosine_similarity(cv_matrix, cv_matrix)","04b22d94":"content_recommendations('The Dark Knight Rises', cosine_sim2)","3fa08172":"content_recommendations('The Godfather', cosine_sim2)","6f529a8e":"from surprise import SVD, Reader, Dataset \nfrom surprise.model_selection import cross_validate","d4795f65":"df_rating= pd.read_csv('..\/input\/the-movies-dataset\/ratings_small.csv')\ndf_rating.head()","b0cf3c16":"# We will use the famous SVD algorithm.\nsvd = SVD()","bbe60b94":"reader = Reader()","9921cf12":"# Load the ratings_small dataset (download it if needed),\ndata = Dataset.load_from_df(df_rating[['userId', 'movieId', 'rating']], reader)","07e6a069":"# Run 5-fold cross-validation and print the results\ncross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)","76106f89":"#sample full trainset\ntrainset = data.build_full_trainset()","c51c19ca":"# Train the algorithm on the trainset\nsvd.fit(trainset)","e4ea9b63":"df_rating[df_rating['userId'] == 1]","5d345969":"# predict ratings for the testset\nsvd.predict(uid=1, iid=302, r_ui=None)","eea34167":"# directly grab the estimated ratings for the testset\nsvd.predict(uid=1, iid=302, r_ui=None).est","0dbcc2c2":"df_movielens.columns=['movieId', 'title', 'cast', 'crew', 'budget', 'genres', 'homepage',\n       'keywords', 'original_language', 'original_title', 'overview',\n       'popularity', 'production_companies', 'production_countries',\n       'release_date', 'revenue', 'runtime', 'spoken_languages', 'status',\n       'tagline', 'vote_average', 'vote_count', 'director', 'actor', 'soup']","1cab6f46":"# Function that takes in movie title as input and outputs most similar movies\ndef hybrid_recommendations(userId, title):\n    \n    # Get the index of the movie that matches the title\n    idx = indices[title]\n    \n    # Get the pairwsie similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim2[idx]))\n    \n    # Sort the movies based on the similarity scores\n    sim_scores.sort(key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores=sim_scores[1:11]\n    \n    # Get the movie indices\n    ind=[]\n    for (x,y) in sim_scores:\n        ind.append(x)\n        \n    # Grab the title,movieid,vote_average and vote_count of the top 10 most similar movies\n    tit=[]\n    movieid=[]\n    vote_average=[]\n    vote_count=[]\n    for x in ind:\n        tit.append(df_movielens.iloc[x]['title'])\n        movieid.append(df_movielens.iloc[x]['movieId'])\n        vote_average.append(df_movielens.iloc[x]['vote_average'])\n        vote_count.append(df_movielens.iloc[x]['vote_count'])\n\n        \n    # Predict the ratings a user might give to these top 10 most similar movies\n    est_rating=[]\n    for a in movieid:\n        est_rating.append(svd.predict(userId, a, r_ui=None).est)  \n        \n    return pd.DataFrame({'index': ind, 'title':tit, 'movieId':movieid, 'vote_average':vote_average, 'vote_count':vote_count,'estimated_rating':est_rating}).set_index('index').sort_values(by='estimated_rating', ascending=False)\n","a82f9646":"hybrid_recommendations(1,'Avatar')","d08ed516":"hybrid_recommendations(4,'Avatar')","66ec11b1":"content_recommendations('Avatar', cosine_sim2)","19bbce1f":"We should keep in mind that this demographic recommender provide a general chart of recommended movies to all the users, regardless of the user's personal taste. It is not sensitive to the interests and tastes of a particular user, and it does not give personalized recommendations based on the users.","b90ef537":"### Movie Cast, Crew, Keywords, Genres Based Recommender","e6ab5417":"## Introduction\n\nThe rapid growth of data collection has led to a new era of information. Data is being used to create more efficient systems and this is where Recommendation Systems come into play. Recommendation Systems are a type of information filtering systems as they improve the quality of search results and provides items that are more relevant to the search item or are related to the search history of the user.\n\nThey are used to predict the rating or preference that a user would give to an item. Almost every major tech company has applied them in some form or the other: Amazon uses it to suggest products to customers, YouTube uses it to decide which video to play next on autoplay, and Facebook uses it to recommend pages to like and people to follow. Moreover, companies like Netflix and Spotify depend highly on the effectiveness of their recommendation engines for their business and success.\n\nThere are mainly three types of recommender systems:\n\n- **Demographic Recommender**\n   - It offers generalized recommendations to every user, based on movie popularity. This system recommends the same movies with similar demographic features to all users and it does not give personalized recommendations to users. \n\n\n- **Content-Based Recommender**\n    - It builds an engine that computes similarity between movies based on certain metrics (such as genre, director, description, actors, etc.) and suggests movies that are most similar to a particular movie that a user liked. The general idea behind these recommender systems is that if a person liked a particular item, he or she will also like an item that is similar to it.\n\n- **Collaborative Recommender**\n   - This system matches persons with similar interests and provides recommendations based on this matching. Collaborative filtering is based on the idea that users similar to a particular user can be used to predict how much that particular user will like a particular product or service those users have used\/experienced but that particular user has not. \n\nIn this notebook, we will use MovieLens datasets and implement three recommendation algorithms including Demographic, Content-Based and Collaborative Filtering, and finally try to build an ensemble of these models to come up with our final **Hybrid Recommendation System**.\n\n\n**The MovieLens datasets include**:\n- \"tmdb_5000_credits\" which contains the following features:\n\n   -  movie_id - A unique identifier for each movie.\n   -  title - Title of each movie.\n   -  cast - The name of lead and supporting actors.\n   -  crew - The name of Director, Editor, Composer, Writer etc.\n   \n   \n- \"tmdb_5000_movies\" which contains the following features:\n  - budget - The budget in which the movie was made.\n  - genre - The genre of the movie, Action, Comedy,Thriller etc.\n  - homepage - A link to the homepage of the movie.\n  - id - This is in fact the movie_id as in the first dataset.\n  - keywords - The keywords or tags related to the movie.\n  - original_language - The language in which the movie was made.\n  - original_title - The title of the movie before translation or adaptation.\n  - overview - A brief description of the movie.\n  - popularity - A numeric quantity specifying the movie popularity.\n  - production_companies - The production house of the movie.\n  - production_countries - The country in which it was produced.\n  - release_date - The date on which it was released.\n  - revenue - The worldwide revenue generated by the movie.\n  - runtime - The running time of the movie in minutes.\n  - status - \"Released\" or \"Rumored\".\n  - tagline - Movie's tagline.\n  - title - Title of the movie.\n  - vote_average - average ratings the movie recieved.\n  - vote_count - the count of votes recieved.\n  \n\n- \"ratings_small\" which contains the following features:\n  - userId - A unique identifier for each user.\n  - movieId - A unique identifier for each movie. \n  - rating - The rating given by the user for each movie.\n  - timestamp - The time when rating was recorded.\n  ","3dc00460":"Finally, we sort the dataframe based on the score feature. Then we output the title, genres, vote count, vote average, popularity and score of the top 10 movies.","9e8b80a2":"We see that our recommender has been successful in capturing more information due to more metadata and has given us better recommendations. It is more likely that Marvels or DC comics fans will like the movies of the same production house. Therefore, to our features above we can add production_company . We can also increase the weight of the director , by adding the feature multiple times in the soup.","3a7d66c5":"We see that over 20,000 different words were used to describe the 4803 movies in our dataset.","b544261a":"#### Defining Recommendation Function","2135a451":"## Collaborative Recommender","bbc30809":"We now have a pairwise cosine similarity matrix for all the movies in our dataset. ","8fcda30e":"#### Applying Recommendation Function","8237bd28":"## Conclusion","9cc2dbeb":"### Movie Overview Based Recommender","5e81eafb":"The next step would be to convert the names and keyword instances into lowercase and strip all the spaces between them. This is done so that our vectorizer doesn't count the Johnny of \"Johnny Depp\" and \"Johnny Galecki\" as the same.","611c5f5a":"Now, we filter the movies that qualify for the chart and put them in a new dataframe called df_filtered.","3e798d64":"Now we apply these clean functions on director, actor, genres and keywords columns.","ad6a2371":"Now we join these two dataset on the 'id' column. As both dataframes contain a 'title' column, we remove on of the title columns.","9f1740ca":"## Importing Libraries","0c41e41a":"We use the algorithm to predict his\/her score for move_id of 302.","40158a58":"For movie with ID 302, we get an estimated prediction of 2.63. One startling feature of this recommender system is that it does not care what the movie is (or what it contains). It works purely on the basis of an assigned movie ID and tries to predict ratings based on how the other users have predicted the movie.","d92f5ca5":"We can see that if content-based recommendation is used alone and the 'soup' column is used as the content, the order of  recommended movies similar to a particular movie is fixed, regardless of the users. However, when we combine the content-based recommendation with the collaborative recommendation and build a hybrid recommendation, the order of recommended movies similar to a particular movie varies for different users.  ","5fba07de":"The next step is to define a recommendation function that takes in a movie title as an input and outputs a list of the 10 most similar movies. In order to do this;\n\n- We need a reverse mapping of movie titles and dataframe indices. In other words, we build a series to identify the index of a movie in our dataframe, given its title.\n\n- The function should get the index of the movie given its title.\n\n- Get the list of cosine similarity scores for that particular movie with all movies. Convert it into a list of tuples where the first element is its position and the second is the similarity score.\n\n- Sort the aforementioned list of tuples based on the similarity scores; that is, the second element.\n\n- Get the top 10 elements of this list. Ignore the first element as it refers to self (the movie most similar to a particular movie is the movie itself).\n\n- Return the titles corresponding to the indices of the top elements.","89430a36":"So we made a demographic recommender. To find the movies that are very popular, we sort the dataset by the 'popularity' column.","b828a15d":"#### Constructing TF-IDF Matrix ","0ce56e8c":"In order to improve the quality of the content-based recommender, we use better metadata. So we build a recommender based on the following metadata: \n- the director\n- the 3 top actors\n- the 3 top related genres \n- the 3 top movie plot keywords\n\nFrom the crew, cast, genres and keywords features, we need to extract the the director, and the three most important actors, genres and keywords associated with that movie. ","18fb994c":"##### Applying literal_eval Function on Stringified Lists","b5698e39":"## Loading Datasets","ae089b91":"#### Preprocessing the Contents","819cc3fd":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Introduction<\/a><\/span><\/li><li><span><a href=\"#Importing-Libraries\" data-toc-modified-id=\"Importing-Libraries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Importing Libraries<\/a><\/span><\/li><li><span><a href=\"#Loading-Datasets\" data-toc-modified-id=\"Loading-Datasets-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Loading Datasets<\/a><\/span><\/li><li><span><a href=\"#Demographic-Recommender\" data-toc-modified-id=\"Demographic-Recommender-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Demographic Recommender<\/a><\/span><\/li><li><span><a href=\"#Content-Based-Recommender\" data-toc-modified-id=\"Content-Based-Recommender-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Content-Based Recommender<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Movie-Overview-Based-Recommender\" data-toc-modified-id=\"Movie-Overview-Based-Recommender-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;<\/span>Movie Overview Based Recommender<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Constructing-TF-IDF-Matrix\" data-toc-modified-id=\"Constructing-TF-IDF-Matrix-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;<\/span>Constructing TF-IDF Matrix<\/a><\/span><\/li><li><span><a href=\"#Computing-Similarity-Score\" data-toc-modified-id=\"Computing-Similarity-Score-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;<\/span>Computing Similarity Score<\/a><\/span><\/li><li><span><a href=\"#Defining-Recommendation-Function\" data-toc-modified-id=\"Defining-Recommendation-Function-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;<\/span>Defining Recommendation Function<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Movie-Cast,-Crew,-Keywords,-Genres-Based-Recommender\" data-toc-modified-id=\"Movie-Cast,-Crew,-Keywords,-Genres-Based-Recommender-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;<\/span>Movie Cast, Crew, Keywords, Genres Based Recommender<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing-the-Contents\" data-toc-modified-id=\"Preprocessing-the-Contents-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;<\/span>Preprocessing the Contents<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Applying-literal_eval-Function-on-Stringified-Lists\" data-toc-modified-id=\"Applying-literal_eval-Function-on-Stringified-Lists-5.2.1.1\"><span class=\"toc-item-num\">5.2.1.1&nbsp;&nbsp;<\/span>Applying literal_eval Function on Stringified Lists<\/a><\/span><\/li><li><span><a href=\"#Defining-Functions-to-Grab-the-Contents\" data-toc-modified-id=\"Defining-Functions-to-Grab-the-Contents-5.2.1.2\"><span class=\"toc-item-num\">5.2.1.2&nbsp;&nbsp;<\/span>Defining Functions to Grab the Contents<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Constructing-TF-IDF-Matrix\" data-toc-modified-id=\"Constructing-TF-IDF-Matrix-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;<\/span>Constructing TF-IDF Matrix<\/a><\/span><\/li><li><span><a href=\"#Computing-Similarity-Score\" data-toc-modified-id=\"Computing-Similarity-Score-5.2.3\"><span class=\"toc-item-num\">5.2.3&nbsp;&nbsp;<\/span>Computing Similarity Score<\/a><\/span><\/li><li><span><a href=\"#Applying-Recommendation-Function\" data-toc-modified-id=\"Applying-Recommendation-Function-5.2.4\"><span class=\"toc-item-num\">5.2.4&nbsp;&nbsp;<\/span>Applying Recommendation Function<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#Collaborative-Recommender\" data-toc-modified-id=\"Collaborative-Recommender-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>Collaborative Recommender<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#SVD:-Matrix-Factorization-Based-Algorithm\" data-toc-modified-id=\"SVD:-Matrix-Factorization-Based-Algorithm-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;<\/span>SVD: Matrix Factorization Based Algorithm<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Hybrid-Recommender\" data-toc-modified-id=\"Hybrid-Recommender-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;<\/span>Hybrid Recommender<\/a><\/span><\/li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;<\/span>Conclusion<\/a><\/span><\/li><\/ul><\/div>","b87c01a5":"We can compute the similarity score by different methods such as euclidean, Pearson and cosine similarity. We choose the cosine similarity to calculate a numeric quantity that denotes the similarity between two movies because it is independent of magnitude and is relatively easy and fast to calculate. Mathematically, it is defined as follows:\n\n$cosine(x,y) = \\frac{x. y^\\intercal}{||x||.||y||} $\n\n\nSince we have used the TfidfVectorizer, calculating the dot product will directly give us the cosine similarity score. Therefore, we will use sklearn's **linear_kernel** instead of cosine_similarities since it is faster.","fe9e62ba":"Since we have used Countvectorizer, we use **cosine_similarities** to compute the similarity score.","5412ab1e":"We see that there are 481 movies which qualify to be in this list.","45612f52":"The mean rating for all the movies is approximately 6 on a scale of 10.\n\nThe next step is to determine an appropriate value for m, the minimum number of votes required for a movie to be listed in the chart. We use 90th percentile as our cutoff. In other words, for a movie to feature in the charts, the number of its votes should be higher than that of 90% of the movies in the list.","666b0464":"Now we create the 'soup' column, that contains all the metadata that we want to feed to our vectorizer (namely actors, director, genres and keywords).","39e2a230":"We replace NaN in 'overview' column with an empty string.","9de41bb1":"# <center> Movie Recommendation Systems <\/center>","2d6d27d8":"The next steps are the same as what we did with our Movie Overview Based Recommender. One important difference is that we use the CountVectorizer() instead of TF-IDF. This is because we do not want to down-weight the presence of an actor\/director if he or she has acted or directed in relatively more movies.","6625067d":"#### Computing Similarity Score","e4398fc1":"The implementation of Demographic Filtering is straighforward. All we have to do is sort our movies based on ratings, and display the top movies of our list. Therefore, we should;\n\n- Create a metric to score or rate the movies.\n- Calculate the score for every movie\n- Sort the scores and recommend the best rated movie to the users.\n\nWe can use the average ratings of the movie as the score but using this will not be fair enough since a movie with 8.9 average rating and only 3 votes cannot be considered better than the movie with 7.8 as as average rating but 40 votes. So, we use IMDB's weighted rating formula to score the movies, as follows:\n\nWeighted Rating (WR) = $(\\frac{v}{v + m} . R) + (\\frac{m}{v + m} . C)$ \n\n- v: the number of votes for the movie\n\n- m: the minimum votes required to be listed in the chart\n\n- R: the average rating of the movie\n\n- C: the mean vote across the whole report\n\nWe already have v or 'vote_count' column, and R or 'vote_average' column. So we calculate C.","356b34af":"##### Defining Functions to Grab the Contents","2c4e89e8":"To personalize the recommendations, we build an engine that computes similarity between movies based on certain metrics and suggests movies that are most similar to a particular movie that a user liked. \n\nWe build two Content-Based Recommenders based on contents including:\n\n- Movie Overview \n- Movie Cast, Crew, Keywords and Genre","552cf78a":"Our content-based engine suffers from some severe limitations. It is only capable of suggesting movies which are close to a certain movie. That is, it is not capable of capturing tastes and providing recommendations across genres.\n\nAlso, the engine that we built is not really personal in that it does not capture the personal tastes and biases of a user. Anyone querying our engine for recommendations based on a movie will receive the same recommendations for that movie, regardless of who she\/he is.\n\nTherefore, in this section, we will use a technique called **Collaborative Filtering** to make recommendations to Movie Watchers.\n\nCollaborative Filtering matches persons with similar interests and provides recommendations based on this matching. It is based on the idea that users similar to me can be used to predict how much I will like a particular product or service those users have used\/experienced but I have not. This system does not require item metadata like its content-based counterparts.\n\n**Surprise** library is a Python scikit for building and analyzing recommender systems that deal with explicit rating data. Here we use the Surprise library that uses extremely powerful algorithms like **Singular Value Decomposition (SVD)** to minimise Root Mean Square Error (RMSE) that is measured by **Kfold Cross Validation** and give great recommendations.","7dc46aec":"Now we compute Term Frequency-Inverse Document Frequency (TF-IDF) vectors for each overview.\n\nTerm Frequency (TF) is the relative frequency of a word in a document and is given as (term instances\/total instances). Inverse Document Frequency (IDF) is the relative count of documents containing the term and is given as log(number of documents\/documents with term). The overall importance of each word to the documents in which they appear is equal to TF * IDF\n\nThis gives us a matrix where each column represents a word in the overall overview vocabulary and each row represents a movie.This is done to reduce the importance of words that occur frequently in plot overviews and therefore, their significance in computing the final similarity score.\n\nScikit-learn has a built-in TfIdfVectorizer class that produces the TF-IDF matrix in a couple of lines.","5a32e73b":"We get a mean Root Mean Sqaure Error of 0.89 approx which is good enough for our case. Let us now train on our dataset and arrive at predictions.","90af6934":"![13.png](attachment:13.png)","7d8074dc":"In this section, we try to build a simple hybrid recommender that brings together techniques we have implemented in the content-based and collaborative filter based engines. This is how it works:\n\n- Input: User ID and the Title of a Movie\n\n- Output: Similar movies sorted on the basis of expected ratings by that particular user.","64833bcc":"### SVD: Matrix Factorization Based Algorithm","3a896fe8":"Let us pick user with user Id 1 and check the ratings she\/he has given.\n","507fef9d":"Right now, our data in 'crew', 'cast', 'genres' and 'keywords' columns is present in the form of \"stringified\" lists. So we need to convert it into a safe and usable structure. literal_eval is a function which evaluates a string as though it were an expression and returns a result.","c7a85943":"While our system has done a decent job of finding movies with similar overviews and descriptions, the quality of recommendations is not that great. \"The Dark Knight Rises\" returns all Batman movies while it is more likely that the people who liked that movie are more inclined to enjoy other Christopher Nolan movies. This is something that cannot be captured by the present system.","65feba0b":"#### Constructing TF-IDF Matrix ","508d1779":"Note that in this dataset, movies are rated on a scale of 5 unlike 'vote_average' column in df_movielens.","b97668e9":"First we compute pairwise similarity scores for all movies based on their 'overview' column. Then recommend movies based on that similarity score.","f58d1e0d":"Now we define new director, actor, genres and keywords columns.","87c588ab":"#### Computing Similarity Score","9af448ef":"## Content-Based Recommender","16701b35":"## Demographic Recommender ","f7f36383":"We can now reuse our content_recommendations function by passing in the new cosine_sim2 matrix as the second argument.","803fb85d":"We built four different recommendation engines based on different ideas and algorithms. They are as follows:\n\n-   **Demographic Recommender:** This system used the overall Vote Count and Vote Averages to build Top Movies Charts, in general and for a specific genre. The IMDB Weighted Rating System was used to calculate ratings on which the sorting was finally performed.\n\n    \n-   **Content-Based Recommender:** We built two content-based engines; one that took movie overview as input and the other took metadata such as cast, crew, genre and keywords to come up with predictions. \n\n\n-   **Collaborative Filtering:** We used the powerful Surprise Library to build a collaborative filter based on single value decomposition. The RMSE obtained was less than 1 and the engine gave estimated ratings for a given user and movie.\n\n\n-   **Hybrid Engine:** We combined content-based and collaborative filtering to build an engine that gave movie suggestions to a particular user who liked a particular movie based on the estimated ratings that had been internally calculated for that user as well as the similarities between movies. While Demographic Filtering is very elementary and cannot be used practically, Hybrid Systems can take advantage of both Content-Based and Collaborative filtering and make reliable predictions. ","7d35120c":"## Hybrid Recommender","dc745737":"Now, we calculate score for each qualified movie. To do this, we define a function, weighted_rating(), and apply this function to the DataFrame of qualified movies."}}