{"cell_type":{"7dcbf533":"code","cd3950d9":"code","4a3d99ba":"code","2888da07":"code","cd4d9a8e":"code","98d0a719":"code","63b01b28":"code","adb4d3a8":"code","0c4e6fb2":"code","71673fd6":"code","a68ab49c":"code","8d6bcb2a":"markdown"},"source":{"7dcbf533":"  import numpy as np\n  import pandas as pd\n  from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n  from sklearn.model_selection import train_test_split # Import train_test_split function\n  from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation","cd3950d9":"name = ['sepal_length', 'sepal_width','petal_length','petal_width','class1']","4a3d99ba":"iris1 = pd.read_csv(\"..\/input\/iris-dataset\/iris.data.csv\",header=None, names=name)\niris1.head(8)","2888da07":"iris1.isnull().sum()","cd4d9a8e":"#split dataset in features and target variable\nfeature = ['sepal_length', 'sepal_width','petal_length','petal_width'] \nX = iris1[feature].values # Features\ny = iris1.class1 # Target variable","98d0a719":"# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)","63b01b28":"#Phase3\n#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","adb4d3a8":"#Using Logistic Regression Algorithm to the Training Set\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state = 0)\nlr.fit(X_train, y_train)\n\n#Using KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\nfrom sklearn.neighbors import KNeighborsClassifier\nkNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nkNN.fit(X_train, y_train)\n\n#Using SVC method of svm class to use Support Vector Machine Algorithm\nfrom sklearn.svm import SVC\nlsvc = SVC(kernel = 'linear', random_state = 0)\nlsvc.fit(X_train, y_train)\n\n#Using SVC method of svm class to use Kernel SVM Algorithm\nfrom sklearn.svm import SVC\nrbf = SVC(kernel = 'rbf', random_state = 0)\nrbf.fit(X_train, y_train)\n\n#Using GaussianNB method of na\u00efve_bayes class to use Na\u00efve Bayes Algorithm\nfrom sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\n\n#Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm\n\nfrom sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\ndtc.fit(X_train, y_train)\n\n#Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\n\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nrfc.fit(X_train, y_train)","0c4e6fb2":"Y_pred = gnb.predict(X_test)","71673fd6":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, Y_pred)\ncm","a68ab49c":"#test the three models with the test data and print their accuracy scores\n\n#print('classifier: {}'.format(sc.score(X_test, y_test)))\nprint('lr: {}'.format(lr.score(X_test, y_test)))\nprint('kNN: {}'.format(kNN.score(X_test, y_test)))\nprint('lsvc: {}'.format(lsvc.score(X_test, y_test)))\nprint('rdf: {}'.format(rbf.score(X_test, y_test)))\nprint('gnbr: {}'.format(gnb.score(X_test, y_test)))\nprint('dtc: {}'.format(dtc.score(X_test, y_test)))\nprint('rfc: {}'.format(rfc.score(X_test, y_test)))","8d6bcb2a":"# 4. Use iris dataset and create a classification model using Gaussian na\u00efve bayes classifier. \n- Compare the result of Na\u00efve bayes Classifier with the Decision tree classifier and Logistic Regessor."}}