{"cell_type":{"c0899f8e":"code","9e54a4e3":"code","493dfa8a":"code","e45b202d":"code","20eb49c1":"code","f4546468":"code","95950dac":"code","2acf3f5b":"code","8a17d8d7":"code","98366ccc":"code","9065ac14":"code","68e49dc7":"code","ab865ec2":"code","b93d3a12":"code","1005d8e4":"code","3fddceb1":"code","a90425f4":"code","cda635fe":"code","0809c68d":"markdown","ee0a7108":"markdown","03b010a9":"markdown","5fcd10ce":"markdown","5608d525":"markdown","11db2037":"markdown","1ea9c1f3":"markdown","bc19e45b":"markdown"},"source":{"c0899f8e":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport tensorflow as tf\nfrom tensorflow.keras import datasets ,layers,models\nimport matplotlib.pyplot as plt\nfrom keras.applications import VGG19\nfrom keras.applications.vgg19 import preprocess_input\nfrom tensorflow.keras.applications import *\nfrom keras.callbacks import ReduceLROnPlateau\n\nimport numpy as np\nimport pickle\nimport cv2\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization","9e54a4e3":"IMG_SIZE = 256\nBATCH_SIZE = 32\nNB_CHANNELS = 3\nNB_CLASSES = 15","493dfa8a":"\n### train = ImageDataGenerator(rescale = 1\/255)\ntrain = ImageDataGenerator(rescale=1.\/255,\n        validation_split=0.2,\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n","e45b202d":"train_dataset = train.flow_from_directory(\n        '..\/input\/plant-village\/PlantVillage',\n        target_size=(256, 256), \n        subset=\"training\",\n        shuffle=True,\n        class_mode='sparse')\nval_dataset = train.flow_from_directory(\n        '..\/input\/plant-village\/PlantVillage',\n        target_size=(256, 256), \n        subset=\"validation\",\n        shuffle=True,\n        class_mode='sparse')","20eb49c1":"val_dataset.class_indices\n","f4546468":"BATCH_SIZE = 32\nIMAGE_SIZE = 256\nCHANNELS=3\nEPOCHS=50\ndataset = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/plant-village\/PlantVillage\",\n    seed=123,\n    shuffle=True,\n    image_size=(IMAGE_SIZE,IMAGE_SIZE),\n    batch_size=BATCH_SIZE\n)","95950dac":"class_names = dataset.class_names\nclass_names","2acf3f5b":"\nfor image_batch, labels_batch in dataset.take(1):\n    print(image_batch.shape)\n    print(labels_batch.numpy())","8a17d8d7":"plt.figure(figsize=(15,15))\nfor image_batch , label_batch in dataset.take(1) :\n    #convert the array from tensor to numpy array\n    print(image_batch.shape)\n    print(label_batch.numpy())\n    for i in range(12) : \n        ax = plt.subplot(3,4,i+1)\n        #convert the array from tensor to numpy array\n        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[label_batch[i]])\n        plt.axis(\"off\")","98366ccc":"def get_dataset_partition(ds , train_split=0.8, val_split=0.1, test_split=0.1, shuffle = True, shuffle_size=10000 ) : \n    ds_size = len(ds)\n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed = 12)\n    train_size = int(train_split * ds_size)\n    val_size = int(val_split * ds_size)\n    \n    train_ds = ds.take(train_size)\n    val_ds = ds.skip(train_size).take(val_size)\n    test_ds = ds.skip(val_size).skip(val_size)\n    \n    return train_ds, val_ds, test_ds","9065ac14":"train_ds , val_ds , test_ds = get_dataset_partition(dataset)","68e49dc7":"type(train_ds)","ab865ec2":"len(train_ds)","b93d3a12":"\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\nval_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\ntest_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\n","1005d8e4":"resize_and_rescale = tf.keras.Sequential([\n  layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n  layers.experimental.preprocessing.Rescaling(1.\/255),\n])","3fddceb1":"data_augmentation = tf.keras.Sequential([\n  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n  layers.experimental.preprocessing.RandomRotation(0.2),\n])","a90425f4":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape = (IMG_SIZE , IMG_SIZE , NB_CHANNELS)))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dense(NB_CLASSES))\nmodel.add(Activation(\"softmax\"))\nmodel.summary()","cda635fe":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n                                            patience = 2,\n                                            verbose=1,\n                                            factor=0.1,\n                                            min_lr=0.000001)\nopt = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(optimizer='adam',\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy'])\nhistory = model.fit(train_dataset ,validation_data = val_dataset , batch_size = 32 , epochs = 20  , shuffle=True,callbacks = [learning_rate_reduction])\nhistory\nmodel.save('.\/plant_model')","0809c68d":"## Creating the Dataset using keras.preprocessing.image_dataset_from_directory","ee0a7108":"##### ","03b010a9":"# build a cnn model","5fcd10ce":"# Caching\nThe tf.data.Dataset.cache transformation can cache a dataset, either in memory or on local storage. This will save some operations (like file opening and data reading) from being executed during each epoch.\n![image.png](attachment:c2b703bc-a00f-41f1-844c-490acaab491f.png)","5608d525":"# Prefetching\nThe tf.data API provides the tf.data.Dataset.prefetch transformation. It can be used to decouple the time when data is produced from the time when data is consumed\n![image.png](attachment:a07c6036-f627-43ea-8a30-91e15115f409.png)","11db2037":"# Creating the Dataset using tf.keras.preprocessing.image_dataset_from_directory","1ea9c1f3":"# in this part , will use the tf.data API to build highly performant TensorFlow input pipelines for those who are going to implement this code locally ","bc19e45b":"Under the hood, this is how  execution time was spent on a specific Dataset \n![image.png](attachment:dff9ef65-9d03-4583-a07d-084e8b286cf3.png)"}}