{"cell_type":{"3379c8d6":"code","38e961dc":"code","9a7cf0fa":"code","96f70735":"code","c07bc375":"code","f90bda0c":"code","d9aa2baa":"code","79d402ba":"code","f411c382":"code","e5278213":"code","c4bae51e":"code","a5938bc8":"code","490ee032":"code","e5423a28":"code","3aa503f9":"code","d7d1b237":"code","b2e312b4":"code","2c4de493":"code","bc26dbfb":"code","89975eab":"code","33c5ee10":"code","cb227782":"code","b1f780f9":"code","06085175":"code","f79fc3fe":"markdown","61dfde03":"markdown","6469cfd5":"markdown","5fe336cc":"markdown","5de0b281":"markdown","cf8a3da5":"markdown","47ba96be":"markdown","1594ed1b":"markdown","e48d6dd2":"markdown","827a5e9b":"markdown","9624eeb4":"markdown","8dfea084":"markdown","0514396f":"markdown","283bc246":"markdown","91fb21cb":"markdown"},"source":{"3379c8d6":"import numpy as np\nimport pandas as pd\nimport os\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.figure_factory as ff\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","38e961dc":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-feb-2021\/train.csv', index_col='id')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-feb-2021\/test.csv', index_col='id')\nsample = pd.read_csv('\/kaggle\/input\/tabular-playground-series-feb-2021\/sample_submission.csv', index_col='id')","9a7cf0fa":"print(\"Train shape :\",train.shape, \"\\n  Test shape:\", test.shape, \"\\nSample shape:\", sample.shape)","96f70735":"pd.set_option('display.max_columns',None)\ntrain.head()","c07bc375":"test.head()","f90bda0c":"train.info()","d9aa2baa":"import missingno as msno \nmisshing_info = msno.bar(train)\nmisshing_info.set_title('Training data missing values chart',fontdict={'fontsize':25})","79d402ba":"test_missing_info = msno.bar(test)\ntest_missing_info.set_title('Test data missing values chart',fontdict={'fontsize':25})","f411c382":"fig = px.histogram(train, x=\"target\",marginal=\"box\",color_discrete_sequence=['forestgreen'])\nfig.update_layout(showlegend=True,\n                  title = { 'text' : '<b>Distribution of target variable<b>',\n                          'x':0.5,\n                        'xanchor': 'center',\n                        'yanchor': 'top'\n                        },\n                  title_font_color='black',\n                  yaxis={\"title\": \"Count\",\n                         \"zeroline\":False, \"showgrid\":False,\n                         \"fixedrange\": False\n                        },\n                  plot_bgcolor=\"#ffffff\",\n                  margin={\"r\":20, \"l\":30},\n                 )\niplot(fig)\n","e5278213":"cat_cols = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8','cat9']","c4bae51e":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfig = make_subplots(rows=5, cols=2,subplot_titles=cat_cols,shared_yaxes=True)\n\n\ncol = 0\nfor i in range(0,2):\n    col = i+1\n    cat=train[cat_cols[i]].value_counts().reset_index()\n    fig.add_trace(\n        go.Bar(\n                x=cat['index'], y=cat[cat_cols[i]],\n                text=cat[cat_cols[i]],\n                textposition='auto',\n                name=cat_cols[i]\n            ),\n        row=1, col=col\n    )\ncol = 0    \nfor i in range(2,4):\n    col = col+1\n    cat=train[cat_cols[i]].value_counts().reset_index()\n    fig.add_trace(\n        go.Bar(\n                x=cat['index'], y=cat[cat_cols[i]],\n                text=cat[cat_cols[i]],\n                textposition='auto',\n                name=cat_cols[i]\n            ),\n        row=2, col=col\n    )\n\ncol = 0    \nfor i in range(4,6):\n    col = col+1\n    cat=train[cat_cols[i]].value_counts().reset_index()\n    fig.add_trace(\n        go.Bar(\n                x=cat['index'], y=cat[cat_cols[i]],\n                text=cat[cat_cols[i]],\n                textposition='auto',\n                name=cat_cols[i]\n            ),\n        row=3, col=col\n    )\ncol = 0    \nfor i in range(6,8):\n    col = col+1\n    cat=train[cat_cols[i]].value_counts().reset_index()\n    fig.add_trace(\n        go.Bar(\n                x=cat['index'], y=cat[cat_cols[i]],\n                text=cat[cat_cols[i]],\n                textposition='auto',\n                name=cat_cols[i]\n            ),\n        row=4, col=col\n    )    \ncol = 0    \nfor i in range(8,10):\n    col = col+1\n    cat=train[cat_cols[i]].value_counts().reset_index()\n    fig.add_trace(\n        go.Bar(\n                x=cat['index'], y=cat[cat_cols[i]],\n                text=cat[cat_cols[i]],\n                textposition='auto',\n                name=cat_cols[i]\n            ),\n        row=5, col=col\n    )     \nfig.update_layout(showlegend=True,\n                  title = { 'text' : '<b>Categorical column value counts<b>',\n                          'x':0.5,\n                        'xanchor': 'center',\n                        'yanchor': 'top'\n                        },\n                  title_font_color='black',\n                  yaxis={\"title\": \"Count\",\n                         \"zeroline\":False, \"showgrid\":False,\n                         \"fixedrange\": False\n                        },\n                  plot_bgcolor=\"#ffffff\",\n                  margin={\"r\":20, \"l\":30},\n                 )\niplot(fig)","a5938bc8":"fig, axes = plt.subplots(5, 2, sharey=True, figsize=(8, 15))\nsns.set_theme(palette=\"spring_r\",style=\"ticks\")\nfor i, ax in zip(range(10), axes.flat):\n    sub_plot = sns.boxplot(x=\"cat{}\".format(i), y=\"target\",\n            data=train,  ax=ax)\n    if (i % 2) != 0:\n        sub_plot.yaxis.set_visible(False) \n    sub_plot.set_xlabel(\"cat{}\".format(i),fontsize=18)\n    sub_plot.set_ylabel(\"target\",fontsize=18)\n\nsns.despine(offset=5, trim=True)\nsns.despine(left=True)     \nfig.tight_layout(pad=3.0)\nfig.suptitle('Distribution of target per category across categorical attributes', fontsize=16)\nfig.subplots_adjust(top=0.95)\nplt.show()","490ee032":"numeric_cols = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6','cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']","e5423a28":"fig = make_subplots(rows=2, cols=7,subplot_titles=numeric_cols, shared_yaxes=True)\n\ncol = 0\nfor i in range(0,7):\n    col = col+1\n    fig.add_trace(go.Box(y=train[numeric_cols[i]], name=numeric_cols[i],\n                    marker_color = 'indianred'),\n                     row=1, col=col)\ncol = 0\nfor i in range(7,14):\n    col = col+1\n    fig.add_trace(go.Box(y=train[numeric_cols[i]], name=numeric_cols[i],\n                    marker_color = 'indianred'),\n                     row=2, col=col)\n    \nfig.update_layout(showlegend=True,\n                  title = { 'text' : '<b>Numerical column distribution<b>',\n                          'x':0.5,\n                        'xanchor': 'center',\n                        'yanchor': 'top'\n                        },\n                  title_font_color='black',\n                  yaxis={\"title\": \"Count\",\n                         \"zeroline\":False, \"showgrid\":False,\n                         \"fixedrange\": False\n                        },\n                  plot_bgcolor=\"#ffffff\",\n                  margin={\"r\":20, \"l\":30},\n                 )\niplot(fig)","3aa503f9":"numeric_cols = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6','cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13','target']\ncorr=train[numeric_cols].corr()","d7d1b237":"sns.set_theme(palette=\"mako\",style=\"ticks\")\nfig, axes = plt.subplots(7, 2, sharey=True, figsize=(8, 15))\nfor i, ax in zip(range(14), axes.flat):\n    sub_plot = sns.scatterplot(data=train, x=\"cont{}\".format(i), y=\"target\", ax=ax)\n    if (i % 2) != 0:\n        sub_plot.yaxis.set_visible(False) \n    sub_plot.set_xlabel(\"cont{}\".format(i),fontsize=18)\n    sub_plot.set_ylabel(\"target\",fontsize=18)\n\nsns.despine(offset=5, trim=True)\nsns.despine(left=True)     \nfig.tight_layout(pad=3.0)\nfig.suptitle('Scatter plot of numerical attributes vs target', fontsize=16)\nfig.subplots_adjust(top=0.95)\nplt.show()","b2e312b4":"fig = px.imshow(corr)\nfig.update_layout(showlegend=True,\n                  title = { 'text' : '<b>Correlation Matrix of numerical attributes<b>',\n                          'x':0.5,\n                        'xanchor': 'center',\n                        'yanchor': 'top'\n                        },\n                  title_font_color='black',\n                 \n                 )\niplot(fig)","2c4de493":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import set_config\n\nnumeric_cols = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6','cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']\nX = train.drop(\"target\", axis = 1)  \ny = train['target'] # label to predict\n\ndef build_model(model):\n    #numerical_pipe = Pipeline([('std_scaler',StandardScaler())])\n    categorical_pipe = Pipeline([('one_hot',OneHotEncoder())])\n    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numeric_transformer, numeric_cols),\n            ('cat', categorical_transformer, cat_cols)])\n    regr = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('regression_model', model)])   \n    set_config(display='diagram')\n    return regr\n\ndef get_pipeline():\n    #numerical_pipe = Pipeline([('std_scaler',StandardScaler())])\n    categorical_pipe = Pipeline([('one_hot',OneHotEncoder())])\n    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numeric_transformer, numeric_cols),\n            ('cat', categorical_transformer, cat_cols)])\n    return preprocessor\n\ndef calculate_train_rmse(name, model):\n    runs_predictions = model.predict(X)\n    mse = mean_squared_error(y, runs_predictions)\n    rmse = np.sqrt(mse)\n    print(\"Training RMSE of {} : {}\".format(name,rmse))\n\ndef sample_prediction(name, model, num_records):\n    some_data = X.iloc[:num_records]\n    some_labels = y.iloc[:num_records]\n    preds = []\n    for label in list(model.predict(some_data)):\n        preds.append(math.floor(label))\n\n    print(\"Predictions on training data using :\", name)    \n    print(\"Predictions    :\", preds)\n    print(\"Actual labels  :\", list(some_labels))    \n","bc26dbfb":"from sklearn.ensemble import RandomForestRegressor\nforest_reg = build_model(RandomForestRegressor(random_state = 42))\nforest_reg.fit(X,y)","89975eab":"calculate_train_rmse(\"RandomForestRegressor\",forest_reg)","33c5ee10":"sample['target'] = forest_reg.predict(test)\n","cb227782":"sample","b1f780f9":"sample.to_csv('random_forest_v1.csv')","06085175":"import joblib as jbl\njbl.dump(forest_reg, \"forest_reg.pkl\")","f79fc3fe":"# Pipeline","61dfde03":"# Load Data","6469cfd5":"# Any missing values? - NO","5fe336cc":"### Lets zoom in and look at each category","5de0b281":"### To be continued. Thanks for going through. Long way to go. Please upvote if you find it useful!","cf8a3da5":"# RandomForestRegressor\nLet's train RandomForestRegressor base version with standard scaler and one-hot encoding. Nothing fancy here. Just an initial version","47ba96be":"## Prediction","1594ed1b":"## Value Counts","e48d6dd2":"# Explore the target variable\n> We are dealing with bimodal distribution with outliers !","827a5e9b":"# Tabular Playground Series - Feb 2021\n\nThis notebook presents starter EDA and trains a RandomForestRegressor","9624eeb4":"Columns with Outliers are \n* cont0\n* cont2\n* cont6\n* cont8\n","8dfea084":"# Explore Categorical Attribute\n> There are 10 categorical attributes cat0 - cat9","0514396f":">  No significant linear correlation ","283bc246":"# Explore Numerical Attributes\n\nThere are 14 numerical attributes cont0 - cont13","91fb21cb":"* cat0 - cat5 has upto 4 categories\n* cat6 - cat 9 has upt 8 categories"}}