{"cell_type":{"d09e3d27":"code","c8ac5cfc":"code","694248d3":"code","8b141e66":"code","cb8ab2bc":"code","9e224af8":"code","5c0c2c40":"code","7264d549":"code","550c3b29":"code","7d6cb961":"code","65557e68":"code","e5b3e6cb":"code","fc3b8fc8":"code","cb8ee332":"code","8d0be5be":"code","dc8b54c3":"code","82563ff4":"code","8597cdcf":"code","f390c219":"code","a41f9c17":"code","5fa0dfc4":"code","e96e9097":"code","bdb40524":"code","fc42162f":"code","e887212f":"code","7ee45351":"code","d908d9d2":"code","7bd35c13":"code","86d020ce":"code","2dca2a0e":"code","1faa0c00":"code","f6791b3d":"code","884b11fa":"code","fef10dd8":"code","bc3eba65":"code","83bd7bb5":"code","b0a9a3fb":"code","8568a843":"code","8ab17fb4":"code","a3676808":"code","8925300b":"code","06a039c2":"code","e5bc953e":"code","89a28ff7":"code","c6b73e6b":"code","83287f24":"code","72aac5f1":"code","bb3444d7":"code","12924db6":"code","7ded0a75":"code","441d0724":"code","b9bef9f3":"code","53a5f459":"code","330939a0":"code","6b3703d7":"code","d6b88b94":"code","72ad7052":"code","41c5ece1":"code","005b7961":"code","723af07b":"code","7032ec1a":"code","12b9cf2b":"code","b5f34c82":"code","c575ceb1":"code","e594cf1c":"code","611e9bbf":"code","8a21311c":"code","957e86cd":"code","f1e4c640":"code","c2de762f":"code","5c34c2ce":"code","76081eca":"code","434b76c0":"code","b322f068":"code","abfdaa30":"code","85e315c5":"code","9d778f50":"code","86b5a7ff":"code","53355203":"code","aefee274":"code","f93b527c":"code","9c1dc144":"code","1a22068b":"code","c84584bf":"code","2285eb07":"code","f67f12e9":"code","0f7beaac":"code","29cf9c96":"code","9f30b03d":"code","30a3d12b":"code","f309f019":"code","6c1bd8e2":"code","3d5ab3cf":"code","5ae1ab83":"code","0722e528":"code","783084e8":"code","6fd2b171":"code","223b18f2":"code","be1c0243":"code","dd2e3afa":"code","255bb717":"code","e8089f3f":"code","7cab5a3b":"code","79af8c06":"code","24f3adef":"code","05265b1c":"code","71e9e01b":"code","e9973f48":"code","07bd6f18":"code","43d41bd4":"code","f49a1bc5":"code","d09ca196":"code","698015da":"code","cd7f8a00":"code","b0f0c7c9":"code","019ed01e":"code","499c6bb2":"code","3248b416":"code","05fd6af7":"code","1b9c6a3f":"code","56017dab":"code","9bcf6ac3":"code","5895938a":"code","38ea28fa":"code","09f08f11":"code","988fd9fa":"code","459c2f82":"code","c6b88fdd":"code","1e024504":"code","d41ef3d8":"code","44ed3ccd":"code","9e7cdd5a":"code","338c2a5d":"code","ceb7a175":"code","26826e39":"code","beeb90bd":"code","de1934c1":"code","ce588c9f":"code","8ff3026c":"code","d250696f":"code","76258bc2":"code","b0493124":"code","580890be":"code","db7d8882":"code","8d88e76a":"code","f8db8c74":"code","7084692f":"markdown","bc0421b3":"markdown","f9f4d554":"markdown","e0251c52":"markdown","6d5bf07b":"markdown","d7594743":"markdown","4745ca4d":"markdown","b55d0109":"markdown","50b0104a":"markdown","ed84b3b1":"markdown","f3a47a7d":"markdown","1040046b":"markdown","3144af65":"markdown","3c9c2143":"markdown","e0565097":"markdown","a5ab08b7":"markdown","c5915548":"markdown","a071ec91":"markdown","9d898e17":"markdown","226abfd5":"markdown","62d9114a":"markdown","849d4e3b":"markdown","16601f5a":"markdown","3f31a3e7":"markdown","b7aa63d9":"markdown","646ee3c5":"markdown","6b574863":"markdown","83636f38":"markdown","71cbe0de":"markdown","74d39ba4":"markdown","d3307983":"markdown","ea78c0c1":"markdown","0dc4bf8b":"markdown","26f6d251":"markdown","e5c35b13":"markdown","e7c84ad6":"markdown","98d79ac3":"markdown","cf30fb55":"markdown","fa226aee":"markdown","e2694d77":"markdown","199c514f":"markdown"},"source":{"d09e3d27":"#import the library we use to open URLs\nimport numpy as np\nimport PIL\nfrom PIL import Image\nimport pandas as pd\npd.set_option('display.max_colwidth',None)\nimport urllib.request\nfrom urllib.request import urlopen","c8ac5cfc":"Image.open('..\/input\/telugu-actors\/10271174_659397960820464_3372644202548436589_o.jpg')","694248d3":"# import the BeautifulSoup library so we can parse HTML and XML documents\n!pip install beautifulsoup4\nfrom bs4 import BeautifulSoup","8b141e66":"def len_header(url):\n    y= urllib.request.urlopen(url)\n    soup = BeautifulSoup(y, \"lxml\")\n    right_table = soup.find('table', class_='wikitable')\n    for row in right_table.findAll('tr'):\n        cells=row.findAll('td')\n        if len(cells)>0:\n            x = len(cells)\n    return x # returns number of columns in the table from scrapped url","cb8ab2bc":"## 1930-60 (61)\n\nurl30 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_the_1930s\" \nurl40 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1940\"\n\nurl41 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1941\"\nurl42 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1942\"\nurl43 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1943\"\nurl44 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1944\"\nurl45 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1945\"\nurl46 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1946\"\nurl47 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1947\"\nurl48 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1948\"\nurl49 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1949\"\nurl50 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1950\"\n\nurl51 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1951\"\nurl52 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1952\"\nurl53 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1953\"\nurl54 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1954\"\nurl55 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1955\"\nurl56 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1956\"\nurl57 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1957\"\nurl58 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1958\"\nurl59 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1959\"\nurl60 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1960\"\n\n## 1961-90 (39)\n\nurl61 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1961\"\nurl62 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1962\"\nurl63 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1963\"\nurl64 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1964\"\nurl65 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1965\"\nurl66 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1966\"\nurl67 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1967\"\nurl68 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1968\"\nurl69 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1969\"\nurl70 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1970\"\n\nurl71 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1971\"\nurl72 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1972\"\nurl73 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1973\"\nurl74 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1974\"\nurl75 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1975\"\nurl76 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1976\"\nurl77 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1977\"\nurl78 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1978\"\nurl79 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1979\"\nurl80 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1980\"\n\nurl81 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1981\"\nurl82 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1982\"\nurl83 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1983\"\nurl84 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1984\"\nurl85 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1985\"\nurl86 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1986\"\nurl87 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1987\"\nurl88 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1988\"\nurl89 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1989\"\nurl90 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1990\"\n\nurl91 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1991\"\nurl92 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1992\"\nurl93 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1993\"\nurl94 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1994\"\nurl95 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1995\"\nurl96 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1996\"\nurl97 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1997\"\nurl98 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1998\"\nurl99 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1999\"","9e224af8":"## 2000-2021 (21)\n\nurl2000 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2000\"\nurl2001 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2001\"\nurl2002 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2002\"\nurl2003 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2003\"\nurl2004 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2004\"\nurl2005 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2005\"\nurl2006 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2006\"\nurl2007 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2007\"\nurl2008 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2008\"\nurl2009 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2009\"\nurl2010 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2010\"\nurl2011 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2011\"\nurl2012 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2012\"\nurl2013 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2013\"\nurl2014 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2014\"\nurl2015 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2015\"\nurl2016 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2016\"\nurl2017 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2017\"\nurl2018 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2018\"\nurl2019 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2019\"\nurl2020 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2020\"\nurl2021 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_2021\"","5c0c2c40":"url_list1 = [url30,url40,\n             url41,url42,url43,url44,url45,url46,url47,url48,url49,url50,url51,url52,url53,url54,url55,url56,url57,url58,url59,url60,\n             url61,url62,url63,url64,url65,url66,url67,url68,url69,url70,url71,url72,url73,url74,url75,url76,url77,url78,url79,url80,\n             url81,url82,url83,url84,url85,url86,url87,url88,url89,url90,url91,url92,url93,url94,url95,url96,url97,url98,url99]\n\nurl_list2 = [url2000,url2001,url2002,url2003,url2004,url2005,url2006,url2007,url2008,url2009,\n             url2010,url2011,url2012,url2013,url2014,url2015,url2016,url2017,url2018,url2019,\n             url2020,url2021] \n\n\nprint(\"Total Number of Years          :\",len(url_list1)+len(url_list2))\nprint(\"Total Number of Years 1930-1999:\",len(url_list1))\nprint(\"Total Number of Years 2000-2021:\",len(url_list2))","7264d549":"from collections import defaultdict\nd = defaultdict(list)\n\nfor i in range(len(url_list1)):\n    d[url_list1[i]].append(len_header(url_list1[i]))","550c3b29":"import gc\ngc.collect()","7d6cb961":"for i in d.items():\n    print(i)","65557e68":"# From 1930-1999. Thereafter, format changed in wikipedia. Doing different approach from 2000-2021\n\nl7 = [url46,url47,url48,url49,url50,url82,url83,url84,url86]\nl6 = [url30,url51,url52,url53,url54,url61,url64,url81]\nl5 = [url40,url41,url42,url43,url44,url45,url52,url55,url56,url57,url58,url59,url60,url62,url63,url65,url66,url67,url68,url69,url70,\n     url71,url72,url73,url74,url75,url76,url77,url78,url79,url80,url85,url87,url88,url90,url91,url92,url93,url94,url95,url96,url97,\n     url98,url99]","e5b3e6cb":"len(l7),len(l6),len(l5)","fc3b8fc8":"l7[0]","cb8ee332":"soup = BeautifulSoup(urllib.request.urlopen(l7[0]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\nG=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==7:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        G.append(cells[6].find(text=True))\n    \n        \n\ndf1946 =pd.DataFrame(A,columns=['Title'])\ndf1946['Director']=B\ndf1946['Production']=C\ndf1946['Music Composer']=D\ndf1946['Cast']=E\ndf1946['Genre']=F\ndf1946['Release Date']=G\ndf1946['Year']=1946\ndf1946","8d0be5be":"import gc\ngc.collect()","dc8b54c3":"l7[1]","82563ff4":"soup = BeautifulSoup(urllib.request.urlopen(l7[1]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\nG=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==7:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        G.append(cells[6].find(text=True))\n    \n        \n\ndf1947 =pd.DataFrame(A,columns=['Title'])\ndf1947['Director']=B\ndf1947['Production']=C\ndf1947['Music Composer']=D\ndf1947['Cast']=E\ndf1947['Genre']=F\ndf1947['Release Date']=G\ndf1947['Year']=1947","8597cdcf":"l7[2]","f390c219":"soup = BeautifulSoup(urllib.request.urlopen(l7[2]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\nG=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==7:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        G.append(cells[6].find(text=True))\n    \n        \n\ndf1948 =pd.DataFrame(A,columns=['Title'])\ndf1948['Director']=B\ndf1948['Production']=C\ndf1948['Music Composer']=D\ndf1948['Cast']=E\ndf1948['Genre']=F\ndf1948['Release Date']=G\ndf1948['Year']=1948","a41f9c17":"l7[3]","5fa0dfc4":"soup = BeautifulSoup(urllib.request.urlopen(l7[3]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\nG=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==7:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        G.append(cells[6].find(text=True))\n    \n        \n\ndf1949 =pd.DataFrame(A,columns=['Title'])\ndf1949['Director']=B\ndf1949['Production']=C\ndf1949['Music Composer']=D\ndf1949['Cast']=E\ndf1949['Genre']=F\ndf1949['Release Date']=G\ndf1949['Year']=1949","e96e9097":"l7[4]","bdb40524":"soup = BeautifulSoup(urllib.request.urlopen(l7[4]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\nG=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==7:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        G.append(cells[6].find(text=True))\n    \n        \n\ndf1950 =pd.DataFrame(A,columns=['Title'])\ndf1950['Director']=B\ndf1950['Production']=C\ndf1950['Music Composer']=D\ndf1950['Cast']=E\ndf1950['Genre']=F\ndf1950['Release Date']=G\ndf1950['Year']=1950","fc42162f":"l7[5]","e887212f":"soup = BeautifulSoup(urllib.request.urlopen(l7[5]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\nG=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==7:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        G.append(cells[6].find(text=True))\n    \n        \n\ndf1982 =pd.DataFrame(A,columns=['Title'])\ndf1982['Director']=B\ndf1982['Production']=C\ndf1982['Music Composer']=D\ndf1982['Cast']=E\ndf1982['Genre']=F\ndf1982['Release Date']=G\ndf1982['Year']=1982","7ee45351":"l7[6]","d908d9d2":"soup = BeautifulSoup(urllib.request.urlopen(l7[6]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\nG=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==7:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        G.append(cells[6].find(text=True))\n    \n        \n\ndf1983 =pd.DataFrame(A,columns=['Title'])\ndf1983['Director']=B\ndf1983['Production']=C\ndf1983['Music Composer']=D\ndf1983['Cast']=E\ndf1983['Genre']=F\ndf1983['Release Date']=G\ndf1983['Year']=1983","7bd35c13":"l7[7]","86d020ce":"soup = BeautifulSoup(urllib.request.urlopen(l7[7]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\nG=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==7:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        G.append(cells[6].find(text=True))\n    \n        \n\ndf1984 =pd.DataFrame(A,columns=['Title'])\ndf1984['Director']=B\ndf1984['Production']=C\ndf1984['Music Composer']=D\ndf1984['Cast']=E\ndf1984['Genre']=F\ndf1984['Release Date']=G\ndf1984['Year']=1984","2dca2a0e":"l7[8]","1faa0c00":"soup = BeautifulSoup(urllib.request.urlopen(l7[8]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\nG=[]\nH=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)>7:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        G.append(cells[6].find(text=True))\n    \n        \n\ndf1986 =pd.DataFrame(A,columns=['Title'])\ndf1986['Director']=B\ndf1986['Production']=C\ndf1986['Music Composer']=D\ndf1986['Cast']=E\ndf1986['Genre']=F\ndf1986['Release Date']=G\ndf1986['Year']=1986","f6791b3d":"l7","884b11fa":"d7 = pd.concat([df1946,df1947,df1948,df1949,df1950,df1982,df1983,df1984,df1986]) # 7 Columns \nd7.fillna('',inplace=True)\nd7","fef10dd8":"for col in d7.columns:\n    if d7[col].dtype=='int64':\n        print('Number of Major Movies Released\\n')\n        print(d7[col].value_counts())\n","bc3eba65":"gc.collect()","83bd7bb5":"l6 = [url30,url51,url52,url53,url54,url61,url64,url81]\nl6[0]","b0a9a3fb":"soup = BeautifulSoup(urllib.request.urlopen(l6[0]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==6:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n\ndf1930 =pd.DataFrame(A,columns=['Title'])\ndf1930['Director']=B\ndf1930['Production']=C\ndf1930['Music Composer']='Not Known'\ndf1930['Cast']=D\ndf1930['Genre']=E\ndf1930['Release Date']=F\ndf1930['Year']=1930","8568a843":"l6[1]","8ab17fb4":"soup = BeautifulSoup(urllib.request.urlopen(l6[1]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[] #Title\nB=[] #Director\nC=[] #Production\nD=[] #Music Composer\nE=[] #Cast\nF=[] #Genre\nG=[] #Release Date\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==6:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n\n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1951 =pd.DataFrame(A,columns=['Title'])\ndf1951['Director']=B\ndf1951['Production']=D\ndf1951['Music Composer']=F\ndf1951['Cast']=C\ndf1951['Genre']=E\ndf1951['Release Date']=1951\ndf1951['Year']=1951","a3676808":"l6[2]","8925300b":"soup = BeautifulSoup(urllib.request.urlopen(l6[2]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==6:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1952 =pd.DataFrame(A,columns=['Title'])\ndf1952['Director']=B\ndf1952['Production']=C\ndf1952['Music Composer']=E\ndf1952['Cast']=D\ndf1952['Genre']=F\ndf1952['Release Date']=1952\ndf1952['Year']=1952","06a039c2":"l6[3]","e5bc953e":"soup = BeautifulSoup(urllib.request.urlopen(l6[3]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==6:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1953 =pd.DataFrame(A,columns=['Title'])\ndf1953['Director']=B\ndf1953['Production']=C\ndf1953['Music Composer']=E\ndf1953['Cast']=D\ndf1953['Genre']=F\ndf1953['Release Date']=1953\ndf1953['Year']=1953","89a28ff7":"l6[4]","c6b73e6b":"soup = BeautifulSoup(urllib.request.urlopen(l6[4]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==6:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1954 =pd.DataFrame(A,columns=['Title'])\ndf1954['Director']=B\ndf1954['Production']=C\ndf1954['Music Composer']=F\ndf1954['Cast']=D\ndf1954['Genre']=E\ndf1954['Release Date']=1954\ndf1954['Year']=1954","83287f24":"l6[5]","72aac5f1":"soup = BeautifulSoup(urllib.request.urlopen(l6[5]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==6:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1961 =pd.DataFrame(A,columns=['Title'])\ndf1961['Director']=B\ndf1961['Production']=''\ndf1961['Music Composer']=E\ndf1961['Cast']=C\ndf1961['Genre']=D\ndf1961['Release Date']=1961\ndf1961['Year']=1961","bb3444d7":"l6[6]","12924db6":"soup = BeautifulSoup(urllib.request.urlopen(l6[6]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==6:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1964 =pd.DataFrame(A,columns=['Title'])\ndf1964['Director']=B\ndf1964['Production']=\"\"\ndf1964['Music Composer']=\"\"\ndf1964['Cast']=C\ndf1964['Genre']=D\ndf1964['Release Date']=1964\ndf1964['Year']=1964","7ded0a75":"l6[7]","441d0724":"soup = BeautifulSoup(urllib.request.urlopen(l6[7]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==6:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1981 =pd.DataFrame(A,columns=['Title'])\ndf1981['Director']=B\ndf1981['Production']=\"\"\ndf1981['Music Composer']=\"\"\ndf1981['Cast']=C\ndf1981['Genre']=D\ndf1981['Release Date']=1981\ndf1981['Year']=1981","b9bef9f3":"d6 = pd.concat([df1930,df1951,df1952,df1953,df1954,df1961,df1964,df1981])\nd6.fillna('',inplace=True)\nd6","53a5f459":"gc.collect()","330939a0":"l5[0]","6b3703d7":"soup = BeautifulSoup(urllib.request.urlopen(l5[0]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\nG=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==6:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1940 = pd.DataFrame(A,columns=['Title'])\ndf1940['Director']=B\ndf1940['Production']=D\ndf1940['Music Composer']=\"\"\ndf1940['Cast']=C\ndf1940['Genre']=E\ndf1940['Release Date']=1940\ndf1940['Year']=1940","d6b88b94":"l5[1]","72ad7052":"soup = BeautifulSoup(urllib.request.urlopen(l5[1]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\nG=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1941 = pd.DataFrame(A,columns=['Title'])\ndf1941['Director']=B\ndf1941['Production']=D\ndf1941['Music Composer']=\"\"\ndf1941['Cast']=C\ndf1941['Genre']=E\ndf1941['Release Date']=1941\ndf1941['Year']=1941\ndf1941","41c5ece1":"l5[2]","005b7961":"soup = BeautifulSoup(urllib.request.urlopen(l5[2]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1942 = pd.DataFrame(A,columns=['Title'])\ndf1942['Director']=B\ndf1942['Production']=D\ndf1942['Music Composer']=\"\"\ndf1942['Cast']=C\ndf1942['Genre']=E\ndf1942['Release Date']=\"\"\ndf1942['Year']=1942","723af07b":"l5[3]","7032ec1a":"soup = BeautifulSoup(urllib.request.urlopen(l5[3]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1943 = pd.DataFrame(A,columns=['Title'])\ndf1943['Director']=B\ndf1943['Production']=D\ndf1943['Music Composer']=\"\"\ndf1943['Cast']=C\ndf1943['Genre']=E\ndf1943['Release Date']=\"\"\ndf1943['Year']=1943","12b9cf2b":"l5[4]","b5f34c82":"soup = BeautifulSoup(urllib.request.urlopen(l5[4]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1944 = pd.DataFrame(A,columns=['Title'])\ndf1944['Director']=B\ndf1944['Production']=D\ndf1944['Music Composer']=\"\"\ndf1944['Cast']=C\ndf1944['Genre']=E\ndf1944['Release Date']=\"\"\ndf1944['Year']=1944","c575ceb1":"l5[5]","e594cf1c":"soup = BeautifulSoup(urllib.request.urlopen(l5[5]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1945 = pd.DataFrame(A,columns=['Title'])\ndf1945['Director']=B\ndf1945['Production']=D\ndf1945['Music Composer']=\"\"\ndf1945['Cast']=C\ndf1945['Genre']=E\ndf1945['Release Date']=\"\"\ndf1945['Year']=1945","611e9bbf":"l5[6]","8a21311c":"soup = BeautifulSoup(urllib.request.urlopen(l5[6]), \"lxml\") ## parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==6:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1952 = pd.DataFrame(A,columns=['Title'])\ndf1952['Director']=B\ndf1952['Production']=C\ndf1952['Music Composer']=E\ndf1952['Cast']=D\ndf1952['Genre']=F\ndf1952['Release Date']=\"\"\ndf1952['Year']=1952","957e86cd":"l5[7]","f1e4c640":"soup = BeautifulSoup(urllib.request.urlopen(l5[7]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1955 = pd.DataFrame(A,columns=['Title'])\ndf1955['Director']=B\ndf1955['Production']=\"\"\ndf1955['Music Composer']=E\ndf1955['Cast']=C\ndf1955['Genre']=D\ndf1955['Release Date']=\"\"\ndf1955['Year']=1955","c2de762f":"l5[8]","5c34c2ce":"soup = BeautifulSoup(urllib.request.urlopen(l5[8]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1956 = pd.DataFrame(A,columns=['Title'])\ndf1956['Director']=B\ndf1956['Production']=\"\"\ndf1956['Music Composer']=E\ndf1956['Cast']=C\ndf1956['Genre']=D\ndf1956['Release Date']=\"\"\ndf1956['Year']=1956","76081eca":"l5[9]","434b76c0":"soup = BeautifulSoup(urllib.request.urlopen(l5[9]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1957 = pd.DataFrame(A,columns=['Title'])\ndf1957['Director']=B\ndf1957['Production']=\"\"\ndf1957['Music Composer']=E\ndf1957['Cast']=C\ndf1957['Genre']=D\ndf1957['Release Date']=\"\"\ndf1957['Year']=1957","b322f068":"l5[10]","abfdaa30":"soup = BeautifulSoup(urllib.request.urlopen(l5[10]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1958 = pd.DataFrame(A,columns=['Title'])\ndf1958['Director']=B\ndf1958['Production']=\"\"\ndf1958['Music Composer']=E\ndf1958['Cast']=C\ndf1958['Genre']=D\ndf1958['Release Date']=\"\"\ndf1958['Year']=1958","85e315c5":"l5[11]","9d778f50":"soup = BeautifulSoup(urllib.request.urlopen(l5[11]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1959 = pd.DataFrame(A,columns=['Title'])\ndf1959['Director']=B\ndf1959['Production']=\"\"\ndf1959['Music Composer']=E\ndf1959['Cast']=C\ndf1959['Genre']=D\ndf1959['Release Date']=\"\"\ndf1959['Year']=1959","86b5a7ff":"l5[12]","53355203":"# 1960\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[12]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1960 = pd.DataFrame(A,columns=['Title'])\ndf1960['Director']=B\ndf1960['Production']=\"\"\ndf1960['Music Composer']=E\ndf1960['Cast']=C\ndf1960['Genre']=D\ndf1960['Release Date']=\"\"\ndf1960['Year']=1960","aefee274":"l5[13]","f93b527c":"# 1962\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[13]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1962 = pd.DataFrame(A,columns=['Title'])\ndf1962['Director']=B\ndf1962['Production']=\"\"\ndf1962['Music Composer']=E\ndf1962['Cast']=C\ndf1962['Genre']=D\ndf1962['Release Date']=\"\"\ndf1962['Year']=1962","9c1dc144":"l5[14]","1a22068b":"# 1963\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[14]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1963 = pd.DataFrame(A,columns=['Title'])\ndf1963['Director']=B\ndf1963['Production']=\"\"\ndf1963['Music Composer']=E\ndf1963['Cast']=C\ndf1963['Genre']=D\ndf1963['Release Date']=\"\"\ndf1963['Year']=1963","c84584bf":"l5[15]","2285eb07":"# 1965\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[15]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1965 = pd.DataFrame(A,columns=['Title'])\ndf1965['Director']=B\ndf1965['Production']=\"\"\ndf1965['Music Composer']=\"\"\ndf1965['Cast']=C\ndf1965['Genre']=D\ndf1965['Release Date']=\"\"\ndf1965['Year']=1965","f67f12e9":"l5[16]","0f7beaac":"# 1966\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[16]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1966 = pd.DataFrame(A,columns=['Title'])\ndf1966['Director']=B\ndf1966['Production']=\"\"\ndf1966['Music Composer']=E\ndf1966['Cast']=C\ndf1966['Genre']=D\ndf1966['Release Date']=\"\"\ndf1966['Year']=1966","29cf9c96":"l5[17]","9f30b03d":"# 1967\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[17]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1967 = pd.DataFrame(A,columns=['Title'])\ndf1967['Director']=B\ndf1967['Production']=\"\"\ndf1967['Music Composer']=E\ndf1967['Cast']=C\ndf1967['Genre']=D\ndf1967['Release Date']=\"\"\ndf1967['Year']=1967","30a3d12b":"l5[18]","f309f019":"# 1968\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[18]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1968 = pd.DataFrame(A,columns=['Title'])\ndf1968['Director']=B\ndf1968['Production']=\"\"\ndf1968['Music Composer']=\"\"\ndf1968['Cast']=C\ndf1968['Genre']=D\ndf1968['Release Date']=\"\"\ndf1968['Year']=1968","6c1bd8e2":"l5[19]","3d5ab3cf":"# 1969\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[19]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1969 = pd.DataFrame(A,columns=['Title'])\ndf1969['Director']=B\ndf1969['Production']=\"\"\ndf1969['Music Composer']=\"\"\ndf1969['Cast']=C\ndf1969['Genre']=D\ndf1969['Release Date']=\"\"\ndf1969['Year']=1969","5ae1ab83":"l5[20]","0722e528":"# 1970\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[20]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1970 = pd.DataFrame(A,columns=['Title'])\ndf1970['Director']=B\ndf1970['Production']=\"\"\ndf1970['Music Composer']=\"\"\ndf1970['Cast']=C\ndf1970['Genre']=D\ndf1970['Release Date']=\"\"\ndf1970['Year']=1970","783084e8":"l5[21]","6fd2b171":"# 1971\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[21]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1971 = pd.DataFrame(A,columns=['Title'])\ndf1971['Director']=B\ndf1971['Production']=\"\"\ndf1971['Music Composer']=\"\"\ndf1971['Cast']=C\ndf1971['Genre']=D\ndf1971['Release Date']=\"\"\ndf1971['Year']=1971","223b18f2":"l5[22]","be1c0243":"# 1972\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[22]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1972 = pd.DataFrame(A,columns=['Title'])\ndf1972['Director']=B\ndf1972['Production']=\"\"\ndf1972['Music Composer']=\"\"\ndf1972['Cast']=C\ndf1972['Genre']=D\ndf1972['Release Date']=\"\"\ndf1972['Year']=1972","dd2e3afa":"l5[23]","255bb717":"# 1973\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[23]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1973 = pd.DataFrame(A,columns=['Title'])\ndf1973['Director']=B\ndf1973['Production']=\"\"\ndf1973['Music Composer']=\"\"\ndf1973['Cast']=C\ndf1973['Genre']=D\ndf1973['Release Date']=\"\"\ndf1973['Year']=1973","e8089f3f":"l5[24]","7cab5a3b":"# 1974\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[22]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1974 = pd.DataFrame(A,columns=['Title'])\ndf1974['Director']=B\ndf1974['Production']=\"\"\ndf1974['Music Composer']=\"\"\ndf1974['Cast']=C\ndf1974['Genre']=D\ndf1974['Release Date']=1974\ndf1974['Year']=1974","79af8c06":"l5[25]","24f3adef":"# 1975\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[25]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1975 = pd.DataFrame(A,columns=['Title'])\ndf1975['Director']=B\ndf1975['Production']=\"\"\ndf1975['Music Composer']=\"\"\ndf1975['Cast']=C\ndf1975['Genre']=D\ndf1975['Release Date']=1975\ndf1975['Year']=1975","05265b1c":"l5[26]","71e9e01b":"# 1976\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[26]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1976 = pd.DataFrame(A,columns=['Title'])\ndf1976['Director']=B\ndf1976['Production']=\"\"\ndf1976['Music Composer']=\"\"\ndf1976['Cast']=C\ndf1976['Genre']=D\ndf1976['Release Date']=1976\ndf1976['Year']=1976","e9973f48":"l5[27]","07bd6f18":"# 1977\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[27]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1977 = pd.DataFrame(A,columns=['Title'])\ndf1977['Director']=B\ndf1977['Production']=\"\"\ndf1977['Music Composer']=\"\"\ndf1977['Cast']=C\ndf1977['Genre']=D\ndf1977['Release Date']=\"\"\ndf1977['Year']=1977","43d41bd4":"l5[28]","f49a1bc5":"# 1978\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[28]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1978 = pd.DataFrame(A,columns=['Title'])\ndf1978['Director']=B\ndf1978['Production']=\"\"\ndf1978['Music Composer']=\"\"\ndf1978['Cast']=C\ndf1978['Genre']=D\ndf1978['Release Date']=\"\"\ndf1978['Year']=1978","d09ca196":"l5[29]","698015da":"# 1979\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[29]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1979 = pd.DataFrame(A,columns=['Title'])\ndf1979['Director']=B\ndf1979['Production']=\"\"\ndf1979['Music Composer']=\"\"\ndf1979['Cast']=C\ndf1979['Genre']=D\ndf1979['Release Date']=\"\"\ndf1979['Year']=1979","cd7f8a00":"l5[30]","b0f0c7c9":"# 1980\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[30]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1980 = pd.DataFrame(A,columns=['Title'])\ndf1980['Director']=B\ndf1980['Production']=D\ndf1980['Music Composer']=\"\"\ndf1980['Cast']=C\ndf1980['Genre']=\"\"\ndf1980['Release Date']=\"\"\ndf1980['Year']=1980","019ed01e":"l5[31]","499c6bb2":"# 1985\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[31]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1985 = pd.DataFrame(A,columns=['Title'])\ndf1985['Director']=B\ndf1985['Production']=\"\"\ndf1985['Music Composer']=D\ndf1985['Cast']=C\ndf1985['Genre']=\"\"\ndf1985['Release Date']=\"\"\ndf1985['Year']=1985","3248b416":"l5[32]","05fd6af7":"# 1987\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[32]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1987 = pd.DataFrame(A,columns=['Title'])\ndf1987['Director']=B\ndf1987['Production']=\"\"\ndf1987['Music Composer']=D\ndf1987['Cast']=C\ndf1987['Genre']=\"\"\ndf1987['Release Date']=\"\"\ndf1987['Year']=1987","1b9c6a3f":"l5[33]","56017dab":"# 1988\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[33]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1988 = pd.DataFrame(A,columns=['Title'])\ndf1988['Director']=B\ndf1988['Production']=\"\"\ndf1988['Music Composer']=D\ndf1988['Cast']=C\ndf1988['Genre']=\"\"\ndf1988['Release Date']=\"\"\ndf1988['Year']=1988","9bcf6ac3":"l5[34]","5895938a":"# 1990\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[34]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1990 = pd.DataFrame(A,columns=['Title'])\ndf1990['Director']=B\ndf1990['Production']=\"\"\ndf1990['Music Composer']=D\ndf1990['Cast']=C\ndf1990['Genre']=\"\"\ndf1990['Release Date']=\"\"\ndf1990['Year']=1990","38ea28fa":"l5[35]","09f08f11":"# 1991\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[35]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1991 = pd.DataFrame(A,columns=['Title'])\ndf1991['Director']=B\ndf1991['Production']=\"\"\ndf1991['Music Composer']=\"\"\ndf1991['Cast']=C\ndf1991['Genre']=D\ndf1991['Release Date']=\"\"\ndf1991['Year']=1991","988fd9fa":"l5[36]","459c2f82":"# 1992\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[36]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1992 = pd.DataFrame(A,columns=['Title'])\ndf1992['Director']=B\ndf1992['Production']=\"\"\ndf1992['Music Composer']=D\ndf1992['Cast']=C\ndf1992['Genre']=\"\"\ndf1992['Release Date']=\"\"\ndf1992['Year']=1992","c6b88fdd":"l5[37]","1e024504":"# 1993\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[37]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1993 = pd.DataFrame(A,columns=['Title'])\ndf1993['Director']=B\ndf1993['Production']=\"\"\ndf1993['Music Composer']=D\ndf1993['Cast']=C\ndf1993['Genre']=\"\"\ndf1993['Release Date']=\"\"\ndf1993['Year']=1993","d41ef3d8":"l5[38]","44ed3ccd":"# 1994\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[38]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1994 = pd.DataFrame(A,columns=['Title'])\ndf1994['Director']=B\ndf1994['Production']=\"\"\ndf1994['Music Composer']=D\ndf1994['Cast']=C\ndf1994['Genre']=\"\"\ndf1994['Release Date']=\"\"\ndf1994['Year']=1994","9e7cdd5a":"l5[39]","338c2a5d":"# 1995\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[39]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1995 = pd.DataFrame(A,columns=['Title'])\ndf1995['Director']=B\ndf1995['Production']=\"\"\ndf1995['Music Composer']=D\ndf1995['Cast']=C\ndf1995['Genre']=\"\"\ndf1995['Release Date']=\"\"\ndf1995['Year']=1995","ceb7a175":"l5[40]","26826e39":"# 1996\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[40]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1996 = pd.DataFrame(A,columns=['Title'])\ndf1996['Director']=B\ndf1996['Production']=\"\"\ndf1996['Music Composer']=D\ndf1996['Cast']=C\ndf1996['Genre']=\"\"\ndf1996['Release Date']=\"\"\ndf1996['Year']=1996","beeb90bd":"l5[41]","de1934c1":"# 1997\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[41]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1997 = pd.DataFrame(A,columns=['Title'])\ndf1997['Director']=B\ndf1997['Production']=\"\"\ndf1997['Music Composer']=D\ndf1997['Cast']=C\ndf1997['Genre']=\"\"\ndf1997['Release Date']=\"\"\ndf1997['Year']=1997","ce588c9f":"l5[42]","8ff3026c":"# 1998\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[42]), \"lxml\") # # parse the HTML from the URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1998 = pd.DataFrame(A,columns=['Title'])\ndf1998['Director']=B\ndf1998['Production']=\"\"\ndf1998['Music Composer']=D\ndf1998['Cast']=C\ndf1998['Genre']=\"\"\ndf1998['Release Date']=\"\"\ndf1998['Year']=1998","d250696f":"l5[43]","76258bc2":"# 1999\n\nsoup = BeautifulSoup(urllib.request.urlopen(l5[43]), \"lxml\") # # parse the HTML from our URL into the BeautifulSoup parse tree format\nright_table = soup.find('table', class_='wikitable')\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        #G.append(cells[6].find(text=True))\n    \n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1999 = pd.DataFrame(A,columns=['Title'])\ndf1999['Director']=B\ndf1999['Production']=\"\"\ndf1999['Music Composer']=D\ndf1999['Cast']=C\ndf1999['Genre']=\"\"\ndf1999['Release Date']=\"\"\ndf1999['Year']=1999","b0493124":"d5 =pd.concat([df1940,df1941,df1942,df1943,df1944,df1945,df1952,df1955,df1956,df1957,df1958,df1959,df1960,\n               df1962,df1963,df1965,df1966,df1967,df1968,df1969,df1970,df1971,df1972,df1973,df1974,df1975,df1976,df1977,df1978,df1979,df1980,\n               df1985,df1987,df1988,df1990,df1991,df1992,df1993,df1994,df1995,df1996,df1997,df1998,df1999])","580890be":"# There are two separate tables in the source.\n\nurl89 = \"https:\/\/en.wikipedia.org\/wiki\/List_of_Telugu_films_of_1989\"\nhtml=urllib.request.urlopen(url89) # open the url using urllib.request and put the HTML into the page variable\nsoup= BeautifulSoup(html, \"lxml\")\ntables = soup.find_all(\"table\", class_=\"wikitable\")\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\n\nfor row in tables[0].findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==4:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\ndf1989 =pd.DataFrame(A,columns=['Title'])\ndf1989['Director']=C\ndf1989['Production']=\"\"\ndf1989['Music Composer']=\"\"\ndf1989['Cast']=B\ndf1989['Genre']=\"\"\ndf1989['Release Date']=1989\ndf1989['Year']=1989\n\nA=[]\nB=[]\nC=[]\nD=[]\nE=[]\nF=[]\n\nfor row in tables[1].findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==5:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        D.append(cells[3].find(text=True))\n        #E.append(cells[4].find(text=True))\n        #F.append(cells[5].find(text=True))\n        \n# 'Title', 'Director', 'Production', 'Music Composer', 'Cast', 'Genre','Release Date', 'Year'\n\ndf1989 =pd.DataFrame(A,columns=['Title'])\ndf1989['Director']=B\ndf1989['Production']=\"\"\ndf1989['Music Composer']=D\ndf1989['Cast']=C\ndf1989['Genre']=\"\"\ndf1989['Release Date']=1989\ndf1989['Year']=1989","db7d8882":"df30_99 =pd.concat([d5,d6,d7,df1989])","8d88e76a":"for col in df30_99.columns:\n    if df30_99[col].dtype=='int64':\n        print(\"Number of Years:\",len(df30_99[col].unique()))\n        print('Year -- Number of Major Movies Released')\n        print(df30_99[col].value_counts())\n       ","f8db8c74":"df30_99.fillna('',inplace=True)\ndf30_99.to_csv(\"Wiki_Telugu_Movies_1930_1999.csv\",index=False)","7084692f":"# Telugu Movies Tables From Wikipedia (1930 & 1940-2021)","bc0421b3":"> ## Let's try with 1946!! I am collecting the data from the list 'l7' \n\n### Data Mining:\n\nData collection can be automated with function. The real problem is arranging the relevant data in the tabular format and check the errors. Rectifing the errors in the collected data with automation is very very difficult task.\n\nIt's always better to do data collection manually. As we can cross check the data source and data collected to maintain it free of errors. Hence, it is hard work and consumes a lot of time.\n\nData collected may contain null values and other redundant characters. It's next step of data cleaning.","f9f4d554":"## Segregating the url according to number of columns in the table","e0251c52":"## 2000-2021 Movies","6d5bf07b":"## 1930, 1940-1999 Movies","d7594743":"### After 1999, the table format has been changed in wikipedia.\n\nHence, Will do different approach for 2000-2021 period","4745ca4d":"# 1930-1999 (61 Years)","b55d0109":"## 1961","50b0104a":"## 1952","ed84b3b1":"## 1958","f3a47a7d":"### 1947","1040046b":"## 1944","3144af65":"## 1955","3c9c2143":"## 1986","e0565097":"## 1964","a5ab08b7":"## Tables with 6 columns","c5915548":"## 1951","a071ec91":"## 1956","9d898e17":"## 1952","226abfd5":"## 1941","62d9114a":"### 1948","849d4e3b":"### 1950","16601f5a":"## Concatanated all the tables to form single dataframe","3f31a3e7":"## 1954","b7aa63d9":"## 1982","646ee3c5":"## 1983","6b574863":"## 1984","83636f38":"### __END OF PARSING WIKIPEDIA TELUGU MOVIES DATA FROM 1930 & 1940 to 1999 (61 Years)__","71cbe0de":"## 1930","74d39ba4":"## 1943","d3307983":"# 5 columns in the table","ea78c0c1":"## 1945","0dc4bf8b":"## 1959","26f6d251":"## 1940","e5c35b13":"## 1989","e7c84ad6":"## 2000-2021 coming soon!!!!","98d79ac3":"### 1946","cf30fb55":"## 1981","fa226aee":"### 1949","e2694d77":"## 1957","199c514f":"### BeautifulSoup Package"}}