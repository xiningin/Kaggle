{"cell_type":{"36fbb2fc":"code","7e662cc5":"code","cfa02e24":"code","ce949a95":"code","0b114ca6":"code","c01f4e69":"code","7926a6b0":"code","c9ae857a":"code","714cf5ac":"code","6ecae014":"code","5109e8d1":"code","17ef8396":"code","9e313d8e":"code","1b658d61":"code","3752812b":"code","3b105050":"code","0411ebef":"code","059898cd":"code","5b712b8b":"code","8e4594b6":"code","87dbdf1c":"code","63646178":"code","fb6074d4":"code","9da8d341":"code","7717a16a":"code","98387eb6":"code","1ed63f1b":"markdown","a2ef83b6":"markdown","610b455d":"markdown","4dfbd223":"markdown"},"source":{"36fbb2fc":"!pip install imutils","7e662cc5":"#set the data set folder\nimport os\n#original input data set path\nORIGINAL_INPUT_DATASET = \"..\/input\/breast-histopathology-images\"\n#master folder to contain the train test valid data \nBASE_PATH = \"\/kaggle\/working\/datasets\"\n#derive the training testing and validation directories\nTRAIN_PATH = os.path.sep.join([BASE_PATH , 'training'])\nVAL_PATH = os.path.sep.join([BASE_PATH , 'validation'])\nTEST_PATH = os.path.sep.join([BASE_PATH , \"testing\"])\n#Train test split\nTRAIN_SPLIT = 0.8\n#validation split\nVAL_SPLIT = 0.1","cfa02e24":"!ls \/kaggle\/working\/","ce949a95":"from imutils import paths\nimport shutil\nimport random\nimport os\n\n#grab the paths to the input images in the base folder\nimgPaths = list(paths.list_images(ORIGINAL_INPUT_DATASET))\n#define a random seed to shuffle\nrandom.seed(42)\nrandom.shuffle(imgPaths)\nprint(len(imgPaths))","0b114ca6":"from PIL import Image\n%matplotlib inline\nimport matplotlib.pyplot as plt","c01f4e69":"#do some visualization\ntest_img_path = imgPaths[5]\nclass_label = test_img_path.split(os.path.sep)[-2]\nprint(\"Class Label \" ,class_label)\nimage = Image.open(test_img_path)\nplt.figure(figsize=(5,5))\nplt.imshow(image)\nplt.show()","7926a6b0":"#take 80% of the data from the folder\nimgPaths = imgPaths[:int(len(imgPaths)*0.7)]\n#define the split index for train  test\nsplit_idx = int(len(imgPaths)*TRAIN_SPLIT)\ntrainPaths= imgPaths[:split_idx]\ntestPaths = imgPaths[split_idx:]\n\n#define the train val split\nval_split = int(len(trainPaths)*VAL_SPLIT)\nvalPaths = trainPaths[:val_split]\ntrainPaths = trainPaths[val_split:]\n\n#define the datasets\ndatasets=[\n    ('training',trainPaths , TRAIN_PATH),\n    ('validation' , valPaths , VAL_PATH),\n    ('testing' , testPaths , TEST_PATH)\n]\n\nfor (dtype , imgPaths , baseoutput) in datasets:\n    print(\"Building the Dataset for \",dtype)\n    #if the base output is not exists then create a folder\n    if not os.path.exists(baseoutput):\n        print(\"Create a directory for the dataset \", baseoutput)\n        os.makedirs(baseoutput)\n    \n    for imgPath in imgPaths :\n        #define the class and the file name\n        filename = imgPath.split(os.path.sep)[-1]\n        label = filename[-5:-4]\n        #build the path to the label directory for 1 and 0\n        labelPath = os.path.sep.join([baseoutput,label])\n        \n        if not os.path.exists(labelPath):\n            print(\"Create the directory for the label {}\".format(labelPath))\n            os.makedirs(labelPath)        \n        p = os.path.sep.join([labelPath,filename])\n     \n        shutil.copy2(imgPath , p)","c9ae857a":"!ls \/kaggle\/working","714cf5ac":"from torchvision import datasets\nimport torch\nfrom torchvision import transforms\ndef make_weights_for_balanced_classes(images, nclasses):                        \n    count = [0] * nclasses                                                      \n    for item in images:                                                         \n        count[item[1]] += 1                                                     \n    weight_per_class = [0.] * nclasses                                      \n    N = float(sum(count))                                                   \n    for i in range(nclasses):                                                   \n        weight_per_class[i] = N\/float(count[i])                                 \n    weight = [0] * len(images)                                              \n    for idx, val in enumerate(images):                                          \n        weight[idx] = weight_per_class[val[1]]                                  \n    return weight \n\ntransform_train = transforms.Compose([\n    transforms.Pad(64, padding_mode='reflect'),\n    transforms.RandomRotation((0,10)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor() ,\n    transforms.Normalize([0.5,0.5,0.5] , [0.5,0.5,0.5])\n])\ntransform_test = transforms.Compose([\n    transforms.Pad(64, padding_mode='reflect'),\n    transforms.ToTensor() ,\n    transforms.Normalize([0.5,0.5,0.5] , [0.5,0.5,0.5])\n])\ntransform_valid = transforms.Compose([\n    transforms.Pad(64, padding_mode='reflect'),\n    transforms.ToTensor() ,\n    transforms.Normalize([0.5,0.5,0.5] , [0.5,0.5,0.5])\n])\n\n\ndataset_train = datasets.ImageFolder('\/kaggle\/working\/datasets\/training' ,transform=transform_train)                                                                         \ndataset_test = datasets.ImageFolder(\"\/kaggle\/working\/datasets\/testing\",transform=transform_test)   \ndataset_valid = datasets.ImageFolder(\"\/kaggle\/working\/datasets\/validation\",transform=transform_valid)\n\n# For unbalanced dataset we create a weighted sampler                       \nweights = make_weights_for_balanced_classes(dataset_train.imgs, len(dataset_train.classes))                                                                \nweights = torch.DoubleTensor(weights)                                       \nsampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))                     \n                                                                                \ntrain_loader = torch.utils.data.DataLoader(dataset_train, batch_size=64 , sampler = sampler, num_workers=0, pin_memory=True)   \ntest_loader = torch.utils.data.DataLoader(dataset_test , batch_size=32 , pin_memory=True)\nvalid_loader = torch.utils.data.DataLoader(dataset_valid , batch_size=32 , pin_memory=True)","6ecae014":"import torch.nn as nn\nimport torch.nn.functional as F\n#define the CNN model\nclass Cancer_Net(nn.Module):\n    def __init__(self , input_shape , output_shape , seed):\n        super(Cancer_Net , self).__init__()\n    \n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(in_channels=input_shape , out_channels=32 , kernel_size=3 , stride=1 , padding=1),\n            nn.ReLU() ,\n            nn.BatchNorm2d(32) ,\n            #nn.Conv2d(32 , 32 , kernel_size=3 ,stride=1 , padding=1) ,            \n            #nn.ReLU() , \n            #nn.BatchNorm2d(32) , \n            nn.MaxPool2d(kernel_size=(2,2) , stride=(2,2)) , \n            #nn.Dropout(p=0.2)\n        )\n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(in_channels=32 , out_channels=64 , kernel_size=3 , stride=1 , padding=1),\n            nn.ReLU() ,\n            nn.BatchNorm2d(64) ,\n            #nn.Conv2d(64 , 64 , kernel_size=3 ,stride=1 , padding=1) ,            \n            #nn.ReLU() , \n            #nn.BatchNorm2d(64) , \n            nn.MaxPool2d(kernel_size=(2,2) , stride=(2,2)) , \n            #nn.Dropout(p=0.2)\n        )\n        self.conv_block3 = nn.Sequential(\n            nn.Conv2d(in_channels=64 , out_channels=128 , kernel_size=3 , stride=1 , padding=1),\n            nn.ReLU() ,\n            nn.BatchNorm2d(128) ,\n            #nn.Conv2d(128 , 128 , kernel_size=3 ,stride=1 , padding=1) ,            \n            #nn.ReLU() , \n            #nn.BatchNorm2d(128) , \n            #nn.Conv2d(128 , 128 , kernel_size=3 ,stride=1 , padding=1) ,            \n            #nn.ReLU() , \n            #nn.BatchNorm2d(128) , \n            nn.MaxPool2d(kernel_size=(2,2) , stride=(2,2)) , \n            #nn.Dropout(p=0.2)\n        )\n        self.conv_block4 = nn.Sequential(\n            nn.Conv2d(in_channels=256 , out_channels=512 , kernel_size=3 , stride=1 , padding=1),\n            nn.ReLU(inplace=True) ,\n            nn.BatchNorm2d(512) ,\n            #nn.Conv2d(512 , 512 , kernel_size=3 ,stride=1 , padding=1) ,            \n            #nn.ReLU(inplace=True) , \n            #nn.BatchNorm2d(512) , \n            nn.MaxPool2d(kernel_size=(2,2) , stride=(2,2)) , \n            #nn.Dropout(p=0.5)\n        )\n        self.size = 512*4*4\n        self.fc_block = nn.Sequential(\n            nn.Linear(self.size ,128) ,\n            nn.ReLU() , \n            nn.Dropout(p=0.5) ,\n            nn.Linear(128,1) , \n            nn.Sigmoid()\n        )\n        \n    def forward(self, x):\n        \n        #forward pass on the conv layers\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        x = self.conv_block3(x)\n        x = self.conv_block4(x)\n        x = x.view(-1,self.size)\n        x = self.fc_block(x)\n        #since the binary classificcation\n        return x\n\ncancer_net = Cancer_Net(3 , 1 , 0)       ","5109e8d1":"import torch\ndevice='cuda:0' if torch.cuda.is_available() else 'cpu'\ncancer_net.to(device)","17ef8396":"import torch.optim as optim\nend_lr = 1e-6\nstart_lr = 0.001\n#define the loss function and the optimizer use the binary cross entropy loss\ncriterion = nn.BCELoss()\n#lets use the gpu and move data to gpu\n#criterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = optim.SGD(cancer_net.parameters(), start_lr)","9e313d8e":"def get_lr_search_scheduler(optimizer, min_lr, max_lr, max_iterations):\n    # max_iterations should be the number of steps within num_epochs_*epoch_iterations\n    # this way the learning rate increases linearily within the period num_epochs*epoch_iterations \n    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer=optimizer, \n                                               base_lr=min_lr,\n                                               max_lr=max_lr,\n                                               step_size_up=max_iterations,\n                                               step_size_down=max_iterations,\n                                               mode=\"triangular\")\n    \n    return scheduler","1b658d61":"lr_find_epochs=1\nscheduler = get_lr_search_scheduler(optimizer, start_lr, end_lr, lr_find_epochs*len(train_loader))","3752812b":"from collections import deque\nimport numpy as np\nEPOCHS = 10\ntotal_score = []\nmean_loss = deque(maxlen=500)\nfor epoch in range(EPOCHS):\n    \n    epoch_loss =0\n    epoch_val_loss = 0\n    epoch_accuracy = 0\n    for idx , (data , label) in enumerate(train_loader) :\n        data , label = data.to(device) , label.view(-1,1).to(device).float()\n        output = cancer_net(data)\n        loss = criterion(output , label)\n        epoch_loss += loss.to('cpu').detach().numpy()\n        mean_loss.append(loss.to('cpu').detach().item())\n        #reset the optimizer\n        optimizer.zero_grad()\n        #backprop the loss\n        loss.backward()\n        #optimize the model\n        optimizer.step()\n        if((idx+1)%500 == 0 ):\n            print(\"Epoch : {} Mean Train loss : {} \".format(epoch , np.mean(mean_loss)))\n        total_score.append(loss.to('cpu').detach().numpy())\n    cancer_net.eval()\n    with torch.no_grad():\n        for data , label in valid_loader :\n            data , label = data.to(device) , label.to(device)\n            output = cancer_net(data)\n            top_prob , top_k = torch.topk(output , 1)\n            eqauls = (label == top_k.view(label.shape))\n            accuracy = torch.mean(eqauls.type(torch.FloatTensor))\n            epoch_accuracy += accuracy.to('cpu').detach().numpy()\n    cancer_net.train()\n    scheduler.step()  \n    \n    print(\"Epoch : {} Total loss : {} Total Accuracy : {}\".format(epoch ,epoch_loss\/len(train_loader) , epoch_accuracy\/len(valid_loader)))\n    ","3b105050":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import SeparableConv2D , Conv2D\nfrom tensorflow.keras.layers import MaxPool2D\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import backend as K","0411ebef":"class CancerNet :\n    @staticmethod\n    def build(width , height , depth , classes):\n        model= Sequential()\n        inputShape = (height , width , depth)\n        channel_dim = -1\n        \n        if K.image_data_format()==\"channels_first\":\n            inputShape = (depth , height , width)\n            channel_dim =1\n            \n        #using the seprable convs getting higher computation but the kernels not getting much higher accuracy    \n        model.add(Conv2D(32 , (3,3) , padding='same' , input_shape=inputShape , \n                         kernel_regularizer = regularizers.l1_l2(l1=1e-2 , l2=1e-3)))\n        \n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=channel_dim))\n        model.add(MaxPool2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n        \n        model.add(Conv2D(64 , (3,3) , padding='same' , \n                                 kernel_regularizer = regularizers.l1_l2(l1=1e-3)))\n        \n        \n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=channel_dim))\n        model.add(Conv2D(128 , (3,3) , padding='same' , \n                                 kernel_regularizer = regularizers.l1_l2(l1=1e-3)))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=channel_dim))\n        model.add(MaxPool2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n        \n        model.add(Conv2D(256 , (3,3) , padding='same' , \n                                 kernel_regularizer = regularizers.l1_l2(l1=1e-3)))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=channel_dim))\n        model.add(Conv2D(512 , (3,3) , padding='same' , \n                                 kernel_regularizer = regularizers.l1_l2(l1=1e-3)))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=channel_dim))\n        model.add(Conv2D(1024 , (3,3) , padding='same' , \n                                 kernel_regularizer = regularizers.l1_l2(l1=1e-3)))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=channel_dim))\n        model.add(MaxPool2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25)) \n        \n        #add the dense layers\n        model.add(Flatten())\n        model.add(Dense(256))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        \n        model.add(Dense(classes))\n        model.add(Activation('softmax'))\n        \n        return model","059898cd":"#implement the training scipt\nimport matplotlib\nmatplotlib.use(\"Agg\")\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers import Adagrad\nfrom tensorflow.keras.utils  import to_categorical\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport argparse\nimport os\nimport keras","5b712b8b":"NUM_EPOCHS = 40\nINIT_LR = 1e-2\nBS = 32\n\ntrainPaths = list(paths.list_images(TRAIN_PATH))\ntotalTrain = len(trainPaths)\ntotalVal = len(list(paths.list_images(VAL_PATH)))\ntotalTest = len(list(paths.list_images(TEST_PATH)))\n\ntrainLabels = [int(p.split(os.path.sep)[-2])  for p in trainPaths]\ntrainLabels = to_categorical(trainLabels)\nclassTotals = trainLabels.sum(axis=0)\nclassWeight = dict()\n\n#for all the classes calculate the weight\nfor i in range(0,len(classTotals)):\n    classWeight[i] = classTotals.max()\/classTotals[i]","8e4594b6":"!pip install keras --upgrade","87dbdf1c":"import tensorflow as tf\nwith tf.device(\"gpu:0\"):\n   print(\"tf.keras code in this scope will run on GPU\")","63646178":"# initialize the training data augmentation object\ntrainAug = ImageDataGenerator(\n\trescale=1 \/ 255.0,\n\trotation_range=20,\n\tzoom_range=0.05,\n\twidth_shift_range=0.1,\n\theight_shift_range=0.1,\n\tshear_range=0.05,\n\thorizontal_flip=True,\n\tvertical_flip=True,\n\tfill_mode=\"nearest\")\n# initialize the validation (and testing) data augmentation object\nvalAug = ImageDataGenerator(rescale=1 \/ 255.0)","fb6074d4":"#define the training generators\ntrainGen = trainAug.flow_from_directory(\n    TRAIN_PATH ,\n    class_mode = 'categorical',\n    target_size=(48,48) ,\n    color_mode = 'rgb',\n    shuffle=True ,\n    batch_size=BS\n)\n\n# initialize the validation generator\nvalGen = valAug.flow_from_directory(\n\tVAL_PATH,\n\tclass_mode=\"categorical\",\n\ttarget_size=(48, 48),\n\tcolor_mode=\"rgb\",\n\tshuffle=False,\n\tbatch_size=BS)\n# initialize the testing generator\ntestGen = valAug.flow_from_directory(\n\tTEST_PATH,\n\tclass_mode=\"categorical\",\n\ttarget_size=(48, 48),\n\tcolor_mode=\"rgb\",\n\tshuffle=False,\n\tbatch_size=BS)","9da8d341":"model = CancerNet.build(width=48 , height=48 , depth=3 ,classes=2)\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-2,\n    decay_steps=10000,\n    decay_rate=0.9)\nopt = keras.optimizers.SGD(learning_rate=lr_schedule)\nmodel.compile(loss='binary_crossentropy', optimizer=opt , metrics=['accuracy'])\n\nH = model.fit(\n    x = trainGen , \n    steps_per_epoch = totalTrain \/\/ BS ,\n    validation_data = valGen ,\n    validation_steps = totalVal\/\/BS ,\n    class_weight = classWeight ,\n    epochs = 10 )\n\n","7717a16a":"print(\"Model ecavluation \")\ntestGen.reset()\npredIdx = model.predict(x = testGen , steps=(totaltest\/\/BS)+1)\n\npredIdx = np.argmax(predIdx , axis=1)\nprint(classification_report(testGen.classes , predIdx , target_names=testGen.class_indices.keys()))","98387eb6":"cm = confusion_matrix(testGen.classes , predIdx)\nprint(cm)","1ed63f1b":"# Pytroch Model","a2ef83b6":"**** Define the Convolutional nureal network","610b455d":"# Tensorflow model","4dfbd223":"### Build the dataset and create the target train , test , valid data folders"}}