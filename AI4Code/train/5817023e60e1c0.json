{"cell_type":{"c2ec05d7":"code","21d7a479":"code","b99778ea":"code","5639137d":"code","1615e942":"code","7485cc72":"code","02efb54c":"code","d817134c":"code","f79621bc":"code","3c726a78":"code","58403ffc":"code","68a87baa":"code","280c8c77":"code","183dd90b":"code","5b2dc78b":"code","d0c58f23":"code","a1c60efe":"code","690917ea":"code","0dbab03b":"code","40d6347d":"code","c34747cd":"code","99d6dfdf":"code","e0d9699d":"code","d03dc2d1":"code","a829379c":"code","e7df49b8":"code","fb7c7cf9":"code","960595b3":"code","ba12bd64":"markdown","331ecf37":"markdown","b8fab120":"markdown","b39f0210":"markdown","e7531fd7":"markdown","f19ef269":"markdown"},"source":{"c2ec05d7":"import fastai\nfrom fastai.vision import *\nfrom pathlib import Path\nimport cv2\ntorch.backends.cudnn.benchmark = False","21d7a479":"fastai.__version__, torch.__version__","b99778ea":"MASKS = 'train.csv'\n\nPATH = Path('\/kaggle\/input')\nTRAIN = Path('train')\nTEST = Path('test')\nTMP = Path('\/kaggle\/working')\n\nSAMPLE = Path('sample_submission.csv')\n\nseg = pd.read_csv(PATH\/MASKS)\nsample_sub = pd.read_csv(PATH\/SAMPLE)\ntrain_names = list(seg.Id.values)\ntest_names = list(sample_sub.Id.values)\n\nclasses = [str(l) for l in range(28)]","5639137d":"df = pd.read_csv(PATH\/MASKS); len(df)","1615e942":"arch = models.resnet18;","7485cc72":"stats = ([0.08069, 0.05258, 0.05487], [0.13704,0.10145, 0.15313])\ntfms = get_transforms(do_flip=True, flip_vert=True, \n                      max_lighting=0.1, max_warp=0.4)","02efb54c":"class FocalLoss(nn.Module):\n    def __init__(self, gamma=2):\n        super().__init__()\n        self.gamma = gamma\n        \n    def forward(self, input, target):\n        if not (target.size() == input.size()):\n            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n                             .format(target.size(), input.size()))\n\n        max_val = (-input).clamp(min=0)\n        loss = input - input * target + max_val + \\\n            ((-max_val).exp() + (-input - max_val).exp()).log()\n\n        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n        loss = (invprobs * self.gamma).exp() * loss\n        \n        return loss.sum(dim=1).mean()","d817134c":"def open_image4d(path:PathOrStr)->Image:\n    '''open RGBA image from 4 different 1-channel files.\n    return: numpy array [4, sz, sz]'''\n    path=str(path)\n    flags = cv2.IMREAD_GRAYSCALE\n    red = cv2.imread(path+ '_red.png', flags)\n    blue = cv2.imread(path+ '_blue.png', flags)\n    green = cv2.imread(path+ '_green.png', flags)\n#     yellow = cv2.imread(path+ '_yellow.png', flags)\n    im = np.stack(([red, green, blue]))\n\n    return Image(Tensor(im\/255).float())","f79621bc":"class MyImageItemList(ImageItemList):\n    def open(self, fn:PathOrStr)->Image:\n        return open_image4d(fn)","3c726a78":"def get_data(sz=64, bs=64, pct=0.2, sample=5000):\n#     sz, pct, bs = 64, 0.2, 64\n    src = (MyImageItemList.from_df(df=df, path=PATH, folder=TRAIN)\n           .random_split_by_pct(pct)\n           .label_from_df(sep=' ', classes=classes)\n           .add_test([PATH\/TEST\/f for f in test_names]))\n    data = (src.transform(tfms, size=sz)\n            .databunch(bs=bs, num_workers=0).normalize(stats)) #this really sucks!\n    return data","58403ffc":"data = get_data(sample=100)","68a87baa":"# data.show_batch(rows=3, figsize=(12,9))","280c8c77":"f1 = partial(fbeta, beta=1)\n\ndef get_learner(data, focal=False, fp16=False):\n    learn = create_cnn(data, arch, metrics=[accuracy_thresh, f1], \n               callback_fns=[partial(GradientClipping, clip=0.1), ShowGraph], model_dir=TMP)\n    if focal: learn.loss_func = FocalLoss()\n    if fp16: learn.to_fp16();\n    return learn.mixup(stack_y=False)","183dd90b":"data = get_data(256, 128, 0.1)","5b2dc78b":"learn = get_learner(data, focal=True, fp16=True)","d0c58f23":"learn.lr_find()","a1c60efe":"learn.recorder.plot()","690917ea":"lr = 1e-2","0dbab03b":"learn.fit_one_cycle(3,slice(lr))","40d6347d":"learn.unfreeze()","c34747cd":"learn.fit_one_cycle(4,slice(lr\/10, lr\/3))","99d6dfdf":"learn.save('r18_256')","e0d9699d":"learn.data.test_dl.add_tfm(to_half)\np,t = learn.get_preds(ds_type=DatasetType.Test)","d03dc2d1":"model_name = 'r18_256'","a829379c":"preds = to_np(p.sigmoid())  #Check if we are using focal loss or BCE.\nnp.save(model_name, preds)  #save for further model ensemble","e7df49b8":"threshold = 0.4 #ths\nprint(preds.shape)\nclasses = np.array(data.classes)\nres = np.array([\" \".join(classes[(np.where(pp>threshold))])for pp in preds])","fb7c7cf9":"frame = pd.DataFrame(np.array([test_names, res]).T, columns = ['Id','Predicted'])\nframe.to_csv(f'{model_name}.csv', index=False)","960595b3":"frame.head()","ba12bd64":"let's check version!","331ecf37":"# Focal Loss","b8fab120":"good!","b39f0210":"# Predict","e7531fd7":"# Custom image read, just first 3 channels","f19ef269":"# Learner"}}