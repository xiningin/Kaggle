{"cell_type":{"18144538":"code","50f50701":"code","9fb706cb":"code","200b5402":"code","97b2088b":"code","91d99475":"code","731bd84b":"code","a55a1854":"code","faae7195":"code","2a646aa3":"code","a9b24c4c":"code","3ca68dc8":"code","aba329b5":"code","71c67d50":"code","b70c2cc4":"code","7f8d2fb8":"code","1f5b7bc0":"code","7f581559":"code","ba56bec8":"markdown"},"source":{"18144538":"import os\nfrom PIL import Image\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import utils as keras_utils\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom cv2 import cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import BatchNormalization","50f50701":"path = '..\/input\/fruit-and-vegetable-image-recognition\/train\/'\nfruits = []\nfor x in os.listdir(path):\n    fruits.append(x)\n","9fb706cb":"data=[]\nlabels=[]\nim_w = 224\nim_h = 224","200b5402":"for x in range(len(fruits)):\n    sub_path = path+fruits[x]+'\/'\n    for y in os.listdir(sub_path):        \n        img_path = sub_path+y  \n        last = img_path[-12:]\n        imag=cv2.imread(img_path)  \n        if last == 'Image_56.jpg':\n            continue\n        if last == 'Image_96.jpg': \n            continue\n        img_from_ar = Image.fromarray(imag, 'RGB')\n        resized_image = img_from_ar.resize((im_w, im_h))\n        data.append(np.array(resized_image))\n        labels.append(x)","97b2088b":"categories=np.array(data)\nlabels=np.array(labels)\n\ns=np.arange(categories.shape[0])\nnp.random.shuffle(s)\ncategories=categories[s]\nlabels=labels[s]\n\nnum_classes=len(np.unique(labels))\ndata_length=len(categories)","91d99475":"(x_train,x_test)=categories[(int)(0.1*data_length):],categories[:(int)(0.1*data_length)]\nx_train = x_train.astype('float32')\/255\nx_test = x_test.astype('float32')\/255\ntrain_length=len(x_train)\ntest_length=len(x_test)\n\n(y_train,y_test)=labels[(int)(0.1*data_length):],labels[:(int)(0.1*data_length)]\n\ny_train=keras.utils.to_categorical(y_train,num_classes)\ny_test=keras.utils.to_categorical(y_test,num_classes)\n","731bd84b":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(im_w,im_h,3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\n#model.add(Dropout(0.3))\nmodel.add(Dense(36, activation = 'softmax'))","a55a1854":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=17)\nhistory = model.fit(x_train,y_train,batch_size=50, epochs=90,verbose=1, validation_split=0.33, callbacks=[early_stop])\n\nscore = model.evaluate(x_test, y_test, verbose=1)\nprint('\\n', 'Test accuracy:', score[1])","faae7195":"plt.plot(history.history['val_loss'])\nplt.plot(history.history['loss'])\nplt.title(\"Model Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel('Time')\nplt.legend(['val_loss', 'loss'], loc='upper left')\nplt.show()","2a646aa3":"plt.plot(history.history['val_accuracy'])\nplt.plot(history.history['accuracy'])\nplt.title(\"Model Accuracy\")\nplt.ylabel(\"Epocs\")\nplt.xlabel('Time')\nplt.legend(['val_accuracy', 'acc'], loc='upper left')\nplt.show()","a9b24c4c":"pred_list = []\nacc_list = []","3ca68dc8":"def convert_to_array(img):\n    im = cv2.imread(img)\n    img = Image.fromarray(im, 'RGB')\n    image = img.resize((im_w, im_h))\n    return np.array(image)\n\ndef get_fruit_name(label):\n    return fruits[label] \n\ndef predict_fruit(file):\n    print(\"Predicting .................................\")\n    ar=convert_to_array(file)\n    ar=ar\/255\n    a=[]\n    a.append(ar)\n    a=np.array(a)\n    score=model.predict(a,verbose=1)\n    #print(score)\n    label_index=np.argmax(score)\n    #print(label_index)\n    acc=np.max(score)\n    fruit=get_fruit_name(label_index)\n    pred_list.append(fruit)\n    acc_list.append(acc)\n    print(\"The predicted fruit is a \"+fruit+\" with accuracy =    \"+str(acc))\n","aba329b5":"test_path = '..\/input\/fruit-and-vegetable-image-recognition\/test\/'\nt_fruits = []\nfor x in os.listdir(test_path):\n    t_fruits.append(x)","71c67d50":"for x in range(len(t_fruits)):\n    sub_path = test_path+t_fruits[x]+'\/'\n    for y in os.listdir(sub_path):\n        img_path = sub_path+y\n        predict_fruit(img_path)","b70c2cc4":"real_fruits = []\nfor f in fruits:\n    for i in range(10):\n        real_fruits.append(f)","7f8d2fb8":"complist = list(zip(pred_list, real_fruits, acc_list))","1f5b7bc0":"tp,fp = 0,0\nfor i in range(len(complist)):\n    if complist[i][0] == complist[i][1]:\n        tp += 1\n    else:\n        fp += 1\n","7f581559":"rate = tp\/(tp+fp)\ntp,fp,rate","ba56bec8":"Code forked from https:\/\/www.kaggle.com\/huzeyfedegirmenci\/fruit-veg-classification . I will be updating the CNN with few more layers and neurons pretty soon"}}