{"cell_type":{"a37f27c0":"code","5161f7e0":"code","718df084":"code","d3a3f144":"code","624906dd":"code","5c4067dc":"code","ff95edaa":"code","d0561681":"code","834a1da6":"code","e410d90a":"code","00ffb002":"code","9fb72403":"code","37007afd":"code","8f889f48":"code","7cf42819":"code","46d43ca1":"code","a39a6960":"code","211abdda":"code","ee656ebe":"code","d75737fb":"code","597c5fba":"code","a5dc86e2":"code","3493a045":"code","9b138845":"code","0939a16c":"code","4d65b34f":"code","4a1567bf":"code","0e9483d5":"code","1848d937":"code","7a138511":"code","deb95224":"code","ed5c5910":"code","1d251ee8":"code","3a62d3f7":"code","8a3987e5":"code","6d165de9":"code","73c51842":"code","d9abd95f":"code","f7b57e33":"code","3099f72d":"code","d19ce62e":"code","79006f0d":"code","c658422c":"code","56c82863":"markdown","89f3e837":"markdown","df5c765a":"markdown","778b0816":"markdown","1643db65":"markdown","cdcc7502":"markdown","7a277dde":"markdown","15aa89f0":"markdown","5302f942":"markdown","1446c9c9":"markdown","e0d474fc":"markdown","9a4d943d":"markdown","684a3683":"markdown","75748a5a":"markdown","3ebdd63b":"markdown","4858201c":"markdown","aa6bc23f":"markdown","00a5c2a2":"markdown","700c7221":"markdown","e1eb10b2":"markdown","b4481eeb":"markdown","36559423":"markdown","fcdd4052":"markdown","96865199":"markdown","72eba028":"markdown","ac6cd736":"markdown","53480b27":"markdown","b3de93a5":"markdown"},"source":{"a37f27c0":"import numpy as np\nimport pandas as pd \nimport os\nimport shutil\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\nfrom skimage import exposure\nfrom glob import glob\n\nfrom scipy.io import wavfile\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import GroupKFold","5161f7e0":"dataset_dir = '..\/input\/vinbigdata-chest-xray-abnormalities-detection'","718df084":"def dicom2array(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n        \n    \ndef plot_img(img, size=(7, 7), is_rgb=True, title=\"\", cmap='gray'):\n    plt.figure(figsize=size)\n    plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n\n\ndef plot_imgs(imgs, cols=4, size=7, is_rgb=True, title=\"\", cmap='gray', img_size=(1000,1000)):\n    rows = len(imgs)\/\/cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img_size is not None:\n            img = cv2.resize(img, img_size)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()","d3a3f144":"def clahe(image, clipLimit = 2., tileGridSize = (10,10)):\n    clahe = cv2.createCLAHE(\n        clipLimit, \n        tileGridSize\n    )\n    \n    image = clahe.apply(image) \n    #image = tf.expand_dims(image, axis = 2)\n    \n    return image","624906dd":"def bcet(img):\n    Lmin = np.min(img) # MINIMUM OF INPUT IMAGE\n    Lmax = np.max(img) # MAXIMUM OF INPUT IMAGE\n    Lmean = np.mean(img) #MEAN OF INPUT IMAGE\n    LMssum = np.mean(img * img) #MEAN SQUARE SUM OF INPUT IMAGE\n\n    Gmin = 0 #MINIMUM OF OUTPUT IMAGE\n    Gmax = 255 #MAXIMUM OF OUTPUT IMAGE\n    Gmean = 110 #MEAN OF OUTPUT IMAGE\n\n    bnum = Lmax * Lmax *(Gmean-Gmin) - LMssum*(Gmax-Gmin) + Lmin * Lmin *(Gmax-Gmean)\n    bden = 2*(Lmax*(Gmean-Gmin)-Lmean*(Gmax-Gmin)+Lmin*(Gmax-Gmean))\n\n    b = bnum\/bden\n\n    a = (Gmax-Gmin)\/((Lmax-Lmin)*(Lmax+Lmin-2*b))\n\n    c = Gmin - a*(Lmin-b) * (Lmin-b)\n\n    y = a*(img-b) * (img-b) +c #PARABOLIC FUNCTION\n    y = np.array(y, dtype=np.uint8)\n\n    return y","5c4067dc":"dicom_paths = glob(f'{dataset_dir}\/train\/*.dicom')\nimgs = [dicom2array(path) for path in dicom_paths[:4]]\nplot_imgs(imgs)\nplt.show()\nclahe_img = [clahe(img) for img in imgs]\nplot_imgs(clahe_img)\nplt.show()\nbcet_img = [bcet(img) for img in imgs]\nplot_imgs(bcet_img)\nplt.show()\n","ff95edaa":"hist_ori = cv2.calcHist(imgs[0],[0],None,[256],[0,256])\nhist_clahe = cv2.calcHist(clahe_img[0],[0],None,[256],[0,256])\nhist_bcet = cv2.calcHist(bcet_img[0],[0],None,[256],[0,256])\n\n\nplt.plot(hist_ori,color='r', label='original'), plt.legend()\nplt.plot(hist_clahe,color='g', label = 'clahe'), plt.legend()\nplt.plot(hist_bcet,color='b', label = 'bcet'), plt.legend()\n","d0561681":"clahe_img = [clahe(img) for img in imgs]\nplot_imgs(clahe_img)\nplt.show()\nbcet_img = [bcet(img) for img in imgs]\nplot_imgs(bcet_img)\nplt.show()\nbcet_clahe = [clahe(img) for img in bcet_img]\nplot_imgs(bcet_clahe)","834a1da6":"clahe_bcet = [bcet(img) for img in clahe_img]\nplot_imgs(clahe_bcet)","e410d90a":"dim = 512 #1024, 256, 'original'\ntest_dir = f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/test'\nweights_dir = '\/kaggle\/input\/vinbigdata-cxr-ad-yolov5-14-class-train\/yolov5\/runs\/train\/exp\/weights\/best.pt'\n\ntrain_df = pd.read_csv(f'..\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/train.csv')\ntrain_df['image_path'] = f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/train\/'+train_df.image_id+('.png' if dim!='original' else '.jpg')\n\ntrain_df = train_df[train_df.class_id!=14].reset_index(drop = True)\n\n\nfold = 4\ngkf  = GroupKFold(n_splits = 5)\ntrain_df['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.image_id.tolist())):\n    train_df.loc[val_idx, 'fold'] = fold\nval_df = train_df[train_df['fold']==4]\n#val_df.head()\n","00ffb002":"train_files = []\nval_files   = []\nval_files += list(train_df[train_df.fold==fold].image_path.unique())\ntrain_files += list(train_df[train_df.fold!=fold].image_path.unique())\nlen(train_files), len(val_files)","9fb72403":"os.makedirs('\/kaggle\/working\/vinbigdata\/labels\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata\/labels\/val', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata\/images\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata\/images\/val', exist_ok = True)\nlabel_dir = '\/kaggle\/input\/vinbigdata-yolo-labels-dataset\/labels'\nfor file in train_files:\n    shutil.copy(file, '\/kaggle\/working\/vinbigdata\/images\/train')\n    filename = file.split('\/')[-1].split('.')[0]\n    shutil.copy(os.path.join(label_dir, filename+'.txt'), '\/kaggle\/working\/vinbigdata\/labels\/train')\n    \nfor file in val_files:\n    shutil.copy(file, '\/kaggle\/working\/vinbigdata\/images\/val')\n    filename = file.split('\/')[-1].split('.')[0]\n    shutil.copy(os.path.join(label_dir, filename+'.txt'), '\/kaggle\/working\/vinbigdata\/labels\/val')\n    \nval_dir = f'\/kaggle\/working\/vinbigdata\/images\/val'","37007afd":"os.makedirs('\/kaggle\/working\/vinbigdata_clahe\/images\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata_clahe\/images\/val', exist_ok = True)\n\nos.makedirs('\/kaggle\/working\/vinbigdata_bcet\/images\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata_bcet\/images\/val', exist_ok = True)\n\nos.makedirs('\/kaggle\/working\/vinbigdata_bcet_clahe\/images\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata_bcet_clahe\/images\/val', exist_ok = True)\n\n\n# clahe\nshutil.copytree('\/kaggle\/working\/vinbigdata\/labels\/train','\/kaggle\/working\/vinbigdata_clahe\/labels\/train', )\nshutil.copytree('\/kaggle\/working\/vinbigdata\/labels\/val','\/kaggle\/working\/vinbigdata_clahe\/labels\/val')\n\n# bcet\nshutil.copytree('\/kaggle\/working\/vinbigdata\/labels\/train','\/kaggle\/working\/vinbigdata_bcet\/labels\/train')\nshutil.copytree('\/kaggle\/working\/vinbigdata\/labels\/val','\/kaggle\/working\/vinbigdata_bcet\/labels\/val')\n\n# bcet_clahe\nshutil.copytree('\/kaggle\/working\/vinbigdata\/labels\/train','\/kaggle\/working\/vinbigdata_bcet_clahe\/labels\/train')\nshutil.copytree('\/kaggle\/working\/vinbigdata\/labels\/val','\/kaggle\/working\/vinbigdata_bcet_clahe\/labels\/val')","8f889f48":"# clahe\npath = '\/kaggle\/working\/vinbigdata\/images\/train'\nsave_path = '\/kaggle\/working\/vinbigdata_clahe\/images\/train'\nimages = os.listdir(path)\n\nfor image in images:\n    img_path = os.path.join(path, image)\n    ori_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    dst_img = clahe(ori_img)\n\n    cv2.imwrite(os.path.join(save_path, image), dst_img)\n    \nprint('clahe done')\n\n# bcet    \npath = '\/kaggle\/working\/vinbigdata\/images\/train'\nsave_path_bcet = '\/kaggle\/working\/vinbigdata_bcet\/images\/train'\nimages_bcet = os.listdir(path)\n\nfor image in images_bcet:\n    img_path = os.path.join(path, image)\n    ori_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    dst_img = bcet(ori_img)\n\n    cv2.imwrite(os.path.join(save_path_bcet, image), dst_img)\n    \nprint('bcet done')\n\n# bcet -> clahe\npath = '\/kaggle\/working\/vinbigdata_bcet\/images\/train'\nsave_path_bclahe = '\/kaggle\/working\/vinbigdata_bcet_clahe\/images\/train'\nimages_bcet_clahe = os.listdir(path)\n\nfor image in images_bcet_clahe:\n    img_path = os.path.join(path, image)\n    ori_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    dst_img = clahe(ori_img)\n\n    cv2.imwrite(os.path.join(save_path_bclahe, image), dst_img)\n    \nprint('bcet_clahe done')","7cf42819":"print(len(os.listdir(save_path)))\nsample = cv2.imread(os.path.join(save_path, images[0]))\nplt.imshow(sample)","46d43ca1":"print(len(os.listdir(save_path_bcet)))\nsample = cv2.imread(os.path.join(save_path_bcet, images[0]))\nplt.imshow(sample)","a39a6960":"print(len(os.listdir(save_path_bclahe)))\nsample = cv2.imread(os.path.join(save_path_bclahe, images[0]))\nplt.imshow(sample)","211abdda":"# clahe\nval_path = '\/kaggle\/working\/vinbigdata\/images\/val'\nsave_path = '\/kaggle\/working\/vinbigdata_clahe\/images\/val'\nimages = os.listdir(val_path)\n\nfor image in images:\n    img_path = os.path.join(val_path, image)\n    ori_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    dst_img = clahe(ori_img)\n\n    cv2.imwrite(os.path.join(save_path, image), dst_img)\n    \nprint('clahe done')\n\n# bcet    \nval_path = '\/kaggle\/working\/vinbigdata\/images\/val'\nval_save_path_bcet = '\/kaggle\/working\/vinbigdata_bcet\/images\/val'\nimages = os.listdir(val_path)\n\nfor image in images:\n    img_path = os.path.join(val_path, image)\n    ori_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    dst_img = bcet(ori_img)\n\n    cv2.imwrite(os.path.join(val_save_path_bcet, image), dst_img)\n    \nprint('bcet done')\n\n# bcet -> clahe\nval_path = '\/kaggle\/working\/vinbigdata_bcet\/images\/val'\nval_save_path_bclahe = '\/kaggle\/working\/vinbigdata_bcet_clahe\/images\/val'\nimages = os.listdir(val_path)\n\nfor image in images:\n    img_path = os.path.join(val_path, image)\n    ori_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    dst_img = clahe(ori_img)\n\n    cv2.imwrite(os.path.join(val_save_path_bclahe, image), dst_img)\n    \nprint('bcet_clahe done')","ee656ebe":"print(len(os.listdir(save_path)))\nsample = cv2.imread(os.path.join(save_path, images[0]))\nplt.imshow(sample)","d75737fb":"print(len(os.listdir(val_save_path_bcet)))\nsample = cv2.imread(os.path.join(val_save_path_bcet, images[0]))\nplt.imshow(sample)","597c5fba":"print(len(os.listdir(save_path)))\nsample = cv2.imread(os.path.join(val_save_path_bclahe, images[0]))\nplt.imshow(sample)","a5dc86e2":"class_ids, class_names = list(zip(*set(zip(train_df.class_id, train_df.class_name))))\nclasses = list(np.array(class_names)[np.argsort(class_ids)])\nclasses = list(map(lambda x: str(x), classes))\nclasses","3493a045":"from os import listdir\nfrom os.path import isfile, join\nimport yaml\n\ncwd = '\/kaggle\/working\/'\n\nwith open(join( cwd , 'train.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata\/images\/train\/*'):\n        f.write(path+'\\n')\n            \nwith open(join( cwd , 'val.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata\/images\/val\/*'):\n        f.write(path+'\\n')\n\ndata = dict(\n    train =  join( cwd , 'train.txt') ,\n    val   =  join( cwd , 'val.txt' ),\n    nc    = 14,\n    names = classes\n    )\n\nwith open(join( cwd , 'vinbigdata.yaml'), 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open(join( cwd , 'vinbigdata.yaml'), 'r')\nprint('\\nyaml:')\nprint(f.read())\n","9b138845":"shutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5')\nos.chdir('\/kaggle\/working\/yolov5') # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","0939a16c":"!WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 20 --data \/kaggle\/working\/vinbigdata.yaml --weights yolov5s.pt --cache","4d65b34f":"from os import listdir\nfrom os.path import isfile, join\nimport yaml\n\ncwd = '\/kaggle\/working\/'\n\nwith open(join( cwd , 'train_clahe.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata_clahe\/images\/train\/*'):\n        f.write(path+'\\n')\n            \nwith open(join( cwd , 'val_clahe.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata_clahe\/images\/val\/*'):\n        f.write(path+'\\n')\n\ndata = dict(\n    train =  join( cwd , 'train_clahe.txt') ,\n    val   =  join( cwd , 'val_clahe.txt' ),\n    nc    = 14,\n    names = classes\n    )\n\nwith open(join( cwd , 'vinbigdata_clahe.yaml'), 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open(join( cwd , 'vinbigdata_clahe.yaml'), 'r')\nprint('\\nyaml:')\nprint(f.read())\n","4a1567bf":"shutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5_clahe')\nos.chdir('\/kaggle\/working\/yolov5_clahe') # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","0e9483d5":"!WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 20 --data \/kaggle\/working\/vinbigdata_clahe.yaml --weights yolov5s.pt --cache\n","1848d937":"from os import listdir\nfrom os.path import isfile, join\nimport yaml\n\ncwd = '\/kaggle\/working\/'\n\nwith open(join( cwd , 'train_bcet.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata_bcet\/images\/train\/*'):\n        f.write(path+'\\n')\n            \nwith open(join( cwd , 'val_bcet.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata_bcet\/images\/val\/*'):\n        f.write(path+'\\n')\n\ndata = dict(\n    train =  join( cwd , 'train_bcet.txt') ,\n    val   =  join( cwd , 'val_bcet.txt' ),\n    nc    = 14,\n    names = classes\n    )\n\nwith open(join( cwd , 'vinbigdata_bcet.yaml'), 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open(join( cwd , 'vinbigdata_bcet.yaml'), 'r')\nprint('\\nyaml:')\nprint(f.read())","7a138511":"shutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5_bcet')\nos.chdir('\/kaggle\/working\/yolov5_bcet') # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","deb95224":"!WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 20 --data \/kaggle\/working\/vinbigdata_bcet.yaml --weights yolov5s.pt --cache\n","ed5c5910":"from os import listdir\nfrom os.path import isfile, join\nimport yaml\n\ncwd = '\/kaggle\/working\/'\n\nwith open(join( cwd , 'train_bcet_clahe.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata_bcet_clahe\/images\/train\/*'):\n        f.write(path+'\\n')\n            \nwith open(join( cwd , 'val_bcet_clahe.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata_bcet_clahe\/images\/val\/*'):\n        f.write(path+'\\n')\n\ndata = dict(\n    train =  join( cwd , 'train_bcet_clahe.txt') ,\n    val   =  join( cwd , 'val_bcet_clahe.txt' ),\n    nc    = 14,\n    names = classes\n    )\n\nwith open(join( cwd , 'vinbigdata_bcet_clahe.yaml'), 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open(join( cwd , 'vinbigdata_bcet_clahe.yaml'), 'r')\nprint('\\nyaml:')\nprint(f.read())","1d251ee8":"shutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5_bcet_clahe')\nos.chdir('\/kaggle\/working\/yolov5_bcet_clahe') # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","3a62d3f7":"!WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 20 --data \/kaggle\/working\/vinbigdata_bcet_clahe.yaml --weights yolov5s.pt --cache","8a3987e5":"os.chdir('\/kaggle\/working\/yolov5')\n!python detect.py --weights '\/kaggle\/working\/yolov5\/runs\/train\/exp\/weights\/best.pt'\\\n--img 640\\\n--conf 0.15\\\n--iou 0.5\\\n--source \/kaggle\/working\/vinbigdata\/images\/val\\\n--exist-ok","6d165de9":"os.chdir('\/kaggle\/working\/yolov5_clahe')\n!python detect.py --weights '\/kaggle\/working\/yolov5_clahe\/runs\/train\/exp\/weights\/best.pt'\\\n--img 640\\\n--conf 0.15\\\n--iou 0.5\\\n--source \/kaggle\/working\/vinbigdata_clahe\/images\/val\\\n--exist-ok","73c51842":"os.chdir('\/kaggle\/working\/yolov5_bcet')\n!python detect.py --weights '\/kaggle\/working\/yolov5_bcet\/runs\/train\/exp\/weights\/best.pt'\\\n--img 640\\\n--conf 0.15\\\n--iou 0.5\\\n--source \/kaggle\/working\/vinbigdata_bcet\/images\/val\\\n--exist-ok","d9abd95f":"os.chdir('\/kaggle\/working\/yolov5_bcet_clahe')\n!python detect.py --weights '\/kaggle\/working\/yolov5_bcet_clahe\/runs\/train\/exp\/weights\/best.pt'\\\n--img 640\\\n--conf 0.15\\\n--iou 0.5\\\n--source \/kaggle\/working\/vinbigdata_bcet_clahe\/images\/val\\\n--exist-ok","f7b57e33":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('\/kaggle\/working\/yolov5\/runs\/detect\/exp\/*')\n\nfor _ in range(1):\n    row = 4\n    col = 4\n    grid_files = files[:16]\n    images     = []\n    for image_path in tqdm(grid_files):\n        img          = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","3099f72d":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('\/kaggle\/working\/yolov5_clahe\/runs\/detect\/exp\/*')\n\nfor _ in range(1):\n    row = 4\n    col = 4\n    grid_files = files[:16]\n    images     = []\n    for image_path in tqdm(grid_files):\n        img          = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","d19ce62e":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('\/kaggle\/working\/yolov5_bcet\/runs\/detect\/exp\/*')\n\nfor _ in range(1):\n    row = 4\n    col = 4\n    grid_files = files[:16]\n    images     = []\n    for image_path in tqdm(grid_files):\n        img          = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","79006f0d":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('\/kaggle\/working\/yolov5_bcet_clahe\/runs\/detect\/exp\/*')\n\nfor _ in range(1):\n    row = 4\n    col = 4\n    grid_files = files[:16]\n    images     = []\n    for image_path in tqdm(grid_files):\n        img          = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","c658422c":"import random\nfrom random import randint\n\nimgs = []\nfile = '\/kaggle\/working\/yolov5\/runs\/detect\/exp\/'\noriginal_file = '\/kaggle\/working\/vinbigdata\/images\/val\/'\nimg_ids = os.listdir(file)\nclass_ids = val_df['class_id'].unique()\n\n# map label_id to specify color\nlabel2color = {class_id:[randint(0,255) for i in range(3)] for class_id in class_ids}\nthickness = 3\nscale = 5\n\n\nfor i in range(16):\n    img_id = img_ids[i][:-4]\n    img_png = img_ids[i]\n    #img_path = f'{dataset_dir}\/train\/{img_id}.dicom'\n    img = cv2.imread(os.path.join(original_file, img_png))\n    #img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n    #img = np.stack([img, img, img], axis=-1)\n    \n    boxes = val_df.loc[val_df['image_id'] == img_id, ['x_min', 'y_min', 'x_max', 'y_max']].values\/scale\n    labels = val_df.loc[val_df['image_id'] == img_id, ['class_id']].values.squeeze()\n\n    \n    for label_id, box in zip(labels, boxes):\n        color = label2color[label_id]\n        img = cv2.rectangle(\n            img,\n            (int(box[0]), int(box[1])),\n            (int(box[2]), int(box[3])),\n            color, thickness\n    )\n    #img = cv2.resize(img, (500,500))\n    imgs.append(img)\n    \nplot_imgs(imgs, cmap=None)","56c82863":"# Train with bcet_clahe images","89f3e837":"# Compare with GT labels","df5c765a":"# Inference result (train with bcet images)","778b0816":"Clahe highlights the bones and blood vessels \\\nBcet emphasizes the information on the volume of the lungs.","1643db65":"# Inference result (train with original images)","cdcc7502":"# Image comparison when seen with the eyes","7a277dde":"Bcet emphasizes black area","15aa89f0":"# Inference result (train with clahe images)","5302f942":"# train with original image","1446c9c9":"### It seems without Clahe performs best for mAP score. \n#### But this experiment use abnormal images only, so I will experiment with normal images.\n### Bcet-clahe is the worst, so multiple preprocessing are not recommended.","e0d474fc":"# What to do?\n\n1. Introducing another way to enhance chest x-ray image (BCET) \n2. After training the images (Original, Clahe, Bcet, Bcet+Clahe) with Yolo v5 model, inference the result\n3. GT label vs prediction\n4. Compare with mAP score\n\n","9a4d943d":"> mAP compare\n\n\n1. Original\n    * mAP_0.5 0.30146\n    * mAP_0.5:0.95 0.12736\n\n1. Clahe\n    * mAP_0.5 0.29131  \n    * mAP_0.5:0.95 0.12017\n\n2. Bcet\n    * mAP_0.5 0.28734\n    * mAP_0.5:0.95 0.12204\n\n3. Bcet-clahe\n    * mAP_0.5 0.28066\n    * mAP_0.5:0.95 0.1193\n    \n    \ntrain(3515) 20 epoch and validate abnormal images(879) , 512x512, yolov5s","684a3683":"1st row : original images \\\n2nd row : clahe images \\\n3rd row : bcet images","75748a5a":"How about vice versa??","3ebdd63b":"# Train and compare performances","4858201c":"# Histogram analysis","aa6bc23f":"Terrible...","00a5c2a2":"1st row : clahe images  \\\n2nd row : bcet images  \\\n3rd row : bcet -> clahe images","700c7221":"# Inference","e1eb10b2":"# Setups for training yolo v5\n","b4481eeb":"## This notebook is quick save version, so if you want see the results, please see ver 9.\n","36559423":"# Train with bcet images","fcdd4052":"# train with clahe image","96865199":"# Conclusion","72eba028":"# Inference result (train with bcet_clahe images)","ac6cd736":"# References\n\n1. https:\/\/www.kaggle.com\/trungthanhnguyen0502\/eda-vinbigdata-chest-x-ray-abnormalities\n2. https:\/\/www.kaggle.com\/bhallaakshit\/dicom-wrangling-and-enhancement\n3. https:\/\/www.kaggle.com\/awsaf49\/vinbigdata-cxr-ad-yolov5-14-class-train\n4. https:\/\/www.kaggle.com\/kuuuuub\/x-ray-image-enhancement-test\/data\n\nThanks for above great works!\n\n","53480b27":"# Balance Contrast Enhancement Technique(BCET)\n\nPaper : LIU JIAN GUO (1991) Balance contrast enhancement technique and its application in image colour composition, International Journal of Remote Sensing, 12:10, 2133-2151, DOI: 10.1080\/01431169108955241\n\nMatlab implemented code : https:\/\/www.imageeprocessing.com\/2017\/11\/balance-contrast-enhancement-technique.html\n\nThe above code was modified and used.","b3de93a5":"Check samples"}}