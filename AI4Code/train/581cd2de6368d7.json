{"cell_type":{"a8238ac0":"code","cd91f730":"code","e40088b9":"code","7f363e06":"code","01010053":"code","dbef348b":"code","ed044768":"code","d95e59b2":"code","c38cc3b3":"code","1ff9976e":"code","8b9fa2bd":"code","753da4eb":"code","0c644e9a":"code","a98ad4d3":"code","334c97ba":"code","71351f97":"code","365ccd9a":"code","8fffeb06":"code","74703f77":"markdown"},"source":{"a8238ac0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cd91f730":"dtypes = {\n\"duration\": np.int8,\n\"protocol_type\": np.object,\n\"service\": np.object,\n\"flag\": np.object,\n\"src_bytes\":  np.int8,\n\"dst_bytes\":  np.int8,\n\"land\": np.int8,\n\"wrong_fragment\":  np.int8,\n\"urgent\": np.int8,\n\"hot\": np.int8,\n\"m_failed_logins\":  np.int8,\n\"logged_in\":  np.int8,\n\"num_compromised\":  np.int8,\n\"root_shell\":  np.int8,\n\"su_attempted\":  np.int8,\n\"num_root\": np.int8,\n\"num_file_creations\":  np.int8,\n\"num_shells\":  np.int8,\n\"num_access_files\":  np.int8,\n\"num_outbound_cmds\":  np.int8,\n\"is_host_login\":  np.int8,\n\"is_guest_login\":  np.int8,\n\"count\": np.int8,\n\"srv_count\":  np.int8,\n\"serror_rate\": np.float16,\n\"srv_serror_rate\": np.float16,\n\"rerror_rate\": np.float16,\n\"srv_rerror_rate\": np.float16,\n\"same_srv_rate\": np.float16,\n\"diff_srv_rate\": np.float16,\n\"srv_diff_host_rate\": np.float16,\n\"dst_host_count\":  np.int8,\n\"dst_host_srv_count\":  np.int8,\n\"dst_host_same_srv_rate\": np.float16,\n\"dst_host_diff_srv_rate\": np.float16,\n\"dst_host_same_src_port_rate\": np.float16,\n\"dst_host_srv_diff_host_rate\": np.float16,\n\"dst_host_serror_rate\": np.float16,\n\"dst_host_srv_serror_rate\": np.float16,\n\"dst_host_rerror_rate\": np.float16,\n\"dst_host_srv_rerror_rate\": np.float16,\n\"label\": np.object\n}\n","e40088b9":"columns = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"m_failed_logins\",\n\"logged_in\", \"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\"num_access_files\",\n\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\n\"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\n\"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\n\"dst_host_srv_rerror_rate\",\"label\"]\n\ndf = pd.read_csv(\"\/kaggle\/input\/kdd-cup-1999-data\/kddcup.data.corrected\", sep=\",\", names=columns,  index_col=None)","7f363e06":"df.head()","01010053":"df.describe()","dbef348b":"#filter out the data to only include data entries that involve an http attack, and drop the service column\ndf=df[df[\"service\"]==\"http\"]\ndf=df.drop(\"service\",axis=1)\ncolumns.remove(\"service\")\ndf.head()","ed044768":"df.shape","d95e59b2":"df[\"label\"].value_counts()","c38cc3b3":"for col in df.columns:\n    if(df[col].dtypes==\"object\"):\n        encoded=LabelEncoder()\n        encoded.fit(df[col])\n        df[col]=encoded.transform(df[col])","1ff9976e":"df.head()\ndf.shape","8b9fa2bd":"# let's now shuffle the values in df and create our own training testing and validaion datasets\n\nfor f in range(0,3):\n    df=df.iloc[np.random.permutation(len(df))]\n\ndf2=df[:500000]\nlabels=df2[\"label\"]\ndf_validate=df[500000:]\nx_train,x_test,y_train,y_test=train_test_split(df2,labels,test_size=0.2,random_state=42)\nx_val,y_val=df_validate,df_validate[\"label\"]","753da4eb":"print(x_train.shape)\nprint(x_test.shape)\nprint(x_val.shape)","0c644e9a":"#let's build our Isolation Forest model\nmodel=IsolationForest(n_estimators=500,max_samples=256,contamination=0.1,random_state=42)\n#check sklearn website for details of Isolation Forest\n","a98ad4d3":"model.fit(x_train)","334c97ba":"anomaly_scores=model.decision_function(x_val)\nplt.figure(figsize=(15,10))\nplt.hist(anomaly_scores,bins=100)\nplt.xlabel('Average Path Lengths',fontsize=14)\nplt.ylabel('Number of Data Points',fontsize=14)\nplt.show()","71351f97":"from sklearn.metrics import roc_auc_score\nanomalies=anomaly_scores>-0.19\nmatches=y_val==list(encoded.classes_).index(\"normal.\")\nauc=roc_auc_score(anomalies,matches)\nprint(\"AUC: {:.2%}\".format(auc))","365ccd9a":"anomaly_scores_test=model.decision_function(x_test)\nplt.figure(figsize=(15,10))\nplt.hist(anomaly_scores_test,bins=100)\nplt.xlabel('Average Path Lengths',fontsize=14)\nplt.ylabel('Number of Data Points',fontsize=14)\nplt.show()","8fffeb06":"from sklearn.metrics import roc_auc_score\nanomalies=anomaly_scores_test>-0.19\nmatches=y_test==list(encoded.classes_).index(\"normal.\")\nauc=roc_auc_score(anomalies,matches)\nprint(\"AUC: {:.2%}\".format(auc))","74703f77":"# Getting the anomaly scores from the trained isolation forest model and plot a histogram"}}