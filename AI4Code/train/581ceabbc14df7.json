{"cell_type":{"6e20a9ea":"code","5a382615":"code","7169015f":"code","5df8fa9e":"code","ad136b58":"code","5ce68ce7":"code","c263bd6b":"code","44c7ff22":"code","d3993636":"code","24430708":"code","e0b668ed":"code","834d76b7":"code","532304a3":"code","e87c1c68":"code","eb88c0c7":"code","73aaa022":"code","1e5d2692":"code","aaa3c73c":"code","24e01613":"code","1a508630":"code","693ba96a":"code","b43b64e4":"code","32d7701a":"code","c1d5830f":"code","cd54f1a6":"code","a0fc42ab":"code","3f1218f1":"code","f14673c3":"code","c395ddd9":"code","aba50396":"code","d6f4d6f7":"code","6ba6bcd9":"code","3b72ae53":"code","b683ac1c":"code","31f8322d":"code","49eba8d9":"code","5b4902b8":"code","985fc782":"code","dfd2bc6a":"code","7e77c4d2":"code","e5bbddf8":"code","057a025c":"code","0f9a218e":"code","21202b6d":"code","4fcf0fdf":"code","7c447c80":"code","2a65f0d3":"code","d7a9df2c":"code","4e7fdcd3":"code","e9814115":"markdown","cb53c7fc":"markdown","1194395d":"markdown","bde71d65":"markdown","10196bbd":"markdown","a8f8f32a":"markdown","2b4e533a":"markdown","d8bc97d7":"markdown","340bafee":"markdown","47ccdac1":"markdown","37dea3f9":"markdown","d0cd7e9f":"markdown","f6e8355b":"markdown","af90af77":"markdown","f8dd5e0f":"markdown","ae2fd196":"markdown","5d3a9cbd":"markdown","78fbbac4":"markdown","8553ef02":"markdown","9c52af35":"markdown","1f005c66":"markdown","ca55bbf5":"markdown","68c02c15":"markdown","460259e2":"markdown","6180254e":"markdown","64efd4ac":"markdown","97a3060e":"markdown","4371f1a0":"markdown","a44060b3":"markdown","7d821bef":"markdown","a0c763a0":"markdown","d1d1d56b":"markdown","9f6da74a":"markdown","0b8e901e":"markdown","18e8e12b":"markdown","62086761":"markdown","f9437b8d":"markdown","4a30a64b":"markdown","28cc3b6b":"markdown","efd2f3e1":"markdown","8673d88a":"markdown","e8483d66":"markdown","d44d4fc3":"markdown","b604a03f":"markdown","424eb177":"markdown","5313b6ac":"markdown","ae8ffa61":"markdown","0906ecad":"markdown","2ea9dd42":"markdown","0d9295c5":"markdown","4e406580":"markdown","62b65bfb":"markdown","1f0c8bca":"markdown","d4be8400":"markdown","ef1a7192":"markdown","69a7f45f":"markdown","d91a0045":"markdown","c6b9b09d":"markdown","870c8b64":"markdown","86952a2a":"markdown","1bcfe295":"markdown","1b37b2d0":"markdown"},"source":{"6e20a9ea":"import pandas as pd \nimport numpy as np\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nfrom matplotlib.patches import Rectangle\nimport seaborn as sns\nimport openslide\nimport PIL\n%matplotlib inline \nPATH = \"\/kaggle\/input\/prostate-cancer-grade-assessment\/\"","5a382615":"sample_submission_df = pd.read_csv(os.path.join(PATH,'sample_submission.csv'))\ntrain_df = pd.read_csv(os.path.join(PATH,'train.csv'))\ntest_df = pd.read_csv(os.path.join(PATH,'test.csv'))","7169015f":"print(f\"sample submission shape: {sample_submission_df.shape}\")\nprint(f\"train shape: {train_df.shape}\")\nprint(f\"test shape: {test_df.shape}\")","5df8fa9e":"sample_submission_df.head()","ad136b58":"train_df.head()","5ce68ce7":"test_df.head()","c263bd6b":"train_image_list = os.listdir(os.path.join(PATH, 'train_images'))\ntrain_label_masks_list = os.listdir(os.path.join(PATH, 'train_label_masks'))","44c7ff22":"print(f\"train image_id list: {train_df.image_id.nunique()}\")\nprint(f\"train image list: {len(train_image_list)}\")\nprint(f\"train label masks list: {len(train_label_masks_list)}\")","d3993636":"print(f\"sample of image_id list: {train_df.image_id.values[0:3]}\")\nprint(f\"sample of image list: {train_image_list[0:3]}\")\nprint(f\"sample of label masks list: {train_label_masks_list[0:3]}\")","24430708":"trimmed_image_list = []\nfor img in train_image_list:\n    trimmed_image_list.append(img.split('.tiff')[0])","e0b668ed":"trimmed_label_masks_list = []\nfor img in train_label_masks_list:\n    trimmed_label_masks_list.append(img.split('_mask.tiff')[0])","834d76b7":"intersect_i_m = (set(trimmed_image_list) & set(trimmed_label_masks_list))\nintersect_id_m = (set(train_df.image_id.unique()) & set(trimmed_label_masks_list))\nprint(f\"image (tiff) & label masks: {len(intersect_i_m)}\")\nprint(f\"image_id (train) & label masks: {len(intersect_id_m)}\")","532304a3":"!pip install bokeh","e87c1c68":"from bokeh.plotting import ColumnDataSource, figure, output_notebook, show\nfrom bokeh.palettes import Spectral8\noutput_notebook()","eb88c0c7":"provider = train_df['data_provider'].unique().tolist()\ncount_provider = train_df['data_provider'].value_counts().tolist()\n\ntools = \"hover,pan,wheel_zoom,box_zoom,reset,lasso_select\"\nsource = ColumnDataSource(data=dict(provider=provider, counts=count_provider, color=Spectral8))\np = figure(x_range=provider, y_range=(0,6000), plot_width =900, plot_height = 400, title=\"Data Provider - Data Count\",\n           toolbar_location=\"right\", tools = tools)\np.xaxis.axis_label = \"Data Provider\"\np.yaxis.axis_label = \"Value Count\"\n\n# Render and show the vbar plot\np.vbar(x='provider', top='counts', width=0.3, color='color', source=source)\nshow(p)\n\n","73aaa022":"isup_grade = train_df['isup_grade'].unique().tolist()\ncount_isup_grade = train_df['isup_grade'].value_counts().tolist()\n\nsource2 = ColumnDataSource(data=dict(isup_grade=isup_grade, counts=count_isup_grade, color=Spectral8))\np2 = figure(y_range=(0,6000), plot_width =900, plot_height = 400, title=\"ISUP grade - Data Count\",\n           toolbar_location=\"right\", tools = tools)\n\np2.xaxis.axis_label = \"isup_grade\"\np2.yaxis.axis_label = \"Value Count\"\np2.vbar(x='isup_grade', top='counts', width=0.3, color='color', source=source2)\nshow(p2)","1e5d2692":"gleason_score = train_df['gleason_score'].unique().tolist()\ncount_gleason_score= train_df['gleason_score'].value_counts().tolist()\n\nsource_3 = ColumnDataSource(data=dict(gleason_score = gleason_score, counts = count_gleason_score, color=Spectral8))\np3 = figure(x_range = gleason_score,y_range=(0,4000), plot_width =900, plot_height = 400, title=\"Gleason score - Data Count\",\n           toolbar_location=\"right\", tools = tools)\n\np3.xaxis.axis_label = \"isup_grade\"\np3.yaxis.axis_label = \"Value Count\"\np3.vbar(x='gleason_score', top='counts', width=0.4, color='color', source = source_3)\nshow(p3)","aaa3c73c":"sns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(nrows=1,figsize=(15,6))\ntemp = train_df.groupby('isup_grade')['gleason_score'].value_counts()\ndf = pd.DataFrame(data={'Exams': temp.values}, index=temp.index).reset_index()\nsns.barplot(ax=ax,x = 'isup_grade', y='Exams',hue='gleason_score',data=df,palette = 'magma',dodge = True)\nplt.title(\"Number of Examinations Grouped on ISUP Grade and Gleason Score\")\nplt.show()","24e01613":"sns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(nrows=1,figsize=(15,6))\nheatmap_data = pd.pivot_table(df, values='Exams', index=['isup_grade'], columns='gleason_score')\nsns.heatmap(heatmap_data,linewidth=0.5,linecolor='skyblue')\nplt.title('Number of examinations grouped on ISUP grade and Gleason score')\nplt.show()","1a508630":"sns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(nrows=1,figsize=(18,10)) \ntmp = train_df.groupby('data_provider')['gleason_score'].value_counts() \ndf = pd.DataFrame(data={'Exams': tmp.values}, index=tmp.index).reset_index() \nsns.barplot(ax=ax,x = 'data_provider', y='Exams',hue='gleason_score',data=df, palette='Set2',errcolor='black',saturation = 1) \nplt.title(\"Number of examinations grouped on Data provider and Gleason score\") \nplt.show()","693ba96a":"sns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(nrows=1,figsize=(18,10)) \ntmp = train_df.groupby('data_provider')['isup_grade'].value_counts() \ndf = pd.DataFrame(data={'Exams': tmp.values}, index=tmp.index).reset_index() \nsns.barplot(ax=ax,x = 'data_provider', y='Exams',hue='isup_grade',data=df, palette='Set3',errcolor='black',saturation = 5)\nplt.title(\"Number of examinations grouped on Data provider and Gleason score\") \nplt.show()","b43b64e4":"def show_images(df, read_region=(1780,1950)):\n    \n    data = df\n    f, ax = plt.subplots(3,3, figsize=(16,18))\n    for i,data_row in enumerate(data.iterrows()):\n        image = str(data_row[1][0])+'.tiff'\n        image_path = os.path.join(PATH,\"train_images\",image)\n        image = openslide.OpenSlide(image_path)\n        spacing = 1 \/ (float(image.properties['tiff.XResolution']) \/ 10000)\n        patch = image.read_region(read_region, 0, (256, 256))\n        ax[i\/\/3, i%3].imshow(patch) \n        image.close()       \n        ax[i\/\/3, i%3].axis('off')\n        ax[i\/\/3, i%3].set_title('ID: {}\\nSource: {} ISUP: {} Gleason: {}'.format(\n                data_row[1][0], data_row[1][1], data_row[1][2], data_row[1][3]))\n\n    plt.show()","32d7701a":"images = [\n    '07a7ef0ba3bb0d6564a73f4f3e1c2293',\n    '037504061b9fba71ef6e24c48c6df44d',\n    '035b1edd3d1aeeffc77ce5d248a01a53',\n    '059cbf902c5e42972587c8d17d49efed',\n    '06a0cbd8fd6320ef1aa6f19342af2e68',\n    '06eda4a6faca84e84a781fee2d5f47e1',\n    '0a4b7a7499ed55c71033cefb0765e93d',\n    '0838c82917cd9af681df249264d2769c',\n    '046b35ae95374bfb48cdca8d7c83233f'\n]\ndata_sample = train_df.loc[train_df.image_id.isin(images)]\nshow_images(data_sample)","c1d5830f":"data_sample","cd54f1a6":"image_path = os.path.join(PATH,\"train_images\")\nimage = openslide.OpenSlide(os.path.join(image_path, '00a76bfbec239fd9f465d6581806ff42.tiff'))\npatch = image.read_region((1780,1950), 0, (256, 256))\n\ndisplay(patch)\n\nimage.close()","a0fc42ab":"def print_slide_details(slide, show_thumbnail=True, max_size=(600,400)):\n  \n    if show_thumbnail:\n        display(slide.get_thumbnail(size=max_size))\n        \n    spacing = 1 \/ (float(slide.properties['tiff.XResolution']) \/ 10000)\n    \n    print(f\"File id: {slide}\")\n    print(f\"Dimensions: {slide.dimensions}\")\n    print(f\"Microns per pixel \/ pixel spacing: {spacing:.3f}\")\n    print(f\"Number of levels in the image: {slide.level_count}\")\n    print(f\"Downsample factor per level: {slide.level_downsamples}\")\n    print(f\"Dimensions of levels: {slide.level_dimensions}\")","3f1218f1":"train_labels = train_df.set_index('image_id')\nexample_slides = [\n    '028098c36eb49a8c6aa6e76e365dd055',\n    '0280f8b612771801229e2dde52371141',\n    '028dc05d52d1dd336952a437f2852a0a',\n    '02a2dcd6ad8bc1d9ad7fdc04ffb6dff3',\n    '049031b0ea0dede1ca1e5ca470c1332d',\n    '05f4e9415af9fdabc19109c980daf5ad',\n    '07fd8d4f02f9b95d86da4bc89563e077'\n    \n]\n\nfor case_id in example_slides:\n    biopsy = openslide.OpenSlide(os.path.join(image_path, f'{case_id}.tiff'))\n    print_slide_details(biopsy)\n    biopsy.close()\n    \n\n    print(f\"ISUP grade: {train_labels.loc[case_id, 'isup_grade']}\")\n    print(f\"Gleason score: {train_labels.loc[case_id, 'gleason_score']}\\n\\n\")","f14673c3":"def show_masks(slides): \n    f, ax = plt.subplots(5,3, figsize=(18,22))\n    for i, slide in enumerate(slides):\n        \n        mask = openslide.OpenSlide(os.path.join(mask_dir, f'{slide}_mask.tiff'))\n        mask_data = mask.read_region((0,0), mask.level_count - 1, mask.level_dimensions[-1])\n        cmap = matplotlib.colors.ListedColormap(['black', 'gray', 'green', 'yellow', 'orange', 'red'])\n\n        ax[i\/\/3, i%3].imshow(np.asarray(mask_data)[:,:,0], cmap=cmap, interpolation='nearest', vmin=0, vmax=5) \n        mask.close()       \n        ax[i\/\/3, i%3].axis('off')\n        \n        image_id = slide\n        data_provider = data_sample_mask.loc[slide, 'data_provider']\n        isup_grade = data_sample_mask.loc[slide, 'isup_grade']\n        gleason_score = data_sample_mask.loc[slide, 'gleason_score']\n        ax[i\/\/3, i%3].set_title(f\"ID: {image_id}\\nSource: {data_provider} ISUP: {isup_grade} Gleason: {gleason_score}\")\n        f.tight_layout()\n        \n    plt.show()","c395ddd9":"images_mask  = [\n    '07a7ef0ba3bb0d6564a73f4f3e1c2293',\n    '037504061b9fba71ef6e24c48c6df44d',\n    '035b1edd3d1aeeffc77ce5d248a01a53',\n    '059cbf902c5e42972587c8d17d49efed',\n    '06a0cbd8fd6320ef1aa6f19342af2e68',\n    '06eda4a6faca84e84a781fee2d5f47e1',\n    '0a4b7a7499ed55c71033cefb0765e93d',\n    '0838c82917cd9af681df249264d2769c',\n    '028098c36eb49a8c6aa6e76e365dd055',\n    '0280f8b612771801229e2dde52371141',\n    '028dc05d52d1dd336952a437f2852a0a',\n    '02a2dcd6ad8bc1d9ad7fdc04ffb6dff3',\n    '049031b0ea0dede1ca1e5ca470c1332d',\n    '05f4e9415af9fdabc19109c980daf5ad',\n    '07fd8d4f02f9b95d86da4bc89563e077'\n]\n\nmask_dir = os.path.join(PATH,\"train_label_masks\")\ndata_sample_mask = train_df.set_index('image_id')\nshow_masks(images_mask)","aba50396":"def overlay_mask_on_slide(images, center='radboud', alpha=0.8, max_size=(800, 800)):\n    \n    f, ax = plt.subplots(5,3, figsize=(18,22))\n    \n    \n    for i, image_id in enumerate(images):\n        \n        slide = openslide.OpenSlide(os.path.join(data_dir, f'{image_id}.tiff'))\n        mask = openslide.OpenSlide(os.path.join(mask_dir, f'{image_id}_mask.tiff'))\n        slide_data = slide.read_region((0,0), slide.level_count - 1, slide.level_dimensions[-1])\n        mask_data = mask.read_region((0,0), mask.level_count - 1, mask.level_dimensions[-1])\n        mask_data = mask_data.split()[0]\n        \n        \n        # Create alpha mask\n        alpha_int = int(round(255*alpha))\n        if center == 'radboud':\n            alpha_content = np.less(mask_data.split()[0], 2).astype('uint8') * alpha_int + (255 - alpha_int)\n        elif center == 'karolinska':\n            alpha_content = np.less(mask_data.split()[0], 1).astype('uint8') * alpha_int + (255 - alpha_int)\n\n        alpha_content = PIL.Image.fromarray(alpha_content)\n        preview_palette = np.zeros(shape=768, dtype=int)\n\n        if center == 'radboud':\n            # Mapping: {0: background, 1: stroma, 2: benign epithelium, 3: Gleason 3, 4: Gleason 4, 5: Gleason 5}\n            preview_palette[0:18] = (np.array([0, 0, 0, 0.5, 0.5, 0.5, 0, 1, 0, 1, 1, 0.7, 1, 0.5, 0, 1, 0, 0]) * 255).astype(int)\n        elif center == 'karolinska':\n            # Mapping: {0: background, 1: benign, 2: cancer}\n            preview_palette[0:9] = (np.array([0, 0, 0, 0, 1, 0, 1, 0, 0]) * 255).astype(int)\n\n        mask_data.putpalette(data=preview_palette.tolist())\n        mask_rgb = mask_data.convert(mode='RGB')\n        overlayed_image = PIL.Image.composite(image1=slide_data, image2=mask_rgb, mask=alpha_content)\n        overlayed_image.thumbnail(size=max_size, resample=0)\n\n        \n        ax[i\/\/3, i%3].imshow(overlayed_image) \n        slide.close()\n        mask.close()       \n        ax[i\/\/3, i%3].axis('off')\n        \n        data_provider = train.loc[image_id, 'data_provider']\n        isup_grade = train.loc[image_id, 'isup_grade']\n        gleason_score = train.loc[image_id, 'gleason_score']\n        ax[i\/\/3, i%3].set_title(f\"ID: {image_id}\\nSource: {data_provider} ISUP: {isup_grade} Gleason: {gleason_score}\")","d6f4d6f7":"BASE_PATH = '..\/input\/prostate-cancer-grade-assessment'\ndata_dir = f'{BASE_PATH}\/train_images'\ntrain = train_df.set_index('image_id')","6ba6bcd9":"images_com = [\n    '07a7ef0ba3bb0d6564a73f4f3e1c2293',\n    '037504061b9fba71ef6e24c48c6df44d',\n    '035b1edd3d1aeeffc77ce5d248a01a53',\n    '059cbf902c5e42972587c8d17d49efed',\n    '06a0cbd8fd6320ef1aa6f19342af2e68',\n    '06eda4a6faca84e84a781fee2d5f47e1',\n    '0a4b7a7499ed55c71033cefb0765e93d',\n    '0838c82917cd9af681df249264d2769c',\n    '028098c36eb49a8c6aa6e76e365dd055',\n    '0280f8b612771801229e2dde52371141',\n    '028dc05d52d1dd336952a437f2852a0a',\n    '02a2dcd6ad8bc1d9ad7fdc04ffb6dff3',\n    '049031b0ea0dede1ca1e5ca470c1332d',\n    '05f4e9415af9fdabc19109c980daf5ad',\n    '07fd8d4f02f9b95d86da4bc89563e077'\n]\n\noverlay_mask_on_slide(images_com)","3b72ae53":"files = os.listdir(PATH+\"train_images\/\")\nprint(f\"there are {len(files)} tiff files in train_images folder\")\nfor i in train_df.image_id:\n    assert i+\".tiff\" in files\nprint(\"all training image_ids have their files in train_images folder\")","b683ac1c":"slide = openslide.OpenSlide(PATH+\"train_images\/\"+files[105])\nspacing = 1 \/ (float(slide.properties['tiff.XResolution']) \/ 10000)\nprint(f\"File id: {slide}\")\nprint(f\"Dimensions: {slide.dimensions}\")\nprint(f\"Microns per pixel \/ pixel spacing: {spacing:.3f}\")\nprint(f\"Number of levels in the image: {slide.level_count}\")\nprint(f\"Downsample factor per level: {slide.level_downsamples}\")\nprint(f\"Dimensions of levels: {slide.level_dimensions}\")\npatch = slide.read_region((1780,1950), 0, (256, 256))\ndisplay(patch) \nslide.close()","31f8322d":"import time\nstart_time = time.time()\nslide_dimensions, spacings, level_counts = [], [], []\ndown_levels, level_dims = [], []\n\nfor image_id in train_df.image_id:\n    image = str(image_id)+'.tiff'\n    image_path = os.path.join(PATH,\"train_images\",image)\n    slide = openslide.OpenSlide(image_path)\n    spacing = 1 \/ (float(slide.properties['tiff.XResolution']) \/ 10000)\n    slide_dimensions.append(slide.dimensions)\n    spacings.append(spacing)\n    level_counts.append(slide.level_count)\n    down_levels.append(slide.level_downsamples)\n    level_dims.append(slide.level_dimensions)\n    slide.close()\n    del slide\n\n\nend_time = time.time()\nprint(f\"Total processing time: {round(end_time - start_time,2)} sec.\")","49eba8d9":"train_df['width']  = [i[0] for i in slide_dimensions]\ntrain_df['height'] = [i[1] for i in slide_dimensions]\ntrain_df['spacing'] = spacings\ntrain_df['level_count'] = level_counts","5b4902b8":"train_df","985fc782":"fig = plt.figure(figsize=(18,10))\nax = sns.scatterplot(x='width', y='height', data=train_df, alpha=0.3)\nplt.title(\"height(y) width(x) scatter plot\")\nplt.show()","dfd2bc6a":"fig = plt.figure(figsize=(18,10))\nax = sns.scatterplot(x='width', y='height', hue='isup_grade', data=train_df, alpha=0.6)\nplt.title(\"height(y) width(x) scatter plot with target\")\nplt.show()","7e77c4d2":"fig, ax = plt.subplots(nrows=1,figsize=(18,10)) \nsns.distplot(train_df['width'], kde=True, label='width')\nsns.distplot(train_df['height'], kde=True, label='height')\nplt.xlabel('dimension')\nplt.title('Images Width and Height distribution')\nplt.legend()\nplt.show()","e5bbddf8":"def plot_distribution_grouped(feature, feature_group, hist_flag=True):\n    fig, ax = plt.subplots(nrows=1,figsize=(18,10)) \n    for f in train_df[feature_group].unique():\n        df = train_df.loc[train_df[feature_group] == f]\n        sns.distplot(df[feature], hist=hist_flag, label=f)\n    plt.title(f'Images {feature} distribution, grouped by {feature_group}')\n    plt.legend()\n    plt.show()","057a025c":"plot_distribution_grouped('width', 'data_provider')","0f9a218e":"plot_distribution_grouped('height', 'data_provider')","21202b6d":"plot_distribution_grouped('width', 'isup_grade', False)","4fcf0fdf":"plot_distribution_grouped('height', 'isup_grade', False)","7c447c80":"plot_distribution_grouped('width', 'gleason_score', False)","2a65f0d3":"plot_distribution_grouped('height', 'gleason_score', False)","d7a9df2c":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,10))\nsns.distplot(ax=ax1, a=train_df['width'])\nax1.set_title(\"width distribution\")\nsns.distplot(ax=ax2, a=train_df['height'])\nax2.set_title(\"height distribution\")\nplt.show()","4e7fdcd3":"shapes = [j for i in level_dims for j in i]\nlevel  = np.array([j for i in level_dims for j in range(len(i))])\nwidths  = np.array([i[0] for i in shapes])\nheights = np.array([i[1] for i in shapes])\nfig, axes = plt.subplots(1, 3 ,figsize=(18,10))\nfor i in range(3):\n    ax = sns.scatterplot(ax=axes[i], x=widths[level==i], y=heights[level==i], alpha=0.9)\n    axes[i].set_title(f\"Level {i}\")\nplt.tight_layout()\nplt.show()\n\nfig = plt.figure(figsize=(18,10))\nsns.scatterplot(x=widths, y=heights,hue=level, alpha=0.9)\nplt.show()","e9814115":"### Width vs ISUP Grade","cb53c7fc":"The above plot clearly illustrates that the data is imbalanced with respect of **Gleason Score** values distribution.","1194395d":"![what-is-a-PSA-test_745x510_njaecd.jpg](attachment:what-is-a-PSA-test_745x510_njaecd.jpg)","bde71d65":"* Most of the 0 & 1 ISUP Grade samples are originated from Karolinska.\n* Most of the 2-5 ISUP Grade samples are originated from Radboud.","10196bbd":"## Let's see the **Characterstics** on a Single image slide!","a8f8f32a":"We will write a function that will take each image name and then combine it with the image path and displays the images.","2b4e533a":"We have succesfully added the width,height,spacing and level_count!","d8bc97d7":"### Using OpenSlide to load the data\n\nIn the following sections we will load data from the slides with OpenSlide. The benefit of OpenSlide is that we can load arbitrary regions of the slide, without loading the whole image in memory. Want to interactively view a slide? We have added an interactive viewer to this notebook in the last section.\n\nYou can read more about the OpenSlide python bindings in the documentation: https:\/\/openslide.org\/api\/python\/","340bafee":"Let's do a little analysis on the **ISUP grade**","47ccdac1":"[**Radboud University Medical Center**](http:\/\/www.radboudumc.nl\/en\/research) and [**Karolinska Institute** ](http:\/\/ki.se\/en\/meb)are the two data providers as well as the organisers of the competition.\n","37dea3f9":"This can also be illustrated using a heat-map! Looks really awesome!","d0cd7e9f":"Let's create a function that can create visuals by taking the features as input","f6e8355b":"# References\n\n* [PANDA Challenge Starting EDA](http:\/\/www.kaggle.com\/gpreda\/panda-challenge-starting-eda)\n* [PANDA - EDA + Better Visualization+Simple Baseline](http:\/\/www.kaggle.com\/rohitsingh9990\/panda-eda-better-visualization-simple-baseline)\n","af90af77":"#### Let's Do a lite Analysis on the Gleason_Score","f8dd5e0f":"### Let's Visualise the Levels!","ae2fd196":"### BokehJS\n\nBokehJS is the in-browser client-side runtime library that users of Bokeh ultimately interact with. This library is written primarily in TypeScript and is one of the unique things about the Bokeh plotting system.\n\n","5d3a9cbd":"We can use Matplotlib, Seaborn, Plotly etc. to generate great visualisations but let's also give BokehJS a try!!\n\n**Install BokehJS with Pip, if you don't have it!**","78fbbac4":"![Screen%20Shot%202020-04-08%20at%202.03.53%20PM.png](attachment:Screen%20Shot%202020-04-08%20at%202.03.53%20PM.png)","8553ef02":"# Contents\n1. [Understanding Data Files](#p1)\n2. [Loading Required Packages](#p2)\n3. [Load Data](#p3)\n4. [Check for Missing Values](#p4)\n5. [Exploratory Data Analysis](#p5)\n6. [Images of Microscopy Scans of Prostate Biopsy Samples](#p6)\n7. [Visualise the Label Masks](#p7)\n8. [Overlaying Masks on the Slides](#p8)\n9. [Analysis on the Imgae Characterstics](#p9)\n10. [Conclusion](#p10)\n11. [References](#p11)","9c52af35":"Running the cell below loads **seven** example biopsies using OpenSlide. \n\n**Some things you can notice:**\n\n* The image dimensions are quite large (typically between 5.000 and 40.000 pixels in both x and y).\n* Each slide has 3 levels you can load, corresponding to a downsampling of 1, 4 and 16. Intermediate levels can be created   by downsampling a higher resolution level.\n* The dimensions of each level differ based on the dimensions of the original image.\n* Biopsies can be in different rotations. This rotation has no clinical value, and is only dependent on how the biopsy was   collected in the lab.\n* There are noticable color differences between the biopsies, this is very common within pathology and is caused by different laboratory procedures.","1f005c66":"## Overlaying Masks on the Slides\n\nAs the masks have the same dimension as the slides, we can overlay the masks on the tissue to directly see which areas are cancerous. This overlay can help you identifying the different growth patterns. To do this, we load both the mask and the biopsy and merge them using PIL.","ca55bbf5":"> **Note:** In the example below you can also observe a few pen markings on the slide (**Dark green patches**). \nThese markings are not part of the tissue but were made by the pathologists who originally checked this case. These pen markings are available on some slides in the training set.","68c02c15":"#### Now' let us look at how the Gleason Score is distributed bas on the two data sources","460259e2":"### Width vs Data Provider","6180254e":"# Understanding Data Files\n\nLet's look at the data files given and understand what data they have and what they represent.","64efd4ac":"# Conclusion\n\nThat's it! We reached the end of our exercise. We saw how we can do a simple exploratory data analysis that gives us great insights!!\n\nIf you liked the Kernal then don't forget to hit the Upvote! :) Also, Suggestion are always Welcomed! \n\nPost your Doubts and Suggestions on the Comment Section.","97a3060e":"Let's start with checking the distribution of **data_provider**,**isup_grade** and **gleason_score** in the training data (train_df).\n\nWe are gonna see the count of the data providers!","4371f1a0":"In the output we can see the metadata like the File id, Dimensions, Microns per pixel etc.","a44060b3":"> Warning!! - While you run the below code, Don't think your kernel isn't responding!! This takes a little time!","7d821bef":"# Check for Missing Data\n\nLet's check for the missing values in the data. For this, we will remove the suffix and extension from label masks and will remove the extension from image list.","a0c763a0":"# Exploratory Data Analysis","d1d1d56b":"The above graph illustrates that majority of data samples in training set have ISUP grade values 0 or 1 (total > 50%) and the rest of the data samples have associated ISUP grades from 2 to 5 with all ranging in the 11-12% each.","9f6da74a":"# Load all the Data Files","0b8e901e":"### Height vs ISUP Grade","18e8e12b":"**[train\/test].csv**\n\n* **image_id:** ID code for the image.\n\n* **data_provider**: The name of the institution that provided the data. Both the Karolinska Institute and Radboud University Medical Center contributed data. They used different scanners with slightly different maximum microscope resolutions and worked with different pathologists for labeling their images.\n\n* **isup_grade:** Train only. The target variable. The severity of the cancer on a 0-5 scale.\n\n* **gleason_score:** Train only. An alternate cancer severity rating system with more levels than the ISUP scale. For details on how the gleason and ISUP systems compare, see the Additional Resources tab.\n\n**[train\/test]_images: ** The images. Each is a large multi-level tiff file. You can expect roughly 1,000 images in the hidden test set. Note that slightly different procedures were in place for the images used in the test set than the training set. Some of the training set images have stray pen marks on them, but the test set slides are free of pen marks.\n\n* **train_label_masks**: Segmentation masks showing which parts of the image led to the ISUP grade. Not all training images have label masks, and there may be false positives or false negatives in the label masks for a variety of reasons. These masks are provided to assist with the development of strategies for selecting the most useful subsamples of the images. The mask values depend on the data provider:\n\n* **Radboud:** Prostate glands are individually labelled. Valid values are:\n\n    0: background (non tissue) or unknown\n    1: stroma (connective tissue, non-epithelium tissue)\n    2: healthy (benign) epithelium\n    3: cancerous epithelium (Gleason 3)\n    4: cancerous epithelium (Gleason 4)\n    5: cancerous epithelium (Gleason 5)\n\n* **Karolinska:** Regions are labelled. Valid values are:\n\n    1: background (non tissue) or unknown\n    2: benign tissue (stroma and epithelium combined)\n    3: cancerous tissue (stroma and epithelium combined)\n\n* **sample_submission.csv**: A valid submission file. This is a notebooks-only competition; the downloadable test.csv and sample_submission.csv have been truncated. The full versions will be available to your submitted notebooks.","62086761":"#### Now, that we have done a some good amount of exploration on the data files, let's look ta the Image Files","f9437b8d":"#### Let's try to read a single patch! By giving the name of the file","4a30a64b":"* We can observe that all of the 0+0 Gleason score data samples are from Karolinska while from Radboud we have most of negative data.\n\n* For Karolinska, next (in terms of frequency) are samples with Gleason score 3+3, 3+4, 4+4.\n\n* For Radboud, next (in terms of frequency) most frequent are samples with Gleason score 4+3, 3+3, 3+4, 4+4, 4+5.\n\n* Let's see how ISUP grade is distributed with respect of Data provider.","28cc3b6b":"# Load Required Packages","efd2f3e1":"# Analysis on the Image Characterstics","8673d88a":"#### Let's look at the Columns of each dataframes","e8483d66":"# Prostate cANcer graDe Assessment (PANDA) Challenge\n**Prostate cancer diagnosis using the Gleason grading system**","d44d4fc3":"### Height vs Data Provider","b604a03f":"### Let's create a Scatter Plot for Height and Width!!","424eb177":"With more than 1 million new diagnoses reported every year, prostate cancer (PCa) is the second most common cancer among males worldwide that results in more than 350,000 deaths annually. The key to decreasing mortality is developing more precise diagnostics. Diagnosis of PCa is based on the grading of prostate tissue biopsies. These tissue samples are examined by a pathologist and scored according to the Gleason grading system.\n\nThe grading process consists of finding and classifying cancer tissue into so-called Gleason patterns (3, 4, or 5) based on the architectural growth patterns of the tumor (Fig. 1). After the biopsy is assigned a Gleason score, it is converted into an ISUP grade on a 1-5 scale.","5313b6ac":"The cardnality of both the intersections is equal with the data dimmensions. That means there is **No Missing Data!!!**:\n\nAll images indexed in train data has corresponding tiff images and tiff label masks.","ae8ffa61":"### Height vs Gleason Score","0906ecad":"Test and Sample Submission .csv files have only 3 rows (samples).\n\nThe column **(gleason_score)** is only present in train data, that is not present either in test (with image_id & data_provider) or in sample submission (image_id & isup_grade) csv.\n\nThe goal is to predict **isup_grade** for each image in test set.\n\nLet's check now the train data in train_images and train_label masks folders.","2ea9dd42":"Hi Kagglers!! We are here again with another amazing competition! \n\nIn this notebook, let us try and explore the data given for **Prostate cANcer graDe Assessment (PANDA) Challenge**. Before we dive deep into the data, let us know a little more about the competition.","0d9295c5":"### Width vs Gleason Score","4e406580":"## Visualise the Label Masks","62b65bfb":"In 2012, the [International Society of Urologic Pathologists (ISUP)](http:\/\/isupweb.org\/isup\/) proposed a novel, validated grading system for clear cell renal cell carcinoma (ccRCC) and papillary renal cell carcinoma (pRCC) that has been implemented by the World Health Organization (WHO).This system is based primarily on the nucleoli assessment of the tumors, as follows [1]:\n\n* Grade 1: Inconspicuous nucleoli at \u00d7400 magnification and basophilic\n* Grade 2: Clearly visible nucleoli at \u00d7400 magnification and eosinophilic\n* Grade 3: Clearly visible nucleoli at \u00d7100 magnification\n* Grade 4: Extreme pleomorphism or rhabdoid and\/or sarcomatoid morphology\n","1f0c8bca":"### Height and Width Distribution Side-by-Side!","d4be8400":"#### Visualizing masks (using matplotlib)\n\nGiven that the masks are just integer matrices, you can also use other packages to display the masks. For example, using matplotlib and a custom color map we can quickly visualize the different cancer regions:","ef1a7192":"# Images of Microscopy Scans of Prostate Biopsy Samples","69a7f45f":"Now, we will compare the intersections of sets of resulted lists.","d91a0045":"## Let's load all Characterstics for all the images ","c6b9b09d":"### More analysis on the distribution of the Height and Width","870c8b64":"#### Discussion:\n\n* All exams with ISUP grade = 0 have Gleason score 0+0 or negative.\n* All exams with ISUP grade = 1 have Gleason score 3+3.\n* All exams with ISUP grade = 2 have Gleason score 3+4.\n* All exams with ISUP grade = 3 have Gleason score 4+3.\n* All exams with ISUP grade = 4 have Gleason score 4+4 (majority), 3+5 or 5+3.\n* All exams with ISUP grade = 5 have Gleason score 4+5 (majority), 5+4 or 5+5.","86952a2a":"#### Let's now do a collective exploration on the distribution of **ISUP Grade** and **Gleason Score** Values.","1bcfe295":"**I hope you find this notebook useful and your <font color=\"red\"><b>UPVOTES<\/b><\/font> would be very much appreciated. It helps me keep Motivated :)**","1b37b2d0":"We can also, create a small function, that will give us the meta data about the slides!"}}