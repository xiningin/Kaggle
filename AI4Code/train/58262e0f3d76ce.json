{"cell_type":{"b99b6cac":"code","5b6c53b7":"code","f77032b7":"code","8cb89187":"code","3ab3137e":"code","b76fb8ad":"code","5af552f6":"code","f994b174":"code","d19cf5dc":"code","1d857d8b":"code","7bd605c0":"code","6c3ca694":"code","3f4af78b":"code","4ac851e5":"code","265e0000":"code","bd37869f":"code","f633cb75":"code","ef3a780b":"code","bc97983c":"code","cda5509b":"code","d86b8bee":"code","080bc1c9":"code","07cb80b6":"code","10fe99fa":"code","a8084b1c":"code","3be9b4ca":"code","9b426253":"code","a83cf833":"code","472ebb33":"code","8ccafb78":"code","8baf8a31":"code","6c26fdb3":"code","93045ccc":"code","1e6d20aa":"code","165ee540":"code","ff759070":"code","aa3ffd0e":"code","a3807a01":"code","7edc90ea":"code","4304fc7f":"markdown","d0f2c54e":"markdown","21fcbdc8":"markdown","7d4915e5":"markdown","4ea6f341":"markdown","b54ae07f":"markdown","eb1d4118":"markdown","f31e80d0":"markdown","74d2918e":"markdown","345cdd64":"markdown","ff4cb405":"markdown","0b91fd3d":"markdown","19f9b0cf":"markdown","4e4f155d":"markdown","999460d5":"markdown","55bb421a":"markdown","8d77f605":"markdown","55d456bf":"markdown","85d1c5a3":"markdown","cb7835e7":"markdown","36f33911":"markdown","9573f87b":"markdown","3acd1d98":"markdown","9449d38d":"markdown","91e1fa9c":"markdown","27b1cf9c":"markdown","060ec9be":"markdown"},"source":{"b99b6cac":"!pip install -q plotnine   \nfrom plotnine import *\n%matplotlib inline\n\nimport pandas as pd\nimport numpy as np","5b6c53b7":"df_wine = pd.read_csv('..\/input\/winequality-red.csv') ","f77032b7":"df_wine.head()","8cb89187":"import seaborn as sns\ncolor = sns.color_palette()\n\nimport matplotlib.pyplot as plt\nsns.set(style=\"white\")","3ab3137e":"# Calculate the correlation\ncorr= df_wine.corr()\ncorr","b76fb8ad":"# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","5af552f6":"df_wine.drop([\"residual sugar\",'free sulfur dioxide','pH'],axis = 1,inplace = True)","f994b174":"df_wine.head()","d19cf5dc":"sns.distplot(df_wine['quality'])\nplt.show()","1d857d8b":"# Bin \"quality\" variable into three levels: poor, normal and excellent\n\nbins = [0, 4, 6, 10]\nlabels = [\"poor\",\"normal\",\"excellent\"]\ndf_wine['binned_quality'] = pd.cut(df_wine['quality'], bins=bins, labels=labels)\ndf_wine.head()\ndf_wine.drop('quality',axis =1, inplace = True)","7bd605c0":"sns.distplot(df_wine['alcohol'])\nplt.show()","6c3ca694":"# Bin \"alcohol\" variable into three levels: low, median and high\n\nbins = [0, 10, 12, 15]\nlabels = [\"low alcohol\",\"median alcohol\",\"high alcohol\"]\ndf_wine['binned_alcohol'] = pd.cut(df_wine['alcohol'], bins=bins, labels=labels)\ndf_wine.drop('alcohol',axis =1, inplace = True)","3f4af78b":"df_wine.head()","4ac851e5":"sns_plot = sns.pairplot(df_wine, hue=\"binned_quality\", palette=\"husl\",\n             diag_kind=\"kde\")\nsns_plot.savefig(\"pairplot.png\")","265e0000":"(ggplot(df_wine, aes('citric acid', 'volatile acidity', color = 'binned_alcohol',\n                          size = 'binned_alcohol',\n                          shape = 'binned_alcohol'))\n + geom_point(alpha=0.3)\n + facet_wrap(\"binned_quality\",ncol =1)\n + theme_xkcd())","bd37869f":" (\n    ggplot(df_wine) +\n    geom_violin(\n        aes(x = 'binned_quality',\n            y = 'volatile acidity')) +\n    labs(\n        title ='Distribution of volatile acidity by quality',\n        x = 'wine quality',\n        y = 'volatile acidity',\n    ))","f633cb75":"(\n    ggplot(df_wine) +\n    geom_boxplot(\n        aes(x = 'binned_quality',\n            y = 'citric acid')\n    ) +\n    labs(\n        title ='Distribution of citric acid by quality',\n        x = 'wine quality',\n        y = 'citric acid',\n    ) \n)","ef3a780b":"# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score","bc97983c":"df_wine_ml = df_wine.copy()\ndf_wine_ml.info()","cda5509b":"#get dummies\ndf_wine_ml = pd.get_dummies(df_wine_ml, columns=[\"binned_alcohol\"], drop_first=True)\ndf_wine_ml.head()","d86b8bee":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nscaler.fit(df_wine_ml.drop('binned_quality',axis=1))\nscaled_features = scaler.transform(df_wine_ml.drop('binned_quality',axis=1))\ndf_wine_ml_sc = pd.DataFrame(scaled_features, columns=df_wine_ml.columns.difference(['binned_quality']))","080bc1c9":"# use 70% of the data for training and 30% for testing\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df_wine_ml.drop( \"binned_quality\",axis=1), df_wine_ml[\"binned_quality\"], test_size=0.30, random_state=101)\nX_train_sc, X_test_sc, y_train_sc, y_test_sc = train_test_split(df_wine_ml_sc, df_wine_ml[\"binned_quality\"], test_size=0.30, random_state=101)","07cb80b6":"# unscaled\nX_train_all = df_wine_ml.drop(\"binned_quality\",axis=1)\ny_train_all = df_wine_ml[\"binned_quality\"]\n\n\n# scaled\nX_train_all_sc = df_wine_ml_sc\ny_train_all_sc = df_wine_ml[\"binned_quality\"]\n","10fe99fa":"logreg = LogisticRegression()\nlogreg.fit(X_train,y_train)\npred_logreg = logreg.predict(X_test)\nprint(accuracy_score(y_test, pred_logreg))","a8084b1c":"logreg.coef_","3be9b4ca":"gnb=GaussianNB()\ngnb.fit(X_train,y_train)\npred_gnb = gnb.predict(X_test)\nprint(accuracy_score(y_test, pred_gnb))","9b426253":"knn = KNeighborsClassifier(n_neighbors=20)\nknn.fit(X_train_sc,y_train_sc)\npred_knn = knn.predict(X_test)\nprint(accuracy_score(y_test, pred_knn))","a83cf833":"dtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)\npred_dtree = dtree.predict(X_test)\nprint(accuracy_score(y_test, pred_dtree))","472ebb33":"dtree_2 = DecisionTreeClassifier(max_features=7 , max_depth=6,  min_samples_split=8)\ndtree_2.fit(X_train,y_train)\npred_dtree_2 = dtree_2.predict(X_test)\nprint(accuracy_score(y_test, pred_dtree_2))","8ccafb78":"rfc = RandomForestClassifier(max_depth=6, max_features=7)\nrfc.fit(X_train, y_train)\npred_rfc = rfc.predict(X_test)\nprint(accuracy_score(y_test, pred_rfc))","8baf8a31":"# feature importance\nimportances = pd.DataFrame({'feature':X_train.columns,\n                            'importance':np.round(rfc.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances.head(15)","6c26fdb3":"svc = SVC(gamma = 0.01, C = 100, probability=True)\nsvc.fit(X_train_sc, y_train_sc)\npred_svc = svc.predict(X_test_sc)\nprint(accuracy_score(y_test_sc, pred_svc))","93045ccc":"scores_logreg = cross_val_score(logreg, X_train_all_sc, y_train_all_sc, cv=10, scoring='accuracy')\nprint(scores_logreg)\nprint(scores_logreg.mean())","1e6d20aa":"scores_knn = cross_val_score(knn, X_train_all_sc, y_train_all_sc, cv=10, scoring='accuracy')\nprint(scores_knn)\nprint(scores_knn.mean())","165ee540":"scores_svc = cross_val_score(svc, X_train_all_sc, y_train_all_sc, cv=10, scoring='accuracy')\nprint(scores_svc)\nprint(scores_svc.mean())","ff759070":"scores_rfc = cross_val_score(rfc, X_train_all_sc, y_train_all_sc, cv=10, scoring='accuracy')\nprint(scores_rfc)\nprint(scores_rfc.mean())","aa3ffd0e":"df= pd.DataFrame(y_test_sc)\ndf['binned_quality'].value_counts()","a3807a01":"from sklearn.metrics import confusion_matrix\n# creating a confusion matrix \ncm = confusion_matrix(y_test_sc, pred_svc) \ncm","7edc90ea":"names = [\"excellent\",\"normal\",\"poor\"]\ndf = pd.DataFrame(cm, index=names, columns=names)\ndf","4304fc7f":"### 6. SVM","d0f2c54e":"### Seaborn: pairplot","21fcbdc8":"Based on the heatmap above, except for \"residual sugar\", 'free sulfur dioxide' and 'pH', other variables seem to have some relationships with \u201cquality\u201d.","7d4915e5":" **For SVM:**","4ea6f341":"### 3. kNN","b54ae07f":"Based on k fold cross-validation, SVM(Support vector machine) has the best performance. ","eb1d4118":"### 1. Logistic Regression","f31e80d0":"### train_test_split","74d2918e":"***Overview ***\n\nThis project mainly explores the relationship between red wine quality with wine\u2019s physicochemical and sensory variables (1 - fixed acidity; 2 - volatile acidity; 3 - citric acid; 4 - residual sugar; 5 \u2013 chlorides; 6 - free sulfur dioxide; 7 - total sulfur dioxide; 8 \u2013 density; 9 \u2013 pH; 10 \u2013 sulphates; 11 - alcohol Output variable). In addition, EDA(seaborn and ggplot) and multiple machine learning algorithms are used to determine which physiochemical properties have impact on a wine\u2019s quality.\n","345cdd64":"# ML algorithms and model comparison","ff4cb405":"Among 6 algorithms above, logistic regression, kNN, SVM and random forest have the highest accuracy rate. Thus, K fold cross-validation is used here to further estimate model accuracy.","0b91fd3d":"### ggplot: Faceted plot, Violin boxplot and Generic boxplot","19f9b0cf":"Arbitrary cutoffs are set for the dependent variable (wine quality) and independent variable (alcohol) based on their distributions in order to facilitate the further analysis.  ","4e4f155d":"However, what we should not ignore is that the wine quality classes are ordered and **not balanced** (e.g. there are much more normal wines than excellent or poor ones). Consequently, as we can see from the confusion matrix above, the predictive ability of the model for normal class(accuracy rate = 0.966) is much better than poor(accuracy rate = 0) and excellent class(accuracy rate = 0.265). \n\nFor the next step, we should try to find out methods to improve the model performance for unbalanced dataset. ","999460d5":"### 4. Decision Tree","55bb421a":"### Seaborn: Correlation Heatmap","8d77f605":"# Exploratory Data Analysis","55d456bf":"**For rfc:**","85d1c5a3":"### Confusion matrix, without normalization for SVM","cb7835e7":"## K fold cross-validation","36f33911":"### 2. Gaussian Naive Bayes\u00b6","9573f87b":"### 5. Random Forest","3acd1d98":"Based on the three plots below, we can conclude that compared with poor quality level, excellent quality level has higher proportion of high alcohol wine; on average, higher level the wine quality, lower the volatile acidity and higher the citric acid.","9449d38d":"According to the pairplot above, \"volatile acidity\" and \"citric acid\" are two variables whose distributions are rather distinguishable among three-level quality.","91e1fa9c":"**For knn:**","27b1cf9c":"### sklearn StandardScaler","060ec9be":"**For logistic regression:**"}}