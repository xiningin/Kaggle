{"cell_type":{"f9ec1463":"code","9eabe6a7":"code","7abb5486":"code","fb5f0a7a":"code","e1a47eaa":"code","6640dd7a":"code","ea7d2977":"code","63fb52ab":"code","23cd0650":"code","ac83e0c1":"code","179c4f2e":"code","c0b88c4f":"code","6c908f2e":"code","6f337b5a":"code","62962017":"code","98868c52":"code","8213dcb3":"code","5d0829e2":"code","ce4e2800":"code","927fdc5a":"code","c747abec":"code","e7e718db":"code","aff76d39":"markdown","a71c8d70":"markdown","bdcc3b12":"markdown","13f860d8":"markdown","3ff5464c":"markdown","0912d748":"markdown","5627bea3":"markdown","6b0e72f7":"markdown","291c8ae2":"markdown","3cbc9c07":"markdown","67c21438":"markdown","20105cee":"markdown","2400baa3":"markdown","192f9244":"markdown","f4734f33":"markdown","035d06b5":"markdown","daff13b3":"markdown","1547723d":"markdown","962c4b90":"markdown","556c1ca7":"markdown","2c03a209":"markdown","97698f94":"markdown","170501f4":"markdown","8942a893":"markdown","b892ad4c":"markdown"},"source":{"f9ec1463":"from IPython.display import Image\nImage(\"..\/input\/mnistimages\/1.png\")","9eabe6a7":"Image(\"..\/input\/mnistimages\/MnistExamples.png\")","7abb5486":"# importing tensorflow and keras\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.utils import to_categorical, plot_model","fb5f0a7a":"# Printing version of the TensorFlow\n\nprint(tf.__version__)","e1a47eaa":"# Loading the dataset\n\nmnist=keras.datasets.mnist # Loading the dataset\n\n(xtrain,ytrain),(xtest,ytest)= mnist.load_data()\n\nprint(xtrain.shape)\nprint(ytrain.shape)\nprint(xtest.shape)\nprint(ytest.shape)\nprint(ytrain)\n\n# see the size of the dataset\n# print(\"Train Images Shape: %s \\nTrain Labels: %s \\nTest Images Shape: %s \\nTest Labels: %s\"  % (xtrain.shape, xtrain,xtest.shape,ytest))\n","6640dd7a":"# Defining array. Each item of array represent integer value of labels. 10 clothing item for 10 integer label.\n\nclass_names =['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\nprint(class_names)","ea7d2977":"# inspect the data in the array\n\nindex=0 # change this number \nplt.imshow(xtrain[index], cmap=plt.cm.binary) # printing 10th image. You may use cmap='gray'\nplt.colorbar() # shows the bar on the right side of the image\nplt.grid(True) # will shot the grid\nplt.show()\nprint(\"Class ID: %s and Class name: %s\" % (ytrain[index], class_names[ytrain[index]]))","63fb52ab":"# display the first 25 images from traing set\n\nplt.figure(figsize=(10,10))\nfor i in range(25): # 25 images\n  plt.subplot(5,5,i+1) # matrix of 5 X 5 array\n  plt.xticks([])\n  plt.yticks([])\n  plt.grid(False)\n  plt.imshow(xtrain[i], cmap=plt.cm.binary) # printing binary\/black and white image\n  plt.xlabel(\"%s %s\" % (ytrain[i], class_names[ytrain[i]])) # Assigning name to each image\nplt.show()","23cd0650":"# Pixel value of the image falls between 0 to 255.\n\nxtrain = xtrain\/255 # So, we are scale the value between 0 to 1 before by deviding each value by 255\nprint(xtrain.shape)\n\nxtest = xtest\/255 # So, we are scale the value between 0 to 1 before by deviding each value by 255\nprint(xtest.shape)","ac83e0c1":"# One hot encoding of the labels.\n#(generally we do one hot encoding of the features in EDA but in this case we are doing it for labels)\n\n# Before one hot encoding\nprint(\"ytrain Shape: %s and value: %s\" % (ytrain.shape, ytrain))\nprint(\"ytest Shape: %s and value: %s\" % (ytest.shape, ytest))\n\nytrain=to_categorical(ytrain)\nytest=to_categorical(ytest)\n\n# After one hot encoding\nprint(\"ytrain Shape: %s and value: %s\" % (ytrain.shape, ytrain[0]))\nprint(\"ytest Shape: %s and value: %s\" % (ytest.shape, ytest[1]))","179c4f2e":"from IPython.display import Image\nImage(\"..\/input\/mnistimages\/2.png\")","c0b88c4f":"# Modelling - Model on CNN\n\nfrom tensorflow.keras import models, layers\n\n# create a sequential model i.e. empty neural network which has no layers in it.\nmodel=models.Sequential()\n\n#==================== Feature Detection \/ extraction Block ====================#\n\n# Add first convolutional block - To deal with images we use Conv2D and for colour images and shape use Conv3D\n#model.add(layers.Conv2D(filters=6, kernal_size(3,3), input_shape=(28,28,1), activation='relu'))\n# in the first block we need to mention input_shape\nmodel.add(layers.Conv2D(6,(3,3),input_shape=(28,28,1),activation='relu'))\n# Add the max pooling layer\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\n\n# Add Second convolutional block\n#model.add(layers.Conv2D(filters=6, kernal_size(3,3), activation='relu'))\nmodel.add(layers.Conv2D(10,(3,3),activation='relu'))\n# Add the max pooling layer\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\n\n#==================== Transition Block (from feature detection to classification) ====================#\n\n# Add Flatten layer. Flatten simply converts matrics to array\nmodel.add(layers.Flatten(input_shape=(28,28))) # this will flatten the image and after this Classification happens\n\n#==================== Classification Block ====================#\n\n# Classification segment - fully connected network\n# The Dence layer does classification and is deep neural network. Dense layer always accept the array.\nmodel.add(layers.Dense(128, activation='relu')) # as C5 layer in above image. \nmodel.add(layers.Dense(100, activation='relu')) # as C5 layer in above image. \nmodel.add(layers.Dense(80, activation='relu')) # as C5 layer in above image. \n# this 120 is hyper parameter whcih is number of neuron \n#model.add(layers.Dense(84, activation='relu'))# as F6 layer in aboave image\n\n# Add the output layer\nmodel.add(layers.Dense(10, activation='softmax')) # as Output layer in above image. The output layer normally have softmax activation\n\n# Ploting the Model\nplot_model(model)","6c908f2e":"# Compile the model\n\n# if we use softmax activation in output layer then best fit optimizer is categorical_crossentropy\n# for sigmoid activation in output layer then loss will be binary_crossentropy\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n# if we do not go for One Hot Encoding then use loss='sparse_categorical_crossentropy'\n\nmodel.summary()","6f337b5a":"# Train the model \n# Using GPU really speeds up this code\nxtrain2=xtrain.reshape(60000,28,28,1)\nxtest2=xtest.reshape(10000,28,28,1)\n\n# print(xtrain.shape)\n# print(xtest.shape)\n# print(ytrain.shape)\n# print(ytest.shape)\n\nmodel.fit(xtrain2,ytrain,epochs=20,batch_size=1000,verbose=True,validation_data=(xtest2,ytest))","62962017":"# evaluate accuracy of the model\n\ntest_loss, test_acc = model.evaluate(xtest2, ytest)\nprint(\"accuracy:\", test_acc)","98868c52":"# predicting lable for test_images\n\npredictions=model.predict(xtest2)\n\n# Prediction of the 1st result. It will show the 10 predictions of labels for test image\nprint(\"1. Prediction array: %s\" % (predictions[0]))\n\n# we will verify that which result for label has highest confidence\nprint(\"2. Label number having highest confidence in prediction array: %s\" % (np.argmax(predictions[0])))\n\n# let us verify what is the label in test_labels.\nprint(\"3. Actual label in dataset: %s\" % (ytest[0]))","8213dcb3":"# creating a funtion which will help to verify the prediction is true of not\n\ndef plot_image(i, predictions_array, true_label, img): # taking index and 3 arrays viz. prediction array, true label array and image array\n  \n  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  \n  plt.imshow(img, cmap=plt.cm.binary) # showing b\/w image\n\n  predicted_label=np.argmax(predictions_array)\n  true_label=np.argmax(true_label)\n\n  # print(predicted_label)\n  # print(true_label)\n  \n  if predicted_label == true_label: #setting up label color\n    color='blue' # correct then blue colour\n    \n  else:\n    color='red' # wrong then red colour\n\n  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n                                       100*np.max(predictions_array),\n                                       class_names[true_label]),\n             color=color)\n  \n# function to display bar chart showing whether image prediction is how much correct  \ndef plot_value_array(i, predictions_array, true_label): # taking index along with predictions and true label array\n  predictions_array, true_label = predictions_array[i], true_label[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  thisplot=plt.bar(range(10), predictions_array, color='gray')\n  plt.ylim([0,1])\n  predicted_label=np.argmax(predictions_array)\n  true_label=np.argmax(true_label)\n\n  thisplot[predicted_label].set_color('red')\n  thisplot[true_label].set_color('green')","5d0829e2":"# call the function\n\n# defining parameters to pass to function\ni=12 # image number 56. You may change value of i for play around\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\n\nplot_image(i, predictions, ytest, xtest)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions, ytest)\nplt.show()","ce4e2800":"# call the function\n\n# defining parameters to pass to function\ni=7 # image number 5. You may change value of i for play around\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions, ytest, xtest)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions, ytest)\nplt.show()","927fdc5a":"# call the function\n\n# defining parameters to pass to function\ni=12 # image number 12. You may change value of i for play around\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions, ytest, xtest)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions, ytest)\nplt.show()","c747abec":"# verification our prediction on single image\n\ni=24 # image number 0. You may change value of i for play around\nimg = xtest2[i]\nprint(img.shape)\n\nimg=(np.expand_dims(img,0))\nprint(img.shape)\n\npredictions_single = model.predict(img)\nprint(predictions_single)\n\nplot_value_array(i, predictions,ytest)\n_ = plt.xticks(range(10), class_names,rotation=45)\n\nnp.argmax(predictions_single[0])","e7e718db":"# verification of several images\n\nnum_rows=6\nnum_cols=5\nnum_images=num_rows*num_cols\n\nplt.figure(figsize=(2*2*num_cols,2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(i,predictions, ytest, xtest)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(i, predictions, ytest)\nplt.show()","aff76d39":"# Evaluation of the model","a71c8d70":"## One hot encoding of the labels\n- This is NOT required in two-class classification problem\n- This is REQUIRED in multi-class classification problem\n- This is 10 class classification problem so after one hot encoding it will generate 10 columns i.e. 10 output nurons for each label","bdcc3b12":"# Evaluation of the data","13f860d8":"## Test for single image","3ff5464c":"## Predicting label","0912d748":"Reading the summary:\n- There are 5 computational layers i.e. all the layers where param value is non-zero that is why it is called LeNet-5.\n- Params are weights and bias\n- the value 60 = 6 filters X  kernal size 9 i.e.(3 X 3) = 54 + 6 bias (equal to number of filters) = 60\n- the value 550 = 10 filters X  kernal size 9 i.e.(3 X 3) = 90 X 6 filters of earliar layer = 540 + 10 bias (equal to number of filters) = 550\n- In case of Dense layer 30120 = 250 X 120 = 30,000 + 120 bias\n- In case of Dense layer 10164 = 120 X 84 = 10080 + 84 bias","5627bea3":"## Scaling the image values","6b0e72f7":"Observation:\n* there is a very little gap between accracy of train and test model i.e. 0.9881 and 0.9826 that means model is almost perfect... very little overfitting.","291c8ae2":"# Conclusions\n\n* With a complex sequential model with multiple convolution layers and 20 epochs for the training, we obtained an accuracy ~0.91 for test prediction. \n* After investigating the validation accuracy and loss, we understood that the model is overfitting.\n* Model may be retrained with Dropout layers to reduce overfitting.\n* Most of the images can be identified except few.","3cbc9c07":"# Testing the model on data","67c21438":"# Loading the Dataset","20105cee":"# Modelling - Model on CNN\n- There are 2 ways to program CNN with keras:\n  - Sequential approach: Here, we generally add layers in sequence.\n  - Modular approach: This is more important. This more dynamic, cusotmized, moulded and easy to explore. We generally use this.\n\nEffectiveness in both the approach will remain same.\n\nWe are creating this model based on lecun-99\nSource: http:\/\/yann.lecun.com\/exdb\/publis\/pdf\/lecun-99.pdf\n\n","2400baa3":"## Evaluating model accuracy","192f9244":"## Verifying several images","f4734f33":"Observation:\n* This means model shows most confidence about 1st test_image is 'Ankle boot' ('T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])\n* test_labels[0] also gives result as 9 (i.e. 'Ankle boot'). So, the prediction is correct. The data is one hot encoded so there is 1 at the last\n","035d06b5":"# Data Preparation","daff13b3":"## Compile the model","1547723d":"## Building model","962c4b90":"## Train the model","556c1ca7":"## Creating a function to verify prediction is True or False","2c03a209":"# Computer Vision: Image Classification of MNIST dataset using TensorFlow\n\n**Domain:**Image Identification \/ Classification\n\n**About:**\nThe MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning. It was created by \"re-mixing\" the samples from NIST's original datasets. The creators felt that since NIST's training dataset was taken from American Census Bureau employees, while the testing dataset was taken from American high school students, it was not well-suited for machine learning experiments. Furthermore, the black and white images from NIST were normalized to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels. \n\nThe MNIST database contains 60,000 training images and 10,000 testing images.Half of the training set and half of the test set were taken from NIST's training dataset, while the other half of the training set and the other half of the test set were taken from NIST's testing dataset.The original creators of the database keep a list of some of the methods tested on it.In their original paper, they use a support-vector machine to get an error rate of 0.8%. An extended dataset similar to MNIST called EMNIST has been published in 2017, which contains 240,000 training images, and 40,000 testing images of handwritten digits and characters.\n[Source: https:\/\/en.wikipedia.org\/wiki\/MNIST_database]\n\n**Problem Statement:** To predict correct label for each image given in test dataset.\n\nDescription text source: https:\/\/www.tensorflow.org\/datasets\/catalog\/mnist\n\nTo see image, visit: https:\/\/en.wikipedia.org\/wiki\/MNIST_database#\/media\/File:MnistExamples.png\n\n**We will use GPU for this notebook to speed up process.**\n","97698f94":"# Importing packages","170501f4":"## Test for single image","8942a893":"## Test for single image","b892ad4c":"Observations:\n* There are 60,000 images. We assigned 10,000 to test dataset\n* Images are black and white and is of 28 x 28 pixels\n* Train Images: Array of 60,000 images in 28 X 28 pixel\n* Train Labels: Integer array of 60,000 labels, value between 0 to 9\n* Test Images: Array of 10,000 images in 28 X 28 pixel\n* Test Labels: Integer array of 10,000 labels, value between 0 to 9\n* Each image mapped to a single label\n* Each integer value in label array represent clothing item"}}