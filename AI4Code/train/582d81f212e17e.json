{"cell_type":{"99322cae":"code","98d911c2":"code","dba6eabe":"code","b704e4ee":"code","168cb405":"code","0a897ac3":"code","5535d7d9":"code","d034f190":"code","a555309b":"code","f30e95b1":"code","063b86f9":"code","0e8802d6":"code","d11071bb":"code","3a5448a5":"code","5eb34bab":"code","54b57d61":"code","a5084caf":"code","254ad47b":"code","d870e731":"code","6d0e70a4":"code","8f9853b4":"code","5bac2cbd":"code","7771fb54":"markdown","ca365eaf":"markdown","264e63fd":"markdown","83da2490":"markdown","6347f3cd":"markdown","fb3fff34":"markdown","1e1aeccf":"markdown","5814f03e":"markdown","db76dcbc":"markdown","194ad92a":"markdown","b1206cff":"markdown","4f60288f":"markdown","abc52810":"markdown","7a29e0cf":"markdown"},"source":{"99322cae":"pip install grammarbot","98d911c2":"!nvidia-smi","dba6eabe":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport json\nimport pandas as pd\n\n# import the client library\nfrom grammarbot import GrammarBotClient\n\nimport spacy\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","b704e4ee":"client = GrammarBotClient()\n\nnlp = spacy.load(\"en_core_web_sm\") ","168cb405":"CLEAN_CSV_FILE = \"\/kaggle\/input\/stanford-plato-corpus\/clean.csv\"","0a897ac3":"df = pd.read_csv(CLEAN_CSV_FILE, index_col=0)\n\nBAD_COL = \"Unnamed: 0.1\"\nif BAD_COL in df.columns:\n    df = df.drop(BAD_COL, axis=1)\n\nBAD_COL = \"Unnamed: 0.1.1\"\nif BAD_COL in df.columns:\n    df = df.drop(BAD_COL, axis=1)\n\nBAD_COL = \"Unnamed: 0.1.1.1\"\nif BAD_COL in df.columns:\n    df = df.drop(BAD_COL, axis=1)\n\ndf.head(1)","5535d7d9":"# @LogDecorator()\n# def _json_file_to_dataframe(json_filename):\n#     with open(json_filename,'r') as json_file:\n#         json_dict = json.loads(json_file.read())\n    \n#     data = []\n#     for k, v in json_dict.items():\n#         data.append({\"json_filename\":json_filename, \"question\":k, \"summarized_answer\":v})\n#     return pd.DataFrame(data)\n\n# JSON_DIR = '\/kaggle\/input\/stanford-plato-corpus\/Questions from 20 docs\/Questions from 20 docs\/'\n\n# df = pd.concat(\n#     [\n#         _json_file_to_dataframe(jf) \n#         for jf in (os.path.join(JSON_DIR, jf) \n#          for jf in filter(\n#              lambda f: f.endswith(\".json\"), \n#              os.listdir(JSON_DIR)\n#          ))\n#     ]\n# )","d034f190":"df.shape","a555309b":"df.head()","f30e95b1":"\ndef _get_rule_1_data(question):\n    \"\"\"\n    Given a question\n    Return a grammar dictionary & and extra bit of data\n    \"\"\"\n    rj = client.check(question).raw_json\n    extra = [m.get(\"rule\", dict()).get(\"category\", dict()).get(\"id\", \"\") for m in rj[\"matches\"]]\n    return (rj, extra)\n\n\ndef _rule_1(question_data, qd_extra):\n    \"\"\"\n    Given a question_data && qd_extra\n    Return True\/False depending on the rule application\n        True means keep this question\n        False means forget-about-it\n    \"\"\"\n    if question_data[\"matches\"] == []:\n        # no grammar problems found\n        return True\n    elif \"TYPOGRAPHY\" in qd_extra:\n        # TYPOGRAPHY often means some whitespace issues for our questions\n        # that's okay, don't worry about it. \n        return True\n    else:\n        return False\n\n\ndef rule_1(question):\n    \"\"\"\n    Given question\n    Return a tuple (question_data, boolean_result_of_rule)\n    \"\"\"\n    qd, qd_extra = _get_rule_1_data(question)\n    res = _rule_1(qd, qd_extra)\n    return (qd, qd_extra, res)","063b86f9":"\ndef _get_rule_2_data(question):\n    \"\"\"\n    Given a question\n    Return a list of the found wh-words & an extra bit of data\n    \"\"\"\n    doc = nlp(question)\n    wh_words = []\n    for token in doc:\n        if token.tag_ in [\"WDT\",\"WP\", \"WP$\", \"WRB\"]:\n            wh_words.append({\"token\": token, \"tag\": token.tag_ })\n    return wh_words, None\n\n\ndef _rule_2(question_data):\n    \"\"\"\n    Given a question_data\n    Return True\/False depending on the rule application\n        True means keep this question\n        False means forget-about-it\n    \"\"\"\n    if len(question_data) <= 1:\n        return True\n    else:\n        return False\n\n\ndef rule_2(question):\n    \"\"\"\n    Given question\n    Return a tuple (question_data, boolean_result_of_rule)\n    \"\"\"\n    qd, _ = _get_rule_2_data(question)\n    res = _rule_2(qd)\n    return (qd, None, res)","0e8802d6":"\ndef _get_rule_3_data(question):\n    \"\"\"\n    Given a question\n    Return a list of the found wh-words & an extra bit of data\n    \"\"\"\n    doc = nlp(question)\n    ent_data = []\n    for ent in doc.ents:\n        ent_data.append(\n            {\n                \"text\": ent.text,\n                \"label\": ent.label_,\n            }\n        )\n    return ent_data, None\n\n\ndef _rule_3(question_data):\n    \"\"\"\n    Given a question_data\n    Return True\/False depending on the rule application\n        True means keep this question\n        False means forget-about-it\n    \"\"\"\n    if len(question_data) >= 1:\n        # if there exists at least 1 entity, then maybe prioritize such a question?\n        return True\n    else:\n        return False\n\n\ndef rule_3(question):\n    \"\"\"\n    Given question\n    Return a tuple (question_data, boolean_result_of_rule)\n    \"\"\"\n    qd, _ = _get_rule_3_data(question)\n    res = _rule_3(qd)\n    return (qd, None, res)","d11071bb":"# ques  = list()\n\n# rule1_data = list()\n# rule1_extra = list()\n# rule1_bools = list()\n\n# rule2_data = list()\n# rule2_extra = list()\n# rule2_bools = list()\n\n# rule3_data = list()\n# rule3_extra = list()\n# rule3_bools = list()\n\ni = 0\ndef _with_printouts(fn):\n    def _fn(*args, **kwargs):\n        global i\n        i += 1\n        tabs10 = \"\\t\"*10\n        tabs100 = \"\\t\"*100\n        print(f\"{i}{tabs10}{fn.__name__}{tabs10}{args}{tabs10}{kwargs}{tabs100}\", end=\"\\r\")\n        return fn(*args, **kwargs)\n    return _fn\n\n\nfun = _with_printouts(rule_1)\nrule_data_frame = df[\"question\"].apply(fun).apply(pd.Series)\nrule_data_frame.columns = [\"data_rule_1\", \"extra_rule_1\", \"bool_rule_1\"]\ndf = df.join(rule_data_frame, rsuffix=\"_rule_1\")\n\nfun = _with_printouts(rule_2)\nrule_data_frame = df[\"question\"].apply(fun).apply(pd.Series)\nrule_data_frame.columns = [\"data_rule_2\", \"extra_rule_2\", \"bool_rule_2\"]\ndf = df.join(rule_data_frame, rsuffix=\"_rule_2\")\n\nfun = _with_printouts(rule_3)\nrule_data_frame = df[\"question\"].apply(fun).apply(pd.Series)\nrule_data_frame.columns = [\"data_rule_3\", \"extra_rule_3\", \"bool_rule_3\"]\ndf = df.join(rule_data_frame, rsuffix=\"_rule_3\")\n\n\n# for question in json_dict.keys():\n#     ques.append(question)\n\n#     r1d, r1e, r1b = rule_1(question)\n#     rule1_data.append(r1d)\n#     rule1_extra.append(r1e)\n#     rule1_bools.append(r1b)\n\n#     r2d, r2e, r2b = rule_2(question)\n#     rule2_data.append(r2d)\n#     rule2_extra.append(r2e)\n#     rule2_bools.append(r2b)\n\n#     r3d, r3e, r3b = rule_3(question)\n#     rule3_data.append(r3d)\n#     rule3_extra.append(r3e)\n#     rule3_bools.append(r3b)","3a5448a5":"df","5eb34bab":"mask1 = df[\"bool_rule_1\"] & df[\"bool_rule_2\"] \nmask2 = df[\"bool_rule_1\"] & df[\"bool_rule_3\"] \nmask3 = df[\"bool_rule_2\"] & df[\"bool_rule_3\"] \n\nfiltered_df = df[ \n    # if any two bool rules agree with each other, keep it, else filter out\n    mask1 | mask2 | mask3 \n]","54b57d61":"df[\"extra_rule_1\"].astype(str).unique()\n\n# df[df[\"rule1_extra\"].astype(str).str.contains(\"TYPO\")][\"question\"].apply(print)\n# df[df[\"rule1_extra\"].astype(str).str.contains(\"TYPOGRAPHY\")][\"question\"].apply(print)\n# df[df[\"rule1_extra\"].astype(str).str.contains(\"GRAMMAR\")][\"question\"].apply(print)","a5084caf":"filtered_df","254ad47b":"filtered_max_25_per_article_df = filtered_df.groupby(\"title\").head(25)","d870e731":"filtered_max_25_per_article_df.groupby(\"title\").describe()","6d0e70a4":"df.to_csv(\"annotated.csv\")","8f9853b4":"filtered_df.to_csv(\"filtered.csv\")","5bac2cbd":"filtered_max_25_per_article_df.to_csv(\"filtered_max_25_per_article.csv\")","7771fb54":"## Check GPU","ca365eaf":"# Heuristics \/ Functions","264e63fd":"# Save the annotated CSV","83da2490":"## Heuristic 3 -- NER ??","6347f3cd":"# Apply The Heuristics","fb3fff34":"# Save the filtered_max_25_per_article_df CSV","1e1aeccf":"# Final Rule -- each article must have <= 25 questions","5814f03e":"## Heuristic 1 -- grammar check is good","db76dcbc":"## Heuristic 2 -- wh-words","194ad92a":"# Save the filtered CSV","b1206cff":"# Installs","4f60288f":"# Setup","abc52810":"### Setup for iterating over every json document","7a29e0cf":"# Imports"}}