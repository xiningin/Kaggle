{"cell_type":{"adccf9f3":"code","d474952d":"code","d1214c89":"code","8ade6adf":"code","77854b2a":"code","6d442c4e":"code","fb9bff8f":"code","61184aaf":"code","f62f6518":"code","bee4be27":"code","e7c90f05":"code","f35cacaa":"code","bf09038d":"code","7cbe71e7":"code","cc26a695":"code","1c22e684":"code","972804ce":"code","fb842ec8":"code","e0a6da40":"code","7b1cb80f":"code","5987ce3d":"code","f9e922f2":"code","81db71c4":"code","20c5ec7a":"code","1187d454":"code","d1a415af":"markdown","36e208ba":"markdown","b01886e7":"markdown","a2984566":"markdown","4bde6459":"markdown","db29187e":"markdown","0690edd9":"markdown","1ac0eb75":"markdown","864ae528":"markdown","75963280":"markdown","2bb8d81a":"markdown","5eef1c0b":"markdown","522780d2":"markdown"},"source":{"adccf9f3":"# import packages needed as a separate cell. It makes it easy to add and rerun in the future as you progress through the project.\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn import tree\nimport graphviz","d474952d":"# importing data sets from kernel \n\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","d1214c89":"# displaying shape of data and column names\n# as you can see the test data is missing the survival rate, which is what we need to eventually estimate on the test data\n\nprint(\"Train Shape:   \" + str(train.shape))\nprint(\"Test Shape:    \" + str(test.shape))\nprint(\"Train Columns: \" + str(train.columns))\nprint(\"Test Columns:  \" + str(test.columns))","8ade6adf":"# displaying the first five rows of the training data to see what is in each column\n\ntrain.head()","77854b2a":"# Pandas loc operator allows you to build a boolean script to see a filtered list from the data. \n# Here I am asking for a view of the training data where the Age column contains a null value (missing value). \n\n# In addition, I am using the sort_values modifier to sort by the family relationship attributes SibSp and Parch to see if these are useful in possibly filling the values \n\ntrain.loc[train['Age'].isna()].sort_values(['SibSp', 'Parch'],ascending=[False, False]).head()","6d442c4e":"ages = train.loc[~train['Age'].isna()].append(test.loc[~test['Age'].isna()], sort=False)\nages = ages[['Name','Age', 'Sex']]\nages.head()","fb9bff8f":"def groupby_age_sex(row):\n    if 'Mr.' in row['Name']:\n        return 0\n    elif 'Master.' in row['Name']:\n        return 1\n    elif 'Mrs.' in row['Name']:\n        return 2\n    elif 'Miss.' in row['Name']:\n        return 3\n    elif 'Ms.' in row['Name']:\n        return 3\n    elif 'Dr.' in row['Name']:\n        if row['Sex'] == 'Male':\n            return 0\n        else:\n            return 2\n    \n\nages['group'] = ages.apply(lambda x: groupby_age_sex(x), axis=1)\nages.head()","61184aaf":"ages = ages.groupby('group').agg({'Age':'mean'})\nages.rename(columns = {'Age': 'Avg Age'}, inplace=True)\nages.head()","f62f6518":"#add group to test and train\ntest['group'] = test.apply(lambda x: groupby_age_sex(x), axis=1)\ntrain['group'] = train.apply(lambda x: groupby_age_sex(x), axis=1)\n\n#set index for easy join\ntest.set_index('group', inplace=True)\ntrain.set_index('group', inplace=True)\n\n#join to averages to add column Avg Age\ntest = test.join(ages, how='left')\ntrain = train.join(ages, how='left')\n\n#fill in avg age where age is NaN\ntest.loc[test['Age'].isna(), 'Age'] = test.loc[test['Age'].isna()]['Avg Age']\ntest.drop('Avg Age', axis=1, inplace=True)\ntest.head()","bee4be27":"train.loc[train['Age'].isna(), 'Age'] = train.loc[train['Age'].isna()]['Avg Age']\ntrain.drop('Avg Age', axis=1, inplace=True)\ntrain.head()","e7c90f05":"# removing our group values to avoid introducing new variables that are summaries of current variables. Also dropping Name, PassengerId, SibSp, Parch and Ticket \n# as they no longer hold value worth based on analysis in the Shiny app.\n\ntrain = train.fillna(0)\ntest = test.fillna(0)\n\ntrain.reset_index(inplace=True)\ntrain_target = train['Survived'].copy()\ntrain_results = train[['PassengerId', 'Survived']].copy() # preparing to check accuracy\ntrain.drop(['group', 'Name', 'Ticket', 'PassengerId', 'SibSp', 'Parch', 'Survived'], axis=1, inplace=True)\n\ntrain.head()","f35cacaa":"test.reset_index(inplace=True)\ntest_results = test[['PassengerId']].copy() #preparing for output\ntest.drop(['group', 'Name', 'Ticket', 'PassengerId', 'SibSp', 'Parch'], axis=1, inplace=True)\n\ntest.head()","bf09038d":"def build_mapping(arr):\n    arr = sorted(set(arr)) #get unique values\n    i=0\n    \n    for ea in arr:\n        i += 1\n        try:\n            item_map.update({ea:i})\n        except:\n            item_map = {ea:i}\n    \n    return item_map\n\n#setting mapping fields all to strings for matching purposes - ensuring everything is mapped correctly\n\ntrain['Sex'] = train['Sex'].astype(str)\ntrain['Embarked'] = train['Embarked'].astype(str)\ntrain['Cabin'] = train['Cabin'].astype(str)\n\ntest['Sex'] = test['Sex'].astype(str)\ntest['Embarked'] = test['Embarked'].astype(str)\ntest['Cabin'] = test['Cabin'].astype(str)\n\nmap_sex = build_mapping(train['Sex']) #no need to combine, there are only two choices and both represented in train data\nmap_sex","7cbe71e7":"map_embarked = build_mapping(train['Embarked'].astype(str)) #no need to combine, there are only three choices and both represented in train data\nmap_embarked","cc26a695":"#need to combine and organize test and train data since unique values are in each. The null is probably the highest value item (now 0 to avoid it being dropped from results)\n#but alphabatizing cabin should also help map it to ship location if they were logically created on the ship\n\n\ncabin_list = train['Cabin'].append(test['Cabin'])\ncabin_list.sort_values(inplace=True)\ncabin_list","1c22e684":"map_cabin = build_mapping(cabin_list)\nmap_cabin","972804ce":"train['Sex'] = train['Sex'].map(map_sex)\ntrain['Cabin'] = train['Cabin'].map(map_cabin)\ntrain['Embarked'] = train['Embarked'].map(map_embarked)\n\ntrain.head(25)","fb842ec8":"test['Sex'] = test['Sex'].map(map_sex)\ntest['Cabin'] = test['Cabin'].map(map_cabin)\ntest['Embarked'] = test['Embarked'].map(map_embarked)\n\ntest.head(25)","e0a6da40":"dt = tree.DecisionTreeClassifier(min_samples_split=30)\ndt","7b1cb80f":"dt = dt.fit(train, train_target)\ndt","5987ce3d":"dot_data = tree.export_graphviz(dt, out_file=None) \ngraph = graphviz.Source(dot_data) \ngraph.render(\"Titanic\") ","f9e922f2":"dot_data = tree.export_graphviz(dt, out_file=None, \n                     filled=True, rounded=True,  \n                     special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph ","81db71c4":"train_results['Survived Estimate'] = dt.predict(train)\ntrain_results","20c5ec7a":"tot = len(train_results.index)\nmatches = len(train_results.loc[train_results['Survived'] == train_results['Survived Estimate']].index)\nprint(\"Successfully guessed \" + str(matches) + \" out of \" + str(tot) + \" total records.   \" + str(round((matches\/tot) * 100, 2)) + \"%\")","1187d454":"test_results['Survived'] = dt.predict(test)\ntest_results.set_index('PassengerId', inplace=True)\ntest_results.to_csv(\"results.csv\")\ntest_results","d1a415af":"## Import Python packages needed and data","36e208ba":"Applying averages by age group to test and train data","b01886e7":"This is important, since we have all heard of the women and children first approach to catastrophes. By this nature, we should expect our data to reflect a bias in survival rates towards the young and female.\nWe will verify this later, but for now we just want to see how impactful these missing values could be.Clearly there are a lot of missing ages which could be helpful in determining survival rate. \n\nThe family relationship statistics do not appear to be all that useful to me. Instead we can use the name field for evaluating average age by name prefix (Miss, Mrs, Mr, Master). There are some others like Dr, and ms. and miss seem to be interchangable. ","a2984566":"## Extract modified training data and visualize in shinyapps.io","4bde6459":"## Test Data and Submit Results","db29187e":"After this point the modified training data was extracted and imported into R for use in an R Shiny dashboard. Please see the published R Shinny app here for visual investigations of the data:\n\n[https:\/\/ian-stone30.shinyapps.io\/Titanic_Project\/]( https:\/\/ian-stone30.shinyapps.io\/Titanic_Project\/)\n\nBy moving the visuals to an interactive graph, we can quickly compare many different items at once without extra coding. As you will see from the home page, all data and code is available for download directly from the application itself. \n\nPlease review and come back to this kernel for the next steps.","0690edd9":"## Review the data and identify missing data","1ac0eb75":"With the name, age and sex parsed out, we will use a custom function of nested if statements to group the passengers into four distinct groups: adult male, adult female, boy, and girl. We can then evaluate each subgroups average age to get closer average for each missing value.\n\nUsing an apply method like this is not ideal for large data sets, but here it is a small enough list of values the performance is not a concern and it allows for a clean view of the logic.","864ae528":"## Build on insights from visuals to train a basic machine learning model\n\n### Decision Trees\n\nDecision Trees are easy to explain what is going on. Before investigating many other types of classification models, starting with one that almost emulates how people solve problems is a good start. The decision tree will investigate the attributes in our data and set decision points to get us to a logical classification of if our passenger survived or died in the Titanic crash based on the attributes we have available.","75963280":"## Clean key data by filling estimates for missing data","2bb8d81a":"# Conclusion\n\nFor a reasonable effort in data cleansing and organizing, the training model accuracy of over 86% is very good for a decision tree with a data set this size. Based on this, we can confidently say we succeeded in a first run Kaggle competition. Hopefully some of the items here can help other new-Kagglers!","5eef1c0b":"# Introduction to problem solving for data\nThis kernel hopes to outline techniques to creatively fill missing values, transform data for statistical analysis, blend technologies, and deliver a model for estimating results.\n\n## Document Outline\n1. Import Python packages needed and data\n2. Review the data and identify missing data\n3. Clean key data by filling estimates for missing data\n4. Extract modified training data and visualize in shinyapps.io\n5. Build on insights from visuals to train a basic machine learning model\n7. Test data and submit results","522780d2":"### Cleaning Data\n\nNext we need to make everything numeric. Here are a few other ways to handle this that are different than the grouping done above."}}