{"cell_type":{"15dd17d2":"code","72e1b7d5":"code","941c9663":"code","83ff7331":"code","357c7e1d":"markdown","8e093e70":"markdown","182c8f0b":"markdown","d5779469":"markdown","e663e4b2":"markdown","76684510":"markdown","1515a6f9":"markdown","092fd82d":"markdown"},"source":{"15dd17d2":"import pandas as pd\nimport numpy as np\nimport string\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom wordcloud import WordCloud\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","72e1b7d5":"train = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")","941c9663":"def W_Cloud():\n    \"\"\"\n    Visualize the most common words contributing to the token.\n    \"\"\"\n    threat_context = train\n    threat_text = threat_context[\"more_toxic\"]\n    neg_text = pd.Series(threat_text).str.cat(sep=' ')\n    wordcloud = WordCloud(width=1600, height=800, max_font_size=200).generate(neg_text)\n\n    plt.figure(figsize=(15, 10))\n    plt.imshow(wordcloud.recolor(colormap=\"Blues\"), interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()","83ff7331":"W_Cloud()","357c7e1d":"![Alt Text](https:\/\/media.giphy.com\/media\/7frSUXgbGqQPKNnJRS\/giphy.gif)","8e093e70":"# **Visualizing**","182c8f0b":"# **Imports**","d5779469":"# **Load the Data**","e663e4b2":"------","76684510":"# **\ud83d\udcbb Work in Progress...**","1515a6f9":"----","092fd82d":"# **If you find this usefull give it an upvote! :)**"}}