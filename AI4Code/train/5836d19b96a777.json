{"cell_type":{"3a3e2ba1":"code","90a64a52":"code","8ded098a":"code","71afd9b0":"code","c42d7761":"code","1defded5":"code","9ebae402":"code","71529331":"code","5e8c623a":"code","fa5b4b99":"code","229db4ae":"code","945e1935":"code","16b58f40":"code","1207982a":"code","1df18c91":"code","f1f1271c":"code","3939436e":"code","f94137b6":"code","75f00d1d":"code","f10a4da0":"code","f2ba96c0":"code","6e7a8f33":"code","42ee18a6":"code","10d96b5f":"code","f3ed3d1f":"code","2c07dd00":"code","d9c793e0":"code","f91fc9c1":"code","e31fb9c4":"code","ca236582":"code","e08251ca":"code","95e5e1ba":"code","d6f43a5b":"code","b6e7c667":"code","c400101b":"code","15bc2692":"code","e86fb769":"code","dfc8f982":"code","b66b7268":"code","5e8f7264":"code","a5283fe5":"code","e5488b65":"code","77a52be8":"code","0ee650b1":"code","6efd2a7d":"code","883b685c":"code","681cbb68":"markdown","a19776a4":"markdown","e517e7e1":"markdown","5984b8ee":"markdown","938bfdaf":"markdown","acb013d7":"markdown","10452eed":"markdown","7e4001e4":"markdown","48b7ae78":"markdown","eeff99dd":"markdown"},"source":{"3a3e2ba1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random as rnd\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Any results you write to the current directory are saved as output.","90a64a52":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ncombine = [train,test]","8ded098a":"print(train.columns.values)","71afd9b0":"train.head()","c42d7761":"train.info()\nprint('*'*50)\ntest.info()","1defded5":"train.describe()","9ebae402":"train.describe(include=[np.object])\n#train.describe(include=['O'])","71529331":"train[['Pclass','Survived']].groupby(['Pclass'],as_index=False)['Survived'].mean()","5e8c623a":"train[['Sex','Survived']].groupby(['Sex'],as_index=False)['Survived'].mean()","fa5b4b99":"train[['SibSp','Survived']].groupby(['SibSp'],as_index=False)['Survived'].mean().sort_values(\n    by='Survived',ascending=False)","229db4ae":"train[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False)['Survived'].mean().sort_values(\n    by='Survived', ascending=False)","945e1935":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","16b58f40":"g = sns.FacetGrid(train,col='Survived')\ng.map(plt.hist,'Age',bins=20)","1207982a":"grid = sns.FacetGrid(train,col='Survived',row='Pclass',size=3,aspect=1.5)\ngrid.map(plt.hist,'Age',alpha=.5,bins=20)\ngrid.add_legend()","1df18c91":"grid = sns.FacetGrid(train, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex')\ngrid.add_legend()","f1f1271c":"grid = sns.FacetGrid(train,row='Embarked',col='Survived')\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.3, ci=None)\ngrid.add_legend()","3939436e":"train['Cabin'].fillna('U0',inplace = True)\ntest['Cabin'].fillna('U0',inplace = True)\n#train[train['Cabin'] == 'U0']","f94137b6":"grid = sns.FacetGrid(train[train['Cabin'] == 'U0'])\ngrid.map(plt.hist,'Survived',color='r')\ngrid = sns.FacetGrid(train[train['Cabin'] != 'U0'])\ngrid.map(plt.hist,'Survived',color='b')","75f00d1d":"train = train.drop(['Ticket','PassengerId'],axis=1)\ntest = test.drop(['Ticket','PassengerId'],axis=1)\ncombine = [train,test]\n","f10a4da0":"for dataset in combine:\n    dataset['Title'] = dataset['Name'].str.extract('([A-Za-z]+)\\.',expand=False)\npd.crosstab(train['Title'],train['Sex'])","f2ba96c0":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n                                                 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\ntrain[['Title','Survived']].groupby(['Title'],as_index=False).mean().sort_values(by='Survived')","6e7a8f33":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n","42ee18a6":"train = train.drop(['Name'],axis=1)\ntest = test.drop(['Name'],axis=1)\ncombine = [train,test]","10d96b5f":"train.head()","f3ed3d1f":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map({'female':1, 'male':0}).astype(int)\ntrain.head()","2c07dd00":"grid = sns.FacetGrid(train,row='Pclass',col='Sex',size=3,aspect=1.6)\ngrid.map(plt.hist,'Age',bins=25)\ngrid.add_legend()","d9c793e0":"guess_age = np.zeros((2,3))\nguess_age","f91fc9c1":"for dataset in combine:\n    for i in range(0,2):\n        for j in range(0,3):\n            guess = dataset[(dataset['Sex']==i) & (dataset['Pclass']==j+1)]['Age'].dropna()\n            age_guess = guess.median()\n            guess_age[i,j] = int(age_guess\/0.5 + 0.5)*0.5\n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),'Age'] = guess_age[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\ntrain.head()","e31fb9c4":"train['AgeBand'] = pd.cut(train['Age'],5)\ntrain[['AgeBand','Survived']].groupby(['AgeBand'],as_index=False).mean().sort_values(by='AgeBand', ascending=True)","ca236582":"for dataset in combine:\n    dataset.loc[dataset['Age']<=16,'Age'] = 0\n    dataset.loc[(dataset['Age']<=32) & (dataset['Age']>16),'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\n","e08251ca":"train = train.drop(['AgeBand'],axis=1)\ncombine = [train,test]","95e5e1ba":"for dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass","d6f43a5b":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\ntrain[['FamilySize','Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","b6e7c667":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","c400101b":"for dataset in combine:\n    dataset['HasCabin'] = 1\n    dataset.loc[dataset['Cabin'] == 'U0', 'HasCabin'] = 0\n\ntrain[['HasCabin', 'Survived']].groupby(['HasCabin'], as_index=False).mean()","15bc2692":"train = train.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest = test.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train,test]\ntrain","e86fb769":"train['FareBand'] = pd.qcut(train['Fare'],4)\ntrain[['FareBand','Survived']].groupby(['FareBand'],as_index=False).mean().sort_values(by='FareBand', ascending=True)","dfc8f982":"test['Fare'].fillna(test['Fare'].dropna().median(),inplace=True)","b66b7268":"for dataset in combine:\n    dataset.loc[dataset['Fare']<=7.91,'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain = train.drop(['FareBand'], axis=1)\ncombine = [train,test]","5e8f7264":"freq_port = train.Embarked.mode()[0]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)","a5283fe5":"train = train.drop(['Cabin'], axis=1)\ntest = test.drop(['Cabin'], axis=1)\ntrain = pd.get_dummies(train)\ntest = pd.get_dummies(test)\ncombine = [train,test]","e5488b65":"train","77a52be8":"test","0ee650b1":"train_x = train.drop('Survived', axis=1)\ntrain_y = train['Survived']\ntest_x = test\ntrain_x.shape,train_y.shape,test_x.shape","6efd2a7d":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nrandom_forest = RandomForestClassifier(n_estimators=100)\n\nresults = cross_val_score(random_forest,train_x,train_y,scoring='accuracy',cv=10)\nprint(np.mean(results))","883b685c":"random_forest.fit(train_x,train_y)\npredict = random_forest.predict(test_x)\ncol = pd.read_csv('..\/input\/test.csv')\noutput = pd.DataFrame({'PassengerId':col['PassengerId'],'Survived':predict})\noutput.to_csv('submission.csv',index=False)","681cbb68":"Embarked=C \u4e2d \u7537\u6027\u5b58\u6d3b\u7387\u66f4\u9ad8 \u8fd9\u8868\u660ePclass\u548cEmbarked\u5b58\u5728\u76f8\u5173\u6027\n\nembarked\u4e0d\u4e00\u5b9a\u4e0e\u5b58\u6d3b\u7387\u6709\u76f4\u63a5\u5173\u7cfb \u53ef\u80fd\u662f embarked->pclass->survived\n","a19776a4":"\u6dfb\u52a0\u65b0\u7684\u7279\u5f81 \u6539\u540d\u5b57","e517e7e1":"\u5b8c\u5584Age\u7684\u7f3a\u5931\u503c","5984b8ee":"## \u901a\u8fc7\u56fe\u50cf\u9a8c\u8bc1\u76f8\u5173\u6027","938bfdaf":"Parch and SibSp","acb013d7":"# \u4f7f\u7528RF\u7b97\u6cd5","10452eed":"\u5229\u7528\u6027\u522b Pclass \u9884\u6d4b\u5e74\u9f84","7e4001e4":"\u5904\u7406\u7968\u4ef7","48b7ae78":"## \u76f8\u5173\u6027\u5206\u6790\n\n\u7b80\u5355\u7684\u4ece\u6570\u636e\u4e2d\u770b\u51fa\u76f8\u5173\u6027\uff08\u65e0\u56fe\uff09","eeff99dd":"\u5206\u6790\u6570\u636e\u5206\u5e03"}}