{"cell_type":{"db13c53e":"code","17940db4":"code","e97294bf":"code","ccb97011":"code","87471c53":"code","c403de3b":"code","bd83a596":"code","915253ed":"code","4dd42195":"markdown","70c781dc":"markdown","83c9e999":"markdown","f3b3e124":"markdown"},"source":{"db13c53e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","17940db4":"!pip install monai","e97294bf":"!pip install numpy\n\n!pip install torch\n\n!pip install 'monai[itk, nibabel, pillow]'","ccb97011":"import logging\nimport os\nimport sys\nimport tempfile\nfrom glob import glob\n\nimport nibabel as nib\nfrom ignite.engine import Engine\n\nimport torch\nfrom PIL import Image\nfrom torch.utils.data import DataLoader\n\nimport monai\n\nfrom monai.visualize import plot_2d_or_3d_image\nfrom monai.data import create_test_image_2d, list_data_collate, decollate_batch\nfrom monai.inferers import sliding_window_inference\nfrom monai.metrics import DiceMetric\nfrom monai.networks.nets import UNet\nfrom monai.transforms import Activations, AddChanneld, AsDiscrete, Compose, LoadImaged, SaveImage, ScaleIntensityd, EnsureTyped, EnsureType","87471c53":"# Importing essential datasets\nBASE = '..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/'","c403de3b":"def main(tempdir):\n    monai.config.print_config()\n    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n\n    print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n    for i in range(5):\n        im, seg = create_test_image_2d(128, 128, num_seg_classes=1)\n        Image.fromarray(im.astype(\"uint8\")).save(os.path.join(tempdir, f\"img{i:d}.png\"))\n        Image.fromarray(seg.astype(\"uint8\")).save(os.path.join(tempdir, f\"seg{i:d}.png\"))\n\n    images = sorted(glob(os.path.join(tempdir, \"img*.png\")))\n    segs = sorted(glob(os.path.join(tempdir, \"seg*.png\")))\n    val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images, segs)]\n\n    # define transforms for image and segmentation\n    val_transforms = Compose(\n        [\n            LoadImaged(keys=[\"img\", \"seg\"]),\n            AddChanneld(keys=[\"img\", \"seg\"]),\n            ScaleIntensityd(keys=\"img\"),\n            EnsureTyped(keys=[\"img\", \"seg\"]),\n        ]\n    )\n    val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n    # sliding window inference need to input 1 image in every iteration\n    val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\n    dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n    post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold_values=True)])\n    saver = SaveImage(output_dir=\".\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/\", output_ext=\".png\", output_postfix=\"seg\")\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = UNet(\n        dimensions=2,\n        in_channels=1,\n        out_channels=1,\n        channels=(16, 32, 64, 128, 256),\n        strides=(2, 2, 2, 2),\n        num_res_units=2,\n    ).to(device)\n\n    model.load_state_dict(torch.load(\"best_metric_model_segmentation2d_dict.pth\"))\n\n    model.eval()\n    with torch.no_grad():\n        for val_data in val_loader:\n            val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n            # define sliding window size and batch size for windows inference\n            roi_size = (96, 96)\n            sw_batch_size = 4\n            val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n            val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n            val_labels = decollate_batch(val_labels)\n            # compute metric for current iteration\n            dice_metric(y_pred=val_outputs, y=val_labels)\n            for val_output in val_outputs:\n                saver(val_output)\n        # aggregate the final mean dice result\n        print(\"evaluation metric:\", dice_metric.aggregate().item())\n        # reset the status\n        dice_metric.reset()","bd83a596":"def main(tempdir):\n    monai.config.print_config()\n    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n\n    # create a temporary directory and 40 random image, mask pairs\n    print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n    for i in range(40):\n        im, seg = create_test_image_2d(128, 128, num_seg_classes=1)\n        Image.fromarray(im.astype(\"uint8\")).save(os.path.join(tempdir, f\"img{i:d}.png\"))\n        Image.fromarray(seg.astype(\"uint8\")).save(os.path.join(tempdir, f\"seg{i:d}.png\"))\n\n    images = sorted(glob(os.path.join(tempdir, \"img*.png\")))\n    segs = sorted(glob(os.path.join(tempdir, \"seg*.png\")))\n    train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[:20], segs[:20])]\n    val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[-20:], segs[-20:])]\n\n    # define transforms for image and segmentation\n    train_transforms = Compose(\n        [\n            LoadImaged(keys=[\"img\", \"seg\"]),\n            AddChanneld(keys=[\"img\", \"seg\"]),\n            ScaleIntensityd(keys=\"img\"),\n            RandCropByPosNegLabeld(\n                keys=[\"img\", \"seg\"], label_key=\"seg\", spatial_size=[96, 96], pos=1, neg=1, num_samples=4\n            ),\n            RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5, spatial_axes=[0, 1]),\n            EnsureTyped(keys=[\"img\", \"seg\"]),\n        ]\n    )\n    val_transforms = Compose(\n        [\n            LoadImaged(keys=[\"img\", \"seg\"]),\n            AddChanneld(keys=[\"img\", \"seg\"]),\n            ScaleIntensityd(keys=\"img\"),\n            EnsureTyped(keys=[\"img\", \"seg\"]),\n        ]\n    )\n\n    # define dataset, data loader\n    check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n    # use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n    check_loader = DataLoader(check_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)\n    check_data = monai.utils.misc.first(check_loader)\n    print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n\n    # create a training data loader\n    train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n    # use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=2,\n        shuffle=True,\n        num_workers=4,\n        collate_fn=list_data_collate,\n        pin_memory=torch.cuda.is_available(),\n    )\n    # create a validation data loader\n    val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n    val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\n    dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n    post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold_values=True)])\n    # create UNet, DiceLoss and Adam optimizer\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = monai.networks.nets.UNet(\n        dimensions=2,\n        in_channels=1,\n        out_channels=1,\n        channels=(16, 32, 64, 128, 256),\n        strides=(2, 2, 2, 2),\n        num_res_units=2,\n    ).to(device)\n    loss_function = monai.losses.DiceLoss(sigmoid=True)\n    optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n\n    # start a typical PyTorch training\n    val_interval = 2\n    best_metric = -1\n    best_metric_epoch = -1\n    epoch_loss_values = list()\n    metric_values = list()\n    writer = SummaryWriter()\n    for epoch in range(10):\n        print(\"-\" * 10)\n        print(f\"epoch {epoch + 1}\/{10}\")\n        model.train()\n        epoch_loss = 0\n        step = 0\n        for batch_data in train_loader:\n            step += 1\n            inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = loss_function(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n            epoch_len = len(train_ds) \/\/ train_loader.batch_size\n            print(f\"{step}\/{epoch_len}, train_loss: {loss.item():.4f}\")\n            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n        epoch_loss \/= step\n        epoch_loss_values.append(epoch_loss)\n        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n\n        if (epoch + 1) % val_interval == 0:\n            model.eval()\n            with torch.no_grad():\n                val_images = None\n                val_labels = None\n                val_outputs = None\n                for val_data in val_loader:\n                    val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n                    roi_size = (96, 96)\n                    sw_batch_size = 4\n                    val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n                    val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n                    # compute metric for current iteration\n                    dice_metric(y_pred=val_outputs, y=val_labels)\n                # aggregate the final mean dice result\n                metric = dice_metric.aggregate().item()\n                # reset the status for next validation round\n                dice_metric.reset()\n                metric_values.append(metric)\n                if metric > best_metric:\n                    best_metric = metric\n                    best_metric_epoch = epoch + 1\n                    torch.save(model.state_dict(), \"best_metric_model_segmentation2d_dict.pth\")\n                    print(\"saved new best metric model\")\n                print(\n                    \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n                        epoch + 1, metric, best_metric, best_metric_epoch\n                    )\n                )\n                writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n                plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n                plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n                plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n\n    print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n    writer.close()","915253ed":"if __name__ == \"__main__\":\n    with tempfile.TemporaryDirectory() as tempdir:\n        main(tempdir)","4dd42195":"#After the snippet above I got File not found: best_metric_model_segmentation2d_dict.pth\n\nThen I tried the second snippet below to get: \"NameError: name 'RandCropByPosNegLabeld' is not defined.","70c781dc":"![](https:\/\/www.dino.com.br\/DinoImages\/c4fed9b0-7ecf-4ff5-834a-0c334d0055c5.png?quality=100&width=620)metropoles.com","83c9e999":"Above I got: NameError: name 'RandCropByPosNegLabeld' is not defined.\n\n#I'll wait till someone make a decent Kaggle Notebook with MONAI (Medical Open Network for AI)","f3b3e124":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #5F9EA0;\"><b style=\"color:black;\">NVIDIA Launches MONAI - AI In Healthcare<\/b><\/h1><\/center>\n\nNVIDIA Launches MONAI Framework To Accelerate AI In Healthcare - Dec 7, 2020 03\n\n\"NVIDIA has released MONAI, a Medical Open Network for AI, a domain-optimized, open source platform for healthcare, in an effort to accelerate artificial intelligence in the healthcare industry. MONAI is now ready for manufacturing with the forthcoming release of the company's Clara application platform for AI-powered healthcare and life sciences, according to the official release by NVIDIA.\"\n\n\"The MONAI framework is a PyTorch-based framework that was launched in April 2020 and has already been adopted by some of the leading research institutions in the field of healthcare. The use of artificial intelligence for medical imaging is advanced by this system. This is achieved with industry-specific data handling, reproducible state-of-the-art solution reference implementations, and high-performance workflows for training.\"\n\n\"MONAI has been released and will come with over 20 pre-trained models, including those recently produced for COVID pandemics. It also includes the new NVIDIA DGX A100 GPU training optimizations that include up to a six-fold increase in training turnaround time.\"\n\n\"The framework is currently becoming a key in the healthcare industry by paving the way for closer collaboration between data scientists and clinicians.\"\n\n\"The NVIDIA framework will become a deep learning framework for healthcare. Much of this can be attributed to the challenges of moving AI-based applications from research to production to provide effective clinical care.\"\n\nThus, NVIDIA\u2019s commitment to allowing the academic community to contribute to a framework that is production-ready will allow for further innovation to build enterprise-ready features.\n\nhttps:\/\/www.globalnewsstore.com\/nvidia-launches-monai"}}