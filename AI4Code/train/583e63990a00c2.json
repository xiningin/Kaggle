{"cell_type":{"b9e10dc5":"code","7fcb0861":"code","790697d5":"code","dbd734d3":"code","b136c745":"code","f6ea2ee4":"code","8469f000":"code","89fdc916":"code","1b26fa1a":"code","c26eb438":"code","7ebb5454":"code","7e8c4015":"code","d448bed7":"code","ec2205f7":"code","92483431":"code","5a077ed1":"code","c8e7e472":"code","47efedeb":"code","bffabf1e":"code","9ab48246":"code","f9054c0e":"code","c063080b":"markdown","10aa5fa7":"markdown","6c16f49d":"markdown","94ab69e0":"markdown","a0125cea":"markdown","df9bc9ef":"markdown","0ffe57e5":"markdown","58c4e138":"markdown","f0822003":"markdown","1bb14370":"markdown","7a02c49f":"markdown","800b4474":"markdown","786e837a":"markdown","e980a864":"markdown"},"source":{"b9e10dc5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7fcb0861":"! pip install -U google-api-python-client\n! pip install -U google-cloud\n! pip install -U google-cloud-storage\n! pip install -U requests\n\n# Automatically restart kernel after installs\nimport IPython\nimport time\n# app = IPython.Application.instance()\n# app.kernel.do_shutdown(True)  ","790697d5":"time.sleep(5)","dbd734d3":"from kaggle_gcp import KaggleKernelCredentials\nimport io","b136c745":"%env GOOGLE_APPLICATION_CREDENTIALS \/kaggle\/input\/automltablessa\/kaggle-playground-170215-6ed5acf02acd.json","f6ea2ee4":"!gcloud auth activate-service-account --key-file=\/kaggle\/input\/automltablessa\/kaggle-playground-170215-6ed5acf02acd.json\n\n# ! gcloud auth application-default login\n# ! gcloud auth login","8469f000":"PROJECT_ID = \"kaggle-playground-170215\"\n! gcloud config set project $PROJECT_ID","89fdc916":"import json\nimport time\nimport datetime\nfrom googleapiclient import errors","1b26fa1a":"USER = 'devvret' #@param {type: 'string'}\n\nSTUDY_ID = '{}_study_{}'.format(USER, datetime.datetime.now().strftime('%Y%m%d_%H%M%S')) #@param {type: 'string'}\nREGION = 'us-central1'\n\ndef study_parent():\n  return 'projects\/{}\/locations\/{}'.format(PROJECT_ID, REGION)\n\n\ndef study_name(study_id):\n  return 'projects\/{}\/locations\/{}\/studies\/{}'.format(PROJECT_ID, REGION, study_id)\n\n\ndef trial_parent(study_id):\n  return study_name(study_id)\n\n\ndef trial_name(study_id, trial_id):\n  return 'projects\/{}\/locations\/{}\/studies\/{}\/trials\/{}'.format(PROJECT_ID, REGION,\n                                                                study_id, trial_id)\n\ndef operation_name(operation_id):\n  return 'projects\/{}\/locations\/{}\/operations\/{}'.format(PROJECT_ID, REGION, operation_id)\n\n\nprint('USER: {}'.format(USER))\nprint('PROJECT_ID: {}'.format(PROJECT_ID))\nprint('REGION: {}'.format(REGION))\nprint('STUDY_ID: {}'.format(STUDY_ID))","c26eb438":"from google.cloud import storage\nfrom googleapiclient import discovery\n\n\n_OPTIMIZER_API_DOCUMENT_BUCKET = 'caip-optimizer-public'\n_OPTIMIZER_API_DOCUMENT_FILE = 'api\/ml_public_google_rest_v1.json'\n\n\ndef read_api_document():\n  client = storage.Client(PROJECT_ID, credentials=KaggleKernelCredentials())\n  bucket = client.get_bucket(_OPTIMIZER_API_DOCUMENT_BUCKET)\n  blob = bucket.get_blob(_OPTIMIZER_API_DOCUMENT_FILE)\n  return blob.download_as_string()\n\n\nml = discovery.build_from_document(service=read_api_document())\nprint('Successfully built the client.')","7ebb5454":"param_learning_rate = {\n    'parameter': 'learning_rate',\n    'type' : 'DOUBLE',\n    'double_value_spec' : {\n        'min_value' : 0.00001,\n        'max_value' : 1.0\n    },\n    'scale_type' : 'UNIT_LOG_SCALE',\n    'parent_categorical_values' : {\n        'values': ['LINEAR', 'WIDE_AND_DEEP']\n    },\n}\n\nparam_dnn_learning_rate = {\n    'parameter': 'dnn_learning_rate',\n    'type' : 'DOUBLE',\n    'double_value_spec' : {\n        'min_value' : 0.00001,\n        'max_value' : 1.0\n    },\n    'scale_type' : 'UNIT_LOG_SCALE',\n    'parent_categorical_values' : {\n        'values': ['WIDE_AND_DEEP']\n    },\n}\n\nparam_model_type = {\n    'parameter': 'model_type',\n    'type' : 'CATEGORICAL',\n    'categorical_value_spec' : {'values': ['LINEAR', 'WIDE_AND_DEEP']},\n    'child_parameter_specs' : [param_learning_rate, param_dnn_learning_rate,]\n}\n\nmetric_accuracy = {\n    'metric' : 'accuracy',\n    'goal' : 'MAXIMIZE'\n}\n\nstudy_config = {\n    'algorithm' : 'ALGORITHM_UNSPECIFIED',  # Let the service choose the `default` algorithm.\n    'parameters' : [param_model_type,],\n    'metrics' : [metric_accuracy,],\n}\n\nstudy = {'study_config': study_config}\nprint(json.dumps(study, indent=2, sort_keys=True))\n","7e8c4015":"# Creates a study\nreq = ml.projects().locations().studies().create(\n    parent=study_parent(), studyId=STUDY_ID, body=study)\ntry :\n  print(req.execute())\nexcept errors.HttpError as e:\n  if e.resp.status == 409:\n    print('Study already existed.')\n  else:\n    raise e","d448bed7":"# `job_dir` will be `gs:\/\/${OUTPUT_BUCKET}\/${OUTPUT_DIR}\/${job_id}`\nOUTPUT_BUCKET = 'vizier-test-kaggle-playground' #@param {type: 'string'}\nOUTPUT_DIR = 'test-dir' #@param {type: 'string'}\nTRAINING_DATA_PATH = 'gs:\/\/caip-optimizer-public\/sample-data\/raw_census_train.csv' #@param {type: 'string'}\n\nprint('OUTPUT_BUCKET: {}'.format(OUTPUT_BUCKET))\nprint('OUTPUT_DIR: {}'.format(OUTPUT_DIR))\nprint('TRAINING_DATA_PATH: {}'.format(TRAINING_DATA_PATH))\n\n# Create the bucket in Cloud Storage\n#! gsutil mb -p $PROJECT_ID gs:\/\/$OUTPUT_BUCKET\/","ec2205f7":"import logging\nimport math\nimport subprocess\nimport os\nimport yaml\n\nfrom google.cloud import storage\n\n_TRAINING_JOB_NAME_PATTERN = '{}_condition_parameters_{}_{}'\n_IMAGE_URIS = {'LINEAR' : 'gcr.io\/cloud-ml-algos\/linear_learner_cpu:latest',\n               'WIDE_AND_DEEP' : 'gcr.io\/cloud-ml-algos\/wide_deep_learner_cpu:latest'}\n_STEP_COUNT = 'step_count'\n_ACCURACY = 'accuracy'\n\n\ndef EvaluateTrials(trials):\n  \"\"\"Evaluates trials by submitting training jobs to AI Platform Training service.\n\n     Args:\n       trials: List of Trials to evaluate\n\n     Returns: A dict of <trial_id, measurement> for the given trials.\n  \"\"\"\n  trials_by_job_id = {}\n  mesurement_by_trial_id = {}\n\n  # Submits a AI Platform Training job for each trial.\n  for trial in trials:\n    trial_id = int(trial['name'].split('\/')[-1])\n    model_type = _GetSuggestedParameterValue(trial, 'model_type', 'stringValue')\n    learning_rate = _GetSuggestedParameterValue(trial, 'learning_rate',\n                                                'floatValue')\n    dnn_learning_rate = _GetSuggestedParameterValue(trial, 'dnn_learning_rate',\n                                                    'floatValue')\n    job_id = _GenerateTrainingJobId(model_type=model_type, \n                                    trial_id=trial_id)\n    trials_by_job_id[job_id] = {\n        'trial_id' : trial_id,\n        'model_type' : model_type,\n        'learning_rate' : learning_rate,\n        'dnn_learning_rate' : dnn_learning_rate,\n    }\n    _SubmitTrainingJob(job_id, trial_id, model_type, learning_rate, dnn_learning_rate)\n\n  # Waits for completion of AI Platform Training jobs.\n  print(trials_by_job_id.keys())\n  while not _JobsCompleted(trials_by_job_id.keys()):\n    time.sleep(60)\n\n  # Retrieves model training result(e.g. global_steps, accuracy) for AI Platform Training jobs.\n  metrics_by_job_id = _GetJobMetrics(trials_by_job_id.keys())\n  for job_id, metric in metrics_by_job_id.items():\n    measurement = _CreateMeasurement(trials_by_job_id[job_id]['trial_id'],\n                                     trials_by_job_id[job_id]['model_type'],\n                                     trials_by_job_id[job_id]['learning_rate'],\n                                     trials_by_job_id[job_id]['dnn_learning_rate'],\n                                     metric)\n    mesurement_by_trial_id[trials_by_job_id[job_id]['trial_id']] = measurement\n  return mesurement_by_trial_id\n\n\ndef _CreateMeasurement(trial_id, model_type, learning_rate, dnn_learning_rate, metric):\n  if not metric[_ACCURACY]:\n    # Returns `none` for trials without metrics. The trial will be marked as `INFEASIBLE`.\n    return None\n  print(\n      'Trial {0}: [model_type = {1}, learning_rate = {2}, dnn_learning_rate = {3}] => accuracy = {4}'.format(\n          trial_id, model_type, learning_rate,\n          dnn_learning_rate if dnn_learning_rate else 'N\/A', metric[_ACCURACY]))\n  measurement = {\n      _STEP_COUNT: metric[_STEP_COUNT],\n      'metrics': [{'metric': _ACCURACY, 'value': metric[_ACCURACY]},]}\n  return measurement\n\n\ndef _SubmitTrainingJob(job_id, trial_id, model_type, learning_rate, dnn_learning_rate=None):\n  \"\"\"Submits a built-in algo training job to AI Platform Training Service.\"\"\"\n  try:\n    if model_type == 'LINEAR':\n      subprocess.check_output(_LinearCommand(job_id, learning_rate), stderr=subprocess.STDOUT)\n    elif model_type == 'WIDE_AND_DEEP':\n      subprocess.check_output(_WideAndDeepCommand(job_id, learning_rate, dnn_learning_rate), stderr=subprocess.STDOUT)\n    print('Trial {0}: Submitted job [https:\/\/console.cloud.google.com\/ai-platform\/jobs\/{1}?project={2}].'.format(trial_id, job_id, PROJECT_ID))\n  except subprocess.CalledProcessError as e:\n    logging.error(e.output)\n\n\ndef _GetTrainingJobState(job_id):\n  \"\"\"Gets a training job state.\"\"\"\n  cmd = ['gcloud', 'ai-platform', 'jobs', 'describe', job_id,\n         '--project', PROJECT_ID,\n         '--format', 'json']\n  try:\n    output = subprocess.check_output(cmd, stderr=subprocess.STDOUT, timeout=3)\n  except subprocess.CalledProcessError as e:\n    logging.error(e.output)\n    print(e.output)\n  return json.loads(output)['state']\n\n\ndef _JobsCompleted(jobs):\n  \"\"\"Checks if all the jobs are completed.\"\"\"\n  all_done = True\n  for job in jobs:\n    if _GetTrainingJobState(job) not in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n      print('Waiting for job[https:\/\/console.cloud.google.com\/ai-platform\/jobs\/{0}?project={1}] to finish...'.format(job, PROJECT_ID))\n      all_done = False\n  return all_done\n\n\ndef _RetrieveAccuracy(job_id):\n  \"\"\"Retrices the accuracy of the trained model for a built-in algorithm job.\"\"\"\n  storage_client = storage.Client(project=PROJECT_ID)\n  bucket = storage_client.get_bucket(OUTPUT_BUCKET)\n  blob_name = os.path.join(OUTPUT_DIR, job_id, 'model\/deployment_config.yaml')\n  blob = storage.Blob(blob_name, bucket)\n  try: \n    blob.reload()\n    content = blob.download_as_string()\n    accuracy = float(yaml.safe_load(content)['labels']['accuracy']) \/ 100\n    step_count = int(yaml.safe_load(content)['labels']['global_step'])\n    return {_STEP_COUNT: step_count, _ACCURACY: accuracy}\n  except:\n    # Returns None if failed to load the built-in algo output file.\n    # It could be due to job failure and the trial will be `INFEASIBLE`\n    return None\n\n\ndef _GetJobMetrics(jobs):\n  accuracies_by_job_id = {}\n  for job in jobs:\n    accuracies_by_job_id[job] = _RetrieveAccuracy(job)\n  return accuracies_by_job_id\n\n\ndef _GetSuggestedParameterValue(trial, parameter, value_type):\n  param_found = [p for p in trial['parameters'] if p['parameter'] == parameter]\n  if param_found:\n    return param_found[0][value_type]\n  else:\n    return None\n\n\ndef _GenerateTrainingJobId(model_type, trial_id):\n  return _TRAINING_JOB_NAME_PATTERN.format(STUDY_ID, model_type, trial_id)\n\n\ndef _GetJobDir(job_id):\n  return os.path.join('gs:\/\/', OUTPUT_BUCKET, OUTPUT_DIR, job_id)\n\n\ndef _LinearCommand(job_id, learning_rate):\n  return ['gcloud', 'ai-platform', 'jobs', 'submit', 'training', job_id,\n          '--scale-tier', 'BASIC',\n          '--region', 'us-central1',\n          '--master-image-uri', _IMAGE_URIS['LINEAR'],\n          '--project', PROJECT_ID,\n          '--job-dir', _GetJobDir(job_id),\n          '--',\n          '--preprocess',\n          '--model_type=classification',\n          '--batch_size=250',\n          '--max_steps=1000',\n          '--learning_rate={}'.format(learning_rate),\n          '--training_data_path={}'.format(TRAINING_DATA_PATH)]\n\n\ndef _WideAndDeepCommand(job_id, learning_rate, dnn_learning_rate):\n  return ['gcloud', 'ai-platform', 'jobs', 'submit', 'training', job_id,\n          '--scale-tier', 'BASIC',\n          '--region', 'us-central1',\n          '--master-image-uri', _IMAGE_URIS['WIDE_AND_DEEP'],\n          '--project', PROJECT_ID,\n          '--job-dir', _GetJobDir(job_id),\n          '--',\n          '--preprocess',\n          '--test_split=0',\n          '--use_wide',\n          '--embed_categories',\n          '--model_type=classification',\n          '--batch_size=250',\n          '--learning_rate={}'.format(learning_rate),\n          '--dnn_learning_rate={}'.format(dnn_learning_rate),\n          '--max_steps=1000',\n          '--training_data_path={}'.format(TRAINING_DATA_PATH)]","92483431":"client_id = 'client1' #@param {type: 'string'}\nsuggestion_count_per_request =   2 #@param {type: 'integer'}\nmax_trial_id_to_stop =   4 #@param {type: 'integer'}\n\nprint('client_id: {}'.format(client_id))\nprint('suggestion_count_per_request: {}'.format(suggestion_count_per_request))\nprint('max_trial_id_to_stop: {}'.format(max_trial_id_to_stop))\n","5a077ed1":"current_trial_id = 0\nwhile current_trial_id < max_trial_id_to_stop:\n  # Request trials\n  resp = ml.projects().locations().studies().trials().suggest(\n    parent=trial_parent(STUDY_ID), \n    body={'client_id': client_id, 'suggestion_count': suggestion_count_per_request}).execute()\n  op_id = resp['name'].split('\/')[-1]\n\n  # Polls the suggestion long-running operations.\n  get_op = ml.projects().locations().operations().get(name=operation_name(op_id))\n  while True:\n      operation = get_op.execute()\n      if 'done' in operation and operation['done']:\n        break\n      time.sleep(1)\n\n  # Featches the suggested trials.\n  trials = []\n  for suggested_trial in get_op.execute()['response']['trials']:\n    trial_id = int(suggested_trial['name'].split('\/')[-1])\n    trial = ml.projects().locations().studies().trials().get(name=trial_name(STUDY_ID, trial_id)).execute()\n    if trial['state'] not in ['COMPLETED', 'INFEASIBLE']:\n      print(\"Trial {}: {}\".format(trial_id, trial))\n      trials.append(trial)\n\n  # Evaluates trials - Submit model training jobs using AI Platform Training built-in algorithms.\n  measurement_by_trial_id = EvaluateTrials(trials)\n\n  # Completes trials.\n  for trial in trials:\n    trial_id = int(trial['name'].split('\/')[-1])\n    current_trial_id = trial_id\n    measurement = measurement_by_trial_id[trial_id]\n    print((\"=========== Complete Trial: [{0}] =============\").format(trial_id))\n    if measurement:\n      # Completes trial by reporting final measurement.\n      ml.projects().locations().studies().trials().complete(\n        name=trial_name(STUDY_ID, trial_id), \n        body={'final_measurement' : measurement}).execute()\n    else:\n      # Marks trial as `infeasbile` if when missing final measurement.\n      ml.projects().locations().studies().trials().complete(\n        name=trial_name(STUDY_ID, trial_id), \n        body={'trial_infeasible' : True}).execute()","c8e7e472":"resp = ml.projects().locations().studies().trials().list(parent=trial_parent(STUDY_ID)).execute()\nprint(json.dumps(resp, indent=2, sort_keys=True))","47efedeb":"!pip install --upgrade google-cloud-language","bffabf1e":"from google.cloud import language_v1\nfrom google.cloud.language import enums\nfrom google.cloud.language import types","9ab48246":"language_client = language_v1.LanguageServiceClient(credentials=KaggleKernelCredentials())","f9054c0e":"text = u'This product is excellent! It works exactly like I would expect, look forward to recommending it to a friend'\ndocument = types.Document(\n    content=text,\n    type=enums.Document.Type.PLAIN_TEXT)\n\n# Detects the sentiment of the text\nsentiment = language_client.analyze_sentiment(document=document).document_sentiment\n\nprint('Text: {}'.format(text))\nprint('Sentiment: {}, {}'.format(sentiment.score, sentiment.magnitude))","c063080b":"# Try GCP ML APIs","10aa5fa7":"## Create the study","6c16f49d":"# FINISHED! End-to-end Vizier and example of Natural Language API","94ab69e0":"# Google CloudAI: Vizier on Kaggle Demo","a0125cea":"We will start off with the natural language APIs","df9bc9ef":"## Set input\/output parameters","0ffe57e5":"## Metric Evaluation","58c4e138":"Pulling the getting started content from: https:\/\/cloud.google.com\/ai-platform\/optimizer\/docs\/overview?hl=en","f0822003":"### Set Credentials for Vizier and GCP Project","1bb14370":"### Install the python libraries necessary","7a02c49f":"### Run Trials","800b4474":"### Define Helper Functions","786e837a":"## Study Configuration","e980a864":"### List out all trials and status"}}