{"cell_type":{"5e0fa433":"code","82a232ad":"code","39e939be":"code","3fede7d5":"code","160218bb":"code","625cde59":"code","74e4a39d":"code","7c26ddb9":"code","87687b31":"code","84a561d8":"code","ff249d25":"code","af7e18a4":"code","31511b49":"code","d70df0ed":"code","a86dbf64":"code","24463f54":"code","67d59215":"code","fca0c3ec":"code","2f52be9b":"code","d3f46847":"code","ef6435ab":"code","d1fc51e3":"code","cc02d50e":"code","6edcc58b":"code","9bcb4b1d":"code","80fff734":"code","e5f0bc6c":"code","434e2c97":"code","c1cc5c1b":"code","f20e5db8":"code","a9a68a04":"code","7ed1c097":"code","c7ff3c33":"code","1e6dba65":"code","aa149044":"code","aa3dbe74":"code","b8f1fc12":"code","416298e9":"code","6c1fbb19":"code","5a6e666c":"code","3763a4a0":"code","96f18044":"code","69b968ca":"code","87b7e978":"code","28c548c9":"code","fef7cd4e":"code","a2b5d9fc":"code","a2f79129":"code","12c42de5":"code","6454fb0e":"code","d7364ced":"code","647b4d7c":"code","78776a0b":"code","9d5f86ca":"code","1abab7d5":"code","5712cf60":"code","b3ecd5ee":"code","daa5500e":"code","980b78e9":"code","7af385c6":"code","93fa1e69":"code","e7740762":"code","961b1fa2":"code","9d1304b2":"code","b666db84":"code","f3ba2f1e":"code","3e7c5659":"code","0ffede5d":"code","51956934":"code","75b1889a":"code","b7673d75":"code","dddc17d5":"code","0d4bbdff":"code","2bd8de12":"code","337647b5":"code","f5e94f4e":"code","16e76a65":"code","6f35e7f7":"code","f3e02582":"code","383dc61f":"code","ec845280":"code","a038670b":"code","ac476f7d":"code","caab1886":"code","71b4d6fe":"code","f45e582a":"code","53b51386":"code","9e219ba5":"code","4d994d04":"code","5438de9e":"code","01594f85":"code","8b3fa864":"code","a23d7954":"code","b8c53ff9":"code","35a5cbb5":"code","9e2e7af2":"code","56af93d1":"code","68524018":"code","955ae417":"code","e6b7619d":"code","c318f50f":"code","cc5cb05a":"code","d2e2bc10":"code","dd871ebe":"code","933f99f6":"code","657e3f8b":"code","6516e691":"code","5f7c8ba8":"code","878204b9":"code","e5d4d5ef":"code","3646c291":"code","ab044e61":"code","a55ddf3e":"code","2e95d8b7":"code","152ab4a4":"code","5024d410":"code","91fc257e":"code","9cbfc1c6":"code","26cd9bfe":"code","8e034e2e":"code","95e90657":"code","905f052d":"code","51f83e40":"code","b9e37ae5":"code","dd3758ce":"code","a0c94c04":"code","edc7ceac":"code","98b362ad":"code","e8a115b4":"code","b910e98f":"code","5c21edb0":"code","50050e09":"code","5e9cc1dc":"code","926909a0":"markdown","b8e3fb21":"markdown","bdcc4352":"markdown","9a680a5e":"markdown","24a7403c":"markdown","283af58c":"markdown","19fa269a":"markdown","b3037f35":"markdown","871b65d1":"markdown","6453f7c5":"markdown","930d4ff4":"markdown","b002349a":"markdown","76e83d46":"markdown","e480651d":"markdown","5541122a":"markdown","046c9bb4":"markdown","8f442fd0":"markdown","34fcb1cc":"markdown","cb6876e2":"markdown","53874ad5":"markdown","ec7cd080":"markdown","36f7a5f1":"markdown","3608bcaf":"markdown","9cfa4464":"markdown","a379ccc5":"markdown","37da47d7":"markdown","a0bfcab1":"markdown","05940567":"markdown","28bc487e":"markdown","f8c23e74":"markdown","c834fd04":"markdown","2e44a10c":"markdown","385f484a":"markdown","2abf5d58":"markdown","ff1923e8":"markdown","1075032b":"markdown","141b0bb1":"markdown","b280f784":"markdown","d093e346":"markdown","13a6cd14":"markdown","35550490":"markdown","0250d0de":"markdown","6937f68d":"markdown","1002c8ca":"markdown","951ef6fa":"markdown","7133d0f4":"markdown","30a6e9d8":"markdown","ae4054fb":"markdown","b14d429a":"markdown","73a24bd6":"markdown","d4e82e88":"markdown","e351755f":"markdown","14e348dd":"markdown","e86ce1fd":"markdown","ec989cda":"markdown","c7896d53":"markdown","7ccfcc26":"markdown","4a448341":"markdown","035da63c":"markdown","6a143e4c":"markdown","7759d1f4":"markdown","6c1affce":"markdown","16657f79":"markdown","6514450f":"markdown","e2b5778f":"markdown","e3c9d15b":"markdown","945e6a19":"markdown","e2f5a31c":"markdown","dcd598bf":"markdown","91171f70":"markdown","ec3664d6":"markdown","2c809090":"markdown","21b2a1f0":"markdown","28b33b99":"markdown","adc52577":"markdown","99c403a9":"markdown","cc776d50":"markdown","fe58a0b3":"markdown","16e76649":"markdown","f068d3ce":"markdown","5ce9d940":"markdown","d06dea35":"markdown","902a7c7f":"markdown","6c12093b":"markdown","9f7e9f5e":"markdown","12ab4868":"markdown","6e143f4b":"markdown","47c9834b":"markdown"},"source":{"5e0fa433":"### IMPORT: ------------------------------------\nimport scipy.stats as stats \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore') # To supress warnings\n # set the background for the graphs\nfrom scipy.stats import skew\nplt.style.use('ggplot')\nimport missingno as msno # to get visualization on missing values\nfrom sklearn.model_selection import train_test_split # Sklearn package's randomized data splitting function\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nimport math\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.max_rows', 300)\npd.set_option('display.max_colwidth',400)\npd.set_option('display.float_format', lambda x: '%.5f' % x) # To supress numerical display in scientific notations\nimport statsmodels.api as sm\nprint(\"Load Libraries- Done\")","82a232ad":"#Reading the csv file  used car data.csv \ndata_path='..\/input\/cars4u\/used_cars_data.csv'\ndf=pd.read_csv(data_path,index_col=0)\ncars=df.copy()\nprint(f'There are {cars.shape[0]} rows and {cars.shape[1]} columns') # fstring \n","39e939be":"# inspect data, print top 5 \ncars.head(5)","3fede7d5":"# bottom 5 rows:\ncars.tail(5)","160218bb":"#get the size of dataframe\nprint (\"Rows     : \" , cars.shape[0])  #get number of rows\/observations\nprint (\"Columns  : \" , cars.shape[1]) #get number of columns\nprint (\"#\"*40,\"\\n\",\"Features : \\n\\n\", cars.columns.tolist()) #get name of columns\/features\nprint (\"#\"*40,\"\\nMissing values :\\n\\n\", cars.isnull().sum().sort_values(ascending=False))\nprint( \"#\"*40,\"\\nPercent of missing :\\n\\n\", round(cars.isna().sum() \/ cars.isna().count() * 100, 2)) # looking at columns with most Missing Values\nprint (\"#\"*40,\"\\nUnique values :  \\n\\n\", cars.nunique())  #  count of unique values\n","625cde59":"cars.info()","74e4a39d":"#Visualize missing values\nmsno.bar(cars)\n","7c26ddb9":"# Making a list of all categorical variables\ncat_col = [\n    \"Fuel_Type\",\n    \"Location\",\n    \"Transmission\",\n    \"Seats\",\n    \"Year\",\n    \"Owner_Type\",\n    \n]\n# Printing number of count of each unique value in each column\nfor column in cat_col:\n    print(cars[column].value_counts())\n    print(\"#\" * 40)\n","87687b31":"#np.random.seed(9)\ncars[['Engine','Power','Mileage']].sample(10)","84a561d8":"typeoffuel=['CNG','LPG']\ncars.loc[cars.Fuel_Type.isin(typeoffuel)].head(10)","ff249d25":"cars[cars.Mileage.isnull()==True]","af7e18a4":"cars[\"Mileage\"] = cars[\"Mileage\"].str.rstrip(\" kmpl\")\ncars[\"Mileage\"] = cars[\"Mileage\"].str.rstrip(\" km\/g\")\n","31511b49":"#remove units\ncars[\"Engine\"] = cars[\"Engine\"].str.rstrip(\" CC\")\n","d70df0ed":"#remove bhp and replace null with nan\ncars[\"Power\"] = cars[\"Power\"].str.rstrip(\" bhp\")\ncars[\"Power\"]= cars[\"Power\"].replace(regex=\"null\", value = np.nan)\n","a86dbf64":"#verify the data\nnum=['Engine','Power','Mileage']\ncars[num].sample(20)","24463f54":"cars.query(\"Power == '0.0'\")['Power'].count()\n","67d59215":"cars.query(\"Mileage == '0.0'\")['Mileage'].count()\n","fca0c3ec":"cars.loc[cars[\"Mileage\"]=='0.0','Mileage']=np.nan","2f52be9b":"cars.loc[cars[\"Engine\"]=='0.0','Engine'].count()","d3f46847":"cars[num].nunique()","ef6435ab":"cars[num].isnull().sum()","d1fc51e3":"cars.query(\"Seats == 0.0\")['Seats']","cc02d50e":"#seats cannot be 0 so changing it to nan and will be handled in missing value\ncars.loc[3999,'Seats'] =np.nan\n","6edcc58b":"# Create a new column after splitting the New_Price values.\nimport re\n\nnew_price_num = []\n\n# Regex for numeric + \" \" + \"Lakh\"  format\nregex_power = \"^\\d+(\\.\\d+)? Lakh$\"\n\nfor observation in df[\"New_Price\"]:\n    if isinstance(observation, str):\n        if re.match(regex_power, observation):\n            new_price_num.append(float(observation.split(\" \")[0]))\n        else:\n            # To detect if there are any observations in the column that do not follow [numeric + \" \" + \"Lakh\"]  format\n            # that we see in the sample output\n            print(\n                \"The data needs furthur processing.mismatch \",\n                observation,\n            )\n    else:\n        # If there are any missing values in the New_Price column, we add missing values to the new column\n        new_price_num.append(np.nan)","9bcb4b1d":"new_price_num = []\n\nfor observation in df[\"New_Price\"]:\n    if isinstance(observation, str):\n        if re.match(regex_power, observation):\n            new_price_num.append(float(observation.split(\" \")[0]))\n        else:\n            # Converting values in Crore to lakhs\n            new_price_num.append(float(observation.split(\" \")[0]) * 100)\n    else:\n        # If there are any missing values in the New_Price column, we add missing values to the new column\n        new_price_num.append(np.nan)\n\n# Add the new column to the data\ncars[\"new_price_num\"] = new_price_num\n\n# Checking the new dataframe\ncars.head(5)  # Looks ok","80fff734":"#converting object data type to category data type\ncars[\"Fuel_Type\"] = cars[\"Fuel_Type\"].astype(\"category\")\ncars[\"Transmission\"] = cars[\"Transmission\"].astype(\"category\")\ncars[\"Owner_Type\"] = cars[\"Owner_Type\"].astype(\"category\")\n#converting datatype  \ncars[\"Mileage\"] = cars[\"Mileage\"].astype(float)\ncars[\"Power\"] = cars[\"Power\"].astype(float)\ncars[\"Engine\"]=cars[\"Engine\"].astype(float)","e5f0bc6c":"cars.describe().T","434e2c97":"cars['Current_year']=2021\ncars['Ageofcar']=cars['Current_year']-cars['Year']\ncars.drop('Current_year',axis=1,inplace=True)\ncars.head()","c1cc5c1b":"#dropping rows with name as null\ncars['Name'] = cars.dropna(subset=['Name'])","f20e5db8":"#As mentioned in dataset car name has Brand and model so extracting it ,This can help to fill missing values of price column as brand \ncars['Brand'] = cars['Name'].str.split(' ').str[0] #Separating Brand name from the Name\ncars['Model'] = cars['Name'].str.split(' ').str[1] + cars['Name'].str.split(' ').str[2]\n","a9a68a04":"cars.Brand.unique()","7ed1c097":"col=['ISUZU','Isuzu','Mini','Land']\n#correcting brand names\ncars[cars.Brand.isin(col)].sample(5)\n","c7ff3c33":"cars.info()","1e6dba65":"#changing brandnames\ncars.loc[cars.Brand == 'ISUZU','Brand']='Isuzu'\ncars.loc[cars.Brand=='Mini','Brand']='Mini Cooper'\ncars.loc[cars.Brand=='Land','Brand']='Land Rover'\n#cars['Brand']=cars[\"Brand\"].astype(\"category\")","aa149044":"cars.Brand.nunique()","aa3dbe74":"cars.groupby(cars.Brand).size().sort_values(ascending =False)","b8f1fc12":"cars.Model.isnull().sum()","416298e9":"#drop row with no model\ncars.dropna(subset=['Model'],axis=0,inplace=True)","6c1fbb19":"cars.Model.nunique()","5a6e666c":"cars.groupby('Model')['Model'].size().nlargest(30)","3763a4a0":"cars.info()","96f18044":"cars.describe()","69b968ca":"plt.style.use('ggplot')\n#select all quantitative columns for checking the spread\nnumeric_columns = cars.select_dtypes(include=np.number).columns.tolist()\nplt.figure(figsize=(20,25))\n\nfor i, variable in enumerate(numeric_columns):\n                     plt.subplot(10,3,i+1)\n                       \n                     sns.distplot(cars[variable],kde=False,color='blue')\n                     plt.tight_layout()\n                     plt.title(variable)\n","87b7e978":"cat_columns=['Location','Fuel_Type','Transmission', 'Owner_Type', 'Brand'] #cars.select_dtypes(exclude=np.number).columns.tolist()\n\nplt.figure(figsize=(15,21))\n\nfor i, variable in enumerate(cat_columns):\n                     plt.subplot(4,2,i+1)\n                     order = cars[variable].value_counts(ascending=False).index    \n                     ax=sns.countplot(x=cars[variable], data=cars , order=order ,palette='viridis')\n                     for p in ax.patches:\n                           percentage = '{:.1f}%'.format(100 * p.get_height()\/len(cars[variable]))\n                           x = p.get_x() + p.get_width() \/ 2 - 0.05\n                           y = p.get_y() + p.get_height()\n                           plt.annotate(percentage, (x, y),ha='center')\n                     plt.xticks(rotation=90)\n                     plt.tight_layout()\n                     plt.title(variable)\n","28c548c9":"numeric_columns= numeric_columns = cars.select_dtypes(include=np.number).columns.tolist()\nplt.figure(figsize=(13,17))\n\nfor i, variable in enumerate(numeric_columns):\n                     plt.subplot(5,2,i+1)\n                     sns.scatterplot(x=cars[variable],y=cars['Price']).set(title='Price vs '+ variable)\n                     #plt.xticks(rotation=90)\n                     plt.tight_layout()","fef7cd4e":"cars.isnull().sum()","a2b5d9fc":"# counting the number of missing values per row\nnum_missing = cars.isnull().sum(axis=1)\nnum_missing.value_counts()","a2f79129":"#Investigating how many missing values per row are there for each variable\nfor n in num_missing.value_counts().sort_index().index:\n    if n > 0:\n        print(\"*\" *30,f'\\nFor the rows with exactly {n} missing values, NAs are found in:')\n        n_miss_per_col = cars[num_missing == n].isnull().sum()\n        print(n_miss_per_col[n_miss_per_col > 0])\n        print('\\n\\n')","12c42de5":"cars[num_missing==7]","6454fb0e":"col=['Engine','Power','Mileage']\ncars[col].isnull().sum()","d7364ced":"cars.groupby(['Name','Year'])['Engine'].median().head(30)\n","647b4d7c":"cars['Engine']=cars.groupby(['Name','Year'])['Engine'].apply(lambda x:x.fillna(x.median()))\ncars['Power']=cars.groupby(['Name','Year'])['Power'].apply(lambda x:x.fillna(x.median()))\ncars['Mileage']=cars.groupby(['Name','Year'])['Mileage'].apply(lambda x:x.fillna(x.median()))","78776a0b":"col=['Engine','Power','Mileage']\ncars[col].isnull().sum()","9d5f86ca":"cars.groupby(['Brand','Model'])['Engine'].median().head(10)","1abab7d5":"#chosing Median to fill the the missing value as there are many outliers, \n#grouping by model and year to get  more granularity and more accurate Engine and then fillig with median\ncars['Engine']=cars.groupby(['Brand','Model'])['Engine'].apply(lambda x:x.fillna(x.median()))\n","5712cf60":"#chosing Median to fill the the missing value as there are many outliers, \n#grouping by model to get more granularity and more accurate Engine\ncars['Power']=cars.groupby(['Brand','Model'])['Power'].apply(lambda x:x.fillna(x.median()))","b3ecd5ee":"#chosing Median to fill the the missing value as there are many outliers, \n#grouping by model to get more granularity and more accurate Engine\ncars['Mileage']=cars.groupby(['Brand','Model'])['Mileage'].apply(lambda x:x.fillna(x.median()))\n","daa5500e":"col=['Engine','Power','Mileage']\ncars[col].isnull().sum()\n","980b78e9":"cars.groupby(['Model','Year'])['Engine'].agg({'median','mean','max'}).sort_values(by='Model',ascending='True').head(10)","7af385c6":"cars.groupby(['Brand','Engine'])['Power'].agg({'mean','median','max'}).head(10)","93fa1e69":"cars['Seats'].isnull().sum()","e7740762":"cars['Seats']=cars.groupby(['Name'])['Seats'].apply(lambda x:x.fillna(x.median()))","961b1fa2":"cars['Seats'].isnull().sum()","9d1304b2":"cars['Seats']=cars.groupby(['Model'])['Seats'].apply(lambda x:x.fillna(x.median()))","b666db84":"cars['Seats'].isnull().sum()","f3ba2f1e":"cars[cars['Seats'].isnull()==True].head(10)","3e7c5659":"#most of cars are 5 seater so fillrest of 23 by 5\ncars['Seats']=cars['Seats'].fillna(5)","0ffede5d":"cars['Seats'].isnull().sum()","51956934":"\ncars[\"Location\"] = cars[\"Location\"].astype(\"category\")\ncars['Brand'] =cars['Brand'].astype(\"category\")","75b1889a":"cars.info()","b7673d75":"#For better granualarity grouping has there would be same car model present so filling with a median value brings it more near to real value\ncars['new_price_num']=cars.groupby(['Name','Year'])['new_price_num'].apply(lambda x:x.fillna(x.median()))","dddc17d5":"cars.new_price_num.isnull().sum()","0d4bbdff":"cars['new_price_num']=cars.groupby(['Name'])['new_price_num'].apply(lambda x:x.fillna(x.median()))","2bd8de12":"cars.new_price_num.isnull().sum()","337647b5":"cars['new_price_num']=cars.groupby(['Brand','Model'])['new_price_num'].apply(lambda x:x.fillna(x.median()))","f5e94f4e":"cars.new_price_num.isnull().sum()","16e76a65":"cars['new_price_num']=cars.groupby(['Brand'])['new_price_num'].apply(lambda x:x.fillna(x.median()))","6f35e7f7":"cars.drop(['New_Price'],axis=1,inplace=True)","f3e02582":"cars.new_price_num.isnull().sum()","383dc61f":"cars.groupby(['Brand'])['new_price_num'].median().sort_values(ascending=False)","ec845280":"cars.isnull().sum()","a038670b":"\ncols1 = [\"Power\",\"Mileage\",\"Engine\"]\n\nfor ii in cols1:\n    cars[ii] = cars[ii].fillna(cars[ii].median())","ac476f7d":"#dropping remaining rows\n#cannot further fill this rows so dropping them\n\ncars.dropna(inplace=True,axis=0)","caab1886":"cars.isnull().sum()","71b4d6fe":"cars.head()","f45e582a":"cars.isnull().sum()","53b51386":"df.shape ","9e219ba5":"cars.groupby(['Brand'])['Price'].agg({'median','mean','max'})","4d994d04":"#using business knowledge to create class \nLow=['Maruti', \n     'Hyundai',\n     'Ambassdor',\n     'Hindustan',\n     'Force',\n     'Chevrolet',\n     'Fiat',\n     'Tata',\n     'Smart',\n     'Renault',\n     'Datsun',\n     'Mahindra',\n     'Skoda',\n     'Ford',\n     'Toyota',\n     'Isuzu',\n     'Mitsubishi','Honda']\n\nHigh=['Audi',\n      'Mini Cooper',\n      'Bentley',\n      'Mercedes-Benz',\n      'Lamborghini',\n      'Volkswagen',\n      'Porsche',\n      'Land Rover',\n      'Nissan',\n      'Volvo',\n      'Jeep',\n      'Jaguar',\n      'BMW']# more than 30lakh","5438de9e":"def classrange(x):\n    if x in Low:\n        return \"Low\"\n    elif x in High:\n        return \"High\"\n    else: \n        return x","01594f85":"cars['Brand_Class'] = cars['Brand'].apply(lambda x: classrange(x))","8b3fa864":"cars['Brand_Class'].unique()","a23d7954":"cars['Engine']=cars['Engine'].astype(int)\ncars['Brand_Class']=cars[\"Brand_Class\"].astype('category')","b8c53ff9":"plt.figure(figsize=(10,8))\nsns.heatmap(cars.corr(),annot=True ,cmap=\"YlGnBu\" )\nplt.show()","35a5cbb5":"sns.pairplot(data=cars , corner=True)\nplt.show()","9e2e7af2":"# understand relation ship of Engine vs Price and Transmimssion\nplt.figure(figsize=(10,7))\n\nplt.title(\"Price VS Engine based on Transmission\")\nsns.scatterplot(y='Engine', x='Price', hue='Transmission', data=cars)","56af93d1":" #understand relationship betweem Price and Power\nplt.figure(figsize=(10,7))\nplt.title(\"Price vs Power based on Transmission\")\nsns.scatterplot(y='Power', x='Price', hue='Transmission', data=cars)","68524018":"# Understand the relationships  between mileage and Price\nsns.scatterplot(y='Mileage', x='Price', hue='Transmission', data=cars)","955ae417":"# Impact of years on price \nplt.figure(figsize=(10,7))\nplt.title(\"Price based on manufacturing Year of model\")\nsns.lineplot(x='Year', y='Price',hue='Transmission',\n             data=cars)\n","e6b7619d":"# Impact of years on price \nplt.figure(figsize=(10,7))\nplt.title(\"Price Vs Year VS FuelType\")\nsns.lineplot(x='Year', y='Price',hue='Fuel_Type',\n             data=cars)","c318f50f":"plt.figure(figsize=(10,7))\nplt.title(\"Price Vs Year VS Owner_Type\")\nsns.lineplot(x='Year', y='Price',hue='Owner_Type',\n             data=cars)","cc5cb05a":"cars[(cars[\"Owner_Type\"]=='Third') & (cars[\"Year\"].isin([2010]))].sort_values(by='Price',ascending =False)","d2e2bc10":"cars.describe()","dd871ebe":"# Understand relationships  between price and mileage\nplt.figure(figsize=(10,7))\nplt.title(\"Price Vs Mileage\")\nsns.scatterplot(y='Price', x='Mileage', hue='Fuel_Type', data=cars)","933f99f6":"#Price and seats \nplt.figure(figsize=(20,15))\nsns.set(font_scale=2)\nsns.barplot(x='Seats', y='Price', data=cars)\nplt.grid()","657e3f8b":"#Price and LOcation \nplt.figure(figsize=(20,15))\nsns.set(font_scale=2)\nsns.barplot(x='Location', y='Price', data=cars)\nplt.grid()","6516e691":"#Price and band \nplt.figure(figsize=(20,15))\nsns.set(font_scale=2)\nsns.boxplot(x='Price', y='Brand', data=cars)\nplt.grid()","5f7c8ba8":"sns.relplot(data=cars, y='Price',x='Mileage',hue='Transmission',aspect=1,height=5)","878204b9":"sns.relplot(data=cars, y='Price',x='Year',col='Owner_Type',hue='Transmission',aspect=1,height=5)","e5d4d5ef":"sns.relplot(data=cars, y='Price',x='Engine',col='Transmission',aspect=1,height=6,hue=\"Fuel_Type\")","3646c291":"\nsns.relplot(data=cars, y='Price',x='Ageofcar',col='Transmission',aspect=1,height=6)","ab044e61":"# check distrubution if skewed. If distrubution is skewed , it is advice to use log transform\ncols_to_log = cars.select_dtypes(include=np.number).columns.tolist()\nfor colname in cols_to_log:\n    sns.distplot(cars[colname], kde=True)\n    plt.show()","a55ddf3e":"\ndef Perform_log_transform(df,col_log):\n    \"\"\"#Perform Log Transformation of dataframe , and list of columns \"\"\"\n    for colname in col_log:\n        df[colname + '_log'] = np.log(df[colname])\n    #df.drop(col_log, axis=1, inplace=True)\n    df.info()","2e95d8b7":"#This needs to be done before the data is split\nPerform_log_transform(cars,['Kilometers_Driven','Price'])","152ab4a4":"\ncars.drop(['Name','Model','Year','Brand','new_price_num'],axis=1,inplace=True)","5024d410":"cars.info()","91fc257e":"X = cars.drop([\"Price\", \"Price_log\"], axis=1)\ny = cars[[\"Price_log\", \"Price\"]]","9cbfc1c6":"def encode_cat_vars(x):\n    x = pd.get_dummies(\n        x,\n        columns=x.select_dtypes(include=[\"object\", \"category\"]).columns.tolist(),\n        drop_first=True,\n    )\n    return x","26cd9bfe":"#Dummy variable creation is done before spliting the data , so all the different categories are covered\n#create dummy variable\nX = encode_cat_vars(X)\nX.head()","8e034e2e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nX_train.reset_index()\nprint(\"X_train:\",X_train.shape)\nprint(\"X_test:\",X_test.shape)\nprint(\"y_train:\",y_train.shape)\nprint(\"y_test:\",y_test.shape)","95e90657":"# Statsmodel api does not add a constant by default. We need to add it explicitly.\nX_train = sm.add_constant(X_train)\n# Add constant to test data\nX_test = sm.add_constant(X_test)\n\n\ndef build_ols_model(train):\n    # Create the model\n    olsmodel = sm.OLS(y_train[\"Price_log\"], train)\n    return olsmodel.fit()","905f052d":"#fit statmodel\nolsmodel1 = build_ols_model(X_train)\nprint(olsmodel1.summary())","51f83e40":"import math\n\n# RMSE\ndef rmse(predictions, targets):\n    return np.sqrt(((targets - predictions) ** 2).mean())\n\n\n# MAPE\ndef mape(predictions, targets):\n    return np.mean(np.abs((targets - predictions)) \/ targets) * 100\n\n\n# MAE\ndef mae(predictions, targets):\n    return np.mean(np.abs((targets - predictions)))\n\n\n# Model Performance on test and train data\ndef model_pref(olsmodel, x_train, x_test):\n\n    # Insample Prediction\n    y_pred_train_pricelog = olsmodel.predict(x_train)\n    y_pred_train_Price = y_pred_train_pricelog.apply(math.exp)\n    y_train_Price = y_train[\"Price\"]\n\n    # Prediction on test data\n    y_pred_test_pricelog = olsmodel.predict(x_test)\n    y_pred_test_Price = y_pred_test_pricelog.apply(math.exp)\n    y_test_Price = y_test[\"Price\"]\n\n    print(\n        pd.DataFrame(\n            {\n                \"Data\": [\"Train\", \"Test\"],\n                \"RMSE\": [\n                    rmse(y_pred_train_Price, y_train_Price),\n                    rmse(y_pred_test_Price, y_test_Price),\n                ],\n                \"MAE\": [\n                    mae(y_pred_train_Price, y_train_Price),\n                    mae(y_pred_test_Price, y_test_Price),\n                ],\n                \"MAPE\": [\n                    mape(y_pred_train_Price, y_train_Price),\n                    mape(y_pred_test_Price, y_test_Price),\n                ],\n            }\n        )\n    )\n\n\n# Checking model performance\nmodel_pref(olsmodel1, X_train, X_test)  # High Overfitting.","b9e37ae5":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\n\ndef checking_vif(train):\n    vif = pd.DataFrame()\n    vif[\"feature\"] = train.columns\n\n    # calculating VIF for each feature\n    vif[\"VIF\"] = [\n        variance_inflation_factor(train.values, i) for i in range(len(train.columns))\n    ]\n    return vif\n","dd3758ce":"# Check VIF\nprint(checking_vif(X_train))","a0c94c04":"X_train1=X_train.drop(['Engine'],axis=1)\nX_test1=X_test.drop(['Engine'],axis=1)\nolsmodel2= build_ols_model(X_train1)\n\nprint(olsmodel2.summary())\n\n# Checking model performance\nmodel_pref(olsmodel2, X_train1, X_test1)","edc7ceac":"print(checking_vif(X_train1))","98b362ad":"residuals = olsmodel2.resid\nnp.mean(residuals)","e8a115b4":"import statsmodels.stats.api as sms\nfrom statsmodels.compat import lzip\n\nname = [\"F statistic\", \"p-value\"]\ntest = sms.het_goldfeldquandt(residuals, X_train1)\nlzip(name, test)","b910e98f":"# predicted values\nfitted = olsmodel2.fittedvalues\n\n# sns.set_style(\"whitegrid\")\nsns.residplot(fitted, residuals, color=\"purple\", lowess=True)\nplt.xlabel(\"Fitted Values\")\nplt.ylabel(\"Residual\")\nplt.title(\"Residual PLOT\")\nplt.show()","5c21edb0":"sns.distplot(residuals)","50050e09":"# Plot q-q plot of residuals\nimport pylab\nimport scipy.stats as stats\n\nstats.probplot(residuals, dist=\"norm\", plot=pylab)\nplt.show()","5e9cc1dc":"print(olsmodel2.summary())\n# Checking model performance\nmodel_pref(olsmodel2, X_train1, X_test1)","926909a0":"### Mileage","b8e3fb21":"### Calculating missing values in each row","bdcc4352":"\n    \n* Both the R-squared and Adjusted R squared of our model are very high. This is a clear indication that we have been able to create a very good model that is able to explain variance in price of used cars for upto 89% \n    \n* The model is not an underfitting or overfitting model.\n    \n* To be able to make statistical inferences from our model, we will have to test that the linear regression assumptions are followed.\n    \n* Before we move on to assumption testing, we'll do a quick performance check on the test data.","9a680a5e":"Need to check the reason for spike in price  for third owner and model in 2010.","24a7403c":"# Insights based on EDA","283af58c":"Power has some values as \"nullbhp\" .Mileage also has some observations as 0. For fuel type and CNG and LPG mileage is measured in km\/kg where as for other type it is measured in kmpl. Since  those units are in  km for both of them no need of conversion . Dropping units from mileages,Engine and Power.","19fa269a":"We can start filling missing values by grouping  name and year and fill in missing values. with median.","b3037f35":"Assumptions 4 is satisfied by our olsmodel2. There is no pattern in the residual vs fitted values plot.","871b65d1":"# Read and Understand data","6453f7c5":"## Data Set\n<br>\n<p style = \"font-size : 15px ; color: black;font-family:TimesNewRoman\">\n    \n1. S.No. : Serial Number<br>\n    \n2. Name : Name of the car which includes Brand name and Model name<br>\n    \n3. Location : The location in which the car is being sold or is available for purchase Cities<b<br>r>\n    \n4. Year : Manufacturing year of the car<br>\n    \n5. Kilometers_driven : The total kilometers driven in the car by the previous owner(s) in KM.<br>\n    \n6. Fuel_Type : The type of fuel used by the car. (Petrol, Diesel, Electric, CNG, LPG)<br>\n    \n7. Transmission : The type of transmission used by the car. (Automatic \/ Manual)<br>\n    \n8. Owner : Type of ownership<br>\n    \n9. Mileage : The standard mileage offered by the car company in kmpl or km\/kg<br>\n    \n10. Engine : The displacement volume of the engine in CC.<br>\n    \n11. Power : The maximum power of the engine in bhp.<br>\n    \n12. Seats : The number of seats in the car.<br>\n    \n13. New_Price : The price of a new car of the same model in INR Lakhs.(1 Lakh = 100, 000)<br>\n    \n14. Price : The price of the used car in INR Lakhs (1 Lakh = 100, 000)<br>\n<\/p>","930d4ff4":"Brand names like ISUZU and Isuzu are same and needs to be corrected. Land, Mini seems to be incorrect. So correcting brand names.","b002349a":"### Power","76e83d46":"### Variables that are correlated with Price variable","e480651d":"There are 726 unique models and Swift Dzire is most popular Model.","5541122a":"### Creating dummy variables","046c9bb4":"# Handling missing values","8f442fd0":"Datatype for Engine ,Power and Mileage  are object because of unit assigned ,so striping  units.","34fcb1cc":"#### Price Vs Seat","cb6876e2":"Distrubtions are right skewed , using Log transform can help in normalization","53874ad5":"\n* Homoscedacity - If the residuals are symmetrically distributed across the regression line , then the data is said to homoscedastic.\n\n* Heteroscedasticity- - If the residuals are not symmetrically distributed across the regression line, then the data is said to be heteroscedastic. In this case the residuals can form a funnel shape or any other non symmetrical shape.\n\nWe'll use `Goldfeldquandt Test` to test the following hypothesis\n\nNull hypothesis : Residuals are homoscedastic\nAlternate hypothesis : Residuals have hetroscedasticity\n\nalpha = 0.05 ","ec7cd080":"# Recommendations","36f7a5f1":"#### Price Vs Location","3608bcaf":"<p style = \"font-size : 20px ; color: black;font-family:TimesNewRoman\">\n    <b>Table of Contents<\/b>\n<\/p><br>\n<p style = \"font-size : 15px ; color: black;font-family:TimesNewRoman\">\n    \n- [Data Set](#Data-Set)\n\n-  [Problem](#Problem)\n\n- [Libraries](#Libraries)\n\n- [Read and Understand Data](#Read-and-Understand-data)\n\n- [Data Preprocessing](#Data-Preprocessing)\n    \n- [Basic EDA](#EDA)    \n    \n- [Handling Missing Value](#Handling-missing-values)\n    \n- [Exploratory Data Analysis](#Exploratory-Data-Analysis) \n    \n- [Insights based on EDA](#Insights-based-on-EDA)\n  \n- [Model Building](#Model-Building)\n    \n- [Test Assumptions](#Test-Assumptions) \n    \n- [Recommendation](#Recommendation)\n\n<br>\n","9cfa4464":"Brands do play an important role in Car selection and Prices. So extracting brand names from the Name.","a379ccc5":"# EDA\n","37da47d7":"<p style = \"font-size : 20px ; color: blue;font-family:TimesNewRoman\">\n    <b>Observations<\/b><\/p>\n   \n   **Car Profile**\n    \n-  ~71 % cars available for sell have manual Transmission.\n- ~82 % cars are First owned cars.\n- ~39% of car available for sale are from  Maruti & Hyundai brands.\n-  ~53% of car being sold\/avialable for purchase  have fuel type as Diesel .\n- Mumbai has highest numbers of car availabe for purchase whereas Ahmedabad has least\n- Most of the cars are 5 seaters.\n- Car being sold\/available for purchase are in  2 - 23 years old\n- ~ 71% car are lower price range car.","a0bfcab1":"#### Price  Vs Engine Vs Transmission","05940567":"### Processing Engine,Power ,Mileage columns","28bc487e":"   \n* Root Mean Squared Error of train and test data is not  different, indicating that our model is not overfitting the train data.\n    \n* Mean Absolute Error indicates that our current model is able to predict used cars prices within mean error of 2.5 lakhs on test data.\n    \n* The units of both RMSE and MAE are same - Lakhs in this case. But RMSE is greater than MAE because it peanalises the outliers more.\n    \n* Mean Absolute Percentage Error is ~23% on the test data.","f8c23e74":"###  Processing Seats","c834fd04":"### Checking Assumption 2: Mean of residuals should be 0","2e44a10c":"# Test Assumptions","385f484a":"### Engine ","2abf5d58":"### Checking Assumption 1: No Multicollinearity \n\nWe will use VIF, to check if there is multicollinearity in the data.\n\nFeatures having a VIF score >5 will be dropped\/treated till all the features have a VIF score <5","ff1923e8":"# Processing New Price","1075032b":"The observation is for The Porsche Panamera is expensive and luxury car so the data is valid.","141b0bb1":"# Feature Enginering","b280f784":"### Processing Name column","d093e346":"<p style = \"font-size : 20px ; color: blue;font-family:TimesNewRoman\">\n    <b>  Observations<\/b><\/p>\n\n - Maximum car being sold have fuel type as Diesel.\n - Mumbai has highest numbers of car availabe for purchase.\n - 5204 cars with Manual transmission are available for purchase.\n - Most of the cars are 5 seaters and First owned.\n - Years of car ranges form 1996- 2015","13a6cd14":"###  Processing  New Price\nWe know that `New_Price` is the price of a new car of the same model in INR Lakhs.(1 Lakh = 100, 000)\n\nThis column clearly has a lot of missing values. We will impute the missing values later. For now we will only extract the numeric values from this column.\n","35550490":"Grouping with Model should give me more granularity, and near to accurate Seat values.","0250d0de":"<p style = \"font-size : 15px ; color: blue;font-family:TimesNewRoman\">\n    <b>Observations<\/b><\/p>\n    \n- Same observation  about correlation as seen in heatmap.\n\n- Kilometer driven  doesnot have impact on  Price . \n- As power increase mileage decrease.\n- Car with recent make sell at higher prices.\n- Engine and Power increase , price of the car seems to increase.","6937f68d":"There are 32 unique Brands in the dataset.Maruti brand is most available for purchase\/Sold followed by Hyundai.","1002c8ca":"#### Price Vs Mileage vs Fuel_type","951ef6fa":"There are 46 missing values in Engine, 175 in  Power,83 in Mileage. ","7133d0f4":"<p style = \"font-size : 20px ; color: blue;font-family:TimesNewRoman\">\n<b>Observations<\/b>\n<\/p>\n\n\n- Expensive cars are in Coimbatore and Banglore.\n- 2 Seater cars are more expensive.\n- Deisel Fuel type car are more expensive compared to other fuel type.\n- As expected, Older model are sold cheaper compared to latest model\n- Automatic transmission vehicle have a higher price than manual transmission vehicles.\n- Vehicles with more engine capacity have higher prices. \n- Price decreases as number of owner increases.\n- Automatic transmission require high engine and power.\n- Prices for Cars with fuel type as Deisel has increased with recent models \n- Engine,Power, how old the car his, Mileage,Fuel type,location,Transmission effect the price.","30a6e9d8":"Grouping with Name should give me more granularity, and near to accurate Seat values.","ae4054fb":"\n    \n **It is important to note here that the predicted values are log(price) and therefore coefficients have to be converted accordingly to understand their influence in price.**\n\n1. With our linear regression model we have been able to capture ~89 variation in our data.\n    \n2. The model indicates that the most significant predictors of price of used cars are - \n    - Age of the car\n    - Number of seats in the car\n    - Power of the engine\n    - Mileage\n    - Kilometers Driven\n    - Location\n    - Fuel_Type\n    - OwnerType\n    - Transmission - Automatic\/Manual\n        \n3. Newer cars sell for higher prices. 1 unit increase in age  of the car leads to [ exp(0.1123) = 1.12 Lakh ] decrease in the price of the vehicle, when everything else is constant.\n\n\n4. As the number of seats increases, the price of the car increases - exp(0.05) = 1.05 Lakhs\n    \n5. Mileage is inversely correlated with Price. Generally, high mileage cars are the lower budget cars.\n    \n6. Kilometers Driven have a negative relationship with the price which is intuitive. A car that has been driven more will have more wear and tear and hence sell at a lower price, everything else being 0.\n    \n7. The categorical variables are a little hard to interpret. But it can be seen that all the car_category variables in the dataset have a negative relationship with the Price and the magnitude of this negative relationship decrease as the brand category moves to lower brands.","b14d429a":" There are still missing values , analyzing further .Grouping by only Model for Engine and then filling missing values with median. For  Power and Mileage Engine values for a Brand can be used to get more accurate value.","73a24bd6":" Lets check which car types have missing values.","d4e82e88":"## Observations from the model\n","e351755f":"Here are my other notebooks....Do checkout if you find my work helpful, happy learning.\n\n1.[Predicting diabetes ](https:\/\/www.kaggle.com\/yogidsba\/diabetes-prediction-eda-model)\n\n2.[Predict if customer will buy Personsal Loan](https:\/\/www.kaggle.com\/yogidsba\/personal-loan-logistic-regression-decision-tree\/edit\/run\/65292079)\n\n3.[Insurance Claim Hypothesis Testing](http:\/\/www.kaggle.com\/yogidsba\/insurance-claims-eda-hypothesis-testing)\n\n4.[Basic EDA on Covid vaccination](http:\/\/www.kaggle.com\/yogidsba\/basic-eda-on-covid-vaccination)\n\n5.[Pandas Tutorial](http:\/\/www.kaggle.com\/yogidsba\/pandas-function-and-data-analysis)\n\n6.[Case study EDA on cardio good fitness](http:\/\/www.kaggle.com\/yogidsba\/casestudy-eda-for-cardio-good-fitness)","14e348dd":"### Checking Assumption 5: Normality of error terms\n\nThe residuals should be normally distributed.","e86ce1fd":"****This is my first time training a model. I am using statmodel and checking for all Linear regression assumptions.Special thanks to people on kaggle who answered by queries related to dummy variables and log transform. I hope this notebook helps you the way it helped me.**** ","ec989cda":"## Checking the Linear Regression Assumptions\n\n1. **No Multicollinearity**\n2. **Mean of residuals should be 0**\n3. **No Heteroscedasticity**\n4. **Linearity of variables**\n5. **Normality of error terms**","c7896d53":"<center><span style=\"font-family: TimesNewRoman; font-size:1.4em;color:blue;\"><b>  LinearRegression:  Predict Price for Used Car in India<\/b><\/span><\/center><br>\n<center><img src=https:\/\/images.unsplash.com\/photo-1506883968894-6e7738ccfc05?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=800&q=80 width=\"400\" height=\"300\"><\/center>\n<p size=1 ><i>image source:Meri\u00e7 Da\u011fl\u0131 on Unsplash<\/i><\/p>\n<br>","7ccfcc26":"## Context\n    \n<p style = \"font-size : 15px ; color: black;font-family:TimesNewRoman\">\nThere is a huge demand for used cars in the Indian Market today. As sales of new cars have slowed down in the recent past, the pre-owned car market has continued to grow over the past years and is larger than the new car market now. Cars4U is a budding tech start-up that aims to find footholes in this market.\nIn 2018-19, while new car sales were recorded at 3.6 million units, around 4 million second-hand cars were bought and sold. There is a slowdown in new car sales and that could mean that the demand is shifting towards the pre-owned market. In fact, some car sellers replace their old cars with pre-owned cars instead of buying new ones. Unlike new cars, where price and supply are fairly deterministic and managed by OEMs (Original Equipment Manufacturer \/ except for dealership level discounts which come into play only in the last stage of the customer journey), used cars are very different beasts with huge uncertainty in both pricing and supply. Keeping this in mind, the pricing scheme of these used cars becomes important in order to grow in the market. We have to come up with a pricing model that can effectively predict the price of used cars and can help the business in devising profitable strategies using differential pricing.<\/p>","4a448341":"# Libraries\n","035da63c":"<p style = \"font-size : 20px ; color: blue;font-family:TimesNewRoman\"><b>Observations<\/b><\/p>\n\n    \n- Years is left skewed. Years ranges from 1996- 2019 . Age of cars 2 year old to 25 years old\n\n- Kilometer driven , median is ~53k Km and mean is ~58K. Max values seems to be 6500000. This is very high , and seems to be outlier. Need to analyze further.\n\n- Mileage is almost Normally distrubuited\n\n- Engine is right skewed and has outliers on higher  and lower end\n\n- Power and Price are also right skewed.\n\n- Price 160 Lakh is too much for a used car. Seems to be an outlier.","6a143e4c":"Let us now remove multicollinearity from the model. Engine,power,Fuel_type have high mutlicollinearity.but fuel_type is an important feature in model prediction. So will remove engine.","7759d1f4":"### Bivariate & Multivariate Analysis","6c1affce":"Converting this observations to Nan so we will remember to handle them when handling missing values.","16657f79":"### Processing Years to Derive Age of car\nSince year has 2014, 1996  etc. But this will not help to understand how old cars is and its effect on  price.\nso creating  two new columns current year and Age . Current year would be 2021 and Age column would be Ageofcar= currentyear-year. And then drop currentyear columns\n","6514450f":"#### Price Vs Mileage Vs Transmission","e2b5778f":"<p style = \"font-size : 20px ; color: blue;font-family:TimesNewRoman\">\n<b>Observations<\/b><\/p>\nThis preview  shows that some columns potentially have a lot of missingness so we'll want to make sure to look into that later.\n\n-  **`New_Price`** has only 1006 values. 86 % values are missing\n\n-  **`Price`**, which is a Target variable 17 % missing values.This needs to be analysed further.\n\n-  **`Seats`** has only 53 values missing and number of seats can be one of key factor in deciding price.\n-  **`Power`** and **`Engine`** has 46 missing values.\n\n-  **`Mileage`** only has two values missing.\n\n-  **`Mileage`,`Power`,`Engine`,`New_Price`** we know are quantitative variables but are of object dtype here and needs to to converted to numeric.","e3c9d15b":"# Data Preprocessing","945e6a19":"The residuals have a close to normal distribution. Assumption 5 is also satisfied.\nWe should further investigate these values in the tails where we have made huge residual errors.\n\nNow that we have seen that olsmodel2 follows all the linear regression assumptions. Let us use this model to draw inferences.","e2f5a31c":"#### Price Vs Year VS Fuel Type","dcd598bf":"#### Price Vs Year Vs Transmission","91171f70":"As we can see most of the model have same engine \nsize and instead  of just applying median , grouping with model and year that should give me more granularity, and near to accurate Engine values.\n","ec3664d6":"<p style = \"font-size : 20px ; color: blue;font-family:TimesNewRoman\">\n    <b>Observations<\/b><\/p>\n\n    \n- Engine has strong positive correlation to Power [0.86]. \n- Price has positive correlation to Engine[0.66] as well Power [0.77].\n- Mileage is negative correlated to Engine,Power,Price.,Ageofcar\n- Price has negative  correlation to age of car.\n- Kilometer driven doesnt impact Price\n","2c809090":"<p style = \"font-size : 15px ; color: blue;font-family:TimesNewRoman\">\n    <b>Observations<\/b><\/p>\n    \n  \n- Year is left skewed and has outilers on lower side., This column can be dropped\n- Kilometer_driven is right skewed.\n- Mileage is almost Normally distrubuted. Has few outliers on upper and lower side. need to check further.\n- Engine ,power and price are  right skewed and has outliers on upper side.\n- Age of car is right skewed.\n","21b2a1f0":"## converting datatype","28b33b99":"\nWe have removed multicollinearity from the data now.Fuel_Type variables are showing high vif because most cars are either diesel and petrol. These two features are correlated with each other.\n\nWe will not drop this variable from the model because this will not affect the interpretation of other features in the model.","adc52577":"Mean of redisuals is very close to 0. The second assumption is also satisfied.","99c403a9":"### Checking Assumption 4: Linearity of variables\n\nPredictor variables must have a linear relation with the dependent variable.\n\nTo test the assumption, we'll plot residuals and fitted values on a plot and ensure that residuals do not form a strong pattern. They should be randomly and uniformly scattered on the x axis.","cc776d50":"# Model Building","fe58a0b3":"\n\n- Our final Linear Regression model has a MAPE of 23% on the test data, which means that we are able to predict within 23% of the price value. This is a very good model but can be further improved\n    \n- Some southern markets tend to have higher prices. It might be a good strategy to plan growth in southern cities using this information. Markets like Kolkata(coeff = -0.2) are very risky and we need to be careful about investments in this area.\n\n   \n- Based on Analysis,  we can to divide our cars into 3 segment Low, Medium and High budget.\n    \n- Brands like Maruti, Hyundai ,Honda are low budget and very popular brands in used car market.\n    \n- Brands  like BMW, Bentley, Jaguar, Land Rover, Mercedes Benz,Porche,Mini Cooper are high budget cars and are mostly bought by car enthusiast who are ready to buy a  two user owned car at higher price as well. \n    \n- Brands  like Toyota,Volvo can be Medium budget cars.\n    \n- Mumbai and Hyderbad seems to be more popular in Used car market, need to verify this with more data from other demographic regions. The next step post that would be to cluster different sets of data and see if we should make multiple models for different locations\/car types. \n    \n- Need to acquire more Automatic cars  to earn more profits, as this car sell at higher prices.\n    \n- With Increasing petrol rates diesel car are in more demand  in recent years, acquiring and selling them can high profits\n    \n- Along with this we can include scheme like take a test drive for  half day to pursue customer to buy.\n    \n- We can provide Car maintenance packages where  customers  pays a small upfront fees and   can bring the car for servicing anytime in a year to attract more customers.\n    \n  \n<b>Important points<\/b>\n- There are more soft parameters which also should be considered when buying a car, the wear and tear the car has been through and how much the company will have to work on car to make it ready for sale.\n    \n- If the car as already been in some kind of accident that would also effect the price.\n    \n- Other good to have feature like AC,Moon roof,Airbags can also have impact on the price.\n    \n- Car model that are too old will depreciate a lot  can impact the demand .","16e76649":"#### Price Vs Brand","f068d3ce":"### Checking Assumption 3: No Heteroscedasticity","5ce9d940":"## Problem\n<p style = \"font-size : 15px ; color: black;font-family:TimesNewRoman\">\n\n- Does various predicating factors effect the price of the used car .?<br>\n- What all  independent variables effect the pricing of used cars?<br>\n- Does name of a car have any effect on  pricing of car.?<br>\n- How does type of Transmission  effect  pricing?<br>\n- Does Location in which the car being sold has any effect on the price?<br>\n- Does kilometers_Driven,Year of manufacturing  have negative correlation with  price of the car?<br>\n- Does Mileage ,Engine and Power have any effect on the pricing of the car?<br>\n- How does number of seat ,Fuel type effect the pricing.?<br>\n<\/p>","d06dea35":"This confirms that certain columns tend to be missing together or all nonmissing together. So will try to fill the missing values , as much as possible.","902a7c7f":"Finally done with all missing  values handling","6c12093b":"#### Price Vs Power vs Transmission","9f7e9f5e":"I had seen some values in Power and Mileage as 0.0 so verifying data for Engine, Power, Mileage. Will check once again after converting datatype","12ab4868":"#### Year Vs Price Vs Owner_Type","6e143f4b":"\n    \nSince p-value > 0.05 we cannot reject the Null Hypothesis that the residuals are homoscedastic. \n\nAssumptions 3 is also satisfied by our olsmodel2","47c9834b":"Need to analyse along with price if seats plays any role in price"}}