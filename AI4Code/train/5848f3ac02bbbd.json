{"cell_type":{"3f3ea598":"code","f4e7e42f":"code","10e803bd":"code","0aebcb14":"code","d52d3de6":"code","44198bbf":"code","f938e750":"code","cabdcf92":"code","ccb91c3c":"code","f20234a0":"code","7074a5c7":"code","81f33c1d":"code","3358d0f3":"code","8f2042ad":"code","61f509c0":"code","12f548a4":"code","161f3042":"code","f36e39f6":"code","6264a7f9":"code","a7ab4180":"code","142c5c75":"code","bf6c716d":"code","6e616229":"code","24ee4760":"code","8328a202":"code","fabe8806":"code","1805c7a2":"code","807e0acc":"code","a37f0a7c":"code","e9a83e2c":"code","7c7cdb0b":"code","493fdf89":"code","507ea7c2":"code","c604f66d":"markdown","d0b22241":"markdown","7af9f458":"markdown","1c62cab2":"markdown","ce447041":"markdown","dd462bc2":"markdown","b95005d1":"markdown","17f46a97":"markdown","541c789a":"markdown","7278832c":"markdown","b487ff82":"markdown","93d42e2b":"markdown","c34703d3":"markdown","6c774f4a":"markdown","5337d441":"markdown"},"source":{"3f3ea598":"\n#  Helpful packages\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport csv as csv\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\n\n#Shuffle the datasets\nfrom sklearn.utils import shuffle\n\n#Learning curve\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\nimport seaborn as sns\n\n\nimport seaborn as sns; sns.set() # For a different plotting theme\nfrom scipy.stats import chi2_contingency\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest","f4e7e42f":"#loading the data sets from the csv files\nprint('--------load train & test file------')\n\ntrain_dataset = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_dataset = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n","10e803bd":"#Printing Top 5 data in train Data Set to have Over view\ntrain_dataset.head()","0aebcb14":"#Getting Knowledge on Dataset\ntrain_dataset.info()","d52d3de6":"#Convert PassengerId,Pclass to object\ntrain_dataset['PassengerId']=train_dataset['PassengerId'].astype(str)\ntrain_dataset['Pclass']=train_dataset['Pclass'].astype(str)\n#printing Result\ntrain_dataset.dtypes","44198bbf":"#Univariat Analysis Numerical data\n# Adjust the figure size\nplt.figure(figsize=(10,5))\n\n# Plot the histograms of X and Y next to each other\n\nplt.subplot(2,2,1)\nplt.hist(x = train_dataset['Age'], bins = 10)\nplt.title(\"Age\")\n\nplt.subplot(2,2,2)\nplt.hist(x = train_dataset['SibSp'], bins = 10,color='purple')\nplt.title(\"SibSp\")\n\nplt.subplot(2,2,3)\nplt.hist(x = train_dataset['Parch'], bins = 10,color='purple')\nplt.title(\"Parch\")\n\nplt.subplot(2,2,4)\nplt.hist(x = train_dataset['Fare'], bins = 10,color='purple')\nplt.title(\"Fare\")\n\nplt.tight_layout(pad=0.2)\nplt.show()","f938e750":"fig, ax =plt.subplots(2,2)\nsns.countplot(train_dataset['Survived'], ax=ax[0][0])\nsns.countplot(train_dataset['Sex'], ax=ax[0][1])\nsns.countplot(train_dataset['Pclass'], ax=ax[1][0])\nsns.countplot(train_dataset['Embarked'], ax=ax[1][1])\nfig.tight_layout(pad=0.2)\nfig.show()","cabdcf92":"#Pair plot\nplt_train= train_dataset.loc[:,[\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\",\"Parch\",\"Fare\",\"Cabin\",\"Embarked\"]]\nplt_train.head()","ccb91c3c":"#Bivariate Analysis numerical and Categorical data\nsns.set(style=\"darkgrid\")\ng = sns.PairGrid(plt_train, hue=\"Survived\",palette=\"Set1\")\ng.map_diag(plt.hist)\ng.map_offdiag(plt.scatter)\ng.add_legend();","f20234a0":"#more bi-variate analysis to understand data better\n#Survival\ng = sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Pclass\",\n                data=plt_train, saturation=.2,\n                kind=\"bar\", ci=None, aspect=.4,palette=\"Set1\")\n(g.set_axis_labels(\"\", \"Survival Rate\")\n  .set_xticklabels([\"Men\", \"Women\"])\n  .set_titles(\"{col_name} {col_var}\")\n  .set(ylim=(0, 1))\n  .despine(left=True))  ","7074a5c7":"#count  of men and woman based on Pclass \ng = sns.catplot(x=\"Pclass\", hue=\"Sex\", col=\"Survived\",\n                data=plt_train, kind=\"count\",\n                height=4, aspect=.7);","81f33c1d":"#count  of men and woman based on Pclass \nsns.set(style=\"darkgrid\")\ng = sns.catplot(x=\"Embarked\", hue=\"Sex\", col=\"Survived\",\n                data=plt_train, kind=\"count\",\n                height=4, aspect=.7,palette=\"GnBu_r\");","3358d0f3":"#Corelation Analysis Numerical Vs Numerical\ndf_corr_num_num=train_dataset.loc[:,[\"Survived\",\"Age\", \"SibSp\",\"Parch\",\"Fare\"]]\nsns.heatmap(df_corr_num_num.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm')","8f2042ad":"x=train_dataset.copy()\nx.loc[train_dataset['Sex']=='male','Sex'] = 0\nx.loc[train_dataset['Sex'] == 'female','Sex'] = 1\ndf_corr_num_num =x.loc[:,['Survived','Sex']]\ndf_corr_num_num['Sex']=df_corr_num_num['Sex'].astype('int64')\nsns.heatmap(df_corr_num_num.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm')","61f509c0":"train_dataset.isna().sum()","12f548a4":"#Imputing Embarked Column with Mode Value(Maximum occured Value)\ndataset_miss = train_dataset.copy()\n#Removing Row where age is null and people have survived the idea behind is\n#We don't want to train our model with imputed value as It can deviate our model as we already have less 1.\ndataset_miss.drop(dataset_miss[(dataset_miss['Age'].isna()) & (dataset_miss['Survived']==1)].index,axis=0,inplace=True)\ndataset_miss = dataset_miss.append(test_dataset)#Test data appended so that we don't require process it seperately.\n#Categorical data imputed with Mode\ndataset_miss[\"Embarked\"]=dataset_miss['Embarked'].fillna(dataset_miss['Embarked'].mode()[0])\n#Imputing Age with Mean the column\ndataset_miss['Age']= dataset_miss['Age'].fillna(dataset_miss['Age'].mean())\n#Imputing Cabin Missing data with 'Gen' Category 'Gen' means people having General cabin\n#Since It contain too many Missing vale still I have considerd it. The idea is Cabin is null means \n#people have not got cabin ie: they got hall,room etc\ndataset_miss[\"Cabin\"] = dataset_miss['Cabin'].fillna(0)\ndataset_miss.loc[dataset_miss['Cabin']!=0,'Cabin'] = 1","161f3042":"#correlation with newly created filed cabin\ndataset_miss[\"Cabin\"]=dataset_miss[\"Cabin\"].astype('int64')\ndf_corr_num_num=dataset_miss.loc[:,[\"Survived\",\"Cabin\"]]\nsns.heatmap(df_corr_num_num.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm')","f36e39f6":"pd.crosstab(dataset_miss['Cabin'],dataset_miss['Survived'],normalize='index')","6264a7f9":"#count  of men and woman based on Pclass \ng = sns.catplot(x=\"Cabin\", y=\"Survived\",\n                data=dataset_miss, saturation=.2,\n                kind=\"bar\", ci=None, aspect=.4,palette=\"Set1\")\n(g.set_axis_labels(\"\", \"Survival Rate\")\n  .set_titles(\"{col_name} {col_var}\")\n  .set(ylim=(0, 1))\n  .despine(left=True))  ","a7ab4180":"#Drop Passenger Column As It is not required\n#Creating New DataFrame\nfeature_df=pd.DataFrame()\n#Adding Target column to bewly created DataFrame\nfeature_df['Survived']=dataset_miss['Survived']\nfeature_df['PassengerId']=dataset_miss['PassengerId']\nfeature_df['Cabin']=dataset_miss['Cabin']\nfeature_df['Fare']=dataset_miss['Fare']\nfeature_df['SibSp']=dataset_miss['SibSp']\nfeature_df['Parch']=dataset_miss['Parch']\nfeature_df['Sex']=dataset_miss['Sex']\nfeature_df.loc[feature_df['Sex']=='male','Sex'] = 0\nfeature_df.loc[feature_df['Sex'] == 'female','Sex'] = 1\nfeature_df['Sex']=feature_df['Sex'].astype('int64')\ndataset_miss['Pclass'] = dataset_miss['Pclass'].astype('int64')\nfeature_df['Pclass']= dataset_miss['Pclass']#Research\ndataset_miss['Embarked'] = pd.Categorical(dataset_miss['Embarked'])\ndfdummies = pd.get_dummies(dataset_miss['Embarked'], prefix = 'Embarked')\nfeature_df = pd.concat([feature_df, dfdummies], axis=1)\n#Getting Total Family Number But This will deviate our model \n# feature_df['Total_Family_No'] = dataset_miss['Parch']+dataset_miss['SibSp']+1","142c5c75":"#Bining Age __from above stage we decided to make bining For getting good binning I have drawn a graph below\nbins = [0,18,35,45,62,200]\nlabels = ['Child','Teen','Youth1','Old1','Old2']\ndataset_miss['Age_binned'] = pd.cut(dataset_miss['Age'], bins=bins, labels=labels)\n#converting Age to Dummies and Adding to newly created DataFrame\ndataset_miss['Age_binned'] = pd.Categorical(dataset_miss['Age_binned'])\n# dfdummies = pd.get_dummies(dataset_miss['Age_binned'], prefix = 'Age_Cat')\n# feature_df = pd.concat([feature_df, dfdummies], axis=1)\nfeature_df['Age']= dataset_miss['Age_binned'] \nsns.distplot(dataset_miss['Age'],bins=40);\nfeature_df['Age'].unique()","bf6c716d":"feature_df.loc[feature_df['SibSp']+feature_df['Parch'] == 0,'Is_Alone'] = 0\nfeature_df['Is_Alone']=feature_df['Is_Alone'].fillna(1)\nfeature_df['Is_Alone']=feature_df['Is_Alone'].astype('int64')\nfeature_df","6e616229":"#Referance From Analytics Vidya\ntitles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\ndataset = dataset_miss.copy()\n# extract titles\ndataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n# replace titles with a more common title or as Rare\ndataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n                                        'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\ndataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\ndataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n# convert titles into numbers\ndataset['Title'] = dataset['Title'].map(titles)\n# filling NaN with 0, to get safe\ndataset['Title'] = dataset['Title'].fillna(0)\ndataset_miss['Title'] = dataset['Title']\nfeature_df['Title']=dataset['Title']","24ee4760":"#Considering Ticket as DeckClass for the people\ndataset_miss['Deck'] = dataset_miss['Ticket'].apply(lambda x: x.split(' ')[0].split('\/')[0].split('.')[0])\ndataset_miss['Deck'] = dataset_miss['Deck'].apply(lambda x: 'Gen' if x.isnumeric()  else x)\ndataset_miss['Deck'] = pd.Categorical(dataset_miss['Deck'])\ndfdummies = pd.get_dummies(dataset_miss['Deck'], prefix = 'Deck')\nfeature_df = pd.concat([feature_df, dfdummies], axis=1)","8328a202":"DeckList = { 'Child':1,'Teen':2, 'Youth1':3, 'Old1':4,'Old2':5}\nfeature_df['Age']= feature_df['Age'].map(DeckList)","fabe8806":"train_df = feature_df.loc[feature_df['Survived'].notnull()]\ntest_df = feature_df.loc[feature_df['Survived'].isna()]","1805c7a2":"logreg = LogisticRegression(max_iter=1000)\nY_train = train_df['Survived']\nX_train = train_df.drop(['Survived','PassengerId'],axis=1)\n# Y_train\n# X_train, X_test, y_train, y_test = train_test_split( X_train, Y_train, test_size=0.20, random_state=0)\nlogreg.fit(X_train,Y_train)\n# Y_pred = logreg.predict(X_test)\n# acc_log = round(logreg.score(X_test, y_test) * 100, 2)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)","807e0acc":"acc_log","a37f0a7c":"#I have performed Grid search to get best parameter for Random forest and it will give you almost 80+ Result\nrandom_forest = RandomForestClassifier(criterion = \"gini\", \n                                       min_samples_leaf = 1, \n                                       min_samples_split = 10,   \n                                       n_estimators=100, \n                                       max_features='auto', \n                                       oob_score=True, \n                                       random_state=1, \n                                       n_jobs=-1)\n\nrandom_forest.fit(X_train, Y_train)\nrandom_forest.score(X_train, Y_train)\n# random_forest.score(X_test, y_test)","e9a83e2c":"#Taking Test dataframe\ntest= test_df.drop(['Survived','PassengerId'],axis=1)\ntest['Fare']=test['Fare'].fillna(test['Fare'].mean())","7c7cdb0b":"#Predicting Result for Test dataset\nY_prediction = random_forest.predict(test).astype(int)","493fdf89":"#Geeting Final Result\nres=pd.DataFrame()\nres['PassengerId'] = test_df['PassengerId']\nres['Survived'] = Y_prediction","507ea7c2":"#Saving Final Result and Ready for submission\nres.to_csv(\"res.csv\",index=False)","c604f66d":"**Dataset Discription By column Wise based on understanding**\nFrom Above Dataset Discription and top 5 view of data set. We observed followings:\nThere are Total 891 records with 12 columns and some of the columns contain null value such as (Age,Cabin,Embarked)\n1. Categorical Columns: Pclass,Sex,Cabin\n2. Numerical Columns: Fare,SibSp,Age,Parch\n3. Nominal Columns: Name,Ticket,PassengerId\n4. Target Column: Survived\n\nSince PassengerId is nominal field but it's datatype is INT so we need to convert it to Object.\nSimilarlly Pclass is Categorical filed but it's datatyoe is INT so we need to convert to Object.","d0b22241":"In Above plot Age show's likely uniform distributed curve and shown  bell shape curved with unimodel shape.\nwhile other sibsp,Parch,Fare are ****right skewed and having missing value.\n\nCategorical Variables:- For categorical variables, we\u2019ll use frequency table to understand distribution of each category. We can also read as percentage of values under each category. It can be be measured using two metrics, Count and Count% against each category. Bar chart can be used as visualization.","7af9f458":"#From The Graph one can find that 0-18 it is having constant shape again 18-35 it shows same height but we found one hike due to our missing value tratment so again binning is important as it is good way of handling outliers","1c62cab2":"# 3. Missing Value Treatment\n","ce447041":"#Above Two Matrix shows that People having Cabin has more survival Rate than who didn't have.","dd462bc2":"**PairGrid** also allows you to quickly draw a grid of small subplots using the same plot type to visualize data in each. In a PairGrid, each row and column is assigned to a different variable, so the resulting plot shows each pairwise relationship in the dataset. This style of plot is sometimes called a \u201cscatterplot matrix\u201d, as this is the most common way to show each relationship, but PairGrid is not limited to scatterplots.","b95005d1":"A analysis is shown why cabin column is important.","17f46a97":"From above graph it is clear that Embarked is also co-related with Survivval as People who embarked from port s has higher chances of survival .where as mail portion who have embarked from Q has almost zero survival rate.\n\nfrom above Visualization It is clear that we need strong feature Engg","541c789a":"From above observation Fare plays the vital role.From Correlation Matrix It is clear that none of the column are related to \neach other sincce all columns are independent in nature","7278832c":"#from above Pair plot It is we have drawn following observation:\n1. Fig 2 and Fig 6 It is clear that People belongs to Pclass 3 and having age more than 40  has less survival in compare with Pclass 1 and 2 and Pclass 1 with any age group  has more survival than other two classes.\n2. Fig 3,4 and Fig 11,16 It is clear that people belongs to 3rd class and having more (>4) family member has less chance of survival.\n3. While looking at Fare and Pclass with survival rate it is interesting that the person who have paid less for class 1 have less survival Rate.\n4. While looking at Age vs Family member ,It is clear that people who have more family member and belongs to age group of 30-50 has less chance of survival,(It may be mail person who secrifise for its family).\n5. While looking at age vs Fare people having age group (60>) and paid less fair have very less chances of Survival\n\n**Over all obervation :\nIt is necessary to bin age group to have better result and understanding from above obervation bins are 1-12,12-20,20-28,28-36,36-44,44-60,60-72,72+\nIt is also necessary to have family count in total rather than having seperate columns ,\nNew column Total member = Parch+sibsp**","b487ff82":"# 3. Data Visualization (Bi-variate Analysis )\nBi-variate Analysis finds out the relationship between two variables. Here, we look for association and disassociation between variables at a pre-defined significance level. We can perform bi-variate analysis for any combination of categorical and continuous variables. The combination can be: Categorical & Categorical, Categorical & Continuous and Continuous & Continuous. Different methods are used to tackle these combinations during analysis process","93d42e2b":"#Above correlation value 0.35 shows it has good impact on Survived column","c34703d3":"# 1. Understanding Data","6c774f4a":"From the above figure It is clear that target column having imbalanced data i.e: number of people died is more than number of people survived.","5337d441":"# 2. Data Visualization (Univariat analysis)\nAt this stage, we explore variables one by one. Method to perform uni-variate analysis will depend on whether the variable type is categorical or continuous. Let\u2019s look at these methods and statistical measures for categorical and continuous variables individually:\n\nContinuous Variables:- In case of continuous variables, we need to understand the central tendency and spread of the variable. These are measured using various statistical metrics visualization methods as shown below:"}}