{"cell_type":{"3cb49459":"code","2fa96bbd":"code","c938a0e5":"code","aa160a28":"code","e9b1d0d1":"code","aac42f81":"code","91d0e4b7":"code","8893375d":"code","85c1ed3c":"code","675a88b8":"code","7f5343a8":"code","a4d07b29":"code","6269eb14":"code","cd504d2e":"code","0cbb0898":"code","7598ae79":"code","d8f076d8":"code","21d12b64":"code","afd2038a":"code","cc2e43ab":"code","d9fc5591":"code","d2e6beb8":"markdown","1324347b":"markdown","46a9b507":"markdown","5747bbe3":"markdown","aa0247c8":"markdown","a526be12":"markdown","7ac9cc8c":"markdown","de5d45b4":"markdown","af1fa0c2":"markdown","531a97c2":"markdown","7cd64808":"markdown","3c0419c0":"markdown","b68abb28":"markdown","a86a7342":"markdown","b2a3c2cf":"markdown","457b8990":"markdown","1c4f66d0":"markdown","5b8ce7a1":"markdown"},"source":{"3cb49459":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2fa96bbd":"# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\n# data visualisation and manipulation\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\n \n#configure\n# sets matplotlib to inline and displays graphs below the corressponding cell.\n%matplotlib inline  \nstyle.use('fivethirtyeight')\nsns.set(style='whitegrid',color_codes=True)\n\n#model selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\n\n#preprocess.\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#dl libraraies\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom keras.utils import to_categorical\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils.vis_utils import plot_model\n\n# specifically for cnn\nfrom keras.layers import Dropout, Flatten,Activation\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization,GlobalAveragePooling2D\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler\n    \nimport tensorflow as tf\nimport random\n\n# specifically for manipulating zipped images and getting numpy arrays of pixel values of images.\nimport cv2                  \nfrom tqdm import tqdm\nimport os                   \nfrom random import shuffle  \nfrom zipfile import ZipFile\nfrom PIL import Image","c938a0e5":"## the number of cat individuals \nnum_classes = 10\n\n# I select 10 cat individauls who have more than 40 images \nselection = [6, 7, 15, 18, 19, 29, 55, 57, 82, 152]\n\n## initial an empty list 'labels' to store name of cat individual for each image.\nlabels = []\n\n#for i in range(1, num_classes+1): <ignore>\nfor i in selection:\n    label = '000' + str(i)\n    labels.append(label[-4:])\n\n# initial an empty list X to store image of np.array()\nX = []\n\n# initial an empty list Z to store labels\/names of cat individauls\nZ = []\n\n# standard image size, which will be sent to Neural Network\nIMG_SIZE = 150\n\n# directioary of storage of cat images\ndir = '\/kaggle\/input\/cat-individuals\/cat_individuals_dataset\/'\n\n# function to automate store images of np.array() to X, and labels to Z \ndef make_train_data(labels = labels):\n    for label in labels:\n        DIR = dir + label\n        for img in tqdm(os.listdir(DIR)):\n            path = os.path.join(DIR,img)\n            # reading images\n            img = cv2.imread(path,cv2.IMREAD_COLOR)\n            # resizing images to (150, 150, 3), 3 is the number of channels - RGB\n            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        \n            X.append(np.array(img))\n            Z.append(str(label))\n\nmake_train_data()","aa160a28":"## Transform labels in Z to Y from class 0 to class 9, as 10 different cat individuals\nle=LabelEncoder()\nY=le.fit_transform(Z)\n\n## Transform and normalize X in the range of [0, 1]\nX=np.array(X)\nX=X\/255.","e9b1d0d1":"## shape of X, (number_image, image_size, image_size, channel_size)\nX.shape","aac42f81":"# separate data train:val:test = 80:10:10\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2, stratify = Y, random_state=42)\nx_val,x_test,y_val,y_test=train_test_split(x_test,y_test, stratify = y_test, test_size=0.5,random_state=42)","91d0e4b7":"## Helper ## Function to create positive pairs and negative pairs\ndef create_pairs(images, labels, numClasses = num_classes):\n    # initialize two empty lists to hold the (image, image) pairs and\n    # labels to indicate if a pair is positive (0) or negative (1)\n    np.random.seed(2021)\n    pairImages = []\n    pairLabels = []\n    \n    # calculate the total number of classes present in the dataset\n    # and then build a list of indexes for each class label that\n    # provides the indexes for all examples with a given label\n    idx = [np.where(labels == i)[0] for i in range(numClasses)]\n    \n    # loop voer all images\n    for idxA in range(len(images)):\n        # grab the current image and label belonging to the current iteration\n        currentImage = images[idxA]\n        label = labels[idxA]\n        \n        # randomly pick on an image that belongs to the *same* class label\n        posId = random.choice(idx[label])\n        posImage = images[posId]\n        \n        # prepare a positive pair and update the images and labels\n        pairImages.append([currentImage, posImage])\n        pairLabels.append([0])\n        \n        # grab the indices for each of the class labels *not* equal to\n        # the current label and randomly pick an image corresponding\n        # to a label *not* equal to the current label\n        negId = np.where(labels != label)[0]\n        negIdx = random.choice(negId)\n        negImage = images[negIdx]\n        \n        # prepare a negative pair of images and update out lists\n        pairImages.append([currentImage, negImage])\n        pairLabels.append([1])\n    \n    return (np.array(pairImages), np.array(pairLabels))\n\n\n# Function to calculate the distance between two images (Euclidean Distance used here)\nimport tensorflow.keras.backend as K\ndef euclidean_distance(vectors):\n    # unpack the vectors into separate lists\n    (featsA, featsB) = vectors\n    # compute the sum of squared distances between the vectors\n    sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n                       keepdims=True)\n    # return the euclidean distance between the vectors\n    return K.sqrt(K.maximum(sumSquared, K.epsilon()))\n\n# Generate pos\/neg pairs for train_set, val_set\n(pairTrain, labelTrain) = create_pairs(x_train, y_train)\n(pairVal, labelVal) = create_pairs(x_val, y_val)","8893375d":"# contrastive loss function\ndef contrastive_loss(y, preds, margin=1):\n    # explicitly cast the true class label data type to the predicted\n    # class label data type (otherwise we run the risk of having two\n    # separate data types, causing TensorFlow to error out)\n    y = tf.cast(y, preds.dtype)\n    # calculate the contrastive loss between the true labels and\n    # the predicted labels\n    squaredPreds = K.square(preds)\n    squaredMargin = K.square(K.maximum(margin - preds, 0))\n    loss = K.mean((1 - y) * squaredPreds + y * squaredMargin)\n    # return the computed contrastive loss to the calling function\n    return loss\n\n\n# Base model with pre-training VGG16\ndef embedding_model_cl(inputShape, embeddingDim=128):\n    # VGG16 as base_model\n    base_model = tf.keras.applications.vgg16.VGG16(include_top=False,\n                                                   input_shape = inputShape,\n                                                   weights = 'imagenet')\n\n    # freeze all the layers of VGG16, so they won't be trained.\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    inputs = tf.keras.layers.Input(shape=inputShape)\n    #x = data_augmentation(inputs)\n    x = base_model(inputs)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(units=256, activation='relu')(x)\n    outputs = tf.keras.layers.Dense(units=embeddingDim)(x)\n    \n    model = tf.keras.Model(inputs, outputs)\n    return model\n\n# Complete model\ndef complete_model_cl(base_model):\n    # Create the complete model with pair\n    # embedding models and minimize the distance for positive pair\n    # and maximum the distance for negative pair\n    # between their output embeddings\n    imgA = tf.keras.layers.Input(shape=((IMG_SIZE, IMG_SIZE, 3)))\n    imgB = tf.keras.layers.Input(shape=((IMG_SIZE, IMG_SIZE, 3)))\n\n    base_model = embedding_model_cl((IMG_SIZE, IMG_SIZE, 3))\n    \n    featsA = base_model(imgA)\n    featsB = base_model(imgB)\n   \n    distance = tf.keras.layers.Lambda(euclidean_distance)([featsA, featsB])\n    model = tf.keras.Model(inputs=[imgA, imgB], outputs=distance)\n    model.compile(loss=contrastive_loss, optimizer=\"adam\")\n    return model","85c1ed3c":"base_model_cl = embedding_model_cl((IMG_SIZE, IMG_SIZE, 3))\nmodel_cl = complete_model_cl(base_model_cl)\nmodel_cl.summary()\n\nhistory_cl = model_cl.fit([pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:], \n                   validation_data = ([pairVal[:, 0], pairVal[:, 1]], labelVal[:]),\n                   batch_size = 16, epochs=100)","675a88b8":"def get_image(label, val=False):\n    \"\"\"Choose an image from our training or val data with the\n    given label.\"\"\"\n    if val:\n        y = y_val; X = x_val\n    else:\n        y = y_train; X = x_train\n    idx = np.random.randint(len(y))\n    while y[idx] != label:\n        # keep searching randomly!\n        idx = np.random.randint(len(y))\n    return X[idx]\n\n\ndef get_triplet(val=False):\n    \"\"\"Choose a triplet (anchor, positive, negative) of images\n    such that anchor and positive have the same label and\n    anchor and negative have different labels.\"\"\"\n    n = a = np.random.randint(10)\n    while n == a:\n        # keep searching randomly!\n        n = np.random.randint(10)\n    a, p = get_image(a, val), get_image(a, val)\n    n = get_image(n, val)\n    return a, p, n\n\n\ndef generate_triplets(val=False):\n    \"\"\"Generate an un-ending stream (ie a generator) of triplets for\n    training or val.\"\"\"\n    while True:\n        list_a = []\n        list_p = []\n        list_n = []\n\n        for i in range(batch_size):\n            a, p, n = get_triplet(val)\n            list_a.append(a)\n            list_p.append(p)\n            list_n.append(n)\n            \n        A = np.array(list_a, dtype='float32')\n        P = np.array(list_p, dtype='float32')\n        N = np.array(list_n, dtype='float32')\n        # a \"dummy\" label which will come in to our identity loss\n        # function below as y_true. We'll ignore it.\n        label = np.ones(batch_size)\n        yield [A, P, N], label","7f5343a8":"def identity_loss(y_true, y_pred):\n    return K.mean(y_pred)\n\ndef triplet_loss(x, alpha = 0.2):\n    # Triplet Loss function.\n    anchor,positive,negative = x\n    # distance between the anchor and the positive\n    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n    # distance between the anchor and the negative\n    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n    # compute loss\n    basic_loss = pos_dist-neg_dist+alpha\n    loss = K.maximum(basic_loss,0.0)\n    return loss\n\ndef embedding_model_tl(inputShape, embeddingDim=128):\n    # VGG16 as base_model\n    base_model = tf.keras.applications.vgg16.VGG16(include_top=False,\n                                                   input_shape = inputShape,\n                                                   weights = 'imagenet')\n\n    # freeze all the layers of VGG16, so they won't be trained.\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    inputs = tf.keras.layers.Input(shape=inputShape)\n    #x = data_augmentation(inputs)\n    x = base_model(inputs)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(units=256, activation='relu')(x)\n    outputs = tf.keras.layers.Dense(units=embeddingDim)(x)\n    \n    model = tf.keras.Model(inputs, outputs)\n    return model\n\n\ndef complete_model_tl(base_model):\n    # Create the complete model with three\n    # embedding models and minimize the loss \n    # between their output embeddings\n    input_1 = tf.keras.layers.Input((imsize, imsize, 3))\n    input_2 = tf.keras.layers.Input((imsize, imsize, 3))\n    input_3 = tf.keras.layers.Input((imsize, imsize, 3))\n        \n    A = base_model(input_1)\n    P = base_model(input_2)\n    N = base_model(input_3)\n   \n    loss = tf.keras.layers.Lambda(triplet_loss)([A, P, N]) \n    model = tf.keras.Model(inputs=[input_1, input_2, input_3], outputs=loss)\n    model.compile(loss=identity_loss, optimizer=Adam(LR))\n    return model","a4d07b29":"imsize = 150\nbatch_size = 16\nembedding_dim = 2 \nLR = 0.0001\nEPOCHS = 5\nalpha = 0.5 \n\ntrain_generator = generate_triplets()\nval_generator = generate_triplets(val=True)\nbatch = next(train_generator)\n\nbase_model_tl = embedding_model_tl((imsize, imsize, 3))\nmodel_tl = complete_model_tl(base_model_tl)\nmodel_tl.summary()\n\nhistory_tl = model_tl.fit_generator(train_generator, \n                                    validation_data=val_generator, \n                                    epochs=100, \n                                    verbose=1,steps_per_epoch=20, \n                                    validation_steps=30)","6269eb14":"def plt_metric(history, metric, title, has_valid=True):\n    \"\"\"Plots the given 'metric' from 'history'.\n\n    Arguments:\n        history: history attribute of History object returned from Model.fit.\n        metric: Metric to plot, a string value present as key in 'history'.\n        title: A string to be used as title of plot.\n        has_valid: Boolean, true if valid data was passed to Model.fit else false.\n\n    Returns:\n        None.\n    \"\"\"\n    plt.plot(history[metric])\n    if has_valid:\n        plt.plot(history[\"val_\" + metric])\n        plt.legend([\"train\", \"validation\"], loc=\"upper right\")\n    plt.title(title)\n    plt.ylabel(metric)\n    plt.xlabel(\"epoch\")\n    plt.show()\n\n# Plot the constrastive loss\nplt_metric(history=history_cl.history, metric=\"loss\", title=\"contrastive loss\")\n\n# Plot the triplet loss\nplt_metric(history=history_tl.history, metric=\"loss\", title=\"triplet loss\")","cd504d2e":"anchor_images = [x_train[y_train==i][0] for i in range(10)]\nanchor_images = np.array(anchor_images)\n\ndef evluate_acc(x_test=x_test, y_test=y_test, anchors=anchor_images, model = 'cl'):\n    # model = 'cl' - contrastive loss\n    # model = 'tl' - triplet loss\n    pred = []\n    for i in range(len(y_test)):\n        dists = []\n        imgA = x_test[i].reshape(1, 150, 150, 3)\n        if model == 'cl':\n            for j in range(len(anchors)):\n                imgB = anchors[j].reshape(1, 150, 150, 3)\n                dist = model_cl.predict([imgA, imgB])[0][0]\n                dists.append(dist)\n            dists = np.array(dists)\n            idx = np.argmin(dists)\n            pred.append(idx)\n        elif model == 'tl':\n            featsA = base_model_tl(x_test[i].reshape(1, 150, 150, 3))\n            for j in range(len(anchors)):\n                imgB = anchors[j].reshape(1, 150, 150, 3)\n                featsB = base_model_tl(anchors[j].reshape(1, 150, 150, 3))\n                dist = np.linalg.norm(featsA - featsB, 2)\n                dists.append(dist)\n            dists = np.array(dists)\n            idx = np.argmin(dists)\n            pred.append(idx)\n    pred=np.array(pred)\n    accuracy = np.sum(y_test == pred) \/ len(y_test)\n    return accuracy","0cbb0898":"acc_cl = evluate_acc(model = 'cl')\nprint('The accuracy of contrastive loss on test set is {}%'.format(round(acc_cl * 100)))\n\nacc_tl = evluate_acc(model = 'tl')\nprint('The accuracy of triplet loss on test set is {}%'.format(round(acc_tl * 100)))","7598ae79":"for i in range(len(anchor_images)):\n    test = x_test[y_test==0][0].reshape(1, 150, 150, 3)\n    anchor = anchor_images[i].reshape(1, 150, 150, 3)\n    dist = model_cl.predict([test, anchor])[0][0]\n    \n    fig = plt.figure(\"Pair #{}\".format(i + 1), figsize=(4, 2)) \n    plt.suptitle(\"Dist_Test_ID0006_Anchor_ID{}: {:.2f}\".format(labels[i], dist))\n    \n    ax = fig.add_subplot(1, 2, 1)\n    plt.imshow(test[0])\n    plt.axis(\"off\")\n    \n    ax = fig.add_subplot(1, 2, 2)\n    plt.imshow(anchor[0])\n    plt.axis(\"off\")\n    \n    plt.show()","d8f076d8":"label = '0004'\nnum_lab = '002'\nunknown = cv2.imread('\/kaggle\/input\/cat-individuals\/cat_individuals_dataset\/'+ label + '\/' + label + '_' + num_lab + '.JPG')\nunknown = cv2.resize(unknown, (IMG_SIZE,IMG_SIZE))\nunknown = unknown\/255.\nunknown = unknown.reshape(1, 150, 150, 3)","21d12b64":"for i in range(len(anchor_images)):\n    test = unknown.reshape(1, 150, 150, 3)\n    anchor = anchor_images[i].reshape(1, 150, 150, 3)\n    dist = model_cl.predict([test, anchor])[0][0]\n    \n    fig = plt.figure(\"Pair #{}\".format(i + 1), figsize=(4, 2)) \n    plt.suptitle(\"Dist_Unknown vs. ID_{}: {:.2f}\".format(labels[i], dist))\n    \n    ax = fig.add_subplot(1, 2, 1)\n    plt.imshow(test[0])\n    plt.axis(\"off\")\n    \n    ax = fig.add_subplot(1, 2, 2)\n    plt.imshow(anchor[0])\n    plt.axis(\"off\")\n    \n    plt.show()","afd2038a":"anchor_images = [x_train[y_train==i][0] for i in range(10)]\nanchor_images = np.array(anchor_images)\n\ndef re_id(test_img, anchors = anchor_images, dist_threshold=0.4):\n    dists = []\n    for i in range(len(anchors)):\n        anchor = anchors[i].reshape(1, 150, 150, 3)\n        dist = model_cl.predict([test_img, anchor])[0][0]\n        dists.append(dist)\n    dists = np.array(dists)\n    if np.sum(dists <= dist_threshold) >= 1:\n        idx = np.argmin(dists)\n        print('This is cat ID:{}'.format(labels[idx]))\n        plt.imshow(test_img[0])\n        plt.show()\n    else:\n        print('This cat is unknown!')\n        plt.imshow(test_img[0])\n        plt.show()\n    ","cc2e43ab":"labels_idx = 0\nprint('The true label of this cat individual is ID: {}'.format(labels[labels_idx]))\ntest_img = x_test[y_test==labels_idx][0].reshape(1, 150, 150, 3)\nre_id(test_img, dist_threshold=0.4)","d9fc5591":"label = '0004'\nnum_lab = '002'\nunknown = cv2.imread('\/kaggle\/input\/cat-individuals\/cat_individuals_dataset\/'+ label + '\/' + label + '_' + num_lab + '.JPG')\nunknown = cv2.resize(unknown, (IMG_SIZE,IMG_SIZE))\nunknown = unknown\/255.\nunknown = unknown.reshape(1, 150, 150, 3)\nre_id(unknown, dist_threshold=0.4)","d2e6beb8":"# Evaluating both models our test_set","1324347b":"# Visualizing the distance on pairs","46a9b507":"# **Example - not existing cat individual in training set**","5747bbe3":"# **Loading images**","aa0247c8":"## Plot of accuacy and loss over epoch","a526be12":"## **Example - existing cat individual in training set**","7ac9cc8c":"## Compare unknown cat individual with anchor images","de5d45b4":"# **SNN with triplet loss**","af1fa0c2":"## SNN with contrastive loss structure ","531a97c2":"# **Additional Packages** ","7cd64808":"## Helper functions","3c0419c0":"## SNN with triplet loss structure","b68abb28":"## Helper functions","a86a7342":"# Training with contrastive loss","b2a3c2cf":"# Training with triplet loss","457b8990":"# **Spliting Dataset (train_set\/val_set\/test_set)**","1c4f66d0":"# Existing cat individual with anchor images","5b8ce7a1":"# **SNN with contrastive loss**"}}