{"cell_type":{"2b0a51e7":"code","58cb90c4":"code","6eab272d":"code","d5f2442e":"code","d82f8f75":"code","cc98d695":"code","56a794fb":"code","5476f3c5":"code","17442040":"code","b539dde0":"code","f7fa334c":"code","fe8e5b73":"code","940d9341":"code","db97e331":"code","b74fa013":"code","7dbd5734":"code","61187422":"code","5558b45b":"code","e59b4d8e":"code","c3ac15a8":"code","af368857":"code","8fe662f6":"code","e1aa5c90":"code","7355d3f1":"code","7f16cc07":"code","47e2dbb3":"code","7c5b80ca":"code","fb10b897":"code","2c1b78f9":"code","58b62aed":"code","9da06331":"code","46bd33e7":"code","3955c106":"code","82b9c790":"code","a6ce1e60":"code","e7b06ce8":"code","755f4ff8":"code","f449eace":"code","e3cac92b":"code","7d2108d4":"code","c4b41a06":"markdown","93808a5a":"markdown","8c3be771":"markdown","987e9272":"markdown","78410a7a":"markdown","b9ca1c97":"markdown","c00e0c98":"markdown","52ed633c":"markdown","6f0531c2":"markdown","d82df52e":"markdown","125c6006":"markdown","04d4dfa7":"markdown","ddd03ba2":"markdown"},"source":{"2b0a51e7":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import accuracy_score\n\n\nsns.set(rc={'figure.figsize':(5,5)})","58cb90c4":"train=pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\nval=pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')","6eab272d":"train['dataset']= \"Train\"\nval['dataset']=\"Test\"\n\n\ndata= pd.concat([train,val],axis=0)","d5f2442e":"print(data.shape)\nprint(data.columns)\n\nprint(data.isna().agg('sum'))","d82f8f75":"sns.countplot(x='Sex',hue='Survived',data=train)","cc98d695":"plt.hist(x=data.Age, bins=10)\nplt.grid(axis='y', alpha=0.75)\nplt.xlabel('Age')\nplt.ylabel('Frequency')","56a794fb":"#Creating a variable for ticket with first 2 letters\ndata['Ticket']=data['Ticket'].fillna('NA')\ndata['Ticket_1']=data['Ticket'].str.slice(stop=2)\n\n\n\n#Plotting the overall distribution\nsns.set(rc={'figure.figsize':(11.7,20)})\n\nsns.countplot(y='Ticket_1',data=data, order = data['Ticket_1'].value_counts().index)\n\nsns.set(rc={'figure.figsize':(5,5)})\n\n\n#Plotting survival rate based on ticket\np=data[['Ticket_1','Survived']].groupby(['Ticket_1']).agg(np.mean)\n\np=p.reset_index()\np=p.sort_values(['Survived'],ascending=False)\np.plot.bar(x='Ticket_1',y='Survived',figsize=(20,10))\n\n\n","5476f3c5":"\n#Varaible for high survival\nconditions = [\n    (data['Ticket_1'] == 'PC') | (data['Ticket_1'] == 'PP')]\nchoices = [1]\n\ndata['ticket_pp']=np.select(conditions, choices,default=0)\n\n#Varaible for lower survival\nconditions = [\n    (data['Ticket_1'] == 'ST') | (data['Ticket_1'] == 'A.')| (data['Ticket_1'] == 'SO')| (data['Ticket_1'] == 'CA')]\nchoices = [1]\n\ndata['ticket_S']=np.select(conditions, choices,default=0)","17442040":"data['Cabin_new']=data.Cabin.str.slice(stop=1)\ndata['Cabin_new']=data['Cabin_new'].fillna('NA')\n\nsns.countplot(x='Cabin_new',hue='Survived',data=data)","b539dde0":"data.Fare.hist(by=[data.Survived])","f7fa334c":"sns.countplot(x='Parch',hue='Survived',data=train)\n\n#Passengers with 0 ,4,5,6 Parch are less likely to survive than 1,2,3","fe8e5b73":"sns.countplot(x='SibSp',hue='Survived',data=train)","940d9341":"data['Family']=data['SibSp']+data['Parch']+1\n\n\nsns.countplot(x='Family',hue='Survived',data=data)","db97e331":"conditions = [\n    (data['Family'] == 1),\n    (data['Family'] == 2),\n    (data['Family'] == 3),\n    (data['Family'] == 4),\n    (data['Family'] == 5),]\nchoices = ['1','2','3','4','5']\n\ndata['FamSize']=np.select(conditions, choices,default='6')\n\ndata['FamSize']=pd.to_numeric(data['FamSize'])\ndata.FamSize.value_counts()","b74fa013":"sns.boxplot(x=\"Pclass\",y=\"Age\",data=data)\n","7dbd5734":"sns.boxplot(x=\"Sex\",y=\"Age\",data=data)\n","61187422":"sns.boxplot(x=\"SibSp\",y=\"Age\",data=data)\n","5558b45b":"sns.boxplot(x=\"Parch\",y=\"Age\",data=data)","e59b4d8e":"age_avg=pd.DataFrame(data[['Age','Pclass','Parch','SibSp']].groupby(['Pclass','Parch','SibSp']).median())\n\nage_avg.reset_index(inplace=True)\nage_avg['Age_avg']=age_avg['Age']\nage_avg=age_avg.drop('Age',axis=1)\nm=np.median(age_avg['Age_avg'].dropna())\nage_avg=age_avg.fillna(m)","c3ac15a8":"data=data.merge(age_avg,on=['Pclass','Parch','SibSp'],how='left')","af368857":"data['Age']=data['Age'].fillna(data['Age_avg'])","8fe662f6":"sns.countplot(x='Embarked',hue='Survived',data=train)","e1aa5c90":"print(data['Embarked'].isna().agg('sum'))\n\ndata['Embarked']=data['Embarked'].fillna('S')\nprint(data['Embarked'].isna().agg('sum'))\n\n\nprint(data['Fare'].isna().agg('sum'))\ndata['Fare']=data['Fare'].fillna(np.mean(data['Fare']))\nprint(data['Fare'].isna().agg('sum'))","7355d3f1":"conditions = [\n    (data['Sex'] == 'male') ]\nchoices = [1]\n\ndata['Sex']=np.select(conditions, choices,default=0)\n\ndata.Sex.hist()","7f16cc07":"data_final=pd.get_dummies(data,columns=['Pclass','Cabin_new','Embarked'],prefix=['Pclass','Cabin','Embark'])\n\ndata_final=data_final.drop(['PassengerId','Ticket_1','Name','Cabin','Ticket','Age_avg'],axis=1)\n\n\ndata_final.head()\n\ndata_final.dtypes","47e2dbb3":"Train_final = data_final[data_final['dataset']=='Train']\nVal_final=data_final[data_final['dataset']=='Test']\n\nTrain_final=Train_final.drop('dataset',axis=1)\nVal_final=Val_final.drop(['dataset','Survived'],axis=1)","7c5b80ca":"y=Train_final['Survived']\nX=Train_final.drop('Survived', axis =1)","fb10b897":"X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=10, test_size=0.2)","2c1b78f9":"from sklearn.ensemble import RandomForestClassifier\n\nparams={'max_depth' : [6,8,10], \n       'n_estimators': [50, 100], \n        'min_samples_split': [2, 3], \n        'min_samples_leaf': [1, 3], \n        'bootstrap': [False]\n       }\n\nrf=RandomForestClassifier()\n\nrf_b=GridSearchCV(rf,param_grid=params,cv=3) \n\nrf_b.fit(X_train,y_train)\n\nprint(rf_b.best_score_)\n\nprint(rf_b.score(X_test,y_test))\n\nprint(rf_b.best_params_)\n\ny_rf_pred=rf_b.predict(X_test)\n\nprint(confusion_matrix(y_test,y_rf_pred))\n\ny_rf_prob_pred=rf_b.predict_proba(X_test)\n\nprint(roc_auc_score(y_test,y_rf_prob_pred[:,1]))","58b62aed":"d={'Feature':np.array(X_train.columns),'Importance':rf_b.best_estimator_.feature_importances_} \nFeatures=pd.DataFrame(d) \nFeatures.sort_values('Importance', inplace=True,ascending=False)","9da06331":"sns.barplot(y='Feature',x='Importance', data=Features,palette=\"Blues_d\")\n","46bd33e7":"from sklearn.ensemble import GradientBoostingClassifier\n\nparams={'n_estimators':[200,400], \n#        'learning_rate': [ 0.1,0.2,0.4],\n#        'max_features': [2,3,4,7],\n        'max_depth': [2,4]}\n\ngb=GradientBoostingClassifier(random_state=42)\n\ngb_b=GridSearchCV(gb,param_grid=params,cv=3)\ngb_b.fit(X_train,y_train)\n\nprint(gb_b.best_score_)\n\nprint(gb_b.score(X_test,y_test))\n\nprint(gb_b.best_params_)\n\ny_gb_pred=gb_b.predict(X_test)\nprint(confusion_matrix(y_test,y_gb_pred))\n\ny_gb_prob_pred=gb_b.predict_proba(X_test)\n\nprint(roc_auc_score(y_test,y_gb_prob_pred[:,1]))","3955c106":"d={'Feature':np.array(X_train.columns),'Importance':gb_b.best_estimator_.feature_importances_}\nFeatures_gb=pd.DataFrame(d)\nFeatures_gb.sort_values('Importance', inplace=True,ascending=False)","82b9c790":"sns.barplot(y='Feature',x='Importance', data=Features_gb,palette=\"Blues_d\")\n","a6ce1e60":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\n\nxgb = XGBClassifier(use_label_encoder=False,verbosity=1)\n\n\nparameters = {'eval_metric':[\"error\"],\n              'objective':['binary:logistic'],\n              'learning_rate': [0.1,0.2], \n              'max_depth': [1,2,5],\n              'booster' : ['gbtree'],\n              'n_estimators': [200],\n              'seed': [1337]}\n\n\nxgb_b = GridSearchCV(xgb, parameters, \n                   cv=3, \n                   scoring='accuracy',\n                    refit=True)\n\nxgb_b.fit(X_train,y_train)\n\nprint(xgb_b.best_params_)\n\nprint(xgb_b.score(X_test,y_test))\n","e7b06ce8":"import lightgbm as lgb\n\nX_lgb_train,X_lgb_eval,y_lgb_train,y_lgb_eval = train_test_split(X_train,y_train,random_state=10, test_size=0.2)\n\n\nparams = {\n        \"objective\" : \"binary\",\n        \"eval_metric\" : \"error\",\n        \"learning_rate\" : 0.004,\n        \"bagging_fraction\" : 1,\n        \"feature_fraction\" : 0.9,\n        \"bagging_seed\" : 42,\n        \"verbosity\" : -1,\n        \"seed\": 42\n    }\n    \nlgtrain = lgb.Dataset(X_lgb_train, label=y_lgb_train)\nlgval = lgb.Dataset(X_lgb_eval, label=y_lgb_eval)\n\n\nmodel_lgb = lgb.train(params, lgtrain, 5000, \n                      valid_sets=[lgtrain, lgval], \n                       early_stopping_rounds=100,\n                      verbose_eval=150\n                      )\npreds=model_lgb.predict(X_test)  \npreds=[round(value) for value in preds]\n\nprint(accuracy_score(y_test,preds))","755f4ff8":"ensemble=VotingClassifier(estimators=[ ('XGBoost', xgb_b.best_estimator_), ('Random Forest', rf_b.best_estimator_), ('Gradient boosting', gb_b.best_estimator_)], voting='soft', weights=[1,1,1]).fit(X_train,y_train) \nprint('The accuracy for Ensemble is:',ensemble.score(X_test,y_test))","f449eace":"print(Val_final['Fare'].isnull().agg('sum'))\n\nVal_final['Fare']=Val_final['Fare'].fillna(np.mean(Val_final['Fare']))\n\nprint(Val_final['Fare'].isnull().agg('sum'))","e3cac92b":"pred=gb_b.predict(Val_final)\n\n#pred2=pred.astype('int64')\npred2=[round(value) for value in pred]\n\nsubmission = pd.DataFrame({'PassengerId': val['PassengerId'],'Survived': pred2})\n\nsubmission.head()","7d2108d4":"submission.to_csv(\".\/Submission.csv\", index=False)","c4b41a06":"***Using an ensemble for all classifiers to get the accuracy***","93808a5a":"**Using lable encoding for variable \"Sex\"**","8c3be771":"We Can check the ditribution and ratio of survived passenger based on first 2 letters of 'Ticket' variable","987e9272":"***TICKET***","78410a7a":"**AGE**","b9ca1c97":"***Combining training and validation data for feature engineering. This is usefull at the later stage when predicting on validation set***","c00e0c98":"Lets see the distribution of survival based on variable 'Sex'","52ed633c":"***Variables contains missing values, We use different methodology for each variable based on best estimation possible ***","6f0531c2":"Nest stpes - \n\nImpute Fare and Embarked missing values based on other variables","d82df52e":"**It can be seen in the charts above Tickets with PP and PC have higher chance of survival, SO we can built a new binary variable for them. We do the same for lower survival rate as well**","125c6006":"d={'Feature':np.array(X_train.columns),'Importance':rf_b.best_estimator_.feature_importances_}\nFeatures=pd.DataFrame(d)\nFeatures.sort_values('Importance', inplace=True,ascending=False)","04d4dfa7":"**Average Age varies widely within Sibsp, Pclass, Parch, We can use median ages within these categories to use as proxy data for missing age values**","ddd03ba2":"Distribution of 'Age'"}}