{"cell_type":{"a8b84039":"code","dd83bbd5":"code","4a92dadb":"code","69afb4aa":"code","7409abff":"code","faaeac13":"code","ecce5c82":"code","dcdfbf39":"code","9895f6a9":"code","202e25e8":"code","b62866c0":"code","e0bd9f5d":"code","ae22225e":"code","494e6e29":"code","e0ad0774":"code","e98f705a":"code","090cd6fd":"code","2b49f57e":"code","0f4204cc":"code","5b810c85":"code","0e9a666c":"code","9a034a3f":"code","b0c3e650":"code","f20181e7":"code","652b2c2b":"code","a8462a96":"code","1c180d41":"code","b2ab4ec3":"code","6a324040":"code","c7f5ce97":"code","70147d02":"code","80b03317":"code","41af0c7a":"code","02d995d4":"code","9bd10205":"markdown","6576a03b":"markdown","1d6b03f6":"markdown","2c12fdcd":"markdown","f2956107":"markdown","6fdf6346":"markdown","eeb9d023":"markdown","b33cbf40":"markdown","2437e1fb":"markdown","e7ee48a4":"markdown","2b657edc":"markdown","fa8947f0":"markdown","54b2c9a4":"markdown","2dbee823":"markdown"},"source":{"a8b84039":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\npd.set_option('max_rows', None)  # para ver todas las filas de un df\nsns.set()","dd83bbd5":"!ls ..\/input\/bankdscor9","4a92dadb":"# Descomentar las siguientes lineas para leer la descripcion de las columnas\n# with open('bankdata\/bank-columns-description.txt') as fp:\n#     print(fp.read())","69afb4aa":"df = pd.read_csv('..\/input\/bankdscor9\/data_train.csv').reset_index(drop=True)\ndf.tail(3)","7409abff":"df.shape","faaeac13":"df_test = pd.read_csv('..\/input\/bankdscor9\/data_test.csv').reset_index(drop=True)\ndf_test.tail(3)","ecce5c82":"df_test.head(5)","dcdfbf39":"print('Columnas nulas:', sum(df.isnull().sum() > 0))\nprint('Columnas con valores categoricos:', sum([df[col].dtype == 'object' for col in df.columns]))\nprint('Columnas con valores reales:', sum([df[col].dtype == 'float' for col in df.columns]))\nprint('Columnas con valores enteras:', sum([df[col].dtype == 'int64' for col in df.columns]))","9895f6a9":"df.y = df.y.map({'no': 0, 'yes': 1})","202e25e8":"df.isnull().sum()","b62866c0":"df_test.isnull().sum()","e0bd9f5d":"df.describe()","ae22225e":"chart = sns.countplot(df.y)\nchart.set_title(f'Cantidad NO ({sum(df.y==0)}) vs SI ({sum(df.y==1)})',{'fontsize':13});","494e6e29":"corr = df.corr().abs()  # vemos los valores absolutos para buscar relaciones entre las features\n# mask = np.tril(np.ones_like(corr, dtype=np.bool))\n\nplt.figure(figsize=(15,10))\nchart = sns.heatmap(corr, cmap='hot_r', annot=True, fmt= '.2f', linewidths=0.4, vmin=0, vmax=1, annot_kws={'size': 10}) # add \"mask=mask,\" for triangular matrix \nchart.set_title(\"Matriz de correlacion\", {'fontsize':14});","e0ad0774":"# Esta comentado porque puede tardar un rato\n# sns.pairplot(df, hue=\"y\", diag_kind=\"kde\");","e98f705a":"# for col in df.drop(columns=['y', 'id']).columns.to_list():\n#     if df[col].dtype != 'object':\n#         print(col, df[col].dtype)\n#         plt.figure(figsize=(12,4))\n        \n#         chart = sns.distplot(df[col], label='Train')\n#         chart = sns.distplot(df_test[col], label='Test')\n        \n#         chart.set_title(f'Distribution of \"{col}\" feature')\n#         plt.legend()\n#         plt.show()","090cd6fd":"for col in df.columns:\n    if df[col].dtype == 'object':\n        print(f'- Column \"{col}\": \\n\\t{df[col].unique()}', end='\\n\\n') ","2b49f57e":"for col in df.drop(columns=['y']).columns.to_list():\n    if df[col].dtype == 'object':\n        df = pd.concat([df.drop(columns=[col]), pd.get_dummies(df[col], prefix=col)], axis=1)\n\ndf.tail(5)","0f4204cc":"for col in df_test.columns.to_list():\n    if df_test[col].dtype == 'object':\n        df_test = pd.concat([df_test.drop(columns=[col]), pd.get_dummies(df_test[col], prefix=col)], axis=1)\n\ndf_test.tail(5)","5b810c85":"# la funcion de set de python nos devuelve un conjunto dada una lista, esto es, un grupo de valores unicos\ncommon_features = list(set(df.columns).intersection(set(df_test.columns)))\n\ndf = df[common_features + ['y']]  # dejamos la columna target en el df de entrenamiento y validacion\n\ndf_test = df_test[common_features]","0e9a666c":"df.duplicated().sum()","9a034a3f":"# Borramos los duplicados\n# df.drop_duplicates(inplace=True)","b0c3e650":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import classification_report, roc_curve, roc_auc_score, f1_score","f20181e7":"X = df.drop(columns=['y']).values\ny = df.y","652b2c2b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=16)","a8462a96":"tree = DecisionTreeClassifier(max_depth=10)","1c180d41":"tree.fit(X_train, y_train)","b2ab4ec3":"f1_score( y_test, tree.predict(X_test) )","6a324040":"print(classification_report(y_test, tree.predict(X_test)))","c7f5ce97":"y_pred_proba = tree.predict_proba(X_test)[:,1]\n\nfpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n\nauc = roc_auc_score(y_test, y_pred_proba)\n\nplt.figure(figsize=(10,5))\nplt.plot(fpr, tpr)\n\nplt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([-0.01, 1.05])\nplt.title(f'ROC CURVE   auc={auc:.4f}')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","70147d02":"y_pred = tree.predict(df_test.values)","80b03317":"import pickle \n\nwith open('model1.pkl', 'wb') as fp:\n    pickle.dump(tree, fp)","41af0c7a":"pd.Series(y_pred, name='y').to_csv('sample_submit.csv', index_label='id')","02d995d4":"!head -n 20 sample_submit.csv","9bd10205":"Vemos las distribuciones de las features numericas","6576a03b":"#### Metricas","1d6b03f6":"Vemos los valores unicos de las features categoricas","2c12fdcd":"## Entrega Clasificacion","f2956107":"Creamos un csv con los resultados de la prediccion para subir en [kaggle](https:\/\/www.kaggle.com\/c\/Banco-PF-DSCOR9)","6fdf6346":"### Modelo de prueba","eeb9d023":"Ver el nombre de la carpeta donde descromprimen los archivos!","b33cbf40":"### EDA","2437e1fb":"### Feature engineer","e7ee48a4":"Transformamos las features categoricas en dummies (oneHotEncoder)","2b657edc":"Como algunos valores pueden no estar en ambos dataframes nos quedamos con las columnas en comun","fa8947f0":"### Submit","54b2c9a4":"Predecimos sobre el conjunto de Test","2dbee823":"Replicamos lo mismo en el dataset de Test"}}