{"cell_type":{"44323542":"code","912a75ce":"code","e92434b4":"code","0abb7016":"code","863aa004":"code","17d77b2f":"code","fe823e66":"code","38a78b23":"code","38963ac5":"code","48276da5":"code","36140999":"code","ba37d62d":"code","69f9958c":"code","674fa36c":"code","e71f4349":"code","eedf553a":"code","18a8745d":"code","26e79c5b":"code","baf27f89":"code","c92a9ddf":"markdown","3475f09e":"markdown","610a8819":"markdown","648e150a":"markdown","e81f5939":"markdown","8a64cf47":"markdown","c122a4da":"markdown","ecbf849b":"markdown","36c51858":"markdown","9e5d7dcf":"markdown","3468d219":"markdown","39f4b478":"markdown","13896c3c":"markdown","4c880846":"markdown"},"source":{"44323542":"import os\nimport re\nimport nltk\nimport requests\nimport warnings\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\nfrom nltk.corpus import stopwords\nnltk.download(\"stopwords\")\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nwarnings.filterwarnings('ignore')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","912a75ce":"books = pd.read_csv('\/kaggle\/input\/bookcrossing-dataset\/Books Data with Category Language and Summary\/Preprocessed_data.csv')\nbooks.head(3)","e92434b4":"df = books.copy()\ndf.dropna(inplace=True)\ndf.reset_index(drop=True, inplace=True)\n\ndf.drop(columns = ['Unnamed: 0','location','isbn',\n                   'img_s','img_m','city','age',\n                   'state','Language','country',\n                   'year_of_publication'],axis=1,inplace = True) #remove useless cols\n\ndf.drop(index=df[df['Category'] == '9'].index, inplace=True) #remove 9 in category\n\ndf.drop(index=df[df['rating'] == 0].index, inplace=True) #remove 0 in rating\n\ndf['Category'] = df['Category'].apply(lambda x: re.sub('[\\W_]+',' ',x).strip())\n\ndf.head()","0abb7016":"def item_based_recommender(book_title):\n    \n    book_title = str(book_title)\n    if book_title in df['book_title'].values:\n    \n        rating_counts = pd.DataFrame(df['book_title'].value_counts())\n        rare_books = rating_counts[rating_counts['book_title'] <= 180].index\n        common_books = df[~df['book_title'].isin(rare_books)]\n        \n        if book_title in rare_books:\n            \n            random = pd.Series(common_books['book_title'].unique()).sample(2).values\n            print('There are no recommendations for this book')\n            print('Try: \\n')\n            print('{}'.format(random[0]),'\\n')\n            print('{}'.format(random[1]),'\\n')\n        \n        else:\n            user_book_df = common_books.pivot_table(index=['user_id'],\n                                                    columns=['book_title'],\n                                                    values='rating')\n        \n            book = user_book_df[book_title]\n            recom_data = pd.DataFrame(user_book_df.corrwith(book). \\\n                                      sort_values(ascending=False)).reset_index(drop=False)\n            \n            if book_title in [book for book in recom_data['book_title']]:\n                recom_data = recom_data.drop(recom_data[recom_data['book_title'] == book_title].index[0])\n                \n            low_rating = []\n            for i in recom_data['book_title']:\n                if df[df['book_title'] == i]['rating'].mean() < 5:\n                    low_rating.append(i)\n                    \n            if recom_data.shape[0] - len(low_rating) > 5:\n                recom_data = recom_data[~recom_data['book_title'].isin(low_rating)]\n            \n            recom_data = recom_data[0:5]    \n            recom_data.columns = ['book_title','corr']\n            \n            fig, axs = plt.subplots(1, 5,figsize=(18,5))\n            fig.suptitle('You may also like these books', size = 22)\n            for i in range(len(recom_data['book_title'].tolist())):\n        \n                url = books.loc[books['book_title'] == recom_data['book_title'].tolist()[i],'img_l'][:1].values[0]\n                im = Image.open(requests.get(url, stream=True).raw)\n                axs[i].imshow(im)\n                axs[i].axis(\"off\")\n                axs[i].set_title('Rating: {}'.format(round(df[df['book_title'] == recom_data['book_title'].tolist()[i]]['rating'].mean(),1)),\n                             y=-0.18,\n                                 color=\"red\",\n                                 fontsize=18)\n                fig.show()\n    else:\n        print('Cant find book in dataset, please check spelling')","863aa004":"item_based_recommender('Fahrenheit 451')","17d77b2f":"item_based_recommender('The Street Lawyer')","fe823e66":"def content_based_recommender(book_title):\n    \n    book_title = str(book_title)\n    if book_title in df['book_title'].values:\n        rating_counts = pd.DataFrame(df['book_title'].value_counts())\n        rare_books = rating_counts[rating_counts['book_title'] <= 100].index\n        common_books = df[~df['book_title'].isin(rare_books)]\n        \n        if book_title in rare_books:\n            \n            random = pd.Series(common_books['book_title'].unique()).sample(2).values\n            print('There are no recommendations for this book')\n            print('Try: \\n')\n            print('{}'.format(random[0]),'\\n')\n            print('{}'.format(random[1]),'\\n')\n        \n        else:\n            \n            common_books = common_books.drop_duplicates(subset=['book_title'])\n            common_books.reset_index(inplace= True)\n            common_books['index'] = [i for i in range(common_books.shape[0])]\n            target_cols = ['book_title','book_author','publisher','Category']\n            common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])]\n            cv = CountVectorizer()\n            count_matrix = cv.fit_transform(common_books['combined_features'])\n            cosine_sim = cosine_similarity(count_matrix)\n            index = common_books[common_books['book_title'] == book_title]['index'].values[0]\n            sim_books = list(enumerate(cosine_sim[index]))\n            sorted_sim_books = sorted(sim_books,key=lambda x:x[1],\n                                      reverse=True)[1:6]\n            \n            books = []\n            for i in range(len(sorted_sim_books)):\n                books.append(common_books[common_books['index'] == sorted_sim_books[i][0]]['book_title'].item())\n            \n            fig, axs = plt.subplots(1, 5,figsize=(18,5))\n            fig.suptitle('You may also like these books', size = 22)\n            for i in range(len(books)):\n        \n                url = common_books.loc[common_books['book_title'] == books[i],'img_l'][:1].values[0]\n                im = Image.open(requests.get(url, stream=True).raw)\n                axs[i].imshow(im)\n                axs[i].axis(\"off\")\n                axs[i].set_title('Rating: {}'.format(round(df[df['book_title'] == books[i]]['rating'].mean(),1)),\n                             y=-0.18,\n                                 color=\"red\",\n                                 fontsize=18)\n                fig.show()\n                     \n    else:\n        \n        print('Cant find book in dataset, please check spelling')","38a78b23":"content_based_recommender('The Testament')","38963ac5":"content_based_recommender('1st to Die: A Novel')","48276da5":"def content_based_recommender2(book_title):\n    \n    book_title = str(book_title)\n    if book_title in df['book_title'].values:\n        rating_counts = pd.DataFrame(df['book_title'].value_counts())\n        rare_books = rating_counts[rating_counts['book_title'] <= 100].index\n        common_books = df[~df['book_title'].isin(rare_books)]\n        \n        if book_title in rare_books:\n            \n            random = pd.Series(common_books['book_title'].unique()).sample(2).values\n            print('There are no recommendations for this book')\n            print('Try: \\n')\n            print('{}'.format(random[0]),'\\n')\n            print('{}'.format(random[1]),'\\n')\n        \n        else:\n            common_books = common_books.drop_duplicates(subset=['book_title'])\n            common_books.reset_index(inplace= True)\n            common_books['index'] = [i for i in range(common_books.shape[0])]\n            \n            summary_filtered = []\n            for i in common_books['Summary']:\n                \n                i = re.sub(\"[^a-zA-Z]\",\" \",i).lower()\n                i = nltk.word_tokenize(i)\n                i = [word for word in i if not word in set(stopwords.words(\"english\"))]\n                i = \" \".join(i)\n                summary_filtered.append(i)\n            \n            common_books['Summary'] = summary_filtered   \n            cv = CountVectorizer()\n            count_matrix = cv.fit_transform(common_books['Summary'])\n            cosine_sim = cosine_similarity(count_matrix)\n            index = common_books[common_books['book_title'] == book_title]['index'].values[0]\n            sim_books = list(enumerate(cosine_sim[index]))\n            sorted_sim_books = sorted(sim_books,key=lambda x:x[1],reverse=True)[1:6]\n            \n            books = []\n            for i in range(len(sorted_sim_books)):\n                books.append(common_books[common_books['index'] == sorted_sim_books[i][0]]['book_title'].item())\n            \n            fig, axs = plt.subplots(1, 5,figsize=(18,5))\n            fig.suptitle('You may also like these books', size = 22)\n            for i in range(len(books)):\n        \n                url = common_books.loc[common_books['book_title'] == books[i],'img_l'][:1].values[0]\n                im = Image.open(requests.get(url, stream=True).raw)\n                axs[i].imshow(im)\n                axs[i].axis(\"off\")\n                axs[i].set_title('Rating: {}'.format(round(df[df['book_title'] == books[i]]['rating'].mean(),1)),\n                             y=-0.18,\n                                 color=\"red\",\n                                 fontsize=18)\n                fig.show()\n                     \n    else:\n        \n        print('Cant find book in dataset, please check spelling')","36140999":"content_based_recommender2('To Kill a Mockingbird')","ba37d62d":"content_based_recommender2('A Walk to Remember')","69f9958c":"def custom_recommender(book_title):\n    \n    #ITEM-BASED\n    book_title = str(book_title)\n    if book_title in df['book_title'].values:\n    \n        rating_counts = pd.DataFrame(df['book_title'].value_counts())\n        rare_books = rating_counts[rating_counts['book_title'] <= 180].index\n        common_books = df[~df['book_title'].isin(rare_books)]\n        \n        if book_title in rare_books:\n            \n            random = pd.Series(common_books['book_title'].unique()).sample(2).values\n            print('There are no recommendations for this book')\n            print('Try: \\n')\n            print('{}'.format(random[0]),'\\n')\n            print('{}'.format(random[1]),'\\n')\n        \n        else:\n            user_book_df = common_books.pivot_table(index=['user_id'],\n                                                    columns=['book_title'], values='rating')\n        \n            book = user_book_df[book_title]  \n            recom_data = pd.DataFrame(user_book_df.corrwith(book). \\\n                                      sort_values(ascending=False)).reset_index(drop=False)\n            \n            if book_title in [book for book in recom_data['book_title']]:\n                recom_data = recom_data.drop(recom_data[recom_data['book_title'] == book_title].index[0])\n                \n            low_rating = []\n            for i in recom_data['book_title']:\n                if df[df['book_title'] == i]['rating'].mean() < 5:\n                    low_rating.append(i)\n                    \n            if recom_data.shape[0] - len(low_rating) > 5:\n                recom_data = recom_data[~recom_data['book_title'].isin(low_rating)]\n            \n            recom_data = recom_data[0:1]    \n            recom_data.columns = ['book_title','corr']\n            recommended_books = []\n            for i in recom_data['book_title']:\n                recommended_books.append(i)\n                \n            df_new = df[~df['book_title'].isin(recommended_books)]\n            \n            #CONTENT-BASED (Title, Author, Publisher, Category)\n            rating_counts = pd.DataFrame(df_new['book_title'].value_counts())\n        \n            rare_books = rating_counts[rating_counts['book_title'] <= 100].index\n    \n            common_books = df_new[~df_new['book_title'].isin(rare_books)]\n            common_books = common_books.drop_duplicates(subset=['book_title'])\n            common_books.reset_index(inplace= True)\n            common_books['index'] = [i for i in range(common_books.shape[0])]   \n            target_cols = ['book_title','book_author','publisher','Category']\n            common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])]\n            cv = CountVectorizer()\n            count_matrix = cv.fit_transform(common_books['combined_features'])\n            cosine_sim = cosine_similarity(count_matrix)\n            index = common_books[common_books['book_title'] == book_title]['index'].values[0]\n            sim_books = list(enumerate(cosine_sim[index]))\n            sorted_sim_books = sorted(sim_books,key=lambda x:x[1],reverse=True)[1:2]\n            \n            books = []\n            for i in range(len(sorted_sim_books)):\n                books.append(common_books[common_books['index'] == sorted_sim_books[i][0]]['book_title'].item())\n                \n            for i in books:\n                recommended_books.append(i)\n            \n            df_new = df_new[~df_new['book_title'].isin(recommended_books)]\n            \n            #CONTENT-BASED (SUMMARY)\n            rating_counts = pd.DataFrame(df_new['book_title'].value_counts())\n            rare_books = rating_counts[rating_counts['book_title'] <= 100].index\n            common_books = df_new[~df_new['book_title'].isin(rare_books)]\n            \n            common_books = common_books.drop_duplicates(subset=['book_title'])\n            common_books.reset_index(inplace= True)\n            common_books['index'] = [i for i in range(common_books.shape[0])]\n            \n            summary_filtered = []\n            for i in common_books['Summary']:\n                \n                i = re.sub(\"[^a-zA-Z]\",\" \",i).lower()\n                i = nltk.word_tokenize(i)\n                i = [word for word in i if not word in set(stopwords.words(\"english\"))]\n                i = \" \".join(i)\n                summary_filtered.append(i)\n            \n            common_books['Summary'] = summary_filtered\n            cv = CountVectorizer()\n            count_matrix = cv.fit_transform(common_books['Summary'])\n            cosine_sim = cosine_similarity(count_matrix) \n            index = common_books[common_books['book_title'] == book_title]['index'].values[0]\n            sim_books = list(enumerate(cosine_sim[index]))\n            sorted_sim_books2 = sorted(sim_books,key=lambda x:x[1],reverse=True)[1:4]\n            sorted_sim_books = sorted_sim_books2[:2]\n            summary_books = []\n            for i in range(len(sorted_sim_books)):\n                summary_books.append(common_books[common_books['index'] == sorted_sim_books[i][0]]['book_title'].item())\n                \n            for i in summary_books:\n                recommended_books.append(i)\n                \n            df_new = df_new[~df_new['book_title'].isin(recommended_books)]\n            \n            #TOP RATED OF CATEGORY\n            category = common_books[common_books['book_title'] == book_title]['Category'].values[0]\n            top_rated = common_books[common_books['Category'] == category].groupby('book_title').agg({'rating':'mean'}).reset_index()\n            \n            if top_rated.shape[0] == 1:\n                recommended_books.append(common_books[common_books['index'] == sorted_sim_books2[2][0]]['book_title'].item())\n                \n            else:\n                top_rated.drop(top_rated[top_rated['book_title'] == book_title].index[0],inplace=True)\n                top_rated = top_rated.sort_values('rating',ascending=False).iloc[:1]['book_title'].values[0]\n                recommended_books.append(top_rated)\n                \n            fig, axs = plt.subplots(1, 5,figsize=(18,5))\n            fig.suptitle('You may also like these books', size = 22)\n            for i in range(len(recommended_books)):\n        \n                url = df.loc[df['book_title'] == recommended_books[i],'img_l'][:1].values[0]\n                im = Image.open(requests.get(url, stream=True).raw)\n                axs[i].imshow(im)\n                axs[i].axis(\"off\")\n                axs[i].set_title('Rating: {}'.format(round(df[df['book_title'] == recommended_books[i]]['rating'].mean(),1)),\n                             y=-0.18,\n                                 color=\"red\",\n                                 fontsize=18)\n                fig.show()     \n\n    else:\n        print('Cant find book in dataset, please check spelling')","674fa36c":"custom_recommender('A Painted House')","e71f4349":"custom_recommender('Snow Falling on Cedars')","eedf553a":"item_based_recommender('Harry Potter and the Order of the Phoenix (Book 5)')","18a8745d":"content_based_recommender('Harry Potter and the Order of the Phoenix (Book 5)')","26e79c5b":"content_based_recommender2('Harry Potter and the Order of the Phoenix (Book 5)')","baf27f89":"custom_recommender('Harry Potter and the Order of the Phoenix (Book 5)')","c92a9ddf":"# Load and Check Data","3475f09e":"# Preprocessing","610a8819":"**If you liked this notebook, please upvote** \ud83d\ude0a\n\n**If you have any suggestions or questions, feel free to comment!**\n\n**Best Wishes!**","648e150a":"## Summary","e81f5939":"# Custom Recommender","8a64cf47":"## Title, Author, Publisher, Category","c122a4da":"# Item-Based Collaborative Filtering","ecbf849b":"# Book Recommendation System","36c51858":"# About Dataset\n\nContains 278,858 users (anonymized but with demographic information) providing 1,149,780 ratings (explicit \/ implicit) about 271,379 books.","9e5d7dcf":"# Content-Based Collaborative Filtering","3468d219":"![recommender.bmp](attachment:3596095b-026a-419e-93dd-38b5c2082d06.bmp)","39f4b478":"# Libraries and Utilities","13896c3c":"# Comparison of All Recommenders","4c880846":"## Content\n\n1. About Dataset\n2. Libraries and Utilities\n3. Preprocessing\n4. Item-Based Collaborative Filtering\n5. Content-Based Collaborative Filtering using *Title, Author, Publisher, Category* as features\n6. Content-Based Collaborative Filtering using *Summary* as a feature\n7. Custom Recommender\n8. Comparison of All Recommenders"}}