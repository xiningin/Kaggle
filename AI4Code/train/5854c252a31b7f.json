{"cell_type":{"f2a2e50f":"code","5ab8d8c3":"code","4e5d0815":"code","0e2b2246":"code","be571df3":"code","e7b600ed":"code","872c60a1":"code","46ad6107":"code","e16ced62":"code","145f5fc2":"code","7a92592d":"code","22c89dd1":"code","b2cd640c":"code","c3a36be5":"code","bb4dfef2":"markdown","0e431bbe":"markdown","01c2fd2d":"markdown","8587db6a":"markdown","27e3e237":"markdown","f94e44f4":"markdown","2ff58f2d":"markdown","b8055c3e":"markdown","c09d8404":"markdown","6aea7543":"markdown","e9312fbc":"markdown","26100f53":"markdown"},"source":{"f2a2e50f":"import pandas as pd\nimport numpy as np\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder","5ab8d8c3":"#directory = r\"C:\\Users\\user\\Desktop\\projet python\\House Prediction Kaggle\"\n#list_of_files = os.listdir(directory) #get file names from directory\n\ndf = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\nsubmmission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\n\ndf.shape","4e5d0815":"features_name = df.columns \nfeatures_name , len(features_name)\n\ntest_null = []\n#for x in df_test.columns:             #Removing the null columns from the test dataset\n    #if df_test[x].isnull().sum() > 0 :\n#        df_test = df_test.drop(x , axis = 1)\n#       test_null.append(x)\ntest_null","0e2b2246":"corr = df.corr()\nplt.subplots(figsize = (20 , 20))\ncmap = sns.heatmap(corr , cmap = 'RdBu') \nplt.title(\"Multicollinearity Plot.\")","be571df3":"#Look for depandant features:\nrows , columns = corr.shape\ncorr_features_detected_2d = []   #The depandant variables list\ncorr_features = corr.columns           #All the corr() features (excluding the NA \/\/ Null values)\n\nfor x in corr_features:\n    \n    for i in corr_features:\n        if (corr[x][i] > 0.8 and i!=x and [i , x] not in corr_features_detected_2d):\n            corr_features_detected_2d.append([x , i])  #Does not contain the corr with 'SalaryPrice'\ncorr_features_detected_1d = []\nfor x in corr_features_detected_2d:\n    \n    if x[0] not in corr_features_detected_1d:\n        corr_features_detected_1d.append(x[0])\n    \n    if x[1] not in corr_features_detected_1d:\n        corr_features_detected_1d.append(x[1])\n        \ndf = df.drop(columns = corr_features_detected_1d)\ndf_test = df_test.drop(columns = corr_features_detected_1d)","e7b600ed":"rows , columns = df.shape\ntemp_na_value = []\nfor x in df.columns:\n    y = df[x].isnull().sum()\n    if y>0:\n        temp_na_value.append([round(y * 100 \/ rows , 3) , x]) #percentage of na values by column\n        \nfrom operator import itemgetter\ntemp_na_value = sorted(temp_na_value, key=itemgetter(0), reverse=True) #sorting the 2d list ::temp_na_value::\n\nfor x in temp_na_value:\n    print (x[0] ,'% of' , x[1] ,'valuesare Na values.')\ntemp_na_value","872c60a1":"temp = []\nfor y in temp_na_value:\n    temp.append(y[1])\nif temp[0] in df.columns:\n    df = df.drop(temp [:5] , axis = 1) #dropping the 5 five columns for the two datasets\n    df_test = df_test.drop(temp [:5] , axis = 1)\nfor x in df.columns:   #labelEnconding for the rest of the columns\n    try:\n        df[x].mean(skipna = True) #random method for the except\n    except:\n        le = LabelEncoder()\n        df[x]= le.fit_transform(df[x].astype(str))\n        df_test[x] = le.fit_transform(df_test[x].astype(str))\nfor x in temp[5:]:\n    try:\n        df[x] = df[x].fillna(df[x].mean(skipna = True))\n        df_test[x] = df_test[x].fillna(df_test[x].mean(skipna = True))\n    except:\n        pass\nfor x in df_test.columns: #found 7 Nan values non filled:\n    if df_test[x].isnull().sum() > 0 :\n        df_test[x] = df_test[x].fillna(df_test[x].mean(skipna = True))\nif df.isnull().sum().sum() == 0:  #Nan_checker\n    print('No Na_values for df~~')\nif df_test.isnull().sum().sum() == 0:  #Nan_checker\n    print('No Na_values for df_test~~')\n\n","46ad6107":"sale_corr = corr['SalePrice'].sort_values(ascending = False).drop('SalePrice')\n\nml_features = []\nfor j in range(0,len(sale_corr)):\n    if sale_corr[j] > 0.3:\n        ml_features.append(sale_corr.index[j])\nml_features","e16ced62":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nparam_grid = {'learning_rate': [x for x in [0.1, 0.2, 0.3, 0.4, 0.5]], 'max_depth' : [x for x in range(4,20)]}\nclf = GridSearchCV(GradientBoostingRegressor() , param_grid = param_grid )\n#clf.fit(X, Y)\n#best_score = clf.best_score_\n#estimators = clf.best_estimator_","145f5fc2":"#print(best_score, estimators)","7a92592d":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import cross_val_score , train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nstnd = StandardScaler()\nX = df #Making the inputs\n#for x in X.columns:\n    #if x not in ml_features:\n        #X = X.drop(x , axis = 1)\nY = df['SalePrice']\nX = X.drop('SalePrice' , axis =1 )\n\nfor x in test_null: #Keeping only the same features as in the test dataset\n    try:\n        X = X.drop(x , axis = 1)\n    except:\n        pass\n\nX_stnd= stnd.fit_transform(X)\nclf = GradientBoostingRegressor(learning_rate = 0.2, max_depth =6, random_state = 42) #check the Gridsearch\nscores = cross_val_score(clf , X_stnd , Y , cv = 3, scoring = 'r2' )\nprint(scores)","22c89dd1":"#for x in df_test.columns:\n#    if x not in X.columns:\n#        df_test = df_test.drop(x , axis = 1) #Getting the model features\n#temp = df_test\n#for x in df_test.columns :   #labelEnconding for the rest of the columns\n#    try:\n#        df_test[x].mean(skipna = True) \n#    except:\n        \n#        le = LabelEncoder()\n#        df_test[x]= le.fit_transform(df_test[x].astype(str))\nclf.fit(X_stnd, Y)\n\ndf_test = stnd.fit_transform(df_test) #Standard Scaling df_test\npredictions = clf.predict(df_test)\npredictions","b2cd640c":"submmission['SalePrice'] = predictions\n#submmission.to_csv(r\"C:\/Users\/user\/Desktop\/projet python\/House Prediction Kaggle\/x_subs\/submission.csv\" , index = False)","c3a36be5":"clf.score(X_stnd, Y)","bb4dfef2":"## Fix na_values:","0e431bbe":"## Using GridSearchCv:","01c2fd2d":"## Check for the highly correlated features with the target 'Sale Price':","8587db6a":"# Building Model :","27e3e237":"## NA Values:","f94e44f4":"## Preliminaries:","2ff58f2d":"## Model:","b8055c3e":"# Import Librairies:   ","c09d8404":"# Import dataset:","6aea7543":"# EDA:","e9312fbc":"We can Drop the first 5 features since all of there values are NA.\nFor the rest we gonna fill them with the mean of each of them after label encoding the string columns.","26100f53":"## Multicollinearity:"}}