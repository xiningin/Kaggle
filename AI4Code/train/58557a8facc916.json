{"cell_type":{"9f2d4d3c":"code","09f73ea6":"code","fc859e25":"code","4b0289d2":"code","ca455a47":"code","4eaa27b7":"code","0caa89fd":"code","325ea3e7":"code","45a7a54c":"code","e1aa987e":"code","2c8b0c8f":"code","91ee52e6":"code","5968bfbb":"code","7b8eb79a":"markdown","4ab7b7cd":"markdown","2753ae99":"markdown","36d816d9":"markdown","7c57d23b":"markdown","b9b8268f":"markdown","5c1c4f4b":"markdown","d71c7c2b":"markdown","dfcf8a18":"markdown","36442dd4":"markdown","587647c5":"markdown","f36c0c2d":"markdown","e764058d":"markdown","a4684f73":"markdown","4ebc41fd":"markdown","b694d41e":"markdown","43d5a73c":"markdown","4bab3cef":"markdown","c7beb08d":"markdown","7a72ffc1":"markdown","a0ab3a49":"markdown","7d25e577":"markdown","59e27431":"markdown","cd0861f5":"markdown","e645e49e":"markdown","908ee5e4":"markdown","fbee0d65":"markdown","517f6f0c":"markdown","6e8d3b92":"markdown"},"source":{"9f2d4d3c":"import pandas as pd\n\ndf_image_labels = pd.read_csv('..\/input\/nfl-health-and-safety-helmet-assignment\/image_labels.csv')\ndf_image_labels.head()","09f73ea6":"img = Image.open('..\/input\/nfl-health-and-safety-helmet-assignment\/images\/57503_000116_Endzone_frame443.jpg')\nimg","fc859e25":"\ndraw_obj = ImageDraw.Draw(img)\n\ndraw_obj.rectangle(((1099, 456), (1099 + 16, 456 + 15)), outline=(255, 0, 0))\nimg","4b0289d2":"df = df_image_labels.where(df_image_labels[\"image\"]==\"57503_000116_Endzone_frame443.jpg\").dropna()\nfor _ ,(l, w, t, h) in df[['left', 'width', 'top', 'height']].iterrows():\n        draw_obj.rectangle(((l, t), (l + w, t + h)), outline=(255, 0, 0), width=2)\n\nimg","ca455a47":"\nfrom IPython.display import Video\n\nVideo(\"..\/input\/nfl-health-and-safety-helmet-assignment\/train\/57583_000082_Endzone.mp4\")\n\n#note : if video does not start here just duble click the video in the dataset and enjoy","4eaa27b7":"Video(\"..\/input\/nfl-health-and-safety-helmet-assignment\/train\/57583_000082_Sideline.mp4\")","0caa89fd":"df_train_labels = pd.read_csv('..\/input\/nfl-health-and-safety-helmet-assignment\/train_labels.csv')\ndf_train_labels.head()","325ea3e7":"# lets look over columns \nprint(df_train_labels.columns)","45a7a54c":"\ndf_train_baseline = pd.read_csv('..\/input\/nfl-health-and-safety-helmet-assignment\/train_baseline_helmets.csv')\n\ndf_train_baseline.head()","e1aa987e":"df_train_player_tracking = pd.read_csv('..\/input\/nfl-health-and-safety-helmet-assignment\/train_player_tracking.csv')\ndf_train_player_tracking.head()","2c8b0c8f":"# look from 5th to 15th\ndf_train_player_tracking.head(20)","91ee52e6":"sub_df = pd.read_csv('..\/input\/nfl-health-and-safety-helmet-assignment\/sample_submission.csv')\nsub_df.head()","5968bfbb":"#end","7b8eb79a":"Let\u2019s go over each column name.\n\n* Gamekey: key for each distinct game\n* playID: key for each distinct play\n* video: name of the video file\n\nLet\u2019s take the e.g.: 57583_000082_Endzone.mp4, here \n\n* string before the first '_' represents the gamekey (57583)\n* string before the second '_' represents the playID (82)\n* string after second '_' represents the Category of the video (either Endzone or Sideline)\n\n            \n* view: endzone or sideline\n* video_frame : name of the video frame (given)\n* frame : frame number (helps to identify the sequence of the frames)","4ab7b7cd":"### train_labels.csv","2753ae99":"Well there is a lot in the data, but primarily we have folders and CSV files. \n\nLets start with folders: \n\n* images\n* train\/test\n\n'images' folder contains images from the game (like the example we saw above). we shall be using this folder for training our helmet detecting model.\n\n'train' and 'test' folders contain the video files that we have to use while training and inferring the helmet and label detector model.\n\nIt can be little overwhelming at first to be asked to deal with images and videos at oncce, but the process is quite easier. It will become much more clearer as we move along.","36d816d9":"Now that we saw the videos we can start understanding train_label.csv ","7c57d23b":"## Let's look at the CSV files ","b9b8268f":"Lets see what the first data point in the image label.csv says \n\n57503_000116_Endzone_frame443.jpg\tHelmet\t**1099\t16\t456\t15**\n    ","5c1c4f4b":"#### Sideline","d71c7c2b":"### train\/test_player_tracking.csv\n\nOne of the most imp csv files ","dfcf8a18":"So, basically, this file contains imperfect baseline predictions for helmet boxes\n\n* They trained a model on the images in the images folder and gave a baseline to us, in other words, we should try developing the model that at least outperforms this model (above the baseline).\n\n","36442dd4":"Understanding the problem is a very important step. The National Football League (NFL) and Amazon Web Services (AWS) are teaming up to develop the best sports injury surveillance and mitigation program. In previous competitions, Kaggle has helped detect helmet impacts. As a next step, the NFL wants to assign specific players to each helmet, which would help accurately identify each player's \u201cexposures\u201d throughout a football play. After reading the information given on the competition\u2019s home page, we can easily understand the situation we are dealing with. Also, we can read more on the NFL and its efforts for health and safety from this website: www.NFL.com\/PlayerHealthandSafety.\n\nTo summarize, we want to detect helmets in the given image and assign the player's number as a label to it.\n","587647c5":"We can see from the time difference in the consecutive data points that we have 10 recordings for every second in the dataset.\n\nLet\u2019s have a quick look at the other columns :\n\n1. x: player position along the long axis of the field.\n2. y: player position along the short axis of the field. \n3. s: speed in yards\/second.\n4. a: acceleration in yards\/second^2.\n5. dis: distance traveled from prior time point, in yards.\n6. o: orientation of player (deg).\n7. dir: angle of player motion (deg).\n8. event: game events like a snap, whistle, etc.\n","f36c0c2d":"# Problem Statement","e764058d":"# Data Tour :)","a4684f73":"### image_labels.csv\n\nThis file contains the corresponding bbox for helmets in the images from the images folder. ","4ebc41fd":"#### Endzone","b694d41e":"Before going to the CSV file let\u2019s have one deep look into the train folder. Remember it contains videos from two distinct angles.\n","43d5a73c":"It gets a little tricky here, so read with attention:\n\nEach player wears a sensor that helps precisely locate them on the field. And all that information is located in the train_player_tracking.csv\n\nWe knew that the position of the player or pretty much every data given in all other CSV files is important for the development and training  of the machine learning algorithms.\n\nBut the real question is how can we use this? Let's find out.\n\n\n","4bab3cef":"Remember every frame (image) multiple helmets and every helmet must be represented by four values left, width, top, and hight.\n\n\n* Label: name of the player wearing a helmet (or number)\n* left, width, top, height: defines the exact position of the helmet in the image \n* impactType: a description of the type of helmet impact: helmet, shoulder, body, ground, etc.\n* isDefinitiveImpact: True\/False indicator of definitive impacts. Definitive impact boxes are given additional weight in the scoring algorithm.\n* isSidelinePlayer: True\/False indicator of if the helmet box is on the sideline of the play. Only rows where this field is False will be used in the scoring.","c7beb08d":"That was all about the videos.\n\nWe know that a video is nothing but just a set of frames (images) running at a very fast rate. The rate at which the frame moves is called as the frame rate. \n\nPreviously in the image_label.csv we saw that there is one image and a lot of helmets and each helmet is represented in one row of CSV file making it large. Here we can think of two images (one from the endzone and another from the sideline video) representing the same situation in the play.\n\n\nTo simplify - There is a play. There are two videos for this play. Each video contains 'x' frames. Each frame makes y rows in the train_label.csv (i.e 'y' helmets).\n","7a72ffc1":"Now we should be clear about images and image_labels.csv, together we can use them for the training of the helmet detector model.","a0ab3a49":"Here, we see three categories of columns: \n\n1. video_frame: \n \tname of the video frame file \n    \n2. left, width, top, height: \n    predicted positions of the helmet in the images \n    \n3. conf: \n    confidence of the model","7d25e577":"Lets look at one image (first one from the above table)","59e27431":"\nWe know gameKey, playID, and player. But what about the remaining attributes?\n\nWe know that players are wearing the sensors, the time column notes the time of recording responses from those sensors.\n\nThis time representation is in the ISO 8601 format, in other words, it shows date and time up to millisecond.","cd0861f5":"This is all the data available to us. We are going to use all of this to build wonderful models going forward.","e645e49e":"### train\/test_baseline_helmets.csv","908ee5e4":"For those who have no idea of what this game is and how the cameras are set:\n\nThere is a play going on in the closed room. There are two cameras in the room, one is on the front wall (endzone view) and another on the side wall (sideline).\n\nThere are two videos for each play, one recording everything from the front and the other recording everything from the side, But both represent the same instance of the play.\n","fbee0d65":"Let\u2019s have a look at the submission.csv file.","517f6f0c":"Let\u2019s have a look at the first video  ","6e8d3b92":"We see there is only one helmet detected. Which means, every row in the image_label.csv represents a single helmet in a single image. If there are x helmets in an image then there will be x rows in the image_labels.csv corresponding to the same image. We can simply iterate over all the rows corresponding to our image and get all the helmets marked."}}