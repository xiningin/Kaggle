{"cell_type":{"5b92d245":"code","30388f67":"code","36c8dd11":"code","10b38d6e":"code","0079113d":"code","f20b0acc":"code","e4a0c38c":"code","4d660ce3":"code","f7e0e4d2":"code","33bafa13":"code","e84206b2":"code","3e7de22e":"code","24fdf51a":"code","138aaf7d":"code","49f8295c":"code","677e39eb":"code","24ca012b":"code","6a77ca0e":"code","9f072593":"code","fbeae69c":"code","27f9a0cb":"code","3a2f06ad":"code","4bbf48b1":"code","72e3dbb0":"code","889b7527":"code","9cfbeb3b":"code","75729aeb":"code","b0f363a8":"code","73f7bee2":"code","f4e0bbfc":"code","05a9cbbf":"code","f85b74ce":"code","dc2b3216":"code","b590c06a":"code","1ad072f8":"code","d778042e":"markdown","cf63c6bc":"markdown","54b202b1":"markdown","8279fd75":"markdown"},"source":{"5b92d245":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","30388f67":"IMAGE_PATH = \"..\/input\/plant-pathology-2020-fgvc7\/images\/\"\nTEST_PATH = \"..\/input\/plant-pathology-2020-fgvc7\/test.csv\"\nTRAIN_PATH = \"..\/input\/plant-pathology-2020-fgvc7\/train.csv\"\nSUB_PATH = \"..\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv\"\n\nsample_submission = pd.read_csv(SUB_PATH)\ntest = pd.read_csv(TEST_PATH)\ntrain = pd.read_csv(TRAIN_PATH)","36c8dd11":"print(train.head())\nprint(train['image_id'].count())\nprint(train.describe())","10b38d6e":"print('Healthy 0, diseases 1: \\n',train['healthy'].value_counts()\/train['image_id'].count())\nprint('\\nHealthy 0, multiple_diseases 1: \\n',train['multiple_diseases'].value_counts()\/train['image_id'].count())\nprint('\\nHealthy 0, rust 1: \\n',train['rust'].value_counts()\/train['image_id'].count())\nprint('\\nHealthy 0, scab 1: \\n',train['scab'].value_counts()\/train['image_id'].count())","0079113d":"print(test.head())\nprint(test['image_id'].count())\nprint(test.describe())","f20b0acc":"print(sample_submission.head())\nprint(sample_submission['image_id'].count())\nprint(sample_submission.describe())","e4a0c38c":"import matplotlib.pyplot as plt\nimport cv2 # Open cv","4d660ce3":"def loadimage(data_input,nb=None):\n    \"\"\"\n    @Input\n        data_input: data\n        nb: nb of image load\n    @Output\n        data_output: dataset\n    \"\"\"\n    data_output = []\n    i=0\n    if nb is None:\n        nb,_=np.shape(data_input)\n        \n    for name in data_input[\"image_id\"]:\n        path = '..\/input\/plant-pathology-2020-fgvc7\/images\/'+name+'.jpg'\n        img=cv2.imread(path)\n        data_output.append(img)\n        if i>nb:\n            break\n        i=i+1\n    return data_output\n        \ndef generalpreprocessing(data_input,function,cmap=None):\n    \"\"\"\n    @Input\n        data_input: data\n        function: function to apply to all the dataset\n    @Output\n        data_output: transformation of data\/preprocessing\n    \"\"\"\n    data_output = []\n    for img in data_input:\n        image = function(img)\n        data_output.append(image) # listing tha datas\n    return data_output\n\ndef plotNimage(data,n,titre=None,cmap=None):\n    fig, axs = plt.subplots(1, n,figsize=(20,20))\n    i=0\n    for ax in axs:\n        ax.set_axis_off()\n        ax.imshow(data[i], cmap = cmap)\n        i=i+1\n    plt.title(titre)\n    plt.show()","f7e0e4d2":"#Set for image processing\nnb_image=4\nimg_trainBGR = loadimage(train,nb_image)\nimg_trainRGB = generalpreprocessing(img_trainBGR,lambda img: cv2.cvtColor(img, cv2.COLOR_BGR2RGB) )#convert in BGR to RGB\nplotNimage(img_trainRGB,nb_image)   ","33bafa13":"#Color-space RGB\nimg_H = generalpreprocessing(img_trainRGB,lambda img: img[:,:,0])# select R canal\nplotNimage(img_H,nb_image,'Channel R',cmap='gray')  \nimg_S = generalpreprocessing(img_trainRGB,lambda img: img[:,:,1])# select G canal\nplotNimage(img_S,nb_image,'Channel G',cmap='gray')  \nimg_V = generalpreprocessing(img_trainRGB,lambda img: img[:,:,2])# select B canal\nplotNimage(img_V,nb_image, 'Channel B',cmap='gray')  \n","e84206b2":"# Color-space HSV\nimg_hsv = generalpreprocessing(img_trainBGR,lambda img: cv2.cvtColor(img, cv2.COLOR_BGR2HSV))# HSV\n\nimg_H = generalpreprocessing(img_hsv,lambda img: img[:,:,0])# select H canal\nplotNimage(img_H,nb_image,'Channel H',cmap='gray')  \nimg_S = generalpreprocessing(img_hsv,lambda img: img[:,:,1])# select S canal\nplotNimage(img_S,nb_image,'Channel S',cmap='gray')  \nimg_V = generalpreprocessing(img_hsv,lambda img: img[:,:,2])# select V canal\nplotNimage(img_V,nb_image,'Channel V',cmap='gray')  ","3e7de22e":"# Canny filter: derivative + gaussian\nimg_canny = generalpreprocessing(img_trainBGR,lambda img: cv2.Canny(img,threshold1=100,threshold2=100))# canny filter good for some not for all\nplotNimage(img_canny,nb_image,'Canny',cmap='gray')","24fdf51a":"# Fourier transform\ndef FT(img):\n    f = np.fft.fft2(img)\n    fshift = np.fft.fftshift(f)\n    return fshift\n\nimg_grey = generalpreprocessing(img_trainBGR,lambda img: cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\nimg_FT = generalpreprocessing(img_grey,lambda img: FT(img))#input in CNN\nimg_magFT=20*np.log(np.abs(img_FT)+0.01)#for plot only\nplotNimage(img_magFT,nb_image,'Fourier transform',cmap='gray')","138aaf7d":"# Inverse Fourier transform #allow us to use filter in frequency field\ndef invFT(img_in):\n    f_ishift = np.fft.ifftshift(img_in)\n    img_back = np.fft.ifft2(f_ishift)\n    img_out = np.real(img_back)\n    return img_out\nimg_back = generalpreprocessing(img_FT,lambda img: invFT(img))\nplotNimage(img_back,nb_image,'Image back',cmap='gray')","49f8295c":"print('Check dimension after fourier transform')\nprint(np.shape(img_FT[0]))\nprint(np.shape(img_back[0]))","677e39eb":"from keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model,Input\nfrom keras.layers import Dense,Conv2D,Dropout,BatchNormalization,Activation,GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom keras.applications import DenseNet121\n\n#To compare with: https:\/\/www.kaggle.com\/shawon10\/plant-pathology-classification-using-densenet121\/","24ca012b":"x = train['image_id']","6a77ca0e":"img_size=150","9f072593":"train_image=[]\nfor name in train['image_id']:\n    path='\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/'+name+'.jpg'\n    img=cv2.imread(path)\n    image=cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_AREA)\n            \n    #Grey scale\n    img_grey= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    #Fourier transform\n    f = np.fft.fft2(img_grey)\n    fshift = np.fft.fftshift(f)\n    img_magFT=20*np.log(np.abs(fshift)+0.01)\n\n    #Normalise channel\n    image=image\/np.max(image)\n    img_magFT=img_magFT\/np.max(img_magFT)\n\n    #Add FT channel\n    imgbis=cv2.merge((image[:,:,0],image[:,:,1],image[:,:,2],#BGR\n                      img_magFT[:,:])) #FT\n                      \n    train_image.append(imgbis)","fbeae69c":"test_image=[]\nfor name in test['image_id']:\n    path='\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/'+name+'.jpg'\n    img=cv2.imread(path)\n    image=cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_AREA)\n     \n    #Grey scale\n    img_grey= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    #Fourier transform\n    f = np.fft.fft2(img_grey)\n    fshift = np.fft.fftshift(f)\n    img_magFT=20*np.log(np.abs(fshift)+0.01)\n\n    #Normalise channel\n    image=image\/np.max(image)\n    img_magFT=img_magFT\/np.max(img_magFT)\n\n    #Add FT channel\n    imgbis=cv2.merge((image[:,:,0],image[:,:,1],image[:,:,2],#BGR\n                      img_magFT[:,:])) #FT\n\n    test_image.append(imgbis)","27f9a0cb":"#from keras.preprocessing.image import img_to_array\nX_Train = np.ndarray(shape=(len(train_image), img_size, img_size, 4),dtype = np.float32)\ni=0\nfor image in train_image:\n    #X_Train[i]=img_to_array(image)\n    X_Train[i]=train_image[i]\n    i=i+1\nprint('Train Shape: {}'.format(X_Train.shape))","3a2f06ad":"X_Test = np.ndarray(shape=(len(test_image), img_size, img_size, 4),dtype = np.float32)\ni=0\nfor image in test_image:\n    #X_Test[i]=img_to_array(image)\n    X_Test[i]=test_image[i]\n    i=i+1\nprint('Test Shape: {}'.format(X_Test.shape))","4bbf48b1":"y = train.copy()\ndel y['image_id']\ny.head()","72e3dbb0":"y_train = np.array(y.values)\nprint(y_train.shape,y_train[0])","889b7527":"X_train, X_val, Y_train, Y_val = train_test_split(X_Train, y_train, test_size=0.2, random_state=42)","9cfbeb3b":"def build_densenet():\n    densenet = DenseNet121(weights='imagenet', include_top=False)\n\n    input = Input(shape=(img_size, img_size, 4))\n    x = Conv2D(3, (3, 3), padding='same')(input)\n    \n    x = densenet(x)\n    \n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n\n    # multi output\n    output = Dense(4,activation = 'softmax', name='root')(x)\n \n\n    # model\n    model = Model(input,output)\n    \n    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    model.summary()\n    \n    return model","75729aeb":"model = build_densenet()","b0f363a8":"annealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\ncheckpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n# Generates batches of image data with data augmentation\ndatagen = ImageDataGenerator(horizontal_flip=True, # Randomly flip inputs horizontally\n                             vertical_flip=True) # Randomly flip inputs vertically\ndatagen.fit(X_train)","73f7bee2":"# Fits the model on batches with real-time data augmentation\nhist = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n               steps_per_epoch=X_train.shape[0] \/\/ 32,\n               epochs=50,\n               verbose=2,\n               callbacks=[annealer, checkpoint],\n               validation_data=(X_val, Y_val))","f4e0bbfc":"print(hist.history.keys())\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","05a9cbbf":"predict = model.predict(X_Test)\nall_predict = np.ndarray(shape = (test.shape[0],4),dtype = np.float32)\nfor i in range(0,test.shape[0]):\n    for j in range(0,4):\n        if predict[i][j]==max(predict[i]):\n            all_predict[i][j] = 1\n        else:\n            all_predict[i][j] = 0 ","f85b74ce":"healthy = [y_test[0] for y_test in all_predict]\nmultiple_diseases = [y_test[1] for y_test in all_predict]\nrust = [y_test[2] for y_test in all_predict]\nscab = [y_test[3] for y_test in all_predict]","dc2b3216":"df = {'image_id':test.image_id,'healthy':healthy,'multiple_diseases':multiple_diseases,'rust':rust,'scab':scab}","b590c06a":"data = pd.DataFrame(df)\ndata.tail()","1ad072f8":"data.to_csv('submission.csv',index = False)","d778042e":"# DenseNet 121","cf63c6bc":"# Image processing","54b202b1":"# Submission","8279fd75":"# Statistic"}}