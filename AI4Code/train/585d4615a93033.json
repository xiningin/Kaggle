{"cell_type":{"817b3659":"code","03aba84a":"code","4a06cf87":"code","4bc06ed5":"code","166fad66":"code","0549fc00":"code","e2408855":"code","758b1dc1":"code","b8cc1293":"code","56fc6a0a":"code","5f858708":"code","ae6da60c":"code","8b6d80d2":"code","5ea59650":"code","04acbdf9":"code","fbcc8649":"code","0beaada3":"code","c85d3fc6":"code","98f76447":"code","e527456a":"code","3422de7a":"code","10bbbf9d":"code","01f6358b":"code","155b30f2":"code","51d91a76":"code","523bcd03":"code","0642c0a9":"code","7b8b6235":"code","634af3a8":"code","877262cc":"code","67b32ab2":"code","dfa6e741":"code","a2d7e4e8":"code","2fe0967b":"code","c7016813":"code","382e906b":"code","378fc755":"code","c48a371c":"code","37bbf5c0":"code","7d77baca":"code","c059bc1e":"markdown","91feacbc":"markdown","5b564d6a":"markdown","48815fd5":"markdown","f666bb5e":"markdown","6f20fab8":"markdown","74348f2b":"markdown","334cddb5":"markdown","e044d2fb":"markdown","740e64e2":"markdown","466a4cc2":"markdown","34281a4d":"markdown","dc02d541":"markdown","836062cb":"markdown","fb65f875":"markdown","1a448e5e":"markdown","05c083fd":"markdown","b2d5e609":"markdown","09c11474":"markdown","aa10dedc":"markdown","70dc0b61":"markdown","11a084b9":"markdown","3b3f2e98":"markdown","818b6a24":"markdown","e2448845":"markdown","5e475d74":"markdown","00c6a7f4":"markdown","3c071cd9":"markdown","d7314a85":"markdown","1bb95cc6":"markdown","6005bd8a":"markdown","9d340893":"markdown","04145767":"markdown","cee54fd0":"markdown","315ea797":"markdown"},"source":{"817b3659":"import numpy as np\nimport pandas as pd\n        \nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go","03aba84a":"data = pd.read_csv('\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\ndata","4a06cf87":"questions = data.iloc[0]\ndata = data.drop(data.index[0])\nquestions","4bc06ed5":"data","166fad66":"ds = data['Q1'].value_counts().reset_index()\nds.columns = [\n    'age', \n    'count'\n]\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"age\", \n    orientation='h', \n    title='Age distribution', \n    width=800,\n    height=600 \n)\n\nfig.show()","0549fc00":"ds = data['Q2'].value_counts().reset_index()\nds.columns = [\n    'sex', \n    'count'\n]\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"sex\", \n    orientation='h', \n    title='Sex distribution', \n    width=800,\n    height=400 \n)\n\nfig.show()","e2408855":"ds = data['Q3'].value_counts().reset_index()\nds.columns = [\n    'country', \n    'count'\n]\nds['country'] = ds['country'].replace(\n    {\n        'United Kingdom of Great Britain and Northern Ireland': 'United Kingdom'\n    }\n)\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"country\", \n    orientation='h', \n    title='Country distribution', \n    width=800,\n    height=1000 \n)\n\nfig.show()","758b1dc1":"ds = data['Q4'].value_counts().reset_index()\nds.columns = [\n    'degree', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"degree\", \n    orientation='h', \n    title='Degree distribution', \n    width=800,\n    height=500 \n)\n\nfig.show()","b8cc1293":"ds = data['Q5'].value_counts().reset_index()\nds.columns = [\n    'title', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"title\", \n    orientation='h', \n    title='Title distribution', \n    width=800,\n    height=500 \n)\n\nfig.show()","56fc6a0a":"ds = data['Q6'].value_counts().reset_index()\nds.columns = [\n    'exp', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"exp\", \n    orientation='h', \n    title='Coding experience distribution', \n    width=800,\n    height=500 \n)\n\nfig.show()","5f858708":"q7 = [\n    'Q7_Part_1', 'Q7_Part_2', 'Q7_Part_3', 'Q7_Part_4', \n    'Q7_Part_5', 'Q7_Part_6', 'Q7_Part_7', 'Q7_Part_8', \n    'Q7_Part_9', 'Q7_Part_10', 'Q7_Part_11', \n    'Q7_Part_12', 'Q7_OTHER'\n]\n\nds = data['Q7_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q7)):\n    term = data[q7[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title='Programming languages distribution', \n    width=800,\n    height=500 \n)\n\nfig.show()","ae6da60c":"ds = data['Q8'].value_counts().reset_index()\nds.columns = [\n    'exp', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"exp\", \n    orientation='h', \n    title='Recommended language distribution', \n    width=800,\n    height=600 \n)\n\nfig.show()","8b6d80d2":"q9 = [\n    'Q9_Part_1', 'Q9_Part_2', 'Q9_Part_3', 'Q9_Part_4', \n    'Q9_Part_5', 'Q9_Part_6', 'Q9_Part_7', 'Q9_Part_8', \n    'Q9_Part_9', 'Q9_Part_10', 'Q9_Part_11', 'Q9_OTHER'\n]\n\nds = data['Q9_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q9)):\n    term = data[q9[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"IDE's distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","5ea59650":"q10 = [\n    'Q10_Part_1', 'Q10_Part_2', 'Q10_Part_3', 'Q10_Part_4', \n    'Q10_Part_5', 'Q10_Part_6', 'Q10_Part_7', 'Q10_Part_8', \n    'Q10_Part_9', 'Q10_Part_10', 'Q10_Part_11', \n    'Q10_Part_12', 'Q10_Part_13', 'Q10_OTHER'\n]\n\nds = data['Q10_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q10)):\n    term = data[q10[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Popular hosted notebooks distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","04acbdf9":"ds = data['Q11'].value_counts().reset_index()\nds.columns = [\n    'exp', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"exp\", \n    orientation='h', \n    title='Computing platform distribution', \n    width=800,\n    height=400 \n)\n\nfig.show()","fbcc8649":"q12 = [\n    'Q12_Part_1', 'Q12_Part_2', 'Q12_Part_3', 'Q12_OTHER'\n]\n\nds = data['Q12_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q12)):\n    term = data[q12[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Used hardware distribution\", \n    width=800,\n    height=400 \n)\n\nfig.show()","0beaada3":"ds = data['Q13'].value_counts().reset_index()\nds.columns = [\n    'exp', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"exp\", \n    orientation='h', \n    title='TPU usage distribution', \n    width=800,\n    height=600 \n)\n\nfig.show()","c85d3fc6":"q14 = [\n    'Q14_Part_1', 'Q14_Part_2', 'Q14_Part_3', 'Q14_Part_4', \n    'Q14_Part_5', 'Q14_Part_6', 'Q14_Part_7', 'Q14_Part_8', \n    'Q14_Part_9', 'Q14_Part_10', 'Q14_Part_11', 'Q14_OTHER'\n]\n\nds = data['Q14_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q14)):\n    term = data[q14[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Popular visualization libraries distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","98f76447":"ds = data['Q15'].value_counts().reset_index()\nds.columns = [\n    'exp', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"exp\", \n    orientation='h', \n    title='Years in ML distribution', \n    width=800,\n    height=600 \n)\n\nfig.show()","e527456a":"q16 = [\n    'Q16_Part_1', 'Q16_Part_2', 'Q16_Part_3', 'Q16_Part_4', \n    'Q16_Part_5', 'Q16_Part_6', 'Q16_Part_7', 'Q16_Part_8', \n    'Q16_Part_9', 'Q16_Part_10', 'Q16_Part_11', 'Q16_Part_12',\n    'Q16_Part_13', 'Q16_Part_14', 'Q16_Part_15', 'Q16_OTHER'\n]\n\nds = data['Q16_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q16)):\n    term = data[q16[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Popular ML frameworks distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","3422de7a":"q17 = [\n    'Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', \n    'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', \n    'Q17_Part_9', 'Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER'\n]\n\nds = data['Q17_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q17)):\n    term = data[q17[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Popular ML algorithms distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","10bbbf9d":"q18 = [\n    'Q18_Part_1', 'Q18_Part_2', 'Q18_Part_3', 'Q18_Part_4', \n    'Q18_Part_5', 'Q18_Part_6', 'Q18_OTHER'\n]\n\nds = data['Q18_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q18)):\n    term = data[q18[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Popular CV methods distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","01f6358b":"q19 = [\n    'Q19_Part_1', 'Q19_Part_2', 'Q19_Part_3', 'Q19_Part_4', \n    'Q19_Part_5', 'Q19_OTHER'\n]\n\nds = data['Q19_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q19)):\n    term = data[q19[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Popular NLP methods distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","155b30f2":"ds = data['Q20'].value_counts().reset_index()\nds.columns = [\n    'exp', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"exp\", \n    orientation='h', \n    title='Company size distribution', \n    width=800,\n    height=600 \n)\n\nfig.show()","51d91a76":"ds = data['Q21'].value_counts().reset_index()\nds.columns = [\n    'exp', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"exp\", \n    orientation='h', \n    title='DS team size distribution', \n    width=800,\n    height=600 \n)\n\nfig.show()","523bcd03":"ds = data['Q22'].value_counts().reset_index()\nds.columns = [\n    'exp', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"exp\", \n    orientation='h', \n    title='ML methods usage distribution', \n    width=800,\n    height=600 \n)\n\nfig.show()","0642c0a9":"q23 = [\n    'Q23_Part_1', 'Q23_Part_2', 'Q23_Part_3', 'Q23_Part_4', \n    'Q23_Part_5', 'Q23_Part_6', 'Q23_Part_7', 'Q23_OTHER'\n]\n\nds = data['Q23_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q23)):\n    term = data[q23[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Important activities distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","7b8b6235":"ds = data['Q24'].value_counts().reset_index()\nds.columns = [\n    'exp', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"exp\", \n    orientation='h', \n    title='Yearly compensation distribution', \n    width=800,\n    height=600 \n)\n\nfig.show()","634af3a8":"ds = data['Q25'].value_counts().reset_index()\nds.columns = [\n    'exp', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"exp\", \n    orientation='h', \n    title='Money spent on ML distribution', \n    width=800,\n    height=600 \n)\n\nfig.show()","877262cc":"q26 = [\n    'Q26_A_Part_1', 'Q26_A_Part_2', 'Q26_A_Part_3', 'Q26_A_Part_4', \n    'Q26_A_Part_5', 'Q26_A_Part_6', 'Q26_A_Part_7', 'Q26_A_Part_8',\n    'Q26_A_Part_9', 'Q26_A_Part_10', 'Q26_A_Part_11','Q26_A_OTHER'\n]\n\nds = data['Q26_A_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q26)):\n    term = data[q26[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Cloud computing platforms distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","67b32ab2":"q27 = [\n    'Q27_A_Part_1', 'Q27_A_Part_2', 'Q27_A_Part_3', 'Q27_A_Part_4', \n    'Q27_A_Part_5', 'Q27_A_Part_6', 'Q27_A_Part_7', 'Q27_A_Part_8',\n    'Q27_A_Part_9', 'Q27_A_Part_10', 'Q27_A_Part_11','Q27_A_OTHER'\n]\n\nds = data['Q27_A_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q27)):\n    term = data[q27[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Cloud computing products distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","dfa6e741":"q28 = [\n    'Q28_A_Part_1', 'Q28_A_Part_2', 'Q28_A_Part_3', 'Q28_A_Part_4', \n    'Q28_A_Part_5', 'Q28_A_Part_6', 'Q28_A_Part_7', 'Q28_A_Part_8',\n    'Q28_A_Part_9', 'Q28_A_Part_10','Q28_A_OTHER'\n]\n\nds = data['Q28_A_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q28)):\n    term = data[q28[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"ML products distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","a2d7e4e8":"q29 = [\n    'Q29_A_Part_1', 'Q29_A_Part_2', 'Q29_A_Part_3', 'Q29_A_Part_4', \n    'Q29_A_Part_5', 'Q29_A_Part_6', 'Q29_A_Part_7', 'Q29_A_Part_8',\n    'Q29_A_Part_9', 'Q29_A_Part_10', 'Q29_A_Part_11', 'Q29_A_Part_12',\n    'Q29_A_Part_13', 'Q29_A_Part_14', 'Q29_A_Part_15', 'Q29_A_Part_16',\n    'Q29_A_Part_17', 'Q29_A_OTHER'\n]\n\nds = data['Q29_A_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q29)):\n    term = data[q29[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Big Data Products distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","2fe0967b":"ds = data['Q30'].value_counts().reset_index()\nds.columns = [\n    'exp', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"exp\", \n    orientation='h', \n    title='Most used big data products distribution', \n    width=800,\n    height=600 \n)\n\nfig.show()","c7016813":"q31 = [\n    'Q31_A_Part_1', 'Q31_A_Part_2', 'Q31_A_Part_3', 'Q31_A_Part_4', \n    'Q31_A_Part_5', 'Q31_A_Part_6', 'Q31_A_Part_7', 'Q31_A_Part_8',\n    'Q31_A_Part_9', 'Q31_A_Part_10', 'Q31_A_Part_11', 'Q31_A_Part_12',\n    'Q31_A_Part_13', 'Q31_A_Part_14', 'Q31_A_OTHER'\n]\n\nds = data['Q31_A_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q31)):\n    term = data[q31[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"BI Products distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","382e906b":"ds = data['Q32'].value_counts().reset_index()\nds.columns = [\n    'exp', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"exp\", \n    orientation='h', \n    title='Most used BI products distribution', \n    width=800,\n    height=600 \n)\n\nfig.show()","378fc755":"q33 = [\n    'Q33_A_Part_1', 'Q33_A_Part_2', 'Q33_A_Part_3', 'Q33_A_Part_4', \n    'Q33_A_Part_5', 'Q33_A_Part_6', 'Q33_A_Part_7', 'Q33_A_OTHER'\n]\n\nds = data['Q33_A_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q33)):\n    term = data[q33[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Automated ML tools distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","c48a371c":"q34 = [\n    'Q34_A_Part_1', 'Q34_A_Part_2', 'Q34_A_Part_3', 'Q34_A_Part_4', \n    'Q34_A_Part_5', 'Q34_A_Part_6', 'Q34_A_Part_7', 'Q34_A_Part_8',\n    'Q34_A_Part_9', 'Q34_A_Part_10', 'Q34_A_Part_11', 'Q34_A_OTHER'\n]\n\nds = data['Q34_A_Part_1'].value_counts().reset_index()\nds.columns = [\n    'language', \n    'users'\n]\n\nfor i in range(1, len(q34)):\n    term = data[q34[i]].value_counts().reset_index()\n    term.columns = [\n        'language', \n        'users'\n    ]\n    ds = pd.concat([ds, term])\n\nds = ds.sort_values(['users'])\n\nfig = px.bar(\n    ds, \n    x='users', \n    y=\"language\", \n    orientation='h', \n    title=\"Most used Automated ML tools distribution\", \n    width=800,\n    height=500 \n)\n\nfig.show()","37bbf5c0":"questions[198]","7d77baca":"questions[208:]","c059bc1e":"<a id=\"9\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q9. Which of the following integrated development environments (IDE's) do you use on a regular basis?<\/center><h2>","91feacbc":"<a id=\"17\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q17. Which of the following ML algorithms do you use on a regular basis?<\/center><h2>","5b564d6a":"<a id=\"19\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q19. Which of the following natural language processing (NLP) methods do you use on a regular basis?<\/center><h2>","48815fd5":"<a id=\"5\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q5. Select the title most similar to your current role (or most recent title if retired)<\/center><h2>","f666bb5e":"<a id=\"32\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q32. Which of the following business intelligence tools do you use most often?<\/center><h2>","6f20fab8":"<a id=\"28\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q28. Do you use any of the following machine learning products on a regular basis?<\/center><h2>","74348f2b":"<a id=\"33\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q33. Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?<\/center><h2>","334cddb5":"<a id=\"24\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q24. What is your current yearly compensation<\/center><h2>","e044d2fb":"<a id=\"4\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q4. What is the highest level of formal education that you have attained or plan to attain within the next 2 years?<\/center><h2>","740e64e2":"<a id=\"27\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q27. Do you use any of the following cloud computing products on a regular basis?<\/center><h2>","466a4cc2":"<a id=\"29\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q29. Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis?<\/center><h2>\n","34281a4d":"<a id=\"14\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q14. What data visualization libraries or tools do you use on a regular basis?<\/center><h2>","dc02d541":"\n<h2><center>2020 Kaggle ML & DS Survey. Full overview.<\/center><\/h2>\n\n<center><img src=\"https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/16394\/logos\/header.png?t=2019-10-17-20-37-58\"><\/center>","836062cb":"<a id=\"20\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q20. What is the size of the company where you are employed?<\/center><h2>","fb65f875":"<a id=\"31\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q31. Which of the following business intelligence tools do you use on a regular basis?<\/center><h2>","1a448e5e":"<a id=\"10\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q10. Which of the following hosted notebook products do you use on a regular basis?<\/center><h2>","05c083fd":"<a id=\"6\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q6. For how many years have you been writing code and\/or programming?<\/center><h2>","b2d5e609":"<a id=\"8\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q8. What programming language would you recommend an aspiring data scientist to learn first?<\/center><h2>","09c11474":"<a id=\"22\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q22. Does your current employer incorporate machine learning methods into their business?<\/center><h2>","aa10dedc":"<a id=\"23\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q23. Select any activities that make up an important part of your role at work<\/center><h2>","70dc0b61":"<a id=\"1\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q2. What is your gender?<\/center><h2>","11a084b9":"<a id=\"16\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q16. Which of the following machine learning frameworks do you use on a regular basis?<\/center><h2>","3b3f2e98":"<a id=\"21\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q21. Approximately how many individuals are responsible for data science workloads at your place of business?<\/center><h2>","818b6a24":"<a id=\"15\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q15. For how many years have you used machine learning methods?<\/center><h2>","e2448845":"<a id=\"26\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q26. Which of the following cloud computing platforms do you use on a regular basis?<\/center><h2>","5e475d74":"<a id=\"13\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q13. Approximately how many times have you used a TPU (tensor processing unit)?<\/center><h2>","00c6a7f4":"<a id=\"1\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q1. What is your age (# years)?<\/center><h2>","3c071cd9":"<a id=\"11\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q11. What type of computing platform do you use most often for your data science projects?<\/center><h2>","d7314a85":"<a id=\"12\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q12. Which types of specialized hardware do you use on a regular basis?<\/center><h2>","1bb95cc6":"<a id=\"30\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q30. Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?<\/center><h2>","6005bd8a":"<a id=\"34\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q34. Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?<\/center><h2>","9d340893":"<a id=\"3\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q3. In which country do you currently reside?<\/center><h2>","04145767":"<a id=\"25\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q25. Approximately how much money have you (or your team) spent on machine learning and\/or cloud computing services at home (or at work) in the past 5 years (approximate $USD)?<\/center><h2>","cee54fd0":"<a id=\"18\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q18. Which categories of computer vision methods do you use on a regular basis?<\/center><h2>","315ea797":"<a id=\"7\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Q7. What programming languages do you use on a regular basis?<\/center><h2>"}}