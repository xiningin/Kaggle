{"cell_type":{"7ba158e5":"code","0bbaa812":"code","2cca7420":"code","30599738":"code","23e70f18":"code","02a90c26":"code","99915541":"code","2d06b726":"code","df1c09d1":"code","de2feab0":"code","9db9687d":"code","8a5e55b4":"code","6f097470":"code","f1f3cd93":"code","a5100a3b":"code","43c94d10":"code","aab46c1b":"code","d3102bc5":"code","8a79f478":"code","e1b58af9":"code","ca5617aa":"code","94addecb":"code","19497d26":"code","adbf1f27":"code","a87702bb":"code","73578bab":"code","6ce10a9f":"code","7cf6012d":"code","e4119a9c":"code","dd486b76":"code","b4bc6061":"code","97564c41":"code","12ffe8c7":"code","e98b30c5":"code","8d7ec968":"code","54ea31d0":"code","9458ec9d":"code","f9c90243":"code","bf733995":"code","3cd58165":"code","99e9991a":"code","270e87a0":"code","b0fb941b":"code","bf57ba66":"code","4353be97":"code","91ca75b6":"code","0bdb5d13":"code","55d747e3":"code","c11e2529":"code","63de2fd1":"code","e175ba6f":"code","ccd40b0a":"code","f8b8e094":"code","fa9ef068":"code","5fd97770":"code","031a0791":"code","1b8bda34":"code","ca8d8418":"markdown","cfcbca2c":"markdown","06bc1ecc":"markdown","15a761b8":"markdown","61b707a6":"markdown","189b64d6":"markdown","7b805a92":"markdown","2b67ac8f":"markdown","2678ea7f":"markdown","d3d2922b":"markdown","ccb83b8b":"markdown","9a52a8e0":"markdown","058be80f":"markdown","a18cabc2":"markdown","695aee8c":"markdown","eccc5b85":"markdown","5823b282":"markdown","7edbfd84":"markdown","4317af71":"markdown","56d2fadd":"markdown","6727edf4":"markdown","a5132ead":"markdown","da45a4f5":"markdown","dfa5547f":"markdown","213fe3bb":"markdown","27fc8229":"markdown","a83ecadb":"markdown","dade2867":"markdown","0a37b1ee":"markdown","9151669c":"markdown"},"source":{"7ba158e5":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport gc\nfrom contextlib import redirect_stdout","0bbaa812":"baseline_train = pd.read_csv(\"..\/input\/google-smartphone-decimeter-challenge\/baseline_locations_train.csv\")\nbaseline_test = pd.read_csv(\"..\/input\/google-smartphone-decimeter-challenge\/baseline_locations_test.csv\")\nsubmission = pd.read_csv(\"..\/input\/google-smartphone-decimeter-challenge\/sample_submission.csv\")\n# submission = submission.assign(latDeg=test.latDeg.round(6), lngDeg=test.lngDeg.round(6))","2cca7420":"import numpy as np\n\n# evaluation\ndef calc_haversine(lat1, lon1, lat2, lon2):\n    \"\"\"Calculates the great circle\uff08\u5186\u5468\uff09 distance between two points\n    on the earth. Inputs are array-like and specified in decimal degrees.\n    \u7def\u5ea6\u7d4c\u5ea6\u306e2\u5730\u70b9\u9593\u306e\u5730\u7403\u4e0a\u306e\u5186\u5468\u8ddd\u96e2\u3092\u8a08\u7b97\uff08haversine formula\uff09\n    \"\"\"\n    RADIUS = 6_367_000 # \u8d64\u9053\u534a\u5f84\uff1a6_378_100[m], \u6975\u534a\u5f84\uff1a 6_356_775[m], avg. = 6_367_437.5[m]\n    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = np.sin(dlat\/2)**2 + \\\n        np.cos(lat1) * np.cos(lat2) * np.sin(dlon\/2)**2\n    dist = 2 * RADIUS * np.arcsin(a**0.5)\n    return dist\n\n# percentile: \u4e2d\u592e\u5024\u30844\u5206\u6570\u306e\u4e00\u822c\u5316\u300150\u30d1\u30fc\u30bb\u30f3\u30bf\u30a4\u30eb\u2192\u4e2d\u592e\u5024\u300195\u30d1\u30fc\u30bb\u30f3\u30bf\u30a4\u30eb\u2192\u4e0a\u4f4d5%\u306e\u533a\u5207\u308a\u306e\u5024\ndef percentile50(x):\n    return np.percentile(x, 50)\n\ndef percentile95(x):\n    return np.percentile(x, 95)\n\ndef get_train_score(df, gt):\n    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n    # calc_distance_error\n    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n    # calc_evaluate_score\n    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n    res = df.groupby('phone')['err'].agg([percentile50, percentile95])\n    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) \/ 2 \n    score = res['p50_p90_mean'].mean()\n    return score","30599738":"# ground_truth\nimport pathlib\nfrom tqdm.notebook import tqdm\nINPUT = '..\/input\/google-smartphone-decimeter-challenge'\n\np = pathlib.Path(INPUT)\ngt_files = list(p.glob('train\/*\/*\/ground_truth.csv'))\nprint('ground_truth.csv count : ', len(gt_files))\n\ngts = []\nfor gt_file in tqdm(gt_files):\n    gts.append(pd.read_csv(gt_file))\nground_truth = pd.concat(gts)","23e70f18":"print(get_train_score(baseline_train, ground_truth))","02a90c26":"def ansolute_error(df, gt):\n    # calc_distance_error\n    err_latDeg = abs(df[\"latDeg\"] - gt[\"latDeg\"])\n    err_lngDeg = abs(df[\"lngDeg\"] - gt[\"lngDeg\"])\n    return err_latDeg, err_lngDeg\n#err_latDeg, err_lngDeg = ansolute_error(baseline_train, ground_truth)\n#print(err_latDeg.mean(), err_lngDeg.mean())","99915541":"del baseline_train, baseline_test, submission\ngc.collect()","2d06b726":"import pandas as pd\nimport copy\nimport numpy as np\nimport pathlib\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom multiprocessing import Pool\nimport multiprocessing as multi\n\n\nINPUT = '..\/input\/google-smartphone-decimeter-challenge'\np = pathlib.Path(INPUT)","df1c09d1":"def file_load_multi_pricessing(filename):\n    df = pd.read_csv(filename)\n    return df","de2feab0":"class FeatureEngineering:\n    def __init__(self, debug_flag=True):\n        if debug_flag:\n            self.train_files = list(p.glob('train\/*\/*\/*_derived.csv'))\n            self.test_files = list(p.glob('test\/*\/*\/*_derived.csv')) \n            self.raw_data = self.load_raw_data()\n        else:\n            pass\n        \n    def load_raw_data(self):\n        # load all data, return merged train\/test data\n        result_train = []\n        thread_num = multi.cpu_count()\n        with Pool(thread_num) as pool:\n            imap = pool.imap(file_load_multi_pricessing, self.train_files)\n            result_train = list(tqdm(imap, total=len(self.train_files), desc=\"load train data\"))\n        train_data = pd.concat(result_train, ignore_index=True)\n\n        result_test = []\n        with Pool(4) as pool:\n            imap = pool.imap(file_load_multi_pricessing, self.test_files)\n            result_test = list(tqdm(imap, total=len(self.test_files), desc=\"load test data\"))\n        test_data = pd.concat(result_test, ignore_index=True)\n\n        return pd.concat([train_data, test_data])\n\n    def test_all(self):\n        df = self.load_raw_data()        \n        self.df = self.data_process(df)\n    \n    def data_process(self, df):\n        assert len(df) == 6357741, \"train, test\u306b\u540c\u69d8\u306e\u5909\u63db\u304c\u884c\u308f\u308c\u308b\u3053\u3068\u3092\u4fdd\u8a3c\u3059\u308b\u305f\u3081\u306b\u3001\uff12\u3064\u306e\u30c7\u30fc\u30bf\u3092\uff11\u3064\u306eDataFrame\u306b\u307e\u3068\u3081\u3066\u304f\u3060\u3055\u3044\u3002len(df) = 6357741\u884c\u306b\u306a\u308b\u306f\u305a\u3067\u3059\u3002\\n To guarantee train\/test are same transformation, it requires combine train and test data to one DataFrame. It should be len(df)=6357741.\" \n        \n        df = self.received_sv_time_nanos2(df)        \n        df = self.raw_prm2(df)\n        df = self.signal_type2(df)\n        df = self.sat_pos2(df)\n        df = self.sat_vel2(df)\n\n        df = self.sat_clk_bias_m2(df)\n        df = self.sat_clk_drift_mps2(df)\n        df = self.raw_pr_unc_m2(df)\n        df = self.isrb_m2(df)\n        df = self.iono_delay_m2(df)\n        df = self.tropo_delay_m2(df)\n        df = self.constellation_type2(df)\n        df = self.svid2(df)\n\n        gc.collect()\n        return df\n    \n    def received_sv_time_nanos(self, df):\n        print(\"received_sv_time_nanos ... it takes a bit time\")\n        # 'receivedSvTimeInGpsNanos' - 'millisSinceGpsEpoch' = \u885b\u661f\u9001\u4fe1\u6642\u9593\u304b\u3089\u30b9\u30de\u30db\u3067\u306e\u8a18\u9332\u6642\u9593\u306e\u5dee\uff1fmillisSinceGpsEpoch \u2190\u3053\u3044\u3064\u306f\u4f55\u3060\n        df['receivedSvTimeInGpsNanos_processed'] = 1000_000*df['millisSinceGpsEpoch'] - df['receivedSvTimeInGpsNanos'] # float\u3067\u8a08\u7b97\u3067\u304d\u306a\u3044\u5927\u304d\u306a\u5024\u306a\u306e\u3067\u3001int\u3067\u8a08\u7b97\u3057\u305f\u5f8c\u306bfloat\u306b\u3059\u308b\n        df['receivedSvTimeInGpsNanos_processed'] = 0.001*0.001*0.001*df['receivedSvTimeInGpsNanos_processed']  # [sec]\u306b\u3059\u308b\n\n        return df\n    \n    def received_sv_time_nanos2(self, df):\n        print(\"received_sv_time_nanos2\")\n        df = self.received_sv_time_nanos(df)\n        target = df['receivedSvTimeInGpsNanos_processed']\n        \n        target = (target-1.075)\/0.025\n        target[-1 > target] = -1\n        target[1 < target] = 1\n        \n        df['receivedSvTimeInGpsNanos_processed']  = target\n        return df\n    \n    def raw_prm(self, df):\n        print(\"raw_prm\")\n        param = 0.00000001\n        df['rawPrM_processed'] = df['rawPrM'] * param \n        return df.drop(['rawPrM'], axis=1) \n    \n    def raw_prm2(self, df):\n        print(\"raw_prm_2\")\n        df = self.raw_prm(df)\n        target = df['rawPrM_processed']\n        \n        target[target > 0.3] = 0.3\n        target = (target - np.min(target))\n        target = target \/ np.max(target)\n        target = (target - 0.5) * 2\n        \n        df['rawPrM_processed'] = target\n        return df\n      \n    def signal_type(self, df):\n        print(\"signal_type\")\n        ret = []\n        signal_list = [\"GPS_L1\", \"GPS_L5\", \"GAL_E1\", \"GAL_E5A\", \"GLO_G1\", \"BDS_B1I\", \"BDS_B1C\", \"BDS_B2A\", \"QZS_J1\", \"QZS_J5\"]\n        for data in tqdm(df['signalType']):\n            \n            if \"GPS_L1\":\n                if data in signal_list:\n                    ret.append(signal_list.index(data)+1)\n            else:\n                ret.append(0)\n            \n        df['signalType_processed'] = ret\n        return df.drop(['signalType'], axis=1)\n    \n    def signal_type2(self, df):\n        # 0~1\u306b\u3059\u308b\n        print(\"signal_type2\")\n        df = self.signal_type(df)\n        df['signalType_processed'] = df['signalType_processed'] * 0.1\n        return df\n\n    \n    def sat_pos(self, df):\n        print(\"sat_pos\")\n        param = 10e-7\n        df['xSatPosM_processed']  =  df['xSatPosM'] * param\n        df['ySatPosM_processed']  =  df['ySatPosM'] * param\n        df['zSatPosM_processed']  =  df['zSatPosM'] * param\n        return df.drop(['xSatPosM', 'ySatPosM', 'zSatPosM'], axis=1)\n    \n    def sat_pos2(self, df):\n        print(\"sat_pos2\")\n        #df = self.sat_pos(df)\n        def func(target):\n            target = (target - np.min(target))\n            target = target \/ np.max(target)\n            target = (target - 0.5) * 2\n            return target\n        \n        df['xSatPosM_processed'] = func(df['xSatPosM'])\n        df['ySatPosM_processed'] = func(df['ySatPosM'])\n        df['zSatPosM_processed'] = func(df['zSatPosM'])\n        return df.drop(['xSatPosM', 'ySatPosM', 'zSatPosM'], axis=1)\n\n    def sat_vel(self, df):\n        print(\"sat_pos\")\n        param = 10e-4\n        df['xSatVelMps_processed']  =  df['xSatVelMps'] * param\n        df['ySatVelMps_processed']  =  df['ySatVelMps'] * param\n        df['zSatVelMps_processed']  =  df['zSatVelMps'] * param\n        return df.drop(['xSatVelMps', 'ySatVelMps', 'zSatVelMps'], axis=1)\n    \n    def sat_vel2(self, df):\n        print(\"sat_vel2\")\n        def func(target):\n            target = (target - np.min(target))\n            target = target \/ np.max(target)\n            target = (target - 0.5) * 2\n            return target\n        \n        df['xSatVelMps_processed'] = func(df['xSatVelMps'])\n        df['ySatVelMps_processed'] = func(df['ySatVelMps'])\n        df['zSatVelMps_processed'] = func(df['zSatVelMps'])\n        return df.drop(['xSatVelMps', 'ySatVelMps', 'zSatVelMps'], axis=1)    \n\n    def sat_clk_bias_m(self, df):\n        print(\"sat_clk_bias_m\")\n        param = 10e-6\n        df['satClkBiasM_processed'] = df['satClkBiasM'] * param \n        return df.drop(['satClkBiasM'], axis=1)\n    \n    def sat_clk_bias_m2(self, df):\n        print(\"sat_clk_bias_m2\")\n        df = self.sat_clk_bias_m(df)\n        target = df['satClkBiasM_processed']\n        \n        target[target > 5] = 5\n        target[target < -5] = -5\n\n        target = (target - np.min(target))\n        target = target \/ np.max(target)\n        target = (target - 0.5) * 2\n        \n        df['satClkBiasM_processed'] = target\n        return df\n    \n    def sat_clk_drift_mps(self, df):\n        print(\"sat_clk_drift_mps\")\n        param = 1.0\n        df['satClkDriftMps_processed'] = df['satClkDriftMps'] * param \n        return df.drop(['satClkDriftMps'], axis=1)\n    \n    def sat_clk_drift_mps2(self, df):\n        print(\"sat_clk_drift_mps2\")\n        df = self.sat_clk_drift_mps(df)\n        target = df['satClkDriftMps_processed']\n        \n        target[target > 0.015] = 0.015\n        target[target < -0.015] = -0.015\n\n        target = (target - np.min(target))\n        target = target \/ np.max(target)\n        target = (target - 0.5) * 2\n        \n        df['satClkDriftMps_processed'] = target\n        return df\n\n    \n    def raw_pr_unc_m(self, df):\n        print(\"raw_pr_unc_m\")\n        param = 1.0\n        df['rawPrUncM_processed'] = df['rawPrUncM'] * param \n        return df.drop(['rawPrUncM'], axis=1)\n\n    def raw_pr_unc_m2(self, df):\n        print(\"raw_pr_unc_m2\")\n        df = self.raw_pr_unc_m(df)\n        target = df['rawPrUncM_processed']\n        \n        target[target > 26] = 25\n        target[target < 0] = 0\n\n        target = (target - np.min(target))\n        target = target \/ np.max(target)\n        target = (target - 0.5) * 2\n        \n        df['rawPrUncM_processed'] = target\n        return df\n    \n    def isrb_m(self, df):\n        print(\"isrb_m\")\n        param = 1.0\n        df['isrbM_processed'] = df['isrbM'] * param \n        return df.drop(['isrbM'], axis=1)\n    \n    def isrb_m2(self, df):\n        print(\"isrb_m2: don't use this value\")\n        return df.drop(['isrbM'], axis=1)\n    \n    def iono_delay_m(self, df):\n        print(\"iono_delay_m\")\n        param = 1.0\n        df['ionoDelayM_processed'] = df['ionoDelayM'] * param \n        return df.drop(['ionoDelayM'], axis=1)\n    \n    def iono_delay_m2(self, df):\n        print(\"iono_delay_m2\")\n        df = self.iono_delay_m(df)\n        target = df['ionoDelayM_processed']\n        \n        target[target > 21] = 21\n        target[target < 2] = 2\n\n        target = (target - np.min(target))\n        target = target \/ np.max(target)\n        target = (target - 0.5) * 2\n        \n        df['ionoDelayM_processed'] = target\n        return df\n\n    def tropo_delay_m(self, df):\n        print(\"tropo_delay_m\")\n        param = 1.0\n        df['tropoDelayM_processed'] = df['tropoDelayM'] * param \n        return df.drop(['tropoDelayM'], axis=1)\n    \n    def tropo_delay_m2(self, df):\n        print(\"tropo_delay_m2\")\n        df = self.tropo_delay_m(df)\n        target = df['tropoDelayM_processed']\n        \n        target[target > 30] = 30\n        target[target < 2] = 2\n\n        target = (target - np.min(target))\n        target = target \/ np.max(target)\n        target = (target - 0.5) * 2\n        \n        df['tropoDelayM_processed'] = target\n        return df\n    \n    def constellation_type(self, df):\n        print(\"constellation_type\")\n        return df\n        \n    def constellation_type2(self, df):\n        print(\"constellation_type2\")\n        df['constellationType_processed'] = df['constellationType'] \/ max(df['constellationType'])\n        return df.drop(['constellationType'], axis=1)\n    \n    def svid(self, df):\n        print(\"svid\")\n        return df\n    \n    def svid2(self, df):\n        print(\"svid2\")\n        df['svid_processed'] = df['svid'] \/ max(df['svid'])\n        return df.drop(['svid'], axis=1)\n","9db9687d":"feature_engineering = FeatureEngineering()","8a5e55b4":"data = feature_engineering.received_sv_time_nanos(feature_engineering.raw_data)[\"receivedSvTimeInGpsNanos_processed\"]\n\nplt.hist(data)","6f097470":"target = data[(1.05 < data) & (data < 1.1)]\nplt.hist(target, 50)\nprint(len(data))\nprint(len(target))\nprint(len(target)\/len(data))","f1f3cd93":"plt.hist((target-1.075)\/0.025, 50)","a5100a3b":"p_data = data\np_data = (p_data-1.075)\/0.025\np_data[-1 > p_data] = -1\np_data[1 < p_data] = 1\n\nplt.hist(p_data, 50)","43c94d10":"data = feature_engineering.received_sv_time_nanos2(feature_engineering.raw_data)[\"receivedSvTimeInGpsNanos_processed\"]\nplt.hist(data, 50)\ndel data, p_data, target # to reduce using RAM\ngc.collect()","aab46c1b":"feature_engineering.signal_type(feature_engineering.raw_data)","d3102bc5":"signal_type_data = feature_engineering.signal_type(feature_engineering.raw_data)[\"signalType_processed\"].value_counts()\nprint(signal_type_data)","8a79f478":"signal_type_data = feature_engineering.signal_type2(feature_engineering.raw_data)[\"signalType_processed\"].value_counts()\nprint(signal_type_data)\n\ndel signal_type_data # to reduce using RAM\ngc.collect()","e1b58af9":"rawPrM_processed = feature_engineering.raw_prm(feature_engineering.raw_data)[\"rawPrM_processed\"]\nplt.hist(rawPrM_processed, 50)\nprint(len(rawPrM_processed))\nprint(len(rawPrM_processed[rawPrM_processed<0.3]))\nprint(len(rawPrM_processed[rawPrM_processed<0.3])\/len(rawPrM_processed))","ca5617aa":"target = rawPrM_processed\ntarget[target > 0.3] = 0.3\nplt.hist(target, 100)","94addecb":"target2 = (target - np.min(target))\ntarget2 = target2 \/ np.max(target2)\ntarget2 = (target2 - 0.5) * 2\nplt.hist(target2, 100)","19497d26":"rawPrM_processed = feature_engineering.raw_prm2(feature_engineering.raw_data)[\"rawPrM_processed\"]\nplt.hist(rawPrM_processed, 50)\n\ndel rawPrM_processed, target2, target\ngc.collect()","adbf1f27":"position_processed = feature_engineering.sat_pos(feature_engineering.raw_data)\n\nx_position = position_processed[\"xSatPosM_processed\"]\ny_position = position_processed[\"ySatPosM_processed\"]\nz_position = position_processed[\"zSatPosM_processed\"]\n\nplt.figure(figsize=(34, 7), dpi=50)\nplt.subplot(1,3,1)\nplt.hist(x_position, 50) \nplt.subplot(1,3,2)\nplt.hist(y_position, 50)\nplt.subplot(1,3,3)\nplt.hist(z_position, 50)\nplt.show()","a87702bb":"position_processed = feature_engineering.sat_pos2(feature_engineering.raw_data)\n\nx_position = position_processed[\"xSatPosM_processed\"]\ny_position = position_processed[\"ySatPosM_processed\"]\nz_position = position_processed[\"zSatPosM_processed\"]\n\nplt.figure(figsize=(34, 7), dpi=50)\nplt.subplot(1,3,1)\nplt.hist(x_position, 50) \nplt.subplot(1,3,2)\nplt.hist(y_position, 50)\nplt.subplot(1,3,3)\nplt.hist(z_position, 50)\nplt.show()\n\ndel position_processed, x_position, y_position, z_position\ngc.collect()","73578bab":"vel_processed = feature_engineering.sat_vel(feature_engineering.raw_data)\n\nx_vel = vel_processed[\"xSatVelMps_processed\"]\ny_vel = vel_processed[\"ySatVelMps_processed\"]\nz_vel = vel_processed[\"zSatVelMps_processed\"]\n\nplt.figure(figsize=(34, 7), dpi=50)\nplt.subplot(1,3,1)\nplt.hist(x_vel, 50) \nplt.subplot(1,3,2)\nplt.hist(y_vel, 50)\nplt.subplot(1,3,3)\nplt.hist(z_vel, 50)\nplt.show()","6ce10a9f":"vel_processed = feature_engineering.sat_vel2(feature_engineering.raw_data)\n\nx_vel = vel_processed[\"xSatVelMps_processed\"]\ny_vel = vel_processed[\"ySatVelMps_processed\"]\nz_vel = vel_processed[\"zSatVelMps_processed\"]\n\nplt.figure(figsize=(34, 7), dpi=50)\nplt.subplot(1,3,1)\nplt.hist(x_vel, 50) \nplt.subplot(1,3,2)\nplt.hist(y_vel, 50)\nplt.subplot(1,3,3)\nplt.hist(z_vel, 50)\nplt.show()\n\ndel vel_processed, x_vel, y_vel, z_vel\ngc.collect()","7cf6012d":"sat_clk_bias_m = feature_engineering.sat_clk_bias_m(feature_engineering.raw_data)['satClkBiasM_processed']\nsat_clk_drift_mps = feature_engineering.sat_clk_drift_mps(feature_engineering.raw_data)['satClkDriftMps_processed']\nraw_pr_unc_m = feature_engineering.raw_pr_unc_m(feature_engineering.raw_data)['rawPrUncM_processed']\nisrb_m = feature_engineering.isrb_m(feature_engineering.raw_data)['isrbM_processed']\niono_delay_m = feature_engineering.iono_delay_m(feature_engineering.raw_data)['ionoDelayM_processed']\ntropo_delay_m = feature_engineering.tropo_delay_m(feature_engineering.raw_data)['tropoDelayM_processed']\n\nplt.figure(figsize=(34, 14), dpi=50)\nplt.subplot(2,3,1)\nplt.title(\"sat_clk_bias_m\")\nplt.hist(sat_clk_bias_m, 50) \n\nplt.subplot(2,3,2)\nplt.title(\"sat_clk_drift_mps\")\nplt.hist(sat_clk_drift_mps, 50)\n\nplt.subplot(2,3,3)\nplt.title(\"raw_pr_unc_m\")\nplt.hist(raw_pr_unc_m, 50)\n\nplt.subplot(2,3,4)\nplt.title(\"isrb_m\")\nplt.hist(isrb_m, 50)\n\nplt.subplot(2,3,5)\nplt.title(\"iono_delay_m\")\nplt.hist(iono_delay_m, 50)\n\nplt.subplot(2,3,6)\nplt.title(\"tropo_delay_m\")\nplt.hist(tropo_delay_m, 50)\nplt.show()\n","e4119a9c":"plt.figure(figsize=(34, 14), dpi=50)\nplt.subplot(2,3,1)\nplt.title(\"sat_clk_bias_m(-5, 5)\")\nplt.hist(sat_clk_bias_m[(-5 < sat_clk_bias_m)&(sat_clk_bias_m<5)], 50) \nprint(\"sat_clk_bias_m\u306e-5 ~ 5\u306b\u542b\u307e\u308c\u308b\u5272\u5408\")\nprint(len(sat_clk_bias_m[(-5 < sat_clk_bias_m)&(sat_clk_bias_m<5)])\/len(sat_clk_bias_m))\n\nplt.subplot(2,3,2)\nplt.title(\"sat_clk_drift_mps(-0.015, 0.015)\")\nplt.hist(sat_clk_drift_mps[(-0.015 < sat_clk_drift_mps)&(sat_clk_drift_mps<0.015)], 50)\nprint(\"sat_clk_drift_mps -0.015 ~ 0.015\u306b\u542b\u307e\u308c\u308b\u5272\u5408\")\nprint(len(sat_clk_drift_mps[(-0.015 < sat_clk_drift_mps)&(sat_clk_drift_mps<0.015)])\/len(sat_clk_drift_mps))\n\nplt.subplot(2,3,3)\nplt.title(\"raw_pr_unc_m(0,25)\")\nplt.hist(raw_pr_unc_m[(0 < raw_pr_unc_m)&(raw_pr_unc_m<25)], 50)\nprint(\"raw_pr_unc_m 0 ~ 25\u306b\u542b\u307e\u308c\u308b\u5272\u5408\")\nprint(len(raw_pr_unc_m[(0 < raw_pr_unc_m)&(raw_pr_unc_m<25)])\/len(raw_pr_unc_m))\n\nplt.subplot(2,3,4)\nplt.title(\"isrb_m\")\nplt.hist(isrb_m[(-0.001 < isrb_m)&(isrb_m<0.001)], 50)\nprint(\"isrb_m: \u50be\u5411\u304c\u898b\u3048\u306a\u3044\u306e\u3067\u3001\u5f8c\u3067\u5225\u51e6\u7406\")\n\nplt.subplot(2,3,5)\nplt.title(\"iono_delay_m\")\nplt.hist(iono_delay_m[(2 < iono_delay_m)&(iono_delay_m<21)], 100)\nprint(\"iono_delay_m 2 ~ 21\u306b\u542b\u307e\u308c\u308b\u5272\u5408\")\nprint(len(iono_delay_m[(1 < iono_delay_m)&(iono_delay_m<21)])\/len(iono_delay_m))\n\nplt.subplot(2,3,6)\nplt.title(\"tropo_delay_m\")\nplt.hist(tropo_delay_m[(2 < tropo_delay_m)&(tropo_delay_m<30)], 100)\nprint(\"tropo_delay_m 2 ~ 30\u306b\u542b\u307e\u308c\u308b\u5272\u5408\")\nprint(len(tropo_delay_m[(2 < tropo_delay_m)&(tropo_delay_m<30)])\/len(tropo_delay_m))\nplt.show()","dd486b76":"isrb_m.value_counts()","b4bc6061":"sat_clk_bias_m = feature_engineering.sat_clk_bias_m2(feature_engineering.raw_data)['satClkBiasM_processed']\nsat_clk_drift_mps = feature_engineering.sat_clk_drift_mps2(feature_engineering.raw_data)['satClkDriftMps_processed']\nraw_pr_unc_m = feature_engineering.raw_pr_unc_m2(feature_engineering.raw_data)['rawPrUncM_processed']\n#isrb_m = feature_engineering.isrb_m2(feature_engineering.raw_data)['isrbM_processed']\niono_delay_m = feature_engineering.iono_delay_m2(feature_engineering.raw_data)['ionoDelayM_processed']\ntropo_delay_m = feature_engineering.tropo_delay_m2(feature_engineering.raw_data)['tropoDelayM_processed']\n\nplt.figure(figsize=(34, 14), dpi=50)\nplt.subplot(2,3,1)\nplt.title(\"sat_clk_bias_m\")\nplt.hist(sat_clk_bias_m, 50) \n\nplt.subplot(2,3,2)\nplt.title(\"sat_clk_drift_mps\")\nplt.hist(sat_clk_drift_mps, 50)\n\nplt.subplot(2,3,3)\nplt.title(\"raw_pr_unc_m\")\nplt.hist(raw_pr_unc_m, 50)\n\n#plt.subplot(2,3,4)\n#plt.title(\"isrb_m\")\n#plt.hist(isrb_m, 50)\n\nplt.subplot(2,3,5)\nplt.title(\"iono_delay_m\")\nplt.hist(iono_delay_m, 50)\n\nplt.subplot(2,3,6)\nplt.title(\"tropo_delay_m\")\nplt.hist(tropo_delay_m, 50)\nplt.show()","97564c41":"del sat_clk_bias_m, sat_clk_drift_mps, raw_pr_unc_m, isrb_m, iono_delay_m, tropo_delay_m\ngc.collect()","12ffe8c7":"constellationType = feature_engineering.constellation_type2(feature_engineering.raw_data)['constellationType_processed']\nsvid = feature_engineering.svid2(feature_engineering.raw_data)['svid_processed']\n\nprint(constellationType.value_counts())\nprint(svid.value_counts())\n\ndel constellationType, svid\ngc.collect()","e98b30c5":"feature_engineering.test_all()\ndisplay(feature_engineering.df)","8d7ec968":"del feature_engineering\ngc.collect()","54ea31d0":"# check memory: https:\/\/qiita.com\/AnchorBlues\/items\/883790e43417640140aa\nimport sys\n\nprint(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\nprint(\" ------------------------------------ \")\nfor var_name in dir():\n    if not var_name.startswith(\"_\"):\n        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))","9458ec9d":"import pandas as pd\nimport copy\nimport numpy as np\nimport pathlib\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nfrom multiprocessing import Pool\nimport multiprocessing as multi\n\n\nINPUT = '..\/input\/google-smartphone-decimeter-challenge'\np = pathlib.Path(INPUT)","f9c90243":"def file_load_multi_pricessing(filename):\n    df = pd.read_csv(filename)\n    return df","bf733995":"class DataLoader:\n    def __init__(self):\n        self.train_files = list(p.glob('train\/*\/*\/*_derived.csv'))\n        self.test_files = list(p.glob('test\/*\/*\/*_derived.csv'))\n    \n        self.feature_engineering = FeatureEngineering(debug_flag=False)\n        \n        raw_data = self.load_raw_data() \n        \n        raw_data = self.feature_engineering.data_process(raw_data)\n        \n        # train\/test split\n        train_data = raw_data[raw_data[\"train_flag\"]==1]\n        test_data = raw_data[raw_data[\"train_flag\"]==0]\n        \n        del raw_data\n        gc.collect()\n        \n        # add ground truth to train data\n        gt_files = list(p.glob('train\/*\/*\/ground_truth.csv'))\n        data=[]\n        for filename in tqdm(gt_files, desc=\"Loading ground truth\"):\n            df = pd.read_csv(filename)\n            data.append(df)\n        train_gt = pd.concat(data, ignore_index=True)\n\n        train_gt[\"receivedSvTimeInGpsNanos\"] = train_gt.millisSinceGpsEpoch*int(1e6)\n        train_data = train_data.drop(\"millisSinceGpsEpoch\", axis=1)\n        \n        train_gt_data = pd.merge_asof(train_data.sort_values('receivedSvTimeInGpsNanos'), train_gt.sort_values('receivedSvTimeInGpsNanos'), \n                                                   on=\"receivedSvTimeInGpsNanos\", by=[\"collectionName\", \"phoneName\"], direction='nearest',tolerance=int(1e9))\n        self.train_gt_data = train_gt_data.sort_values(by=[\"collectionName\", \"phoneName\", \"millisSinceGpsEpoch\"], ignore_index=True)\n        \n        # add baseline value\n        # merge with baseline data\n        baseline_train = pd.read_csv(\"..\/input\/google-smartphone-decimeter-challenge\/baseline_locations_train.csv\")\n        baseline_test = pd.read_csv(\"..\/input\/google-smartphone-decimeter-challenge\/baseline_locations_test.csv\")\n\n\n        self.train_gt_data = pd.merge_asof(self.train_gt_data.sort_values('millisSinceGpsEpoch'), baseline_train.sort_values('millisSinceGpsEpoch'), \n                                                           on=\"millisSinceGpsEpoch\", suffixes=(\"_gt\", \"_base\"),  by=[\"collectionName\", \"phoneName\"], direction='nearest',tolerance=int(1e9))\n        self.test_data = pd.merge_asof(test_data.sort_values('millisSinceGpsEpoch'), baseline_test.sort_values('millisSinceGpsEpoch'), \n                                                           on=\"millisSinceGpsEpoch\", suffixes=(\"_gt\", \"_base\"),  by=[\"collectionName\", \"phoneName\"], direction='nearest',tolerance=int(1e9))\n\n        self.train_gt_data = self.gt_ajust(self.train_gt_data)\n        #self.train_gt_data, self.test_data, self.lat_bias, self.lng_bias = self.lat_lng_ajust(self.train_gt_data, self.test_data)\n\n    def load_raw_data(self):\n        # load all data, return merged train\/test data\n        result_train = []\n        thread_num = multi.cpu_count()\n        with Pool(thread_num) as pool:\n            imap = pool.imap(file_load_multi_pricessing, self.train_files)\n            result_train = list(tqdm(imap, total=len(self.train_files), desc=\"load train data\"))\n        train_data_ = pd.concat(result_train, ignore_index=True)\n        train_data = pd.DataFrame([{\"train_flag\":1}]*len(train_data_)).join([train_data_])\n\n        result_test = []\n        with Pool(4) as pool:\n            imap = pool.imap(file_load_multi_pricessing, self.test_files)\n            result_test = list(tqdm(imap, total=len(self.test_files), desc=\"load test data\"))\n        test_data = pd.concat(result_test, ignore_index=True)\n        test_data = pd.DataFrame([{\"train_flag\":0}]*len(test_data)).join([test_data])\n        \n        return pd.concat([train_data, test_data])\n        \n    def load_one_data(self, df):\n        ret_data = []\n        unique_time = sorted(df[\"millisSinceGpsEpoch\"].unique())\n        for target_time in unique_time:\n            tmp_df = df[df[\"millisSinceGpsEpoch\"]==target_time]\n            ret_data.append(copy.deepcopy(tmp_df))\n            break # debug\n        return ret_data\n    \n    def lat_lng_ajust(self, df_train, df_test):\n        lat_bias = df_train['latDeg_gt'].mean()\n        lng_bias = df_train['lngDeg_gt'].mean()\n        \n        df_train['latDeg_gt'] = df_train['latDeg_gt'] - lat_bias\n        df_train['lngDeg_gt'] = df_train['lngDeg_gt'] - lng_bias\n        df_train['latDeg_base'] = df_train['latDeg_base'] - lat_bias\n        df_train['lngDeg_base'] = df_train['lngDeg_base'] - lng_bias\n\n        # same transformation with train\n        df_test['latDeg'] = df_test['latDeg'] - lat_bias\n        df_test['lngDeg'] = df_test['lngDeg'] - lng_bias\n        return df_train, df_test, lat_bias, lng_bias\n    \n    def gt_ajust(self, df_train):\n        df_train['latDeg_gt2'] = df_train['latDeg_gt'] - df_train['latDeg_base']\n        df_train['lngDeg_gt2'] = df_train['lngDeg_gt'] - df_train['lngDeg_base']\n        return df_train","3cd58165":"gc.collect()","99e9991a":"data_loader = DataLoader()","270e87a0":"df = data_loader.train_gt_data[['latDeg_gt', 'lngDeg_gt', 'latDeg_base', 'lngDeg_base']]\nprint(df.max())\nprint(df.min())","b0fb941b":"df = data_loader.test_data[['latDeg', 'lngDeg']]\nprint(df.max())\nprint(df.min())","bf57ba66":"data_loader.train_gt_data","4353be97":"data_loader.test_data","91ca75b6":"data_loader.train_gt_data.columns","0bdb5d13":"del data_loader\ngc.collect()","55d747e3":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\n\nimport os\nfrom contextlib import redirect_stdout\n\n# \u8a55\u4fa1\u6307\u6a19\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import log_loss\n\n# keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.layers.core import Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Model\nfrom keras.layers import Input, Dense\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.callbacks import ModelCheckpoint","c11e2529":"'''\nall_feature_train = ['train_flag', 'collectionName', 'phoneName', 'receivedSvTimeInGpsNanos',\n                   'receivedSvTimeInGpsNanos_processed', 'rawPrM_processed',\n                   'signalType_processed', 'xSatPosM_processed', 'ySatPosM_processed',\n                   'zSatPosM_processed', 'xSatVelMps_processed', 'ySatVelMps_processed',\n                   'zSatVelMps_processed', 'satClkBiasM_processed',\n                   'satClkDriftMps_processed', 'rawPrUncM_processed',\n                   'ionoDelayM_processed', 'tropoDelayM_processed',\n                   'constellationType_processed', 'svid_processed', 'millisSinceGpsEpoch',\n                   'latDeg_gt', 'lngDeg_gt', 'heightAboveWgs84EllipsoidM_gt',\n                   'timeSinceFirstFixSeconds', 'hDop', 'vDop', 'speedMps', 'courseDegree',\n                   'latDeg_base', 'lngDeg_base', 'heightAboveWgs84EllipsoidM_base',\n                   'phone']\n'''\n\nuse_feature_train = ['receivedSvTimeInGpsNanos_processed', 'rawPrM_processed',\n           'signalType_processed', 'xSatPosM_processed', 'ySatPosM_processed',\n           'zSatPosM_processed', 'xSatVelMps_processed', 'ySatVelMps_processed',\n           'zSatVelMps_processed', 'satClkBiasM_processed',\n           'satClkDriftMps_processed', 'rawPrUncM_processed',\n           'ionoDelayM_processed', 'tropoDelayM_processed',\n           'constellationType_processed', 'svid_processed',\n           'latDeg_base', 'lngDeg_base']\n\nuse_feature_test = ['receivedSvTimeInGpsNanos_processed', 'rawPrM_processed',\n   'signalType_processed', 'xSatPosM_processed', 'ySatPosM_processed',\n   'zSatPosM_processed', 'xSatVelMps_processed', 'ySatVelMps_processed',\n   'zSatVelMps_processed', 'satClkBiasM_processed',\n   'satClkDriftMps_processed', 'rawPrUncM_processed',\n   'ionoDelayM_processed', 'tropoDelayM_processed',\n   'constellationType_processed', 'svid_processed',\n   'latDeg', 'lngDeg']\n\nnn_data_param_length = len(use_feature_train)\n\n\nassert_error_str = \"must be same length with use_feature_train=\"+str(len(use_feature_train))+\" and use_feature_test=\"+str(len(use_feature_test))\nassert nn_data_param_length == len(use_feature_test), assert_error_str\n                                                                                                                          ","63de2fd1":"class NeuralNet:\n    def __init__(self, data_loader):\n        \n        print(\"split to x\/y\")\n        self.train_data_x = data_loader.train_gt_data[use_feature_train]\n        self.train_data_y = data_loader.train_gt_data[['latDeg_gt2', 'lngDeg_gt2']]\n        \n        self.test_data_x = data_loader.test_data[use_feature_test]\n        \n        self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(self.train_data_x, self.train_data_y, test_size=0.1, random_state=40, shuffle=False)        \n\n\n        \n    \n    ###########################################################################################################\n    #\n    #    model \n    #\n    #########################################################################################################    \n    \n    \n    def create_model_simple(self):\n        activation_fun = \"swish\"\n        \n        inputs = keras.Input(shape=(nn_data_param_length,))\n        x = inputs\n                \n        x = layers.Dense(512, activation=activation_fun, kernel_initializer='he_normal')(x)\n        x = BatchNormalization()(x)\n\n        x = layers.Dense(512, activation=activation_fun, kernel_initializer='he_normal')(x)\n        x = BatchNormalization()(x)\n        \n        x = layers.Dense(512, activation=activation_fun, kernel_initializer='he_normal')(x)\n        x = BatchNormalization()(x)\n        \n        x = layers.Dense(512, activation=activation_fun, kernel_initializer='he_normal')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        \n        outputs = layers.Dense(2, activation=\"linear\")(x)\n        return keras.Model(inputs, outputs)\n    \n    def create_model_self_attention(self):\n        activation_fun = \"swish\"\n        \n        inputs = keras.Input(shape=(nn_data_param_length,))\n        x = inputs\n        \n        query_encoding = x\n        query_value_attention = tf.keras.layers.Attention()([x, x])\n        x = tf.keras.layers.Concatenate()([query_encoding, query_value_attention])\n        x = layers.Dense(256, activation=activation_fun, kernel_initializer='he_normal')(x)\n        x = BatchNormalization()(x)\n        \n        x = layers.Dense(512, activation=activation_fun, kernel_initializer='he_normal')(x)\n        x = BatchNormalization()(x)\n        \n        x_ = x\n        \n        x = layers.Dense(512, activation=activation_fun, kernel_initializer='he_normal')(x)\n        x = BatchNormalization()(x)\n        \n        query_encoding = x\n        query_value_attention = tf.keras.layers.Attention()([x, x])\n        x = tf.keras.layers.Concatenate()([query_encoding, query_value_attention])\n        x = layers.Dense(512, activation=activation_fun, kernel_initializer='he_normal')(x)\n        x = BatchNormalization()(x)\n        \n        x = layers.Dense(512, activation=activation_fun, kernel_initializer='he_normal')(x)\n        x = BatchNormalization()(x)\n        \n        x = keras.layers.Concatenate()([x, x_])\n        x = layers.Dense(512, activation=activation_fun, kernel_initializer='he_normal')(x)\n        x = BatchNormalization()(x)\n        \n        x = layers.Dense(512, activation=activation_fun, kernel_initializer='he_normal')(x)\n        x = BatchNormalization()(x)\n        \n        x = layers.Dense(256, activation=activation_fun, kernel_initializer='he_normal')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        \n        outputs = layers.Dense(2, activation=\"linear\")(x)\n        return keras.Model(inputs, outputs)\n    \n    ###########################################################################################################\n    #\n    #    training & test\n    #\n    #########################################################################################################   \n    \n    def calculate_loss(self, ground_truth, pred):\n        loss = pd.DataFrame({'LogLoss': log_loss(ground_truth, pred)},\n                               index = ['scores'])\n        return loss\n    \n    def calculate_scores(self, ground_truth, pred):\n        scores = pd.DataFrame({'Accuracy': accuracy_score(ground_truth, pred),\n                              'F1': f1_score(ground_truth, pred),\n                              'Precision': precision_score(ground_truth, pred),\n                              'Recall': recall_score(ground_truth, pred)},\n                               index = ['scores'])\n        return scores\n    \n    def haversine_my_metrics(self, y_true, y_pred):\n        \n        lat1, lon1, lat2, lon2 = y_true[0], y_true[1], y_pred[0], y_pred[1]\n\n        RADIUS = 6_367_000 # \u8d64\u9053\u534a\u5f84\uff1a6_378_100[m], \u6975\u534a\u5f84\uff1a 6_356_775[m], avg. = 6_367_437.5[m]\n        def deg2rad(deg):\n            pi_on_180 = 0.017453292519943295\n            return deg * pi_on_180\n        lat1, lon1, lat2, lon2 = map(deg2rad, [lat1, lon1, lat2, lon2])\n        dlat = lat2 - lat1\n        dlon = lon2 - lon1\n        a = tf.sin(dlat\/2)**2 + \\\n            tf.cos(lat1) * tf.cos(lat2) * tf.sin(dlon\/2)**2\n        dist = 2 * RADIUS * tf.asin(a**0.5)\n        return dist\n        \n    def test(self):\n        self.model_compile()\n        self.model.load_weights('.\/best_weights.hdf5')\n        self.result = self.model.predict(self.test_data_x, batch_size=2048)\n        \n        result = pd.DataFrame(self.result, columns=[\"latDeg\", \"lngDeg\"])\n        result[\"latDeg\"] = result[\"latDeg\"] + self.test_data_x[\"latDeg\"]\n        result[\"lngDeg\"] = result[\"lngDeg\"] + self.test_data_x[\"lngDeg\"]\n\n        tmp = data_loader.test_data[['phone', 'millisSinceGpsEpoch']]\n        test_result = tmp.join(result)        \n        test_result = test_result.groupby([\"phone\", \"millisSinceGpsEpoch\"]).mean().reset_index()\n\n        sample_df = pd.read_csv(\"..\/input\/google-smartphone-decimeter-challenge\/sample_submission.csv\")\n        sample_df = sample_df.drop([\"latDeg\", \"lngDeg\"], axis=1)\n        self.submission = pd.merge_asof(sample_df.sort_values('millisSinceGpsEpoch'), \n                                    test_result.sort_values('millisSinceGpsEpoch'), \n                                    on=\"millisSinceGpsEpoch\", by=[\"phone\"], direction='nearest', tolerance=100000)\n        \n        self.submission = sample_df.merge(self.submission) # sort to the submission order\n        self.submission.to_csv(\"my_submission.csv\", index=False)\n        display(self.submission)\n        \n    def model_compile(self):\n        #self.model = self.create_model_self_attention()\n        self.model = self.create_model_simple()\n        lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n            initial_learning_rate=1e-2,\n            decay_steps=10000,\n            decay_rate=0.9)\n        self.optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n        self.model.compile(loss='huber', optimizer=self.optimizer, metrics=[\"mae\", self.haversine_my_metrics])\n        \n    def train(self, print_result_flag=False):\n        self.model_compile()\n        cp = ModelCheckpoint(\"best_weights.hdf5\", monitor=\"val_mae\", verbose=1,\n             save_best_only=True, save_weights_only=True, mode=\"min\")\n        self.model.fit(self.x_train, self.y_train, epochs=10, batch_size=2048, verbose=2, callbacks=[cp], validation_data=(self.x_val, self.y_val))\n\n    def evaluate_train(self):\n        self.model_compile()\n        self.model.load_weights('.\/best_weights.hdf5')\n        \n        train_score = self.model.evaluate(self.x_train, self.y_train, batch_size=2048)\n        val_score = self.model.evaluate(self.x_val, self.y_val, batch_size=2048)\n        \n        print(f\"train_score: {train_score}, val_score: {val_score}\")\n        \n    def evaluate_train2(self):\n        self.model_compile()\n        self.model.load_weights('.\/best_weights.hdf5')\n        result = self.model.predict(self.train_data_x, batch_size=2048)\n        \n        self.train_result = pd.DataFrame(result, columns=['latDeg', 'lngDeg'])\n        \n        self.train_result = self.train_result.rename(columns={\"latDeg\": \"latDeg_original\", \"lngDeg\": \"lngDeg_original\"})\n        self.train_result[\"latDeg\"] = self.train_result[\"latDeg_original\"] + self.train_data_x[\"latDeg_base\"]\n        self.train_result[\"lngDeg\"] = self.train_result[\"lngDeg_original\"] + self.train_data_x[\"lngDeg_base\"]\n        err_latDeg, err_lngDeg = ansolute_error(self.train_result, ground_truth)\n        print(err_latDeg.mean(), err_lngDeg.mean())        \n        \n        tmp = data_loader.train_gt_data[['collectionName', 'phoneName', 'millisSinceGpsEpoch']]\n        train_result = tmp.join(self.train_result)\n        print(get_train_score(train_result, ground_truth))","e175ba6f":"data_loader = DataLoader()","ccd40b0a":"gc.collect()\nmy_nn = NeuralNet(data_loader)\ngc.collect()","f8b8e094":"my_nn.train()","fa9ef068":"my_nn.evaluate_train()","5fd97770":"my_nn.evaluate_train2()","031a0791":"def get_train_score(df, gt):\n    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n    # calc_distance_error\n    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n    # calc_evaluate_score\n    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n    res = df.groupby('phone')['err'].agg([percentile50, percentile95])\n    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) \/ 2 \n    score = res['p50_p90_mean'].mean()\n    return score","1b8bda34":"my_nn.test()","ca8d8418":"# Feature Enginerrling","cfcbca2c":"### receivedSvTimeInGpsNanos(and millisSinceGpsEpoch)\n\u30c1\u30c3\u30d7\u30bb\u30c3\u30c8\u304c\u53d7\u4fe1\u3057\u305f\u4fe1\u53f7\u306e\u9001\u4fe1\u6642\u9593\u3067\u3001GPS\u30a8\u30dd\u30c3\u30af\u4ee5\u964d\u306e\u30ca\u30ce\u79d2\u6570\u3067\u8868\u3057\u307e\u3059\u3002ReceivedSvTimeNanos\u304b\u3089\u5909\u63db\u3059\u308b\u3068\u3001\u3053\u306e\u6d3e\u751f\u5024\u306f\u3059\u3079\u3066\u306e\u661f\u5ea7\u3067\u7d71\u4e00\u3055\u308c\u305f\u6642\u9593\u30b9\u30b1\u30fc\u30eb\u306b\u306a\u308a\u307e\u3059\u304c\u3001ReceivedSvTimeNanos\u306fGLONASS\u3067\u306f\u4e00\u65e5\u306e\u6642\u9593\u3001GLONASS\u4ee5\u5916\u306e\u661f\u5ea7\u3067\u306f\u9031\u306e\u6642\u9593\u3092\u53c2\u7167\u3057\u307e\u3059\u3002\n\nThe signal transmission time received by the chipset, in the numbers of nanoseconds since the GPS epoch. Converted from ReceivedSvTimeNanos, this derived value is in a unified time scale for all constellations, while ReceivedSvTimeNanos refers to the time of day for GLONASS and the time of week for non-GLONASS constellations.\n\nmillisSinceGpsEpoch(GPS\u30a8\u30dd\u30c3\u30af(1980\/1\/6 midnight UTC)\u304b\u3089\u306e\u30df\u30ea\u79d2\u5358\u4f4d\u306e\u6574\u6570\u3002)\u3068\u306e\u5dee\u5206\u3092\u3068\u3063\u3066\u5024\u3092\u5c0f\u3055\u304f\u3059\u308b\u3002\u3069\u3061\u3089\u3082\u5927\u304d\u3044\u5024\u306a\u306e\u3067\u3001\u9069\u5f53\u306b\u5c0f\u3055\u304f\u3057\u305f\u304b\u3063\u305f\u3002\u3053\u306e\u5dee\u5206\u304c\u4f55\u3092\u610f\u5473\u3059\u308b\u306e\u304b\u306f\u3044\u307e\u3044\u3061\u308f\u304b\u3063\u3066\u306a\u3044\uff08millisSinceGpsEpoch\u304c\u4f55\u3092\u610f\u5473\u3057\u3066\u3044\u308b\u306e\u304b\u304c\u3044\u307e\u3044\u3061\u63b4\u3081\u3066\u3044\u306a\u3044\uff09\n\nreceived_sv_time_nanos_result = param1\\*receivedSvTimeInGpsNanos - param2\\*millisSinceGpsEpoch","06bc1ecc":"### rawPrM\n\u30e1\u30fc\u30c8\u30eb\u5358\u4f4d\u306e\u751f\u306e\u7591\u4f3c\u8ddd\u96e2\u3002\u3053\u308c\u306f\u3001\u5149\u901f\u3068\u3001\u4fe1\u53f7\u9001\u4fe1\u6642\u523b(receivedSvTimeInGpsNanos)\u304b\u3089\u4fe1\u53f7\u5230\u7740\u6642\u523b(Raw::TimeNanos - Raw::FullBiasNanos - Raw::BiasNanos)\u307e\u3067\u306e\u6642\u9593\u5dee\u306e\u7a4d\u3067\u3042\u308b\u3002\n\nRaw pseudorange in meters. It is the product between the speed of light and the time difference from the signal transmission time (receivedSvTimeInGpsNanos) to the signal arrival time (Raw::TimeNanos - Raw::FullBiasNanos - Raw::BiasNanos).\n\n**\u203b\u3053\u3053\u3067\u306f\u30d8\u30f3\u30c6\u30b3\u51e6\u7406\u3092\u3057\u305f\u5f8c\u306a\u306e\u3067\u5024\u306f\u5c0f\u3055\u304f\u306a\u3063\u3066\u3044\u308b\u304c\u3001\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u306e\u5f62\u72b6\u306f\u5909\u308f\u3089\u306a\u3044\u306f\u305a(This result is processed so the value is different from the original rawPrM but the shape of histgram is same.)**\n\n**cf.     def raw_prm(self, df):**","15a761b8":"0.3\u672a\u6e80\u306b97%\u306e\u30c7\u30fc\u30bf\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u306e\u3067\u30010.3\u4ee5\u4e0a\u306foutlier\u3068\u3057\u3066\u6271\u3046","61b707a6":"outlier\u3068\u504f\u308a\u304c\u305d\u308c\u305e\u308c\u3042\u308b\u306e\u3067\u3001\uff11\u3064\u3065\u3064\u8abf\u6574\u3059\u308b","189b64d6":"baseline absolute error: lat = 0.10239727214110347, lng = 0.1432227609733908\n\n5.287970649084159","7b805a92":"OK\n\n1\u304c\u591a\u304f\u306610\u304c\u5c11\u306a\u3044\n\n0~1\u306b\u3059\u308b **<span style=\"color: red; \">\u672c\u5f53\u306fone-hot vector\u306b\u3059\u3079\u304d\u3060\u3068\u601d\u3046<\/span>**","2b67ac8f":"### Others - satClkBiasM\tsatClkDriftMps\trawPrUncM\tisrbM\tionoDelayM\ttropoDelayM\t","2678ea7f":"# Neural Net","d3d2922b":"-> \u3053\u306e\u7d50\u679c\u304b\u3089received_sv_time_nanos2\u3092\u6c7a\u3081\u305f","ccb83b8b":"isrb_m\u306f\u307b\u3068\u3093\u30690\n\n\u30ce\u30a4\u30ba\u306b\u3057\u304b\u306a\u3089\u306a\u305d\u3046\u306a\u306e\u3067\u3001\u524a\u9664\uff1f","9a52a8e0":"\u5168\u30c7\u30fc\u30bf\u306e\u3046\u3061\u7d0495%\u304c1.05 ~ 1.10\u306b\u3042\u308b\u3002\n\n1.75\u304c\u4e2d\u592e\u306b\u306a\u308b\u3088\u3046\u306b\u5909\u66f4\u30011.05\u672a\u6e80\u30920\u30011.10\u4ee5\u4e0a\u30921\u306b\u3059\u308b","058be80f":"# Google Smartphone Decimeter Challenge_MyFirstTry by Neural Net\n* This is my first try using Neural Net(Keras)\n* Input of NN is (_derived.csv, baseline)\n* I couldn't still understand the data about _derived.csv(https:\/\/www.kaggle.com\/c\/google-smartphone-decimeter-challenge\/discussion\/246424)\n* Getting fucking score like 21263.733\n  * I found some wrong point about creating submission file. Time and estimated values were set to wrong correspondence. Thats why I got fuckin score like  21263.733. See the NeuralNet().test()\n  * Fixed this wrong point then I get the score 7.345, this is the start line I think.\n* I will try to improve the score based on this code\n  * Many people are using Kalman Filter as a Post processing.","a18cabc2":"-1~1\u306b\u6574\u5f62\u3059\u308b","695aee8c":"def \u00d7\u00d7\u00d7(self, df)\u3000\u306f\u601d\u3044\u4ed8\u304d\u306e\u7279\u5fb4\u91cf\u8a08\u7b97\uff08\u5927\u304d\u3059\u304e\u308b\u5024\u3092\u5c0f\u3055\u304f\u3059\u308b\u306a\u3069\uff09\n\ndef \u00d7\u00d7\u00d72(self, df)\u306f\ud83d\udc46\u306e\u7d50\u679c\u3092\u898b\u3066\u3001\u3061\u3083\u3093\u3068\u6574\u5f62\u3057\u305f\u3082\u306e\uff08\u5fd8\u308c\u306a\u3044\u3088\u3046\u306b\u3001\u4ee5\u4e0b\u306b\u305d\u306e\u904e\u7a0b\u3092\u793a\u3059\uff09","eccc5b85":"# Data Analysis with Feature Engineering for Neural Net","5823b282":"outlier\u306f\u306a\u3055\u305d\u3046\u306a\u306e\u3067\u3001\u3053\u306e\u307e\u307e1~-1\u306b\u6574\u5f62\u3059\u308b(sat_pos2\u3092\u53c2\u7167)","7edbfd84":"outlier\u306f\u306a\u3055\u305d\u3046\u306a\u306e\u3067\u3001\u3053\u306e\u307e\u307e1~-1\u306b\u6574\u5f62\u3059\u308b(sat vel2\u3092\u53c2\u7167)","4317af71":"baseline absolute error: lat = 0.10239727214110347, lng = 0.1432227609733908","56d2fadd":"## data loader","6727edf4":"\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u304c\u305a\u3044\u3076\u3093\u504f\u3063\u3066\u3044\u308b\u306e\u3067\u7bc4\u56f2\u30921.05~1.10\u306b\u72ed\u3081\u3066\u307f\u3066\u307f\u308b(\u3053\u306e\u7bc4\u56f2\u306f\u4f55\u56de\u304b\u8a66\u3057\u3066\u6c7a\u3081\u305f)","a5132ead":"\u3053\u308c\u3092raw_prm2\u3068\u3059\u308b","da45a4f5":"# Show Baseline Score","dfa5547f":"### constellationType, svid","213fe3bb":"## test all","27fc8229":"## sat vel","a83ecadb":"sat vel2","dade2867":"## [x\/y\/z]SatPosM\nttx = receivedSvTimeInGpsNanos - satClkBiasNanos (\u4ee5\u4e0b\u306b\u5b9a\u7fa9)\u3067\u5b9a\u7fa9\u3055\u308c\u308b \"\u771f\u306e\u4fe1\u53f7\u9001\u4fe1\u6642\u9593 \"\u306e\u6700\u826f\u306e\u63a8\u5b9a\u5024\u306b\u304a\u3051\u308bECEF\u5ea7\u6a19\u30d5\u30ec\u30fc\u30e0\u5185\u306e\u885b\u661f\u4f4d\u7f6e(\u30e1\u30fc\u30c8\u30eb)\u3002\u3053\u308c\u3089\u306f\u3001\u885b\u661f\u653e\u9001\u306e\u30a8\u30d5\u30a7\u30e1\u30ea\u30b9\u3092\u7528\u3044\u3066\u8a08\u7b97\u3055\u308c\u3001\u771f\u306e\u885b\u661f\u4f4d\u7f6e\u306b\u5bfe\u3057\u3066\u7d041m\u306e\u8aa4\u5dee\u304c\u3042\u308a\u307e\u3059\u3002\n\nThe satellite position (meters) in an ECEF coordinate frame at best estimate of \u201ctrue signal transmission time\u201d defined as ttx = receivedSvTimeInGpsNanos - satClkBiasNanos (defined below). They are computed with the satellite broadcast ephemeris, and have ~1-meter error with respect to the true satellite position.","0a37b1ee":"## Training and Test(submission)","9151669c":"### signalType\n\nGNSS\u4fe1\u53f7\u30bf\u30a4\u30d7\u306f\u3001\u30b3\u30f3\u30b9\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u540d\u3068\u5468\u6ce2\u6570\u5e2f\u306e\u7d44\u307f\u5408\u308f\u305b\u3067\u3059\u3002\u30b9\u30de\u30fc\u30c8\u30d5\u30a9\u30f3\u3067\u6e2c\u5b9a\u3055\u308c\u308b\u4e00\u822c\u7684\u306a\u4fe1\u53f7\u30bf\u30a4\u30d7\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002GPS_L1\u3001GPS_L5\u3001GAL_E1\u3001GAL_E5A\u3001GLO_G1\u3001BDS_B1I\u3001BDS_B1C\u3001BDS_B2A\u3001QZS_J1\u3001QZS_J5\u3002\n\nThe GNSS signal type is a combination of the constellation name and the frequency band. Common signal types measured by smartphones include: GPS_L1, GPS_L5, GAL_E1, GAL_E5A, GLO_G1, BDS_B1I, BDS_B1C, BDS_B2A, QZS_J1, and QZS_J5.\n\n**cf.    def signal_type(self, df):**    \n\n| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |\n| Other | GPS_L1 | GPS_L5 | GAL_E1 | GAL_E5A | GLO_G1 | BDS_B1I | BDS_B1C | BDS_B2A | QZS_J1 | QZS_J5 |"}}