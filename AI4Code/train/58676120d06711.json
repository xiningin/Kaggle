{"cell_type":{"35c5ed34":"code","676f5a7c":"code","9dc831ac":"code","fa1d79f7":"code","bad2424b":"code","f7d21da3":"code","40541c05":"code","c11f3f5a":"code","5e10bea4":"code","aca7e0d9":"code","0678f443":"code","398ec224":"code","6a9cdb81":"code","4743a749":"code","08f17220":"code","38acab55":"markdown","a04d78dc":"markdown"},"source":{"35c5ed34":"import numpy as np\nimport pandas as pd\nfrom sklearn import datasets\n\niris = datasets.load_iris()\n\ndf = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n                     columns= iris['feature_names'] + ['target'])\nprint(df.info())\ndf.head()","676f5a7c":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndf.plot(y='sepal length (cm)', kind='box', title='Sepal length analysis')\n\ndf.plot(y='sepal length (cm)', kind='hist', bins=30, range=(4,8), normed=True, title='Normalized histogram for sepal length')\n\ndf.plot(y='sepal length (cm)', kind='hist', bins=30, range=(4,8), cumulative=True, normed=True, title='Cumulative distribution function (CDF) for sepal length')","9dc831ac":"## Analysing the sepal width","fa1d79f7":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndf.plot(y='sepal width (cm)', kind='box', title='Sepal width analysis')\n\ndf.plot(y='sepal width (cm)', kind='hist', bins=30, range=(2,4.5), normed=True, title='Normalized histogram for sepal width')\n\ndf.plot(y='sepal width (cm)', kind='hist', bins=30, range=(2,4.5), cumulative=True, normed=True, title='Cumulative distribution function (CDF) for sepal width')","bad2424b":"## Statistical EDA","f7d21da3":"print(df.describe())\nprint(df.median())\nprint(df.mean())\nprint(df.std())\n\ndf.plot(kind= 'box') \n\ndf['target'].describe()\ndf['target'].unique()","40541c05":"from sklearn.model_selection import train_test_split\n\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nprint('There are {} samples in the training set and {} samples in the test set'.format(\nX_train.shape[0], X_test.shape[0]))","c11f3f5a":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n\nsc.fit(X_train)\n\nX_train_std = sc.transform(X_train)\nX_test_std = sc.transform(X_test)\n\nX_combined_std = np.vstack((X_train_std, X_test_std))\ny_combined = np.hstack((y_train, y_test))\nprint(\"Data scaled\")","5e10bea4":"from matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nmarkers = ('s', 'x', 'o')\ncolors = ('red', 'blue', 'lightgreen')\ncmap = ListedColormap(colors[:len(np.unique(y_test))])\nfor idx, cl in enumerate(np.unique(y)):\n    plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n               c=cmap(idx), marker=markers[idx], label=cl)","aca7e0d9":"from sklearn.linear_model import Perceptron\nfrom sklearn.metrics import accuracy_score\n\nppn = Perceptron(max_iter=32, eta0=0.1, random_state=0)\nppn.fit(X_train_std, y_train)\ny_pred = ppn.predict(X_test_std)\nprint('Misclassfied samples: %d' % (y_test != y_pred).sum())\nprint ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))","0678f443":"from sklearn.svm import SVC\n\nC = 1.0  # SVM regularization parameter\nsvm = SVC(kernel='linear', C=C, gamma=0.1)\nsvm.fit(X_train_std, y_train)\n\nprint('The accuracy of the linear svm classifier on training data is {:.2f} out of 1'.format(svm.score(X_train_std, y_train)))\nprint('The accuracy of the linear svm classifier on test data is {:.2f} out of 1'.format(svm.score(X_test_std, y_test)))","398ec224":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\nsvm.fit(X_train_std, y_train)\n\nprint('The accuracy of the svm classifier on training data is {:.2f} out of 1'.format(svm.score(X_train_std, y_train)))\nprint('The accuracy of the svm classifier on test data is {:.2f} out of 1'.format(svm.score(X_test_std, y_test)))","6a9cdb81":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='poly', degree=3, C=1.0)\nsvm.fit(X_train_std, y_train)\n\nprint('The accuracy of the svm classifier on training data is {:.2f} out of 1'.format(svm.score(X_train_std, y_train)))\nprint('The accuracy of the svm classifier on test data is {:.2f} out of 1'.format(svm.score(X_test_std, y_test)))","4743a749":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=3)\npca.fit(X_train_std, y_train)\nprint('The accuracy of the svm classifier on training data is {:.2f} out of 1'.format(svm.score(X_train_std, y_train)))\nprint('The accuracy of the svm classifier on test data is {:.2f} out of 1'.format(svm.score(X_test_std, y_test)))","08f17220":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=6, p=2, metric='minkowski')\nknn.fit(X_train_std, y_train)\n\nprint('The accuracy of the knn classifier is {:.2f} out of 1 on training data'.format(knn.score(X_train_std, y_train)))\nprint('The accuracy of the knn classifier is {:.2f} out of 1 on test data'.format(knn.score(X_test_std, y_test)))","38acab55":"# Iris Dataset Exploration and Training","a04d78dc":"## Analysing the sepal length"}}