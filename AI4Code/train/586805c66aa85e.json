{"cell_type":{"5755c806":"code","5e625407":"code","ad4de55a":"code","df1ce405":"code","603c5829":"code","59e26833":"code","8c8ba4fc":"code","c6cf335c":"code","a5ef0c47":"code","f3203e48":"code","36967a83":"code","9262e168":"code","947940bf":"code","feea910b":"code","0963e44b":"code","b74acccc":"code","76ccbe27":"code","351fece4":"code","48163a22":"code","ba9f30fb":"code","81879d1a":"markdown","016aca78":"markdown","30795be4":"markdown","8f67d915":"markdown","b5a87c8e":"markdown","c565a4b4":"markdown","157efcac":"markdown","262f3b79":"markdown","07c7b104":"markdown","464d5ccc":"markdown","cb070fed":"markdown"},"source":{"5755c806":"!apt-get install -y graphviz libgraphviz-dev libcgraph6","5e625407":"!pip install git+https:\/\/github.com\/danielegrattarola\/spektral","ad4de55a":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom skimage.util import montage\nfrom IPython.display import Image, display, SVG, clear_output, HTML\nplt.rcParams[\"figure.figsize\"] = (6, 6)\nplt.rcParams[\"figure.dpi\"] = 125\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})\nplt.rcParams['image.cmap'] = 'gray' # grayscale looks better\nimport networkx as nx\ndef draw_graph_mpl(g, pos=None, ax=None, layout_func=nx.drawing.layout.kamada_kawai_layout, draw_labels=True):\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n    else:\n        fig = None\n    if pos is None:\n        pos = layout_func(g)\n    node_color = []\n    node_labels = {}\n    shift_pos = {}\n    for k in g:\n        node_color.append(g.nodes[k].get('color', 'green'))\n        node_labels[k] = g.nodes[k].get('label', k)\n        shift_pos[k] = [pos[k][0], pos[k][1]]\n    \n    edge_color = []\n    edge_width = []\n    for e in g.edges():\n        edge_color.append(g.edges[e].get('color', 'black'))\n        edge_width.append(g.edges[e].get('width', 0.5))\n    nx.draw_networkx_edges(g, pos, font_weight='bold', edge_color=edge_color, width=edge_width, alpha=0.5, ax=ax)\n    nx.draw_networkx_nodes(g, pos, node_color=node_color, node_shape='p', node_size=300, alpha=0.75, ax=ax)\n    if draw_labels:\n        nx.draw_networkx_labels(g, shift_pos, labels=node_labels, arrows=True, ax=ax)\n    ax.autoscale()\n    return fig, ax, pos","df1ce405":"from keras import Input, Model\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dense, Flatten\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\n\nfrom spektral.datasets import mnist\nfrom spektral.layers import GraphConv\nfrom spektral.layers.ops import sp_matrix_to_sp_tensor\nfrom spektral.utils import normalized_laplacian","603c5829":"# Parameters\nl2_reg = 5e-4         # Regularization rate for l2\nlearning_rate = 1e-3  # Learning rate for SGD\nbatch_size = 32       # Batch size\nepochs = 5        # Number of training epochs\nes_patience = 200     # Patience fot early stopping","59e26833":"# Load data\nX_train, y_train, X_val, y_val, X_test, y_test, adj = mnist.load_data()\nX_train, X_val, X_test = X_train[..., None], X_val[..., None], X_test[..., None]\nN = X_train.shape[-2]      # Number of nodes in the graphs\nF = X_train.shape[-1]      # Node features dimensionality\nn_out = 10  # Dimension of the target\n\nprint(X_train.shape, 'model input')","8c8ba4fc":"print(adj.shape, 'adjacency matrix')\nplt.matshow(adj.todense())","c6cf335c":"xx, yy = np.meshgrid(np.arange(28), np.arange(28))\nnode_id = ['X:{:02d}_Y:{:02d}'.format(x, y) for x, y in zip(xx.ravel(), yy.ravel())]","a5ef0c47":"print(node_id[300], 'is connected to')\nfor row, col in zip(*adj[300].nonzero()):\n    print(col, '->', node_id[col])","f3203e48":"G = nx.from_scipy_sparse_matrix(adj[:10, :10])\nfor k, pix_val in zip(G.nodes, X_train[0]):\n    G.nodes[k]['label'] = node_id[k]\ndraw_graph_mpl(G);","36967a83":"MAX_NODE = 28*12\nG = nx.from_scipy_sparse_matrix(adj[:MAX_NODE, :MAX_NODE])\nfor k, pix_val in zip(G.nodes, X_train[0]):\n    G.nodes[k]['label'] = node_id[k]\n    G.nodes[k]['color'] = 'red' if pix_val>0.5 else 'green'\ndraw_graph_mpl(G);","9262e168":"G = nx.from_scipy_sparse_matrix(adj)\nfor k, pix_val in zip(G.nodes, X_train[0]):\n    G.nodes[k]['label'] = ''\n    G.nodes[k]['color'] = 'red' if pix_val>0.5 else 'green'\ndraw_graph_mpl(G, pos=np.stack([xx.ravel(), yy.ravel()], -1));","947940bf":"fltr = normalized_laplacian(adj)\n\n# Model definition\nX_in = Input(shape=(N, F))\n# Pass A as a fixed tensor, otherwise Keras will complain about inputs of\n# different rank.\nA_in = Input(tensor=sp_matrix_to_sp_tensor(fltr))\n\ngraph_conv_1 = GraphConv(32,\n                       activation='elu',\n                       kernel_regularizer=l2(l2_reg),\n                       use_bias=True)([X_in, A_in])\ngraph_conv_2 = GraphConv(32,\n                       activation='elu',\n                       kernel_regularizer=l2(l2_reg),\n                       use_bias=True)([graph_conv_1, A_in])\nflatten = Flatten()(graph_conv_2)\nfc = Dense(512, activation='relu')(flatten)\noutput = Dense(n_out, activation='softmax')(fc)\n\n# Build model\nmodel = Model(inputs=[X_in, A_in], outputs=output)\noptimizer = Adam(lr=learning_rate)\nmodel.compile(optimizer=optimizer,\n              loss='sparse_categorical_crossentropy',\n              metrics=['acc'])\nmodel.summary()","feea910b":"# Train model\nvalidation_data = (X_val, y_val)\nmodel.fit(X_train,\n          y_train,\n          batch_size=batch_size,\n          validation_data=validation_data,\n          epochs=epochs,\n          callbacks=[\n              EarlyStopping(patience=es_patience, restore_best_weights=True)\n          ])","0963e44b":"# Evaluate model\nprint('Evaluating model.')\neval_results = model.evaluate(X_test,\n                              y_test,\n                              batch_size=batch_size)\nprint('Test loss: {}\\n'\n      'Test acc: {}'.format(*eval_results))","b74acccc":"W, b = model.layers[2].get_weights()\nprint(W.shape, b.shape)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\nax1.bar(np.arange(W.shape[1]), W[0])\nax2.bar(np.arange(W.shape[1]), b)","76ccbe27":"W, b = model.layers[3].get_weights()\nprint(W.shape, b.shape)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\nax1.imshow(W, vmin=-1, vmax=1, cmap='RdBu')\nax2.bar(np.arange(W.shape[1]), b)","351fece4":"i_model = Model(inputs=[X_in, A_in], outputs=[graph_conv_1, graph_conv_2])","48163a22":"gc1_out, gc2_out = i_model.predict(X_test[:32])","ba9f30fb":"fig, m_axs = plt.subplots(4, 3, figsize=(20, 15))\nfor i, (ax1, ax2, ax3) in enumerate(m_axs):\n    ax1.imshow(X_test[i].reshape((28, 28)))\n    gc_stack = gc1_out[i].reshape((28, 28, -1)).swapaxes(0, 2).swapaxes(1, 2)\n    ax2.imshow(montage(gc_stack), vmin=-0.5, vmax=0.5, cmap='RdBu')\n    ax2.set_title(i_model.output_names[0])\n    gc_stack = gc2_out[i].reshape((28, 28, -1)).swapaxes(0, 2).swapaxes(1, 2)\n    ax3.imshow(montage(gc_stack), vmin=-0.5, vmax=0.5, cmap='RdBu')\n    ax3.set_title(i_model.output_names[1])","81879d1a":"## Install Dependencies","016aca78":"# Weights\nNot sure exactly how to interpret these but we can show them easily enough","30795be4":"## Show intermediate output values\nHere we can rearrange the output of the graph convolutions to see if the model is learning similar sorts of features to the standard convolutional neural networks","8f67d915":"# What did the model actually learn?\nWe can now try and reassemble what the model actually learnt by exporting the intermediate layers","b5a87c8e":"- Show network (using the X, Y coordinates)","c565a4b4":"### Label Nodes and Show Connections\nHere we can visualize the topology a bit better and see what the graph actually looks like.","157efcac":"- Show 12 rows of the network","262f3b79":"## Libraries\nHere are the libraries and imports to make the model","07c7b104":"# Model Building\nNow we can build the model which uses the graph topology shown above as the basis. We feed the topology in as a constant tensor ($A_{in}$) and the convolutions occur across this topology. ","464d5ccc":"## Goal\nThe goal of the problem is to correctly classify the digits using the intensity values as the nodes and the neighborhood relationships as the edges. When we visualize the adjacency matrix we can see the effect of a simply unraveled 2D array","cb070fed":"# Overview\nThe notebook is mainly done for my own benefit to better understand what graph convolutional networks do on a very basic and visual task (MNIST). \n\nThe notebook is just a slightly more visual version of the MNIST example provided at https:\/\/github.com\/danielegrattarola\/spektral\/blob\/master\/examples\/graph_signal_classification_mnist.py as part of the [Spektral](https:\/\/github.com\/danielegrattarola\/spektral) package. "}}