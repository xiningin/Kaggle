{"cell_type":{"783a81aa":"code","93cca756":"code","088d27e4":"code","21d62cd7":"code","9f02321d":"code","270912cd":"code","d57b8db4":"code","dfd06fac":"code","2bd058df":"code","aaf6dc95":"code","373526e2":"code","6b8f2b3f":"code","89905bf7":"code","4f387377":"code","386edfe8":"code","6228db4b":"code","e5b6463a":"code","ee057cc1":"code","16c007a4":"code","7e14f211":"code","8070773a":"code","bf171fe3":"code","70289d68":"code","5cfa400a":"code","d3917b92":"code","0576b0af":"code","b75bb996":"code","7eb94285":"code","e3310639":"code","cc828b6c":"code","cbcdf4e5":"code","718d3115":"code","0424a7c8":"code","f23b30d2":"code","5aeaf10a":"code","b271c460":"code","66e48fdb":"code","979d237a":"code","0cacf716":"code","a82397a8":"code","45a0ba0f":"code","2918fe5f":"code","2b464e14":"code","8b253d25":"code","c8e42a5e":"code","c4d4f712":"code","dd74cdae":"code","bfcaff99":"code","9251f4cd":"code","75aa0bc6":"code","5f18ab57":"markdown","31050e5c":"markdown","5020cfe0":"markdown","50000fc8":"markdown","520ef25c":"markdown","98e92b98":"markdown","4244565b":"markdown","8232c9bb":"markdown","0318ffed":"markdown","0ed69ed5":"markdown","bc830b58":"markdown","e22e2862":"markdown","f651138a":"markdown","aaec063a":"markdown","49d4aa24":"markdown","1bd7f483":"markdown","c71e89c5":"markdown","96c551f7":"markdown","ea988f1b":"markdown","bec0d0b9":"markdown","44e1e1a7":"markdown","7ac992f8":"markdown","f90985f1":"markdown","6d5de5d0":"markdown","4246f0c5":"markdown","e89ebd37":"markdown","f1e79d01":"markdown","1a9bbfc7":"markdown","4943091f":"markdown","a5cb79d8":"markdown","bb028341":"markdown","47b7259c":"markdown","9270db4e":"markdown"},"source":{"783a81aa":"!pip -q install mplfinance\nimport mplfinance as mpf","93cca756":"import pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom itertools import cycle\nimport datetime as dt\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense, Dropout, LSTM\npd.set_option('max_columns', 50)\n\nplt.style.use('dark_background')\n\ncolor_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])","088d27e4":"train_df = pd.read_csv('..\/input\/g-research-crypto-forecasting\/train.csv')\nasset_df = pd.read_csv('..\/input\/g-research-crypto-forecasting\/asset_details.csv')\nsupplement_train_df = pd.read_csv('..\/input\/g-research-crypto-forecasting\/supplemental_train.csv')","21d62cd7":"print (train_df.shape)\nprint (asset_df.shape)\nprint (supplement_train_df.shape)","9f02321d":"asset_df.head(15)","270912cd":"asset_df['wgt_pct'] = asset_df['Weight'] \/asset_df['Weight'].sum()*100","d57b8db4":"explode = [0, 0, 0, 0, 0,0,0,0, 0,0,0,0.08,0.15, 0.18]\n\ndef func(pct, allvals):\n    absolute = int(round(pct\/100.*np.sum(allvals)))\n    return \"{:.1f}%\\n({:d} g)\".format(pct, absolute)\n\n\nax = asset_df.set_index('Asset_Name')['wgt_pct'] \\\n    .sort_values(ascending=False) \\\n    .plot(kind='pie',\n          figsize=(22, 12),\n          fontsize = 14,\n          textprops={'color':\"magenta\"}, \n           autopct='%0.2f%%',\n          explode = explode,\n          shadow = True,\n          startangle=90, \n         )\nax.legend(asset_df['Asset_Name'],\n          loc =\"upper right\",\n          fontsize = 14,\n          bbox_to_anchor =(1, 0, 0.5, 1))\n\n\nax.set_title('Assets by Weight Percentage\\n\\n ', fontsize=20, color = 'cyan')\nax.set_ylabel('')\nplt.show()","dfd06fac":"id_mapping = dict(asset_df[['Asset_ID', 'Asset_Name']].values)\nwgt_mapping = dict(asset_df[['Asset_ID', 'Weight']].values)","2bd058df":"train_df[\"Asset name\"] = train_df[\"Asset_ID\"].map(id_mapping)\ntrain_df[\"Asset weight\"] = train_df[\"Asset_ID\"].map(wgt_mapping)","aaf6dc95":"train_df.head()","373526e2":"corr = train_df.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n#with sns.axes_style(\"darkgrid\"):\nf, ax = plt.subplots(figsize=(15, 8))\nax = sns.heatmap(corr,mask=mask, annot = True, cmap = 'PiYG')\n","6b8f2b3f":"ethereum = train_df.query(\"Asset_ID == 6\").reset_index(drop = True)\nethereum['date'] = pd.to_datetime(ethereum['timestamp'], unit='s')\nethereum = ethereum.set_index('date')","89905bf7":"ethereum.shape[0]","4f387377":"ethereum[ethereum['Target'].isnull()]\n","386edfe8":"ethereum.index.min(), ethereum.index.max()","6228db4b":"mpf.plot(ethereum, type = 'renko')","e5b6463a":"sample_ = ethereum.loc['2021-04-01 05:45:00':'2021-04-01 8:00:00']","ee057cc1":"mpf.plot(sample_, # the dataframe containing the OHLC (Open, High, Low and Close) data\n         type='candle', # use candlesticks \n         volume=True, # also show the volume\n         mav=(10, 20), # use three different moving averages\n         figratio=(3,1), # set the ratio of the figure\n         style='yahoo',  # choose the yahoo style\n         title='Single day - short time frame transactions ');","16c007a4":"sample_1 = ethereum.loc['2021-09-02 05:45:00':'2021-09-02 07:00:00']","7e14f211":"mpf.plot(sample_1,type='line',mav=(5,15),volume=True)","8070773a":"iday = ethereum.loc['2020-11-05':'2020-11-06',:]","bf171fe3":"mpf.plot(iday,type='line',volume=True, warn_too_much_data=50, mav=(25,50))","70289d68":"#Drop null values\n\"\"\"\nanalyse single asset \n\"\"\"\nethereum.dropna(axis = 0, inplace = True)\nethereum.shape","5cfa400a":"ethereum.head(5)","d3917b92":"#ethereum[ethereum.index == '2021-01-01 00:01:00']","0576b0af":"\nethereum.reset_index()\nethereum = ethereum.set_index('timestamp')","b75bb996":"####https:\/\/www.kaggle.com\/sami116\/first-steps-crypto-forecasting\nf = plt.figure(figsize = (10,6))\n\nax = f.add_subplot(111)\nax.set_facecolor('azure')\nplt.plot(ethereum['Close'], c = 'darkviolet')\nplt.axvline(x = 1514764860, label = 'Start of 2018', c = 'gray')\nplt.axvline(x = 1546300860, label = 'Start of 2019', c = 'orange')\nplt.axvline(x = 1577836860, label = 'Start of 2020', c = 'forestgreen')\nplt.axvline(x = 1609459260, label = 'Start of 2021', c = 'crimson')\nplt.legend()\nplt.xlabel('Time')\nplt.ylabel('Ethereum Close')\nplt.grid()\nplt.title('Close price of ethereum')\n\nplt.show()","7eb94285":"ethereum.head()","e3310639":"ethereum.reset_index(inplace = True)\nethereum['date'] = pd.to_datetime(ethereum['timestamp'], unit='s')\nethereum = ethereum.set_index('date')\nethereum.head()","cc828b6c":"FullData = ethereum.loc['2021-05-01 00:01:00':'2021-06-30 23:59:59']\nFullData.head()","cbcdf4e5":"\n# Extracting the closing prices of each day\nFullData=FullData[['Target']].values \n                  #ethereum[:25000][['Target']].values\nprint(FullData[0:5])\n \n# Feature Scaling for fast training of neural networks\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n \n# Choosing between Standardization or normalization\n#sc = StandardScaler()\nsc=MinMaxScaler()\n \nDataScaler = sc.fit(FullData)\nX=DataScaler.transform(FullData)\n#X=FullData\n \nprint('### After Normalization ###')\nX[0:5]","718d3115":"# split into samples\nX_samples = list()\ny_samples = list()\n\nNumerOfRows = len(X)\nTimeSteps=15  # next day's Price Prediction is based on last how many past day's prices\n\n# Iterate thru the values to create combinations\nfor i in range(TimeSteps , NumerOfRows , 1):\n    x_sample = X[i-TimeSteps:i]\n    y_sample = X[i]\n    X_samples.append(x_sample)\n    y_samples.append(y_sample)\n\n################################################\n# Reshape the Input as a 3D (number of samples, Time Steps, Features)\nX_data=np.array(X_samples)\nX_data=X_data.reshape(X_data.shape[0],X_data.shape[1], 1)\nprint('\\n#### Input Data shape ####')\nprint(X_data.shape)\n\n# We do not reshape y as a 3D data  as it is supposed to be a single column only\ny_data=np.array(y_samples)\ny_data=y_data.reshape(y_data.shape[0], 1)\nprint('\\n#### Output Data shape ####')\nprint(y_data.shape)","0424a7c8":"# Choosing the number of validation data records\nTestingRecords=500\n \n# Splitting the data into train and test\nX_train=X_data[:-TestingRecords]\nX_test=X_data[-TestingRecords:]\ny_train=y_data[:-TestingRecords]\ny_test=y_data[-TestingRecords:]\n \n############################################\n \n# Printing the shape of training and testing\nprint('\\n#### Training Data shape ####')\nprint(X_train.shape)\nprint(y_train.shape)\nprint('\\n#### Validation Data shape ####')\nprint(X_test.shape)\nprint(y_test.shape)","f23b30d2":"\n# Visualizing the input and output being sent to the LSTM model\nfor inp, out in zip(X_train[0:2], y_train[0:2]):\n    print(inp,'--', out)","5aeaf10a":"\n# Defining Input shapes for LSTM\nTimeSteps=X_train.shape[1]\nTotalFeatures=X_train.shape[2]\nprint(\"Number of TimeSteps:\", TimeSteps)\nprint(\"Number of Features:\", TotalFeatures)","b271c460":"from keras.models import Sequential\nfrom keras.layers import Activation, Dense, Dropout, LSTM\n \n# Initialising the RNN\nregressor = Sequential()\n \n# Adding the First input hidden layer and the LSTM layer\n# return_sequences = True, means the output of every time step to be shared with hidden next layer\nregressor.add(LSTM(units = 15, activation = 'relu', input_shape = (TimeSteps, TotalFeatures), return_sequences=True))\n \n# Adding the Second Second hidden layer and the LSTM layer\nregressor.add(LSTM(units = 10, activation = 'relu', input_shape = (TimeSteps, TotalFeatures), return_sequences=True))\n \n# Adding the Second Third hidden layer and the LSTM layer\nregressor.add(LSTM(units = 5, activation = 'relu', return_sequences=False ))\n \nregressor.add(Dropout(0.3))\n# Adding the output layer\nregressor.add(Dense(units = 1))\n \n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n \n##################################################\n \nimport time\n# Measuring the time taken by the model to train\nStartTime=time.time()\n \n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, batch_size = 15, epochs = 3)\n \nEndTime=time.time()\nprint(\"## Total Time Taken: \", round((EndTime-StartTime)\/60), 'Minutes ##')","66e48fdb":"\n# Making predictions on test data\npredicted_Price = regressor.predict(X_test)\npredicted_Price = DataScaler.inverse_transform(predicted_Price)\n \n# Getting the original price values for testing data\norig=y_test\norig=DataScaler.inverse_transform(y_test)\n \n# Accuracy of the predictions\n#print('Accuracy:', 100 - (100*(abs(orig-predicted_Price)\/orig)).mean())\n \n# Visualising the results\nimport matplotlib.pyplot as plt\n \nplt.plot(predicted_Price, color = 'pink', label = 'Predicted Volume')\nplt.plot(orig, color = 'green', label = 'Original Volume')\n \nplt.title('Predicting Ethereum ')\nplt.xlabel(' Date')\nplt.xticks(range(TestingRecords), ethereum.tail(TestingRecords)['Target'])\nplt.ylabel(' Price')\n \nplt.legend()\nfig=plt.gcf()\nfig.set_figwidth(20)\nfig.set_figheight(6)\nplt.show()","979d237a":"TrainPredictions=DataScaler.inverse_transform(regressor.predict(X_train))\nTestPredictions=DataScaler.inverse_transform(regressor.predict(X_test))\n \nFullDataPredictions=np.append(TrainPredictions, TestPredictions)\nFullDataOrig=FullData[TimeSteps:]\n \n# plotting the full data\nplt.plot(FullDataPredictions, color = 'magenta', label = 'Predicted Price')\nplt.plot(FullDataOrig , color = 'lightblue', label = 'Original Price')\n \n \nplt.title(' Price Predictions')\nplt.xlabel(' Date')\nplt.ylabel(' Price')\nplt.legend()\nfig=plt.gcf()\nfig.set_figwidth(20)\nfig.set_figheight(8)\nplt.show()","0cacf716":"ethereum[['Target']].tail(51).values.flatten()","a82397a8":"\n# Last 10 days prices\nLast50Days=np.array([ 0.00045282,  0.00061184,  0.0012775 ,  0.00086473,  0.00072952,\n        0.00110401,  0.00171625,  0.00118262,  0.00100348,  0.00164157,\n        0.0029463 ,  0.00314749,  0.00281155,  0.00217294,  0.00238924,\n        0.00390146,  0.00361306,  0.0040886 ,  0.00405105,  0.00269954,\n        0.00242405,  0.00102109,  0.00140944,  0.00131124,  0.00059185,\n       -0.00050834,  0.0010392 ,  0.00123086,  0.00070894,  0.00061493,\n       -0.00096887, -0.00127859, -0.00162916, -0.00223221, -0.00142235,\n       -0.00225987, -0.00152843, -0.00087532, -0.00061999,  0.00025487,\n        0.00057095, -0.00130277, -0.00127819, -0.00129005, -0.00076483,\n       -0.00189372, -0.00130851, -0.0007357 , -0.00049116, -0.00056185\n      ])\n \n# Normalizing the data just like we did for training the model\nLast50Days=DataScaler.transform(Last50Days.reshape(-1,1))\n \n# Changing the shape of the data to 3D\n# Choosing TimeSteps as 10 because we have used the same for training\nNumSamples=1\nTimeSteps=50\nNumFeatures=1\nLast50Days=Last50Days.reshape(NumSamples,TimeSteps,NumFeatures)\n \n#############################\n \n# Making predictions on data\npredicted_Price = regressor.predict(Last50Days)\npredicted_Price = DataScaler.inverse_transform(predicted_Price)\npredicted_Price","45a0ba0f":"\n# Considering the Full Data again which we extracted above\n# Printing the last 10 values\nprint('Original Prices')\nprint(FullData[-10:])\n \nprint('###################')\n \n# Printing last 10 values of the scaled data which we have created above for the last model\n# Here I am changing the shape of the data to one dimensional array because\n# for Multi step data preparation we need to X input in this fashion\nX=X.reshape(X.shape[0],)\nprint('Scaled Prices')\nprint(X[-10:])","2918fe5f":"\n# Multi step data preparation\n \n# split into samples\nX_samples = list()\ny_samples = list()\n \nNumerOfRows = len(X)\nTimeSteps=50  # next few day's Price Prediction is based on last how many past day's prices\nFutureTimeSteps=15 # How many days in future you want to predict the prices\n \n# Iterate thru the values to create combinations\nfor i in range(TimeSteps , NumerOfRows-FutureTimeSteps , 1):\n    x_sample = X[i-TimeSteps:i]\n    y_sample = X[i:i+FutureTimeSteps]\n    X_samples.append(x_sample)\n    y_samples.append(y_sample)\n    \n# Reshape the Input as a 3D (samples, Time Steps, Features)\nX_data=np.array(X_samples)\nX_data=X_data.reshape(X_data.shape[0],X_data.shape[1], 1)\nprint('### Input Data Shape ###') \nprint(X_data.shape)\n \n# We do not reshape y as a 3D data  as it is supposed to be a single column only\ny_data=np.array(y_samples)\nprint('### Output Data Shape ###') \nprint(y_data.shape)","2b464e14":"\n# Choosing the number of testing data records\nTestingRecords=5\n \n# Splitting the data into train and test\nX_train=X_data[:-TestingRecords]\nX_test=X_data[-TestingRecords:]\ny_train=y_data[:-TestingRecords]\ny_test=y_data[-TestingRecords:]\n \n#############################################\n# Printing the shape of training and testing\nprint('\\n#### Training Data shape ####')\nprint(X_train.shape)\nprint(y_train.shape)\n \nprint('\\n#### Testing Data shape ####')\nprint(X_test.shape)\nprint(y_test.shape)","8b253d25":"\n# Visualizing the input and output being sent to the LSTM model\n# Based on last 10 days prices we are learning the next 5 days of prices\nfor inp, out in zip(X_train[0:2], y_train[0:2]):\n    print(inp)\n    print('====>')\n    print(out)\n    print('#'*20)","c8e42a5e":"\n# Defining Input shapes for LSTM\nTimeSteps=X_train.shape[1]\nTotalFeatures=X_train.shape[2]\nprint(\"Number of TimeSteps:\", TimeSteps)\nprint(\"Number of Features:\", TotalFeatures)","c4d4f712":"# Initialising the RNN\nregressor = Sequential()\n \n# Adding the First input hidden layer and the LSTM layer\n# return_sequences = True, means the output of every time step to be shared with hidden next layer\nregressor.add(LSTM(units = 10, activation = 'relu', input_shape = (TimeSteps, TotalFeatures), return_sequences=True))\n \n \n# Adding the Second hidden layer and the LSTM layer\nregressor.add(LSTM(units = 5, activation = 'relu', input_shape = (TimeSteps, TotalFeatures), return_sequences=True))\n \n# Adding the Third hidden layer and the LSTM layer\nregressor.add(LSTM(units = 5, activation = 'relu', return_sequences=False ))\n \nregressor.add(Dropout(0.25))\n# Adding the output layer\n# Notice the number of neurons in the dense layer is now the number of future time steps \n# Based on the number of future days we want to predict\nregressor.add(Dense(units = FutureTimeSteps))\n \n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n \n###################################################################\n \nimport time\n# Measuring the time taken by the model to train\nStartTime=time.time()\n \n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, batch_size = 15, epochs = 3)\n \nEndTime=time.time()\nprint(\"############### Total Time Taken: \", round((EndTime-StartTime)\/60), 'Minutes #############')\n","dd74cdae":"#Making predictions on test data\npredicted_Price = regressor.predict(X_test)\npredicted_Price = DataScaler.inverse_transform(predicted_Price)\nprint('#### Predicted Prices ####')\nprint(predicted_Price)\n \n# Getting the original price values for testing data\norig=y_test\norig=DataScaler.inverse_transform(y_test)\nprint('\\n#### Original Prices ####')\nprint(orig)","bfcaff99":" \nfor i in range(len(orig)):\n    Prediction=predicted_Price[i]\n    Original=orig[i]\n     \n    # Visualising the results\n    plt.plot(Prediction, color = 'brown', label = 'Predicted Volume')\n    plt.plot(Original, color = 'lightblue', label = 'Original Volume')\n \n    plt.title('### Accuracy of the predictions:'+ str(100 - (100*(abs(Original-Prediction)\/Original)).mean().round(2))+'% ###')\n    plt.xlabel(' Date')\n    \n    startDateIndex=(FutureTimeSteps*TestingRecords)-FutureTimeSteps*(i+1)\n    endDateIndex=(FutureTimeSteps*TestingRecords)-FutureTimeSteps*(i+1) + FutureTimeSteps\n    TotalRows=ethereum.shape[0]\n \n    plt.xticks(range(FutureTimeSteps), ethereum.iloc[TotalRows-endDateIndex : TotalRows-(startDateIndex) , :]['Target'])\n    plt.ylabel(' Price')\n \n    plt.legend()\n    fig=plt.gcf()\n    fig.set_figwidth(20)\n    fig.set_figheight(3)\n    plt.show()","9251f4cd":"ethereum[['Target']].tail(65).values.flatten()","75aa0bc6":"\n# Making predictions on test data\nLast50DaysPrices=np.array([-0.00480228, -0.0048188 , -0.00373259, -0.00228633, -0.00241039,\n       -0.00222162, -0.00076806, -0.00089731, -0.00111598, -0.00050295,\n       -0.00094476, -0.00030015,  0.00144354,  0.00243018,  0.00045282,\n        0.00061184,  0.0012775 ,  0.00086473,  0.00072952,  0.00110401,\n        0.00171625,  0.00118262,  0.00100348,  0.00164157,  0.0029463 ,\n        0.00314749,  0.00281155,  0.00217294,  0.00238924,  0.00390146,\n        0.00361306,  0.0040886 ,  0.00405105,  0.00269954,  0.00242405,\n        0.00102109,  0.00140944,  0.00131124,  0.00059185, -0.00050834,\n        0.0010392 ,  0.00123086,  0.00070894,  0.00061493, -0.00096887,\n       -0.00127859, -0.00162916, -0.00223221, -0.00142235, -0.00225987])\n \n# Reshaping the data to (-1,1 )because its a single entry\nLast50DaysPrices=Last50DaysPrices.reshape(-1, 1)\n \n# Scaling the data on the same level on which model was trained\nX_test=DataScaler.transform(Last50DaysPrices)\n \nNumberofSamples=1\nTimeSteps=X_test.shape[0]\nNumberofFeatures=X_test.shape[1]\n# Reshaping the data as 3D input\nX_test=X_test.reshape(NumberofSamples,TimeSteps,NumberofFeatures)\n \n# Generating the predictions for next 5 days\nNext15DaysPrice = regressor.predict(X_test)\n \n# Generating the prices in original scale\nNext15DaysPrice = DataScaler.inverse_transform(Next15DaysPrice)\nNext15DaysPrice","5f18ab57":"# Making Prediction for next 15 days","31050e5c":"![image.png](attachment:2e89556b-2524-440f-9852-c296e99f6bef.png)","5020cfe0":"# Visualizing the Full Data","50000fc8":"**Correlation**","520ef25c":"**Assume We need to predict next 15 days price from the last 50 days values**","98e92b98":"# **[The below model is taken from the case study , ](https:\/\/thinkingneuron.com\/predicting-stock-prices-using-deep-learning-lstm-model-in-python\/)**","4244565b":"**Few graph ideas are taken from the below beautiful kernels.**\n\nhttps:\/\/www.kaggle.com\/robikscube\/predict-crypto-prices-twitch-stream\n\nhttps:\/\/www.kaggle.com\/carlmcbrideellis\/g-research-plot-financial-data-using-mplfinance\/notebook\n\nhttps:\/\/www.kaggle.com\/sami116\/first-steps-crypto-forecasting\/notebook","8232c9bb":"# Preparing the data","0318ffed":"I have taken single asset *Ethereum* here for demo purpose, the competition requires all 14 assets to be predicted..\n\nThank you for reading","0ed69ed5":"# Visualize the input output data for LSTM","bc830b58":"# Simple LSTM ","e22e2862":"# Two Consequetive Day Transactions","f651138a":"# Train Test Split","aaec063a":"[The below data description copied from](https:\/\/www.kaggle.com\/c\/g-research-crypto-forecasting\/data)","49d4aa24":"# Train Test Split","1bd7f483":"#### some of the important hyperparameters of LSTM \n\n1. **units=15**: This means we are creating a layer with fifteen neurons in it. Each of these fifteen neurons will be receiving the values of inputs.\n1. **input_shape = (TimeSteps, TotalFeatures):** The input expected by LSTM is in 3D format. Our training data has a shape of (24470, 30, 1) this is in the form of (number of samples, time steps, number of features). This means we have 25000 examples to learn in training data, each example looks back 30-steps in time like what was the asset price yesterday, the day before yesterday so on till last 30 days. This is known as Time steps. The last number \u20181\u2019 represents the number of features. Here we are using just one column \u2018Target\u2019 hence its equal to \u20181\u2019\n1. **kernel_initializer=\u2019uniform\u2019:** When the Neurons start their computation, some algorithm has to decide the value for each weight. This parameter specifies that. You can choose different values for it like \u2018normal\u2019 or \u2018glorot_uniform\u2019.\n1. **activation=\u2019relu\u2019:** This specifies the activation function for the calculations inside each neuron. You can choose values like \u2018relu\u2019, \u2018tanh\u2019, \u2018sigmoid\u2019, etc.\n1. **return_sequences=True:** LSTMs backpropagate thru time, hence they return the values of the output from each time step to the next hidden layer. This keeps the expected input of the next hidden layer in the 3D format. This parameter is False for the last hidden layer because now it does not have to return a 3D output to the final Dense layer.\n1. **optimizer=\u2019adam\u2019: ** This parameter helps to find the optimum values of each weight in the neural network. \u2018adam\u2019 is one of the most used optimizers\u2019\n1. **batch_size=20:** This specifies how many rows will be passed to the Network.\n\n1. **Epochs=5:**  The LSTM network looks at the full training data 5 times and adjusts its weights.","c71e89c5":"# Query only ethereum for the analysis","96c551f7":"# Measuring the accuracy on validation data","ea988f1b":"# With above model, we just predict one last value for ethereum","bec0d0b9":"# Data Preparation for Multi Step LSTM","44e1e1a7":"Lets find the yearwise transaction pattern for ethereum","7ac992f8":"# Measuring the Accuracy of the model on validation data","f90985f1":"#  DATA DESCRIPTION\n\n# Files\n\n### train.csv - The training set\n\n* timestamp - A timestamp for the minute covered by the row.\n* Asset_ID - An ID code for the cryptoasset.\n* Count - The number of trades that took place this minute.\n* Open - The USD price at the beginning of the minute.\n* High - The highest USD price during the minute.\n* Low - The lowest USD price during the minute.\n* Close - The USD price at the end of the minute.\n* Volume - The number of cryptoasset units traded during the minute.\n* VWAP - The volume weighted average price for the minute.\n* Target - 15 minute residualized returns. See the 'Prediction and Evaluation' section of this notebook for details of how the target is calculated.\n\n","6d5de5d0":"# Define Multi Step LSTM model","4246f0c5":"##### example_test.csv - An example of the data that will be delivered by the time series API.\n##### example_sample_submission.csv - An example of the data that will be delivered by the time series API. The data is just copied from train.csv.\n##### asset_details.csv - Provides the real name and of the cryptoasset for each Asset_ID and the weight each cryptoasset receives in the metric.\n##### gresearch_crypto - An unoptimized version of the time series API files for offline work. You may need Python 3.7 and a Linux environment to run it without errors.\n##### supplemental_train.csv - After the submission period is over this file's data will be replaced with cryptoasset prices from the submission period. The current copy, which is just filled approximately the right amount of data from train.csv is provided as a placeholder.","e89ebd37":"# Prepare LSTM inputs","f1e79d01":"# MultiStep Time Series","1a9bbfc7":"Note **FutureTimeSteps** will be the number of days prices to be predicted","4943091f":"**Model has predicted -0.00062102 whereas actual target value is -0.0003459, the prediction is not accurate, But, we can improve the model performance....**","a5cb79d8":"# Define LSTM Model","bb028341":"# Show Intra-day","47b7259c":"Its good to take 2021 data for prediction as compared to previous years ","9270db4e":"# Visualizing the input->output sent to LSTM Multi-step model"}}