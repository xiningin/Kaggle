{"cell_type":{"d12945cf":"code","f7ade15e":"code","bbd1dbea":"code","656ec2f3":"code","e92b7079":"code","e2047e4c":"code","5067488b":"code","15dc833f":"code","f00dcdc8":"code","5a59ab0d":"code","dd9260eb":"code","e83af85d":"code","c2030b26":"code","56a262dc":"code","851646f5":"code","e11c987d":"code","107b25e1":"code","f85a643d":"code","6fe376fd":"code","3f65d63b":"code","387830a5":"code","b53bb113":"code","5c43b769":"code","d1345912":"code","bdfaa7e0":"code","e9f452df":"code","8e7b73e8":"code","6e796353":"code","3df78e18":"code","3f16239a":"code","df52fbe2":"code","ecfd612c":"code","1beccc81":"code","ce1b2f7d":"code","bbf18e9c":"code","c3b36ba8":"code","82daac3f":"code","833408ba":"code","8927c3d4":"code","bc225df0":"code","2e839e9f":"code","bea1be8c":"code","82f339f6":"code","03d1b90d":"markdown","2a1cefc8":"markdown","c26b0b04":"markdown","c5990d9f":"markdown","e50adc2a":"markdown","fd0490b3":"markdown","21178b3f":"markdown","3abc66f7":"markdown"},"source":{"d12945cf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f7ade15e":"from matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom sklearn.model_selection import train_test_split","bbd1dbea":"from sklearn.model_selection import learning_curve\ndef plot_learning_curve(est, X_train, y_train) :\n    train_sizes, train_scores, test_scores = learning_curve(estimator=est, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10),\n                                                        cv=5,\n                                                        n_jobs=-1)\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.figure(figsize=(8,10))\n    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n    plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n    plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n    plt.grid(b='on')\n    plt.xlabel('Number of training samples')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylim([0.6, 1.0])\n    plt.show()","656ec2f3":"from keras.datasets import mnist\n\nfrom keras.models import Sequential, load_model\n\nfrom keras.layers import Dense, Dropout, Flatten\n\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\n\nfrom keras.utils.np_utils import to_categorical","e92b7079":"def plot_roc_curve(est,X_test,y_test) :\n    probas = est.predict_proba(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    plt.figure(figsize=(8,8))\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0,1],[0,1],'r--')        # plus mauvaise courbe\n    plt.plot([0,0,1],[0,1,1],'g:')     # meilleure courbe\n    plt.xlim([-0.05,1.2])\n    plt.ylim([-0.05,1.2])\n    plt.ylabel('Taux de vrais positifs')\n    plt.xlabel('Taux de faux positifs')\n    plt.show","e2047e4c":"import h5py","5067488b":"with h5py.File('..\/input\/food41\/food_c101_n10099_r64x64x3.h5',\"r\") as f:\n    for key in f.keys():\n        print(f[key], key, f[key].name) # f[key] means a dataset or a group object. f[key].value visits dataset' value,except group object.","15dc833f":"f=h5py.File('..\/input\/food41\/food_c101_n10099_r64x64x3.h5',\"r\")","f00dcdc8":"print(f[\"category\"][:][0])","5a59ab0d":"dictionnaire = {}\nfor i in range(101):\n    dictionnaire[f['category_names'][i]]=i\nprint(dictionnaire)","dd9260eb":"X = f[\"images\"][:]\/255\ny_train=f['category'][:]\ny=[]\nfor i in range(10099):\n    index= np.where(f['category'][:][i]==True)\n    y.append(index[0])\ny_cat=to_categorical(y)\nprint(len(y_cat))","e83af85d":"with h5py.File('..\/input\/food41\/food_test_c101_n1000_r64x64x3.h5',\"r\") as f_test:\n    for key in f_test.keys():\n        print(f_test[key], key, f_test[key].name) # f[key] means a dataset or a group object. f[key].value visits dataset' value,except group object.","c2030b26":"f_test=h5py.File('..\/input\/food41\/food_test_c101_n1000_r64x64x3.h5',\"r\")\nX_test = f_test[\"images\"][:]\/255\ny_test=f_test['category'][:]\ny_testcat=[]\nfor i in range(1000):\n    index= np.where(f_test['category'][:][i]==True)\n    y_testcat.append(index[0])\ny_test_cat=to_categorical(y_testcat)\n","56a262dc":"train_h5_path='..\/input\/food41\/food_c101_n10099_r64x64x3.h5'\nsample_imgs = 25\n\nwith h5py.File(train_h5_path, 'r') as n_file:\n    total_imgs = n_file['images'].shape[0]\n    read_idxs = slice(0,sample_imgs)\n    im_data = n_file['images'][read_idxs]\n    im_label = n_file['category'].value[read_idxs]\n    label_names = [x.decode() for x in n_file['category_names'].value]\nfig, m_ax = plt.subplots(5, 5, figsize = (12, 12))\nfor c_ax, c_label, c_img in zip(m_ax.flatten(), im_label, im_data):\n    c_ax.imshow(c_img if c_img.shape[2]==3 else c_img[:,:,0], cmap = 'gray')\n    c_ax.axis('off')\n    c_ax.set_title(label_names[np.argmax(c_label)])","851646f5":"X_train=np.array(X)","e11c987d":"import cv2\nimport glob\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport pandas as pd\nfrom torch.utils.data import DataLoader, Dataset\nimport time","107b25e1":"#model CNN\nmodel1 = Sequential()\nmodel1.add(Conv2D(64, (3, 3), input_shape=(64, 64, 3), activation='relu'))\nmodel1.add(Conv2D(64, (3, 3), activation='relu'))\nmodel1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel1.add(Dropout(0.2))\n\n#model1.add(Conv2D(64, (3, 3), activation='relu'))\n#model1.add(Conv2D(64, (3, 3), activation='relu'))\n#model1.add(MaxPooling2D(pool_size=(2, 2)))\n#model1.add(Dropout(0.2))\n#model1.add(Conv2D(20, (3, 3), activation='relu'))\n#model1.add(MaxPooling2D(pool_size=(2, 2)))\n#model1.add(Dropout(0.2))\n\nmodel1.add(Flatten())\nmodel1.add(Dense(512, activation='relu'))\nmodel1.add(Dense(101, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","f85a643d":"model1.summary()","6fe376fd":"from keras.datasets import mnist\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.utils.np_utils import to_categorical\nimport tensorflow as tf","3f65d63b":"# Mod\u00e8le CNN plus profond\nmodel2 = Sequential()\nmodel2.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.2))\nmodel2.add(Flatten())\nmodel2.add(Dense(101))\n\nmodel2.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])","387830a5":"model2.summary()","b53bb113":"# Apprentissage\ntrain1 = model1.fit(X_train, y_cat, validation_data=(X_test, y_test_cat), epochs=20, batch_size=200, verbose=1)\n\n# Test\nscores = model1.evaluate(X_test, y_test, verbose=0)\n\nprint(\"Score : %.2f%%\" % (scores[1]*100))","5c43b769":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","d1345912":"plot_scores(train1)","bdfaa7e0":"# Apprentissage\ntrain2 = model2.fit(X_train, y_cat, validation_data=(X_test, y_test_cat), epochs=10, batch_size=200, verbose=1)\n\n# Test\nscores = model2.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","e9f452df":"plot_scores(train2)","8e7b73e8":"from keras.applications import InceptionV3, ResNet50V2","6e796353":"resnet = ResNet50V2(weights='imagenet', include_top=False, input_shape=(64,64,3))\nResNet50V2.trainable = False","3df78e18":"model3 = Sequential()\nmodel3.add(resnet)\nmodel3.add(Flatten())\nmodel3.add(Dense(512, activation='relu'))\nmodel3.add(Dense(128, activation='relu'))\nmodel3.add(Dropout(0.2))\nmodel3.add(Flatten())\nmodel3.add(Dense(101))","3f16239a":"model3.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])","df52fbe2":"train = model3.fit(X_train, y_cat, validation_data=(X_test, y_test_cat), epochs=50, batch_size=200, verbose=1)","ecfd612c":"# Test\nscores = model3.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","1beccc81":"plot_scores(train)\n","ce1b2f7d":"from keras.applications.vgg16 import VGG16\nvgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(64,64,3))\nvgg16.trainable = False","bbf18e9c":"model4 = Sequential()\nmodel4.add(vgg16)\nmodel4.add(Flatten())\nmodel4.add(Dense(512, activation='relu'))\nmodel4.add(Dense(128, activation='relu'))\nmodel4.add(Dense(101))","c3b36ba8":"model4.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])","82daac3f":"train4 = model4.fit(X_train, y_cat, validation_data=(X_test, y_test_cat), epochs=30, batch_size=200, verbose=1)","833408ba":"plot_scores(train4)","8927c3d4":"for layer in vgg16.layers[15:]:\n    layer.trainable=True\nfor layer in vgg16.layers[0:15]:\n    layer.trainable=False","bc225df0":"model4.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\ntrain4 = model4.fit(X_train, y_cat, validation_data=(X_test, y_test_cat), epochs=30, batch_size=200, verbose=1)","2e839e9f":"plot_scores(train4)","bea1be8c":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nimport os\nimport glob\nimport cv2\n\n\nnr_foods=10\nfoods = list(os.walk('..\/input\/food41\/images\/'))[0][1]\nnp.random.shuffle(foods)\n\nidx_to_name = {i:x for (i,x) in enumerate(foods[:nr_foods])}\nname_to_idx = {x:i for (i,x) in enumerate(foods[:nr_foods])}\n\ndata = []\nlabels = []\nimg_size = (112, 112)\n\nfor food in idx_to_name.values():\n    path = '..\/input\/food41\/images\/'\n    imgs = [cv2.resize(cv2.imread(img), img_size, interpolation=cv2.INTER_AREA) for img in glob.glob(path + food + '\/*.jpg')]\n    for img in imgs:\n        labels.append(name_to_idx[food])\n        data.append(img)\n        \n# Normalize data\ndata = np.array(data)\ndata = data \/ 255.0\ndata = data.astype('float32')\n\n# Create one hot encoding for labels\nlabels = np.array(labels)\nlabels = np.eye(len(idx_to_name.keys()))[list(labels)]\n# split training, labels\nX_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)","82f339f6":"resnet = ResNet50V2(weights='imagenet', include_top=False, input_shape=(112,112,3))\nResNet50V2.trainable = False\nmodel = Sequential()\nmodel.add(resnet)\n#model.add(Flatten())\n#model.add(Dense(512, activation='relu'))\n#model.add(Dense(128, activation='relu'))\n#model.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(nr_foods))\n\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\ntrain = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200, verbose=1)","03d1b90d":"Le premier mod\u00e8le CNN profond que nous avions cr\u00e9\u00e9 cr\u00e9ait du sur-apprentissage. Nous avons donc d\u00fb supprimer une couche de neurones pour \u00e9viter cela. ","2a1cefc8":"Fonction pour tracer la courbe ROC :","c26b0b04":"# Methode en important les images directement et en n'entrainant que certaines cat\u00e9gories","c5990d9f":"### R\u00e9seau Dense\n","e50adc2a":"## Lecture des images de Food","fd0490b3":"Fonction pour tracer les courbes d'apprentissage sur l'ensemble d'apprentissage et l'ensemble de validation :","21178b3f":"## H5","3abc66f7":"On observe un surappretissage en utilisant VGG16"}}