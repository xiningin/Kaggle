{"cell_type":{"4eaf2e15":"code","ed35d3a4":"code","02d60339":"code","dc1fb571":"code","db54aa83":"code","b7b33086":"code","ccff8716":"code","a79b906f":"code","c092aa4f":"code","a3820d11":"code","df2c463e":"code","4892c279":"code","f87cd438":"code","4ad9f175":"code","b3a2feef":"code","8e29aa81":"code","d8b4c3c4":"code","a565283c":"code","582cf289":"code","40f4fee7":"code","0b2082d6":"code","59f6665d":"code","c39b811d":"code","b3a24cba":"code","52a4aa4b":"code","c278270a":"code","b35c0f05":"code","55a81cee":"code","2aef8f0b":"code","dc095a7d":"code","e7df3f72":"code","2b46ebe7":"code","c800e3a1":"code","f23b5979":"code","8f7153bc":"code","24a5ff4c":"code","b7809777":"code","9cad0eee":"code","578798bb":"code","0fd38a77":"code","35c956bb":"code","417518f4":"code","caca99b5":"code","fc39c6a1":"code","44d02d81":"code","c82706f5":"code","d3e3701a":"code","57a271ef":"code","1be82eb0":"code","924e2023":"code","7ea937ac":"code","42e4f1a2":"code","9e7a9424":"code","beefc374":"code","30b9c97c":"code","3458f1a0":"code","ab403fdf":"code","d689d37a":"code","23cd2aea":"code","935b6511":"code","e4f62836":"code","884ee716":"code","2247f3c2":"code","643e32cc":"code","6bc36427":"code","931082b9":"code","223bc81e":"code","57ea1672":"code","bb7be5d5":"code","42b9617d":"code","a3751f91":"code","76d398b7":"code","f9dbaa60":"code","b2f7c0c0":"code","b868401c":"code","4de142ef":"code","b0decbe1":"code","94112eb9":"code","bc7e6fec":"code","3f6ba7f9":"code","d165e13a":"code","31e1907d":"code","f818bd95":"code","3dc6e921":"code","9a76d116":"code","247899f3":"code","03b41c1c":"code","0c266dac":"code","72ae4313":"code","ea0a4d3d":"code","88c66e02":"code","751255da":"code","95d0dbc2":"code","b41f27d8":"code","45ebda12":"code","c35f6eca":"code","1ba354d8":"code","4d891ba0":"code","c16ec0dd":"code","5ebce855":"code","163a0d53":"code","92d4489f":"code","68ada92e":"code","52ca1f82":"code","f3f7a175":"code","6fdc8102":"code","ccc2a47f":"code","ac6cc71f":"code","048135f7":"code","04341aee":"code","a44ebcc4":"code","4ba9b118":"code","5b27586e":"code","bd69ad82":"code","da7663e2":"code","12638d38":"code","9e4ab9aa":"code","ea8ce7bb":"code","58cedabb":"code","9e47898b":"code","6daf1fac":"code","4977cc68":"code","2bb6cbfb":"code","bcacb29c":"code","8ac99f0e":"code","ff0a2388":"code","73e9c2d5":"code","75a506a5":"code","32b9c702":"code","c7ec1c96":"code","9159cd7b":"code","7160618f":"code","0cb21b38":"code","a59bc86b":"code","9fe073a1":"code","2aa239a0":"code","5ee4e788":"code","75db3529":"code","6298726e":"markdown","9f6d28f7":"markdown","7905ce9d":"markdown","cf192cec":"markdown","975d3b7d":"markdown","b6f69bcf":"markdown","0acbe0c2":"markdown","c1d04d04":"markdown","4e33f662":"markdown","6964028d":"markdown","7ad57568":"markdown","1d57542d":"markdown","3827978d":"markdown","9c989af2":"markdown","4464d785":"markdown","c8dd4b9d":"markdown","210f5acd":"markdown","76f1c63a":"markdown","d689346b":"markdown","b6e31c30":"markdown","51b57e81":"markdown","903e04cd":"markdown","07a005fc":"markdown","2f871a33":"markdown","d266b8cd":"markdown","12d56379":"markdown","e56e5248":"markdown","c602e8a3":"markdown","da0eb322":"markdown","e59fb356":"markdown","875d6f32":"markdown","f6a9e327":"markdown","792b8fc2":"markdown","c15fc49f":"markdown","fabea09f":"markdown","d3523891":"markdown","0221bc7f":"markdown","60e378b9":"markdown","acdb2059":"markdown","7eb95dac":"markdown","ac06836f":"markdown","99e2be2d":"markdown","69f51cb1":"markdown","1a4edb28":"markdown","187cc75b":"markdown","e65988a5":"markdown","fff648fe":"markdown","69bafa70":"markdown","e3f2bcf4":"markdown","213fb6f1":"markdown","481cc2c5":"markdown","728ed58a":"markdown","513f2915":"markdown","9d8f648b":"markdown","87a664c5":"markdown","d92172ca":"markdown","75075416":"markdown","9ecdda90":"markdown","f43c5e32":"markdown","28588e26":"markdown","a621723e":"markdown","93a31e6e":"markdown","9d665aa8":"markdown","6615e7fb":"markdown","57b62499":"markdown"},"source":{"4eaf2e15":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport seaborn as sns\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.linear_model import ElasticNetCV,LassoCV,RidgeCV\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,LeakyReLU\n\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\n\n\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","ed35d3a4":"df_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_train.head()","02d60339":"df_train.drop('Id',axis=1,inplace=True)","dc1fb571":"def visualNA(df,perc=0):\n    #Percentage of NAN Values \n    NAN = [(c, df[c].isna().mean()*100) for c in df]\n    NAN = pd.DataFrame(NAN, columns=[\"column_name\", \"percentage\"])\n    NAN = NAN[NAN.percentage > perc]\n    print(NAN.sort_values(\"percentage\", ascending=False))\n    ","db54aa83":"\nvisualNA(df_train)","b7b33086":"def handleNA(df):\n    df['Alley'].fillna(value='No alley access',inplace=True)    \n    df['BsmtQual'].fillna(value='No Basement',inplace=True)\n    df['BsmtCond'].fillna(value='No Basement',inplace=True)\n    df['BsmtExposure'].fillna(value='No Basement',inplace=True)\n    df['BsmtFinType1'].fillna(value='No Basement',inplace=True)    \n    df['BsmtFinType2'].fillna(value='No Basement',inplace=True)    \n    df['FireplaceQu'].fillna(value='No Fireplace',inplace=True)    \n    df['GarageType'].fillna(value='No Garage',inplace=True)  \n    df['GarageYrBlt'].fillna(value=0,inplace=True)\n    df['GarageFinish'].fillna(value='No Garage',inplace=True)\n    df['GarageQual'].fillna(value='No Garage',inplace=True)\n    df['GarageCond'].fillna(value='No Garage',inplace=True)\n    df['MasVnrType'].fillna(value='None',inplace=True)\n    df['MasVnrArea'].fillna(value=0.0,inplace=True)\n    df['PoolQC'].fillna(value='No Pool',inplace=True)    \n    df['Fence'].fillna(value='No Fence',inplace=True)\n    df['MiscFeature'].fillna(value='None',inplace=True)\n    \n    ","ccff8716":"handleNA(df_train)","a79b906f":"\nvisualNA(df_train)","c092aa4f":"df_train[df_train['Electrical'].isnull()]","a3820d11":"df_train[(df_train['Electrical'].notnull()) & (df_train['MSSubClass']==80) \n        & (df_train['LotFrontage']==73) ]['Electrical']","df2c463e":"df_train.loc[df_train['Electrical'].isnull(),'Electrical'] = 'SBrkr'","4892c279":"dict_neighbor = {\n'NAmes'  :{'lat': 42.045830,'lon': -93.620767},\n'CollgCr':{'lat': 42.018773,'lon': -93.685543},\n'OldTown':{'lat': 42.030152,'lon': -93.614628},\n'Edwards':{'lat': 42.021756,'lon': -93.670324},\n'Somerst':{'lat': 42.050913,'lon': -93.644629},\n'Gilbert':{'lat': 42.060214,'lon': -93.643179},\n'NridgHt':{'lat': 42.060357,'lon': -93.655263},\n'Sawyer' :{'lat': 42.034446,'lon': -93.666330},\n'NWAmes' :{'lat': 42.049381,'lon': -93.634993},\n'SawyerW':{'lat': 42.033494,'lon': -93.684085},\n'BrkSide':{'lat': 42.032422,'lon': -93.626037},\n'Crawfor':{'lat': 42.015189,'lon': -93.644250},\n'Mitchel':{'lat': 41.990123,'lon': -93.600964},\n'NoRidge':{'lat': 42.051748,'lon': -93.653524},\n'Timber' :{'lat': 41.998656,'lon': -93.652534},\n'IDOTRR' :{'lat': 42.022012,'lon': -93.622183},\n'ClearCr':{'lat': 42.060021,'lon': -93.629193},\n'StoneBr':{'lat': 42.060227,'lon': -93.633546},\n'SWISU'  :{'lat': 42.022646,'lon': -93.644853}, \n'MeadowV':{'lat': 41.991846,'lon': -93.603460},\n'Blmngtn':{'lat': 42.059811,'lon': -93.638990},\n'BrDale' :{'lat': 42.052792,'lon': -93.628820},\n'Veenker':{'lat': 42.040898,'lon': -93.651502},\n'NPkVill':{'lat': 42.049912,'lon': -93.626546},\n'Blueste':{'lat': 42.010098,'lon': -93.647269}\n}","f87cd438":"df_train['Lat'] = df_train['Neighborhood'].map(lambda neighbor: dict_neighbor[neighbor]['lat'])\ndf_train['Lon'] = df_train['Neighborhood'].map(lambda neighbor: dict_neighbor[neighbor]['lon'])","4ad9f175":"Categorical_features = df_train.select_dtypes(include=['object'])\nNumerical_features = df_train.select_dtypes(exclude=['object'])","b3a2feef":"Numerical_features.columns","8e29aa81":"def plotdist(data):\n    try:\n        sns.distplot(data)\n    except RuntimeError as re:\n        if str(re).startswith(\"Selected KDE bandwidth is 0. Cannot estimate density.\"):\n            sns.distplot(data, kde_kws={'bw': 0.1})\n        else:\n            raise re","d8b4c3c4":"for feature in Numerical_features.columns:\n    plotdist(Numerical_features[feature])\n    plt.show()","a565283c":"for feature in Categorical_features.columns:\n    \n    if Categorical_features[feature].nunique() > 12 :\n        continue\n    if Categorical_features[feature].nunique() > 5 :\n        plt.figure(figsize=(10,6))\n        plt.xticks(rotation=45)\n    sns.violinplot(x=feature,y='SalePrice',data=df_train)\n    plt.tight_layout()\n    plt.show()","582cf289":"X = df_train.drop('SalePrice',axis=1)\ny = df_train['SalePrice']","40f4fee7":"LotFrontageX = X['LotFrontage']\nGarageYrBltX = X['GarageYrBlt']","0b2082d6":"ohe = OneHotEncoder(sparse=False,drop=\"if_binary\")\nCategorical_Encoded = ohe.fit_transform(Categorical_features.astype(str))","59f6665d":"Categorical_Encoded_Frame = pd.DataFrame(Categorical_Encoded, columns= ohe.get_feature_names(Categorical_features.columns))\nCategorical_Encoded_Frame.head()","c39b811d":"Numerical_features_X = Numerical_features.drop(['SalePrice','LotFrontage','GarageYrBlt'],axis=1)","b3a24cba":"X = Categorical_Encoded_Frame.join(Numerical_features_X).join(LotFrontageX).join(GarageYrBltX)\nXcolumns = X.columns\nX.head()","52a4aa4b":"X = KNNImputer(n_neighbors=5).fit_transform(X)","c278270a":"X = pd.DataFrame(X,columns=Xcolumns)\nX.head()","b35c0f05":"sns.distplot(y)","55a81cee":"y.skew()","2aef8f0b":"y_log = np.log(y)","dc095a7d":"y_log.skew()","e7df3f72":"sns.distplot(y_log)","2b46ebe7":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y_log, test_size=0.3, random_state=42)","c800e3a1":"print(\"X_train Shape: \",X_train.shape)\nprint(\"X_test Shape: \",X_test.shape)\nprint(\"y_train Shape: \",y_train.shape)\nprint(\"y_test Shape: \",y_test.shape)","f23b5979":"\nxStandardScaler = StandardScaler()\nyStandardScaler = StandardScaler()","8f7153bc":"X_train = xStandardScaler.fit_transform(X_train)\nX_test = xStandardScaler.transform(X_test)","24a5ff4c":"y_train = yStandardScaler.fit_transform(y_train.ravel().reshape(-1, 1))\ny_test = yStandardScaler.transform(y_test.ravel().reshape(-1, 1))","b7809777":"ModelCompList = list()","9cad0eee":"alphas = np.linspace(0,.1,num=21)\nlgLasso = LassoCV(cv=10,alphas=alphas)\nlgLasso.fit(X_train,y_train)","578798bb":"# print the intercept\nprint(lgLasso.alpha_)","0fd38a77":"coeff_df = pd.DataFrame(lgLasso.coef_.T,X.columns,columns=['Coefficient'])\ncoeff_df.sort_values(by='Coefficient').head(10).plot(kind='bar')\nplt.xlabel('Features')\nplt.title('Top 10 Negative Features')\n\ncoeff_df.sort_values(by='Coefficient',ascending=False).head(10).plot(kind='bar')\nplt.xlabel('Features')\nplt.title('Top 10 Positive Features')\n","35c956bb":"predictionsLinear = lgLasso.predict(X_test)","417518f4":"plt.scatter(np.exp(yStandardScaler.inverse_transform(y_test)),np.exp(yStandardScaler.inverse_transform(predictionsLinear)))","caca99b5":"sns.distplot((yStandardScaler.inverse_transform(y_test)-yStandardScaler.inverse_transform(predictionsLinear)),bins=50);","fc39c6a1":"def evaluateModel(name,y_test,Predictions):\n    modelComp = dict()\n    modelComp['Name'] = name\n    modelComp['MAE'] = metrics.mean_absolute_error(np.exp(yStandardScaler.inverse_transform(y_test)),\n                                                   np.exp(yStandardScaler.inverse_transform(Predictions)))\n    modelComp['MSE'] = metrics.mean_squared_error(np.exp(yStandardScaler.inverse_transform(y_test)),\n                                                  np.exp(yStandardScaler.inverse_transform(Predictions)))\n    modelComp['RMSE'] = np.sqrt(metrics.mean_squared_error(np.exp(yStandardScaler.inverse_transform(y_test)),\n                                                           np.exp(yStandardScaler.inverse_transform(Predictions))))\n    \n    print('MAE:', modelComp['MAE'])\n    print('MSE:', modelComp['MSE'])\n    print('RMSE:', modelComp['RMSE'])\n    \n    ModelCompList.append(modelComp)","44d02d81":"evaluateModel('Lasso',y_test,predictionsLinear)","c82706f5":"alphas = np.linspace(0,20,num=21)\nlgRidge = RidgeCV(cv=10,alphas=alphas)\nlgRidge.fit(X_train,y_train)","d3e3701a":"# print the intercept\nprint(lgRidge.alpha_)","57a271ef":"coeff_df = pd.DataFrame(lgRidge.coef_.T,X.columns,columns=['Coefficient'])\ncoeff_df.sort_values(by='Coefficient').head(10).plot(kind='bar')\nplt.xlabel('Features')\nplt.title('Top 10 Negative Features')\n\ncoeff_df.sort_values(by='Coefficient',ascending=False).head(10).plot(kind='bar')\nplt.xlabel('Features')\nplt.title('Top 10 Positive Features')\n","1be82eb0":"predictionsLinear = lgRidge.predict(X_test)","924e2023":"plt.scatter(np.exp(yStandardScaler.inverse_transform(y_test)),np.exp(yStandardScaler.inverse_transform(predictionsLinear)))","7ea937ac":"sns.distplot((yStandardScaler.inverse_transform(y_test)-yStandardScaler.inverse_transform(predictionsLinear)),bins=50);","42e4f1a2":"evaluateModel('Ridge',y_test,predictionsLinear)","9e7a9424":"alphas = np.linspace(0,10,num=21)\nl1_ratio = np.linspace(0,1,num=21)\nlgNet = ElasticNetCV(cv=10,alphas=alphas,l1_ratio=l1_ratio)\nlgNet.fit(X_train,y_train)","beefc374":"# print the intercept\nprint(lgNet.alpha_)\nprint(lgNet.l1_ratio_)","30b9c97c":"coeff_df = pd.DataFrame(lgNet.coef_.T,X.columns,columns=['Coefficient'])\ncoeff_df.sort_values(by='Coefficient').head(10).plot(kind='bar')\nplt.xlabel('Features')\nplt.title('Top 10 Negative Features')\n\ncoeff_df.sort_values(by='Coefficient',ascending=False).head(10).plot(kind='bar')\nplt.xlabel('Features')\nplt.title('Top 10 Positive Features')\n","3458f1a0":"predictionsLinear = lgNet.predict(X_test)","ab403fdf":"plt.scatter(np.exp(yStandardScaler.inverse_transform(y_test)),np.exp(yStandardScaler.inverse_transform(predictionsLinear)))","d689d37a":"sns.distplot((yStandardScaler.inverse_transform(y_test)-yStandardScaler.inverse_transform(predictionsLinear)),bins=50);","23cd2aea":"evaluateModel('Elastic Net',y_test,predictionsLinear)","935b6511":"rfr = RandomForestRegressor(n_estimators=2500)\nparameters = {'min_samples_split': [2],\n              'max_depth': [8],\n              'min_samples_leaf' :[2],\n              'max_samples': [.7]}\n","e4f62836":"rfr_grid = GridSearchCV(rfr,\n                        parameters,\n                        cv = 2)","884ee716":"rfr_grid.fit(X_train,y_train)","2247f3c2":"print(rfr_grid.best_score_)\nprint(rfr_grid.best_params_)","643e32cc":"coeff_df = pd.DataFrame(rfr_grid.best_estimator_.feature_importances_,X.columns,columns=['Importances'])\n\ncoeff_df.sort_values(by='Importances',ascending=False).head(10).plot(kind='bar')\nplt.xlabel('Features')\nplt.title('Top 10 Positive Features')\n","6bc36427":"predictionsForest = rfr_grid.best_estimator_.predict(X_test)","931082b9":"plt.scatter(yStandardScaler.inverse_transform(y_test),yStandardScaler.inverse_transform(predictionsForest))","223bc81e":"sns.distplot((np.exp(yStandardScaler.inverse_transform(y_test))-np.exp(yStandardScaler.inverse_transform(predictionsForest))),bins=50);","57ea1672":"evaluateModel('Random Forest',y_test,predictionsForest)","bb7be5d5":"xgb = XGBRegressor()\nparameters = {'objective':['reg:squarederror'],\n            'learning_rate': [.1],\n              'max_depth': [3],\n              'min_child_weight': [2],\n              'subsample': [0.7],\n              'colsample_bytree': [.7],\n              'colsample_bylevel':[.7],\n              'alpha' : [.05],\n              'lambda' : [.3],\n              'n_estimators': [2500]}\n","42b9617d":"xgb_grid = GridSearchCV(xgb,\n                        parameters,\n                        cv = 2)\nxgb_grid.fit(X_train,\n         y_train)","a3751f91":"print(xgb_grid.best_score_)\nprint(xgb_grid.best_params_)","76d398b7":"coeff_df = pd.DataFrame(xgb_grid.best_estimator_.feature_importances_,X.columns,columns=['Coefficient'])\n\ncoeff_df.sort_values(by='Coefficient',ascending=False).head(10).plot(kind='bar')\nplt.xlabel('Features')\nplt.title('Top 10 Positive Features')\n","f9dbaa60":"predictionsLinear = xgb_grid.predict(X_test)","b2f7c0c0":"plt.scatter(np.exp(yStandardScaler.inverse_transform(y_test)),np.exp(yStandardScaler.inverse_transform(predictionsLinear)))","b868401c":"sns.distplot((yStandardScaler.inverse_transform(y_test)-yStandardScaler.inverse_transform(predictionsLinear)),bins=50);","4de142ef":"evaluateModel('XG Boost',y_test,predictionsLinear)","b0decbe1":"xgb = LGBMRegressor()\nparameters = {'learning_rate': [.1],\n              'max_depth': [6],\n              'min_child_weight': [1],\n              'subsample': [0.7],\n              'colsample_bytree': [.7],\n              'colsample_bylevel': [.7],\n              'reg_alpha' : [.1],\n              'reg_lambda' : [.3],\n              'n_estimators': [12500]}\n","94112eb9":"xgb_grid = GridSearchCV(xgb,\n                        parameters,\n                        cv = 2)\nxgb_grid.fit(X_train,\n         y_train)","bc7e6fec":"print(xgb_grid.best_score_)\nprint(xgb_grid.best_params_)","3f6ba7f9":"coeff_df = pd.DataFrame(xgb_grid.best_estimator_.feature_importances_,X.columns,columns=['Coefficient'])\n\ncoeff_df.sort_values(by='Coefficient',ascending=False).head(10).plot(kind='bar')\nplt.xlabel('Features')\nplt.title('Top 10 Positive Features')\n","d165e13a":"predictionsLinear = xgb_grid.predict(X_test)","31e1907d":"plt.scatter(np.exp(yStandardScaler.inverse_transform(y_test)),np.exp(yStandardScaler.inverse_transform(predictionsLinear)))","f818bd95":"sns.distplot((yStandardScaler.inverse_transform(y_test)-yStandardScaler.inverse_transform(predictionsLinear)),bins=50);","3dc6e921":"evaluateModel('Light GBM',y_test,predictionsLinear)","9a76d116":"from sklearn.model_selection import train_test_split\nX_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X, y, test_size=0.3, random_state=42)","247899f3":"print(\"X_train Shape: \",X_train_nn.shape)\nprint(\"X_test Shape: \",X_test_nn.shape)\nprint(\"y_train Shape: \",y_train_nn.shape)\nprint(\"y_test Shape: \",y_test_nn.shape)","03b41c1c":"\nxStandardScaler = StandardScaler()\nyStandardScaler = StandardScaler()\n\nX_train_nn = xStandardScaler.fit_transform(X_train_nn)\nX_test_nn = xStandardScaler.transform(X_test_nn)\n\ny_train_nn = yStandardScaler.fit_transform(y_train_nn.ravel().reshape(-1, 1))\ny_test_nn= yStandardScaler.transform(y_test_nn.ravel().reshape(-1, 1))","0c266dac":"model = Sequential()\nmodel.add(Dense(256, input_dim=301))\nmodel.add(LeakyReLU(alpha=.1))\nmodel.add(Dropout(.1))\nmodel.add(Dense(192, activation='relu'))\nmodel.add(Dropout(.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(.1))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(.2))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(.1))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(1))\n\nmodel.summary()","72ae4313":"model.compile(loss='mean_squared_error',optimizer='adam',metrics=['mse'])","ea0a4d3d":"mcp = ModelCheckpoint(\n    'model.h5',\n    monitor=\"val_mse\",\n    verbose=2,\n    save_best_only=True,\n    mode=\"min\"\n)","88c66e02":"history = model.fit(X_train_nn,y_train_nn,epochs=100,batch_size=32,callbacks=mcp,validation_data=(X_test_nn,y_test_nn))","751255da":"# summarize history for accuracy\nplt.plot(history.history['mse'])\nplt.plot(history.history['val_mse'])\nplt.title('model MSE')\nplt.ylabel('MSE')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","95d0dbc2":"model = load_model('model.h5')","b41f27d8":"predictionsNeural = model.predict(X_test_nn)","45ebda12":"modelComp = dict()\nmodelComp['Name'] = 'Neural Network'\nmodelComp['MAE'] = metrics.mean_absolute_error(yStandardScaler.inverse_transform(y_test_nn),\n                                               yStandardScaler.inverse_transform(predictionsNeural))\nmodelComp['MSE'] = metrics.mean_squared_error(yStandardScaler.inverse_transform(y_test_nn),\n                                              yStandardScaler.inverse_transform(predictionsNeural))\nmodelComp['RMSE'] = np.sqrt(metrics.mean_squared_error(yStandardScaler.inverse_transform(y_test_nn),\n                                                       yStandardScaler.inverse_transform(predictionsNeural)))\n\nprint('MAE:', modelComp['MAE'])\nprint('MSE:', modelComp['MSE'])\nprint('RMSE:', modelComp['RMSE'])\n\nModelCompList.append(modelComp)","c35f6eca":"df_models = pd.DataFrame(ModelCompList)\ndf_models.head()","1ba354d8":"for i in df_models.columns[1:]:\n    sns.barplot(x='Name',y=i,data=df_models)\n    plt.xlabel('Model')\n    plt.xticks(rotation=-45)\n    plt.show()","4d891ba0":"df_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ndf_test.head()","c16ec0dd":"IdTest = df_test['Id']\ndf_test.drop('Id',axis=1,inplace=True)","5ebce855":"visualNA(df_test)","163a0d53":"handleNA(df_test)","92d4489f":"visualNA(df_test)","68ada92e":"df_test.loc[(df_test['MSZoning'].isnull()) & (df_test['MSSubClass'].astype(int)<70),'MSZoning'] = 'RL'\ndf_test.loc[(df_test['MSZoning'].isnull()) & (df_test['MSSubClass'].astype(int)>=70),'MSZoning'] = 'RM'","52ca1f82":"df_test.loc[df_test['Utilities'].isnull(),'Utilities'] = 'AllPub'","f3f7a175":"df_test.loc[df_test['Exterior1st'].isnull(),'Exterior1st'] = 'Wd Sdng'","6fdc8102":"df_test.loc[df_test['Exterior2nd'].isnull(),'Exterior2nd'] = 'Wd Sdng'","ccc2a47f":"df_test.loc[df_test['BsmtFinSF1'].isnull(),'BsmtFinSF1'] = 180","ac6cc71f":"df_test.loc[df_test['BsmtFinSF2'].isnull(),'BsmtFinSF2'] = 374","048135f7":"df_test.loc[df_test['BsmtUnfSF'].isnull(),'BsmtUnfSF'] = 340","04341aee":"df_test.loc[df_test['TotalBsmtSF'].isnull(),'TotalBsmtSF'] = 894","a44ebcc4":"df_test.loc[(df_test['BsmtFullBath'].isnull()) & (df_test['FullBath']==1),'BsmtFullBath'] = 0\ndf_test.loc[(df_test['BsmtFullBath'].isnull()) & (df_test['FullBath']==3),'BsmtFullBath'] = 1","4ba9b118":"df_test.loc[df_test['BsmtHalfBath'].isnull(),'BsmtHalfBath'] = 0","5b27586e":"df_test.loc[df_test['KitchenQual'].isnull(),'KitchenQual'] = 'TA'","bd69ad82":"df_test.loc[(df_test['Functional'].isnull()) & (df_train['ScreenPorch']<1), 'Functional'] = 'Typ'\ndf_test.loc[(df_test['Functional'].isnull()) & (df_train['ScreenPorch']>1) , 'Functional'] = 'Mod'","da7663e2":"df_test.loc[df_test['GarageCars'].isnull(),'GarageCars']= 2","12638d38":"df_test.loc[df_test['GarageArea'].isnull(),'GarageArea']= 324","9e4ab9aa":"df_test.loc[df_test['SaleType'].isnull(),'SaleType'] = 'WD'","ea8ce7bb":"visualNA(df_test)","58cedabb":"df_test['Lat'] = df_test['Neighborhood'].map(lambda neighbor: dict_neighbor[neighbor]['lat'])\ndf_test['Lon'] = df_test['Neighborhood'].map(lambda neighbor: dict_neighbor[neighbor]['lon'])","9e47898b":"Categorical_features_test = df_test.select_dtypes(include=['object'])\nNumerical_features_test = df_test.select_dtypes(exclude=['object'])","6daf1fac":"Categorical_Encoded_test = ohe.transform(Categorical_features_test)\n\nCategorical_Encoded_Frame_test = pd.DataFrame(Categorical_Encoded_test, columns= ohe.get_feature_names(Categorical_features_test.columns))\nCategorical_Encoded_Frame_test.head()","4977cc68":"LotFrontageTestX = Numerical_features_test['LotFrontage']\nGarageYrBltTestX = Numerical_features_test['GarageYrBlt']\nNumerical_features_test.drop(['LotFrontage','GarageYrBlt'],axis=1,inplace=True)","2bb6cbfb":"X_test_Full = Categorical_Encoded_Frame_test.join(Numerical_features_test).join(LotFrontageTestX).join(GarageYrBltTestX)\nX_testcolumns = X_test_Full.columns\nX_test_Full.head()","bcacb29c":"X_test_Full = KNNImputer(n_neighbors=5).fit_transform(X_test_Full)","8ac99f0e":"X_test_Frame = pd.DataFrame(X_test_Full,columns=X_testcolumns)\nX_test_Frame.head()","ff0a2388":"Xtest = StandardScaler()\nYtest = StandardScaler()\n\nX_Full = Xtest.fit_transform(X)\ny_Full = Ytest.fit_transform(y_log.ravel().reshape(-1,1))","73e9c2d5":"lgLassoFinal = LassoCV(cv=5,alphas =[.02])\nlgLassoFinal.fit(X_Full,y_Full)","75a506a5":"X_test_Frame = Xtest.transform(X_test_Frame)","32b9c702":"ypredLasso = lgLassoFinal.predict(X_test_Frame)","c7ec1c96":"lgRidgeFinal = RidgeCV(cv=5,alphas =[20])\nlgRidgeFinal.fit(X_Full,y_Full)","9159cd7b":"ypredRidge = lgRidgeFinal.predict(X_test_Frame)","7160618f":"ypredRidge = ypredRidge.reshape(-1,)","0cb21b38":"xgbFinal = XGBRegressor(objective='reg:squarederror',\n            learning_rate= .1,\n              max_depth= 3,\n              min_child_weight= 2,\n              subsample= 0.7,\n              colsample_bytree= .7,\n              colsample_bylevel=.7,\n              alpha = .05,\n              reg_lambda = .3,\n              n_estimators= 2500)","a59bc86b":"xgbFinal.fit(X_Full,y_Full)","9fe073a1":"ypredXG = xgbFinal.predict(X_test_Frame)","2aa239a0":"Final_Pred = -4447 + np.exp(Ytest.inverse_transform((ypredRidge*.20309379 + ypredLasso*.46724816 + ypredXG*.37162723)))","5ee4e788":"Final_Pred[np.exp(Ytest.inverse_transform(ypredRidge))>y.max()] = np.exp(Ytest.inverse_transform(ypredXG))[np.exp(Ytest.inverse_transform(ypredRidge))>y.max()]","75db3529":"submission = pd.DataFrame({\n        \"Id\": IdTest,\n        \"SalePrice\": Final_Pred\n    })\nsubmission.to_csv('submission.csv', index=False)","6298726e":"## Evaluation","9f6d28f7":"We have seen that to make our machine model work better in terms of error  we have to follow normal distribution phenomenon to make machine model results reliable but that's not the case with neural network. Neural network works on converges, pattern finding doesnt depend on normal distribution formula either we can use it or we can drop it .","7905ce9d":"## Residual Plot","cf192cec":"## Residual Plot","975d3b7d":"From above data cleaning and transformation we got to know that only Lot Frontage is the column which need to be handle for its missing value and It will be done at the time of data modelling for price predictions.","b6f69bcf":"## Defining model","0acbe0c2":"## Residual Plot","c1d04d04":"## Top 10 Feature Importance ( Positive and Negative Role )","4e33f662":"## Prediction from Linear Model","6964028d":"## One Hot Encoding Categorical Variables","7ad57568":"## Prediction","1d57542d":"## Predictions","3827978d":"## XG Boost","9c989af2":"# Ridge Linear Regression","4464d785":"## Prediction from Linear Model","c8dd4b9d":"## Alpha","210f5acd":"## Standardization","76f1c63a":"## Residual Plot","d689346b":"## Alpha","b6e31c30":"## Evaluation","51b57e81":"## Top 10 Feature Importance ( Positive and Negative Role )","903e04cd":"## Residual Plot","07a005fc":"# Elastic Net Linear Regression","2f871a33":"# Light GBM Regressor","d266b8cd":"# Lasso Linear Regression","12d56379":"## Evaluation","e56e5248":"# Target Model Creation","c602e8a3":"## Model Comparision Storage","da0eb322":"## Train\/Test Split","e59fb356":"## Top 10 Feature Importance ( Positive and Negative Role )","875d6f32":"## Feature Importance","f6a9e327":"## Ridge","792b8fc2":"## Alpha","c15fc49f":"Most of the notebooks are dropping missing percentage values due to its sheer size of missing value percentage but these missing values make insignificant impact on pricing as well as insights that we will see later our findings.","fabea09f":"## Data Preparation of Test Data","d3523891":"## Prediction from Linear Model","0221bc7f":"## Lasso","60e378b9":"## Performance","acdb2059":"## Distribution of Categorical Features with respect to Sales Price","7eb95dac":"#  Don't forget to upvote if you like my notebook. :)","ac06836f":"## Prediction from Linear Model","99e2be2d":"## Distribution of numerical features","69f51cb1":"# Data Modelling","1a4edb28":"Data Cleaning and transformation of test data is done using proper analysis with respect to other co factor variables.","187cc75b":"## Train\/Test Split","e65988a5":"# Data Visualization","fff648fe":"## Top 10 Feature Importance ( Positive and Negative Role )","69bafa70":"# Neural Network","e3f2bcf4":"## Best Score and Params","213fb6f1":"## Evaluation","481cc2c5":"# Model Comparision","728ed58a":"## Evaluation","513f2915":"## Distribution of dependent variable","9d8f648b":"It is clear from above plot that dependent variable sale price is showing right skewed distribution which need to be handle using log transformation.","87a664c5":"# Random Forest Regressor","d92172ca":"## Evaluation","75075416":"## Best Score and Parameters","9ecdda90":"#  Import Libraries","f43c5e32":"## Top 10 Feature Importance ( Positive and Negative Role )","28588e26":"## Best Score and Parameters","a621723e":"## Final Prediction","93a31e6e":"## Prediction from Linear Model","9d665aa8":"# XG Boost Regressor","6615e7fb":"## Residual Plot","57b62499":"## Evaluation"}}