{"cell_type":{"12212a74":"code","49899a3b":"code","59fc9caa":"code","824159fd":"code","8301bdf7":"code","c8d42db1":"code","a49f5796":"code","50105526":"code","4ec10ad4":"code","2afd2b2c":"code","dd3c4393":"code","d7ce609e":"code","a647caf3":"code","28de3877":"code","fdb65355":"code","c9136874":"code","f39bda5c":"code","a86c9c58":"code","5b3db2fb":"code","31de020c":"code","cc87bdf4":"code","f06ff490":"code","9c67eb7f":"code","549d1f4e":"code","10565eca":"code","25b34710":"code","69e41335":"code","7f95e955":"markdown","0412c4f1":"markdown","6060e0b5":"markdown","dfe5ef38":"markdown","5d81490b":"markdown","fcf8b960":"markdown","110f3e17":"markdown","c73c3525":"markdown","e8dbe3bc":"markdown","41cabcfb":"markdown","76f9b5ef":"markdown","5af09df6":"markdown","3271844e":"markdown","d04d74a6":"markdown","34d6aca9":"markdown","749ad3be":"markdown","42400308":"markdown","8c280e7a":"markdown","194caa74":"markdown","629a4c97":"markdown","58c37e7b":"markdown","c9047c01":"markdown","3c0bb898":"markdown","6953745d":"markdown"},"source":{"12212a74":"# Loading the required packages and libraries\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport nltk\nfrom nltk import FreqDist\nimport warnings\n\nimport spacy\nimport gensim\nfrom gensim import corpora\n\n# Libraries for visualization\nimport seaborn as sns\nimport pyLDAvis\nimport pyLDAvis.gensim\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","49899a3b":"# Input data files that are available\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndf1 = pd.read_csv(\"\/kaggle\/input\/airbnb-reviews_listing id 329997.csv\")\ndf2 = pd.read_csv(\"\/kaggle\/input\/airbnb-reviews_listing id 15440.csv\")\ndf3 = pd.read_csv(\"\/kaggle\/input\/airbnb-reviews_listing id 1260528.csv\")","59fc9caa":"df1.head()","824159fd":"#Dropping columns that aren't required\ndf1 = df1.drop(['id','date','reviewer_id','reviewer_name'], axis=1)\ndf2 = df2.drop(['id','date','reviewer_id','reviewer_name'], axis=1)\ndf3 = df3.drop(['id','date','reviewer_id','reviewer_name'], axis=1)\n\n#Dropping the rows with no comments\ndf1 = df1.dropna()\ndf2 = df2.dropna()\ndf3 = df3.dropna()","8301bdf7":"# Creating a new column to store the length of each review\ndf1['Comment_Length'] = df1['comments'].apply(len)\ndf2['Comment_Length'] = df2['comments'].apply(len)\ndf3['Comment_Length'] = df3['comments'].apply(len)","c8d42db1":"# Checking out the changes\ndf3.head()","a49f5796":"#Getting descriptive statistics for the new column 'Comment_Length' \ndf1.Comment_Length.describe()","50105526":"df2.Comment_Length.describe()","4ec10ad4":"df3.Comment_Length.describe()","2afd2b2c":"# Identifying the location of the longest review\ndf1[df1['Comment_Length'] == 1598]['comments'].iloc[0]","dd3c4393":"df2[df2['Comment_Length'] == 2617]['comments'].iloc[0]","d7ce609e":"df3[df3['Comment_Length'] == 2359]['comments'].iloc[0]","a647caf3":"# Using the plot style as seaborn-poster\nplt.style.use('default')\n\n# Plotting the histogram for the first data frame\ndf1['Comment_Length'].plot(bins=70, kind='hist') ","28de3877":"# Concatenated the three dataframe into one\ndf = pd.concat([df1,df2,df3])\n\n# Visualize the comment length for all three listing using subplots \nplt.style.use('classic')\ndf.hist(column='Comment_Length', by='listing_id', bins=40,figsize=(12,4))","fdb65355":"# Function to plot most frequent words\ndef freq_words(x, terms = 30):\n    all_words = ' '.join([text for text in x])\n    all_words = all_words.split()\n    \n    # using FreqDist function from nltk library to find number of\n    # time a word has appeared\n    fdist = FreqDist(all_words)\n    words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n    \n    # selecting top 10 most frequent words\n    d = words_df.nlargest(columns=\"count\", n = terms)\n    sns.set_color_codes('pastel')\n    plt.figure(figsize=(20,5))\n    ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n    ax.set(ylabel = 'Count')\n    plt.show()","c9136874":"freq_words(df1['comments'])","f39bda5c":"df1['comments'] = df1['comments'].str.replace(\"[^a-zA-Z#]\", \" \")","a86c9c58":"# Importing stop words list from the nltk.corpus\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')","5b3db2fb":"# Loading the pre-trained NLP model in spacy\nnlp=spacy.load(\"en_core_web_lg\") \n\n\n# Define a function to extract keywords\/topics\ndef get_words(x):\n    doc=nlp(x) ## Tokenize and extract grammatical components\n    doc=[i.text for i in doc if i.text not in stop_words and i.pos_==\"NOUN\"] # Extracting nouns\n    doc=list(map(lambda i: i.lower(),doc)) ## Normalize text to lower case\n    doc=pd.Series(doc)\n    doc=doc.value_counts().head().index.tolist() ## Get 5 most frequent nouns\n    return doc","31de020c":"# Loading the extracted word from comments\nkey_words = []\nfor i in range(0, 501):\n    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n    if i == 395:\n        continue\n    else:\n        key_words.append(get_words(df1['comments'][i]))\n\n# Merging multiple lists into a single list\nwords = []\nfor x in  key_words:\n    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n    for word in x:\n        words.append(word)\n\nprint(words)","cc87bdf4":"# Creating a new dataframe for the keywords and value count\ndf_new = pd.DataFrame()\ndf_new['Keywords'] = words\n\ncounts = df_new['Keywords'].value_counts()\ndf = pd.DataFrame(counts, df_new.Keywords.unique())\ndf = df.reset_index()\ndf = df.rename(columns={\"index\": \"Topic\", \"Keywords\": \"Count\"})\n\n# Printing the top 15 words in the dataframe\ndf = df.sort_values('Count', ascending = False)\ndf.head(15)","f06ff490":"plt.style.use('default')\nfreq_words(df_new['Keywords'])","9c67eb7f":"dictionary = corpora.Dictionary(key_words)","549d1f4e":"doc_term_matrix = [dictionary.doc2bow(rev) for rev in key_words]","10565eca":"# Creating the object for LDA model using gensim library\nLDA = gensim.models.ldamodel.LdaModel\n\n# Build LDA model\nlda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=7, random_state=100,\n                chunksize=1000, passes=50)","25b34710":"lda_model.print_topics()","69e41335":"# Visualize the topics\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\nvis","7f95e955":"# Overview\n\nThis notebook is a created as a part of Mini Project 2b that focuses on obtaining insights from the traveler's reviews left on Airbnb's site for specific listings.\n\nThe notebook uses the Airbnb review data from [Opendatasoft](https:\/\/public.opendatasoft.com\/explore\/dataset\/airbnb-reviews\/export\/?dataChart=eyJxdWVyaWVzIjpbeyJjb25maWciOnsiZGF0YXNldCI6ImFpcmJuYi1yZXZpZXdzIiwib3B0aW9ucyI6e319LCJjaGFydHMiOlt7ImFsaWduTW9udGgiOnRydWUsInR5cGUiOiJsaW5lIiwiZnVuYyI6IkNPVU5UIiwic2NpZW50aWZpY0Rpc3BsYXkiOnRydWUsImNvbG9yIjoicmFuZ2UtY3VzdG9tIn1dLCJ4QXhpcyI6Imxpc3RpbmdfaWQiLCJtYXhwb2ludHMiOiIiLCJ0aW1lc2NhbGUiOiIiLCJzb3J0IjoiIiwic2VyaWVzQnJlYWtkb3duIjoiZGF0ZSIsInNlcmllc0JyZWFrZG93blRpbWVzY2FsZSI6InllYXIifV0sImRpc3BsYXlMZWdlbmQiOnRydWUsImFsaWduTW9udGgiOnRydWUsInRpbWVzY2FsZSI6IiJ9). The data includes listing_id, reviewer_id, review comments, and the date the review has been posted and is used in csv file format as an input. \n\nWith this data, I am trying to simplify the data using visualization and through an unsupervised Machine Learning (ML) Topic model to understand : What is the average length of the review?, What are the most talked aspects of the property in the review e.g host, location, internet etc.?\"\n\n## Problem statement\n* To enable researchers to quickly extract the key topics covered in the reviews without having to go through all of them\n\n* **Extracting insights to help average properties\/listings to improve by sharing attributes of popular vacation rental:** Performing analysis on comments shared by guests for a property or listing based on multiple to identify the key winning attributes of the place\n\nI am using Latent Dirichlet Allocation (LDA) to perform the topic modeling. [Here is the article](https:\/\/towardsdatascience.com\/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0) that helped me to creat my very first first topic model using the sklearn implementation in python 2.7","0412c4f1":"I converted the list of words into a Document Term Matrix using the dictionary prepared above","6060e0b5":"I started analysing the text by defining a function that find out which are the most common words in our review comments.","dfe5ef38":"I created a new dataframe to store the list of words and their value counts","5d81490b":"# Text Pre-Processing\nFor this processing, I am using the data from first dataframe which is for below listing:\n> Funky Pad Suite - Parkside Portland in Portland, Oregon, United States","fcf8b960":"I used the freq_words function to print the most frequent words in the cleaned list","110f3e17":"Here we can see a new column \u2018comment_Length\u2019 has been added to the dataframes.\n\nNow, let's check the statistical data of the newly added column to figure out the average and max lenghth of reviews for different listings","c73c3525":"And then by storing the common stop words from nltk.corpus library","e8dbe3bc":"# Organizing the data\n\nThe first step was to load all the necessary libraries used in this notebook and the files that I used as an input. \n\nFor the purpose of this project, I used three separate csv files that contain review comments from different or same travelers for three different listings on Airbnb viz\n1. Funky Pad Suite, Portland, Oregan\n2. Venice Beach Walkstreet Getaway, Venice, California\n3. A+ Cottage & private courtyard, Nashville, Tennessee","41cabcfb":"# Data Visualization\n\nNext I did some visualization by plotting the histogram for the length column\n","76f9b5ef":"Well, all these reviews seem to be quite detailed  :)","5af09df6":"As we can see the length of the reviews varies a lot with an average og ~300 words to a max of 1598, 2617 and 2359 words for the three listings respectively. Here are the longest review for the three properties:","3271844e":"And I was able to get the most frequent terms used in the comments. Next I went ahead and started building our topic model.","d04d74a6":"I then separated all the nouns and adjectives that can be consider as a 'topic' a review is focused on by defining a function","34d6aca9":"The data contains the following columns:\n* listing_id \u2013 The unique ID provided by Airbnb to each listing\/property\n* id \u2013 ID of the unique comment row in the databasr\n* date \u2013 Date on which the review was posted\n* reviewer_id \u2013 Unique ID assigned to each guest or reviewer\n* reviewer_name \u2013 Guest\/reviewer name\n* comments \u2013 The review comment about the listing\n\nFor the scope of the analysis, I will be using only the review column, i.e. 'comments'","749ad3be":"To import the files, I first extracted the data to the working directory and then used the read_csv( ) function of pandas to read the file content into three pandas dataframes (one for each listing described in the overview).","42400308":"# Findings and conclusion \nTopic modeling using python save the labor of going through listing reviews one by one and gave me a fair idea of what people are talking about a specific listing. The results helped me to identify the keywords from the reviews that can further be analysed to assign attributes to popularity of a listing. The analysis also revealed the length of average reviews to say how much motivated guests were about their stay.\n\nThe project could be further explored for multiple properties and coming up with a set of common popular attributes and to identify the emerging trends based on the timestamp of the reviews, new and emerging topics or entities can be identified. ","8c280e7a":"# Building a topic model\nI used Latent Dirichlet Allocation (LDA) for my topic model as it's widely used to classify text in a document to a particular topic. I started by extracting the unique words in the dataframe and creating a dictionary for the corpus, where every term is assigned an index.","194caa74":"# Analysing the data\nI started by identifying the length of each comments using the apply(len) function","629a4c97":"Here I checked one of the dataframe to see available columns","58c37e7b":"From the output, we can see that the most common range of words for the reviews given by the customer is 200 \u2013 400 words for the first property but what about all three properties?","c9047c01":"Most common words are \u2018and\u2019, \u2018was\u2019, \u2018to\u2019, so on. These words are not important for my model so I have to separate from the word that matters lik 'great' 'place' 'studio' etc. \n\nI started by removing the punctuations and numbers from the text data.","3c0bb898":"I then used the fuction get_words to extract the words from the comments for listing - Funky pad suits. As the words were returned as a multiple lists, I then combined them to form a single list called 'words' ","6953745d":"The range of average words is almost similar for both the categories. Hence we can see some pattern emerging in the reviews when it comes to lenght.\n\nI will now begin to process the text further to perform my analysis. "}}