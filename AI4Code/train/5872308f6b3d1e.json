{"cell_type":{"470e3c9d":"code","a15ec0bf":"code","abbab280":"code","61ff0d15":"code","ae1fa72e":"code","86533b3d":"code","31f29391":"code","ae897b76":"code","8bffa220":"code","d0fe627b":"code","4d6a7ef4":"code","7dc1484c":"code","d9869be0":"code","e0bf271e":"code","75545201":"code","86f11804":"code","595f791f":"code","2f82f3fd":"code","6ac105a4":"code","11b007a1":"code","def169b0":"code","d3005347":"code","8c6cf932":"markdown","c58f8ec5":"markdown","e979f33c":"markdown","2d653118":"markdown","389ce2b1":"markdown","bea09285":"markdown","6faa3f12":"markdown","96ba7934":"markdown","a8a60c90":"markdown"},"source":{"470e3c9d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a15ec0bf":"data = pd.read_csv(r\"\/kaggle\/input\/bank-marketing\/bank-full.csv\")","abbab280":"data.head()","61ff0d15":"import matplotlib as plt\nax = data[\"y\"].value_counts().plot(kind=\"bar\", figsize = (6,6), fontsize = 11, color = \"orange\")\nax.set_title(\"Bank details:\",size=20, pad=5)\nax.set_ylabel(\"Categorie counts\",fontsize = 11)","ae1fa72e":"\"\"\"\nlist_of_object_variables = data.dtypes[data.dtypes==\"object\"].index.tolist()\nlist_of_object_variables\n\"\"\"","86533b3d":"\"\"\"#removing target variable from list of variables that needs to be changed\nlist_of_object_variables.remove(\"y\")\"\"\"","31f29391":"\"\"\"list_of_object_variables.remove(\"month\")\"\"\"","ae897b76":"\ndata.month = pd.to_datetime(data.month, format = \"%b\").dt.month","8bffa220":"data.head(10)","d0fe627b":"\"\"\"for col in list_of_object_variables:\n    data[col] = data[col].replace(data[col].unique().tolist(),list(range(0,data[col].nunique())))\"\"\"","4d6a7ef4":"\"\"\"data.head(10)\"\"\"","7dc1484c":"print(data.nunique(),\"\\n\\n\")\ndata.info()","d9869be0":"#list of variables with 2 categories:\nbi_list = data.nunique()[data.nunique()==2].index.tolist()\nbi_list","e0bf271e":"for col in bi_list:\n    data[col] = data[col].replace(data[col].unique().tolist(),[0,1])","75545201":"data.head(10)","86f11804":"data = pd.get_dummies(data, drop_first=True)\ndata.head(10)","595f791f":"from sklearn.preprocessing import MinMaxScaler\n\n#Scaling columns that have values greater than 1\n\nto_scale = [col for col in data.columns if data[col].max()>1]\nmms= MinMaxScaler()\nscaled = mms.fit_transform(data[to_scale])\nscaled = pd.DataFrame(scaled,columns=to_scale)\n\n#Replace the original columns with the scaled ones\nfor col in scaled:\n    data[col] = scaled[col]\n\ndata.head(10)","2f82f3fd":"data.columns","6ac105a4":"from sklearn.model_selection import train_test_split\n\nX = data.drop(\"y\", axis=1)\ny = data.y\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=42)\n\nprint(f'''% Positive class in train = {np.round(y_train.value_counts(normalize=True)[1]*100,2)}\n% Positive class in test = {np.round(y_test.value_counts(normalize=True)[1]*100,2)}''')","11b007a1":"import seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, recall_score, plot_confusion_matrix\n\n#Train\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train,y_train)\nprediction = model.predict(X_test)\n\n#Evaluating performance\nprint(f'Accuracy = {accuracy_score(y_test, prediction):.2f}\\nRecall = {recall_score(y_test, prediction):.2f}\\n')\ncm = plot_confusion_matrix(model,X_test,y_test)\n\"\"\"plt.figure(cm,size=(6,6))\nplt.title(\"CONFUSION MATRIX WITHOUT SMOTE\", size=20)\n\nsns.heatmap(cm, annot=True, cmap=\"Blues\")\n\"\"\"","def169b0":"from imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=42)\n\nX_sm, y_sm = sm.fit_resample(X,y)\n\nprint(f'''Shape of X before SMOTE: {X.shape}\nShape of X after SMOTE: {X_sm.shape}''')\n\nprint(\"\\nBalance of positive and negative classes (%):\")\ny_sm.value_counts(normalize = True) *100\n","d3005347":"X_train, X_test, y_train, y_test = train_test_split(X_sm,y_sm, test_size=0.25, random_state=42)\n#Train\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train,y_train)\nprediction = model.predict(X_test)\n\n#Evaluating performance\nprint(f'Accuracy = {accuracy_score(y_test, prediction):.2f}\\nRecall = {recall_score(y_test, prediction):.2f}\\n')\ncm = plot_confusion_matrix(model,X_test,y_test)\n\n","8c6cf932":"DATA TRANSFORMATION","c58f8ec5":"Getting dummy data","e979f33c":"DATA SCALING","2d653118":"Hence the model has high accuracy but cannot be used. \nRecall = number of True Positives\/ Total number of positives, which is 39% here.\nMeaning the classifier poorly classifies the true class.","389ce2b1":" Mapping all object variables to integer variables.","bea09285":"**MODELING WITHOUT SMOTE**","6faa3f12":"**MACHINE LEARNING WITH SMOTE**","96ba7934":"TARGET VARIABLE DISTRIBUTION","a8a60c90":"SMOTE increases the recall from 39% to 97%."}}