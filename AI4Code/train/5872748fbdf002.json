{"cell_type":{"4fb80fc6":"code","f5a6dc13":"code","6eee405d":"code","ea1bc9ef":"code","5d95888e":"code","619261de":"code","8417034a":"code","9b827336":"code","602258ac":"code","72f72430":"code","616c86ca":"code","22356956":"code","bdb25408":"code","3c0aebcd":"code","93932191":"code","60c1edda":"code","3f5dece8":"markdown","71980257":"markdown","deddf353":"markdown","5cdd8b10":"markdown","648e687c":"markdown"},"source":{"4fb80fc6":"!pip install tqdm -q","f5a6dc13":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport tensorflow as tf\nfrom tqdm.notebook import tqdm","6eee405d":"AUTO = tf.data.experimental.AUTOTUNE\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver().connect()\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    print(f\"Running on TPU {tpu.master()} with {strategy.num_replicas_in_sync} replicas\")\nexcept ValueError:\n    print(\"Not connected to a TPU runtime. Using CPU\/GPU strategy\")\n    strategy = tf.distribute.MirroredStrategy()","ea1bc9ef":"train_df = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ntest_df = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync\nSEED = 42\n\n# Hyperparameters should be the same as model in training\nIMAGE_SIZE = (300, 300)\nN_CLASSES = train_df['label_group'].nunique()\n\n# On submission, change this variable to false\nTRAIN = True\nMODEL_FILENAME = '..\/input\/models\/EfficientNetB3_300_42_m0.5_s30.h5'\n\n# Max cluster size as stated in rules\n# If statement avoids sklearn ValueError: Expected n_neighbors <= n_samples\nif TRAIN or len(test_df) > 50:\n    KNN_LIMIT = 50\nelse:\n    KNN_LIMIT = len(test_df)","5d95888e":"# Function to create dataframe for easy calculation of f1 score\ndef construct_df():\n    if TRAIN:\n        df = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\n        df['image_paths'] = '..\/input\/shopee-product-matching\/train_images\/' + df['image']\n        match_map = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n        df['matches']  = df['label_group'].map(match_map)\n        df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n    else:\n        df = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n        df['image_paths'] = '..\/input\/shopee-product-matching\/test_images\/' + df['image']\n    return df\n\n# Function to decode images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    return image\n\n# Function to read image from file\ndef read_image(image):\n    image = tf.io.read_file(image)\n    image = decode_image(image)\n    return image\n\ndef build_dataset(image_paths):\n    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset","619261de":"# Function to calculate f1 score\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection \/ (len_y_pred + len_y_true)\n    return f1\n\n#Calculate the f1 score\ndef get_score(df, predictions):\n    scores = f1_score(df['matches'], predictions)\n    return np.mean(scores)\n\n# Function to assist in submissions\ndef submit(df, predictions):\n    df['matches'] = predictions\n    df[['posting_id', 'matches']].to_csv('submission.csv', index=False)","8417034a":"class ArcMarginProduct(tf.keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https:\/\/arxiv.org\/pdf\/1801.07698.pdf\n        https:\/\/github.com\/lyakaap\/Landmark2019-1st-and-3rd-Place-Solution\/\n            blob\/master\/src\/modeling\/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(np.pi - m)\n        self.mm = tf.math.sin(np.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps \/ self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output\n    \nclass GeMPoolingLayer(tf.keras.layers.Layer):\n    '''\n    Implements Generalized-Mean Pooling layer\n    Reference:\n        https:\/\/arxiv.org\/pdf\/1711.02512.pdf\n    '''\n    def __init__(self, p=1., eps=1e-6):\n        super().__init__()\n        self.p = p\n        self.eps = eps\n\n    def call(self, inputs: tf.Tensor, **kwargs):\n        inputs = tf.clip_by_value(inputs, clip_value_min=self.eps, clip_value_max=tf.reduce_max(inputs))\n        inputs = tf.pow(inputs, self.p)\n        inputs = tf.reduce_mean(inputs, axis=[1, 2], keepdims=False)\n        inputs = tf.pow(inputs, 1. \/ self.p)\n        return inputs\n    \n    def get_config(self):\n        return {\n            'p': self.p,\n            'eps': self.eps\n        }","9b827336":"# Function to construct the model\ndef get_model(params):\n    # Do not include weights in function call; internet required\n    backbone = tf.keras.applications.EfficientNetB3(weights = None, include_top = False)\n    margin = ArcMarginProduct(\n        n_classes = N_CLASSES, \n        s = params['s'],\n        m = params['m'],\n        name='arc_margin_product', \n        dtype='float32'\n        )\n    inp = tf.keras.layers.Input(shape = IMAGE_SIZE + (3,), name = 'image')\n    label = tf.keras.layers.Input(shape = (), name = 'label')\n    x = tf.keras.applications.efficientnet.preprocess_input(inp)\n    x = backbone(x)\n    x = GeMPoolingLayer()(x)\n    x = tf.keras.layers.Dense(512, kernel_regularizer=tf.keras.regularizers.l2(), activation=None)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = margin([x, label])\n    output = tf.keras.layers.Softmax(dtype='float32')(x)\n    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n\n    return model","602258ac":"def build_models():\n    model = get_model(params)\n    model.load_weights(MODEL_FILENAME)\n    #Cut off model, ArcFace is used as loss and not for embeddings\n    image_model = tf.keras.models.Model(\n        inputs = model.input[0], \n        outputs = model.layers[-4].output\n    )\n    image_model.summary()\n    \n    text_model = TfidfVectorizer(stop_words='english', binary=True)\n    return image_model, text_model","72f72430":"def get_image_embeddings(model, dataset):\n    embeddings = []\n    image_dataset = build_dataset(df['image_paths'])\n    embeddings.append(model.predict(image_dataset))\n    return np.concatenate(embeddings)\n\ndef get_text_embeddings(model, df):\n    text_embeddings = model.fit_transform(df['title'])\n    return text_embeddings\n\ndef get_neighbors(df, image_embeddings, text_embeddings, params):\n    image_neighbors = NearestNeighbors(n_neighbors = KNN_LIMIT, metric='cosine').fit(image_embeddings)\n    image_distances, image_indices = image_neighbors.kneighbors(image_embeddings)\n    \n    text_neighbors = NearestNeighbors(n_neighbors = KNN_LIMIT, metric='cosine').fit(text_embeddings)\n    text_distances, text_indices = text_neighbors.kneighbors(text_embeddings)\n\n    predictions=[]\n    image_threshold = params['image_threshold']\n    text_threshold = params['text_threshold']\n    \n    for k in range(len(df)):\n        idx_image = np.where(image_distances[k,] < image_threshold)[0]\n        ids_image = image_indices[k, idx_image]\n        idx_text = np.where(text_distances[k,] < text_threshold)[0]\n        ids_text = text_indices[k, idx_text]\n        ids = np.union1d(ids_image, ids_text).tolist()\n        posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n        predictions.append(posting_ids)\n    return pd.Series(predictions)","616c86ca":"def predict(image_model, text_model, df, params):\n    image_embeddings = get_image_embeddings(image_model, df)\n    text_embeddings = get_text_embeddings(text_model, df)\n    predictions = get_neighbors(df, image_embeddings, text_embeddings, params)\n    return predictions","22356956":"params = {\n    'm': 0.5,\n    's': 30,\n    'image_threshold': 0.25,\n    'text_threshold': 0.37\n}","bdb25408":"#search for optimal text_embed features\nwith strategy.scope():\n    df = construct_df()\n    image_model, text_model = build_models()","3c0aebcd":"def grid_search(image_thresholds, text_thresholds):\n    grid = np.zeros( (len(image_thresholds), len(text_thresholds)) )\n    with tqdm(total=len(image_thresholds) * len(text_thresholds)) as pbar:\n        for i, image_threshold in enumerate(image_thresholds):\n            for j, text_threshold in enumerate(text_thresholds):\n                params['image_threshold'] = image_threshold\n                params['text_threshold'] = text_threshold \n                predictions = predict(image_model, text_model, df, params)\n                grid[i,j] = get_score(df, predictions)\n                pbar.update(1)\n    max_score = grid.max()\n    max_idx = np.where(grid == max_score)\n    print(f'max of f1={max_score} occurs at image_threshold={image_thresholds[max_idx[0][0]]} and at text_threshold={text_thresholds[max_idx[1][0]]}')\n    ax = sns.heatmap(grid, annot=True, fmt=\".4f\", xticklabels=text_thresholds, yticklabels=image_thresholds)\n    ax.set_xlabel('Text thresholds')\n    ax.set_ylabel('Image thresolds')\n    plt.savefig('grid_search.png')\n    plt.show()\n\nwith strategy.scope():\n    # arange() is not end-inclusive\n    image_thresholds = np.arange(0.2, 0.45, 0.05)\n    text_thresholds = np.arange(0.2, 0.45, 0.05)\n    grid_search(image_thresholds, text_thresholds)","93932191":"#Final model\nwith strategy.scope():\n    # Set to optimal values\n    params['image_threshold'] = 0.25\n    params['text_threshold'] = 0.35 \n    predictions = predict(image_model, text_model, df, params)\n    score = get_score(df, predictions)\n    print(f'Mean F1 Score: {score}')","60c1edda":"with strategy.scope():\n    # Set to optimal values\n    params['image_threshold'] = 0.25\n    params['text_threshold'] = 0.35 \n    predictions = predict(image_model, text_model, df, params)\n    submit(df, predictions)","3f5dece8":"# Shopee Product Matching - KNN Threshold Searching","71980257":"## Create evaluation tools","deddf353":"This notebook outlines the construnction of a hybrid model to determine product similary. This model consists of:\n* Image similarity - CNN model. For construction of this model, please reference [this link](https:\/\/www.kaggle.com\/sandersli\/shopee-product-matching-efficientnet-gem-arcface)\n* Title similarity - TF-IDF model","5cdd8b10":"## Construct model","648e687c":"## Fine tuning threshold"}}