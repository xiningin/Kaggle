{"cell_type":{"4d7e64ff":"code","fa57d7cc":"code","5bdffac6":"code","66d339ec":"code","89b3d8c1":"code","1d0d8b67":"code","28e06e57":"code","654de410":"code","8d6b30f5":"code","69d870d5":"code","7c11e06b":"code","62c6a91a":"code","28a583e7":"code","601ce277":"code","d23ca57a":"code","f6a7c9b9":"code","4f53133d":"code","4b6bad8f":"code","4f00f046":"code","263bbaca":"code","14f6ee7b":"code","2fc9c3c7":"code","d00e133d":"code","0ea192cc":"code","4962791f":"code","7c7bc7da":"code","84c4877d":"code","fb8e0002":"code","aebd3321":"code","eb655e81":"code","b6c953c3":"code","fda93b61":"code","b5b028f8":"code","cf995cfb":"code","b14eeba3":"code","3c7fbd34":"code","a58a202e":"code","7fad00ff":"code","914affa6":"code","f3431f62":"code","30660bd9":"markdown","72320ed8":"markdown","20222f9c":"markdown","8cac46f0":"markdown","11b56abd":"markdown","28b582b6":"markdown","44f9cdd8":"markdown","d8f1be96":"markdown","d00b9c82":"markdown","0d6b57b9":"markdown","35623ce6":"markdown","72132687":"markdown","9051a12f":"markdown","99ad51b0":"markdown","c084afb1":"markdown","d12f5006":"markdown","3a941e22":"markdown","55fa99cc":"markdown","f6338b77":"markdown","c430fcec":"markdown","1ebfd82e":"markdown","7b063867":"markdown","73cdd29e":"markdown","7caae7b3":"markdown","fea2cd19":"markdown"},"source":{"4d7e64ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt  # For plotting graphs \nfrom datetime import datetime    # To access datetime \nfrom pandas import Series        # To work on series \n%matplotlib inline \nimport warnings                   # To ignore the warnings warnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fa57d7cc":"path1 = '\/kaggle\/input\/Train.csv'\npath2 = '\/kaggle\/input\/Test.csv'","5bdffac6":"train=pd.read_csv(path1) \ntest=pd.read_csv(path2)","66d339ec":"# copy of train and test data so that even if we do changes in these dataset we do not lose the original dataset.\n\ntrain_original=train.copy() \ntest_original=test.copy()","89b3d8c1":"print(train.columns)","1d0d8b67":"print(test.columns)","28e06e57":"train.head()","654de410":"test.head()","8d6b30f5":"train.shape","69d870d5":"test.shape","7c11e06b":"train.dtypes","62c6a91a":"test.dtypes","28a583e7":"train['Datetime'] = pd.to_datetime(train.Datetime,format='%d-%m-%Y %H:%M') \ntest['Datetime'] = pd.to_datetime(test.Datetime,format='%d-%m-%Y %H:%M') \ntest_original['Datetime'] = pd.to_datetime(test_original.Datetime,format='%d-%m-%Y %H:%M') \ntrain_original['Datetime'] = pd.to_datetime(train_original.Datetime,format='%d-%m-%Y %H:%M')","601ce277":"for i in (train, test, test_original, train_original):\n    i['year']=i.Datetime.dt.year \n    i['month']=i.Datetime.dt.month \n    i['day']=i.Datetime.dt.day\n    i['Hour']=i.Datetime.dt.hour \n","d23ca57a":"train['day of week']=train['Datetime'].dt.dayofweek \ntemp = train['Datetime']","f6a7c9b9":"\n# Let\u2019s assign 1 if the day of week is a weekend and 0 if the day of week in not a weekend.\n\ndef applyer(row):\n    if row.dayofweek == 5 or row.dayofweek == 6:\n        return 1\n    else:\n        return 0 \ntemp2 = train['Datetime'].apply(applyer) \ntrain['weekend']=temp2","4f53133d":"# look at the time series.\n\ntrain.index = train['Datetime'] # indexing the Datetime to get the time period on the x-axis. \ndf=train.drop('ID',1)           # drop ID variable to get only the Datetime on x-axis. \nts = df['Count'] \nplt.figure(figsize=(16,8)) \nplt.plot(ts, label='Passenger Count') \nplt.title('Time Series') \nplt.xlabel(\"Time(year-month)\") \nplt.ylabel(\"Passenger count\") \nplt.legend(loc='best')","4b6bad8f":"# Let us try to verify our hypothesis using the actual data.\n\n# Our first hypothesis was traffic will increase as the years pass by. So let\u2019s look at yearly passenger count.\n\ntrain.groupby('year')['Count'].mean().plot.bar()","4f00f046":"# Our second hypothesis was about increase in traffic from May to October. So, let\u2019s see the relation between count and month.\n\ntrain.groupby('month')['Count'].mean().plot.bar()","263bbaca":"# Let\u2019s look at the monthly mean of each year separately.\n\ntemp=train.groupby(['year', 'month'])['Count'].mean() \ntemp.plot(figsize=(15,5), title= 'Passenger Count(Monthwise)', fontsize=14)","14f6ee7b":"# Let\u2019s look at the daily mean of passenger count.\n\ntrain.groupby('day')['Count'].mean().plot.bar()","2fc9c3c7":"\n# We also made a hypothesis that the traffic will be more during peak hours. So let\u2019s see the mean of hourly passenger count.\n\ntrain.groupby('Hour')['Count'].mean().plot.bar()","d00e133d":"# Let\u2019s try to validate our hypothesis in which we assumed that the traffic will be more on weekdays.\n\ntrain.groupby('weekend')['Count'].mean().plot.bar()","0ea192cc":"# Now we will try to look at the day wise passenger count.\n\n# Note - 0 is the starting of the week, i.e., 0 is Monday and 6 is Sunday.\n\ntrain.groupby('day of week')['Count'].mean().plot.bar()","4962791f":"train=train.drop('ID',1)","7c7bc7da":"train.Timestamp = pd.to_datetime(train.Datetime,format='%d-%m-%Y %H:%M') \ntrain.index = train.Timestamp \n# Hourly time series \nhourly = train.resample('H').mean() \n# Converting to daily mean \ndaily = train.resample('D').mean() \n# Converting to weekly mean \nweekly = train.resample('W').mean() \n# Converting to monthly mean \nmonthly = train.resample('M').mean()","84c4877d":"# Let\u2019s look at the hourly, daily, weekly and monthly time series.\n\nfig, axs = plt.subplots(4,1) \nhourly.Count.plot(figsize=(15,8), title= 'Hourly', fontsize=14, ax=axs[0]) \ndaily.Count.plot(figsize=(15,8), title= 'Daily', fontsize=14, ax=axs[1]) \nweekly.Count.plot(figsize=(15,8), title= 'Weekly', fontsize=14, ax=axs[2]) \nmonthly.Count.plot(figsize=(15,8), title= 'Monthly', fontsize=14, ax=axs[3])","fb8e0002":"test.Timestamp = pd.to_datetime(test.Datetime,format='%d-%m-%Y %H:%M') \ntest.index = test.Timestamp ","aebd3321":"# Converting to daily mean \ntest = test.resample('D').mean() ","eb655e81":"train.Timestamp = pd.to_datetime(train.Datetime,format='%d-%m-%Y %H:%M') \ntrain.index = train.Timestamp ","b6c953c3":"# Converting to daily mean \ntrain = train.resample('D').mean()","fda93b61":"Train=train.loc['2012-08-25':'2014-06-24']\nvalid=train.loc['2014-06-25':'2014-09-2']","b5b028f8":"Train.Count.plot(figsize=(15,8), title= 'Daily Ridership', fontsize=14, label='train') \nvalid.Count.plot(figsize=(15,8), title= 'Daily Ridership', fontsize=14, label='valid') \nplt.xlabel(\"Datetime\") \nplt.ylabel(\"Passenger count\") \nplt.legend(loc='best') \nplt.show()\n","cf995cfb":"Train=train.loc['2012-08-25':'2014-06-24'] \nvalid=train.loc['2014-06-25':'2014-09-25']","b14eeba3":"Train.Count.plot(figsize=(15,8), title= 'Daily Ridership', fontsize=14, label='train') \nvalid.Count.plot(figsize=(15,8), title= 'Daily Ridership', fontsize=14, label='valid') \nplt.xlabel(\"Datetime\") \nplt.ylabel(\"Passenger count\") \nplt.legend(loc='best') \nplt.show()","3c7fbd34":"dd= np.asarray(Train.Count) \ny_hat = valid.copy() \ny_hat['naive'] = dd[len(dd)-1] \nplt.figure(figsize=(12,8)) \nplt.plot(Train.index, Train['Count'], label='Train') \nplt.plot(valid.index,valid['Count'], label='Valid') \nplt.plot(y_hat.index,y_hat['naive'], label='Naive Forecast') \nplt.legend(loc='best') \nplt.title(\"Naive Forecast\") \nplt.show()","a58a202e":"y_hat_avg = valid.copy() \ny_hat_avg['moving_avg_forecast'] = Train['Count'].rolling(10).mean().iloc[-1] # average of last 10 observations. \nplt.figure(figsize=(15,5)) \nplt.plot(Train['Count'], label='Train') \nplt.plot(valid['Count'], label='Valid') \nplt.plot(y_hat_avg['moving_avg_forecast'], label='Moving Average Forecast using 10 observations') \nplt.legend(loc='best') \nplt.show() \ny_hat_avg = valid.copy() \ny_hat_avg['moving_avg_forecast'] = Train['Count'].rolling(20).mean().iloc[-1] # average of last 20 observations. \nplt.figure(figsize=(15,5)) \nplt.plot(Train['Count'], label='Train') \nplt.plot(valid['Count'], label='Valid') \nplt.plot(y_hat_avg['moving_avg_forecast'], label='Moving Average Forecast using 20 observations') \nplt.legend(loc='best') \nplt.show() \ny_hat_avg = valid.copy() \ny_hat_avg['moving_avg_forecast'] = Train['Count'].rolling(50).mean().iloc[-1] # average of last 50 observations. \nplt.figure(figsize=(15,5)) \nplt.plot(Train['Count'], label='Train') \nplt.plot(valid['Count'], label='Valid') \nplt.plot(y_hat_avg['moving_avg_forecast'], label='Moving Average Forecast using 50 observations') \nplt.legend(loc='best') \nplt.show()\n","7fad00ff":"from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt \ny_hat_avg = valid.copy() \nfit2 = SimpleExpSmoothing(np.asarray(Train['Count'])).fit(smoothing_level=0.6,optimized=False) \ny_hat_avg['SES'] = fit2.forecast(len(valid)) \nplt.figure(figsize=(16,8)) \nplt.plot(Train['Count'], label='Train') \nplt.plot(valid['Count'], label='Valid') \nplt.plot(y_hat_avg['SES'], label='SES') \nplt.legend(loc='best') \nplt.show()","914affa6":"# Lets visualize all these parts.\n\nimport statsmodels.api as sm \nsm.tsa.seasonal_decompose(Train.Count).plot() \nresult = sm.tsa.stattools.adfuller(train.Count) \nplt.show()","f3431f62":"y_hat_avg = valid.copy() \nfit1 = Holt(np.asarray(Train['Count'])).fit(smoothing_level = 0.3,smoothing_slope = 0.1) \ny_hat_avg['Holt_linear'] = fit1.forecast(len(valid)) \nplt.figure(figsize=(16,8)) \nplt.plot(Train['Count'], label='Train') \nplt.plot(valid['Count'], label='Valid') \nplt.plot(y_hat_avg['Holt_linear'], label='Holt_linear') \nplt.legend(loc='best') \nplt.show()","30660bd9":"We have 18288 different records for the Count of passengers in train set and 5112 in test set.\n\n### Let\u2019s look at the data types of each feature.","72320ed8":"We can see that the time series is becoming more and more stable when we are aggregating it on daily, weekly and monthly basis.\n\nBut it would be difficult to convert the monthly and weekly predictions to hourly predictions, as first we have to convert the monthly predictions to weekly, weekly to daily and daily to hourly predictions, which will become very expanded process. So, we will work on the daily time series.","20222f9c":"### Shape of the Datset","8cac46f0":"Here the blue part represents the train data and the orange part represents the validation data.\n\nWe will predict the traffic for the validation part and then visualize how accurate our predictions are. Finally we will make predictions for the test dataset.","11b56abd":"## Splitting the data into training and validation part","28b582b6":"Time Series is generally data which is collected over time and is dependent on it.\n\nHere we see that the count of cars is independent of time, hence it is not a time series. While the CO2 level increases with respect to time, hence it is a time series.\n\nLet us now look at the formal definition of Time Series.\n\nA series of data points collected in time order is known as a time series. Most of business houses work on time series data to analyze sales number for the next year, website traffic, count of traffic, number of calls received, etc. Data of a time series can be used for forecasting.\n\nNot every data collected with respect to time represents a time series.\n\nSome of the examples of time series are:\n- Stock Price\n- Passenger Count of an airlines \n- Temperature over time\n- Number of visitors in a hotel","44f9cdd8":"We made a hypothesis for the traffic pattern on weekday and weekend as well. So, let\u2019s make a weekend variable to visualize the impact of weekend on traffic.\n\n- We will first extract the day of week from Datetime and then based on the values we will assign whether the day is a weekend or not.\n\n- Values of 5 and 6 represents that the days are weekend.","d8f1be96":"Difference between a time series and regression problem\n\nHere you might think that as the target variable is numerical it can be predicted using regression techniques, but a time series problem is different from a regression problem in following ways:\n\n- The main difference is that a time series is time dependent. So the basic assumption of a linear regression model that the observations are independent doesn\u2019t hold in this case.\n- Along with an increasing or decreasing trend, most Time Series have some form of seasonality trends,i.e. variations specific to a particular time frame.\nSo, predicting a time series using regression techniques is not a good approach.\n\nTime series analysis comprises methods for analyzing time series data in order to extract meaningful statistics and other characteristics of the data. Time series forecasting is the use of a model to predict future values based on previously observed values.","d00b9c82":"## Happy Learning","0d6b57b9":"- ID and Count are in integer format while the Datetime is in object format for the train file.\n- Id is in integer and Datetime is in object format for test file.\n## Feature Extraction\n\nWe will extract the time and date from the Datetime. We have seen earlier that the data type of Datetime is object. So first of all we have to change the data type to datetime format otherwise we can not extract features from it.","35623ce6":"As we have seen that there is a lot of noise in the hourly time series, we will aggregate the hourly time series to daily, weekly, and monthly time series to reduce the noise and make it more stable and hence would be easier for a model to learn.","72132687":"We have ID, Datetime and corresponding count of passengers in the train file. For test file we have ID and Datetime only so we have to predict the Count for test file.\n\n### Let\u2019s understand each feature first:\n\nID is the unique number given to each observation point.\nDatetime is the time of each observation.\nCount is the passenger count corresponding to each Datetime.","9051a12f":"We are not getting much insights from day wise count of the passengers.","99ad51b0":"Here we see a decrease in the mean of passenger count in last three months. This does not look right\n\n","c084afb1":"## Exploratory Analysis","d12f5006":"We made some hypothesis for the effect of hour, day, month and year on the passenger count. So, let\u2019s extract the year, month, day and hour from the Datetime to validate our hypothesis.","3a941e22":"2. Seasonality : \n\nAnother clear pattern can also be seen in the above time series, i.e., the pattern is repeating at regular time interval which is known as the seasonality. Any predictable change or pattern in a time series that recurs or repeats over a specific time period can be said to be seasonality.","55fa99cc":"### Components of a Time Series\n1. Trend :\n\nTrend is a general direction in which something is developing or changing. So we see an increasing trend in this time series. We can see that the passenger count is increasing with the number of years.","f6338b77":"We see an exponential growth in the traffic with respect to year which validates our hypothesis.","c430fcec":"- It can be inferred that the peak traffic is at 7 PM and then we see a decreasing trend till 5 AM.\n- After that the passenger count starts increasing again and peaks again between 11AM and 12 Noon.","1ebfd82e":"- We see that the months 10, 11 and 12 are not present for the year 2014 and the mean value for these months in year 2012 is very less.\n\n- Since there is an increasing trend in our time series, the mean value for rest of the months will be more because of their larger passenger counts in year 2014 and we will get smaller value for these 3 months.\n\n- In the above line plot we can see an increasing trend in monthly passenger count and the growth is approximately exponential.","7b063867":"## Introduction to Time Series","73cdd29e":"From the above bar plot, we can infer that the passenger count is less for saturday and sunday as compared to the other days of the week. Now we will look at basic modeling techniques. Before that we will drop the ID variable as it has nothing to do with the passenger count.","7caae7b3":"It can be inferred from the above plot that the traffic is more on weekdays as compared to weekends which validates our hypothesis.","fea2cd19":"As we have validated all our hypothesis, let\u2019s go ahead and build models for Time Series Forecasting. But before we do that, we will need a dataset(validation) to check the performance and generalisation ability of our model. Below are some of the properties of the dataset required for the purpose.\n\n- The dataset should have the true values of the dependent variable against which the predictions can be checked. Therefore, test dataset cannot be used for the purpose.\n\n- The model should not be trained on the validation dataset. Hence, we cannot train the model on the train dataset and validate on it as well."}}