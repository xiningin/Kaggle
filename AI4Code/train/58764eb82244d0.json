{"cell_type":{"5269ef7d":"code","08b7777f":"code","5551897f":"code","a43442f2":"code","24596e6f":"code","44f3012f":"code","a90e214b":"code","41757f58":"code","95109107":"code","9b81fa42":"code","a827b289":"code","8921e27e":"code","68f9d7a1":"code","4a43cf75":"code","ef70c456":"code","4593f39d":"code","a06e94c2":"code","6ee3bbec":"code","2768d073":"code","892c919c":"code","6dafc8a9":"code","692bc979":"code","313c221b":"code","808c6873":"code","32b3ce4e":"code","a7d43d47":"code","5ba822ed":"code","da48f4e3":"code","5e16ec73":"code","1a83090e":"code","c57473dc":"code","64647e00":"code","021e4583":"code","b441fcb5":"code","a8fed2dc":"code","bbe38e0b":"code","877f046c":"code","9540a807":"code","294a4b94":"code","6cbbefcc":"code","d0116fbf":"code","3ac35bd2":"code","744f3168":"code","2db9d095":"code","936666bd":"code","0b540be1":"code","9b777213":"code","469461d3":"code","71d72555":"code","ea4a2b92":"code","796342fc":"code","361b3612":"markdown","b40aca4c":"markdown","617bfa98":"markdown","b992e6f3":"markdown","29a306a8":"markdown","cc438d03":"markdown","61c535a9":"markdown","b51dc4fb":"markdown"},"source":{"5269ef7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","08b7777f":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA, IncrementalPCA","5551897f":"sub = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nsub.head()","a43442f2":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain.head()","24596e6f":"test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest.head()","44f3012f":"sns.pairplot(train)","a90e214b":"train.info()","41757f58":"train = train.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)\ntest = test.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)\ntrain.head()","95109107":"train.Pclass = train.Pclass.map(lambda x: 'First' if x==1 else 'Second' if x==2 else 'Third' if x==3 else None)\ntrain.Embarked = train.Embarked.map(lambda x: 'Cherbourg' if x=='C' else 'Queenstown' if x=='Q' else 'Southampton' if x=='S' else None)\n\ntest.Pclass = test.Pclass.map(lambda x: 'First' if x==1 else 'Second' if x==2 else 'Third' if x==3 else None)\ntest.Embarked = test.Embarked.map(lambda x: 'Cherbourg' if x=='C' else 'Queenstown' if x=='Q' else 'Southampton' if x=='S' else None)\n\ntrain.head()","9b81fa42":"train.info()","a827b289":"female = train.loc[train.Sex=='female',:]\nfemale_med_age = female.Age.median()\n\nmale = train.loc[train.Sex=='male',:]\nmale_med_age = male.Age.median()\n\ntrain.loc[train.Sex=='female','Age'] = train.loc[train.Sex=='female','Age'].fillna(female_med_age)\ntrain.loc[train.Sex=='male','Age'] = train.loc[train.Sex=='male','Age'].fillna(male_med_age)","8921e27e":"female = test.loc[test.Sex=='female',:]\nfemale_med_age = female.Age.median()\n\nmale = test.loc[test.Sex=='male',:]\nmale_med_age = male.Age.median()\n\ntest.loc[test.Sex=='female','Age'] = test.loc[test.Sex=='female','Age'].fillna(female_med_age)\ntest.loc[test.Sex=='male','Age'] = test.loc[test.Sex=='male','Age'].fillna(male_med_age)","68f9d7a1":"train.info()","4a43cf75":"train.head()","ef70c456":"cat_cols = train.select_dtypes(include=['object']).columns\nnum_cols = train.select_dtypes(include=['int64','float64']).columns[1:]\ncat_cols, num_cols","4593f39d":"train[num_cols].plot(kind='box', subplots=True, layout=(2,2), figsize=(20,8))\nplt.show()","a06e94c2":"for i in num_cols:\n    Q1 = train[i].quantile(0.25)\n    Q3 = train[i].quantile(0.75)\n    IQR = Q3 - Q1\n    upper_fence = Q3 + (1.5*IQR)\n    lower_fence = Q1 - (1.5*IQR)\n    train = train[(train[i]>=lower_fence) & (train[i]<=upper_fence)]\n    \ntrain.head()","6ee3bbec":"train[num_cols].plot(kind='box', subplots=True, layout=(2,2), figsize=(20,8))\nplt.show()","2768d073":"train = train.reset_index(drop=True)\ntrain.head()","892c919c":"train.info()","6dafc8a9":"train = pd.get_dummies(data=train, columns=cat_cols, prefix=cat_cols, drop_first=True)\ntest = pd.get_dummies(data=test, columns=cat_cols, prefix=cat_cols, drop_first=True)\n\ntrain.head()","692bc979":"test.head()","313c221b":"test.info()","808c6873":"fare = test[(test.Pclass_Third==1) & (test.Sex_male==1)].Fare.median()\ntest.loc[test.Fare.isnull()] = test.loc[test.Fare.isnull()].fillna(fare)\ntest.info()","32b3ce4e":"X = train.drop('Survived', axis=1)\ny = train.Survived","a7d43d47":"pca = PCA(random_state=25)\npca_df = pca.fit_transform(X)\nv_ratio = np.cumsum(pca.explained_variance_ratio_)\nv_ratio","5ba822ed":"# Scree plot\nplt.plot(range(1,len(v_ratio)+1), v_ratio)\nplt.show()","da48f4e3":"inc_pca = IncrementalPCA(n_components=2)\npca_df = inc_pca.fit_transform(X)\npca_df = pd.DataFrame(pca_df, columns=['PC_1','PC_2'])\npca_df = pd.concat([pca_df,y], axis=1)\npca_df.head()","5e16ec73":"plt.figure(figsize=(20,8))\nsns.pairplot(data=pca_df, x_vars='PC_1', y_vars='PC_2', hue='Survived', size=10, markers='o')\nplt.show()","1a83090e":"X_train,X_test, y_train,y_test = train_test_split(X,y, train_size=0.7, random_state=100)","c57473dc":"scaler = StandardScaler()\nX_train[num_cols] = scaler.fit_transform(X_train[num_cols])\nX_test[num_cols] = scaler.transform(X_test[num_cols])\n\ntest[num_cols] = scaler.transform(test[num_cols])","64647e00":"folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=40)\nlg_reg = LogisticRegression()\ncv_score = cross_val_score(estimator=lg_reg, X=X_train, y=y_train, cv=folds, scoring='accuracy')\ncv_score.mean()","021e4583":"hyp = {'penalty':['l1', 'l2', 'elasticnet', 'none'],\n      'C':[0.00001,0.0001,0.01,0.1,0.13,0.15,0.2,0.22,0.3,0.5,0.7,0.8,0.9,1,1.2,1.3,1.5,1.6],\n      'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n      'max_iter':[100,150,200,250,300],\n      'intercept_scaling':[0.01,0.1,0.2,0.4,0.6,0.8,0.9,1,1.2,1.5,1.7,1.9,2]}\n\nrnd_lg_reg = RandomizedSearchCV(estimator=lg_reg, param_distributions=hyp, n_iter=100, n_jobs=-1, scoring='accuracy',\n                        cv=folds, verbose=3, random_state=45)\nrnd_lg_reg.fit(X_train, y_train)\n\nrnd_lg_reg.best_params_, rnd_lg_reg.best_score_","b441fcb5":"rf = RandomForestClassifier(random_state=68)\ncv_score = cross_val_score(estimator=rf, X=X_train, y=y_train, cv=folds, scoring='accuracy')\ncv_score.mean()","a8fed2dc":"hyp = {'max_depth':[2,4,6,8,10,12,15,18,20],\n      'n_estimators':[100,200,300,400,500],\n      'min_samples_split':[1,2,4,6,8,15,20,25,35,48,60],\n      'min_samples_leaf':[1,2,4,6,8,12,18,20,30,40]}\n\nrnd_rf = RandomizedSearchCV(estimator=rf, param_distributions=hyp, n_iter=100, n_jobs=-1, scoring='accuracy',\n                        cv=folds, verbose=3, random_state=45)\nrnd_rf.fit(X_train, y_train)\n\nrnd_rf.best_params_, rnd_rf.best_score_","bbe38e0b":"sv = SVC()\ncv_score = cross_val_score(estimator=sv, X=X_train, y=y_train, cv=folds, scoring='accuracy')\ncv_score.mean()","877f046c":"hyp = {'C':[0.00001,0.0001,0.01,0.1,0.13,0.15,0.2,0.22,0.3,0.5,0.7,0.8,0.9,1,1.2,1.3,1.5,1.6],\n      'gamma':[0.0000000001,0.00000001,0.00001,0.001,0.01,0.1,0.13,0.17,0.2,0.22,0.3,0.4,0.6,0.8]}\n\nrnd_sv = RandomizedSearchCV(estimator=sv, param_distributions=hyp, n_iter=100, n_jobs=-1, scoring='accuracy',\n                        cv=folds, verbose=3, random_state=45)\nrnd_sv.fit(X_train, y_train)\n\nrnd_sv.best_params_, rnd_sv.best_score_","9540a807":"gb = GradientBoostingClassifier(random_state=80)\ncv_score = cross_val_score(estimator=gb, X=X_train, y=y_train, cv=folds, scoring='accuracy')\ncv_score.mean()","294a4b94":"hyp = {'max_depth':[2,4,6,8,10,12,15,18,20],\n      'n_estimators':[100,200,300,400,500],\n      'learning_rate':[0.05,0.07,0.09,0.1,0.2,0.3,0.4,0.5],\n      'min_samples_split':[1,2,4,6,8,15,20,25,35,48,60],\n      'min_samples_leaf':[1,2,4,6,8,12,18,20,30,40]}\n\nrnd_gb = RandomizedSearchCV(estimator=gb, param_distributions=hyp, n_iter=100, n_jobs=-1, scoring='accuracy',\n                        cv=folds, verbose=3, random_state=45)\nrnd_gb.fit(X_train, y_train)\n\nrnd_gb.best_params_, rnd_gb.best_score_","6cbbefcc":"kn = KNeighborsClassifier()\ncv_score = cross_val_score(estimator=kn, X=X_train, y=y_train, cv=folds, scoring='accuracy')\ncv_score.mean()","d0116fbf":"hyp = {'n_neighbors':np.arange(1,70),\n      'metric':['minkowski','euclidean']}\n\nrnd_kn = RandomizedSearchCV(estimator=kn, param_distributions=hyp, n_iter=100, n_jobs=-1, scoring='accuracy',\n                        cv=folds, verbose=3, random_state=45)\nrnd_kn.fit(X_train, y_train)\n\nrnd_kn.best_params_, rnd_kn.best_score_","3ac35bd2":"models = []\n\nlg_reg = rnd_lg_reg.best_estimator_\nmodels.append(('lg_reg',lg_reg))\n\nrf = rnd_rf.best_estimator_\nmodels.append(('rf',rf))\n\nsv = rnd_sv.best_estimator_\nmodels.append(('sv',sv))\n\ngb = rnd_gb.best_estimator_\nmodels.append(('gb', gb))\n\nkn = rnd_kn.best_estimator_\nmodels.append(('kn', kn))\n\n\nvote = VotingClassifier(models)\ncv_score = cross_val_score(estimator=vote, X=X_train, y=y_train, cv=folds, scoring='accuracy')\ncv_score.mean()","744f3168":"sv.fit(X_train,y_train)\ny_pred = sv.predict(X_test)\nprint('Accuracy =',accuracy_score(y_test, y_pred))\nprint('Sensitivity',recall_score(y_test, y_pred))\nconf = confusion_matrix(y_test,y_pred)\nprint('Specificity=',conf[0,0]\/conf[0].sum())","2db9d095":"lg_reg.fit(X_train,y_train)\ny_pred = lg_reg.predict(X_test)\n\nprint('Accuracy =',round(100*accuracy_score(y_test, y_pred),2),'%')\nprint('Sensitivity',round(100*recall_score(y_test, y_pred),2),'%')\nconf = confusion_matrix(y_test,y_pred)\nprint('Specificity=',round(100*conf[0,0]\/conf[0].sum(),2),'%')","936666bd":"rf.fit(X_train,y_train)\ny_pred = rf.predict(X_test)\n\nprint('Accuracy =',round(100*accuracy_score(y_test, y_pred),2),'%')\nprint('Sensitivity',round(100*recall_score(y_test, y_pred),2),'%')\nconf = confusion_matrix(y_test,y_pred)\nprint('Specificity=',round(100*conf[0,0]\/conf[0].sum(),2),'%')","0b540be1":"gb.fit(X_train,y_train)\ny_pred = gb.predict(X_test)\n\nprint('Accuracy =',round(100*accuracy_score(y_test, y_pred),2),'%')\nprint('Sensitivity',round(100*recall_score(y_test, y_pred),2),'%')\nconf = confusion_matrix(y_test,y_pred)\nprint('Specificity=',round(100*conf[0,0]\/conf[0].sum(),2),'%')","9b777213":"vote = VotingClassifier(models)\nvote.fit(X_train,y_train)\ny_pred = vote.predict(X_test)\n\nprint('Accuracy =',round(100*accuracy_score(y_test, y_pred),2),'%')\nprint('Sensitivity',round(100*recall_score(y_test, y_pred),2),'%')\nconf = confusion_matrix(y_test,y_pred)\nprint('Specificity=',round(100*conf[0,0]\/conf[0].sum(),2),'%')","469461d3":"scaler2 = StandardScaler()\nX[X.columns] = scaler.fit_transform(X[X.columns])\n\ntest[test.columns] = scaler.transform(test[test.columns])","71d72555":"vote.fit(X,y)\ntest_pred = vote.predict(test)","ea4a2b92":"sub.Survived = test_pred\nsub","796342fc":"sub.to_csv('\/kaggle\/working\/submission.csv')","361b3612":"### Random Forest","b40aca4c":"### Gradient Boosting","617bfa98":"### Logistic Regression","b992e6f3":"### Support Vector Classifier","29a306a8":"### Voting Classifier","cc438d03":"## Model Building","61c535a9":"### KNeighbors Classifier","b51dc4fb":"## PCA"}}