{"cell_type":{"1240e40c":"code","91d9286d":"code","78b697b1":"code","bc91740b":"code","2b1491af":"code","502e86c5":"code","c47abf08":"code","6ec86b8b":"code","a354c1a8":"code","4e0f9096":"code","56287de2":"code","79e17369":"code","b6a9f18b":"code","1e03b83b":"code","c254b662":"code","87ac4a76":"markdown","5fe7fdc5":"markdown","cf0cabd1":"markdown","919c32f9":"markdown","d2e6fef5":"markdown","fab99ffd":"markdown","4e259ddc":"markdown","ea481a84":"markdown"},"source":{"1240e40c":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","91d9286d":"dataset = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","78b697b1":"from sklearn.preprocessing import LabelEncoder\nle= LabelEncoder()\ny= le.fit_transform(y)","bc91740b":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","2b1491af":"print(X_train)","502e86c5":"print(y_train)","c47abf08":"print(X_test)","6ec86b8b":"print(y_test)","a354c1a8":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","4e0f9096":"print(X_train)","56287de2":"print(X_test)","79e17369":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train, y_train)","b6a9f18b":"y_pred = classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","1e03b83b":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","c254b662":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))","87ac4a76":"## Training the Kernel SVM model on the Training set","5fe7fdc5":"## Splitting the dataset into the Training set and Test set","cf0cabd1":"## Importing the dataset","919c32f9":"## Predicting the Test set results","d2e6fef5":"## Importing the libraries","fab99ffd":"## Feature Scaling","4e259ddc":"# Kernel SVM","ea481a84":"## Making the Confusion Matrix"}}