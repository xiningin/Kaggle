{"cell_type":{"5031fd20":"code","13f7cedf":"code","39ec7234":"code","a60236e5":"code","34fce581":"code","8da8db60":"code","4cabc362":"code","74fc3042":"markdown"},"source":{"5031fd20":"import numpy as np\nimport pandas as pd\nimport string\nimport re\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')","13f7cedf":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\nall_Data = [train,test]\ntrain.shape, test.shape\nprint('Train Data Shape = {}'.format(train.shape))\nprint('Test Data Shape = {}'.format(test.shape))\nprint('Train Data Columns = {}'.format(train.columns))\nprint('Test Data Columns = {}'.format(test.columns))","39ec7234":"#print(test.isnull().sum())\n# Define function to extract titles from passenger names\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\ndef extract_surname(data):    \n    families = []\n    for i in range(len(data)):        \n        name = data.iloc[i]\n\n        if '(' in name:\n            name_no_bracket = name.split('(')[0] \n        else:\n            name_no_bracket = name\n            \n        family = name_no_bracket.split(',')[0]\n        title = name_no_bracket.split(',')[1].strip().split(' ')[0]\n        \n        for c in string.punctuation:\n            family = family.replace(c, '').strip()\n        families.append(family)\n    return families\n\nfor i in all_Data:\n    # Create a new feature Title, containing the titles of passenger names\n    i['Title'] = i['Name'].apply(get_title)\n    i['Title'] = i['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don','Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Others')\n    i['Title'] = i['Title'].replace('Mlle', 'Miss')\n    i['Title'] = i['Title'].replace('Ms', 'Miss')\n    i['Title'] = i['Title'].replace('Mme', 'Mrs')\n    \n    # Fix missing values in Age with Title mean\n    i.loc[(i.Age.isnull())&(i.Title=='Mr'),'Age']= i.Age[i.Title==\"Mr\"].mean()\n    i.loc[(i.Age.isnull())&(i.Title=='Mrs'),'Age']= i.Age[i.Title==\"Mrs\"].mean()\n    i.loc[(i.Age.isnull())&(i.Title=='Master'),'Age']= i.Age[i.Title==\"Master\"].mean()\n    i.loc[(i.Age.isnull())&(i.Title=='Miss'),'Age']= i.Age[i.Title==\"Miss\"].mean()\n    i.loc[(i.Age.isnull())&(i.Title=='Others'),'Age']= i.Age[i.Title==\"Others\"].mean()\n    \n    # Fix fare missing values with median\n    i['Fare'] = i['Fare'].fillna(train['Fare'].median())\n    \n    # Filling the missing values in Embarked with S\n    i['Embarked'] = i['Embarked'].fillna('S')\n    \n    # Create a new feature Deck, containing the Cabins\n    i['Deck'] = i['Cabin'].astype(str).str[0]\n    i['Deck'] = i['Deck'].replace('T','A')\n    i['Deck'] = i['Deck'].replace(['A', 'B', 'C'], 'ABC')\n    i['Deck'] = i['Deck'].replace(['D', 'E'], 'DE')\n    i['Deck'] = i['Deck'].replace(['F', 'G'], 'FG')\n    i['Deck'] = i['Deck'].replace('n', 'UN')\n    \n    # Ticket Frequency\n    i['Ticket_Frequency'] = i.groupby('Ticket')['Ticket'].transform('count')\n    \n    # Is Married\n    i['Is_Married'] = 0\n    i['Is_Married'].loc[i['Title'] == 'Mrs'] = 1\n    \n    i['Family_Size'] = i['SibSp'] + i['Parch'] + 1\n    i['Family'] = extract_surname(i['Name'])\n    \n    i['Mother'] = np.where((i.Title=='Mrs') & (i.Parch >0),1,0)\n    i['Free'] = np.where(i['Fare']==0, 1,0)","a60236e5":"# Creating a list of families and tickets that are occuring in both training and test set\nnon_unique_families = [x for x in train['Family'].unique() if x in test['Family'].unique()]\nnon_unique_tickets = [x for x in train['Ticket'].unique() if x in test['Ticket'].unique()]\n\ndf_family_survival_rate = train.groupby('Family')['Survived', 'Family','Family_Size'].median()\ndf_ticket_survival_rate = train.groupby('Ticket')['Survived', 'Ticket','Ticket_Frequency'].median()\n\nfamily_rates = {}\nticket_rates = {}\n\nfor i in range(len(df_family_survival_rate)):\n    # Checking a family exists in both training and test set, and has members more than 1\n    if df_family_survival_rate.index[i] in non_unique_families and df_family_survival_rate.iloc[i, 1] > 1:\n        family_rates[df_family_survival_rate.index[i]] = df_family_survival_rate.iloc[i, 0]\n\nfor i in range(len(df_ticket_survival_rate)):\n    # Checking a ticket exists in both training and test set, and has members more than 1\n    if df_ticket_survival_rate.index[i] in non_unique_tickets and df_ticket_survival_rate.iloc[i, 1] > 1:\n        ticket_rates[df_ticket_survival_rate.index[i]] = df_ticket_survival_rate.iloc[i, 0]\n\n        \nmean_survival_rate = np.mean(train['Survived'])\n\ntrain_family_survival_rate = []\ntrain_family_survival_rate_NA = []\ntest_family_survival_rate = []\ntest_family_survival_rate_NA = []\n\nfor i in range(len(train)):\n    if train['Family'][i] in family_rates:\n        train_family_survival_rate.append(family_rates[train['Family'][i]])\n        train_family_survival_rate_NA.append(1)\n    else:\n        train_family_survival_rate.append(mean_survival_rate)\n        train_family_survival_rate_NA.append(0)\n        \nfor i in range(len(test)):\n    if test['Family'].iloc[i] in family_rates:\n        test_family_survival_rate.append(family_rates[test['Family'].iloc[i]])\n        test_family_survival_rate_NA.append(1)\n    else:\n        test_family_survival_rate.append(mean_survival_rate)\n        test_family_survival_rate_NA.append(0)\n        \ntrain['Family_Survival_Rate'] = train_family_survival_rate\ntrain['Family_Survival_Rate_NA'] = train_family_survival_rate_NA\ntest['Family_Survival_Rate'] = test_family_survival_rate\ntest['Family_Survival_Rate_NA'] = test_family_survival_rate_NA\n\ntrain_ticket_survival_rate = []\ntrain_ticket_survival_rate_NA = []\ntest_ticket_survival_rate = []\ntest_ticket_survival_rate_NA = []\n\nfor i in range(len(train)):\n    if train['Ticket'][i] in ticket_rates:\n        train_ticket_survival_rate.append(ticket_rates[train['Ticket'][i]])\n        train_ticket_survival_rate_NA.append(1)\n    else:\n        train_ticket_survival_rate.append(mean_survival_rate)\n        train_ticket_survival_rate_NA.append(0)\n        \nfor i in range(len(test)):\n    if test['Ticket'].iloc[i] in ticket_rates:\n        test_ticket_survival_rate.append(ticket_rates[test['Ticket'].iloc[i]])\n        test_ticket_survival_rate_NA.append(1)\n    else:\n        test_ticket_survival_rate.append(mean_survival_rate)\n        test_ticket_survival_rate_NA.append(0)\n        \ntrain['Ticket_Survival_Rate'] = train_ticket_survival_rate\ntrain['Ticket_Survival_Rate_NA'] = train_ticket_survival_rate_NA\ntest['Ticket_Survival_Rate'] = test_ticket_survival_rate\ntest['Ticket_Survival_Rate_NA'] = test_ticket_survival_rate_NA\nfor df in [train, test]:\n    df['Survival_Rate'] = (df['Ticket_Survival_Rate'] + df['Family_Survival_Rate']) \/ 2\n    df['Survival_Rate_NA'] = (df['Ticket_Survival_Rate_NA'] + df['Family_Survival_Rate_NA']) \/ 2 ","34fce581":"non_numeric_features = ['Embarked', 'Sex', 'Deck', 'Title', 'Age', 'Fare']\ncat_features = ['Pclass', 'Sex', 'Deck', 'Embarked', 'Title']\nfor df in all_Data:\n    for feature in non_numeric_features:        \n        df[feature] = LabelEncoder().fit_transform(df[feature])\nencoded_features = []\n\nfor df in all_Data:\n    for feature in cat_features:\n        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n        n = df[feature].nunique()\n        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n        encoded_df.index = df.index\n        encoded_features.append(encoded_df)\n\ntrain = pd.concat([train, *encoded_features[:5]], axis=1)\ntest = pd.concat([test, *encoded_features[5:]], axis=1)\n\n\nremove_cols = ['Name','Cabin','PassengerId','Ticket','Family']\ntrain1 = train.drop(remove_cols, axis=1)\ntest1 = test.drop(remove_cols, axis=1)\n\nX = train1.drop('Survived', 1)\ny = train1['Survived']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1729)","8da8db60":"def get_Score(name, clf):\n    clf.fit(X_train, y_train)\n    score = round(clf.score(X_test, y_test) * 100, 4)\n    print('{} Classifier = {}'.format(name,score))\n    pass\n# =========================== CATBOOST ================================= #\nfrom catboost import CatBoostClassifier\ncatboost = CatBoostClassifier(verbose=False, one_hot_max_size=3, learning_rate=1,depth=2)\nget_Score(\"CATBOOST\", catboost)\n# =========================== XGBOOST ================================= #\nimport xgboost as xgb\nxgboost = xgb.XGBClassifier(n_estimators=500, nthread=-1, max_depth = 5, seed=1729)\nget_Score(\"XG BOOST\", xgboost)\n# =========================== GRADIENTBOOST ================================= #\nfrom sklearn.ensemble import GradientBoostingClassifier\ngradientboost = GradientBoostingClassifier(n_estimators=500, max_features='auto')\nget_Score(\"GRADIENT BOOST\", gradientboost)\n# =========================== KNN ================================= #\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=5)\nget_Score(\"KNN\", knn)\n# =========================== KNN ================================= #\nfrom sklearn.svm import SVC\nsvm = SVC(gamma='auto')\nget_Score(\"SVM\", svm)\n# =========================== LGBM ================================= #\nimport lightgbm as lgb\nlgbc = lgb.LGBMClassifier(\n                          n_estimators=1700,\n                          max_depth=7,\n                          min_samples_split=4,\n                          min_samples_leaf=6,\n                         )\nget_Score(\"LGBM\", lgbc)\n# =========================== GRADIENTBOOST ================================= #\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(criterion='gini',\n                                           bootstrap=True,\n                                           n_estimators=1700,\n                                           max_depth=7,\n                                           min_samples_split=4,\n                                           min_samples_leaf=6,\n                                           max_features='auto',\n                                           oob_score=True,\n                                           random_state=30,\n                                           verbose=0) \n\nget_Score(\"RANDOM FOREST\", rfc)\n\nfrom sklearn.linear_model import RidgeClassifier\nrc  =  RidgeClassifier()\nget_Score(\"Ridge \", rc)\n\nfrom sklearn.tree import DecisionTreeClassifier\ndc = DecisionTreeClassifier(random_state=390,\n                           max_features='auto',\n                           criterion='gini',\n                           max_depth=7\n                           )\nget_Score(\"DECISION TREE \", dc)\n# *************************************************************** #\n\"\"\"\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'min_samples_split': [4,5,6,7,8], \n              \n             }\n# Type of scoring used to compare parameter combinations\nacc_scorer = make_scorer(accuracy_score)\n# Run the grid search\ngrid_obj = GridSearchCV(lgbc, parameters, scoring=acc_scorer)\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nclf2 = grid_obj.best_estimator_\nprint(grid_obj.best_estimator_)\n# Fit the best algorithm to the data. \nclf2.fit(X_train, y_train)\npredictions = clf2.predict(X_test)\nprint('Grid Classifier = {}'.format((accuracy_score(y_test, predictions))* 100))\n\"\"\"\n# *************************************************************** #\n\n# =========================== VOTING CLASSIFIER ================================= #\nfrom sklearn.ensemble import VotingClassifier\nvclf = VotingClassifier(estimators=[('random forest', rfc), ('XG Boost', xgboost),('catboost',catboost)],weights=[3,1,1])\nget_Score(\"VOTING CLASSIFIER \", vclf)\ngradientboost.fit(X_train, y_train)\npred = gradientboost.predict(test1)","4cabc362":"submission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"],\n                           \"Survived\": pred\n                         })\nsubmission.to_csv('submission36.csv', index=False)","74fc3042":"> FEATURE ENGINEERING"}}