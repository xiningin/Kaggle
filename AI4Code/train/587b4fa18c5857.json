{"cell_type":{"31fcc3ea":"code","81748bf8":"code","48c5e2df":"code","4286307c":"code","a9ac8c48":"code","31e01a5e":"code","269041fa":"code","b287b279":"code","e03b6612":"code","3a154e5d":"code","042b3120":"code","f875011d":"code","79f2147a":"code","8f6fa683":"code","3ca798e0":"code","67ab3ef0":"code","4ba08ab8":"code","16cd5b8a":"code","fb1b22a0":"code","763f7c09":"code","6ca351dc":"code","901b6bc9":"markdown","46e02624":"markdown","2723bbf3":"markdown","ba177aba":"markdown","7a775684":"markdown"},"source":{"31fcc3ea":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","81748bf8":"data = pd.read_excel('..\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')\n\n#preparing to be easier later\ndata['NEW ICU'] = 0\n\ndata","48c5e2df":"\n#same code from the https:\/\/www.kaggle.com\/felipeveiga\/starter-covid-19-sirio-libanes-icu-admission\n\ncomorb_lst = [i for i in data.columns if \"DISEASE\" in i]\ncomorb_lst.extend([\"HTN\", \"IMMUNOCOMPROMISED\", \"OTHER\"])\n\ndemo_lst = [i for i in data.columns if \"AGE_\" in i]\ndemo_lst.append(\"GENDER\")\n\nvitalSigns_lst = data.iloc[:,193:-2].columns.tolist()\n\nlab_lst = data.iloc[:,13:193].columns.tolist()","4286307c":"#dataframe where each patient is a row\ndata_groupby = data.groupby(\"PATIENT_VISIT_IDENTIFIER\", as_index = False).agg({\"ICU\":(list), \"WINDOW\":list, 'NEW ICU':(list)})","a9ac8c48":"#so we need to create this new dataset\n\ndata_groupby['USEFUL WINDOWS'] = 99\n\ndata_groupby['NEW ICU'] = 0\n\ndata_groupby\n","31e01a5e":"\n#for each row of the dataset\nfor index1, row in data_groupby.iterrows():\n\n  #count = 0 means that we did not encounter 1\n  count= 0\n\n  #for each element of the ICU list of that row\n  for i in range(len(data_groupby['ICU'][index1])):\n\n    #it means it is our first 1. If is the first element, we dont want it\n    if count == 0 and data_groupby['ICU'][index1][i] == 1 and i ==0:\n\n      data_groupby['USEFUL WINDOWS'][index1] = int(-99)\n\n    #it is our first one and we want the previous value\n    if count == 0 and data_groupby['ICU'][index1][i] == 1 and i !=0:\n\n      data_groupby['USEFUL WINDOWS'][index1] = int(i - 1)\n\n      data_groupby['NEW ICU'][index1] = 1\n\n    #count gett updated\n    if data_groupby['ICU'][index1][i] == 1:\n\n      count =+ 1\n","269041fa":"data_groupby.head(20)","b287b279":"#creating the new dataframe\ndf = pd.DataFrame(columns=data.columns)\n\nlst_new_icu = []\n#for each row in our groupby dataset\nfor index1, row in data_groupby.iterrows():\n\n    #list where we are going to put the index that we want we have to see if we need to change ICU target or not\n    lst_row_number = []\n\n    #if -99, we ignore\n    if data_groupby['USEFUL WINDOWS'][index1] == -99:\n      pass\n\n    #if 99, we want all rows of that patient\n    if data_groupby['USEFUL WINDOWS'][index1] == 99:\n\n      lst_row_number = [index1*5, (index1*5) + 1, (index1*5) + 2, (index1*5) + 3, (index1*5) + 4]\n      lst_new_icu.append(0)\n      lst_new_icu.append(0)\n      lst_new_icu.append(0)\n      lst_new_icu.append(0)\n      lst_new_icu.append(0)\n\n    if data_groupby['USEFUL WINDOWS'][index1] > -1 and data_groupby['USEFUL WINDOWS'][index1] < 6:\n      #we only want the row before the first 1\n      lst_row_number = [(index1*5) + (data_groupby['USEFUL WINDOWS'][index1])]\n      lst_new_icu.append(1)\n\n\n    if len(lst_row_number) > 0:\n\n      for i in range(len(lst_row_number)):\n\n        df = df.append(data.iloc[int(lst_row_number[i])], ignore_index=False, verify_integrity=False, sort=None)","e03b6612":"df['NEW ICU 2'] = lst_new_icu","3a154e5d":"df.head(20)","042b3120":"#removing column window and using one hot enconding\ndf = df.drop(['WINDOW', 'PATIENT_VISIT_IDENTIFIER'], axis = 1)","f875011d":"df = pd.get_dummies(df, drop_first=True)\n\ndf.rename(columns={'NEW ICU 2': 'ICU'}, inplace=True)","79f2147a":"df","8f6fa683":"#target class\nsns.countplot('ICU', data=df, palette = 'GnBu')\nplt.title('Does not need ICU vs Needs ICU', fontsize=14);","3ca798e0":"#we changed the names, so we have to create the list again\ndemo_lst = ['GENDER_1', 'AGE_ABOVE65_1', 'AGE_PERCENTIL_20th', 'AGE_PERCENTIL_30th', 'AGE_PERCENTIL_40th', 'AGE_PERCENTIL_50th', 'AGE_PERCENTIL_60th', 'AGE_PERCENTIL_70th', 'AGE_PERCENTIL_80th', 'AGE_PERCENTIL_90th', 'AGE_PERCENTIL_Above 90th' ]\n\n#we do not have the column window anymore\nvitalSigns_lst = vitalSigns_lst[:-1]\n\n#using demographics + comorbities\nX = df[comorb_lst + demo_lst]\n\ny = df['ICU']","67ab3ef0":"#xgboost with hyperopt\nimport xgboost as xgb\nimport numpy as np\nfrom hyperopt import hp, fmin, tpe, STATUS_OK, Trials\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score, f1_score, recall_score\n\ndata_dmatrix = xgb.DMatrix(data=X,label=y)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=2)\n","4ba08ab8":"y_test.value_counts()","16cd5b8a":"y_train.value_counts()","fb1b22a0":"\ndef objective(space):\n    print(space)\n    clf = xgb.XGBRegressor(n_estimators =int(space['n_estimators']),\n                           n_fold = 3,\n                           num_parallel_tree = int(space['num_parallel_tree']),\n                           colsample_bytree=space['colsample_bytree'],\n                           learning_rate = space['learning_rate'],\n                           max_depth = int(space['max_depth']),\n                           min_child_weight = int(space['min_child_weight']),\n                           subsample = space['subsample'],\n                           gamma = space['gamma'],\n                           reg_alpha = space['reg_alpha'],\n                           reg_lambda = space['reg_lambda'],\n                           scale_pos_weight = space['scale_pos_weight'],\n                           objective = 'binary:logistic')\n\n    eval_set  = [( X_train, y_train), ( X_test, y_test)]\n\n    clf.fit(X_train, y_train,\n            eval_set=eval_set,\n            early_stopping_rounds=10,verbose=False)\n\n    pred = clf.predict(X_test)\n\n    \n    for i in range(len(pred)):\n\n      if pred[i] >= 0.5:\n\n        pred[i] = 1\n\n      else:\n\n        pred[i] = 0\n    \n\n\n    #score = roc_auc_score(y_test, pred)\n    #score = f1_score(y_test, pred)\n    score = recall_score(y_test, pred)\n    #score = accuracy_score(y_test, pred)\n    print (\"SCORE:\", score)\n    return {'loss':1 - score, 'status': STATUS_OK }\n\n\nspace ={'max_depth': hp.uniform(\"x_max_depth\", 1, 10),\n        'min_child_weight': hp.uniform ('x_min_child', 1, 10),\n        'subsample': hp.uniform ('x_subsample', 0.5, 1),\n        'gamma' : hp.uniform ('x_gamma', 0.1, 1.0),\n        'colsample_bytree' : hp.uniform ('x_colsample_bytree', 0.1 ,1),\n        'reg_alpha' : hp.uniform('x_reg_alpha', 5, 7),\n        'n_estimators' :hp.uniform('x_n_estimators', 100, 500),\n        'learning_rate' :hp.uniform('x_learning_rate', 0.01 , 0.05),\n        'scale_pos_weight' :hp.uniform('x_scale_pos_weight', 4.5, 6.5),\n        'reg_lambda' : hp.uniform ('x_reg_lambda',1, 1.1),\n        'num_parallel_tree' :hp.uniform('x_num_parallel_tree', 100, 200)\n    }\n\n\ntrials = Trials()\n\nbest = fmin(fn=objective,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=200,\n            trials=trials)\n\nprint(best)","763f7c09":"import matplotlib.pyplot as plt\n\nxg_reg = xgb.XGBRegressor(n_estimators = int(best['x_n_estimators']),\n                          n_fold = 3,\n                          num_parallel_tree = int(best['x_num_parallel_tree']),\n                          colsample_bytree=best['x_colsample_bytree'],\n                          learning_rate = best['x_learning_rate'],\n                          max_depth = int(best['x_max_depth']),\n                          min_child_weight = int(best['x_min_child']),\n                          subsample = best['x_subsample'],\n                          gamma = best['x_gamma'],\n                          reg_alpha = best['x_reg_alpha'],\n                          reg_lambda = best['x_reg_lambda'],\n                          scale_pos_weight = best['x_scale_pos_weight'],\n                          objective = 'binary:logistic')\n\n\nxg_reg.fit(X_train,y_train)\n\npreds = xg_reg.predict(X_test)\n\n\n\nfor i in range(len(preds)):\n\n  if preds[i] >= 0.5:\n\n    preds[i] = round(1)\n\n  else:\n\n    preds[i] = round(0)\n\n\nlst_y_test = []\n\nfor i in range(len(y_test)):\n\n  lst_y_test.append(y_test.iloc[i])\n\nlst_y_test\n\n\nxgb.plot_importance(xg_reg)\n\n\nplt.rcParams['figure.figsize'] = [5, 5]\nplt.show()\n\n","6ca351dc":"from sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn import metrics\n\nconf_matrix = confusion_matrix(lst_y_test, preds)\n\n#tn, fp, fn, tp = conf_matrix.ravel()\n\ntp = conf_matrix[0,0]\nfp = conf_matrix[1,0]\ntn = conf_matrix[1,1]\nfn = conf_matrix[0,1]\n\n\nprint('True Positives = ', tp)\nprint('True Negatives = ', tn)\nprint('False Positives = ', fp)\nprint('False Negatives = ', fn)\n\nprint(\"correct ICU predictions = %.2f%%\" % (100*tn\/(tn + fp)))\n\nprint(\"correct no ICU predictions = %.2f%%\" % (100*tp\/(tp + fn)))\n\nplt.subplots(figsize=(8,8))\nax= plt.subplot()\nsns.heatmap(conf_matrix, annot=True, ax = ax);\n\nax.set_xlabel('Prediction');ax.set_ylabel('Label'); \nax.set_title('Confusion matrix xgboost'); \nax.xaxis.set_ticklabels(['No ICU', 'ICU']); ax.yaxis.set_ticklabels(['No ICU', 'ICU']);\n\n\nprint(\"Accuracy: %.2f\" % metrics.accuracy_score(y_test, preds))\nprint(\"Precision: %.2f\" % metrics.precision_score(y_test, preds))\nprint(\"Recall: %.2f\" % metrics.recall_score(y_test, preds))\nprint(\"f1_score: %.2f\" % metrics.f1_score(y_test, preds))","901b6bc9":"This is our first try using the XGBoost model with Bayesian Optimization tuning of the hyperparameters.\n\nOur first try is to use only the Demographics and Comorbities data.\n\nFor patients that were not in the ICU, we are using all windows.\n\nFor patients that were in the ICU, we are using the window immediately before the incident.\n\nIf the patient was already in the ICU in his first window, we cannot use the data because we do not know if the exams results were obtained before the incident.\n\nIn that way we have a very unbalanced dataset\n\nWarning: We think that all other notebooks so far are not using the data properly, this is why the metrics here are lower.","46e02624":"Meaning:\n\n99 = we can use all windows\n\n-99 = we cannot use any window\n\n2 = we need to pick the row of index 2 related with that patient, it means the third row of that patient","2723bbf3":"Conclusion: With Demographics and Comorbities we can go from around 20% (random guess based on the distribution) to <b> 58% Recall <\/b> of ICU cases predicted.\n\nOur next step is to do an ensemble of other models such as catboost, lightgbm, etc\n\nAny feedback is welcomed!","ba177aba":"If ICU is a list of all zeros, it means the patient does not need ICU and we can use every window as a row of our dataset. If those rows are similar, we can keep one or we will have to deal with this later on. Target will be 0\n\nIf ICU gets 1 somewhere, we need to get the last non 0 and it will be our row. Target will be 1\n\nIf ICU already starts with 1, we cannot do anything with the data.\n\nThis was based in the following tip: Beware NOT to use the data when the target variable is present, as it is unknown the order of the event (maybe the target event happened before the results were obtained). They were kept there so we can grow this dataset in other outcomes latter on.","7a775684":"Now that we already have the real dataset, we can start build our model\n"}}