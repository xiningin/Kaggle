{"cell_type":{"17abdbe1":"code","9cfb500f":"code","71fc6015":"code","a4fed9c8":"code","908c7e8c":"code","d3ad323b":"code","448308c6":"code","77f1fbeb":"code","502d7d01":"code","5473f50e":"code","003fd3ab":"code","c87d2a33":"code","8d97db76":"code","4dda53a7":"code","3e2485b8":"code","28be16e8":"code","3f0a8ea4":"code","470cbf14":"code","cfb27586":"code","d0d55518":"code","e323c6ca":"code","03028c5f":"code","0cea76bb":"code","b05ad565":"code","43b5d92d":"code","4c3f0daf":"code","1240d4e5":"code","82bc3a95":"code","74034140":"code","81fb9c33":"code","0e1a2f07":"code","c014103c":"code","756047f3":"code","411d791a":"code","ad73f07c":"code","27365aba":"code","2670c63d":"code","c5fcb9a1":"code","27384f7b":"code","f6d004b3":"code","fe998c46":"code","2f73485b":"code","1c61e7fc":"code","ce20f3b4":"code","b171e33e":"code","6b18b0a6":"code","8eb83588":"code","7df52cad":"code","55be5e28":"code","a96dbeef":"code","57a654eb":"code","43653c09":"code","3e96b41a":"code","3eb91905":"code","daf8c0b3":"code","c0d8e8a8":"code","390f0851":"code","0f13d8f3":"markdown","94ab6f16":"markdown","8551146f":"markdown","a766f7a1":"markdown","01b7930d":"markdown","fa8a731b":"markdown","f519e0c9":"markdown","2f57ce71":"markdown","6db051dd":"markdown","0a9e1bf0":"markdown","a7629273":"markdown","c72a1aaf":"markdown","5019f0c7":"markdown","6b937a91":"markdown","b226aa6e":"markdown","20b68975":"markdown","fe992271":"markdown","1174fadc":"markdown","5b4fbf7f":"markdown","99acc17c":"markdown","e8ccc268":"markdown","d82c5f98":"markdown","66d2da8b":"markdown","79befea4":"markdown","030971ba":"markdown","dda82e1f":"markdown","b0c64ded":"markdown","7856a699":"markdown","6a8c4302":"markdown","948398cd":"markdown","688c7402":"markdown","6fcb3c93":"markdown","c8d8972d":"markdown","eb1211d7":"markdown","cd4fbbc7":"markdown","61a8c745":"markdown"},"source":{"17abdbe1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9cfb500f":"train=pd.read_csv('\/kaggle\/input\/avhealthcare\/Train.csv')\npatient=pd.read_csv('\/kaggle\/input\/avhealthcare\/Patient_Profile.csv')\ncamp=pd.read_csv('\/kaggle\/input\/avhealthcare\/Health_Camp_Detail.csv')\nFHC=pd.read_csv('\/kaggle\/input\/avhealthcare\/First_Health_Camp_Attended.csv')\nSHC=pd.read_csv('\/kaggle\/input\/avhealthcare\/Second_Health_Camp_Attended.csv')\nTHC=pd.read_csv('\/kaggle\/input\/avhealthcare\/Third_Health_Camp_Attended.csv')\nFHC=FHC.iloc[:, :-1]\nSHC.info()","71fc6015":"train1=pd.merge(train,patient, on='Patient_ID', how='left')\ntrain12=pd.merge(train1,camp, on='Health_Camp_ID',how='left')\ntrain123=pd.merge(train12,FHC, on=['Patient_ID','Health_Camp_ID'], how='left')\ntrain1234=pd.merge(train123,SHC, on=['Patient_ID','Health_Camp_ID'], how='left')\ntrain12345=pd.merge(train1234,THC, on=['Patient_ID','Health_Camp_ID'], how='left')","a4fed9c8":"train12345","908c7e8c":"train12345['Outcome'] = train12345.apply(lambda x: 1 if (x['Health_Score'] > 0 \n                                                                 or x['Health Score'] > 0 \n                                                                 or x['Number_of_stall_visited'] > 0) \n                                                     else 0,axis=1)","d3ad323b":"train12345['Outcome'].value_counts()","448308c6":"train12345.isnull().sum()","77f1fbeb":"train12345.Income.value_counts()","502d7d01":"train12345['Income'] = train12345['Income'].replace('None', np.nan)\ntrain12345['Income'].fillna(train12345['Income'].mode()[0], inplace=True)\ntrain12345['Education_Score'] = train12345['Education_Score'].replace('None', np.nan)\ntrain12345['Education_Score'].fillna(train12345['Education_Score'].mode()[0], inplace=True)\ntrain12345['Age'] = train12345['Age'].replace('None', np.nan)\ntrain12345['Age'].fillna(train12345['Age'].mode()[0], inplace=True)\ntrain12345['Registration_Date'].fillna(train12345['Registration_Date'].mode()[0], inplace=True)","5473f50e":"train12345['Income'] = train12345['Income'].astype(\"int16\")\ntrain12345['Education_Score'] = train12345['Education_Score'].astype(\"float64\")\ntrain12345['Age'] = train12345['Age'].astype(\"int16\")\n","003fd3ab":"train12345['City_Type'] = train12345['City_Type'].fillna('Unknown')\ntrain12345['Employer_Category'] = train12345['Employer_Category'].fillna('Unknown')","c87d2a33":"catcols = ['Online_Follower', 'LinkedIn_Shared', 'Twitter_Shared', 'Facebook_Shared', 'Category1', 'Category2', 'Category3', 'City_Type', 'Employer_Category']\nfor col in catcols:\n    train12345[col] = train12345[col].astype('category')\n    train12345[col] = train12345[col].cat.codes.astype(\"int16\")","8d97db76":"train12345=train12345.drop(['Patient_ID', 'Health_Camp_ID', 'Donation', 'Health_Score', 'Health Score', 'Number_of_stall_visited', 'Last_Stall_Visited_Number'],axis=1)","4dda53a7":"train12345['Registration_Date']=pd.to_datetime(train12345['Registration_Date'],dayfirst=True)\ntrain12345['First_Interaction']=pd.to_datetime(train12345['First_Interaction'],dayfirst=True)\ntrain12345['Camp_Start_Date']=pd.to_datetime(train12345['Camp_Start_Date'],dayfirst=True)\ntrain12345['Camp_End_Date']=pd.to_datetime(train12345['Camp_End_Date'],dayfirst=True)\ntrain12345['Campduration']=(train12345['Camp_End_Date']-train12345['Camp_Start_Date']).dt.days\ntrain12345['registrationgapwithcampstart']=(train12345['Registration_Date']-train12345['Camp_Start_Date']).dt.days\ntrain12345['registrationgapwithcampend']=(train12345['Camp_End_Date']-train12345['Registration_Date']).dt.days \ntrain12345['interactiongapwithcampstart']=(train12345['First_Interaction']-train12345['Camp_Start_Date']).dt.days\ntrain12345['interactiongapwithcampend']=(train12345['Camp_End_Date']-train12345['First_Interaction']).dt.days\ntrain12345['interactiongapwithregistration']=(train12345['Registration_Date']-train12345['First_Interaction']).dt.days","3e2485b8":"train12345.columns","28be16e8":"train12345['Regquarter'] = train12345['Registration_Date'].dt.quarter\ntrain12345['Regyear'] = train12345['Registration_Date'].dt.year\ntrain12345['Regmonth'] = train12345['Registration_Date'].dt.month\ntrain12345['Regdate'] = train12345['Registration_Date'].dt.day\ntrain12345['Regweek_day'] = train12345['Registration_Date'].dt.dayofweek\ntrain12345['Intgquarter'] = train12345['First_Interaction'].dt.quarter\ntrain12345['Intyear'] = train12345['First_Interaction'].dt.year\ntrain12345['Intgmonth'] = train12345['First_Interaction'].dt.month\ntrain12345['Intdate'] = train12345['First_Interaction'].dt.day\ntrain12345['Intweek_day'] = train12345['First_Interaction'].dt.dayofweek\ntrain12345['Campstquarter'] = train12345['Camp_Start_Date'].dt.quarter\ntrain12345['Campstyear'] = train12345['Camp_Start_Date'].dt.year\ntrain12345['Campstgmonth'] = train12345['Camp_Start_Date'].dt.month\ntrain12345['Campstdate'] = train12345['Camp_Start_Date'].dt.day\ntrain12345['Campstweek_day'] = train12345['Camp_Start_Date'].dt.dayofweek\ntrain12345['Campendquarter'] = train12345['Camp_End_Date'].dt.quarter\ntrain12345['Campendyear'] = train12345['Camp_End_Date'].dt.year\ntrain12345['Campendgmonth'] = train12345['Camp_End_Date'].dt.month\ntrain12345['Campenddate'] = train12345['Camp_End_Date'].dt.day\ntrain12345['Campendweek_day'] = train12345['Camp_End_Date'].dt.dayofweek","3f0a8ea4":"train12345=train12345.drop(['Registration_Date','First_Interaction','Camp_Start_Date','Camp_End_Date'], axis=1)","470cbf14":"train12345.isnull().sum()","cfb27586":"train12345.isnull().info()","d0d55518":"X= train12345.drop(['Outcome'],axis=1)\ny= train12345['Outcome']","e323c6ca":"from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, RepeatedStratifiedKFold, cross_val_score, RandomizedSearchCV, GridSearchCV\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)","03028c5f":"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom sklearn.preprocessing import *\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\nimport gc\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, mean_absolute_error,accuracy_score, classification_report\nkfold = KFold(n_splits=10, random_state=7)\n#rf = RandomForestRegressor(n_estimators = 200)\n#rf.fit(X_train, y_train,eval_metric = 'auc', early_stopping_rounds = 100)\n#RF=rf.fit(X_train, y_train)\n\nnum_trees = 200\nmax_features = 3\nmodelRF = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\nresultsRF = cross_val_score(modelRF,X_train, y_train,cv=kfold)\nprint(\"Random Forest\",resultsRF.mean()*100)","0cea76bb":"RF=modelRF.fit(X_train, y_train)","b05ad565":"y_pred_randomforest= RF.predict(X_train)\nprint(100*np.sqrt(mean_squared_log_error(y_train, y_pred_randomforest)))\n","43b5d92d":"y_pred_randomforest= RF.predict(X_test)\nprint(100*np.sqrt(mean_squared_log_error(y_test, y_pred_randomforest)))\n\n#print('RMSLE score is', 100*(np.sqrt(np.mean(np.power(np.log1p(y_test)-np.log1p(test_pred), 2)))))\nresultsRF_test = cross_val_score(modelRF,X_test, y_test,cv=kfold)\nprint(\"Random Forest\",resultsRF_test.mean()*100)","4c3f0daf":"sorted(zip(RF.feature_importances_, X_train), reverse = True)","1240d4e5":"predict_Prob_RF=RF.predict_proba(X_train)[:,1]\npredict_Prob_RF","82bc3a95":"from lightgbm import LGBMRegressor\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_log_error\n#rmsle = 0\n#for i in ratio:\n#  x_train,y_train,x_val,y_val = train_test_split(i)\n#lgbc=LGBMRegressor(boosting_type='gbdt',n_estimators=800, learning_rate=0.12,objective= 'regression',n_jobs=-1,random_state=100)\n#LGB=lgbc.fit(X_train,y_train)\n\nlgbc = LGBMClassifier(n_estimators=550,\n                     learning_rate=0.03,\n                     min_child_samples=40,\n                     random_state=1,\n                     colsample_bytree=0.5,\n                     reg_alpha=2,\n                     reg_lambda=2)\n\nresultsLGB = cross_val_score(lgbc,X_train, y_train,cv=kfold)\nprint(\"LightGBM\",resultsLGB.mean()*100)\n","74034140":"LGB=lgbc.fit(X_train,y_train)","81fb9c33":"y_predict_LGBM = LGB.predict(X_train)\nprint(100*(np.sqrt(mean_squared_log_error(np.exp(y_train), np.exp(y_predict_LGBM)))))","0e1a2f07":"y_predict_LGBM = LGB.predict(X_test)\nprint(100*(np.sqrt(mean_squared_log_error(np.exp(y_test), np.exp(y_predict_LGBM)))))\nresultsLGB_test = cross_val_score(lgbc,X_test, y_test,cv=kfold)\nprint(\"LightGBM\",resultsLGB_test.mean()*100)","c014103c":"sorted(zip(LGB.feature_importances_, X_train), reverse = True)","756047f3":"predict_Prob_LGBM=LGB.predict_proba(X_train)[:,1]\npredict_Prob_LGBM","411d791a":"from catboost import CatBoostRegressor \nfrom catboost import  CatBoostClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import roc_auc_score\n\n#cb = CatBoostRegressor(\n    #n_estimators = 1000,\n    #learning_rate = 0.11,\n    #iterations=1000,\n    #loss_function = 'RMSE',\n    #eval_metric = 'RMSE',\n    #verbose=0)\n    \ncb= CatBoostClassifier(\n    iterations=100, \n    learning_rate=0.1, \n    #loss_function='CrossEntropy'\n)\n\n#rmsle = 0\n#for i in ratio:\n # x_train,y_train,x_val,y_val = train_test_split(i)\n\n#CAT=cb.fit(X_train,y_train)\n#resultsCAT = cross_val_score(cb,X_train, y_train,cv=kfold)\n#print(\"CAT\",resultsCAT.mean()*100)\n                        \ncb.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=50,early_stopping_rounds = 100)","ad73f07c":"resultsCAT = cross_val_score(cb,X_train, y_train,cv=kfold)\nprint(\"CAT\",resultsCAT.mean()*100)","27365aba":"y_predict_CAT = cb.predict(X_train)\nprint(100*(np.sqrt(mean_squared_log_error(np.exp(y_train), np.exp(y_predict_CAT)))))\nresultsCAT_train = cross_val_score(cb,X_train, y_train,cv=kfold)\nprint(\"CAT\",resultsCAT_train.mean()*100)","2670c63d":"y_predict_CAT = cb.predict(X_test)\nprint(100*(np.sqrt(mean_squared_log_error(np.exp(y_test), np.exp(y_predict_CAT)))))\nresultsCAT_test = cross_val_score(cb,X_test, y_test,cv=kfold)\nprint(\"CAT\",resultsCAT_test.mean()*100)","c5fcb9a1":"sorted(zip(cb.feature_importances_, X_train), reverse = True)","27384f7b":"predict_Prob_CAT=cb.predict_proba(X_train)[:,1]\npredict_Prob_CAT","f6d004b3":"test=pd.read_csv('\/kaggle\/input\/avhealthcare1\/test_l0Auv8Q.csv') \ntest.columns\ntest.info()","fe998c46":"test1=pd.merge(test,patient, on='Patient_ID', how='left')\ntest12=pd.merge(test1,camp, on='Health_Camp_ID',how='left')\ntest123=pd.merge(test12,FHC, on=['Patient_ID','Health_Camp_ID'], how='left')\ntest1234=pd.merge(test123,SHC, on=['Patient_ID','Health_Camp_ID'], how='left')\ntest12345=pd.merge(test1234,THC, on=['Patient_ID','Health_Camp_ID'], how='left')","2f73485b":"test12345.isnull().sum()","1c61e7fc":"test12345['Income']=test12345['Income'].replace('None',np.nan)\ntest12345['Income'].fillna(test12345['Income'].mode()[0],inplace=True)\ntest12345['Education_Score']=test12345['Education_Score'].replace('None',np.nan)\ntest12345['Education_Score'].fillna(test12345['Education_Score'].mode()[0],inplace=True)\ntest12345['Age']=test12345['Age'].replace('None',np.nan)\ntest12345['Age'].fillna(test12345['Age'].mode()[0],inplace=True)\n\ntest12345['Income'] = test12345['Income'].astype(\"int16\")\ntest12345['Education_Score'] = test12345['Education_Score'].astype(\"float64\")\ntest12345['Age'] = test12345['Age'].astype(\"int16\")\n","ce20f3b4":"test12345.info()","b171e33e":"test12345['City_Type'].fillna(test12345['City_Type'].mode()[0],inplace=True)\ntest12345","6b18b0a6":"ForSubmission=test12345\ntest12345=test12345.drop(['Patient_ID', 'Health_Camp_ID', 'Donation', 'Health_Score', 'Health Score', 'Number_of_stall_visited', 'Last_Stall_Visited_Number'],axis=1)","8eb83588":"test12345","7df52cad":"test12345['City_Type'] = test12345['City_Type'].fillna('Unknown')\ntest12345['Employer_Category'] = test12345['Employer_Category'].fillna('Unknown')\ntest12345","55be5e28":"catcols = ['Online_Follower', 'LinkedIn_Shared', 'Twitter_Shared', 'Facebook_Shared', 'Category1', 'Category2', 'Category3', 'City_Type', 'Employer_Category']\nfor col in catcols:\n    test12345[col] = test12345[col].astype('category')\n    test12345[col] = test12345[col].cat.codes.astype(\"int16\")","a96dbeef":"test12345","57a654eb":"test12345['Registration_Date']=pd.to_datetime(test12345['Registration_Date'],dayfirst=True)\ntest12345['First_Interaction']=pd.to_datetime(test12345['First_Interaction'],dayfirst=True)\ntest12345['Camp_Start_Date']=pd.to_datetime(test12345['Camp_Start_Date'],dayfirst=True)\ntest12345['Camp_End_Date']=pd.to_datetime(test12345['Camp_End_Date'],dayfirst=True)\ntest12345['Registration_Date'].fillna(test12345['Registration_Date'].mode()[0], inplace=True)\ntest12345['Campduration']=(test12345['Camp_End_Date']-test12345['Camp_Start_Date']).dt.days\ntest12345['registrationgapwithcampstart']=(test12345['Registration_Date']-test12345['Camp_Start_Date']).dt.days\ntest12345['registrationgapwithcampend']=(test12345['Camp_End_Date']-test12345['Registration_Date']).dt.days \n\ntest12345['interactiongapwithcampstart']=(test12345['First_Interaction']-test12345['Camp_Start_Date']).dt.days\ntest12345['interactiongapwithcampend']=(test12345['Camp_End_Date']-test12345['First_Interaction']).dt.days\n\n\ntest12345['interactiongapwithregistration']=(test12345['Registration_Date']-test12345['First_Interaction']).dt.days\n\ntest12345['Regquarter'] = test12345['Registration_Date'].dt.quarter\ntest12345['Regyear'] = test12345['Registration_Date'].dt.year\ntest12345['Regmonth'] = test12345['Registration_Date'].dt.month\ntest12345['Regdate'] = test12345['Registration_Date'].dt.day\ntest12345['Regweek_day'] = test12345['Registration_Date'].dt.dayofweek\n\ntest12345['Intgquarter'] = test12345['First_Interaction'].dt.quarter\ntest12345['Intyear'] = test12345['First_Interaction'].dt.year\ntest12345['Intgmonth'] = test12345['First_Interaction'].dt.month\ntest12345['Intdate'] = test12345['First_Interaction'].dt.day\ntest12345['Intweek_day'] = test12345['First_Interaction'].dt.dayofweek\n\ntest12345['Campstquarter'] = test12345['Camp_Start_Date'].dt.quarter\ntest12345['Campstyear'] = test12345['Camp_Start_Date'].dt.year\ntest12345['Campstgmonth'] = test12345['Camp_Start_Date'].dt.month\ntest12345['Campstdate'] = test12345['Camp_Start_Date'].dt.day\ntest12345['Campstweek_day'] = test12345['Camp_Start_Date'].dt.dayofweek\n\ntest12345['Campendquarter'] = test12345['Camp_End_Date'].dt.quarter\ntest12345['Campendyear'] = test12345['Camp_End_Date'].dt.year\ntest12345['Campendgmonth'] = test12345['Camp_End_Date'].dt.month\ntest12345['Campenddate'] = test12345['Camp_End_Date'].dt.day\ntest12345['Campendweek_day'] = test12345['Camp_End_Date'].dt.dayofweek\n","43653c09":"test12345.info()","3e96b41a":"test12345=test12345.drop(['Registration_Date','First_Interaction','Camp_Start_Date','Camp_End_Date'], axis=1)","3eb91905":"predict_Prob_LGBM=LGB.predict_proba(test12345)[:,1]\npredict_Prob_LGBM","daf8c0b3":"df_solution = pd.DataFrame()\ndf_solution['Patient_ID'] = ForSubmission.Patient_ID\ndf_solution['Health_Camp_ID'] =ForSubmission.Health_Camp_ID\ndf_solution['Outcome'] = predict_Prob_LGBM\ndf_solution","c0d8e8a8":"df_solution.Outcome.value_counts()","390f0851":"df_solution.to_csv(\"LGB_Implementation_Health_Analytics_Submission.csv\", index=False)","0f13d8f3":"# The data type should be float or integer. And category data should be either hot coded or label coded or Category coded","94ab6f16":"*82 % accuracy of LGBM is better than 81% accuracy of Random forest*","8551146f":"# Lets Submit the solution","a766f7a1":"*CATBooster Classifier Acccuracy is 82.3 for the Training data set *","01b7930d":"# CATBOOST","fa8a731b":"**We dont need 'Registration_Date','First_Interaction','Camp_Start_Date','Camp_End_Date'. ","f519e0c9":"**Found that data type for numerical columns are not Integer or float. So converting them to integer or float","2f57ce71":"# CatBoost is a high-performance open source library for gradient boosting on decision trees\n","6db051dd":"# Preparing the Training Dataset","0a9e1bf0":"# LGBM has less error compared to Random forest. LGBM classifier model seems to be better fit compared to Random forest classifier model","a7629273":"WE dont need (['Patient_ID', 'Health_Camp_ID', 'Donation', 'Health_Score', 'Health Score', 'Number_of_stall_visited', 'Last_Stall_Visited_Number']","c72a1aaf":"*CAT AccurCAT 82.2 and LGBM is 82.4. We will choose LGBM instead of CAT","5019f0c7":"*Xtrain and Xtest both have same accuracy of 82.4 so model is not overfitting. we will check the same when we actually use Test data*","6b937a91":"**Found that instead of empty cells some of the Columns have \"None\". Like Income,Education_Score and Age Columns","b226aa6e":"****H\nHackathon 8: HealthCare Analytics\n\nhttps:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-healthcare-analytics\/\n\nPlatform: Analytics Vidhya\n\nProblem Statement\nIdenity the sucess of Health Camps. Defination of Sucess is the chance that patient visited or got registerd in any one or more health camps. Higher the probability means greater chance that patient wil visit the camp in future. Hence MedCamp can decide how much inventory is needed for similar camps in future\n\nMedCamp organizes health camps in several cities. Patients registers in health camp for undergoing health checks.In last 4 years, they have stored data of ~110,000 registrations they have done.\n\n\n\nData Description\nTrain.zip contains the following 6 csvs alongside the data dictionary that contains definitions for each variable\n\nHealth_Camp_Detail.csv \u2013 File containing Health_Camp_Id, Camp_Start_Date, Camp_End_Date and Category details of each camp.\n\nTrain.csv \u2013 File containing registration details for all the test camps. This includes Patient_ID, Health_Camp_ID, Registration_Date and a few anonymized variables as on registration date.\n\nPatient_Profile.csv \u2013 This file contains Patient profile details like Patient_ID, Online_Follower, Social media details, Income, Education, Age, First_Interaction_Date, City_Type and Employer_Category\n\nFirst_Health_Camp_Attended.csv \u2013 This file contains details about people who attended health camp of first format. This includes Donation (amount) & Health_Score of the person.\n\nSecond_Health_Camp_Attended.csv - This file contains details about people who attended health camp of second format. This includes Health_Score of the person.\n\nThird_Health_Camp_Attended.csv - This file contains details about people who attended health camp of third format. This includes Number_of_stall_visited & Last_Stall_Visited_Number.\n\n\n\nTest Set\n\nTest.csv \u2013 File containing registration details for all the test camps. This includes Patient_ID, Health_Camp_ID, Registration_Date and a few anonymized variables as on registration date.\n\n \n\nTrain \/ Test split:\n\nCamps started on or before 31st March 2006 are considered in Train\nTest data is for all camps conducted on or after 1st April 2006.\n\n\nSample Submission:\n\nPatient_ID: Unique Identifier for each patient. This ID is not sequential in nature and can not be used in modeling\n\nHealth_Camp_ID: Unique Identifier for each camp. This ID is not sequential in nature and can not be used in modeling\n\nOutcome: Predicted probability of a favourable outcome\n\n","20b68975":"**Feature Engineering. Identifying more Features from columns in Dateformat. Parsing the Date columns. Filling the missing datapoints. ","fe992271":"# Model Creation\nno null values in the Trainging data set and all the Features are either Integer or Float. So we can start Model Creation","1174fadc":"**There are still columns like City_Type and Employer_Category that have empty data","5b4fbf7f":"****Defining new Target Variable Outcome. This is inline with our Problem Statekemnt. 1 means Patient has registerd or vistied atleast one time in one of the Camps","99acc17c":"# Preparing Test (Validation Dataset)","e8ccc268":"# **For the Training data set, Light Gradient Boost is the best classifier now lets implement this classifier on the  Test data set****","d82c5f98":"*Gap between Camp start and registration date has higest impact on the probability of patient (re)visting a camp, followed by the City he belongs to  and his Age*\nRamdom Forest Classifier is able to have accuracy 81% for the Training data set. ","66d2da8b":"# Dates are the only datatype as Oject. Lets parse the dates and derive features out of  dates","79befea4":"**Checking if there is any Null or Empty data points in the Training Data Set. Registration date, City , Employer category has missing data points","030971ba":"\n**Gap between Camp start and registration date has higest impact on the probability of patient (re)visting a camp, followed by the City he belongs to and his Age*","dda82e1f":"# Deriving features out of dates","b0c64ded":"**We do not need 'Patient_ID', 'Health_Camp_ID', 'Donation', 'Health_Score', 'Health Score', 'Number_of_stall_visited', 'Last_Stall_Visited_Number'. These columns are not sequential. There is no relaation between any two subsequent rows of any of these columns","7856a699":"# Test (Validation) data set is ready. Now lets implement the CAT model that was best fit for the Training dataset","6a8c4302":"*Creating Training Dataset by merging all the Datasets***","948398cd":"*CAT Accuracy on Training data set is 82.25*","688c7402":"**Coverting the Categorical columns to Category encoding. Also making sure the data type is integer","6fcb3c93":"**Feature Engineering from all the Dates columns","c8d8972d":"# LGBM**\nLightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n\nFaster training speed and higher efficiency.\n\nLower memory usage.\n\nBetter accuracy.\n\nSupport of parallel and GPU learning.\n\nCapable of handling large-scale data.","eb1211d7":"**Gap between Camp start and registration date has higest impact on the probability of patient (re)visting a camp, followed by the City he belongs to  and his Age","cd4fbbc7":"# Reading the Data","61a8c745":"# Random Forest\nA random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. "}}