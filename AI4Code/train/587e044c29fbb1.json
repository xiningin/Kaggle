{"cell_type":{"6498116b":"code","37612092":"code","0bee9f6c":"code","716abdd3":"code","b6e4c7b0":"code","753be623":"code","5c1bf0c2":"code","f5c31fd3":"code","d342c312":"code","1b44e8d5":"code","3801f096":"code","50bfce71":"code","8880b1f3":"code","c2bdb9e4":"code","4ba43b1d":"code","a992339f":"code","16310132":"code","04d42d80":"code","943236c4":"code","6118c591":"code","a7793e3a":"code","f6063cb9":"code","c76a27cb":"code","b2dd6b7f":"code","b7bedf68":"code","73d6a078":"code","fd6f9d5c":"code","3252e8b8":"code","329762aa":"code","3a0968cf":"code","7ac797c3":"code","7423eaed":"code","5ef5ab5b":"code","77ff3b50":"code","e32d7207":"code","5a6133f1":"code","6aff44ed":"code","a600f1ca":"code","77e810f0":"code","6275f907":"code","944e5d14":"code","e4a81cb3":"code","13151294":"code","06ee12c2":"code","c5b95b90":"code","40210df0":"code","f5539e7a":"code","a86ed883":"code","9a78e713":"markdown","b9234ced":"markdown","9bfa0d38":"markdown","8f5bfe32":"markdown","b9bee628":"markdown","36cd201a":"markdown"},"source":{"6498116b":"import pandas as pd","37612092":"df=pd.read_csv('..\/input\/bargainnon-bargain\/Dataset.csv')","0bee9f6c":"df","716abdd3":"###Drop Nan Values\ndf=df.dropna()\n","b6e4c7b0":"Rake_df=df[df['Label']==0]","753be623":"## Get the Independent Features\n\nX=df.drop('Label',axis=1)","5c1bf0c2":"## Get the Dependent features\ny=df['Label']","f5c31fd3":"y.value_counts()","d342c312":"X.shape","1b44e8d5":"y.shape","3801f096":"import tensorflow as tf","50bfce71":"tf.__version__","8880b1f3":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Bidirectional\nfrom tensorflow.keras.layers import Dropout","c2bdb9e4":"### Vocabulary size\nvoc_size=5000","4ba43b1d":"messages=X.copy()","a992339f":"messages['text'][1]","16310132":"messages.reset_index(inplace=True)","04d42d80":"import nltk\nimport re\nfrom nltk.corpus import stopwords","943236c4":"nltk.download('stopwords')","6118c591":"### Dataset Preprocessing\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n   \n    review = re.sub('[^a-zA-Z]', ' ', messages['text'][i])#SUBSTITUTING EVERYTHING WITH WHITESPACE EXCEPT WORDS\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]#stem word for each word in review, if it is not in stopwords\n    review = ' '.join(review)\n    corpus.append(review)","a7793e3a":"corpus","f6063cb9":"onehot_repr=[one_hot(words,voc_size)for words in corpus] \nonehot_repr","c76a27cb":"sent_length=20\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\nprint(embedded_docs)","b2dd6b7f":"embedded_docs[0]","b7bedf68":"## Creating model\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","73d6a078":"## Creating model\nembedding_vector_features=40\nmodel1=Sequential()\nmodel1.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel1.add(Bidirectional(LSTM(100)))\nmodel1.add(Dropout(0.3))\nmodel1.add(Dense(1,activation='sigmoid'))\nmodel1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model1.summary())","fd6f9d5c":"len(embedded_docs),y.shape","3252e8b8":"import numpy as np\nX_final=np.array(embedded_docs)\ny_final=np.array(y)","329762aa":"X_final.shape,y_final.shape","3a0968cf":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)","7ac797c3":"### Finally Training\nmodel1.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)","7423eaed":"\ny_pred1=model1.predict_classes(X_test)","5ef5ab5b":"from sklearn.metrics import confusion_matrix","77ff3b50":"confusion_matrix(y_test,y_pred1)","e32d7207":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred1)","5a6133f1":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred1))","6aff44ed":"Text=['Hello, how are you']","a600f1ca":"Text=['Hello, how are you']\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\n\nc=[]\nreview = re.sub('[^a-zA-Z]', ' ', Text[0])\nreview = review.lower()\nreview = review.split()\n\nreview = [ps.stem(word) for word in review if not word in stopwords.words('english')]\nreview = ' '.join(review)\nc.append(review)\n\no_repr=[one_hot(words,voc_size)for words in c] \no_repr\n\nsent_length=20\ndoc=pad_sequences(o_repr,padding='pre',maxlen=sent_length)\n\ntest=np.array(doc)","77e810f0":"pred1=model1.predict_classes(x_test)","6275f907":"pred1","944e5d14":"Rake_df.reset_index(inplace=True)","e4a81cb3":"Sent=Rake_df['text'].values","13151294":"Sent","06ee12c2":"!pip install python-rake==1.4.4\n\nimport RAKE\nimport operator\n\n\nstop_dir = \"..\/input\/stopwords\/SmartStoplist.txt\"\nrake_object = RAKE.Rake(stop_dir)\n","c5b95b90":"BOW=[]\nfor i in Sent:\n    \n\n\n    # Extract keywords\n    keywords = rake_object.run(i)\n    if keywords  :\n        BOW.append(keywords)\n       \n\n    ","40210df0":"bow=[]\nfor i in BOW:\n    for j in i[0]:\n      \n        bow.append(j)","f5539e7a":"with open('BOW.txt', 'w+') as f:\n      \n    # write elements of list\n    for items in bow:\n        f.write('%s\\n' %items)\n      \n    print(\"File written successfully\")\n  \n  \n# close the file\nf.close()","a86ed883":"bow","9a78e713":"### Embedding Representation","b9234ced":"1. READ THE DATASET\n2. PREPROCESS INTO CLEAN LANGUAGE AND COVER Y TO ARRAY\n3. ENCODE WORDS TO LABEL [OHE]\n4. PAD\/TRUNCATE TO EQUAL LENGTH\n5. CREATE MODEL USING EMBEDINGS","9bfa0d38":"### Performance Metrics And Accuracy","8f5bfe32":"### Model Training","b9bee628":"### Onehot Representation","36cd201a":"##  Classifier Using Bi LSTM\n\n"}}