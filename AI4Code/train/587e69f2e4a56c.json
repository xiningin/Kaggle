{"cell_type":{"0f9579aa":"code","0458bb0f":"code","aef14579":"code","8f0a7cc4":"code","941d3b5d":"code","837e1cda":"code","b1d2e2e8":"code","db0e0a0c":"code","ccd5f43e":"code","c40f56cc":"code","c25fddd7":"code","5a1da166":"code","82ab336d":"code","5a2832cd":"code","0d502fbd":"code","86d4b9fd":"code","11b72a9c":"code","1f805d47":"code","ac0e1042":"code","af7614d2":"code","e78d806c":"code","c91ad527":"code","256c7c1c":"code","10cc019c":"code","0e45b766":"code","cdcfebb2":"code","c7f2b1ad":"code","10d711e3":"code","70e50a18":"code","d4417d6e":"code","87ad39a8":"code","829aeeaf":"markdown","33a74560":"markdown","a38b597b":"markdown","16ce32bb":"markdown","7c00169a":"markdown","fa990b06":"markdown","169f3481":"markdown","18ce831d":"markdown","85a3c71a":"markdown","b21f65b5":"markdown","80dc9972":"markdown","2c3a30da":"markdown","3f73b3bc":"markdown"},"source":{"0f9579aa":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport networkx as nx \nfrom PIL import Image\nfrom pathlib import Path\nimport cv2\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d import proj3d\nfrom imageio import imread\nfrom skimage.transform import resize\nfrom scipy.spatial import distance\nfrom keras.models import load_model\nfrom tqdm import tqdm\n\nimport os\nprint(os.listdir(\"..\/input\"))","0458bb0f":"train_df = pd.read_csv('..\/input\/recognizing-faces-in-the-wild\/train_relationships.csv')\ntrain_df.head()","aef14579":"def add_image_path(x):\n    image_path = '..\/input\/recognizing-faces-in-the-wild\/train\/' + x\n    if os.path.exists(image_path):\n        path = os.path.join(image_path, os.listdir(image_path)[0])\n        return path","8f0a7cc4":"train_df['p1_path'] = train_df.p1.apply(lambda x: add_image_path(x))\ntrain_df['p2_path'] = train_df.p2.apply(lambda x: add_image_path(x))","941d3b5d":"train_df.head()","837e1cda":"fam = os.listdir(\"..\/input\/recognizing-faces-in-the-wild\/train\")\nprint('We have',len(fam),'families')\nind = []\nnum = []\npic = []\ntot = 0\ntotpic = 0\nfor i in fam:\n    path = \"..\/input\/recognizing-faces-in-the-wild\/train\/\"+str(i)\n    temp = os.listdir(path)\n    ind.append(temp)\n    num.append(len(temp))\n    tot+=len(temp)\n    for j in temp:\n        newpath = path+\"\/\"+str(j)\n        temp = os.listdir(newpath)\n        pic.append(temp)\n        totpic+=len(temp)\nprint('And',tot,'individuals with',totpic,'pictures.')\nprint('On average, we see',tot\/len(fam),'members per family.')\nprint('With an average of',totpic\/tot,'per individual.')","b1d2e2e8":"img_path = Path('..\/input\/recognizing-faces-in-the-wild\/train\/')","db0e0a0c":"img_list = os.listdir(img_path \/ train_df.p1[0])","ccd5f43e":"fig,ax = plt.subplots(2,5, figsize=(50,20))\n\nfor i in range(len(img_list)):\n    with open(img_path \/ train_df.p1[0] \/ img_list[i] ,'rb') as f:\n        img = Image.open(f)\n        ax[i%2][i\/\/2].imshow(img)\nfig.show()","c40f56cc":"img_list = os.listdir(img_path \/ train_df.p2[0])","c25fddd7":"fig,ax = plt.subplots(2,5, figsize=(50,20))\n\nfor i in range(len(img_list)):\n    with open(img_path \/ train_df.p2[0] \/ img_list[i] ,'rb') as f:\n        img = Image.open(f)\n        ax[i%2][i\/\/2].imshow(img)\nfig.show()","5a1da166":"# Create graph from data \ng = nx.Graph()\ncolor_map = []\nitt = 0\nfor i in range(0,len(fam)): #len(names)\n    g.add_node(fam[i], type = 'fam')\n    for j in ind[i]:\n        temp = fam[i]+j\n        g.add_node(temp, type = 'ind')\n        g.add_edge(fam[i], temp, color='green', weight=1)\n        for k in pic[itt]:\n            g.add_node(k, type = 'pic')\n            g.add_edge(temp, k, color='blue', weight=1)\n        itt+=1\nfor n1, attr in g.nodes(data=True):\n    if attr['type'] == 'fam':\n        color_map.append('lime')\n    else: \n        if attr['type'] == 'ind':\n            color_map.append('cyan')\n        else:\n            color_map.append('red')","82ab336d":"# Plot the graph\nplt.figure(3,figsize=(90,90))  \nedges = g.edges()\ncolors = [g[u][v]['color'] for u,v in edges]\nnx.draw(g,node_color = color_map, edge_color = colors, with_labels = True)\nplt.show()","5a2832cd":"# Extract reference graph facts & metrics \nprint('Reference Graph')\nprint('Do we have a fully connected graph? ',nx.is_connected(g))\nd = list(nx.connected_component_subgraphs(g))\nprint('The graph contains',len(d), 'sub-graph')\nnx.isolates(g)\nh = g.to_directed()\nN, K = h.order(), h.size()\navg_deg= float(K) \/ N\nprint (\"# Nodes: \", N)\nprint (\"# Edges: \", K)\nprint (\"Average Degree: \", avg_deg)\n# Extract reference graph facts & metrics \nin_degrees= h.in_degree() # dictionary node:degree","0d502fbd":"!pip install git+https:\/\/github.com\/rcmalli\/keras-vggface.git","86d4b9fd":"from keras_applications.imagenet_utils import _obtain_input_shape\nfrom keras_vggface.vggface import VGGFace\n\n# Convolution Features\nvgg_features = VGGFace(include_top=False, input_shape=(160, 160, 3), pooling='avg')\nmodel = vgg_features","11b72a9c":"def prewhiten(x):\n    if x.ndim == 4:\n        axis = (1, 2, 3)\n        size = x[0].size\n    elif x.ndim == 3:\n        axis = (0, 1, 2)\n        size = x.size\n    else:\n        raise ValueError('Dimension should be 3 or 4')\n\n    mean = np.mean(x, axis=axis, keepdims=True)\n    std = np.std(x, axis=axis, keepdims=True)\n    std_adj = np.maximum(std, 1.0\/np.sqrt(size))\n    y = (x - mean) \/ std_adj\n    return y\n\ndef l2_normalize(x, axis=-1, epsilon=1e-10):\n    output = x \/ np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n    return output\n\ndef load_and_align_images(filepaths, margin,image_size = 160):\n    \n    aligned_images = []\n    for filepath in filepaths:\n        img = imread(filepath)\n        aligned = resize(img, (image_size, image_size), mode='reflect')\n        aligned_images.append(aligned)\n            \n    return np.array(aligned_images)","1f805d47":"def calc_embs(filepaths, margin=10, batch_size=512):\n    pd = []\n    for start in tqdm(range(0, len(filepaths), batch_size)):\n        aligned_images = prewhiten(load_and_align_images(filepaths[start:start+batch_size], margin))\n        pd.append(model.predict_on_batch(aligned_images))\n    embs = l2_normalize(np.concatenate(pd))\n\n    return embs","ac0e1042":"test_images = os.listdir(\"..\/input\/recognizing-faces-in-the-wild\/test\/\")\ntest_embs = calc_embs([os.path.join(\"..\/input\/recognizing-faces-in-the-wild\/test\/\", f) for f in test_images])\nnp.save(\"test_embs_vgg.npy\", test_embs)","af7614d2":"test_embs.shape","e78d806c":"model_path = '..\/input\/facenet-keras\/facenet_keras.h5'\nmodel = load_model(model_path)","c91ad527":"test_embs_vgg = calc_embs([os.path.join(\"..\/input\/recognizing-faces-in-the-wild\/test\/\", f) for f in test_images])\nnp.save(\"test_embs_fnet.npy\", test_embs_vgg)","256c7c1c":"test_embs_vgg.shape","10cc019c":"df_submit = pd.read_csv('..\/input\/recognizing-faces-in-the-wild\/sample_submission.csv')","0e45b766":"df_submit[\"distance\"] = 0\nimg2idx = dict()\nfor idx, img in enumerate(test_images):\n    img2idx[img] = idx","cdcfebb2":"for idx, row in tqdm(df_submit.iterrows(), total=len(df_submit)):\n    imgs = [test_embs[img2idx[img]] for img in row.img_pair.split(\"-\")]\n    df_submit.loc[idx, \"distance1\"] = distance.euclidean(*imgs)\n    \n    # For vggface\n    imgs_2 = [test_embs_vgg[img2idx[img]] for img in row.img_pair.split(\"-\")]\n    df_submit.loc[idx, \"distance2\"] = distance.euclidean(*imgs_2)","c7f2b1ad":"df_submit['distance'] = df_submit[['distance1','distance2']].mean(axis=1)\ndf_submit.head()\n","10d711e3":"all_distances = df_submit.distance.values\nsum_dist = np.sum(all_distances)","70e50a18":"probs = []\nfor dist in tqdm(all_distances):\n    prob = np.sum(all_distances[np.where(all_distances <= dist)[0]])\/sum_dist\n    probs.append(1 - prob)","d4417d6e":"sub_df = pd.read_csv(\"..\/input\/recognizing-faces-in-the-wild\/sample_submission.csv\")\nsub_df.is_related = probs\nsub_df.to_csv(\"submission.csv\", index=False)","87ad39a8":"sub_df.head(10)","829aeeaf":"## What can we learn from our graph?","33a74560":"### Reference:\n1. [iFace (Basic) EDA](https:\/\/www.kaggle.com\/a45632\/iface-basic-eda)\n2. [VGGFace baseline in Keras](https:\/\/www.kaggle.com\/ateplyuk\/vggface-baseline-in-keras)\n","a38b597b":"**Convert the distances to probabiliy values and submit the result**","16ce32bb":"# Northeastern SMILE Lab - Recognizing Faces in the Wild","7c00169a":"## Let's put train relations in a graph","fa990b06":"## Lets Visualize Some Images","169f3481":"### Preprocessing stuff","18ce831d":"**Compute all the embeddings for the test images using the pretrained model**","85a3c71a":"## Let's load our pretrained model.","b21f65b5":"## FaceNet model","80dc9972":"**Compute the actual distance between provided image pairs**","2c3a30da":"## Let's explore the train folder","3f73b3bc":"## Import Packages"}}