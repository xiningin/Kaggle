{"cell_type":{"169e964b":"code","97db354a":"code","ffe021c1":"code","f3fc6ab1":"code","0f24faed":"code","8f3d7157":"code","5918c491":"code","a1492556":"code","fde67d10":"code","85445aff":"code","89f4ee6e":"code","796ea163":"code","b85f844e":"code","46af52b4":"code","4e46091c":"code","52dd68f4":"code","15f7be87":"code","351f0001":"code","cbda6ddc":"code","d8346d9c":"code","611e3699":"code","2ca8a149":"code","d26f1f21":"code","dc01c686":"code","821c7c2c":"code","5bb2df38":"code","b4664366":"code","4840bfe5":"code","9e8e2fcc":"code","8f71f798":"code","055256a1":"code","8209f9e4":"code","1d704d3c":"code","6d52afb2":"code","2a9d4ae2":"code","576abf43":"code","e5256a4a":"code","01c85e26":"code","b36151e0":"code","cffa3fe5":"code","95bf19c4":"code","bf339413":"code","7c85e3c8":"code","55112b17":"code","027eed90":"code","5cff041b":"code","eef751cf":"code","246cc1e3":"code","a686a214":"code","2a68b8c5":"code","422f0d27":"code","81ed5317":"code","0901c387":"code","0f47daae":"code","3ad40dc5":"code","6fc086d3":"code","dadbc057":"code","15e0b75c":"code","0c34b64e":"code","3db09934":"code","24900420":"code","3e0172cd":"code","bf1eed11":"code","95337ae0":"markdown","8e5d1325":"markdown","eeeb8cb3":"markdown","f974ecd2":"markdown","bab9e52b":"markdown","91b31b89":"markdown","0c9154af":"markdown","a1b38558":"markdown","4b02b3a0":"markdown","55a858db":"markdown","bceae95f":"markdown","63367b98":"markdown","b8ee86fd":"markdown","21d9d3bb":"markdown","eb26203c":"markdown","8ae7d97a":"markdown","a2d753e7":"markdown","acc45c77":"markdown","092fad26":"markdown","2060d3e2":"markdown","7ce0ae56":"markdown","028b4bf6":"markdown","338f879e":"markdown"},"source":{"169e964b":"## **My musical preferences**\n\n\n\n","97db354a":"import pandas as pd\nimport seaborn as sns\nimport plotly.express as xp\nimport plotly.graph_objects as go\nimport numpy as np\nfrom datetime import datetime\nimport missingno\nimport yaml\nfrom collections import Counter\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV,ShuffleSplit\nfrom sklearn.manifold import TSNE\nfrom sklearn.ensemble import RandomForestClassifier\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\npalette = [\"#3ADF00\",\"#DF0101\",\"#045FB4\"]\nsns.palplot(palette)","ffe021c1":"def split_to_onehot(df, col):\n    \"\"\"\n    This method converts features separated by '|' into one-hot vectors.\n    Additionally it drops unnecessary values, which present only in \n    test set \/ train set or have only one value.\n    \"\"\"\n    # Getting all unique ganres values.\n    unique = []\n    for i in df.index:\n        unique.extend(df.loc[i,col].split(\"|\"))\n    if \"\" in unique:\n        unique.remove(\"\")\n    unique = list(set(unique))\n    \n    # Putting values into binary form \n    onehot = df.loc[:,[\"Category\"]]\n    onehot[unique] = np.zeros((len(unique),), dtype = np.int8)\n    for i in df.index:\n        g = set(df.loc[i,col].split(\"|\"))\n        for j in g:\n            if j!=\"\":\n                onehot.loc[i,j] = 1\n                \n    # Dropping unnecessary values            \n    _a = onehot.groupby(\"Category\").sum()\n    only_one = list(_a.sum()[_a.sum()==1].index)\n    only_train = list(_a.loc[\"none\"][_a.loc[\"none\"]==0].index)\n    only_test = list(_a.loc[[\"like\",'dislike']].sum()[_a.loc[[\"like\",'dislike']].sum()==0].index)\n    _a = set(only_one + only_train + only_test)\n    onehot = onehot.drop(_a, axis=1)\n    \n    return onehot\n\ndef onehot_to_tsne2(df, title):\n    \"\"\"\n    This method converts one-hot representation into two tsne values.\n    Such operation is needed to shrink the dimentionality of the dataset\n    \"\"\"\n    onehot = df.drop(\"Category\",axis=1)\n    embedding = TSNE(n_components=2, init=\"pca\")\n    embedded = embedding.fit_transform(onehot)\n    embedded = pd.DataFrame(embedded,columns=[f\"{title}_tsne1\",f\"{title}_tsne2\"])\n    return embedded\n\ndef plot_commulative_onehot(onehot):\n    \"\"\"\n    Method of plotting commulative values of the one hot feature representation\n    \"\"\"\n    _df = onehot.groupby(\"Category\").sum()\n    fig = go.Figure()\n    for i in range(len(_df.index)):\n        k = _df.index[i]\n        x,y=[],[]\n        for g in _df.columns:\n            if _df.loc[k,g]!=0:\n                x.append(g)\n                y.append(_df.loc[k,g])\n        fig.add_trace(go.Bar(x=x, y=y,name=k,marker=dict(color=palette[i])))\n    fig.show()","f3fc6ab1":"PATH = \"..\/input\/mymusicalprefrences\/\" \ntrain = pd.read_csv(f\"{PATH}train.csv\")\ntest = pd.read_csv(f\"{PATH}test.csv\")\ndescription = yaml.load(open(f\"{PATH}Description.yaml\",'r'),Loader=yaml.FullLoader)\ndf = pd.concat([train,test]).reset_index(drop=True)\ntr_mask = ~df.Category.isna()","0f24faed":"df.columns = [i.strip() for i in df.columns]\nprint(set(df.columns))","8f3d7157":"df.describe()","5918c491":"# Displaing of None values in the dataset\nmissingno.bar(df, color=palette, figsize=(30,2))","a1492556":"cat_features = {\"Artists\",\"Track\",\"Version\",\"Artists_Genres\",\"Album\",\"Album_type\",\"Labels\",\"Vocal\",\"Country\",\"Key\"}\ncon_features = {\"Duration\",\"Release_year\",\"BPM\",\"Energy\",\"Dancebility\",\"Happiness\"}\ndisplay(df[cat_features].head())\ndisplay(df[con_features].head())","fde67d10":"sns.pairplot(df[list(con_features)+[\"Category\"]],palette=palette[:2], hue=\"Category\")","85445aff":"# For more easy usage of the Category feature\ndf[\"Category\"] = df[\"Category\"].fillna(\"none\").replace({0:\"dislike\",1:\"like\"})","89f4ee6e":"description[\"Key\"]","796ea163":"xp.scatter(df, x=\"Key\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=palette)","b85f844e":"# We correct strings and replace some ambivalent values\ndf[\"isMajor\"], df[\"Key\"] = df[\"Key\"].apply(lambda x: x.split(\" \")[1]), df[\"Key\"].apply(lambda x: x.split(\" \")[0])\ndf.loc[:,\"Key\"] = df[\"Key\"].replace({\"D\u266d\": \"C#\", \"E\u266d\": \"D#\", \"G\u266d\": \"F#\", \"A\u266d\": \"G#\",\"B\u266d\":\"A#\"})\nxp.scatter(df, x=\"Key\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=palette)","46af52b4":"# We put the Major\/Minor part into new feature, to make it more easy for our model to fit on it\ndf.loc[:,\"isMajor\"] = (df[\"isMajor\"]==\"Major\").astype(int)\n_df = df.groupby([\"isMajor\",\"Category\"], as_index=False).count()\nxp.bar(_df,x=\"isMajor\", y=\"Track\",color=\"Category\", height=400, color_discrete_sequence=palette)","4e46091c":"_df = df.copy(deep=True)\n_df[\"Key_percise\"] = _df[\"Key\"] +\"_major:\"+ _df[\"isMajor\"].astype(str)\n_df = _df.groupby([\"Key_percise\",\"Category\"], as_index=False).count()\nxp.bar(_df, x=\"Key_percise\", y=\"Track\", color=\"Category\", height=500, color_discrete_sequence=palette)","52dd68f4":"df[list(set(df[\"Key\"].values))] = OneHotEncoder().fit_transform(df[[\"Key\"]]).toarray()\ndf = df.drop(\"Key\", axis=1)","15f7be87":"description[\"Release year\"]","351f0001":"xp.scatter(df, x=\"Release_year\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=palette)","cbda6ddc":"# Lets create the decade feature, to detect some music of 80th, 90th etc. as a specific janre\ndf.loc[:,\"Release_decade\"] = (df.loc[:,\"Release_year\"]\/\/10 * 10)\n# Cause of the small number of values, we will put all <90th toone value, called 80th\ndf.loc[df.loc[:,\"Release_decade\"]<1990,\"Release_decade\"] = 1980 \n_df = df.groupby([\"Release_decade\",\"Category\"], as_index=False).count()\nxp.bar(_df,x=\"Release_decade\", y=\"Track\",color=\"Category\",height=500, color_discrete_sequence=palette)","d8346d9c":"description[\"Artists Genres\"]","611e3699":"ganres_onehot = split_to_onehot(df, \"Artists_Genres\")\nplot_commulative_onehot(ganres_onehot)","2ca8a149":"genres_embedded = onehot_to_tsne2(ganres_onehot, \"Genres\")\n_df = genres_embedded.copy(deep=True)\n_df[[\"Category\",\"Artists_Genres\"]] = df[[\"Category\",\"Artists_Genres\"]]\nxp.scatter(_df,x=\"Genres_tsne1\",y=\"Genres_tsne2\",color=\"Category\", hover_data=[\"Artists_Genres\"], height=500, color_discrete_sequence=palette)","d26f1f21":"df = pd.concat([df,genres_embedded], axis=1)\ndf = df.drop(\"Artists_Genres\", axis=1)","dc01c686":"for k in [\"Energy\",\"Happiness\",\"Dancebility\",\"BPM\"]:\n    print(f\"{k}:{description[k]}\")","821c7c2c":"df[\"BPM\"] = df[\"BPM\"].apply(lambda x: str(x)[1:] if str(x)[0]=='`' else x)\ndf[['Energy', 'Happiness', 'Dancebility','BPM']] = df[['Energy', 'Happiness', 'Dancebility','BPM']].fillna(0)\ndf[['Energy%', 'Happiness%', 'Dancebility%']] = df[['Energy', 'Happiness', 'Dancebility']].apply(lambda x: x\/sum(x), axis=1)\ndf[['Energy%', 'Happiness%', 'Dancebility%']] = df[['Energy%', 'Happiness%', 'Dancebility%']].fillna(0)","5bb2df38":"print(description[\"Labels\"])","b4664366":"df.Labels = df.Labels.fillna('NA')\nlabels_onehot = split_to_onehot(df, \"Labels\")\nplot_commulative_onehot(labels_onehot)","4840bfe5":"labels_embedded = onehot_to_tsne2(labels_onehot, \"Labels\")\n_df = labels_embedded.copy(deep=True)\n_df[[\"Category\",\"Labels\"]] = df[[\"Category\",\"Labels\"]]\nxp.scatter(_df,x=\"Labels_tsne1\",y=\"Labels_tsne2\",color=\"Category\", hover_data=[\"Labels\"], height=500, color_discrete_sequence=palette)","9e8e2fcc":"df = pd.concat([df,labels_embedded[[\"Labels_tsne1\",\"Labels_tsne2\"]]], axis=1)\ndf = df.drop(\"Labels\", axis=1)","8f71f798":"print(description[\"Artists\"])","055256a1":"df.Artists = df.Artists.fillna(\"NA\")\nallstars = []\nfor i in df.index:\n    allstars.extend(df.loc[i, \"Artists\"].split(\"|\"))\nlen(set(allstars))","8209f9e4":"# We will put some threshold, not to put some rare artists into one-hot vector.\nthreshold = 3\nothers = Counter(allstars)\nothers = [k for k in others if others[k]<=threshold]\nlen(others)","1d704d3c":"# Drop all artists who are just in test set or just in train set\nin_train, in_test = [], []\nfor i in df.loc[tr_mask].index:\n    in_train.extend(df.loc[i, \"Artists\"].split(\"|\"))\nfor i in df.loc[~tr_mask].index:\n    in_test.extend(df.loc[i, \"Artists\"].split(\"|\"))\n    \nonly_test = set(in_test) - set(in_train)\nonly_train = set(in_train) - set(in_test)\ndisplay(len(only_test))\ndisplay(len(only_train))","6d52afb2":"allstars = list(set(allstars) - set(others) - only_test - only_train)\nprint(len(allstars))\nothers = set(others) | only_test | only_train\nprint(len(others))","2a9d4ae2":"res = []\ndef prune(x):\n    vector = np.zeros(len(allstars)+1) #for others\n    x = [i for i in x.split(\"|\")]\n    for i in range(len(allstars)):\n        vector[i]=1 if allstars[i] in x else 0\n    if len(x)>sum(vector):\n        vector[-1]=1\n    res.append(vector)\n\ndf[\"Artists\"].apply(prune)\nonehot_artists = pd.DataFrame(res, columns = allstars+[\"Others\"], index=df.index)","576abf43":"onehot_artists","e5256a4a":"df[\"Other_Artists\"] = onehot_artists[\"Others\"]\nonehot_artists = onehot_artists.drop(\"Others\", axis=1)\nonehot_artists[\"Category\"] = df[\"Category\"]","01c85e26":"plot_commulative_onehot(onehot_artists)","b36151e0":"artists_embedded = onehot_to_tsne2(onehot_artists, \"Artists\")\n_df = artists_embedded.copy(deep=True)\n_df[[\"Category\",\"Artists\"]] = df[[\"Category\",\"Artists\"]]\nxp.scatter(_df,x=\"Artists_tsne1\",y=\"Artists_tsne2\",color=\"Category\", hover_data=[\"Artists\"], height=500, color_discrete_sequence=palette)","cffa3fe5":"df = pd.concat([df,artists_embedded[[\"Artists_tsne1\",\"Artists_tsne2\"]]], axis=1)\ndf = df.drop(\"Artists\", axis=1)","95bf19c4":"for i in [\"Track\", \"Version\", \"Album_type\"]:\n    print(description[i])","bf339413":"artists_encoder = LabelEncoder()\ndf[\"Track\"] = artists_encoder.fit_transform(df[\"Track\"])","7c85e3c8":"_df = df.groupby([\"Version\",\"Category\"], as_index=False).count()\nxp.bar(_df,x=\"Version\",y=\"Id\",color=\"Category\", color_discrete_sequence=palette)","55112b17":"df[\"Version\"] = df[\"Version\"].fillna(\"NA\")\nversions = set(df[\"Version\"])\ndf[list(versions)] = OneHotEncoder().fit_transform(df[[\"Version\"]]).toarray()\ndf = df.drop([\"Version\",\"NA\"], axis=1)","027eed90":"_df = df.groupby([\"Album_type\",\"Category\"], as_index=False).count()\nxp.bar(_df,x=\"Album_type\",y=\"Id\",color=\"Category\", color_discrete_sequence=palette)","5cff041b":"df[\"Album_type\"] = df[\"Album_type\"].fillna(\"NA\")\nversions = set(df[\"Album_type\"])\ndf[list(versions)] = OneHotEncoder().fit_transform(df[[\"Album_type\"]]).toarray()\ndf = df.drop([\"Album_type\",\"NA\"], axis=1)","eef751cf":"print(description[\"Album\"])","246cc1e3":"df[\"Album\"] = df[\"Album\"].fillna(\"NA\")\nganres_onehot = split_to_onehot(df, \"Album\")\nplot_commulative_onehot(ganres_onehot)","a686a214":"album_embedded = onehot_to_tsne2(onehot_artists, \"Album\")\n_df = album_embedded.copy(deep=True)\n_df[[\"Category\",\"Album\"]] = df[[\"Category\",\"Album\"]]\nxp.scatter(_df,x=\"Album_tsne1\",y=\"Album_tsne2\",color=\"Category\", hover_data=[\"Album\"], height=500, color_discrete_sequence=palette)","2a68b8c5":"df = pd.concat([df,album_embedded[[\"Album_tsne1\",\"Album_tsne2\"]]], axis=1)\ndf = df.drop(\"Album\", axis=1)","422f0d27":"print(description[\"Vocal\"])","81ed5317":"df[\"Vocal\"] = df[\"Vocal\"].fillna('N')\nonehot = np.zeros((len(df),2))\nfor i in range(len(df)):\n    v = df.iloc[i][\"Vocal\"]\n    if v == 'F':\n        onehot[i] = [1,0]\n    elif v == 'M':\n        onehot[i] = [0,1]\n    elif v == 'F|M':\n        onehot[i] = [1,1]\ndf[[\"Fem_voc\",\"Mal_voc\"]] = onehot\ndf = df.drop(\"Vocal\",axis=1)","0901c387":"print(description[\"Country\"])","0f47daae":"df[\"Country\"] = df[\"Country\"].fillna(\"NA\")\ncountry_onehot = split_to_onehot(df, \"Country\")\nplot_commulative_onehot(country_onehot)","3ad40dc5":"country_onehot = country_onehot.drop(\"Category\", axis=1)\ndf = pd.concat([df,country_onehot], axis=1)\ndf = df.drop(\"Country\", axis=1)","6fc086d3":"# We drop some of features\ndf = df.drop(\"Duration\", axis=1)","dadbc057":"## 3 Model selection","15e0b75c":"df","0c34b64e":"df=df.drop(\"Id\",axis=1)","3db09934":"x, y = df.loc[tr_mask].iloc[:,2:], df.loc[tr_mask,\"Category\"]\ndeploy = df.loc[~tr_mask].iloc[:,2:]","24900420":"model_c = RandomForestClassifier()\nmodel_c.fit(x,y)","3e0172cd":"sample = pd.read_csv(f\"{PATH}sample_submition.csv\")\nsample[\"Category\"] = model_c.predict(deploy)\nsample[\"Category\"] = (sample[\"Category\"]==\"like\").astype(int)\nsample","bf1eed11":"sample.to_csv(\".\/submission.csv\", index=False)","95337ae0":"## 2.4 Energy,Happiness,Dancebility, BPM","8e5d1325":"## 2.1 Key feature","eeeb8cb3":"## 2.2 Release year feature","f974ecd2":"From the analisys of this feature we can say:\n* There are some ganres that I do not like (or not really): **dance, house, dnb, latinfolk, epicmetal, electronics, ruspop**\n* There are some ganres that I do mostly like: **rock, indie, pop, rnd, soul, numetal**","bab9e52b":"### 2.7.2 Version","91b31b89":"## 2.8 Album","0c9154af":"## 2.8 Vocal","a1b38558":"## 2.5 Labels","4b02b3a0":"# 2. Data Preparation and Feature Engeneering\n","55a858db":"This feature is the most complicated one. For the example, lets assume, that the main artist for the track - named the 1st. Others will be named as collaborators.This is cause for not to make the one-hot matrix too spars putting all the artists to the single columns. Experiment with this feature - the result of its preprocessing may influence significantly to the final result.","bceae95f":"In this cases we do not have much features (so our one-hot representation wont be too spars) so we will apply onehot or label encoders (dependong of the number of features) to encode out values","63367b98":"## 2.7 Tracks, Version, Album_type","b8ee86fd":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/29548\/logos\/header.png?t=2021-06-16-09-31-18)","21d9d3bb":"## 2.3 Genres features","eb26203c":"From the analisys of this feature we can get the porportion of likes\/ dislikes:\n\n| Decade | like\/dislike  | koeff |\n| ------ |:-------------:| -----:|\n| 1980s  | 9\/6           | 1.5   |\n| 1990s  | 16\/8          | 2     |\n| 2000s  | 81\/90         | 0.9   |\n| 2010s  | 213\/153       | 1.39  |\n| 2020s  | 32\/57         | 0.56  |\n\nNumber of values in decades less then 1990 - may not be destinctive, but according to the koefficient - this music i like the most (this is true).\n\nAt the same time, the modern music (Like, two last years) is not in my top .","8ae7d97a":"# 1. Explorational Data Analysis \n","a2d753e7":"Nothing to do here. We will just add some propotional values of the same features.","acc45c77":"We can see, that we have to much values in one-hot vector representation. It may cause much problems, during the fitting of our model (it couldn't find distinctive dependencies in sparse matrix). In this case we will apply TSNE as a handy solution, to transfer our n columns into two, without losing the information. I recommend you to experiment with this step during your work.","092fad26":"From the analisys of this feature we can say:\n* There are some favorite artists, such as: **twenty one pilots, radiohead, monatik, rhcp, \u0441\u043a\u0440\u0438\u043f\u0442\u043e\u043d\u0438\u0442, etc.**\n* There are some artists that i do not like much: **morgenshtern, 6ix9ine, \u042d\u043b\u0434\u0436\u0435\u0439, Lady GaGa, Pitbul etc.**","2060d3e2":"## 2.9 Country","7ce0ae56":"### 2.7.3 Album_type","028b4bf6":"## 2.6 Artists","338f879e":"### 2.7.1 Tracks"}}