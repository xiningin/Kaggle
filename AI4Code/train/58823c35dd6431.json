{"cell_type":{"81c8374d":"code","2fb198eb":"code","42c96366":"code","3de788f9":"code","62fbe501":"code","99f5de7b":"code","9f2e8c6b":"code","925a53c3":"code","76ea630e":"code","d88dbe0c":"code","9502ae4a":"code","e529f489":"code","8d0f361a":"code","414299ac":"code","531f86b0":"code","660acbe6":"code","fe3217ae":"code","207d9205":"code","3c1f7c66":"code","39a44e15":"code","16e3d84a":"code","21c08eb2":"code","ec663a87":"code","07f9de2c":"markdown","432855e4":"markdown","8658492a":"markdown","5554e03b":"markdown","0e686914":"markdown","8edad6a3":"markdown"},"source":{"81c8374d":"#Import libraries and loading datasets\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm.libsvm import predict_proba\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_curve\n\nvle = pd.read_csv('..\/input\/vle.csv')\nassessments = pd.read_csv('..\/input\/assessments.csv')\ncourses = pd.read_csv('..\/input\/courses.csv')\nstudentAssessment = pd.read_csv('..\/input\/studentAssessment.csv')\nstudentInfo = pd.read_csv('..\/input\/studentInfo.csv')\nstudentRegistration = pd.read_csv('..\/input\/studentRegistration.csv')\nstudentVle = pd.read_csv('..\/input\/studentVle.csv')\nvle = pd.read_csv('..\/input\/vle.csv')","2fb198eb":"# Calculate average clicks of students on VLE activity sites.\n\nclicks = studentVle.groupby(['id_student', 'code_module', 'code_presentation']).agg({'sum_click':'mean'})\nclicks.reset_index(level=[0, 1, 2], inplace=True)\n\nresults_aged = pd.merge(studentInfo, \n                        clicks, \n                        how = 'left', \n                        left_on = ['id_student', 'code_module', 'code_presentation'], \n                        right_on = ['id_student', 'code_module', 'code_presentation'])","42c96366":"# TO Add average delays in assessment submissions\n# result of this cell: the dataset results_aged2 will have column 'delay' \n#with average number of days between fixed assessment date and submission date by student. \n\nassessments_totalled = pd.merge(studentAssessment, \n                        assessments, \n                        how = 'left', \n                        left_on = ['id_assessment'], \n                        right_on = ['id_assessment'])\nassessments_totalled['delay'] = assessments_totalled['date_submitted'] - assessments_totalled['date']\nassessments_totalled\n\nstudent_delays = assessments_totalled.groupby(['code_presentation', 'code_module', 'id_student']).agg({'delay':'mean'})\nstudent_delays.reset_index(level=[0, 1, 2], inplace=True)\n\nresults_aged1 = pd.merge(results_aged, \n                        student_delays, \n                        how = 'left', \n                        left_on = ['id_student', 'code_module', 'code_presentation'], \n                        right_on = ['id_student', 'code_module', 'code_presentation'])","3de788f9":"\nresults_aged2 = pd.merge(results_aged1, \n                        studentRegistration, \n                        how = 'left', \n                        left_on = ['id_student', 'code_module', 'code_presentation'], \n                        right_on = ['id_student', 'code_module', 'code_presentation'])\n","62fbe501":"# TO define and clean data for the RF model \nmodel_data = results_aged2[[\n#'id_student',\n'code_module',\n'code_presentation',\n'gender',\n'region',\n'highest_education',\n'imd_band',\n'age_band',\n'num_of_prev_attempts',\n'studied_credits',\n'disability',\n'sum_click',\n'delay',\n'date_registration',\n'final_result'\n]]\n\nmodel_data2 = model_data.copy()\n#1. model: predicting failures among courses that have been finalized\n#model_data2 = model_data2[model_data2['final_result'].isin(['Pass', 'Fail', 'Distinction'])]\n#model_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 0))\n\n#2. model: predicting failures\/withdraws \n#model_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 0, Withdrawn = 0))\n\n#3. model: predicting withdraws\n#model_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 1, Withdrawn = 0))\n\n# model 4: predicting failures\n#model_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 0, Withdrawn = 1))\n\n# model 5: multilabel\nmodel_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=2, Fail = 0, Withdrawn = -1))\n\n\nmodel_data2.gender = model_data2.gender.map(dict(M=1, F=0))\nmodel_data2.disability = model_data2.disability.map(dict(Y=1, N=0))\n\ntext_columns = [\n'code_module',\n'code_presentation',\n'region',\n'highest_education',\n'imd_band',\n'age_band',\n'num_of_prev_attempts',\n'studied_credits'] \n\nmodel_data2 = pd.get_dummies(model_data2, columns=text_columns)","99f5de7b":"#Clean data from 'na' values\nmodel_data2.sum_click = model_data2.sum_click.fillna(0)\nmodel_data2.date_registration = model_data2.date_registration.fillna(0)\nmodel_data2.delay = model_data2.delay.fillna(0)\nmodel_data2.reset_index(level=[0], inplace=True)","9f2e8c6b":"#Splitting data into main training and testing(validation) datasets, 70\/30\nmodel_data_train = model_data2.sample(int(np.floor(model_data2.shape[0] * 0.9)), random_state=999)\nmodel_data_test = model_data2[np.logical_not(model_data2['index'].isin(model_data_train['index']))]\n\nprint(model_data_train[model_data_train['final_result'] == 0].shape\n    , model_data_train[model_data_train['final_result'] == -1].shape\n    , model_data_train[model_data_train['final_result'] == 1].shape\n    , model_data_train[model_data_train['final_result'] == 2].shape\n     , model_data_test.shape)\n","925a53c3":"# Undersampling\nmodel_data_train_0 = model_data_train[model_data_train['final_result'] == 0]\nmodel_data_train_1 = model_data_train[model_data_train['final_result'] == 1]\nmodel_data_train_2 = model_data_train[model_data_train['final_result'] == 2]\nmodel_data_train_3 = model_data_train[model_data_train['final_result'] == -1]\n\n\nmodel_data_train_new = pd.concat([model_data_train_0, model_data_train_0,\n                                  model_data_train_1,\n                                  model_data_train_2, model_data_train_2, model_data_train_2, model_data_train_2, \n                                  model_data_train_3, ])\nprint(model_data_train_new.shape)\n\n","76ea630e":"# model 2: Oversampling\nmodel_data_train_fail = model_data_train[model_data_train['final_result'] == 0]\nmodel_data_train_pass = model_data_train[model_data_train['final_result'] == 1]\ndiff = model_data_train_fail.shape[0] - model_data_train_pass.shape[0]\n\nprint(model_data_train_fail.shape, model_data_train_pass.shape)\n\nmodel_data_train_new = pd.concat([model_data_train_pass, \n                                  model_data_train_fail, \n                                  model_data_train_pass.sample(diff, random_state = 999)])\nprint(model_data_train_new.shape)","d88dbe0c":"# model 5: Multilabel\n\nmodel_data_train_new = model_data_train","9502ae4a":"# Oversampling\nmodel_data_train_fail = model_data_train[model_data_train['final_result'] == 0]\nmodel_data_train_pass = model_data_train[model_data_train['final_result'] == 1]\n\nprint(model_data_train_fail.shape, model_data_train_pass.shape)\n\nmodel_data_train_new = pd.concat([model_data_train_pass, model_data_train_fail, model_data_train_fail, model_data_train_fail])\nprint(model_data_train_new.shape)\n","e529f489":"#test_train_sample\nX_train, X_test, y_train, y_test = train_test_split(\n    model_data_train_new[model_data_train_new.columns.difference(['final_result'])],\n    model_data_train_new['final_result'], test_size=0.0, random_state=1)","8d0f361a":"# GridSearch to find out the best performing parameters (!!! takes long time, ~50 min)\n'''\nparam_grid = { \n    'n_estimators': [100, 500, 800, 1100],\n    'max_depth' : [10,20,30,50],\n#    'max_features': ['auto', 'sqrt', 'log2'],\n    'criterion' :['gini', 'entropy']\n}\n\nCV_rfc = GridSearchCV(estimator=RandomForestClassifier(random_state=1), param_grid=param_grid, cv= 5)\nCV_rfc.fit(X_train, y_train)\nCV_rfc.best_params_\n'''\n","414299ac":"#Train the RF model\nrf = RandomForestClassifier(\n    n_estimators=1100, max_depth = 60, criterion = 'entropy', random_state = 0).fit(\n    X_train, y_train)","531f86b0":"# Run model on Test Validation data and see the accuracy\ntest_dt = model_data_test[model_data_test.columns.difference(['final_result'])]\ntest_dt_y = model_data_test.final_result\nacc = accuracy_score(test_dt_y, rf.predict(test_dt))\nacc","660acbe6":"# TO define and clean data for the RF model \nmodel_data = results_aged2[[\n#'id_student',\n'code_module',\n'code_presentation',\n'gender',\n'region',\n'highest_education',\n'imd_band',\n'age_band',\n'num_of_prev_attempts',\n'studied_credits',\n'disability',\n'sum_click',\n'delay',\n'date_registration',\n'final_result'\n]]\n\nmodel_data2 = model_data.copy()\n#1. model: predicting failures among courses that have been finalized\n#model_data2 = model_data2[model_data2['final_result'].isin(['Pass', 'Fail', 'Distinction'])]\n#model_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 0))\n\n#2. model: predicting failures\/withdraws \n#model_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 0, Withdrawn = 0))\n\n#3. model: predicting withdraws\nmodel_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 1, Withdrawn = 0))\n\n# model 4: predicting failures\n#model_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 0, Withdrawn = 1))\n\n# model 5: multilabel\n#['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 0, Withdrawn = -1))\n\n\nmodel_data2.gender = model_data2.gender.map(dict(M=1, F=0))\nmodel_data2.disability = model_data2.disability.map(dict(Y=1, N=0))\n\ntext_columns = [\n'code_module',\n'code_presentation',\n'region',\n'highest_education',\n'imd_band',\n'age_band',\n'num_of_prev_attempts',\n'studied_credits'] \n\nmodel_data2 = pd.get_dummies(model_data2, columns=text_columns)\n\n#Clean data from 'na' values\nmodel_data2.sum_click = model_data2.sum_click.fillna(0)\nmodel_data2.date_registration = model_data2.date_registration.fillna(0)\nmodel_data2.delay = model_data2.delay.fillna(0)\nmodel_data2.reset_index(level=[0], inplace=True)\n\n#Splitting data into main training and testing(validation) datasets, 70\/30\nmodel_data_train2 = model_data2.sample(int(np.floor(model_data2.shape[0] * 0.9)), random_state=999)\nmodel_data_test2 = model_data2[np.logical_not(model_data2['index'].isin(model_data_train2['index']))]\n\nprint(model_data_train2[model_data_train2['final_result'] == 0].shape\n    , model_data_train2[model_data_train2['final_result'] == 1].shape\n     , model_data_test2.shape)\n","fe3217ae":"# model 2: Oversampling\nmodel_data_train_fail = model_data_train2[model_data_train2['final_result'] == 0]\nmodel_data_train_pass = model_data_train2[model_data_train2['final_result'] == 1]\ndiff = 2*model_data_train_fail.shape[0] - model_data_train_pass.shape[0]\n\nprint(model_data_train_fail.shape, model_data_train_pass.shape)\n\nmodel_data_train_new = pd.concat([model_data_train_pass, \n                                  model_data_train_fail, \n                                  model_data_train_fail, \n                                  model_data_train_fail.sample(abs(diff), random_state = 999)])\nprint(model_data_train_new.shape)\n\n\n","207d9205":"#test_train_sample\nX_train, X_test, y_train, y_test = train_test_split(\n    model_data_train_new[model_data_train_new.columns.difference(['final_result'])],\n    model_data_train_new['final_result'], test_size=0.0, random_state=1)\n\n#Train the RF model\nrf2 = RandomForestClassifier(\n    n_estimators=1100, max_depth = 60, criterion = 'entropy', random_state = 0).fit(\n    X_train, y_train)\n\n# Run model on Test Validation data and see the accuracy\ntest_dt2 = model_data_test2[model_data_test2.columns.difference(['final_result'])]\ntest_dt_y2 = model_data_test2.final_result\nacc = accuracy_score(test_dt_y2, rf2.predict(test_dt2))\nacc\n","3c1f7c66":"# TO define and clean data for the RF model \nmodel_data = results_aged2[[\n#'id_student',\n'code_module',\n'code_presentation',\n'gender',\n'region',\n'highest_education',\n'imd_band',\n'age_band',\n'num_of_prev_attempts',\n'studied_credits',\n'disability',\n'sum_click',\n'delay',\n'date_registration',\n'final_result'\n]]\n\nmodel_data2 = model_data.copy()\n#1. model: predicting failures among courses that have been finalized\n#model_data2 = model_data2[model_data2['final_result'].isin(['Pass', 'Fail', 'Distinction'])]\n#model_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 0))\n\n#2. model: predicting failures\/withdraws \nmodel_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 0, Withdrawn = 0))\n\n#3. model: predicting withdraws\n#model_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 1, Withdrawn = 0))\n\n# model 4: predicting failures\n#model_data2['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 0, Withdrawn = 1))\n\n# model 5: multilabel\n#['final_result'] = model_data2['final_result'].map(dict(Pass=1, Distinction=1, Fail = 0, Withdrawn = -1))\n\n\nmodel_data2.gender = model_data2.gender.map(dict(M=1, F=0))\nmodel_data2.disability = model_data2.disability.map(dict(Y=1, N=0))\n\ntext_columns = [\n'code_module',\n'code_presentation',\n'region',\n'highest_education',\n'imd_band',\n'age_band',\n'num_of_prev_attempts',\n'studied_credits'] \n\nmodel_data2 = pd.get_dummies(model_data2, columns=text_columns)\n\n#Clean data from 'na' values\nmodel_data2.sum_click = model_data2.sum_click.fillna(0)\nmodel_data2.date_registration = model_data2.date_registration.fillna(0)\nmodel_data2.delay = model_data2.delay.fillna(0)\nmodel_data2.reset_index(level=[0], inplace=True)\n\n#Splitting data into main training and testing(validation) datasets, 70\/30\nmodel_data_train3 = model_data2.sample(int(np.floor(model_data2.shape[0] * 0.9)), random_state=999)\nmodel_data_test3 = model_data2[np.logical_not(model_data2['index'].isin(model_data_train3['index']))]\n\nprint(model_data_train3[model_data_train3['final_result'] == 0].shape\n    , model_data_train3[model_data_train3['final_result'] == 1].shape\n     , model_data_test3.shape)\n","39a44e15":"# model 2: Oversampling\nmodel_data_train_fail = model_data_train3[model_data_train3['final_result'] == 0]\nmodel_data_train_pass = model_data_train3[model_data_train3['final_result'] == 1]\ndiff = model_data_train_fail.shape[0] - model_data_train_pass.shape[0]\n\nprint(model_data_train_fail.shape, model_data_train_pass.shape)\n\nmodel_data_train_new = pd.concat([model_data_train_pass, \n                                  model_data_train_fail, \n                                  model_data_train_pass.sample(diff, random_state = 999)])\nprint(model_data_train_new.shape)\n","16e3d84a":"#test_train_sample\nX_train, X_test, y_train, y_test = train_test_split(\n    model_data_train_new[model_data_train_new.columns.difference(['final_result'])],\n    model_data_train_new['final_result'], test_size=0.0, random_state=1)\n\n#Train the RF model\nrf3 = RandomForestClassifier(\n    n_estimators=1100, max_depth = 60, criterion = 'entropy', random_state = 0).fit(\n    X_train, y_train)\n\n# Run model on Test Validation data and see the accuracy\ntest_dt3 = model_data_test3[model_data_test.columns.difference(['final_result'])]\ntest_dt_y3 = model_data_test3.final_result\nacc = accuracy_score(test_dt_y3, rf3.predict(test_dt3))\nacc\n","21c08eb2":"# R O C\nfrom sklearn.svm.libsvm import predict_proba\n\nprobs = pd.DataFrame(rf3.predict_proba(test_dt3))\nprobs = probs[1]\ncutoffs = pd.DataFrame({'cutoff':probs.unique()}) \ncutoffs = cutoffs.sort_values('cutoff')\ntpr = cutoffs.apply(lambda cut: np.sum(np.logical_and(probs >= cut[0], model_data_test3.final_result == 1)) \/ np.sum(model_data_test3.final_result == 1), axis=1)\nfpr = cutoffs.apply(lambda cut: np.sum(np.logical_and(probs >= cut[0], model_data_test3.final_result == 0)) \/ np.sum(model_data_test3.final_result == 0), axis=1)\nstats = pd.DataFrame({'cutoff':cutoffs.cutoff, 'tpr':tpr, 'fpr':fpr})","ec663a87":"# R O C\nfrom sklearn.svm.libsvm import predict_proba\n\nprobs = pd.DataFrame(rf2.predict_proba(test_dt2))\nprobs = probs[1]\ncutoffs = pd.DataFrame({'cutoff':probs.unique()}) \ncutoffs = cutoffs.sort_values('cutoff')\n\ntpr = cutoffs.apply(lambda cut: np.sum(np.logical_and(probs >= cut[0], model_data_test2.final_result == 1)) \/ np.sum(model_data_test2.final_result == 1), axis=1)\nfpr = cutoffs.apply(lambda cut: np.sum(np.logical_and(probs >= cut[0], model_data_test2.final_result == 0)) \/ np.sum(model_data_test2.final_result == 0), axis=1)\nstats2 = pd.DataFrame({'cutoff':cutoffs.cutoff, 'tpr':tpr, 'fpr':fpr})\n\n#rf_df = pd.DataFrame({'prob':probs,'class':rf.predict(test_dt)})\n#pd.set_option('display.max_rows', 4000)\n#rf_df.sort_values('prob')\n\npd.set_option('display.max_rows', 10)\nrf_val = pd.DataFrame({'actual':model_data_test2.final_result,'predicted':rf2.predict(test_dt2)})\nrf_val[rf_val.actual == rf_val.predicted].shape[0] \/ rf_val.shape[0]\n\n#default_cutoff = 0.501250\n\ndefault_tpr = np.sum(np.logical_and(probs >= default_cutoff, model_data_test2.final_result == 1)) \/ np.sum(model_data_test2.final_result == 1)\ndefault_fpr = np.sum(np.logical_and(probs >= default_cutoff, model_data_test2.final_result == 0)) \/ np.sum(model_data_test2.final_result == 0)\n#roc_curve(stats)\nfigure = plt.figure(figsize=(14,11))\nplt.plot(stats2.fpr, stats2.tpr, '-', marker='o', markersize=1, color = \"navy\", label=\"Prediction: Passing \/ Not Passing the course. Accuracy ~81 %\")\nplt.plot(stats.fpr, stats.tpr, '-', marker='o', markersize=1, color = \"blue\", label = \"Predictio: Complete \/ Withdrawn of the course. Accuracy ~79 %\")\n#plt.plot(default_fpr, default_tpr, color='crimson', marker='o', markersize=8)\n#plt.annotate('', xy = (default_fpr, default_tpr), xytext=(0.5, 0.75), color=\"blacredk\", size=15)\nplt.plot([0,1],[0,1],'--',linewidth=1, markersize=2, color = \"crimson\")\nplt.legend(loc=4, fontsize='x-large')\nplt.show()\n","07f9de2c":"<H1> Scenario 2: Predict Withdrawns <\/h1>\n<h3> RF model binary label <\/h3>","432855e4":"<h1> Data loading and preparation <\/h1>","8658492a":"<h3> ROC dataframe for Passing the course <h3>","5554e03b":"<h1> Scenario 3: Predict passing the course <\/h1> <h3>\nRF model binary label <\/h3>","0e686914":"<h1> ROC Curve and Plotting <\/h1>","8edad6a3":"<h1>Scenario 1: RF multilabel model. <\/h1>"}}