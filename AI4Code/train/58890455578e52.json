{"cell_type":{"2a1ce268":"code","e2b9fe7f":"code","653ea555":"code","1d5d20be":"code","63514dc7":"code","75627086":"code","0293f74e":"code","5c1f1285":"code","7a39f190":"code","46873c46":"code","2b79d452":"code","bf55ffae":"code","f4df266d":"code","70a38063":"code","c7905ff3":"code","6e3c72c3":"code","916e9459":"code","e7b7fe47":"code","2273a6ee":"code","5f666ebc":"code","c7edae58":"code","df08c34b":"code","b7c174e6":"code","0537bf50":"code","d454cbf4":"code","5f2f5857":"markdown","771af3f5":"markdown","88d51b37":"markdown","0bb8f348":"markdown","b884d3e2":"markdown","3e0200ab":"markdown","9ef4eecf":"markdown","574bb037":"markdown","f47c8573":"markdown","bcf9efee":"markdown","c36d3d12":"markdown","900a28db":"markdown","8cd7ac06":"markdown","0ba524fc":"markdown","e8964886":"markdown","691d8069":"markdown","2f5ddd5f":"markdown","31c7a5b5":"markdown"},"source":{"2a1ce268":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n# Ignore warning\nimport warnings\nwarnings.filterwarnings('ignore')","e2b9fe7f":"import pandas as pd\nimport numpy as np\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nfrom sklearn import preprocessing\n\nfrom sklearn import tree","653ea555":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\nprint(train.columns.values)","1d5d20be":"train.head()","63514dc7":"plt.figure(figsize=(15,7))\nsns.heatmap(train.isnull(), cbar=False, cmap=\"viridis\")","75627086":"plt.figure(figsize=(15,7))\nsns.heatmap(test.isnull(), cbar=False, cmap=\"viridis\")","0293f74e":"# dataframe \ndf = pd.concat([train, test], axis=0, sort=False)","5c1f1285":"corr_df = df.corr()\nprint(corr_df)\nfig, axs = plt.subplots(figsize=(12, 8))\nsns.heatmap(corr_df).set_title(\"Correlation Map\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});","7a39f190":"sns.set(style=\"ticks\", color_codes=True)\ng = sns.pairplot(data=df[columns], kind=\"reg\", plot_kws={'line_kws':{'color':'red'}}, corner=True)","46873c46":"columns = ['Pclass', 'Sex','Embarked','SibSp', 'Parch','Survived']\n\nplt.figure(figsize=(16, 14))\nsns.set(font_scale= 1.2)\nsns.set_style('ticks')\n\nfor i, feature in enumerate(columns):\n    plt.subplot(3, 3, i+1)\n    sns.countplot(data=df, x=feature, hue='Survived', palette='Paired')\n    \nsns.despine()","2b79d452":"columns = ['Pclass', 'Sex','Embarked','SibSp', 'Parch','Survived']\n\nplt.figure(figsize=(16, 14))\nsns.set(font_scale= 1.2)\nsns.set_style('ticks')\n\nfor i, feature in enumerate(columns):\n    plt.subplot(3, 3, i+1)\n    sns.countplot(data=train, x=feature, hue='Sex', palette='BrBG')\n    \nsns.despine()","bf55ffae":"fig, axs = plt.subplots(figsize=(10, 5))\nsns.histplot(data=df, x='Age').set_title(\"Age distribution\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});\nsns.despine()","f4df266d":"ageBin=pd.cut(df['Age'],7)\n\nfig, axs = plt.subplots(figsize=(15, 5))\nsns.countplot(x=ageBin, hue='Survived', data=df)\naxs.set_title(\"Age Bins\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});\nsns.despine()","70a38063":"df.groupby(by=\"Pclass\", dropna=False).agg('mean')","c7905ff3":"sns.set_style(\"ticks\")\ndf['Cabin'].fillna('Z',inplace=True)\naxs = sns.countplot(x=df['Cabin'].str.get(0), hue=\"Pclass\", data=df)\nplt.title('Pclass cabin distribution', fontsize=20)\nplt.xlabel('Cabin', fontsize=20)\nplt.ylabel('Count', fontsize=20)\nplt.show()","6e3c72c3":"sns.set_style(\"ticks\")\naxs = sns.catplot(x=\"Survived\", y=\"Fare\", hue=\"Pclass\", kind=\"box\", data=df,\n                 height = 5, aspect = 1.5, legend=False)\naxs.set(ylim=(0, 300))\nplt.title('Passager paid for their ticket', fontsize=20)\nplt.xlabel('Survived', fontsize=20)\nplt.ylabel('Fare', fontsize=20)\nplt.legend(title='Pclass')\nplt.show()","916e9459":"df.groupby(by=[\"Survived\",\"Pclass\"], dropna=True).agg('mean')","e7b7fe47":"# log transformation\nauxfare = np.log(df['Fare']+1).round()\n\nfig, axs = plt.subplots(figsize=(15, 5))\nsns.despine()\n\naxs = plt.subplot(1, 2, 1)\nsns.kdeplot(x=df['Fare'], hue='Survived', data=df, shade=True, palette='Paired')\naxs.set_title(\"Fare Bins\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});\naxs.set(xlim=(0, 250))\n\naxs = plt.subplot(1, 2, 2)\nsns.kdeplot(x=auxfare, hue='Survived',data=df, shade=True, palette='Paired')\naxs.set_title(\"Fare Bins(log transform)\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});","2273a6ee":"fig, axs = plt.subplots(figsize=(15, 5))\ndf['Cabin'].fillna('Z',inplace=True)\nsns.countplot(x=df['Cabin'].str.get(0), hue='Survived', data=df)\naxs.set_title(\"Cabin Bins\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});\nsns.despine()","5f666ebc":"isAlone = lambda cols: 1 if not cols[0] and not cols[1] else 0\ndf[\"isAlone\"] = df[[\"Parch\", \"SibSp\"]].apply(isAlone, axis=1)\n\ng = sns.FacetGrid(df, col='Survived', col_wrap=2)\ng.map(plt.hist, 'isAlone', bins=2)","c7edae58":"df_train = train[['PassengerId','Sex','Pclass','Age','Survived','Embarked','Cabin','Fare','Parch','SibSp','Name','Ticket']]\ndf_test = test[['PassengerId','Sex','Pclass','Age','Embarked','Cabin','Fare','Parch','SibSp', 'Name','Ticket']]\n\n# Fill n\/a with average age by pessagers class\nimputeAge = lambda cols: list([39,30,25])[int(cols[1]-1)] if pd.isnull(cols[0]) else cols[0]    \ndf_train[\"Age\"] = df_train[[\"Age\", \"Pclass\"]].apply(imputeAge, axis=1)\ndf_test[\"Age\"] = df_test[[\"Age\", \"Pclass\"]].apply(imputeAge, axis=1)\n\ndef ageBinning(dataset):\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n    return dataset\n\ndf_train = ageBinning(df_train)\ndf_test = ageBinning(df_test)\n    \ndef titleBinning(dataset):\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n                                                 'Don', 'Dr', 'Major', 'Rev', 'Sir', \n                                                 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    dataset['Title'] = dataset['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5})\n    dataset['Title'] = dataset['Title'].fillna(0)\n    return dataset\n\ndf_train = titleBinning(df_train)\ndf_test = titleBinning(df_test)\n\n# Identify single onboarding pessagers\nisAlone = lambda cols: 1 if not cols[0] and not cols[1] else 0\ndf_train[\"isAlone\"] = df_train[[\"Parch\", \"SibSp\"]].apply(isAlone, axis=1)\ndf_test[\"isAlone\"] = df_test[[\"Parch\", \"SibSp\"]].apply(isAlone, axis=1)","df08c34b":"# Fill n\/a with non-existing cabin label 'Z'\ndf_train['Cabin'].fillna('Z',inplace=True)\ndf_test['Cabin'].fillna('Z',inplace=True)\n\n# Get Cabin Label\ndf_train['Cabin'] = df_train['Cabin'].str.get(0)\ndf_test['Cabin'] = df_test['Cabin'].str.get(0)\n\n# Labeling\nle = preprocessing.LabelEncoder()\ndef labelCol(col):\n    le.fit(col)\n    return le.transform(col)\n\ndf_train['Sex'] = labelCol(df_train['Sex'])\ndf_test['Sex'] = labelCol(df_test['Sex'])\ndf_train['Embarked'] = labelCol(df_train['Embarked'])\ndf_test['Embarked'] = labelCol(df_test['Embarked'])\ndf_train['Cabin'] = labelCol(df_train['Cabin'])\ndf_test['Cabin'] = labelCol(df_test['Cabin'])\n\n# Fill n\/a\n# df_train['Embarked'].fillna(df_train['Embarked'].median()[0],inplace=True)\ndf_train.Embarked.fillna(df_train.Embarked.median(), inplace = True)\n\ndf_test[\"Fare\"].fillna(df_test.groupby(['Pclass', 'Sex'])['Fare'].transform(\"median\"), inplace=True)\n# Power law fits better\ndf_train['Fare'] = np.log(df_train['Fare']+1).round()\ndf_test['Fare'] = np.log(df_test['Fare']+1).round()\n\ndf_train['Age*Class'] = df_train.Age * df_train.Pclass\ndf_test['Age*Class'] = df_test.Age * df_test.Pclass\n\ndf_train['Ticket'] = df_train.Ticket.str.split().apply(lambda x : 0 if x[:][-1] == 'LINE' else x[:][-1])\ndf_train.Ticket = df_train.Ticket.values.astype('int64')\ndf_test['Ticket'] = df_test.Ticket.str.split().apply(lambda x : 0 if x[:][-1] == 'LINE' else x[:][-1])\ndf_test.Ticket = df_test.Ticket.values.astype('int64')","b7c174e6":"import xgboost as xgb\nimport sklearn\nimport scipy\n\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\n\ntarget = df_train[\"Survived\"].values\ntrain_features = df_train[[\"Pclass\", \"Sex\", \"Age\",'Embarked','Cabin','Fare','Title','isAlone','Age*Class','Ticket']].values\ntest_features = df_test[[\"Pclass\", \"Sex\", \"Age\",\"Embarked\",'Cabin','Fare','Title','isAlone','Age*Class','Ticket']].values\n\nX_train, X_val, y_train, y_val = train_test_split(\n    train_features,target , test_size=0.2, random_state=0) \n\nclf = xgb.XGBClassifier(seed=0, nthread=1)\nclf = clf.fit(X_train, \n              y_train, eval_set=[(X_train, y_train),\n                                 (X_val, y_val)],\n              verbose=False)\n\ny_pred = clf.predict(test_features)\n#y_pred = clf.predict(test_features, ntree_limit=clf.booster().best_ntree_limit)\ny_pred_probs = clf.predict_proba(test_features)","0537bf50":"y_pred","d454cbf4":"submission = pd.DataFrame({\n        \"PassengerId\": df_test[\"PassengerId\"],\n        \"Survived\": y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)","5f2f5857":"## Training and Fitting","771af3f5":"To handle the missing value of age, we impute it by the average age that people purphrase on a Pclass\n- Pclass 1: ~39\n- Pclass 2: ~30\n- Pclass 3: ~25","88d51b37":"### Survival Factors","0bb8f348":"### Pclass\nMajority of first class passengers were allocated at cabin C,E,D,A,B","b884d3e2":"### Fare Bins\nDon't just split fare in equally distributed bin, they're long-tail distribution. Preferably doing a log transformation or manually spliting with a unequally sized range could yield a better differentiation between the Fare and Survival Rate","3e0200ab":"## Data preprocessing","9ef4eecf":"### Fare\nPeople who survived in the disaster not only bought a first class ticket, but also paid a averagely higher fare","574bb037":"### Correlations","f47c8573":"## Exploratory Data Analysis\n- Sex\n- Age\n- Fare\n- Pclass\n- Cabin\n- Parch, SibSp","bcf9efee":"## Missing values checking","c36d3d12":"## Updates\n- May 2 | Inital XGBoost Model (Top 89%)\n- May 3 | Feature Engineering (Top 67%)\n- May 4 | More Feature Engineering (Top 7%)\n- May 7 | Basic EDA, added 'ticket' feature (Top 4%)\n- ... More EDA to be added\n\n## Features\n- Pclass: Class of the Passenger\n- Name: Passenger name(title + first name + last name)\n- Sex: M\/F\n- Age: Passenger age\n- SibSp: #Spouses or Siblings\n- ParCh: #Children or Parents\n- Ticket: Ticket identifier\n- Fare: USD paid, Numeric\n- Cabin: Cabin Number\n- Embark: Cock embarked: Southhampton, Queenstown, and Cherbourg","900a28db":"### Age\nSeem teenage has a higher odds to survive in the disaster","8cd7ac06":"# Reference\n#### EDA\nhttps:\/\/www.kaggle.com\/truesight\/predicting-titanic-survivor\n- complihensive visualization\n\nhttps:\/\/www.kaggle.com\/lourenswalters\/ii-titanic-exploratory-data-analysis-0-80\n#### Feature Engineering\nhttps:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\n- verbose feature engineering\n\nhttps:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial\n- top 3% example\n\nhttps:\/\/www.kaggle.com\/javiervallejos\/titanic-top-3\n#### Hyperparameter Tuning\nhttps:\/\/www.kaggle.com\/aditiani\/survive-from-titanic-using-random-forest-top-17\n#### XGBoost Tutorial\nhttps:\/\/www.kaggle.com\/feralhog\/tutorial-xgboost\n\nhttps:\/\/www.slideshare.net\/JaroslawSzymczak1\/gradient-boosting-in-practice-a-deep-dive-into-xgboost","0ba524fc":"Average Fare Cost for First Class Passagers\n- Survived: ~\\$95.6\n- Died: ~\\$64.7","e8964886":"### Sex","691d8069":"### Feature Engeering","2f5ddd5f":"### Parch, SibSp -> is alone\nWe reduced Parch and SibSp into new feature isAlone. A passager who travel alone has a lower survival rate.","31c7a5b5":"### Cabin Bins\nAlthough most of the Cabin label are missing, we can still surmise that whose Cabin in 'B, C, D, E, F' are more likely to survive."}}