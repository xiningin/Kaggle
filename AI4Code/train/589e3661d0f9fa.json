{"cell_type":{"dccc545b":"code","96d7b8ad":"code","50bf1131":"code","acd69009":"code","03a8041b":"code","c3f27e0e":"code","b61883ec":"code","0321c877":"code","1e802dc8":"code","f423d90d":"code","907bc72d":"code","c57640f6":"code","1722fa50":"code","8288deec":"code","ebc5df9f":"code","d71c980c":"code","091a5b22":"code","eb29215c":"code","a54e85fa":"code","62647183":"markdown","95592550":"markdown","e739857f":"markdown","fff76776":"markdown","7daf35ee":"markdown","a499f820":"markdown","39d734a3":"markdown"},"source":{"dccc545b":"import pandas as pd\nimport numpy as np ","96d7b8ad":"df = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')","50bf1131":"df.head()","acd69009":"targets = pd.get_dummies(df.pop('label')).values\ndata = df.values","03a8041b":"targets.shape","c3f27e0e":"data.shape","b61883ec":"input_shape = (28,28, 1) # 28*28 = 784","0321c877":"from sklearn.preprocessing import minmax_scale\ndata = minmax_scale(data)","1e802dc8":"data = np.reshape(data,(-1, 28, 28,1))","f423d90d":"data.shape","907bc72d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data, targets , test_size = 0.2, random_state=0)","c57640f6":"import tensorflow as tf","1722fa50":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n# Creating a Sequential Model and adding the layers\nmodel = Sequential()\nmodel.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten()) # Flattening the 2D arrays for fully connected layers\nmodel.add(Dense(128, activation=tf.nn.relu))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(targets.shape[1],activation=tf.nn.softmax))","8288deec":"model.compile(optimizer='adam', \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=10, batch_size=20)","ebc5df9f":"loss, accuracy = model.evaluate(X_test, y_test)","d71c980c":"print(f\"Accuracy : {accuracy}\")","091a5b22":"y_pred = model.predict(X_test)","eb29215c":"y_pred = np.argmax(y_pred, axis =1)\ny_test = np.argmax(y_test, axis =1)","a54e85fa":"from sklearn.metrics import confusion_matrix, plot_confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_recall_fscore_support\nimport matplotlib.pyplot as plt\n\ncm = confusion_matrix(y_test, y_pred)\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(cm)\nplt.title('Confusion matrix of the classifier')\nfig.colorbar(cax)\n\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\nprint(\"Accuracy :\" + str(round(accuracy_score(y_test, y_pred),4)))\np, r, f, s = precision_recall_fscore_support(y_test, y_pred, average='macro')\nprint(round(p,4),round(r,4),round(f,4))","62647183":"### Step 1b : Preprocessing the data\nThis step is important to scale our data to nominal values for Classification problem, We only scale data and not the targets. Separating the data (image pixels) from the target values is also done","95592550":"### Reshape data","e739857f":"## STEP 4:  EVALUATE MODEL PERFORMANCE","fff76776":"## STEP 2 : SPLITTING THE DATA INTO TRAIN AND TEST SET ","7daf35ee":"## STEP 1 : LOAD THE DATASET","a499f820":"### Step 1a : Visualilzing the dataset","39d734a3":"## STEP 3:  APPLYING THE REGRESSOR"}}