{"cell_type":{"4ee7bb43":"code","ff27c605":"code","46c624a3":"code","998b910d":"code","31db1d20":"code","4fb6fdba":"code","3f83ada9":"code","8f2ffa5a":"code","657e2d21":"code","d9baffda":"code","9e2554f6":"code","222fdb2c":"code","ff4e42e6":"code","163af124":"code","5636eb06":"code","45047ac8":"code","4d0e7852":"markdown","5bcff042":"markdown","7f4ea40b":"markdown","635afa45":"markdown","9aadeec3":"markdown","a4a28cb1":"markdown","75b0b3e4":"markdown"},"source":{"4ee7bb43":"import numpy as np \nimport pandas as pd \nfrom pathlib import Path\nimport os.path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D,Lambda, Dropout, InputLayer, Input\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.applications.xception import preprocess_input\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import Sequential","ff27c605":"# Create a list with the filepaths for training and testing\ndir_train = Path('..\/input\/skin-cancer-malignant-vs-benign\/train')\ntrain_filepaths = list(dir_train.glob(r'*\/*.jpg'))\n\ndir_test = Path('..\/input\/skin-cancer-malignant-vs-benign\/test')\ntest_filepaths = list(dir_test.glob(r'*\/*.jpg'))","46c624a3":"def proc_img(filepath):\n    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n    \"\"\"\n\n    labels = [str(filepath[i]).split(\"\/\")[-2] \\\n              for i in range(len(filepath))]\n    \n\n   \n\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    # Concatenate filepaths and labels\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1,random_state=0).reset_index(drop = True)\n    \n    return df\ntrain = proc_img(train_filepaths)\ntest = proc_img(test_filepaths)\n\nprint(f'Number of pictures in the training dataset: {train.shape[0]}\\n')\nprint(f'Number of pictures in the test dataset: {test.shape[0]}\\n')\nprint(f'Number of different labels: {len(train.Label.unique())}\\n')\nprint(f'Labels: {train.Label.unique()}')","998b910d":"pd.set_option('display.max_colwidth',200)","31db1d20":"train.head()","4fb6fdba":"#Extracting different classes\nclasses = sorted(train['Label'].unique())\nn_classes = len(classes)\nprint(f'number of class: {n_classes}')","3f83ada9":"classes_to_num = dict(zip(classes,range(n_classes)))","8f2ffa5a":"# Display some pictures of the dataset\nfig, axes = plt.subplots(nrows=4, ncols=6, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(train.Filepath[i]))\n    ax.set_title(train.Label[i], fontsize = 15)\nplt.tight_layout(pad=0.5)\nplt.show()","657e2d21":"#Function to load and convert images to array\n\ndef images_to_array(data_dir,df,image_size):\n    image_names = df['Filepath']\n    image_labels = df['Label']\n    data_size = len(image_names)\n    \n    X = np.zeros([data_size,image_size[0],image_size[1],image_size[2]],dtype = np.uint8)\n    y = np.zeros([data_size,1],dtype = np.uint8)\n    \n    for i in range(data_size):\n        img_name = image_names[i]\n        img_pixels = load_img(img_name,target_size=image_size)\n        X[i] = img_pixels\n        y[i] = classes_to_num[image_labels[i]]\n        \n    y = to_categorical(y)\n    ind = np.random.permutation(data_size)\n    X = X[ind]\n    y = y[ind]\n    print('Ouptut Data Size: ', X.shape)\n    print('Ouptut Label Size: ', y.shape)\n    return X, y  ","d9baffda":"#Selecting image size according to pretrained models\nimg_size = (299,299,3)\nX, y = images_to_array(dir_train,train,img_size)","9e2554f6":"def get_features(model_name, data_preprocessor,weight, input_size, data):\n    #Prepare pipeline.\n    input_layer = Input(input_size)\n    preprocessor = Lambda(data_preprocessor)(input_layer)\n    \n    base_model = model_name(weights=weight,\n                            include_top=False,\n                            input_shape=input_size)(preprocessor)\n    \n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    \n    #Extract feature.\n    feature_maps = feature_extractor.predict(data, batch_size=128, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps","222fdb2c":"#Extracting features using Xception\nXception_preprocessor = preprocess_input\nXception_features = get_features(Xception,\n                                  Xception_preprocessor,\n                                 '..\/input\/keras-pretrained-models\/Xception_NoTop_ImageNet.h5',\n                                  img_size, X)","ff4e42e6":"#Callbacks\nEarlyStop_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","163af124":"#Adding the final layers to the above base models where the actual classification is done in the dense layers\n#Building Model\nmodel = Sequential()\nmodel.add(InputLayer(Xception_features.shape[1:]))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(2,activation='sigmoid'))\n\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel.summary()\n\n# Training the CNN on the Train features and evaluating it on the val data\nhistory = model.fit(Xception_features,y,validation_split=0.20,callbacks=my_callback, epochs = 50, batch_size=128)","5636eb06":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","45047ac8":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","4d0e7852":"<div style=\"background-color:gray;\">\n    <h1><center>Importing Libraries<\/center><\/h1>\n<\/div>","5bcff042":"<div style=\"background-color:gray;\">\n    <h1><center>Importing The Dataset<\/center><\/h1>\n<\/div>","7f4ea40b":"<div style=\"background-color:gray;\">\n    <h1><center>Image Visualization<\/center><\/h1>\n<\/div>","635afa45":"<div style=\"background-color:gray;\">\n    <h1><center>Converting Images to Array<\/center><\/h1>\n<\/div>","9aadeec3":"<div style=\"background-color:gray;\">\n    <h1><center>Model Building<\/center><\/h1>\n<\/div>","a4a28cb1":"<div style=\"background-color:gray;\">\n    <h1><center>Extracting features using Xception<\/center><\/h1>\n<\/div>","75b0b3e4":"This dataset contains a balanced dataset of images of benign skin moles and malignant skin moles."}}