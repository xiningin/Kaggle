{"cell_type":{"afe904fd":"code","ffd4ac7d":"code","a135fa24":"code","4d01850d":"code","2220e58c":"code","82019875":"code","02fe2a72":"code","f0c4e9f8":"code","94a066f5":"code","0354584a":"code","b356ae7a":"code","38a3c7ae":"code","bccee8b0":"markdown","293550ea":"markdown","dfa15acd":"markdown","323b497a":"markdown","e162fabb":"markdown","4d5e81e1":"markdown"},"source":{"afe904fd":"from tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\n#from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n#from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nfrom tensorflow.keras.applications.nasnet import NASNetLarge, preprocess_input\n#from tensorflow.keras.applications.efficientnet import EfficientNetB7, preprocess_input\n#from tensorflow.keras.applications.xception import Xception, preprocess_input\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\n%matplotlib inline","ffd4ac7d":"# Alguns par\u00e2metros para leitura do dataset\n#im_shape = (299,299)\nim_shape = (331,331)\n\nTRAINING_DIR = '..\/input\/amazon-fruits-small\/ds_frutas_am\/train'\nTEST_DIR = '..\/input\/amazon-fruits-small\/ds_frutas_am\/test'\n\nseed = 10\n\nBATCH_SIZE = 16","a135fa24":"#Using keras ImageGenerator and flow_from_directoty\n\n# Image dataset without augmentation\n#data_generator = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n# With augmentation\ndata_generator = ImageDataGenerator(\n        validation_split=0.2,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        preprocessing_function=preprocess_input,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\nval_data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,validation_split=0.2)","4d01850d":"# Generator para parte train\ntrain_generator = data_generator.flow_from_directory(TRAINING_DIR, target_size=im_shape, shuffle=True, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n# Generator para parte valida\u00e7\u00e3o\nvalidation_generator = val_data_generator.flow_from_directory(TRAINING_DIR, target_size=im_shape, shuffle=False, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\n\n# Generator para dataset de teste\ntest_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\ntest_generator = test_generator.flow_from_directory(TEST_DIR, target_size=im_shape, shuffle=False, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE)\n\nnb_train_samples = train_generator.samples\nnb_validation_samples = validation_generator.samples\nnb_test_samples = test_generator.samples\nclasses = list(train_generator.class_indices.keys())\nprint('Classes: '+str(classes))\nnum_classes  = len(classes)","2220e58c":"base_model = NASNetLarge(weights='imagenet', include_top=False, input_shape=(im_shape[0], im_shape[1], 3), pooling=max)\n\nx = base_model.output\nx = Flatten()(x)\nx = Dense(100, activation='relu')(x)\nx = Dropout(0.2)(x)\n\npredictions = Dense(num_classes, activation='softmax', kernel_initializer='random_uniform')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freezing pretrained layers\nfor layer in base_model.layers:\n    layer.trainable=False\n    \noptimizer = Adam()\nmodel.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])","82019875":"epochs = 40\n\n# Saving the best model\ncallbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='model.h5',\n        monitor='val_loss', save_best_only=True, verbose=1),\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,verbose=1)\n]\n\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch=nb_train_samples \/\/ BATCH_SIZE,\n        epochs=epochs,\n        callbacks = callbacks_list,\n        validation_data=validation_generator,\n        verbose = 1,\n        validation_steps=nb_validation_samples \/\/ BATCH_SIZE)","02fe2a72":"#Vamos ver como foi o treino?\nimport matplotlib.pyplot as plt\n\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs_x = range(1, len(loss_values) + 1)\nplt.figure(figsize=(10,10))\nplt.subplot(2,1,1)\nplt.plot(epochs_x, loss_values, 'bo', label='Training loss')\nplt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation Loss and Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n#plt.legend()\nplt.subplot(2,1,2)\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nplt.plot(epochs_x, acc_values, 'bo', label='Training acc')\nplt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n#plt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.legend()\nplt.show()","f0c4e9f8":"from tensorflow.keras.models import load_model\n# Load the best saved model\nmodel = load_model('model.h5')","94a066f5":"# Using the validation dataset\nscore = model.evaluate_generator(validation_generator)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])","0354584a":"# Using the test dataset\nscore = model.evaluate_generator(test_generator)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","b356ae7a":"import itertools\n\n#Plot the confusion matrix. Set Normalize = True\/False\ndef plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","38a3c7ae":"# Some reports\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\n#Confution Matrix and Classification Report\nY_pred = model.predict_generator(test_generator)#, nb_test_samples \/\/ BATCH_SIZE, workers=1)\ny_pred = np.argmax(Y_pred, axis=1)\ntarget_names = classes\n\n#Confution Matrix\ncm = confusion_matrix(test_generator.classes, y_pred)\nplot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\nprint('Classification Report')\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","bccee8b0":"# Imports de Libs","293550ea":"This is a simple example using Transfer Learning for an image recognition problem.","dfa15acd":"# Transfer Learning from a Deep Model","323b497a":"# Lendo o dataset","e162fabb":"Como tentativa para melhorar o modelo,foi-se testado outros modelos fora o InceptionResNetV2, e para a conclus\u00e3o desta atividade foi escolhido o modelo da NASNetLarge e adicionando um Dropout() para auxiliar na redu\u00e7\u00e3o de overfitting. Al\u00e9m disso, para obter uma melhor resposta do modelo, foram usadas 40 \u00e9pocas para que conseguisse chegar num valor de acur\u00e1cia aceit\u00e1vel.","4d5e81e1":"### "}}