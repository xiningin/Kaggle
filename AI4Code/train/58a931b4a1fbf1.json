{"cell_type":{"a4a0fca6":"code","0cdece11":"code","1c960418":"code","fd8dc056":"code","5064462b":"code","5fbfc884":"code","4beee445":"code","6aaaa538":"code","e7e6d339":"code","76b57b46":"code","fb7c9df2":"code","67e72c5b":"code","9a4ade25":"code","4bc0651a":"code","b3c0022e":"code","365ff39e":"code","b3461ff4":"code","e7b57e98":"code","c4026c6a":"code","6398fb10":"code","a72c6d34":"code","567d57cb":"code","5ebba49f":"code","c2af0cb6":"code","2c094e7b":"code","9aa368ed":"code","a273e64e":"code","c0a1c2c4":"code","1e4e8821":"code","727baf6e":"code","73be170a":"code","b102239f":"code","cd079b34":"markdown","fa66e89d":"markdown","2d431a93":"markdown","a4a0d91f":"markdown"},"source":{"a4a0fca6":"#Text Classification\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\n\n","0cdece11":"import pandas as pd","1c960418":"train_data = pd.read_csv(\"..\/input\/train_data.csv\")\ntrain_label = pd.read_csv(\"..\/input\/train_label.csv\")","fd8dc056":"train_data.head()","5064462b":"train_label.head()","5fbfc884":"train_label.loc[train_label['id']==122885]","4beee445":"train_data.loc[train_data['id']==122885]","6aaaa538":"train_data.isnull().sum()","e7e6d339":"test_data = pd.read_csv(\"..\/input\/test_data.csv\")","76b57b46":"test_data.head()","fb7c9df2":"train_label.isnull().sum()","67e72c5b":"test_data.info()","9a4ade25":"train_data.info()","4bc0651a":"sample_sub = pd.read_csv(\"..\/input\/sample_submission.csv\")","b3c0022e":"sample_sub.head()","365ff39e":"train_label['label'].unique()","b3461ff4":"training_data = pd.merge(train_data,train_label)\n","e7b57e98":"training_data.head()","c4026c6a":"#2. Noise Removal\n#Lower case\ntraining_data['text'] = training_data['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ntraining_data['text'].head()","6398fb10":"#Remove punctuation\ntraining_data['text'] = training_data['text'].str.replace('[^\\w\\s]','')\ntraining_data['text'].head()","a72c6d34":"#commonly occuring words in our text\nfreq = pd.Series(' '.join(training_data['text']).split()).value_counts()[:10]\nfreq","567d57cb":"#remove these words\nfreq = list(freq.index)\ntraining_data['text'] = training_data['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\ntraining_data['text'].head()","5ebba49f":"#rare word \nfreq = pd.Series(' '.join(training_data['text']).split()).value_counts()[-10:]\nfreq","c2af0cb6":"freq = list(freq.index)\ntraining_data['text'] = training_data['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\ntraining_data['text'].head()","2c094e7b":"#Data Visualization\nimport matplotlib.pyplot as plt\nfig = plt.figure(figsize=(8,6))\ntraining_data.groupby('label').text.count().plot.bar(ylim=0)\nplt.show()","9aa368ed":"# Feature Engineering\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\ncount_vect = CountVectorizer()","a273e64e":"X_train_counts = count_vect.fit_transform(training_data['text'])\ntf_transformer = TfidfTransformer().fit(X_train_counts)\nX_train_transformed = tf_transformer.transform(X_train_counts)","c0a1c2c4":"X_test_counts = count_vect.transform(test_data['text'])\nX_test_transformed = tf_transformer.transform(X_test_counts)","1e4e8821":"#Label Encoding\nlabels = LabelEncoder()\ny_train_labels_fit = labels.fit(training_data['label'])\ny_train_lables_trf = labels.transform(training_data['label'])\n\nprint(labels.classes_)","727baf6e":"# Model Fitting\nfrom sklearn.svm import LinearSVC\nfrom sklearn.calibration import CalibratedClassifierCV\n\nlinear_svc = LinearSVC()\nclf = linear_svc.fit(X_train_transformed,y_train_lables_trf)\n\ncalibrated_svc = CalibratedClassifierCV(base_estimator=linear_svc,\n                                        cv=\"prefit\")\n\ncalibrated_svc.fit(X_train_transformed,y_train_lables_trf)\npredicted = calibrated_svc.predict(X_test_transformed)\nto_predict = test_data['text']\np_count = count_vect.transform(to_predict)\np_tfidf = tf_transformer.transform(p_count)","73be170a":"# prediction\npd.DataFrame(calibrated_svc.predict_proba(p_tfidf), columns=labels.classes_)","b102239f":"pd.DataFrame(calibrated_svc.predict_proba(p_tfidf)*100, columns=labels.classes_)","cd079b34":"These are the 15 unique labels dataset has","fa66e89d":"id is the feature which map the text in train_data to label in train_label","2d431a93":"Each id has different labels but not at the same time.Hence This is a multiclass problem.","a4a0d91f":"There are different text correspond to unique 15 labels."}}