{"cell_type":{"e33ecc26":"code","f16b27de":"code","fffacd68":"code","815f43e1":"code","fb3ac90e":"code","7cd0244e":"code","00b7cd00":"code","0a0f5370":"code","abcf637e":"code","9e2ba211":"code","27d881d0":"code","ffa4f606":"code","932fe5b3":"code","04e18556":"code","2258f53a":"code","feff04db":"code","9f0d61e1":"code","56fa6e4a":"code","6e656f08":"code","d6b38153":"code","c9ac95e4":"code","c506892d":"code","9e93c72c":"code","17881007":"code","698dbada":"code","8061db1e":"code","7826145a":"code","c5ef11dd":"code","2f3678a1":"code","01e102e8":"code","abf6f1a5":"code","0087a12c":"code","ac6145fe":"code","4d42d827":"code","8007be4e":"code","37255720":"code","be454461":"code","512590ec":"code","3c6eace2":"code","b7ca1b44":"code","69c357be":"code","8c9dd98c":"code","47af2332":"markdown","da3be471":"markdown","2ff5ebbb":"markdown","5731d0a0":"markdown","f763e140":"markdown","76770e05":"markdown","a5fe8c05":"markdown","437e71dc":"markdown","7d2981b5":"markdown"},"source":{"e33ecc26":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f16b27de":"df = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-3\/train.csv', sep=',')\ndf['Date'] = pd.to_datetime(df['Date'])\ntrain_last_date = df.Date.unique()[-1]\nprint(f\"Dataset has training data untill : {train_last_date}\")","fffacd68":"\nwpop = pd.read_csv('\/kaggle\/input\/worldpopulationbyage\/WPP2019_PopulationByAgeSex_Medium.csv')\n\ncountry_mapper = {\n'Iran (Islamic Republic of)' : \"Iran\",\n'Bolivia (Plurinational State of)' : 'Bolivia',\n'Brunei Darussalam' : 'Brunei',\n'Congo' : 'Congo (Kinshasa)',\n'Democratic Republic of the Congo' : \"Congo (Brazzaville)\",\n\"C\u00f4te d'Ivoire\": \"Cote d'Ivoire\",\n\"Gambia\" : \"Gambia, The\",\n\"Republic of Korea\": \"Korea, South\",\n\"Republic of Moldova\": \"Moldova\",\n'R\u00e9union' : \"Reunion\",\n'Russian Federation' : \"Russia\",\n'China, Taiwan Province of China' : \"Taiwan*\",\n\"United Republic of Tanzania\": \"Tanzania\",\n\"Bahamas\": \"The Bahamas\",\n\"Gambia\": \"The Gambia\",\n\"United States of America (and dependencies)\" : \"US\",\n\"Venezuela (Bolivarian Republic of)\" : \"Venezuela\",\n'Viet Nam' : \"Vietnam\"}\n\ndef rename_countries(x, country_dict):\n    new_name = country_dict.get(x)\n    if new_name is not None:\n        #print(x, \"-->\", new_name)\n        return new_name\n    else:\n        return x\n\nwpop = wpop[wpop['Time']==2020].reset_index(drop=True)\nwpop['Location'] = wpop.Location.apply(lambda x : rename_countries(x, country_mapper))\nclean_wpop = wpop[wpop['Location'].isin(df['Country_Region'].unique())].reset_index()\n\npopulation_distribution = []\nfor country, gpdf in clean_wpop.groupby(\"Location\"):\n    aux = {f\"age_{age_grp}\": tot for age_grp, tot in zip(gpdf.AgeGrp, gpdf.PopTotal)}\n    aux[\"Country_Region\"] = country\n    population_distribution.append(aux)\n    \ndf_pop_distrib = pd.DataFrame(population_distribution)\n\n# add missing countries with median values\nno_data = []\nfor country in df['Country_Region'].unique():\n    if country not in df_pop_distrib['Country_Region'].unique():\n        aux = df_pop_distrib.drop('Country_Region', axis=1).median(axis=0).to_dict()\n        aux[\"Country_Region\"] = country\n        no_data.append(aux)\ndf_no_data = pd.DataFrame(no_data)\n\ndf_pop_distrib = pd.concat([df_pop_distrib, df_no_data], axis=0)\n\n# normalize features\nnorm_pop_distrib = df_pop_distrib.drop(\"Country_Region\", axis=1).div(df_pop_distrib.drop(\"Country_Region\", axis=1).sum(axis=1), axis=0)\nnorm_pop_distrib['total_pop'] = df_pop_distrib.drop(\"Country_Region\", axis=1).sum(axis=1)\nnorm_pop_distrib[\"Country_Region\"] = df_pop_distrib[\"Country_Region\"]\n\ndel df_pop_distrib\ndel df_no_data\n# del clean_wpop\n# del wpop\n\ndf = df.merge(norm_pop_distrib, on=\"Country_Region\", how='left')\ndf.shape","815f43e1":"wpop.sample(10)","fb3ac90e":"#https:\/\/ourworldindata.org\/smoking#prevalence-of-smoking-across-the-world\nsmokers = pd.read_csv('\/kaggle\/input\/smokingstats\/share-of-adults-who-smoke.csv')\nsmokers = smokers[smokers.Year == 2016].reset_index(drop=True)\n\nsmokers_country_dict = {'North America' : \"US\",\n 'Gambia' : \"The Gambia\",\n 'Bahamas': \"The Bahamas\",\n \"'South Korea'\" : \"Korea, South\",\n'Papua New Guinea' : \"Guinea\",\n \"'Czech Republic'\" : \"Czechia\",\n 'Congo' : \"Congo (Brazzaville)\"}\n\nsmokers['Entity'] = smokers.Entity.apply(lambda x : rename_countries(x, smokers_country_dict))\n\nno_datas_smoker = []\nfor country in df['Country_Region'].unique():\n    if country not in smokers.Entity.unique():\n        mean_score = smokers[['Smoking prevalence, total (ages 15+) (% of adults)']].mean().to_dict()\n        mean_score['Entity'] = country\n        no_datas_smoker.append(mean_score)\nno_data_smoker_df = pd.DataFrame(no_datas_smoker)   \nclean_smoke_data = pd.concat([smokers, no_data_smoker_df], axis=0)[['Entity','Smoking prevalence, total (ages 15+) (% of adults)']]\nclean_smoke_data.rename(columns={\"Entity\": \"Country_Region\",\n                                  \"Smoking prevalence, total (ages 15+) (% of adults)\" : \"smokers_perc\"}, inplace=True)\n\ndf = df.merge(clean_smoke_data, on=\"Country_Region\", how='left')\ndf.shape","7cd0244e":"smokers.shape","00b7cd00":"smokers.head()","0a0f5370":"countries = list(df.Country_Region.unique())","abcf637e":"healht_info = pd.read_csv('..\/input\/health-nutrition-and-population-statistics\/data.csv')\n#healht_info.sample(5)\n\nhealth_cols_2014 = [\n'GNI per capita, Atlas method (current US$)',\n       'Health expenditure per capita (current US$)',\n       'Health expenditure per capita, PPP',\n       'Health expenditure, private (% of GDP)',\n       'Health expenditure, private (% of total health expenditure)',\n       'Health expenditure, public (% of GDP)',\n       'Health expenditure, public (% of government expenditure)',\n       'Health expenditure, public (% of total health expenditure)',\n       'Health expenditure, total (% of GDP)',\n        'Prevalence of overweight (% of adults)',\n        ]\nhealth_cols_2015 = ['Diabetes prevalence (% of population ages 20 to 79)',]\nhealth_BCG_col =['Immunization, BCG (% of one-year-old children)',]\nhealth_cols_index = ['Country Name', 'Country Code', 'Indicator Name']\n\nhealht1 = healht_info[healht_info['Indicator Name'].isin(health_cols_2014)].pivot(index ='Country Code', columns ='Indicator Name', values = '2014').reset_index()\nhealht2 = healht_info[healht_info['Indicator Name'].isin(health_cols_2015)].pivot(index ='Country Code', columns ='Indicator Name', values = '2015').reset_index()\nhealht3 = healht_info[healht_info['Indicator Name'].isin(health_BCG_col)].pivot(index ='Country Code', columns ='Indicator Name', values = [ '1980', '1990', '2000'])\nhealht3.columns = healht3.columns.get_level_values(0)\nhealht3.columns = [' '.join(col).strip() for col in healht3.columns.values]\nhealht3 = healht3.add_prefix('BCG_')\nhealht3 = healht3.reset_index()\n#healht1.drop(columns=['Indicator Name'], axis=1, inplace=True)\n\nhealth_countries = healht_info[['Country Code','Country Name']].drop_duplicates(subset=['Country Code','Country Name'], keep=\"first\", inplace=False)\n#health_countries\n\nhealht_merged = health_countries.merge(healht1, on='Country Code').merge(healht2, on='Country Code').merge(healht3, on='Country Code')\n###\nhealht_merged.loc[healht_merged['Country Code']=='RUS',['BCG_1 9 8 0','BCG_1 9 9 0' ]] = [96.0,96.0]\nhealht_merged.loc[healht_merged['Country Code']=='UKR',['BCG_1 9 8 0','BCG_1 9 9 0' ]] = [98.0,98.0]\nhealht_merged.loc[healht_merged['Country Code']=='BLR',['BCG_1 9 8 0','BCG_1 9 9 0' ]] = [99.0,99.0]\nhealht_merged.drop(columns=['Country Name'], axis=1, inplace=True)\n##\nhealht_merged.info()","9e2ba211":"corruption_info = pd.read_csv('..\/input\/corruption-index\/index.csv')\ncorruption_info.sample(5)","27d881d0":"corruption_info.shape","ffa4f606":"iso_info = pd.read_csv('..\/input\/iso-country-codes-global\/wikipedia-iso-country-codes.csv')\niso_info.rename(columns={\"Alpha-3 code\": \"Country Code\", 'English short name lower case':'Country Name',\n                                 }, inplace=True)\niso_info.head()","932fe5b3":"iso_info.shape","04e18556":"rel_info = pd.read_csv('..\/input\/religions-vs-gdp-per-capita\/religion_vs_GDP_per_Capita.csv')\nrel_info.rename(columns={\"country\": \"Country Name\" }, inplace=True)\nrel_info.head()","2258f53a":"country_mapper = {\n'Laos' : \"Lao People's Democratic Republic\",\n'Hong Kong' : 'Hong Kong S.A.R., China',\n'Democratic Republic of the Congo' : 'Congo (Brazzaville)',\n    'Moldova': 'Moldova, Republic of',\n    'Macedonia': 'Macedonia, the former Yugoslav Republic of'       \n}\ndef rename_countries(x, country_dict):\n    new_name = country_dict.get(x)\n    if new_name is not None:\n        #print(x, \"-->\", new_name)\n        return new_name\n    else:\n        return x\n\n\nrel_info['Country Name'] = rel_info['Country Name'].apply(lambda x : rename_countries(x, country_mapper))","feff04db":"list(set(rel_info.loc[:,'Country Name'].unique()) - set(iso_info.loc[:,'Country Name'].unique()))","9f0d61e1":"sars_2003_info = pd.read_csv('..\/input\/sars-outbreak-2003-complete-dataset\/sars_2003_complete_dataset_clean.csv')\nsars_2003_info.sample(5)\n#sars_2003_info.Date.max()","56fa6e4a":"sars_2003_info_ = sars_2003_info.iloc[:,1:].groupby('Country').max().add_prefix('sars_').reset_index()\n#sars_2003_info_.head()\ncountry_mapper = {\n'Russian Federation' : \"Russia\",\n'Hong Kong SAR, China' : 'Hong Kong S.A.R., China',\n'Taiwan, China' : 'Taiwan',\n    'Macao SAR, China': 'Macao',\n    'Republic of Korea': 'South Korea',\n    'Republic of Ireland': 'Ireland',\n    'Viet Nam': 'Vietnam'    \n}\ndef rename_countries(x, country_dict):\n    new_name = country_dict.get(x)\n    if new_name is not None:\n        #print(x, \"-->\", new_name)\n        return new_name\n    else:\n        return x\n\n\nsars_2003_info_['Country'] = sars_2003_info_['Country'].apply(lambda x : rename_countries(x, country_mapper))\n\n\nsars_2003_info_ = sars_2003_info_.merge(iso_info[['Country Code', 'Country Name']], left_on= 'Country', right_on = 'Country Name')\n#sars_2003_info_ = sars_2003_info_.drop(\"English short name lower case\")\nsars_2003_info_.iloc[:,1:-1].sample()","6e656f08":"freedom_info = pd.read_csv('..\/input\/cato-2017-human-freedom-index\/cato_2017_hfi_by_year_summary.csv')\nfreedom_info = freedom_info.loc[freedom_info.Year==2015,['ISO_Code','PERSONAL FREEDOM (Score)','ECONOMIC FREEDOM (Score)','HUMAN FREEDOM (Score)'] ]\nfreedom_info.rename(columns={\"ISO_Code\": \"Country Code\",\n                                 }, inplace=True)\nfreedom_info.info()\n","d6b38153":"hh_info = pd.read_csv('..\/input\/global-household-data\/hh_by_country.csv', decimal=',')\nhh_info_ = hh_info.merge(iso_info[['Country Code', 'Numeric code']], left_on= 'ISO Code', right_on = 'Numeric code')\nhh_info_.iloc[:,4:-1].head()","c9ac95e4":"merged1 = iso_info[['Country Code','Country Name']].merge(healht_merged,  on='Country Code', how='left').merge(corruption_info[['Country Code', 'Corruption Perceptions Index (CPI)']], on='Country Code', how='left').\\\n    merge(sars_2003_info_.iloc[:,1:-1], on='Country Code', how='left').\\\n        merge(hh_info_.iloc[:,4:-1], on='Country Code', how='left').\\\n            merge(freedom_info, on='Country Code', how='left').merge(rel_info[['Country Name', 'religiousity%']], on='Country Name', how='left')\n\nmerged1.info()","c506892d":"# merged1 = healht_merged.merge(corruption_info[['Country Code', 'Corruption Perceptions Index (CPI)']], on='Country Code', how='left').\\\n#     merge(sars_2003_info_.iloc[:,1:-1], on='Country Code', how='left').merge(hh_info_.iloc[:,4:-1], on='Country Code', how='left')\n# merged1.info()\n\ncountry_mapper = {\n'Iran (Islamic Republic of)' : \"Iran\",\n'Bolivia (Plurinational State of)' : 'Bolivia',\n'Brunei Darussalam' : 'Brunei',\n    'The Bahamas': 'Bahamas',\n'Congo' : 'Congo (Kinshasa)',\n'Democratic Republic of the Congo' : \"Congo (Brazzaville)\",\n\"C\u00f4te d'Ivoire\": \"Cote d'Ivoire\",\n\"Gambia\" : \"Gambia, The\",\n\"Republic of Korea\": \"Korea, South\",\n\"Republic of Moldova\": \"Moldova\",\n'R\u00e9union' : \"Reunion\",\n'Russian Federation' : \"Russia\",\n\"United Republic of Tanzania\": \"Tanzania\",\n\"Bahamas, The\": \"Bahamas\",\n\"Gambia\": \"The Gambia\",\n\"United States\" : \"US\",\n\"Venezuela, RB\" : \"Venezuela\",\n'Viet Nam' : \"Vietnam\",\n'Egypt, Arab Rep.':'Egypt',\n'Czech Republic': 'Czechia',\n'Macedonia, FYR':'North Macedonia',\n'Gambia, The':'Gambia',\n'Iran, Islamic Rep.':'Iran',\n'Slovak Republic':'Slovakia',\n'South Korea':'Korea, South',\n'Kyrgyz Republic':'Kyrgyzstan',\n    'Syrian Arab Republic':'Syria', \n'Taiwan':'Taiwan*',\n'Myanmar':'Burma',\n'St. Vincent and the Grenadines':'Saint Vincent and the Grenadines',\n'Swaziland':'Eswatini',\n'Macedonia, the former Yugoslav Republic of':'North Macedonia',\n'Moldova, Republic of':'Moldova'}\ndef rename_countries(x, country_dict):\n    new_name = country_dict.get(x)\n    if new_name is not None:\n        #print(x, \"-->\", new_name)\n        return new_name\n    else:\n        return x\n\n\nmerged1['Country Name'] = merged1['Country Name'].apply(lambda x : rename_countries(x, country_mapper))\n\n\nlist(set(countries) - set(merged1.loc[:,'Country Name'].unique()))","9e93c72c":"df = df.merge(merged1, left_on=\"Country_Region\",right_on=\"Country Name\", how='left')\ndf.drop(columns=['Country Code', 'Country Name'], axis=1, inplace=True)\ndf.info()","17881007":"def concat_country_province(country, province):\n    if not isinstance(province, str):\n        return country\n    else:\n        return country+\"_\"+province\n\n# Concatenate region and province for training\ndf[\"Country_Region\"] = df[[\"Country_Region\", \"Province_State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\n","698dbada":"df[\"Country_Region\"].nunique()","8061db1e":"# country_info = pd.read_csv('\/kaggle\/input\/countryinfo\/covid19countryinfo.csv')\n# country_info = country_info[~country_info.country.isnull()].reset_index(drop=True)\n# country_info.drop([ c for c in country_info.columns if c.startswith(\"Unnamed\")], axis=1, inplace=True)\n# country_info.drop(columns=['pop', 'sex0', 'sex14', 'sex25', 'sex54', 'sex64', 'sex65plus', 'medianage', \"smokers\", \"sexratio\"],\n#                   axis=1,\n#                   inplace=True)\n# ##","7826145a":"lock_info = pd.read_csv('\/kaggle\/input\/covid19-lockdown-dates-by-country\/countryLockdowndates.csv')\n# Concatenate region and province for training\nlock_info[\"Country_Region\"] = lock_info[[\"Country\/Region\", \"Province\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\nlock_info.loc[lock_info.Country_Region=='Vatican City',['Country_Region']]=\"Holy See\"\nlock_info[\"lockdown\"] = pd.to_datetime(lock_info[\"Date\"])\n#lock_info.sample(10)","c5ef11dd":"list(set(df[\"Country_Region\"]) - set(lock_info[\"Country_Region\"].unique()))","2f3678a1":"lock_info.info()","01e102e8":"df = df.merge(lock_info[['Country_Region','lockdown']], on=\"Country_Region\", how=\"left\")","abf6f1a5":"country_info = pd.read_csv('\/kaggle\/input\/countryinfo\/covid19countryinfo.csv')\ncountry_info = country_info[~country_info.country.isnull()].reset_index(drop=True)\ncountry_info.drop([ c for c in country_info.columns if c.startswith(\"Unnamed\")], axis=1, inplace=True)\ncountry_info.drop(columns=['pop', 'sex0', 'sex14', 'sex25', 'sex54', 'sex64', 'sex65plus', 'medianage', \"smokers\", \"sexratio\"],\n                  axis=1,\n                  inplace=True)\n##\ncountry_info = country_info.drop(country_info[country_info.country=='Mali'].index)\n#country_info.loc[country_info.country=='Ukraine','quarantine'] = '3\/12\/2020'\n# country_info.loc[country_info.country=='Ukraine','gathering'] = '3\/12\/2020'\n# country_info.loc[country_info.country=='Ukraine','schools'] = '3\/12\/2020'\n# country_info.loc[country_info.country=='Ukraine','nonessential'] = '4\/06\/2020'\n####\n# Columns with dates\ncountry_info[\"quarantine\"] = pd.to_datetime(country_info[\"quarantine\"])\ncountry_info[\"publicplace\"] = pd.to_datetime(country_info[\"publicplace\"])\ncountry_info[\"gathering\"] = pd.to_datetime(country_info[\"gathering\"])\ncountry_info[\"nonessential\"] = pd.to_datetime(country_info[\"nonessential\"])\ncountry_info[\"schools\"] = pd.to_datetime(country_info[\"schools\"])\ncountry_info[\"firstcase\"] = pd.to_datetime(country_info[\"firstcase\"])\n##\ncountry_info['gdp2019'] = country_info['gdp2019'].str.replace(',', '')\ncountry_info['healthexp'] = country_info['healthexp'].str.replace(',', '')\n\n\n\n\nsame_state = []\nfor country in df[\"Province_State\"].unique():\n    if country in country_info.country.unique():\n        same_state.append(country)\n    else:\n        pass\n        # This part can help matching different external dataset and find corresponding countries\n        #print(country)\n        #matches = []\n        #scores = []\n        #if str(country)==\"nan\":\n        #    continue\n        #for possible_match in country_info.country.unique():\n        #    matches.append(possible_match)\n        #    scores.append(fuzz.partial_ratio(country, possible_match))\n            \n        #top_5_index = np.argsort(scores)[::-1][:5]\n        #print(np.array(matches)[top_5_index])\n        #print(np.array(scores)[top_5_index])\n        #print(\"-------------------\")\n        \ncountry_to_state_country = {}\nfor state in same_state:\n    #print(state)\n    #print(df[df[\"Province\/State\"]==state][\"Country\/Region\"].unique())\n    #print(\"----\")\n    country_to_state_country[state] = df[df[\"Province_State\"]==state][\"Country_Region\"].unique()[0]+\"_\"+state\n\ncountry_info['country'] =country_info[[\"country\", \"region\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)                                                                      \n\n\ndates_info = [\"publicplace\", \"gathering\", \"nonessential\", \"quarantine\", \"schools\",\"firstcase\"]\ncoutry_merge_info = country_info[[\"country\", \"density\", \"urbanpop\", \"hospibed\", \"lung\",\n                                  \"femalelung\", \"malelung\",'gdp2019', 'healthexp', 'healthperpop', 'fertility'] + dates_info]\n\ncols_median = [\"density\", \"urbanpop\", \"hospibed\", \"lung\", \"femalelung\", \"malelung\",'gdp2019', 'healthexp', 'healthperpop', 'fertility']\ncoutry_merge_info.loc[:, cols_median] = coutry_merge_info.loc[:, cols_median].apply(lambda x: x.fillna(x.median()),axis=0)\n\n\nmerged = df.merge(coutry_merge_info, left_on=\"Country_Region\", right_on=\"country\", how=\"left\")\nmerged.loc[:, cols_median] = merged.loc[:, cols_median].apply(lambda x: x.fillna(x.median()),axis=0)\n\ncountry_dates_info = country_info[[\"country\", \"publicplace\", \"gathering\", \"nonessential\", \"quarantine\", \"schools\",\"firstcase\"]]\n\n\n\n# def dates_diff_days(date_curr, date_):\n#     if date_curr>date_:\n#         return (date_curr - date_).days\n#     else :\n#         return 0\n\n\n# for col in dates_info:\n#     #print(merged.shape)\n#     merged[col+'_days'] =merged[[\"Date\", col]].apply(lambda x : dates_diff_days(x[0], x[1]), axis=1)                                                                      \n\nprint(merged.shape)\n#drop_country_cols = [x for x in merged.columns if x.startswith(\"country\")] + dates_info\ndrop_country_cols = [x for x in merged.columns if x.startswith(\"country\")]\nmerged.drop(columns=drop_country_cols, axis=1, inplace=True)\nprint(merged.shape)","0087a12c":"merged.Country_Region.value_counts().mean()","ac6145fe":"merged.info()","4d42d827":"merged.sample(10)","8007be4e":"# weather_info = pd.read_csv('..\/input\/weather-info\/training_data_with_weather_info_week_2.csv')\n# weather_info.sample(5)","37255720":"# weather_info.Date.min(), weather_info.Date.max() , weather_info.shape","be454461":"# merged.Date.min(), merged.Date.max(), merged.shape","512590ec":"# weather_info[\"Country_Region\"] = weather_info[[\"Country_Region\", \"Province_State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\n# weather_info[\"Date\"] = pd.to_datetime(weather_info[\"Date\"])\n\n","3c6eace2":"# merged_ = merged.merge(weather_info[['temp','min','max','stp','wdsp','prcp','fog','Country_Region', 'Date']], on=[\"Country_Region\", 'Date'])\n# merged_.shape","b7ca1b44":"# merged_.Country_Region.value_counts().mean()","69c357be":"merged.info()","8c9dd98c":"merged.to_csv('enriched_covid_19_week_3.csv', index=None)","47af2332":"### Add Smokers Percentages By Country****","da3be471":"## Weather","2ff5ebbb":"Health, Corruption","5731d0a0":"### religion","f763e140":"\n****","76770e05":"### Sars","a5fe8c05":"## Add Population Distributions By Country","437e71dc":"## Concatenate Country and Region Province","7d2981b5":"# ISO Country codes"}}