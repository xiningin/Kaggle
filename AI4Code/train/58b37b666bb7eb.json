{"cell_type":{"7102ec25":"code","d139c6b3":"code","39f09984":"code","2c6296b5":"code","95553869":"code","3b986ac0":"code","06ec2be2":"code","849fd47f":"code","53b66b78":"code","e4b7c67d":"code","373f9bb1":"code","98c04f92":"code","9fcdaa48":"code","de001184":"code","f83b4727":"code","6cfb8ea3":"code","637825f8":"code","797937b0":"code","19175be7":"code","45b5b5b8":"code","14e0222c":"code","a5f68644":"code","7af4588d":"code","916b8a5f":"code","4dbf5915":"code","121d2a46":"code","0ec066de":"code","dcdf3ec3":"code","a0fae321":"code","e02581d7":"code","10308684":"code","5c5beed6":"code","ca6bb2ee":"code","4aad21e5":"code","3076951d":"code","89519f6b":"code","3f365ed8":"code","53f39d8b":"code","893869a3":"code","26fea2d2":"code","58f61d02":"code","d6ab8ba7":"code","6880cb0c":"code","678e56ea":"code","66a9a7f4":"code","03490760":"code","ca1e8442":"markdown","b8006e4c":"markdown","95e7969a":"markdown","8c755b2b":"markdown","6473e088":"markdown","5747a5d0":"markdown","e413b95a":"markdown","a28f9317":"markdown","ce5b2f95":"markdown","e6d45032":"markdown","f703d184":"markdown","552a7c1e":"markdown","9587cdea":"markdown","93b18f05":"markdown"},"source":{"7102ec25":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', 1000)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nbase_dir = '\/kaggle\/input'\ndataset_name = 'us-campaign-finance-20192020-fec'\nfor dirname, _, filenames in os.walk(base_dir):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\nimport bs4\nimport urllib.request\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d139c6b3":"class DataCleaner:\n    def __init__(self, columns, func):\n        self.columns = columns\n        self.func = func\n    \n    def __call__(self, df):\n        if not list(filter(lambda x: x not in df.columns, self.columns)):\n            return self.func(df)\n        return df\ndata_cleaner_registry = []","39f09984":"def read_table(page_url):\n    page=urllib.request.urlopen(page_url)\n    soup = bs4.BeautifulSoup(page, 'lxml')\n    table = soup.find(name='table')\n    result = dict()\n    for tr in table.findAll('tr'):\n        tds = tr.findAll('td')\n        if len(tds) >=2:\n            result[tds[0].text] = tds[1].text\n    return result","2c6296b5":"all_candidates = pd.read_csv(f\"{base_dir}\/{dataset_name}\/All candidates.csv\")\nall_candidates.head()","95553869":"def correct_receipts_disbursements(df):\n    cond = (df['TRANS_FROM_AUTH'] != 0.0) & (df['TRANS_TO_AUTH'] != 0.0)\n    df.loc[cond, 'TTL_RECEIPTS_CORRECTED'] = df['TTL_RECEIPTS'] - df['TRANS_FROM_AUTH']\n    df['TTL_RECEIPTS_CORRECTED'] = df['TTL_RECEIPTS_CORRECTED'].fillna(df['TTL_RECEIPTS'])\n    df.loc[cond, 'TTL_DISB_CORRECTED'] = df['TTL_DISB'] - df['TRANS_TO_AUTH']\n    df['TTL_DISB_CORRECTED'] = df['TTL_DISB_CORRECTED'].fillna(df['TTL_DISB'])\n    return df\nreceipts_disb_corrector = DataCleaner(['TRANS_FROM_AUTH', 'TRANS_TO_AUTH', 'TTL_RECEIPTS', 'TTL_DISB'], correct_receipts_disbursements)\ndata_cleaner_registry.append(receipts_disb_corrector)","3b986ac0":"def map_cand_ici(df):\n    ici_map = {'C': 'Challenger', 'I': 'Incumbent', 'O': 'Open Seat'}\n    df['CAND_ICI_FULL'] = df['CAND_ICI'].map(ici_map)\n    return df\ncand_ici_mapper = DataCleaner(['CAND_ICI'], map_cand_ici)\ndata_cleaner_registry.append(cand_ici_mapper)","06ec2be2":"party_codes = read_table(\"https:\/\/www.fec.gov\/campaign-finance-data\/party-code-descriptions\/\")\ndef map_cand_party(df):\n    df['CAND_PTY_AFFILIATION_FULL'] = df['CAND_PTY_AFFILIATION'].map(party_codes)\n    return df\ncand_party_mapper = DataCleaner(['CAND_PTY_AFFILIATION'], map_cand_party)\ndata_cleaner_registry.append(cand_party_mapper)","849fd47f":"def fix_cand_office_district(df):\n    if df['CAND_OFFICE_DISTRICT'].dtype == 'int64':\n        df['CAND_OFFICE_DISTRICT'] = df['CAND_OFFICE_DISTRICT'].map(lambda x: str(x).zfill(2) if not pd.isna(x) else np.nan)\n    elif df['CAND_OFFICE_DISTRICT'].dtype == 'float':\n        df['CAND_OFFICE_DISTRICT'] = df['CAND_OFFICE_DISTRICT'].map(lambda x: str(int(x)).zfill(2) if not pd.isna(x) else np.nan)\n    return df\ncand_office_district_fixer = DataCleaner(['CAND_OFFICE_DISTRICT'], fix_cand_office_district)\ndata_cleaner_registry.append(cand_office_district_fixer)","53b66b78":"for data_cleaner in data_cleaner_registry:\n    all_candidates = data_cleaner(all_candidates)\nall_candidates.head()","e4b7c67d":"candidate_master = pd.read_csv(f\"{base_dir}\/{dataset_name}\/Candidate master.csv\")\ncandidate_master.head()","373f9bb1":"from functools import partial\ndef fix_zip_codes(col, df):\n    if df[col].dtype == 'float':\n        df[col] = df[col].map(lambda x: str(int(x)).zfill(5) if not pd.isna(x) else np.nan)\n    elif df[col].dtype == 'int64':\n        df[col] = df[col].map(lambda x: str(x).zfill(5) if not pd.isna(x) else np.nan)\n    return df\ncand_zip_fixer = DataCleaner(['CAND_ZIP'], partial(fix_zip_codes, 'CAND_ZIP'))\ndata_cleaner_registry.append(cand_zip_fixer)","98c04f92":"def map_cand_office(df):\n    office_map = {'H': 'House', 'S': 'Senate', 'P': 'President'}\n    df['CAND_OFFICE_FULL'] = df['CAND_OFFICE'].map(office_map)\n    return df\ncand_office_mapper = DataCleaner(['CAND_OFFICE'], map_cand_office)\ndata_cleaner_registry.append(cand_office_mapper)","9fcdaa48":"def map_cand_status(df):\n    status_map = {\n        'C': 'Statutory candidate', 'F': 'Statutory candidate for future election',\n        'N': 'Not yet a statutory candidate', 'P': 'Statutory candidate in prior cycle'\n    }\n    df['CAND_STATUS_FULL'] = df['CAND_STATUS'].map(status_map)\n    return df\ncand_status_mapper = DataCleaner(['CAND_STATUS'], map_cand_status)\ndata_cleaner_registry.append(cand_status_mapper)","de001184":"for data_cleaner in data_cleaner_registry:\n    candidate_master = data_cleaner(candidate_master)\ncandidate_master.head()","f83b4727":"committee_master = pd.read_csv(f\"{base_dir}\/{dataset_name}\/Committee master.csv\")\ncommittee_master.head()","6cfb8ea3":"def map_cmte_desg(df):\n    designation_map = {\n        'A': 'Authorized by a candidate',\n        'B': 'Lobbyist\/Registrant PAC',\n        'D': 'Leadership PAC',\n        'J': 'Joint fundraiser',\n        'P': 'Principal campaign committee of a candidate',\n        'U':  'Unauthorized'\n    }\n    df['CMTE_DSGN_FULL'] = df['CMTE_DSGN'].map(designation_map)\n    return df\ncmte_desg_mapper = DataCleaner(['CMTE_DSGN'], map_cmte_desg)\ndata_cleaner_registry.append(cmte_desg_mapper)","637825f8":"committee_type_map = read_table(\"https:\/\/www.fec.gov\/campaign-finance-data\/committee-type-code-descriptions\/\")\ndef map_cmte_type(df):\n    df['CMTE_TP_FULL'] = df['CMTE_TP'].map(committee_type_map)\n    return df\ncmte_type_mapper = DataCleaner(['CMTE_TP'], map_cmte_type)\ndata_cleaner_registry.append(cmte_type_mapper)","797937b0":"def map_cmte_party(df):\n    df['CMTE_PTY_AFFILIATION_FULL'] = df['CMTE_PTY_AFFILIATION'].map(party_codes)\n    return df\ncmte_party_mapper = DataCleaner(['CMTE_PTY_AFFILIATION'], map_cmte_party)\ndata_cleaner_registry.append(cmte_party_mapper)","19175be7":"def map_cmte_filing_freq(df):\n    filing_freq_map = {\n        'A': 'Administratively terminated',\n        'D': 'Debt',\n        'M': 'Monthly filer',\n        'Q': 'Quarterly filer',\n        'T': 'Terminated',\n        'W': 'Waived'\n    }\n    df['CMTE_FILING_FREQ_FULL'] = df['CMTE_FILING_FREQ'].map(filing_freq_map)\n    return df\ncmte_filing_freq_mapper = DataCleaner(['CMTE_FILING_FREQ'], map_cmte_filing_freq)\ndata_cleaner_registry.append(cmte_filing_freq_mapper)","45b5b5b8":"def map_cmte_org_type(df):\n    org_type_map = {\n        'C': 'Corporation',\n        'L': 'Labor organization',\n        'M': 'Membership organization',\n        'T': 'Trade association',\n        'V': 'Cooperative',\n        'W': 'Corporation without capital stock'\n    }\n    df['ORG_TP_FULL'] = df['ORG_TP'].map(org_type_map)\n    return df\ncmte_org_type_mapper = DataCleaner(['ORG_TP'], map_cmte_org_type)\ndata_cleaner_registry.append(cmte_org_type_mapper)","14e0222c":"for data_cleaner in data_cleaner_registry:\n    committee_master = data_cleaner(committee_master)\ncommittee_master.head()","a5f68644":"candidate_committee_linkage = pd.read_csv(f\"{base_dir}\/{dataset_name}\/Candidate-committee linkages.csv\")\ncandidate_committee_linkage.head()","7af4588d":"for data_cleaner in data_cleaner_registry:\n    candidate_committee_linkage = data_cleaner(candidate_committee_linkage)\ncandidate_committee_linkage.head()","916b8a5f":"house_senate_current_campaigns = pd.read_csv(f\"{base_dir}\/{dataset_name}\/House_Senate current campaigns.csv\")\nhouse_senate_current_campaigns.head()","4dbf5915":"for data_cleaner in data_cleaner_registry:\n    house_senate_current_campaigns = data_cleaner(house_senate_current_campaigns)\nhouse_senate_current_campaigns.head()","121d2a46":"pac_summary = pd.read_csv(f\"{base_dir}\/{dataset_name}\/PAC summary.csv\")\npac_summary.head()","0ec066de":"for data_cleaner in data_cleaner_registry:\n    pac_summary = data_cleaner(pac_summary)\npac_summary.head()","dcdf3ec3":"contributions_from_committees = pd.read_csv(f\"{base_dir}\/{dataset_name}\/Contributions from committees to candidates  independent expenditures.csv\")\ncontributions_from_committees.head()","a0fae321":"cand_zip_fixer = DataCleaner(['ZIP_CODE'], partial(fix_zip_codes, 'ZIP_CODE'))\ndata_cleaner_registry.append(cand_zip_fixer)","e02581d7":"def map_amndt_ind(df):\n    df['AMNDT_IND_FULL'] = df['AMNDT_IND'].map({'N': 'New', 'A': 'Amendment', 'T': 'Termination'})\n    return df\namndt_ind_mapper = DataCleaner(['AMNDT_IND'], map_amndt_ind)\ndata_cleaner_registry.append(amndt_ind_mapper)","10308684":"report_type_map = read_table(\"https:\/\/www.fec.gov\/campaign-finance-data\/report-type-code-descriptions\/\")\ndef map_report_type(df):\n    df['RPT_TP_FULL'] = df['RPT_TP'].map(report_type_map)\n    return df\nreport_type_mapper = DataCleaner(['RPT_TP'], map_report_type)\ndata_cleaner_registry.append(report_type_mapper)","5c5beed6":"election_type_map = {\n    'P': 'Primary',\n    'G': 'General',\n    'O': 'Other',\n    'C': 'Convention',\n    'R': 'Runoff',\n    'S': 'Special',\n    'E': 'Recount'\n}\ndef parse_transaction_pgi(df):\n    df['ELECTION_TYPE'] = df['TRANSACTION_PGI'].astype('object').str[0].map(election_type_map)\n    df['ELECTION_YEAR'] = df['TRANSACTION_PGI'].astype('object').str[1:].map(\n        lambda x: int(x) if x and not pd.isnull(x) else np.nan).fillna(0).astype('int')\n    return df\ntransaction_pgi_parser = DataCleaner(['TRANSACTION_PGI'], parse_transaction_pgi)\ndata_cleaner_registry.append(transaction_pgi_parser)","ca6bb2ee":"def parse_image_num(df):\n    df['IMAGE_DATE'] = pd.to_datetime(df['IMAGE_NUM'].astype('str').str[:8])\n    df['IMAGE_SOURCE'] = df['IMAGE_NUM'].astype('str').str[8:10].map(\n        lambda x: 'Senate' if x == '02' else 'FEC Paper' if x == '03' else 'FEC Electronic')\n    return df\nimage_num_parser = DataCleaner(['IMAGE_NUM'], parse_image_num)\ndata_cleaner_registry.append(image_num_parser)","4aad21e5":"transaction_type_map = read_table(\"https:\/\/www.fec.gov\/campaign-finance-data\/transaction-type-code-descriptions\/\")\ndef map_transaction_type(df):\n    df['TRANSACTION_TP_FULL'] = df['TRANSACTION_TP'].map(transaction_type_map)\n    return df\ntransaction_type_mapper = DataCleaner(['TRANSACTION_TP'], map_transaction_type)\ndata_cleaner_registry.append(transaction_type_mapper)","3076951d":"entity_type_map = {\n    'CAN': 'Candidate',\n    'CCM': 'Candidate Committee',\n    'COM': 'Committee',\n    'IND': 'Individual (a person)',\n    'ORG': 'Organization (not a committee and not a person)',\n    'PAC': 'Political Action Committee',\n    'PTY': 'Party Organization'\n}\ndef map_entity_type(df):\n    df['ENTITY_TP_FULL'] = df['ENTITY_TP'].map(entity_type_map)\n    return df\nentity_type_mapper = DataCleaner(['ENTITY_TP'], map_entity_type)\ndata_cleaner_registry.append(entity_type_mapper)","89519f6b":"for data_cleaner in data_cleaner_registry:\n    contributions_from_committees = data_cleaner(contributions_from_committees)\ncontributions_from_committees.head()","3f365ed8":"any_transaction_between_committees = pd.read_csv(f\"{base_dir}\/{dataset_name}\/Any transaction from one committee to another.csv\")\nany_transaction_between_committees.head()","53f39d8b":"for data_cleaner in data_cleaner_registry:\n    any_transaction_between_committees = data_cleaner(any_transaction_between_committees)\nany_transaction_between_committees.head()","893869a3":"operating_expenditures = pd.read_csv(f\"{base_dir}\/{dataset_name}\/Operating expenditures.csv\")\noperating_expenditures.head()","26fea2d2":"for data_cleaner in data_cleaner_registry:\n    operating_expenditures = data_cleaner(operating_expenditures)\noperating_expenditures.head()","58f61d02":"contribs_by_indivs = pd.read_csv(f\"{base_dir}\/{dataset_name}\/Contributions by individuals.csv\", nrows=1000)\ncontribs_by_indivs_cols = contribs_by_indivs.columns\ncontribs_by_indivs.head()","d6ab8ba7":"def process_contribs_by_indivs(df):\n    try:\n        df['TRANSACTION_DT'] = pd.to_datetime(df['TRANSACTION_DT'].fillna(0).astype('int')\n                                              .astype('str').replace('0', np.NaN).str.zfill(8), format='%m%d%Y')\n    except Exception as e:\n        print(df['TRANSACTION_DT'])\n        raise e\n    for data_cleaner in data_cleaner_registry:\n        df = data_cleaner(df)\n    return df","6880cb0c":"contribs_by_indivs = process_contribs_by_indivs(contribs_by_indivs)\ncontribs_by_indivs.head()","678e56ea":"s = f\"{base_dir}\/{dataset_name}\/Contributions by individuals.csv\"\nresult = ! wc -l \"{s}\"\nlength = int(result[0].split()[0])\nlength","66a9a7f4":"# Iteration 42 has some bad data that needs to be fixed manually as below\ndef handle_iteration_42(df):\n    bad_row = df[df['TRANSACTION_DT'] == 'SAN DIEGO']\n    bad_rows = bad_row['OCCUPATION'].str.split('\\n').values[0]\n    other_rows = []\n    for i, row in enumerate(bad_rows):\n        if i==0:\n            first_row_last_part = row.split('|')\n        elif i == len(bad_rows)-1:\n            last_row_first_part = row.split('|')\n        else:\n            other_rows.append(row.split('|'))\n    all_dfs = [df]\n    first_row = list(df.loc[bad_row.index].iloc[:, 0:12].copy().values[0]) + first_row_last_part\n    all_dfs.append(pd.DataFrame([first_row], columns=df.columns))\n    all_dfs.append(pd.DataFrame(other_rows, columns=df.columns))\n    all_dfs.append(pd.DataFrame([last_row_first_part + list(df.loc[bad_row.index].iloc[:, 13:].copy().values[0])\n                                   + [np.NaN, np.NaN, np.NaN, np.NaN, np.NaN]], columns=df.columns))\n    df = pd.concat(all_dfs, axis=0)\n    df = df.drop(index=bad_row.index).reset_index()\n    return df","03490760":"import time\nimport gc\nchunksize = 100000\ncols = None\nfor i in range(length\/\/chunksize):\n    print(f\"Processing chunk {i}\")\n    df = pd.read_csv(f\"{base_dir}\/{dataset_name}\/Contributions by individuals.csv\", skiprows=i*chunksize, nrows=chunksize)\n    if i == 0:\n        cols = df.columns\n    else:\n        df.columns = cols\n    if i == 42:\n        df = handle_iteration_42(df)\n    df = process_contribs_by_indivs(df)\n    del df\n    gc.collect()\n    time.sleep(2)","ca1e8442":"Now, let's try this processing on the whole file (chunk-by-chunk) to make sure there are no errors raised","b8006e4c":"## Contributions by individuals file","95e7969a":"## Any transaction from one committee to another file","8c755b2b":"### We'll clean up the various data files as per their data description at the FEC site","6473e088":"## Candidate master file","5747a5d0":"## Candidate committee linkage file","e413b95a":"We'll use a DataCleaner class & a registry to easily manage cleaning up common fields between the files","a28f9317":"## All Candidates file","ce5b2f95":"## House Senate current campaigns file","e6d45032":"This file is too big to load it all in memory. So, we'll do 2 things :\n1. Load a small chunk & clean\/expand the data\n1. Load the whole file as small chunks (delete old chunks in memory) & make sure data is cleaned\/expanded without any errors","f703d184":"## Committee master file","552a7c1e":"## Contributions from committes to candidates file","9587cdea":"## Operating expenditures file","93b18f05":"## PAC Summary file"}}