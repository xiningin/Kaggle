{"cell_type":{"c6fbe699":"code","c8cb8ba0":"code","4fbaffaa":"code","2a42bd4b":"code","dcbc0af5":"code","14940091":"code","e01b785e":"code","9f685dd8":"code","7c1179fb":"code","9ace090f":"code","c24b8bc3":"code","3dc35872":"code","52eadd2b":"code","e0d75562":"code","fac923d2":"code","219adebd":"markdown","2681072c":"markdown"},"source":{"c6fbe699":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8cb8ba0":"def plot_series(time, series, format=\"-\", start=0, end=None):\n    plt.plot(time[start:end], series[start:end], format)\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Value\")\n    plt.grid(True)","4fbaffaa":"dataset=pd.read_csv(\"..\/input\/sunspots\/Sunspots.csv\")\ndataset.head()","2a42bd4b":"import pandas_profiling as pp\npp.ProfileReport(dataset)","dcbc0af5":"time = dataset['Unnamed: 0']\nsunspots = dataset['Monthly Mean Total Sunspot Number']","14940091":"sunspots","e01b785e":"time","9f685dd8":"sunspots = np.array(sunspots)\ntime = np.array(time)","7c1179fb":"plt.figure(figsize=(10, 6))\nplot_series(time, sunspots)","9ace090f":"# 80% dari data yang ada = 2612, sehingga kita hanya membutuhkan 653 rows untuk memvalidasi data.\nsplit_time = 2612\ntime_train = time[:split_time]\nx_train = sunspots[:split_time]\ntime_valid = time[split_time:]\nx_valid = sunspots[split_time:]\n\nwindow_size = 30\nbatch_size = 32","c24b8bc3":"x_train","3dc35872":"time_train","52eadd2b":"def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n    series = tf.expand_dims(series, axis=-1)\n    ds = tf.data.Dataset.from_tensor_slices(series)\n    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n    ds = ds.shuffle(shuffle_buffer)\n    ds = ds.map(lambda w: (w[:-1], w[1:]))\n    return ds.batch(batch_size).prefetch(1)","e0d75562":"import tensorflow as tf\ntrain_set = windowed_dataset(x_train, window_size=60, batch_size=100, shuffle_buffer=1000)\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv1D(filters=60, kernel_size=5,\n                      strides=1, padding=\"causal\",\n                      activation=\"relu\",\n                      input_shape=[None, 1]),\n  tf.keras.layers.LSTM(60, return_sequences=True),\n  tf.keras.layers.LSTM(60, return_sequences=True), #declaring the LSTM layers\n  tf.keras.layers.Dense(10, activation=\"relu\"),\n  tf.keras.layers.Dense(10, activation=\"relu\"),\n  tf.keras.layers.Dense(1),\n  tf.keras.layers.Lambda(lambda x: x * 400)\n])\n","fac923d2":"optimizer=tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)\nmodel.compile(loss=tf.keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nhistory = model.fit(train_set,epochs=100)","219adebd":"## Name: Farel Arden","2681072c":"Fungsi dibawah ini digunakan untuk mem-plot grafik"}}