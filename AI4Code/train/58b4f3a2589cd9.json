{"cell_type":{"91979514":"code","58ba6d77":"code","9042bb7c":"code","9459f8d1":"code","da1dcc0e":"code","53302423":"code","bc5eedea":"code","cfe1f7e0":"code","c11be6ba":"code","2faf04fd":"code","dc45a118":"code","b6185d48":"code","801d3fbc":"code","288f4650":"code","91e11fbd":"markdown","32702313":"markdown","24f8a87b":"markdown","5898e842":"markdown","c10625d9":"markdown","ae53db34":"markdown","0e83291d":"markdown"},"source":{"91979514":"import numpy as np\nimport pandas as pd","58ba6d77":"train_df = pd.read_csv('..\/input\/nlp-getting-started\/train.csv') \ntest_df =  pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","9042bb7c":"train_df","9459f8d1":"train_df[train_df['target']==0]['text'].values[0]","da1dcc0e":"#Count Vectorizer class present in feature_extraction.text module from scikit learn so importing.\nfrom sklearn import feature_extraction","53302423":"#Python OOP so create a object as instance of CountVectorizer Class\ntfidf_vec = feature_extraction.text.TfidfVectorizer()","bc5eedea":"#transform ur raw text to DTM using cnt_vec object so u can feed it to any ML model\n#fit transform on train and transform on test. Followed convention. To prevent data leakage etc\ndtm_train = tfidf_vec.fit_transform(train_df['text'])\ndtm_test = tfidf_vec.transform(test_df['text'])","cfe1f7e0":"#from sklearn import linear_model\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\n#from sklearn.ensemble import RandomForestClassifier","c11be6ba":"#Model object\n#clf = svm.SVC(kernel='linear',C=1,gamma=1)\nclf = LogisticRegression()\n#clf = RandomForestClassifier()","2faf04fd":"# #Doing Grid Search\n# from sklearn.model_selection import GridSearchCV \n  \n# # defining parameter range \n# param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n#               'kernel': ['rbf','linear']}  \n  \n# grid = GridSearchCV(svm.SVC(), param_grid, refit = True, verbose = 0) \n  \n# # fitting the model for grid search \n# grid.fit(dtm_train, train_df['target']) \n\n# # print best parameter after tuning \n# print(grid.best_params_) \n  \n# # print how our model looks after hyper-parameter tuning \n# print(grid.best_estimator_) \n","dc45a118":"#need model_selection module to implement cross validation\nfrom sklearn import model_selection","b6185d48":"import statistics\n#Getting scores\nscores = model_selection.cross_val_score(clf, dtm_train, train_df['target'], cv=5, scoring='f1')\nprint(scores)\nprint(statistics.mean(scores))","801d3fbc":"#now train on complete dtm_train\nclf.fit(dtm_train, train_df['target'])","288f4650":"#Now predict and store the pred in sample_submission and submit fresh submission\nsample_submission = pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')\n#overwrite\nsample_submission['target'] = clf.predict(dtm_test)\n#submit csv file with just id and predictions without index\nsample_submission.to_csv('LogisticRegressionsubmission.csv',index=False)","91e11fbd":"Import Basic Libraries","32702313":"Import model now","24f8a87b":"Now Train your model by feeding dtm_train and cross validate and get the scores. F1 score","5898e842":"View Train data","c10625d9":"View a sample fake disaster tweet","ae53db34":"Modelling starts - Plan-> DTM made using TFIDF-Vectorizer and apply preferred model","0e83291d":"Import train and test tweets data in to notebook."}}