{"cell_type":{"f5fc0734":"code","c2e42bae":"code","f35e89b7":"code","bd028d1d":"code","1b9c56bc":"code","56534b9e":"code","049d731d":"code","7b4ea80a":"code","a0b56a8f":"code","53a0d6ee":"code","a974bae7":"code","91d90990":"code","f5e1bd1f":"code","27e4156f":"code","bf71e52d":"code","fa401754":"code","e265b429":"code","a4ef3d19":"code","2fc21d63":"markdown","e5deeefb":"markdown","e0c927e7":"markdown","e8f50f7c":"markdown","5085d948":"markdown","17fb3452":"markdown","a694564a":"markdown","481012ba":"markdown"},"source":{"f5fc0734":"import numpy as np\nimport pandas as pd\nimport PIL\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pathlib\nimport cv2\n\nfrom mpl_toolkits.axes_grid1 import ImageGrid","c2e42bae":"train = '..\/input\/flower-classification\/flowers\/flowers\/flower_photos\/train'\ntest = '..\/input\/flower-classification\/flowers\/flowers\/flower_photos\/test'\nval = '..\/input\/flower-classification\/flowers\/flowers\/flower_photos\/validation'","f35e89b7":"data_dir = pathlib.Path(train)\nfolder = list(data_dir.glob('*'))\nimages = list(data_dir.glob('*\/*.jpg')) #list of all images (full path)\nprint('Folder Structure:')\nfor f in folder:\n    print(f)\nprint('\\nNumber of images: ', len(images))","bd028d1d":"fig = plt.figure(figsize=(10, 10))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    plt.title(str(images[i]).split('\/')[-1], fontsize=10) #get the file name and disply as title\n    plt.imshow(PIL.Image.open(images[i]))\n    ax = plt.axis(\"off\")","1b9c56bc":"image_size = 256\nbatch_size = 32","56534b9e":"idg = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.2\n)","049d731d":"train_gen = idg.flow_from_directory(train,\n                                    target_size=(image_size, image_size),\n                                    subset='training',\n                                    class_mode='categorical',\n                                    batch_size=batch_size,\n                                    shuffle=True,\n                                    seed=1\n                                    )","7b4ea80a":"val_gen = idg.flow_from_directory(val,\n                                  target_size=(image_size, image_size),                                                   \n                                  subset='validation',\n                                  class_mode='categorical',\n                                  batch_size=batch_size,\n                                  shuffle=True,\n                                  seed=1\n                                  )","a0b56a8f":"classes = train_gen.class_indices\nprint(classes)\nclass_names = []\nfor c in classes:\n    class_names.append(c)\nprint('The name of the classes are: ', class_names)","53a0d6ee":"unique, counts = np.unique(train_gen.classes, return_counts=True)\ndict1 = dict(zip(train_gen.class_indices, counts))\n\nkeys = dict1.keys()\nvalues = dict1.values()\n\nplt.xticks(rotation='vertical')\nbar = plt.bar(keys, values)","a974bae7":"x,y = next(train_gen)\n","91d90990":"fig = plt.figure(None, (10,10),frameon=False)\ngrid = ImageGrid(fig, 111, \n                 nrows_ncols=(2, 4),  \n                 axes_pad=0.2, \n                 share_all=True,\n                 )\nfor i in range(2*4):\n    ax = grid[i]\n    ax.imshow(x[i],cmap='Greys_r')\n    ax.axis('off')  ","f5e1bd1f":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.InputLayer(input_shape=(image_size,image_size,3,))) # Input layer\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu')) # 2D Convolution layer\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2))) # Max Pool layer \nmodel.add(tf.keras.layers.BatchNormalization()) # Normalization layer\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), strides = (1,1), activation='relu')) # 2D Convolution layer\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2))) # Max Pool layer \nmodel.add(tf.keras.layers.BatchNormalization()) # Normalization layer\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3), strides = (1,1), activation='relu')) # 2D Convolution layer\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2))) # Max Pool layer \nmodel.add(tf.keras.layers.BatchNormalization()) # Normalization layer\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3), strides = (1,1), activation='relu')) # 2D Convolution layer\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2))) # Max Pool layer \nmodel.add(tf.keras.layers.GlobalMaxPool2D()) # Global Max Pool layer\nmodel.add(tf.keras.layers.Flatten()) # Dense Layers after flattening the data\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2)) # Dropout\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization()) # Normalization layer\nmodel.add(tf.keras.layers.Dense(5, activation='softmax')) # Add Output Layer","27e4156f":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","bf71e52d":"model.summary()\n","fa401754":"# checkpoint = tf.keras.callbacks.ModelCheckpoint('flower_classification.h5', #where to save the model\n#                                                 save_best_only=True, \n#                                                 monitor='val_accuracy', \n#                                                 mode='max', \n#                                                 verbose = 1)\n","e265b429":"activity = model.fit(train_gen,\n          epochs=20, # Increase number of epochs if you have sufficient hardware\n          steps_per_epoch= 1000\/\/batch_size,  # Number of train images \/\/ batch_size\n          validation_data=val_gen,\n          validation_steps = 10\/\/batch_size, # Number of val images \/\/ batch_size\n          \n          verbose = 1\n)","a4ef3d19":"plt.plot(activity.history['accuracy'], label='accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.xticks(list(range(1,21)))\nplt.ylim([0, 1])\nplt.legend(loc='lower right')","2fc21d63":"### Image Preprocessing\n\nImage Datagenerator - Generate batches of tensor image data with real-time data augmentation.","e5deeefb":"Categorical crossentropy is a loss function that is used in multi-class classification tasks. These are tasks where an example can only belong to one out of many possible categories, and the model must decide which one.\nFormally, it is designed to quantify the difference between two probability distributions.\n\n![CatCrossEntropy](https:\/\/peltarion.com\/static\/categorical_crossentropy_setup.svg)","e0c927e7":"### Plotting Images","e8f50f7c":"### Classes Processing","5085d948":"### Model Building","17fb3452":"### Importing Libraries","a694564a":"![adam](https:\/\/preview.redd.it\/9trhbha3lui21.png?width=521&format=png&auto=webp&s=499099ad10ac65e98754dc48cb01cd0b97456c68)\n\nAdam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models. Adam combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems.","481012ba":"### Setting up Paths"}}