{"cell_type":{"f795d05f":"code","dc41fd5c":"code","38a9ab17":"code","8d309ae7":"code","be44fd85":"code","cbfa0d14":"code","af0ce644":"code","d46e559b":"code","5d7300e5":"code","17274075":"code","616fecfe":"code","701cfbcb":"code","a82766f4":"markdown","def37882":"markdown","e7d4b735":"markdown","1c3bd84d":"markdown","a3701037":"markdown","14bbd2d8":"markdown","cc88d79d":"markdown","af1eb106":"markdown","c0b909fb":"markdown","567c7e22":"markdown","e07e7ac8":"markdown"},"source":{"f795d05f":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_wine\nfrom sklearn.pipeline import make_pipeline\n%matplotlib inline","dc41fd5c":"RANDOM_STATE = 42\nFIG_SIZE = (10, 7)","38a9ab17":"dataset = pd.read_csv('..\/input\/social-network-ads\/Social_Network_Ads.csv')\nX = dataset.iloc[:, [2, 3]].values\ny = dataset.iloc[:, 4].values","8d309ae7":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","be44fd85":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","cbfa0d14":"# Fit to data and predict using pipelined GNB and PCA.\nunscaled_clf = make_pipeline(PCA(n_components=2), GaussianNB())\nunscaled_clf.fit(X_train, y_train)\npred_test = unscaled_clf.predict(X_test)","af0ce644":"std_clf = make_pipeline(StandardScaler(), PCA(n_components=2), GaussianNB())\nstd_clf.fit(X_train, y_train)\npred_test_std = std_clf.predict(X_test)","d46e559b":"print('\\nPrediction accuracy for the normal test dataset with PCA')\nprint('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test)))\nprint()\nprint('\\nPrediction accuracy for the standardized test dataset with PCA')\nprint('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test_std)))\n","5d7300e5":"pca = unscaled_clf.named_steps['pca']\npca_std = std_clf.named_steps['pca']","17274075":"print('\\nPC 1 without scaling:\\n', pca.components_[0])\nprint('\\nPC 1 with scaling:\\n', pca_std.components_[0])","616fecfe":"X_train_transformed = pca.transform(X_train)\nscaler = std_clf.named_steps['standardscaler']\nX_train_std_transformed = pca_std.transform(scaler.transform(X_train))","701cfbcb":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=FIG_SIZE)\n\n\nfor l, c, m in zip(range(0, 3), ('blue', 'red', 'green'), ('^', 's', 'o')):\n    ax1.scatter(X_train_transformed[y_train == l, 0],\n                X_train_transformed[y_train == l, 1],\n                color=c,\n                label='class %s' % l,\n                alpha=0.5,\n                marker=m\n                )\n\nfor l, c, m in zip(range(0, 3), ('blue', 'red', 'green'), ('^', 's', 'o')):\n    ax2.scatter(X_train_std_transformed[y_train == l, 0],\n                X_train_std_transformed[y_train == l, 1],\n                color=c,\n                label='class %s' % l,\n                alpha=0.5,\n                marker=m\n                )\n\nax1.set_title('Training dataset after PCA')\nax2.set_title('Standardized training dataset after PCA')\n\nfor ax in (ax1, ax2):\n    ax.set_xlabel('1st principal component')\n    ax.set_ylabel('2nd principal component')\n    ax.legend(loc='upper right')\n    ax.grid()\n\nplt.tight_layout()\n\nplt.show()","a82766f4":"\n# Use PCA without and with scale on X_train data for visualization.","def37882":"# Importing the dataset","e7d4b735":"# Visualize standardized vs. untouched dataset with PCA performed","1c3bd84d":"# Fitting K-NN to the Training set","a3701037":"# Splitting the dataset into the Training set and Test set","14bbd2d8":"# Fit to data and predict using pipelined scaling, GNB and PCA.","cc88d79d":"\n# Show prediction accuracies in scaled and unscaled data.","af1eb106":"  # Show first principal components","c0b909fb":"# Importing the libraries","567c7e22":"# Extract PCA from pipeline","e07e7ac8":"# Feature Scaling\n\n### <b style=\"color:blue\"> Feature scaling is a method used to normalize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step.<\/b>"}}