{"cell_type":{"ae97cc29":"code","fec3022e":"code","9edd6b4d":"code","e7b63dbd":"code","4a34cf5e":"code","9206367f":"code","cdc7e542":"code","236142d8":"code","699c20ce":"code","2c44104a":"markdown"},"source":{"ae97cc29":"import pandas as pd\nimport numpy as np\nimport os\nimport requests\nimport json\nimport datetime\nimport time\n","fec3022e":"MIN_FINAL_RATING = 500 # top submission in a match must have reached this score\nnum_api_calls_today = 0\n","9edd6b4d":"all_files = []\nfor root, dirs, files in os.walk('..\/input\/', topdown=False):\n    all_files.extend(files)\nseen_episodes = [int(f.split('.')[0]) for f in all_files \n                      if '.' in f and f.split('.')[0].isdigit() and f.split('.')[1] == 'json']\nprint('{} games in existing library'.format(len(seen_episodes)))\n","e7b63dbd":"NUM_TEAMS = 1\nEPISODES = 600 \n\nBUFFER = 1\n\nbase_url = \"https:\/\/www.kaggle.com\/requests\/EpisodeService\/\"\nget_url = base_url + \"GetEpisodeReplay\"\nlist_url = base_url + \"ListEpisodes\"","4a34cf5e":"# inital team list\n\nr = requests.post(list_url, json = {\"teamId\":  5586412}) # arbitrary ID, change to leading ID during challenge\n\nrj = r.json()\n\nteams_df = pd.DataFrame(rj['result']['teams'])","9206367f":"teams_df.sort_values('publicLeaderboardRank', inplace = True)\nteams_df.head(6)","cdc7e542":"def getTeamEpisodes(team_id):\n    # request\n    r = requests.post(list_url, json = {\"teamId\":  int(team_id)})\n    rj = r.json()\n\n    # update teams list\n    global teams_df\n    teams_df_new = pd.DataFrame(rj['result']['teams'])\n    \n    if len(teams_df.columns) == len(teams_df_new.columns) and (teams_df.columns == teams_df_new.columns).all():\n        teams_df = pd.concat( (teams_df, teams_df_new.loc[[c for c in teams_df_new.index if c not in teams_df.index]] ) )\n        teams_df.sort_values('publicLeaderboardRank', inplace = True)\n    else:\n        print('teams dataframe did not match')\n    \n    # make df\n    team_episodes = pd.DataFrame(rj['result']['episodes'])\n    team_episodes['avg_score'] = -1;\n    \n    for i in range(len(team_episodes)):\n        agents = team_episodes['agents'].loc[i]\n        agent_scores = [a['updatedScore'] for a in agents if a['updatedScore'] is not None]\n        team_episodes.loc[i, 'submissionId'] = [a['submissionId'] for a in agents if a['submission']['teamId'] == team_id][0]\n        team_episodes.loc[i, 'updatedScore'] = [a['updatedScore'] for a in agents if a['submission']['teamId'] == team_id][0]\n        \n        if len(agent_scores) > 0:\n            team_episodes.loc[i, 'avg_score'] = np.mean(agent_scores)\n\n    for sub_id in team_episodes['submissionId'].unique():\n        sub_rows = team_episodes[ team_episodes['submissionId'] == sub_id ]\n        max_time = max( [r['seconds'] for r in sub_rows['endTime']] )\n        final_score = max( [r['updatedScore'] for r_idx, (r_index, r) in enumerate(sub_rows.iterrows())\n                                if r['endTime']['seconds'] == max_time] )\n\n        team_episodes.loc[sub_rows.index, 'final_score'] = final_score\n        \n    team_episodes.sort_values('avg_score', ascending = False, inplace=True)\n    return rj, team_episodes","236142d8":"def saveEpisode(epid, rj):\n    # request\n    re = requests.post(get_url, json = {\"EpisodeId\": int(epid)})\n        \n    # save replay\n    with open('{}.json'.format(epid), 'w') as f:\n        f.write(re.json()['result']['replay'])\n\n    # save episode info\n    with open('{}_info.json'.format(epid), 'w') as f:\n        json.dump([r for r in rj['result']['episodes'] if r['id']==epid][0], f)","699c20ce":"global num_api_calls_today\n\npulled_teams = {}\npulled_episodes = []\nstart_time = datetime.datetime.now()\nr = BUFFER;\n\nwhile num_api_calls_today < EPISODES:\n    # pull team\n    top_teams = [i for i in teams_df.id if i not in pulled_teams]\n    if len(top_teams) > 0:\n        team_id = top_teams[0]\n    else:\n        break;\n        \n    # get team data\n    team_json, team_df = getTeamEpisodes(team_id); r+=1;\n    num_api_calls_today+=1\n    print('{} games for {}'.format(len(team_df), teams_df.loc[teams_df.id == team_id].iloc[0].teamName))\n\n    \n    team_df = team_df[  (MIN_FINAL_RATING is None or (team_df.final_score > MIN_FINAL_RATING))]\n    \n    print('   {} in score range from {} submissions'.format(len(team_df), len(team_df.submissionId.unique() ) ) )\n    \n    team_df = team_df[~team_df.id.isin(pulled_episodes + seen_episodes)]        \n    print('      {} remain to be downloaded\\n'.format(len(team_df)))\n        \n    # pull games\n    target_team_games = int(np.ceil(EPISODES \/ NUM_TEAMS))\n    if target_team_games + len(pulled_episodes) > EPISODES:\n        target_team_games = EPISODES - len(pulled_episodes)\n     \n    pulled_teams[team_id] = 0\n    \n    i = 0\n    while i < len(team_df) and pulled_teams[team_id] < target_team_games:\n        epid = team_df.id.iloc[i]\n        if not (epid in pulled_episodes or epid in seen_episodes):\n            try:\n                saveEpisode(epid, team_json); r+=1;\n                num_api_calls_today+=1\n            except:\n                time.sleep(20)\n                i+=1;\n                continue;\n                \n            pulled_episodes.append(epid)\n            pulled_teams[team_id] += 1\n            try:\n                size = os.path.getsize('{}.json'.format(epid)) \/ 1e6\n                print(str(num_api_calls_today) + ': Saved Episode #{} @ {:.1f}MB'.format(epid, size))\n            except:\n                print('  file {}.json did not seem to save'.format(epid))    \n            if r > (datetime.datetime.now() - start_time).seconds:\n                time.sleep( r - (datetime.datetime.now() - start_time).seconds)\n                \n\n        i+=1;\n    print(); print()","2c44104a":"This is an edited version of David NQ's Halite Game Scraper at https:\/\/www.kaggle.com\/david1013\/halite-game-scraper\n\nKaggle's API limit for Google Football is yet to be made explicit but in Kaggle Halite the limit of 1000 requests per day was eventually raised to 3600 requests per day max.\n\nRate limits are shared between the ListEpisodes and GetEpisodeReplay endpoints. Exceeding limits repeatedly will lead to temporary and then permanent bans. At some point it is expected Kaggle will remove this public API and provide datasets of episodes.\n\nThe episodes take a lot of space. In Kaggle Halite, I ended up with 200GB of games. The Football JSON files are **ten times larger** so you may end up with terabytes. If you use this or any scraper, consider posting the dataset to Kaggle Datasets for others to use."}}