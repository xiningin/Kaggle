{"cell_type":{"c3a1dce4":"code","3ae2f0b5":"code","286b807e":"code","26536db8":"code","3f36ce9e":"code","cae2e65a":"code","a59dc4e4":"code","74eaf079":"code","25e026ef":"code","3003b2ef":"code","1739d848":"code","8e9a2a73":"code","2349144c":"code","29e3005d":"code","b13a6344":"code","f883d7a5":"code","e0af46c5":"code","4da0c3a2":"code","24ca70d1":"code","198cee7b":"code","534239d2":"code","aee07cba":"code","fef09474":"code","2cfaabb4":"code","0efafb66":"code","df8c1907":"code","c670b716":"code","ee71cb5c":"code","5ec5b363":"code","1888e653":"code","f9ffccc8":"code","d1c8141a":"code","f3802504":"code","c8aa86c8":"code","ad317a27":"code","2debf42c":"code","e440f938":"code","704cb1a0":"code","5e5c6fc2":"code","f4245739":"code","2b24dcf7":"code","00e45112":"code","e101c4b7":"code","60c726ab":"code","918175ed":"code","49f7adaf":"code","98eeef2a":"code","f57b1b05":"code","2cca15c4":"code","45e3a1e7":"code","058aa60e":"code","d08ad1c3":"code","462fc789":"code","2d064f45":"code","fc53526d":"code","539e3813":"code","5fa7dcd0":"code","5c9c4aea":"code","cbe78e13":"code","90dacad6":"code","25b1ff1a":"markdown","b2344382":"markdown","5d9285fd":"markdown","3d28b81e":"markdown","0b0aba23":"markdown","eb221101":"markdown","f2c4beac":"markdown","40b88809":"markdown","b9071d16":"markdown","da71c817":"markdown","86591644":"markdown","26d53ff5":"markdown"},"source":{"c3a1dce4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3ae2f0b5":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","286b807e":"df_train = pd.read_csv('..\/input\/train.csv')\n\ndf_test = pd.read_csv('..\/input\/test.csv')\n","26536db8":"df_train.drop('Id',axis=1,inplace=True )\nid_test = df_test['Id']                      # for submissions\n","3f36ce9e":"df_test.drop('Id',axis=1,inplace=True )\n","cae2e65a":"df_train.head(5)","a59dc4e4":"df_train.columns","74eaf079":"row_train=df_train.shape[0]\nrow_test=df_test.shape[0]","25e026ef":"df_train['SalePrice'].describe()","3003b2ef":"sns.distplot(df_train['SalePrice'])","1739d848":"# for numeric variable\ndf_train.describe().transpose()","8e9a2a73":"# for categrocial variables\ndf_train.describe(include = ['O']).transpose()","2349144c":"cols = df_train.select_dtypes([np.number]).columns\nprint(cols)","29e3005d":"num_df=df_train[cols]\nnum_df.head(5)","b13a6344":"corrmat = num_df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=1, vmin=0.4, square=True);","f883d7a5":"var = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","e0af46c5":"outliers_GrLivArea = df_train.loc[(df_train['GrLivArea']>4500.0)]\noutliers_GrLivArea[['OverallQual','GrLivArea' , 'SalePrice']]\noutliers=[524,1299]\ndf_train = df_train.drop(df_train.index[outliers])\n","4da0c3a2":"df_train1=df_train[['MSSubClass','YearBuilt','YearRemodAdd','TotalBsmtSF','1stFlrSF','GrLivArea','FullBath','TotRmsAbvGrd','GarageCars', \n          'GarageArea','MSSubClass','MSZoning', 'Neighborhood','LotConfig',\n'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageType','OverallQual']]","24ca70d1":"total = df_train1.isnull().sum().sort_values(ascending=False)\npercent = (df_train1.isnull().sum()\/df_train1.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","198cee7b":"#fill train na\nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond','BsmtQual',\n            'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\"PoolQC\"\n           ,'Alley','Fence','MiscFeature','FireplaceQu','MasVnrType','Utilities']:\n    df_train[col] = df_train[col].fillna('None')\n\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars','MasVnrArea','BsmtFinSF1','BsmtFinSF2'\n           ,'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BsmtUnfSF','TotalBsmtSF'):\n    df_train[col] = df_train[col].fillna(0)\n\n# group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\ndf_train['LotFrontage'] = df_train.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))","534239d2":"# fill test set na\nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond','BsmtQual',\n            'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\"PoolQC\"\n           ,'Alley','Fence','MiscFeature','FireplaceQu','MasVnrType','Utilities']:\n    df_test[col] = df_test[col].fillna('None')\n    \nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars','MasVnrArea','BsmtFinSF1','BsmtFinSF2'\n           ,'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BsmtUnfSF','TotalBsmtSF'):\n    df_test[col] = df_test[col].fillna(0)\n\ndf_test['LotFrontage'] = df_test.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n\ndf_test['MSZoning'] = df_test['MSZoning'].fillna('RL')\ndf_test['KitchenQual'] = df_test['KitchenQual'].fillna(df_test['KitchenQual'].mode()[0])\n","aee07cba":"df_train['GarageYrBlt'] = df_train['GarageYrBlt'].fillna(df_train['YearBuilt'])","fef09474":"# fill test set na\ndf_test['GarageYrBlt'] = df_test['GarageYrBlt'].fillna(df_test['YearBuilt'])","2cfaabb4":"#check train na\ntotal0 = df_train.isnull().sum().sort_values(ascending=False)\npercent0 = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data0 = pd.concat([total0, percent0], axis=1, keys=['Total0', 'Percent0'])\nmissing_data0.head(20)","0efafb66":"#check test na\ntotal1 = df_test.isnull().sum().sort_values(ascending=False)\npercent1 = (df_test.isnull().sum()\/df_test.isnull().count()).sort_values(ascending=False)\nmissing_data1 = pd.concat([total1, percent1], axis=1, keys=['Total1', 'Percent1'])\nmissing_data1.head(20)","df8c1907":"df_train['remod'] = np.where(df_train['YearBuilt']==df_train['YearRemodAdd'],0,1)\ndf_train['age']=df_train['YrSold']-df_train['YearRemodAdd']\ndf_train['new']=np.where(df_train['YrSold']==df_train['YearBuilt'],0,1) # is new house?\ndf_train['TotalBath']=df_train['BsmtFullBath']+0.5*df_train['BsmtHalfBath']+df_train['FullBath']+0.5*df_train['HalfBath']\ndf_train['TotalSqFeet']=df_train['GrLivArea']+df_train['TotalBsmtSF']\ndf_train['TotalPorchSF']=df_train['OpenPorchSF']+df_train['EnclosedPorch']+df_train['3SsnPorch']+df_train['ScreenPorch']","c670b716":"df_test['remod'] = np.where(df_test['YearBuilt']==df_test['YearRemodAdd'],0,1)\ndf_test['age']=df_test['YrSold']-df_test['YearRemodAdd']\ndf_test['new']=np.where(df_test['YrSold']==df_test['YearBuilt'],0,1) # is new house?\ndf_test['TotalBath']=df_test['BsmtFullBath']+0.5*df_test['BsmtHalfBath']+df_test['FullBath']+0.5*df_test['HalfBath']\ndf_test['TotalSqFeet']=df_test['GrLivArea']+df_test['TotalBsmtSF']\ndf_test['TotalPorchSF']=df_test['OpenPorchSF']+df_test['EnclosedPorch']+df_test['3SsnPorch']+df_test['ScreenPorch']","ee71cb5c":"#df_test['TotalBath'] = df_test['TotalBath'].fillna(0.0)\n#df_test['TotalSqFeet'] = df_test['TotalSqFeet'].fillna(0.0)","5ec5b363":"corrmat = df_train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=1, square=True);","1888e653":"corr_num = 15 #number of variables for heatmap\ncols_corr = corrmat.nlargest(corr_num, 'SalePrice')['SalePrice'].index\ncorr_mat_sales = np.corrcoef(df_train[cols_corr].values.T)\nsns.set(font_scale=1.25)\nf, ax = plt.subplots(figsize=(12, 9))\nhm = sns.heatmap(corr_mat_sales, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 7}, yticklabels=cols_corr.values, xticklabels=cols_corr.values)\nplt.show()","f9ffccc8":"#num_df1=df_train[[, \n              #  , , ,'age',',','TotalPorchSF']]","d1c8141a":"#'OverallQual','TotalSqFeet','GrLivArea','GarageCars','TotalBath','GarageArea','TotalBsmtSF', '1stFlrSF', 'FullBath','YearBuilt',\n#'GarageYrBlt','YearRemodAdd','TotRmsAbvGrd'","f3802504":"sns.distplot(df_train['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)","c8aa86c8":"df_train['SalePrice'] = np.log(df_train['SalePrice'])","ad317a27":"sns.distplot(df_train['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)","2debf42c":"X_train=df_train[['OverallQual', 'GrLivArea', 'TotalSqFeet', 'GarageCars','TotalBath','GarageArea','TotalBsmtSF',\n'1stFlrSF','FullBath','YearBuilt','MSSubClass','MSZoning','Neighborhood','LotConfig','YearRemodAdd','TotRmsAbvGrd',\n'HeatingQC','KitchenQual','FireplaceQu','OverallQual']]\ny_train=df_train['SalePrice']","e440f938":"\nX_test=df_test[['OverallQual', 'GrLivArea', 'TotalSqFeet', 'GarageCars','TotalBath','GarageArea','TotalBsmtSF',\n'1stFlrSF','FullBath','YearBuilt','MSSubClass','MSZoning','Neighborhood','LotConfig','YearRemodAdd','TotRmsAbvGrd',\n'HeatingQC','KitchenQual','FireplaceQu','OverallQual']]","704cb1a0":"#check final feature train set na\n\ntotal2 = X_train.isnull().sum().sort_values(ascending=False)\npercent2 = (X_train.isnull().sum()\/X_train.isnull().count()).sort_values(ascending=False)\nmissing_data2 = pd.concat([total2, percent2], axis=1, keys=['Total2', 'Percent2'])\nmissing_data2.head(20)","5e5c6fc2":"#check final feature test set na\ntotal3 = X_test.isnull().sum().sort_values(ascending=False)\npercent3 = (X_test.isnull().sum()\/X_test.isnull().count()).sort_values(ascending=False)\nmissing_data3 = pd.concat([total3, percent3], axis=1, keys=['Total3', 'Percent3'])\nmissing_data3.head(20)","f4245739":"#convert numeric to string\nstr_vars = ['MSSubClass','YrSold','MoSold']\nfor var in str_vars:\n    df_train[var] = df_train[var].apply(str)\n    df_test[var] = df_test[var].apply(str)","2b24dcf7":"#one hot encoding\nX_train1 = pd.get_dummies(data=X_train, drop_first=True)\nX_train1.head(5)","00e45112":"X_test1 = pd.get_dummies(data=X_test, drop_first=True)","e101c4b7":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, make_scorer\n#lr = LinearRegression()\n#lr.fit(X_train1, y_train)\n\n","60c726ab":"from sklearn.model_selection import cross_val_score, train_test_split\nscorer = make_scorer(mean_squared_error, greater_is_better = False)\n\ndef rmse_cv_train(model):\n    rmse= np.sqrt(-cross_val_score(model, X_train1, y_train, scoring = scorer, cv = 10))\n    return(rmse)","918175ed":"#lasso regression\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.pipeline import make_pipeline","49f7adaf":"lr = LinearRegression()","98eeef2a":"kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\nalphas2 = [0.0001, 0.0002, 0.0003, 0.0005, 0.0006, 0.0007]\nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, \n                    alphas=alphas2,random_state=42, cv=kfolds))","f57b1b05":"alphas_alt = [14.6, 14.7,15, 15.1, 15.3, 15.4]\nridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))","2cca15c4":"e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\nelastic = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, \n                         alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))","45e3a1e7":"import lightgbm as lgb\nfrom lightgbm import LGBMRegressor\n\nlgbm = LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)","058aa60e":"# store models, scores and prediction values \nmodels = {'Ridge': ridge,\n          'Lasso': lasso, \n          'Linear regression':lr\n#          'ElasticNet': elasticnet}\n#           'lightgbm': lightgbm,\n#           'xgboost': xgboost}\n         }\npredictions = {}\nscores = {}","d08ad1c3":"# model scoring and validation function\ndef cv_rmse(model, X_train1=X_train1):\n    rmse = np.sqrt(-cross_val_score(model, X_train1, y_train, scoring=\"neg_mean_squared_error\",cv=kfolds))\n    return (rmse)\n\n# rmsle scoring function\ndef rmsle(y_train, y_train_pred):\n    return np.sqrt(mean_squared_error(y_train, y_train_pred))","462fc789":"for name, model in models.items():\n    \n    model.fit(X_train1, y_train)\n    predictions[name] = np.expm1(model.predict(X_train1))\n    \n    score = cv_rmse(model, X_train1)\n    scores[name] = (score.mean(), score.std())","2d064f45":"# get the performance of each model on training data(validation set)\nprint('---- Score with CV_RMSLE-----')\nscore = cv_rmse(lr)\nprint(\"Linear regression score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = cv_rmse(ridge)\nprint(\"Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = cv_rmse(lasso)\nprint(\"Lasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = cv_rmse(elastic)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = cv_rmse(lgbm)\nprint(\"lgbm score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","fc53526d":"\nlgbm_fit = lgbm.fit(X_train1, y_train)\ny_test_pred = lgbm_fit.predict(X_test1)\n","539e3813":"#y_test_pred = lgbm_model_fit.predict(X_test1)","5fa7dcd0":"#Inverse Logtransforming using np.expm1\ny_test_pred_final=np.expm1(y_test_pred)\ny_test_pred_final\n\n","5c9c4aea":"len(y_test_pred_final)\n","cbe78e13":"df_test.shape","90dacad6":"my_submission = pd.DataFrame({'Id': id_test, 'SalePrice': y_test_pred_final})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","25b1ff1a":"From the heatmap, see OverallQual, YearBuilt, YearRemodAdd,TotalBsmtSF, 1stFlrSF\uff0cGrLivArea, FullBath, TotRmsAbvGrd, GarageCars, GarageArea ","b2344382":"run heatmap again","5d9285fd":"Log transformation of SalePrice","3d28b81e":"Train model","0b0aba23":"Select catogorical varables based on business sense. \/\/\nHouse type:MSSubClass\/\/\nSurrouding conditions: MSZoning, Neighborhood\/\/\nHouse appearance: LotConfig\/\/\nHouse Facility: HeatingQC, KitchenQual, FireplaceQu, GarageType\/\/\nHouse Quality: OverallQual\n","eb221101":"Good news! The features that I select don't have too much missing values.","f2c4beac":"Seperate characteristic and numeric variables","40b88809":"Create new variable","b9071d16":"house 524 and 1299 are outliers with really big area and low salesprice","da71c817":"my submission","86591644":"Model 1","26d53ff5":"Check missing value"}}