{"cell_type":{"52f4b8b7":"code","965d326c":"code","83a7446f":"code","3b3354ae":"code","ccbfae2c":"code","e89588ab":"code","7a03cb8d":"code","4ac7899d":"code","6f180753":"code","32d41866":"code","a984321d":"code","11ed5dd0":"markdown","e7b1f5b8":"markdown","663034ad":"markdown","96b5321b":"markdown","af0e9865":"markdown","bfdaf0b7":"markdown"},"source":{"52f4b8b7":"%matplotlib inline\n\n#ignore all warning informations\nimport warnings \nwarnings.filterwarnings('ignore') \n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimage\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow import keras\nfrom tensorflow.keras.models import load_model\n","965d326c":"train_dir='..\/input\/cat-and-dog\/training_set\/training_set\/'\ntest_dir='..\/input\/cat-and-dog\/test_set\/test_set\/'\n\n\ntrain_cat_dir=train_dir+'cats'\ntrain_dog_dir=train_dir+'dogs'\n\ntrain_cat_fnames=os.listdir(train_cat_dir)\ntrain_dog_fnames=os.listdir(train_dog_dir)\n\n# test_cat_fnames=os.listdir(test_dir+'cats')\n# test_dog_fnames=os.listdir(test_dir+'dogs')","83a7446f":"nrows=4\nncols=4\npic_index=0","3b3354ae":"fig=plt.gcf()\nfig.set_size_inches(nrows*4,ncols*4)\n\npic_index+=8\n\nnext_cat_pix=[os.path.join(train_cat_dir,fname) for fname in train_cat_fnames[pic_index-8:pic_index]]\nnext_dog_pix=[os.path.join(train_dog_dir,fname) for fname in train_dog_fnames[pic_index-8:pic_index]]\n\nfor i,img_path in enumerate(next_cat_pix+next_dog_pix):\n    sp=plt.subplot(nrows,ncols,i+1)\n    sp.axis('off')\n    \n    img=mpimage.imread(img_path)\n    plt.imshow(img)\n    ","ccbfae2c":"train_datagen=ImageDataGenerator(rescale=1.0\/255.0,#rescaling factor\n                                rotation_range=45, #Int. Degree range for random rotations.\n                                width_shift_range=0.2, #fraction of total width\n                                height_shift_range=0.2,#fraction of total height\n                                shear_range=0.2, #Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n                                zoom_range=0.2,#Float or [lower, upper]. Range for random zoom\n                                horizontal_flip=True,#Boolean. Randomly flip inputs horizontally.\n                                fill_mode='nearest' #Points outside the boundaries of the input are filled according to the given mode\n                                )\n\ntest_datagen=ImageDataGenerator(rescale=1.0\/255.0)\n\n#ImageDataGenarator will generate dataset, as well as generate training labels based on the path,for example,\n#our training directory is ..\/input\/cat-and-dog\/training_set\/training_set\/, there are two directory under it, cats and dogs,\n#then the generator will generate data with label 'cats' and 'dogs', and with all pictures under each directory respectively\ntrain_generator=train_datagen.flow_from_directory(train_dir,\n                                                target_size=(150,150),\n                                                batch_size=20,\n                                                class_mode='binary')\n\ntest_generator=test_datagen.flow_from_directory(test_dir,\n                                                target_size=(150,150),\n                                                batch_size=20,\n                                                class_mode='binary')\n","e89588ab":"model=tf.keras.models.Sequential([\n    keras.layers.Conv2D(32,(3,3),input_shape=(150,150,3),activation='relu'),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Conv2D(64,(3,3),activation=\"relu\"),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Conv2D(128,(3,3),activation='relu'),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Conv2D(128,(3,3),activation='relu'),\n    keras.layers.MaxPooling2D(2,2),\n    \n    keras.layers.Flatten(),\n    keras.layers.Dense(512,activation='relu'),\n    keras.layers.Dense(1,activation='sigmoid')    \n])","7a03cb8d":"model.summary()","4ac7899d":"model.compile(loss='binary_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])","6f180753":"history=model.fit_generator(train_generator,\n                  epochs=150,\n                  steps_per_epoch=100,\n                  validation_data=test_generator,\n                  validation_steps=50,\n                  verbose=1\n                 )","32d41866":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')","a984321d":"#Save model to a file\nmodel.save('cat-dogs-model.h5') ","11ed5dd0":"Based the result above, the training is quite good because accurary of validation set is higher than that of training set.\nI only trained for 150 epochs and you can try to set it o 200 or more, to see how accurate you can get at the end.\n\nI plot the result as below, as you can see, the accuracy of both training and validation are still growing,which means we defenity can improve that by adding more epochs, and at the sametime, there's no sigh of overfitting, which is great.","e7b1f5b8":"## Using Keras to do image classification\nThis kernel uses Keras within Tensorflow to build CNN to build a model to do image classification.\n\nHere are the steps:\n1. Load dataset, both training and testing(validation) dataset\n2. Image preprocess with data argumentation API - ImageDataGenerator\n3. Setup model parameters\n4. Train the model\n5. Plot accuracy line to check how the model is working\n6. Save model to a file\n\nThese are typical steps for image classification.","663034ad":"We will use three CNN with three Maxpooling layers first, then get it flattened,then one fully connected layer with 512 neurons.  \nfor input layer and all hidden layers, we will use relu as activation function. \nIn the output layer, we will use sigmoid to activate it.","96b5321b":"# If you think this kernel helped you, I will be gratefull if you upvote it, and any comments are welcome.","af0e9865":"Let's see how the pictures look like","bfdaf0b7":"We use ImageDataGenerator to do data argumentation,please note we only apply argumentation to training data, and only rescalling with testing(validation) data"}}