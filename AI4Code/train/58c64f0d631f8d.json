{"cell_type":{"d05eb872":"code","e8dc3ee6":"code","9b8a0588":"code","e0de3e8f":"code","8d3150a9":"code","5e648953":"code","d06d8cbc":"code","5182dae7":"code","c3bee495":"code","63af9e34":"code","4e986090":"code","f6ef6e0c":"code","d7540162":"code","966bd495":"code","b876321c":"code","73ff9491":"code","620bc0e6":"code","286bcce4":"code","92753441":"code","d0a7f8e0":"code","92614a61":"code","bbe28db2":"code","4b877f36":"code","0ad992f0":"code","49cadc50":"code","2c1778e3":"code","f9ea0474":"code","227847a9":"code","f8321a09":"code","6bdd92da":"code","bd4973b6":"code","e608e1e0":"code","595b4e78":"code","56e7c8b3":"code","f051dded":"code","63f86b94":"markdown","6026aa06":"markdown","245989f5":"markdown","d42decd8":"markdown","9122c88a":"markdown","c3446b80":"markdown","66cce1ea":"markdown","f02d8fdc":"markdown","9ed12fff":"markdown","5eefd6d3":"markdown","56d80df7":"markdown","106ac1d6":"markdown","a7734f70":"markdown"},"source":{"d05eb872":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e8dc3ee6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","9b8a0588":"data = pd.read_csv(\"..\/input\/imdb-movie-ratings-sentiment-analysis\/movie.csv\")","e0de3e8f":"data.head()","8d3150a9":"data.info()","5e648953":"data.isnull().sum()","d06d8cbc":"data.shape","5182dae7":"data['label'].value_counts()","c3bee495":"from wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nfrom wordcloud import ImageColorGenerator\ntext = \" \".join(i for i in data.text)\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\nplt.figure( figsize=(15,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","63af9e34":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus = []\nfor i in range(0, len(data)):\n  review = re.sub('[^a-zA-Z]', ' ', data['text'][i])\n  review = review.lower()\n  review = review.split()\n  ps = PorterStemmer()\n  all_stopwords = stopwords.words('english')\n  all_stopwords.remove('not')\n  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n  review = ' '.join(review)\n  corpus.append(review)","4e986090":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1500,ngram_range=(1,3))\nX = cv.fit_transform(corpus).toarray()\ny = data.iloc[:, -1].values","f6ef6e0c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","d7540162":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)","966bd495":"y_pred = classifier.predict(X_test)","b876321c":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc = accuracy_score(y_test, y_pred)","73ff9491":"print(acc)","620bc0e6":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_v=TfidfVectorizer(max_features=5000,ngram_range=(1,3))\nX=tfidf_v.fit_transform(corpus).toarray()","286bcce4":"y=data['label']","92753441":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","d0a7f8e0":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","92614a61":"count_df = pd.DataFrame(X_train, columns=tfidf_v.get_feature_names())","bbe28db2":"count_df.head()","4b877f36":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)","0ad992f0":"y_pred = classifier.predict(X_test)","49cadc50":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","2c1778e3":"acc1 = accuracy_score(y_test, y_pred)\nacc1","f9ea0474":"from sklearn.naive_bayes import MultinomialNB\nclassifier=MultinomialNB()","227847a9":"classifier.fit(X_train, y_train)\npred = classifier.predict(X_test)\npred = classifier.predict(X_test)\nscore = accuracy_score(y_test, pred)\nscore","f8321a09":"classifier=MultinomialNB(alpha=0.1)","6bdd92da":"previous_score=0\nfor alpha in np.arange(0,1,0.1):\n    sub_classifier=MultinomialNB(alpha=alpha)\n    sub_classifier.fit(X_train,y_train)\n    y_pred=sub_classifier.predict(X_test)\n    score = accuracy_score(y_test, pred)\n    if score>previous_score:\n        classifier=sub_classifier\n    print(\"Alpha: {}, Score : {}\".format(alpha,score))","bd4973b6":"from xgboost import XGBClassifier\nclassifier = XGBClassifier()\nclassifier.fit(X_train, y_train)","e608e1e0":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc4 = accuracy_score(y_test, y_pred)","595b4e78":"print(acc4)","56e7c8b3":"mylist=[]\nmylist2=[]\nmylist.append(acc)\nmylist2.append(\"Naive Bayes(Bag of Words)\")\nmylist.append(acc1)\nmylist2.append(\"Naive Bayes(TF - IDF)\")\nmylist.append(score)\nmylist2.append(\"MultinominalNB\")\nmylist.append(acc4)\nmylist2.append(\"XG Boost\")","f051dded":"plt.rcParams['figure.figsize']=8,6\nsns.set_style(\"darkgrid\")\nax = sns.barplot(x=mylist2, y=mylist, palette = \"rocket\", saturation =1.5)\nplt.xlabel(\"Classification Models\", fontsize = 20 )\nplt.ylabel(\"Accuracy\", fontsize = 20)\nplt.title(\"Accuracy of different Classification Models\", fontsize = 20)\nplt.xticks(fontsize = 11, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2%}', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","63f86b94":"# Most common words","6026aa06":"# Training the Naive Bayes model on the Training set","245989f5":"# Confusion Matrix","d42decd8":"# Splitting the dataset into the Training set and Test set","9122c88a":"# Naive Bayes ","c3446b80":"# Creating the TF - IDF Vectorizer model","66cce1ea":"# Cleann the texts","f02d8fdc":"# Creating the Bag of Words model","9ed12fff":"# Multinomial Classifier with Hyperparameter","5eefd6d3":"# Splitting the dataset into the Training set and Test set for TF - IDF","56d80df7":"# MultinomialNB Algorithm","106ac1d6":"# Create visualization for all models","a7734f70":"# confusion matrix"}}