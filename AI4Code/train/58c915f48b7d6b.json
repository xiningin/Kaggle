{"cell_type":{"553f0df2":"code","854071fd":"code","52cc0693":"code","aab65fba":"code","efc90219":"code","931a6e48":"code","b3b46d11":"code","1a945e93":"code","a6f6105e":"code","696c202c":"code","5272fd2f":"code","d1762f92":"code","e0599495":"markdown","b9f9a384":"markdown","14606265":"markdown","e97a7980":"markdown","10a7d52b":"markdown","cef78887":"markdown","8ddc6b26":"markdown","da98dd1b":"markdown"},"source":{"553f0df2":"!pip install --quiet \/kaggle\/input\/kerasapplications\n!pip install --quiet \/kaggle\/input\/efficientnet-git","854071fd":"import math, os, re, warnings, random, glob\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import Sequential, Model\nimport efficientnet.tfkeras as efn\n\ndef seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 0\nseed_everything(seed)\nwarnings.filterwarnings('ignore')","52cc0693":"# TPU or GPU detection\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(f'Running on TPU {tpu.master()}')\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","aab65fba":"BATCH_SIZE = 16 * REPLICAS\nHEIGHT = 512\nWIDTH = 512 \nCHANNELS = 3\nN_CLASSES = 5\nTTA_STEPS = 3 # Do TTA if > 0 ","efc90219":"def data_augment(image, label):\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n            \n    # \u041f\u043e\u0432\u043e\u0440\u043e\u0442\u044b\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        \n    # \u0412\u0440\u0430\u0449\u0435\u043d\u0438\u0435\n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3) # rotate 270\u00ba\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) # rotate 180\u00ba\n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1) # rotate 90\u00ba\n        \n    # \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043d\u0430 \u0443\u0440\u043e\u0432\u043d\u0435 \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439\n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n            \n\n    return image, label","931a6e48":"# Datasets utility functions\ndef get_name(file_path):\n    parts = tf.strings.split(file_path, os.path.sep)\n    name = parts[-1]\n    return name\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    \n#     image = center_crop(image)\n    return image\n\ndef center_crop(image):\n    image = tf.reshape(image, [600, 800, CHANNELS]) # Original shape\n    \n    h, w = image.shape[0], image.shape[1]\n    if h > w:\n        image = tf.image.crop_to_bounding_box(image, (h - w) \/\/ 2, 0, w, w)\n    else:\n        image = tf.image.crop_to_bounding_box(image, 0, (w - h) \/\/ 2, h, h)\n        \n    image = tf.image.resize(image, [HEIGHT, WIDTH]) # Expected shape\n    return image\n\ndef resize_image(image, label):\n    image = tf.image.resize(image, [HEIGHT, WIDTH])\n    image = tf.reshape(image, [HEIGHT, WIDTH, CHANNELS])\n    return image, label\n\ndef process_path(file_path):\n    name = get_name(file_path)\n    img = tf.io.read_file(file_path)\n    img = decode_image(img)\n    return img, name\n\ndef get_dataset(files_path, shuffled=False, tta=False, extension='jpg'):\n    dataset = tf.data.Dataset.list_files(f'{files_path}*{extension}', shuffle=shuffled)\n    dataset = dataset.map(process_path, num_parallel_calls=AUTO)\n    if tta:\n        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.map(resize_image, num_parallel_calls=AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","b3b46d11":"database_base_path = '\/kaggle\/input\/cassava-leaf-disease-classification\/'\nsubmission = pd.read_csv(f'{database_base_path}sample_submission.csv')\ndisplay(submission.head())\n\nTEST_FILENAMES = tf.io.gfile.glob(f'{database_base_path}test_tfrecords\/ld_test*.tfrec')\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nprint(f'GCS: test: {NUM_TEST_IMAGES}')","1a945e93":"model_path_list = glob.glob('\/kaggle\/input\/cassava-leaf-disease-tpu-tensorflow-training\/*.h5')\nmodel_path_list.sort()\n\nprint('Models to predict:')\nprint(*model_path_list, sep='\\n')","a6f6105e":"model_path_list_2 = glob.glob('\/kaggle\/input\/cassava-leaf-disease-training-with-tpu-v2-pods\/*.h5')\nmodel_path_list_2.sort()\n\nprint('Models to predict:')\nprint(*model_path_list_2, sep='\\n')","696c202c":"def model_fn(input_shape, N_CLASSES):\n    inputs = L.Input(shape=input_shape, name='inputs')\n    base_model = efn.EfficientNetB3(input_tensor=inputs, \n                                    include_top=False, \n                                    weights=None, \n                                    pooling='avg')\n\n    model = tf.keras.Sequential([\n        base_model,\n        L.Dropout(.25),\n        L.Dense(N_CLASSES, activation='softmax', name='output')\n    ])\n    \n    return model\n\ndef model_fn_2(input_shape, N_CLASSES):\n    inputs = L.Input(shape=input_shape, name='inputs')\n    base_model = efn.EfficientNetB4(input_tensor=inputs, \n                                    include_top=False, \n                                    weights=None, \n                                    pooling='avg')\n    \n    \n\n\n    x = L.Dropout(.5)(base_model.output)\n    output = L.Dense(N_CLASSES, activation='softmax', name='output')(x)\n    model = Model(inputs=inputs, outputs=output)\n\n    return model\n\n\nwith strategy.scope():\n    model = model_fn((None, None, CHANNELS), N_CLASSES)\n    model_2 = model_fn_2((None, None, CHANNELS), N_CLASSES)\n    \nmodel.summary()\n# model_2.summary()","5272fd2f":"files_path = f'{database_base_path}test_images\/'\ntest_preds = np.zeros((len(os.listdir(files_path)), N_CLASSES))\n\n\nprint('First model')\nfor model_path in model_path_list:\n    print(model_path)\n    K.clear_session()\n    model.load_weights(model_path)\n\n    if TTA_STEPS > 0:\n        test_ds = get_dataset(files_path, tta=True)\n        for step in range(TTA_STEPS):\n            print(f'TTA step {step+1}\/{TTA_STEPS}')\n            x_test = test_ds.map(lambda image, image_name: image)\n            test_preds += model.predict(x_test) \/ (TTA_STEPS * len(model_path_list))\n    else:\n        test_ds = get_dataset(files_path, tta=False)\n        x_test = test_ds.map(lambda image, image_name: image)\n        test_preds += model.predict(x_test) \/ len(model_path_list)\n\n\nprint('\\nSecond model')\nfor model_path in model_path_list_2:\n    print(model_path)\n    K.clear_session()\n    model_2.load_weights(model_path)\n\n    if TTA_STEPS > 0:\n        test_ds = get_dataset(files_path, tta=True)\n        for step in range(TTA_STEPS):\n            print(f'TTA step {step+1}\/{TTA_STEPS}')\n            x_test = test_ds.map(lambda image, image_name: image)\n            test_preds += model_2.predict(x_test) \/ (TTA_STEPS * len(model_path_list))\n    else:\n        test_ds = get_dataset(files_path, tta=False)\n        x_test = test_ds.map(lambda image, image_name: image)\n        test_preds += model_2.predict(x_test) \/ len(model_path_list)\n    \ntest_preds = np.argmax(test_preds, axis=-1)\nimage_names = [img_name.numpy().decode('utf-8') for img, img_name in iter(test_ds.unbatch())]","d1762f92":"submission = pd.DataFrame({'image_id': image_names, 'label': test_preds})\nsubmission.to_csv('submission.csv', index=False)\ndisplay(submission.head())","e0599495":"# Model parameters","b9f9a384":"## Dependencies","14606265":"# \u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f","e97a7980":"# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435","10a7d52b":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","cef78887":"# \u0412\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438","8ddc6b26":"### Hardware configuration","da98dd1b":"# \u0412\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u043e\u0432"}}