{"cell_type":{"6cd29218":"code","9b7c1068":"code","00497151":"code","e6dbb82b":"code","efff7ef2":"code","3a84c00e":"code","3ca7dd6c":"code","04b0b312":"code","059a7673":"code","501d1a06":"code","6a785d82":"code","84073201":"code","d9613140":"code","6d5b43fb":"code","afbcf040":"code","a1912f68":"code","d11bfe9d":"code","02e585db":"code","a214d1ef":"code","331cf7a7":"code","48332850":"code","16e2e4b7":"code","02096a0a":"code","b7eccf9b":"code","5e6d6bc0":"code","ec72b19a":"code","34c81133":"code","267f8db5":"code","e6a965da":"code","7e06dbae":"code","93086198":"code","70dcd786":"code","30e72cfb":"markdown","20e56a1a":"markdown","b9c888fb":"markdown","b17bd8df":"markdown","62c71486":"markdown","a49d0e42":"markdown","0c87334d":"markdown","b78c6653":"markdown","ccaa1b8f":"markdown","5a8dedd2":"markdown","1a5b03ae":"markdown","3ca8ea9b":"markdown","1db4eb4f":"markdown","c5cb0ba7":"markdown","706012fd":"markdown","07173b30":"markdown","25414ca9":"markdown","f831e48d":"markdown","771c7746":"markdown","ea88f579":"markdown","4f7922c5":"markdown","a08d7e22":"markdown","7fb716b1":"markdown","7266dce5":"markdown","fdc9a0b5":"markdown","b658b37d":"markdown","412513ca":"markdown","0196eaf3":"markdown","72eb38a1":"markdown","d034ba60":"markdown","c968f72c":"markdown","df40f818":"markdown","1ad689e6":"markdown","bbd1fb24":"markdown","85b2669a":"markdown","aa096636":"markdown","9ef04763":"markdown","28803b77":"markdown","92211b8b":"markdown","8284ad93":"markdown","0ae55598":"markdown","342dcf9a":"markdown"},"source":{"6cd29218":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9b7c1068":"import keras\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np","00497151":"Train_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\nTest_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","e6dbb82b":"Train_data.shape","efff7ef2":"Train_data.head()","3a84c00e":"X=Train_data.drop('label',axis=1).values\ny=Train_data['label'].values","3ca7dd6c":"X.shape","04b0b312":"test = Test_data.values","059a7673":"X=X\/255\ntest=test\/255","501d1a06":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)","6a785d82":"print(X_train.shape)\nprint(X_test.shape)","84073201":"X_train  = X_train.reshape(-1,28,28)\nX_test = X_test.reshape(-1,28,28)","d9613140":"plt.matshow(X_train[0])","6d5b43fb":"y_train[0]","afbcf040":"from keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Activation\n\nmodel = Sequential()\nmodel.add(Flatten(input_shape=[28,28]))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(10,activation='softmax'))\n","a1912f68":"model.summary()","d11bfe9d":"model.compile(loss='sparse_categorical_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])","02e585db":"model.fit(X_train,y_train,epochs=35)","a214d1ef":"model.evaluate(X_test,y_test)","331cf7a7":"test=test.reshape(-1,28,28)","48332850":"yp=model.predict(test)","16e2e4b7":"plt.matshow(test[0])","02096a0a":"yp[0]","b7eccf9b":"y_pred=np.argmax(yp, axis=1)","5e6d6bc0":"y_pred","ec72b19a":"plt.matshow(test[0])","34c81133":"y_pred[0]","267f8db5":"ypredictions = model.predict(X_test)\nypredictions=np.argmax(ypredictions, axis=1)","e6a965da":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,ypredictions)\nprint(cm)","7e06dbae":"import seaborn as sns\nplt.subplots(figsize=(15,8))\nsns.heatmap(cm,annot=True,fmt='g')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","93086198":"sub = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')","70dcd786":"sub['Label']=y_pred\n#sub.to_csv(\"Submission.csv\",index=False)\nsub.head()","30e72cfb":"Now we will import train_test_split module from sklearn.model_selection library which will help us in spliting our dataset in Training data and Testing data.","20e56a1a":"label which represent this image is 8.","b9c888fb":"# About the Dataset","b17bd8df":"Now from here our Neural Network part starts.\n\nWe will import Sequential model from Keras.models library.\n\nAnd import Flatten, Dense, Activation Layer\n   * Flatten is used to flatten a matrix to a 1D-Array\n   * Dense is used to add hidden layers and output layers\n   * Activation is used to add and activation to model. Some popular activation are: Sigmoid, Relu, Softmax\n   \nYou can learn more by going through the keras documentation site: https:\/\/keras.io\/","62c71486":"The matrix shows the Predicted Label on X-axis and True label on Y-axis.","a49d0e42":"In our yp i.e. predictions, we get an array as an output for a row of features from X_test.\n\nThe array represents the probabilites for each label and we can see in the above output that at index=2 we got the maximum probability.\n\nSo for the first image it predicts 2, which is absolutely correct.","0c87334d":"# Predicitng from model\nNow we will predict our output for our X_test data using our trained model.","b78c6653":"Here we will import all the necessary packages which we will require in to solve these problem. \n\n>#### Here is the brief introduction about all the packages from their documentation page.\n\n> **Keras** is an open-source neural-network library written in Python. It is capable of running on top of TensorFlow, Microsoft Cognitive Toolkit, R, Theano, or PlaidML. Designed to enable fast experimentation with deep neural networks, it focuses on being user-friendly, modular, and extensible. \n\n> **Pandas** is a Python package providing fast, flexible, and expressive data structures designed to make working with structured (tabular, multidimensional, potentially heterogeneous) and time series data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis \/ manipulation tool available in any language.\n\n>**Matplotlib** produces publication-quality figures in a variety of hardcopy formats and interactive environments across platforms. Matplotlib can be used in Python scripts, the Python and IPython shell, web application servers, and various graphical user interface toolkits.\n\n>**NumPy** is the fundamental package for array computing with Python.\n\n>**sklearn** Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities.\n\n>**Seaborn** ta visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.","ccaa1b8f":"![image.png](attachment:image.png)","5a8dedd2":"But for each image we get probabilites for each label. We can simplify this by using the np.argmax() function which represent the highest probability for the test image and thus, classify the image.","1a5b03ae":"# Import Necessary Packages","3ca8ea9b":"## **Hello Everyone!**\n\nThis is my first Neural Network Notebook. \n\nYou may also call MNIST, **Hello World!** of Deep Learning.\n\nIn this I have learn how to apply Multi Layer Neural Network for Multi Class Classification. \n\nAnd I think that it would be very benificial to all of you wh are beginner in Deep Learning.","1db4eb4f":"In the above dataframe, among the 785 columns, 1st columns is for the **Label** which is our **target** or our class.","c5cb0ba7":"As we can see in the above image that each image is of 28x28 pixels. \n\nLets consider a table of 28x28 cells i.e. total of 784 cells. And each cell contains some value between 0 - 255. \n\nIf the value is **0** - then its **'black'**\n\nIf the value is **255** - then its **'white'**\n\nAnd if its between 0-255 then it will be **'gray'** with respect to its value as it shows intensity.\n\nRange 0f 0-255 is quite large and if we can bring all the values between 0 to 1 then our model will work more efficiently.\n\nSo we need to divide each value by 255 which will give us value between 0 to 1.","706012fd":"# Compiling the model","07173b30":"# **Digits Recoginizer using Keras for Beginners - 0.974 Accuracy**","25414ca9":"# Split the Data","f831e48d":"Now we will split our dataset in Features(X) and Target(y).","771c7746":"The matrix may change each time we run the notebook.","ea88f579":"![image.png](attachment:image.png)","4f7922c5":"We can you use model.summary() funtion to view the summary of our model.\n\n* The first Layer is the Input Layer which includes 784 nodes.\n* The second Layer is the hidden layer of 256 nodes. \n* The last layer is the output layer of 10, which classifies all the numbers from 0-9.","a08d7e22":"\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning lighter. This pixel-value is an integer between 0 and 255, inclusive.\n\nThe training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.","7fb716b1":"![image.png](attachment:image.png)","7266dce5":"## *Thank you!* for being with me till the end. Hope you liked the notebook. \n\n## Please upvote\ud83d\udc4d this notebook as it motivates me to play with more datasets and share with you all.","fdc9a0b5":"![ezgif-1-6bce8ddc963c.jpg](attachment:ezgif-1-6bce8ddc963c.jpg)","b658b37d":"# Neural Network Model","412513ca":"The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n\n\n","0196eaf3":"# Training our model","72eb38a1":"# Normalize the Data\n\n### Two Questions arise here:\n\n1. Why do we need to normalize our Data ?\n\n2. Why do we need to divide by 255 to normalize the Data ?","d034ba60":"We will fit our model to X_train and y_train datasets to train our model.\n\nEpochs are the number of iterations to be performed to train our model.","c968f72c":"Our Training data consist of 42000 rows and 785 columns.","df40f818":"# Evaluating our model","1ad689e6":"![image.png](attachment:image.png)","bbd1fb24":"### **Finally, we have built our first Neural Network model which classifies the hand-written images.**","85b2669a":"We will evaluate this model on our splitted test data. \n\nmodel.evaluate() function will return two values.\n* Loss value\n* metrics value i.e. Accuracy","aa096636":"The first image in our test dataset is 2.","9ef04763":"We can see that our data is split in Train and testing. We will train our model using X_train and test our model on X_test. Spliting also helps in evaluating our model better.","28803b77":"Now we will store **train.csv** and **test.csv** in their respective format using pandas.read_csv function","92211b8b":"# Submiting our output\n\nWe will submit our submission csv file using pandas.to_csv() function.","8284ad93":"# Classification Matrix\n\nHere we are using just above splitted test data (which we splitted using train_test_split) to create a confusion matrix to visulalise results of our model.","0ae55598":"# Reshape the Data\n\nWe will reshape our data so we can plot it.\n\n-1 means the reshape function automatically computer the first parameter, and as our images are in 784(28x28) pixels, so we will reshape it to matirx of 28x28","342dcf9a":"We will use Cross Entropy ti calculate Loss, optimizer - 'adam' and metrics as 'accuracy'.\n\nYou can learn more about the parameters on the documentation page."}}