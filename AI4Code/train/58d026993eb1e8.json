{"cell_type":{"3e48bddf":"code","442e1f5f":"code","aea9aba6":"code","a2136ebf":"code","49a68dfe":"code","8f6d44c9":"code","c91d1893":"code","89bbd03a":"code","a4754d62":"code","4c3ae511":"code","60ac80f2":"code","3772f622":"code","402dd33f":"code","a3db0c20":"code","e9be0cd2":"code","c8019ab4":"code","115fd25a":"code","d6c14ec2":"code","c129cd45":"code","a2bc1f18":"code","144a29e6":"code","79e0f8de":"code","a6c0c671":"markdown","cbc1dc0d":"markdown","4d50d47d":"markdown","e37715d6":"markdown","c3536fa5":"markdown","65bcafa8":"markdown","2a10b788":"markdown","e55add86":"markdown","64202b16":"markdown"},"source":{"3e48bddf":"import pandas as pd\nfrom sklearn.model_selection import cross_val_score","442e1f5f":"data = pd.read_csv(\"\/kaggle\/input\/diamonds\/diamonds.csv\")","aea9aba6":"data.head()","a2136ebf":"data.describe()","49a68dfe":"data['x']==0","8f6d44c9":"data = data[(data[['x','y','z']] != 0).all(axis=1)]","c91d1893":"for i in data.columns:\n    print(i,sum(data[i].isna()))","89bbd03a":"# z \/ mean(x, y)\ndata['volume'] = data['x']*data['y']*data['z']\ndata['area'] = data['x']*data['y']\ndata['priceunvol'] = data['price']\/data['volume']","a4754d62":"data = data.drop(['Unnamed: 0','x','y','z'],axis = 1)\n# data = data.drop(['Unnamed: 0'],axis = 1)","4c3ae511":"data.head()","60ac80f2":"data['table'].unique()","3772f622":"\nnp.where(data['volume'].values )\n","402dd33f":"data =  pd.get_dummies(data)\ndata.head()\n","a3db0c20":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\n# data_fitter =  pd.DataFrame(sc.fit_transform(data[['carat','depth','volume','table']]),columns=['carat','depth','volume','table'],index=data.index)\n\n# data_fitter =  pd.DataFrame(sc.fit_transform(data[['carat','depth','volume','table','area']]),columns=['carat','depth','volume','table','area'],index=data.index)\n\ndata_fitter =  pd.DataFrame(sc.fit_transform(data[['carat','depth','volume','table','area','priceunvol']]),columns=['carat','depth','volume','table','area','priceunvol'],index=data.index)","e9be0cd2":"data2 = data.copy(deep=True)\n# data2[['carat','depth','volume','table']] = data_fitter[['carat','depth','volume','table']]\n# data2[['carat','depth','volume','table','area']] = data_fitter[['carat','depth','volume','table','area']]\ndata2[['carat','depth','volume','table','area','priceunvol']] = data_fitter[['carat','depth','volume','table','area','priceunvol']]","c8019ab4":"data2.head()","115fd25a":"\nfrom sklearn.model_selection import train_test_split\nx = data2.drop([\"price\"],axis=1)\ny = data2.price\ntrain_x, test_x, train_y, test_y = train_test_split(x, y,random_state = 2,test_size=0.3)","d6c14ec2":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn import linear_model\n\nregr = linear_model.LinearRegression()\nregr.fit(train_x,train_y)\ny_pred = regr.predict(test_x)\nprint(\"accuracy: \"+ str(regr.score(test_x,test_y)*100) + \"%\")\nprint(\"Mean absolute error: {}\".format(mean_absolute_error(test_y,y_pred)))\nprint(\"Mean squared error: {}\".format(mean_squared_error(test_y,y_pred)))\nR2 = r2_score(test_y,y_pred)\nprint('R Squared: {}'.format(R2))\nn=test_x.shape[0]\np=test_x.shape[1] - 1\nadj_rsquared = 1 - (1 - R2) * ((n - 1)\/(n-p-1))\nprint('Adjusted R Squared: {}'.format(adj_rsquared))","c129cd45":"from sklearn.ensemble import AdaBoostRegressor \n\nclf_rf = AdaBoostRegressor()\nclf_rf.fit(train_x , train_y)\naccuracies = cross_val_score(estimator = clf_rf, X = train_x, y = train_y, cv = 5,verbose = 1)\ny_pred2 = clf_rf.predict(test_x)\nprint('Score : %.4f' % clf_rf.score(test_x, test_y))\nmse = mean_squared_error(test_y, y_pred2)\nmae = mean_absolute_error(test_y, y_pred2)\nrmse = mean_squared_error(test_y, y_pred2)**0.5\nr2 = r2_score(test_y, y_pred2)\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)","a2bc1f18":"from sklearn.ensemble import RandomForestRegressor\nclf_rf = RandomForestRegressor()\nclf_rf.fit(train_x , train_y)\naccuracies = cross_val_score(estimator = clf_rf, X = train_x, y = train_y, cv = 5,verbose = 1)\ny_pred2 = clf_rf.predict(test_x)\nprint('Score : %.4f' % clf_rf.score(test_x, test_y))\nmse = mean_squared_error(test_y, y_pred2)\nmae = mean_absolute_error(test_y, y_pred2)\nrmse = mean_squared_error(test_y, y_pred2)**0.5\nr2 = r2_score(test_y, y_pred2)\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)","144a29e6":"from tabulate import tabulate\nheaders = [\"name\", \"score\"]\nvalues = sorted(zip(train_x.columns, clf_rf.feature_importances_), key=lambda x: x[1] * -1)\nprint(tabulate(values, headers, tablefmt=\"plain\"))","79e0f8de":"from sklearn.ensemble import GradientBoostingRegressor\n\nclf_gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0, loss='ls',verbose = 1)\nclf_gbr.fit(train_x , train_y)\naccuracies = cross_val_score(estimator = clf_gbr, X = train_x, y = train_y, cv = 5,verbose = 1)\ny_pred2 = clf_gbr.predict(test_x)\nprint('Score : %.4f' % clf_gbr.score(test_x, test_y))\nmse = mean_squared_error(test_y, y_pred2)\nmae = mean_absolute_error(test_y, y_pred2)\nrmse = mean_squared_error(test_y, y_pred2)**0.5\nr2 = r2_score(test_y, y_pred2)\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)","a6c0c671":"# Models","cbc1dc0d":"# Cleaning","4d50d47d":"## Gradient Boost","e37715d6":"## Reg","c3536fa5":"## Random Forest","65bcafa8":"## Standardization","2a10b788":"## One Hot","e55add86":"## Reading","64202b16":"## Adaboost"}}