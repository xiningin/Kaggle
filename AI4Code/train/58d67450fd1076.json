{"cell_type":{"7938fdfc":"code","0782e8ba":"code","ddd573d3":"code","a4c0fd3b":"code","c589e5d8":"code","bd2af10b":"code","8b84f0c9":"code","7abdceed":"code","a1ffe3c1":"code","ee44d4cf":"code","d05034ff":"code","3b7cb050":"code","e8c03d6f":"code","fcc6b4cb":"code","94625083":"code","468a4569":"code","61172611":"code","3d22d829":"code","e051906c":"code","3fb00bfb":"code","258eedc3":"code","abbe45e3":"code","014618f1":"code","c0d86500":"code","a1182c84":"markdown","aaad4f09":"markdown","d809a9b7":"markdown","5bcaf1b3":"markdown","0f58a308":"markdown","fc3dfa57":"markdown","85bd3b3b":"markdown","00aa9952":"markdown","7318e0f8":"markdown","7a7fca81":"markdown","4e5ad186":"markdown","39843431":"markdown","7acb2033":"markdown","841786ad":"markdown","3ffb4cb1":"markdown","63630920":"markdown","a24eed89":"markdown","9a347cdb":"markdown","550ccd6a":"markdown","6c3708fa":"markdown","1721eff4":"markdown"},"source":{"7938fdfc":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","0782e8ba":"data = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/train.csv', parse_dates=True)\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/test.csv')\nsemp_sub = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv')\npseudolabels = pd.read_csv('..\/input\/psd-sub\/submission_psd.csv')\n","ddd573d3":"data.head()","a4c0fd3b":"for col in ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']:\n    test_data[col] = pseudolabels[col]","c589e5d8":"full_data = pd.concat([data, test_data]).reset_index(drop = True)","bd2af10b":"test_data = test_data.drop(['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides'], axis=1)\nall_data = [full_data, test_data]\n\nfor df in all_data:\n    df['date_time'] = df['date_time'].astype('datetime64[ns]').astype(np.int64)\/10**9\n    df['S1xS2'] = df['sensor_1'] * df['sensor_2']\n    df['S2xS5'] = df['sensor_2'] * df['sensor_5']\n    df['S2^2'] = df['sensor_2']**2\ndata = data.sample(frac=1)","8b84f0c9":"x_data = full_data.drop(['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides'], axis=1)\ny_data = full_data[['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']]\nx_data.shape, y_data.shape","7abdceed":"x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42)","a1ffe3c1":"!pip install scikit-learn-intelex --progress-bar off >> \/tmp\/pip_sklearnex.log","ee44d4cf":"from sklearnex import patch_sklearn\npatch_sklearn()","d05034ff":"from sklearn.multioutput import RegressorChain\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_log_error\nimport numpy as np\nimport optuna\nimport matplotlib.pyplot as plt","3b7cb050":"def objective_rf(trial):\n    params ={\n        'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n        'max_depth': trial.suggest_int('max_depth', 3, 70),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n        'criterion': trial.suggest_categorical('criterion', ['mse']),\n        'n_jobs': -1 \n        \n    }\n    model = RegressorChain(RandomForestRegressor(**params), random_state=47).fit(x_train, y_train)\n    y_pred = model.predict(x_val)\n    loss = np.sqrt(mean_squared_log_error(y_val, y_pred))\n    return loss\n\n","e8c03d6f":"study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"minimize\",\n                            pruner=optuna.pruners.HyperbandPruner())","fcc6b4cb":"%%time\nstudy.optimize(objective_rf, n_trials=40)","94625083":"%%time\nnew_model_rf = RegressorChain(RandomForestRegressor(**study.best_params, n_jobs=-1)).fit(x_data, y_data)\n","468a4569":"fet0 = new_model_rf.estimators_[0].feature_importances_\nfet1 = new_model_rf.estimators_[1].feature_importances_\nfet2 = new_model_rf.estimators_[2].feature_importances_\nfets = [fet0, fet1, fet2]","61172611":"for i, _ in enumerate(fets):\n    fets[i] = np.sort(fets[i])\n\nfor fet in fets:\n    plt.figure()\n    plt.barh(full_data.drop(['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides'], axis=1).columns, fet[:12])","3d22d829":"%%time\ny_pred = new_model_rf.predict(test_data)","e051906c":"semp_sub['target_carbon_monoxide'] = y_pred[:, 0]\nsemp_sub['target_benzene'] = y_pred[:, 1]\nsemp_sub['target_nitrogen_oxides'] = y_pred[:, 2]\nsemp_sub.to_csv('submission.csv', index=False)\nsemp_sub.head()","3fb00bfb":"from sklearnex import unpatch_sklearn\nunpatch_sklearn()","258eedc3":"from sklearn.ensemble import RandomForestRegressor","abbe45e3":"study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"minimize\",\n                            pruner=optuna.pruners.HyperbandPruner())","014618f1":"%%time\nstudy.optimize(objective_rf, n_trials=40)","c0d86500":"%%time\nnew_model_rf = RegressorChain(RandomForestRegressor(**study.best_params, n_jobs=-1)).fit(x_data, y_data)","a1182c84":"<big>Let's see the execution time without patch.<\/big>","aaad4f09":"<big><strong>Select parameters<\/strong><\/big>","d809a9b7":"<big>Select parameters for Random Forest Regressor.<\/big>","5bcaf1b3":"<big>For classical machine learning algorithms, we often use the most popular Python library, Scikit-learn. With Scikit-learn you can fit models and search for optimal parameters, but\u202fit\u202fsometimes works for hours.<\/big><br><br>\n\n<big>I want to show you how to use Scikit-learn library and get the results faster without changing the code. To do this, we will make use of another Python library, \u202f<a href='https:\/\/github.com\/intel\/scikit-learn-intelex'>Intel\u00ae Extension for Scikit-learn*<\/a>.<\/big><br><br>\n\n<big>I will show you how to <strong>speed up your kernel more than 2 times<\/strong> without changing your code!<\/big>","0f58a308":"<big>Let's see the execution time.<\/big>","fc3dfa57":"<h2>Preprocessing<\/h2>\n\n<big><strong>Pseudodating<\/strong><\/big><br><br>\n<big>I took the previously predicted labels and added them to the test dataset.<\/big>","85bd3b3b":"<h2>Prediction<\/h2>","00aa9952":"<big>Now let's combine the test and train datasets.<\/big>","7318e0f8":"<big>Let\u2019s run the same Scikit-learn code without the patching offered by Intel\u00ae Extension for Scikit-learn and compare its execution time with the execution time of the patched Scikit-learn.<\/big>","7a7fca81":"<h2>Now we use the same algorithms with original scikit-learn<h2>","4e5ad186":"<h2>Using optuna to select parameters for Random Forest Regressor<\/h2><br><br>\n<big>Random Forest is an ensemble of Decision Trees. The work of this algorithm can be represented as a collective decision made by some expert committee.<\/big><br><br>\n<big>We adjust hyperparameters for the best result.<\/big><br><br>\n<big>The parameters that we select:<\/big><br>\n<big>1. <code>n_estimators<\/code> -  the number of trees to be used in the algorithm.<br><\/big>\n<big>2. <code>max_depth<\/code> -  the depth of each tree.<br><\/big>\n<big>3. <code>min_samples_split<\/code> - the minimum number of samples in a leaf to split.<br> <\/big>","39843431":"<h2>Conclusions<\/h2>\n<big>We can see that using only one classical machine learning algorithm may give you a pretty hight accuracy score. We also use well-known libraries Scikit-learn and Optuna, as well as the increasingly popular library Intel\u00ae Extension for Scikit-learn. Noted that Intel\u00ae Extension for Scikit-learn gives you opportunities to:<\/big>\n\n* <big>Use your Scikit-learn code for training and inference without modification.<\/big>\n* <big>Speed up selection of parameters <strong>from 45 minutes to 20 minutes.<\/strong><\/big>\n* <big>Get predictions of the similar quality.<\/big>\n","7acb2033":"<big>Let's look at the importance of features in training.<\/big>","841786ad":"<big>Patch original scikit-learn.<\/big>","3ffb4cb1":"<big>Next step is split the data into features and targets.<\/big>","63630920":"<h2>Training the model with the selected parameters<\/h2>","a24eed89":"<big>Save the results in 'submission.csv'.<\/big>","9a347cdb":"<h2>Installing Intel(R) Extension for Scikit-learn<\/h2>\n\n<big>Use Intel\u00ae Extension for Scikit-learn* for fast compute Scikit-learn estimators.<\/big>","550ccd6a":"<h2>Importing data<\/h2>","6c3708fa":"<big>Now split the data into training and validation sets.<\/big>","1721eff4":"<big>I added new features to the dataset.<\/big> \n<big>They were obtained by researching combinations of original features using <code>feature_importances_<\/code>.<\/big>"}}