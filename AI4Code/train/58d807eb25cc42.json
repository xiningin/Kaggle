{"cell_type":{"ecf8b0c2":"code","f9f7fa19":"code","9d56fdbc":"code","dac6c7b0":"code","2f437839":"code","8c45c8f8":"code","23bde461":"markdown","3fab0af9":"markdown","89e209a1":"markdown"},"source":{"ecf8b0c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f9f7fa19":"import time \nimport matplotlib.pyplot as plt\nimport seaborn as sns","9d56fdbc":"filename = 'GSE67123_v6_scrna_10x_143_23548_Mouse_Embryo_HSCs_invivo_fromCytotrace.csv'\nt0 = time.time()\ndf = pd.read_csv('\/kaggle\/input\/genes-expressions-datasets-collection\/' + filename, index_col= 0)\nprint(time.time() - t0,'seconds passed')\ndf","dac6c7b0":"y = np.array( [ s.split('||')[0] for s in df.index] )\nprint(y[:15])\npd.Series(y).value_counts()","2f437839":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\n#import umap \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX = df.values\n\nt0=time.time()\nfig = plt.figure(figsize = (20,4) )\nfig.suptitle(filename.split('_')[0] + '\\n'+str(X.shape) )\nc = 0;  n_x_subplots = 2\n\nc += 1; fig.add_subplot(1,n_x_subplots,c)  \nX2 = PCA().fit_transform(X)\nsns.scatterplot(x=X2[:,0], y=X2[:,1] , hue = y) \nplt.title('PCA')\nplt.grid()\n\nc += 1; fig.add_subplot(1,n_x_subplots,c)  \nX2 = PCA().fit_transform(scaler.fit_transform(X) ) \nsns.scatterplot(x=X2[:,0], y=X2[:,1] , hue = y) \nplt.title('StandardScaler+PCA')\nplt.grid()\n\nplt.show()","8c45c8f8":"list_files = os.listdir('\/kaggle\/input\/genes-expressions-datasets-collection\/') \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\n#import umap \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\n\nfor filename in list_files:\n    t0 = time.time()\n    df = pd.read_csv('\/kaggle\/input\/genes-expressions-datasets-collection\/' + filename, index_col= 0)\n    print(filename, 'shape:',  df.shape, np.round(time.time() - t0,2) ,'seconds passed')\n    \n\n    X = df.values\n    y = np.array( [ s.split('||')[0] for s in df.index] )    \n\n    t0=time.time()\n    fig = plt.figure(figsize = (20,4) )\n    fig.suptitle(filename.split('_')[0] + '\\n'+str(X.shape) )\n    c = 0;  n_x_subplots = 2\n\n    c += 1; fig.add_subplot(1,n_x_subplots,c)  \n    X2 = PCA().fit_transform(X)\n    sns.scatterplot(x=X2[:,0], y=X2[:,1] , hue = y) \n    plt.title('PCA')\n    plt.grid()\n\n    c += 1; fig.add_subplot(1,n_x_subplots,c)  \n    X2 = PCA().fit_transform(scaler.fit_transform(X) ) \n    sns.scatterplot(x=X2[:,0], y=X2[:,1] , hue = y) \n    plt.title('StandardScaler+PCA')\n    plt.grid()\n\n    plt.show()    ","23bde461":"# Example - with one file - load, extract cell labeling, plot ..","3fab0af9":"# Loading many files","89e209a1":"# What is about\n\nSeveral genes expression datasets are collected at the Kaggle dataset collection. \nMany of them - single cell-RNA sequencing https:\/\/en.wikipedia.org\/wiki\/Single_cell_sequencing datasets\nThey repsented by matrices cells X genes. \n\nIf labels for cells exists (typically) we mostly store them in dataframe.index - the first part of symbols before \"||\". \n\nThe present notebook shows basic operations with datasets - how to load files, extract labels etc. \n\n"}}