{"cell_type":{"aef02a9f":"code","e4e1e9bf":"code","89c780fa":"code","90bdaeca":"code","4f2a30fa":"code","f29e16b7":"code","a807958b":"code","18ebede0":"code","0517018b":"code","0957785c":"code","642179c1":"code","2c18ba45":"code","813ab458":"code","db07bb87":"code","4681cf2d":"code","873d095d":"code","bb099285":"code","2442c6ff":"code","4dd6eb68":"code","de685b5b":"code","4b479fb5":"code","fc965b54":"code","7a7c2579":"code","e34d76ae":"code","e8eb3f1e":"code","1eb3563a":"code","17a504fc":"code","9e61711d":"markdown","e1117e47":"markdown","2b627da0":"markdown","d973e258":"markdown","d374d519":"markdown","37a9f72b":"markdown","4fcab08c":"markdown","5ed3e899":"markdown","5a4c446a":"markdown","4573ce49":"markdown","d375988c":"markdown","f729d3b8":"markdown"},"source":{"aef02a9f":"%matplotlib inline\nfrom matplotlib import pylab as plt\n\nimport matplotlib.dates as mdates\nplt.rcParams['figure.figsize'] = (15.0, 8.0)\nimport pandas as pd\nimport seaborn as sns\n\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n\nimport bokeh as bk","e4e1e9bf":"energy_data = pd.read_csv(\"..\/input\/house-hold-energy-data\/D202.csv\")","89c780fa":"energy_data[\"DATE_TIME\"] = pd.to_datetime(energy_data.DATE + \" \" + energy_data[\"END TIME\"])\nenergy_data = energy_data[[\"DATE_TIME\",\"USAGE\"]]","90bdaeca":"energy_data.head()","4f2a30fa":"energy_data[\"DAY_TYPE\"] = energy_data.DATE_TIME.apply(lambda x: 1 if x.dayofweek > 5 else 0  )","f29e16b7":"energy_data.head()","a807958b":"cal = calendar()\nholidays = cal.holidays(start = energy_data.DATE_TIME.min(),\n                        end = energy_data.DATE_TIME.max())\nenergy_data[\"IS_HOLIDAY\"] = energy_data.DATE_TIME.isin(holidays)","18ebede0":"energy_data.head()","0517018b":"phm_raw = pd.read_csv(\"..\/input\/phm-2018\/05_M02_DC_train.csv\")\nphm_raw.head(2)","0957785c":"phm_raw.shape","642179c1":"phm_tgt = pd.read_csv(\"..\/input\/phm-2018\/05_M02_train_fault_data.csv\")\nphm_tgt.head(2)","2c18ba45":"phm_tgt.shape","813ab458":"phm_joined = pd.merge(phm_raw,\n                     phm_tgt,\n                     how='left',\n                    on=['time','Tool'])","db07bb87":"phm_joined.head(5)","4681cf2d":"phm_joined['time_stamp'] = pd.to_datetime(phm_joined.time,unit='s')","873d095d":"from IPython.display import Image, display","bb099285":"display(Image(\"..\/input\/pic-nb\/1_EXwJYgnAok6XLu1x1l3V_g.png\"))","2442c6ff":"train_data = pd.read_csv(\"\/kaggle\/input\/collision-detection-ai-using-vibration-data\/train_features.csv\")\ntrain_target = pd.read_csv(\"\/kaggle\/input\/collision-detection-ai-using-vibration-data\/train_target.csv\")","4dd6eb68":"import numpy as np\nimport sklearn as sl\nimport scipy as sp\nfrom tqdm import tqdm","de685b5b":"def plot_data(accelaration_df : pd.DataFrame,features : list, title : str) -> None:\n    \"\"\" Plot the accelaration data\n        :params accelaration_df: accelaration data for one id\n        :params title: string\n    \"\"\"\n    \n    fig = plt.figure(figsize=(10,6))\n    fig.tight_layout(pad=10.0)\n    fig.suptitle(title)\n    \n    for idx,feature in enumerate(features):\n        ax = fig.add_subplot(2,2,idx+1)\n        accelaration_df[feature].plot(kind='line',\n                                     title = title + \" \" + feature,\n                                     ax=ax)","4b479fb5":"feats_to_plot = [\"S1\",\"S2\",\"S3\", \"S4\"]\nplot_data(train_data[train_data.id == 0],feats_to_plot,\"Accelaration Params\")","fc965b54":"train_data[train_data.id == 1]","7a7c2579":"fs = 5 #sampling frequency\nfmax = 25 #sampling period\ndt = 1\/fs #length of signal\nn = 75\n\ndef fft_features(data_set : pd.DataFrame) -> np.ndarray:\n    \"\"\" Convert the dataset to fourier transfomed\n        :params data_set: original collider params data\n        :returns ft_data: Fourier transformed data\n        #Reference - https:\/\/dacon.io\/competitions\/official\/235614\/codeshare\/1174\n    \"\"\"\n    ft_data = list()\n    \n    features = [\"S1\",\"S2\",\"S3\", \"S4\"]\n    \n    id_set = list(data_set.id.unique())\n    \n    for ids in tqdm(id_set):\n        s1_fft = np.fft.fft(data_set[data_set.id==ids]['S1'].values)*dt\n        s2_fft = np.fft.fft(data_set[data_set.id==ids]['S2'].values)*dt\n        s3_fft = np.fft.fft(data_set[data_set.id==ids]['S3'].values)*dt\n        s4_fft = np.fft.fft(data_set[data_set.id==ids]['S4'].values)*dt\n        \n        ft_data.append(np.concatenate([np.abs(s1_fft[0:int(n\/2+1)]),\n                                       np.abs(s2_fft[0:int(n\/2+1)]),\n                                       np.abs(s3_fft[0:int(n\/2+1)]),\n                                       np.abs(s4_fft[0:int(n\/2+1)])]))\n    \n    return np.array(ft_data)","e34d76ae":"train_fft = fft_features(train_data)","e8eb3f1e":"def generate_agg_feats(data_set : pd.DataFrame) -> pd.DataFrame:\n    \"\"\" Create aggrage features from the data\n        :param data_set: Base data as DataFrame\n        :returns agg_data: Aggragated DataFrame\n    \"\"\"\n    \n    max_feats = data_set.groupby(['id']).max().add_suffix('_max').iloc[:,1:]\n    min_feats = data_set.groupby(['id']).min().add_suffix('_min').iloc[:,1:]\n    mean_feats = data_set.groupby(['id']).mean().add_suffix('_mean').iloc[:,1:]\n    std_feats = data_set.groupby(['id']).std().add_suffix('_std').iloc[:,1:]\n    median_feats = data_set.groupby(['id']).median().add_suffix('_median').iloc[:,1:]\n    skew_feats = data_set.groupby(['id']).skew().add_suffix('_skew').iloc[:,1:]\n    \n    agg_data = pd.concat([max_feats,min_feats,\n                          mean_feats,std_feats,median_feats,skew_feats],\n                        axis=1)\n    \n    return agg_data","1eb3563a":"agg_train = generate_agg_feats(train_data)\nagg_train.shape","17a504fc":"Reference","9e61711d":"## Excercise \n\nCreate Time to failure bases on the filure time.\n\nTip!\n\nFor each observation in the uptime duration sustract the failure time !\n\n\n# Let's Nuke the Plan!!!\n\nData Source - https:\/\/www.kaggle.com\/imeintanis\/collision-detection-ai-using-vibration-data ","e1117e47":"## How to approach Feature Engineering\n\n### Fourier Transform\n\nOne of the prominent methods to approach signal data is to apply forurier transformation in the data. The Fourier transformed data can be used for training a model.","2b627da0":"## Feature Engineering for Time Series Data\n\n### Time Series\n\nA time series is a sequential set of data points, measured typically over successive times. It is mathematically defined as a set of vectors *f(t),t = 0,1,2,*... where *t* represents the time elapsed . The variable *f(t)* is treated as a random variable. The measurements taken during an event in a time series are arranged in a proper chronological order. \n\n   * A time series containing records of a single variable is is termed as **univarite**.\n   * A time series containing records of more than one variable is reffered as **multivarite**\n\n\nA time series can be discrete or continuous. \n\n### Creating Feature from Time","d973e258":"## Challenge\n\nBuild regression model for the collider parameter detection!!","d374d519":"### Excercise \n\nCreate a feature to represent part of the day such as Morning (M), Noon (N), Evening (E) and Night (N).\n","37a9f72b":"## What is the Challenge Here!\n\nOne record != one sample ","4fcab08c":"## Reference\n\nPHM 2018 Data - https:\/\/www.phmsociety.org\/events\/conference\/phm\/18\/data-challenge\n\nHydrogen Collider Data - https:\/\/www.kaggle.com\/jaganadhg\/atomicai-starter \n\nElectricity Usage Data - https:\/\/www.kaggle.com\/jaganadhg\/house-hold-energy-data ","5ed3e899":"### Impact of Holidays","5a4c446a":"### Alternative Fature Engineering\n\nAn alternative approach in feature engineering is to aggregate the features and compute key statistics such as mean, median, standard deviation, minimum value, and skew.","4573ce49":"![](http:\/\/)","d375988c":"### Target from Time\n\nSometimes we may have to create taget variables from time itself. Such an excercise is required in usecases such as **Survival Models\/Predictive Maintainance** .","f729d3b8":"### Determine Type of Day"}}