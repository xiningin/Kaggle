{"cell_type":{"89dabffa":"code","5f56a5fb":"code","86d855eb":"code","49c50f65":"code","a66f519f":"code","9081673b":"code","1c3f975f":"code","39bbaddb":"code","fc1ea7f7":"code","8f815d1f":"code","254b523e":"code","13ae5e98":"code","29b62fee":"code","a30b0823":"code","b7a2d4ca":"code","033b7dcf":"code","c81d57cf":"code","369a133b":"code","eef41a41":"code","2ae7c781":"code","4bd65acb":"code","4ebeda45":"code","4d4f989c":"code","d4b8c8c2":"code","979ee247":"code","b54a59a2":"code","3e538992":"code","e5099904":"code","88918551":"code","14152a7e":"code","73d150c7":"code","96fd789c":"markdown","da1ea42f":"markdown","b09c3912":"markdown","83d8f45e":"markdown","5ea0a96c":"markdown","27380dcd":"markdown","ebab33e8":"markdown","69c282e3":"markdown","029f4ded":"markdown","ab907887":"markdown","56a0a994":"markdown","c3290a0c":"markdown","6fcc6c6b":"markdown","19c86cc6":"markdown"},"source":{"89dabffa":"import numpy as np \nimport pandas as pd \nfrom sklearn.preprocessing import LabelEncoder  #for encoding the data to int values\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV","5f56a5fb":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data  = pd.read_csv('..\/input\/titanic\/test.csv')","86d855eb":"# checking train data first 5 rows\ntrain_data.head() ","49c50f65":"train_data = train_data.drop(['Ticket', 'Cabin','PassengerId','Name'], axis=1)\ntest_data = test_data.drop(['Ticket', 'Cabin','PassengerId','Name'], axis=1)","a66f519f":"print(\"Training data :\",\"\\n\\n\",train_data.isnull().sum(),\"\\n\")\nprint('_'*10,\"Testing data\",'-'*10)\ntest_data.isnull().sum()","9081673b":"train_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\ntest_data['Age'] = test_data['Age'].fillna(test_data['Age'].median())","1c3f975f":"train_data.Fare.fillna(train_data.Fare.mean(), inplace=True)\ntest_data.Fare.fillna(test_data.Fare.mean(), inplace=True)","39bbaddb":"train_data.Embarked.fillna('S', inplace=True)\nembarked_dummies = pd.get_dummies(train_data['Embarked'], prefix='Embarked')\ntrain_data = pd.concat([train_data, embarked_dummies], axis=1)\ntrain_data.drop('Embarked', axis=1, inplace=True)\n\ntest_data.Embarked.fillna('S', inplace=True)\nembarked_dummies1 = pd.get_dummies(test_data['Embarked'], prefix='Embarked')\ntest_data = pd.concat([test_data, embarked_dummies1], axis=1)\ntest_data.drop('Embarked', axis=1, inplace=True)","fc1ea7f7":"print(\"Training data :\",\"\\n\\n\",train_data.isnull().sum(),\"\\n\")\nprint('_'*10,\"Testing data\",'-'*10)\ntest_data.isnull().sum()","8f815d1f":"encounder=LabelEncoder()\ntrain_data['Sex']=encounder.fit_transform(train_data['Sex'].values)\ntest_data['Sex']=encounder.fit_transform(test_data['Sex'].values)\n\ntrain_data.head()\n# test_data.head()","254b523e":"train_data.describe()","13ae5e98":"train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","29b62fee":"train_data.head()","a30b0823":"test_data.head()","b7a2d4ca":"train= train_data\ntrain = train.drop(['Survived'], axis=1)\n","033b7dcf":"clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\nclf = clf.fit(train, train_data['Survived'])","c81d57cf":"model = SelectFromModel(clf, prefit=True)\ntrain_reduced = model.transform(train)\nprint (train_reduced.shape)","369a133b":"\ntest_reduced = model.transform(test_data)\nprint (test_reduced.shape)","eef41a41":"logreg = LogisticRegression()\nlogreg_cv = LogisticRegressionCV()\nrf = RandomForestClassifier()\ngboost = GradientBoostingClassifier()\n\nmodels = [logreg, logreg_cv, rf, gboost]","2ae7c781":"for model in models:\n    print ('Cross-validation of : {0}'.format(model.__class__))\n    score = compute_score(clf=model, X=train_reduced, y=targets, scoring='accuracy')\n    print ('CV score = {0}'.format(score))\n    print ('****')","4bd65acb":"y=train_data['Survived']\nX = train","4ebeda45":"from sklearn import preprocessing\nscaler = preprocessing.StandardScaler()\nprint(scaler.fit(X,y))","4d4f989c":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.3,\n                                                    random_state=10)","d4b8c8c2":"# Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\n\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(max_depth=1,\n                                    max_features=1,\n                                    n_estimators = 9,\n                                    random_state = 13,\n    criterion='gini',\n    min_samples_split=2,\n    min_samples_leaf=1,\n    min_weight_fraction_leaf=0.0,\n#     max_features='auto',\n    max_leaf_nodes=None,\n    min_impurity_decrease=0.0,\n    min_impurity_split=None,\n    bootstrap=True,\n    oob_score=False,\n    n_jobs=None,\n    verbose=0,\n    warm_start=False,\n    class_weight=None)\n#-------------------------------------------------------------------------------------------------------\nclassifier.fit(X_train, Y_train)\n# ---------------------------------------------------------------------------------------------------------------------\nY_pred = classifier.predict(X_test)\n# ----------------------------------------------------------------------------------------------------------------------\nfrom sklearn.metrics import accuracy_score, classification_report\nprint(\"                  Accuracy score=\",accuracy_score(Y_test, Y_pred)*100,\"%\") #most accurate\n# ------------------------------------------------------------------------------------------------------------------------\nfrom sklearn.metrics import confusion_matrix #confusuon matrix for randomforest\npd.crosstab(Y_test, Y_pred)","979ee247":"from sklearn.linear_model import LogisticRegression\nclassifier1 = LogisticRegression(random_state = 0)\nclassifier1.fit(X_train, Y_train)\n#Using KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier2 = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier2.fit(X_train, Y_train)\n#Using SVC method of svm class to use Support Vector Machine Algorithm\nfrom sklearn.svm import SVC\nclassifier3 = SVC(kernel = 'linear', random_state = 0)\nclassifier3.fit(X_train, Y_train)\n# Using SVC method of svm class to use Kernel SVM Algorithm\nfrom sklearn.svm import SVC\nclassifier4 = SVC(kernel = 'rbf', random_state = 1)\nclassifier4.fit(X_train, Y_train)\n#Using GaussianNB method of na\u00efve_bayes class to use Na\u00efve Bayes Algorithm\nfrom sklearn.naive_bayes import GaussianNB\nclassifier5 = GaussianNB()\nclassifier5.fit(X_train, Y_train)\n#Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm\n\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier6 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier6.fit(X_train, Y_train)","b54a59a2":"Y_pred1 = classifier1.predict(X_test)\nY_pred2 = classifier2.predict(X_test)\nY_pred3 = classifier3.predict(X_test)\nY_pred4 = classifier4.predict(X_test)\nY_pred5= classifier5.predict(X_test)\nY_pred6 = classifier6.predict(X_test)","3e538992":"print(accuracy_score(Y_test, Y_pred1))\nprint(accuracy_score(Y_test, Y_pred2))\nprint(accuracy_score(Y_test, Y_pred3))\nprint(accuracy_score(Y_test, Y_pred4))\nprint(accuracy_score(Y_test, Y_pred5))\nprint(accuracy_score(Y_test, Y_pred6))","e5099904":"pred = classifier1.predict(test_data)","88918551":"u=pd.DataFrame(pred)","14152a7e":"u.c","73d150c7":"u.to_csv('mycsvfile.csv',index=False)","96fd789c":"## filling null values","da1ea42f":"# dropping unwanted features","b09c3912":"# Import Modules","83d8f45e":"# Encode the data to feed into our algorithms\n*machine only treat int and float values*\n* Male-1 Female-0","5ea0a96c":"### age","27380dcd":"### embarked","ebab33e8":"# checking null values\n**cabin,age and embarked are conataining some null values**","69c282e3":"test","029f4ded":"* ### maximum people survived are from 1 Pclass ~62%","ab907887":"# data null values are filled","56a0a994":"# Data Insights","c3290a0c":"### fare","6fcc6c6b":"# Reading data","19c86cc6":"* ### 38% survival rate\n* ### gender ratio is also good 64%"}}