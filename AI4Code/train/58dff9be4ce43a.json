{"cell_type":{"75a1d11a":"code","ef1c4f92":"code","096f771e":"code","c30f593d":"code","32cffc89":"code","1441615f":"code","f9154261":"code","0d54b5a6":"code","226a74b7":"code","6db43ab2":"code","c26ba228":"code","a6f86a69":"code","e2203ecc":"code","2d5af389":"code","02716747":"code","3090d1b2":"code","1be16025":"code","e385d484":"code","77e03c34":"code","c09b1150":"code","fa9f6f21":"code","79b99592":"code","d86e9eae":"code","4df00aae":"code","ade50b5e":"code","67e32085":"code","8a020db4":"code","f49840e9":"code","71581b17":"code","f5c59e13":"code","e979685b":"code","97730381":"code","b7d614c9":"code","5c026a3d":"code","1230e4c7":"code","08f28751":"code","b4a82a38":"code","0f5eba49":"code","53358824":"code","d41e6086":"code","5108b092":"code","536af0ad":"code","36aefa07":"code","4ffb0b41":"code","613604a1":"code","72c431ba":"code","972b4aa0":"code","dfa764b3":"code","85d6e7ae":"code","53be65e3":"code","2ce1c40c":"code","865687a1":"code","d820542e":"code","32847c07":"code","fd88fd7a":"code","2b346d0d":"code","9334d133":"code","4593279f":"code","e21f200d":"code","ee7e4a08":"code","48018eb0":"code","3a48b25d":"code","13a529e7":"code","84884119":"code","50291028":"code","d51601e7":"code","c86e1095":"code","5560fa14":"code","c9fa56a9":"code","3139c4b0":"code","42191d1b":"code","146483ba":"code","07bc16ef":"code","d01e59e7":"code","bafa5ee1":"markdown","dbb2f9d5":"markdown","0c3dc65c":"markdown","bdbe5dc2":"markdown","72670b4d":"markdown","61fb5594":"markdown","092f21f8":"markdown","f699c002":"markdown","43167d81":"markdown","a6725a98":"markdown","7971be97":"markdown"},"source":{"75a1d11a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom imblearn.over_sampling import SMOTE as sm\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_predict, cross_val_score\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix \nfrom sklearn.metrics import f1_score,precision_recall_curve, roc_curve,  roc_auc_score, accuracy_score\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ef1c4f92":"df = pd.read_csv(\"..\/input\/credit-card-customers\/BankChurners.csv\")\ndf.head(2)","096f771e":"print(df['Education_Level'].unique())\nprint(df['Marital_Status'].unique())\nprint(df['Card_Category'].unique())\nprint(df['Income_Category'].unique())","c30f593d":"df.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'],axis=1, inplace=True)\ndf.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1'],axis=1, inplace=True)\ndf.drop(['CLIENTNUM'],axis=1, inplace=True)","32cffc89":"df.describe(include='all').T","1441615f":"# Checking for null values\n\nsns.heatmap(df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\nplt.show()","f9154261":"sns.countplot(x='Attrition_Flag',data = df, label = 'Counts')\nplt.show()","0d54b5a6":"sns.countplot(x='Gender',data = df, hue='Attrition_Flag')\nplt.show()","226a74b7":"sns.countplot(x='Marital_Status',data = df, hue='Attrition_Flag')\nplt.show()","6db43ab2":"plt.figure(figsize=[15,8])\nsns.countplot(x='Customer_Age',data = df, hue='Attrition_Flag')\nplt.show()","c26ba228":"df['Dependent_count'].hist(bins=5)","a6f86a69":"sns.countplot(x='Card_Category',data = df, hue='Attrition_Flag')\nplt.show()","e2203ecc":"plt.figure(figsize=[8,8])\nsns.countplot(x='Income_Category',data = df, hue='Attrition_Flag')\nplt.show()","2d5af389":"plt.figure(figsize=[8,8])\nsns.countplot(x='Education_Level',data = df, hue='Attrition_Flag')\nplt.show()","02716747":"def update_education_unknown(df):\n    edu_level = df[0]\n    if edu_level == 'Unknown':\n        return 'Edu_Unknown'\n    else: \n        return edu_level\n\ndef update_marital_unknown(df):\n    marital = df[0]\n    if marital == 'Unknown':\n        return 'Marital_Unknown'\n    else: \n        return marital","3090d1b2":"df['Education_Level'] = df[['Education_Level']].apply(update_education_unknown,axis=1)\ndf['Marital_Status'] = df[['Marital_Status']].apply(update_marital_unknown,axis=1)","1be16025":"attir_flag = pd.get_dummies(df['Attrition_Flag'],drop_first=True)\ndf.drop(['Attrition_Flag'], axis=1, inplace=True)\ndf = pd.concat([df, attir_flag], axis=1)","e385d484":"corr_matrix = df.corr()\ncorr_matrix['Existing Customer'].sort_values(ascending = False)","77e03c34":"g = sns.heatmap(df.corr(),annot=True,fmt = \".2f\", cmap = \"coolwarm\")\nfig=plt.gcf()\nfig.set_size_inches(10,10)\nplt.show()","c09b1150":"df2 = df.copy()","fa9f6f21":"df2.drop(['Avg_Open_To_Buy'], axis=1, inplace=True) # dropping because of multicollinearity ","79b99592":"g = sns.heatmap(df2.corr(),annot=True,fmt = \".2f\", cmap = \"coolwarm\")\nfig=plt.gcf()\nfig.set_size_inches(10,10)\nplt.show()","d86e9eae":"# ENCODING THE CATEGORICAL VARIABLES\ngender_flag = pd.get_dummies(df2['Gender'],drop_first=True)\ndf2.drop(['Gender'], axis=1, inplace=True)\ndf2 = pd.concat([df2, gender_flag], axis=1)\n\nmarital_flag = pd.get_dummies(df2['Marital_Status'],drop_first=True)\ndf2.drop(['Marital_Status'], axis=1, inplace=True)\ndf2 = pd.concat([df2, marital_flag], axis=1)\n\nedu_flag = pd.get_dummies(df2['Education_Level'],drop_first=True)\ndf2.drop(['Education_Level'], axis=1, inplace=True)\ndf2 = pd.concat([df2, edu_flag], axis=1)\n\ncard_flag = pd.get_dummies(df2['Card_Category'],drop_first=True)\ndf2.drop(['Card_Category'], axis=1, inplace=True)\ndf2 = pd.concat([df2, card_flag], axis=1)\n\nincome_flag = pd.get_dummies(df2['Income_Category'],drop_first=True)\ndf2.drop(['Income_Category'], axis=1, inplace=True)\ndf2 = pd.concat([df2, income_flag], axis=1)","4df00aae":"df2.head()","ade50b5e":"df2.columns","67e32085":"from sklearn.model_selection import train_test_split\nX = df2.loc[:, df2.columns != 'Existing Customer'] \ny = df2.loc[:,df2.columns == 'Existing Customer']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state = 10, stratify=y)","8a020db4":"print(\"Number transactions X_train dataset: \", X_train.shape) \nprint(\"Number transactions y_train dataset: \", y_train.shape) \nprint(\"Number transactions X_test dataset: \", X_test.shape) \nprint(\"Number transactions y_test dataset: \", y_test.shape)","f49840e9":"sns.countplot(x = 'Existing Customer',data = y_train)\nplt.show()","71581b17":"smo = sm(random_state = 2) \nX_train_res, y_train_res = smo.fit_sample(X_train, y_train.values.ravel()) ","f5c59e13":"l = list(y_train_res)\nsns.countplot(x = l)\nplt.show()","e979685b":"sc = StandardScaler()\nX_train_res= sc.fit_transform(X_train_res)","97730381":"X_test = sc.transform(X_test)","b7d614c9":"def display_scores(scores):\n    print('Scores',scores)\n    print('Mean',scores.mean())\n    print('Standard Deviation',scores.std())","5c026a3d":"def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n    plt.xlabel(\"Threshold\")\n    plt.legend(loc=\"upper left\")\n    plt.ylim([0, 1])\n\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')","1230e4c7":"# k = KNeighborsClassifier()\n# k_param_grid = {\"n_neighbors\":[5,10,15,20],\n#                \"metric\" : ['minkowski','euclidean','manhattan',\"chebyshev\"]\n#                }\n# k_NN = GridSearchCV(k,param_grid = k_param_grid, cv=5, scoring=\"accuracy\", n_jobs= -1, verbose = 2)\n# k_NN.fit(X_train_res,y_train_res)\n# k_NN.best_estimator_","08f28751":"# k_NN.best_score_","b4a82a38":"k = KNeighborsClassifier(metric='manhattan')\nk_score = cross_val_score(k, X_train_res, y_train_res, cv=5, scoring=\"accuracy\")\ndisplay_scores(k_score)","0f5eba49":"y_train_pred = cross_val_predict(k, X_train_res, y_train_res, cv=5)","53358824":"print(precision_score(y_train_res, y_train_pred))\nprint(recall_score(y_train_res, y_train_pred))\nprint(f1_score(y_train_res, y_train_pred))\nprint(roc_auc_score(y_train_res, y_train_pred))","d41e6086":"knn = k.fit(X_train_res,y_train_res)\nknn_pred = knn.predict(X_test)  #PREDICTION\nprint(accuracy_score(y_test, knn_pred))","5108b092":"cfm_vpc = confusion_matrix(y_test,knn_pred)\nsns.heatmap(cfm_vpc, annot=True,fmt = \".2f\", cmap = \"coolwarm\")\nfig=plt.gcf()\nfig.set_size_inches(5,5)\nplt.show()","536af0ad":"print(precision_score(y_test,knn_pred))\nprint(recall_score(y_test,knn_pred))\nprint(f1_score(y_test,knn_pred))\nprint(roc_auc_score(y_test,knn_pred))\nfpr, tpr, thresholds = roc_curve(y_test,knn_pred)\nplot_roc_curve(fpr, tpr)\nplt.show()","36aefa07":"# svc_c = SVC(random_state = 2)\n# svc_param_grid = {'kernel': ['sigmoid','rbf'], \n#                   'gamma': [ 0.001, 0.01, 0.1, 1],\n#                   'C': [1, 10, 20],\n#                  'probability': [True],\n#                   'tol': [0.001, 0.01, 0.1, 1],\n#                  'decision_function_shape':['ovr'],\n#                  }\n# gsSVMC = GridSearchCV(svc_c,param_grid = svc_param_grid, cv=5, scoring=\"accuracy\", \n#                       n_jobs= -1, verbose = 1)\n# gsSVMC.fit(X_train_res,y_train_res)\n# gsSVMC.best_estimator_","4ffb0b41":"# gsSVMC.best_score_","613604a1":"svc_c = SVC(C=20, gamma=0.01, probability=True, random_state=2, tol=0.1)\nc_score = cross_val_score(svc_c, X_train_res, y_train_res, cv=5, scoring=\"accuracy\")\ndisplay_scores(c_score)","72c431ba":"y_train_pred = cross_val_predict(svc_c, X_train_res, y_train_res, cv=5)","972b4aa0":"print(precision_score(y_train_res, y_train_pred))\nprint(recall_score(y_train_res, y_train_pred))\nprint(f1_score(y_train_res, y_train_pred))\nprint(roc_auc_score(y_train_res, y_train_pred))","dfa764b3":"svc = svc_c.fit(X_train_res,y_train_res)\nsvc_pred = svc.predict(X_test)\nprint(accuracy_score(y_test, svc_pred))","85d6e7ae":"cfm_vpc = confusion_matrix(y_test,svc_pred)\nsns.heatmap(cfm_vpc, annot=True,fmt = \".2f\", cmap = \"coolwarm\")\nfig=plt.gcf()\nfig.set_size_inches(5,5)\nplt.show()","53be65e3":"print(precision_score(y_test, svc_pred))\nprint(recall_score(y_test, svc_pred))\nprint(f1_score(y_test, svc_pred))\nprint(roc_auc_score(y_test, svc_pred))\nfpr, tpr, thresholds = roc_curve(y_test, svc_pred)\nplot_roc_curve(fpr, tpr)\nplt.show()","2ce1c40c":"# DTC = DecisionTreeClassifier()\n# DTC_param_grid = {'criterion' : ['entropy'],\n#                   'max_depth':[2,3,4,5],\n#                   \"min_samples_split\": [1,2,3,4,5,6,7,8,9,10],\n#                   \"min_samples_leaf\": [1,2,3,4,5,6,7,8,9,10]\n#                  }\n# gsDTC = GridSearchCV(DTC,param_grid = DTC_param_grid, cv=5, scoring=\"accuracy\", n_jobs= -1, verbose = 2)\n# gsDTC.fit(X_train_res,y_train_res)\n# gsDTC.best_estimator_","865687a1":"# gsDTC.best_score_","d820542e":"DTC = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=9,\n                       min_samples_split=8)\nc_score = cross_val_score(DTC, X_train_res, y_train_res, cv=5, scoring=\"accuracy\")\ndisplay_scores(c_score)","32847c07":"y_train_pred = cross_val_predict(DTC, X_train_res, y_train_res, cv=5)","fd88fd7a":"print(precision_score(y_train_res, y_train_pred))\nprint(recall_score(y_train_res, y_train_pred))\nprint(f1_score(y_train_res, y_train_pred))\nprint(roc_auc_score(y_train_res, y_train_pred))","2b346d0d":"dt = DTC.fit(X_train_res,y_train_res)\ndtc_pred = dt.predict(X_test)  #PREDICTION\nprint(accuracy_score(y_test, dtc_pred))\n","9334d133":"cfm_vpc = confusion_matrix(y_test, dtc_pred)\nsns.heatmap(cfm_vpc, annot=True,fmt = \".2f\", cmap = \"coolwarm\")\nfig=plt.gcf()\nfig.set_size_inches(5,5)\nplt.show()","4593279f":"print(precision_score(y_test, dtc_pred))\nprint(recall_score(y_test, dtc_pred))\nprint(f1_score(y_test, dtc_pred))\nprint(roc_auc_score(y_test, dtc_pred))\nfpr, tpr, thresholds = roc_curve(y_test, dtc_pred)\nplot_roc_curve(fpr, tpr)\nplt.show()","e21f200d":"# RFC = RandomForestClassifier()\n\n\n# rf_param_grid = {\"max_depth\": [2,3,4,5],\n#               \"max_features\": [1,2,3,4,5],\n#               \"min_samples_split\": [2,3,4,5],\n#               \"min_samples_leaf\": [1,2,3,4,5],\n#               \"bootstrap\": [False],\n#               \"n_estimators\" :[50,100,150,200],\n#               \"criterion\": [\"entropy\"]}\n\n# gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=5, scoring=\"accuracy\", n_jobs= -1, verbose = 2)\n# gsRFC.fit(X_train_res,y_train_res)\n# gsRFC.best_estimator_","ee7e4a08":"# gsRFC.best_score_","48018eb0":"RFC = RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=5,\n                       max_features=5, n_estimators=200)\nc_score = cross_val_score(RFC, X_train_res, y_train_res, cv=5, scoring=\"accuracy\")\ndisplay_scores(c_score)","3a48b25d":"y_train_pred = cross_val_predict(RFC, X_train_res, y_train_res, cv=5)","13a529e7":"print(precision_score(y_train_res, y_train_pred))\nprint(recall_score(y_train_res, y_train_pred))\nprint(f1_score(y_train_res, y_train_pred))\nprint(roc_auc_score(y_train_res, y_train_pred))","84884119":"rf = RFC.fit(X_train_res,y_train_res)\nrfc_pred = rf.predict(X_test)  #PREDICTION\nprint(accuracy_score(y_test, rfc_pred))","50291028":"cfm_vpc = confusion_matrix(y_test, rfc_pred)\nsns.heatmap(cfm_vpc, annot=True,fmt = \".2f\", cmap = \"coolwarm\")\nfig=plt.gcf()\nfig.set_size_inches(5,5)\nplt.show()\n","d51601e7":"print(precision_score(y_test, rfc_pred))\nprint(recall_score(y_test, rfc_pred))\nprint(f1_score(y_test, rfc_pred))\nprint(roc_auc_score(y_test, rfc_pred))\nfpr, tpr, thresholds = roc_curve(y_test, rfc_pred)\nplot_roc_curve(fpr, tpr)\nplt.show()","c86e1095":"# lr_ = LogisticRegression() \n# lr_param_grid = {'penalty':['l1','l2'],\n#                 'tol':[1e-4,1e-3,1e-2,1e-5],\n#                  'C':[0.1, 1, 100],\n#                  'multi_class':['ovr'],\n#                  'max_iter':[1000],\n#                  'solver':['newton_cg','sag','saga','lbfgs']\n#                 }\n# gslr = GridSearchCV(lr_,param_grid = lr_param_grid, cv=5, scoring=\"accuracy\", n_jobs= -1, verbose = 2)\n# gslr.fit(X_train_res,y_train_res)","5560fa14":"# gslr_best = gslr.best_estimator_\n# gslr_best","c9fa56a9":"lr = LogisticRegression(C=0.1, max_iter=1000, multi_class='ovr', solver='saga',\n                   tol=0.001) \nc_score = cross_val_score(lr, X_train_res, y_train_res, cv=5, scoring=\"accuracy\")\ndisplay_scores(c_score)","3139c4b0":"y_train_pred = cross_val_predict(lr, X_train_res, y_train_res, cv=5)","42191d1b":"print(precision_score(y_train_res, y_train_pred))\nprint(recall_score(y_train_res, y_train_pred))\nprint(f1_score(y_train_res, y_train_pred))\nprint(roc_auc_score(y_train_res, y_train_pred))\n","146483ba":"lrc = lr.fit(X_train_res,y_train_res)\nlr_pred = lrc.predict(X_test)  #PREDICTION\nprint(accuracy_score(y_test, lr_pred))","07bc16ef":"cfm_vpc = confusion_matrix(y_test,lr_pred)\nsns.heatmap(cfm_vpc, annot=True,fmt = \".2f\", cmap = \"coolwarm\")\nfig=plt.gcf()\nfig.set_size_inches(5,5)\nplt.show()","d01e59e7":"print(precision_score(y_test,lr_pred))\nprint(recall_score(y_test,lr_pred))\nprint(f1_score(y_test,lr_pred))\nprint(roc_auc_score(y_test,lr_pred))\nfpr, tpr, thresholds = roc_curve(y_test,lr_pred)\nplot_roc_curve(fpr, tpr)\nplt.show()","bafa5ee1":"### Decision Tree Classifier","dbb2f9d5":"### K Neighbours Classifier","0c3dc65c":"### Logistic Regression","bdbe5dc2":"# SCALING DATASET","72670b4d":"# HANDLING IMBALANCED CLASS","61fb5594":"# EDA","092f21f8":"# TRAIN TEST SPLIT","f699c002":"# MODELING","43167d81":"### SVC","a6725a98":"### Random Forest Classifier","7971be97":"## *Decision Tree Classifier and Random Forest are the two classifiers which gave us satisfactory results. Rest classifiers overfitted by a big margin.*"}}