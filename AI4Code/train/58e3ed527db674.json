{"cell_type":{"1c5739fc":"code","e5f528f5":"code","0b389c63":"code","12810402":"code","eb80e965":"code","43fee799":"code","acc0d10c":"code","c61ad91d":"code","3a359535":"code","520bf36c":"code","9a5f512c":"code","518a77f0":"code","f9d6241c":"code","55c0d7f1":"code","f36c98cb":"code","fcee9409":"code","4b080283":"code","27f8e20a":"code","cee88853":"code","ed758400":"code","1cfa3dce":"code","c1a5c58f":"code","22626a7a":"code","d847eff8":"code","a11c8dca":"code","8ab8522d":"code","4906bd31":"code","307fab1b":"code","2afbe3ac":"code","2d3a4f14":"code","eb448c42":"markdown","21725e02":"markdown","17d6c7b3":"markdown","81eb04b2":"markdown","657dc3f5":"markdown","87d5ea2a":"markdown","fa8af118":"markdown","852b95c7":"markdown","e5736911":"markdown","90193d3e":"markdown","60448be2":"markdown","df14fd76":"markdown","7876b93f":"markdown","0db73f2f":"markdown","e03a0416":"markdown","a650b87b":"markdown"},"source":{"1c5739fc":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # basic plotting\nimport seaborn as sns # additional plotting functionality\nimport os\nfrom tqdm import tqdm\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nprint(os.listdir(\"..\/input\"))","e5f528f5":"# load data\ndf = pd.read_csv('..\/input\/data\/Data_Entry_2017.csv')\n\n# see how many observations there are\nnum_obs = len(df)\nprint('Number of observations:',num_obs)\n\ndf.head(5) ","0b389c63":"my_glob = glob('..\/input\/data\/images*\/images\/*.png')\nprint('Number of Observations: ', len(my_glob)) # check to make sure I've captured every pathway, should equal 112,120","12810402":"full_img_paths = {os.path.basename(x): x for x in my_glob}\ndf['full_path'] = df['Image Index'].map(full_img_paths.get)","eb80e965":"num_unique_labels = df['Finding Labels'].nunique()\nprint('Number of unique labels:',num_unique_labels)\n\ncount_per_unique_label = df['Finding Labels'].value_counts() # get frequency counts per label\ndf_count_per_unique_label = count_per_unique_label.to_frame() # convert series to dataframe for plotting purposes\n\nprint(df_count_per_unique_label) # view tabular results\nplt.figure(figsize = (12,8))\nsns.barplot(x = df_count_per_unique_label.index[:20], y=\"Finding Labels\", data=df_count_per_unique_label[:20], color = \"blue\"), plt.xticks(rotation = 90) # visualize results graphically","43fee799":"# Selecting only 14 classes excluding 'No finding'\nclasses = ['Atelectasis',\n                'Consolidation',\n                'Infiltration', \n                'Pneumothorax', \n                'Edema', \n                'Emphysema',\n                'Fibrosis', \n                'Effusion', \n                'Pneumonia',\n                'Pleural_Thickening',\n                'Cardiomegaly',\n                'Nodule', \n                'Mass', \n                'Hernia'] # taken from paper\n\n# One Hot Encoding of Finding Labels to classes\nfor label in classes:\n    df[label] = df['Finding Labels'].map(lambda result: 1.0 if label in result else 0)\ndf.head(5) # check the data, looking good!","acc0d10c":"# now, let's see how many cases present for each of of our 14 clean classes (which excl. 'No Finding')\nclean_labels = df[classes].sum().sort_values(ascending= False) # get sorted value_count for clean labels\n\n# plot cases using seaborn barchart\nclean_labels_df = clean_labels.to_frame() # convert to dataframe for plotting purposes\nplt.figure(figsize = (12, 8))\nsns.barplot(x = clean_labels_df.index[::], y= 0, data = clean_labels_df[::], color = \"blue\"), plt.xticks(rotation = 90) # visualize results graphically","c61ad91d":"data = df[classes]","3a359535":"df['labels'] = data.apply(lambda row: np.argmax(row) if np.sum(row)>0 else -1, axis = 1)","520bf36c":"df.head()","9a5f512c":"from tqdm import tqdm\ndef cut_labels(df, target = 'labels', max_sample_per_class = 100):\n    \n    data = pd.DataFrame({})\n    \n    for label in tqdm(df[target].unique()):\n        \n        temp = df[df[target]==label].iloc[:max_sample_per_class, :]\n        data = pd.concat((data, temp),axis = 0)\n            \n    return data","518a77f0":"short_df = cut_labels(df[df.labels>=0], max_sample_per_class = 1000)\nshort_df.labels.value_counts()","f9d6241c":"n_row = 14\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*4, n_row*4), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    data = df[df.labels ==row]\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(plt.imread(data.full_path.iloc[n_col*row + col]), cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])\n        title = data['Finding Labels'].iloc[n_col*row + col]\n        ax[row][col].set_title(f'{title}', fontsize = 10)","55c0d7f1":"# split the data into a training and testing set\nfrom sklearn.model_selection import train_test_split\ntrain_df, test_df = train_test_split(short_df, test_size = 0.2, stratify = short_df.labels, random_state = 1993)\n\n# quick check to see that the training and test set were split properly\nprint('training set - # of observations: ', len(train_df))\nprint('test set - # of observations): ', len(test_df))\nprint('prior, full data set - # of observations): ', len(short_df))","f36c98cb":"import tensorflow as tf","fcee9409":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_gen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.1,\n        zoom_range=0.1,\n        rotation_range=20,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip=True)\n\ntest_gen = ImageDataGenerator(\n        rescale=1.\/255)","4b080283":"train_df['labels'] = train_df['labels'].astype(str)\ntest_df['labels'] = test_df['labels'].astype(str)","27f8e20a":"image_size = (128, 128)\ntrain_generator  = train_gen.flow_from_dataframe(train_df,\n                                                x_col = 'full_path',\n                                                y_col = 'labels',\n                                                batch_size = 64,\n                                                target_size = image_size)\n\ntest_generator  = test_gen.flow_from_dataframe(test_df,\n                                                x_col = 'full_path',\n                                                y_col = 'labels',\n                                                batch_size = 64,\n                                                target_size = image_size)","cee88853":"\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport pandas.util.testing as tm\nfrom sklearn import metrics\nimport seaborn as sns\nsns.set()\n\nplt.rcParams[\"font.family\"] = 'DejaVu Sans'\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues,\n                          save = False):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.grid(b=False)\n    if save == True:\n      plt.savefig('Confusion Matrix.png', dpi = 900)\n\ndef plot_roc_curve(y_true, y_pred, classes):\n\n    from sklearn.metrics import roc_curve, auc\n\n    # create plot\n    fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n    for (i, label) in enumerate(classes):\n        fpr, tpr, thresholds = roc_curve(y_true[:,i].astype(int), y_pred[:,i])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (label, auc(fpr, tpr)))\n\n    # Set labels for plot\n    c_ax.legend()\n    c_ax.set_xlabel('False Positive Rate')\n    c_ax.set_ylabel('True Positive Rate')\n    c_ax.set_title('Roc AUC Curve')\n    \n    \n# test model performance\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\n\ndef test_model(model, test_generator, y_test, class_labels, cm_normalize=True, \\\n                 print_cm=True):\n    \n    results = dict()\n\n    print('\\nPredicting test data')\n    test_start_time = datetime.now()\n    y_pred_original = model.predict_generator(test_generator,verbose=1)\n    # y_pred = (y_pred_original>0.5).astype('int')\n\n    y_pred = np.argmax(y_pred_original, axis = 1)\n    # y_test = np.argmax(testy, axis= 1)\n    #y_test = np.argmax(testy, axis=-1)\n    \n    test_end_time = datetime.now()\n    print('Done \\n \\n')\n    results['testing_time'] = test_end_time - test_start_time\n    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n    results['predicted'] = y_pred\n    y_test = y_test.astype(int) # sparse form not categorical\n    \n\n    # balanced_accuracy\n    from sklearn.metrics import balanced_accuracy_score\n    balanced_accuracy = balanced_accuracy_score(y_true=y_test, y_pred=y_pred)\n    print('---------------------')\n    print('| Balanced Accuracy  |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(balanced_accuracy))\n\n    \n    # calculate overall accuracty of the model\n    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n    # store accuracy in results\n    results['accuracy'] = accuracy\n    print('---------------------')\n    print('|      Accuracy      |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(accuracy))\n    \n\n    # get classification report\n    print('-------------------------')\n    print('| Classifiction Report |')\n    print('-------------------------')\n    classification_report = metrics.classification_report(y_test, y_pred)\n    # store report in results\n    results['classification_report'] = classification_report\n    print(classification_report)\n    \n    #roc plot\n    plot_roc_curve(tf.keras.utils.to_categorical(y_test), y_pred_original, class_labels)\n    \n   \n\n    # confusion matrix\n    cm = metrics.confusion_matrix(y_test, y_pred)\n    results['confusion_matrix'] = cm\n    if print_cm: \n        print('--------------------')\n        print('| Confusion Matrix |')\n        print('--------------------')\n        print('\\n {}'.format(cm))\n        \n    # plot confusin matrix\n    plt.figure(figsize=(16,12))\n    plt.grid(b=False)\n    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix')\n    plt.show()\n\n    \n    # add the trained  model to the results\n    results['model'] = model\n    \n    return\n\n\nfrom tensorflow.keras.callbacks import Callback\nclass MyLogger(Callback):\n  \n  def __init__(self, test_generator, y_test, class_labels):\n    super(MyLogger, self).__init__()\n    self.test_generator = test_generator\n    self.y_test = y_test\n    self.class_labels = class_labels\n    \n  def on_epoch_end(self, epoch, logs=None):\n    test_model(self.model, self.test_generator, self.y_test, self.class_labels)\n\n#   def _implements_train_batch_hooks(self): return True\n#   def _implements_test_batch_hooks(self): return True\n#   def _implements_predict_batch_hooks(self): return True","ed758400":"from tensorflow.keras.callbacks import *\ndef get_callbacks():\n    \n    filepath = 'best_model_multiclass_128.h5'\n    callback1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n    callback2 = MyLogger(test_generator,\n                    test_df[classes].values.argmax(axis = 1), \n                    classes)\n    \n\n    return [callback1 ,callback2]","1cfa3dce":"from tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *","c1a5c58f":"def Residual_Unit(input_tensor, nb_of_input_channels, max_dilation, number_of_units):\n    \n  for i in range(number_of_units):\n    x1 = Conv2D(nb_of_input_channels*2, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(input_tensor)\n    x1 = BatchNormalization()(x1)\n  \n    a = []\n\n    for i in range(1, max_dilation+1):\n      temp = DepthwiseConv2D( kernel_size=(3,3), dilation_rate = (i,i), padding = 'same', activation= 'relu')(x1)\n      temp = BatchNormalization()(temp)\n      a.append(temp)\n\n    x = Concatenate(axis= -1)(a)\n    x = Conv2D(nb_of_input_channels, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(x)\n    x = BatchNormalization()(x)\n\n    x = Add()([x, input_tensor])\n\n    input_tensor = x\n  \n  return x","22626a7a":"def Shifter_Unit(input_tensor, nb_of_input_channels, max_dilation):\n    x1 = Conv2D(nb_of_input_channels*4, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(input_tensor)\n    x1 = BatchNormalization()(x1)\n\n    a = []\n\n    for i in range(1, max_dilation+1):\n      temp = DepthwiseConv2D( kernel_size=(3,3), dilation_rate = (i,i), padding = 'same', activation= 'relu')(x1)\n      temp = MaxPool2D(pool_size=(2,2), padding = 'same')(temp)\n      temp = BatchNormalization()(temp)\n      a.append(temp)\n\n    x = Concatenate(axis= -1)(a)\n\n    x = Conv2D(nb_of_input_channels*2, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(x)\n    x = BatchNormalization()(x)\n\n    return x","d847eff8":"from tensorflow.keras.optimizers import Adam\n\n#Network:\n  \ndef Network128(input_shape, nb_class, depth):\n  xin = Input(shape= input_shape)\n\n  x = Conv2D(16, kernel_size = (5,5), strides= (1,1), padding = 'same', activation='relu')(xin)\n  x = BatchNormalization()(x)\n\n  x = Conv2D(32, kernel_size = (3,3), strides= (2,2), padding = 'same', activation='relu')(x)\n  x = BatchNormalization()(x)\n  \n##Max Dilation rate will be vary in the range (1,5). \n\n# Max Dilation rate is 5 for tensor (64x64x32)\n  x = Residual_Unit(input_tensor=x, nb_of_input_channels=32, max_dilation=5, number_of_units=depth)\n  x = Shifter_Unit(input_tensor=x, nb_of_input_channels=32, max_dilation=5)\n\n\n# Max Dilation rate is 4 for (32x32x64)\n  x = Residual_Unit(input_tensor=x, nb_of_input_channels=64, max_dilation=4, number_of_units=depth)\n  x = Shifter_Unit(input_tensor=x, nb_of_input_channels=64, max_dilation=4)\n\n# Max Dilation rate is 3 for (16x16x128)\n  x = Residual_Unit(input_tensor=x, nb_of_input_channels=128, max_dilation=3, number_of_units=depth)\n  x = Shifter_Unit(input_tensor=x, nb_of_input_channels=128, max_dilation=3)\n\n# Max Dilation rate is 2 for (8x8x256)\n  x = Residual_Unit(input_tensor=x, nb_of_input_channels=256, max_dilation=2, number_of_units=depth)\n\n  x = GlobalAveragePooling2D()(x)\n\n  x = Dense(128, activation='relu')(x)\n  x = Dense(64, activation='relu')(x)\n\n  x = Dense(nb_class, activation= 'softmax')(x)\n\n  model = Model(xin, x)\n\n  model.compile(loss='categorical_crossentropy', optimizer = Adam(lr = 1e-3), metrics = ['accuracy'])\n\n  return model\n","a11c8dca":"from sklearn.utils import class_weight\n \n \nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(train_df.labels.astype(int)),\n                                                 train_df.labels.astype(int))\nclass_weight =  dict(zip(np.sort(train_df.labels.astype(int).unique()), class_weights))\nclass_weight","8ab8522d":"model = Network128(input_shape = (128, 128, 3), nb_class = 14, depth = 5)\nmodel.summary()","4906bd31":"model.fit_generator(generator = train_generator,\n                    steps_per_epoch = train_generator.samples\/train_generator.batch_size,\n                    epochs = 45,\n                    validation_data = test_generator,\n                    validation_steps = test_generator.samples\/test_generator.batch_size,\n                    class_weight = class_weight,\n                    callbacks = get_callbacks()\n                   )","307fab1b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nacc = model.history.history['accuracy']\nval_acc = model.history.history['val_accuracy']\nloss = model.history.history['loss']\nval_loss = model.history.history['val_loss']\n\nepochs = range(0,len(acc))\nfig = plt.gcf()\nfig.set_size_inches(16, 8)\n\nplt.plot(epochs, acc, 'r', label='Training accuracy',marker = \"o\")\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy',marker = \"o\")\nplt.title('Training and validation accuracy')\nplt.xticks(np.arange(0, len(acc), 10))\nplt.legend(loc=0)\nplt.figure()\n\nfig = plt.gcf()\nfig.set_size_inches(16, 8)\nplt.plot(epochs, loss, 'r', label='Training Loss',marker = \"o\")\nplt.plot(epochs, val_loss, 'b', label='Validation Loss',marker = \"o\")\nplt.title('Training and validation Loss')\nplt.xticks(np.arange(0, len(acc), 10))\nplt.legend(loc=0)\n#plt.savefig('Multiclass Model .png')\nplt.figure()\nplt.show()\n","2afbe3ac":"from tensorflow.keras.models import load_model\n\nbest_model = load_model('\/kaggle\/working\/best_model_multiclass_128.h5')","2d3a4f14":"test_model(best_model, test_generator, y_test = test_df[classes].values.argmax(axis = 1), class_labels = classes)","eb448c42":"## Shifter Unit","21725e02":"## Residual Unit","17d6c7b3":"# Seleting some samples from all the images\nRemoving other other labels","81eb04b2":"# Visualization","657dc3f5":"## Network128","87d5ea2a":"# Training","fa8af118":"# Loading DataFrame","852b95c7":"# [CovXNet: A multi-dilation convolutional neural network for automatic COVID-19 and other pneumonia detection from chest X-ray images with transferable multi-receptive feature optimization](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0010482520302250)\n\n#### Code:[here](https:\/\/github.com\/Perceptron21\/CovXNet)\n## Residual & Shifter Unit:\n![Residual & Shifter Unit](https:\/\/ars.els-cdn.com\/content\/image\/1-s2.0-S0010482520302250-gr2.jpg)\n\n## Model:\n![Model](https:\/\/ars.els-cdn.com\/content\/image\/1-s2.0-S0010482520302250-gr4.jpg)\n","e5736911":"# Loading Best Model","90193d3e":"# Assigning Labels","60448be2":"# ImageDataGenerator","df14fd76":"# Custom Callback","7876b93f":"# Best Model Performance\n","0db73f2f":"# EpochPlot","e03a0416":"# Finding Paths for Image","a650b87b":"# Dealing with Class Imbalance"}}