{"cell_type":{"871f0b9f":"code","7047f360":"code","f386a74f":"code","fafc97cc":"code","ec3c9cd5":"code","d35de905":"code","ff168fdf":"code","287c4d86":"code","701c8405":"code","97b87f23":"code","802b31a7":"code","da62c6d8":"code","c6bf8be4":"code","1e3a6f69":"code","15ee8c92":"code","c1e626f0":"code","af311793":"code","1d02697d":"code","a8ebdc03":"code","ce8140ec":"code","a28f01d6":"code","e013b881":"code","4e0aa52e":"code","df97b9b3":"code","7ca073e7":"code","f61219bc":"code","a48cf30b":"markdown","bc36dc06":"markdown","2102f3a9":"markdown","1fd9cb16":"markdown","22f20482":"markdown","c830dd93":"markdown","66e4f6f1":"markdown"},"source":{"871f0b9f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nflag = 0\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if flag == 5:\n            break\n        print(os.path.join(dirname, filename))\n        flag += 1\n    if flag ==5:\n        break\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7047f360":"from PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as D\nfrom torch.optim.lr_scheduler import ExponentialLR\n\nfrom torchvision import models as M, transforms as T\n\nfrom tqdm import tqdm_notebook\n\nfrom glob import glob\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Loss, Accuracy\nfrom ignite.contrib.handlers.tqdm_logger import ProgressBar\nfrom ignite.handlers import ModelCheckpoint, EarlyStopping ","f386a74f":"!pip install efficientnet_pytorch","fafc97cc":"from efficientnet_pytorch import EfficientNet","ec3c9cd5":"os.listdir(\"\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/\")","d35de905":"BASE_PATH = \"\/kaggle\/input\/siim-isic-melanoma-classification\"\ndf_train = pd.read_csv(BASE_PATH + \"\/train.csv\")\ndf_test = pd.read_csv(BASE_PATH + \"\/test.csv\")\ndf_sub = pd.read_csv(BASE_PATH + \"\/sample_submission.csv\")","ff168fdf":"temp = plt.imread(BASE_PATH + \"\/jpeg\/train\/ISIC_4232172.jpg\")\nplt.xticks([])\nplt.yticks([])\nplt.imshow(temp)","287c4d86":"batch_size = 32\ndevice = \"cuda\"\ntorch.manual_seed(0)","701c8405":"temp.shape","97b87f23":"BINGO_PATH = \"\/kaggle\/input\/siic-isic-224x224-images\"","802b31a7":"class ImagesDS(D.Dataset):\n    def __init__(self, df, dir, mode = \"train\"):\n        self.records = df.to_records(index = False)\n        self.mode = mode\n        self.dir = dir\n        self.len = df.shape[0]\n        \n    @staticmethod\n    def _load_img_as_tensor(filename):\n        with Image.open(filename) as img:\n            return T.Compose([T.Resize((224, 224)), T.RandomHorizontalFlip(), T.ToTensor(), T.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])(img)\n        \n    def _get_image_path(self, index):\n        image_id = self.records[index].image_name\n        return \"\/\".join([self.dir, self.mode, f\"{image_id}.png\"])\n    \n    def __getitem__(self, index):\n        path = self._get_image_path(index)\n        img = self._load_img_as_tensor(path)\n        if self.mode == \"train\":\n            return img, self.records[index].target\n        else:\n            return img, self.records[index].image_name\n        \n    def __len__(self):\n        return self.len","da62c6d8":"train_data, val_data = train_test_split(df_train, test_size = 0.2, random_state = 42)","c6bf8be4":"ds = ImagesDS(train_data, BINGO_PATH, mode = \"train\")\nds_val = ImagesDS(val_data, BINGO_PATH, mode = \"train\")\nds_test = ImagesDS(df_test, BINGO_PATH, mode = \"test\")","1e3a6f69":"classes = 1\nmodel = EfficientNet.from_pretrained(\"efficientnet-b0\")\nmodel.fc = nn.Linear(1280, classes, bias = True)","15ee8c92":"loader = D.DataLoader(ds, batch_size = 64, shuffle = True, num_workers = 4)\nval_loader = D.DataLoader(ds_val, batch_size = batch_size, shuffle = True, num_workers = 4)\ntest_loader = D.DataLoader(ds_test, batch_size = batch_size, shuffle = False, num_workers = 4)","c1e626f0":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 3e-4, weight_decay = 0.00001)","af311793":"metrics = {\"loss\" : Loss(criterion), \"accuracy\" : Accuracy()}\n\ntrainer = create_supervised_trainer(model, optimizer, criterion, device = device)\nval_eval = create_supervised_evaluator(model, metrics = metrics, device = device)","1d02697d":"@trainer.on(Events.EPOCH_COMPLETED)\ndef compute_and_display(engine):\n    epoch = engine.state.epoch\n    metrics = val_eval.run(val_loader).metrics\n    print(\"Validation Results - Epoch : {} Average loss : {:.4f} Average Accuracy : {:.4f}\".format(engine.state.epoch, metrics[\"loss\"], metrics[\"accuracy\"]))","a8ebdc03":"handler = EarlyStopping(patience = 4, score_function = lambda engine : engine.state.metrics[\"accuracy\"], trainer = trainer)\n\nval_eval.add_event_handler(Events.COMPLETED, handler)","ce8140ec":"checkpoints = ModelCheckpoint(\"models\", \"Model\", n_saved = 3, create_dir = True)\n\ntrainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoints, {\"Konoha_senpu\" : model})","a28f01d6":"pbar = ProgressBar(bar_format = \"\")\n\npbar.attach(trainer, output_transform = lambda x : {\"loss\" : x})","e013b881":"trainer.run(loader, max_epochs = 15)","4e0aa52e":"model.eval()\ntest_preds = np.zeros((df_test.shape[0], ))\nwith torch.no_grad():\n    for i, data in enumerate(tqdm_notebook(test_loader, position=0, leave=True)):\n        images, _ = data\n        images = images.to(device)\n        output = model(images)\n        output = torch.softmax(output,1).cpu().detach().numpy()[:,1]\n        test_preds[i*batch_size : (i+1)*batch_size] = output","df97b9b3":"test_preds","7ca073e7":"df_sub.target = test_preds","f61219bc":"df_sub.to_csv(\"submission.csv\", index = False)","a48cf30b":"Have a Great day ahead! :)","bc36dc06":"* Although this is a basic notebook, I believe if you want to try your ideas on it, it have a lot of possibilities for that. \n\n* Some of the options you might want to try are Augmentation, Fold training, loss, Metrics etc.\n\nThanks for reading this kernel. ^_^","2102f3a9":"## Training Images","1fd9cb16":"### Getting our pretrained model...","22f20482":"### Loss and Optimizer","c830dd93":"## Importing necessary Libraries","66e4f6f1":"### Here starts the ignite magic! "}}