{"cell_type":{"f2c71a18":"code","167593e5":"code","8cb89b0c":"code","5fc7986d":"code","c02ab8ae":"code","ba682aaa":"code","dfe4442e":"code","52450d43":"code","f44a3355":"code","cfaaf718":"code","a3d82496":"code","8a887c86":"code","e863049b":"code","41be498a":"code","a5fa9758":"code","dd59d3b2":"code","b8c9eecb":"code","5bbf50e7":"code","8391cf73":"code","9798a785":"markdown","6de951c8":"markdown","5036796c":"markdown","7c43a1b7":"markdown","c6f1e053":"markdown","1329cf46":"markdown","4839913e":"markdown","21752bd2":"markdown","7aff7ca0":"markdown","eec981ab":"markdown","84f8020f":"markdown","adaa73da":"markdown","e77cb420":"markdown","b0aaf25f":"markdown","24720b33":"markdown","776c6307":"markdown","91231063":"markdown","4b12a056":"markdown","dc432c0a":"markdown","2b34d21f":"markdown"},"source":{"f2c71a18":"import numpy as np \nimport pandas as pd\nimport sklearn as skl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","167593e5":"data_train = pd.read_csv('..\/input\/train_data.csv')\ndata_test = pd.read_csv('..\/input\/test_data.csv')","8cb89b0c":"data_train.columns","5fc7986d":"data_train=data_train.drop(['Unnamed: 0'],axis=1).drop(['Unnamed: 1'],axis=1)\ndata_test=data_test.drop(['Unnamed: 0'],axis=1).drop(['Unnamed: 1'],axis=1)","c02ab8ae":"corr_matrix=data_train.corr()\n\nf,ax=plt.subplots(figsize=(30,20))\nsns.heatmap(corr_matrix,vmax=1,annot=True)","ba682aaa":"for i in list(data_train.columns):\n    if data_train[i].nunique()==1:\n        print('Drop Column:',i)\n        data_train=data_train.drop([i],axis=1)\n        data_test =data_test.drop([i],axis=1)","dfe4442e":"highly_correlated_feature     = list(corr_matrix.index[abs(corr_matrix[\"Survived\"])>0.7])\nmoderately_correlated_feature = list(corr_matrix.index[abs(corr_matrix[\"Survived\"])>0.4])\nmodestely_correlated_feature  = list(corr_matrix.index[abs(corr_matrix[\"Survived\"])>0.1])\nweakly_correlated_feature     = list(corr_matrix.index[abs(corr_matrix[\"Survived\"])>0.01])\n\nhighly_correlated_feature.remove('Survived')\nmoderately_correlated_feature.remove('Survived')\nmodestely_correlated_feature.remove('Survived')\nweakly_correlated_feature.remove('Survived')\n\nprint(\"highly_correlated_feature:\\n\",highly_correlated_feature,'\\n')\nprint(\"moderately_correlated_feature:\\n\",moderately_correlated_feature,'\\n')\nprint(\"modestely_correlated_feature:\\n\",modestely_correlated_feature,'\\n')\nprint(\"weakly_correlated_feature:\\n\",weakly_correlated_feature)","52450d43":"useless_features=list(corr_matrix.index[abs(corr_matrix[\"Survived\"])<0.01])\nprint(\"UselessFeatures:\",useless_features)","f44a3355":"sns.countplot(x=data_train['male'],hue = data_train['Survived'])","cfaaf718":"sns.countplot(x=data_train['Mr'],hue = data_train['Survived'])","a3d82496":"data_train['Survived'].value_counts().plot.pie(autopct = '%1.2f%%')","8a887c86":"from sklearn.model_selection import train_test_split","e863049b":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(max_depth = 3, n_estimators=10)\nmodel.fit(data_train[moderately_correlated_feature],data_train['Survived'])\nestimator_limited = model.estimators_[7]\n\nfrom sklearn.tree import export_graphviz\nexport_graphviz(estimator_limited, out_file='tree_limited.dot', rounded = True, proportion = False, precision = 2, filled = True,\n                feature_names = moderately_correlated_feature)\n!dot -Tpng tree_limited.dot -o tree_limited.png -Gdpi=110\n\nfrom IPython.display import Image\nImage(filename = 'tree_limited.png')","41be498a":"# No max depth\nmodel = RandomForestClassifier(max_depth = None, n_estimators=10)\nmodel.fit(data_train[modestely_correlated_feature],data_train['Survived'])\nestimator_nonlimited = model.estimators_[5]\nexport_graphviz(estimator_nonlimited, out_file='tree_nonlimited.dot',\n                feature_names = modestely_correlated_feature,rounded = True, \n                proportion = False, precision = 2, filled = True)\n!dot -Tpng tree_nonlimited.dot -o tree_nonlimited.png -Gdpi=600\nImage(filename = 'tree_nonlimited.png')","a5fa9758":"from sklearn.model_selection import GridSearchCV","dd59d3b2":"from sklearn.tree import DecisionTreeClassifier\nDTC_model = DecisionTreeClassifier()\nDTC_parameters={'random_state':list(range(10))}\nDTC_GSCV= GridSearchCV(DTC_model,DTC_parameters,refit=True,cv=3)\n\nlist_correlated_feature = [moderately_correlated_feature,modestely_correlated_feature,weakly_correlated_feature]\n\nfor correlated_feature in list_correlated_feature:\n    X_train, X_test, y_train, y_test = train_test_split(data_train[correlated_feature], data_train['Survived'],test_size=0.25, random_state=33)\n    DTC_GSCV.fit(X_train,y_train)\n    DTC_GSCV_result = DTC_GSCV.predict(data_test[correlated_feature])\n    params_DTC = DTC_GSCV.best_params_\n    best_score_DTC=DTC_GSCV.best_score_\n    print('Features:\\n',correlated_feature)\n    print('best_params_:',params_DTC)\n    print('best_score_:',best_score_DTC)\n    print('GSCV_result:\\n',DTC_GSCV_result)\n    submission = pd.DataFrame({'PassengerId':data_test['PassengerId'],'Survived':DTC_GSCV_result})\n    filename = 'Titanic_DecisionTreeClassifier_'+str(len(correlated_feature))+'features.csv'\n    submission.to_csv(filename,index=False)\n    print('Saved file: ' + filename)\n    print('\\n','-'*77,'\\n')","b8c9eecb":"from sklearn.ensemble import RandomForestClassifier\n\nRFC_model = RandomForestClassifier()\nRFC_parameters={'random_state':list(range(10)),'n_estimators':list(range(50,100,2)),'max_depth':list(range(3,10))}\nRFC_GSCV= GridSearchCV(RFC_model,RFC_parameters,refit=True,cv=3)\n\nlist_correlated_feature = [moderately_correlated_feature,modestely_correlated_feature,weakly_correlated_feature]\n\nfor correlated_feature in list_correlated_feature:\n    X_train, X_test, y_train, y_test = train_test_split(data_train[correlated_feature], data_train['Survived'],test_size=0.25, random_state=33)\n    RFC_GSCV.fit(X_train,y_train)\n    RFC_GSCV_result = RFC_GSCV.predict(data_test[correlated_feature])\n    params_RFC = RFC_GSCV.best_params_\n    best_score_RFC=RFC_GSCV.best_score_\n    print('Features:\\n',correlated_feature)\n    print('best_params_:',params_RFC)\n    print('best_score_:',best_score_RFC)\n    print('GSCV_result:\\n',RFC_GSCV_result)\n    submission = pd.DataFrame({'PassengerId':data_test['PassengerId'],'Survived':RFC_GSCV_result})\n    filename = 'Titanic_RandomForestClassifier_'+str(len(correlated_feature))+'features.csv'\n    submission.to_csv(filename,index=False)\n    print('Saved file: ' + filename)\n    print('\\n','-'*77,'\\n')","5bbf50e7":"from sklearn.linear_model import LogisticRegression\nLR_model = LogisticRegression()\n\nLR_parameters={'random_state':list(range(10))}\nLR_GSCV= GridSearchCV(LR_model,LR_parameters,refit=True,cv=3)\n\nlist_correlated_feature = [moderately_correlated_feature,modestely_correlated_feature,weakly_correlated_feature]\n\nfor correlated_feature in list_correlated_feature:\n    X_train, X_test, y_train, y_test = train_test_split(data_train[correlated_feature], data_train['Survived'],test_size=0.25, random_state=33)\n    LR_GSCV.fit(X_train,y_train)\n    LR_GSCV_result = LR_GSCV.predict(data_test[correlated_feature])\n    params_LR      = LR_GSCV.best_params_\n    best_score_LR  = LR_GSCV.best_score_\n    print('Features:\\n',correlated_feature)\n    print('best_params_:',params_LR)\n    print('best_score_:',best_score_LR)\n    print('GSCV_result:\\n',LR_GSCV_result)\n    submission = pd.DataFrame({'PassengerId':data_test['PassengerId'],'Survived':LR_GSCV_result})\n    filename = 'Titanic_LogisticRegression_'+str(len(correlated_feature))+'features.csv'\n    submission.to_csv(filename,index=False)\n    print('Saved file: ' + filename)\n    print('\\n','-'*77,'\\n')","8391cf73":"from xgboost import XGBClassifier\n\nXGB_model = XGBClassifier()\nXGB_parameters={'random_state':list(range(10)),'max_depth':list(range(3,10)),'n_estimators':list(range(50,100,2))}\nXGB_GSCV= GridSearchCV(XGB_model,XGB_parameters,refit=True,cv=3)\n\nlist_correlated_feature = [moderately_correlated_feature,modestely_correlated_feature,weakly_correlated_feature]\n\nfor correlated_feature in list_correlated_feature:\n    X_train, X_test, y_train, y_test = train_test_split(data_train[correlated_feature], data_train['Survived'],test_size=0.25, random_state=33)\n    XGB_GSCV.fit(X_train,y_train)\n    XGB_GSCV_result = XGB_GSCV.predict(data_test[correlated_feature])\n    params_XGB     = XGB_GSCV.best_params_\n    best_score_XGB  = XGB_GSCV.best_score_\n    print('Features:\\n',correlated_feature)\n    print('best_params_:',params_XGB)\n    print('best_score_:',best_score_XGB)\n    print('GSCV_result:\\n',XGB_GSCV_result)\n    submission = pd.DataFrame({'PassengerId':data_test['PassengerId'],'Survived':XGB_GSCV_result})\n    filename = 'Titanic_XGBClassifier_'+str(len(correlated_feature))+'features.csv'\n    submission.to_csv(filename,index=False)\n    print('Saved file: ' + filename)\n    print('\\n','-'*77,'\\n')","9798a785":"## DecisionTreeClassifier","6de951c8":"### The \"gradient\" in \"gradient boosting\" refers to the fact that we'll use gradient descent on the loss function to determine the parameters in this new model.\n![](https:\/\/ithelp.ithome.com.tw\/upload\/images\/20171203\/20001976tHmwPv6YYG.png)\n![](https:\/\/i.imgur.com\/MvCGENh.png)","5036796c":"### Cross validation","7c43a1b7":"# Read Fileds","c6f1e053":"### Correlation Coefficien\n![](https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/86c6b669f6b937c12ba7e0d1afce559904c5a092)\n![](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*xQiOsMfd4HQT9yW-pF_V_g.png)","1329cf46":"# Import","4839913e":"![](https:\/\/i.imgur.com\/9k60cVA.png)","21752bd2":"* 1\t         \u5b8c\u5168\u76f8\u95dc (Perfect correlated)\n* 0.7~0.99\t \u9ad8\u5ea6\u76f8\u95dc (Highly correlated)\n* 0.4~0.69\t \u4e2d\u5ea6\u76f8\u95dc (Moderately correlated)\n* 0.1~0.39\t \u4f4e\u5ea6\u76f8\u95dc (Modestly correlated)\n* 0.01~0.09\t \u63a5\u8fd1\u7121\u76f8\u95dc (Weakly correlated)\n* \u7d04=0\t    \u7121\u76f8\u95dc","7aff7ca0":"### data_train.Mr","eec981ab":"### Drop Columns","84f8020f":"### GridSearch","adaa73da":"### Underfitting \/ Overfitting\n![](https:\/\/cdn-images-1.medium.com\/max\/1200\/1*_7OPgojau8hkiPUiHoGK_w.png)","e77cb420":"# Choose Features ","b0aaf25f":"### train_data.male","24720b33":"### data_train.Survived","776c6307":"## XGBClassifier","91231063":"[\u53c3\u8003\u8cc7\u6599](https:\/\/medium.com\/@chih.sheng.huang821\/%E6%A9%9F%E5%99%A8-%E7%B5%B1%E8%A8%88%E5%AD%B8%E7%BF%92-%E7%BE%85%E5%90%89%E6%96%AF%E5%9B%9E%E6%AD%B8-logistic-regression-aff7a830fb5d)\n![](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*RL7IQqlKrvVaeJGsc11GXg.png)\n![](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*F9koiudfoqYIP0sDoZyG4g.png)\n![](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*bihmixRiehXugTYRpku9HA.png)\n### Sigmoid Function\n![](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*xZEQyrVAecH-pl_ogcGubg.png)","4b12a056":"# Models","dc432c0a":"## RandomForestClassifier","2b34d21f":"## LogisticRegression"}}