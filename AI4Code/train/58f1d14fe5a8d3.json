{"cell_type":{"7e3f2538":"code","80116934":"code","4c11f5bd":"code","4f83c9f8":"code","9cc9d81e":"code","89582a9d":"code","8b3de2c5":"code","fc619d3f":"code","e7a3aa45":"code","bb38e2b7":"code","02fd8065":"code","642f4ce1":"code","1579f1ba":"code","cdf4fcb3":"code","c326ead6":"code","81ac1ba5":"code","03067d65":"code","5f1a002f":"code","f0f4a439":"code","1e4f4c49":"code","a1a0007e":"code","df134dc2":"code","9442b1aa":"code","652c0946":"code","d1900e8e":"code","2bbce87e":"code","1e597ee2":"code","689f9d1a":"code","b96ab478":"code","edf4214e":"code","e906d840":"code","7de54f93":"code","a649e791":"code","92dfa20e":"code","665999ba":"code","add87f2e":"code","5ac2d3de":"code","5eb0a9df":"code","c0349d91":"code","0b3cd266":"code","c2aaa771":"code","7a638f43":"code","d280dd50":"code","e664e3df":"code","52d46d3e":"code","c4bd9352":"code","ee5e8c15":"code","e92061bb":"code","4d16d2fb":"code","a4a9ae65":"code","5992459f":"code","2a2c77ce":"code","2a80b1d1":"code","6df963b5":"code","eee4ad7f":"code","7dbd0a38":"code","0cdc4e81":"code","d39b449b":"code","590d8f79":"code","474341bf":"code","3bb2febe":"code","0bafde4d":"code","1cf4e344":"code","fd3d6faa":"code","23865745":"code","f7d6a6b1":"code","3cd408e6":"code","b71a4c43":"code","cfddb9fc":"code","920f69ee":"code","e7998b48":"code","d50d9662":"code","ea0e174f":"code","176e2880":"code","a60c91f2":"code","140efdca":"code","8003ceb0":"code","7d9d5405":"code","3563a136":"code","533b023a":"code","29a814ef":"code","8bd4216b":"code","d8e186f1":"code","6cb678be":"code","bb2e96b0":"code","d24a2596":"code","ceb6c8cf":"code","e5dc409f":"code","4f04dc2e":"code","315bf038":"code","edbb4421":"code","7ad943fc":"code","01537def":"code","7be3980e":"code","6ac90fbc":"code","af79a935":"code","f1a44dcd":"code","aebac812":"code","ec26dd95":"code","6e084499":"code","206ca414":"code","bf4b475c":"code","6d6a8bae":"code","0462ecac":"code","742107d3":"code","5690a367":"code","6844c586":"code","e3a5555c":"code","e0caf3a3":"code","c9fcac12":"code","ca7afb3b":"code","b35178c0":"code","90234eea":"code","979a6256":"markdown","a0aee883":"markdown","e8f1aa91":"markdown","bdca330c":"markdown","848e68f0":"markdown","4266a51d":"markdown","cde4e6d9":"markdown","7ff59da8":"markdown","e0e4dee8":"markdown","03e02491":"markdown","098b7f41":"markdown","da50a396":"markdown","78578569":"markdown","b9ab7861":"markdown","ade879a4":"markdown","4123ba55":"markdown","50d04e64":"markdown","9d74a3b4":"markdown","e5f96da3":"markdown","5fd51ea7":"markdown","e59632e5":"markdown","f97ee2f1":"markdown","503109a1":"markdown","4ba43377":"markdown","7bce016b":"markdown","bb0e940f":"markdown","22453efb":"markdown","8833b630":"markdown","059e5476":"markdown","42421f38":"markdown","578fc58d":"markdown","389493f7":"markdown","f0aab251":"markdown","abec6970":"markdown","d9a070d7":"markdown","19bd58e1":"markdown","fa6d9183":"markdown","f3421055":"markdown","fd6697c9":"markdown","15b3c294":"markdown","da876370":"markdown","793cb3a0":"markdown","0efac6df":"markdown"},"source":{"7e3f2538":"import time\nfrom datetime import datetime\n#measure notebook running time\nstart_time = time.time()\n\n%matplotlib inline\n\n# backbone\nimport os, warnings\nimport numpy as np \nfrom numpy.random import seed\nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV, RandomizedSearchCV\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor,RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import ElasticNet, Lasso, Ridge,LinearRegression\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.svm import SVR\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\nfrom category_encoders import MEstimateEncoder\n\nsns.set(style='darkgrid', context='notebook', palette='deep', rc={'figure.figsize':(10,8)})\nprint(\"loaded ...\")","80116934":"# Reproducibility\ndef set_seed(sd=13):\n    seed(sd)\n    np.random.seed(sd)\n    os.environ['PYTHONHASHSEED'] = str(sd)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed(13)","4c11f5bd":"def make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores","4f83c9f8":"mm = StandardScaler()\n#mm = MinMaxScaler()\n#mm = RobustScaler()","9cc9d81e":"TRAIN = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\nTEST = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\nTRAIN['Set'] = \"Train\"\nTEST['Set'] = \"Test\"\nTEST['SalePrice'] = -1\nDATA = TRAIN.append(TEST)\nDATA.reset_index(inplace=True)\nprint(\"DATA set ...\")","89582a9d":"DATA = DATA.drop(DATA[DATA.Set == \"Train\"][DATA[DATA.Set == \"Train\"]['GrLivArea'] > 4000].index)\nDATA.reset_index(inplace=True, drop = True)","8b3de2c5":"DATA[DATA.columns[DATA.isna().sum() > 0]].isna().sum().sort_values().plot.bar();","fc619d3f":"DATA['MSZoning'].fillna(\"RL\", inplace = True)\nDATA.Alley.fillna(\"NO\", inplace = True)\nDATA.Utilities.fillna('AllPub',inplace = True)\nDATA.Exterior1st.fillna(\"VinylSd\", inplace = True)\nDATA.Exterior2nd.fillna(\"VinylSd\", inplace = True)\nDATA.MasVnrArea.fillna(0., inplace=True)\nDATA.BsmtCond.fillna(\"No\", inplace=True)\nDATA.BsmtQual.fillna(\"No\", inplace=True)\nDATA.BsmtExposure.fillna(\"NB\", inplace=True)\nDATA.BsmtFinType1.fillna(\"NB\", inplace=True)\nDATA.BsmtFinType2.fillna(\"NB\", inplace=True)\nDATA.BsmtFinSF1.fillna(0., inplace=True)\nDATA.BsmtFinSF2.fillna(0., inplace=True)\nDATA.BsmtUnfSF.fillna(0., inplace=True)\nDATA.TotalBsmtSF.fillna(0., inplace=True)\nDATA.Electrical.fillna(\"SBrkr\", inplace = True)\nDATA.BsmtFullBath.fillna(0., inplace=True)\nDATA.BsmtHalfBath.fillna(0., inplace=True)\nDATA.KitchenQual.fillna(\"TA\", inplace = True)\nDATA.Functional.fillna('Typ', inplace = True)\nDATA.FireplaceQu.fillna(\"No\", inplace = True)\nDATA.GarageType.fillna(\"No\", inplace = True)\nDATA.GarageYrBlt.fillna(0, inplace = True)\nDATA.GarageFinish.fillna(\"No\", inplace = True)\nDATA.GarageCars.fillna(0, inplace = True)\nDATA.GarageArea.fillna(0, inplace = True)\nDATA.GarageQual.fillna(\"No\", inplace = True)\nDATA.GarageCond.fillna(\"No\", inplace = True)\nDATA.PoolQC.fillna(\"No\", inplace = True)\nDATA.Fence.fillna(\"No\", inplace = True)\nDATA.MiscFeature.fillna(\"No\", inplace = True)\nDATA.SaleType.fillna(\"Con\", inplace = True)\nDATA.SaleCondition.fillna(\"Normal\", inplace = True)","e7a3aa45":"DATA['LotFrontage'] = DATA.groupby(['Neighborhood', 'Street'])['LotFrontage'].transform(lambda x: x.fillna(x.median()))","bb38e2b7":"DATA.BsmtFullBath.replace(3.0, 2.0, inplace=True) #better score\nDATA.BsmtFullBath = DATA.BsmtFullBath.astype('int')\nDATA.BsmtHalfBath = DATA.BsmtHalfBath.astype('int')\nDATA.KitchenAbvGr = pd.cut(DATA.KitchenAbvGr,2)\nDATA.KitchenAbvGr = DATA.KitchenAbvGr.astype('category').cat.rename_categories([0, 1])\nDATA.Fireplaces = DATA.Fireplaces.apply(lambda row: 2 if row >= 2 else row)\nDATA.Fireplaces = DATA.Fireplaces.astype('int')\nDATA['GarageAgeCat'] = DATA.GarageYrBlt.apply(lambda row: 'recent' if row >= 2000 else 'old')\nDATA.GarageCars = DATA.GarageCars.astype('int')","02fd8065":"marks = {\"No\":0, \"Po\": 1, 'Fa': 2, \"TA\": 3, 'Gd': 4, 'Ex': 5}\n\ndef mark_to_num(mark):\n    return marks[mark]\n\nDATA['ExterQual'] = DATA['ExterQual'].apply(mark_to_num)\nDATA['ExterCond'] = DATA['ExterCond'].apply(mark_to_num)\nDATA['HeatingQC'] = DATA['HeatingQC'].apply(mark_to_num)\nDATA['KitchenQual'] = DATA['KitchenQual'].apply(mark_to_num)\nDATA['FireplaceQu'] = DATA['FireplaceQu'].apply(mark_to_num)\nDATA['GarageQual'] = DATA['GarageQual'].apply(mark_to_num)\nDATA['GarageCond'] = DATA['GarageCond'].apply(mark_to_num)\nDATA['PoolQC'] = DATA['PoolQC'].apply(mark_to_num)\nDATA['BsmtCond'] = DATA['BsmtCond'].apply(mark_to_num)\nDATA['BsmtQual'] = DATA['BsmtQual'].apply(mark_to_num)","642f4ce1":"DATA['BsmtFinSF'] = DATA.BsmtFinSF1 + DATA.BsmtFinSF2\nDATA['Porch'] = DATA.ScreenPorch + DATA.EnclosedPorch + DATA.OpenPorchSF + DATA.WoodDeckSF + DATA['3SsnPorch']\nDATA['Total_surface'] = DATA.TotalBsmtSF + DATA['1stFlrSF'] + DATA['2ndFlrSF']\nDATA['Age'] = DATA.YrSold - DATA.YearBuilt\nDATA['RemodAge'] = DATA.YrSold - DATA.YearRemodAdd\nDATA['GarageAge'] = DATA.YrSold - DATA.GarageYrBlt\nDATA['Overall'] = (DATA['OverallCond'] * DATA.OverallQual)\nDATA['External_Overall'] = DATA['ExterCond'] * DATA['ExterQual']\nDATA['LotArea_log'] = np.log(DATA['LotArea'])\nDATA[\"Spaciousness\"] = (DATA['1stFlrSF'] + DATA['2ndFlrSF']) \/ DATA.TotRmsAbvGrd\nDATA['Porch_types'] = DATA[['ScreenPorch', 'EnclosedPorch', 'OpenPorchSF', 'WoodDeckSF', '3SsnPorch']].gt(0.0).sum(axis=1)\nDATA['WOW'] = np.sqrt(DATA['Overall'] * DATA['GrLivArea']) # WOW factor\nDATA[\"MedNhbdArea\"] = DATA.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\nDATA['GarageOverall'] = DATA.GarageQual * DATA.GarageCond\nDATA['GarageWow'] = DATA.GarageOverall * DATA.GarageArea\nDATA['BsmtWow'] = DATA.BsmtCond * DATA.BsmtFinSF #not used\nDATA['Freshness'] = DATA.Age * DATA.RemodAge #not used\nDATA['Newness'] = np.sqrt(DATA.YearRemodAdd * DATA.GrLivArea)\nDATA['TotalOverall'] = DATA['Overall'] + DATA['GarageOverall'] + DATA['External_Overall'] #not used\nDATA['TotalWow'] = DATA['WOW'] + DATA['GarageWow'] + DATA['BsmtWow']\nDATA['NewWOW'] = np.sqrt(DATA['Overall'] * DATA['GrLivArea'] * DATA.YearRemodAdd) #not used\nDATA['New'] = DATA.Age.apply(lambda row: 1 if row == 0 else 0)\nDATA['Fresh'] = DATA.RemodAge.apply(lambda row: 1 if row == 0 else 0) #not used\nDATA['MSZ_Age'] =(DATA.groupby(['MSZoning'])['Age'].transform(lambda x: x.median()) + DATA.Age)\/2 #not used\n\n#PCA inspired\nDATA['Grand_Total'] = DATA.GrLivArea * 0.55 + DATA.GarageArea * 0.55 + DATA.BsmtFinSF * 0.4 + DATA.Porch * 0.5 #not used","1579f1ba":"DATA['hasBsmt'] = DATA.TotalBsmtSF.apply(lambda row: 1 if row > 0 else 0)\nDATA['hasGarage'] = DATA.GarageArea.apply(lambda row: 1 if row > 0 else 0)\nDATA['hasFireplace'] = DATA.Fireplaces.apply(lambda row: 1 if row > 0 else 0) #excluded, worsens score\nDATA['hasPool'] = DATA.PoolArea.apply(lambda row: 1 if row > 0 else 0) #excluded, worsens score","cdf4fcb3":"sns.jointplot(data = DATA[DATA.Set == \"Train\"], x=\"hasPool\",y=\"SalePrice\", kind='reg');\n# sns.jointplot(data = DATA[DATA.Set == \"Train\"], x=\"TotalWow\",y=\"SalePrice\", kind='reg');","c326ead6":"check = sorted([\"Grand_Total\",\"Newness\", \"MedNhbdArea\",\"WOW\",\"LotArea_log\",'Total_surface','BsmtFinSF','Porch',\"Spaciousness\", \"Age\", 'Freshness','GarageOverall'])","81ac1ba5":"%%time\ndef plot(x,y,hue, **kwargs):\n    sns.scatterplot(x=x,y=y, hue=hue);\n    _=plt.xticks(rotation=90)\n\nf = pd.melt(DATA[DATA.Set == \"Train\"], id_vars=['SalePrice','SaleCondition'], value_vars=check)\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=6, sharex=False, sharey=True, height=4);\ng = g.map(plot, \"value\", \"SalePrice\", 'SaleCondition');\ng.add_legend();","03067d65":"%%time\ndef plot(x,y,hue, **kwargs):\n    sns.scatterplot(x=x,y=y, hue=hue);\n    _=plt.xticks(rotation=90)\n\nf = pd.melt(DATA[DATA.Set == \"Train\"], id_vars=['SalePrice','SaleType'], value_vars=check)\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=6, sharex=False, sharey=True, height=4);\ng = g.map(plot, \"value\", \"SalePrice\", 'SaleType');\ng.add_legend();","5f1a002f":"_X = DATA[DATA.Set == \"Train\"].copy()\n_X.drop(['index','Id'], axis=1, inplace =True)\nmi_scores = make_mi_scores(_X, _X.pop('SalePrice'))\nmi_scores.head(20)","f0f4a439":"mi_scores.tail(20)\n# utilities not dropped, it actually helps the score (a little ...)","1e4f4c49":"sns.lmplot(\n    x='GrLivArea', y=\"SalePrice\", hue=\"BldgType\", col=\"BldgType\",\n    data=DATA[DATA.Set == \"Train\"], scatter_kws={\"edgecolor\": 'w'}, col_wrap=5, height=4,\n);","a1a0007e":"X1 = pd.get_dummies(DATA.BldgType, prefix = 'Bldg')\nX1 = X1.mul(DATA.GrLivArea, axis=0)\nX1[X1.columns] = mm.fit_transform(X1[X1.columns])","df134dc2":"sns.lmplot(\n    x='GrLivArea', y=\"SalePrice\", hue=\"Neighborhood\", col=\"Neighborhood\",\n    data=DATA[DATA.Set == \"Train\"], scatter_kws={\"edgecolor\": 'w'}, col_wrap=6, height=3,\n);","9442b1aa":"X2 = pd.get_dummies(DATA.Neighborhood, prefix = 'NB')\nX2 = X2.mul(DATA.GrLivArea, axis=0)\nX2[X2.columns] = mm.fit_transform(X2[X2.columns])","652c0946":"sns.lmplot(\n    x='TotalBsmtSF', y=\"SalePrice\", hue=\"BsmtQual\", col=\"BsmtQual\",\n    data=DATA[DATA.Set == \"Train\"], scatter_kws={\"edgecolor\": 'w'}, col_wrap=5, height=4,\n);","d1900e8e":"X3 = pd.get_dummies(DATA.BsmtQual, prefix = 'BSQ')\nX3 = X3.mul(DATA.TotalBsmtSF, axis=0)\nX3[X3.columns] = mm.fit_transform(X3[X3.columns])","2bbce87e":"sns.lmplot(\n    x='GrLivArea', y=\"SalePrice\", hue='MSZoning', col='MSZoning',\n    data=DATA[DATA.Set == \"Train\"], scatter_kws={\"edgecolor\": 'w'}, col_wrap=5, height=4,\n);","1e597ee2":"#excluded\nX4 = pd.get_dummies(DATA.MSZoning, prefix = 'MSZ')\nX4 = X4.mul(DATA.GrLivArea, axis=0)\nX4[X4.columns] = mm.fit_transform(X4[X4.columns])","689f9d1a":"sns.lmplot(\n    x='GrLivArea', y=\"SalePrice\", hue='SaleCondition', col='SaleCondition',\n    data=DATA[DATA.Set == \"Train\"], scatter_kws={\"edgecolor\": 'w'}, col_wrap=6, height=4,\n);","b96ab478":"#exluded\nX5 = pd.get_dummies(DATA.SaleCondition, prefix = 'SaleCond')\nX5 = X5.mul(DATA.GrLivArea, axis=0)\nX5[X5.columns] = mm.fit_transform(X5[X5.columns])","edf4214e":"sns.lmplot(\n    x='Age', y=\"SalePrice\", hue='MSZoning', col='MSZoning',\n    data=DATA[DATA.Set == \"Train\"], scatter_kws={\"edgecolor\": 'w'}, col_wrap=6, height=4,\n);","e906d840":"#excluded\nX6 = pd.get_dummies(DATA.MSZoning, prefix = 'MSZ')\nX6 = X6.mul(DATA.Age, axis=0)\nX6[X6.columns] = mm.fit_transform(X6[X6.columns])","7de54f93":"sns.lmplot(\n    x='WOW', y=\"SalePrice\", hue='SaleCondition', col='SaleCondition',\n    data=DATA[DATA.Set == \"Train\"], scatter_kws={\"edgecolor\": 'w'}, col_wrap=6, height=4,\n);","a649e791":"#exluded\nX7 = pd.get_dummies(DATA.SaleCondition, prefix = 'SC2')\nX7 = X7.mul(DATA.WOW, axis=0)\nX7[X7.columns] = mm.fit_transform(X7[X7.columns])","92dfa20e":"sns.lmplot(\n    x='Age', y=\"SalePrice\", hue='MSSubClass', col='MSSubClass',\n    data=DATA[DATA.Set == \"Train\"], scatter_kws={\"edgecolor\": 'w'}, col_wrap=8, height=3,\n);","665999ba":"X8 = pd.get_dummies(DATA.MSSubClass, prefix = 'MSSC_AGE')\nX8 = X8.mul(DATA.Age, axis=0)\nX8[X8.columns] = mm.fit_transform(X8[X8.columns])","add87f2e":"sns.lmplot(\n    x='WOW', y=\"SalePrice\", hue='SaleType', col='SaleType',\n    data=DATA[DATA.Set == \"Train\"], scatter_kws={\"edgecolor\": 'w'}, col_wrap=6, height=4,\n);","5ac2d3de":"#excluded\nX9 = pd.get_dummies(DATA.SaleType, prefix = 'ST')\nX9 = X9.mul(DATA.WOW, axis=0)\nX9[X9.columns] = mm.fit_transform(X9[X9.columns])","5eb0a9df":"sns.lmplot(\n    x='GarageWow', y=\"SalePrice\", hue='GarageFinish', col='GarageFinish',\n    data=DATA[DATA.Set == \"Train\"], scatter_kws={\"edgecolor\": 'w'}, col_wrap=6, height=4,\n);","c0349d91":"X10 = pd.get_dummies(DATA.GarageFinish, prefix = 'GF')\nX10 = X10.mul(DATA.GarageWow, axis=0)\nX10[X10.columns] = mm.fit_transform(X10[X10.columns])","0b3cd266":"DATA['SaleTypeCat'] = DATA.SaleType\nDATA['SaleConditionCat'] = DATA.SaleCondition","c2aaa771":"encode_features = ['MSSubClass','SaleType','OverallCond','HouseStyle','GarageType', 'SaleCondition', \"FullBath\"]\n#encode_features = ['MSSubClass','SaleType','OverallCond','HouseStyle','GarageType', 'SaleCondition']\nX_encode = DATA[DATA.Set == 'Train'].sample(frac=0.2, random_state=13)\ny_encode = X_encode.pop(\"SalePrice\")","7a638f43":"encoder = MEstimateEncoder(cols=encode_features,m=1)\nencoder.fit(X_encode, y_encode)\nENC = encoder.transform(DATA.drop(\"SalePrice\", axis=1))\nDATA[encode_features] = ENC[encode_features]\nDATA[encode_features].head()","d280dd50":"drop_cols = ['LowQualFinSF','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea',\n             'MiscVal','MoSold','YrSold','1stFlrSF','2ndFlrSF' ,'BsmtUnfSF', 'YearBuilt','YearRemodAdd', 'BldgType','Neighborhood','BsmtQual','MiscFeature','Street', 'PoolQC',\n             'LandSlope','RoofMatl','LotConfig','RoofStyle','BsmtHalfBath','Functional','Heating','Grand_Total', \"Fresh\",'MSZ_Age','BsmtWow', 'Freshness','GarageFinish','TotalOverall',\n            'NewWOW','hasFireplace','hasPool']\n\nnumeric = sorted(['LotFrontage','MasVnrArea','BsmtFinSF','GrLivArea','GarageArea','Porch','Total_surface', 'Age','RemodAge','OverallQual', 'GarageCars','LotArea',\n           'ExterQual','HeatingQC','KitchenQual','FireplaceQu','GarageQual','GarageCond','Overall','External_Overall', 'LotArea_log',\n                  'TotRmsAbvGrd', \"Spaciousness\", 'BedroomAbvGr', 'Porch_types','WOW',\"MedNhbdArea\", 'TotalBsmtSF', 'Newness', 'SaleType','OverallCond','HouseStyle',\n                  'GarageType', 'SaleCondition','MSSubClass','GarageOverall','GarageWow','BsmtCond','BsmtFinSF1','BsmtFinSF2','TotalWow',\"FullBath\",\n                 'hasGarage','hasBsmt'])\n\ncategorical = sorted(['Alley','LotShape','LandContour','MasVnrType','Foundation','BsmtExposure','Electrical', 'BsmtFullBath','HalfBath',\n                'Fireplaces','KitchenAbvGr','PavedDrive','GarageAgeCat','Utilities','ExterCond', 'CentralAir', 'MSZoning','Fence',\n                     'SaleTypeCat','SaleConditionCat',\"New\"])","e664e3df":"DATA.drop(drop_cols, inplace = True, axis=1)\nDATA[categorical] = DATA[categorical].astype('category')\nDATA[numeric] = DATA[numeric].astype('float')","52d46d3e":"# remaining potential candidates for target encoding\nDATA.select_dtypes([\"category\"]).nunique().sort_values(ascending=False).head(10)","c4bd9352":"# %%time\n# def scatterplot(x,y,**kwargs):\n#     sns.scatterplot(x=x,y=y)\n#     _=plt.xticks(rotation=90)\n\n# f = pd.melt(DATA[(DATA.Set == \"Train\")].loc[worst], id_vars=['SalePrice'], value_vars=numeric)\n# g = sns.FacetGrid(f, col=\"variable\",  col_wrap=6, sharex=False, sharey=True, height=4)\n# g = g.map(scatterplot, \"value\", \"SalePrice\")","ee5e8c15":"%%time\ndef scatterplot(x,y,**kwargs):\n    sns.regplot(x=x,y=y)\n    _=plt.xticks(rotation=90)\n\nf = pd.melt(DATA[DATA.Set == \"Train\"], id_vars=['SalePrice'], value_vars=numeric)\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=5, sharex=False, sharey=True, height=5)\ng = g.map(scatterplot, \"value\", \"SalePrice\")","e92061bb":"DATA[numeric] = mm.fit_transform(DATA[numeric])","4d16d2fb":"# %%time\n# def boxplot(x,y,**kwargs):\n#     sns.boxplot(x=x,y=y)\n#     _=plt.xticks(rotation=90)\n\n# f = pd.melt(DATA[DATA.Set == \"Train\"].loc[worst], id_vars=['SalePrice'], value_vars=categorical)\n# g = sns.FacetGrid(f, col=\"variable\",  col_wrap=7, sharex=False, sharey=True, height=3)\n# g = g.map(boxplot, \"value\", \"SalePrice\")","a4a9ae65":"%%time\ndef boxplot(x,y,**kwargs):\n    sns.boxplot(x=x,y=y)\n    _=plt.xticks(rotation=90)\n\nf = pd.melt(DATA[DATA.Set == \"Train\"], id_vars=['SalePrice'], value_vars=categorical)\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=6, sharex=False, sharey=True, height=4)\ng = g.map(boxplot, \"value\", \"SalePrice\")","5992459f":"fig, ax = plt.subplots(figsize=(30,30))     \ng = sns.heatmap(DATA[DATA.Set == 'Train'][[*numeric,'SalePrice']].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")","2a2c77ce":"%%time\n#corr_features = sorted(['GrLivArea','GarageArea','RemodAge','TotalBsmtSF','Total_surface',\"Porch\",\"OverallQual\"])\ncorr_features = sorted(['GrLivArea','GarageArea','BsmtFinSF',\"Porch\"])\n#pca = PCA(0.90)\npca = PCA(3)\nX_PCA = pca.fit_transform(DATA.loc[:, corr_features])\ncomponent_names = [f\"PC{i+1}\" for i in range(X_PCA.shape[1])]\nX_PCA = pd.DataFrame(X_PCA, columns=component_names)\nX_PCA.head()","2a80b1d1":"pca.explained_variance_ratio_","6df963b5":"DATA_PCA = X_PCA.copy()\nDATA_PCA['SalePrice'] = DATA['SalePrice']\nDATA_PCA=DATA_PCA[DATA_PCA['SalePrice'] != -1]","eee4ad7f":"%%time\ndef scatterplot(x,y,**kwargs):\n    sns.regplot(x=x,y=y)\n    _=plt.xticks(rotation=90)\n\nf = pd.melt(DATA_PCA, id_vars=['SalePrice'], value_vars=component_names)\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=4, sharex=False, sharey=True, height=5)\ng = g.map(scatterplot, \"value\", \"SalePrice\")","7dbd0a38":"fig, axs = plt.subplots(1, 2)\nn = pca.n_components_\ngrid = np.arange(1, n + 1)\n# Explained variance\nevr = pca.explained_variance_ratio_\naxs[0].bar(grid, evr)\naxs[0].set(xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0))\n# Cumulative Variance\ncv = np.cumsum(evr)\naxs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\naxs[1].set(xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0))\n# Set up figure\nfig.set(figwidth=8, dpi=100);","0cdc4e81":"loadings = pd.DataFrame(\n        pca.components_.T,  # transpose the matrix of loadings\n        columns=component_names,  # so the columns are the principal components\n        index=DATA.loc[:, corr_features].columns,  # and the rows are the original features\n    )\nloadings","d39b449b":"cond = DATA[['Condition1','Condition2']]\ncondition_cats = [\"Condition_\"+s for s in set([*cond.Condition1.unique(), *cond.Condition2.unique()])]\nCOND_FRAME = pd.DataFrame(columns=condition_cats, index = DATA.index).fillna(0)\nfor i in cond.index:\n    cs = set(cond.loc[i, ['Condition1','Condition2']].values)\n    for c in cs:\n        COND_FRAME.loc[i][\"Condition_\"+c] = 1\n\n     \nDATA = DATA.join(COND_FRAME)\nDATA.drop(['Condition1','Condition2'], axis=1, inplace = True)","590d8f79":"%%time\ndef scatterplot(x,y,**kwargs):\n    sns.boxplot(x=x,y=y)\n    _=plt.xticks(rotation=90)\n\nf = pd.melt(DATA[DATA.Set == \"Train\"], id_vars=['SalePrice'], value_vars=DATA[DATA.Set == 'Train'][DATA.filter(like='Condition_').columns])\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=5, sharex=False, sharey=True, height=4)\ng = g.map(scatterplot, \"value\", \"SalePrice\")","474341bf":"ext = DATA[['Exterior1st','Exterior2nd']]\next_cats = [\"Ext_\"+s for s in set([*ext.Exterior1st.unique(), *ext.Exterior2nd.unique()])]\nEXT_FRAME = pd.DataFrame(columns=ext_cats, index = DATA.index).fillna(0)\nfor i in ext.index:\n    cs = set(ext.loc[i, ['Exterior1st','Exterior2nd']].values)\n    for c in cs:\n        EXT_FRAME.loc[i][\"Ext_\"+c] = 1\n\nEXT_FRAME = EXT_FRAME.mul(DATA.GrLivArea, axis=0)   \nDATA = DATA.join(EXT_FRAME)\nDATA.drop(['Exterior1st','Exterior2nd'], axis=1, inplace = True)","3bb2febe":"%%time\ndef scatterplot(x,y,**kwargs):\n    sns.regplot(x=x,y=y)\n    _=plt.xticks(rotation=90)\n\nf = pd.melt(DATA[DATA.Set == \"Train\"], id_vars=['SalePrice'], value_vars=DATA[DATA.Set == 'Train'][DATA.filter(like='Ext_').columns])\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=7, sharex=False, sharey=True, height=3)\ng = g.map(scatterplot, \"value\", \"SalePrice\")","0bafde4d":"mulCols = ['BsmtFinSF1','BsmtFinSF2']\nbf = DATA[['BsmtFinType1','BsmtFinType2']]\nbf_cats = [\"BF_\"+s for s in set([*bf.BsmtFinType1.unique(), *bf.BsmtFinType2.unique()])]\nBF_FRAME = pd.DataFrame(columns=bf_cats, index = DATA.index).fillna(0).astype(\"float\")\n\nfor i in bf.index:\n    cs = set(bf.loc[i, ['BsmtFinType1','BsmtFinType2']].values)\n    for j,c in enumerate(cs):\n        BF_FRAME.loc[i][\"BF_\"+c] =  DATA.loc[i][mulCols[j]]\n        #BF_FRAME.loc[i][\"BF_\"+c] =  1\n\nDATA = DATA.join(BF_FRAME)\nDATA.drop(['BsmtFinType1','BsmtFinType2','BsmtFinSF1','BsmtFinSF2'], axis=1, inplace = True)","1cf4e344":"%%time\ndef scatterplot(x,y,**kwargs):\n    #sns.boxplot(x=x,y=y)\n    sns.regplot(x=x,y=y)\n    _=plt.xticks(rotation=90)\n\nf = pd.melt(DATA[DATA.Set == \"Train\"], id_vars=['SalePrice'], value_vars=DATA[DATA.Set == 'Train'][DATA.filter(like=\"BF_\").columns])\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=7, sharex=False, sharey=True, height=3)\ng = g.map(scatterplot, \"value\", \"SalePrice\")","fd3d6faa":"DATA = pd.get_dummies(DATA,columns=categorical, drop_first=True)","23865745":"clustering_features = ['GrLivArea','Total_surface', 'LotArea_log', 'Overall','WOW',\"Spaciousness\",'Porch','BsmtFinSF','Age', 'RemodAge']\nkmeans = KMeans(n_clusters = 13, random_state=13)\nclust_data = DATA[DATA.Set == 'Train'].loc[:, clustering_features]\nclust_data['cluster'] = kmeans.fit_predict(clust_data)\nclust_data['cluster'] = clust_data['cluster'].astype('category')\nclust_data['SalePrice'] = DATA[DATA.Set == 'Train']['SalePrice']","f7d6a6b1":"sns.relplot(data = clust_data.melt(value_vars=clustering_features, id_vars = [\"SalePrice\", \"cluster\"]), x=\"value\", y=\"SalePrice\", hue='cluster', col= \"variable\", col_wrap=5, height=4);","3cd408e6":"clust_data = DATA.loc[:, clustering_features]\nX_CD = kmeans.fit_transform(clust_data)\nX_CD = mm.fit_transform(X_CD)\nX_CD = pd.DataFrame(X_CD, columns=[f\"Centroid_{i}\" for i in range(X_CD.shape[1])])","b71a4c43":"DATA = DATA.join([X1, X2, X3, X_CD, X8, X10])\nDATA.head()","cfddb9fc":"TRAIN = DATA[DATA.Set == 'Train']\nTEST = DATA[DATA.Set == 'Test']\nHouseIds = TEST.Id.to_list()\nTEST = TEST.drop(['Id','Set',\"SalePrice\",'index'], axis = 1)\ny = TRAIN.SalePrice\nX = TRAIN.drop(['SalePrice','Id','Set','index'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 13)","920f69ee":"print(\"Currently using {} feature columns\".format(len(TRAIN.columns)))","e7998b48":"# %%time\n# param_grid = {'n_estimators': [100, 200, 500],'max_depth': [4, 10, None], 'max_features':['auto','sqrt',0.9,0.75]}\n# rf_grid = GridSearchCV(RandomForestRegressor(random_state=13, n_jobs=-1), param_grid, cv=4)\n# rf_grid.fit(X, y)\n# print(rf_grid.best_estimator_)\n# print(rf_grid.best_params_)\n# rf_score = rf_grid.best_score_\n# print(rf_score) ","d50d9662":"%%time\n#best submission score\nRF_model = RandomForestRegressor(n_estimators=500, n_jobs=-1, random_state=13).fit(X_train,y_train)\n\n#best internal score\n#RF_model = RandomForestRegressor(max_features='sqrt', n_estimators=1000, n_jobs=-1,random_state=13).fit(X_train,y_train)","ea0e174f":"features = {}\nfor feature, importance in zip(X_train.columns, RF_model.feature_importances_):\n    features[feature] = importance\n\nimportances = pd.DataFrame({\"RF\":features})\nimportances.sort_values(\"RF\", ascending = False, inplace=True)\nimportances[:15].plot.bar();","176e2880":"# %%time\n# param_grid = {'alpha': [0.01,0.1, 1, 10, 100, 1000]}\n# ridge_grid = GridSearchCV(Ridge(random_state=13), param_grid, cv=4)\n# ridge_grid.fit(X, y)\n# print(ridge_grid.best_estimator_)\n# print(ridge_grid.best_params_)\n# ridge_score = ridge_grid.best_score_\n# print(ridge_score) ","a60c91f2":"%%time\nridge_model = Ridge(alpha=10, random_state=13).fit(X_train,y_train)","140efdca":"# %%time\n# param_grid = {'alpha': [1, 10, 100, 200, 1000]}\n# lasso_grid = GridSearchCV(Lasso(random_state=13, max_iter = 10000, fit_intercept = False), param_grid, cv=4)\n# lasso_grid.fit(X, y)\n# print(lasso_grid.best_estimator_)\n# print(lasso_grid.best_params_)\n# lasso_score = lasso_grid.best_score_\n# print(lasso_score) ","8003ceb0":"%%time\nlasso_model = Lasso(alpha=100, max_iter=10000, random_state=13).fit(X_train,y_train)","7d9d5405":"# %%time\n# param_grid = {'alpha': [0.05,0.1,0.5, 1],'l1_ratio':[0.1,0.25, 0.5, 0.75,0.9]}\n# elastic_grid = GridSearchCV(ElasticNet(random_state=13, max_iter = 10000), param_grid, cv=4)\n# elastic_grid.fit(X, y)\n# print(elastic_grid.best_estimator_)\n# print(elastic_grid.best_params_)\n# elastic_score = elastic_grid.best_score_\n# print(elastic_score) ","3563a136":"%%time\nelastic_model= ElasticNet(alpha=0.05, l1_ratio=0.75, max_iter=10000, random_state=13).fit(X_train,y_train)","533b023a":"# %%time\n# #gbm_param_grid = {'learning_rate': [0.01,0.1,0.5],'n_estimators': [500, 750],'subsample': [0.75, 0.8, 0.9],'reg_alpha':[0.001, 0.01], 'reg_lambda':[0.1,1,10]}\n# gbm_param_grid = {'learning_rate': [0.1],'n_estimators': [750, 1000],'subsample': [0.8, 0.9],'reg_alpha':[0.001, 0.01], 'reg_lambda':[0.1,1,10], 'max_depth': [4,6,8]}\n# grid_xgb = GridSearchCV(xgb.XGBRegressor(seed = 13), gbm_param_grid,cv=4, scoring='neg_mean_squared_error', verbose = 1)\n# grid_xgb.fit(X, y)\n# print(grid_xgb.best_estimator_)\n# print(grid_xgb.best_params_)\n# xgb_score = grid_xgb.best_score_\n# print(xgb_score) ","29a814ef":"%%time\nxg_model = xgb.XGBRegressor(objective = 'reg:squarederror', n_estimators = 500, seed = 13, subsample = 0.8, learning_rate = 0.1, reg_alpha=0.01, reg_lambda = 10).fit(X_train,y_train)","8bd4216b":"feature_imporances = xg_model.get_booster().get_score(importance_type='weight')\nimportances = pd.DataFrame({\"XGB\":feature_imporances.values()}, index = feature_imporances.keys())\nimportances.sort_values(\"XGB\", ascending = False, inplace=True)\nimportances[:15].plot.bar();","d8e186f1":"# %%time\n# ada_param_grid = {'learning_rate': [0.5, 1],'n_estimators': [500, 750], 'base_estimator__max_depth':[4, 8,  None], 'base_estimator__max_features':['auto','sqrt',0.8] }\n# grid_ada = GridSearchCV(AdaBoostRegressor(random_state = 13, base_estimator=DecisionTreeRegressor()), ada_param_grid, cv=4)\n# grid_ada.fit(X, y)\n# print(grid_ada.best_estimator_)\n# print(grid_ada.best_params_)\n# ada_score = grid_ada.best_score_\n# print(ada_score) ","6cb678be":"%%time\n\n#original\n#ada_model = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=20),learning_rate=1, n_estimators=500, random_state=13).fit(X_train,y_train)\n\n#best\nada_model = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_features='sqrt'),learning_rate=1, n_estimators=500, random_state=13).fit(X_train,y_train)","bb2e96b0":"features = {}\nfor feature, importance in zip(X_train.columns, ada_model.feature_importances_):\n    features[feature] = importance\n\nimportances = pd.DataFrame({\"ADA\":features})\nimportances.sort_values(\"ADA\", ascending = False, inplace=True)\nimportances[:15].plot.bar();","d24a2596":"# %%time\n# param_grid = {'n_estimators': [500, 750], 'max_depth': [10,20, None], 'bootstrap': [False, True], 'max_samples': [0.8, 0.9, 1], 'max_features':['auto',0.9, 0.8, 0.75]}\n# grid_ET = GridSearchCV(ExtraTreesRegressor(random_state = 13, n_jobs=-1), param_grid, cv=4)\n# grid_ET.fit(X, y)\n# print(grid_ET.best_estimator_)\n# print(grid_ET.best_params_)\n# ET_score = grid_ET.best_score_\n# print(ET_score) ","ceb6c8cf":"%%time\nET_model = ExtraTreesRegressor(max_samples=0.8, n_estimators=500, random_state=13, n_jobs=-1).fit(X_train,y_train)","e5dc409f":"features = {}\nfor feature, importance in zip(X_train.columns, ET_model.feature_importances_):\n    features[feature] = importance\n\nimportances = pd.DataFrame({\"ET\":features})\nimportances.sort_values(\"ET\", ascending = False, inplace=True)\nimportances[:20].plot.bar();","4f04dc2e":"# %%time\n# #param_grid = {'n_estimators': [2000, 3000], 'max_depth': [4, 10, None], 'min_samples_leaf': [5,15], 'min_samples_split': [5, 10],'learning_rate': [0.05, 0.1]}\n# #param_grid = {'n_estimators': [3000], 'max_depth': [4,10],'learning_rate': [0.05], 'max_features':['auto','sqrt',0.9, 0.8, 0.75]}\n# param_grid = {'n_estimators': [3000], 'max_depth': [4,10],'learning_rate': [0.05], 'max_features':['auto','sqrt', 0.8]}\n# #grid_GB = GridSearchCV(GradientBoostingRegressor(random_state = 13, loss='huber',  max_features='sqrt'), param_grid, cv=3)\n# grid_GB = GridSearchCV(GradientBoostingRegressor(random_state = 13, loss='huber'), param_grid, cv=3)\n# grid_GB.fit(X, y)\n# print(grid_GB.best_estimator_)\n# print(grid_GB.best_params_)\n# GB_score = grid_GB.best_score_\n# print(GB_score) ","315bf038":"%%time\nGBoost_model = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', \n                                         random_state =13).fit(X_train,y_train)","edbb4421":"features = {}\nfor feature, importance in zip(X_train.columns, GBoost_model.feature_importances_):\n    features[feature] = importance\n\nimportances = pd.DataFrame({\"GBoost\":features})\nimportances.sort_values(\"GBoost\", ascending = False, inplace=True)\nimportances[:20].plot.bar();","7ad943fc":"%%time\nnp.random.seed(13)\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5, learning_rate=0.05, n_estimators=720, max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319, feature_fraction_seed=9, bagging_seed=9,min_data_in_leaf =6, \n                              min_sum_hessian_in_leaf = 11).fit(X_train,y_train)","01537def":"features = {}\nfor feature, importance in zip(X_train.columns, model_lgb.feature_importances_):\n    features[feature] = importance\n\nimportances = pd.DataFrame({\"LGBM\":features})\nimportances.sort_values(\"LGBM\", ascending = False, inplace=True)\nimportances[:20].plot.bar();","7be3980e":"# %%time\n# param_grid = {'kernel': ['linear', 'polynomial'], 'degree': [1,2,3], 'alpha':[0.1,0.5, 0.9, 1],'coef0': [1,2,2.5]}\n#param_grid = {'alpha': np.linspace(0, 1, 20), 'kernel': ['polynomial'], 'degree': [1, 2], 'coef0':np.linspace(0, 3.5,21)}\n# grid_KRR = GridSearchCV(KernelRidge(coef0=2.5), param_grid, cv=4)\n# grid_KRR.fit(X, y)\n# print(grid_KRR.best_estimator_)\n# print(grid_KRR.best_params_)\n# KRR_score = grid_KRR.best_score_\n# print(KRR_score) ","6ac90fbc":"%%time\n#original\nKRR_model = KernelRidge(alpha=0.1, degree=1, kernel='polynomial').fit(X_train,y_train)\n\n#retune\n#KRR_model = KernelRidge(alpha=0.10526315789473684, coef0=0.0, degree=1, kernel='polynomial').fit(X_train,y_train)","af79a935":"# %%time\n# param_grid = {'kernel': ['linear'],  'C':[1000, 10**4, 10**5], 'gamma': ['scale']}\n# grid_SVR = GridSearchCV(SVR(), param_grid, cv=4)\n# grid_SVR.fit(X, y)\n# print(grid_SVR.best_estimator_)\n# print(grid_SVR.best_params_)\n# SVR_score = grid_SVR.best_score_\n# print(SVR_score) ","f1a44dcd":"# %%time\n# SVR_model = SVR(C=1000, kernel='linear').fit(X_train,y_train)","aebac812":"#10 models (no SVR)\nmodels = [RF_model, ridge_model, elastic_model, xg_model, ada_model,ET_model, GBoost_model, model_lgb, KRR_model, lasso_model]\nmodel_names = [\"RF\", 'Ridge', \"Elastic\", \"XGB\", \"ADA\", \"ET\", \"GBoost\", \"LGBM\", \"KRR\", \"Lasso\"]\n\n#9 models (no SVR, Lasso)\n# models = [RF_model, ridge_model, elastic_model, xg_model, ada_model,ET_model, GBoost_model, model_lgb, KRR_model]\n# model_names = [\"RF\", 'Ridge', \"Elastic\", \"XGB\", \"ADA\", \"ET\", \"GBoost\", \"LGBM\", \"KRR\"]","ec26dd95":"%%time\nscoreList = []\nfor i, m in enumerate(models):\n    score = [model_names[i]]\n    score.append(m.score(X_train,y_train))\n    score.append(m.score(X_test,y_test))\n    score.append(np.sqrt(mean_squared_error(np.log(y_train),np.log(m.predict(X_train)))))\n    score.append(np.sqrt(mean_squared_error(np.log(y_test),np.log(m.predict(X_test)))))\n    scoreList.append(score)\n\nSCORES = pd.DataFrame(scoreList, columns = ['model', 'train_score', 'test_score', 'train_RMSE', 'test_RMSE'])\nSCORES['overfit'] = SCORES.test_RMSE - SCORES.train_RMSE\nSCORES.sort_values(['test_RMSE'], ascending = True, inplace = True)\nSCORES.reset_index(drop=True, inplace=True)\nSCORES","6e084499":"sns.barplot(data = SCORES, x=\"model\", y=\"test_RMSE\");","206ca414":"%%time\n\nN_cols = 3\ncol_width = 8\nN_rows = round(len(models) \/ N_cols + 0.49)\nfig, axs = plt.subplots(nrows = N_rows, ncols=N_cols, figsize=(col_width * N_cols, N_rows * col_width))\n\nfor i in range(len(models)):\n    axs[i\/\/N_cols, i%N_cols].scatter(models[i].predict(X), y, alpha = 0.8, color=\"b\", label = \"X\")\n    axs[i\/\/N_cols, i%N_cols].scatter(models[i].predict(X_test), y_test, alpha = 0.3, color=\"g\", label = \"X_test\")\n    axs[i\/\/N_cols, i%N_cols].set_title(model_names[i])\n    axs[i\/\/N_cols, i%N_cols].legend();","bf4b475c":"train_dict = {\"Id\": TRAIN.Id}\nfor i, m in enumerate(models):\n    train_dict[model_names[i]] = m.predict(X)\n\nALL_TRAIN = pd.DataFrame(train_dict)\nALL_TRAIN['Voting'] = ALL_TRAIN[model_names].mean(axis=1)\nALL_TRAIN['True'] = y\nALL_TRAIN['DIFF'] = ALL_TRAIN['True'] - ALL_TRAIN.Voting\n\nALL_TRAIN.head(10)","6d6a8bae":"checkN = 20\nALL_TRAIN.loc[np.abs(ALL_TRAIN.DIFF).nlargest(checkN).index]","0462ecac":"#print(np.abs(ALL_TRAIN.DIFF).nlargest(checkN).index)\n# X.loc[np.abs(ALL_TRAIN.DIFF).nlargest(checkN).index]","742107d3":"print(\"Voting RMSE:\", np.sqrt(mean_squared_error(np.log(y),np.log(ALL_TRAIN['Voting']))))","5690a367":"plt.scatter(ALL_TRAIN['Voting'], y, alpha = 0.8, color='b', label = 'Voting');\nplt.title(\"Voting\")\nplt.legend()\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show();","6844c586":"colors = [\"red\", 'blue', \"yellow\", \"aquamarine\", \"coral\", \"magenta\", \"gold\", \"hotpink\", \"teal\", \"aqua\", \"peru\"]\ncolors = colors[:len(models)]\ncolors.append('lawngreen') #Voting\ncolors.append('black') #True","e3a5555c":"disp = 80\nfig, ax = plt.subplots(figsize=(30,10))  \nfor i, col in enumerate(ALL_TRAIN.columns[1:-1].tolist()):\n    plt.scatter(x = ALL_TRAIN[:disp].Id, y= ALL_TRAIN[:disp][col], alpha=0.8, c = colors[i], edgecolors= \"white\", s=80)\n    plt.legend(ALL_TRAIN.columns[1:].tolist())\n\nplt.show()","e0caf3a3":"test_dict = {\"Id\": HouseIds}\nfor i, m in enumerate(models):\n    test_dict[model_names[i]] = m.predict(TEST)\n\nALL = pd.DataFrame(test_dict)\nALL['Voting'] = ALL[model_names].mean(axis=1)\nALL.head(10)","c9fcac12":"disp = 150\nfig, ax = plt.subplots(figsize=(30,10))  \nfor i, col in enumerate(ALL.columns[1:].tolist()):\n    plt.scatter(x = ALL[:disp].Id, y= ALL[:disp][col], alpha=0.8, c = colors[i], edgecolors= \"white\", s=80)\n    plt.legend(ALL.columns[1:].tolist())\n\nplt.show()","ca7afb3b":"output = pd.DataFrame({\"Id\": HouseIds, \"SalePrice\": ALL['Voting']})\noutput.head(10)","b35178c0":"output.to_csv('submission.csv', index=False)\nprint(\"Submission was successfully saved!\")","90234eea":"end_time = time.time()\nprint(\"Notebook run time: {:.1f} seconds. Finished at {}\".format(end_time - start_time, datetime.now()) )","979a6256":"## Mutual information","a0aee883":"## Fill NA","e8f1aa91":"# Data","bdca330c":"## XGBoost","848e68f0":"## Scores","4266a51d":"## Split","cde4e6d9":"## Feature Eng","7ff59da8":"## Predict","e0e4dee8":"### Condition1,2","03e02491":"# Models\n","098b7f41":"### Worst fit","da50a396":"## ElasticNet","78578569":"## Ridge","b9ab7861":"### BsmtFinType1,BsmtFinType2","ade879a4":"## Random Forest","4123ba55":"### Exterior1st, Exterior2nd","50d04e64":"# House Prices\n\nfinal model, voting regressor, equal weights <br>","9d74a3b4":"### All","e5f96da3":"### Observe TEST predictions","5fd51ea7":"## Numeric","e59632e5":"### All","f97ee2f1":"## GradientBoostingRegressor","503109a1":"## Join interaction features","4ba43377":"## Extra Trees","7bce016b":"## LGBM","bb0e940f":"## Interactions from MI (Feature encoding)","22453efb":"## Lasso","8833b630":"## Clustering","059e5476":"## KRR\n","42421f38":"## Drop & Classify","578fc58d":"## SVR","389493f7":"## Categorical to dummies","f0aab251":"### Worst fit","abec6970":"## Joining 'double categories' and converting to dummies","d9a070d7":"## Observe TRAIN predictions ","19bd58e1":"## Missing data","fa6d9183":"## Drop Outliers","f3421055":"## Target encoding","fd6697c9":"## PCA","15b3c294":"## Correlations","da876370":"## Categorical","793cb3a0":"## ADA Boost","0efac6df":"### 'Existentitial'"}}