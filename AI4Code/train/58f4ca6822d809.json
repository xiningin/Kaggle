{"cell_type":{"6a732f86":"code","f5b708bc":"code","6b4ca4be":"code","ad5fed7e":"code","78f2e971":"code","7e29bfd1":"code","6f355388":"code","2bb25329":"code","4079164d":"code","96d30287":"code","e5b50b8c":"code","548bccb6":"code","5da134f2":"code","7e913c6c":"code","daa06aba":"code","9ad55838":"markdown","c1719ee6":"markdown","03801469":"markdown","feda186b":"markdown","4fa8f094":"markdown","cd16dc2a":"markdown","53c2d3a8":"markdown","0d3dc3be":"markdown","e258245b":"markdown","04fb052b":"markdown","fd1cbc03":"markdown"},"source":{"6a732f86":"import pandas as pd\n\npd.set_option('display.max_columns', 100) # Setting pandas to display a N number of columns\npd.set_option('display.max_rows', 10) # Setting pandas to display a N number rows\npd.set_option('display.width', 1000) # Setting pandas dataframe display width to N\n\n#plotting library\nimport matplotlib.pyplot as plt\nimport seaborn as sns             \n\n# interactive plotting library\nimport plotly.express as px       \nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly.offline import iplot\nfrom plotly.subplots import make_subplots\n\nimport pandas_profiling # library for automatic EDA\n%pip install autoviz # installing and importing autoviz, another library for automatic data visualization\nfrom autoviz.AutoViz_Class import AutoViz_Class\n\nfrom IPython.display import HTML\nfrom IPython.display import display # display from IPython.display\n\nimport os","f5b708bc":"from scipy import stats # statistical library\nfrom statsmodels.stats.weightstats import ztest # statistical library for hypothesis testing\nfrom itertools import cycle # function used for cycling over values\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(\"\")\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6b4ca4be":"home = '..\/input\/police-violence-in-the-us'\ntry:\n    deaths_arrests_race = pd.read_csv(os.path.join(home, 'deaths_arrests_race.csv'))\n    dod_equipment_purchases = pd.read_csv(os.path.join(home, 'dod_equipment_purchases.csv'))\n    fatal_encounters_dot_org = pd.read_csv(os.path.join(home, 'fatal_encounters_dot_org.csv'))\n    po_contracts = pd.read_csv(os.path.join(home, 'police_contracts.csv'))\n    po_deaths_538 = pd.read_csv(os.path.join(home, 'police_deaths_538.csv'))\n    po_employment_fbi = pd.read_csv(os.path.join(home, 'police_employment_fbi.csv'))\n    po_killings = pd.read_csv(os.path.join(home, 'police_killings.csv'))\n    po_policies = pd.read_csv(os.path.join(home, 'police_policies.csv'))\n    shootings_wash_post = pd.read_csv(os.path.join(home, 'shootings_wash_post.csv'))\nexcept:\n    print('File names have changed!')","ad5fed7e":"datasets = {\"deaths_arrests_race\": deaths_arrests_race,\n            \"dod_equipment_purchases\" : dod_equipment_purchases,\n            \"fatal_encounters_dot_org\": fatal_encounters_dot_org,\n            \"po_contracts\": po_contracts,\n            \"po_deaths_538\": po_deaths_538,\n            \"po_employment_fbi\": po_employment_fbi,\n            \"po_killings\": po_killings,\n            \"po_policies\": po_policies,\n            \"shootings_wash_post\": shootings_wash_post}","78f2e971":"keys_datasets = []\nfor key, value in datasets.items():  #accessing keys\n    #print(key,end=',')\n    keys_datasets.append(key)\n    \nprint(keys_datasets)","7e29bfd1":"for key, value in datasets.items():\n    display(\"Dataset name: %s\" % key)\n    display(value.head(5),\n            value.shape,\n            value.info(),\n            value.describe(include = \"all\"),\n            value.columns,\n            #value.value_counts(),\n            value.nunique())\n    ","6f355388":"# Installing and loading the library\n!pip install dabl\n\nimport dabl","2bb25329":"shootings_wash_post_clean = dabl.clean(shootings_wash_post, verbose=1)\n\ntypes = dabl.detect_types(shootings_wash_post)\nprint(types) ","4079164d":"dabl.plot(shootings_wash_post, target_col=\"manner_of_death\")","96d30287":"report = pandas_profiling.ProfileReport(shootings_wash_post)","e5b50b8c":"# Let's now visualize the report generated by pandas_profiling.\ndisplay(report)\n\n# Also, there is an option to generate an .HTML file containing all the information generated by the report.\n# report.to_file(output_file='report.html')","548bccb6":"import numpy as np\nimport pandas as pd\nfrom pandas_profiling import ProfileReport\n\ndf = pd.DataFrame(\n    np.random.rand(100, 5),\n    columns=[\"a\", \"b\", \"c\", \"d\", \"e\"]\n)\n#To generate the report, run:\n\nprofile = ProfileReport(df, title=\"Pandas Profiling Report\")\n\nprofile = ProfileReport(df, title='Pandas Profiling Report', explorative=True)","5da134f2":"''' Another great library for automatic EDA is AutoViz.\nWith this library, several plots are generated with only 1 line of code.\nWhen combined with pandas_profiling, we obtain lots of information in a\nmatter of seconds, using less then 5 lines of code. '''\n\nAV = AutoViz_Class()\n\n# Let's now visualize the plots generated by AutoViz.\nreport_2 = AV.AutoViz(os.path.join(home, 'shootings_wash_post.csv'))","7e913c6c":"# First distribution for the hypothesis test: Ages of survivors\ndist_a = df_survivors['Age'].dropna()\n\n# Second distribution for the hypothesis test: Ages of non-survivors\ndist_b = df_nonsurvivors['Age'].dropna()","daa06aba":"# Z-test: Checking if the distribution means (ages of survivors vs ages of non-survivors) are statistically different\nt_stat, p_value = ztest(dist_a, dist_b)\nprint(\"----- Z Test Results -----\")\nprint(\"T stat. = \" + str(t_stat))\nprint(\"P value = \" + str(p_value)) # P-value is less than 0.05\n\nprint(\"\")\n\n# T-test: Checking if the distribution means (ages of survivors vs ages of non-survivors) are statistically different\nt_stat_2, p_value_2 = stats.ttest_ind(dist_a, dist_b)\nprint(\"----- T Test Results -----\")\nprint(\"T stat. = \" + str(t_stat_2))\nprint(\"P value = \" + str(p_value_2)) # P-value is less than 0.05","9ad55838":"> ## Exploratory Data analysis with AutoViz\n**AutoViz**\n\n","c1719ee6":"## First look at all datasets","03801469":"# Section 0 - Getting the data","feda186b":"Checking out the plots and hypothesis tests over fare distributions, comparing Survivors and non-Survivors, we can again observe that there is a statistically significant difference between the means of both groups.\n\nWhen checking out the boxplots, we can see that fare values of survivors are generally higher, when compared to fare values of non-survivors. This information is probably related to the \"Pclass\" percentages we have seen before on the pie plots","4fa8f094":"## Exploratory Data analysis with dabl\ndabl provides a high-level interface that summarizes several common high-level plots. For low dimensional datasets, all features are shown; for high dimensional datasets, only the most informative features for the given task are shown","cd16dc2a":"To begin our analysis, lets take our first look at the dataset. \n\nTo save some precious time on our Exploratory Data Analysis process, we are going to use 2 libraries: \"pandas_profiling\" and \"autoviz\".","53c2d3a8":"## Exploratory Data analysis with pandas profiling\n**pandas_profiling**\n\nThe pandas profiling library is really useful on helping us understand the data we're working on.\nIt saves us some precious time on the EDA process.","0d3dc3be":"## Seaborn","e258245b":"## Automated Preprocessing with dabl\nAs part of the preprocessing, dabl will attempt to identify missing values, feature types and erroneous data. if the detection of semantic types (continuous, categorical, ordinal, text, etc) fails, the user can provide type_hints. Let's demo the library with the help of the titanic dataset","04fb052b":"# US Police Violence & Racial Equity\n**Data from a variety of sources to support analysis promoting fair treatment**\n\nThe aim of this notebook is to use some tools to speed up the process of the exploratory data analysis.\nWe have plenty of different datasets and i will have a first look at what we got here.","fd1cbc03":"# Section 1 - Data Exploration"}}