{"cell_type":{"af82745d":"code","d27a5afb":"code","36532fb8":"code","82c7053a":"code","b64e048e":"code","aecc0215":"code","189ed528":"code","e263c1c6":"code","b1d583cf":"code","a9a31b2f":"code","f01f1f07":"code","e4180f17":"code","e91cfa2a":"code","a00c2105":"code","9bbbb037":"code","4aa3cbda":"code","c76b15f5":"code","10fcf5de":"code","7325809a":"code","6911bd38":"code","6e873b46":"code","948d3b8f":"code","1273abc5":"code","ac4febb3":"code","ff298c3d":"code","4b436499":"code","9b1dcc0a":"code","400afce9":"code","ab524735":"code","39b53761":"code","a1ed17c1":"code","ce8db077":"code","16b4f2c7":"code","603b1401":"markdown","f13e397c":"markdown","8b195ae7":"markdown","20f09588":"markdown"},"source":{"af82745d":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nimport seaborn  as sb","d27a5afb":"%matplotlib inline\nrcParams['figure.figsize']=7,5\nplt.style.use('seaborn-whitegrid')","36532fb8":"data = pd.read_csv('..\/input\/loan-prediction.csv') \ndata.head() #overview of our dataset\n","82c7053a":"data.info()","b64e048e":"data.isnull().sum()\n\n","aecc0215":"data.describe()","189ed528":"sb.distplot(data['ApplicantIncome'])","e263c1c6":"sb.distplot(data[data['ApplicantIncome']<22000]['ApplicantIncome'])","b1d583cf":"data[data['ApplicantIncome']<22000]['ApplicantIncome'].describe()","a9a31b2f":"# std decreased nearly half.So,here we are assuming that 8 values are outliers.\ndata[data['ApplicantIncome']>=22000]['ApplicantIncome'].index","f01f1f07":"data=data.drop([126, 155, 171, 183, 185, 333, 409, 443],axis=0)","e4180f17":"sb.distplot(data['CoapplicantIncome'])","e91cfa2a":"sb.distplot(data[data['CoapplicantIncome']<12000]['CoapplicantIncome'])","a00c2105":"data[data['CoapplicantIncome']<12000]['CoapplicantIncome'].describe()","9bbbb037":"data[data['CoapplicantIncome']>=12000]['CoapplicantIncome'].index","4aa3cbda":"data=data.drop([402, 417, 581, 600],axis=0)","c76b15f5":"data.boxplot(column = 'LoanAmount',showmeans=True)","10fcf5de":"rcParams['figure.figsize']=7,5\n\nplt.subplot(1,2,1)\ndata['modified_LoanAmount']=data['LoanAmount'].fillna(data['LoanAmount'].mean() )\ndata.boxplot(column='modified_LoanAmount',showmeans=True)\nplt.title('Filled with mean')\n\nplt.subplot(1,2,2)\ndata['modified_LoanAmount']=data['LoanAmount'].fillna(data['LoanAmount'].median() )\ndata.boxplot(column='modified_LoanAmount',showmeans=True)\nplt.title('Filled with Median')\n","7325809a":"#we are filling with median.\ndata['LoanAmount']=data['LoanAmount'].fillna(data['LoanAmount'].mean() )\ndata.drop(['modified_LoanAmount'],axis=1,inplace=True)\nsb.distplot(data['LoanAmount'])","6911bd38":"## After data visualization,most of velues are arround 360(median) so, median will be better for missing velues.\ndata['Loan_Amount_Term']=data['Loan_Amount_Term'].fillna(data['Loan_Amount_Term'].median() )\nsb.distplot(data['Loan_Amount_Term'])","6e873b46":"#and also for credit history median fits best.\ndata['Credit_History']=data['Credit_History'].fillna(data['Credit_History'].median() )\nsb.distplot(data['Credit_History'])","948d3b8f":"#For all categorical variables,we are using Mode to remove our Nan from Dataset\n\ndata['Gender']=data['Gender'].fillna(data['Gender'].mode()[0])\ndata['Married']=data['Married'].fillna(data['Married'].mode()[0])\ndata['Dependents']=data['Dependents'].fillna(data['Dependents'].mode()[0])\ndata['Self_Employed']=data['Self_Employed'].fillna(data['Self_Employed'].mode()[0])","1273abc5":"data.isnull().sum()","ac4febb3":"sb.countplot(x='Gender',data=data,hue='Loan_Status')","ff298c3d":"sb.countplot(x='Dependents',data=data,hue='Loan_Status')","4b436499":"sb.countplot(x='Education',data=data,hue='Loan_Status')\n","9b1dcc0a":"sb.countplot(x='Married',data=data,hue='Loan_Status')","400afce9":"data = pd.get_dummies(data, columns = ['Gender','Married','Dependents','Education','Self_Employed','Credit_History','Property_Area','Loan_Status'],drop_first = True)\ndata.head()","ab524735":"import sklearn\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.ensemble import RandomForestClassifier","39b53761":"Y=data['Loan_Status_Y']\nX=data.drop(columns=['Loan_Status_Y','Loan_ID'])\n# split the train and test dataset where test set is 30% of dataset\nxtrain,xtest,ytrain,ytest = train_test_split(X,Y,test_size=0.3) ","a1ed17c1":"model= RandomForestClassifier(max_depth=5) \nmodel=model.fit(xtrain,ytrain) ","ce8db077":"model.score(xtest,ytest)","16b4f2c7":"from sklearn.metrics import confusion_matrix\n\nypred=model.predict(xtest)\n\nconfusion_matrix(ytest,ypred)","603b1401":"**filling missing values in LoanAmount**","f13e397c":"**Filling missing values in LoanAmount_term**","8b195ae7":"**Checking distribution and outlier**","20f09588":"**Treating Categorical Columns**"}}