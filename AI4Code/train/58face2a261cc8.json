{"cell_type":{"d03deef5":"code","a6f8ef31":"code","8054c12c":"code","3271b7c2":"code","b62483d6":"code","fa537100":"code","a1775b8d":"code","8e7bbe08":"code","b609671a":"code","a95d1b3e":"code","219e02eb":"code","12f45885":"code","ded32eaf":"code","386dd76b":"code","3d42adfe":"code","d034b6cb":"code","0682f70e":"code","15d87ea2":"code","46050e7d":"code","9d5dcb6a":"code","1a9720f3":"code","9f44b30e":"code","184fc15e":"code","3f64fefc":"code","2cc6717f":"code","c653fdd0":"code","59c3779e":"code","63674f04":"code","75097d25":"code","ce01a905":"code","37fa062a":"code","136a9c95":"code","14b2202a":"code","3692c440":"code","56fa588d":"code","36308b91":"code","97f64bf6":"code","dd817f6b":"code","e023e942":"code","8429fa16":"code","b0decede":"code","128062a6":"code","33c44441":"code","61c16db4":"code","a5fddbb4":"code","7f7e14ff":"code","9714a4b4":"code","13ce10ac":"code","00c2c116":"code","87aa0ee6":"code","907fc4ee":"code","dd9a9421":"code","5c227933":"code","bfa9ced7":"markdown","89f8ccad":"markdown","8a939327":"markdown","7b2ecc70":"markdown","eb9bbb11":"markdown","7a7b3019":"markdown","ea326f29":"markdown","13a2bc45":"markdown","fe4ebb67":"markdown","5647a3dc":"markdown","2ba1ed0a":"markdown","88299a28":"markdown","b259d323":"markdown","41d77ab5":"markdown","44bef546":"markdown","deea8c1a":"markdown","45966365":"markdown","e425cb6a":"markdown","9cf14082":"markdown","83d00c50":"markdown","98889b54":"markdown","7b7ae635":"markdown","6a218908":"markdown","5888b6d1":"markdown","13fa918f":"markdown","8dfa7c6f":"markdown","3f438f5a":"markdown","b652f81d":"markdown","5b04d280":"markdown","d28394e3":"markdown","22865998":"markdown","cd77ddd2":"markdown","7ec2b353":"markdown","00d9dd12":"markdown","3d6045e7":"markdown","bc4dbe55":"markdown","15ceec2e":"markdown","90ed80e1":"markdown","6dc90f14":"markdown","bb6f2a83":"markdown","23aeb899":"markdown"},"source":{"d03deef5":"import numpy  as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#\u5c06\u56fe\u8868\u5d4c\u5165\u5230notebook\u4e2d\n%matplotlib inline   ","a6f8ef31":"import os\nprint(os.listdir('\/kaggle\/input\/ashrae-energy-prediction\/'))","8054c12c":"%%time\nroot='\/kaggle\/input\/ashrae-energy-prediction\/'\ntrain_df=pd.read_csv(root+'train.csv')\n#\u8f6c\u6362\u65e5\u671f\u683c\u5f0f\uff0c\u65b9\u4fbf\u4ee5\u540e\u7684\u5904\u7406\ntrain_df[\"timestamp\"] = pd.to_datetime(train_df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\nweather_train_df = pd.read_csv(root + 'weather_train.csv')\nweather_test_df = pd.read_csv(root + 'weather_test.csv')\n\nweather_train_df[\"timestamp\"] = pd.to_datetime(weather_train_df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\nweather_test_df[\"timestamp\"] = pd.to_datetime(weather_test_df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n\nbuilding_meta_df = pd.read_csv(root + 'building_metadata.csv')\n\ntest_df = pd.read_csv(root + 'test.csv')\ntest_df[\"timestamp\"] = pd.to_datetime(test_df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n\nsample_submission = pd.read_csv(root + 'sample_submission.csv')","3271b7c2":"print('Size of train_df data', train_df.shape)\nprint('Size of weather_train_df data', weather_train_df.shape)\nprint('Size of weather_test_df data', weather_test_df.shape)\nprint('Size of building_meta_df data', building_meta_df.shape)\nprint('Size of test_df data', test_df.shape)\nprint('Size of sample_submission data', sample_submission.shape)","b62483d6":"train_df.head()","fa537100":"weather_train_df.head()","a1775b8d":"weather_test_df.head()","8e7bbe08":"building_meta_df.head()","b609671a":"test_df.head()","a95d1b3e":"sample_submission.head()","219e02eb":"## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","12f45885":"train_df = reduce_mem_usage(train_df)\ntest_df = reduce_mem_usage(test_df)\n\nweather_train_df = reduce_mem_usage(weather_train_df)\nweather_test_df = reduce_mem_usage(weather_test_df)\nbuilding_meta_df = reduce_mem_usage(building_meta_df)","ded32eaf":"plt.figure(figsize=(15,5))\ntrain_df['meter_reading'].plot()","386dd76b":"#set_index\ntrain=train_df.set_index(['timestamp'])\n\n#plot missing values per building\/meter\nf,a=plt.subplots(1,4,figsize=(20,30))\nfor meter in np.arange(4):\n    df=train[train.meter==meter].copy().reset_index()\n    df['timestamp']=pd.to_timedelta(df.timestamp-pd.to_datetime(\"2016-01-01\")).dt.total_seconds()\/3600\n    df['timestamp']=df.timestamp.astype(int)\n    df.timestamp=df.timestamp-df.timestamp.min()\n    missmap=np.empty((1449,df.timestamp.max()+1))\n    missmap.fill(np.nan)\n    for l in df.values:\n        #print(l)\n        if l[2]!=meter:continue\n        missmap[int(l[1]),int(l[0])]=0 if l[3]==0 else 1\n    a[meter].set_title(f'meter {meter:d}')\n    sns.heatmap(missmap,cmap='Paired',ax=a[meter],cbar=True)\n        \n        ","3d42adfe":"total = train_df.isnull().sum().sort_values(ascending=False)\npercent=(train_df.isnull().sum()\/train_df.isnull().count()*100).sort_values(ascending=False)\nmissing_train_data=pd.concat([total,percent],axis=1,keys=['Total','Percent'])\nmissing_train_data","d034b6cb":"# checking missing data\ntotal = weather_train_df.isnull().sum().sort_values(ascending = False)\npercent = (weather_train_df.isnull().sum()\/weather_train_df.isnull().count()*100).sort_values(ascending = False)\nmissing_weather_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_weather_data.head(9)","0682f70e":"# checking missing data\ntotal = weather_test_df.isnull().sum().sort_values(ascending = False)\npercent = (weather_test_df.isnull().sum()\/weather_test_df.isnull().count()*100).sort_values(ascending = False)\nmissing_weather_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_weather_data.head(9)","15d87ea2":"# checking missing data\ntotal = building_meta_df.isnull().sum().sort_values(ascending = False)\npercent = (building_meta_df.isnull().sum()\/building_meta_df.isnull().count()*100).sort_values(ascending = False)\nmissing_building_meta_df  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_building_meta_df.head(9)","46050e7d":"train_df=train_df.merge(building_meta_df,on='building_id',how='left')\ntest_df=test_df.merge(building_meta_df,on='building_id',how='left')\n\ntrain_df=train_df.merge(weather_train_df,on=['site_id','timestamp'],how='left')\ntest_df=test_df.merge(weather_test_df,on=['site_id','timestamp'],how='left')\n\n\ngc.collect()","9d5dcb6a":"fig, axes = plt.subplots(1, 1, figsize=(14, 6), dpi=100)\ntrain_df[['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes, label='By hour', alpha=0.7).set_ylabel('Meter reading', fontsize=14);\ntrain_df[['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes, label='By day', alpha=1).set_ylabel('Meter reading', fontsize=14);\naxes.set_title('Mean Meter reading by hour and day', fontsize=16);\n\n#\u663e\u793a\u56fe\u4e2d\u7684\u6807\u7b7e\naxes.legend();","1a9720f3":"train_df.head()","9f44b30e":"fig, axes = plt.subplots(8,2,figsize=(15, 30), dpi=100)\nfor i in range(train_df['site_id'].nunique()):\n    train_df[train_df['site_id'] == i][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i%8][i\/\/8], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=13);\n    train_df[train_df['site_id'] == i][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i%8][i\/\/8], alpha=1, label='By day', color='tab:orange').set_xlabel('');\n    axes[i%8][i\/\/8].legend();\n    axes[i%8][i\/\/8].set_title('site_id {}'.format(i), fontsize=13);\n    plt.subplots_adjust(hspace=0.45)","184fc15e":"fig, axes = plt.subplots(8,2,figsize=(14, 30), dpi=100)\nfor i, use in enumerate(train_df['primary_use'].value_counts().index.to_list()):\n    try:\n        train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == use)][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i%8][i\/\/8], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=13);\n        train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == use)][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i%8][i\/\/8], alpha=1, label='By day', color='tab:orange').set_xlabel('');\n        axes[i%8][i\/\/8].legend();\n    except TypeError:\n        pass\n    axes[i%8][i\/\/8].set_title(use, fontsize=13);\n    plt.subplots_adjust(hspace=0.45)","3f64fefc":"fig, axes = plt.subplots(3,1,figsize=(14, 18), dpi=100)\nfor i in train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education')]['meter'].value_counts(dropna=False).index.to_list():\n    train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == i)][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=13);\n    train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == i)][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i], alpha=1, label='By day', color='tab:orange').set_xlabel('');\n    axes[i].legend();\n    axes[i].set_title('Meter: ' + str(i), fontsize=13);","2cc6717f":"len(train_df[(train_df['primary_use']=='Education')&(train_df['site_id']==13)&(train_df['meter']==2)]['building_id'].value_counts().index.to_list())","c653fdd0":"fig, axes = plt.subplots(9,2,figsize=(14, 36), dpi=100)\nfor i, building in enumerate(train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == 2)]['building_id'].value_counts(dropna=False).index.to_list()):\n    train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == 2) & (train_df['building_id'] == building)][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i%9][i\/\/9], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=13);\n    train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == 2) & (train_df['building_id'] == building)][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i%9][i\/\/9], alpha=1, label='By day', color='tab:orange').set_xlabel('');\n    axes[i%9][i\/\/9].legend();\n    axes[i%9][i\/\/9].set_title('building_id: ' + str(building), fontsize=13);\n    plt.subplots_adjust(hspace=0.45)","59c3779e":"fig, axes = plt.subplots(3,1,figsize=(14, 20), dpi=100)\n\ntrain_df[(train_df['meter'] == 2) & (train_df['building_id'] == 1099)][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[0], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=13);\ntrain_df[(train_df['meter'] == 2) & (train_df['building_id'] == 1099)][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[0], alpha=1, label='By day', color='tab:orange').set_xlabel('');\n\ntrain_df[['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[1], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=13);\ntrain_df[['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[1], alpha=1, label='By day', color='tab:orange').set_xlabel('');\n\ntrain_df[~((train_df['meter'] == 2) & (train_df['building_id'] == 1099))][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[2], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=13);\ntrain_df[~((train_df['meter'] == 2) & (train_df['building_id'] == 1099))][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[2], alpha=1, label='By day', color='tab:orange').set_xlabel('');\n\naxes[0].set_title('building_id==1099 and meter==2', fontsize=13);\naxes[1].set_title('Full dataset', fontsize=13);\naxes[2].set_title('building_id 1099 excluded', fontsize=13);\nplt.subplots_adjust(hspace=0.45)","63674f04":"# Find correlations with the target and sort\ncorrelations = train_df.corr()['meter_reading'].sort_values()\n\n# Display correlations\nprint('Most Positive Correlations:\\n', correlations.tail(7))\nprint('\\nMost Negative Correlations:\\n', correlations.head(4))\n\ncorrs = train_df.corr()\ncorrs","75097d25":"def plot_dist_col(column):\n    fig,ax=plt.subplots(figsize=(10,10))\n    sns.distplot(weather_train_df[column].dropna(),color='green',ax=ax).set_title(column,fontsize=16)\n    sns.distplot(weather_test_df[column].dropna(),color='purple',ax=ax).set_title(column,fontsize=16)\n    plt.xlabel(column,fontsize=15)\n    plt.legend(['train','test'])\n    plt.show()","ce01a905":"plot_dist_col('air_temperature')","37fa062a":"plot_dist_col('cloud_coverage')","136a9c95":"weather_train_df['cloud_coverage'].unique()","14b2202a":"plot_dist_col('dew_temperature')","3692c440":"plot_dist_col('precip_depth_1_hr')","56fa588d":"weather_train_df['precip_depth_1_hr'].unique()","36308b91":"plot_dist_col('sea_level_pressure')","97f64bf6":"plot_dist_col('wind_direction')","dd817f6b":"plot_dist_col('wind_speed')","e023e942":"#\u98ce\u901f\u5c0f\u4e8e0\uff0c\u8fd9\u91cc\u4e0d\u786e\u5b9a\u662f\u6570\u636e\u6709\u95ee\u9898\u8fd8\u662f\u56e0\u4e3a\u9006\u98ce\nlen(weather_train_df[weather_train_df['precip_depth_1_hr']<0])","8429fa16":"def plot_dist_col(column):\n    fig,ax=plt.subplots(figsize=(10,10))\n    sns.distplot(building_meta_df[column].dropna(),color='green',ax=ax).set_title(column,fontsize=16)\n       \n    plt.xlabel(column,fontsize=15)\n    plt.legend(['building'])\n    plt.show()","b0decede":"plot_dist_col('floor_count')","128062a6":"plot_dist_col('year_built')","33c44441":"building_meta_df['year_built'].unique()","61c16db4":"plot_dist_col('square_feet')","a5fddbb4":"train_df_sub_1099=train_df[~((train_df['meter'] == 2) & (train_df['building_id'] == 1099))]\nts=train_df_sub_1099.groupby([\"timestamp\"])[\"meter_reading\"].mean()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('average meter_reading with time')\nplt.xlabel('timestamp')\nplt.ylabel('meter_reading')\nplt.plot(ts)","7f7e14ff":"plt.figure(figsize=(16,6))\nplt.plot(ts.rolling(window=12).mean(),label='Rolling Mean')\nplt.plot(ts.rolling(window=12).std(),label='Rolling sd')\nplt.legend()","9714a4b4":"building_meta_df.groupby('site_id').primary_use.agg(lambda x:x.value_counts().to_dict()).to_dict()","13ce10ac":"building_meta_df.groupby('site_id').building_id.agg(lambda x:x.value_counts().to_dict()).to_dict()[0]","00c2c116":"fig, axes = plt.subplots(8,2,figsize=(14, 20), dpi=100)\n#weather_train_df[weather_train_df['site_id']==0].plot()\n\nimport datetime\n# plt.figure(figsize=(16,6))\n\n# plt.xlabel('timestamp')\n# plt.ylabel('air_temperature')\n\n#plt.plot(weather_train_df[])\n#plt.legend()\nweather_train_df['hour']=weather_train_df.timestamp.dt.hour\nweather_train_df_mean_by_hour=weather_train_df.groupby(['site_id','hour']).mean()\n# #train_df[train_df['site_id'] == i][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i%8][i\/\/8], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=13);\nfor i in range(16):\n    weather_train_df_mean_by_hour[i*24:(i+1)*24]['air_temperature'].plot(ax=axes[i%8][i\/\/8])\n    axes[i%8][i\/\/8].legend();\n    axes[i%8][i\/\/8].set_title('site_id {} max temperature hour is {}'.format(i,np.argmax(weather_train_df_mean_by_hour[i*24:(i+1)*24]['air_temperature'])[1]), fontsize=13);\nplt.subplots_adjust(hspace=0.8)","87aa0ee6":"#load training data 2016\nweather_train=pd.read_csv(root+'weather_train.csv', parse_dates=['timestamp'])\nweather_train.head()","907fc4ee":"#pivot to plot\nwmatrix_train=weather_train.pivot(index='timestamp',columns='site_id',values='air_temperature')\nwmatrix_train.head()","dd9a9421":"#\u5bfb\u627e\u8bad\u7ec3\u96c6\u4e2d\u6709\u6700\u591a\u7f3a\u5931\u503c\u7684site_id\nsite_id=wmatrix_train.count().idxmin()\n\n#\u6311\u9009\u51fa\u4e00\u6bb5\u65f6\u95f4\u8fdb\u884c\u89c2\u6d4b\nstart_date,end_date=datetime.date(2016,1,1),datetime.date(2016,1,9)\n\n#\u521d\u59cb\u5316\u7ed8\u56fe\nf,ax=plt.subplots(figsize=(18,6))\n\n#load test data 2017-2018\nweather_test=pd.read_csv(root+'weather_test.csv', parse_dates=['timestamp'])\n\n#shift 2017 to 2016\nweather_test.timestamp=weather_test.timestamp-datetime.timedelta(365)\nwtmatrix=weather_test.pivot(index='timestamp',columns='site_id',values='air_temperature')\nwtmatrix.loc[start_date:end_date,site_id].plot(ax=ax,label=f'2017.1.1-2017.1.9 site:{site_id}',alpha=0.5)\n\n#shift 2018 to 2016\nweather_test.timestamp=weather_test.timestamp-datetime.timedelta(365)\nwtmatrix=weather_test.pivot(index='timestamp',columns='site_id',values='air_temperature')\nwtmatrix.loc[start_date:end_date,site_id].plot(ax=ax,label=f'2018.1.1.-2018.1.9 site:{site_id}',alpha=0.5)\n\n\ndef fill_with_polynomial(wmatrix):\n    return wmatrix.fillna(wmatrix.interpolate(method='polynomial',order=3))\n\ndef fill_with_lin(wmatrix):\n    return wmatrix.fillna(wmatrix.interpolate(method='linear'))\n\ndef fill_with_mix(wmatrix):\n    wmatrix=(wmatrix.fillna(wmatrix.interpolate(method='linear',limit_direction='both'))+ wmatrix.fillna(wmatrix.interpolate(method='polynomial', order=3, limit_direction='both')))*0.5  \n    \n    return wmatrix        # fill with second item\n    \nfill_with_lin(wmatrix_train).loc[start_date:end_date,site_id].plot(ax=ax,label=f'linear Jan 2016 site:{site_id}',alpha=0.5) \nfill_with_polynomial(wmatrix_train).loc[start_date:end_date,site_id].plot(ax=ax,label=f'polynomial Jan 2016 site:{site_id}',alpha=0.5)    \nfill_with_mix(wmatrix_train).loc[start_date:end_date,site_id].plot(ax=ax,label=f'mix Jan 2016 site:{site_id}',alpha=0.5)    \nwmatrix_train.loc[start_date:end_date, site_id].plot(ax=ax, label=f'Jan 2016 site:{site_id}')\nplt.legend()","5c227933":"# pivot to plot\ncol = 'dew_temperature'\nwmatrix = weather_train.pivot(index='timestamp', columns='site_id', values=col)\n# site with largest amount of missing data points\nsite_id = wmatrix.count().idxmin()\n# plot perid\nstart_date, end_date = datetime.date(2016, 1, 1), datetime.date(2016, 1, 12)\nf,ax = plt.subplots(figsize=(18,6))\n\n_ = fill_with_lin(wmatrix).loc[start_date:end_date, site_id].plot(ax=ax, label=f'linear Jan 2016 site:{site_id}', alpha=0.5)\n_ = fill_with_polynomial(wmatrix).loc[start_date:end_date, site_id].plot(ax=ax, label=f'cubic Jan 2016 site:{site_id}', alpha=0.5)\n_ = fill_with_mix(wmatrix).loc[start_date:end_date, site_id].plot(ax=ax, label=f'mix Jan 2016 site:{site_id}', alpha=0.5)\n_ = wmatrix.loc[start_date:end_date, site_id].plot(ax=ax, label=f'Jan 2016 site:{site_id}')\n\n_ = plt.legend()","bfa9ced7":"<font  size=3 face=\"\u5fae\u8f6f\u96c5\u9ed1\">  &ensp; &ensp; \u6e29\u5ea6\u6700\u9ad8\u7684\u65f6\u95f4\u5e94\u8be5\u662f\u572814\uff1a00\u4ece\u4e0a\u56fe\u6211\u4eec \u6bcf\u4e2asite_id\u7684\u6700\u9ad8\u6e29\u5ea6\u65f6\u95f4\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u51fa\u65f6\u95f4\u5dee\u3002<\/font> <br\/><br\/>&ensp; &ensp; <font  size=3 face=\"\u5fae\u8f6f\u96c5\u9ed1\" color=\"blue\">\u6211\u4eec\u5c06\u4f1a\u4f7f\u7528\u8fd9\u4e2a\u5dee\u6765\u91cd\u65b0\u8c03\u6574weather\u6570\u636e\u4e2d\u7684timestamp    site_GMT_offsets = [-5, 0, -9, -6, -8, 0, -6, -6, -5, -7, -8, -6, 0, -7, -6, -6]<\/font>","89f8ccad":" Exploratory Data Analysis (EDA) is an open-ended process where we calculate statistics and make figures to find trends, anomalies, patterns, or relationships within the data.\n \n glimpse at meter_reading(y)","8a939327":"### Correlations\nOne way to try and understand the data is by looking for correlations between the features and the target. We can calculate the Pearson correlation coefficient between every variable and the target using the `.corr` dataframe method.\n\n* .00-.19 \u201cvery weak\u201d\n*  .20-.39 \u201cweak\u201d\n*  .40-.59 \u201cmoderate\u201d\n*  .60-.79 \u201cstrong\u201d\n* .80-1.0 \u201cvery strong\u201d","7b2ecc70":"checking missing data for building_meta_df","eb9bbb11":"# size of data","7a7b3019":"<font  size=3 face=\"\u5fae\u8f6f\u96c5\u9ed1\" color=\"blue\">  &ensp; &ensp; \u770b\u8d77\u6765 \u662f\u7ebf\u6027\u548c\u591a\u9879\u5f0f1:1\u6df7\u5408\u4fee\u8865\u7f3a\u5931\u503c\u6bd4\u8f83\u5e73\u6ed1\uff0c\u4f46\u5728\u5efa\u6a21\u7684\u65f6\u50193\u79cd\u65b9\u6cd5\u90fd\u5c1d\u8bd5\u540e\u53d1\u73b0\uff0c\u7ebf\u6027\u8865\u503c\u6700\u597d\n<\/font>","ea326f29":"building_metadata.csv\n> - site_id:0-15\n> - building_id:0-1448\n> - primary_use:Education Office an other(14) total 16\n> - square_feet:283-875k\n> - year_built:1900-2017\n> - floor_count:1-26\n\ntrain.csv\n> - timestamp :2016.1.1-2017.1.1\n> - 0: electricity, 1: chilledwater, 2: steam, 3: hotwater\n> - total data is a year\n\ntest.csv\n> - timestamp :2017.1.1-2019.1.1\n> - total data is 2 year","13a2bc45":"# Examine Missing Values","fe4ebb67":"checking missing data for train_df","5647a3dc":"checking missing data for weather_train_df","2ba1ed0a":"<font color=#000000 size=6 face=\"\u5fae\u8f6f\u96c5\u9ed1\">simple time series analysis <\/font>","88299a28":"# Reduce Memory","b259d323":"After going through all the buildings, we can find the problem ,It is building 1099","41d77ab5":"# we can learn lot from Data  download homepage","44bef546":"\n\nOne more level of conclusions:\n\n* site_id == 13 and primary_use == Education looks a lot like a general mean for meter reading. So it is really invest a lost into the whole data\n* site_id == 13 and primary_use == Technology\/Science also have 0's in meter readings in January. Just like site_id 0, that we found earlier.\n\nLets keep digging and see what meter type is responsible for such weird look of the meter reading for site_id 13 and primary_use Education.","deea8c1a":"<font  size=6 face=\"\u5fae\u8f6f\u96c5\u9ed1\">\u7f3a\u5931\u503c\u586b\u8865\u63a2\u7d22\n<\/font>","45966365":"checking missing data for weather_test_df","e425cb6a":"<font  size=3 face=\"\u5fae\u8f6f\u96c5\u9ed1\">  &ensp; &ensp; \u4ece\u5efa\u6a21\u540e\u7684\u7279\u5f81\u91cd\u8981\u6027\u4ee5\u53ca\u5c1d\u8bd5\u5404\u79cd\u7279\u5f81\u540e\u5f97\u51fa air_temperature\u4ee5\u53cadew_temperature\n\u662f\u548c\u80fd\u6e90\u4f7f\u7528\u60c5\u51b5\u6700\u76f8\u5173\uff0c\u6700\u91cd\u8981\u7684\u7279\u5f81\u3002\u8bad\u7ec3\u96c6\u4e2d\u7684 air_temperature\u548cdew_temperature\u5206\u522b\u6709 4%\u548c8%\u7684\u7f3a\u5931\uff0c\u6d4b\u8bd5\u96c6\u4e2d\u5206\u522b\u6709 4%\u548c11%\u7684\u7f3a\u5931\u3002\n<\/font>","9cf14082":"Mean meter reading by primary_use for site_id==13","83d00c50":"<font color=#000000 size=6 face=\"\u5b8b\u4f53\"> plot dist curves for building data for the given column name <\/font>","98889b54":"#load training data 2016\nweather=pd.read_csv(root + 'weather_train.csv',parse_dates=['timestamp'])\nweather.head()#pivot to plot","7b7ae635":"### same for dew_temperature","6a218908":"# Exploratory Data Analysis","5888b6d1":"\u6807\u51c6\u5dee\u662f\u6709\u89c4\u5f8b\u7684\uff0c\u53ef\u80fd\u5468\u671f\u662f\u4e00\u661f\u671f\uff1f","13fa918f":"<font  size=4 face=\"\u5fae\u8f6f\u96c5\u9ed1\">\u67e5\u770b\u6bcf\u4e2asite_id \u768424\u5c0f\u65f6\u7684\u5e73\u5747\u6e29\u5ea6\u6570\u636e <\/font>","8dfa7c6f":"<font  size=5 face=\"\u5fae\u8f6f\u96c5\u9ed1\">  &ensp; &ensp; air_temperature<\/font>","3f438f5a":"meter_reading \u6309\u7167\u5c0f\u65f6\u4ee5\u53ca\u5929\u7684\u5e73\u5747\u503c \u4ece3\u6708\u52307\u6708\u4ee5\u53ca11\u6708\u7684\u4e00\u6bb5\u65f6\u95f4\u503c\u5f88\u5927\uff0c\u8fd9\u6709\u4e9b\u5947\u602a\u3002\n\n\u9700\u8981\u518d\u505a\u4e00\u4e0b\u8be6\u7ec6\u7684\u5206\u6790\u3002\n\nsite_id \u670916\u4e2a\uff0c\u53ef\u4ee5\u5206\u522b\u770b\u4e00\u4e0b\u8fd916\u4e2asite\u7684meter_reading","b652f81d":"Legend:\n* X axis: hours elapsed since Jan 1st 2016, for each of the 4 meter types\n* Y axis: building_id\n* Brown: meter reading available with non-zero value\n* Light blue: meter reading available with zero value\n* White: missing meter reading\n\nwe can draw some question:\n* building_id 0-100 time0-2315 meter_reading is all zero they are error data,so we should clear them\n* meter1 and meter3 are chillwater and hotwater so some building have Seasonal characteristics\n","5b04d280":"# Analyse train.csv","d28394e3":"we can see that the meter_reading of site_id 13 is too big and very like total data \n\nwe can see it deeply","22865998":"<font  size=3 face=\"\u5fae\u8f6f\u96c5\u9ed1\">  &ensp; &ensp; \u4ece\u4e0a\u56fe\u6211\u4eec\u53ef\u4ee5\u53d1\u73b0\u4e00\u4e9b\u95ee\u9898\uff0c\u4e0d\u540c\u7684site_id \u7684\u6700\u9ad8\u6e29\u5ea6\u5728\u4e0d\u540c\u7684\u65f6\u95f4\uff0c\u6bd4\u5982site_id=13\u5730\u533a\u7684\u6700\u9ad8\u6e29\u5ea6\u572822\u70b9\u621623\u70b9\u5de6\u53f3\uff0c\u8fd9\u662f\u6709\u95ee\u9898\u7684\u3002\u8fd9\u8bf4\u660eweather_data\u91cc\u9762\u7684timestamp\u662f\u6709\u95ee\u9898\u7684\u3002\u6211\u4eec\u9700\u8981\u6821\u51c6\u65f6\u95f4\uff0c\u8fd9\u6837\u548ctraain_df\u8868\u8fde\u63a5\u540e\u624d\u662f\u6709\u610f\u4e49\u7684\u3002<\/font>","cd77ddd2":"<font color=#000000 size=6 face=\"\u5b8b\u4f53\"> plot dist curves for train and  test weather data for the given column name <\/font>","7ec2b353":"# Take a quick look at each data","00d9dd12":"Mean meter reading by meter type for primary_use==Education and site_id==13","3d6045e7":"# EDA","bc4dbe55":" so we should clean data of building_id ==1099 and meter ==2 ","15ceec2e":"<font  size=4 face=\"\u5fae\u8f6f\u96c5\u9ed1\">\u67e5\u770b\u6bcf\u4e2asite_id \u5404\u6709\u591a\u5c11\u7c7b\u578b\u7684\u5efa\u7b51 <\/font>","90ed80e1":"Fine. What we have right now is that site_id 13 with primary_use Education and meter type 2 is responsible for this mess.\nBut we need to go deeper. There are 17 buildings that fall under these criteria. No problem. Another plot.","6dc90f14":"<font color='red' size=4 face=\"\u5fae\u8f6f\u96c5\u9ed1\">square_feet\u7684\u503c\u6bd4\u8f83\u5927\uff0c\u5e94\u8be5\u505a\u5e73\u6ed1\u5904\u7406 <\/font>","bb6f2a83":"<font  size=3 face=\"\u5fae\u8f6f\u96c5\u9ed1\" color=\"blue\">  &ensp; &ensp; \u540c\u6837\u770b\u8d77\u6765 \u662f\u7ebf\u6027\u548c\u591a\u9879\u5f0f1:1\u6df7\u5408\u4fee\u8865\u7f3a\u5931\u503c\u6bd4\u8f83\u5e73\u6ed1\uff0c\u4f46\u5728\u5efa\u6a21\u7684\u65f6\u50193\u79cd\u65b9\u6cd5\u90fd\u5c1d\u8bd5\u540e\u53d1\u73b0\uff0c\u7ebf\u6027\u8865\u503c\u6700\u597d\n<\/font>","23aeb899":"look that by ganfear:[ Missing data and zeros visualized](https:\/\/www.kaggle.com\/ganfear\/missing-data-and-zeros-visualized)\n\ndivide train data into building meter and time,\nthen seek missing data and zeros and the number of data"}}