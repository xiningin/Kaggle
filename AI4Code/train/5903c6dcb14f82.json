{"cell_type":{"16f66271":"code","5db3dc1f":"code","b50369e0":"code","6ed95589":"code","4ad1ab30":"code","6881983f":"code","96b10c3f":"code","6aabb846":"code","a5d40baf":"code","ba43e4ec":"code","0fc1d52e":"code","1f791ae6":"code","7de14d5c":"code","13b4f31e":"code","5040c93c":"code","0c42a2f3":"code","8adb3298":"code","f2027c24":"code","7ceb9a15":"code","ab43d45c":"code","24c0b9c8":"code","0bcd73dc":"code","79456128":"markdown"},"source":{"16f66271":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5db3dc1f":"train_data = pd.read_csv('\/kaggle\/input\/jejubusdacon\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/jejubusdacon\/test.csv')\ntrain_data.head()","b50369e0":"train_data.info()","6ed95589":"import numpy as np # \ud589\ub82c \uc5f0\uc0b0 \/ \ub370\uc774\ud130 \ud578\ub4e4\ub9c1\nimport pandas as pd # \ub370\uc774\ud130 \ubd84\uc11d\nimport matplotlib.pyplot as plt # \uadf8\ub798\ud504 \uc2dc\uac01\ud654\nimport seaborn as sns # \uadf8\ub798\ud504 \uc2dc\uac01\ud654\nfrom xgboost import XGBRegressor # XGBoost Regressor \ubaa8\ub378\nfrom sklearn.model_selection import KFold # K-validation\nfrom sklearn.metrics import accuracy_score # \uc815\ud655\ub3c4 \uce21\uc815 \ud568\uc218\nfrom sklearn.preprocessing import LabelEncoder # \ub77c\ubca8 \uc778\ucf54\ub354","4ad1ab30":"# !pip install \ud328\ud0a4\uc9c0 \uc774\ub984 \n# !pip install -U finance-datareader","6881983f":"idx","96b10c3f":"idx = (train_data['next_arrive_time'] <= 700)\ntrain_data = train_data.loc[idx,:]\ntrain_data","6aabb846":"station_encoder = LabelEncoder() # \uc778\ucf54\ub354 \uc0dd\uc131\n# _station = list(train_data['now_station'].values) + list(train_data['next_station'].values) # train_data \uc758 \ubaa8\ub4e0 \uc815\ub958\uc7a5 \uc774\ub984\n_station = list(train_data['now_station']) + list(train_data['next_station']) # train_data \uc758 \ubaa8\ub4e0 \uc815\ub958\uc7a5 \uc774\ub984\nstation_set = set(_station)\nprint(len(station_set))\n# len([[1,2,3,4,5,6],[1,2,3,4,5,6]])\n# len('Hello World')\n\nstation_encoder.fit(list(station_set)) # \uc778\ucf54\ub529\nstation_encoder\n\ntrain_data['now_station'] = station_encoder.transform(train_data['now_station'])\ntrain_data['next_station'] = station_encoder.transform(train_data['next_station'])\ntest_data['now_station'] = station_encoder.transform(test_data['now_station'])\ntest_data['next_station'] = station_encoder.transform(test_data['next_station'])\ntrain_data.head()","a5d40baf":"times_ = train_data['now_arrive_time'] # \ntimes_.hist()","ba43e4ec":"target_ = train_data['next_arrive_time']\ntarget_.hist(bins=50)\n","0fc1d52e":"target_ = train_data['distance']\ntarget_.hist(bins=50)\n","1f791ae6":"train_data['date'] = pd.to_datetime(train_data['date']) # date \uac12\uc744 datetime\uc73c\ub85c\ntrain_data['weekday'] = train_data['date'].dt.weekday  # Monday 0, Sunday 6\ntrain_data['weekday'] = train_data['weekday'].apply(lambda x: 0 if x <= 5 else 1) \n# 0 ~ 5 \ub294 \uc6d4\uc694\uc77c ~ \uae08\uc694\uc77c\uc774\ubbc0\ub85c \ud3c9\uc77c\uc774\uba74 0, \uc8fc\ub9d0\uc774\uba74 1\uc744 \uc124\uc815\ud558\uc600\ub2e4\ntrain_data['weekday'].unique()","7de14d5c":"train_data = pd.get_dummies(train_data, columns=['weekday']) # \ud3c9\uc77c\/\uc8fc\ub9d0\uc5d0 \ub300\ud574 One-hot Encoding","13b4f31e":"train_data = train_data.drop('date', axis=1) # \ud544\uc694\uc5c6\ub294 date \uce7c\ub7fc\uc744 drop\ntrain_data.head()","5040c93c":"test_data['date'] = pd.to_datetime(test_data['date'])\ntest_data['weekday'] = test_data['date'].dt.weekday  # Monday 0, Sunday 6\ntest_data['weekday'] = test_data['weekday'].apply(lambda x: 0 if x <= 5 else 1)\ntest_data = pd.get_dummies(test_data, columns=['weekday'])\n\ntest_data = test_data.drop('date', axis=1)\ntest_data.head()","0c42a2f3":"train_data['time_group']='group' #time_group \ubcc0\uc218\ub97c \ubbf8\ub9ac \uc0dd\uc131\n\ntrain_data.loc[ (train_data['now_arrive_time']>='05\uc2dc') & (train_data['now_arrive_time']<'12\uc2dc') ,['time_group'] ]= 'morning' # 05~11\uc2dc\ntrain_data.loc[ (train_data['now_arrive_time']>='12\uc2dc') & (train_data['now_arrive_time']<'18\uc2dc') ,['time_group'] ]= 'afternoon' #12~17\uc2dc\ntrain_data.loc[ (train_data['now_arrive_time']>='18\uc2dc') | (train_data['now_arrive_time']=='00\uc2dc'),['time_group'] ]= 'evening' #18~00\uc2dc\n\ntrain_data = pd.get_dummies(train_data,columns=['time_group']) # \uc6d0 \ud56b \uc778\ucf54\ub529\uc744 \uc218\ud589\ntrain_data = train_data.drop('now_arrive_time', axis=1) # \ud544\uc694\uc5c6\ub294 now_arrive_time drop\ntrain_data.head()","8adb3298":"test_data['time_group']='group'\n\ntest_data.loc[ (test_data['now_arrive_time']>='05\uc2dc') & (test_data['now_arrive_time']<'12\uc2dc') ,['time_group'] ]= 'morning' # 05~11\uc2dc\ntest_data.loc[ (test_data['now_arrive_time']>='12\uc2dc') & (test_data['now_arrive_time']<'18\uc2dc') ,['time_group'] ]= 'afternoon' #12~17\uc2dc\ntest_data.loc[ (test_data['now_arrive_time']>='18\uc2dc') | (test_data['now_arrive_time']=='00\uc2dc'),['time_group'] ]= 'evening' #18~00\uc2dc\n\ntest_data = pd.get_dummies(test_data,columns=['time_group'])\ntest_data = test_data.drop('now_arrive_time', axis=1)\ntest_data.head()","f2027c24":"train_data = train_data.drop(['id', 'route_nm', 'next_latitude', 'next_longitude', \n                              'now_latitude', 'now_longitude'], axis=1)\ntrain_data.head()","7ceb9a15":"test_data = test_data.drop(['route_nm', 'next_latitude', 'next_longitude', \n                              'now_latitude', 'now_longitude'], axis=1)\ntest_data.head()","ab43d45c":"input_var = list(train_data.columns) \ninput_var.remove('next_arrive_time')\n\nXtrain = train_data[input_var] # \ud559\uc2b5 \ub370\uc774\ud130 \uc120\ud0dd\nYtrain = train_data['next_arrive_time'] # target \uac12\uc778 Y \ub370\uc774\ud130 \uc120\ud0dd\n\nXtest = test_data[input_var] # \uc2dc\ud5d8 \ub370\uc774\ud130\ub3c4 \uc120\ud0dd","24c0b9c8":"model = XGBRegressor(random_state=110, verbosity=0, nthread=23, n_estimators=980, max_depth=4)\nkfold = KFold(n_splits=8, shuffle=True, random_state=777)\nn_iter = 0\ncv_score = []\n\ndef rmse(target, pred):\n    return np.sqrt(np.sum(np.power(target - pred, 2)) \/ np.size(pred))","0bcd73dc":"# i = 0 \nfor train_index, test_index in kfold.split(Xtrain, Ytrain):\n    # K Fold\uac00 \uc801\uc6a9\ub41c train, test \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc628\ub2e4\n    X_train, X_test = Xtrain.iloc[train_index,:], Xtrain.iloc[test_index, :]\n    Y_train, Y_test = Ytrain.iloc[train_index], Ytrain.iloc[test_index]\n    \n    # \ubaa8\ub378 \ud559\uc2b5\uacfc \uc608\uce21 \uc218\ud589\n    model.fit(X_train, Y_train)\n    pred = model.predict(X_test)\n    print(pred)\n    \n    # \uc815\ud655\ub3c4 RMSE \uacc4\uc0b0\n    n_iter += 1\n    score = rmse(Y_test, pred)\n    print(score)\n    cv_score.append(score)\n#     i += 1\n#     print(i)\nprint('\\n\uad50\ucc28 \uac80\uc99d\ubcc4 RMSE :', np.round(cv_score, 4))\nprint('\ud3c9\uade0 \uac80\uc99d RMSE :', np.mean(cv_score))","79456128":"**\ub530\ub77c\ud574\ubcfc \ucf54\ub4dc**\n<br> \nhttps:\/\/dacon.io\/competitions\/official\/229611\/codeshare\/605?page=1&dtype=recent&ptype=pub"}}