{"cell_type":{"b01c414f":"code","26cc785e":"code","9db4e27a":"code","1acc5d7e":"code","b5b476ae":"code","0987a59d":"code","d901baec":"code","1e13c9ba":"code","0f7a927f":"code","021c3b92":"code","6e4732ce":"code","72d4f60e":"markdown","bebbd5f9":"markdown","92ee73df":"markdown","f3982ded":"markdown","20a301fc":"markdown","ae7f2fac":"markdown","62fe156d":"markdown","069311f0":"markdown"},"source":{"b01c414f":"import pandas as pd\nimport numpy as np\nimport json\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Check the revision log\nwith open('\/kaggle\/input\/arthropod-taxonomy-orders-object-detection-testset\/ArTaxOr_TestSet\/revision history.txt', 'r') as f:\n    print(f.read())","26cc785e":"pfile='\/kaggle\/input\/arthropod-taxonomy-orders-object-detection-testset\/ArTaxOr_TestSet\/positives\/annotations\/ArTaxOr_TestSet.vott'\ndf=pd.DataFrame()\nwith open(pfile) as file:\n    pdata=json.load(file)\n    df=df.append(pd.DataFrame(list(pdata['assets'].values())), ignore_index=True)\ndf['path']=df['path'].str.replace('file:F:\/','')\ndf.sample(5)","9db4e27a":"tags=pd.DataFrame(list(pdata['tags']))\npattern=r'[A-Z]'\nlabels=tags[tags.name.str.match(pattern)]\nlabels","1acc5d7e":"import seaborn as sns\n\nps=np.zeros(len(df))\nfor i in range(len(df)):\n    ps[i]=df['size'][i]['width'] * df['size'][i]['height']\/1e6\nsns.distplot(ps, bins=21,kde=False).set_title('Image resolution in Mpix (total {})'.format(len(df)));","b5b476ae":"import os\n\nARTAXOR_PATH='\/kaggle\/input\/arthropod-taxonomy-orders-object-detection-testset\/'\n\nanno=pd.DataFrame(columns=['label', 'label_idx', 'xres', 'yres', 'height', 'width', 'left', 'top', \n                           'right', 'bottom', 'area', 'xcenter', 'ycenter', 'blurred', \n                           'occluded', 'truncated', 'file', 'id'])\nfor i in range(len(df)):\n    p=df['path'][i].split('\/')\n    p='\/'.join(p[:2])\n    afile=ARTAXOR_PATH+p+'\/annotations\/'+df['id'][i]+'-asset.json'\n    if os.path.isfile(afile):\n        with open(afile) as file:\n            adata=json.load(file)\n        xres,yres=adata['asset']['size']['width'],adata['asset']['size']['height'] \n        for j in range(len(adata['regions'])):\n            h=adata['regions'][j]['boundingBox']['height']\/yres\n            w=adata['regions'][j]['boundingBox']['width']\/xres\n            tags=adata['regions'][j]['tags']\n            anno=anno.append({'label': tags[0],\n                              'label_idx': labels[labels.name==tags[0]].index[0],\n                              'xres': xres,\n                              'yres': yres,\n                              'height': h,\n                              'width': w,                              \n                              'left': adata['regions'][j]['boundingBox']['left']\/xres,\n                              'top': adata['regions'][j]['boundingBox']['top']\/yres,\n                              'right': adata['regions'][j]['boundingBox']['left']\/xres+w,\n                              'bottom': adata['regions'][j]['boundingBox']['top']\/yres+h, \n                              'area': h*w,\n                              'xcenter': adata['regions'][j]['boundingBox']['left']\/xres+0.5*w,\n                              'ycenter': adata['regions'][j]['boundingBox']['top']\/yres+0.5*h,\n                              'blurred': int(any(ele == '_blurred' for ele in tags)),\n                              'occluded': int(any(ele == '_occluded' for ele in tags)),\n                              'truncated': int(any(ele == '_truncated' for ele in tags)),\n                              'file': adata['asset']['path'].replace('file:F:\/',''),\n                              'id': adata['asset']['id'],}, ignore_index=True)\nanno.head()","0987a59d":"graph=sns.countplot(data=anno, x='label')\ngraph.set_xticklabels(graph.get_xticklabels(),rotation=90)\nfor p in graph.patches:\n    height = p.get_height()\n    graph.text(p.get_x()+p.get_width()\/2., height + 0.1,height ,ha=\"center\")","d901baec":"labels.to_pickle('.\/testset_labels.pkl')\ndf.to_pickle('.\/testset_filelist.pkl')\nanno.to_pickle('.\/testset_objects.pkl')","1e13c9ba":"!ls -al *.pkl","0f7a927f":"import hashlib\nfrom io import BytesIO\nfrom PIL import Image, ImageFont, ImageDraw\nimport tensorflow as tf\n\n# Fetch attribution string from image EXIF data\ndef get_attribution(file):\n    with Image.open(file) as img:\n        exif_data = img._getexif()\n    s='Photo: unknown'\n    if exif_data is not None:\n        if 37510 in exif_data:\n            if len(exif_data[37510]) > 0:\n                s = exif_data[37510][8:].decode('ascii')\n        if 315 in exif_data:\n            if len(exif_data[315]) > 0:\n                s = 'Photo: ' + exif_data[315]\n    return s\n\ndef create_tf_example(imagedf, longest_edge=1024):\n    fname = ARTAXOR_PATH+imagedf.file.iloc[0]\n    filename=fname.split('\/')[-1] # exclude path\n    by = get_attribution(fname)\n    img = Image.open(fname, \"r\")\n    # resize image if larger that longest edge while keeping aspect ratio\n    if max(img.size) > longest_edge:\n        img.thumbnail((longest_edge, longest_edge), Image.ANTIALIAS)\n    height = img.size[1] # Image height\n    width = img.size[0] # Image width\n    buf= BytesIO()\n    img.save(buf, format= 'JPEG') # encode to jpeg in memory\n    encoded_image_data= buf.getvalue()\n    image_format = b'jpeg'\n    source_id = filename.split('.')[0]\n    license = 'CC BY-NC-SA 4.0'\n    # A hash of the image is used in some frameworks\n    key = hashlib.sha256(encoded_image_data).hexdigest()   \n    # object bounding boxes \n    xmins = imagedf.left.values # List of normalized left x coordinates in bounding box (1 per box)\n    xmaxs = imagedf.right.values # List of normalized right x coordinates in bounding box\n    ymins = imagedf.top.values # List of normalized top y coordinates in bounding box (1 per box)\n    ymaxs = imagedf.bottom.values # List of normalized bottom y coordinates in bounding box\n    # List of string class name & id of bounding box (1 per box)\n    object_cnt = len(imagedf)\n    classes_text = []\n    classes = []\n    for i in range(object_cnt):\n        classes_text.append(imagedf.label.iloc[i].encode())\n        classes.append(1+imagedf.label_idx.iloc[i])\n    # unused features from Open Image \n    depiction = np.zeros(object_cnt, dtype=int)\n    group_of = np.zeros(object_cnt, dtype=int)\n    occluded = imagedf.occluded.values #also Pascal VOC\n    truncated = imagedf.truncated.values # also Pascal VOC\n    # Pascal VOC\n    view_text = []\n    for i in range(object_cnt):\n        view_text.append('frontal'.encode())\n    difficult = np.zeros(object_cnt, dtype=int)\n\n    tf_record = tf.train.Example(features=tf.train.Features(feature={\n        'image\/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n        'image\/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n        'image\/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode()])),\n        'image\/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[source_id.encode()])),\n        'image\/license': tf.train.Feature(bytes_list=tf.train.BytesList(value=[license.encode()])),\n        'image\/by': tf.train.Feature(bytes_list=tf.train.BytesList(value=[by.encode()])),\n        'image\/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image_data])),\n        'image\/key\/sha256': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode()])),\n        'image\/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_format])),\n        'image\/object\/bbox\/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n        'image\/object\/bbox\/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n        'image\/object\/bbox\/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n        'image\/object\/bbox\/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n        'image\/object\/class\/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n        'image\/object\/class\/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n        'image\/object\/depiction': tf.train.Feature(int64_list=tf.train.Int64List(value=depiction)),\n        'image\/object\/group_of': tf.train.Feature(int64_list=tf.train.Int64List(value=group_of)),\n        'image\/object\/occluded': tf.train.Feature(int64_list=tf.train.Int64List(value=occluded)),\n        'image\/object\/truncated': tf.train.Feature(int64_list=tf.train.Int64List(value=truncated)),\n        'image\/object\/difficult': tf.train.Feature(int64_list=tf.train.Int64List(value=difficult)),\n        'image\/object\/view': tf.train.Feature(bytes_list=tf.train.BytesList(value=view_text))\n    }))\n    return tf_record","021c3b92":"with tf.io.TFRecordWriter('ArTaxOr_TestSet.tfrecord') as writer:\n    for i in range(len(df)):\n        imagedf=anno[anno.file == df.path[i]]\n        tfr=create_tf_example(imagedf)\n        writer.write(tfr.SerializeToString())","6e4732ce":"!ls -al *.tfrecord","72d4f60e":"## Metadata import\nThere are two image directories:\n* negatives: True negatives with no valid objects\n* positives: True positives with valid objects","bebbd5f9":"Extract the labels for later use:","92ee73df":"## Image resolution\nPlot the distribution of image size - there is a peak around 3Mpix.","f3982ded":"# ArTaxOr TestSet Data\nThe Arthropod Taxonomy Orders dataset is a collection of highres images annotated with labels from the taxanomy rank [order](https:\/\/en.wikipedia.org\/wiki\/Order_(biology)). Annotations have been made with [VoTT](https:\/\/github.com\/microsoft\/VoTT). VoTT stores all metadata in json files. In this kernel we will import all the metadata into DataFrames before storing it in pickled format for use by other kernels.  \nThe dataset is distributed under CC BY-NC-SA 4.0","20a301fc":"## Object data import\nWe will now import all the object data from the json files into a dataframe. In the process, we convert object positions to relative values.","ae7f2fac":"# Metadata export\nMetadata is pickled for use in other kernels. For exporting to other formats, see [Starter: Arthropod Taxonomy Orders Data Exploring](https:\/\/www.kaggle.com\/mistag\/starter-arthropod-taxonomy-orders-data-exploring)","62fe156d":"Let's check how many objects there are per label:","069311f0":"## Export TFRecord\nFinally we will export this dataset to TFRecord file."}}