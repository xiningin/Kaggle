{"cell_type":{"e92aa2f3":"code","ef962284":"code","c5472bed":"code","275581d7":"code","cd808cf9":"code","6a30ca44":"code","8a951843":"code","af845fff":"code","d34d773e":"code","8ba30291":"code","3e19db6f":"code","6a3b318d":"code","32a6d73f":"code","ff7e0f74":"code","c1a892b0":"code","104ff4af":"code","1a0072c0":"code","bb0341f4":"code","2dafcd99":"markdown","430bbeee":"markdown","c7231704":"markdown","b38cf364":"markdown","f491f8fe":"markdown","9b363592":"markdown","d39a86dc":"markdown","530a61e9":"markdown","7cd185f6":"markdown","fda7b5e1":"markdown","3e2fdced":"markdown","b15bfd58":"markdown","3cba29eb":"markdown","8703ae05":"markdown","dfde07e2":"markdown","00b060da":"markdown","05d06730":"markdown","172284fd":"markdown","9d5b748e":"markdown"},"source":{"e92aa2f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ef962284":"iris_df=pd.read_csv(\"\/kaggle\/input\/iris-flower-dataset\/IRIS.csv\")\niris_df.head()","c5472bed":"print(\"Shape of the data frame: \",iris_df.shape)\nprint(\"Total null values: \",iris_df.isna().sum().sum())\nprint(\"Duplicate values: \",iris_df.duplicated().sum() )\n\n","275581d7":"iris_df.drop_duplicates(inplace=True)\nprint(\"Shape of the data frame: \",iris_df.shape)\nprint(\"\\n\")\nprint(\"Species categories with its count \\n\",iris_df[\"species\"].value_counts())","cd808cf9":"iris_df.describe()","6a30ca44":"#iris_df.plot(kind='box')\n#plt.show()\nsns.boxplot(data=iris_df)","8a951843":"skewness_value=iris_df.skew(axis=0)\nprint(\"Measure of skewness column wise:\\n\",skewness_value)  ","af845fff":"\nkurtosis_values=iris_df.kurt(axis=0)\nprint(kurtosis_values)","d34d773e":"\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder=LabelEncoder()\niris_df[\"species\"]=label_encoder.fit_transform(iris_df[\"species\"])\nprint(iris_df.head(10))\nprint(\"\\n\")\nprint(iris_df[\"species\"].value_counts())","8ba30291":"X=iris_df.drop([\"species\"],axis=1)\nY=iris_df[\"species\"]","3e19db6f":"from sklearn.model_selection import train_test_split\nX_train1,X_test1,Y_train1,Y_test1=train_test_split(X,Y,test_size=0.2,random_state=3)","6a3b318d":"from sklearn.linear_model import LogisticRegression\nlogistic_reg=LogisticRegression()","32a6d73f":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nlogistic_reg.fit(X_train1,Y_train1)\npredicted_result1=logistic_reg.predict(X_test1)\nprint(\"Accuracy Score: \",accuracy_score(Y_test1, predicted_result1))\n\nprint(\"Confusion Matrix:\\n \",confusion_matrix(Y_test1, predicted_result1))\n\nprint(\"Classification Report:\\n \",classification_report(Y_test1, predicted_result1))","ff7e0f74":"from sklearn.model_selection import train_test_split\nX_train2,X_test2,Y_train2,Y_test2=train_test_split(X,Y,test_size=0.2,random_state=5,stratify=Y)","c1a892b0":"from sklearn.preprocessing import StandardScaler\nss=StandardScaler()\nX_train2=ss.fit_transform(X_train2)\nX_test2=ss.transform(X_test2)","104ff4af":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \nLDA=LinearDiscriminantAnalysis()\nX_train2=LDA.fit_transform(X_train2,Y_train2)\nX_test2=LDA.transform(X_test2)","1a0072c0":"from sklearn.linear_model import LogisticRegression\nLR=LogisticRegression()\nLR.fit(X_train2,Y_train2)\ny_prediction=LR.predict(X_test2)\n","bb0341f4":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nprint(\"\\n Accuracy Score:\",accuracy_score(Y_test2,y_prediction))\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(Y_test2,y_prediction))\nprint(\"Classification Report:\")\nprint(classification_report(Y_test2,y_prediction))","2dafcd99":"2. Standard Scaler","430bbeee":">  From the above result it is clear that the model is 96% accurate and f1score as 1 indicating very low false positive and false negative prediction","c7231704":"4.LG Model","b38cf364":"1.Train Test Split","f491f8fe":"# Measure of skewness\n#https:\/\/pythontic.com\/pandas\/dataframe-computations\/skew","9b363592":"# Feature Selection","d39a86dc":"> Removing the duplicated entries","530a61e9":"# Measure of kurtosis\n#https:\/\/pythontic.com\/pandas\/dataframe-computations\/kurtosis\n#https:\/\/pythontic.com\/pandas\/dataframe-computations\/kurtosis","7cd185f6":"# Data Inspection","fda7b5e1":"1. > If skewness value lies above +1 or below -1, data is highly skewed. If it lies between +0.5 to -0.5, it is moderately skewed. If the value is 0, then the data is symmetric\n1. > For Symmetric distribution, mean=median\n1. > Positively skewed data:\nIf tail is on the right as that of the second image in the figure, it is right skewed data. It is also called positive skewed data.\nCommon transformations of this data include square root, cube root, and log.\n1. > Negatively skewed data:\nIf the tail is to the left of data, then it is called left skewed data. It is also called negatively skewed data.\nCommon transformations include square , cube root and logarithmic.\n* https:\/\/medium.com\/@TheDataGyan\/day-8-data-transformation-skewness-normalization-and-much-more-4c144d370e55* ","3e2fdced":"# Accuracy prior scaling\/normalizing","b15bfd58":"# Selected model - Logistic Regression","3cba29eb":"5.Analysis","8703ae05":"\n# Implementing Scaling,LDA followed by generating a model:-","dfde07e2":"> from the above box plot it's clear \n1. sepal_width has outliers and it's right skewed\n2. petal_length and petal_with are left skewed\n3. sepal_length is symmetrical","00b060da":"# Train Test Split","05d06730":"3.LDA","172284fd":"> On comparng the mean and median values for these four paramater we can observe skewness","9d5b748e":"# Handling Categorical values\n#https:\/\/medium.com\/@contactsunny\/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621"}}