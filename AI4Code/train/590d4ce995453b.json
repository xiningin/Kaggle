{"cell_type":{"244fede3":"code","7268b287":"code","acfa10dc":"code","432e35cf":"code","2e6ec4e7":"code","8655b292":"code","80542e41":"code","9aedca04":"code","c45c3ee6":"code","95a517db":"code","9ed2ad9c":"code","efd88735":"code","a7576e6d":"code","91eabe94":"code","869ddfd7":"code","3855a786":"code","5fe99439":"code","5c76c447":"code","19ed7ad3":"code","07fd138d":"code","e79c589e":"code","808db946":"code","02c1203e":"code","26a1a5f9":"code","77baf32b":"code","7aa5f876":"code","0871939a":"code","bd5ad6e4":"code","a0208639":"markdown","cd247f31":"markdown","c20b0b61":"markdown","c3bb9718":"markdown","c21c7c67":"markdown","1a7d5c79":"markdown","149db7d8":"markdown","e3f69664":"markdown","a635e71d":"markdown","ae47f8ca":"markdown","3e8306ff":"markdown","69384890":"markdown","bd67566a":"markdown","f05b2c09":"markdown","f78f3b53":"markdown","f7c3f1e6":"markdown","254f27af":"markdown","909a1747":"markdown","87dd89bc":"markdown","e07b82aa":"markdown","60c97f56":"markdown","91469888":"markdown","9d1c2866":"markdown","a43c6c65":"markdown","ce69bc94":"markdown","103c41d9":"markdown","573a6a5d":"markdown"},"source":{"244fede3":"from tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential  \nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport re","7268b287":"df = pd.read_csv(\"..\/input\/fake-news\/train.csv\")\ndf.head()","acfa10dc":"df.info()","432e35cf":"print('Number of Rows : ', df.shape[0])\nprint('Number of Columns : ', df.shape[1])","2e6ec4e7":"df.isna().sum()","8655b292":"df = df.dropna()","80542e41":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nlength=df[df[\"label\"]==1]['title'].str.len()\nax1.hist(length,bins = 20,color='skyblue')\nax1.set_title('Fake News')\nlength=df[df[\"label\"]==0]['title'].str.len()\nax2.hist(length, bins = 20)\nax2.set_title('Real News')\nfig.suptitle('Characters in title')\nplt.show()","9aedca04":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nlength=df[df[\"label\"]==1]['text'].str.len()\nax1.hist(length,bins = 20,color='skyblue')\nax1.set_title('Fake News')\nlength=df[df[\"label\"]==0]['text'].str.len()\nax2.hist(length, bins = 20)\nax2.set_title('Real News')\nfig.suptitle('Characters in text')\nplt.show()","c45c3ee6":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nnum=df[df[\"label\"]==1]['title'].str.split().map(lambda x: len(x))\nax1.hist(num,bins = 20,color='skyblue')\nax1.set_title('Fake News')\nnum=df[df[\"label\"]==0]['title'].str.split().map(lambda x: len(x))\nax2.hist(num,bins = 20)\nax2.set_title('Real News')\nfig.suptitle('Words in title')\nplt.show()","95a517db":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nnum=df[df[\"label\"]==1]['text'].str.split().map(lambda x: len(x))\nax1.hist(num,bins = 20,color='skyblue')\nax1.set_title('Fake News')\nnum=df[df[\"label\"]==0]['text'].str.split().map(lambda x: len(x))\nax2.hist(num,bins = 20)\nax2.set_title('Real News')\nfig.suptitle('Words in text')\nplt.show()","9ed2ad9c":"print('Number of 0 (Not Fake) : ', df[\"label\"].value_counts()[0])\nprint('Number of 1 (Fake) : ', df[\"label\"].value_counts()[1])","efd88735":"label = df[\"label\"].value_counts()\nsns.barplot(label.index, label, color=\"salmon\")\nplt.title('Target Count', fontsize=14)","a7576e6d":"data = df.copy()","91eabe94":"# here we reset the index because we had drop NaN values from df\ndata.reset_index(inplace=True)","869ddfd7":"X = data['text']# Independent Variable\ny = data['label'] # Target or Dependent Variable","3855a786":"# Dataset Preprocessing\nlemmatizer = WordNetLemmatizer()\ndef text_cleaning(text):\n    text = re.sub(\"[^a-zA-Z]\", \" \", text) # removing punctuation\n    text = text.lower() # text to lowercase\n    text = text.split()\n    text = [lemmatizer.lemmatize(word) for word in text if not word in stopwords.words('english')]\n    return ' '.join(text)    ","5fe99439":"data['text'] = data['text'].apply(text_cleaning)","5c76c447":"plt.figure(figsize = (20,20)) # Text that is not Fake(0)\nwc = WordCloud(width = 1600 , height = 800 , max_words = 3000).generate(\" \".join(data[data.label == 0].text))\nplt.imshow(wc , interpolation = 'bilinear')","19ed7ad3":"plt.figure(figsize = (20,20)) # Text that is Fake(1)\nwc = WordCloud(width = 1600 , height = 800 , max_words = 3000).generate(\" \".join(data[data.label == 1].text))\nplt.imshow(wc , interpolation = 'bilinear')","07fd138d":"# Vocabulary size\n# here using one_hot method, here the word of sentence converted into particular index\nvoc_size=5000\noneHot = [ one_hot(word,voc_size) for word in data.text ]","e79c589e":"# here we used padding because here sentences are not of equal length,\n# so we used pad_sequence to make the sentence of equal length .\nsent_length = 20\npadding = pad_sequences(oneHot, padding='pre', maxlen=sent_length)\npadding[0]","808db946":"vector_feature = 40\nseq = Sequential()\nseq.add(Embedding(voc_size, vector_feature, input_length = sent_length))\nseq.add(Dropout(0.3))\nseq.add(LSTM(100))\nseq.add(Dropout(0.3))\nseq.add(Dense(1, activation = 'sigmoid'))\nseq.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nseq.summary()","02c1203e":"x_final = np.array(padding)\ny_final = np.array(y)\nprint(x_final.shape)\nprint(y_final.shape)","26a1a5f9":"# here we had split data into training and testing set\nx_train, x_test, y_train, y_test = train_test_split(x_final, y_final, test_size = 0.2, random_state = 42)","77baf32b":"seq.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=10,batch_size=64)","7aa5f876":"pred = seq.predict_classes(x_test)","0871939a":"cfm = confusion_matrix(pred, y_test)\nplt.figure(figsize = (7,5))\nsns.heatmap(cfm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='')\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")","bd5ad6e4":"print(classification_report(pred, y_test))","a0208639":"### Data Info","cd247f31":"### Title","c20b0b61":"### Divide the Dataset into Dependent and Independent Variables","c3bb9718":"### Text Cleaning\n\n#### Remove Punctuation, Stopwords and Applying WordNetLemmatizer","c21c7c67":"### One-Hot Representation","1a7d5c79":"### Embedding Representation","149db7d8":"### Confusion Matrix","e3f69664":"### Text","a635e71d":"### Number of words\n\nLet's compare the number of words in the fake news and real news and try to distinguish pattern in the fake and real news based on number of words used ","ae47f8ca":"### Text","3e8306ff":"We can see the Target column is balanced","69384890":"### Classification Report","bd67566a":"![](http:\/\/)![](http:\/\/)If you like my kernel, please feel free to UPVOTE!  Leave Comments for your suggestions.\n\nStay Tuned for More!","f05b2c09":"### Title","f78f3b53":"### Target Column","f7c3f1e6":"### Model Prediction","254f27af":"### Split Data into Train and Test Set","909a1747":"### Drop NaN Values ","87dd89bc":"## Fake News\n\n### Why Fake News is a Problem ?\n\nFake news refers to misinformation, disinformation or mal-information which is spread through word of mouth and traditional media and more recently through digital forms of communication such as edited videos, memes, unverified advertisements and social media propagated rumours.Fake news spread through social media has become a serious problem, with the potential of it resulting in mob violence, suicides etc as a result of misinformation circulated on social media.\n\n### Description of Dataset\n\nThis dataset consists of about 20000 articles consisting of fake as well as real news. Our aim is train our model so that it can correctly predict whether a given piece of news is real or fake.\n\nid: unique id for a news article<br>\ntitle: the title of a news article<br>\nauthor: author of the news article<br>\ntext: the text of the article; could be incomplete<br>\nlabel: a label that marks the article as potentially unreliable<br>\n1: unreliable<br>\n0: reliable","e07b82aa":"### Word-Cloud","60c97f56":"### Shape of Dataset","91469888":"### Number of characters\nLet's compare the number of character in the fake news and real news and try to distinguish pattern in the fake and real news based on number of charater used.","9d1c2866":"### Null Values","a43c6c65":"### Pad_Sequence","ce69bc94":"### Import Libraries","103c41d9":"### Read Dataset","573a6a5d":"### Reset Index"}}