{"cell_type":{"4c8ba347":"code","82444607":"code","27c6fc90":"code","02c7df2d":"code","c37c67c0":"code","1b1143c3":"code","524f8f27":"code","088ffce3":"code","3ae8df6d":"code","ae0751ff":"code","e2f8f994":"code","651c05ed":"code","c64acf31":"code","72467bd7":"code","6ddbc5a3":"code","09d13391":"code","b6606ab5":"code","86aea653":"code","57431886":"code","d57313a2":"code","54ef0523":"code","a74a9fd7":"code","fe5978e7":"code","0e339aff":"code","657a8989":"code","bc659c48":"code","1806c099":"code","20b0f4b4":"code","10601aac":"code","da257f02":"code","de577639":"code","7b836859":"code","3c27a765":"code","d3880f3e":"code","e017eb83":"code","dbcd4e84":"code","ee7db9c0":"code","53a62880":"code","7126ed31":"code","48698185":"code","0ef0a36d":"code","042c65fa":"code","db316fa6":"code","4999a3c5":"code","9174ac08":"code","43681c5b":"code","1309c606":"code","1d68fcb2":"code","486c9759":"code","d698f952":"code","72dc7cf0":"code","f3f37143":"code","33cf5f2d":"code","09025f8b":"code","8f5a0f39":"code","bcd2c954":"code","2105235d":"code","af61e2a4":"code","30ccebfd":"code","4abfd2f5":"code","74b69b0e":"code","b628c967":"code","c1831ef6":"code","d50d6612":"code","1202fa4d":"code","33e27765":"code","64006ce1":"code","f33376c8":"code","c6a1b533":"markdown","b3ce23ff":"markdown","9b5dd3eb":"markdown","b5d70f24":"markdown","d1f08fb6":"markdown","df8b9747":"markdown","10ea0ce3":"markdown","2358b122":"markdown","7522853f":"markdown","178e7c6d":"markdown","ff47a663":"markdown","36000e60":"markdown"},"source":{"4c8ba347":"from timeit import default_timer\nstart = default_timer()\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')","82444607":"import pandas as pd\ntag = pd.read_csv(\"..\/input\/movielens-20m-dataset\/tag.csv\")\nmovies = pd.read_csv(\"..\/input\/movielens-20m-dataset\/movie.csv\")\nrating = pd.read_csv(\"..\/input\/movielens-20m-dataset\/rating.csv\")\nlink = pd.read_csv(\"..\/input\/movielens-20m-dataset\/link.csv\")\ngenome_tags = pd.read_csv(\"..\/input\/movielens-20m-dataset\/genome_tags.csv\")\ngenome_scores = pd.read_csv(\"..\/input\/movielens-20m-dataset\/genome_scores.csv\")","27c6fc90":"tag.head(15)","02c7df2d":"tag.describe()","c37c67c0":"tag.info()","1b1143c3":"tag[\"tag\"].unique()","524f8f27":"tag[\"userId\"].unique()","088ffce3":"tag[\"movieId\"].unique()","3ae8df6d":"tag[\"timestamp\"].unique()","ae0751ff":"tag.isnull().sum()","e2f8f994":"tag.isna().sum()","651c05ed":"tag.shape","c64acf31":"tag.dtypes","72467bd7":"movies.head(15)","6ddbc5a3":"movies.describe()","09d13391":"movies.info()","b6606ab5":"movies[\"genres\"].unique()","86aea653":"movies[\"title\"].unique()","57431886":"movies.isnull().sum()","d57313a2":"movies.isna().sum()","54ef0523":"movies.dtypes","a74a9fd7":"rating.head(20)","fe5978e7":"rating.describe()","0e339aff":"rating.info()","657a8989":"rating[\"rating\"].unique()","bc659c48":"rating[\"timestamp\"].unique()","1806c099":"rating.shape","20b0f4b4":"rating.isnull().sum()","10601aac":"rating.isna().sum()","da257f02":"link.info()","de577639":"link.describe()","7b836859":"link.shape","3c27a765":"genome_tags.head(20)","d3880f3e":"genome_tags.info()","e017eb83":"genome_tags[\"tag\"].unique()","dbcd4e84":"genome_tags.shape","ee7db9c0":"genome_scores.head(20)","53a62880":"genome_scores.info()","7126ed31":"genome_scores.describe()","48698185":"genome_scores[\"movieId\"].unique()","0ef0a36d":"genome_scores[\"relevance\"].unique()","042c65fa":"rating","db316fa6":"rating_movies = rating[[\"rating\",\"timestamp\"]]\nrating_movies","4999a3c5":"#considered as high demand movies and thus more requested\nd = rating[\"rating\"]>3.5\nd","9174ac08":"d.shape","43681c5b":"st = default_timer()\n\n# First time data load.\nmovies = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\nratings = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')\n    \n# Organise a bit and store into feather-format\nmovies.sort_values(by='movieId', inplace=True)\nmovies.reset_index(inplace=True, drop=True)\nratings.sort_values(by='movieId', inplace=True)\nratings.reset_index(inplace=True, drop=True)\n\nprint(ratings.dtypes)\n\n# Split title and release year in separate columns in movies dataframe. Convert year to timestamp.\nmovies['year'] = movies.title.str.extract(\"\\((\\d{4})\\)\", expand=True)\nmovies.year = pd.to_datetime(movies.year, format='%Y')\nmovies.year = movies.year.dt.year # As there are some NaN years, resulting type will be float (decimals)\nmovies.title = movies.title.str[:-7]\n\n# Categorize movies genres properly. Working later with +20MM rows of strings proved very resource consuming\ngenres_unique = pd.DataFrame(movies.genres.str.split('|').tolist()).stack().unique()\ngenres_unique = pd.DataFrame(genres_unique, columns=['genre']) # Format into DataFrame to store later\nmovies = movies.join(movies.genres.str.get_dummies().astype(bool))\nmovies.drop('genres', inplace=True, axis=1)\n\n# Modify rating timestamp format (from seconds to datetime year)\n#ratings.timestamp = pd.to_datetime(ratings.timestamp, unit='s')\nratings.timestamp = pd.to_datetime(ratings.timestamp, infer_datetime_format=True)\nratings.timestamp = ratings.timestamp.dt.year\n\n# Check and clean NaN values\nprint (\"Number of movies Null values: \", max(movies.isnull().sum()))\nprint (\"Number of ratings Null values: \", max(ratings.isnull().sum()))\nmovies.dropna(inplace=True)\nratings.dropna(inplace=True)\n    \n# Organise a bit, then save into feather-formatand clear from memory\nmovies.sort_values(by='movieId', inplace=True)\nratings.sort_values(by='movieId', inplace=True)\nmovies.reset_index(inplace=True, drop=True)\nratings.reset_index(inplace=True, drop=True)\n    \nruntime = default_timer() - st\nprint (\"Elapsed time(sec): \", round(runtime,2))","1309c606":"st = default_timer()\n\n# Let's work with a temp smaller slice 'dftmp' of the original dataframe to reduce runtime (ratings hass +2MM rows)\ndftmp = movies[['movieId', 'year']].groupby('year')\n\nfig, ax1 = plt.subplots(figsize=(10,5))\nax1.plot(dftmp.year.first(), dftmp.movieId.nunique(), \"g-o\")\nax1.grid(None)\nax1.set_ylim(0,)\n\ndftmp = ratings[['rating', 'timestamp']].groupby('timestamp')\nax2 = ax1.twinx()\nax2.plot(dftmp.timestamp.first(), dftmp.rating.count(), \"r-o\")\nax2.grid(None)\nax2.set_ylim(0,)\n\nax1.set_xlabel('Year')\nax1.set_ylabel('Number of movies released'); ax2.set_ylabel('Number of ratings')\nplt.title('Movies per year')\nplt.show()\n\n# Housekeeping\n%reset_selective -f (^dftmp$|^ax1$|^ax2$)\n\nruntime = default_timer() - st\nprint (\"Elapsed time(sec): \", round(runtime,2))","1d68fcb2":"st = default_timer()\n\nplt.figure(figsize=(10,5))\ndftmp = movies[['movieId', 'year']].groupby('year')\ndf = pd.DataFrame({'All_movies' : dftmp.movieId.nunique().cumsum()})\n# Plot histogram for each individual genre\nfor genre in genres_unique.genre:\n    dftmp = movies[movies[genre]][['movieId', 'year']].groupby('year')\n    df[genre]=dftmp.movieId.nunique().cumsum()\ndf.fillna(method='ffill', inplace=True)\ndf.loc[:,df.columns!='All_movies'].plot.area(stacked=True, figsize=(10,5))\n# Plot histogram for all movies\nplt.plot(df['All_movies'], marker='o', markerfacecolor='black')\nplt.xlabel('Year')\nplt.ylabel('Cumulative number of movies-genre')\nplt.title('Total movies-genre') # Many movies have multiple genres, so counthere is higher than number of movies\nplt.legend(loc=(1.05,0), ncol=2)\nplt.show()\n# Plot simple scatter of the number of movies tagged with each genre\nplt.figure(figsize=(15,5))\nbarlist = df.iloc[-1].plot.bar()\nbarlist.patches[0].set_color('b') # Color 'All_movies' differently, as it's not a genre tag count\nplt.xticks(rotation='vertical')\nplt.title('Movies per genre tag')\nplt.xlabel('Genre')\nplt.ylabel('Number of movies tagged')\nplt.show()\n\n# Housekeeping\n%reset_selective -f (^barlist$|^dftmp$|^genre$)\n\nruntime = default_timer() - st\nprint (\"Elapsed time(sec): \", round(runtime,2))","486c9759":"st = default_timer()\n\ndftmp = ratings[['movieId','rating']].groupby('movieId').mean()\n\n# Initialize empty list to capture basic stats by genre\nrating_stats = []\n# Plot general histogram of all ratings\ndftmp.hist(bins=25, grid=False, edgecolor='b', label ='All genres', figsize=(10,5))\n# Plot histograms (kde lines for better visibility) per genre\nfor genre in genres_unique.genre:\n    dftmp = movies[movies[genre]==True]\n    dftmp = ratings[ratings.set_index('movieId').index.isin(dftmp.set_index('movieId').index)]\n    dftmp = dftmp[['movieId','rating']].groupby('movieId').mean()\n    dftmp.rating.plot(grid=False, alpha=0.6, kind='kde', label=genre)\n    avg = dftmp.rating.mean()\n    std = dftmp.rating.std()\n    rating_stats.append((genre, avg, std))\nplt.legend(loc=(1.05,0), ncol=2)\nplt.xlim(0,5)\nplt.xlabel('Movie rating')\nplt.title('Movie rating histograms')\nplt.show()\n\n# Housekeeping\n%reset_selective -f (^avg$|^dftmp$|^genre$|^std$)\n\nruntime = default_timer() - st\nprint (\"Elapsed time(sec): \", round(runtime,2))","d698f952":"st = default_timer()\n\n# Construct a DataFrame with all the basic stats per genre\nrating_sum = pd.DataFrame(rating_stats,  columns=['genre', 'average', 'std_dev'])\nrating_sum.set_index('genre', inplace=True)\n# Display a boxplot to show the dispersion of average and standard deviation\nbxplot = plt.boxplot(rating_sum.T, labels=['Average', 'STD'], sym=\"ro\")\n# Properly label the outliers\noutliers = []\nfor i, value in enumerate(bxplot['fliers']):\n    for val in value.get_ydata():\n        bxplot_label = rating_sum.index[rating_sum.iloc[:, i] == val][0]\n        outliers.append(bxplot_label)\n        plt.annotate(bxplot_label, xy=(i+1.1, val+np.random.uniform(-0.25,0.25))) # Trick to prevent overlapping\noutliers = set(outliers)\nplt.ylim(0,)\nplt.ylabel('Movie rating')\nplt.title('Movie rating descriptive stats')\nplt.show()\n\n# Bar chart with average rating, standard deviation and normalized number of ratings per genre\n# Calculate the normalized number of ratings per genre\nrating_sum['num_ratings_norm']=df.iloc[-1, 1:]\/df.iloc[-1, 1:].sum()\n# Calculate the average rating for all genres\nrating_sum['average_all']=rating_sum.average.mean()\n\nfig = plt.figure(figsize=(15,5))\nax = fig.add_subplot(111)\nax2 = ax.twinx()\n\nrating_sum[['average', 'std_dev']].plot(kind='bar', color=['b','r'], ax=ax, position=0.5, grid=False)\nrating_sum['average_all'].plot(kind='line',style='--', color=['black'], ax=ax, grid=False)\nrating_sum['num_ratings_norm'].plot(kind='line', color='g', ax=ax2, grid=False, linewidth=3)\n\nax.legend(loc=2)\nax2.legend(loc=1)\n\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.title('Movie rating descriptive stats')\nplt.autoscale()\nax2.set_ylim(0,)\nplt.show()\n\nprint(\"Outliers: \", outliers)\nprint(rating_sum.T)\n\n# Quick pie chart to visualize how 3 genres take almost 50% of ratings\nrating_sum.sort_values(by='num_ratings_norm', inplace=True)\nplt.pie(rating_sum['num_ratings_norm'], labels=rating_sum.T.columns, labeldistance=1.5)\nplt.show()\n\n\n# Housekeeping\n%reset_selective -f (^avg$|ax|bxplot|^df$|^dftmp$|^i$|^rating_stats$|^rating_sum$|^val$|^value$)\n\nruntime = default_timer() - st\nprint (\"Elapsed time(sec): \", round(runtime,2))","72dc7cf0":"st = default_timer()\n\ndftmp = movies[['movieId', 'year']].set_index('movieId').join(\n    ratings[['movieId','rating']].groupby('movieId').mean())\n\nplt.figure(figsize=(10,5))\nplt.plot(dftmp.year, dftmp.rating,\"g.\", markersize=4)\nplt.xlabel('Year')\nplt.ylabel('Movie average rating')\nplt.title('All movies rating')\nplt.ylim(0,)\nplt.show()\n\n# Housekeeping\n%reset_selective -f (^dftmp$)\n\nruntime = default_timer() - st\nprint (\"Elapsed time(sec): \", round(runtime,2))","f3f37143":"st = default_timer()\n\nplt.figure(figsize=(10,5))\n# For each genre\nfor genre in genres_unique.genre:\n    # Select only movies matching current genre. Pick only movieId (as index) and year.\n    dftmp = movies[movies[genre]==True][['movieId', 'year']].set_index('movieId')\n    # Selects ratings, with movieId as index. Select only movies that match also the previous step. Join both.\n    dftmp = dftmp.join(ratings[ratings.set_index('movieId').index.isin(dftmp.index)][['movieId', 'rating']]\n                       .groupby('movieId').mean())\n    # Now we have a df of movieId, year and multiple ratings. Group by year and compute the average rating.\n    dftmp = dftmp.groupby('year').mean()\n    plt.plot(dftmp, label = genre, alpha=0.7)\n\n# For all genres\ndftmp = movies[['movieId', 'year']].set_index('movieId')\ndftmp = dftmp.join(ratings[ratings.set_index('movieId').index.isin(dftmp.index)][['movieId', 'rating']]\n                   .groupby('movieId').mean())\ndftmp = dftmp.groupby('year').mean()\nplt.plot(dftmp, \"o\", label='All genres', color='red')\n\nplt.xlabel('Year')\nplt.ylabel('Rating')\nplt.title('Average rating per year per genre')\nplt.legend(loc=(1.05,0), ncol=2)\nplt.ylim(0,)\nplt.show()\n\n# Housekeeping\n%reset_selective -f (^dftmp$|^genre$)\n\nruntime = default_timer() - st\nprint (\"Elapsed time(sec): \", round(runtime,2))","33cf5f2d":"st = default_timer()\n\nplt.figure(figsize=(10,5))\nfor genre in outliers:\n    # Select only movies matching current genre. Pick only movieId (as index) and year.\n    dftmp = movies[movies[genre]==True][['movieId', 'year']].set_index('movieId')\n    # Selects ratings, with movieId as index. Select only movies that match also the previous step. Join both.\n    dftmp = dftmp.join(ratings[ratings.set_index('movieId').index.isin(dftmp.index)][['movieId', 'rating']]\n                       .groupby('movieId').mean())\n    # Now we have a df of movieId, year and multiple ratings. Group by year and compute the average rating.\n    dftmp = dftmp.groupby('year').mean()\n    plt.plot(dftmp, label = genre, alpha=0.7)\n\n# For all genres\ndftmp = movies[['movieId', 'year']].set_index('movieId')\ndftmp = dftmp.join(ratings[ratings.set_index('movieId').index.isin(dftmp.index)][['movieId', 'rating']]\n                   .groupby('movieId').mean())\ndftmp = dftmp.groupby('year').mean()\nplt.plot(dftmp, \"o\", label='All genres', color='indigo')\n    \nplt.xlabel('Year')\nplt.ylabel('Rating')\nplt.title('Average rating per year (outlier genres)')\nplt.legend(loc=(1.05,0), ncol=2)\nplt.ylim(0,)\nplt.show()\n\n# Housekeeping\n%reset_selective -f (^dftmp$|^genre$|^outliers$)\n\nruntime = default_timer() - st\nprint (\"Elapsed time(sec): \", round(runtime,2))","09025f8b":"st = default_timer()\n\ndftmp = ratings[['userId','rating']].groupby('userId').mean()\n# Plot histogram\ndftmp.plot(kind='hist', bins=50, grid=0, edgecolor='purple', figsize=(10,5))\n# Plot cumulative function on top (couldn't do any other way)\n# evaluate the histogram\nvalues, base = np.histogram(dftmp, bins=40)\n# evaluate the cumulative (multiply by the average distance between points in the x-axis to get UNIT area)\ncumulative = np.cumsum(values) * np.diff(base).mean()\n# plot the cumulative function\nplt.plot(base[:-1], cumulative, c='blue', label='CDF')\nplt.xlim(0,5)\nplt.legend()\nplt.xlabel ('Average movie rating')\nplt.ylabel ('Normalized frequency')\nplt.title ('Average ratings per user')\nplt.show()\n\n# Housekeeping\n%reset_selective -f (^dftmp$|^base$|^cumulative$|^values$)\n\nruntime = default_timer() - st\nprint (\"Elapsed time(sec): \", round(runtime,2))","8f5a0f39":"st = default_timer()\n\n# Scatter plot of all users and individual ratings count.\ndftmp = ratings[['userId', 'movieId']].groupby('movieId').count()\ndftmp.columns=['num_ratings']\nplt.figure(figsize=(15,5))\nplt.scatter(dftmp.index, dftmp.num_ratings, edgecolor='blue')\nplt.xlim(0,dftmp.index.max())\nplt.ylim(0,)\nplt.title('Ratings per movie')\nplt.xlabel('movieId')\nplt.ylabel('Number of ratings received')\nplt.show()\n\n# Histogram of ratings counts.\nplt.figure(figsize=(15,5))\nplt.hist(dftmp.num_ratings, bins=100, edgecolor='black', log=True)\nplt.title('Ratings per movie')\nplt.xlabel('Number of ratings received')\nplt.ylabel('Number of movieIds')\nplt.xlim(0,)\nplt.show()\n\n# Let's check those movies with +40k reviews, those should be pretty popular movies!\nprint(movies.set_index('movieId').loc[dftmp.index[dftmp.num_ratings>40000]]['title'])\n# Let's check the average rating too, those should be pretty good movies!\nratings.set_index('movieId').loc[dftmp.index[dftmp.num_ratings>40000]].groupby('movieId').mean().rating.plot(style='o')\nplt.ylabel('Average rating')\nplt.title('Most popular movies rating')\nplt.show()\n\n# Which is the best most popular movie ever??\ntmp = ratings.set_index('movieId').loc[dftmp.index[dftmp.num_ratings>40000]].groupby('movieId').mean()\nbest = movies.set_index('movieId').loc[tmp.rating.idxmax].title\nprint ('Best most popular movie ever is...%s' %best)\n\n# Housekeeping\n%reset_selective -f (^dftmp$|^tmp$|^best$)\n\nruntime = default_timer() - st\nprint (\"Elapsed time(sec): \", round(runtime,2))\n","bcd2c954":"rating['rating'].mean()","2105235d":"rating['rating'].max()","af61e2a4":"rating['rating'].min()","30ccebfd":"rating['rating'].median()","4abfd2f5":"ratings.corr()","74b69b0e":"a= rating['rating']<2\na.head(30)","b628c967":"rating.isnull().any().any()","c1831ef6":"tag.isnull().any().any()","d50d6612":"tag=tag.dropna()","1202fa4d":"tag.isna().any().any()","33e27765":"movies.isnull().any().any()","64006ce1":"movies.isna().any().any()","f33376c8":"c = movies.merge(rating, on='movieId', how='inner')\nc.head(20)","c6a1b533":"**rating.csv has no null values**","b3ce23ff":"# Import necessary Libraries","9b5dd3eb":"**PLOT#2**: Cumulative number of movies, in total and per genre.\n\n**INSIGHT#2**: On average, movies are categorized into 2 genres (i.e. number of movies-genres 54k doubles the number of movies 27k). Comedy 8.3k and Drama 13.3k are the top genres used.","b5d70f24":"**PLOT#1**: Number of movies and ratings per year.\n\n**INSIGHT#1**: Number of movies released per year increasing almost exponentially until 2009, then flattening and dropping signifincantly in 2014 (2015 data is incomplete). Does this confirm expontential growth (i.e. bubbles) is seldom sustainable in the long term? No ratings before 1995, likely to do with the availability of Internet to general public.","d1f08fb6":"**PLOT#5**: Average rating for all individual movies.\n\n**INSIGHT#5**: Especially after 1970, it seems there are more lower ratings, but also more higher (4.5-5.0)...it could just an effect of having more movies. Not many insights from this plot.","df8b9747":"**PLOT#6**: Average rating for all movies in each year, and also per genre.\n\n**INSIGHT#6**: Slight decline in average movie ratings after 1960, but still remains above 3. Range quite narrow, except for a few outliers.","10ea0ce3":"**PLOT#9**: Rating timestamp vs. movie year vs. rating count\n\n**INSIGHT#9**: Besides the evident insight that newer movies get more ratings, and that older movies get a number of ratings inversely proportional to their age, we can also see than the oldest movies have just received ratings very recently (2010+), implying those were not readily for users to watch available before. There's also sort of a \"block behaviour\", where at any point in time, movies with X number of ratings stop some Y years before (e.g. in 2005, there are no movies older than 1980 with +10000 ratings).","2358b122":"**PLOT#8**: Average ratings per user.\n\n**INSIGHT#8**: Users have a positive bias in general, with roughly 95% of their average ratings above the mid-point of 2.5. This is to be expected, and could have many explanations: users actually watch the better movies due to available ratings (and this should get better over time, as the rating system expands); users don't bother that much to rate bad movies as they do with the good ones (i.e. we don't want other to know we watched such a piece of s***), etc.","7522853f":"**PLOT#7**: Same as #6, but only the outliers now.\n\n**INSIGHT#7**: All the outliers present vary few occurrences: IMAX 196, Film-Noir 330, no-genre 237. In any case, Film-Noir movies are generally rated well above average, and the ones without any classification tend to do very poorly...perhaps having no genre to anchor or relate to impairs critics?.","178e7c6d":"**No null or nan values in movies.csv and tag.csv**","ff47a663":"**PLOT#3**: Distributions by genre, on top of total rating distribution. This will help identifying consistent ratings or outliers (e.g. Comedies being rated higher in general).\n\n**INSIGHT#3**: All genres show a similar pattern (right-skewed log-normal distribution??), except perhaps Horror movies which are a bit skewed to the left (poorer ratings)...people don't like being scared, no matter how good the movie is fro a technical point of view? Movies without a tagged genre (no-genres listed) are also outliers, but likely due to the low number of ocurrences.","36000e60":"# Exploratory Data Aanalysis"}}