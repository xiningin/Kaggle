{"cell_type":{"0265159d":"code","912e00e8":"code","9cdcbcf5":"code","09a36d0f":"code","85213169":"code","3c49f2bd":"code","ea7c79c0":"code","2603b0a4":"code","2b1c7d5d":"code","0413b010":"code","df0fe4d5":"code","83e742f2":"code","b3099092":"code","a0893886":"markdown"},"source":{"0265159d":"import numpy as np \nimport os\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\nimport torch\nimport torchvision.transforms as T\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets as torch_dataset\nfrom torchvision.utils import make_grid\nfrom torch import nn\nfrom torch.nn import functional as F","912e00e8":"!pip install torch-summary","9cdcbcf5":"from torchsummary import summary","09a36d0f":"img_size = 64\ndata_dir = '..\/input\/anime-faces\/data'\ndata_transforms = T.Compose([\n    T.Resize(img_size),\n    T.CenterCrop(img_size),\n    T.ToTensor(),\n    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\nanime_dataset = torch_dataset.ImageFolder(root=data_dir, transform=data_transforms)\ndataloader = DataLoader(dataset=anime_dataset, batch_size=128, shuffle=True, num_workers=4)","85213169":"dataset","3c49f2bd":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n        \ndef Conv(n_input, n_output, k_size=4, stride=2, padding=0, bn=False):\n    return nn.Sequential(\n        nn.Conv2d(\n            n_input, n_output,\n            kernel_size=k_size,\n            stride=stride,\n            padding=padding, bias=False),\n        nn.BatchNorm2d(n_output),\n        nn.LeakyReLU(0.2, inplace=True),\n        nn.Dropout(p=0.2, inplace=False))\n\ndef Deconv(n_input, n_output, k_size=4, stride=2, padding=1):\n    return nn.Sequential(\n        nn.ConvTranspose2d(\n            n_input, n_output,\n            kernel_size=k_size,\n            stride=stride, padding=padding,\n            bias=False),\n        nn.BatchNorm2d(n_output),\n        nn.ReLU(inplace=True))\n\nclass Generator(nn.Module):\n    def __init__(self, z=100, nc=64):\n        super(Generator, self).__init__()\n        self.net = nn.Sequential(\n            Deconv(z, nc*8, 4,1,0),\n            Deconv(nc*8, nc*4, 4,2,1),\n            Deconv(nc*4, nc*2, 4,2,1),\n            Deconv(nc*2, nc, 4,2,1),\n            nn.ConvTranspose2d(nc,3, 4,2,1,bias=False),\n            nn.Tanh()\n        )\n        \n    def forward(self, input):\n        return self.net(input)\n    \nclass Discriminator(nn.Module):\n    def __init__(self, nc=64):\n        super(Discriminator, self).__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(\n                3, nc,\n                kernel_size=4,\n                stride=2,\n                padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            Conv(nc, nc*2, 4,2,1),\n            Conv(nc*2, nc*4, 4,2,1),\n            Conv(nc*4, nc*8, 4,2,1),\n            nn.Conv2d(nc*8, 1,4,1,0, bias=False),\n            nn.Sigmoid())\n        \n    def forward(self, input):\n        return self.net(input)\n\ndevice = torch.device('cuda')\ndis_model = Discriminator()\ngen_model = Generator()\n\ngen_model.apply(weights_init)\ndis_model.apply(weights_init)\ndis_model.to(device)\ngen_model.to(device)\nprint('init model')","ea7c79c0":"# gen_model\n# dis_model","2603b0a4":"# summary(gen_model, (100,1,1))\n# summary(dis_model, (3, 64, 64))","2b1c7d5d":"from torch import optim\n\nreal_label = 1.\nfake_label = 0.\nlr = 0.0002\nbeta1 = 0.5\n\ncriterion = nn.BCELoss()\noptim_D = optim.Adam(dis_model.parameters(), lr=lr, betas=(beta1, 0.999))\noptim_G = optim.Adam(gen_model.parameters(), lr=lr, betas=(beta1, 0.999))","0413b010":"img_list = []\nG_losses = []\nD_losses = []\niters = 1\nepoch_nb = 30\nfixed_noise = torch.randn(32, 100, 1,1, device=device)\nD_x = 0","df0fe4d5":"from torch.distributions.uniform import Uniform\n\nfor epoch in range(epoch_nb):\n    for i, data in enumerate(dataloader):\n        # Train Discriminator\n        ## Train with real image \n        dis_model.zero_grad()\n        real_img = data[0].to(device)\n        bz = real_img.size(0)\n        \n        #  label smoothing\n        label = Uniform(0.9, 1.0).sample((bz,)).to(device)\n#         label = torch.full((bz,), real_label, device=device, dtype=torch.float)\n        \n        output = dis_model(real_img).view(-1)\n        error_real = criterion(output, label)\n        error_real.backward()\n        D_x = output.mean().item()\n        \n        ## Train with fake image \n        noise = torch.randn(bz, 100, 1,1, device=device)\n        fake_img = gen_model(noise)\n        label = Uniform(0., 0.05).sample((bz,)).to(device)\n\n        output = dis_model(fake_img.detach()).view(-1)\n        error_fake = criterion(output, label)\n        error_fake.backward()\n        D_G_z1 = output.mean().item()\n        error_D = error_real + error_fake\n#         error_D.backward()\n        optim_D.step()\n        \n        ## Train Generator\n        gen_model.zero_grad()\n#         noise = torch.randn(bz, 100, 1,1, device=device)\n#         fake_img = gen_model(noise)\n        label = Uniform(0.95, 1.0).sample((bz,)).to(device)\n        output = dis_model(fake_img).view(-1)\n        error_G = criterion(output, label)\n        error_G.backward()\n        optim_G.step()\n        D_G_z2 = output.mean().item()\n        \n        if i % 300 == 0:\n            print('[%d\/%d][%d\/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f \/ %.4f'\n                  % (epoch, epoch_nb, i, len(dataloader),\n                     error_D.item(), error_G.item(), D_x, D_G_z1, D_G_z2))\n        if epoch > 1:\n            if (iters % 1000 == 0) or ((epoch == epoch_nb-1) and (i == len(dataloader)-1)):\n                with torch.no_grad():\n                    fake_img = gen_model(fixed_noise).detach().cpu()\n                fake_img = make_grid(fake_img, padding=2, normalize=True)\n                img_list.append(fake_img)\n                plt.figure(figsize=(10,10))\n                plt.imshow(img_list[-1].permute(1,2,0))\n                plt.show()\n\n        iters += 1","83e742f2":"from matplotlib import animation\nfrom IPython.display import HTML\n\nfig = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nimgs = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\nimg_animation = animation.ArtistAnimation(fig, imgs, interval=1000, repeat_delay=100, blit=True)\nHTML(img_animation.to_jshtml())","b3099092":"img_animation.save('img_animation.gif', writer='imagemagick', fps=3)","a0893886":"# Train model"}}