{"cell_type":{"3efa8293":"code","807f3161":"code","009fbf05":"code","298d7c15":"code","b7fb12c6":"code","ac7bb6a7":"code","255797f4":"code","5ae1736b":"code","e49149cc":"code","0ec1a9ff":"code","de46e387":"code","14f52ad8":"code","02149594":"code","b3e6cbf6":"code","1d216c72":"code","a2bd5e60":"markdown","0920d3ff":"markdown","5b89ef08":"markdown","5849fa7e":"markdown","356f5a49":"markdown","3661e28f":"markdown","733956d6":"markdown","5eb308d8":"markdown","f5f538b8":"markdown","f56d42b1":"markdown","723c8bc6":"markdown","426882db":"markdown","49ea217b":"markdown","bb8cf9e1":"markdown","50e8c4fc":"markdown"},"source":{"3efa8293":"import numpy as np\nimport pandas as pd\n\nimport os\nimport pickle\nimport glob\nimport matplotlib.pyplot as plt\nimport time\nimport keras\nimport imageio\nfrom scipy import signal\nfrom keras.models import load_model\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.metrics import mean_absolute_error as MAE\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import roc_curve, auc\nfrom skimage.transform import resize\nfrom matplotlib.lines import Line2D\nimport matplotlib.patches as mpatches\nimport matplotlib.gridspec as gridspec\nfrom mpl_toolkits.axes_grid1.inset_locator import inset_axes","807f3161":"save_figures = False\nfile_ending = '.png'\nmodel_string = 'NMDA'\n\ndataset_folder = '\/kaggle\/input\/single-neurons-as-deep-nets-nmda-test-data'\n\nmodels_folder     = os.path.join(dataset_folder, 'Models')\nmorphology_folder = os.path.join(dataset_folder, 'Morphology')\ntest_data_folder  = os.path.join(dataset_folder, 'Data_test')\nauxiliary_folder  = os.path.join(dataset_folder, 'Auxiliary')\n\nmodel_filename           = os.path.join(models_folder, 'NMDA_TCN__DWT_7_128_153__model.h5')\nmodel_metadata_filename  = os.path.join(models_folder, 'NMDA_TCN__DWT_7_128_153__training.pickle')\nmorphology_filename      = os.path.join(morphology_folder, 'morphology_dict.pickle')\nNN_illustration_filename = os.path.join(auxiliary_folder, 'TCN_7_layers.png')\ntest_files               = sorted(glob.glob(os.path.join(test_data_folder, '*_128_simulationRuns*_6_secDuration_*')))\n\nprint('-----------------------------------------------')\nprint('finding files: model, morphology and test data')\nprint('-----------------------------------------------')\nprint('model found          : \"%s\"' %(model_filename.split('\/')[-1]))\nprint('model metadata found : \"%s\"' %(model_metadata_filename.split('\/')[-1]))\nprint('morphology found     : \"%s\"' %(morphology_filename.split('\/')[-1]))\nprint('number of test files is %d' %(len(test_files)))\nprint('-----------------------------------------------')","009fbf05":"##%% helper functions\n\ndef bin2dict(bin_spikes_matrix):\n    spike_row_inds, spike_times = np.nonzero(bin_spikes_matrix)\n    row_inds_spike_times_map = {}\n    for row_ind, syn_time in zip(spike_row_inds,spike_times):\n        if row_ind in row_inds_spike_times_map.keys():\n            row_inds_spike_times_map[row_ind].append(syn_time)\n        else:\n            row_inds_spike_times_map[row_ind] = [syn_time]\n\n    return row_inds_spike_times_map\n\n\ndef dict2bin(row_inds_spike_times_map, num_segments, sim_duration_ms):\n    \n    bin_spikes_matrix = np.zeros((num_segments, sim_duration_ms), dtype='bool')\n    for row_ind in row_inds_spike_times_map.keys():\n        for spike_time in row_inds_spike_times_map[row_ind]:\n            bin_spikes_matrix[row_ind,spike_time] = 1.0\n    \n    return bin_spikes_matrix\n\ndef parse_sim_experiment_file(sim_experiment_file):\n    \n    print('-----------------------------------------------------------------')\n    print(\"loading file: '\" + sim_experiment_file.split(\"\\\\\")[-1] + \"'\")\n    loading_start_time = time.time()\n    experiment_dict = pickle.load(open(sim_experiment_file, \"rb\" ), encoding='latin1')\n    \n    # gather params\n    num_simulations = len(experiment_dict['Results']['listOfSingleSimulationDicts'])\n    num_segments    = len(experiment_dict['Params']['allSegmentsType'])\n    sim_duration_ms = experiment_dict['Params']['totalSimDurationInSec'] * 1000\n    num_ex_synapses  = num_segments\n    num_inh_synapses = num_segments\n    num_synapses = num_ex_synapses + num_inh_synapses\n    \n    # collect X, y_spike, y_soma\n    X = np.zeros((num_synapses,sim_duration_ms,num_simulations), dtype='bool')\n    y_spike = np.zeros((sim_duration_ms,num_simulations), dtype=np.float32)\n    y_soma  = np.zeros((sim_duration_ms,num_simulations), dtype=np.float32)\n    for k, sim_dict in enumerate(experiment_dict['Results']['listOfSingleSimulationDicts']):\n        X_ex  = dict2bin(sim_dict['exInputSpikeTimes'] , num_segments, sim_duration_ms)\n        X_inh = dict2bin(sim_dict['inhInputSpikeTimes'], num_segments, sim_duration_ms)\n        X[:,:,k] = np.vstack((X_ex,X_inh))\n        spike_times = (sim_dict['outputSpikeTimes'].astype(float) - 0.5).astype(int)\n        y_spike[spike_times,k] = 1.0\n        y_soma[:,k] = sim_dict['somaVoltageLowRes']\n\n    loading_duration_sec = time.time() - loading_start_time \n    print('loading took %.3f seconds' %(loading_duration_sec))\n    print('-----------------------------------------------------------------')\n\n    return X, y_spike, y_soma\n\n\ndef parse_multiple_sim_experiment_files(sim_experiment_files):\n    \n    for k, sim_experiment_file in enumerate(sim_experiment_files):\n        X_curr, y_spike_curr, y_soma_curr = parse_sim_experiment_file(sim_experiment_file)\n        \n        if k == 0:\n            X       = X_curr\n            y_spike = y_spike_curr\n            y_soma  = y_soma_curr\n        else:\n            X       = np.dstack((X,X_curr))\n            y_spike = np.hstack((y_spike,y_spike_curr))\n            y_soma  = np.hstack((y_soma,y_soma_curr))\n\n    return X, y_spike, y_soma\n\n\ndef calc_AUC_at_desired_FP(y_test, y_test_hat, desired_false_positive_rate=0.01):\n    fpr, tpr, thresholds = roc_curve(y_test.ravel(), y_test_hat.ravel())\n\n    linear_spaced_FPR = np.linspace(0,1,num=20000)\n    linear_spaced_TPR = np.interp(linear_spaced_FPR, fpr, tpr)\n    \n    desired_fp_ind = min(max(1,np.argmin(abs(linear_spaced_FPR-desired_false_positive_rate))),linear_spaced_TPR.shape[0]-1)\n    \n    return linear_spaced_TPR[:desired_fp_ind].mean()\n\n\ndef calc_TP_at_desired_FP(y_test, y_test_hat, desired_false_positive_rate=0.0025):\n    fpr, tpr, thresholds = roc_curve(y_test.ravel(), y_test_hat.ravel())\n    \n    desired_fp_ind = np.argmin(abs(fpr-desired_false_positive_rate))\n    if desired_fp_ind == 0:\n        desired_fp_ind = 1\n\n    return tpr[desired_fp_ind]\n\n\ndef exctract_key_results(y_spikes_GT, y_spikes_hat, y_soma_GT, y_soma_hat, desired_FP_list=[0.0025,0.0100]):\n    \n    # evaluate the model and save the results\n    print('----------------------------------------------------------------------------------------')\n    print('calculating key results...')\n    \n    evaluation_start_time = time.time()\n    \n    # store results in the hyper param dict and return it\n    evaluations_results_dict = {}\n    \n    for desired_FP in desired_FP_list:\n        TP_at_desired_FP  = calc_TP_at_desired_FP(y_spikes_GT, y_spikes_hat, desired_false_positive_rate=desired_FP)\n        AUC_at_desired_FP = calc_AUC_at_desired_FP(y_spikes_GT, y_spikes_hat, desired_false_positive_rate=desired_FP)\n        print('-----------------------------------')\n        print('TP  at %.4f FP rate = %.4f' %(desired_FP, TP_at_desired_FP))\n        print('AUC at %.4f FP rate = %.4f' %(desired_FP, AUC_at_desired_FP))\n        TP_key_string = 'TP @ %.4f FP' %(desired_FP)\n        evaluations_results_dict[TP_key_string] = TP_at_desired_FP\n    \n        AUC_key_string = 'AUC @ %.4f FP' %(desired_FP)\n        evaluations_results_dict[AUC_key_string] = AUC_at_desired_FP\n    \n    print('--------------------------------------------------')\n    fpr, tpr, thresholds = roc_curve(y_spikes_GT.ravel(), y_spikes_hat.ravel())\n    AUC_score = auc(fpr, tpr)\n    print('AUC = %.4f' %(AUC_score))\n    print('--------------------------------------------------')\n    \n    soma_explained_variance_percent = 100.0*explained_variance_score(y_soma_GT.ravel(),y_soma_hat.ravel())\n    soma_RMSE = np.sqrt(MSE(y_soma_GT.ravel(),y_soma_hat.ravel()))\n    soma_MAE  = MAE(y_soma_GT.ravel(),y_soma_hat.ravel())\n    \n    print('--------------------------------------------------')\n    print('soma explained_variance percent = %.2f%s' %(soma_explained_variance_percent, '%'))\n    print('soma RMSE = %.3f [mV]' %(soma_RMSE))\n    print('soma MAE = %.3f [mV]' %(soma_MAE))\n    print('--------------------------------------------------')\n    \n    evaluations_results_dict['AUC'] = AUC_score\n    evaluations_results_dict['soma_explained_variance_percent'] = soma_explained_variance_percent\n    evaluations_results_dict['soma_RMSE'] = soma_RMSE\n    evaluations_results_dict['soma_MAE'] = soma_MAE\n    \n    evaluation_duration_min = (time.time() - evaluation_start_time)\/60\n    print('finished evaluation. time took to evaluate results is %.2f minutes' %(evaluation_duration_min))\n    print('----------------------------------------------------------------------------------------')\n    \n    return evaluations_results_dict\n\n\ndef filter_and_exctract_key_results(y_spikes_GT, y_spikes_hat, y_soma_GT, y_soma_hat, desired_FP_list=[0.0025,0.0100], \n                                                                                      ignore_time_at_start_ms=500, \n                                                                                      num_spikes_per_sim=[0,24]):\n\n    time_points_to_eval = np.arange(y_spikes_GT.shape[1]) >= ignore_time_at_start_ms\n    simulations_to_eval = np.logical_and((y_spikes_GT.sum(axis=1) >= num_spikes_per_sim[0]),(y_spikes_GT.sum(axis=1) <= num_spikes_per_sim[1]))\n    \n    print('total amount of simualtions is %d' %(y_spikes_GT.shape[0]))\n    print('percent of simulations kept = %.2f%s' %(100*simulations_to_eval.mean(),'%'))\n    \n    y_spikes_GT_to_eval  = y_spikes_GT[simulations_to_eval,:][:,time_points_to_eval]\n    y_spikes_hat_to_eval = y_spikes_hat[simulations_to_eval,:][:,time_points_to_eval]\n    y_soma_GT_to_eval    = y_soma_GT[simulations_to_eval,:][:,time_points_to_eval]\n    y_soma_hat_to_eval   = y_soma_hat[simulations_to_eval,:][:,time_points_to_eval]\n    \n    return exctract_key_results(y_spikes_GT_to_eval, y_spikes_hat_to_eval, y_soma_GT_to_eval, y_soma_hat_to_eval, desired_FP_list=desired_FP_list)\n\n\ndef draw_weights(first_layer_weights, selected_filter_ind, set_ylabel, ax00,ax10, ax01,ax11, ax02,ax12):\n\n    time_span, _, num_filters = first_layer_weights.shape\n    \n    weight_granularity = 0.06\n    time_granularity = 20\n    max_time_to_show = 40\n    \n    if use_filtered:\n        first_layer_weights_filtered = signal.convolve(first_layer_weights, (1.0\/filter_size)*np.ones((filter_size,1,1)), mode='valid')\n        first_layer_weights = first_layer_weights_filtered\n    \n    if first_layer_weights.shape[0] >= max_time_to_show:\n        first_layer_weights = first_layer_weights[:max_time_to_show]\n    \n    num_segments =  639\n    basal_cutoff =  262\n    tuft_cutoff  = [366,559]\n\n    # invert if needed\n    exc_sum = first_layer_weights[:12,:num_segments,selected_filter_ind].sum()\n    inh_sum = first_layer_weights[:12,num_segments:,selected_filter_ind].sum()\n    exc_minus_inh = exc_sum - inh_sum\n    \n    if exc_minus_inh < 0:\n        first_layer_weights = -first_layer_weights\n    \n    upper_limit = max(np.percentile(abs(first_layer_weights[:,:,selected_filter_ind]),99.95),np.percentile(abs(first_layer_weights[:,:,selected_filter_ind]),0.05))\n    xlims = [-5*int(first_layer_weights.shape[0]\/5),0]\n    \n    ex_basal_syn_inds    = np.arange(basal_cutoff)\n    ex_oblique_syn_inds  = np.hstack((np.arange(basal_cutoff,tuft_cutoff[0]),np.arange(tuft_cutoff[1],num_segments)))\n    ex_tuft_syn_inds     = np.arange(tuft_cutoff[0],tuft_cutoff[1])\n    inh_basal_syn_inds   = num_segments + ex_basal_syn_inds\n    inh_oblique_syn_inds = num_segments + ex_oblique_syn_inds\n    inh_tuft_syn_inds    = num_segments + ex_tuft_syn_inds\n    \n    basal_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_basal_syn_inds,selected_filter_ind].T)\n    basal_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_basal_syn_inds,selected_filter_ind].T)\n    basal_weights_example_filter     = np.concatenate((basal_weights_example_filter_ex,basal_weights_example_filter_inh),axis=0)\n    oblique_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_oblique_syn_inds,selected_filter_ind].T)\n    oblique_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_oblique_syn_inds,selected_filter_ind].T)\n    oblique_weights_example_filter     = np.concatenate((oblique_weights_example_filter_ex, oblique_weights_example_filter_inh),axis=0)\n    tuft_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_tuft_syn_inds,selected_filter_ind].T)\n    tuft_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_tuft_syn_inds,selected_filter_ind].T)\n    tuft_weights_example_filter     = np.concatenate((tuft_weights_example_filter_ex,tuft_weights_example_filter_inh),axis=0)\n    \n    time_axis = -np.arange(first_layer_weights.shape[0])\n    \n    ##%% create nice figure\n    figure_xlims = xlims\n    figure_xlims[0] = max(-40, figure_xlims[0])\n    \n    ex_basal_syn_inds    = np.arange(basal_cutoff)\n    ex_oblique_syn_inds  = np.hstack((np.arange(basal_cutoff,tuft_cutoff[0]),np.arange(tuft_cutoff[1],num_segments)))\n    ex_tuft_syn_inds     = np.arange(tuft_cutoff[0],tuft_cutoff[1])\n    inh_basal_syn_inds   = num_segments + ex_basal_syn_inds\n    inh_oblique_syn_inds = num_segments + ex_oblique_syn_inds\n    inh_tuft_syn_inds    = num_segments + ex_tuft_syn_inds\n    \n    basal_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_basal_syn_inds,selected_filter_ind].T)\n    basal_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_basal_syn_inds,selected_filter_ind].T)\n    basal_weights_example_filter     = np.concatenate((basal_weights_example_filter_ex,basal_weights_example_filter_inh),axis=0)\n    oblique_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_oblique_syn_inds,selected_filter_ind].T)\n    oblique_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_oblique_syn_inds,selected_filter_ind].T)\n    oblique_weights_example_filter     = np.concatenate((oblique_weights_example_filter_ex, oblique_weights_example_filter_inh),axis=0)\n    tuft_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_tuft_syn_inds,selected_filter_ind].T)\n    tuft_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_tuft_syn_inds,selected_filter_ind].T)\n    tuft_weights_example_filter     = np.concatenate((tuft_weights_example_filter_ex,tuft_weights_example_filter_inh),axis=0)\n    \n    combined_filter = np.concatenate((basal_weights_example_filter_ex,oblique_weights_example_filter_ex,tuft_weights_example_filter_ex,\n                                      basal_weights_example_filter_inh,oblique_weights_example_filter_inh,tuft_weights_example_filter_inh),axis=0)\n    \n    ##%% draw 2 x 3 (basal,oblique,tuft) matrix\n    ex_basal_syn_inds    = np.arange(basal_cutoff)\n    ex_oblique_syn_inds  = np.hstack((np.arange(basal_cutoff,tuft_cutoff[0]),np.arange(tuft_cutoff[1],num_segments)))\n    ex_tuft_syn_inds     = np.arange(tuft_cutoff[0],tuft_cutoff[1])\n    inh_basal_syn_inds   = num_segments + ex_basal_syn_inds\n    inh_oblique_syn_inds = num_segments + ex_oblique_syn_inds\n    inh_tuft_syn_inds    = num_segments + ex_tuft_syn_inds\n    \n    basal_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_basal_syn_inds,selected_filter_ind].T)\n    basal_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_basal_syn_inds,selected_filter_ind].T)\n    basal_weights_example_filter     = np.concatenate((basal_weights_example_filter_ex,basal_weights_example_filter_inh),axis=0)\n    oblique_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_oblique_syn_inds,selected_filter_ind].T)\n    oblique_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_oblique_syn_inds,selected_filter_ind].T)\n    oblique_weights_example_filter     = np.concatenate((oblique_weights_example_filter_ex, oblique_weights_example_filter_inh),axis=0)\n    tuft_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_tuft_syn_inds,selected_filter_ind].T)\n    tuft_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_tuft_syn_inds,selected_filter_ind].T)\n    tuft_weights_example_filter     = np.concatenate((tuft_weights_example_filter_ex,tuft_weights_example_filter_inh),axis=0)\n    \n    time_axis = -np.arange(first_layer_weights.shape[0])\n    \n    upper_limit = max(np.percentile(abs(first_layer_weights[:,:,selected_filter_ind]),99.8),np.percentile(abs(first_layer_weights[:,:,selected_filter_ind]),0.2))\n    weights_ylims = np.array([-1.08,1.08]) * upper_limit\n    \n    weight_ticks_lims = (np.array(weights_ylims)\/weight_granularity).astype(int) * weight_granularity\n    \n    ax00.axis('off')\n    ax01.axis('off')\n    ax02.axis('off')\n    \n    # basal\n    weights_images = ax00.imshow(resize(basal_weights_example_filter, (combined_filter.shape[0], 200)),\n                                 cmap='jet', vmin=weights_ylims[0],vmax=weights_ylims[1], aspect='auto')\n    ax00.set_xticks([])\n    ax00.set_ylabel('Synaptic index', fontsize=xylabels_fontsize)\n    for ytick_label in ax00.get_yticklabels():\n        ytick_label.set_fontsize(xytick_labels_fontsize)\n    \n    ax_colorbar = inset_axes(ax00, width=\"67%\", height=\"6%\", loc=2)\n    cbar = plt.colorbar(weights_images, cax=ax_colorbar, orientation=\"horizontal\", ticks=[weight_ticks_lims[0], 0, weight_ticks_lims[1]])\n    ax_colorbar.xaxis.set_ticks_position(\"bottom\")\n    cbar.ax.tick_params(labelsize=xytick_labels_fontsize-2)\n    ax00.text(10, 190, 'Weight (A.U)', color='k', fontsize=xytick_labels_fontsize+1, ha='left', va='top', rotation='horizontal')\n    \n    ax10.plot(time_axis, np.fliplr(basal_weights_example_filter_ex).T , c='r', alpha=all_traces_alpha)\n    ax10.plot(time_axis, np.mean(np.fliplr(basal_weights_example_filter_ex).T, axis=1) , c='r', lw=mean_linewidth)\n    ax10.plot(time_axis, np.fliplr(basal_weights_example_filter_inh).T, c='b', alpha=all_traces_alpha)\n    ax10.plot(time_axis, np.mean(np.fliplr(basal_weights_example_filter_inh).T, axis=1) , c='b', lw=mean_linewidth)\n    \n    ax10.set_xlim(time_axis.min(),time_axis.max())\n    ax10.set_ylim(weights_ylims[0],weights_ylims[1])\n    if set_ylabel:\n        ax10.set_ylabel('Weight (A.U)', fontsize=xylabels_fontsize)\n    \n    time_ticks_to_show = np.unique((np.array(time_axis)\/time_granularity).astype(int) * time_granularity)\n    ax10.set_xticks(time_ticks_to_show)\n    \n    weights_axis = np.linspace(weights_ylims[0],weights_ylims[1],10)\n    weight_ticks_to_show = np.unique((np.array(weights_axis)\/weight_granularity).astype(int) * weight_granularity)\n    ax10.set_yticks(weight_ticks_to_show)\n    \n    \n    ax10.spines['top'].set_visible(False)\n    ax10.spines['right'].set_visible(False)\n    \n    for ytick_label in ax10.get_yticklabels():\n        ytick_label.set_fontsize(xytick_labels_fontsize)\n    for xtick_label in ax10.get_xticklabels():\n        xtick_label.set_fontsize(xytick_labels_fontsize)\n    \n    # oblique\n    weights_images = ax01.imshow(resize(oblique_weights_example_filter, (combined_filter.shape[0], 200)),\n                                 cmap='jet', vmin=weights_ylims[0],vmax=weights_ylims[1], aspect='auto')\n    ax01.set_xticks([])\n    ax01.set_ylabel('Synaptic index', fontsize=xylabels_fontsize)\n    for ytick_label in ax01.get_yticklabels():\n        ytick_label.set_fontsize(xytick_labels_fontsize)\n    \n    ax11.plot(time_axis, np.fliplr(oblique_weights_example_filter_ex).T , c='r', alpha=all_traces_alpha)\n    ax11.plot(time_axis, np.mean(np.fliplr(oblique_weights_example_filter_ex).T, axis=1) , c='r', lw=mean_linewidth)\n    ax11.plot(time_axis, np.fliplr(oblique_weights_example_filter_inh).T, c='b', alpha=all_traces_alpha)\n    ax11.plot(time_axis, np.mean(np.fliplr(oblique_weights_example_filter_inh).T, axis=1) , c='b', lw=mean_linewidth)\n    \n    ax11.set_xlim(time_axis.min(),time_axis.max())\n    ax11.set_xlabel('Time before $t_0$ (ms)', fontsize=xylabels_fontsize);\n    ax11.set_ylim(weights_ylims[0],weights_ylims[1])\n    \n    time_ticks_to_show = np.unique((np.array(time_axis)\/time_granularity).astype(int) * time_granularity)\n    ax11.set_xticks(time_ticks_to_show)\n    \n    ax11.spines['top'].set_visible(False)\n    ax11.spines['right'].set_visible(False)\n    ax11.spines['left'].set_visible(False)\n    \n    ax11.set_yticks([])\n    for ytick_label in ax11.get_yticklabels():\n        ytick_label.set_fontsize(xytick_labels_fontsize)\n    for xtick_label in ax11.get_xticklabels():\n        xtick_label.set_fontsize(xytick_labels_fontsize)\n        \n    # tuft\n    #weights_images = ax02.imshow(tuft_weights_example_filter,cmap='jet', aspect='auto')\n    weights_images = ax02.imshow(resize(tuft_weights_example_filter, (combined_filter.shape[0], 200)),\n                                 cmap='jet', vmin=weights_ylims[0],vmax=weights_ylims[1], aspect='auto')\n    ax02.set_xticks([])\n    ax02.set_ylabel('Synaptic index', fontsize=xylabels_fontsize)\n    for ytick_label in ax02.get_yticklabels():\n        ytick_label.set_fontsize(xytick_labels_fontsize)\n    \n    ax12.plot(time_axis, np.fliplr(tuft_weights_example_filter_ex).T , c='r', alpha=all_traces_alpha)\n    ax12.plot(time_axis, np.mean(np.fliplr(tuft_weights_example_filter_ex).T, axis=1) , c='r', lw=mean_linewidth)\n    ax12.plot(time_axis, np.fliplr(tuft_weights_example_filter_inh).T, c='b', alpha=all_traces_alpha)\n    ax12.plot(time_axis, np.mean(np.fliplr(tuft_weights_example_filter_inh).T, axis=1) , c='b', lw=mean_linewidth)\n    \n    ax12.set_xlim(time_axis.min(),time_axis.max())\n    ax12.set_ylim(weights_ylims[0],weights_ylims[1])\n    ax12.set_yticks([])\n    \n    time_ticks_to_show = np.unique((np.array(time_axis)\/time_granularity).astype(int) * time_granularity)\n    ax12.set_xticks(time_ticks_to_show)\n    \n    ax12.spines['top'].set_visible(False)\n    ax12.spines['right'].set_visible(False)\n    ax12.spines['left'].set_visible(False)\n    \n    for ytick_label in ax12.get_yticklabels():\n        ytick_label.set_fontsize(xytick_labels_fontsize)\n    for xtick_label in ax12.get_xticklabels():\n        xtick_label.set_fontsize(xytick_labels_fontsize)\n","298d7c15":"#%% load test dataset\n\nprint('------------------------------------------------------------------------------------')\nprint('loading testing files...')\ntest_file_loading_start_time = time.time()\n\nv_threshold = -55\n\n# kaggle RAM only permits 6 files to be loaded at the same time, so we select only 6 \n# (the 6th file was slected specifically to contain the trace from Figure 2 that was used in the paper)\ntest_files = test_files[:5] + [test_files[10]]\n\nprint('-------------')\nprint('will be loading the following files:')\n[print(x) for x in test_files]\nprint('-------------')\n\n# load test data\nX_test , y_spike_test , y_soma_test  = parse_multiple_sim_experiment_files(test_files)\ny_soma_test[y_soma_test > v_threshold] = v_threshold\n\ntest_file_loading_duration_min = (time.time() - test_file_loading_start_time)\/60\nprint('time took to load data is %.3f minutes' %(test_file_loading_duration_min))\nprint('------------------------------------------------------------------------------------')","b7fb12c6":"##%% load morphology\n\nmorphology_dict = pickle.load(open(morphology_filename, \"rb\" ), encoding='latin1')\n\nallSectionsLength                  = morphology_dict['all_sections_length']\nallSections_DistFromSoma           = morphology_dict['all_sections_distance_from_soma']\nallSegmentsLength                  = morphology_dict['all_segments_length']\nallSegmentsType                    = morphology_dict['all_segments_type']\nallSegments_DistFromSoma           = morphology_dict['all_segments_distance_from_soma']\nallSegments_SectionDistFromSoma    = morphology_dict['all_segments_section_distance_from_soma']\nallSegments_SectionInd             = morphology_dict['all_segments_section_index']\nallSegments_seg_ind_within_sec_ind = morphology_dict['all_segments_segment_index_within_section_index']\n\nall_basal_section_coords  = morphology_dict['all_basal_section_coords']\nall_basal_segment_coords  = morphology_dict['all_basal_segment_coords']\nall_apical_section_coords = morphology_dict['all_apical_section_coords']\nall_apical_segment_coords = morphology_dict['all_apical_segment_coords']\n\n# show some colored DVTs with morphology colored with same segment color and soma voltage at the bottom\nlist_of_basal_section_inds  = np.unique(sorted([x[0] for x in list(all_basal_segment_coords.keys())]))\nlist_of_apical_section_inds = np.unique(sorted([x[0] for x in list(all_apical_segment_coords.keys())]))\n\nseg_ind_to_xyz_coords_map = {}\nseg_ind_to_sec_ind_map = {}\nfor k in range(len(allSegmentsType)):\n    curr_segment_ind = allSegments_seg_ind_within_sec_ind[k]\n    if allSegmentsType[k] == 'basal':\n        curr_section_ind = allSegments_SectionInd[k]\n        seg_ind_to_xyz_coords_map[k] = all_basal_segment_coords[(curr_section_ind,curr_segment_ind)]\n        seg_ind_to_sec_ind_map[k] = ('basal', curr_section_ind)\n    elif allSegmentsType[k] == 'apical':\n        curr_section_ind = allSegments_SectionInd[k] - len(list_of_basal_section_inds)\n        seg_ind_to_xyz_coords_map[k] = all_apical_segment_coords[(curr_section_ind,curr_segment_ind)]\n        seg_ind_to_sec_ind_map[k] = ('apical', curr_section_ind)\n    else:\n        print('error!')\n\n# plot 3 color image of the morphology\nplt.close('all')\n\nnum_segments =  639\nbasal_cutoff =  262\ntuft_cutoff  = [366,559]\n\napical_color = 'g'\noblique_color = 'orange'\nbasal_color = 'm'\n\nbasal_syn_inds    = np.arange(basal_cutoff)\noblique_syn_inds  = np.hstack((np.arange(basal_cutoff,tuft_cutoff[0]),np.arange(tuft_cutoff[1],num_segments)))\ntuft_syn_inds     = np.arange(tuft_cutoff[0],tuft_cutoff[1])\n\nall_basal_section_inds   = np.unique([seg_ind_to_sec_ind_map[x][1] for x in basal_syn_inds])\nall_oblique_section_inds = np.unique([seg_ind_to_sec_ind_map[x][1] for x in oblique_syn_inds])\nall_tuft_section_inds    = np.unique([seg_ind_to_sec_ind_map[x][1] for x in tuft_syn_inds])\n\n# remove overlaping sections if any\nall_oblique_section_inds = np.array(list(set(all_oblique_section_inds) - set(all_tuft_section_inds)))\n\n# collect all basal, oblique, tuft segments\nwidth_mult_factor = 1.2\n\nplt.figure(figsize=(8,11))\n\n# basal segments\nfor key in basal_syn_inds:\n    line_width = width_mult_factor*np.array(seg_ind_to_xyz_coords_map[key]['d']).mean()\n    plt.plot(seg_ind_to_xyz_coords_map[key]['x'],seg_ind_to_xyz_coords_map[key]['y'],lw=line_width,color=basal_color)\n\n# oblique segments\nfor key in oblique_syn_inds:\n    line_width = width_mult_factor*np.array(seg_ind_to_xyz_coords_map[key]['d']).mean()\n    plt.plot(seg_ind_to_xyz_coords_map[key]['x'],seg_ind_to_xyz_coords_map[key]['y'],lw=line_width,color=oblique_color)\n\n# tuft segments\nfor key in tuft_syn_inds:\n    line_width = width_mult_factor*np.array(seg_ind_to_xyz_coords_map[key]['d']).mean()\n    plt.plot(seg_ind_to_xyz_coords_map[key]['x'],seg_ind_to_xyz_coords_map[key]['y'],lw=line_width,color=apical_color)\n\n# add black soma    \nplt.scatter(x=46.0,y=15.8,s=180,c='k', zorder=100)\nplt.xlim(-180,235)\nplt.ylim(-210,1200)\nplt.axis('off')\n\nsave_figures = False\nif save_figures:\n    figure_name = '%s__morphology' %(model_dir.split('\/')[-2])\n    file_ending = '.png'\n    plt.savefig(output_figures_dir + figure_name + file_ending, bbox_inches='tight')\n","ac7bb6a7":"##%% load TCN model\n\nprint('------------------------------------------------------------------------------------')\nprint('loading model \"%s\"' %(model_filename.split('\/')[-1]))\n\nmodel_loading_start_time = time.time()\n\ntemporal_conv_net = load_model(model_filename)\ntemporal_conv_net.summary()\n\ninput_window_size = temporal_conv_net.input_shape[1]\n\n# load metadata pickle file\nmodel_metadata_dict = pickle.load(open(model_metadata_filename, \"rb\" ), encoding='latin1')\n\narchitecture_dict = model_metadata_dict['architecture_dict']\ntime_window_T = (np.array(architecture_dict['filter_sizes_per_layer']) - 1).sum() + 1\noverlap_size = min(max(time_window_T+1, min(150, input_window_size-50)),250)\n\nprint('overlap_size = %d' %(overlap_size))\nprint('time_window_T = %d' %(time_window_T))\nprint('input shape: %s' %(str(temporal_conv_net.get_input_shape_at(0))))\n\nmodel_loading_duration_min = (time.time() - model_loading_start_time)\/60\nprint('time took to load model is %.3f minutes' %(model_loading_duration_min))\nprint('------------------------------------------------------------------------------------')","255797f4":"##%% create spike predictions on test set\n\nprint('------------------------------------------------------------------------------------')\nprint('predicting using model...')\n\nprediction_start_time = time.time()\n\ny_train_soma_bias = -67.7\n\nX_test_for_TCN = np.transpose(X_test,axes=[2,1,0])\ny1_test_for_TCN = y_spike_test.T[:,:,np.newaxis]\ny2_test_for_TCN = y_soma_test.T[:,:,np.newaxis] - y_train_soma_bias\n\ny1_test_for_TCN_hat = np.zeros(y1_test_for_TCN.shape)\ny2_test_for_TCN_hat = np.zeros(y2_test_for_TCN.shape)\n\nnum_test_splits = int(2 + (X_test_for_TCN.shape[1] - input_window_size) \/ (input_window_size - overlap_size))\n\nfor k in range(num_test_splits):\n    start_time_ind = k*(input_window_size - overlap_size)\n    end_time_ind   = start_time_ind + input_window_size\n    \n    curr_X_test_for_TCN = X_test_for_TCN[:,start_time_ind:end_time_ind,:]\n    \n    if curr_X_test_for_TCN.shape[1] < input_window_size:\n        padding_size = input_window_size - curr_X_test_for_TCN.shape[1]\n        X_pad = np.zeros((curr_X_test_for_TCN.shape[0],padding_size,curr_X_test_for_TCN.shape[2]))\n        curr_X_test_for_TCN = np.hstack((curr_X_test_for_TCN,X_pad))\n        \n    curr_y1_test_for_TCN, curr_y2_test_for_TCN, _ = temporal_conv_net.predict(curr_X_test_for_TCN)\n\n    if k == 0:\n        y1_test_for_TCN_hat[:,:end_time_ind,:] = curr_y1_test_for_TCN\n        y2_test_for_TCN_hat[:,:end_time_ind,:] = curr_y2_test_for_TCN\n    elif k == (num_test_splits-1):\n        t0 = start_time_ind + overlap_size\n        duration_to_fill = y1_test_for_TCN_hat.shape[1] - t0\n        y1_test_for_TCN_hat[:,t0:,:] = curr_y1_test_for_TCN[:,overlap_size:(overlap_size+duration_to_fill),:]\n        y2_test_for_TCN_hat[:,t0:,:] = curr_y2_test_for_TCN[:,overlap_size:(overlap_size+duration_to_fill),:]\n    else:\n        t0 = start_time_ind + overlap_size\n        y1_test_for_TCN_hat[:,t0:end_time_ind,:] = curr_y1_test_for_TCN[:,overlap_size:,:]\n        y2_test_for_TCN_hat[:,t0:end_time_ind,:] = curr_y2_test_for_TCN[:,overlap_size:,:]\n\n# zero score the prediction and align it with the actual test\ns_dst = y2_test_for_TCN.std()\nm_dst = y2_test_for_TCN.mean()\n\ns_src = y2_test_for_TCN_hat.std()\nm_src = y2_test_for_TCN_hat.mean()\n\ny2_test_for_TCN_hat = (y2_test_for_TCN_hat - m_src)\/s_src\ny2_test_for_TCN_hat = s_dst*y2_test_for_TCN_hat + m_dst\n\n# convert to simple (num_simulations, num_time_points) format\ny_spikes_GT  = y1_test_for_TCN[:,:,0]\ny_spikes_hat = y1_test_for_TCN_hat[:,:,0]\ny_soma_GT    = y2_test_for_TCN[:,:,0]\ny_soma_hat   = y2_test_for_TCN_hat[:,:,0]\n\nprediction_duration_min = (time.time() - prediction_start_time)\/60\nprint('finished prediction. time took to predict is %.2f minutes' %(prediction_duration_min))\nprint('------------------------------------------------------------------------------------')","5ae1736b":"##%% evaluate the model and save the results\n\nprint('----------------------------------------------------------------------------------------')\nprint('calculating key accuracy results...')\n\nsaving_start_time = time.time()\n\ndesired_FP_list = [0.0001, 0.0005, 0.0010, 0.0015, 0.0020, 0.0025, 0.0050, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.1000]\nevaluations_results_dict = {}\n\nignore_time_at_start_ms = 500  # ignore everything that happens in the first 500ms since it's \"warmup time of the simulation\"\nnum_spikes_per_sim = [0,24]    # limit the number of output spikes per simulation (used for more correct comparison with AMPA model)\nfilter_string = 'starting_at_%dms_spikes_in_[%d,%d]_range' %(ignore_time_at_start_ms, num_spikes_per_sim[0], num_spikes_per_sim[1])\nevaluations_results_dict[filter_string] = filter_and_exctract_key_results(y_spikes_GT, y_spikes_hat, y_soma_GT, y_soma_hat, \n                                                                          desired_FP_list=desired_FP_list, \n                                                                          ignore_time_at_start_ms=ignore_time_at_start_ms, \n                                                                          num_spikes_per_sim=num_spikes_per_sim)\n\nmodel_metadata_dict['evaluations_results_dict'] = evaluations_results_dict\n\nprint('---------------------------')\nprint('main results:')\nprint('---------------------------')\nprint('TP @ 0.0025 FP = %.3f' %(evaluations_results_dict['starting_at_500ms_spikes_in_[0,24]_range']['TP @ 0.0025 FP']))\nprint('spikes AUC = %.4f' %(evaluations_results_dict['starting_at_500ms_spikes_in_[0,24]_range']['AUC']))\nprint('soma explained var = %.2f%s' %(evaluations_results_dict['starting_at_500ms_spikes_in_[0,24]_range']['soma_explained_variance_percent'],'%'))\nprint('soma RMSE = %.3f [mV]' %(evaluations_results_dict['starting_at_500ms_spikes_in_[0,24]_range']['soma_RMSE']))\nprint('soma MAE = %.3f [mV]' %(evaluations_results_dict['starting_at_500ms_spikes_in_[0,24]_range']['soma_MAE']))\nprint('---------------------------')\n\nsaving_duration_min = (time.time() - saving_start_time)\/60\nprint('time took to calculate key prediction accuracy results is %.3f minutes' %(saving_duration_min))\nprint('----------------------------------------------------------------------------------------')\n","e49149cc":"##%% plot the evaluation figures:\n# (1) ROC curve of binary prediction\n# (2) cross correlation between prediction and GT (illustrating the temporal accuracy of the prediction) \n# (3) voltage prediction scatter plot\n\nplt.close('all')\n\nignore_time_at_start_ms = 500\nnum_spikes_per_sim = [0,24]\n\nxytick_labels_fontsize = 18\ntitle_fontsize = 29\nxylabels_fontsize = 22\nlegend_fontsize = 18\n\nfig = plt.figure(figsize=(10,11));\n\ntime_points_to_eval = np.arange(y_spikes_GT.shape[1]) >= ignore_time_at_start_ms\nsimulations_to_eval = np.logical_and((y_spikes_GT.sum(axis=1) >= num_spikes_per_sim[0]),(y_spikes_GT.sum(axis=1) <= num_spikes_per_sim[1]))\n\nprint('total amount of simualtions is %d' %(y_spikes_GT.shape[0]))\nprint('percent of simulations kept = %.2f%s' %(100*simulations_to_eval.mean(),'%'))\n\ny_spikes_GT_to_eval  = y_spikes_GT[simulations_to_eval,:][:,time_points_to_eval]\ny_spikes_hat_to_eval = y_spikes_hat[simulations_to_eval,:][:,time_points_to_eval]\ny_soma_GT_to_eval    = y_soma_GT[simulations_to_eval,:][:,time_points_to_eval]\ny_soma_hat_to_eval   = y_soma_hat[simulations_to_eval,:][:,time_points_to_eval]\n\n\n# ROC curve\ndesired_false_positive_rate = 0.002\n\nfpr, tpr, thresholds = roc_curve(y_spikes_GT_to_eval.ravel(), y_spikes_hat_to_eval.ravel())\n\ndesired_fp_ind = np.argmin(abs(fpr-desired_false_positive_rate))\nif desired_fp_ind == 0:\n    desired_fp_ind = 1\nactual_false_positive_rate = fpr[desired_fp_ind]\n\nAUC_score = auc(fpr, tpr)\n\nprint('AUC = %.4f' %(AUC_score))\nprint('at %.4f FP rate, TP = %.4f' %(actual_false_positive_rate, tpr[desired_fp_ind]))\n\n\n# cross correlation\nhalf_time_window_size_ms = 50\n\ndesired_threshold = thresholds[desired_fp_ind]\nground_truth_output_spikes = y_spikes_GT_to_eval\npredicted_output_spikes    = y_spikes_hat_to_eval > desired_threshold\nnum_test_traces            = y_spikes_GT_to_eval.shape[0]\n\nzero_padding_matrix = np.zeros((num_test_traces,half_time_window_size_ms))\npredicted_output_spikes_padded    = np.hstack((zero_padding_matrix,predicted_output_spikes,zero_padding_matrix))\nground_truth_output_spikes_padded = np.hstack((zero_padding_matrix,ground_truth_output_spikes,zero_padding_matrix))\n\nrecall_curve = np.zeros(1+2*half_time_window_size_ms)\ntrace_inds, spike_inds = np.nonzero(ground_truth_output_spikes_padded)\nfor trace_ind, spike_ind in zip(trace_inds,spike_inds):\n    recall_curve += predicted_output_spikes_padded[trace_ind,spike_ind-half_time_window_size_ms:1+spike_ind+half_time_window_size_ms]\nrecall_curve \/= recall_curve.sum()\n\nfilter_cross_corr = True\nif filter_cross_corr:\n    cc_filter_size = 2\n    recall_curve_filtered = signal.convolve(recall_curve, (1.0\/cc_filter_size)*np.ones(cc_filter_size), mode='same')\n    recall_curve = 0.5*recall_curve + 0.5*recall_curve_filtered\n\ntime_axis_cc = np.arange(-half_time_window_size_ms, half_time_window_size_ms+1)\n\n\n# voltage scatter plot\nnum_datapoints_in_scatter = 20000\n\nselected_datapoints = np.random.choice(range(len(y_soma_GT_to_eval.ravel())),size=num_datapoints_in_scatter,replace=False)\nselected_GT = y_soma_GT_to_eval.ravel()[selected_datapoints] + 0.02*np.random.randn(num_datapoints_in_scatter) + y_train_soma_bias\nselected_pred = y_soma_hat_to_eval.ravel()[selected_datapoints] + y_train_soma_bias\n\nsoma_explained_variance_percent = 100.0*explained_variance_score(y_soma_GT_to_eval.ravel(), y_soma_hat_to_eval.ravel())\nsoma_RMSE = np.sqrt(MSE(y_soma_GT_to_eval.ravel(), y_soma_hat_to_eval.ravel()))\nsoma_MAE  = MAE(y_soma_GT_to_eval.ravel(), y_soma_hat_to_eval.ravel())\n\nprint('soma voltage prediction explained variance = %.2f%s' %(soma_explained_variance_percent,'%'))\n\n\ngs2 = gridspec.GridSpec(5,2)\ngs2.update(left=0.15, right=0.85, bottom=0.15, top=0.88, wspace=0.58, hspace=1.1)\na33_left  = plt.subplot(gs2[:2,0])\na33_right = plt.subplot(gs2[:2,1])\nax34      = plt.subplot(gs2[2:,:])\n\n\n# ROC curve\na33_left.plot(fpr, tpr, c='k'); \na33_left.set_xlabel('False alarm rate', fontsize=xylabels_fontsize); \na33_left.set_ylabel('Hit rate', fontsize=xylabels_fontsize);\na33_left.set_ylim(0,1.05);\na33_left.set_xlim(-0.03,1);\n\na33_left.spines['top'].set_visible(False)\na33_left.spines['right'].set_visible(False)\n\nfor tick_label in (a33_left.get_xticklabels() + a33_left.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\na33_left.set_xticks([0.0,0.5,1.0])\na33_left.set_yticks([0.0,0.5,1.0])\n\nleft, bottom, width, height = [0.264, 0.68, 0.14, 0.15]\na33_left_inset = fig.add_axes([left, bottom, width, height])\na33_left_inset.plot(fpr, tpr, c='k'); \na33_left_inset.set_ylim(0,1.05);\na33_left_inset.set_xlim(-0.001,0.05);\na33_left_inset.spines['top'].set_visible(False)\na33_left_inset.spines['right'].set_visible(False)\n\na33_left_inset.scatter(actual_false_positive_rate, tpr[desired_fp_ind+1], c='r', s=100); \n\n\n## cross correlation curve ( P( predicted spikes | ground truth==spike) )\nmax_firing_rate = 10*int(max(1000*recall_curve)\/10)\nmidpoint_firing_rate = 5*int(max_firing_rate\/10)\na33_right.set_yticks([0,midpoint_firing_rate,max_firing_rate])\n\na33_right.plot(time_axis_cc, 1000*recall_curve, c='k'); \na33_right.set_ylim(0,1.05*1000*recall_curve.max());\na33_right.set_xlabel('$\\Delta t$ (ms)', fontsize=xylabels_fontsize)\na33_right.set_ylabel('spike rate (Hz)', fontsize=xylabels_fontsize)\na33_right.set_xticks([-50,0,50])\na33_right.spines['top'].set_visible(False)\na33_right.spines['right'].set_visible(False)\n\nfor tick_label in (a33_right.get_xticklabels() + a33_right.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\n\n\n# voltage scatter plot\nsoma_voltage_lims = np.round([np.percentile(selected_GT,0.2),np.percentile(selected_GT,99.8)]).astype(int)\nsoma_voltage_lims = np.round([np.percentile(selected_GT,0.2),-56]).astype(int)\nvoltage_granularity = 6\nvoltage_setpoint = -57\nvoltage_axis = np.arange(soma_voltage_lims[0],soma_voltage_lims[1])\nvoltage_ticks_to_show = np.unique(((voltage_axis-voltage_setpoint)\/voltage_granularity).astype(int) * voltage_granularity + voltage_setpoint)\nvoltage_ticks_to_show = voltage_ticks_to_show[np.logical_and(voltage_ticks_to_show >= soma_voltage_lims[0], \n                                                             voltage_ticks_to_show <= soma_voltage_lims[1])]\nax34.set_xticks(voltage_ticks_to_show)\nax34.set_yticks(voltage_ticks_to_show)\n\nax34.scatter(selected_GT,selected_pred, s=1.0, alpha=0.8)\nax34.set_xlabel('L5PC (%s) (mV)' %(model_string), fontsize=xylabels_fontsize); \nax34.set_ylabel('ANN (mV)', fontsize=xylabels_fontsize);\nax34.set_xlim(soma_voltage_lims[0],soma_voltage_lims[1]);\nax34.set_ylim(soma_voltage_lims[0],soma_voltage_lims[1]);\n\nax34.plot([-90,-50],[-90,-50], ls='-', c='k')\n\nax34.spines['top'].set_visible(False)\nax34.spines['right'].set_visible(False)\n\nfor tick_label in (ax34.get_xticklabels() + ax34.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\nif save_figures:\n    figure_name = '%s__model_evaluation' %(models_folder.split('\/')[-2])\n    plt.savefig(output_figures_dir + figure_name + file_ending, bbox_inches='tight')\n","0ec1a9ff":"#%% show prediction trace\n\nnum_spikes_per_simulation = y1_test_for_TCN.sum(axis=1)[:,0]\npossible_presentable_candidates = np.nonzero(np.logical_and(num_spikes_per_simulation >= 3, num_spikes_per_simulation <= 10))[0]\n\nselected_trace = np.random.choice(possible_presentable_candidates)\nzoomin_fraction = [0.25+0.23*np.random.rand(),0.52+0.23*np.random.rand()]\n\n# selected_trace  = 128\n# zoomin_fraction = [0.61,0.85]\n\nselected_trace  = 673\nzoomin_fraction = [0.34,0.65]\n\nprint('selected trace = %d' %(selected_trace))\nprint('zoomin_fraction = %s' %(zoomin_fraction))\nprint('at %.4f FP rate, TP = %.4f' %(actual_false_positive_rate, tpr[desired_fp_ind]))\n\nspike_trace_GT   = y1_test_for_TCN[selected_trace,:,0]\nspike_trace_pred = y1_test_for_TCN_hat[selected_trace,:,0] > desired_threshold\n\noutput_spike_times_in_ms_GT   = np.nonzero(spike_trace_GT)[0]\noutput_spike_times_in_ms_pred = np.nonzero(spike_trace_pred)[0]\n\nsoma_voltage_trace_GT   = y2_test_for_TCN[selected_trace,:,0] + y_train_soma_bias\nsoma_voltage_trace_pred = y2_test_for_TCN_hat[selected_trace,:,0] + y_train_soma_bias\n\nsoma_voltage_trace_GT[output_spike_times_in_ms_GT] = 40\nsoma_voltage_trace_pred[output_spike_times_in_ms_pred] = 40\n\nsim_duration_ms = spike_trace_GT.shape[0]\n\n# show raster plot and cell output\ntime_in_sec = np.arange(sim_duration_ms) \/ 1000.0\nsim_duration_ms = spike_trace_GT.shape[0]\nsim_duration_sec = int(sim_duration_ms \/ 1000.0)\n\nxytick_labels_fontsize = 16\ntitle_fontsize = 26\nxylabels_fontsize = 19\nlegend_fontsize = 15\n\nplt.close('all')\nfig = plt.figure(figsize=(17,8));\n\ngs1 = gridspec.GridSpec(2,1)\ngs1.update(left=0.05, right=0.95, bottom=0.05, top=0.95, wspace=0.01, hspace=0.01)\n\nax11 = plt.subplot(gs1[0,0])\nax12 = plt.subplot(gs1[1,0])\nax11.axis('off')\nax12.axis('off')\n\n\nax11.plot(time_in_sec,soma_voltage_trace_GT,c='c')\nax11.plot(time_in_sec,soma_voltage_trace_pred,c='m',linestyle=':')\nax11.set_xlim(0,sim_duration_sec)\nax11.set_ylabel('$V_m$ (mV)', fontsize=xylabels_fontsize);\n\nfor tick_label in (ax11.get_xticklabels() + ax11.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\nzoomout_scalebar_xloc = 0.95*sim_duration_sec\n\n\nzoomin_xlims = [zoomin_fraction[0]*sim_duration_sec, zoomin_fraction[1]*sim_duration_sec]\nzoomin_dur_sec = zoomin_xlims[1] - zoomin_xlims[0]\nzoomin_time_in_sec = np.logical_and(time_in_sec >= zoomin_xlims[0], time_in_sec <= zoomin_xlims[1])\nzoomin_ylims = [soma_voltage_trace_GT[zoomin_time_in_sec].min()-2.5,-52]\nzoomin_scalebar_xloc = zoomin_xlims[1] - 0.05*zoomin_dur_sec\n\nax12.plot(time_in_sec,soma_voltage_trace_GT,c='c')\nax12.plot(time_in_sec,soma_voltage_trace_pred,c='m',linestyle=':')\nax12.set_xlim(zoomin_xlims[0],zoomin_xlims[1])\nax12.set_ylim(zoomin_ylims[0],zoomin_ylims[1])\nax12.set_ylabel('$V_m$ (mV)', fontsize=xylabels_fontsize);\nax12.set_xlabel('time (sec)', fontsize=xylabels_fontsize);\n\nfor tick_label in (ax12.get_xticklabels() + ax12.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\n\n# add scale bar to top plot\nscalebar_loc = np.array([zoomout_scalebar_xloc,-25])\nscalebar_size_x = 0.6\nscalebar_str_x = '600 ms'\nscalebar_size_y = 40\nscalebar_str_y = '40 mV'\n\nx = [scalebar_loc[0], scalebar_loc[0] - scalebar_size_x]\ny = [scalebar_loc[1], scalebar_loc[1]]\nax11.plot(x,y,lw=2,c='k')\nax11.text(scalebar_loc[0] - 0.05*scalebar_size_x, scalebar_loc[1] - 0.15*scalebar_size_y, \n          scalebar_str_x, color='k', fontsize=15, ha='right', va='top', rotation='horizontal')\n\nx = [scalebar_loc[0], scalebar_loc[0]]\ny = [scalebar_loc[1], scalebar_loc[1] + scalebar_size_y]\nax11.plot(x,y,lw=2,c='k')\nax11.text(scalebar_loc[0] + 0.1*scalebar_size_x, scalebar_loc[1] + 0.6*scalebar_size_y, \n          scalebar_str_y, color='k', fontsize=15, ha='left', va='top', rotation='horizontal')\n\n\n# add dashed rectangle\nrect_w = zoomin_xlims[1] - zoomin_xlims[0]\nrect_h = zoomin_ylims[1] - zoomin_ylims[0]\nrect_bl_x = zoomin_xlims[0]\nrect_bl_y = zoomin_ylims[0]\ndashed_rectangle = mpatches.Rectangle((rect_bl_x,rect_bl_y),rect_w,rect_h,linewidth=2,edgecolor='k',linestyle='--',facecolor='none')\n\nax11.add_patch(dashed_rectangle)\n\n\n# add scalebar to bottom plot\nscalebar_loc = np.array([zoomin_scalebar_xloc,-60])\nscalebar_size_x = 0.06\nscalebar_str_x = '60 ms'\nscalebar_size_y = 5\nscalebar_str_y = '5 mV'\n\nx = [scalebar_loc[0], scalebar_loc[0] - scalebar_size_x]\ny = [scalebar_loc[1], scalebar_loc[1]]\nax12.plot(x,y,lw=2,c='k')\nax12.text(scalebar_loc[0] - 0.15*scalebar_size_x, scalebar_loc[1] - 0.15*scalebar_size_y, \n          scalebar_str_x, color='k', fontsize=15, ha='right', va='top', rotation='horizontal')\n\nx = [scalebar_loc[0], scalebar_loc[0]]\ny = [scalebar_loc[1], scalebar_loc[1] + scalebar_size_y]\nax12.plot(x,y,lw=2,c='k')\nax12.text(scalebar_loc[0] + 0.1*scalebar_size_x, scalebar_loc[1] + 0.6*scalebar_size_y, \n          scalebar_str_y, color='k', fontsize=15, ha='left', va='top', rotation='horizontal')\n\nif save_figures:\n    figure_name = '%s__single_prediction_trace_%d' %(model_dir.split('\/')[-2], selected_trace)\n    plt.savefig(output_figures_dir + figure_name + file_ending, bbox_inches='tight')\n","de46e387":"#%% show several prediction traces \n\nnum_subplots = 5\n\nxytick_labels_fontsize = 16\ntitle_fontsize = 26\nxylabels_fontsize = 19\nlegend_fontsize = 15\n\nnum_spikes_per_simulation = y1_test_for_TCN.sum(axis=1)[:,0]\npossible_presentable_candidates = np.nonzero(np.logical_and(num_spikes_per_simulation >= 3, num_spikes_per_simulation <= 15))[0]\nselected_traces = np.random.choice(possible_presentable_candidates, size=num_subplots)\n\nplt.close('all')\nfig, ax = plt.subplots(nrows=num_subplots, ncols=1, figsize=(20,30))\nfig.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.95, wspace=0.01, hspace=0.01)\nfor k, selected_trace in enumerate(selected_traces):\n    \n    spike_trace_GT   = y1_test_for_TCN[selected_trace,:,0]\n    spike_trace_pred = y1_test_for_TCN_hat[selected_trace,:,0] > desired_threshold\n    \n    output_spike_times_in_ms_GT   = np.nonzero(spike_trace_GT)[0]\n    output_spike_times_in_ms_pred = np.nonzero(spike_trace_pred)[0]\n    \n    soma_voltage_trace_GT   = y2_test_for_TCN[selected_trace,:,0] + y_train_soma_bias\n    soma_voltage_trace_pred = y2_test_for_TCN_hat[selected_trace,:,0] + y_train_soma_bias\n    \n    soma_voltage_trace_GT[output_spike_times_in_ms_GT] = 40\n    soma_voltage_trace_pred[output_spike_times_in_ms_pred] = 40\n        \n    ax[k].axis('off')\n    ax[k].plot(time_in_sec,soma_voltage_trace_GT,c='c')\n    ax[k].plot(time_in_sec,soma_voltage_trace_pred,c='m',linestyle=':')\n    ax[k].set_xlim(0.02,sim_duration_sec)\n    ax[k].set_ylabel('$V_m$ (mV)', fontsize=xylabels_fontsize);\n    for tick_label in (ax11.get_xticklabels() + ax11.get_yticklabels()):\n        tick_label.set_fontsize(xytick_labels_fontsize)\n    \n    if k == int(num_subplots\/2):\n        # add scale bar to top plot\n        scalebar_loc = np.array([zoomout_scalebar_xloc,-25])\n        scalebar_size_x = 0.6\n        scalebar_str_x = '600 ms'\n        scalebar_size_y = 40\n        scalebar_str_y = '40 mV'\n        \n        x = [scalebar_loc[0], scalebar_loc[0] - scalebar_size_x]\n        y = [scalebar_loc[1], scalebar_loc[1]]\n        ax[k].plot(x,y,lw=2,c='k')\n        ax[k].text(scalebar_loc[0] - 0.05*scalebar_size_x, scalebar_loc[1] - 0.15*scalebar_size_y, \n                   scalebar_str_x, color='k', fontsize=15, ha='right', va='top', rotation='horizontal')\n        \n        x = [scalebar_loc[0], scalebar_loc[0]]\n        y = [scalebar_loc[1], scalebar_loc[1] + scalebar_size_y]\n        ax[k].plot(x,y,lw=2,c='k')\n        ax[k].text(scalebar_loc[0] + 0.1*scalebar_size_x, scalebar_loc[1] + 0.6*scalebar_size_y, \n                   scalebar_str_y, color='k', fontsize=15, ha='left', va='top', rotation='horizontal')\n\nif save_figures:\n    figure_name = '%s__multiple_prediction_traces_%d' %(model_dir.split('\/')[-2], np.random.randint(10))\n    plt.savefig(output_figures_dir + figure_name + file_ending, bbox_inches='tight')","14f52ad8":"#%% show all first layer learned weights\n\nfirst_layer_weights = temporal_conv_net.get_weights()[0]\ntime_span, _, num_filters = first_layer_weights.shape\n\nylims = np.array([-1.01,1.01]) * max(abs(first_layer_weights.max()),abs(first_layer_weights.min()))\n\nif time_span <= 50:\n    max_num_plots_per_figure = 32\nelif time_span <= 100:\n    max_num_plots_per_figure = 24\nelse:\n    max_num_plots_per_figure = 16\n    \ntotal_num_figures = int(np.ceil(num_filters\/float(max_num_plots_per_figure)))\n\nfor fig_ind in range(total_num_figures):\n    start_filter_to_show = fig_ind * max_num_plots_per_figure\n    end_filter_to_show   = min(num_filters, start_filter_to_show + max_num_plots_per_figure)\n\n    filters_to_show = list(range(start_filter_to_show,end_filter_to_show))\n\n    plt.figure(figsize=(34,17));\n    for k, filter_ind in enumerate(filters_to_show):\n        plt.subplot(1,len(filters_to_show),k+1); plt.title('filter %d' %(filter_ind))\n        plt.imshow(first_layer_weights[:,:,filter_ind].T,cmap='jet'); \n        plt.axis('off')\n    plt.tight_layout()\n","02149594":"#%% show selected filter in depth and temporal profile as well\n\nplt.close('all');\n\n# NMDA 7x128x153\ninteresting_filters = [8,17,25,37,52,54,59,66,71,89,91,93,96,114]\nselected_filter_ind = np.random.choice(interesting_filters)\nselected_filter_ind = 89\nfilter_size = 2\n\nfirst_layer_weights = np.flip(temporal_conv_net.get_weights()[0], axis=0)\ntime_span, _, num_filters = first_layer_weights.shape\n\nweight_granularity = 0.06\ntime_granularity = 20\n\nmax_time_to_show = 40\n\nuse_filtered = True\n#use_filtered = False\nif use_filtered:\n    first_layer_weights_filtered = signal.convolve(first_layer_weights, (1.0\/filter_size)*np.ones((filter_size,1,1)), mode='valid')\n    first_layer_weights = first_layer_weights_filtered\n\nif first_layer_weights.shape[0] >= max_time_to_show:\n    first_layer_weights = first_layer_weights[:max_time_to_show]\n\n# invert if needed\nexc_sum = first_layer_weights[:12,:num_segments,selected_filter_ind].sum()\ninh_sum = first_layer_weights[:12,num_segments:,selected_filter_ind].sum()\nexc_minus_inh = exc_sum - inh_sum\n\nif exc_minus_inh < 0:\n    first_layer_weights = -first_layer_weights\n\n\nupper_limit = max(np.percentile(abs(first_layer_weights[:,:,selected_filter_ind]),99.95),np.percentile(abs(first_layer_weights[:,:,selected_filter_ind]),0.05))\nylims = np.array([-1.06,1.06]) * upper_limit\nxlims = [-5*int(first_layer_weights.shape[0]\/5),0]\n\nnum_segments =  639\nbasal_cutoff =  262\ntuft_cutoff  = [366,559]\n\nex_basal_syn_inds    = np.arange(basal_cutoff)\nex_oblique_syn_inds  = np.hstack((np.arange(basal_cutoff,tuft_cutoff[0]),np.arange(tuft_cutoff[1],num_segments)))\nex_tuft_syn_inds     = np.arange(tuft_cutoff[0],tuft_cutoff[1])\ninh_basal_syn_inds   = num_segments + ex_basal_syn_inds\ninh_oblique_syn_inds = num_segments + ex_oblique_syn_inds\ninh_tuft_syn_inds    = num_segments + ex_tuft_syn_inds\n\nbasal_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_basal_syn_inds,selected_filter_ind].T)\nbasal_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_basal_syn_inds,selected_filter_ind].T)\nbasal_weights_example_filter     = np.concatenate((basal_weights_example_filter_ex,basal_weights_example_filter_inh),axis=0)\noblique_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_oblique_syn_inds,selected_filter_ind].T)\noblique_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_oblique_syn_inds,selected_filter_ind].T)\noblique_weights_example_filter     = np.concatenate((oblique_weights_example_filter_ex, oblique_weights_example_filter_inh),axis=0)\ntuft_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_tuft_syn_inds,selected_filter_ind].T)\ntuft_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_tuft_syn_inds,selected_filter_ind].T)\ntuft_weights_example_filter     = np.concatenate((tuft_weights_example_filter_ex,tuft_weights_example_filter_inh),axis=0)\n\ntime_axis = -np.arange(first_layer_weights.shape[0])\n\n##%% create nice figure\nex_basal_color    = 'red'\nex_oblique_color  = 'darkorange'\nex_tuft_color     = 'yellow'\ninh_basal_color   = 'darkblue'\ninh_oblique_color = 'blue'\ninh_tuft_color    = 'skyblue'\n\ncmap = plt.cm.coolwarm\n\ncustom_lines = [Line2D([0], [0], color=ex_basal_color, lw=4),\n                Line2D([0], [0], color=ex_oblique_color, lw=4),\n                Line2D([0], [0], color=ex_tuft_color, lw=4),\n                Line2D([0], [0], color=inh_basal_color, lw=4),\n                Line2D([0], [0], color=inh_oblique_color, lw=4),\n                Line2D([0], [0], color=inh_tuft_color, lw=4)]\n\n\nall_traces_alpha = 0.08\nmean_linewidth = 4.0\n\nfigure_xlims = xlims\nfigure_xlims[0] = max(-40, figure_xlims[0])\n\n\nex_basal_syn_inds    = np.arange(basal_cutoff)\nex_oblique_syn_inds  = np.hstack((np.arange(basal_cutoff,tuft_cutoff[0]),np.arange(tuft_cutoff[1],num_segments)))\nex_tuft_syn_inds     = np.arange(tuft_cutoff[0],tuft_cutoff[1])\ninh_basal_syn_inds   = num_segments + ex_basal_syn_inds\ninh_oblique_syn_inds = num_segments + ex_oblique_syn_inds\ninh_tuft_syn_inds    = num_segments + ex_tuft_syn_inds\n\nbasal_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_basal_syn_inds,selected_filter_ind].T)\nbasal_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_basal_syn_inds,selected_filter_ind].T)\nbasal_weights_example_filter     = np.concatenate((basal_weights_example_filter_ex,basal_weights_example_filter_inh),axis=0)\noblique_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_oblique_syn_inds,selected_filter_ind].T)\noblique_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_oblique_syn_inds,selected_filter_ind].T)\noblique_weights_example_filter     = np.concatenate((oblique_weights_example_filter_ex, oblique_weights_example_filter_inh),axis=0)\ntuft_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_tuft_syn_inds,selected_filter_ind].T)\ntuft_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_tuft_syn_inds,selected_filter_ind].T)\ntuft_weights_example_filter     = np.concatenate((tuft_weights_example_filter_ex,tuft_weights_example_filter_inh),axis=0)\n\n\ncombined_filter = np.concatenate((basal_weights_example_filter_ex,oblique_weights_example_filter_ex,tuft_weights_example_filter_ex,\n                                  basal_weights_example_filter_inh,oblique_weights_example_filter_inh,tuft_weights_example_filter_inh),axis=0)\n\n\n##%% draw 2 x 3 (basal,oblique,tuft) matrix\nex_basal_syn_inds    = np.arange(basal_cutoff)\nex_oblique_syn_inds  = np.hstack((np.arange(basal_cutoff,tuft_cutoff[0]),np.arange(tuft_cutoff[1],num_segments)))\nex_tuft_syn_inds     = np.arange(tuft_cutoff[0],tuft_cutoff[1])\ninh_basal_syn_inds   = num_segments + ex_basal_syn_inds\ninh_oblique_syn_inds = num_segments + ex_oblique_syn_inds\ninh_tuft_syn_inds    = num_segments + ex_tuft_syn_inds\n\nbasal_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_basal_syn_inds,selected_filter_ind].T)\nbasal_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_basal_syn_inds,selected_filter_ind].T)\nbasal_weights_example_filter     = np.concatenate((basal_weights_example_filter_ex,basal_weights_example_filter_inh),axis=0)\noblique_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_oblique_syn_inds,selected_filter_ind].T)\noblique_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_oblique_syn_inds,selected_filter_ind].T)\noblique_weights_example_filter     = np.concatenate((oblique_weights_example_filter_ex, oblique_weights_example_filter_inh),axis=0)\ntuft_weights_example_filter_ex  = np.fliplr(first_layer_weights[:,ex_tuft_syn_inds,selected_filter_ind].T)\ntuft_weights_example_filter_inh = np.fliplr(first_layer_weights[:,inh_tuft_syn_inds,selected_filter_ind].T)\ntuft_weights_example_filter     = np.concatenate((tuft_weights_example_filter_ex,tuft_weights_example_filter_inh),axis=0)\n\ntime_axis = -np.arange(first_layer_weights.shape[0])\n\nupper_limit = max(np.percentile(abs(first_layer_weights[:,:,selected_filter_ind]),99.8),np.percentile(abs(first_layer_weights[:,:,selected_filter_ind]),0.2))\nweights_ylims = np.array([-1.08,1.08]) * upper_limit\n\nweight_ticks_lims = (np.array(weights_ylims)\/weight_granularity).astype(int) * weight_granularity\n\n\nxytick_labels_fontsize = 27\ntitle_fontsize = 37\nxylabels_fontsize = 37\nlegend_fontsize = 16\nall_traces_alpha = 0.08\nmean_linewidth = 4.0\n\nfig = plt.figure(figsize=(19,19));\n\ngs1 = gridspec.GridSpec(1,3)\ngs1.update(left=0.10, right=0.97, bottom=0.30, top=0.98, wspace=0.14, hspace=0.03)\n\ngs2 = gridspec.GridSpec(1,3)\ngs2.update(left=0.10, right=0.97, bottom=0.06, top=0.28, wspace=0.11, hspace=0.03)\n\nax00 = plt.subplot(gs1[0,0])\nax10 = plt.subplot(gs2[0,0])\n\nax01 = plt.subplot(gs1[0,1])\nax11 = plt.subplot(gs2[0,1])\n\nax02 = plt.subplot(gs1[0,2])\nax12 = plt.subplot(gs2[0,2])\n\nax00.axis('off')\nax01.axis('off')\nax02.axis('off')\n\n# basal\nweights_images = ax00.imshow(resize(basal_weights_example_filter, (combined_filter.shape[0], 200)),\n                             cmap='jet', vmin=weights_ylims[0],vmax=weights_ylims[1], aspect='auto')\nax00.set_xticks([])\nax00.set_ylabel('Synaptic index', fontsize=xylabels_fontsize)\nfor ytick_label in ax00.get_yticklabels():\n    ytick_label.set_fontsize(xytick_labels_fontsize)\n\nax_colorbar = inset_axes(ax00, width=\"67%\", height=\"6%\", loc=2)\ncbar = plt.colorbar(weights_images, cax=ax_colorbar, orientation=\"horizontal\", ticks=[weight_ticks_lims[0], 0, weight_ticks_lims[1]])\nax_colorbar.xaxis.set_ticks_position(\"bottom\")\ncbar.ax.tick_params(labelsize=xytick_labels_fontsize)\nax00.text(10, 132, 'Weight (A.U)', color='k', fontsize=title_fontsize, ha='left', va='top', rotation='horizontal')\n\nax10.plot(time_axis, np.fliplr(basal_weights_example_filter_ex).T , c='r', alpha=all_traces_alpha)\nax10.plot(time_axis, np.mean(np.fliplr(basal_weights_example_filter_ex).T, axis=1) , c='r', lw=mean_linewidth)\nax10.plot(time_axis, np.fliplr(basal_weights_example_filter_inh).T, c='b', alpha=all_traces_alpha)\nax10.plot(time_axis, np.mean(np.fliplr(basal_weights_example_filter_inh).T, axis=1) , c='b', lw=mean_linewidth)\n\nax10.set_xlim(time_axis.min(),time_axis.max())\nax10.set_xlabel('Time before $t_0$ (ms)', fontsize=xylabels_fontsize);\nax10.set_ylim(weights_ylims[0],weights_ylims[1])\nax10.set_ylabel('Weight (A.U)', fontsize=xylabels_fontsize)\n\ntime_ticks_to_show = np.unique((np.array(time_axis)\/time_granularity).astype(int) * time_granularity)\nax10.set_xticks(time_ticks_to_show)\n\nweights_axis = np.linspace(weights_ylims[0],weights_ylims[1],10)\nweight_ticks_to_show = np.unique((np.array(weights_axis)\/weight_granularity).astype(int) * weight_granularity)\nax10.set_yticks(weight_ticks_to_show)\n\n\nax10.spines['top'].set_visible(False)\nax10.spines['right'].set_visible(False)\n\nfor ytick_label in ax10.get_yticklabels():\n    ytick_label.set_fontsize(xytick_labels_fontsize)\nfor xtick_label in ax10.get_xticklabels():\n    xtick_label.set_fontsize(xytick_labels_fontsize)\n\n# oblique\nweights_images = ax01.imshow(resize(oblique_weights_example_filter, (combined_filter.shape[0], 200)),\n                             cmap='jet', vmin=weights_ylims[0],vmax=weights_ylims[1], aspect='auto')\nax01.set_xticks([])\nax01.set_ylabel('Synaptic index', fontsize=xylabels_fontsize)\nfor ytick_label in ax01.get_yticklabels():\n    ytick_label.set_fontsize(xytick_labels_fontsize)\n\nax11.plot(time_axis, np.fliplr(oblique_weights_example_filter_ex).T , c='r', alpha=all_traces_alpha)\nax11.plot(time_axis, np.mean(np.fliplr(oblique_weights_example_filter_ex).T, axis=1) , c='r', lw=mean_linewidth)\nax11.plot(time_axis, np.fliplr(oblique_weights_example_filter_inh).T, c='b', alpha=all_traces_alpha)\nax11.plot(time_axis, np.mean(np.fliplr(oblique_weights_example_filter_inh).T, axis=1) , c='b', lw=mean_linewidth)\n\nax11.set_xlim(time_axis.min(),time_axis.max())\nax11.set_xlabel('Time before $t_0$ (ms)', fontsize=xylabels_fontsize);\nax11.set_ylim(weights_ylims[0],weights_ylims[1])\n\ntime_ticks_to_show = np.unique((np.array(time_axis)\/time_granularity).astype(int) * time_granularity)\nax11.set_xticks(time_ticks_to_show)\n\nax11.spines['top'].set_visible(False)\nax11.spines['right'].set_visible(False)\nax11.spines['left'].set_visible(False)\n\nax11.set_yticks([])\nfor ytick_label in ax11.get_yticklabels():\n    ytick_label.set_fontsize(xytick_labels_fontsize)\nfor xtick_label in ax11.get_xticklabels():\n    xtick_label.set_fontsize(xytick_labels_fontsize)\n\n# tuft\nweights_images = ax02.imshow(resize(tuft_weights_example_filter, (combined_filter.shape[0], 200)),\n                             cmap='jet', vmin=weights_ylims[0],vmax=weights_ylims[1], aspect='auto')\nax02.set_xticks([])\nax02.set_ylabel('Synaptic index', fontsize=xylabels_fontsize)\nfor ytick_label in ax02.get_yticklabels():\n    ytick_label.set_fontsize(xytick_labels_fontsize)\n\nax12.plot(time_axis, np.fliplr(tuft_weights_example_filter_ex).T , c='r', alpha=all_traces_alpha)\nax12.plot(time_axis, np.mean(np.fliplr(tuft_weights_example_filter_ex).T, axis=1) , c='r', lw=mean_linewidth)\nax12.plot(time_axis, np.fliplr(tuft_weights_example_filter_inh).T, c='b', alpha=all_traces_alpha)\nax12.plot(time_axis, np.mean(np.fliplr(tuft_weights_example_filter_inh).T, axis=1) , c='b', lw=mean_linewidth)\n\nax12.set_xlim(time_axis.min(),time_axis.max())\nax12.set_ylim(weights_ylims[0],weights_ylims[1])\nax12.set_xlabel('Time before $t_0$ (ms)', fontsize=xylabels_fontsize);\nax12.set_yticks([])\n\ntime_ticks_to_show = np.unique((np.array(time_axis)\/time_granularity).astype(int) * time_granularity)\nax12.set_xticks(time_ticks_to_show)\n\nax12.spines['top'].set_visible(False)\nax12.spines['right'].set_visible(False)\nax12.spines['left'].set_visible(False)\n\nfor ytick_label in ax12.get_yticklabels():\n    ytick_label.set_fontsize(xytick_labels_fontsize)\nfor xtick_label in ax12.get_xticklabels():\n    xtick_label.set_fontsize(xytick_labels_fontsize)\n\nif save_figures:\n    figure_name = '%s__first_layer_weights_filter_ind_%d' %(model_dir.split('\/')[-2], selected_filter_ind)\n    fig.savefig(output_figures_dir + figure_name + file_ending, bbox_inches='tight')","b3e6cbf6":"#%% full combined figure (version 2)\n\n# content params\npossible_presentable_candidates = np.nonzero(np.logical_and(num_spikes_per_simulation >= 4, num_spikes_per_simulation <= 12))[0]\nselected_trace  = np.random.choice(possible_presentable_candidates)\nzoomin_fraction = [0.23+0.24*np.random.rand(), 0.53+0.24*np.random.rand()]\n\n# selected_trace  = 128\n# zoomin_fraction = [0.61,0.85]\n\nselected_trace  = 673\nzoomin_fraction = [0.34,0.65]\n\nselected_filter_inds = [91,93,114]\n\nuse_filtered = True\nfilter_size = 3\n\n# figure params\nxytick_labels_fontsize = 15\ntitle_fontsize = 26\nxylabels_fontsize = 19\nlegend_fontsize = 15\nall_traces_alpha = 0.08\nmean_linewidth = 4.0\n\n# figure layout\nplt.close('all')\nfig = plt.figure(figsize=(26,20));\n\ngs_top_left = gridspec.GridSpec(nrows=1,ncols=1)\ngs_top_left.update(left=0.04, right=0.20, bottom=0.45, top=0.95, wspace=0.5, hspace=0.01)\ngs_top_middle = gridspec.GridSpec(nrows=7,ncols=1)\ngs_top_middle.update(left=0.22, right=0.59, bottom=0.45, top=0.95, wspace=0.5, hspace=0.01)\ngs_top_right = gridspec.GridSpec(nrows=5,ncols=2)\ngs_top_right.update(left=0.65, right=0.97, bottom=0.47, top=0.95, wspace=0.3, hspace=0.5)\n\ngs_bottom_left = gridspec.GridSpec(nrows=3,ncols=3)\ngs_bottom_left.update(left=0.09, right=0.35, bottom=0.05, top=0.39, wspace=0.15, hspace=0.07)\ngs_bottom_middle = gridspec.GridSpec(nrows=3,ncols=3)\ngs_bottom_middle.update(left=0.40, right=0.66, bottom=0.05, top=0.39, wspace=0.15, hspace=0.07)\ngs_bottom_right = gridspec.GridSpec(nrows=3,ncols=3)\ngs_bottom_right.update(left=0.71, right=0.97, bottom=0.05, top=0.39, wspace=0.15, hspace=0.07)\n\n\n# top\nax_morphology      = plt.subplot(gs_top_left[:,:])\nax_nn_illustration = plt.subplot(gs_top_middle[:3,:])\nax_trace_full      = plt.subplot(gs_top_middle[3:5,:])\nax_trace_zoomin    = plt.subplot(gs_top_middle[5:,:])\nax_roc        = plt.subplot(gs_top_right[:2,0])\nax_cross_corr = plt.subplot(gs_top_right[:2,1])\nax_scatter    = plt.subplot(gs_top_right[2:,:])\n\n# bottom\nax_weights_left_basal_heatmap    = plt.subplot(gs_bottom_left[:2,0])\nax_weights_left_oblique_heatmap  = plt.subplot(gs_bottom_left[:2,1])\nax_weights_left_apical_heatmap   = plt.subplot(gs_bottom_left[:2,2])\nax_weights_left_basal_temporal   = plt.subplot(gs_bottom_left[2,0])\nax_weights_left_oblique_temporal = plt.subplot(gs_bottom_left[2,1])\nax_weights_left_apical_temporal  = plt.subplot(gs_bottom_left[2,2])\n\nax_weights_middle_basal_heatmap    = plt.subplot(gs_bottom_middle[:2,0])\nax_weights_middle_oblique_heatmap  = plt.subplot(gs_bottom_middle[:2,1])\nax_weights_middle_apical_heatmap   = plt.subplot(gs_bottom_middle[:2,2])\nax_weights_middle_basal_temporal   = plt.subplot(gs_bottom_middle[2,0])\nax_weights_middle_oblique_temporal = plt.subplot(gs_bottom_middle[2,1])\nax_weights_middle_apical_temporal  = plt.subplot(gs_bottom_middle[2,2])\n\nax_weights_right_basal_heatmap    = plt.subplot(gs_bottom_right[:2,0])\nax_weights_right_oblique_heatmap  = plt.subplot(gs_bottom_right[:2,1])\nax_weights_right_apical_heatmap   = plt.subplot(gs_bottom_right[:2,2])\nax_weights_right_basal_temporal   = plt.subplot(gs_bottom_right[2,0])\nax_weights_right_oblique_temporal = plt.subplot(gs_bottom_right[2,1])\nax_weights_right_apical_temporal  = plt.subplot(gs_bottom_right[2,2])\n    \n################################################\n# set morphology\n################################################\n\nwidth_mult_factor = 1.2\napical_color = 'g'\noblique_color = 'orange'\nbasal_color = 'm'\n\n# basal segments\nfor key in basal_syn_inds:\n    line_width = width_mult_factor*np.array(seg_ind_to_xyz_coords_map[key]['d']).mean()\n    ax_morphology.plot(seg_ind_to_xyz_coords_map[key]['x'],seg_ind_to_xyz_coords_map[key]['y'],lw=line_width,color=basal_color)\n\n# oblique segments\nfor key in oblique_syn_inds:\n    line_width = width_mult_factor*np.array(seg_ind_to_xyz_coords_map[key]['d']).mean()\n    ax_morphology.plot(seg_ind_to_xyz_coords_map[key]['x'],seg_ind_to_xyz_coords_map[key]['y'],lw=line_width,color=oblique_color)\n\n# tuft segments\nfor key in tuft_syn_inds:\n    line_width = width_mult_factor*np.array(seg_ind_to_xyz_coords_map[key]['d']).mean()\n    ax_morphology.plot(seg_ind_to_xyz_coords_map[key]['x'],seg_ind_to_xyz_coords_map[key]['y'],lw=line_width,color=apical_color)\n\n# add black soma    \nax_morphology.scatter(x=46.0,y=15.8,s=180,c='k', zorder=100)\nax_morphology.set_xlim(-180,235)\nax_morphology.set_ylim(-210,1200)\nax_morphology.set_axis_off()\n\n\n################################################\n# set illustration\n################################################\n\nax_nn_illustration.set_axis_off()\nax_nn_illustration.imshow(imageio.imread(NN_illustration_filename))\n\n################################################\n# set traces \n################################################\n\nspike_trace_GT   = y1_test_for_TCN[selected_trace,:,0]\nspike_trace_pred = y1_test_for_TCN_hat[selected_trace,:,0] > desired_threshold\n\noutput_spike_times_in_ms_GT   = np.nonzero(spike_trace_GT)[0]\noutput_spike_times_in_ms_pred = np.nonzero(spike_trace_pred)[0]\n\nsoma_voltage_trace_GT   = y2_test_for_TCN[selected_trace,:,0] + y_train_soma_bias\nsoma_voltage_trace_pred = y2_test_for_TCN_hat[selected_trace,:,0] + y_train_soma_bias\n\nsoma_voltage_trace_GT[output_spike_times_in_ms_GT] = 37\nsoma_voltage_trace_pred[output_spike_times_in_ms_pred] = 37\n\n\nax_trace_full.set_axis_off()\nax_trace_zoomin.set_axis_off()\n\nax_trace_full.plot(time_in_sec,soma_voltage_trace_GT,c='c')\nax_trace_full.plot(time_in_sec,soma_voltage_trace_pred,c='m',linestyle=':')\nax_trace_full.set_xlim(0.05,sim_duration_sec)\nax_trace_full.set_ylabel('$V_m$ (mV)', fontsize=xylabels_fontsize);\n\nfor tick_label in (ax_trace_full.get_xticklabels() + ax_trace_full.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\nzoomout_scalebar_xloc = 0.95*sim_duration_sec\n\nzoomin_xlims = [zoomin_fraction[0]*sim_duration_sec, zoomin_fraction[1]*sim_duration_sec]\nzoomin_dur_sec = zoomin_xlims[1] - zoomin_xlims[0]\nzoomin_time_in_sec = np.logical_and(time_in_sec >= zoomin_xlims[0], time_in_sec <= zoomin_xlims[1])\nzoomin_ylims = [soma_voltage_trace_GT[zoomin_time_in_sec].min()-2.5,-52]\nzoomin_scalebar_xloc = zoomin_xlims[1] - 0.05*zoomin_dur_sec\n\nax_trace_zoomin.plot(time_in_sec,soma_voltage_trace_GT,c='c')\nax_trace_zoomin.plot(time_in_sec,soma_voltage_trace_pred,c='m',linestyle=':')\nax_trace_zoomin.set_xlim(zoomin_xlims[0],zoomin_xlims[1])\nax_trace_zoomin.set_ylim(zoomin_ylims[0],zoomin_ylims[1])\nax_trace_zoomin.set_ylabel('$V_m$ (mV)', fontsize=xylabels_fontsize);\nax_trace_zoomin.set_xlabel('time (sec)', fontsize=xylabels_fontsize);\n\nfor tick_label in (ax_trace_zoomin.get_xticklabels() + ax_trace_zoomin.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\n\n# add scale bar to top plot\nscalebar_loc = np.array([zoomout_scalebar_xloc,-25])\nscalebar_size_x = 0.6\nscalebar_str_x = '600 ms'\nscalebar_size_y = 40\nscalebar_str_y = '40 mV'\n\nx = [scalebar_loc[0], scalebar_loc[0] - scalebar_size_x]\ny = [scalebar_loc[1], scalebar_loc[1]]\nax_trace_full.plot(x,y,lw=2,c='k')\nax_trace_full.text(scalebar_loc[0] - 0.05*scalebar_size_x, scalebar_loc[1] - 0.15*scalebar_size_y, \n          scalebar_str_x, color='k', fontsize=15, ha='right', va='top', rotation='horizontal')\n\nx = [scalebar_loc[0], scalebar_loc[0]]\ny = [scalebar_loc[1], scalebar_loc[1] + scalebar_size_y]\nax_trace_full.plot(x,y,lw=2,c='k')\nax_trace_full.text(scalebar_loc[0] + 0.1*scalebar_size_x, scalebar_loc[1] + 0.6*scalebar_size_y, \n          scalebar_str_y, color='k', fontsize=15, ha='left', va='top', rotation='horizontal')\n\n\n# add dashed rectangle\nrect_w = zoomin_xlims[1] - zoomin_xlims[0]\nrect_h = zoomin_ylims[1] - zoomin_ylims[0]\nrect_bl_x = zoomin_xlims[0]\nrect_bl_y = zoomin_ylims[0]\ndashed_rectangle = mpatches.Rectangle((rect_bl_x,rect_bl_y),rect_w,rect_h,linewidth=2,edgecolor='k',linestyle='--',facecolor='none')\n\nax_trace_full.add_patch(dashed_rectangle)\n\n\n# add scalebar to bottom plot\nscalebar_loc = np.array([zoomin_scalebar_xloc,-60])\nscalebar_size_x = 0.06\nscalebar_str_x = '60 ms'\nscalebar_size_y = 5\nscalebar_str_y = '5 mV'\n\nx = [scalebar_loc[0], scalebar_loc[0] - scalebar_size_x]\ny = [scalebar_loc[1], scalebar_loc[1]]\nax_trace_zoomin.plot(x,y,lw=2,c='k')\nax_trace_zoomin.text(scalebar_loc[0] - 0.15*scalebar_size_x, scalebar_loc[1] - 0.15*scalebar_size_y, \n          scalebar_str_x, color='k', fontsize=15, ha='right', va='top', rotation='horizontal')\n\nx = [scalebar_loc[0], scalebar_loc[0]]\ny = [scalebar_loc[1], scalebar_loc[1] + scalebar_size_y]\nax_trace_zoomin.plot(x,y,lw=2,c='k')\nax_trace_zoomin.text(scalebar_loc[0] + 0.1*scalebar_size_x, scalebar_loc[1] + 0.6*scalebar_size_y, \n          scalebar_str_y, color='k', fontsize=15, ha='left', va='top', rotation='horizontal')\n\n\n################################################\n# set evaluation plots\n################################################\n\n# ROC curve\nax_roc.plot(fpr, tpr, c='k'); \nax_roc.set_xlabel('False alarm rate', fontsize=xylabels_fontsize); \nax_roc.set_ylabel('Hit rate', fontsize=xylabels_fontsize);\nax_roc.set_ylim(0,1.05);\nax_roc.set_xlim(-0.03,1);\nax_roc.spines['top'].set_visible(False)\nax_roc.spines['right'].set_visible(False)\nfor tick_label in (ax_roc.get_xticklabels() + ax_roc.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\nax_roc.set_xticks([0.0,0.5,1.0])\nax_roc.set_yticks([0.0,0.5,1.0])\n\n# ROC inset plot\nleft, bottom, width, height = [0.70, 0.80, 0.075, 0.12]\nax_roc_inset = fig.add_axes([left, bottom, width, height])\nax_roc_inset.plot(fpr, tpr, c='k'); \nax_roc_inset.set_ylim(0,1.05);\nax_roc_inset.set_xlim(-0.001,0.045);\nax_roc_inset.spines['top'].set_visible(False)\nax_roc_inset.spines['right'].set_visible(False)\nax_roc_inset.scatter(actual_false_positive_rate, tpr[desired_fp_ind+1], c='r', s=100); \n\n\n# cross correlation curve\nmax_firing_rate = 10*int(max(1000*recall_curve)\/10)\nmidpoint_firing_rate = 5*int(max_firing_rate\/10)\nax_cross_corr.set_yticks([0,midpoint_firing_rate,max_firing_rate])\nax_cross_corr.plot(time_axis_cc, 1000*recall_curve, c='k'); \nax_cross_corr.set_ylim(0,1.05*1000*recall_curve.max());\nax_cross_corr.set_xlabel('$\\Delta t$ (ms)', fontsize=xylabels_fontsize)\nax_cross_corr.set_ylabel('spike rate (Hz)', fontsize=xylabels_fontsize)\nax_cross_corr.set_xticks([-50,0,50])\nax_cross_corr.spines['top'].set_visible(False)\nax_cross_corr.spines['right'].set_visible(False)\n\nfor tick_label in (ax_cross_corr.get_xticklabels() + ax_cross_corr.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\n\n# voltage scatter plot\nsoma_voltage_lims = np.round([np.percentile(selected_GT,0.2),np.percentile(selected_GT,99.8)]).astype(int)\nsoma_voltage_lims = np.round([np.percentile(selected_GT,0.2),-56]).astype(int)\nvoltage_granularity = 6\nvoltage_setpoint = -57\nvoltage_axis = np.arange(soma_voltage_lims[0],soma_voltage_lims[1])\nvoltage_ticks_to_show = np.unique(((voltage_axis-voltage_setpoint)\/voltage_granularity).astype(int) * voltage_granularity + voltage_setpoint)\nvoltage_ticks_to_show = voltage_ticks_to_show[np.logical_and(voltage_ticks_to_show >= soma_voltage_lims[0], \n                                                             voltage_ticks_to_show <= soma_voltage_lims[1])]\nax_scatter.set_xticks(voltage_ticks_to_show)\nax_scatter.set_yticks(voltage_ticks_to_show)\n\nax_scatter.scatter(selected_GT,selected_pred, s=3.0, alpha=0.7)\nax_scatter.set_xlabel('L5PC (%s) (mV)' %(model_string), fontsize=xylabels_fontsize); \nax_scatter.set_ylabel('ANN (mV)', fontsize=xylabels_fontsize);\nax_scatter.set_xlim(soma_voltage_lims[0],soma_voltage_lims[1]);\nax_scatter.set_ylim(soma_voltage_lims[0],soma_voltage_lims[1]);\nax_scatter.plot([-90,-50],[-90,-50], ls='-', c='k')\nax_scatter.spines['top'].set_visible(False)\nax_scatter.spines['right'].set_visible(False)\n\nfor tick_label in (ax_scatter.get_xticklabels() + ax_scatter.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\n\n################################################\n# set first layer weights plots\n################################################\n\ndraw_weights(first_layer_weights, selected_filter_inds[0], True, \n                                                           ax_weights_left_basal_heatmap,   ax_weights_left_basal_temporal, \n                                                           ax_weights_left_oblique_heatmap, ax_weights_left_oblique_temporal, \n                                                           ax_weights_left_apical_heatmap,  ax_weights_left_apical_temporal)\n\ndraw_weights(first_layer_weights, selected_filter_inds[1], False, \n                                                           ax_weights_middle_basal_heatmap,   ax_weights_middle_basal_temporal, \n                                                           ax_weights_middle_oblique_heatmap, ax_weights_middle_oblique_temporal, \n                                                           ax_weights_middle_apical_heatmap,  ax_weights_middle_apical_temporal)\n\ndraw_weights(first_layer_weights, selected_filter_inds[2], False,\n                                                           ax_weights_right_basal_heatmap,   ax_weights_right_basal_temporal, \n                                                           ax_weights_right_oblique_heatmap, ax_weights_right_oblique_temporal, \n                                                           ax_weights_right_apical_heatmap, ax_weights_right_apical_temporal)\n\n# save figure\nif save_figures:\n    figure_name = '%s__full_combined_figure_v2_%d' %(model_dir.split('\/')[-2], np.random.randint(20))\n    fig.savefig(output_figures_dir + figure_name + file_ending, bbox_inches='tight')\n","1d216c72":"#%% full combined figure (version 3)\n\n# content params\npossible_presentable_candidates = np.nonzero(np.logical_and(num_spikes_per_simulation >= 4, num_spikes_per_simulation <= 15))[0]\nselected_trace  = np.random.choice(possible_presentable_candidates)\nzoomin_fraction = [0.23+0.24*np.random.rand(), 0.53+0.24*np.random.rand()]\n\n# NMDA 7x128x153\n# selected_trace  = 128\n# zoomin_fraction = [0.61,0.85]\n\nselected_trace  = 673\nzoomin_fraction = [0.34,0.65]\n\nselected_filter_ind = 93\n\nuse_filtered = True\nfilter_size = 3\n\n# figure params\nxytick_labels_fontsize = 15\ntitle_fontsize = 26\nxylabels_fontsize = 19\nlegend_fontsize = 15\nall_traces_alpha = 0.08\nmean_linewidth = 4.0\n\n# figure layout\nfig = plt.figure(figsize=(35,15));\n\ngs_top_left = gridspec.GridSpec(nrows=1,ncols=1)\ngs_top_left.update(left=0.01, right=0.17, bottom=0.05, top=0.95, wspace=0.5, hspace=0.01)\ngs_top_middle = gridspec.GridSpec(nrows=7,ncols=1)\ngs_top_middle.update(left=0.185, right=0.465, bottom=0.05, top=0.95, wspace=0.5, hspace=0.01)\ngs_top_right = gridspec.GridSpec(nrows=3,ncols=1)\ngs_top_right.update(left=0.515, right=0.63, bottom=0.09, top=0.95, wspace=0.3, hspace=0.22)\n\ngs_top_right_2 = gridspec.GridSpec(nrows=3,ncols=3)\ngs_top_right_2.update(left=0.69, right=0.99, bottom=0.09, top=0.89, wspace=0.15, hspace=0.07)\n\n\n# morphology, illustratrion, trace and performance evaluation\nax_morphology      = plt.subplot(gs_top_left[:,:])\nax_nn_illustration = plt.subplot(gs_top_middle[:3,:])\nax_trace_full      = plt.subplot(gs_top_middle[3:5,:])\nax_trace_zoomin    = plt.subplot(gs_top_middle[5:,:])\nax_roc        = plt.subplot(gs_top_right[0,0])\nax_cross_corr = plt.subplot(gs_top_right[1,0])\nax_scatter    = plt.subplot(gs_top_right[2,0])\n\n# weights plot\nax_weights_left_basal_heatmap    = plt.subplot(gs_top_right_2[:2,0])\nax_weights_left_oblique_heatmap  = plt.subplot(gs_top_right_2[:2,1])\nax_weights_left_apical_heatmap   = plt.subplot(gs_top_right_2[:2,2])\nax_weights_left_basal_temporal   = plt.subplot(gs_top_right_2[2,0])\nax_weights_left_oblique_temporal = plt.subplot(gs_top_right_2[2,1])\nax_weights_left_apical_temporal  = plt.subplot(gs_top_right_2[2,2])\n\n    \n################################################\n# set morphology\n################################################\n\nwidth_mult_factor = 1.2\napical_color = 'g'\noblique_color = 'orange'\nbasal_color = 'm'\n\n# basal segments\nfor key in basal_syn_inds:\n    line_width = width_mult_factor*np.array(seg_ind_to_xyz_coords_map[key]['d']).mean()\n    ax_morphology.plot(seg_ind_to_xyz_coords_map[key]['x'],seg_ind_to_xyz_coords_map[key]['y'],lw=line_width,color=basal_color)\n\n# oblique segments\nfor key in oblique_syn_inds:\n    line_width = width_mult_factor*np.array(seg_ind_to_xyz_coords_map[key]['d']).mean()\n    ax_morphology.plot(seg_ind_to_xyz_coords_map[key]['x'],seg_ind_to_xyz_coords_map[key]['y'],lw=line_width,color=oblique_color)\n\n# tuft segments\nfor key in tuft_syn_inds:\n    line_width = width_mult_factor*np.array(seg_ind_to_xyz_coords_map[key]['d']).mean()\n    ax_morphology.plot(seg_ind_to_xyz_coords_map[key]['x'],seg_ind_to_xyz_coords_map[key]['y'],lw=line_width,color=apical_color)\n\n# add black soma    \nax_morphology.scatter(x=46.0,y=15.8,s=180,c='k', zorder=100)\nax_morphology.set_xlim(-180,235)\nax_morphology.set_ylim(-210,1200)\nax_morphology.set_axis_off()\n\n\n################################################\n# set illustration\n################################################\n\nax_nn_illustration.set_axis_off()\nax_nn_illustration.imshow(imageio.imread(NN_illustration_filename))\n\n################################################\n# set traces \n################################################\n\nspike_trace_GT   = y1_test_for_TCN[selected_trace,:,0]\nspike_trace_pred = y1_test_for_TCN_hat[selected_trace,:,0] > desired_threshold\n\noutput_spike_times_in_ms_GT   = np.nonzero(spike_trace_GT)[0]\noutput_spike_times_in_ms_pred = np.nonzero(spike_trace_pred)[0]\n\nsoma_voltage_trace_GT   = y2_test_for_TCN[selected_trace,:,0] + y_train_soma_bias\nsoma_voltage_trace_pred = y2_test_for_TCN_hat[selected_trace,:,0] + y_train_soma_bias\n\nsoma_voltage_trace_GT[output_spike_times_in_ms_GT] = 37\nsoma_voltage_trace_pred[output_spike_times_in_ms_pred] = 37\n\n\nax_trace_full.set_axis_off()\nax_trace_zoomin.set_axis_off()\n\nax_trace_full.plot(time_in_sec,soma_voltage_trace_GT,c='c')\nax_trace_full.plot(time_in_sec,soma_voltage_trace_pred,c='m',linestyle=':')\nax_trace_full.set_xlim(0.05,sim_duration_sec)\nax_trace_full.set_ylabel('$V_m$ (mV)', fontsize=xylabels_fontsize);\n\nfor tick_label in (ax_trace_full.get_xticklabels() + ax_trace_full.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\nzoomout_scalebar_xloc = 0.95*sim_duration_sec\n\nzoomin_xlims = [zoomin_fraction[0]*sim_duration_sec, zoomin_fraction[1]*sim_duration_sec]\nzoomin_dur_sec = zoomin_xlims[1] - zoomin_xlims[0]\nzoomin_time_in_sec = np.logical_and(time_in_sec >= zoomin_xlims[0], time_in_sec <= zoomin_xlims[1])\nzoomin_ylims = [soma_voltage_trace_GT[zoomin_time_in_sec].min()-2.5,-52]\nzoomin_scalebar_xloc = zoomin_xlims[1] - 0.05*zoomin_dur_sec\n\nax_trace_zoomin.plot(time_in_sec,soma_voltage_trace_GT,c='c')\nax_trace_zoomin.plot(time_in_sec,soma_voltage_trace_pred,c='m',linestyle=':')\nax_trace_zoomin.set_xlim(zoomin_xlims[0],zoomin_xlims[1])\nax_trace_zoomin.set_ylim(zoomin_ylims[0],zoomin_ylims[1])\nax_trace_zoomin.set_ylabel('$V_m$ (mV)', fontsize=xylabels_fontsize);\nax_trace_zoomin.set_xlabel('time (sec)', fontsize=xylabels_fontsize);\n\nfor tick_label in (ax_trace_zoomin.get_xticklabels() + ax_trace_zoomin.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\n\n# add scale bar to top plot\nscalebar_loc = np.array([zoomout_scalebar_xloc,-25])\nscalebar_size_x = 0.6\nscalebar_str_x = '600 ms'\nscalebar_size_y = 40\nscalebar_str_y = '40 mV'\n\nx = [scalebar_loc[0], scalebar_loc[0] - scalebar_size_x]\ny = [scalebar_loc[1], scalebar_loc[1]]\nax_trace_full.plot(x,y,lw=2,c='k')\nax_trace_full.text(scalebar_loc[0] - 0.05*scalebar_size_x, scalebar_loc[1] - 0.15*scalebar_size_y, \n          scalebar_str_x, color='k', fontsize=15, ha='right', va='top', rotation='horizontal')\n\nx = [scalebar_loc[0], scalebar_loc[0]]\ny = [scalebar_loc[1], scalebar_loc[1] + scalebar_size_y]\nax_trace_full.plot(x,y,lw=2,c='k')\nax_trace_full.text(scalebar_loc[0] + 0.1*scalebar_size_x, scalebar_loc[1] + 0.6*scalebar_size_y, \n          scalebar_str_y, color='k', fontsize=15, ha='left', va='top', rotation='horizontal')\n\n\n# add dashed rectangle\nrect_w = zoomin_xlims[1] - zoomin_xlims[0]\nrect_h = zoomin_ylims[1] - zoomin_ylims[0]\nrect_bl_x = zoomin_xlims[0]\nrect_bl_y = zoomin_ylims[0]\ndashed_rectangle = mpatches.Rectangle((rect_bl_x,rect_bl_y),rect_w,rect_h,linewidth=2,edgecolor='k',linestyle='--',facecolor='none')\n\nax_trace_full.add_patch(dashed_rectangle)\n\n\n# add scalebar to bottom plot\nscalebar_loc = np.array([zoomin_scalebar_xloc,-60])\nscalebar_size_x = 0.06\nscalebar_str_x = '60 ms'\nscalebar_size_y = 5\nscalebar_str_y = '5 mV'\n\nx = [scalebar_loc[0], scalebar_loc[0] - scalebar_size_x]\ny = [scalebar_loc[1], scalebar_loc[1]]\nax_trace_zoomin.plot(x,y,lw=2,c='k')\nax_trace_zoomin.text(scalebar_loc[0] - 0.15*scalebar_size_x, scalebar_loc[1] - 0.15*scalebar_size_y, \n          scalebar_str_x, color='k', fontsize=15, ha='right', va='top', rotation='horizontal')\n\nx = [scalebar_loc[0], scalebar_loc[0]]\ny = [scalebar_loc[1], scalebar_loc[1] + scalebar_size_y]\nax_trace_zoomin.plot(x,y,lw=2,c='k')\nax_trace_zoomin.text(scalebar_loc[0] + 0.1*scalebar_size_x, scalebar_loc[1] + 0.6*scalebar_size_y, \n          scalebar_str_y, color='k', fontsize=15, ha='left', va='top', rotation='horizontal')\n\n\n################################################\n# set evaluation plots\n################################################\n\n# ROC curve\nax_roc.plot(fpr, tpr, c='k'); \nax_roc.set_xlabel('False alarm rate', fontsize=xylabels_fontsize); \nax_roc.set_ylabel('Hit rate', fontsize=xylabels_fontsize);\nax_roc.set_ylim(0,1.05);\nax_roc.set_xlim(-0.03,1);\nax_roc.spines['top'].set_visible(False)\nax_roc.spines['right'].set_visible(False)\nfor tick_label in (ax_roc.get_xticklabels() + ax_roc.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\nax_roc.set_xticks([0.0,0.5,1.0])\nax_roc.set_yticks([0.0,0.5,1.0])\n\n# ROC inset plot\nleft, bottom, width, height = [0.555, 0.75, 0.065, 0.15]\nax_roc_inset = fig.add_axes([left, bottom, width, height])\nax_roc_inset.plot(fpr, tpr, c='k'); \nax_roc_inset.set_ylim(0,1.05);\nax_roc_inset.set_xlim(-0.001,0.045);\nax_roc_inset.spines['top'].set_visible(False)\nax_roc_inset.spines['right'].set_visible(False)\nax_roc_inset.scatter(actual_false_positive_rate, tpr[desired_fp_ind+1], c='r', s=100); \n\n\n# cross correlation curve\nmax_firing_rate = 10*int(max(1000*recall_curve)\/10)\nmidpoint_firing_rate = 5*int(max_firing_rate\/10)\nax_cross_corr.set_yticks([0,midpoint_firing_rate,max_firing_rate])\nax_cross_corr.plot(time_axis_cc, 1000*recall_curve, c='k'); \nax_cross_corr.set_ylim(0,1.05*1000*recall_curve.max());\nax_cross_corr.set_xlabel('$\\Delta t$ (ms)', fontsize=xylabels_fontsize)\nax_cross_corr.set_ylabel('spike rate (Hz)', fontsize=xylabels_fontsize)\nax_cross_corr.set_xticks([-50,0,50])\nax_cross_corr.spines['top'].set_visible(False)\nax_cross_corr.spines['right'].set_visible(False)\n\nfor tick_label in (ax_cross_corr.get_xticklabels() + ax_cross_corr.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\n\n# voltage scatter plot\nsoma_voltage_lims = np.round([np.percentile(selected_GT,0.2),np.percentile(selected_GT,99.8)]).astype(int)\nsoma_voltage_lims = np.round([np.percentile(selected_GT,0.2),-56]).astype(int)\nvoltage_granularity = 6\nvoltage_setpoint = -57\nvoltage_axis = np.arange(soma_voltage_lims[0],soma_voltage_lims[1])\nvoltage_ticks_to_show = np.unique(((voltage_axis-voltage_setpoint)\/voltage_granularity).astype(int) * voltage_granularity + voltage_setpoint)\nvoltage_ticks_to_show = voltage_ticks_to_show[np.logical_and(voltage_ticks_to_show >= soma_voltage_lims[0], \n                                                             voltage_ticks_to_show <= soma_voltage_lims[1])]\nax_scatter.set_xticks(voltage_ticks_to_show)\nax_scatter.set_yticks(voltage_ticks_to_show)\n\nax_scatter.scatter(selected_GT,selected_pred, s=3.0, alpha=0.7)\nax_scatter.set_xlabel('L5PC (%s) (mV)' %(model_string), fontsize=xylabels_fontsize); \nax_scatter.set_ylabel('ANN (mV)', fontsize=xylabels_fontsize);\nax_scatter.set_xlim(soma_voltage_lims[0],soma_voltage_lims[1]);\nax_scatter.set_ylim(soma_voltage_lims[0],soma_voltage_lims[1]);\nax_scatter.plot([-90,-50],[-90,-50], ls='-', c='k')\nax_scatter.spines['top'].set_visible(False)\nax_scatter.spines['right'].set_visible(False)\n\nfor tick_label in (ax_scatter.get_xticklabels() + ax_scatter.get_yticklabels()):\n    tick_label.set_fontsize(xytick_labels_fontsize)\n\n\n################################################\n# set first layer weights plots\n################################################\n\ndraw_weights(first_layer_weights, selected_filter_ind, True, \n                                                       ax_weights_left_basal_heatmap,   ax_weights_left_basal_temporal, \n                                                       ax_weights_left_oblique_heatmap, ax_weights_left_oblique_temporal, \n                                                       ax_weights_left_apical_heatmap,  ax_weights_left_apical_temporal)\n\n# save figure\nif save_figures:\n    figure_name = '%s__full_combined_figure_v3_%d' %(model_dir.split('\/')[-2], np.random.randint(20))\n    fig.savefig(output_figures_dir + figure_name + file_ending, bbox_inches='tight')\n","a2bd5e60":"# Load test simulation dataset of a detailed biophysical cortical neuron\n","0920d3ff":"# Load previously trained TCN model","5b89ef08":"# Load and display cell Morphology\nNOTE: for those unfamiliar with kaggle, please press the \"code\" rectangle on the right to collapse\/uncollapse this cell\n","5849fa7e":"# Show a single prediction trace (trace used in Fig. 2)\nNOTE: for those unfamiliar with kaggle, please press the \"code\" rectangle on the right to collapse\/uncollapse this cell\n","356f5a49":"# Calculate various evaluation metrics\nNOTE: for those unfamiliar with kaggle, please press the \"code\" rectangle on the right to collapse\/uncollapse this cell\n\n","3661e28f":"# Script params and file paths","733956d6":"# Display the evaluation figures:\n- ROC curve of binary spike prediction at 1ms temporal resolution\n- cross correlation between prediction and GT (illustrating the temporal accuracy of the prediction)  \n- sub-threshold somatic voltage prediction scatter plot  \n\nNOTE: for those unfamiliar with kaggle, please press the \"code\" rectangle on the right to collapse\/uncollapse this cell\n","5eb308d8":"# Show multiple prediction (randomly selected) traces\nNOTE: for those unfamiliar with kaggle, please press the \"code\" rectangle on the right to collapse\/uncollapse this cell\n","f5f538b8":"# Show weights (as spatio-temporal heatmaps) of all first layer units\nNOTE: for those unfamiliar with kaggle, please press the \"code\" rectangle on the right to collapse\/uncollapse this cell\n","f56d42b1":"# Show filter of a selected unit in depth\ndisplay spatio-temporal heatmap for all 3 major morphological section of the neuron (basal, oblique, apical) and temporal corss-section as well\n\nNOTE: for those unfamiliar with kaggle, please press the \"code\" rectangle on the right to collapse\/uncollapse this cell\n\n","723c8bc6":"# Alternative smaller version of the same plot as above\nNOTE: for those unfamiliar with kaggle, please press the \"code\" rectangle on the right to collapse\/uncollapse this cell\n","426882db":"# Figure 2 full replication\nNOTE: for those unfamiliar with kaggle, please press the \"code\" rectangle on the right to collapse\/uncollapse this cell\n","49ea217b":"# Define some helper functions\nIn the section below we have some costum functions that will be used later in the script to load and parse the data, calculate various evaluation metrics and also visualize first layer TCN weights\n\nNOTE: for those unfamiliar with kaggle, please press the \"code\" rectangle on the right to collapse\/uncollapse this cell\n","bb8cf9e1":"# Make predictions on test set using TCN model\nNOTE: for those unfamiliar with kaggle, please press the \"code\" rectangle on the right to collapse\/uncollapse this cell\n","50e8c4fc":"# Single Cortical Neurons as Deep Artificial Neural Networks \n\nThis script replicates the main result (Figure 2) in the paper \"[Single Cortical Neurons as Deep Artificial Neural Networks](https:\/\/www.biorxiv.org\/content\/10.1101\/613141v2)\".  \n\nThis work is my attempt to compactly summarize what biological neurons actually are, when taking into consideration their full biological complexity.  \nThis is done by simulating a state of the art detailed biophysical model of a single cortical neuron (that attmepts to capture all biological details that are currently known about the innter workings of biological neurons), and attempting to fit a deep network to that dataset that will also be as-small-as-possible.  \nThis work was made for the benefit of, first of all, myself, but additionally for the benifit of all other machine learning practitioners who are familiar with artificial neural networks and want to be more biologically inspired in their endeavors.  \n\n**TD;LR**:  \nI've previously created a short [twitter thread](https:\/\/twitter.com\/DavidBeniaguev\/status\/1131890349578829825) to simply explain the key results of the full paper. Welcome to have a look for a brief visual summery.\n\n**TD;LR to the TD;LR**:  \nbiological neurons are more complex than the neurons we use in our artificial neural networks by quite a bit, but at the same time they are not unimaginably more complex so we can still have a firm handle of what they actually are.\n\n### What this script contains\n- loads a pre-trained temrporally convolutional net (TCN)\n- makes a prediction using the TCN model on the full test dataset used in the paper\n- evaluates TCN model performance by comparing the model's prediction to a detailed biophysical simulation of a single neuron\n- visualizes first layer weights of the TCN as spatio-temporal heat maps \n- combines everything together to form the exact Figure 2 in the paper\n\n\n### Additional resources \n- A [dataset](https:\/\/www.kaggle.com\/selfishgene\/single-neurons-as-deep-nets-nmda-test-data) of a cortical neuron simulation (the test data that is used in this script)\n- A [script](https:\/\/www.kaggle.com\/selfishgene\/exploring-a-single-cortical-neuron) to explore this dataset\n- A [GitHub](https:\/\/github.com\/SelfishGene\/neuron_as_deep_net) repo for all simulation fitting and analysis code \n"}}