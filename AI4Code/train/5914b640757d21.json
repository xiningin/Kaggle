{"cell_type":{"15404205":"code","9372a3a4":"code","9f8c8b4e":"code","17d80488":"code","96f3eff3":"code","e5dcf391":"code","6ee73f86":"code","efa58f75":"code","06f0ffb1":"code","caa16d2e":"code","e9ffe826":"code","c197b9a3":"code","bad8d293":"code","391c80a3":"code","70c44b23":"code","24872dcf":"code","408ad96a":"code","39d7d621":"code","6c9e477d":"code","c3da6b70":"code","e96b4f55":"code","aab048cf":"code","1d968980":"code","d916c3af":"markdown","b05807f7":"markdown","0fca973e":"markdown","026f6c00":"markdown","5b19250b":"markdown","e91ac1ab":"markdown","d39b9bbd":"markdown","0c4f2a73":"markdown","a5a10d02":"markdown","1e23930e":"markdown","ea41045d":"markdown"},"source":{"15404205":"import pandas as pd","9372a3a4":"def rsna_to_pivot(df, sub_type_name='HemType'):\n    \"\"\"Convert RSNA data frame to pivoted table with\n    each subtype as a binary encoded column.\"\"\"\n    df2 = df.copy()\n    ids, sub_types = zip(*df['ID'].str.rsplit('_', n=1).values)\n    df2.loc[:, 'ID'] = ids\n    df2.loc[:, sub_type_name] = sub_types\n    return df2.pivot(index='ID', columns=sub_type_name, values='Label')\n\ndef pivot_to_rsna(df, sub_type_name='HemType'):\n    \"\"\"Converted pivoted table back to RSNA spec for submission.\"\"\"\n    df2 = df.copy()\n    df2 = df2.reset_index()\n    unpivot_vars = df2.columns[1:]\n    df2 = pd.melt(df2, id_vars='ID', value_vars=unpivot_vars, var_name=sub_type_name, value_name='Label')\n    df2['ID'] = df2['ID'].str.cat(df2[sub_type_name], sep='_')\n    df2.drop(columns=sub_type_name, inplace=True)\n    return df2","9f8c8b4e":"sample_sub = pd.read_csv('\/kaggle\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_sample_submission.csv')\ntrain = pd.read_csv('\/kaggle\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_train.csv')\n#First step is to get rid of duplicated entries. Luckily they are consistent.","17d80488":"# Let's check that that is true just to be sure.\n# If there were any groups that were not consistent,\n# the set of labels should be more than 0 and 1, therefore we are safe.\nset(train.groupby('ID').mean()['Label'].values)","96f3eff3":"# Actually remove duplicates\ntrain = train.groupby('ID').first().reset_index()\ntrain.head()","e5dcf391":"print(train.shape) # Notice all the rows\ntrain.head()","6ee73f86":"split_series = train['ID'].str.rsplit('_', n=1)\nsplit_series.head()","efa58f75":"ids, sub_types = zip(*train['ID'].str.rsplit('_', n=1).values)\ntrain.loc[:, 'ID'] = ids\ntrain.loc[:, 'HemType'] = sub_types # We are using HemType as our column name for our sub_types\ntrain.head()","06f0ffb1":"train = train.pivot(index='ID', columns='HemType', values='Label')\nprint(train.shape)\ntrain.head()","caa16d2e":"# Yay! That's what I like to see. Let's grab some stats real quick.\n# We can save these for later.\ntrain.mean()","e9ffe826":"train = train.reset_index()","c197b9a3":"unpivot_vars = train.columns[1:] # Here we need the names of categories so we can push them back in the ID\ntrain = pd.melt(train, id_vars='ID', value_vars=unpivot_vars, var_name='HemType', value_name='Label')\ntrain.head()","bad8d293":"train['ID'] = train['ID'].str.cat(train['HemType'], sep='_')\ntrain.drop(columns='HemType', inplace=True)\ntrain.head()","391c80a3":"# The only additions I\"m adding is copying dataframes so we don't accidentally change data we want to keep.\n\ndef rsna_to_pivot(df, sub_type_name='HemType'):\n    \"\"\"Convert RSNA data frame to pivoted table with\n    each subtype as a binary encoded column.\"\"\"\n    df2 = df.copy()\n    ids, sub_types = zip(*df['ID'].str.rsplit('_', n=1).values)\n    df2.loc[:, 'ID'] = ids\n    df2.loc[:, sub_type_name] = sub_types\n    return df2.pivot(index='ID', columns=sub_type_name, values='Label')\n\ndef pivot_to_rsna(df, sub_type_name='HemType'):\n    \"\"\"Converted pivoted table back to RSNA spec for submission.\"\"\"\n    df2 = df.copy()\n    df2 = df2.reset_index()\n    unpivot_vars = df2.columns[1:]\n    df2 = pd.melt(df2, id_vars='ID', value_vars=unpivot_vars, var_name=sub_type_name, value_name='Label')\n    df2['ID'] = df2['ID'].str.cat(df2[sub_type_name], sep='_')\n    df2.drop(columns=sub_type_name, inplace=True)\n    return df2","70c44b23":"# Just prep work we did before\nsample_sub = pd.read_csv('\/kaggle\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_sample_submission.csv')\ntrain = pd.read_csv('\/kaggle\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_train.csv')\ntrain = train.groupby('ID').first().reset_index()","24872dcf":"# Easy. Abstraction makes life great.\ntrain_pivot = rsna_to_pivot(train)\nsample_sub_pivot = rsna_to_pivot(sample_sub)","408ad96a":"train_pivot.head()","39d7d621":"sample_sub_pivot.head()","6c9e477d":"# We did this before.\naverages = train_pivot.mean()\naverages","c3da6b70":"# Go through the averages and deliver them to the columns of the submission.\nfor label, value in averages.items():\n    sample_sub_pivot.loc[:, label] = value","e96b4f55":"sample_sub_pivot.head()","aab048cf":"# We pivoted and now let's melt this back on in.\nsubmission = pivot_to_rsna(sample_sub_pivot)\nsubmission.head()","1d968980":"# What's easier than this?\nsubmission.to_csv('submission.csv', index=False)","d916c3af":"Now we will do our melt, which will be roughly the inverse operation of what we just performed.","b05807f7":"First we will separate out the class name from the ID by using an rsplit:","0fca973e":"The next line is the real magic. We can use a pivot to package everything up as we described.","026f6c00":"Now we have the split we need. We just now need to package that back into the original dataframe. This is easy, we just need to grab these and asign them as new columns:","5b19250b":"Almoost there, now we just need to convert ID and HemType into one column:","e91ac1ab":"# Averaged baseline\n\nNow let's use these functions to create a dead simple baseline that we can use without waiting for all the CT data to unzip.\n\nWe will look at the training data, and just assign the probability of a sub_type of hemmorhage to be the frequency of each type of hemmorhage in the dataset.","d39b9bbd":"# Pandas data tricks and baseline\n\nSometimes it is nice to turn the data you recieve into formats that are more easily fed to your models of interest. Let's not worry about the actual imaging data and just make it easier to work with the labels.\n\nTL;DR: Just use these functions below do convert your sample_submission or train_csv dataframes:","0c4f2a73":"Of course though, if we can transform in this direction. We want to transform in the other. This backwards operation is called a melt, and we can do that just as easily. First we will clean up the index:","a5a10d02":"This is a really nice way to work with your data, not only for feeding data to a neural network, but also just to make it more expressive for your exploratory data analysis. Hope this helps!","1e23930e":"Wow look at that! We went from one representation and back again really easily. If you want to learn more about these manipulations of data, I found Hadley Wickham's Tidy Data paper to be extremely helpful. (https:\/\/vita.had.co.nz\/papers\/tidy-data.pdf) \n\nWith all said, our code is really short and fits in these two functions:","ea41045d":"If we look at the data in the train CSV, we find that each image has an ID with a corresponding sub-type and a binary label. It isn't fun to have to work with classes buried in the ID. It would be much better to separate these out into lines where each line simply contained the ID and then having separate columns for each class contained at the end of ID, delineating whether or not that type of hemmorhage was present. Luckily the pandas package has some magical functionality to do this."}}