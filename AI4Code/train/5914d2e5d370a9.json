{"cell_type":{"318f39f3":"code","df8113bb":"code","dee8dc2d":"code","18950da1":"code","d95dab4e":"code","1bb27145":"code","df70c60f":"code","ad9aee5c":"code","6b5edc0b":"code","58725fbc":"markdown","90eb827a":"markdown","7de2b5ed":"markdown","c6b0034d":"markdown","ddfd015e":"markdown","3f5d7b10":"markdown","31a8971c":"markdown","d7008943":"markdown","2b7510d0":"markdown","81b74209":"markdown"},"source":{"318f39f3":"import numpy as np\nimport tensorflow as tf\nimport keras\nimport cv2\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import img_to_array\nimport os\nfrom tqdm import tqdm\nimport re\nimport matplotlib.pyplot as plt","df8113bb":"# to get the files in proper order\ndef sorted_alphanumeric(data):  \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n    return sorted(data,key = alphanum_key)\n# defining the size of the image\nSIZE = 256\nhigh_img = []\npath = '..\/input\/image-super-resolution\/dataset\/Raw Data\/high_res'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):    \n    if i == '855.jpg':\n        break\n    else:    \n        img = cv2.imread(path + '\/'+i,1)\n        # open cv reads images in BGR format so we have to convert it to RGB\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        #resizing image\n        img = cv2.resize(img, (SIZE, SIZE))\n        img = img.astype('float32') \/ 255.0\n        high_img.append(img_to_array(img))\n\n\nlow_img = []\npath = '..\/input\/image-super-resolution\/dataset\/Raw Data\/low_res'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):\n     if i == '855.jpg':\n        break\n     else: \n        img = cv2.imread(path + '\/'+i,1)\n\n        #resizing image\n        img = cv2.resize(img, (SIZE, SIZE))\n        img = img.astype('float32') \/ 255.0\n        low_img.append(img_to_array(img))","dee8dc2d":"for i in range(4):\n    a = np.random.randint(0,855)\n    plt.figure(figsize=(10,10))\n    plt.subplot(1,2,1)\n    plt.title('High Resolution Imge', color = 'green', fontsize = 20)\n    plt.imshow(high_img[a])\n    plt.axis('off')\n    plt.subplot(1,2,2)\n    plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n    plt.imshow(low_img[a])\n    plt.axis('off')","18950da1":"train_high_image = high_img[:700]\ntrain_low_image = low_img[:700]\ntrain_high_image = np.reshape(train_high_image,(len(train_high_image),SIZE,SIZE,3))\ntrain_low_image = np.reshape(train_low_image,(len(train_low_image),SIZE,SIZE,3))\n\nvalidation_high_image = high_img[700:830]\nvalidation_low_image = low_img[700:830]\nvalidation_high_image= np.reshape(validation_high_image,(len(validation_high_image),SIZE,SIZE,3))\nvalidation_low_image = np.reshape(validation_low_image,(len(validation_low_image),SIZE,SIZE,3))\n\n\ntest_high_image = high_img[830:]\ntest_low_image = low_img[830:]\ntest_high_image= np.reshape(test_high_image,(len(test_high_image),SIZE,SIZE,3))\ntest_low_image = np.reshape(test_low_image,(len(test_low_image),SIZE,SIZE,3))\n\nprint(\"Shape of training images:\",train_high_image.shape)\nprint(\"Shape of test images:\",test_high_image.shape)\nprint(\"Shape of validation images:\",validation_high_image.shape)\n","d95dab4e":"from keras import layers\ndef down(filters , kernel_size, apply_batch_normalization = True):\n    downsample = tf.keras.models.Sequential()\n    downsample.add(layers.Conv2D(filters,kernel_size,padding = 'same', strides = 2))\n    downsample.add(layers.Dropout(.2))\n    if apply_batch_normalization:\n        downsample.add(layers.BatchNormalization())\n    downsample.add(keras.layers.LeakyReLU())\n    return downsample\n\n\ndef up(filters, kernel_size, dropout = False):\n    upsample = tf.keras.models.Sequential()\n    upsample.add(layers.Conv2DTranspose(filters, kernel_size,padding = 'same', strides = 2))\n    upsample.add(layers.Dropout(.2))\n    if dropout:\n        upsample.dropout(0.2)\n    upsample.add(keras.layers.LeakyReLU())\n    return upsample\n\ndef model():\n    inputs = layers.Input(shape= [SIZE,SIZE,3])\n    d1 = down(128,(3,3),False)(inputs)\n    d2 = down(128,(3,3),False)(d1)\n    d3 = down(256,(3,3),True)(d2)\n    d4 = down(512,(3,3),True)(d3)\n    \n    d5 = down(512,(3,3),True)(d4)\n    #upsampling\n    u1 = up(512,(3,3),False)(d5)\n    u1 = layers.concatenate([u1,d4])\n    u2 = up(256,(3,3),False)(u1)\n    u2 = layers.concatenate([u2,d3])\n    u3 = up(128,(3,3),False)(u2)\n    u3 = layers.concatenate([u3,d2])\n    u4 = up(128,(3,3),False)(u3)\n    u4 = layers.concatenate([u4,d1])\n    u5 = up(3,(3,3),False)(u4)\n    u5 = layers.concatenate([u5,inputs])\n    output = layers.Conv2D(3,(2,2),strides = 1, padding = 'same')(u5)\n    return tf.keras.Model(inputs=inputs, outputs=output)\n\nmodel = model()\nmodel.summary()","1bb27145":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n              metrics = ['acc'])","df70c60f":"model.fit(train_low_image, train_high_image, epochs = 7, batch_size = 1,\n          validation_data = (validation_low_image,validation_high_image))","ad9aee5c":"def plot_images(high,low,predicted):\n    plt.figure(figsize=(15,15))\n    plt.subplot(1,3,1)\n    plt.title('High Image', color = 'green', fontsize = 20)\n    plt.imshow(high)\n    plt.subplot(1,3,2)\n    plt.title('Low Image ', color = 'black', fontsize = 20)\n    plt.imshow(low)\n    plt.subplot(1,3,3)\n    plt.title('Predicted Image ', color = 'Red', fontsize = 20)\n    plt.imshow(predicted)\n   \n    plt.show()\n\nfor i in range(1,10):\n    \n    predicted = np.clip(model.predict(test_low_image[i].reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)\n    plot_images(test_high_image[i],test_low_image[i],predicted)","6b5edc0b":"model.save(\"final_model.h5\")","58725fbc":"# Data Visualization","90eb827a":"# Import Libraires ","7de2b5ed":"# Slicing and Reshaping Images","c6b0034d":"# Saving model","ddfd015e":"# Fitting model","3f5d7b10":"# Defining Model","31a8971c":"# Compile ","d7008943":"# Load Data","2b7510d0":"# Prediction Visualization","81b74209":"## Thank You !!!"}}