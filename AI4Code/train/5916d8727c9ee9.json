{"cell_type":{"a43254c0":"code","1cc0b907":"code","6bc0d574":"code","41b65cf0":"code","221a81ed":"code","c26e9029":"code","8603386a":"code","75aad4dd":"code","bc7a2aed":"code","f6919222":"code","86c39408":"code","71f07c2c":"code","00f61feb":"code","3ffd67d0":"code","021a2ec3":"code","c04201c6":"code","7081f0b8":"code","9da52c1e":"code","ffb5e97d":"code","98dd73d1":"code","cb2c9d06":"code","1ade7888":"markdown","b25aec7c":"markdown","572c0aa5":"markdown","93cfafdc":"markdown","f240f55f":"markdown","8b5670af":"markdown","984be394":"markdown"},"source":{"a43254c0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom scipy.stats import entropy","1cc0b907":"ref_df=pd.read_csv('..\/input\/predict-volcanic-eruptions-ingv-oe\/train.csv')\nprint(ref_df.isna().sum().sum())\nref_df.head()","6bc0d574":"sample_sub=pd.read_csv('..\/input\/predict-volcanic-eruptions-ingv-oe\/sample_submission.csv')\nprint(sample_sub.isna().sum().sum())\nsample_sub.head()","41b65cf0":"%%time\nmissings=pd.DataFrame()\nfor seg_id in ref_df['segment_id']:\n    df=pd.read_csv(f'..\/input\/predict-volcanic-eruptions-ingv-oe\/train\/{seg_id}.csv')\n    missings=missings.append(pd.DataFrame(df.isna().sum()).T)\n    \n    \nmissings.set_index(ref_df['segment_id'],inplace=True)\nprint(missings.head())\nplt.figure(figsize=(15,25))\nsns.heatmap(missings,cmap = 'magma_r')","221a81ed":"%%time\n\ntrain=pd.DataFrame()\nfor seg_id in ref_df['segment_id']:\n    df=pd.read_csv(f'..\/input\/predict-volcanic-eruptions-ingv-oe\/train\/{seg_id}.csv')\n    #print(df.isna().sum())\n    for col in df.columns:\n        if df[col].isna().sum()==len(df):\n            df[col].fillna(0,inplace=True)\n        else:\n            df[col].fillna(df[col].mean(),inplace=True)\n    #print(df.isna().sum())\n    #print(df.head())\n    summary=pd.DataFrame()\n    des=df.describe()\n    \n    # df describe statistics\n    for i in range(10):\n        col=pd.DataFrame(des.iloc[:,i][1:]).T.reset_index(drop=True)\n        summary=pd.concat([summary,col],axis=1)\n    \n    # skew statistics\n    stat=pd.DataFrame(df.skew().values.reshape(1,-1))\n    summary=pd.concat([summary,stat],axis=1)\n    \n    # mean absolute deviation statistics\n    stat=pd.DataFrame(df.mad().values.reshape(1,-1))\n    summary=pd.concat([summary,stat],axis=1)\n    \n    # standard error statistics\n    stat=pd.DataFrame(df.sem().values.reshape(1,-1))\n    summary=pd.concat([summary,stat],axis=1)\n\n    #print(summary)\n    \n    train=train.append(summary)\n    del summary, des, df\n    ","c26e9029":"print(train.shape)\ntrain.columns=range(train.shape[1])\ntrain.set_index(ref_df['segment_id'].values,inplace=True)\nprint(train.shape)\ntrain.to_csv('train__.csv', index=False)\ntrain.head()","8603386a":"%%time\n\ntest=pd.DataFrame()\nfor seg_id in sample_sub['segment_id']:\n    df=pd.read_csv(f'..\/input\/predict-volcanic-eruptions-ingv-oe\/test\/{seg_id}.csv')\n    #print(df.isna().sum())\n    for col in df.columns:\n        if df[col].isna().sum()==len(df):\n            df[col].fillna(0,inplace=True)\n        else:\n            df[col].fillna(df[col].mean(),inplace=True)\n    #print(df.isna().sum())\n    #print(df.head())\n    summary=pd.DataFrame()\n    des=df.describe()\n\n    \n    for i in range(10):\n        col=pd.DataFrame(des.iloc[:,i][1:]).T.reset_index(drop=True)\n        summary=pd.concat([summary,col],axis=1)\n    \n    # skew statistics\n    stat=pd.DataFrame(df.skew().values.reshape(1,-1))\n    summary=pd.concat([summary,stat],axis=1)\n    \n    # mean absolute deviation statistics\n    stat=pd.DataFrame(df.mad().values.reshape(1,-1))\n    summary=pd.concat([summary,stat],axis=1)\n    \n    # standard error statistics\n    stat=pd.DataFrame(df.sem().values.reshape(1,-1))\n    summary=pd.concat([summary,stat],axis=1)\n    \n    #print(summary)\n    \n    test=test.append(summary)\n    del summary, des, df\n    ","75aad4dd":"print(test.shape)\ntest.columns=range(test.shape[1])\ntest.set_index(sample_sub['segment_id'].values,inplace=True)\nprint(test.shape)\ntest.to_csv('test__.csv', index=False)\ntest.head()","bc7a2aed":"train_df=pd.read_csv('.\/train__.csv')\ntest_df=pd.read_csv('.\/test__.csv')\nX=train_df.values\ny=ref_df['time_to_eruption']\nx_tr,x_ts,y_tr,y_ts=train_test_split(X,y,test_size=.25,random_state=40)\nx_tr.shape","f6919222":"from sklearn.tree import DecisionTreeRegressor","86c39408":"clf=DecisionTreeRegressor()\nclf .fit(x_tr,y_tr)\npred=clf.predict(x_ts)\nprint('training mae: ',mae(y_tr,clf.predict(x_tr)))\nprint('testing mae: ',mae(y_ts,pred))","71f07c2c":"%%time\nparams={'max_depth':range(13,18,3), 'min_samples_split':range(2,20,3), 'min_samples_leaf':range(1,20,4)}\nclf=DecisionTreeRegressor()\nclfcv=RandomizedSearchCV(clf,params,n_iter=1000,n_jobs=-1,random_state=10,return_train_score=True)\nclfcv.fit(x_tr,y_tr)\n","00f61feb":"print('train error: ',mae(y_tr,clfcv.best_estimator_.predict(x_tr)))\nprint('test error: ',mae(y_ts,clfcv.best_estimator_.predict(x_ts)))\nclfcv.best_estimator_","3ffd67d0":"feat_im=pd.DataFrame({'features':x_tr.columns,'importance':clfcv.best_estimator_.feature_importances_})\nfeat_im.sort_values(by='importance',inplace=True,ascending=False)\nplt.figure(figsize=(9,18))\nsns.barplot(y='features',x='importance',data=feat_im)","021a2ec3":"columns=feat_im[feat_im['importance']>=.015]['features'].values\nx_tr_n=x_tr[columns]\nx_ts_n=x_ts[columns]\nx_tr_n.shape","c04201c6":"%%time\nparams={'max_depth':range(13,18),'min_samples_split':range(2,20,3), 'min_samples_leaf':range(1,20,2)}\n        #'max_features':[\"auto\", \"sqrt\", \"log2\"]}\nclf=DecisionTreeRegressor()\nclfcv=GridSearchCV(clf,params,n_jobs=-1,cv=5)\nclfcv.fit(x_tr_n,y_tr)\n","7081f0b8":"print('train error: ',mae(y_tr,clfcv.best_estimator_.predict(x_tr_n)))\nprint('test error: ',mae(y_ts,clfcv.best_estimator_.predict(x_ts_n)))\nclfcv.best_estimator_","9da52c1e":"from sklearn.ensemble import RandomForestRegressor","ffb5e97d":"%%time\nparams={'max_depth':range(13,18),'min_samples_split':range(2,20,3), 'min_samples_leaf':range(1,20,2)}\nclf=RandomForestRegressor(n_estimators=15)\nclfcv=RandomizedSearchCV(clf,params,n_iter=100,n_jobs=-1,random_state=23,cv=10)\nclfcv.fit(x_tr_n,y_tr)","98dd73d1":"print('train error: ',mae(y_tr,clfcv.best_estimator_.predict(x_tr_n)))\nprint('test error: ',mae(y_ts,clfcv.best_estimator_.predict(x_ts_n)))\nclfcv.best_estimator_","cb2c9d06":"# subfile\ntest_n=test[columns]\npred=clfcv.predict(test_n)\nsub_file['time_to_eruption']=pred\nsub_file.to_csv('sub.csv',index=False)\nsub_file.head()","1ade7888":"# Submission file","b25aec7c":"### New Columns for better understading of both new train and test set","572c0aa5":"### For test set and submission file","93cfafdc":"# Decision Tree Regressor","f240f55f":"# Making new test set","8b5670af":"# Random Forest Regressor","984be394":"# Making new train set"}}