{"cell_type":{"b3a0e109":"code","187f4af5":"code","140bb4d4":"code","75aa5948":"code","c1ee2653":"code","26e67376":"code","dd40f58a":"code","ada761d1":"code","cfc2148c":"code","0272f28e":"code","25b8dfbe":"code","eb295f31":"code","086fef0d":"markdown","d9cb828d":"markdown","ebfcc108":"markdown","02aee684":"markdown","0d75a4b7":"markdown","79a2da57":"markdown","5f34a267":"markdown","8d752360":"markdown","8beb7445":"markdown","fa895518":"markdown"},"source":{"b3a0e109":"# Set up code checking\nimport os\nif not os.path.exists(\"..\/input\/train.csv\"):\n    os.symlink(\"..\/input\/home-data-for-ml-course\/train.csv\", \"..\/input\/train.csv\")  \n    os.symlink(\"..\/input\/home-data-for-ml-course\/test.csv\", \"..\/input\/test.csv\") \nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.ml_intermediate.ex4 import *\nprint(\"Setup Complete\")","187f4af5":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\nX_full = pd.read_csv('..\/input\/train.csv', index_col='Id')\nX_test_full = pd.read_csv('..\/input\/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\nX_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)\n\n# Break off validation set from training data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n                                                                train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncategorical_cols = [cname for cname in X_train_full.columns if\n                    X_train_full[cname].nunique() < 10 and \n                    X_train_full[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X_train_full.columns if \n                X_train_full[cname].dtype in ['int64', 'float64']]\n\n# Keep selected columns only\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()","140bb4d4":"X_train.head()","75aa5948":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define model\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\n\n# Bundle preprocessing and modeling code in a pipeline\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', model)\n                     ])\n\n# Preprocessing of training data, fit model \nclf.fit(X_train, y_train)\n\n# Preprocessing of validation data, get predictions\npreds = clf.predict(X_valid)\n\nprint('MAE:', mean_absolute_error(y_valid, preds))","c1ee2653":"# Preprocessing for numerical data\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\nnumerical_transformer = Pipeline(steps= [\n    (\"imputer\",SimpleImputer(strategy=\"constant\")), # Categorical- because of that, no usage of mode, median.\n    (( 'std_scaler', StandardScaler()))\n])\n\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps= [\n    (\"imputer\",SimpleImputer(strategy=\"most_frequent\")), # Categorical- because of that, no usage of mode, median.\n    (\"onehot\",OneHotEncoder(handle_unknown=\"ignore\"))\n]) # Your code here\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define model\nmodel = RandomForestRegressor(n_estimators=30,random_state=0) # Your code here\n\n# Check your answer\nstep_1.a.check()","26e67376":"X_train=X_train.fillna(method='bfill')\nX_train=X_train.fillna(method='ffill')\nX_train=X_train.fillna(0)\ny_train=y_train.fillna(method='bfill')\ny_train=y_train.fillna(method='ffill')\ny_train=y_train.fillna(0)\nX_valid=X_valid.fillna(method='bfill')\nX_valid=X_valid.fillna(method='ffill')\nX_valid=X_valid.fillna(0)\ny_valid=y_valid.fillna(method='bfill')\ny_valid=y_valid.fillna(method='ffill')\ny_valid=y_valid.fillna(0)","dd40f58a":"# Lines below will give you a hint or solution code\n#step_1.a.hint()\n#step_1.a.solution()","ada761d1":"# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])\n\n# Preprocessing of training data, fit model \nmy_pipeline.fit(X_train, y_train)\n\n# Preprocessing of validation data, get predictions\npreds = my_pipeline.predict(X_valid)\n\n# Evaluate the model\nscore = mean_absolute_error(y_valid, preds)\nprint('MAE:', score)\n\n# Check your answer\nstep_1.b.check()","cfc2148c":"# Line below will give you a hint\n#step_1.b.hint()","0272f28e":"# Preprocessing of test data, fit model\npreds_test = my_pipeline.predict(X_test) # Your code here\n\n# Check your answer\nstep_2.check()","25b8dfbe":"# Lines below will give you a hint or solution code\n#step_2.hint()\n#step_2.solution()","eb295f31":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","086fef0d":"The next code cell uses code from the tutorial to preprocess the data and train a model.  Run this code without changes.","d9cb828d":"You will work with data from the [Housing Prices Competition for Kaggle Learn Users](https:\/\/www.kaggle.com\/c\/home-data-for-ml-course). \n\n![Ames Housing dataset image](https:\/\/i.imgur.com\/lTJVG4e.png)\n\nRun the next code cell without changes to load the training and validation sets in `X_train`, `X_valid`, `y_train`, and `y_valid`.  The test set is loaded in `X_test`.","ebfcc108":"Run the next code cell without changes to save your results to a CSV file that can be submitted directly to the competition.","02aee684":"**[Intermediate Machine Learning Home Page](https:\/\/www.kaggle.com\/learn\/intermediate-machine-learning)**\n\n---\n","0d75a4b7":"# Step 3: Submit your results\n\nOnce you have successfully completed Step 2, you're ready to submit your results to the leaderboard!  If you choose to do so, make sure that you have already joined the competition by clicking on the **Join Competition** button at [this link](https:\/\/www.kaggle.com\/c\/home-data-for-ml-course).  \n- Begin by clicking on the blue **COMMIT** button in the top right corner.  This will generate a pop-up window.  \n- After your code has finished running, click on the blue **Open Version** button in the top right of the pop-up window.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n- Click on the **Output** tab on the left of the screen.  Then, click on the **Submit to Competition** button to submit your results to the leaderboard.\n- If you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your model and repeat the process.\n\n# Keep going\n\nMove on to learn about [**cross-validation**](https:\/\/www.kaggle.com\/alexisbcook\/cross-validation), a technique you can use to obtain more accurate estimates of model performance!","79a2da57":"In this exercise, you will use **pipelines** to improve the efficiency of your machine learning code.\n\n# Setup\n\nThe questions below will give you feedback on your work. Run the following cell to set up the feedback system.","5f34a267":"The code yields a value around 17862 for the mean absolute error (MAE).  In the next step, you will amend the code to do better.\n\n# Step 1: Improve the performance\n\n### Part A\n\nNow, it's your turn!  In the code cell below, define your own preprocessing steps and random forest model.  Fill in values for the following variables:\n- `numerical_transformer`\n- `categorical_transformer`\n- `model`\n\nTo pass this part of the exercise, you need only define valid preprocessing steps and a random forest model.","8d752360":"### Part B\n\nRun the code cell below without changes.\n\nTo pass this step, you need to have defined a pipeline in **Part A** that achieves lower MAE than the code above.  You're encouraged to take your time here and try out many different approaches, to see how low you can get the MAE!  (_If your code does not pass, please amend the preprocessing steps and model in Part A._)","8beb7445":"# Step 2: Generate test predictions\n\nNow, you'll use your trained model to generate predictions with the test data.","fa895518":"---\n**[Intermediate Machine Learning Home Page](https:\/\/www.kaggle.com\/learn\/intermediate-machine-learning)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https:\/\/www.kaggle.com\/learn-forum) to chat with other Learners.*"}}