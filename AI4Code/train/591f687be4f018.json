{"cell_type":{"163fd058":"code","b2221ddf":"code","9fc20a59":"code","e28dd5f1":"code","0ecd4518":"code","a7ffde33":"code","a8da8f8b":"code","1540cda6":"code","a73555a0":"code","73a94395":"code","5e77138a":"code","7a90da11":"code","34089d7d":"code","b0ec9b98":"code","5a8f3ec2":"code","04d37a4f":"code","974a7c22":"code","72347a0d":"code","9e3c1b23":"markdown","521fe7cb":"markdown","3beafe13":"markdown","5cd774cf":"markdown","5c8d12d5":"markdown","b9b12487":"markdown","e446d95d":"markdown","5bbd9c68":"markdown","ae309d61":"markdown"},"source":{"163fd058":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport altair as alt\nalt.renderers.enable('notebook')\nprint(os.listdir(\"..\/input\"))\nfrom IPython.display import HTML\n\n\n# The below is great for working but if you publish it, no charts show up.\n# The workaround in the next cell deals with this.\n#alt.renderers.enable('notebook')\n\nHTML(\"This code block contains import statements and setup.\")\n# Any results you write to the current directory are saved as output.","b2221ddf":"## Dont worry about the code in this block. This is just the setup for showing Altair graphs in Kaggle Notebooks\n\n\nfrom  altair.vega import v3\nimport json\nfrom IPython.display import HTML\n\n\nvega_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega@' + v3.SCHEMA_VERSION\nvega_lib_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lib'\nvega_lite_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https:\/\/cdn.jsdelivr.net\/npm\/',\n    paths: {}\n}});\n\"\"\"\n\ndef add_autoincrement(render_func):\n    # Keep track of unique <div\/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n            \n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"><\/div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    <\/script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"<\/script>\",\n    \"This code block sets up embedded rendering in HTML output and<br\/>\",\n    \"provides the function `render(chart, id='vega-chart')` for use below.\"\n)))\n","9fc20a59":"#!pip install fbprophet","e28dd5f1":"from fbprophet import Prophet\n\n#!mkdir -p dataset\n#!wget -c -b http:\/\/www-personal.umich.edu\/~mejn\/cp\/data\/sunspots.txt -P dataset\ndata = pd.read_excel('..\/input\/reliance-industries\/Petroleum_orig Reliance_Industries.xlsx', header=0, index_col=0, parse_dates=True, squeeze=True)","0ecd4518":"#!ls dataset\/","a7ffde33":"# View the data as a table\ndata_as_frame = pd.DataFrame(data, columns=['Reliance_Industries', 'Day'])\ndata_as_frame.tail(10)","a8da8f8b":"data_as_frame['ds']=data_as_frame['Day'].astype(int)","1540cda6":"data_as_frame.head()","a73555a0":" data_as_frame['time_stamp']=data_as_frame.apply(lambda x:(pd.Timestamp('01-01-2008')+pd.DateOffset(days = int(x['ds']))),axis=1)","73a94395":"#Cleaning the df, we only need two columns date time and the data\nclean_df=data_as_frame.drop(['Day','ds'],axis=1)","5e77138a":"clean_df.head()","7a90da11":"render(alt.Chart(clean_df).mark_line(size=15, opacity=0.8, color = 'Orange').encode(\n        x='yearmonthdate(time_stamp):T',\n        y=alt.Y('Reliance_Industries', title='Reliance_Industries'),    \n        tooltip=['yearmonthdate(time_stamp)', 'Reliance_Industries']\n    ).interactive().properties(width=900, height=450,title='Reliance_Industries Stock Price')\\\n              .configure_title(fontSize=20))","34089d7d":"## Prophet requires two columns, one is ds (the date time) and y (variable to be forecasted)\nclean_df.columns = ['y', 'ds']","b0ec9b98":"def fit_predict_model(dataframe, interval_width = 0.99, changepoint_range = 0.99):\n    m = Prophet(daily_seasonality = False, yearly_seasonality = False, weekly_seasonality = False,\n                seasonality_mode = 'multiplicative', \n                interval_width = interval_width,\n                changepoint_range = changepoint_range)\n    m = m.fit(dataframe)\n    \n    forecast = m.predict(dataframe)\n    forecast['fact'] = dataframe['y'].reset_index(drop = True)\n    print('Displaying Prophet plot')\n    fig1 = m.plot(forecast)\n    return forecast\n    \npred = fit_predict_model(clean_df)\n","5a8f3ec2":"def detect_anomalies(forecast):\n    forecasted = forecast[['ds','trend', 'yhat', 'yhat_lower', 'yhat_upper', 'fact']].copy()\n    #forecast['fact'] = df['y']\n\n    forecasted['anomaly'] = 0\n    forecasted.loc[forecasted['fact'] > forecasted['yhat_upper'], 'anomaly'] = 1\n    forecasted.loc[forecasted['fact'] < forecasted['yhat_lower'], 'anomaly'] = -1\n\n    #anomaly importances\n    forecasted['importance'] = 0\n    forecasted.loc[forecasted['anomaly'] ==1, 'importance'] = \\\n        (forecasted['fact'] - forecasted['yhat_upper'])\/forecast['fact']\n    forecasted.loc[forecasted['anomaly'] ==-1, 'importance'] = \\\n        (forecasted['yhat_lower'] - forecasted['fact'])\/forecast['fact']\n    \n    return forecasted\n\npred = detect_anomalies(pred)","04d37a4f":"pred.head()","974a7c22":"pred[pred.anomaly == 1]","72347a0d":"def plot_anomalies(forecasted):\n    interval = alt.Chart(forecasted).mark_area(interpolate=\"basis\", color = '#7FC97F').encode(\n    x=alt.X('ds:T',  title ='date'),\n    y='yhat_upper',\n    y2='yhat_lower',\n    tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper']\n    ).interactive().properties(\n        title='Anomaly Detection'\n    )\n\n    fact = alt.Chart(forecasted[forecasted.anomaly==0]).mark_circle(size=15, opacity=0.7, color = 'Black').encode(\n        x='ds:T',\n        y=alt.Y('fact', title='Sunspots'),    \n        tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper']\n    ).interactive()\n\n    anomalies = alt.Chart(forecasted[forecasted.anomaly!=0]).mark_circle(size=30, color = 'Red').encode(\n        x='ds:T',\n        y=alt.Y('fact', title='Sunspots'),    \n        tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper'],\n        size = alt.Size( 'importance', legend=None)\n    ).interactive()\n\n    return render(alt.layer(interval, fact, anomalies)\\\n              .properties(width=870, height=450)\\\n              .configure_title(fontSize=20))\n              \nplot_anomalies(pred)","9e3c1b23":"# Detecting Anomalies:\n* The light blue boundaries in the above graph are yhat_upper and yhat_lower.\n* If y value is greater than yhat_upper and less than yhat lower then it is an anomaly.\n* Also getting the importance of that anomaly based on its distance from yhat_upper and yhat_lower.","521fe7cb":"## Lets Predict","3beafe13":"## Lets view the data in graphical format","5cd774cf":"### Converting data to Pandas dataframe","5c8d12d5":"# Getting the data","b9b12487":"References:\n* http:\/\/www-personal.umich.edu\/~mejn\/cp\/programs.html\n* https:\/\/towardsdatascience.com\/anomaly-detection-time-series-4c661f6f165f\n* https:\/\/github.com\/altair-viz\/altair\/issues\/1270\n","e446d95d":"### Converting the months column in format acceptable for Prophet, starting from 1749 ","5bbd9c68":"# Preparing data for modelling in Prophet","ae309d61":"# Plotting the anomalies for a better view"}}