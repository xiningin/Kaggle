{"cell_type":{"eb0e71e3":"code","060eaf36":"code","54843ddf":"code","f62ddec1":"code","2a121508":"code","fe3c53b0":"code","50373faa":"code","6339ff71":"code","cb6a994b":"code","ca0bf43e":"code","54d8ef41":"code","78aa272c":"code","b8870eaa":"code","a3374b09":"code","a57aaec7":"code","5f75a5a0":"code","1991174c":"code","becfa97d":"code","23b0774b":"code","7466179d":"code","8db5a00d":"code","f7060cf6":"code","8c92ff41":"code","9f86c04f":"code","d3a2f89e":"code","fa8c4770":"code","4e6ad64d":"code","6c8d8b1d":"code","6b985502":"code","797fda0a":"code","78676d0d":"code","05121aa0":"code","1cafaa91":"code","a7852b90":"code","c1a70cc8":"code","5032b43c":"code","85355b35":"code","dcf1943c":"code","8cf0826c":"code","bb3916c4":"code","3db3efee":"code","bcaec552":"code","59f8efd0":"code","8b41f487":"code","2ebe6d0f":"code","50bcb9e3":"code","3b63f60b":"code","69447eba":"code","7c55290f":"markdown"},"source":{"eb0e71e3":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# import cv2\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","060eaf36":"%config Completer.use_jedi = False\n","54843ddf":"import tensorflow as tf\n\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\nfrom tensorflow.keras import Model\nimport pandas as pd\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\n","f62ddec1":"data = pd.read_csv('\/kaggle\/input\/state-farm-distracted-driver-detection\/driver_imgs_list.csv')","2a121508":"data.head()","fe3c53b0":"img = cv2.imread('\/kaggle\/input\/state-farm-distracted-driver-detection\/imgs\/train\/c0\/img_25094.jpg')\n","50373faa":"img.shape","6339ff71":"def get_im_cv2(path, img_rows, img_cols, color_type=3):\n    # Load as grayscale\n#     if color_type == 1:\n    img = cv2.imread(path,0)\n#     elif color_type == 3:\n#         img = cv2.imread(path)\n    #Reduce size\n    resized = cv2.resize(img, (img_cols, img_rows))\n    return resized","cb6a994b":"X = data[['img']]\ny = data[['classname']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\nprint(X_train.columns,y_train.columns)","ca0bf43e":"\nplt.figure(figsize=(30,30))\nfor i in range(5):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(True)\n    path = \"\/kaggle\/input\/state-farm-distracted-driver-detection\/imgs\/train\/{}\/{}\".format(y.loc[i+3,'classname'],X.loc[i+3,'img'])\n    train_image= get_im_cv2(path,200,200)\n    print(train_image.shape)\n#     print(train_image)\n#     print(type(train_image))\n\n    plt.imshow(train_image)\n    # The CIFAR labels happen to be arrays, \n    # which is why you need the extra index\n    plt.xlabel(\"_{}\".format(train_image.shape))\nplt.show()\n","54d8ef41":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","78aa272c":" model.summary()\n\n    ","b8870eaa":"image_train_arr = []\nfor i in range(len(X_train)):\n#     print((X_train.loc[i,'']))\n#     print(y_train.iloc[i,0],X_train.iloc[i,0])\n#     break\n\n    path = \"\/kaggle\/input\/state-farm-distracted-driver-detection\/imgs\/train\/{}\/{}\".format(y_train.iloc[i,0],X_train.iloc[i,0])\n    resized = get_im_cv2(path,32,32)\n    image_train_arr.append(resized)\n#     print(data.loc[i,'images'])\n    ","a3374b09":"image_test_arr = []\nfor i in range(len(X_test)):\n#     print((X_train.loc[i,'']))\n#     print(y_train.iloc[i,0],X_train.iloc[i,0])\n#     break\n\n    path = \"\/kaggle\/input\/state-farm-distracted-driver-detection\/imgs\/train\/{}\/{}\".format(y_test.iloc[i,0],X_test.iloc[i,0])\n    resized = get_im_cv2(path,32,32)\n    image_test_arr.append(resized)\n#     print(data.loc[i,'images'])","a57aaec7":"image_train_arr = np.array(image_train_arr)\nimage_test_arr = np.array(image_test_arr)\nprint(image_train_arr.shape,image_test_arr.shape)\n","5f75a5a0":"image_train_arr,image_test_arr = image_train_arr\/255.0, image_test_arr\/255.0","1991174c":"model.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10))\nmodel.add(Dense(10, activation='softmax'))","becfa97d":"model.summary()\n","23b0774b":"type(image_test_arr),type(y_test)\n","7466179d":"image_test_arr.shape,y_test.shape","8db5a00d":"image_train_arr = image_train_arr.reshape(15024,32,32,1)\nimage_test_arr = image_test_arr.reshape(7400,32,32,1)","f7060cf6":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ny_train['new-col'] = labelencoder.fit_transform(y_train)\ny_test['new-col'] = labelencoder.fit_transform(y_test)\n","8c92ff41":"y_train","9f86c04f":"y_test['new-col']","d3a2f89e":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nhistory = model.fit(image_train_arr, y_train['new-col'], epochs=30,validation_data=(image_test_arr, y_test['new-col']))\n","fa8c4770":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1.1])\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model.evaluate(image_test_arr, y_test['new-col'], verbose=2)","4e6ad64d":"test_data = pd.read_csv('\/kaggle\/input\/state-farm-distracted-driver-detection\/sample_submission.csv')\ntest_data.shape","6c8d8b1d":"test_data.columns","6b985502":"y_test","797fda0a":"test_arr = []\nfor i in range(len(test_data)):\n#     print((X_train.loc[i,'']))\n#     print(y_train.iloc[i,0],X_train.iloc[i,0])\n#     break\n\n    path = \"\/kaggle\/input\/state-farm-distracted-driver-detection\/imgs\/test\/{}\".format(test_data.iloc[i,0])\n    resized = get_im_cv2(path,32,32)\n    test_arr.append(resized)\n#     print(data.loc[i,'images'])","78676d0d":"test_arr=np.array(test_arr)\n","05121aa0":"test_arr.shape","1cafaa91":"test_arr_norm =test_arr\/255.0","a7852b90":"test_arr_norm= test_arr_norm.reshape(79726,32,32,1)","c1a70cc8":"test_output_arr = model.predict(test_arr_norm)","5032b43c":"test_output_arr","85355b35":"test_output_arr.shape","dcf1943c":"test_output_prob = pd.DataFrame(test_output_arr)\n","8cf0826c":"type(test_output_prob)","bb3916c4":"for i in range (len(test_output_prob.columns)):\n    test_output_prob[\"c{}\".format(i)] = test_output_prob.iloc[:,i]\nprint(test_output_prob.columns)","3db3efee":"test_output_prob.shape","bcaec552":"test=test_output_prob.drop([0,1,2,3,4,5,6,7,8,9], axis = 1) \n","59f8efd0":"test.columns\n","8b41f487":"result = pd.concat([test_data.iloc[:,0], test], axis=1)","2ebe6d0f":"result.shape,result.columns","50bcb9e3":"result.isnull().values.any()","3b63f60b":"result.head()","69447eba":"result.to_csv(r'result.csv',index=False)","7c55290f":"With 10 Epoch we got 0.9723 accuracy\nWith 30 Epoch we got 0.9723 accuracy\n"}}