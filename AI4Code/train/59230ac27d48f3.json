{"cell_type":{"a9b56f70":"code","9aa11e3b":"code","68e94223":"code","14f12c88":"code","1540358c":"code","3ccb7b8e":"code","6c94543c":"code","41de008c":"code","d96aa9d3":"code","df832a64":"code","6afd894a":"code","c9a050f5":"code","dd60124a":"code","ef5656ed":"code","8e12d377":"code","bc0429c0":"code","f58a32bd":"code","b186ad49":"code","933ab86e":"code","bf8fbcd4":"code","f118a63f":"code","ba6972f7":"code","75c0c5d3":"code","3042c0e1":"code","0e6799f8":"code","e01a22bf":"code","4efcd478":"code","52847c74":"code","451b6fb2":"code","5ecd0866":"code","0db95946":"code","bb5e99f8":"code","d08a0fc5":"code","d57f55eb":"code","21f6010e":"code","b19be850":"code","fdeaf726":"code","b5c81d0e":"code","01efc13d":"code","94d5b416":"code","cece1e14":"code","b2d6f004":"code","89636d3a":"code","7a3db3fe":"code","287cf12c":"code","ef5fcc84":"code","2b28a177":"code","89ae876d":"code","d1611f7d":"code","4ecaa315":"code","28b6eb03":"code","f624eba4":"code","6e64c2f0":"code","4fdfdf75":"code","ac980563":"code","39f5a932":"code","a4e633b8":"markdown","1430fdb3":"markdown","59c2e50e":"markdown","501af80b":"markdown","2fcc854e":"markdown","01299091":"markdown","2f6e2ccf":"markdown","1126cea6":"markdown","b89b0449":"markdown","1966b87e":"markdown","71e29711":"markdown","22a69ecd":"markdown","56816d42":"markdown","5dd7c25e":"markdown"},"source":{"a9b56f70":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(\"ignore\")","9aa11e3b":"df = pd.read_csv(\"..\/input\/hepatitis-c-dataset\/HepatitisCdata.csv\")\ndf.head()","68e94223":"df.drop(\"Unnamed: 0\", axis=1, inplace=True)","14f12c88":"df.dtypes","1540358c":"df.Category.unique()","3ccb7b8e":"# Mapping numeric values\n\ndf['Category'] = df['Category'].map({'0=Blood Donor': 0, '0s=suspect Blood Donor': 0, \n                                     \"1=Hepatitis\" : 1, \"2=Fibrosis\" : 1, \"3=Cirrhosis\" : 1})\n\ndf['Sex'] = df['Sex'].map({'m': 1, 'f': 2})","6c94543c":"df.head()","41de008c":"# Checking the data types again after the transformation\ndf.dtypes","d96aa9d3":"# Checking for missing values in the dataset\ndf.isna().sum()","df832a64":"# Filling missing values with the median\ndf.fillna(df.median(), inplace=True)","6afd894a":"df.isna().sum()","c9a050f5":"# Having a look at the correlation matrix\n\nfig, ax = plt.subplots(figsize=(10,8))\nsns.heatmap(df.corr(), annot=True, fmt='.1g', cmap=\"Blues_r\", cbar=False, linewidths=0.5, linecolor='grey');","dd60124a":"print ('Total Suspected Patients : {} '.format(df.Category.value_counts()[0]))\nprint ('Total Healthy Patients : {} '.format(df.Category.value_counts()[1]))","ef5656ed":"fig, ax = plt.subplots(figsize=(8,8))\n\nplt.pie(x=df[\"Category\"].value_counts(), \n        colors=[\"firebrick\",\"seagreen\"], \n        labels=[\"Suspected Patients\",\"Healthy Patients\"], \n        shadow = True, \n        explode = (0, 0.1)\n        )\n\nplt.show()","8e12d377":"df.Sex.value_counts()","bc0429c0":"fig, ax = plt.subplots(figsize=(8,8))\nplt.pie(x=df[\"Sex\"].value_counts(), \n        colors=[\"skyblue\",\"pink\"], \n        labels=[\"Male\",\"Female\"], \n        shadow = True, \n        autopct=\"%1.2f%%\", \n        explode = (0, 0.1)\n        )\nplt.show()","f58a32bd":"fig, ax =plt.subplots(5,2, figsize=(20,25)) \nplt.style.use(\"classic\")\n\n\nsns.histplot(x = df[\"Age\"], hue = df[\"Category\"], palette=\"viridis\", kde=True, ax=ax[0,0]);\nax[0,0].set_xlabel(\"Age\",fontsize=15)\n\nsns.histplot(x = df[\"ALB\"], hue = df[\"Category\"], palette=\"viridis\", kde=True, ax=ax[0,1]);\nax[0,1].set_xlabel(\"ALB\",fontsize=15)\n\n\nsns.histplot(x = df[\"ALP\"], hue = df[\"Category\"], palette=\"dark\", kde=True, ax=ax[1,0]);\nax[1,0].set_xlabel(\"ALP\",fontsize=15)\n\nsns.histplot(x = df[\"ALT\"], hue = df[\"Category\"], palette=\"dark\", kde=True, ax=ax[1,1]);\nax[1,1].set_xlabel(\"ALT\",fontsize=15)\n\n\nsns.histplot(x = df[\"AST\"], hue = df[\"Category\"], palette=\"flare\", kde=True, ax=ax[2,0]);\nax[2,0].set_xlabel(\"AST\",fontsize=15)\n\nsns.histplot(x = df[\"BIL\"], hue = df[\"Category\"], palette=\"flare\", kde=True, ax=ax[2,1]);\nax[2,1].set_xlabel(\"BIL\",fontsize=15)\n\n\nsns.histplot(x = df[\"CHE\"], hue = df[\"Category\"], palette=\"viridis\", kde=True, ax=ax[3,0]);\nax[3,0].set_xlabel(\"CHE\",fontsize=15)\n\nsns.histplot(x = df[\"CHOL\"], hue = df[\"Category\"], palette=\"viridis\", kde=True, ax=ax[3,1]);\nax[3,1].set_xlabel(\"CHOL\",fontsize=15);\n\n\nsns.histplot(x = df[\"CREA\"], hue = df[\"Category\"], palette=\"dark\", kde=True, ax=ax[4,0]);\nax[4,0].set_xlabel(\"CREA\",fontsize=15)\n\nsns.histplot(x = df[\"GGT\"], hue = df[\"Category\"], palette=\"dark\", kde=True, ax=ax[4,1]);\nax[4,1].set_xlabel(\"GGT\",fontsize=15);","b186ad49":"# X data\nX = df.drop(\"Category\", axis=1)\nX.head()","933ab86e":"# y data\ny = df[\"Category\"]\ny.head()","bf8fbcd4":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","f118a63f":"len(X_train), len(X_test)","ba6972f7":"# Scaling the data \n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","75c0c5d3":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, y_train)","3042c0e1":"LogisticRegressionScore = lr.score(X_test, y_test)\nprint(\"Accuracy obtained by Logistic Regression model:\",LogisticRegressionScore*100)","0e6799f8":"# Having a look at the confusion matrix for Logistic Regression\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nsns.set_style(\"white\")\ny_pred_lr = lr.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred_lr)\nsns.heatmap(cf_matrix, annot=True, cmap=\"Blues_r\")\nplt.title(\"Confusion Matrix for Logistic Regression\", fontsize=14, fontname=\"Helvetica\", y=1.03);","e01a22bf":"# Having a look at the classification report of Logistic Regression\n\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, y_pred_lr))","4efcd478":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)","52847c74":"RandomForestClassifierScore = rfc.score(X_test,y_test)\nprint(\"Accacy obtained by Random Forest Classifier :\", RandomForestClassifierScore*100)","451b6fb2":"# Confusion Matrix of Random Forest Classifier\n\ny_pred_rfc = rfc.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred_rfc)\nsns.heatmap(cf_matrix, annot=True, cmap=\"Blues_r\")\nplt.title(\"Confusion Matrix for Random Forest Classifier\", fontsize=14, fontname=\"Helvetica\", y=1.03);","5ecd0866":"print(metrics.classification_report(y_test, y_pred_rfc))","0db95946":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)","bb5e99f8":"KNeighborsClassifierScore = knn.score(X_test, y_test)\nprint(\"Accuracy obtained by K Neighbors Classifier :\", KNeighborsClassifierScore*100)","d08a0fc5":"# Confustion Matrix \n\ny_pred_knn = knn.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred_knn)\nsns.heatmap(cf_matrix, annot=True, cmap=\"Blues_r\")\nplt.title(\"Confusion Matrix for K Neighbors Classifier\", fontsize=14, fontname=\"Helvetica\", y=1.03);","d57f55eb":"print(metrics.classification_report(y_test,y_pred_knn))","21f6010e":"from sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier()\ntree.fit(X_train, y_train)","b19be850":"DecisionTreeClassifierScore = tree.score(X_test,y_test)\nprint(\"Accuracy obtained by Decision Tree Classifier :\", DecisionTreeClassifierScore*100)","fdeaf726":"y_pred_tree = tree.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred_tree)\nsns.heatmap(cf_matrix, annot=True, cmap=\"Blues_r\")\nplt.title(\"Confusion Metrix for Decision Tree Classifier\", fontsize=14, fontname=\"Helvetica\", y=1.03);","b5c81d0e":"print(metrics.classification_report(y_test, y_pred_tree));","01efc13d":"from catboost import CatBoostClassifier\ncat = CatBoostClassifier(iterations=10)\ncat.fit(X_train, y_train);","94d5b416":"CatBoostClassifierScore = cat.score(X_test,y_test)\nprint(\"Accuracy obtained by CatBoost Classifier model:\",CatBoostClassifierScore*100)","cece1e14":"# Confusion matrix\ny_pred_cat = cat.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred_cat)\nsns.heatmap(cf_matrix, annot=True, cmap=\"Blues_r\")\nplt.title(\"Confusion Matrix for CatBoost Classifier\", fontsize=14, fontname=\"Helvetica\", y=1.03);","b2d6f004":"# Classification Report of CatBoost Classifier\n\nprint(metrics.classification_report(y_test, y_pred_cat))","89636d3a":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier()\ngb.fit(X_train, y_train)","7a3db3fe":"GradientBoostingClassifierScore = gb.score(X_test,y_test)\nprint(\"Accuracy obtained by Gradient Boosting Classifier model:\",GradientBoostingClassifierScore*100)","287cf12c":"# Confusion matrix\ny_pred_gb = gb.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred_gb)\nsns.heatmap(cf_matrix, annot=True, cmap=\"Blues_r\")\nplt.title(\"Confusion Matrix for Gradient Boosting Classifier\", fontsize=14, fontname=\"Helvetica\", y=1.03);","ef5fcc84":"# Classification Report of Gradient Boosting Classifier\n\nprint(metrics.classification_report(y_test, y_pred_gb))","2b28a177":"plt.style.use(\"seaborn\")\n\nx = [\"LogisticRegression\", \n     \"Decision Tree Classifier\", \n     \"RandomForestClassifier\", \n     \"KNeighborsClassifier\", \n     \"CatBoost Classifier\", \n     \"Gradient Boosting Classifier\"]\n\ny = [LogisticRegressionScore, \n     DecisionTreeClassifierScore, \n     RandomForestClassifierScore, \n     KNeighborsClassifierScore, \n     CatBoostClassifierScore, \n     GradientBoostingClassifierScore]\n\nfig, ax = plt.subplots(figsize=(10,5))\nsns.barplot(x=x,y=y, palette=\"Blues_r\");\nplt.ylabel(\"Model Accuracy\")\nplt.xticks(rotation=40)\nplt.title(\"Model Comparison - Model Accuracy\", fontsize=14, fontname=\"Helvetica\", y=1.03);","89ae876d":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'bootstrap': [True],\n    'max_depth': [80, 90, 100, 110],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'criterion' : ['gini', 'entropy'],\n    'n_estimators': [100, 200, 300, 1000]\n}\n\ngrid_search_rfc = GridSearchCV(estimator = rfc, \n                           param_grid = param_grid, \n                           cv = 3, n_jobs = -1, verbose = 2)","d1611f7d":"grid_search_rfc.fit(X_train, y_train)","4ecaa315":"grid_search_rfc.best_params_","28b6eb03":"grid_search_rfc.best_score_","f624eba4":"grid_search_rfc_predict = grid_search_rfc.predict(X_test)","6e64c2f0":"print('Improvement in Random Forest Classifier after GridSearchCV: {:0.2f}%.'.format(100 * (grid_search_rfc.best_score_ - RandomForestClassifierScore) \/ RandomForestClassifierScore))","4fdfdf75":"# Comparing the results after the improvement in Random Forest Classifier\n\nplt.style.use(\"seaborn\")\n\nx = [\"Random Forest Classifier\",  \n     \"GridSearch-RandomForestClassifier\"]\n\ny = [RandomForestClassifierScore,  \n     grid_search_rfc.best_score_]\n\nfig, ax = plt.subplots(figsize=(5,5))\nsns.barplot(x=x,y=y, palette=\"Blues_r\");\nplt.ylabel(\"Accuracy\")\nplt.xticks(rotation=45)\nplt.title(\"Random Forest Classifier  vs  GridSearched Random Forest Classifier\", fontsize=14, fontname=\"Helvetica\", y=1.03);","ac980563":"# Comparing the GridSearch-Random Forest Regression and Gradient Boosting Classifier \n\nplt.style.use(\"seaborn\")\n\nx = [\"Gradient Boosting Classifier\",\n     \"GridSearch-Random Forest Regression\"]\n\ny = [GradientBoostingClassifierScore,\n     grid_search_rfc.best_score_]\n\nfig, ax = plt.subplots(figsize=(5,5))\nsns.barplot(x=x,y=y, palette=\"Blues_r\");\nplt.ylabel(\"Accuracy\")\nplt.xticks(rotation=30)\nplt.title(\"Gradient Boosting Classifier  vs  GridSearched Random Forest Regression\", fontsize=14, fontname=\"Helvetica\", y=1.03);","39f5a932":"# Classification Report of GridSearch-RandomForestRegression\n\nprint(classification_report(y_test, grid_search_rfc_predict))","a4e633b8":"## LogisticRegression","1430fdb3":"### After Hyperparameter tuning, the Random Forest Regression model performs better than the Gradient Boosting Classifier which was not the case before!","59c2e50e":"## DecisionTreeClassifier","501af80b":"## Hyperparameter Tuning on Random Forest Classifier","2fcc854e":"## Importing Libraries","01299091":"## Loading up the data","2f6e2ccf":"## K Neighbors Classifier","1126cea6":"#### If you like my work, It will be really great of you to upvote this notebook!\n#### If not then you leaving a comment on what do I need to work on and improve will be really helpful!","b89b0449":"## Splitting the data into training and test datasets\nHere, we are trying to predict whether the patient has Hepatitis C or not using the given data. Hence, the `Category` will be the y label and rest of the data will be the X or the input data.","1966b87e":"* `Gradient Boosting Classifier` and `Random Forest Regression` perform best on the test set.","71e29711":"## Random Forest Classifier","22a69ecd":"## Gradient Boosting Classifier","56816d42":"## CatBoost Classifier","5dd7c25e":"# Predicting Hepatitis C \ud83e\ude7a"}}