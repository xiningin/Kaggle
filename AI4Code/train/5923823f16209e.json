{"cell_type":{"3bf22920":"code","c9eac3c5":"code","03b42398":"code","48a20a3f":"code","dabb36bd":"code","dd064a30":"code","bdbd4e75":"code","a3f83b5c":"code","0749d8c0":"code","64298b3b":"code","ca72790d":"code","84fbc435":"code","cebbbb76":"code","c60e1c20":"code","08608201":"code","38350f9e":"code","18dd97f2":"code","e8717d9b":"code","b1717f61":"code","6b5651e7":"code","979d4c29":"code","59dfc20a":"code","72ae3cfe":"markdown","958bf3c0":"markdown","86f7d5fd":"markdown","b7390d5c":"markdown","1fbcd889":"markdown","69f2df80":"markdown","f9822d5e":"markdown","ddac9f58":"markdown","7ade9019":"markdown","41fdc25e":"markdown","1dead88f":"markdown"},"source":{"3bf22920":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import KFold\n\nfrom cuml.svm import SVR, SVC\nfrom sklearn.svm import SVC as skSVC\n\nimport lightgbm as lgb\n\nplt.style.use('ggplot')\nimport warnings\nwarnings.filterwarnings('ignore')","c9eac3c5":"train = pd.read_parquet('..\/input\/kaggle-pog-series-s01e01\/train.parquet')\ntest = pd.read_parquet('..\/input\/kaggle-pog-series-s01e01\/test.parquet')\nss = pd.read_csv('..\/input\/kaggle-pog-series-s01e01\/sample_submission.csv')\ntrain_tn = pd.read_parquet('..\/input\/pog-youtube-like-thumbnail-feature-embeddings\/train_thumbnail_feats.parquet')\ntest_tn = pd.read_parquet('..\/input\/pog-youtube-like-thumbnail-feature-embeddings\/test_thumbnail_feats.parquet')","03b42398":"train.shape, train_tn.shape, test.shape, test_tn.shape","48a20a3f":"cfg = {\n    'TARGET' : 'target',\n    'N_FOLDS' : 5,\n    'RANDOM_STATE': 529,\n    'N_ESTIMATORS' : 50_000,\n    'LEARNING_RATE': 0.1\n}\n\ntrain_vids = train['video_id'].unique()","dabb36bd":"kf = KFold(n_splits=cfg['N_FOLDS'],\n           shuffle=True,\n           random_state=cfg['RANDOM_STATE'])\n\n# Create Folds\nfold = 1\nfor tr_idx, val_idx in kf.split(train_vids):\n    fold_vids = train_vids[val_idx]\n    train.loc[train['video_id'].isin(fold_vids), 'fold'] = fold\n    fold += 1\ntrain['fold'] = train['fold'].astype('int')","dd064a30":"train.groupby('fold')['target'].agg(['std','mean','count'])","bdbd4e75":"train = train.merge(train_tn[['id'] + [f'f{n}' for n in range(1000)]],\n            how='left',\n            on=['id'],\n           )\n\ntest = test.merge(test_tn[['id'] + [f'f{n}' for n in range(1000)]],\n            how='left',\n            on=['id'],\n           )","a3f83b5c":"tn_feat_cols = [f'f{n}' for n in range(1000)]","0749d8c0":"train[tn_feat_cols] = train[tn_feat_cols].fillna(0)\ntest[tn_feat_cols] = test[tn_feat_cols].fillna(0)","64298b3b":"def create_features(df, train=True):\n    \"\"\"\n    Adds features to training or test set.\n    \"\"\"\n    df['publishedAt'] = pd.to_datetime(df['publishedAt'])\n    df['trending_date'] = pd.to_datetime(df['trending_date'], utc=True)\n    \n    # Feature 1 - Age of video\n    df['video_age_seconds'] = (df['trending_date'] - df['publishedAt']) \\\n        .dt.total_seconds().astype('int')\n    \n    # Trending day of week As a category\n    df['trending_dow'] = df['trending_date'].dt.day_name()\n    df['trending_dow']= df['trending_dow'].astype('category')\n    \n    df['published_dow'] = df['publishedAt'].dt.day_name()\n    df['published_dow']= df['published_dow'].astype('category')\n    \n    df['categoryId'] = df['categoryId'].astype('category')\n    \n    df['channel_occurance'] = df['channelId'].map(\n        df['channelId'].value_counts().to_dict())\n\n    df['channel_unique_video_count'] = df['channelId'].map(\n        df.groupby('channelId')['video_id'].nunique().to_dict())\n    \n    df['video_occurance_count'] = df.groupby('video_id')['trending_date'] \\\n        .rank().astype('int')\n    \n    \n    # One Hot Encode Features\n    df = pd.concat([df,\n           pd.get_dummies(df['trending_dow'], prefix='trending')\n          ], axis=1\n         )\n\n    df = pd.concat([df,\n               pd.get_dummies(df['published_dow'], prefix='pub')\n              ], axis=1\n             )\n\n    df = pd.concat([df,\n               pd.get_dummies(df['categoryId'], prefix='catid')\n              ], axis=1\n             )\n    return df","ca72790d":"train['isTrain'] = True\ntest['isTrain'] = False\ntt = pd.concat([train, test]).reset_index(drop=True).copy()\ntt = create_features(tt)\ntrain_feats = tt.query('isTrain').reset_index(drop=True).copy()\ntest_feats = tt.query('isTrain == False').reset_index(drop=True).copy()","84fbc435":"# FEATURES = ['video_age_seconds',\n#             'trending_dow',\n#             'published_dow',\n#             'duration_seconds',\n#             'categoryId',\n#             'comments_disabled',\n#             'ratings_disabled',\n#             'channel_occurance',\n#             'channel_unique_video_count',\n#             'video_occurance_count',\n#             'pca0', 'pca1', 'pca2', 'pca3', 'pca4'\n# ]\nFEATURES = tn_feat_cols\nTARGET = ['target']","cebbbb76":"# FEATURES","c60e1c20":"X_test = test_feats[FEATURES]\noof = train_feats[['id','target','fold']].reset_index(drop=True).copy()\nsubmission_df = test[['id']].copy()","08608201":"# Example Fold 1\nfor fold in range(1, 6):\n    print(f'===== Running for fold {fold} =====')\n    # Split train \/ val\n    X_tr = train_feats.query('fold != @fold')[FEATURES]\n    y_tr = train_feats.query('fold != @fold')[TARGET]\n    X_val = train_feats.query('fold == @fold')[FEATURES]\n    y_val = train_feats.query('fold == @fold')[TARGET]\n    print(X_tr.shape, y_tr.shape, X_val.shape, y_val.shape)\n\n    # Create our model\n    model = SVR(C=16.0, kernel='rbf', degree=3, max_iter=40_000, output_type='numpy')\n    # Fit our model\n    model.fit(X_tr, y_tr,)\n\n    # Predicting on validation set\n    fold_preds = model.predict(X_val)\n    oof.loc[oof['fold'] == fold, 'preds'] = fold_preds\n    # Score validation set\n    fold_score = mean_absolute_error(\n        oof.query('fold == @fold')['target'],\n        oof.query('fold == @fold')['preds']\n    )\n\n    # Predicting on test\n    fold_test_pred = model.predict(X_test)\n    submission_df[f'pred_{fold}'] = fold_test_pred\n    print(f'Score of this fold is {fold_score:0.6f}')","38350f9e":"oof_score = mean_absolute_error(oof['target'], oof['preds'])\nprint(f'Out of fold score {oof_score:0.6f}')","18dd97f2":"FEATURES = ['video_age_seconds',\n#             'trending_dow', # Cat\n#             'published_dow', # Cat\n            'duration_seconds',\n#             'categoryId', # Cat\n            'comments_disabled',\n            'ratings_disabled',\n            'channel_occurance',\n            'channel_unique_video_count',\n            'video_occurance_count',\n#             'pca0', 'pca1', 'pca2', 'pca3', 'pca4'\n             'trending_Friday',\n             'trending_Monday',\n             'trending_Saturday',\n             'trending_Sunday',\n             'trending_Thursday',\n             'trending_Tuesday',\n             'trending_Wednesday',\n             'pub_Friday',\n             'pub_Monday',\n             'pub_Saturday',\n             'pub_Sunday',\n             'pub_Thursday',\n             'pub_Tuesday',\n             'pub_Wednesday',\n             'catid_1',\n             'catid_2',\n             'catid_10',\n             'catid_15',\n             'catid_17',\n             'catid_19',\n             'catid_20',\n             'catid_22',\n             'catid_23',\n             'catid_24',\n             'catid_25',\n             'catid_26',\n             'catid_27',\n             'catid_28',\n             'catid_29'\n            \n]\n# FEATURES = tn_feat_cols\nTARGET = ['target']","e8717d9b":"X_test = test_feats[FEATURES]\nX_test = X_test.astype('float')\nX_test = X_test.fillna(0)\n\noof = train_feats[['id','target','fold']].reset_index(drop=True).copy()\nsubmission_df = test[['id']].copy()\n\nfor fold in range(1, 6):\n    print(f'===== Running for fold {fold} =====')\n    # Split train \/ val\n    X_tr = train_feats.query('fold != @fold')[FEATURES]\n    y_tr = train_feats.query('fold != @fold')[TARGET]\n    X_val = train_feats.query('fold == @fold')[FEATURES]\n    y_val = train_feats.query('fold == @fold')[TARGET]\n    \n    # Force as floats\n    X_tr= X_tr.astype('float')\n    X_val= X_val.astype('float')\n    \n    X_tr = X_tr.fillna(0)\n    X_val = X_val.fillna(0)\n\n    print(X_tr.shape, y_tr.shape, X_val.shape, y_val.shape)\n\n    # Create our model\n    model = SVR(C=1, kernel='rbf', degree=3, max_iter=5_000, output_type='numpy')\n    # Fit our model\n    model.fit(X_tr, y_tr,)\n\n    # Predicting on validation set\n    fold_preds = model.predict(X_val)\n    oof.loc[oof['fold'] == fold, 'preds'] = fold_preds\n    # Score validation set\n    fold_score = mean_absolute_error(\n        oof.query('fold == @fold')['target'],\n        oof.query('fold == @fold')['preds']\n    )\n\n    # Predicting on test\n    fold_test_pred = model.predict(X_test)\n    submission_df[f'pred_{fold}'] = fold_test_pred\n    print(f'Score of this fold is {fold_score:0.6f}')","b1717f61":"FEATURES = ['video_age_seconds',\n#             'trending_dow', # Cat\n#             'published_dow', # Cat\n            'duration_seconds',\n#             'categoryId', # Cat\n            'comments_disabled',\n            'ratings_disabled',\n            'channel_occurance',\n            'channel_unique_video_count',\n            'video_occurance_count',\n#             'pca0', 'pca1', 'pca2', 'pca3', 'pca4'\n             'trending_Friday',\n             'trending_Monday',\n             'trending_Saturday',\n             'trending_Sunday',\n             'trending_Thursday',\n             'trending_Tuesday',\n             'trending_Wednesday',\n             'pub_Friday',\n             'pub_Monday',\n             'pub_Saturday',\n             'pub_Sunday',\n             'pub_Thursday',\n             'pub_Tuesday',\n             'pub_Wednesday',\n             'catid_1',\n             'catid_2',\n             'catid_10',\n             'catid_15',\n             'catid_17',\n             'catid_19',\n             'catid_20',\n             'catid_22',\n             'catid_23',\n             'catid_24',\n             'catid_25',\n             'catid_26',\n             'catid_27',\n             'catid_28',\n             'catid_29'\n] + tn_feat_cols\n# FEATURES = tn_feat_cols\nTARGET = ['target']","6b5651e7":"X_test = test_feats[FEATURES]\nX_test = X_test.astype('float')\nX_test = X_test.fillna(0)\n\noof = train_feats[['id','target','fold']].reset_index(drop=True).copy()\nsubmission_df = test[['id']].copy()\n\nfor fold in range(1, 6):\n    print(f'===== Running for fold {fold} =====')\n    # Split train \/ val\n    X_tr = train_feats.query('fold != @fold')[FEATURES]\n    y_tr = train_feats.query('fold != @fold')[TARGET]\n    X_val = train_feats.query('fold == @fold')[FEATURES]\n    y_val = train_feats.query('fold == @fold')[TARGET]\n    \n    # Force as floats\n    X_tr= X_tr.astype('float')\n    X_val= X_val.astype('float')\n    \n    X_tr = X_tr.fillna(0)\n    X_val = X_val.fillna(0)\n\n    print(X_tr.shape, y_tr.shape, X_val.shape, y_val.shape)\n\n    # Create our model\n    model = SVR(C=1, kernel='linear', degree=3, max_iter=5_000, output_type='numpy')\n    # Fit our model\n    model.fit(X_tr, y_tr,)\n\n    # Predicting on validation set\n    fold_preds = model.predict(X_val)\n    oof.loc[oof['fold'] == fold, 'preds'] = fold_preds\n    # Score validation set\n    fold_score = mean_absolute_error(\n        oof.query('fold == @fold')['target'],\n        oof.query('fold == @fold')['preds']\n    )\n\n    # Predicting on test\n    fold_test_pred = model.predict(X_test)\n    submission_df[f'pred_{fold}'] = fold_test_pred\n    print(f'Score of this fold is {fold_score:0.6f}')","979d4c29":"pred_cols = [c for c in submission_df.columns if c.startswith('pred_')]\n\nsubmission_df['target'] = submission_df[pred_cols].mean(axis=1)\n# Visually check correlation between fold predictions\nsns.heatmap(submission_df[pred_cols].corr(), annot=True)","59dfc20a":"submission_df[['id','target']] \\\n    .to_csv('submission.csv', index=False)","72ae3cfe":"# SVR with just old features","958bf3c0":"# Create Submission","86f7d5fd":"# Pog Competition Baseline\n- Inspiration from Giba's solution: https:\/\/www.kaggle.com\/titericz\/imagenet-embeddings-rapids-svr-finetuned-models\n- Use image embeddings and SVC to predict video likes!","b7390d5c":"# Feature Engineering","1fbcd889":"# Setup KFold","69f2df80":"# SVR Model with both Embedding Features + Old Features","f9822d5e":"# Score with just Embedding Features -> 0.05489\n## Score (from before with lgbm) -> 0.018522","ddac9f58":"# Merge Features with Thumbnail Embeddings","7ade9019":"# Train LGBM Model","41fdc25e":"# Set Target and Features","1dead88f":"# Create Folds\n- This is how we will later split when validating our models\n- I should have used GroupKFold"}}