{"cell_type":{"648e6fc8":"code","97d5b665":"code","a906ff71":"code","768f2349":"code","d312eff3":"code","85d152bc":"code","858c1cfc":"code","d095e51d":"code","e50a2504":"code","270fff2a":"code","a78ea469":"code","feaad6d5":"code","eb332008":"code","f1d2fbf8":"code","b77721b3":"code","f955cef3":"code","b16a5d93":"code","24c1eb80":"code","779b887b":"code","247111f7":"markdown","54aa58b8":"markdown","8bad412b":"markdown","e413c096":"markdown","f847d0d3":"markdown"},"source":{"648e6fc8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","97d5b665":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn\nimport sklearn\n%matplotlib inline","a906ff71":"from tensorflow.keras.datasets import mnist     \n(X_train, Y_train), (X_test, Y_test) = mnist.load_data()","768f2349":"print('X_train Shape :' + str(X_train.shape))   #shape of Data\nprint('Y_train Shape :' + str(Y_train.shape))\nprint('X_test Shape :' + str(X_test.shape))\nprint('Y_test Shape :' + str(Y_test.shape))","d312eff3":"X_pixels =X_train.flatten()    #flattening the input pixel from 28*28 to 784\nX=X_pixels.reshape(60000,784)\n","85d152bc":"Xtest = X_test.flatten()\nXtest = Xtest.reshape(10000,784)","858c1cfc":"print(X.shape)\nprint(Xtest.shape)","d095e51d":"import matplotlib\nsome_digit = X[2]\nsome_digit_image = some_digit.reshape(28, 28)\nplt.imshow(some_digit_image, cmap = matplotlib.cm.binary,\n interpolation=\"nearest\")\nplt.axis(\"off\")\nplt.show()\n","e50a2504":"from sklearn.svm import SVC   #using Support vector machine classifier","270fff2a":"svc = SVC(kernel='rbf', C=1).fit(X, Y_train)    #training the data\ny_pred = svc.predict(Xtest)   #prediction","a78ea469":"#importing confusion matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion = confusion_matrix(Y_test, y_pred)\nprint('Confusion Matrix\\n')\nprint(confusion)","feaad6d5":"import seaborn as sns\nplt.figure(figsize=(15,8))\nsns.heatmap(confusion, annot=True, \n             cmap='Blues')","eb332008":"#importing accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nprint('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(Y_test, y_pred)))\n\nprint('Micro Precision: {:.2f}'.format(precision_score(Y_test, y_pred, average='micro')))\nprint('Micro Recall: {:.2f}'.format(recall_score(Y_test, y_pred, average='micro')))\nprint('Micro F1-score: {:.2f}\\n'.format(f1_score(Y_test, y_pred, average='micro')))\n\nprint('Macro Precision: {:.2f}'.format(precision_score(Y_test, y_pred, average='macro')))\nprint('Macro Recall: {:.2f}'.format(recall_score(Y_test, y_pred, average='macro')))\nprint('Macro F1-score: {:.2f}\\n'.format(f1_score(Y_test, y_pred, average='macro')))\n\nprint('Weighted Precision: {:.2f}'.format(precision_score(Y_test, y_pred, average='weighted')))\nprint('Weighted Recall: {:.2f}'.format(recall_score(Y_test, y_pred, average='weighted')))\nprint('Weighted F1-score: {:.2f}'.format(f1_score(Y_test, y_pred, average='weighted')))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification Report\\n')\nprint(classification_report(Y_test, y_pred, target_names=['Class 1', 'Class 2', 'Class 3','Class 4','Class 5','Class 6','Class 7','Class 8','Class 9','Class 10']))","f1d2fbf8":"plt.matshow(confusion, cmap=plt.cm.gray)\nplt.show()\n","b77721b3":"row_sums = confusion.sum(axis=1, keepdims=True)\nnorm_conf_mx = confusion \/ row_sums","f955cef3":"\nnp.fill_diagonal(confusion, 0)\nplt.matshow(confusion, cmap=plt.cm.gray)\nplt.show()\n","b16a5d93":"from sklearn.model_selection import cross_val_predict\nsv = SVC(kernel='rbf', C=1)\ny_train_pred = cross_val_predict(sv, X, Y_train, cv=3)","24c1eb80":"# EXTRA\ndef plot_digits(instances, images_per_row=10, **options):\n    size = 28\n    images_per_row = min(len(instances), images_per_row)\n    images = [instance.reshape(size,size) for instance in instances]\n    n_rows = (len(instances) - 1) \/\/ images_per_row + 1\n    row_images = []\n    n_empty = n_rows * images_per_row - len(instances)\n    images.append(np.zeros((size, size * n_empty)))\n    for row in range(n_rows):\n        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n        row_images.append(np.concatenate(rimages, axis=1))\n    image = np.concatenate(row_images, axis=0)\n    plt.imshow(image, cmap = matplotlib.cm.binary, **options)\n    plt.axis(\"off\")","779b887b":"\ncl_a, cl_b = 3, 5\nX_aa = X[(Y_train == cl_a) & (y_train_pred == cl_a)]\nX_ab = X[(Y_train == cl_a) & (y_train_pred == cl_b)]\nX_ba = X[(Y_train == cl_b) & (y_train_pred == cl_a)]\nX_bb = X[(Y_train == cl_b) & (y_train_pred == cl_b)]\nplt.figure(figsize=(8,8))\nplt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\nplt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\nplt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\nplt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\nplt.show()","247111f7":"## This confusion matrix looks fairly good, since most images are on the main diagonal,which means that they were classified correctly. ","54aa58b8":"*The columns or cells appearing bright represents the errors our classifier has made.\nSome rows are pretty dark, such as row 1 it means our classifier has identified numeric digit 1 correctly.\nNotice that the errors are not perfectly symmetrical; for example, there are more 7s misclassified as 9s than the reverse.\n*","8bad412b":"# Error Analysis\nDividing each value in the confusion matrix by the number of images in the corresponding class, so we can compare error\nrates instead of absolute number of errors ","e413c096":"Filling the diagonal with zeros to keep only the errors, and  plotting the result.\nThe rows represent actual classes, while columns represent predicted classes.","f847d0d3":"The two 5\u00d75 blocks on the left show digits classified as 3s, and the two 5\u00d75 blocks on\nthe right show images classified as 5s"}}