{"cell_type":{"72a2dd9b":"code","b6ddc5e5":"code","1fcbd4c2":"code","c89b54ee":"code","8ea1411a":"code","e3d3f68b":"code","f17ec79c":"code","063065b4":"code","8feaa08e":"code","c0c2fb05":"code","a895b0f8":"code","a9d7cf03":"code","b5f6432f":"code","ff093f14":"code","5f3fe13c":"code","75536949":"markdown","f149301d":"markdown","cec69f98":"markdown","c46400c8":"markdown","2ea7e437":"markdown"},"source":{"72a2dd9b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b6ddc5e5":"df = pd.read_csv('\/kaggle\/input\/churn-modelling\/Churn_Modelling.csv')\ndf.head()","1fcbd4c2":"X = df.iloc[:,3:13]\ny = df.iloc[:, 13]\n\nX.Geography.unique()\n\nX['Gender'].unique()\n\ngeo_cat = pd.get_dummies(X[\"Geography\"], drop_first = True)\ngender_cat = pd.get_dummies(X['Gender'], drop_first = True)\n\n# merge geo_cat and gender_cat into our X.\n\nX = pd.concat([X, geo_cat, gender_cat], axis = 1)\n\nX = X.drop(['Geography',\"Gender\"], axis = 1)","c89b54ee":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 9)","8ea1411a":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","e3d3f68b":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Embedding, Flatten, BatchNormalization\nfrom keras.layers import LeakyReLU, PReLU, ELU\nfrom keras.layers import Dropout\nfrom keras.activations import relu, sigmoid","f17ec79c":"# Define a method to create a model.\ndef create_model(layers, activation):\n    model = Sequential()\n    \n    for i, nodes in enumerate(layers):\n        if i == 0:\n            model.add(Dense(nodes, input_dim = X_train.shape[1]))\n            model.add(Activation(activation))\n            model.add(Dropout(0.3))\n        else:\n            model.add(Dense(nodes))\n            model.add(Activation(activation))\n            model.add(Dropout(0.3))\n            \n    model.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n    \n    model.compile(optimizer ='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    \n    return model","063065b4":"model = KerasClassifier(build_fn = create_model, verbose = 0)","8feaa08e":"# layers = [[20], [40,20], [45,30,15]]\n# In case your have runtime error, you may need to change the list of lists that specify the layers to a list of tuples\n# RuntimeError: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fb8700b6f90>, as the constructor either does not set or modifies parameter layers\n# https:\/\/stackoverflow.com\/questions\/59818584\/cannot-clone-object-keras-wrappers\n\nlayers = [(20,), (40,20), (45,30,15)] \n\n# it indicates that we need a layers as 1 hidden layer with 20 neurons.\n# [40,20] will indicates 2 hidden layer, with 40 neurns at first layer, and 20 neurons on 2nd hidden layer\n# and so on\n\n# Dont forget to add (,) in (20,) otherwise it will throw an error like : TypeError: 'int' object is not iterable This is because single tuple without comma(,) is treated as int.\n","c0c2fb05":"activations = ['sigmoid', 'relu']\n\nparam_grid =dict(layers = layers, activation = activations, batch_size = [128, 256], epochs = [30])\n\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 5)","a895b0f8":"grid_result = grid.fit(X_train, y_train)","a9d7cf03":"grid_result.best_score_, grid_result.best_params_","b5f6432f":"y_pred = grid.predict(X_test)\ny_pred = (y_pred > 0.5)","ff093f14":"# Lets see the accuracy of our Test Dataset.\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","5f3fe13c":"from sklearn.metrics import accuracy_score\nscore = accuracy_score(y_pred, y_test)\n\nscore","75536949":"# Best Model ","f149301d":"Above is the Best parameters and activation function and epochs to be use for better result.","cec69f98":"# Deep Learning - Hyper Parameter Tuning\n\n* We can use Hyper-Parameer to decide Number of Hidden Layers required in a Neural Network.\n\n","c46400c8":"# Perform Hyperparameter Optimization","2ea7e437":"Using the dataset of Churn Modelling. Refer to https:\/\/www.kaggle.com\/dskagglemt\/churn-modelling-using-keras "}}