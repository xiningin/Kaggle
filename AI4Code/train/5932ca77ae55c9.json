{"cell_type":{"07b2c9f0":"code","b2101ae3":"code","6f878b52":"code","3aa327a2":"code","b8c88489":"code","3376a00e":"code","23f79e94":"code","8864761c":"code","8b3a9e81":"code","0f9a9da0":"code","291946f1":"code","81a5f0a8":"code","e1a37ee7":"code","fc93616a":"code","255bc204":"code","38224ff3":"code","fb46c7a0":"code","7a1d13f9":"code","a8553bca":"code","b96e877c":"code","7680e3b3":"code","53e30f0f":"code","05d8da0c":"code","ddf4dfac":"code","d9470fc5":"code","8236e73d":"code","2c8f11ac":"code","9cb968c8":"code","13195721":"code","52fc7548":"code","126414bc":"code","f45f180e":"code","3387a4e1":"code","f85d3e0c":"code","b4e0bd4d":"code","c24e24bc":"code","6f1f921e":"code","ba2062fb":"code","06523007":"code","ef06c9d2":"code","b7c8b7bb":"code","23f4266f":"code","56c839e5":"markdown","881929bf":"markdown","44731e56":"markdown","604a4bd1":"markdown","2f99941b":"markdown","d6b5cbb2":"markdown","31156fe2":"markdown","c613c1b8":"markdown","ce4a55a4":"markdown","bba3f796":"markdown","9a69d9ec":"markdown","23a5f196":"markdown","21667ecd":"markdown","c89c5bfa":"markdown","598f9d8f":"markdown","b0d35789":"markdown","4cd23e51":"markdown","0584e44a":"markdown","d2f6bbde":"markdown","30b63a43":"markdown","9248898c":"markdown","d89ac0c9":"markdown","e3a94b21":"markdown","becdbeae":"markdown","01e44f10":"markdown","9da0ceec":"markdown","03f5f12c":"markdown","501fbe32":"markdown","3463da05":"markdown","2ff214d2":"markdown","6359aca5":"markdown","97300024":"markdown"},"source":{"07b2c9f0":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport time\nfrom datetime import datetime\nfrom scipy import integrate, optimize\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML libraries\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import Ridge, RidgeCV","b2101ae3":"submission_example = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-2\/submission.csv\")\ntest = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-2\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-2\/train.csv\")\ndisplay(train.head(5))\ndisplay(train.describe())\nprint(\"Number of Country_Region: \", train['Country_Region'].nunique())\nprint(\"Dates go from day\", max(train['Date']), \"to day\", min(train['Date']), \", a total of\", train['Date'].nunique(), \"days\")\nprint(\"Countries with Province\/State informed: \", train[train['Province_State'].isna()==False]['Country_Region'].unique())","6f878b52":"#confirmed_country = train.groupby(['Country\/Region', 'Province\/State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country = train.groupby(['Country\/Region', 'Province\/State']).agg({'Fatalities':['sum']})\nconfirmed_total_date = train.groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date = train.groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date = confirmed_total_date.join(fatalities_total_date)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\nfatalities_total_date.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases\", size=13)\nax2.set_ylabel(\"Number of cases\", size=13)\nax2.set_xlabel(\"Date\", size=13)","3aa327a2":"#confirmed_country_noChina = train[train['Country_Region']!='China'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_noChina = train[train['Country_Region']!='China'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_noChina = train[train['Country_Region']!='China'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_noChina = train[train['Country_Region']!='China'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_noChina = confirmed_total_date_noChina.join(fatalities_total_date_noChina)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\ntotal_date_noChina.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases excluding China\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\nfatalities_total_date_noChina.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases excluding China\", size=13)\nax2.set_ylabel(\"Number of cases\", size=13)\nax2.set_xlabel(\"Date\", size=13)","b8c88489":"#confirmed_country_China = train[train['Country_Region']=='China'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_China = train[train['Country_Region']=='China'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_China = train[train['Country_Region']=='China'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_China = train[train['Country_Region']=='China'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_China = confirmed_total_date_China.join(fatalities_total_date_China)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\ntotal_date_China.plot(ax=ax1)\nax1.set_title(\"China confirmed cases\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\nfatalities_total_date_China.plot(ax=ax2, color='orange')\nax2.set_title(\"China deceased cases\", size=13)\nax2.set_ylabel(\"Number of cases\", size=13)\nax2.set_xlabel(\"Date\", size=13)","3376a00e":"#confirmed_country_Italy = train[train['Country_Region']=='Italy'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Italy = train[train['Country_Region']=='Italy'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Italy = train[train['Country_Region']=='Italy'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Italy = train[train['Country_Region']=='Italy'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Italy = confirmed_total_date_Italy.join(fatalities_total_date_Italy)\n\n#confirmed_country_Spain = train[train['Country_Region']=='Spain'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Spain = train[train['Country_Region']=='Spain'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Spain = train[train['Country_Region']=='Spain'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Spain = train[train['Country_Region']=='Spain'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Spain = confirmed_total_date_Spain.join(fatalities_total_date_Spain)\n\n#confirmed_country_UK = train[train['Country_Region']=='United Kingdom'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_UK = train[train['Country_Region']=='United Kingdom'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_UK = train[train['Country_Region']=='United Kingdom'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_UK = train[train['Country_Region']=='United Kingdom'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_UK = confirmed_total_date_UK.join(fatalities_total_date_UK)\n\n#confirmed_country_Australia = train[train['Country_Region']=='Australia'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Australia = train[train['Country_Region']=='Australia'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Australia = train[train['Country_Region']=='Australia'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Australia = train[train['Country_Region']=='Australia'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Australia = confirmed_total_date_Australia.join(fatalities_total_date_Australia)\n\n#confirmed_country_Singapore = train[train['Country_Region']=='Singapore'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Singapore = train[train['Country_Region']=='Singapore'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Singapore = train[train['Country_Region']=='Singapore'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Singapore = train[train['Country_Region']=='Singapore'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Singapore = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_date_Italy.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nplt.subplot(2, 2, 2)\ntotal_date_Spain.plot(ax=plt.gca(), title='Spain')\n\nplt.subplot(2, 2, 3)\ntotal_date_UK.plot(ax=plt.gca(), title='United Kingdom')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nplt.subplot(2, 2, 4)\ntotal_date_Singapore.plot(ax=plt.gca(), title='Singapore')","23f79e94":"pop_italy = 60486683.\npop_spain = 46749696.\npop_UK = 67784927.\npop_singapore = 5837230.\n\ntotal_date_Italy.ConfirmedCases = total_date_Italy.ConfirmedCases\/pop_italy*100.\ntotal_date_Italy.Fatalities = total_date_Italy.ConfirmedCases\/pop_italy*100.\ntotal_date_Spain.ConfirmedCases = total_date_Spain.ConfirmedCases\/pop_spain*100.\ntotal_date_Spain.Fatalities = total_date_Spain.ConfirmedCases\/pop_spain*100.\ntotal_date_UK.ConfirmedCases = total_date_UK.ConfirmedCases\/pop_UK*100.\ntotal_date_UK.Fatalities = total_date_UK.ConfirmedCases\/pop_UK*100.\ntotal_date_Singapore.ConfirmedCases = total_date_Singapore.ConfirmedCases\/pop_singapore*100.\ntotal_date_Singapore.Fatalities = total_date_Singapore.ConfirmedCases\/pop_singapore*100.\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_date_Italy.ConfirmedCases.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Fraction of population infected\")\nplt.ylim(0, 0.06)\n\nplt.subplot(2, 2, 2)\ntotal_date_Spain.ConfirmedCases.plot(ax=plt.gca(), title='Spain')\nplt.ylim(0, 0.06)\n\nplt.subplot(2, 2, 3)\ntotal_date_UK.ConfirmedCases.plot(ax=plt.gca(), title='United Kingdom')\nplt.ylabel(\"Fraction of population infected\")\nplt.ylim(0, 0.005)\n\nplt.subplot(2, 2, 4)\ntotal_date_Singapore.ConfirmedCases.plot(ax=plt.gca(), title='Singapore')\nplt.ylim(0, 0.005)","8864761c":"#confirmed_country_Italy = train[(train['Country_Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Italy = train[(train['Country_Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Italy = train[(train['Country_Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Italy = train[(train['Country_Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Italy = confirmed_total_date_Italy.join(fatalities_total_date_Italy)\n\n#confirmed_country_Spain = train[(train['Country_Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Spain = train[(train['Country_Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Spain = train[(train['Country_Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Spain = train[(train['Country_Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Spain = confirmed_total_date_Spain.join(fatalities_total_date_Spain)\n\n#confirmed_country_UK = train[(train['Country_Region']=='United Kingdom') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_UK = train[(train['Country_Region']=='United Kingdom') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_UK = train[(train['Country_Region']=='United Kingdom') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_UK = train[(train['Country_Region']=='United Kingdom') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_UK = confirmed_total_date_UK.join(fatalities_total_date_UK)\n\n#confirmed_country_Australia = train[(train['Country_Region']=='Australia') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Australia = train[(train['Country_Region']=='Australia') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Australia = train[(train['Country_Region']=='Australia') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Australia = train[(train['Country_Region']=='Australia') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Australia = confirmed_total_date_Australia.join(fatalities_total_date_Australia)\n\n#confirmed_country_Singapore = train[(train['Country_Region']=='Singapore') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Singapore = train[(train['Country_Region']=='Singapore') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Singapore = train[(train['Country_Region']=='Singapore') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Singapore = train[(train['Country_Region']=='Singapore') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Singapore = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n\nitaly = [i for i in total_date_Italy.ConfirmedCases['sum'].values]\nitaly_30 = italy[0:50] \nspain = [i for i in total_date_Spain.ConfirmedCases['sum'].values]\nspain_30 = spain[0:50] \nUK = [i for i in total_date_UK.ConfirmedCases['sum'].values]\nUK_30 = UK[0:50] \nsingapore = [i for i in total_date_Singapore.ConfirmedCases['sum'].values]\nsingapore_30 = singapore[0:50] \n\n\n# Plots\nplt.figure(figsize=(12,6))\nplt.plot(italy_30)\nplt.plot(spain_30)\nplt.plot(UK_30)\nplt.plot(singapore_30)\nplt.legend([\"Italy\", \"Spain\", \"UK\", \"Singapore\"], loc='upper left')\nplt.title(\"COVID-19 infections from the first confirmed case\", size=15)\nplt.xlabel(\"Days\", size=13)\nplt.ylabel(\"Infected cases\", size=13)\nplt.ylim(0, 60000)\nplt.show()","8b3a9e81":"# Susceptible equation\ndef fa(N, a, b, beta):\n    fa = -beta*a*b\n    return fa\n\n# Infected equation\ndef fb(N, a, b, beta, gamma):\n    fb = beta*a*b - gamma*b\n    return fb\n\n# Recovered\/deceased equation\ndef fc(N, b, gamma):\n    fc = gamma*b\n    return fc","0f9a9da0":"# Runge-Kutta method of 4rth order for 3 dimensions (susceptible a, infected b and recovered r)\ndef rK4(N, a, b, c, fa, fb, fc, beta, gamma, hs):\n    a1 = fa(N, a, b, beta)*hs\n    b1 = fb(N, a, b, beta, gamma)*hs\n    c1 = fc(N, b, gamma)*hs\n    ak = a + a1*0.5\n    bk = b + b1*0.5\n    ck = c + c1*0.5\n    a2 = fa(N, ak, bk, beta)*hs\n    b2 = fb(N, ak, bk, beta, gamma)*hs\n    c2 = fc(N, bk, gamma)*hs\n    ak = a + a2*0.5\n    bk = b + b2*0.5\n    ck = c + c2*0.5\n    a3 = fa(N, ak, bk, beta)*hs\n    b3 = fb(N, ak, bk, beta, gamma)*hs\n    c3 = fc(N, bk, gamma)*hs\n    ak = a + a3\n    bk = b + b3\n    ck = c + c3\n    a4 = fa(N, ak, bk, beta)*hs\n    b4 = fb(N, ak, bk, beta, gamma)*hs\n    c4 = fc(N, bk, gamma)*hs\n    a = a + (a1 + 2*(a2 + a3) + a4)\/6\n    b = b + (b1 + 2*(b2 + b3) + b4)\/6\n    c = c + (c1 + 2*(c2 + c3) + c4)\/6\n    return a, b, c","291946f1":"def SIR(N, b0, beta, gamma, hs):\n    \n    \"\"\"\n    N = total number of population\n    beta = transition rate S->I\n    gamma = transition rate I->R\n    k =  denotes the constant degree distribution of the network (average value for networks in which \n    the probability of finding a node with a different connectivity decays exponentially fast\n    hs = jump step of the numerical integration\n    \"\"\"\n    \n    # Initial condition\n    a = float(N-1)\/N -b0\n    b = float(1)\/N +b0\n    c = 0.\n\n    sus, inf, rec= [],[],[]\n    for i in range(10000): # Run for a certain number of time-steps\n        sus.append(a)\n        inf.append(b)\n        rec.append(c)\n        a,b,c = rK4(N, a, b, c, fa, fb, fc, beta, gamma, hs)\n\n    return sus, inf, rec","81a5f0a8":"# Parameters of the model\nN = 7800*(10**6)\nb0 = 0\nbeta = 0.7\ngamma = 0.2\nhs = 0.1\n\nsus, inf, rec = SIR(N, b0, beta, gamma, hs)\n\nf = plt.figure(figsize=(8,5)) \nplt.plot(sus, 'b.', label='susceptible');\nplt.plot(inf, 'r.', label='infected');\nplt.plot(rec, 'c.', label='recovered\/deceased');\nplt.title(\"SIR model\")\nplt.xlabel(\"time\", fontsize=10);\nplt.ylabel(\"Fraction of population\", fontsize=10);\nplt.legend(loc='best')\nplt.xlim(0,1000)\nplt.savefig('SIR_example.png')\nplt.show()","e1a37ee7":"population = float(46750238)\ncountry_df = pd.DataFrame()\ncountry_df['ConfirmedCases'] = train.loc[train['Country_Region']=='Spain'].ConfirmedCases.diff().fillna(0)\ncountry_df = country_df[10:]\ncountry_df['day_count'] = list(range(1,len(country_df)+1))\n\nydata = [i for i in country_df.ConfirmedCases]\nxdata = country_df.day_count\nydata = np.array(ydata, dtype=float)\nxdata = np.array(xdata, dtype=float)\n\nN = population\ninf0 = ydata[0]\nsus0 = N - inf0\nrec0 = 0.0\n\ndef sir_model(y, x, beta, gamma):\n    sus = -beta * y[0] * y[1] \/ N\n    rec = gamma * y[1]\n    inf = -(sus + rec)\n    return sus, inf, rec\n\ndef fit_odeint(x, beta, gamma):\n    return integrate.odeint(sir_model, (sus0, inf0, rec0), x, args=(beta, gamma))[:,1]\n\npopt, pcov = optimize.curve_fit(fit_odeint, xdata, ydata)\nfitted = fit_odeint(xdata, *popt)\n\nplt.plot(xdata, ydata, 'o')\nplt.plot(xdata, fitted)\nplt.title(\"Fit of SIR model for Spain infected cases\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()\nprint(\"Optimal parameters: beta =\", popt[0], \" and gamma = \", popt[1])","fc93616a":"# Merge train and test, exclude overlap\ndates_overlap = ['2020-03-19','2020-03-20','2020-03-21','2020-03-22','2020-03-23', '2020-03-24', '2020-03-25', \n                 '2020-03-26', '2020-03-27', '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31']\ntrain2 = train.loc[~train['Date'].isin(dates_overlap)]\nall_data = pd.concat([train2, test], axis = 0, sort=False)\n\n# Double check that there are no informed ConfirmedCases and Fatalities after 2020-03-11\nall_data.loc[all_data['Date'] >= '2020-03-19', 'ConfirmedCases'] = np.nan\nall_data.loc[all_data['Date'] >= '2020-03-19', 'Fatalities'] = np.nan\nall_data['Date'] = pd.to_datetime(all_data['Date'])\n\n# Create date columns\nle = preprocessing.LabelEncoder()\nall_data['Day_num'] = le.fit_transform(all_data.Date)\nall_data['Day'] = all_data['Date'].dt.day\nall_data['Month'] = all_data['Date'].dt.month\nall_data['Year'] = all_data['Date'].dt.year\n\n# Fill null values given that we merged train-test datasets\nall_data['Province_State'].fillna(\"None\", inplace=True)\nall_data['ConfirmedCases'].fillna(0, inplace=True)\nall_data['Fatalities'].fillna(0, inplace=True)\nall_data['Id'].fillna(-1, inplace=True)\nall_data['ForecastId'].fillna(-1, inplace=True)\n\ndisplay(all_data)\ndisplay(all_data.loc[all_data['Date'] == '2020-03-19'])","255bc204":"missings_count = {col:all_data[col].isnull().sum() for col in all_data.columns}\nmissings = pd.DataFrame.from_dict(missings_count, orient='index')\nprint(missings.nlargest(30, 0))","38224ff3":"def calculate_trend(df, lag_list, column):\n    for lag in lag_list:\n        trend_column_lag = \"Trend_\" + column + \"_\" + str(lag)\n        df[trend_column_lag] = (df[column]-df[column].shift(lag, fill_value=-999))\/df[column].shift(lag, fill_value=0)\n    return df\n\n\ndef calculate_lag(df, lag_list, column):\n    for lag in lag_list:\n        column_lag = column + \"_\" + str(lag)\n        df[column_lag] = df[column].shift(lag, fill_value=0)\n    return df\n\n\nts = time.time()\nall_data = calculate_lag(all_data, range(1,7), 'ConfirmedCases')\nall_data = calculate_lag(all_data, range(1,7), 'Fatalities')\nall_data = calculate_trend(all_data, range(1,7), 'ConfirmedCases')\nall_data = calculate_trend(all_data, range(1,7), 'Fatalities')\nall_data.replace([np.inf, -np.inf], 0, inplace=True)\nall_data.fillna(0, inplace=True)\nprint(\"Time spent: \", time.time()-ts)","fb46c7a0":"all_data[all_data['Country_Region']=='Spain'].iloc[40:50][['Id', 'Province_State', 'Country_Region', 'Date',\n       'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num', 'ConfirmedCases_1',\n       'ConfirmedCases_2', 'ConfirmedCases_3', 'Fatalities_1', 'Fatalities_2',\n       'Fatalities_3']]","7a1d13f9":"# Load countries data file\nworld_population = pd.read_csv(\"\/kaggle\/input\/population-by-country-2020\/population_by_country_2020.csv\")\n\n# Select desired columns and rename some of them\nworld_population = world_population[['Country (or dependency)', 'Population (2020)', 'Density (P\/Km\u00b2)', 'Land Area (Km\u00b2)', 'Med. Age', 'Urban Pop %']]\nworld_population.columns = ['Country (or dependency)', 'Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']\n\n# Replace United States by US\nworld_population.loc[world_population['Country (or dependency)']=='United States', 'Country (or dependency)'] = 'US'\n\n# Remove the % character from Urban Pop values\nworld_population['Urban Pop'] = world_population['Urban Pop'].str.rstrip('%')\n\n# Replace Urban Pop and Med Age \"N.A\" by their respective modes, then transform to int\nworld_population.loc[world_population['Urban Pop']=='N.A.', 'Urban Pop'] = int(world_population.loc[world_population['Urban Pop']!='N.A.', 'Urban Pop'].mode()[0])\nworld_population['Urban Pop'] = world_population['Urban Pop'].astype('int16')\nworld_population.loc[world_population['Med Age']=='N.A.', 'Med Age'] = int(world_population.loc[world_population['Med Age']!='N.A.', 'Med Age'].mode()[0])\nworld_population['Med Age'] = world_population['Med Age'].astype('int16')\n\nprint(\"Cleaned country details dataset\")\ndisplay(world_population)\n\n# Now join the dataset to our previous DataFrame and clean missings (not match in left join)- label encode cities\nprint(\"Joined dataset\")\nall_data = all_data.merge(world_population, left_on='Country_Region', right_on='Country (or dependency)', how='left')\nall_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']] = all_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']].fillna(0)\ndisplay(all_data)\n\nprint(\"Encoded dataset\")\n# Label encode countries and provinces. Save dictionary for exploration purposes\nall_data.drop('Country (or dependency)', inplace=True, axis=1)\nall_data['Country_Region'] = le.fit_transform(all_data['Country_Region'])\nnumber_c = all_data['Country_Region']\ncountries = le.inverse_transform(all_data['Country_Region'])\ncountry_dict = dict(zip(countries, number_c)) \nall_data['Province_State'] = le.fit_transform(all_data['Province_State'])\nnumber_p = all_data['Province_State']\nprovince = le.inverse_transform(all_data['Province_State'])\nprovince_dict = dict(zip(province, number_p)) \ndisplay(all_data)","a8553bca":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n# Day_num = 38 is March 1st\ny1 = all_data[(all_data['Country_Region']==country_dict['Spain']) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)][['ConfirmedCases']]\nx1 = range(0, len(y1))\nax1.plot(x1, y1, 'bo--')\nax1.set_title(\"Spain ConfirmedCases between days 39 and 49\")\nax1.set_xlabel(\"Days\")\nax1.set_ylabel(\"ConfirmedCases\")\n\ny2 = all_data[(all_data['Country_Region']==country_dict['Spain']) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)][['ConfirmedCases']].apply(lambda x: np.log(x))\nx2 = range(0, len(y2))\nax2.plot(x2, y2, 'bo--')\nax2.set_title(\"Spain Log ConfirmedCases between days 39 and 49\")\nax2.set_xlabel(\"Days\")\nax2.set_ylabel(\"Log ConfirmedCases\")","b96e877c":"# Filter selected features\ndata = all_data.copy()\nfeatures = ['Id', 'ForecastId', 'Country_Region', 'Province_State', 'ConfirmedCases', 'Fatalities', \n       'Day_num']\ndata = data[features]\n\n# Apply log transformation to all ConfirmedCases and Fatalities columns, except for trends\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].astype('float64')\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].apply(lambda x: np.log1p(x))\n\n# Replace infinites\ndata.replace([np.inf, -np.inf], 0, inplace=True)\n\n\n# Split data into train\/test\ndef split_data(data):\n    \n    # Train set\n    x_train = data[data.ForecastId == -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n    y_train_1 = data[data.ForecastId == -1]['ConfirmedCases']\n    y_train_2 = data[data.ForecastId == -1]['Fatalities']\n\n    # Test set\n    x_test = data[data.ForecastId != -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n\n    # Clean Id columns and keep ForecastId as index\n    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n    return x_train, y_train_1, y_train_2, x_test\n\n\n# Ridge replace of the Linear regression model\ndef ridge_reg(X_train, Y_train, X_test):\n    # Create Ridge regression object\n    #regr = Ridge()        # commit 2\n    #regr = RidgeCV(cv=5)  # commit 4\n    regr = Ridge(alpha=10) # commit 5\n\n    # Train the model using the training sets\n    regr.fit(X_train, Y_train)\n\n    # Make predictions using the testing set\n    y_pred = regr.predict(X_test)\n    \n    return regr, y_pred\n\n\n# Submission function\ndef get_submission(s, df, target1, target2):\n    \n    prediction_1 = df[target1]\n    prediction_2 = df[target2]\n\n    # Submit predictions\n    prediction_1 = [int(item) for item in list(map(round, prediction_1))]\n    prediction_2 = [int(item) for item in list(map(round, prediction_2))]\n    \n    submission = pd.DataFrame({\n        \"ForecastId\": df['ForecastId'].astype('int32'), \n        \"ConfirmedCases\": prediction_1, \n        \"Fatalities\": prediction_2\n    })\n    submission.to_csv(s + '.csv', index=False)","7680e3b3":"# Select train (real) data from March 1 to March 22nd\ndates_list = ['2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04', '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09', \n                 '2020-03-10', '2020-03-11','2020-03-12','2020-03-13','2020-03-14','2020-03-15','2020-03-16','2020-03-17','2020-03-18',\n                 '2020-03-19','2020-03-20','2020-03-21','2020-03-22','2020-03-23', '2020-03-24', '2020-03-25', '2020-03-26', '2020-03-27', \n                 '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31']","53e30f0f":"all_data.loc[all_data['Country_Region']==country_dict['Spain']][40:65]","05d8da0c":"def plot_rreg_basic_country(data, country_name, dates_list, day_start, shift):\n    \n    data_country = data[data['Country_Region']==country_dict[country_name]]\n    data_country = data_country.loc[data_country['Day_num']>=day_start]\n    X_train, Y_train_1, Y_train_2, X_test = split_data(data_country)\n    model, pred = ridge_reg(X_train, Y_train_1, X_test)\n\n    # Create a df with both real cases and predictions (predictions starting on March 12th)\n    X_train_check = X_train.copy()\n    X_train_check['Target'] = Y_train_1\n\n    X_test_check = X_test.copy()\n    X_test_check['Target'] = pred\n\n    X_final_check = pd.concat([X_train_check, X_test_check])\n\n    # Select predictions from March 1st to March 25th\n    predicted_data = X_final_check.loc[(X_final_check['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Target\n    real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\n    dates_list_num = list(range(0,len(dates_list)))\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n    ax1.plot(dates_list_num, np.expm1(predicted_data))\n    ax1.plot(dates_list_num, real_data)\n    ax1.axvline(17-shift, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax1.set_xlabel(\"Day count (from March \" + str(1+shift) + \" to March 25th)\")\n    ax1.set_ylabel(\"Confirmed Cases\")\n\n    ax2.plot(dates_list_num, predicted_data)\n    ax2.plot(dates_list_num, np.log1p(real_data))\n    ax2.axvline(17-shift, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax2.set_xlabel(\"Day count (from March \" + str(1+shift) + \" to March 30th)\")\n    ax2.set_ylabel(\"Log Confirmed Cases\")\n\n    plt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))\n    \n    \n    \n# Filter Spain, run the Linear Regression workflow\ncountry_name = \"Spain\"\nmarch_day = 0\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","ddf4dfac":"# Filter Spain, run the Linear Regression workflow\ncountry_name = \"Spain\"\nmarch_day = 15\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","d9470fc5":"# Filter Italy, run the Linear Regression workflow\ncountry_name = \"Italy\"\nmarch_day = 0\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","8236e73d":"# Filter Italy, run the Linear Regression workflow\ncountry_name = \"Italy\"\nmarch_day = 15\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","2c8f11ac":"# Filter Germany, run the Linear Regression workflow\ncountry_name = \"Germany\"\nmarch_day = 0\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","9cb968c8":"# Filter Germany, run the Linear Regression workflow\ncountry_name = \"Germany\"\nmarch_day = 15\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","13195721":"# Filter Albania, run the Linear Regression workflow\ncountry_name = \"Albania\"\nmarch_day = 0\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","52fc7548":"# Filter Albania, run the Linear Regression workflow\ncountry_name = \"Albania\"\nmarch_day = 15\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","126414bc":"# Filter Andorra, run the Linear Regression workflow\ncountry_name = \"Andorra\"\nshift = 0\nday_start = 39+shift\ndates_list2 = dates_list[shift:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, shift)","f45f180e":"# Filter Andorra, run the Linear Regression workflow\ncountry_name = \"Andorra\"\nshift = 7\nday_start = 39+shift\ndates_list2 = dates_list[shift:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, shift)","3387a4e1":"ts = time.time()\n\ndef ridge_reg_basic_all_countries(data, day_start):\n    \n    data2 = data.loc[data.Day_num >= day_start]\n\n    # Set the dataframe where we will update the predictions\n    data_pred = data[data.ForecastId != -1][['Country_Region', 'Province_State', 'Day_num', 'ForecastId']]\n    data_pred = data_pred.loc[data_pred['Day_num']>=day_start]\n    data_pred['Predicted_ConfirmedCases'] = [0]*len(data_pred)\n    data_pred['Predicted_Fatalities'] = [0]*len(data_pred)\n\n    print(\"Currently running Logistic Regression for all countries\")\n\n    # Main loop for countries\n    for c in data2['Country_Region'].unique():\n\n        # List of provinces\n        provinces_list = data2[data2['Country_Region']==c]['Province_State'].unique()\n\n        # If the country has several Province\/State informed\n        if len(provinces_list)>1:\n            for p in provinces_list:\n                data_cp = data2[(data2['Country_Region']==c) & (data2['Province_State']==p)]\n                X_train, Y_train_1, Y_train_2, X_test = split_data(data_cp)\n                model_1, pred_1 = ridge_reg(X_train, Y_train_1, X_test)\n                model_2, pred_2 = ridge_reg(X_train, Y_train_2, X_test)\n                data_pred.loc[((data_pred['Country_Region']==c) & (data2['Province_State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n                data_pred.loc[((data_pred['Country_Region']==c) & (data2['Province_State']==p)), 'Predicted_Fatalities'] = pred_2\n\n        # No Province\/State informed\n        else:\n            data_c = data2[(data2['Country_Region']==c)]\n            X_train, Y_train_1, Y_train_2, X_test = split_data(data_c)\n            model_1, pred_1 = ridge_reg(X_train, Y_train_1, X_test)\n            model_2, pred_2 = ridge_reg(X_train, Y_train_2, X_test)\n            data_pred.loc[(data_pred['Country_Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n            data_pred.loc[(data_pred['Country_Region']==c), 'Predicted_Fatalities'] = pred_2\n\n    # Apply exponential transf. and clean potential infinites due to final numerical precision\n    data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.expm1(x))\n    data_pred.replace([np.inf, -np.inf], 0, inplace=True) \n    \n    return data_pred\n\n\nday_start = 52\ndata_pred = ridge_reg_basic_all_countries(data, day_start)\nget_submission('submission', data_pred, 'Predicted_ConfirmedCases', 'Predicted_Fatalities')\n\nprint(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")","f85d3e0c":"# ts = time.time()\n\n# # Set the dataframe where we will update the predictions\n# data2 = data.loc[data.Day_num >= day_start]\n# data_pred3 = data[data.ForecastId != -1][['Country_Region', 'Province_State', 'Day_num', 'ForecastId']]\n# data_pred3['Predicted_ConfirmedCases'] = [0]*len(data_pred3)\n# data_pred3['Predicted_Fatalities'] = [0]*len(data_pred3)\n# how_many_days = test.Date.nunique()\n    \n# print(\"Currently running Logistic Regression for all countries\")\n\n# # Main loop for countries\n# for c in data['Country_Region'].unique():\n    \n#     # List of provinces\n#     provinces_list = data2[data2['Country_Region']==c]['Province_State'].unique()\n        \n#     # If the country has several Province\/State informed\n#     if len(provinces_list)>1:\n        \n#         for p in provinces_list:\n#             # Only fit starting from the first confirmed case in the country\n#             train_countries_no0 = data.loc[(data['Country_Region']==c) & (data['Province_State']==p) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n#             test_countries_no0 = data.loc[(data['Country_Region']==c) & (data['Province_State']==p) &  (data.ForecastId!=-1)]\n#             data2 = pd.concat([train_countries_no0, test_countries_no0])\n\n#             # If there are no previous cases, predict 0\n#             if len(train_countries_no0) == 0:\n#                 data_pred3.loc[((data_pred2['Country_Region']==c) & (data_pred3['Province_State']==p)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n#                 data_pred3.loc[((data_pred2['Country_Region']==c) & (data_pred3['Province_State']==p)), 'Predicted_Fatalities'] = [0]*how_many_days\n                \n#             else: \n#                 data_cp = data2[(data2['Country_Region']==c) & (data2['Province_State']==p)]\n#                 X_train, Y_train_1, Y_train_2, X_test = split_data(data_cp)\n#                 model_1, pred_1 = ridge_reg(X_train, Y_train_1, X_test)\n#                 model_2, pred_2 = ridge_reg(X_train, Y_train_2, X_test)\n#                 data_pred3.loc[((data_pred3['Country_Region']==c) & (data_pred3['Province_State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n#                 data_pred3.loc[((data_pred3['Country_Region']==c) & (data_pred3['Province_State']==p)), 'Predicted_Fatalities'] = pred_2\n\n#     # No Province\/State informed\n#     else:\n#         # Only fit starting from the first confirmed case in the country\n#         train_countries_no0 = data.loc[(data['Country_Region']==c) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n#         test_countries_no0 = data.loc[(data['Country_Region']==c) &  (data.ForecastId!=-1)]\n#         data2 = pd.concat([train_countries_no0, test_countries_no0])\n\n#         # If there are no previous cases, predict 0\n#         if len(train_countries_no0) == 0:\n#             data_pred3.loc[((data_pred3['Country_Region']==c)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n#             data_pred3.loc[((data_pred3['Country_Region']==c)), 'Predicted_Fatalities'] = [0]*how_many_days\n        \n#         else:\n#             data_c = data2[(data2['Country_Region']==c)]\n#             X_train, Y_train_1, Y_train_2, X_test = split_data(data_c)\n#             model_1, pred_1 = ridge_reg(X_train, Y_train_1, X_test)\n#             model_2, pred_2 = ridge_reg(X_train, Y_train_2, X_test)\n#             data_pred3.loc[(data_pred3['Country_Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n#             data_pred3.loc[(data_pred3['Country_Region']==c), 'Predicted_Fatalities'] = pred_2\n\n# # Aplly exponential transf. and clean potential infinites due to final numerical precision\n# data_pred3[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred3[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.expm1(x))\n# data_pred3.replace([np.inf, -np.inf], 0, inplace=True) \n\n# get_submission('sub0', data_pred3, 'Predicted_ConfirmedCases', 'Predicted_Fatalities')\n\n# print(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")","b4e0bd4d":"# # New split function, for one forecast day\n# def split_data_one_day(data, d):\n    \n#     #Train\n#     x_train = data[data.Day_num<d]\n#     y_train_1 = x_train.ConfirmedCases\n#     y_train_2 = x_train.Fatalities\n#     x_train.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n    \n#     #Test\n#     x_test = data[data.Day_num==d]\n#     x_test.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n    \n#     # Clean Id columns and keep ForecastId as index\n#     x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n#     x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n#     x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n#     x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n#     return x_train, y_train_1, y_train_2, x_test\n\n\n# def plot_real_vs_prediction_country(data, train, country_name, day_start, dates_list, march_day):\n\n#     # Select predictions from March 1st to March 25th\n#     predicted_data = data.loc[(data['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].ConfirmedCases\n#     real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\n#     dates_list_num = list(range(0,len(dates_list)))\n\n#     # Plot results\n#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n#     ax1.plot(dates_list_num, np.expm1(predicted_data))\n#     ax1.plot(dates_list_num, real_data)\n#     ax1.axvline(17-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n#     ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n#     ax1.set_xlabel(\"Day count (starting on March \" + str(march_day) + \"))\")\n#     ax1.set_ylabel(\"Confirmed Cases\")\n\n#     ax2.plot(dates_list_num, predicted_data)\n#     ax2.plot(dates_list_num, np.log1p(real_data))\n#     ax2.axvline(17-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n#     ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n#     ax2.set_xlabel(\"Day count (starting on March \" + str(march_day) + \")\")\n#     ax2.set_ylabel(\"Log Confirmed Cases\")\n\n#     plt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))\n    \n    \n# def plot_real_vs_prediction_country_fatalities(data, train, country_name, day_start, dates_list, march_day):\n\n#     # Select predictions from March 1st to March 25th\n#     predicted_data = data.loc[(data['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Fatalities\n#     real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['Fatalities']\n#     dates_list_num = list(range(0,len(dates_list)))\n\n#     # Plot results\n#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n#     ax1.plot(dates_list_num, np.expm1(predicted_data))\n#     ax1.plot(dates_list_num, real_data)\n#     ax1.axvline(17-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n#     ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n#     ax1.set_xlabel(\"Day count (starting on March \" + str(march_day) + \")\")\n#     ax1.set_ylabel(\"Fatalities Cases\")\n\n#     ax2.plot(dates_list_num, predicted_data)\n#     ax2.plot(dates_list_num, np.log1p(real_data))\n#     ax2.axvline(17-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n#     ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n#     ax2.set_xlabel(\"Day count (starting on March \" + str(march_day) + \")\")\n#     ax2.set_ylabel(\"Log Fatalities Cases\")\n\n#     plt.suptitle((\"Fatalities predictions based on Log-Lineal Regression for \"+country_name))","c24e24bc":"# # Function to compute the Linear Regression predictions with lags, for a certain Country\/Region\n# def ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict):\n    \n#     ts = time.time()\n    \n#     # Filter country and features from all_data (dataset without data leaking)\n#     data = all_data.copy()\n#     features = ['Id', 'Province_State', 'Country_Region',\n#            'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num']\n#     data = data[features]\n\n#     # Select country an data start (all days)\n#     data = data[data['Country_Region']==country_dict[country_name]]\n#     data = data.loc[data['Day_num']>=day_start]\n\n#     # Lags\n#     data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n#     data = calculate_lag(data, range(1,8), 'Fatalities')\n\n#     filter_col_confirmed = [col for col in data if col.startswith('Confirmed')]\n#     filter_col_fatalities= [col for col in data if col.startswith('Fataliti')]\n#     filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n    \n#     # Apply log transformation\n#     data[filter_col] = data[filter_col].apply(lambda x: np.log1p(x))\n#     data.replace([np.inf, -np.inf], 0, inplace=True)\n#     data.fillna(0, inplace=True)\n\n\n#     # Start\/end of forecast\n#     start_fcst = all_data[all_data['Id']==-1].Day_num.min()\n#     end_fcst = all_data[all_data['Id']==-1].Day_num.max()\n\n#     for d in list(range(start_fcst, end_fcst+1)):\n#         X_train, Y_train_1, Y_train_2, X_test = split_data_one_day(data, d)\n#         model_1, pred_1 = ridge_reg(X_train, Y_train_1, X_test)\n#         data.loc[(data['Country_Region']==country_dict[country_name]) \n#                  & (data['Day_num']==d), 'ConfirmedCases'] = pred_1[0]\n#         model_2, pred_2 = ridge_reg(X_train, Y_train_2, X_test)\n#         data.loc[(data['Country_Region']==country_dict[country_name]) \n#                  & (data['Day_num']==d), 'Fatalities'] = pred_2[0]\n\n#         # Recompute lags \n#         data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n#         data = calculate_lag(data, range(1,8), 'Fatalities')\n#         data.replace([np.inf, -np.inf], 0, inplace=True)\n#         data.fillna(0, inplace=True)\n\n#     #print(\"Process for \", country_name, \"finished in \", round(time.time() - ts, 2), \" seconds\")\n    \n#     return data\n\n\n# # Function to compute the Linear Regression predictions with lags, for a certain Country\/Region and State\/province\n# def ridge_reg_with_lags_country_province(all_data, country_name, province_name, day_start, lag_size, country_dict):\n    \n#     ts = time.time()\n    \n#     # Filter country and features from all_data (dataset without data leaking)\n#     data = all_data.copy()\n#     features = ['Id', 'Province_State', 'Country_Region',\n#            'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num']\n#     data = data[features]\n\n#     # Select country an data start (all days)\n#     data = data[(data['Country_Region']==country_dict[country_name]) & (data['Province_State']==province_dict[province_name])]\n#     data = data.loc[data['Day_num']>=day_start]\n\n#     # Lags\n#     data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n#     data = calculate_lag(data, range(1,lag_size), 'Fatalities')\n\n#     # Apply log transformation\n#     filter_col_confirmed = [col for col in data if col.startswith('Confirmed')]\n#     filter_col_fatalities= [col for col in data if col.startswith('Fataliti')]\n#     filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n#     data[filter_col] = data[filter_col].apply(lambda x: np.log1p(x))\n#     data.replace([np.inf, -np.inf], 0, inplace=True)\n#     data.fillna(0, inplace=True)\n\n#     # Start\/end of forecast\n#     start_fcst = all_data[all_data['Id']==-1].Day_num.min()\n#     end_fcst = all_data[all_data['Id']==-1].Day_num.max()\n\n#     for d in list(range(start_fcst, end_fcst+1)):\n#         X_train, Y_train_1, Y_train_2, X_test = split_data_one_day(data, d)\n#         model_1, pred_1 = ridge_reg(X_train, Y_train_1, X_test)\n#         data.loc[(data['Country_Region']==country_dict[country_name]) & (data['Province_State']==province_dict[province_name]) \n#                  & (data['Day_num']==d), 'ConfirmedCases'] = pred_1[0]\n#         model_2, pred_2 = ridge_reg(X_train, Y_train_2, X_test)\n#         data.loc[(data['Country_Region']==country_dict[country_name]) & (data['Province_State']==province_dict[province_name])\n#                  & (data['Day_num']==d), 'Fatalities'] = pred_2[0]\n\n#         # Recompute lags \n#         data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n#         data = calculate_lag(data, range(1,lag_size), 'Fatalities')\n#         data.replace([np.inf, -np.inf], 0, inplace=True)\n#         data.fillna(0, inplace=True)\n\n#     #print(\"Process for \", country_name, \"\/\", province_name, \"finished in \", round(time.time() - ts, 2), \" seconds\")\n    \n#     return data\n\n\n\n# # Run the model for Spain\n# country_name = 'Spain'\n# march_day = 0\n# day_start = 39 + march_day\n# dates_list2 = dates_list[march_day:]\n# lag_size = 30\n\n# data_c = ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n# plot_real_vs_prediction_country(data_c, train, country_name, day_start, dates_list2, march_day)\n# plot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, dates_list2, march_day)","6f1f921e":"# ts = time.time()\n\n# # Inputs\n# country_name = \"Italy\"\n# march_day = 0\n# day_start = 39 + march_day\n# dates_list2 = dates_list[march_day:]\n# lag_size = 30\n\n# data_c = ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n# plot_real_vs_prediction_country(data_c, train, country_name, day_start, dates_list2, march_day)\n# plot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, dates_list2, march_day)","ba2062fb":"# # Inputs\n# country_name = \"Germany\"\n# march_day = 0\n# day_start = 39 + march_day\n# dates_list2 = dates_list[march_day:]\n# lag_size = 30\n\n# data_c = ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n# plot_real_vs_prediction_country(data_c, train, country_name, day_start, dates_list2, march_day)\n# plot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, dates_list2, march_day)","06523007":"# # Inputs\n# country_name = \"Albania\"\n# march_day = 10\n# day_start = 39 + march_day\n# dates_list2 = dates_list[march_day:]\n# lag_size = 7\n\n# data_c = ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n# plot_real_vs_prediction_country(data_c, train, country_name, day_start, dates_list2, march_day)\n# plot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, dates_list2, march_day)","ef06c9d2":"# # Inputs\n# country_name = \"Andorra\"\n# march_day = 5\n# day_start = 39 + march_day\n# dates_list2 = dates_list[march_day:]\n# lag_size = 1\n\n# data_c = ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n# plot_real_vs_prediction_country(data_c, train, country_name, day_start, dates_list2, march_day)\n# plot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, dates_list2, march_day)","b7c8b7bb":"# # Inputs\n# day_start = 39 \n# lag_size = 30\n\n# train3 = train.copy()\n# train3.Province_State.fillna(\"None\", inplace=True)\n\n# results_df = pd.DataFrame()\n\n# tp = time.time()\n\n# # Main loop for countries\n# for country_name in train3['Country_Region'].unique():\n\n#     # List of provinces\n#     provinces_list = train3[train3['Country_Region']==country_name]['Province_State'].unique()\n        \n#     # If the country has several Province\/State informed\n#     if len(provinces_list)>1:\n#         for province_name in provinces_list:\n#             pred_province = ridge_reg_with_lags_country_province(all_data, country_name, province_name, day_start, lag_size, country_dict)\n#             results_df = pd.concat([results_df, pred_province])\n\n#     else:\n#         pred_country = ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n#         results_df = pd.concat([results_df, pred_country])\n        \n# results_df_submit = results_df.copy()\n# results_df_submit['ConfirmedCases'] = results_df_submit['ConfirmedCases'].apply(lambda x: np.expm1(x))\n# results_df_submit['Fatalities'] = results_df_submit['Fatalities'].apply(lambda x: np.expm1(x))\n        \n# get_submission('sub1',results_df_submit.loc[results_df_submit['ForecastId']!=-1], 'ConfirmedCases', 'Fatalities')\n# print(\"Complete process finished in \", time.time()-tp)","23f4266f":"# results_df_2 = results_df.copy()\n\n# day_start = 39\n# data_pred2 = ridge_reg_basic_all_countries(data, day_start)\n# day_num_test = 57    # Day 2020-04-18\n\n\n# # Main loop for countries\n# for country_name in train3['Country_Region'].unique():\n\n#     # List of provinces\n#     provinces_list = train3[train3['Country_Region']==country_name]['Province_State'].unique()\n\n#     # Countries with several Province_State informed\n#     if len(provinces_list)>1:\n#         for province_name in provinces_list:\n        \n#             tmp_index = all_data.index[(all_data['Country_Region']==country_dict[country_name]) & \n#                            (all_data['Province_State']==province_dict[province_name]) & \n#                            (all_data['Day_num']<day_num_test) & \n#                            (all_data['ConfirmedCases']!=0)]\n\n#             # When there is not enough data\n#             if len(tmp_index) < 30:\n                \n#                 # ConfirmedCases\n#                 results_df_2.loc[((results_df_2['Country_Region']==country_dict[country_name]) & \n#                                   (results_df_2['Province_State']==province_dict[province_name]) &\n#                                   (results_df_2['Day_num']>=day_num_test)), 'ConfirmedCases'] = data_pred2.loc[((data_pred2['Country_Region']==country_dict[country_name]) & \n#                                   (data_pred2['Province_State']==province_dict[province_name]) & \n#                                   (data_pred2['Day_num']>=day_num_test)), 'Predicted_ConfirmedCases'].apply(lambda x: np.log1p(x))\n                \n#                 #Fatalities\n#                 results_df_2.loc[((results_df_2['Country_Region']==country_dict[country_name]) & \n#                                   (results_df_2['Province_State']==province_dict[province_name]) &\n#                                   (results_df_2['Day_num']>=day_num_test)), 'Fatalities'] = data_pred2.loc[((data_pred2['Country_Region']==country_dict[country_name]) & \n#                                   (data_pred2['Province_State']==province_dict[province_name]) & \n#                                   (data_pred2['Day_num']>=day_num_test)), 'Predicted_Fatalities'].apply(lambda x: np.log1p(x))\n                \n#     # Countries without Province_State\n#     else:\n#         tmp_index = all_data.index[(all_data['Country_Region']==country_dict[country_name]) & \n#                            (all_data['Day_num']<day_num_test) & \n#                            (all_data['ConfirmedCases']!=0)]\n\n#         # When there is not enough data\n#         if len(tmp_index) < 30:\n            \n#             #Confirmed Cases\n#             results_df_2.loc[((results_df_2['Country_Region']==country_dict[country_name]) & \n#                             (results_df_2['Day_num']>=day_num_test)), 'ConfirmedCases'] = data_pred2.loc[((data_pred2['Country_Region']==country_dict[country_name]) & \n#                             (data_pred2['Day_num']>=day_num_test)), 'Predicted_ConfirmedCases'].apply(lambda x: np.log1p(x))\n            \n#             results_df_2.loc[((results_df_2['Country_Region']==country_dict[country_name]) & \n#                             (results_df_2['Day_num']>=day_num_test)), 'Fatalities'] = data_pred2.loc[((data_pred2['Country_Region']==country_dict[country_name]) & \n#                             (data_pred2['Day_num']>=day_num_test)), 'Predicted_Fatalities'].apply(lambda x: np.log1p(x))\n            \n# results_df_2 = results_df_2.loc[results_df_2['Day_num']>=day_num_test]\n# results_df_2[['ConfirmedCases', 'Fatalities']] = results_df_2[['ConfirmedCases', 'Fatalities']].apply(lambda x: np.expm1(x))\n# get_submission('sub2',results_df_2, 'ConfirmedCases', 'Fatalities')","56c839e5":"## 4.1. Ridge Regression for one country <a id=\"section41\"><\/a>","881929bf":"# My upgrade 1\n\n## Ridge model instead of Lin_reg","44731e56":"# [COVID19 Global Forecasting (Week 2)](https:\/\/www.kaggle.com\/c\/covid19-global-forecasting-week-2)","604a4bd1":"## 3.1. Join data, filter dates and clean missings <a id=\"section31\"><\/a>\n\nFirst of all, we perform some pre-processing prepare the dataset, consisting on:\n\n* **Join data**. Join train\/test to facilitate data transformations\n* **Filter dates**. According to the challenge conditions, remove ConfirmedCases and Fatalities post 2020-03-12. Create additional date columns\n* **Missings**. Analyze and fix missing values","2f99941b":"## 4.4. Ridge regression with lags <a id=\"section44\"><\/a>","d6b5cbb2":"* **Italy**","31156fe2":"## 2.1. Implementing the SIR model <a id=\"section21\"><\/a>\n","c613c1b8":"* **Andorra**","ce4a55a4":"# 4. Predictions<a id=\"section4\"><\/a>\n\nOur obective in this section consists on  predicting the evolution of the expansion from a data-centric perspective, like any other regression problem. To do so, remember that the challenge specifies that submissions on the public LB shouldn only contain data previous to 2020-03-12.\n\nModels to apply:\n1. Ridge Regression for one country\n2. Ridge Regression for all countries (method 1)\n3. Ridge Regression for all countries (method 2)","bba3f796":"# Acknowledgements\n\n\n* Very GOOD kernel: [COVID Global Forecast: SIR model + ML regressions](https:\/\/www.kaggle.com\/saga21\/covid-global-forecast-sir-model-ml-regressions)\n* That kernel \"COVID Global Forecast: SIR model + ML regressions\" used dataset [Population by Country - 2020](https:\/\/www.kaggle.com\/tanuprabhu\/population-by-country-2020)\n* [BOD prediction in river - 15 regression models](https:\/\/www.kaggle.com\/vbmokin\/bod-prediction-in-river-15-regression-models)\n* [Automatic selection from 20 classifier models](https:\/\/www.kaggle.com\/vbmokin\/automatic-selection-from-20-classifier-models)","9a69d9ec":"* **Albania**","23a5f196":"## 3.3. Add country details <a id=\"section33\"><\/a>","21667ecd":"## 1.2. COVID-19 tendency in China <a id=\"section12\"><\/a>","c89c5bfa":"\n**TABLE OF CONTENTS**\n\n1. [Exploratory data analysis (EDA)](#section1)\n\n    1.1. [COVID-19 global tendency excluding China](#section11)\n    \n    1.2. [COVID-19 tendency in China](#section12)\n    \n    1.3. [Italy, Spain, UK and Singapore](#section13)\n    \n2. [SIR model](#section2)\n\n    2.1. [Implementing the SIR model](#section21)\n    \n    2.2. [Fit SIR parameters to real data](#section22)\n    \n3. [Data enrichment](#section3)\n\n    3.1. [Join data, filter dates and clean missings](#section31)\n    \n    3.2. [Compute lags and trends](#section32)\n    \n    3.3. [Add country details](#section33)\n    \n4. [Predictions with machine learning](#section4)\n\n    4.1. [Ridge Regression for one country](#section41)\n    \n    4.2. [Ridge Regression for all countries (method 1)](#section42)\n    \n    4.3. [Ridge Regression for all countries (method 2)](#section43)\n    \n    4.4. [Ridge regression with lags](#section44)","598f9d8f":"As you see, the process is really fast. An example of some of the lag\/trend columns for Spain:","b0d35789":"# 3. Data enrichment <a id=\"section3\"><\/a>\n","4cd23e51":"* **Germany**","0584e44a":"# 1. Exploratory data analysis (EDA) <a id=\"section1\"><\/a>","d2f6bbde":"Let's try to see results when training with a single country:\n\n* **Spain**","30b63a43":"## 1.3. Italy, Spain, UK and Singapore <a id=\"section13\"><\/a>","9248898c":"## 3.2. Compute lags and trends <a id=\"section32\"><\/a>","d89ac0c9":"* **Germany**","e3a94b21":"* **Spain**","becdbeae":"## 1.1. COVID-19 global tendency excluding China <a id=\"section11\"><\/a>","01e44f10":"* **Albania**","9da0ceec":"* **Italy**","03f5f12c":"# My upgrade 2\n\n## RidgeCV model instead of Lin_reg","501fbe32":"## 2.2. Fit SIR parameters to real data <a id=\"section22\"><\/a>\n","3463da05":"# 2. SIR model <a id=\"section2\"><\/a>","2ff214d2":"* **Andorra**","6359aca5":"## 4.3 Ridge Regression for all countries (method 2) <a id=\"section43\"><\/a>","97300024":"## 4.2 Ridge Regression for all countries (method 1) <a id=\"section42\"><\/a>"}}