{"cell_type":{"d49b1699":"code","c8070e83":"code","4c7099ba":"code","c2a642c9":"code","d51d7b57":"code","fc07d29c":"code","0e389013":"code","17b6b8b4":"code","a7a7055f":"code","f3ea1f0f":"code","67668d54":"code","0978d806":"code","612f647b":"code","39c4beee":"code","1fcfd62d":"code","f6831641":"code","29c57550":"code","9afb0394":"code","e1574f26":"code","e58c29e7":"code","2ef39ce0":"code","d27e43ef":"code","f51f81e4":"code","715c26f5":"code","23db1ebd":"code","f8045517":"code","46d3d215":"code","36a2f4c8":"code","d1186d86":"code","3b8fe23b":"code","d234d70d":"code","524969e1":"markdown","b7ad9207":"markdown","3b25cc1c":"markdown","ec83e111":"markdown","0d078404":"markdown","3fff275f":"markdown","3276ca4c":"markdown","7cbdd764":"markdown","c09b3c62":"markdown","04336a6f":"markdown","5bbec484":"markdown","158905aa":"markdown","e825dcd3":"markdown","04a55736":"markdown","26577d4b":"markdown","6674bc43":"markdown","24b0ab75":"markdown","bcdb8de1":"markdown","168d8085":"markdown","32543491":"markdown","ce010b40":"markdown","336a8fa5":"markdown"},"source":{"d49b1699":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8070e83":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","4c7099ba":"train_data.info()","c2a642c9":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","d51d7b57":"tested = pd.read_csv(\"\/kaggle\/input\/tested\/submission1.csv\")","fc07d29c":"number_columns = [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\nobject_columns = [\"Sex\", \"Embarked\"]\ncols_that_seem_trivial = [\"PassengerId\", \"Cabin\", \"Name\", \"Ticket\"]","0e389013":"from sklearn.impute import SimpleImputer\n\n# Imputation of number columns.\nmy_imputer = SimpleImputer()\n\ntrain_data[number_columns] = pd.DataFrame(my_imputer.fit_transform(train_data[number_columns]))\n\ntest_data[number_columns] = pd.DataFrame(my_imputer.transform(test_data[number_columns]))","17b6b8b4":"sns.countplot(x ='Sex', hue = \"Survived\", data = train_data).set_title(\"Sex meaning in Survival\")\nsns.despine()","a7a7055f":"sns.countplot(x ='Pclass', hue = \"Survived\", data = train_data).set_title(\"Pclass meaning in Survival\")\nsns.despine()","f3ea1f0f":"sns.countplot(x ='Embarked', data = train_data).set_title(\"Amount of people embarked at each place\")\nsns.despine()","67668d54":"train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(\"S\")\n\nsns.countplot(x ='Embarked', hue = \"Survived\", data = train_data).set_title(\"Embarked meaning in Survival\")\nsns.despine()","0978d806":"sns.countplot(x ='Parch', hue = \"Survived\", data = train_data).set_title(\"Parch meaning in Survival\")\nsns.despine()","612f647b":"sns.countplot(x ='SibSp', hue = \"Survived\", data = train_data).set_title(\"SibSp meaning in Survival\")\nsns.despine()","39c4beee":"train_data[\"Family\"] = train_data.apply((lambda row: row.Parch + row.SibSp + 1), axis = 1)\ntest_data[\"Family\"] = test_data.apply((lambda row: row.Parch + row.SibSp + 1), axis = 1)\nsns.countplot(x ='Family', hue = \"Survived\", data = train_data).set_title(\"Total Family Members meaning in Survival\")\nsns.despine()","1fcfd62d":"train_data[\"IsAlone\"] = train_data[\"Family\"].apply(lambda x: 1 if x == 1 else 0)\ntest_data[\"IsAlone\"] = test_data[\"Family\"].apply(lambda x: 1 if x == 1 else 0)","f6831641":"sns.countplot(x ='IsAlone', hue = \"Survived\", data = train_data).set_title(\"Being alone on ship meaning in Survival\")\nsns.despine()","29c57550":"train_data['Age'].hist(bins=40).set_title(\"Spread out of passenger ages\")\nsns.despine()","9afb0394":"def age_group(age):\n    if age <= 10:\n        return \"0-10\"\n    elif age > 10 and age <= 20:\n        return \"11-20\"\n    elif age > 20 and age <= 30:\n        return \"21-30\"\n    elif age > 30 and age <= 40:\n        return \"31-40\"\n    elif age > 40 and age <= 50:\n        return \"41-50\"\n    elif age > 50 and age <= 60:\n        return \"51-60\"\n    elif age > 60 and age <= 70:\n        return \"61-70\"\n    else:\n        return \"71+\"\ntrain_data[\"Age_group\"] = train_data[\"Age\"].apply(age_group)\ntest_data[\"Age_group\"] = test_data[\"Age\"].apply(age_group)\nsns.countplot(x ='Age_group', hue = \"Survived\", data = train_data).set_title(\"Age meaning in Survival\")\nsns.despine()","e1574f26":"# get title for each passenger\ntrain_data[\"Title\"] = train_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest_data[\"Title\"] = test_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\nprint(pd.crosstab(train_data['Title'], train_data['Sex']))","e58c29e7":"# replace synonyms in train_data\ntrain_data['Title'] = train_data['Title'].replace('Mlle', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Ms', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Mme', 'Mrs')\n\n# replace synonyms in test_data\ntest_data['Title'] = test_data['Title'].replace('Mlle', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Ms', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Mme', 'Mrs')\n\n#apply title to dataframe title column\ntitles = [\"Mr\", \"Mrs\", \"Miss\", \"Master\"]\ntrain_data[\"Title\"] = train_data.Title.apply(lambda row: row if row in titles else \"Other\")\ntest_data[\"Title\"] = test_data.Title.apply(lambda row: row if row in titles else \"Other\")\n\ntrain_data[\"Title\"] = train_data[\"Title\"].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Other\": 5})\ntest_data[\"Title\"] = test_data[\"Title\"].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Other\": 5})","2ef39ce0":"sns.countplot(x ='Title', hue = \"Survived\", data = train_data).set_title(\"Title meaning in Survival\")\nsns.despine()","d27e43ef":"#trying to find a pattern in tickets according to ticket prefix\ntrain_data[\"Ticket_prefix\"] = train_data.Ticket.apply(lambda ticket: ticket[0])\ntest_data[\"Ticket_prefix\"] = train_data.Ticket.apply(lambda ticket: ticket[0])\n\nprint(sorted(set(train_data[\"Ticket_prefix\"])))\nprint(sorted(set(test_data[\"Ticket_prefix\"])))","f51f81e4":"sns.countplot(x ='Ticket_prefix', hue = \"Survived\", data = train_data).set_title(\"Ticket prefix meaning in Survival\")\nsns.despine()","715c26f5":"# Mapping ticket prefixes to numerical values:\ntrain_data[\"Ticket_prefix\"] = train_data[\"Ticket_prefix\"].map({'1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'A': 10, 'C': 11, 'F': 12, 'L': 13, 'P': 14, 'S': 15, 'W': 16})\ntest_data[\"Ticket_prefix\"] = test_data[\"Ticket_prefix\"].map({'1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'A': 10, 'C': 11, 'F': 12, 'L': 13, 'P': 14, 'S': 15, 'W': 16})","23db1ebd":"train_data[\"PassengerId_prefix\"] = train_data[\"PassengerId\"].apply(lambda x: int(str(x)[:1]))\ntest_data[\"PassengerId_prefix\"] = test_data[\"PassengerId\"].apply(lambda x: int(str(x)[:1]))\nsns.countplot(x ='PassengerId_prefix', hue = \"Survived\", data = train_data).set_title(\"PassengerId meaning in Survival\")\nsns.despine()","f8045517":"train_data['FareBand'] = pd.qcut(train_data['Fare'], 4)\ntest_data['FareBand'] = pd.qcut(test_data['Fare'], 4)","46d3d215":"#create FareBand column\ndef fare_fun(row):\n    if row <= 7.91:\n        return 0\n    elif row > 7.91 and row <= 14.454:\n        return 1\n    elif row > 14.454 and row <= 31:\n        return 2\n    else:\n        return 3\n    \ntrain_data[\"FareBand\"] = train_data[\"Fare\"].apply(fare_fun)\ntest_data[\"FareBand\"] = test_data[\"Fare\"].apply(fare_fun)\nsns.countplot(x ='FareBand', hue = \"Survived\", data = train_data).set_title(\"Fare meaning in Survival\")\nsns.despine()","36a2f4c8":"object_columns.append(\"Ticket_prefix\")\nobject_columns.append(\"Title\")\nfor column in object_columns:\n    print(column + \":\")\n    print(\"amount of unique values in column:\")\n    print(len(pd.unique(train_data[column])))\n    print(\"amount of null values in column:\")\n    print(train_data[column].isnull().sum())\n    print('_'*40)","d1186d86":"for column in cols_that_seem_trivial:\n    print(column + \":\")\n    print(\"amount of unique values in column:\")\n    print(len(pd.unique(train_data[column])))\n    print(\"amount of null values in column:\")\n    print(train_data[column].isnull().sum())\n    print('_'*40)","3b8fe23b":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\ny = train_data[\"Survived\"]\n\nfeatures = [*number_columns, *object_columns]\nprint(\"Features:\")\nprint(features)\nprint('_'*92)\n\nX = pd.get_dummies(train_data[features])\n#X = X.drop(['Fare'], axis=1)\nX_test = pd.get_dummies(test_data[features])\n#X_test = X_test.drop(['Fare'], axis=1)\n\n# add columns that weren't one-hot encoded in X_test\nfor i in X.columns:\n    if i not in X_test.columns:\n        X_test[i] = 0\n        \nprint(\"Columns after encoding:\")\nprint(X.columns)\nprint('_'*92)\n\nmodel = RandomForestClassifier(n_estimators=60, max_depth=5, random_state=0)\nmodel.fit(X, y)\n\nscore = model.score(X_test, tested[\"Survived\"])*100\nprint(\"Model score is:\")\nprint(score)\n\npredictions = model.predict(X_test)","d234d70d":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","524969e1":"### Age","b7ad9207":"### Parch","3b25cc1c":"### Fare","ec83e111":"# Imputing missing values in number columns (train and test data)","0d078404":"# Looking at object cols, to figure out whether or not they are worth encoding or imputing based on amount of null values and amount of unique values.","3fff275f":"### IsAlone (based on family size)","3276ca4c":"It seems as if the numbers 1, 2 and 3 as a ticket prefix, note the passenger class,because the widest difference between deaths and survivals is in ticket prefix 3, as we saw above in Pclass","7cbdd764":"### PassengerId","c09b3c62":"# Breaking down columns according to features such as type, and Whether or not they seem trivial...","04336a6f":"### Turnes out there is a limited amount of ticket prefixes, probably noting things like Class, or area of cabin. So I will try to plot them and see if it has anything to do with survival.","5bbec484":"There seems to be no connection between the passenger Id and survival, meaning Id, was given by random.","158905aa":"### Ticket","e825dcd3":"# Looking at various columns to see connection with survival.","04a55736":"# Loading data and viewing it...","26577d4b":"# Training and predicting","6674bc43":"### Pclass","24b0ab75":"### Embarked","bcdb8de1":"### Sex","168d8085":"### Family (based on Parch and SibSp)","32543491":"# conclsion:\n### cols that are worth OneHot encoding: Sex, Embarked, Ticket_prefix, Title\n### cols with to many missing values: Cabin\n### cols with no meaning: PassengerId\n### cols that would be in features before we use pandas get_dummies:\n1. Pclass\n2. SibSp\n3. Parch\n4. Fare\n5. Embarked\n6. Ticket_prefix (abbr. from Ticket)\n7. Title (abbr. from Name)\n8. Age","ce010b40":"### Name (we will be looking at the passengers title)","336a8fa5":"### SibSp"}}