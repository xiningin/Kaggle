{"cell_type":{"39d69173":"code","e40a0d4d":"code","14792e55":"code","ae8fe3fa":"code","8b78ce68":"code","2dccf216":"code","3dc17405":"code","71f8cbcf":"code","580b3d1e":"code","1cb4ce95":"code","5080a60e":"code","e23be04e":"code","098759e7":"code","3ab36932":"code","3501e6f3":"code","213cec1e":"code","91258bd6":"code","b58a589a":"code","70d8b5fc":"markdown","1d86208f":"markdown","5d9c8bb2":"markdown","68b9c12c":"markdown","0a29e3c9":"markdown","736eac73":"markdown","8595fc36":"markdown","f0d9bd3d":"markdown","de399005":"markdown","586b940e":"markdown","f076c9d7":"markdown"},"source":{"39d69173":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e40a0d4d":"data_raw = pd.read_csv('..\/input\/titanic\/train.csv')\ndata_val = pd.read_csv('..\/input\/titanic\/test.csv')\ndata1 = data_raw.copy(deep=True)\ndata_cleaner = [data1, data_val]\n\nTarget = ['Survived']","14792e55":"for dataset in data_cleaner:\n    print(dataset.info())\n    print(dataset.describe(include='all'))","ae8fe3fa":"for dataset in data_cleaner:\n    dataset.Age.fillna(dataset.Age.median(), inplace=True)\n    dataset.Embarked.fillna('S', inplace=True)\n    dataset.Fare.fillna(dataset.Fare.median(), inplace=True)\n    # dataset['Title'] = dataset.Name.str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n    dataset['Family_members'] = dataset.Parch + dataset.SibSp","8b78ce68":"data1.sample(5)","2dccf216":"data1.drop(['Name', 'PassengerId', 'Ticket', 'SibSp', 'Parch'], axis=1, inplace=True)","3dc17405":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfor i in data1.columns:\n    sns.countplot(data1[i])\n    plt.show()","71f8cbcf":"# data1.groupby(data1['Cabin'].isnull()).mean()\ndata1.groupby(data1['Cabin'].isnull())['Survived'].mean()","580b3d1e":"for dataset in data_cleaner:\n    dataset['Cabin_Allotted'] = np.where(dataset.Cabin.isnull(), 0, 1)\n    dataset.drop('Cabin', axis=1, inplace=True)","1cb4ce95":"data1.sample(5)\n# data1['Title'].value_counts()","5080a60e":"from sklearn.preprocessing import LabelEncoder\n\nlb = LabelEncoder()\n\nfor dataset in data_cleaner:\n    dataset['Sex_labeled'] = lb.fit_transform(dataset.Sex)\n    \n    dataset['AgeBin'] = pd.qcut(dataset.Age, 3)\n    dataset['Age_labeled'] = lb.fit_transform(dataset['AgeBin'])\n\n    dataset['FareBin'] = pd.qcut(dataset.Fare, 4)\n    dataset['Fare_labeled'] = lb.fit_transform(dataset['FareBin'])\n\n    dataset['Embarked_labeled'] = lb.fit_transform(dataset.Embarked)","e23be04e":"data1.sample(5)","098759e7":"print(data1['Age_labeled'].value_counts())\nprint(data1['Fare_labeled'].value_counts())","3ab36932":"data1_X = [\n    'Pclass', \n    'Family_members', \n    'Cabin_Allotted', \n    'Sex_labeled', \n    'Age_labeled', \n    'Fare_labeled', \n    'Embarked_labeled'\n]\n\nfor i in data1[data1_X].columns:\n    sns.lineplot(i, 'Survived', data=data1)\n    plt.show()","3501e6f3":"data1[data1_X].info()","213cec1e":"from sklearn import ensemble, tree, neighbors\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn import model_selection\n\nMLA = [\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    neighbors.KNeighborsClassifier(), \n\n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(), \n\n    XGBClassifier(objective='binary:logistic', eval_metric='logloss'),\n    LGBMClassifier()\n]\n\ncv_split = model_selection.ShuffleSplit(n_splits=10, test_size=.2, train_size=.8, random_state=1)\n\nMLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD', 'MLA Time']\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\nrow_index = 0\nfor alg in MLA:\n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n\n    cv_results = model_selection.cross_validate(alg, data1[data1_X], data1[Target].values.reshape(-1,), cv=cv_split, return_train_score=True)\n\n    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean() \n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3\n\n    row_index += 1\n\n# MLA_compare.sort_values(by=['MLA Test Accuracy Mean'], ascending=False, inplace=True)\nMLA_compare","91258bd6":"import time\n\ngrid_n_estimator = [10, 50, 100, 300]\ngrid_ratio = [.1, .25, .5, .75, 1.0]\ngrid_learn = [.01, .03, .05, .1, .25]\ngrid_max_depth = [1, 2, 3, 4, 5, 6, 7, 8, 10, None]\ngrid_min_samples = [5, 10, .03, .05, .10]\ngrid_criterion = ['gini', 'entropy']\n# grid_bool = [True, False]\ngrid_seed = [1]\n\ngrid_param = [\n    [{\n        # Ada\n        'learning_rate': grid_learn, \n        'n_estimators': grid_n_estimator, \n        'random_state': grid_seed\n    }], \n    [{\n        # Bagging\n        'max_samples': grid_ratio, \n        'n_estimators': grid_n_estimator, \n        'random_state': grid_seed\n    }],\n    [{\n        # e.ExtraTrees\n        'n_estimators': grid_n_estimator, \n        'criterion': grid_criterion, \n        'max_depth': grid_max_depth, \n        'random_state': grid_seed\n    }],\n    [{\n        # GBC\n        'learning_rate': grid_learn,\n        'n_estimators': grid_n_estimator,\n        'max_depth': grid_max_depth,\n        'random_state': grid_seed\n    }], \n    [{\n        # RandomForestClassifier\n        'n_estimators': grid_n_estimator,\n        'criterion': grid_criterion, \n        'max_depth': grid_max_depth[:-1], \n        'random_state': grid_seed, \n        # 'oob_score': grid_bool\n        # otherwise there will ba an error:\n        # UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n    }], \n    [{\n        # KN\n        'n_neighbors': grid_max_depth[:-1], \n        # Otherwise, there will be a TypeError: '>' not supported between instances of 'NoneType' and 'int', because of [None].\n        # the others are likewise\n        'weights': ['uniform', 'distance'], \n        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n    }], \n    [{\n        # DTC\n        'criterion': grid_criterion, \n        'max_depth': grid_max_depth, \n        'random_state': grid_seed, \n    }], \n    [{\n        # t.ExtraTree\n        'criterion': grid_criterion, \n        'max_depth': grid_max_depth, \n        'random_state': grid_seed, \n    }],\n    [{\n        # XGB\n        'learning_rate': grid_learn,\n        'max_depth': grid_max_depth[:-1],\n        'n_estimators': grid_n_estimator, \n        'seed': grid_seed, \n        'objective': ['binary:logistic'], \n        'eval_metric': ['logloss']     \n    }],\n    [{\n        # LGBM\n        'n_estimators': [1000, 1500, 2000, 2500],\n        'max_depth':  [4, 5, 11, -1], # [4, 5, 8, 11, -1]\n        'num_leaves': [15, 31, 58, 127], # [15, 31, 58, 63, 127]\n        'subsample': [0.6, 0.708, 0.8, 1.0], # [0.6, 0.7, 0.708, 0.8, 1.0]\n        'colsample_bytree': [0.613, 0.7, 0.8, 1.0], # [0.6, 0.613, 0.7, 0.8, 1.0]\n        'learning_rate' : [0.01, 0.02, 0.03]\n    }]\n]\n\nrow_index = 0\n\nstart_total = time.perf_counter()\n\nfor clf, param in zip(MLA, grid_param):\n    # tuning_____________________________________________________\n    start = time.perf_counter()\n    \n    best_search = model_selection.GridSearchCV(estimator = clf, \n                                               param_grid = param, \n                                               cv = cv_split, \n                                               scoring = 'roc_auc', \n                                               return_train_score = True)\n    best_search.fit(data1[data1_X], data1[Target].values.reshape(-1,))\n    \n    run = time.perf_counter() - start\n\n    best_param = best_search.best_params_\n    print(f'The best parameter for {clf.__class__.__name__} is {best_param} with a runtime of {run:.2f} seconds.')\n    print('-'*60)\n    clf.set_params(**best_param)\n\n    # cross validating____________________________________________\n    MLA_name = clf.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(clf.get_params())\n    \n    # https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html\n    MLA_compare.loc[row_index, 'MLA Time'] = np.asarray(best_search.cv_results_['mean_fit_time']).mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = np.asarray(best_search.cv_results_['mean_train_score']).mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = np.asarray(best_search.cv_results_['mean_test_score']).mean() \n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = np.asarray(best_search.cv_results_['mean_test_score']).std()*3\n\n    row_index += 1\n\nrun_total = time.perf_counter() - start_total\n\nprint('-'*60)\nprint(f'Total optimization time was {run_total \/ 60:.2f} minutes.')\nprint('-'*60)\n\nMLA_compare.sort_values(by=['MLA Test Accuracy Mean'], ascending=False, inplace=True)\nMLA_compare","b58a589a":"model = LGBMClassifier(**{'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 1000, 'num_leaves': 15, 'subsample': 0.6})\nmodel.fit(data1[data1_X], data1[Target].values.reshape(-1, ))\npredictions = model.predict(data_val[data1_X])\n\noutput = pd.DataFrame({'PassengerId': data_val.PassengerId, 'Survived': predictions})\noutput.to_csv('.\/my_submission_RandomForestClassifier_tunned_F4.csv', index=False)\nprint(\"Your submission was successfully saved!\")","70d8b5fc":"# Next: Synthanic Titanic\n\nTabular Playground Series - Apr 2021\n\nThe dataset is used for this competition is synthetic but based on a real dataset (in this case, the actual [Titanic data](https:\/\/www.kaggle.com\/c\/titanic\/data)!) and generated using a CTGAN. The statistical properties of this dataset are very similar to the original Titanic dataset, but there's no way to \"cheat\" by using public labels for predictions. How well does your model perform on truly private test labels?\n\nGood luck and have fun!\n\nYou can start from [here](https:\/\/www.kaggle.com\/chienhsianghung\/tps-apr-starter-pack-all-models).","1d86208f":"# Submit","5d9c8bb2":"# Data preprocessing- Cabin","68b9c12c":"# Define the Problem\n\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. <br>\n- Tools\n    - It's a classic **Binary classification**. \n- Data\n    - The dataset is given to us on a golden plater with test and train data at Kaggle's Titanic: Machine Learning from Disaster\n    \n***A warm reminder: If you haven't read [Titanic Top 11%| Starter I: Models Comparing](https:\/\/www.kaggle.com\/chienhsianghung\/titanic-top-11-starter-i-models-comparing) yet, go there first!***","0a29e3c9":"# Combine Tuning with Models Selection","736eac73":"# References\n* [A Data Science Framework: To Achieve 99% Accuracy](https:\/\/www.kaggle.com\/ldfreeman3\/a-data-science-framework-to-achieve-99-accuracy)\n* [MY FIRST KAGGLE WORK TITANIC](https:\/\/www.kaggle.com\/saptarshisit\/my-first-kaggle-work-titanic)","8595fc36":"# Data Preprocessing- Fill Na","f0d9bd3d":"# Simple Data Visualization (for setting bins)","de399005":"# Models Selection","586b940e":"# Data Preprocessing","f076c9d7":"# Data Preprocessing- Encoder\n\nIt all goes on how you explain your feature's (X) effect on the final prediction (Y).<br>\nLet's take a look at the feature `Fare`. <br>\nDo you think the Fare's increment like 1 dollar would make any significant impact on their survival rate?<br>\nThe answer is quite obvious, right? But what if we raise the increment to i.e. 30 dollars..? Hard to tell huh!<br>\nAgain, it all goes on how you interpret data. In this case, I've tried them so many times. And I received the better result by *categoricalization* on `Fare` in most of them."}}