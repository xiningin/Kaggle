{"cell_type":{"33385e44":"code","8d0c40d8":"code","64366cb7":"code","cfa548f0":"code","66d10625":"code","821d5d04":"code","32edbb03":"code","70d5e451":"code","91faa0c0":"code","a42c3c38":"code","cdc1d9eb":"code","1cad1c25":"code","877f3bb8":"code","c1293216":"code","d1bee041":"code","45832b45":"code","e2d82375":"code","abc5db36":"code","cd55131d":"code","30524444":"code","453c9716":"code","54d593e7":"code","25882feb":"code","2b7bb15a":"code","2210ebf4":"code","15adf3a0":"code","cd4e606b":"code","6cbf99db":"markdown","4a6366a7":"markdown","f2757b74":"markdown","37c5e6f5":"markdown","f85049fb":"markdown","79c16ab2":"markdown","242c9bd2":"markdown","cb7c6901":"markdown","f55402ca":"markdown","a856ed1d":"markdown","61659fb6":"markdown","ca29c12c":"markdown","6823a95b":"markdown"},"source":{"33385e44":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random \n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\n\nfrom scipy.interpolate import griddata\nimport plotly.graph_objs as go\nfrom plotly.tools import FigureFactory as FF\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n\n\nimport pickle\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\n\nimport os\nimport copy\nimport gc\nimport cv2\nfrom datetime import datetime\n\nfrom albumentations.pytorch import ToTensor\nfrom albumentations import (OneOf, PadIfNeeded, OpticalDistortion,\n                            GridDistortion, ElasticTransform, GaussianBlur,\n                            MedianBlur, MotionBlur, Compose,\n                            ShiftScaleRotate, VerticalFlip, HorizontalFlip)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8d0c40d8":"# metaparemeters\nn_folds = 5\nseed = 0\ndata_path = '..\/input\/zindi-flood-prediction\/'\npath_models = '.\/models\/'","64366cb7":"if not os.path.exists(path_models):\n    os.makedirs(path_models)","cfa548f0":"train = pd.read_csv(os.path.join(data_path, 'Train.csv'))\nss = pd.read_csv(os.path.join(data_path, 'SampleSubmission.csv'))","66d10625":"# get all unique x, y coordinates\n_x = train['X'].round(2).unique()\n_y = train['Y'].round(2).unique()\nprint(len(_x), len(_y))\n\n#and create their all possible combinations\n_xn = np.meshgrid(_x, _y)[0]\n_yn = np.meshgrid(_x, _y)[1]\n\nall_xy = np.dstack([_xn, _yn]).reshape(-1, 2)\n\n\n#with this combinations create an empty df and merge it with the original one by unique (x, y) tuples\ntrain_full = pd.DataFrame()\ntrain_full.loc[:, 'X'] = all_xy[:, 0]\ntrain_full.loc[:, 'Y'] = all_xy[:, 1]\ntrain_full.loc[:, 'id'] = train_full['X'].astype(str) + '_' + train_full['Y'].astype(str)\nid2ind = dict(zip(train_full.loc[:, 'id'].values, train_full.loc[:, 'id'].factorize()[0]))\ntrain_full.loc[:, 'id'] = train_full.loc[:, 'id'].map(id2ind)\n\ntrain.loc[:, 'id'] = train['X'].astype(str) + '_' + train['Y'].astype(str)\ntrain.loc[:, 'id'] = train.loc[:, 'id'].map(id2ind)\ndel train['X'], train['Y']\n\ntrain_full = train_full.merge(train, on=['id'], how='left').sort_values(['Y', 'X'], ascending=[False, True]).reset_index(drop=True)\ndel train_full['id']","821d5d04":"#sanity check that we can switch from IMG to DF and vice versa\ndef df2pix(ind):\n    assert  ind < 161 * 144\n    h = np.floor(ind \/ 161)\n    w = ind - h * 161\n    return int(h), int(w)\n\ndef pix2df(h, w):\n    assert h < 144\n    assert w < 161\n    ind = h * 161 + w\n    return int(ind)\n\nimg = train_full['elevation'].values.reshape(144,161)\nprint(f'img: 50:55, {img.flatten()[50:55]}')\nprint(f'df: 50:55, {train_full[\"elevation\"].values[50:55]}')\nprint(f'df2img: loc 3000, {train_full[\"elevation\"].loc[3000]} -> {img[df2pix(3000)]}')\nprint(f'img2df: (34, 46), {img[34, 46]} -> {train_full[\"elevation\"].loc[pix2df(34, 46)]}')","32edbb03":"#functions for filling NaN by max falue in each channel and min-max normalization\ndef _fill_na(img):\n    _img = img.copy()\n    if len(img.shape) == 3:\n        for i in range(_img.shape[2]):\n            _img[np.isnan(_img[:, :, i]), i] = np.max(_img[~np.isnan(_img[:, :, i]), i])\n    else:\n        _img[np.isnan(_img)] = np.max(_img[~np.isnan(_img)])\n    return _img\n\ndef _norm(img):\n    _img = img.copy()\n    if len(img.shape) == 3:\n        for i in range(_img.shape[2]):\n            _img[:, :, i] = (_img[:, :, i] - _img[:, :, i].min()) \/ (_img[:, :, i].max() - _img[:, :, i].min())  \n    else:\n        _img = (_img - _img.min()) \/ (_img.max() - _img.min())\n    return _img\n    ","70d5e451":"#create simple feature\n\nrain2019 = train_full[['precip 2019-01-20 - 2019-01-27', 'precip 2019-01-27 - 2019-02-03',\n       'precip 2019-02-03 - 2019-02-10', 'precip 2019-02-10 - 2019-02-17',\n       'precip 2019-02-17 - 2019-02-24', 'precip 2019-02-24 - 2019-03-03',\n       'precip 2019-03-03 - 2019-03-10', 'precip 2019-03-10 - 2019-03-17',\n       'precip 2019-03-17 - 2019-03-24', 'precip 2019-03-24 - 2019-03-31',\n       'precip 2019-03-31 - 2019-04-07', 'precip 2019-04-07 - 2019-04-14',\n       'precip 2019-04-14 - 2019-04-21', 'precip 2019-04-21 - 2019-04-28',\n       'precip 2019-04-28 - 2019-05-05', 'precip 2019-05-05 - 2019-05-12',\n       'precip 2019-05-12 - 2019-05-19']].sum(axis=1)\n\nrain2015 = train_full[['precip 2014-12-28 - 2015-01-04',\n       'precip 2015-01-04 - 2015-01-11', 'precip 2015-01-11 - 2015-01-18',\n       'precip 2015-01-18 - 2015-01-25', 'precip 2015-01-25 - 2015-02-01',\n       'precip 2015-02-01 - 2015-02-08', 'precip 2015-02-08 - 2015-02-15',\n       'precip 2015-02-15 - 2015-02-22', 'precip 2015-02-22 - 2015-03-01',\n       'precip 2015-03-01 - 2015-03-08', 'precip 2015-03-08 - 2015-03-15',]].sum(axis=1)\n\n\nimg1 = train_full['elevation'].values.reshape(144,161)\nimg2 = train_full['LC_Type1_mode'].values.reshape(144,161)\nimg3_train = np.log1p(rain2015).values.reshape(144,161)\nimg3_test = np.log1p(rain2019).values.reshape(144,161)\n\nimg_target = train_full['target_2015'].values.reshape(144,161)\nimg_train = np.dstack([img1, img2, img3_train])\nimg_test = np.dstack([img1, img2, img3_test])\n\nmask = ~np.isnan(img_target)","91faa0c0":"plt.figure(figsize=(10, 6))\n\nplt.subplot(2, 3, 1)\nplt.imshow(img_target)\nplt.title('2015 target')\n\nplt.subplot(2, 3, 2)\nplt.imshow(img_train[:, :, 0])\nplt.title('elevation')\n\nplt.subplot(2, 3, 3)\nplt.imshow(img_train[:, :, 1])\nplt.title('LC_Type1_mode')\n\nplt.subplot(2, 3, 4)\nplt.imshow(img_train[:, :, 2])\nplt.title('2015 rains')\n\nplt.subplot(2, 3, 5)\nplt.imshow(img_test[:, :, 2])\nplt.title('2019 rains')\n\nplt.subplot(2, 3, 6)\nplt.imshow(mask)\nplt.title('mask')\n\n\nplt.show()","a42c3c38":"def set_seed(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed + 1)\n    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed + 2)\n    random.seed(seed + 4)\n       \nclass SnapshotEns(object):\n    def __init__(self, k):\n        self.best_loss = np.array([np.inf]*k)\n        self.k = k\n        self.models = [0]*k\n\n    def train(self, model, loss):\n        if np.any(self.best_loss > loss):\n            presorted_loss = self.best_loss\n            self.best_loss = np.sort(self.best_loss)\n            \n            self.models = [self.models[z] for z in np.argsort(presorted_loss)]\n        \n            pos = np.where(self.best_loss > loss)[0][-1]\n\n            self.best_loss[pos] = loss            \n            self.models[pos] = copy.deepcopy(model.eval())\n\n    def get(self):\n        return (self.best_loss, self.models)\n    \n    def predict(self, data1):\n        preds = 0\n        for model in self.models:\n            model.eval()\n            preds += model.forward(data1)\n        preds \/= self.k\n        return preds\n\ndef rmse(y, pred, mask):\n    loss = np.sqrt(np.sum((_fill_na(y)*mask - pred*mask)**2) \/ np.sum(mask))\n    return loss\n\nclass Trainer():\n    def __init__(self, net, net_params, opt, opt_params, criterion, n_epochs, device,\n                 dataloader=None, is_snap=False, snap_k=3,\n                 sch=None, scheduler_params=None, verbose=1):\n        self.net = net\n        self.net_params = net_params\n        self.opt = opt\n        self.opt_params = opt_params\n        self.criterion = criterion\n        self.n_epochs = n_epochs\n        self.device = device\n        self.is_snap = is_snap\n        self.snap_k = snap_k\n        self.dataloader = dataloader\n        self.sch = sch\n        self.scheduler_params = scheduler_params\n        self.verbose = verbose\n        \n    def fit(self, dataloader=None):\n        if dataloader is not None:\n            self.dataloader = dataloader\n        if self.dataloader is None and dataloader is None:\n            raise ValueError('At least one dataloader should be not None')\n            \n        \n        self.model = self.net(**self.net_params).to(self.device)\n        self.optimizer = self.opt(self.model.parameters(), **self.opt_params)   \n        if self.sch is not None:\n            self.scheduler = self.sch(self.optimizer, 'min', **self.scheduler_params)\n            \n        self.se = SnapshotEns(k=self.snap_k)\n        train_log = []\n        for epoch in range(self.n_epochs):\n            # train\n            train_loss = self.train()\n            train_log.extend(train_loss)   \n            # test\n            val_loss, val_data = self.test()\n            if self.is_snap: \n                self.se.train(self.model, np.mean(val_loss))\n            if (self.verbose is not None) and ((epoch + 1) % self.verbose == 0):\n                print('Epoch: {e}, train loss: {tl}, val loss: {vl}, val metric: {rmse}'.format(rmse=rmse(*val_data),\n                                                                                                e=epoch,\n                                                                                                tl=np.mean(train_loss),\n                                                                                                vl=np.mean(val_loss)))\n            if self.sch is not None:\n                self.scheduler.step(np.mean(val_loss))\n                \n        if self.is_snap:\n            val_loss, val_data = self.test(snap=True)\n            print('Result, val loss: {vl}, val metric: {rmse}'.format(rmse=rmse(*val_data),\n                                                                      vl=np.mean(val_loss)))\n            \n    def train(self):        \n        loss_log =  []\n        self.model.train()\n        running_loss = 0\n        for n, sample in enumerate(self.dataloader['train']):\n            \n            image = Variable(sample['image']).to(self.device)\n            mask = Variable((sample['image1'].mean(dim=1) > 0)).to(self.device).float()\n            y_train = Variable((sample['image2'].mean(dim=1))).to(self.device).float()\n                    \n            output = self.model(image).squeeze(1)\n            loss = self.criterion(output * mask, y_train * mask) \/ mask.sum()\n            \n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n    \n            \n            loss = loss.data.cpu().numpy()\n            loss_log.append(loss)\n            running_loss += loss\n            \n        return loss_log\n    \n    def test(self, snap=False):        \n        loss_log =  []\n        self.model.eval()\n        with torch.no_grad():\n            for n, sample in enumerate(self.dataloader['val']):\n                image = Variable(sample['image']).to(self.device)\n                mask = Variable((sample['image1'].mean(dim=1) > 0)).to(self.device).float()\n                y_val = Variable((sample['image2'].mean(dim=1))).to(self.device).float()\n\n                if snap:\n                    output = self.se.predict(image).squeeze(1)\n                else:\n                    output = self.model(image).squeeze(1)\n                loss = self.criterion(output * mask, y_val * mask) \/ mask.sum()\n                loss = loss.data.cpu().numpy()\n                loss_log.append(loss)\n            \n        return loss_log, (y_val[0].data.cpu().numpy(), output[0].data.cpu().numpy(), mask[0].data.cpu().numpy())\n    \n    def predict(self, X):\n        X_test = _norm(_fill_na(X.copy()).astype(np.float32))\n        self.model.eval()\n        with torch.no_grad():\n            sample = self.dataloader['test'].dataset.transforms['test'](**{'image': X_test})\n            image = Variable(sample['image']).unsqueeze(0).to(self.device)\n            if self.is_snap:\n                output = self.se.predict(image).squeeze(1)\n            else:\n                output = self.model(image).squeeze(1)\n            \n        return output[0].data.cpu().numpy()\n    \n","cdc1d9eb":"# pytorch dataset\nclass OneShotSegDataset(torch.utils.data.Dataset):\n    def __init__(self, X, y, mask, transforms, stage, steps):\n        #transform target and mask to rgb for some augmentations\n        self.X = _norm(_fill_na(X.copy()).astype(np.float32))\n        self.y = cv2.cvtColor(_fill_na(y.copy()).astype(np.float32), cv2.COLOR_GRAY2RGB).copy()\n        self.mask = cv2.cvtColor((mask.copy()).astype(np.float32), cv2.COLOR_GRAY2RGB).copy()\n        \n        self.transforms = transforms\n        self.stage = stage\n        self.steps = steps\n        \n    def __len__(self):\n        return steps \n\n    def __getitem__(self, index):       \n        sample = self.transforms[self.stage](**{'image': self.X, 'image1': self.mask, 'image2': self.y})                  \n        return sample\n    \ndef is_shuffle(stage):\n    is_sh = {'train': True, 'val': False, 'test': False}    \n    return is_sh[stage]","1cad1c25":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        \n        self.conv = nn.Sequential(nn.Conv2d(in_channels, out_channels, 3, padding=1),\n                                  nn.ReLU(inplace=True),\n                                  nn.Conv2d(out_channels, out_channels, 3, padding=1),\n                                  nn.ReLU(inplace=True))\n        \n    def forward(self, x):\n        return self.conv(x)\n    \nclass UNet(nn.Module):\n\n    def __init__(self, in_channels, n_class):\n        super(UNet, self).__init__()\n        self.dconv_down1 = DoubleConv(in_channels, 6)\n        self.dconv_down2 = DoubleConv(6, 9)      \n\n        self.maxpool = nn.MaxPool2d(2)\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n        \n        self.dconv_up3 = DoubleConv(9, 12)\n        self.dconv_up2 = DoubleConv(9 + 12, 9)\n        self.dconv_up1 = DoubleConv(9 + 6, 6)\n        \n        self.conv_last = nn.Conv2d(6, n_class, 1)\n            \n       \n    def forward(self, x):\n        inp = x\n        conv1 = self.dconv_down1(x)\n        x = self.maxpool(conv1)\n\n        conv2 = self.dconv_down2(x)\n        x = self.maxpool(conv2)\n                \n        x = self.dconv_up3(x)\n        x = self._upsample_cat(x, conv2)       \n\n        x = self.dconv_up2(x)\n        x = self._upsample_cat(x, conv1)  \n        \n        x = self.dconv_up1(x)\n        \n        out = self.conv_last(x)\n        \n        return self._check_shape(out, inp)\n    \n    def _check_shape(self, x, y):\n\n        _, _, H, W = y.size()\n        if y.shape != x.shape:\n            return F.interpolate(x, size=(H, W), mode='bilinear', align_corners=False)\n        else:\n            return x\n    \n    def _upsample_add(self, x, y):\n        return self._check_shape(x, y) + y\n\n        \n    def _upsample_cat(self, x, y):\n        return torch.cat([self._check_shape(x, y), y], dim=1)","877f3bb8":"#create folds\ntrain_full.loc[:, 'folds'] = 0\nnot_na_index = train_full.index[~train_full.target_2015.isna()]\nfolds = list(KFold(n_splits=n_folds, random_state=seed, shuffle=False).split(not_na_index))\nfor n, (tr, vl) in enumerate(folds):\n    train_full.loc[not_na_index[vl], 'folds'] = n + 1 ","c1293216":"val_folds = train_full['folds'].values.reshape(144, 161) \nplt.figure(figsize=(10, 5))\nfor i in range(n_folds):\n    plt.subplot(2, n_folds, i+1)\n    plt.imshow(mask*(1-(val_folds==(i+1))))\n    plt.title(f'Training fold {i}')\n    \n    plt.subplot(2, n_folds, n_folds+i+1)\n    plt.imshow(mask*(val_folds==(i+1)))\n    plt.title(f'Validation fold {i}')\n\nplt.tight_layout()\nplt.show()  ","d1bee041":"#set augmentations\naugs = {'train' : Compose([VerticalFlip(p=0.5), HorizontalFlip(p=0.5),\n                           MotionBlur(blur_limit=5, p=0.05),\n                           OneOf([ElasticTransform(alpha=1, sigma=10, alpha_affine=20,\n                                                   interpolation=1, border_mode=2, p=1),\n                                  GridDistortion(num_steps=3, distort_limit=0.3,\n                                                 interpolation=1, border_mode=4, p=1),\n                                  OpticalDistortion(distort_limit=0.2, shift_limit=0.2,\n                                                    interpolation=1, border_mode=4, p=1)],\n                                 p=0.1),\n                           ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.0, rotate_limit=45,\n                                            interpolation=1, border_mode=4, p=0.5),\n                           ToTensor()],\n                          additional_targets={'image1': 'image', 'image2': 'image'}),\n\n        'val' : Compose([ToTensor()],\n                        additional_targets={'image1': 'image', 'image2': 'image'}),\n\n        'test': Compose([ToTensor()],\n                        additional_targets={'image1': 'image', 'image2': 'image'})}","45832b45":"#check, that image, target and mask transformed in the same way\nset_seed(1)\nplt.figure(figsize=(20, 15))\nfor i in range(3):\n    sample = augs['train'](**{'image':  _norm(_fill_na(img_train)),\n                              'image1':  cv2.cvtColor(_fill_na(mask.copy()).astype(np.float32),\n                                                      cv2.COLOR_GRAY2RGB),\n                              'image2':  cv2.cvtColor(_fill_na(img_target.copy()).astype(np.float32),\n                                                      cv2.COLOR_GRAY2RGB)})\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(sample['image'].numpy()[0])\n    plt.title(f\"Training image {i}. First channel only\")\n    \n    plt.subplot(3, 3, 3 + i + 1)\n    plt.imshow(sample['image1'].numpy()[0])\n    plt.title(f\"Mask image {i}\")\n    \n    plt.subplot(3, 3, 6 + i + 1)\n    plt.imshow(sample['image2'].numpy()[0])\n    plt.title(f\"Target image {i}\")\n    \nplt.tight_layout()\nplt.show()    ","e2d82375":"#more aug examples\nset_seed(42)\nplt.figure(figsize=(20, 15))\nfor i in range(20):\n    plt.subplot(4, 5, i+1)\n    plt.imshow(augs['train'](image = _norm(_fill_na(img_train)))['image'].numpy()[0])\n    plt.title(f\"Training image {i}. First channel only\")\n    \nplt.tight_layout()\nplt.show()    ","abc5db36":"%%time\nset_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\n#init model and training params\nbs = 1 #batch size\nnum_workers = 4\nsteps = 50 #images per epoch\nn_epochs = 50\nsnap_k = 5 # number of snapshots per fold\nn_starts = 2\n\nnn_model = Trainer(net=UNet,\n                   net_params={'in_channels': 3, 'n_class': 1},\n                   opt=torch.optim.Adam,\n                   opt_params={'lr':1e-3},\n                   criterion=nn.MSELoss(reduction='sum'),\n                   n_epochs=n_epochs,\n                   device=torch.device(\"cuda:0\"),\n                   is_snap=True,\n                   snap_k=snap_k,\n                   sch=lr_scheduler.ReduceLROnPlateau,\n                   scheduler_params={'patience':15, 'factor':0.5, 'verbose':False},\n                   verbose=None)\n\n\n\n#Start training\noof = np.zeros((144, 161))\n\nfor j in range(n_starts):\n    print('=====================')\n    print(f'Iteration: {j}')\n    for i in range(n_folds):\n        print(f'Fold: {i}')\n        val_folds = train_full['folds'].values.reshape(144, 161)\n\n        masks = {'train': mask*(1-(val_folds==(i+1))), 'val': mask*(val_folds==(i+1)), 'test': mask}\n        \n        image_datasets = {x: OneShotSegDataset(X={'train': img_train, 'val': img_train, 'test': img_test}[x],\n                                               y=img_target, mask=masks[x], transforms=augs, stage=x,\n                                               steps=steps) for x in ['train', 'val', 'test']}\n\n        dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n                                                      batch_size={'train': bs, 'val': 1, 'test': 1}[x],\n                                                      shuffle=is_shuffle(x),\n                                                      num_workers=num_workers,\n                                                      pin_memory=True) for x in ['train', 'val', 'test']}\n        \n        nn_model.fit(dataloaders)\n\n        pred = nn_model.predict(img_train)        \n        oof += mask * (val_folds==(i+1)) * pred\n        print('')\n        \n        torch.save(nn_model, os.path.join(path_models, f'model_iter_{j}_fold_{i}.pickle'))\n\n    print(f'OOF rmse: {rmse(img_target, oof \/ (j+1), mask)}')\n    print('')\n\noof \/= (j+1)","cd55131d":"oof = np.zeros((144, 161))\npred_train = np.zeros(144 * 161)\npred_test = np.zeros(144 * 161)\n\n\nfor j in range(n_starts):\n    for i in range(n_folds):\n        nn_model = torch.load(os.path.join(path_models, f'model_iter_{j}_fold_{i}.pickle'))\n        \n        pred = nn_model.predict(img_train)\n        pred_train += pred.flatten() \/ n_folds \/ n_starts\n        pred_test += nn_model.predict(img_test).flatten() \/ n_folds \/ n_starts        \n        oof += mask * (val_folds==(i+1)) * pred\n\noof \/= (j+1)\nprint(f'OOF rmse: {rmse(img_target, oof, mask)}')\nprint('')        ","30524444":"ss_full = train_full[['Square_ID']].copy()\nss_full.loc[:, 'target_2019'] = pred_train\nss_full = ss_full[~ss_full.Square_ID.isna()].reset_index(drop=True)\nss_full.to_csv('sub_train.csv', index=None) # ~0.11 public lb +- 0.01\nss_full.head()","453c9716":"ss_full = train_full[['Square_ID']].copy()\nss_full.loc[:, 'target_2019'] = oof.flatten()\nss_full = ss_full[~ss_full.Square_ID.isna()].reset_index(drop=True)\nss_full.to_csv('sub_train_oof.csv', index=None)  # ~0.15 public lb +- 0.01\nss_full.head()","54d593e7":"ss_full = train_full[['Square_ID']].copy()\nss_full.loc[:, 'target_2019'] = pred_test\nss_full = ss_full[~ss_full.Square_ID.isna()].reset_index(drop=True)\nss_full.to_csv('sub_test.csv', index=None)  # ~0.11 public lb +- 0.01\nss_full.head()","25882feb":"plt.figure(figsize=(15, 3))\n\nplt.subplot(1, 4, 1)\nplt.imshow(img_target)\nplt.title('2015 target')\n\nplt.subplot(1, 4, 2)\nplt.imshow(np.ma.masked_where(1-mask, pred_train.reshape(144, 161)))\nplt.title('Train prediction')\n\nplt.subplot(1, 4, 3)\nplt.imshow(np.ma.masked_where(1-mask, pred_test.reshape(144, 161)))\nplt.title('Test prediction')\n\nplt.subplot(1, 4, 4)\nplt.imshow(np.ma.masked_where(1-mask, oof))\nplt.title('Train OOF prediction')\n\nplt.tight_layout()\nplt.show()","2b7bb15a":"def get_data(train, color):\n    x, y, z, c = train['X'], train['Y'], train['elevation'], color\n    xi=np.linspace(min(x), max(x),200)\n    yi=np.linspace(min(y),max(y),200)\n    X,Y= np.meshgrid(xi,yi)\n    Z = (griddata((x,y), z, (X, Y), method='nearest'))\n    C = (griddata((x,y), c, (X, Y), method='nearest'))\n    return X, Y, Z, C\n    ","2210ebf4":"def plot3D(X, Y, Z, C):\n    data = [go.Surface(x=X,y=Y, z=Z, surfacecolor=C ,colorscale='Viridis')]\n    layout = go.Layout(\n        width=800,\n        height=900,\n        autosize=False,\n        margin=dict(t=0, b=0, l=0, r=0),\n        scene=dict(\n            xaxis=dict(\n                gridcolor='rgb(255, 255, 255)',\n                zerolinecolor='rgb(255, 255, 255)',\n                showbackground=True,\n                backgroundcolor='rgb(230, 230,230)'\n            ),\n            yaxis=dict(\n                gridcolor='rgb(255, 255, 255)',\n                zerolinecolor='rgb(255, 255, 255)',\n                showbackground=True,\n                backgroundcolor='rgb(230, 230, 230)'\n            ),\n            zaxis=dict(\n                gridcolor='rgb(255, 255, 255)',\n                zerolinecolor='rgb(255, 255, 255)',\n                showbackground=True,\n                backgroundcolor='rgb(230, 230,230)'\n            ),\n            aspectratio = dict(x=1, y=1, z=0.7),\n            aspectmode = 'manual'\n        )\n    )\n\n    updatemenus=list([\n        dict(\n            buttons=list([\n                dict(\n                    args=['type', 'surface'],\n                    label='3D Surface',\n                    method='restyle'\n                ),\n                \n            ]),\n            direction = 'left',\n            pad = {'r': 10, 't': 10},\n            showactive = True,\n            type = 'buttons',\n            x = 0.1,\n            xanchor = 'left',\n            y = 1.1,\n            yanchor = 'top'\n        ),\n    ])\n\n    annotations = list([\n        dict(text='Trace type:', x=0, y=1.085, yref='paper', align='left', showarrow=False)\n    ])\n    layout['updatemenus'] = updatemenus\n    layout['annotations'] = annotations\n\n    fig = dict(data=data, layout=layout)\n    iplot(fig, filename='cmocean-picker-one-button')\n    ","15adf3a0":"plot3D(*get_data(train_full, train_full['target_2015']))","cd4e606b":"plot3D(*get_data(train_full, oof.flatten()))","6cbf99db":"## Model training","4a6366a7":"### Inference","f2757b74":"In this notebook, you can see how to use the UNet on data from the https:\/\/zindi.africa\/competitions\/2030-vision-flood-prediction-in-malawi competition.\n\nDISCLAIMER\n\nThis kernel was written solely for educational purposes. The proposed model is poor in a number of ways: low quality; instability from start to start (all seeds are fixed); predictions on the test set are really close to the predictions of the train; not enough data for such model; and the predictions themselves are rather blurry between adjacent pixels of the 2015 target. This is not how machine learning should be applied to real business tasks. \n\nHowever, this approach allows you to look at the data in its entirety and consider a large neighborhood when setting the prediction for the given coordinates.","37c5e6f5":"### Model: small UNet","f85049fb":"### Dataset","79c16ab2":"### Make submission","242c9bd2":"## Data preprocessing","cb7c6901":"### Create validation","f55402ca":"### Training","a856ed1d":"### Augmentations","61659fb6":"### Main training class","ca29c12c":"### Kaggle Dataset has been removed from public use due to changes in data sharing policy at Zindi. \n### You can download data here: https:\/\/zindi.africa\/competitions\/2030-vision-flood-prediction-in-malawi\/data","6823a95b":"## 3D interactive plotly visualization"}}