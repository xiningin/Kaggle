{"cell_type":{"73a3ea79":"code","14e596bf":"code","bf6cbfe5":"code","5329f3f7":"code","473d14f4":"code","af9cc2b5":"code","42113c73":"code","e8820335":"code","19f69663":"code","2df7a9a9":"code","0f2f3e53":"code","4d98fb04":"code","dca9e9f2":"code","88fcd8e2":"code","5034a1d4":"code","20cc098c":"code","31940575":"code","9bf6179b":"code","43599d57":"code","b25a6f9b":"code","6752a01c":"code","34c02c0a":"code","4568daa0":"markdown"},"source":{"73a3ea79":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","14e596bf":"import os                       # for working with files\nimport numpy as np              # for numerical computationss\nimport pandas as pd             # for working with dataframes\nimport torch                    # Pytorch module \nimport matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\nimport torch.nn as nn           # for creating  neural networks\nfrom torch.utils.data import DataLoader # for dataloaders \nfrom PIL import Image           # for checking images\nimport torch.nn.functional as F # for functions for calculating loss\nimport torchvision.transforms as transforms   # for transforming images into tensors \nfrom torchvision.utils import make_grid       # for data checking\nfrom torchvision.datasets import ImageFolder  # for working with classes and images\n ","bf6cbfe5":"!pip install torchsummary","5329f3f7":"import torchsummary","473d14f4":"data_dir_Train = \"\/kaggle\/input\/intel-image-classification\/seg_train\"\ndata_dir_Test = \"\/kaggle\/input\/intel-image-classification\/seg_test\"\n\ntrain_dir = data_dir_Train + \"\/seg_train\"\nvalid_dir = data_dir_Test + \"\/seg_test\/\"\noutcomes = os.listdir(train_dir)","af9cc2b5":"# printing the all outcomes\nprint(outcomes)","42113c73":"print(\"Total outcome classes are: {}\".format(len(outcomes)))","e8820335":"# Number of images for each Class\nnums = {}\nfor outcome in outcomes:\n    nums[outcome] = len(os.listdir(train_dir + '\/' + outcome))\n    \n# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n\nimg_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\nimg_per_class","19f69663":"# plotting number of images available for each disease\nindex = [n for n in range(6)]\nplt.figure(figsize=(10, 5))\nplt.bar(index, [n for n in nums.values()], width=0.3)\nplt.xlabel('Possible Outcomes', fontsize=10)\nplt.ylabel('No of images available', fontsize=10)\nplt.xticks(index, outcomes, fontsize=10, rotation=90)\nplt.title('Images per each class :')","2df7a9a9":"n_train = 0\nfor value in nums.values():\n    n_train += value\nprint(f\"There are {n_train} images for training\")","0f2f3e53":"from torchvision.transforms import ToTensor,Resize,Normalize","4d98fb04":"transforms = transforms.Compose([Resize((224,224)),\n                         ToTensor(),\n                         Normalize([0.485,0.456,0.406],[0.299,0.224,0.225])])","dca9e9f2":"train_data = ImageFolder(root=train_dir,transform=transforms)","88fcd8e2":"val_data = ImageFolder(root=valid_dir,transform=transforms)","5034a1d4":"dataloader_Train = DataLoader(train_data,batch_size=32,shuffle=True,num_workers=4)\ndataloader_Test = DataLoader(val_data,batch_size=32,shuffle=True,num_workers=4)","20cc098c":"import torchvision\nimport torch.nn as nn\nimport torch","31940575":"samples, labels = iter(dataloader_Train).next()\nplt.figure(figsize=(16,24))\ngrid_imgs = torchvision.utils.make_grid(samples[:24])\nnp_grid_imgs = grid_imgs.numpy()\n# in tensor, image is (batch, width, height), so you have to transpose it to (width, height, batch) in numpy to show it.\nplt.imshow(np.transpose(np_grid_imgs, (1,2,0)))","9bf6179b":"# transfer learning\nimport torchvision\ndevice = 'cuda'\nmodel = torchvision.models.densenet121(pretrained=True)","43599d57":"model = model.to(device)","b25a6f9b":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.002, amsgrad=True)\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[500,1000,1500], gamma=0.5)","6752a01c":"epochs = 15\nitr = 1\np_itr = 200\nmodel.train()\ntotal_loss = 0\nloss_list = []\nacc_list = []\n\nfor epoch in range(epochs):\n    for samples, labels in dataloader_Train:\n        samples, labels = samples.to(device), labels.to(device)\n        optimizer.zero_grad()\n        output = model(samples)\n        loss = criterion(output, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        scheduler.step()\n        \n        if itr%p_itr == 0:\n            pred = torch.argmax(output, dim=1)\n            correct = pred.eq(labels)\n            acc = torch.mean(correct.float())\n            print('[Epoch {}\/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss\/p_itr, acc))\n            loss_list.append(total_loss\/p_itr)\n            acc_list.append(acc)\n            total_loss = 0\n            \n        itr += 1\n\n        \n","34c02c0a":"samples, _ = iter(dataloader_Test).next()\nsamples = samples.to(device)\nfig = plt.figure(figsize=(24, 16))\nfig.tight_layout()\noutput = model(samples[:24])\npred = torch.argmax(output, dim=1)\npred = [p.item() for p in pred]\nad = {0:'buildings', 1:'forest',2:'glacier',3:'mountain',4:'sea',5:'street'}\n#'mountain', 'glacier', 'sea', 'street', 'buildings', 'forest'\nfor num, sample in enumerate(samples[:24]):\n    plt.subplot(4,6,num+1)\n    plt.title(ad[pred[num]])\n    plt.axis('off')\n    sample = sample.cpu().numpy()\n    plt.imshow(np.transpose(sample, (1,2,0)))","4568daa0":"## So as we can see there are 6 categories can be classified; And all classes have almost equal images"}}