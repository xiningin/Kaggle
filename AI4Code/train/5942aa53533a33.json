{"cell_type":{"668f5761":"code","14bc8f77":"code","77d3fa68":"code","a5437965":"code","6d1f12fd":"code","9705607a":"code","60c03a71":"code","a74c215f":"code","ca2084b0":"code","416fc199":"code","d6983abc":"code","662d9a34":"code","25c9bf73":"code","17a35d24":"code","0a072ff5":"code","3962076c":"code","2f21fa4c":"code","9fe66e28":"code","2a766fd7":"code","4f29351d":"code","f8150692":"code","7125fc33":"code","8d60ed00":"code","4b1e6c82":"code","ba736600":"code","3fa57831":"code","da864889":"code","5e14da95":"code","91e59c2e":"code","c7bc7bf2":"code","f758a8b4":"code","065dc4b9":"code","c71acdbc":"code","959f59ac":"code","88b05ccd":"code","d1c71838":"code","73b2618e":"code","0a05180d":"code","80191a43":"code","e47cf39f":"code","75a6f00f":"code","020d9cfe":"code","3229928a":"markdown","11b10fd1":"markdown","1b24f5e0":"markdown","94d6a049":"markdown","b4e2c6c3":"markdown","830d2f2d":"markdown","5533a0d9":"markdown","1192e976":"markdown","6ed4e23c":"markdown","e92f0d34":"markdown","978eeb1d":"markdown","06ed3af0":"markdown","6eceb8c8":"markdown","4325ead5":"markdown","e1b13e96":"markdown","457b7213":"markdown","15ba035e":"markdown","f1986cef":"markdown","2779c103":"markdown","6e3ccd42":"markdown","b3084e5d":"markdown","142235a6":"markdown","9f13198c":"markdown","fe13a63a":"markdown","bde90d4f":"markdown","877a21ea":"markdown","a7d62178":"markdown","7fc68873":"markdown","ceb5aa48":"markdown"},"source":{"668f5761":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","14bc8f77":"data = pd.read_csv('..\/input\/precipitation-prediction-in-la\/dataset.csv', parse_dates = ['DATE'])\ndata.head()\n#data.DATE.dtype","77d3fa68":"data.loc[data['PRCP'] > 0, 'PRCP'] = 1","a5437965":"data.info()","6d1f12fd":"data.shape","9705607a":"data.describe()","60c03a71":"sns.countplot(x = 'PRCP',data = data)","a74c215f":"sns.heatmap(data.isnull())","ca2084b0":"data = data.drop(['PGTM','TAVG'],axis = 'columns')\ndata.head()","416fc199":"#data.STATION.value_counts()\n#Since all have same value, dropping this feature\ndata = data.drop(['STATION'],axis='columns')","d6983abc":"#data.NAME.value_counts()\n#Since all have same value, dropping this feature\ndata = data.drop(['NAME'],axis='columns')","662d9a34":"#data.DATE.nunique()\n#Since all values are different, dropping this row for now since this is the basic version of the model.\n#Later, in the advanced version, will try to categorize based on d,m,y etc.\ndata = data.drop(['DATE'],axis = 'columns')","25c9bf73":"#finding and dropping duplicates\ndata.duplicated().sum()\ndata.drop_duplicates(inplace = True)\ndata.reset_index(drop=True, inplace=True)","17a35d24":"#checking for remaining null values before performing simple imputation\ndata.isnull().any()","0a072ff5":"data['WT01'].fillna(value = 0,inplace = True)\ndata['WT02'].fillna(value = 0,inplace = True)\ndata['WT08'].fillna(value = 0,inplace = True)","3962076c":"data.head()","2f21fa4c":"#imputing the null values with mode\nfor i in data.columns:\n    if data[i].isnull().any():\n        data[i].fillna(data[i].mode()[0], inplace=True)","9fe66e28":"#finally checking to see if all null values have been dealt with\ndata.isnull().any()","2a766fd7":"data.head()","4f29351d":"#Showing that all null values have been dealt with\nsns.heatmap(data.isnull())","f8150692":"from sklearn.feature_selection import chi2\nX = data.drop(['PRCP'],axis='columns')\ny = data.PRCP\nchi_scores = chi2(X,y)\nchi_scores","7125fc33":"p_values = pd.Series(chi_scores[1],index = X.columns)\np_values.sort_values(ascending = False , inplace = True)\np_values.plot.bar()","8d60ed00":"data = X.drop(['WT02'],axis = 'columns')\ndata.head()","4b1e6c82":"#pip install imblearn","ba736600":"from sklearn.preprocessing import MinMaxScaler\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score,f1_score,roc_auc_score,precision_score,recall_score,confusion_matrix,classification_report\nX_train,X_test,y_train,y_test = train_test_split(data,y,train_size = 0.8,stratify = y)\nsmote = SMOTE(random_state = 11)\nX_train, y_train = smote.fit_resample(X_train, y_train)\nscaler = MinMaxScaler()\nX_w_train = scaler.fit_transform(X_train)\nX_train_x = pd.DataFrame(X_w_train,columns = X_train.columns)\nX_w_test = scaler.transform(X_test)\nX_test_x = pd.DataFrame(X_w_test,columns = X_test.columns)","3fa57831":"# defining a function to evaluate my models based on certain metrics(all proposed ones except roc_auc which has been done separately)\ndef print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")        \n    elif train==False:\n        pred = clf.predict(X_test)\n        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")","da864889":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {'C' : np.logspace(-4, 4, 50),'penalty' :['l2']} \n\ngrid = GridSearchCV(LogisticRegression(), param_grid, cv=5,scoring = 'roc_auc')\ngrid.fit(X_train_x, y_train)\n\nbest_params = grid.best_params_\nprint(f\"Best params: {best_params}\")\n\nlr = LogisticRegression(**best_params)\nlr.fit(X_train_x,y_train)\ny_preds = lr.predict_proba(X_test_x)\nprint(\"ROC_AUC score is :\",end = ' ')\nprint(roc_auc_score(y_test,y_preds[:,1]))\nprint_score(lr, X_train_x, y_train, X_test_x, y_test,train = False)\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_preds[:,1])\nroc_auc = metrics.auc(fpr, tpr)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\nlabels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(confusion_matrix(y_test, lr.predict(X_test_x)),annot = labels,fmt='',cmap = \"YlGnBu\")","5e14da95":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nparam_grid = {'C': [0.01, 0.1, 0.5, 1, 10, 100], \n              'gamma': [1, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001], \n              'kernel': ['rbf', 'poly', 'linear']} \n\ngrid = GridSearchCV(SVC(), param_grid,cv=5)\ngrid.fit(X_train_x, y_train)\n\nbest_params = grid.best_params_\nprint(f\"Best params: {best_params}\")\n\nsvm = SVC(**best_params,probability = True)\nsvm.fit(X_train_x, y_train)\ny_preds = svm.predict_proba(X_test_x)\nprint(\"ROC_AUC score is :\",end = ' ')\nprint(roc_auc_score(y_test,y_preds[:,1]))\nprint_score(svm, X_train_x, y_train, X_test_x, y_test,train = False)\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_preds[:,1])\nroc_auc = metrics.auc(fpr, tpr)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\nlabels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(confusion_matrix(y_test, svm.predict(X_test_x)),annot = labels,fmt='',cmap = 'YlGnBu')","91e59c2e":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\n# param_grid = {} \n\n# grid = GridSearchCV(DecisionTreeClassifier(), param_grid,cv=5)\n# grid.fit(X_train_x, y_train)\n\n# best_params = grid.best_params_\n# print(f\"Best params: {best_params}\")\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train_x, y_train)\ny_preds = dt.predict_proba(X_test_x)\nprint(\"ROC_AUC score is :\",end = ' ')\nprint(roc_auc_score(y_test,y_preds[:,1]))\nprint_score(dt, X_train_x, y_train, X_test_x, y_test,train = False)\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_preds[:,1])\nroc_auc = metrics.auc(fpr, tpr)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\nlabels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(confusion_matrix(y_test, dt.predict(X_test_x)),annot = labels,fmt='',cmap = 'YlGnBu')","c7bc7bf2":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.naive_bayes import GaussianNB\n# param_grid = {} \n\n# grid = GridSearchCV(GaussianNB(), param_grid,cv=5)\n# grid.fit(X_train_x, y_train)\n\n# best_params = grid.best_params_\n# print(f\"Best params: {best_params}\")\n\ngnb = GaussianNB()\ngnb.fit(X_train_x, y_train)\ny_preds = gnb.predict_proba(X_test_x)\nprint(\"ROC_AUC score is :\",end = ' ')\nprint(roc_auc_score(y_test,y_preds[:,1]))\nprint_score(gnb, X_train_x, y_train, X_test_x, y_test,train = False)\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_preds[:,1])\nroc_auc = metrics.auc(fpr, tpr)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\nlabels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(confusion_matrix(y_test, gnb.predict(X_test_x)),annot = labels,fmt='',cmap = 'YlGnBu')","f758a8b4":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingClassifier\n# param_grid = {} \n\n# grid = GridSearchCV(GradientBoostingClassifier(), param_grid,cv=5)\n# grid.fit(X_train_x, y_train)\n\n# best_params = grid.best_params_\n# print(f\"Best params: {best_params}\")\n\ngb = GradientBoostingClassifier()\ngb.fit(X_train_x, y_train)\ny_preds = gb.predict_proba(X_test_x)\nprint(\"ROC_AUC score is :\",end = ' ')\nprint(roc_auc_score(y_test,y_preds[:,1]))\nprint_score(gb, X_train_x, y_train, X_test_x, y_test,train = False)\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_preds[:,1])\nroc_auc = metrics.auc(fpr, tpr)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\nlabels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(confusion_matrix(y_test, dt.predict(X_test_x)),annot = labels,fmt='',cmap = 'YlGnBu')","065dc4b9":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n# param_grid = {} \n\n# grid = GridSearchCV(DecisionTreeClassifier(), param_grid,cv=5)\n# grid.fit(X_train_x, y_train)\n\n# best_params = grid.best_params_\n# print(f\"Best params: {best_params}\")\n\nrf = RandomForestClassifier()\nrf.fit(X_train_x, y_train)\ny_preds = rf.predict_proba(X_test_x)\nprint(\"ROC_AUC score is :\",end = ' ')\nprint(roc_auc_score(y_test,y_preds[:,1]))\nprint_score(rf, X_train_x, y_train, X_test_x, y_test,train = False)\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_preds[:,1])\nroc_auc = metrics.auc(fpr, tpr)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\nlabels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(confusion_matrix(y_test, dt.predict(X_test_x)),annot = labels,fmt='',cmap = 'YlGnBu')","c71acdbc":"from xgboost import XGBClassifier\n# param_grid = {} \n\n# grid = GridSearchCV(DecisionTreeClassifier(), param_grid,cv=5)\n# grid.fit(X_train_x, y_train)\n\n# best_params = grid.best_params_\n# print(f\"Best params: {best_params}\")\n\nxgb = XGBClassifier(use_label_encoder=False, eval_metric = 'error')\nxgb.fit(X_train_x, y_train)\ny_preds = rf.predict_proba(X_test_x)\nprint(\"ROC_AUC score is :\",end = ' ')\nprint(roc_auc_score(y_test,y_preds[:,1]))\nprint_score(xgb, X_train_x, y_train, X_test_x, y_test,train = False)\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_preds[:,1])\nroc_auc = metrics.auc(fpr, tpr)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\nlabels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(confusion_matrix(y_test, dt.predict(X_test_x)),annot = labels,fmt='',cmap = 'YlGnBu')","959f59ac":"from catboost import CatBoostClassifier\n# param_grid = {} \n\n# grid = GridSearchCV(DecisionTreeClassifier(), param_grid,cv=5)\n# grid.fit(X_train_x, y_train)\n\n# best_params = grid.best_params_\n# print(f\"Best params: {best_params}\")\n\ncat = CatBoostClassifier(logging_level='Silent')\ncat.fit(X_train_x, y_train)\ny_preds = rf.predict_proba(X_test_x)\nprint(\"ROC_AUC score is :\",end = ' ')\nprint(roc_auc_score(y_test,y_preds[:,1]))\nprint_score(cat, X_train_x, y_train, X_test_x, y_test,train = False)\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_preds[:,1])\nroc_auc = metrics.auc(fpr, tpr)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\nlabels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(confusion_matrix(y_test, dt.predict(X_test_x)),annot = labels,fmt='',cmap = 'YlGnBu')","88b05ccd":"MLA = [lr,dt,gnb,svm,gb,rf,xgb,cat]","d1c71838":"MLA_columns = []\nMLA_compare = pd.DataFrame(columns = MLA_columns)\nindex = 0\nfor alg in MLA:\n    predicted = alg.fit(X_train_x, y_train).predict(X_test_x)\n    fp, tp, th = metrics.roc_curve(y_test, predicted)\n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[index,'MLA Name'] = MLA_name\n    MLA_compare.loc[index, 'MLA Train Accuracy'] = round(alg.score(X_train_x, y_train), 4)\n    MLA_compare.loc[index, 'MLA Test Accuracy'] = round(alg.score(X_test_x, y_test), 4)\n    MLA_compare.loc[index, 'MLA Precission'] = precision_score(y_test, predicted)\n    MLA_compare.loc[index, 'MLA Recall'] = recall_score(y_test, predicted)\n    MLA_compare.loc[index, 'MLA AUC'] = metrics.auc(fp, tp)\n    index+=1\nMLA_compare.sort_values(by = ['MLA Test Accuracy'], ascending = False, inplace = True)    \nMLA_compare","73b2618e":"plt.subplots(figsize=(15,6))\nsns.barplot(x=\"MLA Name\", y=\"MLA Train Accuracy\",data=MLA_compare,palette='hot')\nplt.xticks(rotation=90)\nplt.title('MLA Train Accuracy Comparison')\nplt.show()","0a05180d":"plt.subplots(figsize=(15,6))\nsns.barplot(x=\"MLA Name\", y=\"MLA Test Accuracy\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\nplt.xticks(rotation=90)\nplt.title('MLA Test Accuracy Comparison')\nplt.show()","80191a43":"plt.subplots(figsize=(15,6))\nsns.barplot(x=\"MLA Name\", y=\"MLA Precission\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\nplt.xticks(rotation=90)\nplt.title('MLA Precission Comparison')\nplt.show()","e47cf39f":"plt.subplots(figsize=(16,6))\nsns.barplot(x=\"MLA Name\", y=\"MLA Recall\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\nplt.xticks(rotation=90)\nplt.title('MLA Recall Comparison')\nplt.show()","75a6f00f":"plt.subplots(figsize=(16,6))\nsns.barplot(x=\"MLA Name\", y=\"MLA AUC\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\nplt.xticks(rotation = 90)\nplt.title('MLA AUC Comparison')\nplt.show()","020d9cfe":"index = 1\nfor alg in MLA:\n    \n    \n    predicted = alg.fit(X_train_x, y_train).predict(X_test_x)\n    fp, tp, th = metrics.roc_curve(y_test, predicted)\n    roc_auc_mla = metrics.auc(fp, tp)\n    MLA_name = alg.__class__.__name__\n    plt.plot(fp, tp, lw=2, alpha=0.3, label='ROC %s (AUC = %0.2f)'  % (MLA_name, roc_auc_mla))\n   \n    index+=1\n\nplt.title('ROC Curve comparison')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2)\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([0,1])\nplt.ylim([0,1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')    \nplt.show()","3229928a":"### Support Vector Classifier","11b10fd1":"# Model Comparision","1b24f5e0":"### Gradient Boosting Classifier","94d6a049":"#### Applied Hyperparameter training for all models but it did not result in any significant improvement in most cases.","b4e2c6c3":"# Implementing Different Models","830d2f2d":"### Random Forest Classifier","5533a0d9":"# Feature Selection and normalization of data\n* Feature selection will be made using the chi-square test.\n* We will normalize the data using MinMaxScaler.","1192e976":"#### Based on the heatmap, columns PGTM,TAVG have too many null values and shall be dropped. The rest of the cells with null values will be imputed with the mode value ","6ed4e23c":"## Visualizing Class Imbalance","e92f0d34":"## Steps involved in this basic DIY Machine Learning Project are:\n1. Data Importing and Exploration\n2. Handling Class Imbalance and missing values\n3. Standardizing Data and Feature Selection\n4. Train Model Using different techniques\n5. Model Comparision","978eeb1d":"### Decision Tree Classifier","06ed3af0":"### Checking for Null Values","6eceb8c8":"### Since WT02 has high p-value, it says that this variables is independent of the repsone and can not be considered for model training","4325ead5":"# Visualizing Class Imbalance and  dealing with missing values\n* In our dataset, there is an imbalance between examples where precipitation occurs or not. We will use seaborn\/matplotlib to visualize it.\n* Most of the ML algos used for classification were designed with the assumption of an equal no. of examples in each case. Therefore we need to balance it. This is done later using SMOTE to oversample the data.\n* We will check for null values. If any feature contains many null values, we will drop it. We will convert the rest of the null values with mode.","e1b13e96":"### Performing some Exploratory Data Analysis on text and datetime features","457b7213":"### XGB Classifier","15ba035e":"### Chi Square Test","f1986cef":"## Loading Dataset","2779c103":"## Feature Selection (Selecting features based on statistical analysis)","6e3ccd42":"### Cat Boost Classifier","b3084e5d":"### Gaussian Naive Bayes","142235a6":"## Importing Libraries","9f13198c":"### Working on PRCP column (Target Column)","fe13a63a":"# Data Importing and Exploration\n* We will use pandas framework to import the data and perform further analysis on it.\n* PRCP column in the dataframe will be our target feature in this model. We have to replace all values greater than 0 as 1 (representing precipitation will occur), and values that are equal to 0 representing precipitation will not occur.","bde90d4f":"## Normalization (Setting a scale for all the features in the dataset)","877a21ea":"# Introduction\n\n##### This is a basic project offered by the Coding Club of Indian Institute of Technology, Guwahati (IIT Guwahati). The main aim of this project was to get familiar with the workflow and various techniques involved in a Machine Learning project.","a7d62178":"### Defining Scoring Function","7fc68873":"### Logistic Regression","ceb5aa48":"#### Here we can clearly see the number of samples for the case when precipitation occurs is much less than for the case when precipitation does not occur. Hence, there is class imbalance"}}