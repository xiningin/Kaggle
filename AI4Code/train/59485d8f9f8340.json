{"cell_type":{"63b1340f":"code","c5fef8e3":"code","c6c8faef":"code","51d0783d":"code","23bec686":"code","cf949802":"code","60f967e8":"code","3515af03":"code","49358bf5":"code","5a7b407f":"code","0ece22b9":"code","71a1d1c4":"code","d2345737":"code","85058469":"code","bcf0fc37":"code","a26c1527":"code","0a9e33fd":"code","8e407b4e":"code","318b1a2d":"code","7098448e":"code","a65f12cb":"code","58af1305":"code","6c97db41":"code","eedddd4a":"code","40bf5618":"code","3dcccea1":"code","386c3ce4":"code","b1801193":"code","9d91aa20":"code","4ff291a3":"code","40da6d85":"code","49205034":"code","afc970ab":"code","beccaf22":"code","02df76bc":"code","cb6f6f40":"code","51532e42":"code","ceaa7232":"code","642058d1":"code","08a08f96":"code","a1587bdc":"code","6264266f":"code","253edf2e":"code","9e30abb6":"code","5919479f":"code","063e48d2":"code","49d09b09":"code","2bb70036":"code","7e013132":"code","3f885b37":"code","b8f459d6":"code","8bc500f2":"code","18bbfaea":"code","662fad7d":"code","492e0ab9":"code","0f2dec93":"code","3457f531":"code","8cbd859d":"code","da7b01ba":"code","c22d102e":"code","5399b89b":"code","af7682c6":"code","fca53257":"code","4d6698a6":"code","d4e299b1":"code","614360dd":"code","e79a98a0":"code","1c363923":"code","78e8b935":"code","da98a8fb":"code","17d409bd":"code","ae4dfdc6":"code","e8b80e8c":"code","a898f06d":"code","a4143839":"code","b9571956":"code","cc283d93":"code","d8d35fc7":"code","dd2d12d6":"code","e3450957":"code","3f2f384d":"code","8dc7fc1d":"code","89c7edc8":"code","c1c0fbf1":"code","d755d194":"code","1b92cab9":"code","fec14bf8":"code","2c6144a0":"code","46679259":"code","b5ad0e5d":"code","a7a13dad":"code","49a61f95":"code","d34c7003":"code","9481295a":"code","d24bd2a9":"code","da3f8e30":"code","9178e236":"code","43a98473":"code","711bea96":"code","78814785":"code","a0ef7a44":"code","62a63b63":"code","75f3345a":"code","5ed30fbc":"code","f07342d6":"code","11789588":"code","e84c65ec":"code","4ebcef54":"code","32c6ab3b":"code","54a39f05":"code","189b82fc":"code","aa2e03a2":"code","25882097":"code","521040d4":"markdown","35d1c0ae":"markdown","69dd4660":"markdown","02d56016":"markdown","55687e17":"markdown","ae89cd28":"markdown","450acb63":"markdown","83aea741":"markdown","86fbae5c":"markdown","b3c2d44b":"markdown","53b3a301":"markdown","874e4b43":"markdown","42a895df":"markdown","59f3864b":"markdown","1587cf47":"markdown","6e47eca3":"markdown","2cd3e2c5":"markdown","69f266df":"markdown","5c31def6":"markdown"},"source":{"63b1340f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c5fef8e3":"#import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)","c6c8faef":"#Load the sentiment_values.csv - The smallest dataset\ndf = pd.read_csv('..\/input\/nowplayingrs\/sentiment_values.csv')\n\n#Look at size of the dataset\ndf.shape","51d0783d":"#Look at the columns and initial rows of the dataset\ndf.head()","23bec686":"#Rename hashtag column\ndf.rename(columns = {'hashtag':'ss_score'}, inplace = True)\n\n#Reset index\ndf.reset_index(inplace=True)\n\n#Rename columns\ndf.rename(columns = {'level_0':'hashtag','level_1':'vader_score','level_2':'afinn_score','level_3':'ol_score'}, inplace = True)\n\n#Show dataset to confirm changes\ndf.head()","cf949802":"#Set columns\ndf.columns=['hashtag','vader_score','afinn_score','ol_score','ss_score','vader_min','vader_max','vader_sum','vader_avg','afinn_min',\n            'afinn_max','afinn_sum','afinn_avg','ol_min','ol_max','ol_sum','ol_avg','ss_min','ss_max','ss_sum','ss_avg']","60f967e8":"df = df.drop(['vader_min','vader_max','vader_sum','afinn_min','afinn_max','afinn_sum','ol_min','ol_max','ol_sum','ss_min','ss_max','ss_sum'], axis=1)\ndf.head()","3515af03":"#Show how many (sum) unique values are in the hashtag column\nlen(df['hashtag'].unique().tolist())","49358bf5":"df.info()\n#There all score columns are missing values","5a7b407f":"#Fill in missing vader_score with vader_avg score, if available\ndf['vader_score'] = df.apply(\n    lambda row: row['vader_avg'] if np.isnan(row['vader_score']) else row['vader_score'],\n    axis=1\n)","0ece22b9":"df.info()\n#vader_score didn't change","71a1d1c4":"#Fill in missing afinn_score with afinn_avg score, if available\ndf['afinn_score'] = df.apply(\n    lambda row: row['afinn_avg'] if np.isnan(row['afinn_score']) else row['afinn_score'],\n    axis=1\n)","d2345737":"df.info()\n#afinn_score increased from 3867 to 4532","85058469":"#Fill in missing ol_score with ol_avg score, if available\ndf['ol_score'] = df.apply(\n    lambda row: row['ol_avg'] if np.isnan(row['ol_score']) else row['ol_score'],\n    axis=1\n)","bcf0fc37":"df.info()\n#ol_score increased from 3867 to 4831","a26c1527":"#Fill in missing ss_score with ss_avg score, if available\ndf['ss_score'] = df.apply(\n    lambda row: row['ss_avg'] if np.isnan(row['ss_score']) else row['ss_score'],\n    axis=1\n)","0a9e33fd":"df.info()\n#ss_score increased from 3867 to 4471","8e407b4e":"#Remove all of the unnecessary scores - ol_score has the highest amount of ratings per hashtag\ndf1 = df.drop(['vader_score','afinn_score','ss_score','vader_avg','afinn_avg','ol_avg','ss_avg'], axis=1)\ndf1.head()","318b1a2d":"df1 = df1.dropna(axis = 0, how ='any') \ndf1.info()","7098448e":"df1.sort_index(by='hashtag', ascending=[False])","a65f12cb":"#Rename column\ndf1.rename(columns = {'ol_score':'sentiment_score'}, inplace = True)\ndf1.head()","58af1305":"#Show top 10 hashtags with the largest sentiment_score\nx = df1.nlargest(10, 'sentiment_score', keep='all')\nx","6c97db41":"#Look at dataset by sentiment score counts\ncount = df1.groupby(['sentiment_score']).count() \nprint(count)","eedddd4a":"#Load second dataset\ndf2 = pd.read_csv('..\/input\/nowplayingrs\/user_track_hashtag_timestamp.csv')\n\n#Look at size of the dataset\ndf2.shape","40bf5618":"#Look at the columns and initial rows of the dataset\ndf2.head()","3dcccea1":"#Check for null values\ndf2.apply(lambda x: x.isnull().sum())","386c3ce4":"#Drop null rows\ndf2.dropna(subset=['hashtag'], inplace=True)\ndf2.apply(lambda x: x.isnull().sum())","b1801193":"# Get the count of the track_id\ncounts = df2['track_id'].value_counts()\n\n# Select the items where the track_id count is less than 50 and remove them\ndf2 = df2[~df2['track_id'].isin(counts[counts < 50].index)]\n\n# Show info\ndf2.info()","9d91aa20":"df2.user_id.value_counts()","4ff291a3":"df2.track_id.value_counts()","40da6d85":"#Merge CSV files into a single file based on hashtag\ndf_sentiment = pd.merge(df1, df2, on=\"hashtag\", how='inner')\ndf_sentiment.head()","49205034":"#Confirm null values in new dataframe\ndf_sentiment.apply(lambda x: x.isnull().sum())","afc970ab":"df_sentiment.shape","beccaf22":"df_sentiment.hashtag.value_counts().head(10)","02df76bc":"#Load third dataset and limit it to only load 22 columns\ndf3 = pd.read_csv('..\/input\/nowplayingrs\/context_content_features.csv', usecols=range(0, 22))\n\n#Look at size of the dataset\ndf3.shape","cb6f6f40":"# Get the count of the track_id\ncounts = df3['track_id'].value_counts()\n\n# Select the items where the track_id count is less than 50 and remove them\ndf3 = df3[~df3['track_id'].isin(counts[counts < 50].index)]\n\n# Show info\ndf3.info()","51532e42":"#Drop unnecessary columns before merging with df_sentiment dataframe\ndf3 = df3.drop(['coordinates','id','place','geo'], axis=1)\ndf3.head()","ceaa7232":"#Drop all null value rows\ndf3 = df3.dropna()\n\n#Convert mode to Int64\ndf3['mode'] = df3['mode'].astype('Int64')\n\ndf3.shape","642058d1":"#Limit dataset to only en (English) language\ndf3 = df3.loc[~((df3['lang'] != 'en')),:]\ndf3.info()","08a08f96":"#Confirm change by looking at the unique values in the lang column\ndf3.lang.unique()","a1587bdc":"#Merge df_sentiment and df3 CSV files into new CSV file based on track_id, created_at and user_id\ndf4 = df_sentiment.merge(df3, on=['track_id','created_at','user_id'], how='inner')\ndf4.head()","6264266f":"#Convert hashtag info string\ndf4['hashtag'] = df4['hashtag'].astype(str)\n\n#Convert user_id info string\ndf4['user_id'] = df4['user_id'].astype(str)\n\n#Show changes\ndf4.info()","253edf2e":"#Create new column sentiment that will be the predictor based on the sentiment_score values\ndf4['sentiment'] = np.where(df4['sentiment_score']>= 0.01, 1, 0)\ndf4.head()","9e30abb6":"#Drop all null value rows\ndf4 = df4.dropna()\n\n#Drop unnecessary columns lang and created_at\ndf4 = df4.drop(['hashtag','created_at','artist_id','tweet_lang','lang'], axis=1)\n\ndf4.head()","5919479f":"#Look at unique values for time_zone column\ndf4.time_zone.unique()","063e48d2":"#Make all USA Timezone values consistent\ndf4['time_zone'].replace('Eastern Time (US & Canada)', 'Eastern Time',inplace=True)\ndf4['time_zone'].replace('Central Time (US & Canada)', 'Central Time',inplace=True)\ndf4['time_zone'].replace('Pacific Time (US & Canada)', 'Pacific Time',inplace=True)\ndf4['time_zone'].replace('Mountain Time (US & Canada)', 'Mountain Time',inplace=True)\ndf4['time_zone'].replace('Alaska', 'Alaska Time',inplace=True)\ndf4['time_zone'].replace('Hawaii', 'Hawaii Time',inplace=True)\ndf4['time_zone'].replace('Arizona', 'Mountain Time',inplace=True)\ndf4['time_zone'].replace('America\/Chicago', 'Central Time',inplace=True)\ndf4['time_zone'].replace('America\/New_York', 'Eastern Time',inplace=True)\ndf4['time_zone'].replace('America\/Los_Angeles', 'Pacific Time',inplace=True)\ndf4['time_zone'].replace('America\/Denver', 'Mountain Time',inplace=True)\ndf4['time_zone'].replace('America\/Detroit', 'Eastern Time',inplace=True)","49d09b09":"#Limit dataset to only USA time zones\ndf4 = df4.loc[~((df4['time_zone'] != 'Eastern Time') & (df4['time_zone'] != 'Central Time') & (df4['time_zone'] != 'Pacific Time') & \n               (df4['time_zone'] != 'Mountain Time') & (df4['time_zone'] != 'Alaska Time') & (df4['time_zone'] != 'Hawaii Time')),:]\ndf4.info()","2bb70036":"# Reorder columns\ndf_mvp = df4[['sentiment','sentiment_score','user_id','track_id','time_zone','instrumentalness',\n              'liveness','speechiness','danceability','valence','loudness','tempo','acousticness','energy','mode','key']]\ndf_mvp.info()","7e013132":"# Create new dataset with only user_id, track_id and time_zone and the category variables\ndf_timezone = df_mvp.drop(['user_id','track_id','sentiment','sentiment_score','instrumentalness','liveness','speechiness',\n                             'danceability','valence','loudness','tempo','acousticness','energy','mode','key'], axis=1)\ndf_timezone.head()","3f885b37":"from numpy import array\nfrom numpy import argmax\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\n# One Hot Encode the category data set\none_hot_df = pd.get_dummies(df_timezone)\none_hot_df.head()","b8f459d6":"# Rename the columns\none_hot_df.columns = ['tz_Alaska_Time','tz_Central_Time','tz_Eastern_Time','tz_Hawaii_Time','tz_Mountain_Time','tz_Pacific_Time']\none_hot_df.head()","8bc500f2":"#Drop time_zone from MVP dataset\ndf_mvp = df_mvp.drop([\"time_zone\"], axis=1)","18bbfaea":"#Concatenate one hot encoded dataframe\ndf_mvp = pd.concat([df_mvp,one_hot_df], axis=1)\ndf_mvp.head()","662fad7d":"df_mvp.to_csv('module4_cleaned.csv',index=False)","492e0ab9":"#Look at value counts of the predictor variable sentiment\ndf_mvp.sentiment.value_counts()","0f2dec93":"# Visualize the predictor variable\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.countplot(x='sentiment', data=df_mvp, palette='hls')\nplt.show()","3457f531":"# Create continuous dataset and look at distributions of data\ndf_mvp_lin = df_mvp.drop(['user_id','track_id','sentiment','mode','tz_Alaska_Time','tz_Central_Time','tz_Eastern_Time',\n                          'tz_Hawaii_Time','tz_Mountain_Time','tz_Pacific_Time'], axis=1)\ndf_mvp_lin.hist(figsize = [30, 20]);","8cbd859d":"#Create coorelation heatmap and check for multicolinarity\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\ncorrelation = df_mvp_lin.corr()\nplt.figure(figsize=(14, 12))\nheatmap = sns.heatmap(correlation, annot=True, linewidths=0, vmin=-1, cmap=\"RdBu_r\")","da7b01ba":"# Define X and y\ny = df_mvp['sentiment']\nX = df_mvp.drop('sentiment', axis = 1)","c22d102e":"# Normalizing the data prior to fitting the model.\nx_feats = ['sentiment_score','instrumentalness','liveness','speechiness','danceability',\n           'loudness','tempo','acousticness','energy','mode','key','valence','tz_Alaska_Time',\n           'tz_Central_Time','tz_Eastern_Time','tz_Hawaii_Time','tz_Mountain_Time','tz_Pacific_Time']\n\nX = pd.get_dummies(df_mvp[x_feats], drop_first=False)\ny = df_mvp.sentiment\nX.head()","5399b89b":"from sklearn.model_selection import train_test_split\n\n# Splitting the data into train and test sets (automatically uses stratified sampling by labels)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)","af7682c6":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(fit_intercept = True, C=1e12)\nmodel_log = logreg.fit(X_train, y_train)\nmodel_log","fca53257":"print(y_train.value_counts())\nprint(y_test.value_counts())","4d6698a6":"#Predict against test set using Sigmoid function\nimport time\nstart = time.time()\n\ny_hat_test = logreg.predict(X_test)\ny_hat_train = logreg.predict(X_train)\n\nend = time.time()\nprint(\"Execution time:\", end - start)","d4e299b1":"y_hat_test = logreg.predict_proba(X_test)\ny_hat_test[0]","614360dd":"import time\nstart = time.time()\n\nlogreg.predict_proba(X_train)\n\nend = time.time()\nprint(\"Execution time:\", end - start)","e79a98a0":"# How may times was the classifier correct for the training set?\nlogreg.score(X_train, y_train)","1c363923":"# How may times was the classifier correct for the test set?\nlogreg.score(X_test, y_test)","78e8b935":"# Function to calculate the precision\ndef precision(y_hat, y):\n    y_y_hat = list(zip(y, y_hat))\n    tp = sum([1 for i in y_y_hat if i[0]==1 and i[1]==1])\n    fp = sum([1 for i in y_y_hat if i[0]==0 and i[1]==1])\n    return tp\/float(tp+fp)","da98a8fb":"# Function to calculate the recall\ndef recall(y_hat, y):\n    y_y_hat = list(zip(y, y_hat))\n    tp = sum([1 for i in y_y_hat if i[0]==1 and i[1]==1])\n    fn = sum([1 for i in y_y_hat if i[0]==1 and i[1]==0])\n    return tp\/float(tp+fn)","17d409bd":"# Function to calculate the accuracy\ndef accuracy(y_hat, y):\n    y_y_hat = list(zip(y, y_hat))\n    tp = sum([1 for i in y_y_hat if i[0]==1 and i[1]==1])\n    tn = sum([1 for i in y_y_hat if i[0]==0 and i[1]==0])\n    return (tp+tn)\/float(len(y_hat))","ae4dfdc6":"# Calculate the precision, recall and accuracy of the classifier.\ny_hat_test = logreg.predict(X_test)\ny_hat_train = logreg.predict(X_train)\n\nprint('Training Precision: ', precision(y_hat_train, y_train))\nprint('Testing Precision: ', precision(y_hat_test, y_test))\nprint('\\n')\n\nprint('Training Recall: ', recall(y_hat_train, y_train))\nprint('Testing Recall: ', recall(y_hat_test, y_test))\nprint('\\n')\n\nprint('Training Accuracy: ', accuracy(y_hat_train, y_train))\nprint('Testing Accuracy: ', accuracy(y_hat_test, y_test))","e8b80e8c":"# concatenate our training data back together\ntraining_data = pd.concat([X_train, y_train], axis=1)","a898f06d":"# separate minority and majority classes\nnot_safe = training_data[training_data.sentiment==0]\nsafe = training_data[training_data.sentiment==1]","a4143839":"from sklearn.utils import resample\n# upsample minority\nnot_safe_upsampled = resample(not_safe, \n                              replace=True, # sample with replacement\n                              n_samples=len(safe), # match number in majority class\n                              random_state=42) # reproducible results","b9571956":"# combine majority and upsampled minority\nupsampled = pd.concat([safe, not_safe_upsampled])","cc283d93":"# check new class counts\nprint(upsampled.sentiment.value_counts())","d8d35fc7":"sns.countplot(x='sentiment', data=upsampled, palette='hls')\nplt.show()","dd2d12d6":"X_train = upsampled.drop('sentiment', axis=1)\ny_train = upsampled.sentiment","e3450957":"# Scaling X using StandardScaler\nfrom sklearn.preprocessing import StandardScaler\n\n# Only fit training data to avoid data leakage\nscaler = StandardScaler()\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns=list(X.columns))\nX_test = pd.DataFrame(scaler.transform(X_test), columns=list(X.columns))\nX_train.head()","3f2f384d":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nlogreg2 = LogisticRegression(fit_intercept = True, C=1e12)\nmodel_log = logreg2.fit(X_train, y_train)\nmodel_log","8dc7fc1d":"print(y_train.value_counts())\nprint(y_test.value_counts())","89c7edc8":"# Predict against test set using Sigmoid function\nimport time\nstart = time.time()\n\ny_hat_test = logreg2.predict(X_test)\ny_hat_train = logreg2.predict(X_train)\n\nend = time.time()\nprint(\"Execution time:\", end - start)","c1c0fbf1":"y_hat_test = logreg2.predict_proba(X_test)\ny_hat_test[0]","d755d194":"import time\nstart = time.time()\n\nlogreg2.predict_proba(X_train)\n\nend = time.time()\nprint(\"Execution time:\", end - start)","1b92cab9":"#Train score\nlogreg2.score(X_train, y_train)","fec14bf8":"#Test score\nlogreg2.score(X_test, y_test)","2c6144a0":"logreg2.coef_[0]","46679259":"for feature, weight in zip(X.columns, logreg2.coef_[0]):\n    print(\"{} has a weight of : {}\".format(feature, weight))","b5ad0e5d":"#Create a Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\n\ncnf_matrix = confusion_matrix(y_train, y_hat_train)\nprint('Confusion Matrix:\\n',cnf_matrix)","a7a13dad":"#Plot the Confusion Matrix\nimport itertools\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.imshow(cnf_matrix,  cmap=plt.cm.Blues) #Create the basic matrix\n\n#Add title and axis labels\nplt.title('Confusion Matrix')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n\n#Add appropriate axis scales\nclass_names = set(y) #Get class labels to add to matrix\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names, rotation=45)\nplt.yticks(tick_marks, class_names)\n\n#Add Labels to each cell\nthresh = cnf_matrix.max() \/ 2. #Used for text coloring below\n#Here we iterate through the confusion matrix and append labels to our visualization\nfor i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n        plt.text(j, i, cnf_matrix[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n\n#Add a side bar legend showing colors\nplt.colorbar()","49a61f95":"#conf_matrix function\ndef conf_matrix(y_true, y_pred):\n    cm = {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0}\n    \n    for ind, label in enumerate(y_true):\n        pred = y_pred[ind]\n        if label == 1:\n            # CASE: TP \n            if label == pred:\n                cm['TP'] += 1\n            # CASE: FN\n            else:\n                cm['FN'] += 1\n        else:\n            # CASE: TN\n            if label == pred:\n                cm['TN'] += 1\n            # CASE: FP\n            else:\n                cm['FP'] += 1\n    return cm","d34c7003":"#Set variable\nmodel_confusion_matrix = conf_matrix(y_train, y_hat_train)","9481295a":"#Precision function\ndef precision(confusion_matrix):\n    return confusion_matrix['TP'] \/ (confusion_matrix['TP'] + confusion_matrix['FP'])","d24bd2a9":"#Recall function\ndef recall(confusion_matrix):\n    return confusion_matrix['TP'] \/ (confusion_matrix['TP'] + confusion_matrix['FN'])","da3f8e30":"#Accuracy function\ndef accuracy(confusion_matrix):\n    return (confusion_matrix['TP'] + confusion_matrix['TN']) \/ sum(confusion_matrix.values())","9178e236":"#f1 score\ndef f1(confusion_matrix):\n    precision_score = precision(confusion_matrix)\n    recall_score = recall(confusion_matrix)\n    numerator = precision_score * recall_score\n    denominator = precision_score + recall_score\n    return 2 * (numerator \/ denominator)","43a98473":"from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n\npreds = [y_hat_train]\n\nfor ind, i in enumerate(preds):\n    print('-'*40)\n    print('Model Metrics:'.format(ind + 1))\n    print('Precision: {}'.format(precision_score(y_train, i)))\n    print('Recall: {}'.format(recall_score(y_train, i)))\n    print('Accuracy: {}'.format(accuracy_score(y_train, i)))\n    print('F1-Score: {}'.format(f1_score(y_train, i)))","711bea96":"from sklearn.metrics import classification_report\n\nfor ind, i in enumerate(preds):\n    print('-'*40)\n    print(\"Model Classification Report:\".format(ind + 1))\n    print(classification_report(y_train, i))","78814785":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nlinreg = LinearRegression()\nimport matplotlib.pyplot as plt\n\nnum = 20\ntrain_err = []\ntest_err = []\nfor i in range(num):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n    logreg2.fit(X_train, y_train)\n    y_hat_train = logreg2.predict(X_train)\n    y_hat_test = logreg2.predict(X_test)\n    train_err.append(mean_squared_error(y_train, y_hat_train))\n    test_err.append(mean_squared_error(y_test, y_hat_test))\nplt.scatter(list(range(num)), train_err, label='Training Error')\nplt.scatter(list(range(num)), test_err, label='Testing Error')\nplt.legend();","a0ef7a44":"#K-Fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\n\ncv_5_results = np.mean(cross_val_score(logreg2, X, y, cv=5, scoring=\"accuracy\"))\ncv_10_results = np.mean(cross_val_score(logreg2, X, y, cv=10, scoring=\"accuracy\"))\ncv_20_results = np.mean(cross_val_score(logreg2, X, y, cv=20, scoring=\"accuracy\"))\n\nprint(cv_5_results)\nprint(cv_10_results)\nprint(cv_20_results)","62a63b63":"# Load libraries\nfrom numpy import loadtxt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import ModelCheckpoint\n\n# split into input (X) and output (y) variables\nX = pd.get_dummies(df_mvp[x_feats], drop_first=False)\ny = df_mvp.sentiment","75f3345a":"# define the keras model\nmodel = Sequential()\nmodel.add(Dense(12, input_dim=18, activation='relu'))\nmodel.add(Dense(19, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","5ed30fbc":"# compile the keras model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","f07342d6":"# Set callback functions to early stop training and save the best model so far\ncheckpoint = [ModelCheckpoint(filepath='models.hdf5', save_best_only=True, monitor='val_loss')]","11789588":"# fit the keras model on the dataset\nmodel.fit(X, y, epochs=10, callbacks=checkpoint, batch_size=100)","e84c65ec":"# evaluate the keras model\n_, accuracy = model.evaluate(X, y)\nprint('Accuracy: %.2f' % (accuracy*100))","4ebcef54":"# split into input (X) and output (y) variables\nX = pd.get_dummies(X_train, drop_first=False) #X_train = upsampled.drop('sentiment', axis=1)\ny = y_train #y_train = upsampled.sentiment","32c6ab3b":"# define the keras model\nmodel2 = Sequential()\nmodel2.add(Dense(12, input_dim=18, activation='relu'))\nmodel2.add(Dense(8, activation='relu'))\nmodel2.add(Dense(1, activation='sigmoid'))","54a39f05":"# compile the keras model\nmodel2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","189b82fc":"# Set callback functions to early stop training and save the best model so far\ncheckpoint = [ModelCheckpoint(filepath='models.hdf5', save_best_only=True, monitor='val_loss')]","aa2e03a2":"# fit the keras model on the dataset\nmodel2.fit(X, y, epochs=10, callbacks=checkpoint, batch_size=100)","25882097":"# evaluate the keras model\n_, accuracy = model2.evaluate(X, y)\nprint('Accuracy: %.2f' % (accuracy*100))","521040d4":"**Observation**: The data is very imbalanced and will need to be balanced.","35d1c0ae":"Reduced the dataset from 4,916,702 to **2,267,492** by limiting it to USA Timezone data only.\n\n### Create MVP Dataset\n- Reduced to U.S.A. only dataset\n- **13 feature columns**\n    - sentiment_score: Sentiment score from Opinion Lexicon. If no score was provided then a 0 was input.\n    - user_id: Unique user ID\n    - track_id: Unique track ID\n    - sentiment: Sentiment extracted from sentiment score based on range 0-1\n    - Instrumentalness: Signifies whether a track contains vocals.\n    - Liveness: Presence of an audience in the track recording (range is [0, 1], where 1 indicates high probability of liveness).\n    - Speechiness: Presence of spoken words in a track - whether a track contains more music or words (range is [0, 1], where 0 is a track with no speech).\n    - Danceability: Suitability of a track for dancing based on a combination of musical elements like tempo, rhythm stability, beat strength, and overall regularity (range is [0, 1], where 1 is a most danceable song).\n    - Valence: Musical positiveness conveyed by a track (range is [0, 1], where 1 is a highly positive and cheerful song).\n    - Loudness: The overall loudness of a track in decibel (dB).\n    - Tempo: The overall estimated tempo of a track in beats per minute (BPM).\n    - Acousticness: Probability whether a track is acoustic (range is [0, 1]).\n    - Energy: Perceptual measure of intensity and activity (range is [0, 1], where 1 indicates a high-energy track).\n    - Mode: Modality (major or minor) of a track, i.e., the type of scale from which its melodic content is derived. Major is 1 and minor is 0.\n    - Key: The key that the track is in. Integers map to pitches using standard Pitch Class notation.\n    - tz_Alaska_Time: Categorical - One hot encoded from (dropped) timezone column\n    - tz_Central_Time: Categorical - One hot encoded from (dropped) timezone column\n    - tz_Eastern_Time: Categorical - One hot encoded from (dropped) timezone column\n    - tz_Hawaii_Time: Categorical - One hot encoded from (dropped) timezone column\n    - tz_Mountain_Time: Categorical - One hot encoded from (dropped) timezone column\n    - tz_Pacific_Time: Categorical - One hot encoded from (dropped) timezone column\n    - sentiment: Extracted from `sentiment_score` with a range 0-1 and is the **predictor column**","69dd4660":"Now that the two CSV files are joined (inner join), the new dataframe `df_sentiment` is reduced to **5,126,717** rows (from 17,560,114).\n\n## Load the third dataset\n* Remove tracks that were played less than 50 times\n* Remove unnecessary columns\n* Remove null values\n* Reduce the dataset to English only language\n* Merge it with the df_sentiment dataset based on `track_id`, `created_at` and `user_id` columns","02d56016":"## Load the second dataset\n* Remove null values\n* Remove tracks that were played less than 50 times\n* Merge it with the cleaned df1 dataset (4831 hastags and sentiment scores)","55687e17":"## Create a Sequential Neural Network\n- ReLU activation function\n- Sigmoid function on the output layer ","ae89cd28":"Reduced the dataset from 7,740,906 to **4,916,702** by limiting it to English only (lang = en).\n\n### Merge datasets based on track_id, created_at, and user_id","450acb63":"The following 12 columns are unecessary and will be removed from the data set:\n\n- **vader_min**: no valuable information, will use vader_score instead\n- **vader_max**: no valuable information, will use vader_score instead\n- **vader_sum**: no valuable information, will use vader_score instead\n- **affin_min**: no valuable information, will use affin_score instead\n- **affin_max**: no valuable information, will use affin_score instead\n- **affin_sum**: no valuable information, will use affin_score instead\n- **ol_min**: no valuable information, will use ol_score instead\n- **ol_max**: no valuable information, will use ol_score instead\n- **ol_sum**: no valuable information, will use ol_score instead\n- **ss_min**: no valuable information, will use ss_score instead\n- **ss_max**: no valuable information, will use ss_score instead\n- **ss_sum**: no valuable information, will use ss_score instead","83aea741":"## Purpose\nFor this project, I will be using Twitter hashtags, sentiment scores, and music streaming session data from Spotify to predict the next song to be played.\n\n## OBTAIN & SCRUB: Prepare the Datasets\n* Load 3 datasets: **sentiment_values.csv, user_track_hashtag_timestamp.csv and context_content_features.csv**\n* Data type conversions (e.g. numeric data mistakenly encoded as objects)\n* Detect and deal with missing values\n* Remove unnecessary columns","86fbae5c":"By removing tracks that were played less than 50 times, the dataset is reduced from 11,614,671 to **9,143,294** rows. The following unnecessary columns will be droped:\n\n- **coordinates**: no valuable information, will use `time_zone` instead\n- **id**: no valuable information, will use `user_id instead\n- **place**: no valuable information, will use `time_zone` instead\n- **geo**: no valuable information, will use `time_zone` instead","b3c2d44b":"**Observation**: Loudness and Energy seem to be highly coorelated.\n\n## Logistic Regression\n* Normalize the data prior to fitting the model\n* Train-Test Split\n* Fit the model\n* Predict\n* Evaluate","53b3a301":"Reduced the dataset from 10,887,911 to **6,413,576** by dropping all null value rows.","874e4b43":"### Classification Model Performance\nCheck the precision, recall, and accuracy of the model.","42a895df":"### Confusion Matrix\n\nShow the performance of the classification model.","59f3864b":"### Run another Logistic Regression Model with resampled data","1587cf47":"The following unnecessary columns will be droped:\n\n- **hashtag**: no valuable information, will use `sentiment_score` instead\n- **created_at**: no valuable information after the data merge\n- **artist_id**: no valuable information for this model\n- **tweet_lang**: no valuable information for this model\n- **lang**: no valuable information since this dataset has been reduced to English only","6e47eca3":"## Cross Validation\nRepeat a train-test-split creation 20 times, using a test_size of 0.05.","2cd3e2c5":"### Resample data since it's imbalanced and all scores are very high.","69f266df":"## Explore the data\n\n* Look at the distribution for the data\n* Look for Multicollinearity\n* Remove unnecessary features\n* Balace and scale data","5c31def6":"## Create a Sequential Neural Network with the scaled data\n- ReLU activation function\n- Sigmoid function on the output layer "}}