{"cell_type":{"a7c7a591":"code","66772da2":"code","dfe2003c":"code","b074f2ab":"code","9297ce9a":"code","ed9bc750":"code","c3149666":"code","f9013a94":"code","660d7a35":"code","800ea38d":"code","26b9c0eb":"code","14844fe6":"code","1b17d456":"code","fa50c6a2":"code","0f71adf5":"code","2574fa88":"code","f6d930de":"markdown","74047b42":"markdown","7edf2373":"markdown","9b6720c6":"markdown","eb9b8ede":"markdown","3770d8e9":"markdown","6e807f14":"markdown","ff5b9cb4":"markdown"},"source":{"a7c7a591":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","66772da2":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/test.csv\")\nSS = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")","dfe2003c":"train[\"target\"].value_counts()\n","b074f2ab":"train.isna().sum().sum()","9297ce9a":"X = train[['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n       'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19',\n       'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24',\n       'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29',\n       'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34',\n       'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39',\n       'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44',\n       'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49',\n       'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54',\n       'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59',\n       'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64',\n       'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69',\n       'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74',]]\ntest1 = test[['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n       'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19',\n       'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24',\n       'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29',\n       'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34',\n       'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39',\n       'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44',\n       'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49',\n       'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54',\n       'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59',\n       'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64',\n       'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69',\n       'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74',]]\nY = train[[\"target\"]]","ed9bc750":"plt.figure(figsize=(15,30))\nfor i in range(0,75):\n    plt.subplot(25,3,i+1)\n    plt.hist(X.iloc[:,i])","c3149666":"obj_standatd_scalar = StandardScaler()\nX_normalized = obj_standatd_scalar.fit_transform(X)\nX_normalized_df = pd.DataFrame(X_normalized)\nX= X_normalized_df","f9013a94":"plt.figure(figsize=(15,30))\nfor i in range(0,75):\n    plt.subplot(25,3,i+1)\n    plt.hist(X_normalized_df.iloc[:,i])","660d7a35":"x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=1)","800ea38d":"#DTC = DecisionTreeClassifier(random_state=1,max_depth=10).fit(x_train,y_train)\n#KNN = KNeighborsClassifier(n_neighbors=20).fit(x_train,y_train)\n#RFC = RandomForestClassifier(random_state=1).fit(x_train,y_train.values.ravel())\nDTC = GaussianNB().fit(x_train, y_train.values.ravel())\n","26b9c0eb":"DTC_predict = DTC.predict(x_test)\n#DTC_predict = KNN.predict(x_test)\n","14844fe6":"#checking the accuracy of the model\ny_pred_list = list(DTC_predict)\ny_test_list = list(y_test[\"target\"])\ncount = 0\nfor i in range (0,len(y_pred_list)):\n    if(y_pred_list[i]==y_test_list[i]):\n        count =count+1\naccuracy = count\/len(y_test)\naccuracy  \n    ","1b17d456":"conf_mat = confusion_matrix(y_test,RFC_predict)\nplt.matshow(conf_mat, cmap = plt.cm.gray)","fa50c6a2":"preds = RFC.predict_proba(test1)","0f71adf5":"subm1 = pd.DataFrame(preds, columns=['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9'])\nsubm = pd.DataFrame({'id':SS['id']}) \ns = pd.concat([subm,subm1],axis=1)","2574fa88":" s.to_csv(\"submission.csv\",index=False)","f6d930de":"> ***Clearly this is a multi-class classification problem***","74047b42":"# Part two :- Getting dataset ready","7edf2373":">  We will be applying different classification model and check for the one which gives the most accurate result :-\n\n> 1. Decision Tree classifier\n> 2. K-nearest neighbours\n> 3. Random forest regressor  \n\n\n> SVM cant be used here because the dataset is huge\n","9b6720c6":"# Part one :- Exploratory data analysis","eb9b8ede":"> **Hence, there is no null value in the data, so we dont require any imputation**","3770d8e9":"This shows that the model performs really bad.","6e807f14":"# Lets import the dataset into variables :-\n* train for training data\n* test for test data\n* ss for sample submission","ff5b9cb4":"> **So, we have the following classes in the dataset :- Class_1 through 9 i.e 9 classes** "}}