{"cell_type":{"8d31578a":"code","f14ff483":"code","5a96ae0b":"code","fb8cb1cd":"code","519ee2d7":"code","5ebeb676":"code","de78f110":"code","b1835f2f":"code","693e5455":"code","dcec5dd3":"code","ab7685f2":"code","a0160273":"code","78b48d05":"code","7b69dd82":"code","79ea83a7":"code","216b7da9":"code","7282b4c9":"code","e4dd0621":"code","c6f6e3c8":"code","0c7dfa6d":"code","7bad2903":"code","777b8e43":"code","5e8b11a8":"code","8c44ca91":"code","3b5b2313":"code","106f1d19":"code","9b11aac8":"code","95e8f9d6":"code","d9130ec2":"code","2d5574b6":"code","606137fe":"code","5c46a319":"code","e40f2fdf":"code","e16a8a43":"code","3dd1ea96":"code","481df169":"code","dd351372":"code","f285a602":"code","2de04739":"code","c1489440":"code","49b828cb":"code","71481864":"code","e39cd0e6":"code","3131275b":"code","39b04d3c":"code","6ae90171":"code","7bf2e177":"markdown","3c196234":"markdown","f0120e9c":"markdown","0a56089e":"markdown","3ffa3930":"markdown","dda38d33":"markdown","e9567cf2":"markdown","4920ea10":"markdown","93eb4e7e":"markdown","9b1c7d06":"markdown","be3434b6":"markdown","b8002f61":"markdown","b88e864c":"markdown","f4e57c2e":"markdown","b371f3c6":"markdown","34c7e683":"markdown","1fe5238d":"markdown","7daa4da9":"markdown","8f7d7a99":"markdown","94e40834":"markdown","66cff6d6":"markdown","5bb09417":"markdown","1555eb82":"markdown"},"source":{"8d31578a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f14ff483":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nfrom sklearn import preprocessing\nfrom scipy import stats\nsns.set()","5a96ae0b":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","fb8cb1cd":"train.head()","519ee2d7":"test.head()","5ebeb676":"print(train.shape,test.shape)","de78f110":"print(train.columns, test.columns)","b1835f2f":"#Store indexes for splitting back later\ntrain_total_rows = train.shape[0]\ntest_total_rows = test.shape[0]\n\nconcat = pd.concat([train,test]).reset_index(drop=True)\nconcat.drop(['SalePrice'],axis=1,inplace=True)\nprint(train.shape)\nprint(test.shape)\nprint(concat.shape)","693e5455":"concat_na = (concat.isna().sum() \/ len(concat))*100\nconcat_na = concat_na.sort_values(ascending=False)\nconcat_na = concat_na.drop(concat_na[concat_na==0].index)\nnan_values = pd.DataFrame({'NaN %':concat_na})\nnan_values.head()","dcec5dd3":"sns.barplot(data=nan_values,x=nan_values.index,y='NaN %')\nplt.xlabel('Features')\nplt.ylabel('Percentage of NaN values')\nplt.title('Percentage of NaN by features')\nplt.xticks(rotation=90)\nplt.show()","ab7685f2":"concat_full = concat.copy()\nconcat_full['PoolQC'].fillna('None',inplace=True)\nnan_values","a0160273":"concat_full['MiscFeature'].fillna('None',inplace=True)\nconcat_full['Alley'].fillna('None',inplace=True)\nconcat_full['Fence'].fillna('None',inplace=True)\nconcat_full['FireplaceQu'].fillna('None',inplace=True)","78b48d05":"concat_full[\"LotFrontage\"] = concat_full.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))","7b69dd82":"for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    concat_full[col].fillna('None', inplace=True)","79ea83a7":"for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    concat_full[col].fillna(0, inplace=True)","216b7da9":"for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','MasVnrType',):    \n    concat_full[col].fillna('None', inplace=True)\n\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtHalfBath', 'BsmtFullBath','MasVnrArea'):\n    concat_full[col].fillna(0, inplace=True)","7282b4c9":"nan_values","e4dd0621":"concat_full","c6f6e3c8":"for col in ('Electrical', 'Functional', 'Utilities','KitchenQual', 'Exterior1st', 'Exterior2nd','SaleType','MSZoning'):\n    concat_full[col].fillna(concat_full[col].mode()[0], inplace=True)","0c7dfa6d":"concat_na = (concat_full.isna().sum() \/ len(concat_full))*100\nconcat_na = concat_na.sort_values(ascending=False)\nconcat_na = concat_na.drop(concat_na[concat_na==0].index)\nnan_values = pd.DataFrame({'NaN %':concat_na})\nnan_values.head()","7bad2903":"train_full = concat_full[:train_total_rows]\ntrain_full['SalePrice'] = train['SalePrice']\ntest_full = concat_full[train_total_rows:]","777b8e43":"sns.boxplot(data=train_full,y='SalePrice',x='OverallQual')","5e8b11a8":"fig, ax = plt.subplots(figsize=(7,5))\nax.scatter(train_full['GrLivArea'],train_full['SalePrice'], alpha=0.5)\nax.set_ylabel('Sale Price')\nax.set_xlabel('GrLivArea')\nplt.show()","8c44ca91":"train_full = train_full.drop(train_full[train_full['GrLivArea'] > 4000].index)","3b5b2313":"fig, ax = plt.subplots(figsize=(7,5))\nax.scatter(train_full['GrLivArea'],train_full['SalePrice'], alpha=0.5)\nax.set_ylabel('Sale Price')\nax.set_xlabel('GrLivArea')\nplt.show()","106f1d19":"fig, ax = plt.subplots(figsize=(7,5))\nax.scatter(train_full['GarageArea'],train_full['SalePrice'], alpha=0.5)\nax.set_ylabel('Sale Price')\nax.set_xlabel('GarageArea')\nplt.show()","9b11aac8":"sns_rows = 7\nsns_cols = 5\nfig, axes = plt.subplots(sns_rows, sns_cols,figsize=(21,30))\npalette= sns.color_palette(\"Paired\", 10)\n\n#train_full = train_full.drop(columns=['Id'])\nnum_features = train_full.dtypes[train_full.dtypes != \"object\"].index\nnum_list = list(num_features)\n\nfor num in range(0,sns_rows):\n    for col in range(0, sns_cols):  \n        i = num * sns_cols + col\n        if i < len(num_list):\n            sns.regplot(x=num_list[i],y='SalePrice',\n            data = train_full, ax = axes[num][col],\n            color = palette[num],marker=\".\")     \nplt.show()   ","95e8f9d6":"corrmat = train_full.corr()\nwith sns.axes_style(\"white\"):\n\n    f, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(corrmat, ax=ax, cbar_kws={\"shrink\": .82},vmax=.9, cmap='coolwarm', square=True)","d9130ec2":"from sklearn.preprocessing import LabelEncoder\ndata = train_full.copy()\ncategorical_features= data.select_dtypes(include=['object']).copy()\nnumber=[len(data[features].unique()) for features in categorical_features]\ndata_tuples = list(zip(categorical_features,number))\ncategorical_data= pd.DataFrame(data_tuples, columns=['Features','Number of distinct values '])\ncategorical_data","2d5574b6":"for cat in categorical_features:\n    label_encoder = LabelEncoder()\n    label_encoder.fit(list(data[cat].values))\n    data[cat] = label_encoder.transform(list(data[cat].values))\ntraining_data=data.copy()\n\ndata = test_full.copy()\ncategorical_features = [features for features in data.columns if data[features].dtype == 'O']\n\nfor cat in categorical_features:\n    label_encoder = LabelEncoder()\n    label_encoder.fit(list(data[cat].values))\n    data[cat] = label_encoder.transform(list(data[cat].values))\ntest_data=data.copy()","606137fe":"training_data.head()","5c46a319":"def correlatedFeatures(correlation_data, threshold):\n    feature=[]\n    value=[]\n    for i,index in enumerate(correlation_data.index):\n        if abs(correlation_data[index]) > threshold:\n            feature.append(index)\n            value.append(correlation_data[index])\n    df = pd.DataFrame(data=value,index=feature,columns=['Corr Value'])\n    return df","e40f2fdf":"corr_check = correlatedFeatures(training_data.corr()['SalePrice'],0.5)\ncorr_check.sort_values(by='Corr Value', ascending=False)","e16a8a43":"plt.scatter(training_data.GrLivArea, training_data.SalePrice);\nplt.show()","3dd1ea96":"from scipy.stats import norm, skew\nprint(\"Skewness: %f\" % training_data['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % training_data['SalePrice'].kurt())\nprint()\nfig, ax = plt.subplots(1,2, figsize=(16,4))\nsns.distplot(training_data['SalePrice'] , fit=norm, ax=ax[0])\n\nres = stats.probplot(training_data['SalePrice'],plot=ax[1])\nplt.show()","481df169":"training_data['SalePrice'] = np.log(training_data['SalePrice'])","dd351372":"print(\"Skewness: %f\" % training_data['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % training_data['SalePrice'].kurt())\nprint()\nfig, ax = plt.subplots(1,2, figsize=(16,4))\nsns.distplot(training_data['SalePrice'] , fit=norm, ax=ax[0])\n\nres = stats.probplot(training_data['SalePrice'],plot=ax[1])\nplt.show()","f285a602":"numeric_feats =training_data.dtypes[training_data.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = training_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","2de04739":"skewness = skewness[abs(skewness) > 0.75]\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlambda_value = 0.15\nfor feat in skewed_features:\n    training_data[feat] = boxcox1p(training_data[feat], lambda_value)\n    \nnumeric_feats =test_data.dtypes[test_data.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = test_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness = skewness[abs(skewness) > 0.75]\n\nskewed_features = skewness.index\nlambda_value = 0.15\nfor feat in skewed_features:\n    test_data[feat] = boxcox1p(test_data[feat], lambda_value)","c1489440":"final_data=training_data.copy()\nfinal_data.drop(['SalePrice'],axis=1)\nX_train=final_data\nX_train= X_train.drop(['SalePrice'],axis=1)\ny_train=training_data['SalePrice'].values\nX_test=test_data","49b828cb":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)","71481864":"from sklearn.model_selection import KFold,cross_val_score\nfrom sklearn.metrics import make_scorer,r2_score\nfrom sklearn.linear_model import Ridge\n\ndef test_model(model, X_train=X_train,y_train=y_train):\n    cv = KFold(n_splits=7,shuffle=True,random_state=42)\n    r2= make_scorer(r2_score)\n    r2_val_score = cross_val_score(model,X_train,y_train,cv=cv,scoring=r2)\n    score= [r2_val_score.mean()]\n    return score","e39cd0e6":"rr = Ridge(normalize=True, alpha = 0.5)\nrr.fit(X_train,y_train)\ntest_model(rr)","3131275b":"from sklearn.tree import DecisionTreeRegressor\ndt = DecisionTreeRegressor(max_depth=8)\ndt.fit(X_train,y_train)\ntest_model(dt)","39b04d3c":"import xgboost\nxgb = xgboost.XGBRegressor(learning_rate=0.05, max_depth=3, random_state=4)\nxgb.fit(X_train,y_train)\ntest_model(xgb)","6ae90171":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(random_state=42)\nrf.fit(X_train,y_train)\ntest_model(rf)","7bf2e177":"**4. Normality of Errors**\n\nI will check for normal distribution, if its skews I'll try to normalize it by log transformation.","3c196234":"#### Decision Tree","f0120e9c":"# **EDA**","0a56089e":"**Null values**\n\nI will concatenate the train and the test together for simpler preprocessing, and afterward I'll calculate the null values by percentages.","3ffa3930":"### Box-Cox Transformation","dda38d33":"For LotFrontage its a bit more tricky. LotFrontage is the linear feet of street connected to the property, if I will replace it by 0 we will damage the data.\nI dont want to drop the column, so I will replace the null values with the median per neighborhood.\n(Credit to niekvanderzwaag for the solution)","e9567cf2":"#### XGBoost","4920ea10":"Given breif about the data:\n\n","93eb4e7e":"Now I have the last features which are categorial, so I will replace the null values by their mode","9b1c7d06":"## Outliers","be3434b6":"There is an obvious right skewness, and so I will apply log transformation","b8002f61":"## Label Encoding","b88e864c":"#### Ridge Regression","f4e57c2e":"Checking if there are remaining null values","b371f3c6":"## Finding Assumptions\n\n**1. Correlation**","34c7e683":"It seems that we have heteroscedasticity. By log transoformation in the next code I'll try to remove it.","1fe5238d":"**Imputing null values**\n\nI will replace the missing values with a relevent value which is given in the description file. For example:\n\n**PoolQC: Pool Quality**\n\n   Ex   Excellent\n   \n   Gd   Good\n   \n   TA   Average\/Typical\n   \n   Fa   Fair\n   \n   NA   No Pool\n   \n   \nIt means I can replace the null values with 'None', and I will do the same with the rest of the features.\n","7daa4da9":"We've achived normality and removed the heteroscedasticity","8f7d7a99":"# Model Building","94e40834":"#### Random Forest","66cff6d6":"# **Importing data**","5bb09417":"Jan 19, 2022\n# Houses Price Prediction\n\nThis is a residential houses database which I used for practice of prediction by using regresson with Python.\n\nSince it is just for practice I would like to mention credits and inspirations:\nhttps:\/\/www.kaggle.com\/niekvanderzwaag\/housing-price-prediction-regression\/notebook\nhttps:\/\/www.kaggle.com\/neesha12\/house-prices-regression\/notebook\n\nI recommend reading ahead the breif or the full data description. \n\nFor convenience here is the breif:\n* SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n* MSSubClass: The building class\n* MSZoning: The general zoning classification\n* LotFrontage: Linear feet of street connected to property\n* LotArea: Lot size in square feet\n* Street: Type of road access\n* Alley: Type of alley access\n* LotShape: General shape of property\n* LandContour: Flatness of the property\n* Utilities: Type of utilities available\n* LotConfig: Lot configuration\n* LandSlope: Slope of property\n* Neighborhood: Physical locations within Ames city limits\n* Condition1: Proximity to main road or railroad\n* Condition2: Proximity to main road or railroad (if a second is present)\n* BldgType: Type of dwelling\n* HouseStyle: Style of dwelling\n* OverallQual: Overall material and finish quality\n* OverallCond: Overall condition rating\n* YearBuilt: Original construction date\n* YearRemodAdd: Remodel date\n* RoofStyle: Type of roof\n* RoofMatl: Roof material\n* Exterior1st: Exterior covering on house\n* Exterior2nd: Exterior covering on house (if more than one material)\n* MasVnrType: Masonry veneer type\n* MasVnrArea: Masonry veneer area in square feet\n* ExterQual: Exterior material quality\n* ExterCond: Present condition of the material on the exterior\n* Foundation: Type of foundation\n* BsmtQual: Height of the basement\n* BsmtCond: General condition of the basement\n* BsmtExposure: Walkout or garden level basement walls\n* BsmtFinType1: Quality of basement finished area\n* BsmtFinSF1: Type 1 finished square feet\n* BsmtFinType2: Quality of second finished area (if present)\n* BsmtFinSF2: Type 2 finished square feet\n* BsmtUnfSF: Unfinished square feet of basement area\n* TotalBsmtSF: Total square feet of basement area\n* Heating: Type of heating\n* HeatingQC: Heating quality and condition\n* CentralAir: Central air conditioning\n* Electrical: Electrical system\n* 1stFlrSF: First Floor square feet\n* 2ndFlrSF: Second floor square feet\n* LowQualFinSF: Low quality finished square feet (all floors)\n* GrLivArea: Above grade (ground) living area square feet\n* BsmtFullBath: Basement full bathrooms\n* BsmtHalfBath: Basement half bathrooms\n* FullBath: Full bathrooms above grade\n* HalfBath: Half baths above grade\n* Bedroom: Number of bedrooms above basement level\n* Kitchen: Number of kitchens\n* KitchenQual: Kitchen quality\n* TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n* Functional: Home functionality rating\n* Fireplaces: Number of fireplaces\n* FireplaceQu: Fireplace quality\n* GarageType: Garage location\n* GarageYrBlt: Year garage was built\n* GarageFinish: Interior finish of the garage\n* GarageCars: Size of garage in car capacity\n* GarageArea: Size of garage in square feet\n* GarageQual: Garage quality\n* GarageCond: Garage condition\n* PavedDrive: Paved driveway\n* WoodDeckSF: Wood deck area in square feet\n* OpenPorchSF: Open porch area in square feet\n* EnclosedPorch: Enclosed porch area in square feet\n* 3SsnPorch: Three season porch area in square feet\n* ScreenPorch: Screen porch area in square feet\n* PoolArea: Pool area in square feet\n* PoolQC: Pool quality\n* Fence: Fence quality\n* MiscFeature: Miscellaneous feature not covered in other categories\n* MiscVal: $Value of miscellaneous feature\n* MoSold: Month Sold\n* YrSold: Year Sold\n* SaleType: Type of sale\n* SaleCondition: Condition of sale","1555eb82":"**2. Linearity**\n\nI've already checked linearity when plotting regression for all columns, and found that most of the plots had linear relationship.\n\n\n**3. Homoscedasticity**\n\nWe can check homoscedasticity by plotting and seeing if the variance of errors is increasing over time."}}