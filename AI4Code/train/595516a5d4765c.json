{"cell_type":{"88605d66":"code","82fe1cfc":"code","325f8530":"code","74d0ddb2":"code","7d90cb78":"code","cd166c50":"code","7a5fb3f2":"code","6eb1cf54":"code","04a02238":"code","e7e878c9":"code","2aa8089b":"code","809db114":"code","d16da962":"code","14c4cd9a":"code","45ca2e2b":"code","8dcccdbb":"code","a0d1ce9e":"code","0449ccde":"code","ffcc2767":"code","9dd151b8":"markdown","9743636b":"markdown","002ae85d":"markdown","ffd8b8ed":"markdown","38319cc7":"markdown","8dc1971d":"markdown","89c81d07":"markdown","753ec66a":"markdown","7bb9cf78":"markdown","656bc38d":"markdown","dcd4e0f4":"markdown"},"source":{"88605d66":"import os\nimport cv2\nimport glob\n\nimport pickle\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n\nfrom kornia.augmentation import RandomAffine, RandomRotation","82fe1cfc":"torch.manual_seed(3407)\nprint(torch.cuda.is_available())","325f8530":"def get_data(file, is_test=False):\n    def _do_csv():\n        data = pd.read_csv(file).to_numpy()\n        if not is_test:\n            lbl, img = data[:, 0], data[:, 1:]\n            img = img.reshape((-1, 28, 28))\n        else:\n            lbl = None\n            img = data.reshape((-1, 28, 28))\n        return img, lbl\n    def _do_pickle():\n        with open(file, 'rb') as fo:\n            qmnist = pickle.load(fo, encoding='bytes')\n        return qmnist[\"data\"], qmnist[\"labels\"].squeeze(-1)\n    if \"csv\" in file:\n        return _do_csv()\n    return _do_pickle()\n\ndef show_data(data, n_rows=5, n_cols=5, figsize=(10, 10)):\n    fig, axs = plt.subplots(n_rows, n_cols, figsize=figsize)\n    for i in range(n_rows):\n        for j in range(n_cols):\n            index = j + i * n_cols\n            axs[i, j].imshow(data[0][index], cmap=\"gray\")\n            axs[i, j].set_title(data[1][index])\n            axs[i, j].axis('off')\n    plt.show()","74d0ddb2":"data = {\n    \"submission\": pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\"),\n    \"test\": get_data(\"..\/input\/digit-recognizer\/test.csv\", is_test=True),\n    \"train_mnist\": get_data(\"..\/input\/digit-recognizer\/train.csv\"),\n    \"train_qmnist\": get_data(\"..\/input\/qmnist-the-extended-mnist-dataset-120k-images\/MNIST-120k\")\n}\n\n\n# image 28x28\nsubmission = data[\"submission\"]\ntrain_mnist = data[\"train_mnist\"]\ntrain_qmnist = data[\"train_qmnist\"]\ntest = data[\"test\"]","7d90cb78":"show_data(train_mnist)","cd166c50":"show_data(train_qmnist)","7a5fb3f2":"train = (np.concatenate([train_mnist[0], train_qmnist[0]], axis=0),\n         np.concatenate([train_mnist[1], train_qmnist[1]], axis=0))","6eb1cf54":"labels, counts = np.unique(train[1], return_counts=True)\nplt.figure(figsize=(15, 7))\nplt.bar(labels, counts)\nplt.grid(axis=\"y\", linestyle=\"--\")\nplt.xticks(labels)\nplt.xlabel(\"label\")\nplt.ylabel(\"num_samples\")\nplt.show()","04a02238":"class MNISTData(Dataset):\n    def __init__(self, data, transforms, is_training=True):\n        self.is_training = is_training\n        self.images, self.labels = data\n        \n        self.transforms = transforms\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        img = torch.from_numpy(self.images[idx]).float()\n        img = img \/ 255.\n        img = img.unsqueeze(0).cuda()\n        if self.is_training:\n            if self.transforms is not None:\n                img = self.transforms(img)\n            lbl = torch.as_tensor(self.labels[idx]).cuda()\n            return (\n                img.squeeze(1), \n                lbl\n            )\n        \n        else:\n            return (\n                img.unsqueeze(0), \n                None\n            )","e7e878c9":"class SimpleModel(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.conv11 = nn.Conv2d(1, 32, 3, padding=0)\n        self.dropout1 = nn.Dropout2d(0.25)\n        self.conv12 = nn.Conv2d(32, 32, 3, padding=0)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.pool1 = nn.MaxPool2d (2)\n        \n        self.conv21 = nn.Conv2d(32, 64, 3, padding=0)\n        self.dropout2 = nn.Dropout2d(0.25)\n        self.conv22 = nn.Conv2d(64, 64, 3, padding=0)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.pool2 = nn.MaxPool2d (2)\n        \n        self.flatten = nn.Flatten()\n        \n        self.relu = nn.ReLU()  # nn.LeakyReLU()\n        self.fc1 = nn.Linear(1024, 256)\n        self.bn3 = nn.BatchNorm1d(256)\n        \n        self.dropout3 = nn.Dropout(0.25) \n        self.fc2 = nn.Linear(256, 10)\n        self.softmax = nn.Softmax(dim=-1)  # nn.LogSoftmax(dim=-1) \n\n        self.loss = nn.NLLLoss() # nn.CrossEntropyLoss()\n        \n        self.log_stack = {\n            \"train\": {\n                \"loss\": dict(),\n                \"acc\": dict()\n            },\n            \"val\": {\n                \"loss\": dict(),\n                \"acc\": dict()\n            }\n        }\n        \n    def forward(self, x):\n        x = self.dropout1(self.relu(self.conv11(x)))\n        x = self.bn1(self.relu(self.conv12(x)))\n        x = self.pool1(x)\n        \n        x = self.dropout2(self.relu(self.conv21(x)))\n        x = self.bn2(self.relu(self.conv22(x)))\n        x = self.pool2(x)\n        \n        x = self.flatten(x)\n        x = self.dropout3(self.bn3(self.relu(self.fc1(x))))\n        x = self.softmax(self.fc2(x))\n        return x\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.RMSprop(\n            self.parameters(), \n            lr=1e-4, weight_decay=0, momentum=0\n        )\n#         optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n#         scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=False)\n        return {\n           'optimizer': optimizer,\n#            'scheduler': scheduler,\n#            'monitor': 'val_loss'\n       }\n    \n    def get_acc(self, y_hat, y):\n        y_hat_class = torch.argmax(y_hat, dim=1)\n        hit = torch.sum(y_hat_class==y)\n        return hit \/ len(y)\n    \n    def add_log(self, phase, metric, data):\n        if self.current_epoch not in self.log_stack[phase][metric]:\n            self.log_stack[phase][metric][self.current_epoch] = [data]\n        else:\n            self.log_stack[phase][metric][self.current_epoch].append(data)\n    \n    def training_step(self, train_batch, batch_idx):\n        x, y = train_batch\n        y_hat = self.forward(x)\n        loss = self.loss(torch.log(y_hat), y)\n        acc = self.get_acc(torch.log(y_hat), y)\n        \n        self.log('train_loss', loss)\n        self.log('train_acc', acc)\n        \n        self.add_log(phase=\"train\", metric=\"loss\", data=loss)\n        self.add_log(phase=\"train\", metric=\"acc\", data=acc)\n        return loss\n    \n    def validation_step(self, val_batch, batch_idx):\n        x, y = val_batch\n        y_hat = self.forward(x)\n        loss = self.loss(torch.log(y_hat), y)\n        acc = self.get_acc(torch.log(y_hat), y)\n        \n        self.log('val_loss', loss)\n        self.log('val_acc', acc)\n        \n        self.add_log(phase=\"val\", metric=\"loss\", data=loss)\n        self.add_log(phase=\"val\", metric=\"acc\", data=acc)\n        return loss\n    \n# check forward\ninp = torch.rand(2, 1, 28, 28).cuda()\nmodel = SimpleModel().cuda()\nout = model(inp)\nprint(out.shape)","2aa8089b":"# transforms = nn.Sequential(\n#     RandomAffine(\n#         p=0.5, \n#         degrees=15,\n#         translate=(0.2, 0.2),\n#         shear=10\n#     )\n# #     RandomRotation(20)\n# )\ntransforms = None\n\nlabeled_data = MNISTData(train, transforms)\n# -----\n\nlen_labeled_data = len(labeled_data)\ntrain_ratio = 0.8\nnum_train_samples = int(len_labeled_data*train_ratio)\nnum_valid_samples = len_labeled_data - num_train_samples\ntrain_data, valid_data = random_split(labeled_data, [num_train_samples, num_valid_samples])\n# -----\n\nbatch_size = 256\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_data, batch_size=batch_size)","809db114":"!rm -rf \/kaggle\/working\/MNIST\/models\nmodel_folder = \"\/kaggle\/working\/MNIST\/models\"\nif not os.path.exists(model_folder):\n    os.makedirs(model_folder)\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor=\"val_acc\",\n    dirpath=model_folder,\n    filename=\"mnist-{epoch:02d}-{val_acc:.5f}\",\n    save_top_k=1,\n    mode=\"max\",\n)","d16da962":"epochs = 20\n\nmodel = SimpleModel().cuda()\ntrainer = pl.Trainer(gpus=1, max_epochs=epochs, callbacks=[checkpoint_callback])\ntrainer.fit(model, train_loader, valid_loader)","14c4cd9a":"! ls \/kaggle\/working\/MNIST\/models","45ca2e2b":"def get_avg(data):\n    result = list()\n    for _, values in data.items():\n        mean = torch.mean(torch.tensor(values))\n        result.append(mean)\n    return result\n\nlog_train = model.log_stack[\"train\"]\nlog_val = model.log_stack[\"val\"]\nfig, axs = plt.subplots(2, 1, figsize=(20, 10))\n\nfor i, metric in enumerate([\"loss\", \"acc\"]):\n    axs[i].plot(get_avg(log_train[metric]), \"-o\",label=\"train\")\n    axs[i].plot(get_avg(log_val[metric]), \"-o\", label=\"val\")\n    axs[i].set_title(metric)\n    axs[i].legend(loc=\"upper left\")\nplt.show()","8dcccdbb":"# load weight\nmodel_path = glob.glob(f\"{model_folder}\/*.ckpt\")[-1]\nprint(\"Loading: \", model_path)\nmodel = SimpleModel.load_from_checkpoint(model_path).cuda()\nmodel.eval()","a0d1ce9e":"test_data = MNISTData(test, None, is_training=False)\n\nfor i, (img, _) in enumerate(test_data):\n    out = model(img)\n    most_likely = int(torch.argmax(out))\n    submission.loc[i, \"Label\"] = most_likely","0449ccde":"k = 200  # starting index\nn_rows = 10\nn_cols = 10\nfig, axs = plt.subplots(n_rows, n_cols, figsize=(20, 20))\n\nfor row in range(n_rows):\n    for col in range(n_cols):\n        idx = k + row * n_cols + col\n        axs[row, col].imshow(test_data.images[idx], cmap=\"gray\")\n        axs[row, col].set_title(f\"pred: {submission['Label'].iloc[idx]}\")\n        axs[row, col].axis(\"off\")\nplt.show()","ffcc2767":"submission.to_csv(\"\/kaggle\/working\/submission.csv\", index=False)","9dd151b8":"### Save submission","9743636b":"### Generate test output","002ae85d":"### Training model","ffd8b8ed":"### Dataloader for MNIST","38319cc7":"### Split train\/valid data","8dc1971d":"### Check result in test-set","89c81d07":"### Get data","753ec66a":"### Libraries","7bb9cf78":"### Utility function","656bc38d":"### Simple model ","dcd4e0f4":"### Concatenate extra data"}}