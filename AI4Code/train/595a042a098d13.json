{"cell_type":{"081da3bc":"code","c917177d":"code","c73939c7":"code","68b8f202":"code","f2ff7839":"code","7d28743f":"code","eb919bf5":"code","7711b049":"code","07531cf7":"code","58669563":"code","555d0a74":"code","da5d944c":"code","9c942739":"code","8f74c264":"code","247a17d2":"code","c9091aae":"code","1f165f33":"code","8eacc4b7":"code","fcc7efb4":"code","0e1925f0":"code","2df0dacf":"code","9a84623f":"code","583366fd":"code","505feb1e":"code","035c5d7f":"code","d3146bef":"markdown","d7e444a9":"markdown","aba11c6c":"markdown","5d6ed77d":"markdown","6463bdad":"markdown","e0f84455":"markdown","15e40393":"markdown","4f2b0b59":"markdown","6fa2907c":"markdown","ac6f4d0e":"markdown","87cd5eb3":"markdown","fe9c81d0":"markdown","4affefb1":"markdown"},"source":{"081da3bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd# data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c917177d":"df=pd.read_csv('\/kaggle\/input\/updated-resume-dataset\/UpdatedResumeDataSet.csv')","c73939c7":"df.head()","68b8f202":"df.tail()","f2ff7839":"df.describe()","7d28743f":"df.info()","eb919bf5":"df['Category'].unique()","7711b049":"plt.figure(figsize=(20,5))\nplt.xticks(rotation=90)\nax=sns.countplot(x=\"Category\", data=df)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nplt.grid()","07531cf7":"from matplotlib.gridspec import GridSpec\ntargetCounts = df['Category'].value_counts()\ntargetLabels  = df['Category'].unique()\n# Make square figures and axes\nplt.figure(1, figsize=(22,22))\nthe_grid = GridSpec(2, 2)\n\n\ncmap = plt.get_cmap('coolwarm')\nplt.subplot(the_grid[0, 1], aspect=1, title='CATEGORY DISTRIBUTION')\n\nsource_pie = plt.pie(targetCounts, labels=targetLabels, autopct='%1.1f%%', shadow=True)\nplt.show()","58669563":"import re\ndef cleanResume(resumeText):\n    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-.\/:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n    return resumeText\n    \ndf['cleaned_resume'] = df.Resume.apply(lambda x: cleanResume(x))","555d0a74":"df.head()","da5d944c":"new_df=df.copy()","9c942739":"import nltk\nfrom nltk.corpus import stopwords\nimport string\nfrom wordcloud import WordCloud","8f74c264":"\noneSetOfStopWords = set(stopwords.words('english')+['``',\"''\"])\ntotalWords =[]\nSentences = df['Resume'].values\ncleanedSentences = \"\"\nfor records in Sentences:\n    cleanedText = cleanResume(records)\n    cleanedSentences += cleanedText\n    requiredWords = nltk.word_tokenize(cleanedText)\n    for word in requiredWords:\n        if word not in oneSetOfStopWords and word not in string.punctuation:\n            totalWords.append(word)\n    \nwordfreqdist = nltk.FreqDist(totalWords)\nmostcommon = wordfreqdist.most_common(50)\nprint(mostcommon)","247a17d2":"wc = WordCloud().generate(cleanedSentences)\nplt.figure(figsize=(16,16))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","c9091aae":"from sklearn.preprocessing import LabelEncoder\n\nvar_mod = ['Category']\nle = LabelEncoder()\nfor i in var_mod:\n    df[i] = le.fit_transform(df[i])","1f165f33":"df.head()","8eacc4b7":"df.Category.value_counts()","fcc7efb4":"new_df.Category.value_counts() #understanding decode LabelEncoder","0e1925f0":"del new_df #clearing the space occupied ","2df0dacf":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.sparse import hstack\n\nrequiredText = df['cleaned_resume'].values\nrequiredTarget = df['Category'].values\n\nword_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    stop_words='english')\nword_vectorizer.fit(requiredText)\nWordFeatures = word_vectorizer.transform(requiredText)\n\nprint (\"Feature completed .....\")\n","9a84623f":"\nX_train,X_test,y_train,y_test = train_test_split(WordFeatures,requiredTarget,random_state=1, test_size=0.2,shuffle=True, stratify=requiredTarget)\nprint(X_train.shape)\nprint(X_test.shape)","583366fd":"import warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics","505feb1e":"clf = OneVsRestClassifier(KNeighborsClassifier())\nclf.fit(X_train, y_train)\nprediction = clf.predict(X_test)\nprint('Accuracy of KNeighbors Classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\nprint('Accuracy of KNeighbors Classifier on test set:     {:.2f}'.format(clf.score(X_test, y_test)))","035c5d7f":"print(\"\\n Classification report for classifier %s:\\n%s\\n\" % (clf, metrics.classification_report(y_test, prediction)))","d3146bef":"# Check head and tail of the dataset","d7e444a9":"# Now Ploting","aba11c6c":"# Now Check Model Score","5d6ed77d":"# Now Label Encoding","6463bdad":"# Now Fit and Prediict the model","e0f84455":"# Now Train test split and fit transform","15e40393":"# Now Import Important Libs","4f2b0b59":"# Now Import Nltk lib","6fa2907c":"# Thanks for read my notebook holofully its help full Please upvote it and support me.\n","ac6f4d0e":"# Now Copy the dataset","87cd5eb3":"# Now EDA Part","fe9c81d0":"# Now Check Uniques catageory ","4affefb1":"# Now Cleaning the df[Category] part"}}