{"cell_type":{"29c63156":"code","e6c9083c":"code","6543c5f7":"code","fbc23948":"code","95953fb2":"code","8c5cdde2":"code","4bd28144":"code","b3cd7ea7":"code","8a3368da":"code","7d211ab8":"code","ea3ba8aa":"code","60981605":"code","7fbc2f06":"code","f8715a0c":"code","bcea72e1":"code","b61265bd":"code","f7f7aa99":"code","50641f65":"code","7ef4cbbe":"code","518b68bf":"code","ef3668c9":"markdown","5b16ac79":"markdown","81e3505d":"markdown","85fb0aba":"markdown"},"source":{"29c63156":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch,re\nfrom tensorflow import image as timage\nfrom torchvision.datasets import CIFAR10 as tcifar10\nfrom torchvision import transforms,utils\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nfrom torch.utils.data.dataset import Subset\nimport torch.nn as tnn\nimport torch.utils.checkpoint as tcp\nfrom collections import OrderedDict as od\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")","e6c9083c":"class TData(tds):\n    def __init__(self,X,y):   \n        self.X=torch.tensor(X,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        train_img,train_lbl=self.X[index],self.y[index]\n        return train_img,train_lbl\n    def __len__(self):\n        return self.y.shape[0]","6543c5f7":"def load_h5py(path,img_size):\n    f=h5py.File(path,'r')\n    keys=list(f.keys()); print(keys)\n    x=np.array(f[keys[1]],dtype='float32')\/255\n    x=x.reshape(-1,3,img_size,img_size)\n    y=np.array(f[keys[2]],dtype='int32')-1\n    N=len(y); n=int(.2*N)\n    shuffle_ids=np.arange(N)\n    np.random.RandomState(23).shuffle(shuffle_ids)\n    x,y=x[shuffle_ids],y[shuffle_ids]\n    x_test,x_valid,x_train=x[:n],x[n:2*n],x[2*n:]\n    y_test,y_valid,y_train=y[:n],y[n:2*n],y[2*n:]\n    df=pd.DataFrame([[x_train.shape,x_valid.shape,x_test.shape],\n                     [x_train.dtype,x_valid.dtype,x_test.dtype],\n                     [y_train.shape,y_valid.shape,y_test.shape],\n                     [y_train.dtype,y_valid.dtype,y_test.dtype]],\n                    columns=['train','valid','test'],\n                    index=['image shape','image type',\n                           'label shape','label type'])\n    display(df)    \n    return [[x_train,x_valid,x_test],\n            [y_train,y_valid,y_test]]","fbc23948":"def display_examples(data_loader,img_size):\n    for images,labels in data_loader:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        fig=pl.figure(figsize=(11,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=labels[i].item())\n            ax.imshow((images[i]).reshape(img_size,img_size,3))\n        break\ndef show_image(img):\n    npimg=img.numpy()\/2.+.5; tr=(1,2,0)\n    pl.figure(figsize=(10,2))\n    pl.imshow(np.transpose(npimg,tr))\n    pl.xticks([]); pl.show()\ndef show_examples(data_loader,classes,num_examples):\n    dataiter=iter(data_loader)\n    images,labels=dataiter.next()\n    show_image(utils.make_grid(images[0:num_examples]))\n    print('^'.join('%9s'%classes[labels[j]] \n                   for j in range(num_examples)),end='^')","95953fb2":"def model_acc(model,data_loader):\n    model.eval()\n    correct_preds,num_examples=0,0    \n    for features,targets in data_loader:\n        features=features.to(dev)\n        targets=targets.to(dev)\n        logits,probs=model(features)\n        _,pred_labels=torch.max(probs,1)\n        num_examples+=targets.size(0)\n        correct_preds+=(pred_labels==targets).sum()        \n    return correct_preds.float()\/num_examples*100\n@register_line_magic\ndef print_acc(n):\n    if int(n)==1:\n        data_loader=\\\n        [train_loader,valid_loader,test_loader]\n    if int(n)==2:\n        data_loader=\\\n        [train_loader2,valid_loader2,test_loader2]\n    print('Train accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[0])))\n    print('Valid accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[1])))\n    print('Test accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[2])))","8c5cdde2":"random_seed=12; batch_size=128\ntrain_ids=torch.arange(0,44000)\nvalid_ids=torch.arange(44000,50000)\ntr0=(.5,.5,.5)\ntransform=transforms\\\n.Compose([transforms.ToTensor(),\n          transforms.Normalize(tr0,tr0)])\ntrain_valid=tcifar10(root='data',transform=transform,\n                     download=True,train=True)\ntrain=Subset(train_valid,train_ids)\nvalid=Subset(train_valid,valid_ids)\ntest=tcifar10(root='data',train=False, \n              transform=transform)\ntrain_loader=tdl(dataset=train,shuffle=True, \n                 batch_size=batch_size)\nvalid_loader=tdl(dataset=valid,shuffle=True, \n                 batch_size=batch_size)\ntest_loader=tdl(dataset=test,shuffle=False, \n                batch_size=batch_size)","4bd28144":"classes=('plane','car','bird','cat','deer',\n         'dog','frog','horse','ship','truck')\nshow_examples(valid_loader,classes,7)","b3cd7ea7":"fpath='..\/input\/classification-of-handwritten-letters\/'\nf='LetterColorImages_123.h5'\n[[x_train,x_valid,x_test],\n [y_train,y_valid,y_test]]=\\\nload_h5py(fpath+f,32)","8a3368da":"random_seed=23; batch_size2=128\ntrain2=TData(x_train,y_train)\nvalid2=TData(x_valid,y_valid)\ntest2=TData(x_test,y_test)\ntrain_loader2=tdl(dataset=train2,\n                  batch_size=batch_size2,shuffle=True)\nvalid_loader2=tdl(dataset=valid2,\n                  batch_size=batch_size2,shuffle=True)\ntest_loader2=tdl(dataset=test2,\n                 batch_size=batch_size2,shuffle=False)\ndisplay_examples(valid_loader2,32)","7d211ab8":"def _bn_function_call(norm,relu,conv):\n    def bn_function(*inputs):\n        concated_features=torch.cat(inputs,1)\n        bottleneck_output=conv(relu(norm(concated_features)))\n        return bottleneck_output\n    return bn_function\nclass _DenseLayer(tnn.Sequential):\n    def __init__(self,num_input_features,growth_rate,\n                 bn_size,drop_rate,memory_efficient=False):\n        super(_DenseLayer,self).__init__()\n        self.add_module('norm1',\n                        tnn.BatchNorm2d(num_input_features)),\n        self.add_module('relu1',tnn.ReLU(inplace=True)),\n        self.add_module('conv1',\\\n        tnn.Conv2d(num_input_features,bn_size*growth_rate,\n                   kernel_size=1,stride=1,bias=False)),\n        self.add_module('norm2',\n                        tnn.BatchNorm2d(bn_size*growth_rate)),\n        self.add_module('relu2',tnn.ReLU(inplace=True)),\n        self.add_module('conv2',\\\n        tnn.Conv2d(bn_size*growth_rate,growth_rate,\n                   kernel_size=3,stride=1,\n                   padding=1,bias=False)),\n        self.drop_rate=drop_rate\n        self.memory_efficient=memory_efficient\n    def forward(self,*prev_features):\n        bn_function=_bn_function_call(self.norm1,\n                                      self.relu1,self.conv1)\n        if self.memory_efficient and \\\n        any(prev_feature.requires_grad \\\n            for prev_feature in prev_features):\n            bottleneck_output=tcp.checkpoint(bn_function,*prev_features)\n        else:\n            bottleneck_output=bn_function(*prev_features)\n        new_features=self.conv2(self.relu2(\n            self.norm2(bottleneck_output)))\n        if self.drop_rate>0:\n            new_features=tnn.functional.dropout(new_features,\\\n            p=self.drop_rate,training=self.training)\n        return new_features","ea3ba8aa":"class _DenseBlock(tnn.Module):\n    def __init__(self,num_layers,num_input_features,\n                 bn_size, growth_rate,drop_rate,\n                 memory_efficient=False):\n        super(_DenseBlock,self).__init__()\n        for i in range(num_layers):\n            layer=_DenseLayer(\n                num_input_features+i*growth_rate,\n                growth_rate=growth_rate,\n                bn_size=bn_size,drop_rate=drop_rate,\n                memory_efficient=memory_efficient)\n            self.add_module('denselayer%d'%(i+1),layer)\n    def forward(self,init_features):\n        features=[init_features]\n        for name,layer in self.named_children():\n            new_features=layer(*features)\n            features.append(new_features)\n        return torch.cat(features,1)\nclass _Transition(tnn.Sequential):\n    def __init__(self,num_input_features,num_output_features):\n        super(_Transition,self).__init__()\n        self.add_module('norm',\n                        tnn.BatchNorm2d(num_input_features))\n        self.add_module('relu',tnn.ReLU(inplace=True))\n        self.add_module('conv',\\\n        tnn.Conv2d(num_input_features,num_output_features,\n                   kernel_size=1,stride=1,bias=False))\n        self.add_module('pool',\n                        tnn.AvgPool2d(kernel_size=2,stride=2))   ","60981605":"class DenseNN121(tnn.Module):\n    def __init__(self,growth_rate=32,block_config=(6,12,24,16),\n                 num_init_featuremaps=64,bn_size=4,drop_rate=0,\n                 num_classes=1000,memory_efficient=False,\n                 grayscale=False):\n        super(DenseNN121,self).__init__()\n        if grayscale: in_channels=1\n        else: in_channels=3       \n        self.features=tnn.Sequential(od([\n            ('conv0',tnn.Conv2d(in_channels=in_channels,\n                                out_channels=num_init_featuremaps,\n                                kernel_size=7,stride=2,\n                                padding=3,bias=False)),\n            ('norm0',tnn.BatchNorm2d(num_features=num_init_featuremaps)),\n            ('relu0',tnn.ReLU(inplace=True)),\n            ('pool0',tnn.MaxPool2d(kernel_size=3,stride=2,padding=1))]))\n        num_features=num_init_featuremaps\n        for i,num_layers in enumerate(block_config):\n            block=_DenseBlock(\n                num_layers=num_layers,\n                num_input_features=num_features,\n                bn_size=bn_size,drop_rate=drop_rate,\n                growth_rate=growth_rate,\n                memory_efficient=memory_efficient)\n            self.features.add_module('denseblock%d'%(i+1),block)\n            num_features=num_features+num_layers*growth_rate\n            if i!=len(block_config)-1:\n                trans=_Transition(num_input_features=num_features,\n                                  num_output_features=num_features\/\/2)\n                self.features.add_module('transition%d'%(i+1),trans)\n                num_features=num_features\/\/2\n        self.features.add_module('norm5',tnn.BatchNorm2d(num_features))\n        self.classifier=tnn.Linear(num_features,num_classes)\n        for m in self.modules():\n            if isinstance(m,tnn.Conv2d):\n                tnn.init.kaiming_normal_(m.weight)\n            elif isinstance(m,tnn.BatchNorm2d):\n                tnn.init.constant_(m.weight,1)\n                tnn.init.constant_(m.bias,0)\n            elif isinstance(m,tnn.Linear):\n                tnn.init.constant_(m.bias,0)\n    def forward(self,x):\n        y=self.features(x)\n        y=tnn.functional.relu(y,inplace=True)\n        y=tnn.functional.adaptive_avg_pool2d(y,(1,1))\n        y=torch.flatten(y,1)\n        logits=self.classifier(y)\n        probs=tnn.functional.softmax(logits,dim=1)\n        return logits,probs","7fbc2f06":"random_seed=34; num_classes=10\nlearning_rate=.001; grayscale=False\nmodel=DenseNN121(num_classes=num_classes,\n                 grayscale=grayscale)\nmodel.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),\n                           lr=learning_rate) ","f8715a0c":"@register_line_magic\ndef train_run(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        model.train()\n        for batch_ids,(features,targets) in enumerate(train_loader):        \n            features=features.to(dev); targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnn.functional.cross_entropy(logits,targets)\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%100:\n                print ('Epoch: %03d\/%03d | Batch %03d\/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train)\/\/batch_size,cost))\n        model.eval()         \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d\/%03d train acc: %.2f%% valid acc: %.2f%%'%\\\n                  (epoch+1,epochs,\n                   model_acc(model,train_loader),\n                   model_acc(model,valid_loader)))","bcea72e1":"%train_run 20","b61265bd":"%print_acc 1","f7f7aa99":"random_seed=45; num_classes=33\nlearning_rate=.001; grayscale=False\nmodel=DenseNN121(num_classes=num_classes,\n                 grayscale=grayscale)\nmodel.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),\n                           lr=learning_rate) ","50641f65":"@register_line_magic\ndef train_run2(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        model.train()\n        for batch_ids,(features,targets) in enumerate(train_loader2):        \n            features=features.to(dev); targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnn.functional.cross_entropy(logits,targets.long())\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%50:\n                print ('Epoch: %03d\/%03d | Batch %03d\/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train2)\/\/batch_size2,cost))\n        model.eval()         \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d\/%03d train acc: %.2f%% valid acc: %.2f%%'%\\\n                  (epoch+1,epochs,\n                   model_acc(model,train_loader2),\n                   model_acc(model,valid_loader2)))","7ef4cbbe":"%train_run2 30","518b68bf":"%print_acc 2","ef3668c9":"## DenseNet","5b16ac79":"Reading classics [Deep Learning Models](https:\/\/nbviewer.jupyter.org\/github\/rasbt\/deeplearning-models\/blob\/master\/pytorch_ipynb\/cnn\/cnn-densenet121-mnist.ipynb)\n\nCode Modules, Classes & Functions","81e3505d":"## Training","85fb0aba":"## Data"}}