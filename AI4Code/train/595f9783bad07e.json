{"cell_type":{"47581a77":"code","d8c20e19":"code","106aef2c":"code","ed141eb2":"code","e34bc817":"code","9daf726e":"code","9fb7e647":"code","a3e96b65":"code","043bc34d":"code","58b55d5f":"markdown","4122dc4a":"markdown","bdf27b69":"markdown","dc142fa2":"markdown","6d1f9387":"markdown"},"source":{"47581a77":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom keras.preprocessing import image\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.applications.vgg19 import VGG19\nfrom keras.layers import Dense, Flatten\nfrom sklearn.model_selection import train_test_split","d8c20e19":"#prepare a list of image files to be loaded\ndef image_files(input_directory):\n    filepaths=[]\n    labels=[]\n    \n    digit_folders=os.listdir(input_directory)\n    #print(digit_folders)\n    \n    for digit in digit_folders:\n        path=os.path.join(input_directory, digit)\n        flist=os.listdir(path)\n        for f in flist:\n            fpath=os.path.join(path,f)        \n            filepaths.append(fpath)\n            labels.append(digit) \n    return filepaths,labels\n\ndef load_images(filepaths):\n    images = []\n    for i in tqdm(range(len(filepaths))):\n        img = image.load_img(filepaths[i], target_size=(32,32,3), grayscale=False)\n        img = image.img_to_array(img)\n        img.astype('float32')\n        img = img\/255\n        images.append(img)\n\n    images = np.array(images)\n    return images","106aef2c":"#load the paths and labels in differnt variables\ndirectory_10k = \"\/kaggle\/input\/didadataset\/10000\/10000\"\nfilepaths,labels = image_files(directory_10k)","ed141eb2":"#load the 10K images\nimages = load_images(filepaths)","e34bc817":"y = to_categorical(labels,num_classes=10)\nX_train, X_test, y_train, y_test = train_test_split(images, y, random_state=42, test_size=0.2)\n\nprint(X_train.shape)\nprint(X_test.shape)","9daf726e":"vgg19 = VGG19(weights = 'imagenet', \n              include_top = False,\n              input_shape=(32, 32, 3)\n              )\n\nmodel = Sequential()\nmodel.add(vgg19)\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', \n              optimizer='sgd', \n              metrics=['accuracy'])\n\nmodel.summary()","9fb7e647":"history = model.fit(X_train, y_train, \n                    epochs=20, \n                    batch_size=128, \n                    validation_data=(X_test, y_test)\n                    )","a3e96b65":"score = model.evaluate(X_test, y_test)\nprint(score)","043bc34d":"fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n\naxes[0].plot(history.history['accuracy'])\naxes[0].plot(history.history['val_accuracy'])\naxes[0].set_title('Model Accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['train', 'validation'], loc='upper left')\n\naxes[1].plot(history.history['loss'])\naxes[1].plot(history.history['val_loss'])\naxes[1].set_title('Model Loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['train', 'validation'], loc='upper left')\n\nplt.show()","58b55d5f":"## Evaluate the model performance","4122dc4a":"## Split the dataset for training and validating","bdf27b69":"# Handwritten Digit recognition with VGG19 and DIDA\nIn this notebook, I would like to show simply how the DIDA dataset could be used to train a pre-trained VGG19 model to recognize handwritten digits. This is a very basic implementation.","dc142fa2":"## Load the images from the dataset","6d1f9387":"## Train the model"}}