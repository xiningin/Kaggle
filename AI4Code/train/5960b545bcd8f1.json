{"cell_type":{"d9770c6e":"code","ed66a93c":"code","bcf524c3":"code","4203ef77":"code","0ca08f10":"code","41676962":"code","f85327d0":"code","52d4a260":"code","7e8644f4":"code","7c1611be":"code","e7c50554":"code","d5bb3b9e":"code","3bd2f185":"code","6106b8cc":"code","af989d85":"code","17be6868":"code","54f85b14":"code","cebea7c1":"code","cdc6f4d8":"code","3df3466f":"code","da06e574":"code","060affe8":"code","6bde343e":"code","08aec653":"code","1bed0e09":"code","89f29e0c":"code","49877618":"code","bf11d51a":"code","a6f46742":"code","b3d633b0":"code","4d3504f9":"code","7068a147":"code","0a10b571":"code","ec84bb7b":"code","47746c97":"code","f8a0e6e8":"code","ab8f30ce":"code","f57efc20":"code","05630d8e":"code","fee03ae9":"code","dd0b9dcd":"code","84a622a6":"code","2ebdb007":"code","5a3d3f20":"code","b9ff36c4":"code","09199bc2":"markdown","bfec1df3":"markdown","0435d153":"markdown","eb81eea0":"markdown","e143fc7e":"markdown","7a9b5f16":"markdown","ac1d5d9d":"markdown","6a52787c":"markdown","0f2609e7":"markdown","99695089":"markdown","988be9c6":"markdown","0466046c":"markdown","aed51394":"markdown","fecd28cb":"markdown","fb6dcd0b":"markdown","e40c3696":"markdown","4a4cdd20":"markdown","01c603b7":"markdown","8564341e":"markdown","fa9549d4":"markdown","669bcb39":"markdown","c820b15f":"markdown","8a9f3dae":"markdown","587e5f08":"markdown","c93de9b4":"markdown","bb16231d":"markdown","05d82105":"markdown","9f2abfbd":"markdown","e0162869":"markdown","2c7e0b1e":"markdown","d4ed96f1":"markdown","7b20846c":"markdown","1ac4d5bf":"markdown","2fe05b1d":"markdown","68804acd":"markdown","bcdc48c1":"markdown"},"source":{"d9770c6e":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))\n\n\nSentence_1 = 'Today is Friday'\nSentence_2 = 'Tomorrow is Saturday'\nSentence_3 = 'Day After Tomorrow is Sunday'\n\nprint(jaccard(Sentence_1,Sentence_2))\nprint(jaccard(Sentence_1,Sentence_3))\nprint(jaccard(Sentence_2,Sentence_3))","ed66a93c":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\n\n#!pip install chart_studio\n#!pip install textstat\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# text processing libraries\nimport re #regular expression\nimport string #strings manipulation\nimport nltk #natural language toolkit\nfrom nltk.corpus import stopwords #stopwords\nfrom tqdm import tqdm\nimport spacy\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\n\n# Visualisation libraries\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly.offline import iplot\nfrom collections import Counter\nfrom string import *\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\n\n# sklearn \nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n\n# File system manangement\nimport os\n\n# Pytorch\nimport torch\n\n#Transformers\nfrom transformers import BertTokenizer\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport random","bcf524c3":"train = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')","4203ef77":"print(train.shape)\nprint(test.shape)","0ca08f10":"train.info()","41676962":"test.info()","f85327d0":"train.head()","52d4a260":"train.describe()","7e8644f4":"train['sentiment'].value_counts()","7c1611be":"train['NoOfSelectedTextWords'] = train['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ntrain['NoOfTextWords'] = train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\ntrain['DiffOfTextWordsToSelectedTextWords'] = train['NoOfTextWords'] - train['NoOfSelectedTextWords'] #Difference in Number of words text and Selected Text","e7c50554":"train.head()","d5bb3b9e":"def clean_text(text):\n    '''Convert text to lowercase,remove punctuation, remove words containing numbers, ,remove links and remove text in square brackets,.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    return text","3bd2f185":"train['text'] = train['text'].apply(lambda x:clean_text(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))","6106b8cc":"train.head()","af989d85":"train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())","17be6868":"def remove_stopword(x):\n    return [y for y in x if y not in stopwords.words('english')]\ntrain['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))","54f85b14":"top = Counter([item for sublist in train['temp_list'] for item in sublist])\ndf = pd.DataFrame(top.most_common(20))\ndf = df.iloc[1:,:]\ndf.columns = ['commonwords','count']\ndf.style.background_gradient(cmap='Purples')","cebea7c1":"def text_preprocessing(text):\n    \"\"\"\n    Parsing the text and removing stop words.\n\n    \"\"\"\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    #remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n    combined_text = ' '.join(tokenized_text)\n    return combined_text","cdc6f4d8":"positive_text = train[train['sentiment'] == 'positive']['selected_text']\nnegative_text = train[train['sentiment'] == 'negative']['selected_text']\nneutral_text = train[train['sentiment'] == 'neutral']['selected_text']","3df3466f":"positive_text_clean = positive_text.apply(lambda x: text_preprocessing(x))\nnegative_text_clean = negative_text.apply(lambda x: text_preprocessing(x))\nneutral_text_clean = neutral_text.apply(lambda x: text_preprocessing(x))","da06e574":"train['sentiment'].value_counts().iplot(kind='bar',yTitle='Percentage', \n                                                      linecolor='black', \n                                                      opacity=0.7,\n                                                      color='red',\n                                                      theme='pearl',\n                                                      bargap=0.6,\n                                                      gridcolor='white',\n                                                      title='Distribution of Sentiment column from the train dataset')","060affe8":"test['sentiment'].value_counts().iplot(kind='bar',yTitle='Percentage', \n                                                      linecolor='black', \n                                                      opacity=0.7,\n                                                      color='green',\n                                                      theme='pearl',\n                                                      bargap=0.6,\n                                                      gridcolor='white',\n                                                      title='Distribution  of Sentiment column from the test dataset')","6bde343e":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.rcParams['text.color'] = 'black'\nplt.pie(df['count'], labels=df['commonwords'], colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('commonwords')\nplt.show()","08aec653":"from wordcloud import WordCloud\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[30, 15])\n# Positive sentiment visualizing\nwordcloud1 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(positive_text_clean))\nax1.imshow(wordcloud1)\nax1.axis('off')\nax1.set_title('Positive text',fontsize=40);\n\n# Negative sentiment visualizing\nwordcloud2 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(negative_text_clean))\nax2.imshow(wordcloud2)\nax2.axis('off')\nax2.set_title('Negative text',fontsize=40);\n\n# Neutral sentiment visualizing\nwordcloud3 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(neutral_text_clean))\nax3.imshow(wordcloud3)\nax3.axis('off')\nax3.set_title('Neutral text',fontsize=40);","1bed0e09":"from plotly import graph_objs as go\n\nfig = go.Figure(go.Funnelarea(\n    text =train['sentiment'].value_counts().index,\n    values = train['sentiment'].value_counts().values,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n    ))\nfig.show()","89f29e0c":"import plotly.express as px\nfig = px.violin(train, y=\"NoOfSelectedTextWords\", color=\"sentiment\",\n                violinmode='overlay', # draw violins on top of each other\n                # default violinmode is 'group' as in example above\n                hover_data=train)\nfig.show()","49877618":"import seaborn as sns\nplt.figure(figsize=(12,6))\np1=sns.kdeplot(train['NoOfSelectedTextWords'], shade=True, color=\"r\").set_title('Kernel Distribution of Number Of words')\np1=sns.kdeplot(train['NoOfTextWords'], shade=True, color=\"b\")","bf11d51a":"import plotly.express as px\nfig = px.treemap(df, path=['commonwords'], values='count',title='Tree of Most Common Words')\nfig.show()","a6f46742":"fig = px.bar(df, x=\"count\", y=\"commonwords\", title='Commmon Words in Text', orientation='h', width=700, height=700, color='commonwords')\nfig.show()","b3d633b0":"sns.jointplot(x=train['NoOfTextWords'], y=train['NoOfSelectedTextWords'], kind=\"kde\")","4d3504f9":"import plotly.express as px\n#df = px.data.iris()\nfig = px.scatter(train, x=\"NoOfTextWords\", y=\"NoOfSelectedTextWords\", color=\"sentiment\",\n                 size='DiffOfTextWordsToSelectedTextWords', hover_data=train)\nfig.show()","7068a147":"import plotly.express as px\nfig = px.histogram(train, x=\"NoOfTextWords\", y=\"NoOfSelectedTextWords\", color=\"sentiment\", marginal=\"rug\",\n                   hover_data=train)\nfig.show()","0a10b571":"from nltk import FreqDist\n\nfdist=FreqDist()\n\nfor word in train['selected_text'].values:\n    fdist[word.lower()]+=1\nfdist_top20=fdist.most_common(20)\ndf = pd.DataFrame(fdist_top20, columns =['commonwords', 'count']) ","ec84bb7b":"df_train = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\ndf_submission = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')","47746c97":"df_train['Num_words_text'] = df_train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set","f8a0e6e8":"df_train = df_train[df_train['Num_words_text']>=3]","ab8f30ce":"def save_model(output_dir, nlp, new_model_name):\n    ''' This Function Saves model to \n    given output directory'''\n    \n    output_dir = f'..\/working\/{output_dir}'\n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)","f57efc20":"def train(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    \"\"\n    if model is not None:\n        nlp = spacy.load(output_dir)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    \n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n    \n    # add labels\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        if model is None:\n            nlp.begin_training()\n        else:\n            nlp.resume_training()\n\n\n        for itn in tqdm(range(n_iter)):\n            random.shuffle(train_data)\n            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts,  # batch of texts\n                            annotations,  # batch of annotations\n                            drop=0.5,   # dropout - make it harder to memorise data\n                            losses=losses, \n                            )\n            print(\"Losses\", losses)\n    save_model(output_dir, nlp, 'st_ner')","05630d8e":"def get_model_out_path(sentiment):\n    '''\n    Returns Model output path\n    '''\n    model_out_path = None\n    if sentiment == 'positive':\n        model_out_path = 'models\/model_pos'\n    elif sentiment == 'negative':\n        model_out_path = 'models\/model_neg'\n    return model_out_path","fee03ae9":"def get_training_data(sentiment):\n    '''\n    Returns Trainong data in the format needed to train spacy NER\n    '''\n    train_data = []\n    for index, row in df_train.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.selected_text\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n    return train_data","dd0b9dcd":"sentiment = 'positive'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n#print(train_data)\n# For Demo Purposes I have taken 3 iterations you can train the model as you want\ntrain(train_data, model_path, n_iter=3, model=None)","84a622a6":"sentiment = 'negative'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n\ntrain(train_data, model_path, n_iter=3, model=None)","2ebdb007":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","5a3d3f20":"selected_texts = []\nMODELS_BASE_PATH = '..\/working\/models\/'\n\nif MODELS_BASE_PATH is not None:\n    print(\"Loading Models  from \", MODELS_BASE_PATH)\n    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n    model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n        \n    for index, row in df_test.iterrows():\n        text = row.text\n        output_str = \"\"\n        if row.sentiment == 'neutral' or len(text.split()) <= 2:\n            selected_texts.append(text)\n        elif row.sentiment == 'positive':\n            selected_texts.append(predict_entities(text, model_pos))\n        else:\n            selected_texts.append(predict_entities(text, model_neg))\n        \ndf_test['selected_text'] = selected_texts","b9ff36c4":"df_submission['selected_text'] = df_test['selected_text']\ndf_submission.to_csv(\"submission.csv\", index=False)\ndisplay(df_submission.head(10))","09199bc2":"## Data Visualization : Tree Map [plotly library]","bfec1df3":"## Data Visualization : Pie Chart [Matplotlib Library]","0435d153":"## Data Visualization : Funnel Graph [plotly library]","eb81eea0":"# Data Visualization :Scatter plot[plotly Library]","e143fc7e":"## Counting of words from columns 'selected_text','text' and creating new columns - 'NoOfSelectedTextWords', 'NoOfTextWords'","7a9b5f16":"## Data Visualization : Kernel Distribution [Seaborn library]","ac1d5d9d":"## Seperating text to it's sentiment type ","6a52787c":"### Calling the function to apply on the columns - text and selected_text","0f2609e7":"### Function for cleaning text","99695089":"## Number of positive, negative and neutral sentiments from training dataset","988be9c6":"# Data Visualization : joint plot[Seaborn Library]","0466046c":"# Data Visualization : Horizontal Bar Chart [plotly library]","aed51394":"## Number of rows and Number of columns present in dataset","fecd28cb":"## Statistical Information of training dataset","fb6dcd0b":"## Objective\n\nSentiment analysis is a common use case of NLP where the idea is to classify the tweet as positive, negative or neutral depending upon the text in the tweet. This problem goes a way ahead and expects us to also determine the words in the tweet which decide the polarity of the tweet.\n\n## Understanding the Evaluation Metric\n\nThe metric in this competition is the word-level **Jaccard score**. Jaccard Score is a measure of how similar\/dissimilar two sets are.  The higher the score, the more similar the two strings. The idea is to find the number of common tokens and divide it by the total number of unique tokens. Its expressed in the mathematical terms by,\n\n![](https:\/\/imgur.com\/lMHa8CL.png)\n\n![](https:\/\/images.deepai.org\/glossary-terms\/jaccard-index-391304.jpg)","e40c3696":"## Importing the required libraries","4a4cdd20":"# Data Visualization :Histogram Graph[plotly Library]","01c603b7":"## Checking the new columns by viewing top 5 rows","8564341e":"## Cleaning data with .apply() Function[pandas library]","fa9549d4":"## Top 5 Rows from the training dataset","669bcb39":"# Data Visualization :Violin Graph[plotly Library]","c820b15f":"## Frequncy Distribution on selected_text columns of training dataset","8a9f3dae":"## Viewing the top 5 rows","587e5f08":"## Training Dataset Information","c93de9b4":"### WordCloud of all 3 sentiments - Neutral, Positive and Negative Sentiments","bb16231d":"## Tokenization","05d82105":"## Jaccard Metric","9f2abfbd":"## Testing Dataset Information","e0162869":"## Removing the Stopwords from the text","2c7e0b1e":"## Cleaning Text","d4ed96f1":"## Data Visualization of Testing dataset","7b20846c":"## splitting each word in selected_text[Target class]","1ac4d5bf":"## Reading Data ","2fe05b1d":"## Counting the most common words from the Text","68804acd":"## Data Visualization of Training dataset","bcdc48c1":"## Data Visualization : WordCloud [wordcloud library]"}}