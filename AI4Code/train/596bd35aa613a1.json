{"cell_type":{"791cee48":"code","ef3818da":"code","7f2af2fb":"code","3bcc7fc9":"code","66b1dc96":"code","080139ad":"code","3ca7a42d":"code","40d3a157":"code","dc0b8412":"code","2d1eccb6":"code","45f4cfb3":"code","53205f0c":"code","3495ab0a":"code","ff686bba":"code","73b55cd7":"code","56ce1491":"code","a1d3a8c4":"code","bcaefece":"code","e941e978":"code","8e7d73fa":"code","4eed5cfb":"code","92a9aff6":"code","3b5b6647":"code","91e8ca8a":"code","77278a54":"code","e3de2bb8":"code","5555839c":"code","d97d3a59":"code","7151584a":"code","bfd7864a":"markdown"},"source":{"791cee48":"#loading_all libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import RandomizedSearchCV\nimport matplotlib.pylab as pylab\nfrom pandas import get_dummies\nimport xgboost as xgb\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport warnings\nimport sklearn\nimport scipy\nimport numpy\nimport sys\nimport csv\nimport os","ef3818da":"warnings.filterwarnings('ignore')\n%matplotlib inline","7f2af2fb":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","3bcc7fc9":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","66b1dc96":"df_train=pd.read_csv('\/kaggle\/input\/insurance\/insurance.csv')","080139ad":"df_train.head()","3ca7a42d":"#function for missing data\ndef missing_data(df_train):\n    total = df_train.isnull().sum().sort_values(ascending=False)\n    percent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return(missing_data.head(20))","40d3a157":"missing_data(df_train)","dc0b8412":"df_train['children']=df_train['children'].astype('object')","2d1eccb6":"df_train.dtypes","45f4cfb3":"encoded=pd.get_dummies(df_train)","53205f0c":"encoded.head()","3495ab0a":"dependent_all=encoded['charges']\nindependent_all=encoded.drop(['charges'],axis=1)","ff686bba":"x_train,x_test,y_train,y_test=train_test_split(independent_all,dependent_all,test_size=0.3,random_state=100)","73b55cd7":"linregr = LinearRegression()\nlinregr.fit(x_train, y_train)\npred_linreg = linregr.predict(x_train)","56ce1491":"print(\"accuracy score for train using linearregression is\",linregr.score(x_train,y_train))\nprint(\"accuracy score for test using linearregression is\",linregr.score(x_test,y_test))","a1d3a8c4":"mae_train = mean_absolute_error(linregr.predict(x_train),y_train)\nprint('Mae on train using linearregression :',mae_train)\nmae_test = mean_absolute_error(linregr.predict(x_test),y_test)\nprint('Mae on test using linearregression :',mae_test)\n\nmse_train = mean_squared_error(linregr.predict(x_train),y_train)\nprint('Mse on train using linearregression :',mse_train)\nmse_test = mean_squared_error(linregr.predict(x_test),y_test)\nprint('Mse on test using linearregression :',mse_test)","bcaefece":"#random Forest\nrfr = RandomForestRegressor(n_estimators=100)\nrfr.fit(x_train,y_train)\npredicted = rfr.predict(x_train)","e941e978":"print(\"accuracy score for train using randomforest\",rfr.score(x_train,y_train))\nprint(\"accuracy score for test using randomforest\",rfr.score(x_test,y_test))","8e7d73fa":"mae_train = mean_absolute_error(rfr.predict(x_train),y_train)\nprint('Mae on train using Randomforest :',mae_train)\nmae_test = mean_absolute_error(rfr.predict(x_test),y_test)\nprint('Mae on test using Randomforest :',mae_test)\n\nmse_train = mean_squared_error(rfr.predict(x_train),y_train)\nprint('Mse on train using Randomforest :',mse_train)\nmse_test = mean_squared_error(rfr.predict(x_test),y_test)\nprint('Mse on test using Randomforest :',mse_test)","4eed5cfb":"#decisiontreeregressor\ndtr = DecisionTreeRegressor()\ndtr.fit(x_train,y_train)\npredicted=dtr.predict(x_train)","92a9aff6":"print(\"accuracy score for train using Decision_tree\",dtr.score(x_train,y_train))\nprint(\"accuracy score for test using Decision_tree\",dtr.score(x_test,y_test))","3b5b6647":"mae_train = mean_absolute_error(dtr.predict(x_train),y_train)\nprint('Mae on train using decision tree :',mae_train)\nmae_test = mean_absolute_error(dtr.predict(x_test),y_test)\nprint('Mae on test using decision tree :',mae_test)\n\nmse_train = mean_squared_error(dtr.predict(x_train),y_train)\nprint('Mse on train using decision tree :',mse_train)\nmse_test = mean_squared_error(dtr.predict(x_test),y_test)\nprint('Mse on test using decision tree :',mse_test)","91e8ca8a":"xgboost = xgb.XGBRegressor(n_estimators=300)\nxgboost.fit(x_train,y_train)\npredicted=xgboost.predict(x_train)","77278a54":"print(\"accuracy score for train using Xgboost:\",xgboost.score(x_train,y_train))\nprint(\"accuracy score for test using Xgboost :\",xgboost.score(x_test,y_test))","e3de2bb8":"mae_train = mean_absolute_error(xgboost.predict(x_train),y_train)\nprint('Mae on train using XGboost :',mae_train)\nmae_test = mean_absolute_error(xgboost.predict(x_test),y_test)\nprint('Mae on test using XGboost :',mae_test)\n\nmse_train = mean_squared_error(xgboost.predict(x_train),y_train)\nprint('Mse on train using XGboost :',mse_train)\nmse_test = mean_squared_error(xgboost.predict(x_test),y_test)\nprint('Mse on test using XGboost :',mse_test)","5555839c":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)\n{'bootstrap': [True, False],\n 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n 'max_features': ['auto', 'sqrt'],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [2, 5, 10],\n 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}","d97d3a59":"rf = RandomForestRegressor()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(x_train,y_train)","7151584a":"print(\"accuracy score for train using randomforest gridsearch:\",rf_random.score(x_train,y_train))\nprint(\"accuracy score for test using randomforest gridsearch :\",rf_random.score(x_test,y_test))","bfd7864a":"RandomForest (gridsearch) gave the best accuracy score on test ie..0.89056 \nhence the randomforest(gridsearch) is best model"}}