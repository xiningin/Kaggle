{"cell_type":{"9a67e6f5":"code","3a2dbe93":"code","180d3e55":"code","5743fa3c":"code","d3e8d60d":"code","bd3fd244":"code","def20776":"code","735fb91e":"code","333469f3":"code","1ae78412":"code","7b9bff6e":"code","41c55189":"code","7a449b28":"code","76133233":"code","73daf2c3":"code","a3839d7a":"code","4914776e":"code","dd9b9b3a":"code","37a3107d":"code","7b6aa150":"code","bdc0efd3":"code","a0db6fac":"code","1dc422e1":"code","9193829f":"code","6116f406":"markdown","a7bb4758":"markdown","34a863fe":"markdown","54f4c09d":"markdown","9c4ad4f3":"markdown","9d9f2d20":"markdown","d4787d7a":"markdown","6e679ea1":"markdown","b640f4bb":"markdown","b8cd9023":"markdown","130fc8e7":"markdown","1e765e5b":"markdown","40522123":"markdown","01efe0cd":"markdown","1b1d082e":"markdown","0b0b7544":"markdown","065c33f7":"markdown","e7fba20f":"markdown","1b91a41b":"markdown","8ae9e1d6":"markdown","33dd3071":"markdown"},"source":{"9a67e6f5":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","3a2dbe93":"pip install --upgrade vaex","180d3e55":"import vaex","5743fa3c":"import numpy as np\nn_rows = 30000000 #30 million rows\nn_cols = 10 #10 variables\ndf = pd.DataFrame(np.random.randint(100000000, 1000000000, size=(n_rows, n_cols)), columns=['c%d' % i for i in range(n_cols)])","d3e8d60d":"df.info(memory_usage='deep') \n## 2.2GB of artificial data","bd3fd244":"%%time\n# Save the artificial data to read in use both pandas and vaex later\ndf.to_csv('data.csv', index=False)","def20776":"%%time\npandas_df = pd.read_csv(\"data.csv\", low_memory=False)","735fb91e":"%%time\nvaex_df = vaex.from_csv(\"data.csv\",copy_index=False)","333469f3":"%%time\nvaex_chunk_df = vaex.from_csv(\"data.csv\",copy_index=False, convert=True, chunk_size=5_000)","1ae78412":"vaex_df.head(3)","7b9bff6e":"# Unique function to Vaex: View first few lines of the beginning part and another few lines from the last part of the dataframe\nvaex_df.head_and_tail_print(2)","41c55189":"vaex_df.describe()","7a449b28":"vaex_df = vaex_df.drop(\"c9\")","76133233":"list(vaex_df.columns) # \"c9\" column has been successfully dropped","73daf2c3":"gender = ['male','male','female','male','female']\n\nIQ = [120, 83, 52, 160, 97]\n\nexample_vaex_df = vaex.from_arrays(gender=gender, IQ=IQ)","a3839d7a":"example_vaex_df.groupby(by='gender').agg({'IQ':'mean'})","4914776e":"test = [0,np.nan,np.nan,12,28,1932,130234]\n\ntest_vaex_df = vaex.from_arrays(co=test)","dd9b9b3a":"test_vaex_df.fillna(1)","37a3107d":"test_vaex_df.co.ismissing()","7b6aa150":"test_vaex_df.co.isna()","bdc0efd3":"test_vaex_df.co.isnan()","a0db6fac":"del pandas_df\ndel vaex_df\ndel vaex_chunk_df","1dc422e1":"import gc\ngc.collect()","9193829f":"%%time\nfrom vaex.ml.sklearn import Predictor\nfrom sklearn.ensemble import GradientBoostingClassifier\n\niris_df = vaex.ml.datasets.load_iris()\n\nfeatures = ['petal_length', 'petal_width', 'sepal_length', 'sepal_width']\ntarget = 'class_'\n\nmodel = GradientBoostingClassifier(random_state=42)\nvaex_model = Predictor(features=features, target=target, model=model, prediction_name='prediction')\n\nvaex_model.fit(df=iris_df)\n\niris_df = vaex_model.transform(iris_df)","6116f406":"Refer to the official documentation and the tutorials there for further detailed info! https:\/\/vaex.io\/docs\/index.html","a7bb4758":"### Import Relevant Libraries","34a863fe":"There are mainly three functions for identifying missing values\n\n- ismissing(): Returns True where there are missing values (masked arrays), missing strings or None\n- isna(): Returns a boolean expression indicating if the values are Not Availiable (missing or NaN).\n- isnan(): Returns an array where there are NaN values\n\nand three dropna functions associated with each of these nan identifying functions\n\n- test_df.dropna( )\n- test_df.dropnan( )\n- test_df.dropmissing( )","54f4c09d":"### Comparing time it takes to Read in CVS (pandas v.s. Vaex)","9c4ad4f3":"### Machine learning with Vaex-ml","9d9f2d20":"##### groupby -- aggregate calculations","d4787d7a":"The big flow of things looks the same as sklearn but one difference you can see below is the use of the \"Predictor\" in vaex.ml.sklearn which is kind of a model placeholder that can hold various parameters for a model (e.g. features, target, which algorithm to use etc.). In a typical sklearn setting, this would usually be done within each algorithm instance (in this case within the GradientBoostingClassifier( ) instance)","6e679ea1":"##### Drop a column\/variable","b640f4bb":"And so many other operations you would normally think of doing in pandas are mostly available. Things like:\n\njoining, sorting, string operations (e.g. lower, contains, endswith, alphanumeric check). ","b8cd9023":"There are good articles that analyze the performance speed of Vaex in comparison to Pandas or other big data tech (e.g. Dask, Pyspark)\n\n- https:\/\/towardsdatascience.com\/how-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94\n- https:\/\/towardsdatascience.com\/beyond-pandas-spark-dask-vaex-and-other-big-data-technologies-battling-head-to-head-a453a1f8cc13\n- https:\/\/www.kdnuggets.com\/2021\/05\/vaex-pandas-1000x-faster.html\n\nThese articles show how efficient and fast Vaex can be in doing various operations from reading in big data, merging, sorting to joining and calculating basic summary statistics like the mean.\n\nIt seems to be the case that Vaex's performance, as a library for dealing with \"big data\", actually backfires when it's dealing with smaller data for which pandas is enough. Here our artificial data was 2.2GB in memory and maybe it wasn't big enough to justify the use of Vaex. **Let's keep in mind that for small datasets for which pandas is enough to read in, just using pandas instead of other big data libraries may actually be more efficient**\n\nAnother article that compares the performance of read_csv for various sized data and shows that Vaex's speed\/performance might not be better than Pandas for not much of a big dataset\n- https:\/\/towardsdatascience.com\/is-something-better-than-pandas-when-the-dataset-fits-the-memory-7e8e983c4fe5","130fc8e7":"One pros of Vaex in comparison to other big data libraries is its **HIGH SIMILARITY to the PANDAS syntax and API**. Most of the functions and syntax are exactly the same or extremely similar more or less.","1e765e5b":"##### describe the data","40522123":"Following is one example from the official documentation of how supervised learning works in vaex-ml using the iris dataset.","01efe0cd":"### Basic Operations","1b1d082e":"### Installing Vaex","0b0b7544":"Using Conda, you can install Vaex via the following:\n\n**conda install -c conda-forge vaex**","065c33f7":"From the above results, we see that ysing Vaex to read in the 2.2GB of artificial data takes slightly less than reading in the same data using pandas. It actually takes way longer if you read in the data in chunks. The documentation of Vaex proudly boasts that \"Vaex is a high performance Python library for lazy Out-of-Core DataFrames (similar to Pandas), to visualize and explore big tabular datasets. It calculates statistics such as mean, sum, count, standard deviation etc, on an N-dimensional grid for more than a billion (10^9) samples\/rows per second\". The gains doesn't seem to be that big. What is going on here?","e7fba20f":"##### View some rows of the dataset","1b91a41b":"There is a even a separate machine learning library for Vaex whose syntax is similar to sklearn. Things like clustering, PCA and supervised learning are all made possible via vaex-ml.","8ae9e1d6":"### Make Artificial Data for Tutorial","33dd3071":"##### Dealing with Missing Data"}}