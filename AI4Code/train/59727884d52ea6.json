{"cell_type":{"fb5a8a72":"code","8a3a0e07":"code","8db27202":"code","dcd5f1bb":"code","da0f022f":"code","1ffa0f52":"code","6e2cb071":"code","faa2feff":"code","e1276a2a":"code","53d9ff14":"code","2207dd93":"code","551fd5b7":"code","f7a71f45":"code","4454ed45":"code","b051fd61":"code","5bea1bab":"code","68261c70":"code","ddae2766":"code","84b5ac45":"code","125b5ae0":"code","5150ec9a":"code","3bb13234":"code","ceb5388c":"code","188e3080":"code","9e674a9a":"code","4e13c215":"code","5ae642f9":"code","008331db":"code","081c2721":"code","0f2dbe5a":"code","8978fd2d":"code","bb124a15":"code","3177cdce":"code","aa3fa4e3":"code","4d98cd35":"code","4d168a5c":"code","a35e0ef4":"code","a2a079b6":"code","4fbe226c":"code","27786c80":"code","4b2c64fd":"code","a81e4bf9":"code","daaf2fe4":"code","d5447d84":"code","5018c924":"code","9a3dd05d":"code","d0417190":"code","2ca7a6f4":"code","64d90d20":"code","96c82f1f":"code","832292f4":"code","f941e587":"code","04810de9":"code","f0783ef1":"code","9ba7e708":"code","36b894f5":"code","6124bba8":"markdown","f016aaac":"markdown","89997908":"markdown","25143537":"markdown","a04ac882":"markdown","78b0b54d":"markdown","2d7b2ec3":"markdown","5fa8daa7":"markdown","670e3610":"markdown","3b7d0ee2":"markdown","915c1848":"markdown"},"source":{"fb5a8a72":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","8a3a0e07":"# import required libraries\nimport numpy as np \nimport pandas as pd \nfrom fastai import *\nfrom fastai.vision import *\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.preprocessing import image\nfrom pathlib import Path\nimport os\nimport glob  # used for loading multiple files\n# import PIL \n!mkdir -p \/tmp\/.cache\/torch\/checkpoints\/\n# !cp \/input\/resnet34\/resnet34.pth \/tmp\/.cache\/torch\/checkpoints\/resnet34-333f7ec4.pth","8db27202":"# root directory\npath = Path(\"..\/input\/severstal-steel-defect-detection\");\npath.ls()","dcd5f1bb":"path_train_img = path\/'train_images';\npath_test_img = path\/'test_images';","da0f022f":"# get a list of filenames in the train image directory\nfnames = get_image_files(path_train_img)\nfnames[:5]","1ffa0f52":"# labels in the train.csv file  \ntrain = pd.read_csv(path\/'train.csv')\ntrain.head()","6e2cb071":"# function to plot an image\ndef plot_img(ImageId):\n    img_id = ImageId+'.jpg'\n    img = open_image(str(path_train_img) + '\/'+img_id)\n    return img\n\n# function to plot a mask of an image\ndef plot_mask(ImageId_ClassId):\n    mask = open_mask_rle(train.loc[lambda df: df[\"ImageId_ClassId\"] == ImageId_ClassId, \"EncodedPixels\"].values[0], shape=(256, 1600))\n    mask = ImageSegment(mask.data.transpose(2, 1))\n    return mask\n\ndef plot_img_mask(ImageId,ClassId):\n    defect_img = plot_img(ImageId)\n    defect_mask = plot_mask(ImageId+'.jpg_'+str(ClassId))\n    defect_img.show(y=defect_mask, figsize=(20, 10), title = 'image & its masks')","faa2feff":"plot_img('0002cc93b')","e1276a2a":"plot_mask('0002cc93b.jpg_1')","53d9ff14":"plot_img('fff02e9c5')","2207dd93":"plot_mask('fff02e9c5.jpg_3')","551fd5b7":"plot_img('000f6bf48')","f7a71f45":"plot_mask('000f6bf48.jpg_4')","4454ed45":"# Visualize mask and image in one plot\nplot_img_mask('000f6bf48',4)","b051fd61":"# https:\/\/www.kaggle.com\/mayurkulkarni\/fastai-simple-model-0-88-lb\ndef train_pivot(train_csv):\n    df = pd.read_csv(train_csv)\n\n    def group_func(df, i):\n        reg = re.compile(r'(.+)_\\d$')\n        return reg.search(df['ImageId_ClassId'].loc[i]).group(1)\n\n    group = df.groupby(lambda i: group_func(df, i))\n\n    df = group.agg({'EncodedPixels': lambda x: list(x)})\n\n    df['ImageId'] = df.index\n    df = df.reset_index(drop=True)\n\n    df[[f'EncodedPixels_{k}' for k in range(1, 5)]] = pd.DataFrame(df['EncodedPixels'].values.tolist())\n    \n    df = df.drop(columns='EncodedPixels')\n    train_df = df.fillna(value=' ')\n    return train_df","5bea1bab":"train_df = train_pivot(str(path)+'\/train.csv')\ntrain_df.head()","68261c70":"# adding a flag to determine whether or not an image has defects\ntrain_df['has_defects'] = 0\ntrain_df.loc[(train_df['EncodedPixels_1'] != ' ') |  (train_df['EncodedPixels_2'] != ' ') | (train_df['EncodedPixels_3'] != ' ')\n            | (train_df['EncodedPixels_4'] != ' '), 'has_defects'] = 1 ","ddae2766":"train_df.head()","84b5ac45":"print('There are' ,train_df[train_df.has_defects == 1].shape[0] , 'images with defects and' , train_df[train_df.has_defects == 0].shape[0]\n      , 'without defects in the training set') ","125b5ae0":"# using the original dataframe where there are 4 lines for each ImageId, I calculate the number of defects for each image\n\ntmp = train.copy()\ntmp['ImageId'] = tmp['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntmp['ClassId'] = tmp['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntmp['has_defects'] = tmp.EncodedPixels.apply(lambda x: 1 if not pd.isnull(x) else 0)\ndefects = pd.DataFrame(tmp.groupby(by=\"ImageId\")['has_defects'].sum())\ndefects.reset_index(inplace=True)  # convert the image_id which is an index to a column so that the dataframes can be joined on that\ndefects.rename(columns={\"has_defects\": \"no_of_defects\"},inplace=True) # rename the aggregated column ready for the join \ndefects.head()\n\n\n# add the no_of_defects to the labels dataframe\n\ntrain_df = train_df.merge(defects, left_on='ImageId', right_on='ImageId', how='left')\ntrain_df.head(4)","5150ec9a":"sns.countplot(train_df.no_of_defects)","3bb13234":"train_df.no_of_defects.value_counts().sort_values(ascending=False)","ceb5388c":"# example of steel images more than 1 defects\ntrain_df[train_df.no_of_defects > 1]","188e3080":"# an example image with 2 defects: class 3 & class 4\nplot_img('fd26ab9ad')","9e674a9a":"plot_img_mask('fd26ab9ad','3')\nplot_img_mask('fd26ab9ad','4')","4e13c215":"train_clf = train_df[['ImageId','no_of_defects']] \ntrain_clf.head()","5ae642f9":"# creating the specific data format called ImageDataBunch required by the fastai models. It bundles the actual training images\n# in the image directory with the labels we loaded into a dataframe \nnp.random.seed(42)\nbs = 64\ndata = ImageDataBunch.from_df(path_train_img, train_clf, ds_tfms=get_transforms(), size=256, bs=bs, test=path_test_img\n                                  ).normalize(imagenet_stats)","008331db":"data.show_batch(rows=3, figsize=(7,6))","081c2721":"print(data.classes)\nlen(data.classes),data.c","0f2dbe5a":"learn = cnn_learner(data, models.resnet34, metrics=error_rate, model_dir=\"\/kaggle\/working\")","8978fd2d":"learn.model","bb124a15":"learn.fit_one_cycle(1)","3177cdce":"learn.save('DefectClass_stage-1')","aa3fa4e3":"# !mkdir exports","4d98cd35":"# learn.export()","4d168a5c":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","a35e0ef4":"interp.plot_top_losses(9, figsize=(15,11))","a2a079b6":"interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","4fbe226c":"interp.most_confused(min_val=2)","27786c80":"learn.recorder.plot()","4b2c64fd":"# ingest more data into the model to improve error_rate\nlearn.unfreeze()\nlearn.fit_one_cycle(2, max_lr=slice(1e-04,1e-03))","a81e4bf9":"learn.save('DefectClass_stage-2')","daaf2fe4":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","d5447d84":"interp.plot_top_losses(9, figsize=(15,11))","5018c924":"interp.most_confused(min_val=2)","9a3dd05d":"learn.recorder.plot()","d0417190":"learn.unfreeze()\nlearn.fit_one_cycle(1, max_lr=slice(1e-05,1e-04))","2ca7a6f4":"learn.save('DefectClass_stage-3')","64d90d20":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","96c82f1f":"interp.most_confused(min_val=2)","832292f4":"learn.predict(is_test=True)","f941e587":"learn.show_results()","04810de9":"from fastai.widgets import *","f0783ef1":"ds, idxs = DatasetFormatter().from_toplosses(learn, n_imgs=100)","9ba7e708":"ImageCleaner(ds, idxs, path)","36b894f5":"ds, idxs = DatasetFormatter().from_similars(learn)","6124bba8":"## Train the model with Resnet34","f016aaac":"#### Can our model do any better by fine-tunning even more?","89997908":"# Cleaning up","25143537":"### Sneak peek in the train data","a04ac882":"I liked Mayur's idea on pivoting the labels for each class (class1-class4) so that we'll have one line per _ImageId_. I believe this will prevent overfitting when splitting the data into train and validation i.e. no ImageId will leak from train to the validation set.","78b0b54d":"# Model : Image Classifier to predict non-defect images in the test set\n\nI use the number of defects as the dependent variable in my classifier. Here, I create a subset of the train_df dataframe that contains the ImageId and no_of_defects columns to predict number of defects.","2d7b2ec3":"**Observations:**\n\n_ClassId_ is attached to the filename. Each filename has 4 classes 1-4 and each class does or does not have a mask (run Length Encoding) associated to it. Mask is represented as NaN when there does not an RLE string for a _ClassId_. An image may have none, one or multiple RLE codes.  ","5fa8daa7":"### Visualize images and masks","670e3610":"# Construct Masks from RLE strings","3b7d0ee2":"### File operations","915c1848":"# Multilabel Image Classification_ fastai\n\nIn order to predict RLE segments of the steel images in the test set, I've decided to first train a model that predicts whether or not an image has defects. Although, to make it more interesting, my model is going to predict how many defects a steel image has. As you will see later in my analysis, an image can have 0-3 defects. \n\nThe aim of this kernel is to train a **cnn_learner with resnet34 architecture** and save the weights of the model (if I can figure out how to save and reuse the model in another kernel! :P) and also export the predicted labels for the test set so that I can exclude those images in my segmentation solution.\n\nPeople who inspired the idea are [Mayur Kulkarni](https:\/\/www.kaggle.com\/mayurkulkarni\/fastai-simple-model-0-88-lb) and [xhlulu](https:\/\/www.kaggle.com\/xhlulu\/severstal-simple-2-step-pipeline). Please go and check out their kernels and vote up their kernels if you like their approach. \n\nAlso, thanks to [Jeremy Howard](https:\/\/www.kaggle.com\/jhoward) for his great deep learning tutorials. I'm following his instructions while still trying to get my head round how to use _fastai_, so bear with me Jeremy! :D    "}}