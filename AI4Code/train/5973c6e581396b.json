{"cell_type":{"0b8fa19b":"code","5748bca7":"code","4f6c7e34":"code","196659c3":"code","21c295fc":"code","349721fd":"code","d0ebbbcb":"code","94befa25":"code","24f40abf":"code","a29ac9b4":"code","5ceefad1":"code","5b639550":"markdown","e3fe8c22":"markdown","4e7c3677":"markdown","88fe8a95":"markdown","4718531e":"markdown","366e2c9b":"markdown","2d4994bd":"markdown"},"source":{"0b8fa19b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5748bca7":"import pandas as pd\nimport numpy as np\n\ninput_file = \"\/kaggle\/input\/movie-synopsis-dataset\/movie_synopsis.csv\"\ndf = pd.read_csv(input_file)\ndf.head()","4f6c7e34":"df.info()","196659c3":"index_drop = df[df['synopsis'] == \"No overview found.\"].index\ndf.drop(index_drop, inplace = True)\ndf.reset_index(drop = True, inplace = True)","21c295fc":"df.info()","349721fd":"df['synopsis'] = df['synopsis'].str.lower()\ndf.head()","d0ebbbcb":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(stop_words = 'english') # Use filter to remove english stopwords\nfeatures = vectorizer.fit_transform(df['synopsis'].values)\nfeatures","94befa25":"from sklearn.cluster import KMeans\n\nk = 19 # Number of clusters\nmodel = KMeans(k)\nmodel.fit(features)","24f40abf":"df['cluster'] = model.labels_\ndf.head()","a29ac9b4":"df.to_csv(\"df_movies_labeled.csv\")","5ceefad1":"order_centroids = model.cluster_centers_.argsort()[:, ::-1]\nterms = vectorizer.get_feature_names()\nn_terms = 10\n\nfor i in range(k) :\n\tprint(\"Cluster %d :\" % i)\n\tfor j in order_centroids [i, :n_terms] :\n\t\tprint('   %s' % terms[j])\n\tprint('----------')","5b639550":"# Preprocessing","e3fe8c22":"# Model Training","4e7c3677":"# Clusters Top Terms","88fe8a95":"# Data Collection","4718531e":"# Feature Engineering","366e2c9b":"# Data Labeling","2d4994bd":"# Remove Missing Value"}}