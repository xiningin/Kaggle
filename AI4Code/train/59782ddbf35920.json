{"cell_type":{"64a9f56a":"code","4e5f7185":"code","66669a1f":"code","d4fd91cb":"code","bf3b04b1":"code","a1577f80":"code","5fa9ef17":"code","a219235a":"code","2a67d4cd":"code","29efbbdc":"code","52bb7c1a":"code","59f9a610":"code","d95e3d22":"code","274c92c2":"code","49a18536":"code","0087fecb":"code","a0d20bd6":"code","31b22c35":"code","fc54d459":"code","0712ff49":"code","36767e6d":"code","6c5861eb":"code","84378e47":"code","025bd592":"code","9e6f63cb":"code","2db871a5":"code","d429dcc4":"code","7d21cb8d":"code","81249fb3":"code","d26ee50c":"code","0502e359":"code","9cc9527b":"code","869a579f":"code","619d7deb":"code","86320b4d":"code","1c5dffd0":"code","8279fa8c":"code","36c98502":"code","0ee92479":"code","ce8c8bfd":"code","2b60a5ac":"code","fa3d3c33":"markdown","3a68ea24":"markdown","e691a4b4":"markdown","599af86e":"markdown","680e217d":"markdown","e421db57":"markdown","39e5588e":"markdown","8ce6a07c":"markdown","f3060277":"markdown","56da3015":"markdown","9a097467":"markdown","e08b080e":"markdown","ce7435f3":"markdown","8c82a984":"markdown","60649175":"markdown","153439b3":"markdown","1f50b572":"markdown","f4903fe1":"markdown","e2ec5815":"markdown","eb400228":"markdown","7047ff0e":"markdown","8a258125":"markdown","9723a2ab":"markdown","d0ca010c":"markdown","1f0ced2d":"markdown","e8553fc2":"markdown","b107960e":"markdown","0f724917":"markdown","e8f30756":"markdown","95247cb2":"markdown","1be95599":"markdown","c2038eae":"markdown","f14158be":"markdown","8ded7fb4":"markdown","21d17e2e":"markdown","fe807afa":"markdown","1eb3d12d":"markdown"},"source":{"64a9f56a":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport tensorflow as tf\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Activation, Dropout, Convolution2D, MaxPooling2D, BatchNormalization","4e5f7185":"data_train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","66669a1f":"print('Number of non-valid elements in training set:', data_train[data_train.isna() == True].count().sum(),\n      '\\nNumber of non valid elements in test set:', data_test[data_test.isna() == True].count().sum())","d4fd91cb":"data_train_pd = data_train.copy()","bf3b04b1":"true_labels = data_train.label\ndata_train = data_train.drop('label', axis = 1)","a1577f80":"data_train = data_train.values.reshape(-1, 28, 28, 1)\ndata_test = data_test.values.reshape(-1, 28, 28, 1)","5fa9ef17":"plt.figure(figsize=(10,5))\nsns.countplot(x = true_labels, palette = 'rocket')\nplt.show()","a219235a":"fig = plt.figure(figsize=(12, 12))\nfor i in range(1, 26, 1):\n    plt.subplot(5, 5, i)\n    plt.imshow(data_train[i])","2a67d4cd":"fig = plt.figure(figsize=(12, 12))\nfor i in range(1, 26, 1):\n    plt.subplot(5, 5, i)\n    plt.imshow(data_test[i])","29efbbdc":"sample = data_train_pd.sample(n=10000, random_state=17)","52bb7c1a":"from sklearn.manifold import TSNE\n\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\ndata_train_embedded = tsne.fit_transform(sample.drop('label', axis = 1))","59f9a610":"plt.figure(figsize=(10, 10))\nplt.xlabel(\"new variable 1\")\nplt.title(\"Digits in reducted space\")\nplt.ylabel(\"new variable 2\")\nsns.scatterplot(x = data_train_embedded[:,0], y=data_train_embedded[:,1], hue=sample.label,legend=True, palette='bright')\nplt.show()","d95e3d22":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\n\nX_train, X_holdout, y_train, y_holdout = train_test_split(data_train_pd.drop('label', axis = 1), data_train_pd.label, \n                                                     test_size = 0.25, random_state=0)\nknn = KNeighborsClassifier(n_neighbors=10, n_jobs=-1)\nknn.fit(X_train, y_train)\n","274c92c2":"#predictions = knn.predict(X_holdout)\n#%time","49a18536":"from sklearn.naive_bayes import BernoulliNB\n\nX_train, X_holdout, y_train, y_holdout = train_test_split(data_train_pd.drop('label', axis = 1), data_train_pd.label, \n                                                     test_size = 0.25, random_state=0)\nbnbclf = BernoulliNB()\nbnbclf.fit(X_train, y_train)","0087fecb":"print(\"Accuracy score: {:.2f}\".format(bnbclf.score(X_holdout, y_holdout)))\nprint(\"Cross-entropy loss: {:.2f}\".format(log_loss(np.array(y_holdout), bnbclf.predict_proba(X_holdout))))","a0d20bd6":"result = pd.DataFrame({'true_label' : y_holdout, 'predicted' : bnbclf.predict(X_holdout)})\nerrors = result[result.true_label != result.predicted]\n\nplt.figure(figsize=(10,5))\nsns.countplot(x = errors.true_label, palette = 'rocket')\nplt.show()","31b22c35":"plt.figure(figsize=(11,9))\nplt.title('Wrongly classified digits')\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(pd.crosstab(errors['true_label'], errors['predicted']).reset_index().drop('true_label', axis = 1), annot=True, fmt=\"d\", cmap = cmap)\nplt.show()","fc54d459":"from sklearn.model_selection import GridSearchCV\nbnb_params = {'alpha':      np.arange(0.01, 0.1, 0.05),\n              'binarize' :  np.arange(0, 0.5, 0.2),\n              'fit_prior':  [True, False]\n             }\nbnbcv = GridSearchCV(bnbclf, param_grid = bnb_params, cv = 3)","0712ff49":"bnbcv.fit(X_train, y_train)\nbnb_best = bnbcv.best_estimator_","36767e6d":"bnbcv.best_params_","6c5861eb":"print(\"Accuracy score: {:.2f}\".format(bnb_best.score(X_holdout, y_holdout)))\nprint(\"Cross-entropy loss: {:.2f}\".format(log_loss(np.array(y_holdout), bnb_best.predict_proba(X_holdout))))","84378e47":"model = Sequential()\n\nmodel.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization( axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer=\"zeros\", gamma_initializer=\"ones\",))\nmodel.add(Convolution2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization( axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer=\"zeros\", gamma_initializer=\"ones\",))\n\n\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","025bd592":"data_train = data_train \/ 255\ndata_test = data_test \/ 255","9e6f63cb":"y = np.array(pd.get_dummies(true_labels))","2db871a5":"X_train, X_holdout, y_train, y_holdout = train_test_split(data_train, y, \n                                                     test_size = 0.25, random_state=17)","d429dcc4":"reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                 factor=0.1,\n                                                 patience=5,\n                                                 min_lr=0.000001,\n                                                 verbose=1)","7d21cb8d":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\nresult = model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_holdout, y_holdout), callbacks = [reduce_lr])","81249fb3":"plt.figure(figsize=(10, 9))\nplt.plot(result.history['accuracy'])\nplt.plot(result.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'holdout'], loc='upper left')\nplt.show()","d26ee50c":"filters , bias = model.layers[0].get_weights()\nf_min, f_max = filters.min(), filters.max()\nfilters = (filters - f_min) \/ (f_max - f_min)\n\nn_filters = 8\nix=1\nfig = plt.figure(figsize=(20,40))\nfor i in range(n_filters):\n\n    plt.subplot(n_filters,4,ix)\n    plt.imshow(filters[:,:,:,i] ,cmap='gray', aspect='auto')\n    ix+=1\n#plot the filters \nplt.show()","0502e359":"from tensorflow.keras.models import Model\nlayer_names = [layer.name for layer in model.layers]\nlayer_outputs = [layer.output for layer in model.layers]\nlayer_outputs = [layer_outputs[0], layer_outputs[2]]\nfeature_map_model = Model(model.input, layer_outputs)\nim = X_train[99:100,:]\nfeature_maps = feature_map_model.predict(im)","9cc9527b":"for i in range(2):\n    ix = 1\n    plt.figure(figsize=(20,9))\n    for j in range(feature_maps[i].shape[3]):\n        im = feature_maps[i]\n        \n        ax = plt.subplot(4, 8, ix)\n        ax.set_xticks([])\n\n       \n        ax.set_yticks([])\n    # plot filter channel in grayscale\n        plt.imshow(im[0,:,:,j])\n        ix += 1\n# show the figure\n    plt.show()","869a579f":"augumentator =  tf.keras.preprocessing.image.ImageDataGenerator(   \n    rotation_range=15,\n    width_shift_range=0.15,\n    shear_range=0.1,\n    zoom_range=0.1,\n    validation_split=0.0,\n    horizontal_flip=False,\n    vertical_flip=False)\n\naugumentator.fit(X_train)","619d7deb":"fig.suptitle(\"Title centered above all subplots\", fontsize=14)\nfor _ in range(5):\n    ind = np.random.randint(10000)\n    im = X_train[ind:ind+1,:][0]\n    \n    plt.subplot(1, 2, 1)\n    plt.imshow(im)\n    plt.subplot(1, 2, 2)\n    plt.imshow(augumentator.random_transform(im))\n    plt.show()","86320b4d":"history = model.fit(augumentator.flow(X_train, y_train, batch_size = 32), epochs = 10, \n         validation_data = (X_holdout, y_holdout), verbose = 1, callbacks = [reduce_lr])","1c5dffd0":"mnist = tf.keras.datasets.mnist\n(X_train_mnist, y_train_mnist), (X_val_mnist, y_val_mnist) = mnist.load_data()","8279fa8c":"y_train_mnist = np.array(pd.get_dummies(pd.Series(y_train_mnist)))\ny_holdout_mnist = np.array(pd.get_dummies(pd.Series(y_val_mnist)))","36c98502":"X_train_mnist = X_train_mnist.reshape(-1, 28, 28, 1)\nX_holdout_mnist = X_val_mnist.reshape(-1, 28, 28, 1)\nX_train_mnist = X_train_mnist \/ 255\nX_holdout_mnist = X_holdout_mnist \/255","0ee92479":"X_train_ext = np.concatenate((X_train, X_train_mnist), axis = 0)\nX_holdout_ext = np.concatenate((X_holdout, X_holdout_mnist), axis = 0)\ny_train_ext = np.concatenate((y_train, y_train_mnist), axis = 0)\ny_holdout_ext = np.concatenate((y_holdout, y_holdout_mnist), axis = 0)","ce8c8bfd":"model.fit(X_train_ext, y_train_ext, batch_size=32, epochs=20, verbose=1, validation_data=(X_holdout, y_holdout), callbacks = [reduce_lr])","2b60a5ac":"predictions = model.predict(data_test).argmax(axis = 1)\npredictions\nsubmission = pd.DataFrame({'ImageId':np.arange(1, len(predictions)+1), 'Label':predictions})\nsubmission.to_csv('submission.csv', index=False)","fa3d3c33":"![risovach.ru.jpg](attachment:2e09bd21-2f2c-45a9-bccd-adf2984ea3a1.jpg)","3a68ea24":"# T-SNE Dimensionality reduction\n### The main idea of t-SNE algorythm\nWe have a data with points, but its dimensionality is much larger than 3 (which is possible to visualise). We need to get a new variable which can save the structure of the data. SNE transforms distance between points into probabilities that shows the similarity of the points","e691a4b4":"### Visualizing the errors","599af86e":"### Checking the data","680e217d":"# Neural Network\nFirst of all: \"why Neural Network?\". The answer is that NN is much more *non-linear* than standart algorythms.\nIt means, that it can resolve some extraordinal dependencies of an object.\n#### Useful resource\n[Here](https:\/\/playground.tensorflow.org\/#activation=tanh&regularization=L2&batchSize=10&dataset=spiral&regDataset=reg-gauss&learningRate=0.3&regularizationRate=0&noise=0&networkShape=8,6,5&seed=0.23031&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=regression&initZero=false&hideText=false&batchSize_hide=false) you can play with neural networks in classification and regression problems. It is the great resource that allows you to create a NN and see how it *learns*","e421db57":"# Loading Data","39e5588e":"### Visualizing the filters\nWe have a chance to see what our model learned to see. In the graphs below you may see some abstract features extracted from images. For example, it can be some horizontal or vertical lines detection.","8ce6a07c":"### I'll try to predict the digits using only kNN classifier","f3060277":"## Visualize an augumented images","56da3015":"# Overview\nI am very pleased to see you here. This notebook is dedicated to the digit recognition. I will use both ML model and Neural Networks. A lot of attention will be paid to visualization and understanding of the process. Hope you enjoy!","9a097467":"After visualizing the results of t-Sne we can obtain some interesting results. Some digits (for example 0, 1 and 6) form visible clusters. It is also possible to understand, why digits 9 and 4 are now mixed.","e08b080e":"#### Visualizing the results","ce7435f3":"# Extending the data\nA great idea is to exdend our training data. I hope it can influence quality of recognition","8c82a984":"#### Establishing base model","60649175":"As we can see, tuning did not lead to great results","153439b3":"## Visualizing the dataset\n### Training set\nLet's visualize some images!","1f50b572":"# Importing Libraries","f4903fe1":"# k-Nearest Neighbours","e2ec5815":"## Training on augumented dataset","eb400228":"##### Taking a 1\/4 of the data to visualize","7047ff0e":"## Setting an architecture\nOur model consists of group of convolution layers, which are needed to extract some image features. Here I use BatchNormalization in order to scale the outputs of MaxPooling layers. After all, outputs of convolution go to fully connected layers, which end up with Softmax. I have chosen softmax because it is great for classification problems.","8a258125":"# Naive-Bayes Classification","9723a2ab":"#### Tuning model","d0ca010c":"# Convolutional Neural Network\nWhen it comes to image classification, we face the problem, that number of input features is very big. Even for this dataset, the standart input is 28x28 = 784. It is the number of neurons that you have to place in the input layer. This can affect perfomance. Convolutional Neural Networks (CNN) solve this problem by reducing the number of thainable parameters using filters (or kernels)\n![im1](https:\/\/i.stack.imgur.com\/Z0tNA.png)\n## Useful resources\n[Resource](https:\/\/towardsdatascience.com\/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) to understand CNN\n\n[Here](https:\/\/www.cs.ryerson.ca\/~aharley\/vis\/conv\/) you can play with digit regognizer in see CNN from the inside\n\n[Here](https:\/\/poloclub.github.io\/cnn-explainer\/) you can understand image recognition via CNN","1f0ced2d":"### Test set","e8553fc2":"### Using the algorythm implemented in sklearn","b107960e":"After some time of predicting i found out that kNN is very SLOW","0f724917":"What we got here? We got the great improvement in quality!","e8f30756":"## Label distribution","95247cb2":"# Visualizing the results","1be95599":"## Model Training\nHere is the finction, that can reduce learning rate in order to smoothen learning process","c2038eae":"### Visualizing feature maps\nLet's explore, what happens to an image inside the network. Here you can see the transformation of the image when it passes the layer.","f14158be":"Classes of digits seem to be well-balanced, so we have to train the great classifier to solve the problem","8ded7fb4":"# Quick visualization","21d17e2e":"# Improving the model\n## Augumentation\nWhat can we do, to improve the score? Of course we need to feed the model with more data! But where can we take this data? Let's just create it.\nWhat I am going to do is to take a picture and do some random stuff with it. For example, rotate a bit, or zoom a little. By practice, augumentation can help our model not to overfit.","fe807afa":"## Scaling the data\nNeural network is very sensitive to numbers, which are larger than 1. Large unscaled numbers can dramatically affect the perfomance and influence the stability of the optimization ","1eb3d12d":"### Learning curve\n\u041d\u0435re it is possible to see the progress of learning."}}