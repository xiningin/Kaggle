{"cell_type":{"fab215b6":"code","b7d7fb31":"code","350eba75":"code","f502dd0b":"code","7c3a033b":"code","3d23f215":"code","1281db6e":"code","d515e174":"code","3f2cb2de":"code","deb4813c":"code","002cf3e3":"code","8b95506b":"code","dca69f8e":"code","739a112f":"code","99019742":"code","243d56e7":"code","8c7e3355":"code","313ae46e":"code","20256c48":"code","1fe7f29d":"code","82c537c2":"code","965bfc23":"code","bb8e5d3a":"code","0611b7c6":"code","d328a64f":"code","c784d4dc":"code","a8208d79":"code","7bbe9b23":"code","9ebaad6e":"code","1fbc52e8":"code","c6b9175b":"code","cfe84b98":"markdown","eb04b46c":"markdown","6c7d35f1":"markdown","87881275":"markdown","b2ef7b78":"markdown","8073eb7b":"markdown","54a92f69":"markdown","71254786":"markdown","8401c665":"markdown","97ec3cd5":"markdown","9b4a07dc":"markdown","cc055aa3":"markdown","57645969":"markdown","3f3b3ca3":"markdown","f8f04d89":"markdown"},"source":{"fab215b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport os\n","b7d7fb31":"# Check out the folder structure\nfor dirname, _, _ in os.walk('\/kaggle\/input'):\n    print(dirname)","350eba75":"print(tf.__version__)","f502dd0b":"# Number of images in each class\ntrain_pneumonia_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/PNEUMONIA'\ntrain_normal_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/NORMAL'\n\ntrain_pneumonia_count = len(os.listdir(train_pneumonia_dir))\ntrain_normal_count = len(os.listdir(train_normal_dir))\n\nprint(f'Number of pneumonia images in training set: {train_pneumonia_count}')\nprint(f'Number of normal images in training set: {train_normal_count}')\n\nval_pneumonia_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val\/PNEUMONIA'\nval_normal_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val\/NORMAL'\n\nval_pneumonia_count = len(os.listdir(val_pneumonia_dir))\nval_normal_count = len(os.listdir(val_normal_dir))\n\nprint(f'Number of pneumonia images in validation set: {val_pneumonia_count}')\nprint(f'Number of normal images in validation set: {val_normal_count}')\n","7c3a033b":"batch_size = 32\nimg_height = 224\nimg_width = 224","3d23f215":"train_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train'\nval_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val'\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    train_dir,\n    image_size = (img_height, img_width),\n    batch_size = batch_size\n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    val_dir,\n    image_size = (img_height, img_width),\n    batch_size = batch_size\n)","1281db6e":"print(f'Train class names: {train_ds.class_names}')\nprint(f'Validation class names: {val_ds.class_names}')\n\nclass_names = train_ds.class_names","d515e174":"for image, label in train_ds.take(1):\n    print(image.shape)\n    print(label.shape)","3f2cb2de":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","deb4813c":"train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)","002cf3e3":"weight_for_normal = (1\/train_normal_count) * ((train_pneumonia_count+train_normal_count) \/ 2)\nweight_for_pneumonia = (1\/train_pneumonia_count) * ((train_pneumonia_count+train_normal_count) \/ 2)\n\nclass_weight = {0: weight_for_normal, 1: weight_for_pneumonia}\n\nprint('Weight for Normal class (0): {:.2f}'.format(weight_for_normal))\nprint('Weight for Pneumonia class (0): {:.2f}'.format(weight_for_pneumonia))\n","8b95506b":"vgg16_model = tf.keras.applications.vgg16.VGG16(\n    include_top=True, weights='imagenet', input_tensor=None,\n    input_shape=None, pooling=None, classes=1000,\n    classifier_activation='softmax'\n)","dca69f8e":"vgg16_model.summary()","739a112f":"model = tf.keras.Sequential()\nfor layer in vgg16_model.layers[:-1]:\n    model.add(layer)","99019742":"model.summary()","243d56e7":"for layer in model.layers:\n    layer.trainable = False\n    \nmodel.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid'))","8c7e3355":"# #############################################################################\n# # YOUR CODE HERE\n# # Here is the base model we commonly used in class, you can modify this and \n# # see if you can improve on the model performance\n# #############################################################################\n\n\n# base_model = tf.keras.Sequential([\n#     # Standardize the input data\n#     tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255),\n    \n#     # {Conv -> MaxPool} x 3\n#     tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n#     tf.keras.layers.MaxPooling2D(2,2),\n#     tf.keras.layers.Dropout(0.2),\n    \n#     tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n#     tf.keras.layers.MaxPooling2D(2,2), \n#     tf.keras.layers.Dropout(0.2),\n    \n#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n#     tf.keras.layers.MaxPooling2D(2,2),\n#     tf.keras.layers.Dropout(0.2),\n    \n#     # Flatten the results to feed into a DNN\n#     tf.keras.layers.GlobalAveragePooling2D(),\n    \n#     # 512 neuron hidden layer\n#     tf.keras.layers.Dense(512, activation='relu'), \n#     tf.keras.layers.Dropout(0.5),\n    \n#     tf.keras.layers.Dense(128, activation='relu'), \n#     tf.keras.layers.Dropout(0.5),\n    \n#     # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n#     tf.keras.layers.Dense(1, activation='sigmoid')  \n# ])","313ae46e":"# # input layer\n# inputs = tf.keras.layers.InputLayer(input_shape=(img_height, img_width, 3))\n\n# # Data augmentation\n# data_augmentation = tf.keras.Sequential([\n#                               tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n#                               tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n# ], name='data_augmentation')","20256c48":"# model = tf.keras.Sequential([inputs, data_augmentation, base_model])\nmodel.summary()","1fe7f29d":"METRICS = [\n      tf.keras.metrics.TruePositives(name='tp'),\n      tf.keras.metrics.FalsePositives(name='fp'),\n      tf.keras.metrics.TrueNegatives(name='tn'),\n      tf.keras.metrics.FalseNegatives(name='fn'), \n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall')\n]\n    \nmodel.compile(optimizer='adam',\n             loss='binary_crossentropy',\n             metrics= METRICS)\n","82c537c2":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_prc', \n    verbose=1,\n    patience=10,\n    mode='max',\n    restore_best_weights=True)","965bfc23":"EPOCHS = 5","bb8e5d3a":"history = model.fit(train_ds, \n                    epochs=EPOCHS, \n                    validation_data=val_ds, \n                    class_weight=class_weight,\n                    callbacks=[early_stopping])","0611b7c6":"def plot_metrics(history):\n  metrics = ['loss', 'accuracy', 'precision', 'recall']\n  for n, metric in enumerate(metrics):\n    name = metric.replace(\"_\",\" \").capitalize()\n    plt.figure(figsize=(15,15))\n    plt.subplot(2,2,n+1)\n    plt.plot(history.epoch, history.history[metric], color='b', label='Train')\n    plt.plot(history.epoch, history.history['val_'+metric],\n             color='r', linestyle=\"--\", label='Val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    if metric == 'loss':\n      plt.ylim([0, plt.ylim()[1]])\n    elif metric == 'auc':\n      plt.ylim([0.8,1])\n    else:\n      plt.ylim([0,1])\n\n    plt.legend()\n","d328a64f":"plot_metrics(history)","c784d4dc":"import sklearn\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ndef plot_cm(labels, predictions, p=0.5):\n  cm = confusion_matrix(labels, predictions > p)\n  plt.figure(figsize=(5,5))\n  sns.heatmap(cm, annot=True, fmt=\"d\")\n  plt.title('Confusion matrix @{:.2f}'.format(p))\n  plt.ylabel('Actual label')\n  plt.xlabel('Predicted label')\n\n  print('Detected (True Negatives): ', cm[0][0])\n  print('Incorrectly Detected (False Positives): ', cm[0][1])\n  print('Missed (False Negatives): ', cm[1][0])\n  print('Detected (True Positives): ', cm[1][1])\n  print('Total images: ', np.sum(cm[1]))","a8208d79":"evaluation = model.evaluate(val_ds)\nprint(evaluation)","7bbe9b23":"for images, labels in val_ds.take(1):\n    print(images.shape)","9ebaad6e":"for images, labels in val_ds.take(1):\n    plot_cm(labels, model.predict(images))","1fbc52e8":"test_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test'\n\ntest_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    test_dir,\n    image_size = (img_height, img_width),\n    batch_size = batch_size\n)","c6b9175b":"print(model.evaluate(test_ds))","cfe84b98":"## 3.0 - Train your model","eb04b46c":"Check training and validation performance","6c7d35f1":"The validation curves for all metrics are a bit bumpy since our validation set is too little (only 16 images). ","87881275":"### 2.1 - Correct data imbalance\nThere are a couple of ways to handle data imbalance issue. One of them is by assigning higher class weights to the class with less data (minority class), such that the loss is higher with misclassifying the minority class. Another method is to perform oversampling on the minority class.\nFor more details, you can refer to: https:\/\/www.tensorflow.org\/tutorials\/structured_data\/imbalanced_data.","b2ef7b78":"**NOTE** Our dataset is imbalance, accuracy itself is less meaningful in this case since the model can get 'NORMAL' class all wrong but the accuracy would still be 74%. Hence, we introduce precision and recall as the evaluation metrics.\n\n**Accuracy** - Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations.\n\n**Precision** - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. TP\/(TP+FP)\n\n**Recall** - Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes. TP\/(TP+FN)\n","8073eb7b":"## 4.0 - Evaluate your model's training performance","54a92f69":"Visualize the dataset, as always, let's visualize the dataset.","71254786":"## 1.0 - Data importation and preprocessing","8401c665":"Configure the dataset for performance","97ec3cd5":"This training dataset is imbalance, the number of pneumonia images are 3 times the number of normal images. We will handle this later in Section 2.0. We will create the dataset for training set and validation set.","9b4a07dc":"*after 8 epochs\n20\/20 [==============================] - 3s 115ms\/step - loss: 0.5892 - tp: 387.0000 - fp: 96.0000 - tn: 138.0000 - fn: 3.0000 - accuracy: 0.8413 - precision: 0.8012 - recall: 0.9923\n[0.5891705751419067, 387.0, 96.0, 138.0, 3.0, 0.8413461446762085, 0.8012422323226929, 0.9923076629638672]\n\n*after 10 epochs:\n20\/20 [==============================] - 4s 140ms\/step - loss: 0.4608 - tp: 375.0000 - fp: 63.0000 - tn: 171.0000 - fn: 15.0000 - accuracy: 0.8750 - precision: 0.8562 - recall: 0.9615\n[0.46082639694213867, 375.0, 63.0, 171.0, 15.0, 0.875, 0.8561643958091736, 0.9615384340286255]\n\n*after 16 epochs\n20\/20 [==============================] - 4s 130ms\/step - loss: 0.7493 - tp: 381.0000 - fp: 101.0000 - tn: 133.0000 - fn: 9.0000 - accuracy: 0.8237 - precision: 0.7905 - recall: 0.9769\n[0.7493147850036621, 381.0, 101.0, 133.0, 9.0, 0.8237179517745972, 0.7904564142227173, 0.9769230484962463]","cc055aa3":"## 2.0 - Define model architecture","57645969":"**My results**\nAfter 50 epochs, with this simple model (all layers were covered in class). I got accuracy: 0.8606 - precision: 0.8722 - recall: 0.9103.\nTry your own model and see if you can beat me.","3f3b3ca3":"## 5.0 - Evaluate your model's performance with test dataset","f8f04d89":"Inspect the shape of each batch"}}