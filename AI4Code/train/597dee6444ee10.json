{"cell_type":{"7da9e9ba":"code","45e192d2":"code","1d41bf47":"code","e60c9d78":"code","93d6362e":"code","4a4d9054":"code","c43ef969":"code","5a074aa4":"code","3f0359b7":"code","df8315e5":"code","1f9192f7":"code","3be5c48e":"code","d6c72069":"code","922b08be":"code","3ca0a333":"code","ee201857":"code","887e1eec":"code","1050cbeb":"code","81af5a39":"code","2e6c96d2":"code","1959d368":"code","f529fdd7":"code","06ea8c52":"code","282d206b":"code","18dd9544":"code","8fc0015c":"code","242b9911":"code","b86d0f41":"code","e288a1a4":"code","15c9d5a4":"code","e1522734":"code","e128b1cb":"code","9ad6481d":"code","a5c364bd":"code","d0b6ff86":"code","7787afdc":"code","aef564cb":"code","b9ff1e50":"code","c167bb8e":"code","2f136f04":"code","539c24d1":"code","3ffa5779":"code","82dc039a":"code","6140e228":"code","4ecc29c5":"code","e8cd2345":"code","e715b1bf":"code","38e53f9e":"code","0f603766":"code","2879ca8d":"code","f2080fe9":"code","90bc432f":"code","48e0650a":"code","a0eec0ca":"code","67504d96":"code","1bcd54ea":"code","43b7f860":"code","a8f319e6":"markdown","7b389ad6":"markdown","59798292":"markdown","17bd307c":"markdown","dcfca3c6":"markdown","21c9d715":"markdown","810ce316":"markdown","70961aa5":"markdown","16c95d54":"markdown","dd21c137":"markdown","d1ee1a2b":"markdown","16ae3bd8":"markdown","6f241369":"markdown","ba80a271":"markdown"},"source":{"7da9e9ba":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\npd.pandas.set_option('display.max_columns',None)","45e192d2":"dataset=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndataset.shape # to find the number of rows and colums in dataset","1d41bf47":"dataset.head() # shows the top 5 records","e60c9d78":"null_features=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>0]\nfor i in null_features:\n    print(i ,dataset[i].isnull().sum())","93d6362e":"for feature in null_features:\n    data = dataset.copy()\n    data[feature] = np.where(data[feature].isnull(), 1, 0)# 1 denotes missing values otherwise 0\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.title(feature)\n    plt.show()","4a4d9054":"numerical_features = [feature for feature in dataset.columns if dataset[feature].dtypes != 'O']\ndataset[numerical_features].head()","c43ef969":"# list of variables that contain year information\nyear_feature = [feature for feature in numerical_features if 'Yr' in feature or 'Year' in feature]\n\nyear_feature","5a074aa4":"# let's explore the content of these year variables\nfor feature in year_feature:\n    print(feature, dataset[feature].unique())","3f0359b7":"dataset.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Median House Price')\nplt.title(\"House Price vs YearSold\")","df8315e5":"year_feature","1f9192f7":"for feature in year_feature:\n    if feature!='YrSold':\n        data=dataset.copy()\n        ## We will capture the difference between year variable and year the house was sold for\n        data[feature]=data['YrSold']-data[feature]\n\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()","3be5c48e":"## Numerical variables are usually of 2 type\n## 1. Continous variable and Discrete Variables\n\ndiscrete_feature=[feature for feature in numerical_features if len(dataset[feature].unique())<25 and feature not in year_feature+['Id']]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","d6c72069":"discrete_feature","922b08be":"dataset[discrete_feature].head()","3ca0a333":"## Lets Find the realtionship between them and Sale PRice\n\nfor feature in discrete_feature:\n    data=dataset.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","ee201857":"continuous_feature=[feature for feature in numerical_features if feature not in discrete_feature+year_feature+['Id']]\nprint(\"Continuous feature Count {}\".format(len(continuous_feature)))","887e1eec":"## Lets analyse the continuous values by creating histograms to understand the distribution\n\nfor feature in continuous_feature:\n    data=dataset.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"Count\")\n    plt.title(feature)\n    plt.show()","1050cbeb":"## We will be using logarithmic transformation\n\n\nfor feature in continuous_feature:\n    data=dataset.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        data['SalePrice']=np.log(data['SalePrice'])\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalesPrice')\n        plt.title(feature)\n        plt.show()","81af5a39":"for feature in continuous_feature:\n    data=dataset.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        data.boxplot(column=feature)\n        plt.ylabel(feature)\n        plt.title(feature)\n        plt.show()","2e6c96d2":"categorical_features=[feature for feature in dataset.columns if data[feature].dtypes=='O']\ncategorical_features","1959d368":"dataset[categorical_features].head()","f529fdd7":"for feature in categorical_features:\n    data=dataset.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","06ea8c52":"null_features=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>0]\nfor i in null_features:\n    print(i ,dataset[i].isnull().sum())","282d206b":"## Replace missing value with a new label\ndef replace_cat_feature(dataset,features_nan):\n    data=dataset.copy()\n    data[features_nan]=data[features_nan].fillna('Missing')\n    return data\n\ndataset=replace_cat_feature(dataset,features_nan)\n\ndataset[features_nan].isnull().sum()","18dd9544":"dataset.head()","8fc0015c":"## Now lets check for numerical variables the contains missing values\nnumerical_with_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes!='O']\n\n## We will print the numerical nan variables and percentage of missing values\n\nfor feature in numerical_with_nan:\n    print(\"{}: {}% missing value\".format(feature,np.around(dataset[feature].isnull().mean(),4)))","242b9911":"## Replacing the numerical Missing Values\n\nfor feature in numerical_with_nan:\n    ## We will replace by using median since there are outliers\n    median_value=dataset[feature].median()\n    \n    ## create a new feature to capture nan values\n    dataset[feature+'nan']=np.where(dataset[feature].isnull(),1,0)\n    dataset[feature].fillna(median_value,inplace=True)\n    \ndataset[numerical_with_nan].isnull().sum()\n    \n    ","b86d0f41":"dataset.head(10)","e288a1a4":"## Temporal Variables (Date Time Variables)\n\nfor feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n       \n    dataset[feature]=dataset['YrSold']-dataset[feature]","15c9d5a4":"dataset.head()","e1522734":"dataset[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()","e128b1cb":"dataset.head()","9ad6481d":"import numpy as np\nnum_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n\nfor feature in num_features:\n    dataset[feature]=np.log(dataset[feature])","a5c364bd":"dataset.head()","d0b6ff86":"## Handling Rare Categorical Feature\n\n##We will remove categorical variables that are present less than 1% of the observations","7787afdc":"categorical_features=[feature for feature in dataset.columns if dataset[feature].dtype=='O']","aef564cb":"categorical_features","b9ff1e50":"for feature in categorical_features:\n    temp=dataset.groupby(feature)['SalePrice'].count()\/len(dataset)\n    temp_df=temp[temp>0.01].index\n    dataset[feature]=np.where(dataset[feature].isin(temp_df),dataset[feature],'Rare_var')\n    \n    ","c167bb8e":"dataset.head(10)","2f136f04":"for feature in categorical_features:\n    labels_ordered=dataset.groupby([feature])['SalePrice'].mean().sort_values().index\n    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n    dataset[feature]=dataset[feature].map(labels_ordered)","539c24d1":"dataset.head(5)","3ffa5779":"scaling_feature=[feature for feature in dataset.columns if feature not in ['Id','SalePerice'] ]\nlen(scaling_feature)","82dc039a":"scaling_feature","6140e228":"dataset.head()\n","4ecc29c5":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(dataset,dataset['SalePrice'],test_size=0.1,random_state=0)","e8cd2345":"X_train.shape, X_test.shape","e715b1bf":"feature_scale=[feature for feature in dataset.columns if feature not in ['Id','SalePrice']]\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nscaler.fit(dataset[feature_scale])","38e53f9e":"scaler.transform(dataset[feature_scale])","0f603766":"# transform the train and test set, and add on the Id and SalePrice variables\ndata = pd.concat([dataset[['Id', 'SalePrice']].reset_index(drop=True),\n                    pd.DataFrame(scaler.transform(dataset[feature_scale]), columns=feature_scale)],\n                    axis=1)","2879ca8d":"\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel","f2080fe9":"## Capture the dependent feature\ny_train=dataset[['SalePrice']]\n## drop dependent feature from dataset\nX_train=dataset.drop(['Id','SalePrice'],axis=1)","90bc432f":"\nfeature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) # remember to set the seed, the random state in this function\nfeature_sel_model.fit(X_train, y_train)\n","48e0650a":"feature_sel_model.get_support()","a0eec0ca":"# let's print the number of total and selected features\n\n# this is how we can make a list of the selected features\nselected_feat = X_train.columns[(feature_sel_model.get_support())]\n\n# let's print some stats\nprint('total features: {}'.format((X_train.shape[1])))\nprint('selected features: {}'.format(len(selected_feat)))\nprint('features with coefficients shrank to zero: {}'.format(\n    np.sum(feature_sel_model.estimator_.coef_ == 0)))","67504d96":"selected_feat","1bcd54ea":"X_train=X_train[selected_feat]","43b7f860":"X_train.head()","a8f319e6":"### Categorical Variables","7b389ad6":"### Data Analysis\n#### In data analysis we will find out :-\n#### 1.Missing Values \n#### 2.finding relationship between missing values and target value\n#### 3.Numerical Variable\n#### 4.Catagorical variable\n#### 5.Finding Outliers\n#### 6. finding relationship between independent variable and dependent variable","59798292":"#### we can clearly see the relation between the missing value and dependent variable ,so we cant drop a perticular column instead we need to replace nan value with some meaningful.","17bd307c":"### Continuous Variable","dcfca3c6":"# House Prices : Advance Regression Technique","21c9d715":"## Numerical Variables\nSince the numerical variables are skewed we will perform log normal distribution","810ce316":"## Missing Values","70961aa5":"## Numerical variables","16c95d54":"## Feature Scaling","dd21c137":"### Outliers","d1ee1a2b":"## Steps involved in data science project.\n#### 1. Data Analysis\n#### 2. Feature Engineering\n#### 3. Feature Selection\n#### 4. Model Building\n#### 5. Model Deployment","16ae3bd8":"### Exploratory Data Analysis Part 2","6f241369":"### Since there are many null values , Now we should find the relationship between the null values and the sale price","ba80a271":"### The main aim of the dataset is to predict the house price based on various features.\n### Kindly  understand the dataset first before moving further as it will help in data analysis part."}}