{"cell_type":{"62ba3757":"code","b947d4b2":"code","048b9a4e":"code","92aafe41":"code","715ec842":"code","fc92aa52":"code","fbf046ba":"code","98228ec3":"code","834526b2":"code","d40beb7f":"code","7e8cbe9a":"code","890eddc9":"code","a6d8cb8f":"code","7f3f1fea":"code","726268cc":"code","fb23d07a":"code","7ba10447":"code","1e73539c":"code","8113e99f":"code","f65d3181":"code","4eb090fb":"code","84c0d62a":"code","8930bbee":"code","7c939d2f":"code","9a099063":"markdown","509e5840":"markdown","5369cdf4":"markdown","547d680d":"markdown","586c7aa4":"markdown","d53ab406":"markdown","e62237e0":"markdown","75f52561":"markdown","2f39961a":"markdown","975f51d0":"markdown","218e7a2e":"markdown","41ebdc9e":"markdown","d69174bf":"markdown","c7bdfad2":"markdown","2e4da982":"markdown","213c3187":"markdown","ae30f8f2":"markdown","112bcb8d":"markdown","3a2949ee":"markdown"},"source":{"62ba3757":"import os\nimport pandas as pd\nimport numpy as np\n\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\nfrom sklearn.utils import class_weight as cw\nfrom keras.models import load_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import Flatten, Dense, Dropout\n\n# Import des librairies pour la gestion des Callback\nfrom keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping","b947d4b2":"EPOCHS                  = 100   # Nombre d'epoch\nIMGSIZE                 = 96    # Taille des images\nBATCH_SIZE              = 32    # Pour le traitement par lot des images (optimisation de la decente de gradient)\nSTOPPING_PATIENCE       = 10    # Callback pour stopper si le mod\u00e8le n'apprend plus\nVERBOSE                 = 0     # Niveau de verbosit\u00e9\nMODEL_NAME              = 'cnn_80epochs_imgsize160'\nOPTIMIZER               = 'adam'\nTRAINING_DIR            = '..\/input\/dogs-vs-cats-redux-kernels-edition\/train'\nTEST_DIR                = '..\/input\/dogs-vs-cats-redux-kernels-edition\/test'\nTRAIN_MODEL             = True  # Entrainement du modele (True) ou chargement (False)","048b9a4e":"train_files = os.listdir(TRAINING_DIR)\ntrain_labels = []\n\nfor file in train_files:\n    train_labels.append(file.split(\".\")[0])\n    \ndf_train = pd.DataFrame({\"id\": train_files, \"label\": train_labels})\n\ndf_train.head()","92aafe41":"# Augmentation d'images \u00e0 la vol\u00e9e et split train \/ validation\ntrain_datagen =  \\\n        ImageDataGenerator(\n            rescale=1.\/255,\n            shear_range=0.1,\n            zoom_range=0.3,\n            rotation_range=10,\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            horizontal_flip=True,\n            vertical_flip=True,\n            validation_split=0.10)\n\n# Parcours du jeu d'entrainement (subset = 'training')\ntrain_generator = \\\n        train_datagen.flow_from_dataframe(\n            df_train,\n            TRAINING_DIR,\n            x_col='id',\n            y_col='label',\n            has_ext=True,\n            shuffle=True,\n            target_size=(IMGSIZE, IMGSIZE),\n            batch_size=BATCH_SIZE,\n            subset='training',\n            class_mode='categorical')","715ec842":"valid_generator = \\\n        train_datagen.flow_from_dataframe(\n            df_train,\n            TRAINING_DIR,\n            x_col='id',\n            y_col='label',\n            has_ext=True,\n            shuffle=True,\n            target_size=(IMGSIZE, IMGSIZE),\n            batch_size=BATCH_SIZE,\n            subset='validation',\n            class_mode='categorical')","fc92aa52":"test_files = os.listdir(TEST_DIR)\ndf_test = pd.DataFrame({\"id\": test_files, 'label': 'nan'})","fbf046ba":"# https:\/\/medium.com\/@vijayabhaskar96\/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n# Le ImageDataGenerator fait juste une normalisation des valeurs\ntest_datagen = ImageDataGenerator(rescale=1.0\/255)\ntest_generator = test_datagen.flow_from_dataframe(\n    df_test, \n    TEST_DIR, \n    x_col='id',\n    y_col=None,       # None car nous ne connaissons pas les labels\n    has_ext=True, \n    target_size=(IMGSIZE, IMGSIZE), \n    class_mode=None,  # None pour le jeu de test\n    seed=42,\n    batch_size=1,     # batch_size = 1 sur le jeu de test\n    shuffle=False     # Pas de m\u00e9lange sur le jeu de test\n)","98228ec3":"# Cette fonction permet de retourner le ratio entre chat vs chien (utile dans le cas ou une classe et pro\u00e9minente sur les autres)\ndef get_weight(y):\n    class_weight_current =  cw.compute_class_weight('balanced', np.unique(y), y)\n    return class_weight_current\nclass_weights = get_weight(train_generator.classes)","834526b2":"# G\u00e9n\u00e9ration des STEPS_SIZE (comme nous utilisons des g\u00e9n\u00e9rateurs infinis)\nSTEP_SIZE_TRAIN = train_generator.n \/\/ train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n \/\/ valid_generator.batch_size\nSTEP_SIZE_TEST  = test_generator.n  \/\/ test_generator.batch_size","d40beb7f":"# Permet de stopper l'apprentissage si il stagne\nEARLY_STOPPING = \\\n        EarlyStopping(\n            monitor='val_loss',\n            patience=STOPPING_PATIENCE,\n            verbose=VERBOSE,\n            mode='auto')\n\n\n# Reduit le LearningRate si stagnation\nLR_REDUCTION = \\\n        ReduceLROnPlateau(\n            monitor='val_acc',\n            patience=5,\n            verbose=VERBOSE,\n            factor=0.5,\n            min_lr=0.00001)\n\nCALLBACKS = [EARLY_STOPPING, LR_REDUCTION]","7e8cbe9a":"# Initialisation du mod\u00e8le\nclassifier = Sequential()\n\n# R\u00e9alisation des couches de Convolution  \/ Pooling\n\n# ---- Conv \/ Pool N\u00b01\nclassifier.add(Conv2D(filters=16,\n                      kernel_size=3,\n                      strides=1,\n                      padding='same',\n                      input_shape=(IMGSIZE, IMGSIZE, 3),\n                      activation='relu'))\n\nclassifier.add(BatchNormalization())\nclassifier.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n\n# ---- Conv \/ Pool N\u00b02\nclassifier.add(Conv2D(filters=16,\n                      kernel_size=3,\n                      strides=1,\n                      padding='same',\n                      activation='relu'))\n\nclassifier.add(BatchNormalization())\nclassifier.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n\n# ---- Conv \/ Pool N\u00b03\nclassifier.add(Conv2D(filters=32,\n                      kernel_size=3,\n                      strides=1,\n                      padding='same',\n                      activation='relu'))\n\nclassifier.add(BatchNormalization())\nclassifier.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n\n# ---- Conv \/ Pool N\u00b04\nclassifier.add(Conv2D(filters=32,\n                      kernel_size=3,\n                      strides=1,\n                      padding='same',\n                      activation='relu'))\n\nclassifier.add(BatchNormalization())\n\nclassifier.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n\n\n# Fully Connected\n# Flattening : passage de matrices 3D vers un vecteur\nclassifier.add(Flatten())\nclassifier.add(Dense(512, activation='relu'))\nclassifier.add(Dropout(0.1))\n\n\n# Couche de sortie : classification => softmax sur le nombre de classe\nclassifier.add(\n    Dense(\n        units=2,\n        activation='softmax',\n        name='softmax'))\n\n# compilation du  model de classification\nclassifier.compile(\n    optimizer=OPTIMIZER,\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\n\n\nprint(\"Input Shape :{}\".format(classifier.get_input_shape_at(0)))\nclassifier.summary()","890eddc9":"def train_model():\n    # https:\/\/keras.io\/models\/sequential\/#fit_generator\n    # Pour visualisation avec Tensorboard (console anaconda): \n    # tensorboard --logdir=\/full_path_to_your_logs\n    history = classifier.fit_generator(\n        generator=train_generator,           # le g\u00e9n\u00e9rateur pour les donn\u00e9es d'entrainement\n        steps_per_epoch=STEP_SIZE_TRAIN,     # le Step_size pour les donn\u00e9es d'entrainement\n        validation_data=valid_generator,     # le g\u00e9n\u00e9rateur pour les donn\u00e9es de validation\n        validation_steps=STEP_SIZE_VALID,    # le Step_size pour les donn\u00e9es de validation\n        epochs=EPOCHS,                       # le nombre d'epoch sur l'ensemble du jeu de donn\u00e9es\n        verbose=VERBOSE,                     # la verbosit\u00e9\n        class_weight=class_weights,          # le ratio de r\u00e9partition des classes chien\/chat\n        callbacks=CALLBACKS)                 # la liste des fonctions de callback \u00e0 appeler apr\u00e8s chaque epoch\n    return history    ","a6d8cb8f":"def plot_history(history):\n    # --------------------------------------\n    # Affichage des courbes accuracy et Loss\n    # --------------------------------------\n    plt.figure(1)\n    plt.subplot(211)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n\n    plt.subplot(212)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()     ","7f3f1fea":"if (TRAIN_MODEL):\n    print(\"Entrainement du mod\u00e8le CNN\")\n    hist = train_model()     # Entrainement du mod\u00e8le\n    plot_history(hist)       # Affichage de la courbe d'apprentissage\n    classifier.save(MODEL_NAME + '.h5')\nelse:\n    print(\"Chargement du mod\u00e8le...\")\n    classifier = load_model('..\/input\/weight\/cnn\/cnn.h5')","726268cc":"classifier.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_TEST)","fb23d07a":"# Le g\u00e9n\u00e9rateur doit \u00eatre reseter avant utilisation pour les pr\u00e9dictions\ntest_generator.reset()\npred=classifier.predict_generator(test_generator, steps=STEP_SIZE_TEST, verbose=1)","7ba10447":"# Visualisation du vecteur de probabilit\u00e9 des 5 premi\u00e8res lignes des pr\u00e9dictions\npred[0:5,:]","1e73539c":"predicted_class_indices=np.argmax(pred,axis=1)\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","8113e99f":"# Cr\u00e9ation d'un dataframe contenant les images et classes pr\u00e9dites\nfilenames=test_generator.filenames\nresults=pd.DataFrame({\"id\":filenames,\"label\":predictions})\nresults.head()","f65d3181":"# copy du dataframe de resultat\nsoumission = results.copy()\n\n# suppression de l'extension du fichier et conversion de la colonne en int avec la m\u00e9thode vectorielle str\nsoumission['id'] = soumission['id'].str[:-4].astype('int')\nsoumission.head()","4eb090fb":"# Tri sur la colonne des id avec la methode sort_values du dataframe\nsoumission = soumission.sort_values(by=['id'])\nsoumission.head()","84c0d62a":"# Remplacement du label 'cat' ou 'dog' par une valeur num\u00e9rique : utilisation de la fonction replace\n# Rappel sur les classes : {0: \"Cat\", 1: \"Dog\"} \nsoumission.replace({'dog': 1, 'cat': 0}, inplace=True)\nsoumission.head()","8930bbee":"# conversion du Dataframe vers un fichier de sortie\n# This is saved in the same directory as your notebook\nfilename = 'results.csv'\nsoumission.to_csv(filename,index=False)\nprint('Fichier enregistr\u00e9: ' + filename)","7c939d2f":"import random\n\nn = results.shape[0]\nf = list(np.arange(1,n))\n\nc = 20\nr =random.sample(f, c)\nnrows = 4\nncols = 5\nfig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(nrows*5, ncols*5))    \nfor i in range(c):\n    file = str(results['id'][r[i]])\n    path = TEST_DIR+\"\/\"+file\n    img = plt.imread(path)\n    plt.subplot(4, 5, i+1)\n    plt.imshow(img, aspect='auto')\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(str(results['id'][r[i]])+\"\\n\"+str(results['label'][r[i]]))\nplt.show()","9a099063":"### Entrainement ou Chargement du mod\u00e8le\n\n**Cette \u00e9tape permet de charger un mod\u00e8le d\u00e9j\u00e0 entrain\u00e9**.\n\nPour charger le mod\u00e8le il faut d'abord avoir entrain\u00e9 le r\u00e9seau, commit\u00e9 le notebook et ensuite upload\u00e9 en zip le fichier contenant les poids et l'architecture du mod\u00e8le. Il est \u00e9galement n\u00e9cessaire de configurer la variable TRAIN_MODEL = False.\n\nA la suite de l'entrainement nous pouvons observer les courbes d'accuracy et de loss pour v\u00e9rifier si le mod\u00e8le apprend correctement","509e5840":"## Entrainement du mod\u00e8le\n\nIl est temps d'entrainer le mod\u00e8le que nous avons cr\u00e9e avec les donn\u00e9es que nous avons pr\u00e9par\u00e9es.","5369cdf4":"### Mise en forme des pr\u00e9dictions\nMise en forme pour pr\u00e9parer le format attendu pour la soumission des r\u00e9sultats","547d680d":"## Import des librairies n\u00e9cessaire\n\nCi-dessous nous importons toutes les libraries n\u00e9cessaires pour la cr\u00e9ation du r\u00e9seau de la m\u00eame mani\u00e8re que dans le pr\u00e9c\u00e9dent tutorial.\n\nNous allons \u00e9galement rajouter des librairies de Keras pour la gestion des callback (nous allons voir ce point plus en d\u00e9tail)","586c7aa4":"## Data Generators & Image Real Time Augmentation","d53ab406":"## Configuration du mod\u00e8le\n\nAfin de variabiliser et de configurer plus facilement le r\u00e9seau nous exposons ici les principaux param\u00e8tres configurables","e62237e0":"## Pr\u00e9dictions","75f52561":"## Pr\u00e9paration des Jeux de donn\u00e9es\n\nCr\u00e9ation du dataframe des **donn\u00e9es d'entrainement** contenant les id des images et leur labels.\nNous utilisons toujours le Dataframe de Panda pour construire nos tableaux de donn\u00e9es.\n\nCette fois ci le jeu d'entrainement contient le nom du fichier ainsi que le label de l'image dans le nom du fichier (ie cat.100.jpg)\n\nNous allons donc cr\u00e9er un tableau avec la colonne id contenant le nom du fichier et la colonne label contenant la classe \u00e0 pr\u00e9dire.","2f39961a":"### Jeu de Validation\nTraitement du jeu de **validation qui est une sous partie du jeu d'entrainement** (subset = 'validation'). \n\nA noter que pour le jeu de validation nous appliquons aussi l'augmentation des images \u00e0 la vol\u00e9e (utilisation du train_datagen) , ce n'est pas une obligation.","975f51d0":"### Jeu de Test\nLe jeu de test contient les images non classifi\u00e9es sur lesquels nous devons faire les pr\u00e9dictions pour d\u00e9terminer si l'image est un chien ou un chat.\n\nNous allons donc suivre le m\u00eame processus que pour les donn\u00e9es de l'entrainement sauf qu'ici : \n* Nous ne connaissons pas les labels des images (evidence)\n* Nous n'appliquons pas de transformations sur les images","218e7a2e":"### Ecriture du fichier de soumission","41ebdc9e":"### G\u00e9n\u00e9ration des pr\u00e9dictions depuis le mod\u00e8le\n\nLe mod\u00e8le \u00e9tant entrain\u00e9 il est temps de g\u00e9n\u00e9rer les pr\u00e9dictions sur les images, nous obtenons en sortie deux probabilit\u00e9s fournies par la couche de sortie du mod\u00e8le de classification.","d69174bf":"## Affichage al\u00e9atoire des images pr\u00e9dites","c7bdfad2":"## Evaluations du mod\u00e8le\n\nNous proc\u00e9dons maintenant \u00e0 l'\u00e9valuation de la performance du mod\u00e8le sur le jeu de Validation. \nLa premi\u00e8re valeur est le Loss et la seconde l'accuracy","2e4da982":"### Jeu d'entrainement \n**Augmentation des images** \u00e0 la vol\u00e9e via les g\u00e9n\u00e9rateurs pour permettre de simuler une augmentation du nombre de donn\u00e9es disponible pour l'entrainement du r\u00e9seau. \n\nComme vu pr\u00e9c\u00e9dement c'est la classe de **Keras ImageDataGenerator** qui va permettre l'application de filtres et de transformations sur les images sources.\n\nIl faut \u00e9galement noter ici que nous faisons **split du jeu d'entrainement en deux sous parties** (les donn\u00e9es d'entrainement et celles de validation)\nCeci est r\u00e9alis\u00e9 gr\u00e2ce \u00e0 validation_split de ImageDataGenerator pour lequel on pr\u00e9ciser un ratio.","213c3187":"## CNN Convolutional Neural Network pour Classification des Images\n\nPour cette deuxi\u00e8me partie du tutorial nous allons R\u00e9aliser un R\u00e9seau de Convolution mais cette fois-ci sur un jeu de donn\u00e9es plus complexe que les chiffres du MNIST. En effet nous allons utiliser un dataset avec des **vrais images pour la reconnaissance Chien \/ Chat** (toujours en apprentissage supervis\u00e9)\n\nNous Utiliserons encore une fois les libraries de KERAS pour la cr\u00e9ation du r\u00e9seau de Convolution.\n\nTous les principaux \u00e9l\u00e9ments qui composent ce r\u00e9seau ont \u00e9t\u00e9 abord\u00e9s en partie 1, s'y reporter en cas de besoin.\n\n### Image Classification R\u00e9f\u00e9rences:\nhttps:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\nhttps:\/\/blog.keras.io\/building-powerful-image-classification-models-using-very-little-data.html\nhttps:\/\/www.kaggle.com\/stevenhurwitt\/cats-vs-dogs-using-a-keras-convnet\nhttps:\/\/stanford.edu\/~shervine\/blog\/keras-how-to-generate-data-on-the-fly\nhttps:\/\/github.com\/shervinea\/enzynet\/blob\/master\/scripts\/architecture\/enzynet_uniform.py\nhttps:\/\/stanford.edu\/~shervine\/blog\/evolution-image-classification-explained\nhttps:\/\/www.analyticsvidhya.com\/blog\/2016\/10\/tutorial-optimizing-neural-networks-using-keras-with-image-recognition-case-study\/\nhttp:\/\/ruder.io\/optimizing-gradient-descent\/\nhttps:\/\/medium.com\/@vijayabhaskar96\/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n\ndataset : https:\/\/www.kaggle.com\/c\/dogs-vs-cats-redux-kernels-edition\/data\n","ae30f8f2":"## Callbacks Keras\n\nPetite nouveaut\u00e9 par rapport \u00e0 la partie 1 : **L'utilisation des Callbacks**.\n\nLes callback permettent d'appliquer des traitements pendant l'entrainement du r\u00e9seau.  Nous pouvons donc influer ou observer l'apprentissage en cours.\n\nDans notre cas nous allons en d\u00e9finir deux : un pour permettre **l'arr\u00eat pr\u00e9matur\u00e9** de l'entrainement afin d'\u00e9conomiser les temps de calcul dans le cas ou le r\u00e9seau ne progresse plus, et le deuxi\u00e8me pour influer sur un param\u00e8tre appel\u00e9 le **Learning Rate** utilis\u00e9 dans les calculs num\u00e9riques de la decente de gradient.","112bcb8d":"## Architecture du CNN\n\nCi-dessous comme nous l'avons d\u00e9j\u00e0 vu nous d\u00e9finissons l'architecture du CNN puis de sa couche de classification (cf partie 1).\n\nComme nous ne pr\u00e9disons que deux classes, **la couche de sortie sera compos\u00e9e de deux neurones**.","3a2949ee":"Avec l'utilisation des generator il est n\u00e9cessaire de maitriser les \"step_size\" : "}}