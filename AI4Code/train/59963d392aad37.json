{"cell_type":{"d4adc6fb":"code","68835a45":"code","c93f3b4f":"code","aa7125fd":"code","8503f466":"code","1cd8760e":"code","468b258b":"code","499b1ef1":"code","3cc880e3":"code","5b4d582c":"code","2d12119f":"code","fc3504a0":"code","a8d198a4":"code","515913bc":"code","9fd09c71":"markdown","e8a183c5":"markdown","513d7cc7":"markdown","1b6abe91":"markdown","7b6615ec":"markdown","d72a3a18":"markdown","27c14513":"markdown","fe23686c":"markdown","1f87a99f":"markdown","9524ee9d":"markdown","3b2776db":"markdown"},"source":{"d4adc6fb":"import os\nimport cv2\n\nimport numpy as np\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import regularizers, optimizers\nfrom keras.models import Sequential","68835a45":"INPUT = \"\/kaggle\/input\/imet-2020-fgvc7\/\"\nTRAIN_DIR = \"\/kaggle\/input\/imet-2020-fgvc7\/train\/\"\nTEST_DIR = \"\/kaggle\/input\/imet-2020-fgvc7\/test\/\"\n\nEPOCHS = 6\nBATCH_SIZE = 512\nIM_SIZE = 128","c93f3b4f":"train_df = pd.read_csv(INPUT + \"train.csv\")\ntest_df = pd.read_csv(INPUT + \"sample_submission.csv\")\nlabels_df = pd.read_csv(INPUT + \"labels.csv\")","aa7125fd":"# adding \"png\" to the image id\ntest_df[\"id\"] = test_df[\"id\"] + \".png\" \ntrain_df['id'] = train_df[\"id\"] + \".png\"\ntrain_df.head(2)","8503f466":"# labels = labels_df.attribute_id.to_list()","1cd8760e":"train_df[\"attribute_ids\"] = train_df[\"attribute_ids\"].apply(lambda x:x.split())\nprint(train_df.shape)\ntrain_df.head(3)","468b258b":"datagen = ImageDataGenerator(width_shift_range=0.1,\n                             height_shift_range=0.1,\n                             zoom_range=0.2,\n                             rescale=1\/255. )\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255.)","499b1ef1":"train_generator = datagen.flow_from_dataframe(\n                                            dataframe=train_df,\n                                            directory=TRAIN_DIR,\n                                            x_col=\"id\",\n                                            y_col=\"attribute_ids\",\n                                            batch_size=BATCH_SIZE,\n                                            seed=42,\n                                            shuffle=True,\n                                            class_mode=\"categorical\",\n#                                             classes=labels,\n                                            target_size=(IM_SIZE,IM_SIZE))","3cc880e3":"# valid_generator = test_datagen.flow_from_dataframe(\n#                                                  dataframe=val_x,\n#                                                  directory=TRAIN_DIR,\n#                                                  x_col=\"id\",\n#                                                  y_col=\"attribute_ids\",\n#                                                  batch_size=BATCH_SIZE,\n#                                                  seed=42,\n#                                                  shuffle=True,\n#                                                  class_mode=\"categorical\",\n# #                                                  classes=labels,\n#                                                  target_size=(IM_SIZE,IM_SIZE))\n","5b4d582c":"test_generator = test_datagen.flow_from_dataframe(\n                                                dataframe=test_df,\n                                                directory=TEST_DIR,\n                                                x_col=\"id\",\n                                                batch_size=1,\n                                                seed=42,\n                                                shuffle=False,\n                                                class_mode=None,\n                                                target_size=(IM_SIZE,IM_SIZE))","2d12119f":"model = Sequential()\ninputShape = (IM_SIZE, IM_SIZE, 3)\nchanDim = -1\n\n# first CONV => RELU => CONV => RELU => POOL layer set\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n    input_shape=inputShape))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# second CONV => RELU => CONV => RELU => POOL layer set\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# third CONV => RELU => CONV => RELU => POOL layer set\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# first (and only) set of FC => RELU layers\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# softmax classifier\nmodel.add(Dense(3471, activation='sigmoid')) \n\nmodel.compile(optimizers.Adam(),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","fc3504a0":"def build_lrfn(lr_start=0.00001, lr_max=0.000075, \n               lr_min=0.000001, lr_rampup_epochs=20, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    \n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n    \n    return lrfn\n\nlrfn = build_lrfn()\nlr_schedule = LearningRateScheduler(lrfn, verbose=1)","a8d198a4":"STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\n# STEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\nSTEP_SIZE_TEST=test_generator.n\/\/test_generator.batch_size\n\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n#                     validation_data=valid_generator,\n#                     validation_steps=STEP_SIZE_VALID,\n                    callbacks=[lr_schedule],\n                    epochs=EPOCHS\n                   )","515913bc":"test_generator.reset()\npred=model.predict_generator(test_generator,\nsteps=STEP_SIZE_TEST,\nverbose=1)\npred_bool = (pred >0.2)\npredictions=[]\nlabels = train_generator.class_indices\nlabels = dict((v,k) for k,v in labels.items())\nfor row in pred_bool:\n    l=[]\n    \n    for index,cls in enumerate(row):\n        if cls:\n            l.append(labels[index])\n    predictions.append(\" \".join(l))\n    \nfilenames=test_generator.filenames\n\nresults = pd.DataFrame({\"id\":filenames,\"attribute_ids\":predictions})\nresults[\"id\"] = results[\"id\"].apply(lambda x:x.split(\".\")[0])\nresults.to_csv(\"submission.csv\",index=False)","9fd09c71":"#### The data is not distributed normally, so in this paper I do not clear the data. I want to look at the previous results.","e8a183c5":"## Constants","513d7cc7":"### Fitting the Model","1b6abe91":"### This function changes Learning Rate ","7b6615ec":"### Build model","d72a3a18":"## Prepare image to train","27c14513":"### Why \u201cbinary_crossentropy\u201d as loss function and \u201csigmoid\u201d as the final layer activation?\n\nRefer to this [thread](https:\/\/github.com\/keras-team\/keras\/issues\/741) it includes many articles and discussions related to this","fe23686c":"## Working with our datasets","1f87a99f":"### If you have some ideas please tell me.","9524ee9d":"### The DataFrame has the following format:\n![](https:\/\/miro.medium.com\/max\/276\/1*Aofuhp0h0qLZ2hEvYSbNPg.png)\n\nIf the dataset is formatted this way, In order to tell the flow_from_dataframe function that \u201cdesert,mountains\u201d is not a single class name but 2 class names separated by a comma, you need to convert each entry in the \u201clabels\u201d column to a list(not necessary to convert single labels to a list of length 1 along with entries that contains more than 1 label,but it\u2019s good to maintain everything as a list anyway).","3b2776db":"### Predict the output"}}