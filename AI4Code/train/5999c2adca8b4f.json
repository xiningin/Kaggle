{"cell_type":{"512b55ee":"code","9f407d4e":"code","f463f4e3":"code","6d5127e6":"code","e41f073e":"code","c24a3f39":"code","b8e37455":"code","4293c442":"code","13723bce":"code","20747851":"code","925d6aeb":"code","5140a7da":"code","d27783cd":"code","758d89f3":"code","55085214":"code","80be0962":"code","836b628b":"code","d59a9358":"code","52802a12":"code","88b05f20":"code","89358aa7":"code","7d774120":"code","32d65c17":"code","7d3ec45b":"code","cfed12bc":"code","01ffed38":"code","66399c53":"code","a181ce02":"code","9019ae32":"code","5b215481":"code","97c57e80":"code","5459d0d6":"code","0b621d97":"code","1d94250e":"code","3131c5f2":"code","6307dc9a":"code","3d5f9d9c":"code","f6d37b9b":"code","17119ad4":"code","75ce0d43":"code","b961fc3f":"code","8f223dee":"code","a9784977":"code","1caf59d9":"code","e4e89ba2":"code","29c7f21c":"code","bf76d1bf":"code","4d0ef147":"code","75532b2c":"code","b60a2c4b":"code","dd54b31a":"code","058ce93a":"code","e29a27fb":"code","a5029a36":"code","710afd93":"code","0f72dd30":"code","6c8954bc":"code","549f44f9":"code","871dc10a":"code","79e063d8":"code","bb45eb6d":"code","ff06efbc":"code","ae6a9954":"code","9dd47f35":"markdown","2cfb74af":"markdown","4f77a1c2":"markdown","74e94055":"markdown","868bced7":"markdown","03b3411a":"markdown","0b55faa7":"markdown","9e0e50ba":"markdown","17cff102":"markdown","99f2dafa":"markdown","4ada5486":"markdown","7d706cf7":"markdown","82e6db97":"markdown","25ba71e8":"markdown","d2baa70e":"markdown"},"source":{"512b55ee":"import numpy as np\nimport pandas as pd\n\nimport sklearn\n\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt","9f407d4e":"sklearn.__version__","f463f4e3":"data = pd.read_csv(r'..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndata.head()","6d5127e6":"# remove irrelevant variables\ndata = data.drop(\"Id\", axis=1)\ndata.head()","e41f073e":"# create the test set\nfrom sklearn.model_selection import train_test_split\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)","c24a3f39":"train_data.info()","b8e37455":"train_data.shape","4293c442":"# compute the standard correlation coefficient\nhousing = train_data.copy()\n\ncorr_matrix = housing.corr()\ncorr_matrix[\"SalePrice\"].sort_values(ascending=False)","13723bce":"from pandas.plotting import scatter_matrix\nattributes = [\"SalePrice\",\"OverallQual\", \"GrLivArea\", \"GarageCars\", \"GarageArea\", \"TotalBsmtSF\"]\nscatter_matrix(housing[attributes], figsize=(12, 12));","20747851":"# separate the predictors and the labels\nX_train = train_data.drop(\"SalePrice\", axis=1)\ny_train = train_data[\"SalePrice\"].copy()  # save the labels","925d6aeb":"X_train.head()","5140a7da":"y_train.head()","d27783cd":"X_train.dtypes","758d89f3":"X_train.shape","55085214":"X_train['OverallQual'].value_counts()","80be0962":"X_train['ExterQual'].value_counts()","836b628b":"X_train['BsmtFinType1'].value_counts()","d59a9358":"X_train['BsmtFinType2'].value_counts()","52802a12":"X_train['HeatingQC'].value_counts()","88b05f20":"X_train['LowQualFinSF'].value_counts()","89358aa7":"X_train['KitchenQual'].value_counts()","7d774120":"X_train['FireplaceQu'].value_counts()","32d65c17":"X_train['PoolQC'].value_counts()","7d3ec45b":"X_train['Fence'].value_counts()","cfed12bc":"X_train['GarageQual'].value_counts()","01ffed38":"def getOrdinalPip(order):\n    return Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n                             ('encoder', OrdinalEncoder(categories=order,\n                                                        handle_unknown='use_encoded_value', # New in version 0.24\n                                                        unknown_value=-1,)),\n                             ('scaler', StandardScaler())])","66399c53":"ordinal_columns = ['HeatingQC', 'GarageQual','FireplaceQu','KitchenQual','ExterQual']\n# drop all ordinal columns\ndef drop_ordinal(df):\n    X_train_dump = df.drop(columns=ordinal_columns)\n    return X_train_dump    ","a181ce02":"from sklearn.compose import make_column_selector as selector\nfrom sklearn.compose import ColumnTransformer\n\n# a function for getting all categorical_columns\ndef get_categorical_columns(df):\n    categorical_columns_selector = selector(dtype_include=object)\n    categorical_columns = categorical_columns_selector(drop_ordinal(df))\n    return categorical_columns","9019ae32":"# a function for getting all numerical_columns\ndef get_numerical_columns(df):\n    numerical_columns_selector = selector(dtype_exclude=object)\n    numerical_columns = numerical_columns_selector(df)\n    return numerical_columns","5b215481":"get_numerical_columns(X_train)","97c57e80":"get_categorical_columns(X_train)","5459d0d6":"def get_ordinal_pipeline(order):\n    return Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n                             ('encoder', OrdinalEncoder(categories=order,\n                                                        handle_unknown='error',\n                                                        unknown_value=None,)),\n                             ('scaler', StandardScaler())])\n    ","0b621d97":"from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\n# a function for Transformation the data\ndef my_transformation(df):\n    df = df.copy()\n    \n    numerical_columns = get_numerical_columns(df)\n    nominal_columns = get_categorical_columns(df)\n    ordinal_columns = ['GarageQual']\n    ordinal_columns1 = ['FireplaceQu']\n    ordinal_columns2 = ['HeatingQC']\n    order1 = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]\n  \n    ordinal_columns3 = ['KitchenQual']\n    ordinal_columns4 = ['ExterQual']\n    order2 = [['Fa', 'TA', 'Gd', 'Ex']]\n    \n    numerical_pipeline = Pipeline([('imputer', SimpleImputer(strategy='mean')),\n                               ('scaler', StandardScaler())])\n    nominal_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n                             ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n    ordinal_pipeline1 = get_ordinal_pipeline(order1)\n    ordinal_pipeline2 = get_ordinal_pipeline(order2)\n\n    preprocessor = ColumnTransformer([\n        ('numerical_transformer', numerical_pipeline, numerical_columns),\n        ('nominal_transformer', nominal_pipeline, nominal_columns),\n        ('ordinal_transformer', ordinal_pipeline1, ordinal_columns),\n        ('ordinal_transformer1', ordinal_pipeline1, ordinal_columns1),\n        ('ordinal_transformer2', ordinal_pipeline1, ordinal_columns2),\n        ('ordinal_transformer3', ordinal_pipeline2, ordinal_columns3),\n        ('ordinal_transformer4', ordinal_pipeline2, ordinal_columns4),\n    ])\n    \n    preprocessor.fit(df)\n    \n    return preprocessor","1d94250e":"preprocessor= my_transformation(X_train)\nX_train_prepared = preprocessor.transform(X_train)\nX_train_prepared.shape","3131c5f2":"from sklearn.model_selection import GridSearchCV\n\n# a function for tuning the model with hyper-parameter\ndef tune_model(model, param_grid, X_train_prepared):\n    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n    grid_search.fit(X_train_prepared, y_train);\n    print('grid_search.best_estimator_: ', grid_search.best_estimator_)\n    final_model = grid_search.best_estimator_\n    return final_model","6307dc9a":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\n\ndef showPerformance(clf):\n    y_train_pred = clf.predict(X_train_prepared)\n    \n    print(\"RMSE train: \", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n    scores = cross_val_score(lin_reg, X_train_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=3)\n    lin_rmse_scores = np.sqrt(-scores)\n    print(\"Validation score RMSE Mean:\", lin_rmse_scores.mean(), \"; Standard deviation:\", lin_rmse_scores.std())\n    print(\"Training set score: {:.2f}\".format(clf.score(X_train_prepared, y_train)))","3d5f9d9c":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train_prepared, y_train);\nshowPerformance(lin_reg)","f6d37b9b":"from sklearn.linear_model import RidgeCV\nridge = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1, 10], cv=5).fit(X_train_prepared, y_train)\n\nprint(\"alpha = \", ridge.alpha_)\nshowPerformance(ridge)","17119ad4":"from sklearn.linear_model import LassoCV\nlasso = LassoCV(alphas=[1e-3, 1e-2, 1e-1, 1, 10], max_iter=10000, cv=5).fit(X_train_prepared, y_train)","75ce0d43":"print(\"alpha = \", lasso.alpha_)\nprint(\"Number of features used:\", np.sum(lasso.coef_ != 0))\nshowPerformance(lasso)","b961fc3f":"from sklearn.linear_model import ElasticNet\nelastic =  ElasticNet(max_iter=1e7)\nelastic.fit(X_train_prepared, y_train)\n\nshowPerformance(elastic)","8f223dee":"param_grid = {\n            'alpha'     : [0.1, 1, 10, 0.01],\n            'l1_ratio'  :  np.arange(0.40,1.00,0.10),\n            'tol'       : [0.0001,0.001]\n            }\n\nfinal_model_elastic = tune_model(elastic, param_grid, X_train_prepared)\n","a9784977":"showPerformance(final_model_elastic)","1caf59d9":"from sklearn.ensemble import VotingRegressor\n\ner = VotingRegressor([('ridge', ridge), ('lasso', lasso)], weights=[1,2])\ner.fit(X_train_prepared, y_train)\n\nshowPerformance(er)","e4e89ba2":"X_test = test_data.drop(\"SalePrice\", axis=1)\ny_test = test_data[\"SalePrice\"].copy()\nX_test.shape","29c7f21c":"X_test_prepared = preprocessor.transform(X_test) \nX_test_prepared.shape","bf76d1bf":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import median_absolute_error\nfrom sklearn.metrics import mean_absolute_percentage_error # New in version 0.24\n# show the model permormance on test data\ndef perfor_test(model):\n    y_test_predicted = model.predict(X_test_prepared)\n    print(f\"Mean absolute error (MAE): \" f\"{mean_absolute_error(y_test, y_test_predicted):.4f} $\")\n    print(f\"Median absolute error (MedAE): \" f\"{median_absolute_error(y_test, y_test_predicted):.4f} $\")\n    print(f\"Mean absolute percentage error (MAPE): \" f\"{mean_absolute_percentage_error(y_test, y_test_predicted) * 100:.4f} %\")","4d0ef147":"perfor_test(lin_reg)","75532b2c":"perfor_test(lasso)","b60a2c4b":"perfor_test(ridge)","dd54b31a":"perfor_test(er)","058ce93a":"perfor_test(elastic)","e29a27fb":"import seaborn as sns\n# plot the regression\ndef plot_reg(model):\n    y_test_predicted = model.predict(X_test_prepared)\n    predicted_actual = {\"True values ($)\": y_test, \"Predicted values ($)\": y_test_predicted}\n    predicted_actual = pd.DataFrame(predicted_actual)\n    \n    sns.scatterplot(data=predicted_actual,\n                     x=\"True values ($)\", y=\"Predicted values ($)\",\n                     color=\"black\", alpha=0.5)\n    plt.axline((0, 0), slope=1, label=\"Perfect fit\")\n    plt.axis('square')\n    plt.title(\"Regression using a model without \\ntarget transformation\");","a5029a36":"plot_reg(er)","710afd93":"from sklearn.preprocessing import QuantileTransformer\nfrom sklearn.compose import TransformedTargetRegressor\n\ndef target_transform(model):\n    quantile_transformer = QuantileTransformer(n_quantiles=900, output_distribution=\"normal\")\n    model_transformed_target = TransformedTargetRegressor(regressor=model,\n                                transformer=quantile_transformer)\n\n    model_transformed_target.fit(X_train_prepared, y_train)\n    return model_transformed_target","0f72dd30":"perfor_test(target_transform(lasso))","6c8954bc":"perfor_test(target_transform(er))","549f44f9":"plot_reg(target_transform(lasso))","871dc10a":"test = pd.read_csv(r'..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nID = test[\"Id\"]\ntest = test.drop(\"Id\", axis=1)\ntest.shape","79e063d8":"ID.shape","bb45eb6d":"test_prepared = preprocessor.transform(test) \ntest_prepared.shape","ff06efbc":"prediction = target_transform(er).predict(test_prepared)\nprediction = pd.DataFrame(data={\"Id\":ID,\"SalePrice\":prediction}).to_csv('prediction.csv', index= False)","ae6a9954":"res = pd.read_csv(r'..\/input\/prediction\/prediction.csv')\nres.head()","9dd47f35":"### Output predictions","2cfb74af":"- The model tends to under-estimate the price of the house.","4f77a1c2":"### Select one machine learning model, train, optimise","74e94055":"#### Use ElasticNet","868bced7":"### Test model performance on test data","03b3411a":"The dataset contains a mixture of categorical and numerical columns, `dtypes: float64(3), int64(34), object(43)`. There are continuous, nominal, and ordinal data types.\nIt also has missing data which indicates we need to apply transformation `ColumnTransformer` for different columns of data.  \n\nFor continuous columns, use `SimpleImputer` with `strategy='mean'` to handle missing values, then apply `StandardScaler` to normalize data.\n\nFor ordinal columns and norminal columns, use `SimpleImputer` with `strategy='most_frequent` to handle missing values, and use `OrdinalEncoder` and `OneHotEncoder` to convert categorical values to numerical values.","0b55faa7":"### Explore the training set to gain insights","9e0e50ba":"#### Apply a target transformation","17cff102":"### Load the dataset","99f2dafa":"#### Use LassoCV","4ada5486":"### Identify all ordinal_columns: all quality related","7d706cf7":"#### Use VotingRegressor","82e6db97":"#### Train a Linear Regression model","25ba71e8":"- There is a positive correlation between the `SalePrice` and `OverallQual`, `GrLivArea`, `GarageCar` and  `GarageArea`.","d2baa70e":"#### Use RidgeCV"}}