{"cell_type":{"4cfba306":"code","49d1eb8a":"code","adb62183":"code","4bcf8c7c":"code","5bd98b88":"code","6120428e":"code","86e4eb4e":"code","c1e0178f":"code","41ee0825":"code","4de42807":"code","c17a5100":"code","a482859f":"code","349c0372":"code","64e068bf":"code","dc587262":"code","ada1673e":"markdown","05af62ea":"markdown","0b51a8d7":"markdown","37596657":"markdown","d6ec93c8":"markdown","593f83e1":"markdown","57e26217":"markdown","59dd5dd5":"markdown","82bed1e2":"markdown","9bd456f0":"markdown"},"source":{"4cfba306":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.utils import shuffle\nfrom sklearn.utils.extmath import softmax\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\nfrom torch.utils.data import Subset\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\n\nimport os\nimport cv2\nimport math","49d1eb8a":"class RPSDataset(Dataset):\n    def __init__(self, path):\n        self.features, self.labels = self.get_features_labels(path)\n        categories = ['rock', 'paper', 'scissors']\n        self.cat_to_idx = {v:k for k,v in enumerate(categories)}\n        self.idx_to_cat = {k:v for k,v in enumerate(categories)}\n        \n    def get_features_labels(self, path):\n        lst = [path + p for p in os.listdir(path)]\n        dir_lst = []\n        for i in range(len(lst)):\n            dir_lst += [[lst[i] + \"\/\" + p, lst[i].split('\/')[-1]] \n                                for p in os.listdir(lst[i])]\n\n        dir_lst = np.array(dir_lst)\n        features = dir_lst[:,0]\n        labels = dir_lst[:,1]\n\n        features, labels = shuffle(features, labels)\n        return features, labels\n    \n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, idx):\n        dim = (28, 28)\n        image = cv2.imread(self.features[idx]) \n        image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n        \n        label = rps_ds.cat_to_idx[self.labels[idx]]\n        label = np.eye(3)[label]\n        \n        return image.tolist(), label","adb62183":"path = '..\/input\/rock-paper-scissor\/rps\/rps\/'\n\nrps_ds = RPSDataset(path)","4bcf8c7c":"img, lbl = rps_ds[0]","5bd98b88":"plt.imshow(img)","6120428e":"rps_ds.idx_to_cat[np.argmax(lbl)]","86e4eb4e":"def collate_fn(batch):\n    features, labels = list(map(list, zip(*batch)))\n    return np.array(features), np.array(labels)\n\n\ntrain_idx, test_idx = train_test_split(np.arange(len(rps_ds)), test_size=0.33)\ntrain_dataset = Subset(rps_ds, train_idx)\ntest_dataset = Subset(rps_ds, test_idx)\n\ntrain_dl = DataLoader(train_dataset, batch_size=4, collate_fn=collate_fn,\n                        shuffle=True, num_workers=0)\ntest_dl = DataLoader(test_dataset, batch_size=len(test_dataset), collate_fn=collate_fn,\n                        shuffle=True, num_workers=0)","c1e0178f":"def batchnorm_forward(x,gamma,beta):    \n    # x is size (m,w,h,c)\n    # Gamma is size of (C,)\n    # Beta is size of (C.) \n    m,h,w,c = x.shape\n    N = (m*h*w)\n    mu = (1.\/N) * np.sum(x,axis=(0,1,2),keepdims = True)\n    sigma = (1.\/N) * np.sum((x - mu) ** 2,axis=(0,1,2),keepdims=True) \n    xhat = (x - mu)\/(np.sqrt(sigma+1e-8))\n    y = gamma.reshape(1,1,1,c) * xhat + beta.reshape(1,1,1,c)\n    cache = (x,mu,sigma,xhat,y,gamma,beta)\n    return xhat,cache\n\n\ndef batchnorm_backward(dout,cache):\n    # computes the graidents for batchnorm\n    x,mu,sigma,xhat,y,gamma,beta = cache\n    m,h,w,c = x.shape\n    gamma = gamma.reshape(1,1,1,c)\n    dbeta = np.sum(dout, axis=(0, 1, 2))\n    dgamma = np.sum(dout * xhat, axis=(0, 1, 2))\n    Nt = m*h*w\n    dxhat = dout * gamma\n    dsigma = np.sum(dxhat * (x-mu),axis=(0,1,2)).reshape(1,1,1,c) * -0.5 * (sigma+1e-8) ** -1.5\n    dmu = np.sum(dxhat * (-1.0\/np.sqrt(sigma+1e-8)), axis=  (0,1,2)).reshape(1,1,1,c) + dsigma * np.sum(-2 * (x-mu),axis=(0,1,2)).reshape(1,1,1,c)\/Nt\n    dx = dxhat * (1.0\/np.sqrt(sigma+1e-8)) + dsigma * (2.0* (x-mu))\/Nt + dmu * (1.\/Nt)\n \n    return dx,dgamma,dbeta","41ee0825":"np.random.seed(324)\n\ngamma = np.ones(3)\nbeta = np.zeros(3)\n\nscale = 1\/max(1., (2+2)\/2.)\nlimit = math.sqrt(3.0 * scale)\n\nw1 = np.random.uniform(-limit, limit, size=(2352,128))\nw2 = np.random.uniform(-limit, limit, size=(128,32))\nw3 = np.random.uniform(-limit, limit, size=(32,3))\n\ndelta = w1, w2, w3, gamma, beta","4de42807":"def sigmoid(x):\n    return 1. \/ (1. + np.exp(-x))\n\ndef dsigmoid(x):\n    return sigmoid(x) * (1. - sigmoid(x))","c17a5100":"def train(X, y, delta, lr=0.005):\n    w1, w2, w3, gamma, beta = delta\n    \n    # forward\n    xhat, cache = batchnorm_forward(X, gamma, beta)\n    flat = xhat.reshape(len(xhat), -1)\n\n    l1 = flat @ w1\n    l1_a = sigmoid(l1)\n\n    l2 = l1_a @ w2\n    l2_a = sigmoid(l2)\n\n    l3 = l2_a @ w3\n    r = softmax(l3)\n\n    # loss\n    loss = mean_squared_error(r, y)\n    acc = len(np.where(np.argmax(r, axis=1) \n                == np.argmax(y, axis=1))[0]) \/ len(y)\n\n    # backward\n    dy = r - lbls\n    dl3 = w3.dot(dy.T)\n\n    dl2_a = dsigmoid(l2)\n    dl1_a = dsigmoid(l1)\n\n    dw3 = l2_a.T.dot(dy)\n    dw2 = l1_a.T.dot(dl3.T * dl2_a)\n\n    dl2 = w2.dot((dl3.T * dl2_a).T)\n    dw1 = flat.T.dot(dl2.T * dl1_a)\n    dl1 = w1.dot((dl2.T * dl1_a).T).T\n    dout = dl1.reshape(dl1.shape[0], 28, 28, 3)\n\n    dx,dgamma,dbeta = batchnorm_backward(dout,cache)\n\n    # update\n    w1 -= dw1 * lr\n    w2 -= dw2 * lr\n    w3 -= dw3 * lr\n\n    gamma -= dgamma * lr\n    beta -= dbeta * lr\n    \n    delta = w1, w2, w3, gamma, beta\n    \n    return loss, acc, delta","a482859f":"nr_epochs = 10\n\nepoch_losses = []\nepoch_accs = []\nfor epoch in range(nr_epochs):\n    \n    losses, accs = [], []\n    for imgs, lbls in train_dl:\n\n        loss, acc, delta = train(imgs, lbls, delta, lr=0.005)\n        losses.append(loss)\n        accs.append(acc)\n\n\n    epoch_losses.append(losses)\n    epoch_accs.append(accs)\n    print('Epoch:{:3d}, Mean_Loss:{:1.3f}, Mean_Accuracy:{:1.3f}'\n            .format(epoch+1, np.array(losses).mean(), np.array(accs).mean()))","349c0372":"plt.figure(figsize=(16,8))\nplt.plot(np.array(epoch_losses).mean(axis=1), label='Mean Losses')\nplt.plot(np.array(epoch_accs).mean(axis=1), label='Mean Accuracies')\nplt.legend(loc=\"upper left\")","64e068bf":"def forward(X, y, delta, lr=0.005):\n    w1, w2, w3, gamma, beta = delta\n    \n    # forward\n    xhat, cache = batchnorm_forward(X, gamma, beta)\n    flat = xhat.reshape(len(xhat), -1)\n\n    l1 = flat @ w1\n    l1_a = sigmoid(l1)\n\n    l2 = l1_a @ w2\n    l2_a = sigmoid(l2)\n\n    l3 = l2_a @ w3\n    r = softmax(l3)\n\n    # loss\n    loss = mean_squared_error(r, y)\n    acc = len(np.where(np.argmax(r, axis=1) \n                == np.argmax(y, axis=1))[0]) \/ len(y)\n    \n    return r, loss, acc","dc587262":"X, y = next(iter(test_dl))\nr, loss, acc =  forward(X, y, delta)\nprint('Valid_Loss:{:1.3f}, Valid_Accuracy:{:1.3f}'\n          .format(loss, acc))","ada1673e":"<div>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/408863\/783233\/1bb8f2dc05690a85fc206715e96539e7\/dataset-cover.jpg\"\/>\n<\/div>","05af62ea":"<h1 id=\"activation\" style=\"color:#cb9a96; border: 1px dotted #cb9a96;\"> \n    <center>Activation Function\n        <a class=\"anchor-link\" href=\"#activation\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","0b51a8d7":"Spatial batchnorm implementation - [Medium Sam Kirkiles](https:\/\/medium.com\/samkirkiles\/spatial-batchnorm-backprop-implementation-notes-8ccde1ac62a2)","37596657":"<h1 id=\"reference\" style=\"color:#cb9a96; border: 1px dotted #cb9a96;\"> \n    <center>Reference\n        <a class=\"anchor-link\" href=\"#reference\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","d6ec93c8":"<h1 id=\"weights\" style=\"color:#cb9a96; border: 1px dotted #cb9a96;\"> \n    <center>Parameters\n        <a class=\"anchor-link\" href=\"#weights\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","593f83e1":"<h1 id=\"train\" style=\"color:#cb9a96; border: 1px dotted #cb9a96;\"> \n    <center>Train\n        <a class=\"anchor-link\" href=\"#train\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","57e26217":"<h1 id=\"batchnorm\" style=\"color:#cb9a96; border: 1px dotted #cb9a96;\"> \n    <center>Spatial Batchnorm\n        <a class=\"anchor-link\" href=\"#batchnorm\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","59dd5dd5":"<h1 id=\"analyze\" style=\"color:#cb9a96; border: 1px dotted #cb9a96;\"> \n    <center>Analyze\n        <a class=\"anchor-link\" href=\"#analyze\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","82bed1e2":"<h1 id=\"dataset\" style=\"color:#cb9a96; border: 1px dotted #cb9a96;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","9bd456f0":"<h1 id=\"validation\" style=\"color:#cb9a96; border: 1px dotted #cb9a96;\"> \n    <center>Validation\n        <a class=\"anchor-link\" href=\"#validation\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>"}}