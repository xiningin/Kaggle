{"cell_type":{"069f5817":"code","2fe81471":"code","93e71905":"code","799c36c2":"code","94ada921":"code","ed2b94d6":"code","66c24cd5":"code","5ee5bdc5":"code","9fd2493c":"markdown","e30fefa4":"markdown","83ef5588":"markdown","02d619c4":"markdown","209296fb":"markdown"},"source":{"069f5817":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nimport xml.etree.ElementTree as ET\nfrom numpy import random\nimport zipfile\nprint(os.listdir(\"..\/input\"))","2fe81471":"import glob\nimage = glob.glob('..\/input\/all-dogs\/all-dogs\/*')\nbreed = glob.glob('..\/input\/annotation\/Annotation\/*')\nannot = glob.glob('..\/input\/annotation\/Annotation\/*\/*')\nprint(len(image), len(breed), len(annot))","93e71905":"def get_bbox(annot):\n    \"\"\"\n    This extracts and returns values of bounding boxes\n    \"\"\"\n    xml = annot\n    tree = ET.parse(xml)\n    root = tree.getroot()\n    objects = root.findall('object')\n    bbox = []\n    for o in objects:\n        bndbox = o.find('bndbox')\n        xmin = int(bndbox.find('xmin').text)\n        ymin = int(bndbox.find('ymin').text)\n        xmax = int(bndbox.find('xmax').text)\n        ymax = int(bndbox.find('ymax').text)\n        bbox.append((xmin,ymin,xmax,ymax))\n    return bbox","799c36c2":"def get_image(annot):\n    \"\"\"\n    Retrieve the corresponding image given annotation file\n    \"\"\"\n    img_path = '..\/input\/all-dogs\/all-dogs\/'\n    file = annot.split('\/')\n    img_filename = img_path+file[-1]+'.jpg'\n    return img_filename","94ada921":"# initialize tensor for dog images\nn_x = 64\nn_c = 3\ndogs = np.zeros((len(image), n_x, n_x, n_c))\nprint(dogs.shape)","ed2b94d6":"for a in range(len(image)):\n    bbox = get_bbox(annot[a])\n    dog = get_image(annot[a])\n    if dog == '..\/input\/all-dogs\/all-dogs\/n02105855_2933.jpg':   # this jpg is not in the dataset\n        continue\n    im = Image.open(dog)\n    im = im.crop(bbox[0])\n    im = im.resize((64,64), Image.ANTIALIAS)\n    dogs[a,:,:,:] = np.asarray(im) \/ 255.","66c24cd5":"# pick some images randomly from dogs and look at these\nplt.figure(figsize=(15,8))\nn_images = 60\nselect = random.randint(low=0,high=dogs.shape[0],size=n_images)\nfor i, index in enumerate(select):  \n    plt.subplot(6, 10, i+1)\n    plt.imshow(dogs[index])\n    plt.axis('off')\nplt.subplots_adjust(wspace=0.3, hspace=-0.1)\nplt.show()","5ee5bdc5":"z = zipfile.PyZipFile('images.zip', mode='w')\nfor d in range(10000):\n    dog_image = Image.fromarray((255*dogs[d]).astype('uint8').reshape((64,64,3)))\n    f = str(d)+'.png'\n    dog_image.save(f,'PNG')\n    z.write(f)\n    os.remove(f)\nz.close()","9fd2493c":"# Introduction","e30fefa4":"This is a follow-on from my [Reference 2][1] which looked the dog images, annotation files, bounding boxes etc.\n\nHere is a kernel where I crop and load the dog images into tensors ready for use by the neural networks in GAN. I did not managed to load all the possible cropped images though, just 20k plus....\n\nI have also included codes to load images into a zip file \"image.zip\" for submission purposes.\n\n[1]: https:\/\/www.kaggle.com\/rhodiumbeng\/crop-dog-images","83ef5588":"# Crop images to bounding boxes, and load","02d619c4":"# Create zip file to store the images","209296fb":"Started on 8 July 2019\n\n**References:**\n1. https:\/\/www.kaggle.com\/cdeotte\/supervised-generative-dog-net\n2. https:\/\/www.kaggle.com\/rhodiumbeng\/crop-dog-images"}}