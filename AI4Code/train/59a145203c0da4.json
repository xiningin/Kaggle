{"cell_type":{"453a5a37":"code","0eb31fdc":"code","67f37b91":"code","31b859b7":"code","be084076":"code","63cb5214":"code","6a53daca":"code","72a56833":"code","f394cee4":"code","4b50363f":"code","564b989b":"code","344793ad":"code","3e3b0f77":"code","db2d4bc3":"code","54abb0c9":"code","b56213f1":"code","7595ba26":"code","ab0d40e9":"code","49a8f98b":"code","01be1f52":"code","c90ec295":"code","528921cf":"code","4d3f1224":"markdown","d6239268":"markdown","822f02c0":"markdown","a4cd007c":"markdown","a98a2866":"markdown","986ff5fe":"markdown","81190931":"markdown"},"source":{"453a5a37":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0eb31fdc":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import style\n\nstyle.use('fivethirtyeight')\n\ndf = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\nprint(df.shape, test.shape)","67f37b91":"df.info()","31b859b7":"x = [col for col in df.columns]\ny = []\nfor col in df.columns:\n    i = df[col].isnull().sum()\n    y.append(i)\n# print(x)    \n# print(y)\nf = plt.subplots(figsize=(20,5))\nplt.bar(x,y)","be084076":"# find the corelation between features\ncorel = df.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corel)","63cb5214":"# plotting all the numerical features against the sales price\nf, ax = plt.subplots(figsize=(20,20))\nnum_cols = [col for col in df.columns if df[col].dtype == 'int64' or df[col].dtype == 'float64']\npos = 0\nfor col in num_cols:\n    pos = pos+1\n    ax = plt.subplot(3, 3, pos)\n    plt.plot(df['Fare'], df[col], 'o')\n    plt.xlabel('Fare')\n    plt.ylabel(col)    ","6a53daca":"df.head()","72a56833":"df['name_len'] = df['Name'].apply(lambda x : len(x))\ndf['Survived'].groupby(pd.qcut(df['name_len'], 5)).mean()","f394cee4":"df['tick_len'] = df['Ticket'].apply(lambda x : len(x))\ndf['Survived'].groupby(pd.qcut(df['tick_len'], 4)).mean()","4b50363f":"df['tick_let'] = df['Ticket'].apply(lambda x : x[ :1]).apply(lambda x: x.split()[0])\ndf['tick_let'].value_counts()","564b989b":"df['Name_Title'] = df['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x : x.split()[0])\ndf['Name_Title'].value_counts()\ndf['Survived'].groupby(df['Name_Title']).mean()","344793ad":"def name_ticket_length(train, test):\n    for i in (train, test):\n            i['name_len'] = i['Name'].apply(lambda x : len(x))\n            i['tick_len'] = i['Ticket'].apply(lambda x: len(x))\n            i['tick_lett'] = i['Ticket'].apply(lambda x : x[ :1])\n            i['name_tit'] = i['Name'].apply(lambda x : x.split(',')[1]).apply(lambda x : x.split()[0])\n            \n    return train, test\n\n\ndf = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest1 = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n# test1 = pd.read_csv('titanic_test.csv')\ntest = test1.copy()\n\nname_ticket_length(df, test)\n\ny = df['Survived']\nfeature_cols = ['Pclass', 'Sex', 'Age', 'SibSp','Parch', \n                'Fare', 'Embarked', 'name_len', 'tick_len','tick_lett', 'name_tit']\ntrain = df[feature_cols]\ntest = test[feature_cols]\nprint(train.shape, test.shape)\n","3e3b0f77":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(train, y, train_size = 0.8, test_size = 0.2, random_state = 42)\nprint('X - Train : ',X_train.shape)\nprint('Y - Train : ',y_train.shape)\nprint('X - Valid : ',X_valid.shape)\nprint('y - Valid : ',y_valid.shape)","db2d4bc3":"X_train.dtypes\ncat_cols = [col for col in X_train.columns if X_train[col].dtypes == 'object']\ncat_cols\nnum_cols = [col for col in X_train.columns if (X_train[col].dtypes == 'int64') or (X_train[col].dtypes == 'float64')]\nprint(cat_cols)\nprint(num_cols)","54abb0c9":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# processing of numerical values\nnum_preprocessor = SimpleImputer(strategy= 'mean')\n\n# processing of catagorial values\ncat_preprocessor = Pipeline(steps = [\n    ('impute', SimpleImputer(strategy = 'most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n])\n# Bundle processing\nbundle_preprocess = ColumnTransformer(transformers = [\n    ('nums',num_preprocessor, num_cols),\n    ('cats',cat_preprocessor, cat_cols)\n])\n\n\nclf = Pipeline(steps = [\n    ('preprocessor', bundle_preprocess),\n    ('model', RandomForestClassifier(n_estimators = 400, max_features='auto', oob_score=True, random_state=1, n_jobs=-1))\n])\n\n# print(RandomForestClassifier.oob_score_)rf","b56213f1":"from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\nclf.fit(X_train, y_train)\nprediction = clf.predict(X_valid)\n\ncm = confusion_matrix(y_valid, prediction)\nprint('Confusion Matrix : \\n',cm)\n\nf1_score = f1_score(y_valid, prediction)\nprint('F1 Score : \\n', f1_score)\nscore = accuracy_score(y_valid,prediction)\nprint('Accuracy : ', score)\n\n# print(prediction)","7595ba26":"test_preds = clf.predict(test)\ntest_preds.shape","ab0d40e9":"result_titanic = pd.DataFrame({'PassengerId' : test1['PassengerId'],\n                              'Survived' : test_preds })\nresult_titanic.head()\nresult_titanic.to_csv('submission.csv')","49a8f98b":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\n# processing of numerical values\nnum_preprocessor = SimpleImputer(strategy= 'mean')\n\n# processing of catagorial values\ncat_preprocessor = Pipeline(steps = [\n    ('impute', SimpleImputer(strategy = 'most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n])\n# Bundle processing\nbundle_preprocess = ColumnTransformer(transformers = [\n    ('nums',num_preprocessor, num_cols),\n    ('cats',cat_preprocessor, cat_cols)\n])\n\nC_range = [0.001, .050, 0.009, 0.01,0.02, 0.1]\n\n\nresult_table = pd.DataFrame(columns = ['C_range', 'Accuracy'])\nresult_table['C_range'] = C_range\nj = 0\nfor i in C_range:\n    clf = Pipeline(steps = [\n        ('preprocessor', bundle_preprocess),\n        ('model', LogisticRegression(penalty = 'l2',solver = 'lbfgs', C = i, max_iter = 500))\n    ])\n    clf.fit(X_train, y_train)\n    prediction = clf.predict(X_valid)\n    score = accuracy_score(y_valid,prediction)\n#     print(\"C-Range: {} : accuracy = {}\".format(i,score))\n    result_table.iloc[j , 1] = score\n    j +=1\nresult_table\n# print(RandomForestClassifier.oob_score_)rf","01be1f52":"best_clf = Pipeline(steps = [\n            ('preprocessor', bundle_preprocess),\n            ('model', LogisticRegression(penalty = 'l2',solver = 'lbfgs', C = 0.009, max_iter = 500))\n            ])\n\nbest_clf.fit(X_train, y_train)\nprediction = best_clf.predict(X_valid)\nscore = accuracy_score(y_valid,prediction)\nprint('accuracy = ',score)","c90ec295":"logestic_prediction = best_clf.predict(test)\nlen(logestic_prediction)","528921cf":"submission = np.array(test1['PassengerId'])\nsubmission.shape\n\nsub_results_logesticR = pd.DataFrame({'PassengerId' : submission, \n                                      'Survived' : logestic_prediction})\n# sub_results\nsub_results_logesticR.to_csv('titanic_submission_logestic_reg.csv')","4d3f1224":"Lets start with Model Selection.. I'll import the csv's again, just to not have scroll back and forth.","d6239268":"Quick Information on the counts, and importantly gives an insite on null columns.","822f02c0":"Graphical rep of null values","a4cd007c":"Using the value of C that provided the best Accuracy","a98a2866":"Finding Accuracy using Logestic regression and Hyperparameters","986ff5fe":"Hmm.. seems like the longer the name, higher is the survival rate. I'll keep the length column.\nLet's see if the lenght of the ticket makes any sense..","81190931":"The name column in itself does not seem to be of help. I will be extracting the length and the title of the names to see if it can be used in anyway."}}