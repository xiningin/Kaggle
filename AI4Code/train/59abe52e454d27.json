{"cell_type":{"3f1e21dd":"code","666fb158":"code","87c78709":"code","b4eea9f7":"code","8dfa0c96":"code","4d324e52":"code","6eff20f3":"code","6e8da81e":"code","723a5f76":"code","48556b18":"code","0f1b10a9":"code","22520f96":"code","b085f2df":"code","16139e4b":"code","17f077fc":"code","67506c8e":"code","e1fb048a":"code","f4ae1229":"code","04f6eaac":"code","11eba9ac":"code","0c8e7e09":"code","783c26c9":"code","611c026b":"code","83fc6986":"code","ee3619e2":"code","9055df48":"code","2e6c6ff2":"code","834d1197":"code","54d9696b":"code","e48fb746":"code","f16e3ef0":"code","72526e17":"code","fb99e174":"code","d9b0b126":"code","7dad7399":"code","de9c8fbc":"code","a284eabf":"code","0ef37436":"code","1a0d372b":"code","081f6615":"code","f8754c50":"code","ed26bd53":"code","1ef1879f":"markdown","58ccf181":"markdown","6a34b3c9":"markdown","bd0d5a06":"markdown","9e8d33a8":"markdown","9fb058cd":"markdown","cc6673b1":"markdown","4951672d":"markdown","062eac7a":"markdown","2d30d1d9":"markdown","a2d03ce1":"markdown","f0ae0bb7":"markdown","7c37152c":"markdown","d30f346b":"markdown","5db0471f":"markdown","8d12f4f1":"markdown","d1658d63":"markdown","2d819c25":"markdown"},"source":{"3f1e21dd":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","666fb158":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if filename.endswith(\".csv\"):\n            print(os.path.join(dirname, filename))","87c78709":"base_path=\"\/kaggle\/input\/applications-of-deep-learning-wustl-fall-2020\/final-kaggle-data\"\nsubmission_file=\"\/kaggle\/input\/applications-of-deep-learning-wustl-fall-2020\/final-kaggle-data\/submit.csv\"\ntest_path=\"\/kaggle\/input\/applications-of-deep-learning-wustl-fall-2020\/final-kaggle-data\/test.csv\"\ntrain_path=\"\/kaggle\/input\/applications-of-deep-learning-wustl-fall-2020\/final-kaggle-data\/train.csv\"","b4eea9f7":"train_data=pd.read_csv(train_path)\ntest_data=pd.read_csv(test_path)","8dfa0c96":"train_data.head()","4d324e52":"test_data.head()","6eff20f3":"submission=pd.read_csv(submission_file)","6e8da81e":"submission.head()","723a5f76":"def remove_defected_images(ids,labels,to_remove):\n    defected = []\n    for i,img_id in enumerate(ids):\n        if img_id in to_remove:\n            defected.append(img_id)\n            ids = np.delete(ids,i)\n            labels = np.delete(labels,i)\n    return defected,ids,labels","48556b18":"def check_and_remove_defected_images(ids,labels):\n    defected = []\n    for i,img_id in enumerate(ids):\n        try:\n            image = tf.io.read_file(get_path_of_image(img_id))\n            image = tf.image.decode_png(image,channels=3)\n        except:\n            defected.append(img_id)\n            ids = np.delete(ids,i)\n            labels = np.delete(labels,i)\n    return defected,ids,labels","0f1b10a9":"defected,dataX,dataY = remove_defected_images(train_data.iloc[:,0].values,\n                                                train_data.iloc[:,1].values,\n                                                [1300])\nprint(\"Train Elements Defected: \",defected)","22520f96":"trainX,evalX,trainY,evalY = train_test_split(dataX,\n                                             dataY,\n                                             random_state=11,\n                                             test_size=0.1\n                                            )","b085f2df":"testX = test_data.iloc[:,0].values","16139e4b":"num_train_images = len(trainX)\nnum_eval_images=len(evalX)","17f077fc":"print(\"Number of train images: \",num_train_images)\nprint(\"Number of eval images: \",num_eval_images)\nprint(\"Number of test images: \",len(testX))","67506c8e":"EPOCHS=50\nBATCH_SIZE=32\nIMAGE_DIM=(192,192)","e1fb048a":"def get_path_of_image(image_id):\n    return os.path.join(base_path,f\"{image_id}.png\")","f4ae1229":"def load_tf_image(image_path,dim):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image,channels=3)\n    image = tf.image.resize(image,dim)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = image\/255.0\n    return image","04f6eaac":"def generate_tf_dataset(X,Y,image_size):\n    X = [get_path_of_image(str(x)) for x in X]\n    datasetX = tf.data.Dataset.from_tensor_slices(X).map(\n            lambda path: load_tf_image(path,image_size),\n            num_parallel_calls=tf.data.experimental.AUTOTUNE\n    )\n    datasetY = tf.data.Dataset.from_tensor_slices(Y)\n    dataset = tf.data.Dataset.zip((datasetX,datasetY))\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n    return dataset","11eba9ac":"def plot_images_grid(data,num_rows=1,labels=None,class_names=None):\n    images, labels = data\n    n=len(images)\n    if n > 1:\n        num_cols=np.ceil(n\/num_rows)\n        fig,axes=plt.subplots(ncols=int(num_cols),nrows=int(num_rows))\n        axes=axes.flatten()\n        fig.set_size_inches((20,20))\n        for i,image in enumerate(images):\n            axes[i].axis('off')\n            axes[i].imshow(image.numpy())\n            label = labels[i].numpy()\n            axes[i].set_title(class_names[label])","0c8e7e09":"train_dataset=generate_tf_dataset(trainX,trainY,IMAGE_DIM)\nprint(train_dataset.element_spec)","783c26c9":"eval_dataset=generate_tf_dataset(evalX,evalY,IMAGE_DIM)\nprint(eval_dataset.element_spec)","611c026b":"class_names=[\"not stable\",\"stable\"]","83fc6986":"plot_images_grid(next(iter(train_dataset.take(1))),class_names=class_names,num_rows=4)","ee3619e2":"plot_images_grid(next(iter(eval_dataset.take(1))),class_names=class_names,num_rows=4)","9055df48":"pretrained= tf.keras.applications.InceptionResNetV2(\n                include_top=False, weights='imagenet',input_shape=(*IMAGE_DIM,3)\n            )","2e6c6ff2":"pretrained.trainable=True","834d1197":"model = tf.keras.Sequential([\n    pretrained,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n])","54d9696b":"model.summary()","e48fb746":"model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])","f16e3ef0":"LR_START = 0.00001\nLR_MAX = 0.00005\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 0\nLR_EXP_DECAY = .8\n\ndef change_lr(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n","72526e17":"checkpoint_path=\"best_checkpoint\"","fb99e174":"model_checkpoint=tf.keras.callbacks.ModelCheckpoint(checkpoint_path,monitor=\"val_accuracy\",\n                                                    save_best_only=True,mode=\"max\",\n                                                    save_weights_only=True,\n                                                    verbose=1)\nearly_stop=tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=10,\n                                            mode=\"max\",verbose=1)\nchange_lr = tf.keras.callbacks.LearningRateScheduler(change_lr, verbose=True)","d9b0b126":"callbacks=[model_checkpoint,early_stop,change_lr]","7dad7399":"history=model.fit(train_dataset,\n                  epochs=EPOCHS,\n                  steps_per_epoch=num_train_images\/\/BATCH_SIZE,\n                  validation_data=eval_dataset,\n                  validation_steps=num_eval_images\/\/BATCH_SIZE,\n                  callbacks=callbacks)","de9c8fbc":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","a284eabf":"if os.path.isfile(checkpoint_path):\n    model.load_weights(checkpoint_path)","0ef37436":"test_images_path = [get_path_of_image(str(x)) for x in testX]\ntest_dataset = tf.data.Dataset.from_tensor_slices(test_images_path).map(\n        lambda path: load_tf_image(path,IMAGE_DIM),\n        num_parallel_calls=tf.data.experimental.AUTOTUNE\n)\ntest_dataset=test_dataset.batch(BATCH_SIZE)\ntest_dataset=test_dataset.prefetch(tf.data.experimental.AUTOTUNE)","1a0d372b":"predictions = model.predict(test_dataset,verbose=1)","081f6615":"predictions= np.squeeze(predictions,axis=1)","f8754c50":"predictions.shape","ed26bd53":"submission.stable = predictions\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","1ef1879f":"Splitting data into training and evaluation","58ccf181":"predicting test data using test dataset and saving results in`predictions`","6a34b3c9":"## Predicting Stable Structures\n\nThis is starter notebook for tensorflow users for this competition. It uses tf.data for loading data for training and model is trained using transfer learning.","bd0d5a06":"Loading best model checkpoint","9e8d33a8":"model training happens here with fit method. It takes tf datasets and steps.","9fb058cd":"Saving predictions is submission.csv file.","cc6673b1":"Importing required dependencies","4951672d":"Callbacks for:\n- model_checkpointing- For checpointing model with best validation accuracy.\n- early_stop- Stop training of model if model's validation accuracy did not improved in last 10 steps\n- reduce_lr- reduce learning rate if validation accuracy did not improved in last 5 steps.","062eac7a":"Reading CSV files and viewing their heads","2d30d1d9":"Getting Path to csv files:\n\n- train.csv\n- test.csv \n- submission.csv","a2d03ce1":"## Setting up train and eval tf dataset\n\nCreate tf datasets using tf.data for training and validation. A single element of these datasets return *(Image,Label)* where Image = *(batch_size,image_width,image_height,channels)* and Label = *(batch_size,)*. ","f0ae0bb7":"remove any corrupted png files from dataset","7c37152c":"Setting Parameters here","d30f346b":"## Predicting test data\n\nTest dataset is created which return *(batch_size,Image Tensor)* as single element.","5db0471f":"## Plotting and Visualizing images","8d12f4f1":"## Training Model\n\nIt uses densenet201 pretrained model on imagenet, chop off its last classification layers (Dense Layers) and finetune it.","d1658d63":"## Remove curroupted files\n\n- remove_defected_images : remove corrupted images (if previously known) from data\n- check_and_remove_defected_images : check and remove any corrupted image","2d819c25":"## Helper Functions\n\n- get_path_of_image : for getting path to image from its id\n- load_tf_image : loading and normalizing image and converting to tensor\n- generate_tf_dataset : generate tf dataset"}}