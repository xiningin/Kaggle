{"cell_type":{"85c07820":"code","ed90d3b6":"code","8904b7ea":"code","ec8a84c5":"code","d1901347":"code","55b717c9":"code","301c5ecd":"code","f68cec39":"code","360371da":"code","28b7cde6":"code","21ffc55d":"code","cf8f510f":"code","dcdd6031":"code","d34330af":"code","30d6a05b":"code","25297ee8":"code","42ddc791":"code","5765aaed":"code","94fba3dc":"code","cb4ef0fb":"code","06c5b505":"code","8c618306":"code","3fdaf98f":"code","e06ac4ef":"code","6d0b538a":"code","a75b5f70":"code","ad1885bd":"code","c16826c8":"code","58200bff":"code","51d28bd7":"code","09c79fa4":"code","5baa96a5":"code","8393ad41":"code","f13659db":"code","b17f9ba3":"code","b1565fa7":"code","bb6f84b1":"code","932cf608":"code","fdf7f031":"code","cb0c3de0":"code","e6bae86f":"code","8b6001bb":"code","9f6b2289":"code","ba8108b7":"code","3b7fe166":"code","39aa280a":"code","1dfe43a1":"code","1f6068cc":"code","722dff74":"code","fd4011ff":"code","61cd02c5":"code","69b2070c":"code","5011dc86":"code","536c9a55":"code","83f0bb17":"code","f4c34505":"code","e0b60ce9":"code","c695dfdf":"code","f71995be":"code","91b24b57":"code","65ce6d06":"code","44bfd16f":"code","b0c4cd5b":"code","12b98195":"code","ca83790e":"code","66afe93a":"code","faa2cf34":"markdown","ceec6615":"markdown","73e01472":"markdown","bda4d833":"markdown","9e3f8391":"markdown","88bb760a":"markdown","ee024b9f":"markdown","43cfa009":"markdown","41b3a958":"markdown","5eec7dca":"markdown","3115a018":"markdown","adc39b88":"markdown","8e3e0735":"markdown","80441ad8":"markdown","3b5dfb38":"markdown","1f1ff60f":"markdown","559e4b3b":"markdown","13534189":"markdown","66f2e5ae":"markdown","ac87b4a6":"markdown","1f9cf9fc":"markdown","65658bf0":"markdown","557380bc":"markdown","9e27349f":"markdown","4393aa5f":"markdown","de55dad0":"markdown","28c0b4c4":"markdown","4e4da438":"markdown","9aeeacd1":"markdown","e2f82889":"markdown","7a43770d":"markdown","0edc098f":"markdown"},"source":{"85c07820":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport warnings\nfrom datetime import datetime\nimport calendar\nfrom math import sin, cos, sqrt, atan2, radians\nfrom folium import FeatureGroup, LayerControl, Map, Marker\nfrom folium.plugins import HeatMap\nimport matplotlib.dates as mdates\nimport matplotlib as mpl\nfrom datetime import timedelta\nimport datetime as dt\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_colwidth', -1)\nplt.style.use('fivethirtyeight')\nimport folium\nfrom sklearn.cluster import KMeans\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer as Imputer\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nimport pickle\nimport zipfile","ed90d3b6":"zf_train = zipfile.ZipFile('..\/input\/nyc-taxi-trip-duration\/train.zip')\ntrain = pd.read_csv(zf_train.open('train.csv'))\n\nzf_test = zipfile.ZipFile('..\/input\/nyc-taxi-trip-duration\/test.zip')\ntest = pd.read_csv(zf_test.open('test.csv'))","8904b7ea":"train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'], format = '%Y-%m-%d %H:%M:%S')\ntrain['dropoff_datetime'] = pd.to_datetime(train['dropoff_datetime'], format = '%Y-%m-%d %H:%M:%S')\ntrain.head()","ec8a84c5":"# version 1\ntrain[pd.isnull(train)].sum()","d1901347":"# version 2\ntrain.any()","55b717c9":"# version 3\ntrain.isnull().sum()","301c5ecd":"print(\"Min pickup time:\",min(train['pickup_datetime']))\nprint(\"Max pickup time:\",max(train['pickup_datetime']))","f68cec39":"train['pickup_date'] = train['pickup_datetime'].dt.date\ntrain['pickup_day'] = train['pickup_datetime'].apply(lambda x : x.day)\ntrain['pickup_hour'] = train['pickup_datetime'].apply(lambda x : x.hour)\ntrain['pickup_day_of_week'] = train['pickup_datetime'].apply(lambda x : calendar.day_name[x.weekday()])\ntrain['dropoff_date'] = train['dropoff_datetime'].dt.date\ntrain['dropoff_day'] = train['dropoff_datetime'].apply(lambda x : x.day)\ntrain['dropoff_hour'] = train['dropoff_datetime'].apply(lambda x : x.hour)\ntrain['dropoff_day_of_week'] = train['dropoff_datetime'].apply(lambda x : calendar.day_name[x.weekday()])","360371da":"train['pickup_latitude_round3'] = train['pickup_latitude'].apply(lambda x : round(x, 3))\ntrain['pickup_longitude_round3'] = train['pickup_longitude'].apply(lambda x : round(x, 3))\n\ntrain['dropoff_latitude_round3'] = train['dropoff_latitude'].apply(lambda x : round(x, 3))\ntrain['dropoff_longitude_round3'] = train['pickup_longitude'].apply(lambda x : round(x, 3))","28b7cde6":"def calculateDistance(row):\n    R = 6373.0 # approximate radius of earth in km\n    pickup_lat = radians(row['pickup_latitude'])\n    pickup_lon = radians(row['pickup_longitude'])\n    \n    dropoff_lat = radians(row['dropoff_latitude'])\n    dropoff_lon = radians(row['dropoff_longitude'])\n    \n    dlon = dropoff_lon - pickup_lon\n    dlat = dropoff_lat - pickup_lat\n    \n    a = sin(dlat \/ 2)** 2 + cos(pickup_lat) * cos(dropoff_lat) * sin(dlon \/ 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n    distance = R * c\n    return distance","21ffc55d":"train['trip_distance'] = train.apply(lambda row : calculateDistance(row), axis =1)\ntrain.head()","cf8f510f":"train['trip_duration_in_hour'] = train['trip_duration'].apply(lambda x : x\/3600)\ntrain.head()","dcdd6031":"plt.figure(figsize = (10, 5))\nsns.distplot(train['trip_duration_in_hour']).set_title('distribution of trip duration')\nplt.xlabel('trip duration (in hour)')","d34330af":"outlier_trip_duration = train.loc[train['trip_duration_in_hour'] > 24]\noutlier_trip_duration","30d6a05b":"plt.figure(figsize = (10,5))\nsns.distplot(np.log(train['trip_duration'].values)).set_title('distribution of trip duration')\nplt.title('distribution of trip duration (sec) in log scale')","25297ee8":"pickup = train.groupby(['pickup_latitude_round3','pickup_longitude_round3'])['id'].count().reset_index().rename(columns={'id':'Num_Trips'})","42ddc791":"pickup['Num_Trips'] = pickup['Num_Trips'].astype('float64')","5765aaed":"# TypeError: Object of type 'int64' is not JSON serializable\n\n# You can change that specific columns with int dtype to float64, as example:","94fba3dc":"pickup_map = folium.Map(location = [40.730610,-73.935242],zoom_start = 10,)\n\nhm_wide = HeatMap(list(zip(pickup.pickup_latitude_round3.values, \n                           pickup.pickup_longitude_round3.values,\n                           pickup.Num_Trips.values)),\n                  min_opacity = 0.2,\n                  radius = 5, blur = 15,\n                  max_zoom = 1)\n\npickup_map.add_child(hm_wide)\n\npickup_map","cb4ef0fb":"city_long_border = (-74.03, -73.75)\ncity_lat_border = (40.63, 40.85)\n\nfig, ax = plt.subplots(ncols = 1, sharex = True, sharey = True)\nax.scatter(train['pickup_longitude'], train['pickup_latitude'],\n           color = 'blue', label = 'train', alpha = 0.1)\n\nfig.suptitle('lat lng of pickups in train data as scatter plot')\n\nax.set_ylabel('latitude')\nax.set_xlabel('longitude')\nplt.ylim(city_lat_border)\nplt.xlim(city_long_border)","06c5b505":"drop=train.groupby(['dropoff_latitude_round3','dropoff_longitude_round3'])['id'].count().reset_index().rename(columns={'id':'Num_Trips'})","8c618306":"# TypeError: Object of type 'int64' is not JSON serializable\n\n# You can change that specific columns with int dtype to float64, as example:\n\nfor col in drop.columns:\n    if drop[col].dtype != 'float64':\n        drop[col] = drop[col].astype('float64')","3fdaf98f":"drop_map = folium.Map(location = [40.730610,-73.935242],zoom_start = 10,)\n\nhm_wide = HeatMap( list(zip(drop.dropoff_latitude_round3.values, drop.dropoff_longitude_round3.values, drop.Num_Trips.values)),\n                     min_opacity=0.2,\n                     radius=5, blur=15,\n                     max_zoom=1)\n\ndrop_map.add_child(hm_wide)\ndrop_map","e06ac4ef":"pickup = train.groupby(['pickup_latitude_round3', 'pickup_longitude_round3'])['trip_duration'].mean().reset_index().rename(columns = {'trip_duration' : 'Avg_Trip_duration'})","6d0b538a":"pickup_map = folium.Map(location = [40.730610,-73.935242],zoom_start = 10)\n\nhm_wide = HeatMap(list(zip(pickup.pickup_latitude_round3.values,\n                           pickup.pickup_longitude_round3.values,\n                           pickup.Avg_Trip_duration.values)),\n                  min_opacity = 0.2,\n                  radoius = 7, blur = 15,\n                  max_zoom = 1)\n\npickup_map.add_child(hm_wide)\npickup_map","a75b5f70":"plt.figure(figsize = (8, 5))\nsns.countplot(x = train['pickup_hour']).set_title('pickup hours distribution')","ad1885bd":"plt.figure(figsize = (8, 5))\nsns.countplot(x = train['dropoff_hour']).set_title('dropoff hours distribution')","c16826c8":"plt.figure(figsize = (8, 5))\nplt.plot(train.groupby('pickup_date').count()[['id']], 'o-', label = 'train')\n\nplt.title('distribution of pickups over time')","58200bff":"train['trip_distance'].values","51d28bd7":"plt.figure(figsize = (10, 5))\nsns.kdeplot(np.log(train['trip_distance'].values)).set_title(\"Trip Distance Distribution\")\n#sns.kdeplot(np.log(train['trip_distance'].values)).set_title('trip distance distribution')\nplt.xlabel('trip distribution (log)')\nplt.show()","09c79fa4":"plt.scatter(np.log(train['trip_distance'].values), np.log(train['trip_duration'].values),\n            color = 'blue', label = 'train')\n\nplt.title('distribution of trip distance vs trip duration')\nplt.xlabel('trip distribution (log scale)')\nplt.ylabel('trip distribution (log scale)')","5baa96a5":"avg_duration_hour = train.groupby(['pickup_hour'])['trip_duration'].mean().reset_index().rename(columns = {'trip_duration':'avg_trip_duration'})\nplt.figure(figsize = (8, 5))\nplt.plot(avg_duration_hour['avg_trip_duration'], 'o-')","8393ad41":"plt.figure(figsize = (10, 5))\nsns.countplot(train['pickup_day_of_week'], order = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'])","f13659db":"avg_duration_day = train.groupby(['pickup_day_of_week'])['trip_duration'].mean().reset_index().rename(columns = {'trip_duration' : 'avg_trip_duration'})\n\nplt.figure(figsize = (10, 5))\nsns.barplot(x = 'pickup_day_of_week', y = 'avg_trip_duration', data = avg_duration_day,\n            order = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday']).set_title('avg trip duration vs pickup days of week')","b17f9ba3":"def calculateBearing(lat1,lng1,lat2,lng2):\n    R = 6371 \n    lng_delta_rad = np.radians(lng2 - lng1)\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    y = np.sin(lng_delta_rad) * np.cos(lat2)\n    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n    return np.degrees(np.arctan2(y, x))","b1565fa7":"train['bearing']=train.apply(lambda row:calculateBearing(row['pickup_latitude_round3'],row['pickup_longitude_round3'],\n                                                         row['dropoff_latitude_round3'],row['dropoff_longitude_round3']),axis=1)","bb6f84b1":"train['pickup_latitude_round3']","932cf608":"sns.kdeplot(train['bearing'])","fdf7f031":"plt.figure(figsize = (8, 5))\nplt.scatter(train['bearing'].values, y = np.log(train['trip_duration'].values))\nplt.xlabel('bearing')\nplt.ylabel('trip duration (log scale)')","cb0c3de0":"train['store_and_fwd_flag'].value_counts()","e6bae86f":"plt.figure(figsize=(8,5))\nsns.kdeplot(np.log(train.loc[train['store_and_fwd_flag']=='Y','trip_duration'].values),label= 'Store and Fwd =Yes')\nsns.kdeplot(np.log(train.loc[train['store_and_fwd_flag']=='N','trip_duration'].values),label= 'Store and Fwd =No')\n   \nplt.title(\"Distribution of  Store and Fwd Flag vs Trip Duration(log scale)\")\nplt.xlabel('Trip Duration (log scale)')\nplt.ylabel('Density')","8b6001bb":"coords = np.vstack((train[['pickup_latitude', 'pickup_longitude']].values,\n                   train[['dropoff_latitude', 'dropoff_longitude']].values,\n                   test[['pickup_latitude', 'pickup_longitude']].values,\n                   test[['dropoff_latitude', 'dropoff_longitude']].values))\nkmeans = KMeans(n_clusters = 8, random_state = 0).fit(coords)\ntrain.loc[:, 'pickup_neighbourhood'] = kmeans.predict(train[['pickup_latitude', \n                                                            'dropoff_longitude']])\ntrain.loc[:, 'dropoff_neighbourhood'] = kmeans.predict(train[['dropoff_latitude',\n                                                            'pickup_longitude']])\ncity_long_border = (-74.03, -73.75)\ncity_lat_border = (40.63, 40.85)\nfig, ax = plt.subplots(ncols = 1, sharex = True, sharey = True)\nax.scatter(train['pickup_longitude'], train['pickup_latitude'],\n           c = train['pickup_neighbourhood'], label = 'train', alpha = 0.1)\nfig.suptitle('pickup neighbourhood')\n\nax.set_ylabel('latitude')\nax.set_xlabel('longitude')\nplt.ylim(city_lat_border)\nplt.xlim(city_long_border)","9f6b2289":"plt.figure(figsize=(8,5))\nsns.countplot(train['pickup_neighbourhood']).set_title(\"Distribution of Number of Pickups across Neighbourhoods\")","ba8108b7":"avg_duration_neighbourhood = train.groupby(['pickup_neighbourhood'])['trip_duration'].mean().reset_index().rename(columns = {'trip_duration':'avg_trip_duration'})\nplt.figure(figsize = (8, 5))\nsns.barplot(x = 'pickup_neighbourhood', y ='avg_trip_duration',\n            data = avg_duration_neighbourhood).set_title('avg trip duration vs neighbourhood')","3b7fe166":"train['avg_speed_kph']=train['trip_distance']\/train['trip_duration_in_hour']\nplt.figure(figsize=(8,5))\nsns.kdeplot(train['avg_speed_kph'].values).set_title(\"Distribution of Average Speed (in kph)\")","39aa280a":"print(\"Average speed is\",np.mean(train['avg_speed_kph']),\"kph\") #The average speed is 14 kmph","1dfe43a1":"avg_speed_per_day=train.groupby(['pickup_day_of_week'])['avg_speed_kph'].mean().reset_index()\nplt.figure(figsize=(8,5))\nsns.barplot(x='pickup_day_of_week',y='avg_speed_kph',data=avg_speed_per_day,order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday']).set_title(\"Avg Speed (kph) vs Pickup Days of Week\")","1f6068cc":"test['pickup_datetime']=pd.to_datetime(test['pickup_datetime'],format='%Y-%m-%d %H:%M:%S')\ntest['pickup_date']= test['pickup_datetime'].dt.date\ntest['pickup_day']=test['pickup_datetime'].apply(lambda x:x.day)\ntest['pickup_hour']=test['pickup_datetime'].apply(lambda x:x.hour)\ntest['pickup_day_of_week']=test['pickup_datetime'].apply(lambda x:calendar.day_name[x.weekday()])\ntest['pickup_latitude_round3']=test['pickup_latitude'].apply(lambda x:round(x,3))\ntest['pickup_longitude_round3']=test['pickup_longitude'].apply(lambda x:round(x,3))\ntest['dropoff_latitude_round3']=test['dropoff_latitude'].apply(lambda x:round(x,3))\ntest['dropoff_longitude_round3']=test['dropoff_longitude'].apply(lambda x:round(x,3))\ntest['trip_distance']=test.apply(lambda row:calculateDistance(row),axis=1)\ntest['bearing']=test.apply(lambda row:calculateBearing(row['pickup_latitude_round3'],row['pickup_longitude_round3'],row['dropoff_latitude_round3'],row['dropoff_longitude_round3']),axis=1)\ntest.loc[:, 'pickup_neighbourhood'] = kmeans.predict(test[['pickup_latitude', 'pickup_longitude']])\ntest.loc[:, 'dropoff_neighbourhood'] = kmeans.predict(test[['dropoff_latitude', 'dropoff_longitude']])","722dff74":"drop_cols=['avg_speed_kph','trip_duration_in_hour','dropoff_date','dropoff_day','dropoff_hour','dropoff_day_of_week','dropoff_datetime','pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude']\ntraining=train.drop(drop_cols,axis=1)\ntesting=test.drop(['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude'],axis=1)","fd4011ff":"training['log_trip_duration'] = training['trip_duration'].apply(lambda x:np.log(x))\ntraining.drop(['trip_duration'], axis = 1, inplace = True)","61cd02c5":"print(\"Training Data Shape \",training.shape)\nprint(\"Testing Data Shape \",testing.shape)","69b2070c":"def encodeDays(day_of_week):\n    day_dict = {'Sunday':0, 'Monday':1, 'Tuesday':2, 'Wednesday':3, 'Thursday':4,\n                'Friday':5, 'Saturday':6}\n    return day_dict[day_of_week]","5011dc86":"training['pickup_day_of_week'] = training['pickup_day_of_week'].apply(lambda x:encodeDays(x))\ntesting['pickup_day_of_week'] = testing['pickup_day_of_week'].apply(lambda x:encodeDays(x))","536c9a55":"training.to_csv('input_training.csv', index = False)\ntesting.to_csv('input_testing.csv', index = False)\ndel training\ndel testing\ndel train\ndel test","83f0bb17":"def LabelEncoding(train_df, test_df, max_levels = 2):\n    for col in train_df:\n        if train_df[col].dtype == 'object':\n            if len(list(train_df[col].unique())) <= max_levels:\n                le = preprocessing.LabelEncoder()\n                le.fit(train_df[col])\n                train_df[col] = le.transform(train_df[col])\n                test_df[col] = le.transform(test_df[col])\n    return [train_df, test_df]\n\n\ndef readInputAndEncode(input_path,train_file,test_file,target_column):\n    training = pd.read_csv(input_path + train_file)\n    testing = pd.read_csv(input_path + test_file)\n    \n    training, testing = LabelEncoding(training, testing)\n    \n    train_cols = training.columns.tolist()\n    test_cols = testing.columns.tolist()\n    \n    col_in_train_not_test = set(train_cols) - set(test_cols)\n    for col in col_in_train_not_test:\n        if col != target_column:\n            testing[col] = 0\n    \n    col_in_test_not_train = set(test_cols) - set(train_cols)\n    for col in col_in_test_not_train:\n        training[col] = 0\n    \n    print('training data shape after preprocessing: ', training.shape)\n    print('testing data shape after preprocessing: ', testing.shape)\n    return [training, testing]","f4c34505":"train,test=readInputAndEncode(\"\",'input_training.csv','input_testing.csv','log_trip_duration')\ntrain.drop(['pickup_date'],axis=1,inplace=True)\ntest.drop(['pickup_date'],axis=1,inplace=True)\ntrain.drop(['pickup_datetime'],axis=1,inplace=True)\ntest.drop(['pickup_datetime'],axis=1,inplace=True)\ntest_id=test['id']\ntrain.drop(['id'],axis=1,inplace=True)\ntest.drop(['id'],axis=1,inplace=True)","e0b60ce9":"def GetFeaturesAndSplit(train,test,target,imputing_strategy='median',\n                        split=0.25,imputation=True):\n    labels = np.array(train[target])\n    training = train.drop(target, axis = 1)\n    training = np.array(training)\n    testing = np.array(test)\n    \n    if imputation == True:\n        imputer = Imputer(strategy = imputing_strategy, missing_values = np.nan)\n        imputer.fit(training)\n        training = imputer.transform(training)\n        testing = imputer.transform(testing)\n        \n    train_features, validation_features, train_labels, validation_labels = train_test_split(training, labels, test_size = split, random_state = 42)\n    return [train_features, validation_features, train_labels, validation_labels, testing]","c695dfdf":"train_features, validation_features, train_labels, validation_labels, testing = GetFeaturesAndSplit(train,test,'log_trip_duration',imputation=False)","f71995be":"lm=linear_model.LinearRegression()\nlm.fit(train_features,train_labels)","91b24b57":"valid_pred=lm.predict(validation_features)","65ce6d06":"rmse=mean_squared_error(validation_labels,valid_pred)\nprint(\"Root Mean Squared Error for Linear Regression(log scale) \",rmse)","44bfd16f":"test_pred=lm.predict(testing)\nsubmit=pd.DataFrame()\nsubmit['id']=test_id\nsubmit['trip_duration']=np.exp(test_pred)\nsubmit.to_csv(\"submission_linear_regression_baseline.csv\",index=False)\ndel submit","b0c4cd5b":"rf = RandomForestRegressor(n_estimators = 10, random_state = 42)","12b98195":"rf.fit(train_features,train_labels)","ca83790e":"valid_pred_rf=rf.predict(validation_features)\nrmse=mean_squared_error(validation_labels,valid_pred_rf)\nprint(\"Root Mean Squared Error for Random Forest\",rmse)","66afe93a":"test_pred=rf.predict(testing)\nsubmit=pd.DataFrame()\nsubmit['id']=test_id\nsubmit['trip_duration']=np.exp(test_pred)\nsubmit.to_csv(\"submission_random_forest_baseline.csv\",index=False)","faa2cf34":"#### This kernel used dataset from the Home Credit Default Risk and copied from the 'EDA + Baseline Model' written by AiswaryaRamachandran.\n\n**Introduction to 'EDA + Baseline Model': [URL](https:\/\/www.kaggle.com\/aiswaryaramachandran\/eda-baseline-model-0-40-rmse\/notebook)**\n\n*Thanks for sharing kernel, AiswaryaRamachandran*\n\n---------------------------------------","ceec6615":"#### heatmap of trip duration, when pickup originates from a point","73e01472":"#### Convert to appropriate datatype\nconvert pickup datetime adn dropoff datetime into date-time object","bda4d833":"#### Building Models\n\nFrom the training data we need to drop \"dropoff datetime features\". We also only keep lat lng rounded to 3 decimal places\n\n","9e3f8391":"### Apply Linear Regression","88bb760a":"#### Bearing vs trip duration","ee024b9f":"#### Heatmap of common locations from where pickup and dropoff occurs","43cfa009":"#### Number of pickups in each neighbourhood","41b3a958":"#### What is the distribution of trip distance","5eec7dca":"#### create new day,month, hour info from Pickup time","3115a018":"#### Distribution of pickups across days","adc39b88":"#### Avg Trip Duration over Days of week","8e3e0735":"#### Average Speed across days of week - this is indication of traffic speed.","80441ad8":"#### Distribution of Average speed","3b5dfb38":"#### Round lat lng to 3 decimal places","1f1ff60f":"#### which hours are pickup and dropoff higher?","559e4b3b":"#### Exploratory Analysis","13534189":"#### is the trip duration higher at diffent hours?","66f2e5ae":"#### Pickups over the entire time period","ac87b4a6":"#### This graph clearly shows heavy density of pickups near JFK","1f9cf9fc":"#### Distribution of store and FWD Flag","65658bf0":"#### Distribution of Bearing","557380bc":"#### Based on Latitude and Longitude get the distance of the trip in km\nThis uses Haversine Distance","9e27349f":"#### Group Locations into cluster\nThis will help creating neighbourhoods. And pickups from certain neightbourhoods may have a longer trip duration","4393aa5f":"Log transformation of the trip duration results in a normal distribution. Most trips are between 54 sec (exp(4)) and 2980 sec (exp(8)) . This indicates that most trip are withing one hour. But, there are trips which are less than a minute and need to be explored in detail. There are trips lasting for 100 hours which is weird as the taxi rides are within New York","de55dad0":"There are 4 records which have very high trip duration, but the distance travelled is very low. These are outliers. But is there any particular location to which these trips begin or end? Trip duration is also skewed, so let us take log transformation.\n\nWe will not remove these from the analysis, because they might be a part of test data as well","28c0b4c4":"#### Create a caluclated field Bearing\nBearing measures the direction of travel The formula is: \u03b8 = atan2( sin \u0394\u03bb \u22c5 cos \u03c62 , cos \u03c61 \u22c5 sin \u03c62 \u2212 sin \u03c61 \u22c5 cos \u03c62 \u22c5 cos \u0394\u03bb ) \u03bb is the longitude","4e4da438":"### Apply Random Forest Regressor","9aeeacd1":"#### Trip Duration vs Trip Distance","e2f82889":"#### Are there any missing values in the data?","7a43770d":"#### Feature Engineering on Test Data","0edc098f":"#### What is the time period of the dataset?"}}