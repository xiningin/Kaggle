{"cell_type":{"70d86fe6":"code","3c240f3d":"code","89822966":"code","ef40d2be":"code","62922adc":"code","3d8a459d":"code","9568202b":"code","0e65e3df":"code","fc81ae5a":"code","f5d28d6d":"code","17ed397b":"code","49ff433d":"code","8876f43f":"code","7b137b3e":"code","b0be3d9d":"code","ef43f0be":"code","3588f4c6":"code","90956e96":"code","f683f8fe":"code","5bb3323c":"code","adbeb397":"code","d85d25a4":"code","4fd2a350":"code","08129a2e":"code","651844c5":"code","b71b5688":"code","cf00a5f0":"code","2c04e72f":"code","2da00107":"code","6b3c5b7c":"code","9e4c560c":"code","de3fe4d1":"code","279bc0ac":"code","d2538689":"code","d4fb36e4":"code","4cc750aa":"code","fd9c443c":"code","fef86170":"code","c4122234":"code","3dd67055":"code","8031a625":"code","0a1ea832":"code","4b71c1f8":"code","888c2a86":"code","90c4641e":"code","e1323620":"code","6a2d9a3b":"code","440844ac":"code","24f893a0":"code","43370bc5":"code","b667ce85":"code","a43c11c7":"code","d12e5825":"code","9d31bf12":"code","1a374f45":"code","0f43ce55":"code","5fb2a37e":"code","910ddf7d":"code","68edb36a":"code","b503a8ed":"markdown","b1097cad":"markdown","0ae23eef":"markdown","81ce1b4c":"markdown","2fd40470":"markdown","7c37ba49":"markdown","3c970034":"markdown","ec7c207e":"markdown","8b3d252d":"markdown","427d1811":"markdown","cb2134f4":"markdown","8a2d86aa":"markdown","49cfe85c":"markdown","cb7b5d84":"markdown","2fe27f6a":"markdown","32aa8526":"markdown","9013f70d":"markdown","ed86fbd5":"markdown","951800f1":"markdown","276a32b4":"markdown","e7566e96":"markdown","b1ab59fa":"markdown","c06df60b":"markdown","77de9d1b":"markdown","ae4a52c4":"markdown","13c2dc83":"markdown","fcab1b64":"markdown","86c199f4":"markdown","1ab8273f":"markdown","c4ec3265":"markdown","85882625":"markdown","970d9ad6":"markdown","1d8f0162":"markdown","cc8e2b62":"markdown","38a311b5":"markdown"},"source":{"70d86fe6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3c240f3d":"import pandas as pd\nlistings = pd.read_csv(\"\/kaggle\/input\/berlin-airbnb-data\/listings_summary.csv\")\nprint(listings.shape)\nlistings.head()","89822966":"# 2.1 Check column names\nlistings.columns","ef40d2be":"# 2.2 Check dataset info\nlistings.info()","62922adc":"# 2.3 Examie missing values\nlistings_na = listings.isna().sum()\nlistings_na[listings_na.values > 0].sort_values(ascending=False) # Find out all variables that contain missing values","3d8a459d":"# 3.1 Describe column \"price\"\nlistings.describe(include=\"all\")[\"price\"]","9568202b":"# 3.2 Convert column \"price\" into a numeric variable\nlistings[\"price\"] = listings[\"price\"].apply(lambda x: x.replace(\"$\", \"\")) # Remove dollar sign\nlistings[\"price\"] = listings[\"price\"].apply(lambda x: x.replace(\",\", \"\")) # Remove thousand seperator\nlistings[\"price\"] = listings[\"price\"].astype(\"float\") # Cast the column into type float\nlistings.describe()[\"price\"]","0e65e3df":"# 3.3 Check outliers\nimport numpy as np\nprint(\"99.5% properties have a price lower than {0: .2f}\".format(np.percentile(listings[\"price\"], 99.5)))\nlistings = listings[(listings.price <= np.percentile(listings[\"price\"], 99.5)) & (listings.price > 0)] # Exclude outliers","fc81ae5a":"# 3.4 Create column price range\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn\")\nprice_range = pd.cut(listings[\"price\"], \n                     bins=[0, 20, 40, 60, 80, 100, 120, 140, listings[\"price\"].max()], \n                     labels=[\"0-20\", \"20-40\", \"40-60\", \"60-80\", \"80-100\", \"100-120\", \"120-140\", \"140+\"])\nlistings[\"price_range\"] = price_range \nlistings[\"price_range\"].value_counts().sort_index().plot(kind=\"bar\")\nplt.title(\"Number of Listings in each Price Range\")\nplt.show()","f5d28d6d":"## Step 4: Split listing properties\nselected = []\nhost = ['host_is_superhost', 'host_neighbourhood', 'host_listings_count', 'host_total_listings_count', 'host_verifications', 'host_identity_verified']\nlocation = ['neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed']\ngeo = [\"latitude\", \"longitude\"]\ncondition = ['property_type', 'room_type', 'bed_type', 'amenities', 'cleaning_fee', 'minimum_nights']\nreview = ['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']\nsize = ['space', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'square_feet']\nothers = ['instant_bookable', 'is_business_travel_ready', 'cancellation_policy']","17ed397b":"## Step 5: Host statistics\nimport matplotlib.pyplot as plt\n# 5.1 Descriptive statistics\nlistings.describe(include=\"all\")[host]\nfor col in host:\n    if listings[col].nunique() <= 10:\n        avg_price_host = listings.groupby(col).mean()[\"price\"]\n        avg_price_host.plot(kind=\"bar\")\n        plt.title(\"Avg. Price grouped by \"+col)\n        plt.show()\n    else:\n        continue","49ff433d":"# 5.2 Fill out missing values\nlistings[\"host_is_superhost\"] = listings[\"host_is_superhost\"].replace(np.NAN, \"f\")\nlistings[\"host_identity_verified\"] = listings[\"host_identity_verified\"].replace(np.NAN, \"f\")","8876f43f":"# 5.3 Statistical test\nfrom scipy import stats\nfrom statsmodels.stats.multicomp import (pairwise_tukeyhsd, MultiComparison)\n# Define multicomp function\ndef multicomp(target_name, group_name, data):\n    if (np.nan in data[target_name]) | (np.nan in data[group_name]):\n        print(\"Please remove NaN in target variable or group variable!\")\n    elif (data[target_name].nunique() == 1) | (data[group_name].nunique() == 1):\n        print(\"There is only one unique value in target variable or group variable.\")\n    elif data[group_name].nunique() == 2:\n        mod = MultiComparison(data[target_name], data[group_name])\n        comp = mod.allpairtest(stats.ttest_ind)\n        print(comp[0])\n    else:\n        mod = MultiComparison(data[target_name], data[group_name])\n        print(mod.tukeyhsd().summary())\nmulticomp(\"price\", \"host_is_superhost\", listings)\nmulticomp(\"price\", \"host_identity_verified\", listings)","7b137b3e":"selected.append(\"host_is_superhost\")\nselected.append(\"host_identity_verified\")\nselected","b0be3d9d":"# 5.3 Handle host verification\nlistings[\"host_ver_types\"] = listings[\"host_verifications\"].apply(lambda x: x[1:-1].replace(\"\\'\", \"\").split(\", \"))\nlistings[\"host_ver_type_counts\"] = listings[\"host_ver_types\"].apply(lambda x: len(x))\nlistings[\"host_ver_type_counts\"].hist()\nhost_ver_types = []\nfor i in listings[\"host_ver_types\"]:\n    host_ver_types += i\nhost_ver_types_freq = dict((x, host_ver_types.count(x)) for x in set(host_ver_types))\nhost_ver_types_freq = pd.DataFrame.from_dict(host_ver_types_freq, orient=\"index\")\nhost_ver_types_freq.reset_index(inplace=True)\nhost_ver_types_freq.columns = [\"Verification\", \"Frequency\"]\nhost_ver_types_freq = host_ver_types_freq.sort_values(by=\"Frequency\", ascending=True)\nhost_ver_types_freq.plot.barh(x=\"Verification\", y=\"Frequency\")\nplt.title(\"Most frequently used verification types\")\nplt.show()","ef43f0be":"## Step 6: Geoplot\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.offline import plot as plotoffline\nimport seaborn as sns\n# 6.1 Create dataset\ngeo = listings[['latitude', 'longitude', 'price', 'price_range']]\ngeo = geo.sort_values(\"price\", ascending=True) # This sorting is necessary for the color scale to work properly. \ngeo.describe()\n# 6.2 Simple scatter plot\nsns.scatterplot(x=\"longitude\", \n                y=\"latitude\", \n                hue=\"price\", \n                data=geo, \n                alpha=0.4)","3588f4c6":"# 6.3 Map plot\npx.set_mapbox_access_token(\"XXX\") # Replace XXX with your Mapbox Token\nfig = px.scatter_mapbox(geo, \n                        lat=\"latitude\", \n                        lon=\"longitude\", \n                        color=\"price_range\",\n                        color_discrete_sequence=px.colors.sequential.Plasma,\n                        opacity=0.3, \n                        zoom=10)\nfig.show()","90956e96":"# 6.4 Calcuate the distance bwteen the listing and mianat tractions in Berlin\n# Formula to calculate distances\nfrom math import sin, cos, sqrt, atan2, radians\ndef distance(lat1, lat2, lon1, lon2):\n    R = 6373.0\n    rlat1 = radians(lat1)\n    rlat2 = radians(lat2)\n    rlon1 = radians(lon1)\n    rlon2 = radians(lon2)\n    rdlon = rlon2 - rlon1\n    rdlat = rlat2 - rlat1\n    a = sin(rdlat \/ 2)**2 + cos(rlat1) * cos(rlat2) * sin(rdlon \/ 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n    distance = R * c\n    return distance\n# Top locations in Berlin\ntoploc = {\"hbf\": [52.525293, 13.369359], \n          \"txl\": [52.558794, 13.288437], \n          \"btor\": [52.516497, 13.377683], \n          \"museum\": [52.517693, 13.402141], \n          \"reichstag\": [52.518770, 13.376166]}\ntoploc = pd.DataFrame.from_dict(toploc)\ntoploc_trans = toploc.transpose()\ntoploc_trans.columns = [\"latitude\", \"longitude\"]\nfig = px.scatter_mapbox(toploc_trans, \n                        lat=\"latitude\", \n                        lon=\"longitude\", \n                        zoom=10)\nfig.show()\n# Construct distance columns\ndist = []\nfor col in toploc.columns:\n    listings[\"dist_\"+col] = listings.apply(lambda x: distance(x.latitude, toploc[col][0], x.longitude, toploc[col][1]), axis=1)\n    dist.append(\"dist_\"+col)","f683f8fe":"for distance in dist:\n    sns.scatterplot(x=distance, y=\"price\", data=listings, alpha=0.3)\n    plt.title(\"Correlation between price and \"+distance)\n    plt.show()\n    print(\"The correlation between price and \"+distance+ \" is {0[0]: .4f} with a p-value of {0[1]: .4f}.\".format(stats.pearsonr(listings[-listings[distance].isna()][distance], \n                                                                                            listings[-listings[distance].isna()][\"price\"])))","5bb3323c":"for col in dist:\n   listings[col+\"_close\"] = (listings[col] < listings[col].median())\n   print(listings.groupby(col+\"_close\").mean()[\"price\"])\nlistings[\"good_distance\"] = listings.apply(lambda x: any([x.dist_hbf_close, x.dist_txl_close, x.dist_museum_close, x.dist_reichstag_close]), axis=1)\nlistings.groupby(\"good_distance\").mean()[\"price\"].plot(kind=\"bar\")\nplt.show()","adbeb397":"selected.append(\"good_distance\")\nselected","d85d25a4":"## Step 7: Neighbourhood statistics\n# 7.1 Top popular nerghbourhoods\nneighbourhood_group_pop = pd.DataFrame(listings[\"neighbourhood_group_cleansed\"].value_counts())\n# 7.2 Average price of each neighbourhood\nneighbourhood_group_price = listings.groupby(\"neighbourhood_group_cleansed\").mean()[\"price\"]\nneighbourhood_group_price = pd.DataFrame(neighbourhood_group_price)\n# 7.3 Create neighbourhood stats\nneighbourhood_stat = pd.merge(neighbourhood_group_pop, \n                              neighbourhood_group_price, \n                              how=\"inner\", left_index=True, right_index=True)\nneighbourhood_stat.reset_index(inplace=True)\nneighbourhood_stat.columns = [\"neighbourhood_group_cleansed\", \"count_properties\", \"avg_price\"]\nneighbourhood_stat = neighbourhood_stat.sort_values(by=\"count_properties\", ascending=False)\nneighbourhood_stat","4fd2a350":"# 7.4 Plot\nfig = plt.figure(figsize=(5, 5))\nax = neighbourhood_stat.plot(x=\"neighbourhood_group_cleansed\", y=\"count_properties\", kind=\"bar\")\nneighbourhood_stat.plot(x=\"neighbourhood_group_cleansed\", y=\"avg_price\", secondary_y=True, color=\"red\", ax=ax)\nplt.show()","08129a2e":"listings[condition].head()","651844c5":"# 8.1 Property type\nprop_type_avg_price = listings.groupby(\"property_type\").mean()[\"price\"]\nprop_type_count_listings = listings[\"property_type\"].value_counts()\nprop_type_stat = pd.merge(prop_type_count_listings, prop_type_avg_price, how=\"inner\", left_index=True, right_index=True)\nprop_type_stat.columns = [\"count_prop\", \"avg_price\"]\nprop_type_stat.sort_values(by=\"count_prop\", ascending=False).head(10)","b71b5688":"# 8.2 Room type\nroom_type_avg_price = listings.groupby(\"room_type\").mean()[\"price\"]\nroom_type_count_listings = listings[\"room_type\"].value_counts()\nroom_type_stat = pd.merge(room_type_count_listings, room_type_avg_price, how=\"inner\", left_index=True, right_index=True)\nroom_type_stat.columns = [\"count_prop\", \"avg_price\"]\nroom_type_stat.sort_values(by=\"count_prop\", ascending=False).head(10)\nroom_type_avg_price.plot(kind=\"bar\")\nplt.title(\"Avg. Price per Room Type\")\nplt.show()","cf00a5f0":"listings[\"is_entire_apt\"] = listings[\"room_type\"]==\"Entire home\/apt\"\nselected.append(\"is_entire_apt\")","2c04e72f":"# 8.3 Bed type\nlistings[\"bed_type\"].value_counts()","2da00107":"# 8.4 Amendities\nlistings[\"amenities\"].head()\nlistings[\"amenities\"] = listings[\"amenities\"].apply(lambda x: x[1:-1].replace(\"\\'\", \"\").split(\",\"))","6b3c5b7c":"listings[\"amenities\"].head()\namenity_types = []\nfor i in listings[\"amenities\"]:\n    amenity_types += i\namenity_types_freq = dict((x, amenity_types.count(x)) for x in set(amenity_types))\namenity_types_freq = pd.DataFrame.from_dict(amenity_types_freq, orient=\"index\")\namenity_types_freq.reset_index(inplace=True)\namenity_types_freq.columns = [\"Amenity\", \"Frequency\"]\namenity_types_freq = amenity_types_freq.sort_values(by=\"Frequency\", ascending=False)\namenity_types_freq.head(20).plot.barh(x=\"Amenity\", y=\"Frequency\")\nplt.title(\"Top20 most frequent amenity types\")\nplt.show()","9e4c560c":"listings[\"with_hair_dryer\"] = listings[\"amenities\"].apply(lambda x: '\"Hair dryer\"' in x)\nlistings[\"lap_friendly\"] = listings[\"amenities\"].apply(lambda x: '\"Laptop friendly workspace\"' in x)\nlistings[\"with_hanger\"] = listings[\"amenities\"].apply(lambda x: \"Hangers\" in x)\nprint(multicomp(\"price\", \"with_hair_dryer\", listings))\nprint(multicomp(\"price\", \"lap_friendly\", listings))\nprint(multicomp(\"price\", \"with_hanger\", listings))\nfor i in [\"with_hair_dryer\", \"lap_friendly\", \"with_hanger\"]:\n    selected.append(i)","de3fe4d1":"# 8.5 Minimum nights\nlistings[\"minimum_nights\"].describe()\nlistings[\"min_nights_greater_than_two\"] = listings[\"minimum_nights\"] > 2\nmulticomp(\"price\", \"min_nights_greater_than_two\", data=listings)","279bc0ac":"selected.append(\"min_nights_greater_than_two\")","d2538689":"# 8.6 Cleaning fee\n# Remove dollar sign\nlistings[\"cleaning_fee\"][-listings[\"cleaning_fee\"].isna()] = listings[\"cleaning_fee\"][-listings[\"cleaning_fee\"].isna()].apply(lambda x: x.replace(\"$\", \"\").replace(\",\", \"\"))\nlistings[\"cleaning_fee\"] = listings[\"cleaning_fee\"].astype(\"float\")","d4fb36e4":"listings[\"cleaning_fee\"].isna().sum() # Check missing values\nlistings[\"cleaning_fee\"].describe()\nsns.scatterplot(x=\"cleaning_fee\", y=\"price\", data=listings, alpha=0.3)\nplt.title(\"Correlation bewteen Cleaning Fee and Price\")\nplt.show()\nprint(\"The correlation between cleaning fee and price is {0[0]: .4f} with a p-value of {0[1]: .4f}.\".format(stats.pearsonr(listings[-listings[\"cleaning_fee\"].isna()][\"cleaning_fee\"], \n                                                                                            listings[-listings[\"cleaning_fee\"].isna()][\"price\"])))","4cc750aa":"selected.append(\"cleaning_fee\")\nselected","fd9c443c":"# Step 9: Review statistics\n# 9.1 Examine the distribution of score ratings\nlistings[\"review_scores_rating\"].hist()","fef86170":"# 9.2 Scatter plot between review score and price\nimport seaborn as sns\nimport scipy.stats as stats\nsns.regplot(x=\"review_scores_rating\", y=\"price\", data=listings[listings[\"review_scores_rating\"]>=75])\nplt.title(\"Price vs Review Score Rating\")\nplt.show()\nprint(\"The correlation between review score and price is {0[0]: .4f} with a p-value of {0[1]: .4f}.\".format(stats.pearsonr(listings[-listings[\"review_scores_rating\"].isna()][\"review_scores_rating\"], \n                                                                                            listings[-listings[\"review_scores_rating\"].isna()][\"price\"])))","c4122234":"# 9.3 Check the correlation between price and other scores\nfor col in review:\n    print((\"The pearson correlation coefficient between \" + col + \" and price is {0[0]: .4f}.\").format(stats.pearsonr(listings[-listings[col].isna()][col], \n                                                                                            listings[-listings[col].isna()][\"price\"])))","3dd67055":"# Step 10: Size\n# 10.1 Look at size-related variables\nlistings[size].head(10)","8031a625":"# 10.2 Check the correlation between number of accommodates and price\nlistings[\"accommodates\"].hist()\nlistings[\"accommodates\"].describe()","0a1ea832":"listings.groupby(\"accommodates\").mean()[\"price\"].plot(kind=\"bar\")\nplt.title(\"Avg. Price grouped by Number of Accommodates\")\nplt.show()\nprint(\"The pearson correlation coefficient between ther number of acoommodates and price is {0[0]: .4f} with a p-value of {0[1]: .4f}.\".format(stats.pearsonr(listings[\"accommodates\"], listings[\"price\"])))","4b71c1f8":"selected.append(\"accommodates\")\nselected","888c2a86":"# 10.3 Check the correlation bewteen accommodates and other size variables\nsize_variables = listings[size]\nsize_variables.drop([\"space\", \"square_feet\"], axis=1, inplace=True)\nsize_variables.head()","90c4641e":"size_corr = size_variables.corr()\ncolormap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(size_corr, cmap=colormap, annot=True, fmt=\".4f\")","e1323620":"# Step 11: Other conditions\nlistings[others].head()","6a2d9a3b":"# 11.1 Instant bookable\nlistings[\"instant_bookable\"].value_counts()\nmulticomp(\"price\", \"instant_bookable\", listings)\nlistings.groupby(\"instant_bookable\").mean()[\"price\"].plot(kind=\"bar\")\nplt.title(\"Avg. Price split by Instant Bookable Policy\")\nplt.show()\nselected.append(\"instant_bookable\")","440844ac":"# 11.2 Ready for Business Travel\nlistings[\"is_business_travel_ready\"].value_counts()\nmulticomp(\"price\", \"is_business_travel_ready\", listings)\nlistings.groupby(\"is_business_travel_ready\").mean()[\"price\"].plot(kind=\"bar\")\nplt.title(\"Avg. Price split by Ready for Business Travel\")\nplt.show()","24f893a0":"# 11.3 Cancellation plicy\nprint(listings[\"cancellation_policy\"].value_counts())\nmulticomp(\"price\", \"cancellation_policy\", listings)\nlistings.groupby(\"cancellation_policy\").mean()[\"price\"].plot(kind=\"bar\")\nplt.title(\"Avg. Price split by Cancellation Policy\")\nplt.show()","43370bc5":"listings[\"cancellation_non_flexible\"] = listings[\"cancellation_policy\"]!=\"flexible\"\nlistings[\"cancellation_non_flexible\"].value_counts()\nmulticomp(\"price\", \"cancellation_non_flexible\", listings)\nselected.append(\"cancellation_non_flexible\")","b667ce85":"listings[selected].info()","a43c11c7":"# 1.1 Convert string variables into categorical variables\nlistings[\"host_is_superhost\"] = listings[\"host_is_superhost\"]==\"t\"\nlistings[\"host_identity_verified\"] = listings[\"host_identity_verified\"]==\"t\"\nlistings[\"instant_bookable\"] = listings[\"instant_bookable\"]==\"t\"","d12e5825":"for col in listings[selected].select_dtypes(\"bool\").columns:\n    listings[col] = listings[col].astype(\"int\")","9d31bf12":"listings[selected].info()","1a374f45":"# 1.2 Standardisation\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nscaledFeatures = sc.fit_transform(listings[selected])","0f43ce55":"# 1.3 Load packages and create test set\nimport xgboost as xgb\nfrom xgboost import plot_importance\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nX = scaledFeatures\ny = listings[\"price\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","5fb2a37e":"# 2.1 Initialize XGBoost classifier and find the best parameter sets with Grid Search CV\nxgb_clf = xgb.XGBRegressor()\nparameters = {'n_estimators': [120, 100, 140], 'max_depth':[3,5,7,9]}\ngrid_search = GridSearchCV(estimator=xgb_clf, param_grid=parameters, cv=5, n_jobs=-1)\ngrid_search.fit(X_train, y_train)\nprint(grid_search.best_params_)","910ddf7d":"# 2.2 Xgb with best parameters\nxgb_clf = xgb.XGBRegressor(n_estimators=100, max_depth=5)\nxgb_clf.fit(X_train, y_train)\ny_test_pred = xgb_clf.predict(X_test)\nprint(\"R^2 score is: {0: .4f}\".format(r2_score(y_test, y_test_pred)))\nprint(\"RMSE is: {0: .4f}\".format(np.sqrt(mean_squared_error(y_test, y_test_pred))))","68edb36a":"# 2.3 Plot feature importance\nfeatureImport = pd.DataFrame(xgb_clf.feature_importances_, index=selected)\nfeatureImport.columns = [\"Importance\"]\nfeatureImport.sort_values([\"Importance\"], ascending=True).plot(kind=\"barh\")\nplt.title(\"XGBoost Relative Feature Importance\")\nplt.show()","b503a8ed":"Conclusion: there is strong correlation between distances to Top5 locations and the listing price. ","b1097cad":"As 90% of listings are apartments, it does not help to explain the variation in price.","0ae23eef":"## Step 3: Pre-process column \"price\"\n\nSince \"price\" is our target variable, we need to make sure it is in good shape: no missing values, data type is correct, etc.\n\nFrom Step 2 we have seen that variable \"price\" does not have any missing values, therefore we can skip the examination of missing values.","81ce1b4c":"Since columns \"host_is_superhost\" and \"host_identity_verified\" are of data type Boolean, we would fill out missing values with False.","2fd40470":"## Step 4: Store variable names that might be interesting for exploration\n\nWith this step we will select the variables that could be helpful to explain the variation in property price.\n\nThe selection is based on the hypothesis that the following factors will affect the rent:\n* Host: identity verification, super host\n* Location: neighborhood, distance to top locations\n* Property conditions: amenities, property types, cleaninig fee, etc \n* Review scores\n* Property Size\n* Others: cancellation policy, instant bookable or not, etc","7c37ba49":"Conclusion: cleaning fee is highly correlated with price and thus should be selected into our model.","3c970034":"## Step 1: Feature Engineering\n\nFrom previous steps we have identified features that should be included in our model. We need to do some final preparation before putting them into regressor.","ec7c207e":"## Step 2: Describe the dataset\n\nNext, we examine the dataset with more details: column names, data types and missing values.","8b3d252d":"Conclusion: the variable \"accommodates\" is highly correlated with \"beds\" and \"bedrooms\", so it is sufficient to include only accommodates into our model.","427d1811":"There is no significant correlation between review score and price.","cb2134f4":"# Intro\n\nThe dataset contains 22,552 Airbnb listings in Berlin as of November 2018. For each listing we have the information about the property (e.g. property type, location, number of accommodated guests, cancellation policy, etc) and the host (e.g. whether the host is a super host, whether the identity of the host has been verified). \n\nThe goal of this project is to identify the factors that have the biggest impact on daily price of each listing. Below are some hypotheses that I have in mind before starting the analysis (although I actually have only used Aribnb once so far):\n* **Location**: the closer the property is to some top locations in Berlin (e.g. Berlin main train station, Reichtag, etc), the higher the price.\n* **Property type**: the price of an entire apartment should be higher than a shared apartment or a single bedroom.\n* **Host quality**: according to Airbnb page (https:\/\/www.airbnb.com\/help\/article\/829\/how-do-i-become-a-superhost), a host will become a superhost if he\/she has both been an experience traveler and host and achived higher overall ratings. Properties that are offered by superhosts should have a higher price.\n* **Amenities**: if the property has offered some special amenities that others don't (e.g. TV, hangers, a laptop-friendly workplace), it should have a higher price.\n* **Policies**: properties with more favorable policies (e.g. more flexible cancellation policy) will haev a higher price.\n\nThe project can be devided into two parts:\n1. Explanatory data analysis: data cleansing, data visualisation, summary statistisc, feature engineering\n2. Feature importance using XGBoost (with Grid Search for model selection)\n\nThe explanatory analysis has confirmed most of the hypotheses above with statistical significance. In the end, two factors stand out as the most important features when predicting the daily price of Airbnb listings in Berlin:\n\n\ud83c\udfd8 Property types: the price of an entire apartment is higher than a shared apartment or a single bedroom.\n\n\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66 Accommodates: the more guests a property can host, the higher the price. This variable is a good proxy of the size of the property (which is not explicitly provided in the dataset).","8a2d86aa":"Accommodates can be used as a proxy of space and has sig. correlation with price.","49cfe85c":"Conclusion: properties that require at least three nights have sig. higher price. ","cb7b5d84":"Step 3.1 suggests that column \"price\" is of type object rather than int\/float. Therefore, we need to convert this column into numeric value.","2fe27f6a":"## Step 9: Review statistics\n\nOne hypothesis is that the higher the rating, the higher the price.","32aa8526":"We found that listings with a good distance (i.e. identified as \"close\" to any of the Top5 locations) have a sig. higher price.","9013f70d":"The statistical tests show that the variable \"host_is_superhost\" and \"host_identity_verified\" has stat. sig. impact on price and thus should be included in the prediction model.\n\nWe also notice that column \"host_verifications\" stores the ways of identity verification that is provided by each host. It would be nice to know which are the most frequently used ways of identity verification.","ed86fbd5":"Entire apartment has a sig. higher price than a private room. Therefore we take it into our model.","951800f1":"## Step 1: Load the dataset\n\nFirst of all, let's load the dataset and have a first look into the shape and structure.","276a32b4":"## Step 2: Model Selection\n\nWe choose XGBoost as our regressor for two reasons:\n1. We are trying to predict price which is a continuous variable. This means we have a prediction problem.\n2. We are interested in deriving featrue importance in the end and XGBoost fits as a perfect regressor to achieve that purpose.","e7566e96":"90%+ beds are real beds, so the bed type should have no sig. impact of price.","b1ab59fa":"90%+ listings have the Top3 features: wifi, kitchen and heating. Therefore they won't have a huge impact on price. We choose to focuse on features that ~50% listings have. They are:\n* Hair dryer \n* Laptop friendly workspace\n* Hanger","c06df60b":"# Appendix\n\n* Scatterplots on Mapbox: https:\/\/plot.ly\/python\/scattermapbox\/\n* Multicomparison on Python: http:\/\/www.statsmodels.org\/devel\/generated\/statsmodels.sandbox.stats.multicomp.MultiComparison.html\n* XGBoost: https:\/\/towardsdatascience.com\/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d","77de9d1b":"## Step 5: Host statistics\n\nRegarding the host information we have two hypothesis:\n* If a property has a super host, its price should be higher.\n* If the host of a property has been verified, the property price should be higher.","ae4a52c4":"Conclusion: the most important factors that decide Airbnb rent in Berlin area are the property type and the number of accommodated guests - the two together account for 70% of the explainig power of all variables included in the model. ","13c2dc83":"## Step 7: Neighbourhood statistics\n\nWe would also like to check the popularity and price level at each neighbourhood of Berlin.","fcab1b64":"# Explanatory Data Analysis","86c199f4":"We could also map the scatter plot to the actual Berlin map.\n\nFor this we would use the Mapbox API. Here you can find the instructions on how Mapbox works: https:\/\/plot.ly\/python\/scattermapbox\/\n\nIn general, the price is higher in the north-eastern part of Berlin.","1ab8273f":"# Feature Importance","c4ec3265":"## Step 6: Geoplot\n\nThe dataset also includes the latitude and logitude of each property - this provides a perfect opportunity to do some geospatial plots!","85882625":"To better evaluate the location of each listing, we would like to calcuate the distance between each listing and one of the Top5 locations in Berlin. Here we define the Top5 locations as:\n* Berlin main train station (hbf)\n* Berlin Tegel Airport (txl)\n* Brandenburg Tor (btor)\n* Museum Island (museum)\n* Reichstag (reichstag)","970d9ad6":"There is no significant correlation between other review scores and price.","1d8f0162":"The description of column \"price\" suggests that there might be outliers - 75% properties have a price that is lower than \\$ 70 yet the highest price is \\$ 90,000. We need to further investigate the outliers and remove them if necessary.","cc8e2b62":"## Step 8: Condition statistics\n\nWe would also like to check the impact of conditions.","38a311b5":"Since 99.5% entries have a price that is lower than 400, we choose to remove the rest as outliers. \n\nWe would like to create a new column \"price_range\" for visualisations later on. The choice of cutoff points (e.g. 20, 40, 60, etc) is inspired by the quartiles of column \"price\"."}}