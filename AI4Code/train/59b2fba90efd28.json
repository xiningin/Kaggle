{"cell_type":{"e91f3f18":"code","39fca8c4":"code","0857737a":"code","6e2ab67c":"code","1c8ea6ad":"code","a62cd602":"code","8c325bb6":"code","33fc539f":"code","779c5ac0":"code","c4b91482":"code","86d5e61c":"code","cd6274cc":"code","cbdf1b66":"code","5271eb2a":"code","3d4da9a0":"code","61a829fb":"code","716c0689":"code","d85328bf":"code","01134066":"code","b6e21614":"code","b39575e9":"code","e256430d":"code","d4ab099c":"code","2a9d41a9":"code","e418786b":"code","81abb410":"code","d1ae82b3":"code","b3f43ca2":"code","46155849":"code","8b4c842d":"code","5192f36b":"markdown","c852bef5":"markdown","dfaf28f3":"markdown","eaa78328":"markdown","117eeab2":"markdown","cc8af9f7":"markdown","a706f352":"markdown"},"source":{"e91f3f18":"# Import libraries \nimport os\nimport sys\nimport warnings\n\nimport numpy as np\nimport pandas as pd\n\nimport librosa\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Keras\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input, Flatten, Dropout, Activation, BatchNormalization\nfrom keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\nfrom keras.utils import np_utils, to_categorical\n\n# sklearn\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# ignore warnings \nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","39fca8c4":"#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\nTESS = \"\/kaggle\/input\/toronto-emotional-speech-set-tess\/tess toronto emotional speech set data\/TESS Toronto emotional speech set data\/\"\nRAV = \"\/kaggle\/input\/ravdess-emotional-speech-audio\/audio_speech_actors_01-24\/\"\nSAVEE = \"\/kaggle\/input\/surrey-audiovisual-expressed-emotion-savee\/ALL\/\"\nCREMA = \"\/kaggle\/input\/cremad\/AudioWAV\/\"\n\n# Run one example \ndir_list = os.listdir(SAVEE)\ndir_list[0:9]","0857737a":"# Get the data location for SAVEE\ndir_list = os.listdir(SAVEE)\n\n# parse the filename to get the emotions\nemotion=[]\npath = []\nfor i in dir_list:\n    if i[-8:-6]=='_a':\n        emotion.append('male_angry')\n    elif i[-8:-6]=='_d':\n        emotion.append('male_disgust')\n    elif i[-8:-6]=='_f':\n        emotion.append('male_fear')\n    elif i[-8:-6]=='_h':\n        emotion.append('male_happy')\n    elif i[-8:-6]=='_n':\n        emotion.append('male_neutral')\n    elif i[-8:-6]=='sa':\n        emotion.append('male_sad')\n    elif i[-8:-6]=='su':\n        emotion.append('male_surprise')\n    else:\n        emotion.append('male_error') \n    path.append(SAVEE + i)\n    \n# Now check out the label count distribution \nSAVEE_df = pd.DataFrame(emotion, columns = ['labels'])\nSAVEE_df['source'] = 'SAVEE'\nSAVEE_df = pd.concat([SAVEE_df, pd.DataFrame(path, columns = ['path'])], axis = 1)\nSAVEE_df.labels.value_counts()","6e2ab67c":"dir_list = os.listdir(RAV)\ndir_list.sort()\n\nemotion = []\ngender = []\npath = []\nfor i in dir_list:\n    fname = os.listdir(RAV + i)\n    for f in fname:\n        part = f.split('.')[0].split('-')\n        emotion.append(int(part[2]))\n        temp = int(part[6])\n        if temp%2 == 0:\n            temp = \"female\"\n        else:\n            temp = \"male\"\n        gender.append(temp)\n        path.append(RAV + i + '\/' + f)\n\n        \nRAV_df = pd.DataFrame(emotion)\nRAV_df = RAV_df.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\nRAV_df = pd.concat([pd.DataFrame(gender),RAV_df],axis=1)\nRAV_df.columns = ['gender','emotion']\nRAV_df['labels'] =RAV_df.gender + '_' + RAV_df.emotion\nRAV_df['source'] = 'RAVDESS'  \nRAV_df = pd.concat([RAV_df,pd.DataFrame(path, columns = ['path'])],axis=1)\nRAV_df = RAV_df.drop(['gender', 'emotion'], axis=1)\nRAV_df.labels.value_counts()","1c8ea6ad":"dir_list = os.listdir(TESS)\ndir_list.sort()\ndir_list","a62cd602":"path = []\nemotion = []\n\nfor i in dir_list:\n    fname = os.listdir(TESS + i)\n    for f in fname:\n        if i == 'OAF_angry' or i == 'YAF_angry':\n            emotion.append('female_angry')\n        elif i == 'OAF_disgust' or i == 'YAF_disgust':\n            emotion.append('female_disgust')\n        elif i == 'OAF_Fear' or i == 'YAF_fear':\n            emotion.append('female_fear')\n        elif i == 'OAF_happy' or i == 'YAF_happy':\n            emotion.append('female_happy')\n        elif i == 'OAF_neutral' or i == 'YAF_neutral':\n            emotion.append('female_neutral')                                \n        elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n            emotion.append('female_surprise')               \n        elif i == 'OAF_Sad' or i == 'YAF_sad':\n            emotion.append('female_sad')\n        else:\n            emotion.append('Unknown')\n        path.append(TESS + i + \"\/\" + f)\n\nTESS_df = pd.DataFrame(emotion, columns = ['labels'])\nTESS_df['source'] = 'TESS'\nTESS_df = pd.concat([TESS_df,pd.DataFrame(path, columns = ['path'])],axis=1)\nTESS_df.labels.value_counts()","8c325bb6":"dir_list = os.listdir(CREMA)\ndir_list.sort()\nprint(dir_list[0:10])","33fc539f":"gender = []\nemotion = []\npath = []\nfemale = [1002,1003,1004,1006,1007,1008,1009,1010,1012,1013,1018,1020,1021,1024,1025,1028,1029,1030,1037,1043,1046,1047,1049,\n          1052,1053,1054,1055,1056,1058,1060,1061,1063,1072,1073,1074,1075,1076,1078,1079,1082,1084,1089,1091]\n\nfor i in dir_list: \n    part = i.split('_')\n    if int(part[0]) in female:\n        temp = 'female'\n    else:\n        temp = 'male'\n    gender.append(temp)\n    if part[2] == 'SAD' and temp == 'male':\n        emotion.append('male_sad')\n    elif part[2] == 'ANG' and temp == 'male':\n        emotion.append('male_angry')\n    elif part[2] == 'DIS' and temp == 'male':\n        emotion.append('male_disgust')\n    elif part[2] == 'FEA' and temp == 'male':\n        emotion.append('male_fear')\n    elif part[2] == 'HAP' and temp == 'male':\n        emotion.append('male_happy')\n    elif part[2] == 'NEU' and temp == 'male':\n        emotion.append('male_neutral')\n    elif part[2] == 'SAD' and temp == 'female':\n        emotion.append('female_sad')\n    elif part[2] == 'ANG' and temp == 'female':\n        emotion.append('female_angry')\n    elif part[2] == 'DIS' and temp == 'female':\n        emotion.append('female_disgust')\n    elif part[2] == 'FEA' and temp == 'female':\n        emotion.append('female_fear')\n    elif part[2] == 'HAP' and temp == 'female':\n        emotion.append('female_happy')\n    elif part[2] == 'NEU' and temp == 'female':\n        emotion.append('female_neutral')\n    else:\n        emotion.append('Unknown')\n    path.append(CREMA + i)\n    \nCREMA_df = pd.DataFrame(emotion, columns = ['labels'])\nCREMA_df['source'] = 'CREMA'\nCREMA_df = pd.concat([CREMA_df,pd.DataFrame(path, columns = ['path'])],axis=1)\nCREMA_df.labels.value_counts()","779c5ac0":"df = pd.concat([SAVEE_df, RAV_df, TESS_df, CREMA_df], axis = 0)\nprint(df.labels.value_counts())\ndf.to_csv(\"Data_path.csv\",index=False)","c4b91482":"data_path = pd.read_csv(\"\/kaggle\/working\/Data_path.csv\")\ndata_path.head()","86d5e61c":"plt.figure(figsize=(20, 8))\nsns.countplot('labels', data=df)","cd6274cc":"# This takes a few minutes (~15 mins): \ndf = pd.DataFrame(columns=['feature'])\n\n# feature extraction \ncounter=0\nfor index,path in enumerate(data_path.path):\n    X, sample_rate = librosa.load(path\n                                  , res_type='kaiser_fast'\n                                  ,duration=2.5\n                                  ,sr=44100\n                                  ,offset=0.5\n                                 )\n    sample_rate = np.array(sample_rate)\n    \n    # mean as the feature. Could do min and max etc as well. \n    mfccs = np.mean(librosa.feature.mfcc(y=X, \n                                        sr=sample_rate, \n                                        n_mfcc=13),\n                    axis=0)\n    df.loc[counter] = [mfccs]\n    counter=counter+1   \n\n# Check a few records to make sure its processed successfully\nprint(len(df))\ndf.head()","cbdf1b66":"df = pd.concat([data_path, pd.DataFrame(df['feature'].values.tolist())],axis=1)\ndf[:5]","5271eb2a":"df=df.fillna(0)\nprint(df.shape)\ndf[:5]","3d4da9a0":"df.to_csv(\"Data_mfcc.csv\",index=False)","61a829fb":"df = pd.read_csv(\"\/kaggle\/working\/Data_mfcc.csv\")\ndf.head() ","716c0689":"facet = sns.FacetGrid(df, hue=\"labels\", aspect=4)\nfacet.map(sns.kdeplot,'207', shade= True)\nfacet.set(xlim=(0, df['207'].max()))\nfacet.add_legend()","d85328bf":"facet = sns.FacetGrid(df, hue=\"labels\", aspect=4)\nfacet.map(sns.kdeplot,'208', shade= True)\nfacet.set(xlim=(0, df['208'].max()))\nfacet.add_legend()","01134066":"facet = sns.FacetGrid(df, hue=\"labels\", aspect=4)\nfacet.map(sns.kdeplot,'111', shade= True)\nfacet.set(xlim=(0, df['111'].max()))\nfacet.add_legend()","b6e21614":"facet = sns.FacetGrid(df, hue=\"labels\", aspect=4)\nfacet.map(sns.kdeplot,'150', shade= True)\nfacet.set(xlim=(0, df['150'].max()))\nfacet.add_legend()","b39575e9":"# Split between train and test \ny = df.labels\nX_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels','source'],axis=1)\n                                                    , y\n                                                    , test_size=0.25\n                                                    , stratify = y #shuffle=True\n                                                    , random_state=42\n                                                   )\n\n# Quick Check: before\nX_train[110:130]","e256430d":"# Data normalization \nmean = np.mean(X_train, axis=0)\nstd = np.std(X_train, axis=0)\n\nX_train = (X_train - mean)\/std\nX_test = (X_test - mean)\/std\n\n# Quick Check: after\nX_train[110:130]","d4ab099c":"# prepare the format for Keras \nX_train = np.array(X_train)\ny_train = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n\n# one hot encode the target \nlb = LabelEncoder()\ny_train = np_utils.to_categorical(lb.fit_transform(y_train))\ny_test = np_utils.to_categorical(lb.fit_transform(y_test))\n\nprint(X_train.shape)\nprint(lb.classes_)","2a9d41a9":"# Using a CNN, we need to specify the 3rd dimension: 1 because we're doing a 1D CNN. \nX_train = np.expand_dims(X_train, axis=2)\nX_test = np.expand_dims(X_test, axis=2)\nX_train.shape","e418786b":"# building the model:\nmodel = Sequential()\nmodel.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(256, 8, padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling1D(pool_size=(8)))\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling1D(pool_size=(8)))\nmodel.add(Conv1D(64, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(64, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Flatten())\nmodel.add(Dense(14)) # Target class number\nmodel.add(Activation('softmax'))\n\nmodel.summary()","81abb410":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# feel free to try the optimizers bellow for better results:\n# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n# opt = keras.optimizers.Adam(lr=0.0001)\n# opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n# model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","d1ae82b3":"from keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(patience=2, verbose=1)","b3f43ca2":"model_history=model.fit(X_train, y_train, batch_size=16, epochs=15, validation_data=(X_test, y_test), callbacks=[early_stopping])","46155849":"test_loss, test_acc = model.evaluate(X_test, y_test)\nprint(f\"Test accuracy {test_acc * 100:.2f} %\")\nprint(f\"Test loss {test_loss}\")","8b4c842d":"pd.DataFrame(model_history.history).plot()","5192f36b":"Let's chose a more colorful way of seeing things:","c852bef5":"Before we move forward, for a basic better understanding of what we have done above, let's have a look at how bands capture the labels:","dfaf28f3":"Transforming the data and Building the model:","eaa78328":"Let it run for more epochs and you increase step by step your accuracy:\n\nfor batch_size=16, epochs=15 I got:\n\n3041\/3041 [==============================] - 8s 3ms\/step\n\nTest accuracy 41.93 %\n\nTest loss 1.8744198793802007\n\n- somewhere between 25 and 35 epochs: a 44-47% accuracy is possible.\n\n- due to time and computational constrains on Kaggle I have used early_stopping \/ though feel free to play at home.","117eeab2":"Now will go through data sets, and arrange them in such a way that would enable us to merge them together later. I have left visible the outputs so you can have a quick idea of what sentiment classes are represented in each data set. ","cc8af9f7":"Hi everyone, \n\nYou might have visit this kernel due to my [Medium article](https:\/\/medium.com\/@daniel.moraite) or [Github](https:\/\/github.com\/DanielMoraite) repository on How to **Deploy a NN with Flask, Docker and Amazon Web Services Elastic Beanstalk**.\n\nThis is useful if you want to have a quick understanding of how the data was managed and the model built for the application above. Actually the model I offer on github has around 50% accuracy. I am working (and will provide later) on a better accuracy model .. though you need some patience, this models do take a little bit of time to train (due on my current computational resources).\n\nI would like to bring many thanks to [Eu Jin Lok](https:\/\/www.kaggle.com\/ejlok1) who was kind enough to provide us all with his detailed work and kernels for audio processing. He said this might be tricky to deploy and I hope I proved him otherwise. \n\nHope this helps and if you do improve the model give me a shout! Would be fun to see your take on it. \n\nGood Luck, \n\nDaniel","a706f352":"There is still room for huuuge improvement: \n\nLooks(plot above) like an underfit model that does not have sufficient capacity. ;) \n\nLet it run for a considerable no of epochs. \n\nBest of luck,\n\nDaniel"}}