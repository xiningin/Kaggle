{"cell_type":{"052e32cb":"code","7f54a68b":"code","ca606f23":"code","61b1b748":"code","b1c558a9":"code","10b29f93":"code","2dd3e5b4":"code","1c0d24ae":"code","21d8d125":"code","549c0242":"code","784c849b":"code","ffb348c3":"code","dd9d023f":"code","ebc4857a":"code","57021697":"code","1338d04d":"code","b24ddabf":"code","423e8bb3":"code","6edcf755":"code","79039d46":"code","795ca408":"code","5b6652d7":"code","0fdbd1a1":"code","fb3ed00a":"code","87f2e29c":"code","ebe4bbb0":"code","f1eb0a5d":"code","9513ff24":"markdown","f1b67a86":"markdown","ab3db67a":"markdown","eaed8185":"markdown","2e556181":"markdown","efe6d1a4":"markdown","423b599c":"markdown"},"source":{"052e32cb":"import os\nimport pandas as pd\ntry:\n    #Kaggle\n    data = pd.read_pickle('..\/input\/chest-xrays-multi-and-single-label-with-resampling\/xrays-nih-data-binary.plk')\nexcept FileNotFoundError:\n    #Local\n    data = pd.read_pickle('..\/preprocesing\/dataset\/xrays-data-binary.plk')\n    \nprint(f'The dimentions of the Dataset are: {data.shape}')\ndata.head()","7f54a68b":"import numpy as np\n\nall_labels = np.unique(data['disease'])\nprint(f'Labels: {len(all_labels)}')","ca606f23":"from sklearn.model_selection import train_test_split\n\ntrain_and_valid_df, test_df = train_test_split(data, \n                                   test_size = 0.30, \n                                   random_state = 2018)\n\ntrain_df, valid_df = train_test_split(train_and_valid_df,\n                                      test_size=0.30,\n                                      random_state=2018)\n\nprint(f'Train {train_df.shape[0]} Validation {valid_df.shape[0]} Test: {test_df.shape[0]}')","61b1b748":"from keras.applications.resnet50 import preprocess_input\nfrom keras_preprocessing.image import ImageDataGenerator\n\ntrain_idg = ImageDataGenerator(rescale=1.\/255, horizontal_flip=True)\n\"\"\"Nuevo\"\"\"\ncore_idg = ImageDataGenerator(preprocessing_function=preprocess_input)\n#core_idg = ImageDataGenerator()","b1c558a9":"def flow_from_dataframe(img_data_gen, in_df, target_size, batch_size):\n\n    df_gen = img_data_gen.flow_from_dataframe(in_df,\n                                              class_mode='binary',\n                                              x_col='path',\n                                              y_col='disease',\n                                              target_size=target_size,\n                                              batch_size=batch_size)\n    return df_gen","10b29f93":"# En este caso le pasamos el tama\u00f1o de imagen, por si se desea por ejemplo reducir el tama\u00f1o\nIMG_SIZE = (224, 224)\n\ntrain_gen = flow_from_dataframe(img_data_gen=core_idg, \n                                in_df= train_df, \n                                target_size = IMG_SIZE,\n                                batch_size = 32)\n\nvalid_gen = flow_from_dataframe(img_data_gen=core_idg, \n                                in_df=valid_df,\n                                target_size = IMG_SIZE,\n                                batch_size = 256) # we can use much larger batches for evaluation\n\ntest_gen = flow_from_dataframe(img_data_gen=core_idg, \n                               in_df=test_df,\n                               target_size = IMG_SIZE,\n                               batch_size = 256) # one big batch\nprint(f'Train: {train_gen.n}, Validation: {valid_gen.n}, Test: {test_gen.n}')","2dd3e5b4":"from keras.applications import ResNet50\nfrom keras.models import Sequential\nfrom keras.layers import Dense","1c0d24ae":"t_x, ty = next(train_gen)\nprint(t_x.shape[1:])","21d8d125":"#resnet_weights_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'","549c0242":"#Conv1D(filters, kernel_size, strides=1, padding='valid', data_format='channels_last', dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)","784c849b":"print(224\/2)\nprint(224\/2\/2)\nprint(224\/2\/2\/2)","ffb348c3":"#input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n\n#x = Conv2D(112, (3, 3), activation='relu', padding='same')(input_img)\n#x = MaxPooling2D((2, 2), padding='same')(x)\n#x = Conv2D(56, (3, 3), activation='relu', padding='same')(x)\n#x = MaxPooling2D((2, 2), padding='same')(x)\n#x = Conv2D(28, (3, 3), activation='relu', padding='same')(x)\n#x = MaxPooling2D((2, 2), padding='same')(x)\n#x = \n\n#model = ","dd9d023f":"#model = Sequential()\n\n#model.add(Conv1D(filters = 32, kernel_size = (5,5),padding = 'Same', \n#                 activation ='relu', input_shape = (28,28,1)))\n#model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n#                 activation ='relu'))\n#model.add(MaxPool2D(pool_size=(2,2)))\n#model.add(Dropout(0.25))\n\n\n#model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n#                 activation ='relu'))\n#model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n#                 activation ='relu'))\n#model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n#model.add(Dropout(0.25))\n\n\n#model.add(Flatten())\n#model.add(Dense(256, activation = \"relu\"))\n#model.add(Dropout(0.5))\n#model.add(Dense(10, activation = \"softmax\"))","ebc4857a":"from keras.models import Sequential\nfrom keras.optimizers import SGD\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy', 'binary_accuracy'])","57021697":"model.summary()","1338d04d":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nimport keras.callbacks as kcall\nweight_path=\"{}_weights.best.hdf5\".format('cnn_from_scratch_xray_class')\nweight_path","b24ddabf":"class LossHistory(kcall.Callback):\n    def on_train_begin(self, logs={}):\n        #Batch\n        self.batch_losses = []\n        self.batch_acc = []\n        #Epochs\n        self.epochs_losses = []\n        self.epochs_acc = []\n        self.epochs_val_losses = []\n        self.epochs_val_acc = []\n        \n    def on_batch_end(self, batch, logs={}):\n        self.batch_losses.append(logs.get('loss'))\n        self.batch_acc.append(logs.get('acc'))\n        \n    def on_epoch_end(self, epoch, logs={}):\n        self.epochs_losses.append(logs.get('loss'))\n        self.epochs_acc.append(logs.get('acc'))\n        self.epochs_val_losses.append(logs.get('val_loss'))\n        self.epochs_val_acc.append(logs.get('val_acc'))","423e8bb3":"history = LossHistory()\n\n# To save the bests weigths\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=5)\n\ncallbacks_list = [checkpoint, early, history]\ncallbacks_list","6edcf755":"\"\"\"\nvalidation_steps: Only relevant if validation_data is a generator. \nTotal number of steps (batches of samples) to yield from validation_data generator \nbefore stopping at the end of every epoch. It should typically be equal to the number of samples \nof your validation dataset divided by the batch size\n\"\"\"\nfit_history = model.fit_generator(train_gen,\n                    steps_per_epoch=train_gen.n\/\/train_gen.batch_size,\n                    validation_data = valid_gen,\n                    validation_steps=valid_gen.n\/\/valid_gen.batch_size,\n                    epochs = 20,\n                    callbacks = callbacks_list)","79039d46":"print(fit_history.history.keys())","795ca408":"import matplotlib.pyplot as plt\n\nplt.figure(1, figsize = (15,8)) \n    \nplt.subplot(221)  \nplt.plot(fit_history.history['accuracy'])  \nplt.plot(fit_history.history['val_accuracy'])  \nplt.title('model accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'valid']) \n    \nplt.subplot(222)  \nplt.plot(fit_history.history['loss'])  \nplt.plot(fit_history.history['val_loss'])  \nplt.title('model loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'valid']) \n\nplt.show()","5b6652d7":"#Numpy array(s) of predictions.\nmodel.load_weights(weight_path)\nmodel.compile(loss='binary_crossentropy',\n              optimizer=SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy', 'binary_accuracy'])\n\n\npred_y = model.predict_generator(test_gen, steps=test_gen.n\/\/test_gen.batch_size+1, verbose = True)","0fdbd1a1":"a = np.array([0.3, 0.4, 0.5, 0.52, 0.60])\nnp.rint(a)","fb3ed00a":"pred_y","87f2e29c":"print(np.rint(pred_y))","ebe4bbb0":"test_gen.reset()\n\n# Convert the predicted classes from arrays to integers.\ncls_pred = np.rint(pred_y)\ncls_test = np.array(test_gen.classes)\nprint(cls_pred)\nprint(cls_test)","f1eb0a5d":"## For Confusion Matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ntest_gen.reset()\n\n# Convert the predicted classes from arrays to integers.\ncls_pred = np.rint(pred_y)\ncls_test = np.array(test_gen.classes)\n\n# Import a function from sklearn to calculate the confusion-matrix.\nfrom sklearn.metrics import confusion_matrix\n\ndef print_confusion_matrix(cls_pred,):\n    # cls_pred is an array of the predicted class-number for\n    # all images in the test-set.\n\n    # Get the confusion matrix using sklearn.\n    cm = confusion_matrix(y_true=cls_test,  # True class for test-set.\n                          y_pred=cls_pred)  # Predicted class.\n\n    print(\"Confusion matrix:\")\n    \n    # Print the confusion matrix as text.\n    print(cm)\n    \n    # Print the class-names for easy reference.\n    for i, class_name in enumerate(all_labels):\n        print(\"({0}) {1}\".format(i, class_name))\n        \n    df_cm = pd.DataFrame(cm, index = ['True_'+i for i in all_labels],\n                  columns = ['Pred_'+i for i in all_labels])\n    plt.figure(figsize = (10,7))\n    sns.heatmap(df_cm, annot=True,fmt=\"d\",cmap=\"BuPu\",annot_kws={\"size\": 10})# font size\n    sns.set(font_scale=1)#for label size\n    plt.show()\n    \nprint_confusion_matrix(cls_pred)","9513ff24":"### First Train (Transfer)","f1b67a86":"### Check Output\nHere we see how many positive examples we have of each category","ab3db67a":"## 2. Split the data\n\nFor this process the library **sklearn** is used.\n\nThe data set is separated into three: training, validation and test data set.\n\nThe steps to follow are:\n\n1. Separate the data set in training and test, 70% and 30% respectively.\n2. Remove 30% of the training data set to generate the validation data set.\n\n> To generate a good separation of the data, the proportion of the classes must be maintained, the parameter **stratify** will be used with the [pandas.Serie](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.Series.html) generated from the *Finding Labels* column.","eaed8185":"Se hace siguiendo: https:\/\/www.kaggle.com\/suniliitb96\/tutorial-keras-transfer-learning-with-resnet50 no uso softmax ni categorical","2e556181":"## 3. Generate the inputs for the CNN\n\nAn instance of the ImageGenerator object is created in which it is possible to define by constructor if you want to make some transformations to the images, but in this case the images have been previously processed.\n\nThis istances will be used to generate the inputs for the CNN","efe6d1a4":"## 1. Read The data\nThe following libraries will be used to read the dataset:\n* **os:** to recognize operating system folders\n* **pandas:** to read the file with plk extension\n\nAn exception handling is added with the intention of running the notebook in kaggle or in local","423b599c":"### Create a simple model"}}