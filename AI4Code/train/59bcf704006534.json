{"cell_type":{"136abb76":"code","3d6632d9":"code","acfcee67":"code","cdc1ad56":"code","14bbf1dd":"code","97c186f8":"code","814b7d8b":"code","92091599":"code","b25ce355":"code","d53b653b":"code","3af294ca":"code","796fdc06":"code","77df7366":"code","f44e6e5c":"code","72651ffd":"code","f04cd832":"code","b623546f":"code","f6a2503f":"code","7a1b8394":"code","86bf4fae":"code","1488609f":"code","5c024d4c":"code","e2e32a50":"code","c4cb71c8":"markdown","b7665ae4":"markdown","d4f46d5f":"markdown","b5bcec05":"markdown","ffdb2bb0":"markdown"},"source":{"136abb76":"import os\nimport random\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","3d6632d9":"# Tabular data file paths\nTRAIN_DATA_PATH = '..\/input\/petfinder-pawpularity-score\/train.csv'\nTEST_DATA_PATH = '..\/input\/petfinder-pawpularity-score\/test.csv'\n\n# Image data directories\nTRAIN_DIRECTORY = '..\/input\/petfinder-pawpularity-score\/train'\nTEST_DIRECTORY = '..\/input\/petfinder-pawpularity-score\/test'","acfcee67":"# Parameters for processing tabular data\nTARGET_NAME = 'Pawpularity'\nVAL_SIZE = 0.15\nSEED = 5","cdc1ad56":"# TensorFlow settings and training parameters\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nIMG_SIZE = 224\nBATCH_SIZE = 64\nDROPOUT_RATE = 0.2\nLEARNING_RATE = 1e-4\nDECAY_STEPS = 200\nDECAY_RATE = 0.96\nEPOCHS = 500\nPATIENCE = 3","14bbf1dd":"# Pretrained image classification model EfficientNetB4\n# from tf.keras.applications with global average pooling as a final layer.\n# In this notebook the model is loaded from a public dataset on Kaggle\n# at https:\/\/www.kaggle.com\/ekaterinadranitsyna\/keras-applications-models\nIMG_MODEL = '..\/input\/keras-applications-models\/EfficientNetB0.h5'","97c186f8":"def set_seed(seed=42):\n    \"\"\"Utility function to use for reproducibility.\n    :param seed: Random seed\n    :return: None\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\n\ndef set_display():\n    \"\"\"Function sets display options for charts and pd.DataFrames.\n    \"\"\"\n    # Plots display settings\n    plt.style.use('fivethirtyeight')\n    plt.rcParams['figure.figsize'] = 12, 8\n    plt.rcParams.update({'font.size': 14})\n    # DataFrame display settings\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    pd.options.display.float_format = '{:.4f}'.format\n\n\ndef id_to_path(img_id: str, dir: str):\n    \"\"\"Function returns a path to an image file.\n    :param img_id: Image Id\n    :param dir: Path to the directory with images\n    :return: Image file path\n    \"\"\"\n    return os.path.join(dir, f'{img_id}.jpg')\n\n\n@tf.function\ndef get_image(path: str) -> tf.Tensor:\n    \"\"\"Function loads image from a file and preprocesses it.\n    :param path: Path to image file\n    :return: Tensor with preprocessed image\n    \"\"\"\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    image = tf.cast(tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE), dtype=tf.int32)\n    return tf.keras.applications.efficientnet.preprocess_input(image)\n\n\n@tf.function\ndef process_dataset(path: str, label: int) -> tuple:\n    \"\"\"Function returns preprocessed image and label.\n    :param path: Path to image file\n    :param label: Class label\n    :return: tf.Tensor with preprocessed image, numeric label\n    \"\"\"\n    return get_image(path), label\n\n\n@tf.function\ndef get_dataset(x, y=None) -> tf.data.Dataset:\n    \"\"\"Function creates batched optimized dataset for the model\n    out of an array of file paths and (optionally) class labels.\n    :param x: Input data for the model (array of file paths)\n    :param y: Target values for the model (array of class indexes)\n    :return TensorFlow Dataset object\n    \"\"\"\n    if y is not None:\n        ds = tf.data.Dataset.from_tensor_slices((x, y))\n        return ds.map(process_dataset, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(x)\n        return ds.map(get_image, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\n\ndef plot_history(hist):\n    \"\"\"Function plots a chart with training and validation metrics.\n    :param hist: Tensorflow history object from model.fit()\n    \"\"\"\n    # Losses and metrics\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n    rmse = hist.history['root_mean_squared_error']\n    val_rmse = hist.history['val_root_mean_squared_error']\n\n    # Epochs to plot along x axis\n    x_axis = range(1, len(loss) + 1)\n\n    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n\n    ax1.plot(x_axis, loss, 'bo', label='Training')\n    ax1.plot(x_axis, val_loss, 'ro', label='Validation')\n    ax1.set_title('MSE Loss')\n    ax1.legend()\n\n    ax2.plot(x_axis, rmse, 'bo', label='Training')\n    ax2.plot(x_axis, val_rmse, 'ro', label='Validation')\n    ax2.set_title('Root Mean Squared Error')\n    ax2.set_xlabel('Epochs')\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.show()","814b7d8b":"set_seed(SEED)\nset_display()","92091599":"# Train data set\ndata_train = pd.read_csv(TRAIN_DATA_PATH)\nprint(f'Train data shape: {data_train.shape}')\ndata_train.head()","b25ce355":"# Test data set\ndata_test = pd.read_csv(TEST_DATA_PATH)\nprint(f'Test data shape: {data_test.shape}')\ndata_test.head()","d53b653b":"# Reconstruct the paths to train and test images.\ndata_train['path'] = data_train['Id'].apply(\n    lambda x: id_to_path(x, TRAIN_DIRECTORY))\ndata_test['path'] = data_test['Id'].apply(\n    lambda x: id_to_path(x, TEST_DIRECTORY))\n\n# Keep a portion of the labeled data for validation.\ntrain_subset, valid_subset = train_test_split(\n    data_train[['path', TARGET_NAME]],\n    test_size=VAL_SIZE, shuffle=True, random_state=SEED\n)","3af294ca":"# Create TensorFlow datasets\ntrain_ds = get_dataset(x=train_subset['path'], y=train_subset[TARGET_NAME])\nvalid_ds = get_dataset(x=valid_subset['path'], y=valid_subset[TARGET_NAME])\ntest_ds = get_dataset(x=data_test['path'])","796fdc06":"# Pretrained image classification model\nfeature_model = tf.keras.models.load_model(IMG_MODEL)\n\n# Make top layers trainable with the exception of BatchNormalization.\nfeature_model.trainable = False\nfor layer in feature_model.layers[-20:]:\n    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n        layer.trainable = True","77df7366":"# This model takes in 224 x 224 images, applies random horizontal flip\n# (only in the train mode), passes image arrays through pretrained\n# feature extraction model and applies batch normalization, dropout\n# and activations to get the target score.\nimage_model = tf.keras.models.Sequential(\n    [\n        tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal'),\n        feature_model,\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(DROPOUT_RATE, name='top_dropout'),\n        tf.keras.layers.Dense(32, activation='relu'),\n        tf.keras.layers.Dense(1, name='score')\n    ]\n)","f44e6e5c":"# To gradually decrease learning rate\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=LEARNING_RATE,\n    decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE,\n    staircase=True)","72651ffd":"# Compile the model\nimage_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n                    loss=tf.keras.losses.MeanSquaredError(),\n                    metrics=[tf.keras.metrics.RootMeanSquaredError()])","f04cd832":"image_model.summary()","b623546f":"# To monitor validation loss and stop the training.\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=PATIENCE, restore_best_weights=True)","f6a2503f":"history = image_model.fit(train_ds, validation_data=valid_ds,\n                          epochs=EPOCHS, callbacks=[early_stop],\n                          use_multiprocessing=True, workers=-1)","7a1b8394":"val_mse, val_rmse = image_model.evaluate(valid_ds)\nprint(f'Validation MSE = {val_mse}\\nValidation RMSE = {val_rmse}')","86bf4fae":"plot_history(history)","1488609f":"image_model.save_weights('img_model_weights.h5')","5c024d4c":"# Predict popularity score for the test\ndata_test[TARGET_NAME] = image_model.predict(\n    test_ds, use_multiprocessing=True, workers=os.cpu_count())","e2e32a50":"data_test[['Id', TARGET_NAME]].to_csv('submission.csv', index=False)\ndata_test[['Id', TARGET_NAME]].head()","c4cb71c8":"## Data Processing","b7665ae4":"Pretrained **EfficientNetB0 model from Keras applications** is fine-tuned with small learning rate and used to extract features from images resized to 224 x 224. Popularity score is estimated based solely on images. Tabular data is ignored. Since image quality affects the target value only horizontal flip is used for data augmentation.","d4f46d5f":"## Inference","b5bcec05":"## Functions","ffdb2bb0":"# Pretrained Image Model to Predict Pet Popularity"}}