{"cell_type":{"84e9858f":"code","285ddc3b":"code","843e78f4":"code","614faae4":"code","1013f663":"code","251af745":"code","91ae1cc3":"code","50d46f38":"code","75d30ba2":"code","6f7532ff":"code","108af2a0":"code","404144de":"code","4bd06d56":"code","dcc304e0":"code","ee64d1fa":"code","86d83df5":"code","af9bd93f":"code","6c5cbcb8":"code","eca8a85f":"markdown","567044d9":"markdown","1de1b778":"markdown","a764d1a1":"markdown","8b98a5fa":"markdown","8c0f0ed6":"markdown","9a83f12b":"markdown","15799c1f":"markdown","e223dcb2":"markdown","d760fe0d":"markdown","0955ee9d":"markdown","60c098d5":"markdown","6e1ed128":"markdown","fb10c6b5":"markdown","f82ce4e8":"markdown","9632c58d":"markdown"},"source":{"84e9858f":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping\nfrom keras import optimizers\nfrom keras import regularizers","285ddc3b":"TRAIN_PATH = '..\/input\/train.csv'\nTEST_PATH = '..\/input\/test.csv'\nSUBMISSION_NAME = 'submission.csv'\nDATASET_SIZE = 200000\n# datatypes = {'key': 'str', \n#               'fare_amount': 'float32',\n#               'pickup_datetime': 'str', \n#               'pickup_longitude': 'float32',\n#               'pickup_latitude': 'float32',\n#               'dropoff_longitude': 'float32',\n#               'dropoff_latitude': 'float32',\n#               'passenger_count': 'uint8'}\ntrain = pd.read_csv(TRAIN_PATH, nrows=DATASET_SIZE)\ntest = pd.read_csv(TEST_PATH)\n# train.head()\n# test=test.drop('key', axis=1)\ntrain.head()\nprint('Old size: %d' % len(train))\ntrain = train[train.fare_amount>=0]\nprint('New size: %d' % len(train))\n","843e78f4":"print('Old size: %d' % len(train))\ntrain = train.dropna(how = 'any', axis = 'rows')\nprint('New size: %d' % len(train))","614faae4":"# def select_within_boundingbox(df, BB):\n#     return (df.pickup_longitude >= BB[0]) & (df.pickup_longitude <= BB[1]) & \\\n#            (df.pickup_latitude >= BB[2]) & (df.pickup_latitude <= BB[3]) & \\\n#            (df.dropoff_longitude >= BB[0]) & (df.dropoff_longitude <= BB[1]) & \\\n#            (df.dropoff_latitude >= BB[2]) & (df.dropoff_latitude <= BB[3])\n            \n# # load image of NYC map\n# BB = (-74.5, -72.8, 40.5, 41.8)\n# print('Old size: %d' % len(train))\n# train = train[select_within_boundingbox(train, BB)]\n# print('New size: %d' % len(train))","1013f663":"print('Old size: %d' % len(train))\ndef clean(df):\n    # Delimiter lats and lons to NY only\n    df = df[(-76 <= df['pickup_longitude']) & (df['pickup_longitude'] <= -72)]\n    df = df[(-76 <= df['dropoff_longitude']) & (df['dropoff_longitude'] <= -72)]\n    df = df[(38 <= df['pickup_latitude']) & (df['pickup_latitude'] <= 42)]\n    df = df[(38 <= df['dropoff_latitude']) & (df['dropoff_latitude'] <= 42)]\n    # Remove possible outliers\n    df = df[(0 < df['fare_amount']) & (df['fare_amount'] <= 250)]\n    # Remove inconsistent values\n    df = df[(df['dropoff_longitude'] != df['pickup_longitude'])]\n    df = df[(df['dropoff_latitude'] != df['pickup_latitude'])]\n    \n    return df\ntrain = clean(train)\nprint('New size: %d' % len(train))\ntrain.head()","251af745":"def late_night (row):\n    if (row['hour'] <= 6) or (row['hour'] >20):\n        return 1\n    else:\n        return 0\ndef night (row):\n    if ((row['hour'] <= 20) and (row['hour'] > 16)) and (row['weekday'] < 5):\n        return 1\n    else:\n        return 0    \ndef day_time(row):\n    if (row['hour'] <= 16) and (row['hour'] >6):\n        return 1\n    else:\n        return 0\ndef spring(row):\n    if (row['month'] >=4) and (row['month'] <7):\n        return 1\n    else:\n        return 0  \ndef summer(row):\n    if (row['month'] >=7) and (row['month'] <10):\n        return 1\n    else:\n        return 0\ndef fall(row):\n    if (row['month'] >=10) and (row['month'] <=12):\n        return 1\n    else:\n        return 0  \ndef winter(row):\n    if (row['month'] >=1) and (row['month'] <4):\n        return 1\n    else:\n        return 0  \n\ndef add_time_features(df):\n    df['pickup_datetime'] =  pd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S %Z')\n    df['year'] = df['pickup_datetime'].apply(lambda x: x.year)\n    df['month'] = df['pickup_datetime'].apply(lambda x: x.month)\n    df['day'] = df['pickup_datetime'].apply(lambda x: x.day)\n    df['hour'] = df['pickup_datetime'].apply(lambda x: x.hour)\n    df['weekday'] = df['pickup_datetime'].apply(lambda x: x.weekday())\n    df['pickup_datetime'] =  df['pickup_datetime'].apply(lambda x: str(x))\n    df['night'] = df.apply (lambda x: night(x), axis=1)\n    df['late_night'] = df.apply (lambda x: late_night(x), axis=1)\n    df['day_time'] = df.apply (lambda x: day_time(x), axis=1)\n    df['spring']=df.apply (lambda x: spring(x), axis=1)\n    df['summer']=df.apply (lambda x: summer(x), axis=1)\n    df['fall']=df.apply (lambda x: fall(x), axis=1)\n    df['winter']=df.apply (lambda x: winter(x), axis=1)\n    # Drop 'pickup_datetime' as we won't need it anymore\n    df = df.drop('pickup_datetime', axis=1)\n    return df\ntrain = add_time_features(train)\ntest = add_time_features(test)\ntrain.head(100)","91ae1cc3":"# print(train.year.min(),train.year.max())\n# print(test.year.min(),test.year.max())\ndef distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295 # Pi\/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)\/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) \/ 2\n    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a))","50d46f38":"def add_coordinate_features(df):\n    lat1 = df['pickup_latitude']\n    lat2 = df['dropoff_latitude']\n    lon1 = df['pickup_longitude']\n    lon2 = df['dropoff_longitude']\n    # Add new features\n    df['latdiff'] = (lat1 - lat2)\n    df['londiff'] = (lon1 - lon2)\n    return df","75d30ba2":"def manhattan(pickup_lat, pickup_long, dropoff_lat, dropoff_long):\n    return np.abs(dropoff_lat - pickup_lat) + np.abs(dropoff_long - pickup_long)\ndef add_distances_features(df):\n    # Add distances from airpot and downtown\n    ny = (-74.0063889, 40.7141667)\n    jfk = (-73.7822222222, 40.6441666667)\n    ewr = (-74.175, 40.69)\n    lgr = (-73.87, 40.77)\n    \n    lat1 = df['pickup_latitude']\n    lat2 = df['dropoff_latitude']\n    lon1 = df['pickup_longitude']\n    lon2 = df['dropoff_longitude']\n    \n    df['euclidean'] = (df['latdiff'] ** 2 + df['londiff'] ** 2) ** 0.5\n    df['manhattan'] = manhattan(lat1, lon1, lat2, lon2)\n    \n    df['downtown_pickup_distance'] = manhattan(ny[1], ny[0], lat1, lon1)\n    df['downtown_dropoff_distance'] = manhattan(ny[1], ny[0], lat2, lon2)\n    df['jfk_pickup_distance'] = manhattan(jfk[1], jfk[0], lat1, lon1)\n    df['jfk_dropoff_distance'] = manhattan(jfk[1], jfk[0], lat2, lon2)\n    df['ewr_pickup_distance'] = manhattan(ewr[1], ewr[0], lat1, lon1)\n    df['ewr_dropoff_distance'] = manhattan(ewr[1], ewr[0], lat2, lon2)\n    df['lgr_pickup_distance'] = manhattan(lgr[1], lgr[0], lat1, lon1)\n    df['lgr_dropoff_distance'] = manhattan(lgr[1], lgr[0], lat2, lon2)\n    return df","6f7532ff":"\nadd_coordinate_features(train)\nadd_coordinate_features(test)\ntrain = add_distances_features(train)\ntest = add_distances_features(test)\ntrain.head()","108af2a0":"dropped_columns = ['pickup_longitude', 'pickup_latitude', \n                   'dropoff_longitude', 'dropoff_latitude']\ntrain_clean = train.drop(dropped_columns, axis=1)\ntest_clean = test.drop(dropped_columns + ['key', 'passenger_count'], axis=1)\n\n# peek data\ntrain_clean.head()","404144de":"train_df, validation_df = train_test_split(train_clean, test_size=0.10, random_state=1)\n# Get labels\ntrain_labels = train_df['fare_amount'].values\nvalidation_labels = validation_df['fare_amount'].values\ntrain_df = train_df.drop(['fare_amount'], axis=1)\nvalidation_df = validation_df.drop(['fare_amount'], axis=1)","4bd06d56":"scaler = preprocessing.MinMaxScaler()\ntrain_df_scaled = scaler.fit_transform(train_df)\nvalidation_df_scaled = scaler.transform(validation_df)\ntest_scaled = scaler.transform(test_clean)","dcc304e0":"BATCH_SIZE = 256\nEPOCHS = 20\nLEARNING_RATE = 0.001\nmodel = Sequential()\nmodel.add(Dense(256, activation='relu', input_dim=train_df_scaled.shape[1], activity_regularizer=regularizers.l1(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(8, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1))\nadam = optimizers.Adam(lr=LEARNING_RATE)\nmodel.compile(loss='mse', optimizer=adam, metrics=['mae'])","ee64d1fa":"history = model.fit(x=train_df_scaled, y=train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, \n                    verbose=1, validation_data=(validation_df_scaled, validation_labels), \n                    shuffle=True)","86d83df5":"plt.figure(figsize=(20,10))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","af9bd93f":"prediction = model.predict(test_scaled, batch_size=128, verbose=1)","6c5cbcb8":"def output_submission(raw_test, prediction, id_column, prediction_column, file_name):\n    df = pd.DataFrame(prediction, columns=[prediction_column])\n    df[id_column] = raw_test[id_column]\n    df[[id_column, prediction_column]].to_csv((file_name), index=False)\n    print('Output complete')\noutput_submission(test, prediction, 'key', 'fare_amount', SUBMISSION_NAME)","eca8a85f":"## step 2: Data clean","567044d9":"\n* * Year, Month, Day, Hour, Weekday\n* * Night (between 16h and 20h, from monday to friday)\n* * Late night (between 20h and and 6h)","1de1b778":"## Step 1 : Data load and clean","a764d1a1":"make map small","8b98a5fa":"## step 6 : Create Model","8c0f0ed6":"* * Latitude difference (difference from pickup and dropout latitudes)\n* * Longitude difference (difference from pickup and dropout longitudes)","9a83f12b":"## step 5 : Split data in train and validation","15799c1f":"## step 3.2 : Coordinate features","e223dcb2":"remove missing data","d760fe0d":"# New York City Taxi Fare Prediction","0955ee9d":"## step 3.1 : Time features","60c098d5":"## step 3.3 : Distances features","6e1ed128":"### After analysis of data, we need to remove some noisy from data.\n* Lats and lons that do not belong to New York.\n* Negative fare.\n* Fare greater than 250 (this seems to be noisy data).\n* Rides that begin and end in the same location.","fb10c6b5":"## step 7 : Training Model","f82ce4e8":"## step 4 : Process data","9632c58d":"## Team member\uff1a\n### Haoun Guo          hg1483\n### Da Cai             dc4069\n### Naisheng Zhang     nz862"}}