{"cell_type":{"4f9fc9b4":"code","1c809f23":"code","c458067f":"code","9a18d451":"code","a3e6abfb":"code","6edc0cb9":"code","9b7bffa7":"code","139a4ffd":"code","b3aa05ec":"code","8e6afc33":"code","6d99c6e8":"code","29cafd7d":"code","ef5b5e5a":"code","b8fe7a98":"code","1236252d":"code","4d5ae0d8":"code","b1f93455":"code","37fb4d2d":"markdown","342118de":"markdown","e57d42a5":"markdown","a1c5ea4b":"markdown","b55bab2b":"markdown","44a7d025":"markdown","38027230":"markdown"},"source":{"4f9fc9b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nimport keras\nimport albumentations as A\nfrom sklearn import model_selection, preprocessing \nimport cv2\nimport tensorflow as tf\nimport numpy as np \nfrom matplotlib import pyplot as plt\nfrom PIL import Image\n","1c809f23":"INPUT_PATH = \"..\/input\/cassava-leaf-disease-classification\/\"\ntrain_images_path = INPUT_PATH+\"train_images\/\"\ntest_images_path = INPUT_PATH+\"test_images\/\"\nsample = \"..\/input\/cassava-leaf-disease-classification\/sample_submission.csv\"","c458067f":"df = pd.read_csv(INPUT_PATH+\"train.csv\")##..\/input\/cassava-leaf-disease-classification\/train.csv\"\ndf.head(5)","9a18d451":"for img in os.listdir(INPUT_PATH+\"train_images\/\")[:1]:\n    #print(img)\n    img = Image.open(os.path.join(train_images_path+img))\n    plt.imshow(img)\n    plt.show()","a3e6abfb":"sample_df = pd.read_csv(sample)\nsample_df.head()","6edc0cb9":"num_classes = sorted(df[\"label\"].unique())\ndf.info()","9b7bffa7":"df.label = df.label.astype(\"str\")\nbatch_size=16\ninput_size = (299, 299)","139a4ffd":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    validation_split = 0.1,\n    rotation_range=360,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    #channel_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rescale=None,\n    preprocessing_function=None,\n    )\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=train_images_path,\n    x_col=\"image_id\",\n    y_col=\"label\",\n    batch_size=batch_size,\n    target_size=input_size,\n    class_mode=\"sparse\", \n    subset = \"training\"\n)\nvalid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.1)\nvalid_generator = train_datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=train_images_path,\n    x_col=\"image_id\",\n    y_col=\"label\",\n    batch_size=batch_size,\n    target_size=input_size ,\n    class_mode=\"sparse\", \n    subset=\"validation\")","b3aa05ec":"plt.figure(figsize=(12,10))\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    batch = train_generator.next()\n    image = batch[0].astype('uint8')\n    plt.imshow(np.array(image[0,:,:,::-1]))\n    plt.axis(\"off\")\n# show the figure\nplt.show()            \n                        ","8e6afc33":"from keras import Model\nfrom keras import optimizers\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import GlobalAveragePooling2D,Dense\n\nmodel_dir = \"..\/input\/inceptionresnetv2\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nmodel = Sequential()\nmodel.add( tf.keras.applications.InceptionResNetV2(\n    include_top=False,\n    weights= model_dir, input_shape=(299, 299, 3)))\n\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(len(num_classes), activation=\"softmax\"))\nmodel.summary()\n","6d99c6e8":"\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n             metrics=['accuracy'])","29cafd7d":"\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath='best_inceptionresnetV2.h5',\n        save_weights_only=True,\n        monitor='val_loss',\n        mode='max',\n        save_best_only=True)\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n\nhist  = model.fit_generator(\n    train_generator,\n    validation_data = valid_generator,\n    #\n    steps_per_epoch = len(df)*0.9\/\/batch_size,\n    validation_steps = len(df)*0.1\/\/batch_size, \n    epochs = 10,\n    callbacks = [model_checkpoint ,early_stopping],\n    \n)","ef5b5e5a":"# accuracy \nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# loss\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","b8fe7a98":"#model = model.load_weights(\".\/best_inceptionresnetV2.h5\")","1236252d":"\npredictions = []\nfor  image_id in sample_df.image_id:\n    img = Image.open(os.path.join(test_images_path+image_id))\n    img = img.resize((224,224))\n    img = np.expand_dims(img, axis=0)\n    predictions.append(np.argmax(model.predict(img)))\n\nsample_df[\"label\"] = predictions\nsample_df","4d5ae0d8":"sample_df.head\n","b1f93455":"sample_df.to_csv(\"submission.csv\", index = False)","37fb4d2d":"**Data Augmentation**","342118de":"# Define Model, Train and Evaluate","e57d42a5":"**Let's Train**","a1c5ea4b":"**Predict and make Submission**","b55bab2b":"**Let's Have a look of few data** ","44a7d025":"# **Prepare Dataset For training**","38027230":"# Loading Paths, Directory and Data-Folders "}}