{"cell_type":{"ebf83b71":"code","bcf66935":"code","d3257e13":"code","bbaa3568":"code","fd126db9":"code","06f70729":"code","3bc4ec7d":"code","0a493576":"code","58b4a5c5":"code","b1f15c7e":"code","115cdaaa":"code","78d76c3d":"code","5036fe84":"code","acae9384":"code","531dc57b":"code","ffb38349":"code","a75e2e84":"code","f2eb80fd":"code","fb46b688":"markdown"},"source":{"ebf83b71":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport sys\n\nprint(os.listdir(\"..\/input\"))\nprint(os.listdir(\"..\/input\/seg_train\/seg_train\"))\n# Any results you write to the current directory are saved as output.","bcf66935":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom IPython.display import display\nimport cv2\nimport matplotlib.image as mtim\nimport matplotlib.pyplot as plt\nimport tqdm\nfrom tqdm import tqdm_notebook\nimport random","d3257e13":"seed = 50\nnp.random.seed(seed)\ntorch.manual_seed(seed)","bbaa3568":"train_path = '..\/input\/seg_train\/seg_train\/'\ntest_path = \"..\/input\/seg_test\/seg_test\/\"\npred_path = \"..\/input\/seg_pred\/seg_pred\/\"\nclasses = dict(enumerate(os.listdir(test_path)))\nprint(classes)","fd126db9":"class ImageDataset(torch.utils.data.Dataset):\n    def __init__(self, imgs_path, root_path, transforms=None):\n        super().__init__()\n        if root_path[-1] != '\/':\n            root_path += '\/'\n        self.root_path = root_path\n        self.imgs_path = imgs_path\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.imgs_path)\n    \n    def __getitem__(self, idx):\n        img = self.get_image(idx)\n        \n        if self.transforms:\n            img = self.transforms(img)\n        return (img, self.imgs_path[idx][1])\n    \n    def get_image(self, idx):\n        img = Image.open(self.root_path + self.imgs_path[idx][0])\n        return img","06f70729":"def get_ImageDataset(path, transform = True):\n    path += '\/' if path[-1] != '\/' else ''\n    classes = os.listdir(path)\n    imgs_path = []\n    counter = 0\n    for cl in classes:\n        for i in os.listdir(path + cl):\n            imgs_path.append((cl + '\/' + i, counter))\n        counter += 1\n        \n    _mean = [.485, .456, .406]\n    _std = [.229, .224, .225]\n    trans = transforms.Compose([\n        transforms.Resize((150, 150)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomCrop((75,75)),\n        transforms.ToTensor(),\n        transforms.Normalize(_mean, _std),\n    ])\n    if transform:\n        return ImageDataset(imgs_path, path, trans)\n    return ImageDataset(imgs_path, path)","3bc4ec7d":"def get_test_valid_ImageDataset(path, valid_size, transform = True):\n    path += '\/' if path[-1] != '\/' else ''\n    classes = os.listdir(path)\n    imgs_path = []\n    counter = 0\n    for cl in classes:\n        for i in os.listdir(path + cl):\n            imgs_path.append((cl + '\/' + i, counter))\n        counter += 1\n        \n    _mean = [.485, .456, .406]\n    _std = [.229, .224, .225]\n    trans = transforms.Compose([\n        transforms.Resize((150, 150)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomCrop((75,75)),\n        transforms.ToTensor(),\n        transforms.Normalize(_mean, _std),\n    ])\n    valid_path = []\n    for i in range(int(valid_size*len(imgs_path))):\n        idx = random.randint(0, len(imgs_path)-1)\n        valid_path.append(imgs_path.pop(idx))\n    if transform:\n        return ImageDataset(imgs_path, path, trans), ImageDataset(valid_path,path, trans)\n    return ImageDataset(imgs_path, path), ImageDataset(valid_path, path)","0a493576":"test_ds, val_ds = get_test_valid_ImageDataset(test_path, 0.4)\ntrain_ds = get_ImageDataset(train_path)\n\ntrain_dl = DataLoader(train_ds, batch_size=30, shuffle=True)\nval_dl = DataLoader(val_ds, batch_size=30, shuffle=True)\ntest_dl = DataLoader(test_ds, batch_size=30, shuffle=False)","58b4a5c5":"ys = []\nfor _, yy in val_dl:\n    ys.extend(yy.tolist())\nprint(classification_report(ys, ys))","b1f15c7e":"print(len(val_dl))\nprint(len(test_dl))\nprint(len(train_dl))","115cdaaa":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 3* 150\n        self.conv1 = nn.Conv2d(3, 25, 11)\n        # 60* 140\n        self.pool1 = nn.MaxPool2d(4, 4)\n        # 60* 35\n        self.conv3 = nn.Conv2d(25, 80, 6)\n        # 100* 30\n        self.conv4 = nn.Conv2d(80, 200, 6)\n        # 200* 25\n        self.pool2 = nn.AvgPool2d(25, 25)\n        self.l1 = nn.Linear(200, 6)\n        \n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(self.pool1(x))    \n        x = self.conv4(self.conv3(x))\n        x = F.relu(self.pool2(x))\n        x = x.view(-1, 200)\n        x = self.l1(x)\n        return x\n    \n    \n    def predict(self, x):\n        return F.log_softmax(self.forward(x), dim=1)\n    \n        \nmodel = Net().cuda() if torch.cuda.is_available() else Net()\nprint(model)","78d76c3d":"def fit(model, train_dl, valid_dl, lr=3e-4, epoches=5):\n        criterion = nn.CrossEntropyLoss()\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n        best_state = None\n        best_acc = 0\n        for epoche in range(epoches):\n            model.train()\n            print(\"Training\")\n            ep_loss = 0\n            for num, (xx, yy) in tqdm_notebook(enumerate(train_dl, 0), total=len(train_dl)):\n                if(torch.cuda.is_available()):\n                    xx, yy = xx.cuda(), yy.cuda()\n                optimizer.zero_grad()\n                y_ = model(xx)\n                loss = criterion(y_, yy)\n                loss.backward()\n                ep_loss+=loss.item()\n                optimizer.step()\n            print(\"Loss: {}\".format(ep_loss\/len(train_dl)))\n        \n            model.eval()\n            y_pred = []\n            y_true = []\n            print(\"Validation\")\n            with torch.no_grad():\n                for num, (xx, yy) in tqdm_notebook(enumerate(valid_dl), total=len(valid_dl)):\n                    y_true.extend(yy.tolist())\n                    if(torch.cuda.is_available()):\n                        xx, yy = xx.cuda(), yy.cuda()\n                    y_ = model.predict(xx).argmax(dim=1)\n                    y_pred.extend(y_.tolist())\n            print(\"Epoche {}\".format(epoche))\n            #print(classification_report(y_true, y_pred))\n            print(confusion_matrix(y_true, y_pred))\n            ep_acc = accuracy_score(y_true, y_pred)\n            print(ep_acc)\n            if best_acc < ep_acc:\n                best_acc = ep_acc\n                best_state = model.state_dict()\n            elif best_acc > ep_acc:\n                model.load_state_dict(best_state)\n                print(\"Ep_acc({:.2}) < Prev_acc({:.2})\".format(ep_acc, best_acc))\n                print(\"Model state was reloaded\")","5036fe84":"fit(model, train_dl, val_dl, epoches=5)","acae9384":"model.eval()\ny_true = []\ny_pred = []\nfor num ,(xx, yy) in tqdm_notebook(enumerate(test_dl), total=(len(test_dl))):\n    if torch.cuda.is_available():\n        xx, yy = xx.cuda(), yy.cuda()\n    out = model(xx).argmax(dim=1)\n    y_true.extend(yy.tolist())\n    y_pred.extend(out.tolist())\nprint(classification_report(y_true, y_pred))\nprint(confusion_matrix(y_true, y_pred))\n    ","531dc57b":"with torch.no_grad():\n    params = list(model.parameters())\n    ps = params[2][1].to(\"cpu\").numpy()\n    print(len(ps))\n    img = mtim.imread(pred_path + os.listdir(pred_path)[9])\n    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    fig=plt.figure(figsize=(10, 10))\n    k = 1\n    j = 1\n    for i in range(0,len(ps)+1):\n        fig.add_subplot(k, len(ps)+1, j)\n        if(j%5 == 0):\n            j = 1\n        if(i%5 == 0):\n            k += 1\n        j += 1\n        if i == 0:\n            plt.imshow(img)        \n        else:\n            f_img = cv2.filter2D(img_gray, -1, ps[i-1])\n            plt.imshow(f_img, cmap='gray')\n    plt.show()","ffb38349":"import random\n_mean = [.485, .456, .406]\n_std = [.229, .224, .225]\ntrans = transforms.Compose([\n    transforms.Resize((150, 150)),\n    transforms.ToTensor(),\n    transforms.Normalize(_mean, _std)])\nimgs_path = []\nbatch_size = 5\nimgs = random.choices(os.listdir(pred_path), k=batch_size)\nprint(imgs)\nfor i in range(batch_size):\n    imgs_path.append((imgs[i],0))\npred_ds = ImageDataset(imgs_path, pred_path, trans)\npred_dl = DataLoader(pred_ds)","a75e2e84":"model.eval()\ncounter = 0\nfor xx, yy in pred_dl:\n    if torch.cuda.is_available():\n        xx = xx.cuda()\n    out = model(xx).argmax(dim=1).item()\n    print(\"This is a {}\".format(classes[out]))\n    display(pred_ds.get_image(counter))\n    counter += 1","f2eb80fd":"import gc\ngc.collect()","fb46b688":"**NetV2 - \n    4ep, lr=0.001 => 2ep, lr=0.0001 : 82%"}}