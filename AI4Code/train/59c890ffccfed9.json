{"cell_type":{"a04745ec":"code","05b7eb14":"code","fab769b3":"code","c542b22b":"code","abdc6c98":"code","acf56528":"code","7f17d23c":"code","05f97624":"code","009192c0":"code","72d9ab12":"code","45f32af9":"code","bc89f1ae":"code","5754358a":"code","778266ab":"code","8c269e6b":"code","d6da0ec2":"code","fa5b1f42":"code","1c5f0e1b":"code","c3b8cfcf":"code","ebde168a":"code","1dc75b4d":"code","456c5573":"code","2b024ab4":"code","2b502b24":"markdown","c205e042":"markdown","699bb54c":"markdown","0435eb5a":"markdown","bbc078ae":"markdown","b4e01764":"markdown"},"source":{"a04745ec":"import warnings\nimport inspect\nimport datetime\nimport gc\nfrom collections.abc import Iterable\nwarnings.filterwarnings('ignore')\n\n# Imports\nimport plotly.offline as py\nimport plotly.graph_objs as go\nfrom functools import reduce\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport cv2\nimport seaborn as sns\nimport missingno\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Dense, Lambda, RandomRotation, RandomFlip, RandomCrop, RandomZoom, RandomContrast, BatchNormalization, LeakyReLU, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dropout, Reshape, Rescaling, GlobalAveragePooling2D, Input\nfrom keras.models import Sequential\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.backend import repeat_elements, expand_dims, resize_images\n\n\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.models import Model\n\n# from keras_tuner import RandomSearch, Objective\nfrom mlxtend.classifier import StackingCVClassifier\nfrom sklearn.linear_model import Ridge, Lasso, LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\n","05b7eb14":"''' Shuffles two separate arrays in the same manner '''\n# https:\/\/stackoverflow.com\/a\/4602224\ndef unison_shuffled_copies(a, b):\n    assert len(a) == len(b)\n    p = np.random.permutation(len(a))\n    return a[p], b[p]","fab769b3":"LOG_DIR = 'nov-19-2021--1'\nNUM_CSV = 1","c542b22b":"# Utils\n\n''' Ensures element(s) is\/are a specific data type \n    Returns a collection of the element(s)\n    \n    I.e. if given a single `el`, returns a list containing only `el`.\n'''\ndef check_type_or_list_of_type(el, dtype):\n    if type(el) is dtype:\n        return [el]\n    \n    elif not all(type(x) is dtype for x in el):\n        raise ValueError(f\"Expected single or collection of {dtype}\")\n    \n    return el\n    \n''' Drops column(s) from a\/multiple DataFrame(s) '''\ndef drop_cols(dfs, cols, inplace=True, verbose=False):\n    \n    # Ensure dtypes and that arguments are in list\/iterable form\n    dfs = check_type_or_list_of_type(dfs, type(pd.DataFrame()))\n    cols = check_type_or_list_of_type(cols, str)\n    \n    res = []\n    \n    for df in dfs:\n        res.append(df.drop(list(set(df.columns.values) & set(cols)), axis=1, inplace=inplace))\n    \n    if not inplace:\n        if len(res) is 1:\n            return res[0]\n        return tuple(res)","abdc6c98":"class ThresholdStopping(Callback):\n    def __init__(self, monitor='val_loss', num_epochs=5, thresh=0.00001, verbose=0, mode='min'):\n        super(Callback, self).__init__()\n        assert mode in ['min', 'max']\n        self.mode = mode\n        self.monitor = monitor\n        self.num_epochs = num_epochs\n        self.thresh = thresh\n        self.verbose = verbose\n        self.thresh_passed = False\n\n    def on_epoch_end(self, epoch, logs={}):\n        if self.thresh_passed:\n            return\n        \n        # Try to pass threshold\n        if epoch + 1 < self.num_epochs:\n            current = logs.get(self.monitor)\n            if current is None:\n                warnings.warn(\"Threshold stopping requires %s available!\" % self.monitor, RuntimeWarning)\n\n            if self.mode is 'min':\n                if current < self.thresh:\n                    self.thresh_passed = True\n            elif self.mode is 'max':\n                if current > self.thresh:\n                    self.thresh_passed = True\n                \n        # Halt if threshold isn't achieved\n        else:\n            if self.verbose > 0:\n                print(\"Epoch %05d: threshold stopping\" % epoch)\n            self.model.stop_training = True","acf56528":"def get_image_edges(img):\n    cv2.imwrite('tmp.jpg', img)\n    img = cv2.cvtColor(cv2.imread('tmp.jpg'), cv2.COLOR_BGR2GRAY)\n    height, width = img.shape\n    white_padding = np.zeros((50, width, 3))\n    white_padding[:, :] = [255, 255, 255]\n    img = np.row_stack((white_padding, img))\n    \n    plt.imshow(img)\n    plt.show()\n\n    print(img.shape)\n    gray_img = 255 - img\n    gray_img[gray_img > 200] = 255\n    gray_img[gray_img <= 200] = 0\n    black_padding = np.zeros((height, width))\n    gray_img = np.row_stack((black_padding, gray_img))\n\n    plt.imshow(gray_img)\n    plt.show()\n    \n    kernel = np.ones((height, width), np.uint8)\n    closing = cv2.morphologyEx(gray_img, cv2.MORPH_CLOSE, kernel)\n    closing = np.uint8(closing)\n\n    plt.imshow(closing)\n    plt.show()\n    \n    edges = cv2.Canny(closing, 1, 100)\n\n    print('edges:', edges.shape)\n    \n    return edges","7f17d23c":"''' credit https:\/\/github.com\/yu4u\/cutout-random-erasing\/blob\/master\/random_eraser.py '''\ndef get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1\/0.3, v_l=0, v_h=255, pixel_level=False, n_erases=1):\n    def eraser(input_img, n_erases=n_erases):\n        if n_erases < 1:\n            return input_img\n        if input_img.ndim == 3:\n            img_h, img_w, img_c = input_img.shape\n        elif input_img.ndim == 2:\n            img_h, img_w = input_img.shape\n\n        p_1 = np.random.rand()\n\n        if p_1 > p:\n            return input_img if n_erases < 2 else eraser(input_img, n_erases=n_erases - 1)\n\n        while True:\n            s = np.random.uniform(s_l, s_h) * img_h * img_w\n            r = np.random.uniform(r_1, r_2)\n            w = int(np.sqrt(s \/ r))\n            h = int(np.sqrt(s * r))\n            left = np.random.randint(0, img_w)\n            top = np.random.randint(0, img_h)\n\n            if left + w <= img_w and top + h <= img_h:\n                break\n\n        if pixel_level:\n            if input_img.ndim == 3:\n                c = np.random.uniform(v_l, v_h, (h, w, img_c))\n            if input_img.ndim == 2:\n                c = np.random.uniform(v_l, v_h, (h, w))\n        else:\n            c = np.random.uniform(v_l, v_h)\n\n        input_img[top:top + h, left:left + w] = c\n\n        return input_img if n_erases < 2 else eraser(input_img, n_erases=n_erases - 1)\n\n    return eraser","05f97624":"train_df = pd.read_csv('..\/input\/cap-4611-2021-fall-assignment-4\/train.csv')\ntest_df = pd.read_csv('..\/input\/cap-4611-2021-fall-assignment-4\/eval.csv')","009192c0":"train_df.head()","72d9ab12":"train_df.describe()","45f32af9":"# Check for null values in train dataset\n(train_df.isna().sum() > 0).sum()","bc89f1ae":"# Check for null values in eval dataset\n(test_df.isna().sum() > 0).sum()","5754358a":"# Scale & Standardize features\nX_train = drop_cols(train_df, ['id', 'label'], inplace=False)\ny_train = train_df['label']","778266ab":"# Use pre-augmented training data (from previous runs)\ntransformed_csv = pd.read_csv('..\/input\/mnistfashionaugmented\/transformed_train (2).csv').astype(np.uint8)\ntransformed_csv.columns = [*X_train.columns, 'label']\ntransformed_csv.describe()","8c269e6b":"''' Returns only the kwargs for keras' Rescaling, Conv2D and MaxPool2D layers'''\ndef layer_kwargs(layer_dict):\n    _layer_defaults = ['filters', 'kernel_size', 'scale']\n    return {key: layer_dict[key] for key in set(list(layer_dict.keys())) - set(_layer_defaults)}\n\n''' Returns all the arguments needed for keras' Conv2D layer'''\ndef conv_spec(filters, kernel_size, strides=(1, 1), padding='valid',\n    data_format=None, dilation_rate=(1, 1), groups=1, activation=None,\n    use_bias=True, kernel_initializer='glorot_uniform',\n    bias_initializer='zeros', kernel_regularizer=None,\n    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n    bias_constraint=None, input_shape=None):\n    return dict(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, data_format=data_format,\n        dilation_rate=dilation_rate, groups=groups, activation=activation, use_bias=use_bias, kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer, activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint, bias_constraint=bias_constraint)\n\n''' Returns all the arguments needed for keras' MaxPool2D layer'''\ndef pool_spec(pool_size=(2, 2), strides=None, padding='valid', data_format=None, input_shape=None):\n    return dict(pool_size=pool_size, strides=strides, padding=padding, data_format=data_format)\n\ndef rescale_spec(scale, offset=0.0):\n    return dict(scale=scale, offset=offset)\n\n\ndef create_model(hidden_layers, optimizer='adam', loss='categorical_crossentropy',\n                 metrics=['accuracy'], input_shape=X_train.columns.shape, output_neurons=10, output_activation='softmax'):\n    model = Sequential()\n\n    for idx, layer in enumerate(hidden_layers):\n        inpt = []\n        if idx is 0:\n            inpt.append(dict(input_shape=input_shape))\n        if 'normalize' in layer and layer['normalize'] is True:\n            model.add(BatchNormalization(*inpt))\n        elif 'preprocessing' in layer:\n            model.add(create_model([\n                {'reshape': (28, 28, 1)},\n                {'rotate': (-0.2, 0.2)},\n                {'zoom': (-0.05, 0.05)},\n                {'contrast': (0, 0.22)},\n                {'flip': True},\n                {'rescale': dict(scale=1.0\/255.0)},\n            ]))\n        elif 'flatten' in layer and layer['flatten'] is True:\n            model.add(Flatten(*inpt))\n        elif 'dropout' in layer and type(layer['dropout']) is float \\\n                        and layer['dropout'] > 0 and layer['dropout'] < 1:\n            model.add(Dropout(layer['dropout'],*inpt))\n        elif 'reshape' in layer:\n            model.add(Reshape(layer['reshape'], input_shape=input_shape))\n        elif 'rotate' in layer:\n            model.add(RandomRotation(layer['rotate']))\n        elif 'flip' in layer:\n            model.add(RandomFlip(mode='horizontal'))\n        elif 'contrast' in layer:\n            model.add(RandomContrast(layer['contrast']))\n        elif 'zoom' in layer:\n            model.add(RandomZoom(layer['zoom']))\n        elif 'rescale' in layer:\n            args = rescale_spec(**layer['rescale'])\n            model.add(Rescaling(args['scale'], **layer_kwargs(args), input_shape=input_shape))\n        elif 'conv' in layer and type(layer['conv']) is dict:\n            args = conv_spec(**layer['conv'])\n            model.add(Conv2D(args['filters'], args['kernel_size'], **layer_kwargs(args)))\n        elif 'pool' in layer and type(layer['pool']) is dict:\n            args = pool_spec(**layer['pool'])\n            model.add(MaxPooling2D(**layer_kwargs(args)))\n        elif 'avgpool' in layer and type(layer['avgpool']) is dict:\n            args = pool_spec(**layer['avgpool'])\n            model.add(AveragePooling2D(**layer_kwargs(args)))\n        else:\n            model.add(\n                Dense(\n                    layer['n_neurons'],\n                    activation=layer['activation'],\n                    *inpt\n                )\n            )\n    model.add(Dense(output_neurons, activation=output_activation))\n    \n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n    return model","d6da0ec2":"# Architectures for Stacking model\n# Batch Size 512\ntest_archs = [\n        # Exccellent - 94.420% leaderboard (30 epochs - 95.35% val)  ---- 55 Epochs BEST\n        [\n            {'rescale': dict(scale=1.0\/255.0)},\n#             {'preprocessing': True},\n            {'reshape': (28, 28, 1)},\n#             {'contrast': (0, 0.22)},\n#             {'rotate': (-0.2, 0.2)},\n            {'conv': dict(filters=128, kernel_size=3, activation='relu', padding='same', input_shape=(28, 28, 1))},\n            {'dropout': 0.2},\n            {'conv': dict(filters=128, kernel_size=3, activation='relu', padding='same')},\n            {'conv': dict(filters=128, kernel_size=3, activation='relu', padding='same')},\n            {'dropout': 0.2},\n            {'pool': dict(pool_size=2)},\n            {'conv': dict(filters=128, kernel_size=3, activation='relu', padding='same')},\n            {'conv': dict(filters=128, kernel_size=3, activation='relu', padding='same')},\n            {'dropout': 0.2},\n            {'pool': dict(pool_size=2)},\n            {'conv': dict(filters=256, kernel_size=3, activation='relu', padding='same')},\n            {'conv': dict(filters=256, kernel_size=3, activation='relu', padding='same')},\n            {'dropout': 0.2},\n            {'pool': dict(pool_size=2)},\n            {'flatten': True},\n            {'n_neurons': 512, 'activation':'relu'},\n            {'dropout': 0.2},\n            {'n_neurons': 512, 'activation':'relu'},\n            {'dropout': 0.2},\n            {'n_neurons': 256, 'activation':'relu'},\n            {'dropout': 0.2},\n            {'n_neurons': 128, 'activation':'relu'},\n            {'dropout': 0.2},\n            {'n_neurons': 64, 'activation':'relu'},\n            {'dropout': 0.2},\n        ],\n    \n        # Good - 92.422% val (30 epochs)\n        [\n            {'rescale': dict(scale=1.0\/255.0)},\n            {'reshape': (28, 28, 1)},\n            {'conv': dict(filters=32, kernel_size=3, activation='relu', input_shape=(28, 28, 1))},\n            {'dropout': 0.25},\n            {'pool': dict(pool_size=2, strides=2)},\n            {'conv': dict(filters=64, kernel_size=3, activation='relu', input_shape=(28, 28, 1))},\n            {'dropout': 0.25},\n            {'pool': dict(pool_size=2, strides=2)},\n            {'flatten': True},\n            {'n_neurons': 128, 'activation':'relu'},\n            {'dropout': 0.3},\n        ],\n        # Good - 92.583% val (0.91550 leaderboard) (30 epochs) ---- 40 Epochs BEST\n        [\n            {'rescale': dict(scale=1.0\/255.0)},\n            {'reshape': (28, 28, 1)},\n            {'conv': dict(filters=32, kernel_size=3, activation='relu', input_shape=(28, 28, 1))},\n            {'dropout': 0.25},\n            {'pool': dict(pool_size=2, strides=2)},\n            {'conv': dict(filters=64, kernel_size=3, activation='relu', input_shape=(28, 28, 1))},\n            {'dropout': 0.25},\n            {'pool': dict(pool_size=2, strides=2)},\n            {'conv': dict(filters=128, kernel_size=3, activation='relu', input_shape=(28, 28, 1))},\n            {'dropout': 0.4},\n            {'flatten': True},\n            {'n_neurons': 128, 'activation':'relu'},\n            {'n_neurons': 128, 'activation':'relu'},\n            {'dropout': 0.3},\n        ],\n        # Excellent - 94.2389% val (30 epochs) ---- 38 Epochs BEST\n        [\n            {'rescale': dict(scale=1.0\/255.0)},\n            {'reshape': (28, 28, 1)},\n            {'conv': dict(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(28, 28, 1))},\n            {'dropout': 0.2},\n            {'pool': dict(pool_size=2)},\n            {'conv': dict(filters=128, kernel_size=3, activation='relu', padding='same')},\n            {'conv': dict(filters=128, kernel_size=3, activation='relu', padding='same')},\n            {'dropout': 0.2},\n            {'pool': dict(pool_size=2)},\n            {'conv': dict(filters=256, kernel_size=3, activation='relu', padding='same')},\n            {'conv': dict(filters=256, kernel_size=3, activation='relu', padding='same')},\n            {'flatten': True},\n            {'n_neurons': 128, 'activation':'relu'},\n            {'dropout': 0.5},\n            {'n_neurons': 64, 'activation':'relu'},\n            {'dropout': 0.5},\n        ],\n#         # Excellent - 93.744% val (30 epochs) ---- 20 Epochs BEST\n#         [\n#             {'rescale': dict(scale=1.0\/255.0)},\n#             {'reshape': (28, 28, 1)},\n#             {'conv': dict(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(28, 28, 1))},\n#             {'pool': dict(pool_size=2)},\n#             {'conv': dict(filters=128, kernel_size=3, activation='relu', padding='same')},\n#             {'conv': dict(filters=128, kernel_size=3, activation='relu', padding='same')},\n#             {'pool': dict(pool_size=2)},\n#             {'conv': dict(filters=256, kernel_size=3, activation='relu', padding='same')},\n#             {'conv': dict(filters=256, kernel_size=3, activation='relu', padding='same')},\n#             {'flatten': True},\n#             {'n_neurons': 128, 'activation':'relu'},\n#             {'dropout': 0.5},\n#             {'n_neurons': 64, 'activation':'relu'},\n#             {'dropout': 0.5},\n#         ],\n]\n#test_model = create_model(test_archs[0], optimizer=keras.optimizers.Adam(0.001))","fa5b1f42":"# Use architectures for Stacking Model\nstackd_archs = test_archs\n\n# Best Epochs for each model\n# Model 1 - 55 epochs\n# Model 2 - 30 epochs\n# Model 3 - 40 epochs\n# Model 3 - 38 epochs\n\n# Transfer Learning MobileNet\ndef build_special_model():\n    input_image = Input(shape=(784,))\n    input_image = Reshape((28, 28, 1))(input_image)\n    rgb_image = Lambda(lambda image: tf.image.grayscale_to_rgb(image))(input_image)\n    resized_image = Lambda(lambda image: resize_images(x=image, height_factor=2, width_factor=2, data_format='channels_last'))(rgb_image)\n\n    base_model = MobileNet(weights='imagenet', include_top=False, input_tensor=resized_image)\n\n    x = base_model.output\n    x = Dropout(0.5)(x)\n    x = GlobalAveragePooling2D()(x)\n    predictions = Dense(10, activation='softmax')(x)\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n    return model\n\n# Base models for stacking\nclss = [\n    KerasClassifier(build_fn=build_special_model, epochs=20, batch_size=512, verbose=0),\n    KerasClassifier(build_fn=lambda: create_model(stackd_archs[0], optimizer=keras.optimizers.Adam(0.001)), epochs=55, batch_size=512, verbose=0),\n    KerasClassifier(build_fn=lambda: create_model(stackd_archs[1], optimizer=keras.optimizers.Adam(0.001)), epochs=30, batch_size=512, verbose=0),\n    KerasClassifier(build_fn=lambda: create_model(stackd_archs[2], optimizer=keras.optimizers.Adam(0.001)), epochs=40, batch_size=512, verbose=0),\n    KerasClassifier(build_fn=lambda: create_model(stackd_archs[3], optimizer=keras.optimizers.Adam(0.001)), epochs=38, batch_size=512, verbose=0),\n]\n\n# Create Stacking Model\nstacked_model = StackingCVClassifier(\n    classifiers=clss,\n    meta_classifier=SVC(),\n    use_probas=True,\n    verbose=55\n)","1c5f0e1b":"# Use Augmented Data for training\nxxx_submission = X_train.append(transformed_csv.iloc[:, :-1])\nyyy_submission = y_train.append(transformed_csv.iloc[:, -1])\nxxx1_submission, yyy1_submission = unison_shuffled_copies(xxx_submission.values, yyy_submission.values)","c3b8cfcf":"del train_df\ndel X_train\ndel transformed_csv\ndel y_train\ndel test_df\ngc.collect()","ebde168a":"# Fit the Stacking Model\nstacked_model.fit(xxx1_submission, yyy1_submission)","1dc75b4d":"X_test = drop_cols(pd.read_csv('\/content\/eval.csv'), ['id', 'label'], inplace=False)\nsubmission_df = test_df[['id']]\nsubmission_df['label'] = stacked_model.predict(X_test)\nsubmission_df.to_csv(f'submission-super-ensemble-420--crasy.csv',index=False)\nsubmission_df","456c5573":" sns.countplot(submission_df['label'])","2b024ab4":"print(submission_df.to_string())","2b502b24":"# Load Dataset\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels, and represents the article of clothing.\n\n## Content\nLabels have the following mapping:\n\n0. T-shirt\/top\n1. Trouser\n2. Pullover\n3. Dress\n4. Coat\n5. Sandal\n6. Shirt\n7. Sneaker\n8. Bag\n9. Ankle boot\nThe rest of the columns contain the pixel-values of the associated image.\n\nTo locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.\n\n### TLDR;\nWe 28x28 grayscale pixels and 10 classifications target labels.\\\nAll columns are features except `label` and `id` is just the id.\n* `label` is just the label encoded target.\n* `id` is just the id which is only needed for submission","c205e042":"# Building a Model\nFirst we will make a utility method that creates a convolution model from an architecture specification.\\\nWe will then create a stacking model that uses multiple convolution classifiers because it's meta af.\\\nWe will also implement random search using `keras-tuner` to help us find better architechtures and hyper parameters.","699bb54c":"# Submit Predictions\nUse the Stacking Model to generate predictions for submission.\\\n*Note*: The final submitted model uses an aggregate voting of best submissions (either from stacking or single models). I.e. the `mode` of all the predictions is the submitted value.","0435eb5a":"## Exploring Data\nCheck for missing data in both `train` and `eval` (test) datasets","bbc078ae":"# Split Data\nSplit data to X and y (features and labels) and read the saved preprocessed augmented data.","b4e01764":"# Building a Model\nWe'll make a stacking model that's has Convolutional Neural Networks as its base models"}}