{"cell_type":{"3a5cd4ca":"code","86626a42":"code","ebe793b7":"code","0eda84b3":"code","12bf874b":"code","94b645e9":"code","aca4869e":"code","c1460998":"code","f4f2bfa0":"code","36b82f32":"code","360e8a67":"code","774c51d2":"code","a95c256f":"code","f3ef1ce6":"code","6c5c2764":"code","811b1556":"code","bee73d7d":"code","da1f6abf":"code","bed1b272":"code","df93ff2a":"code","fb8fd5d2":"code","2263aac2":"code","b4e1d9e4":"markdown","e8936820":"markdown","1ae6c682":"markdown","8d8708c1":"markdown","3842f4fb":"markdown"},"source":{"3a5cd4ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport xml.etree.ElementTree as ET \nimport matplotlib.pyplot as plt, zipfile \nfrom PIL import Image \n\nfrom tqdm import tqdm\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Model\nfrom keras.initializers import RandomNormal, Constant\nfrom keras import initializers\nfrom keras.layers import Input, Dense, Dropout, Flatten, Reshape , LeakyReLU , Lambda, PReLU, Concatenate\nfrom keras.layers import Conv2D, MaxPooling2D,AveragePooling2D, UpSampling2D, Conv2DTranspose,BatchNormalization\nfrom keras import regularizers\nfrom keras.optimizers import SGD, Adam\n\nfrom keras import backend as K\nfrom keras.engine import *\nfrom keras.utils import conv_utils\n\nfrom IPython.display import FileLink, FileLinks\n\nimport time\nstart_time = time.time()\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","86626a42":"PATH = '..\/input\/all-dogs\/all-dogs\/'\nimageNames = os.listdir(PATH)\n#print(images)\nimg = plt.imread(PATH + imageNames[np.random.randint(0,len(imageNames))])\nplt.imshow(img)\nprint(img.size)","ebe793b7":"PATH_ANNO = '..\/input\/annotation\/Annotation\/'\nbreeds = os.listdir(PATH_ANNO)\nimagesInput = np.zeros((len(imageNames)*2,64,64,3))\nimages_breed = []\ni = 0\nprint(imagesInput.shape)\nfor breed in breeds:\n    for dog in os.listdir(PATH_ANNO+breed):\n        tree = ET.parse(PATH_ANNO + breed + '\/' + dog)\n        root = tree.getroot()\n        try: img = Image.open(PATH + root.find('filename').text +'.jpg')\n        except: continue\n        for obj in root.findall('object'):\n            bndbox = obj.find('bndbox')\n            xmin = int(bndbox.find('xmin').text)\n            ymin = int(bndbox.find('ymin').text)\n            xmax = int(bndbox.find('xmax').text)\n            ymax = int(bndbox.find('ymax').text)\n            img_crop = img.crop((xmin, ymin, xmax, ymax))\n            w = img_crop.size[0]; h = img_crop.size[1];\n            a=0; b=0\n            if w<h:\n                w2 = 64; h2 = int((64\/w)*h)\n                #b = np.random.randint(0,(h2-64)) if (h2-64 > 0) else 0\n            else:\n                h2 = 64; w2 = int((64\/h)*w)\n                #a = np.random.randint(0,(w2-64)) if (w2-64 > 0) else 0\n            img_crop = img_crop.resize((w2,h2), Image.ANTIALIAS)\n            img_crop = img_crop.crop((0+a, 0+b, 64+a, 64+b))\n            imagesInput[i,:,:,:] = np.asarray(img_crop)\n            images_breed.append(obj.find('name').text)\n            i += 1\nimagesInput = imagesInput[:i,:,:,:]        \nflip_imagesInput = np.flip(imagesInput,2)\nimagesInput = np.vstack((imagesInput,flip_imagesInput))\nflip_imagesInput = None\nimages_breed = images_breed + images_breed\nimagesInput = imagesInput \/ (255 \/ 2) - 1\nprint(imagesInput.shape,len(images_breed))","0eda84b3":"rnd = np.random.randint(0,imagesInput.shape[0])\nplt.imshow(imagesInput[rnd]\/2 + .5)\nprint(imagesInput[0].shape)","12bf874b":"def load_img_full():    \n    images = np.zeros((len(imageNames),64,64,3))\n    i = 0\n    for i, dog in enumerate(imageNames):\n        img = Image.open(PATH + dog)\n        w = img.size[0]; h = img.size[1];\n        a=0; b=0\n        if w<h:\n            w2 = 64; h2 = int((64\/w)*h)\n            b = np.random.randint(0,(h2-64)) if (h2-64 > 0) else 0\n        else:\n            h2 = 64; w2 = int((64\/h)*w)\n            a = np.random.randint(0,(w2-64)) if (w2-64 > 0) else 0\n        img = img.resize((w2,h2), Image.ANTIALIAS)\n        img = img.crop((0+a, 0+b, 64+a, 64+b))\n        images[i,:,:,:] = np.asarray(img)\n    images = images \/ (255 \/ 2) - 1\n    print(images.shape)\n    return images\nimagesInput = np.vstack((imagesInput,load_img_full()))\nprint(imagesInput.shape)","94b645e9":"class ConvSN2D(Conv2D):\n\n    def build(self, input_shape):\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (input_dim, self.filters)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n            \n        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n                         initializer=initializers.RandomNormal(0, 1),\n                         name='sn',\n                         trainable=False)\n        \n        # Set input spec.\n        self.input_spec = InputSpec(ndim=self.rank + 2,\n                                    axes={channel_axis: input_dim})\n        self.built = True\n    def call(self, inputs, training=None):\n        def _l2normalize(v, eps=1e-12):\n            return v \/ (K.sum(v ** 2) ** 0.5 + eps)\n        def power_iteration(W, u):\n            #Accroding the paper, we only need to do power iteration one time.\n            _u = u\n            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n            _u = _l2normalize(K.dot(_v, W))\n            return _u, _v\n        #Spectral Normalization\n        W_shape = self.kernel.shape.as_list()\n        #Flatten the Tensor\n        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n        _u, _v = power_iteration(W_reshaped, self.u)\n        #Calculate Sigma\n        sigma=K.dot(_v, W_reshaped)\n        sigma=K.dot(sigma, K.transpose(_u))\n        #normalize it\n        W_bar = W_reshaped \/ sigma\n        #reshape weight tensor\n        if training in {0, False}:\n            W_bar = K.reshape(W_bar, W_shape)\n        else:\n            with tf.control_dependencies([self.u.assign(_u)]):\n                W_bar = K.reshape(W_bar, W_shape)\n                \n        outputs = K.conv2d(\n                inputs,\n                W_bar,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n\nclass ConvSN2DTranspose(Conv2DTranspose):\n\n    def build(self, input_shape):\n        if len(input_shape) != 4:\n            raise ValueError('Inputs should have rank ' +\n                             str(4) +\n                             '; Received input shape:', str(input_shape))\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n            \n        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n                         initializer=initializers.RandomNormal(0, 1),\n                         name='sn',\n                         trainable=False)\n        \n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n        self.built = True  \n    \n    def call(self, inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n        if self.data_format == 'channels_first':\n            h_axis, w_axis = 2, 3\n        else:\n            h_axis, w_axis = 1, 2\n\n        height, width = input_shape[h_axis], input_shape[w_axis]\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.strides\n        if self.output_padding is None:\n            out_pad_h = out_pad_w = None\n        else:\n            out_pad_h, out_pad_w = self.output_padding\n\n        # Infer the dynamic output shape:\n        out_height = conv_utils.deconv_length(height,\n                                              stride_h, kernel_h,\n                                              self.padding,\n                                              out_pad_h)\n        out_width = conv_utils.deconv_length(width,\n                                             stride_w, kernel_w,\n                                             self.padding,\n                                             out_pad_w)\n        if self.data_format == 'channels_first':\n            output_shape = (batch_size, self.filters, out_height, out_width)\n        else:\n            output_shape = (batch_size, out_height, out_width, self.filters)\n            \n        #Spectral Normalization    \n        def _l2normalize(v, eps=1e-12):\n            return v \/ (K.sum(v ** 2) ** 0.5 + eps)\n        def power_iteration(W, u):\n            #Accroding the paper, we only need to do power iteration one time.\n            _u = u\n            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n            _u = _l2normalize(K.dot(_v, W))\n            return _u, _v\n        W_shape = self.kernel.shape.as_list()\n        #Flatten the Tensor\n        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n        _u, _v = power_iteration(W_reshaped, self.u)\n        #Calculate Sigma\n        sigma=K.dot(_v, W_reshaped)\n        sigma=K.dot(sigma, K.transpose(_u))\n        #normalize it\n        W_bar = W_reshaped \/ sigma\n        #reshape weight tensor\n        if training in {0, False}:\n            W_bar = K.reshape(W_bar, W_shape)\n        else:\n            with tf.control_dependencies([self.u.assign(_u)]):\n                W_bar = K.reshape(W_bar, W_shape)\n        self.kernel = W_bar\n        \n        outputs = K.conv2d_transpose(\n            inputs,\n            self.kernel,\n            output_shape,\n            self.strides,\n            padding=self.padding,\n            data_format=self.data_format)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs","aca4869e":"class Attention(Layer):\n    def __init__(self, ch, **kwargs):\n        super(Attention, self).__init__(**kwargs)\n        self.channels = ch\n        self.filters_f_g = self.channels \/\/ 8\n        self.filters_h = self.channels\n\n    def build(self, input_shape):\n        kernel_shape_f_g = (1, 1) + (self.channels, self.filters_f_g)\n        print(kernel_shape_f_g)\n        kernel_shape_h = (1, 1) + (self.channels, self.filters_h)\n\n        # Create a trainable weight variable for this layer:\n        self.gamma = self.add_weight(name='gamma', shape=[1], initializer='zeros', trainable=True)\n        self.kernel_f = self.add_weight(shape=kernel_shape_f_g,\n                                        initializer='glorot_uniform',\n                                        name='kernel_f')\n        self.kernel_g = self.add_weight(shape=kernel_shape_f_g,\n                                        initializer='glorot_uniform',\n                                        name='kernel_g')\n        self.kernel_h = self.add_weight(shape=kernel_shape_h,\n                                        initializer='glorot_uniform',\n                                        name='kernel_h')\n        self.bias_f = self.add_weight(shape=(self.filters_f_g,),\n                                      initializer='zeros',\n                                      name='bias_F')\n        self.bias_g = self.add_weight(shape=(self.filters_f_g,),\n                                      initializer='zeros',\n                                      name='bias_g')\n        self.bias_h = self.add_weight(shape=(self.filters_h,),\n                                      initializer='zeros',\n                                      name='bias_h')\n        super(Attention, self).build(input_shape)\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4,\n                                    axes={3: input_shape[-1]})\n        self.built = True\n\n\n    def call(self, x):\n        def hw_flatten(x):\n            return K.reshape(x, shape=[K.shape(x)[0], K.shape(x)[1]*K.shape(x)[2], K.shape(x)[-1]])\n\n        f = K.conv2d(x,\n                     kernel=self.kernel_f,\n                     strides=(1, 1), padding='same')  # [bs, h, w, c']\n        f = K.bias_add(f, self.bias_f)\n        g = K.conv2d(x,\n                     kernel=self.kernel_g,\n                     strides=(1, 1), padding='same')  # [bs, h, w, c']\n        g = K.bias_add(g, self.bias_g)\n        h = K.conv2d(x,\n                     kernel=self.kernel_h,\n                     strides=(1, 1), padding='same')  # [bs, h, w, c]\n        h = K.bias_add(h, self.bias_h)\n\n        s = tf.matmul(hw_flatten(g), hw_flatten(f), transpose_b=True)  # # [bs, N, N]  \/\/ Why matmul vs K.batch_dot\n\n        beta = K.softmax(s, axis=-1)  # attention map\n\n        o = K.batch_dot(beta, hw_flatten(h))  # [bs, N, C]\n\n        o = K.reshape(o, shape=K.shape(x))  # [bs, h, w, C]\n        x = self.gamma * o + x\n\n        return x\n\n    def compute_output_shape(self, input_shape):\n        return input_shape","c1460998":"def PixelwiseNorm(x):\n    alpha=1e-8\n    y = x ** 2\n    y = K.mean(y, axis=-1, keepdims=True)\n    y = y + alpha\n    y = K.sqrt(y)\n    y = x \/ y  # normalize the input x volume\n    return y","f4f2bfa0":"drop = 0.1\ninit = RandomNormal(mean=0.0, stddev=0.02) #'glorot_uniform'#\ngen_input = Input(shape=(100,))\n\nx = Dense(1024, activation='relu',)(gen_input)\nx = BatchNormalization(momentum=0.8)(x)\nx = Reshape((4,4,64))(x)\n\nx3 = ConvSN2DTranspose(256, (3, 3),strides=(1, 1),padding='same',kernel_initializer=init)(x)\nx5 = ConvSN2DTranspose(128, (5, 5),strides=(1, 1),padding='same',kernel_initializer=init)(x)\nx = Concatenate(axis=-1)([x3,x5])\nx = Lambda(PixelwiseNorm)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\n\nx3 = ConvSN2DTranspose(128, (3, 3),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx5 = ConvSN2DTranspose(64, (5, 5),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx = Concatenate(axis=-1)([x3,x5])\nx = Lambda(PixelwiseNorm)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\nx3 = ConvSN2DTranspose(64, (3, 3),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx5 = ConvSN2DTranspose(32, (5, 5),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx = Concatenate(axis=-1)([x3,x5])\nx = Lambda(PixelwiseNorm)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\nx3 = ConvSN2DTranspose(32, (3, 3), strides=(2, 2), padding='same',kernel_initializer=init)(x)\nx5 = ConvSN2DTranspose(16, (5, 5),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx = Concatenate(axis=-1)([x3,x5])\nx = Lambda(PixelwiseNorm)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\nx = Attention(32+16)(x)\n\nx3 = ConvSN2DTranspose(32, (3, 3), strides=(2, 2), padding='same',kernel_initializer=init)(x)\nx5 = ConvSN2DTranspose(16, (5, 5),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx = Concatenate(axis=-1)([x3,x5])\nx = Lambda(PixelwiseNorm)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\n\n#x = AveragePooling2D(pool_size=(2, 2),strides=(1, 1),padding='same')(x)\n\nx = ConvSN2D(3, (5, 5), activation='tanh', padding='same',kernel_initializer=init)(x)\n\ngenerator = Model(gen_input, x)\ngenerator.compile(optimizer=Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy')\ngenerator.summary()","36b82f32":"inpt = np.random.random(100*2).reshape(2,100)\nimg = generator.predict(inpt)\nprint(img.shape)\nplt.imshow(img[0]\/2+.5)\nplt.imshow(img[1]\/2+.5)\n#print(img[1]\/2+.5)","360e8a67":"init = RandomNormal(mean=0.0, stddev=0.02)\ndrop = 0.0\ndis_input = Input(shape=(64,64,3,))\nx = ConvSN2D(32, (5, 5), padding='same',kernel_initializer=init)(dis_input)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\nx = ConvSN2D(64, (5, 5), padding='same',strides=(2, 2),kernel_initializer=init)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = Dropout(drop)(x)\n\n#x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\nx = ConvSN2D(64, (3, 3), padding='same',strides=(2, 2),kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\nx = ConvSN2D(128, (3, 3), padding='same',strides=(2, 2),kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\nx = ConvSN2D(256, (3, 3), padding='same',strides=(2, 2),kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = Conv2D(64, (3, 3), padding='valid',strides=(1, 1),kernel_initializer=init)(x)\n#x = LeakyReLU()(x)\n#x = BatchNormalization()(x)\n#x = Dropout(drop)(x)\n\nx = ConvSN2D(512, (3, 3), padding='same',strides=(1, 1),kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = AveragePooling2D(pool_size=(2, 2),strides=(1, 1),padding='same')(x)\n\nx = Flatten()(x)\nx = Dense(1 , activation = \"sigmoid\")(x)\ndiscriminator = Model(dis_input, x)\ndiscriminator.compile(optimizer=Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy')\ndiscriminator.summary()","774c51d2":"gan_input = Input(shape=(100,))\ndiscriminator.trainable=False\nx = generator(gan_input)\nx = discriminator(x)\ngan = Model(gan_input, x)\ngan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\ngan.summary()","a95c256f":"def gen_noise(batch_size=128):\n    noise = np.random.randn(batch_size,100)\n    #noise = np.random.normal(size = 100 * batch_size).reshape(batch_size,100)\n    # noise =  np.random.random(100 * batch_size).reshape(batch_size,100)\n    return noise ","f3ef1ce6":"print(\"--- %s seconds ---\" % (time.time() - start_time))","6c5c2764":"def training(epochs=3, batch_size=128):\n    imagesProgress = np.zeros((epochs,64,64,3))\n    progress_noise = gen_noise(1)\n        \n    min_learning_rate = 0.00005\n    max_learning_rate = K.eval(gan.optimizer.lr)\n    cycle_length = batch_size * 1200\n    mult_factor=2\n    batch_since_restart = 0\n    global learning_rate_log\n    learning_rate_log = []\n    \n    for e in range(1,epochs+1):\n        #print(imagesInput.shape[0]\/\/batch_size)\n        #print('Epoch:', e)\n        np.random.shuffle(imagesInput)\n        for b in tqdm(range(imagesInput.shape[0]\/\/batch_size)):\n            noise = gen_noise(batch_size)\n            gen_imgs = generator.predict(noise)\n            real_imgs = imagesInput[b*batch_size:(b+1)*batch_size]\n            #X = np.concatenate([real_imgs, gen_imgs])\n            #y_dis = np.zeros(2*batch_size) \n            #y_dis[:batch_size] = .8 +  np.random.normal(loc=0, scale=.050)\n            \n            y_dis = np.ones(batch_size) - np.abs(np.random.normal(loc=.2, scale=.1))\n            #y_dis = 1 - y_dis if np.random.random() <= .05 else y_dis\n            discriminator.trainable=True\n            discriminator.train_on_batch(real_imgs,y_dis)\n            \n            y_dis.fill(0.0)\n            y_dis += np.abs(np.random.normal(loc=.2, scale=.1))\n            #y_dis = 1 - y_dis if np.random.random() <= .05 else y_dis\n            discriminator.trainable=True\n            discriminator.train_on_batch(gen_imgs,y_dis)\n                        \n            noise = gen_noise(batch_size\/\/2)\n            #noise[:,np.random.randint(100)] += 1\n            y_gen = np.ones(batch_size\/\/2) - .1\n            \n            discriminator.trainable=False\n            gan.train_on_batch(noise, y_gen)\n            #inpt = np.random.random(100).reshape(1,100)\n                        \n            learning_rate = min_learning_rate + 0.5 * (max_learning_rate - min_learning_rate) * (1 + np.cos(np.pi * batch_since_restart\/cycle_length))\n            if learning_rate < min_learning_rate:\n                learning_rate = min_learning_rate\n            if batch_since_restart >= cycle_length:\n                batch_since_restart = 0\n                learning_rate = max_learning_rate\n                cycle_length = cycle_length * mult_factor\n            batch_since_restart += 1\n            K.set_value(gan.optimizer.lr, learning_rate)\n            learning_rate_log.append(learning_rate)\n          \n        inpt = gen_noise(1)\n        i = np.random.randint(0,real_imgs.shape[0])\n        print('Epoch: ', e,\n        ' || Gen: ' , discriminator.predict(generator.predict(inpt))[0,0],\n        ' || Dog: ' , discriminator.predict(real_imgs[i:i+1])[0,0])\n        #print(np.average(y_dis))\n        imagesProgress[e-1,:,:,:] = generator.predict(progress_noise)[0]\n        os.system(f'echo \\\"{e}\\\"')\n        if (time.time() - start_time) > 31800:\n            imagesProgress = imagesProgress[:e-1,:,:,:]\n            break\n    return imagesProgress\ntry: imagesProgress\nexcept NameError: imagesProgress = np.zeros((0,64,64,3))\nimagesProgress = np.vstack((imagesProgress,training(epochs=600,batch_size=128)))","811b1556":"plt.plot(learning_rate_log)","bee73d7d":"print('Epochs: ' , imagesProgress.shape[0])\ncolumns = 6 ; rows = min(6,(imagesProgress.shape[0] \/\/ columns) + 1);\nfig=plt.figure(figsize=(32, 5 * rows))\nj=0\nfor i in range(0 , min(36,imagesProgress.shape[0])):\n    fig.add_subplot(rows,columns,i+1)\n    plt.imshow(imagesProgress[int(j)]\/2+.5)\n    j += max(1,imagesProgress.shape[0] \/ 36)\nplt.show()","da1f6abf":"columns = 6 ; rows = 4;\ninpt = gen_noise(columns * rows)\n#inpt[:,np.random.randint(100)] += 1\nimg = generator.predict(inpt)\n#print(discriminator.predict(imagesInput[:10]))\n#print(discriminator.predict(img))\n#print(img[0,0,:10])\nfig=plt.figure(figsize=(32, 5 * rows))\nfor i in range(0 , columns * rows):\n    fig.add_subplot(rows,columns,i+1)\n    plt.imshow(img[i]\/2+.5)\nplt.show()","bed1b272":"z = zipfile.PyZipFile('images.zip', mode='w')\ninpt = gen_noise(10000)\nimgs = generator.predict(inpt) \nimgs = imgs + 1\nimgs = imgs \/ 2\nprint(imgs.shape)\nfor k in range(10000):\n    f = str(k)+'.png'\n    img = imgs[k,:,:,:]#.numpy()\n    tf.keras.preprocessing.image.save_img(\n        f,\n        img,\n        scale=True\n    )\n    z.write(f); os.remove(f)\nz.close()\nFileLinks('.')\n#!ls","df93ff2a":"#inpt = gen_noise(10000)\n#img = generator.predict(inpt) \n#img = img + 1\n#img = img * (255 \/ 2)\n#np.array(img).min(), np.array(img).max()\n#if not os.path.exists('..\/tmp'):\n#    os.mkdir('..\/tmp')\n#for i in range(0,img.shape[0]):\n#    plt.imsave('..\/tmp\/dog_'+ str (i)+'.png' , img[i].astype(np.uint8))\n#import shutil\n#shutil.make_archive('images', 'zip', '..\/tmp')","fb8fd5d2":"#print(img[9].astype(np.uint8))\n#im = Image.fromarray(img[0].astype(np.uint8))\n#plt.imshow(im)","2263aac2":"print(\"--- %s seconds ---\" % (time.time() - start_time))","b4e1d9e4":"# **Generator**","e8936820":"[**Self Attention**](https:\/\/stackoverflow.com\/questions\/50819931\/self-attention-gan-in-keras)   \n[More](https:\/\/sthalles.github.io\/advanced_gans\/)","1ae6c682":"# **Discriminator**","8d8708c1":"**[Spectral Normalization](https:\/\/github.com\/IShengFang\/SpectralNormalizationKeras\/blob\/master\/SpectralNormalizationKeras.py)**","3842f4fb":"# **Training**"}}