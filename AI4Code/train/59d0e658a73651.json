{"cell_type":{"5183e878":"code","75841506":"code","9cd81bca":"code","0416bb75":"code","8b7d136c":"code","bc64c1a2":"code","a77c616d":"code","08bc72ba":"code","597756b0":"code","80b521ec":"code","f8e8ec07":"code","158a8ba1":"code","4b6a3d5b":"code","bd08b15a":"code","13f8665b":"code","e02d61c7":"code","7fd23dee":"markdown","a3e0b6fd":"markdown","b5f0fc8d":"markdown","1d3f3aa1":"markdown","0d284a58":"markdown","5390b2b4":"markdown","b293d121":"markdown","9b7a95ac":"markdown","af6094a8":"markdown","f2d55675":"markdown","f90ecb04":"markdown","17236bb9":"markdown"},"source":{"5183e878":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","75841506":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.utils import to_categorical\n\nfrom matplotlib import ticker\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')","9cd81bca":"train = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/sample_submission.csv\")","0416bb75":"print(f\"train.shape: {train.shape}\")\nprint(f\"test.shape: {test.shape}\")","8b7d136c":"train.head()","bc64c1a2":"# basic statistics for train data\ntrain.describe()","a77c616d":"test.head()","08bc72ba":"# basic statistics for test data\ntest.describe()","597756b0":"# get target variable\nset(train.columns) - set(test.columns)","80b521ec":"# remove 'Id' from train and test\ntrain.drop(['Id'], axis = 1, inplace = True)\ntest.drop(['Id'], axis = 1, inplace = True)\n\n# get features\ntarget = 'Cover_Type'\nfeatures = [col for col in train.columns if col not in ['Id', target]]\nprint(f\"features: {features}\")\nprint(f\"features len: {len(features)}\")  # we have dataset that has 54 columns\n\nrandom_state = 42","f8e8ec07":"train.iloc[:, :-1].describe().T.sort_values(by='std' , ascending = False)\\\n                     .style.background_gradient(cmap='GnBu')\\\n                     .bar(subset=[\"max\"], color='#BB0000')\\\n                     .bar(subset=[\"mean\",], color='green')","158a8ba1":"df = pd.concat([train[features], test[features]], axis = 0)\n\ncat_features = [col for col in features if df[col].nunique() < 25]\ncont_features = [col for col in features if df[col].nunique() > 25]\n\ndel df\nprint(f'Total number of features: {len(features)}')\nprint(f'Number of categorical features: {len(cat_features)}')\nprint(f'Number of continuos features: {len(cont_features)}')\n\nplt.pie([len(cat_features), len(cont_features)], \n        labels=['Categorical', 'Continuos'],\n        colors=['#76D7C4', '#F5B7B1'],\n        textprops={'fontsize': 13},\n        autopct='%1.1f%%')\nplt.show()","4b6a3d5b":"ncols = 5\nnrows = int(len(cont_features) \/ ncols + (len(features) % ncols > 0))-1\n\nfig, axes = plt.subplots(nrows, ncols, figsize=(18, 8), facecolor='#EAEAF2')\n\nfor r in range(nrows):\n    for c in range(ncols):\n        col = cont_features[r*ncols+c]\n        sns.kdeplot(x=train[col], ax=axes[r, c], color='#58D68D', label='Train data')\n        sns.kdeplot(x=test[col], ax=axes[r, c], color='#DE3163', label='Test data')\n        axes[r, c].set_ylabel('')\n        axes[r, c].set_xlabel(col, fontsize=8, fontweight='bold')\n        axes[r, c].tick_params(labelsize=5, width=0.5)\n        axes[r, c].xaxis.offsetText.set_fontsize(4)\n        axes[r, c].yaxis.offsetText.set_fontsize(4)\nplt.show()","bd08b15a":"if len(cat_features) == 0 :\n    print(\"No Categorical features\")\nelse:\n    ncols = 5\n    nrows = int(len(cat_features) \/ ncols + (len(features) % ncols > 0)) \n\n    fig, axes = plt.subplots(nrows, ncols, figsize=(18, 45), facecolor='#EAEAF2')\n\n    for r in range(nrows):\n        for c in range(ncols):\n            if r*ncols+c >= len(cat_features):\n                break\n            col = cat_features[r*ncols+c]\n            sns.countplot(x=train[col], ax=axes[r, c], color='#58D68D', label='Train data')\n            sns.countplot(x=test[col], ax=axes[r, c], color='#DE3163', label='Test data')\n            axes[r, c].set_ylabel('')\n            axes[r, c].set_xlabel(col, fontsize=8, fontweight='bold')\n            axes[r, c].tick_params(labelsize=5, width=0.5)\n            axes[r, c].xaxis.offsetText.set_fontsize(4)\n            axes[r, c].yaxis.offsetText.set_fontsize(4)\n    plt.show()","13f8665b":"target_df = pd.DataFrame(train[target].value_counts()).reset_index()\ntarget_df.columns = [target, 'count']\nfig = px.bar(data_frame =target_df, \n             x = 'Cover_Type',\n             y = 'count' , \n             color = \"count\",\n             color_continuous_scale=\"Emrld\") \nfig.show()\ntarget_df.sort_values(by =target , ignore_index = True)","e02d61c7":"train = train.drop(index = int(np.where(train[\"Cover_Type\"] == 5)[0]))\ntrain = train.drop(labels = [\"Soil_Type7\", \"Soil_Type15\"], axis = 1)\n\nfeatures.remove(\"Soil_Type7\")\nfeatures.remove(\"Soil_Type15\")","7fd23dee":"# Introduction","a3e0b6fd":"'Cover_Type' is target variable!","b5f0fc8d":"# Import Libraries","1d3f3aa1":"## Continuous and Categorical Data Distribution","0d284a58":"## Target Distribution","5390b2b4":"# Simple EDA","b293d121":"## Removing Unwanted Rows and columns","9b7a95ac":"## Feature Distribution of Categorical Features","af6094a8":"<h2>Update<\/h2>\n\n> Please visit the last update Notebook :)\n\n[[TPS-Dec] End-to-End ML Project for Beginner \ud83d\ude03](https:\/\/www.kaggle.com\/leeyj0511\/tps-dec-end-to-end-ml-project-for-beginner\/notebook)","f2d55675":"# Data Loading and Preperation","f90ecb04":"This Notebook is for beginner who just start kaggle\n\n## TL;DR\n**Let's Start Journey with me!**","17236bb9":"## Feature Distribution of Continuous Features"}}