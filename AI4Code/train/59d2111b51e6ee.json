{"cell_type":{"c1b49477":"code","6b3381c1":"code","775e9ffb":"code","9476956a":"code","679ed136":"code","d991ac01":"code","f34bfbaf":"code","0cbfcc90":"code","ea4af698":"code","9216283f":"code","5de62944":"code","c3abd1b8":"code","311807ea":"code","f51d1201":"code","dbb2ae7b":"code","2f04077c":"code","365123dc":"code","cc992dc6":"code","7bc4538f":"code","467b3fbe":"code","b9d2cd1f":"code","d4d856bc":"code","ce7b61fa":"code","e8d23219":"code","348c1abe":"code","18ea55c0":"code","1b54dbc8":"code","668d31b7":"code","3885441c":"code","145f7a1a":"markdown","a9448319":"markdown","4bfd397b":"markdown","bed18d84":"markdown","608bcd01":"markdown","6cd128f1":"markdown","4f2f154d":"markdown","901ba08d":"markdown","ed257157":"markdown","157099f6":"markdown","e3ca2c96":"markdown","2ee5b191":"markdown","a7b91279":"markdown","07c08cbf":"markdown","debba37b":"markdown","228e25a0":"markdown","329ab671":"markdown","38173723":"markdown","85e194b8":"markdown","81b5c2da":"markdown","dabea114":"markdown","1e184da9":"markdown","075ad143":"markdown"},"source":{"c1b49477":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom functools import reduce\nimport matplotlib.pyplot as plt","6b3381c1":"path = '\/kaggle\/input\/nfl-big-data-bowl-2021\/'\n\ngames_df = pd.read_csv(path+'games.csv')#,iterator=True, chunksize=100_000)\nplayers_df = pd.read_csv(path+'players.csv')#,iterator=True, chunksize=100_000)\nplays_df = pd.read_csv(path+'plays.csv')#,iterator=True, chunksize=100_000)\n\nplays_df['uniqueID'] = plays_df['gameId'].astype(str) + '_' + plays_df['playId'].astype(str)\nplays_df.head()\n\ntracking = list()\nfor i in range(1,18):\n    tracking.append(pd.read_csv(path+'week{}.csv'.format(i)))\ntracking_df = pd.concat(tracking)","775e9ffb":"tracking_df['uniqueID'] = tracking_df['gameId'].astype(str) + '_' + tracking_df['playId'].astype(str)\ntracking_df.head()","9476956a":"tracking_df['position'].unique()","679ed136":"plays_df.head()","d991ac01":"defenders = ['SS', 'FS', 'MLB', 'CB', 'LB', 'OLB', 'ILB', 'DL', 'DB', 'NT', 'S', 'DE', 'DT']\ntracking_df['Is Defender'] = tracking_df['position'].isin(defenders)","f34bfbaf":"tracking_df.loc[tracking_df['playDirection'] == 'left', 'x'] = tracking_df[tracking_df['playDirection'] == 'left']['x'].apply(lambda x: 120 - x)","0cbfcc90":"defender_counts = tracking_df[(tracking_df['Is Defender'] == True) & (tracking_df['frameId'] == 1)].groupby('uniqueID').size().reset_index(name='Defender Count')\ntracking_df = tracking_df.merge(defender_counts, on='uniqueID')\n\ntracking_df.tail()","ea4af698":"tracking_df.groupby(['Defender Count']).size()","9216283f":"num_defenders = 7\ntracking_df = tracking_df[tracking_df['Defender Count'] == num_defenders]\ntracking_df.columns","5de62944":"#Grab player positions at snap (frameID=1) and s seconds into play\n#frameID iterates every .1sec\n\nsnapshot_time = 2\nsnap = 1\nsnapshot_frames = int(snapshot_time*10+1)\n\nsnapshot_df = tracking_df[tracking_df['frameId'] == 1]\nsnapshot_df = snapshot_df[['uniqueID', 'playDirection', 'nflId', 'displayName', 'jerseyNumber', 'position', 'team', 'Is Defender', 'Defender Count', 'x', 'y']]\nsnapshot_df = snapshot_df.rename(columns={'x' : 'x_frame1', 'y' : 'y_frame1'})\n#print(\"Frame 1 cols: {}\".format(snapshot_df.columns))\nfor s in range(2,snapshot_frames):\n    temp_df = tracking_df[tracking_df['frameId'] == s]\n    temp_df = temp_df[['uniqueID', 'playDirection', 'nflId', 'displayName', 'jerseyNumber', 'position', 'team', 'Is Defender', 'Defender Count', 'x', 'y']]\n    temp_df = temp_df.rename(columns={'x' : 'x_frame{}'.format(s), 'y' : 'y_frame{}'.format(s)})\n    #print(\"Frame {} cols: {}\".format(s, temp_df.columns))\n    snapshot_df = snapshot_df.merge(temp_df, on=['uniqueID', 'playDirection', 'nflId', 'displayName', 'jerseyNumber', 'position', 'team', 'Is Defender', 'Defender Count'])","c3abd1b8":"snapshot_df.columns","311807ea":"ball_pos = snapshot_df[(snapshot_df['position']).isna()][['uniqueID', 'x_frame1', 'y_frame1']].rename(columns={'x_frame1': 'ball_x', 'y_frame1': 'ball_y'})\ndefenders = snapshot_df[(snapshot_df['Is Defender'] == True)].groupby('uniqueID')\ndfs = [ball_pos]\nfor s in range(1, snapshot_frames):\n    x = defenders['x_frame{}'.format(s)].apply(list).reset_index(name='defenders_x_frame{}'.format(s))\n    y = defenders['y_frame{}'.format(s)].apply(list).reset_index(name='defenders_y_frame{}'.format(s))\n    dfs.append(x)\n    dfs.append(y)\n    \ndistance_metrics = reduce(lambda left,right: pd.merge(left, right, on='uniqueID'), dfs)","f51d1201":"def distance(vec_x, vec_y, o_x, o_y):\n    return np.sqrt((np.array(vec_x)-np.array([o_x]))**2 + (np.array(vec_y)-np.array([o_y]))**2)","dbb2ae7b":"def angle(vec_x, vec_y, o_x, o_y):\n    return np.degrees(np.arctan2(np.array(vec_y)-np.array([o_y]), np.array(vec_x)-np.array([o_x])))","2f04077c":"#Y coordinate is already normalized\n#X coordinate needs to be normalized by subtracting the yardline at snap\ndef normalize_cartesian(vec_x, yardline):\n    return np.array(vec_x) - np.array([yardline])","365123dc":"for s in range(1, snapshot_frames):\n    distance_metrics['distance_frame{}'.format(s)] = distance_metrics.apply(lambda row: distance(row['defenders_x_frame{}'.format(s)], row['defenders_y_frame{}'.format(s)], row['ball_x'], row['ball_y']), axis=1)\n    distance_metrics['angle_frame{}'.format(s)] = distance_metrics.apply(lambda row: angle(row['defenders_x_frame{}'.format(s)], row['defenders_y_frame{}'.format(s)], row['ball_x'], row['ball_y']), axis=1)\n\n    distance_metrics['defenders_xnorm_frame{}'.format(s)] = distance_metrics.apply(lambda row: normalize_cartesian(row['defenders_x_frame{}'.format(s)], row['ball_x']), axis=1)\n    distance_metrics['defenders_xnorm_frame{}'.format(s)] = distance_metrics.apply(lambda row: normalize_cartesian(row['defenders_x_frame{}'.format(s)], row['ball_x']), axis=1)","cc992dc6":"distance_metrics.head()","7bc4538f":"def do_kmeans(X):\n    scaler = StandardScaler()\n    X_std = scaler.fit_transform(X)\n    sse = {}\n    for k in range(1, 15):\n        kmeans = KMeans(n_clusters=k, max_iter=2000).fit(X_std)\n        labels = kmeans.labels_\n        sse[k] = kmeans.inertia_\n    plt.figure()\n    plt.plot(list(sse.keys()), list(sse.values()))\n    plt.xlabel(\"Number of clusters\")\n    plt.ylabel(\"SSE\")\n    plt.show()\n    return labels","467b3fbe":"#Cartesian coordinates; this contains bias towards the play location on the field\nfeatures = [x for x in distance_metrics.columns if 'defenders_x_' in x or 'defenders_y_' in x]\nX = np.array(distance_metrics[features].values.tolist()).reshape(len(distance_metrics.index), len(features)*num_defenders)\n\nlabels = do_kmeans(X)","b9d2cd1f":"#Polar coordinates\nfeatures = [x for x in distance_metrics.columns if 'distance' in x or 'angle' in x]\nX = np.array(distance_metrics[features].values.tolist()).reshape(len(distance_metrics.index), len(features)*num_defenders)\nlabels = do_kmeans(X)","d4d856bc":"#Normalized Cartesian coordinates\nfeatures = [x for x in distance_metrics.columns if 'xnorm' in x or 'defenders_y_' in x]\n\n#Normalized Cartesian coordinates and Polar coordinates\n#features = [x for x in distance_metrics.columns if 'xnorm' in x or 'defenders_y_' in x or 'angle' in x or 'distance' in x]\n\nX = np.array(distance_metrics[features].values.tolist()).reshape(len(distance_metrics.index), len(features)*num_defenders)\nlabels = do_kmeans(X)","ce7b61fa":"optimal_k = 2","e8d23219":"distance_metrics['kmeans_class'] = pd.Series(labels)","348c1abe":"distance_metrics[distance_metrics['kmeans_class'] == 1]","18ea55c0":"def plot_play(df, df2, unique_id, snapshot_time, snapshot_frames):\n    pd.set_option(\"display.max_colwidth\", 10000)\n    halfway_frame = int(snapshot_frames\/2)\n    halfway_time = int(snapshot_time\/2)\n    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(30,10))\n    defenders = df[(df['uniqueID'] == unique_id)]\n    \n    #dropping ball position\n    defenders = defenders[defenders['position'].notna()]\n    \n    defenders['color_col'] = defenders['Is Defender'].astype(int)\n    defenders.plot.scatter(x='y_frame{}'.format(1), y='x_frame{}'.format(1), c='color_col', colormap='plasma', ax=axes[0], title='At snap')\n    defenders.plot.scatter(x='y_frame{}'.format(halfway_frame), y='x_frame{}'.format(halfway_frame), c='color_col', colormap='plasma', ax=axes[1], title='After {} sec'.format(halfway_time))\n    defenders.plot.scatter(x='y_frame{}'.format(snapshot_frames-1), y='x_frame{}'.format(snapshot_frames-1), c='color_col', colormap='plasma', ax=axes[2], title='After {} sec'.format(snapshot_time))\n    \n    defenders2 = df2[(df2['uniqueID'] == unique_id)]\n    defenders2 = defenders2[defenders2['position'].notna()]\n    defenders2['color_col'] = defenders2['Is Defender'].astype(int)\n    defenders2.plot.scatter(x='y', y='x'.format(1), c='color_col', colormap='plasma', ax=axes[3], title='Whole play')\n    \n    print(\"Plotting play: {}\".format(unique_id))\n    print(plays_df[plays_df['uniqueID'] == unique_id]['playDescription'].to_string)\n    print(\"Number of Defenders in Coverage: {}\".format(defenders['Defender Count'].iloc[0]))\n    print(\"Defenders by position: \\n{}\".format(defenders[(defenders['Is Defender'] == True)]['position']))\n    return defenders\n","1b54dbc8":"#Plot a random example from each class\n#unique_id = distance_metrics[distance_metrics['kmeans_class'] == 0].sample()['uniqueID'].iloc[0]\nunique_id = '2018092312_2899'\na = plot_play(snapshot_df, tracking_df, unique_id, snapshot_time, snapshot_frames)","668d31b7":"#unique_id = distance_metrics[distance_metrics['kmeans_class'] == 1].sample()['uniqueID'].iloc[0]\nunique_id = '2018092000_2899'\na = plot_play(snapshot_df, tracking_df, unique_id, snapshot_time, snapshot_frames)","3885441c":"unique_id = distance_metrics[distance_metrics['kmeans_class'] == 1].sample()['uniqueID'].iloc[0]\na = plot_play(snapshot_df, tracking_df, unique_id, snapshot_time, snapshot_frames)","145f7a1a":"The Polar coordinates did not yiled nearly as convincing of an elbow curve. Some follow on online research has taught me that KMeans operates best with Cartesian coordinates so perhaps that has something to do with the poor result. \n\nNote: The Polar coordinate angles were calculated in degrees. Perhaps it would have been worthwhile to see if radians made a difference. Doubtful though since it is merely a linear scaling of the same data. ","a9448319":"It should be noted that the provided data will track player positions throughout the field of play, regardless what yardline the ball was spotted on to begin the play. For this reason, the x coordinate in the raw Cartesian data for each play carries some bias and should be normalized. Two different methods were considered for this:\n\nPolar coordinates: Convert each set of Cartesian coordinates to a polar pair where the origin is the ball location when the play begins. Polar coordinates replace the typical (x,y) coordinate pair with a (distance, angle) pair relative to the origin. Thus each player will now be tracked throughout the play via their distance and angle from the original ball spot.\n\nNormalized Cartesian coordinates: Maintain the Cartesian coordinate format but subtract the ball spot yardline from the x coordinate to produce a dataset where all of the tracking data starts from the same point.\n\nNote: I now realize that I should have normalized the y coordinate as well since the ball is spotted on different hashmarks depending on the previous play result. I didn't have time before the submission deadline to explore what impact this would have. The Polar coordinates do now have this issue at all since using the ball location as the origin removes the bias of both the x and y coordinate. ","4bfd397b":"Listing all of the positions seen in the data. Of note, there are 13 defensive positions in the data","bed18d84":"Discovered that tracking data is not available for all 22 players on the field in a given play\nPlayer data for defenders is only tracked if they are in coverage. Count how many defenders are tracked per play","608bcd01":"Import the data into three dataframes. Combine all of the player tracking data for each of the 17 weeks of the season into a single dataframe","6cd128f1":"Calculated the most frequent number of players in coverage per play and kept that group to produce more uniform dataset. Will filter to just plays with 7 defenders in coverage. Plays with more than 11 defenders in coverage appear to mostly be edge cases such as fake punt passes","4f2f154d":"This analyis yielded some interesting results and showed some initial promise towards a KMeans implementaion that can cluster defensive coverages. Bin 0 appeared to contain many Man coverage plays while bin 1 contained many Zone coverage plays but extensive visual analysis would be needed to confirm this. Nonetheless, a stronger dispartiy in the elbow curve would inspire more confidence that there was a clear distinction being drawn in the data.\n\nFurther work on this project would involve building out more granular features to better capture the distinction between Man and Zone coverage. As discussed above, perhaps a varience metric that could illustrate how well a defensive shape is maintained in the first few seconds of a play or if the shape quickly dissolves because the players are in man coverage. This also presents the opportunity to experiment with other Machine Learning Algorithms such as a Neural Net for classifying these derived coverage \"shapes.\"\n\nThanks to the NFL for providing the opportunity for this fun project. Hail to the Washington Football Team \u270c ","901ba08d":"![Elbow Method for KMeans](attachment:image.png)","ed257157":"**Summary**\n\nThis notebook was an attempt to classify defensive coverages from the 2018 NFL season based on defensive player locations on the field at the snap and in the first few moments after the play began. Those player locations were provided as x,y Cartesian coordinates for each defensive player in coverage and all offensive skill positions as well as the Quarterback. We apply KMeans as an Unsupervised Machine Learning Algorithm and analyze the results. \n\nThe KMeans algorithm attempts to bin each example (play) into a specified number of bins based on similarity of each example's features. The goal in implementing this algorithm was to distinguish the type of coverage at a high level (man vs zone) or even more granularly (Cover 0, Cover 1, Cover 2, Cover 3, etc.). The features provided were the defensive player locations in .1 sec increments over the first 2 seconds of the play - assumed to be enough time for a zone coverage to take shape or man coverage to appear more random with defenders mimicing offensive player movements.\n\nThe results of this analysis proved largely inconclusive as there was no clear clustering of two bins (Man vs Zone) or any larger number of bins for that matter. Further attempts to develop this project could incorporate the offensive player movements, explore different features derived from the player positions that would better capture their resemblence to a defined\/structured zone coverage versus the relative unpredictability of player locations in man coverage. A different algorithm could be considered as well. ","157099f6":"In order to explore how each training set was being clustered by the algorithm, the results were merged back into the dataframe and so random plays from each set could be plotted.\n\nWe selected k=2 to evaluate whether the algorithm could distinguish between Man and Zone Coverage.","e3ca2c96":"Uniform training data is required as the input for the KMeans algorithm is a matrix of features. Inconsistent numbers of players tracked on a play will lead to inconsistent vector dimensions comprising of the matrix. If tracking data was available for all 11 players on defense - or all 22 players on the field total - we would use that as our uniform training set.","2ee5b191":"We now have a dataset ready to process via KMeans. The next step is to provide the algorithm with a desired number of bins - how many categories of defensive coverages each play could be categorized as.\n\nIn order to properly evaluate the best number of bins (k) in the KMeans algorithm, a common approach is the \"elbow\" method in which we evaluate the smallest k that garners a reasonably small Sum of Squared Error (SSE). In the plot of SSE over k, the \"elbow\" (shown in the red circle below) is typically the point at which any further increase in k does not yield a significant decrease in SSE, thus that k is the optimal number of bins determined for the training set.\n\nSource: https:\/\/stackoverflow.com\/questions\/43784903\/scikit-k-means-clustering-performance-measure","a7b91279":"Unfortunately, the Normalized Cartesian coordinates produced a similarly ambiguous elbow curve. This was rather disappointing considering the promise the raw Cartesian coordinates showed, despite the bias. Further research is needed here to determine how other feature scaling or altering of the data could improve the performance.","07c08cbf":"The tracking data for each player for a given frame (.1 sec) in a given play is an individual row in the dataframe. In order to present each player position at each frame as a feature in the KMeans algorithm, we need to create a dataframe where each column is a defensive player in coverage and the row is their location during each frame in each play during the 2018 season.\n\nA defensive coverage is only shown in it's original form during the first few seconds of a passing play. From there, either the ball is thrown and the defenders converge on the target, or the coverage breaks down as the play progresses. For this reason, only the first few seconds of each play were considered valuable training data. In order to determine an appropriate snapshot time length for the training set, the average time to throw needed to be considered. For 2018, this was between 2-3 seconds per NFL Next Gen Stats, thus a 2 second snapshot length was chosen to produce the cleanest but most informative training set.\n\nNext Gen Stats 2018 Time to Throw: https:\/\/nextgenstats.nfl.com\/stats\/passing\/2018\/REG\/all#average-time-to-throw","debba37b":"A very simple plotting function was put together to show the player positions at the snap, halfway through the snapshot, at the end of the snapshot, and finally as a culmination throughout the entire snapshot. Visual analysis of the first three plots offers some clarity into what the algorithm was presented with in order to perform the clustering. The final plot shows each player's location every .1 sec as a single point on the plot. Visual analysis of this shows a clear distinction between which plays are Man Coverage vs Zone. ","228e25a0":"Now we have a dataframe where each row is a uniqueID -  a particular frame within the first two seconds of a pass play - and the columns include the Cartesian coordinates of each defensive player in coverage on that play.","329ab671":"Just as an intial test of the algorithm, we used the raw non-normalized Cartesian coordinates as our features. In somewhat of a surprise, this data actually produced the best looking elbow curve as shown below with an optimal k value of 3. However, this should probably be attributed to the known bias in the data. Perhaps the three bins may be three sections of the field where the play was run. A good less on how biased data can be misleading.","38173723":"This second play shows a similar single high safety look resembling either the same Cover 1 Man or Cover 3 shell. However as the play progresses, the defenders maintain their shape, resemblant of a zone pattern and thus is a Cover 3 scheme. \n\nAnalysis of this play suggest we could implement further features to track the integrity of the shape of the coverage such as the variance of the distance between defenders. The player positions alone did not appear to be enough data to carry this information in the algorithm. This play was clustered in bin 1.","85e194b8":"After observation of several random examples from each set, two plays were highlighted in particular to express the intent of this research.\n\nThe first play we observe is has a single high safety with the other safety \"in the box\" along with the linebackers at a relatively similar depth as the corners near the line of scrimage. This typically indicates either a Cover 1 Man scheme or a Cover 3 Zone scheme. In the first three plots, it can be seen that the defenders in yellow are closely mimicing the alignment of the offensive players in blue, but there is still some ambiguity as to whether this is zone or man coverage. Finally in the plot of the full play, it can be seen that the defenders mirror the offensive player movements so this is clearly Cover 1 Man. \n\nAnalysis of this play suggests we may need to have a longer snapshot time and perhaps even add the offensive player tracking data as features. This play was clustered in bin 0.","81b5c2da":"Implement a boolean field to track which players are on defense","dabea114":"The final play we observe is a classic Cover 2 look with two deeep safeties while the corner and linebackers hook underneath. This could also be a Cover 2 Man scheme where the underneath defenders are playing man coverage but it is clear that the defenders maintain their relative shape throughout the play, thus they are in a Cover 2 Zone. This play was also clustered in bin 1.","1e184da9":"The gameId and playId columns are not unique individually but when combined they form a unique ID for tracking the player positions for specific plays throughout the season","075ad143":"Normalize player tracking data to all be in the Right direction so comparisons can be made properly"}}