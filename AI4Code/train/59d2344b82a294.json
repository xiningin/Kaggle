{"cell_type":{"b6b97008":"code","cd133167":"code","5055ae20":"code","ebb5c59f":"code","13b9b276":"code","c8130af1":"code","5ee480dd":"code","9be49732":"code","ad1cccd4":"code","4098ecc1":"code","e2cdc86d":"code","dc55ff6f":"code","d14aed99":"code","3fe01118":"code","8db43af3":"code","bb97943a":"code","a1dea8b1":"code","85ab5668":"code","56f337e3":"code","5dd28265":"code","24d73b84":"code","b9d01506":"code","6c1b6228":"code","13586603":"code","f9404bf1":"code","38558795":"code","5f7cb03a":"code","6bdff181":"code","cb9eaa1b":"markdown","156fac65":"markdown","28f82385":"markdown","9c909608":"markdown"},"source":{"b6b97008":"import fastai\nfrom fastai.vision import *\nfrom fastai.callbacks import *","cd133167":"from torchvision.models import vgg16_bn","5055ae20":"path = Path('data\/imagenet')\npath_hr = path\/'images\/train'\npath_lr = path\/'small-64\/train'\npath_mr = path\/'small-256\/train'","ebb5c59f":"il = ImageItemList.from_folder(path_hr)","13b9b276":"bs,size=16,256\narch = models.resnet34\n# sample = 0.1\nsample = False\n\ntfms = get_transforms()","c8130af1":"src = ImageImageList.from_folder(path_lr)","5ee480dd":"if sample: src = src.filter_by_rand(sample, seed=42)","9be49732":"src = src.random_split_by_pct(0.1, seed=42)","ad1cccd4":"def get_data(bs,size):\n    data = (src.label_from_func(lambda x: path_hr\/x.relative_to(path_lr))\n           .transform(get_transforms(max_zoom=2.), size=size, tfm_y=True)\n           .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n\n    data.c = 3\n    return data","4098ecc1":"data = get_data(bs,size)","e2cdc86d":"def gram_matrix(x):\n    n,c,h,w = x.size()\n    x = x.view(n, c, -1)\n    return (x @ x.transpose(1,2))\/(c*h*w)","dc55ff6f":"vgg_m = vgg16_bn(True).features.cuda().eval()\nrequires_grad(vgg_m, False)\nblocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]","d14aed99":"base_loss = F.l1_loss\n\nclass FeatureLoss(nn.Module):\n    def __init__(self, m_feat, layer_ids, layer_wgts):\n        super().__init__()\n        self.m_feat = m_feat\n        self.loss_features = [self.m_feat[i] for i in layer_ids]\n        self.hooks = hook_outputs(self.loss_features, detach=False)\n        self.wgts = layer_wgts\n        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n\n    def make_features(self, x, clone=False):\n        self.m_feat(x)\n        return [(o.clone() if clone else o) for o in self.hooks.stored]\n    \n    def forward(self, input, target):\n        out_feat = self.make_features(target, clone=True)\n        in_feat = self.make_features(input)\n        self.feat_losses = [base_loss(input,target)]\n        self.feat_losses += [base_loss(f_in, f_out)*w\n                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n        return sum(self.feat_losses)\n    \n    def __del__(self): self.hooks.remove()","3fe01118":"feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])","8db43af3":"wd = 1e-3\nlearn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight)\ngc.collect();","bb97943a":"learn.unfreeze()","a1dea8b1":"learn.load(Path('data\/oxford-iiit-pet\/small-96\/models\/2b').absolute());","85ab5668":"learn.fit_one_cycle(1, slice(1e-6,1e-4))","56f337e3":"learn.save('imagenet')","5dd28265":"learn.show_results(rows=3, imgsize=5)","24d73b84":"learn.recorder.plot_losses()","b9d01506":"data_mr = (ImageImageList.from_folder(path_mr).random_split_by_pct(0.1, seed=42)\n          .label_from_func(lambda x: path_hr\/x.relative_to(path_lr))\n          .transform(get_transforms(), size=(819,1024), tfm_y=True)\n          .databunch(bs=2).normalize(imagenet_stats, do_y=True))","6c1b6228":"learn.data = data_mr","13586603":"fn = '\/data0\/datasets\/part1v3\/oxford-iiit-pet\/other\/dropout.jpg'","f9404bf1":"img = open_image(fn); img.shape","38558795":"_,img_hr,b = learn.predict(img)","5f7cb03a":"show_image(img, figsize=(18,15), interpolation='nearest');","6bdff181":"Image(img_hr).show(figsize=(18,15))","cb9eaa1b":"## Feature loss","156fac65":"## Test","28f82385":"## Super resolution on Imagenet","9c909608":"## Train"}}