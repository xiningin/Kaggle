{"cell_type":{"d3210ad3":"code","6a560efb":"code","ff8271f4":"code","5655b1ea":"code","4f9bb252":"code","76297bb3":"code","87e1c72a":"code","1dc062a5":"code","849ed43e":"code","d68deb45":"code","5175e52c":"code","4eb2b669":"code","eb21b5ed":"code","f2bde8c8":"code","7c8a09cb":"code","6ad63055":"code","d3de23f5":"code","4b2309e7":"code","499f2564":"code","92486943":"code","7a24cbdd":"code","e429035d":"markdown","524e757f":"markdown","70c0aa7e":"markdown","42c9ac9c":"markdown","c2443e9d":"markdown","4202bfaf":"markdown","e071b984":"markdown","bc3c85dc":"markdown","d68d57c4":"markdown","eec74a42":"markdown","3b2ddce5":"markdown","596567b2":"markdown"},"source":{"d3210ad3":"import os\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom PIL import Image\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split, KFold\n\nimport keras\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\nK.set_image_data_format('channels_last')","6a560efb":"print(os.listdir(\"..\/input\"))","ff8271f4":"path = \"..\/input\/train\/\"\nfile_list = os.listdir(path)\nfile_list[:20]","5655b1ea":"reg = re.compile(\"[0-9]+\")\n\ntemp1 = list(map(lambda x: reg.match(x).group(), file_list)) \ntemp1 = list(map(int, temp1))\n\ntemp2 = list(map(lambda x: reg.match(x.split(\"_\")[1]).group(), file_list))\ntemp2 = list(map(int, temp2))\n\nfile_list = [x for _,_,x in sorted(zip(temp1, temp2, file_list))]\nfile_list[:20]","4f9bb252":"train_image = []\ntrain_mask = []\nfor idx, item in enumerate(file_list):\n    if idx % 2 == 0:\n        train_image.append(\"..\/input\/train\/\"+item)\n    else:\n        train_mask.append(\"..\/input\/train\/\"+item)\n        \nprint(train_image[:10],\"\\n\" ,train_mask[:10])","76297bb3":"# Display the first image and mask of the first subject.\nimage1 = np.array(Image.open(path+\"1_1.tif\"))\nimage1_mask = np.array(Image.open(path+\"1_1_mask.tif\"))\nimage1_mask = np.ma.masked_where(image1_mask == 0, image1_mask)\n\nfig, ax = plt.subplots(1,3,figsize = (16,12))\nax[0].imshow(image1, cmap = 'gray')\n\nax[1].imshow(image1_mask, cmap = 'gray')\n\nax[2].imshow(image1, cmap = 'gray', interpolation = 'none')\nax[2].imshow(image1_mask, cmap = 'jet', interpolation = 'none', alpha = 0.7)","87e1c72a":"mask_df = pd.read_csv(\"..\/input\/train_masks.csv\")\nmask_df.head()","1dc062a5":"width = 512\nheight = 512\n\ntemp = mask_df[\"pixels\"][0]\ntemp = temp.split(\" \")","849ed43e":"mask1 = np.zeros(height * width)\nfor i, num in enumerate(temp):\n    if i % 2 == 0:\n        run = int(num) -1             # very first pixel is 1, not 0\n        length = int(temp[i+1])\n        mask1[run:run+length] = 255 \n\n#Since pixels are numbered from top to bottom, then left to right, we are careful to change the shape\nmask1 = mask1.reshape((width, height))\nmask1 = mask1.T ","d68deb45":"# RLE : run-length-encoding\ndef RLE_to_image(rle):\n    '''\n    rle : array in mask_df[\"pixels\"]\n    '''\n    width, height = 580, 420\n    \n    if rle == 0:\n        return np.zeros((height,width))\n    \n    else:\n        rle = rle.split(\" \")\n        mask = np.zeros(width * height)\n        for i, num in enumerate(rle):\n            if i % 2 == 0:\n                run = int(num) - 1\n                length = int(rle[i+1])\n                mask[run:run+length] = 255\n\n        mask = mask.reshape((width, height))\n        mask = mask.T \n\n        return mask","5175e52c":"mask_df.head()\nsubject_df = mask_df[['subject', 'img']].groupby(by = 'subject').agg('count').reset_index()\nsubject_df.columns = ['subject', 'N_of_img']\nsubject_df.sample(10)","4eb2b669":"pd.value_counts(subject_df['N_of_img']).reset_index()","eb21b5ed":"print(os.listdir(\"..\/input\/test\")[0:15])","f2bde8c8":"from keras.models import Model, Input, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","7c8a09cb":"smooth = 1.\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred, smooth = 100):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac","6ad63055":"def unet(input_size=(256,256,1)):\n    \n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","d3de23f5":"def train_generator(data_frame, batch_size, train_path, aug_dict,\n        image_color_mode=\"grayscale\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n    '''\n    can generate image and mask at the same time use the same seed for\n    image_datagen and mask_datagen to ensure the transformation for image\n    and mask is the same if you want to visualize the results of generator,\n    set save_to_dir = \"your path\"\n    '''\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        directory = train_path,\n        x_col = \"filename\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        directory = train_path,\n        x_col = \"mask\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img \/ 255\n    mask = mask \/ 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","4b2309e7":"df = pd.DataFrame(data={\"filename\": train_image, 'mask' : train_mask})\n\nkf = KFold(n_splits = 5, shuffle=False)","499f2564":"train_generator_args = dict(rotation_range=0.2,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\n\nhistories = []\nlosses = []\naccuracies = []\ndicecoefs = []\nious = []\n\nEPOCHS = 50\nBATCH_SIZE = 32\n\nfor k, (train_index, test_index) in enumerate(kf.split(df)):\n    train_data_frame = df.iloc[train_index]\n    test_data_frame = df.iloc[test_index]\n    \n    train_gen = train_generator(train_data_frame, BATCH_SIZE,\n                                None,\n                                train_generator_args,\n                                target_size=(height, width))\n\n    test_gener = train_generator(test_data_frame, BATCH_SIZE,\n                                None,\n                                train_generator_args,\n                                target_size=(height, width))\n\n    model = unet(input_size=(height,width, 1))\n    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, \\\n                      metrics=[iou, dice_coef, 'binary_accuracy'])\n#    model.summary()\n\n    model_checkpoint = ModelCheckpoint(str(k+1) + '_unet_lung_seg.hdf5', \n                                       monitor='loss', \n                                       verbose=1, \n                                       save_best_only=True)\n\n    history = model.fit_generator(train_gen,\n                                  steps_per_epoch=len(train_data_frame) \/ BATCH_SIZE, \n                                  epochs=EPOCHS, \n                                  callbacks=[model_checkpoint],\n                                  validation_data = test_gener,\n                                  validation_steps=len(test_data_frame) \/ BATCH_SIZE)\n    \n    #test_gen = test_generator(test_files, target_size=(512,512))\n    test_gen = train_generator(test_data_frame, BATCH_SIZE,\n                                None,\n                                train_generator_args,\n                                target_size=(height, width))\n    results = model.evaluate_generator(test_gen, steps=len(test_data_frame))\n    results = dict(zip(model.metrics_names,results))\n    \n    histories.append(history)\n    accuracies.append(results['binary_accuracy'])\n    losses.append(results['loss'])\n    dicecoefs.append(results['dice_coef'])\n    ious.append(results['iou'])","92486943":"for h, history in enumerate(histories):\n\n    keys = history.history.keys()\n    fig, axs = plt.subplots(1, 4, figsize = (25, 5))\n    fig.suptitle('No. ' + str(h+1) + ' Fold Results', fontsize=30)\n\n    for k, key in enumerate(list(keys)[len(keys)\/\/2:]):\n        training = history.history[key]\n        validation = history.history['val_' + key]\n\n        epoch_count = range(1, len(training) + 1)\n\n        axs[k].plot(epoch_count, training, 'r--')\n        axs[k].plot(epoch_count, validation, 'b-')\n        axs[k].legend(['Training ' + key, 'Validation ' + key])","7a24cbdd":"print('average accuracy : ', np.mean(np.array(accuracies)), '+-', np.std(np.array(accuracies)))\nprint('average loss : ', np.mean(np.array(losses)), '+-', np.std(np.array(losses)))\nprint('average iou : ', np.mean(np.array(ious)), '+-', np.std(np.array(ious)))\nprint('average dice_coe : ', np.mean(np.array(dice_cos)), '+-', np.std(np.array(dice_cos)))","e429035d":"Now, I try to load all image files and store them variables X and y. Afther doing this, I recognize that it takes very much memory.<br\/>\nPlease let me know if there are several efficient ways to store image file","524e757f":"## Exploratory data analysis\nFirst of all, let's check how many train data we have.","70c0aa7e":"Each test image name is numbered in different way, so we cannot exploit subject information when we predict test data.","42c9ac9c":"## How to deal with train_masks.csv ?","c2443e9d":"There are total 47 subjects and almost almost all subjects have 120 images except for 5 subjects who have 119 images.<br\/>\nI want to know whether test dataset has similar distribution or not. Let's check this by using the similar way when we listed the train data.","4202bfaf":"**Sort the file list in ascending order and seperate it into images and masks**<br\/>\nEach file has the form of either \"subject_imageNum.tif\" or \"subject_imageNum_mask.tif\", so we can extract `subject` and `imageNum` from each file name by using regular expression. `\"[0-9]+\"` means to find the first consecutive number.<br\/>","e071b984":"Hi, I am a semantic segmentation beginner.(I'm sorry for my poor English in advance)<br\/>\n(I refered to many part of this [site](https:\/\/github.com\/jocicmarko\/ultrasound-nerve-segmentation\/blob\/master\/submission.py))","bc3c85dc":"Let's check that I did well","d68d57c4":"One can find the number of subjects in train data by `groupby` method on `mask_df`.","eec74a42":"## Building the training dataset.\nLet's look at the train image list","3b2ddce5":"Let's modularize this work.","596567b2":"**How to deal with `pixels` column ?**<br\/>\nLet me try to convert the first `pixels` column to the mask image.<br\/>\nActually, this work could be not necessary, since we are provided mask_image. But other competition that I want to join provide only run length encoded data, so I do this to practice. "}}