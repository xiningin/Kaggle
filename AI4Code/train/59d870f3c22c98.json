{"cell_type":{"f85eae31":"code","ba43215e":"code","8833017f":"code","5ae38951":"code","56950ef9":"code","541a70c0":"code","0e61ed41":"code","6c71b4bb":"code","88052e44":"code","c3283be1":"code","5f3f6419":"code","1a9407c2":"code","f7575da8":"code","0493e580":"code","f58ad88f":"code","0b63ee1e":"code","fe48b8fc":"code","de926c76":"code","c5854a94":"code","ac668b70":"code","e9f84f0a":"code","44b4b7f9":"code","39bc38f4":"code","2725204b":"code","6fd2a644":"code","5d084114":"code","c066899b":"code","e25a7fe4":"code","2097b513":"code","88b224c3":"code","e44d191f":"code","01ffa049":"code","d166959a":"code","eaf2cb00":"code","8c41e762":"code","f22c37eb":"code","7196a6ce":"code","ca053ba9":"code","419d8382":"code","55a0e84c":"code","a3334cca":"code","e927d6e9":"code","af7fb8a0":"code","70a5c391":"code","6544a222":"code","8acfcd2f":"markdown","6900f58e":"markdown","43d8cb5e":"markdown","6777b45c":"markdown","ff26a94d":"markdown","22975d06":"markdown","3b4ca00b":"markdown","060c17a0":"markdown","35b63d0e":"markdown","52d2d1d3":"markdown","77068db9":"markdown","6d8d0615":"markdown","c0a72330":"markdown","f6ecbe8d":"markdown","10ddf29e":"markdown","83c4dc1a":"markdown","5bd4ad44":"markdown","51445ff4":"markdown","def2afc6":"markdown","635cfbdc":"markdown","6755bb25":"markdown","bd3efaa5":"markdown","1aa00d37":"markdown","66f38915":"markdown","33d59f21":"markdown","792ef7cd":"markdown","3fc2dfb8":"markdown","c0b4662c":"markdown","053c2655":"markdown","9f37c815":"markdown","cd665ec3":"markdown","5d340db4":"markdown","456e1ced":"markdown","4d88edb0":"markdown","0410292f":"markdown","7c0af1d5":"markdown","ea558665":"markdown","e7f7d6d7":"markdown","2f29e28a":"markdown","3f0b55d5":"markdown","675e7df9":"markdown","040ba469":"markdown","ef2dbc1f":"markdown","a7497864":"markdown","2956bded":"markdown","640839a7":"markdown","f6911b31":"markdown","b8238661":"markdown","5e47e544":"markdown","e1747b02":"markdown","9c97cfbf":"markdown","0f000357":"markdown","2c2674da":"markdown","1d93f925":"markdown","be6932b2":"markdown","98fc6fd2":"markdown","2c0913a0":"markdown","ac10cb9a":"markdown","b2a9f8b6":"markdown","2736c391":"markdown","fb6a4232":"markdown"},"source":{"f85eae31":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","ba43215e":"df=pd.read_csv('..\/input\/mushrooms.csv')","8833017f":"df.shape","5ae38951":"df.head()","56950ef9":"df.columns","541a70c0":"df.isnull().sum()","0e61ed41":"df.duplicated().sum()","6c71b4bb":"df.nunique()","88052e44":"df['class'].unique()","c3283be1":"df.describe()","5f3f6419":"df['class'].value_counts()","1a9407c2":"%matplotlib inline\nitems=pd.DataFrame(df['class'].value_counts())\nitems.plot(kind='bar', figsize=(4,6), width=0.3, color=[('#63d363', '#d36363')], legend=False)\nplt.title(\"Number of Edible and Poisonous Mushrooms in this Dataset\", fontsize=\"15\")\nplt.xlabel(\"Edible or Poisonous\", fontsize=\"12\")\nplt.ylabel(\"Number of Mushrooms\", fontsize=\"12\")\nplt.xticks(np.arange(2),(\"Edible\", \"Poisonous\"), rotation=0)\nplt.grid()   \nplt.show()","f7575da8":"df['cap-color'].value_counts()","0493e580":"caps=pd.DataFrame(df['cap-color'].value_counts())\ncaps.plot(kind='bar', figsize=(8,8), width=0.8, color=[('#bf7050', '#A9A9A9', '#d36363', '#f3f6c3', '#DCDCDC', '#bfa850', '#f9d7f7', '#D2691E', '#63d363', '#7050bf')], legend=False)\nplt.xlabel(\"Cap Color\",fontsize=12)\nplt.ylabel('Number of Mushrooms',fontsize=12)\nplt.title('Mushroom Cap Color Types in the Dataset', fontsize=15)\nplt.xticks(np.arange(10),('Brown', 'Gray','Red','Yellow','White','Buff','Pink','Cinnamon', 'Green','Purple'))\nplt.grid()       \nplt.show() ","f58ad88f":"df['cap-shape'].value_counts()","0b63ee1e":"capsh=pd.DataFrame(df['cap-shape'].value_counts())\ncapsh.plot(kind='bar', figsize=(8,8), width=0.5, color=[('#A9A9A9')], legend=False)\nplt.xlabel(\"Cap Shape\",fontsize=12)\nplt.ylabel('Number of Mushrooms',fontsize=12)\nplt.title('Mushroom Cap Types in the Dataset', fontsize=15)\nplt.xticks(np.arange(6),('Convex', 'Flat','Knobbed','Bell','Sunken','Conical'))\nplt.grid()       \nplt.show() ","fe48b8fc":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing","de926c76":"# Encodes labels from 0 to n_classes-1\nlabelEncoder = preprocessing.LabelEncoder()\nfor col in df.columns:\n    df[col] = labelEncoder.fit_transform(df[col])","c5854a94":"df.head()","ac668b70":"df['class'].value_counts()","e9f84f0a":"# 75% train, 25% test\ntrain, test = train_test_split(df, test_size = 0.25) \ny_train = train['class']\nX_train = train[[x for x in train.columns if 'class' not in x]]\ny_test = test['class']\nX_test = test[[x for x in test.columns if 'class' not in x]]\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# Vectorize the training and test data \nvec = TfidfVectorizer(sublinear_tf=True, max_df=0.5,stop_words='english')","44b4b7f9":"from sklearn.naive_bayes import MultinomialNB\n# Creating a MultinomialNB classifier and fit the model\ncl = MultinomialNB()\ncl.fit(X_train, y_train)","39bc38f4":"y_pred=cl.predict(X_test)","2725204b":"from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n\nprint(\"Accuracy score: \", accuracy_score(y_test, y_pred))\nprint(\"Recall score: \", recall_score(y_test, y_pred, average = 'weighted'))\nprint(\"Precision score: \", precision_score(y_test, y_pred, average = 'weighted'))\nprint(\"F1 score: \", f1_score(y_test, y_pred, average = 'weighted'))","6fd2a644":"from sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nkfold = model_selection.KFold(n_splits=10, random_state=7)\nscoring = 'accuracy'\nresults = model_selection.cross_val_score(cl, X_train, y_train, cv=kfold, scoring=scoring)\nprint(\"Cross validation average accuracy with 10-folds: %f\" % (results.mean()))","5d084114":"from sklearn.metrics import confusion_matrix\nimport itertools","c066899b":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","e25a7fe4":"cm = confusion_matrix(y_test, y_pred)\nplt.figure()\nplot_confusion_matrix(cm, classes=['p','e'], title='Confusion matrix, without normalization')","2097b513":"plt.figure()\nplot_confusion_matrix(cm, classes=['p','e'], normalize=True, title='Confusion matrix, with normalization')","88b224c3":"from sklearn import svm","e44d191f":"clf = svm.SVC(gamma='auto')\nclf.fit(X_train, y_train) ","01ffa049":"y_pred=clf.predict(X_test)","d166959a":"print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\nprint(\"Recall score: \", recall_score(y_test, y_pred, average = 'weighted'))\nprint(\"Precision score: \", precision_score(y_test, y_pred, average = 'weighted'))\nprint(\"F1 score: \", f1_score(y_test, y_pred, average = 'weighted'))","eaf2cb00":"from sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nkfold = model_selection.KFold(n_splits=10, random_state=7)\nscoring = 'accuracy'\nresults = model_selection.cross_val_score(clf, X_train, y_train, cv=kfold, scoring=scoring)\nprint(\"Cross validation average accuracy with 10-folds: %.3f\" % (results.mean()))","8c41e762":"from sklearn.metrics import confusion_matrix","f22c37eb":"cm = confusion_matrix(y_test, y_pred)\nplt.figure()\nplot_confusion_matrix(cm, classes=['p','e'], title='Confusion matrix, without normalization')","7196a6ce":"plt.figure()\nplot_confusion_matrix(cm, classes=['p','e'], normalize=True, title='Confusion matrix, with normalization')","ca053ba9":"from sklearn import linear_model, datasets\nlogreg = linear_model.LogisticRegression(solver='lbfgs',max_iter=2000)","419d8382":"logreg.fit(X_train, y_train)","55a0e84c":"y_pred=logreg.predict(X_test)","a3334cca":"from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n\nprint(\"Accuracy score: \", accuracy_score(y_test, y_pred))\nprint(\"Recall score: \", recall_score(y_test, y_pred, average = 'weighted'))\nprint(\"Precision score: \", precision_score(y_test, y_pred, average = 'weighted'))\nprint(\"F1 score: \", f1_score(y_test, y_pred, average = 'weighted'))","e927d6e9":"from sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nkfold = model_selection.KFold(n_splits=10, random_state=7)\nscoring = 'accuracy'\nresults = model_selection.cross_val_score(logreg, X_train, y_train, cv=kfold, scoring=scoring)\nprint(\"Cross validation average accuracy with 10-folds: %.3f\" % (results.mean()))","af7fb8a0":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","70a5c391":"plt.figure()\nplot_confusion_matrix(cm, classes=['p','e'], title='Confusion matrix, without normalization')","6544a222":"plt.figure()\nplot_confusion_matrix(cm, classes=['p','e'], normalize=True, title='Confusion matrix, with normalization')","8acfcd2f":"Poisonous mushrooms can often times confuse people into thinking they are not posionous due to their similar appearance to some non-poisonous mushroom types. Even though most mushrooms seem to be edible, mushroom poisoning can cause discomfort and even in some cases death.  Poisonous mushrooms are found to mostly cause gastrointestinal problems and in the worst case may cause respiratory or kidney failure.  The symptoms appear within twenty minutes to four hours of ingestion. The goal is to find the best model to predict whether a mushroom is poisionous or edible (poisonous or not poisonous).","6900f58e":"Let's look at the descriptive statistics for the data:","43d8cb5e":"I chose the Mushroom Classification dataset from Kaggle.  The dataset was put on Kaggle by UCI Machine Learning Repository which maintains around 351 datasets.  This dataset is one of those.  The sample set contains around 23 species of mushrooms from the gilled mushroom Agaricus and Lepiota Family.  The mushrooms are either identified as completely poisonous or completely edible.      ","6777b45c":"Visualizing number of each cap color:","ff26a94d":"Scikit-Learn Implementation","22975d06":"Seeing what labelEncoder did to the poisonous (p) and edible (e) labels.  ","3b4ca00b":"Now that we have trained our model. Let us predict our labels using the test portion of the data set.","060c17a0":"### 5. Exploration and Visualization\n","35b63d0e":"The two classes of mushrooms are p (poisonous) and e (edible).","52d2d1d3":"### 8. References","77068db9":"Cross validation is a way to check for overfitting.","6d8d0615":"There are more edible mushrooms than poisonous mushrooms 4,208 versus 3,916 in this dataset.","c0a72330":"Now that we have trained our model. Let us predict our labels using the test portion of the data set.","f6ecbe8d":"There are no null values in this dataset.","10ddf29e":"### 7. Conclusion\n","83c4dc1a":"Scikit-Learn Implementation","5bd4ad44":"### 1. Introduction","51445ff4":"There are 8124 rows and 23 columns in this dataset.","def2afc6":"To prepare the model the dataset needs to be split into test and train.  The method train_test_split randomly splits the dataset into 75% train and 25% test.","635cfbdc":"Looking at the number of mushrooms there are for each cap shape in this dataset.","6755bb25":"Showing first 5 rows of the dataset.  This dataset is comprised of completely categorical features.","bd3efaa5":"Looking at the cap-color distribution in this dataset.","1aa00d37":"Cross validation is a way to check for overfitting.","66f38915":"Same matrix with normalization:","33d59f21":"#### Objectives \n* Preprocessing and exploratory data analysis steps such as: loading the data into the data frame, checking the shape (number of rows\/columns), getting the head of data, checking for missing and duplicate values, etc.  \n* Splitting the dataset into test and train.  \n* Finding the best sklearn model that accurately predicts whether a mushroom is poisonous or edible using naive bayes, support vector machines, and logistic regression","792ef7cd":"Given the cross validation average is close to the accuracy of the naive bayes model we can conclude that our model does not really overfit. ","3fc2dfb8":"##### Logistic Regression","c0b4662c":"Visualizing number of poisonous and edible mushrooms:","053c2655":"### 2. Problem Definition\n","9f37c815":"##### Naive Bayes","cd665ec3":"Scikit-Learn Implementation","5d340db4":"Let's look at how the LabelEncoder transformed our data.","456e1ced":"The Kaggle website provides information on what the column data means:\n    \n**class**: p=poisonous,e=edible  \n**cap-shape**: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s                   \n**cap-surface**: fibrous=f,grooves=g,scaly=y,smooth=s                 \n**cap-color**: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y                   \n**bruises**: bruises=t,no=f                      \n**odor**: almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s                         \n**gill-attachment**: attached=a, descending=d, free=f, notched=n              \n**gill-spacing**: close=c,crowded=w,distant=d                \n**gill-size**: broad=b,narrow=n                 \n**gill-color**: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y               \n**stalk-shape**: enlarging=e,tapering=t                  \n**stalk-root**: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?                  \n**stalk-surface-above-ring**: fibrous=f,scaly=y,silky=k,smooth=s    \n**stalk-surface-below-ring**: fibrous=f,scaly=y,silky=k,smooth=s     \n**stalk-color-above-ring**: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y        \n**stalk-color-below-ring**: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y       \n**veil-type**: partial=p,universal=u                    \n**veil-color**: brown=n,orange=o,white=w,yellow=y                \n**ring-number**: none=n,one=o,two=t                 \n**ring-type**: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z                    \n**spore-print-color**: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y            \n**population**: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y                   \n**habitat**: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d ","4d88edb0":"Now the categorical variables are shown numerically. ","0410292f":"##### Support Vector Machines (SVM)","7c0af1d5":"Edible is set to 0 and Poisonous is now set to 1.","ea558665":"For this project I used the Mushroom Classification dataset from Kaggle.  It was put on Kaggle by the UCI Machine Learning group.  I first started with regular data preparation techniques and went on to exploring the data.  The data is completely categorical and there are 8124 rows and 23 columns.  To prepare the data for use in machine learning models, I had to map these categorical values to numerical values using the labelEncoder function.  Then I split the dataset into test (25%) and train (75%).  The two main classes of mushrooms are poisonous and not poisonous (edible).  The purpose of these models are to predict that.  I used three types of models using scikit learn which are naive bayes, svm (secure vector machines), and logistic regression. The best model was svm and it gave 100% accuracy, the next best model was logistic regression with around 94% accuracy, and finally naive bayes with 81% accuracy.         ","e7f7d6d7":"https:\/\/towardsdatascience.com\/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n\nhttps:\/\/www.namyco.org\/mushroom_poisoning_syndromes.php\n\nhttp:\/\/scikit-learn.org\/stable\/index.html","2f29e28a":"Now let's evaluate how well the logistic model performs.","3f0b55d5":"Given the cross validation average is close to the accuracy of the SVM model we can conclude that our model generalizes well and is not overfitting.","675e7df9":"Cross validation:","040ba469":"Now let's evaluate how well the model performs.","ef2dbc1f":"The sklearn naive bayes algorithm cannot directly operate on categorical features that are non-numeric so we will use sklearn's LabelEncoder to convert the categorical features to numeric values.","a7497864":"### 3. Data Sets","2956bded":"### 4. Preparation","640839a7":"Looking at the columns in dataset:","f6911b31":"The matrix below is the same but is normalized.   ","b8238661":"Shows how many unique values there are for each column.","5e47e544":"#### Abstract\n","e1747b02":"### 6. Modeling and Evaluation\n","9c97cfbf":"The two matrices below show that the SVM model performed with 100% accuracy.  There was nothing inaccurately predicted.","0f000357":"Visualizing number of each cap shape:","2c2674da":"There are no duplicate values in this dataset.","1d93f925":"Normalized matrix:","be6932b2":"Even though all models did well the best model out of naive bayes, SVM, and logistic regression is SVM.  SVM gave about 100% accuracy while logistic gave about 94% accuracy and naive bayes performed the worst which was around 81% accuracy.  The worst situation seems to be if it is predicted edible but it is actually poisonous.  The other situations are if it is predicted poisonous but is edible, poisonous and is poisonous, edible and is edible.     ","98fc6fd2":"Looking at the number of poisonous and edible mushrooms in this dataset.","2c0913a0":"Now let's evaluate how well the model performs.","ac10cb9a":"## Mushroom Classification-Is it poisonous or edible?\n\n## PinkDragon1000\n\n#### Date: 8\/13\/18\n\n![](https:\/\/img.webmd.com\/dtmcms\/live\/webmd\/consumer_assets\/site_images\/articles\/health_tools\/all_about_mushrooms_slideshow\/493ss_thinkstock_rf_poisonous_mushroom.jpg)\n---\n\n","b2a9f8b6":"Since the cross validation score is close to the logistic regression model score that means it is not overfitting the data. ","2736c391":"The dataset can be found here: https:\/\/www.kaggle.com\/uciml\/mushroom-classification\/home. The format of the data is in a CSV format and is in one single file called mushrooms.csv. To prepare the dataset for classification purposes it needs to be split for the test and train.","fb6a4232":"Making a confusion matrix:"}}