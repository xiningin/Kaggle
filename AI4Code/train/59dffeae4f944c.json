{"cell_type":{"4dad0407":"code","944dca06":"code","41145763":"code","1ee715d4":"code","b94c1a6b":"code","12afbefd":"code","3d84d59f":"code","389e2258":"code","3fdc0db7":"code","80a07159":"code","591dc6f5":"code","65ede65a":"code","58fd4d01":"code","24060f7e":"code","23feb958":"code","4f60de01":"code","38b58fa2":"code","6066abe6":"code","32e50a13":"code","21144393":"code","55ae461f":"code","82f649c8":"code","5559a213":"code","c36c408b":"code","8db25113":"code","6ccf4bfd":"code","1454770d":"code","31d75b85":"code","4c4ac048":"code","e2b22ebc":"code","82a3a0a6":"code","d9204f97":"code","5ceb4999":"code","f8894396":"code","e5d2f7b8":"code","16dbe2c5":"code","0c08022d":"markdown","e0976407":"markdown","f0987f3a":"markdown","66cb2d01":"markdown","9f0386ec":"markdown","bcf2d7f9":"markdown","fcffcd69":"markdown","aa45a03f":"markdown","6a618b4e":"markdown","9aafe119":"markdown","0ed268b1":"markdown"},"source":{"4dad0407":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport os \nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom catboost import CatBoostRegressor, Pool\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error","944dca06":"PATH = '..\/input\/predict-volcanic-eruptions-ingv-oe\/'\n\ntrain_list = os.listdir('..\/input\/predict-volcanic-eruptions-ingv-oe\/train')\ntest_list = os.listdir(\"..\/input\/predict-volcanic-eruptions-ingv-oe\/test\")\ntrain_time = pd.read_csv(PATH + 'train.csv')","41145763":"print('Number of train files: {}'.format(len(train_list)))\nprint('Number of test files: {}'.format(len(test_list )))","1ee715d4":"example = pd.read_csv(PATH + 'train\/' + train_list[0])","b94c1a6b":"example[:5]","12afbefd":"example_test = pd.read_csv(PATH + 'test\/' + test_list[0])","3d84d59f":"example_test[:5]","389e2258":"train_list[0]","3fdc0db7":"train_time","80a07159":"example.plot(figsize=(15,15), subplots=True);","591dc6f5":"train_time[train_time.segment_id == int(train_list[0].split('.')[0])]","65ede65a":"pd.DataFrame(example.fillna(0).describe().iloc[1:, :].unstack()).reset_index()","58fd4d01":"process = pd.DataFrame(example.fillna(0).describe().iloc[1:, :].unstack()).reset_index()\nprocess = process.rename(columns={0: 'value'})\nprocess['feature'] = process['level_0'] + '_' + process['level_1']","24060f7e":"process","23feb958":"process = process.drop(['level_0', 'level_1'], axis=1).set_index('feature').T","4f60de01":"process","38b58fa2":"process['time'] = train_time[train_time.segment_id == int(train_list[0].split('.')[0])].time_to_eruption.values[0]","6066abe6":"process","32e50a13":"pd.DataFrame(example.fillna(0).skew()).T","21144393":"def create_frame(data, data_time=None, type_data='train'):\n    data = data.fillna(0)\n    \n    # \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\u0430\n    data_transform = data.describe().iloc[1:, :]\n    \n    # \u0414\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\n    # \u041a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442 \u0430\u0441\u0438\u043c\u043c\u0435\u0442\u0440\u0438\u0438\n    data_transform.loc['skew'] = data.skew().tolist()\n    \n    #\u0421\u0440\u0435\u0434\u043d\u0435\u0435 \u0430\u0431\u0441\u043e\u043b\u044e\u0442\u043d\u043e\u0435 \u043e\u0442\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u0435\n    data_transform.loc['mad'] = data.mad().tolist()\n    \n    # \u041a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442 \u044d\u043a\u0441\u0446\u0435\u0441\u0441\u0430 \u2014 \u043c\u0435\u0440\u0430 \u043e\u0441\u0442\u0440\u043e\u0442\u044b \u043f\u0438\u043a\u0430 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0439 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b.\n    data_transform.loc['kurtosis'] = data.kurtosis().tolist()\n    \n    # \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043a\u0432\u0430\u043d\u0442\u0438\u043b\u0435\u0439\n    for i in range(0, 100, 5):\n        if ((i!=25) & (i!=50)):\n                str_col = f\"{i}%\"\n                int_col = float(i)\/100\n                data_transform.loc[str_col] = data_transform.quantile(int_col).tolist()\n        else:\n            continue\n            \n    data_transform = pd.DataFrame(data_transform.unstack()).reset_index()\n    data_transform = data_transform.rename(columns={0: 'value'})\n    data_transform['feature'] = data_transform['level_0'] + '_' + data_transform['level_1']\n    data_transform = data_transform.drop(['level_0', 'level_1'], axis=1).set_index('feature').T\n    \n    if type_data=='train':\n        data_transform['time'] = data_time\n    return data_transform","55ae461f":"all_train = pd.DataFrame()\n\nfor file in tqdm(train_list):\n    df = pd.read_csv(PATH + 'train\/' + file)\n    data_time = train_time[train_time.segment_id == int(file.split('.')[0])].time_to_eruption.values[0]\n    df = create_frame(df, data_time, type_data='train')\n    all_train = all_train.append(df)\n\nall_train = all_train.reset_index(drop=True)","82f649c8":"all_test = pd.DataFrame()\n\nfor file in tqdm(test_list):\n    df = pd.read_csv(PATH + 'test\/' + file)\n    df = create_frame(df, data_time=None, type_data='test')\n    all_test = all_test.append(df)\n\nall_test = all_test.reset_index(drop=True)","5559a213":"all_train[:5]","c36c408b":"all_test[:5]","8db25113":"X = all_train.drop('time',axis=1)\ny = all_train['time']\n\ntest = all_test.copy()","6ccf4bfd":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, shuffle=True, random_state=10)\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size=0.25, shuffle=True, random_state=10)","1454770d":"def mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)\/y_true))","31d75b85":"clf = CatBoostRegressor(loss_function='MAPE')  \ntrain_dataset = Pool(data=X_train,\n                     label=y_train,\n                     )\n    \neval_dataset = Pool(data=X_val,\n                    label=y_val,\n                    )\n    \nclf.fit(train_dataset,\n          use_best_model=True,\n          verbose = 0,\n          eval_set=eval_dataset)","4c4ac048":"y_pred = clf.predict(Pool(data=X_test))\n    \nprint(f\"MAPE: {mape(y_test, y_pred)}\")\nprint(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}\")","e2b22ebc":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, shuffle=True, random_state=10)","82a3a0a6":"n_fold = 5\ncv = KFold(n_splits=n_fold, shuffle=True, random_state=10)\nprediction = np.zeros(len(test))\nmape_, mae, rmse = [], [], []\n\nparams = {\n            'iterations':1000,\n            'learning_rate':0.1,\n            'depth':6,\n            'eval_metric':'RMSE'\n}\n\nfor fold, (train_index, val_index) in enumerate(cv.split(X)):\n    X_train = X.iloc[train_index,:]\n    X_val = X.iloc[val_index,:]\n\n    y_train = y.iloc[train_index]\n    y_val = y.iloc[val_index]\n          \n    clf = CatBoostRegressor(**params)  \n    \n    train_dataset = Pool(data=X_train,\n                     label=y_train,\n                     )\n    \n    eval_dataset = Pool(data=X_val,\n                    label=y_val,\n                    )\n    \n    clf.fit(train_dataset,\n              use_best_model=True,\n              verbose = 0,\n              eval_set=eval_dataset)\n   \n    y_pred = clf.predict(Pool(data=X_test))\n    \n    mape_.append(mape(y_test, y_pred))\n    mae.append(mean_absolute_error(y_test, y_pred))\n    rmse.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n\n    print(f\"fold: {fold}, MAPE: {mape(y_test, y_pred)}\")\n    print(f\"fold: {fold}, MAE: {mean_absolute_error(y_test, y_pred)}\")\n    print(f\"fold: {fold}, RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}\")\n\n    # test array predictions\n    prediction += clf.predict(Pool(data=test))\n        \nprediction \/= n_fold\n\nprint('CV mean MAPE:  {0:.4f}, std: {1:.4f}.'.format(np.mean(mape_), np.std(mape_)))\nprint('CV mean MAE: {0:.4f}, std: {1:.4f}.'.format(np.mean(mae), np.std(mae)))\nprint('CV mean RMSE: {0:.4f}, std: {1:.4f}.'.format(np.mean(rmse), np.std(rmse)))","d9204f97":"sub_example = pd.read_csv(PATH + 'sample_submission.csv')\nsub_example[:5]","5ceb4999":"test_index = [int(i.split('.')[0]) for i in test_list]","f8894396":"test_index[:5]","e5d2f7b8":"submission = pd.DataFrame()\nsubmission['segment_id'] = test_index\nsubmission['time_to_eruption'] = prediction\nsubmission.to_csv('submission.csv', header=True, index=False)","16dbe2c5":"submission[:5]","0c08022d":"Look at one of the train signal","e0976407":"Create a function for data preparation","f0987f3a":"https:\/\/catboost.ai\/docs\/concepts\/python-usages-examples.html","66cb2d01":"We can transform our signals in 1 row","9f0386ec":"# Preprocessing Train and Test","bcf2d7f9":"# Import the data","fcffcd69":"We are going to use KFold with CatBoostRegressor. We didn't use GridSearch because save time","aa45a03f":"Train and Test size","6a618b4e":"# Modeling","9aafe119":"# Using KFold with some parametrs","0ed268b1":"#  Baseline"}}