{"cell_type":{"591edd6c":"code","dae4d470":"code","0c2f0600":"code","a29110f4":"code","d855524a":"code","78a41a9a":"code","55f8b6f3":"code","7d90b0af":"code","af9ff349":"code","7b5c7600":"code","f907bd48":"code","f627d390":"code","606af203":"code","1ae85122":"code","c3d94c58":"code","f875207f":"code","88e42b03":"code","f342b345":"code","f0a49dff":"code","e351d732":"code","4017b0ab":"code","cdbbac23":"code","f75ccda1":"code","05d8353b":"code","47a5c14f":"code","3c111c8a":"code","d653238a":"code","fb579923":"code","6428696a":"code","2216e884":"code","0c6a52d1":"code","5341bd17":"code","5e6bfe7f":"code","73cb53b0":"code","94552960":"code","e3e9f56f":"code","96e63860":"code","ac270b42":"code","8ffa86d8":"code","a00a9b0e":"code","940d2eda":"code","c7b491bf":"code","b3d98db5":"code","9b46092e":"code","1a6eaa17":"code","6dfd7571":"code","922b337c":"code","2d0f64d5":"code","fcbcc687":"code","952d672c":"code","4303c5e2":"code","5c1c3cbb":"code","90412743":"code","cc9f1948":"code","8a3e10a2":"code","a9a36778":"code","4598277d":"code","478d2e18":"markdown","8972f9c1":"markdown","bf80bf90":"markdown","e82c86b9":"markdown","5bd7374f":"markdown","ecea616e":"markdown","8c124800":"markdown","88ff63a8":"markdown","8a2b1ac8":"markdown","045da620":"markdown","88c3dce1":"markdown","c3d21ad9":"markdown","2a36d532":"markdown","d8427c4b":"markdown","75d303fb":"markdown","82173dbb":"markdown","8eec513d":"markdown","b9ecf740":"markdown","138df21b":"markdown","94a0ef36":"markdown","ceb7af53":"markdown","d6d7aa4b":"markdown","2dc13ef0":"markdown","2ef0ede2":"markdown","55ad54af":"markdown","76802213":"markdown","7caf7c64":"markdown","514b27dd":"markdown","883c7987":"markdown","1994a35e":"markdown","7ad13df0":"markdown","909a1704":"markdown","35ac1d22":"markdown","fbd8758a":"markdown","43e2c306":"markdown","8d3b380c":"markdown","7129fb8f":"markdown","258f9f5d":"markdown","76d8e6d2":"markdown","f6254828":"markdown","5baa9ae5":"markdown","fc69484b":"markdown","db77e7d1":"markdown","4ed654f3":"markdown","48624190":"markdown","bcea3307":"markdown","a980116b":"markdown","aebb35c1":"markdown","044554b0":"markdown","f3bc3376":"markdown","96771565":"markdown","ace09642":"markdown","99f458df":"markdown","4c0bad5f":"markdown","f0a52f12":"markdown","dc9c0d73":"markdown","f82fef89":"markdown","e38cac9b":"markdown","bf06ddc0":"markdown","a2a42f1e":"markdown","8395b744":"markdown","d8bed00a":"markdown","1b786bda":"markdown","0dd3642c":"markdown","6f0ce5ef":"markdown","ca4d60ec":"markdown","feaa6ee7":"markdown","a2d8e701":"markdown","3496d30c":"markdown","a17f514c":"markdown","a8347a26":"markdown","2a4b2e12":"markdown","33fe9acc":"markdown","1f295c38":"markdown","0f0d0002":"markdown","957ca5cc":"markdown","a5d03e18":"markdown","e034bac1":"markdown","b9095308":"markdown","e413dd5e":"markdown","45c138f0":"markdown","f7b5cc63":"markdown","b37312de":"markdown","6232bd6c":"markdown","5d839bb2":"markdown"},"source":{"591edd6c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dae4d470":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, RidgeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC, NuSVC, LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, classification_report, roc_curve, plot_roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, average_precision_score\nfrom sklearn.model_selection import cross_val_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","0c2f0600":"dataset = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')","a29110f4":"dataset","d855524a":"dataset.info()","78a41a9a":"dataset.isnull().sum()","55f8b6f3":"dataset.describe()","7d90b0af":"# Renaming columns.\ndataset.columns = ['Age', 'Sex', 'Chest Pain Type', 'Resting Blood Pressure', 'Cholesterol', 'Fasting Blood Sugar', 'Resting ECG', 'Max. Heart Rate',\n       'Exercise Induced Angina', 'Previous Peak', 'Slope', 'No. Major Blood Vessels', 'Thal Rate', 'Condition']","af9ff349":"numerical = ['Age','Resting Blood Pressure','Cholesterol','Max. Heart Rate','Previous Peak']\ncategorical= ['Sex','Chest Pain Type','Fasting Blood Sugar','Resting ECG','Exercise Induced Angina','Slope','No. Major Blood Vessels','Thal Rate']","7b5c7600":"# Compute the correlation matrix\ncorr = dataset.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(8, 8))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","f907bd48":"plt.figure(figsize=(14,12))\nax = sns.heatmap(corr, square=True, annot=True, fmt='.2f')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)          \nplt.show()","f627d390":"labels = ['More Chance of Heart Attack', 'Less Chance of Heart Attack']\nsizes = dataset['Condition'].value_counts(sort = True)\n\ncolors = [\"#ffb3b3\",\"#C2C4E2\"]\nexplode = (0.05,0) \n \nplt.figure(figsize=(7,7))\nplt.suptitle(\"Number of Targets in the dataset\",y=0.9, family='Sherif', size=18, weight='bold')\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90,)\n\nplt.show()","606af203":"# Count Plot of Categorical Data w\/o Condition\ncolors = [\"#D0DBEE\", \"#C2C4E2\", \"#EED4E5\", \"#D1E6DC\", \"#BDE2E2\"]\nj=0\nfig=plt.figure(figsize=(10,10),constrained_layout =True)\nplt.suptitle(\"Count of the Categorical Variables\",y=1.07, family='Sherif', size=18, weight='bold')\nfig.text(0.31,1.02,\"Categorical Data without Condition\", size=13, fontweight='light', fontfamily='monospace')\nfor i in dataset[categorical]:\n    ax=plt.subplot(241+j)\n    ax.set_aspect('auto')\n    ax.grid(color='gray', linestyle=':', axis='y', zorder=0, dashes=(1,5))\n    ax=sns.countplot(data=dataset, x=i, palette=colors, alpha=1)\n    for s in ['left','right','top','bottom']:\n        ax.spines[s].set_visible(False)\n    j=j+1","1ae85122":"# Count Plot of Categorical Data with Condition\ncolors = ['#ccccff','#ffcccc']\nj=0\nfig=plt.figure(figsize=(10,10),constrained_layout =True)\nplt.suptitle(\"Count of the Categorical Variables\",y=1.07, family='Sherif', size=18, weight='bold')\nfig.text(0.33,1.02,\"Categorical Data with Condition\", size=13, fontweight='light', fontfamily='monospace')\nfor i in dataset[categorical]:\n    ax=plt.subplot(241+j)\n    ax.set_aspect('auto')\n    ax.grid(color='gray', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\n    ax=sns.countplot(data=dataset, x=i, hue='Condition', palette=colors, alpha=1)\n    for s in ['left','right','top','bottom']:\n        ax.spines[s].set_visible(False)\n    j=j+1","c3d94c58":"# Distribution Plot of Numerical Data w\/o Condition\nj=0\nfig=plt.figure(figsize=(10,10),constrained_layout =True)\nplt.suptitle(\"Distribution of the Numeric Variables\",y=1.07, family='Sherif', size=18, weight='bold')\nfig.text(0.315,1.02,\"Numerical Data without Condition\", size=13, fontweight='light', fontfamily='monospace')\nfor i in dataset[numerical]:\n    ax=plt.subplot(321+j)\n    ax.set_aspect('auto')\n    ax.grid(color='gray', linestyle=':', axis='x', zorder=0,  dashes=(1,5))\n    ax=sns.kdeplot(data=dataset, x=i, color='#D0DBEE', fill=True, edgecolor='black', alpha=1)\n    for s in ['left','right','top','bottom']:\n        ax.spines[s].set_visible(False)\n    j=j+1","f875207f":"# Distribution Plot of Numerical Data with Condition\ncolors = ['#D0DBEE','#ffcccc']\nj=0\nfig=plt.figure(figsize=(10,10),constrained_layout =True)\nplt.suptitle(\"Distribution of the Numeric Variables\",y=1.07, family='Sherif', size=18, weight='bold')\nfig.text(0.333,1.02,\"Numerical Data with Condition\", size=13, fontweight='light', fontfamily='monospace')\nfor i in dataset[numerical]:\n    ax=plt.subplot(321+j)\n    ax.set_aspect('auto')\n    ax.grid(color='gray', linestyle=':', axis='x', zorder=0,  dashes=(1,5))\n    ax=sns.kdeplot(data=dataset, x=i, hue='Condition', palette=colors, fill=True, edgecolor='black', alpha=1)\n    for s in ['left','right','top','bottom']:\n        ax.spines[s].set_visible(False)\n    j=j+1","88e42b03":"# Scatter Plot of Numerical Data with Condition\ncolors = ['#D0DBEE','#ff3333']\nnum_cols = ['Resting Blood Pressure','Cholesterol','Max. Heart Rate','Previous Peak']\nj=0\nfig=plt.figure(figsize=(10,10),constrained_layout =True)\nplt.suptitle(\"Scatter Plot of the Numeric Variables\",y=1.07, family='Sherif', size=18, weight='bold')\nfig.text(0.333,1.02,\"Numerical Data with Condition\", size=13, fontweight='light', fontfamily='monospace')\nfor i in dataset[num_cols]:\n    ax=plt.subplot(321+j)\n    ax.set_aspect('auto')\n    ax.grid(color='gray', linestyle=':', axis='x', zorder=0,  dashes=(1,5))\n    ax=sns.scatterplot(data=dataset,x=dataset['Age'],y=i,hue=dataset['Condition'],ec='black',palette=colors)\n    for s in ['left','right','top','bottom']:\n        ax.spines[s].set_visible(False)\n    j=j+1","f342b345":"# Outliers Detection\ncolors = ['#CBE4F9','#CDF5F6','#EFF9DA','#F9EBDF','#F9D8D6']\nplt.figure(figsize=(9,9))\nplt.suptitle(\"Outliers of Numeric Variables\",y=0.94, family='Sherif', size=18, weight='bold')\nplt.text(-0.4, 1.64, 'Detecting Outliers in Numerical Columns', horizontalalignment='center',verticalalignment='center', transform=ax.transAxes,size=14,fontweight='light', fontfamily='monospace')\nsns.boxenplot(data = dataset[numerical],palette = colors)\nplt.grid(color='gray', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nplt.xticks(rotation=45)\nplt.show()","f0a49dff":"# Removing Outliers\nfor i in dataset[numerical]:\n    q1 = dataset[i].quantile(0.25)\n    q3 = dataset[i].quantile(0.75)\n    iqr = q3-q1\n    Lower_tail = q1 - 1.5 * iqr\n    Upper_tail = q3 + 1.5 * iqr\n    med = np.median(dataset[i])\n    for j in dataset[i]:\n        if j > Upper_tail or j < Lower_tail:\n            dataset[i] = dataset[i].replace(j, med)","e351d732":"colors = ['#CBE4F9','#CDF5F6','#EFF9DA','#F9EBDF','#F9D8D6']\nplt.figure(figsize=(9,9))\nplt.suptitle(\"Outliers of Numeric Variables\",y=0.94, family='Sherif', size=18, weight='bold')\nplt.text(-0.405, 1.64, 'Removing Outliers in Numerical Columns', horizontalalignment='center',verticalalignment='center', transform=ax.transAxes,size=14,fontweight='light', fontfamily='monospace')\nsns.boxenplot(data = dataset[numerical],palette = colors)\nplt.grid(color='gray', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nplt.xticks(rotation=45)\nplt.show()","4017b0ab":"colors = ['#80d4ff','#ff3333']\nsns.pairplot(data=dataset,hue='Condition',diag_kind='kde',palette=colors)\nplt.show()","cdbbac23":"x = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","f75ccda1":"# Splitting Data into Train and Test Set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state= 0)","05d8353b":"print(\"Number transactions x_train dataset: \", x_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions x_test dataset: \", x_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","47a5c14f":"# Feature Scaling with StandardScaler\nfrom sklearn.preprocessing import StandardScaler \nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","3c111c8a":"#Fitting Logistic Regression Model\nclassifier = LogisticRegression(random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\nplt.figure(figsize = (6, 6))\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","d653238a":"#Fitting PassiveAggressiveClassifier Model\nclassifier = PassiveAggressiveClassifier()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier._predict_proba_lr(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","fb579923":"#Fitting RidgeClassifier Model\nclassifier = RidgeClassifier()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier._predict_proba_lr(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","6428696a":"#Fitting KNeighborsClassifier Model\nclassifier = KNeighborsClassifier()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","2216e884":"#Fitting RadiusNeighborsClassifier Model\nclassifier = RadiusNeighborsClassifier(outlier_label=1,radius=6)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","0c6a52d1":"#Fitting GaussianNB Model\nclassifier = GaussianNB()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","5341bd17":"#Fitting BernoulliNB Model\nclassifier = BernoulliNB()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","5e6bfe7f":"#Fitting SVC Model\nclassifier = SVC(probability=True)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","73cb53b0":"#Fitting Nu-SVC Model\nclassifier = NuSVC(nu=0.3,probability=True)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","94552960":"#Fitting LinearSVC Model\nclassifier = LinearSVC()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier._predict_proba_lr(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","e3e9f56f":"#Fitting DecisionTreeClassifier Model\nclassifier = DecisionTreeClassifier(criterion= 'gini',random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","96e63860":"#Fitting RandomForestClassifier Model\nclassifier = RandomForestClassifier(criterion= 'entropy', n_estimators= 200,random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","ac270b42":"#Fitting ExtraTreesClassifier Model\nclassifier = ExtraTreesClassifier(criterion= 'gini',n_estimators= 100,random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","8ffa86d8":"#Fitting AdaBoostClassifier Model\nclassifier = AdaBoostClassifier(algorithm= 'SAMME', learning_rate= 0.1, n_estimators= 100,random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","a00a9b0e":"#Fitting GradientBoostingClassifier Model\nclassifier = GradientBoostingClassifier(criterion= 'mse', learning_rate= 0.1, loss= 'exponential', n_estimators= 100,random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","940d2eda":"#Fitting BaggingClassifier Model\nclassifier = BaggingClassifier(random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","c7b491bf":"#Fitting XGBClassifier Model\nclassifier = XGBClassifier(eval_metric= 'error', learning_rate= 0.1)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","b3d98db5":"#Fitting LGBMClassifier Model\nclassifier = LGBMClassifier(learning_rate= 0.1, n_estimators= 100, random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","9b46092e":"#Fitting LinearDiscriminantAnalysis Model\nclassifier = LinearDiscriminantAnalysis()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","1a6eaa17":"#Fitting QuadraticDiscriminantAnalysis Model\nclassifier = QuadraticDiscriminantAnalysis()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","6dfd7571":"#Fitting MLPClassifier Model\nclassifier = MLPClassifier()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","922b337c":"# Starting H2O\nimport h2o\nfrom h2o.automl import H2OAutoML\n\nh2o.init(nthreads = -1)","2d0f64d5":"# Import Dataset\ndataset = h2o.import_file('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')","fcbcc687":"dataset","952d672c":"# Identify predictors and response\nx = dataset.columns\ny = \"output\"\nx.remove(y)\n\ndataset[y] = dataset[y].asfactor()\n\n# Run AutoML for 20 base models (limited to 1 hour max runtime by default)\naml = H2OAutoML(max_models=20, seed=11)\naml.train(x=x, y=y, training_frame=dataset)","4303c5e2":"lb = aml.leaderboard\nlb.head()","5c1c3cbb":"#Best Model\naml.leader ","90412743":"# Variable Importance Plot\naml.leader.varimp_plot()","cc9f1948":"# SHAP Summary Plot\naml.leader.shap_summary_plot(dataset)","8a3e10a2":"# Partial Dependence Plot\naml.pd_multi_plot(dataset, column='caa')","a9a36778":"from tpot import TPOTClassifier\n\ntpot = TPOTClassifier(generations=5, verbosity=2)\ntpot.fit(x_train,y_train)","4598277d":"y_pred = tpot.predict(x_test)\ny_prob = tpot.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15})\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()","478d2e18":"## **Count Plot** <a id='3.3' ><\/a>","8972f9c1":"## **Linear SVC** <a id='5.10' ><\/a>","bf80bf90":"\ud83d\udccc *Linear Discriminant Analysis or LDA is a statistical technique for binary and multiclass classification. It too assumes a Gaussian distribution for the numerical input variables. You can construct an LDA model using the LinearDiscriminantAnalysis class.*","e82c86b9":"## **Gradient Boosting** <a id='5.15' ><\/a>","5bd7374f":"## **Scatter Plot** <a id='3.5' ><\/a>","ecea616e":"\ud83d\udccc We have 303 rows and 14 columns in our dataset. <br>\n\ud83d\udccc We can see that the dataset contains *numerical* variables. <br>","8c124800":"## **Nu-SVC** <a id='5.9' ><\/a>","88ff63a8":"\ud83d\udccc From the above plots, we can see that the distribution density of different features them being skew. Let's also compare them with the target column of *Condition* to see how to perform.","8a2b1ac8":"\ud83d\udccc From the above plots, we can see that we have different features which have a common and uncommon type of categories in our dataset. <br>\n\ud83d\udccc But, It is not enough to tell us about the features. Let's compare all the categorical features with the target column of *Condition*.","045da620":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:Beige;\n           font-size:110%;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:black;\">\n    \nHello Kagglers, <br>\n\nIn this notebook, I am going to predict the chance of a person suffering from a heart attack. But, first I am going to do deal with missing values in the dataset and then perform exploratory data analysis and learn more about the features. Then, I am going to use different classification models on our dataset and select the best performing one. <br>\n    So, let's get started.\n<\/p>\n<\/div> ","88c3dce1":"\ud83d\udccc From the above plot, we can see that the relationship between *Age* and different numerical features in our dataset with *Condition*. We can also few Outliers in our plot.","c3d21ad9":"\ud83d\udccc *A Gaussian Naive Bayes algorithm is a special type of NB algorithm. It's specifically used when the features have continuous values. It's also assumed that all the features are following a gaussian distribution i.e, normal distribution.*","2a36d532":"\ud83d\udccc *Similar to SVC with parameter kernel=\u2019linear\u2019, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.*","d8427c4b":"\ud83d\udccc *Like MultinomialNB, this classifier is suitable for discrete data. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary\/boolean features. The Passive-Aggressive algorithms are a family of Machine learning algorithms that are not very well known by beginners and even intermediate Machine Learning enthusiasts. However, they can be very useful and efficient for certain applications.*","75d303fb":"From above categorical plots we can see that: <br>\n\ud83d\udccc In *Chest Pain*, Type 0 has the highest number of people who have less chance of suffering from a heart attack. <br>\n\ud83d\udccc *Fasting Blood Sugar* and *Resting ECG* doesn't have much difference in their respective conditions. <br>\n\ud83d\udccc In *Exercise-Induced Angina*, Type 0 has the highest number of people who are likely to suffer a heart attack. <br>\n\ud83d\udccc *Slope* has Type 2, *No. of Major Blood Vessels* has Type 0 and *Thal Rate* has Type 2 which shows people who are likely to suffer from a heart attack.","82173dbb":"\ud83d\udccc **True Positives (TP)** - These are the correctly predicted positive values which means that the value of actual class is yes and the value of predicted class is also yes. <br>\n\ud83d\udccc **True Negatives (TN)** - These are the correctly predicted negative values which means that the value of actual class is no and value of predicted class is also no. <br>\n\ud83d\udccc **False Positives (FP)** \u2013 When actual class is no and predicted class is yes. <br>\n\ud83d\udccc **False Negatives (FN)** \u2013 When actual class is yes but predicted class in no. <br>\n\ud83d\udccc **Accuracy** - Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. `Accuracy = TP+TN\/TP+FP+FN+TN` <br>\n\ud83d\udccc **Precision** - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. `Precision = TP\/TP+FP` <br>\n\ud83d\udccc **Recall (Sensitivity)** - Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes. `Recall = TP\/TP+FN` <br>\n\ud83d\udccc **F1 score** - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account.  `F1 Score = 2(Recall Precision) \/ (Recall + Precision)` <br>\n\ud83d\udccc **Support** - Support is the number of actual occurrences of the class in the specified dataset. Support doesn\u2019t change between models but instead diagnoses the evaluation process.","8eec513d":"\ud83d\udccc From the above distribution plot, we can see that, *Age* and *Max. Heart Rate* is Negative Skewed and *Resting Blood Pressure*, *Cholesterol*, and *Previous Peak* are Positive Skewed.","b9ecf740":"### Removal <a id='3.6.2' ><\/a>","138df21b":"\ud83d\udccc After extensive data analysis and I tried different classification models to see how it performs on the dataset. I got pretty good results with classification report. <br>\n\ud83d\udccc Also, I plotted ROC and Precision-Recall Curve for classification models also Variable Importance, SHAP Summary and Partial Dependenced Plot for H2O AutoML. <br>\n\ud83d\udccc Note that all models are used with default parameters, we can also tune the models and see how they perform.","94a0ef36":"\ud83d\udccc *Similar to SVC but uses a parameter to control the number of support vectors.*","ceb7af53":"## **LightGBM** <a id='5.18' ><\/a>","d6d7aa4b":"\ud83d\udccc *A classifier with a quadratic decision boundary, generated by fitting class conditional densities to the data and using Bayes\u2019 rule. The model fits a Gaussian density to each class.*","2dc13ef0":"## **TPOT** <a id='5.23' ><\/a>","2ef0ede2":"\ud83d\udccc *XGBoost stands for Extreme Gradient Boosting, it is a performant machine learning library based on the paper Greedy Function Approximation: A Gradient Boosting Machine, by Friedman. XGBoost implements a Gradient Boosting algorithm based on decision trees.*","55ad54af":"\ud83d\udccc The above graphs produce a matrix of relationships between each variable in your data for an instant examination of our data. We can see that the outliers in our dataset have been taken care of.","76802213":"\ud83d\udccc *Support Vector Machines (or SVM) seek a line that best separates two classes. Those data instances that are closest to the line that best separates the classes are called support vectors and influence where the line is placed. SVM has been extended to support multiple classes Of particular importance is the use of different kernel functions via the kernel parameter .A powerful Radial Basis Function is used by default. You can construct an SVM model using the SVC class.*","7caf7c64":"1. [Importing Libraries](#1)<a href='1' ><\/a> <br>\n2. [Importing Dataset](#2)<a href='2' ><\/a> <br>\n3. [Exploratory Data Analysis](#3)<a href='3' ><\/a> <br>\n    3.1. [Heat Map Correlation](#3.1)<a href='3.1' ><\/a> <br>\n    3.2. [Pie Chart](#3.2)<a href='3.2' ><\/a> <br>\n    3.3. [Count Plot](#3.3)<a href='3.3' ><\/a> <br>\n    3.4. [Distribution Plot](#3.4)<a href='3.4' ><\/a> <br>\n    3.5. [Scatter Plot](#3.5)<a href='3.5' ><\/a> <br>\n    3.6. [Outliers](#3.6)<a href='3.6' ><\/a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; a. [Detection](#3.6.1)<a href='3.6.1' ><\/a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; b. [Removal](#3.6.2)<a href='3.6.2' ><\/a> <br>\n    3.7. [Pair Plot](#3.7)<a href='3.7' ><\/a> <br>\n4. [Data Preprocessing](#4)<a href='4' ><\/a> <br>\n5. [Models](#5)<a href='5' ><\/a> <br>\n    5.1. [Logistic Regression](#5.1)<a href='5.1' ><\/a> <br>\n    5.2. [Passive Aggressive Classifier](#5.2)<a href='5.2' ><\/a> <br>\n    5.3. [Ridge Classifier](#5.3)<a href='5.3' ><\/a> <br>\n    5.4. [K-Nearest Neighbors](#5.4)<a href='5.4' ><\/a> <br>\n    5.5. [Radius Neighbors Classifier](#5.5)<a href='5.5' ><\/a> <br>\n    5.6. [GaussianNB](#5.6)<a href='5.6' ><\/a> <br>\n    5.7. [BernoulliNB](#5.7)<a href='5.7' ><\/a> <br>\n    5.8. [SVM](#5.8)<a href='5.8' ><\/a> <br>\n    5.9. [Nu-SVC](#5.9)<a href='5.9' ><\/a> <br>\n    5.10. [Linear SVC](#5.10)<a href='5.10' ><\/a> <br>\n    5.11. [Decision Tree](#5.11)<a href='5.11' ><\/a> <br>\n    5.12. [Random Forest](#5.12)<a href='5.12' ><\/a> <br>\n    5.13. [Extra Trees](#5.13)<a href='5.13' ><\/a> <br>\n    5.14. [AdaBoost](#5.14)<a href='5.14' ><\/a> <br>\n    5.15. [Gradient Boosting](#5.15)<a href='5.15' ><\/a> <br>\n    5.16. [Bagging Classifier](#5.16)<a href='5.16' ><\/a> <br>\n    5.17. [XGBoost](#5.17)<a href='5.17' ><\/a> <br>\n    5.18. [LightGBM](#5.18)<a href='5.18' ><\/a> <br>\n    5.19. [Linear Discriminant Analysis](#5.19)<a href='5.19' ><\/a> <br>\n    5.20. [Quadratic Discriminant Analysis](#5.20)<a href='5.20' ><\/a> <br>\n    5.21. [MLPClassifier](#5.21)<a href='5.21' ><\/a> <br>\n    5.22. [H2O AutoML](#5.22)<a href='5.22' ><\/a> <br>\n    5.23. [TPOT](#5.23)<a href='5.23' ><\/a> <br>\n6. [Conclusion](#6)<a href='6' ><\/a> <br>","514b27dd":"\ud83d\udccc In this notebook, we are using Boxen Plot to detect the outliers of each features in our dataset, where any point above or below the whiskers represent an outlier. This is also known as \u201cUnivariate method\u201d as here we are using one variable outlier analysis.","883c7987":"## **H2O AutoML** <a id='5.22' ><\/a>","1994a35e":"## **Random Forest** <a id='5.12' ><\/a>","7ad13df0":"## **AdaBoost** <a id='5.14' ><\/a>","909a1704":"\ud83d\udccc *Extra Trees are another modification of bagging where random trees are constructed from samples of the training dataset. You can construct an Extra Trees model for classification using the ExtraTreesClassifier class.*","35ac1d22":"\ud83d\udccc *TPOT is meant to be an assistant that gives you ideas on how to solve a particular machine learning problem by exploring pipeline configurations that you might have never considered, then leaves the fine-tuning to more constrained parameter tuning techniques such as grid search.*","fbd8758a":" <div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n     Welcome\n<\/div>","43e2c306":"## **SVM** <a id='5.8' ><\/a>","8d3b380c":"## **Ridge Classifier** <a id='5.3' ><\/a>","7129fb8f":"## **Decision Tree** <a id='5.11' ><\/a>","258f9f5d":"\ud83d\udccc *The H2O AutoML interface is designed to have as few parameters as possible so that all the user needs to do is point to their dataset, identify the response column and optionally specify a time constraint or limit on the number of total models trained.* <br>\n\ud83d\udccc *In both the R and Python API, AutoML uses the same data-related arguments, x, y, training_frame, validation_frame, as the other H2O algorithms. Most of the time, all you\u2019ll need to do is specify the data arguments. You can then configure values for max_runtime_secs and\/or max_models to set explicit time or number-of-model limits on your run.*","76d8e6d2":"## **Logistic Regression** <a id='5.1' ><\/a>","f6254828":"\ud83d\udccc From the above correlation matrix, we can see that the correlation between features is less. <br>\n\ud83d\udccc *Chest Pain Type* with *Condition* and *Max. Heart Rate* with *Condition* have high correlated features in our dataset; Correlation Coefficient of 0.43 and 0.42 respectively. <br>\n\ud83d\udccc Our features have a lot of negative correlation coefficient indicating that two individual variables have a statistical relationship such that generally move in opposite directions from one another.","5baa9ae5":"\ud83d\udccc Classifier implementing a vote among neighbors within a given radius","fc69484b":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           border:2px solid DodgerBlue;\n           background-color:white;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n    Thank You!\n<\/div>","db77e7d1":"\ud83d\udccc *AdaBoost was perhaps the first successful boosting ensemble algorithm. It generally works by weighting instances in the dataset by how easy or difficult they are to classify, allowing the algorithm to pay or less attention to them in the construction of subsequent models. You can construct an AdaBoost model for classification using the AdaBoostClassifier class*","4ed654f3":"\ud83d\udccc Variable Importance shows the relative importance of the most important variables in the model. H2O displays each feature\u2019s importance after scaling between 0 and 1. <br>\n\ud83d\udccc It is straightforward to interpret this graph. Variable with the longest bar (aka the topmost one) is the most important and the one with the shortest bar (aka the bottom-most one) is the least important.","48624190":"\ud83d\udccc The above command df.describe() helps us to view the statistical properties of numerical variables. It excludes character variables.","bcea3307":"## **Extra Trees** <a id='5.13' ><\/a>","a980116b":"\ud83d\udccc *MLPClassifier stands for Multi-layer Perceptron classifier which in the name itself connects to a Neural Network. Unlike other classification algorithms such as Support Vectors or Naive Bayes Classifier, MLPClassifier relies on an underlying Neural Network to perform the task of classification.*","aebb35c1":"## **Quadratic Discriminant Analysis** <a id='5.20' ><\/a>","044554b0":"\ud83d\udccc SHAP value which is an acronym for **SHapley Additive exPlanations** interprets the impact of having a particular value for a given variable compared to the prediction we would make if that variable took some baseline value instead. <br>\n\ud83d\udccc The y-axis indicates the variable name, usually in the descending order of importance from top to bottom. <br>\n\ud83d\udccc SHAP value on the x-axis indicates the change in log-odds. From this value, we can extract the probability of an event (*Condition* in this case). <br>\n\ud83d\udccc Gradient color indicates the original value for that variable. In binary classification problems(as in our case), it will take two colors, but it can contain the whole spectrum for numeric target variables(regression problems). <br>\n\ud83d\udccc Each point in the plot represents a record from the original dataset.","f3bc3376":"## **Linear Discriminant Analysis** <a id='5.19' ><\/a>","96771565":" <div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n     Table of Contents\n<\/div>","ace09642":"\ud83d\udccc *Random Forests is an extension of bagged decision trees. Samples of the training dataset are taken with replacement, but the trees are constructed in a way that reduces the correlation between individual classifiers. Specifically, rather than greedily choosing the best split point in the construction of each tree, only a random subset of features are considered for each split. You can construct a Random Forest model for classification using the RandomForestClassifier class.*","99f458df":"## **Heat Map Correlation** <a id='3.1' ><\/a>","4c0bad5f":"## **Radius Neighbors Classifier** <a id='5.5' ><\/a>","f0a52f12":"\ud83d\udccc Partial dependence plot (PDP) gives a graphical depiction of the marginal effect of a variable on the response. <br>\n\ud83d\udccc The effect of a variable is measured in change in the mean response. PDP assumes independence between the feature for which is the PDP computed and the rest.","dc9c0d73":"\ud83d\udccc *Classification and Regression Trees (CART or just decision trees) construct a binary tree from the training data. Split points are chosen greedily by evaluating each attribute and each value of each attribute in the training data in order to minimize a cost function (like the Gini index). You can construct a CART model using the DecisionTreeClassifier class*","f82fef89":"## **K-Nearest Neighbors** <a id='5.4' ><\/a>","e38cac9b":"## **MLPClassifier** <a id='5.21' ><\/a>","bf06ddc0":"\ud83d\udccc An outlier is an observation that lies an abnormal distance from other values in a random sample from a population.","a2a42f1e":"\ud83d\udccc *Stochastic Gradient Boosting (also called Gradient Boosting Machines) are one of the most sophisticated ensemble techniques. It is also a technique that is proving to be perhaps one of the best techniques available for improving performance via ensembles. You can construct a Gradient Boosting model for classification using the GradientBoostingClassifier class*","8395b744":"\ud83d\udccc *LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages: Faster training speed and higher efficiency, Lower memory usage, Better accuracy, Support of parallel and GPU learning, Capable of handling large-scale data.*","d8bed00a":"## **Outliers** <a id='3.6' ><\/a>","1b786bda":"\ud83d\udccc After detecting, we are using Median Imputation to take care of outliers. In this technique, we replace the extreme values with median values. <br>\n\ud83d\udccc It is represented by the formula IQR = Q3 \u2212 Q1. The lines of code below calculate and print the interquartile range for each of the variables in the dataset. <br>\n\ud83d\udccc It is advised to not use mean values as they are affected by outliers.","0dd3642c":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='6'><\/a>\n    \n    Conclusion\n<\/div>","6f0ce5ef":"## **GaussianNB** <a id='5.6' ><\/a>","ca4d60ec":"## **Bagging Classifier** <a id='5.16' ><\/a>","feaa6ee7":"\ud83d\udccc From the above pie chart, we can see that we have relatively more people who have more chances of having a Heart Attack. <br>\n\ud83d\udccc We can also see that the our dataset is balanced.","a2d8e701":"## **Distribution Plot** <a id='3.4' ><\/a>","3496d30c":"### Detection <a id='3.6.1' ><\/a>","a17f514c":"\ud83d\udccc *Like MultinomialNB, this classifier is suitable for discrete data. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary\/boolean features.*","a8347a26":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='4'><\/a>\n    \n    Data Preprocessing\n<\/div>","2a4b2e12":"\ud83d\udccc *The k-nearest neighbors (KNN) algorithm is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems*","33fe9acc":"## **BernoulliNB** <a id='5.7' ><\/a>","1f295c38":"## **Pair Plot** <a id='3.7' ><\/a>","0f0d0002":"\ud83d\udccc *Logistic Regression assumes a Gaussian distribution for the numeric input variables and can model binary classification problems. You can construct a logistic regression model using the LogisticRegression class.*","957ca5cc":"\ud83d\udccc There are no missing values present in our dataset.","a5d03e18":"## **Passive Aggressive Classifier** <a id='5.2' ><\/a>","e034bac1":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='3'><\/a>\n    \n    Exploratory Data Analysis\n<\/div>","b9095308":"\ud83d\udccc *Classifier using Ridge regression. This classifier first converts the target values into {-1, 1} and then treats the problem as a regression task (multi-output regression in the multiclass case).*","e413dd5e":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='5'><\/a>\n    \n    Models\n<\/div>","45c138f0":"## **Pie Chart** <a id='3.2' ><\/a>","f7b5cc63":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='1'><\/a>\n    \n    Importing Libraries \n<\/div>","b37312de":"## **XGBoost** <a id='5.17' ><\/a>","6232bd6c":"\ud83d\udccc *A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.*","5d839bb2":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '2'><\/a>\n    \n    Importing Dataset \n<\/div>"}}