{"cell_type":{"db9849f1":"code","6a945904":"code","504e17a5":"code","d5debceb":"code","f51083ac":"code","eeb11770":"code","82fcf909":"code","25b5f0b0":"code","9afc41b9":"code","c687d8d4":"code","a2fcce95":"code","a0903493":"code","03d034d4":"code","4b506dff":"code","5ae5d550":"code","6a21fd8b":"code","e82e8fce":"code","bb51b512":"code","7ac6e4c3":"code","ca809f04":"code","c217c6a2":"code","e607cb1d":"code","c2159e84":"code","b7b62553":"code","45097356":"code","a35edd75":"code","46a4e323":"code","f6e065f9":"code","a9396def":"markdown","ba5e8aeb":"markdown","da88df08":"markdown","bdef090e":"markdown","ca49ca2a":"markdown","df3f5473":"markdown","bbaefdd4":"markdown","e4432880":"markdown","3bfd87f7":"markdown","d6f09a0d":"markdown","3e8d1894":"markdown","fddd7ff3":"markdown","1b3735f0":"markdown","469eb79c":"markdown","9131ace7":"markdown","b243d897":"markdown","cc6c5a41":"markdown","de513df2":"markdown","4e6be365":"markdown","abbe6604":"markdown","9325b714":"markdown","6fe1da05":"markdown","f97e86a8":"markdown"},"source":{"db9849f1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime as DT\npd.set_option(\"max_rows\", None)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nhome_matches = pd.read_csv(\"\/kaggle\/input\/6-nations-rugby-files\/HomeData.csv\")\nrating = pd.read_csv(\"\/kaggle\/input\/6-nations-rugby-files\/RugbyStats.csv\")\ntarget = pd.read_csv(\"\/kaggle\/input\/targets\/target.csv\")\nhome_matches_with_weather = pd.read_csv(\"\/kaggle\/input\/6-nations-rugby-files\/home_matches_with_weather.csv\")\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6a945904":"home_matches.head()","504e17a5":"home_matches.head()","d5debceb":"rating.head()","f51083ac":"year = []\nopponnents = []\n\nfor index, row in home_matches.iterrows():\n    date = row[\"Match Date\"]\n    year.append(date[-4:])\n\nfor index, row in home_matches.iterrows():\n    opp = row[\"Opposition\"]\n    opponnents.append(opp[2:])\n\nhome_matches[\"year\"] = year\nhome_matches[\"opponnents\"] = opponnents\n","eeb11770":"home_matches.head()","82fcf909":"\nstanding_home = []\nstanding_away = []\n\n# function so given a team and a year I can locate the standing in the standing dataframe and return it. \n\ndef get_standing(team, year):\n#     The numbers I assign here corelate the team to the index in the standing data frame. \n    number = 0\n    if team == \"England\":\n        number = 0\n    elif team == \"Ireland\":\n        number = 1\n    elif team == \"Wales\":\n        number = 2\n    elif team == \"France\":\n        number = 3\n    elif team == \"Scotland\":\n        number = 4\n    else:\n        number = 5\n#     by passing the the year I can now locate in the table rating for a team and year and return the value\n    standing = rating.at[number, year]\n    return standing\n\n# I run this function obver all the rows in the matches data frame\nfor index, row in home_matches.iterrows():\n    standing_home.append(get_standing(row[\"Team\"], row[\"year\"]))\n    standing_away.append(get_standing(row[\"opponnents\"], row[\"year\"]))\n\n#     add the data to the home_matches dataframe\nhome_matches[\"home_standing\"] = standing_home\nhome_matches[\"away_standing\"] = standing_away\n","25b5f0b0":"home_matches.head(20)","9afc41b9":"home_matches['Match Date'] = home_matches['Match Date'].astype('datetime64[ns]')","c687d8d4":"home_matches.head()","a2fcce95":"# import requests \n# import json\n\n# API_KEY = 'insert API key here'\n# url = 'http:\/\/api.worldweatheronline.com\/premium\/v1\/past-weather.ashx'\n\n\n\n# def get_weather(df):\n#     if df['Team'] == 'England':\n#         city = 'London, United+Kingdom'\n#     elif df['Team'] == 'France':\n#         city = 'Paris, France'\n#     elif df['Team'] == 'Italy':\n#         city = 'Rome'\n#     elif df['Team'] == 'Ireland':\n#         city = 'Dublin, Ireland'\n#     elif df['Team'] == 'Wales':\n#         city = 'Cardiff, United+Kingdom'\n#     elif df['Team'] == 'Scotland':\n#         city = 'Edinburgh, United+Kingdom'\n#     else:\n#         df['Team'] = 'error'\n\n#     params = dict(key=API_KEY, q = city, format = 'json', date = '2010-02-14', tp = '12')\n\n#     res = requests.get(url, params = params)\n#     r=res.json()\n#     res.json()\n    \n    \n#     df['temp'] = r['data']['weather'][0]['hourly'][1]['FeelsLikeC']\n#     df['pressure'] = r['data']['weather'][0]['hourly'][1]['pressure']\n#     df['wind'] = r['data']['weather'][0]['hourly'][1]['WindGustKmph']\n    \n#     return df\n\n# home_matches_with_weather = home_matches.apply(get_weather, axis = 1)\n\n","a0903493":"# home_matches_with_weather.to_csv('home_matches_with_weather.csv',index=False)","03d034d4":"home_matches[\"home_prev\"] = \"\"\nhome_matches[\"away_prev\"] = \"\"\ngame_played = False\nsecond_cylce = True\n\nfor row in home_matches.itertuples():\n    if second_cylce == True:\n        if game_played == False:\n            home_matches.loc[row.Index-1,'home_prev'] = 'free'\n            home_matches.loc[row.Index-1,'away_prev'] = 'free'       \n       \n        if game_played == True:\n            home_matches.loc[row.Index-1,'home_prev'] = home_prev\n            home_matches.loc[row.Index-1,'away_prev'] = away_prev\n    \n    second_cylce = True\n    game_played = False\n    match_day = row[5] - DT.timedelta(days=1)\n    week_ago = match_day - DT.timedelta(days=9)\n\n    home_team = row[1]\n    away_team = row[7]\n  \n    home_prev = \"\"\n    away_prev = \"\"\n    \n    for row in home_matches.itertuples():\n        if week_ago <= row[5] <= match_day and row[1] == home_team:\n            home_prev = row[7]\n            game_played = True\n\n        elif week_ago <= row[5] <= match_day and row[7] == home_team:\n            home_prev = row[1]\n            game_played = True\n\n        if week_ago <= row[5] <= match_day and row[7] == away_team:\n            away_prev = row[1]\n            game_played = True\n\n        elif week_ago <= row[5] <= match_day and row[1] == away_team:\n            away_prev = row[7]\n            game_played = True\n    \n  \n   \n        ","4b506dff":"home_matches = home_matches.groupby('year').filter(lambda g: any(g[\"year\"] != \"2020\")).sort_values(by=\"Match Date\")\nhome_matches.head(16)","5ae5d550":"# Function takes dataframe and year as inputs\n\ndef create_trainig_test_data(year, matches):\n    # Group dataframe by input year and assign selected year to test data. All other years will be used as training data.\n    year = str(year)\n    train_full = matches.groupby('year').filter(lambda g: any(g[\"year\"] != year)).copy()\n    test_full = matches.groupby('year').filter(lambda g: any(g[\"year\"] == year)).copy()\n\n    # Drop columns that are no longer required\n\n    train_full = train_full.drop(columns=[\"Opposition\", \"Ground\", \"Match Date\", \"year\",], axis = 1)\n    test_full = test_full.drop(columns=[\"Opposition\", \"Ground\", \"Match Date\", \"year\",], axis = 1)\n    \n    # Split into features and target\n\n    X_train = train_full.drop(columns=\"Diff\", axis=1)\n    y_train = train_full.Diff\n    \n    X_test = test_full.drop(columns=\"Diff\", axis=1)\n    y_test = test_full.Diff\n   \n    # Create global variable dor cat and num cols for the pipeline later on \n    \n    global categorical_cols\n    global numerical_cols\n    \n    \n#     # Define cat and num cals for the columnn transformer in pipeline later  \n    \n    categorical_cols = [col_name for col_name in X_train.columns if\n                    X_train[col_name].dtype == \"object\"]\n\n\n    numerical_cols = [col_name for col_name in X_train.columns if \n                    X_train[col_name].dtype in ['int64', 'float64']]\n\n\n    # return the train and test dfs    \n    return X_train, y_train, X_test, y_test\n\n \n","6a21fd8b":"hello = create_trainig_test_data('2004', home_matches)\nhello[2].head()","e82e8fce":"target.head()","bb51b512":"target.columns = ['Team', 'opponnents', 'home_standing', 'away_standing', 'home_prev', 'away_prev']","7ac6e4c3":"target.head()","ca809f04":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n\n# Function will take the model as an input and return the pipline\n\ndef create_pipeline(model):\n    numerical_transformer = StandardScaler()\n    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, numerical_cols),\n            ('cat', categorical_transformer, categorical_cols)\n        ])\n\n\n    pipe_line = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)\n                         ])\n    return pipe_line","c217c6a2":"# Create a list with all the years\n\nx = range(2004, 2020)","e607cb1d":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\n\n# create regression model \nmodel = LinearRegression()\n\n# Create empty dictionary to store MAE error and year \nyear_results_regession = {}\n\n# for year in years:\n\nfor n in x:\n    # Create data set for each year \n    X_train, y_train, X_test, y_test = create_trainig_test_data(n, home_matches)\n    # Create pipeline with model\n    clf = create_pipeline(model)\n    # Fit the data to the model     \n    clf.fit(X_train, y_train)\n    # Predict using the model     \n    preds = clf.predict(X_test)\n    # Add to the dictionary the results for that year     \n    mae = mean_absolute_error(y_test, preds)\n    year_results_regession[n] = mae\n\n\n# Print out dictionary showing MAE for each year\nprint(year_results_regession)\n# Print out average of all errors\nprint(sum(year_results_regession.values())\/float(len(year_results_regession)))","c2159e84":"from sklearn import linear_model\n\n# create regression lasso model\nmodel = linear_model.Lasso(alpha=1.5)\n\n\n# Create empty dictionary to store MAE error and year \nyear_results_lasso = {}\n\n# for year in years:\n\nfor n in x:\n    # Create data set for each year \n    X_train, y_train, X_test, y_test = create_trainig_test_data(n, home_matches)\n    # Create pipeline with model\n    clf = create_pipeline(model)\n    # Fit the data to the model     \n    clf.fit(X_train, y_train)\n    # Predict using the model     \n    preds = clf.predict(X_test)\n    # Add to the dictionary the results for that year     \n    mae = mean_absolute_error(y_test, preds)\n    year_results_lasso[n] = mae\n\n\n\nprint(year_results_lasso)\n\nprint(sum(year_results_lasso.values())\/float(len(year_results_lasso)))","b7b62553":"from sklearn.ensemble import RandomForestRegressor\n\n# create regression lasso model\nmodel = RandomForestRegressor(max_depth=3)\n\n\n# Create empty dictionary to store MAE error and year \nyear_results_forrest_regressor = {}\n\n# for year in years:\n\nfor n in x:\n    # Create data set for each year \n    X_train, y_train, X_test, y_test = create_trainig_test_data(n, home_matches)\n   \n    # Create pipeline with model\n    clf = create_pipeline(model)\n   \n    # Fit the data to the model     \n    clf.fit(X_train, y_train)\n   \n    # Predict using the model     \n    preds = clf.predict(X_test)\n    \n    # Add to the dictionary the results for that year     \n    mae = mean_absolute_error(y_test, preds)\n    year_results_forrest_regressor[n] = mae\n\n\n\nprint(year_results_forrest_regressor)\n\nprint(sum(year_results_forrest_regressor.values())\/float(len(year_results_forrest_regressor)))","45097356":"predicted = clf.predict(target)\ntarget['Predicted Result'] = predicted\ntarget['Actual'] = ['-40', '-5', '5', '23', '-1', '-2', '-38', '16', 'TBD', 'TBD', 'TBD', 'TBD', 'TBD', 'TBD', 'TBD']\ntarget.head(15)","a35edd75":"from sklearn import svm\n\n\n# create Suport Vector Model\nmodel = svm.SVC()\n\n# Create empty dictionary to store MAE error and year \nyear_results_support_vector = {}\n\n# for year in years:\n\nfor n in x:\n    # Create data set for each year \n    X_train, y_train, X_test, y_test = create_trainig_test_data(n, home_matches)\n   \n    # Create pipeline with model\n    clf = create_pipeline(model)\n   \n    # Fit the data to the model     \n    clf.fit(X_train, y_train)\n   \n    # Predict using the model     \n    preds = clf.predict(X_test)\n    \n    # Add to the dictionary the results for that year     \n    mae = mean_absolute_error(y_test, preds)\n    year_results_support_vector[n] = mae\n\n\n\nprint(year_results_support_vector)\nprint(sum(year_results_support_vector.values())\/float(len(year_results_support_vector)))","46a4e323":"X_results = X_test.copy()","f6e065f9":"from sklearn.model_selection import GridSearchCV\nimport xgboost as xgb\n\n# create regression lasso model\nmodel = xgb.XGBRegressor(learning_rate=0.05, colsample_bytree=0.3,  min_child_weight=7, gamma=20 )\n\n# Create empty dictionary to store MAE error and year \nyear_results_xgBoost = {}\n\n# for year in years:\n\nfor n in x:\n    # Create data set for each year \n    X_train, y_train, X_test, y_test = create_trainig_test_data(n, home_matches)\n   \n    # Create pipeline with model\n    clf = create_pipeline(model)\n    \n    # Fit the data to the model     \n    clf.fit(X_train, y_train)\n   \n    # Predict using the model     \n    preds = clf.predict(X_test)\n    \n    # Add to the dictionary the results for that year     \n    mae = mean_absolute_error(y_test, preds)\n    year_results_xgBoost[n] = mae\n\n\n\nprint(year_results_xgBoost)\n\nprint(sum(year_results_xgBoost.values())\/float(len(year_results_xgBoost)))\n","a9396def":"\n\n# Background \n\nFor those who are interested but don't know much about the 6 nations... \n\nThe 6 nations is an annual rugby union tournament held in February and March. It consists of 6 teams: England, Wales, Ireland, Scotland, France and Italy. All teams play each other once - 3 at home and 2 away alternating each year. If you win all five games its called the Grand Slam and if you lose all 5 then you win the dreaded wooden spoon. You don't get a wooden spoon - but it's a term that started years ago in Cambridge apparently that just meant you were the loser. \n\nIt is worth mentioning that it was the 5 nations until Italy joined in 2000. Since joining however, Italy have not fared quite as well and have been one of the weakest teams. Of the other nations, most have had periods of success but in the last 20 years (my data set runs from 2003) Scotland ranks second in terms of weaker performances while France have tended to be fairly inconsistent. Wales have enjoyed the most successes, winning the most grand slams in this period with Ireland and England enjoying spells of success too. I'm English and I\u2019m sure some people will strongly disagree with what I have just said so I look forward to the comments\u2026\u2026\n\nApart from Italy and possibly Scotland, home advantage is huge in the 6 nations. Later in the data worksheet you can see this clearly as in some years the model only predicts Scotland and Italy home losses.\n","ba5e8aeb":"So, this is the first notebook I have done and given that I am not a data scientist, there is probably going to be a tonne of mistakes. Even so, as a rugby fan I thought it would be interesting to try and predict the score of the upcoming 6 nations tournament using a few of the things I have learnt on here. ","da88df08":"# Check by getting them in data order and looking over...","bdef090e":"# Create Pipeline\n\nThis pipeline takes the numerical data and performs a simple scaler to it. There is no need to impute values as I know there are no missing values. \n\nOne hot encoder is used to deal with the categorical data to avoid any clustering from using label encoding.  ","ca49ca2a":"Below creates two new columns for the home standing and away standing. ","df3f5473":"Below is a my (convoluted?)  way of getting a columns for year only and opposition without the 'v'","bbaefdd4":"# **The Data**\n\nThe data was taken from ESPN and World Rugby websites. \n\nI planned to try and predict the game results using the following data:\n1. The teams ranking points as ranked by world rugby at the begining of the tournament \n2. Home advantage (using the non - US system of putting the home team first)\n3. Historic results in the tournament \n4. Previous matchups in the tournament \n\nI have included three data sheets but in actuality I only used two. \n\nThe Matches data sheet contains all matches played from 2004 onwards but that contains duplication as it contains all the games England played in 2004 and then all the games France played and so on. So it will contain 2 entries for the time England played France. The home matches has stripped that out. I did it in numbers rather than pandas as its just a lot quicker at the moment with my limited skills. \n\nStanding contains the year and the ranking points for the team at the start of the tournament. This was only started in 2003 after the 6 nations so 2004 is the first tournament we look at. \n\nTarget contains all the matches that will happen in 2021's tournament\n\nHome_matches_with_weather contains the matches with the air pressure, wind gust speed and 'feels like' temperature' for the game. The code I used withe the API to create this data set is included below. ","e4432880":"# First model will use simple regression \n\n\nAll models follow the same pattern for creating the model and then a train\/test data set for each year. The Absolute Mean Error was then calculated for each data set and then averaged out.  ","3bfd87f7":"# **6 Nations Predictor **","d6f09a0d":"# Random Forrest Rgression","3e8d1894":" Check !","fddd7ff3":"# XGBoost with Gridsearch","1b3735f0":"# Adding Weather data\n\nThe idea behind this was to see if the weather had a big impact on the game result. A little bit of rugby knowledge is needed here but I was particularly interested to see if rain was more advantageous to teams that traditionally have relied on their forwards such as England and disadvantageous to teams that have relied on their backs like Wales. I had the API collect data for average precipitation in mm but it returned all data as zeros for each game and I know this is false. I then checked for a strung of days in Scotland again returning zeros so there must be an error in the data set maybe? I then decided to use temp, windspeed (affects accuracy of trajectory?) And pressure as an indicator of rain. ","469eb79c":"# Function that creates train\/test data sets based on input of year \n\nAlso removes columns that are not needed for training data\n\nI did this so I could train the model on all years apart from one and then test the remaining year. I could then compare the absolute mean error of the model for that year against predictions I have made in the past, to see if I (thinking I know best with my knowlegde of rugby and with a massive English bias) was better than the model. Worth mentioning - I have never predicted anything less than an English Grand Slam, and given that they have won 2 in the last 20 years, you can tell I am really good at this. ","9131ace7":"I then work this out - this took me a long time to code and I am sure there is a better way!","b243d897":"# Previously Played\n\n\nThe 6 nations is played:\n* Consecutively over two weekends. \n* Rest Week \n* One weekend\n* Rest week\n* Consecutively over two weekends \n\nIt is a tough game and injuries are common so consider the scenario: \n\nEngland play Wales the second weekend of the consecutive cycle. The previous week Wales played Ireland and England played Italy. It is most likely both will have injuries but England would have likely rested a few key players as they have never lost to Italy. Wales will have played their full strength team and I would suspect will be worse off because of it. I therefore would like the model to know the previous playing history of the teams. For this I turn match date into a dtype date \/ time ","cc6c5a41":"# Week 2\n\nWeek two and another 2 away wins which the model failed to predict. The French win in Dublin was the first time they have won there in 11 years - I\u2019m thinking that the Covid effect and lack spectators is having a large effect on the tournament that the model is failing to account for. I am working on another predictor for Basball and Im wondering now whether I dont include the 2020 season results as the lack of spectators in that season may bias the results....\n\n\nI initially thought the model had massively under predicted the England Italy result but in the end it was pretty much on the money. \n\nFor most of the Scotland Wales game I was pretty confident that my one pound accumulator based on the model was going to be a winner. So much so that at one point I had the option of cashing out for 26p profit :) But then disaster struck midway through the second half as Scotland led by 5 (the exact number the model predicted) a Scottish player was sent off for dangerous play. Despite this Scotland were hanging on for the win but a last minute penalty to Wales meant they won 25 - 24. \n\nThe last game of the weekend saw the French ending the winning drought in Dublin with a 13 - 15 win. At the very end Ireland were in possession of the ball and a converted try would have made the result 1 point away from the predicted result. However, it wasn\u2019t to be and I ended the weekend's three games with just one accurate prediction\u2026\n\n# Week 3 \n\nUnfortunately the France Scotland game was cancelled due to a Covid outbreak in the French camp. Hopefully it wiil be rescheduled soon as its looking like a France\/Wales shoot out for the Grand Slam and it would be nice for that to be the last game (as it is scheduled) rather than waitng on the impacted game to be played.\n\nAs for the other results, all correct but the margin was out by more than 10. Two tries that even the Welsh pundits on the BBC said should be dissallowed (so not just the bias of an English supporter and AI model creater!) meant the margin was 16 rather than the predicted 4. Cant help but think remove the 14 points then i would have been pretty much on point. Or maybe I should stop making excuses for the model.....\n\n\n","de513df2":"# Lasso Regession","4e6be365":"# Make sure the target is same format ","abbe6604":"# Actual results vs Predicted Week 1\n\n\nI decided to use random forrest for week one as it performed the best and I have not had time to properly optimise the XGBoost model. \n\nSo looking at the results, the glaring mistake is Scotland beating England which the model had as an England win with a largish margin of 10 points (for the 6 nations and a resurgent Scotland). The model also failed to predict the larger margin of the France win over Italy \n\nThe Covid Effect \n\nIt\u2019s easy to see why the model failed to predict Scotland\u2019s win against England. They haven\u2019t won at Twickenham (England\u2019s Stadium) since the early 80s and there was nothing in the standings that would have indicated this was about to change. Was the win therefore down to there being a lack of home crowd to roar England to victory or was the win down to Scotland\u2019s talisman Finn Russell leading them on to the win? That\u2019s probably a debate, we won\u2019t get to the bottom off. I do think though that the lack of crowd will have affected the game and the model won\u2019t have accounted for it. By how much, I am unsure.  \n\nFrance too may have been effected by Covid in the standings.They narrowly lost their last game of 2020 to England when they effectively fielded a 3rd string side. Had they not done this their standing would have been higher (England were ranked 2 in the world at that point) and the model may have predicted a bigger margin. \n\nThe Ireland vs Wales game was a good prediction. It was looking like an easy Ireland win which would have resulted in 3 away wins in the opening weekend of the 6 nations - the first time that would ever have happened. But then Ireland had a player sent off and in Rugby the sending off of a player usually dooms the penalised side to defeat, as it is such a major disadvantage to be playing with 1 less man. On average you concede 7 points for every 10 minutes that one of your players is off the field. ","9325b714":"Fairly self explanatory but \n\nTeam - Home Team\n\nDiff - target variable and is the match result. Positive means home win and negative is loss and in favour of the away team\n\nOpposition - away team\n\nGround - stadium games were played at\n\nMatch Date - match date. In 2020 some games were played in later months due to Covid-19","6fe1da05":"Member Union - Team \n\nTier - world rugby is divided into tiers. Italy were in a lower tier and moved into the top tier in 2000. The gulf between the two tiers is large and explains why Italy still struggle today but are probably too good to go down. \n\nYear - the ranking is based on games played throughout the year. England's and to a lesser extent France's general higher ranking reflects their better performance in World Cups (except the one held in England!) and against Southern Hemisphere nations in the autumn internationals. However, that does not always translate into success in the 6 nations","f97e86a8":"# Check!"}}