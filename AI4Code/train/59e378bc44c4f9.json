{"cell_type":{"e2c8b9f8":"code","e0c4bd64":"code","949459ec":"code","96b8c64e":"code","7ead302c":"code","d268ae1a":"code","33523d57":"code","353d5a10":"code","ff608325":"code","e7b1b305":"code","0fb92a81":"code","09bc29fc":"code","c6dcce1c":"code","62d581bd":"code","da65a234":"code","a8ef5f4e":"code","4830d8c9":"code","db087ecc":"code","92af7f3d":"code","752316b5":"code","99e165ec":"code","03246d1c":"code","43229477":"code","600705a5":"markdown","5296bb0f":"markdown","33a6022a":"markdown","659a3e57":"markdown","9648517a":"markdown"},"source":{"e2c8b9f8":"# Let's read in our document-term matrix\nimport pandas as pd\nimport pickle\n\ndata = pd.read_pickle('dtm_stop.pkl')\ndata","e0c4bd64":"# Import the necessary modules for LDA with gensim\n# Terminal \/ Anaconda Navigator: conda install -c conda-forge gensim\nfrom gensim import matutils, models\nimport scipy.sparse\n\n# import logging\n# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)","949459ec":"# One of the required inputs is a term-document matrix\ntdm = data.transpose()\ntdm.head()","96b8c64e":"# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\nsparse_counts = scipy.sparse.csr_matrix(tdm)\ncorpus = matutils.Sparse2Corpus(sparse_counts)","7ead302c":"# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\ncv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\nid2word = dict((v, k) for k, v in cv.vocabulary_.items())\n","d268ae1a":"# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n# we need to specify two other parameters as well - the number of topics and the number of passes\nlda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\nlda.print_topics()","33523d57":"# LDA for num_topics = 3\nlda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\nlda.print_topics()","353d5a10":"# LDA for num_topics = 4\nlda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\nlda.print_topics()","ff608325":"# Let's create a function to pull out nouns from a string of text\nimport nltk\nfrom nltk import pos_tag\nfrom nltk import word_tokenize\n\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\n\ndef nouns(text):\n    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n    is_noun = lambda pos: pos[:2] == 'NN'\n    tokenized = word_tokenize(text)\n    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n    return ' '.join(all_nouns)","e7b1b305":"# Read in the cleaned data, before the CountVectorizer step\ndata_clean = pd.read_pickle('data_clean.pkl')\ndata_clean","0fb92a81":"# Apply the nouns function to the speeches to filter only on nouns\ndata_nouns = pd.DataFrame(data_clean.speeches.apply(nouns))\ndata_nouns","09bc29fc":"# Create a new document-term matrix using only nouns\nfrom sklearn.feature_extraction import text\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Re-add the additional stop words since we are recreating the document-term matrix\nadd_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said', 'world','america']\nstop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n\n# Recreate a document-term matrix with only nouns\ncvn = CountVectorizer(stop_words=stop_words)\ndata_cvn = cvn.fit_transform(data_nouns.speeches)\ndata_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\ndata_dtmn.index = data_nouns.index\ndata_dtmn","c6dcce1c":"# Create the gensim corpus\ncorpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n\n# Create the vocabulary dictionary\nid2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())","62d581bd":"# Let's start with 2 topics\nldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\nldan.print_topics()","da65a234":"# Let's create a function to pull out nouns from a string of text\ndef nouns_adj(text):\n    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n    tokenized = word_tokenize(text)\n    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n    return ' '.join(nouns_adj)","a8ef5f4e":"# Apply the nouns function to the transcripts to filter only on nouns\ndata_nouns_adj = pd.DataFrame(data_clean.speeches.apply(nouns_adj))\ndata_nouns_adj","4830d8c9":"# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\ncvna = CountVectorizer(stop_words=stop_words, max_df=.8)\ndata_cvna = cvna.fit_transform(data_nouns_adj.speeches)\ndata_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())\ndata_dtmna.index = data_nouns_adj.index\ndata_dtmna","db087ecc":"# Create the gensim corpus\ncorpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n\n# Create the vocabulary dictionary\nid2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())","92af7f3d":"\n# Let's start with 2 topics\nldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\nldana.print_topics()","752316b5":"\n# Let's start with 3 topics\nldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\nldana.print_topics()","99e165ec":"# Let's try 4 topics\nldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\nldana.print_topics()","03246d1c":"# Our final LDA model (for now)\nldana = models.LdaModel(corpus=corpusna, num_topics=5, id2word=id2wordna, passes=90)\nldana.print_topics()","43229477":"# Let's take a look at which topics each speech contains\n# corpus_transformed = ldana[corpusna]\n# list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))","600705a5":"- Topic 0: America's Security\n- Topic 1: Woman's Rights\n- Topic 2: Supreme Court\/ Justice sytem\n- Topic 3: Terrorism\n- Topic 4: Religion and Faith","5296bb0f":"## Identify Topics in Each Document\n","33a6022a":"## Topic Modeling","659a3e57":"## Topic Modeling - Attempt #2 (Nouns Only)","9648517a":"## Topic Modeling - Attempt #3 (Nouns and Adjectives)\n"}}