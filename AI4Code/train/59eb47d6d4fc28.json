{"cell_type":{"5dd53982":"code","4b405e72":"code","ce7a1a77":"code","9c09b9a4":"code","d6c460ae":"code","5da6f69c":"code","174d6a84":"code","49b29273":"code","aadfec5e":"code","65d0cc95":"markdown","e7b5337d":"markdown","d461394c":"markdown"},"source":{"5dd53982":"import ast\nimport os, cv2\nfrom skimage import io\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport numpy as np","4b405e72":"train = pd.read_csv('\/kaggle\/input\/global-wheat-detection\/train.csv')\ntrain['image_id'] = train['image_id']+'.jpg'\ntrain['bbox_'] = [ast.literal_eval(i) for i in train['bbox'].values.tolist()]\ntrain = train.groupby('image_id')['bbox'].apply(list).reset_index(name='bbox')","ce7a1a77":"train.head(3)","9c09b9a4":"all_images=[]\nfor i in range(0,train.shape[0]):\n    obj_l = []\n    for z in train['bbox'][i]:\n        z = ast.literal_eval(z)\n        xym = {}\n        xym['name'] = 'wheat'\n        xym['xmin'] = z[0]\n        xym['ymin'] = z[1]\n        xym['xmax'] = z[2]+z[0]\n        xym['ymax'] = z[3]+z[1]\n        obj_l.append(xym)\n    \n    dicting = {}\n    dicting['object'] = obj_l\n    dicting['filename'] = '\/kaggle\/input\/global-wheat-detection\/train\/'+train['image_id'][i]\n    dicting['width'] = 1024\n    dicting['height'] = 1024\n    all_images.append(dicting)","d6c460ae":"all_images[0]","5da6f69c":"\nfor i in all_images[:3]:\n    path = i['filename']\n    img = io.imread(path, plugin='matplotlib')\n    for z in i['object']:\n        cv2.rectangle(img, (int(z['xmin']), int(z['ymin'])), (int(z['xmax']), int(z['ymax'])), (0,255,255), 2)\n    plt.figure(figsize=(15,10))\n    plt.title('Image')\n    plt.imshow(img)\n    plt.show()\n    ","174d6a84":"LABELS = ['wheat']\n\nIMAGE_H, IMAGE_W = 416, 416\nGRID_H,  GRID_W  = 13 , 13\nBOX              = 10\nCLASS            = len(LABELS)\nCLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\nOBJ_THRESHOLD    = 0.3\nNMS_THRESHOLD    = 0.3\n\nNO_OBJECT_SCALE  = 1.0\nOBJECT_SCALE     = 5.0\nCOORD_SCALE      = 1.0\nCLASS_SCALE      = 1.0\nBATCH_SIZE       = 16\nWARM_UP_BATCHES  = 100\nTRUE_BOX_BUFFER  = 50","49b29273":"def IOU(ann, centroids):\n    w, h = ann\n    similarities = []\n\n    for centroid in centroids:\n        c_w, c_h = centroid\n\n        if c_w >= w and c_h >= h:\n            similarity = w*h\/(c_w*c_h)\n        elif c_w >= w and c_h <= h:\n            similarity = w*c_h\/(w*h + (c_w-w)*c_h)\n        elif c_w <= w and c_h >= h:\n            similarity = c_w*h\/(w*h + c_w*(c_h-h))\n        else: #means both w,h are bigger than c_w and c_h respectively\n            similarity = (c_w*c_h)\/(w*h)\n        similarities.append(similarity) # will become (k,) shape\n\n    return np.array(similarities)\n\ndef avg_IOU(anns, centroids):\n    n,d = anns.shape\n    sum = 0.\n\n    for i in range(anns.shape[0]):\n        sum+= max(IOU(anns[i], centroids))\n\n    return sum\/n\n\n\ndef print_anchors(centroids):\n    anchors = centroids.copy()\n\n    widths = anchors[:, 0]\n    sorted_indices = np.argsort(widths)\n\n    r = \"anchors: [\"\n    for i in sorted_indices[:-1]:\n        r += '%0.2f,%0.2f, ' % (anchors[i,0], anchors[i,1])\n\n    #there should not be comma after last anchor, that's why\n    r += '%0.2f,%0.2f' % (anchors[sorted_indices[-1:],0], anchors[sorted_indices[-1:],1])\n    r += \"]\"\n\n    print(r)\n\ndef run_kmeans(ann_dims, anchor_num):\n    ann_num = ann_dims.shape[0]\n    iterations = 0\n    prev_assignments = np.ones(ann_num)*(-1)\n    iteration = 0\n    old_distances = np.zeros((ann_num, anchor_num))\n\n    indices = [random.randrange(ann_dims.shape[0]) for i in range(anchor_num)]\n    centroids = ann_dims[indices]\n    anchor_dim = ann_dims.shape[1]\n\n    while True:\n        distances = []\n        iteration += 1\n        for i in range(ann_num):\n            d = 1 - IOU(ann_dims[i], centroids)\n            distances.append(d)\n        distances = np.array(distances) # distances.shape = (ann_num, anchor_num)\n\n        print(\"iteration {}: dists = {}\".format(iteration, np.sum(np.abs(old_distances-distances))))\n\n        #assign samples to centroids\n        assignments = np.argmin(distances,axis=1)\n\n        if (assignments == prev_assignments).all() :\n            return centroids\n\n        #calculate new centroids\n        centroid_sums=np.zeros((anchor_num, anchor_dim), np.float)\n        for i in range(ann_num):\n            centroid_sums[assignments[i]]+=ann_dims[i]\n        for j in range(anchor_num):\n            centroids[j] = centroid_sums[j]\/(np.sum(assignments==j) + 1e-6)\n\n        prev_assignments = assignments.copy()\n        old_distances = distances.copy()","aadfec5e":"import random\ngrid_w = IMAGE_W\/32\ngrid_h = IMAGE_H\/32\n\n# run k_mean to find the anchors\nannotation_dims = []\nfor image in all_images:\n    cell_w = image['width']\/grid_w\n    cell_h = image['height']\/grid_h\n\n    for obj in image['object']:\n        relative_w = (float(obj['xmax']) - float(obj['xmin']))\/cell_w\n        relatice_h = (float(obj[\"ymax\"]) - float(obj['ymin']))\/cell_h\n        annotation_dims.append(tuple(map(float, (relative_w,relatice_h))))\n        \nannotation_dims = np.array(annotation_dims)\nnum_anchors=5\ncentroids = run_kmeans(annotation_dims, num_anchors)\nprint('centroids',centroids)\n# write anchors to file\nprint('\\naverage IOU for', num_anchors, 'anchors:', '%0.2f' % avg_IOU(annotation_dims, centroids))\nprint_anchors(centroids)\n","65d0cc95":"![image.png](attachment:image.png)","e7b5337d":"Go through this https:\/\/www.kaggle.com\/ashoksrinivas\/data-augmentation-data-generation-yolovii?scriptVersionId=33702717 for Data Augumentation & Data Generation process (Next STEP)","d461394c":"# Go through this https:\/\/arxiv.org\/abs\/1612.08242 for understanding YOLO better"}}