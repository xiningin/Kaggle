{"cell_type":{"f9521895":"code","19c98201":"code","00166a3a":"code","441ae59c":"code","0ab05c0d":"code","fddfc2ef":"code","63748776":"code","3593e46a":"code","bbcd831c":"code","83bf7ca9":"code","21571db4":"markdown","53bf5f32":"markdown","8f5de621":"markdown","39b879c6":"markdown"},"source":{"f9521895":"import pandas as pd\nfrom lightgbm import LGBMClassifier\nimport category_encoders as ce\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline","19c98201":"train_df = pd.read_csv('\/kaggle\/input\/kalapas\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/kalapas\/test.csv')","00166a3a":"train_df.head()","441ae59c":"def feature_engineering(train, test):\n    labels = train['label']\n    data = train.drop(columns=['label']).append(test, ignore_index=True)\n    remove_features = ['Field_1', 'Field_2', 'Field_4', 'Field_5', 'Field_6', 'Field_7', 'Field_8', 'Field_9',\n                       'Field_11', 'Field_12', 'Field_15', 'Field_18', 'Field_25', 'Field_32', 'Field_33',\n                       'Field_34', 'Field_35', 'gioiTinh', 'diaChi', 'Field_36', 'Field_38', 'Field_40',\n                       'Field_43', 'Field_44', 'Field_45', 'Field_46', 'Field_47', 'Field_48', 'Field_49',\n                       'Field_54', 'Field_55', 'Field_56', 'Field_61', 'Field_62', 'Field_65', 'Field_66',\n                       'Field_68', 'maCv', 'info_social_sex', 'data.basic_info.locale', 'currentLocationCity',\n                       'currentLocationCountry', 'currentLocationName', 'currentLocationState', 'homeTownCity',\n                       'homeTownCountry', 'homeTownName', 'homeTownState', 'F_startDate', 'F_endDate',\n                       'E_startDate', 'E_endDate', 'C_startDate', 'C_endDate', 'G_startDate', 'G_endDate',\n                       'A_startDate', 'A_endDate', 'brief']\n\n    cat_features_count_encode = ['Field_4', 'Field_12', 'Field_18', 'Field_34', 'gioiTinh', 'diaChi', 'Field_36',\n                                 'Field_38', 'Field_45', 'Field_46', 'Field_47', 'Field_48', 'Field_49',\n                       'Field_54', 'Field_55', 'Field_56', 'Field_61', 'Field_62', 'Field_65', 'Field_66',\n                       'Field_68', 'maCv', 'info_social_sex', 'data.basic_info.locale', 'currentLocationCity',\n                       'currentLocationCountry', 'currentLocationName', 'currentLocationState', 'homeTownCity',\n                       'homeTownCountry', 'homeTownName', 'homeTownState', 'brief']\n    \n    cat_date_array = ['Field_1', 'Field_2', 'Field_5', 'Field_6', 'Field_7', 'Field_8', 'Field_9', 'Field_11',\n                      'Field_15', 'Field_25', 'Field_32', 'Field_33', 'Field_35', 'Field_40', 'Field_43',\n                      'Field_44', 'F_startDate', 'F_endDate', 'E_startDate', 'E_endDate', 'C_startDate',\n                      'C_endDate', 'G_startDate', 'G_endDate', 'A_startDate', 'A_endDate']\n    for col in cat_date_array:\n        data[col+'Year'] = pd.DatetimeIndex(data[col]).year\n        data[col+'Month'] = pd.DatetimeIndex(data[col]).month\n        data[col+'Day'] = pd.DatetimeIndex(data[col]).day\n    \n    data[remove_features].fillna(\"Missing\", inplace=True)\n    count_en = ce.CountEncoder()\n    cat_ce = count_en.fit_transform(data[cat_features_count_encode])\n    data = data.join(cat_ce.add_suffix(\"_ce\"))\n    \n    data.replace(\"None\", -1, inplace=True)\n    data.replace(\"Missing\", -999, inplace=True)\n    data.fillna(-999, inplace=True)\n\n    _train = data[data['id'] < 53030]\n    _test = data[data['id'] >= 53030]\n    \n    _train[\"label\"] = labels\n\n    _train.drop(columns=remove_features, inplace=True)\n    _test.drop(columns=remove_features, inplace=True)\n    \n    return _train, _test","0ab05c0d":"train_data, test_data = feature_engineering(train_df, test_df)","fddfc2ef":"def calculate_woe_iv(dataset, feature, target):\n    lst = []\n    for i in range(dataset[feature].nunique()):\n        val = list(dataset[feature].unique())[i]\n        lst.append({\n            'Value': val,\n            'All': dataset[dataset[feature] == val].count()[feature],\n            'Good': dataset[(dataset[feature] == val) & (dataset[target] == 0)].count()[feature],\n            'Bad': dataset[(dataset[feature] == val) & (dataset[target] == 1)].count()[feature]\n        })\n    dset = pd.DataFrame(lst)\n    dset['Distr_Good'] = dset['Good'] \/ dset['Good'].sum()\n    dset['Distr_Bad'] = dset['Bad'] \/ dset['Bad'].sum()\n    dset['WoE'] = np.log(dset['Distr_Good'] \/ dset['Distr_Bad'])\n    dset = dset.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n    dset['IV'] = (dset['Distr_Good'] - dset['Distr_Bad']) * dset['WoE']\n    iv = dset['IV'].sum()\n    dset = dset.sort_values(by='WoE')\n    return dset, iv\n\nUSELESS_PREDICTOR = []\nWEAK_PREDICTOR = []\nMEDIUM_PREDICTOR = []\nSTRONG_PREDICTOR = []\nGOOD_PREDICTOR = []\nIGNORE_FEATURE = USELESS_PREDICTOR + WEAK_PREDICTOR\nfor col in train_data.columns:\n    if col == 'label' or col == 'id': continue\n    elif col in IGNORE_FEATURE: continue\n    else:\n        print('WoE and IV for column: {}'.format(col))\n        final, iv = calculate_woe_iv(train_data, col, 'label')\n        iv = round(iv,2)\n        print('IV score: ' + str(iv))\n        print('\\n')\n        if (iv < 0.02) and col not in USELESS_PREDICTOR:\n            USELESS_PREDICTOR.append(col)\n        elif iv >= 0.02 and iv < 0.1 and col not in WEAK_PREDICTOR:\n            WEAK_PREDICTOR.append(col)\n        elif iv >= 0.1 and iv < 0.3 and col not in MEDIUM_PREDICTOR:\n            MEDIUM_PREDICTOR.append(col)\n        elif iv >= 0.3 and iv < 0.5 and col not in STRONG_PREDICTOR:\n            STRONG_PREDICTOR.append(col)\n        elif iv >= 0.5 and col not in GOOD_PREDICTOR:\n            GOOD_PREDICTOR.append(col)","63748776":"print('USELESS_PREDICTOR')\nprint(len(USELESS_PREDICTOR))\nprint('WEAK_PREDICTOR')\nprint(len(WEAK_PREDICTOR))\nprint('MEDIUM_PREDICTOR')\nprint(len(MEDIUM_PREDICTOR))\nprint('STRONG_PREDICTOR')\nprint(len(STRONG_PREDICTOR))\nprint('GOOD_PREDICTOR')\nprint(len(GOOD_PREDICTOR))","3593e46a":"IGNORE_FEATURE = USELESS_PREDICTOR\nfinal_train_data = train_data.drop(columns=IGNORE_FEATURE)\nfinal_test_data = test_data.drop(columns=[col for col in IGNORE_FEATURE if col not in ['label']])","bbcd831c":"import gc\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc, f1_score, confusion_matrix, recall_score, classification_report\nimport seaborn as sns\n\n\n# Display\/plot feature importance\ndef display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.savefig('lgbm_importances01.png')\n    \ndef display_roc_curve(y_, oof_preds_,sub_preds_,folds_idx_):\n    # Plot ROC curves\n    plt.figure(figsize=(6,6))\n    scores = [] \n    for n_fold, (_, val_idx) in enumerate(folds_idx_):  \n        # Plot the roc curve\n        fpr, tpr, thresholds = roc_curve(y_.iloc[val_idx], oof_preds_[val_idx])\n        score = 2 * auc(fpr, tpr) -1\n        scores.append(score)\n        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (Gini = %0.4f)' % (n_fold + 1, score))\n    \n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n    fpr, tpr, thresholds = roc_curve(y_, oof_preds_)\n    score = 2 * auc(fpr, tpr) -1\n    plt.plot(fpr, tpr, color='b',\n             label='Avg ROC (Gini = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n             lw=2, alpha=.8)\n    \n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('LightGBM ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.tight_layout()\n    plt.savefig('roc_curve.png')\n\n\n# LightGBM GBDT with Stratified KFold\ndef kfold_lightgbm(train_df, test_df, num_folds, stratified = False, debug= False):\n    # Divide in training\/validation and test data\n    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n    gc.collect()\n    # Cross validation model\n    folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=500)\n\n    # Create arrays and dataframes to store results\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n    feature_importance_df = pd.DataFrame()\n    feats = [f for f in train_df.columns if f not in ['label','id']]\n    \n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['label'])):        \n        train_x, train_y = train_df[feats].iloc[train_idx], train_df['label'].iloc[train_idx]\n        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['label'].iloc[valid_idx]\n\n        clf = LGBMClassifier(\n            nthread=4,\n            n_estimators=10000,\n            learning_rate=0.02,\n            num_leaves=128,\n            colsample_bytree=0.9497036,\n            subsample=0.8715623,\n            max_depth=8,\n            reg_alpha=0.041545473,\n            reg_lambda=0.0735294,\n            min_split_gain=0.0222415,\n            min_child_weight=39.3259775,\n            silent=-1,\n            verbose=-1\n        )\n\n        clf.fit(train_x, train_y.ravel(), eval_set=[(train_x, train_y), (valid_x, valid_y)], \n            eval_metric='auc', verbose= 1000, early_stopping_rounds= 200)\n\n        oof_pred = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n        \n        pred = clf.predict(valid_x, num_iteration=clf.best_iteration_)\n        print('F1 Score: ' + str( f1_score(valid_y, pred) ))\n        print('Recall Score: ' + str( recall_score(valid_y, pred) ))\n        \n        sub_pred = clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] \/ folds.n_splits\n        oof_preds[valid_idx] = oof_pred\n        sub_preds += sub_pred\n                \n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = clf.feature_importances_\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n        del clf, train_x, train_y, valid_x, valid_y\n        gc.collect()\n\n    print('Full AUC score %.6f' % roc_auc_score(train_df['label'], oof_preds))\n    \n    folds_idx = [(trn_idx, val_idx) for trn_idx, val_idx in folds.split(train_df[feats], train_df['label'])]\n    display_roc_curve(y_=train_df['label'],oof_preds_=oof_preds,sub_preds_ = sub_preds, folds_idx_=folds_idx)\n    \n    # Write submission file and plot feature importance\n    test_df['label'] = sub_preds\n    test_df[['id', 'label']].to_csv('submission.csv', index= False)\n    display_importances(feature_importance_df)","83bf7ca9":"kfold_lightgbm(final_train_data, final_test_data, 5)","21571db4":"## 3. Feature Selection","53bf5f32":"## 4. Build Model","8f5de621":"## 1. Load Data","39b879c6":"## 2. Feature Engineering"}}