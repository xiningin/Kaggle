{"cell_type":{"ef645130":"code","0efd7b3d":"code","7c444694":"code","8727110a":"code","239fde76":"code","4f16d1d8":"code","4e957d3c":"code","7654d15e":"code","b579c716":"code","b33fd4ed":"code","d026f409":"code","a0f4a987":"code","c9c9a9a0":"code","8b5963cd":"code","8652b868":"code","7200f92a":"code","48f35d49":"code","1edf665a":"code","9bc3b8d0":"code","149e70af":"code","40792239":"code","6686e9b1":"code","96c2b803":"code","8f7da890":"code","ed4bff9b":"code","97ce567b":"code","f30da327":"code","d0640fbc":"code","b6d2f342":"code","e9bc5485":"code","421436b5":"code","3eec7945":"code","f2ba7607":"code","50cf2722":"code","610c3cd1":"code","eec9e89f":"code","9f21e0ae":"code","f07a5411":"code","13655f7e":"code","b8d1ff67":"code","fbfeb5e1":"code","1ac6c1b6":"markdown","a887b9fd":"markdown","2d73b6aa":"markdown","70eaa2d5":"markdown","c0e27b4f":"markdown","1734d4ba":"markdown"},"source":{"ef645130":"import math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","0efd7b3d":"df = pd.read_csv('..\/input\/training\/training.csv')\ndf.dropna(inplace=True)\ndf.shape","7c444694":"df_test=pd.read_csv('..\/input\/test\/test.csv')\n","8727110a":"from joblib import Parallel, delayed\n\ndef format_img(x):\n    return np.asarray([int(e) for e in x.split(' ')], dtype=np.uint8).reshape(96,96)\n\nwith Parallel(n_jobs=10, verbose=1, prefer='threads') as ex:\n    x = ex(delayed(format_img)(e) for e in df.Image)\nwith Parallel(n_jobs=10, verbose=1, prefer='threads') as ex:\n    test = ex(delayed(format_img)(e) for e in df_test.Image)\ntest = np.stack(test)[..., None]\nx = np.stack(x)[..., None]\nx.shape, test.shape","239fde76":"plt.imshow(x[3,:,:,0])","4f16d1d8":"y = df.iloc[:, :-1].values\ny.shape","4e957d3c":"y[1,:]","7654d15e":"def show(x, y=None):\n    plt.imshow(x[..., 0], 'gray')\n    if y is not None:\n        points = np.vstack(np.split(y, 15)).T\n        plt.plot(points[0], points[1], 'o', color='red')\n        \n    plt.axis('off')\n\nsample_idx = np.random.choice(len(x))    \nshow(x[sample_idx], y[sample_idx])","b579c716":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\nx_train.shape, x_val.shape","b33fd4ed":"x[:,95,95,0]","d026f409":"# Normalizar las im\u00e1genes (1pt)\n# Se requiere que las im\u00e1genes est\u00e9n en el rango de [0,1], solo se dividir\u00e1 entre 255, la primera capa de la red ser\u00e1 un batchnormalizer y normalizar\u00e1\nx_train=(x_train\/255)\nx_val=(x_val\/255)\ntest=(test\/255)","a0f4a987":"#Como primera iteraci\u00f3n utilizaremos ResNet 50 con los entrenados con imagenes de imagenet\n#Se preprocesar\u00e1 de acuerdo al preprocesamiento de resnet \nfrom keras.applications.resnet50 import ResNet50, preprocess_input\n","c9c9a9a0":"test.shape","8b5963cd":"test=np.array([test[:,:,:,0],test[:,:,:,0],test[:,:,:,0]])\ntest=np.swapaxes(test,0,1)\ntest=np.swapaxes(test,1,2)\ntest=np.swapaxes(test,2,3)\ntest.shape","8652b868":"x_train[:,:,:,0].shape\nx_train=np.array([x_train[:,:,:,0],x_train[:,:,:,0],x_train[:,:,:,0]])\nx_train.shape","7200f92a":"x_val[:,:,:,0].shape\nx_val=np.array([x_val[:,:,:,0],x_val[:,:,:,0],x_val[:,:,:,0]])\nx_val.shape\n","48f35d49":"x_train=np.swapaxes(x_train,0,1)\nx_train=np.swapaxes(x_train,1,2)\nx_train=np.swapaxes(x_train,2,3)\nx_train.shape","1edf665a":"x_val=np.swapaxes(x_val,0,1)\nx_val=np.swapaxes(x_val,1,2)\nx_val=np.swapaxes(x_val,2,3)\nx_val.shape","9bc3b8d0":"#x_train[:,:,:,0] = preprocess_input(x_train[:,:,:,0])\n#x_val[:,:,:,0] = preprocess_input(x_val[:,:,:,0])","149e70af":"# Definir correctamente la red neuronal (5 pts)\n#Se utilizar\u00e1n las capas de convoluciones con los pesos fijos y solo se entrenar\u00e1 la capa densa final\n\nbase_model = ResNet50(include_top=False, input_shape=(96,96,3), pooling='avg')\nbase_model.trainable = False\nbase_model.summary()","40792239":"y.shape","6686e9b1":"from keras.models import Sequential \nfrom keras.layers import Dense, Flatten,BatchNormalization, Dropout\nfrom keras.optimizers import Adam\nfrom keras import regularizers\n#Se propondra la capa densa\ntop_model = Sequential([\n    Dense(512, activation='relu', input_shape=(2048,),kernel_initializer='he_normal'), #la capa resnet50 termina con 2048 inputs en una sola dimensi\u00f3n\n    Dense(256, activation='relu',kernel_initializer='he_normal'),\n    Dropout(0.7),\n    Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01),kernel_initializer='he_normal'),\n    Dropout(0.7),\n    Dense(96, activation='relu',kernel_regularizer=regularizers.l2(0.01),kernel_initializer='he_normal'),\n    Dropout(0.7),\n    Dense(48, activation='relu',kernel_regularizer=regularizers.l2(0.01),kernel_initializer='he_normal'),\n    Dense(30)\n])\ntop_model.compile(loss='mse', optimizer=Adam(0.001), metrics=['mae'])\ntop_model.summary()","96c2b803":"#El modelo final consta de la capa convolucional de resnet y la capa densa propia\nfinal_model = Sequential([base_model, top_model])\nfinal_model.compile(loss='mse', optimizer=Adam(0.001), metrics=['mae'])\nfinal_model.summary()","8f7da890":"# Entrenar la red neuronal (2 pts)\n#Pre computamos los pesos de la capa convolucional\nprecomputed_train = base_model.predict(x_train, batch_size=256, verbose=1)\nprecomputed_train.shape","ed4bff9b":"precomputed_val = base_model.predict(x_val, batch_size=256, verbose=1)\nprecomputed_val.shape","97ce567b":"log = top_model.fit(precomputed_train, y_train, epochs=600, batch_size=256, validation_data=[precomputed_val, y_val])","f30da327":"# Resultado del entrenamiento\n# - mae entre 10 y 15 (3 pts)\n# - mae entre 8 y 11 (5 pts)\n# - mae entre 5 y 8 (7 pts)\n# - mae menor o igual a 4.0 (9 pts)\n\nprint(f'MAE final: {final_model.evaluate(x_val, y_val)[1]}')","d0640fbc":"# Ver la perdida en el entrenamiento\ndef show_results(*logs):\n    trn_loss, val_loss, trn_acc, val_acc = [], [], [], []\n    \n    for log in logs:\n        trn_loss += log.history['loss']\n        val_loss += log.history['val_loss']\n    \n    fig, ax = plt.subplots(figsize=(8,4))\n    ax.plot(trn_loss, label='train')\n    ax.plot(val_loss, label='validation')\n    ax.set_xlabel('epoch'); ax.set_ylabel('loss')\n    ax.legend()\n    \nshow_results(log)","b6d2f342":"# Funci\u00f3n para visualizar un resultado\ndef show_pred(x, y_real, y_pred):\n    fig, axes = plt.subplots(1, 2, figsize=(10,5))\n    for ax in axes:\n        ax.imshow(x[0, ..., 0], 'gray')\n        ax.axis('off')\n        \n    points_real = np.vstack(np.split(y_real[0], 15)).T\n    points_pred = np.vstack(np.split(y_pred[0], 15)).T\n    axes[0].plot(points_pred[0], points_pred[1], 'o', color='red')\n    axes[0].set_title('Predictions', size=16)\n    axes[1].plot(points_real[0], points_real[1], 'o', color='green')\n    axes[1].plot(points_pred[0], points_pred[1], 'o', color='red', alpha=0.5)\n    axes[1].set_title('Real', size=16)","e9bc5485":"x_val[0,None].shape","421436b5":"sample_x = x_train[0, None]\nsample_y = y_val[0, None]\npred = final_model.predict(sample_x)\nshow_pred(sample_x, sample_y, pred)","3eec7945":"results=final_model.predict(test)\nresults","f2ba7607":"lookup = pd.read_csv('..\/input\/IdLookupTable.csv')\n","50cf2722":"lookid_list = list(lookup['FeatureName'])\nimageID = list(lookup['ImageId']-1)\npre_list = list(results)\n\nrowid = lookup['RowId']\nrowid=list(rowid)\nlen(rowid)\n\nfeature = []\nfor f in list(lookup['FeatureName']):\n    feature.append(lookid_list.index(f))\n    preded = []\nfor x,y in zip(imageID,feature):\n    preded.append(results[x][y])","610c3cd1":"rowid = pd.Series(rowid,name = 'RowId')","eec9e89f":"loc = pd.Series(preded,name = 'Location')","9f21e0ae":"submission = pd.concat([rowid,loc],axis = 1)","f07a5411":"submission.to_csv('submission_resnet.csv',index = False)","13655f7e":"# Mostrar 5 resultados aleatorios del set de validaci\u00f3n (1 pt)\n","b8d1ff67":"# Mostrar las 5 mejores predicciones del set de validaci\u00f3n (1 pt)\n","fbfeb5e1":"# Mostrar las 5 peores predicciones del set de validaci\u00f3n (1 pt)\n","1ac6c1b6":"Ej:\n``` python\nsample_x = x_val[0, None]\nsample_y = y_val[0, None]\npred = model.predict(sample_x)\nshow_pred(sample_x, sample_y, pred)\n```","a887b9fd":"# Examen Parcial:\n\nPara ejecutar el c\u00f3digo: crear un kernel en la competencia de kaggle (https:\/\/www.kaggle.com\/c\/facial-keypoints-detection) y partir de este notebook. Una vez terminado, se debe descargar el notebook final y subirlo en paideia.\n\n\n## Descripcion de la tarea\n\nEl objetivo de esta tarea es predecir las posiciones de los puntos clave en im\u00e1genes de rostros.\n\nLas im\u00e1genes de entrada son de 96x96 p\u00edxeles y en escala de grises (descritas con n\u00fameros enteros entre 0 y 255).\n\nCada punto clave se especifica mediante un par de valores reales (x, y) en el espacio de los \u00edndices de p\u00edxeles. Hay 15 puntos clave, que representan los siguientes elementos de la cara:\n\n    left_eye_center, right_eye_center, left_eye_inner_corner, left_eye_outer_corner, right_eye_inner_corner, right_eye_outer_corner, left_eyebrow_inner_end, left_eyebrow_outer_end, right_eyebrow_inner_end, right_eyebrow_outer_end, nose_tip, mouth_left_corner, mouth_right_corner, mouth_center_top_lip, mouth_center_bottom_lip\n\nDe modo que se debe entrenar una red neuronal que tome como input la imagen en escala de grises y de como output 30 n\u00fameros (las coordenadas x,y de los 15 puntos claves).\n\nAl compilar el modelo, especificar como funci\u00f3n de p\u00e9rdida el mean squared error **(mse)** y como m\u00e9trica el mean absolute error **(mae)**. Por ejemplo:\n``` python\nmodel.compile(Adam(lr), loss='mse', metrics=['mae'])\n```\n\n## Calificaci\u00f3n\n\n- Normalizar las im\u00e1genes (1 pt)\n- Definir correctamente la red neuronal (4 pts)\n- Entrenar la red neuronal (2 pts)\n  - mae entre 10 y 15 (3 pts)\n  - mae entre 8 y 11 (5 pts)\n  - mae entre 5 y 8 (7 pts)\n  - mae menor o igual a 4.0 (9 pts)\n- Mostrar 5 resultados aleatorios del set de validaci\u00f3n (1 pt)\n- Mostrar las 5 mejores predicciones del set de validaci\u00f3n (1 pt)\n- Mostrar las 5 peores predicciones del set de validaci\u00f3n (1 pt)\n\n## Recomendaciones\n\nActivar el uso de GPU en el kernel de kaggle.\n\nDentro del kernel de kaggle, los botones para bajar y subir kernels, se encuentran en la parte superior de la pagina, a la izquierda del boton commit.\n\n![](https:\/\/i.imgur.com\/m4inkg3.png)","2d73b6aa":"# Resultados","70eaa2d5":"# Lectura de datos","c0e27b4f":"# Train validation split","1734d4ba":"# Model"}}