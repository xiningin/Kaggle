{"cell_type":{"76e71352":"code","a282a441":"code","a27a3230":"code","abfa8ea9":"code","63c3747b":"code","39a11c97":"code","4322d97e":"code","693a87e7":"code","fdf2b0ed":"code","325f8c9e":"code","113d9f05":"code","a6965052":"code","a659d912":"code","bf6ee0f3":"markdown","cc56be94":"markdown","90c5d4d9":"markdown","1fe3fccb":"markdown","4a0bfc1a":"markdown","0f6208a1":"markdown","f250aec8":"markdown","dddd07c0":"markdown","0090a8e7":"markdown","23d94903":"markdown","49a344ee":"markdown","3278a6f5":"markdown","221eb41a":"markdown","092687e8":"markdown"},"source":{"76e71352":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing, model_selection\nimport sklearn\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_absolute_error\nimport os\nimport matplotlib.pyplot as plt","a282a441":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndata = pd.read_csv('\/kaggle\/input\/new_data_99_06_03_13_04.csv', delimiter=',')\n","a27a3230":"data.shape\n","abfa8ea9":"data.head(10)","63c3747b":"len(data) - data.count()","39a11c97":"df = data[:].nunique()\ndf","4322d97e":"data = data.drop(['\u0422\u0430\u043c\u043e\u0436\u043d\u044f', 'description'], axis='columns', inplace=False)\ndata = data.dropna()","693a87e7":"len(data) - data.count()\n","fdf2b0ed":"data.dtypes","325f8c9e":"le = preprocessing.LabelEncoder()\ncategorical_columns = data.columns[data.dtypes == 'object']\n\nfor column in categorical_columns:\n    data[column] = le.fit_transform(list(data[column]))","113d9f05":"data.dtypes","a6965052":"fig = plt.figure(figsize=(15,8))\nax1 = fig.add_subplot(111)\nplt.imshow(data.corr(), cmap='hot', interpolation='nearest')\nplt.colorbar()\nlabels = data.columns\nax1.set_xticks(np.arange(len(labels)))\nax1.set_yticks(np.arange(len(labels)))\nax1.set_xticklabels(labels,rotation=90, fontsize=10)\nax1.set_yticklabels(labels,fontsize=10)\nplt.show()","a659d912":"predict = 'Price'\n\nX = np.array(data.drop([predict], 1))\ny = np.array(data[predict])\n\nx_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2)\n\nmodel = CatBoostRegressor(learning_rate=0.5)\nmodel.fit(x_train, y_train)\naccuracy = model.score(x_test, y_test)\nprint('Accuracy of model:', accuracy)\n\npredictions = model.predict(x_test)\nmae = mean_absolute_error(predictions, y_test)\nprint(\"Mean Absolute Error:\", mae)","bf6ee0f3":"Let's take a quick look at types now, again.","cc56be94":"We can see both negative and positive correlations between price and features like enginepower, mileage and etc. To tune the prediction model we should drop features with low correlation, maybe generate some new features...but this is base-lane notebook, so we try to train model with all those features and and we'll see what happens.","90c5d4d9":"Great! Now we can implement some correlation visualisation.","1fe3fccb":"We see some NaN values, lets check how many NaNs we got.","4a0bfc1a":"Lets also check unique values of each column.","0f6208a1":"## Exploratory Analysis\nTo begin we first importing everything we need, then we going to check our data.","f250aec8":"Check the data for NaNs again and lets check the data types of columns.","dddd07c0":"We can see that about 63% of data in '\u0412\u043b\u0430\u0434\u0435\u043d\u0438\u0435' is missing. We going to drop this. Also we going to drop 'description' columns since in have only text description, that we can use in NLP but not in this case. Aswell we should drop those 1-7 NaNs wich are not very important given the volume of other data. '\u0422\u0430\u043c\u043e\u0436\u043d\u044f' column got only 1 value, so its going to be dropped too.","0090a8e7":"## Conclusion\nWithout any model tuning or feature engineering we got 90-93 pepercents accuracy, wich is pretty good. You can achive way more better scores with those key items i mentioned before - feature engineering and tuning the model.\nFeel free to comment and fork this notebook, stay safe.","23d94903":"Lets check the data!","49a344ee":"# Building the model\nLets build the model and try to predict price of cars with features we got.","3278a6f5":"There is 1 csv file in the current version of the dataset:\n","221eb41a":"# Introduction\nHello there!\nThis notebook describes how to implement basic CatBoost regression.","092687e8":"Now we can see - there are zero NaN values. Columns of data contains lot of objects. For various purposes (for example, to visualize correlations), we need to convert those objects to numbers. In this case we can use Lable Encoder, wich is pretty easy to implement."}}