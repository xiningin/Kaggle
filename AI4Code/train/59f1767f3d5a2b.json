{"cell_type":{"0b21bc05":"code","4132c1d0":"code","6fc08066":"code","289fe126":"code","77a0898f":"code","8d669ea8":"code","a331f2a8":"code","8f033920":"code","d66fa455":"code","9d70b704":"code","b5e68cd1":"code","9d53d418":"code","0a0e4f75":"code","9c7cd706":"code","9fa55d12":"code","52b84dc7":"code","7dfa9891":"code","9f2140b2":"code","a74f736d":"code","5c7a9c73":"code","5fcc9a0d":"code","d6a4525b":"code","94ff0920":"code","16ab377c":"code","b6160e8a":"code","795d9154":"code","5f1e96f8":"code","6f209c89":"code","6d6977b9":"code","8b44ed62":"code","1f1a5b07":"code","1b4f19ed":"code","03996997":"code","ed678441":"code","ee75590c":"code","e5d4e8f6":"code","23103aa4":"code","9f427dc9":"code","54eab170":"code","a9245333":"code","502b14ff":"code","b6d74acd":"code","10e56a2a":"code","8c6b4d00":"code","cf26a34a":"code","492c439e":"code","6144d15a":"code","f2f998a8":"code","9bae6a0d":"code","d847ccbc":"code","08a39a12":"code","fd466dec":"code","85f842ed":"code","4d7a28c4":"code","f1a6a444":"code","d5430c04":"code","85afa03a":"code","510e649a":"code","bbe697dc":"code","f1b367b4":"code","2128555f":"code","e495198a":"code","ac5e60a5":"code","45b835da":"code","b64c7242":"code","422cd25e":"code","312df6df":"code","98cd840e":"code","d4d876b7":"code","b05eecf1":"code","1da9eeed":"code","a0188c83":"code","6b02123f":"code","87b3d809":"code","a9f9d42e":"code","ccfd84c0":"code","849f8746":"markdown","5dcb3538":"markdown","374ecfc5":"markdown","f2f8f7cd":"markdown","287bffb8":"markdown","b38af323":"markdown","fdbe24f3":"markdown","10a78f1d":"markdown"},"source":{"0b21bc05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4132c1d0":"train_df = pd.read_csv(\"\/kaggle\/input\/prml-data-contest-nov-2020\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/prml-data-contest-nov-2020\/test.csv\")\nbikers_df = pd.read_csv(\"\/kaggle\/input\/prml-data-contest-nov-2020\/bikers.csv\")\nbikers_network = pd.read_csv('\/kaggle\/input\/prml-data-contest-nov-2020\/bikers_network.csv')\ntour_convoy = pd.read_csv('\/kaggle\/input\/prml-data-contest-nov-2020\/tour_convoy.csv')\n# tours_df = pd.read_csv('\/kaggle\/input\/prml-data-contest-nov-2020\/tours.csv')\ntours_df = pd.read_csv('\/kaggle\/input\/processed-data\/tours_data.csv')\nlocations_df = pd.read_csv('\/kaggle\/input\/processed-data\/locations.csv')","6fc08066":"train_bikers = train_df['biker_id'].unique()\ntest_bikers = test_df['biker_id'].unique()\nall_bikers = np.concatenate([train_bikers,test_bikers])\nall_bikers","289fe126":"all_bikers_df = bikers_df[bikers_df['biker_id'].apply(lambda x: True if x in all_bikers else False)]\nall_bikers_df.reset_index(drop=True, inplace=True)\nall_bikers_df.sample()","77a0898f":"location_df = locations_df[['biker_id','latitude','longitude']]\nlocation_df.sample()","8d669ea8":"def location(biker_id):\n    try:\n        return location_df[location_df['biker_id'] == biker_id].iloc[0]\n    except:\n        return None","a331f2a8":"location_details =  all_bikers_df['biker_id'].apply(lambda x: location(x))\nlocation_details.sample()","8f033920":"all_bikers_df = all_bikers_df.join(location_details,rsuffix = '_location')\nall_bikers_df = all_bikers_df.drop('biker_id_location',axis = 'columns')\nall_bikers_df.sample()","d66fa455":"all_bikers_df = all_bikers_df.rename(columns={\"latitude\": \"biker_latitude\", \"longitude\": \"biker_longitude\"})\nall_bikers_df.sample()","9d70b704":"train_tours = train_df['tour_id'].unique()\ntest_tours = test_df['tour_id'].unique()\nall_tours = np.concatenate([train_tours,test_tours])\nall_tours","b5e68cd1":"all_tours_df = tours_df[tours_df['tour_id'].apply(lambda x: True if x in all_tours else False)]\nall_tours_df.reset_index(drop=True, inplace=True)\nall_tours_df.sample()","9d53d418":"all_organizers = all_tours_df['biker_id'].unique()\nlen(all_organizers)","0a0e4f75":"all_organizers_friends_df = bikers_network[bikers_network['biker_id'].apply(lambda x: True if x in all_organizers else False)]\nall_organizers_friends_df.reset_index(drop=True, inplace=True)\nall_organizers_friends_df.sample()","9c7cd706":"all_bikers_friends_df = bikers_network[bikers_network['biker_id'].apply(lambda x: True if x in all_bikers else False)]\nall_bikers_friends_df.reset_index(drop=True, inplace=True)\nall_bikers_friends_df.sample()","9fa55d12":"all_tour_convoy_df = tour_convoy[tour_convoy['tour_id'].apply(lambda x: True if x in all_tours else False)]\nall_tour_convoy_df.reset_index(drop=True, inplace=True)\nall_tour_convoy_df.sample()","52b84dc7":"# Friends = pd.concat([all_organizers_friends_df, all_bikers_friends_df], sort=False)\n# Friends.reset_index(drop=True, inplace=True)\n# Friends","7dfa9891":"# all_bikers_df.to_csv('bikers.csv',index=False)\n# all_tours_df.to_csv('tours.csv',index=False)\n# all_tour_convoy_df.to_csv('tour_convoy.csv',index=False)\n# Friends.to_csv('bikers_network.csv',index=False)","9f2140b2":"# all_bikers_df['gender'].unique()\n# all_bikers_df['gender'].mode()\nall_bikers_df['gender'] = all_bikers_df['gender'].fillna('male')\nall_bikers_df['gender'].unique()","a74f736d":"# all_bikers_df['bornIn'].unique()\n# all_bikers_df['bornIn'].mode()\nall_bikers_df['bornIn'] = all_bikers_df['bornIn'].apply(lambda x: '1993' if x == 'None' else x)\nall_bikers_df['bornIn'].unique()","5c7a9c73":"# all_bikers_df['member_since'].mode()\nall_bikers_df['member_since'] = all_bikers_df['member_since'].fillna('30-10-2012')","5fcc9a0d":"all_bikers_df.sample()","d6a4525b":"X = pd.concat([train_df, test_df], sort=False)\nX.reset_index(drop=True, inplace=True)","94ff0920":"tours_details = X['tour_id'].apply(lambda x: all_tours_df[all_tours_df['tour_id'] == x].iloc[0])\ntours_details.head(4)","16ab377c":"X = X.join(tours_details,rsuffix = '_organizer')\nX.head(4)","b6160e8a":"del tours_details\nX = X.drop(['tour_id_organizer'],axis='columns')\nX.sample()","795d9154":"bikers_details = X['biker_id'].apply(lambda x: all_bikers_df[all_bikers_df['biker_id'] == x].iloc[0])\nbikers_details.head(4)","5f1e96f8":"X = X.join(bikers_details,rsuffix = '_biker')\nX.head(4)","6f209c89":"del bikers_details\nX = X.drop(['biker_id_biker'],axis='columns')\nX.sample()","6d6977b9":"def age(born_year,tour_date):\n    tour_year = float(tour_date.split('-')[2])\n    return tour_year - float(born_year)","8b44ed62":"X['age'] = X[['bornIn','tour_date']].apply(lambda x: age(x.bornIn,x.tour_date) ,axis=1)\nX.sample(3)","1f1a5b07":"def time(member_since,tour_date):\n    tour = tour_date.split('-')\n    member = member_since.split('-')\n    year = float(tour[2])-float(member[2])\n    month = float(tour[1])-float(member[1])\n    day = float(tour[0])-float(member[0])\n    return round(((year*12) + month + (day\/30)),2)","1b4f19ed":"X['mambership_time'] = X[['member_since','tour_date']].apply(lambda x: time(x.member_since,x.tour_date),axis = 1)\nX.sample(3)","03996997":"X['ismale'] = X['gender'].apply(lambda x: 1 if x == 'male' else 0)\nX.sample(3)","ed678441":"X = X.drop(['bornIn','member_since','gender'],axis = 'columns')\nX.sample()","ee75590c":"def check_friend(biker_id,organizer_id):\n    try:\n        organizer_friends = (all_organizers_friends_df[all_organizers_friends_df['biker_id'] == organizer_id]['friends'].iloc[0]).split(' ')\n        if(biker_id in organizer_friends):\n            return 1\n    except:\n        pass\n    try:\n        biker_friends = (all_bikers_friends_df[all_bikers_friends_df['biker_id'] == biker_id ]['friends'].iloc[0]).split(' ')\n        if(organizer_id in biker_friends):\n            return 1\n    except:\n        return 0\n    return 0","e5d4e8f6":"check_friend('DG87195364','CJ03662804')","23103aa4":"X['isfriend'] = X[['biker_id','biker_id_organizer']].apply(lambda x: check_friend(x.biker_id,x.biker_id_organizer) ,axis = 1)\nX.sample()","9f427dc9":"def friends_status(biker_id,tour_id):\n    s = np.array([0,0,0,0])\n    try:\n        friends = set((all_bikers_friends_df[all_bikers_friends_df['biker_id'] == biker_id]['friends'].iloc[0]).split(' '))\n    except:\n        return s\n    try:\n        this_tour_convoy = all_tour_convoy_df[all_tour_convoy_df['tour_id'] == tour_id]\n        going = set((this_tour_convoy['going'].iloc[0]).split(' '))\n        maybe = set((this_tour_convoy['maybe'].iloc[0]).split(' '))\n        invited = set((this_tour_convoy['invited'].iloc[0]).split(' '))\n        not_going = set((this_tour_convoy['not_going'].iloc[0]).split(' '))\n    except:\n        return s\n    try:\n        s[0] = len(set(friends) & set(going))\n        s[1] = len(set(friends) & set(maybe))\n        s[2] = len(set(friends) & set(invited))\n        s[3] = len(set(friends) & set(not_going))\n    except:\n        return s\n    return s","54eab170":"friendStatus = X[['biker_id','tour_id']].apply(lambda x: friends_status(x.biker_id,x.tour_id),axis = 1)\nfriendStatus.head()","a9245333":"X['friends_going'] = friendStatus.apply(lambda x: x[0])","502b14ff":"X['friends_maybe'] = friendStatus.apply(lambda x: x[1])","b6d74acd":"X['friends_invited'] = friendStatus.apply(lambda x: x[2])","10e56a2a":"X['friends_not_going'] = friendStatus.apply(lambda x: x[3])","8c6b4d00":"del friendStatus","cf26a34a":"X['language_id'].unique()","492c439e":"# language_0 = X.groupby('language_id')['language_id'].agg('count').sort_values(ascending=False)\n# language_10 = language_0[language_0 < 10]","6144d15a":"# X.language_id = X.language_id.apply(lambda x: 'other_language' if x in language_10 else x)\n# X.groupby('language_id')['language_id'].agg('count').sort_values(ascending=False)","f2f998a8":"lang_dummies = pd.get_dummies(X.language_id)\nlang_dummies.head()","9bae6a0d":"X = pd.concat([X,lang_dummies],axis='columns')\nX.sample()","d847ccbc":"def distance(la1,lo1,la2,lo2):\n    try:\n        ta = la1-la2\n        to = lo1-lo2\n        if abs(to) > 180:\n            a = 180 - abs(lo1)\n            b = 180 - abs(lo2)\n            to = a+b\n        d = (ta**2) + (to**2)\n        return (d**(1\/2))\n    except:\n        return None","08a39a12":"X['distance'] =  X[['latitude','longitude','biker_latitude','biker_longitude']].apply(lambda x: distance(x.latitude,x.longitude,x.biker_latitude,x.longitude),axis='columns')","fd466dec":"X.sample()","85f842ed":"X.columns.values","4d7a28c4":"Q = X.drop(['timestamp','biker_id_organizer', 'tour_date', 'city', 'state', 'pincode','country', 'latitude', 'longitude','w_other','time_zone','language_id','location_id', 'area','biker_latitude','biker_longitude'],axis='columns')\nQ.sample()","f1a6a444":"Q.columns.values","d5430c04":"train_X = Q.iloc[:len(train_df),:]\ntest_X = Q.iloc[len(train_df):,:]","85afa03a":"train_X.reset_index(drop=True, inplace=True)\ntest_X.reset_index(drop=True, inplace=True)","510e649a":"Z = train_X.drop(['biker_id','tour_id'],axis = 'columns')\nZ.head()","bbe697dc":"Zx = Z.drop(['like','dislike'],axis='columns')\nZx.head()","f1b367b4":"Zy = Z['like'].apply(lambda x: int(x))\nZy.head()","2128555f":"Zy.unique()","e495198a":"from xgboost import XGBClassifier","ac5e60a5":"myModel = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.3, gamma=0.0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.05, max_delta_step=0, max_depth=9,\n              min_child_weight=1, monotone_constraints='()',\n              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)\nmyModel.fit(Zx,Zy)","45b835da":"import lightgbm as lgb","b64c7242":"myModeL = lgb.LGBMClassifier(boosting_type='gbdt',colsample_bytree=0.7, learning_rate=0.05, max_depth=19,\n               num_levels=33, reg_lambda=0.35)\nmyModeL.fit(Zx,Zy)","422cd25e":"W = test_X.drop(['biker_id','tour_id','like','dislike'],axis='columns')\ntry:\n    W = W.drop('prediction',axis = 'columns')\nexcept:\n    pass\nW.head()","312df6df":"Y_predict_prob = myModel.predict_proba(W)","98cd840e":"Y_predict_prob_L = myModeL.predict_proba(W)","d4d876b7":"Y_pred_prob = pd.DataFrame(data = Y_predict_prob)\nY_pred_prob_L = pd.DataFrame(data = Y_predict_prob_L)","b05eecf1":"Y_pred_prob_L","1da9eeed":"test_X['prediction'] =  Y_pred_prob[1]\ntest_X['predictionL'] = Y_pred_prob_L[1]","a0188c83":"Ans = test_X[['biker_id','tour_id','prediction']]\nAnsL = test_X[['biker_id','tour_id','predictionL']]","6b02123f":"Bikers_set = test_X['biker_id'].unique()\nlen(Bikers_set)","87b3d809":"bikers = []\ntours = []\nfor biker in Bikers_set:\n    bikers.append(biker)\n    this_tours = []\n    tour_list = test_X[test_X['biker_id'] == biker].sort_values(['prediction'],ascending=0)\n    tour_list['tour_id'].apply(lambda x: this_tours.append(x))\n    tours.append(\" \".join(this_tours))","a9f9d42e":"bikersL = []\ntoursL = []\nfor biker in Bikers_set:\n    bikersL.append(biker)\n    this_tours = []\n    tour_list = test_X[test_X['biker_id'] == biker].sort_values(['predictionL'],ascending=0)\n    tour_list['tour_id'].apply(lambda x: this_tours.append(x))\n    toursL.append(\" \".join(this_tours))","ccfd84c0":"submission1 =pd.DataFrame(columns=[\"biker_id\",\"tour_id\"])\nsubmission1[\"biker_id\"] = bikers\nsubmission1[\"tour_id\"] = tours\nsubmission1.to_csv(\"submission1.csv\",index=False) # download this file from \/kaggle\/working directory\nprint(submission1.shape)\nsubmission1.head(4)\nsubmission2 =pd.DataFrame(columns=[\"biker_id\",\"tour_id\"])\nsubmission2[\"biker_id\"] = bikersL\nsubmission2[\"tour_id\"] = toursL\nsubmission2.to_csv(\"submission2.csv\",index=False) # download this file from \/kaggle\/working directory\nprint(submission2.shape)\nsubmission2.head(4)","849f8746":"# process data","5dcb3538":"# split train test ","374ecfc5":"# submission file","f2f8f7cd":" train_bikers ||\n test_bikers ||\n all_bikers ||\n all_bikers_df\n \n train_tours ||\n test_tours ||\n all_tours ||\n all_tours_df\n\n all_organizers\n \n all_organizers_friends_df ||\n all_bikers_friends_df\n\n all_tour_convoy_df","287bffb8":"# code to order tours for each biker\n","b38af323":"# train model","fdbe24f3":"# read\/organize data","10a78f1d":"# reading test file"}}