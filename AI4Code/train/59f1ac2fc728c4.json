{"cell_type":{"ba8a0974":"code","13167f4c":"code","3414d64c":"code","d635d5eb":"code","69c71a08":"code","05a96f38":"code","58e2fa00":"code","2d03f425":"code","565f0872":"code","d4936490":"code","77e28d25":"code","46eb8716":"code","382a2a65":"code","275703de":"code","e0810113":"code","a8444a1e":"code","39055ca8":"code","3a26969d":"code","85243769":"markdown","266d8b77":"markdown","05016518":"markdown","bf46974a":"markdown","b54ff822":"markdown","40fa1e61":"markdown"},"source":{"ba8a0974":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n%matplotlib inline","13167f4c":"url='https:\/\/raw.githubusercontent.com\/imamanmehrotra\/Datasets\/main\/income_kmeans.csv'","3414d64c":"df=pd.read_csv(url)\nprint(df.shape)\ndf","d635d5eb":"px.scatter(x='Age',y='Income($)',data_frame=df)","69c71a08":"km=KMeans(n_clusters=3)\nkm","05a96f38":"y_pred=km.fit_predict(df[['Age','Income($)']])\ny_pred","58e2fa00":"df['Cluster_Number']=y_pred","2d03f425":"df","565f0872":"px.scatter(x='Age',y='Income($)', data_frame=df, color='Cluster_Number', title='K-Means Clustering')","d4936490":"from sklearn.preprocessing import StandardScaler, MinMaxScaler","77e28d25":"mm=MinMaxScaler()\n\nmm.fit(df[['Income($)']])\ndf['Income_Scaled']=mm.transform(df[['Income($)']])\n\nmm.fit(df[['Age']])\ndf['Age_Scaled']=mm.transform(df[['Age']])\n\ndf","46eb8716":"km=KMeans(n_clusters=3)\ny_pred=km.fit_predict(df[['Age_Scaled','Income_Scaled']])\ndf['New_Cluster']=y_pred\ndf","382a2a65":"px.scatter(x='Age',y='Income($)', data_frame=df, color='New_Cluster', title='K-Means Clustering')","275703de":"cc=km.cluster_centers_\ncc_x=cc[:,0]\ncc_y=cc[:,1]","e0810113":"cc_x,cc_y","a8444a1e":"import plotly.graph_objects as go\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x=df['Age_Scaled'],\n        y=df['Income_Scaled'],\n        mode= 'markers',\n        marker_color=df['New_Cluster'],\n        text=df[['Age','Income($)']],\n        name='Data_Point',\n        marker_size=10\n        \n    ))\n\nfig.add_trace(\n    go.Scatter(\n        x=cc_x,\n        y=cc_y,\n        mode='markers',\n        marker_color='green',\n        text=['Centroids'],\n        name='Centroid',\n        marker_size=15\n        \n        \n    ))\n\nfig.show()","39055ca8":"k_range=range(1,10)\nwcsse=[]\nfor k in k_range:\n    km=KMeans(n_clusters=k)\n    km.fit(df[['Age_Scaled','Income_Scaled']])\n    sse=km.inertia_\n    wcsse.append(sse)","3a26969d":"px.line(x=k_range,y=wcsse,labels=dict(x=\"K-Value\", y=\"Error\"))","85243769":"## Computing the Centroids of our Clusters","266d8b77":"## Now we can observe that Yellow and blue clusters are not proper and this is due to the reason that feature scaling needs to be done, since our feature income has pretty high values, while our feature Age has very narrow values. So lets proceed with feature scaling at this point","05016518":"### From the above graph we could observe that at K=3 there is an abrupt decrease in the Sum of Squared error and hence we can say that this should be the optimal value for K according to ur dataset.","bf46974a":"## K - Means Clustering with Centroid Representation on Scaled Data","b54ff822":"### Now let's see the Elbow Method to find the most optimal value for K while deciding for the number of clusters in K-Means Clustering.","40fa1e61":"# ELBOW METHOD"}}