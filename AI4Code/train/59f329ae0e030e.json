{"cell_type":{"dd7fb395":"code","f1968d02":"code","ed92a25e":"code","3bf38dd0":"code","90d3d48e":"code","c81004da":"code","79df6e22":"code","08450646":"code","10aa7806":"code","ffb2678a":"code","dc6e44b4":"code","61dc388c":"code","b649bea1":"code","a9d0022e":"code","1d53e3c1":"code","32d86d11":"code","665d399f":"code","8a7aea87":"code","313ce33a":"code","484a4ef6":"code","f4ab435b":"code","559e39b7":"code","3a6d7dc2":"code","bfdec4f7":"code","76c19e28":"code","2734acf3":"markdown"},"source":{"dd7fb395":"pip install emoji","f1968d02":"import numpy as np\nimport pandas as pd\nimport torch as torch\nimport torch.nn as nn\nfrom torchvision import models\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nimport emoji\nimport os","ed92a25e":"class myModel(nn.Module):\n    \n    def __init__(self,vocab_size,embedding_dim,pretrained_weight):\n        super(myModel,self).__init__()\n        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n        pretrained_weight = np.array(pretrained_weight)\n        self.word_embeds.weight.data.copy_(torch.from_numpy(pretrained_weight))\n        self.rnn = nn.LSTM(embedding_dim, 128, 2,batch_first=True,dropout=0.5)\n        self.linear = nn.Linear(128,5)\n        self.out = nn.Softmax(dim=1)\n\n    def forward(self,x,h):\n        out = self.word_embeds(x)\n        out, _ = self.rnn(out,h)\n        out = out[:, -1, :]\n        out = self.linear(out)\n        out = self.out(out)\n        return out\n","3bf38dd0":"def read_glove_vecs(glove_file):\n    with open(glove_file, 'r',encoding='UTF-8') as f:\n        words = set()\n        word_to_vec_map = {}\n        for line in f:\n            line = line.strip().split()\n            curr_word = line[0]\n            words.add(curr_word)\n            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n        \n        i = 1\n        words_to_index = {}\n        index_to_words = {}\n        for w in sorted(words):\n            words_to_index[w] = i\n            index_to_words[i] = w\n            i = i + 1\n    return words_to_index, index_to_words, word_to_vec_map\n","90d3d48e":"def sentences_to_indices(X, word_to_index, max_len):\n    m = X.shape[0]\n    X_indices = np.zeros((m, max_len))\n    for i in range(m):\n        sentence_words = X[i].lower().split()\n        j = 0\n        for w in sentence_words:\n            X_indices[i, j] = int(word_to_index[w])\n            j = j + 1\n    return X_indices","c81004da":"def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n    vocab_len = len(word_to_index) + 1  #word index begin with 1,plus 1 for padding 0\n    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]\n    emb_matrix = np.zeros((vocab_len, emb_dim))\n    for word, index in word_to_index.items():\n        emb_matrix[index, :] = word_to_vec_map[word]\n    return emb_matrix","79df6e22":"def convert_to_one_hot(Y, C):\n    Y = np.eye(C)[Y.reshape(-1)]\n    return Y","08450646":"word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('..\/input\/clovefile\/glove.6B.50d.txt')","10aa7806":"training_data=pd.read_csv('..\/input\/emojifydata\/train_emoji.csv')\ntest_data=pd.read_csv('..\/input\/emojifydata\/tesss.csv')","ffb2678a":"train_x,train_y=training_data.iloc[:,0],training_data.iloc[:,1]\ntest_x,test_y=test_data.iloc[:,0],test_data.iloc[:,1]","dc6e44b4":"emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",   \n                    \"1\": \":baseball:\",\n                    \"2\": \":smile:\",\n                    \"3\": \":disappointed:\",\n                    \"4\": \":fork_and_knife:\"}","61dc388c":"print(\"Example of Trining Data \")\nprint(\"Sentence is : {} ,Emoji is : {}\".format(train_x.iloc[4],emoji.emojize(emoji_dictionary[str(train_y.iloc[4])],use_aliases=True)))","b649bea1":"train_x=train_x.to_numpy()\ntest_x=test_x.to_numpy()\ntrain_y=train_y.to_numpy()\ntest_y=test_y.to_numpy()","a9d0022e":"y_hot_train=convert_to_one_hot(train_y,5)\ny_hot_test=convert_to_one_hot(test_y,5)","1d53e3c1":"print(train_y[4], \"is converted into one hot\", y_hot_train[4])","32d86d11":"max_len = len(max(train_x, key=len).split())\nprint(max_len)","665d399f":"train_indces=sentences_to_indices(train_x, word_to_index, max_len)\ntest_indces=sentences_to_indices(test_x, word_to_index, max_len)","8a7aea87":"train_xtensor = torch.from_numpy(train_indces)\ntrainlab = torch.tensor(train_y) \ntrain_tensor = torch.utils.data.TensorDataset(train_xtensor, trainlab)\n\ntest_xtensor = torch.from_numpy(test_indces)\ntestlab = torch.tensor(test_y) \ntest_tensor = torch.utils.data.TensorDataset(test_xtensor, testlab)","313ce33a":"train_loader=torch.utils.data.DataLoader(dataset=train_tensor,batch_size=20,shuffle=True, num_workers=0)\ntest_loader=torch.utils.data.DataLoader(dataset=test_tensor,batch_size=20,shuffle=True, num_workers=0)","484a4ef6":"vocab_len = len(word_to_index) + 1\nemb_matrix = pretrained_embedding_layer(word_to_vec_map, word_to_index)\nmodel = myModel(vocab_len,50,emb_matrix)","f4ab435b":"for param in model.parameters():\n    param.requires_grad = True\n    \n\nmodel = model.cuda()\n\nloss_func = nn.CrossEntropyLoss()\n\noptimizer1 = torch.optim.Adam(model.rnn.parameters(),lr=0.0003)\noptimizer2 = torch.optim.Adam(model.linear.parameters(),lr=0.0003)","559e39b7":"min_valid=np.Inf\ntrain_acc,valid_acc=[],[]\ntrain_losses,valid_losses=[],[]\nfor epoch in range(900):\n    model.train()\n    running=0\n    train_accuracy=0\n    for data,target in train_loader:\n        data = data.long()\n        target = target.long()\n        model.zero_grad()\n        states = (Variable(torch.zeros(2, len(data), 128)).cuda(), Variable(torch.zeros(2, len(data), 128)).cuda())\n        data = Variable(data).cuda()\n        target = Variable(target).cuda()\n        output = model(data,states)\n        loss = loss_func(output,target)\n        loss.backward()\n        optimizer1.step()\n        optimizer2.step()\n        running+=loss.item()\n        target=target.cpu().numpy()\n        output=output.cpu().detach().numpy()\n        for i in range(len(data)):\n            num=np.argmax(output[i])\n            if num==target[i]:\n                train_accuracy+=1\n    else:\n        with torch.no_grad():\n            model.eval()\n            test_accuracy=0\n            valid_loss=0\n            for data1,target1 in test_loader:\n                data1 = Variable(data1.long()).cuda()\n                target1 = Variable(target1.long()).cuda()\n                target1=target1.long()\n                states = (Variable(torch.zeros(2, len(data1), 128)).cuda(), Variable(torch.zeros(2, len(data1), 128)).cuda())\n                pred = model(data1,states)\n                loss = loss_func(pred,target1)\n                valid_loss+=loss.item()\n                target1=target1.cpu().numpy()\n                pred=pred.cpu().numpy()\n                for i in range(len(data1)):\n                    num=np.argmax(pred[i])\n                    if num==target1[i]:\n                        test_accuracy+=1\n            test_accuracy\/=len(test_xtensor)\n            train_accuracy\/=len(train_xtensor)\n            if valid_loss<min_valid:\n                min_valid=valid_loss\n                torch.save(model.state_dict(),\"emojify.pkl\")\n                \n    \n    if (epoch+1)%50==0:\n        print(\"Epoch {}......\".format(epoch+1))\n        print(\"Training Accuracy : {:.4f} Training Loss {:.4f}\".format(train_accuracy*100.0,running))\n        print(\"Validation Accuracy : {:.4f} Validation Loss {:.4f}\".format(test_accuracy*100.0,valid_loss))\n        train_losses.append(running)\n        train_acc.append(train_accuracy)\n        valid_losses.append(valid_loss)\n        valid_acc.append(test_accuracy)\n   ","3a6d7dc2":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\nax1.plot(train_losses,label='Training Loss')\nax1.plot(valid_losses,label='Validation Loss')\n\nax1.legend(frameon=False)\n\nax2.plot(train_acc,label='Training Accuracy')\nax2.plot(valid_acc,label='Validation Accuracy')\n\nax2.legend(frameon=False)","bfdec4f7":"model.load_state_dict(torch.load(\"emojify.pkl\"))","76c19e28":"x_test = np.array(['not feeling happy', 'Holy shit', 'you are so pretty', 'let us play ball'])\nX_test_indices = sentences_to_indices(x_test, word_to_index, 10)\nX_test_indices = torch.from_numpy(X_test_indices)\nX_test_indices = Variable(X_test_indices.long()).cuda()\nstates = (Variable(torch.zeros(2, 4, 128)).cuda(), Variable(torch.zeros(2, 4, 128)).cuda())\npred = model(X_test_indices,states)\npred=pred.cpu()\nfor i in range(len(x_test)):\n    num = np.argmax(pred.data[i])\n    print(' prediction: ' + x_test[i] + ' '+emoji.emojize(emoji_dictionary[str(num.item())],use_aliases=True))","2734acf3":"## Emojify!\nWelcome to the second assignment of Week 2. You are going to use word vector representations to build an Emojifier.\n\nHave you ever wanted to make your text messages more expressive? Your emojifier app will help you do that. So rather than writing \"Congratulations on the promotion! Lets get coffee and talk. Love you!\" the emojifier can automatically turn this into \"Congratulations on the promotion! \ud83d\udc4d Lets get coffee and talk. \u2615\ufe0f Love you! \u2764\ufe0f\"\n\nYou will implement a model which inputs a sentence (such as \"Let's go see the baseball game tonight!\") and finds the most appropriate emoji to be used with this sentence (\u26be\ufe0f). In many emoji interfaces, you need to remember that \u2764\ufe0f is the \"heart\" symbol rather than the \"love\" symbol. But using word vectors, you'll see that even if your training set explicitly relates only a few words to a particular emoji, your algorithm will be able to generalize and associate words in the test set to the same emoji even if those words don't even appear in the training set. This allows you to build an accurate classifier mapping from sentences to emojis, even using a small training set.\n\nIn this exercise, you'll start with a baseline model (Emojifier-V1) using word embeddings, then build a more sophisticated model (Emojifier-V2) that further incorporates an LSTM."}}