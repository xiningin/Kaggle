{"cell_type":{"37ea3628":"code","d8875517":"code","11846407":"code","7b430609":"code","036e5ba9":"code","bc18ebc1":"code","78792cda":"code","7518bcff":"code","201d9837":"code","ce32386a":"code","cdbd95c9":"code","96d39cf9":"code","749b1913":"code","7d6d13e3":"code","28203974":"code","db50cf25":"code","c94c8118":"code","519903da":"code","c0226b1e":"code","e9294a96":"code","de1a98aa":"code","1460e9d6":"code","38ab633a":"code","3a8e269c":"code","7ea7cf99":"code","72f90775":"code","7098d163":"code","8e9a8181":"code","1c200731":"code","73323e15":"code","3650730f":"code","3320605e":"code","6a22d6fd":"markdown","eaf23ba3":"markdown","3a85e64b":"markdown","2d0e5f2e":"markdown","7cf3d57e":"markdown","22ed6280":"markdown","22102c2c":"markdown","9ed3c34d":"markdown","8261c95d":"markdown","e5a7defc":"markdown","0b8ef3bc":"markdown","55af64ab":"markdown","18b5b0ca":"markdown","6186d71e":"markdown","78a4c6e1":"markdown","e564f57e":"markdown","cb6bee80":"markdown","67361ed8":"markdown","90ea3cee":"markdown","e195fb07":"markdown","56232760":"markdown","75808af4":"markdown","d343427b":"markdown","d4d90d36":"markdown","35e8e611":"markdown","11babb28":"markdown","d6046f66":"markdown","c3f9d28e":"markdown","7f2dafae":"markdown","1ce6cbf5":"markdown","38e3f1bf":"markdown","deeb44c3":"markdown","cc805279":"markdown","dba1f5e5":"markdown","f8d7be3e":"markdown","9aa29b47":"markdown","20510cf7":"markdown","f7702eb5":"markdown","f1661018":"markdown","b96720a0":"markdown","d3f24e34":"markdown","b01d73ef":"markdown","08c7c655":"markdown","4378541f":"markdown","b8813153":"markdown","896e8a2d":"markdown","dd086134":"markdown","8ce41cdc":"markdown","71cc42c2":"markdown","261fc7c0":"markdown","8f631f22":"markdown","51658cc0":"markdown","e1fce607":"markdown","747e7005":"markdown","6bd2f917":"markdown","bed7d7af":"markdown","fd5901b0":"markdown","c9fe0dfc":"markdown","256ec47e":"markdown","ba447632":"markdown","f6f57239":"markdown","28010d5f":"markdown","cfb588c6":"markdown","82681450":"markdown","fffdd4eb":"markdown","c3bd9d9a":"markdown","b472a8ec":"markdown","d3970553":"markdown","527ec241":"markdown","863e84cd":"markdown","51b38477":"markdown"},"source":{"37ea3628":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport seaborn as sns\nfrom statistics import mode\nfrom scipy import stats\nfrom warnings import filterwarnings \nimport os\nfilterwarnings('ignore')\nprint(os.listdir(\"..\/input\/\"))\nplt.rcParams['figure.figsize'] = 10,6\n%matplotlib inline","d8875517":"train_df = pd.read_csv(\"..\/input\/train3\/train.csv\",index_col=\"Loan_ID\")\ntest_df = pd.read_csv(\"..\/input\/test-file\/test.csv\")\n\nprint('Train data shape', train_df.shape)\nprint('Test data shape', test_df.shape)\n# print(train_df.columns)","11846407":"train_df.head().style.background_gradient(cmap='Blues')","7b430609":"test_df.sample(3).style.background_gradient(cmap='Greens')","036e5ba9":"pd.DataFrame(train_df.dtypes,columns=['Data type']).T","bc18ebc1":"plt.figure(figsize=(18,6))\nplt.subplot(1,2,1)\ntrain_df.isna().sum().sort_values().plot.barh(color='blue',alpha=0.7)\nplt.title('Train data')\nplt.subplot(1,2,2)\ntest_df.isna().sum().sort_values().plot.barh(color='green',alpha=0.7)\nplt.title('Test data')\nplt.show()","78792cda":"def get_null_columns(df):\n    null_cols = df.isna().sum().sort_values(ascending=False)\n    null_cols = null_cols[null_cols > 0]\n    if len(null_cols):\n        plt.title('Null value count before imputation')\n        sns.barplot(null_cols.values,null_cols.index)\n        return null_cols\n    else:\n        return None\n    \ndef get_num_cols(df):\n    return df.select_dtypes(include=\"number\").columns.values\n\ndef get_cat_cols(df):\n    return df.select_dtypes(exclude=\"number\").columns.values\n\ndef treat_null_cols(df):\n    nulls= get_null_columns(df)\n    \n    if nulls is not None:\n        null_columns = nulls.index.values.tolist()\n        for col in null_columns:\n            if df[col].dtype == 'object':\n                df.loc[:,col]=df.loc[:,col].fillna(method='ffill')\n                df.loc[:,col]=df.loc[:,col].fillna(method='bfill')\n            # Numerical columns    \n            elif col in (\"Credit_History\",\"Loan_Amount_Term\"):\n                df[col].fillna(df[col].mode()[0],inplace=True)\n            else:\n                df[col].fillna(df[col].median(),inplace=True)\n        print(\"Columns after imputation\".center(38,'='))\n        df.info()\n    else:\n        print('No null values !')","7518bcff":"treat_null_cols(train_df)","201d9837":"treat_null_cols(test_df)","ce32386a":"f, ax  = plt.subplots(1,2,figsize = (18,6))\nsns.countplot(train_df['Loan_Status'],ax=ax[0],palette = 'bright',alpha=0.7)\n\nloan_status_count = train_df['Loan_Status'].value_counts(normalize=True)\nloan_status_count.plot.pie(autopct=\"%.2f%%\",explode = [0,0.2],ax=ax[1])\nplt.title('% of loan approval')\nplt.show()","cdbd95c9":"plt.figure(1)\nplt.subplot(221)\ntrain_df['Gender'].value_counts().plot.pie(title='% distribution of Gender',figsize=(20,10),autopct=\"%1.1f\",explode=[0,.1])\n# train_df['Gender'].value_counts(normalize=True).plot.bar(figsize=(20,10), title= 'Gender')\n\nplt.subplot(222)\ntrain_df['Married'].value_counts().plot.pie(title='% distribution of Marital Status',autopct=\"%1.1f\",explode=[0,.1])\n\nplt.subplot(223)\ntrain_df['Self_Employed'].value_counts().plot.pie(title='% distribution of Employment type',autopct=\"%1.1f\",explode=[0,.1])\n\nplt.subplot(224)\ntrain_df['Credit_History'].value_counts().plot.pie(title='% distribution of credit history',autopct=\"%1.1f\",explode=[0,.1])\nplt.show()","96d39cf9":"plt.figure(figsize=(20, 10))\nplt.subplot(231)\nsns.countplot(train_df['Dependents'],palette=\"Accent\")\nplt.subplot(234)\ntrain_df['Dependents'].value_counts().plot.pie(cmap=\"Accent\",autopct=\"%1.1f%%\",explode=[0,0,0,0.2])\n\n\nplt.subplot(232)\nsns.countplot(train_df['Education'],palette=\"Accent\")\nplt.subplot(235)\ntrain_df['Education'].value_counts().plot.pie(cmap=\"Accent\",autopct=\"%1.1f%%\",explode=[0,0.1])\n\n\nplt.subplot(233)\nsns.countplot(train_df['Property_Area'],palette=\"Accent\")\nplt.subplot(236)\ntrain_df['Property_Area'].value_counts().plot.pie(cmap=\"Accent\",autopct=\"%1.1f%%\",explode=[0,0,0.1])\nplt.show()","749b1913":"plt.figure(1,figsize=(16,5))\nplt.subplot(121)\nprint(\"Skewness:\",train_df['ApplicantIncome'].skew())\nsns.distplot(train_df['ApplicantIncome'],fit = stats.norm);\n\nplt.subplot(122)\nsns.boxplot(train_df['ApplicantIncome'])\n\nplt.show()","7d6d13e3":"plt.figure(figsize=(14,5))\nax = sns.boxplot(data=train_df,x=\"ApplicantIncome\",y=\"Education\",palette='Blues')\nfig = plt.gcf()\nplt.tight_layout()","28203974":"plt.figure(1,figsize=(16,5))\nplt.subplot(121)\nprint(train_df['CoapplicantIncome'].skew())\nsns.distplot(train_df['CoapplicantIncome'],fit=stats.norm)\n\nplt.subplot(122)\nsns.boxplot(train_df['CoapplicantIncome'],color='c')\nfig = plt.gcf()\nplt.tight_layout()\n\nplt.figure(2,figsize=(16,5))\nax = sns.boxplot(data=train_df,x=\"CoapplicantIncome\",y=\"Education\")\nplt.show()","db50cf25":"plt.figure(1)\nplt.subplot(121)\n\n# distribution plots cannot handle NaN\ntrain_df = train_df.dropna()\nsns.distplot(train_df['LoanAmount'],fit=stats.norm)\n\nplt.subplot(122)\n# Figsize = width * length\ntrain_df['LoanAmount'].plot.box(figsize=(15,7))\nplt.tight_layout()\nprint(\"Skewness:\",train_df['LoanAmount'].skew())","c94c8118":"plt.figure(figsize=(16,5))\nlat = train_df['Loan_Amount_Term'].value_counts(normalize=True)\nsns.barplot(x=lat.values,y=lat.index, palette=\"rocket\",orient='h')\nplt.show()","519903da":"sns.countplot(train_df['Credit_History'],palette=\"spring\")\nplt.show()","c0226b1e":"# Removing Loan_Status, since it is our target variable\ncat_columns = get_cat_cols(train_df).tolist()\ncat_columns.remove('Loan_Status')\nn_cat_cols = len(cat_columns)\n\nnum_cols = get_num_cols(train_df)\nn_num_cols = len(num_cols)\n\ntarget = 'Loan_Status'","e9294a96":"fig,ax = plt.subplots(n_cat_cols,1,figsize=(8,6*n_cat_cols))\n\nfor i,col in enumerate(cat_columns):\n    # Create a cross table for stacked graph\n    pd.crosstab(train_df[col],train_df[target])\n    ct = pd.crosstab(train_df[col],train_df[target],normalize=\"index\")\n    ct.plot.barh(stacked=True,ax=ax[i])\n    \nplt.show()","de1a98aa":"groups = ['Low','Medium','High']\n\ndef get_categories(x):\n    if x < q1:\n        return groups[0]\n    elif x < q3:\n        return groups[1]\n    else:\n        return groups[2]    \n\nfor col_name in ['ApplicantIncome','CoapplicantIncome','LoanAmount']:\n    q1 = train_df[col_name].quantile(q=0.25)\n    q3 = train_df[col_name].quantile(q=0.75)\n    train_df[col_name+'_cat'] = train_df[col_name].apply(get_categories)","1460e9d6":"train_df.groupby('Loan_Status')['ApplicantIncome'].mean().plot.bar()\nplt.show()","38ab633a":"cross = pd.crosstab(train_df['ApplicantIncome_cat'],train_df['Loan_Status'],normalize=\"index\")\nprint(cross)\ncross.plot.bar(stacked=True)","3a8e269c":"cross = pd.crosstab(train_df['CoapplicantIncome_cat'],train_df['Loan_Status'],normalize=\"index\")\nprint(cross)\ncross.plot.barh(stacked=True)","7ea7cf99":"cross = pd.crosstab(train_df['LoanAmount_cat'],train_df['Loan_Status'],normalize=\"index\")\nprint(cross)\ncross.plot.barh(stacked=True)","72f90775":"train_df = train_df.drop(['ApplicantIncome_cat', 'CoapplicantIncome_cat', 'LoanAmount_cat'], axis=1)","7098d163":"# Property_Area\ncol_name=\"Property_Area\"\nd = {'Urban':2,'Semiurban':1,'Rural':0}\ntrain_df[col_name].replace(d,inplace=True)\ntest_df[col_name].replace(d,inplace=True)\n\n# Self_Employed\ncol_name=\"Self_Employed\"\nd = {'Yes':1,'No':0}\ntrain_df[col_name].replace(d,inplace=True)\ntest_df[col_name].replace(d,inplace=True)\n\n# Education\ncol_name=\"Education\"\nd ={'Graduate':1, 'Not Graduate':0}\ntrain_df[col_name].replace(d,inplace=True)\ntest_df[col_name].replace(d,inplace=True)\n\n# Married\nd = {'Yes':1,'No':0}\ntrain_df['Married'].replace(d,inplace=True)\ntest_df['Married'].replace(d,inplace=True)\n\n# Gender\ngender = {'Male':1,'Female':0}\ntrain_df['Gender'].replace(gender,inplace=True)\ntest_df['Gender'].replace(gender,inplace=True)\n\n# Dependents\nd = {'3+':3}\ntrain_df['Dependents'].replace(d,inplace=True)\ntest_df['Dependents'].replace(d,inplace=True)\n\n#Loan status\nloan_status = {'N':0,'Y':1}\ntrain_df['Loan_Status'].replace(loan_status,inplace=True)","8e9a8181":"#Loan Amount\ncol_name = 'LoanAmount'\ntrain_df[col_name] = np.log(train_df[col_name])\nprint(train_df[col_name].skew())\nax = sns.distplot(train_df[col_name],fit=stats.norm)","1c200731":"# Applicant Income\ncol_name = 'ApplicantIncome'\ntrain_df[col_name] = np.log(train_df[col_name])\nprint(train_df[col_name].skew())\nax = sns.distplot(train_df[col_name],fit=stats.norm)","73323e15":"# Coapplicant Income\ncol_name = 'CoapplicantIncome'\n# Since there are 0 values we will have to use log1p to remove infinite values\ntrain_df[col_name] = np.log1p(train_df[col_name])\nprint(train_df[col_name].skew())\nax = sns.distplot(train_df[col_name],fit=stats.norm)","3650730f":"matrix = train_df.corr()\nf, ax = plt.subplots(figsize=(12, 6))\nwith sns.axes_style(\"white\"):\n    sns.heatmap(matrix,mask=np.triu(matrix,1),annot=True,fmt=\".2f\", vmax=.8,cbar=False,cmap=\"coolwarm\");","3320605e":"# Sending out the cleaned train and test data as output.\ntrain_df.to_csv('train_clean.csv')\ntest_df.to_csv('test_clean.csv')","6a22d6fd":"**Reference**: [Analytics vidhya - Loan status prediction competition](https:\/\/datahack.analyticsvidhya.com\/contest\/practice-problem-loan-prediction-iii\/)","eaf23ba3":"---","3a85e64b":"---","2d0e5f2e":"There are many missing values in both Train and Test data, next we will impute them (replace with appropirate values).","7cf3d57e":"Now lets look at the correlation between all the numerical variables. We will use the heat map to visualize the correlation.\n\nHeatmaps visualize data through variations in coloring. The variables with darker color means their correlation is more.","22ed6280":"**Let us check whether this non uniformity in Income is due to the difference in education level**","22102c2c":"### Loan Amount Term","9ed3c34d":"- Applicant Income is left skewed (6.53).\n- Many outliers are present in the distribution.\n- Most of the applicant income is near a range of 5000.","8261c95d":"- Similar to Applicant Income, Coapplicant income is also left skewed(7.49) and not normally distributed.\n- Also, there are a numer of outliers in the distribution. One of which can be attribued to the level of education.","e5a7defc":"Having more data points with credit history might make our model better at predicting values with a history.","0b8ef3bc":"## Encoding categorical variable","55af64ab":"### Loan Amount","18b5b0ca":"# <span style=\"color:blue\">Imputing train and test data<\/span>","6186d71e":"# <span style=\"color:blue\">Output<\/span>","78a4c6e1":"### Credit history","e564f57e":"### CoapplicantIncome","cb6bee80":"---","67361ed8":"---","90ea3cee":"---","e195fb07":"Let's check for null values in the Train Test data","56232760":"---","75808af4":"Looking at the correlation map we can see that `credit history` is the most important feature for `Loan Status`, with no other feature even close to it. So existing internal customers will be always preferred over the new ones.\n\nAlso, `Applicant Income` and `LoanAmount` are correlated with each other.","d343427b":"### Gender, Married, Self_Employed, Credit_History\n**Nominal variables**","d4d90d36":"### Categorical vs Target Variable","35e8e611":"From the above chart we can see that most of the people who applied for loans were either `Males`, `Married`, `No self employment` or `Had a credit history`.","11babb28":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#About-the-company\" data-toc-modified-id=\"About-the-company-1\"><span style=\"color: blue\">About the company<\/span><\/a><\/span><\/li><li><span><a href=\"#Business-problem\" data-toc-modified-id=\"Business-problem-2\"><span style=\"color: blue\">Business problem<\/span><\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#This-notebook-has-two-parts:\" data-toc-modified-id=\"This-notebook-has-two-parts:-2.1\"><em>This notebook has two parts:<\/em><\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Import-libraries\" data-toc-modified-id=\"Import-libraries-3\"><span style=\"color: blue\">Import libraries<\/span><\/a><\/span><\/li><li><span><a href=\"#Get-to-know-your-data\" data-toc-modified-id=\"Get-to-know-your-data-4\"><span style=\"color: blue\">Get to know your data<\/span><\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Train-data\" data-toc-modified-id=\"Train-data-4.1\"><em>Train data<\/em><\/a><\/span><\/li><li><span><a href=\"#Test-data\" data-toc-modified-id=\"Test-data-4.2\"><em>Test data<\/em><\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Some-helper-functions-for-null-value-treatment\" data-toc-modified-id=\"Some-helper-functions-for-null-value-treatment-5\"><span style=\"color: blue\">Some helper functions for null value treatment<\/span><\/a><\/span><\/li><li><span><a href=\"#Imputing-train-and-test-data\" data-toc-modified-id=\"Imputing-train-and-test-data-6\"><span style=\"color: blue\">Imputing train and test data<\/span><\/a><\/span><\/li><li><span><a href=\"#Exploratory-data-analysis\" data-toc-modified-id=\"Exploratory-data-analysis-7\"><span style=\"color: blue\">Exploratory data analysis<\/span><\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Univariate-analysis\" data-toc-modified-id=\"Univariate-analysis-7.1\">Univariate analysis<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Loan-status\" data-toc-modified-id=\"Loan-status-7.1.1\">Loan status<\/a><\/span><\/li><li><span><a href=\"#Gender,-Married,-Self_Employed,-Credit_History\" data-toc-modified-id=\"Gender,-Married,-Self_Employed,-Credit_History-7.1.2\">Gender, Married, Self_Employed, Credit_History<\/a><\/span><\/li><li><span><a href=\"#Dependents,-Education,-Property_Area\" data-toc-modified-id=\"Dependents,-Education,-Property_Area-7.1.3\">Dependents, Education, Property_Area<\/a><\/span><\/li><li><span><a href=\"#Applicant-Income\" data-toc-modified-id=\"Applicant-Income-7.1.4\">Applicant Income<\/a><\/span><\/li><li><span><a href=\"#Coapplicant-Income\" data-toc-modified-id=\"Coapplicant-Income-7.1.5\">Coapplicant Income<\/a><\/span><\/li><li><span><a href=\"#Loan-Amount\" data-toc-modified-id=\"Loan-Amount-7.1.6\">Loan Amount<\/a><\/span><\/li><li><span><a href=\"#Loan-Amount-Term\" data-toc-modified-id=\"Loan-Amount-Term-7.1.7\">Loan Amount Term<\/a><\/span><\/li><li><span><a href=\"#Credit-history\" data-toc-modified-id=\"Credit-history-7.1.8\">Credit history<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Bivariate-Analysis\" data-toc-modified-id=\"Bivariate-Analysis-7.2\">Bivariate Analysis<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Categorical-vs-Target-Variable\" data-toc-modified-id=\"Categorical-vs-Target-Variable-7.2.1\">Categorical vs Target Variable<\/a><\/span><\/li><li><span><a href=\"#Numerical-vs-Target-Variable\" data-toc-modified-id=\"Numerical-vs-Target-Variable-7.2.2\">Numerical vs Target Variable<\/a><\/span><\/li><li><span><a href=\"#ApplicantIncome\" data-toc-modified-id=\"ApplicantIncome-7.2.3\">ApplicantIncome<\/a><\/span><\/li><li><span><a href=\"#CoapplicantIncome\" data-toc-modified-id=\"CoapplicantIncome-7.2.4\">CoapplicantIncome<\/a><\/span><\/li><li><span><a href=\"#Loan-amount\" data-toc-modified-id=\"Loan-amount-7.2.5\">Loan amount<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#Data-preparation\" data-toc-modified-id=\"Data-preparation-8\"><span style=\"color: blue\">Data preparation<\/span><\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Encoding-categorical-variable\" data-toc-modified-id=\"Encoding-categorical-variable-8.1\">Encoding categorical variable<\/a><\/span><\/li><li><span><a href=\"#Reducing-skewness\" data-toc-modified-id=\"Reducing-skewness-8.2\">Reducing skewness<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Output\" data-toc-modified-id=\"Output-9\"><span style=\"color: blue\">Output<\/span><\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Link-to-part-2\" data-toc-modified-id=\"Link-to-part-2-9.1\"><a href=\"https:\/\/www.kaggle.com\/psvishnu\/loan-prediction-part-2\/\" target=\"_blank\">Link to part 2<\/a><\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Show-your-support-by-upvoting-the-kernel-\ud83d\udc4d\" data-toc-modified-id=\"Show-your-support-by-upvoting-the-kernel-\ud83d\udc4d-9.1.1\">Show your support by upvoting the kernel \ud83d\udc4d<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/div>","d6046f66":"### Applicant Income","c3f9d28e":"# <span style=\"color:blue\">Get to know your data<\/span>","7f2dafae":"From the above charts we can infer that, \n- Most of the applicants(57.6%) did not have any dependants\n- 78.2% are Graduates applying for loan.\n- Eventhough most of the applicants are from Semiurban, an almost equal distribution can be seen among other categories.","1ce6cbf5":"## Bivariate Analysis","38e3f1bf":"### Dependents, Education, Property_Area\n**Ordinal Variables**","deeb44c3":"### ApplicantIncome","cc805279":"Imputing null values with mean, median or mode value is a straight forward method.\n\nBut for best quality data we should impute based on the domain knowledge of the column. One important drawback of first method, if the number of null values are more then it can introduce spikes in the distribution.\n\nIn this case, we will be replacing the null values with forward\/backward fill method. This method is fast and maintains the overall distribution of the data.","dba1f5e5":"Either most of the applicant opted for a specific 30 year (360 months) term followed by 15 years (180 month) term or our sample data is having more of such datapoints.","f8d7be3e":"We can see an imbalance here, the number of **Loan approved is more than twice the rejections.**","9aa29b47":"We have two types of variables in our dataframe - *categorical and numerical.*\n\n**1. Categorical features**\n- Nominal features: These features have categories (Gender, Married, Self_Employed, Credit_History, Loan_Status).\n- Ordinal features: Variables in categorical features having some order involved (Dependents, Education, Property_Area).\n\n**2. Numerical features**: \n- Continuous features: These features have continuously distributed values (ApplicantIncome, CoapplicantIncome, LoanAmount).\n- Discrete featuress: Values in these columns are unique and non-continous in nature( Loan_Amount_Term, Credit_history ).","20510cf7":"## Reducing skewness","f7702eb5":"### Coapplicant Income","f1661018":"---","b96720a0":"It can be seen that the proportion of approved loans is higher for Low and Medium Loan Amount as compared to that of High Loan Amount.","d3f24e34":"**Numerical Variables**","b01d73ef":"---","08c7c655":"### Loan status \n**Dependant variable**","4378541f":"# <span style=\"color:blue\">Exploratory data analysis<\/span>","b8813153":"---","896e8a2d":"---","dd086134":"## Univariate analysis\n\n> For categorical features we can use frequency table or % distribution which will calculate the value per category.\n\n> For numerical features, probability density plots can be used to check the distribution of the variable.","8ce41cdc":"---","71cc42c2":"It can be inferred that Applicant income does not affect the chances of loan approval which contradicts our hypothesis where we assumed that if the applicant income is high the chances of loan approval will also be high.","261fc7c0":"Load all the necessary dependencies which will be required for the purpose of analysis.","8f631f22":"Lets make some new features for performing better EDA.\n\nThree bins Low, Medium and High each for\n1. Applicant Income\n2. Coapplicant Income\n3. LoanAmount","51658cc0":"# <span style=\"color:blue\">About the company<\/span>\n\nDream Housing Finance company deals in all home loans. They have presence across all urban, semi urban and rural areas. Customer first apply for home loan after that company validates the customer eligibility for loan.\n\n# <span style=\"color:blue\">Business problem<\/span>\nCompany wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers. Here they have provided a partial data set.","e1fce607":"- There was no significant pattern observed based on the `gender` or `Self_Employed` status.\n- Proportion of `married applicants` is higher for the approved loans.\n- If one is having 2 `Dependents` the person is having more approval rate compared to `0`(no dependent) or other dependents number, which is quite strange.\n- `Graduates` were having more loan approval rate than their counterpart.\n- Property area plays a role in approval too, but most of it belongs to `Suburban` region rather than `Urban` or `Rural`.","747e7005":"### Numerical vs Target Variable","6bd2f917":"# <span style=\"color:blue\">Some helper functions for null value treatment<\/span>","bed7d7af":"## *Train data*","fd5901b0":"<center><img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcTQ2OEfjwBg26hXQEle2XqFBDp0coC1dVugLBxLZ_5_EFTIS20O\" \n             width=\"650px\"><\/center>","c9fe0dfc":"## *Test data*","256ec47e":"It can be observed that variation in Application income is more among individuals who are Graduates.","ba447632":"---","f6f57239":"In the next part, we will perform\n- baseline model\n- feature engineering\n- evaluation metrics for classification models\n- model selection \n- hyperparameter tuning\n\n## [Link to part 2](https:\/\/www.kaggle.com\/psvishnu\/loan-prediction-part-2\/)\n\n<h3 style='color:red'>Show your support by upvoting the kernel \ud83d\udc4d<\/h3> ","28010d5f":"# <span style=\"color:blue\">Import libraries<\/span>","cfb588c6":"The above three columns(Applicant income, coapplicant income and loan amount) have outliers and a high level of skewness.\n\nWe can later use `log transformation` to remove the skewness and it will even help to scale down the outliers.","82681450":"We will try to find answers to questions like these\n1. Is gender or being self employed a factor for loan approvals?\n2. Does being married decreases your chance of getting a loan?\n3. Does having lower number of dependants gives you an upper hand?\n4. Will being in Urban location make loan approval easy?","fffdd4eb":"---","c3bd9d9a":"There are not much changes in the mean income. \n\nLets check based on applicant income category.","b472a8ec":"## *This notebook has two parts:*\n\n**Part 1: [Data exploration & cleaning](https:\/\/www.kaggle.com\/psvishnu\/loan-prediction-part-1\/)**\n    \n**Part 2: [Modelling & Tuning](https:\/\/www.kaggle.com\/psvishnu\/loan-prediction-part-2\/)**\n","d3970553":"Discrete Numeric values","527ec241":"---\n### Loan amount ","863e84cd":"# <span style=\"color:blue\">Data preparation<\/span>\n\n- Let\u2019s drop the bins which we created for EDA. \n- Categorical columns: We will encode the categorical columns to numbers.\n- Numerical columns: There were continuous numerical variables with outliers and skewness, those will be transformed by applying log operation.\n\nWe will also convert the target variable\u2019s categories into 0 and 1 so that we can find its correlation with numerical variables. One more reason to do so is that few models like logistic regression only understands numeric values as input. We will replace N with 0 and Y with 1.","51b38477":"---"}}