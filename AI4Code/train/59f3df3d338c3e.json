{"cell_type":{"09cfe9bb":"code","7aade214":"code","e417e4d7":"code","85fa1d84":"code","18f9fac7":"code","4f582a49":"code","68f8a949":"code","033c679f":"code","f7967b2f":"code","243d4482":"code","a60aa0cf":"code","025e985a":"code","e2a7d023":"code","fc6db674":"markdown","38e65003":"markdown"},"source":{"09cfe9bb":"import xarray as xr\nimport numpy as np\nimport pandas as pd\nimport os\nimport posixpath as path\nimport cv2\nfrom scipy.interpolate import griddata\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nnp.set_printoptions(threshold=1e6)\n\n# !!!!!!!!!!! ERA5 data !!!!!!!!!!!!!!!!!!\nERA_filename = '\/kaggle\/input\/maria-era5-giirs-flow\/era5_Maria_20180710.nc'  # .nc\u6587\u4ef6\u540d\nfile = xr.open_dataset(ERA_filename)  \n# print(file.time)  # 2018-07-10T00:00 ~ 23:00\n\nlon_range = file.longitude[(file.longitude >= 111) & (file.longitude < 131)]  # 111~130.75\nlat_range = file.latitude[(file.latitude >= 16) & (file.latitude < 31)]  # 16~30.75\nERA_data = file.sel(longitude=lon_range, latitude=lat_range)\n\n# print(data['longitude']) # [111~130.75] # 80\n# print(data['latitude'])  # [30.75~16]!!!!\u6ce8\u610f\u8fd9\u91cc\u7eac\u5ea6\u7684\u5927\u5c0f\u65b9\u5411\n# print(data['latitude'][::-1]) \n\nU_ERA5 = ERA_data['u'][4,:,::-1,:]  # shape:(24, 37, 60, 80)!!!!\u6ce8\u610f\u8fd9\u91cc\u5c06\u7eac\u5ea6(60)\u9006\u5411\u4e86\nV_ERA5 = ERA_data['v'][4,:,::-1,:]\nprint(U_ERA5.shape)","7aade214":"# !!!!!!!!!! Optical Flow data !!!!!!!!!!!!!\nbias_file = '\/kaggle\/input\/maria-era5-giirs-flow\/'\\\n'diags_fy4-1-giirs_2018071000_V0.nc_giirs_detector_bias.txt'  # 128x1650 row\nbias = np.loadtxt(bias_file, skiprows=1)\n\n# .nc files path\n# dir_path = '\/kaggle\/input\/maria-era5-giirs-flow\/2018071000_2018071001_update_SPECCAL_NEW_on20191024\/'\n# dir_path = '\/kaggle\/input\/maria-era5-giirs-flow\/2018071002_2018071003_011_update_SPECCAL_NEW_on20191024\/'\n# dir_path = '\/kaggle\/input\/maria-era5-giirs-flow\/2018071003_2018071004_011_update_SPECCAL_NEW_on20191024\/'\ndir_path = '\/kaggle\/input\/maria-era5-giirs-flow\/2018071004_2018071005_update_SPECCAL_NEW_on20191024\/'\n# dir_path = '\/kaggle\/input\/maria-era5-giirs-flow\/2018071005_2018071006_update_SPECCAL_NEW_on20191024\/'\ndirFiles = os.listdir(dir_path)  # \u8def\u5f84\u4e0b\u6240\u6709\u6587\u4ef6\ndirFiles.sort()\n\n\ndef planckInvert(v, L):\n    \"\"\"\n    https:\/\/ncc.nesdis.noaa.gov\/data\/planck.html\n    input: v means wavenumber in cm^-1\n            L means blackbody radiance in mW\/m^2\/sr\/cm^-1;\n    output: Tb means Brightness Temperature in K\n    \"\"\"\n    c1 = 1.191042722e-5  # units: mW\/(m2 sr cm-4)\n    c2 = 1.4387752  # units: (K cm)\n    Tb = (c2 * v) \/ np.log((c1 * (v ** 3)) \/ L + 1.)\n    return Tb\n\n\ndef cal_Tb(file_ob):\n    ds = xr.open_dataset(file_ob, decode_times=False)\n    # print(ds)\n    ES_RealLW = ds['ES_RealLW'].data  # \u7ecf\u8fc7\u5b9a\u6807\u5904\u7406\u7684\u957f\u6ce2\u8f90\u5c04\u503c(\u5b9e\u90e8); units: mW\/(m2 sr cm-1); [689*128]\n    ES_RealMW = ds['ES_RealMW'].data  # \u4e2d\u6ce2\u8f90\u5c04\u503c(\u5b9e\u90e8)\uff1a[961*128]\n    lat_lw = ds['IRLW_Latitude'].data  #\n    lon_lw = ds['IRLW_Longitude'].data\n    lat_mw = ds['IRMW_Latitude'].data\n    lon_mw = ds['IRMW_Longitude'].data\n\n    num_lw = 689\n    num_mw = 961\n    wn_lw = 700.0 + np.arange(0, num_lw) * 0.625  # \u957f\u6ce2\u8986\u76d6700\u20141130 cm^(-1),\u5171689\u4e2a\u901a\u9053\uff0c\u5176\u5149\u8c31\u5206\u8fa8\u7387\u7ea60.625\n    wn_mw = 1650.0 + np.arange(0, num_mw) * 0.625  # \u4e2d\u6ce2\u8986\u76d61650-2250 cm^(-1),\u5171961\u4e2a\u901a\u9053\uff0c\u5176\u5149\u8c31\u5206\u8fa8\u7387\u7ea60.625\n\n    Tb_lw = []\n    for i in range(0, num_lw):\n        Tb_lw.append(planckInvert(wn_lw[i], ES_RealLW[i]))\n    Tb_mw = []\n    for i in range(0, num_mw):\n        Tb_mw.append(planckInvert(wn_mw[i], ES_RealMW[i]))\n    Tb_all = np.vstack((Tb_lw, Tb_mw))  # \u6cbf\u7740\u7ad6\u76f4\u65b9\u5411\u5c06\u77e9\u9635\u5806\u53e0\u8d77\u6765\n    return Tb_all, lat_lw, lon_lw, lat_mw, lon_mw\n\n\ndef cal_allfield(ch, n):\n    \"\"\"\n    :param ch: calculate single channel once time\n    :param n: n is file index. Use loops to combine all data in the same observation\n    :returns: T_all, lat_all, lon_all  ###size=(51*128) ### \u6b64\u65f6\u5c1a\u672a\u63d2\u503c\uff0c\u53ea\u6709\u9a7b\u70b9\u7684\u503c!!!!!\n    \"\"\"\n\n    T_all = []\n    lat_all = []\n    lon_all = []\n    for i in range(n, n + 17 * 3):\n        file = path.join(dir_path, dirFiles[i])\n        c, d, e, f, g = cal_Tb(file)  # (1650, 128)\n        c = c - bias\n        T_all.append(c[ch])\n        if ch < 689:\n            lat_all.append(d)\n            lon_all.append(e)\n        else:\n            lat_all.append(f)\n            lon_all.append(g)\n    T_all = np.array(T_all)  # (51, 128),where 51 = 17*3\n    lat_all = np.array(lat_all)\n    lon_all = np.array(lon_all)\n    return T_all, lat_all, lon_all\n\n\ndef interp_grid(T_discrete, la_discrete, lo_discrete, lat_grid, lon_grid):\n    \"\"\"\n    2D interpolation.\n    Interpolate the original discrete points (GIIRS obs points) to the grid points.\n    Note: T_discrete is No missing values\n    ** Ori_data shape: (51, 128), where 51 = 17 * 3; After_Interp_data shape: (150, 200) **\n    \"\"\"\n\n    T_discrete = T_discrete.flatten()  # np.flatten\u8fd4\u56de\u4e00\u4e2a\u6298\u53e0\u6210\u4e00\u7ef4\u7684\u6570\u7ec4\n    df = pd.DataFrame(T_discrete)\n    df.fillna(method='ffill', axis=0, inplace=True)\n    T_discrete = df.values.flatten()\n    la_discrete = la_discrete.reshape(-1, 1)\n    lo_discrete = lo_discrete.reshape(-1, 1)\n    points = np.hstack((lo_discrete, la_discrete))  # \u6cbf\u7740\u6c34\u5e73\u65b9\u5411\u5c06\u77e9\u9635\u5806\u53e0\u8d77\u6765\n\n    grid = griddata(points, T_discrete, (lon_grid, lat_grid), method='cubic')\n    return grid\n\n\ndef cal_Optical_flow_on_map(ich, lat_grid, lon_grid, n_1, n_2):\n    \"\"\"\n    \u8ba1\u7b97\u5149\u6d41\n    \"\"\"\n    f1, la1, lo1 = cal_allfield(ich, n_1)\n    grid1 = interp_grid(f1, la1, lo1, lat_grid, lon_grid)\n\n    f2, la2, lo2 = cal_allfield(ich, n_2)\n    grid2 = interp_grid(f2, la2, lo2, lat_grid, lon_grid)\n\n    valMax = 350\n    valMin = 180\n    flow = cv2.calcOpticalFlowFarneback(np.array((np.round((grid1 - valMin) * 255.0 \/ (valMax - valMin))), np.int), \\\n                                        np.array((np.round((grid2 - valMin) * 255.0 \/ (valMax - valMin))), np.int), \\\n                                        pyr_scale=0.5, levels=3, winsize=15, iterations=3, \\\n                                        poly_n=5, poly_sigma=1.2, flags=1, flow=None)\n    flow[:, :, 0] = cv2.bilateralFilter(flow[:, :, 0], 9, 20, 20)\n    flow[:, :, 1] = cv2.bilateralFilter(flow[:, :, 1], 9, 20, 20)\n    u = flow[:, :, 0] * 10 * 1000 \/ (15 * 60)   # (150, 200)\n    v = flow[:, :, 1] * 10 * 1000 \/ (15 * 60)\n    yy = np.arange(0, grid1.shape[0], 2.5).astype(np.int)\n    xx = np.arange(0, grid1.shape[1], 2.5).astype(np.int)\n    x, y = np.meshgrid(xx, yy)  # shape of x,y: (60, 80); \u5b9e\u73b0\u4e86(150, 200)\u5230(60, 80)\n    return u[y, x], v[y, x], grid1[y, x]\n\n\n# The lat and lon grid points are delimited based on the original data(la1, lo1) and are smaller\nlat_grid = np.arange(16.0, 31.0, 0.1)\nlon_grid = np.arange(111.0, 131.0, 0.1)\nlon_grid, lat_grid = np.meshgrid(lon_grid, lat_grid)\n\nn_s = [0, 51]\nfor i in range(0, len(n_s)-1):\n    obs_time = dirFiles[n_s[i]]\n    obs_time = obs_time[44:73]  # \u63d0\u53d6nc\u6587\u4ef6\u540d\u4e2d\u7684time\u5b57\u6bb5\u6765\u4f5c\u4e3a\u56fe\u7247\u7684title\n    print(obs_time)\n    u_f1, v_f1, BT_f1 = cal_Optical_flow_on_map(919, lat_grid, lon_grid, n_s[i], n_s[i + 1])\n    u_f2, v_f2, BT_f2 = cal_Optical_flow_on_map(924, lat_grid, lon_grid, n_s[i], n_s[i + 1])\n    u_f3, v_f3, BT_f3 = cal_Optical_flow_on_map(952, lat_grid, lon_grid, n_s[i], n_s[i + 1])\n    u_f4, v_f4, BT_f4 = cal_Optical_flow_on_map(1046, lat_grid, lon_grid, n_s[i], n_s[i + 1])\n    u_f5, v_f5, BT_f5 = cal_Optical_flow_on_map(960, lat_grid, lon_grid, n_s[i], n_s[i + 1])\n    u_f6, v_f6, BT_f6 = cal_Optical_flow_on_map(1018, lat_grid, lon_grid, n_s[i], n_s[i + 1])\n    u_f7, v_f7, BT_f7 = cal_Optical_flow_on_map(1061, lat_grid, lon_grid, n_s[i], n_s[i + 1])\n    u_f8, v_f8, BT_f8 = cal_Optical_flow_on_map(1090, lat_grid, lon_grid, n_s[i], n_s[i + 1])\n    u_f9, v_f9, BT_f9 = cal_Optical_flow_on_map(1028, lat_grid, lon_grid, n_s[i], n_s[i + 1])\n\n    u_flow_data = np.stack((u_f1, u_f2, u_f3, u_f4, u_f5, u_f6, u_f7, u_f8, u_f9), axis=2)\n    v_flow_data = np.stack((v_f1, v_f2, v_f3, v_f4, v_f5, v_f6, v_f7, v_f8, v_f9), axis=2)\n    BT_flow_data = np.stack((BT_f1, BT_f2, BT_f3, BT_f4, BT_f5, BT_f6, BT_f7, BT_f8, BT_f9), axis=2)\n    print(u_flow_data.shape)\n    print(BT_flow_data.shape)","e417e4d7":"U_flow = u_flow_data.reshape(4800,9) #(60, 80, 9)=>(4800,9) \u6bcf\u4e2a\u683c\u70b9\u4e00\u884c,\u5148\u56fa\u5b9a\u7eac\u5ea6\uff0c\u9010\u4e2a\u7ecf\u5ea6\u8f93\u51fa\uff0c\u4ee5\u7eac\u5ea6\u4e3a\u5916\u5faa\u73af 16~31\uff0c111~131,\u6bcf0.25\u683c\u8ddd\nV_flow = v_flow_data.reshape(4800,9)\nBT_flow = BT_flow_data.reshape(4800,9) \n# print(U_flow[0])\n# print(U_flow[2294])\n\n# U_ERA5[:,0,79] => U_ERA5_new[79,:]; U_ERA5[:,1,0] => U_ERA5_new[80,:]\nU_ERA5_new = U_ERA5.values.reshape(37, -1).swapaxes(1,0) # (4800, 37)\nV_ERA5_new = V_ERA5.values.reshape(37, -1).swapaxes(1,0)\n# print(U_ERA5_new[0])    # (16\u00b0N, 111\u00b0E)\n# print(U_ERA5_new[2294]) # (23\u00b0N, 124.5\u00b0E)","85fa1d84":"import matplotlib.pyplot as plt\nfrom matplotlib.pyplot import MultipleLocator\n\nflow_pressure = np.array([286.26, 328.67, 575.53, 596.31, 639.14, 683.67, 753.67, 802.37, 827.37])\nERA5_pressure = np.array(ERA_data.level)\n# print(flow_pressure)\n# print(ERA5_pressure)\n\ndef plot_profile_uv(u_flow_plot, v_flow_plot, p_flow_plot,u_ERA_plot, v_ERA_plot, p_ERA_plot):\n    fig = plt.figure(figsize=(10, 7.1), dpi=450)\n    ax1 = fig.add_subplot(121)\n    plt.plot(u_flow_plot, p_flow_plot, 'o-', label=\"U_flow\", linewidth=1.5)\n    plt.plot(u_ERA_plot, p_ERA_plot, 's-', label=\"U_ERA\", linewidth=1.5)\n    plt.axvline(x=0, color='k', linestyle='--')\n    plt.ylabel(\"Pressure(hPa)\")  # fontsize=10, fontweight='bold'\n    plt.xlabel(\"U wind(m\/s)\")  # fontsize=10, fontweight='bold'\n    ax1.invert_yaxis()\n    x_major_locator = MultipleLocator(5)\n    ax1.xaxis.set_major_locator(x_major_locator)\n    #\u628ax\u8f74\u7684\u4e3b\u523b\u5ea6\u8bbe\u7f6e\u4e3a1\u7684\u500d\u6570\n    plt.legend()\n\n    ax2 = fig.add_subplot(122)\n    ax2.plot(v_flow_plot, p_flow_plot, 'o-', label=\"V_flow\", linewidth=1.5)\n    ax2.plot(u_ERA_plot, p_ERA_plot, 's-', label=\"V_ERA\",  linewidth=1.5)\n    # plt.axvline(x=0, color='k', linestyle='--')\n    plt.xlabel(\"V wind(m\/s)\")  # fontsize=10, fontweight='bold'\n    ax2.invert_yaxis()\n    x_major_locator = MultipleLocator(5)\n    ax2.xaxis.set_major_locator(x_major_locator)\n    plt.legend()\n\n    plt.suptitle(\"20180709 04 lat:23.00 lon:124.50\")\n    plt.show()\n    \nplot_profile_uv(U_flow[2294],V_flow[2294],flow_pressure,U_ERA5_new[2294],V_ERA5_new[2294],ERA5_pressure)","18f9fac7":"from sklearn.preprocessing import MinMaxScaler # \u6807\u51c6\u5316\nscaler = MinMaxScaler(feature_range=(0, 1))\n\nU_flow_stand = scaler.fit_transform(U_flow)\n# print(U_flow_stand[0:2])\nU_flow_true = scaler.inverse_transform(U_flow_stand)\n# print(U_flow_true[0])\n\nV_flow_stand = scaler.fit_transform(V_flow)\nBT_flow_stand = scaler.fit_transform(BT_flow)\nFlow_data_stand = np.stack((U_flow_stand, V_flow_stand, BT_flow_stand), axis=2)\n# print(Flow_data_stand.shape)\n# print(Flow_data_stand[0,:,:])\n\nU_ERA5_stand = scaler.fit_transform(U_ERA5_new)\n# print(U_ERA5_stand[2294])\n# print(\"#####\")\nU_ERA5_true = scaler.inverse_transform(U_ERA5_stand)\n# print(U_ERA5_true[2294])\n\nV_ERA5_stand = scaler.fit_transform(V_ERA5_new)\n# print(V_ERA5_stand[2294])\n# print(\"#####\")\nV_ERA5_true = scaler.inverse_transform(V_ERA5_stand)\n# print(V_ERA5_true[2294])","4f582a49":"import gc\nimport sys\nimport unicodedata\nimport io\nimport time\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import CSVLogger, EarlyStopping\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n# \u601d\u8def\uff1a3-in-1-out, \u5982\u679c\u53ef\u4ee5\u5e0c\u671b\u505a\u62103-in-2-out\n\n# \u7279\u5f81\u503c\uff1a\u4e00\u4e2a\u683c\u70b9,9\u4e2a\u901a\u9053,\u6bcf\u4e2a\u901a\u90533\u4e2a\u503cu_flow,v_flow,BT_flow  (4800, 9, 3)\n# \u76ee\u6807\u503c\uff1a\u4e00\u4e2a\u683c\u70b9,37level,\u6bcf\u4e2alevel\u4e00\u4e2a\u503cu\u6216\u80051\u4e2av  (4800, 37)\ninput_tensor  = np.array(Flow_data_stand) \ntarget_tensor = np.array(U_ERA5_stand)\nprint(input_tensor.shape)\nprint(target_tensor.shape)\n# \u91c7\u7528 90 - 10 \u7684\u6bd4\u4f8b\u5207\u5206\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u3002train_test_split\u662f\u6765\u81easklearn\u7684\u6570\u636e\u96c6\u5212\u5206\u5de5\u5177\u3002\ninput_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1)\n\n# \u770b\u4e00\u4e0b\u6570\u636e\u957f\u5ea6\nprint(input_tensor_train.shape, target_tensor_train.shape, input_tensor_val.shape, target_tensor_val.shape)\n# print(target_tensor_train[2294]) # \u4e0e\u4e4b\u524d\u7684\u987a\u5e8f\u4e0d\u4e00\u81f4\u4e86\uff0c\u8fd9\u91cc\u662f\u968f\u673a\u5212\u5206\u7684","68f8a949":"BATCH_SIZE = 128\nBUFFER_SIZE = 1000\nfuture_target = 37 # \u76ee\u6807\u662f\u7f6e\u6362\u621037\u5c42\u7684\u6570\u636e\n\ntrain_data_multi = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\ntrain_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n\n\nval_data_multi = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\nval_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()\n\n# for x, y in train_data_multi.take(1):\n#     print(x.shape)\n#     print(y.shape)\n# for x, y in val_data_multi.take(1):\n#     print(x.shape)\n#     print(y.shape)","033c679f":"multi_step_model = tf.keras.models.Sequential()\nmulti_step_model.add(tf.keras.layers.LSTM(32,\n                                          return_sequences=True,\n                                          input_shape=input_tensor_train.shape[-2:]))\nmulti_step_model.add(tf.keras.layers.LSTM(16, activation='relu'))\nmulti_step_model.add(tf.keras.layers.Dense(37))\n\nmulti_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')\nprint(multi_step_model.summary())\n\n# for x, y in train_data_multi.take(1):\n#     print(x.shape)\n#     print(y.shape)\n#     print(x[0])\n#     print (multi_step_model.predict(x).shape)","f7967b2f":"from tensorflow import keras\nEPOCHS = 40\nPATIENCE = 5\nEVALUATION_INTERVAL = 400\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience = 3, restore_best_weights=True)\nmulti_step_history = multi_step_model.fit(train_data_multi,\n                                          epochs=EPOCHS,\n                                          steps_per_epoch=EVALUATION_INTERVAL,\n                                          validation_data=val_data_multi,\n                                          validation_steps=EVALUATION_INTERVAL,\n                                          callbacks=[early_stopping])\nkeras.models.save_model(multi_step_model, \"Maria_U_train_model_5.h5\")","243d4482":"# \u8bc4\u4ef7\u51fd\u6570\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error\n\ndef evaluation_model(test_X, test_Y):\n    y_pred_stand = multi_step_model.predict(test_X) \n    y_pred_true = scaler.inverse_transform(y_pred_stand) \n    y_true = scaler.inverse_transform(test_Y)\n#     print(y_true.shape)\n\n    rmse = sqrt(mean_squared_error(y_true, y_pred_true))\n    return 'Test RMSE: %.3f' % rmse\n\n\n# \u8bc4\u4f30\u8bad\u7ec3\u96c6\u6548\u679c\nevaluation_model_train = evaluation_model(input_tensor_train, target_tensor_train)\nprint(evaluation_model_train)\n# \u8bc4\u4f30\u96c6\u6d4b\u8bd5\u6548\u679c\nevaluation_model_val = evaluation_model(input_tensor_val, target_tensor_val)\nprint(evaluation_model_val)\n# \u8bc4\u4f30\u6574\u4e2a\u6570\u636e\u96c6\u6548\u679c:\nevaluation_model_all = evaluation_model(Flow_data_stand, U_ERA5_stand)\nprint(evaluation_model_all)","a60aa0cf":"# \u60f3\u8981\u753b\u4e0b\u6295\u63a2\u7a7a\u6570\u636epoint11\u7684\u5ed3\u7ebf[23.00,124.50],\u5bf9\u5e94\u8bad\u7ec3\u96c6\u4e2d\u7684\u7b2c2294\u4e2a\u70b9\ndef plot_pred_result_u(test_X, test_Y, p_ERA_plot,n_index):\n    \n    y_pred_stand = multi_step_model.predict(test_X) \n    y_pred_true = scaler.inverse_transform(y_pred_stand) \n    y_true = scaler.inverse_transform(test_Y)\n    \n    print(y_true[n_index])\n    print(y_pred_true[n_index])\n    \n    fig = plt.figure(figsize=(5, 6.1), dpi=450)\n    ax1 = fig.add_subplot(111)\n\n    plt.plot(y_true[n_index], p_ERA_plot, 's-', label=\"U_ERA5\", linewidth=1.5)\n    plt.plot(y_pred_true[n_index], p_ERA_plot, 's-', label=\"U_pred\", linewidth=1.5)\n    plt.axvline(x=0, color='k', linestyle='--')\n    plt.ylabel(\"Pressure(hPa)\")  # fontsize=10, fontweight='bold'\n    plt.xlabel(\"U wind(m\/s)\")  # fontsize=10, fontweight='bold'\n    ax1.invert_yaxis()\n    x_major_locator = MultipleLocator(5)\n    ax1.xaxis.set_major_locator(x_major_locator)\n    #\u628ax\u8f74\u7684\u4e3b\u523b\u5ea6\u8bbe\u7f6e\u4e3a1\u7684\u500d\u6570\n    plt.legend()\n\n    plt.suptitle(\"20180709 04 lat:23.00 lon:124.50\")\n    plt.show()\n    \nplot_pred_result_u(Flow_data_stand, U_ERA5_stand, ERA5_pressure,2294)","025e985a":"# \u7279\u5f81\u503c\uff1a\u4e00\u4e2a\u683c\u70b9,9\u4e2a\u901a\u9053,\u6bcf\u4e2a\u901a\u90533\u4e2a\u503cu_flow,v_flow,BT_flow  (4800, 9, 3)\n# \u76ee\u6807\u503c\uff1a\u4e00\u4e2a\u683c\u70b9,37level,\u6bcf\u4e2alevel\u4e00\u4e2a\u503cu\u6216\u80051\u4e2av  (4800, 37)\ninput_tensor  = np.array(Flow_data_stand) \ntarget_tensor = np.array(V_ERA5_stand)  # !!!!!!!!!!\n# print(input_tensor.shape)\n# print(target_tensor.shape)\n# \u91c7\u7528 90 - 10 \u7684\u6bd4\u4f8b\u5207\u5206\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u3002train_test_split\u662f\u6765\u81easklearn\u7684\u6570\u636e\u96c6\u5212\u5206\u5de5\u5177\u3002\ninput_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1)\n\n# \u770b\u4e00\u4e0b\u6570\u636e\u957f\u5ea6\n# print(input_tensor_train.shape, target_tensor_train.shape, input_tensor_val.shape, target_tensor_val.shape)\n# print(target_tensor_train[2294]) # \u4e0e\u4e4b\u524d\u7684\u987a\u5e8f\u4e0d\u4e00\u81f4\u4e86\uff0c\u8fd9\u91cc\u662f\u968f\u673a\u5212\u5206\u7684\n\nBATCH_SIZE = 128\nBUFFER_SIZE = 1000\nfuture_target = 37 # \u76ee\u6807\u662f\u7f6e\u6362\u621037\u5c42\u7684\u6570\u636e\n\ntrain_data_multi = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\ntrain_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n\n\nval_data_multi = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\nval_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()\n\n# for x, y in train_data_multi.take(1):\n#     print(x.shape)\n#     print(y.shape)\n# for x, y in val_data_multi.take(1):\n#     print(x.shape)\n#     print(y.shape)\n\nmulti_step_model_V = tf.keras.models.Sequential()\nmulti_step_model_V.add(tf.keras.layers.LSTM(32,\n                                          return_sequences=True,\n                                          input_shape=input_tensor_train.shape[-2:]))\nmulti_step_model_V.add(tf.keras.layers.LSTM(16, activation='relu'))\nmulti_step_model_V.add(tf.keras.layers.Dense(37))\n\nmulti_step_model_V.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')\nprint(multi_step_model_V.summary())\n\n# for x, y in train_data_multi_V.take(1):\n#     print(x.shape)\n#     print(y.shape)\n#     print(x[0])\n#     print (multi_step_model_V.predict(x).shape)\n\nEPOCHS = 40\nPATIENCE = 5\nEVALUATION_INTERVAL = 400\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience = 3, restore_best_weights=True)\nmulti_step_history_V = multi_step_model_V.fit(train_data_multi,\n                                          epochs=EPOCHS,\n                                          steps_per_epoch=EVALUATION_INTERVAL,\n                                          validation_data=val_data_multi,\n                                          validation_steps=EVALUATION_INTERVAL,\n                                          callbacks=[early_stopping])\n# \u8bc4\u4ef7\u51fd\u6570\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error\n\ndef evaluation_model(test_X, test_Y):\n    y_pred_stand = multi_step_model_V.predict(test_X) \n    y_pred_true = scaler.inverse_transform(y_pred_stand) \n    y_true = scaler.inverse_transform(test_Y)\n#     print(y_true.shape)\n\n    rmse = sqrt(mean_squared_error(y_true, y_pred_true))\n    return 'Test RMSE: %.3f' % rmse\n\n\n# \u8bc4\u4f30\u8bad\u7ec3\u96c6\u6548\u679c\nevaluation_model_train = evaluation_model(input_tensor_train, target_tensor_train)\nprint(evaluation_model_train)\n# \u8bc4\u4f30\u96c6\u6d4b\u8bd5\u6548\u679c\nevaluation_model_val = evaluation_model(input_tensor_val, target_tensor_val)\nprint(evaluation_model_val)\n# \u8bc4\u4f30\u6574\u4e2a\u6570\u636e\u96c6\u6548\u679c:\nevaluation_model_all = evaluation_model(Flow_data_stand, V_ERA5_stand)\nprint(evaluation_model_all)","e2a7d023":"# \u753b\u51fa850hPa,500hPa,300hPa\u4e09\u4e2a\u5c42\u6b21\u7684\u53cd\u6f14\u98ce\u573a\u53ca\u5bf9\u5e94\u7684ERA5\u98ce\u573a \u5bf9\u5e94index=[18, 22, 31]\nfrom mpl_toolkits.basemap import Basemap\ndef uv2ws(u, v):\n    ws = np.sqrt(u ** 2 + v ** 2)\n    return ws\n\ndef plot_UV_level(test_X, test_U, test_V, p_ERA_plot, level_index, level_value):\n    u_pred_stand = multi_step_model.predict(test_X) \n    u_pred_true = scaler.inverse_transform(u_pred_stand) \n    u_true = scaler.inverse_transform(test_U)\n    \n    # (4800, 37) =>(60, 80, 37) =>(60, 80, 1)\n    u_true = u_true.reshape(60, 80, 37)[:,:,level_index] # (60, 80)\n    u_pred_true = u_pred_true.reshape(60, 80, 37)[:,:,level_index] # (60, 80)\n    \n    v_pred_stand = multi_step_model_V.predict(test_X) #!!!!!!!!!!!!\u6362\u4e86\u4e00\u4e2a\u6a21\u578b\n    v_pred_true = scaler.inverse_transform(v_pred_stand) \n    v_true = scaler.inverse_transform(test_V)\n    \n    # (4800, 37) =>(60, 80, 37) =>(60, 80, 1)\n    v_true = v_true.reshape(60, 80, 37)[:,:,level_index] # (60, 80)\n    v_pred_true = v_pred_true.reshape(60, 80, 37)[:,:,level_index] # (60, 80)\n    \n    lat_grid = np.arange(16.0, 31.0, 0.25)  # 150\n    lon_grid = np.arange(111.0, 131.0, 0.25)  # 220\n    lon_grid, lat_grid = np.meshgrid(lon_grid, lat_grid)  # (60, 80)\n    \n    fig = plt.figure(figsize=(6.5, 4.5), dpi=350)\n    map = Basemap(llcrnrlon=111-0.25, llcrnrlat=16-0.25, urcrnrlon=131, urcrnrlat=31, resolution='l')\n    # map.readshapefile(basemap_path_1, 'whatevername', color='k', linewidth=0.8)\n    # map.readshapefile(basemap_path_2, 'whatevername', color='black', linewidth=0.5)\n\n#     # \u628a\u5750\u6807\u6295\u5f71\u5230\u7403\u9762\u4e0a\n    X, Y = map(lon_grid, lat_grid)  # X,Y shape (60, 80)\n    WS_true = uv2ws(u_true, v_true)\n    WS_pred_true = uv2ws(u_pred_true, v_pred_true)\n    \n    ax1 = fig.add_subplot(211)\n    WS_plot = map.pcolormesh(X, Y, WS_true,vmin=0, vmax=40, cmap='jet') # \n    map.quiver(X, Y, u_true, v_true, angles=\"uv\", units='inches', pivot='mid')\n    bar = plt.colorbar(WS_plot, orientation='vertical', fraction=0.043, pad=0.04)  # fraction\u63a7\u5236\u5927\u5c0f\u6bd4\u4f8b,pad\u63a7\u5236\u4f4d\u7f6e\n    bar.ax.tick_params(labelsize=6)  # \u8bbe\u7f6ecolorbar\u523b\u5ea6\u5b57\u4f53\u5927\u5c0f\n\n    # \u7ed8\u5236\u5750\u6807\u523b\u5ea6\n    map.drawparallels(\n        np.arange(-90, 90.1, 4.),  # \u753b\u7eac\u5ea6\n        color='black', dashes=[5, 5], fontsize=6,\n        linewidth=0, labels=[True, False, False, False]  # labels = [left,right,top,bottom]\n    )\n    map.drawmeridians(\n        np.arange(0, 360, 4.),  # \u753b\u7ecf\u5ea6\n        color='black', dashes=[5, 5], fontsize=6,\n        linewidth=0, labels=[False, False, False, True]  # labels = [left,right,top,bottom]\n    )\n    plt.title(\"04:00 ERA5 wind farm on \"+ str(level_value) + \" hPa\",fontsize=6)\n    \n    ax2 = fig.add_subplot(212)\n    WS_plot = map.pcolormesh(X, Y, WS_pred_true,vmin=0, vmax=40, cmap='jet') # vmin=WS_min, vmax=WS_max,\n    map.quiver(X, Y, u_pred_true, v_pred_true, angles=\"uv\", units='inches', pivot='mid')\n    bar = plt.colorbar(WS_plot, orientation='vertical', fraction=0.043, pad=0.04)  # fraction\u63a7\u5236\u5927\u5c0f\u6bd4\u4f8b,pad\u63a7\u5236\u4f4d\u7f6e\n    bar.ax.tick_params(labelsize=6)  # \u8bbe\u7f6ecolorbar\u523b\u5ea6\u5b57\u4f53\u5927\u5c0f\u3002\n\n    # \u7ed8\u5236\u5750\u6807\u523b\u5ea6\n    map.drawparallels(\n        np.arange(-90, 90.1, 4.),  # \u753b\u7eac\u5ea6\n        color='black', dashes=[5, 5], fontsize=6,\n        linewidth=0, labels=[True, False, False, False]  # labels = [left,right,top,bottom]\n    )\n    map.drawmeridians(\n        np.arange(0, 360, 4.),  # \u753b\u7ecf\u5ea6\n        color='black', dashes=[5, 5], fontsize=6,\n        linewidth=0, labels=[False, False, False, True]  # labels = [left,right,top,bottom]\n    )\n\n    plt.title(\"04:00 Simulation wind farm on \"+ str(level_value) + \" hPa\",fontsize=6) # , pad=15\n    plt.savefig(\"04_wind_farm_\" + str(level_value) +'_hPa.png', dpi=450)\n    plt.show()\n\nplot_UV_level(Flow_data_stand, U_ERA5_stand, V_ERA5_stand, ERA5_pressure, level_index=18, level_value=300) # 300hPa\nplot_UV_level(Flow_data_stand, U_ERA5_stand, V_ERA5_stand, ERA5_pressure, level_index=22, level_value=500) # 500hPa\nplot_UV_level(Flow_data_stand, U_ERA5_stand, V_ERA5_stand, ERA5_pressure, level_index=31, level_value=850) # 850hPa","fc6db674":"## \u9884\u6d4bV\n\n\u4e4b\u524d\u7684\u5de5\u4f5c\u90fd\u662f\u4ee5U_ERA\u4e3atarget\u6765\u505a\u7684\uff0c\u73b0\u5728\u4ee5V_ERA\u518d\u505a\u4e00\u904d\n","38e65003":"# title"}}