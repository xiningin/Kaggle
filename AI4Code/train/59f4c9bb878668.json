{"cell_type":{"ed50fa8f":"code","089be51a":"code","faa51b9c":"code","a7f2c0fb":"code","2aeb3d9c":"code","eee0d99e":"code","ae350d8f":"code","e812c8c7":"code","36fced9d":"code","ad417ad6":"code","a5e765c3":"markdown","50ef31a1":"markdown","2693760f":"markdown","51d30d15":"markdown","ea936e63":"markdown","6dc516f3":"markdown","afed75f5":"markdown","e4ba1686":"markdown","4b8c1f9e":"markdown"},"source":{"ed50fa8f":"import pandas as pd\n\nfrom learntools.advanced_pandas.renaming_and_combining import *\n\npd.set_option('max_rows', 5)\nreviews = pd.read_csv(\"..\/input\/wine-reviews\/winemag-data-130k-v2.csv\", index_col=0)","089be51a":"check_q1(pd.DataFrame())","faa51b9c":"reviews.head()","a7f2c0fb":"# Your code here\nreviews.rename(columns={'region_1': 'region'}) #renames region_1\n","2aeb3d9c":"reviews.rename(columns={'region_2': 'locale'}) #rename region_2\n","eee0d99e":"# Your code here\nreviews.rename_axis(\"wines\", axis='rows')","ae350d8f":"gaming_products = pd.read_csv(\"..\/input\/things-on-reddit\/top-things\/top-things\/reddits\/g\/gaming.csv\")\ngaming_products['subreddit'] = \"r\/gaming\"\nmovie_products = pd.read_csv(\"..\/input\/things-on-reddit\/top-things\/top-things\/reddits\/m\/movies.csv\")\nmovie_products['subreddit'] = \"r\/movies\"","e812c8c7":"# Your code here\npd.concat([gaming_products, movie_products]) #concatenation","36fced9d":"powerlifting_meets = pd.read_csv(\"..\/input\/powerlifting-database\/meets.csv\")\npowerlifting_competitors = pd.read_csv(\"..\/input\/powerlifting-database\/openpowerlifting.csv\")","ad417ad6":"# Your code here\npd.concat([powerlifting_meets, powerlifting_competitors]) #concatenation","a5e765c3":"If you get stuck, **use the `answer_qN` function to see the code with the correct answer.**\n\nFor the first set of questions, running the `check_qN` on the correct answer returns `True`.\n\nFor the second set of questions, using this function to check a correct answer will present an informative graph!","50ef31a1":"# Renaming and combining workbook\n\n## Introduction\n\nThis is the worbook part of the \"Renaming and combining\" section of the Advanced Pandas tutorial. For the reference section, click [here](https:\/\/www.kaggle.com\/residentmario\/renaming-and-combining-reference).\n\nRenaming is covered in its own section in the [\"Essential Basic Functionality\"](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/basics.html#renaming-mapping-labels) section of the extensive official documentation. Combining is covered by the [\"Merge, join, concatenate\"](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/merging.html) section there.","2693760f":"**Exercise 1**: `region_1` and `region_2` are pretty uninformative names for locale columns in the dataset. Rename these columns to `region` and `locale`.","51d30d15":"# Keep going\n[**Continue to the method chaining workbook**](https:\/\/www.kaggle.com\/kernels\/fork\/605139).","ea936e63":"**Exercise 3**: The [Things on Reddit](https:\/\/www.kaggle.com\/residentmario\/things-on-reddit\/data) dataset includes product links from a selection of top-ranked forums (\"subreddits\") on Reddit.com. Create a `DataFrame` of products mentioned on *either* subreddit. Use the following data:","6dc516f3":"# Checking Answers\n\n**Check your answers in each exercise using the  `check_qN` function** (replacing `N` with the number of the exercise). For example here's how you would check an incorrect answer to exercise 1:","afed75f5":"**Exercise 4**: The [Powerlifting Database](https:\/\/www.kaggle.com\/open-powerlifting\/powerlifting-database) dataset on Kaggle includes one CSV table for powerlifting meets and a separate one for powerlifting competitors. Both tables include references to a `MeetID`, a unique key for each meet (competition) included in the database. Using this, generate a dataset combining the two tables into one. Use the following data:","e4ba1686":"# Exercises\n\nLook at your data by running the cell below:","4b8c1f9e":"**Exercise 2**: Set the index name in the dataset to `wines`."}}