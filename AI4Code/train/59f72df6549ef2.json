{"cell_type":{"eae30b05":"code","b10fcf56":"code","fde57fa7":"code","98eadd2f":"code","de5b11fc":"code","bb1d451a":"code","f10fdaa6":"code","8cf9a6fd":"code","761fba8d":"code","1e3d4487":"code","ab739a17":"code","9df9ee33":"code","120019b6":"code","3f6a40ea":"code","589dc968":"code","a07bf6f2":"markdown","6a189895":"markdown","d6cd1fd2":"markdown","3e43515d":"markdown","89d296b2":"markdown","ceb80310":"markdown"},"source":{"eae30b05":"import numpy as np \nimport pandas as pd \nimport math\nimport glob\nimport os\nimport gc\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport time\n%matplotlib inline\n","b10fcf56":"pd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)","fde57fa7":"train=pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ntest=pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')\nsample_submission=pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')","98eadd2f":"print(\"Train has\", train.shape[0], \"elements\")\nprint(\"Test has\", test.shape[0], \"elements\")\n","de5b11fc":"train.head(10)","bb1d451a":"dd=(train.isna().sum()\/train.shape[0]).reset_index(name='percentage_na')\ndd=dd.set_index('index')\ndd.T","f10fdaa6":"features=[f for f in train.columns.tolist() if 'f' in f]","8cf9a6fd":"import cudf\nimport pandas as pd\n\nimport pynvml\nimport numpy as np\nimport xgboost as xgb\n\n\ndata = cudf.from_pandas(train)\nfor col in features:\n    data[col]=data[col].astype('float32')\n## spliting training and test set\nfrom cuml import train_test_split\nX=data[features]\ny=data.iloc[:,119]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)","761fba8d":"from cuml.ensemble import RandomForestClassifier\nX_train.fillna(0, inplace=True)\nmodel = RandomForestClassifier(n_estimators = 140, max_depth =10 )\nmodel.fit(X_train, y_train)","1e3d4487":"\nfrom cuml.metrics import accuracy_score\nfrom cupy import asnumpy\nX_test.fillna(0, inplace=True)\nrf_prediction = model.predict_proba(X_test)\nthreshold=0.38\nrf_predictions = (rf_prediction[1] >= threshold).astype(int)\n#rf_predictions=np.round(rf_prediction,0).astype(int)\ncu_score = accuracy_score( y_test, rf_predictions )\n\nprint(\"cuml Accuracy: %.2f%%\" % (cu_score * 100.0))\n","ab739a17":"start_rapids = time.time()\ndtrain = xgb.DMatrix(\n        X_train,\n        y_train    )\n\ndtest = xgb.DMatrix(\n        X_test,\n        y_test    )\n\n## Train the model\ntrained_model = xgb.train(\n                        {\n                          'nround': 100,\n                          'max_depth': 4,\n                          'max_leavs': 2**8,\n                          'loss': 'ls',\n                          'objective': 'binary:logistic',\n                          'n_estimators':120,\n                          'max_features': 'auto',\n                          'criterion' : 'friedman_mse',\n                          'grow_policy': 'lossguide',\n                          'silent': True,\n                          'verbose_eval': True,\n                          'tree_method':'gpu_hist',\n                        },\n                        dtrain,\n                        num_boost_round=400, evals=[(dtrain, 'train')])\n\n## Predict the model\n\nend_rapids = time.time()\nprint(\"Total time taken\", end_rapids-start_rapids, \"seconds\")","9df9ee33":"\nfrom cuml.metrics import accuracy_score\nfrom cupy import asnumpy\n\nprediction = trained_model.predict(dtest)\nprediction=np.round(prediction,0).astype(int)\ncu_score = accuracy_score( y_test, prediction )\n\nprint(\"cuml Accuracy: %.2f%%\" % (cu_score * 100.0))\n","120019b6":"test.fillna(0, inplace=True)\ntest[features]=test[features].astype('float32')\ntest_data = cudf.from_pandas(test[features])\ndtest_actual = xgb.DMatrix(\n        test_data  )\nboost_pred=trained_model.predict(dtest_actual)\n\nrf_pred=model.predict_proba(test_data)","3f6a40ea":"final_preds=asnumpy(rf_pred[1]*0.3)+asnumpy(.8*boost_pred)\ntest['claim']=np.round(final_preds)\ntest['claim']=test['claim'].astype(int)","589dc968":"test[['id','claim']].to_csv('submission.csv', index=False)","a07bf6f2":"### Please upvote if you find the notebook Useful. I will be working on adding new features and visualizations. ","6a189895":"Most of the columns have less than 1%-2% of missing data","d6cd1fd2":"### Lets try out Random Forest and Xgboost in Rapids","3e43515d":"#### Lets take a look at train data to check NA values and data distrbution","89d296b2":"#### Read Data and Identify data patterns and trends","ceb80310":"### Goal :\n The goal of the task is to predict whether there will be a claim happening or not based on the given variables\n \n##### Here we going to use rapids, cuml where the whole notebook runs with in few minutes. We are going to use an ensemble of Random Forest and XGBoost to test out"}}