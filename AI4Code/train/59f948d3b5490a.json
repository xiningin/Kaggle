{"cell_type":{"45a80976":"code","883c7607":"code","5e6f8d7a":"code","57d2535c":"code","4d28a486":"code","e8808b7b":"code","c57253c7":"code","52a4e117":"code","c6f44789":"code","55390a19":"code","bcb70c18":"code","a146eb98":"code","5b427115":"code","c2ca25b6":"code","c030904d":"code","3f6172d5":"code","8d9029fd":"code","57fc37b2":"code","32216587":"code","0635454e":"code","0c277f9d":"code","bf6b882e":"code","bec97dcd":"code","58c5641a":"code","54a60bc6":"code","0a18a9d6":"code","3bdf811c":"code","f59b8911":"code","53f8f752":"code","af8a7257":"code","a40d49fb":"code","a9e312ba":"code","9e04446d":"code","2ac0963a":"code","85c0a981":"code","681bb614":"code","f6bffd8a":"code","e336765a":"code","aa6675db":"code","4a17aa3b":"code","4aeb7db4":"code","a4e6d10a":"code","a7b84512":"code","7497179e":"code","58526691":"code","a636faa3":"code","c2b1913f":"code","e1bbbbab":"code","60ce8717":"code","84706233":"code","440a5ede":"code","7bb5b52d":"code","4b2af52d":"code","4e14c266":"code","6a351911":"code","aaeb22b1":"code","090d1fdb":"code","a0ebcf59":"code","ad9a4561":"code","8ac38ffd":"code","a294ee88":"code","0de2ee42":"code","9cc135d0":"code","f52e83a4":"markdown","4d2ca796":"markdown","def0370e":"markdown","170f1b45":"markdown","e9fe562d":"markdown","9e936b1a":"markdown","3aa4a697":"markdown","0453acb4":"markdown","af139b51":"markdown","95401598":"markdown","04ccc4fb":"markdown","da14d1ff":"markdown","854d6eca":"markdown","a93e1dd1":"markdown","28c1a1ee":"markdown","433f2ac0":"markdown","f1a7fed8":"markdown","177736ba":"markdown","a3fa64f3":"markdown","afbcf4fb":"markdown","d9cd48f1":"markdown","67893e7e":"markdown","26ae6ae5":"markdown"},"source":{"45a80976":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","883c7607":"#Importing Required Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","5e6f8d7a":"# Loading data into data frames\nhousing = pd.read_csv('..\/input\/california-housing-prices\/housing.csv')\n# Head of Data\nhousing.head()","57d2535c":"# Description of data\nhousing.info()","4d28a486":"# Printing different attributes of \"ocean_proximity\" column\nhousing[\"ocean_proximity\"].value_counts()","e8808b7b":"# Summary of Numerical Columns\nhousing.describe()","c57253c7":"# Histogram of data set\nhousing.hist(bins=50, figsize=(20,15))\nplt.show()","52a4e117":"from sklearn.model_selection import train_test_split\ntrain_set, test_test = train_test_split(housing, test_size=0.2,random_state=42)","c6f44789":"# Adding Income Category to the data set\nhousing[\"income_cat\"] = np.ceil(housing[\"median_income\"]\/1.5)\nhousing[\"income_cat\"].where(housing[\"income_cat\"]< 5,5.0, inplace = True)","55390a19":"# Histogram of Income Categories\nhousing[\"income_cat\"].hist()","bcb70c18":"from sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state=42)\nfor train_index, test_index in split.split(housing,housing[\"income_cat\"]):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]\n\n","a146eb98":"# Income Category Proportions\nhousing[\"income_cat\"].value_counts()\/len(housing)","5b427115":"for set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"income_cat\",axis=1,inplace=True)","c2ca25b6":"# copy of data\nhousing = strat_train_set.copy()","c030904d":"housing.plot(kind='scatter',x='longitude',y='latitude')","3f6172d5":"housing.plot(kind='scatter',x='longitude',y='latitude',alpha=0.1)","8d9029fd":"housing.plot(kind='scatter',x='longitude',y='latitude',alpha=0.4,\n            s=housing[\"population\"]\/100,label=\"Population\",figsize=(15,10),\n            c=\"median_house_value\",cmap=plt.get_cmap(\"jet\"),colorbar=True)\nplt.legend()","57fc37b2":"# Correlation\ncorr_matrix = housing.corr()","32216587":"# Correlation of Median House Value with other attributes\ncorr_matrix[\"median_house_value\"].sort_values(ascending=False)","0635454e":"from pandas.plotting import scatter_matrix\n","0c277f9d":"# Scatter Matrix\n#from pandas.tools.plotting import scatter_matrix\nattributes = ['median_house_value','median_income','total_rooms','housing_median_age']\nscatter_matrix(housing[attributes],figsize=(12,12))","bf6b882e":"# Scatter Plot - Median income VS Median house value\nhousing.plot(kind='scatter',x='median_income',y='median_house_value',alpha=0.1)","bec97dcd":"housing = strat_train_set.drop('median_house_value',axis=1)\nhousing_labels = strat_train_set['median_house_value'].copy()","58c5641a":"# Replacing null values with SimpleImputer\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy = 'median')","54a60bc6":"housing_num = housing.drop('ocean_proximity',axis=1)","0a18a9d6":"imputer.fit(housing_num)","3bdf811c":"imputer.statistics_","f59b8911":"housing_num.median().values","53f8f752":"X = imputer.transform(housing_num)","af8a7257":"housing_tr = pd.DataFrame(X,columns=housing_num.columns)","a40d49fb":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nhousing_cat = housing['ocean_proximity']\nhousing_cat_en = encoder.fit_transform(housing_cat)\nhousing_cat_en","a9e312ba":"encoder.classes_","9e04446d":"from sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder()\nhousing_cat_hot = encoder.fit_transform(housing_cat_en.reshape(-1,1))\nhousing_cat_hot","2ac0963a":"from sklearn.base import BaseEstimator, TransformerMixin\nrooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6","85c0a981":"class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    def fit(self, X, y=None):\n        return self # nothing else to do\n    def transform(self, X, y=None):\n        rooms_per_household = X[:, rooms_ix] \/ X[:, households_ix]\n        population_per_household = X[:, population_ix] \/ X[:, households_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedrooms_ix] \/ X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household,\n                         bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]","681bb614":"attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\nhousing_extra_attribs = attr_adder.transform(housing.values)","f6bffd8a":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n","e336765a":"num_pipeline = Pipeline([('imputer',SimpleImputer(strategy=\"median\")),('attribs_adder',CombinedAttributesAdder()),\n                        ('std_scalar',StandardScaler())])","aa6675db":"housing_num_tr = num_pipeline.fit_transform(housing_num)","4a17aa3b":"from sklearn.compose import ColumnTransformer\nnum_attribs = list(housing_num)\ncat_attribs = [\"ocean_proximity\"]\nfull_pipeline = ColumnTransformer([(\"num\", num_pipeline, num_attribs),\n                                   (\"cat\", OneHotEncoder(), cat_attribs)])\nhousing_prepared = full_pipeline.fit_transform(housing)\n","4aeb7db4":"from sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(housing_prepared,housing_labels)","a4e6d10a":"some_data = housing.iloc[:5]\nsome_labels = housing_labels.iloc[:5]\nsome_data_prepared = full_pipeline.transform(some_data)","a7b84512":"print('Predictions', lin_reg.predict(some_data_prepared))","7497179e":"print('Labels', list(some_labels))","58526691":"# RMSE on the whole training set\nfrom sklearn.metrics import mean_squared_error\nhousing_predictions = lin_reg.predict(housing_prepared)","a636faa3":"lin_mse = mean_squared_error(housing_labels,housing_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","c2b1913f":"#Let\u2019s train a DecisionTreeRegressor\nfrom sklearn.tree import DecisionTreeRegressor\ntree_reg = DecisionTreeRegressor()\ntree_reg.fit(housing_prepared, housing_labels)","e1bbbbab":"# rmse\nhousing_predictions = tree_reg.predict(housing_prepared)\ntree_mse = mean_squared_error(housing_labels, housing_predictions)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse","60ce8717":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(tree_reg,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\ntree_rmse_scores = np.sqrt(-scores)","84706233":"# Results\ndef display_scores(scores):\n    print(\"Scores\",scores)\n    print(\"Mean\",scores.mean())\n    print(\"Standard Deviation\",scores.std())\n\n    \ndisplay_scores(tree_rmse_scores)","440a5ede":"lin_scores = cross_val_score(lin_reg,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)","7bb5b52d":"from sklearn.ensemble import RandomForestRegressor\nforest_reg = RandomForestRegressor()\nforest_reg.fit(housing_prepared,housing_labels)","4b2af52d":"# rmse\nhousing_predictions = forest_reg.predict(housing_prepared)\nforest_mse = mean_squared_error(housing_labels, housing_predictions)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","4e14c266":"# Cross validation\nforest_scores = cross_val_score(forest_reg,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)","6a351911":"from sklearn.model_selection import GridSearchCV\nparam_grid = [{'n_estimators':[3,10,30],'max_features':[2,4,6,8]},\n             {'bootstrap': [False],'n_estimators':[3,10],'max_features':[2,3,4]}]\nforest_reg = RandomForestRegressor()\ngrid_search = GridSearchCV(forest_reg,param_grid, cv=5, scoring='neg_mean_squared_error')\ngrid_search.fit(housing_prepared,housing_labels)","aaeb22b1":"grid_search.best_params_","090d1fdb":"grid_search.best_estimator_","a0ebcf59":"# Evaluation scores\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","ad9a4561":"feature_importances = grid_search.best_estimator_.feature_importances_\nfeature_importances","8ac38ffd":"# Display these importance scores next to their corresponding attribute names\nextra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\ncat_encoder = full_pipeline.named_transformers_[\"cat\"]\ncat_one_hot_attribs = list(cat_encoder.categories_[0])\nattributes = num_attribs + extra_attribs + cat_one_hot_attribs\nsorted(zip(feature_importances, attributes), reverse=True)","a294ee88":"final_model = grid_search.best_estimator_\n\nX_test = strat_test_set.drop('median_house_value',axis=1)\ny_test = strat_test_set['median_house_value'].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)","0de2ee42":"final_predictions = final_model.predict(X_test_prepared)","9cc135d0":"final_mse = mean_squared_error(y_test,final_predictions)\nfinal_rmse = np.sqrt(final_mse)\nfinal_rmse","f52e83a4":"**Analyze the Best Models and Their Errors**","4d2ca796":"**Visual Data Analytics**","def0370e":"**Data Cleaning**","170f1b45":"**Tranformation Pipelines**","e9fe562d":"The performance will usually be slightly worse than what you measured using cross\u0002validation if you did a lot of hyperparameter tuning (because your system ends up\nfine-tuned to perform well on the validation data, and will likely not perform as well\nFine-Tune Your Model | 83\non unknown datasets). It is not the case in this example, but when this happens you\nmust resist the temptation to tweak the hyperparameters to make the numbers look\ngood on the test set; the improvements would be unlikely to generalize to new data.","9e936b1a":"The Decision Tree model is overfitting so badly that it performs worse\nthan the Linear Regression model.\n\nLet\u2019s try one last model now: the RandomForestRegressor.\n","3aa4a697":"It works, although the predictions are not exactly accurate","0453acb4":"**Grid Search**","af139b51":"We have successfully finetuned our best model!","95401598":" Decision Tree doesn\u2019t look as good as it did earlier. In fact, it seems to per\u2010\nform worse than the Linear Regression model.\n\nLet\u2019s compute the same scores for the Linear Regression model just to be sure:\n","04ccc4fb":"**Evaluate Your System on the Test Set**","da14d1ff":"**Handling Text and Categorical Attributes**","854d6eca":"**Custom Transformers**","a93e1dd1":"This is much better, Random Forests look very promising.","28c1a1ee":"This is an example of a model underfitting the training data","433f2ac0":"**Better Evaluation Using Cross-Validation**","f1a7fed8":"**Stratified Sampling based on Income Category**","177736ba":"# Fine-Tune Your Model\n","a3fa64f3":"**Creating a Test Set**","afbcf4fb":"**Training and Evaluating on the Training Set**","d9cd48f1":"From we can see that column 'total_bedrooms' has 207 null values and data has total 10 columns in which 9 of them are numeric and 1 column has categoric values.","67893e7e":"Model has badly overfit the data","26ae6ae5":"# Select and Train a Model\n"}}