{"cell_type":{"b0d3728d":"code","d88a3afb":"code","2e619f82":"code","c76e55c7":"code","1a11501d":"code","3eb53456":"code","5b985348":"code","689148ba":"code","d870c5a6":"code","b85380bb":"code","3bf229c1":"code","84afe3c6":"code","fa48308e":"code","f4051023":"code","5271085c":"code","3593887d":"code","3108c2f4":"code","ba425329":"code","01f0e0cd":"code","ae58683f":"markdown","ae412827":"markdown","abda72f9":"markdown","441f777b":"markdown","8cd5571e":"markdown","4b4a72a8":"markdown","1e7d95c9":"markdown","a7af7adf":"markdown","27884d1a":"markdown","1d6744dd":"markdown"},"source":{"b0d3728d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\n\nimport nltk\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom nltk.corpus import stopwords\nimport string\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV,train_test_split,KFold,cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\nfrom wordcloud import WordCloud\nfrom collections import Counter\n\nfrom sklearn.ensemble import VotingClassifier, RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\nimport re\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings \nwarnings.filterwarnings('ignore')","d88a3afb":"with open(\"\/kaggle\/input\/whats-cooking-kernels-only\/train.json\") as f:\n    train_json= json.load(f)\ntrain = pd.DataFrame(train_json)\n\nwith open(\"\/kaggle\/input\/whats-cooking-kernels-only\/test.json\") as f:\n    test_json= json.load(f)\ntest = pd.DataFrame(test_json)\n\ndisplay(train.head())\ndisplay(test.head())","2e619f82":"print(\"Any null data:\\n\")\nprint(train.isnull().sum())","c76e55c7":"raw_ingredients = [ing for ingredients in train['ingredients'] for ing in ingredients]\n\nprint(\"Any ingredient that is <= 2 chars only:\")\ndisplay([ing for ing in raw_ingredients if len(ing) <=2])\n\nprint(\"\\nIngredient with numbers\")\nx = [ing for ing in raw_ingredients if re.findall('[0-9]',ing)]\nnum_ing = list(set(x))\ndisplay(num_ing[1:10])\n\nprint(\"\\nHow many such ingredients?:\",len(num_ing))\n\nprint(\"\\nSpecial characters in the ingredients:\")\nsp_chrs = [''.join(ing for ing in set(\"\".join(raw_ingredients)) if re.findall('[^a-zA-Z]',ing))]\nsp_chrs=\"\".join(sp_chrs)\ndisplay(sp_chrs)\nprint(\"\\nIngredients have cusine names in them:\\n\")\n\nkeywords = ['italian', 'mexican', 'indian', 'chinese', 'french',\n       'cajun','creole', 'thai', 'japanese', 'greek', 'spanish', 'korean',\n       'vietnamese', 'moroccan', 'filipino', 'irish', 'jamaican',\n       'russian', 'american']\n\nz = {}\n\nfor k in keywords:\n    x = [ing for ing in raw_ingredients if k in ing]\n    z[k] = set(x)\n    \nfor key,values in z.items():\n    print(key,\":\\n\")\n    print(values)\n    print('\\n')\n    ","1a11501d":"def clean_data(data):\n   \n    cleandata = set()\n    sw = stopwords.words('english')    \n            \n    pattern = '[!\"#$%&\\'()*+,-.\/:;<=>?@[\\\\]^_`{|}~]'\n    sp_chrs = '[\u00e8\u2019\u00e2\u00ae(\u00ee\u2122\u00ed\u20ac\u00e7\u00e9\u00fa]'\n\n    wordnet_lemmatizer = WordNetLemmatizer()\n    data =  [word.lower() for word in data]\n    \n    for word in data:\n        word = re.sub(\"[0-9]\",\"\",word) \n        word  = re.sub(pattern,'',word)\n        word = re.sub(sp_chrs,'',word)\n\n        if word not in sw and len(word) > 2:\n            word = re.sub(r'(garlic cloves)','garlic', word)\n                          \n            x = re.sub(r'(nutritional|whole|quick|low|topping|paste|cut into|meal|food|low-fat|into|season|slice|unsalted|fat|thin|thick|pinch|chuck|liquid|packed|granul|firm|black|white|yellow|brown|blue|red|green|oz|ounc|ounce|pound|lb|inch|kilo|kg|cook|big|small|salt|water|ground|hot|cold|dried|medium|skin|crush|crumble|dice|ground|shred|grate|mince|powder|chop|peel|thaw|slice|season|plain|large|fresh|fine|boil|extra|prepare|italian|mexican|indian|chinese|french|cajun|creole|thai|japanese|greek|spanish|korean|vietnamese|moroccan|filipino|irish|jamaican|russian|american)\\w*','', word)\n            cleandata.add(x)\n            \n    return list(cleandata)\n\nprint(\"Cleaning Messages (train)...\") \ntrain['Ingredients'] = train['ingredients'].apply(clean_data)\n\nprint(\"Cleaning Messages (test)...\") \ntest['Ingredients'] = test['ingredients'].apply(clean_data)\n\nprint(\"Done!!\")","3eb53456":"def count_words(data):\n    return len(data)\n\ntrain['Ingredients_count'] = train['Ingredients'].apply(count_words)\ntest['Ingredients_count']  = test['Ingredients'].apply(count_words)","5b985348":"bg_color = (0.25, 0.25, 0.25)\nsns.set(rc={\"font.style\":\"normal\",\n            \"axes.facecolor\":bg_color,\n            \"figure.facecolor\":bg_color,\n            \"text.color\":\"white\",\n            \"xtick.color\":\"white\",\n            \"ytick.color\":\"white\",\n            \"axes.labelcolor\":\"white\",\n            \"axes.grid\":False,\n            'axes.labelsize':25,\n            'figure.figsize':(15.0,15.0),\n            'xtick.labelsize':15,\n            'ytick.labelsize':15})    ","689148ba":"cusines = train.cuisine.value_counts().index\ncount =  train.cuisine.value_counts()\n\nplt.figure(figsize=(10,8));\n\nsns.barplot(x= count,y =cusines,palette=\"Set1\");\nplt.title('Cuisines');\nplt.xlabel(\"Count\");\nplt.show();","d870c5a6":"common  = Counter([item for ing in train['Ingredients'] for item in ing])\n\nmost_common = common.most_common(20)\ningd,count = [list(c) for c in zip(*most_common)]\n\nplt.figure(figsize=(10,8));\nsns.barplot(y=ingd,x=count,palette=\"rainbow\");\nplt.title('Most Common Ingredients');\nplt.xlabel(\"Count\");\nplt.show();\n\nleast_common = common.most_common()[-10:]\ningd,count = [list(c) for c in zip(*least_common)]\n\nplt.figure(figsize=(10,8));\nsns.barplot(y=ingd,x=count,palette=\"rainbow\");\nplt.title('Least Common Ingredients');\nplt.xlabel(\"Count\");\nplt.show();","b85380bb":"ingd = train[train.Ingredients_count > 45]['cuisine']\ncount = train[train.Ingredients_count > 45]['Ingredients_count']\n\nplt.figure(figsize=(10,8));\nsns.barplot(y=ingd,x=count,palette=\"Set1\");\nplt.suptitle('Cuisines with maximum ingredients');\nplt.xlabel(\"\");\n\nplt.ylabel(\"\")\nplt.show();\n\ningd = train[train.Ingredients_count < 2]['cuisine']\ncount = train[train.Ingredients_count < 2]['Ingredients_count']\n\nplt.figure(figsize=(10,8));\nsns.barplot(y=ingd,x=count,palette=\"Set2\");\nplt.suptitle('Cuisines with miniumum ingredients');\nplt.xlabel(\"\")\nplt.ylabel(\"\")\nplt.show();\n","3bf229c1":"cuisine  = train[train['cuisine']=='italian'].reset_index()\nname = []\nfor i in range(0,len(cuisine)):\n    text = cuisine['Ingredients'][i]\n    text = ','.join(text)\n    name.append(text)\n    text = ' '.join(name)\nwc = WordCloud(width = 800, height = 400, background_color ='white', \n                min_font_size = 14).generate(text)                  \nplt.figure(figsize = (15,15), facecolor = None) \nplt.imshow(wc) \nplt.axis('off') \nplt.title(\"Italian Cuisine\")\nplt.show()\n","84afe3c6":"cuisine  = train[train['cuisine']=='indian'].reset_index()\nname = []\nfor i in range(0,len(cuisine)):\n    text = cuisine['Ingredients'][i]\n    text = ','.join(text)\n    name.append(text)\n    text = ' '.join(name)\nwc = WordCloud(width = 800, height = 400, background_color ='white', \n                min_font_size = 14).generate(text)                  \nplt.figure(figsize = (15,15), facecolor = None) \nplt.imshow(wc) \nplt.title(\"Indian Cuisine\")\nplt.axis('off') \nplt.show()","fa48308e":"def count_ingredients(data):    \n    return dict(pd.Series(data).value_counts())\n\nall_ingredients = train.groupby('cuisine')['Ingredients'].sum()\n\ningredients_count = all_ingredients.apply(count_ingredients)\n\ntop10 =pd.Series()\n\nfor cuisine, list_ingredients in ingredients_count.items():\n    count=0\n    top10[cuisine] = []    \n    for ingredient, occurance in pd.Series(list_ingredients)[:25].items():\n        if count == 10:\n            break\n        ingredient = ingredient.strip()\n        if ingredient != '' and ingredient not in top10[cuisine]:\n            top10[cuisine].append(ingredient)\n            count+=1\ndf_top10 = pd.DataFrame.from_items(zip(top10.index, top10.values)).T\n\ndf_top10.columns = ['top{}'.format(i) for i in range(1, 11)]\nprint(\"Top 10 ingredients of each cuisine\")\ndf_top10.style","f4051023":"# Convert list of strings to string\ndef convert_list_to_string(data):\n    return ' '.join(data)\n\ntrain['Ingredients'] = train['Ingredients'].apply(convert_list_to_string)\ntest['Ingredients'] = test['Ingredients'].apply(convert_list_to_string)","5271085c":"tf = TfidfVectorizer()\n#cv = CountVectorizer()\n\nbow_train_data= tf.fit_transform(train['Ingredients'])\nprint(bow_train_data.shape)\n\nbow_test_data = tf.transform(test['Ingredients'])\nprint(bow_test_data.shape)","3593887d":"le = LabelEncoder()\ntrain['cuisine'] = le.fit_transform(train['cuisine'])","3108c2f4":"train_data,test_data,train_label,test_label = train_test_split(bow_train_data,train['cuisine'].values,stratify=train['cuisine'].values,test_size=0.3,random_state=5)\n\ntrain_data.shape,test_data.shape,train_label.shape,test_label.shape","ba425329":"# Unigram model and parameters for the models are not tuned\nvclf=VotingClassifier(estimators=[('lr',LogisticRegression(random_state = 42)),\n                                  ('svc',SVC(kernel='linear',random_state = 42,probability=True)),\n                                  ('rfc',RandomForestClassifier(n_estimators = 500,random_state = 42))], \n                                    voting='soft', weights = [1,1,1]) \nvclf.fit(train_data, train_label)","01f0e0cd":"\nfinal_pred = vclf.predict(bow_test_data) \ncuisine = le.inverse_transform(final_pred)\n\nsub = pd.DataFrame({'id': test['id'], 'cuisine': cuisine}, columns=['id', 'cuisine'])\nsub.to_csv('submission.csv', index = False)","ae58683f":"## Top ingredients in few cuisines\n### Italian","ae412827":"## Most and least common ingredients of each cuisine","abda72f9":"# Loading the json file (train and test data)","441f777b":"# Importing libraries","8cd5571e":"# Data Visualization\n#### Top cuisines","4b4a72a8":"![image.png](attachment:d5e8b25a-14b2-4559-b401-6a0c9e14d077.png)","1e7d95c9":"# Data Cleaning","a7af7adf":"# Data Analysing","27884d1a":"## Cusines with maximum and minumum ingredients","1d6744dd":"## Indian"}}