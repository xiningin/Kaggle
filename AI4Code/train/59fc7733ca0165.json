{"cell_type":{"454f1f3b":"code","2e8f6225":"code","3748670d":"code","55fe8b20":"code","9d27573b":"code","d1f01572":"code","c5eff4f5":"code","3e258672":"code","493b2341":"code","c5018355":"code","1632be97":"code","4bf6198d":"code","964a011e":"code","bcbd6afc":"code","fe250f3a":"code","ce7f154c":"code","681a0d0d":"code","a849b741":"markdown","959757f5":"markdown","2c139322":"markdown","b0232cd0":"markdown","995f7b88":"markdown","a60c60dc":"markdown","74a860b7":"markdown"},"source":{"454f1f3b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2e8f6225":"# NumPy\nimport numpy as np\n\n# Dataframe operations\nimport pandas as pd\n\n# Data visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Scalers\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\n\n# Models\nfrom sklearn.linear_model import LogisticRegression #logistic regression\nfrom sklearn.linear_model import Perceptron\nfrom sklearn import svm #support vector Machine\nfrom sklearn.ensemble import RandomForestClassifier #Random Forest\nfrom sklearn.neighbors import KNeighborsClassifier #KNN\nfrom sklearn.naive_bayes import GaussianNB #Naive bayes\nfrom sklearn.tree import DecisionTreeClassifier #Decision Tree\nfrom sklearn.model_selection import train_test_split #training and testing data split\nfrom sklearn import metrics #accuracy measure\nfrom sklearn.metrics import confusion_matrix #for confusion matrix\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\n\n# Cross-validation\nfrom sklearn.model_selection import KFold #for K-fold cross validation\nfrom sklearn.model_selection import cross_val_score #score evaluation\nfrom sklearn.model_selection import cross_val_predict #prediction\nfrom sklearn.model_selection import cross_validate\n\n# GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns","3748670d":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n# The entire data: train + test.\ndata_df = train_df.append(test_df,sort=True) ","55fe8b20":"data_df['Title'] = data_df['Name']\n\n# Cleaning name and extracting Title\nfor name_string in data_df['Name']:\n    data_df['Title'] = data_df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n\n# Replacing rare titles with more common ones\nmapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss','Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\ndata_df.replace({'Title': mapping}, inplace=True)\ntitles = ['Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev']\nfor title in titles:\n    age_to_impute = data_df.groupby('Title')['Age'].median()[titles.index(title)]\n    data_df.loc[(data_df['Age'].isnull()) & (data_df['Title'] == title), 'Age'] = age_to_impute\n    \n# Substituting Age values in TRAIN_DF and TEST_DF:\ntrain_df['Age'] = data_df['Age'][:891]\ntest_df['Age'] = data_df['Age'][891:]\n\n# Dropping Title feature\ndata_df.drop('Title', axis = 1, inplace = True)","9d27573b":"data_df['Family_Size'] = data_df['Parch'] + data_df['SibSp']\n\n# Substituting Age values in TRAIN_DF and TEST_DF:\ntrain_df['Family_Size'] = data_df['Family_Size'][:891]\ntest_df['Family_Size'] = data_df['Family_Size'][891:]","d1f01572":"data_df['Last_Name'] = data_df['Name'].apply(lambda x: str.split(x, \",\")[0])\ndata_df['Fare'].fillna(data_df['Fare'].mean(), inplace=True)\n\nDEFAULT_SURVIVAL_VALUE = 0.5\ndata_df['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n\nfor grp, grp_df in data_df[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId','SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n    if (len(grp_df) != 1):\n        # A Family group is found.\n        for ind, row in grp_df.iterrows():\n            smax = grp_df.drop(ind)['Survived'].max()\n            smin = grp_df.drop(ind)['Survived'].min()\n            passID = row['PassengerId']\n            if (smax == 1.0):\n                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n            elif (smin==0.0):\n                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n\nprint(\"Number of passengers with family survival information:\", \n      data_df.loc[data_df['Family_Survival']!=0.5].shape[0])","c5eff4f5":"for _, grp_df in data_df.groupby('Ticket'):\n    if (len(grp_df) != 1):\n        for ind, row in grp_df.iterrows():\n            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n                smax = grp_df.drop(ind)['Survived'].max()\n                smin = grp_df.drop(ind)['Survived'].min()\n                passID = row['PassengerId']\n                if (smax == 1.0):\n                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n                elif (smin==0.0):\n                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n                        \nprint(\"Number of passenger with family\/group survival information: \" \n      +str(data_df[data_df['Family_Survival']!=0.5].shape[0]))\n\n# # Family_Survival in TRAIN_DF and TEST_DF:\ntrain_df['Family_Survival'] = data_df['Family_Survival'][:891]\ntest_df['Family_Survival'] = data_df['Family_Survival'][891:]","3e258672":"data_df['Fare'].fillna(data_df['Fare'].median(), inplace = True)\n\n# Making Bins\ndata_df['FareBin'] = pd.qcut(data_df['Fare'], 5)\n\nlabel = LabelEncoder()\ndata_df['FareBin_Code'] = label.fit_transform(data_df['FareBin'])\n\ntrain_df['FareBin_Code'] = data_df['FareBin_Code'][:891]\ntest_df['FareBin_Code'] = data_df['FareBin_Code'][891:]\n\ntrain_df.drop(['Fare'], 1, inplace=True)\ntest_df.drop(['Fare'], 1, inplace=True)","493b2341":"data_df['AgeBin'] = pd.qcut(data_df['Age'], 4)\n\nlabel = LabelEncoder()\ndata_df['AgeBin_Code'] = label.fit_transform(data_df['AgeBin'])\n\ntrain_df['AgeBin_Code'] = data_df['AgeBin_Code'][:891]\ntest_df['AgeBin_Code'] = data_df['AgeBin_Code'][891:]\n\ntrain_df.drop(['Age'], 1, inplace=True)\ntest_df.drop(['Age'], 1, inplace=True)","c5018355":"train_df['Sex'].replace(['male','female'],[0,1],inplace=True)\ntest_df['Sex'].replace(['male','female'],[0,1],inplace=True)\n\ntrain_df.drop(['Name', 'PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin','Embarked'], axis = 1, inplace = True)\ntest_df.drop(['Name','PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin','Embarked'], axis = 1, inplace = True)","1632be97":"train_df.head(3)","4bf6198d":"X = train_df.drop('Survived', 1)\ny = train_df['Survived']\nX_test = test_df.copy()","964a011e":"#scaling the data\nstd_scaler = StandardScaler()\nX = std_scaler.fit_transform(X)\nX_test = std_scaler.transform(X_test)","bcbd6afc":"#KNN to gid search CV\n\nn_neighbors = [6,7,8,9,10,11,12,14,16,18,20,22]\nalgorithm = ['auto']\nweights = ['uniform', 'distance']\nleaf_size = list(range(1,50,5))\nhyperparams = {'algorithm': algorithm, 'weights': weights, 'leaf_size': leaf_size, \n               'n_neighbors': n_neighbors}\ngd=GridSearchCV(estimator = KNeighborsClassifier(), param_grid = hyperparams, verbose=True, \n                cv=10, scoring = \"roc_auc\")\ngd.fit(X, y)\nprint(gd.best_score_)\nprint(gd.best_estimator_)","fe250f3a":"#Using a model found by grid searching\ngd.best_estimator_.fit(X, y)\ny_pred = gd.best_estimator_.predict(X_test)","ce7f154c":"#applying KNN for the above model\nknn = KNeighborsClassifier(algorithm='auto', leaf_size=26, metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=6, p=2, weights='uniform')\nknn.fit(X, y)\ny_pred = knn.predict(X_test)","681a0d0d":"temp = pd.DataFrame(pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")['PassengerId'])\ntemp['Survived'] = y_pred\ntemp.to_csv(\"submission.csv\", index = False)","a849b741":"**Training the data**","959757f5":"**Label Encoding SEX and dropping garbage data**","2c139322":"**Making FARE BINS** making the continous fare data discontinous","b0232cd0":"**Adding FamilySize=Parch+SibSp**","995f7b88":"**Inputting the age as per Title**","a60c60dc":"**Adding Family_Survival** for clubbing together the same tickets and researches the info","74a860b7":"**Making AGE BINS** making the continous age data discontinous"}}