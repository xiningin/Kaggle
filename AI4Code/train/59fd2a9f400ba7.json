{"cell_type":{"71307983":"code","79acf42c":"code","c4593a45":"code","8bb75680":"code","e918296f":"code","a5078c8d":"code","f049eb74":"code","7b9d2d9d":"code","be984e4f":"code","e86d38c8":"code","f7fa3127":"code","2f852b97":"code","f2478791":"code","1a3ae097":"markdown","d28a8252":"markdown","72bc71e6":"markdown","b54cf68f":"markdown"},"source":{"71307983":"%matplotlib inline\n%config InlineBackend.figure_format = 'svg' \nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 100)\n\nimport matplotlib.pyplot as plt\n\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import plot_importance\n\nimport time, sys, gc, pickle\n\n#from itertools import product\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import TimeSeriesSplit","79acf42c":"start = time.time()\ndata = pd.read_pickle('..\/input\/feature-engineering-xgboost\/data.pkl')\nprint('data input costs {:.2f} seconds'.format(time.time()-start))\nprint('data has {} rows and {} columns'.format(data.shape[0], data.shape[1]))\ntest  = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv').set_index('ID')\nprint('test has {} rows and {} columns'.format(test.shape[0], test.shape[1]))","c4593a45":"data = data[[\n    'date_block_num',\n    'shop_id',\n    'item_id',\n    'item_cnt_month',\n    'city_code',\n    'item_category_id',\n    'type_code',\n    'subtype_code',\n    'item_cnt_month_lag_1',\n    'item_cnt_month_lag_2',\n    'item_cnt_month_lag_3',\n    'item_cnt_month_lag_6',\n    'item_cnt_month_lag_12',\n    'date_avg_item_cnt_lag_1',\n    'date_item_avg_item_cnt_lag_1',\n    'date_item_avg_item_cnt_lag_2',\n    'date_item_avg_item_cnt_lag_3',\n    'date_item_avg_item_cnt_lag_6',\n    'date_item_avg_item_cnt_lag_12',\n    'date_shop_avg_item_cnt_lag_1',\n    'date_shop_avg_item_cnt_lag_2',\n    'date_shop_avg_item_cnt_lag_3',\n    'date_shop_avg_item_cnt_lag_6',\n    'date_shop_avg_item_cnt_lag_12',\n    'date_cat_avg_item_cnt_lag_1',\n    'date_shop_cat_avg_item_cnt_lag_1',\n    #'date_shop_type_avg_item_cnt_lag_1',\n    #'date_shop_subtype_avg_item_cnt_lag_1',\n    'date_city_avg_item_cnt_lag_1',\n    'date_item_city_avg_item_cnt_lag_1',\n    #'date_type_avg_item_cnt_lag_1',\n    #'date_subtype_avg_item_cnt_lag_1',\n    'delta_price_lag',\n    'month',\n    'days',\n    'item_shop_last_sale',\n    'item_last_sale',\n    'item_shop_first_sale',\n    'item_first_sale',\n]]\n\n#data = data.sort_values('date_block_num')\nx_train = data[data.date_block_num <= 33].drop(['item_cnt_month'], axis=1)\ny_train = data[data.date_block_num <= 33]['item_cnt_month']\n#X_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n#Y_valid = data[data.date_block_num == 33]['item_cnt_month']\nx_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)\n\ndel data\ngc.collect();\n\ndef run_cross_validate(x_train, y_train, test, N_FOLDS=5):\n    model = XGBRegressor(\n        objective='reg:squarederror',\n        learning_rate=0.05, \n        max_depth=8,\n        n_estimators=1000,\n        min_child_weight=200, \n        colsample_bytree=0.8, \n        subsample=0.8, \n        seed=42,\n        tree_method='gpu_hist' # turn GPU on!!!\n    )\n    tspl = TimeSeriesSplit(n_splits=N_FOLDS)\n    oof_preds = np.zeros(len(x_train))                      # \u4ea4\u53c9\u9a8c\u8bc1\u9884\u6d4b\u7ed3\u679c\n    test_preds = np.zeros(len(test))                        # \u6d4b\u8bd5\u96c6\u9884\u6d4b\u7ed3\u679c\n    oof_losses = []\n    print('gpu training begins ...')\n    for fold, (trn_idx, val_idx) in enumerate(tspl.split(x_train, y_train)):\n        print('Starting fold: ', fold + 1)\n        x_trn, x_val = x_train.iloc[trn_idx], x_train.iloc[val_idx]\n        y_trn, y_val = y_train.iloc[trn_idx], y_train.iloc[val_idx]\n\n        model.fit(x_trn, y_trn, \n                    eval_metric='rmse', \n                    eval_set=[(x_trn, y_trn),(x_val, y_val)], \n                    verbose=10, \n                    early_stopping_rounds = 10)             # set early stopping\n        val_preds = model.predict(x_val) \n        oof_preds[val_idx] = val_preds\n        loss = np.sqrt(mean_squared_error(y_val, val_preds))\n        print('fold {} RMSE is {:.5f}'.format(fold + 1, loss))\n        oof_losses.append(loss)\n        preds = model.predict(test) \n        test_preds += preds \/ N_FOLDS\n        print('-' * 50)\n        print('\\n')\n    print('Mean OOF RMSE across folds is {:.5f}'.format(np.mean(oof_losses))) # \u6bcf\u4e00\u6298\u7684\u9a8c\u8bc1\u5206\u6570\u5e73\u5747\n    print('GPU Xgb costs {:.2f} seconds'.format(time.time()-start))\n    return test_preds, oof_preds","8bb75680":"test_preds, oof_preds = run_cross_validate(x_train, y_train, x_test, 3)","e918296f":"Y_test = test_preds.clip(0, 20)\nsubmission = pd.DataFrame({ 'ID': test.index, 'item_cnt_month': Y_test})\nsubmission.to_csv('submission.csv', index=False)","a5078c8d":"def run_cross_validate(x_train, y_train, test, N_FOLDS=5):\n    model = CatBoostRegressor(eval_metric='RMSE',\n                          iterations=1000,\n                          max_ctr_complexity=4,\n                          random_seed=42,\n                          od_type='Iter',\n                          od_wait=100,\n                          verbose=50,\n                          depth=8,\n                          metric_period = 50,\n                          task_type='GPU'\n                            )\n    tspl = TimeSeriesSplit(n_splits=N_FOLDS)\n    oof_preds = np.zeros(len(x_train))                      # \u4ea4\u53c9\u9a8c\u8bc1\u9884\u6d4b\u7ed3\u679c\n    test_preds = np.zeros(len(test))                        # \u6d4b\u8bd5\u96c6\u9884\u6d4b\u7ed3\u679c\n    oof_losses = []\n    print('gpu training begins ...')\n    for fold, (trn_idx, val_idx) in enumerate(tspl.split(x_train, y_train)):\n        print('Starting fold: ', fold + 1)\n        x_trn, x_val = x_train.iloc[trn_idx], x_train.iloc[val_idx]\n        y_trn, y_val = y_train.iloc[trn_idx], y_train.iloc[val_idx]\n        y_trn = np.array(y_trn).astype('float32')\n        y_val = np.array(y_val).astype('float32')\n        model.fit(x_trn, y_trn,\n                    eval_set=[(x_val, y_val)],  # Multiple eval sets are not supported on GPU\n                    verbose=True,\n                    use_best_model=True)            \n        val_preds = model.predict(x_val) \n        oof_preds[val_idx] = val_preds\n        loss = np.sqrt(mean_squared_error(y_val, val_preds))\n        print('fold {} RMSE is {:.5f}'.format(fold + 1, loss))\n        oof_losses.append(loss)\n        preds = model.predict(test) \n        test_preds += preds \/ N_FOLDS\n        print('-' * 50)\n        print('\\n')\n    print('Mean OOF RMSE across folds is {:.5f}'.format(np.mean(oof_losses))) # \u6bcf\u4e00\u6298\u7684\u9a8c\u8bc1\u5206\u6570\u5e73\u5747\n    print('GPU Xgb costs {:.2f} seconds'.format(time.time()-start))\n    return test_preds, oof_preds","f049eb74":"test_preds, oof_preds = run_cross_validate(x_train, y_train, x_test, 3)","7b9d2d9d":"'''\nstart = time.time()\nprint('cpu training begins ...')\nmodel = XGBRegressor(\n    max_depth=8,\n    n_estimators=1000,\n    min_child_weight=300, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.3,    \n    seed=42\n)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric='rmse', \n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=True, \n    early_stopping_rounds = 10)\n\nprint('CPU Xgb costs {:.2f} seconds'.format(time.time()-start))\n'''","be984e4f":"'''\nstart = time.time()\nprint('gpu training begins ...')\nmodel = XGBRegressor(\n    max_depth=8,\n    n_estimators=1000,\n    min_child_weight=300, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.3,    \n    seed=42,\n    tree_method='gpu_hist' # turn GPU on!!!\n)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric='rmse', \n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=10, \n    early_stopping_rounds = 10)\n\nprint('GPU Xgb costs {:.2f} seconds'.format(time.time()-start))\n'''","e86d38c8":"'''\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nplt.rcParams['figure.facecolor'] = 'white'\nplot_features(model, (7.5,10))\n'''","f7fa3127":"'''\nprint('learning rate:',model.learning_rate_)\nY_pred = model.predict(X_valid).clip(0, 20)\nY_test = model.predict(X_test).clip(0, 20)\n\nsubmission = pd.DataFrame({ 'ID': test.index, 'item_cnt_month': Y_test})\nsubmission.to_csv('submission.csv', index=False)\n'''","2f852b97":"'''\nstart = time.time()\nprint('gpu training begins ...')\nmodel = CatBoostRegressor(eval_metric='RMSE',\n                          iterations=1000,\n                          max_ctr_complexity=4,\n                          random_seed=42,\n                          od_type='Iter',\n                          od_wait=100,\n                          verbose=50,\n                          depth=8,\n                          metric_period = 50,\n                          task_type='GPU'\n)\nY_train = np.array(Y_train).astype('float32')\nY_valid = np.array(Y_valid).astype('float32')\nmodel.fit(X_train, \n          Y_train,\n          eval_set=[(X_valid, Y_valid)], \n          verbose=True, \n          use_best_model=True)\nprint('GPU Cat costs {:.2f} seconds'.format(time.time()-start))    \n'''","f2478791":"# save predictions for an ensemble\n# pickle.dump(Y_pred, open('xgb_train.pickle', 'wb'))\n# pickle.dump(Y_test, open('xgb_test.pickle', 'wb'))","1a3ae097":"In order to use GPU version of Xgboost, remember to turn the 'Always use latest environment' option on!","d28a8252":"# timeseries ml via gpu\n\ngpu guides:   \nhttps:\/\/www.kaggle.com\/c\/santander-customer-transaction-prediction\/discussion\/89004  \nhttps:\/\/www.kaggle.com\/raimonds1993\/gbms-cpu-vs-gpu-400-features-augmentation\/","72bc71e6":"[TypeError: No matching signature found](https:\/\/github.com\/catboost\/catboost\/issues\/1233)","b54cf68f":"https:\/\/xgboost.readthedocs.io\/en\/latest\/python\/python_api.html#module-xgboost.sklearn"}}