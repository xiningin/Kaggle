{"cell_type":{"ca7937bf":"code","654151d5":"code","92778747":"code","29dfa7dc":"code","5edcde64":"code","6fa10028":"code","2d79bbe1":"code","9c6c8b35":"code","3643a704":"code","3e2cb630":"code","91b2adca":"code","feda235e":"code","82a8be3b":"code","9faa0040":"code","8104cc20":"code","53e37645":"code","6a4846f4":"code","8aa29beb":"code","2bf1c305":"code","46df5746":"code","ad0935b3":"code","7dabc473":"code","7aa621df":"code","aabcd97f":"code","522278a5":"code","411f956f":"code","a4927e34":"code","36fd5741":"code","105cec75":"code","517fe4df":"code","4e43058e":"code","9ef0fd2d":"code","ae9eda15":"code","309b729c":"code","af111576":"code","33fab1cd":"code","1a8609a0":"code","3e79620f":"code","639ecf61":"code","8a19ac63":"code","857328f1":"code","4e8c1117":"code","88016213":"code","d99d2636":"code","644ea361":"code","601e301d":"code","6709b49a":"markdown","600f5206":"markdown","2ab0c29a":"markdown","a6306d5b":"markdown","b6c29d88":"markdown","36a06722":"markdown","7d9e8a97":"markdown","81794f10":"markdown","b0fb578a":"markdown","747ab9aa":"markdown","09997395":"markdown","991ad922":"markdown","a7148dc8":"markdown","e8282c92":"markdown","c3ec5078":"markdown","7e974b88":"markdown"},"source":{"ca7937bf":"from numpy.random import seed\nseed(101)\nfrom tensorflow import set_random_seed\nset_random_seed(101)\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nimport os\nimport cv2\n\nimport imageio\nimport skimage\nimport skimage.io\nimport skimage.transform\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","654151d5":"# Number of samples we want in each class.Total images used = SAMPLE_SIZE X 2\n# The minority class is class 1 with 78786 samples.\n\nSAMPLE_SIZE = 78786\n\nIMAGE_SIZE = 50","92778747":"os.listdir('..\/input\/IDC_regular_ps50_idx5')","29dfa7dc":"# Check the number of patient folders.\n\npatients = os.listdir('..\/input\/IDC_regular_ps50_idx5')\n\nlen(patients)","5edcde64":"# Create a new directory to store all available images\nall_images_dir = 'all_images_dir'\nos.mkdir(all_images_dir)\n","6fa10028":"# check that the new diectory has been created\n!ls","2d79bbe1":"# This code copies all images from their seperate folders into the same \n# folder called all_images_dir.\n\n# Create a list with all the patient id numbers.\n# Each patient id folder has 2 sub folders --> folder 0 and folder 1\n\n# Example:\n    # '10285'\n        # '0'\n        # '1'\n\n# create a list of all patient id's\npatient_list = os.listdir('..\/input\/IDC_regular_ps50_idx5')\n\nfor patient in patient_list:\n    \n    path_0 = '..\/input\/IDC_regular_ps50_idx5\/' + str(patient) + '\/0'\n    path_1 = '..\/input\/IDC_regular_ps50_idx5\/' + str(patient) + '\/1'\n\n\n    # create a list of all files in folder 0\n    file_list_0 = os.listdir(path_0)\n    # create a list of list all file in folder 1\n    file_list_1 = os.listdir(path_1)\n\n    # move the 0 images to all_images_dir\n    for fname in file_list_0:\n\n        # source path to image\n        src = os.path.join(path_0, fname)\n        # destination path to image\n        dst = os.path.join(all_images_dir, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n\n\n    # move the 1 images to all_images_dir\n    for fname in file_list_1:\n\n        # source path to image\n        src = os.path.join(path_1, fname)\n        # destination path to image\n        dst = os.path.join(all_images_dir, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n","9c6c8b35":"# check how many images are in all_images_dir\n# should be 277,524\n\n# size: 2.5GB\n\nlen(os.listdir('all_images_dir'))","3643a704":"image_list = os.listdir('all_images_dir')\n\ndf_data = pd.DataFrame(image_list, columns=['image_id'])\n\ndf_data.head()","3e2cb630":"# Define Helper Functions\n\n# Each file name has this format:\n# '14211_idx5_x2401_y1301_class1.png'\n\ndef extract_patient_id(x):\n    # split into a list\n    a = x.split('_')\n    # the id is the first index in the list\n    patient_id = a[0]\n    \n    return patient_id\n\ndef extract_target(x):\n    # split into a list\n    a = x.split('_')\n    # the target is part of the string in index 4\n    b = a[4]\n    # the ytarget i.e. 1 or 2 is the 5th index of the string --> class1\n    target = b[5]\n    \n    return target\n\n# extract the patient id\n\n# create a new column called 'patient_id'\ndf_data['patient_id'] = df_data['image_id'].apply(extract_patient_id)\n# create a new column called 'target'\ndf_data['target'] = df_data['image_id'].apply(extract_target)\n\ndf_data.head(10)","91b2adca":"df_data.shape","feda235e":"# source: https:\/\/www.kaggle.com\/gpreda\/honey-bee-subspecies-classification\n\ndef draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n    \n    \"\"\"\n    Give a column in a dataframe,\n    this function takes a sample of each class and displays that\n    sample on one row. The sample size is the same as figure_cols which\n    is the number of columns in the figure.\n    Because this function takes a random sample, each time the function is run it\n    displays different images.\n    \"\"\"\n    \n\n    categories = (df.groupby([col_name])[col_name].nunique()).index\n    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols, \n                         figsize=(4*figure_cols,4*len(categories))) # adjust size here\n    # draw a number of images for each location\n    for i, cat in enumerate(categories):\n        sample = df[df[col_name]==cat].sample(figure_cols) # figure_cols is also the sample size\n        for j in range(0,figure_cols):\n            file=IMAGE_PATH + sample.iloc[j]['image_id']\n            im=cv2.imread(file)\n            ax[i, j].imshow(im, resample=True, cmap='gray')\n            ax[i, j].set_title(cat, fontsize=16)  \n    plt.tight_layout()\n    plt.show()","82a8be3b":"IMAGE_PATH = 'all_images_dir\/'\n\ndraw_category_images('target',4, df_data, IMAGE_PATH)","9faa0040":"# What is the class distribution?\n\ndf_data['target'].value_counts()","8104cc20":"# take a sample of the majority class 0 (total = 198738)\ndf_0 = df_data[df_data['target'] == '0'].sample(SAMPLE_SIZE, random_state=101)\n# take a sample of class 1 (total = 78786)\ndf_1 = df_data[df_data['target'] == '1'].sample(SAMPLE_SIZE, random_state=101)\n\n# concat the two dataframes\ndf_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n\n# Check the new class distribution\ndf_data['target'].value_counts()","53e37645":"# train_test_split\n\n# stratify=y creates a balanced validation set.\ny = df_data['target']\n\ndf_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)\n\nprint(df_train.shape)\nprint(df_val.shape)","6a4846f4":"df_train['target'].value_counts()","8aa29beb":"df_val['target'].value_counts()","2bf1c305":"# Create a new directory\nbase_dir = 'base_dir'\nos.mkdir(base_dir)\n\n\n#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n\n# now we create 2 folders inside 'base_dir':\n\n# train_dir\n    # a_no_idc\n    # b_has_idc\n\n# val_dir\n    # a_no_idc\n    # b_has_idc\n\n\n\n# create a path to 'base_dir' to which we will join the names of the new folders\n# train_dir\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\n\n# val_dir\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\n\n\n# [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n# Inside each folder we create seperate folders for each class\n\n# create new folders inside train_dir\na_no_idc = os.path.join(train_dir, 'a_no_idc')\nos.mkdir(a_no_idc)\nb_has_idc = os.path.join(train_dir, 'b_has_idc')\nos.mkdir(b_has_idc)\n\n\n# create new folders inside val_dir\na_no_idc = os.path.join(val_dir, 'a_no_idc')\nos.mkdir(a_no_idc)\nb_has_idc = os.path.join(val_dir, 'b_has_idc')\nos.mkdir(b_has_idc)\n","46df5746":"# check that the folders have been created\nos.listdir('base_dir\/train_dir')","ad0935b3":"# Set the id as the index in df_data\ndf_data.set_index('image_id', inplace=True)","7dabc473":"# Get a list of train and val images\ntrain_list = list(df_train['image_id'])\nval_list = list(df_val['image_id'])\n\n\n\n# Transfer the train images\n\nfor image in train_list:\n    \n    # the id in the csv file does not have the .tif extension therefore we add it here\n    fname = image\n    # get the label for a certain image\n    target = df_data.loc[image,'target']\n    \n    # these must match the folder names\n    if target == '0':\n        label = 'a_no_idc'\n    if target == '1':\n        label = 'b_has_idc'\n    \n    # source path to image\n    src = os.path.join(all_images_dir, fname)\n    # destination path to image\n    dst = os.path.join(train_dir, label, fname)\n    # move the image from the source to the destination\n    shutil.move(src, dst)\n    \n\n# Transfer the val images\n\nfor image in val_list:\n    \n    # the id in the csv file does not have the .tif extension therefore we add it here\n    fname = image\n    # get the label for a certain image\n    target = df_data.loc[image,'target']\n    \n    # these must match the folder names\n    if target == '0':\n        label = 'a_no_idc'\n    if target == '1':\n        label = 'b_has_idc'\n    \n\n    # source path to image\n    src = os.path.join(all_images_dir, fname)\n    # destination path to image\n    dst = os.path.join(val_dir, label, fname)\n    # move the image from the source to the destination\n    shutil.move(src, dst)","7aa621df":"# check how many train images we have in each folder\n\nprint(len(os.listdir('base_dir\/train_dir\/a_no_idc')))\nprint(len(os.listdir('base_dir\/train_dir\/b_has_idc')))","aabcd97f":"# check how many val images we have in each folder\n\nprint(len(os.listdir('base_dir\/val_dir\/a_no_idc')))\nprint(len(os.listdir('base_dir\/val_dir\/b_has_idc')))\n","522278a5":"# End of Data Preparation\n### ================================================================================== ###\n# Start of Model Building","411f956f":"train_path = 'base_dir\/train_dir'\nvalid_path = 'base_dir\/val_dir'\n\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 10\nval_batch_size = 10\n\n\ntrain_steps = np.ceil(num_train_samples \/ train_batch_size)\nval_steps = np.ceil(num_val_samples \/ val_batch_size)","a4927e34":"datagen = ImageDataGenerator(rescale=1.0\/255)\n\ntrain_gen = datagen.flow_from_directory(train_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=train_batch_size,\n                                        class_mode='categorical')\n\nval_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=val_batch_size,\n                                        class_mode='categorical')\n\n# Note: shuffle=False causes the test dataset to not be shuffled\ntest_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=1,\n                                        class_mode='categorical',\n                                        shuffle=False)","36fd5741":"# Source: https:\/\/www.kaggle.com\/fmarazzi\/baseline-keras-cnn-roc-fast-5min-0-8253-lb\n\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\ndropout_conv = 0.3\ndropout_dense = 0.3\n\n\nmodel = Sequential()\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu', \n                 input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(2, activation = \"softmax\"))\n\nmodel.summary()","105cec75":"model.compile(Adam(lr=0.0001), loss='binary_crossentropy', \n              metrics=['accuracy'])\n","517fe4df":"filepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3, \n                                   verbose=1, mode='max', min_lr=0.00001)\n                              \n                              \ncallbacks_list = [checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=20, verbose=1,\n                   callbacks=callbacks_list)","4e43058e":"# get the metric names so we can use evaulate_generator\nmodel.metrics_names","9ef0fd2d":"# Here the best epoch will be used.\n\nmodel.load_weights('model.h5')\n\nval_loss, val_acc = \\\nmodel.evaluate_generator(test_gen, \n                        steps=len(df_val))\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","ae9eda15":"# display the loss and accuracy curves\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()","309b729c":"# make a prediction\npredictions = model.predict_generator(test_gen, steps=len(df_val), verbose=1)","af111576":"predictions.shape","33fab1cd":"# This is how to check what index keras has internally assigned to each class. \ntest_gen.class_indices","1a8609a0":"# Put the predictions into a dataframe.\n# The columns need to be oredered to match the output of the previous cell\n\ndf_preds = pd.DataFrame(predictions, columns=['no_idc', 'has_idc'])\n\ndf_preds.head()","3e79620f":"# Get the true labels\ny_true = test_gen.classes\n\n# Get the predicted labels as probabilities\ny_pred = df_preds['has_idc']","639ecf61":"from sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_true, y_pred)","8a19ac63":"# Source: Scikit Learn website\n# http:\/\/scikit-learn.org\/stable\/auto_examples\/\n# model_selection\/plot_confusion_matrix.html#sphx-glr-auto-examples-model-\n# selection-plot-confusion-matrix-py\n\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","857328f1":"# Get the labels of the test images.\n\ntest_labels = test_gen.classes","4e8c1117":"test_labels.shape","88016213":"# argmax returns the index of the max value in a row\ncm = confusion_matrix(test_labels, predictions.argmax(axis=1))","d99d2636":"# Print the label associated with each class\ntest_gen.class_indices","644ea361":"# Define the labels of the class indices. These need to match the \n# order shown above.\ncm_plot_labels = ['no_idc', 'has_idc']\n\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')\n","601e301d":"from sklearn.metrics import classification_report\n\n# Generate a classification report\n\n# For this to work we need y_pred as binary labels not as probabilities\ny_pred_binary = predictions.argmax(axis=1)\n\nreport = classification_report(y_true, y_pred_binary, target_names=cm_plot_labels)\n\nprint(report)","6709b49a":"### Display a random sample of train images by class","600f5206":"### Transfer the images into the folders\u00b6","2ab0c29a":"### Create the train and  val sets\n","a6306d5b":"### Evaluate the model using the val set","b6c29d88":"### Create the Model Architecture","36a06722":"### Copy all images into one directory\nThis will make it easier to work with this data.","7d9e8a97":"### Create a dataframe containing all the information","81794f10":"### Set Up the Generators","b0fb578a":"### What is the AUC Score?","747ab9aa":"### Create a Confusion Matrix","09997395":"### Create a Classification Report","991ad922":"### Plot the Training Curves","a7148dc8":"### Create a Directory Structure","e8282c92":"### Balance the class distribution","c3ec5078":"### Make a prediction on the val set\nWe need these predictions to calculate the AUC score, print the Confusion Matrix and calculate the F1 score.","7e974b88":"### Train the Model"}}