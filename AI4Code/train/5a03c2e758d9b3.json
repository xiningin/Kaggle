{"cell_type":{"b7e899ec":"code","accdd677":"code","5fe6cac7":"code","1472b4af":"code","b3e82641":"code","20f0be8b":"code","6940ed5d":"code","37556de6":"code","cb698c28":"code","a83abd95":"code","f79ad481":"code","446c638b":"code","3c3fe5b8":"code","72f571dd":"code","671df562":"code","1f828bdd":"code","35885c11":"code","086e11c7":"code","f49dc62a":"code","b98cadb3":"code","911feb46":"code","7b071673":"code","34df09c5":"code","e203cc21":"code","0217156d":"code","243e898d":"code","b3fed2da":"code","9fb651c3":"code","4aa23102":"code","8e760c1f":"code","bab441ed":"code","f6b29a98":"markdown"},"source":{"b7e899ec":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","accdd677":"data = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","5fe6cac7":"data.head()","1472b4af":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data.drop('Class',axis=1), \n                                                    data['Class'], test_size=0.30, \n                                                    random_state=101)","b3e82641":"from sklearn.linear_model import LogisticRegression","20f0be8b":"logmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)","6940ed5d":"predictions = logmodel.predict(X_test)","37556de6":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,predictions))","cb698c28":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test,predictions))","a83abd95":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(data.drop('Class',axis=1))","f79ad481":"scaled_data = scaler.transform(data.drop('Class',axis=1))","446c638b":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\npca.fit(scaled_data)","3c3fe5b8":"x_pca = pca.transform(scaled_data)","72f571dd":"x_pca.shape","671df562":"plt.figure(figsize=(8,6))\nplt.scatter(x_pca[:,0],x_pca[:,1],c=data['Class'])\nplt.xlabel('First principal component')\nplt.ylabel('Second Principal Component')","1f828bdd":"X_train, X_test, y_train, y_test = train_test_split(x_pca, \n                                                    data['Class'], test_size=0.30, \n                                                    random_state=101)","35885c11":"logmodel2 = LogisticRegression()\nlogmodel2.fit(X_train,y_train)","086e11c7":"predictions = logmodel2.predict(X_test)","f49dc62a":"print(classification_report(y_test,predictions))","b98cadb3":"print(confusion_matrix(y_test,predictions))","911feb46":"X_train, X_test, y_train, y_test = train_test_split(data.drop('Class',axis=1), \n                                                    data['Class'], test_size=0.30, \n                                                    random_state=101)\n\nfrom sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)\n\npredictions = dtree.predict(X_test)","7b071673":"print(classification_report(y_test,predictions))","34df09c5":"print(confusion_matrix(y_test,predictions))","e203cc21":"from sklearn.svm import SVC\nmodel = SVC()\nmodel.fit(X_train,y_train)\npredictions = model.predict(X_test)","0217156d":"print(classification_report(y_test,predictions))","243e898d":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)","b3fed2da":"print(classification_report(y_test,pred))","9fb651c3":"print(confusion_matrix(y_test,pred))","4aa23102":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=10)\nrfc.fit(X_train, y_train)\nrfc_pred = rfc.predict(X_test)","8e760c1f":"print(confusion_matrix(y_test,rfc_pred))","bab441ed":"print(classification_report(y_test,rfc_pred))","f6b29a98":"# Conclusion\nDamn! I tried almost everything here. I guess the best results were given by random forest classifier and doing that PCA wasn't so useful (I had hoped better). The noteboook isn't explained step by step but I was in a hurry so bear with that. Let me know what else I should have tried and also why you think some of the results were so wierd and unexpected. Also leave an upvote if you liked it (and even if you didn't like it upvote anyway cuz what harm does it do huh)."}}