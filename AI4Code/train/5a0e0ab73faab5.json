{"cell_type":{"1ef33222":"code","8d10a2c2":"code","3640d708":"code","c8648431":"code","66410487":"code","8cd947f3":"code","30410a7c":"code","e4933584":"code","eda17aaf":"code","45c60b53":"code","f0d2a666":"code","70e6181c":"code","952a9806":"code","d28b416c":"code","a69d068e":"code","4ccaef15":"code","e5639130":"code","f357e9ac":"code","62ddab86":"code","0a1823fc":"code","4c46b227":"code","3ec05984":"code","2bb56191":"code","db4d7e33":"code","7de61925":"code","8f58efea":"code","0c98160f":"code","300dc154":"code","5cf64847":"code","7107fd07":"markdown","640700ac":"markdown","2fbdc655":"markdown","a9a97005":"markdown","8d211b8d":"markdown","cf63624a":"markdown","60d12c13":"markdown","423185db":"markdown","96e12bbb":"markdown","7751e82b":"markdown","2aca28cc":"markdown","03dc2f83":"markdown"},"source":{"1ef33222":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.stattools import acf,pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport os\nimport seaborn as sns\nsns.set()\n\nfigsize = (20,7)\nfigsize2 = (20,5)\n\nimport os\ndirectory = '..\/input\/hourly-weather-surface-brazil-southeast-region\/'\nos.chdir(directory)\nimport make_dataset as mk","8d10a2c2":"df_raw = pd.read_csv('southeast.csv')\nstations = ['A612']\nstart_date = '2006-11-01'\ndf = mk.make_dataset(stations, start_date, df_raw)\ndf_raw = None","3640d708":"## adding covariables\ndf['hour'] = df.date_time.dt.hour\ndf['month'] = df.date_time.dt.month\ndf['year'] = df.date_time.dt.year\ndf['day_of_year'] = df.date_time.dt.day_of_year\ndf['weekofyear'] = df.date_time.dt.weekofyear\n\n## transforming start hour in 9, to use hour**3, some models are hierarchical so is necessary to keep hour**2 \ndf['hour_9'] = df['hour'].apply(lambda x: (x-9)%24)\ndf['hour_9**2'] = df['hour_9']**2\ndf['hour_9**3'] = df['hour_9']**3","c8648431":"## preprocessing + covariables\ndef create_sincos_year_array(n,start_date,end_date,n_days_in_year = 366):\n    start_date = pd.to_datetime(start_date)\n    end_date   = pd.to_datetime(end_date)\n    \n    ## day distance\n    first_date = pd.to_datetime('{year}-01-01'.format(year = start_date.year))\n    day_of_the_year_start = (start_date - first_date).days\n        \n    ## year distance\n    distance = (end_date - first_date).days\n    \n    ##\n    start = (np.pi*2)*(day_of_the_year_start\/n_days_in_year)\n    end = np.pi*2*(distance\/n_days_in_year)\n    \n    length = np.arange(start, end, (end-start)\/n)\n    df =  pd.concat([pd.Series(np.sin(length)),pd.Series(np.cos(length))],axis=1)\n    df.columns = ['sin_year','cos_year']\n    return df\n\ndef make_dummies(series):\n    df = pd.get_dummies(series,drop_first=True)\n    df.columns = list(map(lambda x: '{}_'.format(series.name) + str(x),list(df.columns)))\n    return df","66410487":"## setting target variables to be easy to call later\ny1,y2,y3 = 'A612_prcp','A612_tmax','A612_tmin'# 'A612 - total precipitation (mm)' \"max temp\" \"min temp\"","8cd947f3":"## For all\ndf_model = df[df.date_time < '01-01-2020']\ndf_model = pd.concat([df_model,create_sincos_year_array(df_model.shape[0], df_model.date_time.max(), df_model.date_time.min(), n_days_in_year=366)],axis=1)\n_y_ = df_model[[y1,y2,y3]]","30410a7c":"x = df_model.iloc[:,-10:]\nx['hour'] = df_model.hour\nx = x.drop(['day_of_year','weekofyear','year'],axis=1)","e4933584":"## 1 just dummies model\nx_dummy = pd.concat([x,make_dummies(x['hour'])],axis=1)\nx_dummy = pd.concat([x_dummy,make_dummies(x['month'])],axis=1)\nx_dummy.drop(['month', 'hour_9', 'hour_9**2', 'hour_9**3', 'hour', 'sin_year', 'cos_year'],axis=1,inplace=True)\nx_dummy['intercept'] = 1","eda17aaf":"## 2 month dummies and hour transformed\nx_hour_9 = pd.concat([x,make_dummies(x['month'])],axis=1)\nx_hour_9.drop(['month', 'hour', 'sin_year', 'cos_year'],axis=1,inplace=True)\nx_hour_9['intercept'] = 1","45c60b53":"## 3 hour transformed and sin and cos\nx_no_dummies = df_model.loc[:,['hour_9', 'hour_9**2', 'hour_9**3','sin_year', 'cos_year']]\nx_no_dummies['intercept'] = 1","f0d2a666":"from statsmodels.regression.linear_model import OLS\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom sklearn.model_selection import train_test_split\nfrom metrics import create_metrics","70e6181c":"def ols_model(x, y, codename=None):\n    if codename == None:\n        codename = f'{ x.shape[1] }_{ y.name.split(\" \")[2] }'\n        \n    x_train, x_test = x[df_model.date_time<'01-01-2018'], x[df_model.date_time>='01-01-2018']\n    y_train, y_test = y[df_model.date_time<'01-01-2018'], y[df_model.date_time>='01-01-2018']\n    \n    model = OLS(y_train,x_train)\n    fit = model.fit()\n    y_pred = fit.predict(x_test)\n    \n    metrics = create_metrics(y_test,y_pred)\n    return {'y_pred': y_pred, 'fit': fit, 'model':model, 'metrics':metrics, 'codename': codename}","952a9806":"model_dummies = ols_model(x_dummy,_y_.iloc[:,2],codename='Dummies')","d28b416c":"model_dummies['metrics']","a69d068e":"residuals = model_dummies['fit'].resid\nplt.xlim(-10,10)\n_ = sns.histplot(residuals)","4ccaef15":"_ = plot_acf(residuals)\n_ = plot_pacf(residuals)","e5639130":"df_plot = pd.DataFrame(df_model.date_time[:len(residuals)])\ndf_plot['resid'] = residuals\ndf_plot.index = df_plot.date_time\ndf_plot.drop('date_time',inplace=True,axis=1)\ndf_plot = df_plot.resample('M').mean()\n_ = df_plot.plot()","f357e9ac":"model_hour9 = ols_model(x_hour_9,_y_.iloc[:,2], codename='Hour 9')","62ddab86":"model_hour9['metrics']","0a1823fc":"residuals = model_hour9['fit'].resid\nplt.xlim(-10,10)\n_ = sns.histplot(residuals)","4c46b227":"_ = plot_acf(residuals)\n_ = plot_pacf(residuals)","3ec05984":"df_plot = pd.DataFrame(df_model.date_time[:len(residuals)])\ndf_plot['resid'] = residuals\ndf_plot.index = df_plot.date_time\ndf_plot.drop('date_time',inplace=True,axis=1)\ndf_plot = df_plot.resample('M').mean()\n_ = df_plot.plot()","2bb56191":"model_no_dummies = ols_model(x_no_dummies,_y_.iloc[:,2], codename='No Dummies')","db4d7e33":"model_no_dummies['metrics']","7de61925":"residuals = model_no_dummies['fit'].resid\nplt.xlim(-10,10)\n_ = sns.histplot(residuals)","8f58efea":"_ = plot_acf(residuals)\n_ = plot_pacf(residuals)","0c98160f":"df_plot = pd.DataFrame(df_model.date_time[:len(residuals)])\ndf_plot['resid'] = residuals\ndf_plot.index = df_plot.date_time\ndf_plot.drop('date_time',inplace=True,axis=1)\ndf_plot = df_plot.resample('M').mean()\n_ = df_plot.plot()","300dc154":"def metrics_dataframe(models,models_names = None):\n    vector = []\n    lenght = len(models)\n    for i in range(lenght):\n        vector.append(pd.DataFrame([models[i]['metrics']],index=[models[i]['codename']]))\n    return pd.concat(vector)","5cf64847":"# names = ['Dummies','No Dummies','Hour9']\nmodels = [model_dummies, model_hour9, model_no_dummies]\nmetrics_dataframe(models)","7107fd07":"## Conclusions","640700ac":"#### Y","2fbdc655":"# 3. Models","a9a97005":"---\n# Linear Regression Models","8d211b8d":"## 3. No dummies","cf63624a":"# OLS - Linear Regression Models Notebook\nThis notebook is for making first models using dataset ES_0.  \n3 linear reg models to get information about the data to make AR models.\n\n#### Objective:\n1. make models progressively adding information as covariables:\n    1. mean and sd\n    2. ols - hour and month dummies\n    3. ols - hour transformed and month dummies \n    4. ols - hour transformed and month information as sin and cos\n\n### Proposal notebook structure:\n1. Imports and adding non-stocastic covariables\n2. Declaring X and Y to each model\n3. Model making: for each model\n    1. Create X from each of the models\n    1. metrics\n    2. errors graphs\n    3. acf and pacf errors","60d12c13":"## 2. Transformed hour model","423185db":"### X","96e12bbb":"## 2. Transformed hour model","7751e82b":"## 1. Importing and adding basic covariables","2aca28cc":"## 1. Dummies model","03dc2f83":"# 2 - Declaring x and y to be used"}}