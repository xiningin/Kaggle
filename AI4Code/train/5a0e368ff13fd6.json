{"cell_type":{"13dd4275":"code","30602164":"code","766b34fa":"code","f9a63d8a":"code","5b141067":"code","8bf7d1cb":"code","6673d7f9":"code","21c338fb":"code","305245b3":"code","c8a1cccb":"code","991f14bd":"code","02dedbba":"code","53fd29c0":"code","91c65909":"code","9e537fbd":"code","21ff55fd":"code","33935b67":"markdown"},"source":{"13dd4275":"import pandas as pd\nimport numpy as np\nimport datatable as dt\nimport random \nimport time\nimport os\nimport gc\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\n\nimport lightgbm as lgb\nimport catboost as cat\nimport xgboost as xgb\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom warnings import filterwarnings as warning\nprint('done!')\nwarning(\"ignore\")","30602164":"N_SPLITS = 5\nN_ESTIMATORS = 1000\nEARLY_STOPPING_ROUNDS = 200\nVERBOSE = 1000\nSEED   = 42\nSEED_X = 2021\n","766b34fa":"def seed_everything(seed = 42):\n    random.seed(seed)\n    os.environ['PYTHONHASSEED'] = str(seed)\n    np.random.seed(seed)\n    \nseed_everything(SEED)","f9a63d8a":"def reduce_memory(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) \/ start_mem\n            )\n        )\n    return df","5b141067":"%%time\n\npath = \"..\/input\/tabular-playground-series-oct-2021\/\"\n\n# train = pd.read_csv(path + \"train.csv\")\n# test  = pd.read_csv(path + \"test.csv\")\n# sample   = pd.read_csv(path + \"sample_submission.csv\")\n\ntrain = dt.fread(path + \"train.csv\").to_pandas().drop('id', axis =1)\ntrain = reduce_memory(train)\ntest  = dt.fread(path + \"test.csv\").to_pandas().drop('id', axis =1)\ntest  = reduce_memory(test)\nsample= dt.fread(path + \"sample_submission.csv\").to_pandas()\nsample= reduce_memory(sample)","8bf7d1cb":"train.dtypes.unique()","6673d7f9":"bool_cols_train = []\n\nfor i, col in enumerate(train.columns):\n    if train[col].dtypes == bool:\n        bool_cols_train.append(i)\n\n","21c338fb":"bool_cols_test = []\n\nfor i, col in enumerate(test.columns):\n    if train[col].dtypes == bool:\n        bool_cols_test.append(i)\n        ","305245b3":"train.iloc[:, bool_cols_train] = train.iloc[:, bool_cols_train].astype(int)\ntest.iloc[:,  bool_cols_test]  = test.iloc[:, bool_cols_test].astype(int)","c8a1cccb":"train.shape, test.shape","991f14bd":"X = train.drop('target', axis=1).copy()\ny = train['target'].copy()\nX_test = test.copy()\n\ndel train, test","02dedbba":"X['std'] = X.std(axis=1)\nX['min'] = X.min(axis=1)\nX['max'] = X.max(axis=1)\n\nX_test['std'] = X_test.std(axis=1)\nX_test['min'] = X_test.min(axis=1)\nX_test['max'] = X_test.max(axis=1)\n","53fd29c0":"params = {\n    'max_depth': 6,\n    'n_estimators': 9500,\n    'learning_rate': 7e-3,\n    'subsample': 0.7,\n    'colsample_bytree': 0.2,\n    'colsample_bylevel': 0.6000000000000001,\n    'min_child_weight': 56.41980735551558,\n    'reg_lambda': 75.56651890088857,\n    'reg_alpha': 0.11766857055687065,\n    'gamma': 0.6407823221122686,\n    'booster': 'gbtree',\n    'eval_metric': 'auc',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n    'use_label_encoder': False\n    }","91c65909":"def cross_validate_model(class_name, class_params, X, y, test_data, n_splits = N_SPLITS):\n\n    skf = StratifiedKFold(n_splits = N_SPLITS, shuffle=True, random_state=SEED)\n\n    valid_predictions = {}\n    test_predictions  = []\n    \n    oof_scores= []\n    oof_preds = []\n\n    for fold, (trn_idx, val_idx) in enumerate(skf.split(X, y)):\n        print(f\"{'='*10} fold {fold+1} strated {'='*10}\")\n\n        xtrain, ytrain = X.iloc[trn_idx], y.iloc[trn_idx]\n        xvalid, yvalid = X.iloc[val_idx], y.iloc[val_idx]\n\n        start = time.time()\n        \n        clf = class_name(**class_params)\n        \n        if class_name.__name__ == 'CatBoostClassifier':            \n            clf.fit(xtrain, ytrain,\n                    eval_set=[(xvalid, yvalid)],\n                    early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n                    verbose=VERBOSE)            \n        else:\n            clf.fit(xtrain, ytrain,\n                    eval_set=[(xtrain, ytrain), (xvalid, yvalid)],\n                    eval_metric='auc',\n                    early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n                    verbose=VERBOSE) # try False\n            \n        class_params['learning_rate'] = 1e-2\n        clf_2 = class_name(**class_params)\n        \n        clf_2.fit(xtrain, ytrain,                  \n                  eval_set=[(xtrain, ytrain), (xvalid, yvalid)],\n                  eval_metric='auc',\n                  early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n                  verbose=False,\n                  xgb_model=clf\n                 )\n        \n        class_params['learning_rate'] = 457e-4\n        clf = class_name(**class_params)\n        \n        clf.fit(xtrain, ytrain,                  \n                  eval_set=[(xtrain, ytrain), (xvalid, yvalid)],\n                  eval_metric='auc',\n                  early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n                  verbose=False,\n                  xgb_model=clf_2\n                 )\n        \n\n        preds_valid = clf.predict_proba(xvalid)[:, -1]\n        preds_test  = clf.predict_proba(test_data)[:, -1]\n\n#         valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n        test_predictions.append(preds_test) \n\n        elapsed = time.time() - start\n        auc = roc_auc_score(yvalid, preds_valid)\n        oof_preds.append(auc)\n\n        print(f\"fold {fold+1} - auc: {auc: .6f}, elapsed time: {elapsed:.2f} sec\\n\")\n\n    print(f\"Final roc auc = {np.mean(oof_preds)}\")\n    \n    return test_predictions\n#     return valid_predictions, test_predictions\n\n","9e537fbd":"pred = cross_validate_model(xgb.XGBClassifier, params,\n                                 X, y, X_test, N_SPLITS\n                                )","21ff55fd":"predictions = np.mean(np.column_stack(pred), axis=1)\n\nsample.target = predictions\nsample.to_csv(\"submission.csv\", index=False)\nsample.head()","33935b67":"<div style=\";\n            color:red;\n            font-size:40px;\n            style:bold;\n            text-align:center\">\n    <a href=\"https:\/\/www.kaggle.com\/c\/tabular-playground-series-oct-2021\">Tabular Playground Series - Oct 2021<\/a>\n    <\/div>"}}