{"cell_type":{"1d3b493a":"code","54429119":"code","526577a2":"code","9c5b67db":"code","3885750e":"code","f59695bb":"code","e4b4ee73":"code","47d3e917":"code","52fa6378":"code","8de5646f":"code","9c72f060":"code","73c065a5":"code","7370afe5":"code","568802ed":"code","45f93ec5":"code","8963066d":"code","464deb1f":"code","f27940a4":"code","2e1cc3c3":"code","5a21902b":"code","0e06cd77":"code","62344330":"code","64170714":"code","45d8918b":"code","41fbf081":"markdown","e0755888":"markdown","def6a5fc":"markdown"},"source":{"1d3b493a":"!pip install https:\/\/github.com\/CellProfiling\/HPA-Cell-Segmentation\/archive\/master.zip","54429119":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nimport hpacellseg.cellsegmentator as cellsegmentator\nfrom hpacellseg.utils import label_cell, label_nuclei\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px","526577a2":"DATA_DIR = \"\/kaggle\/input\/hpa-single-cell-image-classification\"\ntrain = pd.read_csv(os.path.join(DATA_DIR,'train.csv'))\n\ncolours = ['_red.png', '_blue.png', '_yellow.png', '_green.png']\nTRAIN = '..\/input\/hpa-single-cell-image-classification\/train'\npaths = [[os.path.join(TRAIN, train.iloc[idx,0])+ colour for colour in colours] for idx in range(len(train))]","9c5b67db":"LABELS= {\n    0: \"Nucleoplasm\",\n    1: \"Nuclear membrane\",\n    2: \"Nucleoli\",\n    3: \"Nucleoli fibrillar center\",\n    4: \"Nuclear speckles\",\n    5: \"Nuclear bodies\",\n    6: \"Endoplasmic reticulum\",\n    7: \"Golgi apparatus\",\n    8: \"Intermediate filaments\",\n    9: \"Actin filaments\",\n    10: \"Microtubules\",\n    11: \"Mitotic spindle\",\n    12: \"Centrosome\",\n    13: \"Plasma membrane\",\n    14: \"Mitochondria\",\n    15: \"Aggresome\",\n    16: \"Cytosol\",\n    17: \"Vesicles and punctate cytosolic patterns\",\n    18: \"Negative\"\n}","3885750e":"train","f59695bb":"train_csv = train.copy()\ntrain_csv['Label'] = train_csv['Label'].apply(lambda x: list(map(int,x.split(\"|\"))))\nmlb = MultiLabelBinarizer()\ntrain_csv[list(range(19))] = mlb.fit_transform(train_csv['Label'])\ntrain_csv.columns = [\"ID\", \"Label\"] + list(LABELS.values())\ntrain_csv.head(5)","e4b4ee73":"label_count = train_csv.iloc[:, 2:].sum()\npx.bar(label_count)","47d3e917":"for i in range(3):\n    img_visual = TRAIN + '\/' + train_csv['ID'].iloc[i]\n    r = plt.imread(img_visual + '_red' + '.png')\n    g = plt.imread(img_visual + '_green' + '.png')    \n    b = plt.imread(img_visual + '_blue' + '.png')\n    y = plt.imread(img_visual + '_yellow' + '.png')\n    fig, ax = plt.subplots(1,4, figsize=(10,20))\n    img = np.dstack((r, g, b, y))\n    ax[0].set_title('r_g_b_y')\n    ax[0].imshow(img)\n    ax[0].axis('off')\n\n    img = np.dstack((r, g, b))\n    ax[1].set_title('r_g_b')\n    ax[1].imshow(img)\n    ax[1].axis('off')\n\n    img = np.dstack((r, y, b))\n    ax[2].set_title('r_y_b')\n    ax[2].imshow(img)\n    ax[2].axis('off')\n\n    img = np.dstack((b, y, g))\n    ax[3].set_title(\"b_y_g\")\n    ax[3].imshow(img)\n    ax[3].axis('off')\n\n    plt.show()","52fa6378":"# Input: list of image filters as png\n# Output: list of image filters as np.arrays\ndef image_to_arrays(path):\n    \n    image_arrays = list()\n    for image in path:\n        array = np.asarray(Image.open(image))\n        image_arrays.append(array)\n        \n    return image_arrays","8de5646f":"# Get single image that blends all RGBY into RGB\n# Introduce the images as arrays. Can use the function above.\n\ndef get_blended_image(images): \n    # get rgby images for sample\n\n    # blend rgby images into single array\n    blended_array = np.stack(images[:-1], 2)\n\n    # Create PIL Image\n    blended_image = Image.fromarray( np.uint8(blended_array) )\n    return blended_image","9c72f060":"# Introduce list of image filters\n# Returns a processed image ready for the CNN and an encoded label as tensor\ndef image_prep(paths, label):\n\n    img = image_to_arrays(paths)\n    size = np.shape(img[0])[0]\n    img = tf.image.convert_image_dtype(img, dtype=tf.float32)\n    img = tf.reshape(img, (1, size, size, 3))\n    img = tf.image.resize(img, IMG_SIZE)\n\n    label = tf.strings.split(label, sep='|')\n    label = tf.strings.to_number(label, out_type=tf.int32)\n    label = tf.reduce_sum(tf.one_hot(indices=label, depth=19), axis=0)\n    label = tf.reshape(label, (1, 19))\n    \n    return img, label","73c065a5":"def apply_augmentation(image, label):\n    aug_img = tf.numpy_function(func=aug_fn, inp=[image], Tout=tf.float32)\n    aug_img.set_shape((IMG_SIZE[0], IMG_SIZE[0], 3))\n    \n    return aug_img, label","7370afe5":"def plot_hist(hist):\n    plt.plot(hist.history[\"accuracy\"])\n    plt.plot(hist.history[\"val_accuracy\"])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()","568802ed":"titles = ['microtubules', 'nuclei', 'endoplasmic reticulum', 'protein of interest']\nfig, axs = plt.subplots(3, 4, figsize =(16,8))\nfor entry in range(3):\n    for channel in range(4):\n        img = plt.imread(paths[entry][channel])\n        axs[entry, channel].imshow(img)        \n        if entry == 0:\n            axs[0, channel].set_title(titles[channel])","45f93ec5":"NUC_MODEL = \".\/nuclei-model.pth\"\nCELL_MODEL = \".\/cell-model.pth\"\nsegmentator = cellsegmentator.CellSegmentator(\n    NUC_MODEL,\n    CELL_MODEL,\n    scale_factor=0.25,\n    device=\"cuda\",\n    padding=False,\n    multi_channel_model=True,\n)\n\nimage = paths[4]\narrays = image_to_arrays(image)\nnuclei = arrays[1]\ncell = arrays[:-1]\n\n# Nuclei segmentation\nnuc_segmentations = segmentator.pred_nuclei([nuclei])\n\nf, ax = plt.subplots(1, 2, figsize=(16,16))\nax[0].imshow(arrays[1])\nax[0].set_title('Original Nucleis', size=20)\nax[1].imshow(nuc_segmentations[0])\nax[1].set_title('Segmented Nucleis', size=20)\nplt.show()\n\n# Cell segmentation\ninter_step = [[i] for i in image[:-1]]\ncell_segmentations = segmentator.pred_cells(inter_step)\n\nf, ax = plt.subplots(1, 2, figsize=(16,16))\nax[0].imshow(get_blended_image(arrays))\nax[0].set_title('Original Cells', size=20)\nax[1].imshow(cell_segmentations[0])\nax[1].set_title('Segmented Cells', size=20)\nplt.show()","8963066d":"# Nuclei mask\nnuclei_mask = label_nuclei(nuc_segmentations[0])\n# Cell masks\ncell_nuclei_mask, cell_mask = label_cell(nuc_segmentations[0], cell_segmentations[0])\n# Plotting\nf, ax = plt.subplots(1, 3, figsize=(16,16))\nax[0].imshow(nuclei_mask)\nax[0].set_title('Nuclei Mask', size=20)\nax[1].imshow(cell_nuclei_mask)\nax[1].set_title('Cell Nuclei Mask', size=20)\nax[2].imshow(cell_mask)\nax[2].set_title('Cell Mask', size=20)\nplt.show()","464deb1f":"# Let's stack the original image and the segmentation mask, to see how the segmentation worked out\nplt.figure(figsize=(20,20))\nplt.imshow(get_blended_image(arrays))\nplt.imshow(cell_mask, alpha=0.5)\nplt.title('Segmentation results', size=40)\nplt.axis('off')\nplt.show()","f27940a4":"# Unique vector of cell_mask numbers\nnumbers = set(np.ravel(cell_mask))\nnumbers.remove(0)\n\nfig = plt.figure(figsize=(25,8*len(numbers)\/4))\nindex = 1\n\nax = fig.add_subplot(len(numbers)\/\/4+1, 4, index)\nax.set_title(\"Complete Cell Mask\", size=16)\nplt.imshow(cell_mask)\n\nindex += 1\nfor number in numbers:\n    isolated_cell = np.where(cell_mask==number, cell_mask, 0)\n    ax = fig.add_subplot(len(numbers)\/\/4+1, 4, index)\n    ax.set_title(f\"Segment {number}\", size=16)\n    plt.imshow(isolated_cell)\n    index += 1","2e1cc3c3":"from tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nimport wandb","5a21902b":"# We'll use EfficientNetB0 model, which requires an image dimension of (224,224,3).Therefor, we can only pass a 3 filter image... \n#We'll put aside the yellow filter for now.\nIMG_SIZE = [224, 224]\nBATCH_SIZE = 64\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ncolours = ['_red.png', '_blue.png', '_green.png']\nTRAIN = '..\/input\/hpa-single-cell-image-classification\/train'\npaths = [[os.path.join(TRAIN, train.iloc[idx,0])+ colour for colour in colours] for idx in range(len(train))]","0e06cd77":"# Processing the data for training:\ntraining_data = []\nfor i,path in enumerate(paths[:500]):\n    img, label = image_prep(path, train['Label'][i])\n    training_data.append([img,label])\n\ntrain_ds = tf.data.Dataset.from_tensor_slices(([training_data[i][0] for i in range(len(training_data))], [training_data[i][1] for i in range(len(training_data))]))\nlen(train_ds)","62344330":"val_data = []\nstart_img = 500\nval_num = 100\nfor i,path in enumerate(paths[start_img:start_img+val_num]):\n    img, label = image_prep(path, train['Label'][i+start_img])\n    val_data.append([img,label])\n\nval_ds = tf.data.Dataset.from_tensor_slices(([val_data[i][0] for i in range(len(val_data))], [val_data[i][1] for i in range(len(val_data))]))","64170714":"base_model = EfficientNetB0(include_top=False, weights='imagenet')\nbase_model.trainable = True\n\ninputs = layers.Input((IMG_SIZE[0], IMG_SIZE[0], 3))\n\nx = base_model(inputs, training=True)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(len(LABELS), activation='sigmoid')(x)\n\ntf.keras.backend.clear_session()\n\nmodel = Model(inputs, outputs)\nmodel.summary()","45d8918b":"tf.keras.backend.clear_session()\n\nearlystopper = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=10, verbose=0, mode='min',\n    restore_best_weights=True\n)\n\nmodel.compile('adam', 'binary_crossentropy', metrics=[tf.keras.metrics.AUC(multi_label=True)])\n#model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n#run = wandb.init(entity='ayush-thakur', project='hpa', job_type='train')\n\nhist = model.fit(train_ds, \n          epochs=50,\n          validation_data=val_ds,\n          verbose=1,\n          callbacks=[earlystopper]\n                )\n#plot_hist(hist)\n#run.finish()","41fbf081":"# I. Gi\u1edbi thi\u1ec7u chung\n## 1. Gi\u1edbi thi\u1ec7u b\u00e0i to\u00e1n\n<span style=\"font-size: 18px\">\n    Ta c\u00f3 th\u1ec3 th\u1ea5y protein \u0111\u00f3ng vai tr\u00f2 thi\u1ebft y\u1ebfu trong h\u1ea7u nh\u01b0 t\u1ea5t c\u00e1c qu\u00e1 tr\u00ecnh c\u1ee7a t\u1ebf b\u00e0o. Th\u00f4ng th\u01b0\u1eddng, nhi\u1ec1u protein k\u1ebft h\u1ee3p v\u1edbi nhau t\u1ea1i m\u1ed9t v\u1ecb tr\u00ed c\u1ee5 th\u1ec3 \u0111\u1ec3 th\u1ef1c hi\u1ec7n 1 nhi\u1ec7m v\u1ee5, k\u1ebft qu\u1ea3 ch\u00ednh x\u00e1c c\u1ee7a nhi\u1ec7m v\u1ee5 n\u00e0y ph\u1ee5 thu\u1ed9c v\u00e0o lo\u1ea1i protein n\u00e0o c\u00f3 m\u1eb7t. Nh\u01b0 b\u1ea1n th\u1ea5y, s\u1ef1 ph\u00e2n b\u1ed1 c\u1ee7a protein \u1edf c\u00e1c t\u1ebf b\u00e0o kh\u00e1c nhau l\u00e0 kh\u00e1c nhau, l\u00e0m ph\u00e1t sinh s\u1ef1 kh\u00f4ng \u0111\u1ed3ng nh\u1ea5t v\u1ec1 ch\u1ee9c n\u0103ng gi\u1eefa c\u00e1c t\u1ebf b\u00e0o. Vi\u1ec7c t\u00ecm ra nh\u1eefng \u0111i\u1ec3m kh\u00e1c bi\u1ec7t nh\u01b0 v\u1eady v\u00e0 l\u00fd do t\u1ea1i sao c\u00f3 s\u1ef1 ph\u00e2n b\u1ed1 kh\u00e1c nhau c\u1ee7a protein gi\u1eefa c\u00e1c t\u1ebf b\u00e0o c\u00f3 c\u00f9ng ch\u1ee9c n\u0103ng l\u00e0 \u0111i\u1ec1u quan tr\u1ecdng \u0111\u1ec3 hi\u1ec3u \u0111\u01b0\u1ee3c c\u00e1ch th\u1ee9c ho\u1ea1t \u0111\u1ed9ng c\u1ee7a c\u00e1c t\u1ebf b\u00e0o, t\u00ecm ra c\u00e1ch c\u00e1c c\u0103n b\u1ec7nh ph\u00e1t tri\u1ec3n, sau \u0111\u00f3 t\u00ecm ra c\u00e1c ph\u01b0\u01a1ng ph\u00e1p \u0111i\u1ec1u tr\u1ecb t\u1ed1t h\u01a1n cho nh\u1eefng b\u1ec7nh \u0111\u00f3.\n<\/span>\n\n## 2. D\u1eef li\u1ec7u\n<b style=\"font-size: 18px\">Human Protein Atlas - Single Cell Classification<\/b>\n<br>\n<span style=\"font-size: 18px\">B\u1ed9 d\u1eef li\u1ec7u c\u00f3 3 lo\u1ea1i \u1ea3nh PNG bao g\u1ed3m c\u00e1c k\u00edch th\u01b0\u1edbc:<\/span>\n    \n<ul style=\"font-size: 18px\">\n    <li>1728x1728<\/li>\n    <li>2048x2048<\/li>\n    <li>3072x3072<\/li>\n<\/ul>\n\n<span style=\"font-size: 18px\">\n    T\u1ea5t c\u1ea3 \u0111\u1ec1u \u0111\u01b0\u1ee3c ch\u1ee5p b\u1eb1ng k\u00ednh hi\u1ec3n vi \u0111\u1ed3ng ti\u00eau (Confocal Microscopy)\n    <br>\n    M\u1ed7i \u1ea3nh \u0111\u01b0\u1ee3c ch\u1ee5p tr\u00ean 4 k\u00eanh \u2192 4 \u1ea3nh:\n<br>\n<\/span>\n<ul style=\"font-size: 18px\">\n    <li><code>red:<\/code> microtubule channels (<a href=\"https:\/\/vi.wikipedia.org\/wiki\/Vi_\u1ed1ng\">Vi \u1ed1ng<\/a>)<\/li>\n    <li><code>blue:<\/code> nuclei channels (<a href=\"https:\/\/vi.wikipedia.org\/wiki\/Nh\u00e2n_t\u1ebf_b\u00e0o\">Nh\u00e2n t\u1ebf b\u00e0o<\/a>)<\/li>\n    <li><code>yellow:<\/code> Endoplasmic Reticulum (ER) channels (<a href=\"https:\/\/vi.wikipedia.org\/wiki\/M\u1ea1ng_l\u01b0\u1edbi_n\u1ed9i_ch\u1ea5t\">L\u01b0\u1edbi n\u1ed9i ch\u1ea5t<\/a>)<\/li>\n    <li><code>green:<\/code> protein of interest (<a href=\"https:\/\/www.google.com\/search?q=protein+of+interest&oq=protein+of+interest&aqs=edge..69i57j0l3j0i22i30l3.760j0j1&sourceid=chrome&ie=UTF-8\">???<\/a>)<\/li>\n<\/ul>\n\n## 3. Nhi\u1ec7m v\u1ee5\n<span style=\"font-size: 18px\">\n    C\u00f3 t\u1ea5t c\u1ea3 19 nh\u00e3n c\u1ea7n ph\u00e2n l\u1edbp, 18 nh\u00e3n cho 18 lo\u1ea1i t\u1ebf b\u00e0o v\u00e0 1 nh\u00e3n cho nh\u1eefng t\u1ebf b\u00e0o kh\u00f4ng x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c c\u1ee5 th\u1ec3. \n    \n    \n<\/span>\n\n<pre style=\"font-size: 18px\">\n0.  Nucleoplasm  \n1.  Nuclear membrane   \n2.  Nucleoli   \n3.  Nucleoli fibrillar center   \n4.  Nuclear speckles   \n5.  Nuclear bodies   \n6.  Endoplasmic reticulum   \n7.  Golgi apparatus   \n8.  Intermediate filaments  \n9.  Actin filaments  \n10.  Microtubules      \n11.  Mitotic spindle   \n12.  Centrosome   \n13.  Plasma membrane   \n14.  Mitochondria   \n15.  Aggresome   \n16.  Cytosol   \n17.  Vesicles and punctate cytosolic patterns   \n18.  Negative  \n<\/pre>\n\n<span style=\"font-size: 18px\">\n    T\u1ea5t c\u1ea3 c\u00e1c \u1ea3nh \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n b\u1eb1ng 4 b\u1ed9 l\u1ecdc:\n<\/span>\n<ul style=\"font-size: 18px\">\n    <li>B\u1ed9 l\u1ecdc m\u00e0u xanh(<code>green<\/code>) \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n v\u00e0 g\u00e1n nh\u00e3n<\/li>\n    <li>3 b\u1ed9 l\u1ecdc c\u00f2n l\u1ea1i(<code>red, blue, yellow<\/code>) \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 l\u00e0m t\u00e0i li\u1ec7u tham kh\u1ea3o, cho th\u1ea5y s\u1ef1 t\u01b0\u01a1ng quan c\u1ee7a t\u1ebf b\u00e0o gi\u1eefa c\u00e1c b\u1ed9 l\u1ecdc<\/li>\n<\/ul>\n    \n### Nhi\u1ec7m v\u1ee5 ch\u00ednh\n<span style=\"font-size: 18px\">\nV\u1edbi m\u1ed7i \u1ea3nh ch\u00fang ta \u0111\u00e3 \u0111\u01b0\u1ee3c cho s\u1eb5n c\u00e1c nh\u00e3n c\u1ee7a c\u00e1c t\u1ebf b\u00e0o xu\u1ea5t hi\u1ec7n trong \u1ea3nh.\n<br><b> Nhi\u1ec7m v\u1ee5 c\u1ee7a ch\u00fang ta l\u00e0 segment ra c\u00e1c t\u1ebf b\u00e0o v\u00e0 g\u00e1n nh\u00e3n cho c\u00e1c t\u1ebf b\u00e0o \u0111\u00f3.<\/b>\n<\/span>","e0755888":"## Data Visualize","def6a5fc":"# II. Th\u1ef1c hi\u1ec7n"}}