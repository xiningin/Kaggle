{"cell_type":{"97621595":"code","cd94894e":"code","274189aa":"code","d5823e1d":"code","34b9259c":"code","3115ece2":"code","96ed897e":"code","e9bdbbf5":"code","6c19d77b":"code","39906846":"markdown","2d064045":"markdown","9459f999":"markdown","1c20386c":"markdown"},"source":{"97621595":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport numpy as np\nimport gensim\nfrom matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\n\nfrom IPython.display import display, HTML\nplt.rcParams[\"patch.force_edgecolor\"] = True\nplt.style.use('fivethirtyeight')\n%matplotlib inline","cd94894e":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n# Any results you write to the current directory are saved as output.\n\n#__________________\n# read the datafile\ndf_initial = pd.read_csv('..\/input\/data.csv',encoding=\"ISO-8859-1\",\n                         dtype={'CustomerID': str,'InvoiceNo': str, 'StockCode': str})\ndf_initial['InvoiceDate'] = pd.to_datetime(df_initial['InvoiceDate'])\n#df_initial['StockCode'] = df_initial['StockCode'].astype(str)\nprint('Dataframe dimensions:', df_initial.shape)\n \n# show first lines\ndisplay(df_initial[:5])","274189aa":"## Drop transaction that have negative price or price\n\n#df_initial.dropna(axis = 0, subset = ['CustomerID'], inplace = True)\ndf_initial.drop((df_initial[(df_initial['Quantity'] <= 0) | (df_initial['UnitPrice'] < 0)]).index, inplace=True)\nprint('Dataframe dimensions:', df_initial.shape)","d5823e1d":"## Delete duplicate transaction\n\nprint('Entris dupliqu\u00e9es: {}'.format(df_initial.duplicated().sum()))\ndf_initial.drop_duplicates(inplace = True)\nprint('Dataframe dimensions:', df_initial.shape)","34b9259c":"##\n\nproducts = df_initial[['StockCode', 'Description']].drop_duplicates()\nproducts.head()","3115ece2":"##\n\nstockcode = df_initial.groupby(\"InvoiceNo\").apply(lambda order: order['StockCode'].tolist())\nstockcode[0:5]","96ed897e":"## \nmodel = gensim.models.Word2Vec(stockcode.values, size=5, window=6, min_count=2, workers=4)\nvocab = list(model.wv.vocab.keys())\n\npca = PCA(n_components=2)\npca.fit(model.wv.vectors)","e9bdbbf5":"## \n\ndef get_batch(vocab, model, n_batches=3):\n    output = list()\n    for i in range(0, n_batches):\n        rand_int = np.random.randint(len(vocab), size=1)[0]\n        suggestions = model.wv.most_similar(positive=[vocab[rand_int]], topn=5)\n        suggest = list()\n        for i in suggestions:\n            suggest.append(i[0])\n        output += suggest\n        output.append(vocab[rand_int])\n    return output\n\ndef plot_with_labels(low_dim_embs, labels, filename='tsne.png'):\n    \"\"\"From Tensorflow's tutorial.\"\"\"\n    assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n    plt.figure(figsize=(20, 16))  #in inches\n    for i, label in enumerate(labels):\n        x, y = low_dim_embs[i,:]\n        plt.scatter(x, y)\n        plt.annotate(label,\n                     xy=(x, y),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    #plt.savefig(filename)\n    plt.show()","6c19d77b":"embeds = []\nlabels = []\n\nfor item in get_batch(vocab, model, n_batches=3):\n    embeds.append(model[item])\n    labels.append(products.loc[products.StockCode == item]['Description'].values)\nembeds = np.array(embeds)\nembeds = pca.fit_transform(embeds)\nplot_with_labels(embeds, labels)","39906846":"# Model Building","2d064045":"# Preprocessing","9459f999":"This grapht is random, rerunt cell to get new cluster","1c20386c":"Reference:\n1. https:\/\/www.kaggle.com\/fabiendaniel\/customer-segmentation"}}