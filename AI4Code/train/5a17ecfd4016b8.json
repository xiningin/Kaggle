{"cell_type":{"0ada0ae5":"code","6d5808b9":"code","b4c5d3b5":"code","35cf2214":"code","f2eb0178":"code","de2e447e":"code","79506ce4":"code","fb731fb0":"code","60c1a0cf":"code","e367410f":"code","777e0a6e":"code","fbad1b45":"code","bc710c91":"code","6b6fc025":"code","9cb8bf02":"code","a0b80984":"code","9d020bf7":"code","414e2f76":"code","d3115d74":"code","fdc66fae":"code","8189d1bb":"code","302f8c39":"code","24fa9696":"code","852c7e67":"code","da839e9e":"code","df41bb8c":"code","3d2a4b67":"code","130e6c95":"code","4d568627":"code","ec6d1d46":"code","bd17473f":"code","ef409aeb":"code","4440ddff":"code","ef3514e2":"code","f3b9b27d":"code","9e6b2145":"code","73b73cdd":"code","f6c87347":"code","5e856bfb":"code","0b67b4a9":"code","0d90161d":"code","69beba40":"code","4c301f9f":"code","4ea25089":"code","52f5620f":"code","33207b0a":"code","5c37412a":"code","33c33a0c":"code","e87470d9":"code","799bc570":"code","b4abef37":"code","911becfe":"code","c132038f":"code","8844defc":"code","9c7bb89f":"code","79436c29":"code","2f01af9d":"code","9d4454fd":"code","8e84ebc7":"code","c3dd8f97":"code","b7f5e071":"code","c49d0381":"code","c387fcc2":"code","697d1b77":"code","c0ebb67e":"code","4471d50a":"code","cb210b43":"code","398c1e8b":"code","c21041b1":"code","20b7cfc5":"code","858df677":"code","27cbc636":"markdown","e1f6016f":"markdown","7a894f41":"markdown","d52ad01c":"markdown","84092b48":"markdown","d176c3d5":"markdown","b52bf432":"markdown","711613f0":"markdown","03401344":"markdown","ad711d2d":"markdown","dc5872d2":"markdown","4d097812":"markdown","753de313":"markdown"},"source":{"0ada0ae5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\nimport os\nimport shutil\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Input, BatchNormalization, Multiply, ZeroPadding2D, Activation, Add, AveragePooling2D\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.models import load_model\nfrom keras.initializers import glorot_uniform\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix","6d5808b9":"arabic_characters = ['\u0623', '\u0628', '\u062a', '\u062b', '\u062c', '\u062d', '\u062e', '\u062f', '\u0630','\u0631', '\u0632', '\u0633', '\u0634', '\u0635', '\u0636', '\u0637', '\u0638', '\u0639','\u063a', '\u0641', '\u0642', '\u0643', '\u0644', '\u0645', '\u0646', '\u0647', '\u0648', '\u0649']\n\narabic_characters.sort()\n\narabic_characters = np.array(arabic_characters)\n\narabic_characters","b4c5d3b5":"datapath = \"..\/input\/arabic-hwr-ai-pro-intake1\"\ntrain_df = pd.read_csv(os.path.join(datapath,\"train.csv\"))\ntest_df  = pd.read_csv(os.path.join(datapath,\"test.csv\"))\n\ntrain_df","35cf2214":"if not os.path.isdir(os.path.join('\/kaggle\/working\/train_labeled\/')):\n    os.mkdir('\/kaggle\/working\/train_labeled\/')\n\nfor _, row in train_df.iterrows():\n    f = row['id']\n    l = row['label']\n    \n    if not os.path.isdir(os.path.join( '.\/train_labeled\/{}\/'.format(arabic_characters[l-1]))):\n        os.mkdir(os.path.join('.\/train_labeled\/{}\/'.format(arabic_characters[l-1])))\n        \n    shutil.copy('..\/input\/arabic-hwr-ai-pro-intake1\/train\/{:05d}.png'.format(f), '.\/train_labeled\/{}\/'.format(arabic_characters[l-1]))","f2eb0178":"BATCH_SIZE = 32\n\n### Create Train Generator\ndatagen = ImageDataGenerator( \n            zca_whitening=True,         # apply ZCA whitening\n            zoom_range = 0.1,           # Randomly zoom image \n            width_shift_range=0.1,      # randomly shift images horizontally (fraction of total width)\n            height_shift_range=0.1,     # randomly shift images vertically (fraction of total height)\n            validation_split=0.2 \n            # featurewise_center=False, # set input mean to 0 over the dataset\n            # samplewise_center=False,  # set each sample mean to 0\n            # featurewise_std_normalization=False,  # divide inputs by std of the dataset\n            # samplewise_std_normalization=False,   # divide each input by its std\n            # rotation_range=10,        # randomly rotate images in the range (degrees, 0 to 180)\n            # horizontal_flip=False,    # randomly flip images\n            # vertical_flip=False,      # randomly fli\n)\n\ndatagen","de2e447e":"train_dir = '\/kaggle\/working\/train_labeled\/'\n\n### Create Train Generator\ntrain_gen = datagen.flow_from_directory(train_dir,\n                                       batch_size=BATCH_SIZE,\n                                       target_size=(32, 32),\n                                       subset='training',\n#                                        shuffle=False,\n#                                        color_mode='grayscale',\n                                       )","79506ce4":"### Set as Validation data\nval_gen = datagen.flow_from_directory( train_dir,     # same directory as training data                                    \n                                       batch_size=BATCH_SIZE,\n                                       target_size=(32, 32),\n                                       subset='validation' ,\n) ","fb731fb0":"# train_gen has 168 tuples of Batches ( Batch_size= 64 Images)\nlen(train_gen)","60c1a0cf":"len(train_gen[0])","e367410f":"for i in train_gen:\n    plt.imshow(i[0][1][:,:,1],'binary')\n    plt.title(arabic_characters[np.argmax (i[1][1])])\n    idx = (train_gen.batch_index - 1) * train_gen.batch_size\n    print(train_gen.filenames[idx : idx + train_gen.batch_size])\n    break","777e0a6e":"# each batch has 2 items    [in case BATCH_SIZE=64]\n#   1--> Image (32 x 32x 3)    , 64 Images  --> 64 x 32 x 32 x 3\nprint( train_gen[0][0].shape )\n\n#   2--> Label as a sparse-matrix (1 x 28 )   , 64 Images  --> 64 x 28\nprint( train_gen[0][1].shape )","fbad1b45":"print(train_gen[0][0][1].shape)","bc710c91":"# train_gen.filenames\n# datagen.flow_from_directory?\n# class_mode=None","6b6fc025":"### TEST TTTTTTTTTTTTTTTTTTTTTTTTT  \n\n### Create TEST Generator\ntest_dir = '..\/input\/arabic-hwr-ai-pro-intake1\/test'\n\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    test_dir,\n    image_size=(32, 32),\n    batch_size=30,\n    shuffle=False,\n    label_mode=None,\n    # seed=123,\n)\n\nfile_names = [ int( img.split('\/')[-1].split('.')[0]) for img in test_ds.file_paths ]\n\nfile_names[:20]","9cb8bf02":"## Explaining --> each take is a batch of 64 images\nlist(test_ds.take(1))[0].shape","a0b80984":"#### Test Plotting\nplt.figure(figsize=(10, 10))\n\nfor images in test_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i][:,:,1].numpy().astype(\"uint8\"),'binary')\n        plt.title('test')\n        plt.axis(\"off\")","9d020bf7":"list(test_ds.take(1))[0][0].shape","414e2f76":"def get_CNN_model():\n    In = Input(shape=(32,32,3))\n    \n    x = Conv2D(32, (5,5), padding=\"same\", activation=\"relu\")(In)\n    x = Conv2D(32, (5,5), padding=\"same\", activation=\"relu\")(x)\n    x = Conv2D(32, (5,5), padding=\"same\", activation=\"relu\")(x)\n    x = MaxPooling2D((2,2))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.25)(x)\n    \n    x = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(x)\n    x = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(x)\n    x = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(x)\n    x = MaxPooling2D((2,2))(x)  # try  MaxPooling2D((2,2),strides=(2, 2))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.25)(x)\n    \n    x = Flatten()(x)\n    x = Dense(256, activation=\"relu\")(x)\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dropout(0.4)(x)\n    \n    Out = Dense(28, activation=\"softmax\")(x)\n    \n    model = Model(In, Out)\n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    \n    return model","d3115d74":"model_01 = get_CNN_model()\nmodel_01.summary()","fdc66fae":"# create checkpoint to save model after every epoch\ncheckpoint_cb = ModelCheckpoint(filepath='model_01.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n\n# create early stopping checkpoint\nearly_stopping_cb = EarlyStopping(patience=100, restore_best_weights=True)\n\n\nhistory_01 = model_01.fit(train_gen,\n                    epochs = 500,\n                    steps_per_epoch  = train_gen.samples \/\/ BATCH_SIZE,\n                    validation_data  = val_gen,\n                    validation_steps = val_gen.samples \/\/ BATCH_SIZE,\n                    callbacks        = [checkpoint_cb, early_stopping_cb] )\n\nmodel_01 = load_model('..\/working\/model_01.h5')","8189d1bb":"# model_01 = load_model('..\/input\/messi-pretrained-model\/model_1_CNN_ALI.h5')\n# # model_01.summary()","302f8c39":"model_01.evaluate(train_gen)\nmodel_01.evaluate(val_gen) ","24fa9696":"hist = pd.DataFrame(history_01.history)\n\nfig, ax = plt.subplots(1,2, figsize=(18,7))\nax[0].plot(hist.loss, label='Train' )\nax[0].plot(hist.val_loss, label='validation' )\nax[0].legend()\nax[0].grid()\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\n\n\nax[1].plot(hist.accuracy, label='Train' )\nax[1].plot(hist.val_accuracy, label='validation' )\nax[1].legend()\nax[1].grid()\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Accuracy')\nplt.show()\n","852c7e67":"keras.utils.plot_model(model_01)","da839e9e":"def get_VGG16_model():\n    \n    base_model = tf.keras.applications.VGG16(weights = 'imagenet', include_top = False, input_shape = (32,32,3))\n    \n    for layer in base_model.layers:\n          layer.trainable = True\n  \n\n    x = Flatten()(base_model.output)\n    x = BatchNormalization()(x)\n    x = Dense(256, activation=\"relu\")(x)\n    x = BatchNormalization()(x)\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    \n    Out = Dense(28, activation=\"softmax\")(x)\n    \n    model = Model(inputs = base_model.input, outputs = Out)\n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    \n    return model","df41bb8c":"#### OLD\n# def get_VGG16_model():\n    \n#     base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(32,32,3))\n    \n#     for layer in base_model.layers:\n#           layer.trainable = True\n\n\n#     x = Flatten()(base_model.output)\n#     x = BatchNormalization()(x)\n#     x = Dense(256, activation=\"relu\")(x)\n\n#     x = BatchNormalization()(x)\n#     x = Dense(128, activation=\"relu\")(x)\n    \n#     x = Dense(128, activation=\"relu\")(x)\n#     x = Dropout(0.5)(x)\n    \n#     Out = Dense(28, activation=\"softmax\")(x)\n    \n#     model = Model(inputs = base_model.input, outputs = Out)\n#     model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    \n#     return model","3d2a4b67":"model_02 = get_VGG16_model()\nmodel_02.summary()","130e6c95":"# create checkpoint to save model after every epoch\ncheckpoint_cb = ModelCheckpoint(filepath='model_02.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n\n# create early stopping checkpoint\nearly_stopping_cb = EarlyStopping(patience=100, restore_best_weights=True)\n\n\nhistory_02 = model_02.fit(train_gen,\n                        epochs = 500,\n                        steps_per_epoch  = train_gen.samples \/\/ BATCH_SIZE,\n                        validation_data  = val_gen,\n                        validation_steps = val_gen.samples \/\/ BATCH_SIZE,\n                        callbacks        = [checkpoint_cb, early_stopping_cb] )\n\nmodel_02 = load_model('..\/working\/model_02.h5')","4d568627":"# # model_02 = load_model('..\/input\/messi-pretrained-model\/Nabil_vgg16.h5') \n# model_02 = load_model('..\/input\/messi-pretrained-model\/VGG16_updated.h5') \n# # model_02.summary()","ec6d1d46":"model_02.evaluate(train_gen) \nmodel_02.evaluate(val_gen) ","bd17473f":"hist = pd.DataFrame(history_02.history)\n\nfig, ax = plt.subplots(1,2, figsize=(18,7))\nax[0].plot(hist.loss, label='Train' )\nax[0].plot(hist.val_loss, label='validation' )\nax[0].legend()\nax[0].grid()\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\n\n\nax[1].plot(hist.accuracy, label='Train' )\nax[1].plot(hist.val_accuracy, label='validation' )\nax[1].legend()\nax[1].grid()\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Accuracy')\nplt.show()\n","ef409aeb":"keras.utils.plot_model(model_02)","4440ddff":"def get_MobileNetV2_Trimmed_model():\n    base_model = keras.applications.MobileNet(weights='imagenet',include_top=False)    #imports the mobilenet model and discards the last 1000 neuron layer.\n\n    original_dim = (32, 32, 3)\n    target_size  = (75, 75)\n    input_layer  = keras.layers.Input(original_dim)\n    base_model.layers[0] = tf.keras.layers.Lambda(lambda image: tf.image.resize(image, target_size))(input_layer)\n    \n    x = base_model.output\n    x = keras.layers.GlobalAveragePooling2D()(x)\n    x = Dense(1024,activation='relu')(x)     # we add dense layers so that the model can learn more complex functions and classify for better results.\n    x = Dense(1024,activation='relu')(x)     # dense layer 2\n    x = Dense(512,activation='relu')(x)      # dense layer 3\n    preds = Dense(28,activation='softmax')(x) # final layer with softmax activation\n\n\n    model = keras.models.Model(inputs=base_model.input, outputs=preds)\n    model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adamax(lr=0.001, decay=1e-4,beta_1=0.9,beta_2=0.999), metrics=[\"accuracy\"])\n    \n    return model","ef3514e2":"# model_03 = get_MobileNetV2_Trimmed_model()\n# model_03.summary()","f3b9b27d":"# # create checkpoint to save model after every epoch\n# checkpoint_cb = ModelCheckpoint(filepath='model_03.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n\n# # create early stopping checkpoint\n# early_stopping_cb = EarlyStopping(patience=50, restore_best_weights=True)\n\n\n# history_03 = model_03.fit(train_gen,\n#                     epochs = 500,\n#                     steps_per_epoch  = train_gen.samples \/\/ BATCH_SIZE,\n#                     validation_data  = val_gen,\n#                     validation_steps = val_gen.samples \/\/ BATCH_SIZE,\n#                     callbacks        = [checkpoint_cb, early_stopping_cb] )\n\n\n# model_03 = load_model('..\/working\/model_03.h5')","9e6b2145":"# model_03 = load_model('..\/input\/messi-pretrained-model\/model_4_MobNet_97.5_Messi.h5') \n# # model_03.summary()","73b73cdd":"# model_03.evaluate(train_gen) \n# model_03.evaluate(val_gen) ","f6c87347":"# hist = pd.DataFrame(history_03.history)\n\n# fig, ax = plt.subplots(1,2, figsize=(18,7))\n# ax[0].plot(hist.loss, label='Train' )\n# ax[0].plot(hist.val_loss, label='validation' )\n# ax[0].legend()\n# ax[0].grid()\n# ax[0].set_xlabel('Epoch')\n# ax[0].set_ylabel('Loss')\n\n\n# ax[1].plot(hist.accuracy, label='Train' )\n# ax[1].plot(hist.val_accuracy, label='validation' )\n# ax[1].legend()\n# ax[1].grid()\n# ax[1].set_xlabel('Epoch')\n# ax[1].set_ylabel('Accuracy')\n# plt.show()","5e856bfb":"# keras.utils.plot_model(model_03)","0b67b4a9":"# def get_xception_model():\n    \n#     base_model = tf.keras.applications.xception.Xception(weights='imagenet', include_top=False)\n#     original_shape = (32,32,3)\n#     target_size = (71, 71)\n#     input_layer = keras.layers.Input(original_shape)\n#     base_model.layers[0] = tf.keras.layers.Lambda(lambda image: tf.image.resize(image, target_size))(input_layer)\n    \n#     for layer in base_model.layers:\n#           layer.trainable = True\n\n#     x = base_model.output\n#     x = keras.layers.GlobalAveragePooling2D()(x)\n#     x = Dense(256, activation=\"relu\")(x)\n#     x = BatchNormalization()(x)\n#     x = Dense(128, activation=\"relu\")(x)\n#     x = Dense(128, activation=\"relu\")(x)\n#     x = Dropout(0.5)(x)\n    \n#     Out = Dense(28, activation=\"softmax\")(x)\n    \n#     model = Model(inputs = base_model.input, outputs = Out)\n#     model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    \n#     return model","0d90161d":"# model_04 = get_xception_model()\n# model_04.summary()","69beba40":"# # create checkpoint to save model after every epoch\n# checkpoint_cb = ModelCheckpoint(filepath='model_04.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n\n# # create early stopping checkpoint\n# early_stopping_cb = EarlyStopping(patience=30, restore_best_weights=True)\n\n\n# history_04 = model_04.fit(train_gen,\n#                     epochs = 500,\n#                     steps_per_epoch  = train_gen.samples \/\/ BATCH_SIZE,\n#                     validation_data  = val_gen,\n#                     validation_steps = val_gen.samples \/\/ BATCH_SIZE,\n#                     callbacks        = [checkpoint_cb, early_stopping_cb] )\n\n# model_04 = load_model('..\/working\/model_04.h5')","4c301f9f":"# model_04 = load_model('..\/input\/messi-pretrained-model\/Xception_Afnan.h5')  \n# # model_04.summary()","4ea25089":"# model_04.evaluate(train_gen) \n# model_04.evaluate(val_gen) ","52f5620f":"# hist = pd.DataFrame(history_04.history)\n\n# fig, ax = plt.subplots(1,2, figsize=(18,7))\n# ax[0].plot(hist.loss, label='Train' )\n# ax[0].plot(hist.val_loss, label='validation' )\n# ax[0].legend()\n# ax[0].grid()\n# ax[0].set_xlabel('Epoch')\n# ax[0].set_ylabel('Loss')\n\n\n# ax[1].plot(hist.accuracy, label='Train' )\n# ax[1].plot(hist.val_accuracy, label='validation' )\n# ax[1].legend()\n# ax[1].grid()\n# ax[1].set_xlabel('Epoch')\n# ax[1].set_ylabel('Accuracy')\n# plt.show()","33207b0a":"# keras.utils.plot_model(model_04)","5c37412a":"def get_merged_model():\n    # First Model\n    In_1 = Input(shape=(32,32,3))\n    \n    m_1 = Conv2D(32, (5,5), padding=\"same\", activation=\"relu\")(In_1)\n    m_1 = Conv2D(32, (5,5), padding=\"same\", activation=\"relu\")(m_1)\n    m_1 = Conv2D(32, (5,5), padding=\"same\", activation=\"relu\")(m_1)\n    m_1 = MaxPooling2D((2,2))(m_1)\n    m_1 = BatchNormalization()(m_1)\n    m_1 = Dropout(0.25)(m_1)\n    \n    m_1 = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(m_1)\n    m_1 = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(m_1)\n    m_1 = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(m_1)\n    m_1 = MaxPooling2D((2,2))(m_1)  # try  MaxPooling2D((2,2),strides=(2, 2))(x)\n    m_1 = BatchNormalization()(m_1)\n    m_1 = Dropout(0.25)(m_1)\n    \n    m_1 = Flatten()(m_1)\n    m_1 = BatchNormalization()(m_1)\n    m_1 = Dense(256, activation=\"relu\")(m_1)\n    \n    # Second Model\n    base_model = tf.keras.applications.VGG16(weights = 'imagenet', include_top = False, input_shape = (32,32,3))\n    \n    for layer in base_model.layers:\n          layer.trainable = True\n  \n\n    m_2 = Flatten()(base_model.output)\n    m_2 = BatchNormalization()(m_2)\n    m_2 = Dense(256, activation=\"relu\")(m_2)\n\n    \n    x = Multiply()([m_1, m_2])\n    x = Dense(256, activation=\"relu\")(x)\n    x = BatchNormalization()(x)\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    \n    Out = Dense(28, activation=\"softmax\")(x)\n    \n    model = Model(inputs = [In_1, base_model.input], outputs = Out)\n    \n    opt = tf.keras.optimizers.Adamax(lr=0.001, decay=1e-4,beta_1=0.9,beta_2=0.999)\n    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n    \n    return model","33c33a0c":"def get_data(gen):\n    while True:\n        Xi = gen.next()\n        yield [Xi[0], Xi[0]], Xi[1]\n        \n        \ndef get_evaluate_data(gen):\n    for _ in range(len(gen)):\n        Xi = gen.next()\n        yield [Xi[0], Xi[0]], Xi[1]\n        \n        \ndef get_predict_data(gen):\n    for _ in range(len(list(gen.as_numpy_iterator()))):\n        Xi = gen.as_numpy_iterator().next()\n        yield [Xi, Xi]","e87470d9":"# model_05 = get_merged_model()\n# model_05.summary()","799bc570":"# # create checkpoint to save model after every epoch\n# checkpoint_cb = ModelCheckpoint(filepath='model_05.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n\n# # create early stopping checkpoint\n# early_stopping_cb = EarlyStopping(patience=100, restore_best_weights=True)\n\n\n# history_05 = model_05.fit(get_data(train_gen),\n#                     epochs = 500,\n#                     steps_per_epoch  = train_gen.samples \/\/ BATCH_SIZE,\n#                     validation_data  = get_data(val_gen),\n#                     validation_steps = val_gen.samples \/\/ BATCH_SIZE,\n#                     callbacks        = [checkpoint_cb, early_stopping_cb] )\n\n# model_05 = load_model('..\/working\/model_05.h5')","b4abef37":"# model_05 = load_model('..\/input\/messi-pretrained-model\/merged_model_98810_nabil.h5')  \n# # model_05.summary()","911becfe":"# model_05.evaluate(get_evaluate_data(train_gen))\n# model_05.evaluate(get_evaluate_data(val_gen))","c132038f":"# hist = pd.DataFrame(history_05.history)\n\n# fig, ax = plt.subplots(1,2, figsize=(18,7))\n# ax[0].plot(hist.loss, label='Train' )\n# ax[0].plot(hist.val_loss, label='validation' )\n# ax[0].legend()\n# ax[0].grid()\n# ax[0].set_xlabel('Epoch')\n# ax[0].set_ylabel('Loss')\n\n\n# ax[1].plot(hist.accuracy, label='Train' )\n# ax[1].plot(hist.val_accuracy, label='validation' )\n# ax[1].legend()\n# ax[1].grid()\n# ax[1].set_xlabel('Epoch')\n# ax[1].set_ylabel('Accuracy')\n# plt.show()\n","8844defc":"# keras.utils.plot_model(model_05)","9c7bb89f":"# merged_pred = model_05.predict(get_predict_data(test_ds))","79436c29":"def identity_block(X, f, filters, stage, block):\n    \n    # Defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve filters\n    F1, F2, F3 = filters\n    \n    # A path is a block of conv followed by batch normalization and activation\n    # Save the input value\n    X_shortcut = X\n\n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path \n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X\n\n\n# ========================================================================================== #\ndef convolutional_block(X, f, filters, stage, block, s=2):\n\n    # Defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    # Retrieve filters\n    F1, F2, F3 = filters\n\n    # Save the input value\n    X_shortcut = X\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    ##### SHORTCUT PATH #### \n    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X\n\n# ========================================================================================== #\ndef ResNet(input_shape = (28, 28, 1), classes = 10):\n\n    # Define the input as a tensor with shape input_shape\n    X_input = Input(shape=input_shape)\n\n\n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n\n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n    # Stage 3\n    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    # AVGPOOL\n    X = AveragePooling2D(pool_size=(2,2), padding='same')(X)\n\n    # Output layer\n    X = Flatten()(X)\n    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n\n\n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNet')\n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\n    return model","2f01af9d":"model_06 = ResNet(input_shape=(32, 32, 3), classes=28)\nmodel_06.summary()","9d4454fd":"# create checkpoint to save model after every epoch\ncheckpoint_cb = ModelCheckpoint(filepath='model_06.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n\n# create early stopping checkpoint\nearly_stopping_cb = EarlyStopping(patience=100, restore_best_weights=True)\n\n\nhistory_06 = model_06.fit(train_gen,\n                    epochs = 500,\n                    steps_per_epoch  = train_gen.samples \/\/ BATCH_SIZE,\n                    validation_data  = val_gen,\n                    validation_steps = val_gen.samples \/\/ BATCH_SIZE,\n                    callbacks        = [checkpoint_cb, early_stopping_cb] )\n\n\nmodel_06 = load_model('..\/working\/model_06.h5')","8e84ebc7":"# model_06 = load_model('..\/input\/messi-pretrained-model\/model_2_RNN.h5')  \n# # model_06.summary()","c3dd8f97":"model_06.evaluate(train_gen) \nmodel_06.evaluate(val_gen) ","b7f5e071":"hist = pd.DataFrame(history_06.history)\n\nfig, ax = plt.subplots(1,2, figsize=(18,7))\nax[0].plot(hist.loss, label='Train' )\nax[0].plot(hist.val_loss, label='validation' )\nax[0].legend()\nax[0].grid()\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\n\n\nax[1].plot(hist.accuracy, label='Train' )\nax[1].plot(hist.val_accuracy, label='validation' )\nax[1].legend()\nax[1].grid()\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Accuracy')\nplt.show()\n","c49d0381":"keras.utils.plot_model(model_06)","c387fcc2":"y_true_val  =  np.array([np.argmax(val_gen[i][1], axis=1) for i in range(len(val_gen))]).reshape(val_gen.classes.shape)   \n# not sure this line is correct\ny_preds_val =  model_01.predict(val_gen).argmax(axis=1)\ncm = confusion_matrix(y_true_val, y_preds_val).T\n\nplt.figure(figsize=(20,20))\nsns.heatmap(cm, annot=True,\n#             fmt=\"d\",\n            cmap=\"binary\",\n            xticklabels=arabic_characters,\n            yticklabels=arabic_characters,\n           )\n","697d1b77":"all_models   = [ \n    model_01, \n    model_02, \n#     model_03, \n#     model_04, \n    model_06 \n]\n# merged_model = model_05","c0ebb67e":"# make predictions\nyhats = [ model.predict(test_ds) for model in all_models ]\n# medged_pred = model_05.predict(get_predict_data(test_ds))\n# yhats.append(medged_pred)\n\nyhats = np.array(yhats)\n\n# sum across ensembles\nsummed = np.sum(yhats, axis=0)\n\n# argmax across classes\noutcomes = np.argmax(summed, axis=1) + 1","4471d50a":"yhats.shape","cb210b43":"# argmax across classes\n\nCNN_outcome      = np.argmax(yhats[0], axis=1) + 1\nVGG16_outcome    = np.argmax(yhats[1], axis=1) + 1\n# MobNet_outcome   = np.argmax(yhats[2], axis=1) + 1\n# Xception_outcome = np.argmax(yhats[3], axis=1) + 1\nRNN_outcome      = np.argmax(yhats[2], axis=1) + 1\n# MERGED_outcome   = np.argmax(yhats[5], axis=1) + 1","398c1e8b":"test_df_pred = pd.DataFrame( {\n        'id'                  :  file_names,\n        'ENSEMBLED'           :  outcomes ,\n        'CNN'                 :  CNN_outcome      ,\n        'VGG16'               :  VGG16_outcome    ,\n#         'MobNet'              :  MobNet_outcome   ,\n#         'Xception'            :  Xception_outcome ,\n        'RNN'                 :  RNN_outcome      ,\n#         'MERGED'              :  MERGED_outcome   ,\n\n        'Ensemble_Letter'     :  arabic_characters[outcomes -1] ,\n        'CNN_Letter'          :  arabic_characters[CNN_outcome -1]      ,\n        'VGG16_Letter'        :  arabic_characters[VGG16_outcome -1]    ,\n#         'MobNet_Letter'       :  arabic_characters[MobNet_outcome -1]   ,\n#         'Xception_Letter'     :  arabic_characters[Xception_outcome -1] ,\n        'RNN_Letter'          :  arabic_characters[RNN_outcome -1]      ,\n#         'MERGED_Letter'       :  arabic_characters[MERGED_outcome -1]\n})\n\ntest_df_pred","c21041b1":"test_df_pred.to_csv('test_df_pred_all_models.csv', index=False)","20b7cfc5":"test_df = pd.DataFrame( { 'id' : file_names, \n                         'label':outcomes, \n                         'letter':arabic_characters[outcomes-1]} )\ntest_df","858df677":"test_df[['id','label']].to_csv('submission.csv', index=False)","27cbc636":"----\n## `05`- Transfer + Merged (CNN + VGG16)","e1f6016f":"### All Models","7a894f41":"## Heatmap","d52ad01c":"---\n# Prediction - Ensembling MODELS\n---","84092b48":"---\n# Curate Dataset\n---","d176c3d5":"## `01`- CNN","b52bf432":"----\n## `02`- Transfer\/VGG16","711613f0":"----\n## `06`- RNN","03401344":"---\n# Submission\n---","ad711d2d":"----\n# MODELS WITH DIFFERENT ARCHITECTURE\n----","dc5872d2":"---\n# Create Generator\n---","4d097812":"----\n## `04`- Transfer\/Xception","753de313":"----\n## `03`- Transfer\/MOBILENET"}}