{"cell_type":{"66958ef9":"code","e6d7de48":"code","96930806":"code","088a6cf8":"code","c9f674cb":"code","9c0e9d22":"code","bf413e2d":"code","f8996357":"code","c49b6bdd":"code","cc21cb57":"code","f72b818e":"code","3064dab7":"code","802f8fdf":"code","1c7016c8":"code","0fa1538f":"code","85852315":"code","4a5e41d5":"code","eec14033":"code","1aa3ec40":"code","e017b3ea":"code","19fd9e99":"code","a2b01c28":"code","bf3ee1bf":"code","80d0135d":"code","1910b4d4":"code","54d3cb9e":"code","72aa757e":"code","999f5aba":"code","d9eda63b":"code","07148553":"code","fe4e90d6":"code","defe8f33":"code","64e0c24a":"code","740e74eb":"code","80e3c8be":"code","b1bf1668":"code","e0d1d208":"code","589e0a23":"code","fbcaa06b":"code","5d5405a4":"code","f045855d":"markdown","c3a0aec1":"markdown","24ee3049":"markdown","4f61cb89":"markdown","0493f01b":"markdown","c891e4e6":"markdown","3118cbf8":"markdown","37ae8a2a":"markdown","588bb1ac":"markdown","b0e1643f":"markdown","47b19559":"markdown","499a1e49":"markdown","cac2fcfc":"markdown","74b449f7":"markdown","65054548":"markdown","6d3a5323":"markdown","194dc0a9":"markdown","f2aa1c31":"markdown","f7e8b6d2":"markdown","a24aa03a":"markdown","f9d353eb":"markdown","69b446f9":"markdown"},"source":{"66958ef9":"import pandas as pd\nimport numpy as np\nimport json\nimport plotly.express as px","e6d7de48":"#Loading Json file\nwith open('..\/input\/challange-data\/loan_data.json') as f:\n  data = json.load(f)\n\n\n# Normalizing json to flat dataframe\ndf =  pd.json_normalize(data)\nprint(df.shape)\ndf.head()","96930806":"df.describe(include='all') #Good news is that, none of any columns contain null value","088a6cf8":"df.Dependents.unique()","c9f674cb":"df['Dependents'].replace({'3+':'4'},inplace=True)\n\n#Converting Str type to Int.\ndf['Dependents']= df['Dependents'].apply(lambda x: int(x))","9c0e9d22":"D_unique, D_counts =  np.unique(df.Dependents,return_counts = True)\nDependents_unique_counts = dict(zip(D_unique, D_counts))","bf413e2d":"\nfor key in Dependents_unique_counts:\n    num = Dependents_unique_counts[key]\/511*100\n    num = round(num, 2)\n    num = str(num)+' %'\n    \n    # Adding This percentage as value in Dictionary\n    Dependents_unique_counts[key] = [Dependents_unique_counts.get(key),num]","f8996357":"# Converting Dictionary to Datframe, not necessary step,\n# But it makes analysis easy to eyes, as Dictionary sometimes\n# uneasy to understand","c49b6bdd":"Unique_dap_value = pd.DataFrame.from_dict(Dependents_unique_counts)\nUnique_dap_value['Index'] = ['Total Counts','Percentage']\nUnique_dap_value.set_index('Index',drop=True, inplace=True)\n","cc21cb57":"Unique_dap_value","f72b818e":"total_Dependents = df.Dependents.sum()\nAvg_dependents = total_Dependents\/511\nAvg_dependents = round(Avg_dependents,2)\nAvg_dependents","3064dab7":"df['Counts'] = [1]*511\nsum = df.groupby(by=['Self_Employed','Application_Status']).sum()\nsum.iloc[3:,2:]","802f8fdf":"avg_self_employed_approval = 46\/511\navg_self_employed_approval","1c7016c8":"sum = df.groupby(by=['Gender','Married','Application_Status'], axis=0).sum()\nsum.iloc[6:7,2:] ","0fa1538f":"df.groupby(['Married','Gender']).sum()","85852315":"Percentage_Rex_male =  87\/511*100\nPercentage_Rex_male = round(Percentage_Rex_male,2)\nPercentage_Rex_male","4a5e41d5":"sum = df.groupby(by=['Gender','Application_Status'], axis=0, as_index= False, sort = True).sum()\n\n\nfig = px.histogram(df, x = 'Gender', y = 'Counts', color = 'Application_Status', barmode='group')\nfig.update_layout(\n    title=\"Gender VS Application Status\",\n    xaxis_title=\"Gender\",\n    yaxis_title=\"Total\",\n    legend_title=\"Application Status\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"RebeccaPurple\"\n    ))","eec14033":"sum = df.groupby(['Dependents','Application_Status'], axis = 0, as_index= False, sort = True).sum()\n\n\nfig = px.histogram(df,x='Dependents',y='Counts',color ='Application_Status', barmode = 'group')\nfig.update_layout(\n    title= \"Dependents VS Application Status\",\n    xaxis_title= \"Dependents\",yaxis_title= \"Total\",legend_title= \"Application Status\",\n    font=dict(family= \"Courier New, monospace\",size=18,color= \"RebeccaPurple\"))","1aa3ec40":"sum = df.groupby(['Education','Application_Status'], axis = 0, sort = True, as_index = False).sum()\n\n\nfig = px.bar(sum, x = 'Education', y='Counts', color = 'Application_Status', barmode='group')\nfig.update_layout(\n    title= \"Education VS Application Status\",\n    xaxis_title= \"Level of Education\",yaxis_title= \"Total\",legend_title= \"Application Status\",\n    font=dict(family= \"Courier New, monospace\",size=18,color= \"RebeccaPurple\"))","e017b3ea":"sum = df.groupby(['Property_Area','Application_Status'], axis = 0, as_index = False).sum()\n\n\nfig = px.histogram(sum, x = 'Property_Area', y='Counts', color = 'Application_Status', barmode='group')\nfig.add_annotation(x='Semiurban', y=153,\n            text=\"High Rise\",\n            showarrow=True,\n            arrowhead=1)\n\nfig.update_layout(\n    title= \"Property Area VS Application Status\",\n    xaxis_title= \"Area type\",yaxis_title= \"Total\",legend_title= \"Application Status\",\n    font=dict(family= \"Courier New, monospace\",size=18,color= \"RebeccaPurple\"))","19fd9e99":"sum = df.groupby(['Self_Employed','Application_Status'], axis = 0, as_index = False).sum()\n\n\nfig = px.histogram(sum, x = 'Self_Employed', y='Counts', color = 'Application_Status', barmode='group')\n\nfig.update_layout(\n    title= \"Self-Employed VS Application Status\",\n    xaxis_title= \"Employed\",yaxis_title= \"Total\",legend_title= \"Application Status\",\n    font=dict(family= \"Courier New, monospace\",size=18,color= \"RebeccaPurple\"))","a2b01c28":"sum = df.groupby(['Income','Application_Status'], axis = 0, as_index = False).sum()\n\n\nfig = px.histogram(sum, x = 'Income', y='Counts', color = 'Application_Status', barmode='group')\n\nfig.update_layout(\n    title= \"Income VS Application Status\",\n    xaxis_title= \"Income\",yaxis_title= \"Total\",legend_title= \"Application Status\",\n    font=dict(family= \"Courier New, monospace\",size=18,color= \"RebeccaPurple\"))","bf3ee1bf":"C_unique, C_counts =  np.unique(df.Credit_History,return_counts = True)","80d0135d":"sum = df.groupby(['Credit_History','Application_Status'], axis = 0, as_index = False).sum()\n\nfig = px.histogram(sum, x = 'Credit_History', y='Counts', color = 'Application_Status', barmode='group')\n\nfig.update_layout(\n    title= \"Credit_History VS Application Status\",\n    xaxis_title= \"Credit_History\",yaxis_title= \"Total\",legend_title= \"Application Status\",\n    font=dict(family= \"Courier New, monospace\",size=18,color= \"RebeccaPurple\"))","1910b4d4":"sum = df.groupby(['Married','Application_Status'], axis = 0, as_index = False).sum()\n\nfig = px.histogram(sum, x = 'Married', y='Counts', color = 'Application_Status', barmode='group')\n\nfig.add_annotation(x='Yes', y=240,\n            text=\"High Chance of Acceptance\",\n            showarrow=True,\n            arrowhead=1)\nfig.add_annotation(x='No', y=115,\n            text=\"little aboveto Rejection\",\n            showarrow=True,\n            arrowhead=1)\n\nfig.update_layout(\n    title= \"Maritail Status VS Application Status\",\n    xaxis_title= \"Married\",yaxis_title= \"Total\",legend_title= \"Application Status\",\n    font=dict(family= \"Courier New, monospace\",size=18,color= \"RebeccaPurple\"))","54d3cb9e":"income_group = df.groupby(['Income']).sum()\nincome_group","72aa757e":"ln = []\nfor i in range(3):\n               fraction = income_group.iloc[i,0]\/income_group.iloc[i,2]\n               fraction = round(fraction,2)\n               ln.append(fraction)\nincome_group['Average Dependents'] = ln","999f5aba":"income_group","d9eda63b":"# We gonna Drop Application_ID column because we don't need it, for training Machine.","07148553":"df['Gender'] = df['Gender'].apply(lambda x: 1 if x=='Male' else 0)\n\ndf['Married'] = df['Married'].apply( lambda x: 1 if x=='Yes' else 0 )\n\ndf['Education'] = df['Education'].apply( lambda x: 1 if x=='Graduate' else 0 )\n\ndf['Self_Employed'] = df['Self_Employed'].apply(lambda x: 1 if x=='Yes' else 0)\n\ndf.tail()","fe4e90d6":"dum_df = pd.get_dummies(df[['Property_Area','Income']])\n\n\n# Joining these Two DataFrame.\ndf = pd.concat([df,dum_df], axis = 1)\ndf.tail()","defe8f33":"df.drop(['Application_ID','Income','Property_Area'], axis = 1, inplace = True)","64e0c24a":"df['Application_Status'] = df['Application_Status'].apply(lambda x: 1 if x=='Y' else 0)","740e74eb":"Y = df['Application_Status']\nX = df.drop(['Application_Status'], axis = 1)\n\n#No need to preprocess the data since everything is already between 0-1","80e3c8be":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X,Y,test_size = 0.3, random_state = 1, shuffle = True)","b1bf1668":"from sklearn.linear_model import LogisticRegression","e0d1d208":"linearModel = LogisticRegression(C=0.1, solver = 'liblinear')\nlinearModel.fit(x_train, y_train)\nprediction = linearModel.predict(x_test)","589e0a23":"from sklearn.metrics import f1_score\nscore = f1_score(y_test, prediction)\nprint('F1-Score for Logistics is {:.2f}%'.format(score*100))","fbcaa06b":"linearModel.coef_\n\n# 6th coefficient is corresponds to Credit_History which is of maximum weightage,\n# thus it, confirms our guess, that it is most important factor in loan approval.","5d5405a4":"linearModel.intercept_","f045855d":"*Converting Target variable from <code>Str<\/code> to <code>Int<\/code> , beacause we're gonna use Logistic regression and to that algorithm dosn't support string format.*","c3a0aec1":"<H1>Result-7<\/H1>  \n<H3>we have acheived model <code>accuracy = 86%.<\/code><\/H3>","24ee3049":"<H2>Result-6<\/H2> \n    <H3>Avg Dependetns per income Group.<\/H3>   \n    \n    \n![Web%20capture_12-1-2022_1921_localhost.jpeg](attachment:Web%20capture_12-1-2022_1921_localhost.jpeg)","4f61cb89":"<B><code> One Hot Encoding<\/code> Property_Area & Income.","0493f01b":"As we can see Total numbers of Self employed applicants who got their loan approval is <code>46<\/code>, \nand <code> Total = 511<\/code> so we can find avg of it, just by dividing numbers.","c891e4e6":"<H2>Result-5<\/H2> \n    <H3><code>Credit History <\/code>  is property with maximum approval ratio.\n\n    \n<table>\n   <tr>\n      <th>\n         <center>Factor<\/center>\n      <\/th>\n      <th>Note<\/th>\n   <\/tr>\n   <tr>\n      <td>Married: <\/td>\n      <td>Married people have high chance of getting aproved for loan by <B>2.5<\/B> times<\/td>\n   <\/tr>\n   <tr>\n      <td>Gender: <\/td>\n      <td>Male are more prone to get approval from bank by <B>2.23<\/B> time, while ladies have only 1.167 times chance of getting approval<\/td>\n   <\/tr>\n   <tr>\n      <td>Dependents: <\/td>\n      <td> Those having No dependents have <B>2.06<\/B> times chance of getting loan<\/td>\n   <\/tr>\n   <tr>\n      <td>Land Area: <\/td>\n      <td> People with land in semiurban area have extremely high chance of approval by <B>3.5<\/B> time<\/td>\n   <\/tr>\n   <tr>\n      <td>Employed: <\/td>\n      <td> Employed or Non-Employed people have approximately <B>equal<\/B> chance of getting loan<\/td>\n   <\/tr>\n   <tr>\n      <td>Income: <\/td>\n      <td> Applicants with Low or Medium Income have <B>2.2<\/B> time chance of getting approval,Surprising Fact:Those with high income are more <B>prone to get rejected<\/B><\/td>\n   <\/tr>\n   <tr>\n      <td>Credit History: <\/td>\n      <td> Credit History is Important because, those with no history is extremely prone to rejected while others have <B>3.8<\/B> time chance of getting loan<\/td>\n   <\/tr>\n<\/table>","3118cbf8":"### Checking Statistical significance of each columns","37ae8a2a":"- We will convert <code>Gender<\/code> Columns with <code>( Male=1|Female=0 )<\/code>\n- <code>Dependents<\/code> column has been already modified so no need to alter this.  \n- We will convert <code>Married<\/code> Columns with <code>( Yes=1|No=0 )<\/code>\n- We will convert <code>Education<\/code> Columns with <code>( Graduated=1|Non-Graduated=0 )<\/code>","588bb1ac":"<H1> Logistic Regression  \n<H3><I>Coefficient of Sigmoid Function For Logistic Regression","b0e1643f":"<H4><code>Total applicants = 511<\/code><\/H4>\n<H4><code>Total Married = 331<\/code><\/H4>\n<H4><code>Total Married Male = 306<\/code><\/H4>\n<H4><code>Total Married Male Rejected= 87<\/code><\/H4>\n<H2>Result-4<\/H2> \n    <H3>Out of 511 applicants 17 % are Rejected married male applicants\n    ","47b19559":"## Score of trained Model","499a1e49":"## Train_Test_Split( )","cac2fcfc":"<H2>Result-2<\/H2> <H3><I>Average Numbers of Depenedents per Applicants is <code> 0.86 <\/code>\n<\/H3>","74b449f7":"\n<h1><I> Preparing Data for Machine<\/I><\/h1>\n","65054548":"<code>Dropping Columns<\/code> like   \n- Application_ID\n- Property_Area\n- Income","6d3a5323":"## Intercept of Sigmoid Function For Logistic Regression","194dc0a9":"Thus out of <code>Total = 511<\/code>, there are <code>87<\/code> male applicants who are married and rejected.","f2aa1c31":"<H2>Result-3<\/H2> <H3>Avg application approved for self-employed applicants out of <code> <B>Total:511 <\/B><\/code> applicants is <code><B>0.09<\/B> <\/code>, which is quite low number","f7e8b6d2":"Importing Required Libraries","a24aa03a":"# Taking assumption that categories with 3+ Dependents = 4 Dependents   \n*because mostly people share details of at max 4 people for any loan or bank related tasks*","f9d353eb":"## Training  & Testing Model","69b446f9":"<H2>Result-1<\/H2><H3>Percentage of Total applicants with each unique value of Dependents"}}