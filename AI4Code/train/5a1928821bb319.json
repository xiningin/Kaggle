{"cell_type":{"0cb8a088":"code","b279cf7b":"code","dbd7d92d":"code","6a2d38e7":"code","99ad63ad":"code","fb5bf643":"code","6c047485":"code","31df9627":"code","67656057":"code","04fa07d6":"code","4823ada2":"code","44444da2":"code","1e244379":"code","db5f1115":"code","42327615":"code","ad41d650":"code","ce10af15":"code","0a2ecb35":"code","89653b75":"code","381ccf1e":"code","6f5f3cb5":"code","c3df93c1":"code","fc1dcdd1":"code","0627134b":"markdown","2034e31c":"markdown","af2f02fc":"markdown","517084c0":"markdown","c199f4d9":"markdown"},"source":{"0cb8a088":"import os\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom fastprogress import master_bar, progress_bar\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\n\n\n%matplotlib inline","b279cf7b":"def seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","dbd7d92d":"DIRPATH = '..\/input\/ailab-ml-training-0\/'\nTRAIN_IMAGE_DIR = 'train_images\/train_images\/'\nTEST_IMAGE_DIR = 'test_images\/test_images\/'\n\nID = 'fname'\nTARGET = 'label'\n\nVALID_SIZE = 0.2\nEPOCHS = 5\nBATCH_SIZE = 64\nLR = 1e-3\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nSEED = 42\nseed_everything(SEED)","6a2d38e7":"os.listdir(DIRPATH)","99ad63ad":"train_df = pd.read_csv(os.path.join(DIRPATH, 'train.csv'))","fb5bf643":"train_df.head()","6c047485":"sample_index = [0, 10, 100]\n\nfig, ax = plt.subplots(1, len(sample_index))\nfig.set_size_inches(4 * len(sample_index), 4)\n\nfor i, idx in enumerate(sample_index):\n    fname, label = train_df.loc[idx, [ID, TARGET]]\n    img = cv2.imread(os.path.join(DIRPATH, TRAIN_IMAGE_DIR, fname))\n    ax[i].imshow(img)\n    ax[i].set_title(f'{fname} - label: {label}')\n\nplt.show()","31df9627":"class TrainDataset(Dataset):\n    def __init__(self, fname_list, label_list, image_dir, transform=None):\n        super().__init__()\n        self.fname_list = fname_list\n        self.label_list = label_list\n        self.image_dir = image_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.fname_list)\n    \n    def __getitem__(self, idx):\n        fname = self.fname_list[idx]\n        label = self.label_list[idx]\n        \n        image = cv2.imread(os.path.join(self.image_dir, fname))\n        if self.transform is not None:\n            image = self.transform(image)\n        \n        return image, label","67656057":"class SimpleClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv_module = nn.Sequential(\n            # (N, 3, 28, 28) --> (N, 32, 14, 14)\n            nn.Conv2d(3, 32, 3, stride=1, padding=1, bias=True),\n            nn.ReLU(True),\n            nn.MaxPool2d(2),\n            # (N, 32, 14, 14) --> (N, 64, 7, 7)\n            nn.Conv2d(32, 64, 3, stride=1, padding=1, bias=True),\n            nn.ReLU(True),\n            nn.MaxPool2d(2),\n            # (N, 64, 7, 7) --> (N, 128, 7, 7)\n            nn.Conv2d(64, 128, 3, stride=1, padding=1, bias=True),\n            nn.ReLU(True),\n        )\n        self.dense_module = nn.Sequential(\n            nn.Linear(128*7*7, 10, bias=True)\n        )\n    \n    def forward(self, x):\n        x = self.conv_module(x)\n        x = x.view(x.size(0), -1)\n        x = self.dense_module(x)\n\n        return x","04fa07d6":"fname_list = train_df[ID].to_list()\nlabel_list = train_df[TARGET].to_list()\n\ntrain_fname_list, valid_fname_list, train_label_list, valid_label_list = train_test_split(\n    fname_list, label_list, test_size=VALID_SIZE, random_state=SEED, shuffle=True\n)","4823ada2":"len(fname_list), len(train_fname_list), len(valid_fname_list)","44444da2":"image_dir = os.path.join(DIRPATH, TRAIN_IMAGE_DIR)\n\ntransform = transforms.Compose([\n    transforms.ToTensor()\n])\n\ntrain_dataset = TrainDataset(train_fname_list, train_label_list, image_dir, transform=transform)\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n\nvalid_dataset = TrainDataset(valid_fname_list, valid_label_list, image_dir, transform=transform)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)","1e244379":"model = SimpleClassifier().to(DEVICE)\noptim = Adam(model.parameters(), lr=LR)\ncriterion = nn.CrossEntropyLoss()","db5f1115":"mb = master_bar(range(EPOCHS))\n\nfor epoch in mb:\n    \n    # training\n    \n    model.train()\n    train_loss_list = []\n    train_accuracy_list = []\n    \n    for batch_image, batch_label in progress_bar(train_dataloader, parent=mb):\n        batch_image = batch_image.to(dtype=torch.float32, device=DEVICE)\n        batch_label = batch_label.to(dtype=torch.long, device=DEVICE)\n        \n        optim.zero_grad()\n        batch_pred = model(batch_image)\n        loss = criterion(batch_pred, batch_label)\n        loss.backward()\n        optim.step()\n        \n        train_loss_list.append(loss.item())\n        accuracy = accuracy_score(torch.argmax(batch_pred, axis=1).cpu().numpy(), batch_label.cpu().numpy())\n        train_accuracy_list.append(accuracy)\n    \n    # validation\n    \n    model.eval()\n    valid_loss_list = []\n    valid_accuracy_list = []\n    \n    for batch_image, batch_label in valid_dataloader:\n        batch_image = batch_image.to(dtype=torch.float32, device=DEVICE)\n        batch_label = batch_label.to(dtype=torch.long, device=DEVICE)\n        \n        with torch.no_grad():\n            batch_pred = model(batch_image)\n            loss = criterion(batch_pred, batch_label)\n        \n        valid_loss_list.append(loss.item())\n        accuracy = accuracy_score(torch.argmax(batch_pred, axis=1).cpu().numpy(), batch_label.cpu().numpy())\n        valid_accuracy_list.append(accuracy)\n    \n    # verbose\n    \n    mb.write('epoch: {}\/{} - loss: {:.5f} - accuracy: {:.3f} - val_loss: {:.5f} - val_accuracy: {:.3f}'.format(\n        epoch,\n        EPOCHS, \n        np.mean(train_loss_list),\n        np.mean(train_accuracy_list),\n        np.mean(valid_loss_list),\n        np.mean(valid_accuracy_list)\n    ))","42327615":"submission_df = pd.read_csv(os.path.join(DIRPATH, 'sample_submission.csv'))","ad41d650":"submission_df.head()","ce10af15":"fname_list = submission_df[ID].to_list()\nlabel_list = submission_df[TARGET].to_list()\n\nimage_dir = os.path.join(DIRPATH, TEST_IMAGE_DIR)\n\ntransform = transforms.Compose([transforms.ToTensor()])\n\ntest_dataset = TrainDataset(fname_list, label_list, image_dir, transform=transform)\ntest_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)","0a2ecb35":"model.eval()\npredictions = []\n\nfor batch_image, _ in progress_bar(test_dataloader):\n    batch_image = batch_image.to(dtype=torch.float32, device=DEVICE)\n    \n    with torch.no_grad():\n        batch_pred = model(batch_image)\n        batch_pred = torch.argmax(batch_pred, axis=1).cpu().numpy()\n        \n    predictions.append(batch_pred[0])","89653b75":"submission_df[TARGET] = predictions","381ccf1e":"sample_index = [0, 10, 100]\n\nfig, ax = plt.subplots(1, len(sample_index))\nfig.set_size_inches(4 * len(sample_index), 4)\n\nfor i, idx in enumerate(sample_index):\n    fname, label = submission_df.loc[idx, [ID, TARGET]]\n    img = cv2.imread(os.path.join(DIRPATH, TEST_IMAGE_DIR, fname))\n    ax[i].imshow(img)\n    ax[i].set_title(f'{fname} - label: {label}')\n\nplt.show()","6f5f3cb5":"submission_df.head()","c3df93c1":"submission_df.to_csv('submission.csv', index=False)","fc1dcdd1":"from IPython.display import FileLink\nFileLink('submission.csv')","0627134b":"# Define Dataset & Model","2034e31c":"# Prediction & Submission","af2f02fc":"# Loading","517084c0":"\u6642\u9593\u304c\u306a\u3044\u306e\u3067\u30b3\u30e1\u30f3\u30c8\u306a\u3069\u5272\u611b\u3057\u307e\u3059...","c199f4d9":"# Training"}}