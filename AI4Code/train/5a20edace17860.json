{"cell_type":{"f0155d3e":"code","969301a3":"code","f868d269":"code","e064957b":"code","bd26dc80":"code","be11a395":"code","564fc31d":"code","beb7cf38":"code","93132d6b":"code","3d3a7369":"code","ae2a5d09":"code","99cd4d5b":"markdown","32ff3e02":"markdown","d49e4db0":"markdown","6daff466":"markdown","fb225fa3":"markdown"},"source":{"f0155d3e":"!pip install kaggle\nfrom google.colab import files\nfiles.upload()","969301a3":"ls -1ha kaggle.json","f868d269":"!mkdir -p ~\/.kaggle\n!cp kaggle.json ~\/.kaggle\/\n# Permission Warning \uc774 \uc77c\uc5b4\ub098\uc9c0 \uc54a\ub3c4\ub85d \n!chmod 600 ~\/.kaggle\/kaggle.json\n!kaggle competitions list","e064957b":"! kaggle datasets download -d iluvchicken\/cheetah-jaguar-and-tiger","bd26dc80":"!ls","be11a395":"!unzip cheetah-jaguar-and-tiger.zip","564fc31d":"import torch\nimport os\nfrom skimage import io\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nimport numpy as np\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\nUSE_CUDA = torch.cuda.is_available()\nDEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n\nEPOCH = 20\nBATCH_SIZE = 16\n\n\n\n# class Normalize(object):\n#   def __init__(self, mean, std):\n#     self.mean=mean\n#     self.std=std\n  \n#   def __call__(self, tensor, keepdim=True):\n#     return F.normalize(tensor, self.mean, self.std)\n\n# class ToTensor(object):\n#   def __call__(self, image):\n#     image = image.transpose((2,0,1))\n#     return torch.from_numpy(image)\n\ntransforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485,0.456,0.406],\n                                                                             std=[0.229,0.224,0.225])])\n\nclass MyDataset(Dataset):\n  def __init__(self, image_dir, label, transforms=None):\n    self.image_dir = image_dir\n    self.label = label\n    self.image_list = os.listdir(self.image_dir)\n    self.transforms = transforms\n  \n  def __len__(self):\n    return len(self.image_list)\n  \n  def __getitem__(self,idx):\n    # if torch.is_tensor(idx):\n    #   idx = idx.tolist()\n\n    image_name = os.path.join(self.image_dir, self.image_list[idx])\n    image = io.imread(image_name)\n\n    ### transform\n    image = transforms(image)\n\n    return (image,self.label)\n\n#cheetah : 0 , jaguar : 1, tiger : 2\n### in kaggle notebook, make sure directory path! it is begin with '\/input\/'\ncheetah_train = MyDataset(\".\/cheetah_train_resized\",0,transforms)\njaguar_train = MyDataset(\".\/jaguar_train_resized\",1,transforms)\ntiger_train = MyDataset(\".\/tiger_train_resized\",2,transforms)\ntrain_set = ConcatDataset([cheetah_train, jaguar_train, tiger_train])\nprint(\"Number of Training set images : \", len(train_set))\n\ncheetah_val = MyDataset(\".\/cheetah_validation_resized\",0, transforms)\njaguar_val = MyDataset(\".\/jaguar_validation_resized\",1, transforms)\ntiger_val = MyDataset(\".\/tiger_validation_resized\",2, transforms)\nval_set = ConcatDataset([cheetah_val, jaguar_val, tiger_val])\nprint(\"Numver of Validation set images : \", len(val_set))\n","beb7cf38":"train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle = True)\nval_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)","93132d6b":"import torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models as models\n\nclass Net(nn.Module):\n  def __init__(self):\n    super(Net, self).__init__()\n    self.ConvLayer1 = nn.Sequential(\n        nn.Conv2d(3,8,3),\n        nn.Conv2d(8,16,3),\n        nn.MaxPool2d(2),\n        nn.ReLU()\n    )\n    self.ConvLayer2 = nn.Sequential(\n        nn.Conv2d(16,32,3),\n        nn.Conv2d(32,32,3),\n        nn.MaxPool2d(2),\n        nn.ReLU()\n    )\n    self.ConvLayer3 = nn.Sequential(\n        nn.Conv2d(32,64,3),\n        nn.Conv2d(64,64,3),\n        nn.MaxPool2d(2),\n        nn.ReLU()\n    )\n    self.ConvLayer4 = nn.Sequential(\n        nn.Conv2d(64,128,3),\n        nn.Conv2d(128,128,3),\n        nn.MaxPool2d(2),\n        nn.ReLU()\n    )\n    self.ConvLayer5 = nn.Sequential(\n        nn.Conv2d(128,64,1),\n        nn.ReLU()\n    )\n    self.Lin1 = nn.Linear(64*21*21,4000)\n    self.Lin2 = nn.Linear(4000,500)\n    self.Lin3 = nn.Linear(500,3)\n\n  def forward(self,x):\n    x = self.ConvLayer1(x)\n    x = self.ConvLayer2(x)\n    x = self.ConvLayer3(x)\n    x = self.ConvLayer4(x)\n    x = self.ConvLayer5(x)\n    # print(x.shape)\n    x = x.view(x.size(0),-1)\n    x = self.Lin1(x)\n    x = self.Lin2(x)\n    x = self.Lin3(x)\n    return F.log_softmax(x, dim=1)\n\n### learning rate\nLR = 0.001\n\nmodel = models.resnet18(pretrained=False).to(DEVICE)\n# model = Net().to(DEVICE)\noptimizer = optim.Adam(model.parameters(), lr=LR)","3d3a7369":"def train(model, train_loader, optimizer, epoch):\n  model.train()\n  for batch_idx, (image, target) in enumerate(train_loader):\n    data, target = image.to(DEVICE), target.to(DEVICE)\n    optimizer.zero_grad()\n    output = model(data)\n    loss = F.cross_entropy(output, target)\n    loss.backward()\n    optimizer.step()\n\n    if batch_idx % 70 == 0 :\n      print('Train Epoch : {} [{}\/{} ({:.0f})%]\\tLoss: {:.6f}'\n      .format(epoch, batch_idx*len(image),len(train_loader.dataset), 100.*batch_idx \/ len(train_loader), loss.item()))\n\ndef evaluate(model, test_loader):\n  model.eval()\n  test_loss =0\n  correct =0\n  with torch.no_grad():\n    for (image, target) in test_loader:\n      image, label = image.to(DEVICE), target.to(DEVICE)\n      output = model(image)\n\n      test_loss += F.cross_entropy(output, label, reduction='sum').item()\n      pred = output.max(1, keepdim=True)[1]\n      correct+= pred.eq(label.view_as(pred)).sum().item()\n  \n  test_loss \/= len(test_loader.dataset)\n  test_accuracy = 100. * correct \/ len(test_loader.dataset)\n  return test_loss, test_accuracy","ae2a5d09":"for epoch in range(1, EPOCH+1):\n    train(model, train_loader, optimizer, epoch)\n    test_loss, test_accuracy = evaluate(model, val_loader)\n    print('[{}] Test Loss : {:.4f}, Accuracy : {:.4f}%'.format(epoch, test_loss, test_accuracy))","99cd4d5b":"# Connect kaggel to colab\n**For colab user or who want to use colab instead kaggle notebook**\n\nblew link is colab notebook\n\nhttps:\/\/colab.research.google.com\/drive\/1ISVslooJrBITKYvVbV9bEbXWpdssejBF?usp=sharing\n\ncheck bleow link and download your kaggle account API\n\nhttps:\/\/medium.com\/hyunjulie\/%EC%BA%90%EA%B8%80%EA%B3%BC-%EA%B5%AC%EA%B8%80-colab-%EC%97%B0%EA%B2%B0%ED%95%B4%EC%A3%BC%EA%B8%B0-6a274f6de81d","32ff3e02":"#EXECUTION","d49e4db0":"#Train","6daff466":"# Dataset (load)\nit might be help to dataload. In this example, it load resized image files","fb225fa3":"# MODEL"}}