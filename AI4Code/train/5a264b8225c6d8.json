{"cell_type":{"8a861eba":"code","0c51c51f":"code","61b4e446":"code","ff6144bc":"code","463bb585":"code","38cde134":"code","0f4e1f44":"code","dbe398ce":"code","8120505c":"code","b4472fde":"code","dbe8ca06":"code","6e4e24e2":"code","8fb308c1":"code","f21b3360":"code","8a0af2ff":"code","93307388":"code","d967b90d":"code","e1650a3c":"code","3017c00e":"code","705e3db9":"code","d12a090f":"code","3818d211":"code","6400e548":"code","0a0c41e7":"code","b9393b62":"code","9eac9185":"code","e9828cc8":"markdown"},"source":{"8a861eba":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","0c51c51f":"df = pd.read_csv('..\/input\/concrete-data\/Concrete_Data.csv')\ndf.head()","61b4e446":"for col in df.columns:\n    print(col,'\\n',df[col].unique(),'\\n'*2 )","ff6144bc":"df.skew()","463bb585":"df.isnull().sum()","38cde134":"from scipy.stats import shapiro","0f4e1f44":"df.columns","dbe398ce":"X = df.drop('Concrete compressive strength(MPa, megapascals) ',axis=1)\ny= df['Concrete compressive strength(MPa, megapascals) ']","8120505c":"from sklearn.model_selection import train_test_split\n# train data -70% \nX_train, X_test , y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 42)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","b4472fde":"import warnings \nwarnings.filterwarnings('ignore')\nimport statsmodels.api as sm\nimport scipy.stats as st","dbe8ca06":"X_constant = sm.add_constant(X)\nlin_reg = sm.OLS(y,X_constant).fit()\nlin_reg.summary()","6e4e24e2":"## strong multicollinearity\n## ","8fb308c1":"# Assumption 1: Normality Test\nst.jarque_bera(lin_reg.resid)","f21b3360":"sns.distplot(lin_reg.resid)","8a0af2ff":"import pylab\nfrom statsmodels.graphics.gofplots import ProbPlot\nst_residual = lin_reg.get_influence().resid_studentized_internal\nst.probplot(st_residual, dist=\"norm\", plot = pylab)\nplt.show()","93307388":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\npd.DataFrame({'vif': vif[1:]}, index=X.columns).T","d967b90d":"\ndef calculate_vif(x):\n    thresh = 5.0\n    output = pd.DataFrame()\n    k = x.shape[1]\n    vif = [variance_inflation_factor(x.values, j) for j in range(x.shape[1])]\n    for i in range(1,k):\n        print(\"Iteration no.\")\n        print(i)\n        print(vif)\n        a = np.argmax(vif)\n        print(\"Max VIF is for variable no.:\")\n        print(a)\n        if vif[a] <= thresh :\n            break\n        if i == 1 :          \n            output = x.drop(x.columns[a], axis = 1)\n            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n        elif i > 1 :\n            output = output.drop(output.columns[a],axis = 1)\n            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n    return(output)","e1650a3c":"## passing X to the function so that the multicollinearity gets removed.\ntrain_out = calculate_vif(X)","3017c00e":"from sklearn import datasets, linear_model\nfrom sklearn.model_selection import cross_val_score\nlasso = linear_model.Lasso()\nprint(cross_val_score(lasso, X, y, cv=10))\n","705e3db9":"l=[] \nfor i in df.columns: \n    if((df[i].skew()<0.1) or (df[i].skew()>0.2) and (i!='Outcome')): \n        l.append(i)","d12a090f":"for i in df.columns:\n    if i in l: \n        df[i]=list(st.boxcox(df[i]+1)[0]) \ndf.skew()","3818d211":"#Backward Elimination\ncols = list(X.columns)\npmax = 1\nwhile (len(cols)>0):\n    p= []\n    X_1 = X[cols]\n    X_1 = sm.add_constant(X_1)\n    model = sm.OLS(y,X_1).fit()\n    p = pd.Series(model.pvalues.values[1:],index = cols)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n        cols.remove(feature_with_p_max)\n    else:\n        break\nselected_features_BE = cols\nprint(selected_features_BE)","6400e548":"X = df.drop(['Concrete compressive strength(MPa, megapascals) ','Coarse Aggregate  (component 6)(kg in a m^3 mixture)',\n             'Fine Aggregate (component 7)(kg in a m^3 mixture)'],axis=1)\ny= df['Concrete compressive strength(MPa, megapascals) ']","0a0c41e7":"X_constant = sm.add_constant(X)\nlin_reg = sm.OLS(y,X_constant).fit()\nlin_reg.summary()","b9393b62":"cols = list(X.columns)\npmax = 1\nwhile (len(cols)>0):\n    p= []\n    X_1 = X[cols]\n    X_1 = sm.add_constant(X_1)\n    model = sm.OLS(y,X_1).fit()\n    p = pd.Series(model.pvalues.values[1:],index = cols)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n        cols.remove(feature_with_p_max)\n    else:\n        break\nselected_features_BE = cols\nprint(selected_features_BE)","9eac9185":"from sklearn.preprocessing import StandardScaler\nss=StandardScaler()\nX_trains=ss.fit_transform(X_train)\nX_tests=ss.transform(X_test)\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\n\nlr=LinearRegression()\nknn=KNeighborsRegressor()\nrf=RandomForestRegressor()\nsvr=SVR()\n\nmodels=[]\nmodels.append(('MVLR',lr))\nmodels.append(('KNN',knn))\nmodels.append(('RF',rf))\nmodels.append(('SVR',svr))\n\nresults=[]\nnames=[]\nfor name,model in models:\n    kfold=KFold(shuffle=True,n_splits=3,random_state=42)\n    cv_results=cross_val_score(model,X,y,cv=kfold,scoring='neg_mean_squared_error')\n    results.append(np.sqrt(np.abs(cv_results)))\n    names.append(name)\n    print(\"%s: %f (%f)\"%(name,np.mean(np.sqrt(np.abs(cv_results))),np.var(np.sqrt(np.abs(cv_results)),ddof=1)))\n    ","e9828cc8":"## Checking assumptions"}}