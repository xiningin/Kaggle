{"cell_type":{"ad3c2f17":"code","b7d73ec8":"code","c671477a":"code","c5dbef32":"code","02766dc5":"code","d4e3e43f":"code","98b556ba":"code","6718200d":"code","2362a6cf":"code","b04e2eb4":"code","54fbbc62":"code","52a8462f":"code","33cad3ff":"code","0df953a6":"code","75020de1":"code","8d855bc8":"code","95b0b93f":"code","751d71e5":"code","ceeee8f4":"code","0d66d7c9":"code","5f2a63c7":"code","30fb89b5":"code","549cc642":"code","0eb0ab5a":"code","f12b5bcc":"code","403b2ae6":"code","948db83b":"code","c832954a":"code","cfffe391":"code","f29349dc":"code","60008c74":"code","6f05d90f":"code","f31dfb7f":"code","767f0771":"code","f83c68d3":"code","837ffefa":"code","1e518880":"code","673dcc4a":"code","67b203e6":"code","d5cb188b":"code","1fbc77d0":"code","bf9efe72":"code","960577e5":"code","52c671bd":"code","ebcb76fa":"code","59033a3b":"code","c635327b":"code","7bf08531":"code","01775dfe":"code","f09bbb2a":"code","ccf6c465":"code","e0c26a39":"code","f7e51ec2":"markdown","f23311db":"markdown","e670076e":"markdown","39404724":"markdown","6fe2dd87":"markdown","d232a09c":"markdown","e45d521a":"markdown","35b4887f":"markdown","0bf9c6f9":"markdown","8f965a29":"markdown","b8de293e":"markdown","4cbd1fe5":"markdown","95d8454e":"markdown","c9a25910":"markdown","64f5c040":"markdown","75f4a81a":"markdown"},"source":{"ad3c2f17":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b7d73ec8":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","c671477a":"df = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')","c5dbef32":"df.head(5)","02766dc5":"df.info()","d4e3e43f":"sns.heatmap(df.isnull())","98b556ba":"df.drop(['location','keyword'],axis=1,inplace=True)","6718200d":"df","2362a6cf":"real = df[df['target']==1]","b04e2eb4":"real","54fbbc62":"unreal = df[df['target']==0]","52a8462f":"unreal","33cad3ff":"print('real disaster message percentage:',(len(real)\/len(df))*100)","0df953a6":"print('fake disaster message percentage:',(len(unreal)\/len(df))*100)","75020de1":"sns.countplot(df['target'])","8d855bc8":"import string\n","95b0b93f":"string.punctuation","751d71e5":"from nltk.corpus import stopwords","ceeee8f4":"stopwords.words('english');","0d66d7c9":"def message_cleaning(message):\n    test_punc_removed = [char   for char in message if char not in string.punctuation]\n    test_punc_removed_joined = ''.join(test_punc_removed)\n    test_punc_removed_joined_clean = [word   for word in test_punc_removed_joined.split(' ') if word not in stopwords.words('english')]\n    return test_punc_removed_joined_clean","5f2a63c7":"from sklearn.feature_extraction.text import CountVectorizer","30fb89b5":"vectorizer = CountVectorizer(analyzer=message_cleaning)","549cc642":"disaster_tweet_vectorizer = vectorizer.fit_transform(df['text'])","0eb0ab5a":"print(vectorizer.get_feature_names());","f12b5bcc":"print(disaster_tweet_vectorizer.toarray())","403b2ae6":"disaster_tweet_vectorizer.shape","948db83b":"label = df['target']","c832954a":"label.shape","cfffe391":"X = disaster_tweet_vectorizer","f29349dc":"X = X.toarray()","60008c74":"X","6f05d90f":"y = label","f31dfb7f":"from sklearn.model_selection import train_test_split","767f0771":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","f83c68d3":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\n","837ffefa":"LR = LogisticRegression()\nDTC = DecisionTreeClassifier()\nRFC = RandomForestClassifier()\nNB = GaussianNB()","1e518880":"RFC.fit(X_train,y_train)\nDTC.fit(X_train,y_train)\nNB.fit(X_train,y_train)\nLR.fit(X_train,y_train)","673dcc4a":"predict1 = RFC.predict(X_test)\npredict2 = DTC.predict(X_test)\npredict3 = NB.predict(X_test)\npredict4 = LR.predict(X_test)","67b203e6":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","d5cb188b":"print(classification_report(y_test,prediction))","1fbc77d0":"print(accuracy_score(y_test,predict1))\nprint('\\n')\nprint(accuracy_score(y_test,predict2))\nprint('\\n')\nprint(accuracy_score(y_test,predict3))\nprint('\\n')\nprint(accuracy_score(y_test,predict4))","bf9efe72":"test_df = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","960577e5":"test_df.head()","52c671bd":"test_df.drop(['keyword','location'],axis=1,inplace= True)","ebcb76fa":"test_df.head()","59033a3b":"test_vectorizer = vectorizer.transform(test_df['text'])","c635327b":"test_vectorizer.shape","7bf08531":"final_predictions = LR.predict(test_vectorizer)","01775dfe":"final_predictions","f09bbb2a":"submission_df = pd.DataFrame()","ccf6c465":"submission_df['id'] = test_df['id']\nsubmission_df['target'] = final_predictions","e0c26a39":"submission_df['target'].value_counts()","f7e51ec2":"Making Prediction","f23311db":"The columns - keyword and location will be dropped as they are of no use to us.","e670076e":"Lets predict for testing dataset","39404724":"Highest Accuracy Using Logisitic Regression.","6fe2dd87":"This matrix shows the count of unique words (as shown in previous cell output) in each sentance.","d232a09c":"# Bag Of Words [NLP METHOD]","e45d521a":"Data Visualisation","35b4887f":"Lets Predict!","0bf9c6f9":"**Checking the Performance**","8f965a29":"I feel this is the simplest method in NLP. It includes a basic concept that is creating the text into a vector form which includes the frequency of each word in the sentence - hence creating a vector which will be an independent feature for our model and the classification of text(1 or 0 as in this dataset) will be the dependent feature. Model can be trained using any algorithm (Decision Tree Classifier, Naive Bais). However this method is less efficient as it ignores the semantic part of the text. ","b8de293e":"So there are 7613 disaster tweets and 21637 unique words.","4cbd1fe5":"The accuracy is quite good!","95d8454e":"**Training the Model**","c9a25910":"We are going to vectorize the text along with increasing the readablity of the text by removing the punctuations and countwords!","64f5c040":"![image.png](attachment:image.png)","75f4a81a":"We have quite balanced data!"}}