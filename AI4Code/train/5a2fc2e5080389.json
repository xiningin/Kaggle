{"cell_type":{"0c3c72e4":"code","faff1777":"code","e109c24f":"code","66761ecb":"code","c9c6e263":"code","f14908a8":"code","289d74a0":"code","3c927342":"code","816ceeb7":"code","f241fa21":"code","d4c18c2e":"code","37dc7209":"code","016e8620":"code","90057165":"code","1bcd0ce3":"markdown","a20c7f60":"markdown","3a3c5ed8":"markdown","e651ff2b":"markdown","0de16969":"markdown","82ebf6ea":"markdown","e07391c3":"markdown","00887708":"markdown","84fc48fb":"markdown","90ee3806":"markdown","905adcc0":"markdown","bd1e59a2":"markdown","51499953":"markdown","2f895d82":"markdown","3a2ec2f5":"markdown","36ee7086":"markdown","32fdcc4c":"markdown","8102a339":"markdown","d5b2bf8e":"markdown"},"source":{"0c3c72e4":"import os\nimport numpy as np\nimport pandas as pd\nnp.random.seed(1) # set seed so as to make the results reproductibles\n\n# Graphs\nimport matplotlib.pyplot as plt\nget_ipython().magic('matplotlib inline')\n\n# ML\nfrom sklearn.model_selection import train_test_split\n\n# Tensorflow\nimport tensorflow as tf\nprint(tf.__version__)","faff1777":"train_path=\"..\/input\/digit-recognizer\/train.csv\"\ntest_path=\"..\/input\/digit-recognizer\/test.csv\"\ntrain = pd.read_csv(train_path)\ntest= pd.read_csv(test_path)\nprint(train.shape)\nprint(test.shape)\ntrain.head()","e109c24f":"# put labels into y_train variable\ny = train[\"label\"]\nx = train.drop(labels = [\"label\"],axis = 1,inplace=False)\n\nimport seaborn as sns\nplt.figure(figsize=(15,7))\ng = sns.countplot(y, palette=\"rocket\")\nplt.title(\"Number of images for each digit classes\")","66761ecb":"import random\n\nliste = [random.randint(0,42000) for i in range(25)]\n\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    img = x.iloc[liste[i]].values\n    img = img.reshape((28,28))\n    plt.imshow(-img,cmap='gray')\n    plt.title(y[liste[i]])\n    plt.grid(False)\n    plt.axis(False)\nplt.show()","c9c6e263":"print(\"Initial range is from {:.1f} to {:.1f}\".format(x.min().min(),x.max().max()))\n\n# Scaling to [0;1]\nx = x \/ x.max().max()\n\n# Result\nprint(\"Scaled image range is from {:.1f} to {:.1f}\".format(x.min().min(),x.max().max()))","f14908a8":"# Reshape\nx = x.values.reshape(-1,28,28,1)\nprint(\"x shape: \",x.shape)\n\n# convert to one-hot-encoding\nfrom keras.utils.np_utils import to_categorical\ny = to_categorical(y, num_classes = 10)\nprint(\"y shape: \",y.shape)\n\nprint(y[10])\nplt.imshow(-x[10][:,:,0],cmap='gray')\nplt.axis(False)\nplt.show()","289d74a0":"# Split the train and the validation set for the fitting\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(x, y, test_size = 0.2, random_state=1)\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_val shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_val shape\",Y_val.shape)","3c927342":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(rotation_range = 10,  \n                             zoom_range = 0.1, \n                             width_shift_range = 0.1, \n                             height_shift_range = 0.1,  \n                             horizontal_flip = False, \n                             vertical_flip = False)\ndatagen.fit(X_train)","816ceeb7":"from scipy import signal \n\n# 3x3 exemple image\nImage = [[0,0,0],\n         [0,1,1],\n         [0,1,2]]\n\n# Kernel. Remember that the kernel is always inverted\nkernel = [[-4,0,0],\n          [0,0,0],\n          [0,0,4]]\n\n# Result with scipy\nresult = signal.convolve(Image,kernel,'valid')\n\n# Result with manual multiplication\nresult2 = 4*0 + 0*0 + 0*0 + 0*0 + 0*1 + 0*1 + 0*1 + 0*0 + -4*2\n\nprint(\"Result with scipy: {} \\nResult with manual calculs : {}\".format(result,result2))\nprint(\"\\nWith 'same': \\n{}\".format(signal.convolve(Image,kernel,'same')))\nprint(\"\\nWith 'padding': \\n{}\".format(signal.convolve(Image,kernel,'full')))","f241fa21":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,BatchNormalization\nfrom keras.callbacks import LearningRateScheduler\n\n\ndef define_model(actifun=\"elu\",actifundense1=\"elu\",actifundense2=\"softsign\",optimizer=\"Adam\"):\n\n    model = model = Sequential([\n    Conv2D(32, (3, 3), padding = 'same', activation = 'relu', input_shape = (28,28,1)),\n    BatchNormalization(),\n    Conv2D(32, (3, 3), padding = 'same', activation = 'relu'),\n    BatchNormalization(),\n    MaxPool2D(2, 2),\n    Dropout(0.2),\n    Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n    BatchNormalization(),\n    Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n    BatchNormalization(),\n    MaxPool2D(2, 2),\n    Dropout(0.2),\n    Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n    BatchNormalization(),\n    Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n    BatchNormalization(),\n    MaxPool2D(2, 2),\n    Dropout(0.2),\n    Flatten(),\n    Dense(256, activation = 'relu'),\n    Dropout(0.25),\n    Dense(10, activation = 'softmax')\n    ])\n    \n    # Compilation of the model = loss function and algorithm to change weights\n    model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n    \n    return model\n\nmodel = define_model()\nmodel.summary()","d4c18c2e":"%%time\nfrom tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n\nX_train_train, X_train_val, Y_train_train, Y_train_val = train_test_split(X_train, Y_train, test_size = 0.3, random_state = 0)\n\nmodels={}\nhistory={}\n\n# Hyperparameters\noptim_list = [\"Adam\",\"RMSprop\"]\n\nlr_sched = ReduceLROnPlateau(monitor = 'val_acc', \n                                            patience = 10, \n                                            verbose = 1, \n                                            factor = 0.1, \n                                            min_lr = 0.00001)\n\nearly_stopping = EarlyStopping(monitor = 'val_acc',\n                               patience = 10,\n                               verbose = 1,\n                               mode = 'auto',\n                               restore_best_weights = True)\nepochs=50\nbatch_size = 200\n\nfor optim in optim_list:\n    for fun in [\"elu\",\"relu\"]:\n        fun1 = fun\n        fun2 = fun\n        print(\" \")\n        print(\" \")\n        mtype = optim + ' + ' + fun1 + ' + ' + fun2 + ' + ' + \"softsign\"\n        print(mtype)\n        print(\" \")\n\n        models[mtype] = define_model(fun1,fun2,\"softsign\",optim)\n\n        history[mtype] = models[mtype].fit(X_train,Y_train,\n                                           validation_split=0.2,epochs=epochs\n                                           ,shuffle=True,steps_per_epoch=X_train.shape[0] \/\/ batch_size,\n                                           callbacks=[lr_sched,early_stopping])","37dc7209":"rslts={}\nk=0\nfor optim in optim_list:\n    for fun in [\"elu\",\"relu\"]:\n        fun1 = fun\n        fun2 = fun\n        fun3 = \"softsign\"\n        mtype = optim + ' + ' + fun1 + ' + ' + fun2 + ' + ' + fun3\n        rslts[mtype] = (models[mtype].evaluate(X_val, Y_val, verbose = 0)[1])\n        k=k+1\n    \nfor item in sorted(rslts.items(), key=lambda x: x[1],reverse=True):\n    print(item[0])\n    print(item[1])\n    print(\" \")\n    \nplt.figure(figsize=(30,30))\ni=0\nfun =\"elu\"\nfun1 = fun\nfun2 = fun\nfun3 = \"softsign\"\nmtype = optim + ' + ' + fun1 + ' + ' + fun2 + ' + ' + fun3\nplt.subplot(2,1,i+1)\nplt.plot(history[mtype].history['loss'], label='loss')\nplt.plot(history[mtype].history['val_loss'], color='b', label='val_loss')\nplt.title(\"mtype\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend() \ni = i +1\nplt.show()","016e8620":"datagen.fit(x)\nX_train, X_val, Y_train, Y_val = train_test_split(x, y, test_size = 0.1, random_state = 0)\n\nlr_sched = ReduceLROnPlateau(monitor = 'val_acc', \n                                            patience = 10, \n                                            verbose = 1, \n                                            factor = 0.1, \n                                            min_lr = 0.00001)\n\nearly_stopping = EarlyStopping(monitor = 'val_acc',\n                               patience = 10,\n                               verbose = 1,\n                               mode = 'auto',\n                               restore_best_weights = True)\nepochs=50\nbatch_size = 200\n\nmodel = define_model(\"elu\",\"elu\",\"softsign\",\"RMSprop\")\n\nhistory_final = model.fit(datagen.flow(X_train,Y_train, batch_size = batch_size),\n                              epochs = epochs,\n                              steps_per_epoch = X_train.shape[0] \/\/ batch_size,\n                              validation_data = (X_val, Y_val), \n                              callbacks = [lr_sched, early_stopping])","90057165":"test_path=\"..\/input\/digit-recognizer\/test.csv\"\ntest = pd.read_csv(test_path)\ntest = test \/ 255.0 # Normalize the data\ntest = test.values.reshape(-1,28,28,1) # Reshape\n\nY_pred_test = model.predict(test)\nY_pred_classes_test = np.argmax(Y_pred_test,axis = 1)\n\nnp.savetxt('submission.csv', \n           np.c_[range(1,len(test)+1), Y_pred_classes_test], \n           delimiter=',', \n           header = 'ImageId,Label', \n           comments = '', \n           fmt='%d')","1bcd0ce3":"We submit in csv file :","a20c7f60":"## 4) Data augmentation","3a3c5ed8":"<a id=\"section-four\"><\/a>\n<h2 style='background:green; border:0; color:white' id=\"section-two\"><center> 4) Construction of the convolutionnal model <\/center><\/h2>\n\nIt is now time to construct our model.\n\nDeep learning models are made of different **convolutionnal**, **maxpooling** and **dense layers** :\n\n### 1) Convolutions *([Conv2D function](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/Conv2D))* \nConvultions are the first layers of a convolutionnal neural network. It consists of multiple **kernels** (also called **feature detectors** or **filters**) which are put on the image so as to obtain an array by matrix multiplication, called **feature map or convolved feature**. If multiple kernels are applied, the results consists of a new dimension called **strides**. We won't have to choose which kernels should be applied to the image, Keras will automatically test multiple kernels.\n\nExemple of a kernel applied to 9 pixels and resulting in one. Kernels are first inverted in order to avoid self dependence. Then we apply a matrix multiplication :\n<img style=height:300px src=\"https:\/\/docs-assets.developer.apple.com\/published\/09348c5368\/a55b1477-4f79-4221-8aa1-ab3ae9f01f89.png\">\n\n\nThere are 3 additional options :\n- If we apply the kernel only where all the values of the kernel are one a pixel : **valid**\n- If we apply the kernel on each pixels and we apply a padding (zeros) for values that are not on the image : **full**\n- If we apply the kernel on each pixel so as to obtain a result of a same-shape of the image : **same**","e651ff2b":"## 3) Split train, test and validation data\n\nWe need to split the data into train\/test and validation sets. Classical repartition is 80% train\/test and 20% validation. Inside train\/test set, another split is made, typically 80-20, to test model.\nModel is trained on model data and test on test data. To pick the best model we will make prediction on test data so as the model won't have been trained nor tested on those data. This will limit the 'overfitting' problem (be good on train data but bad to predict new data)","0de16969":"![](https:\/\/www.backprop.fr\/wp-content\/uploads\/2019\/05\/19Mjoc_J0JR294YwHGXwCeg-2.jpeg)","82ebf6ea":"Now, lets visualise the digits !\nWe pick 25 random digits and plot them :","e07391c3":"Hard to imagine digits behind those columns.\nIn fact, what we have to predict is the digit in the 'label' column, that we will store in `y`. The other columns are the values of each gray-scale pixel of the image that we will store in `x`.\n\nWe can visualise the proportion of each digit with __seaborn__, a data visualization library based on matplotlib (documentation [here](https:\/\/seaborn.pydata.org\/tutorial.html)) :","00887708":"<a id=\"section-three\"><\/a>\n<h2 style='background:green; border:0; color:white' id=\"section-two\"><center> 3) Data preparation <\/center><\/h2>\n\nWe have some preparation to make in order to put the data in a deep learning model :\n\n## 1) Scaling\n\nScaling, also known as **normalization**, means converting initial floating-point feature values into a standard range (eg  0 to 1 or -1 to +1). One scaling tactic is to calculate the Z score of each value (number of standard deviations away from the mean id *(value - mean)\/sd)*. Scaling with Z scores allow to **reduce** the variance if there are multiple features (not our case). Most scaled values will be between -3 and +3. All values should have the same order of size, but not necessary the exact same range (eg [0,1], [-3,3] is ok).\n\nIndeed, as deep learning is about wheigts multiplications, if values are not scaled one input could weight more in the learning process just because is value is much bigger.\n\nin the present case, images are gray scaled, that is to say 2 dimensional arrays with values from 0 to 255 :","84fc48fb":"We now test 3 optimizers and 4 activation functions of keras with 30 `epochs` (we run 30 times the whole dataset) and a `batch_size` of 200 (number of observations before ):","90ee3806":"[Tensorflow](https:\/\/www.tensorflow.org\/) is an open source library, developped by Google. It is one of the most used library for deep learning, along to Pytorch.\n\nFor this introduction, we are going to use one of the API of Tensorflow : **Keras**.","905adcc0":"1. [Libraries](#section-one)\n1. [Data exploration](#section-two)\n1. [Data preparation](#section-three)\n1. [Construction of the model](#section-four)\n1. [Submission](#section-five)","bd1e59a2":"Results : ","51499953":"<a id=\"section-two\"><\/a>\n<h2 style='background:green; border:0; color:white' id=\"section-two\"><center> 2) Data exploration <\/center><\/h2>\n\nFor this notebook, we are competing for the teaching competition **digit recognizer** that use the *MNIST dataset* (\"Modified National Institute of Standards and Technology\") with tens of thousands of handwritten images. The goal is to identify the digit in the images in the `test.csv` file.\n\nWe first load `test.csv`and `train.csv`. We display the shapes (n rows , n columns) of the two files and the ten first lines of the train dataset :","2f895d82":"![](https:\/\/www.gstatic.com\/devrel-devsite\/prod\/vfe8af62599ec445552c3fb43608c37ff46463c9fce3b14d8ee63b2e71edddffd\/tensorflow\/images\/lockup.svg)","3a2ec2f5":"## Summary of the model\n\nWe define the model as follow : a succesion of `convolutions`, followed each by `maxpooling`. The the result is `Flatten` to be incorporated to `dense` layers.\n\nWe start to build de model with `Sequential()`and then we had each functions.","36ee7086":"<a id=\"section-one\"><\/a>\n<h2 style='background:green; border:0; color:white'><center> 1) Libraries <\/center><\/h2>","32fdcc4c":"<a id=\"section-five\"><\/a>\n<h2 style='background:green; border:0; color:white'><center> 5) Final submission <\/center><\/h2>\n\nWe now train the best model on the entire augmented dataset :","8102a339":"## 2. Reshape and label-encoding\n\nTrain and test images are subosed to be 28 x 28 and not a list of 784 values (*see shape above*). We hence have to reshape datas to 28x28x1 3D matrices (Keras needs an extra dimension but since oure images are gray scaled it use only one channel).\n\nLabels are just a value from 0 to 9 that represents the digit. For learning process we have to encode the label to one hot vectors (one column for each possible result). For instance if the answer is 2, one hot encoder would be [0,0,1,0,0,0,0,0,0,0]**","d5b2bf8e":"## 2) Maxpooling *([MaxPool2D function](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/MaxPool2D))* \n\nMax Pooling select the higher value of a subset of size (h,H) and stride (s,S) so as to **sub-sampling** (reduces the number of parameters). It makes the detection of features invariant to scale or orientation changes and control overfitting.\n\n## 3) Batch normalisation *([Batch_normalisation](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/Batch_normalisation))*\n\nThe Batch normalisation layer will transform inputs so that they are standardized, meaning that they will have a mean of zero and a standard deviation of one. This will accelerating and in some cases improve the training process. \n\n## 4) Dropout *([Dropout function](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/Dropout))*\n\nThe Dropout layer randomly inactivate neurons at each step during training time, which helps prevent overfitting. \n\n## 5) Flattenning *([Flatten function](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/Flatten))*\n\nMakes an any-dimensional array a 1D list so as to be taken into input in dense layers\n\n\n## 6) Dense \/ fully connected layers *([Dense function](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/Dense))*\n\nFully connected neurons layer\n\n\n## Activation functions\n\nActivation functions take the output of a neuron and transform it through a function. No activation function is equivalent to **linear function** (y = ax). \n\n\n### Classical activation functions\n\n<img style='height:100px;float:right' src='https:\/\/i2.wp.com\/deeplylearning.fr\/wp-content\/uploads\/2018\/09\/logistic-sigmoid.png?resize=180%2C90&ssl=1'>\n\n* **sigmoid** = 1 \/ (1 + exp(-x)). Not efficient for deep layers but can be used as an output layer for binary classification. Output interval : [0;1]\n* **tanh** : Hyperbolic tangent activation function. Output interval : [-1;1]\n* **softsign**: Softsign activation function, softsign(x) = x \/ (abs(x) + 1). Output interval : [-1;1]\n* **hard_sigmoid**: Hard sigmoid activation function.\n<img style='height:200px;float:right' src='https:\/\/s1.qwant.com\/thumbr\/0x0\/0\/1\/4f8a9b5ac5beb26f33fbcdadf27686b156174f088576c6af994954327d7b8d\/OQzvKvA.png?u=http%3A%2F%2Fi.imgur.com%2FOQzvKvA.png&q=0&b=1&p=0&a=1'>\n<img style='height:200px' src='https:\/\/i0.wp.com\/sefiks.com\/wp-content\/uploads\/2017\/11\/softsign.png?resize=371%2C264&ssl=1'>\n\n\n\n* **softmax** : Softmax converts a real vector to a vector of categorical probabilities.\n* **exponential** : Exponential activation function.\n* **relu** : Applies the rectified linear unit activation function. They allow a faster training compared to the sigmoid and tanh functions, being lighter. Beware of the phenomenon of 'Dying ReLU' (see below)\n<img style='height:200px' src='https:\/\/i0.wp.com\/deeplylearning.fr\/wp-content\/uploads\/2018\/09\/rectified-linear-unit.png?resize=180%2C90&ssl=1'>\n\n\n### ReLu modified functions\nThe ReLu modified functions are used so as to avoid dying neuron problems. A new function with an alpha parameter is implemented for the negative part of the trace.\n\n* **Leaky ReLU** : use the alpha parameter for the negative part. alpha can be a parameter of the model and not as an hyperparameter in the **PReLU (Parametric ReLU)**. PreLu needs large dataset.\n<img style='height:100px' src='https:\/\/i2.wp.com\/deeplylearning.fr\/wp-content\/uploads\/2018\/09\/leaky-ReLU.jpg?resize=300%2C213&ssl=1'>\n* **TReLU (Thresholded ReLU)** : same as Relu but the threeshold is changed with a theta parameter.\n* **elu** (Exponential Linear Unit) : exponential is used for negative units. \n* **selu** (Scaled Exponential Linear Unit) same as ELU but with a new *alpha* parameter\n* **softplus** : Softplus activation function, softplus(x) = log(exp(x) + 1). Has a non-zero derivative over the entire trace.\n<img style='height:100px' src='https:\/\/s1.qwant.com\/thumbr\/0x380\/1\/5\/d14a8a827ad6b40449d9c3edb216fbe79986c46bc8a843d1caa1e719b7e1ee\/1200px-Rectifier_and_softplus_functions.svg.png?u=https%3A%2F%2Fupload.wikimedia.org%2Fwikipedia%2Fcommons%2Fthumb%2F6%2F6c%2FRectifier_and_softplus_functions.svg%2F1200px-Rectifier_and_softplus_functions.svg.png&q=0&b=1&p=0&a=1'>\n\n* **swish** : Swish activation function, swish(x) = x * sigmoid(x).\n\n<img style='height:200px' src='https:\/\/s2.qwant.com\/thumbr\/700x0\/7\/1\/eea6e870c4dbc2b87aac4c2f6ae5cfd8b81283647453157cecf501bdf2942d\/Subplot-a-shows-6-different-activation-functions-where-their-main-differences-sit-in.png?u=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FGuoqiang_Zhang22%2Fpublication%2F326646583%2Ffigure%2Fdownload%2Ffig1%2FAS%3A652848589197321%401532662641462%2FSubplot-a-shows-6-different-activation-functions-where-their-main-differences-sit-in.png&q=0&b=1&p=0&a=1'>"}}