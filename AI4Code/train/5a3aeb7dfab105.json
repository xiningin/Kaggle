{"cell_type":{"b315036c":"code","b495870d":"code","db07cc6f":"code","84d045d6":"code","98e90197":"code","418e40ae":"code","14a719e9":"code","1a7b0ca7":"code","6c7b44b9":"code","b7b10dd4":"code","c0a19659":"code","4fc8727b":"code","6a2c57bf":"code","493db92c":"code","68227e35":"code","c3552061":"code","efb7a03a":"code","b40dea81":"code","5c848837":"code","4c5c7683":"code","570950ab":"code","c06ffd81":"code","c564241e":"code","7a71a315":"code","6f4da3a4":"code","54b48a8f":"code","f5bfc73d":"code","253d9ab2":"code","50f055dd":"code","7b8f0570":"code","d2274d66":"code","dd568538":"code","0f44aef0":"code","6c490477":"code","5ad72040":"code","b627704c":"code","303464ba":"code","08dc0119":"code","edd83d42":"code","f755d17f":"code","6fb0ca0a":"code","fcaacb68":"code","ec2cd7bc":"code","a997b3b5":"code","456bdc73":"code","e2b19def":"code","7133bdec":"code","fe675a38":"code","1c09b120":"code","f70e70ee":"code","c1840296":"code","2f85fa5c":"code","387c6ff4":"code","da2fa313":"code","5f27ceaa":"code","0d3933be":"code","13fee1b2":"code","7f69c465":"code","e8e22198":"code","e38762c5":"code","8b97c8a5":"code","08f1a3d6":"code","df9d3c3b":"markdown","aec3de43":"markdown","a937b3d3":"markdown"},"source":{"b315036c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b495870d":"import pandas as pd\n\n#def load_data(path, filename, codec='utf-8'):\n  #csv_path = os.path.join(path, filename)\n  #print(csv_path)\n  #return pd.read_csv(csv_path, encoding=codec)\n","db07cc6f":"\npath=('..\/input\/train.csv')","84d045d6":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.preprocessing import Imputer,LabelEncoder\nfrom scipy.stats import norm, skew\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","98e90197":"#reading of train data\ndf= pd.read_csv(path)\n","418e40ae":"#checking the contents of table\ndf.head()\n","14a719e9":"df.columns","1a7b0ca7":"fig = plt.figure(2)\nax1 = fig.add_subplot(2, 2, 1)\nax2=fig.add_subplot(2,2,2)\nax3=fig.add_subplot(2,2,3)\nax4=fig.add_subplot(2,2,4)\ndf.plot.scatter(x='LotFrontage',y='SalePrice',ax=ax1)\ndf.plot.scatter(x='LotArea',y='SalePrice',ax=ax2)\ndf.plot.scatter(x='MSSubClass',y='SalePrice',ax=ax3)\ndf.plot.scatter(x='OverallQual',y='SalePrice',ax=ax4)\nplt.show()","6c7b44b9":"#Cheking for nulls in target\ndf['SalePrice'].isnull().sum()","b7b10dd4":"#assigning target to y\ny=df['SalePrice']","c0a19659":"sns.set()\ncols=list(df.columns)\nsns.pairplot(df[cols],size=2.5)\nplt.show()","4fc8727b":"#dropping target from rest of features\nX=df.drop('SalePrice',axis=1)","6a2c57bf":"#checking  correlation between the independent features\nsns.heatmap(df.corr())","493db92c":"#selecting continous features\nX_con=X.select_dtypes(exclude='object')\n#X_test_con=df_test.select_dtypes(exclude='object')","68227e35":"X_con_col=list(X_con.columns)","c3552061":"#outlier detection and replacing them with mean\ndef outlier_detect(df):\n    for i in df.describe().columns:\n        Q1=df.describe().at['25%',i]\n        Q3=df.describe().at['75%',i]\n        IQR=Q3 - Q1\n        LTV=Q1 - 1.5 * IQR\n        UTV=Q3 + 1.5 * IQR\n        x=np.array(df[i])\n        p=[]\n        for j in x:\n            if j < LTV or j>UTV:\n                p.append(df[i].median())\n            else:\n                p.append(j)\n        df[i]=p\n    return df","efb7a03a":"#calling outlier dectectfunction\nX_con=outlier_detect(X_con)","b40dea81":"#selecting categorical data\nX_cat=X.select_dtypes(include='object')","5c848837":"X_cat_col=list(X_cat.columns)","4c5c7683":"#checking for nulls in categorical features\nX_cat.isnull().sum()","570950ab":"#checking for nulls in continous data\nX_con.isnull().sum()","c06ffd81":"#dropping the features which have maximum values missing\nX_cat.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)\n","c564241e":"X_cat.drop('Alley',1,inplace=True)","7a71a315":"#again checking for null values----data with no missing values\nX_cat.isnull().sum()","6f4da3a4":"#filling missing value of categorical data  with mode\nfor col in X_cat.columns:\n       \n    X_cat[col]=X_cat[col].fillna(X_cat[col].mode()[0])","54b48a8f":"for cols in X_cat.columns:\n    sns.set(style=\"whitegrid\")\n    ax = sns.barplot(x=cols, y=\"SalePrice\", data=df)\n    plt.show()","f5bfc73d":"#again checking for nulls\nX_cat.isnull().sum()","253d9ab2":"#checking nulls in continous features\nX_con.isnull().sum()","50f055dd":"#replacing NaN with 0 for continous features\nfor col in X_con.columns:\n       \n    X_con[col]=X_con[col].replace(to_replace=np.nan,value=0)","7b8f0570":"\nfor cols in X_con.columns:\n    sns.set()\n    sns.distplot(X_con[cols])\n    plt.show()","d2274d66":"#checking for skewness of data and replacing it by sqrt if skewness>1\nfor feature in X_con.columns:\n    if (X_con[feature].skew())>1.0:\n        X_con[feature]=np.sqrt(X_con[feature])","dd568538":"X_con.head()","0f44aef0":"from sklearn import preprocessing","6c490477":"#converting the categorical values into continous values with the hep of label encoding\nle = preprocessing.LabelEncoder()","5ad72040":"for feat in X_cat:\n    le.fit(X_cat[feat])\n    X_cat[feat]=le.transform(X_cat[feat])","b627704c":"#merging continous and categorical features\nXX=pd.concat([X_con,X_cat],1)","303464ba":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","08dc0119":"#splitting of data\nX_train,X_test,y_train,y_test=train_test_split(XX,y,test_size=.2,random_state=0)","edd83d42":"#creating object of linear model\nlinear=LinearRegression()","f755d17f":"#fitting model on X_train and y_train\nlinear.fit(X_train,y_train)","6fb0ca0a":"#predicting the value of X_test\ny_pred=linear.predict(X_test)","fcaacb68":"from sklearn.metrics import r2_score","ec2cd7bc":"lin_score=r2_score(y_test,y_pred)","a997b3b5":"lin_score","456bdc73":"###applying regularization--Lasso\nfrom sklearn import linear_model\nlasso = linear_model.Lasso(alpha=0.1)","e2b19def":"# Ride---\nridge=linear_model.Ridge(alpha=0.1)","7133bdec":"lasso.fit(X_train,y_train)","fe675a38":"y_lasso=lasso.predict(X_test)","1c09b120":"r2_score(y_test,y_lasso)","f70e70ee":"ridge.fit(X_train,y_train)\ny_ridge=lasso.predict(X_test)\nr2_score(y_test,y_ridge)\n","c1840296":"#apply feature selection\nfrom sklearn.model_selection import cross_validate","2f85fa5c":"from sklearn.feature_selection import chi2\n\nfrom sklearn.feature_selection import SelectKBest","387c6ff4":"feat_sel = SelectKBest(score_func=chi2, k=60)\nX_train=feat_sel.fit_transform(X_train,y_train)\nX_test=feat_sel.transform(X_test)\nmodel=LinearRegression()\nmodel.fit(X_train,y_train)\nchi2_score=model.score(X_test,y_test)\nprint(chi2_score)","da2fa313":"from sklearn.tree import DecisionTreeRegressor\nclf = DecisionTreeRegressor(random_state=0)","5f27ceaa":"clf.fit(X_train,y_train)","0d3933be":"clf.score(X_test,y_test)","13fee1b2":"from sklearn.ensemble import RandomForestRegressor\n\n# Code starts here\nrf_reg=RandomForestRegressor(random_state=9)\nrf_reg.fit(X_train,y_train)\n\nscore_rf=rf_reg.score(X_test,y_test)\nprint(score_rf)","7f69c465":"from sklearn.model_selection import GridSearchCV","e8e22198":"parameter_grid={'n_estimators': [20,40,60,80],'max_depth': [8,10],'min_samples_split': [8,10]}","e38762c5":"rf_reg=RandomForestRegressor(random_state=9)\nrf_reg.fit(X_train,y_train)\ngrid_search=GridSearchCV(estimator=rf_reg,param_grid=parameter_grid)","8b97c8a5":"grid_search.fit(X_train,y_train)\nscore_gs=grid_search.score(X_test,y_test)\nprint(score_gs)","08f1a3d6":"#score_gs","df9d3c3b":"### regularization does'nt increase the accuracy...","aec3de43":"HyperTuning","a937b3d3":"By applying decision tree accuracy is decreased...try random forest"}}