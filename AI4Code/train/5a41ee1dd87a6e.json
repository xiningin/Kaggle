{"cell_type":{"0da6cb6f":"code","d7d29ce4":"code","4da8cec3":"code","e1750526":"code","7be7e8f8":"code","edfaab89":"code","5037098b":"code","db42cbae":"code","f2cea5cd":"code","8df34331":"code","6c07a276":"code","6f01bdff":"code","097e8220":"code","9a5ebdc7":"code","6c0fbb39":"code","cc2d5db3":"code","824482ec":"code","8d4b817e":"code","04ee6f6c":"code","48535edf":"code","7a57a21d":"code","4290321f":"code","fd7fdc22":"code","28bfef65":"code","49461f65":"markdown","3d8a595d":"markdown"},"source":{"0da6cb6f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7d29ce4":"os.chdir(\"..\/input\")\nos.listdir()","4da8cec3":"df=pd.read_csv(\"..\/input\/eeg-clean\/eeg_clean.csv\")\n","e1750526":"from warnings import filterwarnings\nfilterwarnings('ignore')","7be7e8f8":"df.head()","edfaab89":"df.info()","5037098b":"df.isnull().sum()","db42cbae":"print(df[\"eye\"].value_counts())","f2cea5cd":"df.eye=[1 if each ==\"Open\" else 0 for each in df.eye]","8df34331":"df.info()","6c07a276":"y = df[\"eye\"].values\nX = df.drop(['eye'], axis=1).values","6f01bdff":"# Data Standardization \nfrom sklearn.preprocessing import StandardScaler\nScaler=StandardScaler()\nX=Scaler.fit_transform(X)\n\nX[0:3]","097e8220":"from sklearn.model_selection import train_test_split\n# shuffle and split training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n                                                    random_state=0)\n# Multi Layer Perceptron Artificial Neural Network\nfrom sklearn.neural_network import MLPClassifier \n\n# Setting up a primitive (non-validated) model\nmlpc = MLPClassifier(random_state = 0)# ANN model object created\n\nmlpc.fit(X_train, y_train) # ANN model object fit","9a5ebdc7":"# Forecasting on the Unvalidated Model\ny_pred = mlpc.predict(X_test) # model prediction process over test set","6c0fbb39":"import sklearn.metrics as metrics\n\n# Accuracy\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n\n# f1 score\n\nprint(\"f1_weighted:\",metrics.f1_score(y_test, y_pred,average='weighted'))","cc2d5db3":"# Cross Validation Process\n# Parameters for CV created in dictionary structure\n# INFORMATION ABOUT THE INPUTED PARAMETERS\n# alpha: float, default = 0.0001 L2 penalty (regularization term) parameter. (penalty parameter)\n   \nmlpc_params = {\"alpha\": [0.1, 0.01, 0.001],\n              \"hidden_layer_sizes\": [(100,100),\n                                     (100,100,100)],\n              \"solver\" : [\"adam\",\"sgd\"],\n              \"activation\": [\"relu\",\"logistic\"]}\n\nfrom sklearn.model_selection import GridSearchCV\n\n\n\n\nmlpc = MLPClassifier(random_state = 0) # ANN model object created\n\n# Model CV process \nmlpc_cv_model = GridSearchCV(mlpc, mlpc_params, \n                         cv = 5, # To make a 5-fold CV\n                         n_jobs = -1, # Number of jobs to be run in parallel (-1: means to use all processors)\n                         verbose = 2) # Controls the level of detail: higher means more messages gets value as integer.\n\nmlpc_cv_model.fit(X_train, y_train) \n\n\n# The best parameter obtained as a result of CV process\n\nprint(\"The best parameters: \" + str(mlpc_cv_model.best_params_))","824482ec":"# Setting the Final Model with the best parameter\n\nmlpc_tuned = mlpc_cv_model.best_estimator_\n\n# Fitting Final Model\nmlpc_tuned.fit(X_train, y_train)","8d4b817e":"# K-fold f1_weighted\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# K fold\nkf = KFold(shuffle=True, n_splits=5) # To make a 5-fold CV\n\ncv_results_kfold = cross_val_score(mlpc_tuned, X_test, y_test, cv=kf, scoring= 'f1_weighted')\n\nprint(\"K-fold Cross Validation f1_weigted Results: \",cv_results_kfold)\nprint(\"K-fold Cross Validation f1_weigted Results Mean: \",cv_results_kfold.mean())","04ee6f6c":"# K-fold accuracy\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# K fold\nkf = KFold(shuffle=True, n_splits=5) # To make a 5-fold CV\n\ncv_results_kfold = cross_val_score(mlpc_tuned, X_test,y_test, cv=kf, scoring= 'accuracy')\n\nprint(\"K-fold Cross Validation accuracy Results: \",cv_results_kfold)\nprint(\"K-fold Cross Validation accuracy Results Mean: \",cv_results_kfold.mean())","48535edf":"# Tune Model Prediction\n# Prediction process of Final Model over test set\ny_pred = mlpc_tuned.predict(X_test)","7a57a21d":"# Accuracy and f1_weighted value of Final Model\n\n# %% f1 score\nimport sklearn.metrics as metrics\nprint(\"f1_weighted:\",metrics.f1_score(y_test, y_pred,average='weighted'))\n\n# %% Accuracy\n\nprint(\"accuracy:\",metrics.accuracy_score(y_test, y_pred))","4290321f":"#%% Confusion Matrix and Classification Report\nfrom sklearn.metrics import confusion_matrix, classification_report \n\n# Classification Report\nmodel_report = classification_report(y_test, y_pred)\nprint(model_report)","fd7fdc22":"# Confusion Matrix\n# multilabel-indicator is not supported so np.argmax should be used!\nmodel_conf = confusion_matrix(y_test,y_pred)\nprint(model_conf)","28bfef65":"#%% ROC-AUC Curve\nimport matplotlib.pyplot as plt\n\n\n\nprobs=mlpc_tuned.predict_proba(X_test)\nfpr,tpr,threshold=metrics.roc_curve(y_test,y_pred)\nroc_auc=metrics.auc(fpr,tpr)\n\n\n\n\nplt.title(\"ROC\")\nplt.plot(fpr,tpr,label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy',  linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","49461f65":"## Data Read","3d8a595d":"## Grid Search Cross Validation"}}