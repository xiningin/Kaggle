{"cell_type":{"2502aaaf":"code","6f6efabd":"code","a2e80aa8":"code","b1a5edf5":"code","52c3418b":"code","18728f7e":"code","483adad7":"code","6fb86e59":"code","aee77c97":"code","65c444f0":"code","d41a7532":"code","b89dfee3":"code","cb894a9f":"code","14c5447e":"code","be428622":"code","0ccf6f58":"code","00d85829":"code","7b83d1b5":"markdown","93af8fb7":"markdown","e5af8532":"markdown","58581d27":"markdown"},"source":{"2502aaaf":"!rm -r \/opt\/conda\/lib\/python3.6\/site-packages\/lightgbm<br>\n!git clone --recursive https:\/\/github.com\/Microsoft\/LightGBM","6f6efabd":"!apt-get install -y -qq libboost-all-dev","a2e80aa8":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=\/usr\/local\/cuda\/lib64\/libOpenCL.so -DOpenCL_INCLUDE_DIR=\/usr\/local\/cuda\/include\/ ..\nmake -j$(nproc)","b1a5edf5":"!cd LightGBM\/python-package\/;python3 setup.py install --precompile","52c3418b":"!mkdir -p \/etc\/OpenCL\/vendors && echo \"libnvidia-opencl.so.1\" > \/etc\/OpenCL\/vendors\/nvidia.icd\n!rm -r LightGBM","18728f7e":"# Data manipulation and set-up\nimport numpy as np\nimport pandas as pd\n\n# Statistics\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom statistics import mode\nfrom scipy.special import boxcox1p\n\n# Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font_scale=1)\n\n# Modelling (including set-up & evaluation)\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\n\n# Ignore warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore')","483adad7":"# Setting random seed\nrandom_state = 42\nnp.random.seed(random_state)\n\n# Import data\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","6fb86e59":"# Feature engineering\n# Saving train & test shapes\n# ntrain = train.shape[0]\n# ntest = test.shape[0]\n\n# New all encompassing dataset\n# all_data = pd.concat((train, test)).reset_index(drop=True)\n\n# Transform target to object\n# all_data['target'] = all_data['target'].astype('object')\n\n# Extracting continuous features\n# numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# Check for skewness\n# skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n# skewness = pd.DataFrame({'Skew' :skewed_feats})\n# skewness.head(5)","aee77c97":"# Now let's apply the box-cox transformation to correct for skewness\n# skewed_features = skewness.index\n# lam = 0.3\n# for feature in skewed_features:\n#     all_data[feature] = boxcox1p(all_data[feature], lam)","65c444f0":"# Check\n# numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n# skewness = pd.DataFrame({'Skew' :skewed_feats})\n# skewness.head(5)","d41a7532":"# Target back to float\n# all_data['target'] = all_data['target'].astype('float64')\n\n# Now to return to separate train\/test sets for Machine Learning\n# train = all_data[:ntrain]\n# test = all_data[ntrain:]","b89dfee3":"# Data augmentation\ndef disarrange(a, axis=-1):\n    \"\"\"\n    Shuffle `a` in-place along the given axis.\n\n    Apply numpy.random.shuffle to the given axis of `a`.\n    Each one-dimensional slice is shuffled independently.\n    \"\"\"\n    b = a.swapaxes(axis, -1)\n    # Shuffle `b` in-place along the last axis.  `b` is a view of `a`,\n    # so `a` is shuffled in place, too.\n    shp = b.shape[:-1]\n    for ndx in np.ndindex(shp):\n        np.random.shuffle(b[ndx])\n    return\n\ndef augment(x,y,t=2):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        disarrange(x1,axis=0)\n        xs.append(x1)\n\n    for i in range(t\/\/2):\n        mask = y==0\n        x1 = x[mask].copy()\n        disarrange(x1,axis=0)\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y","cb894a9f":"# Model parameters\nlgb_params = {\n    \"objective\" : \"binary\",\n    \"metric\" : \"auc\",\n    \"boosting\": 'gbdt',\n    \"max_depth\" : -1,\n    \"num_leaves\" : 13,\n    \"learning_rate\" : 0.01,\n    \"bagging_freq\": 5,\n    \"bagging_fraction\" : 0.4,\n    \"feature_fraction\" : 0.05,\n    \"min_data_in_leaf\": 80,\n    \"min_sum_hessian_in_leaf\": 10,\n    \"tree_learner\": \"serial\",\n    \"boost_from_average\": \"false\",\n    \"bagging_seed\" : random_state,\n    \"verbosity\" : 1,\n    \"seed\": random_state,\n    'device': 'gpu',\n    'gpu_platform_id': 0,\n    'gpu_device_id': 0}","14c5447e":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\noof = train[['ID_code', 'target']]\noof['predict'] = 0\npredictions = test[['ID_code']]\nval_aucs = []\nfeature_importance = pd.DataFrame()","be428622":"features = [col for col in train.columns if col not in ['target', 'ID_code']]\nX_test = test[features].values","0ccf6f58":"for fold, (trn_idx, val_idx) in enumerate(skf.split(train, train['target'])):\n    X_train, y_train = train.iloc[trn_idx][features], train.iloc[trn_idx]['target']\n    X_valid, y_valid = train.iloc[val_idx][features], train.iloc[val_idx]['target']\n    \n    N = 5\n    p_valid,yp = 0,0\n    for i in range(N):\n        X_t, y_t = augment(X_train.values, y_train.values)\n        X_t = pd.DataFrame(X_t)\n        X_t = X_t.add_prefix('var_')\n    \n        trn_data = lgb.Dataset(X_t, label=y_t)\n        val_data = lgb.Dataset(X_valid, label=y_valid)\n        evals_result = {}\n        lgb_clf = lgb.train(lgb_params,\n                        trn_data,\n                        100000,\n                        valid_sets = [trn_data, val_data],\n                        early_stopping_rounds=3000,\n                        verbose_eval = 1000,\n                        evals_result=evals_result\n                       )\n        p_valid += lgb_clf.predict(X_valid)\n        yp += lgb_clf.predict(X_test)\n    fold_importance = pd.DataFrame()\n    fold_importance[\"feature\"] = features\n    fold_importance[\"importance\"] = lgb_clf.feature_importance()\n    fold_importance[\"fold\"] = fold + 1\n    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n    oof['predict'][val_idx] = p_valid\/N\n    val_score = roc_auc_score(y_valid, p_valid)\n    val_aucs.append(val_score)\n    \n    predictions['fold{}'.format(fold+1)] = yp\/N","00d85829":"# Submission\npredictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\npredictions.to_csv('lgb_all_predictions.csv', index=None)\nsub = pd.DataFrame({\"ID_code\":test[\"ID_code\"].values})\nsub[\"target\"] = predictions['target']\nsub.to_csv(\"lgb_submission.csv\", index=False)\noof.to_csv('lgb_oof.csv', index=False)","7b83d1b5":"This kernel is a work in progress, taking inspiration from:<br>\n<b>LightGBM with GPU support:<\/b> https:\/\/www.kaggle.com\/vinhnguyen\/gpu-acceleration-for-lightgbm<br>\n<b>Data Augmentation:<\/b> https:\/\/www.kaggle.com\/jiweiliu\/fast-inplace-shuffle-for-augmentation","93af8fb7":"## Re-compile LGBM with GPU support","e5af8532":"# Santander Customer Transaction Prediction","58581d27":"## Onto the challenge"}}