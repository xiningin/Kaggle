{"cell_type":{"0748d4a6":"code","7e9ed1a6":"code","38ca1d7f":"code","30bcb8f1":"code","3e3f5fae":"code","0a3e1388":"code","2a824ba5":"code","c674ef7f":"code","8bf7bd72":"code","d0b9d15f":"code","16efda9e":"code","3cdf43c1":"code","846070a5":"code","444562c8":"code","d9166053":"code","86d561f5":"code","2e40d2f0":"code","af55e4f7":"code","ad03e8af":"code","cf460518":"code","7b9fe343":"code","ce663276":"code","784aafd1":"code","efc29e11":"code","bcd85656":"code","38b85bfd":"code","15206a5d":"code","380a9c98":"code","98eab0af":"code","51ff642c":"code","f987ed8d":"code","42dcb187":"code","132dc415":"markdown","54272c26":"markdown","25d74a81":"markdown","cb8e9166":"markdown","ce24e39d":"markdown","a14d68f5":"markdown","146941f5":"markdown","5f3478cf":"markdown","ba2d516d":"markdown","943ffe7e":"markdown","98928078":"markdown","72dd48bf":"markdown","ba0d6e7e":"markdown","fdc93290":"markdown","9638c023":"markdown","6c203996":"markdown","07815c81":"markdown","080fe958":"markdown","4db45588":"markdown","c1b9e42f":"markdown","9ced8a22":"markdown","2ba81d97":"markdown","be160c3e":"markdown","55e7e5d1":"markdown","7522abc7":"markdown","f6ec27da":"markdown","64514ee3":"markdown","045aed82":"markdown","44416f9f":"markdown","0fe15453":"markdown","0d4e5ac5":"markdown","e3654c44":"markdown","27507477":"markdown","d8837170":"markdown"},"source":{"0748d4a6":"#Importing necessary Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns","7e9ed1a6":"#Reading the dataset\ndata=pd.read_csv('..\/input\/imdb-5000-movie-dataset\/movie_metadata.csv')\ndata.head()","38ca1d7f":"#Categorising the target varible \nbins = [ 1, 3, 6, 10]\nlabels = ['FLOP', 'AVG', 'HIT']\ndata['imdb_binned'] = pd.cut(data['imdb_score'], bins=bins, labels=labels)","30bcb8f1":"data.groupby(['imdb_binned']).size().plot(kind=\"bar\",fontsize=14)\nplt.xlabel('Categories')\nplt.ylabel('Number of Movies')\nplt.title('Categorization of Movies')","3e3f5fae":"#Checking the new column\ndata.head(5)","0a3e1388":"#Shape of the dataset\ndata.shape","2a824ba5":"#Total null values present in each column\ndata.isnull().sum()","c674ef7f":"#Droping the samples that have missing values\ndata.dropna(inplace=True)","8bf7bd72":"#Final shape of the data after Droping missing values\ndata.shape","d0b9d15f":"#List of variables in the datset\ndata.columns","16efda9e":"data.shape","3cdf43c1":"#Describing the categorical data\ndata.describe(include='object')","846070a5":"#Dropping 2 columns\ndata.drop(columns=['movie_title','movie_imdb_link'],inplace=True)","444562c8":"#Label encoding the categorical columns\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncat_list=['color', 'director_name', 'actor_2_name',\n        'genres', 'actor_1_name',\n        'actor_3_name',\n        'plot_keywords',\n        'language', 'country', 'content_rating',\n       'title_year', 'aspect_ratio']\ndata[cat_list]=data[cat_list].apply(lambda x:le.fit_transform(x))","d9166053":"#A sample of data after label encoding\ndata.head()","86d561f5":"#Finding Correlation between variables\ncorr = data.corr()\nmask = np.zeros(corr.shape, dtype=bool)\nmask[np.triu_indices(len(mask))] = True\nplt.subplots(figsize=(20,15))\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns,cmap='RdYlGn',annot=True,mask = mask)","2e40d2f0":"#Removing few columns due to multicollinearity\ndata.drop(columns=['cast_total_facebook_likes','num_critic_for_reviews'],inplace=True)","af55e4f7":"#Removing the column \"imdb_score\" since we have \"imdb_binned\"\ndata.drop(columns=['imdb_score'],inplace=True)","ad03e8af":"data.shape","cf460518":"#Independent Variables\nX = data.iloc[:, 0:23].values\n#Dependent\/Target Variable\ny = data.iloc[:, 23].values\ny","7b9fe343":"#Spliting the data into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0,stratify = y)\nprint(X_train.shape)\nprint(y_train.shape)","ce663276":"#Scaling the dependent variables\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","784aafd1":"#Performing Recursive Feauture Elimation with Cross Validation\n#Using Random forest for RFE-CV and logloss as scoring\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss\nclf_rf=RandomForestClassifier(random_state=0)\nrfecv=RFECV(estimator=clf_rf, step=1,cv=5,scoring='neg_log_loss')\nrfecv=rfecv.fit(X_train,y_train)","efc29e11":"#Optimal number of features\nX_train = pd.DataFrame(X_train)\nX_test = pd.DataFrame(X_test)\nprint('Optimal number of features :', rfecv.n_features_)\nprint('Best features :', X_train.columns[rfecv.support_])","bcd85656":"#Feauture Ranking\nclf_rf = clf_rf.fit(X_train,y_train)\nimportances = clf_rf.feature_importances_\n\nstd = np.std([tree.feature_importances_ for tree in clf_rf.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n","38b85bfd":"#Logloss vs Number of features\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score of number of selected features\")\nplt.title(\"Log loss vs Number of fetures\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","15206a5d":"#Selecting the Important Features\nX_opt = X_train.iloc[:,X_train.columns[rfecv.support_]]\nX_test = X_test.iloc[:,X_test.columns[rfecv.support_]]","380a9c98":"#Creating anew dataframe with column names and feature importance\ndset = pd.DataFrame()\ndata1 = data\ndata1.drop(columns=['imdb_binned'],inplace=True)\ndset['attr'] = data1.columns\n\ndset['importance'] = clf_rf.feature_importances_\n#Sorting with importance column\ndset = dset.sort_values(by='importance', ascending=True)\n\n#Barplot indicating Feature Importance\nplt.figure(figsize=(16, 14))\nplt.barh(y=dset['attr'], width=dset['importance'], color='#1976D2')\nplt.title('RFECV - Feature Importances', fontsize=20, fontweight='bold', pad=20)\nplt.xlabel('Importance', fontsize=14, labelpad=20)\nplt.show()","98eab0af":"#Training the Random Forest Classifer on Train data\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_opt, y_train)\n","51ff642c":"#Predicting the target variable\ny_pred = classifier.predict(X_test)","f987ed8d":"#Confusion Matrix\nfrom sklearn.metrics import confusion_matrix \ncm = confusion_matrix(y_test,y_pred)\ncm","42dcb187":"#Classification Report\nfrom sklearn.metrics import classification_report\ncr = classification_report(y_test,y_pred)\nprint(cr)","132dc415":"## 1.2 Describing Data\n\nThe dataset contains 28 variables for 5043 movies, spanning across 100 years in 66 countries. There are 2399 unique director names, and thousands of actors\/actresses. \u201cimdb_score\u201d is the response variable while the other 27 variables are possible predictors.","54272c26":"Removing the column \"imdb_score\" since we have \"imdb_binned\n\nI am gonna train the model with imdb_binned not with imdb_score so dropping the column.\n","25d74a81":"# 3 CLASSIFICATION MODEL BUILDING","cb8e9166":"# 2 DATA EXPLORATION","ce24e39d":"Lets find out how the string variables are behaving","a14d68f5":"## 2.4 Label Encoding\n\nAll the categorical columns and the columns with text data are being Label Encodeded in this step.","146941f5":"Finding optimal features to use for Machine learning model training can sometimes be a difficult task to accomplish.There are just so many methods to choose from and here I am going with RFECV.","5f3478cf":"'movie_title','movie_imdb_link' columns are almost unique,so they doesn't contribute in predicting target variable","ba2d516d":" Barplot of imbd_binned column","943ffe7e":"Our dataset contains 5043 samples(rows) and 28 variables(columns)","98928078":"You will need to declare two variables \u2014 X and y where first represents all the features, and the second represents the target variable. Then you\u2019ll make an instance of the Machine learning algorithm (In this case RandomForests). In it, you can optionally pass a random state seed for reproducibility. Now you can create an instance of RFECV.\n\n\n","72dd48bf":"Lets see which features influence the target varible(IMDB Score)","ba0d6e7e":"## 3.4 Random Forest\n\nRandom forests is an ensemble learning method for classification that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification)  of the individual trees\n\n*n_estimators* is a parameter that specify number of trees in the forest.\n\n*criterion* is to specify what function to measure the quality of a split. \u201centropy\u201d is for the information gain. ","fdc93290":"## 2.3 Handling the Missing values\n\nEvery datset have some missing values, lets find out in which cloumns they are?","9638c023":"Splitting the data into X and y where X contains Indepentent variables and y contain Target\/Dependent variable.\n","6c203996":"#Categorising the IMDB rating into 3 classes Hit,Avg,Flop\nHere I have dataset named movie_metadata in which the target variable is IMDB score and other variables that decide the IMDB score. Instead of just IMDB score,With the help of other parameters I want to predict whether a movie is Hit,Avg or Flop.\n\n\n\n|imdb_score | Classify |\n| --- | ---|\n|1-3 | Flop Movie|\n|3-6 | Average Movie|\n|6-10 | Hit Movie|\n","07815c81":"Dropping all the samples that having missing values\n","080fe958":"## 2.2 Categorizing the target varible \n\nHere we are categorizing the target variable in such a way that IMDB score between 1 and 3 is FLOP , between 3 and 6 is AVG, between 6 and 10 is HIT.\n\nAnd we are using binning in pandas to acheive this.\n","4db45588":"## 3.6 Classification Report","c1b9e42f":"## 1.1 Background\n\n\nSuccess of a movie depends upon alot of factors like good directors or excellent actors or story plotline.However, famous directors and actors can always bring an expected box-office income but cannot guarantee a highly rated imdb score.\n\n","9ced8a22":"# 1 INTRODUCTION\n","2ba81d97":"Recursive Feature Elimination  with Cross Validation\n\nRecursive \u2014 involving doing or saying the same thing several times in order to produce a particular result or effect\n\nFeature \u2014 individual measurable property or characteristic of a phenomenon being observed \u2014 an  attribute in your dataset\n\nCross-Validation \u2014 a technique for evaluating ML models by training several ML models on subsets of the available input data and evaluating them on the complementary subset of the data. Use cross-validation to detect overfitting, ie, failing to generalize a pattern.","be160c3e":"## 3.4 Feature Selection using RFECV\n\n","55e7e5d1":"## 2.1 Importing necessary Libraries\n","7522abc7":"Total samples remaining after dropping missing values\n","f6ec27da":"## 3.1 Train Test Split\n\nWe need data not only to train our model but also to test our model. So splitting the dataset into 70:30 (Train:Test) ratio.We have a predefined a function in Sklearn library called test_train_split, lets use that.","64514ee3":"|Features Selected |\tFeatures Dropped|\n| --- | --- |\n|duration| color|\n|director_facebook_likes\t| director name|\n|actor_3_facebook_likes\t| actor_2_name|\n|actor_1_facebook_likes|\tactor_1_name   |\n|gross|\tfacenumber_in_poster|\n|genres |\tlanguage|\n|num_voted_users |country\t|\n|actor_3_name \t| content_rating|\n|actor_3_name |\taspect_ratio|\n|plot_keywords |\t|\n|num_user_for_reviews |\t |\n|budget| |\n|title_year | \t|\n|actor_2_facebook_likes |\t |\n|movie_facebook_likes |\t |\n","045aed82":"|Variable Name |\tDescription|\n| --- | --- |\n|movie_title\t | Title of the Movie|\n|duration\t| Duration in minutes|\n|director_name\t| Name of the Director of the Movie|\n|director_facebook_likes |\tNumber of likes of the Director on his Facebook Page|\n|actor_1_name |\tPrimary actor starring in the movie|\n|actor_1_facebook_likes |\tNumber of likes of the Actor_1 on his\/her Facebook Page|\n|actor_2_name |\tOther actor starring in the movie|\n|actor_2_facebook_likes\t| Number of likes of the Actor_2 on his\/her Facebook Page|\n|actor_3_name |\tOther actor starring in the movie|\n|actor_3_facebook_likes |\tNumber of likes of the Actor_3 on his\/her Facebook Page|\n|num_user_for_reviews |\tNumber of users who gave a review|\n|num_critic_for_reviews |\tNumber of critical reviews on imdb|\n|num_voted_users | \tNumber of people who voted for the movie|\n|cast_total_facebook_likes |\tTotal number of facebook likes of the entire cast of the movie|\n|movie_facebook_likes |\tNumber of Facebook likes in the movie page|\n|plot_keywords |\tKeywords describing the movie plot|\n|facenumber_in_poster |\tNumber of the actor who featured in the movie poster|\n|color |\tFilm colorization. \u2018Black and White\u2019 or \u2018Color\u2019|\n|genres |\tFilm categorization like \u2018Animation\u2019, \u2018Comedy\u2019, \u2018Romance\u2019, \u2018Horror\u2019, \u2018Sci-Fi\u2019, \u2018Action\u2019, \u2018Family\u2019|\n|title_year |\tThe year in which the movie is released (1916:2016)|\n|language |\tEnglish, Arabic, Chinese, French, German, Danish, Italian, Japanese etc|\n|country |\tCountry where the movie is produced|\n|content_rating |\tContent rating of the movie|\n|aspect_ratio |\tAspect ratio the movie was made in|\n|movie_imdb_link |\tIMDB link of the movie|\n|gross |\tGross earnings of the movie in Dollars|\n|budget |\tBudget of the movie in Dollars|\n|imdb_score |\tIMDB Score of the movie on IMDB|","44416f9f":"## 2.5 Correlation\n\nTo find out whether there is any relation between variables, in other terms multicollineariaty.\n\n","0fe15453":"## 3.2 Scaling\n\nFew variables will be in the range of Millions and some in Tens, lets bring all of them into same scale\n","0d4e5ac5":"These variables that are correlated cause errors in the prediction, so removing them\n","e3654c44":"We can see a new column named imdb_binned correctly categorising the imdb score\n","27507477":"## 3.5 Confusion Matrix\n\nConfusion matrix gives a clear view of ground truth and prediction.","d8837170":"Predicting the test data"}}