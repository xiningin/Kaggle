{"cell_type":{"715c677c":"code","f147793f":"code","31d18d2c":"code","168ae4e6":"code","9cacf79e":"code","e7628826":"code","8821b597":"code","2b58b811":"code","f96d4470":"code","ce9ef46a":"code","01141421":"code","080d7f92":"markdown","6efac184":"markdown","004e2081":"markdown","196cded4":"markdown","ec9c6b9b":"markdown","c651bb1a":"markdown","c407d8da":"markdown","964df929":"markdown","c22c6785":"markdown","c10efad9":"markdown"},"source":{"715c677c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pickle\nimport matplotlib.pyplot as plt\nfrom timeit import default_timer as timer\n\nimport tensorflow as tf\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape, Lambda\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.applications import ResNet50\n\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(os.listdir('..\/input'))","f147793f":"# Fixed for our Cats & Dogs classes\nNUM_CLASSES = 43\n\n# Fixed for Cats & Dogs color images\nCHANNELS = 3\n\nIMAGE_RESIZE = 224\nRESNET50_POOLING_AVERAGE = 'avg'\nDENSE_LAYER_ACTIVATION = 'softmax'\nOBJECTIVE_FUNCTION = 'categorical_crossentropy'\n\n# Common accuracy metric for all outputs, but can use different metrics for different output\nLOSS_METRICS = ['accuracy']\n\n# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\nNUM_EPOCHS = 10\nEARLY_STOP_PATIENCE = 3\n\n# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n# Training images processed in each step would be no.-of-train-images \/ STEPS_PER_EPOCH_TRAINING\nSTEPS_PER_EPOCH_TRAINING = 10\nSTEPS_PER_EPOCH_VALIDATION = 10\n\n# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\nBATCH_SIZE_TRAINING = 100\nBATCH_SIZE_VALIDATION = 100\n\n# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\nBATCH_SIZE_TESTING = 1","31d18d2c":"# Opening file for reading in binary mode\nwith open('..\/input\/traffic-signs-preprocessed\/data2.pickle', 'rb') as f:\n    data = pickle.load(f, encoding='latin1')  # dictionary type\n\n# Preparing y_train and y_validation for using in Keras\ndata['y_train'] = to_categorical(data['y_train'], num_classes=43)\ndata['y_validation'] = to_categorical(data['y_validation'], num_classes=43)\n\n# Making channels come at the end\ndata['x_train'] = data['x_train'].transpose(0, 2, 3, 1)\ndata['x_validation'] = data['x_validation'].transpose(0, 2, 3, 1)\ndata['x_test'] = data['x_test'].transpose(0, 2, 3, 1)\n\n# Showing loaded data from file\nfor i, j in data.items():\n    if i == 'labels':\n        print(i + ':', len(j))\n    else: \n        print(i + ':', j.shape)\n\n# x_train: (86989, 32, 32, 3)\n# y_train: (86989, 43)\n# x_test: (12630, 32, 32, 3)\n# y_test: (12630,)\n# x_validation: (4410, 32, 32, 3)\n# y_validation: (4410, 43)\n# labels: 43\n","168ae4e6":"%matplotlib inline\n\n# Preparing function for ploting set of examples\n# As input it will take 4D tensor and convert it to the grid\n# Values will be scaled to the range [0, 255]\ndef convert_to_grid(x_input):\n    N, H, W, C = x_input.shape\n    grid_size = int(np.ceil(np.sqrt(N)))\n    grid_height = H * grid_size + 1 * (grid_size - 1)\n    grid_width = W * grid_size + 1 * (grid_size - 1)\n    grid = np.zeros((grid_height, grid_width, C)) + 255\n    next_idx = 0\n    y0, y1 = 0, H\n    for y in range(grid_size):\n        x0, x1 = 0, W\n        for x in range(grid_size):\n            if next_idx < N:\n                img = x_input[next_idx]\n                low, high = np.min(img), np.max(img)\n                grid[y0:y1, x0:x1] = 255.0 * (img - low) \/ (high - low)\n                next_idx += 1\n            x0 += W + 1\n            x1 += W + 1\n        y0 += H + 1\n        y1 += H + 1\n\n    return grid\n\n\n# Visualizing some examples of training data\nexamples = data['x_train'][:81, :, :, :]\nprint(examples.shape)  # (81, 32, 32, 3)\n\n# Plotting some examples\nfig = plt.figure()\ngrid = convert_to_grid(examples)\nplt.imshow(grid.astype('uint8'), cmap='gray')\nplt.axis('off')\nplt.gcf().set_size_inches(15, 15)\nplt.title('Some examples of training data', fontsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('training_examples.png')\nplt.close()\n","9cacf79e":"resnet_weights_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'","e7628826":"img_size = (224,224)\nmodel = Sequential()\nmodel.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\nmodel.layers[2].trainable = False","8821b597":"from keras import optimizers\n\nsgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\nmodel.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)","2b58b811":"hist = model.fit(data['x_train'], data['y_train'], validation_data =(data['x_validation'], data['y_validation']), epochs = 20, batch_size = 1000)","f96d4470":"print('Epochs={0:d}, training accuracy={1:.5f}, validation accuracy={2:.5f}'.\\\n      format(10, max(hist.history['acc']), max(hist.history['val_acc'])))","ce9ef46a":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 5.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['font.family'] = 'Times New Roman'\n\nfig = plt.figure()\nplt.plot(hist.history['acc'], '-o', linewidth=3.0)\nplt.plot(hist.history['val_acc'], '-o', linewidth=3.0)\nplt.title('Overfitting small data', fontsize=22)\nplt.legend(['train', 'validation'], loc='upper left', fontsize='xx-large')\nplt.xlabel('Epoch', fontsize=20)\nplt.ylabel('Accuracy', fontsize=20)\nplt.tick_params(labelsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('overfitting_small_data.png')\nplt.close()\n","01141421":"%matplotlib inline\n\n# Preparing image for predicting from test dataset\nx_input = data['x_test'][100:101]\nprint(x_input.shape)\ny_input = data['y_test'][100:101]\nprint(y_input)\n\nplt.rcParams['figure.figsize'] = (2.5, 2.5) # Setting default size of plots\nplt.imshow(x_input[0, :, :, :])\nplt.axis('off')\n\n# Showing the plot\nplt.show()\n\n# Getting scores from forward pass of input image\nscores = model.predict(x_input)\nprint(scores.shape) # (43,)\n\n# Scores is given for image with 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\nprint('ClassId:', prediction)\n\n# Defining function for getting texts for every class - labels\ndef label_text(file):\n    # Defining list for saving label in order from 0 to 42\n    label_list = []\n    \n    # Reading 'csv' file and getting image's labels\n    r = pd.read_csv(file)\n    # Going through all names\n    for name in r['SignName']:\n        # Adding from every row second column with name of the label\n        label_list.append(name)\n    \n    # Returning resulted list with labels\n    return label_list\n\n\n# Getting labels\nlabels = label_text('..\/input\/traffic-signs-preprocessed\/label_names.csv')\n\n# Printing label for classified Traffic Sign\nprint('Label:', labels[prediction])\n","080d7f92":"# \ud83c\udfd7\ufe0f Building model of Resnet50 (Transfer Learning)","6efac184":"# \u26d4\ufe0f Traffic Signs Classification with Resnet50","004e2081":"# \ud83d\udcab Showing some examples","196cded4":"# \ud83d\udce5 Importing needed libraries","ec9c6b9b":"<div id=\"resnet\"><h3>What is A ResNet 50?<\/h3><\/div>\n<p><\/p>\n<center><img src=\"https:\/\/i.stack.imgur.com\/gI4zT.png\" width=600px alt=\"ResNet\"><\/center>\n<p><\/p>\n<p>\nResNet, short for Residual Networks is a classic neural network used as a backbone for many computer vision tasks. This model was the winner of ImageNet challenge in 2015. The fundamental breakthrough with ResNet was it allowed us to train extremely deep neural networks with 150+layers successfully. Prior to ResNet training very deep neural networks was difficult due to the problem of vanishing gradients.<\/p>","c651bb1a":"# \ud83d\udcc8 Plotting results","c407d8da":"# \ud83d\uddbc\ufe0f Predicting with one image from test dataset","964df929":"# \ud83d\udcc2 Loading dataset data2.pickle with RGB examples","c22c6785":"<h2>What is Transfer Learning<\/h2>\n<center><img width=600px src = \"https:\/\/ruder.io\/content\/images\/2017\/03\/transfer_learning_setup.png\" alt=\"Transfer Learning\"><\/center>\n\n<p>Transfer learning allows us to deal with these scenarios by leveraging the already existing labeled data of some related task or domain. We try to store this knowledge gained in solving the source task in the source domain and apply it to our problem of interest as can be seen in Figure above <\/p>","c10efad9":"# \ud83e\udd0f Training Model"}}