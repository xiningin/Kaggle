{"cell_type":{"ccecf502":"code","de954615":"code","8f228aa6":"code","fccc4f1e":"code","3dcfb68c":"code","71f3183a":"code","7a9b6de3":"code","39c2b2dc":"code","a400ad5b":"code","8aeefa88":"code","45a1cb37":"code","f44b1d1e":"code","bf79f2ad":"code","38e3259f":"code","49880169":"code","27f3907e":"code","b20ae5ba":"code","88228ec6":"code","ac79e8a3":"code","283ee6ef":"code","cc5e4916":"code","55e2255d":"code","59a9f9ec":"code","468608a5":"code","7f686039":"code","4b09592e":"code","ad1bbc8e":"code","93d55cff":"code","7fcab71b":"code","a8fee00c":"code","c75e9b5d":"code","dd4199a6":"code","be0c8e73":"markdown","18fdc958":"markdown","cb2d8722":"markdown","025da40f":"markdown","2790fb7f":"markdown","ade247d0":"markdown","8225295d":"markdown"},"source":{"ccecf502":"#k\u00fct\u00fcphaneler\nimport numpy as np\nimport pandas as pd\nfrom textblob import TextBlob\nfrom sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn import decomposition, ensemble\nimport pandas, xgboost, numpy, textblob, string\nfrom keras.preprocessing import text, sequence\nfrom keras import layers, models, optimizers\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nimport seaborn as sns\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","de954615":"#veri setini okuyal\u0131m:\n#veri setinde 1 tane ab\u011f\u0131ms\u0131z de\u011fi\u015fken,1 tane ba\u011f\u0131ml\u0131 de\u011fi\u015fken var.\n#'Sentence' adl\u0131 veri setinde yap\u0131lan yorumlar mevcut\n#'Class' adl\u0131 veri setinde yap\u0131lan bu yorumlar\u0131n negatif -->0 ya da pozitif -->1 olmas\u0131 durumu mevcut.\ndata=pd.read_csv('..\/input\/yorumlar\/comment')\ndata.head()","8f228aa6":"#veri setindeki 'class' adl\u0131 de\u011fi\u015fkenin ismini 'Sentiment' olarak de\u011fi\u015ftirdik.\ndata=data.rename(columns={'Class':'Sentiment'})\ndata.head()","fccc4f1e":"#veri setimizde 1386 tane pozitif yorum,1362 tane negatif yorum var.\ndata['Sentiment'].value_counts()","3dcfb68c":"sns.countplot(data.Sentiment);","71f3183a":"#yap\u0131lan i\u015flemlerde s\u0131n\u0131f d\u00f6n\u00fc\u015ft\u00fcrme i\u015flemi yap\u0131ld\u0131:0 --> negatif,1 --> pozitif oldu.\ndata[\"Sentiment\"].replace(0,value=\"negatif\",inplace=True)\ndata[\"Sentiment\"].replace(1,value=\"pozitif\",inplace=True)","7a9b6de3":"data","39c2b2dc":"#'df' adl\u0131 yeni bir dataframe olu\u015fturuduk\n#'text' adl\u0131 de\u011fi\u015fekene,'Sentence' adl\u0131 de\u011fi\u015fkendeki g\u00f6zlemleri atad\u0131k.\n#'label' adl\u0131 de\u011fi\u015fkene,'Sentiment' adl\u0131 de\u011fi\u015fkendeki g\u00f6zlemleri atad\u0131k.\ndf=pd.DataFrame()\ndf[\"text\"]=data[\"Sentence\"]\ndf[\"label\"]=data[\"Sentiment\"]","a400ad5b":"df","8aeefa88":"#buyuk-kucuk donusumu\ndf['text'] = df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n#noktalama i\u015faretleri\ndf['text'] = df['text'].str.replace('[^\\w\\s]','')\n#say\u0131lar\ndf['text'] = df['text'].str.replace('\\d','')\n#stopwords\nimport nltk\nfrom nltk.corpus import stopwords\nsw = stopwords.words('english')\ndf['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n#seyreklerin silinmesi\nsil = pd.Series(' '.join(df['text']).split()).value_counts()[-1000:]\ndf['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sil))\n#lemmi\nfrom textblob import Word\ndf['text'] = df['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.\nsplit()]))","45a1cb37":"#metin \u00f6n i\u015fleme uyguland\u0131ktan sonra veri setinin son hali:\ndf","f44b1d1e":"#train-test ayr\u0131m\u0131 yap\u0131ld\u0131:\ntrain_x,test_x,train_y,test_y=model_selection.train_test_split(df[\"text\"],\ndf[\"label\"])","bf79f2ad":"train_x.head()","38e3259f":"train_y.head()","49880169":"#ba\u011f\u0131ml\u0131 de\u011fi\u015fkene,0-1 d\u00f6n\u00fc\u015f\u00fcm\u00fc yap\u0131ld\u0131:\nencoder=preprocessing.LabelEncoder()\ntrain_y=encoder.fit_transform(train_y)\ntest_y=encoder.fit_transform(test_y)","27f3907e":"train_y[0:5]","b20ae5ba":"test_y[0:5]","88228ec6":"#de\u011fi\u015fkenler olu\u015fturuldu.\nvectorizer=CountVectorizer()\nvectorizer.fit(train_x)\nx_train_count=vectorizer.transform(train_x)\nx_test_count=vectorizer.transform(test_x)","ac79e8a3":"#de\u011fi\u015fkenlerime bakal\u0131m:\nvectorizer.get_feature_names()[0:5]","283ee6ef":"#1810 tane de\u011fi\u015fken olu\u015fturulmu\u015f\nlen(vectorizer.get_feature_names())","cc5e4916":"#lojisyik regresyon ile model kuruldu.\nloj = linear_model.LogisticRegression()\nloj_model = loj.fit(x_train_count, train_y)\naccuracy = model_selection.cross_val_score(loj_model,\n                                           x_test_count,\n                                           test_y,\n                                           cv = 10).mean()\nprint(\"Count Vectors Do\u011fruluk Oran\u0131:\", accuracy)","55e2255d":"#bir c\u00fcmle olu\u015fturuldu\nyeni_yorum=pd.Series('this film is very nice and good i like it')\nv=CountVectorizer()\nv.fit(train_x)\nyeni_yorum=v.transform(yeni_yorum)","59a9f9ec":"#kurulan model c\u00fcmlenin negatif mi pozitif mi oldu\u011funu tahmin etti:\n#0 --> negatif, 1-->pozitif\n#modelintahmin etti\u011fi sonu\u00e7 do\u011fru\nloj_model.predict(yeni_yorum)","468608a5":"#yeni bir c\u00fcmler olu\u015fturuldu\n#c\u00fcmle negatif bir c\u00fcmle\nyeni_yorum2=pd.Series(\"no not good look at that shit very bad\")\nv2=CountVectorizer()\nv2.fit(train_x)\nyeni_yorum2=v2.transform(yeni_yorum2)","7f686039":"#modelin tahmin etti\u011fi tahmin do\u011fru\n#0 -->negatif, 1 -->pozitif\nloj_model.predict(yeni_yorum2)","4b09592e":"#hiperparametre aral\u0131klar\u0131 belirlendi:\nxgb_params={'n_estimators':[5,10],\n'subsample':[0.6,0.8],\n'max_depth':[3,4],\n'learning_rate':[0.1,0.01],\n'min_samples_split':[2,5]}","ad1bbc8e":"#gridsearch cv y\u00f6ntemi ile optimum hiperparametreler bulundu:\nxgb=XGBClassifier()\nxgb_cv_model=GridSearchCV(xgb,xgb_params,cv=10,n_jobs=1).fit(x_train_count,train_y)","93d55cff":"#optimum hiperparametre de\u011ferleri:\nxgb_cv_model.best_params_","7fcab71b":"#bulunan optimum hiperparametreler ile final modeli kuruldu:\nxgb_model=XGBClassifier(n_estimators=10,subsample=0.6,max_depth=4,learning_rate=0.1,min_samples_split=2)\nxgb_cv_model=xgb_model.fit(x_train_count,train_y)\ny_pred=xgb_cv_model.predict(x_test_count)\naccuracy_score(test_y,y_pred)","a8fee00c":"#\u015fimdi yeni_yorum ve yeni_yorum2 adl\u0131 de\u011fi\u015fkenlerdedi c\u00fcmlelerin negataif mi pozitif mi oldu\u011funu kurmu\u015f oldu\u011fumuz modelin tahmin etme i\u015flemine bakal\u0131m:","c75e9b5d":"#yeni_yorum:'this film is very nice and good i like it' (poztif bir c\u00fcmle)\n#do\u011fru tahmin etti\n#0 -->negatif ,1 -->pozitif\nxgb_cv_model.predict(yeni_yorum)","dd4199a6":"#yeni_yorum2:'no not good look at that shit very bad'  (negatif bir c\u00fcmle)\n#yanl\u0131\u015f tahmin etti\n#0 -->negatif  ,1 -->pozitif\nxgb_cv_model.predict(yeni_yorum2)","be0c8e73":"## Do\u011fal Dil \u0130\u015fleme alan\u0131nda makine \u00f6\u011frenmesi:\n* makine \u00f6\u011frenmesi ile model kurup,sentiment analizi yapm\u0131\u015f olaca\u011f\u0131z.\n* Lojistik regresyon ve extreme gradient boosting algoritmalar\u0131 ile model kuruldu.\n* veri setimizde yorumlar\u0131 ifade eden bir de\u011fi\u015fken vard\u0131.\n* amac\u0131m\u0131z;bir yorum geldi\u011finde,bu yorum pozitif bir yorum mu yokda negatif bir yorum mu  olduunu tahmin edecek bir model kurmak:","18fdc958":"## De\u011fi\u015fken M\u00fchendisli\u011fi:\n* bir metin i\u00e7erisinden \u00f6zellik \u00e7\u0131karma,de\u011fi\u015fken olu\u015fturma i\u015flemi\n* Count Vectors y\u00f6ntemi:\u00f6rne\u011fin elimizde \u00e7ok b\u00fcy\u00fck bir veri seti var,her bir sat\u0131r bir yorumu ya da bir d\u00f6k\u00fcman\u0131 temsil eder,her bir s\u00fctunda bir d\u00f6kumandaki kelimeleri ifade eder,kesi\u015fiminde yer alan ifadeler ise d\u00f6k\u00fcmanlardaki ge\u00e7me s\u0131kl\u0131\u011f\u0131n\u0131 ifade eder.","cb2d8722":"* veri seti 'commnent' adl\u0131 veri seti,veri setinde baz\u0131 siterlerde yap\u0131lan pozitif ve negatif yorumlar mevcut,ben bu yap\u0131lan yorumlar\u0131 birle\u015ftirdim.","025da40f":"## Lojistik Regresyon \u0130le Model Kurma:","2790fb7f":"## Metin \u00d6n \u0130\u015fleme:\n* a\u015fa\u011f\u0131daki i\u015flemlerde,veri setindeki 'text' adl\u0131 de\u011fi\u015fkene metin \u00f6n i\u015fleme yap\u0131ld\u0131,yani daha tutarl\u0131 hale getirildi.","ade247d0":"## Exteme Gradient Boosting(XGBoost) algotritmas\u0131 ile model kurma:","8225295d":"## Count Vector:\n* \u015fimdi count vector y\u00f6ntemiyle de\u011fi\u015fkenlerimizi olu\u015ftural\u0131m:"}}