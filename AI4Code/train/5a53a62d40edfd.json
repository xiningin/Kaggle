{"cell_type":{"f6755e76":"code","24c443dd":"code","6408ced2":"code","3a601571":"code","560838c7":"code","fdb2a24a":"code","415ea6bc":"code","58f756de":"code","56116930":"code","eaac2e89":"code","dfe52888":"code","5f63a394":"code","c00699f9":"code","b8ed9d2d":"code","23f7395e":"code","75817b24":"code","166b204d":"code","68bd0238":"code","b7d93d04":"code","baa1f972":"code","6a23aaf5":"code","c3641c3b":"code","9d4b6082":"code","1abee1bc":"code","eae778f4":"code","725eef42":"code","2104c7c4":"code","b48aefa0":"code","81abb99c":"code","9ef97a72":"code","7db4b022":"code","5f601cea":"code","8350e966":"code","f38937f7":"code","49763d29":"code","f1f08204":"code","a66266c0":"code","ed1069bc":"code","02ffa168":"code","925968e3":"code","53cd95e0":"code","52c7f48a":"code","81a07f83":"code","f60b9170":"code","dc76068d":"code","2d8e7062":"code","6e110f64":"code","126c4d45":"code","e2ebb9a1":"code","abc33b6b":"code","5f36bfc7":"markdown","89f1b3fe":"markdown","212657fe":"markdown","566a0907":"markdown","34dd9554":"markdown","a271c4ec":"markdown","a40a14ad":"markdown","8df510a3":"markdown","8dfd97be":"markdown","92297968":"markdown","c89ee0d9":"markdown","f3ddc905":"markdown","e9890c70":"markdown","3da2a0f1":"markdown","76701a35":"markdown","b42d1edf":"markdown","8a3595f5":"markdown","f0750e41":"markdown","3c90ed5d":"markdown","834b6197":"markdown","87cc54b4":"markdown","33f6fe12":"markdown","15bc8d18":"markdown","1207df09":"markdown","808300b6":"markdown","78ba7623":"markdown","0543cfdf":"markdown","4a1ce49b":"markdown","d3350bff":"markdown","e87b436d":"markdown","ebe5e0fb":"markdown","2896d1d4":"markdown","1a5970a6":"markdown","7e9a5dac":"markdown","bd00c368":"markdown","44a778db":"markdown","e5377cc9":"markdown","8f6a82f8":"markdown","d74c6322":"markdown","cbbf7b17":"markdown","67576038":"markdown","22428451":"markdown","02c57373":"markdown","6ace6ec3":"markdown"},"source":{"f6755e76":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\n\n# for visualization\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# import holoviews as hv\n\n# Testing\nimport scipy\nimport scipy.stats as st\n\n# Modeling\nimport xgboost\nfrom xgboost import XGBClassifier\n\nimport sklearn\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n\nfrom sklearn import model_selection\n# Splitting Dataset\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\n# Scoring\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score\nfrom sklearn.model_selection import KFold\n\n# Class Imbalance\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n# from imblearn import over_sampling\n\n%matplotlib inline","24c443dd":"print('Numpy Version : ' + np.__version__)\nprint('Pandas Version : ' + pd.__version__)\nprint('Matplotlib Version : ' + matplotlib.__version__)\nprint('Seaborn Version : ' + sns.__version__)\nprint('Scipy Version : ' + scipy.__version__)\nprint('Sklearn Version : ' + sklearn.__version__)\nprint('XGBoost Version : ' + xgboost.__version__)","6408ced2":"train = pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/train.csv')\ntrain.head()","3a601571":"train[['id','Region_Code']].groupby('Region_Code', as_index=False).count().sort_values('id', ascending=False).head(10).Region_Code.to_list()","560838c7":"train[train.Region_Code.isin(train[['id','Region_Code']].groupby('Region_Code', as_index=False).count().sort_values('id').head(10).Region_Code.to_list())]","fdb2a24a":"# test = pd.read_csv(groupbyive\/test.csv')\n# test.head()","415ea6bc":"train.shape","58f756de":"train.info()","56116930":"train.describe()","eaac2e89":"numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndisplay(train.select_dtypes(include=numerics).columns)\nprint(train.select_dtypes(include=numerics).shape)\ndata_num = train.select_dtypes(include=numerics)","dfe52888":"#Invalid Value\ndisplay(train.select_dtypes(include=['object']).columns)\nprint(train.select_dtypes(include=object).shape)\ndata_cat = train.select_dtypes(include=['object'])","5f63a394":"train[['id', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured',\n       'Annual_Premium', 'Policy_Sales_Channel', 'Vintage', 'Response']].describe()","c00699f9":"train['Gender'].value_counts()","b8ed9d2d":"train['Vehicle_Age'].value_counts()","23f7395e":"train['Vehicle_Damage'].value_counts()","75817b24":"train[['Gender', 'Vehicle_Age', 'Vehicle_Damage']].describe()","166b204d":"trainGroup = train.loc[:, train.columns.intersection(['id', 'Response'])]\ntrainGroup['Age-Group'] = train['Age'].apply(lambda x : '> 50' if x > 50 else ('36 - 50' if (x > 35) and (x < 51) else '20-35'))\ntrainGroup['Vintage-Group'] = train['Vintage'].apply(lambda x : '0-100' if x < 100 else ('100 - 200' if (x > 100) and (x < 200) else '200 - 300'))\ntrainGroup['Annual_Premium-Group'] = train['Annual_Premium'].apply(lambda x : '> 450K' if x > 450000 else ('150K - 450K' if (x > 150000) and (x < 450001) else '0 - 150K'))\n\ntrainGroup","68bd0238":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\n\n# Count Length Data Vehicle Damage\ndv_len = len(train['Driving_License'])\n\ng = sns.countplot(train['Driving_License'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(train['Driving_License'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\nplt.suptitle('Response to Driving License',y=1, fontsize=24,color='dodgerblue',fontweight='bold')\n\nfig.tight_layout()\n\n\nplt.savefig('.\/driving-license.jpg')\nplt.show();","b7d93d04":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\npi_len = len(train['Previously_Insured'])\n\ng = sns.countplot(train['Previously_Insured'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(train['Previously_Insured'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\nplt.suptitle('Response to Previously Insured',y=1, fontsize=24,color='dodgerblue',fontweight='bold')\n\nfig.tight_layout()\n\nplt.savefig('.\/previously-insured.jpg')\nplt.show();","baa1f972":"fig,ax = plt.subplots(1,4,figsize=(26,8))\n\nag_len = len(trainGroup['Age-Group'])\n\ng = sns.countplot(trainGroup['Age-Group'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\nh = sns.countplot(trainGroup['Age-Group'], hue = trainGroup['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nax[1].legend(loc=\"upper left\", title=\"Response\",)\n\n    \nk = sns.distplot(train['Age'], ax=ax[2])\nl = sns.boxplot(train['Age'], orient='v', ax=ax[3])\n\nplt.suptitle('Distribution Age',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\nfig.tight_layout()\n\nplt.savefig('.\/age.jpg')\nplt.show();","6a23aaf5":"fig,ax = plt.subplots(1,4,figsize=(26,8))\n\nvg_len = len(trainGroup['Vintage-Group'])\n\ng = sns.countplot(trainGroup['Vintage-Group'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(trainGroup['Vintage-Group'], hue = trainGroup['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \ng = sns.distplot(train['Vintage'], ax=ax[2])\ng = sns.boxplot(train['Vintage'], orient='v', ax=ax[3])\n\nplt.suptitle('Distribution Vintage',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\t\nfig.tight_layout()\n\nplt.savefig('.\/vintage.jpg')\nplt.show();","c3641c3b":"fig,ax = plt.subplots(1,4,figsize=(26,8))\n\napg_len = len(trainGroup['Annual_Premium-Group'])\n\ng = sns.countplot(trainGroup['Annual_Premium-Group'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(trainGroup['Annual_Premium-Group'], hue = trainGroup['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \ng = sns.distplot(train['Annual_Premium'], ax=ax[2])\ng = sns.boxplot(train['Annual_Premium'], orient='v', ax=ax[3])\n\nplt.suptitle('Distribution Annual Premium',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\t\nfig.tight_layout()\n\nplt.savefig('.\/annual-premium.jpg')\nplt.show();","9d4b6082":"fig,ax = plt.subplots(2,figsize=(26,15),\n                     sharey=True)\n\ndata_region_code = train[train.Region_Code.isin(train[['id','Region_Code']].groupby('Region_Code', as_index=False).count().sort_values('id', ascending=False).head(10).Region_Code.to_list())]\n\ng = sns.countplot(data_region_code['Region_Code'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\nax[0].set_title('Distribution Region Code',fontsize=24,color='dodgerblue',fontweight='bold')\n\nh = sns.countplot(data_region_code['Region_Code'],hue= data_region_code['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\nax[1].set_title('Response to Region Code',fontsize=24,color='dodgerblue',fontweight='bold')\n\nfig.tight_layout();","1abee1bc":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\ng_len = len(train['Gender'])\n\ng = sns.countplot(train['Gender'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(train['Gender'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nplt.suptitle('Response to Gender',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\nfig.tight_layout()\n\nplt.savefig('.\/gender.jpg')\nplt.show();","eae778f4":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\nva_len = len(train['Vehicle_Age'])\n\ng = sns.countplot(train['Vehicle_Age'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(train['Vehicle_Age'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\n\nplt.suptitle('Response to Vehicle Age',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\nfig.tight_layout()\n\nplt.savefig('.\/vehicle-age.jpg')\nplt.show();","725eef42":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\n# Count Length Data Vehicle Damage\nvd_len = len(train['Vehicle_Damage'])\n\ng = sns.countplot(train['Vehicle_Damage'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\n\n\nh = sns.countplot(train['Vehicle_Damage'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\nplt.suptitle('Response to Vehicle Damage',y=1, fontsize=24,color='dodgerblue',fontweight='bold')\n\nfig.tight_layout()\n\nplt.savefig('.\/vehicle-damage.jpg')\nplt.show();","2104c7c4":"corr_= train.corr().round(3)\nmask = np.zeros_like(corr_)\n    \nwith sns.axes_style(\"white\"):\n    f, ax = plt.subplots(figsize=(21, 10))\n    ax = sns.heatmap(corr_, annot=True, cmap = \"BuPu\")\n\nplt.tight_layout;\n# plt.savefig('fig\/matrix correlation.png');","b48aefa0":"# Finding Missing Value\ndata_missing_value = train.isnull().sum().reset_index()\ndata_missing_value.columns = ['feature','missing_value']\ndata_missing_value = data_missing_value[data_missing_value['missing_value'] > 0]\n\ndata_missing_value","81abb99c":"train.duplicated().sum()","9ef97a72":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nss = StandardScaler()\n\nss_list = [\n    'Annual_Premium',\n    'Vintage',\n]\n\nfor x in ss_list :\n    train[[x]] = ss.fit_transform(train[[x]])","7db4b022":"gd = {'Male' : 0, 'Female' : 1}\npi = {0 : 'No', 1 : 'Yes'}\ntrain['Gender'] = train['Gender'].map(gd)\ntrain['Previously_Insured'] = train['Previously_Insured'].map(pi)\ntrain","5f601cea":"# sns.boxplot(np.log(train['Annual_Premium']), orient='v')\n# train['Annual_Premium'].describe()","8350e966":"train_dummies = pd.get_dummies(train[[\n    'Vehicle_Damage',\n    'Previously_Insured',    \n    'Vehicle_Age'\n]])\n# , drop_first=True\ntrain_d = pd.concat([train, train_dummies], axis=1)\ntrain_d.head()","f38937f7":"train_d=train_d.rename(columns={\"Vehicle_Age_< 1 Year\": \"Vehicle_Age_lt_1_Year\", \"Vehicle_Age_> 2 Years\": \"Vehicle_Age_gt_2_Years\"})\n\ntrain_d['Vehicle_Age_lt_1_Year']=train_d['Vehicle_Age_lt_1_Year'].astype('int')\ntrain_d['Vehicle_Age_gt_2_Years']=train_d['Vehicle_Age_gt_2_Years'].astype('int')\ntrain_d['Vehicle_Damage_Yes']=train_d['Vehicle_Damage_Yes'].astype('int')","49763d29":"train_d = train_d.drop([\n    'id', \n    'Vehicle_Age',\n    'Vehicle_Damage',\n    'Previously_Insured',\n    \n    'Vehicle_Damage_No',    \n    'Vehicle_Age_1-2 Year'\n    \n], axis=1)\ntrain_d.head()","f1f08204":"train_pp = train_d\n\ny = train_pp['Response'].values\nX = train_pp.drop(labels = ['Response'], axis = 1)\nprint(\"Shape of X is {} and that of y is {}\".format(X.shape, y.shape))\n\n# Splitting the dataset \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n\nprint('Shape of training set ', X_train.shape)\nprint('Shape of test set ', X_test.shape)","a66266c0":"classifications = [\n    LogisticRegression(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    XGBClassifier(max_depth= 2, eta= 1, objective= 'binary:logistic')\n]\n\nresult_model = pd.DataFrame(columns = ['Method', 'roc_auc_score'])\nresult_model","ed1069bc":"for model in classifications:\n    model.fit(X_train, y_train)\n    y_score = model.predict_proba(X_test)[:,1]\n    \n    method = str(type(model)).split('.')[-1][:-2]\n    \n    #roc_auc_score\n    roc_auc_score_ = roc_auc_score(y_test, y_score)\n    roc_auc_score_ = roc_auc_score_.item()\n    \n    result_model = result_model.append({\n        'Method': method,\n        'roc_auc_score': roc_auc_score_,\n    },ignore_index=True)\n    \nresult_model","02ffa168":"rf = XGBClassifier(max_depth= 2, eta= 1, objective= 'binary:logistic')\nrf.fit(X_train, y_train)\n\nkfold = model_selection.KFold(n_splits=10, random_state=41)\n\n# Get score:\nresults_k = model_selection.cross_val_score(rf, X, y, cv=kfold, scoring='roc_auc')\nresults_k","925968e3":"from sklearn.model_selection import StratifiedKFold\n\nroc_auc_list = []\nroc_auc_holdout = []\nroc_auc_train = []\nfolds = []\nmodel = XGBClassifier(max_depth= 2, eta= 1, objective= 'binary:logistic')\nkfold = KFold(n_splits=10, random_state=41)\nfor i, (train_index, test_index) in enumerate(kfold.split(X_train)):\n    X1_train, X1_valid = X.iloc[train_index], X.iloc[test_index]\n    y1_train, y1_valid = y[train_index], y[test_index]\n    model.fit(X1_train, y1_train)\n    train_pred = model.predict_proba(X1_train)[:,1] # 70%\n    #Measure of the fit of your model.\n    pred = model.predict_proba(X1_valid)[:,1] # 10%\n    # DATA WHICH MODEL HAS NOT SEEN\n    pred_holdout = model.predict_proba(X_test)[:,1] # 20%\n    \n    print('Prediction length on validation set, XGBoost Classifier, fold ', i, ': ', len(pred))\n\n    folds.append(i)\n    roc_auc_list.append(roc_auc_score(y1_valid, pred))\n    roc_auc_holdout.append(roc_auc_score(y_test, pred_holdout))\n    roc_auc_train.append(roc_auc_score(y1_train, train_pred))","53cd95e0":"roc_auc_train # train","52c7f48a":"roc_auc_holdout # test","81a07f83":"roc_auc_list # val","f60b9170":"# import matplotlib as mpl\n# matplotlib.rcParams.update(mpl.rcParamsDefault)","dc76068d":"rg = np.arange(0.840,0.900,0.005)\n\ntrain_mean = np.mean(roc_auc_train)\ntest_mean = np.mean(roc_auc_holdout)\nval_mean = np.mean(roc_auc_list)\n\ntrain_std = np.std(roc_auc_train)\ntest_std = np.std(roc_auc_holdout)\nval_std = np.std(roc_auc_list)\n\nplt.style.use('tableau-colorblind10')\n\nfig, ax = plt.subplots(figsize=(20,10))\nax.plot(roc_auc_train, label='Train', marker='o', linestyle='-.')\nax.plot(roc_auc_holdout, label='Test', marker='o', linestyle=':')\nax.plot(roc_auc_list, label='Val', marker='o', linestyle='--')\n\ntext_m = '''\n    * Train Mean : ''' + str(format(train_mean, '.5f')) + '''\n    * Test Mean : ''' + str(format(test_mean, '.5f')) + ''' \n    * Val Mean : ''' + str(format(val_mean, '.5f')) + '''     \n'''\n\nax.text(6,0.841,text_m,horizontalalignment='left',color='black',fontsize=16,fontweight='normal')\n\n\ntext_s = '''\n    * Train Standard Deviation : ''' + str(format(train_std, '.5f')) + '''\n    * Test Standard Deviation : ''' + str(format(test_std, '.5f')) + ''' \n    * Val Standard Deviation : ''' + str(format(val_std, '.5f')) + '''     \n'''\n\nax.text(0.5,0.841,text_s,horizontalalignment='left',color='black',fontsize=16,fontweight='normal')\n\n\nax.set_xlabel('No of variable at each split', fontsize=18, labelpad=20)\nax.set_ylabel('ROC_AUC Score', fontsize=18, labelpad=10)\n\nax.set_title('XGBoost - Train, Test, Val Error', pad=20, fontsize=30)\n\nax.legend()\nax.set_yticks(rg)\n\nsns.despine()\n\nplt.savefig('.\/xgb-ttv.jpg')\n\nplt.tight_layout()\n\nplt.show();","2d8e7062":"#\nclf = XGBClassifier()\nclf.fit(X_train, y_train)\n\n#\nclf.feature_importances_\n\n#\nfeature_importances = pd.DataFrame(clf.feature_importances_,\n                                   index = X.columns,\n                                   columns=['importance']).sort_values('importance', ascending=False)\nfeature_importances\n\nfig, ax = plt.subplots(1,1, figsize=(10,15))\nsns.barplot(x='importance', y='index', color='#800000',data=feature_importances.reset_index());\n\nplt.title('Feature Importance', fontsize=30, pad=20)\n\n\nplt.savefig('.\/feature-importance.jpg')\nplt.tight_layout()\nplt.show();","6e110f64":"# from sklearn.model_selection import XGBClassifier\n\n# # Create the parameter grid based on the results of random search \n# param_grid = {\n#     'max_depth': [10,15],\n#     'max_features': [2, 3],\n#     'min_samples_leaf': [3, 4, 5],\n#     'min_samples_split': [3,4,5],\n#     'n_estimators': [100, 200, 300]\n# }\n# # Create a based model\n# rf = RandomForestClassifier()\n# # Instantiate the grid search model\n# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n#                           cv = 3, n_jobs = -1, verbose = 2)\n\n# # Fit the grid search to the data\n# grid_search.fit(X_train,y_train)","126c4d45":"# grid_search.best_estimator_","e2ebb9a1":"# rff = RandomForestClassifier(max_depth=10, max_features=2, min_samples_leaf=5,\n#                        min_samples_split=3)\n# rff.fit(X_train, y_train)\n# y_pred = rff.predict_proba(X_test)\n\n# print('Random Forest Classifier ', roc_auc_score_)","abc33b6b":"# result_model","5f36bfc7":"## 4.4. Multivariate Analysis","89f1b3fe":"![WhatsApp%20Image%202020-12-08%20at%2023.17.36.jpeg](attachment:WhatsApp%20Image%202020-12-08%20at%2023.17.36.jpeg)","212657fe":"#### 4.3.1.1. Visualize Driving License","566a0907":"## 6.3. Cross Validation","34dd9554":"#### 4.3.1.5. Visualize Annual Premium","a271c4ec":"#### 4.3.1.3. Visualize Age","a40a14ad":"## 4.2. Grouping Feature","8df510a3":"## 4.3. Univariate Analysis","8dfd97be":"## 5.1. Feature Engineering","92297968":"#### 4.3.1.2. Visualize Previously Insured","c89ee0d9":"## 6.4. Train, Test, Val Score","f3ddc905":"# 5. Pre-Processing","e9890c70":"### 5.1.7. Drop Feature","3da2a0f1":"### 4.1.2. Non-Numerical Data","76701a35":"#### 4.3.2.3. Visualize Vehicle Damage","b42d1edf":"#### 4.3.1.4. Visualize Vintage","8a3595f5":"# 1. Data Description","f0750e41":"Target Output : Feature <strong>RESPONSE<\/strong>","3c90ed5d":"### 4.3.2. Non-Numerical Data","834b6197":"## 3.3. Non-Numerical data","87cc54b4":"### 5.1.3. Scaling Use StandarScaler","33f6fe12":"## 6.2. Modeling Process","15bc8d18":"### 5.1.5. One Hot Encoding","1207df09":"## 5.2. Splitting Values","808300b6":"#### 4.3.1.6. Visualize Region Code","78ba7623":"## 4.1. Statistika Deskriptif","0543cfdf":"# 8. Tuning Hyperparameter (One Time Running)","4a1ce49b":"### 5.1.2. Duplicate Value","d3350bff":"# 7. Feature Importance","e87b436d":"# 4. Exploratory Data Analyst","ebe5e0fb":"### 5.1.4. Reformat Label","2896d1d4":"## 6.5. Visualize Train, Test, Val Score","1a5970a6":"# 3. Data Understanding","7e9a5dac":"# 6. Modeling","bd00c368":"### 4.3.1. Numerical Data","44a778db":"## 6.1. Define Model","e5377cc9":"## 3.2. Numerical Data","8f6a82f8":"## 3.1. General Information","d74c6322":"### 4.1.1. Numerical Data","cbbf7b17":"### 5.1.6. Rename and Casting Feature","67576038":"#### 4.3.2.2. Visualize Vehicle Age","22428451":"#### 4.3.2.1. Visualize Gender","02c57373":"### 5.1.1. Missing Value","6ace6ec3":"# 2. Data Collection"}}