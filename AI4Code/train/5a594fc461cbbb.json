{"cell_type":{"69bd08cd":"code","f0cc786c":"code","2d6bfa1e":"code","e8dc1eae":"code","7baebbc7":"code","86da4c38":"code","11b3a2b2":"code","559bcb51":"code","709400e2":"markdown","fd835c44":"markdown","4a89f748":"markdown","1202a58f":"markdown","e89e2390":"markdown","2bfcc9d4":"markdown"},"source":{"69bd08cd":"import matplotlib.pyplot as plt\nimport numpy as np","f0cc786c":"def detect_blur_fft(image, size=60, thresh=10, vis=True):\n    (h,w) = image.shape\n    (cX, cY) = (int(w\/2.0), int(h\/2.0))\n    fft = np.fft.fft2(image)\n    fftShift = np.fft.fftshift(fft)\n    # check to see if we are visualizing our output\n    if vis:\n        # compute the magnitude spectrum of the transform\n        magnitude = 20 * np.log(np.abs(fftShift))\n        # display the original input image\n        (fig, ax) = plt.subplots(1, 2, )\n        ax[0].imshow(image, cmap=\"gray\")\n        ax[0].set_title(\"Input\")\n        ax[0].set_xticks([])\n        ax[0].set_yticks([])\n        # display the magnitude image\n        ax[1].imshow(magnitude, cmap=\"gray\")\n        ax[1].set_title(\"Magnitude Spectrum\")\n        ax[1].set_xticks([])\n        ax[1].set_yticks([])\n        # show our plots\n        plt.show()\n    \n    fftShift[cY - size:cY + size, cX - size:cX + size] = 0\n    fftShift = np.fft.ifftshift(fftShift)\n    recon = np.fft.ifft2(fftShift)\n    \n    # compute the magnitude spectrum of the reconstructed image,\n    # then compute the mean of the magnitude values\n    magnitude = 20 * np.log(np.abs(recon))\n    mean = np.mean(magnitude)\n    # the image will be considered \"blurry\" if the mean value of the\n    # magnitudes is less than the threshold value\n    print(mean)\n    return (mean, mean <= thresh)","2d6bfa1e":"!pip install --upgrade imutils\nimport imutils\nimport cv2","e8dc1eae":"!wget \"https:\/\/www.photoshopessentials.com\/newsite\/wp-content\/uploads\/2018\/08\/resize-images-print-photoshop-f.jpg\" -O \"testimage.jpg\"","7baebbc7":"orig = cv2.imread(\".\/testimage.jpg\")\n\n#print(orig)\norig = imutils.resize(orig, width=500)\ngray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n# apply our blur detector using the FFT\n(mean, blurry) = detect_blur_fft(gray, size=60)\n\n# draw on the image, indicating whether or not it is blurry\nimage = np.dstack([gray] * 3)\ncolor = (0, 0, 255) if blurry else (0, 255, 0)\ntext = \"Blurry ({:.4f})\" if blurry else \"Not Blurry ({:.4f})\"\ntext = text.format(mean)\ncv2.putText(image, text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7,color, 2)\nprint(\"[INFO] {}\".format(text))\n# show the output image\n#cv2.imshow(\"Output\", image)\n#cv2.waitKey(0)","86da4c38":"# !pip -q install google-colab\n# from google.colab import files\n# from io import BytesIO\n# from PIL import Image","11b3a2b2":"# INPUT YOUR OWN IMAGE HERE\n# uploaded = files.upload()\n\n# im = Image.open(BytesIO(uploaded['.\/testimage.jpg']))\n\n# #orig = cv2.imread(\".\/testimage.jpg\")\n\n# #print(orig)\n# orig = imutils.resize(orig, width=500)\n# gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n# # apply our blur detector using the FFT\n# (mean, blurry) = detect_blur_fft(gray, size=60)\n\n# # draw on the image, indicating whether or not it is blurry\n# image = np.dstack([gray] * 3)\n# color = (0, 0, 255) if blurry else (0, 255, 0)\n# text = \"Blurry ({:.4f})\" if blurry else \"Not Blurry ({:.4f})\"\n# text = text.format(mean)\n# cv2.putText(image, text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7,color, 2)\n# print(\"[INFO] {}\".format(text))","559bcb51":"orig = cv2.imread(\".\/testimage.jpg\")\n\nimage_blurred = cv2.blur(src=orig, ksize=(15, 15))\nimage_blurred = imutils.resize(image_blurred, width=500)\ngray = cv2.cvtColor(image_blurred, cv2.COLOR_BGR2GRAY)\n# apply our blur detector using the FFT\n(mean, blurry) = detect_blur_fft(gray, size=60)\n\n# draw on the image, indicating whether or not it is blurry\nimage = np.dstack([gray] * 3)\ncolor = (0, 0, 255) if blurry else (0, 255, 0)\ntext = \"Blurry ({:.4f})\" if blurry else \"Not Blurry ({:.4f})\"\ntext = text.format(mean)\ncv2.putText(image, text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7,color, 2)\nprint(\"[INFO] {}\".format(text))\n","709400e2":"# APPLICATION USING FOURIER TRANSFORM : BLUR DETECTION\n\nhttps:\/\/www.pyimagesearch.com\/2020\/06\/15\/opencv-fast-fourier-transform-fft-for-blur-detection-in-images-and-video-streams\/","fd835c44":"# Lets check by  blurring the image","4a89f748":"Lets get an image to test.\n\n![](https:\/\/www.photoshopessentials.com\/newsite\/wp-content\/uploads\/2018\/08\/resize-images-print-photoshop-f.jpg)","1202a58f":"# THE FOURIER TRANSFORM\n\nThe Fourier Transform is an important image processing tool which is used to decompose an image into its sine and cosine components. The output of the transformation represents the image in the Fourier or frequency domain, while the input image is the spatial domain equivalent. In the Fourier domain image, each point represents a particular frequency contained in the spatial domain image.\n\nThe Fourier Transform is used in a wide range of applications, such as image analysis, image filtering, image reconstruction and image compression.\n\n![](https:\/\/i.ytimg.com\/vi\/4gp-3pFFyPk\/hqdefault.jpg)","e89e2390":"\nWhat is the Fast Fourier Transform (FFT)?\n\nThe FFT is useful in many disciplines, ranging from music, mathematics, science, and engineering. For example, electrical engineers, particularly those working with wireless, power, and audio signals, need the FFT calculation to convert time-series signals into the frequency domain because some calculations are more easily made in the frequency domain. Conversely, a frequency domain signal could be converted back into the time domain using the FFT.\n\nIn terms of computer vision, we often think of the FFT as an image processing tool that represents an image in two domains:\n\n1. Fourier (i.e., frequency) domain\n2. Spatial domain","2bfcc9d4":"More detailed input on fourier analysis: https:\/\/homepages.inf.ed.ac.uk\/rbf\/HIPR2\/fourier.htm"}}