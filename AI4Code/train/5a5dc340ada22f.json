{"cell_type":{"d85ae06d":"code","d12b9dc2":"code","c4ae84c9":"code","2f58e649":"code","31f5379a":"code","d0276baf":"code","023f0280":"code","ea8e95c7":"code","3699a54e":"code","bc577b50":"code","b34b0a53":"code","a81bc1b2":"code","60f248bc":"code","31e6eee9":"code","51d3db99":"code","89ed6db1":"code","f017366f":"code","4017e227":"code","e0795cdf":"code","8b31b3f2":"code","b48f534e":"code","e604aa0f":"code","2eac54cb":"code","9083f6e7":"code","10dd2bbb":"code","a2f839e1":"code","c857bca3":"code","d1ba075d":"code","a4c3c50c":"code","799c92ff":"code","b9734203":"code","38f50e89":"code","86dfe1d5":"code","6cd7f08c":"code","892142b3":"code","2e1a1a1a":"code","d19fde10":"code","d14448f6":"code","e53a8b10":"code","83609d7a":"code","09faf1c7":"code","ac2e1127":"code","4d4d8549":"code","980a6c43":"code","0563c52b":"code","cd099313":"code","17823022":"code","ccc62e28":"code","ffc75876":"code","a039d351":"code","b278b3ee":"code","238d0a90":"code","3b29c876":"code","b6ba5997":"code","1fa492da":"code","17a508bc":"code","c6b93e7e":"code","173b6daa":"code","57d28231":"code","9c7f1c3d":"code","e622d3dd":"code","8d06c47a":"code","dfd99212":"code","b0ca06dd":"markdown","b9be4505":"markdown","ca79de48":"markdown","a2fdd2d5":"markdown","a76799c5":"markdown","a3ae2f20":"markdown","a8a2e628":"markdown","7c09a464":"markdown","c4a1b494":"markdown","111c3378":"markdown","6ae3fd1b":"markdown","a39c82cd":"markdown","5a5090ed":"markdown","d1e5e5a4":"markdown","dda0ff76":"markdown","9841a247":"markdown","16a27e18":"markdown","a9107c77":"markdown","fd58dc45":"markdown","abd0429f":"markdown","7e26bed9":"markdown","e1205d9b":"markdown","c99bfcc4":"markdown","c3fccb63":"markdown","76dfe616":"markdown","3cb55f7b":"markdown","3e3f4917":"markdown","b2ecb7f3":"markdown","1a360f00":"markdown","ab395d90":"markdown","bedd2ee1":"markdown","c1cfb6d7":"markdown","94eab292":"markdown","8c6b7938":"markdown","3268844c":"markdown","1fae496e":"markdown","a112f99e":"markdown","a42f7748":"markdown","74114a04":"markdown","1e6ff01a":"markdown","8abeca13":"markdown","51cf0348":"markdown","3d88bd2f":"markdown","b528c825":"markdown","557df376":"markdown","3ae6945b":"markdown","c428dc44":"markdown"},"source":{"d85ae06d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d12b9dc2":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","c4ae84c9":"train.drop('Id', inplace = True, axis =1)\ntest.drop('Id', inplace = True, axis =1)\n","2f58e649":"train.head()","31f5379a":"test.head()","d0276baf":"#variable change for later use\ntest_A = test","023f0280":"corr_overall = train.corr()\nk=12\n\ncol = corr_overall.nlargest(k, 'SalePrice')['SalePrice'].index\ncorr_coeff = np.corrcoef(train[col].values.T)\nax = plt.subplots(figsize=(20,15))\nheatmap = sns.heatmap(corr_coeff, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size':12}, yticklabels=col.values, xticklabels=col.values)","ea8e95c7":"train.shape","3699a54e":"fig, plot = plt.subplots()\nplot.scatter(x= train['OverallQual'], y= train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('OverallQual', fontsize=13)\nplt.show()","bc577b50":"fig, plot = plt.subplots()\nplot.scatter(x= train['GrLivArea'], y= train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","b34b0a53":"train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index) #drop rows that meet this criteria","a81bc1b2":"fig, plot = plt.subplots()\nplot.scatter(x= train['GrLivArea'], y= train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","60f248bc":"train.shape","31e6eee9":"train_A = train.drop(['SalePrice'], axis=1)\ny = pd.DataFrame(train['SalePrice'])\nfeatures = pd.concat([train_A, test_A]).reset_index(drop=True)","51d3db99":"features.head()","89ed6db1":"#function to plot the distribution of a variable. Returns the distribution, skeweness and kurtosis\ndef distribution(df,column_name):\n    \n    sns.distplot(df[column_name], color = 'b',kde = True)\n    plt.title('Distribution of ' + column_name)\n    plt.xlabel(column_name)\n    plt.ylabel('Number of occurences')\n    \n    #skewness\n    skewness = df[column_name].skew()\n    if (skewness > -0.5) & (skewness < 0.5):\n        print('The data is fairly symmetrical with skewness of ' + str(skewness))\n    elif ((skewness > -1) & (skewness < -0.5))| ((skewness > 0.5) & (skewness < 1)):\n        print('The data is moderately skewed with skewness of ' + str(skewness))\n    elif (skewness < -1) | (skewness > 1):\n        print('The data is highly skewed with skewness of ' + str(skewness))\n    #kurtosis    \n    print('The kurtosis is ' + str(df[column_name].kurt()))\n","f017366f":"distribution(y,'SalePrice')","4017e227":"y_log = pd.DataFrame(np.log1p(y['SalePrice']))\ndistribution(y_log,'SalePrice')","e0795cdf":"numerical_features = features.dtypes[features.dtypes != \"object\"].index\ncategorical_features = features.dtypes[features.dtypes == \"object\"].index\n\nnumerical_df = features[numerical_features]\ncategorical_df = features[categorical_features]","8b31b3f2":"features_na = (features.isnull().sum() \/ len(features)) * 100\n#drop features without missing values\nfeatures_na = features_na.drop(features_na[features_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :features_na})\n\n#plot\nf, ax = plt.subplots(figsize=(10, 8))\nsns.barplot(x=features_na.index, y=features_na)\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent', fontsize=15)\nplt.xticks(rotation='90')\nplt.title('Percent of missing data by feature', fontsize=15)\n","b48f534e":"#mean\ndef fill_na_num_mean(df,column_name):\n\n    df[column_name] = df[column_name].transform(lambda x: x.fillna(round(x.mean(),1)))\n    \n    return df\n#median\ndef fill_na_num_median(df,column_name):\n\n    df[column_name] = df[column_name].transform(lambda x: x.fillna(round(x.median(),1)))\n    \n    return df\n\n#Nan to None\ndef fill_na_cat_none(df,column_name):\n    df[column_name].fillna('None',inplace=True)\n    \n#Nan to 0 \ndef fill_na_num_0(df,column_name):\n    df[column_name].fillna(0,inplace=True)\n    \n#mode\ndef fill_na_mode(df,column_name):\n    df[column_name].fillna(df[column_name].mode()[0], inplace = True)\n    ","e604aa0f":"quantitative = [f for f in features.columns if features.dtypes[f] != 'object'] #numerical\nqualitative = [f for f in features.columns if features.dtypes[f] == 'object'] #categorical\n\nf = pd.melt(features, value_vars=quantitative)\ng = sns.FacetGrid(f, col=\"variable\", col_wrap=4, sharex=False, sharey=False)\ng = g.map(sns.distplot, \"value\")","2eac54cb":"features.drop(['MiscFeature'], inplace = True, axis = 1)\nfeatures.drop(['MiscVal'], inplace = True, axis = 1)","9083f6e7":"features.drop(['Fence'], inplace = True, axis =1)\nfeatures.drop(['Alley'], inplace = True, axis = 1)\nfeatures.drop(['PoolQC'], inplace = True, axis = 1)\nfeatures.drop(['PoolArea'], inplace = True, axis =1)","10dd2bbb":"plt.hist(features['LotFrontage'])\nplt.show()\n\n#skewness\nskewness = features['LotFrontage'].skew()\nif (skewness > -0.5) & (skewness < 0.5):\n    print('The data is fairly symmetrical with skewness of ' + str(skewness))\nelif ((skewness > -1) & (skewness < -0.5))| ((skewness > 0.5) & (skewness < 1)):\n    print('The data is moderately skewed with skewness of ' + str(skewness))\nelif (skewness < -1) | (skewness > 1):\n    print('The data is highly skewed with skewness of ' + str(skewness))\n        \n#kurtosis\nprint('The kurtosis is ' + str(features['LotFrontage'].kurt()))","a2f839e1":"fill_na_mode(features,'LotFrontage')","c857bca3":"features[['MasVnrArea','MasVnrType']].head()\n","d1ba075d":"fill_na_cat_none(features,'MasVnrType') \nfill_na_num_0(features,'MasVnrArea')\n","a4c3c50c":"features[['BsmtFinSF2','BsmtFinType2']].head()","799c92ff":"\nfill_na_num_0(features,'BsmtFinSF2')\n\nfeatures[['BsmtFinSF1','BsmtFinType1']].head()\n","b9734203":"\nfeatures[['BsmtUnfSF','BsmtFinType1','BsmtFinType2']].head()","38f50e89":"fill_na_cat_none(features,'BsmtFinType1')\nfill_na_num_0(features,'BsmtFinSF1')\nfill_na_cat_none(features,'BsmtFinType2')\nfill_na_num_0(features,'BsmtFinSF2')\n\nfeatures[['TotalBsmtSF','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF']].head()","86dfe1d5":"fill_na_num_0(features,'TotalBsmtSF')\nfill_na_num_0(features,'BsmtUnfSF')","6cd7f08c":"features[['BsmtFullBath','BsmtHalfBath','TotalBsmtSF']].head()","892142b3":"fill_na_num_0(features,'BsmtFullBath')\nfill_na_num_0(features,'BsmtHalfBath')","2e1a1a1a":"features[['GarageType','GarageFinish','GarageCars','GarageArea','GarageQual','GarageCond']].head()","d19fde10":"features.drop('GarageYrBlt', inplace = True, axis = 1)\nfeatures.drop(['Utilities'], axis=1, inplace = True)\n\nfill_na_cat_none(features,'GarageType')\nfill_na_cat_none(features,'GarageFinish')\nfill_na_cat_none(features,'GarageQual')\nfill_na_cat_none(features,'GarageCond')\n\n\nfill_na_num_0(features,'GarageCars')\nfill_na_num_0(features,'GarageArea')","d14448f6":"new_numerical_features = features.dtypes[features.dtypes != \"object\"].index\n\nnew_categorical_features = features.dtypes[features.dtypes == \"object\"].index\n\nnew_num_df = features[new_numerical_features]\nnew_cat_df = features[new_categorical_features]\n\nfeatures[['BsmtQual','BsmtCond','BsmtExposure','TotalBsmtSF']].head()","e53a8b10":"fill_na_cat_none(features,'BsmtExposure')\nfill_na_cat_none(features,'BsmtCond')\nfill_na_cat_none(features,'BsmtQual')\nfill_na_mode(features,'MSZoning')\nfill_na_mode(features,'SaleType')\nfill_na_mode(features,'KitchenQual')\nfill_na_mode(features,'Electrical')\nfill_na_mode(features,'Exterior1st')\nfill_na_mode(features,'Exterior2nd')\nfill_na_mode(features,'Functional')\n\nfeatures[['FireplaceQu','Fireplaces']].head()","83609d7a":"fill_na_cat_none(features,'FireplaceQu')","09faf1c7":"features.head()","ac2e1127":"#encounding categorical data (ordinal)\nfeatures['LandContour'] = features['LandContour'].replace(dict(Lvl=4, Bnk=3, HLS=2, Low=1))\nfeatures['LandSlope'] = features['LandSlope'].replace(dict(Gtl=3, Mod=2, Sev=1))\nfeatures['ExterQual'] =features['ExterQual'].replace(dict(Ex=5, Gd=4, TA=3, Fa=2, Po=1))\nfeatures['ExterCond'] =features['ExterCond'].replace(dict(Ex=5, Gd=4, TA=3, Fa=2, Po=1))\nfeatures['BsmtQual'] = features['BsmtQual'].replace(dict(Ex=5, Gd=4, TA=3, Fa=2, Po=1))\nfeatures['BsmtCond'] =features['BsmtCond'].replace(dict(Ex=5, Gd=4, TA=3, Fa=2, Po=1))\nfeatures['BsmtCond'] =features['BsmtCond'].replace('None',0)\nfeatures['BsmtExposure'] =features['BsmtExposure'].replace(dict(Gd=4, Av=3, Mn=2, No=1))\nfeatures['BsmtExposure'] =features['BsmtExposure'].replace('None',0)\nfeatures['BsmtFinType1'] = features['BsmtFinType1'].replace(dict(GLQ=6, ALQ=5, BLQ=4, Rec=3, LwQ=2, Unf=1))\nfeatures['BsmtFinType1'] =features['BsmtFinType1'].replace('None',0)\nfeatures['BsmtFinType2'] = features['BsmtFinType2'].replace(dict(GLQ=6, ALQ=5, BLQ=4, Rec=3, LwQ=2, Unf=1))\nfeatures['BsmtFinType2'] = features['BsmtFinType2'].replace('None',0)\nfeatures['HeatingQC'] = features['HeatingQC'].replace(dict(Ex=5, Gd=4, TA=3, Fa=2, Po=1))\nfeatures['CentralAir'] = features['CentralAir'].replace(dict(Y=1, N=0))\nfeatures['KitchenQual'] =features['KitchenQual'].replace(dict(Ex=5, Gd=4, TA=3, Fa=2, Po=1))\nfeatures['Functional'] = features['Functional'].replace(dict(Typ=8, Min1=7, Min2=6, Mod=5, Maj1=4, Maj2=3, Sev=2, Sal=1))\nfeatures['FireplaceQu'] = features['FireplaceQu'].replace(dict(Ex=5, Gd=4, TA=3, Fa=2, Po=1))\nfeatures['FireplaceQu'] = features['FireplaceQu'].replace('None', 0)\nfeatures['GarageQual'] = features['GarageQual'].replace(dict(Ex=5, Gd=4, TA=3, Fa=2, Po=1))\nfeatures['GarageQual'] =features['GarageQual'].replace('None', 0)\nfeatures['GarageCond'] = features['GarageCond'].replace(dict(Ex=5, Gd=4, TA=3, Fa=2, Po=1))\nfeatures['GarageCond'] = features['GarageCond'].replace('None', 0)\nfeatures['LotShape'] = features['LotShape'].replace(dict(Reg=4, IR1=3, IR2=2, IR3=1))\nfeatures['GarageFinish'] = features['GarageFinish'].replace(dict(Fin=3, RFn=2, Unf=1))\nfeatures['GarageFinish'] = features['GarageFinish'].replace('None', 0)\nfeatures['PavedDrive'] =features['PavedDrive'].replace(dict(Y=3, P=2, N=1))\nfeatures =features.astype({\"Functional\": int})","4d4d8549":"features['BsmtQual'] =features['BsmtQual'].replace('None',0)#assigning 0 to none to turn the object into an int\nfeatures =features.astype({\"KitchenQual\": int})\nfeatures =features.astype({\"Functional\": int})\n\n","980a6c43":"#dummy variables of none ranked columns\nfeatures['MSSubClass'] =features['MSSubClass'].astype('category')\nfeatures['MoSold'] = features['MoSold'].astype('category')\nfeatures['YrSold'] =features['YrSold'].astype('category')\ncat_cols = ['MSZoning','Street','MSSubClass', 'MoSold', 'YrSold', 'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating', 'Electrical', 'GarageType', 'SaleType', 'SaleCondition']\ndumies=pd.get_dummies(features[cat_cols],drop_first=True)\ndumies.head()","0563c52b":"for column in cat_cols:\n    features.drop([column],axis=1,inplace=True)","cd099313":"features=pd.concat([ features,dumies],axis=1)\nfeatures.head()","17823022":"features.dtypes","ccc62e28":"new_train = features.iloc[:1458, :]\nnew_test = features.iloc[1458:,:]\n\nX_test = new_test\nX_train = new_train\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_train)\n","ffc75876":"X_standardize = pd.DataFrame(X_scaled, columns = X_train.columns)\nX_standardize.head()","a039d351":"X_standardize.describe().loc['std']","b278b3ee":"from sklearn.linear_model import Ridge\nfrom sklearn import metrics\n\nridge = Ridge()\nridge.fit(X_train, y_log)\n\ny_sale = ridge.predict(X_test)\ny_predict_ridge = np.expm1(y_sale)\nsubmission = pd.DataFrame(y_predict_ridge)\n\n#creating submission file\nsample = pd.read_csv('..\/input\/sample_submission.csv')\nsample['SalePrice']=submission[0]\nsample.to_csv('Ridge.csv',index = False)","238d0a90":"#train predict\ny_train = ridge.predict(X_train)","3b29c876":"from sklearn.linear_model import Lasso,ElasticNet\nfrom sklearn import metrics","b6ba5997":"lasso = Lasso(alpha=0.01)\nlasso.fit(X_train, y_log)\n\ny_lasso_pred = lasso.predict(X_test)\nlasso_predict = np.expm1(y_lasso_pred)\nsubmission = pd.DataFrame(lasso_predict)\n\n#creating submission file\nsample = pd.read_csv('..\/input\/sample_submission.csv')\nsample['SalePrice']=submission[0]\nsample.to_csv('Lasso.csv',index = False)","1fa492da":"y_lasso_train = lasso.predict(X_train)","17a508bc":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n\nENet.fit(X_train, y_log)\nENet_train_pred = ENet.predict(X_train)\n\nENet_pred = np.expm1(ENet.predict(X_test))\nsub = pd.DataFrame(ENet_pred)\n\nsub.head()\n\n#creating submission file\nsample = pd.read_csv('..\/input\/sample_submission.csv')\nsample['SalePrice']=sub[0]\nsample.to_csv('Enet.csv',index = False)\n","c6b93e7e":"ridge.score(X_train,y_log)","173b6daa":"ENet.score(X_train,y_log)","57d28231":"lasso.score(X_train,y_log)","9c7f1c3d":"print('Ridge MSE: ',metrics.mean_squared_error(y_log,y_train))","e622d3dd":"print('Enet MSE: ',metrics.mean_squared_error(y_log,ENet_train_pred))","8d06c47a":"print('Lasso MSE: ',metrics.mean_squared_error(y_log,y_lasso_train))","dfd99212":"plt.scatter(np.arange(len(y_log)), ENet_train_pred, label='Predicted')\nplt.scatter(np.arange(len(y_log)), y_log, label='Training')\n\nplt.legend()\nplt.show()","b0ca06dd":"Basement exposure has NaN on line 948,1498,2348,1487, but theres a basement.missing value\nline 2524,2185,2040 bsmscond NaN but there is a basement\nNaN on BsmntQl but theres a basement, line 2217,2218\n\nSolution: replace all valaues with most frequent where Total area of basement is not 0\ncols most likely correlated, could predict outcome of the other?\n\nsaletype-most frequent\n","b9be4505":"We are now done with numerical data. We Fill the remaining missing data","ca79de48":"# Preparing the dataset for the model\nWe need to separate our dataset back into train and test\n\nLooking at the data set we see that the scale is different. We need to standardise our variables to have the same scale to better predict the response variable.","a2fdd2d5":"# Visualising missing data\n\nWe plot the missing data to show how many missing values we will have to deal with.","a76799c5":"From the above plots, We see that MiscFeature will not serve our model any purpose so we remove it as well as MiscValue (most of these are 0)","a3ae2f20":"Total sq feet for multiple basements including unfinished. Total is dependent on 3 variables\nNan in Total due to no basement is replaced with 0.","a8a2e628":"Here NaN mean NONE-no basement. sq feet here is 0 for all NaN BsmtFinSF2,correlating column is also NaN for presence of bsmt\nNan replaced with None","7c09a464":"Looking at the barplot we see that some features look to have 0 missing features. This is not the case. Those are features that have 1 or just a few missing values.","c4a1b494":"NaN means no garage in categorical. so 0 for corresponding columns\nOne detatched garageType but NaN everywhere. decision to keep value as 0.\n\nWe would also like to drop GarageYrBlt because it has less influence on the house price.\nWe also drop Utilities because almost all records are \"AllPub\" except for one which is 'NoSeWa' and 2 NAs, this is in the training set, therefore will not affect the predictions of the test dataset.","111c3378":"# Introduction\n\nThe aim of this notebook is to predict the sale price of houses in Ames Iowa given features of a house. In order to do this, we will need statistical libraries, the dataset which we sourced from www.kaggle.com\/c\/house-prices-advanced-regression-techniquesand ,perform exploratory data analysis and feature engineering on the dataset to prepare our data for the model. We have chosen to use 3 techniques namely Ridge, Lasso and ENet to train and predict our dataset. We will then decide which one best predicts our test dataset.","6ae3fd1b":"#Let's look at what our train and test data looks like.","a39c82cd":"# Enet","5a5090ed":"# Conclusion\n\nWe see that the R^2 value of Ridge is better than the rest as well as the Mean square error of the train. But Ridge did not perform better than Enet on the test response variable on kaggle. So we have chosen Enet as our Technique that best predicted the SalePrice. The scatter plot shows that our predictions are not far off from the actual sale price in the train dataset.","d1e5e5a4":"Nan also replaced with 0 for sq feet","dda0ff76":"# Distributions of independent variables\n\nBefore we replace missing values we would first like to visualise the distributions of the independent variables.","9841a247":"# Removing outliers","16a27e18":"Our response variable is now somewhat normal which is good for our model accuracy because we will now work with a known distribution.","a9107c77":"We inspect the scatter plot for any outliers in OverallQual vs SalePrice. But first let's look at the shape of our dataset","fd58dc45":"# Exploratory Data Analysis\nThe Id column serves no purpose in our model so we drop it.","abd0429f":"# Functions to replace missing values\n\nSome Nan values are missing and some are actually 0 because the feature is not present.","7e26bed9":"# Replace missing values","e1205d9b":"We check our train size again and we find that 2 rows have been removed.","c99bfcc4":"# Lasso","c3fccb63":"# Preparing the data for cleaning\nWe first merge the train and test dataset and drop the Id column because it has no value to our model.","76dfe616":"# Creating dummy variables","3cb55f7b":"It looks like we still have extreme values. The distribution is skewed to the right. In statistics it it better to work with known distributions when we are trying to make predictions. Our dataset is enough for us to normalise it. We use the log function to try and normalise our distribution.","3e3f4917":"We observe extreme outliers in this relationship where the ground living area is between 4000 and 6000 and the sale price is under 300000. We need to remove these kinds of unusual observation in our dataset because they can cause overfitting.","b2ecb7f3":"We now check whether there is a basement by checking the value of the basement square feet in order to replace Nan values or baths in the basement.","1a360f00":"from the above we see that BsmtFinType1 and BsmtFinType2 has None as a category from the data description provided.\nFor the square feet we replace with 0 for corresponding basement type.","ab395d90":"The dataset looks to be on a similar scale. We also see that the all have the same standard deviation, which is good for our prediction.","bedd2ee1":"We see that Overall Quality of the house and GrLivArea (Ground living area) are highly correlated with the saleprice by 0.79 and 0.71 respectively. We use these two independent variables to inspect any unusual observations.","c1cfb6d7":"Our variables are no longer objects","94eab292":"The distribution is highly skewed and there are outliers. Replacing with the mean doesnt seem to be the best strategy since this is not a normal distribution. We can therefore think about this in terms of the area of interest. Usually housing developments around the same area have the same lot area and frontage. We can use the mode to replace these missing values.","8c6b7938":"Kurtose is the measure of peakness in the distribution. Identifying outliers calls for investigating why the data contains such extreme values.It Could be incorrect entries or other things to help us understand the data better or even remove this incorrect information. Note that we have already removed 2 outliers in our training dataset, we now look at the distribution of the SalePrice.","3268844c":"Now we look at our new merged dataset","1fae496e":"Lets now look at LotFrontage. We investigate the distribution so we can make an informed decision on how to replace the missing values\n","a112f99e":"# MSE\n","a42f7748":"We now separate our data into numerical and categorical data.","74114a04":"# Importing additional libraries and the dataset","1e6ff01a":" If there is no basement present the value of the square feet is zero","8abeca13":"Lets now look at our new dataset for the training data.","51cf0348":"# Model Selection\n\nFor this dataset, we will use 3 techniques to predict the test response variable and choose the one which best predicts this dependent variable.","3d88bd2f":"Let's now dive into replacing missing values. We focus more on numerical data first, but we will also check relating categorical columns simultaneously.\n\nWe replace Nan with mode for MasVnrType, replace Nan with 0 for MasVnrArea","b528c825":"There are too many Nans that mean None for Fence, Alley and PoolQc. We decide to remove these variables because they will not affect our saleprice much.","557df376":"# Ridge regression","3ae6945b":"# Correlation using Heapmap\nWe want to visualise pairwise correlations between independent variables and the dependent variable","c428dc44":"We decide to not remove any outliers for this because they do not look to be too extreme and the price of the house could be because of the ground living area as this also influences house prices.\n\nGrLivArea = 1stFlrSF + 2ndFlrSF and this is a good indicator for predicting a house price. So we try and look for outliers to remove."}}