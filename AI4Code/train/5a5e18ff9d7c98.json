{"cell_type":{"8b58acde":"code","3abba800":"code","e92a56a1":"code","624a79cb":"code","feef8f33":"code","0cede71c":"code","9728ccae":"code","7759de64":"code","17af3771":"code","4e5ab565":"code","5c00b967":"code","80917002":"code","92a3c4f4":"code","b85dd343":"code","6264cb02":"code","203e49c4":"code","fe7fa185":"code","082ad1d5":"code","1dda9a08":"code","1ef347ed":"code","bccca7b2":"code","30cc0aaa":"code","9f7c2810":"code","6ef586df":"code","130376a8":"code","a4b4ef5d":"code","e099b0e3":"code","7454a60c":"code","998dbe0b":"code","50cff435":"code","730365c6":"code","82e00728":"code","0952db00":"code","a8ee1c06":"code","ece91e13":"code","5bcdba39":"code","1329c7f6":"code","b019d8c7":"code","86b41340":"code","668f0473":"code","bcda171e":"code","9990e24c":"code","15600c00":"code","0291b6fe":"code","c7018f95":"code","80d93c81":"code","9c965bd4":"code","227b9bb4":"code","baaa6f84":"code","e62364cd":"code","d2a64b81":"code","b7fe7e5a":"code","55f6c720":"code","fab945e4":"code","694c1f8c":"code","fcfe526e":"code","a6595771":"code","d55ec811":"code","cc1d4f91":"code","907185c1":"code","5696fbc5":"code","52af7d88":"code","95d06a95":"markdown","0117c826":"markdown","7f64f74f":"markdown","cfdb52f5":"markdown","3cce9dde":"markdown","14a461cd":"markdown","352d12f1":"markdown","9cdf9fdd":"markdown","dba7a7c8":"markdown","ff2dc1a3":"markdown","4267113b":"markdown","2c360a38":"markdown","aa60d7e3":"markdown","1c0d9daa":"markdown","6c00da01":"markdown","44d04451":"markdown","8b1b771b":"markdown","22e721f3":"markdown","f282e39c":"markdown","12a0eecf":"markdown","3019bcf0":"markdown","72791901":"markdown","370f3f39":"markdown","6af57666":"markdown","c4450809":"markdown","0e093ba5":"markdown","2528f472":"markdown","5f53e1de":"markdown","3b4010cd":"markdown","b86414e4":"markdown","36bae185":"markdown","2a42b669":"markdown","28e60c92":"markdown","2a13a1e9":"markdown","f871776b":"markdown","11f3b9cf":"markdown","13327ee9":"markdown","987ae317":"markdown","9b1df6df":"markdown","06704b33":"markdown","744427cb":"markdown","21946c02":"markdown","cf97e38e":"markdown","c10d1dfa":"markdown","d5d65593":"markdown","ac4c638f":"markdown"},"source":{"8b58acde":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3abba800":"data = pd.read_csv(\"\/kaggle\/input\/indian-liver-patient-records\/indian_liver_patient.csv\")","e92a56a1":"data.head()","624a79cb":"data.info()","feef8f33":"#Renaming the columns.\n\ndata.rename(columns={'Dataset': 'target', 'Alamine_Aminotransferase': 'Alanine_Aminotransferase', 'Total_Protiens': 'Total_Proteins'}, inplace = True)","0cede71c":"data.target.unique()","9728ccae":"data.target = [0 if each == 2 else 1 for each in data.target]","7759de64":"#Data contains object variables, I want integers or float variables.\n\ndata.Gender = [1 if each == 'Male' else 0 for each in data.Gender]","17af3771":"data.dtypes","4e5ab565":"data.isna().sum()","5c00b967":"#Filling null values.\ndata['Albumin_and_Globulin_Ratio'].mean()","80917002":"data.fillna(0.94, inplace = True)","92a3c4f4":"data.info()","b85dd343":"correlation = data.corr()\nfig, ax = plt.subplots(figsize=(12,12))\nsns.heatmap(correlation, annot = True, linewidths = 0.5, ax = ax)\nplt.show()","6264cb02":"list_ = [\"Age\", \"Total_Bilirubin\", \"Direct_Bilirubin\", \"target\"]\n\nsns.heatmap(data[list_].corr(), annot = True, fmt = \".2f\")\nplt.show()","203e49c4":"list2 = [\"Alkaline_Phosphotase\", \"Alanine_Aminotransferase\", \"Aspartate_Aminotransferase\", \"Total_Proteins\", \"target\"]\nsns.heatmap(data[list2].corr(), annot = True, fmt = \".2f\")\nplt.show()","fe7fa185":"list3 = [\"Albumin_and_Globulin_Ratio\", \"Albumin\", \"target\"]\nsns.heatmap(data[list3].corr(), annot = True, fmt = \".2f\")\nplt.show()","082ad1d5":"f, axes = plt.subplots(1, 2, figsize = (12, 8))\n\nsns.countplot(x = \"target\", data = data, ax=axes[0])\nsns.countplot(x = \"target\", hue = 'Gender', data = data, ax=axes[1])\nplt.show()","1dda9a08":"print(\"Number of people who suffers from liver disease: {}\" .format(data.target.value_counts()[1]))\nprint(\"Number of people who does not suffer from liver disease: {}\" .format(data.target.value_counts()[0]))","1ef347ed":"g = sns.FacetGrid(data, col = \"target\", height = 7)\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","bccca7b2":"#I want to add a column showing globulin values.\n\nratio = data.Albumin_and_Globulin_Ratio.values\nalbumin = data.Albumin.values\nglobulin = []\nfor i in range(0, 583):\n    globulin.append(float(\"{:.2f}\".format(albumin[i] \/ ratio [i])))","30cc0aaa":"data.insert(9, 'Globulin', globulin, True)","9f7c2810":"data.head()","6ef586df":"g = sns.FacetGrid(data, col = \"target\", row = \"Gender\", height = 5)\ng.map(plt.hist, \"Albumin\", bins = 25)\nplt.show()","130376a8":"g = sns.FacetGrid(data, col = \"target\", row = \"Gender\", height = 5)\ng.map(plt.hist, \"Globulin\", bins = 25)\nplt.show()","a4b4ef5d":"g = sns.FacetGrid(data, col = \"target\", row = \"Gender\", height = 5)\ng.map(plt.hist, \"Albumin_and_Globulin_Ratio\", bins = 25)\nplt.show()","e099b0e3":"patient = data[data.target == 1]\nhealthy = data[data.target != 1]\n\ntrace0 = go.Scatter(\n    x = patient['Total_Bilirubin'],\n    y = patient['Direct_Bilirubin'],\n    name = 'Patient',\n    mode = 'markers', \n    marker = dict(color = '#616ADE',\n        line = dict(\n            width = 1)))\n\ntrace1 = go.Scatter(\n    x = healthy['Total_Bilirubin'],\n    y = healthy['Direct_Bilirubin'],\n    name = 'healthy',\n    mode = 'markers',\n    marker = dict(color = '#F3EC1F',\n        line = dict(\n            width = 1)))\n\nlayout = dict(title = 'Total Bilirubin vs Conjugated Bilirubin',\n              yaxis = dict(title = 'Conjugated Bilirubin', zeroline = False),\n              xaxis = dict(title = 'Total Bilirubin', zeroline = False)\n             )\n\ndata2 = [trace0, trace1]\n\nfig = go.Figure(data=data2,\n                layout=layout)\n\nfig.show()","7454a60c":"g = sns.FacetGrid(data, col = \"target\", height = 7)\ng.map(sns.distplot, \"Alkaline_Phosphotase\", bins = 25)\nplt.show()","998dbe0b":"g = sns.FacetGrid(data, col = \"target\", height = 7)\ng.map(sns.distplot, \"Alanine_Aminotransferase\", bins = 25)\nplt.show()","50cff435":"g = sns.FacetGrid(data, col = \"target\", height = 7)\ng.map(sns.distplot, \"Aspartate_Aminotransferase\", bins = 25)\nplt.show()","730365c6":"g = sns.FacetGrid(data, col = \"target\", height = 7)\ng.map(sns.distplot, \"Total_Proteins\", bins = 25)\nplt.show()\n\nprint(\"Mean of the total protein level in patiens:\", float(\"{:.2f}\".format( data['Total_Proteins'][data.target == 1].mean())))\nprint(\"Mean of the total protein level in healthy people:\", float(\"{:.2f}\".format(data['Total_Proteins'][data.target == 0].mean())))","82e00728":"#Importing necessary libraries\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix","0952db00":"#I want to store the scores in a dictionary to see which prediction method works best.\n\nscores = {}","a8ee1c06":"data = data.drop(columns = ['Total_Proteins', 'Age', 'Gender'])","ece91e13":"y = data.target.values\nx_ = data.drop(columns = [\"target\"])","5bcdba39":"#Normalisation\nx = ((x_ - np.min(x_)) \/ (np.max(x_) - np.min(x_))).values","1329c7f6":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)","b019d8c7":"x_train = x_train.T\ny_train = y_train.T\nx_test = x_test.T\ny_test = y_test.T","86b41340":"def initialise(dimension):\n    \n    weight = np.full((dimension,1),0.01)\n    bias = 0.0\n    return weight,bias","668f0473":"def sigmoid(z):\n    y_head = 1\/(1 + np.exp(-z))\n    return y_head","bcda171e":"def forward_backward(weight, bias, x_train, y_train):\n    z = np.dot(weight.T, x_train) + bias\n    y_head = sigmoid(z)\n    loss = -((y_train * np.log(y_head)) + ((1 - y_train) * np.log(1 - y_head)))\n    cost = (np.sum(loss))\/x_train.shape[1]\n    \n    derivative_weight = (np.dot(x_train,((y_head - y_train).T)))\/x_train.shape[1]\n    derivative_bias = np.sum(y_head - y_train)\/x_train.shape[1]\n    gradients = {\"derivative_weight\": derivative_weight,\"derivative_bias\": derivative_bias}\n    \n    return cost, gradients\n\ndef update(weight, bias, x_train, y_train, learning_rate, number_of_iterarion):\n    cost_list = []\n    cost_list2 = []\n    index = []\n    \n    for i in range(number_of_iterarion):\n        cost, gradients = forward_backward(weight, bias, x_train, y_train)\n        cost_list.append(cost)\n        \n        weight = weight - learning_rate * gradients[\"derivative_weight\"]\n        bias = bias - learning_rate * gradients[\"derivative_bias\"]\n        \n        if i % 10 == 0:\n            cost_list2.append(cost)\n            index.append(i)\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n            \n    parameters = {\"weight\": weight, \"bias\": bias}\n    plt.plot(index, cost_list2)\n    plt.xticks(index, rotation='vertical')\n    plt.xlabel(\"Number of Iterarions\")\n    plt.ylabel(\"Cost\")\n    plt.show()\n    \n    return parameters, gradients, cost_list\n\ndef predict(weight, bias, x_test):\n    z = sigmoid(np.dot(weight.T, x_test) + bias)\n    Y_prediction = np.zeros((1, x_test.shape[1]))\n    for i in range(z.shape[1]):\n        if z[0,i]<= 0.5:\n            Y_prediction[0,i] = 0\n        else:\n            Y_prediction[0,i] = 1\n\n    return Y_prediction\n\ndef logistic_regression(x_train, y_train, x_test, y_test, learning_rate,  num_iterations):\n    dimension =  x_train.shape[0]\n    weight, bias = initialise(dimension)\n    parameters, gradients, cost_list = update(weight, bias, x_train, y_train, learning_rate, num_iterations)\n    \n    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n    \n    print(\"test accuracy: {} %\".format(float(\"{:.2f}\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))))\n    scores['Logistic Regression with Functions'] = float(\"{:.2f}\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))","9990e24c":"logistic_regression(x_train, y_train, x_test, y_test, learning_rate = 0.01, num_iterations = 200)","15600c00":"lr = LogisticRegression()\n\nlr.fit(x_train.T, y_train.T)\nprint(\"test accuracy = {}%\" .format(float(\"{:.2f}\".format(lr.score(x_test.T, y_test.T) * 100))))","0291b6fe":"scores['Logistic Regression Score'] = float(\"{:.2f}\".format(lr.score(x_test.T, y_test) * 100))","c7018f95":"x_train = x_train.T\nx_test = x_test.T","80d93c81":"knn_scores = []\nfor each in range(1, 15):\n    knn2 = KNeighborsClassifier(n_neighbors = each)\n    knn2.fit(x_train, y_train)\n    knn_scores.append(knn2.score(x_test, y_test))\n\nplt.figure(figsize = (10, 8))\nplt.plot(range(1, 15), knn_scores)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()","9c965bd4":"knn = KNeighborsClassifier(n_neighbors = 9)\nknn.fit(x_train, y_train)\n\nprediction = knn.predict(x_test)","227b9bb4":"print(\"KNN score: {}\" .format(float(\"{:.2f}\".format(knn.score(x_test, y_test) * 100))))","baaa6f84":"scores['KNN Score'] = (float(\"{:.2f}\".format(knn.score(x_test, y_test) * 100)))","e62364cd":"svm = SVC(random_state = 1)\nsvm.fit(x_train, y_train)","d2a64b81":"print(\"SVM Score is: {}\" .format(float(\"{:.2f}\".format(svm.score(x_test, y_test) * 100))))","b7fe7e5a":"scores['SVM Score'] = (float(\"{:.2f}\".format(svm.score(x_test, y_test) * 100)))","55f6c720":"nb = GaussianNB()\nnb.fit(x_train, y_train)","fab945e4":"print(\"Naive Bayes Score is: {}\" .format(float(\"{:.2f}\".format(nb.score(x_test, y_test) * 100))))","694c1f8c":"scores['Naive Bayes Score'] = (float(\"{:.2f}\".format(nb.score(x_test, y_test) * 100)))","fcfe526e":"dt = DecisionTreeClassifier()\ndt.fit(x_train, y_train)","a6595771":"print(\"Decision Tree Score is: {}\" .format(float(\"{:.2f}\".format(dt.score(x_test, y_test) * 100))))","d55ec811":"scores['Decision Tree Score'] = (float(\"{:.2f}\".format(dt.score(x_test, y_test) * 100)))","cc1d4f91":"rf = RandomForestClassifier(n_estimators = 100, random_state=1)\nrf.fit(x_train, y_train)","907185c1":"print(\"Random Forest Score is: {}\" .format(float(\"{:.2f}\".format(rf.score(x_test, y_test) * 100))))","5696fbc5":"scores['Random Forest Score'] = (float(\"{:.2f}\".format(rf.score(x_test, y_test) * 100)))","52af7d88":"lists = sorted(scores.items())\n\nx_axis, y_axis = zip(*lists)\n\nplt.figure(figsize = (15, 10))\nplt.plot(x_axis, y_axis)\nplt.show()","95d06a95":"<a id=\"10\"><\/a>\n## Age - Disease","0117c826":"<a id=\"17\"><\/a>\n## Prediction with Logistic Regression","7f64f74f":"<a id=\"12\"><\/a>\n## Bilirubin Level and Disease","cfdb52f5":"<a id=\"20\"><\/a>\n### Sigmoid Function","3cce9dde":"Apparently, both albumin and globulin levels are higher in patients.","14a461cd":"With the k value 9, I have the best score.","352d12f1":"<a id=\"3\"><\/a>\n## Data Description\n\n* Age: Age of the patients\n* Gender: Sex of the patients (1 for male and 0 for female)\n* Total_Bilirubin: Total Billirubin in mg\/dL\n* Direct_Bilirubin: Conjugated Billirubin in mg\/dL\n* Alkaline_Phosphotase: ALP in IU\/L (an enzyme)\n* Alanine_Aminotransferase: ALT in IU\/L (an enzyme)\n* Aspartate_Aminotransferase: AST in IU\/L (an enzyme)\n* Total_Protiens: Total Proteins g\/dL\n* Albumin: Albumin in g\/dL\n* Albumin_and_Globulin_Ratio: A\/G ratio\n* target: patient has liver disease or not (1 for having the disease and 0 for not having)","9cdf9fdd":"<a id=\"23\"><\/a>\n## Prediction with KNN","dba7a7c8":"All of the three enzymes are lower in patients.","ff2dc1a3":"I chose weight as 0.01 and bias as 0.00","4267113b":"<a id=\"4\"><\/a>\n# Visualisation","2c360a38":"I get the best score with knn, but even that is not enough.","aa60d7e3":"*Maen are more likely to have a liver disease. Nevertheless, men are the majority among the healthy poeple.*","1c0d9daa":"<a id=\"22\"><\/a>\n## Prediction with Library","6c00da01":"<a id=\"7\"><\/a>\n## Correlation Between Enzymes and Liver Disease","44d04451":"In order to understand the correlations between the columns better, I am going to visualise the data.","8b1b771b":"<a id = 24><\/a>\n## Prediction with SVM","22e721f3":"Bilirubin levels in patients are higher.","f282e39c":"<a id=\"2\"><\/a> \n## Getting Data Ready","12a0eecf":"<a id=\"29\"><\/a>\n\n# Result","3019bcf0":"<a id=\"11\"><\/a>\n## Albumin-Globulin Ratio and Disease","72791901":"<a id=\"13\"><\/a>\n## Enzymes and Disease","370f3f39":"<a id=\"28\"><\/a>\n\n# Comparision of the Prediction Results","6af57666":"Protein levels aren't very distinctive between patients and non-patients.","c4450809":"I added a globulin column to the data.","0e093ba5":"# Introduction\n\n    In this kernel I will practice machine learning with liver disease dataset.\n\n1. [A Quick Look on the Data](#1)\n1. [Getting Data Ready](#2)\n1. [Data Description](#3)\n1. [Visualisation](#4)\n    * [Correlation Between Columns](#5)\n    * [Correlation Between Bilirubin Levels and Liver Disease](#6)\n    * [Correlation Between Enzymes and Liver Disease](#7)\n    * [Correlation Between Albumin-Globulin Ratio and Liver Disease](#8)\n    * [Gender and Disease](#9)\n    * [Age and Disease](#10)\n    * [Albumin-Globulin Ratio and Disease](#11)\n    * [Bilirubin Levels and Disease](#12)\n    * [Enzymes and Disease](#13)\n    * [Protein Levels and Disease](#14)\n1. [Machine Learning](#15)\n    * [Normalisation](#16)\n    * [Prediction with Logistic Regression](#17)\n        * [Defining Functions](#18)\n            * [Initialising](#19)\n            * [Sigmoid Funtion](#20)\n            * [Other Functions](#21)\n        * [Logistic Regression With Library](#22)\n    * [Prediction with KNN](#23)\n    * [Prediction with SVM](#24)\n    * [Prediction with Naive Bayes](#25)\n    * [Prediction with Decision Tree](#26)\n    * [Prediction with Random Forest Regression](#27)\n \n1. [Comparision of Prediction Scores](#28)\n1. [Result](#29)","2528f472":"Two graphs are similar, I don't think age feature will be useful in prediction.","5f53e1de":"<a id=\"15\"><\/a>\n# Machine Learning","3b4010cd":"<a id=\"14\"><\/a>\n## Proteins and Disease","b86414e4":"<a id=\"21\"><\/a>\n### Defining Other Functions","36bae185":"<a id=\"8\"><\/a>\n## Correlation Between Albumin - Globulin Levels and Liver Disease","2a42b669":"<a id = 26><\/a>\n## Prediction with Decision Tree","28e60c92":"<a id=\"6\"><\/a>\n## Correlation Between Bilirubin Levels and Liver Disease","2a13a1e9":"<a id=\"19\"><\/a>\n### Initialising","f871776b":"<a id=\"9\"><\/a>\n## Gender and Disease","11f3b9cf":"<a id = 25><\/a>\n\n## Prediction with Naive Bayes","13327ee9":"<a id=\"18\"><\/a>\n### Defining Functions","987ae317":"Alkaline phosphotase, alaine aminotransferase and aspartate aminotransferase are enzymes mainly found in liver.","9b1df6df":"<a id=\"5\"><\/a>\n## Correlation Between Columns","06704b33":"Before using the library I will define functions for predictions.","744427cb":"<a id=\"1\"><\/a>\n## A Quick Look on the Data","21946c02":"The best score I could get is 75%","cf97e38e":"First, I need to create arrays x and y for training and testing.","c10d1dfa":"The result is the same. Accuracy score is around 75%.","d5d65593":"<a id = 27><\/a>\n## Prediction with Random Forest","ac4c638f":"<a id=\"16\"><\/a>\n## Normalisation"}}