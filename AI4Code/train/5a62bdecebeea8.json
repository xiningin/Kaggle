{"cell_type":{"26a5f1ca":"code","8711b7c7":"code","f4e824e1":"code","2cdd7e3b":"code","a1919931":"code","ee067e43":"code","c5903f99":"code","565f4d5e":"code","66aa6d8e":"code","dcd8399f":"code","5f16fa21":"code","b7ad43d4":"code","f1387f05":"code","4a02c465":"code","5e2a79ba":"code","9504860e":"markdown","5b34b7dc":"markdown","0d3b959e":"markdown","0f76d569":"markdown","514890c9":"markdown"},"source":{"26a5f1ca":"DEBUG = True\n","8711b7c7":"import subprocess\nfrom ast import literal_eval\n\ndef run(command):\n    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n    out, err = process.communicate()\n    print(out.decode('utf-8').strip())\n\nprint('# CPU')\nrun('cat \/proc\/cpuinfo | egrep -m 1 \"^model name\"')\nrun('cat \/proc\/cpuinfo | egrep -m 1 \"^cpu MHz\"')\nrun('cat \/proc\/cpuinfo | egrep -m 1 \"^cpu cores\"')\n\nprint('# RAM')\nrun('cat \/proc\/meminfo | egrep \"^MemTotal\"')\n\nprint('# GPU')\nrun('lspci | grep VGA')\n\nprint('# OS')\nrun('uname -a')","f4e824e1":"!pip install ..\/input\/sacremoses > \/dev\/null\n\nimport sys\nsys.path.insert(0, \"..\/input\/transformers\/\")","2cdd7e3b":"import pandas as pd\nimport numpy as np\nimport sklearn\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n# import tensorflow_hub as hub\nimport tensorflow as tf\n# import bert_tokenization as tokenization\nimport tensorflow.keras.backend as K\nimport os\nfrom scipy.stats import spearmanr\nfrom math import floor, ceil\nfrom transformers import *\n\nimport seaborn as sns\nimport string\nimport re    #for regex\n\nnp.set_printoptions(suppress=True)\nprint(tf.__version__)","a1919931":"HAS_ANS = False\n\ndf = pd.read_csv('..\/input\/60k-stack-overflow-questions-with-quality-rate\/train.csv')\ndf = pd.read_csv('..\/input\/phd-three-level-feature-extraction\/all_features.csv')\ndf['Y0'] = df['Yi'].apply(lambda x: int(x==0))\ndf['Y1'] = df['Yi'].apply(lambda x: int(x==1))\ndf['Y2'] = df['Yi'].apply(lambda x: int(x==2))\ndel df['Y'], df['Yi'], df['Unnamed: 0']\n\n\ndf_train = df.head(45000)\ndf_test = df.tail(15000)\n\nif DEBUG:\n#     df_train = df_train.head(30000)\n    df_test = df_test.head(1000)\n\ndf_sub = df_test.copy()\ndel df_sub['Y0'], df_sub['Y1'], df_sub['Y2']\nprint('train shape =', df_train.shape)\nprint('test shape =', df_test.shape)\n\n","ee067e43":"output_categories = list(df_train.columns[61:])\nTARGET_COUNT = len(output_categories)","c5903f99":"input_categories = list(df_train.columns[7:61])","565f4d5e":"train = df_train.copy()","66aa6d8e":"from scipy.spatial.distance import cdist\n\ndef calc_corr(df, x_cols, y_cols):\n    arr1 = df[x_cols].T.values\n    arr2 = df[y_cols].T.values\n    corr_df = pd.DataFrame(1 - cdist(arr2, arr1, metric='correlation'), index=y_cols, columns=x_cols)\n    return corr_df\n\nnumber_feature_cols = input_categories[2:]\n\ncorr_df = calc_corr(train, output_categories, number_feature_cols)\nfig, ax = plt.subplots(figsize=(2, 6))\nsns.heatmap(corr_df, ax=ax)\n\nprint(corr_df)","dcd8399f":"from sklearn.model_selection import train_test_split\n\n#Particiona o data set originalmente Train em Train(Treino) e Val(valida\u00e7\u00e3o)\nX_train, X_val, Y_train, Y_val = train_test_split(df_train[input_categories], \n                                                                  df_train[output_categories], \n                                                                  test_size=0.2, \n                                                                  random_state=42)\n\nX_train.shape, Y_train.shape, X_val.shape, Y_val.shape","5f16fa21":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nimport random\nimport warnings\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, plot_confusion_matrix, plot_precision_recall_curve","b7ad43d4":"def plot_metric(clf, testX, testY, name):\n    \"\"\"\n    Small function to plot ROC-AUC values and confusion matrix\n    \"\"\"\n    styles = ['bmh', 'classic', 'fivethirtyeight', 'ggplot']\n\n    plt.style.use(random.choice(styles))\n    plot_confusion_matrix(clf, testX, testY)\n    plt.title(f\"Confusion Matrix [{name}]\")","f1387f05":"trainX = X_train.copy()\ntrainY = Y_train['Y0']\nvalidX = X_val.copy()\nvalidY = Y_val['Y0']","4a02c465":"# Define and fit the classifier on the data\nlr_classifier = LogisticRegression(C=1.)\nlr_classifier.fit(trainX, trainY)\n# Print the accuracy score of the classifier\nprint(f\"Validation Accuracy of Logsitic Regression Classifier is: {(lr_classifier.score(validX, validY))*100:.2f}%\")\n\nplot_metric(lr_classifier, validX, validY, \"Logistic Regression\")","5e2a79ba":"# Define and fit the classifier on the data\nnb_classifier = MultinomialNB()\nnb_classifier.fit(trainX, trainY)\nMultinomialNB()\n# Print the accuracy score of the classifier\nprint(f\"Validation Accuracy of Naive Bayes Classifier is: {(nb_classifier.score(validX, validY))*100:.2f}%\")\n# Also plot the metric\nplot_metric(nb_classifier, validX, validY, \"Naive Bayes\")","9504860e":"# prep","5b34b7dc":"## correlation","0d3b959e":"#### models","0f76d569":"#### 1. Read data and tokenizer\n\nRead tokenizer and data, as well as defining the maximum sequence length that will be used for the input to Bert (maximum is usually 512 tokens)","514890c9":"# 3. models\n\nfrom https:\/\/www.kaggle.com\/heyytanay\/stack-overflow-qa-classification-87-acc#Modelling"}}