{"cell_type":{"89a5baab":"code","32525f04":"code","b00d5ae7":"code","ecb306fc":"code","11a9b2ab":"code","11006e77":"code","2de9eaed":"code","2b8dc228":"code","e2f8e484":"code","f13771e1":"code","6b675e05":"code","61003aeb":"code","c8bbed7f":"code","90f7e7cf":"code","9d0d1a20":"code","2cea5c03":"code","91e1e1f9":"code","4129b5f5":"code","c8b57830":"code","19f1fe72":"code","fba61769":"code","fdac5bfc":"code","a15f0af8":"code","5cf3f6ba":"code","b5ecb40a":"code","bf506efc":"code","dcd269c4":"code","d8851330":"code","0cabbaf5":"code","fa439122":"code","39f8efda":"code","256fc4e5":"code","95f48a72":"code","5d253877":"code","0249c2e3":"markdown","3b542cae":"markdown"},"source":{"89a5baab":"import pandas as pd\npd.options.mode.chained_assignment = None\n\nSEED = 42","32525f04":"df = pd.read_csv('..\/input\/scl-2021-ds\/train.csv')","b00d5ae7":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(df, test_size=0.1, random_state=SEED)","ecb306fc":"len(train_df), len(valid_df)","11a9b2ab":"from string import punctuation\nimport re\n\ndef clean(s):\n    res = re.sub(r'(\\w)(\\()(\\w)', '\\g<1> \\g<2>\\g<3>', s)\n    res = re.sub(r'(\\w)([),.:;]+)(\\w)', '\\g<1>\\g<2> \\g<3>', res)\n    res = re.sub(r'(\\w)(\\.\\()(\\w)', '\\g<1>. (\\g<3>', res)\n    res = re.sub(r'\\s+', ' ', res)\n    res = res.strip()\n    return res\n\ndef stripclean(arr):\n    return [s.strip().strip(punctuation) for s in arr]\n\ndef dummy(x):\n    # stupid workaround to deep copy array cause i couldn't get it to work properly\n    return [s for s in x]","11006e77":"train_df['raw_address'] = train_df['raw_address'].apply(lambda x: x.strip())\ntrain_df['POI'] = train_df['POI\/street'].str.split('\/').str[0].apply(clean).str.split().apply(stripclean)\ntrain_df['STR'] = train_df['POI\/street'].str.split('\/').str[1].apply(clean).str.split().apply(stripclean)\ntrain_df['tokens'] = train_df['raw_address'].apply(clean).str.split()\ntrain_df['strip_tokens'] = train_df['tokens'].apply(stripclean)\ntrain_df['full_tokens'] = train_df['tokens'].apply(dummy)\ntrain_df['labels'] = train_df['tokens'].apply(lambda x: ['O'] * len(x))\ntrain_df['pos_poi'] = train_df['tokens'].apply(lambda x: [-1, -1])\ntrain_df['pos_str'] = train_df['tokens'].apply(lambda x: [-1, -1])","2de9eaed":"train_df.head()","2b8dc228":"valid_df['raw_address'] = valid_df['raw_address'].apply(lambda x: x.strip())\nvalid_df['tokens'] = valid_df['raw_address'].apply(clean).str.split()","e2f8e484":"valid_df.head()","f13771e1":"wordlist_raw = {}\nPOI_ERR_IDX = []\nSTR_ERR_IDX = []\nSHORTEN_IDX = []\nOVERLAP_IDX = set()","6b675e05":"from tqdm import tqdm\n\nfor idx in tqdm(range(len(train_df))):\n    row = train_df.iloc[idx]\n    found_poi, found_str, shorten = False, False, False\n    for i in range(len(row['strip_tokens'])):\n        if row['strip_tokens'][i] == '': continue\n        if len(row['POI']) > 0 and row['POI'][0].startswith(row['strip_tokens'][i]):\n            ok = True\n            for j in range(len(row['POI'])):\n                if i + j >= len(row['strip_tokens']) or not row['POI'][j].startswith(row['strip_tokens'][i + j]):\n                    ok = False\n                    break\n            if ok:\n                found_poi = True\n                row['pos_poi'][0] = i\n                row['pos_poi'][1] = i + len(row['POI']) - 1\n                for j in range(len(row['POI'])):\n                    if row['labels'][i + j] != 'O':\n                        OVERLAP_IDX.add(row['id'])\n                    if len(row['POI']) == 1:       row['labels'][i + j] = 'S-POI'\n                    elif j == 0:                   row['labels'][i + j] = 'B-POI'\n                    elif j == len(row['POI']) - 1: row['labels'][i + j] = 'E-POI'\n                    else:                          row['labels'][i + j] = 'I-POI'\n                    if row['strip_tokens'][i + j] != row['POI'][j]:\n                        row['full_tokens'][i + j] = row['full_tokens'][i + j].replace(row['strip_tokens'][i + j], row['POI'][j])\n                        row['labels'][i + j] += '-SHORT'\n                        shorten = True\n                        if not row['strip_tokens'][i + j] in wordlist_raw: wordlist_raw[row['strip_tokens'][i + j]] = {}\n                        if not row['POI'][j] in wordlist_raw[row['strip_tokens'][i + j]]: wordlist_raw[row['strip_tokens'][i + j]][row['POI'][j]] = 0\n                        wordlist_raw[row['strip_tokens'][i + j]][row['POI'][j]] += 1\n        \n        if len(row['STR']) > 0 and row['STR'][0].startswith(row['strip_tokens'][i]):\n            ok = True\n            for j in range(len(row['STR'])):\n                if i + j >= len(row['strip_tokens']) or not row['STR'][j].startswith(row['strip_tokens'][i + j]):\n                    ok = False\n                    break\n            if ok:\n                found_str = True\n                row['pos_str'][0] = i\n                row['pos_str'][1] = i + len(row['STR']) - 1\n                for j in range(len(row['STR'])):\n                    if row['labels'][i + j] != 'O':\n                        OVERLAP_IDX.add(row['id'])\n                    if len(row['STR']) == 1:       row['labels'][i + j] = 'S-STR'\n                    elif j == 0:                   row['labels'][i + j] = 'B-STR'\n                    elif j == len(row['STR']) - 1: row['labels'][i + j] = 'E-STR'\n                    else:                          row['labels'][i + j] = 'I-STR'\n                    if row['strip_tokens'][i + j] != row['STR'][j]:\n                        row['full_tokens'][i + j] = row['full_tokens'][i + j].replace(row['strip_tokens'][i + j], row['STR'][j])\n                        row['labels'][i + j] += '-SHORT'\n                        shorten = True\n                        if not row['strip_tokens'][i + j] in wordlist_raw: wordlist_raw[row['strip_tokens'][i + j]] = {}\n                        if not row['STR'][j] in wordlist_raw[row['strip_tokens'][i + j]]: wordlist_raw[row['strip_tokens'][i + j]][row['STR'][j]] = 0\n                        wordlist_raw[row['strip_tokens'][i + j]][row['STR'][j]] += 1\n    \n    if len(row['POI']) > 0 and not found_poi:\n        POI_ERR_IDX.append(row['id'])\n    if len(row['STR']) > 0 and not found_str:\n        STR_ERR_IDX.append(row['id'])\n    if shorten:\n        SHORTEN_IDX.append(row['id'])","61003aeb":"len(wordlist_raw), len(POI_ERR_IDX), len(STR_ERR_IDX), len(SHORTEN_IDX), len(OVERLAP_IDX)","c8bbed7f":"train_df[train_df['id'].isin(SHORTEN_IDX[:10])]","90f7e7cf":"ERR_IDX = set(POI_ERR_IDX + STR_ERR_IDX + list(OVERLAP_IDX))\nlen(ERR_IDX)","9d0d1a20":"train_df = train_df[~train_df['id'].isin(ERR_IDX)]","2cea5c03":"def cleanshort(arr):\n    return [s.replace('-SHORT', '') for s in arr]\n\nnew_train_df = train_df[train_df['id'].isin(SHORTEN_IDX)].copy(deep=True)\nnew_train_df['tokens'] = new_train_df['full_tokens'].apply(dummy)\nnew_train_df['labels'] = new_train_df['labels'].apply(cleanshort)","91e1e1f9":"new_train_df.head()","4129b5f5":"train_df = train_df.append(new_train_df, ignore_index=True)","c8b57830":"from tqdm import tqdm\n\nswap_parts = []\nswap_tokens = []\nswap_labels = []","19f1fe72":"for idx in tqdm(range(len(train_df))):\n    old_row = train_df.iloc[idx]\n    if old_row['pos_poi'][0] == -1 or old_row['pos_str'][0] == -1: continue\n    \n    start_poi, end_poi = old_row['pos_poi']\n    start_str, end_str = old_row['pos_str']\n    if end_poi < start_str:\n        swap_tokens.append(old_row['tokens'][:start_poi] + \\\n                           old_row['tokens'][start_str:end_str + 1] + \\\n                           old_row['tokens'][end_poi + 1:start_str] + \\\n                           old_row['tokens'][start_poi:end_poi + 1] + \\\n                           old_row['tokens'][end_str + 1:])\n        swap_labels.append(old_row['labels'][:start_poi] + \\\n                           old_row['labels'][start_str:end_str + 1] + \\\n                           old_row['labels'][end_poi + 1:start_str] + \\\n                           old_row['labels'][start_poi:end_poi + 1] + \\\n                           old_row['labels'][end_str + 1:])\n        swap_parts.append((0, \\\n                           old_row['tokens'][:start_poi], \\\n                           old_row['tokens'][start_str:end_str + 1], \\\n                           old_row['tokens'][end_poi + 1:start_str], \\\n                           old_row['tokens'][start_poi:end_poi + 1], \\\n                           old_row['tokens'][end_str + 1:], \\\n                           old_row['labels'][:start_poi], \\\n                           old_row['labels'][start_str:end_str + 1], \\\n                           old_row['labels'][end_poi + 1:start_str], \\\n                           old_row['labels'][start_poi:end_poi + 1], \\\n                           old_row['labels'][end_str + 1:]))\n    else:\n        swap_tokens.append(old_row['tokens'][:start_str] + \\\n                           old_row['tokens'][start_poi:end_poi + 1] + \\\n                           old_row['tokens'][end_str + 1:start_poi] + \\\n                           old_row['tokens'][start_str:end_str + 1] + \\\n                           old_row['tokens'][end_poi + 1:])\n        swap_labels.append(old_row['labels'][:start_str] + \\\n                           old_row['labels'][start_poi:end_poi + 1] + \\\n                           old_row['labels'][end_str + 1:start_poi] + \\\n                           old_row['labels'][start_str:end_str + 1] + \\\n                           old_row['labels'][end_poi + 1:])\n        swap_parts.append((1, \\\n                           old_row['tokens'][:start_str], \\\n                           old_row['tokens'][start_poi:end_poi + 1], \\\n                           old_row['tokens'][end_str + 1:start_poi], \\\n                           old_row['tokens'][start_str:end_str + 1], \\\n                           old_row['tokens'][end_poi + 1:], \\\n                           old_row['labels'][:start_str], \\\n                           old_row['labels'][start_poi:end_poi + 1], \\\n                           old_row['labels'][end_str + 1:start_poi], \\\n                           old_row['labels'][start_str:end_str + 1], \\\n                           old_row['labels'][end_poi + 1:]))","fba61769":"import random\nswap_idx = list(range(len(swap_parts)))\nrandom.Random(SEED).shuffle(swap_idx)","fdac5bfc":"for i in tqdm(range(len(swap_parts))):\n    if i == swap_idx[i]: continue\n    j = swap_idx[i]\n    \n    swap_tokens.append(swap_parts[i][1] + swap_parts[j][2] + swap_parts[i][3] + swap_parts[j][4] + swap_parts[i][5])\n    swap_labels.append(swap_parts[i][6] + swap_parts[j][7] + swap_parts[i][8] + swap_parts[j][9] + swap_parts[i][10])","a15f0af8":"swap_train_df = pd.DataFrame(columns=['tokens', 'labels'], data={'tokens': swap_tokens, 'labels': swap_labels})\nswap_train_df.head()","5cf3f6ba":"train_df.drop(columns=['id', 'raw_address', 'POI\/street', 'POI', 'STR', 'strip_tokens', 'full_tokens', 'pos_poi', 'pos_str'], inplace=True)","b5ecb40a":"train_df = train_df.append(swap_train_df, ignore_index=True)","bf506efc":"train_df.head()","dcd269c4":"len(train_df)","d8851330":"train_df.to_csv('train.csv', index=False)\nvalid_df.to_csv('valid.csv', index=False)","0cabbaf5":"import json\n\nwith open('wordlist_raw.json', 'w') as fp:\n    json.dump(wordlist_raw, fp)","fa439122":"len(wordlist_raw)","39f8efda":"def get_list(raw, p, lmt):\n    res = {}\n    for word, stats in raw.items():\n        best = max(stats, key=stats.get)\n        best_cnt = stats[best]\n        total = sum(stats.values())\n        frac = best_cnt \/ total\n        if total >= lmt and best_cnt \/ total >= p: \n            res[word] = best\n    return res","256fc4e5":"wordlist = get_list(wordlist_raw, 0, 1)","95f48a72":"len(wordlist)","5d253877":"import json\n\nwith open('wordlist.json', 'w') as fp:\n    json.dump(wordlist, fp)","0249c2e3":"# Build word list and token labels","3b542cae":"# Prepare data\n- Format the data into **tokens** and **labels** for **Named Entity Recognition (NER)** task\n- Labels are heavily categorised to give the most useful data to the model: ['B-POI', 'B-POI-SHORT', 'B-STR', 'B-STR-SHORT', 'E-POI', 'E-POI-SHORT', 'E-STR', 'E-STR-SHORT', 'I-POI', 'I-POI-SHORT', 'I-STR', 'I-STR-SHORT', 'O', 'S-POI', 'S-POI-SHORT', 'S-STR', 'S-STR-SHORT']\n- **IOBES** tagging scheme is used for both **POI** and **STR**\n- An additional tag **SHORT** is used to label words that are **incomplete** and need to be fixed using a **prebuilt one-one dictionary wordlist** \n- Simple data augmentation is also used to increase the size of the training data (completing, swapping, etc.)\n\n## Steps:\n1. [Preprocessing](https:\/\/www.kaggle.com\/nguyncaoduy\/1-place-scl-ds-2021-voidandtwotsts-preprocess) - This Notebook\n2. [Training](https:\/\/www.kaggle.com\/nguyncaoduy\/1-place-scl-ds-2021-voidandtwotsts-train) \n3. [Ensembling](https:\/\/www.kaggle.com\/nguyncaoduy\/1-place-scl-ds-2021-voidandtwotsts-ensemble)"}}