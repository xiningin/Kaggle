{"cell_type":{"7eb8c971":"code","e8e56940":"code","139927f8":"code","3edc65eb":"code","df76a6ee":"code","cf807ca4":"code","c0d593c7":"code","daac2030":"code","dd7a8363":"code","6f5acd37":"code","1b498abf":"markdown","4061e63a":"markdown","791e57a5":"markdown","77755695":"markdown"},"source":{"7eb8c971":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e8e56940":"df_train = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-3\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-3\/test.csv')\ndf_train.head()","139927f8":"df_test.head()","3edc65eb":"train = df_train\ntest = df_test\n\n# Converting to datetime64 and splitting off redundant year\ntrain.Date = pd.to_datetime(train.Date)\ntest.Date = pd.to_datetime(test.Date)\ntrain['Date'] = train['Date'].dt.strftime(\"%d%m\").astype(int)\ntest['Date'] = test['Date'].dt.strftime(\"%d%m\").astype(int)","df76a6ee":"# Filling NaNs with 'Data_NA' for Not Applicable\ntrain.Province_State.fillna('Data_NA',inplace=True)\ntest.Province_State.fillna('Data_NA',inplace=True)","cf807ca4":"# Storing various countries in the Countries list\nCountries = train.Country_Region.unique()\nCountries","c0d593c7":"# Storing the Provinces of each country in a pandas series\nProvinces = train.groupby('Country_Region')['Province_State'].unique()\nProvinces","daac2030":"# To find number of predictors\nlen(Countries)*len(Provinces)","dd7a8363":"from xgboost import XGBRegressor\n\nclass COVID_19:\n    def __init__(self):\n        self.count = 0\n        self.Predictions = {'ForecastId':[],'ConfirmedCases':[],'Fatalities':[]}\n        \n    def Forecast_COVID_19(self,N=324):\n        for country in Countries:\n            for province in Provinces[country]:\n                country_df = train[(train.Country_Region==country)]\n                province_df = country_df[(country_df.Province_State==province)]\n\n                X_train = province_df.Date.values.reshape(-1,1)\n                y_trainC = province_df.ConfirmedCases.values\n                y_trainF = province_df.Fatalities.values\n\n                test_country_df = test[(test.Country_Region==country)]\n                test_province_df = test_country_df[(test_country_df.Province_State==province)]\n                X_test = test_province_df.Date.values.reshape(-1,1)\n\n                y_predC = XGBRegressor(n_estimators=N).fit(X_train, y_trainC).predict(X_test)\n                y_predF = XGBRegressor(n_estimators=N).fit(X_train, y_trainF).predict(X_test)\n\n                FC_ID = np.array(test_province_df.ForecastId)\n\n                for i,(j,k) in enumerate(zip(y_predC,y_predF)):\n                    self.Predictions['ForecastId'].append(FC_ID[i])\n                    self.Predictions['ConfirmedCases'].append(np.round(j))\n                    self.Predictions['Fatalities'].append(np.round(k))\n\n        self.df_pred = pd.DataFrame(self.Predictions)\n\n        if self.count==0:\n            self.df_pred.to_csv('submission.csv',index=False)\n        if self.count>=1:\n            self.df_pred.to_csv('submission_'+str(self.count)+'.csv',index=False)\n\n        self.count+=1","6f5acd37":"COVID_Forecaster = COVID_19()\nCOVID_Forecaster.Forecast_COVID_19(1000)","1b498abf":"# Generating Outputs","4061e63a":"# Defining the nCoVID-2019 Forecaster","791e57a5":"# Starting computation on the datasets","77755695":"# Importing the dataset and viewing"}}