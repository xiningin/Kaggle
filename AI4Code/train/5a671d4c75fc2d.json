{"cell_type":{"a7636b7e":"code","38d6b503":"code","1a662282":"code","a07eb414":"code","36df7cbc":"code","3efafd3f":"code","9ec3e6ae":"code","15fa640a":"code","62d353e5":"code","9e46762b":"code","342bb468":"code","051075fe":"code","ee6d001d":"code","0e948a10":"code","6b77adb1":"code","75a99a4b":"code","4b1ba095":"code","723e1ad1":"code","7dfa0e09":"code","e726ffc6":"code","af7b921b":"code","8b3384a7":"code","af18cbba":"code","cb023fa3":"code","903b02d1":"code","59e65aa4":"code","603725a6":"code","eb86a2d6":"code","18586db6":"code","b1ed5c3e":"code","c749eb0b":"code","73406fad":"code","5e26e6d4":"code","0625e671":"code","3257b674":"code","e5b0ee64":"code","d238d386":"code","7f92da7f":"code","6b22f70f":"code","8077204e":"code","3b85ebe6":"code","bba9ced0":"code","78a27260":"code","3ff87b03":"code","1ce7ca64":"code","b7c316c4":"code","3e5a4640":"code","0125036c":"code","af0265b3":"code","777b4d50":"code","0518c416":"code","9ef7926f":"code","929c2051":"code","cdd869a1":"code","fa2f35a8":"code","2a7b58c2":"code","b3bf4064":"code","a609c283":"code","7ef34f8e":"code","d0e76fbc":"code","16c51e86":"code","bb046771":"code","ca37ccf3":"code","52d1e7c4":"code","13f91957":"code","ead8bb3f":"code","c3deb771":"code","e9d59705":"code","684e85ad":"code","fc5af10a":"code","b4487e1b":"code","5bdc2808":"code","e2e7410f":"code","b7a0c07f":"code","f6079fd0":"code","7d89cfc3":"code","07bc4248":"code","e376785e":"code","0ffd7a73":"code","5facdc00":"code","4ca400a5":"code","f6b0beef":"code","d07060d6":"code","4268f999":"code","6e6934c3":"code","04d3a551":"code","42b65b94":"code","e4780c9e":"code","c138309a":"code","0570a942":"code","ae53f1c0":"code","0a241cbd":"code","bfad6632":"code","3bd2dcc0":"code","757170a2":"code","ebaac274":"code","b49af4f1":"code","9da464ce":"code","38ce559e":"code","19fce4e8":"code","2559518f":"code","b3e564db":"code","4e369db7":"code","0bbc4739":"code","6a553bd2":"code","7996767b":"code","0c727798":"code","ec64c76f":"code","229b3091":"code","9661b9df":"code","6d537789":"code","0fc51ecd":"code","1ecfb4fa":"code","4979bd43":"code","b5257763":"code","6ddc3b10":"code","40de64aa":"markdown","2967e019":"markdown","e2f0ddaf":"markdown","9ab9f4ff":"markdown","19e00629":"markdown","94f1cbf5":"markdown","d0286a84":"markdown","a9ab222e":"markdown","9aab964c":"markdown","df08bc0a":"markdown","1f8429cf":"markdown","a9d61d2b":"markdown","3eecb33a":"markdown","231ee561":"markdown","345798d4":"markdown","513eb771":"markdown","fca311a1":"markdown","9bf515d8":"markdown","caae9a7a":"markdown","54acad4e":"markdown","e3ac1a8f":"markdown","a569a109":"markdown","53c7390a":"markdown","2b396c94":"markdown","716a2137":"markdown","7cfe4420":"markdown","97952f45":"markdown","d5db5fc1":"markdown","362ff203":"markdown","8d87ff89":"markdown","a4f11406":"markdown","8c92d64d":"markdown","88763866":"markdown","d7c31373":"markdown","c8b673a6":"markdown","161e25ae":"markdown","b9caa964":"markdown","36f9258e":"markdown","690e8f06":"markdown","707212d2":"markdown","70b99570":"markdown","26b3406a":"markdown","6c3c3369":"markdown","a0fd5224":"markdown","ca84e6a9":"markdown","c773007a":"markdown","f710ad14":"markdown","f6091b4e":"markdown","186d0baa":"markdown","488d11e3":"markdown","fb8605e0":"markdown","581827d4":"markdown","414d49b6":"markdown","79c9cc22":"markdown","3c7209f7":"markdown","be5bfcc6":"markdown","871af476":"markdown","d8750638":"markdown","8df446d8":"markdown","46efff98":"markdown","11affd6f":"markdown","e74593e8":"markdown","64ee8352":"markdown","f9d17747":"markdown","fd374fc1":"markdown","325e2949":"markdown","b653e7ad":"markdown","3ab4f516":"markdown","c366c4b1":"markdown","6317a8d9":"markdown"},"source":{"a7636b7e":"import numpy as np \nimport pandas as pd \n\nimport random as rn\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\n# plotly library\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score, KFold \nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom scipy.stats import uniform\n\nimport itertools\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.utils import np_utils\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, MaxPool2D\n#from keras.layers import AvgPool2D, BatchNormalization, Reshape\nfrom keras.optimizers import Adadelta, RMSprop, Adam\nfrom keras.losses import categorical_crossentropy\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\nimport tensorflow as tf\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","38d6b503":"img_rows, img_cols = 28, 28\n\nnp.random.seed(5)\n#rn.seed(5)\n#tf.set_random_seed(5)","1a662282":"def get_best_score(model):\n    \n    print(model.best_score_)    \n    print(model.best_params_)\n    print(model.best_estimator_)\n    \n    return model.best_score_","a07eb414":"def print_validation_report(y_true, y_pred):\n    print(\"Classification Report\")\n    print(classification_report(y_true, y_pred))\n    acc_sc = accuracy_score(y_true, y_pred)\n    print(\"Accuracy : \"+ str(acc_sc))\n    \n    return acc_sc","36df7cbc":"def plot_confusion_matrix(y_true, y_pred):\n    mtx = confusion_matrix(y_true, y_pred)\n    fig, ax = plt.subplots(figsize=(8,8))\n    sns.heatmap(mtx, annot=True, fmt='d', linewidths=.5,  cbar=False, ax=ax)\n    #  square=True,\n    plt.ylabel('true label')\n    plt.xlabel('predicted label')","3efafd3f":"def plot_history_loss_and_acc(history_keras_nn):\n\n    fig, axs = plt.subplots(1,2, figsize=(12,4))\n\n    axs[0].plot(history_keras_nn.history['loss'])\n    axs[0].plot(history_keras_nn.history['val_loss'])\n    axs[0].set_title('model loss')\n    axs[0].set_ylabel('loss')\n    axs[0].set_xlabel('epoch')\n    axs[0].legend(['train', 'validation'], loc='upper left')\n\n    axs[1].plot(history_keras_nn.history['acc'])\n    axs[1].plot(history_keras_nn.history['val_acc'])\n    axs[1].set_title('model accuracy')\n    axs[1].set_ylabel('accuracy')\n    axs[1].set_xlabel('epoch')\n    axs[1].legend(['train', 'validation'], loc='upper left')\n\n    plt.show()","9ec3e6ae":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","15fa640a":"y = train[\"label\"]\nX = train.drop([\"label\"],axis = 1)\nX_test = test","62d353e5":"X = X\/255.0\nX_test = X_test\/255.0","9e46762b":"# for best performance, especially of the NN classfiers,\n# set mode = \"commit\"\nmode = \"edit\"\nmode = \"commit\"\n#\n\nif mode == \"edit\" :\n    nr_samples = 1200\n\nif mode == \"commit\" :    \n    nr_samples = 30000\n\ny_train=y[:nr_samples]\nX_train=X[:nr_samples]\nstart_ix_val = nr_samples \nend_ix_val = nr_samples + int(nr_samples\/3)\ny_val=y[start_ix_val:end_ix_val]\nX_val=X[start_ix_val:end_ix_val]\n    \nprint(\"nr_samples train data:\", nr_samples)\nprint(\"start_ix_val:\", start_ix_val)\nprint(\"end_ix_val:\", end_ix_val)","342bb468":"print(\"X:\")\nprint(X.info())\nprint(\"*\"*50)\nprint(\"X_test:\")\nprint(X_test.info())\nprint(\"*\"*50)\nprint(\"y:\")\nprint(y.shape)","051075fe":"X.iloc[0:5,:]","ee6d001d":"y.iloc[0:5]","0e948a10":"fig, axs = plt.subplots(1, 5, sharex=True, sharey=True, figsize=(10,6))\naxs = axs.flatten()\nfor i in range(0,5):\n    im = X.iloc[i]\n    im = im.values.reshape(-1,28,28,1)\n    axs[i].imshow(im[0,:,:,0], cmap=plt.get_cmap('gray'))\n    axs[i].set_title(y[i])\nplt.tight_layout()    ","6b77adb1":"y.value_counts()","75a99a4b":"fig, ax = plt.subplots(figsize=(8,5))\ng = sns.countplot(y)","4b1ba095":"li_idxs = []\nfor i in range(10):\n    for nr in range(10):\n        ix = y[y==nr].index[i]\n        li_idxs.append(ix) ","723e1ad1":"fig, axs = plt.subplots(10, 10, sharex=True, sharey=True, figsize=(10,12))\naxs = axs.flatten()\nfor n, i in enumerate(li_idxs):\n    im = X.iloc[i]\n    im = im.values.reshape(-1,28,28,1)\n    axs[n].imshow(im[0,:,:,0], cmap=plt.get_cmap('gray'))\n    axs[n].set_title(y[i])\nplt.tight_layout()    ","7dfa0e09":"from sklearn.linear_model import Perceptron\nclf_Perceptron = Perceptron(random_state=0)\nparam_grid = { 'penalty': ['l1','l2'], 'tol': [0.05, 0.1] }\nGridCV_Perceptron = GridSearchCV(clf_Perceptron, param_grid, verbose=1, cv=5)\nGridCV_Perceptron.fit(X_train,y_train)\nscore_grid_Perceptron = get_best_score(GridCV_Perceptron)","e726ffc6":"pred_val_perc = GridCV_Perceptron.predict(X_val)","af7b921b":"acc_perc = print_validation_report(y_val, pred_val_perc)","8b3384a7":"plot_confusion_matrix(y_val, pred_val_perc)","af18cbba":"from sklearn.linear_model import LogisticRegression\nclf_LR = LogisticRegression(random_state=0)\nparam_grid = {'C': [0.014,0.012], 'multi_class': ['multinomial'],  \n              'penalty': ['l1'],'solver': ['saga'], 'tol': [0.1] }\nGridCV_LR = GridSearchCV(clf_LR, param_grid, verbose=1, cv=5)\nGridCV_LR.fit(X_train,y_train)\nscore_grid_LR = get_best_score(GridCV_LR)","cb023fa3":"pred_val_lr = GridCV_LR.predict(X_val)\nacc_lr = print_validation_report(y_val, pred_val_lr)","903b02d1":"plot_confusion_matrix(y_val, pred_val_lr)","59e65aa4":"from sklearn.neighbors import KNeighborsClassifier\nclf_knn = KNeighborsClassifier(n_neighbors=10)\nclf_knn.fit(X_train,y_train)","603725a6":"pred_val_knn = clf_knn.predict(X_val)\nacc_knn = print_validation_report(y_val, pred_val_knn)","eb86a2d6":"plot_confusion_matrix(y_val, pred_val_knn)","18586db6":"from sklearn.ensemble import RandomForestClassifier\nclf_RF = RandomForestClassifier(random_state=0)\nparam_grid = {'max_depth': [15], 'max_features': [100],  \n              'min_samples_split': [5],'n_estimators' : [50] }\nGridCV_RF = GridSearchCV(clf_RF, param_grid, verbose=1, cv=5)\nGridCV_RF.fit(X_train,y_train)\nscore_grid_RF = get_best_score(GridCV_RF)","b1ed5c3e":"pred_val_rf = GridCV_RF.predict(X_val)","c749eb0b":"acc_rf = print_validation_report(y_val, pred_val_rf)","73406fad":"plot_confusion_matrix(y_val, pred_val_rf)","5e26e6d4":"from sklearn.svm import SVC\nclf_svm = SVC(C=5, gamma=0.05, kernel='rbf', random_state=0)\nclf_svm.fit(X_train,y_train)","0625e671":"pred_val_svm = clf_svm.predict(X_val)\nacc_svm = print_validation_report(y_val, pred_val_svm)","3257b674":"plot_confusion_matrix(y_val, pred_val_svm)","e5b0ee64":"batchsize = int(nr_samples\/15) ","d238d386":"from sklearn.neural_network import MLPClassifier\n\nclf_mlp = MLPClassifier(activation = \"logistic\", hidden_layer_sizes=(200,), random_state=0)\nparam_grid = { 'batch_size' : [batchsize] , 'max_iter': [600], 'alpha': [1e-4], \n               'solver': ['sgd'], 'learning_rate_init': [0.05,0.06],'tol': [1e-4] }\n    \nGridCV_MLP = GridSearchCV(clf_mlp, param_grid, verbose=1, cv=3)\nGridCV_MLP.fit(X_train,y_train)\nscore_grid_MLP = get_best_score(GridCV_MLP)   ","7f92da7f":"fig, ax = plt.subplots(figsize=(6,3))\nax.plot(GridCV_MLP.best_estimator_.loss_curve_)\n\nplt.xlabel(\"number of steps\") \nplt.ylabel(\"Loss During GD\")\nplt.title(\"loss function\")\nplt.show()","6b22f70f":"pred_val_mlp = GridCV_MLP.predict(X_val)","8077204e":"acc_mlp = print_validation_report(y_val, pred_val_mlp)","3b85ebe6":"plot_confusion_matrix(y_val, pred_val_mlp)","bba9ced0":"y_train = to_categorical(y_train, 10)\ny_val_10 = to_categorical(y_val, 10)","78a27260":"def dense_model_0():\n    model = Sequential()\n    model.add(Dense(10, input_dim=784, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","3ff87b03":"model_dense_0 = dense_model_0()\nmodel_dense_0.summary()","1ce7ca64":"model_dense_0.fit(X_train, y_train, epochs=50, batch_size=batchsize)","b7c316c4":"pred_val_dense0 = model_dense_0.predict_classes(X_val)","3e5a4640":"acc_fc0 = print_validation_report(y_val, pred_val_dense0)","0125036c":"plot_confusion_matrix(y_val, pred_val_dense0)","af0265b3":"def dense_model_1():\n    model = Sequential()\n    model.add(Dense(100, input_dim=784, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","777b4d50":"model_dense_1 = dense_model_1()\nmodel_dense_1.summary()","0518c416":"history_dense_1 = model_dense_1.fit(X_train, y_train, validation_data=(X_val,y_val_10), \n                                    epochs=50, batch_size=batchsize)","9ef7926f":"plot_history_loss_and_acc(history_dense_1)","929c2051":"pred_val_dense1 = model_dense_1.predict_classes(X_val)\nplot_confusion_matrix(y_val, pred_val_dense1)\nprint(classification_report(y_val, pred_val_dense1))\nacc_fc1 = accuracy_score(y_val, pred_val_dense1)\nprint(acc_fc1)","cdd869a1":"def dense_model_2():\n    model = Sequential()\n    model.add(Dense(100, input_dim=784, activation='relu'))\n    model.add(Dense(200, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","fa2f35a8":"model_dense_2 = dense_model_2()\nmodel_dense_2.summary()","2a7b58c2":"history_dense_2 = model_dense_2.fit(X_train, y_train, validation_data=(X_val,y_val_10), \n                                    epochs=50, batch_size=batchsize)","b3bf4064":"plot_history_loss_and_acc(history_dense_2)","a609c283":"pred_val_dense2 = model_dense_2.predict_classes(X_val)\nplot_confusion_matrix(y_val, pred_val_dense2)\nprint(classification_report(y_val, pred_val_dense2))\nacc_fc2 = accuracy_score(y_val, pred_val_dense2)\nprint(acc_fc2)","7ef34f8e":"def dense_model_3():\n    \n    model = Sequential()  \n    model.add(Dense(100, activation='relu', input_dim=784))\n    model.add(Dense(200, activation='relu')) \n    model.add(Dense(100, activation='relu')) \n    model.add(Dense(10, activation='softmax'))\n         \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    #model.compile(optimizer=RMSprop(lr=0.001),\n    #         loss='categorical_crossentropy',\n    #         metrics=['accuracy'])\n    \n    return model","d0e76fbc":"model_dense_3 = dense_model_3()\nmodel_dense_3.summary()","16c51e86":"history_dense_3 = model_dense_3.fit(X_train, y_train, validation_data=(X_val,y_val_10), \n                                    epochs=50, batch_size=batchsize)","bb046771":"plot_history_loss_and_acc(history_dense_3)","ca37ccf3":"pred_val_dense3 = model_dense_3.predict_classes(X_val)\nplot_confusion_matrix(y_val, pred_val_dense3)\nprint(classification_report(y_val, pred_val_dense3))\nacc_fc3 = accuracy_score(y_val, pred_val_dense3)\nprint(acc_fc3)","52d1e7c4":"X_train.shape","13f91957":"X_train = X_train.values.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_val = X_val.values.reshape(X_val.shape[0], img_rows, img_cols, 1)\n\ninput_shape = (img_rows, img_cols, 1)","ead8bb3f":"X_train.shape","c3deb771":"y_train.shape","e9d59705":"batchsize = 128\nepochs = 12","684e85ad":"activation = 'relu'\nadadelta = Adadelta()\nloss = categorical_crossentropy","fc5af10a":"def cnn_model_1(activation):\n    \n    model = Sequential()\n    \n    model.add(Conv2D(32, kernel_size=(3, 3), activation=activation, input_shape=input_shape)) \n    \n    model.add(Conv2D(64, (3, 3), activation=activation))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n \n    model.add(Flatten())\n\n    model.add(Dense(128, activation=activation))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(loss=loss, optimizer=adadelta, metrics=['accuracy'])\n\n    return model","b4487e1b":"model_cnn_1 = cnn_model_1(activation)\nmodel_cnn_1.summary()","5bdc2808":"#model_cnn_1.fit(X_train, y_train, batch_size=batchsize, epochs=epochs, verbose=1)\nhistory_cnn_1 = model_cnn_1.fit(X_train, y_train, validation_data=(X_val,y_val_10), \n                                   epochs=epochs, batch_size=batchsize, verbose=1)","e2e7410f":"plot_history_loss_and_acc(history_cnn_1)","b7a0c07f":"pred_val_cnn1 = model_cnn_1.predict_classes(X_val)\nplot_confusion_matrix(y_val, pred_val_cnn1)\nprint(classification_report(y_val, pred_val_cnn1))\nacc_cnn1 = accuracy_score(y_val, pred_val_cnn1)\nprint(acc_cnn1)\n","f6079fd0":"batch_size=90\nepochs=30\n","7d89cfc3":"def cnn_model_2(optimizer,loss):\n\n    model = Sequential()\n\n    model.add(Conv2D(32, (3, 3), padding = 'Same', activation=\"relu\", input_shape=input_shape ))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n\n    model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n\n    model.add(Flatten())\n\n    model.add(Dense(256, activation=activation))\n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy']) \n\n    return model","07bc4248":"model_cnn_2 = cnn_model_2(adadelta, categorical_crossentropy)\nmodel_cnn_2.summary()","e376785e":"#model_cnn_2.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\nhistory_cnn_2 = model_cnn_2.fit(X_train, y_train, validation_data=(X_val,y_val_10), \n                                epochs=epochs, batch_size=batchsize, verbose=1)","0ffd7a73":"plot_history_loss_and_acc(history_cnn_2)","5facdc00":"pred_val_cnn2 = model_cnn_2.predict_classes(X_val)\nplot_confusion_matrix(y_val, pred_val_cnn2)\nprint(classification_report(y_val, pred_val_cnn2))\nacc_cnn2 = accuracy_score(y_val, pred_val_cnn2)\nprint(acc_cnn2)","4ca400a5":"sample_submission = pd.read_csv('..\/input\/sample_submission.csv')\nif mode == \"edit\" :\n    X = X[:nr_samples\/\/2]\n    y = y[:nr_samples\/\/2]\n    X_test = X_test[:nr_samples\/\/2]\n    sample_submission = sample_submission[:nr_samples\/\/2]","f6b0beef":"print(X.shape)\nprint(y.shape)\nprint(X_test.shape)","d07060d6":"print(GridCV_Perceptron.best_params_)\nGridCV_Perceptron.best_estimator_.fit(X,y)","4268f999":"pred_test_perc = GridCV_Perceptron.best_estimator_.predict(X_test)\nresult_perc = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_perc})\nresult_perc.to_csv(\"subm_perc.csv\",index=False)","6e6934c3":"print(GridCV_LR.best_params_)\nGridCV_LR.best_estimator_.fit(X,y)","04d3a551":"pred_test_lr = GridCV_LR.best_estimator_.predict(X_test)\nresult_lr = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_lr})\nresult_lr.to_csv(\"subm_lr.csv\",index=False)","42b65b94":"clf_knn.fit(X,y)","e4780c9e":"pred_test_knn = clf_knn.predict(X_test)\nresult_knn = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_knn})\nresult_knn.to_csv(\"subm_knn.csv\",index=False)","c138309a":"print(GridCV_RF.best_params_)\nGridCV_RF.best_estimator_.fit(X,y)","0570a942":"pred_test_rf = GridCV_RF.best_estimator_.predict(X_test)\nresult_rf = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_rf})\nresult_rf.to_csv(\"subm_rf.csv\",index=False)","ae53f1c0":"clf_svm.fit(X,y)","0a241cbd":"pred_test_svm = clf_svm.predict(X_test)\nresult_svm = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_svm})\nresult_svm.to_csv(\"subm_svm.csv\",index=False)","bfad6632":"print(GridCV_MLP.best_params_)\nGridCV_MLP.best_estimator_.fit(X,y)","3bd2dcc0":"pred_test_mlp = GridCV_MLP.best_estimator_.predict(X_test)\nresult_mlp = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_mlp})\nresult_mlp.to_csv(\"subm_mlp.csv\",index=False)","757170a2":"y = to_categorical(y, 10)","ebaac274":"model_dense_1.fit(X,y)\npred_test_fc1 = model_dense_1.predict_classes(X_test)\nresult_fc1 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_fc1})\nresult_fc1.to_csv(\"dense_1.csv\",index=False)","b49af4f1":"model_dense_2.fit(X,y)\npred_test_fc2 = model_dense_2.predict_classes(X_test)\nresult_fc2 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_fc2})\nresult_fc2.to_csv(\"dense_2.csv\",index=False)","9da464ce":"model_dense_3.fit(X,y)\npred_test_fc3 = model_dense_3.predict_classes(X_test)\nresult_fc3 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_fc3})\nresult_fc3.to_csv(\"dense_3.csv\",index=False)","38ce559e":"X = X.values.reshape(X.shape[0], img_rows, img_cols, 1)\nX_test = X_test.values.reshape(X_test.shape[0], img_rows, img_cols, 1)\n#y = to_categorical(y, 10)","19fce4e8":"batchsize = 128\nepochs = 12\nmodel_cnn_1 = cnn_model_1('relu')\nmodel_cnn_1.fit(X, y, epochs=epochs, batch_size=batchsize, verbose=0)","2559518f":"pred_test_cnn_1 = model_cnn_1.predict(X_test)\npred_test_cnn_1 = np.argmax(pred_test_cnn_1,axis=1)\nresult_cnn_1 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_cnn_1})\nresult_cnn_1.to_csv(\"subm_cnn_1.csv\",index=False)","b3e564db":"batch_size=90\nepochs=30\nmodel_cnn_2 = cnn_model_2(adadelta, categorical_crossentropy)\nmodel_cnn_2.fit(X, y, epochs=epochs, batch_size=batchsize, verbose=0)","4e369db7":"pred_test_cnn_2 = model_cnn_2.predict(X_test)\npred_test_cnn_2 = np.argmax(pred_test_cnn_2,axis=1)\nresult_cnn_2 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_cnn_2})\nresult_cnn_2.to_csv(\"subm_cnn_2_adadelta.csv\",index=False)","0bbc4739":"predictions = {'PERC': pred_test_perc, 'LR': pred_test_lr, 'KNN': pred_test_knn, \n               'RF': pred_test_rf, 'SVM': pred_test_svm, 'MLP': pred_test_mlp, \n               'DENSE1': pred_test_fc1, 'DENSE2': pred_test_fc2, 'DENSE3': pred_test_fc3, \n               'CNN1': pred_test_cnn_1, 'CNN2': pred_test_cnn_2}\ndf_predictions = pd.DataFrame(data=predictions) \ndf_predictions.corr()","6a553bd2":"list_classifiers = ['PERC','LR','KNN','RF','SVM',\n                    'MLP','DENSE1','DENSE2','DENSE3',\n                    'CNN1','CNN2']","7996767b":"val_scores = [acc_perc, acc_lr, acc_knn, acc_rf, \n               acc_svm, acc_mlp, acc_fc1, acc_fc2, \n               acc_fc3, acc_cnn1, acc_cnn2]","0c727798":"score_perc  = 0.88057\nscore_lr    = 0.88700\nscore_knn   = 0.96557\nscore_rf    = 0.96028\nscore_svm   = 0.98100\nscore_mlp   = 0.96985\n\nscore_dns_1  = 0.95971 \nscore_dns_2  = 0.96228      \nscore_dns_3  = 0.96128\nscore_cnn_1  = 0.98928\nscore_cnn_2  = 0.99028","ec64c76f":"test_scores = [score_perc, score_lr, score_knn, score_rf, score_svm, score_mlp,\n               score_dns_1, score_dns_2, score_dns_3, score_cnn_1, score_cnn_2]","229b3091":"trace1 = go.Scatter(x = list_classifiers, y = val_scores,\n                   name=\"Validation\", text = list_classifiers)\ntrace2 = go.Scatter(x = list_classifiers, y = test_scores,\n                   name=\"Submission\", text = list_classifiers)\n\ndata = [trace1, trace2]\n\nlayout = dict(title = \"Validation and Submission Scores\", \n              xaxis=dict(ticklen=10, zeroline= False),\n              yaxis=dict(title = \"Accuracy\", side='left', ticklen=10,),                                  \n              legend=dict(orientation=\"v\", x=1.05, y=1.0),\n              autosize=False, width=750, height=500,\n              )\n\nfig = dict(data = data, layout = layout)\niplot(fig)","9661b9df":"model_cnn_2.optimizer","6d537789":"model_cnn_2_rmsprop = cnn_model_2(RMSprop(), categorical_crossentropy)\nmodel_cnn_2_rmsprop.optimizer","0fc51ecd":"model_cnn_2.fit(X, y, epochs=epochs, batch_size=batchsize, verbose=0)\npred_test_cnn_2 = model_cnn_2.predict(X_test)\npred_test_cnn_2 = np.argmax(pred_test_cnn_2,axis=1)\nresult_cnn_2 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_cnn_2})\nresult_cnn_2.to_csv(\"subm_cnn_2_rmsprop.csv\",index=False)","1ecfb4fa":"model_cnn_2_adam = cnn_model_2(Adam(), categorical_crossentropy)\nmodel_cnn_2_adam.optimizer","4979bd43":"model_cnn_2.fit(X, y, epochs=epochs, batch_size=batchsize, verbose=0)\npred_test_cnn_2 = model_cnn_2.predict(X_test)\npred_test_cnn_2 = np.argmax(pred_test_cnn_2,axis=1)\nresult_cnn_2 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_cnn_2})\nresult_cnn_2.to_csv(\"subm_cnn_2_adam.csv\",index=False)","b5257763":"arr_y_val = y_val.values\nfalse_cnn2 = pred_val_cnn2 != arr_y_val","6ddc3b10":"fig, axs = plt.subplots(5, 5, sharex=True, sharey=True, figsize=(10,12))\naxs = axs.flatten()\nfor i, n  in enumerate(false_cnn2[:25]):\n    im = X_val[false_cnn2][i,:,:,0]\n    axs[i].imshow(im, cmap=plt.get_cmap('gray'))\n    title = (\"predicted: \" + str(pred_val_cnn2[false_cnn2][i]) + \n            \"\\n\" + \"true: \" + str(arr_y_val[false_cnn2][i]) )\n    axs[i].set_title(title)\nplt.tight_layout()    ","40de64aa":"**For the GridSearchCV studies on finding the best model parameters we fit the classifiers using cross validation.**  \n**This reduces the number of training examples because a portion of the data is used for validation.**  \n**We now fit the classifiers on the complete training set (42000 samples).**  \n**Then we use this new fit to make predictions for the test dataset (28000 samples).**","2967e019":"# Part 1 : Exploring the Data","e2f0ddaf":"### setting train and validation data","9ab9f4ff":"Convnets:  \n[Udacity](https:\/\/www.youtube.com\/watch?v=jajksuQW4mc) ","19e00629":"### get_best_score for GridSearchCV","94f1cbf5":"# Part 6: Different Optimizers","d0286a84":"### 3.1.1 Keras: only input and output layer","a9ab222e":"### Random Forest Classifier","9aab964c":"**MLP**","df08bc0a":"# **MNIST: Sklearn and Keras** \n**Comparing the performance of ML and DL classification models on**  \n**the Digit Recognizer (MNIST) competition**  \n\n\n*from Kaggle:*   \nMNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision.  \nIn this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images.","1f8429cf":"Using GridSearchCV with KNN takes very long for this dataset.  \nTherefore I fit the data with one parameter: neighbors = 10  \nThe resulting accuracy is already quite good.","a9d61d2b":"# Part 2 : Sklearn Classifiers","3eecb33a":"from validation data","231ee561":"**Random Forest**","345798d4":"## Fitting on all training data","513eb771":"Like for KNN, GridSearchCV for SVM takes very long, so I only fit one good set of parameters here.","fca311a1":"### Distribution of labels \n**(in train set)**","9bf515d8":"### Check some images","caae9a7a":"**My first kernel for the MNIST Digit Recognizer Competition**  \n\nThe kernel includes an **EDA part** on the distribution of labels and some sample images for each digit.  \nWe explore how the images of handwritten digits are stored as 784 values (pixels).  \nWe transform these 784 pixels back to images of 28 x 28 (width x heigth) and have a look at possible difficulties in identifying and distinguishing certain digits.  \nThe part on **prediction modelling** starts with **classifiers from sklearn**:  \nPerceptron, Logistic Regression, Random Forest, SVM, Multi Layer Perceptron  \nand then continues to **Neural Networks with Keras**:   \nDense (1,2 and 3 layers) and CNN (Conv2D, MaxPooling, Dropout)","54acad4e":"# Part 3: NN Classifiers with Keras","e3ac1a8f":"Adadelta","a569a109":"Correlation of prediction results","53c7390a":"## Validation scores","2b396c94":"**dense_3**","716a2137":"### **some useful functions**","7cfe4420":"from submission ","97952f45":"## Conclusions on classifier performance","d5db5fc1":"* Best accuracy around 99% is obtained with CNN1 and CNN2.  \n* SVC also has very good accuracy with 98%  \n* Except for Perceptron and Logistic regression, all classifiers get accuarcy similar to humans (above 95%)  \n* Fully connected NNs (dense 1,2,3) show most overfitting (validation score much larger than test score)","362ff203":"### plot_history_loss_and_acc","8d87ff89":"### **Reading the data**","a4f11406":"**Outline of the kernel:**\n\n**Part 0: Imports, functions**\n\n[some useful functions](#some-useful-functions)\n\n\n**Part 1: Exploring the Data**\n\n[Distribution of labels](#Distribution-of-labels)  \n[first 10 samples for each digit](#first-10-image-samples-for-each-digit)  \n[Conclusions on EDA](#Conclusions-on-EDA) \n\n\n**Part 2: Sklearn Classifiers** \n\n[Perceptron](#Perceptron)  \n[Logistic Regression](#Logistic-Regression)  \n[KNN](#KNN)  \n[Random Forest Classifier](#Random-Forest-Classifier)  \n[Support Vector Machine Classifier](#Support-Vector-Machine-Classifier)  \n[Multi Layer Perceptron](#Multi-Layer-Perceptron)\n\n\n**Part 3: NN and CNN Classifiers with Keras**\n\n3.1 Fully-Connected Neural Networks  \n[Keras: dense, 1 hidden layer](#Keras:-1-hidden-layer)  \n[Keras: dense, 2 hidden layers](#Keras:-2-hidden-layers)  \n[Keras: dense, 3 hidden layers](#Keras:-3-hidden-layers)  \n3.2 Convolutional Neural Networks, CNN  \n[features : reshaping 1d vector to 2d images](#features-:-reshaping-1d-vector-to-2d-images)  \n[Keras: CNN, model 1](#Keras:-CNN-model-1)  \n[Keras: CNN, model 2](#Keras:-CNN-model-2)\n\n**Part 4: Predictions for test data**  \n[Fitting on all training data](#Fitting-on-all-training-data)  \n\n**Part 5: Comparing classifier performance**  \n[Validation scores](#Validation-scores)  \n[Test scores](#Test-scores)  \n\n\n**Part 6: Different optimizers**  \nadadelta  \nrmsprop  \nadam  \n\n**Part 7: Investigating false predictions**\n","8c92d64d":"### KNN","88763866":"**some global variables**","d7c31373":"### **features : reshaping 1d vector to 2d images**\n\n(784) --> (28,28,1)","c8b673a6":"## 3.2 Keras : Convolutional Neural Networks, CNN","161e25ae":"**get indexes of first 10 occurences for each number**","b9caa964":"### Perceptron","36f9258e":"# Part 5: Comparing classifier performance","690e8f06":"'RandomForestClassifier' object has no attribute 'loss_curve_'","707212d2":"### **Conclusions on EDA**","70b99570":"# Part 4: Predictions for test data","26b3406a":"## Keras: CNN model 1\nConv2D (32, (3, 3))  \nConv2D (64, (3, 3))  \nPooling2D (2,2)  \nDropout (0.25)\nFlatten  \nDense(128, relu)  \nDropout (0.5)  \nDense(10, softmax)","6c3c3369":"Adam","a0fd5224":"**Logistic Regression**","ca84e6a9":"### Logistic Regression","c773007a":"### Normalization","f710ad14":"### Support Vector Machine Classifier","f6091b4e":"**dense_1**","186d0baa":"### Multi Layer Perceptron","488d11e3":"**CNN 1**","fb8605e0":"**SVM**","581827d4":"### Keras: 1 hidden layer","414d49b6":"## 3.1 Fully-Connected Neural Networks  \ndense layers : every node is connected to every other node in the next layer","79c9cc22":"**reshape for CNN**","3c7209f7":"* The 6s in row 0 1 and 6 look close to a 4  \n* The 5 in row 1 looks close to a 6 and the 5 in row 8 looks close to a 8  \n* The 4 in row 4 is wriiten differently as the other 4s and the 4 in row 7 almost looks like a 7  \n* The 8 in row 8 is wriiten differently as the other 8s  ","be5bfcc6":"**dense_2**","871af476":"# Part 0: Imports, Functions","d8750638":"## Test scores","8df446d8":"### Keras: 3 hidden layers","46efff98":"# Part 7: Investigating false predictions","11affd6f":"### first 10 image samples for each digit","e74593e8":"RMSprop","64ee8352":"### Keras: 2 hidden layers","f9d17747":"**Perceptron**","fd374fc1":"**KNN**","325e2949":"### print Classification Report and Accuracy","b653e7ad":"### plot_confusion_matrix","3ab4f516":"**CNN 2**","c366c4b1":"### Keras: CNN model 2  \nConv2D (32, (3, 3))  \nPooling2D (2,2)  \nConv2D (32, (3, 3))  \nPooling2D (2,2)  \nFlatten  \nDense(256, relu)  \nDense(10, softmax)  ","6317a8d9":"1. **We can see that there is a lot of variety in the look of the numbers**  \n2. **The digits are obviously written by many different people**\n3. **And it seems that there might be difficulties identifying some of the digits correctly also for humans:**\n\n\n"}}