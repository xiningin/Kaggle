{"cell_type":{"7ab5a11f":"code","bb6e9456":"code","63b7f4b4":"code","f158164b":"code","e2301e81":"code","67acc29c":"code","da15cc0d":"code","e74e9e42":"code","ad5ae9a1":"code","39a957f1":"code","eb22d5e0":"code","81bd6cff":"code","6b20d2c0":"code","ef4a984e":"code","a51403c2":"code","cde35760":"code","88e9ad52":"code","ef69afb4":"code","0d95616b":"code","569f5950":"code","e7b0192c":"code","67af19b3":"code","f205235a":"code","b985957d":"code","f712e52e":"markdown","c391080e":"markdown","fafa7a46":"markdown","5f147657":"markdown","4cee88a4":"markdown","ffa0b510":"markdown","4b1a041c":"markdown","bc1c59d3":"markdown","e0ded167":"markdown","24543c3d":"markdown","f3d5e7f8":"markdown","31e4d56f":"markdown","6ef9d7fb":"markdown","7f70f044":"markdown","801ba322":"markdown","27c2d108":"markdown","4eec10b3":"markdown","4ded880c":"markdown","90e0f338":"markdown","8576b2f3":"markdown","1495e29c":"markdown","57a41346":"markdown","d41398fe":"markdown","2e636ac4":"markdown","a3bea8a7":"markdown","4968df4f":"markdown","3618828e":"markdown","0befde43":"markdown","4c4c5ff9":"markdown","b1d37aea":"markdown","b4d6de93":"markdown","9d5761db":"markdown","c74d0441":"markdown","3ae4974b":"markdown","67a3b24e":"markdown","32c33869":"markdown","baa61c83":"markdown","9f4ff425":"markdown","ff6a3e95":"markdown","e2b2f832":"markdown","7c481d45":"markdown","a8b01ecf":"markdown","54427a52":"markdown","daf6cecf":"markdown","77244bf2":"markdown","710c9485":"markdown","9c06d9e2":"markdown","292791f1":"markdown","38303d8f":"markdown","77de10fe":"markdown","17c9a80e":"markdown","df2d0850":"markdown","85df62e6":"markdown","937dc3f3":"markdown","08730896":"markdown","b62fddda":"markdown"},"source":{"7ab5a11f":"import random\nimport scipy\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom scipy.stats import kstest\nsns.set(style=\"darkgrid\")","bb6e9456":"# Create a Bernoulli random variable Xi with parameter p\nN = 10000\nXi = np.random.binomial(n=1, p=0.8, size=N).tolist()\n\n# Plot it\nsns.histplot(Xi, stat='probability', discrete=True, shrink=.2);\nplt.xlabel('$X_i$');\nplt.title('Distribution of $X_i$');","63b7f4b4":"# sample size and number of trials\nn = 8000\ntrials = 1000\n\n# true mean and std\ntheta = np.mean(Xi)\nsigma = np.std(Xi)\n\nZ = []\n# for each trial...\nfor i in range(trials):\n    \n    # take n samples with replacement from Xi and average them\n    THETA = np.mean(random.choices(Xi,k=n))\n    \n    # subtract mean, divide by sigma and multiply by sqrt(n)   \n    z = (THETA - theta) \/ (sigma\/np.sqrt(n))\n    \n    # store outcome\n    Z.append(z)\n    \n# Fit a normal distribution to Z\nmu, std = norm.fit(Z)\n\n# Plot the histogram\nplt.hist(Z, bins=25, density=True, alpha=0.6, color='g')\n\n# Plot the PDF\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = norm.pdf(x, mu, std)\nplt.plot(x, p, 'k', linewidth=2)\n\n# title\ntitle = \"Fit results: mu = %.2f,  std = %.2f\" % (mu, std)\nplt.suptitle('Sampling distribution of $Z$')\nplt.title(title)\nplt.ylabel('Density')\nplt.xlabel('$Z$');\nplt.show()","f158164b":"_, pvalue = kstest(Z, 'norm')\n\nif pvalue > 0.05:\n    print('The data are normally distributed')\nelse:\n    print('The data are not normally distributed')","e2301e81":"# sample size and number of trials\nn = 8000\ntrials = 1000\n\n# true mean and std\ntheta = np.mean(Xi)\nsigma = np.std(Xi)\n\n# finite population correction\nf = np.sqrt((N-n)\/(N-1))\n\nZ = []\n# for each trial...\nfor i in range(trials):\n    \n    # take n samples w\/o replacement from Xi and average them\n    THETA = np.mean(random.sample(Xi,n))\n    \n    # subtract mean, divide by sigma and multiply by sqrt(n) \n    # also aply finite population correction\n    z = (THETA - theta) \/ (f*sigma\/np.sqrt(n))\n    \n    # store outcome\n    Z.append(z)\n    \n# Fit a normal distribution to Z\nmu, std = norm.fit(Z)\n\n# Plot the histogram\nplt.hist(Z, bins=25, density=True, alpha=0.6, color='magenta')\n\n# Plot the PDF\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = norm.pdf(x, mu, std)\nplt.plot(x, p, 'k', linewidth=2)\n\n# title\ntitle = \"Fit results: mu = %.2f,  std = %.2f\" % (mu, std)\nplt.suptitle('Sampling distribution of $Z_f$')\nplt.title(title)\nplt.ylabel('Density')\nplt.xlabel('$Z_f$');\nplt.show()","67acc29c":"_, pvalue = kstest(Z, 'norm')\n\nif pvalue > 0.05:\n    print('The data are normally distributed')\nelse:\n    print('The data are not normally distributed')","da15cc0d":"# Population size\nN = 10000\n\n# Create a Bernoulli random variable Xi with parameter p\nnp.random.seed(seed=0)\nXi = np.random.binomial(n=1, p=0.55, size=N).tolist()\n\n# Plot it\nsns.histplot(Xi, stat='probability', discrete=True, shrink=.2);\nplt.xlabel('$X_i$');\nplt.title('Distribution of $X_i$');\n\nprint('The true value of the unknown parameter \u03b8 is:', np.mean(Xi))","e74e9e42":"# Change this random seed to get a different confidence interval\nrandom.seed(25)\n\n# sample size\nn = 50\n\n# sample with replacement\nsample = random.choices(Xi,k=n)\n\n# sample mean\nTHETA = np.mean(sample)\nprint('Sampling with replacement sample mean:', THETA)","ad5ae9a1":"# Approximate the true standard deviation with the sample standard deviation\ns = np.std(sample, ddof=1)\n\n# Calculate the margin of error for a 95% confidence level\nmargin_of_error = (1.96 * s \/ np.sqrt(n))\n\n# Calculate the confidence interval\nCI = [THETA - margin_of_error, THETA + margin_of_error]\nprint('Sampling with replacement using the normal table CI:', [round(el,3) for el in CI])","39a957f1":"import scipy.stats as st\n# create 95% confidence interval for population mean\nst.norm.interval(alpha=0.95, loc=np.mean(sample), scale=st.sem(sample))","eb22d5e0":"margin_of_error = 0.05\ns = 0.5\n\npoll_size = (1.96*s\/margin_of_error)**2\n\nprint('Poll size estimation w\/o the finite population correction:',round(poll_size))","81bd6cff":"# Change this random seed to get a different confidence interval\nrandom.seed(25)\n\n# sample size\nn = 50\n\n# sample with replacement\nsample = random.sample(Xi,n)\n\n# sample mean\nTHETA = np.mean(sample)\nprint('Sampling w\/o replacement sample mean:', THETA)","6b20d2c0":"# Approximate the true standard deviation with the sample standard deviation\ns = np.std(sample, ddof=1)\n\n# finite population correction\nf = np.sqrt((N-n)\/(N-1))\n\n# Calculate the margin of error for a 95% confidence level\nmargin_of_error = 1.96 * f * s \/ np.sqrt(n)\n\n# Calculate the confidence interval\nCI = [THETA - margin_of_error, THETA + margin_of_error]\nprint('Sampling w\/o replacement using the normal table CI:', [round(el,3) for el in CI])","ef4a984e":"margin_of_error = 0.05\ns = 0.5\ngamma = (margin_of_error\/(1.96*s))**2\n\npoll_size = N \/ (gamma*N - gamma + 1)\n\nprint('Poll size estimation w\/o the finite population correction:', round(poll_size))","a51403c2":"# Population & sample size\nN = 10000\nn = 50\n\n# Create a Bernoulli random variable Xi with parameter p\nnp.random.seed(seed=0)\nXi = np.random.binomial(n=1, p=0.55, size=N).tolist()\n\n# sample with replacement\nrandom.seed(25)\nsample = random.choices(Xi,k=n)\n\n# sample mean\nTHETA = np.mean(sample)\nprint('Sampling with replacement sample mean:', THETA)","cde35760":"x = np.arange(start=0.5, step=0.01, stop=1)\ny = x - 1.645*np.sqrt(x*(1-x)\/50)\nplt.plot(x,y)\nplt.xlabel('$\u03b8_0$')\nplt.ylabel('RHS');","88e9ad52":"import matplotlib as mpl\n\nx = np.arange(start=-3, step=0.1, stop=3)\n\ndef f(x):\n    return np.sqrt(2*np.pi) * np.exp(-(x**2)\/2)\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax.plot(x, f(x), 'k')\n\nCOLOR = 'blue'\nmpl.rcParams['text.color'] = COLOR\n\nax.annotate('$t$',\n            xy=(-0.707, 0),\n            xytext=(0.5, 0.3),\n            textcoords='figure fraction',\n            arrowprops=dict(facecolor='blue', shrink=0.05),\n            horizontalalignment='center',\n            verticalalignment='center')\n\nsection = np.arange(start=-3, step=0.1, stop=-0.707)\nplt.fill_between(section,f(section), color='blue', hatch='-', facecolor=\"none\", label='$p-value$')\n\nCOLOR = 'red'\nmpl.rcParams['text.color'] = COLOR\n\nax.annotate(\"$\u03be'$\",\n            xy=(-1.465, 0),\n            xytext=(0.3, 0.05),\n            textcoords='figure fraction',\n            arrowprops=dict(facecolor='red', shrink=0.05),\n            horizontalalignment='center',\n            verticalalignment='baseline')\n\nsection = np.arange(start=-3, step=0.1, stop=-1.465)\nplt.fill_between(section,f(section), color='red', hatch='\/', facecolor=\"none\", edgecolor='red', label='$\u03b1$')\n\nCOLOR = 'k'\nmpl.rcParams['text.color'] = COLOR\nax.legend(loc='right');\n\nax.annotate('Reject $H_0$', xy=(-2.7, 2.75))\nax.hlines(y=3, xmin=-3, xmax=3, ls='--')\nax.vlines(x=-1.465, ymin=0, ymax=3, ls='--')\nax.annotate('Fail to reject $H_0$', xy=(-0.52, 2.75));\n\nplt.suptitle('$One$ $tailed$ $test$')\nax.set_title('$f_T(t;H_0)$');\nax.set_xlabel('$T$');\nax.set_ylabel('Density');","ef69afb4":"# Our poll test statistic realization\ntheta_hat = 0.44\nt = (theta_hat-0.5) \/ (np.sqrt(0.5*(1-0.5)\/n))\n\n# sample size\nn = 50\ntrials = 1000000\n\n# init\ncount = 0 \n\n# Ho: theta0 >= 0.5\ntheta0 = 0.5\n\n# For each trial...\nfor i in range(trials):\n\n    # conduct poll assuming Ho is true\n    sample = np.random.binomial(n=1, p=theta0, size=n)\n    \n    # find the sample mean and the test statistic\n    THETA = (sample==1).sum()\/n\n    T = (THETA-theta0) \/ (np.sqrt(theta0*(1-theta0)\/n))\n    \n    # store the number of occurences for which T<=t\n    if T <= t:\n        count += 1\n        \n# find the probability of such occurences = p-value        \np_value = count\/trials\np_value","0d95616b":"scipy.stats.binom_test(22, 50, 0.5, alternative='less')","569f5950":"n = 50\nobserve = 22\n\nbinoms2 = 0\nfor i in range(1, observe+1):\n    binoms2 += scipy.special.binom(n, i)\n    \nbinoms2 * 0.5**n","e7b0192c":"import matplotlib as mpl\n\nx = np.arange(start=-3, step=0.01, stop=3)\n\ndef f(x):\n    return np.sqrt(2*np.pi) * np.exp(-(x**2)\/2)\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax.plot(x, f(x), 'k')\n\nCOLOR = 'blue'\nmpl.rcParams['text.color'] = COLOR\n\nax.annotate('$t$',\n            xy=(-0.707, 0),\n            xytext=(-0.5, 0.2),\n            arrowprops=dict(facecolor='blue', shrink=0.05),\n            horizontalalignment='center',\n            verticalalignment='center')\n\nsection = np.arange(start=-3, step=0.01, stop=-0.707)\nplt.fill_between(section,f(section), color='blue', hatch='-', facecolor=\"none\", label='$pv\/2$')\n\nCOLOR = 'red'\nmpl.rcParams['text.color'] = COLOR\n\nax.annotate(\"$-\u03be'$\",\n            xy=(-1.96, 0),\n            xytext=(-1.5, -0.3),\n            arrowprops=dict(facecolor='red', shrink=0.05),\n            horizontalalignment='center',\n            verticalalignment='baseline')\n\nax.annotate(\"$+\u03be'$\",\n            xy=(+1.96, 0),\n            xytext=(1.5, -0.3),\n            arrowprops=dict(facecolor='red', shrink=0.05),\n            horizontalalignment='center',\n            verticalalignment='baseline')\n\nsection = np.arange(start=-3, step=0.01, stop=-1.96)\nplt.fill_between(section,f(section), color='red', hatch='\/', facecolor=\"none\", edgecolor='red', label='$\u03b1\/2$')\n\nsection = np.arange(start=+1.96, step=0.01, stop=+3)\nplt.fill_between(section,f(section), color='red', hatch='\/', facecolor=\"none\", edgecolor='red')\n\nCOLOR = 'k'\nmpl.rcParams['text.color'] = COLOR\nax.legend(loc='right');\n\nax.annotate('Reject $H_0$', xy=(-2.9, 2.75))\nax.hlines(y=3, xmin=-3, xmax=3, ls='--')\nax.vlines(x=-1.96, ymin=0, ymax=3, ls='--')\nax.annotate('Fail to reject $H_0$', xy=(-0.52, 2.75));\n\nax.annotate('Reject $H_0$', xy=(+2.1, 2.75))\nax.vlines(x=+1.96, ymin=0, ymax=3, ls='--')\n\nplt.suptitle('$Two$ $tailed$ $test$')\nax.set_title('$f_T(t;H_0)$');\nax.set_xlabel('$T$');\nax.set_ylabel('Density');","67af19b3":"# sample size\nn = 50\ntrials = 1000000\n\n# init\ncount_less = 0 \ncount_greater = 0\n\n# Ho: theta0 = 0.5\ntheta0 = 0.5\n\n# Our poll test statistic realization\ntheta_hat = 0.44\nt = (theta_hat-theta0) \/ (np.sqrt(theta0*(1-theta0)\/n))\n\n# For each trial...\nfor i in range(trials):\n    \n    # conduct poll assuming Ho is true\n    sample = np.random.binomial(n=1, p=theta0, size=n)  \n    \n    # find the sample mean and the test statistic\n    THETA = (sample==1).sum()\/n\n    T = (THETA-theta0) \/ (np.sqrt(theta0*(1-theta0)\/n))\n    \n    # store the number of occurences for which T<=t\n    if T <= t:\n        count_less += 1\n    # store the number of occurences for which T>=t\n    if T >= t:\n        count_greater += 1\n        \n# find the probability of such occurences = p-value        \np_value = 2*min(count_less,count_greater)\/trials\np_value","f205235a":"scipy.stats.binom_test(22, 50, 0.5, alternative='two-sided')","b985957d":"import scipy\n\nn = 50\nobserve = 22\n\nbinoms1 = 0\nfor i in range(observe, n+1):\n    binoms1 += scipy.special.binom(n, i)\n    \nbinoms2 = 0\nfor i in range(1, observe+1):\n    binoms2 += scipy.special.binom(n, i)\n    \n2 * min(binoms1,binoms2) * 0.5**n","f712e52e":"We will close by asking the question \"is there a clear winner or the result is still undecided\"? To answer that question, we will again formulate two hypotheses:\n\n$$H_0 : \\theta_0 = 0.5 \\\\ \nH_1 : \\theta_1 \\neq 0.5$$\n\nIf the null hypothesis was true, I should be getting a sample mean close to 0.5, so:\n\n$$\\left| \\hat{\\Theta}_n - \\theta_0 \\right| < \\xi$$\n\nIf $H_0$ is true, the probability of this event should be high:\n    \n$$P \\left( \\left| \\hat{\\Theta}_n - \\theta_0 \\right| < \\xi ; H_0 \\right) = 1-\\alpha$$\n\nTo invoke the central limit theorem:\n\n$$P \\left( \\left| \\frac{\\hat{\\Theta}_n - \\theta_0}{\\sqrt{\\theta_0(1-\\theta_0)\/n}} \\right| < \\frac{\\xi}{\\sqrt{\\theta_0(1-\\theta_0)\/n}} ; H_0 \\right) = 1-\\alpha$$\n\nor:\n\n$$ P \\left( \\left| T \\right| < \\xi' ; H_0 \\right) = 1-a \\xrightarrow{\\alpha=0.05}\\xi' = 1.96$$\n\nFrom $\\xi'$ we can find $\\xi=0.138$, therefore we have that:\n\n$$\\left| \\hat{\\Theta}_n - \\theta_0 \\right| < \\xi \\Rightarrow \\left| 0.45-0.5 \\right| < 0.138$$ \n\nwhich is true. Or by using $T$ as a statistic:\n\n$$ \\left| \\hat{\\Theta}_n - \\theta_0 \\right| < \\xi \\Rightarrow  \\left| \\frac{\\hat{\\Theta}_n - \\theta_0}{\\sqrt{\\theta_0(1-\\theta_0)\/n}} \\right| < \\frac{\\xi}{\\sqrt{\\theta_0(1-\\theta_0)\/n}}$$\n\nWe also conclude at a true inequality:\n\n$$ \\left| T \\right| < \\xi' \\Rightarrow 0.707 < 1.96 $$\n\nTherefore in both cases we conclude that we fail to reject $H_0$ at the 5% significance level. This means that we cannot reject the belief which asserts that given the data the result is still undecided. Let's plot the two tailed test case now:","c391080e":"### 2.a. - Analytical solution","fafa7a46":"### c) Experiment to test normality","5f147657":"#### b.2 - Sample size","4cee88a4":"We' re still using the same test statistic as before in the left tailed test, namely $T = \\frac{\\hat{\\Theta}_n - \\theta_0}{\\sqrt{\\theta_0(1-\\theta_0)\/n}}$. The plot shows its distribution. \n\nThe critical value $\\xi'$ however is different. It is such that $P \\left( \\left| T \\right| < \\xi' ;H_0 \\right) = P \\left( -\\xi' < T < \\xi' ;H_0 \\right) = 1- \\alpha$, which corresponds to the area under the curve between $-\\xi'$ and $\\xi'$. The remaining area outside this interval is $\\alpha$, and due to symmetry each piece has area $\\alpha \/ 2$.\n\nUnder $H_0$ we arrived at the decision rule $\\left| T \\right| < \\xi'$, so now in order to reject the null hypothesis either $t<-\\xi'$ or $t>\\xi'$ must be true. This is exactly the same as saying that either $P \\left( T \\le t ; H_0 \\right) \\lt \\alpha\/2$ or $P \\left( T \\ge t ; H_0 \\right) \\lt \\alpha\/2$ must be true. This condition can be reduced to: \n\n$$2min\\left\\{ P \\left( T \\le t ; H_0 \\right), P \\left( T \\ge t ; H_0 \\right) \\right\\} \\lt \\alpha$$ \n\nwhich is the **p-value** $pv$ for the two tailed test. If this statement is true then we reject $H_0$ at the significance level $\\alpha$. In our experiment the test statistic $T$ took the value $t = -0.848$, which means that $pv = 2P \\left( T<-0.707 \\right) \\approx 2 \\times 0.239 = 0.478$ which is larger $\\alpha$, so we fail to reject $H_0$ at the significance level $\\alpha$.","ffa0b510":"From the new margin of error formula, solving for $n$:\n\n$$ n = \\frac{N}{\\gamma N - \\gamma +1}, \\text{with } \\gamma = (\\varepsilon \/ zs)^2 $$\n\nWith the population correction factor, the poll size should be:","4b1a041c":"A final note on the use of language: We never prove anything in statistics. \n\nIn the final example we didn't prove that the approval rating is 0.5; we only stated that we can say with high confidence that we cannot disprove the possibility of the approval rating being 0.5, therefore we **failed to reject** that. We support this argument on the fact that the value 0.44 that we observe in the poll is not highly unlikely if we assume that the true approval rating is 0.5\n\n$a$ is also called the **false rejection probability - type I error**: it is the probability of rejecting the null hypothesis even though it is true. So even if we **do reject** the null hypothesis, we also do not prove that it is false. We can say though with high certainty $a$ that the data we collected are highly unlikely to have occured under this hypothesis. \n\nBut there are also other factors to consider; what if the sampling was not truly random? e.g. if we ask about everyone's mood on Monday, the results may differ from Friday.","bc1c59d3":"Let's say we poll $n=50$ people with replacement from this population and average the result.","e0ded167":"*Note: Specifically it has been found that the binomial can be approximated as a normal distribution if $np>5 \\text{ and } n(1-p)>5$. That will be the case throughout this document.*","24543c3d":"This simulation will be essentially identical to the previous one, with the exception of storing both the number of occurences where `T>=t` and where `T<=t`. These two different numbers will be stored in the variables `count_less` and `count_greater` respectively. Then we take the `min` of those two numbers, divide by the sample size `n` and multiply by `2`.","f3d5e7f8":"Let us summarize all the important concepts along with the plot:\n\nOur test statistic $T$ is normally distributed with zero mean and unit variance. The bell-shaped black line is its probability distribution, where the possible realizations of $T$ are on the x-axis and their corresponding probability densities are on the y-axis . From the realized value of $\\hat{\\Theta}_n$ we can find what the realized value $t$ of $T$ is, where $T = \\frac{\\hat{\\Theta}_n - \\theta_0}{\\sqrt{\\theta_0(1-\\theta_0)\/n}}$.\n\nThe critical value $\\xi'$ is such that $P \\left( T<\\xi' ;H_0 \\right) = \\alpha$. It defines two regions, a rejection region where we reject $H_0$ and another region where we fail to reject $H_0$. That is because under $H_0$ we arrived at the decision rule $T > \\xi'$, which is an inequality that must be true if $H_0$ is true. This leads us to say that:\n\n- if $t \\gt \\xi'$ then we fail to reject $H_0$ at the $a$ significance level or at the $1-a$ confidence level.\n- if $t \\le \\xi'$ then we reject $H_0$ at the $a$ significance level or at the $1-a$ confidence level.\n\nWe can say the **exact same thing** using areas or **p-values** $pv$:\n\n- if $pv = P \\left(T<t;H_0 \\right) \\gt \\alpha$ then we fail to reject $H_0$ at the $a$ significance level or at the $1-a$ confidence level.\n- if $pv = P \\left(T<t;H_0 \\right) \\le \\alpha$ then we reject $H_0$ at the $a$ significance level or at the $1-a$ confidence level.\n\nThe **p-value** $p$ is the probability of obtaining test results at least as extreme as the results actually observed, under the assumption that the null hypothesis is correct. A very small p-value means that such an extreme observed outcome would be very unlikely under the null hypothesis.\n\nWe found that in our experiment the test statistic $T$ takes the value $t = -0.707$, which means that $pv = P \\left( T<-0.707 \\right) \\approx 0.239$ from the normal table, which is larger $\\alpha$, so we fail to reject the null hypothesis.\n\n*Note: in particular this is a left tailed test. An easy way to tell from the start whether it is a left tailed or right tailed test, is to look at the direction of the alternative hypothesis inequality. Here we have that $H_1:\\theta_1<0.5$, which is a left tailed test.*","31e4d56f":"We can also test whether the data are normally distributed or not using the **Kolmogorov-Smirnov** test:","6ef9d7fb":"#### a.1 - Confidence interval","7f70f044":"That means that there is a $95\\%$ chance that the interval $\\left[ 0.3,0.58 \\right]$ contains the true value of the approval rating. This is true since the true approval rating is $55\\%$. Without a confidence interval we wouldn't have known how accurate our measurement was. Now we know that our poll was uninformative (due to a small sample size).\n\nNotice however that nothing is certain - there was still a $5\\%$ chance that our confidence interval would not contain the true approval rating.\n\n*For sample sizes less than $30$ the [t-table](https:\/\/cdn.analyticsvidhya.com\/wp-content\/uploads\/2019\/05\/t-table.png) is used instead of the normal table, t-scores instead of z-scores and the t-distribution instead of the normal distribution. For sample sizes greater than $30$ the two distributions look the same. The normal distribution is characterized by two parameters; $\\mu$ and $\\sigma$. The t-distribution is characterized by a single parameter; degrees of freedom. The degrees of freedom parameter is equal to $n-1$, where $n$ is the sample size.*\n\n*From the t-table, for $\\alpha=0.05$ and degrees of freedom $n-1=49$, we get a t-score of $\\approx 2.01$. So we should replace $1.96$ with $2.01$.*\n\n*However it must be the case that the $X_i$'s are normal, which in our case are Bernoulli. We could use the binomial instead (how many people vote for us) as an approximation to the normal, but we would have to conduct more than one poll.*\n\nTesting the result with scipy:","801ba322":"#### a.2 - Sample size","27c2d108":"What statistics is all about, is inferring information about a population by taking a sample. So how might this be useful today? Even if we do have every piece of information about everyone and everything, statistics is still useful. If I can make a useful deduction from data using only part of it, I will need less computer power to do the same job.","4eec10b3":"#### c.2 - Sampling without replacement","4ded880c":"### b) Sampling without replacement","90e0f338":"#### b.1 - Confidence interval","8576b2f3":"### 2.b. - Simulation","1495e29c":"In polling what we have is the yes or no answers from a sample of size $n$. From this we can calculate the sample mean as one realization of the estimator $\\hat{\\Theta}_n$. This is a random variable since if we choose a different sample, the value that the estimator takes changes, as we can see in the plot above. \n\nHowever the estimate $\\theta$ is a specific number because it is the mean of the whole population. This is what we're trying to infer, by knowing the sample mean. We would like the following statement to be true: \n\n$$ P\\left( \\left| \\hat{\\Theta}_{n} - \\theta  \\right| \\lt \\varepsilon \\right) \\approx 0.95 $$\n\nThis means that we're 95% confident (**confidence level**) that the distance between the sample mean and the true mean is quite small. $\\varepsilon$ is called the **margin of error**. \n\nWe would like to work with a standard normal random variable, because as with many phenomena, we do not know their distribution. Therefore we have to transform this statement to the following:\n\n$$ P\\left( \\left| \\frac{ \\hat{\\Theta}_{n} - \\theta}{\\sigma\/\\sqrt{n}}  \\right| \\lt \\frac{\\varepsilon}{\\sigma\/\\sqrt{n}} \\right) \\approx 0.95 $$\n\nFor a $0.95$ probability, accoring to the standard normal table, $\\frac{\\varepsilon}{\\sigma\/\\sqrt{n}}$ should be equal to $1.96$, which is called the **z-score** and it takes a different value depending on the confidence level of choice. When the z-score takes on a specific value, like $1.96$, it is called the **critical value**. It is equal to how many standard deviations you're away from the mean.  Therefore we have that:\n\n$$ \\varepsilon = 1.96 \\frac{\\sigma}{\\sqrt{n}} $$ \n\n$$ P\\left( \\left| \\frac{ \\hat{\\Theta}_{n} - \\theta}{\\sigma\/\\sqrt{n}}  \\right| \\lt 1.96 \\right) \\approx 0.95 $$\n\nAfter some algebra we have that:\n    \n$$ P\\left( \\hat{\\Theta}_n - \\frac{1.96\\sigma}{\\sqrt{n}} \\lt \\theta \\lt \\hat{\\Theta}_n + \\frac{1.96\\sigma}{\\sqrt{n}} \\right) \\approx 0.95 $$\n\nThe bounds on the parameter $\\theta$ define a **confidence interval**. Observe that $\\theta$ is a predetermined number and there is nothing random about it. Also observe that the parameter is bounded by the sample mean which is a random variable. If we repeat the experiment and choose some different $n$ people to poll, we will get a different sample mean and therefore a different confidence interval. However out of $100$ experiments, out of which we will get $100$ different sample means and therefore $100$ different confidence intervals, $95$ of them will containt the true value of the parameter! So the interpretation of a confidence interval, after conducting a poll, calculating a realization of the sample mean and getting an upper and a lower bound, is that there is a $95$% probability that the interval we've found captures the true value of $\\theta$.\n\nHowever there is a problem. We know $\\hat{\\Theta}_n$ and $n$ but we do not know $\\sigma$. In order to find $\\sigma$ we first have to know $\\theta$, which is what we're trying to estimate. One workaround is to use the sample mean in order to approximate $\\sigma$, i.e. use the sample standard deviation $s$:\n\n$$ P\\left( \\hat{\\Theta}_n - \\frac{1.96s}{\\sqrt{n}} \\lt \\theta \\lt \\hat{\\Theta}_n + \\frac{1.96s}{\\sqrt{n}} \\right) \\approx 0.95 $$\n\nAs a final terminology note, the following quanity is called the **standard error**, which is the standard deviation of the estimator (the sample mean in our case):\n\n$$var\\left[ \\hat{\\Theta}_n \\right] = \\frac{n}{n^2}var\\left[ X_i \\right] \\Rightarrow std\\left[\\hat{\\Theta}_n  \\right] = \\frac{\\sigma}{\\sqrt{n}}$$","57a41346":"We will repeat the same experiment by polling again $n=50$ people from the population but this time without replacement.","d41398fe":"### Final note","2e636ac4":"### b) The CLT for the Bernoulli using the sample mean as an estimator","a3bea8a7":"## 1. Background Theory","4968df4f":"Performing the Kolmogorov-Smirnov test:","3618828e":"The Central Limit Theorem states that if $X_{1},...,X_{n}$ are independent and identically distributed (i.i.d.) random variables, as $n\\to \\infty$, \n\n$$\\frac{\\sum_{i=1}^{n}X_{i} - E\\left[ \\sum_{}^{}X_{i} \\right]}{\\sqrt{var\\left[ \\sum_{_{}}^{}X_{i} \\right]}} \\sim \\mathcal{N}(0,1)$$\n\nThis means that the sum of (infinitely many) i.i.d. random variables, after standardizing it (subtracting its mean and dividing it by its standard deviation so that it has a mean of 0 and a standard deviation of 1), is a standard normal random variable (a normal random variable with mean 0 and standard deviation 1).","0befde43":"A useful question to answer would be \"what should the sample size be in order to estimate the approval rating, at the $95\\%$ confidence level with a $5\\%$ error?\"\n\nWe know that at the $95\\%$ confidence level, the margin of error is:\n\n$$ \\varepsilon = 1.96 \\frac{\\sigma}{\\sqrt{n}} \\approx 1.96 \\frac{s}{\\sqrt{n}} = 1.96 \\frac{\\sqrt{\\hat{\\Theta}_{n}(1-\\hat{\\Theta}_{n})}}{\\sqrt{n}}$$\n\nWe might already have an idea about the sample standard deviation $s$ after surveying a few people, but we can always invoke complete ignorance, in which case $\\hat{\\Theta}_{n} = 0.5$. \n\nSolving for $n$:\n\n$$n = \\frac{(1.96)^2 \\hat{\\Theta}_{n}(1 - \\hat{\\Theta}_{n})}{\\varepsilon^2} = \\left( \\frac{1.96s}{\\varepsilon} \\right)^2$$\n\nHence the poll size should be:","4c4c5ff9":"### a) Sampling with replacement","b1d37aea":"### a) The Central Limit Theorem","b4d6de93":"### d) Confidence Interval and margin of error","9d5761db":"Fairly close to the analytic result (0.478).","c74d0441":"Let's first translate the above statement, to an equivalent statement using the sample mean $\\hat{\\Theta}_{n}$ instead of the 'sample sum', for the special case where the $X_{i}$'s are Bernoulli random variables with parameter $\\theta$, i.e.:\n\n$$X_{i} = \\left\\{ \\begin{array}{cl}\n1 & , \\ \\text{if the ith person supports us with probability } \\theta\\\\\n0 & , \\ \\text{if the ith person does not support us with probability } 1-\\theta\n\\end{array} \\right.$$\n\n$\\hat{\\Theta}_{n} = \\frac{\\sum X_i}{n}$ is the sample mean (**estimator**), which is a random variable for which we know a single realization (a single poll conducted) and $\\theta$ is the population or true mean (**estimate**), which is the constant that we are trying to find\/estimate. In our case the estimate is the approval rating of a candidate, i.e. how many approve of him divided by the total number of people. \n\nDoing the calculations:\n\n$$E\\left[\\sum X_i \\right] = n\\theta = n\\mu$$\n\n$$var\\left[\\sum X_i \\right] = n\\theta(1-\\theta) = n\\sigma^{2}$$\n\nAfter replacing the above to the central limit theorem and some algebra we have that:\n\n$$ Z = \\frac{\\hat{\\Theta}_{n} - \\theta}{\\sigma \/ \\sqrt{n}} \\sim \\mathcal{N}(0,1) $$\n\nWhat this is saying is that if I take $n$ independent samples from a Bernoulli distribution, average them, subtract the true mean of the distribution, divide by the true standard deviation of the distribution and multiply by $\\sqrt{n}$, what I will get is a realization of the standard normal distribution.\n\nLet's do this multiple times (trials-experiments) to see if the realizations we get are indeed realizations of the standard normal.","3ae4974b":"### 2.c. - Binomial","67a3b24e":"## 2. Confidence interval and sample size","32c33869":"The simulation result is fairly close to the analytical result (0.239).","baa61c83":"### 1.a. Analytical solution","9f4ff425":"# <center> Part II - Binary Hypothesis Testing & p-values <\/center>","ff6a3e95":"It just so happens that now in this new experiment the true mean is overestimated.","e2b2f832":"# <center> Part I - Confidence Intervals <\/center>","7c481d45":"We can double check the results using the scipy command. It does the exact calculations using the binomial instead of the normal approximation:","a8b01ecf":"### 1.c - Binomial","54427a52":"We have taken a sample of $n=50$ people and asked them whether they support our candidate or not. 44% of those people said that they support our candidate. Therefore our estimator $\\hat{\\Theta}_n$ for the estimate $\\theta$, in this poll has taken the value $0.44$. Should we believe this result? Is this result **statistically significant**? We know this is the incorrect conclusion, since the real approval rating is 55% in favor of our candidate. In order to assess that we will formulate two hypotheses as follows:\n\n$$ H_0 : \\theta = \\theta_0 \\ge 0.5 \\\\ \n   H_1 : \\theta = \\theta_1 \\lt 0.5 $$\n   \nAssuming the **null hypothesis** $H_0$ is true - under $H_0$ - the true approval rating is $\\theta_0$, where $\\theta_0$ is larger than 0.5 in which case we win. Under the **alternative or research hypothesis** $H_1$, the true approval rating is $\\theta_1$, where $\\theta_1$ is smaller than 0.5 in which case we lose. The evidence from our research so far is trying to disprove the null hypothesis. Is that really the case? \n\nIf the null hypothesis is true, then the values of $\\hat{\\Theta}_n$ we should be getting must be larger than $\\theta_0$, because if they are smaller then they fall under the realm of the alternative hypothesis:\n\n$$\\hat{\\Theta}_n - \\theta_0 > \\xi \\Rightarrow \\hat{\\Theta}_n - E \\left[ \\hat{\\Theta}_n ; H_0 \\right] > \\xi$$\n\nThe \"how much\" larger is determined by the **critical value** $\\xi$.  $\\hat{\\Theta}_n - \\theta_0$ is a **test statistic**: it is a summary of the data upon which we will make our decision. The whole inequality is called a **decision rule**: it is a rule with which we will decide whether to **reject or fail to reject $H_0$**, depending on whether this inequality is true or not.\n\nAssuming $H_0$ to be true, the probability of that event occuring should be large:\n\n$$P \\left( \\hat{\\Theta}_n - E \\left[ \\hat{\\Theta}_n ; H_0 \\right] > \\xi ;H_0 \\right) = 1 - \\alpha $$\n\nIn order to invoke the central limit theorem and use a standard normal random variable for convenience, we divide both sides by the square root of the variance under the null hypothesis $ var \\left[ \\hat{\\Theta}_n;H_0 \\right] = \\theta_0(1-\\theta_0)\/n $:\n\n$$P \\left( \\frac{\\hat{\\Theta}_n - \\theta_0}{\\sqrt{\\theta_0(1-\\theta_0)\/n}} < \\frac{\\xi}{\\sqrt{\\theta_0(1-\\theta_0)\/n}} ;H_0 \\right) = P \\left( T<\\xi' ;H_0 \\right) = \\alpha \\xrightarrow{\\alpha=0.05} \\xi' = -1.645$$\n\nWe can also use $T$ as the test statistic and $\\xi'$ as the critical value, which we will do later. The **significance level** $\\alpha$ will determine how high or low the critical value should be. For $\\xi'=-1.645$ we get $\\xi = -1.645\\sqrt{\\smash[b]{\\theta_0(1-\\theta_0)\/n}}$. Replacing $\\xi$ in our decision rule $\\hat{\\Theta}_n - \\theta_0 > \\xi$, we have that $\\hat{\\Theta}_n > \\theta_0 -1.645\\sqrt{\\smash[b]{\\theta_0(1-\\theta_0)\/n}}$. Under $H_0$, the right hand side (RHS) has a minimum for $\\theta_0 = 0.5$:","daf6cecf":"**Interesting note:** We have taken random samples from the Bernoulli distribution *with replacement* using the command `random.choices`.\nThat means we can pick the same person (number) more than once in each trial.\n\nIf instead we pick the samples *without replacement*, using the command `random.sample`, so that we cannot pick the same person more than once in each trial, the standard deviation comes out wrong!","77244bf2":"If the left hand side of the inequality is indeed larger than the RHS then we will fail to reject $H_0$. This means that $\\theta_0 = 0.5$ is the best case scenario for $H_0$, in the sense of not being rejected. Also remember that $\\theta_0$ is not random; we must give it a value. So we will use that value to make our decision. \n\nSolving for $\\xi$: \n    \n$$ \\xi = -1.645 \\sqrt{0.5(1-0.5)\/50} \\approx -0.116 $$\n\nHaving found $\\xi$ we can evaluate the decision rule:\n\n$$\\hat{\\Theta}_n - \\theta_0 = 0.45 - 0.5 = -0.05 > \\xi$$\n\nwhich is true. Since by assuming that $H_0$ was true and having arrived at a true statement we can say that **we failed to reject $H_0$ at the 5% significance level**. This time we used $\\xi$ as the critical value and $\\hat{\\Theta}_n - \\theta_0$ as the test statistic in order to make a decision. We can also do the same by a different 'angle', using $\\xi' = -1.645$ as the new critical value and $T$ as the new test statistic. The new decision rule is:\n\n$$\\hat{\\Theta}_n - \\theta_0 > \\xi \\Rightarrow \\frac{\\hat{\\Theta}_n - \\theta_0}{\\sqrt{\\theta_0(1-\\theta_0)\/n}} > \\frac{\\xi}{\\sqrt{\\theta_0(1-\\theta_0)\/n}} \\Rightarrow T > \\xi'$$\n\nIn our experiment the realized value of $\\hat{\\Theta}_n$ was $0.45$, so the realized value $t$ of $T$ is:\n\n$$t=\\frac{0.45 - 0.5}{\\sqrt{0.5(1-0.5)\/50}} \\approx -0.707 > \\xi'$$\n\nwhich is also true. This means that the 0.44 approval rating we got from our poll was not statistically significant to sway us from our belief that we will win the election. Let us visualize what is happening:\n\n*Note: Instead of using 22\/50 = 0.44 we used a continuity correction 22.5\/50=0.45 as a better normal approximation of the binomial, which does make a very big difference as the test statistc changes from -0.848 to -0.707 which leads to a 4% error in p-values).*","710c9485":"Let's suppose we have a population of size $N=10000$. The result of the election is already predetermined and our candidate is voted by $55\\%$ of the population. That means that a random person has probability $0.55$ of voting for our candidate. Of course we do not know that, but we will use that to test the result of our poll.\n\nSo let's create that population of $10000$, of which $55\\%$ approve of our candidate.","9c06d9e2":"This problem has been solved using the **finite population correction** $f$:\n    \n$$ f = \\sqrt{\\frac{N-n}{N-1}} $$\n\nSo if we sample without replacement then we should apply the following correction:\n    \n$$ Z_f = \\frac{\\hat{\\Theta}_{n} - \\theta}{f\\sigma \/ \\sqrt{n}} \\sim \\mathcal{N}(0,1) $$\n\nLet's test that using the `random.sample` command in conjuction with the finite population correction.","292791f1":"## 2. Two tailed test","38303d8f":"Taking into account the population correction, a factor of $f$ is 'moved along' with $\\sigma$. The new margin of error is:\n\n$$ Z_f = \\frac{\\hat{\\Theta}_{n} - \\theta}{f\\sigma \/ \\sqrt{n}} \\sim \\mathcal{N}(0,1) \\Rightarrow \\varepsilon = z \\frac{fs}{\\sqrt{n}} $$\n\nwhere $1.96$ is replaced with an arbitrary z-score $z$. The confidence interval has the same form as before, namely: $ \\theta \\in (\\hat{\\Theta}_{n} - \\varepsilon, \\hat{\\Theta}_{n} + \\varepsilon ) $","77de10fe":"# <center> Classical Statistics <\/center>\n#### <center> A theoretical and practical approach to the fundamental concepts <\/center>","17c9a80e":"We happened to pick a sample from the population which does not give us the correct result. **But we don't know that**, so we might incorrectly deduce that we will lose the election. Now let's compute the confidence interval.","df2d0850":"#### c.1 - Sampling with replacement","85df62e6":"A simulation is always useful, especially when the problem is not analytically tractable. The realization of the estimator in our experiment was `theta_hat = 0.44` . From this we can calculate the realization `t` of the test statistic. \n\nWe will conduct a million `trials` under the null hypothesis $H_0: \\theta_0 \\ge 0.5$. For all trials we will use the value `theta0 = 0.5` for which it is the hardest to disprove the null hypothesis.\n\nFor that reason under each trial we will :\n\n - generate a `sample` of size `n = 50` people - the same as our poll - as 50 realizations of the Bernoulli distribution with parameter `theta0`. This means that each person has a probability theta_0 of voting in favor of our candidate. \n - find the realization of the sample mean `THETA`, which is the approval rating.\n - having found THETA, calculate the realization of the test statistc `T`.\n - if `T<=t`, the `counter` variable increases by +1, starting from 0. This way at the end of all trials, we will have stored the total number of times when T was less than t.\n \nAfter all trials end, we find the `p-value` as the ratio of the number of occurences where `T<=t` over n.","937dc3f3":"Manually using the binomial:","08730896":"## 1. One tailed test","b62fddda":"### 1.b. Simulation"}}