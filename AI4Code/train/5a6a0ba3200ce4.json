{"cell_type":{"a8cbecf8":"code","3ac04293":"code","621b3b9c":"code","96566edc":"code","8fbf1fee":"code","41d5e7a3":"code","3ee3b530":"code","bff203f5":"code","cbee09c4":"code","29553171":"code","5f31a3dd":"code","0b06cc52":"code","56f0a381":"code","479f7a4d":"code","4a5b449b":"code","16d27bea":"code","0e2fe9d6":"code","ae5962f4":"code","bdc63d7b":"code","7f77bef2":"code","023a1881":"code","ff2086b9":"code","71743ea2":"code","2d20cf6c":"code","7f769955":"code","2881802b":"code","1a03266d":"code","fe5f8ac1":"code","567dffba":"code","651b8fed":"code","feb3ccd8":"code","961bee73":"code","77a7c7d3":"code","1ba362f4":"code","8123a318":"code","821c663f":"code","4b9deb2b":"code","b9411454":"code","cb825664":"code","6a9ed659":"markdown","15ebf483":"markdown","31fd9863":"markdown","cbee21c8":"markdown","098128ee":"markdown"},"source":{"a8cbecf8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import datetime\nimport seaborn as sns\nimport yaml\nfrom collections import Counter\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV,ShuffleSplit\nfrom sklearn.manifold import TSNE\nfrom sklearn.linear_model import RidgeClassifier\nfrom catboost import CatBoostClassifier\n#import plotly.express as xp\n#import plotly.graph_objects as go\nimport missingno\nimport os\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.datasets import make_blobs\nfrom sklearn import svm\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\n#listing all the data and files\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n\n#extracting data from files\ndescription = yaml.load(open(f\"..\/input\/mymusicalprefrences\/Description.yaml\",'r'),Loader=yaml.FullLoader)\ntrain = pd.read_csv(\"..\/input\/mymusicalprefrences\/train.csv\")\ntest = pd.read_csv(\"..\/input\/mymusicalprefrences\/test.csv\")\ncombine = [train,test]\ndf = pd.concat(combine).reset_index(drop=True)\ndf","3ac04293":"print(\"Shape of the data:\", df.shape)\nprint(df.info())\nprint(df.columns)","621b3b9c":"df.columns = [column.strip() for column in df.columns]\ndf.columns","96566edc":"df.describe()","8fbf1fee":"desc = pd.DataFrame(description)\ndesc","41d5e7a3":"df.isnull().sum()","3ee3b530":"#check missing values\nprint(df.Id[df.Artists.isnull()])\nprint(df.Id[df.Vocal.isnull()])\nprint(df.Id[df.Energy.isnull()])\nprint(df.Id[df.Dancebility.isnull()])\nprint(df.Id[df.Happiness.isnull()])","bff203f5":"df.iloc[df.Id[df.Artists.isnull()]]","cbee09c4":"df = df.dropna(subset=[\"Artists\"])\ndf","29553171":"df.iloc[df.Id[df.Vocal.isnull()]]\n#we leave this because is in the test set!","5f31a3dd":"df.isnull().sum()","0b06cc52":"df.Category = df.Category.fillna(\"none\")\ndf.Category = df.Category.replace({0:\"dislike\", 1:\"like\"})\ndf.Country = df.Country.fillna(\"NA\")\ndf.Vocal = df.Vocal.fillna(\"N\")\ndf.Labels= df.Labels.fillna(\"NA\")\ndf.Version = df.Version.fillna(\"NA\")\ndf.Album_type = df.Album_type.fillna(\"NA\")\ndf.Album = df.Album.fillna(\"NA\")","56f0a381":"numerical = {\"Duration\", \"Release_year\", \"BPM\", \"Energy\", \"Dancebility\", \"Happiness\"}\ncategorical = {\"Artists\", \"Track\", \"Version\", \"Artist_genres\", \"Album\", \"Album_type\", \"Labels\", \"Vocal\", \"Country\", \"Key\"}\n#sns.pairplot(df[list(numerical)+[\"Category\"]], hue=\"Category\")","479f7a4d":"data = MinMaxScaler()\n#df[['BPM','Duration','Energy','Dancebility', 'Happiness']] = data.fit_transform(df[['BPM','Duration','Energy','Dancebility', 'Happiness']])\ndf[['Energy','Dancebility', 'Happiness']] = data.fit_transform(df[['Energy','Dancebility', 'Happiness']])\ndf","4a5b449b":"df.BPM.unique()","16d27bea":"#xp.scatter(x = df[\"Release_year\"], y=df['Track'], color = df['Category']) ","0e2fe9d6":"df[\"Release_decade\"] =  df[\"Release_year\"] - df[\"Release_year\"]%10\n#small sample of musics before 1980 - we group them\ndf.loc[df[\"Release_decade\"] < 1990, \"Release_decade\"] = 1980\n\n#group by!\nrelease = df.groupby([\"Release_decade\",\"Category\"], as_index=False).count()\n#xp.bar(release,x=\"Release_decade\", y=\"Track\", color=\"Category\")","ae5962f4":"def split_to_onehot(df, col):\n    \"\"\"\n    This method converts features separated by '|' into one-hot vectors.\n    Additionally it drops unnecessary values, which present only in \n    test set \/ train set or have only one value.\n    \"\"\"\n    # Getting all unique ganres values.\n    unique = []\n    for i in df.index:\n        unique.extend(df.loc[i,col].split(\"|\"))\n    if \"\" in unique:\n        unique.remove(\"\")\n    unique = list(set(unique))\n    \n    # Putting values into binary form \n    onehot = df.loc[:,[\"Category\"]]\n    onehot[unique] = np.zeros((len(unique),), dtype = np.int8)\n    for i in df.index:\n        g = set(df.loc[i,col].split(\"|\"))\n        for j in g:\n            if j!=\"\":\n                onehot.loc[i,j] = 1\n                \n    # Dropping unnecessary values            \n    _a = onehot.groupby(\"Category\").sum()\n    only_one = list(_a.sum()[_a.sum()==1].index)\n    only_train = list(_a.loc[\"none\"][_a.loc[\"none\"]==0].index)\n    only_test = list(_a.loc[[\"like\",'dislike']].sum()[_a.loc[[\"like\",'dislike']].sum()==0].index)\n    _a = set(only_one + only_train + only_test)\n    onehot = onehot.drop(_a, axis=1)\n    \n    return onehot\n\ndef onehot_to_tsne2(df, title):\n    \"\"\"\n    This method converts one-hot representation into two tsne values.\n    Such operation is needed to shrink the dimentionality of the dataset\n    \"\"\"\n    onehot = df.drop(\"Category\",axis=1)\n    embedding = TSNE(n_components=2, init=\"pca\")\n    embedded = embedding.fit_transform(onehot)\n    embedded = pd.DataFrame(embedded,columns=[f\"{title}_tsne1\",f\"{title}_tsne2\"])\n    return embedded\n","bdc63d7b":"description\ndf.isnull().sum()","7f77bef2":"df = df.drop(\"Version\",axis=1)\ndf = df.drop(\"Album_type\",axis=1)\n#version = set(df[\"Version\"])\n#df[list(version)] = OneHotEncoder().fit_transform(df[[\"Version\"]]).toarray()\n#df = df.drop([\"Version\", \"NA\"],axis=1)\n\n#a_type = set(df[\"Album_type\"])\n#df[list(a_type)] = OneHotEncoder().fit_transform(df[[\"Album_type\"]]).toarray()\n#df = df.drop([\"Album_type\", \"NA\"],axis=1)\n#df","023a1881":"#df = df.drop(\"Track\",axis = 1)\ndef enc(string):\n    return str(string)\n\ndf[\"Track\"] = df[\"Track\"].apply(enc)\nlabel_encoder = LabelEncoder()\ndf[\"Track\"] = label_encoder.fit_transform(df[\"Track\"])\ndf","ff2086b9":"def split(string):\n    return string.split(\" \")[1]\n\ndf[\"Major\"] = df[\"Key\"].apply(split)\ndf = df.drop(\"Key\",axis=1)\n\nfrom sklearn.preprocessing import LabelEncoder\ndef encoder(string):\n    if string ==\"Major\":\n        return  1\n    else:\n        return  0\ndf[\"Major\"] = df[\"Major\"].apply(encoder)\ndf","71743ea2":"#df = pd.get_dummies(df, \"Vocal\")\ndf[\"Vocal\"] = df[\"Vocal\"].apply(enc)\nlist_v = []\nfor i in range(len(df)):\n    voc = df.iloc[i][\"Vocal\"]\n    if voc == 'M':\n        list_v.append([1,0])\n    elif voc == 'F':\n        list_v.append([0,1])\n    elif voc =='F|M':\n        list_v.append([1,1])\n    else:\n        list_v.append([0,0])\n        \ndf[[\"Vocal_M\", \"Vocal_F\"]]= list_v\ndf = df.drop(\"Vocal\", axis = 1)","2d20cf6c":"genres_onehot = split_to_onehot(df, \"Artists_Genres\")\n#plot_commulative_onehot(genres_onehot)\ngenres = onehot_to_tsne2(genres_onehot, \"Genres\")\ndf = pd.concat([df, genres],axis=1)\ndf = df.drop(\"Artists_Genres\",axis = 1)\ndf","7f769955":"df.isnull().sum()\ndf = df.dropna(subset=[\"Category\"])","2881802b":"df[\"Labels\"] = df[\"Labels\"].apply(enc)\ndf\nlabels_onehot = split_to_onehot(df, \"Labels\")\n#plot_commulative_onehot(labels_onehot)\nlabels = onehot_to_tsne2(labels_onehot, \"Labels\")\ndf = pd.concat([df, labels],axis=1)\ndf = df.drop(\"Labels\",axis = 1)\ndf","1a03266d":"df[\"Album\"] = df[\"Album\"].apply(enc)\nalbum_onehot = split_to_onehot(df, \"Album\")\n#plot_commulative_onehot(album_onehot)\nalbum = onehot_to_tsne2(album_onehot, \"Album\")\ndf = pd.concat([df, album],axis=1)\ndf = df.drop(\"Album\",axis = 1)\ndf","fe5f8ac1":"df[\"Country\"] = df[\"Country\"].apply(enc)\ncountry_onehot = split_to_onehot(df, \"Country\")\n#plot_commulative_onehot(country_onehot)\ncountry_onehot = country_onehot.drop(\"Category\", axis = 1)\ndf = pd.concat([df, country_onehot],axis=1)\ndf = df.drop(\"Country\",axis = 1)\ndf = df.drop(\"Id\",axis=1)\ndf\n","567dffba":"#save artists who are appearing often\ndf[\"Artists\"] = df[\"Artists\"].apply(enc)\nartists = []\ndf.index\nfor i in range(len(df)):\n    for elt in df.loc[i,\"Artists\"].split(\"|\"):\n        artists.append(elt)\n\n\ntreshold = 3 \nothers = Counter(artists)\nlist_others = []\nfor artist in others:\n    if others[artist] <= treshold:\n        list_others.append(artist)\nprint(list_others)\n\n#drop artists that are just in test or train set\ntestGroup = df.loc[df.Category == 'none']\n\ntrain = []\ntest = []\nfor i in range(len(df)-len(testGroup)):\n    for elt in df.loc[i,\"Artists\"].split(\"|\"):\n        train.append(elt)\nfor i in range(len(df)-len(testGroup), len(df)):\n    for elt in df.loc[i,\"Artists\"].split(\"|\"):\n        test.append(elt)\n        \njust_train = set(train)-set(test)\njust_test = set(test)-set(train)\nprint(len(just_train))\nprint(len(just_test))\n\nartists = list(set(artists)-set(list_others)-just_test-just_train)\nprint(len(artists))\nlist_others = set(list_others) | just_test | just_train\nprint(len(list_others))","651b8fed":"res = []\ndef prune(x):\n    vector = np.zeros(len(artists)+1)\n    list_ = []\n    for elt in x.split(\"|\"):\n        list_.append(elt)\n        \n    for i in range(len(artists)):\n        if artists[i] in list_:\n            vector[i] = 1\n        else:\n            vector[i] = 0\n    if sum(vector) == 0:\n        vector[len(artists)] = 1\n    res.append(vector)\n    \n\ndf[\"Artists\"].apply(prune)\nartists_onehot = pd.DataFrame(res, columns = artists+[\"Others\"])\nartists_onehot","feb3ccd8":"df[\"Other_Artists\"] = artists_onehot[\"Others\"]\nartists_onehot[\"Category\"] = df[\"Category\"]\nartists_onehot = artists_onehot.drop(\"Others\", axis = 1)\n#plot_commulative_onehot(artists_onehot)\nartists_ = onehot_to_tsne2(artists_onehot, \"Artists\")\ndf = pd.concat([df, artists_],axis=1)\ndf = df.drop(\"Artists\",axis = 1)\ndf","961bee73":"df = df.dropna(subset=[\"Genres_tsne1\"])\ndf.isnull().sum()","77a7c7d3":"testGroup\ntrainGroup_size = len(df)-len(testGroup)\ntrainGroup = df.iloc[:trainGroup_size]\nX_train = trainGroup.iloc[:,1:]\ny_train = trainGroup[\"Category\"]\ny_train =  y_train.replace({\"dislike\":0, \"like\":1})\ny_train","1ba362f4":"testGroup = df.iloc[trainGroup_size:,:]\nX_test = testGroup.iloc[:,1:]\nX_test.head(5)","8123a318":"#X_train, X_test, y_train, y_test = train_test_split(X_train,y_train,test_size=0.2,random_state=200,shuffle=True)","821c663f":"#clf = tree.DecisionTreeClassifier()\n#clf = clf.fit(X_train,y_train)\n#y_pred = clf.predict(X_test)\n#y_pred","4b9deb2b":"model = CatBoostClassifier()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)","b9411454":"sample = pd.read_csv(f\"..\/input\/mymusicalprefrences\/sample_submition.csv\")\nsample[\"Category\"] = y_pred\n#sample[\"Category\"] = (sample[\"Category\"]==\"like\").astype(int)","cb825664":"sample.to_csv(\"deploy.csv\", index=False)","6a9ed659":"def plot_commulative_onehot(onehot):\n    \"\"\"\n    Method of plotting commulative values of the one hot feature representation\n    \"\"\"\n    _df = onehot.groupby(\"Category\").sum()\n    fig = go.Figure()\n    for i in range(len(_df.index)):\n        k = _df.index[i]\n        x,y=[],[]\n        for g in _df.columns:\n            if _df.loc[k,g]!=0:\n                x.append(g)\n                y.append(_df.loc[k,g])\n        fig.add_trace(go.Bar(x=x, y=y,name=k))\n    fig.show()","15ebf483":"# Categorical data","31fd9863":"Imported methods from final project:example solution because I do not know how to process values separated with \"|\"\"","cbee21c8":"svclassifier = SVC(kernel='linear')\nsvclassifier.fit(X_train, y_train)\ny_pred = svclassifier.predict(X_test)\nSVM_acc = accuracy_score(y_pred, y_test)\nprint(SVM_acc)\n\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train,y_train)\ny_pred_dt = clf.predict(X_test)\nDT_acc = accuracy_score(y_pred_dt, y_test)\nprint(DT_acc)\n\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\ny_pred_rf = rf.predict(X_test)\nRF_acc = accuracy_score(y_pred_rf, y_test)\nprint(RF_acc)\n\n\nKN = KNeighborsClassifier()\nKN.fit(X_train,y_train)\ny_pred_kn = KN.predict(X_test)\nKNN_acc = accuracy_score(y_pred_kn, y_test)\nprint(KNN_acc)\n\nsvclassifier1 = SVC(kernel='sigmoid')\nsvclassifier1.fit(X_train, y_train)\ny_pred_NL = svclassifier1.predict(X_test)\nSVM_NL_acc = accuracy_score(y_pred_NL, y_test)\nprint(SVM_NL_acc)\n\nsvclassifier1 = SVC(kernel='rbf')\nsvclassifier1.fit(X_train, y_train)\ny_pred_NL = svclassifier1.predict(X_test)\nSVM_NL_acc = accuracy_score(y_pred_NL, y_test)\nprint(SVM_NL_acc)\n\nfrom sklearn.ensemble import AdaBoostClassifier\nclf = AdaBoostClassifier(n_estimators=100, random_state=0)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nada = accuracy_score(y_pred, y_test)\nprint(ada)\n\nmodel = CatBoostClassifier()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ny_pred\ncat = accuracy_score(y_pred, y_test)\nprint(cat)","098128ee":"# Numerical data"}}