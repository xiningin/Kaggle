{"cell_type":{"1fabaf6f":"code","cb0d5997":"code","a561b31a":"code","eb828cd5":"code","f8b48275":"markdown","a24512c9":"markdown","9ad3f572":"markdown","26893c5c":"markdown","c92a162e":"markdown"},"source":{"1fabaf6f":"import pandas as pd\nimport numpy as np\n\nadult = pd.read_csv(\"..\/input\/adult-census-income\/adult.csv\", names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\nadult_test = pd.read_csv(\"..\/input\/us-census-data\/adult-test.csv\", names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\nadult_training = pd.read_csv(\"..\/input\/us-census-data\/adult-training.csv\", names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\n\n# data prep\n\n# remove first line\nadult=adult[1:]\nadult_test=adult_test[1:]\n\n# remove missing data\nnadult = adult.dropna()\nnTestAdult = adult_test.dropna()\nnTrainingAdult = adult_training.dropna()","cb0d5997":"# random forest\n\n# data prep\nfrom sklearn import preprocessing\n\nnumTestAdult = nTestAdult.apply(preprocessing.LabelEncoder().fit_transform)\nnumTrainingAdult = nTrainingAdult.apply(preprocessing.LabelEncoder().fit_transform)\n\nXtestAdult = numTestAdult.iloc[:,0:14]\nYtestAdult = numTestAdult.Target\nXtrainingAdult = numTrainingAdult.iloc[:,0:14]\nYtrainingAdult = numTrainingAdult.Target\n\n# train model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score\n\nrf = RandomForestRegressor(n_estimators = 400, random_state = 42)\nrf.fit(XtrainingAdult, YtrainingAdult)\npredictions = rf.predict(XtestAdult)\n\npredictions = np.array(predictions)\nYtestAdult = np.array(YtestAdult)\n\ny = []\nfor i in predictions:\n    if i >= 0.5:\n        y.append(1)\n    else:\n        y.append(0)\ny = np.array(y)\naccuracy_score(YtestAdult, y)","a561b31a":"# linear regression\n\n# data prep\nnumAdult = nadult.apply(preprocessing.LabelEncoder().fit_transform)\nnumTestAdult = nTestAdult.apply(preprocessing.LabelEncoder().fit_transform)\nnumTrainingAdult = nTrainingAdult.apply(preprocessing.LabelEncoder().fit_transform)\nXadult = numAdult.iloc[:,0:14]\nYadult = numAdult.Target\nXtestAdult = numTestAdult.iloc[:,0:14]\nYtestAdult = numTestAdult.Target\nXtrainingAdult = numTrainingAdult.iloc[:,0:14]\nYtrainingAdult = numTrainingAdult.Target\n\n\nYtestAdult = np.array(YtestAdult)\n\n# train model\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(XtrainingAdult, YtrainingAdult)\ny_pred = regressor.predict(XtestAdult)\n\ny = []\nfor i in y_pred:\n    if i >= 0.5:\n        y.append(1)\n    else:\n        y.append(0)\n\ny = np.array(y)\naccuracy_score(y, YtestAdult)","eb828cd5":"#k-means\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import accuracy_score\n\n# sem sele\u00e7\u00e3o de atributos\n\n# data prep\nXadult = numAdult.iloc[:,0:14]\nXadult = np.array(Xadult)\nYadult = numAdult.Target\nYadult = np.array(Yadult)\n\n# model\nkm = KMeans(n_clusters = 2, init = 'random')\nkm.fit(Xadult)\ny_km = km.predict(Xadult)\ny_km = np.array(y_km)\na = accuracy_score(Yadult,y_km)\nprint(a)\n\n# com sele\u00e7\u00e3o de atributos\n\n#data prep\nXadult1 = nadult[[\"Age\",\"Education-Num\",\"Capital Gain\", \"Capital Loss\", \"Hours per week\"]]\nYadult1 = numAdult.Target\n\n# model\nkm1 = KMeans(n_clusters = 2, init = 'random')\nkm1.fit(Xadult1)\ny1_km = km1.predict(Xadult1)\ny1_km = np.array(y1_km)\nb = accuracy_score(Yadult1,y1_km)\nprint(b)","f8b48275":"**Considera\u00e7\u00f5es**\n\nNo trabalho, testou-se tr\u00eas t\u00e9cnicas de classifica\u00e7\u00e3o na base Adult:\n1. Random Forest\n2. Linear Regression\n3. K-Means\nSendo as duas primeiras t\u00e9cnicas de aprendizado supervisionado e a terceira de aprendizado n\u00e3o supervisionado.\n\nPara a t\u00e9cnica de Random Forest:\nO resultado obtido foi de 84.19% de acertos.\nO pr\u00e9 processamento dos dados consistiu apenas em transformar os dados n\u00e3o num\u00e9ricos em num\u00e9ricos. \nO maior fator que influencia o tempo e uso de mem\u00f3ria computacional \u00e9 o n\u00famero de \u00e1rvores aleat\u00f3rias geradas.\nNesse exemplo, foram usadas 400 \u00e1rvores. Um outro teste feito anteriormente com 200 \u00e1rvores alterou o resultado em menos de 0.1%.\nFoi necess\u00e1rio transformar os valores de sa\u00edda em valores bin\u00e1rios. Para isso, usou-se a regra:\nSe o valor \u00e9 >= 0.5, \u00e9 classificado como 1. Caso contr\u00e1rio, recebe valor 0.\nO classificador foi criado com base no tutorial dispon\u00edvel em: \nhttps:\/\/towardsdatascience.com\/random-forest-in-python-24d0893d51c0\n\nPara a t\u00e9cnica de Linear Regression:\nO resultado obtido foi de 81.24% de acertos.\nO classificador foi constru\u00eddo utilizando todos os atributos. Uma sele\u00e7\u00e3o dos atributos poderia ter melhorado o desempenho.\nO pr\u00e9 processamento dos dados foi bem simples, apenas transformando todos os dados em valores num\u00e9ricos.\nO tempo computacional foi muito mais r\u00e1pido que o classificador anterior.\nComo as predi\u00e7\u00f5es de uma regress\u00e3o linear s\u00e3o valores cont\u00ednuos, foi necess\u00e1rio transform\u00e1-los em bin\u00e1rio: \nPossui valor 1 caso seu valor seja maior que 0.5, ou 0, caso contr\u00e1rio.\nO classificador foi criado com base no tutorial dispon\u00edvel em: \nhttps:\/\/towardsdatascience.com\/machine-learning-simple-linear-regression-with-python-f04ecfdadc13\n\nPara a t\u00e9cnica de K-Means:\nForam feitos dois testes: sem sele\u00e7\u00e3o de atributos e com sele\u00e7\u00e3o de atributos.\nPara o teste sem sele\u00e7\u00e3o de atributos:\nO resultado obtido foi de aproximadamente 50% de acertos, uma taxa bem menor que os outros testes realizados.\nEsse resultado pode variar aproximadamente 1% devido aos centros que s\u00e3o gerados aleatoriamente a cada vez que o programa \u00e9 rodado.\nPara o pr\u00e9 processamento dos dados foi necess\u00e1rio transformar os atributos n\u00e3o num\u00e9ricos em num\u00e9ricos.\nTentou-se criar dummies para cada atributo, mas a quantidade de vari\u00e1veis fez o processamento ser invi\u00e1vel.\nComo deve-se classificar o Target, foram usados 2 clusters.\nPode-se notar que o resultado foi bem abaixo do esperado, visto que houve influ\u00eancia a partir da transforma\u00e7\u00e3o de dados n\u00e3o num\u00e9ricos, e o classificador trabalhou apenas com os dados crus.\nUm contorno para isso seria pr\u00e9-selecionar os atributos. Para o teste feito com sele\u00e7\u00e3o:\nO resultado obtido foi de aproximadamente 76%.\nPode-se notar uma clara melhora na classifica\u00e7\u00e3o, mas ainda assim abaixo das outras duas testadas.\nO classificador foi criado com base no tutorial dispon\u00edvel em: \nhttps:\/\/towardsdatascience.com\/k-means-clustering-with-scikit-learn-6b47a369a83c","a24512c9":"Este trabalho testa tr\u00eas t\u00e9cnicas diferentes de classifica\u00e7\u00e3o na base Adult, e ao final compara implementa\u00e7\u00f5es e resultados.\n\nInicializa\u00e7\u00e3o dos dados","9ad3f572":"Primeiro classificador testado: Random Forest","26893c5c":"Terceiro classificador testado: K-Means","c92a162e":"Segundo classificador testado: Linear Regression"}}