{"cell_type":{"3490a30f":"code","54582c29":"code","9ec1a08f":"code","0f5c22ed":"code","4949775b":"code","b9f3d609":"code","dc9b3d02":"code","5a1d3edb":"code","d73ef0f1":"code","db2a73ac":"code","5669664e":"code","9c2364b3":"code","2650b775":"code","17497b8b":"code","2a2a783e":"code","c5464cc1":"code","b8989efb":"code","8b940aa4":"code","778a85f7":"code","69ec2060":"code","7d9c1037":"code","fa0186b1":"code","f39dcde8":"code","04ac84ca":"code","79ba6df3":"code","399a9299":"code","4a2587d8":"code","e91cbaf2":"code","3df575cd":"code","c3e403a0":"code","7199df7b":"code","8d3ab6a2":"code","d606556b":"code","e6b2d033":"code","c3875e54":"code","e017e48a":"code","c08a5f48":"code","d6fbc1a3":"code","4462f7d1":"code","7ce9ddfc":"code","8427da6d":"code","25293e12":"code","78d329fc":"code","7a2e14e8":"code","bc5ee900":"code","a33af43f":"code","40713c0b":"code","a65dd44b":"code","3b0cf1e5":"code","ea1a59be":"code","642dc607":"code","7468a27c":"code","86ea7988":"code","205f40f5":"markdown","b2e37f64":"markdown","8f1c210b":"markdown","43b5f93f":"markdown","333d93b0":"markdown","4a91dffb":"markdown","56dfa855":"markdown","0fd1ff17":"markdown","a166ac42":"markdown","5a367817":"markdown","a5e90594":"markdown","e5edbd25":"markdown","de872313":"markdown","f8cd96a7":"markdown","7e180758":"markdown","87f7f66d":"markdown","40c604cd":"markdown","a8e82abf":"markdown","f9fcc39e":"markdown","bb045b14":"markdown","8c6c1d23":"markdown"},"source":{"3490a30f":"import pandas as pd\nfrom sklearn import datasets, linear_model, svm\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\nimport math\nimport pandas as pd\nfrom fbprophet import Prophet","54582c29":"# Import Dependencies\n%matplotlib inline\n\n# Start Python Imports\nimport math, time, random, datetime\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import invgauss\n\n# Visualization \nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n# Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n\n# Machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Let's be rebels and ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')","9ec1a08f":"# Load the Diabetes dataset\ndata = pd.read_csv(\"..\/input\/novel-corona-virus-2019-datasetbangladesh\/covid_19_data_Bangladesh.csv\")\ndata.head()","0f5c22ed":"# create training and testing vars\ntrain, test = train_test_split(data, test_size=0.15, random_state = 0)\nprint (train.shape)\nprint (test.shape)","4949775b":"train.head()","b9f3d609":"test.head()","dc9b3d02":"train.describe()","5a1d3edb":"#Plot graphic of missing value\nmissingno.matrix(train, figsize = (30,5))","d73ef0f1":"#to perform data analysis we create data frame\ndf_bin = pd.DataFrame() #for discreated continuous variable\ndf_con = pd.DataFrame() #for continuous variables","db2a73ac":"train.dtypes","5669664e":"# How many people confirmed\/death\/recovered in context of SNo?\nsns.jointplot(x='SNo', y=\"Confirmed\", data=train, color = \"y\");\n\nsns.jointplot(x='SNo', y=\"Deaths\", data=train, color=\"r\");\n\nsns.jointplot(x='SNo', y=\"Recovered\", data=train, color= \"g\");","9c2364b3":"# Let's add this to our subset dataframes\ndf_bin['SNo'] = train['SNo']\ndf_con['SNo'] = train['SNo']","2650b775":"df_bin.head()","17497b8b":"df_con.head()","2a2a783e":"# How many people confirmed\/death\/recovered in context of ObservationDate?\ntrain['ObservationDate'] = pd.to_datetime(train['ObservationDate'])\n\nfig = plt.figure(figsize=(15,1))\ntrain[['ObservationDate','Confirmed']].set_index('ObservationDate').plot(color = \"y\")\n\nfig = plt.figure(figsize=(15,1))\ntrain[['ObservationDate','Deaths']].set_index('ObservationDate').plot(color = \"r\")\n\nfig = plt.figure(figsize=(15,1))\ntrain[['ObservationDate','Recovered']].set_index('ObservationDate').plot(color = \"g\")","c5464cc1":"# Let's add this to our subset dataframes\ndf_bin['ObservationDate'] = train['ObservationDate']\ndf_con['ObservationDate'] = train['ObservationDate']","b8989efb":"df_bin.head()","8b940aa4":"df_con.head()","778a85f7":"df_bin.head()","69ec2060":"df_con.head()","7d9c1037":"# How many people confirmed\/death\/recovered in context of LastUpdate?\ntrain['Last Update'] = pd.to_datetime(train['Last Update'])\n\nfig = plt.figure(figsize=(15,1))\ntrain[['Last Update','Confirmed']].set_index('Last Update').plot(color = \"y\")\n\nfig = plt.figure(figsize=(15,1))\ntrain[['Last Update','Deaths']].set_index('Last Update').plot(color = \"r\")\n\nfig = plt.figure(figsize=(15,1))\ntrain[['Last Update','Recovered']].set_index('Last Update').plot(color = \"g\")","fa0186b1":"df_bin['Last Update'] = train['Last Update']\ndf_con['Last Update'] = train['Last Update']","f39dcde8":"df_bin.head()","04ac84ca":"df_con.head()","79ba6df3":"df_bin['Confirmed'] = train['Confirmed']\ndf_con['Confirmed'] = train['Confirmed']\n\ndf_bin['Deaths'] = train['Deaths']\ndf_con['Deaths'] = train['Deaths']\n\ndf_bin['Recovered'] = train['Recovered']\ndf_con['Recovered'] = train['Recovered']","399a9299":"df_bin.head()","4a2587d8":"df_con.head()","e91cbaf2":"print(len(df_bin))","3df575cd":"print(len(df_con))","c3e403a0":"confirmed = df_con.groupby('ObservationDate').sum()['Confirmed'].reset_index()\ndeaths = df_con.groupby('ObservationDate').sum()['Deaths'].reset_index()\nrecovered = df_con.groupby('ObservationDate').sum()['Recovered'].reset_index()","7199df7b":"confirmed.head()","8d3ab6a2":"deaths.head()","d606556b":"recovered.head()","e6b2d033":"days_to_forecast = 30 # changable\nfirst_forecasted_date = sorted(list(set(df_con['ObservationDate'].values)))[-days_to_forecast]\n\nprint('The first date to perform forecasts for is: ' + str(first_forecasted_date))","c3875e54":"confirmed_df = df_con[['SNo', 'ObservationDate', 'Last Update', 'Confirmed']]\nconfirmed_df.tail()","e017e48a":"confirmed.columns = ['ds','y']\nconfirmed['ds'] = pd.to_datetime(confirmed['ds'])","c08a5f48":"confirmed.head()","d6fbc1a3":"deaths_df = df_con[['SNo', 'ObservationDate', 'Last Update', 'Deaths']]\ndeaths_df.tail()","4462f7d1":"deaths.columns = ['ds','y']\ndeaths['ds'] = pd.to_datetime(deaths['ds'])","7ce9ddfc":"recovered_df = df_con[['SNo', 'ObservationDate', 'Last Update', 'Recovered']]\nrecovered_df.tail()","8427da6d":"recovered.columns = ['ds','y']\nrecovered['ds'] = pd.to_datetime(confirmed['ds'])","25293e12":"m = Prophet(interval_width=0.95)\nm.fit(confirmed)\nfuture = m.make_future_dataframe(periods=30)\nfuture_confirmed = future.copy() # for non-baseline predictions later on\nfuture.tail()","78d329fc":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","7a2e14e8":"confirmed_forecast_plot = m.plot(forecast)","bc5ee900":"forecast_components = m.plot_components(forecast)","a33af43f":"m = Prophet(interval_width=0.95)\nm.fit(deaths)\nfuture = m.make_future_dataframe(periods=30)\nfuture_deaths = future.copy() # for non-baseline predictions later on\nfuture.tail()","40713c0b":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","a65dd44b":"deaths_forecast_plot = m.plot(forecast)","3b0cf1e5":"forecast_components = m.plot_components(forecast)","ea1a59be":"m = Prophet(interval_width=0.95)\nm.fit(recovered)\nfuture = m.make_future_dataframe(periods=30)\nfuture_confirmed = future.copy() # for non-baseline predictions later on\nfuture.tail()","642dc607":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","7468a27c":"deaths_forecast_plot = m.plot(forecast)","86ea7988":"forecast_components = m.plot_components(forecast)","205f40f5":"Data Preparation\nAs we are now forecasting at country and state\/province level, for small values, it is possible for forecasts to become negative. To counter this, we round negative values to zero. To perform forecast evaluations using mean absolute error (MAE), we require to partition the dataset into train & validation sets. Here, the test set will contain the dates for which the Prophet model is trained on and where forecasts were made.","b2e37f64":"# Feature Analyzing","8f1c210b":"What datatypes are in the dataframe?\nAs a general rule of thumb, features with a datatype of object could be considered categorical features. And those which are floats or ints (numbers) could be considered numerical features.\n\nHowever, as we dig deeper, we might find features which are numerical may actually be categorical.\n\nThe goal for the next few steps is to figure out how best to process the data so our machine learning model can learn from it.\n\nIdeally, all the features will be encoded into a numerical value of some kind.","43b5f93f":"Deaths","333d93b0":"Referance: https:\/\/www.kaggle.com\/khoongweihao\/covid-19-novel-coronavirus-eda-forecasting-cases?fbclid=IwAR0FgRqSJFSgxkOoRX2r4JPg84y7F1L2Ky-pmJDAQmvEBLySjNBsnzWV41g\nProphet\nWe use Prophet, a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well. It is also an open source software released by Facebook\u2019s Core Data Science team. It is available for download on CRAN and PyPI.","4a91dffb":"# Creating training and testing dataset","56dfa855":"Forecasting Confirmed, Death & Recovered Cases with Prophet (by Country\/Region & Province\/State)","0fd1ff17":"**Target Feature: SNo\nData type = different integers**","a166ac42":"Data Description\nSNo-Random number\nObservationDate-the date observed\nProvince\/State-NaN\nCountry\/Region-Bangladesh\nLast Update-the dates\nConfirmed-case detected\nDeaths-death ratings\nRecovered-the people who recovered","5a367817":"Let's explore each of these features individually\nWe'll go through each column iteratively and see which ones to use in our first models. Some may need more preprocessing than others to get ready.","a5e90594":"Confirmed","e5edbd25":"**Target Feature: Last Update\nData type = floating points and string**","de872313":"What are the missing values?\nConclusion: We don't need province and count in our featue analysis","f8cd96a7":"**Data Description**","7e180758":"# Import libraries","87f7f66d":"# Training Data for future predictions","40c604cd":"Recovered","a8e82abf":"****Data Forecasting","f9fcc39e":"**Target Feature: ObservationDate \nData type = different integers**","bb045b14":"**Data Preparation**","8c6c1d23":"**Spliting dataset in training and test dataset**\nReferance: https:\/\/towardsdatascience.com\/train-test-split-and-cross-validation-in-python-80b61beca4b6?gi=2d29bc955383\n**Feature Analysing **\nReferance: https:\/\/www.youtube.com\/watch?v=f1y9wDDxWnA"}}