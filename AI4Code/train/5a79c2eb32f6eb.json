{"cell_type":{"ad19a427":"code","11af3fab":"code","0a1ad1ea":"code","310cfa0c":"code","67886f46":"code","792a0a02":"code","89620d69":"code","6d645190":"code","f7ebbb43":"code","a68b373e":"code","128804ac":"code","02219b32":"code","5c26a818":"code","cd64f4e4":"code","54881c67":"code","8b139977":"code","89060074":"code","18405d9c":"code","379a8f1d":"code","29e8d4bc":"code","a527bcf1":"code","6aa0bcfa":"code","0a85d47b":"code","945a708c":"code","9d7cf62b":"code","3797a65d":"code","5bc8f3cf":"code","2da90fb3":"code","71163331":"code","efd9e5c0":"code","03471e7a":"code","c1b1e70a":"code","36f4d71a":"code","22ec43b8":"code","732ece44":"code","0681575c":"code","1c12b333":"code","52ea71bf":"code","e5da9a70":"code","660a2ff9":"code","24bf1214":"code","97b9e300":"code","7d32c81e":"code","a8bf13ad":"code","465f151d":"code","9b066bc0":"code","15ccaaf2":"code","97b68f74":"code","0895bbfa":"code","9dbc1e3c":"code","e0651a9a":"code","2181937c":"code","daae482a":"code","0a28ae65":"code","b0311d4c":"code","3b236957":"code","b40bae64":"code","6b41d73a":"code","608a9ea5":"code","e2cb298a":"code","a9a5b82f":"code","8c9a38bc":"code","e3738d3d":"code","9cdaa359":"code","1502f8f2":"code","85be8928":"code","5fdffce7":"code","54550a77":"code","cd868ea2":"code","923c1f25":"code","2476d42d":"code","4ed00116":"code","a740c2ad":"code","c216f335":"code","7a55bd73":"code","40b3778c":"code","823a072c":"code","b3cde544":"code","19914fe2":"code","1b21cae0":"code","03530e23":"code","154c8957":"code","64c5c2a6":"code","eafcae18":"code","87251d4a":"code","8e3d7d83":"code","adb0dd62":"code","488bc1f5":"code","774004a0":"code","53bfb53a":"code","fc38d639":"code","8de5be9b":"code","4d8532ed":"code","b6fc8ef8":"code","548ce8a1":"code","7690e086":"code","361cb5e9":"code","a9dc88b6":"code","b0ab32e5":"code","8bd03a78":"code","a9b01194":"code","74c6626c":"code","b340c8ab":"code","f12aa00c":"code","19d4eef6":"code","91cef28d":"code","fd792878":"code","90c4759f":"code","1e19e7e5":"code","0d1b21fc":"code","12e40333":"code","730c40b6":"code","570d3244":"markdown","ae3cbce3":"markdown","fe3360a1":"markdown","4f201062":"markdown","1a270feb":"markdown","a8ad0201":"markdown","09572cf5":"markdown","d18a1ce6":"markdown","aeed0309":"markdown","07bcab26":"markdown","52a390e3":"markdown","6b4247ff":"markdown","2b08ca9a":"markdown","a1e988e4":"markdown","b7001def":"markdown","a0edf6cf":"markdown","e0c61fd4":"markdown","984c8764":"markdown","9930264c":"markdown","287cf133":"markdown","d4aa6f6d":"markdown","0b9b0839":"markdown","e7f235f2":"markdown","dc417d87":"markdown","73084c36":"markdown","8df7cbe1":"markdown","c4900d38":"markdown","52a64eaf":"markdown","40725d6a":"markdown","c79569cb":"markdown","af0c97f4":"markdown","dbbc17c4":"markdown","f5eee6f6":"markdown","e543430a":"markdown","64cbf72d":"markdown","7305f891":"markdown","3bb055c8":"markdown","0db49f07":"markdown","9ec90075":"markdown","5c4671ca":"markdown","e3ad7fcd":"markdown","1aaa1d10":"markdown","ce2cf417":"markdown","11e7c19a":"markdown","9dcfc330":"markdown","87e737bd":"markdown"},"source":{"ad19a427":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\n#MUSIC PROCESS\nimport pydub\nfrom scipy.io.wavfile import read, write\nimport librosa\nimport librosa.display\nimport IPython\nfrom IPython.display import Audio\nimport scipy\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape,\\\nConv2DTranspose, LeakyReLU, Conv1D, AveragePooling1D, MaxPooling1D, MaxPool1D, GlobalAvgPool1D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\nfrom tensorflow.keras import regularizers\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","11af3fab":"Set_A_Data = pd.read_csv(\"..\/input\/heartbeat-sounds\/set_a.csv\")\nSet_B_Data = pd.read_csv(\"..\/input\/heartbeat-sounds\/set_b.csv\")","0a1ad1ea":"print(Set_A_Data.head(-1))","310cfa0c":"print(Set_A_Data.isnull().sum())","67886f46":"print(Set_A_Data[\"label\"].value_counts())","792a0a02":"print(Set_A_Data[\"dataset\"].value_counts())","89620d69":"print(Set_B_Data.head(-1))","6d645190":"print(Set_B_Data.isnull().sum())","f7ebbb43":"print(Set_B_Data[\"label\"].value_counts())","a68b373e":"print(Set_B_Data[\"dataset\"].value_counts())","128804ac":"DataFrames = [Set_A_Data,Set_B_Data]\nConcat_Data = pd.concat(DataFrames)","02219b32":"print(Concat_Data.head(-1))","5c26a818":"print(Concat_Data.isnull().sum())","cd64f4e4":"Concat_Data.drop([\"sublabel\",\"dataset\"],axis=\"columns\",inplace=True)","54881c67":"print(Concat_Data.head(-1))","8b139977":"print(Concat_Data[\"label\"].value_counts())","89060074":"Concat_Data = Concat_Data.dropna()","18405d9c":"print(Concat_Data.head(600))","379a8f1d":"Concat_Data = Concat_Data.reset_index()","29e8d4bc":"print(Concat_Data.head(-1))","a527bcf1":"print(Concat_Data.isnull().sum())","6aa0bcfa":"Concat_Data.drop(\"index\",axis=\"columns\",inplace=True)","0a85d47b":"Path_Wav_List = []\nCategory_List = []\n\nfor path_number in range(585):\n    File_Path_Name = \"..\/input\/heartbeat-sounds\/\" + str(Concat_Data[\"fname\"][path_number])\n    Path_Wav_List.append(File_Path_Name)\n    Category_List.append(Concat_Data[\"label\"][path_number])","945a708c":"print(Path_Wav_List[0:4])","9d7cf62b":"print(Category_List[0:4])","3797a65d":"Path_Wav_Series = pd.Series(Path_Wav_List,name=\"WAV\").astype(str)\nCategory_Series = pd.Series(Category_List,name=\"CATEGORY\")","5bc8f3cf":"Main_Heartbeat_Data = pd.concat([Path_Wav_Series,Category_Series],axis=1)","2da90fb3":"print(Main_Heartbeat_Data.head(-1))","71163331":"Main_Heartbeat_Data = Main_Heartbeat_Data.sample(frac=1).reset_index(drop=True)","efd9e5c0":"print(Main_Heartbeat_Data[\"CATEGORY\"].value_counts())","03471e7a":"print(Main_Heartbeat_Data.head(-1))","c1b1e70a":"Concat_Data.to_csv(\"New_Heartbeat_Doc.csv\")","36f4d71a":"Main_Heartbeat_Data.to_csv(\"Main_Heartbeat_Doc.csv\")","22ec43b8":"def noise_function(data):\n    noise_value = 0.009 * np.random.uniform() * np.amax(data)\n    data = data + noise_value * np.random.normal(size=data.shape[0])\n    \n    return data","732ece44":"def stretch_function(data,rate=0.6):\n    \n    return librosa.effects.time_stretch(data,rate)","0681575c":"def shift_function(data):\n    \n    shift_range = int(np.random.uniform(-3,3) * 1000)\n    return np.roll(data,shift_range)","1c12b333":"def pitch_function(data,sampling_rate,pitch_factor=0.3):\n    \n    return librosa.effects.pitch_shift(data,sampling_rate,pitch_factor)","52ea71bf":"def specshow_function(wav_path):\n    \n    figure,axis = plt.subplots(4,1,figsize=(14,6))\n    \n    audio_type,sample_rate = librosa.load(wav_path)\n    stft_audio = librosa.stft(audio_type)\n    Db_audio = librosa.amplitude_to_db(abs(stft_audio))\n    Img_Log = librosa.display.specshow(Db_audio,sr=sample_rate,x_axis=\"time\",y_axis=\"log\",cmap='gray_r',ax=axis[0])\n    axis[0].set(title='LOG')\n    Img_Mel = librosa.display.specshow(Db_audio,sr=sample_rate,x_axis=\"time\",y_axis=\"mel\",cmap='gray_r',ax=axis[1])\n    axis[1].set(title='MEL')\n    Img_Chroma = librosa.display.specshow(Db_audio,sr=sample_rate,x_axis=\"time\",y_axis=\"chroma\",cmap='gray_r',ax=axis[2])\n    axis[2].set(title='CHROMA')\n    Img_Hz = librosa.display.specshow(Db_audio,sr=sample_rate,x_axis=\"time\",y_axis=\"hz\",cmap='gray_r',ax=axis[3])\n    axis[3].set(title='HZ')\n    \n    \n    for ax_i in axis:\n        ax_i.label_outer()\n\n    \n    figure.colorbar(Img_Log, ax=[axis[0], axis[1]])\n\n    # Or have individual colorbars:\n    figure.colorbar(Img_Chroma, ax=[axis[2],axis[3]])\n    \n    axis[0].set(xlim=[1, 3])","e5da9a70":"def waveplot_function(wav_path):\n    figure = plt.figure(figsize=(14,6))\n    \n    audio_type,sample_rate = librosa.load(wav_path)\n    librosa.display.waveplot(audio_type,sr=sample_rate)","660a2ff9":"def playing_function(wav_path):\n    \n    audio_type,sample_rate = librosa.load(wav_path)\n    return Audio(audio_type,rate=sample_rate)","24bf1214":"def extract_function(data):\n    \n    output_result = np.array([])\n    \n    mean_zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=data).T,axis=0)\n    output_result = np.hstack((output_result,mean_zero_crossing_rate))\n    \n    stft_output = np.abs(librosa.stft(data))\n    chroma_mean = np.mean(librosa.feature.chroma_stft(S=stft_output,sr=sample_rate).T,axis=0)\n    output_result = np.hstack((output_result,chroma_mean))\n    \n    mfcc_output = np.mean(librosa.feature.mfcc(y=data,sr=sample_rate).T,axis=0)\n    output_result = np.hstack((output_result,mfcc_output))\n    \n    root_output = np.mean(librosa.feature.rms(y=data).T,axis=0)\n    output_result = np.hstack((output_result,root_output))\n    \n    mel_output = np.mean(librosa.feature.melspectrogram(y=data,sr=sample_rate).T,axis=0)\n    output_result = np.hstack((output_result,mel_output))\n    \n    return output_result","97b9e300":"def export_function(path):\n    \n    data,sample_rate = librosa.load(path,duration=3.0)\n    \n    Output_One = extract_function(data)\n    result = np.array(Output_One)\n    \n    noise_output = noise_function(data)\n    Output_Two = extract_function(noise_output)\n    result = np.vstack((result,Output_Two))\n    \n    stretch_output = stretch_function(data)\n    stretch_pitch = pitch_function(stretch_output,sample_rate)\n    Output_Three = extract_function(stretch_pitch)\n    result = np.vstack((result,Output_Three))\n    \n    return result","7d32c81e":"plt.style.use(\"dark_background\")","a8bf13ad":"try:\n    playing_function(Main_Heartbeat_Data[\"WAV\"][580])\nexcept Exception as error:\n    print(\"NO DIRECTORY ERROR\")","465f151d":"playing_function(Main_Heartbeat_Data[\"WAV\"][480])","9b066bc0":"waveplot_function(Main_Heartbeat_Data[\"WAV\"][480])","15ccaaf2":"specshow_function(Main_Heartbeat_Data[\"WAV\"][480])","97b68f74":"wav_type,sample_rate = librosa.load(Main_Heartbeat_Data[\"WAV\"][480])\nnoise_audio = noise_function(wav_type)\nAudio(noise_audio,rate=sample_rate)","0895bbfa":"wav_type,sample_rate = librosa.load(Main_Heartbeat_Data[\"WAV\"][480])\nstretch_audio = stretch_function(wav_type)\nAudio(stretch_audio,rate=sample_rate)","9dbc1e3c":"wav_type,sample_rate = librosa.load(Main_Heartbeat_Data[\"WAV\"][480])\nshift_audio = shift_function(wav_type)\nAudio(shift_audio,rate=sample_rate)","e0651a9a":"wav_type,sample_rate = librosa.load(Main_Heartbeat_Data[\"WAV\"][480])\npitch_audio = pitch_function(wav_type,sample_rate)\nAudio(pitch_audio,rate=sample_rate)","2181937c":"wav_type,sample_rate = librosa.load(Main_Heartbeat_Data[\"WAV\"][480])\n\nprint(wav_type.shape)\nprint(wav_type.dtype)\nprint(sample_rate)","daae482a":"sample_rate = 22050","0a28ae65":"x_Train = []\ny_Train = []\n    \nfor path,category_wav in zip(Main_Heartbeat_Data.WAV,Main_Heartbeat_Data.CATEGORY):\n    \n    try:  \n        wav_features = export_function(path)\n    \n        for indexing in wav_features:\n            x_Train.append(indexing)\n            y_Train.append(category_wav)\n\n    except Exception as e:\n        print(\"NO DIRECTORY ERROR: \", path)","b0311d4c":"New_Heartbeat_Wav = pd.DataFrame(x_Train)\nNew_Heartbeat_Wav[\"CATEGORY\"] = y_Train\n\nNew_Heartbeat_Wav.to_csv(\"New_Wav_Heartbeat_Data.csv\",index=False)","3b236957":"New_Heartbeat_Wav.head(-1)","b40bae64":"print(New_Heartbeat_Wav[\"CATEGORY\"].value_counts())","6b41d73a":"Encoder_Function = OneHotEncoder()\nScaler_Function = MinMaxScaler()","608a9ea5":"Values_X = New_Heartbeat_Wav.iloc[:,:-1].values\nLabels_X = New_Heartbeat_Wav[\"CATEGORY\"].values","e2cb298a":"print(Values_X.shape)\nprint(Labels_X.shape)","a9a5b82f":"Labels_X_Encode = Encoder_Function.fit_transform(np.array(Labels_X).reshape(-1,1)).toarray()","8c9a38bc":"print(Labels_X_Encode[0:5])","e3738d3d":"print(Labels_X_Encode.shape)","9cdaa359":"xTrain,xTest,yTrain,yTest = train_test_split(Values_X,Labels_X_Encode,train_size=0.9,random_state=42,shuffle=True)","1502f8f2":"print(xTrain.shape)\nprint(yTrain.shape)\nprint(xTest.shape)\nprint(yTest.shape)","85be8928":"xTrain = np.expand_dims(xTrain,axis=2)\nxTest = np.expand_dims(xTest,axis=2)","5fdffce7":"print(xTrain.shape)\nprint(xTest.shape)","54550a77":"output_dim = 4\ncompile_metrics = [\"accuracy\"]\ncompile_loss = \"categorical_crossentropy\"\ncompile_optimizer = Adam()\ninput_shape_dim = (xTrain.shape[1],1)","cd868ea2":"Early_Stopper = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\")\nCheckpoint_Model = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                      save_best_only=True,\n                                                      save_weights_only=True,\n                                                      filepath=\".\/modelcheck\")","923c1f25":"Model = Sequential()\n\nModel.add(Conv1D(256,5,strides=1,padding=\"same\",activation=\"relu\",input_shape=input_shape_dim))\nModel.add(BatchNormalization())\nModel.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\nModel.add(Conv1D(256,4,strides=1,padding=\"same\",activation=\"relu\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\nModel.add(Conv1D(128,4,strides=1,padding=\"same\",activation=\"relu\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\n\nModel.add(Conv1D(64,4,strides=1,padding=\"same\",activation=\"relu\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\nModel.add(Conv1D(32,4,strides=1,padding=\"same\",activation=\"relu\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\n\nModel.add(Flatten())\nModel.add(Dense(1024, activation='relu'))\nModel.add(Dropout(0.3))\n\nModel.add(Dense(units=output_dim, activation='softmax'))","2476d42d":"print(Model.summary())","4ed00116":"print(Model.layers)","a740c2ad":"Model.compile(optimizer=compile_optimizer,loss=compile_loss,metrics=compile_metrics)","c216f335":"Conv1D_Model = Model.fit(xTrain, yTrain,\n                         batch_size=12,\n                         epochs=70,\n                                validation_data=(xTest, yTest), callbacks=[Early_Stopper,Checkpoint_Model])","7a55bd73":"Model_Results = Model.evaluate(xTest,yTest)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\nprint(\"ACCURACY:  \" + \"%.4f\" % Model_Results[1])","40b3778c":"X_train, X_test, Y_train, Y_test = train_test_split(Values_X,Labels_X_Encode, train_size=0.9, random_state = 42, shuffle=True)","823a072c":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)\nprint(Y_test.shape)","b3cde544":"X_train = X_train.reshape(X_train.shape[0], 18, 9, 1)\nX_test = X_test.reshape(X_test.shape[0], 18, 9, 1)","19914fe2":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)\nprint(Y_test.shape)","1b21cae0":"Model_Check_Conv2D = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                     save_best_only=True,\n                                                     filepath=\".\/my_Conv2D_model\")","03530e23":"Model_Conv2D = Sequential()\n#\nModel_Conv2D.add(Conv2D(64,(3, 3),padding=\"same\",activation=\"relu\",input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])))\nModel_Conv2D.add(MaxPool2D(pool_size=(2, 2)))\n#\nModel_Conv2D.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\"))\nModel_Conv2D.add(Dropout(0.3))\nModel_Conv2D.add(MaxPool2D(pool_size=(2, 2)))\n\nModel_Conv2D.add(Conv2D(256, (3, 3), padding = \"same\", activation = \"relu\"))\nModel_Conv2D.add(Dropout(0.3))\nModel_Conv2D.add(MaxPool2D(pool_size=(2, 2)))\n#\nModel_Conv2D.add(Flatten())\nModel_Conv2D.add(Dense(2048, activation = \"relu\"))\nModel_Conv2D.add(Dropout(0.5))\nModel_Conv2D.add(Dense(1024, activation = \"relu\"))\nModel_Conv2D.add(Dropout(0.5))\nModel_Conv2D.add(Dense(output_dim, activation = \"softmax\"))","154c8957":"Model_Conv2D.compile(optimizer=compile_optimizer,loss=compile_loss,metrics=compile_metrics)","64c5c2a6":"Conv2D_Model = Model_Conv2D.fit(X_train, Y_train, batch_size=64, epochs=70,\n                                validation_data=(X_test, Y_test), callbacks=[Early_Stopper,Model_Check_Conv2D])","eafcae18":"Model_Results_Conv2D = Model_Conv2D.evaluate(X_test,Y_test)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results_Conv2D[0])\nprint(\"ACCURACY:  \" + \"%.4f\" % Model_Results_Conv2D[1])","87251d4a":"Model_Check_RNN_SEPCNN = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                     save_best_only=True,\n                                                     filepath=\".\/my_RNN_SEPCNN_model\")","8e3d7d83":"Model_R = Sequential()\n\nModel_R.add(Conv2D(32,(3,3),activation=\"relu\",\n                 input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])))\nModel_R.add(BatchNormalization())\nModel_R.add(MaxPooling2D((2,2)))\n\n#\nModel_R.add(Conv2D(64,(3,3),\n                 activation=\"relu\",padding=\"same\"))\nModel_R.add(Dropout(0.2))\nModel_R.add(MaxPooling2D((2,2)))\n\n\n#\nModel_R.add(TimeDistributed(Flatten()))\nModel_R.add(Bidirectional(LSTM(64,\n                                  return_sequences=True,\n                                  dropout=0.5,\n                                  recurrent_dropout=0.5)))\nModel_R.add(Bidirectional(LSTM(64,\n                                  return_sequences=True,\n                                  dropout=0.5,\n                                  recurrent_dropout=0.5)))\n\n#\nModel_R.add(Flatten())\nModel_R.add(Dense(128,activation=\"relu\"))\nModel_R.add(Dropout(0.5))\nModel_R.add(Dense(output_dim,activation=\"softmax\"))","adb0dd62":"Model_R.compile(optimizer=compile_optimizer,loss=compile_loss,metrics=compile_metrics)","488bc1f5":"RNN_SEPCNN_Model = Model_R.fit(X_train, Y_train, epochs=70,\n                                validation_data=(X_test, Y_test), callbacks=[Early_Stopper,Model_Check_RNN_SEPCNN])","774004a0":"Model_Results_RNN_SEPCNN = Model_R.evaluate(X_test,Y_test)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results_RNN_SEPCNN[0])\nprint(\"ACCURACY:  \" + \"%.4f\" % Model_Results_RNN_SEPCNN[1])","53bfb53a":"X_train, X_test, Y_train, Y_test = train_test_split(Values_X,Labels_X_Encode, train_size=0.9, random_state = 42, shuffle=True)","fc38d639":"X_train = X_train.reshape(X_train.shape[0], X_train.shape[1],1)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1],1)","8de5be9b":"print(X_train.shape)\nprint(X_test.shape)","4d8532ed":"Model_Check_LSTM = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                     save_best_only=True,\n                                                     filepath=\".\/my_LSTM_model\")","b6fc8ef8":"Model_LSTM = Sequential()\n\nModel_LSTM.add(Bidirectional(LSTM(units=64,\n                                  dropout=0.2,\n                                  return_sequences=True),\n                             input_shape=(X_train.shape[1],X_train.shape[2])))\n\nModel_LSTM.add(Bidirectional(LSTM(units=32,\n                                  dropout=0.2,\n                                  return_sequences=False)))\n\nModel_LSTM.add(Dense(output_dim, activation='softmax'))","548ce8a1":"Model_LSTM.compile(optimizer=\"rmsprop\",loss=compile_loss,metrics=compile_metrics)","7690e086":"LSTM_Model = Model_LSTM.fit(X_train, Y_train, epochs=70,\n                                validation_data=(X_test, Y_test), callbacks=[Early_Stopper,Model_Check_LSTM])","361cb5e9":"Model_Results_LSTM = Model_LSTM.evaluate(X_test,Y_test)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results_LSTM[0])\nprint(\"ACCURACY:  \" + \"%.4f\" % Model_Results_LSTM[1])","a9dc88b6":"X_train, X_test, Y_train, Y_test = train_test_split(Values_X,Labels_X_Encode, train_size=0.9, random_state = 42, shuffle=True)","b0ab32e5":"X_train = np.expand_dims(X_train,axis=2)\nX_test = np.expand_dims(X_test,axis=2)","8bd03a78":"print(X_train.shape)\nprint(X_test.shape)","a9b01194":"Model_Check_CONV1D_II = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                     save_best_only=True,\n                                                     filepath=\".\/my_CONV1D_II_model\")","74c6626c":"Model_CONV1D_II = Sequential()\n\nModel_CONV1D_II.add(Conv1D(5,kernel_size=9,strides=1,padding=\"same\",activation='relu',\n                input_shape = (X_train.shape[1],1),\n                kernel_regularizer = regularizers.l1_l2(l1=1e-5, l2=1e-4)))\nModel_CONV1D_II.add(BatchNormalization())\nModel_CONV1D_II.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\nModel_CONV1D_II.add(Conv1D(15,kernel_size=9,strides=1,padding=\"same\", activation='relu',\n                kernel_regularizer = regularizers.l1_l2(l1=1e-5, l2=1e-4)))\nModel_CONV1D_II.add(Dropout(0.25))\nModel_CONV1D_II.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\n\nModel_CONV1D_II.add(Conv1D(45,kernel_size=9,strides=1,padding=\"same\", activation='relu',\n                 kernel_regularizer = regularizers.l1_l2(l1=1e-5, l2=1e-4)))\nModel_CONV1D_II.add(Dropout(0.25))\nModel_CONV1D_II.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\n\nModel_CONV1D_II.add(Conv1D(65,kernel_size=9,strides=1,padding=\"same\", activation='relu'))\nModel_CONV1D_II.add(Dropout(0.25))\nModel_CONV1D_II.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\nModel_CONV1D_II.add(Conv1D(75,kernel_size=9,strides=1,padding=\"same\", activation='relu'))\nModel_CONV1D_II.add(Dropout(0.5))\nModel_CONV1D_II.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\nModel_CONV1D_II.add(Conv1D(85,kernel_size=9,strides=1,padding=\"same\", activation='relu'))\nModel_CONV1D_II.add(Dropout(0.5))\nModel_CONV1D_II.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\nModel_CONV1D_II.add(Dropout(0.75))\nModel_CONV1D_II.add(GlobalAvgPool1D())\nModel_CONV1D_II.add(Dense(output_dim, activation='softmax'))","b340c8ab":"Model_CONV1D_II.compile(optimizer=compile_optimizer,loss=compile_loss,metrics=compile_metrics)","f12aa00c":"CONV1D_II_Model = Model_CONV1D_II.fit(X_train, Y_train, epochs=70,\n                                validation_data=(X_test, Y_test), callbacks=[Early_Stopper,Model_Check_CONV1D_II])","19d4eef6":"Model_Results_CONV1D_II = Model_CONV1D_II.evaluate(X_test,Y_test)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results_CONV1D_II[0])\nprint(\"ACCURACY:  \" + \"%.4f\" % Model_Results_CONV1D_II[1])","91cef28d":"Label_Encode = LabelEncoder()","fd792878":"Labels_X_Encode_II = Label_Encode.fit_transform(Labels_X)","90c4759f":"xTrain,xTest,yTrain,yTest = train_test_split(Values_X,Labels_X_Encode_II,train_size=0.9,random_state=42,shuffle=True)","1e19e7e5":"print(xTrain.shape)\nprint(xTest.shape)\nprint(yTrain.shape)\nprint(yTest.shape)","0d1b21fc":"xTrain = Scaler_Function.fit_transform(xTrain)\nxTest = Scaler_Function.fit_transform(xTest)","12e40333":"lj = LogisticRegression(solver=\"liblinear\").fit(xTrain,yTrain)\ngnb = GaussianNB().fit(xTrain,yTrain)\nknnc = KNeighborsClassifier().fit(xTrain,yTrain)\ncartc = DecisionTreeClassifier(random_state=42).fit(xTrain,yTrain)\nrfc = RandomForestClassifier(random_state=42,verbose=False).fit(xTrain,yTrain)\ngbmc = GradientBoostingClassifier(verbose=False).fit(xTrain,yTrain)\nxgbc = XGBClassifier().fit(xTrain,yTrain)\nlgbmc = LGBMClassifier().fit(xTrain,yTrain)\ncatbc = CatBoostClassifier(verbose=False).fit(xTrain,yTrain)","730c40b6":"modelsc = [lj,gnb,knnc,cartc,rfc,gbmc,xgbc,lgbmc,catbc]\nfor model in modelsc:\n    name = model.__class__.__name__\n    predict = model.predict(xTest)\n    R2CV = cross_val_score(model,xTest,yTest,cv=10,verbose=False).mean()\n    error = -cross_val_score(model,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\",verbose=False).mean()\n    print(name + \": \")\n    print(\"-\" * 10)\n    print(\"ACC-->\",accuracy_score(yTest,predict))\n    print(\"R2CV-->\",R2CV)\n    print(\"MEAN SQUARED ERROR-->\",np.sqrt(error))\n    print(\"-\" * 30)","570d3244":"#### EXTRACT FUNCTION","ae3cbce3":"#### WAVEPLOT","fe3360a1":"# DATA PROCESS AND ENGINEERING","4f201062":"# HISTORY\n\n#### Context\n\n* This dataset was originally for a machine learning challenge to classify heart beat sounds. The data was gathered from two sources: (A) from the general public via the iStethoscope Pro iPhone app, and (B) from a clinic trial in hospitals using the digital stethoscope DigiScope. There were two challenges associated with this competition:\n\n1. Heart Sound Segmentation\n\nThe first challenge is to produce a method that can locate S1(lub) and S2(dub) sounds within audio data, segmenting the Normal audio files in both datasets.\n\n2. Heart Sound Classification\n\nThe task is to produce a method that can classify real heart audio (also known as \u201cbeat classification\u201d) into one of four categories.\n\n#### Content\n\n* The dataset is split into two sources, A and B:\n\n* set_a.csv - Labels and metadata for heart beats collected from the general public via an iPhone app\n\n* setatiming.csv - contains gold-standard timing information for the \"normal\" recordings from Set A.\n\n* set_b.csv - Labels and metadata for heart beats collected from a clinical trial in hospitals using a digital stethoscope\n\n* audio files - Varying lengths, between 1 second and 30 seconds. (some have been clipped to reduce excessive noise and provide the salient fragment of the sound)","1a270feb":"#### MAIN CSV","a8ad0201":"# ANALYSIS","09572cf5":"#### DATA PROCESS AND SPLITTING FOR CON1D AND GLOBALAVGPOOL1D","d18a1ce6":"#### SHIFT","aeed0309":"# MODEL STRUCTURE WITH LSTM","07bcab26":"# PROCESS FUNCTIONS","52a390e3":"#### STRUCTURE","6b4247ff":"#### WAVEPLOT FUNCTION","2b08ca9a":"# MODEL STRUCTURE WITH CON1D AND GLOBALAVGPOOL1D","a1e988e4":"#### TO CREATE NEW DATAFRAME","b7001def":"#### CALLBACKS","a0edf6cf":"#### SPLITTING AND PRE-TRAINING PROCESS","e0c61fd4":"#### TO SHUFFLE","984c8764":"#### SPECSHOW","9930264c":"# SKLEARN","287cf133":"#### NOISE","d4aa6f6d":"#### PITCH","0b9b0839":"#### STRUCTURE","e7f235f2":"# PACKAGES AND LIBRARIES","dc417d87":"#### TO CONCAT","73084c36":"#### DATA PROCESS AND SPLITTING FOR CONV2D","8df7cbe1":"#### NOISE","c4900d38":"# MODEL STRUCTURE","52a64eaf":"#### PITCH FUNCTION","40725d6a":"#### SPECSHOW FUNCTION","c79569cb":"#### PLAYING FUNCTION","af0c97f4":"# MODEL STRUCTURE WITH RNN - SEPCNN","dbbc17c4":"#### DATA PROCESS AND SPLITTING FOR SKLEARN","f5eee6f6":"#### STRUCTURE","e543430a":"#### STRETCH FUNCTION","64cbf72d":"#### TO SAVE","7305f891":"#### DATA PROCESS AND SPLITTING FOR LSTM","3bb055c8":"#### STRUCTURE","0db49f07":"#### SIMPLE CHECKING","9ec90075":"#### STRETCH","5c4671ca":"#### PARAMETERS","e3ad7fcd":"#### SHIFT FUNCTION","1aaa1d10":"# PATH, LABEL, TRANSFORMATION","ce2cf417":"#### PLAYING","11e7c19a":"#### EXPORT FUNCTION","9dcfc330":"# MODEL STRUCTURE WITH CONV2D","87e737bd":"#### STRUCTURE"}}