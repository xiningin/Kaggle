{"cell_type":{"6462daff":"code","f976b660":"code","cda6fdce":"code","23bd746c":"code","34576de3":"code","f212ad70":"code","6bebef98":"code","75a57663":"code","87101b80":"code","1f95a9f6":"code","18c83861":"code","6d4923eb":"code","66099b83":"code","ec442980":"code","7a49625f":"code","46661e25":"code","ed3c595c":"code","8e3ef5a5":"code","01d71ea8":"code","90f65b3b":"code","3665cecc":"code","87a60868":"code","d3154195":"code","0668accc":"code","3e888276":"code","e4ea3206":"code","88011a1b":"markdown","20cabcab":"markdown","c802e97e":"markdown","ad93a0c1":"markdown","a2086736":"markdown","c02fe1f4":"markdown","86598935":"markdown","507e7aab":"markdown","dc9c3e9d":"markdown"},"source":{"6462daff":"import numpy as np\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sbn\n\n%matplotlib inline\n# plt.style.use('seaborn')","f976b660":"types = {'Store_id': np.dtype(int),\n         'Holiday': np.dtype(int),\n         'Sales': np.dtype(float)}\n\n_train = pd.read_csv(\"\/kaggle\/input\/av-jobathon-sep2021\/train.csv\", parse_dates=[5], dtype=types)\n_test = pd.read_csv(\"\/kaggle\/input\/av-jobathon-sep2021\/test.csv\", parse_dates=[5], dtype=types)\n_sample = pd.read_csv(\"\/kaggle\/input\/av-jobathon-sep2021\/sample.csv\")\n\n_train.head()","cda6fdce":"_train.describe()","23bd746c":"_train.isnull().sum()","34576de3":"# _test.info()\n_test.nunique()","f212ad70":"sbn.catplot(x ='Location_Type', y ='Sales', data = _train)","6bebef98":"sbn.catplot(x='Location_Type', y='Sales', hue='Discount', kind='point', data=_train)","75a57663":"sbn.catplot(x='Location_Type', y='Sales', hue='Holiday', kind='point', data=_train)","87101b80":"from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\ndef drop_columns(df, columns = []):\n    for column in columns:\n        if column in df.columns:\n            df.drop([column],axis=1, inplace=True)\n\ndef encode_cat_columns(df, cat_coulmn = []):\n    return pd.get_dummies(df, columns=cat_coulmn)\n\n\ndef accuracy_score(y_test, y_pred):\n    score=r2_score(y_test,y_pred)\n    print(\"r2 socre is \",score)\n    print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n    print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))","1f95a9f6":"def pre_process_features(df):\n    \n    df = df.copy()\n    \n    store_types = {'S1': 0, 'S2': 1, 'S3': 2, 'S4': 3}\n    location_types = {'L1': 0, 'L2': 1, 'L3': 2, 'L4': 3, 'L5': 4}\n    region_code = {'R1': 0, 'R2': 1, 'R3': 2, 'R4': 3}\n    discount = {'No': 0, 'Yes': 1}\n    \n#     Encode categorical features with numerical values\n    df['Store_Type'] = df['Store_Type'].map(store_types)\n    df['Location_Type'] = df['Location_Type'].map(location_types)\n    df['Region_Code'] = df['Region_Code'].map(region_code)\n    df['Discount'] = df['Discount'].map(discount)\n    \n#     df = encode_cat_columns(df, cat_coulmn=[\"Store_Type\",\"Location_Type\",\"Region_Code\",\"Discount\"])\n    \n#     Create month, day of month and day of week features\n    df['Month'] = df.Date.dt.month\n    df['DayOfMonth'] = df.Date.dt.day\n    df['DayOfWeek']= df.Date.dt.day_of_week\n\n    return df","18c83861":"train = pre_process_features(_train)\ntest = pre_process_features(_test)","6d4923eb":"drop_columns(train, ['ID', 'Date', '#Order'])\ndrop_columns(test, ['Date', '#Order'])","66099b83":"train.head()","ec442980":"train.corr().style.background_gradient(cmap='Greens_r')\n\n# sbn.heatmap(train.corr(), annot=True)\n# plt.title(\"Correlation Map\")\n# plt.show()","7a49625f":"from sklearn.model_selection import train_test_split\n\n_X = train.drop([\"Sales\"],axis=1)\n_Y = train[\"Sales\"]\n\n#splitting the dataset for training the model\nX_train, X_test, y_train, y_test = train_test_split(_X, _Y, test_size=0.2)","46661e25":"import xgboost as xg","ed3c595c":"xgb_r = xg.XGBRegressor(objective ='reg:squarederror', n_estimators = 81, max_depth=9)\nxgb_r.fit(X_train, y_train)","8e3ef5a5":"y_pred = xgb_r.predict(X_test)\naccuracy_score(y_test, y_pred)","01d71ea8":"from sklearn.model_selection import GridSearchCV\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=DeprecationWarning)","90f65b3b":"def print_results(results):\n    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n    means = results.cv_results_['mean_test_score']\n    stds = results.cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n        print('{} (+\/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))","3665cecc":"parameters = {\n    'objective': ['reg:squarederror'],\n    'n_estimators': [52, 55, 60],\n    'max_depth': [9]\n}\n\nxgbr = xg.XGBRegressor()\n\ncv = GridSearchCV(xgbr, parameters, cv=5)\n# cv.fit(X_train, y_train.values.ravel())\n\n# print_results(cv)","87a60868":"XX_test = test.drop(['ID'],axis=1)","d3154195":"result = xgb_r.predict(XX_test)","0668accc":"prediction = pd.DataFrame({\n    \"ID\": test[\"ID\"],\n    \"Sales\": result\n})","3e888276":"prediction.head()","e4ea3206":"prediction.to_csv(\"Submission.csv\", index=False)","88011a1b":"# XGBOOSTER","20cabcab":"# Prepare Input","c802e97e":"> Location type is important because the sales depends on it","ad93a0c1":"> Sales in each location is low on holday","a2086736":"> No any null\/empty values","c02fe1f4":"# Preprocessing","86598935":"# Predict Sales","507e7aab":"# GridSearchCV on XGBOOSTER","dc9c3e9d":"> Sales in each location is high when discount is given"}}