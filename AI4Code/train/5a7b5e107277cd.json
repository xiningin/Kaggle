{"cell_type":{"edb7fc21":"code","deb73c5f":"code","79fe02bb":"code","a63cc8d9":"code","2426df69":"code","8b1d2b3d":"code","ca43b2e8":"code","b4b52c91":"code","638a42d3":"markdown","f787438b":"markdown","d5ff1fcb":"markdown","ce80cef4":"markdown","af7ce28c":"markdown","495f5d43":"markdown","7be00dae":"markdown","de2fa665":"markdown"},"source":{"edb7fc21":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nimport pandas as pd\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom keras.layers import Dense, Dropout, BatchNormalization\nfrom keras.models import Sequential","deb73c5f":"df_train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")","79fe02bb":"numerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent',)),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])","a63cc8d9":"class TitleSelector(BaseEstimator, TransformerMixin):\n    def __init__( self):\n        self.dict_title = {\n            \"Capt\":       0,\n            \"Col\":        0,\n            \"Major\":      0,\n            \"Jonkheer\":   1,\n            \"Don\":        1,\n            \"Sir\" :       1,\n            \"Dr\":         0,\n            \"Rev\":        0,\n            \"the Countess\":1,\n            \"Dona\":       1,\n            \"Mme\":        2,\n            \"Mlle\":       3,\n            \"Ms\":         2,\n            \"Mr\" :        4,\n            \"Mrs\" :       2,\n            \"Miss\" :      3,\n            \"Master\" :    5,\n            \"Lady\" :      1\n        }\n   \n    def fit(self, X, y=None):\n        return self \n    \n    def transform( self, X, y=None):\n        for i, name in enumerate(X[\"Name\"]):\n            for title in self.dict_title.keys():\n                if title in name:\n                    X[\"Name\"][i] = self.dict_title[title]\n                    break\n        \n            assert X[\"Name\"][i] in self.dict_title.values()\n        \n        return X\n    \nname_transformer = Pipeline(steps=[\n    ('name', TitleSelector()),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])","2426df69":"num_cols = [\"Age\", \"Fare\", ]\ncat_cols = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Ticket\", \"Cabin\", \"Embarked\"]\ncols = num_cols + cat_cols + [\"Name\"]\n\n\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numerical_transformer, num_cols),\n    ('name', name_transformer, [\"Name\"]),\n    ('cat', categorical_transformer, cat_cols),\n])\n\nX_train = preprocessor.fit_transform(df_train[cols])\ny_train = df_train[\"Survived\"].values","8b1d2b3d":"    model = Sequential()\n    model.add(Dense(32, input_dim=858, activation='relu'))\n    model.add(Dropout(0.9))\n    model.add(Dense(32, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.9))\n    model.add(Dense(1, activation='sigmoid'))","ca43b2e8":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=1000, batch_size=8)","b4b52c91":"X_test = preprocessor.transform(df_test[cols])\ny_pred = model.predict_classes(X_test)\n\ndf_pred = pd.DataFrame(df_test[\"PassengerId\"])\ndf_pred[\"Survived\"] = y_pred\ndf_pred.to_csv(\"submission.csv\", index=False)","638a42d3":"This kernel is a short and simple example of a neural network that achieves top 10% on \"Titanic: Machine Learning from Disaster\" challenge. This kernel does not present any statistical insights about the dataset and the viewer should already be familiar with the challenge. \n\nWe load the dependencies.","f787438b":"And voila! We trained the model! Now its time to save the predictions.","d5ff1fcb":"We create a numerial and categorial transformer using the sklearn's pipeline. The numerical transformer fills the missing values with the mean and then standardizes the data. The categorical transformer fills the missing values with the most frequent and transforms the categories in one-hot vectors. ","ce80cef4":"We need to reate a custom transformer for the 'Name' column. It must replace the title of a person with a corresponding one-hot vector.","af7ce28c":"We load the train and test data using pandas. ","495f5d43":"Now its time to train! We use Adam optimizer and Binary Cross-entropy as the loss function. It should not take more than a few minutes on the CPU.","7be00dae":"We create a neural network with two hidden layers. We use a very high dropout to strongly regularize the model. Also, batch normalization is used to stabilize the training.","de2fa665":"Now we create the ColumnTransformer object to fit and transform the data. "}}