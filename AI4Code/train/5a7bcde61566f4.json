{"cell_type":{"21141ab0":"code","c375b357":"code","2ec122a5":"code","83584216":"code","f3361777":"code","c8677d74":"code","29368bee":"code","4bf8d04f":"code","f30d8f07":"code","3760acab":"code","52780f9f":"code","35fd0184":"code","1e76dd27":"markdown","545eee95":"markdown","483e06f6":"markdown","4aca4085":"markdown","5bfbb238":"markdown","3a232877":"markdown"},"source":{"21141ab0":"# importing libraries\nimport pandas as pd\nimport numpy as np\n\nimport warnings\nwarnings.simplefilter('ignore')\n\n# setting seed\nseed = 11","c375b357":"# reading files\ntrain = pd.read_csv('..\/input\/learn-together\/train.csv', index_col=\"Id\")\ntest = pd.read_csv('..\/input\/learn-together\/test.csv')\n\n# deleting columns with no nulls (found previously)\ndel train['Soil_Type15']\ndel train['Soil_Type7']\n\ndel test['Soil_Type15']\ndel test['Soil_Type7']","2ec122a5":"# defining features and target\nfeatures = train.drop(['Cover_Type'], axis=1)\ntarget = train.Cover_Type","83584216":"from sklearn.ensemble import RandomForestClassifier\n\nRF_model = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n                       max_depth=24, max_features=17, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=138,\n                       n_jobs=None, oob_score=False, random_state=11, verbose=0,\n                       warm_start=False)","f3361777":"from lightgbm import LGBMClassifier\n\nLGBM_model = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n               importance_type='split', learning_rate=0.1, max_depth=-1,\n               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n               n_estimators=198, n_jobs=-1, num_leaves=64, objective=None,\n               random_state=11, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)","c8677d74":"from sklearn.neighbors import KNeighborsClassifier\n\nKN_model = KNeighborsClassifier(algorithm='kd_tree', leaf_size=61, metric='minkowski',\n                     metric_params=None, n_jobs=-1, n_neighbors=2, p=1,\n                     weights='distance')","29368bee":"from sklearn.ensemble import ExtraTreesClassifier\n\nExtraTr_model = ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n                     max_depth=None, max_features=21, max_leaf_nodes=None,\n                     min_impurity_decrease=0.0, min_impurity_split=None,\n                     min_samples_leaf=1, min_samples_split=4,\n                     min_weight_fraction_leaf=0.0, n_estimators=420, n_jobs=-1,\n                     oob_score=False, random_state=11, verbose=0,\n                     warm_start=False)","4bf8d04f":"models_list = [\n    RF_model, \n    LGBM_model, \n    KN_model, \n    ExtraTr_model\n]","f30d8f07":"from mlxtend.classifier import StackingCVClassifier\n\nsclf = StackingCVClassifier(classifiers=models_list,\n                            meta_classifier=RandomForestClassifier(n_estimators=500, random_state=seed),\n                            cv=5,\n                            random_state=seed,\n                            verbose=1, \n                            n_jobs=-1)","3760acab":"# fitting metamodel\nsclf.fit(features, target)","52780f9f":"# applying the metamodel to the test data and getting predictions\ntest_pred = sclf.predict(test.drop('Id', axis=1))","35fd0184":"# making a dataframe with a result set\noutput = pd.DataFrame({'ID': test.Id,\n                       'Cover_Type': test_pred})\n\n# exporting result dataframe to csv\noutput.to_csv('stacking submission.csv', index=False)\nprint('Export done')","1e76dd27":"## Stacking","545eee95":"As a stacking function I use StackingCVClassifier. For me it was most simple and convinient","483e06f6":"## Installs and reading data","4aca4085":"## Exporting to file","5bfbb238":"## Defining models\nFirstly, we choose models to stack.","3a232877":"This notebook is focused on a final \"stacking\" part of DS work on a project. \n\nThe goal is to show the value of model stacking to the overall score.\nAt the moment of committing, this kernel gets top 25% result with no feature engineering at all. \n\nAlthough, as FE is the most important part of DS work, I hope that this kernel as a template for your modelling part will help you to focus on feature engineering."}}