{"cell_type":{"6685f3ff":"code","a24d13db":"code","495d4382":"code","c85da515":"code","9d7588ae":"code","0bc063b2":"code","25184b2b":"code","d920f8e7":"code","bfeb566f":"code","1adbb5ad":"code","05aadaef":"code","57981d54":"code","4293c0e2":"code","331ca4ad":"code","a227623b":"code","0c2aff86":"code","5ef084b1":"code","6766dbce":"code","4115d304":"code","010606e7":"code","a5ac7489":"code","922240c2":"code","4e7dbbcc":"code","ad5cf0d2":"markdown","f90814c6":"markdown","6696ace2":"markdown","b5fdd1d9":"markdown","f308e31b":"markdown","c2436579":"markdown","b2f4b80a":"markdown","e19c6e15":"markdown","285fca98":"markdown","6bdc3a58":"markdown","52915097":"markdown","c4aec701":"markdown","e6931423":"markdown","7ee32c75":"markdown","cdb10ea8":"markdown","3b959ed1":"markdown","bcb8545e":"markdown","86f682c6":"markdown","8210726a":"markdown","414eaff3":"markdown","86f66101":"markdown"},"source":{"6685f3ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch\n# Neural networks can be constructed using the torch.nn package.\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\nimport torchvision\nimport torchvision.transforms as transforms\n'''for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\n# Any results you write to the current directory are saved as output.","a24d13db":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)","495d4382":"BASE_PATH = '\/kaggle\/input\/arthropod-taxonomy-orders-object-detection-dataset\/ArTaxOr\/'","c85da515":"image=[]\nlabels=[]\nfor file in os.listdir(BASE_PATH):\n    if file=='Coleoptera':\n        for c in os.listdir(os.path.join(BASE_PATH, file)):\n            if c!='annotations':\n                image.append(c)\n                labels.append('Coleoptera')\n    if file=='Diptera':\n        for c in os.listdir(os.path.join(BASE_PATH, file)):\n            if c!='annotations':\n                image.append(c)\n                labels.append('Diptera')\n    if file=='Hymenoptera':\n        for c in os.listdir(os.path.join(BASE_PATH, file)):\n            if c!='annotations':\n                image.append(c)\n                labels.append('Hymenoptera')\n    if file=='Lepidoptera':\n        for c in os.listdir(os.path.join(BASE_PATH, file)):\n            if c!='annotations':\n                image.append(c)\n                labels.append('Lepidoptera')\ndata = {'Images':image, 'labels':labels} \ndata = pd.DataFrame(data) \ndata.head()","9d7588ae":"lb = LabelEncoder()\ndata['encoded_labels'] = lb.fit_transform(data['labels'])\ndata.head()","0bc063b2":"batch_size = 128\nvalidation_split = .3\nshuffle_dataset = True\nrandom_seed= 42","25184b2b":"# Creating data indices for training and validation splits:\n# from sklearn.model_selection import train_test_split\n# tr, val = train_test_split(data.label, stratify=data.label, test_size=0.1)\ndataset_size = len(data)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]\n#train_indices is equivalent to list(tr.index)\n#val_indices is equivalent to list(val.index)","d920f8e7":"# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)","bfeb566f":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])","1adbb5ad":"class Arthopod_Dataset(Dataset):\n    def __init__(self, img_data,img_path,transform=None):\n        self.img_path = img_path\n        self.transform = transform\n        self.img_data = img_data\n        \n    def __len__(self):\n        return len(self.img_data)\n    \n    def __getitem__(self, index):\n        img_name = os.path.join(self.img_path,self.img_data.loc[index, 'labels'],\n                                self.img_data.loc[index, 'Images'])\n        image = Image.open(img_name)\n        #image = image.convert('RGB')\n        image = image.resize((300,300))\n        label = torch.tensor(self.img_data.loc[index, 'encoded_labels'])\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label","05aadaef":"dataset = Arthopod_Dataset(data,BASE_PATH,transform)","57981d54":"\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n                                           sampler=train_sampler)\nvalidation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n                                                sampler=valid_sampler)","4293c0e2":"def img_display(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    npimg = np.transpose(npimg, (1, 2, 0))\n    return npimg","331ca4ad":"# get some random training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\narthopod_types = {0: 'Coleoptera', 1: 'Diptera', 2: 'Hymenoptera', 3: 'Lepidoptera'}\n# Viewing data examples used for training\nfig, axis = plt.subplots(3, 5, figsize=(15, 10))\nfor i, ax in enumerate(axis.flat):\n    with torch.no_grad():\n        image, label = images[i], labels[i]\n        ax.imshow(img_display(image)) # add image\n        ax.set(title = f\"{arthopod_types[label.item()]}\") # add label","a227623b":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # 3 input image channel, 16 output channels, 3x3 square convolution kernel\n        self.conv1 = nn.Conv2d(3,16,kernel_size=3,stride=2,padding=1)\n        self.conv2 = nn.Conv2d(16, 32,kernel_size=3,stride=2, padding=1)\n        self.conv3 = nn.Conv2d(32, 64,kernel_size=3,stride=2, padding=1)\n        self.conv4 = nn.Conv2d(64, 64,kernel_size=3,stride=2, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.dropout = nn.Dropout2d(0.4)\n        self.batchnorm1 = nn.BatchNorm2d(16)\n        self.batchnorm2 = nn.BatchNorm2d(32)\n        self.batchnorm3 = nn.BatchNorm2d(64)\n        self.fc1 = nn.Linear(64*5*5,512 )\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 4)\n        \n    def forward(self, x):\n        x = self.batchnorm1(F.relu(self.conv1(x)))\n        x = self.batchnorm2(F.relu(self.conv2(x)))\n        x = self.dropout(self.batchnorm2(self.pool(x)))\n        x = self.batchnorm3(self.pool(F.relu(self.conv3(x))))\n        x = self.dropout(self.conv4(x))\n        x = x.view(-1, 64*5*5) # Flatten layer\n        x = self.dropout(self.fc1(x))\n        x = self.dropout(self.fc2(x))\n        x = F.log_softmax(self.fc3(x),dim = 1)\n        return x","0c2aff86":"model = Net() # On CPU\n#model = Net().to(device)  # On GPU\nprint(model)","5ef084b1":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)","6766dbce":"def accuracy(out, labels):\n    _,pred = torch.max(out, dim=1)\n    return torch.sum(pred==labels).item()\n","4115d304":"n_epochs = 12\nprint_every = 10\nvalid_loss_min = np.Inf\nval_loss = []\nval_acc = []\ntrain_loss = []\ntrain_acc = []\ntotal_step = len(train_loader)\nfor epoch in range(1, n_epochs+1):\n    running_loss = 0.0\n    # scheduler.step(epoch)\n    correct = 0\n    total=0\n    print(f'Epoch {epoch}\\n')\n    for batch_idx, (data_, target_) in enumerate(train_loader):\n        #data_, target_ = data_.to(device), target_.to(device)# on GPU\n        # zero the parameter gradients\n        optimizer.zero_grad()\n        # forward + backward + optimize\n        outputs = model(data_)\n        loss = criterion(outputs, target_)\n        loss.backward()\n        optimizer.step()\n        # print statistics\n        running_loss += loss.item()\n        _,pred = torch.max(outputs, dim=1)\n        correct += torch.sum(pred==target_).item()\n        total += target_.size(0)\n        if (batch_idx) % 20 == 0:\n            print ('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}' \n                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n    train_acc.append(100 * correct \/ total)\n    train_loss.append(running_loss\/total_step)\n    print(f'\\ntrain loss: {np.mean(train_loss):.4f}, train acc: {(100 * correct \/ total):.4f}')\n    batch_loss = 0\n    total_t=0\n    correct_t=0\n    with torch.no_grad():\n        model.eval()\n        for data_t, target_t in (validation_loader):\n            #data_t, target_t = data_t.to(device), target_t.to(device)# on GPU\n            outputs_t = model(data_t)\n            loss_t = criterion(outputs_t, target_t)\n            batch_loss += loss_t.item()\n            _,pred_t = torch.max(outputs_t, dim=1)\n            correct_t += torch.sum(pred_t==target_t).item()\n            total_t += target_t.size(0)\n        val_acc.append(100 * correct_t \/ total_t)\n        val_loss.append(batch_loss\/len(validation_loader))\n        network_learned = batch_loss < valid_loss_min\n        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t \/ total_t):.4f}\\n')\n        # Saving the best weight \n        if network_learned:\n            valid_loss_min = batch_loss\n            torch.save(model.state_dict(), 'model_classification_tutorial.pt')\n            print('Detected network improvement, saving current model')\n    model.train()","010606e7":"fig = plt.figure(figsize=(20,10))\nplt.title(\"Train - Validation Loss\")\nplt.plot( train_loss, label='train')\nplt.plot( val_loss, label='validation')\nplt.xlabel('num_epochs', fontsize=12)\nplt.ylabel('loss', fontsize=12)\nplt.legend(loc='best')","a5ac7489":"fig = plt.figure(figsize=(20,10))\nplt.title(\"Train - Validation Accuracy\")\nplt.plot(train_acc, label='train')\nplt.plot(val_acc, label='validation')\nplt.xlabel('num_epochs', fontsize=12)\nplt.ylabel('accuracy', fontsize=12)\nplt.legend(loc='best')","922240c2":"# Importing trained Network with better loss of validation\nmodel.load_state_dict(torch.load('model_classification_tutorial.pt'))","4e7dbbcc":"dataiter = iter(validation_loader)\nimages, labels = dataiter.next()\narthopod_types = {0: 'Coleoptera', 1: 'Diptera', 2: 'Hymenoptera', 3: 'Lepidoptera'}\n# Viewing data examples used for training\nfig, axis = plt.subplots(3, 5, figsize=(15, 10))\nwith torch.no_grad():\n    model.eval()\n    for ax, image, label in zip(axis.flat,images, labels):\n        ax.imshow(img_display(image)) # add image\n        image_tensor = image.unsqueeze_(0)\n        output_ = model(image_tensor)\n        output_ = output_.argmax()\n        k = output_.item()==label.item()\n        ax.set_title(str(arthopod_types[label.item()])+\":\" +str(k)) # add label","ad5cf0d2":"## Credits\n* [PyTorch CNN from scratch](https:\/\/www.kaggle.com\/bonhart\/pytorch-cnn-from-scratch)\n* [Starting Kit for PyTorch Deep Learning](https:\/\/www.kaggle.com\/mratsim\/starting-kit-for-pytorch-deep-learning)\n* [Simple EDA and model in pytorch](https:\/\/www.kaggle.com\/artgor\/simple-eda-and-model-in-pytorch)\n* [CNN - Digit Recognizer (PyTorch)](https:\/\/www.kaggle.com\/gustafsilva\/cnn-digit-recognizer-pytorch)","f90814c6":"## Would there be any improvement in model performence while classification by using Pytorch?\nAs far as I have learned about PyTorch, the answer is no. The same model architecture would give the same performance in Keras. If you find any exception please let me know in the comments down below. I would be happy to learn about it.","6696ace2":"## Accuracy and loss Curve","b5fdd1d9":"## Evaluation\nevaluating the model performance through visualization","f308e31b":"**NOTE** - In case you already have a separate dataset set for train and validation, you could directly pass the path of the datasets to the __init__ section of the custom dataset class and read it right there and use it.","c2436579":" ## Create custom dataset class\n A dataset must contain following functions to be used by data loader later on.\n\n* __init__() function is where the initial logic happens like reading a csv, assigning transforms etc.\n* __getitem__() function returns the data and labels. This function is called from dataloader like this:\n\n> img, label = MyCustomDataset.__getitem__(99)  # For 99th item\n\n<br>\nAn important thing to note is that __getitem__() return a specific type for a single data point (like a tensor, numpy array etc.), otherwise, in the data loader you will get an error like:\n\n> TypeError: batch must contain tensors, numbers, dicts or lists; found \n> class 'PIL.PngImagePlugin.PngImageFile'\n\n<br>\nCredits: [PyTorch Custom Dataset Examples](https:\/\/github.com\/utkuozbulak\/pytorch-custom-dataset-examples)","b2f4b80a":"## Spliting of Dataset\nI have shown two ways to split a dataset into train and validation. One is by splitting it from sratch and another method is by using train_test_split from scikit-learn( the one which I have commented out).\n","e19c6e15":"**TIP** - If you are facing difficulty in constructing a neural network class, then I hope this tip would be very much helpful.<br><br>\nBefore laying your hands on PyTorch I hope you would be familiar with **Keras**( another python library for deep-learning ). And if you are not, then please go practice Keras first as it allows the simplest way of implementing a deep learning model in python.<br><br>\nIn Keras after implementing a neural network with Model API, there is a command called \"Model.summary()\" which gives you the entire structure of the neural network that you have created along with the number of parameters. Keep that summary side by side while constructing your network class in PyTorch, things would get much easier. It would be much easier to see that network summary, name the layers according to it and connect them concerning their input and output features in PyTorch. It was helpful in my case, and I hope It would be helpful to you also.\n![image](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcQylY4AqnlZcpGxTSj7h8tG5ZeUESvLa9MLk51PDDHwkACgirUc)\n<br>Link to the model whose summary I used to construct my PyTorch model - [ Classifying Cursive hiragana(\u5d29\u3057\u5b57) KMNIST using CNN](https:\/\/www.kaggle.com\/gpreda\/classifying-cursive-hiragana-kmnist-using-cnn)","285fca98":"**NOTE** - In the cell above I have created a csv Data-frame from the raw dataset. In your case you might not have to follow this step if you are already provided with csv file which contains the desired input and target value.","6bdc3a58":"## Introduction\nPytorch tutorial is a series of tutorials created by me to explain the basic aspects of PyTorch and its implementation. PyTorch is complex to implement but not difficult. If you see it as a way of documentation or documenting a program, then things get much easier to understand. The most interesting part of this series is that I am also a beginner with PyTorch, so what's difficult me I expect to be difficult for five other individuals also, so at least I expect my tutorial could help five other individuals to implement PyTorch.<br>\nIn this chapter, I have implemented an image classification problem with the help of PyTorch. Here I have explained everything in the most basic way possible so that you could also understand them easily.","52915097":"## The Neural Network\nIn the **Net** class created below, we have constructed a neural network. Construction of the neural network was the second most difficult situation that I faced after constructing a custom dataset. But I am going to explain you everything step by step.<br>\n* Inside the **init()** method you declare each layer with a unique layer name. For every unique layer, declaring its input features and output features is a must. At least the input feature is a must for some of the layers like batch normalization.\n* Inside the **forward(self, x)** method you need to connect the layers that were declared in the init method. One thing must be kept in mind that the output feature of one layer is an input feature of its next connecting layer.\n\n","c4aec701":"## Visualization\nvisualizing the elements of the dataset","e6931423":"## PyTorch-Tutorial \n## Chapter - 1 (The Classification)\n![logo](https:\/\/code.kaytouch.biz\/wp-content\/uploads\/2018\/05\/pytorch-470x250.png)\n","7ee32c75":"## CrossEntropyLoss\nIt is useful when training a classification problem with C classes. If provided, the optional argument weight should be a 1D Tensor assigning weight to each of the classes. This is particularly useful when you have an unbalanced training set. It is a prototpe of categorical crossentropy in keras.\nIn case of **Binary classification** use **BCELoss(Binary Cross Entropy)** or BCEWithLogitsLoss.","cdb10ea8":"## Transforms\nTransforms are common image transformations. They can be chained together using **Compose**.\n## Normalization\nNormalize a tensor image with mean and standard deviation. Given mean: (M1,...,Mn) and std: (S1,..,Sn) for n channels, this transform will normalize each channel of the input torch.*Tensor i.e. input[channel] = (input[channel] - mean[channel]) \/ std[channel]\nConvert a PIL Image or numpy.ndarray to tensor.\n\n## ToTensor\nConverts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8","3b959ed1":"## Device selection\nSelect your device, whether you to use CPU or GPU for your model.","bcb8545e":"## Conclusion\nWhatever I have explained in this kernel is according to my personal experience in PyTorch as a beginner. If I have missed out to explain something then please let me know. I would be adding more chapters to this pytorch tutorial series. Till then please **UPVOTE** this kernel if you like it, feel free to let me know what all improvements that could be added to this tutorial and have a nice day.","86f682c6":"## Training the Network\nIn the cell below, it is explained how to train your model with epochs. In the \"train_loss\" and \"val_loss\" the training loss and validation loss are stored respectively after every epoch. Similarly in case of training accuracy and validation accuracy also, the same thing happens. just remember while validation the weighhts are not upgraded thats why we use **\" with torch.no_grad() \"**.<br>\nHere, **\"Torch.max(x, dim=1)\"** works same as **\"np.argmax(x, axis=1)\"**. We use **\".item()\"** to get the value inside the tensor. **torch.save(model.state_dict(), 'model_classification_tutorial.pt')** is used to save the PyTorch weight in the given directory.","8210726a":"## Data-set\nDataset used - [Arthropod Taxonomy Orders Object Detection Dataset](https:\/\/www.kaggle.com\/mistag\/arthropod-taxonomy-orders-object-detection-dataset)","414eaff3":"## What is Pytorch?\n### (according to [PyTorch.org](https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py))\nIt\u2019s a Python-based scientific computing package targeted at two sets of audiences:\n* A replacement for NumPy to use the power of GPUs\n* a deep learning research platform that provides maximum flexibility and speed\n\n### (according to ME \ud83d\ude24)\n\nIt is a python based library, useful for a well-documented program in deep learning. I did not observe much speed up in training due to the use of GPU, maybe with multiple GPUs, it might speed up its training. Due to its well-documented feature, I would agree that it is flexible.<br>\nI would recommend you to learn PyTorch but after having a hand full of experience in Keras or at least some knowledge about Keras. Pytorch should not be learned right at the get-go.\n","86f66101":"## Index\nThe things that are explained in this classification tutorial are given below.\n* Creating a custom dataset\n* Creating a neural network in PyTorch\n* Training neural network in PyTorch\n* Plotting of loss and accuracy curve\n* evaluation of performance"}}