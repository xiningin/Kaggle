{"cell_type":{"ae1f4818":"code","fcd3ea35":"code","ff7caf85":"code","b39c81c0":"code","19eb9446":"code","a7bc404f":"code","629e70ef":"code","ee8cc5f7":"code","5367da5d":"code","609e1f10":"code","a4db6f07":"code","dd46d059":"code","0cdea155":"code","0d7752fd":"code","5257f073":"code","db9ca5e6":"code","5eae5d60":"code","7e99f71c":"code","d41cacd7":"code","324581cf":"code","9f452b29":"code","e7fd2b5f":"code","d2770a5f":"code","dc3d1cdd":"code","6edcb43b":"code","cb69c254":"code","1e96fe34":"code","453250d1":"code","ff3764e6":"code","73f459f0":"code","96e9fe0b":"code","bb0a2a7d":"code","b848cbf1":"code","bfb4ce56":"code","9122fed6":"code","4c37675a":"code","cf6c8769":"code","3cfb9fd1":"code","f0465c5a":"code","664fdaa5":"code","6c6596a0":"code","1f30bfac":"code","603faae8":"code","99d45d45":"code","da4060e7":"code","f340b4fd":"code","45659a18":"code","b9229f93":"code","6849ac94":"code","2fd7d8d7":"code","503bdaca":"code","77549d3f":"code","7ddb2f13":"code","a13e4b5f":"code","b7e136fd":"code","14837b09":"code","64994b4c":"code","51876f56":"code","a7bf5a8a":"code","dc5f9b6a":"code","a5ae46fb":"code","22f684da":"code","6f59ba89":"code","dda81d24":"code","956682c1":"code","9fa3c504":"markdown","3901f6a5":"markdown","70a3f662":"markdown","c4e7e25d":"markdown","b9791875":"markdown","a83c40ca":"markdown","0f88dba6":"markdown","946eb440":"markdown","9b79d013":"markdown","0811ae28":"markdown","cfd065ac":"markdown","e91f325d":"markdown","3d666c5b":"markdown","efc0523d":"markdown","f01a99b4":"markdown","2d31a44d":"markdown","3786ff34":"markdown","a7f7b256":"markdown","4ccc227a":"markdown","95d0137f":"markdown","895273bc":"markdown","d67a956e":"markdown","7741c363":"markdown","56949225":"markdown","38bfa44d":"markdown","143d3f11":"markdown","0937d14b":"markdown","1eee3cb4":"markdown","940dc6ed":"markdown","a4d110c7":"markdown","3476f6ce":"markdown","72a2a4df":"markdown","2c7de62c":"markdown","0ac6b076":"markdown","44bde4cb":"markdown","bc48203d":"markdown","8908cf92":"markdown","0fad02af":"markdown","9cf9b73e":"markdown","7ff96830":"markdown","07c87bac":"markdown","a52199e5":"markdown","bfb725cd":"markdown","717a4f93":"markdown","e652c66a":"markdown","46118ef2":"markdown","0cc24172":"markdown","655fe68b":"markdown","7f67cb97":"markdown","7daa26b9":"markdown","2d0dc027":"markdown","a69393f6":"markdown","d4870204":"markdown","92092ea9":"markdown","9c0ba613":"markdown","ce4fdcb3":"markdown","019cfd28":"markdown","fe1e996b":"markdown","fadfa811":"markdown","537a60af":"markdown","48f2bd5e":"markdown","8d962102":"markdown","11ac242c":"markdown","6fdf1eb5":"markdown","f4e276ab":"markdown","1af1e143":"markdown","1696f942":"markdown","5f276f4d":"markdown","e44683ba":"markdown","becba6a5":"markdown","7b1b683a":"markdown","17d0e1a7":"markdown","169bf14a":"markdown","48084b63":"markdown","966b190d":"markdown","8f6db642":"markdown","bd6f7d23":"markdown"},"source":{"ae1f4818":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fcd3ea35":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","ff7caf85":"loans = pd.read_csv('\/kaggle\/input\/loan-data\/loan_data.csv')","b39c81c0":"loans.info()","19eb9446":"loans.describe()","a7bc404f":"loans.head()","629e70ef":"print(loans.isna().sum().sum())","ee8cc5f7":"print(loans['credit.policy'].value_counts())\nprint(loans['purpose'].value_counts())\nprint(loans['not.fully.paid'].value_counts())","5367da5d":"plt.figure(figsize=(10,6))\nloans[loans['credit.policy']==1]['fico'].hist(alpha=0.5,color='blue',\n                                              bins=30,label='Credit.Policy=1')\nloans[loans['credit.policy']==0]['fico'].hist(alpha=0.5,color='red',\n                                              bins=30,label='Credit.Policy=0')\nplt.legend()\nplt.xlabel('FICO')","609e1f10":"plt.figure(figsize=(10,6))\nloans[loans['not.fully.paid']==1]['fico'].hist(alpha=0.5,color='blue',\n                                              bins=30,label='not.fully.paid=1')\nloans[loans['not.fully.paid']==0]['fico'].hist(alpha=0.5,color='red',\n                                              bins=30,label='not.fully.paid=0')\nplt.legend()\nplt.xlabel('FICO')","a4db6f07":"plt.figure(figsize=(11,7))\nsns.countplot(x='purpose',hue='not.fully.paid',data=loans,palette='Set1')","dd46d059":"sns.jointplot(x='fico',y='int.rate',data=loans,color='purple')","0cdea155":"plt.figure(figsize=(11,7))\nsns.lmplot(y='int.rate',x='fico',data=loans,hue='credit.policy',\n           col='not.fully.paid',palette='Set1')","0d7752fd":"categorical_columns = ['credit.policy', 'purpose', 'fico', 'inq.last.6mths', 'delinq.2yrs','pub.rec']\n\nprint(categorical_columns)\nnumerical_columns = ['int.rate', 'installment', 'log.annual.inc', 'dti', 'days.with.cr.line', 'revol.util']\nprint(numerical_columns)\n\nfig,axes = plt.subplots(3,2,figsize=(35,35))\nfor idx,cat_col in enumerate(categorical_columns):\n    row,col = idx\/\/2,idx%2\n    sns.countplot(x=cat_col,data=loans,hue='not.fully.paid',ax=axes[row,col])\n\n\nplt.subplots_adjust(hspace=1)","5257f073":"fig,axes = plt.subplots(1,6,figsize=(40,5))\nfor idx,cat_col in enumerate(numerical_columns):\n    sns.boxplot(y=cat_col,data= loans,x='not.fully.paid',ax=axes[idx])\n\nprint(loans[numerical_columns].describe())\nplt.subplots_adjust(hspace=1)","db9ca5e6":"features_num = ['int.rate', 'installment', 'log.annual.inc',\n                'dti', 'fico', 'days.with.cr.line',\n                'revol.bal', 'revol.util',\n                'inq.last.6mths', 'delinq.2yrs']\ncorr_pearson = loans[features_num].corr(method='pearson')\ncorr_spearman = loans[features_num].corr(method='spearman')\n\nfig = plt.figure(figsize = (9,7))\nsns.heatmap(corr_pearson, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Pearson Correlation')\nplt.show()\n\nfig = plt.figure(figsize = (9,7))\nsns.heatmap(corr_spearman, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Spearman Correlation')\nplt.show()","5eae5d60":"cat_feats = ['purpose']","7e99f71c":"loans.iloc[:,:].hist(figsize=(15,15))\nplt.show()","d41cacd7":"final_data = pd.get_dummies(loans,columns=cat_feats,drop_first=True)","324581cf":"final_data.info()","9f452b29":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score,f1_score, roc_auc_score, roc_curve","e7fd2b5f":"X = final_data.drop('not.fully.paid',axis=1)\ny = final_data['not.fully.paid']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","d2770a5f":"from sklearn.tree import DecisionTreeClassifier\n","dc3d1cdd":"tree_clf = DecisionTreeClassifier()","6edcb43b":"tree_clf.fit(X_train,y_train)","cb69c254":"y_pred = tree_clf.predict(X_train)\nprint(\"Training Data Set Accuracy: \", accuracy_score(y_train,y_pred))\nprint(\"Training Data F1 Score \", f1_score(y_train,y_pred))\n\nprint(\"Validation Mean F1 Score: \",cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='f1_macro').mean())\nprint(\"Validation Mean Accuracy: \",cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='accuracy').mean())","1e96fe34":"training_accuracy = []\nval_accuracy = []\ntraining_f1 = []\nval_f1 = []\ntree_depths = []\n\nfor depth in range(1,20):\n    tree_clf = DecisionTreeClassifier(max_depth=depth)\n    tree_clf.fit(X_train,y_train)\n    y_training_pred = tree_clf.predict(X_train)\n\n    training_acc = accuracy_score(y_train,y_training_pred)\n    train_f1 = f1_score(y_train,y_training_pred)\n    val_mean_f1 = cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='f1_macro').mean()\n    val_mean_accuracy = cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='accuracy').mean()\n    \n    training_accuracy.append(training_acc)\n    val_accuracy.append(val_mean_accuracy)\n    training_f1.append(train_f1)\n    val_f1.append(val_mean_f1)\n    tree_depths.append(depth)\n    \n\nTuning_Max_depth = {\"Training Accuracy\": training_accuracy, \"Validation Accuracy\": val_accuracy, \"Training F1\": training_f1, \"Validation F1\":val_f1, \"Max_Depth\": tree_depths }\nTuning_Max_depth_df = pd.DataFrame.from_dict(Tuning_Max_depth)\n\nplot_df = Tuning_Max_depth_df.melt('Max_Depth',var_name='Metrics',value_name=\"Values\")\nfig,ax = plt.subplots(figsize=(15,5))\nsns.pointplot(x=\"Max_Depth\", y=\"Values\",hue=\"Metrics\", data=plot_df,ax=ax)","453250d1":"import graphviz \nfrom sklearn import tree\n\ntree_clf = tree.DecisionTreeClassifier(max_depth = 6)\ntree_clf.fit(X_train,y_train)\ndot_data = tree.export_graphviz(tree_clf,feature_names = X.columns.tolist())\ngraph = graphviz.Source(dot_data)\ngraph","ff3764e6":"training_accuracy = []\nval_accuracy = []\ntraining_f1 = []\nval_f1 = []\nmin_samples_leaf = []\nimport numpy as np\nfor samples_leaf in range(1,80,3): ### Sweeping from 1% samples to 10% samples per leaf \n    tree_clf = DecisionTreeClassifier(max_depth=6,min_samples_leaf = samples_leaf)\n    tree_clf.fit(X_train,y_train)\n    y_training_pred = tree_clf.predict(X_train)\n\n    training_acc = accuracy_score(y_train,y_training_pred)\n    train_f1 = f1_score(y_train,y_training_pred)\n    val_mean_f1 = cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='f1_macro').mean()\n    val_mean_accuracy = cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='accuracy').mean()\n    \n    training_accuracy.append(training_acc)\n    val_accuracy.append(val_mean_accuracy)\n    training_f1.append(train_f1)\n    val_f1.append(val_mean_f1)\n    min_samples_leaf.append(samples_leaf)\n    \n\nTuning_min_samples_leaf = {\"Training Accuracy\": training_accuracy, \"Validation Accuracy\": val_accuracy, \"Training F1\": training_f1, \"Validation F1\":val_f1, \"Min_Samples_leaf\": min_samples_leaf }\nTuning_min_samples_leaf_df = pd.DataFrame.from_dict(Tuning_min_samples_leaf)\n\nplot_df = Tuning_min_samples_leaf_df.melt('Min_Samples_leaf',var_name='Metrics',value_name=\"Values\")\nfig,ax = plt.subplots(figsize=(15,5))\nsns.pointplot(x=\"Min_Samples_leaf\", y=\"Values\",hue=\"Metrics\", data=plot_df,ax=ax)","73f459f0":"from matplotlib import pyplot","96e9fe0b":"tree_clf = DecisionTreeClassifier(max_depth=6,min_samples_leaf = 32)\ntree_clf.fit(X_train,y_train)\n# get importance\nimportance = tree_clf.feature_importances_\n# summarize feature importance\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nind = [x for x in range(len(importance))]\npyplot.bar(ind, importance)\npyplot.title('Decision Tree')\npyplot.xticks(ind, ('1', '2', '3', '4', '5','6','7','8','9','10','11','12','13','14','15','16','17','18'))\npyplot.xlabel('Features')\npyplot.ylabel('Importance')\npyplot.show()","bb0a2a7d":"# predict\ny_pred = tree_clf.predict(X_test)\nprint(\"Test Accuracy: \",accuracy_score(y_test,y_pred))\nprint(\"Test F1 Score: \",f1_score(y_test,y_pred))\nprint(\"Confusion Matrix on Test Data\")\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","b848cbf1":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score","bfb4ce56":"acc =[]\nf1 = []\nacc.append(accuracy_score(y_test,y_pred))\nf1.append(f1_score(y_test,y_pred))","9122fed6":"print(\"Validation Mean F1 Score: \",cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='f1_macro').mean())\nprint(\"Validation Mean Accuracy: \",cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='accuracy').mean())","4c37675a":"print(classification_report(y_test,y_pred))","cf6c8769":"print(roc_auc_score(y_test, y_pred))\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, label = \"Decision Tree\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Tree ROC Curve\")\nplt.show()","3cfb9fd1":"from sklearn.ensemble import RandomForestClassifier\n\nrf_clf = RandomForestClassifier()\nrf_clf.fit(X_train,y_train)\ny_pred = rf_clf.predict(X_train)\nprint(\"Train F1 Score \", f1_score(y_train,y_pred))\nprint(\"Train Accuracy \", accuracy_score(y_train,y_pred))\n\nprint(\"Validation Mean F1 Score: \",cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='f1_macro').mean())\nprint(\"Validation Mean Accuracy: \",cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='accuracy').mean())","f0465c5a":"training_accuracy = []\nval_accuracy = []\ntraining_f1 = []\nval_f1 = []\ntree_depths = []\n\nfor depth in range(1,20):\n    rf_clf = RandomForestClassifier(max_depth=depth)\n    rf_clf.fit(X_train,y_train)\n    y_training_pred = rf_clf.predict(X_train)\n\n    training_acc = accuracy_score(y_train,y_training_pred)\n    train_f1 = f1_score(y_train,y_training_pred)\n    val_mean_f1 = cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='f1_macro').mean()\n    val_mean_accuracy = cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='accuracy').mean()\n    \n    training_accuracy.append(training_acc)\n    val_accuracy.append(val_mean_accuracy)\n    training_f1.append(train_f1)\n    val_f1.append(val_mean_f1)\n    tree_depths.append(depth)\n    \n\nTuning_Max_depth = {\"Training Accuracy\": training_accuracy, \"Validation Accuracy\": val_accuracy, \"Training F1\": training_f1, \"Validation F1\":val_f1, \"Max_Depth\": tree_depths }\nTuning_Max_depth_df = pd.DataFrame.from_dict(Tuning_Max_depth)\n\nplot_df = Tuning_Max_depth_df.melt('Max_Depth',var_name='Metrics',value_name=\"Values\")\nfig,ax = plt.subplots(figsize=(15,5))\nsns.pointplot(x=\"Max_Depth\", y=\"Values\",hue=\"Metrics\", data=plot_df,ax=ax)","664fdaa5":"rf_clf = RandomForestClassifier(max_depth=10)\nrf_clf.fit(X_train,y_train)\n# get importance\nimportance = rf_clf.feature_importances_\n# summarize feature importance\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nind = [x for x in range(len(importance))]\npyplot.bar(ind, importance)\npyplot.title('Random Forest')\npyplot.xticks(ind, ('1', '2', '3', '4', '5','6','7','8','9','10','11','12','13','14','15','16','17','18'))\npyplot.xlabel('Features')\npyplot.ylabel('Importance')\npyplot.show()","6c6596a0":"y_pred = rf_clf.predict(X_test)\nprint(\"Test Accuracy: \",accuracy_score(y_test,y_pred))\nprint(\"Test F1 Score: \",f1_score(y_test,y_pred))\nprint(\"Confusion Matrix on Test Data\")\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","1f30bfac":"acc.append(accuracy_score(y_test,y_pred))\nf1.append(f1_score(y_test,y_pred))","603faae8":"print(\"Validation Mean F1 Score: \",cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='f1_macro').mean())\nprint(\"Validation Mean Accuracy: \",cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='accuracy').mean())","99d45d45":"print(classification_report(y_test,y_pred))","da4060e7":"print(roc_auc_score(y_test, y_pred))\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, label = \"Random Forest\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"RF ROC Curve\")\nplt.show()","f340b4fd":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_predict","45659a18":"train_accuracies = []\ntrain_f1_scores = []\ntest_accuracies = []\ntest_f1_scores = []\nthresholds = []\n\n#for thresh in np.linspace(0.1,0.9,8): ## Sweeping from threshold of 0.1 to 0.9\nfor thresh in np.arange(0.1,0.9,0.1): ## Sweeping from threshold of 0.1 to 0.9\n    logreg_clf = LogisticRegression(solver='liblinear')\n    logreg_clf.fit(X_train,y_train)\n    \n    y_pred_train_thresh = logreg_clf.predict_proba(X_train)[:,1]\n    y_pred_train = (y_pred_train_thresh > thresh).astype(int)\n\n    train_acc = accuracy_score(y_train,y_pred_train)\n    train_f1 = f1_score(y_train,y_pred_train)\n    \n    y_pred_test_thresh = logreg_clf.predict_proba(X_test)[:,1]\n    y_pred_test = (y_pred_test_thresh > thresh).astype(int) \n    \n    test_acc = accuracy_score(y_test,y_pred_test)\n    test_f1 = f1_score(y_test,y_pred_test)\n    \n    train_accuracies.append(train_acc)\n    train_f1_scores.append(train_f1)\n    test_accuracies.append(test_acc)\n    test_f1_scores.append(test_f1)\n    thresholds.append(thresh)\n    \n    \nThreshold_logreg = {\"Training Accuracy\": train_accuracies, \"Test Accuracy\": test_accuracies, \"Training F1\": train_f1_scores, \"Test F1\":test_f1_scores, \"Decision Threshold\": thresholds }\nThreshold_logreg_df = pd.DataFrame.from_dict(Threshold_logreg)\n\nplot_df = Threshold_logreg_df.melt('Decision Threshold',var_name='Metrics',value_name=\"Values\")\nfig,ax = plt.subplots(figsize=(15,5))\nsns.pointplot(x=\"Decision Threshold\", y=\"Values\",hue=\"Metrics\", data=plot_df,ax=ax)","b9229f93":"# define the model\nlogreg_clf = LogisticRegression()\n# fit the model\nlogreg_clf.fit(X_train, y_train)\n# get importance\nimportance = logreg_clf.coef_[0]\n# summarize feature importance\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nind = [x for x in range(len(importance))]\npyplot.bar(ind, importance)\npyplot.title('Logistic Regression')\npyplot.xticks(ind, ('1', '2', '3', '4', '5','6','7','8','9','10','11','12','13','14','15','16','17','18'))\npyplot.xlabel('Features')\npyplot.ylabel('Importance')\npyplot.show()","6849ac94":"thresh = 0.2 ### Threshold chosen from above Curves\ny_pred_test_thresh = logreg_clf.predict_proba(X_test)[:,1]\ny_pred = (y_pred_test_thresh > thresh).astype(int) \nprint(\"Test Accuracy: \",accuracy_score(y_test,y_pred))\nprint(\"Test F1 Score: \",f1_score(y_test,y_pred))\nprint(\"Confusion Matrix on Test Data\")\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","2fd7d8d7":"acc.append(accuracy_score(y_test,y_pred))\nf1.append(f1_score(y_test,y_pred))","503bdaca":"print(\"Validation Mean F1 Score: \",cross_val_score(logreg_clf,X_train,y_train,cv=5,scoring='f1_macro').mean())\nprint(\"Validation Mean Accuracy: \",cross_val_score(logreg_clf,X_train,y_train,cv=5,scoring='accuracy').mean())","77549d3f":"print(classification_report(y_test,y_pred))","7ddb2f13":"print(roc_auc_score(y_test, y_pred))\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, label = \"Logistic Regression\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"LogReg ROC Curve\")\nplt.show()","a13e4b5f":"from sklearn.ensemble import GradientBoostingClassifier\nimport numpy\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom matplotlib import pyplot\nimport matplotlib\nmatplotlib.use('Agg') ","b7e136fd":"regressor = GradientBoostingClassifier()\nregressor.fit(X_train, y_train)","14837b09":"# grid search\nn_estimators = [300, 400, 500]\nlearning_rate = [0.001, 0.01, 0.1]\nparam_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators)\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\ngrid_search = GridSearchCV(regressor, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\ngrid_result = grid_search.fit(X_train, y_train)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n# plot results\nscores = numpy.array(means).reshape(len(learning_rate), len(n_estimators))\nfor i, value in enumerate(learning_rate):\n    pyplot.plot(n_estimators, scores[i], label='learning_rate: ' + str(value))\npyplot.legend()\npyplot.xlabel('n_estimators')\npyplot.ylabel('Log Loss')\npyplot.savefig('n_estimators_vs_learning_rate.png')","64994b4c":"regressor = GradientBoostingClassifier(n_estimators=500,learning_rate=0.01)\nregressor.fit(X_train, y_train)","51876f56":"# get importance\nimportance = regressor.feature_importances_\n# summarize feature importance\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nind = [x for x in range(len(importance))]\npyplot.bar(ind, importance)\npyplot.title('Gradient Boosting')\npyplot.xticks(ind, ('1', '2', '3', '4', '5','6','7','8','9','10','11','12','13','14','15','16','17','18'))\npyplot.xlabel('Features')\npyplot.ylabel('Importance')\npyplot.show()","a7bf5a8a":"y_pred = regressor.predict(X_test)\nprint(\"Test Accuracy: \",accuracy_score(y_test,y_pred))\nprint(\"Test F1 Score: \",f1_score(y_test,y_pred))\nprint(\"Confusion Matrix on Test Data\")\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","dc5f9b6a":"acc.append(accuracy_score(y_test,y_pred))\nf1.append(f1_score(y_test,y_pred))","a5ae46fb":"print(\"Validation Mean F1 Score: \",cross_val_score(regressor,X_train,y_train,cv=5,scoring='f1_macro').mean())\nprint(\"Validation Mean Accuracy: \",cross_val_score(regressor,X_train,y_train,cv=5,scoring='accuracy').mean())","22f684da":"print(classification_report(y_test,y_pred))","6f59ba89":"print(roc_auc_score(y_test, y_pred))\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, label = \"Gradient Boosting Classifier\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"GB ROC Curve\")\nplt.show()","dda81d24":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nlangs = ['TREE', 'RF', 'Logistic Reg', 'GB']\nax.bar(langs,acc)\nplt.title('ACCURACY')\nplt.show()","956682c1":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.bar(langs,f1)\nplt.title('F1-Score')\nplt.show()","9fa3c504":"# **Tuning based on threshold**","3901f6a5":"\n# **Model 3: Logistic Regression**","70a3f662":"# **Tuning 'n_estimators' and 'learning_rate' in Gradient Boosting**","c4e7e25d":"# **Visulazing Decision Tree with Max Depth = 6**","b9791875":"**Cross-validation**","a83c40ca":"**Feature importance**","0f88dba6":"**Tuning Max_Depth**","946eb440":"**Cross-Validation**","9b79d013":"**Mis-classifications**\n\nIt can be seen that majority of the misclassifications are happening on non-full paid loan applicants being classified as full paid loan.\n\nLet's look into Random Forest Classifier (and later for the other 2 methods)if it can reduce mis-classifications\n","0811ae28":"**Confusion Matrix**","cfd065ac":"Let's predict off the y_test values and evaluate our model.\n\nPredict the class of not.fully.paid for the X_test data.","e91f325d":"**Confusion Matrix**","3d666c5b":"**Let's see the trend between FICO score and interest rate. Recreate the following jointplot.**","efc0523d":"# **Model 2: Random Forest Classifier**","f01a99b4":"Create the GradientBoostingClassifier() called logreg_clf and fit it to the training data.","2d31a44d":"\nThe Plots convey the following things for our dataset. The non-full paid loans are the small portion compared to the other one in the classification for every plot.\n\nNow, let's oberve the Numerical Columns:\n","3786ff34":"## Random Forest: Predictions and Evaluation\n**Create predictions from the test set, a classification report and a confusion matrix.**","a7f7b256":"**Mis-classifications**\n\nIt can be seen that majority of the misclassifications are happening on non-full paid loan applicants being classified as full paid loan in our prediction.\n\nLet's look the Logistic regression, if it can reduce mis-classifications. \n","4ccc227a":"Based on the above Test\/Train curves, we can keep threshold to 0.2.","95d0137f":"**Confusion Matrix**","895273bc":"Overfitting Problem\n\nWe can see from above metrics that Training Accuracy > Test Accuracy with default settings of Decision Tree classifier. Hence, model is overfit. We will try some Hyper-parameter tuning and see if it helps.","d67a956e":"**ROC CURVE**","7741c363":"\n\nFor Numercical Columns, there is significant relation to non paid Loan and days.with.cr.line which is the number of days the borrower has had a credit line as well with revol.util which is the borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available). Also, we can observe similar bevahiors either the features or features-labels.\n","56949225":"**Create the following lmplots to see if the trend differed between not.fully.paid and credit.policy. Check the documentation for lmplot() if you can't figure out how to separate it into columns.**","38bfa44d":"**ROC CURVE**","143d3f11":"Let's predict off the y_test values and evaluate our model.\n\nPredict the class of not.fully.paid for the X_test data.","0937d14b":"Let's predict off the y_test values and evaluate our model.\n\nPredict the class of not.fully.paid for the X_test data.","1eee3cb4":"**Plots for categorical variables**","940dc6ed":"**Feature importance**","a4d110c7":"**Feature importance**","3476f6ce":"# Import Libraries\n\n**Import the usual libraries for pandas and plotting. You can import sklearn later on.**","72a2a4df":"Tunning the best model is challenging due to hyperparameter complex and chaotic numbers you can pick within the model. In our analysis, the results is currently relying on a couple of parameters and specific space numbers for tunning the models. However, the techniques are also implemented in predicting which customers will fully pay their loan. As more sophisticated ML, we applied different models, and we try to tune every model with a couple of parameters (max 2 parameters). Our models are poor performance, but if we compare them based on our metrics, we will have the ranks as follow:\n\n**1st Rank Accuracy          Model**\n*    85%      Random Forest Classifier\n\n**1st Rank F1-score          Model**\n*    30%     Logistic Regression\n\nBased on our results, we can conclude that Logistic regression performs better in classification. That model has lower accuracy than the other 3 models, but it has better results for predicting the non fully paid loans and the most important class.\n\n\n","2c7de62c":"**Now use pd.get_dummies(loans,columns=cat_feats,drop_first=True) to create a fixed larger dataframe that has new feature columns with dummy variables. Set this dataframe as final_data.**","0ac6b076":"## Training + Test Decision Tree, Random Forest, GradientBoostingClassifier & Logistic Regression Models\n\nLet's start by training our models!\n\n**Import DecisionTreeClassifier, RandomForestClassifier, LogisticRegression, GradientBoostingClassifier**","44bde4cb":"**Confusion Matrix**","bc48203d":"# **Tuning 'Max_Depth' and 'Min_Samples_leaf' of tree**","8908cf92":"Check for overfitting","0fad02af":"Visulazing Decision Tree with Max Depth = 6","9cf9b73e":"**Reports Precision, Recall, F1-score**","7ff96830":"## Logistic Regression: Predictions and Evaluation\n**Create predictions from the test set, a classification report and a confusion matrix.**","07c87bac":"## Gradient Boosting Classifier: Predictions and Evaluation\n**Create predictions from the test set, a classification report and a confusion matrix.**","a52199e5":"## Categorical Features\n\nNotice that the **purpose** column as categorical\n\nThat means we need to transform them using dummy variables so sklearn will be able to understand them. Let's do this in one clean step using pd.get_dummies.\n\nLet's show you a way of dealing with these columns that can be expanded to multiple categorical features if necessary.\n\n**Create a list of 1 element containing the string 'purpose'. Call this list cat_feats.**","bfb725cd":"Create the LogisticRegression() called logreg_clf and fit it to the training data.","717a4f93":"**Histograms**","e652c66a":"**Count values**","46118ef2":"**Cross-Validation**","0cc24172":"# **Model 4: Gradient Boosting Classifier**","655fe68b":"From above tree, we could see that some of the leafs have less than 5 samples hence our classifier might overfit. We can sweep hyper-parameter 'min_samples_leaf' to further improve test accuracy by keeping max_depth to 6","7f67cb97":"From above graph, we can conclude that keeping 'Max_Depth' = 6 will yield optimum Test accuracy and F1 score. The Optimum Test Accuracy is roughly 0.8 and Optimum F1 Score for validation is around 0.5","7daa26b9":"Here, we are tuning our Gradient boosting model which involves creating and adding trees to the model sequentially.\n\nNew trees are created to correct the residual errors in the predictions from the existing sequence of trees.\n\nThe effect is that the model can quickly fit, then overfit the training dataset.\n\nA technique to slow down the learning in the gradient boosting model is to apply a weighting factor for the corrections by new trees when added to the model.\n\nThis weighting is called the shrinkage factor or the learning rate, depending on the literature or the tool.\n\nThe setting values less than 1.0 for learning rate that has the effect of making less corrections for each tree added to the model and also cause the trade-off bias with the n_estimators parameter. This in turn results in more trees that must be added to the model.\n\nFor this reason, our tunning have small values in the range of 0.1 to 0.3 (as well as values less than 0.1).","2d0dc027":"The same philosophy with desicion tree ('Max_Depth' = 10).","a69393f6":"**ROC CURVE**","d4870204":"**Reports Precision, Recall, F1-score**","92092ea9":"## Predictions and Evaluation of Decision Tree\n**Create predictions from the test set, a classification report and a confusion matrix.**","9c0ba613":"# **Conclusion**","ce4fdcb3":"**Reports Precision, Recall, F1-score**","019cfd28":"**Create a countplot using seaborn showing the counts of loans by purpose, with the color hue defined by not.fully.paid.**","fe1e996b":"From above plot, we will choose Min_Samples_leaf to 32 to improve test accuracy and F1-score.","fadfa811":"## Train Test Split\n\nNow its time to split our data into a training set and a testing set!\n\n** Use sklearn to split your data into a training set and a testing set as we've done in the past.**","537a60af":"**ROC CURVE**","48f2bd5e":"Our results shows that our optimal learning rate is 0.01 and n_estimators=500","8d962102":"In the next part,we tune the logistic regression with chaning the threshold","11ac242c":"** Check out the info(), head(), and describe() methods on loans.**","6fdf1eb5":"# **Tuning 'Max_Depth' of RF**","f4e276ab":"## Get the Data\n\n** Use pandas to read loan_data.csv as a dataframe called loans.**","1af1e143":"***Correlation Pearson and Spearman***","1696f942":"Recheck for nulls","5f276f4d":"Create the RandomForestClassifier() called rf_clf and fit it to the training data.","e44683ba":"# Exploratory Data Analysis\n\nIn that part, we peform the data visualization!\n\n**Create a histogram of two FICO distributions on top of each other, one for each credit.policy outcome.**\n","becba6a5":"# **Model 1: Decision Tree Classifier**","7b1b683a":"**Plots for numerical variables**","17d0e1a7":"**Create a similar figure, except this time select by the not.fully.paid column.**","169bf14a":"**Feature importance**","48084b63":"**Mis-classifications**\n\nThis method increase the prediciton for non-full paid Loan but decrease the prediction for the full paid Loans. \nLet's look the last model Gradient Boosting Classifier, if it can reduce the mis-classifications. ","966b190d":"**Reports Precision, Recall, F1-score**","8f6db642":"Let's predict off the y_test values and evaluate our model.\n\nPredict the class of not.fully.paid for the X_test data.","bd6f7d23":"**Cross-Validation**"}}