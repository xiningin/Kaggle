{"cell_type":{"01c27e50":"code","2d85df31":"code","b38860b0":"code","39bb2d51":"code","bb7d25b3":"code","b76ed0ee":"code","4c4f55f0":"code","0b2abd74":"code","a69a0874":"code","5d3a5a57":"code","ea5de843":"code","fdf5ddc2":"code","3727e7bf":"code","e8b8e91a":"code","fc0644b4":"code","2725745d":"code","6e7ac03d":"code","cc377bce":"code","e6b26a00":"code","dea95771":"code","b016e125":"code","413ca4d4":"code","4b38b9ae":"code","6c8a8574":"code","b1c5a955":"code","6d8886f6":"code","742908ba":"code","64010b76":"code","709f6908":"code","ac2dbb69":"code","10aedc64":"code","26e9d36d":"code","f847b1ac":"code","0c56f09f":"code","11fd282a":"code","fe4643b3":"code","b0763256":"code","8489550f":"code","297786f1":"markdown","487a796a":"markdown","dd023707":"markdown","843d33b3":"markdown","3d06b1f0":"markdown","76254006":"markdown","6b1f9ff3":"markdown","52a3614d":"markdown","46c1350b":"markdown","7d261b6e":"markdown","9d46a729":"markdown","3dfd6f74":"markdown"},"source":{"01c27e50":"!git clone https:\/\/github.com\/siddharthchaini\/gpvae-raw.git","2d85df31":"!mv -v .\/gpvae-raw\/* .\/","b38860b0":"!rm -rf gpvae-raw\n!rm gpvaeraw.ipynb","39bb2d51":"!wget https:\/\/github.com\/siddharthchaini\/centering-time-series-plasticc\/raw\/main\/np_arrays\/X.npy\n!wget https:\/\/github.com\/siddharthchaini\/centering-time-series-plasticc\/raw\/main\/np_arrays\/y.npy\n!wget https:\/\/github.com\/siddharthchaini\/centering-time-series-plasticc\/raw\/main\/np_arrays\/objlist.npy","bb7d25b3":"import sys\nimport os\nimport time\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nmatplotlib.use(\"Agg\")\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\n\ntf.compat.v1.enable_eager_execution()\n\nfrom sklearn.metrics import average_precision_score, roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","b76ed0ee":"from lib.models import *","4c4f55f0":"latent_dim = 30 # 'Dimensionality of the latent space'\nencoder_sizes = [128, 128] # 'Layer sizes of the encoder'\ndecoder_sizes = [256, 256] # 'Layer sizes of the decoder'\nwindow_size = 24 # 'Window size for the inference CNN: Ignored if model_type is not gp-vae'\nsigma = 1.005 # 'Sigma value for the GP prior: Ignored if model_type is not gp-vae'\nlength_scale = 7.0 # 'Length scale value for the GP prior: Ignored if model_type is not gp-vae'\nbeta = 0.2 # 'Factor to weigh the KL term (similar to beta-VAE'\nnum_epochs = 40 # 'Number of training epochs'\n\n# Flags with common default values for all three datasets\nlearning_rate = 1e-3 # 'Learning rate for training'\ngradient_clip = 1e4 # 'Maximum global gradient norm for the gradient clipping during training'\nnum_steps = 0 # 'Number of training steps: If non-zero it overwrites num_epochs'\nprint_interval = 0 # 'Interval for printing the loss and saving the model during training'\nexp_name = \"plasticc_gpvae_raw\" # 'Name of the experiment'\nbasedir = \"models\" # 'Directory where the models should be stored'\ndata_dir = \"\" # 'Directory from where the data should be read in'\ndata_type = 'physionet' # ['hmnist', 'physionet', 'sprites'], 'Type of data to be trained on'\nseed = 1337 # 'Seed for the random number generator'\nmodel_type = 'gp-vae' # ['vae', 'hi-vae', 'gp-vae'], 'Type of model to be trained'\ncnn_kernel_size = 3 # 'Kernel size for the CNN preprocessor'\ncnn_sizes = [256] # 'Number of filters for the layers of the CNN preprocessor'\ntesting = True # 'Use the actual test set for testing'\nbanded_covar = True # 'Use a banded covariance matrix instead of a diagonal one for the output of the inference network: Ignored if model_type is not gp-vae'\nbatch_size = 64 # 'Batch size for training'\n\nM = 1 # 'Number of samples for ELBO estimation'\nK = 1 # 'Number of importance sampling weights'\n\nkernel = 'cauchy' # ['rbf', 'diffusion', 'matern', 'cauchy'], 'Kernel to be used for the GP prior: Ignored if model_type is not (mgp-vae'\nkernel_scales = 1 # 'Number of different length scales sigma for the GP prior: Ignored if model_type is not gp-vae'","0b2abd74":"np.random.seed(seed)\ntf.compat.v1.set_random_seed(seed)\nprint(\"Testing: \", testing, f\"\\t Seed: {seed}\")","a69a0874":"encoder_sizes = [int(size) for size in encoder_sizes]\ndecoder_sizes = [int(size) for size in decoder_sizes]\n\nif 0 in encoder_sizes:\n    encoder_sizes.remove(0)\nif 0 in decoder_sizes:\n    decoder_sizes.remove(0)","5d3a5a57":"# Make up full exp name\ntimestamp = datetime.now().strftime(\"%y%m%d\")\nfull_exp_name = \"{}_{}\".format(timestamp, exp_name)\noutdir = os.path.join(basedir, full_exp_name)\nif not os.path.exists(outdir): os.mkdir(outdir)\ncheckpoint_prefix = os.path.join(outdir, \"ckpt\")\nprint(\"Full exp name: \", full_exp_name)","ea5de843":"objlist = np.load(\"objlist.npy\")\nX = np.load(\"X.npy\").astype(\"float32\")\ny = np.load(\"y.npy\")\ny, label_strings = pd.factorize(y,sort=True)\ny = tf.keras.utils.to_categorical(y).astype(\"float32\")","fdf5ddc2":"x_train_full = X.copy()\nx_train_miss = x_train_full.copy()\nm_val_artificial = np.zeros_like(x_train_miss)\n\nindex_pos = np.argwhere(X==0)\n\nm_val_artificial[index_pos] = 1\n\nm_train_miss = x_train_miss.copy()\nm_train_miss = (m_train_miss == 0)","3727e7bf":"y_train = y.copy()\n\nx_val_full = x_train_full.copy()\nx_val_miss = x_train_miss.copy()\n\nm_val_miss = m_train_miss.copy()\n\ny_val = y_train.copy()","e8b8e91a":"tf_x_train_miss = tf.data.Dataset.from_tensor_slices((x_train_miss, m_train_miss))\\\n                                 .shuffle(len(x_train_miss)).batch(batch_size).repeat()\ntf_x_val_miss = tf.data.Dataset.from_tensor_slices((x_val_miss, m_val_miss)).batch(batch_size).repeat()\ntf_x_val_miss = tf.compat.v1.data.make_one_shot_iterator(tf_x_val_miss)","fc0644b4":"image_preprocessor = None","2725745d":"X.shape","6e7ac03d":"data_type","cc377bce":"data_dim = X.shape[2]\ntime_length = X.shape[1]\nnum_classes = len(label_strings)\ndecoder = GaussianDecoder","e6b26a00":"del(X,y,objlist)","dea95771":"if model_type == \"vae\":\n    model = VAE(latent_dim=latent_dim, data_dim=data_dim, time_length=time_length,\n                encoder_sizes=encoder_sizes, encoder=DiagonalEncoder,\n                decoder_sizes=decoder_sizes, decoder=decoder,\n                image_preprocessor=image_preprocessor, window_size=window_size,\n                beta=beta, M=M, K=K)\nelif model_type == \"hi-vae\":\n    model = HI_VAE(latent_dim=latent_dim, data_dim=data_dim, time_length=time_length,\n                   encoder_sizes=encoder_sizes, encoder=DiagonalEncoder,\n                   decoder_sizes=decoder_sizes, decoder=decoder,\n                   image_preprocessor=image_preprocessor, window_size=window_size,\n                   beta=beta, M=M, K=K)\nelif model_type == \"gp-vae\":\n    encoder = BandedJointEncoder if banded_covar else JointEncoder\n    model = GP_VAE(latent_dim=latent_dim, data_dim=data_dim, time_length=time_length,\n                   encoder_sizes=encoder_sizes, encoder=encoder,\n                   decoder_sizes=decoder_sizes, decoder=decoder,\n                   kernel=kernel, sigma=sigma,\n                   length_scale=length_scale, kernel_scales = kernel_scales,\n                   image_preprocessor=image_preprocessor, window_size=window_size,\n                   beta=beta, M=M, K=K, data_type=data_type)\nelse:\n    raise ValueError(\"Model type must be one of ['vae', 'hi-vae', 'gp-vae']\")","b016e125":"print(\"GPU support: \", tf.test.is_gpu_available())","413ca4d4":"print(\"Training...\")\n_ = tf.compat.v1.train.get_or_create_global_step()\ntrainable_vars = model.get_trainable_vars()\noptimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n\nprint(\"Encoder: \", model.encoder.net.summary())\nprint(\"Decoder: \", model.decoder.net.summary())","4b38b9ae":"if model.preprocessor is not None:\n    print(\"Preprocessor: \", model.preprocessor.net.summary())\n    saver = tf.compat.v1.train.Checkpoint(optimizer=optimizer, encoder=model.encoder.net,\n                                          decoder=model.decoder.net, preprocessor=model.preprocessor.net,\n                                          optimizer_step=tf.compat.v1.train.get_or_create_global_step())\nelse:\n    saver = tf.compat.v1.train.Checkpoint(optimizer=optimizer, encoder=model.encoder.net, decoder=model.decoder.net,\n                                          optimizer_step=tf.compat.v1.train.get_or_create_global_step())","6c8a8574":"summary_writer = tf.compat.v2.summary.create_file_writer(logdir=outdir, flush_millis=10000)","b1c5a955":"if num_steps == 0:\n    num_steps = num_epochs * len(x_train_miss) \/\/ batch_size\nelse:\n    num_steps = num_steps","6d8886f6":"if print_interval == 0:\n    print_interval = num_steps \/\/ num_epochs","742908ba":"losses_train = []\nlosses_val = []","64010b76":"t0 = time.time()","709f6908":"with summary_writer.as_default(), tf.compat.v2.summary.record_if(True):\n    for i, (x_seq, m_seq) in enumerate(tf_x_train_miss.take(num_steps)):\n        try:\n            with tf.GradientTape() as tape:\n                tape.watch(trainable_vars)\n                loss = model.compute_loss(x_seq, m_mask=m_seq)\n                losses_train.append(loss.numpy())\n            grads = tape.gradient(loss, trainable_vars)\n            grads = [np.nan_to_num(grad) for grad in grads]\n            grads, global_norm = tf.clip_by_global_norm(grads, gradient_clip)\n            optimizer.apply_gradients(zip(grads, trainable_vars),\n                                      global_step=tf.compat.v1.train.get_or_create_global_step())\n\n            # Print intermediate results\n            if i % print_interval == 0:\n                print(\"================================================\")\n                print(\"Learning rate: {} | Global gradient norm: {:.2f}\".format(optimizer._lr, global_norm))\n                print(\"Step {}) Time = {:2f}\".format(i, time.time() - t0))\n                loss, nll, kl = model.compute_loss(x_seq, m_mask=m_seq, return_parts=True)\n                print(\"Train loss = {:.3f} | NLL = {:.3f} | KL = {:.3f}\".format(loss, nll, kl))\n\n                saver.save(checkpoint_prefix)\n                tf.compat.v2.summary.scalar(name=\"loss_train\", data=loss, step=tf.compat.v1.train.get_or_create_global_step())\n                tf.compat.v2.summary.scalar(name=\"kl_train\", data=kl, step=tf.compat.v1.train.get_or_create_global_step())\n                tf.compat.v2.summary.scalar(name=\"nll_train\", data=nll, step=tf.compat.v1.train.get_or_create_global_step())\n\n                # Validation loss\n                x_val_batch, m_val_batch = tf_x_val_miss.get_next()\n                val_loss, val_nll, val_kl = model.compute_loss(x_val_batch, m_mask=m_val_batch, return_parts=True)\n                losses_val.append(val_loss.numpy())\n                print(\"Validation loss = {:.3f} | NLL = {:.3f} | KL = {:.3f}\".format(val_loss, val_nll, val_kl))\n\n                tf.compat.v2.summary.scalar(name=\"loss_val\", data=val_loss, step=tf.compat.v1.train.get_or_create_global_step())\n                tf.compat.v2.summary.scalar(name=\"kl_val\", data=val_kl, step=tf.compat.v1.train.get_or_create_global_step())\n                tf.compat.v2.summary.scalar(name=\"nll_val\", data=val_nll, step=tf.compat.v1.train.get_or_create_global_step())\n\n                if data_type in [\"hmnist\", \"sprites\"]:\n                    # Draw reconstructed images\n                    x_hat = model.decode(model.encode(x_seq).sample()).mean()\n                    tf.compat.v2.summary.image(name=\"input_train\", data=tf.reshape(x_seq, [-1]+list(img_shape)), step=tf.compat.v1.train.get_or_create_global_step())\n                    tf.compat.v2.summary.image(name=\"reconstruction_train\", data=tf.reshape(x_hat, [-1]+list(img_shape)), step=tf.compat.v1.train.get_or_create_global_step())\n                elif data_type == 'physionet':\n                    # Eval MSE and AUROC on entire val set\n                    x_val_miss_batches = np.array_split(x_val_miss, batch_size, axis=0)\n                    x_val_full_batches = np.array_split(x_val_full, batch_size, axis=0)\n                    m_val_artificial_batches = np.array_split(m_val_artificial, batch_size, axis=0)\n                    get_val_batches = lambda: zip(x_val_miss_batches, x_val_full_batches, m_val_artificial_batches)\n\n                    n_missings = m_val_artificial.sum()\n                    mse_miss = np.sum([model.compute_mse(x, y=y, m_mask=m).numpy()\n                                       for x, y, m in get_val_batches()]) \/ n_missings\n\n                    x_val_imputed = np.vstack([model.decode(model.encode(x_batch).mean()).mean().numpy()\n                                               for x_batch in x_val_miss_batches])\n                    x_val_imputed[m_val_miss == 0] = x_val_miss[m_val_miss == 0]  # impute gt observed values\n\n                    x_val_imputed = x_val_imputed.reshape([-1, time_length * data_dim])\n                    val_split = len(x_val_imputed) \/\/ 2\n                    cls_model = LogisticRegression(solver='liblinear', tol=1e-10, max_iter=10000)\n                    cls_model.fit(x_val_imputed[:val_split], y_val.argmax(axis=1)[:val_split])\n                    probs = cls_model.predict_proba(x_val_imputed[val_split:])[:, 1]\n                    auroc = roc_auc_score(y_val[val_split:], probs.reshape(-1,1),multi_class='ovo')\n                    print(\"MSE miss: {:.4f} | AUROC: {:.4f}\".format(mse_miss, auroc))\n\n                    # Update learning rate (used only for physionet with decay=0.5)\n                    if i > 0 and i % (10*print_interval) == 0:\n                        optimizer._lr = max(0.5 * optimizer._lr, 0.1 * learning_rate)\n                t0 = time.time()\n        except KeyboardInterrupt as e:\n            print(\"KeyboardInterrupt\")\n            saver.save(checkpoint_prefix)\n#             if debug:\n#                 import ipdb\n#                 ipdb.set_trace()\n            break","ac2dbb69":"# Split data on batches\nx_val_miss_batches = np.array_split(x_val_miss, batch_size, axis=0)\nx_val_full_batches = np.array_split(x_val_full, batch_size, axis=0)","10aedc64":"if data_type == 'physionet':\n    m_val_batches = np.array_split(m_val_artificial, batch_size, axis=0)\nelse:\n    m_val_batches = np.array_split(m_val_miss, batch_size, axis=0)","26e9d36d":"get_val_batches = lambda: zip(x_val_miss_batches, x_val_full_batches, m_val_batches)","f847b1ac":"# Compute NLL and MSE on missing values\nn_missings = m_val_artificial.sum() if data_type == 'physionet' else m_val_miss.sum()\nnll_miss = np.sum([model.compute_nll(x, y=y, m_mask=m).numpy()\n                   for x, y, m in get_val_batches()]) \/ n_missings\nmse_miss = np.sum([model.compute_mse(x, y=y, m_mask=m, binary=data_type==\"hmnist\").numpy()\n                   for x, y, m in get_val_batches()]) \/ n_missings","0c56f09f":"print(\"NLL miss: {:.4f}\".format(nll_miss))\nprint(\"MSE miss: {:.4f}\".format(mse_miss))","11fd282a":"# Save imputed values\nz_mean = [model.encode(x_batch).mean().numpy() for x_batch in x_val_miss_batches]\nnp.save(os.path.join(outdir, \"z_mean\"), np.vstack(z_mean))\nx_val_imputed = np.vstack([model.decode(z_batch).mean().numpy() for z_batch in z_mean])\nnp.save(os.path.join(outdir, \"imputed_no_gt\"), x_val_imputed)","fe4643b3":"# impute gt observed values\nx_val_imputed[m_val_miss == 0] = x_val_miss[m_val_miss == 0]\nnp.save(os.path.join(outdir, \"imputed\"), x_val_imputed)","b0763256":"if data_type == \"hmnist\":\n    # AUROC evaluation using Logistic Regression\n    x_val_imputed = np.round(x_val_imputed)\n    x_val_imputed = x_val_imputed.reshape([-1, time_length * data_dim])\n\n    cls_model = LogisticRegression(solver='lbfgs', multi_class='multinomial', tol=1e-10, max_iter=10000)\n    val_split = len(x_val_imputed) \/\/ 2\n\n    cls_model.fit(x_val_imputed[:val_split], y_val[:val_split])\n    probs = cls_model.predict_proba(x_val_imputed[val_split:])\n\n    auprc = average_precision_score(np.eye(num_classes)[y_val[val_split:]], probs)\n    auroc = roc_auc_score(np.eye(num_classes)[y_val[val_split:]], probs)\n    print(\"AUROC: {:.4f}\".format(auroc))\n    print(\"AUPRC: {:.4f}\".format(auprc))\n\nelif data_type == \"sprites\":\n    auroc, auprc = 0, 0\n\nelif data_type == \"physionet\":\n    # Uncomment to preserve some z_samples and their reconstructions\n    # for i in range(5):\n    #     z_sample = [model.encode(x_batch).sample().numpy() for x_batch in x_val_miss_batches]\n    #     np.save(os.path.join(outdir, \"z_sample_{}\".format(i)), np.vstack(z_sample))\n    #     x_val_imputed_sample = np.vstack([model.decode(z_batch).mean().numpy() for z_batch in z_sample])\n    #     np.save(os.path.join(outdir, \"imputed_sample_{}_no_gt\".format(i)), x_val_imputed_sample)\n    #     x_val_imputed_sample[m_val_miss == 0] = x_val_miss[m_val_miss == 0]\n    #     np.save(os.path.join(outdir, \"imputed_sample_{}\".format(i)), x_val_imputed_sample)\n\n    # AUROC evaluation using Logistic Regression\n    x_val_imputed = x_val_imputed.reshape([-1, time_length * data_dim])\n    val_split = len(x_val_imputed) \/\/ 2\n    cls_model = LogisticRegression(solver='liblinear', tol=1e-10, max_iter=10000)\n    cls_model.fit(x_val_imputed[:val_split], y_val.argmax(axis=1)[:val_split])\n    probs = cls_model.predict_proba(x_val_imputed[val_split:])[:, 1]\n    auprc = average_precision_score(y_val[val_split:], probs.reshape(-1,1))\n    auroc = roc_auc_score(y_val[val_split:], probs.reshape(-1,1),multi_class='ovo')\n\n    print(\"AUROC: {:.4f}\".format(auroc))\n    print(\"AUPRC: {:.4f}\".format(auprc))","8489550f":"# Visualize reconstructions\nif data_type in [\"hmnist\", \"sprites\"]:\n    img_index = 0\n    if data_type == \"hmnist\":\n        img_shape = (28, 28)\n        cmap = \"gray\"\n    elif data_type == \"sprites\":\n        img_shape = (64, 64, 3)\n        cmap = None\n\n    fig, axes = plt.subplots(nrows=3, ncols=x_val_miss.shape[1], figsize=(2*x_val_miss.shape[1], 6))\n\n    x_hat = model.decode(model.encode(x_val_miss[img_index: img_index+1]).mean()).mean().numpy()\n    seqs = [x_val_miss[img_index:img_index+1], x_hat, x_val_full[img_index:img_index+1]]\n\n    for axs, seq in zip(axes, seqs):\n        for ax, img in zip(axs, seq[0]):\n            ax.imshow(img.reshape(img_shape), cmap=cmap)\n            ax.axis('off')\n\n    suptitle = model_type + f\" reconstruction, NLL missing = {mse_miss}\"\n    fig.suptitle(suptitle, size=18)\n    fig.savefig(os.path.join(outdir, data_type + \"_reconstruction.pdf\"))\n\nresults_all = [seed, model_type, data_type, kernel, beta, latent_dim,\n               num_epochs, batch_size, learning_rate, window_size,\n               kernel_scales, sigma, length_scale,\n               len(encoder_sizes), encoder_sizes[0] if len(encoder_sizes) > 0 else 0,\n               len(decoder_sizes), decoder_sizes[0] if len(decoder_sizes) > 0 else 0,\n               cnn_kernel_size, cnn_sizes,\n               nll_miss, mse_miss, losses_train[-1], losses_val[-1], auprc, auroc, testing, data_dir]\n\nwith open(os.path.join(outdir, \"results.tsv\"), \"w\") as outfile:\n    outfile.write(\"seed\\tmodel\\tdata\\tkernel\\tbeta\\tz_size\\tnum_epochs\"\n                  \"\\tbatch_size\\tlearning_rate\\twindow_size\\tkernel_scales\\t\"\n                  \"sigma\\tlength_scale\\tencoder_depth\\tencoder_width\\t\"\n                  \"decoder_depth\\tdecoder_width\\tcnn_kernel_size\\t\"\n                  \"cnn_sizes\\tNLL\\tMSE\\tlast_train_loss\\tlast_val_loss\\tAUPRC\\tAUROC\\ttesting\\tdata_dir\\n\")\n    outfile.write(\"\\t\".join(map(str, results_all)))\n\nwith open(os.path.join(outdir, \"training_curve.tsv\"), \"w\") as outfile:\n    outfile.write(\"\\t\".join(map(str, losses_train)))\n    outfile.write(\"\\n\")\n    outfile.write(\"\\t\".join(map(str, losses_val)))\n\nprint(\"Training finished.\")","297786f1":"### Load data","487a796a":"### Build Model","dd023707":"- https:\/\/www.kaggle.com\/siddharthchaini\/gp-vae-intro\n- https:\/\/github.com\/siddharthchaini\/GP-VAE\/blob\/master\/train.py","843d33b3":"### Training","3d06b1f0":"### Prep","76254006":"### Get Custom PLAsTiCC data\nhttps:\/\/github.com\/siddharthchaini\/centering-time-series-plasticc","6b1f9ff3":"### Evaluation","52a3614d":"### Training preparation","46c1350b":"### Flags","7d261b6e":"## Kaggle stuff","9d46a729":"### Imports","3dfd6f74":"### Define data specific parameters"}}