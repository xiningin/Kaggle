{"cell_type":{"71b389ac":"code","63c1b5f8":"code","17e12a6c":"code","97b5658b":"code","7041a11e":"code","9976e67f":"code","3f59db12":"code","c0c24ac6":"code","b91ecdeb":"code","f7737ae4":"markdown","8b061c5e":"markdown"},"source":{"71b389ac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","63c1b5f8":"from pathlib import Path\nfrom torch.utils.data import Dataset, DataLoader, sampler\nfrom PIL import Image\nimport torch\nimport matplotlib.pyplot as plt\nimport time","17e12a6c":"class CloudDataset(Dataset):\n    def __init__(self, r_dir, g_dir, b_dir, nir_dir, gt_dir, pytorch=True):\n        super().__init__()\n        \n        # Loop through the files in red folder and combine, into a dictionary, the other bands\n        self.files = [self.combine_files(f, g_dir, b_dir, nir_dir, gt_dir) for f in r_dir.iterdir() if not f.is_dir()]\n        self.pytorch = pytorch\n        \n    def combine_files(self, r_file: Path, g_dir, b_dir,nir_dir, gt_dir):\n        \n        files = {'red': r_file, \n                 'green':g_dir\/r_file.name.replace('red', 'green'),\n                 'blue': b_dir\/r_file.name.replace('red', 'blue'), \n                 'nir': nir_dir\/r_file.name.replace('red', 'nir'),\n                 'gt': gt_dir\/r_file.name.replace('red', 'gt')}\n\n        return files\n                                       \n    def __len__(self):\n        \n        return len(self.files)\n     \n    def open_as_array(self, idx, invert=False, include_nir=False):\n\n        raw_rgb = np.stack([np.array(Image.open(self.files[idx]['red'])),\n                            np.array(Image.open(self.files[idx]['green'])),\n                            np.array(Image.open(self.files[idx]['blue'])),\n                           ], axis=2)\n    \n        if include_nir:\n            nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), 2)\n            raw_rgb = np.concatenate([raw_rgb, nir], axis=2)\n    \n        if invert:\n            raw_rgb = raw_rgb.transpose((2,0,1))\n    \n        # normalize\n        return (raw_rgb \/ np.iinfo(raw_rgb.dtype).max)\n    \n\n    def open_mask(self, idx, add_dims=False):\n        \n        raw_mask = np.array(Image.open(self.files[idx]['gt']))\n        raw_mask = np.where(raw_mask==255, 1, 0)\n        \n        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n    \n    def __getitem__(self, idx):\n        \n        x = torch.tensor(self.open_as_array(idx, invert=self.pytorch, include_nir=True), dtype=torch.float32)\n        y = torch.tensor(self.open_mask(idx, add_dims=False), dtype=torch.torch.int64)\n        \n        return x, y\n    \n    def open_as_pil(self, idx):\n        \n        arr = 256*self.open_as_array(idx)\n        \n        return Image.fromarray(arr.astype(np.uint8), 'RGB')\n    \n    def __repr__(self):\n        s = 'Dataset class with {} files'.format(self.__len__())\n\n        return s","97b5658b":"base_path = Path('..\/input\/38cloud-cloud-segmentation-in-satellite-images\/38-Cloud_training')\ndata = CloudDataset(base_path\/'train_red', \n                    base_path\/'train_green', \n                    base_path\/'train_blue', \n                    base_path\/'train_nir',\n                    base_path\/'train_gt')\nlen(data)","7041a11e":"x, y = data[1000]\nx.shape, y.shape","9976e67f":"fig, ax = plt.subplots(1,2, figsize=(10,9))\nax[0].imshow(data.open_as_array(150))\nax[1].imshow(data.open_mask(150))","3f59db12":"train_ds, valid_ds = torch.utils.data.random_split(data, (6000, 2400))","c0c24ac6":"train_dl = DataLoader(train_ds, batch_size=12, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=12, shuffle=True)","b91ecdeb":"xb, yb = next(iter(train_dl))\nxb.shape, yb.shape","f7737ae4":"## Creating the dataset","8b061c5e":"# The objective of this notebook is to create a custom PyTorch's Dataset (and Dataloader) to handle the multiband images\n- The train set will be splitted into train and validation sets.\n- More information full explanation can can be found on the medium article https:\/\/medium.com\/@cordmaur\/how-to-create-a-custom-dataset-loader-in-pytorch-from-scratch-for-multi-band-satellite-images-c5924e908edf"}}