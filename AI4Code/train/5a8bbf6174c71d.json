{"cell_type":{"9b62465d":"code","c816c90f":"code","810cf5e8":"code","ea20bbbe":"code","9c4b1941":"code","4e75a821":"code","a9b9c624":"code","1ccefc49":"code","af87d9c3":"code","87359d0e":"code","bb3ba69a":"markdown","ba7cb2b7":"markdown","7f686eed":"markdown","d7189d17":"markdown","d1390951":"markdown","59790f2b":"markdown","c52593a5":"markdown","01c08e9d":"markdown","72a935c1":"markdown"},"source":{"9b62465d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c816c90f":"# Singular-value decomposition\nfrom numpy import array\nfrom scipy.linalg import svd\n# define a matrix\nA = array([[1, 2], [3, 4], [5, 6]])\nprint(A)\n# remember m = 3 and n = 2 \n# SVD\nU, s, VT = svd(A)\nprint(U)  # U should 3 x 3\nprint(s)  \nprint(VT) # V should be 2 x 2","810cf5e8":"%%time\n# Singular-value decomposition\nfrom numpy import array\nfrom scipy.linalg import svd\n# define a matrix\nA = array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(A)\n# remember m = 3 and n = 3 \n# SVD\nU, s, VT = svd(A)\nprint(U)  # U should 3 x 3\nprint(s)  \nprint(VT) # V should be 3 x 3","ea20bbbe":"\nimport numpy as np \n\nx = np.array([[1,2],[3,4]]) \ny = np.linalg.inv(x) \nprint(\"Original Matrix :\")\nprint(x) \nprint(\"Inverse Matrix :\")\nprint(y)\nprint(\"Dot product Matrix :\")\nprint((np.around(np.dot(x,y),2)))","9c4b1941":"import numpy as np\na = np.array([[1,2], [3,4]]) \nprint(a)\nprint(np.linalg.det(a))\n\n#(1*4 - 2*3) == -2\n","4e75a821":"%%time \nimport numpy as np \n\nb = np.array([[6,1,1], [4, -2, 5], [2,8,7]]) \nprint(b) \nprint(np.linalg.det(b) )\nprint(6*(-2*7 - 5*8) - 1*(4*7 - 5*2) + 1*(4*8 - -2*2)) # mathemical calculation","a9b9c624":"import numpy as np\n\nm_list = [[4, 3], [-5, 9]]\nA = np.array(m_list)\nprint(\"Matrix A :\")\nprint(A)\n\nB = np.array([20, 26])\nprint(\"Matrix B :\")\nprint(B)\n\n","1ccefc49":"inv_A = np.linalg.inv(A)\nprint(\"Inverse of Matrix A :\")\nprint(inv_A)\n\n\nX = np.linalg.inv(A).dot(B)\nprint(\"Values of x and y of the equations :\")\nprint(X)","af87d9c3":"import numpy as np\n\nA = np.array([[3, 1], [2, 2]])\nprint(\"Matrix A:\")\nprint(A)\n\nw, v = np.linalg.eig(a)\n\nprint( \"Eigen Value :\")\nprint(w)\nprint(\"Eigen Vector :\") \nprint(v)","87359d0e":"%%time\nimport numpy as np\n\n#A = np.array([[1,2,3], [4, 5,6],[7,8,9]])\nA = np.arange(1,10001)\nA = A.reshape(100,100)\nprint(\"Matrix A:\")\nprint(A)\n\nw, v = np.linalg.eig(A)\n\nprint( \"Eigen Value :\")\nprint(w)\nprint(\"Eigen Vector :\") \nprint(v)","bb3ba69a":"please note - we will get as many values of Eigen values - as many columns we have in Eigen Vector \n\nSince we have 2 columns - we get 2 values ","ba7cb2b7":"The Singular-Value Decomposition, or SVD for short, is a matrix decomposition method for reducing a matrix to its constituent parts in order to make certain subsequent matrix calculations simpler.\n\nIt is used in Image and Signal Processing - \n\nThe SVD is used widely both in the calculation of other matrix operations, such as matrix inverse, but also as a data reduction method in machine learning. SVD can also be used in least squares linear regression, image compression, and denoising data.\n\nNote : Mathematic of SVD is beyond the scope of this course , we will see the usage ","7f686eed":"Matrix Inverse \n\nWe use numpy.linalg.inv() function to calculate the inverse of a matrix. The inverse of a matrix is such that if it is multiplied by the original matrix, it results in identity matrix\n\nA * A inverse =  Identity Matrix ","d7189d17":"Determinent Calculation\n","d1390951":"****\n\n","59790f2b":"A = U . Sigma . V^T\n\nWhere A is the real m x n matrix that we wish to decompose,\n\nU is an m x m matrix, \n\nSigma (often represented by the uppercase Greek letter Sigma) is an m x n diagonal matrix return as vector,\n\nV^T is the  transpose of an n x n matrix ","c52593a5":"![](http:\/\/)Solve Linear Equations\n\nHere is an example of a system of linear equations with two unknown variables, x and y:\n\n4x  + 3y = 20\n\n-5x + 9y = 26\n\nTo solve the above system of linear equations, we need to find the values of the x and y variables.\n\nIn the matrix solution, the system of linear equations to be solved is represented in the form of matrix AX = B.\n\nX = inverse(A).B\n\n","01c08e9d":"Eigenvalues & Eigenvector\n\nIf there exists a square matrix called A, a scalar \u03bb, and a non-zero vector v, then \u03bb is the eigenvalue and v is the eigenvector if the following equation is satisfied:\n\nAv =  \u03bbv\n\nthen \u03bb is the eigenvalue ,  where as v is the eigenvector.\n\nEigenvalues & Eigenvector are famously used in Google Page rank Algorithm\n\n","72a935c1":"### Matrix Decomposition ###"}}