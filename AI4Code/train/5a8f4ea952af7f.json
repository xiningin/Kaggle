{"cell_type":{"8e018231":"code","58fcce33":"code","0e07b7f7":"code","7e997d22":"code","cf9968f1":"code","95c936ae":"code","46ad38fb":"code","9ec1202d":"code","7d619026":"code","e59c1d07":"code","01957ca9":"code","3d1309e2":"code","5fc78d44":"code","11b0b660":"code","d0c9f119":"code","e68dd661":"code","124975de":"code","0c5f2534":"code","918549de":"code","56f7b930":"code","20e1187e":"code","eef0df19":"code","4d824cd6":"code","41c2dd54":"code","32cae107":"code","f3460099":"code","2e589694":"code","60bd9c40":"code","4b1cfbf7":"code","087d6bec":"code","1f22416b":"code","6b17293d":"code","b9899146":"code","73935b29":"code","156c61a6":"code","897e6e6a":"code","a4bdc4c4":"code","1d329368":"code","92a5b25e":"code","60699be5":"code","23f5b975":"code","d8147afa":"code","65e1a5c2":"code","b759a085":"code","31a9a0d5":"code","cdccaf43":"code","70be251e":"code","32b6c6cc":"code","b39cee3b":"code","6b63ab36":"code","e2d066b5":"code","c4d00090":"markdown","4a80e04e":"markdown","a8381427":"markdown","6d669b04":"markdown","d055ebfb":"markdown","f38117c4":"markdown","297be4cf":"markdown","559fac4f":"markdown","bfa486e2":"markdown","4cfda87c":"markdown","dc59bb71":"markdown","cb58752d":"markdown","2c052297":"markdown","9b6e1ee1":"markdown","46933ce6":"markdown","01f282d0":"markdown","024c156d":"markdown","3f0f7c90":"markdown","3c7d7692":"markdown","5f2ae10e":"markdown","df76dde0":"markdown","394ca69f":"markdown","54f1b3d7":"markdown","91ec6a22":"markdown","cdb12a81":"markdown","804d8060":"markdown","9164b48d":"markdown","e6980d16":"markdown","3373f718":"markdown","8cd7f72f":"markdown","db336a43":"markdown"},"source":{"8e018231":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","58fcce33":"!pip uninstall keras --yes\n!pip install keras==2.6.0\n!pip uninstall tensorflow --yes\n!pip install tensorflow==2.6.0\nprint(\"pip installs complete\")","0e07b7f7":"from IPython.core.display import HTML\nHTML(\"<script>Jupyter.notebook.kernel.restart()<\/script>\")","7e997d22":"# Imports\nimport os\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')","cf9968f1":"print(tf.__version__)\nprint(keras.__version__)\n\n# Should be versions 2.6.0","95c936ae":"# Read Data\ndf_train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\ndf_train.name = 'Training Set'\ndf_test.name = 'Test Set'\n\ndfs = [df_train, df_test]","46ad38fb":"df_test_copy = df_test.copy()","9ec1202d":"# Concatenate df from train and test sets\ndef concat_df(train, test):\n    return pd.concat([train, test], sort=True).reset_index(drop=True)\n\n# Divides data back into train and test dfs\ndef divide_df(all_data):\n    return all_data.loc[:890], all_data.loc[891:].drop(['Survived'], axis=1)\n\ndf_all = concat_df(df_train, df_test)\ndf_all.name = 'All Set' ","7d619026":"df_all_corr = df_all.corr().abs().unstack().sort_values(ascending=False).reset_index()\ndf_all_corr.rename(columns={\"level_0\": \"Feature A\", \"level_1\": \"Feature B\", 0: 'Correlation Coefficient'}, inplace=True)\ndf_all_corr[df_all_corr['Feature A'] == 'Age']","e59c1d07":"age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n\nfor pclass in range(1, 4):\n    for sex in ['female', 'male']:\n        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\nprint('Median age of all passengers: {}'.format(df_all['Age'].median()))\n\n# Filling missing vals in Age with the medians of Sex and Pclass groups\ndf_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))","01957ca9":"df_all[df_all['Embarked'].isnull()]","3d1309e2":"df_all['Embarked'] = df_all['Embarked'].fillna('S')\ndf_all['Embarked'].value_counts()","5fc78d44":"df_all[df_all['Fare'].isnull()]","11b0b660":"med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0] # for 3rd class, single passenger\ndf_all['Fare'] = df_all['Fare'].fillna(med_fare)","d0c9f119":"df_all['Deck'] = df_all['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n\n# Passenger in the T deck is changed to A\nidx = df_all[df_all['Deck'] == 'T'].index\ndf_all.loc[idx, 'Deck'] = 'A'\n\ndf_all['Deck'] = df_all['Deck'].replace(['A', 'B', 'C'], 'ABC')\ndf_all['Deck'] = df_all['Deck'].replace(['D', 'E'], 'DE')\ndf_all['Deck'] = df_all['Deck'].replace(['F', 'G'], 'FG')\n\n# Drop Cabin feature\ndf_all.drop(['Cabin'], inplace=True, axis=1)\n\n# Display New Category Counts\ndf_all['Deck'].value_counts()","e68dd661":"# Age squared feature\ndf_all['Age_sq'] = df_all['Age']**2\n\n# Age - Fare Interaction\ndf_all['Age_Fare_Int'] = df_all['Age'] * df_all['Fare']\n\n# Family Size Feature\ndf_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1\n\n# Creating Travel Alone Feature \ndf_all['Alone'] = df_all['Family_Size'].apply(lambda s: 1 if s < 2 else 0) ","124975de":"family_dict = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\ndf_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_dict)","0c5f2534":"df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')","918549de":"# Stripping title from name feature\ndf_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n\n# Married Feature\ndf_all['Is_Married'] = 0\ndf_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1","56f7b930":"# Grouping Titles\ndf_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'Dona'],\n                                          'Miss\/Mrs\/Ms')\n\ndf_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev', 'the Countess'],\n                                          'Dr\/Military\/Noble\/Clergy\/Countess')","20e1187e":"def extract_surname(data):    \n    \n    families = []\n    \n    for i in range(len(data)):        \n        name = data.iloc[i]\n\n        if '(' in name:\n            name_no_bracket = name.split('(')[0] \n        else:\n            name_no_bracket = name\n            \n        family = name_no_bracket.split(',')[0]\n        title = name_no_bracket.split(',')[1].strip().split(' ')[0]\n        \n        for c in string.punctuation:\n            family = family.replace(c, '').strip()\n            \n        families.append(family)\n            \n    return families\n\ndf_all['Family'] = extract_surname(df_all['Name'])\ndf_train = df_all.loc[:890]\ndf_test = df_all.loc[891:]\ndfs = [df_train, df_test]","eef0df19":"drop_cols = ['Name', 'Ticket', 'PassengerId']\ndf_all.drop(columns=drop_cols, inplace=True)\n\ndf_all.head()","4d824cd6":"df_all['Embarked'] = df_all['Embarked'].astype('category')\ndf_all['Sex'] = df_all['Sex'].astype('category')\n\ndf_all['Embarked'] = df_all['Embarked'].cat.codes\ndf_all['Sex'] = df_all['Sex'].cat.codes","41c2dd54":"df_all['Family_Size_Grouped'] = df_all['Family_Size_Grouped'].astype('string')\ndf_all['Title'] = df_all['Title'].astype('string')\ndf_all['Family'] = df_all['Family'].astype('string')\ndf_all['Deck'] = df_all['Deck'].astype('string')","32cae107":"# Displaying the datatypes\ndisplay(df_all.dtypes)\n\n# converting Features from float to int\ndataframe = df_all.astype({\"Age\":'int', \"Embarked\": 'int', \"Sex\":'int', \"Age_sq\":'int',\n                           \"Age_Fare_Int\":'int'})\n\n# displaying the datatypes\ndisplay(dataframe.dtypes)","f3460099":"# Split test and training data\ndataframe, df_test = divide_df(dataframe)","2e589694":"val_dataframe = dataframe.sample(frac=0.2, random_state=10)\ntrain_dataframe = dataframe.drop(val_dataframe.index)\n\nprint(\n    \"Using %d samples for training and %d for validation\"\n    % (len(train_dataframe), len(val_dataframe))\n)","60bd9c40":"def dataframe_to_dataset(dataframe):\n    dataframe = dataframe.copy()\n    labels = dataframe.pop(\"Survived\")\n    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n    ds = ds.shuffle(buffer_size=len(dataframe))\n    return ds\n\n\ntrain_ds = dataframe_to_dataset(train_dataframe)\nval_ds = dataframe_to_dataset(val_dataframe)","4b1cfbf7":"train_ds = train_ds.batch(32)\nval_ds = val_ds.batch(32)","087d6bec":"### You may experience issues running the following lines of code ###\n### This could be due to the default keras and tensorflow versions installed in Kaggle ###\n### If you experience issues, See the beginning of the workbook for instructions on installing proper versions (2.6.0) ###","1f22416b":"from tensorflow.keras.layers import IntegerLookup\nfrom tensorflow.keras.layers import Normalization\nfrom tensorflow.keras.layers import StringLookup\n\n\ndef encode_numerical_feature(feature, name, dataset):\n    # Create a Normalization layer for our feature\n    normalizer = Normalization()\n\n    # Prepare a Dataset that only yields our feature\n    feature_ds = dataset.map(lambda x, y: x[name])\n    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n\n    # Learn the statistics of the data\n    normalizer.adapt(feature_ds)\n\n    # Normalize the input feature\n    encoded_feature = normalizer(feature)\n    return encoded_feature\n\ndef encode_categorical_feature(feature, name, dataset, is_string):\n    lookup_class = StringLookup if is_string else IntegerLookup\n    # Create a lookup layer which will turn strings into integer indices\n    lookup = lookup_class(output_mode=\"binary\")\n\n    # Prepare a Dataset that only yields our feature\n    feature_ds = dataset.map(lambda x, y: x[name])\n    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n\n    # Learn the set of possible string values and assign them a fixed integer index\n    lookup.adapt(feature_ds)\n\n    # Turn the string input into integer indices\n    encoded_feature = lookup(feature)\n    return encoded_feature","6b17293d":"# allows us to create a wrapper for any callable\n# will use for Dense layers in code below \nfrom functools import partial","b9899146":"tf.keras.backend.clear_session() # Resets all keras states\ntf.random.set_seed(45) # sets a random seed \n\n\n# Categorical features encoded as integers\nembarked = keras.Input(shape=(1,), name=\"Embarked\", dtype=\"int64\")\npclass = keras.Input(shape=(1,), name=\"Pclass\", dtype=\"int64\")\nsex = keras.Input(shape=(1,), name=\"Sex\", dtype=\"int64\")\nalone = keras.Input(shape=(1,), name=\"Alone\", dtype=\"int64\")\nis_married = keras.Input(shape=(1,), name=\"Is_Married\", dtype=\"int64\")\n\n# Categorical feature encoded as string\nfamily_size_group = keras.Input(shape=(1,), name=\"Family_Size_Grouped\", dtype=\"string\")\ntitle = keras.Input(shape=(1,), name=\"Title\", dtype=\"string\")\nfamily = keras.Input(shape=(1,), name=\"Family\", dtype=\"string\")\ndeck = keras.Input(shape=(1,), name=\"Deck\", dtype=\"string\")\n\n# Numerical features\nage = keras.Input(shape=(1,), name=\"Age\")\nfare = keras.Input(shape=(1,), name=\"Fare\")\nparch = keras.Input(shape=(1,), name=\"Parch\")\nsibsp = keras.Input(shape=(1,), name=\"SibSp\")\nage_sq = keras.Input(shape=(1,), name=\"Age_sq\")\nage_fare_int = keras.Input(shape=(1,), name=\"Age_Fare_Int\")\nfamily_size = keras.Input(shape=(1,), name=\"Family_Size\")\nticket_frequency = keras.Input(shape=(1,), name=\"Ticket_Frequency\")\n\nall_inputs = [\n    embarked,\n    pclass,\n    sex,\n    alone,\n    is_married,\n    family_size_group,\n    title,\n    family,\n    deck,\n    age,\n    fare,\n    parch,\n    sibsp,\n    age_sq,\n    age_fare_int,\n    family_size,\n    ticket_frequency\n]\n\n# Integer categorical features\nsex_encoded = encode_categorical_feature(sex, \"Sex\", train_ds, False)\nembarked_encoded = encode_categorical_feature(embarked, \"Embarked\", train_ds, False)\npclass_encoded = encode_categorical_feature(pclass, \"Pclass\", train_ds, False)\nalone_encoded = encode_categorical_feature(alone, \"Alone\", train_ds, False)\nis_married = encode_categorical_feature(is_married, \"Is_Married\", train_ds, False)\n\n# String categorical features\nfamily_size_group_encoded = encode_categorical_feature(family_size_group, \"Family_Size_Grouped\", train_ds, True)\ntitle_encoded = encode_categorical_feature(title, \"Title\", train_ds, True)\nfamily_encoded = encode_categorical_feature(family, \"Family\", train_ds, True)\ndeck_encoded = encode_categorical_feature(deck, \"Deck\", train_ds, True)\n\n# Numerical features\nage_encoded = encode_numerical_feature(age, \"Age\", train_ds)\nfare_encoded = encode_numerical_feature(fare, \"Fare\", train_ds)\nparch_encoded = encode_numerical_feature(parch, \"Parch\", train_ds)\nsibsp_encoded = encode_numerical_feature(sibsp, \"SibSp\", train_ds)\nage_sq_encoded = encode_numerical_feature(age_sq, \"Age_sq\", train_ds)\nage_fare_int_encoded = encode_numerical_feature(age_fare_int, \"Age_Fare_Int\", train_ds)\nfamily_size_int_encoded = encode_numerical_feature(family_size, \"Family_Size\", train_ds)\nticket_frequency_int_encoded = encode_numerical_feature(ticket_frequency, \"Ticket_Frequency\", train_ds)\n\nall_features = layers.concatenate(\n    [\n        sex_encoded,\n        embarked_encoded,\n        pclass_encoded,\n        alone_encoded,\n        is_married,\n        family_size_group_encoded,\n        title_encoded,\n        family_encoded,\n        deck_encoded,\n        age_encoded,\n        fare_encoded,\n        parch_encoded,\n        sibsp_encoded,\n        age_sq_encoded,\n        age_fare_int_encoded,\n        family_size_int_encoded,\n        ticket_frequency_int_encoded\n    ]\n)\n\n\n# Create thin wrapper for Dense layer\nRegularizedDense = partial(keras.layers.Dense,\n                           activation = \"relu\",\n                           kernel_regularizer = keras.regularizers.l2(0.02))\n\n# Model Structure\nx = RegularizedDense(64)(all_features)\nx = RegularizedDense(32)(x)\nx = layers.Dropout(0.25)(x)\nx = RegularizedDense(16)(x)\nx = layers.Dropout(0.25)(x)\noutput = layers.Dense(1, activation=\"sigmoid\")(x)\n\n\n# Compile Model\nmodel = keras.Model(all_inputs, output)\nmodel.compile(\"nadam\", \"binary_crossentropy\", metrics=[\"accuracy\"])","73935b29":"keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")","156c61a6":"# Early Stopping Callback\nes_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n\n# Callback to control learning rate\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.20,\n                              patience=3, min_lr=0.0009)","897e6e6a":"history = model.fit(train_ds, epochs=50, validation_data=val_ds, callbacks=[reduce_lr, es_callback])","a4bdc4c4":"model.evaluate(x = val_ds)","1d329368":"def visualize_accuracy(history, title):\n    accuracy = history.history[\"accuracy\"]\n    val_accuracy = history.history[\"val_accuracy\"]\n    epochs = range(len(accuracy))\n    plt.figure(figsize=(8,6))\n    plt.plot(epochs, accuracy, \"b\", label=\"Training accuracy\")\n    plt.plot(epochs, val_accuracy, \"r\", label=\"Validation accuracy\")\n    plt.title(title)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.show()\n\nvisualize_accuracy(history, \"Training and Validation Accuracy\")","92a5b25e":"# We'll use passenger '891' as an example below\ndf_test.head()","60699be5":"# Create a dictionary for passenger 891\nsample = {\n    \"Age\": 34,\n    \"Embarked\": 1,\n    \"Fare\": 7.8292,\n    \"Parch\": 0,\n    \"Pclass\": 3,\n    \"Sex\": 1,\n    \"SibSp\": 0,\n    \"Deck\": \"M\",\n    \"Age_sq\": 1190,\n    \"Age_Fare_Int\": 270,\n    \"Family_Size\": 1,\n    \"Alone\": 1,\n    \"Family_Size_Grouped\": \"Alone\",\n    \"Ticket_Frequency\": 1,\n    \"Title\": \"Mr\",\n    \"Is_Married\": 0,\n    \"Family\": \"Kelly\",\n}\n\n# Convert to tensor\ninput_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\npredictions = model.predict(input_dict)\n\nprint(\n    \"This person had a %.1f percent probability \"\n    \"of surviving, as evaluated by our model.\" % (100 * predictions[0][0],)\n)","23f5b975":"X_test_features_dict = {name: np.array(value) \n                         for name, value in df_test.items()}","d8147afa":"target_prob = model.predict(X_test_features_dict)\ntarget_prob[:10]","65e1a5c2":"def BinaryPredictionDF(probs):\n  prediction = []\n\n  for prob in probs: \n    if prob > 0.5:\n      prediction.append(1)\n    else:\n      prediction.append(0)\n  return(pd.DataFrame(prediction, columns = ['Survived']))","b759a085":"BinaryPredictionDF(target_prob)","31a9a0d5":"df_test.head()","cdccaf43":"submission = BinaryPredictionDF(target_prob)\nsubmission['PassengerId'] = df_test_copy['PassengerId']","70be251e":"survived = submission['Survived'].value_counts()[1]\nnot_survived = submission['Survived'].value_counts()[0]\nsurvived_per = survived \/ submission.shape[0] * 100\nnot_survived_per = not_survived \/ submission.shape[0] * 100\n\nprint('Our model predicts that {} of {} passengers survived or {:.2f}% of the test set.'.format(survived, submission.shape[0], survived_per))\nprint('Our model predicts that {} of {} passengers did not survive or {:.2f}% of the test set.'.format(not_survived, submission.shape[0], not_survived_per))\n\nplt.figure(figsize=(8, 6))\nsns.countplot(submission['Survived'])\n\nplt.xlabel('Survival', size=12, labelpad=12)\nplt.ylabel('Passenger Count', size=12, labelpad=12)\nplt.xticks((0, 1), ['Not Survived ({0:.2f}%)'.format(not_survived_per), 'Survived ({0:.2f}%)'.format(survived_per)])\nplt.tick_params(axis='x', labelsize=13)\nplt.tick_params(axis='y', labelsize=13)\n\nplt.title('Training Set Survival Distribution', size=14, y=1.05)\n\nplt.show()","32b6c6cc":"# Rearrange PassengerID and Survived Columns\ncols = list(submission)\ncols[1], cols[0] = cols[0], cols[1]\ncols","b39cee3b":"submission = submission.loc[:, cols]","6b63ab36":"submission.head(10)","e2d066b5":"# submission.to_csv(\"submission.csv\", index=False)","c4d00090":"**Fairly strong correlation between Age and Pclass features**\n- Filling missing values of Age with medians grouped by Sex and Pclass (due to high correlation between feature).\n\n*Source: [Gunes Evitan](https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial)*","4a80e04e":"- **Replacing with most common category seems like a reasonable option**","a8381427":"# **Import Data**\n\n- In this notebook I use a deep neural network in attempt to predict which passengers survived the Titanic shipwreck. \n- A link to the kaggle competition can be found here: [Titanic - Machine Learning from Disaster](https:\/\/www.kaggle.com\/c\/titanic)\n\n![](https:\/\/cdn.britannica.com\/s:690x388,c:crop\/79\/4679-050-BC127236\/Titanic.jpg)","6d669b04":"# **Prepping data for model**\n- Redefining data types in preparation for model","d055ebfb":"# **Handle Missing Values**\n\n- **Obtained a couple of the following preprocessing ideas from Kaggle user [Gunes Evitan](https:\/\/www.kaggle.com\/gunesevitan), who demonstrates some excellent work for this competition.** \n- **Be sure to check out his entire workbook on the [Titanic Competition](https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial) for some amazing insight.**","f38117c4":"## **Model Connectivity Graph**\n\n**Visualize the connectivity graph for our model**","297be4cf":"**Only two missing Emarked feature values.**","559fac4f":"**Only one record includes a missing Fare value**\n- Since this person was a 3rd class passenger, we will replace this missing value with the median fare of a single 3rd class passenger.","bfa486e2":"**The following restarts the kernel. If you had issues with the aforementioned imports:**\n- Run this after the previous line, and then import the packages below","4cfda87c":"## **Some Feature Engineering**\n\n**Feature engineering for Numerics**","dc59bb71":"**This displays the probabilities of survival for each record in the test set as evaluated by our model:**","cb58752d":"**Some housekeeping items:**\n\n- Uncomment and run the following two lines of code if `tensorflow.keras.layers.IntergerLookup`, `tensorflow.keras.layers.Normalization`, `tensorflow.keras.layers.StringLookup` do not import properly later in the workbook.","2c052297":"**Create categories from Titles**\n\n*Source: [Gunes Evitan](https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial)*","9b6e1ee1":"**There are quite a few missing values for Cabin - here we combine some into groups (although it may also be reasonable to drop this feature)**\n- Creating a Deck feature which groups Cabin ABC, DE, and FG\n- Creating an M category for missing values\n\n*Source: [Gunes Evitan](https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial)*","46933ce6":"**Extract Surnames**\n\n*Source: [Gunes Evitan](https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial)*","01f282d0":"# **Train Model**\n\n- First we create an `EarlyStopping` callback to stop training when a monitored metric has stopped improving\n- `ReduceLROnPlateau` models often benefit from reducing the learning rate once learning stagnates. The following callback monitors `'val_loss'` and if no improvement is seen for a `'patience'` number of epochs, the learning rate is reduced.","024c156d":"**Creating Family Size categorical feature**\n\n*Source: [Gunes Evitan](https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial)*","3f0f7c90":"**Generate a `tf.data.Dataset` object for each dataframe**","3c7d7692":"**Defining some helper functions to concatenate, as well as divide data, to help with preprocessing and feature engineering**","5f2ae10e":"# **Feature Preprocessing**\n\n**1. The following are categorical features encoded as integers:**\n- Embarked \n- Pclass\n- Sex\n- Alone\n- Is_Married\n\n**I will encode these features using one-hot encoding.**\n\n- I'll use **`IntegerLookup()`** which will build a lookup table for inputs and reserve an output index for unknown input values.\n- It will also allow for easy handling of out of range inputs during inference.\n\n\n**2. I also have a categorical feature encoded as a string:** \n- Family_Size_grouped, Title, Deck and Family. \n- I will create an index of all possible features and encode output using the `StringLookup()` layer.\n\n**3. Finally, the following feature are continuous numerical features:**\n\n- Age\n- Fare\n- Parch\n- SibSp\n- Age_sq\n- Age_Fare_Int\n- Family_Size\n- Ticket_Frequency\n\n**For each of these features, I will use a `Normalization()` layer to make sure the mean of each feature is 0 and its standard deviation is 1.**\n\n\n**Below, are 3 utility functions to complete this task:**\n\n*Source: [Francois Chollet](https:\/\/keras.io\/examples\/structured_data\/structured_data_classification_from_scratch\/)*","df76dde0":"**Batch the datasets**","394ca69f":"# **Sample validation set**","54f1b3d7":"# **Inference on new data**\n\n**Making a prediction on a new record by calling `model.predict()`. First we have to:**\n\n- Wrap scalars into a list so as to have a batch dimension (models only process batches of data, not single samples)\n- Call `convert_to_tensor` on each feature","91ec6a22":"**Dropping Name, Ticket, PassengerId Features, as they will not provide much useful information for modeling**","cdb12a81":"# **Plot of Predicted Survival Rates**\n\n*Source: [Gunes Evitan](https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial)*","804d8060":"# **Sources used in this workbook**\n\n- [Gunes Evitan - Titanic Advanced Feature Engineering Tutorial](https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial)\n\n- [Francois Chollet - Structured data classification from scratch](https:\/\/keras.io\/examples\/structured_data\/structured_data_classification_from_scratch\/)","9164b48d":"**Creating Ticket Frequency Feature**","e6980d16":"**Using the first record in the test set**","3373f718":"**Define a function to convert probabilities into survival class**\n- 1 = Survived\n- 0 = Not Survived","8cd7f72f":"# **Full Model**\n\n**Create and end-to-end model**","db336a43":"**Add PassengerID column to our new Dataframe for submission**"}}