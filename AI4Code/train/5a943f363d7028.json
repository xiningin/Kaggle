{"cell_type":{"42f1a10f":"code","fa0db64f":"code","f1bd2c6d":"code","bd4e2748":"code","d9744892":"code","f522d59c":"code","9ed3d39f":"code","3fd35aa5":"code","69e18253":"code","71ee5512":"code","8853d2a8":"code","beef6944":"code","5ae8efdd":"code","72d8a539":"code","e45d9ba4":"code","825d7570":"code","c1b8dc5f":"markdown","e070cd7a":"markdown","1a8b5e69":"markdown","20a20421":"markdown","a7e3b6df":"markdown","5fdb3f7a":"markdown","bb7a2883":"markdown","6f02c81f":"markdown","74700544":"markdown","0b309c35":"markdown"},"source":{"42f1a10f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fa0db64f":"import matplotlib.pyplot as plt\nimport cv2\nfrom glob import glob\nfrom PIL import Image, ImageDraw\nimport xml.etree.ElementTree as ET","f1bd2c6d":"PATH = os.path.abspath(\"..\/input\/dhakaai-dhaka-based-traffic-detection-dataset\/train\/Final Train Dataset\")\nimages_jpg = glob(os.path.join(PATH,\"*.jpg\"))\nimages_JPG = glob(os.path.join(PATH,\"*.JPG\"))\nimages_jpeg = glob(os.path.join(PATH,\"*.jpeg\"))\nimages_png = glob(os.path.join(PATH,\"*.png\"))\nimages_PNG = glob(os.path.join(PATH,\"*.PNG\"))\nimages=sorted(images_jpg+images_jpeg+images_png+images_JPG+images_PNG)","bd4e2748":"xml_files=sorted(glob(os.path.join(PATH, \"*.xml\")))","d9744892":"images.remove('\/kaggle\/input\/dhakaai-dhaka-based-traffic-detection-dataset\/train\/Final Train Dataset\/231.jpg')\nxml_files.remove('\/kaggle\/input\/dhakaai-dhaka-based-traffic-detection-dataset\/train\/Final Train Dataset\/231.xml')","f522d59c":"def proc_images(images):\n    \"\"\"\n    Returns : \n        x is an array of resized images\n        \n    \"\"\"\n\n    x = [] # images as arrays\n    \n    WIDTH = 1024\n    HEIGHT = 1024\n\n    for img in images:\n       \n        # Read and resize image\n        full_size_image = cv2.imread(img)\n        x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC))\n\n    return x","9ed3d39f":"x = proc_images(images)","3fd35aa5":"#collecting images name\nimage_ids=[]\nfor image_id in images:\n    ids=image_id.split('\/')[6].split('.')[0]\n    image_ids.append(ids)\nimage_ids[0:10]","69e18253":"# Set it up as a dataframe\ndf = pd.DataFrame()\ndf[\"image_id\"]=image_ids\ndf[\"images\"]=x\ndf.head()","71ee5512":"\nxml_df=pd.DataFrame(columns=['image_id','class','xmin','ymin','xmax','ymax'])\ndictionary={}\nfor xml_dir in xml_files:\n    \n    tree = ET.parse(xml_dir)\n    root = tree.getroot()\n\n    i=xml_dir.split('\/')[6].split('.')[0]\n    sample_annotations = []\n    for objects in root.iter('object'):\n        vehicle=objects.find('name').text\n    \n    \n\n        for neighbor in objects.iter('bndbox'):\n            xmin = int(neighbor.find('xmin').text)\n            ymin = int(neighbor.find('ymin').text)\n            xmax = int(neighbor.find('xmax').text)\n            ymax = int(neighbor.find('ymax').text)\n            \n            \n            if i in dictionary.keys():\n                dictionary[i].append([vehicle,xmin, ymin, xmax, ymax])\n                \n            \n            else:\n                dictionary[i]=[[vehicle,xmin, ymin, xmax, ymax]]\n        \n        \n        \n        xml_df.loc[objects]=[i,vehicle,xmin, ymin, xmax, ymax]\n        \n                   ","8853d2a8":"xml_df.head()","beef6944":"classes=list(xml_df['class'].unique())\nclasses","5ae8efdd":"#Display 12 train images\n\nrow = 3; col = 4;\n\nplt.figure(figsize=(15,int(15*row\/col)))\n\nfor j,img in enumerate(df['images'].loc[0:row*col-1]):\n    \n    plt.subplot(row,col,j+1)\n    plt.axis('off')\n    plt.imshow(img)\n        \nplt.show()","72d8a539":"row = 3; col = 4;\n\nplt.figure(figsize=(15,int(15*row\/col)))\n\nfor j,img in enumerate(images[0:row*col]):\n    \n    plt.subplot(row,col,j+1)\n    plt.axis('off')\n    sample_image_annotated=Image.open(img)\n    \n    img_bbox = ImageDraw.Draw(sample_image_annotated)\n    \n    keys=list(dictionary.keys())\n    for bbox in dictionary[keys[j]]:\n        img_bbox.rectangle(bbox[1:], outline=\"red\",width=3)\n        \n    plt.imshow(sample_image_annotated)","e45d9ba4":"xml_df.to_csv('train_bbox.csv',index=False)","825d7570":"#np.savez(\"train_images_arrays\", df)","c1b8dc5f":"As all the test set images are 1024 1024 size. I resized all the train images into 1024 1024 and the function returns ndarray value in range[0-255]","e070cd7a":"Display train images with bounding box","1a8b5e69":"Separating the xml files.In xml files the bounding box informations are stored","20a20421":"Creating dataframe from xml files bbox information","a7e3b6df":"saving the image dataframe in numpy array.Because of memory shortage it shows error","5fdb3f7a":"There are 21 types of vehicles in this dataset","bb7a2883":"Important Library","6f02c81f":"saving the bounding box dataframe in csv file","74700544":"In input file the 231.xml file is different from others.So i just removed both image and xml from the file","0b309c35":"separating images from input files,there are 3 types of image files, 1.jpg 2.jpeg 3.png"}}