{"cell_type":{"908a4a1f":"code","10773fd1":"code","c8422d21":"code","4a73f148":"code","ab268409":"code","9a1c64eb":"code","e4d72b2b":"code","b9a3c20e":"code","809e82d0":"code","750b4caf":"code","660044c6":"code","01423083":"code","eff8b4dc":"code","22bc387b":"code","4ffc0ac1":"markdown","cae73dd4":"markdown","477542d3":"markdown","4dc33ad0":"markdown","2c6aac12":"markdown","70249f59":"markdown","b6b97432":"markdown"},"source":{"908a4a1f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n","10773fd1":"data = pd.read_csv(\"..\/input\/mushrooms.csv\")","c8422d21":"data.head()","4a73f148":"# Structure of the data (shows 8124 rows and 23 columns)\ndata.shape","ab268409":"data.describe().T","9a1c64eb":"# Check for missing values (No Missing values present)\n\ndata.isnull().values.any()","e4d72b2b":"#Check for uniques values in for class\n\ndata['class'].unique()\n","b9a3c20e":"from sklearn.preprocessing import LabelEncoder\nlabelencoder=LabelEncoder()\nfor col in data.columns:\n    data[col] = labelencoder.fit_transform(data[col])\n \ndata.head()","809e82d0":"# Checking for unique values after labeling to integers\ndata['stalk-color-above-ring'].unique()","750b4caf":"#Check values for target variable\nprint(data.groupby('class').size())","660044c6":"#Exploratory Data analysis for target variable\n\nax = sns.boxplot(x='class', y='stalk-color-above-ring', data=data)","01423083":"#Checking for correlation (color closer to 1 means they are highly correlated)\ncorr = data.corr()\ncorr = data.corr()\nax = sns.heatmap(corr, vmin=-1, vmax=1, center=0, cmap=sns.diverging_palette(20, 220, n=200), square=True)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right');","eff8b4dc":"X = data.drop([\"class\"], axis=1)\ny = data[\"class\"]\nX = pd.get_dummies(X)\n\nle = LabelEncoder()\ny = le.fit_transform(y)","22bc387b":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n\nclf = LogisticRegression(solver=\"lbfgs\").fit(X_train,y_train)\npredicted = clf.predict(X_test)\npredicted_proba = clf.predict(X_test)\n\nprint(\"Accuracy is: \"+ str(clf.score(X_test,y_test)))\nprint(\"Recall score is: \" + str(round(recall_score(y_test, predicted),3)))\nprint(\"Precision score is: \" + str(round(precision_score(y_test, predicted),3)))\nprint(\"F1 score is: \" + str(round(f1_score(y_test, predicted),3)))\nprint(\"\\nConfusion matrix:\")\nprint(confusion_matrix(y_test, predicted))","4ffc0ac1":"**MUSHROOMS CLASSIFICATION**\nBeginners guide to steps for classification.\nSimple EDA and classification with logistic regression will be performed. Data for classification will be one-hot-encoded. Based on the analysis results features importance will be revealed. \n\nReading necesary libraries. We will use [sklearn](https:\/\/scikit-learn.org\/stable\/), [pandas](https:\/\/pandas.pydata.org\/), [numpy](http:\/\/www.numpy.org\/) and [matplotlib](https:\/\/matplotlib.org\/).","cae73dd4":"**Reading raw data from .csv file.**","477542d3":"**Glimpse of the data set.","4dc33ad0":"** Confusion matrix shows 825 (True Positive), 732(True Negative), 35 (False Positive) and 33 (False negative)\n** Accuracy is not the only determination to decide the best model, for this precision, recall or F1 score is also important.\n** Thus F1 score is the best measurent to check the model as it incorporates both precision and recall i.e F1 = 2 * (precision*recall )\/ precision + recall).\n\n#Thus F1 score of 95% is good indicator for the classification.\n","2c6aac12":"**Let's look at the description of columns along with total number of entries.**\n**Here there are 8124 rows with 23 columns.**","70249f59":"**Classification and metrics for logistic regression classifier**","b6b97432":"**Data have to be encoded for classification. One-hot-encoding with pandas_get_dummies() will be performed. \nBinary labels will be encoded using sklearn LabelEncoder() which means Label encoding is simply converting each value in a column to a number.**"}}