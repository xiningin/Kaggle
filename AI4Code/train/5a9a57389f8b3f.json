{"cell_type":{"becf5159":"code","2d731eaa":"code","e253063d":"code","9b2e14e3":"code","fdef3d91":"code","716aeb00":"code","23d21fa9":"code","f7318b39":"code","700a057f":"code","cdf9926f":"code","cb83e8cb":"code","c55dc0ec":"markdown","96b0c4e8":"markdown","b17a2d3f":"markdown","86139357":"markdown","bb8e26df":"markdown","66c33c81":"markdown","d57f1bf8":"markdown","6e266967":"markdown"},"source":{"becf5159":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import r2_score","2d731eaa":"image_dir = Path('..\/input\/age-prediction\/20-50\/20-50')","e253063d":"filepaths = pd.Series(list(image_dir.glob(r'**\/*.jpg')), name='Filepath').astype(str)\nages = pd.Series(filepaths.apply(lambda x: os.path.split(os.path.split(x)[0])[1]), name='Age').astype(np.int)\n\nimages = pd.concat([filepaths, ages], axis=1).sample(frac=1.0, random_state=1).reset_index(drop=True)","9b2e14e3":"images","fdef3d91":"# Let's only use 5000 images to speed up training time\nimage_df = images.sample(5000, random_state=1).reset_index(drop=True)\n\ntrain_df, test_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)","716aeb00":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split=0.2\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255\n)","23d21fa9":"train_df","f7318b39":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Age',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='raw',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Age',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='raw',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Age',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='raw',\n    batch_size=32,\n    shuffle=False\n)","700a057f":"inputs = tf.keras.Input(shape=(120, 120, 3))\nx = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)\nx = tf.keras.layers.MaxPool2D()(x)\nx = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\nx = tf.keras.layers.MaxPool2D()(x)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\noutputs = tf.keras.layers.Dense(1, activation='linear')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='mse'\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True\n        )\n    ]\n)","cdf9926f":"predicted_ages = np.squeeze(model.predict(test_images))\ntrue_ages = test_images.labels\n\nrmse = np.sqrt(model.evaluate(test_images, verbose=0))\nprint(\"     Test RMSE: {:.5f}\".format(rmse))\n\nr2 = r2_score(true_ages, predicted_ages)\nprint(\"Test R^2 Score: {:.5f}\".format(r2))","cb83e8cb":"null_rmse = np.sqrt(np.sum((true_ages - np.mean(true_ages))**2) \/ len(true_ages))\nprint(\"Null\/Baseline Model Test RMSE: {:.5f}\".format(null_rmse))","c55dc0ec":"# Training","96b0c4e8":"# Task for Today  \n\n***\n\n## Age Prediction From Facial Images  \n\nGiven *images of people ages 20-50*, let's try to predict the **age** of the person in a given image.\n\nWe will use a TensorFlow\/Keras CNN to make our predictions.","b17a2d3f":"# Getting Started","86139357":"# Loading Images","bb8e26df":"# Results","66c33c81":"We can see that our model is not even better than the null\/baseline model (predict mean every time)!","d57f1bf8":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/9AnCNBL8c6Q","6e266967":"# Create File DataFrame"}}