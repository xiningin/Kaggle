{"cell_type":{"307338f5":"code","1b74b2aa":"code","13d5d4b0":"code","9a23c877":"code","d11cc982":"code","05137ba4":"code","300a9cfb":"code","b6fbd570":"code","36757bbb":"code","bb599fad":"code","81dbe528":"code","21c0165b":"code","f76aa114":"code","9ce9edad":"code","babd6037":"markdown","5787042a":"markdown","d8794ac6":"markdown","acec8a6c":"markdown","17d24702":"markdown","f3f5a6a7":"markdown","91a74465":"markdown"},"source":{"307338f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1b74b2aa":"# Import TensorFlow and tf.keras\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Print TensorFlow version\nprint(tf.__version__)","13d5d4b0":"train = pd.read_csv(\"..\/input\/train.csv\")\nprint(\"train dataset shape is \", train.shape)\ntrain.head()\n","9a23c877":"# All pixel values - all rows and column 1 (pixel0) to column 785 (pixel 783)\nx_train = (train.iloc[:,1:].values).astype('float32') \n# Take a look at x_train\nx_train","d11cc982":"# Labels - all rows and column 0\ny_train = (train.iloc[:,0].values).astype('int32') \n\n# Take a look at y_train\ny_train","05137ba4":"test = pd.read_csv(\"..\/input\/test.csv\")\nprint(\"test dataset shape is \", test.shape)\ntest.head()","300a9cfb":"x_test = test.values.astype('float32')","b6fbd570":"x_test","36757bbb":"num_classes = 10\n\n# Normalize the input data\nx_train = x_train.astype('float32') \/ 255\nx_test = x_test.astype('float32') \/ 255\n\n# Reshape input data from (28, 28) to (28, 28, 1)\nw, h = 28, 28\nx_train = x_train.reshape(x_train.shape[0], w, h, 1)\nx_test = x_test.reshape(x_test.shape[0], w, h, 1)\n\n# One-hot encode the labels\ny_train = keras.utils.to_categorical(y_train, num_classes)\n\n# Take a look at the dataset shape after conversion with keras.utils.to_categorical\nprint(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)","bb599fad":"model = keras.Sequential()\n\n# Must define the input shape in the first layer of the neural network\nmodel.add(keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1))) \nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.MaxPooling2D(pool_size=2))\nmodel.add(keras.layers.Dropout(0.3))\n\nmodel.add(keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.MaxPooling2D(pool_size=2))\nmodel.add(keras.layers.Dropout(0.3))\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(128, activation='relu'))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.Dense(10, activation='softmax'))\n\n# Take a look at the model summary\nmodel.summary()","81dbe528":"model.compile(loss=keras.losses.categorical_crossentropy,\n             optimizer=keras.optimizers.Adam(),\n             metrics=['accuracy'])","21c0165b":"model.fit(x_train,\n         y_train,\n         batch_size=64,\n         epochs=5)","f76aa114":"predictions = model.predict_classes(x_test, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"mnist_tfkeras.csv\", index=False, header=True)","9ce9edad":"print(os.listdir(\"..\"))","babd6037":"**Train dataset **- split into image pixel data and labels","5787042a":"MNIST is the \"Hello World\" of computer vision. \nIn this notebook, let's classify the MNIST digits with deap learning CNN, with tf.Keras part of the TensorFlow core API.","d8794ac6":"**Load test dataset**","acec8a6c":"# Load train and test datasets","17d24702":"### Preprocess data","f3f5a6a7":"### Define the model architecture","91a74465":"**Load train dataset**"}}