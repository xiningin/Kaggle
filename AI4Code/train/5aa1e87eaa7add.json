{"cell_type":{"fe34b1e3":"code","6e4f5a11":"code","ae4a1fe8":"code","27d59b07":"code","d657ff68":"code","e6f778d9":"code","ec0362fd":"code","6bb9f32f":"code","d5b46ade":"code","b68ce535":"code","ae5d4758":"code","5d99ac92":"code","4ea4fa2a":"code","89c93933":"code","d94d57d3":"code","7526facb":"code","683c491c":"markdown"},"source":{"fe34b1e3":"import numpy as np\nimport pandas as pd\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn')\nsns.set(font_scale=1)","6e4f5a11":"random_state = 42\nnp.random.seed(random_state)\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')","ae4a1fe8":"train_X = df_train.drop(['ID_code', 'target'], axis = 1)\ntest_X = df_test.drop(['ID_code'], axis = 1)","27d59b07":"def augment(x,y,t=2):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xs.append(x1)\n\n    for i in range(t\/\/2):\n        mask = y==0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y","d657ff68":"# Scaling\nmmscale = MinMaxScaler()  \ntrain_X_scaled = mmscale.fit_transform(train_X)  \ntest_X_scaled = mmscale.transform(test_X)","e6f778d9":"# PCA\npca = PCA()  \nfactors_train = pca.fit_transform(train_X_scaled) \nfactors_test = pca.transform(test_X_scaled)","ec0362fd":"# add 200 new PCA features\npca_columns_name = [\"pca_\" + str(col) for col in range(0, 200)]\nfactors_train = pd.DataFrame(factors_train, columns = pca_columns_name)\nfactors_test = pd.DataFrame(factors_test, columns = pca_columns_name)\ntrain_pca = df_train.merge(factors_train, left_index = True, right_index = True)\ntest_pca = df_test.merge(factors_test, left_index = True, right_index = True)","6bb9f32f":"# we choose the most correlated factors with the target (>0.05 and <-0.05) and the less correlated factors with the initial vars\n\n# Correlations of factors with the target:\n# pca_2 +0,218 | pca_7 +0,113 | pca_9 +0,050 | pca_14 +0,135 | pca_19 +0,103 | pca_28 +0,070 | pca_42 +0,050\n# pca_6 -0,064 | pca_34 -0,051 | pca_39 -0,062 | pca_46 -0,055\n\n# Correlations of these pca with some vars are around 0.3 - 0.6, which is ok\n\nimportant_factors = ['pca_2', 'pca_7', 'pca_14', 'pca_19']\nvars_to_exclude = ['var_9', 'var_94', 'var_109', 'var_151']\ndf_train_columns = list(df_train.columns)\ndf_test_columns = list(df_test.columns)\ntrain_columns_with_factors = important_factors + df_train_columns\ntest_columns_with_factors = important_factors + df_test_columns\ntrain_main_pca = train_pca[train_columns_with_factors].drop(vars_to_exclude, axis = 1)\ntest_main_pca = test_pca[test_columns_with_factors].drop(vars_to_exclude, axis = 1)","d5b46ade":"df_train = train_main_pca\ndf_test = test_main_pca","b68ce535":"lgb_params = {\n    \"objective\" : \"binary\",\n    \"metric\" : \"auc\",\n    \"boosting\": 'gbdt',\n    \"max_depth\" : -1,\n    \"num_leaves\" : 13,\n    \"learning_rate\" : 0.01,\n    \"bagging_freq\": 5,\n    \"bagging_fraction\" : 0.4,\n    \"feature_fraction\" : 0.05,\n    \"min_data_in_leaf\": 80,\n    \"min_sum_heassian_in_leaf\": 10,\n    \"tree_learner\": \"serial\",\n    \"boost_from_average\": \"false\",\n    #\"lambda_l1\" : 5,\n    #\"lambda_l2\" : 5,\n    \"bagging_seed\" : random_state,\n    \"verbosity\" : 1,\n    \"seed\": random_state\n}","ae5d4758":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\noof = df_train[['ID_code', 'target']]\noof['predict'] = 0\npredictions = df_test[['ID_code']]\nval_aucs = []\nfeature_importance_df = pd.DataFrame()","5d99ac92":"features = [col for col in df_train.columns if col not in ['target', 'ID_code']]\nX_test = df_test[features].values","4ea4fa2a":"for fold, (trn_idx, val_idx) in enumerate(skf.split(df_train, df_train['target'])):\n    X_train, y_train = df_train.iloc[trn_idx][features], df_train.iloc[trn_idx]['target']\n    X_valid, y_valid = df_train.iloc[val_idx][features], df_train.iloc[val_idx]['target']\n    \n    N = 3\n    p_valid,yp = 0,0\n    for i in range(N):\n        X_t, y_t = augment(X_train.values, y_train.values)\n        X_t = pd.DataFrame(X_t)\n        X_t = X_t.add_prefix('var_')\n    \n        trn_data = lgb.Dataset(X_t, label=y_t)\n        val_data = lgb.Dataset(X_valid, label=y_valid)\n        evals_result = {}\n        lgb_clf = lgb.train(lgb_params,\n                        trn_data,\n                        100000,\n                        valid_sets = [trn_data, val_data],\n                        early_stopping_rounds=3000,\n                        verbose_eval = 500,\n                        evals_result=evals_result\n                       )\n        p_valid += lgb_clf.predict(X_valid)\n        yp += lgb_clf.predict(X_test)\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = lgb_clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    oof['predict'][val_idx] = p_valid\/N\n    val_score = roc_auc_score(y_valid, p_valid)\n    val_aucs.append(val_score)\n    \n    predictions['fold{}'.format(fold+1)] = yp\/N","89c93933":"mean_auc = np.mean(val_aucs)\nstd_auc = np.std(val_aucs)\nall_auc = roc_auc_score(oof['target'], oof['predict'])\nprint(\"Mean auc: %.9f, std: %.9f. All auc: %.9f.\" % (mean_auc, std_auc, all_auc))","d94d57d3":"cols = (feature_importance_df[[\"feature\", \"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:1000].index)\nbest_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n\nplt.figure(figsize=(14,26))\nsns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('LightGBM Features (averaged over folds)')\nplt.tight_layout()\nplt.savefig('lgbm_importances.png')","7526facb":"# submission\npredictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\npredictions.to_csv('lgb_all_predictions.csv', index=None)\nsub_df = pd.DataFrame({\"ID_code\":df_test[\"ID_code\"].values})\nsub_df[\"target\"] = predictions['target']\nsub_df.to_csv(\"lgb_submission.csv\", index=False)\noof.to_csv('lgb_oof.csv', index=False)","683c491c":"# LGB with KFolds"}}