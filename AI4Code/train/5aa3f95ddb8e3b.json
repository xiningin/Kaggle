{"cell_type":{"368f7b5e":"code","817fa47a":"code","f426e7e7":"code","650dd0e6":"code","64600e97":"code","99fb003c":"code","17fe0cb1":"code","435f0518":"code","f09db180":"code","5e180c16":"code","87a24ade":"code","2972031b":"code","7894f1ff":"code","00719dbb":"code","230635f0":"code","2503aa34":"code","f2e0823f":"code","47d5a965":"code","8847b8b8":"code","0ec66b82":"code","2016d582":"code","ec6b7968":"code","cd86fe42":"code","fd451c1a":"code","1aac9ec3":"code","2ccf853b":"code","f4529246":"code","73899568":"code","960d57c6":"code","d45812f7":"code","d00a3d4a":"code","116f9344":"code","b923f169":"code","c5b79f00":"code","9fd3b574":"code","19d53564":"code","d42882aa":"code","0007679b":"code","0d1bcaa0":"code","8c1b2a8c":"code","548fcd09":"code","e3388a4e":"code","1d022ac7":"code","9335cf4a":"code","dee81ec4":"code","bde8b6a7":"code","caf41a7a":"code","fac957be":"markdown","cdcd7531":"markdown","2e81e3be":"markdown","1d766d7e":"markdown","ff96ee82":"markdown","9ef5fb63":"markdown","60d1c74d":"markdown","851fe070":"markdown","33a464ca":"markdown","418fe97f":"markdown","6eee9cdf":"markdown","b73fa916":"markdown","80ef3ccf":"markdown","29e8f9fc":"markdown","6a84e853":"markdown","61b53688":"markdown","7dc83f9d":"markdown","4c14a5ae":"markdown","f0300ee1":"markdown","316f1376":"markdown","815da075":"markdown","7942af9a":"markdown","e2ee29e5":"markdown","cac5a12f":"markdown","9d2d242e":"markdown","e44c7fd3":"markdown","500b3a5c":"markdown","172085da":"markdown","72a942c5":"markdown","a4e8f3ed":"markdown","437f5194":"markdown","7759217e":"markdown","53726712":"markdown","cc2bbaae":"markdown"},"source":{"368f7b5e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","817fa47a":"import json\nimport os\nimport sys\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport cv2","f426e7e7":"f, axarr = plt.subplots(2,2)\nimg1 = cv2.imread('\/kaggle\/input\/iwildcam-2020-fgvc7\/train\/96b00332-21bc-11ea-a13a-137349068a90.jpg')\nimg2 = cv2.imread('\/kaggle\/input\/iwildcam-2020-fgvc7\/train\/879d74d8-21bc-11ea-a13a-137349068a90.jpg')\nimg3 = cv2.imread('\/kaggle\/input\/iwildcam-2020-fgvc7\/train\/9017f7aa-21bc-11ea-a13a-137349068a90.jpg')\nimg4 = cv2.imread('\/kaggle\/input\/iwildcam-2020-fgvc7\/train\/90d93c58-21bc-11ea-a13a-137349068a90.jpg')\naxarr[0,0].imshow(img1)\naxarr[0,1].imshow(img2)\naxarr[1,0].imshow(img3)\naxarr[1,1].imshow(img4)","650dd0e6":"f, axarr = plt.subplots(2,2)\nimg1 = cv2.imread('\/kaggle\/input\/iwildcam-2020-fgvc7\/test\/86761d58-21bc-11ea-a13a-137349068a90.jpg')\nimg2 = cv2.imread('\/kaggle\/input\/iwildcam-2020-fgvc7\/test\/86767820-21bc-11ea-a13a-137349068a90.jpg')\nimg3 = cv2.imread('\/kaggle\/input\/iwildcam-2020-fgvc7\/test\/86763c0c-21bc-11ea-a13a-137349068a90.jpg')\nimg4 = cv2.imread('\/kaggle\/input\/iwildcam-2020-fgvc7\/test\/867665c4-21bc-11ea-a13a-137349068a90.jpg')\naxarr[0,0].imshow(img1)\naxarr[0,1].imshow(img2)\naxarr[1,0].imshow(img3)\naxarr[1,1].imshow(img4)","64600e97":"with open('\/kaggle\/input\/iwildcam-2020-fgvc7\/iwildcam2020_train_annotations.json') as json_file:\n    train_annotations_json = json.load(json_file)","99fb003c":"train_annotations_json.keys()","17fe0cb1":"df_annotations = pd.DataFrame(train_annotations_json[\"annotations\"])","435f0518":"df_annotations.head()","f09db180":"data_train = df_annotations[[\"image_id\",\"category_id\"]].copy()","5e180c16":"data_train.head()","87a24ade":"for index,row in data_train.iterrows():\n    #print(row)\n    #print(index)\n    pathname = str(row['image_id'])+'.jpg'\n    data_train.loc[index,'image_id']=pathname","2972031b":"data_train.shape","7894f1ff":"# Total number of images excluding the corrupted ones\nlen(data_train.index)","00719dbb":"data_train.head()","230635f0":"data_train.tail()","2503aa34":"#data_train.image_id.astype('str')\n#data_train.category_id.astype('str')","f2e0823f":"data_train.info()","47d5a965":"data_train.to_csv(\"train.csv\", index=False)","8847b8b8":"with open(r'\/kaggle\/input\/iwildcam-2020-fgvc7\/iwildcam2020_test_information.json') as json_file:\n    test_information_json = json.load(json_file)","0ec66b82":"test_information_json.keys()","2016d582":"test_information_images = pd.DataFrame(test_information_json[\"images\"])","ec6b7968":"test_information_images.head()","cd86fe42":"data_test = test_information_images[[\"file_name\",\"id\"]].copy()","fd451c1a":"data_test.head()","1aac9ec3":"data_test.rename(columns={'id':'Id'},inplace=True)\n# Adding a new column\ndata_test['Category'] = 0 # 0 is the default value","2ccf853b":"data_test.head()","f4529246":"!git clone https:\/\/github.com\/Tessellate-Imaging\/monk_v1.git","73899568":"!cd monk_v1\/installation\/Misc && pip install -r requirements_kaggle.txt","960d57c6":"# Monk\nimport os\nimport sys\nsys.path.append(\"monk_v1\/monk\/\");","d45812f7":"#Using pytorch backend \nfrom pytorch_prototype import prototype","d00a3d4a":"gtf = prototype(verbose=1);\ngtf.Prototype(\"iWildCam2020\", \"Using_Pytorch_Backend\");","116f9344":"gtf.Default(dataset_path=\"\/kaggle\/input\/iwildcam-2020-fgvc7\/train\/\",\n            path_to_csv=\"train.csv\", # updated csv file \n            model_name=\"resnet18\", \n            freeze_base_network=False,\n            num_epochs=10); ","b923f169":"gtf.Dataset_Percent(20);","c5b79f00":"gtf.Default(dataset_path=\"\/kaggle\/input\/iwildcam-2020-fgvc7\/train\/\",\n            path_to_csv=\"\/kaggle\/working\/sampled_dataset_train.csv\", # updated csv file \n            model_name=\"resnet18\", \n            freeze_base_network=False,\n            num_epochs=1);","9fd3b574":"gtf.EDA(check_corrupt=True)","19d53564":"gtf.List_Models();","d42882aa":"!pip install pillow","0007679b":"import PIL\nprint('PIL',PIL.__version__)","0d1bcaa0":"#Start Training\ngtf.Train();\n#Read the training summary generated once you run the cell and training is completed","8c1b2a8c":"gtf = prototype(verbose=1);\ngtf.Prototype(\"iWildCam2020\", \"Using_Pytorch_Backend\", eval_infer=True);","548fcd09":"img_name = \"\/kaggle\/input\/iwildcam-2020-fgvc7\/test\/867611a0-21bc-11ea-a13a-137349068a90.jpg\";\npredictions = gtf.Infer(img_name=img_name);\n\n#Display \nfrom IPython.display import Image\nImage(filename=img_name)","e3388a4e":"img_name = \"\/kaggle\/input\/iwildcam-2020-fgvc7\/test\/8676382e-21bc-11ea-a13a-137349068a90.jpg\";\npredictions = gtf.Infer(img_name=img_name);\n\n#Display \nfrom IPython.display import Image\nImage(filename=img_name)","1d022ac7":"from tqdm import tqdm_notebook as tqdm\nfrom scipy.special import softmax\n\nfor i in tqdm(range(len(data_test))):\n    #img_name = \"\/kaggle\/input\/iwildcam-2020-fgvc7\/test\/\" + data_test[\"Id\"][i] + \".jpg\";\n    img_name = \"\/kaggle\/input\/iwildcam-2020-fgvc7\/test\/\" + data_test[\"file_name\"][i];\n    #Invoking Monk's nferencing engine inside a loop\n    prediction = gtf.Infer(img_name=img_name, return_raw=True);\n    data_test.loc[i,\"Category\"] = prediction;\n    ","9335cf4a":"data_test_new = data_test[[\"Id\",\"Category\"]].copy() # as per the format given ,the csv file must contain Id and Category\ndata_test_new.to_csv(\"submission.csv\", index=True);","dee81ec4":"! rm -r monk_v1","bde8b6a7":"! rm -r workspace","caf41a7a":"! rm pylg.log train.csv","fac957be":"#  <div id=\"MONK\">  ** [MONK](https:\/\/github.com\/Tessellate-Imaging\/monk_v1)** <\/div>","cdcd7531":"# <div id=\"installingmonk\"> **[Installing Monk](https:\/\/github.com\/Tessellate-Imaging\/monk_v1\/tree\/master\/installation)** <\/div>","2e81e3be":"* https:\/\/www.tessellateimaging.com\/\n* Abhishek - https:\/\/www.linkedin.com\/in\/abhishek-kumar-annamraju\/\n* Akash - https:\/\/www.linkedin.com\/in\/akashdeepsingh01\/","1d766d7e":"Running Inference on all test images","ff96ee82":"**Monk Features**","9ef5fb63":"*Imports*","60d1c74d":"# <div id=\"inf\"> **Running inference on test images** <\/div>","851fe070":"* low-code\n* unified wrapper over major deep learning framework - keras, pytorch, gluoncv\n* syntax invariant wrapper\n","33a464ca":"<div id=\"cme\"> Creating and managing experiments <\/div>\n- Provide project name\n- Provide experiment name\n- For a specific data create a single project\n- Inside each project multiple experiments can be created\n- Every experiment can be have diferent hyper-parameters attached to it","418fe97f":"Data Visualization","6eee9cdf":"Goals","b73fa916":"<div id=\"edaM\"> EDA in MONK <\/div>","80ef3ccf":"**Monk Enables**","29e8f9fc":"* [MONK](#MONK)\n* [Exploratory Data Analysis\/ Data Visualization](#dv)\n* [Installing Monk](#installingmonk)\n* [Importing Pytorch Backend](#pyb)\n* [Creating and Managing experiments](#cme)\n* [Quick Mode Training - Load the data and the model](#train)\n* [EDA Using Monk](#edaM)\n* [See what other models Monk's backend supports](#mod)\n* [Train the classifier](#tc)\n* [Running inference on test images](#inf)","6a84e853":"# **To contribute to Monk AI or Pytorch RoadMap repository raise an issue in the git-repo or DM us on linkedin** ","61b53688":"<div id=\"train\"> Quick mode training <\/div>\n- Using Default Function\n    - dataset_path\n    - model_name\n    - num_epochs","7dc83f9d":"1. To create, manage and version control deep learning experiments.\n2. To compare experiments across training metrics.\n3. To quickly find best hyper-parameters.\n","4c14a5ae":"# <div id=\"tc\"> Train the classifier <\/div>","f0300ee1":"# Load the data and the model","316f1376":"# **Table of Contents**","815da075":"<div id=\"mod\"> See what other models Monk's backend supports <\/div>","7942af9a":"* To use mxnet backend\n\nfrom gluon_prototype import prototype\n\n* To use keras backend\n\nfrom keras_prototype import prototype","e2ee29e5":"*Adding extension .jpg to image_id*","cac5a12f":"*Converting Json to required CSV format*","9d2d242e":"*Monk is a low code Deep Learning tool and a unified wrapper for Computer Vision.*","e44c7fd3":"Viewing 4 images in test folder","500b3a5c":"<div id=\"pyb\"> *Using Pytorch backend* <\/div>","172085da":"- To experiment with Models\n- Understand how easy is it to use Monk","72a942c5":"Load the experiment in inference mode\n- Set flag eval_infer as True","a4e8f3ed":"Docs on  quick mode loading of data and model: https:\/\/github.com\/Tessellate-Imaging\/monk_v1#4\n\nTutorials on Monk: https:\/\/github.com\/Tessellate-Imaging\/monk_v1\/tree\/master\/study_roadmaps\/1_getting_started_roadmap","437f5194":"# <div id=\"dv\"> ** Exploratory Data Analysis ** <\/div>","7759217e":"Viewing 4 images in train folder","53726712":"This creates files and directories as per the following structure\nworkspace\n\n\n    |\n    |--------iWildCam2020 (Project name can be different)\n                    |\n                    |\n                    |-----Using_Pytorch_Backend (Experiment name can be different)\n                                |\n                                |-----experiment-state.json\n                                |\n                                |-----output\n                                        |\n                                        |------logs (All training logs and graphs saved here)\n                                        |\n                                        |------models (all trained models saved here)","cc2bbaae":"Select image and Run inference"}}