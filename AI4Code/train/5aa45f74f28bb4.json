{"cell_type":{"1b696225":"code","8765dfe5":"code","f721f7e2":"code","498217c5":"code","61491e8f":"code","3d73d5be":"code","53bc57b8":"code","7471ef4b":"code","bcefc08c":"code","da4a303c":"code","3362355a":"code","bbb939c4":"code","438971f5":"code","28b32211":"code","babf177b":"code","493372c7":"code","da766984":"code","71fe66c0":"code","175fab5c":"code","ee7e6058":"code","a93493f1":"code","60a7a4e2":"code","41cb5b92":"code","d6c1f309":"code","b755e561":"code","8441a7c7":"code","29825d84":"code","1650fb5b":"code","16a53fc2":"code","d0542f38":"code","27134ca9":"code","6022a57c":"code","1ca71b0f":"code","c9dc1c53":"code","41abfcaf":"markdown","f7dab4e3":"markdown","4c1b1b74":"markdown","85e7f5c0":"markdown","506b51ef":"markdown","a42afbfe":"markdown","bca5962d":"markdown","b460818f":"markdown","1c045307":"markdown","f2df9c09":"markdown"},"source":{"1b696225":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8765dfe5":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\n\ntrain = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ngender = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","f721f7e2":"train.head()","498217c5":"train.drop([train.columns[3]], axis=1, inplace=True)\ntrain.drop([train.columns[7]], axis=1, inplace=True)","61491e8f":"train.head()","3d73d5be":"len(train)","53bc57b8":"len(train[train['Cabin'].isnull()])","7471ef4b":"train.drop([train.columns[8]], axis=1, inplace=True)\ntrain.head()","bcefc08c":"train['Embarked'].unique()","da4a303c":"train['Age'].unique()","3362355a":"train[train['Age'].isnull()].index","bbb939c4":"for i in range(len(train)):\n    age = train['Age'][i]\n    if age < 10:\n        train['Age'][i] = '0~9'\n    elif age >= 10 and age < 20:\n        train['Age'][i] = '10~19'\n    elif age >= 20 and age < 40:\n        train['Age'][i] = '20~39'\n    elif age >= 40 and age < 60:\n        train['Age'][i] = '40~59'\n    elif age >= 60:\n        train['Age'][i] = '60~'","438971f5":"import collections\n\nfor i in train[train['Age'].isnull()].index:\n    train['Age'][i] = collections.Counter(train[train['Pclass']==train['Pclass'][i]][train['Sex']==train['Sex'][i]]['Age']).most_common(1)[0][0]\nfor i in train[train['Embarked'].isnull()].index:\n    train['Embarked'][i] = collections.Counter(train[train['Pclass']==train['Pclass'][i]][train['Sex']==train['Sex'][i]]['Embarked']).most_common(1)[0][0]","28b32211":"train","babf177b":"from sklearn.preprocessing import MinMaxScaler\n\nfare_scaler = MinMaxScaler()\nfare_scaler.fit(train[['Fare']])\ntrain['Fare'] = fare_scaler.transform(train[['Fare']])","493372c7":"train.head()","da766984":"from sklearn.preprocessing import LabelEncoder\n\nsex_encoder = LabelEncoder()\nsex_encoder.fit(train[['Sex']])\ntrain['Sex'] = sex_encoder.transform(train[['Sex']])","71fe66c0":"embarked_encoder = LabelEncoder()\nembarked_encoder.fit(train[['Embarked']])\ntrain['Embarked'] = embarked_encoder.transform(train[['Embarked']])","175fab5c":"age_encoder = LabelEncoder()\nage_encoder.fit(train[['Age']])\ntrain['Age'] = age_encoder.transform(train[['Age']])","ee7e6058":"train.head()","a93493f1":"test.head()","60a7a4e2":"test.drop([test.columns[2]], axis=1, inplace=True)\ntest.drop([test.columns[6]], axis=1, inplace=True)\ntest.drop([test.columns[7]], axis=1, inplace=True)\ntest.head()","41cb5b92":"for i in range(len(test)):\n    age = test['Age'][i]\n    if age < 10:\n        test['Age'][i] = '0~9'\n    elif age >= 10 and age < 20:\n        test['Age'][i] = '10~19'\n    elif age >= 20 and age < 40:\n        test['Age'][i] = '20~39'\n    elif age >= 40 and age < 60:\n        test['Age'][i] = '40~59'\n    elif age >= 60:\n        test['Age'][i] = '60~'","d6c1f309":"import collections\n\nfor i in test[test['Age'].isnull()].index:\n    test['Age'][i] = collections.Counter(test[test['Pclass']==test['Pclass'][i]][test['Sex']==test['Sex'][i]]['Age']).most_common(1)[0][0]\nfor i in test[test['Embarked'].isnull()].index:\n    test['Embarked'][i] = collections.Counter(test[test['Pclass']==test['Pclass'][i]][test['Sex']==test['Sex'][i]]['Embarked']).most_common(1)[0][0]\nfor i in test[test['Fare'].isnull()].index:\n    test['Fare'][i] = collections.Counter(test[test['Pclass']==test['Pclass'][i]][test['Sex']==test['Sex'][i]]['Fare']).most_common(1)[0][0]","b755e561":"test['Sex'] = sex_encoder.transform(test[['Sex']])\ntest['Embarked'] = embarked_encoder.transform(test[['Embarked']])\ntest['Age'] = age_encoder.transform(test[['Age']])","8441a7c7":"data_train = train.drop([train.columns[1]], axis=1)\ntarget_train = train[train.columns[1]]\n\nfrom sklearn.model_selection import train_test_split\ndata_train, data_test, target_train, target_test = train_test_split(data_train, target_train, random_state = 42)\n\ndata_test = test\ntarget_test = gender['Survived']","29825d84":"import matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import f1_score\n\nnumNeighbors = list(range(1, 30))\ntrainF1 = []\ntestF1 = []\nfor k in numNeighbors:\n    clf = DecisionTreeClassifier(max_depth=k)\n    clf.fit(data_train, target_train)\n    Y_predTrain = clf.predict(data_train)\n    Y_predTest = clf.predict(data_test)\n    trainF1.append(f1_score(target_train, Y_predTrain, average='micro'))\n    testF1.append(f1_score(target_test, Y_predTest, average='micro'))\nplt.figure(figsize=(15, 6))\nplt.plot(numNeighbors, trainF1, 'ro-', numNeighbors, testF1, 'bv--')\nplt.legend(['Train F1', 'Test F1'])\nplt.xlabel('Number of Max_depth')\nplt.ylabel('F1 score')\nplt.show()\nprint(\"best testF1 :\", max(testF1))","1650fb5b":"from sklearn.neighbors import KNeighborsClassifier\n\nnumNeighbors = list(range(1, 30))\ntrainF1 = []\ntestF1 = []\nfor k in numNeighbors:\n    clf = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2)\n    clf.fit(data_train, target_train)\n    Y_predTrain = clf.predict(data_train)\n    Y_predTest = clf.predict(data_test)\n    trainF1.append(f1_score(target_train, Y_predTrain, average='micro'))\n    testF1.append(f1_score(target_test, Y_predTest, average='micro'))\nplt.figure(figsize=(15, 6))\nplt.plot(numNeighbors, trainF1, 'ro-', numNeighbors, testF1, 'bv--')\nplt.legend(['Train F1', 'Test F1'])\nplt.xlabel('Number of neighbors')\nplt.ylabel('F1 score')\nplt.show()\nprint(\"best testF1 :\", max(testF1))","16a53fc2":"from sklearn import ensemble\nfrom sklearn.metrics import accuracy_score\ntrainAcc = []\ntestAcc = []\n\nX_train, Y_train, X_test, Y_test = data_train, target_train, data_test, target_test","d0542f38":"numBaseClassifiers = [10, 20, 50, 100, 200, 300, 500]\ntestAcc = []\n\nfor k in numBaseClassifiers:\n    clf = ensemble.RandomForestClassifier(n_estimators=k)\n    clf.fit(data_train, target_train)\n    #Y_predTrain = clf.predict(data_train)\n    Y_predTest = clf.predict(data_test)\n    testAcc.append(accuracy_score(target_test, Y_predTest))\n\nplt.figure(figsize=(15, 6))\nplt.plot(numBaseClassifiers, testAcc, 'bv--')\nplt.xlabel('RandomForest')\nplt.ylabel('Acc score')\n\nprint(\"best : \", max(testAcc))","27134ca9":"numBaseClassifiers = [100, 200, 300, 500]\nmax_depths = [2, 3, 5, 10, 20]\ntestAcc = []\nAcc = []\n\nplt.figure(figsize=(15, 6))\nfor k in numBaseClassifiers:\n    for maxdepth in max_depths:\n        clf = ensemble.BaggingClassifier(DecisionTreeClassifier(max_depth=maxdepth), n_estimators=k)\n        clf.fit(data_train, target_train)\n        #Y_predTrain = clf.predict(data_train)\n        Y_predTest = clf.predict(data_test)\n        Acc.append(accuracy_score(target_test, Y_predTest))\n    plt.plot(max_depths, Acc)\n    testAcc.append(max(Acc))\n    Acc = []\n    \nplt.legend(numBaseClassifiers)\nplt.xlabel('max_depth')\nplt.ylabel('Acc score')\n\nprint(max(testAcc))","6022a57c":"clf = ensemble.BaggingClassifier(DecisionTreeClassifier(max_depth=500), n_estimators=3)\nclf.fit(data_train, target_train)\nY_predTest = clf.predict(data_test)\ngender['Survived'] = Y_predTest","1ca71b0f":"gender","c9dc1c53":"gender.to_csv('gender_submission.csv',index = False)","41abfcaf":"### Transform","f7dab4e3":"### Set train, test dataset","4c1b1b74":"### Fix Null Data","85e7f5c0":"### Delete 'Cabin' Column","506b51ef":"### Delete 'Name', 'Ticket' Column","a42afbfe":"### classfication","bca5962d":"### Test","b460818f":"### Fix Null data in Test dataSet","1c045307":"### MinMaxScaler","f2df9c09":"### LabelEncoder"}}