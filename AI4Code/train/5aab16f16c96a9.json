{"cell_type":{"752415b3":"code","73e07349":"code","29d50f69":"code","840c3bb7":"code","1e5da11c":"code","b0b4863f":"code","a76dfe47":"code","94fdbb25":"code","e3b75972":"code","c14d63bf":"code","36661aef":"code","0614e52b":"code","1ac7608d":"code","288a8477":"code","04a83e3c":"code","c6e7cfb1":"code","055c985f":"code","d0681387":"code","eac7715a":"code","181a9da3":"code","c15a57fb":"code","4f3ada1b":"code","8e491ccb":"markdown"},"source":{"752415b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","73e07349":"train = pd.read_csv(\"..\/input\/train.csv\", encoding=\"latin-1\")\ntrain.head()\n","29d50f69":"train[\"word_count\"]=train['SentimentText'].apply(lambda x: len(str(x).split(\" \")))\ntrain[['word_count', 'SentimentText']].head(5)","840c3bb7":"train[\"character_count\"]=train[\"SentimentText\"].str.len()\ntrain[[\"character_count\", \"SentimentText\"]].head(5)","1e5da11c":"def avg_word(sentence):\n    words=sentence.split()\n    return(sum(len(word) for word in words)\/len(words))\n\ntrain[\"word_length\"]=train[\"SentimentText\"].apply(lambda x: avg_word(x))\ntrain[[\"word_length\", \"SentimentText\"]].head()\n    ","b0b4863f":"from nltk.corpus import stopwords\nstop = stopwords.words('english')\n\ntrain[\"stop_words\"]=train[\"SentimentText\"].apply(lambda x: len([x for x in x.split() if x in stop]))\ntrain[[\"stop_words\", \"SentimentText\"]].head()\n                                                 ","a76dfe47":"train[\"hashtags\"]=train[\"SentimentText\"].apply(lambda x: len([x for x in x.split() if x.startswith(\"#\")]))\ntrain[[\"hashtags\", \"SentimentText\"]].head(10)        ","94fdbb25":"train[\"numerics\"]=train[\"SentimentText\"].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\ntrain[[\"numerics\", \"SentimentText\"]].head()","e3b75972":"train[\"upper\"]=train[\"SentimentText\"].apply(lambda x: len([x for x in x.split() if x.isupper()]))\ntrain[[\"upper\", \"SentimentText\"]].head()","c14d63bf":"train['SentimentText'] = train['SentimentText'].apply(lambda x: (\" \".join(x.lower() for x in x.split())))\ntrain['SentimentText'].head(10)\n","36661aef":"train[\"SentimentText\"]=train[\"SentimentText\"].str.replace('[^\\w\\s]', '')\ntrain[\"SentimentText\"].head(10)","0614e52b":"from nltk.corpus import stopwords\nstop=stopwords.words('english')\n\ntrain[\"SentimentText\"]=train[\"SentimentText\"].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\ntrain[\"SentimentText\"].head(10)","1ac7608d":"freq=pd.Series(' '.join(train[\"SentimentText\"]).split()).value_counts()[:20]\nfreq","288a8477":"import matplotlib.pyplot as plot\nfreq.plot(kind=\"bar\")","04a83e3c":"freq=list(freq.index)\nfreq","c6e7cfb1":"train[\"SentimentText\"]=train[\"SentimentText\"].apply(lambda x: \" \".join(x for x in x.split()if x not in freq))\ntrain[\"SentimentText\"].head(10)","055c985f":"freq=pd.Series(\" \".join(train[\"SentimentText\"]).split()).value_counts()[-10:]\nfreq","d0681387":"train[\"SentimentText\"]=train[\"SentimentText\"].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\ntrain[\"SentimentText\"].head(10)","eac7715a":"from textblob import TextBlob\ntrain[\"SentimentText\"][:5].apply(lambda x: str(TextBlob(x).correct()))","181a9da3":"TextBlob(train[\"SentimentText\"][3]).words","c15a57fb":"from textblob import Word\ntrain[\"SentimentText\"]=train[\"SentimentText\"].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\ntrain[\"SentimentText\"].head(7)","4f3ada1b":"TextBlob(train[\"SentimentText\"][1]).ngrams(2)","8e491ccb":"Here we begin with a dataset containing sample tweets for which we will preprocess the tweets. "}}