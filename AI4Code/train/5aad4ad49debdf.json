{"cell_type":{"ad1bdad3":"code","962d0eab":"code","83a2a4ac":"code","60e58787":"code","c9db8158":"code","89b25882":"code","d9a9adb6":"code","b103a69e":"code","c65957a7":"code","6df0217c":"code","3fe7b0fa":"markdown","4d95322a":"markdown","d5791ffb":"markdown","9d3f980e":"markdown","d570a5d4":"markdown","a7a97f5d":"markdown","1d2e7b84":"markdown","c7139ef9":"markdown","ac408c9c":"markdown","7ea411ad":"markdown","003ae62d":"markdown","444f75c1":"markdown"},"source":{"ad1bdad3":"# Load the libraries\nimport numpy as np # linear algebra\nfrom sklearn.datasets import load_files # used to enumerate files and output data structure for data\nimport matplotlib.pyplot as plt # common plot library matplotlib\nfrom PIL import Image # image library PIL will be used to convert images to np arrays\n\n# This is a bit of gto make matplotlib figures appear inline\n# in the notebook rather than in a new window\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (20.0, 8.0)\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n# Some more magic so that the notebook will reload external python modules;\n# see http:\/\/stackoverflow.com\/questions\/1907993\/autoreload-of-modules-in-ipython\n%load_ext autoreload\n%autoreload 2\n\n#kaggle data set location for this dataset\ntrain_dir = '\/kaggle\/input\/fruits\/fruits-360\/Training\/'\ntest_dir = '\/kaggle\/input\/fruits\/fruits-360\/Test\/'\n\n# this function loads all files and returns 3 objects with the filenames of the images\n# you can use the samples parameter to limit the number of samples for quicker testing or if you run out of memory\ndef load_dataset(path, samples):\n    data = load_files(path)\n    files = np.array(data['filenames'])\n    targets = np.array(data['target'])\n    target_labels = np.array(data['target_names'])\n    return files[:samples],targets[:samples],target_labels[:samples]\n\nx_train, y_train,target_labels = load_dataset(train_dir, 20000)\nx_test, y_test,_ = load_dataset(test_dir, 5000)\n\nprint('Training set size : ' , x_train.shape[0])\nprint('Testing set size : ', x_test.shape[0])","962d0eab":"from scipy import ndimage\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\n#function to translate our image file paths to numpy arrays of image data\ndef make_image_array(path, image_height, image_width, channels):\n    img = load_img(path)  # this is a PIL image\n    # Convert to Numpy Array\n    x = img_to_array(img)  \n    return x.reshape((image_height, image_width, channels))","83a2a4ac":"#load all images as arrays\nimage_width = 100\nimage_height = 100\nchannels = 3\n#predefine our array space with the correct shape for efficiency\ntrainImages = np.ndarray(shape=(len(x_train), image_height, image_width, channels),\n                     dtype=np.float32)\n\n#loop through and call our function\ni = 0\nfor _trainFile in x_train:\n    trainImages[i] = make_image_array(_trainFile, image_height, image_width, channels)\n    i += 1\n    \ntestImages = np.ndarray(shape=(len(x_test), image_height, image_width, channels), \n                        dtype=np.float32)\n                        \ni = 0\nfor _testFile in x_test:\n    testImages[i] = make_image_array(_testFile, image_height, image_width, channels)\n    i += 1\n","60e58787":"# The following defines a function to view a random sample of the images with class label column headers\ndef visualize_sample(X_train, y_train, classes, samples_per_class=5):\n  num_classes = len(classes)\n  for y, cls in enumerate(classes):\n    idxs = np.flatnonzero(y_train == y) # get all the indexes of class\n    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n    for i, idx in enumerate(idxs): # plot the image one by one\n      plt_idx = i * num_classes + y + 1 # i*num_classes and y+1 determine the row and column respectively\n      plt.subplot(samples_per_class, num_classes, plt_idx)\n      plt.imshow(trainImages[idx].astype('uint8'))\n      plt.axis('off')\n      if i == 0:\n        plt.title(cls)\n  plt.show()","c9db8158":"#Get all unique target labels (constitute the classes)\nclasses = np.unique(target_labels)\nprint(classes.shape[0])\n#Call the function to view the images and classes\nvisualize_sample(x_train, y_train, classes[: 5], 5)","89b25882":"# Prepare the train and test data for a CNN\n# One hot encoding is a way to encode non ordinal categorical data\nfrom keras.utils.np_utils import to_categorical\none_hot_train_labels = to_categorical(y_train)\none_hot_test_labels = to_categorical(y_test)\n# We can see that each category is now represented as a single binary 1 in an array of binary values (the number of classes in our dataset)\nprint(one_hot_train_labels[0].shape[0])\nprint(one_hot_train_labels[0])","d9a9adb6":"# Split the data into a train and validation block\nfrom sklearn.model_selection import train_test_split\nx_train, y_val, x_lab, y_lab = train_test_split(trainImages, one_hot_train_labels, test_size = 0.2, random_state = 1)","b103a69e":"#import tenserflow.keras\nfrom tensorflow.keras import models #used for sequential models\nfrom tensorflow.keras import layers \nfrom tensorflow.keras.layers import Input, Concatenate, Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout, AveragePooling2D, SeparableConv2D, BatchNormalization\nfrom tensorflow.keras.models import Model #used for functional api\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras import callbacks\n\n#initialize the sequential model\nmodel = models.Sequential()\n#add the hidden layers to the network\n#add the first input layer (requires an input shape)\nmodel.add(Conv2D(32, (2, 2), padding='same', input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (4, 4), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n# a flatten layer is required to transform the 2 dimensional image to a single dimension to input into a dense layer\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n# output layer should have a node for each class in this classification problem\nmodel.add(Dense(120))\nmodel.add(Activation('softmax'))\n\nmodel.compile(optimizer= 'rmsprop',\n              loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])\n\n#an early stopper can be added to stop the model training when the model begins to overfit the data:\nearlyStopper = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n\n#the model fit will return the results of each training epoch\nhistory = model.fit(x_train,\n                    x_lab,\n                    epochs=20,\n                    verbose = 1,\n                    batch_size=300,\n                    validation_data=(y_val, y_lab),\n                    callbacks=[earlyStopper])\n\n# In order to visualize the results of training we graph the accuracy on the training set as well as the hold out validation set\nimport matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Next we evaluate the model on the yet unseen test data\nresults = model.evaluate(testImages, one_hot_test_labels)\nprint(model.metrics_names)\nprint(results)","c65957a7":"# Build and print (plot) the model architecture\nvisible = Input(shape = (100, 100, 3))\ntrunk_1 = Conv2D(100, kernel_size=2, activation='relu', strides=2, padding='same')(visible)\ntrunk_1 = MaxPooling2D(strides=2, padding='same')(trunk_1)\ntrunk_1 = SeparableConv2D(50, kernel_size=2, strides=1, activation='relu', padding='same')(trunk_1) \ntrunk_1 = BatchNormalization()(trunk_1)\nbranch_1 = Conv2D(50, kernel_size=2, activation='relu', strides=1, padding='same')(trunk_1)\nbranch_1 = Conv2D(75, kernel_size=4, activation='relu', strides=1)(branch_1)\nbranch_1 = Conv2D(100, kernel_size=6, activation='relu', strides=2)(branch_1)\nbranch_2 = Conv2D(50, kernel_size=3, activation='relu', strides=1)(trunk_1)\nbranch_2 = Conv2D(100, kernel_size=6, activation='relu', strides=2)(branch_2)\ntrunk_2 = Concatenate(axis=-1)([branch_1, branch_2])\ntrunk_2 = Conv2D(100, kernel_size=2, activation='relu', strides=1, padding='same')(trunk_2)\ntrunk_2 = Flatten()(trunk_2)\ntrunk_2 = Dense(512)(trunk_2)\ntrunk_2 = Dropout(0.5)(trunk_2)\ntrunk_2 = Dense(120, activation='softmax')(trunk_2)\n\nmodel = Model(inputs=visible, outputs=trunk_2)\n\nprint(model.summary())\n# plot graph\nplot_model(model)","6df0217c":"#Run the Functional API model (similar to the sequential in how it is setup)\nmodel.compile(optimizer= 'rmsprop',\n              loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])\n\nearlyStopper = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n\nhistory = model.fit(x_train,\n                    x_lab,\n                    epochs=35,\n                    verbose = 1,\n                    batch_size=500,\n                    validation_data=(y_val, y_lab),\n                    callbacks=[earlyStopper])\n\nimport matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nresults = model.evaluate(testImages, one_hot_test_labels)\nprint(model.metrics_names)\nprint(results)","3fe7b0fa":"It is useful to see what we are working with before starting any analysis:","4d95322a":"### Building a sequential model\n\nSequential models are great to start with when learning how to use neural networks.","d5791ffb":"Much better accuracy with the Functional API model.  Happy learning!","9d3f980e":"# Introduction to Neural Networks\n\nThe building block of a neural network is the perceptron.  A perceptron is loosely based on how a biological neuron works.  The perceptron accepts input, applies a bias, and outputs an activation.\n\n![Perceptron](https:\/\/pythonmachinelearning.pro\/wp-content\/uploads\/2017\/09\/Single-Perceptron-768x427.png.webp) Figure 1. Mohit Deshpande. (2017). Perceptron [Graphic], Retrieved May 3, 2020, from: https:\/\/pythonmachinelearning.pro\/perceptrons-the-first-neural-networks\/\n\nA neural network is made up of many perceptrons organized in layers.  The first layer of a neural network is called the input layer and the last layer is called, unsurprisingly, the output layer.  Between these two layers are any number of hidden layers.  The input layer is sized according to the input data on which the neural network will operate.  The output layer is (generally) sized to the number of answers desired from the neural network.  The hidden layers are varied in size and number in an attempt to formulate a model that will best fit the problem of \"translating\" the input layer into the best answers.  Each individual node in each hidden layer is connected to all nodes in the previous layer.\n\n![Multilayer Perceptron (MLP)](https:\/\/www.allaboutcircuits.com\/uploads\/articles\/an-introduction-to-training-theory-for-neural-networks_rk_aac_image2.jpg) Figure 2. Robert Keim. (2019). Simple Neural Network Diagram [Graphic], Retrieved May 3, 2020, from: https:\/\/www.allaboutcircuits.com\/uploads\/articles\/an-introduction-to-training-theory-for-neural-networks_rk_aac_image2.jpg\n\nThe perceptrons which make up a neural network are more commonly referred to as nodes.  Each node in a neural network applies a weight to every input from the previous layer plus some internal bias.  After which the resulting value is passed to an activation function.  This activation function outputs the \"activation\" of that node which is then inputted into the next layer's nodes.  The activation function generally outputs a binary response on whether the node is active or not.  This process repeats until reaching the output layer.\n\nThe learning process of a neural network starts with randomly assigned weights and biases at each of the nodes.  The first input data instance is initialized in the input layer and the data is passed through each layer of the network with each node performing its function and passing its output on.  Once the network has completed all calculations and the output layer is populated, a loss function is applied to the output layer.  This loss function has the correct answer and this sums up the output and determines how wrong the network is.  The network then works backward via backpropagation with the output layer values modified by the cost function to \"learn\" new values for the weights and biases of each node.  This process repeated for each instance in the training data set.  This single pass through each instance of the entire training data set constitutes one epoch.  \n\nImages are a particularly challenging data source with great potential for applications in machine learning.  How image data is encoded is important to understanding for our next topic: Convolutional Neural Networks or CNNs.  In an 8-bit grayscale image, each pixel value is represented as a number between 0 and 255.  In a 16-bit color image, a value between 0 and 255 represents each of 3 color channels (red, yellow, blue for RGB images).  These pixel values along with the location of the pixels in a grid are the numerical representation of images that allows for processing by the functions in a neural network.\n\nOrdinary neural networks have limited success in learning to analyze images.  A canonical neural network attempts to find a model that fits the entire image without the ability to account for smaller repeating features that change location.  Convolution, in the context of machine learning or image processing, is the process of applying a kernel or feature map in \"strides\" across an image.  At each stride, the feature map is applied to the image segment and each corresponding pixel value is multiplied together and then divided by the number of pixels in the feature map.  The result is applied to a new image of the image segment.  These feature maps find small patterns throughout the entire image.  Breaking down images into smaller shapes and forms and then assembling those forms into more complex shapes and forms has proven to be much more successful at analyzing images.\n\nAnother commonly used layer in CNN is max polling.  Max pooling is a similar process to convolution except that no feature map is used and at each stride, we take the max pixel value as the result.  Max pooling is used to downsize an image while preserving the most salient information from the image (maximum pixel intensities).  \n\n\n","d570a5d4":"# Welcome to this notebook primer on convolutional neural networks.   This primer will cover:\n* Introduction to Neural Networks and Convolutional Neural Networks\n* Loading an image dataset\n* Preparing the image dataset\n* Splitting the dataset in to training, validation, and test data\n* Convolutional neural network layers\n    * Convolutional Layers\n    * Max Pooling\n    * Batch Normalization\n* Building a convolutional neural network using the sequential model\n* Building a convolutional neural network using the function API\n* Visualizing the neural network \n* Visualizing results","a7a97f5d":"We start with importing the libraries and namespaces which will be used and pulling the data from the directories:","1d2e7b84":"# Image dataset\nFor our CNN image analysis, we will be using the \"Fruits 360\" dataset.  This dataset contains 82,197, 100x100px images of 120 fruit varieties.  When attempting to run the full dataset in Kaggle we quickly run out of memory.  As a result, I have passed a parameter to subset the data to a managable sample size.  The background was removed in the images by post-processing.  In order to build a convolutional neural network, it is required that all the images in our dataset are the same size and ideally the sample size is large.  This dataset fits those requirements so let's get started!","c7139ef9":"## Functional API model\nUtilizing the Functional API allows for more complex models required to achieve better results.  This simple model uses 2 branches with different convolution layers which are then concatenated (a fairly typical operation for functional API models).","ac408c9c":"# References\nHorea Muresan, Mihai Oltean, Fruit recognition from images using deep learning, Acta Univ. Sapientiae, Informatica Vol. 10, Issue 1, pp. 26-42, 2018.","7ea411ad":"Now that we know what our input data looks like lets transform it into the correct format for building a neural network.","003ae62d":"Accuracy of close to 80% on the test data set.  Not bad.","444f75c1":"Now our data is formatted correctly and its time to build a model!  "}}