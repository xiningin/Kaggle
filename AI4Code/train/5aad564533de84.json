{"cell_type":{"260fdac0":"code","18e27ebe":"code","f5e4f860":"code","57024192":"code","e3d74c53":"code","1fa9d61a":"code","5478ffec":"code","fb6df5ac":"code","8c03f418":"code","4e7a558d":"markdown","db09ba3e":"markdown"},"source":{"260fdac0":"%%time\n# INSTALL RAPIDS OFFLINE (FROM KAGGLE DATASET). TAKES 1 MINUTE :-)\nimport sys\n!cp ..\/input\/rapids\/rapids.0.12.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\"] + [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\/site-packages\"] + sys.path\n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","18e27ebe":"import cudf, cuml\nimport cupy as cp\nimport numpy as np\nimport pandas as pd\nfrom cuml.manifold import TSNE\nimport matplotlib.pyplot as plt\n%matplotlib inline","f5e4f860":"train = pd.read_csv('..\/input\/big-five-personality-test\/IPIP-FFM-data-8Nov2018\/data-final.csv', sep='\\t')","57024192":"X_train = train[train.columns[:50]]\nX_train.head()","e3d74c53":"X_train.shape","1fa9d61a":"X_train = X_train.dropna()\nX_train.shape","5478ffec":"X_train = X_train.values\/5","fb6df5ac":"%%time\ntsne = TSNE(n_components=2)\nX_train_2D = tsne.fit_transform(X_train)","8c03f418":"# Plot the embedding\nplt.scatter(X_train_2D[:,0], X_train_2D[:,1], s = 0.5)","4e7a558d":"In this exercise we'll try to use tSNE for decomposition of dimensionality reduction of the Big Five dataset. The final result is not that exciting - we end up with one big \"blob\" and a few little remote satelite \"dots\". But in a way it confirms what has been well know for a while - that personality is really on a continous spectrum, and \"typology\" is not well founded approach to this subject. \n\nEven though the scientific value of this kernel is rather limited, the technical value is still pretty remarkable - thanks to Rapids, it is possible to calculate t-SNE of a million row dataset in just a cuple of minutes. With other algorithms this could potentially take days to do. In other words, Rapids enables you a much faster experimentation than would otherwise be possible. ","db09ba3e":"[Rapids](https:\/\/rapids.ai) is an open-source GPU accelerated Data Sceince and Machine Learning library, developed and mainatained by [Nvidia](https:\/\/www.nvidia.com). It is designed to be compatible with many existing CPU tools, such as Pandas, scikit-learn, numpy, etc. It enables **massive** acceleration of many data-science and machine learning tasks, oftentimes by a factor fo 100X, or even more. \n\nRapids is still undergoing developemnt, and as of right now it's not availabel in the Kaggle Docker environment. If you are interested in installing and riunning Rapids locally on your own machine, then you should [refer to the followong instructions](https:\/\/rapids.ai\/start.html).\n\nIn order to install Rapids locally we'll be follow the setup that was inmplemented by Chris Deotte in [the following kernel](https:\/\/www.kaggle.com\/cdeotte\/rapids-data-augmentation-mnist-0-985)."}}