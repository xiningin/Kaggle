{"cell_type":{"433914d3":"code","5818f406":"code","eb5ee471":"code","e638d921":"code","595f31d7":"code","754088fb":"code","255b166e":"code","3b365e0f":"code","73b46fa2":"code","5607dcab":"code","d7e66282":"code","ba4089fa":"code","86b6797d":"code","97727bf7":"code","6bc9ab8a":"code","00e32f80":"code","bf2cfd35":"code","df895438":"code","76364847":"code","930b4187":"markdown","cff20e39":"markdown","8b7b2f1e":"markdown","b1600486":"markdown","769d2d7d":"markdown","0114fad9":"markdown","b37fb4df":"markdown","08e5fc2d":"markdown","58d6c642":"markdown","b25050d9":"markdown","d51f6069":"markdown","39651299":"markdown","762def3e":"markdown","7d5ce83a":"markdown","1832e638":"markdown","4887ff78":"markdown"},"source":{"433914d3":"import pandas as pd \nimport numpy as np\ndt = pd.read_csv(\"\/kaggle\/input\/simulated-bank-customer-data\/CUST_ASSET_DATA.csv\")\n# input data\nind1 = dt[dt[\"AGE\"].isna()].index\nind2 = dt[dt[\"BRANCH_DIST\"].isna()].index\nind = pd.Series((list(ind1)+list(ind2))).unique()\ndt = dt.drop(index = ind)\n# preprocessing of data","5818f406":"import matplotlib.pyplot as plt\n%matplotlib inline\nfor i,k in zip(range(57,77),range(1,21)):\n    y=[]\n    for j in range(1,14):\n         y = y + list(dt.iloc[i:i+1,:][\"TOTAL_ASSET_\"+str(j)])\n    x = list(range(1,14))\n    plt.figure(figsize=(10,100))\n    plt.subplot(20,1,k)\n    plt.title(str(i)+\"th plot\")\n    plt.plot(x,y)","eb5ee471":"for i in range(2,14):\n    dt[\"M\"+str(i)] = np.zeros(len(dt))\nfor i in range(2,14):\n    c = ((dt[\"TOTAL_ASSET_\"+str(i)]-dt[\"TOTAL_ASSET_\"+str(i-1)])\/dt[\"TOTAL_ASSET_\"+str(i-1)]) >= 0.001\n    d = ((dt[\"TOTAL_ASSET_\"+str(i)]-dt[\"TOTAL_ASSET_\"+str(i-1)])\/dt[\"TOTAL_ASSET_\"+str(i-1)]) <= -0.001\n    dt[\"M\"+str(i)][c[c == True].index] = \"+\"\n    dt[\"M\"+str(i)][d[d == True].index] = \"-\"\n    dt[\"M\"+str(i)][dt.drop(index = c[c == True].index).drop(index = d[d == True].index).index] = \"x\"","e638d921":"# calculating ties\ndt[\"ties\"] = np.zeros(len(dt))\nfor i in range(3,14):\n    c = dt[\"M\"+str(i)] != dt[\"M\"+str(i-1)]\n    dt[\"ties\"][c[c==True].index] = dt[\"ties\"][c[c==True].index] + 1\n# calculating new label\ndt[\"+\"] = np.zeros(len(dt))\ndt[\"unchanged\"] = np.zeros(len(dt))\ndt[\"-\"] = np.zeros(len(dt))\n\nfor i in range(2,14):\n    c = ((dt[\"TOTAL_ASSET_\"+str(i)]-dt[\"TOTAL_ASSET_\"+str(i-1)])\/dt[\"TOTAL_ASSET_\"+str(i-1)]) >= 0.001\n    d = ((dt[\"TOTAL_ASSET_\"+str(i)]-dt[\"TOTAL_ASSET_\"+str(i-1)])\/dt[\"TOTAL_ASSET_\"+str(i-1)]) <= -0.001\n    dt[\"+\"][c[c == True].index] = dt[\"+\"][c[c == True].index] + 1\n    dt[\"-\"][d[d == True].index] = dt[\"-\"][d[d == True].index] + 1\n    dt[\"unchanged\"][dt.drop(index = c[c == True].index).drop(index = d[d == True].index).index] = dt[\"unchanged\"][dt.drop(index = c[c == True].index).drop(index = d[d == True].index).index]+1","595f31d7":"dt[[\"M2\",\"M3\",\"M4\",\"M5\",\"M6\",\"M7\",\"M8\",\"M9\",\"M10\",\"M11\",\n   \"M12\",\"M13\",\"+\",\"unchanged\",\"-\",\"ties\"]]","754088fb":"Pattern_data = dt[[\"+\",\"-\",\"unchanged\",\"ties\"]]\n\nfrom sklearn.cluster import KMeans\n\ndistortions = []\nfor i in range(1, 10):\n    km = KMeans(n_clusters=i, \n                init='k-means++', \n                n_init=10, \n                max_iter=300, \n                random_state=0)\n    km.fit(Pattern_data)\n    distortions.append(km.inertia_)\n    print('Distortion: %.2f' % km.inertia_)\n\nimport matplotlib.pyplot as plt\nplt.plot(range(1, 10), distortions, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Distortion')\nplt.tight_layout()\nplt.show()","255b166e":"km = KMeans(n_clusters=5, \n                init='k-means++', \n                n_init=10, \n                max_iter=300, \n                random_state=0)\nkm.fit(Pattern_data)\ndt[\"label\"] = km.labels_\ndt[[\"+\",\"unchanged\",\"-\",\"ties\",\"label\"]]","3b365e0f":"i_v = dt[dt[\"label\"] == 0].index[0:100]\nj_v = range(1,11)\nfor i,j in zip(i_v,j_v):\n    y=[]\n    for k in range(1,14):\n        y = y + list(dt.iloc[i:i+1,:][\"TOTAL_ASSET_\"+str(k)])\n    x = list(range(1,14))\n    plt.figure(figsize=(5,50))\n    plt.subplot(10,1,j)\n    plt.title(i)\n    plt.plot(x,y)","73b46fa2":"i_v = dt[dt[\"label\"] == 1].index[0:100]\nj_v = range(1,11)\nfor i,j in zip(i_v,j_v):\n    y=[]\n    for k in range(1,14):\n        y = y + list(dt.iloc[i:i+1,:][\"TOTAL_ASSET_\"+str(k)])\n    x = list(range(1,14))\n    plt.figure(figsize=(5,50))\n    plt.subplot(10,1,j)\n    plt.title(i)\n    plt.plot(x,y)","5607dcab":"i_v = dt[dt[\"label\"] == 2].index[0:100]\nj_v = range(1,11)\nfor i,j in zip(i_v,j_v):\n    y=[]\n    for k in range(1,14):\n        y = y + list(dt.iloc[i:i+1,:][\"TOTAL_ASSET_\"+str(k)])\n    x = list(range(1,14))\n    plt.figure(figsize=(5,50))\n    plt.subplot(10,1,j)\n    plt.title(i)\n    plt.plot(x,y)","d7e66282":"i_v = dt[dt[\"label\"] == 3].index[0:100]\nj_v = range(1,11)\nfor i,j in zip(i_v,j_v):\n    y=[]\n    for k in range(1,14):\n        y = y + list(dt.iloc[i:i+1,:][\"TOTAL_ASSET_\"+str(k)])\n    x = list(range(1,14))\n    plt.figure(figsize=(5,50))\n    plt.subplot(10,1,j)\n    plt.title(i)\n    plt.plot(x,y)","ba4089fa":"i_v = dt[dt[\"label\"] == 4].index[0:100]\nj_v = range(1,11)\nfor i,j in zip(i_v,j_v):\n    y=[]\n    for k in range(1,14):\n        y = y + list(dt.iloc[i:i+1,:][\"TOTAL_ASSET_\"+str(k)])\n    x = list(range(1,14))\n    plt.figure(figsize=(5,50))\n    plt.subplot(10,1,j)\n    plt.title(i)\n    plt.plot(x,y)","86b6797d":"from sklearn.metrics import r2_score\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam, SGD\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.layers import Dense\nfrom keras.layers import Dropout","97727bf7":"from sklearn.preprocessing import LabelEncoder\ncolumns = [\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\"ACTIVE_WEB_CUST\",\"SECURITY_ACC\",\n           \"INTERACT_AMT_A\",\"INTERACT_AMT_B\",\"TOTAL_ASSET_X\",\"TOTAL_ASSET_y\"]\n\ndt2 = pd.DataFrame(np.array(dt[dt[\"label\"] == 0][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n          \"ACTIVE_WEB_CUST_1\",\"SECURITY_ACC_1\",\"INTERACT_AMT_A_1\",\n          \"INTERACT_AMT_B_1\",\"TOTAL_ASSET_1\",\"TOTAL_ASSET_2\"]]),columns = columns)\n\nfor i in range(2,12):\n    dt1 = pd.DataFrame(np.array(dt[dt[\"label\"] == 0][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n                           \"ACTIVE_WEB_CUST_\"+str(i),\"SECURITY_ACC_\"+str(i),\n                           \"INTERACT_AMT_A_\"+str(i),\"INTERACT_AMT_B_\"+str(i),\n                           \"TOTAL_ASSET_\"+str(i),\"TOTAL_ASSET_\"+str(i+1)]])\n                       ,columns = columns)\n    Train_dt = pd.concat([dt2,dt1])\n\nTest_dt = pd.DataFrame(np.array(dt[dt[\"label\"] == 0][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n          \"ACTIVE_WEB_CUST_12\",\"SECURITY_ACC_12\",\"INTERACT_AMT_A_12\",\n          \"INTERACT_AMT_B_12\",\"TOTAL_ASSET_12\",\"TOTAL_ASSET_13\"]]),columns = columns)\n\n# transform nominal features into codes\nnominal = [\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\"ACTIVE_WEB_CUST\",\"SECURITY_ACC\"]\n\nTrain_dt = Train_dt.copy()\nfor label in nominal:\n    Train_dt[label] = LabelEncoder().fit_transform(Train_dt[label])\n    \nTest_dt = Test_dt.copy()\nfor label in nominal:\n    Test_dt[label] = LabelEncoder().fit_transform(Test_dt[label])\nX_train, y_train,X_test,y_test = Train_dt.iloc[:,0:9],Train_dt.iloc[:,9:10],Test_dt.iloc[:,0:9],Test_dt.iloc[:,9:10]\n\nX_train=np.array(X_train).reshape(-1,9)\nX_test=np.array(X_test).reshape(-1,9)\ny_train=np.array(y_train).reshape(-1,1)\ny_test=np.array(y_test).reshape(-1,1)\n\nimport tensorflow as tf\nX_train = tf.constant(X_train, tf.float32)\nX_test = tf.constant(X_test, tf.float32)\ny_train = tf.constant(y_train, tf.float32)\ny_test = tf.constant(y_test, tf.float32)\n\n# model construciton \nann=Sequential()\nann.add(Dense(64, input_dim=9, activation='relu'))\nann.add(Dense(32, input_dim=64, activation='relu'))\nann.add(Dense(units=1, kernel_initializer='normal', activation='linear'))\nann.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\nann.fit(X_train, y_train, epochs=100, batch_size=8000, \n        validation_data=(X_test, y_test),\n        verbose=1, shuffle=False)\n\ny_test_pred_origin_0 = ann.predict(X_test)","6bc9ab8a":"from sklearn.preprocessing import LabelEncoder\ncolumns = [\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\"ACTIVE_WEB_CUST\",\"SECURITY_ACC\",\n           \"INTERACT_AMT_A\",\"INTERACT_AMT_B\",\"TOTAL_ASSET_X\",\"TOTAL_ASSET_y\"]\n\ndt2 = pd.DataFrame(np.array(dt[dt[\"label\"] == 1][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n          \"ACTIVE_WEB_CUST_1\",\"SECURITY_ACC_1\",\"INTERACT_AMT_A_1\",\n          \"INTERACT_AMT_B_1\",\"TOTAL_ASSET_1\",\"TOTAL_ASSET_2\"]]),columns = columns)\n\nfor i in range(2,12):\n    dt1 = pd.DataFrame(np.array(dt[dt[\"label\"] == 1][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n                           \"ACTIVE_WEB_CUST_\"+str(i),\"SECURITY_ACC_\"+str(i),\n                           \"INTERACT_AMT_A_\"+str(i),\"INTERACT_AMT_B_\"+str(i),\n                           \"TOTAL_ASSET_\"+str(i),\"TOTAL_ASSET_\"+str(i+1)]])\n                       ,columns = columns)\n    Train_dt = pd.concat([dt2,dt1])\n\nTest_dt = pd.DataFrame(np.array(dt[dt[\"label\"] == 1][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n          \"ACTIVE_WEB_CUST_12\",\"SECURITY_ACC_12\",\"INTERACT_AMT_A_12\",\n          \"INTERACT_AMT_B_12\",\"TOTAL_ASSET_12\",\"TOTAL_ASSET_13\"]]),columns = columns)\n\n# transform nominal features into codes\nnominal = [\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\"ACTIVE_WEB_CUST\",\"SECURITY_ACC\"]\n\nTrain_dt = Train_dt.copy()\nfor label in nominal:\n    Train_dt[label] = LabelEncoder().fit_transform(Train_dt[label])\n    \nTest_dt = Test_dt.copy()\nfor label in nominal:\n    Test_dt[label] = LabelEncoder().fit_transform(Test_dt[label])\nX_train, y_train,X_test,y_test = Train_dt.iloc[:,0:9],Train_dt.iloc[:,9:10],Test_dt.iloc[:,0:9],Test_dt.iloc[:,9:10]\n\nX_train=np.array(X_train).reshape(-1,9)\nX_test=np.array(X_test).reshape(-1,9)\ny_train=np.array(y_train).reshape(-1,1)\ny_test=np.array(y_test).reshape(-1,1)\n\nimport tensorflow as tf\nX_train = tf.constant(X_train, tf.float32)\nX_test = tf.constant(X_test, tf.float32)\ny_train = tf.constant(y_train, tf.float32)\ny_test = tf.constant(y_test, tf.float32)\n\n# model construciton \nann=Sequential()\nann.add(Dense(64, input_dim=9, activation='relu'))\nann.add(Dense(32, input_dim=64, activation='relu'))\nann.add(Dense(units=1, kernel_initializer='normal', activation='linear'))\nann.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\nann.fit(X_train, y_train, epochs=50, batch_size=8000, \n        validation_data=(X_test, y_test),\n        verbose=1, shuffle=False)\n\ny_test_pred_origin_1 = ann.predict(X_test)","00e32f80":"from sklearn.preprocessing import LabelEncoder\ncolumns = [\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\"ACTIVE_WEB_CUST\",\"SECURITY_ACC\",\n           \"INTERACT_AMT_A\",\"INTERACT_AMT_B\",\"TOTAL_ASSET_X\",\"TOTAL_ASSET_y\"]\n\ndt2 = pd.DataFrame(np.array(dt[dt[\"label\"] == 2][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n          \"ACTIVE_WEB_CUST_1\",\"SECURITY_ACC_1\",\"INTERACT_AMT_A_1\",\n          \"INTERACT_AMT_B_1\",\"TOTAL_ASSET_1\",\"TOTAL_ASSET_2\"]]),columns = columns)\n\nfor i in range(2,12):\n    dt1 = pd.DataFrame(np.array(dt[dt[\"label\"] == 2][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n                           \"ACTIVE_WEB_CUST_\"+str(i),\"SECURITY_ACC_\"+str(i),\n                           \"INTERACT_AMT_A_\"+str(i),\"INTERACT_AMT_B_\"+str(i),\n                           \"TOTAL_ASSET_\"+str(i),\"TOTAL_ASSET_\"+str(i+1)]])\n                       ,columns = columns)\n    Train_dt = pd.concat([dt2,dt1])\n\nTest_dt = pd.DataFrame(np.array(dt[dt[\"label\"] == 2][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n          \"ACTIVE_WEB_CUST_12\",\"SECURITY_ACC_12\",\"INTERACT_AMT_A_12\",\n          \"INTERACT_AMT_B_12\",\"TOTAL_ASSET_12\",\"TOTAL_ASSET_13\"]]),columns = columns)\n\n# transform nominal features into codes\nnominal = [\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\"ACTIVE_WEB_CUST\",\"SECURITY_ACC\"]\n\nTrain_dt = Train_dt.copy()\nfor label in nominal:\n    Train_dt[label] = LabelEncoder().fit_transform(Train_dt[label])\n    \nTest_dt = Test_dt.copy()\nfor label in nominal:\n    Test_dt[label] = LabelEncoder().fit_transform(Test_dt[label])\nX_train, y_train,X_test,y_test = Train_dt.iloc[:,0:9],Train_dt.iloc[:,9:10],Test_dt.iloc[:,0:9],Test_dt.iloc[:,9:10]\n\nX_train=np.array(X_train).reshape(-1,9)\nX_test=np.array(X_test).reshape(-1,9)\ny_train=np.array(y_train).reshape(-1,1)\ny_test=np.array(y_test).reshape(-1,1)\n\nimport tensorflow as tf\nX_train = tf.constant(X_train, tf.float32)\nX_test = tf.constant(X_test, tf.float32)\ny_train = tf.constant(y_train, tf.float32)\ny_test = tf.constant(y_test, tf.float32)\n\n# model construciton \nann=Sequential()\nann.add(Dense(64, input_dim=9, activation='relu'))\nann.add(Dense(32, input_dim=64, activation='relu'))\nann.add(Dense(units=1, kernel_initializer='normal', activation='linear'))\nann.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\nann.fit(X_train, y_train, epochs=150, batch_size=8000, \n        validation_data=(X_test, y_test),\n        verbose=1, shuffle=False)\n\ny_test_pred_origin_2 = ann.predict(X_test)","bf2cfd35":"from sklearn.preprocessing import LabelEncoder\ncolumns = [\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\"ACTIVE_WEB_CUST\",\"SECURITY_ACC\",\n           \"INTERACT_AMT_A\",\"INTERACT_AMT_B\",\"TOTAL_ASSET_X\",\"TOTAL_ASSET_y\"]\n\ndt2 = pd.DataFrame(np.array(dt[dt[\"label\"] == 3][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n          \"ACTIVE_WEB_CUST_1\",\"SECURITY_ACC_1\",\"INTERACT_AMT_A_1\",\n          \"INTERACT_AMT_B_1\",\"TOTAL_ASSET_1\",\"TOTAL_ASSET_2\"]]),columns = columns)\n\nfor i in range(2,12):\n    dt1 = pd.DataFrame(np.array(dt[dt[\"label\"] == 3][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n                           \"ACTIVE_WEB_CUST_\"+str(i),\"SECURITY_ACC_\"+str(i),\n                           \"INTERACT_AMT_A_\"+str(i),\"INTERACT_AMT_B_\"+str(i),\n                           \"TOTAL_ASSET_\"+str(i),\"TOTAL_ASSET_\"+str(i+1)]])\n                       ,columns = columns)\n    Train_dt = pd.concat([dt2,dt1])\n\nTest_dt = pd.DataFrame(np.array(dt[dt[\"label\"] == 3][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n          \"ACTIVE_WEB_CUST_12\",\"SECURITY_ACC_12\",\"INTERACT_AMT_A_12\",\n          \"INTERACT_AMT_B_12\",\"TOTAL_ASSET_12\",\"TOTAL_ASSET_13\"]]),columns = columns)\n\n# transform nominal features into codes\nnominal = [\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\"ACTIVE_WEB_CUST\",\"SECURITY_ACC\"]\n\nTrain_dt = Train_dt.copy()\nfor label in nominal:\n    Train_dt[label] = LabelEncoder().fit_transform(Train_dt[label])\n    \nTest_dt = Test_dt.copy()\nfor label in nominal:\n    Test_dt[label] = LabelEncoder().fit_transform(Test_dt[label])\nX_train, y_train,X_test,y_test = Train_dt.iloc[:,0:9],Train_dt.iloc[:,9:10],Test_dt.iloc[:,0:9],Test_dt.iloc[:,9:10]\n\nX_train=np.array(X_train).reshape(-1,9)\nX_test=np.array(X_test).reshape(-1,9)\ny_train=np.array(y_train).reshape(-1,1)\ny_test=np.array(y_test).reshape(-1,1)\n\nimport tensorflow as tf\nX_train = tf.constant(X_train, tf.float32)\nX_test = tf.constant(X_test, tf.float32)\ny_train = tf.constant(y_train, tf.float32)\ny_test = tf.constant(y_test, tf.float32)\n\n# model construciton \nann=Sequential()\nann.add(Dense(64, input_dim=9, activation='relu'))\nann.add(Dense(32, input_dim=64, activation='relu'))\nann.add(Dense(units=1, kernel_initializer='normal', activation='linear'))\nann.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\nann.fit(X_train, y_train, epochs=100, batch_size=8000, \n        validation_data=(X_test, y_test),\n        verbose=1, shuffle=False)\n\ny_test_pred_origin_3 = ann.predict(X_test)","df895438":"from sklearn.preprocessing import LabelEncoder\ncolumns = [\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\"ACTIVE_WEB_CUST\",\"SECURITY_ACC\",\n           \"INTERACT_AMT_A\",\"INTERACT_AMT_B\",\"TOTAL_ASSET_X\",\"TOTAL_ASSET_y\"]\n\ndt2 = pd.DataFrame(np.array(dt[dt[\"label\"] == 4][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n          \"ACTIVE_WEB_CUST_1\",\"SECURITY_ACC_1\",\"INTERACT_AMT_A_1\",\n          \"INTERACT_AMT_B_1\",\"TOTAL_ASSET_1\",\"TOTAL_ASSET_2\"]]),columns = columns)\n\nfor i in range(2,12):\n    dt1 = pd.DataFrame(np.array(dt[dt[\"label\"] == 4][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n                           \"ACTIVE_WEB_CUST_\"+str(i),\"SECURITY_ACC_\"+str(i),\n                           \"INTERACT_AMT_A_\"+str(i),\"INTERACT_AMT_B_\"+str(i),\n                           \"TOTAL_ASSET_\"+str(i),\"TOTAL_ASSET_\"+str(i+1)]])\n                       ,columns = columns)\n    Train_dt = pd.concat([dt2,dt1])\n\nTest_dt = pd.DataFrame(np.array(dt[dt[\"label\"] == 4][[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n          \"ACTIVE_WEB_CUST_12\",\"SECURITY_ACC_12\",\"INTERACT_AMT_A_12\",\n          \"INTERACT_AMT_B_12\",\"TOTAL_ASSET_12\",\"TOTAL_ASSET_13\"]]),columns = columns)\n\n# transform nominal features into codes\nnominal = [\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\"ACTIVE_WEB_CUST\",\"SECURITY_ACC\"]\n\nTrain_dt = Train_dt.copy()\nfor label in nominal:\n    Train_dt[label] = LabelEncoder().fit_transform(Train_dt[label])\n    \nTest_dt = Test_dt.copy()\nfor label in nominal:\n    Test_dt[label] = LabelEncoder().fit_transform(Test_dt[label])\nX_train, y_train,X_test,y_test = Train_dt.iloc[:,0:9],Train_dt.iloc[:,9:10],Test_dt.iloc[:,0:9],Test_dt.iloc[:,9:10]\n\nX_train=np.array(X_train).reshape(-1,9)\nX_test=np.array(X_test).reshape(-1,9)\ny_train=np.array(y_train).reshape(-1,1)\ny_test=np.array(y_test).reshape(-1,1)\n\nimport tensorflow as tf\nX_train = tf.constant(X_train, tf.float32)\nX_test = tf.constant(X_test, tf.float32)\ny_train = tf.constant(y_train, tf.float32)\ny_test = tf.constant(y_test, tf.float32)\n\n# model construciton \nann=Sequential()\nann.add(Dense(64, input_dim=9, activation='relu'))\nann.add(Dense(32, input_dim=64, activation='relu'))\nann.add(Dense(units=1, kernel_initializer='normal', activation='linear'))\nann.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\nann.fit(X_train, y_train, epochs=100, batch_size=8000, \n        validation_data=(X_test, y_test),\n        verbose=1, shuffle=False)\n\ny_test_pred_origin_4 = ann.predict(X_test)","76364847":"p0 = pd.DataFrame(y_test_pred_origin_0,index=dt[dt[\"label\"] == 0].index)\np1 = pd.DataFrame(y_test_pred_origin_1,index=dt[dt[\"label\"] == 1].index)\np2 = pd.DataFrame(y_test_pred_origin_2,index=dt[dt[\"label\"] == 2].index)\np3 = pd.DataFrame(y_test_pred_origin_3,index=dt[dt[\"label\"] == 3].index)\np4 = pd.DataFrame(y_test_pred_origin_4,index=dt[dt[\"label\"] == 4].index)\npredict = pd.concat([p0,p1,p2,p3,p4])\npredict = predict.sort_index()\n\nAnswer = np.array(dt[\"TOTAL_ASSET_13\"]).reshape(-1,1)\nprint(\"MSE of Prediction: \"+str((((np.array(predict).reshape(-1,1)-Answer)**2)\/len(dt)).sum()))","930b4187":"### Group2","cff20e39":"## Group3 : label = 2","8b7b2f1e":"### Group5","b1600486":"### Group1","769d2d7d":"## Group5 : label = 4","0114fad9":"### Group4","b37fb4df":"### Now we're going to use the new features (\"+\", \"-\",  \"unchanged\", \"ties\") to construct clustering model.","08e5fc2d":"## Group4 : label = 3","58d6c642":"### Group 3","b25050d9":"### It seems that saperating data into 5 gruops is a good choice.","d51f6069":"## Group1 : label = 0","39651299":"### From the plot above, we can see that the clustering is not bad. Now we are going to construct the prediction model with these gruops respectively.","762def3e":"## Preface : This is the further research of my former side project. The connections are below:\nhttps:\/\/www.kaggle.com\/show1997\/side-project-customer-asset-prediction-2\nhttps:\/\/www.kaggle.com\/show1997\/side-project-customer-asset-prediction-1\n\n\n## Introduction :\n### From the previous EDA, it can be seen that some customers have fixed patterns in their purchase behaviors. We believe that these purchase behaviors will be affected by other factors that cannot be easily quantified. These factors are  called** *blocks* **in statistics. In turn, it leads the different buying pattern of everyone. Therefore, we hope to eliminate the influence of block with pattern clustering method. We treat the customer\u2019s monthly asset change pattern as a variable. If the customer\u2019s asset increases or decreases by more than 0.1% of the previous month\u2019s asset, it is regarded as the actual increase or decrease, otherwise it is treated as unchanged, and the number of changes in the asset increase or decrease is calculated (ties, as shown in the figure) . I hope to classify groups with similar behavior patterns with this way.","7d5ce83a":"## Conclusion:\n### The MSE become to 42702741275 from 42736531566. It's not a very significant changing, however, it's still helpful for people who want to chase the further improvement. ","1832e638":"### We can see that some of the above graphics have the same patterns like 57,59,62,69 or 65,72,76.","4887ff78":"## Group2 : label = 1"}}