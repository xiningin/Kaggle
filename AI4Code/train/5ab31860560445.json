{"cell_type":{"a1f385a1":"code","a44a10d3":"code","841145f8":"code","65583fd6":"code","0b818066":"code","362ad238":"code","b1dcd528":"code","57052cd3":"code","f028ac7d":"code","0e1223ee":"code","172d191c":"code","9214fd7f":"code","bff64f0f":"code","63253356":"code","4a8ad6dd":"code","293c6f75":"code","aa4eb1b4":"code","06ca38c7":"code","7b192124":"code","ff6f5bb7":"code","e455c351":"code","2e667c65":"code","94b78426":"code","a79578df":"code","2a3b30ef":"code","7cd8b4df":"code","dff0f019":"code","bb099fae":"code","ade50c58":"code","21dc99c4":"code","2d7a9799":"code","67234108":"code","573a3917":"code","261f2ec2":"code","33ab2d66":"code","924335f3":"code","61e945c6":"code","36d0d251":"code","11450d17":"code","93f0a7b0":"code","7a2527f4":"code","d98ac390":"code","bbfd3e30":"code","32d1eaf5":"code","95cae873":"code","2d96e8f5":"code","0e423eb9":"code","794c40e4":"markdown","5310fd4e":"markdown","f397a8eb":"markdown","5d3dc2bc":"markdown","982c30b1":"markdown","ad06eb57":"markdown","be3978a2":"markdown","0ac85340":"markdown","869ac979":"markdown","26db5a78":"markdown","2bc161cd":"markdown","cc8d6a96":"markdown","443f5415":"markdown","7465bfbf":"markdown","6c9c782a":"markdown","34baa37a":"markdown","42c59e4d":"markdown","d6592d72":"markdown","ec592713":"markdown","3eadc32f":"markdown","87448e3b":"markdown","0dfe6dad":"markdown","26ac40ee":"markdown","da76f2af":"markdown","dfb7ca8f":"markdown","49dabfce":"markdown","0be1ac39":"markdown","f12163cf":"markdown","36115dcd":"markdown","17d47710":"markdown","3cc81dbb":"markdown","68c0b9b6":"markdown","e9cf14ad":"markdown","2b621ebe":"markdown","d5332a9e":"markdown","ab40deb2":"markdown","8159fafd":"markdown","72725128":"markdown","f3fe9512":"markdown","330f6a04":"markdown","3d6060b5":"markdown","330fa798":"markdown","c5718fc4":"markdown","1afcb3ae":"markdown","1d64126e":"markdown"},"source":{"a1f385a1":"import numpy as np\nimport pandas as pd\nimport os\nimport json\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n%matplotlib inline\ninline_rc = dict(mpl.rcParams)","a44a10d3":"# We only use the first 100,000 data in this assignment\nusers = []\nwith open('\/kaggle\/input\/yelp-dataset\/yelp_academic_dataset_user.json') as fl:\n    for i, line in enumerate(fl):\n        users.append(json.loads(line))\n        if i+1 >= 100000:\n            break\ndf = pd.DataFrame(users)\ndf.head()","841145f8":"# Measures of central tendency for given data\ndf.describe()","65583fd6":"# An overarching look at the missing data\n# msno.matrix(df)","0b818066":"# Delete multiple columns from the df\ndf = df.drop([\"user_id\", \"name\"], axis=1)\n# df.head()","362ad238":"# Make column friend_count = number of friends\nfriend_count = [0 for _ in range(df.shape[0])]\nfor i in range(df.shape[0]):\n    friend_count[i] = len(df.loc[i, \"friends\"].split(\",\"))\n    \nfriend_count = pd.DataFrame(friend_count)\n# print(friend_count)","b1dcd528":"# Add column friend count column to main db\ndf['friend_count'] = friend_count\n\n# Drop column friends as not used again\ndf = df.drop([\"friends\"], axis=1)\ndf.head()","57052cd3":"elite_count = [0 for _ in range(df.shape[0])]\nfor i in range(df.shape[0]):\n    elite_count[i] = len(df.loc[i, \"elite\"].split(\",\"))\n    \nelite_count = pd.DataFrame(elite_count)\n# print(elite_count)\ndf['elite_count'] = elite_count  # Add column to df\ndf = df.drop([\"elite\"], axis=1) # Drop elite\ndf.head()","f028ac7d":"df['yelping_since'] = pd.to_datetime(df['yelping_since'])\n\ndf['yelp_since_YRMO'] = df['yelping_since'].map(lambda x: 100*x.year + x.month)\ndf['yelp_since_year'] = df['yelping_since'].dt.year\n\ndf.head()","0e1223ee":"# Column to store whether compliment has been tagged\ntagged_compliment = [0 for _ in range(df.shape[0])]\nfor i in range(df.shape[0]):\n    if sum(df.iloc[i, 7:18].values) > 0:\n        tagged_compliment[i] = 1\n        \ntagged_compliment = pd.DataFrame(tagged_compliment)\ndf['tagged_compliment'] = tagged_compliment","172d191c":"# Plot count vs yearmonth, to see the distribution\nplt.figure(figsize=(18,4))\nyrmo = pd.to_datetime(df['yelp_since_YRMO'], format='%Y%m')\nyrmo = pd.DataFrame(yrmo)\nyrmo.yelp_since_YRMO.value_counts().plot(kind='line')","9214fd7f":"plt.figure(figsize=(12,2))\nyear = pd.to_datetime(df['yelp_since_year'], format='%Y')\nyear = pd.DataFrame(year)\nyear.yelp_since_year.value_counts().plot(kind='line')","bff64f0f":"# Time Period 201201-201212 | 201301-201312 | 201401-201412\nplt.figure(figsize=(20,2))\nperiod_12 = yrmo[yrmo.yelp_since_YRMO >= pd.to_datetime(201201, format='%Y%m')]\nperiod_12 = period_12[period_12.yelp_since_YRMO <= pd.to_datetime(201212, format='%Y%m')]\nperiod_12 = pd.to_datetime(period_12.yelp_since_YRMO, format='%Y%m')\n\nperiod_13 = yrmo[yrmo.yelp_since_YRMO >= pd.to_datetime(201301, format='%Y%m')]\nperiod_13 = period_13[period_13.yelp_since_YRMO <= pd.to_datetime(201312, format='%Y%m')]\nperiod_13 = pd.to_datetime(period_13.yelp_since_YRMO, format='%Y%m')\n\nperiod_14 = yrmo[yrmo.yelp_since_YRMO >= pd.to_datetime(201401, format='%Y%m')]\nperiod_14 = period_14[period_14.yelp_since_YRMO <= pd.to_datetime(201412, format='%Y%m')]\nperiod_14 = pd.to_datetime(period_14.yelp_since_YRMO, format='%Y%m')\n\nplt.subplot(131)\nperiod_12.value_counts().plot(kind='line', linewidth=2, color='b')\nplt.subplot(132)\nperiod_13.value_counts().plot(kind='line', linewidth=2, color='b')\nplt.subplot(133)\nperiod_14.value_counts().plot(kind='line', linewidth=2, color='b')\nplt.show()","63253356":"# Time Period 201501-201512 | 201601-201612 | 201701-201712\nplt.figure(figsize=(20,2))\nperiod_15 = yrmo[yrmo.yelp_since_YRMO >= pd.to_datetime(201501, format='%Y%m')]\nperiod_15 = period_15[period_15.yelp_since_YRMO <= pd.to_datetime(201512, format='%Y%m')]\nperiod_15 = pd.to_datetime(period_15.yelp_since_YRMO, format='%Y%m')\n\nperiod_16 = yrmo[yrmo.yelp_since_YRMO >= pd.to_datetime(201601, format='%Y%m')]\nperiod_16 = period_16[period_16.yelp_since_YRMO <= pd.to_datetime(201612, format='%Y%m')]\nperiod_16 = pd.to_datetime(period_16.yelp_since_YRMO, format='%Y%m')\n\nperiod_17 = yrmo[yrmo.yelp_since_YRMO >= pd.to_datetime(201701, format='%Y%m')]\nperiod_17 = period_17[period_17.yelp_since_YRMO <= pd.to_datetime(201712, format='%Y%m')]\nperiod_17 = pd.to_datetime(period_17.yelp_since_YRMO, format='%Y%m')\n\nplt.subplot(131)\nperiod_15.value_counts().plot(kind='line', linewidth=2, color='b')\nplt.subplot(132)\nperiod_16.value_counts().plot(kind='line', linewidth=2, color='b')\nplt.subplot(133)\nperiod_17.value_counts().plot(kind='line', linewidth=2, color='b')\nplt.show()","4a8ad6dd":"# Drop yelping_since column from df as not used again, and we already store lower granularity data in year & yrmo\ndf = df.drop([\"yelping_since\"], axis=1)","293c6f75":"plt.figure(figsize=(16,3))\nsns.distplot(df.average_stars)","aa4eb1b4":"raters_below_3 = len(df.loc[df.average_stars <= 3])\nprint(\"Users who rate <= 3 Avg Stars: {:0.02%}\".format(raters_below_3\/df.shape[0]))","06ca38c7":"low_raters = len(df.loc[df.average_stars < 4])\nhigh_raters = len(df.loc[df.average_stars >= 4])\nprint(\"Low Raters, <4 Avg Stars: {:0.02%}\".format(low_raters\/df.shape[0]))\nprint(\"High Raters >=4 Avg Stars: {:0.02%}\".format(high_raters\/df.shape[0]))","7b192124":"# Make a column raters, which is 1 for high raters (>=4 avg stars), and 0 for the rest (<4)\n\nraters = [0 for _ in range(df.shape[0])]\nfor i in range(df.shape[0]):\n    if df.loc[i,\"average_stars\"] >= 4:\n        raters[i] = 1\n#     elif float(3) <= df.loc[i,\"average_stars\"] < float(4):\n#         rating[i] = \"M\"\n#     else:\n#         raters[i] = \"H\"\n# Add column to main df\ndf['raters'] = raters","ff6f5bb7":"plt.figure(figsize=(16,3))\nplt.subplot(121)\nsns.distplot(df.review_count)\n\n# Taking a Normal Distribution as review_count heavily skewed\nplt.subplot(122)\nsns.distplot(df.review_count.apply(np.log1p))","e455c351":"plt.figure(figsize=(16,3))\nplt.subplot(121)\nsns.distplot(df.friend_count)\n\n# Taking a Normal Distribution as friend_count heavily skewed\nplt.subplot(122)\nsns.distplot(df.friend_count.apply(np.log1p))","2e667c65":"plt.figure(figsize=(24,3))\n\nplt.subplot(141)\nsns.distplot(df.fans)\n\n# Taking a Normal Distribution as fans heavily skewed\nplt.subplot(142)\nsns.distplot(df.fans.apply(np.log1p))\n\nplt.subplot(143)\nsns.distplot(df.elite_count)\n\n# Taking a Normal Distribution as elite_count heavily skewed\nplt.subplot(144)\nsns.distplot(df.elite_count.apply(np.log1p))","94b78426":"useful_reviews = len(df.loc[df.useful > 0])\nprint(\"People who leave useful reviews: {:0.0%}\".format(useful_reviews\/df.shape[0]))","a79578df":"plt.figure(figsize=(16,3))\nplt.subplot(121)\nsns.distplot(df.useful)\n\n# Taking a Normal Distribution as useful count heavily skewed\nplt.subplot(122)\nsns.distplot(df.useful.apply(np.log1p))","2a3b30ef":"from sklearn.preprocessing import StandardScaler\n\n# Don't scale columns: yelp_since_year, yelp_since_YRMO, elite\nfeatures = ['review_count', 'useful', 'funny', 'cool', 'fans',\n       'average_stars', 'compliment_hot', 'compliment_more',\n       'compliment_profile', 'compliment_cute', 'compliment_list',\n       'compliment_note', 'compliment_plain', 'compliment_cool',\n       'compliment_funny', 'compliment_writer', 'compliment_photos',\n       'friend_count', 'elite_count', 'raters', 'tagged_compliment']\nx = df.loc[:, features]\nx = StandardScaler().fit_transform(x)","7cd8b4df":"# Adding column names back to data, and converting ndarray back to datafram obj\ndf_train = pd.DataFrame(x, columns=features)\ndf_train.head()","dff0f019":"# Eyebaling central tendency, and qc-ing scaled values\ndf_train.describe()","bb099fae":"# Covariance matrix of scaled data\ncov = df_train.cov()\ncov.style.background_gradient(cmap='coolwarm').set_precision(2)","ade50c58":"# Correlation matrix of unscaled original data which includes, elite count, yrmo features etc\n# Idea is to see which features are correlated and can be combined (PCA) together to build a hypothesis\/cluster\n\ncorr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm').set_precision(2)","21dc99c4":"df_train.columns","2d7a9799":"df_review = df_train.loc[:, ['funny', 'cool', 'useful']]  # Make df of these 3 features\npca = PCA(n_components=1)\nreview_feedback = pca.fit_transform(df_review)\nreview_feedback = pd.DataFrame(data=review_feedback)","67234108":"print('PCA Components:', pca.components_)\nprint('Ratio of Variance Explained:', pca.explained_variance_ratio_ )","573a3917":"df_compliments = df_train.loc[:, ['compliment_hot', 'compliment_more', 'compliment_profile',\n       'compliment_cute', 'compliment_list', 'compliment_note',\n       'compliment_plain', 'compliment_cool', 'compliment_funny',\n       'compliment_writer', 'compliment_photos']]\npca = PCA(n_components=1)\ncompliments_feedback = pca.fit_transform(df_compliments)\ncompliments_feedback = pd.DataFrame(data=compliments_feedback)","261f2ec2":"print('PCA Components:', pca.components_)\nprint('Ratio of Variance Explained:', pca.explained_variance_ratio_ )","33ab2d66":"df_popularity = df_train.loc[:, ['fans', 'friend_count']]\npca = PCA(n_components=1)\npopularity_feedback = pca.fit_transform(df_popularity)\npopularity_feedback = pd.DataFrame(data=popularity_feedback)","924335f3":"print('PCA Components:', pca.components_)\nprint('Ratio of Variance Explained:', pca.explained_variance_ratio_ )","61e945c6":"df_active = df_train.loc[:, ['review_count', 'elite_count']]\npca4 = PCA(n_components=1)\nactive_feedback = pca4.fit_transform(df_active)\nactive_feedback = pd.DataFrame(data=active_feedback)","36d0d251":"print('PCA Components:', pca.components_)\nprint('Ratio of Variance Explained:', pca.explained_variance_ratio_ )","11450d17":"from yellowbrick.cluster import KElbowVisualizer\ncomp_star = pd.concat([compliments_feedback, df.loc[:,'average_stars']], axis=1)\nmodel = KElbowVisualizer(KMeans(), k=10, metric='calinski_harabasz', timings=False)\nmodel.fit(comp_star)\nmodel.show()","93f0a7b0":"# Reset matplotlib parameters, changed by elbow visualizer\nmpl.rcParams.update(mpl.rcParamsDefault)","7a2527f4":"model = KMeans(n_clusters=3)\nmodel.fit(comp_star)\nall_predictions = model.predict(comp_star)\ncentroids = model.cluster_centers_\n\nplt.figure(figsize=(14, 3))\nplt.scatter(comp_star.iloc[:,0].values, comp_star.iloc[:,1].values, c=all_predictions)\nplt.scatter(centroids[:, 0], centroids[:, 1], marker='*', c='#0f0f0f')\nplt.xlabel('Compliments Feedback')\nplt.ylabel('Average Stars')\nplt.show()","d98ac390":"act_star = pd.concat([active_feedback, df.loc[:,'average_stars']], axis=1)\nmodel = KMeans(n_clusters=2)\nmodel.fit(act_star)\nall_predictions = model.predict(act_star)\ncentroids = model.cluster_centers_\n\nplt.figure(figsize=(14, 3))\nplt.scatter(act_star.iloc[:,0].values, act_star.iloc[:,1].values, c=all_predictions)\nplt.scatter(centroids[:, 0], centroids[:, 1], marker='*', c='#0f0f0f')\nplt.xlabel('Active Feedback (Review Count, Elite Status Count)')\nplt.ylabel('Average Stars')\nplt.show()","bbfd3e30":"pop_stars = pd.concat([popularity_feedback, df.loc[:,'average_stars']], axis=1)\nmodel = KMeans(n_clusters=3)\nmodel.fit(pop_stars)\nall_predictions = model.predict(pop_stars)\ncentroids = model.cluster_centers_\n\nplt.figure(figsize=(14, 3))\nplt.scatter(pop_stars.iloc[:,0].values, pop_stars.iloc[:,1].values, c=all_predictions)\nplt.scatter(centroids[:, 0], centroids[:, 1], marker='*', c='#0f0f0f')\nplt.xlabel('Popularity Feedback (Friends, Fans)')\nplt.ylabel('Average Stars')\nplt.show()","32d1eaf5":"rev_pop = pd.concat([review_feedback, popularity_feedback], axis=1)\nprint(\"Correlation: {:0.02%}\".format((rev_pop.corr()).iloc[0,1]))","95cae873":"model = KMeans(n_clusters=3)\nmodel.fit(rev_pop)\nall_predictions = model.predict(rev_pop)\ncentroids = model.cluster_centers_\n\nplt.figure(figsize=(14, 3))\nplt.scatter(rev_pop.iloc[:,0].values, rev_pop.iloc[:,1].values, c=all_predictions)\nplt.scatter(centroids[:, 0], centroids[:, 1], marker='*', c='#0f0f0f')\nplt.xlabel('Review Feedback (useful, funny, cool)')\nplt.ylabel('Popularity Feedback (fans, friends)')\nplt.show()","2d96e8f5":"rev_act = pd.concat([review_feedback, active_feedback], axis=1)\nprint(\"Correlation: {:0.02%}\".format((rev_act.corr()).iloc[0,1]))","0e423eb9":"model = KMeans(n_clusters=4)\nmodel.fit(rev_act)\nall_predictions = model.predict(rev_act)\ncentroids = model.cluster_centers_\n\nplt.figure(figsize=(12,4))\nplt.scatter(rev_act.iloc[:,0].values, rev_act.iloc[:,1].values, c=all_predictions)\nplt.scatter(centroids[:, 0], centroids[:, 1], marker='*', c='#0f0f0f')\nplt.xlabel('Review Feedback (useful, funny, cool)')\nplt.ylabel('Active Feedback (review, elite counts)')","794c40e4":"### 1. Read Data","5310fd4e":"**2.1 Drop columns name & user_id**\n###### Could have dropped yelping_since and elite as well, but saved for later use","f397a8eb":"review_feedback feature, exlains an overwhelming majority of variance ~99%","5d3dc2bc":"*Much more indepth analyses perfomed in the EDA (Exploratory Data Analyses) script, all that skipped here to keep within the confines of this scipts' focus, which is Dimensionality Reduction and KMeans Clustering*","982c30b1":"*--- End ---*","ad06eb57":"2.2.1 Column for friend count","be3978a2":"**7.1 Review Feedback (useful, funny, cool) vs Avg Stars Ratings**","0ac85340":"3.3 Distributions and corresponding analyses","869ac979":"#### 2.2 Add columns \n1. Column for number of friends\n2. Column to keep count of number of years of elite status\n3. Column to keep user since YR, and user since YRMO","26db5a78":"2.2.2 Make column Elite Status Count (num of years), add it to db","2bc161cd":"**6.2 Principal Component 2**\n> compliments_feedback:  features include all tagged compliments","cc8d6a96":"**Insights from Correlation and Covariance Matrix:**\n> 1. Review count is correlated with useful-funny-cool and elite_count (Hyp: elite users review more)\n> 2. Useful-Funny-Cool are highly coorelated, and show high covariance\n> 3. Fan counts are correlated with Freinds count ~75% (Hyp: popularity measure)\n> 4. Moderate correlation b\/w all the compliment tags (Hyp: Logically can be combined)","443f5415":"Insight:\n> Lets call each centroid\/cluster, low_complimented, moderately_complimented, highly_complimented users.\n> 1. low_complimented users with low count of compliments_feedback, or the leftmost centroid\/cluster depict that users who get low\/occasional compliments, rate across the spectrum of average ratings, but mostly staying at the center (3.5-4 avg).\n> 2. moderately_complimented users, who have a higher numder of compliments, rate in a stricter margin of 3-4.5 star avg rating, with majority at 4, which means users with moderate compliments, rate more highly on average. \n> 3. highly_complimented users, are low in numbers, as opposed to others, and if we assume their sample sparsity is representative of the population, then we can say they also on average rate highly or above 4 stars in most cases, but show wider variance as opposed to moderately complimented users. \n\n> Using Assumption 1: That sample sparsity is represenattive of population, and Assumption 2: Normal Distribution of overall avg ratings is not accounted by Bessels Correction, we can say that if a user has moderate compliments, then we can expect them to show a tight variance of high avg ratings.","7465bfbf":"> 1. Majority people don't have yelp friends (or haven't connected to to friends on yelp)\n> 2. Those that have freinds on yelp, have usually between 2-5 freinds","6c9c782a":"**7.2 Active Feedback (review count, elite status achieved count) vs Avg Stars Ratings**","34baa37a":"> 1. Majority of people of have written lower number of reviews\n> 2. High number of reviews are very low <0.05% of populations\/users (max reviewer has 12,390 reviews!)\n> 3. From the people who actually review, high majority lie b\/w 2-4 reviews","42c59e4d":"Insight:\n> Lets call each centroid\/cluster (left to right), low_target_seg, mid_target_seg, high_target_seg users.\n\n\n> 1. low_target_seg users have review feedback extremely low, and as all reviews are highly correlated (~99%), we can say they have reveies tagged useful least number of times, and also score low on the popularity index. From a buisness perspective, we may consider them as last to approach for targetted advertisement via Yelp ads or in other ways.\n> 2. mid_target_seg users, are moderately targettable segment, as they have some amount of reviews marked as useful, and have relatively speaking a fair amount of poularity in terms of number of fans and friends. We also show via correlation (not causation) that users with some helpful reviews have some popularity.\n> 3. high_target_seg, or very useful reviewers,they have a high number of reviews that were considered useful by fellow members, and have a relatively large fan and freind following. As the user number is low, reviews usefulness is high, and popularity is also high (thereby increasing review visibility), these may be targetted by Yelp Service Providers for high volume, or high worth advertisements. \n\n\n> Keeping in mind all the assumptions mentioned in previous insights, we may say that useful or high review feedback index users have larger followings.","d6592d72":"## Yelp Users Data - Clustering & IDA\n*- Aditya Gupta*\n\n> 1. Read Data\n> 2. Add and Drop Columns\n> 3. Initial Data Analysis (IDA)\n> 4. Scale Data to prep for PCA, & for comparison\n> 5. Compare Covariance and Correlation values for data\n> 6. Dimansionality Reduction (using PCA)\n> 7. KMeans Clustering on Data","ec592713":"**6.3 Principal Component 3**\n> popularity_feedback:  features include fans, freind_count","3eadc32f":"**6.1 Principal Component 1**\n> review_feedback:  features include useful, funny, and cool","87448e3b":"Insight:\n> Lets call each centroid\/cluster (left to right), poor_reviewers, avg_reviewers, good_reviewers, and great_reviewers.\n\n> Correlation calculated earlier is ~50%. Important metric used in insights.\n\n> It is interesting to see that Review Feedback is very poorly correlated with User Activity or active feedback. If we ignore, poor_reviewers clusters, which essentially just shows not active and not useful review writers, we can focus on other 3 segments. If we see the broad distribution or the centroid positions for other 3 segments we notice, that without a significant change in active feedback (more apparent in good & great reviewers), there is a rather discrenable differnce in thier review usefulness\/feedback. There are many good_reviewrs who are very active but have not scored highly on review usefullness. Whereas great_reviewers with majoritarily similar spreads on active feedback (y-axis) vary in a wide range across thier usefullness in terms of writing reviews. \n\n> If we just consider the range of good and great reviewers on active\/y_axis (which is not a good metric by itself, but highlights the low correlation), we see that good_reviewers segments have a wider range of activity metrics but perform comparitevly poor on review feedback metrics. \n\n> Furthermore, in just the great_reviewers spread on review\/x-axis, similar levels of \"activity\" also produces wast amounts of varying review usefullness (or greatness?). Since, Review Feedback consists of highly correlated review_useful_count and Active Feedback also consists of correlated review_count feature, one might further (an untested, non Hypothesis verified, bead on sample data) statement that greatness (review usefulness) has alsmot little to do with number of reviews one writes.\n\nInteresting Aside: Could one misquote Shakespeare and say chance of (being born great, having geatness thrust upon them) > ability to achieve greatness? ","0dfe6dad":"2.2.3 From yelping_since make columns for year and yearmonth (YRMO)","26ac40ee":"### 3. Initail Data Analysis (IDA)\n\n> 1. Time series analysis\n> 2. Avg Stars Rating analysis\n> 3. Feature Distributions","da76f2af":"**7.4 Review Feedback (funny, cool, useful) vs Popularity Feedback (Fan Count, Friends Count)**","dfb7ca8f":"Insight:\n> Lets call each centroid\/cluster, less_active, and more_active users.\n> 1. less_active users with lower count of reviews and who have achieved elite status less number of times, again rate across the spectrum, and show higher variance as opposed to more_active users. The funnel of the cluster is tigher and more widely spread than more_active users. \n> 2. more_active users, or ones with higher review count and more number of elite statuses, have almost non-existent low average ratings as opposed to less-active users, and as number amount of active_feedback increases, users' averages start accumulating towards the center at 3.5-4 avg star ratings, even for a very high amount of activity >20.\n\n> Using assumptions from 7.1, we can tentatively say (can't be sure w\/o chi square, or other hypothesis testing methodologies), that if we see a yelp yser who is very active, then their average rating may fall somewhere between 3.5 - 4. It is important to note, that the normal distribution of ratings also lie at the center, so we dont want to read too much into the data, but as very high active_feedback users lie in the center, we may relatively safely say that there is a tendency for average ratings to fall at 3.5-4range, which is actually a known observation in online ratings. ","49dabfce":"Insights:\n> 1.  Majority of people, >85% rate (or have avg stars) yelp listings above 3 stars\n     *  The above could be deciphered in many ways, like data skewed towards higher avg raters,or\n     *  Most of the people rate things higher on yelp, or\n     *  People tend to only rate when they find something good (weak hypothesis)\n> 2.  Very high raters (>4 avg ratings) are maginally lower ~42%\n    ","0be1ac39":"Insights:\n> 1. For majority of the years, we see max ids, or max usage in months May - August\n> 2. Winter months, starting October usually see decline in new user or user usage\n> 3. Less data (or users) available for 2016 and 2017, though years show similar peaks, the value of maximas and minimas are low comparitively","f12163cf":"Insight:\n> Lets call each centroid\/cluster, less_popular, moderately_popular, paris_hilton users.\n> 1. less_popular users with lower number of fans and freinds, tend to extremely uniformly rate across the spectrum, as opposed to any other user block. \n> 2. moderately_popular users, with rising popularity tend to start diverging from the behavior of less popular users. As the centroid lies smack dab in the middle, yet lower end of the popularity matrix, showing that mode_popular users also have a tendency to have avg ratings more or less across the board, but some do always vote highly (>4 or >5 are there)\n> 3. paris_hilton users, who rate highly on the popularity index do not as opposed to previous 2 segments, have large high avg ratings, but lie majoritarily in the center.\n\n> Using assumptions from 7.1, as w\/o hypothesis testing, and not acoounting for the implicit central tendecy the ratings itself, we may say that if a user is less popular then they may have avg raatings across the borad, but if they are super popular then we can expect them to them have ratings in middel brackett. ","36115dcd":"### 6. Dimensionality Reduction using PCA","17d47710":"### 2. Preprocessing\n1. Drop columns not required\n2. Make new colums from existing data ","3cc81dbb":"#### No significant missing Data - thats good!","68c0b9b6":"### 7. Clustering","e9cf14ad":"> 1. Very low number of people have have fans on yelp\n> 2. Thos that have fans on yelp, usually have on avg 1-2 fans\n> 3. Vast majority of people have never achieved elite status\n> 4. Those who have been elite for multiple years, are also very few (elite status is definitely elusive!)","2b621ebe":"**Using Elbow method to find ideal k number of clusters**\n* Score used: Calinski Harabasz\n* Ref: https:\/\/www.scikit-yb.org\/en\/latest\/api\/cluster\/elbow.html##targetText=K%2Dmeans%20is%20a%20simple,number%20(k)%20of%20clusters.&targetText=The%20elbow%20method%20runs%20k,average%20score%20for%20all%20clusters","d5332a9e":"> 1. ~94% of people have left reviews tagged useful\n> 2. However, people with high count of useful reviews is extremely low\n> 3. Out of those 94%, most users tend to have only 2-6 reviews considered\/tagged useful \n> 4. Metrics similar to ones for funny, and cool, so plots for those skipped here","ab40deb2":"**7.3 Popularity Feedback (Friend Count, Fans Count) vs Avg Stars Ratings**","8159fafd":"### 4. Scaling Feature Values\nScaling values for easy comparision, and for PCA\n> * https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.StandardScaler.html\n> * https:\/\/scikit-learn.org\/stable\/auto_examples\/preprocessing\/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py","72725128":"3.1 Time Series analysis of User Daata","f3fe9512":"**6.4 Principal Component 4**\n> active_feedback:  features include review_count, elite_count","330f6a04":"Insight:\n> For the given data max ids are form years 2010 to 2016","3d6060b5":"**K-cluster value extraction only showed once, as repeated runs make the script run slow**","330fa798":"3.2 Avg Stars rating Analysis","c5718fc4":"> * Ideal compariosn would be 3 way split, b\/w Low-Med-High, but data is skewed towards people with high avg rating\n> * value = 4 chosen as cut off, beacuse count of values with avg rating <= 3 is only ~12%","1afcb3ae":"**7.5 Review Feedback (funny, cool, useful) vs Active Feedback (Review Count, Elite Status Count)**","1d64126e":"### 5. Measuring simalrity between fetaures\n\nComparing covariance for scaled values and correlations for unscaled original df"}}