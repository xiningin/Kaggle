{"cell_type":{"90099c9e":"code","f98e09f7":"code","aa0f145a":"code","fa84778b":"code","7ec6e8b5":"code","a49b3937":"code","4ea42bfd":"code","f160458d":"code","4dc3d588":"code","6a9cad5a":"code","c7cf304b":"code","bdff3164":"code","fed497ae":"code","3858b5e2":"code","3e0f0798":"code","ec55f5ef":"code","466720d2":"code","ede6a256":"code","abdfb94a":"code","a768cdc6":"code","7393b8d4":"code","b3cb0e01":"markdown","33d2fbc2":"markdown","275c519b":"markdown","30868f00":"markdown","b0b68634":"markdown","97ec4e50":"markdown","020b716a":"markdown","9bace9a1":"markdown","6ce572a1":"markdown"},"source":{"90099c9e":"######################\n# Import Libraries and loading dataset\n######################\n\n!pip install openpyxl\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nfrom yellowbrick.cluster.elbow import kelbow_visualizer\nimport seaborn as sns\nimport itertools\nimport missingno as msno\nimport plotly.express as px\nimport datetime as dt\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 20)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.width', 170)\n\n\"import warnings filter\"\nfrom warnings import simplefilter\n\n\"ignore all future warnings\"\nsimplefilter(action='ignore', category=FutureWarning)","f98e09f7":"# load dataset\n\ndef load():\n    data = pd.read_excel(\"..\/input\/online-retail2\/online_retail_II.xlsx\", sheet_name=\"Year 2010-2011\")\n    return data\n\ndf= load()","aa0f145a":"######################\n# EDA\n######################","fa84778b":"\"null values visualization\"\nmsno.bar(df)","7ec6e8b5":"df.isnull().sum()","a49b3937":"\"drop null values\"\ndf.dropna(inplace=True)\n\n\"null values check\"\ndf.isnull().sum()\n\n\"number of unique product\"\ndf[\"StockCode\"].nunique()\n\n\"unique customers\"\ndf[\"Customer ID\"].nunique()\n\n\"best sellers\"\ndf.groupby([\"StockCode\",\"Description\"])[\"StockCode\"].count().sort_values(ascending=False).head(20)\n\n\"remove cancelled sales\"\ndf = df[~df[\"Invoice\"].str.contains(\"C\",na=False)]\n\n\"quantity and price must be different from 0\"\ndf = df[(df['Quantity'] > 0)]\ndf = df[(df['Price'] > 0)]\n\n\"total income per invoice\"\ndf[\"TotalPrice\"] = df[\"Quantity\"] * df[\"Price\"]","4ea42bfd":"######################\n# Creating RFM Metrics\n######################\n\n\"Recency: How recently a customer has made a purchase\"\n\"T: The age of the client in the company. Weekly (for every single user)\"\n\"Frequency: How often a customer makes a purchase\"\n\"Monetary: How much money a customer spends on purchases\"\n\ntoday_date = dt.datetime(2011,12,11)\n\n\nrfm = df.groupby(\"Customer ID\").agg({\"InvoiceDate\": [lambda date: (date.max() - date.min()).days,\n                                                    lambda date: (today_date - date.min()).days],\n                                    \"Invoice\": lambda num: num.nunique(),\n                                    \"TotalPrice\": lambda TotalPrice: TotalPrice.sum()})\n\n# rename columns\nrfm.columns = rfm.columns.droplevel(0)\nrfm.columns = [\"recency\",\"T\",\"frequency\",\"monetary\"]\nrfm.head()","f160458d":"######################\n# K-means\n######################\n\n# Distance based methods effect by outliers, before creating model we should make standardization to dataset.\n\nrfmkmeans = rfm.copy()\n\nsc = MinMaxScaler((0, 1))\nx_sc = sc.fit_transform(rfmkmeans)\nrfm_sc = pd.DataFrame(x_sc)\nrfm_sc.head()","4dc3d588":"# Model creating, we are trying to optimizing with giving cluster numbers manually\n\nkmeans = KMeans(n_clusters=5)\nk_fit = kmeans.fit(rfm_sc)","6a9cad5a":"\"cluster that given\"\nk_fit.n_clusters\n\n\"observation units\"\nk_fit.cluster_centers_\n\n\"represents cluster of customers \"\nk_fit.labels_\n\n\"SSD (sum of square distance)\"\nk_fit.inertia_","c7cf304b":"# Cluster Visualization\n\nk_means = KMeans(n_clusters=2).fit(rfm_sc)\nkumeler = k_means.labels_\ntype(rfm_sc)\nrfm_sc = pd.DataFrame(rfm_sc)\n\nplt.scatter(rfm_sc.iloc[:, 1],\n            rfm_sc.iloc[:, 3],\n            c=kumeler,\n            s=50,\n            cmap=\"viridis\")\nplt.show()\n\n# marking the centers\nmerkezler = k_means.cluster_centers_\n\n","bdff3164":"\"show center and clusters together\"\nplt.scatter(rfm_sc.iloc[:, 1],\n            rfm_sc.iloc[:, 3],\n            c=kumeler,\n            s=50,\n            cmap=\"viridis\")\n\nplt.scatter(merkezler[:,1],\n            merkezler[:, 3],\n            c=\"red\",\n            s=200,\n            alpha=0.8)\nplt.show()","fed497ae":"# Determining optimum cluster number\n\nkmeans = KMeans()\nssd = []\nK = range(1, 30)","3858b5e2":"\"get best parameter with elbow method\"\nfor k in K:\n    kmeans = KMeans(n_clusters=k).fit(rfm_sc)\n    ssd.append(kmeans.inertia_)\n","3e0f0798":"# first way to catch optimum cluster number\nplt.plot(K, ssd, \"bx-\")\nplt.xlabel(\"Distance residual summary for different k values\")\nplt.title(\"Elbow Method for Optimum Cluster\")\nplt.show()","ec55f5ef":"# Second way\nkmeans = KMeans()\nelbow = KElbowVisualizer(kmeans, k=(2, 20))\nelbow.fit(rfm_sc)\nelbow.show();","466720d2":"# results of how many cluster should be\nelbow.elbow_value_","ede6a256":"################################\n# Creating final clusters\n################################\n\nkmeans = KMeans(n_clusters=elbow.elbow_value_).fit(rfm_sc)\nkumeler = kmeans.labels_","abdfb94a":"pd.DataFrame({\"Customers\": rfmkmeans.index, \"Segments\": kumeler})\n\nrfmkmeans[\"cluster_no\"] = kumeler\n\n\nrfmkmeans.groupby(\"cluster_no\").agg({\"cluster_no\": \"count\"})\nrfmkmeans.groupby(\"cluster_no\").agg(np.mean)","a768cdc6":"\"observations that cluster number is 5\"\nrfmkmeans[rfmkmeans[\"cluster_no\"] == 5]\n\n\"observations that cluster number is 2\"\nrfmkmeans[rfmkmeans[\"cluster_no\"] == 2]","7393b8d4":"rfmkmeans.groupby(\"cluster_no\").agg({\"monetary\":\"mean\"})\nrfmkmeans.groupby(\"cluster_no\").agg({\"frequency\":\"mean\"})\nrfmkmeans.groupby(\"cluster_no\").agg({\"T\":\"mean\"})\nrfmkmeans.groupby(\"cluster_no\").agg({\"recency\":\"mean\"})\nrfmkmeans.groupby(\"cluster_no\").agg({\"mean\"})","b3cb0e01":"![large.png](attachment:a18959c6-1c3b-432d-bbff-ac51fd5c8a6a.png)","33d2fbc2":"![1.JPG](attachment:59deb2b6-d9b0-4961-89cc-526cb7ac0df7.JPG)![2.JPG](attachment:205fcc35-b2b0-4a85-816f-03132892010f.JPG)![3.JPG](attachment:50a2fb25-ea1d-4d20-aa56-5d65b649f0cf.JPG)![4.JPG](attachment:eacb37a1-ec39-4d95-a395-f0d4b9a12d7e.JPG)![5.JPG](attachment:a3730c66-6624-44b4-baa7-6cb40ba930e7.JPG)","275c519b":"### K-means is a centroid-based algorithm, or a distance-based algorithm, where we calculate the distances to assign a point to a cluster. In K-Means, each cluster is associated with a centroid.\n\n### The main objective of the K-Means algorithm is to minimize the sum of square distances between the points and their respective cluster centroid.\n\n","30868f00":"#### for visualization:\n\n#### https:\/\/datastudio.google.com\/s\/uOYu5UoAcjc","b0b68634":"## **Dataset story**\n\n### *Online retail-II dataset which is online retail store originally from England includes sales between 01-12-2009\/09-12-2011*\n\n## **Variables**\n\n### *InvoiceNO: Invoice Code: if this code starts with C then it means transaction is cancelled*\n### *StockCode: Product Quantity : Unique number for every product*\n### *Description: Product Name*\n### *Quantity: Product Number : Indicates how many product sales in invoices*\n### *InvoiceDate: Invoice Date*\n### *UnitPrice: (Pound)*\n### *CustomerID: Unique customer number*\n### *Country*\n\n## **Task**\n\n### *Customer segmentation with K-means based on RFM metrics*","97ec4e50":"#### Source:\n\n#### [https:\/\/www.analyticsvidhya.com\/blog\/2019\/08\/comprehensive-guide-k-means-clustering\/](http:\/\/)","020b716a":"# What is K-means clustering? ","9bace9a1":"\n### *Step 1: Choose the number of clusters k*\n#### The first step in k-means is to pick the number of clusters, k.\n\n\n### *Step 2: Select k random points from the data as centroids*\n#### Next, we randomly select the centroid for each cluster. Let\u2019s say we want to have 2 clusters, so k is equal to 2 here. We then randomly select the centroid:\n\n### *Step 3: Assign all the points to the closest cluster centroid*\n#### Once we have initialized the centroids, we assign each point to the closest cluster centroid:\n\n### *Step 4: Recompute the centroids of newly formed clusters*\n#### Now, once we have assigned all of the points to either cluster, the next step is to compute the centroids of newly formed clusters:\n\n### *Step 5: Repeat steps 3 and 4*\n#### We then repeat steps 3 and 4. The step of computing the centroid and assigning all the points to the cluster based on their distance from the centroid is a single iteration","6ce572a1":"# **Customer Segmentation with K-means**\n\n\n"}}