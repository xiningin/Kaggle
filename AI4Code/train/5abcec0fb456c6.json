{"cell_type":{"dae2c2e8":"code","91c6b936":"code","ba872c00":"code","849b1792":"code","1d5ff24b":"code","d19d7b9f":"code","6cd86647":"code","82d519b9":"code","97407fff":"code","c09134f3":"code","af8701eb":"code","c84b3c82":"code","02a8dd33":"code","02e65e60":"code","8a04b16e":"code","78320026":"code","5feadfd7":"code","4c378b8e":"code","2ca6553e":"code","7d38e668":"code","3a6ce28e":"code","2a05b871":"code","8e531083":"code","e495b679":"code","1cc86e93":"code","99b8415c":"code","32af048d":"code","acec9725":"code","d1d1df45":"code","9942696d":"code","688410dc":"code","5c018c55":"code","85e60624":"code","c271f463":"code","2b504ea3":"code","8e79bb30":"code","06bd8352":"code","f7e93871":"code","bb32bd9f":"code","2f582e05":"code","cd7d37a9":"code","2a18ab70":"code","60f50927":"code","0dc649e0":"code","d1f2e0c3":"code","9143d459":"code","32d01d0d":"code","083c0a75":"code","96d29b20":"code","28bd3d0e":"code","0e6f44e0":"code","a3d5a18d":"code","debca10a":"code","f65dbf92":"code","5f2a5842":"code","9df19285":"code","2a4038a8":"code","20f47efe":"code","ee714a36":"code","4a2f5a47":"code","40de2e09":"code","68acd573":"code","91d3d477":"code","0a30468d":"code","3cf2741e":"code","9570b408":"code","b4d6293f":"code","c84616f7":"code","ebecbb91":"code","e036bef7":"code","fe7c47b7":"code","519e9404":"code","c14940b7":"code","26345b19":"code","a0431fbd":"code","44294849":"code","eaa72a4a":"markdown","77a5a731":"markdown","fa1304ab":"markdown","2c892892":"markdown","30002cb9":"markdown","b38033a2":"markdown","61d98992":"markdown","2c5cd248":"markdown","22e7a9a9":"markdown","4134bddd":"markdown","919abefa":"markdown","8aa602ae":"markdown","f9063b47":"markdown","26b2d253":"markdown","f5f61ccd":"markdown","aa648c5e":"markdown","403a8ed1":"markdown","ad63d9c1":"markdown","83785c00":"markdown","0117d7b5":"markdown","7c33eabd":"markdown","063392bc":"markdown"},"source":{"dae2c2e8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","91c6b936":"!unzip \/kaggle\/input\/restaurant-revenue-prediction\/test.csv.zip -d test","ba872c00":"!unzip \/kaggle\/input\/restaurant-revenue-prediction\/train.csv.zip -d train","849b1792":"import pandas as pd \n\ntrain_data = pd.read_csv('train\/train.csv',index_col=0)\ntrain_data.head()","1d5ff24b":"train_data.describe()","d19d7b9f":"train_data.shape","6cd86647":"train_data.columns","82d519b9":"train_data.dtypes","97407fff":"# lets check which city has maximum number of restaurants\ntrain_data[\"City\"].value_counts()","c09134f3":"import matplotlib.pyplot as plt","af8701eb":"# lets check how city affects our revenue feature\nplt.subplots(figsize=(30,10))\ncity_revenue_group = train_data[\"revenue\"].groupby(train_data[\"City\"])\nagg_data = city_revenue_group.sum()\nx_axis = agg_data.index\ny_axis = agg_data\nplt.bar(x_axis,y_axis)\nplt.xlabel(\"City\")\nplt.ylabel(\"Revenue\")\nplt.show()","c84b3c82":"# lets check how city groups affects our revenue feature\ncity_group_revenue_group = train_data[\"revenue\"].groupby(train_data[\"City Group\"])\nagg_data = city_group_revenue_group.sum()\nx_axis = agg_data.index\ny_axis = agg_data\nplt.bar(x_axis,y_axis)\nplt.xlabel(\"City Group\")\nplt.ylabel(\"Revenue\")\nplt.show()","02a8dd33":"# lets check how Type affects our revenue feature\ntype_revenue_group = train_data[\"revenue\"].groupby(train_data[\"Type\"])\nagg_data = type_revenue_group.sum()\nx_axis = agg_data.index\ny_axis = agg_data\nplt.bar(x_axis,y_axis)\nplt.xlabel(\"Type\")\nplt.ylabel(\"Revenue\")\nplt.show()","02e65e60":"# visualizing remaining features , looking for correlation between them\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_theme()\nfig, ax = plt.subplots(figsize=(30,30)) \ncorrelation_matrix = train_data.corr()\nsns.heatmap(correlation_matrix,annot=True,linewidths=.5,ax=ax)","8a04b16e":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# exluding revenue from VIF calculation because it's variable to be predicted\nfeatures=train_data.loc[:,\"P1\":\"P37\"]\nvif_data = pd.DataFrame()\nvif_data[\"features\"] = features.columns\nvif_data[\"vif\"] = [variance_inflation_factor(features.values, i) for i in range(len(features.columns))]\nvif_data = vif_data.sort_values(by=[\"vif\"])\nvif_data","78320026":"#Let check correlation between P2-revenue,P6-revenue,P28-revenue \nplt.figure(1)\nplt.xlabel(\"P2\")\nplt.ylabel(\"revenue\")\nplt.scatter(train_data[\"P2\"],train_data[\"revenue\"])\nplt.figure(2)\nplt.xlabel(\"P6\")\nplt.ylabel(\"revenue\")\nplt.scatter(train_data[\"P6\"],train_data[\"revenue\"])\nplt.figure(3)\nplt.xlabel(\"P28\")\nplt.ylabel(\"revenue\")\nplt.scatter(train_data[\"P28\"],train_data[\"revenue\"])\n","5feadfd7":"# cities with no. of restaurants > 3\ntrain_data[\"City\"].value_counts() > 3","4c378b8e":"# one hot encoding all the major cities (where no. of restaurants are more than 3)\ncity_encodings = pd.get_dummies(train_data[[\"City\"]], prefix = ['City'])\ncity_encodings[\"City_Other\"] = 0\nfor index, rows in city_encodings.iterrows():\n    if (rows[\"City_\u0130stanbul\"] == 0 and rows[\"City_Ankara\"] == 0 and rows[\"City_\u0130zmir\"] == 0 and rows[\"City_Bursa\"] == 0 and rows[\"City_Samsun\"] == 0 and rows[\"City_Antalya\"] == 0 and rows[\"City_Sakarya\"] == 0):\n        city_encodings[\"City_Other\"][index] = 1\n\n# chosing essential groups i.e [Cities with no. of restaurants > 3 and Other (with no. of restaurants < 3)] \ncity_encodings = city_encodings[[\"City_\u0130stanbul\", \"City_Ankara\", \"City_\u0130zmir\", \"City_Bursa\", \"City_Samsun\", \"City_Antalya\", \"City_Sakarya\", \"City_Other\"]]\ncity_encodings","2ca6553e":"train_data = pd.merge(train_data, city_encodings, left_index = True, right_index = True)","7d38e668":"train_data.drop([\"City\"],axis=1,inplace=True)\ntrain_data.head()","3a6ce28e":"# one hot encoding City Groups\ncity_group_encodings = pd.get_dummies(train_data[[\"City Group\"]], prefix = ['City Group'])\ncity_group_encodings","2a05b871":"train_data = pd.merge(train_data, city_group_encodings, left_index = True, right_index = True)","8e531083":"train_data.drop([\"City Group\"], axis=1,inplace=True)","e495b679":"train_data.head()","1cc86e93":"type_encodings = pd.get_dummies(train_data[[\"Type\"]], prefix = ['Type'])\ntype_encodings[\"Type_Other\"] = 0\nfor index, rows in type_encodings.iterrows():\n    if (rows[\"Type_DT\"] == 0 and rows[\"Type_FC\"] == 0):\n        type_encodings[\"Type_Other\"][index] = 1\ntype_encodings = type_encodings[[\"Type_DT\",\"Type_FC\",\"Type_Other\"]]\ntype_encodings","99b8415c":"train_data = pd.merge(train_data, type_encodings, left_index = True, right_index = True)","32af048d":"train_data.drop([\"Type\"],axis=1,inplace=True)","acec9725":"train_data.head()","d1d1df45":"#removing open date\ntrain_data.drop([\"Open Date\"],axis=1,inplace=True)","9942696d":"train_data.head()","688410dc":"# treating obfuscated data \n# keeping P2,P6 and P28 and removing rest all unnecesasry features from train_data\ntrain_data.drop([\"P1\",\"P3\",\"P4\",\"P5\",\"P7\",\t\"P8\",\t\"P9\",\t\"P10\",\t\"P11\",\t\"P12\",\t\"P13\",\t\"P14\",\t\"P15\",\t\"P16\",\t\"P17\",\t\"P18\",\t\"P19\",\t\"P20\",\t\"P21\",\t\"P22\",\t\"P23\",\t\"P24\",\t\"P25\",\"P26\",\"P27\",\"P29\",\t\"P30\",\t\"P31\",\t\"P32\",\t\"P33\",\t\"P34\",\t\"P35\",\t\"P36\",\t\"P37\"],axis=1,inplace=True)","5c018c55":"train_data.head()","85e60624":"train_data[train_data[\"revenue\"] > 12500000].index","c271f463":"train_data.drop(train_data[train_data[\"revenue\"] > 12500000].index, inplace=True)","2b504ea3":"plt.figure(1)\nplt.xlabel(\"P2\")\nplt.ylabel(\"revenue\")\nplt.scatter(train_data[\"P2\"],train_data[\"revenue\"])\nplt.figure(2)\nplt.xlabel(\"P6\")\nplt.ylabel(\"revenue\")\nplt.scatter(train_data[\"P6\"],train_data[\"revenue\"])\nplt.figure(3)\nplt.xlabel(\"P28\")\nplt.ylabel(\"revenue\")\nplt.scatter(train_data[\"P28\"],train_data[\"revenue\"])","8e79bb30":"train_data.head()","06bd8352":"train_data.shape","f7e93871":"Y_Train = train_data[\"revenue\"]\nX_Train = train_data.drop([\"revenue\"],axis=1)","bb32bd9f":"X_Train.head(), X_Train.shape","2f582e05":"Y_Train.head(), Y_Train.shape","cd7d37a9":"import tensorflow as tf","2a18ab70":"X_Train_Tensor = tf.constant(X_Train)\nX_Train_Tensor","60f50927":"Y_Train_Tensor = tf.constant(Y_Train)\nY_Train_Tensor","0dc649e0":"Y_Train_Tensor = tf.reshape(Y_Train_Tensor,shape=(134,1))\nY_Train_Tensor","d1f2e0c3":"tf.random.set_seed(42)","9143d459":"X_Train_Tensor.shape","32d01d0d":"model = tf.keras.Sequential([tf.keras.layers.Dense(16,input_shape=(16,),activation='relu',activity_regularizer=tf.keras.regularizers.L1(0.01)),\n                             tf.keras.layers.Dense(32,activation='relu',activity_regularizer=tf.keras.regularizers.L1(0.01)),\n                             tf.keras.layers.Dense(32,activation='relu',activity_regularizer=tf.keras.regularizers.L1(0.01)),\n                             tf.keras.layers.Dense(32,activation='relu',activity_regularizer=tf.keras.regularizers.L1(0.01)),\n                             tf.keras.layers.Dense(13,activation='relu',activity_regularizer=tf.keras.regularizers.L1(0.01)),\n                             tf.keras.layers.Dense(16,activation='relu',activity_regularizer=tf.keras.regularizers.L1(0.01)),\n                             tf.keras.layers.Dense(16,activation='relu',activity_regularizer=tf.keras.regularizers.L1(0.01)),\n                             tf.keras.layers.Dense(1,activation=None)\n                            ])","083c0a75":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=tf.keras.losses.mse\n)","96d29b20":"model.summary()","28bd3d0e":"history = model.fit(X_Train_Tensor,Y_Train_Tensor,batch_size=128,epochs=2000,validation_split = 0.2)","0e6f44e0":"hist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist.head()","a3d5a18d":"def plot_loss(history):\n  plt.plot(history.history['loss'], label='loss')\n  plt.plot(history.history['val_loss'], label='val_loss')\n  plt.xlabel('Epoch')\n  plt.ylabel('Error [revenue]')\n  plt.legend()\n  plt.grid(True)","debca10a":"plot_loss(history)","f65dbf92":"Y_Pred = model.predict(X_Train_Tensor)","5f2a5842":"plt.figure(figsize=(30,10))\nplt.plot(Y_Pred)\nplt.plot(Y_Train_Tensor)\nplt.legend([\"Y_Pred\",\"Y_Train_Tensor\"])\n","9df19285":"test_data = pd.read_csv('test\/test.csv',index_col=0)\ntest_data.head()","2a4038a8":"# one hot encoding all the major cities (where no. of restaurants are more than 3)\ncity_encodings = pd.get_dummies(test_data[[\"City\"]], prefix = ['City'])\ncity_encodings[\"City_Other\"] = 0\nfor index, rows in city_encodings.iterrows():\n    if (rows[\"City_\u0130stanbul\"] == 0 and rows[\"City_Ankara\"] == 0 and rows[\"City_\u0130zmir\"] == 0 and rows[\"City_Bursa\"] == 0 and rows[\"City_Samsun\"] == 0 and rows[\"City_Antalya\"] == 0 and rows[\"City_Sakarya\"] == 0):\n        city_encodings[\"City_Other\"][index] = 1\n\n# chosing essential groups i.e [Cities with no. of restaurants > 3 and Other (with no. of restaurants < 3)] \ncity_encodings = city_encodings[[\"City_\u0130stanbul\", \"City_Ankara\", \"City_\u0130zmir\", \"City_Bursa\", \"City_Samsun\", \"City_Antalya\", \"City_Sakarya\", \"City_Other\"]]\ncity_encodings","20f47efe":"test_data = pd.merge(test_data, city_encodings, left_index = True, right_index = True)","ee714a36":"# one hot encoding City Groups\ncity_group_encodings = pd.get_dummies(test_data[[\"City Group\"]], prefix = ['City Group'])\ncity_group_encodings","4a2f5a47":"test_data = pd.merge(test_data, city_group_encodings, left_index = True, right_index = True)","40de2e09":"test_data.drop([\"City Group\"], axis=1,inplace=True)","68acd573":"type_encodings = pd.get_dummies(test_data[[\"Type\"]], prefix = ['Type'])\ntype_encodings[\"Type_Other\"] = 0\nfor index, rows in type_encodings.iterrows():\n    if (rows[\"Type_DT\"] == 0 and rows[\"Type_FC\"] == 0):\n        type_encodings[\"Type_Other\"][index] = 1\ntype_encodings = type_encodings[[\"Type_DT\",\"Type_FC\",\"Type_Other\"]]\ntype_encodings","91d3d477":"test_data = pd.merge(test_data, type_encodings, left_index = True, right_index = True)","0a30468d":"test_data.drop([\"Type\"], axis=1,inplace=True)","3cf2741e":"test_data.head()","9570b408":"test_data.drop([\"City\",\"Open Date\"],axis=1,inplace=True)","b4d6293f":"test_data.drop([\"P1\",\"P3\",\"P4\",\"P5\",\"P7\",\t\"P8\",\t\"P9\",\t\"P10\",\t\"P11\",\t\"P12\",\t\"P13\",\t\"P14\",\t\"P15\",\t\"P16\",\t\"P17\",\t\"P18\",\t\"P19\",\t\"P20\",\t\"P21\",\t\"P22\",\t\"P23\",\t\"P24\",\t\"P25\",\"P26\",\"P27\",\"P29\",\t\"P30\",\t\"P31\",\t\"P32\",\t\"P33\",\t\"P34\",\t\"P35\",\t\"P36\",\t\"P37\"],axis=1,inplace=True)","c84616f7":"test_data.head()","ebecbb91":"test_data.shape","e036bef7":"X_Test_Tensor = tf.constant(test_data)","fe7c47b7":"X_Test_Tensor.shape","519e9404":"Y_Predictions = model.predict(X_Test_Tensor)","c14940b7":"Y_Predictions","26345b19":"test_data[\"Predictions\"] = Y_Predictions","a0431fbd":"test_data.head()","44294849":"submit_dataFrame = test_data[[\"Predictions\"]]\n# submit_dataFrame[\"Id\"] = test_data.index\n# submit_dataFrame[\"Prediction\"] = Y_Predictions.reshape(100000,)\nprint(submit_dataFrame)\nsubmit_dataFrame.to_csv(\"submission.csv\")","eaa72a4a":"* \u0130stanbul \n* Ankara   \n* \u0130zmir    \n* Samsun   \n* Bursa    \n* Sakarya  \n* Antalya  \nwill be encoded as individual columns , rest will be put in \"others group\"","77a5a731":"dividing 134 rows in 80:20 ratio for X_Train and X_Val\n* 80% of 134 -> 107\n* 20% of 134 -> 27","fa1304ab":"We can see that there is a high correlation among some feature\n\nLets find VIF of the features:","2c892892":">Restaurants in  Big Cities are generating  higher revenue\n","30002cb9":"> * FC Type is generating maximum revenue.\n> *IL closly competing with FC type\n> *DT is almost generating insignificant amount of revenue.\n> *MB Feature is not present at all","b38033a2":"After grouping Cities, lets group City Group feature","61d98992":"As we have seen above \"Istanbul\" is the only city that has maximum number of restaurants. Most of the other restaurants have significantly less number of restaurants. We can't have one hot encoding for each and every city, it will make so many features","2c5cd248":"### Let's visualize how much difference is there between Observed values and Predicted Values. \n","22e7a9a9":"# Exploratory Data Analysis","4134bddd":"> Istanbul has Maximum number of restaurants = 50\n","919abefa":"We can see that there exits high multicollinearity in our data.\n* We don't know what is the source of this data in this case. Data in columns P1 - P37 is divided in three categories of ***`obfuscated data.`***\n>* Demographic data are gathered from third party providers with GIS systems. These include population in any given area, age and gender distribution, development scales.\n>* Real estate data mainly relate to the m2 of the location, front facade of the location, car park availability.\n>* Commercial data mainly include the existence of points of interest including schools, banks, other QSR operators.\n\n\n**Since the data in obfuscated, we can't clearly identify change in which feature brings a change in revenue.**\n","8aa602ae":"> Since there is no MB feature and very less DT feature values. Lets combine them and make them one as \"Other_Type\"","f9063b47":">Istanbul is mainly generating exceptionally high revenue as compared to other cities","26b2d253":">from the scatter plots above we had observed there were outliers in the data. Revenue above 1.25 * 10^7  in all the 3 graphs were the outliers. ","f5f61ccd":"# 2. Data Preprocessing ","aa648c5e":"After grouping Cities, lets group Type feature","403a8ed1":"There are mainly 2 categorical variables namely : \n> * City Group  \n> *Type (Type of the restaurant. FC: Food Court, IL: Inline, DT: Drive Thru, MB: Mobile)\n\nAnd 37 Numerical variables (discrete)\n> * P1 to P37","ad63d9c1":" Visualizing the data for finding some insights","83785c00":"#3. Model Training","0117d7b5":"By Observing the Heat Map we can say that P2, P6 and P28 have a signicant correlation with revenue as compared to others","7c33eabd":"# Preprocessing Test data for getting predictions ","063392bc":"So I will divide the city restaurants into different groups \n> * All cities having more than 3 restaurants will have individual group \n> * Rest all with be put under the group \"other\"."}}