{"cell_type":{"445b85a1":"code","48680228":"code","a57fc64a":"code","1b2ff6cc":"code","82eda54c":"code","7ccdec13":"code","54139f70":"code","2d8aadd7":"code","43f5fc28":"code","9207d3ba":"code","0667fdc7":"code","feb4e10d":"code","022e2c24":"code","c91df440":"code","3e982b8a":"code","ce9e37d1":"code","a43fa843":"code","feac93ba":"code","439251c7":"code","05c1f1c2":"code","cbd8ded5":"code","0066abc5":"code","7dfd0f35":"code","c99ea3c2":"code","47d7e547":"code","aad295cd":"code","870590f5":"code","d59db5fd":"code","5cbe3eec":"code","5bfb9753":"code","2e188a54":"code","b9cc73a9":"code","3399a53f":"code","e451741b":"code","39149b8e":"code","dc5ad56f":"code","b94abe7d":"code","c7e77fdc":"code","6b060ce7":"code","f4d3de3e":"code","ec7060d9":"code","0bc17f68":"code","fedf1ef5":"code","aab602bd":"code","a839c5f9":"code","1a60105e":"code","ced31e3d":"code","a221c3b6":"code","7525dba5":"code","ff36ccdb":"code","cbe594b9":"code","ed32d863":"code","152bcbc7":"code","cc9ce988":"code","513b3d95":"markdown","3f31d2c5":"markdown","f81dac4d":"markdown","66bf3f5d":"markdown","fb21b751":"markdown","5fc2fa4f":"markdown","b06a6a0c":"markdown","557a1f72":"markdown","5be68bf5":"markdown","1f4cb765":"markdown","0ab677c8":"markdown","6cd0adcc":"markdown","8c1422e6":"markdown","d3f82cf9":"markdown","64a22449":"markdown","b8a6a47f":"markdown","1f3a94a1":"markdown","185472d8":"markdown","d6a37da1":"markdown","4de015a6":"markdown","3fa5cfb3":"markdown","1c40ce58":"markdown","34c0f83c":"markdown"},"source":{"445b85a1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","48680228":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.metrics import classification_report","a57fc64a":"df = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')","1b2ff6cc":"df.head()","82eda54c":"df.drop(['id'], axis = 1, inplace=True)","7ccdec13":"df.sample(6)","54139f70":"df.info()","2d8aadd7":"df.describe().T","43f5fc28":"print (\"Rows     : \" , df.shape[0])\nprint (\"Columns  : \" , df.shape[1])\nprint (\"\\nFeatures : \\n\" , df.columns.tolist())\nprint (\"\\nMissing values :  \", df.isnull().sum().values.sum())\nprint (\"\\nUnique values : \\n\",df.nunique())","9207d3ba":"df.isnull().sum().sort_values(ascending=False)[:]","0667fdc7":"df['bmi'].fillna(df['bmi'].mean(), inplace=True)","feb4e10d":"df.head()","022e2c24":"sns.boxplot(x='avg_glucose_level',data=df, color='Red')","c91df440":"sns.boxplot(x='bmi',data=df, color = 'Green')","3e982b8a":"sns.boxplot(x='age',data=df , color = 'Blue')","ce9e37d1":"plt.figure(figsize=(10,5))\nstroke = df.loc[df['stroke']==1]\nsns.countplot(data=stroke,x='ever_married', palette=\"Set2\")\nplt.title(\"Stroke \/ Ever-Married\")","a43fa843":"plt.figure(figsize=(10,5))\nstroke = df.loc[df['stroke']==1]\nsns.countplot(data=stroke,x='work_type', palette=\"Set2\")\nplt.title(\"Stroke \/ Work Type\")","feac93ba":"plt.figure(figsize=(10,5))\nstroke = df.loc[df['stroke']==1]\nsns.countplot(data=stroke,x='smoking_status', palette=\"Set2\")\nplt.title(\"Stroke \/ Smoking Status\")","439251c7":"plt.figure(figsize=(10,5))\nstroke = df.loc[df['stroke']==1]\nsns.countplot(data=stroke,x='Residence_type', palette=\"Set2\")\nplt.title(\"Stroke \/ Residence Type\")","05c1f1c2":"plt.figure(figsize=(10,5))\nstroke = df.loc[df['stroke']==1]\nsns.countplot(data=stroke,x='hypertension', palette=\"Set2\")\nplt.title(\"Stroke \/ Hypertension\")","cbd8ded5":"plt.figure(figsize=(10,5))\nstroke = df.loc[df['stroke']==1]\nsns.countplot(data=stroke,x='heart_disease', palette=\"Set2\")\nplt.title(\"Stroke \/ Heart Disease\")","0066abc5":"fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\ndf.plot(kind=\"hist\", y=\"age\", bins=70, color=\"b\", ax=axes[0][0])\ndf.plot(kind=\"hist\", y=\"bmi\", bins=100, color=\"r\", ax=axes[0][1])\ndf.plot(kind=\"hist\", y=\"heart_disease\", bins=6, color=\"g\", ax=axes[1][0])\ndf.plot(kind=\"hist\", y=\"avg_glucose_level\", bins=100, color=\"orange\", ax=axes[1][1])\nplt.show()","7dfd0f35":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\ndf.plot(kind='scatter', x='age', y='avg_glucose_level', alpha=0.5, color='green', ax=axes[0], title=\"Age vs. avg_glucose_level\")\ndf.plot(kind='scatter', x='bmi', y='avg_glucose_level', alpha=0.5, color='red', ax=axes[1], title=\"bmi vs. avg_glucose_level\")\nplt.show()","c99ea3c2":"plt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True);","47d7e547":"sns.set(style=\"ticks\");\npal = [\"#FA5858\", \"#58D3F7\"]\n\nsns.pairplot(df, hue=\"stroke\", palette=pal);\nplt.title(\"stroke\");","aad295cd":"df['Residence_type'].unique()","870590f5":"df['ever_married'].unique()","d59db5fd":"residence_mapping = {'Urban': 0, 'Rural': 1}\ndf['Residence_type'] = df['Residence_type'].map(residence_mapping)","5cbe3eec":"marriage_mapping = {'No': 0, 'Yes': 1}\ndf['ever_married'] = df['ever_married'].map(marriage_mapping)","5bfb9753":"df.head()","2e188a54":"df['gender'].unique()","b9cc73a9":"df['smoking_status'].unique()","3399a53f":"df['work_type'].unique()","e451741b":"ohe = OneHotEncoder()","39149b8e":"df['gender'] = pd.Categorical(df['gender'])\ndfDummies_gender = pd.get_dummies(df['gender'], prefix = 'gender_encoded')\ndfDummies_gender","dc5ad56f":"df['smoking_status'] = pd.Categorical(df['smoking_status'])\ndfDummies_smoking_status = pd.get_dummies(df['smoking_status'], prefix = 'smoking_status_encoded')\ndfDummies_smoking_status","b94abe7d":"df['work_type'] = pd.Categorical(df['work_type'])\ndfDummies_work_type = pd.get_dummies(df['work_type'], prefix = 'work_type_encoded')\ndfDummies_work_type","c7e77fdc":"df.drop(\"gender\", axis=1, inplace=True)\ndf.drop(\"work_type\", axis=1, inplace=True)\ndf.drop(\"smoking_status\", axis=1, inplace=True)","6b060ce7":"df = pd.concat([df, dfDummies_gender], axis=1)\ndf = pd.concat([df, dfDummies_work_type], axis=1)\ndf = pd.concat([df, dfDummies_smoking_status], axis=1)\ndf","f4d3de3e":"from sklearn.preprocessing import StandardScaler\nstd=StandardScaler()\ncolumns = ['avg_glucose_level','bmi','age']\nscaled = std.fit_transform(df[['avg_glucose_level','bmi','age']])\nscaled = pd.DataFrame(scaled,columns=columns)\ndf=df.drop(columns=columns,axis=1)","ec7060d9":"df=df.merge(scaled, left_index=True, right_index=True, how = \"left\")\ndf","0bc17f68":"y = df[\"stroke\"]\nX = df.drop(['stroke'],axis=1)\n","fedf1ef5":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 101)\n\nprint(f'Total # of sample in whole dataset: {len(X)}')\nprint(f'Total # of sample in train dataset: {len(X_train)}')\nprint(f'Total # of sample in test dataset: {len(X_test)}')","aab602bd":"model_lgr = 'Logistic Regression'\nlr = LogisticRegression()\nmodel = lr.fit(X_train, y_train)\nlr_predict = lr.predict(X_test)\nlr_conf_matrix = confusion_matrix(y_test, lr_predict)\nlr_acc_score = accuracy_score(y_test, lr_predict)\nprint(\"confussion matrix\")\nprint(lr_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of Logistic Regression:\",lr_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,lr_predict))","a839c5f9":"model_nb = 'Naive Bayes'\nnb = GaussianNB()\nnb.fit(X_train,y_train)\nnbpred = nb.predict(X_test)\nnb_conf_matrix = confusion_matrix(y_test, nbpred)\nnb_acc_score = accuracy_score(y_test, nbpred)\nprint(\"confussion matrix\")\nprint(nb_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of Naive Bayes model:\",nb_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,nbpred))","1a60105e":"model_rfc = 'Random Forest Classfier'\nrf = RandomForestClassifier(n_estimators=10, random_state=101,max_depth=5)\nrf.fit(X_train,y_train)\nrf_predicted = rf.predict(X_test)\nrf_conf_matrix = confusion_matrix(y_test, rf_predicted)\nrf_acc_score = accuracy_score(y_test, rf_predicted)\nprint(\"confussion matrix\")\nprint(rf_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of Random Forest:\",rf_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,rf_predicted))","ced31e3d":"model_egb = 'Extreme Gradient Boost'\nxgb = XGBClassifier(learning_rate=0.01, n_estimators=15, max_depth=10,gamma=0.6, subsample=0.52,colsample_bytree=0.6,seed=27, \n                    reg_lambda=2, booster='dart', colsample_bylevel=0.6, colsample_bynode=0.5)\nxgb.fit(X_train, y_train)\nxgb_predicted = xgb.predict(X_test)\nxgb_conf_matrix = confusion_matrix(y_test, xgb_predicted)\nxgb_acc_score = accuracy_score(y_test, xgb_predicted)\nprint(\"confussion matrix\")\nprint(xgb_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of Extreme Gradient Boost:\",xgb_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,xgb_predicted))","a221c3b6":"model_gb = 'Gradient Boost'\ngb = GradientBoostingClassifier(random_state=0)\ngb.fit(X_train, y_train)\ngb_predicted = gb.predict(X_test)\ngb_conf_matrix = confusion_matrix(y_test, gb_predicted)\ngb_acc_score = accuracy_score(y_test, gb_predicted)\nprint(\"confussion matrix\")\nprint(gb_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of Gradient Boosting:\",gb_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,gb_predicted))","7525dba5":"model_knn = 'K-NeighborsClassifier'\nknn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_train, y_train)\nknn_predicted = knn.predict(X_test)\nknn_conf_matrix = confusion_matrix(y_test, knn_predicted)\nknn_acc_score = accuracy_score(y_test, knn_predicted)\nprint(\"confussion matrix\")\nprint(knn_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of K-NeighborsClassifier:\",knn_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,knn_predicted))","ff36ccdb":"model_dtc = 'DecisionTreeClassifier'\ndt = DecisionTreeClassifier(criterion = 'entropy',random_state=0,max_depth = 5)\ndt.fit(X_train, y_train)\ndt_predicted = dt.predict(X_test)\ndt_conf_matrix = confusion_matrix(y_test, dt_predicted)\ndt_acc_score = accuracy_score(y_test, dt_predicted)\nprint(\"confussion matrix\")\nprint(dt_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of DecisionTreeClassifier:\",dt_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,dt_predicted))","cbe594b9":"model_svc = 'Support Vector Classifier'\nsvc =  SVC(kernel='rbf', C=5)\nsvc.fit(X_train, y_train)\nsvc_predicted = svc.predict(X_test)\nsvc_conf_matrix = confusion_matrix(y_test, svc_predicted)\nsvc_acc_score = accuracy_score(y_test, svc_predicted)\nprint(\"confussion matrix\")\nprint(svc_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of Support Vector Classifier:\",svc_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,svc_predicted))","ed32d863":"model_sgd = 'Stochastic Gradient Descent'\nsgdc = SGDClassifier(max_iter=5000, random_state=0)\nsgdc.fit(X_train, y_train)\nsgdc_predicted = sgdc.predict(X_test)\nsgdc_conf_matrix = confusion_matrix(y_test, sgdc_predicted)\nsgdc_acc_score = accuracy_score(y_test, sgdc_predicted)\nprint(\"confussion matrix\")\nprint(sgdc_conf_matrix)\nprint(\"-------------------------------------------\")\nprint(\"Accuracy of : Stochastic Gradient Descent\",sgdc_acc_score*100,'\\n')\nprint(\"-------------------------------------------\")\nprint(classification_report(y_test,sgdc_predicted))","152bcbc7":"colors = ['red','green','blue','gold','silver','yellow','orange','magenta', 'cyan']\nplt.figure(figsize=(12,5))\nplt.title(\"barplot Represent Accuracy of different models\")\nplt.xlabel(\"Accuracy %\")\nplt.xticks(rotation=90)\nplt.ylabel(\"Algorithms\")\nplt.bar(model_ev['Model'],model_ev['Accuracy'], color = colors)\nplt.show()","cc9ce988":"model_ev = pd.DataFrame({'Model': ['Logistic Regression','Naive Bayes','Random Forest','Extreme Gradient Boost','Gradient Boost',\n                    'K-Nearest Neighbour','Decision Tree','Support Vector Machine', 'Stochastic Gradient Descent'], 'Accuracy': [lr_acc_score*100,\n                    nb_acc_score*100,rf_acc_score*100,xgb_acc_score*100,gb_acc_score*100,knn_acc_score*100,dt_acc_score*100,svc_acc_score*100, sgdc_acc_score*100]})\nmodel_ev","513b3d95":"**Looks like  the number of married people tend to have stroke significantly higher than single people\n!Interesting**","3f31d2c5":"* People without hypertension has more risk to have a stroke","f81dac4d":"<a id=\"heatmap\"><\/a>\n# Heatmap","66bf3f5d":"* Now we have a close distribution of rural and urban type of residence. Looks like it does not effect much","fb21b751":"<a id=\"countplot\"><\/a>\n# Countplots","5fc2fa4f":"* People without any previous heart disease has more risk to have a stroke","b06a6a0c":"<a id=\"boxplot\"><\/a>\n# BoxPlot","557a1f72":"* In total of former smokers and currently smokers has the highest risk ","5be68bf5":"<a id=\"ohe\"><\/a>\n# One-Hot-Encoding","1f4cb765":"<a id=\"import\"><\/a>\n# Libraries","0ab677c8":"<a id=\"pairplot\"><\/a>\n# Pairplot","6cd0adcc":"<a id=\"prep\"><\/a>\n# Data Preprocessing","8c1422e6":"**Printing the informations about stroke data**","d3f82cf9":"<a id=\"introduction\"><\/a>\n**INTRODUCTION**\n\n* A stroke occurs when the blood supply to part of your brain is interrupted or reduced, preventing brain tissue from getting oxygen and nutrients. Brain cells begin to die in minutes.\n\n* A stroke is a medical emergency, and prompt treatment is crucial. Early action can reduce brain damage and other complications.\n\n\n![](https:\/\/images.medicinenet.com\/images\/article\/main_image\/stroke-symptoms-and-treatment.jpg)\n\n<strong> Attribute Information <\/strong>\n*  id: unique identifier\n*  gender: \"Male\", \"Female\" or \"Other\"\n*  age: age of the patient\n*  hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n*  heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n*  ever_married: \"No\" or \"Yes\"\n*  work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n*  Residence_type: \"Rural\" or \"Urban\"\n*  avg_glucose_level: average glucose level in blood\n*  bmi: body mass index\n*  smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n*  stroke: 1 if the patient had a stroke or 0 if not <br>\n\n*Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient","64a22449":"<a id=\"ml\"><\/a>\n# ML Models","b8a6a47f":"<a id=\"data\"><\/a>\n# Importing Data","1f3a94a1":"<a id=\"label\"><\/a>\n# Label Encoding","185472d8":"* People in private sector has higher risk of having a stroke","d6a37da1":"**Let's find out what is missing**","4de015a6":"**Table of Contents**\n* [Introduction](#introduction)\n* [Importing Libraries](#import)\n* [Importing Data](#data)\n* [Plots](#plots)\n    - [Boxplot](#boxplot)\n    - [Countplot](#countplot)\n    - [Heatmap](#heatmap)\n    - [Pairplot](#pairplot)\n* [Data Preprocessing](#prep)\n    - [Label Encoding](#label)\n    - [One Hot Encoding](#ohe)\n* [ML Models](#ml)\n* [CONCLUSION](#conclusion)","3fa5cfb3":"**Other algorithms performed very similar but we have the highest accuracy with logistic regression and Stochastic Gradient Descent (%94.60)**","1c40ce58":"* Age mostly distributed between approximately 25 and 62 ","34c0f83c":"<a id=\"conclusion\"><\/a>\n# Conclusion"}}