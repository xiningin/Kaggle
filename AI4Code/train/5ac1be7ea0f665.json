{"cell_type":{"712720c8":"code","c497a00e":"code","82ab96ab":"code","12d947d1":"code","e5114e78":"code","a3fbb669":"code","85e7dc95":"code","3bb810fc":"code","2415ed59":"code","68df1309":"code","64cb8115":"code","db554a56":"code","154fd135":"code","58c836ab":"code","469f5348":"code","564448cf":"code","b590f9af":"code","00ba6461":"code","543373ea":"code","0f972978":"code","6552ea5d":"code","a36da2ef":"code","089e918e":"code","a3ef0ab5":"code","d70bb6e1":"code","d9429cd7":"markdown"},"source":{"712720c8":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk","c497a00e":"df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")","82ab96ab":"df.info()","12d947d1":"df.head()","e5114e78":"df['msg_len'] = df['text'].apply(len)\ndf['msg_len']","a3fbb669":"df['msg_len'].describe()","85e7dc95":"df[df['msg_len']==157]['text'].iloc[0]","3bb810fc":"sns.barplot(x=df['target'], y=df['msg_len'],data=df)","2415ed59":"sns.set_style('darkgrid')\ndf.hist(column='msg_len', by = 'target', sharey=True, bins = 50, figsize=(12,4))","68df1309":"df.drop(['id','keyword','location','msg_len'],axis=1,inplace=True)","64cb8115":"import string\nimport time\nfrom nltk.corpus import stopwords\ncommonwords = stopwords.words('english') \nfrom nltk.corpus import words\nimport re\nfrom nltk.stem.porter import PorterStemmer\nstring.punctuation","db554a56":"corpus =[]\nfor i in range(0,df.shape[0]):\n    review = re.sub('[^a-zA-Z]',\" \",df['text'][i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = \" \".join(review)\n    corpus.append(review)\ntime.sleep(3)\n    ","154fd135":"corpus[0:5]","58c836ab":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nX = cv.fit_transform(corpus).toarray()\ny = df.iloc[:,-1].values","469f5348":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","564448cf":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\n\n\nnb_model = MultinomialNB()\nnb_model.fit(X_train,y_train)\nnb_preds = nb_model.predict(X_test)\n\nfrom sklearn.metrics import classification_report,accuracy_score\n\nprint(classification_report(y_test,nb_preds))\nprint(\"accuracy is:\", round(accuracy_score(y_test,nb_preds)*100),\"%\")\n\n","b590f9af":"lr_model = LogisticRegression(random_state=101, max_iter=1000)\nlr_model.fit(X_train,y_train)\nlr_preds = lr_model.predict(X_test)\n\nprint(\"lr\",classification_report(y_test,lr_preds))\nprint(\"lr_accuracy is:\", round(accuracy_score(y_test,lr_preds)*100),\"%\")\n\n","00ba6461":"svc_model = LinearSVC()\nsvc_model.fit(X_train,y_train)\nsvc_preds = svc_model.predict(X_test)\n\n\nprint(\"svc\",classification_report(y_test,svc_preds))\nprint(\"svc_accuracy is:\", round(accuracy_score(y_test,svc_preds)*100),\"%\")","543373ea":"dft = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\ndft.drop(['keyword','location','id'],axis=1,inplace=True)\ndft.head(3)","0f972978":"test_corpus =[]\nfor i in range(0,dft.shape[0]):\n    r = re.sub('[^a-zA-Z]',\" \", dft['text'][i])\n    r = r.lower()\n    r = r.split()\n    ps = PorterStemmer()\n    r = \" \".join(r)\n    test_corpus.append(r)\ntime.sleep(3)\n    ","6552ea5d":"test_corpus[0:5]","a36da2ef":"test_data = cv.transform(test_corpus)","089e918e":"op = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\nop['target']= lr_model.predict(test_data)\nop['target'].value_counts()","a3ef0ab5":"op.head()","d70bb6e1":"op.to_csv('Submissions.csv',index=False)","d9429cd7":"# **EDA: check if text length is a factor for deciding.** #"}}