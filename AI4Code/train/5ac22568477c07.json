{"cell_type":{"47d3671f":"code","2eb55a2a":"code","88b35f2e":"code","59d5bd77":"code","cc8b4f46":"code","b27a0161":"code","94f20716":"code","a8e4d8aa":"code","d756a089":"code","36c20ca2":"code","e6e34b60":"code","726fbbf1":"code","f2ffdeb7":"code","1b04d5b5":"code","fd5844d2":"code","9e108df6":"markdown","2e8636a1":"markdown","7e0c5194":"markdown","2899911f":"markdown","9b11d228":"markdown","82836fb1":"markdown","dac6929e":"markdown","4f94a60c":"markdown","0cfd5675":"markdown"},"source":{"47d3671f":"%matplotlib inline\nfrom keras.models import Sequential, load_model\nfrom keras import regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import LeakyReLU\nfrom keras.callbacks import ModelCheckpoint,History,EarlyStopping,LearningRateScheduler\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.optimizers import Adam, Adadelta, RMSprop\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2eb55a2a":"data = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/train.csv')\nprint(data.shape)","88b35f2e":"test_data = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/test.csv')\nprint(test_data.shape)","59d5bd77":"train = data[:]\nval = data[55000:]\ntrain_label = np.float32(train.label)\nval_label = np.float32(val.label)\ntrain_image = np.float32(train[train.columns[1:]])\nval_image = np.float32(val[val.columns[1:]])\ntest_image = np.float32(test_data[test_data.columns[1:]])\nprint('train shape: %s'%str(train.shape))\nprint('val shape: %s'%str(val.shape))\nprint('train_label shape: %s'%str(train_label.shape))\nprint('val_label shape: %s'%str(val_label.shape))\nprint('train_image shape: %s'%str(train_image.shape))\nprint('val_image shape: %s'%str(val_image.shape))\nprint('test_image shape: %s'%str(test_image.shape))","cc8b4f46":"datagen = ImageDataGenerator(\n    rotation_range=10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range = 10,\n    horizontal_flip = False,\n    zoom_range = 0.15)","b27a0161":"# one-hot coding\nfrom sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder(sparse=False,categories='auto')\nyy = [[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]]\nencoder.fit(yy)\n# transform\ntrain_label = train_label.reshape(-1,1)\nval_label = val_label.reshape(-1,1)\n\ntrain_label = encoder.transform(train_label)\nval_label = encoder.transform(val_label)\n\nprint('train_label shape: %s'%str(train_label.shape))\nprint('val_label shape: %s'%str(val_label.shape))","94f20716":"plt.imshow(train_image[13].reshape(28,28))\nplt.show()\nprint(train_image[13].shape)\n\ntrain_image = train_image\/255.0\nval_image = val_image\/255.0\ntest_image = test_image\/255.0\n\ntrain_image = train_image.reshape(train_image.shape[0],28,28,1)\nval_image = val_image.reshape(val_image.shape[0],28,28,1)\ntest_image = test_image.reshape(test_image.shape[0],28,28,1)\nprint('train_image shape: %s'%str(train_image.shape))\n\nprint('train_image shape: %s'%str(train_image.shape))\nprint('val_image shape: %s'%str(val_image.shape))","a8e4d8aa":"model = Sequential()\n\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1),padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(64, kernel_size=3, activation='relu',padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(64, kernel_size=5, padding='same', activation='relu'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(128, kernel_size=5, activation='relu',padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(128, kernel_size=5, activation='relu',padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(128, kernel_size=5, padding='same', activation='relu'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(256, kernel_size=5, activation='relu',padding='same'))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\nmodel.add(Dense(256,kernel_regularizer=regularizers.l2(0.02)))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(256,kernel_regularizer=regularizers.l2(0.02)))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(512,kernel_regularizer=regularizers.l2(0.02)))\nmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()","d756a089":"BATCH_SIZE = 512\nEPOCHS = 60","36c20ca2":"model.compile(loss='categorical_crossentropy',optimizer=Adadelta(),metrics=['accuracy'])\n# fit data\ndatagen.fit(train_image)\n\n# training\nhistory = model.fit_generator(datagen.flow(train_image,train_label, batch_size=BATCH_SIZE),\n                              epochs = EPOCHS,\n                              shuffle=True,\n                              validation_data = (val_image,val_label),\n                              verbose = 1,\n                              steps_per_epoch=train_image.shape[0] \/\/ BATCH_SIZE)","e6e34b60":"# \u7ed8\u5236\u8bad\u7ec3 & \u9a8c\u8bc1\u7684\u51c6\u786e\u7387\u503c\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# \u7ed8\u5236\u8bad\u7ec3 & \u9a8c\u8bc1\u7684\u635f\u5931\u503c\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","726fbbf1":"test_label = model.predict(test_image)\n# label = np.argmax(label_hot,1)\n# id_ = np.arange(0,label.shape[0])","f2ffdeb7":"label_hot = model.predict(test_image)\nlabel = np.argmax(label_hot,1)\nid_ = np.arange(0,label.shape[0])","1b04d5b5":"sim = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/sample_submission.csv')\nprint(sim.head(10))","fd5844d2":"save = pd.DataFrame({'id':id_,'label':label})\nprint(save.head(10))\nsave.to_csv('submission.csv',index=False)","9e108df6":"# One-hot encode","2e8636a1":"# Divide data into training and validation sets","7e0c5194":"# Load Data","2899911f":"# If this kernel helps you fortunately, please upvote it. Thanks you. :)","9b11d228":"# Training","82836fb1":"# Building the model","dac6929e":"# Image transform","4f94a60c":"# Data enhancement","0cfd5675":"# Visualization"}}