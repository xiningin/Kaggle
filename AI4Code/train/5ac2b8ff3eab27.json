{"cell_type":{"553e90f2":"code","85b75d32":"code","213a7258":"code","c9914ace":"code","066bf86f":"code","e9776c6e":"code","cd2910b9":"code","1ca56bb5":"code","7564cf76":"code","e0d1aa86":"code","a3ee4aa8":"code","bd8bde24":"code","6913f6b4":"code","820d954d":"code","e3d64f81":"code","037ecf33":"code","e1ba4182":"code","1ef4794f":"markdown","9da7e388":"markdown","da11338a":"markdown","26c1607e":"markdown","a5f7c52c":"markdown","cd6d6a10":"markdown","428b44a0":"markdown","226966ef":"markdown","36a19800":"markdown","5af95606":"markdown","f2a1c6f0":"markdown","6322ca38":"markdown","0a63ada1":"markdown","5598b35a":"markdown","42869a74":"markdown","d3c4655a":"markdown","790fde8a":"markdown","568f8b36":"markdown"},"source":{"553e90f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.optimizers import Adam, SGD, RMSprop\nimport tensorflow as tf\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport plotly.offline as py\nimport plotly.express as px\nfrom fbprophet import Prophet\nfrom fbprophet.plot import plot_plotly, add_changepoints_to_plot\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","85b75d32":"data = '\/kaggle\/input\/covid-19-x-ray-10000-images\/dataset'","213a7258":"os.listdir(data)","c9914ace":"normal_images = []\nfor img_path in glob.glob(data + '\/normal\/*'):\n    normal_images.append(mpimg.imread(img_path))\n\nfig = plt.figure()\nfig.suptitle('Normal Image')\nplt.imshow(normal_images[0], cmap='gray')","066bf86f":"covid_images = []\nfor img_path in glob.glob(data + '\/covid\/*'):\n    covid_images.append(mpimg.imread(img_path))\n\nfig = plt.figure()\nfig.suptitle('covid Image')\nplt.imshow(covid_images[0], cmap='gray')","e9776c6e":"Image_Width = 150\nImage_Height = 150\nCannels = 3\n\nINPUT_SHAPE = (Image_Width, Image_Height, Cannels)\nNB_CLASSES = 2\nEPOCHS = 45\nBATCH_SIZE = 6","cd2910b9":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(250,(3,3)))\nmodel.add(Activation(\"relu\"))\n  \nmodel.add(Conv2D(128,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\n\nmodel.add(Conv2D(256,(2,2)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(2,2))\n    \nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))","1ca56bb5":"model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])","7564cf76":"model.summary()\nfrom tensorflow.keras.utils import plot_model\nplot_model(model, to_file='model1.png')","e0d1aa86":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.25)\n\ntrain_generator = train_datagen.flow_from_directory(\n    data,\n    target_size=(Image_Height, Image_Width),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n    data, \n    target_size=(Image_Height, Image_Width),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle= False,\n    subset='validation')\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples \/\/ BATCH_SIZE,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples \/\/ BATCH_SIZE,\n    epochs = EPOCHS)","a3ee4aa8":"fig , ax = plt.subplots(1,2, figsize=(14,5))\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('model accuracy')\nax[0].set_ylabel('accuracy')\nax[0].set_xlabel('epoch')\nax[0].legend(['train', 'test'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('model loss')\nax[1].set_ylabel('loss')\nax[1].set_xlabel('epoch')\nax[1].legend(['train', 'test'], loc='upper left')\nplt.show()","bd8bde24":"print(\"training_accuracy\", history.history['accuracy'][-1])\nprint(\"validation_accuracy\", history.history['val_accuracy'][-1])","6913f6b4":"label = validation_generator.classes\npred= model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]\nprint(predicted_class_indices)\nprint (labels)\nprint (predictions)","820d954d":"plt.figure(figsize = (6,6))\nfrom sklearn.metrics import confusion_matrix\ncf = confusion_matrix(predicted_class_indices,label)\nsns.heatmap(cf,cmap= \"Blues\", linecolor = 'black' , annot = True, fmt='')","e3d64f81":"correct = np.nonzero(predicted_class_indices == label)[0]\npred_class = predicted_class_indices.astype(int)","037ecf33":"i = 0\nfor c in correct[:6]:\n    plt.subplot(3,2,i+1)\n    plt.imshow(validation_generator[0][0][c].reshape(150,150,3))\n    plt.title(\"Predicted Class {},Actual Class {}\".format(pred_class.reshape(1,-1)[0][c], label[c]))\n    plt.tight_layout()\n    i += 1","e1ba4182":"#### refrences\n### https:\/\/www.kaggle.com\/madz2000\/x-ray-detection-using-cnn-100-accuracy","1ef4794f":"## <font color='blue'> Accuracy <\/font>","9da7e388":"# <font size=\"+3\" color=red ><b> <center><u>X-ray Detection Using CNN<\/u><\/center><\/b><\/font><br><a id=\"top\"><\/a>","da11338a":"Another important method to improve generalization is augmentation. This means generating more training data by randomly perturbing the images. If done in the right way, it can force the net to only learn translation-invariant features. If you train this model over hundreds of epochs, augmentation will definitely improve your performance. Here in the Kernel, we will only look at each image 4-5 times, so the difference is smaller. We use a Keras function for augmentation.","26c1607e":"# <font color='blue'> Importing the Library <\/font>","a5f7c52c":"## <font color='blue'> Train the model <\/font>\n\n\nKeras offers two different ways of defining a network. We will the Sequential API, where you just add on one layer at a time, starting from the input.\n\nThe most important part are the convolutional layers Conv2D. Here they have 16-32 filters that use nine weights each to transform a pixel to a weighted average of itself and its eight neighbors. As the same nine weights are used over the whole image, the net will pick up features that are useful everywhere. As it is only nine weights, we can stack many convolutional layers on top of each other without running out of memory\/time.\n\nThe MaxPooling layers just look at four neighboring pixels and picks the maximal value. This reduces the size of the image by half, and by combining convolutional and pooling layers, the net be able to combine its features to learn more global features of the image. In the end we use the features in two fully-connected (Dense) layers.\n\nBatch Normalization is a technical trick to make training faster. Dropout is a regularization method, where the layer randomly replaces a proportion of its weights to zero for each training sample. This forces the net to learn features in a distributed way, not relying to much on a particular weight, and therefore improves generalization. 'relu' is the activation function x -> max(x,0).\n\nApplying Convolutional Neural Network which is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects\/objects in the image and be able to differentiate one from the other. Convolution is a mathematical operation to merge two sets of information.In CNN architectures, pooling is typically performed with 2x2 windows, stride 2 and no padding. While convolution is done with 3x3 windows, stride 1 and with padding\n\n","cd6d6a10":"<a href=\"#top\" class=\"btn btn-success btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOP<\/a>","428b44a0":"<font size=\"+3\" color=\"blue\"><b>Table of Content<\/b><\/font>","226966ef":"## <font color='blue'> Labeling & Prediction <\/font>","36a19800":"## <font color='blue'> Model Summary <\/font>","5af95606":"If you like it, please upvote :)\n\nIf you have any question, I will be appreciate to hear it.","f2a1c6f0":"## <font color='blue'> Covid Image<\/font>","6322ca38":"1. Importing Library\n2. Reading Datasets\n3. Normal Image\n4. Covid Images\n5. Train the Model\n6. Model Summary\n6. Plotting the Graph\n7. Accuracy\n8. Labeling and Prediction\n9. Confusion Matrix","0a63ada1":"## <font color='blue'> Normal Image <\/font>","5598b35a":"## <font color='blue'>Confusion Matrix <\/font>\nA confusion matrix is a table that is often used to describe the performance of a classification model (or \u201cclassifier\u201d) on a set of test data for which the true values are known. It allows the visualization of the performance of an algorithm.","42869a74":"## <font color='blue'> Plotting Graph - Accuracy and Loss<\/font>","d3c4655a":"The model needs to be compiled before training can start. As our loss function, we use logloss which is called \"binary_crossentropy\" in Keras. Metrics is only used for evaluation. As optimizer, we could have used rmsprop, but Adam is faster.","790fde8a":"# <font color='blue'> Reading Dataset <\/font>","568f8b36":"### Input Shape, Epochs and Batch Size\n\n    - Epochs - One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE\n    - Batch Size -Total number of training examples present in a single batch."}}