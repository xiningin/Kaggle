{"cell_type":{"a0a0ee37":"code","8c1e4eb9":"code","1f3b2847":"code","06d7a0e0":"code","bfe9b4b4":"code","5346ad3e":"code","c9bd5ed9":"code","af1fcd57":"code","ccda8ed2":"code","5b3741af":"code","a23d7fca":"code","ffd54b94":"code","db0be4b0":"code","709d5041":"code","ed3bc819":"code","3f71f6dc":"code","03889b7e":"code","a07acd56":"code","4e1a57c7":"markdown","c5fbfc79":"markdown","ed42c345":"markdown","5140f473":"markdown","d5ed21ba":"markdown","bfa6bf48":"markdown","83e320e0":"markdown","af2117fd":"markdown","f68d9210":"markdown","3dce19f7":"markdown","d0fa45aa":"markdown","23b700ff":"markdown","d1e2626f":"markdown","c20d0068":"markdown","af83fec0":"markdown","9336041e":"markdown","ccd39b94":"markdown","015d1b7e":"markdown"},"source":{"a0a0ee37":"## \u0423\u0431\u0435\u0440\u0438\u0442\u0435 \u043a\u043e\u043c\u043c\u0435\u043d\u0442\u044b \u0438 \u0432\u043f\u0438\u0448\u0438\u0442\u0435 \u0441\u0432\u043e\u0439 USERNAME \u0438 Key from Kaggle\n# !mkdir \/root\/.kaggle\n# import json\n# kaggle = {\"username\":\"USERNAME\",\"key\":\"Key from Kaggle\"}\n# with open('\/root\/.kaggle\/kaggle.json', 'w') as f:\n#     json.dump(kaggle, f)\n# !chmod 600 \/root\/.kaggle\/kaggle.json\n# kaggle competitions download -c plant-pathology-2020-fgvc7","8c1e4eb9":"!pip install -q efficientnet","1f3b2847":"import math, re, os\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\n## ______________ \u0411\u041b\u041e\u041a \u0421 \u0418\u041c\u041f\u041e\u0420\u0422\u0410\u041c\u0418 \u0410\u0420\u0425\u0418\u0422\u0415\u041a\u0422\u0423\u0420 ____________________\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201 \nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\nfrom tensorflow.keras.applications.nasnet import NASNetLarge\nfrom efficientnet.tfkeras import EfficientNetB7, EfficientNetL2\n## ______________ \u041a\u041e\u041d\u0415\u0426 \u0411\u041b\u041e\u041a\u0410 \u0421 \u0418\u041c\u041f\u041e\u0420\u0422\u0410\u041c\u0418 \u0410\u0420\u0425\u0418\u0422\u0415\u041a\u0422\u0423\u0420 ____________________\n\n# \u0438\u043c\u043f\u043e\u0440\u0442 \u0434\u0440\u0443\u0433\u0438\u0445 \u043f\u043e\u043b\u0435\u0437\u043d\u044b\u0445 \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442\u043e\u0432: \u0441\u043b\u043e\u0435\u0432, \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u043e\u0432, \u0444\u0443\u043d\u043a\u0446\u0438\u0439 \u043e\u0431\u0440\u0430\u0442\u043d\u043e\u0439 \u0441\u0432\u044f\u0437\u0438\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","06d7a0e0":"AUTO = tf.data.experimental.AUTOTUNE\n# \u041f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u044e\u0449\u0435\u0435 \u043e\u0431\u043e\u0440\u0443\u0434\u043e\u0432\u0430\u043d\u0438\u0435 \u0438 \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0443\u044e \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0439\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    # \u043e\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u0435 TPU. \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043d\u0435 \u0442\u0440\u0435\u0431\u0443\u044e\u0442\u0441\u044f \u0435\u0441\u043b\u0438 \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u043d\u0430 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f TPU_NAME. \u041d\u0430 Kaggle \u044d\u0442\u043e \u0432\u0441\u0435\u0433\u0434\u0430 True.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # \u0435\u0441\u043b\u0438 TPU \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u0435\u0442, \u0442\u043e \u0438\u0441\u043f\u043b\u044c\u0437\u0443\u0435\u043c \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044e \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u0434\u043b\u044f TF (CPU or GPU)\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n# \u041f\u0443\u0442\u044c \u043a \u0434\u0430\u043d\u043d\u044b\u043c. \u0415\u0441\u043b\u0438 \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442\u0435 \u043d\u0430 Google Colaboratory, \u0442\u043e \u0437\u0430\u043c\u0435\u043d\u0438\u0442\u0435 KaggleDatasets().get_gcs_path() \u043d\u0430 \u043f\u0443\u0442\u044c \u043a \u0434\u0430\u043d\u043d\u044b\u043c, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0431\u0443\u0434\u0435\u0442 \u0443 \u0432\u0430\u0441\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n\n# \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f\nEPOCHS = 40\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync","bfe9b4b4":"# \u0444\u0443\u043d\u043a\u0446\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043f\u0440\u0435\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0430\u0439\u0434\u0438 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u0432 \u043f\u043e\u043b\u043d\u044b\u0439 \u043f\u0443\u0442\u044c \u043a \u043d\u0435\u0439\ndef format_path(st):\n    return GCS_DS_PATH + '\/images\/' + st + '.jpg'","5346ad3e":"train = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv')\n\ntrain_paths = train.image_id.apply(format_path).values\ntest_paths = test.image_id.apply(format_path).values\n\ntrain_labels = train.loc[:, 'healthy':].values\n\n## \u0435\u0441\u043b\u0438 \u043f\u043b\u0430\u043d\u0438\u0440\u0443\u0435\u0442\u0435 \u043e\u0431\u0443\u0447\u0430\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c \u0441 \u0432\u0430\u043b\u0438\u0434\u0438\u0440\u0443\u044e\u0449\u0438\u043c \u043d\u0430\u0431\u043e\u0440\u043e\u043c \u0434\u0430\u043d\u043d\u044b\u0445\n# train_paths, valid_paths, train_labels, valid_labels = train_test_split(\n#     train_paths, train_labels, test_size=0.15, random_state=2020)","c9bd5ed9":"from matplotlib import pyplot as plt\n\n# \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0441\u0435\u0442\u043a\u0443 2 \u043d\u0430 5, \u0434\u043b\u044f \u0431\u043e\u043b\u0435\u0435 \u043a\u043e\u043c\u043f\u0430\u043a\u0442\u043d\u043e\u0433\u043e \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441\u0438\u043c\u0432\u043e\u043b\u043e\u0432 \u0438 \u0437\u0430\u0434\u0430\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u0438\u0445 \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\nf, ax = plt.subplots(3, 6, figsize=(18, 7))\nax = ax.flatten()\n# \u043e\u0442\u0440\u0438\u0441\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u0432 \u0446\u0438\u043a\u043b\u0435 \u043d\u0430\u0439\u0434\u0435\u043d\u043d\u044b\u0435 \u0442\u043e\u043f N \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0447\u0430\u0441\u0442\u0435\u0439 \u0433\u0440\u0430\u0444\u0435\u043c\nfor i in range(18):\n    img = plt.imread(f'..\/input\/plant-pathology-2020-fgvc7\/images\/Train_{i}.jpg')\n    ax[i].set_title(train[train['image_id']==f'Train_{i}'].melt()[train[train['image_id']==f'Train_{i}'].melt().value == 1]['variable'].values[0])\n    ax[i].imshow(img)\nprint(img.shape)","af1fcd57":"# \u0443\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u0433\u043b\u043e\u0431\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435\nimg_size = 768\n\n# \u0444\u0443\u043d\u043a\u0446\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0447\u0438\u0442\u0430\u0435\u0442 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0438\u0437 \u0444\u0430\u0439\u043b\u0430 \u0438 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u044b\u0432\u0430\u0435\u0442 \u0435\u0433\u043e \u043a \u043d\u0443\u0436\u043d\u043e\u043c\u0443 \u0440\u0430\u0437\u043c\u0435\u0440\u0443, \u0430 \u0442\u0430\u043a \u0436\u0435 \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0443\u0435\u0442\ndef decode_image(filename, label=None, image_size=(img_size, img_size)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0440\u0430\u0441\u0448\u0438\u0440\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\ndef data_augment(image, label=None, seed=2020):\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    image = tf.image.random_flip_up_down(image, seed=seed)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","ccda8ed2":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n## \u0435\u0441\u043b\u0438 \u043f\u043b\u0430\u043d\u0438\u0440\u0443\u0435\u0442\u0435 \u043e\u0431\u0443\u0447\u0430\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c \u0441 \u0432\u0430\u043b\u0438\u0434\u0438\u0440\u0443\u044e\u0449\u0438\u043c \u043d\u0430\u0431\u043e\u0440\u043e\u043c \u0434\u0430\u043d\u043d\u044b\u0445\n# valid_dataset = (\n#     tf.data.Dataset\n#     .from_tensor_slices((valid_paths, valid_labels))\n#     .map(decode_image, num_parallel_calls=AUTO)\n#     .batch(BATCH_SIZE)\n#     .cache()\n#     .prefetch(AUTO)\n# )\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","5b3741af":"# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0443\u043f\u0440\u0430\u0432\u043b\u044f\u044e\u0449\u0430\u044f \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u044f\u043c\u0438 \u0448\u0430\u0433\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0432 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0435 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438\nLR_START = 0.00001\nLR_MAX = 0.0001 * strategy.num_replicas_in_sync\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 15\nLR_SUSTAIN_EPOCHS = 3\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n\n# \u043f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u044f \u0448\u0430\u0433\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u044d\u043f\u043e\u0445\nrng = [i for i in range(EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","a23d7fca":"# \u0442\u0443\u0442 \u043c\u043e\u0436\u0435\u0442\u0435 \u0437\u0430\u043c\u0435\u043d\u044f\u0442\u044c \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0443 EfficientNetB7 \u043d\u0430 \u043b\u044e\u0431\u0443\u044e \u0434\u0440\u0443\u0433\u0443\u044e \u0438\u0437 \u0437\u0430\u0433\u0440\u0443\u0436\u0435\u043d\u043d\u044b\u0445 \u0438 \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0442\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \n# VGG16, VGG19, InceptionV3, InceptionResNetV2, DenseNet121, DenseNet169, DenseNet201, Xception,\n#ResNet50, ResNet50V2, ResNet101V2, ResNet152V2, NASNetLarge, EfficientNetL2\n\ndef get_model():\n    base_model =  InceptionResNetV2(weights='imagenet',\n                                 include_top=False, pooling='avg',\n                                 input_shape=(img_size, img_size, 3))\n    x = base_model.output\n    predictions = Dense(train_labels.shape[1], activation=\"softmax\")(x)\n    return Model(inputs=base_model.input, outputs=predictions)\n\nwith strategy.scope():\n    model = get_model()\n    \nmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['categorical_accuracy'])\nmodel.summary()","ffd54b94":"model.fit(\n            train_dataset, \n            steps_per_epoch=train_labels.shape[0] \/\/ BATCH_SIZE,\n            callbacks=[lr_callback],\n            epochs=EPOCHS\n         )","db0be4b0":"def display_training_curves(training, title, subplot):\n    \"\"\"\n    Source: https:\/\/www.kaggle.com\/mgornergoogle\/getting-started-with-100-flowers-on-tpu\n    \"\"\"\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n#     ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","709d5041":"display_training_curves(\n    model.history.history['loss'], \n    'loss', 211)\ndisplay_training_curves(\n    model.history.history['categorical_accuracy'], \n    'accuracy', 212)","ed3bc819":"name_model = 'InceptionResNetV2.h5'\n\n## \u0435\u0441\u043b\u0438 \u043d\u0430 Google Colab, \u0442\u043e\n# from google.colab import drive\n# drive.mount('\/content\/drive')\n# name_model = 'drive\/My Drive\/Colab Notebooks\/efficientnet.h5'\n\nmodel.save(name_model)\n\n## \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c\n# model = tf.keras.models.load_model(name_model) # \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0433\u043e\u0442\u043e\u0432\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u0433\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f","3f71f6dc":"probs = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs\nsub.to_csv('submission.csv', index=False)\nsub.head()","03889b7e":"# \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0441\u0435\u0442\u043a\u0443 2 \u043d\u0430 5, \u0434\u043b\u044f \u0431\u043e\u043b\u0435\u0435 \u043a\u043e\u043c\u043f\u0430\u043a\u0442\u043d\u043e\u0433\u043e \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441\u0438\u043c\u0432\u043e\u043b\u043e\u0432 \u0438 \u0437\u0430\u0434\u0430\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u0438\u0445 \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\nf, ax = plt.subplots(3, 5, figsize=(18, 8))\nax = ax.flatten()\n# \u043e\u0442\u0440\u0438\u0441\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u0432 \u0446\u0438\u043a\u043b\u0435 \u043d\u0430\u0439\u0434\u0435\u043d\u043d\u044b\u0435 \u0442\u043e\u043f N \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0447\u0430\u0441\u0442\u0435\u0439 \u0433\u0440\u0430\u0444\u0435\u043c\nfor i in range(15):\n    img = plt.imread(f'..\/input\/plant-pathology-2020-fgvc7\/images\/Test_{i}.jpg')\n    ax[i].set_title(sub[sub['image_id']==f'Test_{i}'].melt().iloc[1:][sub[sub['image_id']==f'Test_{i}'].melt().iloc[1:].value >= 0.8]['variable'].values[0])\n    ax[i].imshow(img)\nprint(img.shape)","a07acd56":"## \u0435\u0441\u043b\u0438 \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442\u0435 \u0441 Google Colaboratory\n# !kaggle competitions submit -c plant-pathology-2020-fgvc7 -f submission.csv -m \"xception_1_efficient_1\"","4e1a57c7":"## \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442\u044b \u043d\u0430\u0431\u043e\u0440\u043e\u0432 \u0434\u0430\u043d\u043d\u044b\u0445\n\nA `tf.data.Dataset` \u043e\u0431\u044a\u0435\u043a\u0442 \u043d\u0443\u0436\u0435\u043d \u0434\u043b\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e\u0431\u044b \u043c\u043e\u0434\u0435\u043b\u044c \u0431\u0435\u0441\u043f\u0435\u0440\u0435\u0431\u043e\u0439\u043d\u043e \u0440\u0430\u0431\u043e\u0442\u0430\u043b\u0430 \u043d\u0430 TPUs","c5fbfc79":"\u0421\u0442\u0430\u0432\u0438\u043c Efficientnet","ed42c345":"### \u0417\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f","5140f473":"\u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442\u044b \u043d\u0430\u0431\u043e\u0440\u043e\u0432 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f, \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u0438 \u0442\u0435\u0441\u0442\u0430","d5ed21ba":"Unhide below to see helper function `display_training_curves`:","bfa6bf48":"## \u041d\u0430\u0441\u0442\u0440\u0430\u0438\u0432\u0430\u0435\u043c TPU \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044e","83e320e0":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0434\u0430\u043d\u043d\u044b\u0435","af2117fd":"## \u0414\u0435\u043b\u0430\u0435\u043c \u043f\u0440\u043e\u0433\u043d\u043e\u0437 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u0433\u043e\u0442\u043e\u0432\u0438\u043c \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438","f68d9210":"### \u0412\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438","3dce19f7":"## \u0421\u0442\u0440\u043e\u0438\u043c \u0438 \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c","d0fa45aa":"## \u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438","23b700ff":"### \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 TPU","d1e2626f":"\u0415\u0441\u043b\u0438 \u0445\u043e\u0442\u0438\u0442\u0435 \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c, \u0442\u043e ","c20d0068":"### \u0421\u0441\u044b\u043b\u043a\u0438 \u043d\u0430 \u0440\u0430\u0431\u043e\u0442\u044b, \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0431\u0430\u0437\u0438\u0440\u0443\u0435\u0442\u0441\u044f \u0434\u0430\u043d\u043d\u043e\u0435 \u0440\u0435\u0448\u0435\u043d\u0438\u0435\n\n* https:\/\/www.kaggle.com\/xhlulu\/plant-pathology-very-concise-tpu-efficientnet\n* https:\/\/www.kaggle.com\/dimakyn\/classification-densenet201-efficientnetb7","af83fec0":"## \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043c\u0435\u0442\u043a\u0438 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0438 \u043f\u0443\u0442\u0438 \u043a \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c","9336041e":"\u041a\u043e\u0433\u0434\u0430 \u0432\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u0435 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0441 \u0432\u044b\u0441\u043e\u043a\u0438\u043c\u0438 \u0431\u0430\u043b\u043b\u0430\u043c\u0438, \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u0438\u0445 \u043e\u0431\u044a\u0435\u0434\u0435\u043d\u0438\u0442\u044c\n\nprobs = (model1.predict(test_dataset)+model.predict(test_dataset))\/2\n\n\u0433\u0434\u0435 \u043c\u043e\u0436\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0438 \u0431\u043e\u043b\u044c\u0448\u0435 \u043c\u043e\u0434\u0435\u043b\u0435\u0439, \u043d\u043e \u0442\u043e\u0433\u0434\u0430 \u0434\u0435\u043b\u0438\u0442\u044c \u043d\u0435 \u043d\u0430 2, \u0430 \u043d\u0430 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439","ccd39b94":"\u0415\u0441\u043b\u0438 \u0445\u043e\u0442\u0438\u0442\u0435 \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u043d\u0430 Google Colaboratory\n\n\u0414\u043b\u044f \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u043a\u043b\u044e\u0447\u0430 \u0434\u043e\u0441\u0442\u0443\u043f\u0430 \u0434\u043b\u044f API \u043f\u0435\u0440\u0435\u0445\u043e\u0434\u0438\u0442\u0435\n*   https:\/\/www.kaggle.com\/lkatran (\u0433\u0434\u0435 \"lkatran\" - \u0432\u0430\u0448 user name)\n*   \u043d\u0430\u0436\u0438\u043c\u0430\u0435\u043c Edit Profile\n*   \u043d\u0430\u0445\u043e\u0434\u0438\u043c \u043d\u0438\u0436\u0435 \u0440\u0430\u0437\u0434\u0435\u043b API\n*   \u043d\u0430\u0436\u0438\u043c\u0430\u0435\u043c Create New API Token\n*   \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u0442\u0441\u044f \u0444\u0430\u0439\u043b kaggle.json\n*   \u0432 \u043d\u0435\u043c \u0432\u0430\u0448 \u043a\u043b\u044e\u0447","015d1b7e":"\u0418\u043c\u043f\u043e\u0440\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a"}}