{"cell_type":{"ca2bbb7a":"code","01f04b0f":"code","37a8dcbc":"code","92ab1082":"code","bca6e6bd":"code","2de817bf":"code","b2e42b90":"code","b59c6195":"code","0c12ffda":"code","81989b60":"code","1d724e47":"code","8a8e4ccf":"code","494ec82c":"code","be4feaf9":"code","9aa164b8":"code","0585961b":"code","2107b246":"code","74c06a0c":"code","c24b7fb8":"code","3abb1acf":"code","52715a53":"code","6aa77d88":"code","d3398ca8":"code","6ec7f1af":"code","628efe32":"code","cc57484b":"markdown","fa08a234":"markdown","d7d64626":"markdown","a8785840":"markdown","6e22233e":"markdown","585426ae":"markdown","eaee442c":"markdown","d9390352":"markdown"},"source":{"ca2bbb7a":"# import libraries\nfrom IPython.display import Image, display\nimport numpy as np\nimport os\nfrom os.path import join\nfrom PIL import ImageFile\nimport pandas as pd\nfrom matplotlib import cm\nimport seaborn as sns\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn import svm\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.isotonic import IsotonicRegression\nimport re\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\nplt.style.use('fivethirtyeight')\n%matplotlib inline","01f04b0f":"# import car images from natural images\ntrain_img_dir_n = \"..\/input\/natural-images\/data\/natural_images\/car\"\ntrain_img_paths_n = [join(train_img_dir_n,filename) for filename in os.listdir(train_img_dir_n)]","37a8dcbc":"# import car images from stanford cars\ntrain_img_dir_s = \"..\/input\/stanford-cars-dataset\/cars_train\/cars_train\"\nall_train_img_paths_s = [join(train_img_dir_s,filename) for filename in os.listdir(train_img_dir_s)]\n\n# split cars data into train, test, and val\ntrain_img_paths, test_img_paths_car = train_test_split(all_train_img_paths_s+train_img_paths_n, test_size=0.25, random_state=42)\ntrain_img_paths, val_img_paths_car = train_test_split(train_img_paths, test_size=0.25, random_state=42)","92ab1082":"#  import ~car images\nnatural_images_path = \"..\/input\/natural-images\/data\/natural_images\/\"\ntest_img_paths_no_car = []\nfor d in [d for d in os.listdir(\"..\/input\/natural-images\/data\/natural_images\") if d!= \"car\"]:\n    test_img_dir_na = natural_images_path+d\n    test_img_paths_no_car.append([join(test_img_dir_na,filename) for filename in os.listdir(test_img_dir_na)])\n    \ntest_img_paths_no_car_flat = [item for sublist in test_img_paths_no_car for item in sublist]\ntest_img_paths_no_car, val_img_paths_no_car = train_test_split(test_img_paths_no_car_flat, test_size = 0.25, random_state = 42)","bca6e6bd":"def natural_img_dir(image_path):\n    path_regex = r\"natural_images\\\/(\\w*)\"\n    if 'natural_images' in image_path:\n        return re.findall(path_regex,image_path,re.MULTILINE)[0].strip()\n    else:\n        return 'car'","2de817bf":"# create test dataframe\nall_test_paths = test_img_paths_car+test_img_paths_no_car\ntest_path_df = pd.DataFrame({\n    'path': all_test_paths,\n    'is_car': [1 if path in test_img_paths_car else 0 for path in all_test_paths]\n})\ntest_path_df = shuffle(test_path_df,random_state = 0).reset_index(drop = True)\ntest_path_df['image_type'] = test_path_df['path'].apply(lambda x: natural_img_dir(x))\nall_test_paths = test_path_df['path'].tolist()","b2e42b90":"print('Distribution of Image Types in Test Set')\nprint(test_path_df['image_type'].value_counts())","b59c6195":"# create val dataframe\nall_val_paths = val_img_paths_car+val_img_paths_no_car\nval_path_df = pd.DataFrame({\n    'path': all_val_paths,\n    'is_car': [1 if path in val_img_paths_car else 0 for path in all_val_paths]\n})\nval_path_df = shuffle(val_path_df,random_state = 0).reset_index(drop = True)\nval_path_df['image_type'] = val_path_df['path'].apply(lambda x: natural_img_dir(x))\nall_val_paths = val_path_df['path'].tolist()","0c12ffda":"print('Distribution of Image Types in Validation Set')\nprint(val_path_df['image_type'].value_counts())","81989b60":"# prepare images for resnet50\nimage_size = 224\n\ndef read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n    img_array = np.array([img_to_array(img) for img in imgs])\n    #output = img_array\n    output = preprocess_input(img_array)\n    return(output)\n\nX_train = read_and_prep_images(train_img_paths)\nX_test = read_and_prep_images(all_test_paths)\nX_val = read_and_prep_images(all_val_paths)","1d724e47":"# get features from resnet50 \n\nresnet_weights_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# X : images numpy array\nresnet_model = ResNet50(input_shape=(image_size, image_size, 3), weights=resnet_weights_path, include_top=False, pooling='avg')  # Since top layer is the fc layer used for predictions\n\nX_train = resnet_model.predict(X_train)\nX_test = resnet_model.predict(X_test)\nX_val = resnet_model.predict(X_val)","8a8e4ccf":"# Apply standard scaler to output from resnet50\nss = StandardScaler()\nss.fit(X_train)\nX_train = ss.transform(X_train)\nX_test = ss.transform(X_test)\nX_val = ss.transform(X_val)\n\n# Take PCA to reduce feature space dimensionality\npca = PCA(n_components=512, whiten=True)\npca = pca.fit(X_train)\nprint('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))\nX_train = pca.transform(X_train)\nX_test = pca.transform(X_test)\nX_val = pca.transform(X_val)","494ec82c":"# Train classifier and obtain predictions for OC-SVM\noc_svm_clf = svm.OneClassSVM(gamma=0.001, kernel='rbf', nu=0.08)  # Obtained using grid search\nif_clf = IsolationForest(contamination=0.08, max_features=1.0, max_samples=1.0, n_estimators=40)  # Obtained using grid search\n\noc_svm_clf.fit(X_train)\nif_clf.fit(X_train)\n\noc_svm_preds = oc_svm_clf.predict(X_test)\nif_preds = if_clf.predict(X_test)\n\n# Further compute accuracy, precision and recall for the two predictions sets obtained","be4feaf9":"svm_if_results=pd.DataFrame({\n  'path': all_test_paths,\n  'oc_svm_preds': [0 if x == -1 else 1 for x in oc_svm_preds],\n  'if_preds': [0 if x == -1 else 1 for x in if_preds]\n})\n\n\nsvm_if_results=svm_if_results.merge(test_path_df)\nsvm_if_results.head()","9aa164b8":"print('roc auc score: if_preds')\nif_preds=svm_if_results['if_preds']\nactual=svm_if_results['is_car']\nprint(roc_auc_score(actual, if_preds))\nprint(classification_report(actual, if_preds))\nsns.heatmap(confusion_matrix(actual, if_preds),annot=True,fmt='2.0f')\nplt.show()","0585961b":"print('roc auc score: oc_svm_preds')\noc_svm_preds=svm_if_results['oc_svm_preds']\nactual=svm_if_results['is_car']\nprint(roc_auc_score(actual, oc_svm_preds))\nprint(classification_report(actual, oc_svm_preds))\nsns.heatmap(confusion_matrix(actual, oc_svm_preds),annot=True,fmt='2.0f')\nplt.show()","2107b246":"y_val = val_path_df['is_car'].tolist()\n\ngmm_clf = GaussianMixture(covariance_type='spherical', n_components=18, max_iter=int(1e7))  # From Article (These params should be optimized for this problem)\ngmm_clf.fit(X_train)\nlog_probs_val = gmm_clf.score_samples(X_val)\nisotonic_regressor = IsotonicRegression(out_of_bounds='clip')\nisotonic_regressor.fit(log_probs_val, y_val)  # y_val is for labels 0 - not car 1 - car (validation set)\n\n# Obtaining results on the test set\nlog_probs_test = gmm_clf.score_samples(X_test)\ntest_probabilities = isotonic_regressor.predict(log_probs_test)\ntest_predictions = [1 if prob >= 0.5 else 0 for prob in test_probabilities]\n","74c06a0c":"gmm_results = pd.DataFrame({\n  'path': all_test_paths,\n  'gmm_preds': test_predictions\n})\n\ngmm_results = gmm_results.merge(test_path_df)\ngmm_results.head()","c24b7fb8":"print('roc auc score: gmm_preds')\ngmm_preds = gmm_results['gmm_preds']\nactual = gmm_results['is_car']\nprint(roc_auc_score(actual, gmm_preds))\nprint(classification_report(actual, gmm_preds))\nsns.heatmap(confusion_matrix(actual, gmm_preds),annot = True,fmt = '2.0f')\nplt.show()","3abb1acf":"print('False Positive Actual Image Types for OC SVM: ')\nprint(svm_if_results[svm_if_results['oc_svm_preds']>svm_if_results['is_car']]['image_type'].value_counts())","52715a53":"for index, row in svm_if_results[svm_if_results['oc_svm_preds']!=svm_if_results['is_car']].head(25).iterrows():\n    if row['oc_svm_preds']==1:\n        print('FALSE POSITIVE')\n        print('oc_svm_preds: ' + str(row['oc_svm_preds']) + ' | actual: '+ str(row['is_car']))\n        display(Image(row['path']))\n    else:\n        print('FALSE NEGATIVE')\n        print('oc_svm_preds: ' + str(row['oc_svm_preds']) + ' | actual: '+ str(row['is_car']))\n        display(Image(row['path']))","6aa77d88":"print('False Positive Actual Image Types for IF: ')\nprint(svm_if_results[svm_if_results['if_preds']>svm_if_results['is_car']]['image_type'].value_counts())","d3398ca8":"for index, row in svm_if_results[svm_if_results['if_preds']!=svm_if_results['is_car']].head(25).iterrows():\n    if row['if_preds']==1:\n        print('FALSE POSITIVE')\n        print('if_preds: ' + str(row['if_preds']) + ' | actual: '+ str(row['is_car']))\n        display(Image(row['path']))\n    else:\n        print('FALSE NEGATIVE')\n        print('if_preds: ' + str(row['if_preds']) + ' | actual: '+ str(row['is_car']))\n        display(Image(row['path']))","6ec7f1af":"print('False Positive Actual Image Types for GMM: ')\nprint(gmm_results[gmm_results['gmm_preds']>gmm_results['is_car']]['image_type'].value_counts())","628efe32":"for index, row in gmm_results[gmm_results['gmm_preds']!=gmm_results['is_car']].head(25).iterrows():\n    if row['gmm_preds']==1:\n        print('FALSE POSITIVE')\n        print('gmm_preds: ' + str(row['gmm_preds']) + ' | actual: '+ str(row['is_car']))\n        display(Image(row['path']))\n    else:\n        print('FALSE NEGATIVE')\n        print('gmm_preds: ' + str(row['gmm_preds']) + ' | actual: '+ str(row['is_car']))\n        display(Image(row['path']))","cc57484b":"# One Class Classification for Images\n<br>\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/9\/9f\/King_of_Europe_Round_3_Lydden_Hill_2014_%2814356011899%29.jpg\" alt=\"Car\" title=\"Car\" \/>\n\n## Intro\n\nBinary classification is arguably the most widely documented domain of supervised machine learning, at least within its application toward classifying non-Image data. In a ham vs spam email detector, the data for each class is bound by the limitations of the medium; each instance will most definitely be a variant of an email. However, an interesting problem arises when attempting to apply a ham vs spam concept with image classification.\n\n## The Problem\n\nConsider the issue that arises when building a model whose purpose it is to determine whether a car exists in its field of view. You may have several thousand images of cars you would like to train the model to recognize, but what about instances of \u201cNot Car\u201d images? It doesn\u2019t take long for one to realize that unlike the data in the ham vs spam email problem, the amount of instances that qualify as \u201cNot Car\u201d are near infinite: infinity \\ car if you want to be cheeky about it. \n\n## A Solution\n\nWhile there are several pretrained models for classifying cars, projects in an industry are not always so straightforward. When faced with one such project, I found the documentation around this \u201cOne Class Classification\u201d idea to be pretty paltry. There were several recommendations of building a model with autoencoders, but as a infrequent practitioner of Keras and naive in the space of image classification overall, I found such methods to be a little hard to \u201cpick up and go\u201d within the span of a few hours (maybe one of you readers could contribute a kernel taking this approach for the rest of us).\n\nI did find one promising article written by Aniket Bhatnagar on Hackernoon though. Instead of building a custom model with auto-encoders, Aniket outlined the process of extracting features with the popular ResNet50 model, scaling and reducing the dimensionality of such features, then using a selection of scikit-learn algorithms for classification; all of this while training only on positive class images (the GMM model however uses a combination of positive\/not positive images in its validation set). \n\nI implemented Aniket\u2019s procedure to a project with industry data and was pleased with its results, even before optimization. However, while the article was very informative, it did not include the complete code to create a project from scratch, which is the inspiration behind this notebook. Aniket\u2019s article is also listed below; I definitely recommend reading it alongside this notebook.\n\nhttps:\/\/hackernoon.com\/one-class-classification-for-images-with-deep-features-be890c43455d \n","fa08a234":"## Closing Remarks\n\nI hope this notebook was helpful for those interested in learning a bit more about One Class Image Classification and its application toward solving real world problems. I definitely encourage the community to contribute toward handling this tricky problem with other methods that may promise even better results. Thanks to Aniket who wrote the original article on Hackernoon.","d7d64626":"## Feature Extraction With ResNet50\nRemoving the prediction layer of the pretrained Resnet50 model allows features to quickly be extracted from selected images.","a8785840":"## Preparing Train, Test, and Validation Data\n\nThe training data is comprised of ONLY car images from the Natural Images and Stanford Cars Dataset. The validation and test data contain car images from the same datasets as well as other image types (listed below) from the Natural Images dataset.","6e22233e":"## Gaussian Mixture and Isotonic Regression\nThese models leverage validation data to additionally learn distinctions between positive and not positive class images. With real world problems, the data scientist might have a hunch on what \"not positive images\" might appear alongside its positive counterparts; these selections would be appropriate to include in the validation data. For example, a marine biologist may ask a data scientist to perform One Class Clasification to return only images with a shark in the photo. To leverage the GMM model below, the data scientist might choose to also include non-shark fishes, whales, and open ocean images in the validation data alongside some shark images.","585426ae":"## Scaling and PCA\nReducing the dimensionality of extracted features allow for quicker training times.","eaee442c":"## Error Analysis\n\nThe OC SVM and IF models had fewer False Positives but more False Negatives compared to the GMM model, with the OC SVM model outperforming the IF one. Depending on the use case of a project, it might be wiser to choose the OC SVM over the GMM or vice versa. A fulfillment center might opt to use the OC SVM model as it has fewer False Positives, meaning when it chooses to pack an object, such as a toy car, it is more likely to pack the right object than the GMM model. However, a healthcare imaging device may be favor the GMM more, as making a False Negative is much more costly to the patient than a False Positive.\n\nLooking at the types of images of the False Positives, it isn't surprising to see that motorbikes were the most commonly mispredicted as a car as the presence of wheels and metal chassis share similarities.\n\nA naive look at the cars in the False Negative class show that images of exotic cars and cars shot at atypical angles or with other objects in the view were among the cars mispredicted as non-cars.","d9390352":"## One Class SVM vs Isolation Forest\n\nThese two models can be trained on solely positive class, cars for this project, images, without the need for a validation set."}}