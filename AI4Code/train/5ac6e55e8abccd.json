{"cell_type":{"b8f5e1e1":"code","3ad5e108":"code","2abea81c":"code","55a9291c":"code","15d53982":"code","28f5deef":"code","30516944":"code","b60e846a":"code","2cd9abc8":"code","3c182122":"code","ed1929fa":"code","7bd53e16":"code","7c7a3d2b":"markdown","c9587936":"markdown","817699a9":"markdown","03fa2f72":"markdown","4807fb90":"markdown","6ed3b453":"markdown","c67ebb31":"markdown","ade583bf":"markdown","6fb366c6":"markdown","5eb0f7a2":"markdown","8159c8b8":"markdown","5c626429":"markdown","e99af8a6":"markdown"},"source":{"b8f5e1e1":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport os\nimport torchvision\n","3ad5e108":"class FeedForward(nn.Module):\n    def __init__(self):\n        super(FeedForward, self).__init__()\n        self.layer1 = nn.Linear(3*96 * 96 , 200)\n        self.layer2 = nn.Linear(200, 100)\n        self.layer3 = nn.Linear(100, 3) # The 3 here implies that we wisht to have 3 final classifications for our model.\n    def forward(self, img):\n        #print(img.shape)\n        flattened = img.view(-1, 3*96 * 96)\n        activation1 = F.relu(self.layer1(flattened))\n        activation2 = F.relu(self.layer2(activation1))\n        output = self.layer3(activation2)\n        return  F.log_softmax(output)\n\nmodel = FeedForward()","2abea81c":"import torchvision.transforms as transforms\n\ntrainTransform = transforms.Compose([transforms.ToTensor(),\n                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n \ndata_path = 'Data\/assignment_train\/'\ntrain_dataset = torchvision.datasets.ImageFolder(\n    root = data_path,\n    transform = trainTransform)\n\ntrain_iter = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size = 64,\n    num_workers = 0,\n    shuffle = True\n)","55a9291c":"for i, (images, labels) in enumerate(train_iter):\n    if i >= 15:\n        break\n    plt.subplot(3, 5, i+1)\n    imgb = images[0, :,:]\n    print(imgb.shape)\n    \n    plt.imshow(imgb[0,:,:], cmap='gray')\n    plt.show()\n    print(labels)\n\n        ","15d53982":"train_acc_loader = torch.utils.data.DataLoader(train_dataset, batch_size =  64)\n\ndef get_accuracy(model, train=False):\n    if train:\n        data = train_dataset\n    correct = 0\n    total = 0\n    for imgs, labels in train_acc_loader:#torch.utils.data.DataLoader(data, batch_size=64):\n        output = model(imgs) # We don't need to run F.softmax\n        #print(output)\n        #break\n        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(labels.view_as(pred)).sum().item()\n        total += imgs.shape[0]\n    return correct \/ total","28f5deef":"import torch.optim as optim\n\n#1. Adam, with lr= 0.0001 or 0.001?\n\ndef train(model, data, batch_size=64, num_epochs=1):\n    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001) # 0.01 or 0.001?\n\n    iters, losses, train_acc = [], [], []\n\n    # training\n    n = 0 # the number of iterations\n    for epoch in range(num_epochs):\n        print(\"EPOCH:\",epoch)\n        for iteration,(imgs, labels) in enumerate(train_loader):\n            model.train()\n            out = model(imgs)             # forward pass\n            loss = criterion(out, labels) # compute the total loss\n            loss.backward()               # backward pass (compute parameter updates)\n            optimizer.step()              # make the updates for each parameter\n            optimizer.zero_grad()         # a clean up step for PyTorch\n\n            # save the current training information\n            iters.append(n)\n            losses.append(float(loss)\/batch_size)             # compute *average* loss\n            model.eval()\n            acc = get_accuracy(model, train=False)\n            train_acc.append(acc) # compute training accuracy \n            if iteration%10==0:\n                print(acc,loss.item())\n            n += 1\n\n    # plotting\n    plt.title(\"Loss performance\")\n    plt.plot(iters, losses, label=\"Train\")\n    plt.xlabel(\"Iterations\")\n    plt.ylabel(\"Loss\")\n    plt.show()\n\n    plt.title(\"Training Curve\")\n    plt.plot(iters, train_acc, label=\"Train\")\n    plt.xlabel(\"Iterations\")\n    plt.ylabel(\"Training Accuracy\")\n    plt.legend(loc='best')\n    plt.show()\n\n    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))","30516944":"#print(train_dataset.shape)\n#debug = train_dataset[:100,:,:,:]\n\nmodel = FeedForward()\ntrain(model, train_dataset, num_epochs = 70)","b60e846a":"import torchvision.transforms as transforms\n\ntrainTransform = transforms.Compose([transforms.ToTensor(),\n                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n \ndata_path = 'Data\/assignment_test\/'\ntest_dataset = torchvision.datasets.ImageFolder(\n    root = data_path,\n    transform = trainTransform)\n\ntest_iter = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size = 64,\n    num_workers = 0,\n    shuffle = True\n)","2cd9abc8":"train(model, test_dataset, num_epochs = 50)","3c182122":"import numpy as np\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report","ed1929fa":"def get_confusion_matrix(model, data):\n    torch.no_grad()\n    model.eval()\n    preds, actuals = [], []\n    \n    for imgs, labels in data:\n        imgs = imgs.unsqueeze(0)\n        out = model(imgs)\n        _, predicted = torch.max(out, 1)\n        preds.append(predicted)\n        actuals.append(labels)\n        \n    preds = torch.cat(preds).numpy()\n    actuals = np.asarray(actuals)\n    return confusion_matrix(actuals, preds)","7bd53e16":"get_confusion_matrix(model, test_dataset)","7c7a3d2b":"First of all, we define our FCN model (FeedForward in our case). Our model inherits from the subclass of Pytorch's nn.Module, much like any other model. Like theory, we introduce multiple layers within our network, which in our case, the nn.Linear function. Since our image is coloured with a size of 96 by 96, the first layer's input would naturally be 3 * 96 * 96 (3 channels since its RGB, and 96 by 96) followed by the first layer of output we wish to generate, which in our case, 200. The output of the first layer would naturally be the input of our 2nd layer, hence the equal numbers and followed by 100 outputs. The number of layers also play a role in the performance of our model, but since our model performed fairly well after the third layer, the initial 4th model was removed subsequently. \n\nThe forward method, a.k.a running the forward pass, is called to put the neural network to use in making a prediction. The first argument: flattened, is to flatten to image, to obtain a consistent tensor dimension we wish to use since the dimension of images are defined by batch_size x height x width, which could be [-1, 96 96] or [-1, 1, 96, 96] where the -1 is a placeholder for \"unknown\" dimension size. \nSubsequently, we run the forward pass of the flattened image to our first layer of activation (F.ReLU), the Rectified Linear Unit. Repeat the steps depending on the layer introduced previously and then an output can be generated on the final layer of activation. Note log_softmax is also implemented to ensure a much more stable output. ","c9587936":"Now that our FCN model works semmingly well on our training dataset, we then introduce it to our test dataset. Since our test dataset is relatively small, the number of epochs introduced are much less smaller, in our case 10. Nonetheless, the model performed pretty well with a training accuracy of approximately 65%, with a higher accuracy obtainable by introducint more epochs. ","817699a9":"**<font size=\"5\">FCN Model<\/font>**","03fa2f72":"With all of that out of the way, we can finally use our defined model to implement it on to our training dataset. Note that the num_epochs here entirely arbitary, but are highly crucial to the performance of our model. After much trial and error, the minimal number of epochs that are necessary to obtain an optimistic learning curve is at least 70. Although time consuming, but anything below 65 would end up with a very low learning improvement, eventually affecting our training accuracy. From the graphs, we can also see that as the model \"learns\", our loss performance, a.k.a our training loss had a bit of large spike in the beginning and soon after gradually decrease, finally to a stable low rate. As for our training curve, there were couple of up downs in the middle phase, but overall, it seems to be performing quite ideally. ","4807fb90":"Calling a brief overview of our images. The images were changed to grayscale for quicker processing ","6ed3b453":"Accordingly, we define our training model (train). Our Loss function, the criterion, uses the Cross Entropy Loss, a more general method compared to the Binary Cross Entropy Loss. The Binary Cross-Entropy Loss is much significant when it comes to, unsurprisingly, binary classification. The optimizer includes the learning rate our model operates on. Initially, the SGD was used, but eventually the Adam algorithm was preferred over the former, as it tends to better handle our data. The learning rate is arguably the highlight of our whole training model, as it decided how well our model was performing. Initially, a learning rate of 0.01 was implemented, but the final performance of our model (mainly the Final training accuracy),as you can see below, did not perform well, as the model had a constant 33% training accuracy. Consequently, we then increase(as in decreasing the velocity of our rate) learning rate, achieving our final training accuracy of approximately 72.2%.","c67ebb31":"**Loading our Test Dataset**","ade583bf":"<font size=\"5\">Confusion matrix for test dataset<\/font>","6fb366c6":"**<font size=\"5\">Implementing our model to the Test Dataset<\/font>**","5eb0f7a2":"The first of our model here is the FCN model (Fully Connected Network). First of all, unsurprisingly, we import the necessary packages needed for our model, mainly Pytorch and its torchvision, and Matplotlib.pyplot for image plotting. ","8159c8b8":"**<font size=\"5\">DSA 8021 Assignment: Deep Learning for Image Classification<\/font>**\n\n**<font size=\"3\">Student number: 40195086<\/font>**","5c626429":"**<font size=\"5\">Data Loading<\/font>**\n\nImporting the necessary datasets for our model. Note that the images were transferred to Tensor forms, and Normalize, in order to ensure better processing of our model on the images in later stages. ","e99af8a6":"This notebook will demonstrate the coding of the three models specified from the assignment, which are Fully Connected Network (FCN), Convolutional Neural Networks (CNN), and Recurrent Neural Network (RNN). As the reader goes through the notebook, brief comments of the codes used and the motives will be given. Further information can be referred from the word document report attached with the assignment. "}}