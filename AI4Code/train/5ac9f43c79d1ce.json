{"cell_type":{"56c93bdc":"code","c967895c":"code","73f75670":"code","772fad54":"code","75de8a6f":"code","22729409":"code","fa086e27":"code","d7766107":"code","9af8df5d":"code","3aa0f8f1":"code","01db4e0a":"code","5ebcc0ef":"code","05adcb91":"code","ac8adf5d":"code","542d7c07":"markdown","df6a2bde":"markdown","4994a4c2":"markdown","9f13cc32":"markdown","81c00d16":"markdown","3f0452bc":"markdown","8cc2552d":"markdown","ae2e601f":"markdown"},"source":{"56c93bdc":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\n\nimport matplotlib.pylab as plt","c967895c":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","73f75670":"input_dir = '\/kaggle\/input\/santander-customer-transaction-prediction\/'\ndf_train = pd.read_csv(input_dir + '\/train.csv')\ndf_train","772fad54":"var_columns = [c for c in df_train.columns if c not in ['ID_code','target']]\n\nX = df_train.loc[:,var_columns]\ny = df_train.loc[:,'target']\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","75de8a6f":"model_gbm = GradientBoostingClassifier(n_estimators=5000,\n                                       learning_rate=0.05,\n                                       max_depth=3,\n                                       subsample=0.5,\n                                       validation_fraction=0.1,\n                                       n_iter_no_change=20,\n                                       max_features='log2',\n                                       verbose=1)\nmodel_gbm.fit(X_train, y_train)","22729409":"len(model_gbm.estimators_)","fa086e27":"y_train_pred = model_gbm.predict_proba(X_train)[:,1]\ny_valid_pred = model_gbm.predict_proba(X_valid)[:,1]\n\nprint(\"AUC Train: {:.4f}\\nAUC Valid: {:.4f}\".format(roc_auc_score(y_train, y_train_pred),\n                                                    roc_auc_score(y_valid, y_valid_pred)))","d7766107":"y_train_pred_trees = np.stack(list(model_gbm.staged_predict_proba(X_train)))[:,:,1]\ny_valid_pred_trees = np.stack(list(model_gbm.staged_predict_proba(X_valid)))[:,:,1]\n\ny_train_pred_trees.shape, y_valid_pred_trees.shape","9af8df5d":"auc_train_trees = [roc_auc_score(y_train, y_pred) for y_pred in y_train_pred_trees]\nauc_valid_trees = [roc_auc_score(y_valid, y_pred) for y_pred in y_valid_pred_trees]","3aa0f8f1":"plt.figure(figsize=(12,5))\n\nplt.plot(auc_train_trees, label='Train Data')\nplt.plot(auc_valid_trees, label='Valid Data')\n\nplt.title('AUC vs Number of Trees')\nplt.ylabel('AUC')\nplt.xlabel('Number of Trees')\nplt.legend()\n\nplt.show()","01db4e0a":"pd.DataFrame({\"Variable_Name\":var_columns,\n              \"Importance\":model_gbm.feature_importances_}) \\\n            .sort_values('Importance', ascending=False)","5ebcc0ef":"df_test = pd.read_csv(input_dir + 'test.csv')\ndf_sample_submission = pd.read_csv(input_dir + 'sample_submission.csv')\n\ndf_test.shape, df_sample_submission.shape","05adcb91":"X_test = df_test.loc[:,var_columns]\n\ndf_sample_submission['target'] = model_gbm.predict_proba(X_test)[:,1]\ndf_sample_submission","ac8adf5d":"output_dir = '\/kaggle\/working\/'\ndf_sample_submission.to_csv(output_dir + '\/03_gbm_scores.csv', index=False)","542d7c07":"### Step5: Scoring for Test Data\nFirst, read test.csv and sample_submissions.csv","df6a2bde":"Look at how many estimators\/trees were finally created during training.","4994a4c2":"## Step3: Look at performance with respect to number of trees\n`staged_predict_proba` function allows us to look at predictions at for different number of trees in the model","9f13cc32":"## Step4: Feature Importance\nLow importance features can be removed from the model for simpler, faster and more stable model","81c00d16":"# Santander Customer Transaction Prediction - GBM\n\nIn the Kaggle competition, the objective is to identify which customer will make a transaction in the future.\n\n**Link to the competition**: https:\/\/www.kaggle.com\/c\/santander-customer-transaction-prediction\/  \n**Type of Problem**: Classification  \n**Metric for evalution**: AOC (Area Under Curve)\n\nThis Python 3 environment comes with many helpful analytics libraries installed\nIt is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python","3f0452bc":"## Step2: Create a simple GBM Model and evaluate performance\n\nLet us look at meaning of some of the parameters which are passed to GradientBoostingClassifier:  \n- `n_estimators`: **5000** will be the maximum number of trees in the model\n- `learning_rate`: **0.05** will be weights assigned predictions from each tree in the model\n- `max_depth`: **3** will be the maximum depth of any one tree in the model\n- `subsample`: **50%** of the observations would be used for fitting individual trees\n- `validation_fraction`: **10%** of observations would be used for validation\n- `n_iter_no_change`: **20** is the stopping criteria for training. If no change is observed in performance for 20 iterations, training stops\n- `max_features`: **log2(# features)** will be considered for finding best split","8cc2552d":"## Step1: Read Training Data from CSV\nUse pandas `read_csv` function to read the data from train.csv into a pandas dataframe.  \n\nThen the dataframe is split into train and test datasets using sklean's `train_test_split` function","ae2e601f":"Save the output as a csv"}}