{"cell_type":{"99a68740":"code","9d7ca057":"code","1ad24702":"code","345e2588":"code","0a827ec0":"code","362ce579":"code","6f4eea8c":"code","5f00ce69":"code","31424ad3":"code","38312610":"code","a6f4139d":"code","869f6a3a":"code","bd56defd":"code","d20c7d26":"code","4b6b409d":"code","9a73da89":"code","3bdac028":"code","9c5c7113":"code","98e2f92d":"code","734404ae":"code","9129753d":"code","3f90f16d":"code","05264282":"code","e3f3744c":"code","cb0c5ef3":"code","4247e7f3":"code","cdb8779a":"code","a4d63b8d":"code","3591fc54":"code","36d72283":"code","2462544a":"code","a32dde75":"code","8f3def92":"code","04a15e68":"code","25f5cfd5":"code","02648d7d":"code","4de654ff":"code","1ab52d05":"code","85dcbc86":"code","2c31f6bc":"code","0bb0239c":"markdown","8d74918e":"markdown","6bc4aa7d":"markdown","be200247":"markdown","b8545030":"markdown","254ad05f":"markdown","16b19d9b":"markdown","88bc5299":"markdown","dc8a839d":"markdown","c17f640d":"markdown","d928f0e7":"markdown","f29d412a":"markdown","4f727400":"markdown","9c9a68ae":"markdown","6c8a607c":"markdown","5e9e9d97":"markdown","b7a84973":"markdown","f94c83e4":"markdown","37ae94c9":"markdown","cfb1fb65":"markdown","86e399fc":"markdown","563ef3e6":"markdown","691f724b":"markdown","bbb90be1":"markdown","d09e5178":"markdown","922b6fbe":"markdown","3a56e8b7":"markdown","e6feff1d":"markdown","ee2f650a":"markdown","876ad2f4":"markdown","be4e140b":"markdown","7d57a506":"markdown","646a23ab":"markdown","b7285e0e":"markdown","dae671ab":"markdown","877f0e76":"markdown"},"source":{"99a68740":"! pip install seaborn==0.11.0","9d7ca057":"import numpy as np \n\nimport pandas as pd \npd.set_option('display.max_columns', None)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set_style(style=\"darkgrid\")\nsns.set_palette(palette = 'pastel')\n# color palette for seaborn\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.simplefilter(action='ignore')","1ad24702":"sns.__version__","345e2588":"data = pd.read_csv('\/kaggle\/input\/mental-health-in-tech-survey\/survey.csv')\ndata.head(2)","0a827ec0":"null_values = data.isnull().sum().sort_values(ascending=False).to_frame()\nnull_values = null_values.loc[null_values[0] != 0]\nax = sns.barplot(x=null_values.index, y=null_values[0], data=null_values,  palette=\"ch:.25\")\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\nax = ax.set(ylabel=\"count\", title='Parameters with NULL-values')","362ce579":"treatment_values = data.treatment.value_counts().to_frame()\nfamily_history_values = data.family_history.value_counts().to_frame()\nplot_frame = pd.DataFrame({'answers': ['No', 'Yes'], 'treatment': treatment_values['treatment'], 'family_history': family_history_values['family_history']})\nplot_frame = pd.melt(plot_frame, id_vars='answers', var_name=\"treatment\", value_name=\"family_history\")\nsns.factorplot(x='treatment', y='family_history', hue='answers', data=plot_frame, kind='bar',  palette=\"ch:.25\").set(ylabel='count', xlabel='', title='Answers count')\n\ntreatment_values_yes = data.treatment.loc[data.family_history == 'Yes'].value_counts().to_frame()\ntreatment_values_no = data.treatment.loc[data.family_history == 'No'].value_counts().to_frame()\nplot_frame = pd.DataFrame({'family_history_yes': treatment_values_yes['treatment'], 'family_history_no': treatment_values_no['treatment']})\nplot_frame.index.name = 'answers'\nplot_frame.reset_index(inplace=True)\nplot_frame = pd.melt(plot_frame, id_vars='answers', var_name=\"family_history_yes\", value_name=\"family_history_no\")\nsns.factorplot(x='family_history_yes', y='family_history_no', hue='answers', data=plot_frame, kind='bar',  palette=\"ch:.25\").set(ylabel='count', xlabel='', title='Treatment answers count')\n\nwork_interfere_yes = data.work_interfere.loc[data.treatment == 'Yes'].value_counts().to_frame()\nwork_interfere_no = data.work_interfere.loc[data.treatment == 'No'].value_counts().to_frame()\nplot_frame = pd.DataFrame({'treatment_yes': work_interfere_yes['work_interfere'], 'treatment_no': work_interfere_no['work_interfere']})\nplot_frame.index.name = 'answers'\nplot_frame.reset_index(inplace=True)\nplot_frame = pd.melt(plot_frame, id_vars='answers', var_name=\"treatment_yes\", value_name=\"treatment_no\")\nsns.factorplot(x='treatment_yes', y='treatment_no', hue='answers', data=plot_frame, kind='bar',  palette=\"ch:.25\").set(ylabel='count', xlabel='', title='Work interfere answers count')\n\nwork_interfere_yes = data.work_interfere.loc[data.family_history == 'Yes'].value_counts().to_frame()\nwork_interfere_no = data.work_interfere.loc[data.family_history == 'No'].value_counts().to_frame()\nplot_frame = pd.DataFrame({'family_history_yes': work_interfere_yes['work_interfere'], 'family_history_no': work_interfere_no['work_interfere']})\nplot_frame.index.name = 'answers'\nplot_frame.reset_index(inplace=True)\nplot_frame = pd.melt(plot_frame, id_vars='answers', var_name=\"family_history_yes\", value_name=\"family_history_no\")\nsns.factorplot(x='family_history_yes', y='family_history_no', hue='answers', data=plot_frame, kind='bar',  palette=\"ch:.25\").set(ylabel='count', xlabel='', title='Work interfere answers count')","6f4eea8c":"gender_values = data.Gender.value_counts().sort_values(ascending=False).to_frame()\ngender_values = gender_values.rename(columns={'Gender': 'count'})\ntable_gender = gender_values.style.background_gradient(cmap=cmap)\ntable_gender","5f00ce69":"# clean \"Gender\" column\n\ndata.Gender = data.Gender.str.lower()\nmale = [\"male\", \"m\", \"male-ish\", \"maile\", \"mal\", \"male (cis)\", \"make\", \"male \", \"man\",\"msle\", \"mail\", \"malr\",\"cis man\", \"cis male\"]\nfemale = [\"cis female\", \"f\", \"female\", \"woman\",  \"femake\", \"female \",\"cis-female\/femme\", \"female (cis)\", \"femail\"]\nother = [\"trans-female\", \"something kinda male?\", \"queer\/she\/they\", \"non-binary\",\"nah\", \"all\", \"enby\", \"fluid\", \n         \"genderqueer\", \"androgyne\", \"agender\", \"male leaning androgynous\", \"guy (-ish) ^_^\", \"trans woman\", \"neuter\", \n         \"female (trans)\", \"queer\", \"ostensibly male, unsure what that really means\", \"p\", \"a little about you\"]\n\ndata.Gender.loc[data.Gender.isin(male)] = 'male'\ndata.Gender.loc[data.Gender.isin(female)] = 'female'\ndata.Gender.loc[data.Gender.isin(other)] = 'others'\n\ngender_values = data.Gender.value_counts().sort_values(ascending=False).to_frame()\ngender_values = gender_values.rename(columns={'Gender': 'count'})\ntable_gender = gender_values.style.background_gradient(cmap=cmap)\ntable_gender","31424ad3":"from sklearn.ensemble import IsolationForest\n\n\ndef winsorization_outliers(df):\n    out=[]\n    for i in df:\n        q1 = np.percentile(df , 1)\n        q3 = np.percentile(df , 99)\n        if i > q3 or i < q1:\n            out.append(i)\n    print(\"Outliers:\",out)\n    return out\n    \noutliers = winsorization_outliers(data.Age)","38312610":"# drop age-outliers\n\ndata_age = data.loc[~data.Age.isin(outliers)]\nsns.histplot(data=data_age, x=\"Age\")","a6f4139d":"import plotly.express as px\n\nfig = px.violin(data_age, y=\"Age\", x=\"treatment\", color=\"Gender\", box=True, points=\"all\")\nfig.show()","869f6a3a":"data_outliers = data.loc[data.Age.isin(outliers)]\n\ntreatment_female = data_outliers.treatment.loc[data_outliers.Gender == 'female'].value_counts().to_frame()\ntreatment_male = data_outliers.treatment.loc[data_outliers.Gender == 'male'].value_counts().to_frame()\n\nplot_frame = pd.DataFrame({'treatment_female': treatment_female['treatment'], 'treatment_male': treatment_male['treatment']})\n\nplot_frame.index.name = 'answers'\nplot_frame.reset_index(inplace=True)\nplot_frame = pd.melt(plot_frame, id_vars='answers', var_name=\"treatment_female\", value_name=\"treatment_male\")\nsns.factorplot(x='treatment_female', y='treatment_male', hue='answers', data=plot_frame, kind='bar',  palette=\"ch:.25\").set(ylabel='count', xlabel='', title='Outliers treatment for male\/female')","bd56defd":"country_count = data.Country.value_counts().sort_values(ascending=False).to_frame()[:10]\ncountry_count = country_count.rename(columns={'Country': 'count'})\nplt.figure(figsize=(15,5))\nax = sns.barplot(x=country_count.index, y='count', data=country_count,  palette=\"ch:.25\")\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\nax = ax.set_title('Top 10 countries')","d20c7d26":"state_count = data.state.value_counts().sort_values(ascending=False).to_frame()[:10]\nstate_count = state_count.rename(columns={'state': 'count'})\nplt.figure(figsize=(10,10))\nax = sns.barplot(x=state_count.index, y='count', data=state_count,  palette=\"ch:.25\")\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\nax = ax.set_title('Top 10 States')","4b6b409d":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=data.Country.loc[data.treatment == 'Yes'].value_counts().index.to_list()[:10], values = data.Country.loc[data.treatment == 'Yes'].value_counts()[:10], name=\"Treatment -Yes\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=data.Country.loc[data.treatment == 'No'].value_counts().index.to_list()[:10], values = data.Country.loc[data.treatment == 'No'].value_counts()[:10], name=\"Treatment - No\"),\n              1, 2)\n\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"Country and trearment\",\n   \n    annotations=[dict(text='Yes', x=0.19, y=0.5, font_size=20, showarrow=False),\n                 dict(text='No', x=0.78, y=0.5, font_size=20, showarrow=False)])\nfig.show()\n\n\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=data.state.loc[data.treatment == 'Yes'].value_counts().index.to_list()[:10], values = data.state.loc[data.treatment == 'Yes'].value_counts()[:10], name=\"Treatment -Yes\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=data.state.loc[data.treatment == 'No'].value_counts().index.to_list()[:10], values = data.state.loc[data.treatment == 'No'].value_counts()[:10], name=\"Treatment - No\"),\n              1, 2)\n\n\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"State and trearment\",\n   \n    annotations=[dict(text='Yes', x=0.19, y=0.5, font_size=20, showarrow=False),\n                 dict(text='No', x=0.78, y=0.5, font_size=20, showarrow=False)])\nfig.show()","9a73da89":"from category_encoders.ordinal import OrdinalEncoder\n\ndata_encoding = data\nencoder = OrdinalEncoder()\ndata_encoding = encoder.fit_transform(data.drop(['Timestamp', 'comments', 'Age'], axis=1))","3bdac028":"# new DataFrame\ndata_encoding['Age'] = data.Age\ndata_encoding.head()","9c5c7113":"corr = data_encoding.corr(method ='spearman')\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(15, 15))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.show()","98e2f92d":"f, ax = plt.subplots(figsize=(25, 1))\ntreatment = corr.sort_values(by=['treatment'], ascending=False).head(1).T\ntreatment = treatment.sort_values(by=['treatment'],ascending=False).T\nsns.heatmap(treatment, cmap=cmap, annot=True)\nplt.show()","734404ae":"ten_corr_features = ['family_history', 'work_interfere', 'care_options', 'obs_consequence', 'benefits', 'mental_health_consequence', \n                     'Country', 'anonymity', 'mental_health_interview', 'leave']","9129753d":"print('Top 10 features: \\n', ten_corr_features)","3f90f16d":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.preprocessing import MinMaxScaler\n\nfeatures_norm = MinMaxScaler().fit_transform(data_encoding.drop(['treatment'], axis=1))\nchi_selector = SelectKBest(chi2, k=10)\nchi_selector.fit(features_norm, data_encoding.treatment)\n\nchi_support = chi_selector.get_support()\nchi_feature = data_encoding.drop(['treatment'], axis=1).loc[:,chi_support].columns.tolist()\nprint(str(len(chi_feature)), 'selected features')","05264282":"print('Top-10 features: \\n', chi_feature)","e3f3744c":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n\nrfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=10, step=10, verbose=5)\nrfe_selector.fit(features_norm ,data_encoding.treatment)","cb0c5ef3":"rfe_support = rfe_selector.get_support()\nrfe_features = data_encoding.drop(['treatment'], axis=1).loc[:,rfe_support].columns.tolist()\nprint('Top-10 features: \\n', rfe_features)","4247e7f3":"! pip install git+https:\/\/github.com\/KamitaniLab\/smlr.git","cdb8779a":"import smlr\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(data_encoding.drop(['treatment'], axis=1), data_encoding.treatment, test_size=0.33, random_state=42)\n\nmodel = smlr.SMLR(max_iter=1000, tol=1e-8, verbose=5)\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)","a4d63b8d":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, predictions))","3591fc54":"features_weight = model.coef_[0]\nfeatures_index = [id for id, weight in enumerate(features_weight) if weight!=0]\nsmlr_features = data_encoding.drop(['treatment'], axis=1).iloc[:, features_index].columns.to_list()\nprint('Top SLMR features: \\n', smlr_features)","36d72283":"! pip install ReliefF","2462544a":"from ReliefF import ReliefF\n\nfs = ReliefF(n_neighbors=1, n_features_to_keep=10)\nfeatures = fs.fit_transform(data_encoding.drop(['treatment'], axis=1).to_numpy(), data_encoding['treatment'].to_numpy()).T","a32dde75":"columns = data_encoding.drop(['treatment'], axis=1).columns.to_list()\nreliefF_features = []\nfor feature in features:\n    for column in columns:\n        idx = (data_encoding.drop(['treatment'], axis=1)[column] == feature)\n        if idx.all() == True:\n            reliefF_features.append(column)\n\nprint('Top-10 features: \\n', reliefF_features)","8f3def92":"feature_names = pd.DataFrame({'features': columns})\nfeature_names = feature_names.set_index('features')\nfeature_names[['correlation', 'chi_2', 'rfe', 'smlr', 'reliefF']] = np.nan","04a15e68":"def is_important_feature(row, features):\n    names = []\n    for index in row.index.to_list():\n        if index in features:\n            names.append(index)\n        else:\n            names.append(np.NaN)\n    return names","25f5cfd5":"feature_names.correlation = feature_names.apply(lambda row: is_important_feature(row, ten_corr_features))\nfeature_names.chi_2 = feature_names.apply(lambda row: is_important_feature(row, chi_feature))\nfeature_names.rfe = feature_names.apply(lambda row: is_important_feature(row, rfe_features))\nfeature_names.smlr = feature_names.apply(lambda row: is_important_feature(row, smlr_features))\nfeature_names.reliefF = feature_names.apply(lambda row: is_important_feature(row, reliefF_features))","02648d7d":"feature_names","4de654ff":"feature_names['counts'] = 5 - feature_names.isnull().sum(axis=1)","1ab52d05":"plt.figure(figsize=(20,5))\nfeatures_counts = feature_names['counts'].sort_values(ascending=False).to_frame()\nax = sns.barplot(x=features_counts.index, y='counts', data=features_counts,  palette=\"ch:.25\")\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\nax = ax.set_xticklabels(features_counts.index, rotation = 45, ha=\"right\")\n","85dcbc86":"import plotly.express as px\n\n\nfig = px.parallel_categories(data[['treatment', 'obs_consequence', 'family_history',  \n                                   'work_interfere']])\nfig.show()","2c31f6bc":"fig = px.parallel_categories(data[['treatment', 'care_options', \n                                   'anonymity', 'Gender', 'benefits', 'mental_health_consequence']])\nfig.show()","0bb0239c":"After cleaning \"Gender\"-column:","8d74918e":"## Comparing:","6bc4aa7d":"## Treatment, Family history and Work interfere\n\nExplore our \"target\" value - treatment.\n\nCandidates answered 'yes', if treatment is for a mental health condition was, and 'no' if treatment was not.\n","be200247":"# <center>Exploring mental health in the tech industry in 2014<\/center>\n\nSome information about explored data:\n\n- \"*This dataset is from a 2014 survey that measures attitudes towards mental health and frequency of mental health disorders in the tech workplace*\". \n- **Features:**\n\n<table>\n<thead>\n<tr><th>Feature name<\/th><th>Description<\/th><\/tr>\n<\/thead>\n<tbody>\n<tr><td>Timestamp<\/td><td> - <\/td><\/tr>\n<tr><td>Age<\/td><td> - <\/td><\/tr>\n<tr><td>Gender<\/td><td> - <\/td><\/tr>\n<tr><td>Country<\/td><td> - <\/td><\/tr>\n<tr><td>State<\/td><td> (only for US) <\/td><\/tr>\n<tr><td>Self employed<\/td><td> Are you self-employed? <\/td><\/tr>\n<tr><td>Family history<\/td><td> Family history of mental illness <\/td><\/tr>\n<tr><td>Treatment<\/td><td>Is treatment for a mental health condition was?<\/td><\/tr>\n<tr><td>Work interfere<\/td><td> Is mental health condition affects work? <\/td><\/tr>\n<tr><td>No employees<\/td><td> The number of employees in your company or organization <\/td><\/tr>\n<tr><td>Remote work<\/td><td> Having remote work (outside of an office) at least 50% of the time <\/td><\/tr>\n<tr><td>Tech company<\/td><td> The employer is primarily a tech company\/organization <\/td><\/tr>\n<tr><td>Benefits<\/td><td> Providing mental health benefits by the employer <\/td><\/tr>\n<tr><td>Care options:<\/td><td> Providing options for mental health care by the employer <\/td><\/tr>\n<tr><td>Wellness program<\/td><td> Discussion about mental health as part of an employee wellness program by the employes <\/td><\/tr>\n<tr><td>Seek help<\/td><td> Providing resources by the employer to learn more about mental health issues and how to seek help <\/td><\/tr>\n<tr><td>Anonymity<\/td><td> Protecting anonymity if you choose to take advantage of mental health or substance abuse treatment resources<\/td><\/tr>\n<tr><td>Leave<\/td><td> How easy is it for you to take medical leave for a mental health condition? <\/td><\/tr>\n<tr><td>Mental-health consequence: <\/td><td>  Having negative consequences caused by discussing a mental health issue with your employer<\/td><\/tr>\n<tr><td>Phys-health consequence<\/td><td> Having negative consequences caused by discussing a physical health issue with your employer <\/td><\/tr>\n<tr><td>Coworkers<\/td><td> Would you be willing to discuss a mental health issue with your coworkers?<\/td><\/tr>\n<tr><td>Supervisor<\/td><td> Would you be willing to discuss a mental health issue with your direct supervisor(s)? <\/td><\/tr>\n<tr><td>Mental health interview:<\/td><td> Would you bring up a mental health issue with a potential employer in an interview? <\/td><\/tr>\n<tr><td>Phys health interview<\/td><td> Would you bring up a physical health issue with a potential employer in an interview? <\/td><\/tr>\n<tr><td>Mental vs Physical<\/td><td> Do you feel that your employer takes mental health as seriously as physical health? <\/td><\/tr>\n<tr><td>Obs consequence<\/td><td> Have you heard of or observed negative consequences for coworkers with mental health conditions in your workplace? <\/td><\/tr>\n<tr><td>Comments<\/td><td> Any additional notes or comments <\/td><\/tr>\n<\/tbody>\n<\/table>\n","b8545030":"## Coutry, State\n\n- Exploring country and state columns","254ad05f":"Correlation for 'treatment' column:","16b19d9b":"Explore important features with count = 4:","88bc5299":"## Country, State and Treatment ","dc8a839d":"Well, we have 27 columns (features) and 1259 rows (values - candidates, who answered the questions):","c17f640d":"## Chi-2","d928f0e7":"## SMLR","f29d412a":"Gender unique values:","4f727400":"Have we got any *NULL-values*? Let's plot them:","9c9a68ae":"## Relief","6c8a607c":"All of the questions have categorical answers.\n\nIn the future, we could use categorical encoding for them. I use OrdinalEncoder for all columns with the exception of 'Timestamp', 'comments', 'Age'.","5e9e9d97":"Checking age values:\n\nWell, for the first, let's find outliers with  Percentile Capping (Winsorization) method:\n\n    If a value exceeds the value of the 99th percentile and below the 1st percentile of given values are treated as outliers.","b7a84973":"\n\n\n\n# **<center> Table of content: <\/center>**\n\n**November, 2020.**\n\n - [Exploratory data analysis](#EDA:) \n - [Feature Selection](##Feature-Selection:) \n - ...\n \n \n<p> <font size=\"3\" color=\"red\"> will be updated, if u find it useful, please upvote :) <\/font> <\/p>","f94c83e4":"- In both cases, the median man age is higher than female;\n\n- If treatment was, the max men age is higher than women, and if treatment was not, the max women age is higher than men;\n\n- Women and others have more cases in treatment-yes category.","37ae94c9":"Explore important features with count = 5:","cfb1fb65":"## RFE","86e399fc":"On the bar plot we can see the most important features.\nThey are \n- obs_consequence, wich means having heard of or observed negative consequences for coworkers with mental health conditions in workplace;\n- family history, which means family history of mental illness;\n- work_interfere: \"Is mental health condition affects work?;\n- care options, which means providing options for mental health care by the employer;\n- anonymity, which means protecting anonymity if you choose to take advantage of mental health or substance abuse treatment resources;\n- country;\n- gender;\n- benefits, which means providing mental health benefits by the employer;\n- mental_health_consequence, which means having negative consequences caused by discussing a mental health issue with your employer.","563ef3e6":"**RFE (Recursive Feature Removal)**: \n\nA greedy search algorithm that selects features by recursively defining ever smaller feature sets. It ranks the features according to the order in which they are removed.","691f724b":"## Correlation\n\nCorrelation is a simple approach to find **linear** dependence between features.\n- If correlation == |1| - two features have linear dependence;\n- If correlation == 0 - two features have not linear dependence.","bbb90be1":"# Feature Selection:\n\nTrying different approaches  and comparing results:\n\n- Correlation; \n- Chi-2;\n- RFE;\n- SMLR;\n- ReliefF.","d09e5178":"Explore outliers data:","922b6fbe":"- High correlation is had between ['wellness_program' and 'seek_help'] and ['state' and 'country'];\n- For our target value (treatment) high correlation have 'care_options', 'work interface', 'benefits'.","3a56e8b7":"## Age, Gender and Treatment\n\n- At the first, we explore the \"Gender\" column;\n- At the second, we explore the \"Age\" column;\n- Exploring \"treatment\" from age-gender point.","e6feff1d":"**SLMR(Sparse Logistic Regression MULTINOMIAL, sparse multinomial logistic regression):**\n\nThis algorithm implements the l1-regularization using ARD (Automatic relevance determination, automatic determination of relevance ) in the classical multinomial logistic regression. Regularization determines the importance of each feature and nullifies those that are useless for forecasting.","ee2f650a":"This method samples randomly instances from the dataset and updates the relevance of each feature based on the difference between the selected instance and the two nearest instances of the same and opposite classes. If a feature difference is observed in the neighboring instances of the same class ( a \u2018hit\u2019), the feature score decreases, alternatively if the feature value difference is observed with a different score (a \u2018miss\u2019) then the feature score increases.\n\n![](https:\/\/miro.medium.com\/max\/472\/1*EjkXuRcsUqQyQ-sw8uCM8w.png)\n\nThe extended algorithm, ReliefF applies feature weighting and searches for more nearest neighbors.","876ad2f4":"<center> At first, let's exploring mental health in the tech industry in 2014. Then, comparing results with data from 2016 and adding data from word-happiness in 2016. <\/center>","be4e140b":"Dropping outliers and check distribution:","7d57a506":"\"treatment\" analysis  from the age-gender point:","646a23ab":"# EDA:","b7285e0e":"## Encoding features","dae671ab":"Checks if there is a significant difference between the observed and expected frequencies of two categorical numbers. Thus, the null hypothesis that there is no relationship between the variables is tested:\n\n<center> $X^{2}=\\frac{(\\textrm{Observed frequency} - \\textrm{Expected frequency})^2}{\\textrm{Expected frequency}}$ <\/center>\n\nI want to use top-10 features:","877f0e76":"For most common countries:"}}