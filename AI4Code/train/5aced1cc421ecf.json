{"cell_type":{"96ca03d2":"code","bdea4c44":"code","64314c6c":"code","5bfdafcc":"code","5964d20c":"code","54ccdbec":"code","7a661af7":"code","8ceea229":"code","5a805316":"code","29b5471e":"code","58640a7c":"markdown","1e299232":"markdown","046480a0":"markdown","3798cf6b":"markdown","15042f3a":"markdown","4cb56a36":"markdown","bfcf509b":"markdown","0f9b271f":"markdown"},"source":{"96ca03d2":"import copy\nimport numpy as np\nimport pandas as pd\nimport datatable as dt\nfrom itertools import permutations\nimport networkx as nx\n!apt install -y graphviz libgraphviz-dev pkg-config\n!pip install pygraphviz\n#import pygraphviz\nimport pylab\n\nimport plotly.graph_objs as go","bdea4c44":"train_file = '\/kaggle\/input\/jane-street-market-prediction\/train.csv'\ntags_file = '\/kaggle\/input\/jane-street-market-prediction\/features.csv'\ntags_df = pd.read_csv(tags_file, index_col=0)\nfeat_list = tags_df.index.to_list()\n\n\ndef nx_graph_info(G):\n    print(f\"radius: {nx.radius(G)}\")\n    print(f\"diameter: {nx.diameter(G)}\")\n    print(f\"eccentricity: {nx.eccentricity(G)}\")\n    print(f\"center: {nx.center(G)}\")\n    print(f\"periphery: {nx.periphery(G)}\")\n    print(f\"density: {nx.density(G)}\")\n\n\ndef edge_weights(rows=1_000_000):\n    df = dt.fread(train_file).to_pandas()\n    corrs = df.iloc[:rows, :].corr().abs()\n\n    # Only interested in correlations between features in the tags list\n    corrs = corrs.loc[feat_list, feat_list]\n    return corrs\n\n\ndef graph_data(corrs, tags=None):\n    tag_list = tags_df.columns.to_list()\n    if tags is not None:\n        tag_list = tags\n\n    d = pd.DataFrame()\n    a = tags_df.unstack()\n    a = a[a == True]\n    for tag in tag_list:\n        perms = list(permutations(a[tag].index.to_list(), 2))\n        perms = pd.DataFrame(perms)\n        perms['Tag']=tag\n        d = pd.concat([d, perms])\n    d = d.drop_duplicates().reset_index(drop=True)\n    df1 = pd.DataFrame(np.sort(d[[0, 1]], axis=1))\n    d = d[~df1.duplicated()].reset_index(drop=True)\n\n    vals = pd.Series(dtype=object)\n    for index, row in d.iterrows():\n        vals = vals.append(pd.Series(corrs.loc[row[0], row[1]]))\n    vals = pd.DataFrame(vals).reset_index(drop=True)\n\n    d = pd.concat([d, vals], axis=1)\n    d.columns = ['Source', 'Target', 'Tag', 'Weight']\n    d['Type'] = 'Undirected'\n    return d\n\n\ndef get_nx_graph(d, corrs, min_corr=.0001):\n    G = nx.from_pandas_edgelist(d[d.Weight > min_corr],source='Source',\n                                target='Target',edge_attr=['Tag','Weight'])\n    G.remove_edges_from(nx.selfloop_edges(G))\n    return G","64314c6c":"def do_nx_plotly(G,title='',edge_colors_by_tag=False):\n    edge_x = []\n    edge_y = []\n    edge_t = []\n    for edge in G.edges():\n        x0, y0 = G.nodes[edge[0]]['pos']\n        x1, y1 = G.nodes[edge[1]]['pos']\n        edge_x.extend([x0,x1,None])\n        edge_y.extend([y0,y1,None])\n        if edge_colors_by_tag:\n            tag = G[edge[0]][edge[1]]['Tag']\n            edge_t.extend([tag, tag, tag])\n    edge_trace = []\n    if edge_colors_by_tag:\n        edges = list(G.edges())\n        tags = set([ G[e[0]][e[1]]['Tag'] for e in edges])\n        num_tags = len(tags)\n        # Get a new color for each tag\n        cm = pylab.get_cmap('magma')\n        colors = list((cm(1.*i\/num_tags) for i in range(num_tags)))\n        # Lighten colors by half\n        colors = [ x[:-1] + tuple([.5]) for x in colors]\n        colors = ['rgba'+str(l) for l in colors]\n        \n        # For each tag, make a new set of edges to plot\n        for tag_num,tag in enumerate(tags):\n            msk = [ t == tag for t in edge_t ]\n            x_tag = np.array(edge_x)[msk].tolist()\n            y_tag = np.array(edge_y)[msk].tolist()\n            edge_trace.append(go.Scatter(x=x_tag, y=y_tag,\n                                    line=dict(width=0.5, color=colors[tag_num]),                            \n                                    hoverinfo='none', mode='lines'))\n    else:\n        edge_trace.append(go.Scatter(x=edge_x, y=edge_y,\n                                line=dict(width=0.5, color='#888'),                            \n                                hoverinfo='none', mode='lines'))\n    node_x = []\n    node_y = []\n    texts = []\n    for node in G.nodes():\n        x, y = G.nodes[node]['pos']\n        node_x.append(x)\n        node_y.append(y)\n        if isinstance(node, str):\n            texts.append(node.replace('feature_','f_'))\n    \n\n    node_trace = go.Scatter(x=node_x, y=node_y,mode='markers+text',\n                            text=texts,textposition=\"top left\",\n                    marker=dict(showscale=True, colorscale='YlGnBu',\n                    reversescale=True, color=[],\n                    size=10, colorbar=dict(\n                        thickness=15, title='Node Connections',\n                        xanchor='left', titleside='right'\n                    ),line_width=2))\n    node_adjacencies = []\n    node_text = []\n    for node, adjacencies in enumerate(G.adjacency()):\n        node_adjacencies.append(len(adjacencies[1]))\n        f_str = 'f_' + str(node) + ': '\n        node_text.append(f_str + '# of connections: '+str(len(adjacencies[1])))\n    node_trace.marker.color = node_adjacencies\n    fig = go.Figure(\n        layout=go.Layout(\n            title=title,\n            titlefont_size=16, showlegend=False,\n            hovermode='closest',\n            margin=dict(b=20, l=5, r=5, t=40),\n            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n            height=600,\n        )\n    )\n    fig.add_traces(edge_trace)\n    fig.add_traces(node_trace)\n    fig.show()\n","5bfdafcc":"# This takes a while because we are calculating correlation coefficients for 1_000_000 rows\nprint('Calculating correlation coefficients...', end='')\ncorrs = edge_weights(rows=1_000_000)\nprint('done.')\n\nequal_weights = pd.DataFrame(np.ones((len(feat_list),len(feat_list))), columns=feat_list)\nequal_weights.index = feat_list","5964d20c":"d = graph_data(equal_weights)\nG = get_nx_graph(d, equal_weights)\npos = nx.drawing.nx_agraph.graphviz_layout(G, prog='neato')\nfor n, p in pos.items():\n    G.nodes[n]['pos'] = p\n\ndo_nx_plotly(G,title='All Tags With Weights Set To 1')","54ccdbec":"d = graph_data(corrs)\nG = get_nx_graph(d, corrs)\npos = nx.drawing.nx_agraph.graphviz_layout(G, prog='neato')\nfor n, p in pos.items():\n    G.nodes[n]['pos'] = p\ndo_nx_plotly(G,title='All Tags with Correlation Coefficients as Edge Weights')","7a661af7":"d = graph_data(corrs)\nG = get_nx_graph(d, corrs, min_corr = .4)\npos = nx.drawing.nx_agraph.graphviz_layout(G, prog='neato')\nfor n, p in pos.items():\n    G.nodes[n]['pos'] = p\ndo_nx_plotly(G,title='All Tags with Correlation Coefficients <.4 as Edge Weights')","8ceea229":"d = graph_data(corrs, tags=['tag_15', 'tag_6', 'tag_14', 'tag_17', 'tag_20', 'tag_22', 'tag_21'])\nG = get_nx_graph(d, corrs)\npos = nx.drawing.nx_agraph.graphviz_layout(G, prog='neato')\nfor n, p in pos.items():\n    G.nodes[n]['pos'] = p\ndo_nx_plotly(G,title='Tags 6, 14, 15, 17, 20, 21, 22', edge_colors_by_tag=True)","5a805316":"d = graph_data(corrs, tags=['tag_15', 'tag_17', 'tag_23'])\nG = get_nx_graph(d, corrs)\n\npos = nx.fruchterman_reingold_layout(G, k=.5)\n\nfor n, p in pos.items():\n    G.nodes[n]['pos'] = p\ndo_nx_plotly(G,title='Tags 15, 17, 23', edge_colors_by_tag=True)","29b5471e":"tag_str = '5, 14, 19, 18, 20, 0, 1, 22, 2, 3, 4'\ntags = ['tag_'+str(x) for x in [5,14,19,18,20,0,1,22,2,3,4]]\nd = graph_data(corrs, tags=tags)\nG = get_nx_graph(d, corrs)\n\npos = nx.drawing.nx_agraph.graphviz_layout(G, prog='neato')\n\nfor n, p in pos.items():\n    G.nodes[n]['pos'] = p\ndo_nx_plotly(G,title='Tags '+ str(tag_str))","58640a7c":"## Ideas and Further Research\nWhat does this get us?  These subgraphs potentially help de-anonymize the features.\n\nIt may help to run each of these sets of feature groups through a non-linear dimension reduction algorithm in order to derive a cleaner signal. These feature groups represent properties of the underlying data probably scaled over different time and\/or modal domains.  For example, tags  15, 17 may represent trading Volume and price Volatilty connected by tag 23, which may represent Time.\n\nBy isolating these feature groups and examining how they relate to each other, we can engineer better features.\n\nWhat do you think?\n","1e299232":"What's going on with features 44, 45, 46, 49, and 50?\n\n* Features 45, 46, and 50 have tag 17 but not tag 23\n* Features 49 and 44 have tag 15 but not tag 23\n\nThere are also some other distinct subgraphs (Tags 5, 14, 19, 18, 20, 0, 1, 22, 2, 3, and 4):","046480a0":"Ok, that was unhelpful.  Let's invalidate edges below a minimum correlation coefficient.","3798cf6b":"## Network Graph Plots\nLet's take a simple look at what the graph of these relationships looks like by setting all relationship weights to 1 and using a simple graph layout algorithm. (You can zoom in and examine using plotly's interface).","15042f3a":"We have 7 clusters here. Tags 6, 14, 15, 17, 20, 21, 22 create [fully connected subgraphs](https:\/\/en.wikipedia.org\/wiki\/Complete_graph).\n\nInterestingly, tags 15 and 17 form distinct fully connected subgraphs, which are almost fully connected by tag 23:","4cb56a36":"# Tag Network Analysis\n\nAs we've seen in this competition, the anonymized features seem to have strong underlying structure.  I thought I'd take a look and try to tease out some of this structure using graph analysis with [Gephi](https:\/\/gephi.org\/) and [NetworkX](https:\/\/networkx.org\/).\n\nI encourage you to take a look at Gephi: it's a powerful tool for examining network topologies.\n\nHere's an example:\n![Gephi](https:\/\/media.giphy.com\/media\/oxyhw1j0L1GjK8pRYR\/giphy.gif)\n\nThe features.csv file essentially says that certain features are related to one another in some unknown way.  As noted in the excellent notebook by Andrea Politano [here](https:\/\/www.kaggle.com\/apolitano20\/jane-street-features-hierarchical-clustering\/), we can represent these relationships as an adjacency matrix and conduct various analyses on it.","bfcf509b":"Interesting. We're starting to seem some clusters break off. I took a look in gephi and it was clear that there are groups. Let's plot these and color the edges by tag:","0f9b271f":"Ok that shows what we know: there's plenty of structure here.  Let's use the correlation coefficients between all the features as weights for the graph."}}