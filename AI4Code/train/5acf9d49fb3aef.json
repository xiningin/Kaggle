{"cell_type":{"5aaa69a6":"code","8b57aa05":"code","73503d61":"code","658a8640":"code","f40d2c71":"code","785b2a55":"code","c45588c4":"code","5eecf134":"code","355f4c09":"code","99843309":"code","80f7fc42":"code","9efe2b9d":"code","4659f5fb":"markdown","221f72d8":"markdown","2366d751":"markdown","9885c29a":"markdown","9908e95a":"markdown","f8a329e8":"markdown","71284af3":"markdown","de80e8fb":"markdown","76e85725":"markdown"},"source":{"5aaa69a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8b57aa05":"#We will generate 1,000 samples of two two variables with a strong positive correlation.\nfrom numpy.random import randn\nimport matplotlib.pyplot as plt\nx1=20 * randn(1000)+100\n#print(x1) #will print all the random 1000 numbers\nx2=x1+(10 * randn(1000)+50)\n#print(x2) #will print all the random 1000 numbers\n#plot\nplt.scatter(x1,x2)\nplt.show() # you will expect as a linear relationship between the x1 and x2\nsns.distplot(x1)\nsns.distplot(x2)\nplt.show","73503d61":"from scipy.stats import pearsonr\ncoefp,pvalue=pearsonr(x1,x2)\nprint(\"Pearson Value\",coefp,pvalue)","658a8640":"import numpy as np\nfrom numpy.random import randn\nimport seaborn as sns\nx3=randn(1000)\nx4=10* randn(1000)\nimport matplotlib.pyplot as plt\nplt.scatter(x3,x4)\nplt.show()\nsns.distplot(x3)\nsns.distplot(x4)\nplt.show()","f40d2c71":"from scipy.stats import pearsonr\ncoef1,p=pearsonr(x3,x4)\nprint(\"Pearsonr Value\",coef1,p)\nfrom scipy.stats import spearmanr\ncoef2,p2=spearmanr(x3,x4)\nprint(\"spearmanr value\",coef2,p2)\nfrom scipy.stats import kendalltau\ncoef3,p3=kendalltau(x3,x4)\nprint(\"KendallTau value\",coef3,p3)","785b2a55":"# Applying Spearman's Coeffecient in Uniform Distribution\nimport numpy as np\nimport seaborn as sns\ns = np.random.uniform(-1,0,1000)\nd = np.random.uniform(-1,0,1000)\nimport matplotlib.pyplot as plt\nplt.scatter(s,d)\nplt.show()\nsns.distplot(s)\nsns.distplot(d)\nplt.show()\n# calculate spearman's correlation\nfrom scipy.stats import spearmanr\ncoef,p = spearmanr(s,d)\nprint(coef,p)","c45588c4":"#Comparison of Pearson and Spearman's Coeffecient in Non linear or random Distribution\nfrom numpy.random import randn\nfrom scipy.stats import spearmanr\nimport matplotlib.pyplot as plt\nfrom scipy.stats import pearsonr\nx6=10 * randn(1000) + 20\nx7= randn(1000) + 10\ncoef,p=spearmanr(x6,x7)\npears,p=pearsonr(x6,x7)\nprint(\"Spearmans Coeffecient\",coef,p)\nprint(\"Pearson's Coeffecient\",pears,p)\nplt.scatter(x6,x7)\nplt.show()\n#--------#\nimport seaborn as sns\nsns.distplot(x6)\nsns.distplot(x7)\nplt.show","5eecf134":"#Comparison of Pearson and Spearman's Coeffecient in linear or Normal\/gaussian Distribution\nfrom numpy.random import randn\nfrom scipy.stats import spearmanr\nimport matplotlib.pyplot as plt\nfrom scipy.stats import pearsonr\nx6=10 * randn(1000) + 20\nx7= x6+randn(1000) + 10\ncoef,p=spearmanr(x6,x7)\npears,p=pearsonr(x6,x7)\nprint(\"Spearmans Coeffecient\",coef,p)\nprint(\"Pearson's Coeffecient\",pears,p)\nplt.scatter(x6,x7)\nplt.show()\n#--------#\nimport seaborn as sns\nsns.distplot(x6)\nsns.distplot(x7)\nplt.show","355f4c09":"# Kendalls Tau Coeffecient of correlation\nfrom scipy.stats import kendalltau\nfrom numpy.random import randn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nvar1=10 + randn(1000)\nvar2= randn(1000)\ncoef,p=kendalltau(var1,var2)\nalpha=0.05\nprint(coef,p)\nplt.scatter(var1,var2)\nsns.distplot(var1)\nsns.distplot(var2)\nplt.show()\nif p>alpha:\n    print(\"samples are not correlated\")\nelse:\n    print(\"samples are highly correlated\")","99843309":"from scipy.stats import pearsonr\ncoef1,p1=pearsonr(var1,var2)\nprint(\"Pearsonr value\",coef1,p1)\nfrom scipy.stats import spearmanr\ncoef2,p2=spearmanr(var1,var2)\nprint(\"spearmanr value\",coef2,p2)\nfrom scipy.stats import kendalltau\ncoef3,p3=kendalltau(var1,var2)\nprint(\"KendallTau value\",coef3,p3)","80f7fc42":"#We will generate 1,000 samples of two two variables with a strong positive correlation.\nfrom numpy.random import randn\nimport matplotlib.pyplot as plt\nx1=20 * randn(1000)+100\n#print(x1) #will print all the random 1000 numbers\nx2=x1+(10 * randn(1000)+50)\n#print(x2) #will print all the random 1000 numbers\n#plot\n#plt.scatter(x1,x2)\n#plt.show() # you will expect as a linear relationship between the x1 and x2\nfrom numpy import cov\ncov(x1,x2)","9efe2b9d":"from scipy.stats import pearsonr\ncorr=pearsonr(x1,x2)\nprint(\"Pearson's Correlation Coeffecient:%.3f\",corr)\n","4659f5fb":"* The graph shows there is a linear relationship. But lets find out by using the Pearson's coeffecient\n* The value is close to 1 so they are highly correlated\n* Pearson correlation tests for linear relationship between  X and Y \n","221f72d8":"1. The above value is ~ equal to 1 which tells us that relationship is strongly correlated","2366d751":"* The covariance between x1 and x2 is 387.406\n* This values is positive so so it suggests that both the variables change in the same direction\n* Covariance doesnt give any strength of the relationship unlike correlation.\n* It is because, Covariance depends on the units or scale.\n* Correlation gives us both direction and strength as this doesnt depend on any units.It's a standardised version of covariance\n* If you want to calculate covariance with standardised value,then find z-score first and then calculate the covariance . Else you can directly calculate the correlation which gives the same results\n1. We get two values one is the correlation coeffecient and the other is the P value\n2. Here the value is close to 1 , so both the variables are highly correlated. This explains the strength\n3. Correlations of -1 or +1 imply an exact linear relationship (+ means its positive direction)\n4. So,suppose these two variables are present in your data set then you have to check the impact on the regression  equation by considering them independently (we will discuss later on this)","9885c29a":"* This is a non parametric distribution.\n* Its always better to use Spearman's Coeff. Of Corr for non parametric distribution\n* Spearman correlation tests for any  monotonic relationship between X and Y ","9908e95a":"* You can see that value of Kendall Tau is better than Spearman coeffeiceint which is better than Pearsonr coeffcient for Non Correlated data","f8a329e8":"** SUMMARY**\n* There are several ways to select best method. first check normality assumptions of data. if data obeys normality assumptions, then test with pearson method is the perfect way. if normality assumption fails then test with Spearman method or Kendall Tau.\n\nAnother way is if data falls under scale variable (continous or discrete - integers), some people prefer to do Pearson correlation than Spearman.\nI would like to point assumptions to be considered prior to do Pearson correlation\n\n1. Data should be continuous variables (any value within a interval)\n2. Normality (data points close to mean)\n3. Linearity (data follows linear relationship)\n4. Homoscedascity (Two variables has equal variances)\n5. Paired observations (data points must be in pairs)\n6. No outliers in the data (data points not significantly skewed)\n\n\nScatter plots are one of best tool to check above assumptions. You can test Shapiro-wilk test, levene tests for obtaining clear picture of scenario.\nMy personal opinion is not to present Pearson and Spearman both and if more assumptions met, you can go to Pearson method. If not it satisfied best to go Spearman","71284af3":"* This is a Linear Relationship between the variables,hence we can use pearson's correlation coeffeicient to measure the strength of the linear relationship between two quantitative variables.","de80e8fb":"* Here the value is close to 0 so there is no correlation between the variables s and d also as per the graph it is clear that there is no correlation between them","76e85725":"* Here the relationship is not linear.\n* Hence,the Pearson's Corr Coeff of -0.062 tells that they are not correlated as expected in Non linear data  Also they are negative in direction ,P value( will see later about that ). **But wait**\n* This procedure cannot be used for data that does not have a Gaussian distribution(Normal Distribution). Instead, rank correlation methods must be used.\n* Pearson's correlation coefficient is a measure of strength of **linear relationship** between the variable. So, it may **provide false results for non-linear relationship.**\n* for Non Linear relationship, its better to use Spearman's rank corr coeffecient.\n* This Spearman's Corr. Coef. test of relationship can also be used if there is a linear relationship between the variables, but will have slightly less power (e.g. may result in lower coefficient scores).\n* The graph shows non linear or we do not know what is the type of the distribution here \n* If you are unsure of the distribution and possible relationships between two variables, Spearman correlation coefficient is a good tool to use.\n* Unlike Pearson\u2019s product-momentcorrelation coefficient, it does not require the assumption that the relationship between the variables is linear, nor does it require the variables to\nbe measured on interval scales; it can be used for\nvariables measured at the ordinal level. \n* Because no distribution for the values is assumed, rank correlation methods are referred to as distribution-free correlation or nonparametric correlation.Bekow are them. But mostly used are Spearman and Kendall's Rank Co.\n1. Spearman\u2019s Rank Correlation.\n2. Kendall\u2019s Rank Correlation.\n3. Goodman and Kruskal\u2019s Rank Correlation.\n4. Somers\u2019 Rank Correlation.\n* The spearmanr() SciPy function can be used to calculate the Spearman\u2019s correlation coefficient between two data samples with the same length."}}