{"cell_type":{"ac716110":"code","059b4175":"code","c6e59c0b":"code","8933f989":"code","1ff4384a":"code","03ffed05":"code","34b6bef7":"code","5d5ac5f6":"code","11455bc8":"code","b2835afd":"code","d4a9fc9f":"code","e023fb86":"code","d40e4589":"code","937b55f2":"code","88adb8f0":"code","cd04ebc6":"code","43cc6b3d":"code","93ff6f26":"code","900fe215":"code","4d9aca26":"code","80b6db57":"code","bf191f59":"code","f2f37a74":"code","4774bc76":"code","3ee39b59":"code","d229217e":"code","5972de29":"code","e5eaa50a":"code","6977ccbe":"code","997d4c97":"markdown","3cc0d139":"markdown","5c0ec248":"markdown","6208576d":"markdown","437ca79c":"markdown","523165bb":"markdown","1792e307":"markdown","8fb1da51":"markdown","31e265ac":"markdown","4d4c1c66":"markdown","86f1088c":"markdown","81387458":"markdown","c34b14ed":"markdown","c446d8eb":"markdown","6d23f396":"markdown","f0bb24f5":"markdown","b3ec4d7c":"markdown","4b22bec1":"markdown","41fdf720":"markdown","211d1c6c":"markdown","b7b243e2":"markdown","db408648":"markdown","521fed04":"markdown","525c415f":"markdown","0db9c815":"markdown","1cf47187":"markdown","0ba9b3d1":"markdown","f0477db5":"markdown","bdc026c2":"markdown","6d25dec9":"markdown","898d236b":"markdown"},"source":{"ac716110":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer, InterclusterDistance\nfrom sklearn.cluster import KMeans, AgglomerativeClustering\nimport scipy.cluster.hierarchy as shc\nimport plotly.graph_objs as go","059b4175":"#from google.colab import drive\n#drive.mount('\/content\/drive\/',force_remount=True)\n#path = 'drive\/MyDrive\/Colab Notebooks\/UCSesp_ML1\/Olist_dataset\/'\n\n# replace the product categorie names to english\nproducts = pd.read_csv('\/kaggle\/input\/brazilian-ecommerce\/olist_products_dataset.csv')\nproducts.rename(columns={'product_name_lenght':'product_name_length',\n                         'product_description_lenght':'product_description_length'\n                         },inplace=True)#just a typo correction\ncategory_translation = pd.read_csv('\/kaggle\/input\/brazilian-ecommerce\/product_category_name_translation.csv')\nproducts = pd.merge(products, category_translation,how=\"left\",\n                    on=\"product_category_name\")\nproducts.drop([\"product_category_name\"], axis=1, inplace=True)\nproducts = products.rename(columns={\"product_category_name_english\":\n                                    \"product_category_name\"})\no_items = pd.read_csv(\"\/kaggle\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv\")\norders = pd.read_csv(\"\/kaggle\/input\/brazilian-ecommerce\/olist_orders_dataset.csv\")\no_reviews = pd.read_csv(\"\/kaggle\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv\")\ngeoloc = pd.read_csv(\"\/kaggle\/input\/brazilian-ecommerce\/olist_geolocation_dataset.csv\")\nsellers = pd.read_csv(\"\/kaggle\/input\/brazilian-ecommerce\/olist_sellers_dataset.csv\")\no_payments = pd.read_csv(\"\/kaggle\/input\/brazilian-ecommerce\/olist_order_payments_dataset.csv\")\ncustomers = pd.read_csv(\"\/kaggle\/input\/brazilian-ecommerce\/olist_customers_dataset.csv\")\n\nolist = orders.merge(o_items, on='order_id', how='left')\nolist = olist.merge(o_payments, on='order_id', how='outer', validate='m:m')\nolist = olist.merge(o_reviews, on='order_id', how='outer')\nolist = olist.merge(products, on='product_id', how='outer')\nolist = olist.merge(customers, on='customer_id', how='outer')\nolist = olist.merge(sellers, on='seller_id', how='outer')\nolist.drop(['customer_id','order_purchase_timestamp','order_approved_at',\n           'order_delivered_carrier_date','payment_sequential','review_id',\n           'payment_type','payment_installments','review_id',\n           'review_comment_title','review_comment_message','product_weight_g',\n            'product_length_cm','product_height_cm','product_width_cm',\n            'customer_unique_id','customer_zip_code_prefix',\n            'customer_zip_code_prefix','customer_city','seller_zip_code_prefix',\n            'seller_city','shipping_limit_date'],axis=1, inplace=True)\n\nolist = olist.dropna()\nolist.info()","c6e59c0b":"olist.groupby(\"order_status\").agg({\"order_id\": \"nunique\"}).\\\nsort_values('order_id', ascending=False)","8933f989":"olist = olist[olist.order_status=='delivered']\nolist = olist.drop(columns='order_status')","1ff4384a":"fig = plt.figure(figsize=(24,7))\n\naxes = plt.subplot2grid((1,3),(0,0))\nolist.groupby(\"product_category_name\").agg({\"order_id\": \"nunique\"})\\\n.sort_values('order_id', ascending=False).head(20).plot.\\\nbar(title='Amount of Sales per category', ax=axes)\n\naxes = plt.subplot2grid((1,3),(0,1))\nolist.groupby(\"product_category_name\").agg({\"payment_value\": \"sum\"})\\\n.sort_values('payment_value', ascending=False).head(20).plot.\\\nbar(title='Total Revenue (R$) per category',ax=axes)\n\naxes = plt.subplot2grid((1,3),(0,2))\nolist.groupby(\"product_category_name\").agg({\"payment_value\": \"mean\"})\\\n.sort_values('payment_value', ascending=False).head(20).plot.\\\nbar(title='Average Revenue (R$) per Sale per Category',ax=axes)","03ffed05":"prod_cat_name = olist.groupby(\"product_category_name\")\\\n.agg({\"order_id\": \"nunique\"}).sort_values('order_id', ascending=False).index.\\\nto_list()\noutras_cat = list((Counter(prod_cat_name)-Counter(prod_cat_name[0:10])).elements())\nolist = olist.replace(outras_cat,'others')\n\nfig = plt.figure(figsize=(24,7))\n\naxes = plt.subplot2grid((1,2),(0,0))\nolist.groupby(\"product_category_name\").agg({\"order_id\": \"nunique\"})\\\n.sort_values('order_id', ascending=False).plot.\\\nbar(title='Amount of Sales per category',ax=axes)\n\nprod_cat_name = prod_cat_name[0:10]\nprod_cat_name.append('others')\nprod_cat_name.sort()\n\naxes = plt.subplot2grid((1,2),(0,1))\nolist.groupby(\"seller_id\").agg({\"order_id\": \"nunique\"}).\\\nsort_values('order_id', ascending=False).head(50).plot.bar(\n    title='Top 50 sellers - Amount of Sales',ax=axes)","34b6bef7":"aux_seller = olist.groupby(\"seller_id\").agg({\"order_id\": \"nunique\"}).\\\nsort_values('order_id', ascending=False)\nN_totalsellers,aux = olist.groupby(\"seller_id\").agg({\"order_id\": \"nunique\"}).\\\nsort_values('order_id', ascending=False).shape\nN_uniquesell,aux = aux_seller[aux_seller.order_id==1].shape\nprint(f'There is {round(((N_uniquesell)\/N_totalsellers)*100,2)}% sellers with only one sale.')","5d5ac5f6":"olist['order_delivered_customer_date'] = pd.\\\nto_datetime(olist.order_delivered_customer_date)\nolist['order_estimated_delivery_date'] = pd.\\\nto_datetime(olist.order_estimated_delivery_date)\nolist['review_creation_date'] = pd.to_datetime(olist.review_creation_date)\nolist['review_answer_timestamp'] = pd.to_datetime(olist.review_answer_timestamp)\n\nolist['delivery_delay'] = olist.order_delivered_customer_date-\\\nolist.order_estimated_delivery_date\nolist['delivery_delay'] = olist.delivery_delay.astype('timedelta64[D]')\nolist['delay_review_response'] = olist.review_answer_timestamp-\\\nolist.review_creation_date\nolist['delay_review_response'] = olist.delay_review_response.\\\nastype('timedelta64[D]')\n\nolist = olist.drop(columns=['order_delivered_customer_date',\n                            'order_estimated_delivery_date',\n                            'review_creation_date', 'review_answer_timestamp'])\n","11455bc8":"fig = plt.figure(figsize=(24,7))\n\naxes = plt.subplot2grid((1,2),(0,0))\nolist.groupby('customer_state').agg({'order_id':'nunique'}).sort_values(\n    'order_id', ascending=False).plot.bar(ax=axes)\naxes = plt.subplot2grid((1,2),(0,1))\nolist.groupby('seller_state').agg({'order_id':'nunique'}).sort_values(\n    'order_id', ascending=False).plot.bar(ax=axes)","b2835afd":"States = olist.groupby('customer_state').agg({'order_id':'nunique'})\n\nSoutheast = ['SP','RJ','MG']\nSouth = ['RS','SC','PR']\nOthers = list((Counter(States.index)-Counter(Southeast)-Counter(South)).elements())\n\nolist = olist.replace(Southeast,'Southeast')\nolist = olist.replace(South,'South')\nolist = olist.replace(Others,'Others')\n\nfig = plt.figure(figsize=(24,7))\n\naxes = plt.subplot2grid((1,2),(0,0))\nolist.groupby('customer_state').agg({'order_id':'nunique'}).sort_values(\n    'order_id', ascending=False).plot.bar(title = 'Sales by region',\n                                          ax=axes)\naxes = plt.subplot2grid((1,2),(0,1))\nolist.groupby('seller_state').agg({'order_id':'nunique'}).sort_values(\n    'order_id', ascending=False).plot.bar(title = 'Sellers by region',\n                                          ax=axes)\n\n","d4a9fc9f":"enc = OneHotEncoder(sparse = False)\n\n\nolist[['Cust_Others','Cust_South','Cust_Southeast']] = enc.fit_transform(\n    olist[['customer_state']])\nolist[['Sel_Others','Sel_South','Sel_Southeast']] = enc.fit_transform(\n    olist[['seller_state']])\nolist[prod_cat_name] = enc.fit_transform(olist[['product_category_name']])\n\nolist_encoded = olist.drop(['customer_state','seller_state',\n                            'product_category_name'],axis=1)","e023fb86":"olist_encoded.tail(10)","d40e4589":"data = olist_encoded.groupby('seller_id').agg({'order_id':'nunique',\n                                        'product_id':'nunique',\n                                        'payment_value':'mean',\n                                        'review_score':'mean',\n                                        'product_name_length':'mean',\n                                        'product_description_length':'mean',\n                                        'product_photos_qty':'mean',\n                                        'delivery_delay':'mean',\n                                        'delay_review_response':'mean',\n                                        'Cust_Others':'sum',\n                                        'Cust_Southeast':'sum',\n                                        'Cust_South':'sum',\n                                        'Sel_Others':'max',\n                                        'Sel_Southeast':'max',\n                                        'Sel_South':'max',\n                                        'auto':'sum',\n                                        'bed_bath_table':'sum',\n                                        'computers_accessories':'sum',\n                                        'furniture_decor':'sum',\n                                        'health_beauty':'sum',\n                                        'housewares':'sum',\n                                        'others':'sum',\n                                        'sports_leisure':'sum',\n                                        'telephony':'sum',\n                                        'toys':'sum',\n                                        'watches_gifts':'sum',\n                                              })\ndata","937b55f2":"sns.set_style(\"whitegrid\")\nfont_title = {\"family\": \"serif\",\n              \"color\":  \"#476bff\",\n              \"weight\": \"bold\",\n              \"size\": 18}\n\ncorr = data.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nfig, ax = plt.subplots(figsize=(15,12))\nax = sns.heatmap(corr, annot=True,\n                 vmin=-1, vmax=1,\n                 fmt=\".2f\", annot_kws={'size':8}, \n                 mask=mask, \n                 center=0, \n                 cmap=\"coolwarm\")\nplt.title(f\"Correlation Heatmap\\n\", \n          fontdict=font_title)\nplt.show()","88adb8f0":"data = data.drop(columns = ['product_id','Cust_Others','Cust_Southeast',\n                            'Cust_South'])","cd04ebc6":"corr = data.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nfig, ax = plt.subplots(figsize=(15,12))\nax = sns.heatmap(corr, annot=True,\n                 vmin=-1, vmax=1,\n                 fmt=\".2f\", annot_kws={'size':8}, \n                 mask=mask, \n                 center=0, \n                 cmap=\"coolwarm\")\nplt.title(f\"Heatmap de correla\u00e7\u00f5es lineares\\n\", \n          fontdict=font_title)\nplt.show()","43cc6b3d":"data","93ff6f26":"scaler = MinMaxScaler()\n\ndef Kmeansplots(data):\n    X = data.copy()\n    numerical_features = list(data.select_dtypes(include=['int64','float64',\n                                                          'uint8']).columns)\n    preprocessor = ColumnTransformer([\n        ('scaler', scaler, numerical_features)])\n\n    plt.figure(figsize=(24, 14));ax1 = plt.subplot(2,3,1);ax2 = plt.subplot(2,3,2)\n    ax3 = plt.subplot(2,3,3);ax4 = plt.subplot(2,2,3);ax5 = plt.subplot(2,2,4)\n    \n    visual_grid1 = [\n                    (Pipeline([(\"preprocessor\", preprocessor),(\"kelbowvisualizer\"\n                    , KElbowVisualizer(KMeans(),K=(4,12),metric='distortion',\n                                      ax=ax1))]),'kelbowvisualizer'),\n                    (Pipeline([(\"preprocessor\", preprocessor),(\"kelbowvisualizer\"\n                    , KElbowVisualizer(KMeans(),K=(4,12),metric='silhouette',\n                                      ax=ax2))]),'kelbowvisualizer'),\n                    (Pipeline([(\"preprocessor\", preprocessor),(\"kelbowvisualizer\"\n                    , KElbowVisualizer(KMeans(),K=(4,12),metric='calinski_harabasz',\n                                      ax=ax3))]),'kelbowvisualizer')                    \n                  ]\n\n    i=0\n    for viz in visual_grid1:\n        viz[0].fit(X)\n        if i==0:\n          #Defining the best K by distortion method\n          K = viz[0].named_steps['kelbowvisualizer'].elbow_value_ \n          i = i+1\n        viz[0].named_steps[viz[1]].finalize()\n\n    visual_grid2 = [(Pipeline([(\"preprocessor\", preprocessor),(\"silhouettevisualizer\",\n                                      SilhouetteVisualizer(KMeans(K,random_state=0),ax=ax4))]),\n                                      'silhouettevisualizer'),\n                    (Pipeline([(\"preprocessor\", preprocessor),(\"distancevisualizer\",\n                                      InterclusterDistance(KMeans(K,random_state=0),ax=ax5))]),\n                                        'distancevisualizer')]\n    for viz in visual_grid2:\n      viz[0].fit(X)\n      viz[0].named_steps[viz[1]].finalize()\n\n    # KMeans Pipeline with best K\n    kmeans_model = Pipeline([(\"preprocessor\", preprocessor),\n                            (\"kmeans\", KMeans(K,random_state=0))])\n    kmeans_model.fit(X)\n    # Kmeans labels\n    kmeans_labels = kmeans_model.named_steps['kmeans'].labels_  \n    X[\"kmeans_label\"] = kmeans_labels\n\n    return X\n\nX_0 = Kmeansplots(data)","900fe215":"X_0.groupby(['kmeans_label']).agg({'kmeans_label':'count',  \n                                   'Sel_Others':'sum',\n                                   'Sel_Southeast':'sum',\n                                   'Sel_South':'sum'})","4d9aca26":"data_1 = data.drop(columns=['Sel_Others','Sel_South','Sel_Southeast'])\n#data_1.to_csv(path+'seller_data_1.csv')\nX_1= Kmeansplots(data_1)","80b6db57":"X_1.groupby('kmeans_label').agg({'order_id':'count'})","bf191f59":"fig = plt.figure(figsize=(24,7))\n\naxes = plt.subplot2grid((1,2),(0,0))\nX_1.groupby(['kmeans_label']).agg({'auto':'mean', \n                                   'bed_bath_table':'mean',\n                                   'computers_accessories':'mean',\n                                   'furniture_decor':'mean',\n                                   'health_beauty':'mean',\n                                   'housewares':'mean',\n                                   'others':'mean',\n                                   'sports_leisure':'mean',\n                                   'telephony':'mean',\n                                   'toys':'mean',\n                                   'watches_gifts':'mean',\n                                   }).plot.bar(ax = axes,\n                                          title = 'Average Number of Sales per Category per Cluster')\naxes = plt.subplot2grid((1,2),(0,1))                                   \nX_1.groupby(['kmeans_label']).agg({'auto':'median', \n                                   'bed_bath_table':'median',\n                                   'computers_accessories':'median',\n                                   'furniture_decor':'median',\n                                   'health_beauty':'median',\n                                   'housewares':'median',\n                                   'others':'median',\n                                   'sports_leisure':'median',\n                                   'telephony':'median',\n                                   'toys':'median',\n                                   'watches_gifts':'median',\n                                   }).plot.bar(ax = axes,\n                                          title = 'Median Number of Sales per Category per Cluster')\n                                   ","f2f37a74":"aux = X_1.columns\nfig = plt.figure(figsize=(24,28))\na = 0; b=0\nfor i in aux[8:19]:\n    axes = plt.subplot2grid((4,3),(a,b))\n    sns.violinplot(x = X_1['kmeans_label'],y = X_1[i], ax = axes)\n    axes.set_title(i)\n    axes.yaxis.grid(True)\n    axes.set_xlabel('kmeans_label')  \n    b = b+1\n    if b>=3:\n      b = 0\n      a = a+1","4774bc76":"data_1_reduced = data_1[['order_id','payment_value','review_score',\n                        'product_description_length','product_photos_qty',\n                         'delivery_delay']]\n\nX_1_reduced= Kmeansplots(data_1_reduced)","3ee39b59":"X_1_reduced.groupby('kmeans_label').agg({'order_id':['count','median'],\n                                         'payment_value':'median',\n                                         'review_score':'median',\n                                         'product_description_length':'median',\n                                         'product_photos_qty':'median',\n                                         'delivery_delay':'median'                 \n                                                          })","d229217e":"n_plot = 231\nfig = plt.figure(figsize=(24,14))\nfor i in X_1_reduced.columns:\n  if i!='kmeans_label':\n    axes = fig.add_subplot(n_plot) \n    sns.violinplot(x = X_1_reduced['kmeans_label'],y = X_1_reduced[i], ax = axes)\n    axes.set_title(i)\n    axes.yaxis.grid(True)\n    axes.set_xlabel('kmeans_label')\n    n_plot = n_plot+1","5972de29":"plt.figure(figsize=(24, 8))  \nplt.title(\"Sellers Dendogram\")\nlink = shc.linkage(data_1_reduced, method='ward',metric='euclidean')\ndend = shc.dendrogram(link, color_threshold=11000)  ","e5eaa50a":"X_hier = data_1_reduced.copy()\ncluster = AgglomerativeClustering(n_clusters=6, affinity='euclidean', linkage='ward')\nagrup = cluster.fit_predict(X_hier) \nX_hier['labels'] = agrup\nX_hier.groupby('labels').agg({'order_id':['count','median'],\n                                         'payment_value':'median',\n                                         'review_score':'median',\n                                         'product_description_length':'median',\n                                         'product_photos_qty':'median',\n                                         'delivery_delay':'median'                 \n                                                          })","6977ccbe":"n_plot = 231\nfig = plt.figure(figsize=(24,14))\nfor i in X_hier:\n  if i!='labels':\n    axes = fig.add_subplot(n_plot) \n    sns.violinplot(x = X_hier['labels'],y = X_hier[i], ax = axes)\n    axes.set_title(i)\n    axes.yaxis.grid(True)\n    axes.set_xlabel('hierarchical_label')\n    n_plot = n_plot+1","997d4c97":"The problem is that the cluster were basically defined by the sellers region, as seen in the result of the groupby above. So no useful information. Because of that, I removed the columns of the dataset and did the analisys once again.","3cc0d139":"The bar plots above are the the mean and median number of sales per category per cluster. Apparently, there is no correspondace between the cluster and the category of the product. In the mean of sales, every category appears in every cluster and the median number of sales is zero for every category in every cluster except for the category \"others\". That means that at least 50% of the sellers in each cluster did not make a sell in those categories. This is all corroborated by the violin plots. All the violin are thick at the base and almost a straight line as it goes up, meaning that the large majority of points did not make a single sale at the category.\n\nTherefore, I decided to drop these columns from the dataset looks appealing. So, I created the data_1_reduced dataset and ran the kmeans function once again.","5c0ec248":"### Cluster 0:\nIt is the second largest cluster, the cluster 2 being the largest. They both sold low price products, received the same review from customers, and delivered without delay most of the time. Cluster 0 used more text to describe their products. They used more photos than the cluster 2 but the difference is more subtle.   \n\n### Cluster 1:\nCluster 1 basically sold products with higher price than the rest. Of course, they were not nearly as expensive as those sold by cluster 4. The quantity of sales is not as expressive as other groups, but there are members that made more than 100 sales. They described their products with text similarly as cluster 0, perhaps even longer texts, ans posted a little bit more pictures.\n\n### Cluster 2:\nThis is the largest group. They sold low price products, delivered mostly on time and received practically the same reviews as cluster 0. They described their products with much fewer text, half as long as cluster 0, and less pictures. In this group resides the sellers that sold the most quantity of products.  \n\n### Cluster 3:\nCluster 3 contains sellers that sold low price products and some of them (very few) sold a good quantity of products. They used the longest text of all the clusters to describe their products.\n\n### Cluster 4:\nThis is the smallest group, containing only 3 sellers. They are outliers in the dataset. What sets them apart is the extremely high price of their products. They sold tiny quantities. \n\n\n### Cluster 5:\nThis is a similar cluster to cluster 3: low price products; a few members sold a good quantity of products; nothing to notice about the review scores or the delivery delays. They did not use so much text as cluster 3, even though their descriptions are longer than cluster 0 and 2.\n\n\n","6208576d":"The largest cluster is the number 2 followed by number 4.\n","437ca79c":"# Sellers Clusters Analysis with Kmeans and Hierachical Clustering\n\nThe Olist dataset available in kaggle (https:\/\/www.kaggle.com\/olistbr\/brazilian-ecommerce) contains more than 100k online orders made from 2016 to 2018. Olist is a Brazilian company that focuses on marketplaces. Basically, it aggregates sellers to announce their products in marketplaces such as Mercado Livre, Via Varejo, Amazon and others. Check their wikipedia page (https:\/\/pt.wikipedia.org\/wiki\/Olist) or their website for more information (https:\/\/olist.com\/).\n\nA lot of work has already been done in customers clustering for this dataset. By my reckoning, the customers (people who buy online) are just one part of the marketplace users. OK, alright! Perhaps they are the most important part. Nevertheless, you also have the sellers. Do they have common characteristics? Can they be divided in clusters that share the same principles and take similar actions on the market? That is what I decided to find out.\n","523165bb":"# Loading and Preparing the dataset","1792e307":"The elbow curve with distortion method got 4 clusters. This is different for the elbow curve with the silhouette and Calinski Harabasz. But, for the Silhouette, even though the highest value is 2 clusters, 4 is a local maximum and for the Calinski Harabasz 4 is the second best option. So I decided to stick with 4 clusters.\n\nThe Silhouettte plot shows negative values for some registers in clusters 0, 1 and 2, what is not the best result. Also, the Average Silhouette Coeficient is low. It was a solid 0.7 when the sellers geopgraphical regions were considered but that was not useful.\n\nThe Intercluster Distance plot shows the custers are at a good distance of each other. ","8fb1da51":"Most of the products sold were in bed_bath_table category, meaning products like sheets, blankets, silverware. This category is also the leader for the total revenue. We can see that health_beauty is also very important. The Average Revenue per Sale is leaded by computers. \n\nThere is too many categories in the dataset for someone to make sense of. Since encoding (one hot encoding) is necessary to run the algorithms, I only considered the top 10 categories in order to reduce the amount of columns that will be created in the dataset.   ","31e265ac":"The southeast dominance is still present, but like these I will have less columns when applying the one hot encoding.\n\nBelow I applied the one hot encoding. It transforms categoric variables into columns that has only zeros and ones, so something numerical. It means, something that Kmeans and Hierarchical Clustering can deal with. So, for every possible register that a categorical variable might have, a column will be created. \"One\" is assigned for the specific column that matches the register and 0 for the others.    ","4d4c1c66":"Part of the orders were not delivered, so I deleted them.","86f1088c":"# K-means Clustering","81387458":"### Cluster 0:\nThis group is very similar to cluster 3, but they put more pictures and small texts to describe their products.\n\n### Cluster 1:\nThis is the cluster with the least members. Basically, what sets them apart is that they received lousy reviews from their customers and that is, in part, explained by the delivery delay. Most of these sellers did not manage to get their products delivered on time. They sold the least. Perhaps, it is possible to conclude that this cluster gathered the non-professionals online sellers. People that only needed to sell one item once and never had to do it again.\n\n### Cluster 2:\nIt is the cluster with the most members. Most of them made a few sales and received the smallest payment value (with exceptions). They received the highest review score from their clients. It looks like they do not put too much effort in describing their products, because the have the lowest description length and the least pictures. Their products are delivered on time.\n\n### Cluster 3:\nMembers of this cluster sold a bit more that those in cluster 0, they delivered on time and have good reviews. A clear characteristic is describing their products with a lot of text and not too many pictures. \n\n### Cluster 4:\nThis is the second largest group. The champions of sales are in this cluster, but you can find members that did not sell as much. They do not put much effort in describing their products, their products are delivered on time, but they did not received as good evaluations as those received by cluster 0.\n\n\n","c34b14ed":"So far, I basically merged information of orders. Now, I need to aggregate this data for sellers. I do this using the groupby below. For some variables the aggregation was done in terms of mean value, others maximum value, others sum. I tried to use what made the most sense to me, but there are countless other ways to do it.  ","c446d8eb":"The 3 elbow method defined the optimal number of clusters as 3. The Silhouette plots showed a high silhouette coefficient for all the registers, meaning that the clusters are dense. By the interdistance plot, it is evident that clusters are distant to one another.","6d23f396":"There is a strong correlation between the amount of sales a seller did and the amount of product offered. I dropped the latter. \n\nAlso, there is strong correlations between the variables of customer region and sellers region. I dropped the former.","f0bb24f5":"# Hierarchical Clustering","b3ec4d7c":"In the code above I just created the 'delivery delay' column to replace the info of delivery estimation and actual deliverance. This way I have only one column instead of two in the dataset.","4b22bec1":"First of all, I applied the dendogram to the data_1_reduced dataset. It takes longer than the Kmeans clustering to calculate, so I did not bother to try this for the data or data_1 since that would be even more time consuming.\n\nAs you can see, I did not applied any preprocessor.","41fdf720":"Before running the clustering algorithms, I checked the correlation between variables. If two or more variables are too strongly correlated, they basically do not bring new information to define the clusters. Therefore, replicants can be droped to reduce the computational costs. ","211d1c6c":"I set the threshould of 11000 on a hunch, by visually inspecting the dendogram. As a result, I got 6 clusters. Two of them are huge in members and one is ridiculously small.","b7b243e2":"First of all, I loaded the dataset. All the work was done in Google Colab, so I had to use Google Drive for storage. \n\nNote: The product categories were in Portuguese in the table olist_products_dataset.csv, but a translation was available in the dataset. I just merged it all together in the products DataFrame.  ","db408648":"Exploring the data a little bit...\n\nThe local currency (BRL or R$ - called \"reais\") is used in the dataset.  ","521fed04":"I'm happy with the correlation map now. Let's move on to implementing the clustering algorithms.","525c415f":"The largest group is the cluster 3 followed by cluster 0. Below I checked the data in terms of the category of products.","0db9c815":"I wrote a function for the Kmeans. It does the following things:\n\n\n1.   It preprocesses the dataset using the MinMaxScaler.\n2.   It plots the elbow curve for the distortion method automatically selecting the optimal number of clusters\n3.   It plots the elbow curve for the Silhouette and Calinski_Harabasz method for validation\n4.   It plots the silhouette coefficient for all the samples\n5.   It plots the cluster distance\n6.   It runs the Kmeans algorithm for the optimal number of clusters determined by the distortion method\n7.   It returns the dataset with a new column with the label of the cluster\n\nNotes:\n\nThe elbow curve with distortion method is a plot with the sum of squared distances, or distortion, in the y axis and the number of clusters in the x axis. This curve will always decrease, being that the distortion will be zero if the number of clusters is equal to the number of registers in the dataset (singletons - clusters with only one register). The interesting thing is that this plot always have an inflection point, where the distortion falls rapidly and the decrease slowly. That point is the optimal number of clusters.\n\nThe elbow curves using the Silhouette and Calinski_Harabasz are different from the distortion. In these types, we look for a maximum to determine the optimal number of clusters.\n\n\n\n","1cf47187":"The boxplots above are the geographic distribution of customers and sellers, per Brazilian state. There are 27 states in Brazil, but we can see that transactions are dominated by southeast states, followed by south states. Other regions like north, northeast and central-west are barely present. So I aggregated this information in 3 categories: Southeast, South and Others.","0ba9b3d1":"So, I reached the conclusion that the cluster 4, the smallest group, is composed by outliers. What sets them apart is that they managed to sell online, on rare occasions, products with very high prices, much higher than the crowd of other products. \nThe big groups, clusters 0 and 2, are similar but the former described the products with more detail, being the median of the description length twice as long as the latter. The median of photos is also higher.   ","f0477db5":"# Conclusions\n\nMarketplaces are where buyers and sellers expect to find each other online in order to perform a transaction. Not only buyers are needed. Products need to be offered effectively. Therefore, it is important to know the sellers better to understand them. \n\nI performed a cluster analysis applied to a dataset of online sales. The aim of the analysis was the sellers and not the buyers. Two methods were applied: K-means and Hierarchical Clustering.\n\nWith the help Yellowbrick visualizers, K-means was very straightforward to use. Unfortunately, data from sellers location and product category did not help and had to be dropped. This technique found a group of sellers that received bad reviews and very limited number of sales (probably non professionals sellers).\n\nThe clusters from the hierarchical algorithm were separated based on a threshold set visually in the dendogram. It was less intuitive than K-means. I got a cluster of outliers that K-means did not get. This was interesting. The clusters were influenced by payment-value and description_length than others columns.\n\nAnother interesting to notice is that K-means and Hierarchical Clusters delivered very different results. For next cluster analysis, I will make sure I run both of them.","bdc026c2":"Now I got 5 clusters instead of the previous 3 and 4.","6d25dec9":"We can see above that we have some real good sellers. One of them almost reached 2k sales! ","898d236b":"However, there are a lot of one sale sellers too."}}