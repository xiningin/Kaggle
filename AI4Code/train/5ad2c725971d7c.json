{"cell_type":{"eaa78a9f":"code","421ca3e1":"code","ef4f441e":"code","e4ccd70b":"code","eb9ee33c":"code","07b4071d":"code","872a9630":"code","1d870f37":"code","1cd19dd4":"code","025b7858":"code","16cfa1e5":"code","f8460331":"code","5802b4df":"code","9d761989":"code","f6a717d7":"code","3dfe9fa2":"code","3d7a3ce2":"code","ef3df707":"code","f4581739":"code","259dc3c6":"code","d91e5677":"code","054658e7":"code","c8d51e97":"code","faa591e6":"code","9b4aaffd":"code","f3c96119":"code","61590153":"code","c5f8ac8e":"code","fb38448e":"code","31855f09":"code","0657fd59":"markdown","13ba270b":"markdown","dffdfa10":"markdown","e542fb9b":"markdown","af3e5880":"markdown"},"source":{"eaa78a9f":"# Load in Packages \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt, matplotlib.image as mpimg #plotting\nfrom sklearn.model_selection import train_test_split #machine Learning\nfrom sklearn import svm #support vector machines\n%matplotlib inline","421ca3e1":"#Load CSV file\nlabeled_images = pd.read_csv(\"..\/input\/train.csv\")\n#create labels from first column\nlabels = labeled_images.iloc[:, 0]\n#create images from remaining columns\nimages = labeled_images.iloc[:, 1:]\n#split data into train and testing 80% for training\ntrain_images, test_images,train_labels, test_labels = train_test_split(images, labels, train_size=0.8, random_state=0)","ef4f441e":"#save copies of training and testing image data before image processing steps\ntrain_images_original=train_images.copy()\ntest_images_original=test_images.copy()\n\n#scale image matrices\nmax_value = images.values.max()\ntrain_images_scaled = train_images.copy()\/max_value\ntest_images_scaled= test_images.copy()\/max_value\n\n#turn image matrices of pixel values into 0 and 1s only\ntrain_images.iloc[train_images>0] = 1\ntest_images.iloc[test_images>0] = 1\n\n#plot histogram of 0's compared to 1's for sample image\nplt.hist(train_images.iloc[5])","e4ccd70b":"#function to plot images on grid of m by m with labels\ndef plot_as_grid(images, labels, m):\n    n_pixels = len(images.columns)\n    dimension = int(np.sqrt(n_pixels))\n\n    # set up the figure\n    fig = plt.figure(figsize=(6, 6))  # figure size in inches\n    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.5, wspace=0.05)\n\n    # plot the digits: each image is max mxm pixels\n    for i in range( min(m*m, len(images.index))):\n        ax = fig.add_subplot(m, m, i + 1, xticks=[], yticks=[])    \n    \n        img=images.iloc[i].values.reshape((dimension,dimension))\n    \n        ax.imshow(img, cmap=plt.cm.binary, interpolation='nearest')\n        plt.title(labels.iloc[i])","eb9ee33c":"#compare by eye differences between raw data, processed and scaled images\nplot_as_grid(test_images,test_labels,2)\nplot_as_grid(test_images_scaled,test_labels,2)\nplot_as_grid(test_images_original,test_labels,2)","07b4071d":"#create support vector machine classifier, fit to processed data and check score on test data \nclf = svm.SVC()\nclf.fit(train_images, train_labels)","872a9630":"#create support vector machine classifier, fit to raw data\nclf_raw = svm.SVC()\nclf_raw.fit(train_images_original, train_labels)","1d870f37":"#create support vector machine classifier, fit to scaled data\nclf_scaled = svm.SVC()\nclf_scaled.fit(train_images_scaled, train_labels)","1cd19dd4":"#check scores on training and testing data\ntrainingscore=clf.score(train_images,train_labels)\ntestingscore=clf.score(test_images,test_labels)\nprint(\"Training Score on 0&1 processed data:\"+str(trainingscore))\nprint(\"Testinging Score on 0&1 processed data:\"+str(testingscore))\n\ntestingscore_raw=clf_raw.score(test_images_original,test_labels)\nprint(\"Testing Score on raw data:\"+str(testingscore_raw))\n\ntestingscore_scaled=clf_scaled.score(test_images_scaled,test_labels)\nprint(\"Testing Score on scaled data:\"+str(testingscore_scaled))","025b7858":"trainingscore_raw=clf_raw.score(train_images_original,train_labels)\nprint(\"Training Score on raw data:\"+str(trainingscore_raw))\n\ntrainingscore_scaled=clf_scaled.score(train_images_scaled,train_labels)\nprint(\"Training Score on scaled data:\"+str(trainingscore_scaled))","16cfa1e5":"from sklearn import metrics\n#function to plot confusion matrix\ndef plot_confusion_matrix(labels, predictions):\n    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(labels, predictions))","f8460331":"#create results variable from test_images\nresults=clf.predict(test_images)\n#create dataframe and plot images with predictions as titles\nresults_dataframe = pd.DataFrame(results)\nresults_dataframe.columns=['predictions']\nplot_as_grid(test_images,results_dataframe['predictions'],10)","5802b4df":"#create a confusion matrix to see which values have what issues\nplot_confusion_matrix(test_labels,results)","9d761989":"test_data=pd.read_csv(\"..\/input\/test.csv\")","f6a717d7":"results=clf.predict(test_data)","3dfe9fa2":"df = pd.DataFrame(results)\ndf.index.name='ImageId'\ndf.index+=1\ndf.columns=['Label']\ndf.to_csv('results.csv', header=True)","3d7a3ce2":"def plot_incorrect_classifications(ypred, test_labels, test_images):\n    \"Plots incorrectly classified images and corresponding prediction\"\n    ypred = pd.DataFrame(ypred)\n    ypred = ypred.set_index(test_labels.index.values)\n    ypred.columns = ['prediction']\n    predict_df = pd.concat([ypred, test_labels], axis=1)\n    predict_df['Incorrect'] = predict_df.prediction != predict_df.label\n    idx = predict_df.index[predict_df['Incorrect']]\n\n    plot_as_grid(test_images.loc[idx], predict_df['prediction'].loc[idx], 5)","ef3df707":"results_processed=clf.predict(test_images)\nresults_raw=clf_raw.predict(test_images_original)\nresults_scaled=clf_scaled.predict(test_images_scaled)","f4581739":"plot_incorrect_classifications(results_processed, test_labels, test_images)\nplot_incorrect_classifications(results_raw, test_labels, test_images_original)\nplot_incorrect_classifications(results_scaled, test_labels, test_images_scaled)","259dc3c6":"# Create first network with Keras\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense","d91e5677":"# create model\nmodel_scaled = Sequential()\nmodel_scaled.add(Dense(820, input_dim=784, activation='relu')) #dense type, 820 neurons, 784 inputs ie the number of pixels, activation function relu\nmodel_scaled.add(Dense(410, activation='relu'))\nmodel_scaled.add(Dense(10, activation='softmax'))","054658e7":"# Compile model\nmodel_scaled.compile(optimizer='adam',  # Good default optimizer to start with\n              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n              metrics=['accuracy'])","c8d51e97":"# Fit the model\nmodel_scaled.fit(train_images_scaled, train_labels, epochs=3)","faa591e6":"# create model\nmodel_raw = Sequential()\nmodel_raw.add(Dense(820, input_dim=784, activation='relu'))\nmodel_raw.add(Dense(410, activation='relu'))\nmodel_raw.add(Dense(10, activation='softmax'))\n# Compile model\nmodel_raw.compile(optimizer='adam',  # Good default optimizer to start with\n              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n              metrics=['accuracy'])\n# Fit the model\nmodel_raw.fit(train_images_original, train_labels, epochs=3)","9b4aaffd":"# create model\nmodel_processed = Sequential()\nmodel_processed.add(Dense(820, input_dim=784, activation='relu'))\nmodel_processed.add(Dense(410, activation='relu'))\nmodel_processed.add(Dense(10, activation='softmax'))\n# Compile model\nmodel_processed.compile(optimizer='adam',  # Good default optimizer to start with\n              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n              metrics=['accuracy'])\n# Fit the model\nmodel_processed.fit(train_images, train_labels, epochs=3)","f3c96119":"predictions_scaled=model_scaled.predict(test_images_scaled)\npredictions_raw=model_raw.predict(test_images_original)\npredictions_processed=model_processed.predict(test_images)","61590153":"def probability_matrix_to_classification(predictions):\n    return np.argmax(predictions,axis = 1)","c5f8ac8e":"predictions_scaled_class=probability_matrix_to_classification(predictions_scaled)\npredictions_raw_class=probability_matrix_to_classification(predictions_raw)\npredictions_processed_class=probability_matrix_to_classification(predictions_processed)","fb38448e":"def score_of_cnn(prediction_classes,testlabels):\n    op=prediction_classes==testlabels\n    return np.sum(op)\/len(prediction_classes)","31855f09":"testingscore_scaled=score_of_cnn(predictions_scaled_class,test_labels)\nprint(\"Testing Score on scaled data:\"+str(testingscore_scaled))\n\ntestingscore_raw=score_of_cnn(predictions_raw_class,test_labels)\nprint(\"Testing Score on raw data:\"+str(testingscore_raw))\n\ntestingscore_processed=score_of_cnn(predictions_processed_class,test_labels)\nprint(\"Testing Score on processed data:\"+str(testingscore_processed))","0657fd59":"**Scaled data have the highest score for CNN's**","13ba270b":"**Processed data (where images are matrices of 1's and 0's) has the highest scores for Support Vector Machines**","dffdfa10":"Let us now use the Support Vector machine to predict values and create a figure to see the results versus images","e542fb9b":"We will now save a results file created from test data for the competition. Sample code to write to CSV","af3e5880":"We will now create Neural Networks to classify the data"}}