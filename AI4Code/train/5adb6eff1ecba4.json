{"cell_type":{"f0477940":"code","aa22a692":"code","e9234420":"code","87f53c68":"code","234b9af8":"code","f1788ccf":"code","3a6ae233":"code","0101f9da":"code","cb6de3dd":"code","ff206ec9":"code","5a19bf43":"code","083142f2":"code","cac61250":"code","ce9d3097":"code","930cef41":"code","e89c8e91":"code","4add37f4":"code","1d109f7b":"code","96a731e0":"code","5fa926dd":"code","0cb2c92b":"code","7eb3eb09":"code","caaca60c":"code","fc719c0f":"code","53ccc448":"code","bde4c97b":"code","ff3c488b":"code","c93696c5":"code","ebba6280":"code","61446360":"code","2e9fb700":"markdown","cfd42533":"markdown","57d64ef7":"markdown","48830dbf":"markdown","08af4f0f":"markdown","ae2056f6":"markdown","04e8df34":"markdown","768eb0eb":"markdown","8d4b05a6":"markdown","42893a61":"markdown","2293137a":"markdown","df582b91":"markdown","fe171946":"markdown","17b688d9":"markdown","bfcd3edd":"markdown","f5c24b0f":"markdown","34fdd28d":"markdown","d1b2acef":"markdown","82d90561":"markdown","fceee169":"markdown","2fb2a125":"markdown","9685743a":"markdown","e7ab12bf":"markdown","624ec4e5":"markdown","2961cbb7":"markdown","5567fdef":"markdown","67c5e1c4":"markdown","09b270b5":"markdown","187a36aa":"markdown","1d6c13d0":"markdown","85b651a5":"markdown","94a8dc95":"markdown"},"source":{"f0477940":"#Import all the necessary packages\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\n#to scale the data using z-score \nfrom sklearn.preprocessing import StandardScaler\n\n#importing clustering algorithms\nfrom sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture\n\n\n#installing and importing the sklearn_extra library\n!pip install scikit-learn-extra\nfrom sklearn_extra.cluster import KMedoids\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","aa22a692":"data = pd.read_csv('..\/input\/credit-card-customer-data\/Credit Card Customer Data.csv')\ndata.head()","e9234420":"data.info()","87f53c68":"data.nunique()","234b9af8":"# Identify the duplicated customer keys\nduplicate_keys = data.duplicated('Customer Key') == True","f1788ccf":"# Drop duplicated keys\n\ndata = data[duplicate_keys == False]","3a6ae233":"data.drop(columns = ['Sl_No', 'Customer Key'], inplace = True)","0101f9da":"data[data.duplicated()]","cb6de3dd":"data=data[~data.duplicated()]","ff206ec9":"data.shape","5a19bf43":"data.describe().T","083142f2":"for col in data.columns:\n     print(col)\n     print('Skew :',round(data[col].skew(),2))\n     plt.figure(figsize=(15,4))\n     plt.subplot(1,2,1)\n     data[col].hist()\n     plt.ylabel('count')\n     plt.subplot(1,2,2)\n     sns.boxplot(x=data[col])\n     plt.show()","cac61250":"plt.figure(figsize=(8,8))\nsns.heatmap(data.corr(), annot=True, fmt='0.2f')\nplt.show()","ce9d3097":"scaler=StandardScaler()\ndata_scaled=pd.DataFrame(scaler.fit_transform(data), columns=data.columns)","930cef41":"data_scaled.head()","e89c8e91":"#Creating copy of the data to store labels from each algorithm\ndata_scaled_copy = data_scaled.copy(deep=True)","4add37f4":"# step 1\nsse = {} \n\n# step 2 - iterate for a range of Ks and fit the scaled data to the algorithm. Use inertia attribute from the clustering object and \n# store the inertia value for that k \nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000, random_state=1).fit(data_scaled)\n    sse[k] = kmeans.inertia_\n\n# step 3\nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()), 'bx-')\nplt.xlabel(\"Number of cluster\")\nplt.ylabel(\"SSE\")\nplt.show()","1d109f7b":"#Apply the K-Means algorithm\nkmeans = KMeans(n_clusters=3, max_iter=1000, random_state=1) \n\n#Fit the kmeans function on the scaled data\nkmeans.fit(data_scaled)\n\n#Adding predicted labels to the original data and scaled data \ndata_scaled_copy['Labels'] = kmeans.predict(data_scaled) #Save the predictions on the scaled data from K-Means\ndata['Labels'] = kmeans.predict(data_scaled) #Save the predictions on the scaled data from K-Means","96a731e0":"#Number of observations in each cluster\ndata.Labels.value_counts()","5fa926dd":"#Calculating summary statistics of the original data for each label\nmean = data.groupby('Labels').mean()\nmedian = data.groupby('Labels').median()\ndf_kmeans = pd.concat([mean, median], axis=0)\ndf_kmeans.index = ['group_0 Mean', 'group_1 Mean', 'group_2 Mean', 'group_0 Median', 'group_1 Median', 'group_2 Median']\ndf_kmeans.T","0cb2c92b":"#Visualizing different features w.r.t K-means labels\ndata_scaled_copy.boxplot(by = 'Labels', layout = (1,5),figsize=(20,7))\nplt.show()","7eb3eb09":"#Apply the Gaussian Mixture algorithm\ngmm = GaussianMixture(n_components=3, random_state=1) \n\n#Fit the gmm function on the scaled data\ngmm.fit(data_scaled)\n\ndata_scaled_copy['GmmLabels'] = gmm.predict(data_scaled)\ndata['GmmLabels'] = gmm.predict(data_scaled)","caaca60c":"#Number of observations in each cluster\ndata.GmmLabels.value_counts()","fc719c0f":"#Calculating summary statistics of the original data for each label\noriginal_features = [\"Avg_Credit_Limit\",\"Total_Credit_Cards\",\"Total_visits_bank\",\"Total_visits_online\",\"Total_calls_made\"]\n\nmean = data.groupby('GmmLabels').mean()\nmedian = data.groupby('GmmLabels').median()\ndf_gmm = pd.concat([mean, median], axis=0)\ndf_gmm.index = ['group_0 Mean', 'group_1 Mean', 'group_2 Mean', 'group_0 Median', 'group_1 Median', 'group_2 Median']\ndf_gmm[original_features].T","53ccc448":"# plotting boxplots with the new GMM based labels\n\nfeatures_with_lables = [\"Avg_Credit_Limit\",\"Total_Credit_Cards\",\"Total_visits_bank\",\"Total_visits_online\",\"Total_calls_made\",\"GmmLabels\"]\n\ndata_scaled_copy[features_with_lables].boxplot(by = 'GmmLabels', layout = (1,5),figsize=(20,7))\nplt.show()","bde4c97b":"#Apply the K-Medoids algorithm\nkmedo = KMedoids(n_clusters=3, max_iter=1000, random_state=1)\n\n#Fit the kmedo function on the scaled data\nkmedo.fit(data_scaled)\n\ndata_scaled_copy['kmedoLabels'] = kmedo.predict(data_scaled)\ndata['kmedoLabels'] = kmedo.predict(data_scaled)","ff3c488b":"#Number of observations in each cluster\ndata.kmedoLabels.value_counts()","c93696c5":"#Calculating summary statistics of the original data for each label\nmean = data.groupby('kmedoLabels').mean()\nmedian = data.groupby('kmedoLabels').median()\ndf_kmedoids = pd.concat([mean, median], axis=0)\ndf_kmedoids.index = ['group_0 Mean', 'group_1 Mean', 'group_2 Mean', 'group_0 Median', 'group_1 Median', 'group_2 Median']\ndf_kmedoids[original_features].T","ebba6280":"#plotting boxplots with the new DBScan based labels\n\nfeatures_with_lables = [\"Avg_Credit_Limit\",\t\"Total_Credit_Cards\",\"Total_visits_bank\",\"Total_visits_online\",\"Total_calls_made\",\"kmedoLabels\"]\n\ndata_scaled_copy[features_with_lables].boxplot(by = 'kmedoLabels', layout = (1,5),figsize=(20,7))\nplt.show()","61446360":"comparison = pd.concat([df_kmedoids, df_kmeans], axis=1)[original_features]\ncomparison","2e9fb700":"## Unsupervised Learning\n----------------------------------------\n\n## Context: \n-----------------------------\nAllLife Bank wants to focus on its credit card customer base in the next financial year. They have been advised by their marketing research team, that the penetration in the market can be improved. Based on this input, the Marketing team proposes to run personalized campaigns to target new customers as well as upsell to existing customers. Another insight from the market research was that the customers perceive the support services of the back poorly. Based on this, the Operations team wants to upgrade the service delivery model, to ensure that customers queries are resolved faster. Head of Marketing and Head of Delivery both decide to reach out to the Data Science team for help.\n\n\n----------------------------\n## Objective: \n-----------------------------\n\nIdentify different segments in the existing customer based on their spending patterns as well as past interaction with the bank.\n\n--------------------------\n## About the data:\n--------------------------\nData is of various customers of a bank with their credit limit, the total number of credit cards the customer has, and different channels through which customer has contacted the bank for any queries, different channels include visiting the bank, online and through a call centre.\n\n- Sl_no - Customer Serial Number\n- Customer Key - Customer identification\n- Avg_Credit_Limit\t- Average credit limit (currency is not specified, you can make an assumption around this)\n- Total_Credit_Cards\t- Total number of credit cards \n- Total_visits_bank\t- Total bank visits\n- Total_visits_online -\t Total online visits\n- Total_calls_made - Total calls made","cfd42533":"Let's compare the clusters from K-Means and K-Medoids ","57d64ef7":"- Customer key, which is an identifier, has repeated values. We should treat the same accordingly before applying any algorithm.","48830dbf":"Let's create clusters using Gaussian Mixture Models","08af4f0f":"## Importing libraries and overview of the dataset","ae2056f6":"- After removing duplicated keys and rows and unnecessary columns, there are 644 unique observations and 5 columns in our data.","04e8df34":"**Cluster Profiles:**\n\n\nGroup 0:\n\n- Customers with minimum credit limits (~ 12K in average).\n- They also have the least average number of credit cards (~ 2 cards each).\n- They tend to make phone calls rather than online and bank visits.\n\nGroup 1:\n\n- Customers with middle credit limits (~ 34K in average).\n- They also have the middle average number of credit cards(~ 6 cards each).\n- They tend to visit the bank more often rather than making calls and online transactions.\n\nGroup 2:\n\n- Customers with maximum credit limits (~ 140K in average).\n- They also have the maximum average number of credit cards(~ 9 cards each).\n- They tend to make online transactions rather than phone calls and bank visits.","768eb0eb":"**Observation:**\n\n- Many outliers in average credit limit. High credit customers are causing skewness.\n- Online visits are mostly between 1 and 4 with some outliers with more than 7 and above.","8d4b05a6":"#### Loading data","42893a61":"Let us now fit k-means algorithm on our scaled data and find out the optimum number of clusters to use.\n\nWe will do this in 3 steps:\n1. Initialize a dictionary to store the SSE for each k\n2. Run for a range of Ks and store SSE for each run\n3. Plot the SSE vs K and find the elbow","2293137a":"We have generated the labels with k-means. Let us look at the various features based on the labels.","df582b91":"#### Check the info of the data","fe171946":"#### Identify and drop the rows with duplicated customer keys","17b688d9":"## K-Medoids","bfcd3edd":"## K-Means","f5c24b0f":"#### Fit the K-means algorithms on the scaled data","34fdd28d":"**Observations:___________**\n\n- Credit limit average is around 35K with 50% of customers having a credit limit less than 18K, which implies a high positive skewness.\n- Looking at standard deviation, we can see a considerably high variation in credit limits as well.\n- On average, credit cards owned by each customer are ~5. Some customers have 10.\n- On average, most customer interactions are through calls, then online. Also, some customers never contacted\/visited the bank.","d1b2acef":"#### Scaling the data","82d90561":"## Data Preprocessing and Exploratory Data Analysis","fceee169":"**Now, let's check the correlation among different variables.**","2fb2a125":"#### Now let's go ahead with the exploring each variable at hand. We will check the distribution and outliers for each variable in the data.","9685743a":"Now that we have dropped unnecessary column. We can again check for duplicates. Duplicates would mean customers with identical features.","e7ab12bf":"We have done some basic checks. Now, let's drop the variables that are not required for our analysis.","624ec4e5":"**Observation:**\n\n- Avg_Credit_Limit is positively correlated with Total_Credit_Cards Total_visits_online which can makes sense.\n- Avg_Credit_Limit is negatively correlated with Total_calls_made and Total_visits_bank.\n- Total_visits_bank, Total_visits_online, Total_calls_made are negatively correlated which implies that majority of customers use only one of these channels to contact the bank.","2961cbb7":"We can drop these duplicated rows from the data","5567fdef":"**Let us now figure out the uniques in each column** ","67c5e1c4":"## Gaussian Mixture","09b270b5":"**Cluster Profiles:____________**\n\nGroup 0:\n\n- Customers with minimum credit limits (~ 12K in average).\n- They also have the least average number of credit cards (~ 2 cards each).\n- They tend to make phone calls rather than online and bank visits.\n\nGroup 1:\n\n- Customers with maximum credit limits (~ 85K in average).\n- They also have the maximum average number of credit cards(~ 7 cards each).\n- They tend to make online transactions rather than phone calls and bank visits.\n\nGroup 2:\n\n- Customers with middle credit limits (~ 28K in average).\n- They also have the middle average number of credit cards(~ 5 cards each).\n- They tend to visit the bank more often rather than making calls and online transactions.\n\n**Comparing Clusters:___________________**\n\n- Both algorithms produced one cluster identically (which is cluster 0) having the same profile.\n- K-Medoids grouped the data points differently than K-Means, which could be reasoned to the fact that it centres a median point, rather than mean as in K-Means. This appearantly has driven k-means to expand cluster 2 as the centroid kept moving towards outliers.\n","187a36aa":"#### Summary Statistics","1d6c13d0":"- Looking at the plot, we can say that elbow point is achieved for k=3.\n- We will fit the k-means again with k=3 to get the labels.","85b651a5":"**Observations:**\n\n- There are 660 observations and 7 columns in the dataset.\n- All columns have 660 non-null values i.e. there are no missing values.\n- All columns are of int64 data type.\n- There are no missing values.","94a8dc95":"**Cluster Profiles:____________**\n\nGroup 0:\n\n- Customers with minimum credit limits (~ 12K in average).\n- They also have the least average number of credit cards (~ 2 cards each).\n- They tend to make phone calls rather than online and bank visits.\n\nGroup 1:\n\n- Customers with middle credit limits (~ 34K in average).\n- They also have the middle average number of credit cards(~ 6 cards each).\n- They tend to visit the bank more often rather than making calls and online transactions.\n\nGroup 2:\n\n- Customers with maximum credit limits (~ 140K in average).\n- They also have the maximum average number of credit cards(~ 9 cards each).\n- They tend to make online transactions rather than phone calls and bank visits.\n\n\n**Comparing Clusters,we can clearly see that both algorithms produces clusters with the same clustring profiles**"}}