{"cell_type":{"0aed83c8":"code","4f3bb542":"code","0751273c":"code","c7f571a8":"code","ec150c20":"code","764c9372":"code","ea248c50":"code","da5b25d1":"code","77bc98a6":"code","0387263b":"code","ccc64b7c":"code","9a59514a":"markdown"},"source":{"0aed83c8":"import numpy as np\nimport re\nimport nltk\nfrom nltk.corpus import stopwords","4f3bb542":"#thes function is used to delete enything except words and the convert all letters into lowercase\ndef word_extraction(sentences):\n    words = re.sub('[^\\w]' , ' ' , sentences).split()\n    cleaned_text = [w.lower() for w in words if w not in stopwords.words('english')]\n    return cleaned_text","0751273c":"#here we extract all words from sentences and delete the repetetion\ndef tokenize(sentences):\n    words = []\n    for sentence in sentences:\n        word = word_extraction(sentence)\n        words.extend(word)\n        \n    words = sorted(list(set(words)))\n    \n    return words","c7f571a8":"#test the prevoius two functions\ntext = \"Ahmed and Ali arrived at the bus station early but waited until noon for the bus\"\n\n#word_extraction\nword_extraction(text)","ec150c20":"#tokenize the senetences\ntokenize(word_extraction(text))","764c9372":"#BOW\ndef generate_bow(all_sentences):\n    vocab = tokenize(all_sentences)\n    print(\"The word list for the Document :\\n{0}\\n\".format(vocab))\n    \n    for sentence in all_sentences:\n        words = word_extraction(sentence)\n        bag_of_words = np.zeros(len(vocab))\n        \n        for word in words:\n            for i , w in enumerate(vocab):\n                if w == word:\n                    bag_of_words[i] += 1\n                    \n        \n        print(\"{0}\\n{1}\\n\".format(sentence , np.array(bag_of_words)))\n        print('-'*80)\n                ","ea248c50":"# we can use any other sentences\nall_sentences = ['Joe waited for the train',\n                'The train was late',\n                'Mary and Samantha took the bus',\n                'I looked for Mary and Samantha at the bus station',\n                'Mary and Samantha arrived at the bus station early but waited until noon for the bus']","da5b25d1":"#here is the final output that we need\ngenerate_bow(all_sentences)","77bc98a6":"#instead of implementing BOW from scratch we can use CountVectorizer from sklearn.feature_extraction \nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(all_sentences)\n\nfor i in range(len(all_sentences)):\n    print(all_sentences[i])\n    print(list(X.toarray()[i]))\n    print(\"-\"*50)","0387263b":"#dealing with arabic sentences\narabic_sentences = [\"\u0630\u0647\u0628 \u0645\u062d\u0645\u062f \u0627\u0644\u0649 \u0627\u0644\u062c\u0627\u0645\u0639\u0647\",\n                   \"\u0646\u062c\u062d\u062a \u0645\u0646\u0649 \u0641\u064a \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631\",\n                   \"\u062a\u0645\u0643\u0646 \u0645\u062d\u0645\u062f \u0645\u0646 \u0627\u0644\u0633\u0641\u0631 \u0647\u0630\u0627 \u0627\u0644\u064a\u0648\u0645\",\n                   \"\u0627\u0639\u062a\u0642\u062f \u0627\u0646 \u062c\u0648\u0631\u062c \u0633\u064a\u062a\u0635\u0644 \u0628\u0646\u0627 \u0627\u0644\u064a\u0648\u0645\",\n                   \"\u0644\u0627 \u0627\u0638\u0646 \u0627\u0646 \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631 \u0633\u064a\u0643\u0648\u0646 \u0633\u0647\u0644\u0627\"]\ngenerate_bow(arabic_sentences)","ccc64b7c":"#also we can use CountVectorizer from sklearn with it\nfit_arab = vectorizer.fit_transform(arabic_sentences)\n\nfor i in range(len(arabic_sentences)):\n    print(arabic_sentences[i])\n    print(list(X.toarray()[i]))\n    print('-'*50)","9a59514a":"Here we can implement Bag Of Words from scratch , Bow is a tool that used in NLP to determine the extent to which each word is present in the text and its frequency, which may indicate a specific meaning for this text"}}