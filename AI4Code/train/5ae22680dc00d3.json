{"cell_type":{"4f75fe44":"code","ffe63994":"code","37e08524":"code","2e4c5d35":"code","0b1fd95a":"code","9473d382":"code","2f028e34":"code","d856dc95":"code","0b283da3":"code","10df8078":"code","84fc5e61":"markdown","5d8ed161":"markdown","b3f2ce64":"markdown","445754c4":"markdown","fdc0fce7":"markdown","7685cf30":"markdown","b2088149":"markdown","86862625":"markdown","dfb974a7":"markdown","03564fb8":"markdown"},"source":{"4f75fe44":"# ## Libraries\nfrom tweepy.streaming import StreamListener\nfrom tweepy import OAuthHandler\nfrom tweepy import Stream\nfrom textblob import TextBlob\nimport tweepy\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer","ffe63994":"## Authorization credentials to use Twitter's Api\nconsumer_key = \"XXXX\"  ##API KEY\nconsumer_secret = \"XXXX\" ##API SECRET KEY\naccess_token =\"XXXX\"\naccess_token_secret = \"XXXX\"\n\n## in the picture above it is described\n\n\nauth = tweepy.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_token_secret)\napi = tweepy.API(auth)","37e08524":"# Define the words we want to scrape as well as the date \n\nsearch_words = \"Adidas\",\"#Adidas\" + \" -filter:retweets\"  #  -filter:retweets: here we are removing all the retweets.\ndate_since = \"2021-01-09\"  ## yyyy-mm-dd\n\n\n# Collect tweets (in this case Twitter allows us to webscrape 2500 tweets every 15 minutes)\nAdidas = tweepy.Cursor(api.search,\n              q=search_words,\n              lang=\"en\").items(2500) #language ='es' for spanish. items = number of tweets you will webscrape.\n\n# Storing the Tweets into a python list\nAdidas_tweets = [[tweet.text, tweet.user.location] for tweet in Adidas] \n\n## Above I have just extracted Tweets Text and User location. There are more options to extract more information such as: \n\n        # user.friends_count - no. of other users that user is following (following)\n        # user.followers_count - no. of other users who are following this user (followers)\n        # user.statuses_count - total tweets by user\n        # user.created_at - when the user account was created\n        # created_at - when the tweet was created\n        # retweet_count - no. of retweets\n\n","2e4c5d35":"## Checking addias Tweets \nAdidas_tweets","0b1fd95a":"# Creating a DataFrame \n\ndata = pd.DataFrame(data=Adidas_tweets,  \n                    columns=[\"Tweets\", 'location'])\n\n# Cleaning DataFrame creating a function\n\n\ndef cleanText(text):\n    text = re.sub(r\"(?:\\@|https?\\:\/\/)\\S+\",'', text)#removing hiperlink and @ mentions\n    text = re.sub(r'RT[\\s]+', ' ', text) # Removing Retweets\n    text = re.sub(r'#', ' ', text) #Removing hastags\n    return text\n\n# Applying cleaning text function:\n\ndata['Tweets']= data['Tweets'].apply(cleanText)\n\n\n## checking how it looks\n\ndata.head()","9473d382":"\n## save the file\n\ndata.to_csv(r'C:\\Users\\xxxxxxxxxxxxxxxxxxx\\Adidas_Webscraped_Twitter.csv', index = False)\n# ## Write the path where you want to save your data ","2f028e34":"## Importing dataset\nimport pandas as pd\ndata = pd.read_csv('..\/input\/adidas-data-set-from-twitter\/Adidas_Webscraped_Twitter.csv')\ndata.head()","d856dc95":"from PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n#Importing Adidas image \ncdproject_logo = np.array(Image.open(\"..\/input\/adidas-logo\/adidas_logo.png\")) ##The image you want to see\n\nfig = plt.figure()\nfig.set_figwidth(20) # set width\nfig.set_figheight(20) # set height\n\nplt.imshow(cdproject_logo, cmap=plt.cm.gray, interpolation='bilinear')\nplt.axis('off')\nplt.show()","0b283da3":"from wordcloud import WordCloud, STOPWORDS \nfrom nltk.corpus import stopwords\n\nallWords = ' '.join([tweets for tweets in data['Tweets']])\n\n# instantiate a word cloud object\nwordCloud = WordCloud(background_color='white', max_words=10000, mask=cdproject_logo,contour_width=1, contour_color='black')\n\n# generate the word cloud\nwordCloud.generate(allWords)\n\n# display the word cloud\nfig = plt.figure()\nfig.set_figwidth(20) # set width\nfig.set_figheight(20) # set height\n\nplt.imshow(wordCloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","10df8078":"allWords = ' '.join([tweets for tweets in data['Tweets']])\n\nstopwords = set(STOPWORDS)\nwordCloud = WordCloud(width=500, height=300, random_state =21, max_font_size=119,stopwords=stopwords).generate(allWords)\n\nfig = plt.figure()\nfig.set_figwidth(10) # set width\nfig.set_figheight(10) # set height\n\n# display the cloud\nplt.imshow(wordCloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","84fc5e61":"#### 3. Creating a dataframe <a name=\"c\">","5d8ed161":"\n\n Sentiment analysis will be conducted in future notebooks :) ","b3f2ce64":"### Table of contents\n\n#### [1. Authorization credentials to use Twitter's Api](#a)\n#### [2. Defining our search](#b)\n#### [3. Creating a dataframe ](#c)\n#### [4. Saving the file](#d)\n#### [5. Quick visualization in Workloud ](#e)\n\n","445754c4":"\n\n## <div style=\"text-align: center\"> Webscraping in Twitter and Quick Visualization in Workcloud","fdc0fce7":"#### 5. Quick visualization in Workloud <a name=\"e\">","7685cf30":"#### 4. Saving the file <a name=\"d\">","b2088149":"#### 1. Authorization credentials to use Twitter's Api<a name=\"a\">","86862625":"\n- **Please upvote the noteebook if you like it :)**\n\nThis notebook is a quick guide on how webscraping works in python.\n\n\n1. You must apply for a Twitter Developer account: https:\/\/developer.twitter.com\/en\n\n2. Once you set up the account, you need to retrieve your Keys and tokens accesses (as in the picture)\n\n\n![image.png](attachment:image.png)","dfb974a7":"#### 2. Defining our search <a name=\"b\">","03564fb8":"#### If you want to automatize your code and run it for several times :\n\nThis page might help you: https:\/\/python.plainenglish.io\/scraping-tweets-with-tweepy-python-59413046e788\n    \n    "}}