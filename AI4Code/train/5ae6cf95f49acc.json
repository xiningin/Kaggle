{"cell_type":{"abfa5a31":"code","b320f056":"code","355a79db":"code","6d72d66f":"code","28d5c8c4":"code","3ba7e3d4":"code","5ba077db":"code","976e3068":"code","6578c553":"code","fb6ab0f8":"code","ec703668":"markdown","30710d9d":"markdown","52ff3e98":"markdown","7f29968e":"markdown","23ddf972":"markdown"},"source":{"abfa5a31":"# First, let us import some required libraries\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport tqdm\nfrom socket import socket","b320f056":"CATEGORIES = ['covid', 'healthy']\nDATADIR = '..\/input\/covidistesgp\/CovidDataset\/train'\nfor category in CATEGORIES:\n    path = os.path.join(DATADIR,category)\n    for img in os.listdir(path):\n        img_arr = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)   \n        plt.imshow(img_arr, cmap='gray')\n        plt.xlabel(category)\n        plt.show()\n        break","355a79db":"IMG_SIZE=50\ntrain_data=[]\ntest_data=[]\n\ndef create_data(data_dir):\n    for category in CATEGORIES:\n        path=os.path.join(data_dir, category)\n        class_num=CATEGORIES.index(category)\n        \n        for img in (os.listdir(path)):                                             ## We use os to iterate over all our files in the directory \n            try:\n                img_arr=cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)   ## GRAYSCALING\n                img_arr=cv2.resize(img_arr, (IMG_SIZE,IMG_SIZE))                   ## RESIZING\n                if(data_dir=='..\/input\/covidistesgp\/CovidDataset\/train'):\n                    train_data.append([img_arr,class_num])\n                else:\n                    test_data.append([img_arr,class_num])\n            except exception as e:\n                pass\n     \n# Testing above function\ncreate_data('..\/input\/covidistesgp\/CovidDataset\/train')\ncreate_data('..\/input\/covidistesgp\/CovidDataset\/validation')\n\nprint(len(train_data))\nprint(len(test_data))","6d72d66f":"import random\nrandom.shuffle(train_data)              ## Shuffling the dataset","28d5c8c4":"# Now we can start to get our training and testing data from the dataset\nx_train=[]\ny_train=[]\nx_test=[]\ny_test=[]\n\nfor features,label in train_data:\n    x_train.append(features)\n    y_train.append(label)\n    \nfor features,label in test_data:\n    x_test.append(features)\n    y_test.append(label)\n\nx_train = np.array(x_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)   ## reshaping the dataset to (length, 50, 50, 1)\nx_test = np.array(x_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\nprint(len(x_train))\nprint(len(x_test))","3ba7e3d4":"# Some libraries for performing Deep Learning on the dataset\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D","5ba077db":"trainX = np.array(x_train)\ntrainY = np.array(y_train)\ntestX = np.array(x_test)\ntestY = np.array(y_test)\n\ntrainX = trainX \/ 255;\ntestX = testX \/ 255;\n\nprint(trainX.shape)\nprint(trainY.shape)","976e3068":"model = Sequential()\nmodel.add(Conv2D(16, (3, 3), activation=\"relu\", input_shape=(50, 50, 1)))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(192, activation=\"relu\"))\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(192, activation=\"relu\"))\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(100, activation=\"relu\"))\nmodel.add(Dense(1))\n\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam', metrics=[tf.keras.metrics.AUC()])\n\nhistory = model.fit(trainX, trainY, batch_size=32, epochs=50, validation_split=0.3)","6578c553":"# So we can now test its effectiveness on our training set\nscore = model.evaluate(trainX, trainY, verbose = 1) \n\nprint('Train loss:', score[0]) \nprint('Train accuracy:', score[1])","fb6ab0f8":"# And ofc, it should work decently on other data otherwise its a sign\n# of overfitting\nscore = model.evaluate(testX, testY, verbose = 1) \n\nprint('Test loss:', score[0]) \nprint('Test accuracy:', score[1])","ec703668":"Next up, we train our algorithm using the dataset","30710d9d":"Next up, to maintain the uniformity of data, we should normalize them between 0 and 1 so that the results are not skewed","52ff3e98":"Next up, we grayscale all the images. Also, we resize them to size 50x50. Finally, we put them into two categories, the train data and the test data.","7f29968e":"For better results, we should have our dataset randomized rather than grouped together. We use random module to randmize it.","23ddf972":"The cv2 library is openCV, which we can use to read in our database. The image dataset is already loaded into this notebook. There are two categories of patients, those who are healthy and those infected with Covid."}}