{"cell_type":{"b642f6f4":"code","7a6c38ee":"code","45efb2d7":"code","36a01d2f":"code","aaa364e8":"code","778bbd00":"code","69182ca4":"code","0ecc4924":"code","74d35f17":"code","7d20644d":"code","13a059dc":"code","4a06c780":"code","d82e6324":"code","ca2c4f6c":"code","02ab9c55":"code","df44ad6c":"code","e6c3e8f6":"code","0ce5f9b7":"code","fa159888":"code","76aa970c":"code","2456e680":"code","342d4caf":"code","4836aac9":"code","6c5f81eb":"code","bee03841":"code","f49ab163":"code","4944c56d":"code","9b0ab09d":"code","8c7b4208":"code","1100f578":"code","b4e5c867":"markdown","65967258":"markdown","61940ab8":"markdown","236fc878":"markdown","d8fbf10d":"markdown","4ce3947f":"markdown","4c1fa0d5":"markdown","47407cfc":"markdown","39f9bf0d":"markdown","e5878479":"markdown","1e47079e":"markdown","78565038":"markdown","852ee945":"markdown","31ccf7e0":"markdown","67216998":"markdown","d35acf18":"markdown","b7413fce":"markdown","e744d2a5":"markdown","cf6fa065":"markdown","92c00db6":"markdown","937ebf83":"markdown","aed59940":"markdown","ffd76903":"markdown","5a2cf9df":"markdown","6683f335":"markdown","4cecf059":"markdown"},"source":{"b642f6f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport scikitplot as skplt\nimport seaborn as sns\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Bidirectional, Embedding, Flatten, SpatialDropout1D\nfrom keras.initializers import Constant\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7a6c38ee":"import json\ndata = [json.loads(line) for \n        line in open('..\/input\/sarcasm-detection-through-nlp\/Sarcasm_Headlines_Dataset.json', 'r')]","45efb2d7":"new_df = pd.DataFrame.from_dict(data) ","36a01d2f":"new_df.head()","aaa364e8":"new_df2 = new_df.drop(['article_link'],axis=1)","778bbd00":"new_df2.head()","69182ca4":"new_df2[\"headline_len\"] = new_df2[\"headline\"].str.len()","0ecc4924":"new_df2.head()","74d35f17":"max_features = 10000\nmaxlen = 25\nembedding_size = 200","7d20644d":"# Choose the top 10000 words from the vocabulary\ntop_k = 10000\ntokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n                                                  oov_token=\"<unk>\",\n                                                  filters='!\"#$%&()*+.,-\/:;=?@[\\]^_`{|}~ ')\ntokenizer.fit_on_texts(new_df2['headline'])","13a059dc":"tokenizer.word_index['<pad>'] = 0\ntokenizer.index_word[0] = '<pad>'","4a06c780":"# Create the tokenized vectors\ntrain_seqs = tokenizer.texts_to_sequences(new_df2['headline'])","d82e6324":"# Pad each vector to the max_length of the captions\n# If you do not provide a max_length value, pad_sequences calculates it automatically\nX = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post',maxlen=maxlen)","ca2c4f6c":"Y = new_df2[\"is_sarcastic\"].values","02ab9c55":"print(type(Y))","df44ad6c":"sns.countplot(x='is_sarcastic',data=new_df2);","e6c3e8f6":"tokenizer.word_index","0ce5f9b7":"num_words = len(tokenizer.word_index) + 1\nprint(num_words)","fa159888":"EMBEDDING_FILE = '..\/input\/glovedata\/glove.6B.200d.txt'\n\nembeddings = {}\nfor o in open(EMBEDDING_FILE):\n    word = o.split(\" \")[0]\n    # print(word)\n    embd = o.split(\" \")[1:]\n    embd = np.asarray(embd, dtype='float32')\n    # print(embd)\n    embeddings[word] = embd\n\n# create a weight matrix for words in training docs\nembedding_matrix = np.zeros((num_words, 200))\n\nfor word, i in tokenizer.word_index.items():\n\tembedding_vector = embeddings.get(word)\n\tif embedding_vector is not None:\n\t\tembedding_matrix[i] = embedding_vector","76aa970c":"lstm_out = 196\n\n# define the model\nmodel = Sequential()\nmodel.add(Embedding(num_words,\n                    embedding_size,\n                    embeddings_initializer=Constant(embedding_matrix),\n                    input_length=maxlen,\n                    trainable=False))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(Bidirectional(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\n","2456e680":"# compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# summarize the model\nprint(model.summary())","342d4caf":"X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","4836aac9":"batch_size = 64\nhistory = model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, \n                    verbose = 1, validation_split=0.1)","6c5f81eb":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();","bee03841":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();","f49ab163":"loss, accuracy = model.evaluate(X_test, Y_test)","4944c56d":"print(f'My test loss is {loss*100:.2f}% and test accuracy is {accuracy*100:.2f}%')","9b0ab09d":"def make_confusion_matrix(cf,\n                          group_names=None,\n                          categories='auto',\n                          count=True,\n                          percent=True,\n                          cbar=True,\n                          xyticks=True,\n                          xyplotlabels=True,\n                          sum_stats=True,\n                          figsize=None,\n                          cmap='Blues',\n                          title=None):\n    '''\n    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n    Arguments\n    ---------\n    cf:            confusion matrix to be passed in\n    group_names:   List of strings that represent the labels row by row to be shown in each square.\n    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n    count:         If True, show the raw number in the confusion matrix. Default is True.\n    normalize:     If True, show the proportions for each category. Default is True.\n    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n                   Default is True.\n    xyticks:       If True, show x and y ticks. Default is True.\n    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n    sum_stats:     If True, display summary statistics below the figure. Default is True.\n    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n                   See http:\/\/matplotlib.org\/examples\/color\/colormaps_reference.html\n                   \n    title:         Title for the heatmap. Default is None.\n    '''\n\n\n    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n    blanks = ['' for i in range(cf.size)]\n\n    if group_names and len(group_names)==cf.size:\n        group_labels = [\"{}\\n\".format(value) for value in group_names]\n    else:\n        group_labels = blanks\n\n    if count:\n        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n\n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()\/np.sum(cf)]\n    else:\n        group_percentages = blanks\n\n    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n\n\n    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n    if sum_stats:\n        #Accuracy is sum of diagonal divided by total observations\n        accuracy  = np.trace(cf) \/ float(np.sum(cf))\n\n        #if it is a binary confusion matrix, show some more stats\n        if len(cf)==2:\n            #Metrics for Binary Confusion Matrices\n            precision = cf[1,1] \/ sum(cf[:,1])\n            recall    = cf[1,1] \/ sum(cf[1,:])\n            f1_score  = 2*precision*recall \/ (precision + recall)\n            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n                accuracy,precision,recall,f1_score)\n        else:\n            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n    else:\n        stats_text = \"\"\n\n\n    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n    if figsize==None:\n        #Get default figure size if not set\n        figsize = plt.rcParams.get('figure.figsize')\n\n    if xyticks==False:\n        #Do not show categories if xyticks is False\n        categories=False\n\n\n    # MAKE THE HEATMAP VISUALIZATION\n    plt.figure(figsize=figsize)\n    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n\n    if xyplotlabels:\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label' + stats_text)\n    else:\n        plt.xlabel(stats_text)\n    \n    if title:\n        plt.title(title)","8c7b4208":"cf_matrix = confusion_matrix(Y_test, model.predict_classes(X_test))\nlabels = ['True Neg','False Pos','False Neg','True Pos']\ncategories = ['Non Sarcastic','Sarcastic']\nmake_confusion_matrix(cf_matrix, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='viridis')","1100f578":"np.set_printoptions(precision=2)\ny_pred_proba = model.predict_proba(X_test)\nfpr, tpr, _ = metrics.roc_curve(Y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(Y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"Sarcasm data, auc=\"+str(auc*100)+\"%\")\nplt.legend(loc=4)\nplt.show();","b4e5c867":"## Load the data","65967258":"## Define model\n### Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, flatten it, then dense and dropout layers as required. In the end add a final dense layer with sigmoid activation for binary classification.","61940ab8":"## Setup the environment","236fc878":"## Vocab mapping\n* There is no word for 0th index","d8fbf10d":"## Drop article_link from dataset","4ce3947f":"## Fit the model","4c1fa0d5":"## Get length of each headline and add a column for that","47407cfc":"### Convert the dictionary to a dataframe","39f9bf0d":"## Sarcasm Detection\n\n### Dataset\n### Acknowledgement\n### Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).","e5878479":"## Create embedding matrix","1e47079e":"## Compile the model","78565038":"### Read the json file","852ee945":"## Pad sequences\n\n* Pad each example with a maximum length\n* Convert target column into numpy array","31ccf7e0":"**Package Version:**\n\n* tensorflow==2.2.0\n* pandas==1.0.5\n* numpy==1.18.5\n* google==2.0.3","67216998":"## Initialize parameter values\n\n* Set values for max_features, maxlen, & embedding_size\n* max_features: Number of words to take from tokenizer(most frequent words)\n* maxlen: Maximum length of each sentence to be limited to 25\n* embedding_size: size of embedding vector","d35acf18":"### Set number of words\n\n* Since the above 0th index doesn't have a word, add 1 to the length of the vocabulary","b7413fce":"### We have not trained the embeddings generated from glove data as we are getting good results without it as well","e744d2a5":"### The data is fairly balanced in terms of sarcastic and non sarcastic tagging so no oversampling or undersampling required","cf6fa065":"## The model does a fairly decent job of predicting sarcastic comments with test auc of ~95%","92c00db6":"![image.png](attachment:24802d20-89fe-48ec-ac3d-6515b9120e02.png)![image.png](attachment:a24b262d-e636-4b51-ad75-84e48a32f58d.png)","937ebf83":"## Apply tensorflow.keras Tokenizer and get indices for words\n* Initialize Tokenizer object with number of words as 10000\n* Fit the tokenizer object on headline column\n* Convert the text to sequence","aed59940":"## Plot the model accuracy and loss across epochs","ffd76903":"### Print few sample rows","5a2cf9df":"### Print few sample rows","6683f335":"## Plot the ROC curve","4cecf059":"## Print the confusion matrix"}}