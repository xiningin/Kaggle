{"cell_type":{"485ba23f":"code","63f84367":"code","978521dc":"code","46658bda":"code","6c1d8e64":"code","b73181c7":"code","8bd8bdac":"code","a80d4cbb":"code","2ef6fd8c":"code","bd33f1d8":"code","178ec9e1":"code","bc80bf42":"code","30fc25f3":"code","0ef6e54c":"code","bca56d6b":"code","8c230927":"code","d1742c4f":"code","f3aab3fb":"code","0ff929de":"code","a41543b7":"code","2901feaa":"code","679b53a8":"code","44f7444e":"code","0751afdd":"code","11294fdc":"code","5539c4e7":"code","2c823e74":"code","7024161e":"markdown","82edfc87":"markdown","08548bae":"markdown","ad572b7a":"markdown","e8af56c1":"markdown","509e071c":"markdown","5d64f41e":"markdown","c897ca33":"markdown","c5f792da":"markdown","02bc17c7":"markdown","22611c0e":"markdown","1252139d":"markdown"},"source":{"485ba23f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.tree import DecisionTreeRegressor\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","63f84367":"raw_df = pd.read_csv('\/kaggle\/input\/traningSet.csv')","978521dc":"raw_df.head(10).T","46658bda":"raw_df['year'] = 2019 - raw_df['Created_Timestamp'].str[:4].astype(int)\n\ncontinuous_features = ['Open_Issues_Count', 'Watchers_Count', 'Contributors_Count', 'Forks_Count', 'Size', \\\n           'year','Stars_Count' ]\nbinary_features = ['Fork','Issues_enabled', 'Wiki_enabled','Pages_enabled' ]\ncategorical_features = ['Language','Host_Type']","6c1d8e64":"raw_df.isna().sum()","b73181c7":"missing_value_features = [ 'Open_Issues_Count', 'Watchers_Count', 'Size']\nfor feature in missing_value_features:\n    raw_df[feature].fillna(raw_df[feature].mode()[0], inplace=True)\nraw_df['Pages_enabled'].fillna(0, inplace=True)\nraw_df.head(10).T","8bd8bdac":"for feature in binary_features:\n    raw_df[feature] = raw_df[feature].astype(int)","a80d4cbb":"raw_df['has_readme'] = raw_df['Readme_filename'].notna() * 1\nraw_df['has_description'] = raw_df['Description'].notna() * 1\nbinary_features.extend(['has_readme','has_description'])","2ef6fd8c":"# Double check if any missing in continuous_features\nraw_df[continuous_features + binary_features + categorical_features].isna().sum()","bd33f1d8":"# for feature in continuous_features + binary_features:\n#     raw_df.plot.scatter(feature, 'New_Stars_Count')","178ec9e1":"languages = list(raw_df['Language'].value_counts()[1:11].index)\nfor language in languages:\n    raw_df[language] = raw_df.Language.apply(lambda x : int(x == language))\nraw_df['other_language'] = (raw_df[languages].sum(axis=1) == 0).astype(int)  ","bc80bf42":"for Host_Type in ['GitLab', 'GitHub']:\n    raw_df[Host_Type] = raw_df.Host_Type.apply(lambda x : int(x == Host_Type))","30fc25f3":"# missing handle timestamp...\n\n\n","0ef6e54c":"features_notNeed = ['ID', 'Host_Type', 'Name_with_Owner', 'Description', 'Created_Timestamp', 'Updated_Timestamp', \\\n                   'Last_pushed_Timestamp', 'Homepage_URL', 'Language', 'Mirror_URL', 'Default_branch', 'UUID', \\\n                   'Fork_Source_Name_with_Owner', 'License', 'Readme_filename', 'Changelog_filename', \\\n                   'Contributing_guidelines_filename', 'License_filename', 'Last_Synced_Timestamp', 'SourceRank', \\\n                   'Display_Name', 'duplicate_ID']\ndf = raw_df.drop(features_notNeed, axis=1)","bca56d6b":"features = list(df.columns)\nfeatures.remove('New_Stars_Count')\nk_fold = KFold(n_splits=2, shuffle=True, random_state=11)","8c230927":"def get_cv_results(regressor):\n    \n    results = []\n    for train, test in k_fold.split(df):\n        regressor.fit(df.loc[train, features], df.loc[train, 'New_Stars_Count'])\n        y_predicted = regressor.predict(df.loc[test, features])\n        accuracy = mean_squared_error(df.loc[test, 'New_Stars_Count'], y_predicted)\n        results.append(accuracy)\n\n    return np.mean(results), np.std(results)","d1742c4f":"gbr = GradientBoostingRegressor(\n    max_depth=5,\n    n_estimators=100\n)\n\nget_cv_results(gbr)","f3aab3fb":"rforest = RandomForestRegressor(\n    random_state=11, \n    max_depth=10,\n    n_estimators=200\n)\nget_cv_results(rforest)","0ff929de":"rforest.fit(df[features], df['New_Stars_Count'])  \nfor feature,score in sorted(zip(features,rforest.feature_importances_), key=lambda x:x[1], reverse=True):\n    print(feature, ' ', score)","a41543b7":"regtreemo = DecisionTreeRegressor(\n    random_state=1, \n    max_depth=None,\n    min_samples_leaf=1,\n    max_features=None,\n    max_leaf_nodes=None )\n\nregtreemo.fit(df[features], df['New_Stars_Count'])","2901feaa":"get_cv_results(regtreemo)","679b53a8":"newregtreemo = DecisionTreeRegressor(\n    random_state=1, \n    max_depth=6,\n    min_samples_leaf=3 )\n\nnewregtreemo.fit(df[features], df['New_Stars_Count'])","44f7444e":"get_cv_results(newregtreemo)","0751afdd":"for feature,score in zip(features,newregtreemo.feature_importances_):\n    print(feature, ' ', score)","11294fdc":"hp_values = range(1,50,2)\nall_mu = []\nall_sigma = []\n\nfor m in hp_values:\n\n    dtree=DecisionTreeClassifier(\n        criterion='entropy', \n        random_state=1, \n        max_depth=m,\n        min_samples_leaf=m,\n    )\n\n    mu, sigma = get_cv_results(dtree)\n    all_mu.append(mu)\n    all_sigma.append(sigma)\n    \n    print(m, mu, sigma)","5539c4e7":"plt.figure(figsize=(14, 5))\nplt.plot(hp_values, all_mu)\nplt.ylabel('Cross Validation Accuracy')\nplt.xlabel('Max Depth')","2c823e74":"plt.figure(figsize=(14, 5))\nplt.plot(hp_values, all_sigma)\nplt.ylabel('Cross Validation Std Dev.')\nplt.xlabel('Max Depth')","7024161e":"## Random Forest Tree","82edfc87":"### Regression Tree Model","08548bae":"### Gradient Boosting Regression","ad572b7a":"### Encode Language and host_type features","e8af56c1":"### Seperate all features into continuous, categorical and binary features.","509e071c":"- Convert binary_features from string to 0,1","5d64f41e":"1. # drop columns not gonna use","c897ca33":"- Replace NAN with mode for missing value continuous_features\n- Replace NAN language with 'others'","c5f792da":"# load dataset","02bc17c7":"# simple scatter plot for continuous_features","22611c0e":"### Clean missing data","1252139d":"- Gererate new binary features Readme_filename and Description\n- If the feature is missing, is 0, otherwise 1"}}