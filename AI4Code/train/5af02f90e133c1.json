{"cell_type":{"615ce12e":"code","099b0728":"code","19a535f3":"code","2952d51e":"code","6523185d":"code","1b215bdb":"code","7bbd7d1f":"code","06457677":"code","70f979f3":"code","1aad53af":"code","577626e9":"code","0ca79df5":"code","6a0e52dd":"code","c3c500fd":"code","7af965ff":"code","566ce173":"code","cffc73da":"code","f06a7260":"code","5084c377":"code","edff1444":"code","0db856d2":"code","7d0fa774":"code","6a4795a3":"code","752327ff":"code","2d6fe099":"code","7a667191":"code","3d83d9d7":"code","4ca1ac1d":"code","4084ea2f":"code","879466fa":"code","c6215932":"code","aabf09db":"markdown","76b68dca":"markdown","b195ee76":"markdown","a313932a":"markdown","4aee0b98":"markdown","67571b27":"markdown","5bf13f6f":"markdown"},"source":{"615ce12e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","099b0728":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score","19a535f3":"train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')","2952d51e":"train.head()","6523185d":"train.info()","1b215bdb":"train.describe()","7bbd7d1f":"train['length'] = train['text'].apply(len)","06457677":"train.groupby('target').describe()","70f979f3":"train[train['length'] == 157]['text'].iloc[0]","1aad53af":"train.head()","577626e9":"test = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","0ca79df5":"test.head()","6a0e52dd":"test['length'] = test['text'].apply(len)","c3c500fd":"test.head()","7af965ff":"train['length'].hist(bins=200)","566ce173":"train.hist(column='length',by='target',bins=200,figsize=(12,6))","cffc73da":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","f06a7260":"# nltk.download_shell()","5084c377":"string.punctuation","edff1444":"stopwords.words('english')","0db856d2":"#1. Remove Punctuations\n#2. Remove stopwords\n#3. return list of clean words","7d0fa774":"def text_process(text):\n    nopunc = [punc for punc in text if punc not in string.punctuation]\n    nopunc = ''.join(nopunc)\n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english') ]","6a4795a3":"train['text'].head(5).apply(text_process)","752327ff":"# orginal Dataframe\ntrain.head()","2d6fe099":"X = train['text']\ny = train['target']\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=101)","7a667191":"disaster_test = test['text']","3d83d9d7":"rfc = Pipeline([\n    ('bow',CountVectorizer(analyzer=text_process)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',RandomForestClassifier())\n])\n\nrfc.fit(X_train,y_train)\npredict_rfc = rfc.predict(X_test)\n\nprint(confusion_matrix(y_test,predict_rfc))\nprint(classification_report(y_test,predict_rfc))\nprint('accuracy_score',accuracy_score(y_test,predict_rfc))\nprint('f1_score',f1_score(y_test,predict_rfc))","4ca1ac1d":"nb = Pipeline([\n    ('bow',CountVectorizer(analyzer= text_process)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',MultinomialNB())\n])\n\nnb.fit(X_train,y_train)\npredict_nb = nb.predict(X_test)\n\nprint(confusion_matrix(y_test,predict_nb))\nprint(classification_report(y_test,predict_nb))\nprint('accuracy_score',accuracy_score(y_test,predict_nb))\nprint('f1_score',f1_score(y_test,predict_nb))","4084ea2f":"svm = Pipeline([\n    ('bow',CountVectorizer(analyzer = text_process)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',SVC())\n])\n\nsvm.fit(X_train,y_train)\npredict_svm = svm.predict(X_test)\n\nprint(confusion_matrix(y_test,predict_svm))\nprint(classification_report(y_test,predict_svm))\nprint('accuracy_score',accuracy_score(y_test,predict_svm))\nprint('f1_score',f1_score(y_test,predict_svm))","879466fa":"test.head()","c6215932":"# submission 1\nfinal_predict = nb.predict(disaster_test)\nsubmission = pd.DataFrame({'id':test.id,'target':final_predict})\nsubmission.to_csv('submission.csv',index=False)","aabf09db":"# train_test_split","76b68dca":"# Data Visualization","b195ee76":"# Naive Bayes","a313932a":"# Random Forest","4aee0b98":"# Text Pre-Processing","67571b27":"# Submission","5bf13f6f":"# Support Vector Machine"}}