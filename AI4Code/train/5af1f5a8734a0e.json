{"cell_type":{"1c9739c1":"code","a1e8301c":"code","cd928a39":"code","a4cd7959":"code","2b759874":"code","f3c283b0":"code","2a455f98":"code","b8b495f8":"code","30f6ad2f":"code","d91bf80c":"code","57b5cf2a":"code","3ff33286":"code","6f1f396f":"code","88c1065b":"code","3a8731e9":"code","d73b421c":"code","d3e4b229":"code","9db2e8de":"code","3607467a":"code","9e70a952":"code","36645472":"code","db4f5809":"code","2bd4ca2e":"code","68825800":"code","0a4addb7":"code","c23260e7":"code","f11b1b53":"markdown","84b4a914":"markdown","17a969d2":"markdown","41334daa":"markdown","ad26e6a2":"markdown","e4398209":"markdown","96166501":"markdown","f352600e":"markdown","12a3520c":"markdown","601375e6":"markdown"},"source":{"1c9739c1":"#Data Analysis Liabrarise\nimport numpy as np \nimport pandas as pd\n\n#Data visualization liabraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import preprocessing \n\n\n","a1e8301c":"import pandas as pd\ntest = pd.read_csv(\"..\/input\/titanic-machine-learning-from-disaster\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic-machine-learning-from-disaster\/train.csv\")","cd928a39":"#Take backup of data set for some other use if needed.\ntrain_data = train.copy()\ntest_data  = test.copy()","a4cd7959":"train.head(5)","2b759874":"train.dtypes","f3c283b0":"train.isna().sum()","2a455f98":"train = train.fillna(method='ffill')","b8b495f8":"train.isna().sum()\n","30f6ad2f":"#Dropping columns not required in data set\ntrain = train.drop(['Cabin','Ticket','Parch'], axis = 1)","d91bf80c":"train.isna().sum()","57b5cf2a":"train.describe().T","3ff33286":"sns.boxplot(x = train['Fare'])","6f1f396f":"def outliers_transform(base_dataset):\n    for i in base_dataset.var().sort_values(ascending=False).index[0:10]:\n        x=np.array(base_dataset[i])\n        qr1=np.quantile(x,0.25)\n        qr3=np.quantile(x,0.75)\n        iqr=qr3-qr1\n        utv=qr3+(1.5*(iqr))\n        ltv=qr1-(1.5*(iqr))\n        y=[]\n        for p in x:\n            if p <ltv or p>utv:\n                y.append(np.median(x))\n            else:\n                y.append(p)\n        base_dataset[i]=y","88c1065b":"outliers_transform(train)","3a8731e9":"sns.boxplot(x = train['Fare'])","d73b421c":"train.describe().T","d3e4b229":"train.drop('PassengerId',axis=1,inplace=True)\ntrain.drop('Name',axis=1,inplace=True)","9db2e8de":"label_encoder = preprocessing.LabelEncoder() \ntrain['Embarked']= label_encoder.fit_transform(train['Embarked'])\ntrain['Sex']= label_encoder.fit_transform(train['Sex'])","3607467a":"train","9e70a952":"for i in train.var().index:\n    sns.distplot(train[i],kde=False)\n    plt.show()","36645472":"plt.figure(figsize=(20,10))\nsns.heatmap(train.corr())","db4f5809":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,accuracy_score\n\ntarget = train['Survived']\npredictors = train.drop(['Survived'], axis = 1) \n\nx_train,x_test,y_train,y_test=train_test_split(predictors, target, test_size=0.20, random_state=43)","2bd4ca2e":"x_train.shape","68825800":"x_test.shape","0a4addb7":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier\n\n\n","c23260e7":"classifier = DecisionTreeClassifier()\n# Train Decision Tree Classifer\nclassifier = classifier.fit(x_train,y_train)\n#Predict the response for test dataset\ny_pred = classifier.predict(x_test)\nprint(\"Accuracy:\",accuracy_score(y_test, y_pred))","f11b1b53":"**Model Building**","84b4a914":"** Univariate analysis (EDA)** ","17a969d2":"Spliting the train data","41334daa":"** Label encoders**","ad26e6a2":"**Bivariate analysis (EDA)**","e4398209":"**Loading Data**\n\n","96166501":"**Null value treatment**","f352600e":"**Pre Processing**","12a3520c":"**Outlier treatment**\n","601375e6":"Business Objective: Use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\n"}}