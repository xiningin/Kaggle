{"cell_type":{"a501a1e4":"code","76ec30c9":"code","1dd4ba1f":"code","6d580f1a":"code","52514876":"code","06474325":"code","4a84763d":"code","4c1ef8de":"code","1a179274":"code","80a48600":"code","a6af26f9":"code","55ec40ce":"code","56e65fc2":"code","57aa4fde":"code","7a8f845a":"code","ba96b5b3":"code","3788cbc8":"code","a1d74be9":"code","d2422e7d":"code","c492e734":"code","f72299cf":"code","e93bb384":"code","49476ca3":"markdown","4f52687b":"markdown","643c6522":"markdown","9e888b90":"markdown","f6981556":"markdown","0a35cbc5":"markdown","232608d0":"markdown","31ca8c53":"markdown","f8f71a88":"markdown","153adcb5":"markdown","99997ae1":"markdown","b1ff492a":"markdown","f36ac86b":"markdown","2386f8f1":"markdown","e0964984":"markdown","7d227b66":"markdown","c525b348":"markdown","a3513b86":"markdown"},"source":{"a501a1e4":"classes = {'Black-grass': 0,\n         'Charlock': 1,\n         'Cleavers': 2,\n         'Common Chickweed': 3,\n         'Common wheat': 4,\n         'Fat Hen': 5,\n         'Loose Silky-bent': 6,\n         'Maize': 7,\n         'Scentless Mayweed': 8,\n         'Shepherds Purse': 9,\n         'Small-flowered Cranesbill': 10,\n         'Sugar beet': 11}","76ec30c9":"# ====================================================\n# Library\n# ====================================================\nimport warnings \nwarnings.filterwarnings('ignore')\n\nimport sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\n\nimport os\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score,f1_score\n\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nfrom albumentations import (\n    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose\n    )\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n!pip install timm\nimport timm\n\n","1dd4ba1f":"\n# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=True\n    apex=False\n    print_freq=100\n    num_workers=4\n    model_name='resnext50_32x4d'\n    size=256\n    scheduler='CosineAnnealingWarmRestarts' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n    epochs= 2\n    #factor=0.2 # ReduceLROnPlateau\n    #patience=4 # ReduceLROnPlateau\n    #eps=1e-6 # ReduceLROnPlateau\n    #T_max=10 # CosineAnnealingLR\n    T_0=10 # CosineAnnealingWarmRestarts\n    lr=1e-4\n    min_lr=1e-6\n    batch_size=32\n    weight_decay=1e-6\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    seed=42\n    target_size= 12\n    target_col='label'\n    n_fold=4\n    trn_fold=[0, 1, 2, 3]\n    train=True\n    inference=False\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nif CFG.apex:\n    from apex import amp\n","6d580f1a":"os.listdir('..\/input\/plant-seedlings-classification')","52514876":"# ====================================================\n# Directory settings\n# ====================================================\n\nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\nTRAIN_PATH = '.\/train_jpg_imgs'\nif not os.path.isdir(TRAIN_PATH):\n    os.mkdir(TRAIN_PATH)\nTEST_PATH = '..\/input\/plant-seedlings-classification\/test'","06474325":"train = pd.DataFrame(columns=['image_path','label', 'image_id'])\n#train = pd.DataFrame(columns=['label', 'image_id'])\ntrain.astype({'label': 'int32'})\n\npathToTrainData='..\/input\/plant-seedlings-classification\/train'\n\n\nfor dirname, _, filenames in tqdm(os.walk(pathToTrainData)):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)\n        class_label = dirname.split('\/')[-1]\n        class_label = classes[class_label]\n        image_id = filename\n        \n        train = train.append({'image_id': image_id, 'image_path':path , 'label':class_label}, ignore_index = True)\n        #train = train.append({'image_id': path , 'label':class_label}, ignore_index = True)\n        #save as jpg\n        #img = Image.open(filename)\n        #img.save(f'TRAIN_PATH\/{image_id}'+'.jpg')\ntrain.astype({'label': 'int'}).dtypes\ntrain.head(3)","4a84763d":"test = pd.DataFrame(columns=['image_id'])\npathToTestData='..\/input\/plant-seedlings-classification\/test'\n\n\nfor dirname, _, filenames in os.walk(pathToTestData):\n    for filename in filenames:\n        #print(filename)\n        image_id = filename\n        test = test.append({'image_id': image_id}, ignore_index = True)\ntest.head(3)","4c1ef8de":"# Split train set into train and validation sets\n#Y =  folds[CFG.target_col]~.astype('int')\n#from sklearn.utils.multiclass import type_of_target\n#type_of_target(Y)\nfolds = train.copy()\nX, Y = folds['image_id'], folds[CFG.target_col].astype('int')\nFold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nFold.get_n_splits(X)\n#print(Fold)\nfor n, (train_index, val_index) in enumerate(Fold.split(X, Y)):\n    folds.loc[val_index, 'fold'] = int(n)\n\nfolds['label'] = folds['label'].astype('int32')\nprint(folds.groupby(['fold', CFG.target_col]).size())","1a179274":"\n# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.file_path = df['image_path'].values\n        self.df = df #.drop(['image_path'], axis=1)\n        self.file_name = df['image_id'].values\n        self.labels = df['label'].values\n        self.transform = transform\n        \n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        \n        file_path = f'{self.file_path[idx]}'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        label = torch.tensor(self.labels[idx]).long()\n        return image, label\n    \nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['image_id'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = f'{TEST_PATH}\/{file_name}'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image\n","80a48600":"train_dataset = TrainDataset(train, transform=None)\n\nfor i in range(3):\n    image, label = train_dataset[i]\n    ax = plt.subplot(1, 3, i + 1)\n    plt.tight_layout()\n    ax.set_title(f'label: {label}')\n    ax.axis('off')\n    \n    plt.imshow(image)\n    if i == 2:\n        plt.show()\n        break","a6af26f9":"test_dataset = TestDataset(test, transform=None)\n\nfor i in range(3):\n    image = test_dataset[i]\n    ax = plt.subplot(1, 3, i + 1)\n    plt.tight_layout()\n    ax.set_title(f'Sample: {i}')\n    ax.axis('off')\n    plt.imshow(image)\n    if i == 2:\n        plt.show()\n        break","55ec40ce":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return Compose([\n            Resize(CFG.size, CFG.size),\n            RandomResizedCrop(CFG.size, CFG.size),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return Compose([\n            Resize(CFG.size, CFG.size),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","56e65fc2":"train_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n\nfor i in range(1):\n    image, label = train_dataset[1]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show() ","57aa4fde":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomResNext(nn.Module):\n    def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","7a8f845a":"model = CustomResNext(model_name=CFG.model_name, pretrained=False)\ntrain_dataset = TrainDataset(train, transform=get_transforms(data='train'))\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True,\n                          num_workers=4, pin_memory=True, drop_last=True)\n\nfor image, label in train_loader:\n    output = model(image)\n    print(output)\n    break","ba96b5b3":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s \/ (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to train mode\n    model.train()\n    start = end = time.time()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        y_preds = model(images)\n        loss = criterion(y_preds, labels)\n        # record loss\n        losses.update(loss.item(), batch_size)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        if CFG.apex:\n            with amp.scale_loss(loss, optimizer) as scaled_loss:\n                scaled_loss.backward()\n        else:\n            loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n            global_step += 1\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}\/{2}] '\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  #'LR: {lr:.6f}  '\n                  .format(\n                   epoch+1, step, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses,\n                   remain=timeSince(start, float(step+1)\/len(train_loader)),\n                   grad_norm=grad_norm,\n                   #lr=scheduler.get_lr()[0],\n                   ))\n    return losses.avg\n\ndef valid_fn(valid_loader, model, criterion, device):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to evaluation mode\n    model.eval()\n    preds = []\n    start = end = time.time()\n    for step, (images, labels) in enumerate(valid_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        # record accuracy\n        preds.append(y_preds.softmax(1).to('cpu').numpy())\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}\/{1}] '\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(\n                   step, len(valid_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses,\n                   remain=timeSince(start, float(step+1)\/len(valid_loader)),\n                   ))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions\n\n\ndef inference(model, states, test_loader, device):\n    model.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        for state in states:\n            model.load_state_dict(state['model'])\n            model.eval()\n            with torch.no_grad():\n                y_preds = model(images)\n            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","3788cbc8":"# ====================================================\n# Utils\n# ====================================================\ndef get_score_hamm(y_true, y_pred, normalize=True, sample_weight=None):\n    '''\n    # Code by https:\/\/stackoverflow.com\/users\/1953100\/william\n    # Source: https:\/\/stackoverflow.com\/a\/32239764\/395857\n    # License: cc by-sa 3.0 with attribution required \n\n    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n    https:\/\/stackoverflow.com\/q\/32239577\/395857\n    '''\n    acc_list = []\n    for i in range(y_true.shape[0]):\n        set_true = set( np.where(y_true[i])[0] )\n        set_pred = set( np.where(y_pred[i])[0] )\n        #print('\\nset_true: {0}'.format(set_true))\n        #print('set_pred: {0}'.format(set_pred))\n        tmp_a = None\n        if len(set_true) == 0 and len(set_pred) == 0:\n            tmp_a = 1\n        else:\n            tmp_a = len(set_true.intersection(set_pred))\/\\\n                    float( len(set_true.union(set_pred)) )\n        #print('tmp_a: {0}'.format(tmp_a))\n        acc_list.append(tmp_a)\n    return np.mean(acc_list)\n\ndef get_score(y_true, y_pred):\n    try:\n        return accuracy_score(y_true, y_pred)\n    except:\n        print(type_of_target(y_true))\n        sys.exit()\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","a1d74be9":"# ====================================================\n# Train loop\n# ====================================================\ndef train_loop(folds, fold):\n\n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n\n    train_dataset = TrainDataset(train_folds, \n                                 transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_folds, \n                                 transform=get_transforms(data='valid'))\n\n    train_loader = DataLoader(train_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    # ====================================================\n    # scheduler \n    # ====================================================\n    def get_scheduler(optimizer):\n        if CFG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n        elif CFG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n        return scheduler\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = CustomResNext(CFG.model_name, pretrained=True)\n    model.to(device)\n\n    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n    scheduler = get_scheduler(optimizer)\n\n    # ====================================================\n    # apex\n    # ====================================================\n    if CFG.apex:\n        model, optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n\n    # ====================================================\n    # loop\n    # ====================================================\n    criterion = nn.CrossEntropyLoss()\n\n    best_score = 0.\n    best_loss = np.inf\n    \n    for epoch in range(CFG.epochs):\n        \n        start_time = time.time()\n        \n        # train\n        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # eval\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n        valid_labels = valid_folds[CFG.target_col].values\n        #print(valid_folds.head(2))\n        if isinstance(scheduler, ReduceLROnPlateau):\n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n            scheduler.step()\n\n        # scoring\n        score = get_score(valid_labels, preds.argmax(1))\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Accuracy: {score}')\n\n        if score > best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n    \n    \n    check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n    valid_folds[[str(c) for c in range(CFG.target_size)]] = check_point['preds']\n    valid_folds['preds'] = check_point['preds'].argmax(1)\n\n    return valid_folds","d2422e7d":"# ====================================================\n# main\n# ====================================================\ndef main_fn():\n\n    \"\"\"\n    Prepare: 1.train  2.test  3.submission  4.folds\n    \"\"\"\n\n    def get_result(result_df):\n        preds = result_df['preds'].values\n        labels = result_df[CFG.target_col].values\n        score = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.5f}')\n    \n    if CFG.train:\n        # train \n        oof_df = pd.DataFrame()\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                _oof_df = train_loop(folds, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                LOGGER.info(f\"========== fold: {fold} result ==========\")\n                get_result(_oof_df)\n        # CV result\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        # save result\n        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n    \n    if CFG.inference:\n        # inference\n        model = CustomResNext(CFG.model_name, pretrained=False)\n        states = [torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth') for fold in CFG.trn_fold]\n        test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                                 num_workers=CFG.num_workers, pin_memory=True)\n        predictions = inference(model, states, test_loader, device)\n        # submission\n        test['label'] = predictions.argmax(1)\n        test[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)","c492e734":"# Train the model\nif __name__ == '__main__':\n    main_fn()","f72299cf":"CFG.inference = True\nmain_fn()","e93bb384":"output = pd.read_csv('.\/submission.csv')\noutput.head(4)\n    ","49476ca3":"# 8. Simple inference<a id='sec8'><\/a>","4f52687b":"index","643c6522":"Plot samples from test dataset.","9e888b90":"## Compose transforms","f6981556":"# 3. Configuration <a id=\"sec3\"><\/a>","0a35cbc5":"Let\u2019s instantiate these classes and iterate through the data samples. We will show three samples of each dataset.","232608d0":"## Load train set","31ca8c53":"## Split train set","f8f71a88":"# 2. Import libraries <a id=\"sec2\"><\/a>","153adcb5":"# 1. Introduction<a id=\"sec1\"><\/a>\nIn this competition we aim to create a classifier for determining a plant's species from their photos. \nWe are provided with images of plant seedlings at various stages of growth. The dataset comprises 12 plant species as follows:\nBlack-grass\nCharlock\nCleavers\nCommon Chickweed\nCommon wheat\nFat Hen\nLoose Silky-bent\nMaize\nScentless Mayweed\nShepherds Purse\nSmall-flowered Cranesbill\nSugar beet.","99997ae1":"# 5. Custom Datasets and Transforms<a id=\"sec5\"><\/a>","b1ff492a":"# 9. References<a id='sec9'><\/a>\nCredits to https:\/\/www.kaggle.com\/yasufuminakama\/cassava-resnext50-32x4d-starter-training\/.","f36ac86b":"## Transforms","2386f8f1":"# 6. Customise the resnext50_32x4d model<a id='sec6'><\/a>\nQuoting these notes from [here](https:\/\/cs231n.github.io\/transfer-learning\/):\n\"In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.\"<br>\nHere we are using PyTorch [resnext50_32x4d model](https:\/\/pytorch.org\/hub\/pytorch_vision_resnext\/).\n","e0964984":"# <font color=#002147><center>Plant Seedlings Classification using PyTorch resnext50_32x4d<\/center><\/font> ","7d227b66":"* This is a beginner code for the image classification using Pytorch resnext50_32x4d.<br> \n* You can read about PyTorch ResNext models [here](https:\/\/pytorch.org\/hub\/pytorch_vision_resnext\/).<br> \n\n### Table of contents\n[1. Introduction](#sec1)<br>\n[2. Import libraries](#sec2)<br>\n[3. Configuration](#sec3)<br>\n[4. Datasets prepration](#sec4)<br>\n[5. Create Custom Datasets and Transform](#sec5)<br>\n[6. Customise the resnext50_32x4d model](#sec6)<br>\n[7. Training the Model](#sec7)<br>\n[8. Simple inference](#sec8)<br>\n[9. References](#sec9)<br>","c525b348":"# 7. Training the Model <a id='sec7'><\/a>","a3513b86":"# 4. Datasets prepration<a id=\"sec4\"><\/a>"}}