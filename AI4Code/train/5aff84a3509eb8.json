{"cell_type":{"5406ad57":"code","2e5ba319":"code","70af8310":"code","be39118a":"code","6bdf069b":"code","9f0d01a7":"code","bc960d76":"code","f8300ccb":"code","51087154":"code","e417ef65":"code","77abbd25":"code","a633ca53":"code","43645d0c":"code","a9bafcd4":"code","892d724e":"code","3acdf393":"code","eb1481e3":"code","9265ba11":"code","f8354598":"code","1e88a3ba":"code","0544ffcf":"code","5d397975":"code","9fbbc3c8":"code","037c67af":"code","3931713b":"code","4b91fc9b":"code","783d9122":"code","79951309":"code","748a059e":"code","53b74d56":"code","60ab64a2":"code","daee6e2d":"code","9d1a01e5":"code","49e2a2ad":"code","6e1e25fe":"code","ecacd6f4":"code","62a11a89":"code","b2116235":"code","69a36a0c":"code","fd979da7":"code","3ea5326c":"code","c61c0d87":"code","9b852f37":"markdown","b7784957":"markdown","10b9d622":"markdown","2e3cd73d":"markdown","a996e029":"markdown","e8776420":"markdown","38a22870":"markdown","10c924c2":"markdown","dc717378":"markdown","1e69f968":"markdown"},"source":{"5406ad57":"from sklearn.metrics import roc_auc_score, roc_curve\nimport pandas as pd\nimport numpy as npz\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn import set_config \nset_config(display='diagram')","2e5ba319":"from sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\nfrom sklearn import pipeline\nfrom sklearn import preprocessing\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline as imb_make_pipeline","70af8310":"from catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier","be39118a":"def cv_curve(param_name, mean_test, std_test, mean_train, std_train, param_val, x_type, param_scale=\"log\"):\n    #try:\n    #    param_val.sort()\n    #except:\n    #    pass\n    lower_b_tt = mean_test - 2*std_test\n    upper_b_tt= mean_test + 2*std_test\n    \n    lower_b_tn = mean_train - 2*std_train\n    upper_b_tn = mean_train + 2*std_train\n    \n    f = plt.figure(figsize=(13,5))\n    plt.title('choose ' + param_name)\n    \n    if x_type == 'O':\n        plt.plot(range(len(param_val)), mean_test, label='test mean values of score', color='r', lw=3)\n        plt.plot(range(len(param_val)), lower_b_tt, label='test lower bound', color='b', lw=2, linestyle='dashed')\n        plt.plot(range(len(param_val)), upper_b_tt, label='test upper bound', color='b', lw=2, linestyle='dashed')\n        plt.xticks(range(len(param_val)), param_val)\n\n        plt.plot(range(len(param_val)), mean_train, label='train mean values of score', color='gray', lw=1)\n        plt.plot(range(len(param_val)), lower_b_tn, label='train lower bound', color='gray', lw=1, linestyle='dashed')\n        plt.plot(range(len(param_val)), upper_b_tn, label='train upper bound', color='gray', lw=1, linestyle='dashed')\n        plt.xticks(range(len(param_val)), param_val)\n    else:\n        if param_scale =='log':\n            plt.xscale('log')\n        plt.plot(param_val, mean_test, label='test mean values of score', color='r', lw=3)\n        plt.plot(param_val, lower_b_t, label='lower bound', color='b', lw=2, linestyle='dashed')\n        plt.plot(param_val, upper_b_t, label='upper bound', color='b', lw=2, linestyle='dashed')\n    legend_box = plt.legend(framealpha=1).get_frame()\n    legend_box.set_facecolor('white')\n    legend_box.set_edgecolor('red')\n    plt.xlabel('parameter')\n    plt.ylabel('roc_auc')\n    plt.show()","6bdf069b":"def func_roc_auc(proba, y):\n    sns.set(style=\"whitegrid\", palette='Dark2')\n    \n    auc = roc_auc_score(np.array(y), np.transpose(proba)[1])\n    print(f'\u041b\u0443\u0447\u0448\u0435\u0435 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e auc_best_estimator: {auc:.3}')\n    \n    fpr, tpr, _ = roc_curve(y, proba[:,1])\n    \n    f = plt.figure()\n    plt.plot(fpr, tpr, label = 'best_estimator')\n    plt.plot([0, 1], [0, 1], '--', color = 'grey', label = 'random')\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC curve')\n    plt.legend(loc = \"lower right\")\n    plt.show()","9f0d01a7":"def matthews_cc(contingency_table):\n    \n    a_1 = contingency_table.iloc[0,0]\n    b_2 = contingency_table.iloc[0,1]\n    c_3 = contingency_table.iloc[1,0]\n    d_4 = contingency_table.iloc[1,1]\n    n = contingency_table.sum().sum()\n    \n    if n <= 40:\n        return print('not enough observations')    \n    \n    con_1 = ((a_1 + c_3) * (a_1 + b_2)) \/ n\n    con_2 = ((a_1 + c_3) * (c_3 + d_4)) \/ n\n    con_3 = ((b_2 + d_4) * (a_1 + b_2)) \/ n\n    con_4 = ((b_2 + d_4) * (c_3 + d_4)) \/ n\n    \n    if (con_1 or con_2 or con_3 or con_4) < 5:\n        return print('wrong density of distribution')\n    \n    cont = stats.chi2_contingency(contingency_table)\n    # \u0441\u0447\u0438\u0442\u0430\u0435\u043c \u043a\u043e\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0438\n    MCC = (a_1 * d_4 - b_2 * c_3) \/ (np.sqrt((a_1 + b_2) * (a_1 + c_3) * (b_2 + d_4) * (c_3 + d_4)))\n    # \u0441\u0447\u0438\u0442\u0430\u0435\u043c \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\u0443\n    Chi_square = n * (MCC ** 2) \n    # \u0441\u0447\u0438\u0442\u0430\u0435\u043c p-value \u0434\u043b\u044f \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u0430\n    p_value = 1 - stats.chi2.cdf(Chi_square, df = 1)\n    #'cont =', cont, '\\n',\n    return print( 'MCC =', MCC, '\\n', 'Chi_square =', Chi_square, '\\n', 'p_value =', p_value)\n\ndef cramers_v(x, y):\n    confusion_matrix = pd.crosstab(x,y)\n    chi2 = stats.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2\/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0, phi2-((k-1)*(r-1))\/(n-1))\n    rcorr = r-((r-1)**2)\/(n-1)\n    kcorr = k-((k-1)**2)\/(n-1)\n    return print(f\"\u041a\u043e\u044d\u0444-\u0442 \u041a\u0440\u0430\u043c\u0435\u0440\u0430: {np.sqrt(phi2corr\/min((kcorr-1),(rcorr-1)))}\")","bc960d76":"data = pd.read_csv('\/kaggle\/input\/advanced-dls-spring-2021\/train.csv')\n\nnum_cols = ['ClientPeriod','MonthlySpending', 'TotalSpent']\n\ncat_cols = ['Sex','IsSeniorCitizen','HasPartner','HasChild','HasPhoneService','HasMultiplePhoneNumbers',\n            'HasInternetService','HasOnlineSecurityService','HasOnlineBackup','HasDeviceProtection',\n            'HasTechSupportAccess','HasOnlineTV','HasMovieSubscription','HasContractPhone','IsBillingPaperless',\n            'PaymentMethod']\n\nfeature_cols = num_cols + cat_cols\ntarget_col = 'Churn'\n\n# \u041f\u0435\u0440\u0435\u0432\u043e\u0434\u0438\u043c TotalSpent \u0432 \u0444\u043e\u0440\u043c\u0430\u0442 \u0444\u043b\u043e\u0430\u0442. \n# \u0417\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u0434\u043b\u044f \u043d\u043e\u0432\u044b\u0445 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439 \u043a\u043e\u043b\u043e\u043d\u043a\u0443 TotalSpent 0\ndata.loc[data[\"ClientPeriod\"] == 0, [\"TotalSpent\"]] = 0\ndata.loc[:, \"TotalSpent\"] = data.loc[:, \"TotalSpent\"].astype(float)","f8300ccb":"data.sample(5)","51087154":"data.isnull().sum()","e417ef65":"sns.set(style=\"whitegrid\", palette='Dark2')","77abbd25":"# \u0412\u044b\u0431\u0440\u043e\u0441\u044b \u0432 \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u0445 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0442\nf, axes = plt.subplots(1,2, figsize=(10,3))\ndata.loc[:, num_cols[0:2]].boxplot(ax=axes[0])\ndata.loc[:, num_cols[2:]].boxplot(ax=axes[1])\nplt.show()","a633ca53":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 8))\n\nfor idx, feat in enumerate(num_cols):\n    sns.boxplot(x='Churn', y=feat, data=data, ax=axes[idx])\n    axes[idx].set_xlabel('Churn')\n    axes[idx].set_ylabel(feat);\n    \n# \u041d\u0430 \u043f\u0435\u0440\u0432\u044b\u0439 \u0432\u0437\u0433\u043b\u044f\u0434 \u043a\u0430\u0436\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \n# \u0412\u043e-\u043f\u0435\u0440\u0432\u044b\u0445, \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u0443\u0439\u0442\u0438 \u0432\u044b\u0448\u0435 \u0443 \u043d\u043e\u0432\u044b\u0445 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439\n# \u0412\u043e-\u0432\u0442\u043e\u0440\u044b\u0445, \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0438, \u0441\u043a\u043b\u043e\u043d\u043d\u044b\u0435 \u043a \u043e\u0442\u0442\u0442\u043e\u043a\u0443, \u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u043c \u043d\u0430 \u0435\u0436\u0435\u043c\u0435\u0441\u044f\u0447\u043d\u043e\u0439 \u043e\u0441\u043d\u043e\u0432\u0435 \u043f\u043b\u0430\u0442\u044f\u0442 \u0431\u043e\u043b\u044c\u0448\u0435 \n# \u041d\u0443 \u0438, \u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e, \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u044f \u0442\u043e\u0442 \u0444\u0430\u043a\u0442, \u0447\u0442\u043e \u043d\u043e\u0432\u044b\u0435 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f \u0441\u043a\u043b\u043e\u043d\u043d\u044b \u0443\u0442\u0435\u043a\u0430\u0442\u044c, \n# \u0432\u043f\u043e\u043b\u043d\u0435 \u043b\u043e\u0433\u0438\u0447\u043d\u043e, \u0447\u0442\u043e \u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u043c \u0443 \u0442\u0435\u0445, \u043a\u0442\u043e \u0443\u0448\u0435\u043b, \u043e\u0431\u0449\u0438\u0435 \u0440\u0430\u0441\u0445\u043e\u0434\u044b \u043d\u0438\u0436\u0435 \u0442\u0435\u0445, \u043a\u0442\u043e \u043e\u0441\u0442\u0430\u043b\u0441\u044f","43645d0c":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445\nsns.pairplot(data.loc[:, ['ClientPeriod', 'MonthlySpending', 'TotalSpent', \"Churn\"]], hue=\"Churn\")","a9bafcd4":"# \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u043d\u0430\u043b\u0438\u0447\u0438\u0435 \u043b\u0438\u043d\u0435\u0439\u043d\u044b\u0445 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0435\u0439 \u0432 \u0434\u0430\u043d\u043d\u044b\u0445\ncorr_matrix = data.loc[:, ['Churn']+num_cols].corr()\nf, ax = plt.subplots(figsize=(15,7))\nsns.heatmap(corr_matrix, vmin=-1, vmax=1, linewidths=0.5, cmap = 'vlag', annot=True)\nplt.yticks(rotation = 0)\nplt.show()\n\n# \u041a\u0430\u043a \u0438 \u043e\u0436\u0438\u0434\u0430\u043b\u043e\u0441\u044c \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u0441\u0438\u043b\u044c\u043d\u0430\u044f \u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u0443 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0435\u0439 ClientPeriod \u0438 TotalSpent ","892d724e":"# \u0417\u0430\u043c\u0435\u0442\u0438\u043c, \u0447\u0442\u043e \u043a\u043b\u0430\u0441\u0441\u044b \u0441\u043b\u0435\u0433\u043a\u0430 \u043d\u0435\u0441\u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u044b\n# \u0420\u0430\u0434\u0438 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438 \u0431\u0443\u0434\u0435\u043c \u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0438\u0445 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e SMOTE \u0432 LR\nfig = plt.figure(figsize=(10,5))\nsns.countplot(x=\"Churn\", data=data)\nplt.show()","3acdf393":"# \u0420\u0430\u0441\u043f\u0440\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0444\u0438\u0447\nfor k in range(0,16,3):\n    fig, axes = plt.subplots(1, 3, figsize=(15,4))\n    for i, column in enumerate(cat_cols[k:k+3]):\n        axes = axes.ravel()\n        sns.countplot(x=column, hue='Churn', data=data, ax=axes[i])\n        if k != 15:\n            axes[i].tick_params(axis='x', labelrotation=1)\n        else:\n            axes[i].tick_params(axis='x', labelrotation=50)\n    plt.show()","eb1481e3":"# \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0433\u0438\u043f\u043e\u0442\u0435\u0437\u044b \u043e \u043d\u0430\u043b\u0438\u0447\u0438\u0438 \u0441\u0432\u044f\u0437\u0438 \u043c\u0435\u0436\u0434\u0443 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u043c\u0438 \u043a\u043e\u043b\u043e\u043d\u043a\u0430\u043c\u0438 \u0438 \u043e\u0442\u0442\u043e\u043a\u043e\u043c\nfrom scipy import stats\nfor column in cat_cols:\n    cross = pd.crosstab(data.Churn, data[column])\n    print(f\"\u041a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044f Churn c {column}\")\n    if data[column].value_counts().index.shape[0] == 2:\n        matthews_cc(cross)\n    else:\n        cramers_v(data.Churn, data[column])\n    print(\"\\n\")\n    \n# Sex \u0438 HasPhoneService \u043d\u0435 \u0441\u0432\u044f\u0437\u0430\u043d\u044b \u0441 Churn, \u0432 \u043b\u043e\u0433\u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 \u0438\u0445 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0441\u043c\u044b\u0441\u043b\u0430 \u043d\u0435\u0442","9265ba11":"# \u0417\u0430\u0433\u0440\u0437\u0438\u043c \u0435\u0449\u0435 \u0440\u0430\u0437 \u0434\u0430\u043d\u043d\u044b\u0435, \u0447\u0442\u043e\u0431\u044b \u043a\u0430\u0436\u0434\u044b\u0439 \u0431\u043b\u043e\u043a \u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0442\u044c \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e\ndata = pd.read_csv('\/kaggle\/input\/advanced-dls-spring-2021\/train.csv')\n\n# \u041f\u0435\u0440\u0435\u0432\u043e\u0434\u0438\u043c TotalSpent \u0432 \u0444\u043e\u0440\u043c\u0430\u0442 \u0444\u043b\u043e\u0430\u0442. \n# \u0417\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u0434\u043b\u044f \u043d\u043e\u0432\u044b\u0445 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439 \u043a\u043e\u043b\u043e\u043d\u043a\u0443 TotalSpent 0\ndata.loc[data[\"ClientPeriod\"] == 0, [\"TotalSpent\"]] = 0\ndata.loc[:, \"TotalSpent\"] = data.loc[:, \"TotalSpent\"].astype(float)\n\n# \u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u043c \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u043a\u043e\u043b\u043e\u043d\u043e\u043a\nbinary_data_columns_lr = ['IsSeniorCitizen', 'HasPartner', 'HasChild', 'IsBillingPaperless']\nnumeric_data_columns_lr =  ['ClientPeriod','MonthlySpending']\ncategorical_data_columns_lr = ['HasMultiplePhoneNumbers','HasInternetService','HasOnlineSecurityService',\n                               'HasOnlineBackup','HasDeviceProtection','HasTechSupportAccess','HasOnlineTV',\n                               'HasMovieSubscription','HasContractPhone','PaymentMethod']\n\n# \u0423\u0434\u0430\u043b\u0438\u043c \u043d\u0435\u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0442\u0438\u0432\u043d\u044b\u0435 \u0444\u0438\u0447\u0438, \u0432\u044b\u044f\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0432 \u0445\u043e\u0434\u0435 \u0430\u043d\u0430\u043b\u0438\u0437\u0430\nx_train_lr = data.drop(columns=[\"Sex\",\"HasPhoneService\", \"TotalSpent\", \"Churn\"])\ny_train = data.loc[:, [\"Churn\"]]","f8354598":"# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u041b\u043e\u0433\u0420\u0435\u0433\nregressor = LogisticRegression(random_state=42, C=0.01, penalty=\"l2\", solver=\"lbfgs\")\n\n# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u043c SMOTE\nsm = SMOTE(random_state=123, k_neighbors=4)\n\n# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u041f\u0430\u0439\u043f\u043b\u0430\u0439\u043d \u0434\u043b\u044f GridSearchCV.\nestimator_lr = imb_make_pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n            #binary\n            ('binary_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, binary_data_columns_lr])),\n                ('labelencoder', preprocessing.OrdinalEncoder())])),\n                    \n            #numeric\n            ('numeric_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, numeric_data_columns_lr])),\n                ('scaling', StandardScaler())])),            \n        \n            #categorical\n            ('categorical_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, categorical_data_columns_lr])),\n                ('label', preprocessing.OrdinalEncoder()),\n                ('hot_encoding', preprocessing.OneHotEncoder())])),\n        ])),\n    ('SMOTE', sm),\n    ('model_fitting', regressor), \n    ]\n)","1e88a3ba":"# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u0441\u0435\u0442\u044c \u043f\u043e\u0438\u0441\u043a\u0430\nparam_grid = {\n    'feature_processing__numeric_variables_processing__scaling': [StandardScaler(), RobustScaler(), MinMaxScaler()],\n    'model_fitting__penalty': [\"l1\", \"l2\"],\n    'model_fitting__C': [0.001, 0.01, 0.1, 1, 2],\n    'model_fitting__solver': ['liblinear','lbfgs','saga']\n}\n\n# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u041f\u043e\u0438\u0441\u043a \u043f\u043e \u0441\u0435\u0442\u0438\nclf = GridSearchCV(estimator_lr, \n                   param_grid=param_grid, \n                   scoring='roc_auc', \n                   cv = 4, \n                   return_train_score=True \n                  )\n\n# \u041e\u0431\u0443\u0447\u0430\u0435\u043c clf\nclf.fit(x_train_lr, y_train)","0544ffcf":"# \u0420\u0438\u0441\u0443\u0435\u043c \u043a\u0440\u0438\u0432\u044b\u0435 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \nrs_df = pd.DataFrame(clf.cv_results_).sort_values('rank_test_score').reset_index(drop=True)\nrs_df.drop(columns = ['mean_fit_time', 'std_fit_time', 'mean_score_time','std_score_time', 'params', \n                      'split0_test_score', 'split1_test_score', 'split2_test_score','split3_test_score',\n                      'split0_train_score', 'split1_train_score', \n                      'split2_train_score', 'split3_train_score'], inplace=True)\nrs_df.dropna(inplace=True)\n\nfor element in list(param_grid.keys()):\n   \n    table = rs_df.loc[:, [\"param_\"+element, \"mean_test_score\", \"std_test_score\", \"mean_train_score\", \"std_train_score\"]]\n    if table[\"param_\"+element].dtype == \"O\":\n        table[\"param_\"+element] = table[\"param_\"+element].astype(str)\n    table.sort_values(\"param_\"+element, inplace=True)\n    param_val = table[\"param_\"+element].drop_duplicates().values\n    mean_test, std_test, mean_train, std_train = table.groupby(\"param_\"+element).mean().values.T\n    cv_curve(param_name = element, mean_test=mean_test, std_test=std_test,\n             mean_train=mean_train, std_train=std_train, param_val=param_val, x_type = param_val.dtype)","5d397975":"# \u041b\u0443\u0447\u0448\u0435\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\nclf.best_params_","9fbbc3c8":"func_roc_auc(proba=clf.best_estimator_.predict_proba(x_train_lr), y=y_train)","037c67af":"data = pd.read_csv('\/kaggle\/input\/advanced-dls-spring-2021\/train.csv')\n\n# \u041f\u0435\u0440\u0435\u0432\u043e\u0434\u0438\u043c TotalSpent \u0432 \u0444\u043e\u0440\u043c\u0430\u0442 \u0444\u043b\u043e\u0430\u0442. \n# \u0417\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u0434\u043b\u044f \u043d\u043e\u0432\u044b\u0445 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439 \u043a\u043e\u043b\u043e\u043d\u043a\u0443 TotalSpent 0\ndata.loc[data[\"ClientPeriod\"] == 0, [\"TotalSpent\"]] = 0\ndata.loc[:, \"TotalSpent\"] = data.loc[:, \"TotalSpent\"].astype(float)\n\n# \u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u043c \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u043a\u043e\u043b\u043e\u043d\u043e\u043a\nbinary_data_columns_cbc = [\"Sex\", 'IsSeniorCitizen', 'HasPartner', 'HasChild', 'IsBillingPaperless']\nnumeric_data_columns_cbc =  ['ClientPeriod','MonthlySpending', 'TotalSpent']\ncategorical_data_columns_cbc = ['HasMultiplePhoneNumbers','HasInternetService','HasOnlineSecurityService',\n                               'HasOnlineBackup','HasDeviceProtection','HasTechSupportAccess','HasOnlineTV',\n                               'HasMovieSubscription','HasContractPhone','PaymentMethod']\n\n# \u0423\u0434\u0430\u043b\u0438\u043c \u043d\u0435\u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0442\u0438\u0432\u043d\u044b\u0435 \u0444\u0438\u0447\u0438, \u0432\u044b\u044f\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0432 \u0445\u043e\u0434\u0435 \u0430\u043d\u0430\u043b\u0438\u0437\u0430\nx_train_cbc = data.drop(columns=[\"Churn\"])\nx_train_cbc = x_train_cbc.loc[:, binary_data_columns_cbc+categorical_data_columns_cbc+numeric_data_columns_cbc]\ny_train = data.loc[:, [\"Churn\"]]","3931713b":"X_train_sp, X_test_sp, y_train_sp, y_test_sp = train_test_split(x_train_cbc, y_train,\n                                                                test_size=0.2, random_state=42, stratify=y_train)","4b91fc9b":"# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0433\u0440\u0438\u0434\u0441\u0435\u0440\u0447, \u043d\u043e \u043d\u0435 \u0432\u0441\u0442\u0440\u043e\u0435\u043d\u043d\u044b\u0439, \u0430 \u0438\u0437 sklearn, \u0442\u0430\u043a \u043a\u0430\u043a \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u044b \u0434\u043b\u044f \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0445 \u0444\u0438\u0447 \u0432 \u043f\u0430\u0439\u043f\u043b\u0430\u0439\u043d\n# \u0422\u0430\u043a \u043a\u0430\u043a \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0433\u0440\u0438\u0434\u0441\u0435\u0440\u0447, \u0434\u0435\u043b\u0438\u0442\u044c \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\/\u0442\u0435\u0441\u0442 \u0441\u043c\u044b\u0441\u043b\u0430 \u043d\u0435\u0442","783d9122":"model = CatBoostClassifier(cat_features=np.arange(0,15), task_type=\"GPU\",\n                          learning_rate=0.08, depth=5, l2_leaf_reg=5, iterations=90, logging_level=\"Silent\", \n                          auto_class_weights = \"SqrtBalanced\", loss_function = \"Logloss\")\n\n# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u041f\u0430\u0439\u043f\u043b\u0430\u0439\u043d\nestimator_cbc = imb_make_pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n            #binary\n            ('binary_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, binary_data_columns_cbc]))])),\n        \n            #categorical\n            ('categorical_variables_processing', pipeline.Pipeline(steps = [\n            ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, categorical_data_columns_cbc]))])),\n        \n            #numeric\n            ('numeric_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, numeric_data_columns_cbc])),\n                ('poly', preprocessing.PolynomialFeatures(2))])),            \n        \n        ])),\n    ('model_fitting', model), \n    ]\n)","79951309":"grid = {\n        'model_fitting__learning_rate' : [0.07, 0.08, 0.09],\n        'model_fitting__depth'         : [4, 5, 6],\n        'model_fitting__l2_leaf_reg'   : [4, 5, 6], \n        'model_fitting__iterations'    : [100, 110, 120], \n        'model_fitting__loss_function' : [\"CrossEntropy\", \"Logloss\"],\n        'model_fitting__auto_class_weights': [\"SqrtBalanced\", \"Balanced\"]\n        }\n\n# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u041f\u043e\u0438\u0441\u043a \u043f\u043e \u0441\u0435\u0442\u0438\ncbc = GridSearchCV(estimator_cbc, \n                   param_grid=grid, \n                   scoring='roc_auc', \n                   cv=4,\n                   return_train_score=True)\n\n# \u041e\u0431\u0443\u0447\u0430\u0435\u043c estimator\ncbc.fit(x_train_cbc, y_train)","748a059e":"# \u0420\u0438\u0441\u0443\u0435\u043c \u043a\u0440\u0438\u0432\u044b\u0435 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \nrs_df = pd.DataFrame(cbc.cv_results_).sort_values('rank_test_score').reset_index(drop=True)\nrs_df.drop(columns = ['mean_fit_time', 'std_fit_time', 'mean_score_time','std_score_time', 'params', \n                      'split0_test_score', 'split1_test_score', 'split2_test_score','split3_test_score',\n                      'split0_train_score', 'split1_train_score', \n                      'split2_train_score', 'split3_train_score'], inplace=True)\nrs_df.dropna(inplace=True)\n\nfor element in list(grid.keys()):\n   \n    table = rs_df.loc[:, [\"param_\"+element, \"mean_test_score\", \"std_test_score\", \"mean_train_score\", \"std_train_score\"]]\n    if table[\"param_\"+element].dtype == \"O\":\n        table[\"param_\"+element] = table[\"param_\"+element].astype(str)\n    table.sort_values(\"param_\"+element, inplace=True)\n    param_val = table[\"param_\"+element].drop_duplicates().values\n    mean_test, std_test, mean_train, std_train = table.groupby(\"param_\"+element).mean().values.T\n    cv_curve(param_name = element, mean_test=mean_test, std_test=std_test,\n             mean_train=mean_train, std_train=std_train, param_val=param_val, x_type = param_val.dtype)","53b74d56":"# \u041b\u0443\u0447\u0448\u0435\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\ncbc.best_params_\n\n\n# \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u043b \u043d\u0435 \u043e\u0447 \u0445\u043e\u0440\u043e\u0448\u0438\u0435, \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u0442\u0435 \u0432 \u0434\u0440\u0443\u0433\u0438\u0445 \u043d\u043e\u0443\u0442\u0431\u0443\u043a\u0430\u0445, \u0442\u0430\u043c \u043b\u0443\u0447\u0448\u0435\n#{'model_fitting__depth': 5,\n# 'model_fitting__iterations': 80,\n# 'model_fitting__l2_leaf_reg': 5,\n# 'model_fitting__learning_rate': 0.08}\n","60ab64a2":"model = CatBoostClassifier(cat_features=np.arange(0,15),\n                          learning_rate=0.08, depth=5, l2_leaf_reg=5, iterations=80, logging_level=\"Silent\", \n                          auto_class_weights = \"Balanced\", loss_function = \"Logloss\")\n\n# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u041f\u0430\u0439\u043f\u043b\u0430\u0439\u043d\nestimator_cbc = imb_make_pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n            #binary\n            ('binary_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, binary_data_columns_cbc]))])),\n        \n            #categorical\n            ('categorical_variables_processing', pipeline.Pipeline(steps = [\n            ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, categorical_data_columns_cbc]))])),\n        \n            #numeric\n            ('numeric_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, numeric_data_columns_cbc])),\n                ('poly', preprocessing.PolynomialFeatures(4))])),            \n        \n        ])),\n    ('model_fitting', model), \n    ]\n)","daee6e2d":"estimator_cbc.fit(X_train_sp, y_train_sp)","9d1a01e5":"func_roc_auc(proba=estimator_cbc.predict_proba(X_test_sp), y=y_test_sp)\n","49e2a2ad":"data = pd.read_csv('\/kaggle\/input\/advanced-dls-spring-2021\/train.csv')\n\n# \u041f\u0435\u0440\u0435\u0432\u043e\u0434\u0438\u043c TotalSpent \u0432 \u0444\u043e\u0440\u043c\u0430\u0442 \u0444\u043b\u043e\u0430\u0442. \n# \u0417\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u0434\u043b\u044f \u043d\u043e\u0432\u044b\u0445 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439 \u043a\u043e\u043b\u043e\u043d\u043a\u0443 TotalSpent 0\ndata.loc[data[\"ClientPeriod\"] == 0, [\"TotalSpent\"]] = 0\ndata.loc[:, \"TotalSpent\"] = data.loc[:, \"TotalSpent\"].astype(float)","6e1e25fe":"X = data.drop(columns=[\"Churn\"])\ny = data.loc[:, [\"Churn\"]]","ecacd6f4":"binary_data_columns = ['IsSeniorCitizen', 'HasPartner', 'HasChild', 'IsBillingPaperless']\nnumeric_data_columns =  ['ClientPeriod','MonthlySpending', 'TotalSpent']\ncategorical_data_columns = ['HasMultiplePhoneNumbers','HasInternetService','HasOnlineSecurityService',\n                               'HasOnlineBackup','HasDeviceProtection','HasTechSupportAccess','HasOnlineTV',\n                               'HasMovieSubscription','HasContractPhone','PaymentMethod']\n\n\n# \u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u043c \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u043a\u043e\u043b\u043e\u043d\u043e\u043a\nbinary_data_columns_lr = ['IsSeniorCitizen', 'HasPartner', 'HasChild', 'IsBillingPaperless']\nnumeric_data_columns_lr =  ['ClientPeriod','MonthlySpending']\ncategorical_data_columns_lr = ['HasMultiplePhoneNumbers','HasInternetService','HasOnlineSecurityService',\n                               'HasOnlineBackup','HasDeviceProtection','HasTechSupportAccess','HasOnlineTV',\n                               'HasMovieSubscription','HasContractPhone','PaymentMethod']","62a11a89":"# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u041b\u043e\u0433\u0420\u0435\u0433\nregressor = LogisticRegression(random_state=42, C=0.01, penalty=\"l2\", solver=\"lbfgs\")\n\n# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u043c SMOTE\nsm = SMOTE(random_state=123, k_neighbors=4)\n\n# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u041f\u0430\u0439\u043f\u043b\u0430\u0439\u043d\nestimator_lr = imb_make_pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n            #binary\n            ('binary_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, binary_data_columns_lr])),\n                ('labelencoder', preprocessing.OrdinalEncoder())])),\n                    \n            #numeric\n            ('numeric_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, numeric_data_columns_lr])),\n                ('scaling', StandardScaler())])),            \n        \n            #categorical\n            ('categorical_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, categorical_data_columns_lr])),\n                ('label', preprocessing.OrdinalEncoder()),\n                ('hot_encoding', preprocessing.OneHotEncoder())])),\n        ])),\n    ('SMOTE', sm),\n    ('model_fitting', regressor), \n    ]\n)","b2116235":"model = CatBoostClassifier(cat_features=np.arange(0,14),\n                          learning_rate=0.08, depth=5, l2_leaf_reg=5, iterations=80,\n                          logging_level=\"Silent\", auto_class_weights = \"SqrtBalanced\")\n\n# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u041f\u0430\u0439\u043f\u043b\u0430\u0439\u043d\nestimator_cbc = imb_make_pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n            #binary\n            ('binary_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, binary_data_columns]))])),\n        \n            #categorical\n            ('categorical_variables_processing', pipeline.Pipeline(steps = [\n            ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, categorical_data_columns]))])),\n        \n            #numeric\n            ('numeric_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, numeric_data_columns])),\n                ('poly', preprocessing.PolynomialFeatures(2))])),            \n        \n        ])),\n    ('model_fitting', model), \n    ]\n)","69a36a0c":"from sklearn.ensemble import StackingClassifier\n\nestimators = [\n     ('cbc', estimator_cbc),\n     ('lrc', estimator_lr) ]\n\nstckg = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(random_state=42, C=0.03, penalty=\"l2\"))\n\nstckg.fit(X, y)","fd979da7":"# \u0420\u0438\u0441\u0443\u0435\u043c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \nproba_stckg = stckg.predict_proba(X)","3ea5326c":"# \u041d\u0438\u0447\u0435\u0433\u043e \u0445\u043e\u0440\u043e\u0448\u0435\u0433\u043e \u043d\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u043e\u0441\u044c :D\nfunc_roc_auc(proba=proba_stckg, y=y)","c61c0d87":"# \u041b\u043e\u0433\u0440\u0435\u0433 ~0,846\n# catboost ~0.854\n# \u0441\u0442\u0435\u043a\u0438\u043d\u0433 ~0.85","9b852f37":"<p style=\"align: center;\"><img align=center src=\"https:\/\/s8.hostingkartinok.com\/uploads\/images\/2018\/08\/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500 height=450\/><\/p>\n\n<h3 style=\"text-align: center;\"><b>\u0428\u043a\u043e\u043b\u0430 \u0433\u043b\u0443\u0431\u043e\u043a\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0424\u041f\u041c\u0418 \u041c\u0424\u0422\u0418<\/b><\/h3>\n\n<h3 style=\"text-align: center;\"><b>\u0414\u043e\u043c\u0430\u0448\u043d\u0435\u0435 \u0437\u0430\u0434\u0430\u043d\u0438\u0435. \u041f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0439 \u043f\u043e\u0442\u043e\u043a. \u0412\u0435\u0441\u043d\u0430 2021<\/b><\/h3>\n\n\u042d\u0442\u043e \u0434\u043e\u043c\u0430\u0448\u043d\u0435\u0435 \u0437\u0430\u0434\u0430\u043d\u0438\u0435 \u0431\u0443\u0434\u0435\u0442 \u043f\u043e\u0441\u0432\u044f\u0449\u0435\u043d\u043e \u043f\u043e\u043b\u043d\u043e\u0446\u0435\u043d\u043d\u043e\u043c\u0443 \u0440\u0435\u0448\u0435\u043d\u0438\u044e \u0437\u0430\u0434\u0430\u0447\u0438 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f.","b7784957":"## \u041f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u0433\u043e \u0431\u0443\u0441\u0442\u0438\u043d\u0433\u0430 (2 \u0431\u0430\u043b\u043b\u0430)\n","10b9d622":"# \u041f\u0435\u0440\u0432\u0430\u044f \u0447\u0430\u0441\u0442\u044c. \u0418\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u0435","2e3cd73d":"#### \u0418\u0442\u043e\u0433 \u043f\u043e \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0443:","a996e029":"## \u041f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u043b\u0438\u043d\u0435\u0439\u043d\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 (3 \u0431\u0430\u043b\u043b\u0430)\n","e8776420":"## \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 (2 \u0431\u0430\u043b\u043b\u0430)","38a22870":"# \u0421\u0442\u0435\u043a\u0438\u043d\u0433","10c924c2":"## \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445 (3 \u0431\u0430\u043b\u043b\u0430)","dc717378":"## \u0424\u0443\u043d\u043a\u0446\u0438\u0438","1e69f968":"# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f"}}