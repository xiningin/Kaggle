{"cell_type":{"cbad6c77":"code","bd472d2e":"code","76e17f94":"code","2ac292f2":"code","59ca3030":"code","c64de9de":"code","2ea32190":"code","a1a00b7e":"markdown","53a392f0":"markdown","30f19578":"markdown"},"source":{"cbad6c77":"from PIL import Image, ImageDraw, ImageFont\nfrom os import listdir\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","bd472d2e":"fontsize = 50\n\n# From https:\/\/www.google.com\/get\/noto\/\n!wget -q --show-progress https:\/\/noto-website-2.storage.googleapis.com\/pkgs\/NotoSansCJKjp-hinted.zip\n!unzip -p NotoSansCJKjp-hinted.zip NotoSansCJKjp-Regular.otf > NotoSansCJKjp-Regular.otf\n!rm NotoSansCJKjp-hinted.zip\n\nfont = ImageFont.truetype('.\/NotoSansCJKjp-Regular.otf', fontsize, encoding='utf-8')","76e17f94":"df_train = pd.read_csv('..\/input\/train.csv')\nunicode_map = {codepoint: char for codepoint, char in pd.read_csv('..\/input\/unicode_translation.csv').values}","2ac292f2":"# This function takes in a filename of an image, and the labels in the string format given in train.csv, and returns an image containing the bounding boxes and characters annotated\ndef visualize_training_data(image_fn, labels):\n    # Convert annotation string to array\n    labels = np.array(labels.split(' ')).reshape(-1, 5)\n    \n    # Read image\n    imsource = Image.open(image_fn).convert('RGBA')\n    bbox_canvas = Image.new('RGBA', imsource.size)\n    char_canvas = Image.new('RGBA', imsource.size)\n    bbox_draw = ImageDraw.Draw(bbox_canvas) # Separate canvases for boxes and chars so a box doesn't cut off a character\n    char_draw = ImageDraw.Draw(char_canvas)\n\n    for codepoint, x, y, w, h in labels:\n        x, y, w, h = int(x), int(y), int(w), int(h)\n        char = unicode_map[codepoint] # Convert codepoint to actual unicode character\n\n        # Draw bounding box around character, and unicode character next to it\n        bbox_draw.rectangle((x, y, x+w, y+h), fill=(255, 255, 255, 0), outline=(255, 0, 0, 255))\n        char_draw.text((x + w + fontsize\/4, y + h\/2 - fontsize), char, fill=(0, 0, 255, 255), font=font)\n\n    imsource = Image.alpha_composite(Image.alpha_composite(imsource, bbox_canvas), char_canvas)\n    imsource = imsource.convert(\"RGB\") # Remove alpha for saving in jpg format.\n    return np.asarray(imsource)","59ca3030":"np.random.seed(1337)\n\nfor i in range(10):\n    img, labels = df_train.values[np.random.randint(len(df_train))]\n    viz = visualize_training_data('..\/input\/train_images\/{}.jpg'.format(img), labels)\n    \n    plt.figure(figsize=(15, 15))\n    plt.title(img)\n    plt.imshow(viz, interpolation='lanczos')\n    plt.show()","c64de9de":"# This function takes in a filename of an image, and the labels in the string format given in a submission csv, and returns an image with the characters and predictions annotated.\ndef visualize_predictions(image_fn, labels):\n    # Convert annotation string to array\n    labels = np.array(labels.split(' ')).reshape(-1, 3)\n    \n    # Read image\n    imsource = Image.open(image_fn).convert('RGBA')\n    bbox_canvas = Image.new('RGBA', imsource.size)\n    char_canvas = Image.new('RGBA', imsource.size)\n    bbox_draw = ImageDraw.Draw(bbox_canvas) # Separate canvases for boxes and chars so a box doesn't cut off a character\n    char_draw = ImageDraw.Draw(char_canvas)\n\n    for codepoint, x, y in labels:\n        x, y = int(x), int(y)\n        char = unicode_map[codepoint] # Convert codepoint to actual unicode character\n\n        # Draw bounding box around character, and unicode character next to it\n        bbox_draw.rectangle((x-10, y-10, x+10, y+10), fill=(255, 0, 0, 255))\n        char_draw.text((x+25, y-fontsize*(3\/4)), char, fill=(255, 0, 0, 255), font=font)\n\n    imsource = Image.alpha_composite(Image.alpha_composite(imsource, bbox_canvas), char_canvas)\n    imsource = imsource.convert(\"RGB\") # Remove alpha for saving in jpg format.\n    return np.asarray(imsource)","2ea32190":"image_fn = '..\/input\/test_images\/test_030d9355.jpg'\npred_string = 'U+306F 1231 1465 U+304C 275 1652 U+3044 1495 1218 U+306F 436 1200 U+304C 800 2000 U+3044 1000 300' # Prediction string in submission file format\nviz = visualize_predictions(image_fn, pred_string)\n\nplt.figure(figsize=(15, 15))\nplt.imshow(viz, interpolation='lanczos')","a1a00b7e":"First, in order to visualise the dataset, we need a font that can display the full range of Japanese characters. We're using [Noto Sans](https:\/\/en.wikipedia.org\/wiki\/Noto_fonts), an open source font by Google which can display very almost all the characters used within this competition.","53a392f0":"# Visualising the training data\nYou'll notice that some of the characters \"off to the side\" of columns in the text aren't annotated in the training set. These characters are annotations and not part of the main text of the books, so they shouldn't be transcribed by your model.","30f19578":"# Visualising predictions\nFor the test set, you're only required to predict a single point within each bounding box instead of the entire bounding box (ideally, the centre of the bounding box). It may also be useful to visualise the box centres on the image:"}}