{"cell_type":{"fa257b81":"code","ecd03b8a":"code","9116fba7":"code","41b9116d":"code","208908d1":"code","491e6f88":"code","4f0c0910":"code","28a23f8f":"code","19df1d14":"code","c05d0ae1":"markdown","5302ec07":"markdown","276c65ed":"markdown"},"source":{"fa257b81":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\nfrom tqdm import tqdm\nimport xgboost as xgb","ecd03b8a":"#===========================================================================\n# read in the data\n# Original kernel: https:\/\/www.kaggle.com\/carlmcbrideellis\/very-simple-xgboost-regression\n#===========================================================================\ntrain_data = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ntest_data  = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\n\ntest_ids = test_data['id'].tolist()","9116fba7":"train_data.head()","41b9116d":"missing_values_count = train_data.isnull().sum()\nprint (missing_values_count)\ntotal_cells = np.product(train_data.shape)\ntotal_missing = missing_values_count.sum()\nprint (\"% of missing data = \",(total_missing\/total_cells) * 100)","208908d1":"def add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    return df\n\ntrain_data = add_features(train_data)\ntest_data = add_features(test_data)\n\ntrain_data.drop(['id', 'breath_id'], axis=1, inplace=True)\ntest_data = test_data.drop(['id', 'breath_id'], axis=1)","491e6f88":"#===========================================================================\n# select some features of interest\n#===========================================================================\nfeatures=[]\nfor i in train_data.columns:\n    if i != 'pressure':\n        features.append(i)\n# features = ['R', 'C', 'time_step', 'u_in', 'u_out']\n\n#===========================================================================\n#===========================================================================\nX_train = train_data[features]\ny_train = train_data[\"pressure\"]\nfinal_X_test = test_data[features]\n\n#===========================================================================\n# XGBoost regression: \n# Parameters: \n# n_estimators  \"Number of gradient boosted trees. Equivalent to number \n#                of boosting rounds.\"\n# learning_rate \"Boosting learning rate (xgb\u2019s \u201ceta\u201d)\"\n# max_depth     \"Maximum depth of a tree. Increasing this value will make \n#                the model more complex and more likely to overfit.\" \n#===========================================================================\n# regressor=xgb.XGBRegressor(n_estimators  = 500,\n#                            learning_rate = 0.1,\n#                            max_depth     = 5)\n# regressor.fit(X_train, y_train)\n\n#===========================================================================\n# To use early_stopping_rounds: \n# \"Validation metric needs to improve at least once in every \n# early_stopping_rounds round(s) to continue training.\"\n#===========================================================================\n# perform a test\/train split \nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n\n\nregressor = xgb.XGBRegressor(\n                 tree_method='gpu_hist',\n                 colsample_bytree=0.9,\n                 alpha=0.01563,\n                 #gamma=0.0,\n                 learning_rate=0.5,\n                 max_depth=13,\n                 min_child_weight=257,\n                 n_estimators=1500,                                                                  \n                 #reg_alpha=0.9,\n                 reg_lambda=0.003,\n                 subsample=0.9,\n                 random_state=2020,\n                 metric_period=100,\n                 silent=1)\n\nregressor.fit(X_train, y_train, early_stopping_rounds=6, eval_set=[(X_test, y_test)], verbose=0)","4f0c0910":"#===========================================================================\n# use the model XGB to predict the prices for the test data\n#===========================================================================\npredictions = regressor.predict(final_X_test)","28a23f8f":"#===========================================================================\n# write out CSV submission file\n#===========================================================================\noutput = pd.DataFrame({\"id\":test_ids, \"pressure\":predictions})\noutput.to_csv('submission.csv', index=False)","19df1d14":"output","c05d0ae1":"# Missing Values Count","5302ec07":"![](https:\/\/1.bp.blogspot.com\/-zeFUWzrz2FA\/YUup-VsSKWI\/AAAAAAAAIME\/4s_s--D68xEJmBI8VdAaOJXNO3cd8qkqwCLcBGAsYHQ\/s1900\/header.png)","276c65ed":"# Prediction"}}