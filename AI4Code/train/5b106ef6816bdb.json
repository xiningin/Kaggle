{"cell_type":{"ba3eb357":"code","75a428de":"code","707967f2":"code","c05bc681":"code","ba0cb677":"code","3d0653d0":"code","bc116165":"code","f82ec95c":"code","03112b17":"code","99e71b65":"code","6159dff1":"code","a1ff05a4":"code","43a948f6":"code","b814ff8a":"code","cd921e6a":"code","39a6afd1":"code","dedc4557":"code","34eb98f0":"code","c37f77d0":"code","0d5fb858":"code","870787f8":"code","ca123baa":"code","282e5918":"code","fe8d4cb9":"code","e90830bb":"code","020cbf06":"code","bfbe9fb4":"code","c95aad69":"code","477a81e5":"code","cd0a6fe7":"code","2febaa26":"code","128866c5":"code","42d92c8d":"code","1a3e0f72":"code","992836a4":"code","0462c3ff":"code","c780ae1f":"code","19228451":"code","ff051bcf":"code","8d1905c9":"code","fcd5354c":"code","ac124436":"code","437cc7db":"code","a730de7b":"code","16ab1967":"code","349fe65a":"markdown","9fdf9bce":"markdown"},"source":{"ba3eb357":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport pysal\nimport plotly\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib \nimport matplotlib.pyplot as plt\nimport plotly.plotly as py\nimport sklearn\nimport datetime\nimport descartes\nfrom shapely.geometry import Point, Polygon\nimport plotly.graph_objs as go\n%matplotlib inline\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n#import os\n#print(os.listdir(\"..\/input\"))\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"UTF8\"))\n# Any results you write to the current directory are saved as output.","75a428de":"import geopandas as gpd\n\nMy_file_path_name = r'..\/input\/norm2_18apl17.dbf'\n\nTable = gpd.read_file(My_file_path_name)\n\n#Pandas_Table = pd.DataFrame(Table)\n","707967f2":"Pandas_Table=Table\ncrs= {'init': 'epsg:32635'}\nPandas_Table.head()","c05bc681":"crs= {'init': 'epsg:32635'}\ngeometry = [Point(xy) for xy in zip( Pandas_Table[\"lon\"], Pandas_Table[\"lat\"])]\ngeometry[:3]","ba0cb677":"import geopandas as gdp\nPandas_Table = gdp.GeoDataFrame(Pandas_Table,\n                         crs=crs,\n                         geometry=geometry)\nPandas_Table.head()","3d0653d0":"Pandas_Table.info()","bc116165":"a = Pandas_Table['tweet'].str.encode('latin-1').str.decode('utf-8', errors = 'ignore')\nPandas_Table['tweet'] = a\n","f82ec95c":"#datetime_object = pd.to_datetime(Pandas_Table['inserttime'])\n#datetime_object.loc[\"2017-04-05\":\"2017-04-06\",:]\n#print(type(datetime_object))","03112b17":"print(type(Pandas_Table['inserttime'][1]))\ndatetime_object = pd.to_datetime(Pandas_Table['inserttime'])\nprint(type(datetime_object))\nPandas_Table[\"inserttime\"] = datetime_object\nPandas_Table.dtypes","99e71b65":"Pandas_Table['inserttime'] = Pandas_Table['inserttime'].dt.tz_localize('UTC').dt.tz_convert('Europe\/Istanbul')\nPandas_Table.tail()","6159dff1":"Pandas_Table['twitteruse'].value_counts(dropna =False)  ","a1ff05a4":"filtered = Pandas_Table.groupby('twitteruse').filter(lambda x: len(x) <= 300)\nPandas_Table=Pandas_Table[Pandas_Table.isin(filtered)]\nPandas_Table['twitteruse'].value_counts(dropna =False)","43a948f6":"print(type(Pandas_Table))\nPandas_Table =Pandas_Table[pd.notnull(Pandas_Table['twitteruse'])]\nPandas_Table.info()","b814ff8a":"Pandas_Table['twitteruse'].value_counts(dropna =False)  \n","cd921e6a":"data_fw = Pandas_Table \ndata_fw['inserttime'] = pd.to_datetime(data_fw['inserttime'])\nstart_date = '2017-04-01 00:00:00.615668+03:00'\nend_date = '2017-04-10 00:00:00.615668+03:00'\nmask = (data_fw['inserttime'] > start_date) & (data_fw['inserttime'] <= end_date)\ndata_fw = data_fw.loc[mask]\ndata_fw.info()","39a6afd1":"data_sw = Pandas_Table \ndata_sw['inserttime'] = pd.to_datetime(data_sw['inserttime'])\nstart_date = '2017-04-10 00:00:00.615668+03:00'\nend_date = '2017-04-25 00:00:00.891808+03:00'\nmask = (data_sw['inserttime'] > start_date) & (data_sw['inserttime'] <= end_date)\ndata_sw = data_sw.loc[mask]\ndata_sw.info()","dedc4557":"data_wknd = Pandas_Table \ndata_wknd['inserttime'] = pd.to_datetime(data_wknd['inserttime'])\nstart_date = '2017-04-02 01:00:09.631735+03:00'\nend_date = '2017-04-03 23:59:38.891808+03:00'\nmask = (data_wknd['inserttime'] > start_date) & (data_wknd['inserttime'] <= end_date)","34eb98f0":"data_wknd = data_wknd.loc[mask]\ndata_wknd.head()\ndata_wknd.info()","c37f77d0":"from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nstopwords = set(STOPWORDS)\nstopwords.update([\"https\", \"\u0130stanbul\", \"Istanbul\", \"co\", \"T\u00fcrkiye\",\"posted\",\"photo\",\"Turkey\"])\nfiltered = Table.groupby('twitteruse').filter(lambda x: len(x) >= 300)\nx2011=Table[Table.isin(filtered)]\nx2011 =x2011[pd.notnull(x2011['twitteruse'])]\ntext = \" \".join(review for review in Pandas_Table.tweet)\n#x2011 = Pandas_Table['twitteruse']\n\nplt.subplots(figsize=(20,20))\nwordcloud = WordCloud(    stopwords=stopwords,\n                          background_color='white',\n                          width=512,\n                          height=384\n                         ).generate(text)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\n\nplt.show()","0d5fb858":"aralik=['1','2','2:4','4:6','6:8','8:10','10:300']\nlistemiz = [0,0,0,0,0,0,0]\n\n#Pandas_Table['twitteruse'].value_counts(dropna =False)\n\na = 1\nb = 1\n\nfor i in range(0,7):\n    data10 = Pandas_Table\n    filtered = data10.groupby('twitteruse').filter(lambda x: (len(x) <= a) & (len(x) > a-b))\n    filtrelidata = data10[data10.isin(filtered)]\n    listemiz[i] = filtrelidata['twitteruse'].value_counts().shape[0]\n    \n    if a == 1:\n        a = a + 1\n    elif a<=10:\n        b = 2\n        a = a + 2\n    else:\n        a = 300\n        b = 290\n\nlistemiz \n","870787f8":"barWidth = 0.25\n\nf, ax = plt.subplots(figsize = (20,9))\n\n# Set position of bar on X axis\nr1 = np.arange(len(listemiz))\n#r2 = [x + barWidth for x in r1]\n \n# Make the plot\nplt.bar(r1, listemiz, color='cornflowerblue', width=0.5, edgecolor='white', label='Veri')\n#plt.bar(r2,liste_iki, color='crimson', width=barWidth, edgecolor='white', label='\u0130kinci Hafta')\n \n# Add xticks on the middle of the group bars\nplt.xlabel('Kullan\u0131c\u0131lar\u0131n G\u00f6nderdi\u011fi Tweet Say\u0131s\u0131', fontweight='bold',fontsize=15)\nplt.ylabel('Kullan\u0131c\u0131 Say\u0131s\u0131', fontweight='bold',fontsize=15)\nplt.xticks([r + 0.03 for r in range(len(listemiz))], aralik,fontsize=12)\nplt.yticks(fontsize=12)\n \n# Create legend & Show graphic\nplt.legend(fontsize='15')\nplt.show()\n","ca123baa":"aralik=['1','2','2:4','4:6','6:8','8:10','10:300']\nliste_ilk = [0,0,0,0,0,0,0]\nliste_iki = [0,0,0,0,0,0,0]\n#Pandas_Table['twitteruse'].value_counts(dropna =False)\n\na = 1\nb = 1\n\nfor i in range(0,7):\n    data5 = data_fw\n    data6 = data_sw\n    filtered = data5.groupby('twitteruse').filter(lambda x: (len(x) <= a) & (len(x) > a-b))\n    filtrelidata = data5[data5.isin(filtered)]\n    liste_ilk[i] = filtrelidata['twitteruse'].value_counts().shape[0]\n    filtered = data6.groupby('twitteruse').filter(lambda x: (len(x) <= a) & (len(x) > a-b))\n    filtrelidata = data6[data6.isin(filtered)]\n    liste_iki[i] = filtrelidata['twitteruse'].value_counts().shape[0]\n    if a == 1:\n        a = a + 1\n    elif a<=10:\n        b = 2\n        a = a + 2\n    else:\n        a = 300\n        b = 290\n\nliste_ilk\nliste_iki\n\n","282e5918":"# set width of bar\nbarWidth = 0.25\n\nf, ax = plt.subplots(figsize = (20,9))\n\n# Set position of bar on X axis\nr1 = np.arange(len(liste_ilk))\nr2 = [x + barWidth for x in r1]\n \n# Make the plot\nplt.bar(r1, liste_ilk, color='cornflowerblue', width=barWidth, edgecolor='white', label='\u0130lk Hafta')\nplt.bar(r2,liste_iki, color='crimson', width=barWidth, edgecolor='white', label='\u0130kinci Hafta')\n \n# Add xticks on the middle of the group bars\nplt.xlabel('Kullan\u0131c\u0131lar\u0131 G\u00f6nderdi\u011fi Tweet Say\u0131s\u0131', fontweight='bold')\nplt.ylabel('Kullan\u0131c\u0131 Say\u0131s\u0131', fontweight='bold')\nplt.xticks([r + 0.12 for r in range(len(liste_ilk))], aralik)\n \n# Create legend & Show graphic\nplt.legend(fontsize='15')\nplt.show()\n","fe8d4cb9":"df= [liste_ilk, liste_iki]\nf, ax = plt.subplots(figsize = (20,9))\nsns.barplot(x=liste_ilk,y=aralik,color='orange',alpha = 0.5,label='First Week' )\nsns.barplot(x=liste_iki,y=aralik,color='red',alpha = 0.5,label='Second Week')\n\n\nax.legend(loc='lower right',frameon = True,fontsize='15')     # legendlarin gorunurlugu\nax.set(xlabel='Tweet Say\u0131s\u0131', ylabel='Tweet Say\u0131s\u0131 Aral\u0131klar\u0131',title = \"Haftalara g\u00f6re tweet\")","e90830bb":"data_sw['inserttime'] = pd.to_datetime(data_sw['inserttime'])\nstart_date = '2017-04-11 18:11:39.615668+03:00'\nend_date = '2017-04-25 19:26:38.891808+03:00'\nmask = (data_sw['inserttime'] > start_date) & (data_sw['inserttime'] <= end_date)","020cbf06":"x = ['Pzts','Sal\u0131','\u00c7ar\u015f','Per\u015f','Cuma','Cmrts','Pzr']\ny = [0,0,0,0,0,0,0]\n\nstart_date = pd.to_datetime('2017-04-10 00:00:00.000000').tz_localize('Europe\/Istanbul')\nend_date =  pd.to_datetime('2017-04-11 00:00:00.000000').tz_localize('Europe\/Istanbul')\nfor i in range(0,7):\n    start_date +=  pd.Timedelta('1 days')\n    end_date +=  pd.Timedelta('1 days')\n    mask = (data_sw['inserttime'] > start_date) & (data_sw['inserttime'] <= end_date)\n    y[i] = data_sw.loc[mask].shape[0]\ny\n\n#visualization\nplt.figure(figsize=(10,10))\nsns.barplot(x=x, y=y,palette= sns.diverging_palette(255, 133, l=60, n=7, center=\"dark\"))\nplt.xticks(rotation= 90)\nplt.ylabel('Total Tweet',fontsize = 15)\nplt.grid()","bfbe9fb4":"x = ['Pzts','Sal\u0131','\u00c7ar\u015f','Per\u015f','Cuma','Cmrts','Pzr']\ny = [0,0,0,0,0,0,0]\n\nstart_date = pd.to_datetime('2017-04-10 00:00:00.000000').tz_localize('Europe\/Istanbul')\nend_date =  pd.to_datetime('2017-04-11 00:00:00.000000').tz_localize('Europe\/Istanbul')\nfor i in range(0,7):\n    start_date +=  pd.Timedelta('1 days')\n    end_date +=  pd.Timedelta('1 days')\n    mask = (data_sw['inserttime'] > start_date) & (data_sw['inserttime'] <= end_date)\n    u = data_sw.loc[mask]\n    y[i]=len(u['twitteruse'].value_counts(dropna =False))\n\n#visualization\nplt.figure(figsize=(10,10))\nsns.barplot(x=x, y=y,color='grey',alpha=0.5)\nplt.xticks(rotation= 90)\nplt.ylabel('Ki\u015fi Say\u0131s\u0131',fontsize = 15)\nplt.grid()","c95aad69":"x = [0,1, 2,3, 4,5, 6,7, 8,9, 10,11,12,13, 14,15, 16,17, 18,19, 20,21, 22,23]\ny = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\nc = ['b','g','r','c','y','k','cornflowerblue']\n\nstart_date = pd.to_datetime('2017-04-10 00:00:00.000000').tz_localize('Europe\/Istanbul')\nend_date =  pd.to_datetime('2017-04-11 00:00:00.000000').tz_localize('Europe\/Istanbul')\nstart_time = pd.to_datetime('2017-04-10 22:00:00.000000').tz_localize('Europe\/Istanbul')\nend_time =  pd.to_datetime('2017-04-11 00:00:00.000000').tz_localize('Europe\/Istanbul')\n\nf,ax1 = plt.subplots(figsize =(20,10))\n\nfor i in range(0,7):\n    start_date +=  pd.Timedelta('1 days')\n    end_date +=  pd.Timedelta('1 days')\n    mask = (data_sw['inserttime'] >= start_date) & (data_sw['inserttime'] <= end_date)\n    elbetbirgun = data_sw.loc[mask]\n    for j in range(0,24):\n        start_time +=  pd.Timedelta('1 hours')\n        end_time +=  pd.Timedelta('1 hours')\n        mask = (elbetbirgun['inserttime'] >= start_time) & (elbetbirgun['inserttime'] <= end_time)\n        y[j] = elbetbirgun.loc[mask].shape[0]\n    sns.pointplot(x=x,y=y,color=c[i],alpha=0.8, linestyles='--')\n    plt.text(0,4000-(i*200),str(i+1) + '. G\u00fcn',color=c[i],fontsize = 17,style = 'italic')\n\nplt.xlabel('Saatler',fontsize = 15,color='blue')\nplt.ylabel('Tweet Say\u0131s\u0131',fontsize = 15,color='blue')\nplt.grid()\n \n","477a81e5":"x = [0,1, 2,3, 4,5, 6,7, 8,9, 10,11,12,13, 14,15, 16,17, 18,19, 20,21, 22,23]\ny = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\nc = ['b','g','r','c','y','k','cornflowerblue']\n\nstart_date = pd.to_datetime('2017-04-10 00:00:00.000000').tz_localize('Europe\/Istanbul')\nend_date =  pd.to_datetime('2017-04-11 00:00:00.000000').tz_localize('Europe\/Istanbul')\nstart_time = pd.to_datetime('2017-04-10 22:00:00.000000').tz_localize('Europe\/Istanbul')\nend_time =  pd.to_datetime('2017-04-11 00:00:00.000000').tz_localize('Europe\/Istanbul')\n\nf,ax1 = plt.subplots(figsize =(20,10))\n\nfor i in range(0,7):\n    start_date +=  pd.Timedelta('1 days')\n    end_date +=  pd.Timedelta('1 days')\n    mask = (data_sw['inserttime'] >= start_date) & (data_sw['inserttime'] <= end_date)\n    elbetbirgun = data_sw.loc[mask]\n    for j in range(0,24):\n        start_time +=  pd.Timedelta('1 hours')\n        end_time +=  pd.Timedelta('1 hours')\n        mask = (elbetbirgun['inserttime'] >= start_time) & (elbetbirgun['inserttime'] <= end_time)\n        un = elbetbirgun.loc[mask]\n        y[j]=len(un['twitteruse'].value_counts(dropna =False))\n    sns.pointplot(x=x,y=y,color=c[i],alpha=0.8, linestyles='--')\n    plt.text(0,2900-(i*150),str(i+1) + '. G\u00fcn',color=c[i],fontsize = 15,style = 'italic')\n\nplt.xlabel('Saatler',fontsize = 15,color='blue')\nplt.ylabel('Kullan\u0131c\u0131 Say\u0131s\u0131',fontsize = 15,color='blue')\nplt.grid()\n \n    ","cd0a6fe7":"date = pd.to_datetime('2017-04-11 18:11:39.615668+03:00')\nfor i in range(5): \n    date += pd.Timedelta('1 days')\n    print(date)\n    \n\n","2febaa26":"import folium \n\nicon = folium.features.CustomIcon('https:\/\/upload.wikimedia.org\/wikipedia\/commons\/1\/19\/Twitter_icon.svg',icon_size=(14, 14))\n\nbase_m = folium.Map(location=[40.909550, 29.389620], control_scale=True, zoom_start=10)\nfor lat,lng,num in zip(data_wknd.lat,data_wknd.lon,range(1,data_wknd.shape[0])): \n        #popup = folium.Popup(data_wknd['twitteruse'][num], parse_html=True)\n        #folium.Marker( location=[ lat, lng ]).add_to(base_map)\n        if num<300:\n            folium.Marker( location=[ lat, lng ], popup=data_wknd.iloc[num]['tweet']).add_to(base_m)\n    \nbase_m","128866c5":"fig, ax = plt.subplots(figsize=(15,15))\nTable.plot(ax=ax, alpha= 0.4, color=\"grey\")\nPandas_Table[Pandas_Table['lat']>40].plot(ax=ax, markersize=20, color=\"blue\", marker = \"o\", label=\"Neg\")\nPandas_Table[Pandas_Table['lon']>29.0458].plot(ax=ax, markersize=20, color=\"red\", marker = \"^\", label=\"Pos\")\nplt.legend(prop={'size':15})\n","42d92c8d":"import folium \ndef generateBaseMap(default_location=[41.109550, 28.989620], default_zoom_start=10):\n    base_map = folium.Map(location=default_location, control_scale=True, zoom_start=default_zoom_start)\n    return base_map\nbase_map = generateBaseMap()\nbase_map","1a3e0f72":"from folium.plugins import HeatMap\ndf_copy = data_wknd.copy()\ndf_copy['count'] = 1\nbase_map = generateBaseMap()\nHeatMap(data=df_copy[['lat', 'lon', 'count']].groupby(['lat', 'lon']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)","992836a4":"df_copy.head()","0462c3ff":"base_map","c780ae1f":"arrayunique=data_wknd.twitteruse.unique()\n\n\nyenidf = pd.DataFrame(arrayunique, columns =['twitteruse']) \nyenidf['lat']=0\nyenidf['lon']=0\nyenidf['tweet']=\"\"\n\n\ndef fonkfonk(ts):\n    yuyo=data_wknd[data_wknd[\"twitteruse\"] == ts]\n    return yuyo.sum(axis = 0, skipna = True).lat\/yuyo['lat'].shape[0]\n\ndef fonkfonk2(ts):\n    yuyo=data_wknd[data_wknd[\"twitteruse\"] == ts]\n    return yuyo.sum(axis = 0, skipna = True).lon\/yuyo['lon'].shape[0]\n\ndef fonkfonk3(ts):\n    yuyo=data_wknd[data_wknd[\"twitteruse\"] == ts]\n    return yuyo.sum(axis = 0, skipna = True).tweet\n\nyenidf['lat'] = yenidf['twitteruse'].apply(fonkfonk)\nyenidf['lon'] = yenidf['twitteruse'].apply(fonkfonk2)\nyenidf['tweet'] = yenidf['twitteruse'].apply(fonkfonk3)\n\nyenidf","19228451":"import folium \n\nicon = folium.features.CustomIcon('https:\/\/upload.wikimedia.org\/wikipedia\/commons\/1\/19\/Twitter_icon.svg',icon_size=(14, 14))\n\nbase_m = folium.Map(location=[40.909550, 29.389620], control_scale=True, zoom_start=10)\nfor lat,lng,num in zip(yenidf.lat,yenidf.lon,range(1,yenidf.shape[0])): \n        #popup = folium.Popup(data_wknd['twitteruse'][num], parse_html=True)\n        #folium.Marker( location=[ lat, lng ]).add_to(base_map)\n        if(num<3000):\n            folium.Marker( location=[ lat, lng ]).add_to(base_m)\n    \nbase_m","ff051bcf":"data_gun1 = Pandas_Table \ndata_gun1['inserttime'] = pd.to_datetime(data_gun1['inserttime'])\nstart_date = '2017-04-10 00:00:00.615668+03:00'\nend_date = '2017-04-11 00:00.891808+03:00'\nmask = (data_gun1['inserttime'] > start_date) & (data_gun1['inserttime'] <= end_date)\ndata_gun1 = data_gun1.loc[mask]\ndata_gun1.info()","8d1905c9":"data_gun1['hour'] = 0\n\ndef hr_func(ts):\n    return ts.hour\n\ndata_gun1['hour'] = data_gun1['inserttime'].apply(hr_func)\n","fcd5354c":"df_hour_list = []\ngun = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\nfor hour in gun:\n    df_hour_list.append(data_gun1.loc[data_gun1.hour == hour, ['lat', 'lon']].groupby(['lat', 'lon']).sum().reset_index().values.tolist())","ac124436":"from folium.plugins import HeatMapWithTime\nbase_map3 = generateBaseMap(default_zoom_start=11)\nHeatMapWithTime(df_hour_list, radius=5, gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 1: 'red'},\n                min_opacity=0.5, max_opacity=0.8, use_local_extrema=True).add_to(base_map3)\nbase_map3","437cc7db":"gunluk = data_fw\ngunluk['day'] = 0\n\ndef hr_func_2(ts):\n    return ts.day\n\ngunluk['day'] = gunluk['inserttime'].apply(hr_func_2)\n","a730de7b":"df_day_list = []\ngun = [1,2,3,4,5,6,7,8,9,10,11]\nfor gun in gun:\n    df_day_list.append(gunluk.loc[gunluk.day == gun, ['lat', 'lon']].groupby(['lat', 'lon']).sum().reset_index().values.tolist())\n","16ab1967":"from folium.plugins import HeatMapWithTime\nbase_map4 = generateBaseMap(default_zoom_start=11)\nHeatMapWithTime(df_day_list, radius=5, gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 1: 'red'},\n                min_opacity=0.5, max_opacity=0.8, use_local_extrema=True).add_to(base_map4)\nbase_map4\n","349fe65a":"**VISUALIZATION**","9fdf9bce":" **HeatMap with Time**"}}