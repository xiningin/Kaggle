{"cell_type":{"12cf9269":"code","f0ec73ac":"code","4f89e64a":"code","b26d5da9":"code","2066e1f9":"code","8690bbb3":"code","8b5e65ac":"code","51c7eabb":"code","d85bc682":"code","c0ae3a7c":"code","a0e845be":"code","0112a986":"code","bbdb4f4e":"code","c77b2073":"code","5a78810f":"code","01f82b95":"code","fe8d882b":"code","685beebb":"code","4cfa2bc3":"code","36009ede":"code","c6f7d36a":"code","abed451c":"code","a4459734":"code","a4983c30":"code","8f3cbd70":"code","5850c3a2":"code","04ae3b71":"code","ee309166":"code","21a67f22":"code","5eefee1d":"code","4deff247":"code","29ea90fc":"code","4bbe4e7b":"code","60542f31":"code","b5869c33":"code","ec7e0002":"code","c5587647":"code","8cc40790":"code","bfdc3055":"code","a5c5b981":"code","a1a7285f":"code","e380463f":"code","0c9ec579":"code","10f37d50":"code","04366570":"code","e3f28ffc":"code","4b0f39f8":"code","dab8a28a":"code","9f7d6b7a":"code","47d40704":"code","de7f15f3":"code","6ec0b4ff":"code","4968a750":"code","40d26e3b":"code","f94fed46":"code","f63af7eb":"code","03449921":"code","fe0483e3":"code","70c2285d":"code","af96c3d8":"code","361d8434":"code","d04f2c9e":"code","29279a96":"code","4ac2f7a5":"code","087983ba":"code","b2902215":"code","ac45eb9a":"code","07c86eec":"code","b2f90098":"code","c7556902":"code","a843c17c":"code","5728bed9":"code","86cc178d":"code","3c50092c":"code","27dae332":"code","9e884057":"code","73c407da":"code","a92c77b3":"code","397d5efc":"code","575e1aed":"code","40122d79":"code","d3770893":"code","d9404cdb":"code","acfa253c":"code","d8e112bf":"code","df2780f5":"code","37b76510":"code","7db11777":"code","31a65695":"code","0c41ef51":"code","b34a23aa":"code","584cfbeb":"code","8e9a24e6":"code","8598f9b0":"code","850c57dd":"markdown","dcecd145":"markdown","d470159c":"markdown","16f38d68":"markdown","ff041685":"markdown","cca98a19":"markdown","c93a64c8":"markdown","2e5abf10":"markdown","4d3a79dc":"markdown","e836f16c":"markdown","2b5b0248":"markdown","c37b8d80":"markdown","3fbaf336":"markdown","f02c24c3":"markdown","f9851a39":"markdown","c70c8eda":"markdown","23099c37":"markdown","1342a240":"markdown","6c79abdc":"markdown","410e23db":"markdown","1375457c":"markdown","d6c7dded":"markdown","56c6355c":"markdown","15a086c3":"markdown","67971fd0":"markdown","599506b5":"markdown","a9e704c1":"markdown","6589174a":"markdown","799607cd":"markdown","0e3bb062":"markdown","bdff3855":"markdown","e472faa6":"markdown","287e1662":"markdown","a346a4a2":"markdown","3de99503":"markdown","8e22886d":"markdown","764def6f":"markdown","c383535e":"markdown","1512bbec":"markdown","68abbad2":"markdown","165be842":"markdown","5dcd718d":"markdown","ea670091":"markdown","d43ab7a5":"markdown","fab0ccd6":"markdown","c69161b2":"markdown","d2a5bd02":"markdown","47b40fc2":"markdown","1250ad8a":"markdown"},"source":{"12cf9269":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f0ec73ac":"#Import required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\nfrom sklearn.preprocessing import PowerTransformer\npt = PowerTransformer()\n\nfrom scipy import stats\n\nfrom sklearn.model_selection import train_test_split\n\n#Import (Z-Scaler) StandardScaler\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()","4f89e64a":"#Read dataset from the kaggle\n\ndf= pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv')\ndf.head()","b26d5da9":"#some varaibles which is categorical feature but has datatype as int, so changing those datatype to \n#object\n\ndf[['Driving_License', 'Previously_Insured', 'Response']] = df[['Driving_License', 'Previously_Insured', 'Response']].astype('object')","2066e1f9":"df.info()","8690bbb3":"#Shape\ndf.shape","8b5e65ac":"df_copy = df.copy(deep=True)","51c7eabb":"# Remove insignificant variable id\ndf.drop('id', axis=1, inplace=True)\n\ndf.head(1)","d85bc682":"#Remove duplicates\ndf.duplicated(keep='first').value_counts(normalize=True) * 100\n\n#There are totally 0.07% of duplicate records","c0ae3a7c":"df.duplicated(keep='first').value_counts()","a0e845be":"#We are keeping the first duplicate record and delete the rest\ndf.drop_duplicates(keep='first', inplace=True)\n\ndf.shape\n\n#Shape after removing duplicates","0112a986":"df.head(1)","bbdb4f4e":"#As seen in eda, only Annual_Premium variable had significant number of outliers\n\nq1 = df['Annual_Premium'].quantile(0.25)\nq3 = df['Annual_Premium'].quantile(0.75)\n\niqr = q3-q1\n\nll = q1 - 1.5*iqr\nul = q3 + 1.5*iqr\n\ndf[(df['Annual_Premium']<ll)|(df['Annual_Premium']>ul)].shape","c77b2073":"#There are 10331 outliers\n\n10331\/len(df_copy) * 100\n\n#2.71% outliers","5a78810f":"#We treat the outlier by Power transforming the Annual_Premium feature\n\nprint('Skewness of Annual_premium variable before Power transformation :', df['Annual_Premium'].skew())\n\ndf['Annual_Premium'] = pt.fit_transform(df[['Annual_Premium']])\n\nprint('\\nSkewness of Annual_premium variable after Power transformation :', df['Annual_Premium'].skew())","01f82b95":"#Skewness is reduced after applying Power transformation\n\n#distribution plot\nplt.figure(figsize=(12,8))\n\nplt.subplots_adjust(hspace=0.3)\n\nplt.subplot(2,1,1)\nsns.distplot(df_copy['Annual_Premium'])\nplt.title('Distribution before transformation')\n\nplt.subplot(2,1,2)\nsns.distplot(df['Annual_Premium'])\nplt.title('Distribution after transformation')\n\nplt.show()","fe8d882b":"df.info()","685beebb":"#Dividing the dataset to customers whose Response = 1 as res_1 and customers whose Response = 0 as res_0\n\n#Customer who have not responded\nres_0 = df[df['Response']==0]\n\n#Customer who have responded\nres_1 = df[df['Response']==1]","4cfa2bc3":"#Features whose datatype is 'numeric'\nnum_cols = list(df.select_dtypes(include='number'))\n\nnum_cols","36009ede":"# Test of normality\n# Ho: skew=0 (normal)\n# Ha : skew !=0(not normal)\n\n#Shapiro test\n\nfor col in num_cols:\n    print(f'\\nShapiro test for {col} feature :')\n    print('Response = 0 :',stats.shapiro(res_0[col]))\n    print('Response = 1 :',stats.shapiro(res_1[col]))","c6f7d36a":"#equality of variances\n# Ho: Variance is equal\n# Ha : Variance is not equal\n\nfor col in num_cols:\n    print(f'\\nLevene test for {col} feature :')\n    print(stats.levene(res_0[col], res_1[col]))","abed451c":"#As all the features are not normal, we cannot perform parametric test\n#We will perform non-parametric test (Mannwhitneyu)\n\n# Ho : mu1 = mu2(no relation)\n# Ha : mu1 != mu (relation)\n\nfor col in num_cols:\n    print(f'\\nNon-parametric 2-sample Unpaired test for {col} feature and Response feature :')\n    print(stats.mannwhitneyu(res_0[col], res_1[col]))","a4459734":"#Chi-Square Test for Independence : It is a non-parametric test (hence no assumptions)\n#H0 : The variables are independent\n#H1 : The variables are not independent (i.e. variables are dependent)\n\n#List of categorical features\ncat_cols = list(df.select_dtypes(exclude='number'))\n\n#Remove the target feature from the list\ncat_cols.remove('Response')\n\ncat_cols","a4983c30":"#perform chi2_contingency for all the categorical features and Response target\nfor col in cat_cols:\n    print(f'{col} vs Response :')\n    obs = pd.crosstab(index=df['Response'], columns=df[col]) #create a cross-tab for feature and target\n    print('Observed values :\\n',obs )\n    print(stats.chi2_contingency(obs))\n    print('Pvalue =',stats.chi2_contingency(obs)[1] )\n    print('\\n\\n')","8f3cbd70":"df.head(1)","5850c3a2":"#Driving_License, Previously_Insured, Response are already encoded but Data-type is object\n#Change the datatype to int\n\ndf[['Driving_License', 'Previously_Insured', 'Response']] = df[['Driving_License', 'Previously_Insured', 'Response']].astype('int')","04ae3b71":"df.info()","ee309166":"#One hot encoding the rest of categorical variables, by droping the first column after encoding\n\ncat_cols = list(df.select_dtypes(exclude='number'))\n\ndf = pd.get_dummies(df, columns=cat_cols, drop_first=True)\ndf.head(1)","21a67f22":"df.info()","5eefee1d":"df.shape","4deff247":"# X y split\ny = df['Response']\nX = df.drop('Response', axis=1)\n\n#Train & test split with 0.3%\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=4)\n\nprint('X train Shape :',X_train.shape)\nprint('X test Shape :',X_test.shape)","29ea90fc":"from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score, roc_curve, precision_score, recall_score\n\nresult_df = pd.DataFrame(columns=['Model_Name', 'Accuracy_score_train', 'roc_auc_score_train','f1_score_train','precision_score_train', \n                                  'recall_score_train','Accuracy_score_test', 'roc_auc_score_test','f1_score_test', 'precision_score_test', 'recall_score_test'  ])\n\nresult_df","4bbe4e7b":"#Defining a function to append metrics in dataframe\n\ndef model_score_card(algo,  name, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n    algo.fit(X_train, y_train)\n    \n    #train datset\n    y_train_pred = algo.predict(X_train)\n    y_train_proba = algo.predict_proba(X_train)[::, 1]\n    \n    #test datset\n    y_test_pred = algo.predict(X_test)\n    y_test_proba = algo.predict_proba(X_test)[::, 1]\n    \n    global result_df\n    \n    result_df = result_df.append({'Model_Name' : name,\n                                    \n                                    'Accuracy_score_train' :accuracy_score(y_train, y_train_pred) ,\n                                    'roc_auc_score_train' : roc_auc_score(y_train, y_train_proba),\n                                    'f1_score_train' : f1_score(y_train, y_train_pred), \n                                    'precision_score_train' : precision_score(y_train, y_train_pred), \n                                    'recall_score_train' : recall_score(y_train, y_train_pred),\n                                    \n                                    'Accuracy_score_test':accuracy_score(y_test, y_test_pred),\n                                      'f1_score_test' :f1_score(y_test, y_test_pred) ,\n                                    'roc_auc_score_test' : roc_auc_score(y_test, y_test_proba),\n                                     \n                                    'precision_score_test' : precision_score(y_test, y_test_pred), \n                                    'recall_score_test' : recall_score(y_test, y_test_pred)}, ignore_index = True)\n    \n    return result_df","60542f31":"#Defining a function to get evaluation metrics\n\ndef model_eval(algo,  X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n    algo.fit(X_train, y_train)\n    \n    #train datset\n    y_train_pred = algo.predict(X_train)\n    y_train_proba = algo.predict_proba(X_train)[::, 1]\n\n    print('Train dataset :')\n    print('Confusion matrix :\\n', confusion_matrix(y_train, y_train_pred))\n    print('Accuracy :',accuracy_score(y_train, y_train_pred) )\n    print('AUC score :', roc_auc_score(y_train, y_train_proba))\n    print('F1-score :', f1_score(y_train, y_train_pred))\n    print('Precision score :', precision_score(y_train, y_train_pred))\n    print('Recall score :', recall_score(y_train, y_train_pred))\n    \n    #test datset\n    y_test_pred = algo.predict(X_test)\n    y_test_proba = algo.predict_proba(X_test)[::, 1]\n    print('\\n\\nTest dataset :')\n    print('Confusion matrix :\\n', confusion_matrix(y_test, y_test_pred))\n    print('Accuracy :',accuracy_score(y_test, y_test_pred) )\n    print('AUC score :', roc_auc_score(y_test, y_test_proba))\n    print('F1-score :', f1_score(y_test, y_test_pred))\n    print('Precision score :', precision_score(y_test, y_test_pred))\n    print('Recall score :', recall_score(y_test, y_test_pred))","b5869c33":"from sklearn.linear_model import LogisticRegression\n\nlor = LogisticRegression(solver='liblinear',random_state=4)\n\nmodel_eval(lor)","ec7e0002":"## Appending the evaluation metrics in a DataFrame for further reference\n\nlor = LogisticRegression(solver='liblinear',random_state=4)\n\nmodel_score_card(lor, 'Logistic Regression')","c5587647":"lor = LogisticRegression(solver='liblinear',random_state=4)\nlor.fit(X_train, y_train)\n    \n    #train datset\ny_train_pred = lor.predict(X_train)\ny_train_proba = lor.predict_proba(X_train)[::, 1]\n    \n    #test datset\ny_test_pred = lor.predict(X_test)\ny_test_proba = lor.predict_proba(X_test)[::, 1]\n\nfpr_train,tpr_train,threshold_train = roc_curve(y_train,y_train_proba )\nfpr_test,tpr_test,threshold_test = roc_curve(y_test,y_test_proba )\n\nprint('Logistic Regression Base model :')\n\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.plot(fpr_train,fpr_train)\nplt.plot(fpr_train,tpr_train)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Train Data')\n\nplt.subplot(1,2,2)\nplt.plot(fpr_test,fpr_test)\nplt.plot(fpr_test,tpr_test)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Test Data')\nplt.show()","8cc40790":"#First we check for skewness & then transform the data to reduce the skewness \n#We are checking skewness for numerical columns & only for Train data and transform test data to avoid Data-leakage\n\nX_train[num_cols].skew()","bfdc3055":"#As Age feature is right skewed, we will use Power transformation to reduce the reduce\n\nprint('Skewness before transformation :', X_train['Age'].skew())\n\nX_train['Age'] = pt.fit_transform(X_train[['Age']])\nX_test['Age'] = pt.transform(X_test[['Age']])\n\nprint('\\nSkewness after Power transformation :', X_train['Age'].skew())","a5c5b981":"#Skewness of Region Code is -0.113, which is almost equal to 0\n#So we will avoid transformation for Region_code feature","a1a7285f":"#Policy_Sales_Channel is left skewed, so Power tranformation will not work properly\n#So, after trail & error, (To the power of 6) gives best results\n\nprint('Skewness before transformation :', X_train['Policy_Sales_Channel'].skew())\n\nX_train['Policy_Sales_Channel'] = X_train['Policy_Sales_Channel']**6\nX_test['Policy_Sales_Channel'] = X_test['Policy_Sales_Channel']**6\n\nprint('\\nSkewness after Power transformation :', X_train['Policy_Sales_Channel'].skew())","e380463f":"#Scaling the whole data using StandardScaler\n# Fit on Train data and tranform it on Test data to avoid Data-Leakage\n\nX_train[num_cols] = ss.fit_transform(X_train[num_cols])\n\nX_test[num_cols] = ss.transform(X_test[num_cols])","0c9ec579":"#Building the Logistic regression on transformed data to check the improvement\n\nlor = LogisticRegression(solver='liblinear',random_state=4)\n\nmodel_eval(lor)","10f37d50":"##### There is no change in base model after data transformation\n\n# X and Y dataset after transformation\n\n#concat train and test dataset for variable Y\ny_full = pd.concat([y_train, y_test], axis=0)\ny_full.shape","04366570":"#concat train and test dataset for variable X\n\nX_full = pd.concat([X_train, X_test], axis=0)\nX_full.shape","e3f28ffc":"from sklearn.feature_selection import RFE, RFECV\n\n#estimator used is LogisticRegression\nlor = LogisticRegression(solver='liblinear',random_state=4)\n\n#RUN RFECV to find out the best number of features to be selected\nrfe_n = RFECV(estimator=lor, cv=3, scoring='roc_auc', verbose=2, n_jobs=-1)\nrfe_n.fit(X_full, y_full)","4b0f39f8":"#Number\nprint('Number of features selected :', rfe_n.n_features_)","dab8a28a":"#Selected features\nselected = list(X_full.columns[rfe_n.support_])\nprint('\\nSelected features :',selected)","9f7d6b7a":"#selecting only features from RFE in both train & test dataset\n\nX_train_sel = X_train[selected]\nX_test_sel = X_test[selected]","47d40704":"lor = LogisticRegression(solver='liblinear',random_state=4)\n\nmodel_eval(lor, X_train_sel, X_test_sel, y_train, y_test)","de7f15f3":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(sampling_strategy='minority')\n\n#SMOTE analysis on train dataset\nX_train_sm, y_train_sm = smote.fit_resample(X_train_sel, y_train)\n\nprint('Shape of X train', X_train_sm.shape)\n\nprint('\\nCount of target variable :')\nprint(y_train_sm.value_counts())\n#after smote analysis, target variable is equally distributed","6ec0b4ff":"#building LogisticRegression on smote analysed data\nlor = LogisticRegression(solver='liblinear',random_state=4)\n\n#Model evaluation\nmodel_eval(lor, X_train_sm,X_test_sel, y_train_sm, y_test)","4968a750":"## Appending the evaluation metrics in a DataFrame for further reference\n##This is the final base model\nmodel_score_card(lor, 'Logistic Regression Final base_model', X_train_sm,X_test_sel, y_train_sm, y_test)","40d26e3b":"lor = LogisticRegression(solver='liblinear',random_state=4)\nlor.fit(X_train_sm, y_train_sm)\n    \n    #train datset\ny_train_sm_pred = lor.predict(X_train_sm)\ny_train_sm_proba = lor.predict_proba(X_train_sm)[::, 1]\n    \n    #test datset\ny_test_pred = lor.predict(X_test_sel)\ny_test_proba = lor.predict_proba(X_test_sel)[::, 1]\n\nfpr_train,tpr_train,threshold_train = roc_curve(y_train_sm,y_train_sm_proba )\nfpr_test,tpr_test,threshold_test = roc_curve(y_test,y_test_proba )\n\nprint('Logistic Regression Final-Base_model :')\n\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.plot(fpr_train,fpr_train)\nplt.plot(fpr_train,tpr_train)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Train Data')\n\nplt.subplot(1,2,2)\nplt.plot(fpr_test,fpr_test)\nplt.plot(fpr_test,tpr_test)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Test Data')\nplt.show()","f94fed46":"from sklearn.tree import DecisionTreeClassifier","f63af7eb":"#Build DTC model on Dataset which are : RFE selected features, smote analysed\n\ndtc = DecisionTreeClassifier()\n\nmodel_eval(dtc, X_train_sm,X_test_sel, y_train_sm, y_test)","03449921":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV","fe0483e3":"from scipy.stats import randint as sp_randint","70c2285d":"# GridSearchCV & RandomizedSearchCV results were almost similar\n# We are considering RandomizedSearchCV for Hyper-parameter tuning\n\ndtc = DecisionTreeClassifier(random_state=4)\n\nparams = {'max_depth' : sp_randint(2,10),\n         'min_samples_leaf' : sp_randint(1,12),\n         'criterion' : ['gini', 'entropy']}\n\nrsearch = RandomizedSearchCV(dtc, param_distributions=params, n_iter=100, n_jobs=-1, \n                             cv=3, scoring='roc_auc', random_state=4)\n\n# RandomizedSearchCV on overall transformed datasets\nrsearch.fit(X_full,y_full)","af96c3d8":"#Best parameters\nprint(rsearch.best_params_)","361d8434":"dtc = DecisionTreeClassifier(**rsearch.best_params_, random_state=4)\n\nmodel_eval(dtc, X_train_sm, X_test_sel, y_train_sm, y_test)","d04f2c9e":"## Appending the evaluation metrics in a DataFrame for further reference\n\ndtc = DecisionTreeClassifier(**rsearch.best_params_, random_state=4)\n\nmodel_score_card(dtc, 'DecisionTreeClassifier HyperParameter-tuning', X_train_sm,X_test_sel, y_train_sm, y_test)","29279a96":"dtc = DecisionTreeClassifier(**rsearch.best_params_, random_state=4)\ndtc.fit(X_train_sm, y_train_sm)\n    \n    #train datset\ny_train_sm_pred = dtc.predict(X_train_sm)\ny_train_sm_proba = dtc.predict_proba(X_train_sm)[::, 1]\n    \n    #test datset\ny_test_pred = dtc.predict(X_test_sel)\ny_test_proba = dtc.predict_proba(X_test_sel)[::, 1]\n\nfpr_train,tpr_train,threshold_train = roc_curve(y_train_sm,y_train_sm_proba )\nfpr_test,tpr_test,threshold_test = roc_curve(y_test,y_test_proba )\n\nprint('DecisionTreeClassifier HyperParameter-tuning :')\n\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.plot(fpr_train,fpr_train)\nplt.plot(fpr_train,tpr_train)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Train Data')\n\nplt.subplot(1,2,2)\nplt.plot(fpr_test,fpr_test)\nplt.plot(fpr_test,tpr_test)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Test Data')\nplt.show()","4ac2f7a5":"from sklearn.ensemble import RandomForestClassifier","087983ba":"#Build RFC model on Dataset which are : RFE selected features, smote analysed\n\nrfc = RandomForestClassifier(random_state=4)\n\n#model evaluation\nmodel_eval(rfc, X_train_sm, X_test_sel, y_train_sm, y_test)","b2902215":"# GridSearchCV & RandomizedSearchCV results were almost similar\n# We are considering RandomizedSearchCV for Hyper-parameter tuning\n\nrfc = RandomForestClassifier(random_state=4)\n\nparams = {'n_estimators': sp_randint(50,200),\n         'max_features': sp_randint(1,15),\n         'min_samples_leaf' : sp_randint(1,25),\n          'max_depth' : sp_randint(1,10),\n         'criterion' : ['gini', 'entropy']}\n\nrsearch = RandomizedSearchCV(rfc, param_distributions=params, cv=3, n_iter=10,verbose=2, \n                             scoring='roc_auc', random_state=4, n_jobs=-1)\nrsearch.fit(X_full, y_full)","ac45eb9a":"#Best parameters\nprint(rsearch.best_params_)","07c86eec":"rfc = RandomForestClassifier(**rsearch.best_params_, random_state=4)\n\nmodel_eval(rfc, X_train_sm, X_test_sel, y_train_sm, y_test)","b2f90098":"## Appending the evaluation metrics in a DataFrame for further reference\n\nrfc = RandomForestClassifier(**rsearch.best_params_, random_state=4)\n\nmodel_score_card(rfc, 'RandomForestClassifier HyperParameter-tuning', X_train_sm,X_test_sel, y_train_sm, y_test)","c7556902":"rfc = RandomForestClassifier(**rsearch.best_params_, random_state=4)\nrfc.fit(X_train_sm, y_train_sm)\n    \n    #train datset\ny_train_sm_pred = rfc.predict(X_train_sm)\ny_train_sm_proba = rfc.predict_proba(X_train_sm)[::, 1]\n    \n    #test datset\ny_test_pred = rfc.predict(X_test_sel)\ny_test_proba = rfc.predict_proba(X_test_sel)[::, 1]\n\nfpr_train,tpr_train,threshold_train = roc_curve(y_train_sm,y_train_sm_proba )\nfpr_test,tpr_test,threshold_test = roc_curve(y_test,y_test_proba )\n\nprint('RandomForestClassifier HyperParameter-tuning :')\n\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.plot(fpr_train,fpr_train)\nplt.plot(fpr_train,tpr_train)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Train Data')\n\nplt.subplot(1,2,2)\nplt.plot(fpr_test,fpr_test)\nplt.plot(fpr_test,tpr_test)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Test Data')\nplt.show()","a843c17c":"import lightgbm as lgb","5728bed9":"#Build RFC model on Dataset which are : RFE selected features, smote analysed\n\nlgbc = lgb.LGBMClassifier()\n\n#model evaluation\nmodel_eval(lgbc, X_train_sm, X_test_sel, y_train_sm, y_test)","86cc178d":"from scipy.stats import uniform as sp_uniform","3c50092c":"lgbc = lgb.LGBMClassifier()\n\nparams = {'n_estimators':sp_randint(50,250),\n         'max_depth' : sp_randint(1,50),\n         'learning_rate' : sp_uniform(0,0.5)}\n\nrsearch = RandomizedSearchCV(lgbc, param_distributions=params, scoring='roc_auc', cv=3, n_iter=10,\n                             n_jobs=-1, random_state=4)\nrsearch.fit(X_full, y_full)","27dae332":"#Best parameters\nprint(rsearch.best_params_)","9e884057":"lgbc = lgb.LGBMClassifier(**rsearch.best_params_, random_state=4)\n\nmodel_eval(lgbc,  X_train_sm, X_test_sel, y_train_sm, y_test)","73c407da":"## Appending the evaluation metrics in a DataFrame for further reference\n\nlgbc = lgb.LGBMClassifier(random_state=4)\n\nmodel_score_card(lgbc, 'LGBMClassifier', X_train_sm,X_test_sel, y_train_sm, y_test)","a92c77b3":"lgbc = lgb.LGBMClassifier(random_state=4)\nlgbc.fit(X_train_sm, y_train_sm)\n    \n    #train datset\ny_train_sm_pred = lgbc.predict(X_train_sm)\ny_train_sm_proba = lgbc.predict_proba(X_train_sm)[::, 1]\n    \n    #test datset\ny_test_pred = lgbc.predict(X_test_sel)\ny_test_proba = lgbc.predict_proba(X_test_sel)[::, 1]\n\nfpr_train,tpr_train,threshold_train = roc_curve(y_train_sm,y_train_sm_proba )\nfpr_test,tpr_test,threshold_test = roc_curve(y_test,y_test_proba )\n\nprint('LGBMClassifier :')\n\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.plot(fpr_train,fpr_train)\nplt.plot(fpr_train,tpr_train)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Train Data')\n\nplt.subplot(1,2,2)\nplt.plot(fpr_test,fpr_test)\nplt.plot(fpr_test,tpr_test)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Test Data')\nplt.show()","397d5efc":"from sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.metrics import roc_curve","575e1aed":"#Model built on transformed data\nnb = GaussianNB()\n\nmodel_eval(nb, X_train_sel, X_test_sel, y_train, y_test)","40122d79":"nb = GaussianNB()\nnb.fit(X_train_sm, y_train_sm)\n    \n    #train datset\ny_train_sm_pred = nb.predict(X_train_sm)\ny_train_sm_proba = nb.predict_proba(X_train_sm)[::, 1]\n    \n    #test datset\ny_test_pred = nb.predict(X_test_sel)\ny_test_proba = nb.predict_proba(X_test_sel)[::, 1]\n\nfpr_train,tpr_train,threshold_train = roc_curve(y_train_sm,y_train_sm_proba )\nfpr_test,tpr_test,threshold_test = roc_curve(y_test,y_test_proba )\n\nprint(' GaussianNB :')\n\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.plot(fpr_train,fpr_train)\nplt.plot(fpr_train,tpr_train)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Train Data')\n\nplt.subplot(1,2,2)\nplt.plot(fpr_test,fpr_test)\nplt.plot(fpr_test,tpr_test)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Test Data')\nplt.show()","d3770893":"nb = GaussianNB()\n\nmodel_eval(nb, X_train_sm, X_test_sel, y_train_sm, y_test)\n\n#Recall is increased but the model is over fitted, so we cant consider this model","d9404cdb":"nb_classifier = GaussianNB()\n\n#default var_smoothing is 1e-09\n#We can try a range between 1e-0.15 to 1e-0.5\n\nparams_NB = {'var_smoothing': np.logspace(-5, -15, num=200)}\ngs_NB = GridSearchCV(estimator=nb_classifier, \n                 param_grid=params_NB, \n                 cv=3,   # use any cross validation technique \n                 verbose=1, \n                 scoring='accuracy') \ngs_NB.fit(X_full, y_full)","acfa253c":"#Best parameters\nprint(gs_NB.best_params_)","d8e112bf":"gnb = GaussianNB(**gs_NB.best_params_)\n\n#As we got better result on GaussianNB for data without SMOTE analysis, we will use the same dataset\nmodel_eval(gnb,  X_train_sel, X_test_sel, y_train, y_test)","df2780f5":"## Appending the evaluation metrics in a DataFrame for further reference\n## We can consider GaussianNB before hyper-parameter tuning\n\ngnb = GaussianNB()\n\nmodel_score_card(gnb, 'GaussianNB', X_train_sel, X_test_sel, y_train, y_test)","37b76510":"result_df","7db11777":"result_df.iloc[5]","31a65695":"nb = GaussianNB()\nnb.fit(X_train_sm, y_train_sm)\n    \n    #train datset\ny_train_sm_pred = nb.predict(X_train_sm)\ny_train_sm_proba = nb.predict_proba(X_train_sm)[::, 1]\n    \n    #test datset\ny_test_pred = nb.predict(X_test_sel)\ny_test_proba = nb.predict_proba(X_test_sel)[::, 1]\n\nfpr_train,tpr_train,threshold_train = roc_curve(y_train_sm,y_train_sm_proba )\nfpr_test,tpr_test,threshold_test = roc_curve(y_test,y_test_proba )\n\nprint(' GaussianNB :')\n\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.plot(fpr_train,fpr_train)\nplt.plot(fpr_train,tpr_train)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Train Data')\n\nplt.subplot(1,2,2)\nplt.plot(fpr_test,fpr_test)\nplt.plot(fpr_test,tpr_test)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('Test Data')\nplt.show()","0c41ef51":"from sklearn.inspection import permutation_importance","b34a23aa":"imps = permutation_importance(gnb, X_test_sel, y_test)\nprint(imps.importances_mean)\n\nfeatures = list(X_test_sel.columns)","584cfbeb":"# Print the feature ranking\nimportances = imps.importances_mean\nstd = imps.importances_std\nindices = np.argsort(importances)[::-1]\n\nprint(\"Feature ranking:\")\nfor f in range(X_test_sel.shape[1]):\n    print(\"%d. %s (%f)\" % (f + 1, features[indices[f]], importances[indices[f]]))","8e9a24e6":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(19, 8))\nplt.title(\"Feature importances\")\nplt.bar(range(X_test_sel.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(X_test_sel.shape[1]), [features[indices[i]] for i in range(9)])\nplt.xlim([-1, X_test_sel.shape[1]])\nplt.show()","8598f9b0":"#If we remove the less important features, then recall and AUC_score will be reduced","850c57dd":"## Statistical analysis for Categorical columns","dcecd145":"> ### 2.1 Data Transformation (Power transformation \/ Standard Scaler)","d470159c":"#### I have tried other models also and have updated only the model with best performances\n##### Other models tried :\n>Logistic Regression<br>\nLogistic Regression Data_transformed<br>\nLogistic Regression SMOTE<br>\nLogistic Regression RFE<br>\nDecisionTreeClassifier<br>\nDecisionTreeClassifier HP-tuning<br>\nRandomForestClassifier<br>\nRandomForestClassifier HP-tuning<br>\nKNeighborsClassifier<br>\nKNeighborsClassifier Hp-tuning<br>\nLGBMClassifier<br>\nLGBMClassifier HP-tuning<br>\nGaussianNB w\/o SMOTE<br>\nGradientBoostingClassifier<br>\nXGBoost<br>\nAdaBoost<br>\n","16f38d68":"## 3. Decision Tree Classifier\n>  3.1 Decision Tree Classifier<br>\n>  3.2 Decision Tree Classifier with Hyper-parameter tuning","ff041685":"## Train-Test split","cca98a19":">###  6.1 GaussianNB<br>","c93a64c8":"> ###  6.2 GaussianNB SMOTE analysis","2e5abf10":"For features :  'Age', 'Annual_Premium', 'Policy_Sales_Channel'<br>\n>pval = 0<br>\nsig lvl = 0.05<br>\npval < sig lvl<br>\nWe reject Null hypothesis\n###### There is a relation between ('Age', 'Annual_Premium', 'Policy_Sales_Channel) and 'Response'\n\nFor features : 'Region_Code', 'Vintage'\n>pval = 0.22, 0.26 (Region_Code and Vintage respectively)<br>\nsig lvl = 0.05<br>\npval > sig lvl<br>\nWe fail to reject Null hypothesis<br>\n######  'There is a no relation between (Region_code, Vintage) and Response'","4d3a79dc":"## Remove insignificant variable id","e836f16c":"# Statistical Analysis for feature important","2b5b0248":"### Feature importance","c37b8d80":">### 5.2 LGBMClassifier with Hyper-parameter tuning","3fbaf336":"## 5. LGBMClassifier\n>  5.1 LGBMClassifier<br>\n>  5.2 LGBMClassifier with Hyper-parameter tuning","f02c24c3":">### 4.2 Random forest Classifier with Hyper-parameter tuning","f9851a39":"For features : 'Gender', 'Driving_License', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage'\n>pval = 0<br>\nsig lvl = 0.05<br>\npval < sig lvl<br>\nWe reject Null hypothesis<br>\n\nThere is relationship between these ('Gender',  'Driving_License',  'Previously_Insured', 'Vehicle_Age',  'Vehicle_Damage') and 'RESPONSE' variable<br>\n##### Response (target variable) is dependent on all the categorical variable.\n\n#Except Region_Code and Vintage, Response is dependent on all other variables","c70c8eda":"For all the numerical features<br>\n>pval = 0<br>\nsig lvl = 0.05<br>\npval < sig lvl<br>\nWe reject Null hypothesis<br>\nNone of the Data is not normally distributed","23099c37":"##### This model is better fit compared to other models","1342a240":">### 3.2 Decision Tree Classifier with Hyper-parameter tuning","6c79abdc":"## Statistical analysis for Numerical columns","410e23db":"### Model evaluation metrics","1375457c":"## Duplicate records ","d6c7dded":"##### LGBMClassifier model results before and after hyper-parameter tuning is same, Model is slightly over-fit","56c6355c":"## Label encoding \/ One hot encoding","15a086c3":"##### Random Forest Classifier after hyper-parameter tuning is giving better results. It is better fit model compared to previous model\n##### Recall , F1-score, AUC score is increased compared to previous model.","67971fd0":"#### Test of Normality for numerical data (Shapiro test)","599506b5":"# Thank You","a9e704c1":"## 6. Naive Bayes\n>  6.1 GaussianNB<br>\n>  6.2 GaussianNB SMOTE analysis<br>\n>  6.3 GaussianNB Hyper-parameter Tuning<br>","6589174a":"#### Mannwhitneyu (non-parametric ttest)","799607cd":"#### Test for equality of variances (levene test)","0e3bb062":"##### There is no change in base model after Feature selection (RFE)","bdff3855":"##### Decision Tree Classifier after hyper-parameter tuning is giving better results. It is better fit model compared to previous model\n##### Recall , Precision , F1-score, AUC score is increased compared to previous model.","e472faa6":">### 4.1 Random forest Classifier","287e1662":"# Model building","a346a4a2":"## 2. Improving the base model (Logistic Regression):\n>2.1 Data Transformation (Power transformation \/ Standard Scaler)<br>\n2.2 Feature selection (Recursive Feature Elimination)<br>\n2.3 SMOTE analysis","3de99503":"## 1.Logistic Regression as a base model","8e22886d":"#                                                     Thank you","764def6f":"## 4. Random forest Classifier\n>  4.1 Random forest Classifier<br>\n>  4.2 Random forest Classifier with Hyper-parameter tuning","c383535e":"#### Please let me know, if i need to upload a notebook with these models.","1512bbec":">### 2.3 SMOTE analysis","68abbad2":"> ### 6.3 GaussianNB Hyper-parameter Tuning","165be842":">### 2.2 Feature selection (Recursive Feature Elimination)","5dcd718d":"##### GaussianNB model results before and after hyper-parameter tuning is same, Model is better fit to rest of the models","ea670091":"## Overall results of all the models built","d43ab7a5":">### 3.1 Decision Tree Classifier","fab0ccd6":"# Final model selected","c69161b2":"For features ==> 'Age', 'Region_Code', 'Annual_Premium', 'Policy_Sales_Channel'\n>   pval = 0<br>\n    sig lvl = 0.05<br>\n    pval < sig lvl<br>\n    We reject Null hypothesis\n Population variances are not equal<br>\n\nFor 'Vintage' Feature :\n>pval = 0.89<br>\nsig lvl = 0.05<br>\npval > sig lvl<br>\nWe fail to reject Null hypothesis <br>\nPopulation variances are equal","d2a5bd02":">### 5.1 LGBMClassifier","47b40fc2":"Even though there is huge change in Accuracy<br>\nRecall, Precision and F1-score has been increased<br>\nBut the model is Over-fitting","1250ad8a":"## Outlier treatment"}}