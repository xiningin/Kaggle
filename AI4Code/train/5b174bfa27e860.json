{"cell_type":{"58fee689":"code","8a584b60":"code","a76245bc":"code","075c452d":"code","7e9e2da8":"code","916cf2f1":"code","a2279523":"code","312f552e":"code","5d88aec8":"code","3f91562d":"code","946aee28":"code","9e823cc4":"code","cc886ea9":"code","25bcca88":"markdown","745379da":"markdown","fe0a35db":"markdown","237f983e":"markdown","3a6514e4":"markdown","f88efc9c":"markdown","6e80ed64":"markdown","f77462ec":"markdown","55c28fd3":"markdown","332863bc":"markdown","d093f634":"markdown","d622a5ab":"markdown","b4daebe1":"markdown","6e68f840":"markdown","aef97d37":"markdown","e3a99a2a":"markdown","148dc394":"markdown","3c54d58d":"markdown"},"source":{"58fee689":"# pandas for data processing\nimport pandas as pd\n\n# numpy for mathematical calculations\nimport numpy as np\n\n# matplotlib for visualization\nimport matplotlib.pyplot as plt","8a584b60":"# path of the dataset\npath = r'..\/input\/train.csv'\n\n# read the dataset\ndata = pd.read_csv(path)\nprint(\"Shape of the dataset = {}\".format(data.shape))\n\n# lets see first 5 rows of the dataset\ndata.head(5)","a76245bc":"# drop any rows with 'nan' values\ndata = data.dropna()\nprint(\"Shape of the dataset = {}\".format(data.shape))","075c452d":"# let's visualize the dataset\nplt.plot(data.x[0:500], data.y[0:500], 'x')\nplt.title(\"X vs Y\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")","7e9e2da8":"# training dataset and labels\ntrain_dataset = np.array(data.x[0:500]).reshape(500,1)\ntrain_labels  = np.array(data.y[0:500]).reshape(500,1)\n\n# valid dataset and labels\nvalid_dataset = np.array(data.x[500:700]).reshape(199,1)\nvalid_labels  = np.array(data.y[500:700]).reshape(199,1)\n\n# print the shapes\nprint(\"Train Dataset Shape = {}\".format(train_dataset.shape))\nprint(\"Train Labels  Shape = {}\".format(train_labels.shape))\nprint(\"Valid Dataset Shape = {}\".format(valid_dataset.shape))\nprint(\"Valid Labels  Shape = {}\".format(valid_labels.shape))","916cf2f1":"def forward_propagation(train_dataset, parameters):\n    w = parameters['w']\n    b = parameters['b']\n    predictions = np.multiply(w, train_dataset) + b\n    return predictions","a2279523":"def cost_function(predictions, train_labels):\n    cost = np.mean((train_labels - predictions) ** 2) * 0.5\n    return cost","312f552e":"def backward_propagation(train_dataset, train_labels, predictions):\n    derivatives = dict()\n    df = (train_labels - predictions) * -1\n    dw = np.mean(np.multiply(train_dataset, df))\n    db = np.mean(df)\n    derivatives['dw'] = dw\n    derivatives['db'] = db\n    return derivatives","5d88aec8":"def update_parameters(parameters, derivatives, learning_rate):\n    parameters['w'] = parameters['w'] - learning_rate * derivatives['dw']\n    parameters['b'] = parameters['b'] - learning_rate * derivatives['db']\n    return parameters","3f91562d":"def train(train_dataset, train_labels, learning_rate, iters = 10):\n    #random parameters\n    parameters = dict()\n    parameters[\"w\"] = np.random.uniform(0,1) * -1\n    parameters[\"b\"] = np.random.uniform(0,1) * -1\n    \n    plt.figure()\n    \n    #loss\n    loss = list()\n    \n    #iterate\n    for i in range(iters):\n        \n        #forward propagation\n        predictions = forward_propagation(train_dataset, parameters)\n        \n        #cost function\n        cost = cost_function(predictions, train_labels)\n        \n        #append loss and print\n        loss.append(cost)\n        print(\"Iteration = {}, Loss = {}\".format(i+1, cost))\n        \n        #plot function\n        plt.plot(train_dataset, train_labels, 'x')\n        plt.plot(train_dataset, predictions, 'o')\n        plt.show()\n        \n        #back propagation\n        derivatives = backward_propagation(train_dataset, train_labels, predictions)\n        \n        #update parameters\n        parameters = update_parameters(parameters, derivatives, learning_rate)\n        \n    return parameters, loss","946aee28":"parameters,loss = train(train_dataset, train_labels, 0.0001, 20)","9e823cc4":"valid_predictions = valid_dataset * parameters[\"w\"] + parameters[\"b\"]\nplt.figure()\nplt.plot(valid_dataset, valid_labels, 'x')\nplt.plot(valid_dataset, valid_predictions, 'o')\nplt.show()","cc886ea9":"#cost for valid dataset\ncost_function(valid_predictions, valid_labels)","25bcca88":"## Make Predictions for Valid Dataset","745379da":"### 1.4 Break into Train and Cross-Valid Set","fe0a35db":"## Gradient Descent for Backpropagation \n\nUsing Chain Rule:\n\nc = cost <br>\nf = f(x)\n\n* Partial Derivative of **cost function** w.r.t **w** <br>\ndc\/dw = dc\/df * df\/dw <br>\n* Partial Derivative of **cost function** w.r.t **b**<br>\ndc\/db = dc\/df * df\/db <br>\n\nPartial Derivatives:\n\n\n* dc\/df = (y - f) * -1\n* df\/dw = x\n* df\/db = 1\n","237f983e":"## Required Libraries","3a6514e4":"## Update the Parameters\n\n* w = w - (learning_rate * dw)\n* b = b - (learning_rate * db)","f88efc9c":"Equation for the function is:\n\nf(x) = w*x + b\n\nwhere **w** and **b** are the parameters we will learn through training.","6e80ed64":"### 1.3 Visualize the Data","f77462ec":"# Linear Regression with One Variable from Scratch","55c28fd3":"## Define Cost Function","332863bc":"### 1.2 Clean the data","d093f634":"## Problem Statement","d622a5ab":"Formulate a mathematical function f(x) which takes 'x' as input and predicts the correct value for 'y' according to the dataset given below. x and y are both floating point numbers.","b4daebe1":"## DataSet \n\nhttps:\/\/www.kaggle.com\/andonians\/random-linear-regression\/data","6e68f840":"### 1.1 Read the Data","aef97d37":"## Training","e3a99a2a":"Mean Squared Error\n\ncost = [(y - f(x)) ^ 2] * 0.5 \n\nwhere **y** are the actual or true labels and **f(x)** are the predicted values.","148dc394":"## Forward propagation","3c54d58d":"## Train the Data\n\nSequence of Steps:\n\n1. Forward Propagtaion\n2. Cost Function\n3. Backward Propagation\n4. Update Parameters"}}