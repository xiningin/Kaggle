{"cell_type":{"1b4f54c1":"code","cbb90627":"code","5b66f396":"code","b28681f4":"code","2febb98b":"code","672a50ab":"code","4037dc5a":"code","3c585245":"code","bfae4b39":"code","c31434bf":"code","7c1b30e1":"code","cea5231a":"code","72b9f506":"code","ebba7bd9":"code","3f5c2cdd":"code","4ddaaa01":"code","68bb8a62":"code","1a79aac1":"code","e6c10e46":"code","6d37d929":"code","3d428c32":"code","5cf6ea0e":"code","c4f5342e":"code","4335fc0e":"code","d9a3c826":"code","8e5b723b":"code","cc2c1589":"code","785c6222":"markdown","ae1ae333":"markdown","d178904f":"markdown","7bc1177c":"markdown","879f7eca":"markdown","5dd5f66e":"markdown","aac1e6f7":"markdown","84a762fb":"markdown","afbb3037":"markdown","21d77696":"markdown"},"source":{"1b4f54c1":"import pandas as pd \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier ","cbb90627":"dataset = pd.read_csv('..\/input\/mushroom-classification\/mushrooms.csv')\ndataset.head()","5b66f396":"dataset.columns","b28681f4":"dataset.info()","2febb98b":"encoding = LabelEncoder()\nfor i in dataset.columns:\n    dataset[i] = encoding.fit_transform(dataset[i])","672a50ab":"dataset.head()","4037dc5a":"dataset[\"stalk-root\"].value_counts()","3c585245":"dataset.corr()","bfae4b39":"dataset = dataset.drop('veil-type', axis=1)","c31434bf":"x = dataset.drop(['class'], axis=1)  #delete target column from train dataset\ny = dataset['class'] # test dataset  ","7c1b30e1":"# divide dataset into 65% train, and other 35% test.\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.35, random_state=0)","cea5231a":"dataset['class'].unique()","72b9f506":"classifier1 = KNeighborsClassifier(n_neighbors=2)\nclassifier1.fit(x_train, y_train)\n#Predicting the Test set results \ny_pred = classifier1.predict(x_test)\n#Making the confusion matrix \ncm = confusion_matrix(y_test,y_pred)\nprint(cm)","ebba7bd9":"sns.heatmap(cm, annot=True, linewidth=5, cbar=None)\nplt.title('KNN Classifier confusion matrix')\nplt.ylabel('True label')\nplt.xlabel('predicted label')","3f5c2cdd":"print('accuracy of train dataset is',classifier1.score(x_train, y_train))\nprint('accuracy of test dataset is',classifier1.score(x_test, y_test))","4ddaaa01":"classifier2 = SVC(kernel = 'linear', random_state = 0)\nclassifier2.fit(x_train, y_train)\n#Predicting the Test set results \ny_pred = classifier2.predict(x_test)\n#Making the confusion matrix \n#from sklearn.metrics import confusion_matrix \ncm = confusion_matrix(y_test,y_pred)\nprint(cm)","68bb8a62":"sns.heatmap(cm, annot=True, linewidth=5, cbar=None)\nplt.title('SVM with linear kernel Classifier confusion matrix')\nplt.ylabel('True label')\nplt.xlabel('predicted label')","1a79aac1":"print('accuracy of train dataset is',classifier2.score(x_train, y_train))\nprint('accuracy of test dataset is',classifier2.score(x_test, y_test))","e6c10e46":"classifier3 = SVC(kernel = 'rbf', random_state = 0)\nclassifier3.fit(x_train, y_train)\n#Predicting the Test set results \ny_pred = classifier3.predict(x_test)\n#Making the confusion matrix \n#from sklearn.metrics import confusion_matrix \ncm = confusion_matrix(y_test,y_pred)\nprint(cm)","6d37d929":"sns.heatmap(cm, annot=True, linewidth=5, cbar=None)\nplt.title('SVM with rbf kernel Classifier confusion matrix')\nplt.ylabel('True label')\nplt.xlabel('predicted label')","3d428c32":"print('accuracy of train dataset is',classifier3.score(x_train, y_train))\nprint('accuracy of test dataset is',classifier3.score(x_test, y_test))","5cf6ea0e":"classifier4 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier4.fit(x_train, y_train)\n#Predicting the Test set results \ny_pred = classifier4.predict(x_test)\n#Making the confusion matrix \n#from sklearn.metrics import confusion_matrix \ncm = confusion_matrix(y_test,y_pred)\nprint(cm)","c4f5342e":"sns.heatmap(cm, annot=True, linewidth=5, cbar=None)\nplt.title('Decision tree with entropy impurity confusion matrix')\nplt.ylabel('True label')\nplt.xlabel('predicted label')","4335fc0e":"print('accuracy of train dataset is',classifier4.score(x_train, y_train))\nprint('accuracy of test dataset is',classifier4.score(x_test, y_test))","d9a3c826":"classifier5 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier5.fit(x_train,y_train)\n#Predicting the Test set results \ny_pred = classifier5.predict(x_test)\n#Making the confusion matrix \n#from sklearn.metrics import confusion_matrix \ncm = confusion_matrix(y_test,y_pred)\nprint(cm)","8e5b723b":"sns.heatmap(cm, annot=True, linewidth=5, cbar=None)\nplt.title('RF with with entropy impurity Classifier confusion matrix')\nplt.ylabel('True label')\nplt.xlabel('predicted label')","cc2c1589":"print('accuracy of train dataset is',classifier5.score(x_train, y_train))\nprint('accuracy of test dataset is',classifier5.score(x_test, y_test))","785c6222":"**Feature Selection to do the Machine Learning Process**","ae1ae333":"3. SVM with rbf (radial basis function) kernel ","d178904f":"from the corr() function, we know that variable \"veil-type\" is not contributing into the other value in the dataset","7bc1177c":"5. Random Forest Classifier with entropy impurity ","879f7eca":"from the info() function, we know that there is no missing value in this dataset","5dd5f66e":"1. KNN (K - Nearest Neighbor)","aac1e6f7":"4. Decision Tree Classifier with entropy impurity ","84a762fb":"knowing the class that will be classified based on the data","afbb3037":"2. SVM with linear kernel","21d77696":"**Make the various classification for classifying the mushroom**"}}