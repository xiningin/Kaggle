{"cell_type":{"8bb38fcc":"code","86992bce":"code","04476070":"code","d18478b4":"code","1e4c160d":"code","1539ed97":"code","b93490d5":"code","04417b4b":"code","d452b685":"code","1cb56a86":"code","c352d390":"code","96f4b755":"code","e2bbe2bc":"code","4dcf6026":"code","cd5e5939":"code","1080bf99":"code","65a0607d":"code","b6b0d9f1":"code","7260bc49":"code","17aad125":"code","2dc551c4":"code","0454d7fd":"code","a5530287":"code","46ab31db":"code","24b495c8":"code","87fa63a0":"code","d6c28548":"code","d1a95f70":"markdown","c5783d3f":"markdown"},"source":{"8bb38fcc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# print(os.getcwd())\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n","86992bce":"!pip install nnAudio\n!pip install efficientnet","04476070":"\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras import Sequential, utils, optimizers, metrics\nimport tensorflow as tf\nimport tensorflow.keras.layers as layers\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom random import shuffle\nfrom nnAudio.Spectrogram import CQT1992v2\nimport torch\nfrom scipy import signal, fft\n# from tensorflow.keras.applications import EfficientNetB0\nfrom efficientnet.tfkeras import EfficientNetB0, EfficientNetB1\nimport math\nfrom scipy.interpolate import interp1d\nfrom scipy.signal import butter, lfilter\n\nTOP_INPUT_DIRECTORY = \"..\/input\/g2net-gravitational-wave-detection\"\nBATCH_SIZE = 256\nEPOCHS = 1\nEXAMPLE_IDENTIFIER_1 = \"00000e74ad\"\nEXAMPLE_IDENTIFIER_0 = \"00001f4945\"\nRANDOM_SAMPLE_SIZE = 1\nPERFORM_FITTING = True\nSAMPLING_FREQUENCY = 2048\nSAMPLES_1 = 4096\nSAMPLES_3 = 3 * SAMPLES_1\nUSE_TRAIN_SUBSET = False\nUSE_TEST_SUBSET = False\nSUBSET_SIZE = 1024\nLEARNING_RATE = 0.001\nTRAIN_TEST_SPLIT = 0.95\n\n\n\n# Utility functions\n\ndef make_array_cyclic(array):\n    \"\"\"Takes as input a 2d ndarray, and returns the same array but with the last\n    array copied to the front (so array [[0], [1], [2]] -> [[2], [0], [1], [2]]\n    This is so convolution layers can identifier features between measurements by\n    sensors 0 and 2.\"\"\"\n    last_array = array[-1, :]\n    reshaped_array = np.reshape(last_array, (1, last_array.shape[0]))\n    # print(reshaped_array.shape)\n    return np.insert(array, 0, reshaped_array, 0)\n\n\ndef get_array(identifier, is_training=True):\n    \"\"\"Eg. Given identifier \"00001f4945\", returns array loaded from\n    input\/train\/0\/0\/0\/00001f4945.npy. If is_training is False, use test instead\n    of train.\"\"\"\n    char0 = identifier[0]\n    char1 = identifier[1]\n    char2 = identifier[2]\n    if is_training:\n        path = f\"{TOP_INPUT_DIRECTORY}\/train\/{char0}\/{char1}\/{char2}\/{identifier}.npy\"\n    else:\n        path = f\"{TOP_INPUT_DIRECTORY}\/test\/{char0}\/{char1}\/{char2}\/{identifier}.npy\"\n    return np.load(path)\n\ndef get_array_n(identifier, is_training=True):\n    \"\"\"Return hstack of signal, each signal normalised before stack.\"\"\"\n    arr = get_array(identifier, is_training)\n    arr0 = arr[0]\n    arr0 = arr0 \/ np.max(arr0)\n    arr1 = arr[1]\n    arr1 = arr1 \/ np.max(arr1)\n    arr2 = arr[2]\n    arr2 = arr2 \/ np.max(arr2)\n    return np.hstack([arr0, arr1, arr2])","d18478b4":"# A look and feel of the data.\n\ntargets = pd.read_csv(f\"{TOP_INPUT_DIRECTORY}\/training_labels.csv\")\ny = targets[\"target\"].values\n\nall_identifiers = targets[\"id\"].values\nidentifiers_1 = targets[targets[\"target\"] == 1][\"id\"].values\nidentifiers_0 = targets[targets[\"target\"] == 0][\"id\"].values\n\n# Choose a random few samples with signal and no-signal.\nsample_ids_1 = np.random.choice(identifiers_1, RANDOM_SAMPLE_SIZE)\nprint(f\"\\nRandom samples with SIGNAL + NOISE: {sample_ids_1}\")\nsample_ids_0 = np.random.choice(identifiers_0, RANDOM_SAMPLE_SIZE)\nprint(f\"\\nRandom samples with ONLY NOISE: {sample_ids_0}\")\nprint(\"\\n\")\n\n","1e4c160d":"def plot_hstack(id, is_train=True):\n    plt.figure(figsize=(20,5))\n    plt.plot(np.hstack(get_array(id, is_train)))\n    plt.xlabel(\"sample\")\n    plt.ylabel(\"strain\")\n    plt.title(f\"hstack of data {id} - {targets[targets['id'] == id].target.values}\")\n\nfor id in sample_ids_1:\n    plot_hstack(id)\n    \nfor id in sample_ids_0:\n    plot_hstack(id)","1539ed97":"def plot_normalised_hstack(id, is_train=True):\n    plt.figure(figsize=(20,5))\n    plt.plot(get_array_n(id, is_train))\n    plt.xlabel(\"sample\")\n    plt.ylabel(\"normalised strain\")\n    plt.title(f\"hstack of normalised data {id} - {targets[targets['id'] == id].target.values}\")\n\nfor id in sample_ids_1:\n    plot_normalised_hstack(id)\n\nfor id in sample_ids_0:\n    plot_normalised_hstack(id)","b93490d5":"def plot_data_parallel(id, is_train=True):\n    data = get_array(id, is_train)\n    plt.figure(figsize=(20,5))\n    plt.plot(data[0], color=\"red\", label=\"Detector 0\")\n    plt.plot(data[1], color=\"green\", label=\"Detector 1\")\n    plt.plot(data[2], color=\"blue\", label=\"Detector 2\")\n    plt.xlabel(\"sample\")\n    plt.ylabel(\"strain (m)\")\n    plt.legend()\n    plt.title(f\"data of each detector {id} - {targets[targets['id'] == id].target.values}\")\n    \nfor id in sample_ids_1:\n    plot_data_parallel(id)\n\nfor id in sample_ids_0:\n    plot_data_parallel(id)","04417b4b":"def get_cqt_spectrogram(id, is_train=True):\n    cqt = CQT1992v2(sr=SAMPLING_FREQUENCY, hop_length=64, fmin=20, fmax=1024, bins_per_octave=12, norm=1, window='hann', center=True, pad_mode='reflect', trainable=False, output_format='Magnitude', verbose=False)\n#     cqt = CQT1992v2(sr=SAMPLING_FREQUENCY, fmin=20, fmax=1024, hop_length=64)\n    waveform = np.hstack(get_array(id, is_train))\n#     waveform = get_array_n(id, is_train)\n    waveform = waveform \/ np.max(waveform)\n    waveform = torch.from_numpy(waveform).float()\n    cqt_image = cqt(waveform)\n    cqt_image = np.array(cqt_image)\n#     cqt_image = np.squeeze(cqt_image, axis=0)\n    cqt_image = np.transpose(cqt_image, (1,2,0))\n    return cqt_image\n\ndef plot_cqt_spectrogram(id, is_train=True):\n    image = get_cqt_spectrogram(id, is_train)\n    plt.figure(figsize=(20,5))\n    plt.imshow(image)\n    plt.xlabel(\"scaled time\")\n    plt.ylabel(\"scaled frequency\")\n    plt.legend()\n    plt.title(f\"CQT1992 (nnAudio) spectrogram of hstack'd data {id} - {targets[targets['id'] == id].target.values}\")\n\ncqt_image = get_cqt_spectrogram(EXAMPLE_IDENTIFIER_1)\nprint(\"\")\nprint(f\"nnAudio CQT1992 spectrogram shape: {cqt_image.shape}\")\nprint(\"\")\n\nfor id in sample_ids_1:\n    plot_cqt_spectrogram(id)\n    \nfor id in sample_ids_0:\n    plot_cqt_spectrogram(id)","d452b685":"def get_scipy_spectrogram(id, is_train=True):\n    # Careful using in batch loader, as freq\/time axes values are returned also - repeated and complete waste.\n    waveform = np.hstack(get_array(id))\n    waveform = waveform \/ np.max(waveform)\n    (freq, time, intensity) = signal.spectrogram(waveform, SAMPLING_FREQUENCY, mode=\"magnitude\", scaling=\"spectrum\", window=('kaiser', 14))\n    return (freq, time, intensity)\n\ndef plot_scipy_spectrogram(id, is_train=True):\n    (f, t, i) = get_scipy_spectrogram(id, is_train)\n    plt.figure(figsize=(20,5))\n    plt.pcolormesh(t, f, i, shading='gouraud')\n    plt.ylabel('Frequency [Hz]')\n    plt.xlabel('Time [sec]')\n    plt.ylim(0,100)\n    plt.title(f\"Scipy spectrogram of hstack'd data {id} - {targets[targets['id'] == id].target.values}\")\n    plt.show()\n    \nfor id in sample_ids_1:\n    plot_scipy_spectrogram(id)\n    \nfor id in sample_ids_0:\n    plot_scipy_spectrogram(id)","1cb56a86":"def get_scipy_fft(id, is_train=True):\n    waveform = np.hstack(get_array(id))\n#     window = signal.kaiser(SAMPLES_3, 14)\n#     window = signal.blackman(SAMPLES_3)\n    window = signal.hann(SAMPLES_3)\n    return np.abs(fft.rfft(waveform * window))\n\ndef plot_scipy_fft(id, is_train=True):\n    fast = get_scipy_fft(id)\n    xf = fft.rfftfreq(SAMPLES_3, 1 \/ SAMPLING_FREQUENCY)\n    plt.figure(figsize=(20,5))\n#     plt.xlim(100, 300)\n    plt.yscale(\"log\")\n    plt.xlabel('frequency [Hz]')\n    plt.ylabel('Relative Amplitude')\n    plt.title(f\"Scipy rfft of hstack'd data {id} - {targets[targets['id'] == id].target.values}\")\n    plt.plot(xf, fast)\n\nfor id in sample_ids_1:\n    plot_scipy_fft(id)\n    \nfor id in sample_ids_0:\n    plot_scipy_fft(id)","c352d390":"def get_welch_periodogram(id, is_train=True):\n    f, Pxx_den = signal.welch(np.hstack(get_array(id)), SAMPLING_FREQUENCY, nperseg=1024)\n    return f, Pxx_den\n\ndef plot_welch_periodogram(id, is_train=True):\n    f, Pxx_den = get_welch_periodogram(id)\n    plt.figure(figsize=(20,5))\n    plt.semilogy(f, Pxx_den)\n    # plt.ylim([0.5e-3, 1])\n    plt.xlabel('frequency [Hz]')\n    plt.ylabel('PSD [V**2\/Hz]')\n    plt.title(f\"Scipy welch periodogram of hstack'd data {id} - {targets[targets['id'] == id].target.values}\")\n    plt.show()\n\nfor id in sample_ids_1:\n    plot_welch_periodogram(id)\n    \nfor id in sample_ids_0:\n    plot_welch_periodogram(id)","96f4b755":"def get_coherence(id, is_train=True):\n    \"\"\"Coherence between 2 signals (in this case 0\/1 - improve\/extend for all combos).\"\"\"\n    f0, Cxy0 = signal.coherence(get_array(id)[0], get_array(id)[1], SAMPLING_FREQUENCY, nperseg=1024)\n    f1, Cxy1 = signal.coherence(get_array(id)[1], get_array(id)[2], SAMPLING_FREQUENCY, nperseg=1024)\n    f2, Cxy2 = signal.coherence(get_array(id)[2], get_array(id)[0], SAMPLING_FREQUENCY, nperseg=1024)\n    return (f0, Cxy0, f1, Cxy1, f2, Cxy2)\n\ndef get_coherence_data(id, is_train=True):\n    f0, Cxy0, f1, Cxy1, f2, Cxy2 = get_coherence(id, is_train)\n    return np.vstack((Cxy0, Cxy1, Cxy2))\n\ndef plot_coherence(f, Cxy, detectors, colour):\n    plt.figure(figsize=(20,5))\n    plt.xlabel('frequency [Hz]')\n    plt.ylabel('Coherence')\n    plt.semilogy(f, Cxy, color=colour)\n    plt.title(f\"Scipy coherence plot between detectors {detectors} data {id} - {targets[targets['id'] == id].target.values}\")\n    plt.show()\n\ndef plot_all_coherences(id, is_train=True):\n    f0, Cxy0, f1, Cxy1, f2, Cxy2 = get_coherence(id)\n    plot_coherence(f0,Cxy0, \"0\/1\", \"red\")\n    plot_coherence(f1,Cxy1, \"1\/2\", \"green\")\n    plot_coherence(f2,Cxy2, \"2\/0\", \"blue\")\n\nfor id in sample_ids_1:\n    plot_all_coherences(id)\n\nfor id in sample_ids_0:\n    plot_all_coherences(id)","e2bbe2bc":"def get_correlation(id, is_train=True):\n    samples = get_array(id, is_train)\n    corr0 = signal.correlate(samples[0], samples[1])\n    lags0 = signal.correlation_lags(len(samples[0]), len(samples[1]))\n    corr0 \/= np.max(corr0)\n    \n    corr1 = signal.correlate(samples[1], samples[2])\n    lags1 = signal.correlation_lags(len(samples[1]), len(samples[2]))\n    corr1 \/= np.max(corr1)\n    \n    corr2 = signal.correlate(samples[2], samples[0])\n    lags2 = signal.correlation_lags(len(samples[2]), len(samples[0]))\n    corr2 \/= np.max(corr2)\n    return (lags0, corr0, lags1, corr1, lags2, corr2)\n\ndef get_correlation_data(id, is_train=True):\n    lags0, corr0, lags1, corr1, lags2, corr2 = get_correlation(id, is_train)\n    return np.vstack((corr0, corr1, corr2))\n\ndef plot_correlation(lags, corr, detectors, colour):\n    plt.figure(figsize=(20,5))\n    plt.title(f\"Scipy correlation plot between detectors {detectors} data {id} - {targets[targets['id'] == id].target.values}\")\n    plt.xlabel('Lag')\n    plt.ylabel('Correlation')\n    plt.plot(lags, corr, color=colour)\n\ndef plot_all_correlations(id, is_train=True):\n    lags0, corr0, lags1, corr1, lags2, corr2 = get_correlation(id, is_train)\n    plot_correlation(lags0, corr0, \"0\/1\", \"red\")\n    plot_correlation(lags1, corr1, \"1\/2\", \"green\")\n    plot_correlation(lags2, corr2, \"2\/0\", \"blue\")\n\nfor id in sample_ids_1:\n    plot_all_correlations(id)\n\nfor id in sample_ids_0:\n    plot_all_correlations(id)","4dcf6026":"# Whitening\ndef whiten(waveform):\n    \"\"\"Whitens a signal - fourier transform, divide by PSD, inverse fourier transform.\"\"\"\n    window = signal.hann(waveform.size)\n    spectrum = fft.fft(waveform * window)\n    mag = np.sqrt(np.real(spectrum*np.conj(spectrum)))\n    return np.real(fft.ifft(spectrum\/mag)) * np.sqrt(len(waveform)\/2)\n\n\ndef get_whitened_data(id, detector, is_train=True):\n    return whiten(get_array(id, is_train)[detector])\n\ndef plot_whitened_data(data, detector, colour):\n    plt.figure(figsize=(20,5))\n    plt.title(f\"Whitened detector {detector} data {id} - {targets[targets['id'] == id].target.values}\")\n    plt.xlabel('Scaled time')\n    plt.ylabel('Whitened scaled strain')\n    plt.plot(data, color=colour)\n    \ndef plot_all_whitened_data(id, is_train=True):\n    whitened_data0 = get_whitened_data(id, 0, is_train)\n    whitened_data1 = get_whitened_data(id, 1, is_train)\n    whitened_data2 = get_whitened_data(id, 2, is_train)\n\n    plot_whitened_data(whitened_data0,\"0\", \"red\")\n    plot_whitened_data(whitened_data1,\"1\", \"green\")\n    plot_whitened_data(whitened_data2,\"2\", \"blue\")\n\nfor id in sample_ids_1:\n    plot_all_whitened_data(id)\n\nfor id in sample_ids_0:\n    plot_all_whitened_data(id)","cd5e5939":"# Bandpass filtering (+ whitening)\ndef butter_bandpass(lowcut, highcut, fs, order=5):\n    nyq = 0.5 * fs\n    low = lowcut \/ nyq\n    high = highcut \/ nyq\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\n\ndef butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n    y = lfilter(b, a, data)\n    return y\n\ndef get_cqt_spectrogram_of_data(data):\n    cqt = CQT1992v2(sr=SAMPLING_FREQUENCY, hop_length=64, fmin=20, fmax=1024, bins_per_octave=12, norm=1, window='hann', center=True, pad_mode='reflect', trainable=False, output_format='Magnitude', verbose=False)\n#     cqt = CQT1992v2(sr=SAMPLING_FREQUENCY, fmin=20, fmax=1024, hop_length=64)\n    waveform = data\n    waveform = waveform \/ np.max(waveform)\n    waveform = torch.from_numpy(waveform).float()\n    cqt_image = cqt(waveform)\n    cqt_image = np.array(cqt_image)\n#     cqt_image = np.squeeze(cqt_image, axis=0)\n    cqt_image = np.transpose(cqt_image, (1,2,0))\n    return cqt_image\n\ndef plot_cqt_spectrogram_of_data(data, detector):\n    image = get_cqt_spectrogram_of_data(data)\n    plt.figure(figsize=(20,5))\n    plt.imshow(image)\n    plt.xlabel(\"scaled time\")\n    plt.ylabel(\"scaled frequency\")\n    plt.title(f\"CQT1992 (nnAudio) spectrogram of detector {detector} data {id}\")\n    \ndef plot_all_whitened_bandpassed_spectrograms(id, lowcut=50, highcut=500, is_train=True):\n    whitened_data0 = get_whitened_data(id, 0, is_train)\n    whitened_data1 = get_whitened_data(id, 1, is_train)\n    whitened_data2 = get_whitened_data(id, 2, is_train)\n\n    bandpassed_data0 = butter_bandpass_filter(whitened_data0, lowcut, highcut, whitened_data0.size)\n    bandpassed_data1 = butter_bandpass_filter(whitened_data1, lowcut, highcut, whitened_data1.size)\n    bandpassed_data2 = butter_bandpass_filter(whitened_data2, lowcut, highcut, whitened_data2.size)\n    \n    plot_cqt_spectrogram_of_data(bandpassed_data0,\"0\")\n    plot_cqt_spectrogram_of_data(bandpassed_data1,\"1\")\n    plot_cqt_spectrogram_of_data(bandpassed_data2,\"2\")\n\nfor id in sample_ids_1:\n    plot_all_whitened_bandpassed_spectrograms(id)\n\nfor id in sample_ids_0:\n    plot_all_whitened_bandpassed_spectrograms(id)","1080bf99":"# Shapes of some of the data considered.\n\narr = get_array(EXAMPLE_IDENTIFIER_1)\nprint(\"\\n\")\nprint(f\"Shape of array.shape: {arr.shape}\")\nprint(f\"Shape of array[0].shape: {arr[0].shape}\")\nprint(f\"Shape of np.hstack(array).shape: {np.hstack(arr).shape}\")\nprint(f\"Shape of np.vstack(array).shape: {np.vstack(arr).shape}\")\nprint(\"\\n\")\n(f, t, i) = get_scipy_spectrogram(EXAMPLE_IDENTIFIER_1)\nprint(f\"Shape of scipy spectrogram (get_scipy_spectrogram) time (t of f,t,i): {t.shape}\")\nprint(f\"Shape of scipy spectrogram (get_scipy_spectrogram) frequency (f of f,t,i): {f.shape}\")\nprint(f\"Shape of scipy spectrogram (get_scipy_spectrogram) intensity (i=(f,t) of f,t,i): {i.shape}\")\nprint(f\"Shape of nnAudio CQT1992 spectrogram (get_cqt_spectrogram) (t, f): {get_cqt_spectrogram(EXAMPLE_IDENTIFIER_1).shape}\")\nprint(f\"Shape of Coherence data (get_coherence_data) shape: {get_coherence_data(EXAMPLE_IDENTIFIER_1).shape}\")\nprint(f\"Shape of Correlation data (get_correlation_data) shape: {get_correlation_data(EXAMPLE_IDENTIFIER_1).shape}\")\n\n","65a0607d":"# General Dataset generator, to be extended with specific implementations of fetching sample\/batch\n\nclass DataSetGenerator(Sequence):\n    \"\"\"Allows batch-loading of the ~50GB training data so we don't exhaust RAM.\"\"\"\n\n    def get_sample(self, id, is_train):\n        \"\"\"Needs to be implemented by child.\"\"\"\n        pass\n    \n    def __init__(self, identifiers, y=None, batch_size=256,\n        shuffle=True, no_channels=1, no_classes=10, name=\"Unknown DataSet\"):\n        \"\"\"Provided custom parameters for DataGenerator. At minimum, input an array\n        of identifiers. If training, input the targets values also.\"\"\"\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.identifiers = identifiers\n        self.y = y\n        self.name = name\n        if y is not None:\n            self.is_training = True\n        else:\n            self.is_training = False\n        self.shape = self.get_sample(self.identifiers[0], self.is_training).shape\n        print(f\"{self.name} - Shape of each sample: {self.shape}\\n\")\n#         self.on_epoch_end()\n\n    def __len__(self):\n        \"\"\"States number of batches per epoch (rounds up).\"\"\"\n#         return int(np.ceil(len(self.identifiers) \/ self.batch_size))\n        return math.ceil(len(self.identifiers)\/self.batch_size)\n\n    def __getitem__(self, index):\n        \"\"\"Return batch of X (and y if training). Can be overidden in child if model input shape requires.\"\"\"\n        batch_ids = self.identifiers[index * self.batch_size:(index + 1) * self.batch_size]\n        if self.y is not None:\n            batch_y = self.y[index * self.batch_size: (index + 1) * self.batch_size]\n        \n        # batch_X = np.array([get_array(x, self.is_training) for x in batch_ids])\n        list_x = np.array([self.get_sample(x, self.is_training) for x in batch_ids])\n#         batch_X = batch_X.reshape((batch_X.shape[0], batch_X.shape[1], batch_X.shape[2], 1))\n        batch_X = np.stack(list_x)\n#         batch_X = batch_X.reshape((batch_X.shape[0], batch_X.shape[1], batch_X.shape[2], 1))\n        # batch_X = np.stack(list_x)\n        if self.is_training:\n            return batch_X, batch_y\n        else:\n            return batch_X\n\n    def on_epoch_end(self):\n        \"\"\"Shuffle at the end of each epoch.\"\"\"\n        pass\n        if self.shuffle and self.is_training:\n            ids_y = list(zip(self.identifiers, self.y))\n            shuffle(ids_y)\n            self.identifiers, self.y = list(zip(*ids_y))","b6b0d9f1":"class TimeSeriesDataSetGenerator(DataSetGenerator):\n    \"\"\"Inherits from DataSetGenerator class, methods to get sample and therefore batch are implemented, simply\n    fetching the raw samples of 3x4096 ndarrays.\"\"\"\n    \n    def get_sample(self, id, is_train):\n        \"\"\"Return 3x4096 ndarray (time-series data).\"\"\"\n        return make_array_cyclic(get_array(id, is_train))\n    ","7260bc49":"class Cqt1992DataSetGenerator(DataSetGenerator):\n    \"\"\"Inherits from DataSetGenerator class, methods to get sample and therefore batch are implemented, fetches\n    CQT1992 spectrogram of the hstack'd arrays.\"\"\"\n    \n    def get_sample(self, id, is_train):\n        \"\"\"Return CQT1992 spectrogram.\"\"\"\n        return get_cqt_spectrogram(id, is_train)\n    \n    def __getitem__(self, index):\n        \"\"\"Return batch of X (and y if training). Can be overidden in child if model input shape requires.\"\"\"\n        batch_ids = self.identifiers[index * self.batch_size:(index + 1) * self.batch_size]\n        if self.y is not None:\n            batch_y = self.y[index * self.batch_size: (index + 1) * self.batch_size]\n\n        # batch_X = np.array([get_array(x, self.is_training) for x in batch_ids])\n        list_x = np.array([self.get_sample(x, self.is_training) for x in batch_ids])\n        # batch_X = batch_X.reshape((batch_X.shape[0], batch_X.shape[1], batch_X.shape[2], 1))\n        batch_X = np.stack(list_x)\n#         batch_X = batch_X.reshape((batch_X.shape[0], batch_X.shape[1], batch_X.shape[2], 1))\n\n        # batch_X = np.stack(list_x)\n        if self.is_training:\n            return batch_X, batch_y\n        else:\n            return batch_X","17aad125":"def get_basic_cnn_model(shape):\n    \"\"\"Returns compiled model (callbacks, history, fitting etc not done here).\"\"\"\n#     # detect and init the TPU\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n#     # instantiate a distribution strategy\n#     tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n#     # instantiating the model in the strategy scope creates the model on the TPU\n#     with tpu_strategy.scope():\n    model = Sequential([\n        layers.InputLayer(input_shape=(shape[0], shape[1], 1), name=\"Input\"),\n        layers.Conv2D(3, (2,1024), strides=(1,512), padding='same', name=\"Conv2D_1\"),\n        layers.MaxPooling2D(pool_size=(2,4), strides=(1, 2), padding='valid', name=\"MaxPooling_1\"),\n#         layers.Conv2D(64, 3, activation='relu', padding='same', name=\"Conv2D_2\"),\n#         layers.MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='valid', name=\"MaxPooling_2\"),\n#         layers.GlobalAveragePooling2D(name=\"GlobalAveragePooling_1\"),\n        layers.Flatten(),\n        layers.Dense(32, activation='relu', name=\"Dense_1\"),\n        layers.Dense(1, activation='sigmoid', name=\"Dense_2\")\n    ])\n    \n    # Print summary of model layers.\n    model.summary()\n    # Draw diagram of model\n    # utils.plot_model(model, to_file=\"model.png\", show_shapes=True)\n    model.compile(optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n                  loss='binary_crossentropy',\n                  metrics=[metrics.AUC()])\n    return model","2dc551c4":"def get_cqt1992_model(shape):\n    \"\"\"Returns compiled model (callbacks, history, fitting etc not done here).\"\"\"\n    # Build model layers.\n    model = Sequential([\n        layers.InputLayer(input_shape=(shape[0],shape[1],1)),\n        layers.Conv2D(3,3,activation='relu',padding='same'),\n#         EfficientNetB0(include_top=False,input_shape=(),weights='imagenet'),\n        EfficientNetB1(include_top=False,input_shape=(),weights='imagenet'),\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(32,activation='relu'),\n        layers.Dense(1, activation='sigmoid')\n    ])\n    \n    # Print summary of model layers.\n    model.summary()\n    \n    # Draw diagram of model\n    # utils.plot_model(model, to_file=\"model.png\", show_shapes=True)\n    \n    # Compile with specific optimizer \/ loss \/ metric.\n    model.compile(optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n                  loss='binary_crossentropy',\n                  metrics=[metrics.AUC()])\n    return model","0454d7fd":"def get_model_template(shape):\n    \"\"\"Returns compiled model (callbacks, history, fitting etc not done here).\"\"\"\n    # Build model layers.\n    model = Sequential([\n        layers.InputLayer(input_shape=(shape[0], shape[1], 1), name=\"Input\"),\n        layers.Conv2D(3, (2,1024), strides=(1,512), padding='same', name=\"Conv2D_1\"),\n        # layers.BatchNormalization(),\n        # layers.ReLU(),\n        layers.MaxPooling2D(pool_size=(2,4), strides=(1, 2), padding='valid', name=\"MaxPooling_1\"),\n        layers.Flatten(),\n        layers.Dense(32, activation='relu', name=\"Dense_1\"),\n        layers.Dense(1, activation='sigmoid', name=\"Dense_2\")\n        # layers.Dense(1, activation='softmax', name=\"Dense_1\")\n    ])\n    \n    # Print summary of model layers.\n    model.summary()\n    \n    # Draw diagram of model\n    # utils.plot_model(model, to_file=\"model.png\", show_shapes=True)\n    \n    # Compile with specific optimizer \/ loss \/ metric.\n#     model.compile(optimizer=optimizers.Adam(learning_rate=0.01),\n    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=[metrics.AUC()])\n    return model","a5530287":"# Set up DataSetGenerator and get model\n\ntargets = pd.read_csv(f\"{TOP_INPUT_DIRECTORY}\/training_labels.csv\")\nsample_submission = pd.read_csv(f\"{TOP_INPUT_DIRECTORY}\/sample_submission.csv\")\n\nif USE_TRAIN_SUBSET:\n    targets = targets.sample(SUBSET_SIZE)\n    \nif USE_TEST_SUBSET:\n    sample_submission = sample_submission.sample(SUBSET_SIZE)\n\ntest_identifiers = sample_submission[\"id\"].values\nidentifiers = targets[\"id\"].values\ny = targets[\"target\"].values\n\n# print(identifiers[:5])\n# print(y[:5])\n# print(test_identifiers[:5])\n\ntrain_x, valid_x, train_y, valid_y = train_test_split(identifiers, y, train_size=TRAIN_TEST_SPLIT, random_state=42, stratify=y)\n\n\n\n# train_dataset = TimeSeriesDataSetGenerator(train_x, train_y, batch_size=BATCH_SIZE, name=\"Training\")\n# valid_dataset = TimeSeriesDataSetGenerator(valid_x, valid_y, batch_size=BATCH_SIZE, name=\"Validation\")\n# test_dataset = TimeSeriesDataSetGenerator(test_identifiers, batch_size=BATCH_SIZE, name=\"Test\")\n\ntrain_dataset = Cqt1992DataSetGenerator(train_x, train_y, batch_size=BATCH_SIZE, name=\"Training\")\nvalid_dataset = Cqt1992DataSetGenerator(valid_x, valid_y, batch_size=BATCH_SIZE, name=\"Validation\")\ntest_dataset = Cqt1992DataSetGenerator(test_identifiers, batch_size=BATCH_SIZE, name=\"Test\")\n\nassert train_dataset.shape == valid_dataset.shape == test_dataset.shape\n\n# Get shape from chosen DataSet, and input to model.\nsample_shape = train_dataset.shape\n# print(sample_shape)\nprint(\"\\n\\n\\n\")\nmodel = get_cqt1992_model(sample_shape)\n\n\n\n# Add extras like callbacks to model, and fit.\n\n# Model callbacks\/fitting etc specifics\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\n        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=\"val_loss\", factor=0.5, patience=2, min_lr=0.001\n    ),\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, verbose=1),\n]\n","46ab31db":"if PERFORM_FITTING:\n    # Fit model (obtaining history for later plotting).\n#     history = model.fit(\n    model.fit(\n        train_dataset,\n        validation_data=valid_dataset,\n        epochs=EPOCHS,\n    #     callbacks=callbacks,\n        # validation_split=0.2,\n        verbose=1,\n    )\n\n","24b495c8":"# if PERFORM_FITTING:\n#     # Plot model performance - sort out what key to use (\"auc\") sometimes not available ...\n#     # model = tf.keras.models.load_model(\"best_model.h5\")\n# #     metric = \"auc\"\n# #     plt.figure()\n# #     plt.plot(history.history[metric])\n# #     plt.plot(history.history[\"val_\" + metric])\n# #     plt.title(\"model \" + metric)\n# #     plt.ylabel(metric, fontsize=\"large\")\n# #     plt.xlabel(\"epoch\", fontsize=\"large\")\n# #     plt.legend([\"train\", \"val\"], loc=\"best\")\n# #     plt.show()\n# #     plt.close()\n\n","87fa63a0":"if PERFORM_FITTING:\n    # Use model to make predicitions and submit.\n    preds = model.predict(\n        test_dataset,\n        verbose=1\n    )\n    df = pd.DataFrame({'id': sample_submission['id'], 'target': preds.reshape(-1)})\n    print(df.head(50))\n    df.to_csv(\"submission.csv\", index=False)\n    \n","d6c28548":"# Test ....\n\n# !pip install nnAudio\n# !pip install efficientnet\n\n# import numpy as np\n# import matplotlib.pyplot as plt\n# import scipy.signal as sig\n# from scipy.signal import butter,lfilter\n# from scipy.fft import fft,ifft\n# import pandas as pd\n# import os\n# import glob\n# import seaborn as sns\n# import tensorflow as tf\n# from tensorflow.keras.models import Sequential, Model\n# from tensorflow.keras.utils import to_categorical\n# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n# from sklearn.model_selection import train_test_split\n# from sklearn.svm import SVC\n# from sklearn.calibration import CalibratedClassifierCV\n# import datetime\n# import time\n# #from tensorflow.keras.applications import EfficientNetB0\n# from efficientnet.keras import EfficientNetB0\n# import torch\n# from tensorflow.keras.utils import Sequence\n# import math\n# from random import shuffle\n# import tensorflow.keras.layers as L\n# import pywt\n\n# def get_path(id_no,is_train=True):\n#     file_path = \"..\/input\/g2net-gravitational-wave-detection\/{}\/{}\/{}\/{}\/{}.npy\"\n#     if is_train:\n#         path = file_path.format('train',id_no[0],id_no[1],id_no[2],id_no)\n#     else:\n#         path = file_path.format('test',id_no[0],id_no[1],id_no[2],id_no)\n#     return path    \n\n# def get_spectrogram(idx,is_train,transform=CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=64)): # in order to use efficientnet we need 3 dimension images\n#     waves = np.load(get_path(idx,is_train))\n#     waves = np.hstack(waves)\n#     waves = waves \/ np.max(waves)\n#     waves = torch.from_numpy(waves).float()\n#     image = transform(waves)\n#     image = np.array(image)\n#     image = np.transpose(image,(1,2,0))\n#     #image = np.array(get_scalogram(idx,is_train))\n#     return image\n\n# class G2Dataset(Sequence):\n#     def __init__(self,idx,y=None,batch_size=256,shuffle=True):\n#         self.idx = idx\n#         self.batch_size = batch_size\n#         self.shuffle = shuffle\n#         if y is not None:\n#             self.is_train=True\n#         else:\n#             self.is_train=False\n#         self.y = y\n#     def __len__(self):\n#         return math.ceil(len(self.idx)\/self.batch_size)\n#     def __getitem__(self,ids):\n#         batch_ids = self.idx[ids * self.batch_size:(ids + 1) * self.batch_size]\n#         if self.y is not None:\n#             batch_y = self.y[ids * self.batch_size: (ids + 1) * self.batch_size]\n            \n#         list_x = np.array([get_spectrogram(x,self.is_train) for x in batch_ids])\n#         batch_X = np.stack(list_x)\n#         if self.is_train:\n#             return batch_X, batch_y\n#         else:\n#             return batch_X\n    \n#     def on_epoch_end(self):\n#         if self.shuffle and self.is_train:\n#             ids_y = list(zip(self.idx, self.y))\n\n# samples = targets#.sample(20000)\n# train_idx =  samples['id'].values\n# y = samples['target'].values\n# test_idx = sample_submission['id'].values\n# x_train,x_valid,y_train,y_valid = train_test_split(train_idx,y,test_size=0.05,random_state=42,stratify=y)\n\n# train_dataset = G2Dataset(x_train,y_train)\n# valid_dataset = G2Dataset(x_valid,y_valid)\n# test_dataset = G2Dataset(test_idx)\n\n# model = get_model((69,193))\n\n# model.fit(train_dataset,\n#           epochs=1,\n#           validation_data=valid_dataset)\n\n# preds = model.predict(test_dataset)\n\n# df = pd.DataFrame({'id':sample_submission['id'],'target':preds.reshape(-1)})\n# df.to_csv('submission.csv',index=False)","d1a95f70":"To summarise so far, no signal \"jumps out\" to the naked eye, by considering various time-domain \/ frequency-domain plots. This highlights the non-trivial nature of this data science problem.","c5783d3f":"Spectrograms of the hstack'd data. Obvious peaks at 1\/3 and 2\/3 of the total time due to discontinuity between detector data."}}