{"cell_type":{"50289192":"code","8dd749fa":"code","36f6ef48":"code","47393ad8":"code","8d33ce77":"code","d4b4ba74":"code","1a8c5c0a":"code","9d540ad3":"code","23942b43":"code","e8a1e043":"code","78550e4b":"code","fef0f697":"code","1aadae57":"code","e07ec323":"code","80188e67":"code","729803ad":"markdown","a1fb0392":"markdown","3d02395f":"markdown","98bbb315":"markdown","a8a5fcac":"markdown","8351e77b":"markdown","05979f92":"markdown","e3e1eea2":"markdown","2d16f347":"markdown","1b420cb3":"markdown","33b73cf4":"markdown","1d9bead0":"markdown","5e77166c":"markdown","e2f0eb8a":"markdown","834474f7":"markdown","c0404102":"markdown","467e8b3a":"markdown","620d4373":"markdown"},"source":{"50289192":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms  \nimport torchvision\nimport os\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport cv2\nimport pandas as pd\nimport torchvision.transforms as transforms \nfrom torchvision.transforms import ToTensor,Normalize, RandomHorizontalFlip, Resize\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.autograd import Variable","8dd749fa":"data_dir_Train = \"\/kaggle\/input\/intel-image-classification\/seg_train\"\ndata_dir_Test = \"\/kaggle\/input\/intel-image-classification\/seg_test\"\ndata_dir_pred = \"\/kaggle\/input\/intel-image-classification\/seg_pred\/seg_pred\"\n\ntrain_dir = data_dir_Train + \"\/seg_train\"\nvalid_dir = data_dir_Test + \"\/seg_test\/\"\npred_files = [os.path.join(data_dir_pred, f) for f in os.listdir(data_dir_pred)]\n\noutcomes = os.listdir(train_dir)","36f6ef48":"# printing the all outcomes\nprint(outcomes)","47393ad8":"# convert data to a normalized torch.FloatTensor\ntransform = torchvision.transforms.Compose([\n    transforms.Resize((150,150)),\n    transforms.RandomHorizontalFlip(p=0.5), # randomly flip and rotate\n    transforms.ColorJitter(0.3,0.4,0.4,0.2),\n    transforms.ToTensor(),\n    transforms.Normalize((0.425, 0.415, 0.405), (0.205, 0.205, 0.205))\n    ])\n\n# Augmentation on test images not needed\ntransform_tests = torchvision.transforms.Compose([\n    transforms.Resize((150,150)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.425, 0.415, 0.405), (0.255, 0.245, 0.235))\n    ])","8d33ce77":"# ImageFloder function uses for make dataset by passing dir adderess as an argument\ntrain_data = torchvision.datasets.ImageFolder(root=train_dir,transform=transform)\ntest_data = torchvision.datasets.ImageFolder(root=valid_dir,transform=transform_tests)\n\n\nvalid_size = 0.15\n# Splot data into train and validation set\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)","d4b4ba74":"train_loader = DataLoader(train_data,batch_size=50,sampler=train_sampler,num_workers=2)\nvalid_loader = DataLoader(train_data, batch_size =100, sampler=valid_sampler, num_workers=3)\ntest_loader= DataLoader(test_data,batch_size=32,shuffle=False,num_workers=2)","1a8c5c0a":"# check if cuda is available\ntrain_on_gpu = torch.cuda.is_available()\n\ndevice =  torch.device('cuda' if torch.cuda.is_available else 'cpu')","9d540ad3":"# We will using wide_resnet50_2 for this you can use any model you want\nimport torchvision\nmodel = torchvision.models.wide_resnet50_2(pretrained=True)\n\nfor param in model.parameters():\n    param.required_grad = False\n\n\nnum_ftrt = model.fc.in_features\n\nmodel.fc = nn.Linear(num_ftrt,6)\nmodel.to(device)\nmodel\n","23942b43":"# Specify loss function and optimizer\nimport torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,6], gamma=0.06)","e8a1e043":"# number of epochs for training set\nepochs = 7\n\n# track change in validation loss\nvalid_loss_min = np.Inf\nval_loss = []\ntn_loss = []\nfor epoch in range(1,epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n\n    # Train the model\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):       \n        # move tensor to gpu if cuda is available\n        if train_on_gpu:\n            data, target = data.to(device), target.to(device)\n        # clear the gradiant of all optimizer variable\n        optimizer.zero_grad()\n        # forward pass: compute pradictions by passing inputs\n        output = model(data)\n        # calculate batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradiant of the loss with respect to the parameters\n        loss.backward()\n        # update parameters by optimizing single step\n        optimizer.step()\n        \n        # update training loss\n        train_loss += loss.item()*data.size(0)\n\n    # validate the model\n\n    model.eval()\n    for batch_idx, (data, target) in enumerate(valid_loader):\n        # move tensor to gpu\n        if train_on_gpu:\n            data, target = data.to(device), target.to(device)\n        # forward pass: compute the validation predictions\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update the validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average loss\n    train_loss = train_loss\/len(train_loader.sampler)\n    valid_loss = valid_loss\/len(valid_loader.sampler)\n    val_loss.append(valid_loss)\n    tn_loss.append(train_loss)\n    # update learning rate\n    scheduler.step()\n    # Print the train and validation loss statistic\n    print('Epoch: {} \\t Training Loss: {:.3f} \\t Validation Loss: {:.3f}'.format(epoch, train_loss, valid_loss))\n    \n    # save model if validation loss decrease\n    if valid_loss <= valid_loss_min:\n        print(\"Validation loss decreased {:.4f}--->{:.4f}  Saving model...\".format(valid_loss_min, valid_loss))\n        # save current model\n        torch.save(model.state_dict(), 'model_state.pt')\n        valid_loss_min = valid_loss\n    print('Learning Rate ------------->{:.4f}'.format(optimizer.state_dict()['param_groups'][0]['lr']))","78550e4b":"plt.plot(tn_loss, label='Training loss')\nplt.plot(val_loss, label='Validation loss')\nplt.legend(frameon=False)\n\n\nplt.show()\n\n","fef0f697":"# Load model state dict\nmodel.load_state_dict(torch.load('model_state.pt'))\nmodel.eval()\nmodel.cuda()","1aadae57":"correct_count, all_count = 0,0\nfor images, labels in test_loader:\n    for i in range(len(labels)):\n        if torch.cuda.is_available():\n            images = images.cuda()\n            labels = labels.cuda()\n        img = images[i].view(1,3,150,150)\n        with torch.no_grad():\n            logps = model(img)\n            \n        ps = torch.exp(logps)\n        probab = list(ps.cpu()[0])\n        pred_label = probab.index(max(probab))\n        true_label = labels.cpu()[i]\n        if(true_label == pred_label):\n            correct_count += 1\n        all_count += 1\n        \nprint(\"Number of images Tested=\", all_count)\nprint(\"\\n Model Accuracy=\",(correct_count\/all_count)*100)","e07ec323":"def pred_class(img):\n    # transform images\n    img_tens = transform_tests(img)\n    # change image format (3,150,150) to (1,3,150,150) by help of unsqueeze function\n    # image needs to be in cuda before predition\n    img_im = img_tens.unsqueeze(0).cuda() \n    uinput = Variable(img_im)\n    uinput = uinput.to(device)\n    out = model(uinput)\n    # convert image to numpy format in cpu and snatching max prediction score class index\n    index = out.data.cpu().numpy().argmax()    \n    return index","80188e67":"# make class dictionary so i can grab class name by index(key)\nclasses = {k:v for k , v in enumerate(sorted(outcomes))}\nmodel.eval()\n\n\nplt.figure(figsize=(20,20))\nfor i, images in enumerate(pred_files):\n    # just want 25 images to print\n    if i > 24:break\n    img = Image.open(images)\n    index = pred_class(img)\n    plt.subplot(5,5,i+1)\n    plt.title(classes[index])\n    plt.axis('off')\n    plt.imshow(img)","729803ad":"-------","a1fb0392":"----","3d02395f":"--------","98bbb315":"# Train model","a8a5fcac":"# Load saved parameters ","8351e77b":"# Consider a upvote if you have come this far..","05979f92":"# Using pretrained model.","e3e1eea2":"---","2d16f347":"# Predictions on test dataset","1b420cb3":"----","33b73cf4":"# Table of content\n\n*  Import utilities.\n\n*  [Augmentation](#Augmentation).\n\n*  [Using pretrained model](#Using-pretrained-model.).\n\n* [Train the parameters for our model](#Train-model).\n\n* [Plot graph between training loss and validation loss](#Plot-graph-between-training-loss-and-validation-loss)\n\n* [Load saved parameters](#Load-saved-parameters).\n\n* [Image Predictions](#Image-Predictions)","1d9bead0":"![Upvote](https:\/\/tenor.com\/view\/the-end-end-waving-bye-goodbye-gif-16288632.gif)","5e77166c":"---","e2f0eb8a":"# Image Predictions","834474f7":"# Plot graph between training loss and validation loss","c0404102":"----","467e8b3a":"## Import utilities","620d4373":"# Augmentation"}}