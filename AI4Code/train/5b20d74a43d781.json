{"cell_type":{"b1c24884":"code","b1075d9a":"code","9ad33e03":"code","a444bc52":"code","a044a776":"code","5cd7ab16":"code","8dc16f98":"code","c5d2128b":"code","fec2a810":"code","3147c86b":"code","a45c3065":"code","d683bfc5":"code","b2e95e6c":"code","27b09cf7":"code","6e61c942":"code","bb15841c":"code","a5ffd064":"markdown","0a82101d":"markdown","0dcf02d0":"markdown","8abcced8":"markdown","f3e585f1":"markdown","1368390a":"markdown","4ef813ae":"markdown","2b9eebde":"markdown","5d494673":"markdown","4b46459c":"markdown","0539c191":"markdown","c8e2c5b4":"markdown","5c31cd49":"markdown","23f1ccea":"markdown","ff54230f":"markdown","2613bcd3":"markdown","bc063b76":"markdown","41a762f5":"markdown","2fd03af3":"markdown","1a49ceb3":"markdown","0d60d7ab":"markdown","9ee167a1":"markdown","fa2a8ae8":"markdown","3eb489f9":"markdown","951fdf80":"markdown","7c0dd2dc":"markdown","d00f3222":"markdown","0c75243a":"markdown","76246674":"markdown","8506dbf3":"markdown","c3dbe90e":"markdown","27c4648e":"markdown","c3526bba":"markdown","a7f9e5c9":"markdown","5ddf105a":"markdown","5b7dd760":"markdown","3c41d79b":"markdown","36171613":"markdown","3ec79833":"markdown","3b6ffca1":"markdown"},"source":{"b1c24884":"import pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#loading the data\ndf_2021 = pd.read_csv(\"..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\", low_memory = False)\ndata_2021 = df_2021.copy()\n#dropping the first row which contains all the Question asked \ndata_2021 = data_2021.drop(data_2021.index[0]).reset_index(drop=True)\n","b1075d9a":"#annotation fuction\ndef gen_annotations(annot):\n    \"\"\"\n    Generates annotations to insert in the chart\n    \"\"\"\n    if annot is None:\n        return []\n    \n    annotations = []\n    # Adding labels\n    for d in annot:\n        annotations.append(dict(xref='paper', x=d['x'], y=d['y'],\n                           xanchor='left', yanchor='bottom',\n                           text= d['text'],\n                           font=dict(size=13,\n                           color=d['color']),\n                           showarrow=False))\n    return annotations\n\n#creating a dictionary to store the multiple columns for all that applys\nrole_important={}\n\nrole_important['Analyze and understand data']=data_2021.Q24_Part_1.value_counts().sum()\nrole_important['Build infrastructure for analyzing data']=data_2021.Q24_Part_2.value_counts().sum()\nrole_important['Build prototypes ML']=data_2021.Q24_Part_3.value_counts().sum()\nrole_important['Build machine learning service']=data_2021.Q24_Part_4.value_counts().sum()\nrole_important['improve existing ML models']=data_2021.Q24_Part_5.value_counts().sum()\nrole_important['advances the state of the art of ML']=data_2021.Q24_Part_6.value_counts().sum()\n#role_important['None of these activities']=data_scientist.Q24_Part_7.value_counts().sum()\n\nroll1= round(100*pd.DataFrame.from_dict(role_important, orient='index')\/len(data_2021),2)\nroll1.reset_index(inplace=True)\nroll1.rename(columns={\"index\": \"Importance\", 0 : \"percentage\"}, inplace=True)\nroll1.sort_values(by='percentage', ascending=False, inplace=True)\n\n# Add title and annotationsit\nannot = [{'x': 0.60, 'y': 30, 'text': \"<b>49%<\/b> of the data scientist work is <b>understanding<\/b><br> and  <b>analysing<\/b> data.\",'color': 'crimson'},\n        {'x': 0.60, 'y': 22, 'text': \"While <b>51%<\/b> of the work is building and managing<br> machine learning models<\/b>\",'color': 'lightslategray'}]\n\n#highlight colors\ncolor = ['lightslategray',]*6\ncolor[0] = 'crimson'\ncolor[2] = 'crimson'\nfig = go.Figure()\nfig.add_trace(go.Bar(x = roll1['Importance'], y = roll1['percentage'], marker_color = color))\nfig.update_layout(plot_bgcolor = \"white\",\n                  title = dict(text = \"<b>Important part of Data Scientist Work<\/b>\"),\n                  xaxis = dict(title = \"Important activities\"),\n                  yaxis = dict(title = \"Percentage of Responses\"),\n                 width=700,\n                 height = 500,\n                 annotations = gen_annotations(annot))\nfig.show()","9ad33e03":"# dropping all NaN and I do not wish to disclose my approximate yearly compensation\/salary, because we are only interested in the compansation\/salary\ndata_2021 = data_2021[~data_2021.Q25.isnull()].copy()\nnot_disclosed = data_2021[data_2021.Q25 == 'I do not wish to disclose my approximate yearly compensation'].index\ndata_2021 = data_2021.drop(list(not_disclosed), axis=0)\n\n#arranging the salary to have a good looking \ndata_2021.Q25.replace(to_replace={'$0-999':'$0-10,000',\n                                  '1,000-1,999':'$0-10,000',\n                                  '2,000-2,999':'$0-10,000',\n                                  '3,000-3,999':'$0-10,000',\n                                  '4,000-4,999':'$0-10,000',\n                                  '5,000-7,499':'$0-10,000',\n                                  '7,500-9,999':'$0-10,000',\n                                  '10,000-14,999':'$10-20,000',\n                                  '15,000-19,999':'$10-20,000',\n                                  '20,000-24,999':'$20-30,000',\n                                  '25,000-29,999':'$20-30,000',\n                                  '30,000-39,999':'$30-40,000',\n                                  '40,000-49,999':'$40-50,000',\n                                  '50,000-59,999':'$50-60,000',\n                                  '60,000-69,999':'$60-70,000',\n                                  '70,000-79,999':'$70-80,000',\n                                  '80,000-89,999':'$80-90,000',\n                                  '90,000-99,999':'$90-100,000',\n                                  '100,000-124,999':'$100-200,000',\n                                  '125,000-149,999':'$100-200,000',\n                                  '150,000-199,999':'$100-200,000',       \n                                  '200,000-249,999':'$100-200,000',\n                                  '250,000-299,999':'$200-300,000',\n                                 '300,000-499,999':'$300-500,000',\n                                 '$500,000-999,999':'$500-1,000,000',\n                                 '>$1,000,000':'>$1,000,000'},\n                      inplace=True)\n\n\n# transforming compensation into category type and ordening the values\nfrom pandas.api.types import CategoricalDtype\n\n\ncateg = ['$0-10,000',\n         '$100-200,000',\n         '$10-20,000',\n         '$20-30,000',\n         '$30-40,000',\n         '$50-60,000',\n         '$40-50,000',\n         '$60-70,000',\n         '$70-80,000',\n         '$80-90,000',\n         '$90-100,000',\n         '$300-500,000',\n         '$200-300,000',\n         '$500-1,000,000',\n         '>$1,000,000']\n\ncat_type = CategoricalDtype(categories=categ, ordered=True)\ndata_2021.Q25 = data_2021.Q25.astype(cat_type)\n\n# Doing this we are transforming the category \"I do not wish to disclose my approximate yearly compensation\" into NaN\n\nsalary = data_2021.Q25.value_counts(normalize = True).rename(\"percentage\").mul(100).round(2).sort_values(ascending = False)\n\n\nannot = [{'x': 0.37, 'y': 15, 'text': '<b>12%<\/b> of the respondants earns <b>morethan $100K<\/b> on average' ,'color': 'crimson'},\n         {'x': 0.37, 'y': 12, 'text': '<b>88%<\/b> of respondents earn <b>lessthan $100K<\/b> on average ','color': 'lightslategray'}]\n\n\ncolor = ['lightslategray']*15\ncolor[13] = 'crimson'\ncolor[3] = 'crimson'\ncolor[2] = 'crimson'\ncolor[1] = 'crimson'\nfig = go.Figure()\nfig.add_trace(go.Bar(x=salary.index, y = salary.values,marker_color = color))\nfig.update_layout(plot_bgcolor = 'white',\n                  title = dict(text = '<b>Average Salary Earned<\/b><br>by Kagglers'),\n                  xaxis = dict(title = 'Salary in USD'),\n                  yaxis = dict(title = 'Percentage'),\n                  height = 500,\n                  width = 700,\n                 annotations = gen_annotations(annot))\nfig.show()","a444bc52":"# we are not intereted in students and currently not employed in this plot\nstudent_mask = (data_2021.Q5 != \"Student\") & (data_2021.Q5 != \"Currently not employed\")\n\nroles = data_2021[student_mask].Q5.value_counts(normalize = True).rename(\"percentage\").mul(100).round(2).sort_values(ascending = False)\n#highlight colors\ncolor = ['lightslategray']*13\ncolor[0] = 'crimson'\ncolor[2] = 'crimson'\ncolor[3] = 'crimson'\nfig = go.Figure()\nfig.add_trace(go.Bar(x = roles.index, y = roles.values, marker_color = color))\nfig.update_layout(plot_bgcolor = 'white',\n                  title = dict(text = '<b>Roles \/ Careers Rise in Data Science<\/b>'),\n                  xaxis = dict(title = 'Percentage'),\n                  yaxis = dict(title = 'Roles \/ Careers'),\n                  height = 500,\n                  width = 700)\nfig.show()","a044a776":"#replacing some values to reduce their lenght \ndata_2021.Q4.replace(to_replace={\"Bachelor\u2019s degree\":\"Bachelor\u2019s degree\",\n\"Master\u2019s degree\":\"Master\u2019s degree\",\n\"Some college\/university study without earning a bachelor\u2019s degree\":\"Some college\",\n\"Doctoral degree\":\"Doctoral's degree\",\n\"I prefer not to answer\":\"I prefer not to answer\",\n\"No formal education past high school\":\"High schools\",\n\"Professional doctorate\":\"Professional's\"}, \n                     inplace=True)\n\n#creating a mask for i prefer not to answer\nprefer_not_to_answer_mask = (data_2021.Q4 != \"I prefer not to answer\") \n\n\neducation = data_2021[prefer_not_to_answer_mask].Q4.value_counts(normalize = True).rename(\"percentage\").mul(100).round(2).sort_values(ascending = False)\n\ncolor = ['lightslategray']*6\ncolor[0] = 'crimson'\ncolor[1] = 'crimson'\ncolor[2] = 'crimson'\ncolor[4] = 'crimson'\nannot = [{'x': 0.50, 'y': 35, 'text': '<b>94%<\/b> of Kagglers have <b>University degree<\/b>' ,'color': 'crimson'},\n         {'x': 0.50, 'y': 32, 'text': 'While <b>6%<\/b> have <b>No University degree<\/b> ','color': 'lightslategray'}]\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=education.index, y = education.values,marker_color = color))\nfig.update_layout(plot_bgcolor = 'white',\n                  title = dict(text = '<b>Highest Level of Education Attained<\/b><br>By Kagglers'),\n                  xaxis = dict(title = 'Education Level'),\n                  yaxis = dict(title = 'Percentage'),\n                  height = 500,\n                  width = 700,\n                 annotations = gen_annotations(annot))\nfig.show()","5cd7ab16":"\nrecommended_lang = data_2021.Q8.value_counts(normalize = True).rename(\"Percentage\").mul(100).round(2).sort_values(ascending = False)\n\ncolor = ['lightslategray',]*13\ncolor[0] = 'crimson'\ncolor[1] = 'crimson'\ncolor[2] = 'crimson'\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x = recommended_lang.index, y = recommended_lang.values, marker_color = color))\nfig.update_layout(plot_bgcolor = \"white\",\n                  title = dict(text = \"<b>Top 3 Most Recommended Programming Language<\/b><br>by Kagglers to new Data scientist\"),\n                  xaxis = dict(title = \"Programming Language \"),\n                  yaxis = dict(title = \"Percentage\"),\n                 width=700,\n                 height = 500)\nfig.show()","8dc16f98":"# creating visualization tools dict\nvis_tools={}\n\nvis_tools['Matplotlib']=data_2021.Q14_Part_1.value_counts().sum()\nvis_tools['Seaborn']=data_2021.Q14_Part_2.value_counts().sum()\nvis_tools['Plotly \/ Plotly Express']=data_2021.Q14_Part_3.value_counts().sum()\nvis_tools['Ggplot \/ ggplot2']=data_2021.Q14_Part_4.value_counts().sum()\nvis_tools['Shiny']=data_2021.Q14_Part_5.value_counts().sum()\nvis_tools['D3 js ']=data_2021.Q14_Part_6.value_counts().sum()\nvis_tools['Altair']=data_2021.Q14_Part_7.value_counts().sum()\nvis_tools['Bokeh']=data_2021.Q14_Part_8.value_counts().sum()\nvis_tools['Geoplotlib']=data_2021.Q14_Part_9.value_counts().sum()\nvis_tools['Leaflet \/ Folium']=data_2021.Q14_Part_10.value_counts().sum()\n\n\ntmp = round(100*pd.DataFrame.from_dict(vis_tools, orient='index')\/len(data_2021),2)\ntmp.reset_index(inplace=True)\ntmp.rename(columns={\"index\": \"visualization_tools\", 0 : \"percentage\"}, inplace=True)\ntmp.sort_values(by='percentage', ascending=False, inplace=True)\ncolor = ['lightslategray',]*11\ncolor[0]= 'crimson'\ncolor[1] = 'crimson'\ncolor[2] = 'crimson'\nfig = go.Figure()\nfig.add_trace(go.Bar(x = tmp['visualization_tools'], y = tmp['percentage'], marker_color = color))\nfig.update_layout(plot_bgcolor = \"white\",\n                  title = dict(text = \"<b>Top 3 Data Visualization Libraries\/Tools<\/b><br>used by Kagglers\"),\n                  xaxis = dict(title = \"Visualization Libraries\"),\n                  yaxis = dict(title = \"Percentage\"),\n                 width=700,\n                 height = 500)\nfig.show()","c5d2128b":"#creating BI dict\nBI_tools={}\n\nBI_tools['Amazon Quiksight']=data_2021.Q34_A_Part_1.value_counts().sum()\nBI_tools['Microsoft PowerBI']=data_2021.Q34_A_Part_2.value_counts().sum()\nBI_tools['Google Data Studio']=data_2021.Q34_A_Part_3.value_counts().sum()\nBI_tools['Looker']=data_2021.Q34_A_Part_4.value_counts().sum()\nBI_tools['Tableau']=data_2021.Q34_A_Part_5.value_counts().sum()\nBI_tools['Salesforce']=data_2021.Q34_A_Part_6.value_counts().sum()\nBI_tools['Tableau CRM']=data_2021.Q34_A_Part_7.value_counts().sum()\nBI_tools['Qlik']=data_2021.Q34_A_Part_8.value_counts().sum()\nBI_tools['Domo']=data_2021.Q34_A_Part_9.value_counts().sum()\nBI_tools['TIBCO spotfire']=data_2021.Q34_A_Part_10.value_counts().sum()\nBI_tools['ALteryx']=data_2021.Q34_A_Part_11.value_counts().sum()\nBI_tools['Sisense']=data_2021.Q34_A_Part_12.value_counts().sum()\nBI_tools['Sap analytics Cloud']=data_2021.Q34_A_Part_13.value_counts().sum()\nBI_tools['Microsoft Azure Synapse']=data_2021.Q34_A_Part_14.value_counts().sum()\nBI_tools['Thoughtspot']=data_2021.Q34_A_Part_15.value_counts().sum()\n\n\ntmp = round(100*pd.DataFrame.from_dict(BI_tools, orient='index')\/len(data_2021),2)\ntmp.reset_index(inplace=True)\ntmp.rename(columns={\"index\": \"BI_tools\", 0 : \"percentage\"}, inplace=True)\ntmp.sort_values(by='percentage', ascending=False, inplace=True)\n\n\ncolor = ['lightslategray',]*15\ncolor[0] = 'crimson'\ncolor[1] = 'crimson'\ncolor[2] = 'crimson'\nfig = go.Figure()\nfig.add_trace(go.Bar(x = tmp['BI_tools'], y = tmp['percentage'], marker_color = color))\nfig.update_layout(plot_bgcolor = \"white\",\n                  title = dict(text = \"<b>Top 3 Business intelligence Tools Used<\/b><br> by Kagglers\"),\n                  xaxis = dict(title = \"Business Intelligence Tools\"),\n                  yaxis = dict(title = \"Percentage\"),\n                 width=700,\n                 height = 500)\nfig.show()","fec2a810":"ML_experience = data_2021.Q15.value_counts(normalize = True).rename(\"percentage\").mul(100).round(2)\n\ncolor = ['lightslategray',]*10\ncolor[0] = 'crimson'\ncolor[1] = 'crimson'\ncolor[2] = 'crimson'\n\n# annotation\nannot = [{'x': 0.36, 'y': 25, 'text': '<b>Approximately 65%<\/b> of Kagglers are less proficient in <b>Machine learning<\/b>' ,'color': 'crimson'},\n         {'x': 0.36, 'y': 22, 'text': 'While <b>35%<\/b> are highly proficient in <b>Machine learning<\/b> ','color': 'lightslategray'}]\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x = ML_experience.index, y = ML_experience.values, marker_color = color))\nfig.update_layout(plot_bgcolor = \"white\",\n                  title = dict(text = \"<b>Proficiency in Machine Learning Techniques Gained<\/b><br> by Kagglers\"),\n                  xaxis = dict(title = \"Machine Learning Proficiency \"),\n                  yaxis = dict(title = \"Percentage\"),\n                 width=700,\n                 height = 500,\n                 annotations = gen_annotations(annot))\nfig.show()","3147c86b":"ML_algorithms={}\n\nML_algorithms['Linear or Logistic Regression']=data_2021.Q17_Part_1.value_counts().sum()\nML_algorithms['Decision Trees or Random Forests']=data_2021.Q17_Part_2.value_counts().sum()\nML_algorithms['Gradient Boosting Machines (xgboost, lightgbm, etc)']=data_2021.Q17_Part_3.value_counts().sum()\nML_algorithms['Bayesian Approaches']=data_2021.Q17_Part_4.value_counts().sum()\nML_algorithms['Evolutionary Approaches']=data_2021.Q17_Part_5.value_counts().sum()\nML_algorithms['Dense Neural Networks (MLPs, etc)']=data_2021.Q17_Part_6.value_counts().sum()\nML_algorithms['Convolutional Neural Networks']=data_2021.Q17_Part_7.value_counts().sum()\nML_algorithms['Generative Adversarial Networks']=data_2021.Q17_Part_8.value_counts().sum()\nML_algorithms['Recurrent Neural Networks']=data_2021.Q17_Part_9.value_counts().sum()\nML_algorithms['Transformer Networks (BERT, gpt-3, etc)']=data_2021.Q17_Part_10.value_counts().sum()\n# excluding None column\n\ntmp = round(100*pd.DataFrame.from_dict(ML_algorithms, orient='index')\/len(data_2021),2)\ntmp.reset_index(inplace=True)\ntmp.rename(columns={\"index\": \"ML_algorithms\", 0 : \"percentage\"}, inplace=True)\ntmp.sort_values(by='percentage', ascending=True, inplace=True)\n\n\ncolor = ['lightslategray',]*10\ncolor[9] = 'crimson'\ncolor[8] = 'crimson'\ncolor[7] = 'crimson'\nfig = go.Figure()\nfig.add_trace(go.Bar(x = tmp['percentage'], y = tmp['ML_algorithms'], marker_color = color, orientation = 'h'))\nfig.update_layout(plot_bgcolor = \"white\",\n                  title = dict(text = \"<b>Top 3 Most Used Machine Learning Techniques<\/b><br> by Kagglers\"),\n                  xaxis = dict(title = \"Percentage\"),\n                  yaxis = dict(title = \"ML Techniques\"),\n                 width=700,\n                 height = 500)\nfig.show()","a45c3065":"# dict for ml framework\nML_frameworks={}\n\nML_frameworks['Scikit-learn']=data_2021.Q16_Part_1.value_counts().sum()\nML_frameworks['TensorFlow']=data_2021.Q16_Part_2.value_counts().sum()\nML_frameworks['Keras']=data_2021.Q16_Part_3.value_counts().sum()\nML_frameworks['Pytorch']=data_2021.Q16_Part_4.value_counts().sum()\nML_frameworks['Fast.ai']=data_2021.Q16_Part_5.value_counts().sum()\nML_frameworks['MXnet ']=data_2021.Q16_Part_6.value_counts().sum()\nML_frameworks['XGboost']=data_2021.Q16_Part_7.value_counts().sum()\nML_frameworks['lightGBM']=data_2021.Q16_Part_8.value_counts().sum()\nML_frameworks['catBoost']=data_2021.Q16_Part_9.value_counts().sum()\nML_frameworks['Prophet']=data_2021.Q16_Part_10.value_counts().sum()\nML_frameworks['H2O 3']=data_2021.Q16_Part_11.value_counts().sum()\nML_frameworks['Caret']=data_2021.Q16_Part_12.value_counts().sum()\nML_frameworks['Tidymodels']=data_2021.Q16_Part_13.value_counts().sum()\nML_frameworks['JAX']=data_2021.Q16_Part_14.value_counts().sum()\nML_frameworks['Pytorch lightening']=data_2021.Q16_Part_15.value_counts().sum()\nML_frameworks['Huggingface']=data_2021.Q16_Part_16.value_counts().sum()\n\n\ntmp = round(100*pd.DataFrame.from_dict(ML_frameworks, orient='index')\/len(data_2021),2)\ntmp.reset_index(inplace=True)\ntmp.rename(columns={\"index\": \"ML_framework\", 0 : \"percentage\"}, inplace=True)\ntmp.sort_values(by='percentage', ascending=False, inplace=True)\ncolor = ['lightslategray',]*16\ncolor[0]= 'crimson'\ncolor[1] = 'crimson'\ncolor[2] = 'crimson'\nfig = go.Figure()\nfig.add_trace(go.Bar(x = tmp['ML_framework'], y = tmp['percentage'], marker_color = color))\nfig.update_layout(plot_bgcolor = \"white\",\n                  title = dict(text = \"<b>Top 3 Most Used Machine Learning Frameworks<\/b><br>by Kagglers\"),\n                  xaxis = dict(title = \"Machine Learning Frameworks\"),\n                  yaxis = dict(title = \"Percentage\"),\n                 width=700,\n                 height = 500)\nfig.show()","d683bfc5":"CLoud_computing_P={}\n\nCLoud_computing_P['Amazon Web Services(AWS)']=data_2021.Q27_A_Part_1.value_counts().sum()\nCLoud_computing_P['Microsoft Azure']=data_2021.Q27_A_Part_2.value_counts().sum()\nCLoud_computing_P['Google Cloud Platform(GCP)']=data_2021.Q27_A_Part_3.value_counts().sum()\nCLoud_computing_P['IBM Cloud']=data_2021.Q27_A_Part_4.value_counts().sum()\nCLoud_computing_P['Oracle Cloud']=data_2021.Q27_A_Part_5.value_counts().sum()\nCLoud_computing_P['SAP Cloud']=data_2021.Q27_A_Part_6.value_counts().sum()\nCLoud_computing_P['Salesforce Cloud']=data_2021.Q27_A_Part_7.value_counts().sum()\nCLoud_computing_P['VMware Cloud']=data_2021.Q27_A_Part_8.value_counts().sum()\nCLoud_computing_P['Alibaba Cloud']=data_2021.Q27_A_Part_9.value_counts().sum()\nCLoud_computing_P['Tencent Cloud']=data_2021.Q27_A_Part_10.value_counts().sum()\n\n\n\ntmp = round(100*pd.DataFrame.from_dict(CLoud_computing_P, orient='index')\/len(data_2021),2)\ntmp.reset_index(inplace=True)\ntmp.rename(columns={\"index\": \"Cloud_computing\", 0 : \"percentage\"}, inplace=True)\ntmp.sort_values(by='percentage', ascending=False, inplace=True)\n\n\n\ncolor = ['lightslategray',]*10\ncolor[0] = 'crimson'\ncolor[1] = 'crimson'\ncolor[2] = 'crimson'\nfig = go.Figure()\nfig.add_trace(go.Bar(x = tmp['Cloud_computing'], y = tmp['percentage'], marker_color = color))\nfig.update_layout(plot_bgcolor = \"white\",\n                  title = dict(text = \"<b>Top 3 Most Used CLoud Computing Platforms<\/b><br>by Kagglers\"),\n                  xaxis = dict(title = \"Cloud Computing Platforms\"),\n                  yaxis = dict(title = \"Percentage\"),\n                 width=700,\n                 height = 500)\nfig.show()","b2e95e6c":"# we are not intersted in they all had and none have, vote\nnot_related = (data_2021.Q28 != \"They all had a similarly enjoyable developer experience\")&(data_2021.Q28 != \"None were satisfactory\")&(data_2021.Q28 != 'Other')\n\nBest_c_computing = data_2021[not_related].Q28.value_counts(normalize = True).rename(\"percentage\").mul(100).round(2)\n\ncolor = ['lightslategray',]*10\ncolor[0] = 'crimson'\ncolor[1] = 'crimson'\ncolor[2] = 'crimson'\nfig = go.Figure()\nfig.add_trace(go.Bar(x = Best_c_computing.index, y = Best_c_computing.values, marker_color = color))\nfig.update_layout(plot_bgcolor = \"white\",\n                  title = dict(text = \"<b>Top 3 Most Enjoyable CLoud computing Platforms Voted<\/b><br>by Kagglers\"),\n                  xaxis = dict(title = \"Cloud Computing Platforms\"),\n                  yaxis = dict(title = \"Percentage\"),\n                 width=700,\n                 height = 500)\nfig.show()","27b09cf7":"big_data_P={}\n\nbig_data_P['MySQL']=data_2021.Q32_A_Part_1.value_counts().sum()\nbig_data_P[\"PostgreSQL\"]=data_2021.Q32_A_Part_2.value_counts().sum()\nbig_data_P['SQlite']=data_2021.Q32_A_Part_3.value_counts().sum()\nbig_data_P['Oracle Database']=data_2021.Q32_A_Part_4.value_counts().sum()\nbig_data_P['Mango DB']=data_2021.Q32_A_Part_5.value_counts().sum()\nbig_data_P['Snowflake']=data_2021.Q32_A_Part_6.value_counts().sum()\nbig_data_P['IBM Db2']=data_2021.Q32_A_Part_7.value_counts().sum()\nbig_data_P['Microsoft SQL server']=data_2021.Q32_A_Part_8.value_counts().sum()\nbig_data_P['Microsoft Azure SQL Database']=data_2021.Q32_A_Part_9.value_counts().sum()\nbig_data_P['Microsoft Azure Cosmos DB']=data_2021.Q32_A_Part_10.value_counts().sum()\nbig_data_P['Amazon Redshit']=data_2021.Q32_A_Part_11.value_counts().sum()\nbig_data_P['Amazon Aurora']=data_2021.Q32_A_Part_12.value_counts().sum()\nbig_data_P['Amazon RDS']=data_2021.Q32_A_Part_13.value_counts().sum()\nbig_data_P['Amazon dynamoDB']=data_2021.Q32_A_Part_14.value_counts().sum()\nbig_data_P['Google Cloud BigQuery']=data_2021.Q32_A_Part_15.value_counts().sum()\nbig_data_P['google Cloud SQL']=data_2021.Q32_A_Part_16.value_counts().sum()\nbig_data_P['Google Cloud firestore']=data_2021.Q32_A_Part_17.value_counts().sum()\nbig_data_P['NGoogle Cloud BigTable']=data_2021.Q32_A_Part_18.value_counts().sum()\nbig_data_P['Google Cloud Spanner']=data_2021.Q32_A_Part_19.value_counts().sum()\n\ntmp = round(100*pd.DataFrame.from_dict(big_data_P, orient='index')\/len(data_2021),2)\ntmp.reset_index(inplace=True)\ntmp.rename(columns={\"index\": \"big_data_P\", 0 : \"percentage\"}, inplace=True)\ntmp.sort_values(by='percentage', ascending=True, inplace=True)\n\ncolor = ['lightslategray',]*19\ncolor[18] = 'crimson'\ncolor[17] = 'crimson'\ncolor[16] = 'crimson'\nfig = go.Figure()\nfig.add_trace(go.Bar(x = tmp['percentage'], y = tmp['big_data_P'], marker_color = color, orientation = 'h'))\nfig.update_layout(plot_bgcolor = \"white\",\n                  title = dict(text = \"<b>Top 3 Most Used Big Data Products<\/b><br> by Kagglers\"),\n                  xaxis = dict(title = \"Percentage\"),\n                  yaxis = dict(title = \"Big data Prodcuts\"),\n                 width=700,\n                 height = 500)\nfig.show()","6e61c942":"Learning_Platforms={}\n\nLearning_Platforms['Coursera']=data_2021.Q40_Part_1.value_counts().sum()\nLearning_Platforms['edx']=data_2021.Q40_Part_2.value_counts().sum()\nLearning_Platforms['kaggle']=data_2021.Q40_Part_3.value_counts().sum()\nLearning_Platforms['DataCamp']=data_2021.Q40_Part_4.value_counts().sum()\nLearning_Platforms['Fast.ai']=data_2021.Q40_Part_5.value_counts().sum()\nLearning_Platforms['Udacity']=data_2021.Q40_Part_6.value_counts().sum()\nLearning_Platforms['Udemy']=data_2021.Q40_Part_7.value_counts().sum()\nLearning_Platforms['LinkedIn']=data_2021.Q40_Part_8.value_counts().sum()\nLearning_Platforms['Cloud Certification']=data_2021.Q40_Part_9.value_counts().sum()\nLearning_Platforms['University Courses']=data_2021.Q40_Part_10.value_counts().sum()\nLearning_Platforms['Other']=data_2021.Q40_Part_11.value_counts().sum()\n\ntmp = round(100*pd.DataFrame.from_dict(Learning_Platforms, orient='index')\/len(data_2021),2)\ntmp.reset_index(inplace=True)\ntmp.rename(columns={\"index\": \"Mean of learning ML\", 0 : \"percentage\"}, inplace=True)\ntmp.sort_values(by='percentage', ascending=False, inplace=True)\n\ncolor = ['lightslategray',]*11\ncolor[0] = 'crimson'\ncolor[1] = 'crimson'\ncolor[2] = 'crimson'\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x = tmp['Mean of learning ML'], y = tmp['percentage'], marker_color = color))\nfig.update_layout(plot_bgcolor = \"white\",\n                  title = dict(text = \"<b>Top 3 Most Use Means of learning Data Science <\/b><br> by Kagglers\"),\n                  xaxis = dict(title = \"Means of Learning\"),\n                  yaxis = dict(title = \"Percentage%\"),\n                 width=700,\n                 height = 500,)\n                # annotations = gen_annotations(annot))\nfig.show()","bb15841c":"motivational_p={}\n\nmotivational_p['Twitter']=data_2021.Q42_Part_1.value_counts().sum()\nmotivational_p[\"Email newsletters\"]=data_2021.Q42_Part_2.value_counts().sum()\nmotivational_p['Reddit']=data_2021.Q42_Part_3.value_counts().sum()\nmotivational_p['Kaggle']=data_2021.Q42_Part_4.value_counts().sum()\nmotivational_p['Course Forums']=data_2021.Q42_Part_5.value_counts().sum()\nmotivational_p['YouTube']=data_2021.Q42_Part_6.value_counts().sum()\nmotivational_p['Podcasts']=data_2021.Q42_Part_7.value_counts().sum()\nmotivational_p['Blogs']=data_2021.Q42_Part_8.value_counts().sum()\nmotivational_p['Journal Publications']=data_2021.Q42_Part_9.value_counts().sum()\nmotivational_p['Slack Communities']=data_2021.Q42_Part_10.value_counts().sum()\nmotivational_p['None']=data_2021.Q42_Part_11.value_counts().sum()\n\n\ntmp = round(100*pd.DataFrame.from_dict(motivational_p, orient='index')\/len(data_2021),2)\ntmp.reset_index(inplace=True)\ntmp.rename(columns={\"index\": \"motivational_p\", 0 : \"percentage\"}, inplace=True)\ntmp.sort_values(by='percentage', ascending=False, inplace=True)\n\ncolor = ['lightslategray',]*11\ncolor[0] = 'crimson'\ncolor[1] = 'crimson'\ncolor[2] = 'crimson'\nfig = go.Figure()\nfig.add_trace(go.Bar(x = tmp['motivational_p'], y = tmp['percentage'], marker_color = color))\nfig.update_layout(plot_bgcolor = \"white\",\n                  title = dict(text = \"<b>Top 3 Media Source for Use<\/b> <br>by Kagglers\"),\n                  xaxis = dict(title = \"Motivational Source\"),\n                  yaxis = dict(title = \"Percentage\"),\n                 width=700,\n                 height = 500)\nfig.show()","a5ffd064":"## 6. Where to get motivated and reports on Data Scinece\n<a id = 'Motivation'><\/a>\nAfter you've started to build online presence, its a good idea to start engaging with other data scientist, you can do this in person or in online communities. this is a good way that will guide you to \n1. Find other people to learn with\n2. Strengten your knowledge by learning from others\n3. Enhance your profile, and find opportunities. \n\nlet's look at Online communities were kagglers use to get motivated and reports on data science","0a82101d":"during the survey the respondant were ask to recommend a programming language for beginner or data science aspirants\nSo, i'm going to use the question to show the top 3 most recommeded programming languages.\n\nLet's dive in.\n","0dcf02d0":"## Data science as a field of study\n<a id = 'datascience'><\/a>\n### What is Data Science?\n<a id = 'What_ds'><\/a>\nWe all hear about the word **Data science**, but what does it really means?\n\n**Data science** is a broad field that refers to the collective processes, concepts, theories, tools and technologies that enables the analysis, review and extraction of valuable knowledge and information from raw data. it geared towards helping individuals and organizations make better decisions from consumed, stored and managed data. \nData science blend various tools. it makes use of algorithms and machine learning principles with the goal to discover hidden patterns from raw data.\n","8abcced8":"As the analysis shows, the important work of data scientist which is **analysis and building machine learning models** are almost 50\/50. So we can describe a **Data scientist** as a person who use raw data to understand, analyse and build machine learning models for business decision.","f3e585f1":"### How much did they earns?\n<a id = 'earning'><\/a>","1368390a":"# <center>How to start a Data Science Career in 2021<\/center>","4ef813ae":"as the analytics shows, the **top 3 most recommended proogramming languages** are;\n1. Python\n2. SQL\n3. R\n\nSo, as a Beginner i highly recommend **Python**, and as the most highly recommended language for new data scientist, because you can use python for almost all the steps used in data science because of it versitility. you can learn SQL and R as well, as there are important in the field of data science.\n\n\n","2b9eebde":"## 5. Where to Learn Data Science\n<a id = 'learning'><\/a>\n\nThere are some Schools that now offered specialized programme tailored to the educational requirements pursuing a career in data science, giving students the options to focus on the field of study they are most interested in, helps in a shorter period of time.\n  Some of the many options available include [Massive Open Online Courses(MOOC)](https:\/\/en.wikipedia.org\/wiki\/Massive_open_online_course). with MOOCs, you can get to choose your time and place of studying, even helping you save money while you are at it. the MOOCs programmes offer practical learning methods that you will not find on the continiues of textbooks, including a hands-on approach to learning in demand data science skills, capstone projects and other excercise that help prepare student to become a data scientist.\n\nSo let's get a look at the top 3 most use means of learning ML and DS by kagglers","5d494673":"## 2. Become a Data Science\n<a id = 'DS_onstart'><\/a>\n    \nData science is an umbrella term that encompasses all of the techniques and tools during the life cycle stages of useful data. Note: there are two types of skills to know as a data scienctist these skills are technical skills and soft\/business skills.\n\nthe two skills mentioned above, will be the most important skill any sucessful data scientist needs to have. Now we will start with the Technical Skills, what are the technical skills you need to know.\n\nBut before we start, lets look at one important Question which is weather you can have a university degree to become a data scientist.","4b46459c":"As the plot above shows, the **top 3 most used machine learning frameworks** by kagglers are;\n1. Scikit-Learn\n2. TensorFlow\n3. Keras\n\nwith these **top 3 machine learning frameworks for data science**, you can **create truly amazing projects**,  given that each take's time to learn. but for beginners i will **suggest Scikit-learn** with the fact that it comes with detailed documentation it allows the developer to change the algorithm's preset parameters either in use or at runtime, making it easy to tune and troubleshoot models, scikit learn has extensive pre-processing capabilities, and enables algorithm and model design for clustering, classification, regression, dimensionality reduction and model selection\n","0539c191":"(1). [Data Scientist Salary](https:\/\/www.projectpro.io\/article\/data-scientist-salary-the-ultimate-guide-for-2021\/218): The ultimate guide for 2021\n\n(2). [Your Future in Data Science](https:\/\/www.simplilearn.com\/the-future-of-data-science-article): Career outlook 2020\n\n(3). [LinkedIn 2021 report](https:\/\/www.linkedin.com\/pulse\/linkedin-jobs-rise-15-opportunities-demand-hiring-now-andrew-seaman): rising for data science and machine learning job roles\n\n(4). [bachelors degree programmes in data science](https:\/\/www.coursera.org\/articles\/what-degree-do-i-need-to-become-a-data-analyst): list of bachelors degree programme for data science\n\n(5). https:\/\/towardsdatascience.com\/soft-skills-for-data-science-fee73ae4821a Soft Skills For Data Science\n\n(5). [who codes what and how long- a story told through a heatmap](https:\/\/www.kaggle.com\/tkubacka\/a-story-told-through-a-heatmap?cellIds=63&kernelSessionId=24425090): analysis on which online platform to use as a beginner.","c8e2c5b4":"### Future of Data Science\n<a id = 'ds_future'><\/a>\nCompanies across a wide spectrum of industries are begining to embrace Data science as a means of gathering and leveraging smater business intelligence. those organisations that fail to keep up won't be able to compete in the future. this is exciting time to be a Data Scientist or aspirant data scientist, as dynamic and lucrative new opportunities continue to open up at a rapid Clip.<br> \n     [Ronald Van Loon](https:\/\/www.simplilearn.com\/authors\/ronald-van-loon)  a leader in data analytics talked about the exploring field of Data science and its many career opportunities in his recent webinar titled \"[Your Future in Data Science: career outlook 2020](https:\/\/www.simplilearn.com\/the-future-of-data-science-article)\" he discussed the relevant trends, future predictions and how you can go about landing a job as a data scientist.\n  Below is an edited summary of the webiner covering the main path disscused by Van Loon. For instance, he discussed **how you should approach the job**, **markets for Data scientist**, **how businesses will be utilizing data science in the future** and the **best strategies for chatting your unique path in the exciting field**.\n \n[edited summary](https:\/\/youtu.be\/0rFrqbs6y80)\n","5c31cd49":"\n**Business Intelligence tools** is a form of **software** that is designed to visualize data. each tools capabilities varies, but at most basic, they allow you to input a dataset and visually manipulate it. most but not all, come with build-in templates you can use to generate basic visualization.\n\nthese Business Intelligence tools can then be used for variety of purposes: dashboards, annual reports, sales and marketing materials, investor slide decks, and virtually anywhere else information needs to be interpreted immediately. \n\nNow lets take a look at the **top 3 business intelligence tool** use by kagglers","23f1ccea":"## Table of Contents\n* [1. Data Science as a field of study](#datascience)\n   * [1.1. What is Data Science](#What_ds)\n   * [1.2. Who is a Data Scientist](#whos_DS)\n   * [1.3. How Much Did they Earns](#earning)\n   * [1.4. Future of Data Science](#ds_future)\n   * [1.5. Careers in Data Science](#career_Ds)\n* [2. Become a Data Science](#DS_onstart)\n   * [2.1 Can you get a formal education](#education)\n* [3. Technical Skills Required](#Skills)\n   * [3.1. Programming Skills](#Programming)\n   * [3.2. Data Visualization Skills](#visual_skills)\n   * [3.3. Machine Learning Skills](#ml_skills)\n   * [3.4. Cloud Computing Skills](#c_computing)\n   * [3.5. Big Data Skills](#Bdata_skills)\n* [4. Soft Skills Required](#soft_skills)\n* [5. Where to Learn Data Science ](#learning)\n* [6. Where to Get Daily Updates For Data Science](#Motivation)\n* [7. Conclusion](#conclusion)\n* [8. Reference](#reference)\n","ff54230f":"  So if you want to stand out from other data scientist, you need to know machine learning techniques. **machine learning** is use to build **predictive models**, for example you want to predict the amount of sales you will have in the next month by looking at the past month's data, you will need to use machine learning algorithms\nthese skills will help you to solve different data science problems that are based on **predictions** for major **organisational outcomes**.\n\nso let's look at **the top 3 most used machine learning techniques** by kagglers","2613bcd3":"### III. Machine learning Skills:\n<a id = 'ml_skills'><\/a>\nFor a **data scientist**, **Machine leaning** is the **most important skills** to have, a large amount number of data scientist are **not proficiencts** in **machine learning** areas and techniques. Lets prove this point by looking at the question that says **For how many years have you used machine learning methods?** i am going to classify those with <1-2 years of ML methods as **not proficient in ML** and above 2-20 years as **proficient in ML**","bc063b76":"As the above plot shows, the **top 3 machine leaning techniques** used by kagglers range from the **simpler technioques** to **advance level technigues**, which are;\n1. Linear or Loogistic Regression\n2. Decision Trees or Random Forest\n3. Gradient Boosting Machines\n\nwhile having expert level knowledge in the area isn't always naccessary **for beginners**, a level of familiarity will be expected\n\nMachine learning relies on Algorithms, Unless you are a data scientist or ML Expert, these algorithms are very complicated to understand and work with\n\nA **machine learning framework**, then simplifies **machine learning algorithms**, A machine learning framework is any tool, interface, or library that lets you develop machine learning models easily, without understanding the underlying algorithms. there are varieties of machine learning frameworks geared at different purposes.\n\nNow let's take a look at the **top 3 most used machine learning frameworks** by kagglers.\n\n","41a762f5":"as we go through the above plot the **top 3 most used data visualization libraries** used by kagglers are;\n1. Matplotlib\n2. Seaborn\n3. Plotly\n\nSo it will be promising to get familiar with the 3, but as a beginner you can start with Matplotlib because it was the first python data visualization library, many other libraries are built on top of it or design work together with it during analysis, even some of the libraries like **Pandas** and **Seaborn** are wrappers over **matplotlib**. they allow you to access a number of matplotlib's method with less code.\n let's go to the Business Intelligence tools","2fd03af3":"### Careers in Data Science\n<a id = 'career_Ds'><\/a>\nMajority of People think's that starting a career in data science is all about being a data scientist, but actually there are other specializations. So, if you are starting a career in data science it's important for you to be familiar with other areas in the field.<br>\nNow let's take a look at the careers or roles played by kagglers in the Survey.","1a49ceb3":"As the above plot shows, data scientist have very significant salary. As a data scientist you can earn morethan $100K annually on average, although data scientist salary mostly depends on some certain factors which are;\n1. Experiance \n2. Industry \n3. Location\n4. Companies\n5. Skills\n\nThese factors determines what you can earn as a data scientist. you can check [here](https:\/\/www.projectpro.io\/article\/data-scientist-salary-the-ultimate-guide-for-2021\/218) to find how these factors can affect your salary as a data scientist","0d60d7ab":"### I. Can you have a university degree?\n<a id = 'education'><\/a>","9ee167a1":"## 8. Reference\n<a id = 'reference'><\/a>","fa2a8ae8":"## Introduction\nLearning Data science can be intimidating especially when you are just starting your journey. I felt the same way because when i started learning data science i was just going through processes without even knowing where i am going, i thought becoming professional in python programming and machine learning is the best way to start. but then, i suddently reliaze that i am wrong you can't just be a professional in a short period of time, professionality comes with great experience. Therefore, as a beginner on my career path, all i need was a level of familiarity not becoming a professional. which tools to learn, what techniques to focused on, will be a good question.\nThat is why i thought that i could create this guide which could help Beginners starting on data science field.\n\nSo, in this notebook, with the aid of **Kaggle Data science survey which present a comprehensive view of the state of data science and machine learning the survey was live from 09\/01\/2021 which took one month and end up with 25,973 responses. the result include raw numbers about who is working with data, what happening with machine learning in different industries, and the best way for new data scientist to break into the field.** I will like to **highlight some steps and techniques for beginners to learn** in other to make the learning processes easier and the journey to be straightforward for them. I will also cover some important aspects in the field of data science itself, what is data science, Future of data science and careers or roles in the field , by going through the responses provided by kagglers on the survey. at the meantime i will be using a simple **Bar chart for visualization** to show some useful information.\n\nbefore we start lets's know something about Kaggle\n\nWhat is Kaggle: kaggle is an **online community of data scientist and machine learning practitioners**. kaggle allows users to find and publish a data sets, explore and build models in a web-based data science enviroment, work with other data scientist and machine learning engineers,\n\nLet's get started!","3eb489f9":"The plot above illustrate, Suprisingly the **top 3** with the **highest vote** for **most enjoyable to use** are also the **most used** cloud computing platforms by kagglers. which are;\n1. Amazon Web Services (AWS) as **1st place**\n2. Google Cloud Platforms as **2nd place**\n3. Microsoft Azurea as **3rd place**\n\nAs you can see there are many cloud computing Platforms as well and it's not that easy to be familiar with all the product so, here i will **suggest this top 3** and maybe as a beginner you can start with **Amazon Web Service(AWS)**, which get the first place with highest vote and also for its benefits which includes: **ease of use**, **diverse array of tools**, **unlimited service capacity**, **reliable encryption and security**, and **affordability**\nand it currently support **over 2,000 government agencies** and **5,000 educational institutions**\n\n","951fdf80":"## 4. Soft Skills Required\n<a id = 'soft_skills'><\/a>\n\nIf you really wants to suceed as a data scientist you will need to have also ensure that you have the set of soft skills. these skills are not tough, nor are they listed on most data science courses. the skill are:\n1. Skepticism\n2. Perseverance\n3. Creativity\n4. Business Acumen\n5. Communication\n\nSo, if you really wants to know more about the soft skills meantioned above you can click in [here](https:\/\/towardsdatascience.com\/soft-skills-for-data-science-fee73ae4821a) for more information and guides on how to get them.","7c0dd2dc":"### V. Big data products skills:\n<a id = 'Bdata_skills'><\/a>\n\nBig data typically refers to extremely large data sets that requires specialize and often innovative technologies and techniques.\nData science required data to be stored in easily, accesible and analyzable way even though databases are considered to be most convinient method for data science. A database is structure collection of data of multinational corporation. there are many software and database technologies, these database technologies includes, **database management system (DBMS)**, **Relational database management system (RDBMS)**. and there were the most widely used database system for a long term, there are generally good for transation-based operations and adhering to the **ACID principles** which stands for **Atomicity, Consistency, Isolation, Durability** in general, in order to add, access the data stored in a database, we need this database technologies\/ database managemant system Skills.\n\nlet's look at the **top 3 most use** database management skills or Big data product by Kagglers according to there responses on big data.","d00f3222":"the plot shows that the top 3 most use means of learning data science are:\n1. Coursera\n2. Kaggle\n3. Udemy\n\naccording to [tkubacka](https:\/\/www.kaggle.com\/tkubacka) 1st place winner of the [2019 Kaggle ML & DS Survey](https:\/\/www.kaggle.com\/c\/kaggle-survey-2019\/discussion\/121041) Challenge with her notebook [who codes what and how long- a story told through a heatmap](https:\/\/www.kaggle.com\/tkubacka\/a-story-told-through-a-heatmap). she made analysis on her notebook which says\n**people using kaggle coursera and udemy tend to start thier ML and coding adventure**\nSo, this is a good news for a beginners wanting to start learning data science. but not sure of which online learning platform to use.\n","0c75243a":"## 7. Conclusion\n<a id = 'conclusion'><\/a>\n\nYour data science journey has only begins, there is so much to learn in the field of data science that it would take morethan a lifetime to master, just remember you dont have to be professional to start your data science career, you just had to have some level of familiarity and get started.\n\nas the notebook shows the steps to follow and the skills you need to start your data science career. i did the best i could to bring out some useful information from the survey data even though i'm still  beginner and learning in the field i will not be so perfect.\nBut i hope my little insights will help new data scientist in there career path. and the specialize skills listed above may one day helps you to solve data science problems. However, you don't need to master all these skills to begin your career in data science you can begin today.\n\ni hope you had an interesting time reading about my work and my insights. i also hope to inspired you to search for other  data science skills more especially the soft skills that i don't disccused much in the notebook.\n \n thanks a lot to  to Kaggle team for letting us use this great dataset!. and thanks to other participants of the competition for their insights.","76246674":"If you are thinking about becoming a data scientist and wondering what is a data science salary you could expect to earn.\nthe fact that we are using kaggle survey for the analysis.\nSo, let's look at what kagglers earn annually","8506dbf3":"As the plot above shows, data science are highly educated. Approximately **94% have a University Degree** with 45.1% masters, 31.7% bachelors, 14.7% Doctoral and 1.9% professional doctorates while there are notable exceptions(those without degree) which are the **remaining 6%**. Therefore, very strong educational background is usually required to develop the in-depth of knowledge necessary to be a data scientist. As a beginner you need to start with Bachelors Degree programme. To become a data scientist, below are some of the [bachelors degree programmes in data science](https:\/\/www.coursera.org\/articles\/what-degree-do-i-need-to-become-a-data-analyst):\n1. Data science \n2. Computer science\n3. Applied mathematics, or statistics\n4. Finance\/economics\n5. Psychology\n6. Management information system(MIS)\n\nA degree in any of these courses will give you the basic skills you need to process and analyze big data, these skills may include Linear algebra, statistics, calculus, probability distribution, etc. after a degree programme, you are not done yet, the truth is that most data scientist have a masters degree . therefore, you can enroll for a masters degree program in the field of data science, mathematics, Astrophysics or any other related field, the skills you learn during your degree programme will enable you to easily transition to data science\n","c3dbe90e":"as the above plot show's, the **top 3 most used Big data products** by kagglers response are;\n1. MySQL\n2. PostgreSQL\n3. Microsoft SQL Sever.\n\nBoth **MySQL** and **PostgreSQL** are time-proven solutions that can compete with enterprise solution such as **Oracle** and **Miscrosoft SQL Server**.\n**MySQL** has been famous for its ease of use and speed, while **postgreSQL** is often described as an open-source version of Oracle.\nSo, as a **Beginner in data science** i will strongly **suggest MySQL** for you to start with, for it's ease of use and speed.\n","27c4648e":"As the above plot shows, the **top 3 most used Cloud computing platforms** by kagglers which are as well the **most popular Cloud computing platforms in the world.** there are;\n1. Amazon Web Services(AWS)\n2. Google cloud Platform(GCP)\n3. Microsoft Azure.\n\n\nso with the aid of a question that was asked in the survey which says **\"Of the cloud platforms that you are familiar with, which has the best developer experience (most enjoyable to use)?\"**. i can use the top 3 with the highest vote and compare them with the most used to end up with **a good suggestion** \n\nLet's look at he winners.","c3526bba":"###  IV. Cloud Computing Skills \n<a id = 'c_computing'><\/a>\nWithout cloud computing it will be impossible for data scientist and machine learning engineers to train some of the large **deep learning models** that exist today. \n**Cloud computing** is the delivery of an on-demand computing service from applications to storege and processing power, typically over the internet and on a [pay-as-yo-go](https:\/\/searchstorage.techtarget.com\/definition\/pay-as-you-go-cloud-computing-PAYG-cloud-computing?amp=1) basis, and it's fast replacing centralized systems in terms of both data storage and computing power. Data scientists need to be familiar with using the products offered by cloud services for their daily tasks with data such as examination of data, visualization and other tasks. \nthere is ton's of cloud computing services to choose from, but selecting the right one come's down to factors such as **manageability, security concern, costumer service support, software dependencies and more.**\n\nNow i'm going through kagglers responses to see **the top 3 most use Cloud computing platforms**\n","a7f9e5c9":"as the plot shows, Kaggle is the most used online community for reports and motivation in data science followed by Youtube and Blogs","5ddf105a":"## 3. Technical Skills Required\n<a id = 'Skills'><\/a>\nTo become a data scientist you need to have some relevant technical skills which may include programming skills, data visualization skills Machine learning skills, Cloud computing skills and big data skills.","5b7dd760":"### II. Data Visualization Skills\n<a id = 'visual_skills'><\/a>\n\nThe business world produces a vast amounts of data frequently. This data needs to be translated into a format that will be easy to comprehend. People naturally understand pictures in forms of charts and graphs more than raw data.  Data visualization is one of the most on-demand skills in today's data-centric world.\nas a data scientist you must be able to visualize data with the aid of data visualization libraries or tools, these tools will help you to convert complex result from your project to a format that will be easy to comprehend. \n**Data visualization** gives organisation the oppurtunity to work with data directly. they can Quickly grasp insights that will help them to act on new business opportunities and stay ahead of competitions\n\nlet's explore through the kaggle data science survey and find out which visualization tools used by data scientists and the most frequent tool to recommend, although we have to different questions asked about visualization tools which are the data visualization tools and the business inteligence tools used by kagglers, which are all use to visualize data but we will soon find the difference between them.\n\nLets's dive in and look at these tools and libraries","3c41d79b":"### Who is Data Scientist?\n<a id = 'whos_DS'><\/a>\nHere i will use the kagglers responses on the question that was asked about **the activities that make up an important part of your role at work** to describe who a data scientist is. Now let's analyse the responses and draw our description.","36171613":"As we may see from the plot above, there are alot of Business Intelligence tools, and the **top 3 most use** BI tools by kagglers are;\n1. Tableau\n2. Microsoft PowerBI\n3. Google Data Studio. \n\nit will be helpful to be familier with at least one of them.\n","3ec79833":"### I. Programming Skills\n<a id = 'Programming'><\/a>\nProgramming skills in data science brings together all the foundation skills needed to transform raw data into actionable insights. its also teaches you how to write code to analyze and work with data.\nSo, its promising as a data science to have strong programming skills.\n","3b6ffca1":"As we can see there are **13 job roles played** by the respondants while the top 3 roles with high percentage of responses are \n1. Data scientist\n2. Software Engineer\n3. Data Analyst\n\n**Note: <i>this question was answered on Select choice pattern, which means you can only select what is provided on the list of suggested answers. So, those that select Other couldn't find their respective role in the list stated<\/i>.** So, we exclude the **Other** option in the top 3 because we don't actually know which role it is\n\nAccording to [LinkedIn 2021 report for job on the rise](https:\/\/www.linkedin.com\/pulse\/linkedin-jobs-rise-15-opportunities-demand-hiring-now-andrew-seaman), rising for data science and machine learning job roles gone by 44% and 32% respectively since 2019. incoming data scientist and machine learning engineers can expect higher data scientist salary in line with the increasing accelerate their digital transformation process in the post-COVID-19 recovery to hire more data scientist and machine learning engineers"}}