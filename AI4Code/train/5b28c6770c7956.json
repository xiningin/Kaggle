{"cell_type":{"e54946e0":"code","d0aef0ea":"code","1d52529b":"code","598e3b79":"code","857bd141":"code","fb1685cf":"code","80d5481c":"code","9357da23":"code","37ce24c2":"code","62b2a77a":"code","2c16bce6":"code","3ec189e3":"code","fe10ba39":"code","df28841d":"code","9601485e":"code","71220a30":"code","62f0eccf":"markdown","16d4c0d9":"markdown","a03b5ae0":"markdown","460fbd58":"markdown","b64c9a01":"markdown","05cc0eab":"markdown","c0055d18":"markdown","8c412220":"markdown","2acb74c2":"markdown","bb0169a0":"markdown"},"source":{"e54946e0":"train_csv = '..\/input\/feedback-prize-2021\/train.csv'\nsample_submission_csv = '..\/input\/feedback-prize-2021\/sample_submission.csv'","d0aef0ea":"import numpy as np\nimport pandas as pd","1d52529b":"train = pd.read_csv(train_csv)","598e3b79":"train.head(5)","857bd141":"train.isnull()","fb1685cf":"train.isnull().sum()","80d5481c":"train.dtypes","9357da23":"train.shape","37ce24c2":"train.info()","62b2a77a":"from pandas_profiling import ProfileReport","2c16bce6":"profile_train = ProfileReport(train,title=\"Train Profiling Report\")\nprofile_train.to_file(\"Train Profiling Report.html\")\nprofile_train","3ec189e3":"# !pip install autoviz -q","fe10ba39":"from autoviz.AutoViz_Class import AutoViz_Class\nAV = AutoViz_Class()\n#Automatically produce dataset\nAV.AutoViz(\"\",dfte = train )","df28841d":"! pip install sweetviz","9601485e":"import sweetviz as sv\nsweet_report = sv.analyze(train)\nsweet_report.show_html('sweet_report.html')","71220a30":"# from IPython.display import HTML\n# HTML(filename='.\/sweet_report.html')","62f0eccf":"# Autoviz","16d4c0d9":"**One more way**: Using Sweetviz\nThere is one more additional way using which you can visualize the data however I don't think it is relevant for this data anyways you can use it for another datasets","a03b5ae0":"# Sweetviz","460fbd58":"![image.png](attachment:9351b66e-63ac-4030-a5d4-64e6fb8c6ab5.png)\n![image.png](attachment:6e8535c6-879c-4031-af2c-4d5be8798527.png)\n![image.png](attachment:512afcb5-9220-458c-ba28-c52bf92b3f92.png)","b64c9a01":"# ProfileReport","05cc0eab":"# Data visualization using two easy ways\n1. Using ProfileReport from pandas_profiling library\n2. Using AutoViz\n\n**ProfileReport**\nFor each column the following statistics - if relevant for the column type - are presented in an interactive HTML report:\n\nType inference: detect the types of columns in a dataframe.\nEssentials: type, unique values, missing values\nQuantile statistics like minimum value, Q1, median, Q3, maximum, range, interquartile range\nDescriptive statistics like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness\nMost frequent values\nHistogram\nCorrelations highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices\nMissing values matrix, count, heatmap and dendrogram of missing values\nText analysis learn about categories (Uppercase, Space), scripts (Latin, Cyrillic) and blocks (ASCII) of text data.\nFile and Image analysis extract file sizes, creation dates and dimensions and scan for truncated images or those containing EXIF information.\n\n**Autoviz**\n\nAutomatically visualize any dataset, and it mainly works on visualizing the relationship of the data, it can find the most impactful features and plot creative visualization in just one line of code. Autoviz is incredibly fast and highly useful.\n\nIn Autoviz, a single line of code can identify features and create meaningful plots for you.\n\n","c0055d18":"Check out the References to know more about each of them:\n\nhttps:\/\/pandas-profiling.github.io\/pandas-profiling\/docs\/master\/index.html\n\n\nhttps:\/\/www.journaldev.com\/52615\/autoviz-module-in-python\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2021\/01\/making-exploratory-data-analysis-sweeter-with-sweetviz-2-0\/\n\n","8c412220":"Below are the screenshots of the html file generated, you can see it by downloading the sweet_report.html file in the Output file\n\n\nSweetviz is a python library that focuses on exploring the data with the help of beautiful and high-density visualizations. It not only automates the EDA but is also used for comparing datasets and drawing inferences from it.","2acb74c2":"# **Data Description**\n\nThe dataset contains argumentative essays written by U.S students in grades 6-12. The essays were annotated by expert raters for elements commonly found in argumentative writing.\n\nNote that this is a code competition, in which you will submit code that will be run against an unseen test set. The unseen test set is approximately 10k documents. A small public test sample has been provided for testing your notebooks.\n\nYour task is to predict the human annotations. You will first need to segment each essay into discrete rhetorical and argumentative elements (i.e., discourse elements) and then classify each element as one of the following:\n\nLead - an introduction that begins with a statistic, a quotation, a description, or some other device to grab the reader\u2019s attention and point toward the thesis\nPosition - an opinion or conclusion on the main question\nClaim - a claim that supports the position\nCounterclaim - a claim that refutes another claim or gives an opposing reason to the position\nRebuttal - a claim that refutes a counterclaim\nEvidence - ideas or examples that support claims, counterclaims, or rebuttals.\nConcluding Statement - a concluding statement that restates the claims\nThe training set will consist of individual essays in a folder of .txt files, as well as a .csv file containing the annotated version of these essays. It is important to note that some parts of the essays will be unannotated (i.e., they do not fit into one of the classifications above).\n\nFiles\n\ntrain.zip - folder of individual .txt files, with each file containing the full text of an essay response in the training set\ntrain.csv - a .csv file containing the annotated version of all essays in the training set\nid - ID code for essay response\ndiscourse_id - ID code for discourse element\ndiscourse_start - character position where discourse element begins in the essay response\ndiscourse_end - character position where discourse element ends in the essay response\ndiscourse_text - text of discourse element\ndiscourse_type - classification of discourse element\ndiscourse_type_num - enumerated class label of discourse element\npredictionstring - the word indices of the training sample, as required for predictions\ntest.zip - folder of individual .txt files, with each file containing the full text of an essay response in the test set\nsample_submission.csv - file in the required format for making predictions - note that if you are making multiple predictions for a document, submit multiple rows\n","bb0169a0":"# About the dataset\nWriting is a critical skill for success. However, less than a third of high school seniors are proficient writers, according to the National Assessment of Educational Progress. Unfortunately, low-income, Black, and Hispanic students fare even worse, with less than 15 percent demonstrating writing proficiency. One way to help students improve their writing is via automated feedback tools, which evaluate student writing and provide personalized feedback.\n\nThere are currently numerous automated writing feedback tools, but they all have limitations. Many often fail to identify writing structures, such as thesis statements and support for claims, in essays or do not do so thoroughly. Additionally, the majority of the available tools are proprietary, with algorithms and feature claims that cannot be independently backed up. More importantly, many of these writing tools are inaccessible to educators because of their cost. This problem is compounded for under-serviced schools which serve a disproportionate number of students of color and from low-income backgrounds. In short, the field of automated writing feedback is ripe for innovation that could help democratize education.\n\nGeorgia State University (GSU) is an undergraduate and graduate urban public research institution in Atlanta. U.S. News & World Report ranked GSU as one of the most innovative universities in the nation. GSU awards more bachelor\u2019s degrees to African-Americans than any other non-profit college or university in the country. GSU and The Learning Agency Lab, an independent nonprofit based in Arizona, are focused on developing science of learning-based tools and programs for social good.\n\nIn this competition, you\u2019ll identify elements in student writing. More specifically, you will automatically segment texts and classify argumentative and rhetorical elements in essays written by 6th-12th grade students. You'll have access to the largest dataset of student writing ever released in order to test your skills in natural language processing, a fast-growing area of data science.\n\n![image.png](attachment:58af3e8d-4ead-4717-a7a5-07669e7886f9.png)\n\nIf successful, you'll make it easier for students to receive feedback on their writing and increase opportunities to improve writing outcomes. Virtual writing tutors and automated writing systems can leverage these algorithms while teachers may use them to reduce grading time. The open-sourced algorithms you come up with will allow any educational organization to better help young writers develop."}}