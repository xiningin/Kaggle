{"cell_type":{"4f6d3abf":"code","b6efc546":"code","c28899b5":"code","3b09c35b":"code","f6152198":"code","b534749b":"code","dd4699c5":"code","0d7d4709":"code","d9e57c09":"code","36e7be64":"code","7e2e619a":"code","d037490d":"code","e78029e2":"code","05acf0ac":"markdown"},"source":{"4f6d3abf":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n%matplotlib inline","b6efc546":"# Parameters\nforecast_range = 28 # days\ninput_dir = '\/kaggle\/input\/m5-forecasting-accuracy'","c28899b5":"# Helper functions\ndef plot_time_series(data, ax=None, show=False):\n    \"\"\"Plot time series data.\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n    for ind in data.index:\n        ax.plot([int(col.split('_')[-1]) for col in data.columns], \n                data.loc[ind].values, '-', label=ind)\n    ax.legend(loc='best')\n    ax.set_xlabel('day number')\n    ax.set_ylabel('items sold')\n    if show:\n        plt.show(block=False)\n\ndef plot_aggregation(data):\n    \"\"\"Make plots over two time periods.\"\"\"\n    plot_time_series(data)\n    plot_time_series(data[data.columns[-3*28:]])","3b09c35b":"# Load data\nprint('Loading data...')\nsell_price = pd.read_csv('%s\/sell_prices.csv' % input_dir)\ncalendar = pd.read_csv('%s\/calendar.csv' % input_dir)\ntrain = pd.read_csv('%s\/sales_train_validation.csv' % input_dir).set_index('id')\nsample_sub = pd.read_csv('%s\/sample_submission.csv' % input_dir)\n\n# Get column groups\ncat_cols = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\nts_cols = [col for col in train.columns if col not in cat_cols]\nts_dict = {t: int(t[2:]) for t in ts_cols}\n\n# Describe data\nprint('  unique forecasts: %i' % train.shape[0])\nfor col in cat_cols:\n    print('   N_unique %s: %i' % (col, train[col].nunique()))\n","f6152198":"# 1. All products, all stores, all states (1 series)\nall_sales = pd.DataFrame(train[ts_cols].sum(axis=0)).transpose()\nall_sales.index = ['all']\nplot_aggregation(all_sales)","b534749b":"# 2. All products by state (3 series)\nstate_sales = train.groupby('state_id')[ts_cols].sum(axis=0)\nplot_aggregation(state_sales)","dd4699c5":"# 3. All products by store (10 series)\nstore_sales = train.groupby('store_id')[ts_cols].sum(axis=0)\nplot_aggregation(store_sales)","0d7d4709":"# 4. All products by category (3 series)\ncat_sales = train.groupby('cat_id')[ts_cols].sum(axis=0)\nplot_aggregation(cat_sales)","d9e57c09":"# 5. All products by department (7 series)\ndept_sales = train.groupby('dept_id')[ts_cols].sum(axis=0)\nplot_aggregation(dept_sales)","36e7be64":"# 6. All products by state and category (9 series)\nstate_cat_sales = train.groupby(['state_id', 'cat_id'])[ts_cols].sum(axis=0)\nplot_aggregation(state_cat_sales)","7e2e619a":"# 7. All products by state and category (21 series)\nstate_dept_sales = train.groupby(['state_id', 'cat_id'])[ts_cols].sum(axis=0)\nplot_aggregation(state_dept_sales)","d037490d":"# 8. All products by store and category (30 series)\nstore_cat_sales = train.groupby(['store_id', 'cat_id'])[ts_cols].sum(axis=0)\nplot_aggregation(store_cat_sales)","e78029e2":"# 9. All products by store and department (70 series)\nstore_dept_sales = train.groupby(['store_id', 'dept_id'])[ts_cols].sum(axis=0)\nplot_aggregation(store_dept_sales)","05acf0ac":"## EDA for Sales Aggregations\n\nA careful examination of the cost function reveals that each level of the hierarchy is equally weighted.  Thus, the all-product\/all-state\/all-store forecast alone is equally as important as all of the individual item sales per store forecasts put together.  Similarly, the per-store, per-category, per-item, and per-state forecasts (and their combinations) are very heavily weighted.\n\nThis EDA plots these \"sales aggregations\", so we may better understand the forecasting task before us.  For each aggregation (#1-#9 in the M5 contest document), the entire series is plotted, as well as the last 12 week period."}}