{"cell_type":{"00ddba4b":"code","1dfe6381":"code","0db9f0b7":"code","11807d82":"code","04c186c2":"code","d6367005":"code","5189ab69":"code","0c9c7956":"code","ff936da1":"code","2b89f0dd":"code","0fcacebc":"code","e1fd3574":"code","8680681a":"code","695e9316":"code","f70be7c7":"code","8bbb4ad6":"code","305bd84e":"code","5a8c365b":"markdown","d51a74f2":"markdown","c6ddb686":"markdown","d39ce923":"markdown","e10c78c6":"markdown","d8e8c344":"markdown","8d43cd85":"markdown","72679498":"markdown","51d9d686":"markdown","3b149c50":"markdown","76be7362":"markdown","1d71334f":"markdown"},"source":{"00ddba4b":"# libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold, cross_validate, train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport lightgbm as lgb\nfrom time import time\nfrom scipy import stats","1dfe6381":"# CONFIGURATION\nPATH_TO_TRAIN_SET = '..\/input\/tabular-playground-series-jun-2021\/train.csv'\nPATH_TO_TEST_SET = '..\/input\/tabular-playground-series-jun-2021\/test.csv'\nRANDOM_STATE = 6\nTARGET = 'target'\nK = 10","0db9f0b7":"# Utils\ndef load_data():\n    \"\"\" load data to build the model and submission data on which to make predictions \"\"\"\n    X_all = pd.read_csv(PATH_TO_TRAIN_SET) # data for model development (train set + val sets )\n    X_sub = pd.read_csv(PATH_TO_TEST_SET) # data for prediction to submit on kaggle\n    return X_all, X_sub\n\n# Preprocessing Functions\ndef baseline_preprocessing(X_all, X_sub):\n    \n    # extract target\n    y_all = X_all[TARGET].copy()\n    \n    # drop id and target columns for model inputs\n    X_all = X_all.drop(['id', TARGET], axis=1)\n    X_sub = X_sub.drop('id', axis=1)\n    \n    return X_all, X_sub, y_all","11807d82":"# load and preprocess the data\nX_all, X_sub = load_data()\nsub_idx = X_sub['id']\nX_all, X_sub, y_all = baseline_preprocessing(X_all, X_sub)","04c186c2":"# model\nmodel = lgb.LGBMClassifier(random_state=RANDOM_STATE, n_estimators=50)\n\n# K-Fold Cross-Validation\nkf = KFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)","d6367005":"# estimate generalization error\nclf =  cross_validate(model,\n                      X_all,\n                      y_all,\n                      scoring='neg_log_loss',\n                      return_train_score=True,\n                      cv=kf,\n                      n_jobs=-1)","5189ab69":"clf['train_score'].mean()","0c9c7956":"# print elapsed time\nprint(\"Elapsed time:\", round(clf['fit_time'].sum(),3), \"s\\n\")\n\n# print expected test score\nprint(\"Min  score:\", clf['test_score'].mean() - np.std(clf['test_score'], ddof=1))\nprint(\"Mean score:\", clf['test_score'].mean())\nprint(\"Max  score:\", clf['test_score'].mean() + np.std(clf['test_score'], ddof=1))","ff936da1":"# model\nmodel = lgb.LGBMClassifier(random_state=RANDOM_STATE, n_estimators=50)\n\n# specify cross validation scheme\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n\n# estimate generalization error\nclf =  cross_validate(model,\n                      X_all,\n                      y_all,\n                      scoring='neg_log_loss',\n                      return_train_score=True,\n                      cv=skf,\n                      n_jobs=-1)","2b89f0dd":"# print elapsed time\nprint(\"Elapsed time:\", round(clf['fit_time'].sum(),3), \"s\\n\")\n\n# print expected test score\nprint(\"Min  score:\", clf['test_score'].mean() - np.std(clf['test_score'], ddof=1))\nprint(\"Mean score:\", clf['test_score'].mean())\nprint(\"Max  score:\", clf['test_score'].mean() + np.std(clf['test_score'], ddof=1))","0fcacebc":"# model initialisation\nLGBMC = lgb.LGBMClassifier(random_state=RANDOM_STATE)\n\n# cross validation scheme\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n\n# hyperparameter space\nparam_grid = dict(n_estimators=stats.randint(10, 200),\n                  max_depth=[-1, 2, 4, 8, 16, 32],\n                  num_leaves=stats.randint(2,50),\n                 )\n\n# set up the search\nsearch =  RandomizedSearchCV(LGBMC,\n                            param_grid,\n                            scoring='neg_log_loss',\n                            return_train_score=True,\n                            cv=skf,\n                            refit=True,\n                            n_jobs=-1,\n                            n_iter=20,\n                            verbose=2,\n                            random_state=RANDOM_STATE)\n\n# find the best hyperparameters\nsearch.fit(X_all, y_all)","e1fd3574":"print(\"best score:\", search.best_score_, \"\\n\")\nprint(\"best params:\\n\", search.best_params_)","8680681a":"results = pd.DataFrame(search.cv_results_)\nprint(results.shape)\nresults.columns","695e9316":"# we can sort the models based on performances and only keep keys columns for readibility purpose\nresults.sort_values(by='mean_test_score', ascending=False, inplace=True)\nresults.reset_index(drop=True, inplace=True)\nresults[['mean_fit_time', 'std_fit_time','param_max_depth', 'param_n_estimators', 'param_num_leaves', 'mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score']].head(10)","f70be7c7":"y_pred_sub = search.predict_proba(X_sub)","8bbb4ad6":"sub_idx_array = sub_idx.to_numpy()\nsub_idx_array = sub_idx_array.reshape(-1, 1)\nDATA = np.concatenate((sub_idx_array, y_pred_sub), axis=1)\nsub_columns = ['id','Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']","305bd84e":"my_submission = pd.DataFrame(data=DATA, columns=sub_columns)\nmy_submission['id']=my_submission['id'].astype('int')\nmy_submission.to_csv(\"submissionCV.csv\", index=False)","5a8c365b":"## Repeated K-Fold Cross-Validation\n- This just repeats the KFold Cross-Validation `n` times, each times making a different, randomized data split\n- Before each of the `n` split into `k` folds, the training set is suffled\n- As a result, we obtain `k x n` performance metrics\n- Warnings: there could be overlap between the validation sets in different repeats.","d51a74f2":"## K-Fold Cross-Validation\n- We divide the train set into `k` folds of equal size\n- The model is trained on `k-1` folds and validated on the `kth` fold\n- We obtain `k` performance values one for each fold\n- Final performance metric is mean of the performance for each fold +\/- standard deviation\n\nTypical `k` are 5 or 10.\n- Use 5 if your are short on the computational resources, typically at beginning of the model development lifecycle\n- Use 10 if you can afford the computational cost, if you need tighter confidence intervals around the model performance metric. Typically used when you need to carefully evaluate your model performances, and standard in most notebooks for machine learning competitions.\n\n**With higher `k`:**\n- You get bigger train sets which enables you to reduce model bias\n- You get more variance since the model may start to fit the noise in the data","c6ddb686":"## Predict and Submit","d39ce923":"**Takeaway 1**\n> As baseline when starting out a kaggle competition, I recommend you to use K-Fold Cross Validation with `k = 10`, or Stratified K-Fold if you are working an highly imbalanced dataset.","e10c78c6":"We can see that the margin of error around the mean performance metric is tighter, this is because when using stratified KFold the proportion of classes are kept similar between each fold. This is much better to estimate the generalisation error of the model.\n\n**Stratified KFold is used in the remaining of the notebook**","d8e8c344":"## Stratified KFold Cross-Validation","8d43cd85":"## Stratified K-Fold Cross-Validation\n- Only used for classification problems\n- Procedure is identical to K-Fold Cross Validation\n- It is useful with highly imbalanced datasets, because it ensures that each fold has a similar proportion of observations for each class\n- Your also get `k` performance metrics\n- No overlap of validation sets","72679498":"There are other cross-validation schemes such as LeaveOneOut or LeavePOut but they are excessively computationaly expensive.","51d9d686":"## KFold Cross-Validation","3b149c50":"# Demo","76be7362":"### Simple Hyperparameters Tuning using Stratified KFold Cross-Validation","1d71334f":"## Why should you care about Cross-Validation?\nThere are three main reasons why a clean and robust cross-validation will help:\n1. To estimate the generalization error of a given model\n2. To select the best performing model from a group of models\n3. To select the best hyperparameters for your model"}}