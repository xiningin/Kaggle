{"cell_type":{"f01bbda2":"code","e6771428":"code","cd5c552e":"code","01aa433c":"code","d933cdb4":"code","c308f79a":"code","a20bc835":"code","23910084":"code","6672100f":"code","002c3a80":"code","2ff021ff":"code","c16f424a":"code","90379519":"code","f781defe":"code","7f900a2b":"code","f990788e":"code","7651636d":"code","05efc531":"code","1aec1f54":"code","070de940":"code","ca539db0":"code","75340f4c":"code","9996583f":"code","578bac52":"code","f3e5fce0":"code","2c6c2ef8":"code","cd0ef292":"code","6a098766":"code","56c1cbab":"code","7c15f315":"code","1ca6e5fb":"code","17a842df":"code","21940caa":"code","eb62c7be":"code","2e4742ec":"markdown","379c220f":"markdown","774a4cf4":"markdown","9b751bb2":"markdown","113c063c":"markdown","1ce1a99c":"markdown","b6798a11":"markdown","f0ce4a2e":"markdown","512f2827":"markdown","cbe4fc27":"markdown","7be1a3de":"markdown","431a9333":"markdown","12fd1e28":"markdown","28ad43a1":"markdown","36d96726":"markdown","d2c82814":"markdown","dd33c27d":"markdown","23c67af0":"markdown","d787480f":"markdown","c9ce632d":"markdown","b6f0f6ad":"markdown","3973974b":"markdown","1f0030cd":"markdown","51626bcb":"markdown","b5efeaaa":"markdown","f035be6d":"markdown","0fbd1ac1":"markdown","3b144815":"markdown","1c19003a":"markdown","13634d9e":"markdown","cad248d3":"markdown"},"source":{"f01bbda2":"import os \n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn\nimport matplotlib.mlab as mlab\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, mean_squared_error as MSE\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\n\n\n\n# Settings\nimport matplotlib\nmatplotlib.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (8.5, 5)\nplt.rcParams[\"patch.force_edgecolor\"] = True\npd.set_option('display.float_format', lambda x: '%.3f' % x)\nsns.mpl.rc(\"figure\", figsize=(8.5,5))\n\n\n%matplotlib inline","e6771428":"import os\n\ntrain = pd.read_csv ('..\/input\/train.csv')\ntest = pd.read_csv ('..\/input\/test.csv')\n\ntrain.head(2)","cd5c552e":"print(train.shape);\n","01aa433c":"train.info()","d933cdb4":"#### we have no missing value in our data set. \ntrain.isna().sum()","c308f79a":"train.describe().transpose()","a20bc835":"train = train[train['passenger_count']>0]\ntrain = train[train['passenger_count']<9]","23910084":"#Pro-processing Pickup cordinates\ntrain = train[train['pickup_longitude'] <= -73.75]\ntrain = train[train['pickup_longitude'] >= -74.03]\ntrain = train[train['pickup_latitude'] <= 40.85]\ntrain = train[train['pickup_latitude'] >= 40.63]\n\n\n#Pro-processing dropoff cordinates \ntrain = train[train['dropoff_longitude'] <= -73.75]\ntrain = train[train['dropoff_longitude'] >= -74.03]\ntrain = train[train['dropoff_latitude'] <= 40.85]\ntrain = train[train['dropoff_latitude'] >= 40.63]","6672100f":"#Pre-processing trip duration \ntrip_duration_mean = np.mean(train['trip_duration'])\ntrip_duration_std = np.std(train['trip_duration'])\ntrain = train[train['trip_duration']<=trip_duration_mean + 2*trip_duration_std]\ntrain = train[train['trip_duration']>= trip_duration_mean - 2*trip_duration_std]","002c3a80":"# Confirm removal\ntrain.describe().transpose()","2ff021ff":"# Pickups\ntrain['pickup_datetime'] = pd.to_datetime(train['pickup_datetime']) \n\n# Drop-offs\ntrain['dropoff_datetime'] = pd.to_datetime(train['dropoff_datetime']) ","c16f424a":"# Confirm changes\ntrain.info()","90379519":"# Decomposing pickup_datetime variable into date and time\ntrain['pickup_date'] = train['pickup_datetime'].dt.date # Extract date\ntrain['pickup_time'] = train['pickup_datetime'].dt.time # Extract time\n\n# Decomposing dropoff_datetime variable into date and time \ntrain['dropoff_date'] = train['dropoff_datetime'].dt.date # Extract date\ntrain['dropoff_time'] = train['dropoff_datetime'].dt.time # Extract time\n\n\n\n# Additional pickup features\ntrain['pickup_month'] = train['pickup_datetime'].dt.month # Extract month\n\ntrain['pickup_hour'] = train['pickup_datetime'].dt.hour # Extract hour\n\ntrain['pickup_weekday'] = train['pickup_datetime'].dt.dayofweek # Extract day of week","f781defe":"# Drop concatentated timestamp columns\ntrain.drop(['pickup_datetime'], axis = 1, inplace = True)\ntrain.drop(['dropoff_datetime'], axis = 1, inplace = True)\n\n# Confirm removal\ntrain.columns","7f900a2b":"# Differences between dropoff and pickup geocardiante helps to calculate distance covered during a trips\n\ntrain['dist_long'] = train['pickup_longitude'] - train['dropoff_longitude']\n#test['dist_long'] = test['pickup_longitude'] - test['dropoff_longitude']\n\ntrain['dist_lat'] = train['pickup_latitude'] - train['dropoff_latitude']\n#test['dist_lat'] = test['pickup_latitude'] - test['dropoff_latitude']\n\n\n# Distance covered\ntrain['dist'] = np.sqrt(np.square(train['dist_long']) + np.square(train['dist_lat']))\n#test['dist'] = np.sqrt(np.square(test['dist_long']) + np.square(test['dist_lat']))","f990788e":"# Mean distribution\nmu = train['trip_duration'].mean()\n\n# Std distribution\nsigma = train['trip_duration'].std()\nnum_bins = 100\n\n# Histogram \nfig = plt.figure(figsize=(8.5, 5))\nn, bins, patches = plt.hist(train['trip_duration'], num_bins, normed=1,\n                           edgecolor = 'black', lw = 1, alpha = .40)\n# Normal Distribution\ny = mlab.normpdf(bins, mu, sigma)\nplt.plot(bins, y, 'r--', linewidth=2)\nplt.xlabel('trip_duration')\nplt.ylabel('Probability density')\n\n# Adding a title\nplt.title(r'$\\mathrm{Trip\\ duration\\ skewed \\ to \\ the \\ right:}\\ \\mu=%.3f,\\ \\sigma=%.3f$'%(mu,sigma))\nplt.grid(True)\n#fig.tight_layout()\nplt.show();\n\n","7651636d":"\nimport matplotlib\nmatplotlib.style.use('fivethirtyeight')\n\n# Create boxplot\nplt.figure(figsize=(8.5,5))\npassenger_graph = sns.boxplot(x = 'passenger_count', y = 'trip_duration', data = train, \n                          palette = 'gist_rainbow', linewidth = 2.3)\n\n# Customize tick size\npassenger_graph.tick_params(axis = 'both', which = 'major', labelsize = 12)\n\n\n# Customize tick labels of the y-axis\npassenger_graph.set_yticklabels(labels = [-10, '0  ', '2000  ', '4000  ', '6000  ', '8000  ', '10000  ','12000 s'])\n\n\n# Bolding horizontal line at y = 0\npassenger_graph.axhline(y = 0, color = 'black', linewidth = 1.3, alpha = .70)\n\n\n# # Adding a title and a subtitle\npassenger_graph.text(x =-1.05, y = 13800, s = \"Passenger count does not have much effect on trip duration\",\n               fontsize =15 , weight = 'bold', alpha = .90)\npassenger_graph.text(x = -1.05, y = 13000.3, \n               s = 'Median trip times remain similar despite more passengers being aboard',\n              fontsize = 14, alpha = .85)\nplt.show()\n\n","05efc531":"# Trips by Hour and Day of Week\ntrip_duration_median = train['trip_duration'].median()\nplt.figure(figsize=(8.5,5))\n\npickup_hourday = train.groupby(['pickup_hour','pickup_weekday'])['trip_duration'].median().unstack()\nhourday_graph = sns.heatmap(pickup_hourday[pickup_hourday>trip_duration_median], lw = .5, annot = True, cmap = 'GnBu', fmt = 'g',annot_kws = {\"size\":10} )\n\n\n# Customize tick labels of the y-axis\nhourday_graph.set_xticklabels(labels = ['Mon', 'Tue', 'Wed','Thu','Fri','Sat','Sun'])\n\n\n# Remove the label of the x-axis\nhourday_graph.xaxis.label.set_visible(False)\n\n# # Adding a title and a subtitle\nhourday_graph.text(x =-.8, y = 27, s = \"Trip durations vary greatly depending on day of week\",\n               fontsize =20 , weight = 'bold', alpha = .90)\n\nplt.show()","1aec1f54":"# Box plot of pickups by month\nimport matplotlib\nmatplotlib.style.use('fivethirtyeight')\n\n# Create boxplot\nplt.figure(figsize=(8.5,5))\nmonth_graph = sns.boxplot(x = 'pickup_month', y = 'trip_duration', data = train, palette = 'gist_rainbow', linewidth = 2.3)\n\n# Remove the label of the x-axis\nmonth_graph.xaxis.label.set_visible(False)\nmonth_graph.yaxis.label.set_visible(False)\n\nmonth_graph.text(x =-1.05, y = 13800, s = \"Month of transaction has minimal effect on trip duration\",\n               fontsize =20 , weight = 'bold', alpha = .90)\nmonth_graph.text(x = -1.05, y = 13000.3, \n               s = 'Median trip times hover around ~650 seconds throughout the year',\n              fontsize = 14, alpha = .85)\nplt.show()\n\n\n# Statistical summary\ntrain.groupby('pickup_month')['trip_duration'].describe().transpose()\n\n","070de940":"# Correlations to trip_duration\ncorr = train.select_dtypes(include = ['float64', 'int64']).iloc[:, 1:].corr()\ncor_dict = corr['trip_duration'].to_dict()\ndel cor_dict['trip_duration']\nprint(\"List the numerical features in decending order by their correlation with trip_duration:\\n\")\nfor ele in sorted(cor_dict.items(), key = lambda x: -abs(x[1])):\n    print(\"{0}: {1}\".format(*ele))\n    \n# Correlation matrix heatmap\ncorrmat = train.corr()\nplt.figure(figsize=(12, 7))\n\n# Number of variables for heatmap\nk = 76\ncols = corrmat.nlargest(k, 'trip_duration')['trip_duration'].index\ncm = np.corrcoef(train[cols].values.T)\n\n# Generate mask for upper triangle\nmask = np.zeros_like(cm, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.set(font_scale=1)\nsns.heatmap(cm, mask=mask, cbar=True, annot=True, square=True,\\\n                 fmt='.2f',annot_kws={'size': 12}, yticklabels=cols.values,\\\n                 xticklabels=cols.values, cmap = 'coolwarm',lw = .1)\nplt.show() ","ca539db0":"# Encoding Categoric data (converting 'store_and_fwd_flag' to numeric)\ntrain['store_and_fwd_flag'] = train['store_and_fwd_flag'].map({'N':0,'Y':1})","75340f4c":"train.drop(columns=['pickup_date','pickup_time','dropoff_date', 'dropoff_time', 'dist_long', 'dist_lat'], axis = 1, inplace = True)","9996583f":"train.head(3)","578bac52":"X = train[['vendor_id', 'passenger_count', 'pickup_longitude',\n       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n       'store_and_fwd_flag','pickup_month', 'pickup_hour',\n       'pickup_weekday', 'dist']]\n\n# Target\ny = train['trip_duration']","f3e5fce0":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size = 0.2, random_state = 0)\nX_train.shape, y_train.shape, X_val.shape, y_val.shape","2c6c2ef8":"#instantiate model\nlr = LinearRegression()\n\n# Fit to training data\nlr = lr.fit(X_train,y_train);\n\n#Predict\ny_pred_lr = lr.predict(X_val)","cd0ef292":"#cross_validation_score\ncvs_lr = np.sqrt(\n    -cross_val_score(lr, X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\nprint(cvs_lr)\n\nmean_cvs_lr = np.mean(cvs_lr)\nprint(mean_cvs_lr)","6a098766":"# Score It\nfrom sklearn import metrics\nprint('\\nRandom Forest Regression Performance Metrics')\nprint('R^2 =',metrics.explained_variance_score(y_val,y_pred_lr))\nprint('MAE',metrics.mean_absolute_error(y_val, y_pred_lr))\nprint('MSE',metrics.mean_squared_error(y_val, y_pred_lr))\nprint('RMSE',np.sqrt(metrics.mean_squared_error(y_val, y_pred_lr)))","56c1cbab":"#model selection \nfrom sklearn.ensemble import RandomForestRegressor\n\n# Intantiate model \nrf = RandomForestRegressor(n_estimators = 20, n_jobs = -1)\n\n#fit\nrf = rf.fit(X_train, y_train)\n\n#Predict\ny_pred_rf = rf.predict(X_val)\n\n# crosse validation\ncvs_rf = cross_val_score(rf, X_train, y_train, cv=5)\nprint(cvs_rf)\n\nmean_cvs_rf = np.mean(cvs_rf)\nprint(mean_cvs_rf)","7c15f315":"from sklearn import metrics\nprint('\\nRandom Foresst Performance Metrics')\nprint('R^2=',metrics.explained_variance_score(y_val,y_pred_rf))\nprint('MAE:',metrics.mean_absolute_error(y_val,y_pred_rf))\nprint('MSE:',metrics.mean_squared_error(y_val,y_pred_rf))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_val,y_pred_rf)))\nprint('RMSLE:',np.sqrt(metrics.mean_squared_log_error(y_val, y_pred_rf)))","1ca6e5fb":"# Test data info\ntest.info()\n\n# Test data shape\nprint('shape',test.shape)","17a842df":"# Convert timestamps to date objects\ntest['pickup_datetime'] = pd.to_datetime(test.pickup_datetime) # Pickups\n\n# Delimit pickup_datetime variable \ntest['pickup_date'] = test['pickup_datetime'].dt.date # Extract date\ntest['pickup_time'] = test['pickup_datetime'].dt.time # Extract time\n\n# Additional pickup features\ntest['pickup_month'] = test['pickup_datetime'].dt.month # Extract month\n\n#train_data['pickup_YYYYMM'] = train_data['pickup_datetime'].apply(lambda x: x.strftime('%Y%m')) # Extract yearmonth\ntest['pickup_hour'] = test['pickup_datetime'].dt.hour # Extract hour\ntest['pickup_weekday'] = test['pickup_datetime'].dt.dayofweek # Extract day of week\n\n# Encode categorical variables\ntest['store_and_fwd_flag'] = test['store_and_fwd_flag'].map({'N':0,'Y':1})\n\n\n# Differences between dropoff and pickup geocardiante helps to calculate distance covered during a trips\ntest['dist_long'] = test['pickup_longitude'] - test['dropoff_longitude']\ntest['dist_lat'] = test['pickup_latitude'] - test['dropoff_latitude']\n\n# Distance covered\ntest['dist'] = np.sqrt(np.square(test['dist_long']) + np.square(test['dist_lat']))\n\n#drop useless colomns\ntest.drop(columns=['pickup_datetime', 'pickup_date', 'dist_long', 'dist_lat'], axis = 1, inplace = True)\n\n","21940caa":"# Create new matrix of features from test data\nX_test= test[['vendor_id', 'passenger_count', 'pickup_longitude',\n       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n       'store_and_fwd_flag','pickup_month', 'pickup_hour',\n       'pickup_weekday', 'dist']]\n\n# Feed features into random forest\ntest_pred= rf.predict(X_test)","eb62c7be":"submission = pd.DataFrame({'id':test['id'], 'trip_duration': test_pred})\nsubmission.to_csv('mySubmission.csv', index=False)\n","2e4742ec":"##  Pre-Processing Data\nAfter loading our data, we need to examine the structure of data to out find out what are possible missing values and outiliers.","379c220f":"Trips tend much longer than the median trip_duration of 655 seconds during the following parts of the week:\n\n* **Monday** - Thursday Office Hours: 8:00 am - 6:00 pm\n* **Thursday**, **Friday, Saturday Nights**: 6:00 pm - midnight\n* **Early Saturday** & **Sunday Mornings**: 12:00 am - 1:00 am\n* **Sunday Afternoons**: 2:00 pm and 4:00 pm","774a4cf4":"### 2. Pre-processing Data : Outliers","9b751bb2":"### 1. Pre-processing Data : Missing values ","113c063c":"R2 (R squared) is the proportion of the variance in the dependent variable that is predictable from the independent variable.The better the linear regression fits the data in comparison to the simple average, the closer the value of R^2 is to 1.\nIn this case, R only 60% of the variation in the dependent variable is explained by this model. Such a score is an indication that the relationship between the features and independent variable is average. May be this score can be improuve with a non-linear model. ","1ce1a99c":"#  **VI. Submission**","b6798a11":"\n\nBase on comparaison of performance metrics of the both model, we decide to use the Random Forest type to make our submission as following. ","f0ce4a2e":"## 4.Trip Duration by Month","512f2827":"## 2. Feature Enginering","cbe4fc27":"## 1.Target Variable: trip_duration","7be1a3de":"# **II. Loading files**","431a9333":"**Passenger_count** : Rationaly we would consider a trip with at least a passenger, so values with zero shall be deleted. LIkely trips with number of passengers above 5 shall be deleted because law provide that a a maximum number of passenger should not exced 5 persons, though in some few exception, passengers under the age of 7 who may sit on an adult's lap. However it unlikely that a full 5 person taxi cab would have that many children under the age of 7.   \n\n**Longitude and Latitude Coordinates** \nFurther More, New York City cordinates are normaly found between :\n*          Latitude is between 40.7128 and 40.748817\n*          Longitude is between - 74.0059 and - 73.968285\n\n**Trip_duration**\nLastly, there are unusual observations present in our target variable, trip_duration. The maximum trip_duration is unrealistic : 3526282.00 sec ( approximatively 980 hours). To get ride of this outlayers we will exclude all data points that are a specified number of standard deviations away from the mean.\nWe will remove trip_duration observations that are more than two standard deviations away from the mean duration time, \n\n","12fd1e28":"# **IV. Exploratory Data Analysis (Visualization)**","28ad43a1":"### 4. Pre-processing data : new features\nPickup_date and dropoff_date contain unit information that we can extract individually to get new features that would help us to vizualize the data set. ","36d96726":"### 3. Pre-processing Data : Data type\n   Here we extract dates, by converting them  \"object\" type to \"datetime\" type.               ","d2c82814":"\n### **Headings**\n* I.   Importing modules \n* II.  Loading files \n* II.  Data processing\n* IV. Exporatory data analysis \n* V.  Algorithme \n* VI. submission","dd33c27d":"## 4.Model selection 2 : RandomForest ","23c67af0":"## 1.Droping unnecessary features and incoding store_and_fwd_flag\nWe need to convert store_and_fwd_flag to numeric so as to get it into a ready to use in our model.","d787480f":"# **V. Algorithme**","c9ce632d":"## 3.Model  selection 1 :  (Linear Regression)","b6f0f6ad":"##     3. Train\/valid spliting","3973974b":"#                                       ** PREDICTION NEWYORK TAXI TRIP DURATIONS**","1f0030cd":"June has the highest median trip_duration overall, but only slightly. Median trip times seem to hover around the 10-12 minute mark and do not vary much from month-to-month. This may be an indication that this month feature will not be helpful in predicting our target variable, trip_duration. \n","51626bcb":"# **III. Data processing**","b5efeaaa":"#  **I. Importing modules**","f035be6d":"## 2.Passenger count per trip duration","0fbd1ac1":"The pickup and dropoff timestamp variables are being treated as non-null objects. These features should be converted to date objects to allow for easier feature engineering later on in Data type pre-processing section (section **III.a.3**)","3b144815":"## 3.Trip duration in a week","1c19003a":"## 1. Preprocessing Test data set ","13634d9e":"There is quite a good correlation between distance and trip duration(our target). ","cad248d3":"    In order to submit we need to reshape test data like we did on train data set, so that our model(Random Forest) can be use to predict. "}}