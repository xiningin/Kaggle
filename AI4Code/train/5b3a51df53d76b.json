{"cell_type":{"4bdc9855":"code","0d340546":"code","c66b4fe5":"code","48424981":"code","69cef9bf":"code","11383b0c":"code","be628f1b":"code","680f034b":"code","035558cf":"code","326d20b8":"code","7717feaf":"code","d89322b3":"code","c8115acd":"code","19dccfbd":"code","f369dabc":"code","f1731a7a":"code","e37d0b6b":"code","ceded0cc":"code","d96f81ed":"code","7399097f":"code","e379b24d":"markdown","7c95d234":"markdown","0c2f7f40":"markdown","8e78d444":"markdown","f07e0fec":"markdown","fb37f25d":"markdown","815757cd":"markdown","28a44ede":"markdown","e580e68c":"markdown","6a47caeb":"markdown","3dc96dd6":"markdown","67b71bb9":"markdown","0294a7ed":"markdown","affe496e":"markdown","d3e46564":"markdown","f63eb6e3":"markdown","2079cbb5":"markdown","c966dda3":"markdown","f0ec3133":"markdown","d19b6ac9":"markdown","69c4e8f2":"markdown","7fade58f":"markdown","f2b95430":"markdown"},"source":{"4bdc9855":"import numpy as np\nimport pandas as pd \n\nimport utils_clf_models as clf\nimport utils_data_prepping as udp\nimport utils_eda as eda\n\n%matplotlib inline\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(rc={'figure.figsize':(12, 10)})\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0d340546":"df = udp.loading('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndf.head()","c66b4fe5":"df['quality'].unique()","48424981":"udp.missing_values(df)","69cef9bf":"df['quality_binary'] = np.where(df['quality'] >= 6, 'good', 'bad')\ndf['quality_binary_num'] = np.where(df['quality'] >= 6, 1, 0)\ndf.head()","11383b0c":"d =  { 3 : 0,  4 : 0, \n       5 : 1,  6 : 1,\n       7 : 2,  8 : 2,}\n\nd1 =  { 3 : 'bad',  4 : 'bad', \n       5 : 'good',  6 : 'good',\n       7 : 'very good',  8 : 'very good',}\n\ndf['quality_tri_num'] = df['quality'].map(d)\ndf['quality_tri'] = df['quality'].map(d1)\ndf.head()","be628f1b":"fig = plt.figure(figsize=(16, 12))\ngs = fig.add_gridspec(1, 3, hspace=0.1, wspace=0.1)\n(ax1, ax2, ax3) = gs.subplots(sharex=False, sharey=True)\nfig.suptitle('Histograms for Target Variable (Original vs Binary)')\n\nsns.histplot(ax=ax1, data=df, x='quality')\nsns.histplot(ax=ax2, data=df, x='quality_binary')\nsns.histplot(ax=ax3, data=df, x='quality_tri')\n\nplt.show()","680f034b":"eda.corr_matrix(df)\nplt.show()","035558cf":"sns.scatterplot(data=df, x='alcohol', y='density', hue='quality_binary')\nplt.show()","326d20b8":"sns.scatterplot(data=df, x='alcohol', y='density', hue='quality_tri')\nplt.show()","7717feaf":"fig = plt.figure(figsize=(16, 12))\ngs = fig.add_gridspec(2, 2, hspace=0.2, wspace=0.2)\n(ax1, ax2), (ax3, ax4) = gs.subplots(sharex=False, sharey=True)\nfig.suptitle('Histograms for Target Variable (Original vs Binary)')\n\nsns.scatterplot(ax=ax1, data=df, x='fixed acidity',  y='citric acid', hue='quality_binary')\nsns.scatterplot(ax=ax2, data=df, x='volatile acidity', y='citric acid', hue='quality_binary')\n\nsns.scatterplot(ax=ax3, data=df, x='fixed acidity',  y='citric acid', hue='quality_tri')\nsns.scatterplot(ax=ax4, data=df, x='volatile acidity', y='citric acid', hue='quality_tri')\n\nplt.show()","d89322b3":"fig = plt.figure(figsize=(16, 12))\ngs = fig.add_gridspec(2, 2, hspace=0.2, wspace=0.2)\n(ax1, ax2), (ax3, ax4)  = gs.subplots(sharex=False, sharey=True)\nfig.suptitle('Histograms for Target Variable (Original vs Binary)')\n\nsns.scatterplot(ax=ax1, data=df, x='fixed acidity',  y='pH', hue='quality_binary')\nsns.scatterplot(ax=ax2, data=df, x='citric acid', y='pH', hue='quality_binary')\n\nsns.scatterplot(ax=ax3, data=df, x='fixed acidity',  y='pH', hue='quality_tri')\nsns.scatterplot(ax=ax4, data=df, x='citric acid', y='pH', hue='quality_tri')\n\nplt.show()","c8115acd":"df1 = df.drop(['quality_binary', 'quality_binary_num', \n               'quality_tri', 'quality_tri_num'], axis=1)\nX, y = udp.pre_processing(df1, 'quality')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(size=0.2, state=12)\nknn.fit_predict()\nmulti = knn.metrics().ev['Accuracy']","19dccfbd":"df2 = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_tri_num'], axis=1)\nX, y = udp.pre_processing(df2, 'quality_binary_num')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(size=0.2, state=12)\nknn.fit_predict()\nbinary = knn.metrics().ev['Accuracy']","f369dabc":"df3 = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(df3, 'quality_tri_num')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(size=0.2, state=12)\nknn.fit_predict()\ntrio = knn.metrics().ev['Accuracy']","f1731a7a":"pd.DataFrame({'multi':pd.Series(multi),'binary':pd.Series(binary), 'trio':pd.Series(trio)})\nmet = pd.DataFrame([multi,binary, trio]).T\nmet.rename(index= {0:'Accuracy'}, columns={0: \"multi_class\", 1: \"binary_class\", 2: \"three_classes\"})","e37d0b6b":"# Works using utils_clf_models (See Documentation)\ndef search_best_split(clf, iters):\n    sizes = [round(i, 2) for i in np.arange(0.2, 0.45, 0.05)]\n    states = list(range(0, iters+1))\n    scores = {}\n    for i in sizes:\n        for j in states:\n            clf.preprocess_split(size=i, state=j)\n            clf.fit_predict()\n            scores[(i, j)]  = clf.metrics().ev['Accuracy']\n    \n    best_split = max(scores, key=scores.get)\n    return best_split\ndata = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(data, 'quality_tri_num')\nknn = clf.Classifier(X, y, 'knn')\ns, t = search_best_split(knn, 500)\n\n# Rerunning it with the following sampling parameters\ndata = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(data, 'quality_tri_num')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(size=s, state=t)\nknn.fit_predict()\ntrio = knn.metrics().ev['Accuracy']\ntrio","ceded0cc":"def elbow_method(clf, iters):\n    scores = {}    \n    for k in range(2, iters+1):\n        clf.fit_predict({'n_neighbors':k})\n        clf.metrics().ev['Accuracy']\n        scores[k]  = clf.metrics().ev['Accuracy']\n    k_best = max(scores, key=scores.get)\n    return k_best\n\ndata = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(data, 'quality_tri_num')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(s, t)\nk_best = elbow_method(knn, 30)\n\n# Rerunning it with the following sampling parameters\ndata = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(data, 'quality_tri_num')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(size=s, state=t)\nknn.fit_predict({'n_neighbors': k_best})\ntrio = knn.metrics().ev['Accuracy']\ntrio","d96f81ed":"#Using Grid Search (Exhaustive) with cross validation\nfrom sklearn.neighbors import KNeighborsClassifier as knn\nfrom sklearn.model_selection import GridSearchCV\n\ndata = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(data, 'quality_tri_num')\n\nparameters = {'weights':('uniform', 'distance'), \n              'algorithm':('auto', 'ball_tree', 'kd_tree', 'brute'),\n             'leaf_size': [0, 300], 'p': [0, 300],'n_jobs':(-1, 1)}\nsvc = knn(n_neighbors=2)\nsearch = GridSearchCV(svc, parameters)\nsearch.fit(X, y)\nres = pd.DataFrame(search.cv_results_)\nbest = res[(res['rank_test_score'] == 1)]\nbest.sort_values(by=['std_score_time'], ascending=True)","7399097f":"# Reruning the model using the given parameters \ndata = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(data, 'quality_tri_num')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(size=s, state=t)\nknn_params = {'n_neighbors': k_best, 'weights':'uniform', \n              'algorithm': 'kd_tree', 'leaf_size': 300, \n              'p': 300,'n_jobs':1,}\nknn.fit_predict(knn_params)\ntrio = knn.metrics().ev['Accuracy']\ntrio","e379b24d":"# Modeling Phase 2: Find best sample Split","7c95d234":"# Exploratory Data Analysis","0c2f7f40":"# Loading the data","8e78d444":"## 3. How does one of the strongest relationship fair between wine types?","f07e0fec":"#### Given that we have now our parameters set, we will check for overfitting before proceeding to an overfit check","fb37f25d":"# Modeling ","815757cd":"#### After multiple attempts, it appears that splitting the target variable in three sets works better. We will proceed in finding the best k to maximize accuracy","28a44ede":"## 4. How do the different type of acidity vary between good and bad wines?","e580e68c":"## 1. Distribution of the target variable (Original vs Binary)","6a47caeb":"# Libraries & Environment Setup","3dc96dd6":"# Modifying the target variable","67b71bb9":"## 2. How do our variables interact with one another? (Correlation Matrix)","0294a7ed":"## 1. Target Variable Comparison ","affe496e":"# Table of Contents\n\n### Libraries & Environment Setup\n### Data Loading & Formatting\n### Missing Values\n### Target Variable Binarization\n### Exploratory Data Analysis\n    1. Distribution of the target variable (Original vs Binary)   \n    2. How do our variables interact with one another? (Correlation Matrix)\n    3. How does one of the strongest relationship fair between wine types?\n    4. How do the different type of acidity vary between good and bad wines?\n    5. What are predictors of pH of any type of wine?\n### Modeling \n    1. Target Variable Comparison\n        a. MultiClass Using the Original Target Variable  \n        b. Binary Using the newly created column \n    2. Find best sample Split\n    3. Find best k\n    4. Hyperparameter Tuning\n    5. Check for overfitting","d3e46564":"# Modeling Phase 4: Hyperparameter Tuning","f63eb6e3":"### a. MultiClass Using the Original Target Variable","2079cbb5":"#### From the following loop, we obtain the sampling paramater as the size and state respectively.","c966dda3":"## 5. What are predictors of pH of any type of wine?","f0ec3133":"# Checking for any missing values","d19b6ac9":"### c. Three classes using the newly created column","69c4e8f2":"# Modeling Phase 4: Check for Overfitting","7fade58f":"### b. Binary Using the newly created column","f2b95430":"# Modeling Phase 3: Find best k"}}