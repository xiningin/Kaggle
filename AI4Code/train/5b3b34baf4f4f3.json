{"cell_type":{"c8fd0a81":"code","e283f6fd":"code","f761b3b3":"code","98e5c2e5":"code","adb432be":"code","d13d0fc3":"code","16fd395d":"code","fc0d411c":"code","c8ce5297":"code","44d07886":"code","7e8fca9a":"code","e22f304b":"code","167a724a":"markdown","71bb0f4e":"markdown","a96ba189":"markdown"},"source":{"c8fd0a81":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","e283f6fd":"df = pd.read_csv('..\/input\/college-admission\/College_admission.csv')\ndf = df.rename(columns={'rank':'Rank'})\ndf.head()","f761b3b3":"#One hot encoding for variable ses,Race and Rank\ndummies1 = pd.get_dummies(df.ses, prefix='ses')\ndummies2 = pd.get_dummies(df.Race, prefix='Race')\ndummies3 = pd.get_dummies(df.Rank, prefix='Rank')\n#marge the dataframe\nnew_df = pd.concat([df,dummies1,dummies2,dummies3] , axis='columns')\n#drop ses, Race and Rank columns\ndf = new_df.drop(['ses','Race' , 'Rank'], axis='columns')\ndf.head()\n","98e5c2e5":"x = df.iloc[:,1:]\ny = df.iloc[:,0]","adb432be":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 1,stratify = y)","d13d0fc3":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc_log = accuracy_score(y_test, y_pred)","16fd395d":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc_svm = accuracy_score(y_test, y_pred)","fc0d411c":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc_dtree = accuracy_score(y_test, y_pred)","c8ce5297":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc_rforest = accuracy_score(y_test, y_pred)","44d07886":"models = pd.DataFrame({\n    'Model': ['Logistic Regression','Support Vector Machines',  \n              'Decision Tree','Random Forest'],\n    'Score': [acc_log, acc_svm, \n              acc_dtree,acc_rforest]})\nmodels.sort_values(by='Score', ascending=True)","7e8fca9a":"classifier = LogisticRegression(random_state = 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)","e22f304b":"submission = pd.DataFrame(y_pred)\nsubmission.to_csv('Submission.csv')","167a724a":"Here Logistic Regression model is best. ","71bb0f4e":"**Classification** ","a96ba189":"**Data Preprocessing**"}}