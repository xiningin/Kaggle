{"cell_type":{"ac33bd7b":"code","20957565":"code","6195572c":"code","f1f6406e":"code","dbe8a8c6":"code","ea7064ff":"code","91600fc5":"code","0c518da7":"code","9a9c359d":"code","87e2e8bd":"code","80a03ca8":"code","321eebc5":"code","3f5d57ac":"markdown","88971223":"markdown","d3035911":"markdown","817b7b38":"markdown"},"source":{"ac33bd7b":"package_path = \"..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master\/\"\nimport sys \nsys.path.append(package_path)\n\nimport os\nimport glob\nimport time\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport efficientnet_pytorch\n\nfrom sklearn.model_selection import StratifiedKFold","20957565":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nseed = 123\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed)\n\nclass CFG:\n    img_size = 256\n    n_frames = 16\n    center_crop = 0\n    \n    cnn_features = 256\n    lstm_hidden = 32\n    \n    n_fold = 5\n    n_epochs = 30\n    lr=1e-4","6195572c":"class CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.map = nn.Conv2d(in_channels=4, out_channels=3, kernel_size=1)\n        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b0\")\n        checkpoint = torch.load(\"..\/input\/efficientnet-pytorch\/efficientnet-b0-08094119.pth\")\n        self.net.load_state_dict(checkpoint)\n        \n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=CFG.cnn_features, bias=True)\n    \n    def forward(self, x):\n        x = F.relu(self.map(x))\n        out = self.net(x)\n        return out\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.cnn = CNN()\n        self.rnn = nn.LSTM(CFG.cnn_features, CFG.lstm_hidden, 2, batch_first=True)\n        self.fc = nn.Linear(CFG.lstm_hidden, 1, bias=True)\n\n    def forward(self, x):\n        # x shape: BxTxCxHxW\n        batch_size, timesteps, C, H, W = x.size()\n        c_in = x.view(batch_size * timesteps, C, H, W)\n        c_out = self.cnn(c_in)\n        r_in = c_out.view(batch_size, timesteps, -1)\n        output, (hn, cn) = self.rnn(r_in)\n        \n        out = self.fc(hn[-1])\n        return out","f1f6406e":"# model = Model()\n# x = torch.zeros((1, 15, 4, 256, 256))\n# t = time.time()\n# out = model(x)\n# print(time.time()-t)\n# print(out.shape)","dbe8a8c6":"def load_image(path):\n    image = cv2.imread(path, 0)\n    if image is None:\n        return np.zeros((CFG.img_size, CFG.img_size))\n    \n    # Center crop\n#     height, width = image.shape\n#     margin_h = int(height * CFG.center_crop)\n#     margin_w = int(width * CFG.center_crop)\n#     image = image[margin_h:-margin_h, margin_w:-margin_w]\n    \n    image = cv2.resize(image, (CFG.img_size, CFG.img_size)) \/ 255\n    return image.astype('f')\n\ndef uniform_temporal_subsample(x, num_samples):\n    '''\n        Moddified from https:\/\/github.com\/facebookresearch\/pytorchvideo\/blob\/d7874f788bc00a7badfb4310a912f6e531ffd6d3\/pytorchvideo\/transforms\/functional.py#L19\n        Args:\n            x: input list\n            num_samples: The number of equispaced samples to be selected\n        Returns:\n            Output list     \n    '''\n    t = len(x)\n    indices = torch.linspace(0, t - 1, num_samples)\n    indices = torch.clamp(indices, 0, t - 1).long()\n    return [x[i] for i in indices]","ea7064ff":"class DataRetriever(Dataset):\n    def __init__(self, paths, targets, transform=None):\n        self.paths = paths\n        self.targets = targets\n        self.transform = transform\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def read_video(self, vid_paths):\n        video = [load_image(path) for path in vid_paths]\n        if self.transform:\n            seed = random.randint(0,99999)\n            for i in range(len(video)):\n                random.seed(seed)\n                video[i] = self.transform(image=video[i])[\"image\"]\n        \n        video = [torch.tensor(frame, dtype=torch.float32) for frame in video]\n        if len(video)==0:\n            video = torch.zeros(CFG.n_frames, CFG.img_size, CFG.img_size)\n        else:\n            video = torch.stack(video) # T * C * H * W\n#         video = torch.transpose(video, 0, 1) # C * T * H * W\n        return video\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        patient_path = f\"..\/input\/rsna-miccai-png\/train\/{str(_id).zfill(5)}\/\"\n        channels = []\n        for t in [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"]:\n            t_paths = sorted(\n                glob.glob(os.path.join(patient_path, t, \"*\")), \n                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n            )\n\n            if len(t_paths) < CFG.n_frames:\n                in_frames_path = t_paths\n            else:\n                in_frames_path = uniform_temporal_subsample(t_paths, CFG.n_frames)\n            \n            channel = self.read_video(in_frames_path)\n            \n            if channel.shape[0]<CFG.n_frames:\n                channel = F.pad(channel, (0, 0, 0, 0, 0, CFG.n_frames - channel.shape[0]))\n#                 channel = torch.zeros(num_samples, CFG.img_size, CFG.img_size)\n            channels.append(channel)\n            \n        channels = torch.stack(channels).transpose(0,1)\n        \n        y = torch.tensor(self.targets[index], dtype=torch.float)\n        return {\"X\": channels.float(), \"y\": y}","91600fc5":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\ntrain_transform = A.Compose([\n                                A.HorizontalFlip(p=0.5),\n                                A.ShiftScaleRotate(\n                                    shift_limit=0.0625, \n                                    scale_limit=0.1, \n                                    rotate_limit=10, \n                                    p=0.5\n                                ),\n                                A.RandomBrightnessContrast(p=0.5),\n                            ])\nvalid_transform = A.Compose([\n                            ])","0c518da7":"# data = DataRetriever(\n#         train_df[\"BraTS21ID\"].values, \n#         train_df[\"MGMT_value\"].values\n#     )\n# data[0]['X'].shape","9a9c359d":"df = pd.read_csv(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv\")\ndf.head(10)","87e2e8bd":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n\n    def update(self, val):\n        self.n += 1\n        # incremental update\n        self.avg = val \/ self.n + (self.n - 1) \/ self.n * self.avg\n\n        \nclass AccMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n        \n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().astype(int)\n        y_pred = y_pred.cpu().numpy() >= 0\n        last_n = self.n\n        self.n += len(y_true)\n        true_count = np.sum(y_true == y_pred)\n        # incremental update\n        self.avg = true_count \/ self.n + last_n \/ self.n * self.avg","80a03ca8":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion, \n        loss_meter, \n        score_meter\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.loss_meter = loss_meter\n        self.score_meter = score_meter\n        self.hist = {'val_loss':[],\n                     'val_score':[],\n                     'train_loss':[],\n                     'train_score':[]\n                    }\n        self.best_valid_score = -np.inf\n        self.best_valid_loss = np.inf\n        self.n_patience = 0\n        \n        self.messages = {\n            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n        }\n    \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):\n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_score, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n            \n            self.hist['val_loss'].append(valid_loss)\n            self.hist['train_loss'].append(train_loss)\n            self.hist['val_score'].append(valid_score)\n            self.hist['train_score'].append(train_score)\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n            )\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n            )\n\n            if self.best_valid_score < valid_score:\n                self.info_message(\n                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n                )\n                self.best_valid_score = valid_score\n                self.best_valid_loss = valid_loss\n                self.save_model(n_epoch, save_path)\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(self.messages[\"patience\"], patience)\n                break\n                \n        return self.best_valid_loss, self.best_valid_score\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        train_loss = self.loss_meter()\n        train_score = self.score_meter()\n        \n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(X).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n    \n            loss.backward()\n\n            train_loss.update(loss.detach().item())\n            train_score.update(targets, outputs.detach())\n            self.optimizer.step()\n            \n            _loss, _score = train_loss.avg, train_score.avg\n            message = 'Train Step {}\/{}, train_loss: {:.5f}, train_score: {:.5f}'\n            self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n        \n        return train_loss.avg, train_score.avg, int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        valid_loss = self.loss_meter()\n        valid_score = self.score_meter()\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X).squeeze(1)\n                loss = self.criterion(outputs, targets)\n\n                valid_loss.update(loss.detach().item())\n                valid_score.update(targets, outputs)\n                \n            _loss, _score = valid_loss.avg, valid_score.avg\n            message = 'Valid Step {}\/{}, valid_loss: {:.5f}, valid_score: {:.5f}'\n            self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n        \n        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n    \n    def plot_loss(self):\n        plt.title(\"Loss\")\n        plt.xlabel(\"Training Epochs\")\n        plt.ylabel(\"Loss\")\n\n        plt.plot(self.hist['train_loss'], label=\"Train\")\n        plt.plot(self.hist['val_loss'], label=\"Validation\")\n        plt.legend()\n        plt.show()\n    \n    def plot_score(self):\n        plt.title(\"Score\")\n        plt.xlabel(\"Training Epochs\")\n        plt.ylabel(\"Acc\")\n\n        plt.plot(self.hist['train_score'], label=\"Train\")\n        plt.plot(self.hist['val_score'], label=\"Validation\")\n        plt.legend()\n        plt.show()\n    \n    def save_model(self, n_epoch, save_path):\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            save_path,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","321eebc5":"skf = StratifiedKFold(n_splits=CFG.n_fold)\nt = df['MGMT_value']\n\nstart_time = time.time()\n\nlosses = []\nscores = []\n\nfor fold, (train_index, val_index) in enumerate(skf.split(np.zeros(len(t)), t), 1):\n    print('-'*30)\n    print(f\"Fold {fold}\")\n    \n    train_df = df.loc[train_index]\n    val_df = df.loc[val_index]\n    train_retriever = DataRetriever(\n        train_df[\"BraTS21ID\"].values, \n        train_df[\"MGMT_value\"].values,\n        train_transform\n    )\n    val_retriever = DataRetriever(\n        val_df[\"BraTS21ID\"].values, \n        val_df[\"MGMT_value\"].values\n    )\n    train_loader = torch_data.DataLoader(\n        train_retriever,\n        batch_size=4,\n        shuffle=True,\n        num_workers=4,\n    )\n    valid_loader = torch_data.DataLoader(\n        val_retriever, \n        batch_size=4,\n        shuffle=False,\n        num_workers=4,\n    )\n    \n    model = Model()\n    model.to(device)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr)\n    criterion = F.binary_cross_entropy_with_logits\n    \n    trainer = Trainer(\n        model, \n        device, \n        optimizer, \n        criterion, \n        LossMeter, \n        AccMeter\n    )\n    loss, score = trainer.fit(\n        CFG.n_epochs, \n        train_loader, \n        valid_loader, \n        f\"best-model-{fold}.pth\", \n        100,\n    )\n    losses.append(loss)\n    scores.append(score)\n    \n    trainer.plot_loss()\n    trainer.plot_score()\n    \nelapsed_time = time.time() - start_time\nprint('\\nTraining complete in {:.0f}m {:.0f}s'.format(elapsed_time \/\/ 60, elapsed_time % 60))\nprint('Avg loss {}'.format(np.mean(losses)))\nprint('Avg score {}'.format(np.mean(scores)))","3f5d57ac":"# Import things","88971223":"# Training","d3035911":"# Model","817b7b38":"# Data Processing"}}