{"cell_type":{"f5404169":"code","0fe9eace":"code","c12180e6":"code","6d3db3cf":"code","846043bd":"code","8370e4cf":"code","256ae37e":"code","6b386ea1":"code","2e964a32":"code","ccac8280":"code","b6b738b9":"code","f5901c47":"code","d9314a85":"code","93cd9953":"code","ffc2f1b9":"code","3e707abe":"code","781e47f7":"code","192f6acc":"code","b371508c":"code","13fa1bbf":"code","3a5c6a0f":"code","4e964530":"code","149f58e4":"code","1761baf8":"code","4e44f5f5":"code","5a0be9e9":"code","f8b78270":"code","27a5c512":"code","21fe7c0e":"markdown","90733233":"markdown","e166a6bc":"markdown","e8854cc5":"markdown","56a07b37":"markdown","d213f269":"markdown","1a0f3ed4":"markdown","1c3f3809":"markdown","595b046f":"markdown","20ea59f1":"markdown","aa030c30":"markdown","e73cbf7d":"markdown","4b919f69":"markdown","d0de1b98":"markdown","3d93a43d":"markdown","64e497da":"markdown","588760bc":"markdown","cb87342a":"markdown","b1aff714":"markdown","56dbb301":"markdown","a8d0ce83":"markdown","077ca602":"markdown","c19b602a":"markdown","6882dbb7":"markdown","7368745b":"markdown","28f1678b":"markdown","8e97e6d5":"markdown","534b3685":"markdown","dea6a7b6":"markdown","0e1130f0":"markdown","5514de32":"markdown","78adc9b3":"markdown","c8c29b96":"markdown","aa0868be":"markdown","b8df60e9":"markdown","ac0ecdb5":"markdown","239ccc23":"markdown","7543b087":"markdown","9e20df55":"markdown","f11ea526":"markdown","2b64f67f":"markdown","51972494":"markdown","ee5ec144":"markdown","a05cb0aa":"markdown","c908936b":"markdown","cf8087ab":"markdown","880bd287":"markdown"},"source":{"f5404169":"# importing the libraries\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","0fe9eace":"# reading the dataset\ndf = pd.read_csv('..\/input\/online-retail-ii-uci\/online_retail_II.csv', parse_dates=True, index_col='InvoiceDate')","c12180e6":"# viewing the first few rows\ndf.head()","6d3db3cf":"# extracting the transactions that have occured between 01\/04\/2011 and 09\/12\/2011\ndf_time = df[(df.index>='2011-04-01') & (df.index<='2011-12-09')]","846043bd":"# checking for missing values\ndf_time.isnull().sum()","8370e4cf":"# removing the missing values\ndf_time = df_time[df_time['Customer ID'].notna()]","256ae37e":"df_time = df_time[~df_time.Invoice.str.contains('C')]","6b386ea1":"df_time[df_time.duplicated()].shape","2e964a32":"df_time = df_time.drop_duplicates(keep='first')","ccac8280":"print((df_time.Quantity<0).sum())\nprint((df_time.Price<0).sum())","b6b738b9":"# calculating R\ndf_time['R'] = 12 - df_time.index.month","f5901c47":"# creating a new column and initializing to 0\ndf_time['F'] = 0\n\n# creating a list of unique customer ids\ncustomer_ids = list(df_time['Customer ID'].unique())\n\n# calculating and storing the number of transactions made by each customer\nfor id in customer_ids:\n  df_time.loc[df_time['Customer ID']==id, 'F'] += df_time.groupby(by='Customer ID').Invoice.size()[id]","d9314a85":"# calculating and storing the revenue\ndf_time['Revenue'] = df_time.Quantity * df_time.Price","93cd9953":"# creating a new column and initializing to 0\ndf_time['M'] = 0\n\n# adding the sum of the revenue generated by each customer\nfor id in customer_ids:\n  df_time.loc[df_time['Customer ID']==id, 'M'] += df_time.groupby(by='Customer ID').Revenue.sum()[id]","ffc2f1b9":"# creating a new dataframe\ndf_rfm = pd.DataFrame(customer_ids, columns=['Customer ID'])","3e707abe":"# creating new columns and initializing to 0\ndf_rfm['R'] = 0\ndf_rfm['F'] = 0\ndf_rfm['M'] = 0\n\n# updating value of each column\nfor id in customer_ids:\n    df_rfm.loc[df_rfm['Customer ID']==id, 'R'] += df_time.loc[df_time['Customer ID']==id, 'R'].values[0]\n    df_rfm.loc[df_rfm['Customer ID']==id, 'F'] += df_time.loc[df_time['Customer ID']==id, 'F'].values[0]\n    df_rfm.loc[df_rfm['Customer ID']==id, 'M'] += df_time.loc[df_time['Customer ID']==id, 'M'].values[0]","781e47f7":"# importing KMeans\nfrom sklearn.cluster import KMeans","192f6acc":"# creating a list to store the within-the-cluster-sum-of-squared-distance\nwcss = []\n\n# looping over number of clusters and storing wcss\nfor k in range(0, 10):\n  kmeans = KMeans(n_clusters=k+1, random_state=0).fit(df_rfm[['R', 'F', 'M']])\n  wcss.append(kmeans.inertia_)\n\n# plotting the wcss wrt cluster numbers\nplt.figure(figsize=(15,8))\nax = sns.pointplot(x=list(range(1, 11)), y=wcss)\nax.set_title('K-Means Clustering\\nNumber of Clusters vs Within Cluster Sum of Squares')\nax.set_xlabel('Number of Clusters')\nax.set_ylabel('Within Cluster Sum of Squares')\nplt.show()","b371508c":"# building the kmeans model\nkmeans = KMeans(n_clusters=3, random_state=0).fit(df_rfm[['R', 'F', 'M']])","13fa1bbf":"# generating cluster labels\ndf_rfm['labels'] = kmeans.labels_","3a5c6a0f":"# visualizing the clusters\nsns.lmplot(x='F', y='M', col='R', hue='labels', data=df_rfm, col_wrap=2, fit_reg=False, markers=['o', '^', 'D'])","4e964530":"# printing the cluster centres\nkmeans.cluster_centers_","149f58e4":"# importing Agglomerative Clustering\nfrom sklearn.cluster import AgglomerativeClustering","1761baf8":"# building agglomerative clustering model\nagglo = AgglomerativeClustering(n_clusters=3, compute_distances=True).fit(df_rfm[['R','F','M']])","4e44f5f5":"# importing dendrogram\nfrom scipy.cluster.hierarchy import dendrogram","5a0be9e9":"def plot_dendrogram(agglo, **kwargs):\n    \n    counts = np.zeros(agglo.children_.shape[0])\n    n_samples = len(agglo.labels_)\n    for i, merge in enumerate(agglo.children_):\n        current_count = 0\n        for child_idx in merge:\n            if child_idx < n_samples:\n                current_count += 1\n            else:\n                current_count += counts[child_idx - n_samples]\n        counts[i] = current_count\n\n    linkage_matrix = np.column_stack([agglo.children_, agglo.distances_, counts]).astype(float)\n\n    dendrogram(linkage_matrix, **kwargs)\n    \n\nplt.figure(figsize=(15,8))\nplt.title('Hierarchical Clustering Dendrogram')\nplot_dendrogram(agglo, truncate_mode='level', p=3)\nplt.show()","f8b78270":"# creating a list of labels generated by the kmeans model\nlabels_kmeans = list(kmeans.labels_)\n\n# creating a list of labels generated by the agglomerative clustering model\nlabels_agglo = list(agglo.labels_)","27a5c512":"# printing the size of the kmeans clusters\nprint('Cluster 0 - KMeans: ', labels_kmeans.count(0))\nprint('Cluster 1 - KMeans: ', labels_kmeans.count(1))\nprint('Cluster 2 - KMeans: ', labels_kmeans.count(2))\n\nprint()\n\n# printing the size of the agglomerative clusters\nprint('Cluster 0 - Agglomerative: ', labels_agglo.count(0))\nprint('Cluster 1 - Agglomerative: ', labels_agglo.count(1))\nprint('Cluster 2 - Agglomerative: ', labels_agglo.count(2))","21fe7c0e":"#### *Q1 b.* Select only the transactions that have occurred from 01\/04\/ 2011 and 09\/12\/2011 and create a dataset.","90733233":"Next, we read the dataset. To do this, we use the read_csv() function from the Pandas library. We set the index as the InvoiceDate column and also set the parse_dates parameter to True to convert the index column to the datetime datatype. ","e166a6bc":"As we can see, an elbow point is formed at number of clusters - 3 as that is where the wcss starts changing slowly. Hence, we take the number of clusters to be 3.","e8854cc5":"#### *Q7 b.* Compare the clusters obtained using KMeans vs. Agglomeration","56a07b37":"Next, we generate the cluster labels for each observation in the dataframe and store them in a column. For this, we use the labels_ parameter of the kmeans model.","d213f269":"#### *Q2.* Calculate R (Recency) \u2212 Recency should be calculated as the number of months before he or she has made a purchase from the online store. If he\/she made a purchase in the month of December 2011, then the Recency should be 0. If purchase is made in November 2011 then Recency should be 1 and so on and so forth","1a0f3ed4":"#### *Q7 a.* Visualize the clusters using the dendrogram.","1c3f3809":"Next, we build an AgglomerativeClustering model with 3 clusters (as suggested by the elbow method previously) using the RFM values.","595b046f":"To solve Question 2, we create a new column in the dataframe called R which stores the value of the month in the index column subtracted from 12 (since the month of reference\/analysis is December). Hence, the most recent month gets value 0, second most recent gets 1, and so on..","20ea59f1":"Next, we create a new column M and initialize all its rows to 0. After that, we loop over the customer ids and add the revenue generated of a particular customer id to the M column. To do this, we use the loc() function from the Pandas library to locate exactly where the customer id matches the loop value, and add the sum of the revenue generated by the particular customer using the groupby() and sum() functions from the Pandas library and splicing it.","aa030c30":"Next, we check for missing values. To do this, we use the isnull() function from the Pandas library which returns a boolean array of whether the entry is null or not and then we sum over the null values using the sum() function.","e73cbf7d":"To solve Question 4, we first create a new column Revenue to store the product of the unit price and quantity of an item.","4b919f69":"#### *Q4.* Calculate M (Monetary Value) \u2212 Total spend by the customer from 01\/04\/ 2011 and 09\/12\/2011.","d0de1b98":"**Meta-Data** of the dataset:\n\nThe dataset contains data about the transactions occuring between 01\/12\/2010 and 09\/12\/2011 for a UK based online gift store. Attributes in the dataset:\n\nIdentifiers:\n-   InvoiceNo: Invoice number. A 6-digit integral number uniquely assigned to each transaction. Code starting with 'C' indicate cancellation.\n-   StockCode: Product (item) code. A 5-digit integral number uniquely assigned to each distinct product.\n-   CustomerID: Customer number. A 5-digit integral number uniquely assigned to each customer.\n\n\n\nCategorical Data:\n-   Country: Country name. The name of the country where each customer resides.\n-   Description: Product (item) name.\n\n\nNumeric Data:-   \n-   InvoiceDate: Invice Date and time. The day and time when each transaction was generated.\n-   Quantity: The quantities of each product (item) per transaction.\n-   UnitPrice: Unit price. Product price per unit in sterling.\n\n","3d93a43d":"To solve Question 3, we create a new column F and initialize all its rows to 0. Next, we create a list of all the unique cusotmer ids using the unique() function from the Pandas library. After that, we loop over the customer ids and add the number of invoices of a particular customer id to the F column. To do this, we use the loc() function from the Pandas library to locate exactly where the customer id matches the loop value, and add the size of the group of transactions made by the particular customer using the groupby() and size() functions from the Pandas library and splicing it.","64e497da":"To solve Question 1b, we filter the dataset by comparing the index of the dataframe and store the filtered rows in a new dataframe called df_time. The date format is yyyy\/mm\/dd.","588760bc":"To solve Question 6c, we first import AgglomerativeClustering from sklearn.","cb87342a":"# Clustering using RFM Analysis","b1aff714":"#### *Q5.* Create the customer segments with K-means algorithm by using number of clusters is suggested by elbow method.","56dbb301":"To solve Question 7b, we first create a list of the labels generated by both the KMeans and Agglomerative Clustering models using the list() function.","a8d0ce83":"After that, we plot the clusters using the lmplot() function from the Seaborn library. We set the markers to be a circle, a triangle, and a diamond to better visualize the clusters and also set the the hue parameter to change the colour for every label.","077ca602":"As we can see there are 90853 missing values in the CustomerID column. Since CustomerID being an identifier is essential for the analysis, we drop the missing values. To do this, we filter the dataframe and use the function notna() from the Pandas library which chooses only those values which are not null.","c19b602a":"As we can see, 9 plots have been generated - one for each value of Recency. On the x-axis, we have Monetary Value and on the y-axis we have Frequency. Each cluster has a different colour and a different shape. Cluster 0 is mostly located near the origin, with 2 closeby and 1 at the edges.","6882dbb7":"The cluster centre of cluster:\n\n-  0 has a value of 4.38 for R, 68.6 for F, and 1212 for M (customers with Low Recency, Low Frequency and Low Monetary Value) - customers who are of little value.\n-  1 has a value of 4.00 for R, 1296 for F, and 168158 for M (customers with Low Recency, High Frquency and High Monetary Value)  - loyal customers who should be entered in the Loyalty Program and given special benefits.\n-  2 has a value of 5.25 for R, 865 for F, and 39738 for M (customers with Low Recency, Medium Frequency, and Medium Monetary Value) - occasional shoppers - should be sent more promos and offers.\n\nThe wcss values are caculated by summing up the squared distances between points and their cluster centers to analyze the quality of clusters (lesser the wcss, higher the quality).","7368745b":"As we can see, there are 3730 duplicate records (values in all columns are identical). We decide to remove them in order to deal with them, to make our analysis more accurate. To do this, we select only those entries which are unique and keep only the first one of the duplicate entries by using the drop_duplicates() function from the Pandas library and set the keep parameter value as first.","28f1678b":"To solve Question 5, we first import KMeans from the sklearn library.","8e97e6d5":"Author: Khushee Kapoor\n\nLast Updated: 4\/1\/22","534b3685":"To start, we import the following packages:\n\n-   NumPy: for data manipulation\n-   Pandas: for data manipulation\n-   MatPlotLib: for data visualization\n-   Seaborn: for data visualization","dea6a7b6":"#### *Q3.*  Calculate F (Frequency) \u2212 Number of invoices by the customer from 01\/04\/ 2011 and 09\/12\/2011.","0e1130f0":"Continuing with preprocessing, from the metadata, we can derive that some transactions were canceled. Hence, we need to remove them to get a more accurate analysis. To do that, we use the string function contains() and fiter out only those rows in the dataframe whose InvoiceID does not contain the character 'C'.","5514de32":"After that, we check for duplicate records. To do this, we use the duplicated() function from the Pandas library.","78adc9b3":"As we can see, there are no negative values in these columns. Hence, the dataset is cleaned and ready to be analyzed.","c8c29b96":"#### *Q6 b.* Print the cluster centers of each customer segment and explain them intuitively.","aa0868be":"#### *Q1 a.*  Read and write a summary of the metadata.","b8df60e9":"To solve further questions, we create a new dataframe to store only the unique customer ids and their RFM values. To do this, we use the DataFrame() and loc() functions from the Pandas library.","ac0ecdb5":"Next, we build models by looping over 1 to 10 clusters using the RFM values and storing the within-the-cluster-sum-of-squared-distance (wcss) of each cluster by using the inertia_ parameter of the kmeans model. Then, we plot the inertia wrt to the cluster number of all the clusters and analyze to find the elbow point using pointplot() function from the Seaborn library.","239ccc23":"To solve Question 6b, we print the cluster centers using the cluster_centers_ parameter of the kmeans model.","7543b087":"As we can see, the three clusters formed by both the KMeans and Agglomerative Clustering models are roughly about the same size, although the cluster labels 0 and 2 are interchanged. From this, we can interpret that the customer segments obtained are more or less the same, no matter which algorithm we use.","9e20df55":"As we can see, as we proceed upwards, many small clusters are grouped together to form bigger clusters. If we cut the dendrogram between the 200000 and 300000 mark on the y-axis, we see 3 clusters - one blue, and two green. ","f11ea526":"Next, we write a function to plot the dendrogram. This function is taken from the official sklearn documentaion, and is aesthetically beautified using matplotlib functions.","2b64f67f":"#### *Q6 a.* Plot the clusters in a scatter plot and mark each segment differently using lmplot","51972494":"We also check for any negative values in the Quantity and Price column and figure out a way to deal with them. To do this, we use filter the values in the column and sum them up.","ee5ec144":"Next, we print out the size of each cluster using the count() function on the lists.","a05cb0aa":"To solve Question 7a, we first import dendrogram from the scipy.cluster.heirarchy package.","c908936b":"After that, we view the first few rows of the dataset using the head() function from the Pandas library.","cf8087ab":"#### *Q6 c.* Create the customer segments with Agglomerative algorithm by using number of clusters is suggested by elbow method.","880bd287":"To solve Question 6a, we first build a kmeans model with number of clusters to be 3 (as suggested by the elbow method) and fix the random_state for consistent results and use the RFM values."}}