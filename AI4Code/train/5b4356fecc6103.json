{"cell_type":{"f16627cb":"code","3b3c876c":"code","4c67a14a":"code","3f339559":"code","2b42b1d2":"code","ef77e5c5":"code","de081ae0":"code","537f0af9":"code","a47590ba":"code","8de2764d":"code","d0f18a68":"code","ab4656a3":"code","5069957e":"code","da56596e":"code","442cf117":"code","f44904f3":"code","489312d3":"markdown","f154655c":"markdown","1e0eef33":"markdown","2a1d7797":"markdown","a6053f36":"markdown","d4d5f41e":"markdown","633832eb":"markdown"},"source":{"f16627cb":"import torch\nimport torch.nn.functional as F\nfrom torch import nn, optim\nfrom torchvision import transforms\n\nimport pandas as pd\nimport numpy as np","3b3c876c":"dataset = pd.read_csv('..\/input\/train.csv')","4c67a14a":"# Percentage of data mounting for training that will be used for training tests.\nPERCENTAGE_OF_TESTS = 0.1\n\nlength_tests = int(len(dataset) * PERCENTAGE_OF_TESTS)\ntestdata = dataset[:length_tests]\ntraindata = dataset[length_tests:]\n\n# Verifies that all training data is being used.\ntestdata.shape[0] + traindata.shape[0] == len(dataset)","3f339559":"len(traindata)","2b42b1d2":"# Dataset responsible for manipulating data for training as well as training tests.\nclass DatasetMNIST(torch.utils.data.Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        item = self.data.iloc[index]\n                \n        image = item[1:].values.astype(np.uint8).reshape((28, 28, 1))\n        label = item[0]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image, label","ef77e5c5":"BATCH_SIZE = 100\n\ndef new_trainloader(random_affine=True):\n    train_transform = None\n\n    if random_affine == False:\n        train_transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5,), std=(0.5,))\n        ])\n    else:\n        train_transform = transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.RandomAffine(degrees=45, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5,), std=(0.5,))\n        ])\n    trainset = DatasetMNIST(traindata, transform=train_transform)\n    \n    return torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)","de081ae0":"test_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5,), std=(0.5,))\n])\n\ntestset = DatasetMNIST(testdata, transform=test_transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True)\n\ntrainloader = new_trainloader(random_affine=False)","537f0af9":"class Network(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.fc1 = nn.Linear(784, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 64)\n        self.fc4 = nn.Linear(64, 10)\n        \n        \n        self.dropout = nn.Dropout(p=0.1680)\n        \n    def forward(self, x):\n        # Make sure input tensor is flattened.\n        x = x.view(x.shape[0], -1)\n        \n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.dropout(F.relu(self.fc3(x)))\n\n        x = F.log_softmax(self.fc4(x), dim=1)\n        \n        return x","a47590ba":"# Configuring and Creating the Network for Training.\nLEARNING_RATE = 0.0001680\n\nmodel = Network()\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\nepochs = 500","8de2764d":"train_losses, test_losses = [], []\n\nfor e in range(epochs):\n    running_loss = 0\n    if (e == 3 or e % 5 == 0) and e != 5:\n        trainloader = new_trainloader()\n\n    for images, labels in trainloader:\n        # Clear the gradients, do this because gradients are accumulated.\n        optimizer.zero_grad()\n        \n        # Forward pass, get our log-probabilities.\n        log_ps = model(images)\n\n        # Calculate the loss with the logps and the labels.\n        loss = criterion(log_ps, labels)\n        \n        # Turning loss back.\n        loss.backward()\n        \n        # Take an update step and few the new weights.\n        optimizer.step()\n        \n        running_loss += loss.item()\n    else:\n        test_loss = 0\n        accuracy = 0\n        \n        # Turn off gradients for validation, saves memory and computations.\n        with torch.no_grad():\n            model.eval() # change the network to evaluation mode\n            for images, labels in testloader:\n                # Forward pass, get our log-probabilities.\n                log_ps = model(images)\n                \n                # Calculating probabilities for each class.\n                ps = torch.exp(log_ps)\n                \n                # Capturing the class more likely.\n                top_p, top_class = ps.topk(1, dim=1)\n                \n                # Verifying the prediction with the labels provided.\n                equals = top_class == labels.view(*top_class.shape)\n                \n                test_loss += criterion(log_ps, labels)\n                accuracy += torch.mean(equals.type(torch.FloatTensor))\n                \n        model.train() # change the network to training mode\n        \n        train_losses.append(running_loss\/len(trainloader))\n        test_losses.append(test_loss\/len(testloader))\n\n        if e == 0 or e == 10 or e % 50 == 0:\n            print(f\"Epoch: {e+1}\/{epochs}.. \",\n                  f\"Training Loss: {running_loss\/len(trainloader):.3f}.. \",\n                  f\"Test Loss: {test_loss\/len(testloader):.3f}.. \",\n                  f\"Test Accuracy: {accuracy\/len(testloader):.3f}\")","d0f18a68":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\n\nplt.plot(train_losses, label='Training loss')\nplt.plot(test_losses, label='Validation loss')\nplt.legend(frameon=False)","ab4656a3":"fig, axis = plt.subplots(3, 8, figsize=(20, 10))\nimages, labels = next(iter(testloader))\n\nfor i, ax in enumerate(axis.flat):\n    with torch.no_grad():\n        model.eval()\n        image = images[i]\n\n        log_ps = model(image)\n        ps = torch.exp(log_ps)\n        top_p, top_class = ps.topk(1, dim=1)\n        predicted = top_class\n\n        ax.imshow(image.view(28, 28), cmap='binary') # add image\n        ax.set(title = \"Predicted Digit: {}\".format(predicted.item())) # add label","5069957e":"class DatasetSubmissionMNIST(torch.utils.data.Dataset):\n    def __init__(self, file_path, transform=None):\n        self.data = pd.read_csv(file_path)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        image = self.data.iloc[index].values.astype(np.uint8).reshape((1, 784))\n\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image","da56596e":"submissionset = DatasetSubmissionMNIST('..\/input\/test.csv', transform=test_transform)\nsubmissionloader = torch.utils.data.DataLoader(submissionset, batch_size=BATCH_SIZE, shuffle=False)","442cf117":"submission = [['ImageId', 'Label']]\n\nwith torch.no_grad():\n    model.eval()\n    image_id = 1\n\n    for images in submissionloader:\n        log_ps = model(images)\n        ps = torch.exp(log_ps)\n        top_p, top_class = ps.topk(1, dim=1)\n        \n        for prediction in top_class:\n            submission.append([image_id, prediction.item()])\n            image_id += 1\n            \nprint(len(submission) - 1)","f44904f3":"import csv\n\nwith open('submission.csv', 'w') as submissionFile:\n    writer = csv.writer(submissionFile)\n    writer.writerows(submission)\n    \nprint('Submission Complete!')","489312d3":"### Importing and Modeling Data For Training","f154655c":"### Analyzing Loss Throughout Training","1e0eef33":"### Defining the Neural Network","2a1d7797":"### Creating Data For Submission","a6053f36":"### Making Some Predictions With the Trained Network","d4d5f41e":"### Import Libraries","633832eb":"### Training the Network"}}