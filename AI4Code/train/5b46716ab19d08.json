{"cell_type":{"cd3d3f51":"code","3200937f":"code","6a00d718":"code","844ab152":"code","0db61b7d":"markdown","cd4d241e":"markdown","94c92bc5":"markdown","18d1a726":"markdown","bd3d1d89":"markdown","4db2942f":"markdown"},"source":{"cd3d3f51":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom sklearn.linear_model import LinearRegression","3200937f":"# Creating signal\n\ndef generate_data(x, noise_threshold=0.1):\n    signal = np.sin(2 * x) + (1.5 * x) + 0.5\n    noise = np.random.normal(0, 1, size=len(x)) * noise_threshold\n    return signal + noise\n\nx = np.random.uniform(0, 10, 100)\ny = generate_data(x=x, noise_threshold=0.7)\n\nplt.figure(figsize=(10, 10))\n\nsignal_x = np.linspace(0, 10, 100)\nsignal_y = generate_data(x=signal_x, noise_threshold=0.0)\nplt.plot(signal_x, signal_y, color='cyan', label='Signal')\n\nplt.scatter(x=x, y=y, label='Noise')\n\nplt.legend()\nplt.title(\"The Signal and the Noise\")\nplt.show()","6a00d718":"plt.figure(figsize=(15, 15))\n\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    \n    signal_x = np.linspace(0, 10, 100)\n    signal_y = generate_data(x=signal_x, noise_threshold=0.0)\n    plt.plot(signal_x, signal_y, color='cyan')\n\n    x = np.random.uniform(0, 10, 100)\n    y = generate_data(x=x, noise_threshold=0.7)\n    plt.scatter(x=x, y=y, s= 10)\n\n    model = LinearRegression()\n    model.fit(np.expand_dims(x, axis=1), y)\n\n    fit_x = np.linspace(0, 10, 100)\n    fit_y = (model.coef_ * fit_x) + model.intercept_\n    plt.plot(fit_x, fit_y, color='red')\n\nplt.suptitle(\"High Bias, Low Variance Model\")\nplt.show()","844ab152":"def generate_features(x, deg):\n    return np.stack([x**i for i in range(1, deg + 1)]).T\n\ndeg = 13\n\nplt.figure(figsize=(15, 15))\n\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n\n    signal_x = np.linspace(0, 10, 100)\n    signal_y = generate_data(x=signal_x, noise_threshold=0.0)\n    plt.plot(signal_x, signal_y, color='cyan')\n\n    x = np.random.uniform(0, 10, 100)\n    y = generate_data(x=x, noise_threshold=0.7)\n    plt.scatter(x=x, y=y, s= 10)\n\n    X = generate_features(x, deg=deg)\n    model = LinearRegression()\n    model.fit(X, y)\n\n    fit_x = np.linspace(0, 10, 100)\n    fit_X = generate_features(fit_x, deg=deg)\n    fit_y = np.matmul(fit_X, model.coef_) + model.intercept_\n    plt.plot(fit_x, fit_y, color='red')\n    \nplt.suptitle(\"High Variance, Low Bias Model\")\nplt.show()","0db61b7d":"# High Bias, Low Variance  \n   \n**High bias:** As the nosie generated by the signal varies, the average distance between the fit and the signal is high.  \n**Low variance:** As the noise generated by the signal varies, the fit does not vary much.  ","cd4d241e":"# Understanding Bias-Variance Tradeoff  \n  \nThis notebook aims to provide a graphical intuition of the bias-variance tradeoff in machine learning.  \nWe will look at what happens to a model as we vary the noise generated by the data-generating signal and analyze the results.","94c92bc5":"# Generate Synthetic Data","18d1a726":"# Imports","bd3d1d89":"# YouTube Tutorial Included!  \n  \n***\n  \nThis notebook was made to accompany a YouTube video that I made for my channel.  \n  \nIf you want an in-depth explanation of the steps taken, you can check out the video here:  \nhttps:\/\/youtu.be\/6ftBXIMegN4","4db2942f":"# High Variance, Low Bias Model  \n  \n**High variance:** As the noise generated by the signal varies, the fit varies substantially.  \n**Low bias:** As the nosie generated by the signal varies, the average distance between the fit and the signal is low."}}