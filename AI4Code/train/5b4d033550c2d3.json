{"cell_type":{"54552cc6":"code","124d097f":"code","d6add2a7":"code","4352e594":"code","23fd2eac":"code","f79924f6":"code","a881efeb":"code","a64391ad":"code","8a69ebee":"code","ffda37b7":"code","ac2c8915":"markdown","9ea0b500":"markdown","1ddbdca8":"markdown","2dfac9ba":"markdown","adb34a5b":"markdown","40046001":"markdown","a594a754":"markdown","0e8217d9":"markdown"},"source":{"54552cc6":"import os\nimport time\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n\nimport transformers\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score","124d097f":"def bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n            \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n        tokens += [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n    \n    return np.array(all_tokens)\n\ndef build_model(transformer, max_len=512):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    sequence_output = transformer(input_word_ids)[0]\n    cls_token = sequence_output[:, 0, :]\n    out = Dense(1, activation='sigmoid')(cls_token)\n    \n    model = Model(inputs=input_word_ids, outputs=out)\n    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model","d6add2a7":"train = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest  = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")","4352e594":"%%time\n# Distil Bert Base\n# model_to_use = 'distilbert-base-uncased'\n\n# model_to_use = 'albert-base-v1'\n# model_to_use = 'albert-large-v1'\n# model_to_use = 'albert-xlarge-v1'\n# model_to_use = 'albert-xxlarge-v1'\n\nmodel_to_use = 'bert-base-uncased'\n# model_to_use = 'bert-large-uncased'\n\n# model_to_use = 'roberta-base'\n# model_to_use = 'roberta-large'\n\nif model_to_use.split('-')[0] == 'distilbert':\n    transformer_layer = transformers.TFDistilBertModel.from_pretrained(model_to_use)\n    tokenizer = transformers.DistilBertTokenizer.from_pretrained(model_to_use)\n    \nif model_to_use.split('-')[0] == 'albert':\n    transformer_layer = transformers.TFAlbertModel.from_pretrained(model_to_use)\n    tokenizer = transformers.AlbertTokenizer.from_pretrained(model_to_use)\n    \nif model_to_use.split('-')[0] == 'bert':\n    transformer_layer = transformers.TFBertModel.from_pretrained(model_to_use)\n    tokenizer = transformers.BertTokenizer.from_pretrained(model_to_use)\n    \nif model_to_use.split('-')[0] == 'roberta':\n    transformer_layer = transformers.TFRobertaModel.from_pretrained(model_to_use)\n    tokenizer = transformers.RobertaTokenizer.from_pretrained(model_to_use)","23fd2eac":"max_seq_len = 160\n\ntrain_input = bert_encode(train.text.values, tokenizer, max_len=max_seq_len)\ntest_input  = bert_encode(test.text.values, tokenizer, max_len=max_seq_len)\ntrain_label = train.target.values\n\n# Data split\nX_train, X_test, y_train, y_test = train_test_split(train_input, \n                                                    train_label, \n                                                    test_size=0.25,\n                                                    random_state=42, \n                                                    shuffle=True)\n# X_train.shape, X_test.shape = ((5709, 160), (1904, 160))","f79924f6":"def metrics(y_true, y_pred):\n    print(\"\\nF1-score: \", round(f1_score(y_true, y_pred), 2))\n    print(\"Precision: \", round(precision_score(y_true, y_pred), 2))\n    print(\"Recall: \", round(recall_score(y_true, y_pred), 2))","a881efeb":"model = build_model(transformer_layer, max_len=160)\nmodel.summary()","a64391ad":"# Training\nstart_time = time.time()\ntrain_history = model.fit(X_train, y_train, epochs = 3, batch_size = 8)\nend_time = time.time()\nprint(\"\\n=>Training time :\", round(end_time - start_time, 1), 's')","8a69ebee":"# Validation\nstart_time = time.time()\ntest_pred = model.predict(X_test, verbose=1).round().astype(int)\nend_time = time.time()\n\nprint('\\n=>Average Inference Time :', round((end_time - start_time) \/ len(test_pred) * 1000, 1), 'ms')\nmetrics(y_test, test_pred)","ffda37b7":"submission['target'] = model.predict(test_input, verbose=1).round().astype(int)\nsubmission.to_csv('submission.csv', index=False)","ac2c8915":"## 0 - Benchmark","9ea0b500":"## 3 - Modeling","1ddbdca8":"## 2 - Load & Proprocess","2dfac9ba":"## 4 - Submission","adb34a5b":"* Is there a winner in terms of F1 in this task ? <span style=\"color:red\">Not really.<\/span>\n* In similar classification tasks, which model is more suitable to use, especially in a production environment ? <span style=\"color:red\">DistilBert could be a good choice. It gives acceptable results with a relatively short delay.<\/span>","40046001":"This is an addition to my previous work :\n* [[Tweet NLP Benchmark 1] CNN RNN with GloVe](https:\/\/www.kaggle.com\/vicioussong\/tweet-nlp-benchmark-1-cnn-rnn-with-glove)\n\nThis work is a Benchmark for comparing Elmo and Bert Family. I focused on the indicators below : \n* Performance (F1 \/ Precision \/ Recall)\n* Training \/ Inference speed\n* Model size\n\nMy work is inspired by and based on the following notebooks :\n* [NLP (Disaster Tweets) with Glove and LSTM](https:\/\/www.kaggle.com\/mariapushkareva\/nlp-disaster-tweets-with-glove-and-lstm)\n* [Disaster NLP: Keras BERT using TFHub](https:\/\/www.kaggle.com\/xhlulu\/disaster-nlp-keras-bert-using-tfhub)","a594a754":"| Model           | F1   | Precision | Recall | Training Time | Inference Time |\n|-----------------|------|-----------|--------|---------------|----------------|\n| DistilBert Base | 0.78 | 0.83      | 0.74   | 198.1 s       | 3.9 ms         |\n| AlBert Base     | 0.79 | 0.78      | 0.81   | 371.0 s       | 7.9 ms         |\n| AlBert Large    | 0.78 | 0.84      | 0.73   | 1022.9 s      | 21.6 ms        |\n| Bert Base       | 0.8  | 0.79      | 0.82   | 368.2 s       | 8.3 ms         |\n| Bert Large      | 0.78 | 0.74      | 0.83   | 1060.9 s      | 21.7 ms        |\n| RoBERTa Base    | 0.78 | 0.73      | 0.85   | 390.3         | 8.3 ms         |","0e8217d9":"## 1 - Import"}}