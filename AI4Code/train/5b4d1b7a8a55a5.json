{"cell_type":{"b604b041":"code","bcb4ce82":"code","20154739":"code","f0bd72f2":"code","0b037084":"code","9b06e221":"code","fc2dda28":"code","5e6843b9":"code","40465f19":"code","af07207c":"code","d31fa740":"code","470406bc":"code","b7644821":"code","b567451b":"code","f1bec3eb":"code","f9859599":"code","38a4eaf3":"code","40e7cb23":"code","6a69fcbf":"code","f1bd3e42":"code","b28a86d7":"code","0421bce5":"code","a91607f9":"code","dc393b22":"code","733d5e37":"code","551b1fcb":"code","3368f095":"code","4ef9e00e":"code","de0e9eaa":"code","4616c9c3":"code","6f916a97":"code","fcf1e9b2":"code","768533dc":"code","ede08442":"code","2f03bbd1":"code","9689adb1":"code","57ea916b":"code","27770188":"code","8d55bd9b":"code","3180984d":"code","126728b6":"code","eb051ca9":"code","6ab13179":"code","46c5a78a":"code","bace6ea9":"code","772ca1f2":"code","5541e454":"code","dfbdaa3d":"code","d4f5038b":"code","b0474c33":"code","85f614b5":"code","bfef0abb":"code","dd013ca2":"code","d5b09ab5":"code","a02f4085":"code","9efd92d4":"code","36f44f4d":"code","93d75428":"code","a8dd3176":"code","873f3c0a":"code","22d043c4":"code","0ff73dc2":"code","43f0a1a4":"code","4bc9090a":"code","e4eec776":"code","bb6f0a73":"code","d4604e3f":"code","964a0093":"code","f3066b88":"code","945b13d1":"code","ba2ab7a7":"code","4bae9c81":"code","48b62db2":"code","fd3fe09f":"code","ccede003":"code","afe4f4a5":"code","60d0f47f":"code","e9b79d45":"code","a61c7728":"code","26d0a3a8":"code","63695e8c":"code","411c6794":"code","ee008d2e":"code","06c9b149":"code","c5fc8a88":"code","9ce9e038":"code","f835a9bb":"code","c7446b45":"code","45181d4c":"code","43baa5d3":"code","de0ab38c":"code","e2c6477c":"code","6993c8c7":"code","147900d0":"markdown","0d9ead4d":"markdown","a6eec09e":"markdown","589c528d":"markdown","adc8e18b":"markdown","2d364cdc":"markdown","2a809f70":"markdown","4c5dc2c1":"markdown","c0a42af2":"markdown","15f75910":"markdown","7ec41b1d":"markdown","168b99f5":"markdown","fa5f471c":"markdown","dc7d272b":"markdown","7d7f431e":"markdown","3dacbdff":"markdown","972eff0f":"markdown","dfc4bd57":"markdown","ddec12d3":"markdown","8e45c59a":"markdown","dc3ae7b7":"markdown","bfd0590c":"markdown","26e7b7f4":"markdown","f877af9f":"markdown","8d1a3cc3":"markdown","ebf36270":"markdown","11131f39":"markdown","7e300b3c":"markdown","a781232e":"markdown","896dd2e6":"markdown","51ba38c3":"markdown","15419359":"markdown","25b126c3":"markdown"},"source":{"b604b041":"import pandas as pd\nimport numpy as np\nimport pylab as pl\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","bcb4ce82":"submission = pd.read_csv('..\/input\/sample_submission.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\ntrain_df = pd.read_csv(\"..\/input\/train.csv\")","20154739":"print(train_df.shape)\ntrain_df.head()","f0bd72f2":"print(test_df.shape)\ntest_df.head()","0b037084":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","9b06e221":"train_df.dtypes.to_frame().head()","fc2dda28":"test_df.dtypes.to_frame().head()","5e6843b9":"# Some basic stats on the target variable\nprint ('# target = 1: {}'.format(len(train_df[train_df['target'] == 1])))\nprint ('# target = 0: {}'.format(len(train_df[train_df['target'] == 0])))  \nprint ('% target = 1: {}%'.format(round(float(len(train_df[train_df['target'] == 1])) \/ len(train_df) * 100))) \ntax=round(float(len(train_df[train_df['target'] == 1])) \/ len(train_df) * 100)","40465f19":"plt.figure(num=None, figsize=(20, 20), dpi=80, facecolor='w', edgecolor='k')\nplt.pcolor(train_df.corr(), cmap='Accent')\nplt.colorbar()\nplt.show()","af07207c":"train_df_correlations = train_df.corr()\ntrain_df_correlations = train_df_correlations.values.flatten()\ntrain_df_correlations = train_df_correlations[train_df_correlations != 1]\n\nplt.figure(figsize=(20,5))\nsns.distplot(train_df_correlations, color=\"Red\", label=\"train\")\nplt.xlabel(\"Correlation values found in train (except 1)\")\nplt.ylabel(\"Density\")\nplt.title(\"Are there correlations between features?\"); \nplt.legend();","d31fa740":"def plot_feature_distribution(df0, df1, df2, label0, label1, label2, features):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(10,10,figsize=(24,18))\n\n    for feature in features:\n        i += 1\n        plt.subplot(10,10,i)\n        sns.kdeplot(df0[feature], bw=0.5,label=label0)\n        sns.kdeplot(df1[feature], bw=0.5,label=label1)\n        sns.kdeplot(df2[feature], bw=0.5,label=label2)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n        plt.tick_params(axis='y', which='major', labelsize=6)\n    plt.show();","470406bc":"t0 = train_df.loc[train_df['target'] == 0]\nt1 = train_df.loc[train_df['target'] == 1]\nt2 = test_df\nfeatures = train_df.columns.values[2:102]\nplot_feature_distribution(t0, t1, t2, '0', '1', 'test', features)","b7644821":"features = train_df.columns.values[102:202]\nplot_feature_distribution(t0, t1, t2, '0', '1', 'test', features)","b567451b":"features = train_df.columns.values[202:302]\nplot_feature_distribution(t0, t1, t2, '0', '1', 'test', features)","f1bec3eb":"d=pd.Series(range(0,300))","f9859599":"for df in [test_df, train_df]: \n    d=pd.Series(d)\n    d=(d + 1).tolist()\n    for x in d:\n        df[df.columns[x]]=(df[df.columns[x]]-df[df.columns[x]].min())\/(df[df.columns[x]].max()-df[df.columns[x]].min())\n        df[df.columns[x]]=np.log((1+df[df.columns[x]]))","38a4eaf3":"t0 = train_df.loc[train_df['target'] == 0]\nt1 = train_df.loc[train_df['target'] == 1]\nt2 = test_df\nfeatures = train_df.columns.values[2:102]\nplot_feature_distribution(t0, t1, t2, '0', '1', 'test', features)","40e7cb23":"features = train_df.columns.values[102:202]\nplot_feature_distribution(t0, t1, t2, '0', '1', 'test', features)","6a69fcbf":"features = train_df.columns.values[202:302]\nplot_feature_distribution(t0, t1, t2, '0', '1', 'test', features)","f1bd3e42":"#sample=['target','4','13','16','24','33','65','73','80','91','183','189','194','199','217','276','295','298']\nsample= ['target','16', '33', '80', '91', '217', '295']","b28a86d7":"sns.set(style=\"ticks\", color_codes=True)\npair_sample=train_df[sample]\n# Pairwise plots\npplot = sns.pairplot(pair_sample, hue=\"target\", height=3, kind ='scatter', diag_kind='kde', plot_kws=dict(s=20, linewidth=0) ) ","0421bce5":"#Ex.: between the variables\nsns.lmplot( x='33', y='217', data=train_df, fit_reg=False, hue='target', legend=True)\nsns.lmplot( x='33', y='16', data=train_df, fit_reg=False, hue='target', legend=True)","a91607f9":"#feat_engin=[4,13,16,24,33,65,73,80,91,183,189,194,199,217,276,295,298]\n#feat_engin=[33,217,295,298]\n#feat_engin=[2,4,6,11,14,17,21,29,33,45,46,61,70,71,74,76,80,131,132,135,141,177,205,231,246,293]\n#feat_engin2=[1,13,16,25,26,42,48,65,66,83,111,116,117,138,147,176,195,228,237,266]","dc393b22":"#for df in [test_df, train_df]:\n#      \n#    d=pd.Series(feat_engin)\n#    d=(d + 1).tolist()\n#           \n#    df['300'] = df[df.columns[d]].sum(axis=1)  \n#    df['301'] = df[df.columns[d]].min(axis=1) \n#    df['302'] = df[df.columns[d]].max(axis=1) \n#    df['303'] = df[df.columns[d]].mean(axis=1) \n#    df['304'] = df[df.columns[d]].var(axis=1)\n#    df['305'] = df[df.columns[d]].sum(axis=1)+df[df.columns[d]].median(axis=1)\n#    df['306'] = df[df.columns[d]].std(axis=1) \n#    df['307'] = df[df.columns[d]].mean(axis=1)\n#    df['308'] = df[df.columns[d]].median(axis=1)\n#    \n#    d2=pd.Series(feat_engin2)\n#    d2=(d2 + 1).tolist()\n           \n#    df['309'] = df[df.columns[d2]].sum(axis=1)  \n#    df['310'] = df[df.columns[d2]].min(axis=1) \n#    df['311'] = df[df.columns[d2]].max(axis=1) \n#    df['312'] = df[df.columns[d2]].mean(axis=1) \n#    df['313'] = df[df.columns[d2]].var(axis=1)\n#    df['314'] = df[df.columns[d2]].sum(axis=1)+df[df.columns[d2]].median(axis=1)\n#    df['315'] = df[df.columns[d2]].std(axis=1) \n#    df['316'] = df[df.columns[d2]].mean(axis=1)\n#    df['317'] = df[df.columns[d2]].median(axis=1)","733d5e37":"#train_df[train_df.columns[302:]].head()","551b1fcb":"#test_df[test_df.columns[301:]].head()","3368f095":"#def plot_new_feature_distribution(df1, df2, label1, label2, features):\n#    i = 0\n#    sns.set_style('whitegrid')\n#    plt.figure()\n#    fig, ax = plt.subplots(3,6,figsize=(24,9))\n#\n#    for feature in features:\n#        i += 1\n#        plt.subplot(3,6,i)\n#        sns.kdeplot(df1[feature], bw=0.5,label=label1)\n#        sns.kdeplot(df2[feature], bw=0.5,label=label2)\n#        plt.xlabel(feature, fontsize=9)\n#        locs, labels = plt.xticks()\n#        plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n#        plt.tick_params(axis='y', which='major', labelsize=6)\n#    plt.show();","4ef9e00e":"#t0 = train_df.loc[train_df['target'] == 0]\n#t1 = train_df.loc[train_df['target'] == 1]\n#features = train_df.columns.values[302:]\n#plot_new_feature_distribution(t0, t1, '0', '1', features)","de0e9eaa":"#sns.lmplot( x='305', y='314', data=train_df, fit_reg=False, hue='target', legend=True)\n#sns.lmplot( x='305', y='309', data=train_df, fit_reg=False, hue='target', legend=True)","4616c9c3":"#z_selection=pd.DataFrame()\n#d=pd.Series()\n#z_box=train_df.groupby(['target']).describe()\n#z_box.head()","6f916a97":"#i=0\n#minim=1\n#for x in train_df.columns.drop(['id','target']):\n#    z_selection[x]=[abs((z_box[x]['25%'].iloc[(0)]-z_box[x]['25%'].iloc[(1)])\/(z_box[x]['25%'].iloc[(0)]-z_box[x]['75%'].iloc[(1)]))+\n#                   abs((z_box[x]['75%'].iloc[(0)]-z_box[x]['75%'].iloc[(1)])\/(z_box[x]['75%'].iloc[(0)]-z_box[x]['25%'].iloc[(1)]))]\n#d=np.where(z_selection>0.5)[1]\n#d=feat_engin\nd=sample[1:]","fcf1e9b2":"result=pd.DataFrame()","768533dc":"y = train_df['target'] \nX = train_df.drop(['target','id'], axis=1) # Data set to create and tunning the model\nX_ol=X[d] # Data set with the selected features  - to be studied if is an improvement.\nprint ('Train set:', X.shape,  y.shape, X_ol.shape)","ede08442":"from sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.4, random_state=6)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)\n\nX_train_ol=X_train[d]\nX_test_ol=X_test[d]\n\nprint ('Train set select:', X_train_ol.shape,  y_train.shape)\nprint ('Test set select:', X_test_ol.shape,  y_test.shape)","2f03bbd1":"print ('% target = 1 in train set: {}%'.format(round(float(len(y_train[y_train==1])) \/ len(y_train) * 100))) \nprint ('% target = 1 in test set: {}%'.format(round(float(len(y_test[y_test==1])) \/ len(y_test) * 100)))","9689adb1":"from sklearn import linear_model\n#Model with all 300 features\nregr_all = linear_model.LinearRegression(fit_intercept=True, normalize=True)\nregr_all.fit(X_train,y_train)","57ea916b":"y_hat= regr_all.predict(X_test)\ny_hat=y_hat*0.5\/(np.sort(y_hat)[100-tax]) # --> ajust the array to have 64% of target > 0.5\nresult['regr_all']=y_hat\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat>=0.5])) \/ len(y_hat) * 100))) \n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % regr_all.score(X_test, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat)) #1 is best","27770188":"#Model with the selected features\nregr_ol = linear_model.LinearRegression(fit_intercept=True, normalize=True)\nregr_ol.fit(X_train_ol,y_train)","8d55bd9b":"regr_ol.predict(X_test_ol)\n#y_hat=(y_hat-y_hat.min())\/(y_hat.max()-y_hat.min()) # turn the result to be between 0 and 1\ny_hat=y_hat*0.5\/(np.sort(y_hat)[100-tax]) # --> ajust the array to have 64% of target > 0.5\nresult['regr_ol']=y_hat\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % regr_ol.score(X_test_ol, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat)) #1 is best","3180984d":"from sklearn.feature_selection import RFE\n#Selecting variables via RFE\ni=0\nscore=pd.DataFrame()\nfor nfeatures in range(5,301,3):\n    selector = RFE(regr_all, nfeatures, step=1,verbose=0)\n    selector.fit(X_train,y_train)\n    y_hat= selector.predict(X_test)\n    score[i]=[nfeatures,roc_auc_score(y_test, y_hat)]\n    #print(score, nfeatures)\n    i=i+1\n    \nscore=score.transpose()\nscore.columns=['NumberOfFeatures','AUC ROC']\nplt.plot(score['NumberOfFeatures'],score['AUC ROC'])\nplt.xlabel('Number of Features')\nplt.ylabel('AUC ROC')\nplt.title('AUC ROC x Number of features')\nplt.grid(True)\nplt.show() # best is between 90 and 100 or 201 and 210\n\n#selector.get_support(indices=True) # selected features via RFE","126728b6":"best=score[score['AUC ROC']>score['AUC ROC'].max()*0.95]\nbest","eb051ca9":"from sklearn.feature_selection import RFE\nregr_sel = RFE(regr_all, 4, step=1,verbose=0)\nregr_sel.fit(X_train,y_train)","6ab13179":"y_hat= regr_sel.predict(X_test)\ny_hat=y_hat*0.5\/(np.sort(y_hat)[100-tax]) # --> ajust the array to have 64% of target > 0.5\nresult['regre_sel']=y_hat\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % regr_sel.score(X_test, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat)) #1 is best","46c5a78a":"from sklearn.tree import DecisionTreeClassifier\nparam_grid = { 'criterion': ['gini','entropy'],\n              'splitter': ['best','random'],\n              'max_depth': [2,4,10,20,None],\n              'max_features' : ['auto', 'sqrt', 'log2']}\nTree = DecisionTreeClassifier()","bace6ea9":"grid = GridSearchCV(estimator=Tree, param_grid=param_grid, scoring='roc_auc', verbose=1, n_jobs=-1,cv=2)\ngrid.fit(X_train,y_train)\nprint(\"Best Score= \" + str(grid.best_score_))\nprint (\"Best Parameters= \"+str(grid.best_params_))\nbest_param=grid.best_params_","772ca1f2":"Tree = DecisionTreeClassifier(**best_param)\nTree.fit(X_train,y_train)","5541e454":"y_hat= Tree.predict(X_test)\nresult['Tree']=y_hat\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % Tree.score(X_test, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat)) #1 is best","dfbdaa3d":"grid = GridSearchCV(estimator=Tree, param_grid=param_grid, scoring='roc_auc', verbose=1, n_jobs=-1,cv=2)\ngrid.fit(X_train_ol,y_train)\nprint(\"Best Score= \" + str(grid.best_score_))\nprint (\"Best Parameters= \"+str(grid.best_params_))\nbest_param=grid.best_params_","d4f5038b":"Tree_ol = DecisionTreeClassifier(**best_param)\nTree_ol.fit(X_train_ol,y_train)","b0474c33":"y_hat= Tree_ol.predict(X_test_ol)\nresult['Tree_ol']=y_hat\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % Tree_ol.score(X_test_ol, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat)) #1 is best","85f614b5":"#Selecting variables via RFE\ni=0\nscore=pd.DataFrame()\nfor nfeatures in range(5,301,5):\n    selector = RFE(Tree, nfeatures, step=1,verbose=0)\n    selector.fit(X_train,y_train)\n    y_hat= selector.predict(X_test)\n    score[i]=[nfeatures,roc_auc_score(y_test, y_hat)]\n    #print(score, nfeatures)\n    i=i+1\n    \nscore=score.transpose()\nscore.columns=['NumberOfFeatures','AUC ROC']\nplt.plot(score['NumberOfFeatures'],score['AUC ROC'])\nplt.xlabel('Number of Features')\nplt.ylabel('AUC ROC')\nplt.title('AUC ROC x Number of features')\nplt.grid(True)\nplt.show() \n","bfef0abb":"Tree_selec = RFE(Tree, 94, step=1,verbose=0)\nTree_selec.fit(X_train,y_train)","dd013ca2":"y_hat= Tree_selec.predict(X_test)\nresult['Tree_selec']=y_hat\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % Tree_selec.score(X_test, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat)) #1 is best","d5b09ab5":"from sklearn.linear_model import LogisticRegression\nparam_grid = { 'C': [0.001,0.1,10.0,100.0],\n              'fit_intercept': [True,False],\n              'class_weight': ['balanced', None],\n              'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\nLR = LogisticRegression()","a02f4085":"grid = GridSearchCV(estimator=LR, param_grid=param_grid, scoring='roc_auc', verbose=1, n_jobs=-1,cv=2)\ngrid.fit(X_train,y_train)\nprint(\"Best Score= \" + str(grid.best_score_))\nprint (\"Best Parameters= \"+str(grid.best_params_))\nbest_param=grid.best_params_","9efd92d4":"LR = LogisticRegression(**best_param)\nLR.fit(X_train,y_train)","36f44f4d":"y_hat= LR.predict_proba(X_test)\ny_hat=y_hat*0.5\/(np.sort(y_hat[:,1])[100-tax]) # --> ajust the array to have 64% of target > 0.5\nresult['LR']=y_hat[:,1]\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat[:,1]>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat[:,1] - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % LR.score(X_test, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat[:,1])) #1 is best","93d75428":"grid = GridSearchCV(estimator=LR, param_grid=param_grid, scoring='roc_auc', verbose=1, n_jobs=-1,cv=2)\ngrid.fit(X_train_ol,y_train)\nprint(\"Best Score= \" + str(grid.best_score_))\nprint (\"Best Parameters= \"+str(grid.best_params_))\nbest_param=grid.best_params_","a8dd3176":"LR_ol = LogisticRegression(**best_param)\nLR_ol.fit(X_train_ol,y_train)","873f3c0a":"y_hat= LR_ol.predict_proba(X_test_ol)\ny_hat=y_hat*0.5\/(np.sort(y_hat[:,1])[100-tax]) # --> ajust the array to have 64% of target > 0.5\nresult['LR_ol']=y_hat[:,1]\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat[:,1]>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat[:,1] - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % LR_ol.score(X_test_ol, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat[:,1])) #1 is best","22d043c4":"#Selecting variables via RFE\ni=0\nscore=pd.DataFrame()\nfor nfeatures in range(5,301,3):\n    selector = RFE(LR, nfeatures, step=1,verbose=0)\n    selector.fit(X_train,y_train)\n    y_hat= selector.predict(X_test)\n    score[i]=[nfeatures,roc_auc_score(y_test, y_hat)]\n    #print(score, nfeatures)\n    i=i+1\n    \nscore=score.transpose()\nscore.columns=['NumberOfFeatures','AUC ROC']\nplt.plot(score['NumberOfFeatures'],score['AUC ROC'])\nplt.xlabel('Number of Features')\nplt.ylabel('AUC ROC')\nplt.title('AUC ROC x Number of features')\nplt.grid(True)\nplt.show() ","0ff73dc2":"#take the best results\nbest=score[score['AUC ROC']>score['AUC ROC'].max()*0.95]\nbest","43f0a1a4":"LR_selec = RFE(LR, 14, step=1,verbose=0)\nLR_selec.fit(X_train,y_train)","4bc9090a":"y_hat= LR_selec.predict_proba(X_test)\ny_hat=y_hat*0.5\/(np.sort(y_hat[:,1])[100-tax]) # --> ajust the array to have 64% of target > 0.5\nresult['LR_select']=y_hat[:,1]\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat[:,1]>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat[:,1] - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % LR_selec.score(X_test, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat[:,1])) #1 is best","e4eec776":"from sklearn.neural_network import MLPClassifier\nparam_grid = { 'activation': ['identity', 'logistic', 'tanh', 'relu'],\n              'solver': ['lbfgs', 'sgd', 'adam'],\n              'learning_rate': ['constant', 'invscaling', 'adaptive']}\nMLPerseptron = MLPClassifier()","bb6f0a73":"grid = GridSearchCV(estimator=MLPerseptron, param_grid=param_grid, scoring='roc_auc', verbose=1, n_jobs=-1,cv=2)\ngrid.fit(X_train,y_train)\nprint(\"Best Score= \" + str(grid.best_score_))\nprint (\"Best Parameters= \"+str(grid.best_params_))\nbest_param=grid.best_params_","d4604e3f":"MLPerseptron = MLPClassifier(**best_param)\nMLPerseptron.fit(X_train,y_train)","964a0093":"y_hat= MLPerseptron.predict_proba(X_test)\ny_hat=y_hat*0.5\/(np.sort(y_hat[:,1])[100-tax]) # --> ajust the array to have 64% of target > 0.5\nresult['MLPerseptron']=y_hat[:,1]\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat[:,1]>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat[:,1] - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % MLPerseptron.score(X_test, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat[:,1])) #1 is best","f3066b88":"grid = GridSearchCV(estimator=MLPerseptron, param_grid=param_grid, scoring='roc_auc', verbose=1, n_jobs=-1,cv=2)\ngrid.fit(X_train_ol,y_train)\nprint(\"Best Score= \" + str(grid.best_score_))\nprint (\"Best Parameters= \"+str(grid.best_params_))\nbest_param=grid.best_params_","945b13d1":"MLPerseptron_ol = MLPClassifier(**best_param)\nMLPerseptron_ol.fit(X_train_ol,y_train)","ba2ab7a7":"y_hat= MLPerseptron_ol.predict_proba(X_test_ol)\ny_hat=y_hat*0.5\/(np.sort(y_hat[:,1])[100-tax]) # --> ajust the array to have 64% of target > 0.5\nresult['MLPerseptron_ol']=y_hat[:,1]\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat[:,1]>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat[:,1] - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % MLPerseptron_ol.score(X_test_ol, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat[:,1])) #1 is best","4bae9c81":"from sklearn.naive_bayes import GaussianNB\nparam_grid = { 'priors': [None],\n              'var_smoothing': [1e-3,1e-6,1e-9,1e-12]}\ng_NB = GaussianNB()","48b62db2":"grid = GridSearchCV(estimator=g_NB, param_grid=param_grid, scoring='roc_auc', verbose=1, n_jobs=-1,cv=2)\ngrid.fit(X_train,y_train)\nprint(\"Best Score= \" + str(grid.best_score_))\nprint (\"Best Parameters= \"+str(grid.best_params_))\nbest_param=grid.best_params_","fd3fe09f":"g_NB = GaussianNB(**best_param)\ng_NB.fit(X_train, y_train)","ccede003":"y_hat= g_NB.predict_proba(X_test)\ny_hat=y_hat*0.5\/(np.sort(y_hat[:,1])[100-tax]) # --> ajust the array to have 64% of target > 0.5\nresult['g_NB']=y_hat[:,1]\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat[:,1]>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat[:,1] - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % g_NB.score(X_test, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat[:,1])) #1 is best","afe4f4a5":"grid.fit(X_train_ol,y_train)\nprint(\"Best Score= \" + str(grid.best_score_))\nprint (\"Best Parameters= \"+str(grid.best_params_))\nbest_param=grid.best_params_","60d0f47f":"grid.fit(X_train_ol,y_train)\nbest_param=grid.best_params_\ng_NB_ol = GaussianNB(**best_param)\ng_NB_ol.fit(X_train_ol, y_train)","e9b79d45":"y_hat= g_NB.predict_proba(X_test)\ny_hat=y_hat*0.5\/(np.sort(y_hat[:,1])[100-tax]) # --> ajust the array to have 64% of target > 0.5\nresult['g_NB_ol']=y_hat[:,1]\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat[:,1]>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat[:,1] - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % g_NB.score(X_test, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat[:,1])) #1 is best","a61c7728":"from sklearn.neighbors import KNeighborsClassifier\nparam_grid = { 'n_neighbors': list(range(4,100)),\n              'weights': ['uniform','distance'],\n              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n              'p' : [1,2]}\nknn = KNeighborsClassifier()","26d0a3a8":"grid = GridSearchCV(estimator=knn, param_grid=param_grid, scoring=  'roc_auc', verbose=1, n_jobs=-1)\ngrid.fit(X_train,y_train)\nprint(\"Best Score= \" + str(grid.best_score_))\nprint (\"Best Parameters= \"+str(grid.best_params_))\nbest_param=grid.best_params_","63695e8c":"knn = KNeighborsClassifier(**best_param)\nknn.fit(X_train, y_train)","411c6794":"y_hat= knn.predict_proba(X_test)\ny_hat=y_hat*0.5\/(np.sort(y_hat[:,1])[100-tax]) # --> ajust the array to have 64% of target > 0.5\nresult['knn']=y_hat[:,1]\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat[:,1]>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat[:,1] - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % knn.score(X_test, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat[:,1])) #1 is best","ee008d2e":"grid.fit(X_train_ol,y_train)\nprint(\"Best Score= \" + str(grid.best_score_))\nprint (\"Best Parameters= \"+str(grid.best_params_))\nbest_param=grid.best_params_","06c9b149":"grid.fit(X_train_ol,y_train)\nbest_param=grid.best_params_\nknn_ol = KNeighborsClassifier(**best_param)\nknn_ol.fit(X_train_ol, y_train)","c5fc8a88":"y_hat= knn_ol.predict_proba(X_test_ol)\ny_hat=y_hat*0.5\/(np.sort(y_hat[:,1])[100-tax]) # --> ajust the array to have 64% of target > 0.5\nresult['knn_ol']=y_hat[:,1]\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat[:,1]>=0.5])) \/ len(y_hat) * 100)))\n\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat[:,1] - y_test) ** 2)) # 0 is best score\nprint('Variance score: %.2f' % knn_ol.score(X_test_ol, y_test)) # 1 is perfect prediction\nprint('AUC ROC: %.2f' % roc_auc_score(y_test, y_hat[:,1])) #1 is best","9ce9e038":"temp=pd.DataFrame()\ntemp['mean']=result.mean(axis=1) \nresult2=pd.concat([result, temp], axis=1)","f835a9bb":"FinalResult=pd.DataFrame()\nfor results in result2.columns:\n    y_hat=result2[results]\n    AUC_ROC=roc_auc_score(y_test, y_hat)\n    FinalResult[results]=[AUC_ROC]\nFinalResult.transpose()","c7446b45":"import sklearn.metrics as metrics\nimport matplotlib.pyplot as plt","45181d4c":"def plot_AUCROC(y_test, y_hat, labels):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(4,5,figsize=(20,12))\n\n    for Label in labels:\n        # calculate the fpr and tpr for all thresholds of the classification\n        fpr, tpr, threshold = metrics.roc_curve(y_test, y_hat[Label])\n        roc_auc = metrics.auc(fpr, tpr)\n\n        # method I: plt\n        i += 1\n        plt.subplot(4,5,i)    \n        plt.title(Label)\n        plt.plot(fpr, tpr, 'b', label = 'AUC = %0.3f' % roc_auc)\n        plt.legend(loc = 'lower right')\n        plt.plot([0, 1], [0, 1],'r--')\n        plt.xlim([0, 1])\n        plt.ylim([0, 1])\n        plt.ylabel('True Positive Rate')\n        plt.xlabel('False Positive Rate')\n        plt.tick_params(axis='x', which='major', labelsize=1, pad=-10)\n        plt.tick_params(axis='y', which='major', labelsize=1)\n\nplt.show()","43baa5d3":"labels = result2.columns\nplot_AUCROC(y_test,result2, labels)","de0ab38c":"X_Test = test_df.drop(columns=[\"id\"])\nX_Test_ol=X_Test[d]\n#LR.fit(X,y)\nLR_ol.fit(X_ol,y)\n#regr_ol.fit(X_ol, y)  \n#g_NB.fit(X, y)\n#selector.fit(X,y)","e2c6477c":"#y_hat=g_NB.predict_proba(X_Test)\n#y_hat=regr_ol.predict(X_Test_ol)\n#y_hat=(y_hat-y_hat.min())\/(y_hat.max()-y_hat.min())\n#y_hat= neigh_grid.predict_proba(X_Test_ol)\n#y_hat = gbm.predict(X_Test, num_iteration=gbm.best_iteration)\n#y_hat= selector.predict(X_Test)\ny_hat= knn_ol.predict_proba(X_Test_ol)\ny_hat=y_hat*0.5\/(np.sort(y_hat[:,1])[round((y_hat[:,1].size)*(100-tax)\/100)]) # --> ajust the array to have 64% of target > 0.5\n\n#submission['target']=y_hat\nsubmission['target']=y_hat[:,1]\n\nprint ('% target = 1: {}% (in the train sample 64%)'.format(round(float(len(y_hat[y_hat[:,1]>=0.5])) \/ len(y_hat) * 100)))","6993c8c7":"submission.to_csv('submission.csv', index=False)\nsubmission.head(20)","147900d0":"## **KNN model**","0d9ead4d":"Check the type of variables","a6eec09e":"Check if the models can be better if combined","589c528d":"## Make de prediction based on the regr_ol model","adc8e18b":"We need to get some sense of how balanced our dataset is:","2d364cdc":"Choosing the best prediction","2a809f70":"Knowing that 64% of the targets are 1, that will helps us not be excited by machine learning diagnostics that aren't much better than 64%. If I predicted that all targets are 1, I would be 64% accurate!","4c5dc2c1":"## 3 - Modeling","c0a42af2":"**Feature Transformation**  \nFirst we can make a Log Transform.\nLog transforms are useful when applied to skewed distributions as they tend to expand the values which fall in the range of lower magnitudes and tend to compress or reduce the values which fall in the range of higher magnitudes. Their main significance is that they help in stabilizing variance, adhering closely to the normal distribution and making the data independent of the mean based on its distribution.\nSource:https:\/\/towardsdatascience.com\/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b","15f75910":"## 1- Data Retrieve  \nSetup","7ec41b1d":"1. Making a zoom on some interesting pairs:  (33x217, 16x33,  33x80,  33x91,  33x295)","168b99f5":"**Conclusion of Data Exploration**  \nAll the features have a normal distribution shape.The distribution wen we look the target can't be modeled alone, we can observe a lot o overlap in all features.   Some interesting feature should be looked in more detail, like the feature 33 (some observed features: 9,33,65,63,76.  \nIn the 33 feature, we can observe the test dataframe are more like the train dataframe when the feature are equal to one.  \nSome features has almost the same distribution, like 102,103,112 and 116 and others.  \nWhat is bether???  \n","fa5f471c":"### **SVM** ","dc7d272b":"let's look at the distribution of all variables:","7d7f431e":"## 2.3 Feature Scaling and Selection  ","3dacbdff":"### Load data and store in dataframes (submission, test_df, train_df)","972eff0f":"### **Multi-layer Perceptron** ","dfc4bd57":"No significant correlation between variables!","ddec12d3":"## 2.2 Feature Exploration and Engineering","8e45c59a":"## **4 - Model Evaluation and Tunning  **","dc3ae7b7":"We can observe a concentration of blue points (target=0) in a certain region in this plot. That can help us to be more acetive in engineering feature.","bfd0590c":"Looking at the distribution shape off all features we can  select some that have differente central point to see how the are presented in a pair plot and see if we can find some groups.\nVisuali I select the following features to pair plot: 4,13,16,24,33,65,73,80,91,183,189,194,199,217,276,795,298","26e7b7f4":"## 2- Data Preparation  \n\nImport visualization packages \"Matplotlib\" and \"Seaborn\". Using \"%matplotlib inline\" to plot in a Jupyter notebook:  \n","f877af9f":"### **Logistic Regression**\n","8d1a3cc3":"### **Gaussian Naive Bayes (GaussianNB)**","ebf36270":"## Don't Overfit II: The Overfittening  \nPlayground Prediction Competition - www.kaggle.com  \nPrediction made by *Leopoldo Sprandel - leopoldosprandel@yahoo.com.br*  \n    \nTarget  \nPredicting the binary target associated with each row, without overfitting to the minimal set of training examples provided.  \n\nFiles  \ntrain.csv - the training set. 250 rows. test.csv - the test set. 19,750 rows. sample_submission.csv - a sample submission file in the correct format  \n\nColumns  \nid- sample id target- a binary target of mysterious origin. 0-299- continuous variables.  \n\n## Summay\n1 - Data Retrieve  \n2 - Data Preparation  \n> 2.1 - Data Processing and Wrangling  --> already done by kaggle  \n2.2 - Feature Exploration and Engineering  \n2.3 - Feature Scaling and Selection  \n\n3 - Modeling  \n> Machine Learning algorithms  \n\n4 - Model Evaluation and Tunning  \n>Parameter optimisation  \n> AUC ROC visualization  \n\n5 - Submission  \n\n","11131f39":"# **Don't Overfit II: The Overfittening**\n**Choosing a model - Kernel**  \n https:\/\/www.kaggle.com\/c\/dont-overfit-ii  \nby *Leopoldo Sprandel - leopoldosprandel@yahoo.com.br*","7e300b3c":"Creation a dataframe to store all results and compare each model.  \nCreation of  the dataframes for test and training based on the train dataframe.","a781232e":"### **AUC ROC Visualization**\n","896dd2e6":"### **Multi linear regression**","51ba38c3":"Checking the correlation between all variables.\nWe can calculate the correlation between variables of type \"int64\" or \"float64\" using the method \"corr\":  \nWe observe there is no high correlation between the target and any feature. Therefore it is not a reliable variable to work only with simple correlations.  ","15419359":"Let's take a look on the points in a sctter plot between the secondaryes features","25b126c3":"### **Decision tree**"}}