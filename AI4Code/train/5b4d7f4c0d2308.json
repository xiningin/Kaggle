{"cell_type":{"689a4667":"code","ece114e4":"code","b8a4b253":"code","2559218e":"code","50391ace":"code","0e036a7a":"code","b240e6e5":"code","a1e8ac3e":"code","6d50a08d":"code","3b541b35":"code","05af5daa":"code","e059fb77":"code","3c8e3c6e":"code","bbd67b0f":"code","b10d059e":"code","431d6da7":"code","817be77b":"code","dace2987":"code","01c9d6af":"code","2fefda7d":"code","5d5623c9":"code","30eb9f5e":"code","16b517da":"code","445bd84c":"code","100f7366":"code","dd96151a":"code","f8ff5f96":"code","0a74c652":"code","389932a3":"code","4fff00a7":"code","1b517b4a":"code","4dbb7427":"code","8e081a7b":"code","97afd2e4":"code","2767e0f6":"code","9323bc9b":"code","1c337a53":"code","1a209d6d":"code","72838c0a":"code","17ad3b7f":"code","88156ed4":"code","a306eca0":"code","c40310c7":"code","28b58b2f":"code","76a6e447":"code","ddb4d3f1":"code","85057e45":"code","916f775a":"code","cbad3507":"code","38f45b7c":"code","e196c8eb":"code","cef3c9fb":"code","31ec3565":"code","51bf6366":"code","c18ae381":"code","5999edef":"code","32b97d9a":"code","8377839a":"code","9d44ede3":"code","f1505973":"code","ecbae532":"code","9bc2607b":"code","7750481e":"code","a2a6306f":"code","ed3d5fc4":"code","2a1ba4ae":"code","dc544429":"code","78d48530":"code","1beff691":"code","f244eee1":"code","8b5a514a":"code","f0f1c5fa":"code","70e1f71f":"code","efbb7331":"code","c0839e72":"code","5ec35957":"code","abf2951f":"code","4e51a1c0":"code","377d7d2f":"code","c6b5de8c":"code","0d00d3f8":"code","873ded85":"code","3da1d761":"code","229699c2":"code","79fdc8aa":"code","a7504216":"code","fecd395d":"code","8df3f01d":"code","db2e6166":"code","2d176138":"code","6bc215c2":"code","097e0aad":"code","3d3d2dfb":"code","1d28d196":"code","29510451":"code","0e1b2db9":"code","19a3c520":"code","4f190085":"markdown","d65be24f":"markdown","c5d3e990":"markdown","2a005067":"markdown","100c5255":"markdown","e970dd5f":"markdown","9177c4bc":"markdown","ef9c7e84":"markdown","02313bde":"markdown","82cccd54":"markdown","5e6bf9e3":"markdown","d5856499":"markdown","283cc8c5":"markdown","df238a60":"markdown","4c8c2a26":"markdown","14d244d6":"markdown","f2270d2c":"markdown","35923f99":"markdown","e961cf16":"markdown","5ebdd5aa":"markdown","d6479789":"markdown","3ed0c422":"markdown","660ee438":"markdown","c8374654":"markdown","c590656e":"markdown","a6a1e672":"markdown","f5ef1260":"markdown","387430b8":"markdown","e21c9dd4":"markdown","4113c4b9":"markdown","b90f75b5":"markdown","31f01a4d":"markdown","e63cffe9":"markdown","ecae6fff":"markdown","9cd7994d":"markdown","576fe84c":"markdown","b4a560b4":"markdown","9d287656":"markdown","158525d4":"markdown","097be4dc":"markdown","121f1775":"markdown","34806187":"markdown","47f53962":"markdown","0d353a58":"markdown","2ad2d7e5":"markdown","08603084":"markdown","7b5f6e8a":"markdown","26a3f6db":"markdown","967d792a":"markdown","6fb95cf1":"markdown","2dab59f2":"markdown","638260aa":"markdown","bcc3d159":"markdown","9314982f":"markdown","b45b4b13":"markdown","7fb30a57":"markdown"},"source":{"689a4667":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","ece114e4":"import warnings\nwarnings.filterwarnings('ignore')","b8a4b253":"import seaborn as sns\nsns.set(style=\"darkgrid\")","2559218e":"dataset = pd.read_csv(\"..\/input\/placement-data-full-class\/Placement_data_full_class.csv\")","50391ace":"dataset.head()","0e036a7a":"dataset.isnull().sum()","b240e6e5":"sns.distplot(dataset.salary)","a1e8ac3e":"dataset = dataset.fillna(0)","6d50a08d":"sns.barplot(x = dataset['gender'],y = dataset['salary'])","3b541b35":"sns.barplot(x=dataset[\"gender\"],y=dataset[\"ssc_p\"])","05af5daa":"sns.barplot(x=dataset[\"gender\"],y=dataset[\"hsc_p\"])","e059fb77":"sns.barplot(x=dataset[\"gender\"],y=dataset[\"degree_p\"])","3c8e3c6e":"sns.barplot(x=dataset[\"gender\"],y=dataset[\"mba_p\"])","bbd67b0f":"sns.boxplot(x=dataset[\"status\"],y=dataset[\"mba_p\"])","b10d059e":"sns.boxplot(x=dataset[\"status\"],y=dataset[\"degree_p\"])","431d6da7":"sns.boxplot(x=dataset[\"status\"],y=dataset[\"hsc_p\"])","817be77b":"sns.boxplot(x=dataset[\"status\"],y=dataset[\"ssc_p\"])","dace2987":"dataset=dataset[dataset.salary<600000]","01c9d6af":"sns.jointplot(x=dataset[\"ssc_p\"],y=dataset[\"salary\"],kind=\"reg\",color=\"g\")","2fefda7d":"sns.jointplot(x=dataset[\"hsc_p\"],y=dataset[\"salary\"],kind=\"reg\",color=\"g\")","5d5623c9":"sns.jointplot(x=dataset[\"degree_p\"],y=dataset[\"salary\"],kind=\"reg\",color=\"g\")","30eb9f5e":"sns.jointplot(x=dataset[\"mba_p\"],y=dataset[\"salary\"],kind=\"reg\",color=\"g\")","16b517da":"sns.jointplot(x=dataset[\"etest_p\"],y=dataset[\"salary\"],kind=\"reg\",color=\"g\")","445bd84c":"plt.rc(\"axes\",labelsize=13)\nplt.rc(\"xtick\",labelsize=13)\nplt.rc(\"ytick\",labelsize=13)\nsns.countplot(x=dataset[\"specialisation\"],hue=dataset[\"status\"],palette=\"muted\").set_title(\"Barplot showing placement among specalisation\")","100f7366":"plt.rc(\"axes\",labelsize=13)\nplt.rc(\"xtick\",labelsize=13)\nplt.rc(\"ytick\",labelsize=13)\nsns.countplot(x=dataset[\"workex\"],hue=dataset[\"status\"],palette=\"muted\").set_title(\"Barplot showing placement acocording work experiences\")","dd96151a":"dataset.dtypes","f8ff5f96":"numeric_data= dataset.select_dtypes(include=[np.number])\ncategorical_data = dataset.select_dtypes(exclude=[np.number])\nprint (\"There are {} numeric and {} categorical columns in dataset\"\n.format(numeric_data.shape[1],categorical_data.shape[1]))","0a74c652":"# using label Encoder to change categorical data to numerical\nfrom sklearn.preprocessing import LabelEncoder\nle =  LabelEncoder()\n# implementing le on gender\nle.fit(dataset.gender.drop_duplicates())\ndataset.gender = le.transform(dataset.gender)\n# implementing le on ssc_b\nle.fit(dataset.ssc_b.drop_duplicates())\ndataset.ssc_b = le.transform(dataset.ssc_b)\n# implementing le on hsc_b\nle.fit(dataset.hsc_b.drop_duplicates())\ndataset.hsc_b = le.transform(dataset.hsc_b)\n# implementing le on hsc_b\nle.fit(dataset.hsc_b.drop_duplicates())\ndataset.hsc_b = le.transform(dataset.hsc_b)\n# implementing le on hsc_s\nle.fit(dataset.hsc_s.drop_duplicates())\ndataset.hsc_s = le.transform(dataset.hsc_s)\n# implementing le on degree_t\nle.fit(dataset.degree_t.drop_duplicates())\ndataset.degree_t = le.transform(dataset.degree_t)\n# implementing le on workex\nle.fit(dataset.workex.drop_duplicates())\ndataset.workex = le.transform(dataset.workex)\n# implementing le on specialisation\t\nle.fit(dataset.specialisation.drop_duplicates())\ndataset.specialisation = le.transform(dataset.specialisation)\n# implementing le on status\nle.fit(dataset.status.drop_duplicates())\ndataset.status = le.transform(dataset.status)","389932a3":"# now dataset is converted into numerical value\ndataset.head()","4fff00a7":"plt.figure(figsize=(12,10))\ncorrMatrix=dataset.corr()\nsns.heatmap(corrMatrix,annot=True)\nplt.show()","1b517b4a":"x = dataset.iloc[:, 1:13].values\ny = dataset.iloc[:, -2].values","4dbb7427":"x","8e081a7b":"y","97afd2e4":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.25,random_state=0)","2767e0f6":"print(x_train.shape)\nprint(x_test.shape)","9323bc9b":"x_train","1c337a53":"x_test","1a209d6d":"from imblearn.combine import SMOTETomek\nsmk = SMOTETomek(random_state = 42)\nx,y = smk.fit_sample(x,y)","72838c0a":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression (solver='liblinear', random_state=0)\nclassifier.fit(x_train,y_train)","17ad3b7f":"y_pred = classifier.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","88156ed4":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","a306eca0":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\naccuracy = accuracy_score(y_test,y_pred)\nprecision =  precision_score(y_test,y_pred,average=\"weighted\")\nrecall = recall_score(y_test,y_pred,average=\"weighted\")\nf1 = f1_score(y_test,y_pred,average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall- {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","c40310c7":"from sklearn.metrics import average_precision_score\naverage_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","28b58b2f":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\ndisp = plot_precision_recall_curve(classifier,x_test,y_test)","76a6e447":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","ddb4d3f1":"y_score2 = classifier.predict_proba(x_test)[:,1]\nfalse_positive_rate2, true_positive_rate2, threshold2 = roc_curve(y_test, y_score2)\nprint('roc_auc_score for Logistic Regression: ', roc_auc_score(y_test, y_score2))","85057e45":"plt.subplots(1, figsize=(8,6))\nplt.title('Receiver Operating Characteristic - Logistic regression')\nplt.plot(false_positive_rate2, true_positive_rate2)\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","916f775a":"from sklearn.neighbors import KNeighborsClassifier\nclassifierr = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n                     weights='uniform')\nclassifierr.fit(x_train,y_train)","cbad3507":"y_pred = classifierr.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","38f45b7c":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","e196c8eb":"accuracy = accuracy_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred, average=\"weighted\")\nrecall = recall_score(y_test,y_pred, average=\"weighted\")\nf1 = f1_score(y_test,y_pred, average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall - {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","cef3c9fb":"average_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","31ec3565":"disp = plot_precision_recall_curve(classifierr,x_test,y_test)","51bf6366":"y_score1 = classifierr.predict_proba(x_test)[:,1]\nfalse_positive_rate1, true_positive_rate1, threshold2 = roc_curve(y_test, y_score1)\nprint('roc_auc_score for k_nearest_neibour: ', roc_auc_score(y_test, y_score1))","c18ae381":"plt.subplots(1, figsize=(8,6))\nplt.title('Receiver Operating Characteristic - k_nearest_neibour')\nplt.plot(false_positive_rate1, true_positive_rate1)\n\n\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","5999edef":"from sklearn.svm import SVC\nclassifier1 = SVC(kernel=\"linear\",random_state=0,C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='scale',\n    max_iter=-1, probability=True,shrinking=True, tol=0.001,\n    verbose=False)\nclassifier1.fit(x_train,y_train)","32b97d9a":"y_pred = classifier1.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","8377839a":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","9d44ede3":"accuracy = accuracy_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred, average=\"weighted\")\nrecall = recall_score(y_test,y_pred, average=\"weighted\")\nf1 = f1_score(y_test,y_pred, average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall - {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","f1505973":"average_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","ecbae532":"disp = plot_precision_recall_curve(classifier1,x_test,y_test)","9bc2607b":"y_score3 = classifier1.predict_proba(x_test)[:,1]\nfalse_positive_rate3, true_positive_rate3, threshold3 = roc_curve(y_test, y_score3)\nprint('roc_auc_score for support vector machine ', roc_auc_score(y_test, y_score3))","7750481e":"plt.subplots(1, figsize=(8,6))\nplt.title('Receiver Operating Characteristic - Support vector machine')\nplt.plot(false_positive_rate3, true_positive_rate3)\n\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","a2a6306f":"from sklearn.svm import SVC\nclassifier2 = SVC(kernel=\"rbf\",random_state=0,probability=True)\nclassifier2.fit(x_train,y_train)","ed3d5fc4":"y_pred = classifier2.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","2a1ba4ae":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)\naccuracy_score(y_test,y_pred)","dc544429":"accuracy = accuracy_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred, average=\"weighted\")\nrecall = recall_score(y_test,y_pred, average=\"weighted\")\nf1 = f1_score(y_test,y_pred, average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall - {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","78d48530":"average_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","1beff691":"disp = plot_precision_recall_curve(classifier2,x_test,y_test)","f244eee1":"y_score4 = classifier2.predict_proba(x_test)[:,1]\nfalse_positive_rate4, true_positive_rate4, threshold4 = roc_curve(y_test, y_score4)\nprint('roc_auc_score for support vector machine ', roc_auc_score(y_test, y_score4))","8b5a514a":"plt.subplots(1, figsize=(8,6))\nplt.title('Receiver Operating Characteristic - Kernel SVM')\nplt.plot(false_positive_rate4, true_positive_rate4)\n\n\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","f0f1c5fa":"from sklearn.naive_bayes import GaussianNB\nclassifier3 = GaussianNB()\nclassifier3.fit(x_train, y_train)","70e1f71f":"y_pred = classifier3.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n","efbb7331":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)\naccuracy_score(y_test,y_pred)","c0839e72":"accuracy = accuracy_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred, average=\"weighted\")\nrecall = recall_score(y_test,y_pred, average=\"weighted\")\nf1 = f1_score(y_test,y_pred, average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall - {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","5ec35957":"average_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","abf2951f":"disp = plot_precision_recall_curve(classifier3,x_test,y_test)","4e51a1c0":"y_score5 = classifier3.predict_proba(x_test)[:,1]\nfalse_positive_rate5, true_positive_rate5, threshold5 = roc_curve(y_test, y_score5)\nprint('roc_auc_score for support vector machine ', roc_auc_score(y_test, y_score5))","377d7d2f":"plt.subplots(1, figsize=(8,6))\nplt.title('Receiver Operating Characteristic - Naive Bayes')\nplt.plot(false_positive_rate5, true_positive_rate5)\n\n\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","c6b5de8c":"from sklearn.tree import DecisionTreeClassifier\nclassifier4 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier4.fit(x_train, y_train)","0d00d3f8":"y_pred = classifier4.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","873ded85":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)\naccuracy_score(y_test,y_pred)","3da1d761":"accuracy = accuracy_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred, average=\"weighted\")\nrecall = recall_score(y_test,y_pred, average=\"weighted\")\nf1 = f1_score(y_test,y_pred, average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall - {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","229699c2":"average_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","79fdc8aa":"disp = plot_precision_recall_curve(classifier4,x_test,y_test)","a7504216":"y_score6 = classifier4.predict_proba(x_test)[:,1]\nfalse_positive_rate6, true_positive_rate6, threshold6 = roc_curve(y_test, y_score6)\nprint('roc_auc_score for support vector machine ', roc_auc_score(y_test, y_score6))","fecd395d":"plt.subplots(1, figsize=(8,6))\nplt.title('Receiver Operating Characteristic - decision tree')\nplt.plot(false_positive_rate6, true_positive_rate6)\n\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","8df3f01d":"from sklearn.ensemble import RandomForestClassifier\nclassifier5 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier5.fit(x_train, y_train)","db2e6166":"y_pred = classifier5.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","2d176138":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)\naccuracy_score(y_test,y_pred)","6bc215c2":"accuracy = accuracy_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred, average=\"weighted\")\nrecall = recall_score(y_test,y_pred, average=\"weighted\")\nf1 = f1_score(y_test,y_pred, average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall - {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","097e0aad":"average_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","3d3d2dfb":"disp = plot_precision_recall_curve(classifier5,x_test,y_test)","1d28d196":"y_score7 = classifier5.predict_proba(x_test)[:,1]\nfalse_positive_rate7, true_positive_rate7, threshold6 = roc_curve(y_test, y_score7)\nprint('roc_auc_score for support vector machine ', roc_auc_score(y_test, y_score7))","29510451":"plt.subplots(1, figsize=(8,8))\nplt.title('Receiver Operating Characteristic - Random forest')\nplt.plot(false_positive_rate7, true_positive_rate7)\n\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","0e1b2db9":"classifiers = [LogisticRegression(random_state=0),\n               KNeighborsClassifier(),\n               SVC(random_state=0,probability=True), \n               GaussianNB(), \n               DecisionTreeClassifier(random_state=0),\n               RandomForestClassifier(random_state=0)]\nresult_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\nfor cls in classifiers:\n    model = cls.fit(x_train, y_train)\n    yproba = model.predict_proba(x_test)[:,1]\n    \n    fpr, tpr, _ = roc_curve(y_test,  yproba)\n    auc = roc_auc_score(y_test, yproba)\n    \n    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n                                        'fpr':fpr, \n                                        'tpr':tpr, \n                                        'auc':auc}, ignore_index=True)\nresult_table.set_index('classifiers', inplace=True)\n","19a3c520":"fig = plt.figure(figsize=(8,6))\n\nfor i in result_table.index:\n    plt.plot(result_table.loc[i]['fpr'], \n             result_table.loc[i]['tpr'], \n             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n    \nplt.plot([0,1], [0,1], color='orange', linestyle='--')\n\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"Flase Positive Rate\", fontsize=15)\n\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel(\"True Positive Rate\", fontsize=15)\n\nplt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\nplt.legend(prop={'size':13}, loc='lower right')\n\nplt.show()","4f190085":"We will exclude salary column beacuse people that get placement will get a salary...","d65be24f":"Then we are importing warnings so that we will not get any warning msg...","c5d3e990":"The accuracy of model naive bayes machine is 0.76,roc_auc_score:0.89","2a005067":"LOGISTIC REGRESSION","100c5255":"# Contents","e970dd5f":"For comparing true positive and false positive class...","9177c4bc":"\nDoing featrue scaling on dataset for handling imbalanced values...","ef9c7e84":"Now we are plotting receiver operating characteristic curve(roc)...","02313bde":"Finally conclusion is that it seems like academic results have limited effect on securing a job placement. Specialisation seems to play a much more important role.\nMales have a better chance of getting chosen for the job placement. Males also have a better chance of getting higher pay.\nAnd RandomForestClassifier is predicting best among all classification model with 90 percent.","82cccd54":"Here we are doing prediction...","5e6bf9e3":"**NAIVE BAYES**","d5856499":"From here we see that,It seems like work experience has no effect on job placement...","283cc8c5":"**DECISION TREE**","df238a60":"Now we are doing Salary VS Academic rasult analysis...","4c8c2a26":"# **Introduction**","14d244d6":"1 st graph is of salary","f2270d2c":"The accuracy of model random forest is 0.90,roc_auc_score:0.93","35923f99":"1st observation = in this visualisation we saw that man are given more salary even though women are scoring better the man.","e961cf16":"Spliting dataset into training and testing data...","5ebdd5aa":"**KERNEL SVM**","d6479789":"The accuracy of model logistic regression is 0.87,roc_auc_score:0.90","3ed0c422":"**K NEAREST NEIGHBORS**","660ee438":"Now we are doing gender based analysis...","c8374654":"The accuracy of model decision tree is 0.83,roc_auc_score:0.83","c590656e":"Now we are predicting probability of our x_test...","a6a1e672":"3rd observation = student with average percent of 60 to 70 percent are getting salary around 250000 INR anually. Higher percentage does not neccesarily corresponds to higher salary package...","f5ef1260":"1. Performing explorartory data analysis.\n2. Visualising which factor influenced a candidate in getting placed.\n3. Performing data preprocessing.\n4. Performing model building.\n5. Performing feature scaling for maintaining imbalanced of our dataset.\n6. Applying different types of classification model for predicting best accuracy.\n7. Performing different types of method and curve for calculating and visualising accuracy of our different classification model.\n\n\n\n","387430b8":"Applying confusion matrix for knowing true positive,true neagtive,false postive,false neagtive... and calculating accuracy of our classifiaction model...","e21c9dd4":"**BUILDING MODEL**","4113c4b9":"**EXPLORATORY DATA ANALYSIS**","b90f75b5":"Now we are doing Placement based analysis...","31f01a4d":"Now we are doing classification on our dataset...","e63cffe9":"Now we are analysing that does type of specalisation affect placement or not...","ecae6fff":"Here we are comparing roc  of all calssification model and we get to know here that RandomForestClassifier is best...","9cd7994d":"The accuracy of model Kernel SVM is 0.74,roc_auc_score:0.89","576fe84c":"**RANDOM FOREST**","b4a560b4":"Now we are analysing that work experience affect placement or not...","9d287656":"Now we are making correlation matrix...","158525d4":"The accuracy of model K nearest Neighbors is 0.84,roc_auc_score:0.90","097be4dc":"First we are going to import best trio...","121f1775":"From here we see that, it seems like business related specialisation tend to have a higher chance of getting a job placement...","34806187":"2nd observation - student with higher percentage better acedmic result are able to perfrom better during placement compared to those who are not getting higher percentage...","47f53962":"Then we are importing seaborn library for making graphs...","0d353a58":"Then we are chceking if there is any missing value in our dataset...","2ad2d7e5":"Comparing ROC curve for all classifier that which model is best...","08603084":"Then printing first 5 lines of our dataset....","7b5f6e8a":"Then we are going to fill misisng salaries with 0 as they represent students who have not got placement offer...","26a3f6db":"**SUPPORT VECTOR MACHINE**","967d792a":"# Conclusion","6fb95cf1":"Here we are plotting curve for of precision_recall...","2dab59f2":"Now we are importing roc and auc curve for visualising accuracy...","638260aa":"The accuracy of model support vector machine is 0.84,roc_auc_score:0.92","bcc3d159":"The objective of this project is to determine what variables can increase the chances of securing a job placement in a college recruitment event. You can find the dataset at the end of this project. Once again,we want to determine if grades have an effect on securing a job placement, we will be studying visualization and predictive model to classify if a given student can get a placement or not.","9314982f":"Here we are calculating precision,recall,accuracy,f1 scores...","b45b4b13":"**DATA PRE-PROCESSING**","7fb30a57":"Then we are going to read our dataset which we are using in this project..."}}