{"cell_type":{"52ced4ce":"code","4e206e82":"code","a0883863":"code","7930f1b0":"code","05b6e8d5":"code","09709145":"code","57b9279f":"code","6ebaf2ee":"code","e52c8bd1":"code","07a31aac":"code","1d03005d":"code","3fd1fe3c":"code","d740fd1c":"code","4af5eb94":"code","381f2892":"code","af15bbb4":"code","9cc8c54f":"code","7ef2c488":"code","5b051691":"code","8b11d473":"code","b685ba54":"code","86485ac9":"code","d68cf30d":"code","af8118da":"code","054640c6":"code","0b6aa66f":"code","1570757e":"markdown","b727c8c8":"markdown","79834fd7":"markdown","fedfd36a":"markdown","52a79c51":"markdown","6aabf19a":"markdown","4ace167c":"markdown","0e2dc092":"markdown","62e23c99":"markdown","0ff74538":"markdown","e76c0d8f":"markdown"},"source":{"52ced4ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4e206e82":"# Importando bibliotecas que serao utilizadas neste projeto\nimport seaborn as sns\nimport itertools\nimport imblearn\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Misc\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport pandasql as ps\n\n# Models\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Ignore useless warnings\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\npd.options.display.max_seq_items = 8000\npd.options.display.max_rows = 8000\npd.set_option('display.max_columns', None)\nimport pickle\nimport gc","a0883863":"train = pd.read_csv('\/kaggle\/input\/competicao-dsa-machine-learning-sep-2019\/X_treino.csv'\n                            ,dtype = {\n                                'series_id': np.int16\n                               ,'measurement_number': np.int16\n                               ,'orientation_X': np.float32\n                               ,'orientation_X': np.float32\n                                ,'orientation_Y': np.float32\n                                ,'orientation_Z': np.float32\n                                ,'orientation_W': np.float32\n                                ,'angular_velocity_X': np.float32\n                                ,'angular_velocity_Y': np.float32\n                                ,'angular_velocity_Z': np.float32\n                                ,'linear_acceleration_X': np.float32\n                                ,'linear_acceleration_Y': np.float32\n                                ,'linear_acceleration_Z': np.float32\n                            })\n\ntest = pd.read_csv('\/kaggle\/input\/competicao-dsa-machine-learning-sep-2019\/X_teste.csv'\n                            ,dtype = {\n                                'series_id': np.int16\n                               ,'measurement_number': np.int16\n                               ,'orientation_X': np.float32\n                               ,'orientation_X': np.float32\n                                ,'orientation_Y': np.float32\n                                ,'orientation_Z': np.float32\n                                ,'orientation_W': np.float32\n                                ,'angular_velocity_X': np.float32\n                                ,'angular_velocity_Y': np.float32\n                                ,'angular_velocity_Z': np.float32\n                                ,'linear_acceleration_X': np.float32\n                                ,'linear_acceleration_Y': np.float32\n                                ,'linear_acceleration_Z': np.float32\n                            })\n\ny_train = pd.read_csv('\/kaggle\/input\/competicao-dsa-machine-learning-sep-2019\/y_treino.csv'\n                            ,dtype = {\n                                'series_id': np.int16\n                               ,'group_id': np.int16\n                            })\n\ntrain.shape, test.shape, y_train.shape","7930f1b0":"# Realizando o merge.\n# J\u00e1 eliminando as linhas que tem no dataset 'y_train' mas nao tem no dataset 'train'\ndf = pd.merge(train, y_train, on='series_id', how='left')\ndf.shape","05b6e8d5":"df.info()","09709145":"df.head(5)","57b9279f":"df.tail(5)","6ebaf2ee":"test.head(5)","e52c8bd1":"df.describe(include='all').T","07a31aac":"test.describe(include='all').T","1d03005d":"df[df.isnull().any(axis=1)] ","3fd1fe3c":"df.isnull().values.any() ","d740fd1c":"# Identificar se existem linhas duplicadas\nprint('uniques:', len(df.drop_duplicates()))\nprint('duplicates:', len(df)-len(df.drop_duplicates()))","4af5eb94":"# Removendo as colunas row_id e group_id\n# A coluna group_id foi removida aqui somente para a primeira versao\ndf.drop(columns = ['row_id','group_id'], inplace = True) ","381f2892":"# Analise Exploratoria da variavel target 'surface'\ndf.groupby('surface').size()","af15bbb4":"df.groupby('surface').size().plot(kind='bar', figsize=(6,6))\nplt.title('Classes de Superficies')\nplt.xlabel('Classes')\nplt.ylabel('Frequencia')\nplt.show()","9cc8c54f":"# Cria um label encoder object\nle = preprocessing.LabelEncoder()\nsuf=\"_le\"\n\n# Iteracao para cada coluna do dataset de treino\nfor col in df:\n    if df[col].dtype == 'object':\n        le.fit_transform(df[col].astype(str))\n        df[col+suf] = le.transform(df[col])      ","7ef2c488":"df.head()","5b051691":"# Fazendo uma limpeza na memoria\ngc.collect()","8b11d473":"# Split features and labels\nX = df.drop(['surface', 'surface_le'],axis=1)\ny = df['surface_le']\n\n# Aplicando a mesma escala nos dados\nX = MinMaxScaler().fit_transform(X)\n\n# Padronizando os dados (0 para a m\u00e9dia, 1 para o desvio padr\u00e3o)\nX = StandardScaler().fit_transform(X)","b685ba54":"# Verificando o shape apos o split entre feature e target\nX.shape, y.shape","86485ac9":"# Definindo os valores para o n\u00famero de folds\nnum_folds = 10\nseed = 123\n\n# Separando os dados em folds\nkfold = KFold(num_folds, True, random_state = seed)\n\n# Criando o modelo\nmodeloCART = DecisionTreeClassifier()\n\n# Cross Validation\nresultado = cross_val_score(modeloCART, X, y, cv = kfold, scoring = 'accuracy')\n\n# Print do resultado\nprint(\"Acur\u00e1cia: %.3f\" % (resultado.mean() * 100))\n\n# Treinando o modelo\nmodeloCART.fit(X, y)","d68cf30d":"# Configurando o dataset de teste, retirando algumas colunas \nX_final = test.drop(['row_id'],axis=1)\nX_final = MinMaxScaler().fit_transform(X_final)\nX_final = StandardScaler().fit_transform(X_final)\n\n# Fazendo as previsoes de surface no dataset de teste\npredCART = modeloCART.predict(X_final)\n\n# Voltando a transformacao da variavel target em formato texto\nsurface_pred = le.inverse_transform(predCART)","af8118da":"#Gerando Arquivo de Submissao\nsubmission = pd.DataFrame({\n    \"series_id\": test.series_id, \n    \"surface\": surface_pred\n})\n\n# Removendo registros duplicados\nsubmission = submission.drop_duplicates()","054640c6":"# Executando query para identificar as superficies com maiores quantidade, para fazer o submit\nq1 = \"\"\" SELECT x.series_id, x.surface, MAX(x.qtde) maior\n           FROM (SELECT series_id, surface, count() as qtde\n                   FROM submission\n                  GROUP BY series_id, surface) x\n          GROUP BY x.series_id\"\"\"\n\nsub_final = ps.sqldf(q1, locals())\nsub_final = sub_final.drop(['maior'],axis=1)","0b6aa66f":"# Salvando o resultado das previsoes em um arquivo .csv\nsub_final.to_csv('submission.csv', index=False)","1570757e":"# Cria\u00e7\u00e3o e Valida\u00e7\u00e3o dos Modelos de Machine Learning","b727c8c8":"> ## Importando as bibliotecas que ser\u00e3o utilizadas neste projeto","79834fd7":"Normaliza\u00e7\u00e3o e Padroniza\u00e7\u00e3o de features numericas","fedfd36a":"Sem tratamento nenhum nos dados o modelo classificou mais de uma superficie para a mesma seria. Para este teste, vou deixar no arquivo de submit somente os com maior quantidade. Mas \u00e9 necess\u00e1rio fazer o correto tratamento nos dados!","52a79c51":"# Competi\u00e7\u00e3o DSA de Machine Learning - Edi\u00e7\u00e3o Setembro\/2019","6aabf19a":"Label encoding: executar este enconding na variavel target 'surface' para atribuir para cada classe um inteiro. ","4ace167c":"## An\u00e1lise Explorat\u00f3ria","0e2dc092":"# Trabalhando com o dataset de Teste","62e23c99":"### Encoding Categorical Variables","0ff74538":"Gerando o arquivo de submission com as colunas 'series_id' e 'surface' (indica a previsao do modelo)","e76c0d8f":"# Feature Engineering"}}