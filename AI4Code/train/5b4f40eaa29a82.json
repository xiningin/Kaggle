{"cell_type":{"81b229c9":"code","6a8f8c2c":"code","f4aa4215":"code","158b83ee":"code","d3724e73":"code","dd3f039a":"code","880f6bde":"code","7415bb46":"code","c042d8f3":"code","afac088a":"code","025b54e6":"code","4b56959c":"code","a207b1f6":"code","3a4f0666":"code","8f06b948":"code","25b3bc83":"code","3186abb4":"code","6661e671":"code","0265feae":"code","b0ec1dd1":"code","ed165ec8":"code","14bf8e32":"code","2c694e06":"code","f79d0e83":"code","56078221":"code","31b0e187":"code","4f85ae8c":"code","f29eb525":"code","45d6b518":"code","8f3b0429":"code","7466c35e":"code","288395fd":"code","40131591":"code","39056ebc":"code","fc462a26":"code","47c8f352":"code","3f05efa0":"code","248551b8":"code","d02ffd9a":"code","27b24bf3":"code","10563c09":"code","e17ef7c2":"code","2cfb1f67":"code","ad5cda82":"markdown","ff1f3bba":"markdown"},"source":{"81b229c9":"from statsmodels.tsa.ar_model import AutoReg, ar_select_order\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.api import acf, pacf, graphics\nfrom typing import List, Tuple, Union, NoReturn\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.offline as py\nimport plotly.express as px\nimport cufflinks as cf\nimport plotly\nfrom statsmodels.robust import mad\nimport matplotlib.pyplot as plt\nfrom scipy.signal import butter\nfrom scipy import signal\nimport seaborn as sns\nfrom sklearn import *\nimport pandas as pd \nimport numpy as np\nimport warnings\nimport scipy\nimport pywt\nimport os\nimport gc\n\ncf.go_offline()\npy.init_notebook_mode()\ncf.getThemes()\ncf.set_config_file(theme='ggplot')\nwarnings.simplefilter('ignore')\npd.plotting.register_matplotlib_converters()\nsns.mpl.rc('figure',figsize=(16, 6))\nplt.style.use('ggplot')\nsns.set_style('darkgrid')\n","6a8f8c2c":"base = os.path.abspath('\/kaggle\/input\/liverpool-ion-switching\/')\ntrain = pd.read_csv(os.path.join(base + '\/train.csv'))\ntest  = pd.read_csv(os.path.join(base + '\/test.csv'))","f4aa4215":"train.shape[0], test.shape[0]","158b83ee":"train.head()","d3724e73":"train.describe()","dd3f039a":"test.head()","880f6bde":"def add_bathing_to_data(df : pd.DataFrame) -> pd.DataFrame :\n    batches = df.shape[0] \/\/ 500000\n    df['batch'] = 0\n    for i in range(batches):\n        idx = np.arange(i*500000, (i+1)*500000)\n        df.loc[idx, 'batch'] = i + 1\n    return df\n\ndef p5( x : pd.Series) -> pd.Series : return x.quantile(0.05)\ndef p95(x : pd.Series) -> pd.Series : return x.quantile(0.95)\n","7415bb46":"train = add_bathing_to_data(train)\n","c042d8f3":"train.groupby('batch')[['signal','open_channels']].agg(['min', 'max', 'median', p5, p95])\n","afac088a":"train.groupby('open_channels')[['signal','batch']].agg(['min', 'max', 'median', p5, p95])\n","025b54e6":"train.groupby(['batch','open_channels'])[['signal']].agg(['min', 'max', 'median', p5, p95])\n","4b56959c":"partial = train.iloc[::250, :]\npartial.signal = np.round(partial.signal.values, 2)\npartial['shifted_signal'] = (partial.signal.values + 10) ** 2\nfig = px.scatter(partial, x='signal', y='open_channels', color='open_channels',size='shifted_signal',  title='Signal vs Channels')\nfig.show()\n","a207b1f6":"fig = px.box(partial, x='open_channels', y='signal', color='open_channels', title='Signal vs Channels')\nfig.update_traces(quartilemethod='exclusive')\nfig.show()","3a4f0666":"fig = px.box(partial, x='open_channels', y='signal', color='batch', title='Signal vs Channels for Batches')\nfig.update_traces(quartilemethod='exclusive')\nfig.show()","8f06b948":"fig = px.density_heatmap(train.iloc[::50, :], x='signal', y='open_channels')\nfig.show()\n","25b3bc83":"fig = make_subplots(rows=5, cols=2,  subplot_titles=[f'Batch no {i+1}' for i in range(10)])\ni = 1\nfor row in range(1, 6):\n    for col in range(1, 3):\n        data = train[train.batch==i]['open_channels'].value_counts(sort=False).values\n        fig.add_trace(go.Bar(x=list(range(11)), y=data), row=row, col=col)       \n        i += 1\nfig.update_layout(width=800, height=1500, title_text=\"Target for each batch\", showlegend=False)\n","3186abb4":"train.open_channels.value_counts(sort=False).iplot(kind='bar')","6661e671":"def plot_by_batch_summaries(df : pd.DataFrame) -> NoReturn :\n    by_batch = df.groupby(['batch']).agg(['min', 'max', 'median', p5, p95]).reset_index(drop=True).iloc[:,5:]\n    by_batch.columns = ['MIN-SIG','MAX-SIG', 'MED-SIG', '5P-SIG', '95P-SIG', 'MIN-CHANNEL','MAX-CHANNEL', 'MED-CHANNEL', '5P-CHANNEL', '95P-CHANNEL']\n    by_batch.iloc[:,:5].iplot(kind='bar',xTitle='Batch', yTitle='Signal')\n    by_batch.iloc[:,5:].iplot(kind='bar', xTitle='Batch', yTitle='Channel')\n\nplot_by_batch_summaries(train)","0265feae":"def plot_by_channel_summaries(df : pd.DataFrame) -> NoReturn :\n    by_channel = train.groupby(['open_channels']).agg(['min', 'max', 'median', p5, p95]).reset_index(drop=True).iloc[:,5:]\n    by_channel.columns = ['MIN-SIG','MAX-SIG', 'MED-SIG', '5P-SIG', '95P-SIG', 'MIN-BATCH','MAX-BATCH', 'MED-BATCH', '5P-BATCH', '95P-BATCH']\n    by_channel.iloc[:,5:].iplot(kind='bar' ,xTitle='Channel', yTitle='Batch')\n    by_channel.iloc[:,:5].iplot(kind='bar' )\n\nplot_by_channel_summaries(train)","b0ec1dd1":"def plot_by_channel_summaries(df : pd.DataFrame, resample : int) -> NoReturn :\n    train_resampled = df.iloc[::resample, :]\n    train_resampled[['signal','open_channels']].plot(subplots=True)\n    plt.show()\n    \nplot_by_channel_summaries(train, 10000)\n","ed165ec8":"def plot_smoothed_batch(i : int, window : int) -> NoReturn:\n    batch_resampled = train[train.batch==i].iloc[::1000, :]\n    ts = batch_resampled['signal']\n    plt.plot(ts, 'r-', color='royalblue')\n    plt.ylabel('Signal')\n    smooth_data = pd.Series(ts).rolling(window=window).mean().plot(style='k')\n    plt.show()","14bf8e32":"def maddest(d, axis=None):\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\ndef high_pass_filter(x, low_cutoff=1000, sample_rate=10000):\n\n    nyquist = 0.5 * sample_rate\n    norm_low_cutoff = low_cutoff \/ nyquist\n    print(norm_low_cutoff)\n    sos = butter(10, Wn=[norm_low_cutoff], btype='highpass', output='sos')\n    filtered_sig = signal.sosfilt(sos, x)\n\n    return filtered_sig\n\ndef denoise_signal( x, wavelet='db4', level=1):\n    \n    coeff = pywt.wavedec( x, wavelet, mode=\"per\" )\n    sigma = (1\/0.6745) * maddest( coeff[-level] )\n    uthresh = sigma * np.sqrt( 2*np.log( len( x ) ) )\n    coeff[1:] = ( pywt.threshold( i, value=uthresh, mode='hard' ) for i in coeff[1:] )\n    return pywt.waverec( coeff, wavelet, mode='per' )","2c694e06":"def plot_acf_pacf(i : int, lag : int, resample : int) -> NoReturn:\n    batch_resampled = train[train.batch==i].iloc[::resample, :]\n    plot_acf( batch_resampled['signal'], lags=lag)\n    plot_pacf(batch_resampled['signal'], lags=lag)\n    plt.show()","f79d0e83":"def add_rooling_data(df : pd.DataFrame) -> pd.DataFrame:\n    window_sizes = [10, 50, 100, 1000]\n    for window in window_sizes:\n        df[\"rolling_mean_\" + str(window)] = df['signal'].rolling(window=window).mean()\n        df[\"rolling_std_\" + str(window)] = df['signal'].rolling(window=window).std()\n    return df","56078221":"train = add_rooling_data(train)","31b0e187":"def plot_rolling_window(i : int, resample : int) -> NoReturn:\n    window_sizes = [10, 50, 100, 1000]\n    fig, ax = plt.subplots(len(window_sizes),1,figsize=(20, 6 * len(window_sizes)))\n    n = 0\n    for col in train.columns.values:\n        if 'rolling_' in col:\n            if 'mean' in col:\n                mean_df = train[train.batch==i].iloc[::resample,:][col]\n                ax[n].plot(mean_df, label=col, color='navy')\n            if 'std' in col:\n                std = train[train.batch==i].iloc[::resample,:][col].values\n                ax[n].fill_between(mean_df.index.values,\n                               mean_df.values-std, mean_df.values+std,\n                               facecolor='lightskyblue',\n                               alpha = 0.5, label=col)\n                ax[n].legend()\n                n+=1","4f85ae8c":"def plot_batch(i : int, resample : int) -> NoReturn:\n    batch_resampled = train[train.batch==i].iloc[::resample, :]\n    batch_resampled[['signal','open_channels']].plot(subplots=True)\n    plt.show()\n    ax = sns.distplot(batch_resampled[['signal']], rug=True)\n    ax.set_title(f'  Signal Distribution Batch=={i}', fontsize=13)\n    mod = AutoReg(batch_resampled['signal'], 3)\n    res = mod.fit(cov_type=\"HC0\")\n    sel = ar_select_order(batch_resampled['signal'], 3, glob=True)\n    sel.ar_lags\n    res = sel.model.fit()\n    fig = plt.figure(figsize=(16,9))\n    fig = res.plot_diagnostics(fig=fig, lags=25)\n    plot_rolling_window(i, resample)\n    return None","f29eb525":"def plot_signal_distribution_by_target(i : int) -> NoReturn :\n    data_by_target = train[train.open_channels==0]\n    ax = sns.distplot(data_by_target[['signal']], rug=True)\n    ax.set_title(f'Signal Distribution for Target=={i}', fontsize=13)\n    plt.show()\n    return None","45d6b518":"def plot_denoided_batch(i : int, resample : int) -> NoReturn : \n    batch_resampled = train[train.batch==i].iloc[::5000, :]  \n    batch_resampled['x_dn_1'] = denoise_signal(batch_resampled['signal'], wavelet='db4', level=1)\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=batch_resampled.time, mode='lines+markers', y=batch_resampled.signal, marker=dict(color=\"lightskyblue\"), name=\"Original signal\"))\n    fig.add_trace(go.Scatter(x=batch_resampled.time, y=batch_resampled.x_dn_1, mode='lines', marker=dict(color=\"navy\"), name=\"Denoised signal\"))\n    fig.show()","8f3b0429":"plot_batch(1, resample=1000)","7466c35e":"plot_smoothed_batch(1, window=25)","288395fd":"plot_denoided_batch(1, resample=5000)","40131591":"plot_acf_pacf(1, lag=25, resample=5000)","39056ebc":"plot_signal_distribution_by_target(0)","fc462a26":"train = pd.read_csv(os.path.join(base + '\/train.csv'))\ntest  = pd.read_csv(os.path.join(base + '\/test.csv'))\n\ndef features(df):\n    df = df.sort_values(by=['time']).reset_index(drop=True)\n    df.index = ((df.time * 10_000) - 1).values\n    df['batch'] = df.index \/\/ 25_000\n    df['batch_index'] = df.index  - (df.batch * 25_000)\n    df['batch_slices'] = df['batch_index']  \/\/ 2500\n    df['batch_slices2'] = df.apply(lambda r: '_'.join([str(r['batch']).zfill(3), str(r['batch_slices']).zfill(3)]), axis=1)\n    \n    for c in ['batch','batch_slices2']:\n        d = {}\n        d['mean'+c] = df.groupby([c])['signal'].mean()\n        d['median'+c] = df.groupby([c])['signal'].median()\n        d['max'+c] = df.groupby([c])['signal'].max()\n        d['min'+c] = df.groupby([c])['signal'].min()\n        d['std'+c] = df.groupby([c])['signal'].std()\n        d['mean_abs_chg'+c] = df.groupby([c])['signal'].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        d['abs_max'+c] = df.groupby([c])['signal'].apply(lambda x: np.max(np.abs(x)))\n        d['abs_min'+c] = df.groupby([c])['signal'].apply(lambda x: np.min(np.abs(x)))\n        d['range'+c] = d['max'+c] - d['min'+c]\n        d['maxtomin'+c] = d['max'+c] \/ d['min'+c]\n        d['abs_avg'+c] = (d['abs_min'+c] + d['abs_max'+c]) \/ 2\n        for v in d:\n            df[v] = df[c].map(d[v].to_dict())\n\n    \n    #add shifts\n    df['signal_shift_+1'] = [0,] + list(df['signal'].values[:-1])\n    df['signal_shift_-1'] = list(df['signal'].values[1:]) + [0]\n    for i in df[df['batch_index']==0].index:\n        df['signal_shift_+1'][i] = np.nan\n    for i in df[df['batch_index']==49999].index:\n        df['signal_shift_-1'][i] = np.nan\n\n    for c in [c1 for c1 in df.columns if c1 not in ['time', 'signal', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]:\n        df[c+'_msignal'] = df[c] - df['signal']\n        \n    return df\n\ntrain = features(train)\ntest = features(test)\n\ncol = [c for c in train.columns if c not in ['time', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]\nx1, x2, y1, y2 = model_selection.train_test_split(train[col], train['open_channels'], test_size=0.3, random_state=7)\ntarget = train['open_channels']\ntrain = train[col]\n\ndef MacroF1Metric(preds, dtrain):\n    labels = dtrain.get_label()\n    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n    score = metrics.f1_score(labels, preds, average = 'macro')\n    return ('MacroF1Metric', score, True)\n","47c8f352":"import lightgbm as lgb\nparams = {'learning_rate': 0.1, 'max_depth': -1, 'num_leaves':2**7+1, 'metric': 'rmse', 'random_state': 7, 'n_jobs':-1, 'sample_fraction':0.33} \nmodel = lgb.train(params, lgb.Dataset(x1, y1), 22222,  lgb.Dataset(x2, y2), verbose_eval=0, early_stopping_rounds=250, feval=MacroF1Metric)\npreds_lgb = (model.predict(test[col], num_iteration=model.best_iteration)).astype(np.float16)\noof_lgb = (model.predict(train, num_iteration=model.best_iteration)).astype(np.float16)\ngc.collect()","3f05efa0":"import xgboost as xgb\nparams = {'colsample_bytree': 0.375,'learning_rate': 0.1,'max_depth': 10, 'subsample': 1, 'objective':'reg:squarederror',\n          'eval_metric':'rmse', 'n_estimators':22222,   'tree_method':'gpu_hist',}\ntrain_set = xgb.DMatrix(x1, y1)\nval_set = xgb.DMatrix(x2, y2)\nmodel = xgb.train(params, train_set, num_boost_round=2222, evals=[(train_set, 'train'), (val_set, 'val')], \n                         verbose_eval=0, early_stopping_rounds=250)\npreds_xgb = model.predict(xgb.DMatrix(test[col]), ntree_limit=model.best_ntree_limit)\noof_xgb = (model.predict(xgb.DMatrix(train), ntree_limit=model.best_ntree_limit)).astype(np.float16)\ndel train_set, val_set; gc.collect()","248551b8":"from catboost import Pool,CatBoostRegressor\nmodel = CatBoostRegressor(task_type = 'GPU', iterations=22222, learning_rate=0.1, random_seed = 7, depth=7, eval_metric='RMSE')\ntrain_dataset = Pool(x1,  y1)          \neval_dataset = Pool(x2,  y2)\nmodel.fit(train_dataset, eval_set=eval_dataset, verbose=0, early_stopping_rounds=250)\npreds_cb = (model.predict(test[col])).astype(np.float16)\noof_cb = (model.predict(train)).astype(np.float16)\ndel train_dataset, eval_dataset, model; gc.collect()","d02ffd9a":"final_preds = 0.4 * preds_lgb + 0.4 * preds_xgb + 0.2 * preds_cb \nfinal_oof   = 0.4 * oof_lgb + 0.4 * oof_xgb + 0.2 * oof_cb ","27b24bf3":"from functools import partial\nimport scipy as sp\nclass OptimizedRounder(object):\n\n    def __init__(self):\n        self.coef_ = 0\n\n    def loss(self, coef, X, y):\n        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n        return -metrics.f1_score(y, X_p, average = 'macro')\n\n    def fit(self, X, y):\n        loss_partial = partial(self.loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        return (pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])).astype(np.int8)\n\n    def coefficients(self):\n        return self.coef_['x']\n","10563c09":"def optimize_predictions(preds, coeffs):\n    \n    preds[preds <= coeffs[0]] = 0\n    preds[np.where(np.logical_and(preds > coeffs[0], preds <= coeffs[1]))] = 1\n    preds[np.where(np.logical_and(preds > coeffs[1], preds <= coeffs[2]))] = 2\n    preds[np.where(np.logical_and(preds > coeffs[2], preds <= coeffs[3]))] = 3\n    preds[np.where(np.logical_and(preds > coeffs[3], preds <= coeffs[4]))] = 4\n    preds[np.where(np.logical_and(preds > coeffs[4], preds <= coeffs[5]))] = 5\n    preds[np.where(np.logical_and(preds > coeffs[5], preds <= coeffs[6]))] = 6\n    preds[np.where(np.logical_and(preds > coeffs[6], preds <= coeffs[7]))] = 7\n    preds[np.where(np.logical_and(preds > coeffs[7], preds <= coeffs[8]))] = 8\n    preds[np.where(np.logical_and(preds > coeffs[8], preds <= coeffs[9]))] = 9\n    preds[preds > coeffs[9]] = 10\n    preds = preds.astype(np.int8)\n    \n    return preds","e17ef7c2":"test['open_channels'] = np.round(np.clip(final_preds, 0, 10)).astype(int)\ntest[['time','open_channels']].to_csv('submission.csv', index=False, float_format='%.4f')","2cfb1f67":"test[['time','open_channels']].head()","ad5cda82":"## Different plots for each batch, denoised batch signal and Signal Distribution for each Target\n\nFor showing each batch or eatch target distribution just call the function with the batch nymber","ff1f3bba":"A Simple EDA with minimal Description. The model is just some minor changes to [physically-possible](https:\/\/www.kaggle.com\/jazivxt\/physically-possible)\n\nOne of the charts (plot_rolling_window) is from [eda-ion-switching](https:\/\/www.kaggle.com\/pestipeti\/eda-ion-switching) and the denoising functions are from [dwt-signal-denoising](https:\/\/www.kaggle.com\/jackvial\/dwt-signal-denoising)"}}