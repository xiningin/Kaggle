{"cell_type":{"207d0cb1":"code","df98725b":"code","1bf9a36c":"code","ba20c89f":"code","75d36509":"code","ce8cf177":"code","8b68ea35":"code","6b741ec6":"code","9e839792":"code","47c34c58":"code","7996d153":"code","d180c3c8":"code","c4fe9ec9":"code","cb829244":"code","5623a685":"code","bc22fd51":"code","c17ee5a9":"code","f8ddb700":"code","ef811c41":"code","8c037857":"code","57d10335":"code","eb3cc24a":"code","373589f2":"code","0101400c":"markdown","95c1d00e":"markdown"},"source":{"207d0cb1":"!git clone https:\/\/github.com\/spiorf\/stylegan-encoder","df98725b":"path = \"..\/input\/styleganffhq\/karras2019stylegan-ffhq-1024x1024.pkl\"\n!ls ..\/input","1bf9a36c":"%cd stylegan-encoder","ba20c89f":"\n%pip install tensorflow-gpu==1.15.2\nimport tensorflow as tf\nif tf.__version__ != '1.15.0':\n    print(f\"not {tf.__version__}\")\n\ntf.compat.v1.config.set_soft_device_placement(True)","75d36509":"#sfd","ce8cf177":"import os\nimport pickle\nimport PIL.Image\nimport numpy as np\nimport dnnlib\nimport dnnlib.tflib as tflib\n    \nimport config\nfrom encoder.generator_model import Generator\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\n# if this cell does not execute then restart and run \n# so that tensorflow version is 1.15","8b68ea35":"import config\nprint(config.cache_dir)","6b741ec6":"!nvidia-smi","9e839792":"#!cat \/home\/.local\/lib\/python3.7\/site-packages\/keras\/utils\/multi_gpu_utils.py","47c34c58":"!pwd","7996d153":"path = \"..\/..\/input\/styleganffhq\/karras2019stylegan-ffhq-1024x1024.pkl\"","d180c3c8":"!ls ..\/..\/input\/styleganffhq","c4fe9ec9":"#! mv {path} .\/sample.pkl","cb829244":"# URL_FFHQ = 'https:\/\/drive.google.com\/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ'\n# this is the pickle file\n\n# for this particular cell to work you need to enable your GPU\n\ntflib.init_tf()\n# with dnnlib.util.open_url(URL_FFHQ, cache_dir=config.cache_dir) as f:\n#     generator_network,discriminator_network, Gs_network = pickle.load(f)\n\nwith open(path, 'rb') as pickle_file:\n    generator_network, discriminator_network, Gs_network = pickle.load(pickle_file)\n\n","5623a685":"try:\n    generator = Generator(Gs_network, batch_size=1, randomize_noise=False)\nexcept Exception as e:\n    print(e)\n    \n# we have got exception error\n# lets try to chane","bc22fd51":"!cat \/opt\/conda\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/framework\/ops.py | grep -n \"GPU\"\n\n## these are the problematic lines","c17ee5a9":"# replacing all instances of GPU with XLA_GPU\n\n!sed -i \"s\/GPU:\/XLA_GPU:\/\" \/opt\/conda\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/framework\/ops.py\n!cat \/opt\/conda\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/framework\/ops.py | grep -n \"GPU\"\n","f8ddb700":"try:\n    generator = Generator(Gs_network, batch_size=1, randomize_noise=False)\nexcept Exception as e:\n    print(e)","ef811c41":"!sed '1748!d' \/opt\/conda\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/framework\/ops.py\n\n# I dont have any error in 1748 or mention of GPU. ","8c037857":"def generate_image(latent_vector):\n    latent_vector = latent_vector.reshape((1,18,512))\n    generator.set_dlatents(latent_vector)\n    img_array = generator.generate_images()[0]\n    img = PIL.Image.fromarray(img_array, 'RGB')\n    return Image.resize((256,256))\n\ndef move_and_show(latent_vector, direction, coeffs):\n    fig, ax = plt.subplots(1, len(coeffs), figsize=(15,10), dpi=80)\n    for i, coeff in enumerate(coeffs):\n        new_latent_vector = latent_vector.copy()\n        new_latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n        ax[i].imshow(generate_image(new_latent_vector))\n        ax[i].set_title('Coeff: %0.1f' % coeff)\n    [x.axis('off') for x in ax]\n    plt.show()","57d10335":"# Loading already learned representations\ndonald_trump = np.load('ffhq_dataset\/latent_representations\/donald_trump_01.npy')\nhillary_clinton = np.load('ffhq_dataset\/latent_representations\/hillary_clinton_01.npy')\n\n# Of course you can learn your own vectors using two scripts\n\n# 1) Extract and align faces from images\n# python align_images.py raw_images\/ aligned_images\/\n\n# 2) Find latent representation of aligned images\n# python encode_images.py aligned_images\/ generated_images\/ latent_representations\/","eb3cc24a":"# Loading already learned latent directions\nsmile_direction = np.load('ffhq_dataset\/latent_directions\/smile.npy')\ngender_direction = np.load('ffhq_dataset\/latent_directions\/gender.npy')\nage_direction = np.load('ffhq_dataset\/latent_directions\/age.npy')\n\n# In general it's possible to find directions of almost any face attributes: position, hair style or color ... \n# Additional scripts for doing so will be realised soon\n","373589f2":"move_and_show(donald_trump, smile_direction, [-1, 0, 2])","0101400c":"**restart the kernel after installing tensorflow 1.14**","95c1d00e":"Trying out code from this fork: https:\/\/github.com\/spiorf\/stylegan-encoder"}}