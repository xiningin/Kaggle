{"cell_type":{"61f12b3c":"code","3665271f":"code","a491ba38":"code","4fe41bd0":"code","d0ab75db":"code","ad2947b5":"code","b5d04cad":"code","ce9e8dfc":"code","d49cbbaf":"code","daaa3054":"code","0995e741":"code","24f8d0d7":"code","80d7de77":"code","1f89d65b":"code","a5712517":"code","1bafba73":"code","837f42a8":"code","115fb844":"code","690bf607":"code","00f7776d":"code","383c3c08":"code","b5048152":"code","6cdbf316":"code","af2fcadb":"code","6f963e7a":"code","0a5891e7":"code","192db952":"code","ef27c1c1":"code","1ff0d4c2":"code","7d27d761":"code","455462a8":"code","6140b8ee":"code","de7d0642":"code","471bd013":"code","943e9723":"code","7eb7cd1a":"code","fa7be1ab":"code","c7643a93":"code","514add41":"code","c3be69ee":"code","a27b0511":"code","78113b5f":"code","d8558e3a":"code","c114b595":"code","99a02aee":"code","6038a4b1":"code","34c2382f":"code","b5bc278a":"code","89a4e529":"code","c1a8ca61":"code","a66bad7b":"code","a54bcd8f":"code","6e265c73":"code","20edfac7":"code","fc09f16c":"code","6f9695c0":"code","28dad9b3":"code","d8477cc0":"code","8d984d62":"code","80635283":"code","a654b0b4":"code","a3a7c7f7":"code","4b11925e":"code","c9fb748f":"code","372a8d19":"code","e2b6ec84":"code","94977c86":"code","4a54f8a0":"markdown","a224a989":"markdown","0c992692":"markdown","3b416695":"markdown","41b7439b":"markdown","50fa5239":"markdown","03a2ab01":"markdown","927842f5":"markdown","40f4da55":"markdown","eb97fdea":"markdown","e1bbc5a9":"markdown","0d6fc251":"markdown","4faaaf48":"markdown","c73dc222":"markdown","29ba6933":"markdown","44f101b3":"markdown","893b267c":"markdown","319b93b5":"markdown","766ab3c6":"markdown","f38aebd3":"markdown","81d130d2":"markdown","c99167b4":"markdown","3e60713e":"markdown","e4c694bd":"markdown","2607bacc":"markdown","c807accb":"markdown"},"source":{"61f12b3c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport cv2\ntry:\n    for dirname, _, filenames in os.walk('\/kaggle\/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\nexcept OSError:\n    pass\n        #print(\"Size\",cv2.imread('filename').shape)\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3665271f":"#Data Analysis \nimport numpy as np\nimport pandas as pd\n#Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#Machine Learning\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications import ResNet50\n#Evaluation\nimport time\nfrom sklearn.metrics import precision_score, recall_score,\\\n                            confusion_matrix, classification_report, \\\n                            accuracy_score, f1_score","a491ba38":"TrainImage=\"\/kaggle\/input\/chest-xray-covid19-pneumonia\/Data\/train\/\"\nTestImage=\"\/kaggle\/input\/chest-xray-covid19-pneumonia\/Data\/test\/\"\ndata_path=\"\/kaggle\/input\/chest-xray-covid19-pneumonia\/Data\"\ntrain_dir=os.path.join(data_path,'train')\ntest_dir=os.path.join(data_path,'test')\nimage_labels=os.listdir(TrainImage)\nNormal=os.listdir(TrainImage+\"\/NORMAL\") #returns a list containing the names of the entries in the directory given by path\nPneumonia=os.listdir(TrainImage+\"\/PNEUMONIA\");\nCovid=os.listdir(TrainImage+\"\/COVID19\")","4fe41bd0":"Test_Normal=os.listdir(TestImage+\"\/NORMAL\")\nTest_Pneumonia=os.listdir(TestImage+\"\/PNEUMONIA\")\nTest_Covid=os.listdir(TestImage+\"\/COVID19\")\nTotal_TestData=Test_Normal+Test_Pneumonia+Test_Covid\nprint(f\"Total Normal Images {len(Test_Normal)}\\nTotal Test Pneumonia Images {len(Test_Pneumonia)}\\nTotal Test Covid19 Images {len(Test_Covid)}\\nTotal Test Images {len(Total_TestData)}\\n\")","d0ab75db":"print(Normal[:10])\nprint(\"-\"*100)\nprint(Test_Normal[:10])","ad2947b5":"from PIL import Image\nnor=[]\nfor filenames in Normal:   \n    im = Image.open(os.path.join(TrainImage,\"NORMAL\",filenames))\n    [width_nor, height_nor] = im.size\n    nor.append([width_nor, height_nor])\n\nfor i in range(len(nor)):\n    print(\"Normal-xray image\",nor[i])\n\n#print(max(nor))","b5d04cad":"pne=[]\nfor filenames in Pneumonia:   \n    im2 = Image.open(os.path.join(TrainImage,\"PNEUMONIA\",filenames))\n    width_p, height_p = im2.size\n    pne.append([width_p, height_p])\nfor i in range((len(pne))):\n    print(\"Pneumonia-xray image\",pne[i])\n#print(\"Max size in pne: \",max(pne))","ce9e8dfc":"cov=[]\nfor filenames in Covid:\n    im3=Image.open(os.path.join(TrainImage,\"COVID19\",filenames))\n    width_c,height_c=im3.size\n    cov.append([width_c,height_c])\nfor i in range(len(cov)):     \n    print(\"Covid x-ray image\",cov[i])\n#print(\"Max size in covid\",max(cov))","d49cbbaf":"print(f\"Total Normal Train Images: {len(Normal)}\\nTotal Pneumonia Train Images: {len(Pneumonia)}\\nTotal Train Covid19 Images: {len(Covid)}\\nTotal Train Images Num: {len(Normal)+len(Pneumonia)+len(Covid)}\")","daaa3054":"x = np.arange(3)\nplt.bar(x, height=[len(Normal),len(Pneumonia),len(Covid)])\nplt.xticks(x, ['Normal','Pnemonia','Covid-19'])\nplt.xlabel('Kinds of X-Ray')\nplt.ylabel('Counts')\nplt.legend(loc='upper lef')\nplt.show()","0995e741":"#I used plt.imread for image file to read\n#set up matplotlib fig and size it to fix 5x5 images\n#preview the data\nncolumns,nrows=5,5\nplt.figure(figsize=(10,10))\nfig = plt.gcf()\nfig.set_size_inches(ncolumns*5, nrows*5)\nfor i in range(25):\n    plt.subplot(nrows,ncolumns,i+1)\n    plt.imshow(plt.imread(os.path.join(TrainImage+\"\/PNEUMONIA\",Pneumonia[i])))\n    plt.title(\"Pneumonia\")\n    plt.axis(\"off\") #dont show axis or gridlines\nplt.show()","24f8d0d7":"plt.figure(figsize=(10,10))\nfig = plt.gcf()\nfig.set_size_inches(ncolumns*5, nrows*5)\nfor i in range(25):\n    plt.subplot(nrows,ncolumns,i+1)\n    plt.imshow(plt.imread(os.path.join(TrainImage+\"\/COVID19\",Covid[i])))\n    plt.title(\"Covid-19\")\n    plt.axis(\"off\")\nplt.show()","80d7de77":"plt.figure(figsize=(10,10))\nfig = plt.gcf()\nfig.set_size_inches(ncolumns*5, nrows*5)\nfor i in range(25):\n    plt.subplot(nrows,ncolumns,i+1)\n    plt.imshow(plt.imread(os.path.join(TrainImage+\"\/NORMAL\",Normal[i])))\n    plt.title(\"Normal\")\n    plt.axis(\"off\")\nplt.show()","1f89d65b":"def myFunc(image):\n    image = np.array(image)\n    hsv_image = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n    return Image.fromarray(hsv_image)","a5712517":"train_datagen = ImageDataGenerator( rescale = 1.0\/255.,\n                                    featurewise_center=True,\n                                    featurewise_std_normalization=True,\n                                    rotation_range=30,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2,\n                                    shear_range=0.2,\n                                    zoom_range=0.2,\n                                    horizontal_flip=True,\n                                    vertical_flip=True)\ntest_datagen  = ImageDataGenerator( rescale = 1.0\/255.)\n","1bafba73":"image_size=224\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size=32,#default 32\n                                                    class_mode='categorical',\n                                                    target_size=(image_size, image_size),\n                                                    shuffle=True)  \n# Flow validation images in batches of 20 using test_datagen generator\ntest_generator =  test_datagen.flow_from_directory (test_dir,\n                                                    batch_size=32,\n                                                    class_mode  = 'categorical',\n                                                    target_size = (image_size, image_size))\n","837f42a8":"train_generator.class_indices\nLabels=train_generator.class_indices\ntest_generator.class_indices","115fb844":"#For using GPU accelerator \ntf.test.is_gpu_available()","690bf607":"#Check TF version\nprint(tf.__version__)","00f7776d":"image_size=224 # to resize the all image as same size\nmodel=tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image with what you want to num of bytes colour \n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(image_size, image_size, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'), \n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(256, activation='relu'),\n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n    tf.keras.layers.Dense(3, activation='softmax')  #before I used sigmoid \n])","383c3c08":"model.summary()","b5048152":"model.compile(optimizer=RMSprop(lr=0.01),\n              loss='categorical_crossentropy',\n              metrics = ['accuracy'])","6cdbf316":"image_labels","af2fcadb":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)","6f963e7a":"history=model.fit_generator(\n        train_generator,\n        steps_per_epoch=20,#len(train_generator),\n        epochs=20,\n        validation_data=test_generator,\n        callbacks=[callback],\n        validation_steps=20)#len(test_generator))","0a5891e7":"print(\"Test Accuracy:{:.2f}%\".format(model.evaluate_generator(test_generator,steps=30)[1]*100))\nprint(\"Accuracy with train set {:.2f}%\".format(history.history['accuracy'][-1] * 100))","192db952":"loss_df = pd.DataFrame(model.history.history)\nloss_df","ef27c1c1":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","1ff0d4c2":"model.evaluate(test_generator)","7d27d761":"prediction1 = np.argmax(model.predict(test_generator), axis = -1)\nprediction1","455462a8":"def get_report(predictions):\n    print(classification_report(test_generator.classes,predictions))\n    print(confusion_matrix(test_generator.classes,predictions))\n    sns.heatmap(confusion_matrix(test_generator.classes,predictions), annot = True)\n    \"\"\"\n    print ('Accuracy:', accuracy_score(y_test, prediction))\n    print ('F1 score:', f1_score(y_test, prediction))\n    print ('Recall:', recall_score(y_test, prediction))\n    print ('Precision:', precision_score(y_test, prediction))\n    print ('\\n clasification report:\\n', classification_report(y_test,prediction))\n    print ('\\n confussion matrix:\\n',confusion_matrix(y_test, prediction))\"\"\"","6140b8ee":"test_generator.classes","de7d0642":"test_generator.class_indices\n","471bd013":"get_report(prediction1)","943e9723":"def getLabel(n):\n    for x,c in Labels.items():\n        if n==c:\n            return x","7eb7cd1a":"y_test=[]\nfor i in range(41):\n    y_test.extend(test_generator.__getitem__(i)[1])\ny_test=np.array(y_test)\ny_test=np.argmax(y_test,axis=1)\nconfusion_matrix(prediction1,y_test)\nplt.figure(figsize=(20,10))\nfig = plt.gcf()\nncolumns,nrows=5,5\nfig.set_size_inches(ncolumns*5, nrows*5)\nfor i in range(25):\n    plt.subplot(nrows, ncolumns, i + 1)\n    plt.imshow(test_generator.__getitem__(0)[0][i],cmap='gray')\n    plt.title(f\"REAL: {getLabel(y_test[i])   } vs  PREDICT: {getLabel(prediction1[i])}\")\n","fa7be1ab":"!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/mledu-datasets\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O \/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \n\n\nlocal_weights_file = '\/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npre_trained_model = InceptionV3(input_shape = (224,224, 3), \n                                include_top = False, \n                                weights = None)\npre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n    layer.trainable = False","c7643a93":"pre_trained_model.summary()","514add41":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","c3be69ee":"# Flatten the output layer to 1 dimension\nx = tf.keras.layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = tf.keras.layers.Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = tf.keras.layers.Dropout(0.2)(x)  \nx = tf.keras.layers.Dense(256, activation='relu')(x)\n# Add a final sigmoid layer for classification\nx = tf.keras.layers.Dense  (3, activation='softmax')(x)           \n\nmodel2 = Model( pre_trained_model.input, x) \n\nmodel2.compile(optimizer = RMSprop(lr=0.001), \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])\n","a27b0511":"history2 = model2.fit(train_generator,\n                        validation_data = test_generator,\n                        steps_per_epoch = len(train_generator),\n                        epochs = 10,\n                        validation_steps = len(test_generator))","78113b5f":"print(\"Accuracy with train set {:.2f}%\".format(history2.history['accuracy'][-1] * 100))","d8558e3a":"loss_df2 = pd.DataFrame(model2.history.history)\nloss_df2","c114b595":"acc = history2.history['accuracy']\nval_acc = history2.history['val_accuracy']\nloss = history2.history['loss']\nval_loss = history2.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, loss, 'r', label='Cross entropy loss')\n#plt.plot(epochs, val_acc, 'b',label='Test accuracy')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and Val Accuracy & Loss')\nplt.legend(loc=0)\nplt.figure()\nplt.show()","99a02aee":"model2.evaluate(test_generator)","6038a4b1":"prediction2 = np.argmax(model2.predict(test_generator), axis = -1)\nprediction2","34c2382f":"get_report(prediction2)","b5bc278a":"def getLabel(n):\n    for x,c in Labels.items():\n        if n==c:\n            return x","89a4e529":"y_test2=[]\nfor i in range(41):\n    y_test2.extend(test_generator.__getitem__(i)[1])\ny_test2=np.array(y_test2)\ny_test2=np.argmax(y_test2,axis=1)\n\nconfusion_matrix(prediction2,y_test2)\nplt.figure(figsize=(20,10))\nfig = plt.gcf()\nncolumns,nrows=5,5\nfig.set_size_inches(ncolumns*5, nrows*5)\nfor i in range(25):\n    plt.subplot(nrows, ncolumns, i + 1)\n    plt.imshow(test_generator.__getitem__(0)[0][i],cmap='gray')\n    plt.title(f\"REAL: {getLabel(y_test2[i])   } vs  PREDICT: {getLabel(prediction2[i])}\")","c1a8ca61":"# Flatten the output layer to 1 dimension\nx = tf.keras.layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = tf.keras.layers.Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = tf.keras.layers.Dropout(0.2)(x)  \nx = tf.keras.layers.Dense(256, activation='relu')(x)\n# Add a final sigmoid layer for classification\nx = tf.keras.layers.Dense  (3, activation='softmax')(x)           \n\nmodel3 = Model(pre_trained_model.input, x) \n\nmodel3.compile(optimizer =\"adam\", \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])\n\n","a66bad7b":"history3 = model3.fit(train_generator,\n                        validation_data = test_generator,\n                        steps_per_epoch = 30 ,#len(train_generator),\n                        epochs = 25,\n                        callbacks=[callback],\n                        validation_steps = 30 )#len(test_generator))","a54bcd8f":"print(\"Accuracy with train set {:.2f}%\".format(history3.history['accuracy'][-1] * 100))","6e265c73":"acc = history3.history['accuracy']\nval_acc = history3.history['val_accuracy']\nloss = history3.history['loss']\nval_loss = history3.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.show();","20edfac7":"model3.evaluate(test_generator)","fc09f16c":"loss_df3 = pd.DataFrame(model3.history.history)\nloss_df3","6f9695c0":"prediction3 = np.argmax(model3.predict(test_generator), axis = -1)\nprediction3","28dad9b3":"get_report(prediction3)","d8477cc0":"y_test3=[]\nfor i in range(41):\n    y_test3.extend(test_generator.__getitem__(i)[1])\ny_test3=np.array(y_test3)\ny_test3=np.argmax(y_test3,axis=1)\nconfusion_matrix(prediction3,y_test3)\nplt.figure(figsize=(20,10))\nfig = plt.gcf()\nncolumns,nrows=5,5\nfig.set_size_inches(ncolumns*5, nrows*5)\nfor i in range(25):\n    plt.subplot(nrows, ncolumns, i + 1)\n    plt.imshow(test_generator.__getitem__(0)[0][i],cmap='gray')\n    plt.title(f\"REAL: {getLabel(y_test3[i])   } vs  PREDICT: {getLabel(prediction3[i])}\")","8d984d62":"base_model= ResNet50(include_top=False, weights=\"imagenet\", input_shape=(224, 224,3))\nResNet_model= Sequential()\nResNet_model.add(base_model)\nResNet_model.add(tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'))\nResNet_model.add(tf.keras.layers.Dropout(0.2))\nResNet_model.add(tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'))\nResNet_model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\nResNet_model.add(tf.keras.layers.Dropout(0.2))\nResNet_model.add(tf.keras.layers.Flatten())\nResNet_model.add(tf.keras.layers.Dense(512,activation='relu'))\nResNet_model.add(tf.keras.layers.Dense(256,activation='relu'))\nResNet_model.add(tf.keras.layers.Dropout(0.2))\nResNet_model.add(tf.keras.layers.Dense(128,activation='relu'))\nResNet_model.add(tf.keras.layers.Dense(64,activation='relu'))\nResNet_model.add(tf.keras.layers.Dense(32,activation='relu'))\nResNet_model.add(tf.keras.layers.Dense(16,activation='relu'))\nResNet_model.add(tf.keras.layers.Dense(8,activation='relu'))\nResNet_model.add(tf.keras.layers.Dense(3, activation='softmax'))\nResNet_model.summary()","80635283":"ResNet_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","a654b0b4":"print(\"Training started it takes few minutes..\")\nstart_time = time.time()\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n# This callback will stop the training when there is no improvement in\n# the validation loss for three consecutive epochs.\nlearn_control = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=.5, min_lr=0.1) #min_lr=0.0001\nResNet_history = ResNet_model.fit_generator(\n                                            train_generator,\n                                            steps_per_epoch=20,\n                                            epochs=10,\n                                            callbacks=[callback],\n                                            validation_data=test_generator,\n                                            validation_steps=20)\nprint(\"Successfully completed the traing session..\")\nprint(\"Took %d:%.2d minutes\" % divmod(time.time() - start_time, 60))","a3a7c7f7":"ResNet_model.evaluate(test_generator)","4b11925e":"loss_df4 = pd.DataFrame(ResNet_model.history.history)\nloss_df4","c9fb748f":"prediction4 = np.argmax(ResNet_model.predict(test_generator), axis = -1)\nprediction4","372a8d19":"print(ResNet_history.history['val_accuracy'])\nprint(\"-\"*10)\nResNet_history.history['accuracy']","e2b6ec84":"# Plotting accuracy history\nepochs_no=6\nplt.figure(figsize=(7, 5))\nplt.ylim(0.0, 1.1)\nplt.plot(range(epochs_no), ResNet_history.history['accuracy'], color='blue', label='Training accuracy');\nplt.plot(range(epochs_no), ResNet_history.history['val_accuracy'], color='r', label='Validation accuracy');\nplt.legend();\nplt.title('ResNet50 Accuracy with Data-augmentation');\nplt.ylabel('Accuracy');\nplt.xlabel('epoch');\nplt.savefig('ResNet50_accuracy_with.jpg', dpi=300, bbox_inches='tight');\n\n# Plotting loss history\nplt.figure(figsize=(7, 5))\nplt.ylim(0.0, 2)\n\nplt.plot(range(epochs_no), ResNet_history.history['loss'], color='blue', label='Training loss');\nplt.plot(range(epochs_no), ResNet_history.history['val_loss'], color='r', label='Validation loss');\nplt.legend();\nplt.title('ResNet50 Loss with Data-augmentation');\nplt.ylabel('Loss');\nplt.xlabel('epoch');\nplt.savefig('ResNet50_loss_with.jpg', dpi=300, bbox_inches='tight')","94977c86":"y_test4=[]\nfor i in range(41):\n    y_test4.extend(test_generator.__getitem__(i)[1])\ny_test4=np.array(y_test4)\ny_test4=np.argmax(y_test4,axis=1)\nconfusion_matrix(prediction4,y_test4)\nplt.figure(figsize=(20,10))\nfig = plt.gcf()\nncolumns,nrows=5,5\nfig.set_size_inches(ncolumns*5, nrows*5)\nfor i in range(25):\n    plt.subplot(nrows, ncolumns, i + 1)\n    plt.imshow(test_generator.__getitem__(0)[0][i],cmap='gray')\n    plt.title(f\"REAL: {getLabel(y_test4[i])   } vs  PREDICT: {getLabel(prediction4[i])}\")","4a54f8a0":"# Conclusion","a224a989":"# Visualize the Data\nLet's analyze the number of Normal, Covid-19 and Pneumonia x-ray images. Here are the first 25 images from the training dataset each type.","0c992692":"Building a small model. Define a sequential layer as before, adding some convolutional layers first. Finally add the densely connected layers. Note that because I'm facing a multi class classification problem (not binary classification) I will end my network with a sigmoid function.So that the output of my network will be a single scalar between 0 and 1. ","3b416695":"Ideas in my mind for get better accuracy of my model:\n-> Change optimizer with Adam \n-> Apply Transfer Learning method with Vgg16,19 or ImageNet\n-> Visualize data ","41b7439b":"As we can see, all images in the data set are in different sizes, so I will standardize these images.","50fa5239":"# Standardize the data\nThe RGB channel values are in the [0, 255] range. This is not ideal for a neural network; in general you should seek to make your input values small. Here, we will standardize values to be in the [0, 1] by using a Rescaling layer.\nThese images come in all shapes and sizes. Before training neural network need to tweak the images ","03a2ab01":"# Visualize training results","927842f5":"# Improving the model ","40f4da55":"Explore the images' size in the dataset","eb97fdea":"Let's find out the total number of images in the train and test directories ","e1bbc5a9":"I have developed a convolutional neural network using the some models to detect cases of COVID-19, pneumonia and normal cases from chest radiographs. It is robust and reliable,\nusing a larger dataset and more control classes than most other models published. It is able to accurately distinguish COVID-19 from healthy and pneumonia X-ray images. It achieves an F1-score of 0.96 and a COVID-19 classification accuracy. Given the sheer volume of patients that must be screened, this automated tool can save valuable time, money, and resources that are scarce in healthcare systems around the world. It may especially impact developing countries and resource-strained regions where both molecular tests and trained radiologists are in short supply, as an automated diagnosis tool provides a simple detection solution. I believe that this model, and machine learning as a whole, can significantly improve current COVID-19 diagnosis practices.","0d6fc251":"# Model summary","4faaaf48":"# Compile the model","c73dc222":"data that goes into neural networks should usually be normalized in some way to make it more amenable to processing by the network. (It is uncommon to feed raw pixels into a convnet.) In our case, we will preprocess our images by normalizing the pixel values to be in the [0, 1] range (originally all values are in the [0, 255] range).\nIn Keras this can be done via the keras.preprocessing.image.ImageDataGenerator class using the rescale parameter. This ImageDataGenerator class allows you to instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory). These generators can then be used with the Keras model methods that accept data generators as inputs: fit, evaluate_generator, and predict_generator.","29ba6933":"# Create a model","44f101b3":"# Explore Data Folders","893b267c":"Define some parameters for the loader such as batch size,img_height,img_weight etc\nNote: tf.keras.preprocessing.image_dataset_from_directory","319b93b5":"I used categorical crossentropy loss function because I want to divide it into 3 classes at the exit. \nI tried the learning rate for different cases. When it is too small, training takes too long, so I increased the learning rate.\nI used RMSprop becuase RMSprop automates learning-rate tuning (Other optimizers, such as Adam and Adagrad, \nalso automatically adapt the learning rate during training,and would work equally well here)","766ab3c6":"# Importing Libraries","f38aebd3":"# Train the model","81d130d2":"Planned Workflow: \n1. Examine and Understand Data\n2. Build an input pipeline\n3. Build the model \n4. Train the model\n5. Test the model\n6. Improve the model and repeat the process.","c99167b4":"Result of the analyze is Pneumonia affected samples are quite more than others.","3e60713e":"# Transfer Learning","e4c694bd":"Check out the samples that I've got in the dataset and generate the sample images. This dataset contains 3 sub-directories -one per class-","2607bacc":"![](https:\/\/www.iaea.org\/sites\/default\/files\/styles\/third_page_width_portrait_2_3\/public\/chestxray.png?itok=z07bhz5h&c=b64d5f5d9a54f1cfd815edc18198844a)","c807accb":"# Project Summary\nThis project's aim is make prediction Covid-19 detection from chest xray dataset.Dataset contains chest images of patients which are positive or negative of COVID-19."}}