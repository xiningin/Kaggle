{"cell_type":{"5ee9b6ab":"code","676ba91b":"code","aa2c0bbe":"code","089f90ea":"code","9732c545":"code","5e0ee5f0":"code","53db61a2":"code","a7842110":"code","28163a52":"code","0a25e728":"code","2485ac40":"code","0f0b5669":"code","e16c4423":"code","ca9fa614":"code","75a87cc8":"code","3333edc0":"code","ae945613":"code","921330a7":"code","f6b50bb9":"code","ced134b6":"code","e37c7689":"code","5b1bfc3f":"code","6c4f5c61":"code","291bbde8":"markdown","38590fee":"markdown","04b4d12e":"markdown"},"source":{"5ee9b6ab":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing","676ba91b":"train = pd.read_csv('..\/input\/resolving-citizens-grievances-v1\/dataset\/train.csv')\ntest = pd.read_csv('..\/input\/resolving-citizens-grievances-v1\/dataset\/test.csv')\ntrain.head()","aa2c0bbe":"train.shape, test.shape","089f90ea":"# combining test and train to do feature engineering.\ntest['importance']=-1\ntrain['label'] = 'train'\ntest['label'] = 'test'\ncombined = pd.concat([train,test],axis=0)\ncombined.shape","9732c545":"for col in combined.columns:\n    print(col,'unique values-> ',combined[col].nunique(), 'null values--> ', combined[col].isnull().sum())","5e0ee5f0":"def combine_issues(df):\n    issue_columns = [\n        'issue.0', 'issue.1', 'issue.2', 'issue.3', 'issue.4', 'issue.5', 'issue.6', 'issue.7', 'issue.8', \n        'issue.9', 'issue.10', 'issue.11', 'issue.12', 'issue.13', 'issue.14', 'issue.15', 'issue.16', \n        'issue.17', 'issue.18', 'issue.19', 'issue.20', 'issue.21', 'issue.22', 'issue.23']\n    issue_df = combined[issue_columns]\n    issue_df.fillna('',inplace=True)\n    issue_df['issues'] = issue_df[issue_columns].apply(lambda x: '. '.join([val for val in x if val != '']), axis=1)\n    df.drop(issue_columns, axis=1, inplace=True)\n    issue_df.drop(issue_columns, axis=1, inplace=True)\n    df = pd.concat([df, issue_df], axis=1)\n    return df","53db61a2":"def lowercase_texts(df):\n    print('converting all text columns in lowercase.',)\n    for col in combined.columns:\n        if combined[col].dtype=='object':\n            combined[col] = combined[col].str.lower()\n    return df","a7842110":"def universalize_countries(df):\n# converting all the countries to single symbolic numerical value.(eg - Albania, albania, abl, ab -> 1)\n    country_dict_A = df[['respondentOrderEng','country.name']].set_index('country.name').T.to_dict('list')\n    country_dict_C = df[['respondentOrderEng','respondent.0']].set_index('respondent.0').T.to_dict('list')    \n    country_dict = {}\n    for d in (country_dict_A, country_dict_C):#, country_dict_C): #, country_dict_D, country_dict_E, country_dict_F): \n        country_dict.update(d)\n        \n    country_dict = {k: v for k, v in country_dict.items() if pd.notna(k)}\n    df['respondent.0'] = df['respondent.0'].apply(lambda x: country_dict[x][0])\n    df['respondent.1'] = df['respondent.1'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.2'] = df['respondent.2'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.3'] = df['respondent.3'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.4'] = df['respondent.4'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    del df['respondentOrderEng']\n    return df","28163a52":"def remove_constant_values(df):\n#     this function removes redundant constant features.\n    print('Removing constant columns -> ',)\n    for col in df.columns:\n        if df[col].nunique()==1:\n            print(col,end=', ' )\n            del df[col]\n    return df\n\ndef remove_unwanted_features(df):\n#     these features dont add any valueable signal to the data.\n    remove_cols =['parties.0', 'country.alpha2', 'parties.1', 'country.name', 'docname', 'appno', 'ecli', 'kpdate', 'originatingbody_name']\n    for col in remove_cols:\n        if col in df.columns:\n            df.drop(col, axis=1, inplace=True)\n    return df","0a25e728":"def featurize_columns(df):\n#     making new columns.\n    df['itemid'] = df['itemid'].apply(lambda x: x[4:7])\n    df['sharepointid'] = df['sharepointid'].apply(lambda x: str(x)[:3])\n    df['total_respondents'] = 5- df[['respondent.0','respondent.1','respondent.2','respondent.3','respondent.4']].isna().sum(axis=1)\n\n    return df\n\ndef featurize_date_columns(df):\n    #     making new columns based on dates.\n    df['daysbetween_intro_decision'] = (pd.to_datetime(df['decisiondate']) - pd.to_datetime(df['introductiondate'])).dt.days\n    df['daysbetween_intro_judgement'] = (pd.to_datetime(df['judgementdate']) - pd.to_datetime(df['introductiondate'])).dt.days\n    df['daysbetween_decision_judgement'] = (pd.to_datetime(df['judgementdate']) - pd.to_datetime(df['decisiondate'])).dt.days\n    df.drop(['decisiondate','introductiondate','judgementdate'], axis=1, inplace=True)\n    return df","2485ac40":"le = preprocessing.LabelEncoder()\ndef encoding(df):\n    df['doctypebranch'] = le.fit_transform(df['doctypebranch'])\n    df['separateopinion'] = le.fit_transform(df['separateopinion'])\n    df['typedescription'] = le.fit_transform(df['typedescription'])\n    return df","0f0b5669":"def fill_missing(df):\n    for col in df.columns:\n        if col not in ['label', 'issues']:\n            df[col].fillna(0,inplace=True)\n            df[col] = df[col].astype('int')\n    return df","e16c4423":"combined.head()","ca9fa614":"combined = combine_issues(combined)\nprint('combined shape after combining issues ->', combined.shape)\ncombined = lowercase_texts(combined)\ncombined = universalize_countries(combined)\ncombined = featurize_columns(combined)\ncombined = featurize_date_columns(combined)\ncombined = encoding(combined)\ncombined = remove_constant_values(combined)\nprint('\\ncombined shape after removing constant features->', combined.shape)\ncombined = remove_unwanted_features(combined)\ncombined = fill_missing(combined)","75a87cc8":"combined.to_csv('combined_inbetween.csv',index=False)","3333edc0":"from lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import accuracy_score","ae945613":"target_col = 'importance'","921330a7":"combined_train = combined.query('label == \"train\"').drop(['issues', 'label'] , axis=1)","f6b50bb9":"X_train, X_test, Y_train, Y_test = train_test_split(combined_train.drop([target_col], axis=1),combined_train[target_col],test_size=0.2,stratify=combined_train[target_col])","ced134b6":"XG = XGBClassifier()","e37c7689":"oof_preds = cross_val_predict(XG, X_train, Y_train, cv=5, \n                                  n_jobs=-1, method=\"predict\")\nprint(\"cv score: \", accuracy_score(oof_preds, Y_train) * 100)","5b1bfc3f":"tst = combined.query('label == \"test\"').drop(['issues', 'label', target_col] , axis=1)\nXG.fit(X_train,Y_train)\npreds = XG.predict(tst)\npreds","6c4f5c61":"sub = pd.DataFrame(columns=[\"appno\",\"importance\"])\nsub[\"appno\"] = test.appno\nsub[\"importance\"] = preds\nsub.to_csv(\"result2.csv\", index=False)","291bbde8":"xgbm = LGBMClassifier(max_depth=6, learning_rate=0.1, n_estimators=500,\n                         min_child_weight=100, subsample=1.0, \n                         colsample_bytree=0.8, colsample_bylevel=0.8,\n                         random_state=42, n_jobs=-1)","38590fee":"tst = combined.query('label == \"test\"').drop(['issues', 'label', target_col] , axis=1)\nxgbm.fit(X_train,Y_train)\npreds = xgbm.predict(tst)\npreds ","04b4d12e":"oof_preds = cross_val_predict(xgbm, X_train, Y_train, cv=5, \n                                  n_jobs=-1, method=\"predict\")\nprint(\"cv score: \", accuracy_score(oof_preds, Y_train) * 100)"}}