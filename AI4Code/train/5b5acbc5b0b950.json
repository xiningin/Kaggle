{"cell_type":{"b2e4979f":"code","ab934fa6":"code","d514eb85":"code","2fc01258":"code","25e54396":"code","173d0628":"code","ee3e5423":"code","55c3dced":"code","f085ea4f":"code","fbf60417":"code","337c40e9":"code","d4fd0ac9":"code","45d96d39":"code","ec152d25":"code","a671fd30":"code","d27e77e1":"code","4facbc29":"code","25e9b04a":"code","d32336b9":"code","8acd4621":"markdown","b45bbac9":"markdown","7b675ac6":"markdown","308430f1":"markdown","06b11da1":"markdown","146080ac":"markdown","e5f89e87":"markdown","5ae8e857":"markdown","b654ec5b":"markdown","2f61f958":"markdown","9b5b7bd4":"markdown"},"source":{"b2e4979f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pylab as pl\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nimport scipy.optimize as opt\nimport os","ab934fa6":"for dirname, _, filenames in os.walk('..\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d514eb85":"\ntrain = pd.read_csv(\"\/kaggle\/input\/coronascraper\/timeseries-tidy.csv\")\ntrain.head()","2fc01258":"train[train[\"country\"] == 'South Africa'].head()","25e54396":"train = train[train[\"level\"] == 'country']\ntrain = train.drop(columns = ['name','city','county','state','population','lat','long','aggregate','tz'])\ntrain = train.pivot_table(values='value',index=['country','date'],columns='type').reset_index()\ntrain.index.name = train.columns.name = None\ntrain.head()","173d0628":"#train_=train\n#EMPTY_VAL = \"EMPTY_VAL\"\n\n#def fillState(state, country):\n#    if state == EMPTY_VAL: return country\n#    return state\n\n#train_['Province_State'].fillna(EMPTY_VAL, inplace=True)\n#train_['Province_State'] = train_.loc[:, ['Province_State', 'Country_Region']].apply(lambda x : fillState(x['Province_State'], x['Country_Region']), axis=1)\n#test['Province_State'].fillna(EMPTY_VAL, inplace=True)\n#test['Province_State'] = test.loc[:, ['Province_State', 'Country_Region']].apply(lambda x : fillState(x['Province_State'], x['Country_Region']), axis=1)\n#test.head()","ee3e5423":"train['deaths'] = train['deaths'].fillna(0)\ntrain['cases'] = train['cases'].fillna(0)\ntrain = train[train[\"cases\"] > 0]\ntrain.head(20)","55c3dced":"train['row_number'] = train.groupby(['country']).cumcount()\nx = train[train[\"country\"] == 'United Kingdom']['row_number']\ny = train[train[\"country\"] == 'United Kingdom']['cases']\ny_ = train[train[\"country\"] == 'United Kingdom']['deaths']\n#print(x,y,y_)","f085ea4f":"y_.head(10)","fbf60417":"\n\ndef f(x, L, b, k, x_0):\n    return L \/ (1. + np.exp(-k * (x - x_0))) + b\n\n\ndef logistic(xs, L, k, x_0):\n    result = []\n    for x in xs:\n        xp = k*(x-x_0)\n        if xp >= 0:\n            result.append(L \/ ( 1. + np.exp(-xp) ) )\n        else:\n            result.append(L * np.exp(xp) \/ ( 1. + np.exp(xp) ) )\n    return result\n\np0 = [max(y), 0.0,max(x)]\np0_ = [max(y_), 0.0,max(x)]\nx_ = np.arange(0, 150, 1).tolist()\ntry:\n    popt, pcov = opt.curve_fit(logistic, x, y,p0)\n    yfit = logistic(x_, *popt)\n    popt_, pcov_ = opt.curve_fit(logistic, x, y_,p0_)\n    yfit_ = logistic(x_, *popt_)\nexcept:\n    popt, pcov = opt.curve_fit(f, x, y, method=\"lm\", maxfev=10000)\n    yfit = f(x_, *popt)\n    popt_, pcov_ = opt.curve_fit(f, x, y_, method=\"lm\", maxfev=10000)\n    yfit_ = f(x_, *popt_)\n    #print(\"problem\")\n\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nax.plot(x, y, 'o', label ='Actual Cases')\nax.plot(x_, yfit, '-', label ='Fitted Cases')\n\nax.plot(x, y_, 'o', label ='Actual Fatalities')\nax.plot(x_, yfit_, '-', label ='Fitted fatalities')\nax.title.set_text('South Africa')\nplt.legend(loc=\"center right\")\nplt.show()","337c40e9":"unique = pd.DataFrame(train_.groupby(['Country_Region', 'Province_State'],as_index=False).count())\nunique.head()","d4fd0ac9":"import datetime as dt\n\ndef date_day_diff(d1, d2):\n    delta = dt.datetime.strptime(d1, \"%Y-%m-%d\") - dt.datetime.strptime(d2, \"%Y-%m-%d\")\n    return delta.days\n\nlog_regions = []\n\nfor index, region in unique.iterrows():\n    st = region['Province_State']\n    co = region['Country_Region']\n    \n    rdata = train_[(train_['Province_State']==st) & (train_['Country_Region']==co)]\n\n    t = rdata['Date'].values\n    t = [float(date_day_diff(d, t[0])) for d in t]\n    y = rdata['ConfirmedCases'].values\n    y_ = rdata['Fatalities'].values\n\n    p0 = [max(y), 0.0, max(t)]\n    p0_ = [max(y_), 0.0, max(t)]\n    try:\n        popt, pcov = opt.curve_fit(logistic, t, y, p0, maxfev=10000)\n        try:\n            popt_, pcov_ = opt.curve_fit(logistic, t, y_, p0_, maxfev=10000)\n        except:\n            popt_, pcov_ = opt.curve_fit(f, t, y_,method=\"trf\", maxfev=10000)\n        log_regions.append((co,st,popt,popt_))\n    except:\n        popt, pcov = opt.curve_fit(f, t, y,method=\"trf\", maxfev=10000)\n        popt_, pcov_ = opt.curve_fit(f, t, y_,method=\"trf\", maxfev=10000)\n        log_regions.append((co,st,popt,popt_))\n\nprint(\"All done!\")","45d96d39":"log_regions = pd.DataFrame(log_regions)\nlog_regions.columns = ['Country_Region','Province_State','ConfirmedCases','Fatalities']\nlog_regions.head(1)","ec152d25":"T = np.arange(0, 100, 1).tolist()\npopt = list(log_regions[log_regions[\"Country_Region\"] == 'Italy'][log_regions[\"Province_State\"] == 'Italy']['ConfirmedCases'])[0]\npopt_ = list(log_regions[log_regions[\"Country_Region\"] == 'Italy'][log_regions[\"Province_State\"] == 'Italy']['Fatalities'])[0]\n\ntry:\n    yfit = logistic(T, *popt)\n    yfit_ = logistic(T, *popt_)\nexcept:\n    yfit = f(T, *popt)\n    yfit_ = f(T, *popt_)\n    \n\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nax.plot(T, yfit, label=\"Fitted ConfirmedCases\")\nax.plot(T, yfit_, label=\"Fitted Fatalities\")\nax.title.set_text('Italy fitted params')\nplt.legend(loc=\"upper left\")\nplt.show()","a671fd30":"for index, rt in log_regions.iterrows():\n    st = rt['Province_State']\n    co = rt['Country_Region']\n    popt = list(['ConfirmedCases'])\n    popt_ = list(rt['Fatalities'])\n    print(co,st,popt,popt_)","d27e77e1":"data0 = log_regions['Fatalities'].str[0]\/log_regions['ConfirmedCases'].str[0]\ndata1 = log_regions['Fatalities'].str[1]\/log_regions['ConfirmedCases'].str[1]\ndata2 = log_regions['Fatalities'].str[2]\/log_regions['ConfirmedCases'].str[2]\nbins = np.arange(0, 3, 0.01)\nplt.hist(data1,bins=bins, alpha=0.5)\nplt.xlim([0,3])\nplt.ylabel('count')\nplt.ylim([0,5])\nplt.show()\nfp = np.array([data0.median(),data1.median(),data2.median()])\nfp","4facbc29":"for index, rt in log_regions.iterrows():\n    st = rt['Province_State']\n    co = rt['Country_Region']\n    popt = list(rt['ConfirmedCases'])\n    popt_ = list(rt['Fatalities'])\n    \n    if popt_ == [0.0,0.0,70.0]:\n        popt_ = np.multiply(fp,popt)\n        print(co,st,popt,popt_)","25e9b04a":"submission = []\n\nfor index, rt in log_regions.iterrows():\n    st = rt['Province_State']\n    co = rt['Country_Region']\n    popt = list(rt['ConfirmedCases'])\n    popt_ = list(rt['Fatalities'])\n    if popt_ == [0.0,0.0,70.0]:\n        #popt_ = np.multiply(fp,popt)\n        popt_ = np.array([popt[0]*0.035,popt[1],popt[2]])\n    print(co,st,popt,popt_)\n    rtest = test[(test['Province_State']==st) & (test['Country_Region']==co)]\n    for index, rt in rtest.iterrows():\n        try:\n            tdate = rt['Date']\n            ca = logistic([date_day_diff(tdate, min(train_[(train_['Province_State']==st) & (train_['Country_Region']==co)]['Date'].values))], *popt)\n            try:\n                fa = logistic([date_day_diff(tdate, min(train_[(train_['Province_State']==st) & (train_['Country_Region']==co)]['Date'].values))], *popt_)\n            except:\n                fa = f([date_day_diff(tdate, min(train_[(train_['Province_State']==st) & (train_['Country_Region']==co)]['Date'].values))], *popt_)\n            submission.append((rt['ForecastId'], int(ca[0]), int(fa[0])))\n        except:\n            tdate = rt['Date']\n            ca = f([date_day_diff(tdate, min(train_[(train_['Province_State']==st) & (train_['Country_Region']==co)]['Date'].values))], *popt)\n            fa = f([date_day_diff(tdate, min(train_[(train_['Province_State']==st) & (train_['Country_Region']==co)]['Date'].values))], *popt_)\n            submission.append((rt['ForecastId'], int(ca[0]), int(fa[0])))\n\nprint(\"All done!\") ","d32336b9":"submission = pd.DataFrame(submission)\nsubmission.columns = ['ForecastId','ConfirmedCases','Fatalities']\nsubmission.to_csv('.\/submission.csv', index = False)\nprint(\"submission ready!\")","8acd4621":"So there are a lot of countries that dont have fatalities just yet, but we are going to go with the data that says that meaningful cases lead inevitably to fatalities. To do that we need to estimate fatality parameters for each curve, im going to looking to the medians across the populaiton of countries to infer the params.","b45bbac9":"Check that we can infer:","7b675ac6":"Need to replace all NULLs with country:","308430f1":"Run a graph and see how the logistic curve fits:","06b11da1":"Test one country:","146080ac":"Submit predictions:","e5f89e87":"Fit Logistic curves to data:","5ae8e857":"Give dimension column headers:","b654ec5b":"Apply to test data:\nedit: gonna try estimate based in case curve, say 3.5%:","2f61f958":"In this notebook, as in last weeks (week 2), we are going to fit logitic curves to each intersection and save the estimated parameters for prediction on test data.","9b5b7bd4":"Create a dimension of the country\/states:"}}