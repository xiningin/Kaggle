{"cell_type":{"ff4a5163":"code","01be8129":"code","b2ee3b3c":"code","fc880c4a":"code","ac1c22df":"code","4e816f74":"code","ca20316f":"code","2d80c2bb":"code","66ff935c":"code","aa398927":"code","f56e2d3f":"code","170c338a":"code","70d26ef7":"code","de5f970d":"code","8cd8bd24":"code","0b4340ee":"code","ab926083":"code","7c6874e9":"code","ae6cefa6":"code","ab53eca5":"code","914d35c8":"code","9ca0a888":"code","d6fc8346":"code","13620094":"code","dd2ff843":"code","3f21e7fb":"code","f22962c8":"code","a903f110":"code","e83bee6d":"code","ea35060c":"code","0dcb9930":"code","bffb1ae8":"code","3c5393c5":"code","9592f8dc":"code","e3deac51":"code","0c5a5b98":"code","ddc98b8b":"code","01f36fb3":"code","71ae9d64":"code","f3cb5082":"code","c82adee8":"code","019a1a64":"code","2e0ef0c5":"code","74adfa06":"code","457cbb7d":"markdown","86f6c0ef":"markdown","6d78cb24":"markdown","73d36abf":"markdown","18863a3a":"markdown","b9212d81":"markdown","a3bcdf21":"markdown","8cd1cdad":"markdown","c089379c":"markdown","15fe2127":"markdown","f3314598":"markdown","5ef3f282":"markdown","8c76e2c3":"markdown","d655a385":"markdown","c4ddd818":"markdown","256c1e88":"markdown","e565ebb4":"markdown","0500da7e":"markdown","318a4417":"markdown","9ba15a87":"markdown","0dc1b6ac":"markdown","ad35dad6":"markdown","0e6febc5":"markdown","dab8374b":"markdown","d61ed8a3":"markdown","54dc67dc":"markdown","f3aef2a2":"markdown"},"source":{"ff4a5163":"#Imports\nimport numpy as np\nimport pandas as pd\n\n#Visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nget_ipython().run_line_magic('matplotlib', 'inline')\nsns.set_style(\"whitegrid\")\n\n#Modeling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n#Keras\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, MaxPool2D, Conv2D, Flatten, Dropout, BatchNormalization\nfrom keras.losses import categorical_crossentropy\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","01be8129":"#Data import\ntrain = pd.read_csv(\"\/kaggle\/input\/Kannada-MNIST\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/Kannada-MNIST\/test.csv\")\nvalidation = pd.read_csv(\"\/kaggle\/input\/Kannada-MNIST\/Dig-MNIST.csv\")\n","b2ee3b3c":"train.head()","fc880c4a":"sns.countplot(train[\"label\"])\nplt.title(\"Distribution of Digit Samples in the Training Set\")","ac1c22df":"train.groupby(train[\"label\"]).size()\n","4e816f74":"validation.head()","ca20316f":"sns.countplot(validation[\"label\"])\nplt.title(\"Distribution of Digit Samples in Validation Set\")","2d80c2bb":"validation.groupby(validation[\"label\"]).size()","66ff935c":"test.head()","aa398927":"#Spliting off labels\/Ids\ntrain_labels = to_categorical(train.iloc[:,0])\ntrain = train.iloc[:, 1:].values\n\nX_validation = validation.iloc[:, 1:].values\ny_validation = to_categorical(validation.iloc[:,0])\n\ntest_id = test.iloc[:, 0]\ntest = test.iloc[:, 1:].values","f56e2d3f":"#Normalizing the data\ntrain = train\/255\nX_validation = X_validation\/255\n\ntest = test\/255","170c338a":"#Reshaping data\ntrain = train.reshape(train.shape[0], 28, 28, 1)\n\nX_validation = X_validation.reshape(validation.shape[0], 28, 28, 1)\n\ntest = test.reshape(test.shape[0], 28, 28, 1)","70d26ef7":"#Visualizing the Training Data\nfig, ax = plt.subplots(5, 10)\nfor i in range(5):\n    for j in range(10):\n        ax[i][j].imshow(train[np.random.randint(0, train.shape[0]), :, :, 0], cmap = plt.cm.binary)\n        ax[i][j].axis(\"off\")\nplt.subplots_adjust(wspace=0, hspace=0)\nfig.set_figwidth(15)\nfig.set_figheight(7)\nplt.show()","de5f970d":"#Visualizing the Validation Data\nfig, ax = plt.subplots(5, 10)\nfor i in range(5):\n    for j in range(10):\n        ax[i][j].imshow(X_validation[np.random.randint(0, X_validation.shape[0]), :, :, 0], cmap = plt.cm.binary)\n        ax[i][j].axis(\"off\")\nplt.subplots_adjust(wspace=0, hspace=0)\nfig.set_figwidth(15)\nfig.set_figheight(7)","8cd8bd24":"#Augmenting data\ntrain_datagen = ImageDataGenerator(\n    rotation_range=12,\n    width_shift_range=0.25,\n    height_shift_range=0.25,\n    shear_range=12,\n    zoom_range=0.25\n)\n\nvalid_datagen = ImageDataGenerator(    \n    rotation_range=12,\n    width_shift_range=0.25,\n    height_shift_range=0.25,\n    shear_range=12,\n    zoom_range=0.25)\n\nvalid_datagen_simple = ImageDataGenerator()","0b4340ee":"#Splitting train\/test sets\nX_train, X_test, y_train, y_test = train_test_split(train, train_labels, test_size = 0.2, random_state = 84)\n","ab926083":"def build_model():\n    model = Sequential()\n    \n    #First set of covolutional layers\n    #Each with 32 unit output\n    model.add(Conv2D(32, (3,3), activation = \"relu\", input_shape = (28,28,1), padding = \"same\"))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, (5,5), strides = (2,2) ,activation = \"relu\", padding = \"same\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    #Second set of covolution layers\n    #Each with a 64 unit output\n    model.add(Conv2D(64, (3,3), activation = \"relu\", input_shape = (28,28,1), padding = \"same\"))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, (5,5), strides = (2,2) ,activation = \"relu\", padding = \"same\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    #Third set of covolution layers\n    #Each with a 128 unit output    \n    model.add(Conv2D(128, (3,3), activation = \"relu\", padding = \"same\"))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, (5,5), strides = (2,2), activation = \"relu\", padding = \"same\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n    \n    #Pooling Layer\n    model.add(MaxPool2D(2,2))\n    model.add(Dropout(0.2))\n    \n    #Fourth and final covolution layer\n    #Output of 256 units\n    model.add(Conv2D(256, (3,3), activation = \"relu\", padding = \"same\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    #Flatteing model to pass to dense layer\n    model.add(Flatten())\n    \n    #First Dense Layer    \n    model.add(Dense(128, activation = \"relu\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    #Final Dense layer\n    #Used to predict the ten label classes    \n    model.add(Dense(10, activation = \"softmax\"))\n    \n    #Compile the model\n    model.compile(optimizer = \"adam\", loss = categorical_crossentropy, metrics = [\"accuracy\"])\n    \n    return(model)\n","7c6874e9":"#model\nmodel = build_model()","ae6cefa6":"#fitting model on training split\nhistory = model.fit_generator(\n    train_datagen.flow(X_train, y_train, batch_size = 1024), \n    epochs = 50,\n    steps_per_epoch=50,\n    #shuffle = True, this only has effect when steps_per_epoch = \"None\" \n    validation_data = (X_test, y_test))","ab53eca5":"pd.DataFrame(history.history).describe().iloc[1:,:]","914d35c8":"y_test_labels = []\nfor i in y_test:\n    for j, val in enumerate(i):\n        if val == 0.:\n            pass\n        else:\n            y_test_labels.append(j)","9ca0a888":"#predicting on the test split\npreds = history.model.predict_classes(X_test)","d6fc8346":"#accuracy of the predictions\naccuracy_score(preds, np.array(y_test_labels))","13620094":"plt.figure(figsize=(9,7))\nplt.plot(history.history[\"accuracy\"])\nplt.plot(history.history[\"val_accuracy\"])\nplt.title(\"Accuracy on Training Data vs. Accuracy on Validation Data\\nTraining Step 1\")\nplt.legend([\"Train\", \"Validation\"], loc = \"lower right\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.savefig(\"Accuracy_TrainS1.png\")","dd2ff843":"plt.figure(figsize = (9,7))\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.title(\"Loss on Training Data vs. Loss on Validation Data\\nTraining Step 1\")\nplt.legend([\"Train\", \"Validation\"], loc = \"upper right\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.savefig(\"Loss_TrainS1.png\")","3f21e7fb":"#reinitialize model\nmodel = build_model()","f22962c8":"#Fitting on full training set\n#validation set used for validation\nhistory_full = model.fit_generator(\n    train_datagen.flow(train, train_labels, batch_size = 1024), \n    epochs = 50,\n    steps_per_epoch=train.shape[0]\/\/1024,\n    validation_data = valid_datagen.flow(X_validation, y_validation))","a903f110":"pd.DataFrame(history_full.history).describe().iloc[1:,:]#\n","e83bee6d":"preds = history_full.model.predict_classes(X_validation)\n","ea35060c":"accuracy_score(preds, np.argmax(y_validation, axis = 1))\n","0dcb9930":"pd.crosstab(preds, validation.iloc[:,0])\n","bffb1ae8":"plt.figure(figsize=(9,7))\nplt.plot(history_full.history[\"accuracy\"])\nplt.plot(history_full.history[\"val_accuracy\"])\nplt.title(\"Accuracy on Training Data vs. Accuracy on Validation Data\\nTraining Step 2\")\nplt.legend([\"Train\", \"Validation\"], loc = \"lower right\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.savefig(\"Accuracy_TrainS2.png\")","3c5393c5":"plt.figure(figsize = (9,7))\nplt.plot(history_full.history[\"loss\"])\nplt.plot(history_full.history[\"val_loss\"])\nplt.title(\"Loss on Training Data vs. Loss on Validation Data\\nTraining Step 2\")\nplt.legend([\"Train\", \"Validation\"], loc = \"upper right\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.savefig(\"Loss_TrainS2.png\")","9592f8dc":"#concatenating data\nX_train_total = np.concatenate((train, X_validation))\ny_train_total = np.concatenate((train_labels, y_validation))\n","e3deac51":"X_train_total.shape\n","0c5a5b98":"y_train_total.shape\n","ddc98b8b":"#Reinitializing model\nmodel = build_model()","01f36fb3":"history_final = model.fit_generator(train_datagen.flow(\n    X_train_total, y_train_total, batch_size=1024),\n    epochs = 50, \n    steps_per_epoch = X_train_total.shape[0]\/\/1024,\n    validation_data = valid_datagen.flow(X_validation, y_validation))","71ae9d64":"\nplt.figure(figsize=(9,7))\nplt.plot(history_final.history[\"accuracy\"])\nplt.plot(history_final.history[\"val_accuracy\"])\nplt.title(\"Accuracy on Training Data vs. Accuracy on Validation Data\\nTraining Step 3\")\nplt.legend([\"Train\", \"Validation\"], loc = \"lower right\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.savefig(\"Accuracy_TrainS3.png\")","f3cb5082":"plt.figure(figsize = (9,7))\nplt.plot(history_final.history[\"loss\"])\nplt.plot(history_final.history[\"val_loss\"])\nplt.title(\"Loss on Training Data vs. Loss on Validation Data\\nTraining Step 3\")\nplt.legend([\"Train\", \"Validation\"], loc = \"upper right\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.savefig(\"Loss_TrainS3.png\")","c82adee8":"preds = history_final.model.predict_classes(test)\n","019a1a64":"preds[:10]","2e0ef0c5":"submission = pd.DataFrame(data = [pd.Series(test_id, name = \"id\"), pd.Series(preds, name = \"label\")], ).T","74adfa06":"submission.to_csv(\"submission.csv\", index = False)\n","457cbb7d":"#### Data Augmentation\nThe more data I can provide to the model, the more accurately it should be able to predict on new data. As I'm ~~unwilling~~ unable to draw another 60,000 digit samples to add to my training data, I'll be augmenting the training data using the keras utility `ImageDataGenerator()`. This will implement random alterations on various images throughout the data set, and then supplement the original training data with these new, slightly augmented images. My generator will,\n+ preform a random rotation of no more than 12 degrees\n+ modify the width of the image up to no more than 25% of the original width\n+ modify the height similarly to, but independantly from, the width\n+ shear the images (rotate the top of the image, bu not the bottom, imagine a rhombus compared to a rectagle) up to no more than 12 degrees\n+ preform a random zoom of the image up to 25% of the original image\n","86f6c0ef":"* * *","6d78cb24":"Below I create the model function.","73d36abf":" # Kannada Digit Recognition\n \n In modeling this data, I'll be following a three step training process, to create the best possible senario for creating my final predictions.  \n \n**First Training** In the first training of the model I'll be using a traditional train\/test split of the training data alone, to both training and validate the model. If I notice the model overfits notably, I'll implement different techniques to reduce\/correct this issue. To prevent overfitting I will either be increasing the dropout rate in the various Dropout layers in the model, by increasing the amount of pooling layers, or by implementing som eform of regulation.  \n \n**Second Training** In the second training of the model, I'll be using the entirity of the training data set to train the model, and then wil validate the model on the validation set, `Dig-MNIST.csv`. It may be easier to notice the effects of any overfitting in the model at this stage than it is in the original model, as I'll have the benefit of a much larger dataset, increasing the effect of overfitting if such an issue previously existed. If I notice such an issue, I'll again implement different techniques to reduce\/correct this issue.  \n \n**Third Training** In the third and final training stage of the model, I will concatenate the training and validation data sets to create a new training set, `train_total`. I'll then use this uber-set to train the final model which will be used to predict the labels of the test set.\n","18863a3a":"* * *","b9212d81":"## Submissions","a3bcdf21":"**Validation Data**  \nThis data will be used as the validation data in the model witch trains on the full training set, and will be concatenated with the training data for the final submission model.\n","8cd1cdad":"With our data now in the correct shape, lets visualize the training and the validation sets.","c089379c":"* * *","15fe2127":"**Performance**","f3314598":"To verify the construction of the three dataframes, we will quickly review the first few rowsof the data.\n\n**Training Data**  \nThis data will be used through the training of all models.\n","5ef3f282":"## Data\n### Exploratory Analysis\nThe data for this challenge can be found on [the kaggle competition page](). It consists of three seperate files: the training set, `train.csv`, the validation set, `Dig-MNIST.csv`, and the testing set, `test.csv`. These three sets each contain image data, stored in row\/column styles. As such, each row of the data sets reflects a specific image, while the rows describe the information for the image. The first row contains the image label (or an id in the case of the test set), a number between 0-9, and the last 784 columns each show the value of the individual pixels as an integer between 0 and 255, inclusive, for the 28 x 28 pixel images.\n","8c76e2c3":"Below I create the model function.","d655a385":"**Performance**\n\nThe model is now trained! Let's review the performance of the first training step.\n","c4ddd818":"* * *","256c1e88":"**Testing Data**  \nThis data will be used to generate the class predictions for the competition submissions.","e565ebb4":"**Third Training Step**  \nIn this training step I'll be concatenating the training and validation sets, to provide the most data possible for the training og the model.\n","0500da7e":"**Visualizations**","318a4417":"**First Training Step**  \nThis is the first training of the model, in which the model is trained and validated on different splits of the training data set. The original training of this model showed an average accuracy of ! and a validation accuracy of !. Overfitting was considered at this stage, but I decided to wait and review the second training stage for issues which would stem from overfitting.\n","9ba15a87":"The training for the second training step is complete! Lets review the history to see how well the model performed. \n","0dc1b6ac":"**Second Training Step**  \nThe model will be trained on the full training set in this step, and will be validated against the validation set.\n","ad35dad6":"The above is a random selection of 50 different diits in the training set. ","0e6febc5":"The above is a random selection of 50 different digits in the validation set.","dab8374b":"Although we don't usually need to be as highly concerned with the distribution of the test set, I will be, at some point in the analysis, combining the training and validation data, to fully train the model I'll be using for my submission, in order to provide the most training data as possible for the final model.  \nAs such, I'm going to review the distribution of the validation set as well.\n","d61ed8a3":"In grouping the training data by their labels we can verify the number of classes in our data, as well as the distribution of the digits in the data set. Ideally the sampling distribution of the digits should be uniform.\n","54dc67dc":"## Modeling\nI'll be creating one model for this project, and then training the optimal fit of said  model three seperate times. In the process of optimizing the model, I'll first be overfitting the model, and then reducing\/correcting for the overfitting in optimization. \n","f3aef2a2":"### Data Treatment and Augmentation\n#### Data Treatment\nAs the data is presented in row\/column format, I need to transform it into matrix format both to visualize the images and for the keras CNN model I will be building.\n \nFirst I'll be spliting the label and id columns off of the three data sets, and storing them in seperate variables. I'll then be creating array verisions of the pixel information for the images. The labels will be sent to binary matrices made up of the class vectors for the labels, while the pixel information will be reshapped into the 28 x 28 pixel images. The pixel information will also be normalized, such the maxium pixel value will be 1, with a minimum of zero, to improve the accuracy of the model.\n"}}