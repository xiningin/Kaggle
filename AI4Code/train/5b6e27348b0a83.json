{"cell_type":{"f40bd27e":"code","80f8f21a":"code","da13269b":"code","716123ab":"code","1500d8c1":"code","449dc987":"code","36d892a9":"code","896f67fe":"code","1ce8b15b":"code","3fa6690f":"code","af357fd8":"code","1d08468d":"code","06cce9d8":"code","75fdad13":"code","5a3b188b":"code","25854507":"code","aebc912a":"code","20afd670":"code","61286fce":"code","84b9bde4":"code","8d85335c":"code","290bf17d":"code","42fa989c":"code","8187a41e":"code","2169dcd8":"code","653012c1":"code","6e076fbe":"code","edce7d97":"code","7593abc2":"code","e6cd5cdb":"code","21f8b946":"code","a0a415a4":"code","499b3d85":"code","08593b5e":"code","50b6b5e9":"code","6b194273":"code","c58b647a":"code","2cd81eb4":"code","6c74efa1":"code","5f3a21b5":"code","a76d92c1":"code","fa55f155":"code","595bc878":"code","417c2d06":"code","40685670":"code","ff55b93c":"code","dd978128":"code","65e2a049":"code","1359f3a1":"code","90ff9983":"code","a3362f9f":"code","dd78d3ce":"code","b75cde83":"code","c4ecc01a":"code","f1e040da":"code","fea5bbd8":"code","bdfec15c":"code","49f37339":"code","9f9d3735":"markdown","923dabd5":"markdown"},"source":{"f40bd27e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","80f8f21a":"import pandas_profiling as pr\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","da13269b":"telco = pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ntelco.head()","716123ab":"telco.info()","1500d8c1":"#Checking missing values\ntelco.isnull().any().sum()","449dc987":"telco.describe()","36d892a9":"pr.ProfileReport(telco)","896f67fe":"dict(telco.dtypes)","1ce8b15b":"# Converting Total Charges to a numerical data type.\ntelco.TotalCharges = pd.to_numeric(telco.TotalCharges, errors='coerce')\ntelco.isnull().sum()\ntelco.fillna(0,inplace=True)","3fa6690f":"telco.head()","af357fd8":"telco_churn = pd.DataFrame(telco.Churn.value_counts())\ntelco_churn\nsns.barplot(telco_churn.index, telco_churn.Churn)","1d08468d":"#by gender\n\ngender_count  = telco[['gender','Churn']].groupby(['gender','Churn']).size().reset_index()\ngender_count.columns = ['gender','churn','count']\nsns.catplot(x = 'gender',y='count',hue='churn',data = gender_count,kind='bar')","06cce9d8":"senior_citizen_count  = telco[['SeniorCitizen','Churn']].groupby(['SeniorCitizen','Churn']).size().reset_index()\nsenior_citizen_count.columns = ['SeniorCitizen','churn','count']\nsns.catplot(x = 'SeniorCitizen',y='count',hue='churn',data = senior_citizen_count,kind='bar')","75fdad13":"telco[['MonthlyCharges', 'TotalCharges']].plot.scatter(x = 'MonthlyCharges',\n                                                              y='TotalCharges')","5a3b188b":"#Total charges and Churn\nsns.distplot(telco.MonthlyCharges[(telco[\"Churn\"] == 'No') ] ,color='r')\nsns.distplot(telco.MonthlyCharges[(telco['Churn'] == 'Yes')],color='g')\n","25854507":"#MonthlyCharges and Churn\n\nsns.kdeplot(telco.TotalCharges[(telco[\"Churn\"] == 'No') ] ,color='r',shade=True)\nsns.kdeplot(telco.TotalCharges[(telco['Churn'] == 'Yes')],color='g',shade=True)\n","aebc912a":"sns.boxplot(x='tenure',y='Churn',data=telco)","20afd670":"#payment method and churn\n\npayment_method_count  = telco[['PaymentMethod','Churn']].groupby(['PaymentMethod','Churn']).size().reset_index()\npayment_method_count.columns = ['paymentMethod','churn','count']\nsns.catplot(x = 'count',y='paymentMethod',hue='churn',data = payment_method_count,kind='bar')","61286fce":"#divide numeric and categorical variables\nnumeric_var_names = [key for key in dict(telco.dtypes) if dict(telco.dtypes)[key] in ['int32','int64','float32','float64']]\ncat_var_names = [key for key in dict(telco.dtypes) if dict(telco.dtypes)[key] in ['object','O']]\n                     ","84b9bde4":"telco_num = telco[numeric_var_names]\ntelco_cat = telco[cat_var_names]","8d85335c":"#create data audit report\n\ndef var_summary(x):\n    return pd.Series([x.count(),x.isnull().sum(),x.sum(),x.var(),x.std(),x.mean(),x.median(),x.min(),x.dropna().quantile(0.01),x.dropna().quantile(0.05),\n              x.dropna().quantile(0.10),x.dropna().quantile(0.25),x.dropna().quantile(0.50),x.dropna().quantile(0.75),x.dropna().quantile(0.90),\n              x.dropna().quantile(0.95),x.dropna().quantile(0.99)],index=['N','NMISS','SUM','VAR','STD','MEAN','MEDIAN','MIN','P1','P5','P10','P25','P50','P75','P90','P95','P99'])\nnum_summary = telco_num.apply(lambda x : var_summary(x)).T","290bf17d":"num_summary\n#As we can see that there are no outliers","42fa989c":"sns.boxplot(telco_num.TotalCharges)","8187a41e":"#Missing value treatment of TotalCharges\n\ntelco_num.TotalCharges.fillna(0,inplace=True)","2169dcd8":"def cat_summary(x):\n    return pd.Series([x.count(),x.isnull().sum(),x.value_counts()],index=['N','NMISS','COUNT'])\n\ncat_summary = telco_cat.apply(lambda x : cat_summary(x)).T\ncat_summary","653012c1":"telco_cat.head()","6e076fbe":"#lets convert categorical variables to numeric by Label Encoding\n\ntelco_cat['gender'] = LabelEncoder().fit_transform(telco_cat['gender'])\ntelco_cat['Partner'] = LabelEncoder().fit_transform(telco_cat['Partner'])\ntelco_cat['Dependents'] = LabelEncoder().fit_transform(telco_cat['Dependents'])\ntelco_cat['PhoneService'] = LabelEncoder().fit_transform(telco_cat['PhoneService'])\ntelco_cat['MultipleLines'] = LabelEncoder().fit_transform(telco_cat['MultipleLines'])\ntelco_cat['InternetService'] = LabelEncoder().fit_transform(telco_cat['InternetService'])\ntelco_cat['OnlineSecurity'] = LabelEncoder().fit_transform(telco_cat['OnlineSecurity'])\ntelco_cat['OnlineBackup'] = LabelEncoder().fit_transform(telco_cat['OnlineBackup'])\ntelco_cat['DeviceProtection'] = LabelEncoder().fit_transform(telco_cat['DeviceProtection'])\ntelco_cat['TechSupport'] = LabelEncoder().fit_transform(telco_cat['TechSupport'])\ntelco_cat['StreamingTV'] = LabelEncoder().fit_transform(telco_cat['StreamingTV'])\ntelco_cat['StreamingMovies'] = LabelEncoder().fit_transform(telco_cat['StreamingMovies'])\ntelco_cat['Contract'] = LabelEncoder().fit_transform(telco_cat['Contract'])\ntelco_cat['PaperlessBilling'] = LabelEncoder().fit_transform(telco_cat['PaperlessBilling'])\ntelco_cat['PaymentMethod'] = LabelEncoder().fit_transform(telco_cat['PaymentMethod'])","edce7d97":"telco_cat.drop(['customerID'],axis=1,inplace=True)","7593abc2":"telco_cat['Churn'] = telco_cat['Churn'].map({'No':0,'Yes':1})","e6cd5cdb":"telco_df = pd.DataFrame(pd.concat([telco_num,telco_cat],axis=1))\ntelco_df.head()","21f8b946":"#Correlation\nplt.figure(figsize=(20,10))\nsns.heatmap(telco_df.corr(),annot=True)","a0a415a4":"#Predictive Modelling\n\nfeature_columns = telco_df.columns.difference(['Churn'])\nfeature_columns","499b3d85":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","08593b5e":"train_x, test_x, train_y, test_y = train_test_split(telco_df[feature_columns], telco_df['Churn'], test_size=0.2,random_state=42)\nprint(train_x.shape)\nprint(train_y.shape)\nprint(test_x.shape)\nprint(test_y.shape)","50b6b5e9":"#Building Model\nlogreg = LogisticRegression()\nlogreg.fit(train_x,train_y)","6b194273":"logreg.coef_","c58b647a":"list(zip(feature_columns, logreg.coef_[0]))","2cd81eb4":"logreg.predict_proba(test_x)","6c74efa1":"pred_y = pd.DataFrame({'actual': test_y,'predicted':logreg.predict(test_x)})\npred_y.reset_index()","5f3a21b5":"#confusion Matrix\ncm = metrics.confusion_matrix(pred_y.actual,pred_y.predicted,[1,0])\ncm","a76d92c1":"sns.heatmap(cm, annot=True, xticklabels=['churn','not_churn'], yticklabels = ['churn','not_churn'], fmt='.1f')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","fa55f155":"#Accuracy Score\nprint(\"Accuracy \" +str(metrics.accuracy_score(pred_y.actual,pred_y.predicted)))\nprint(\"Precision \" +str(metrics.precision_score(pred_y.actual,pred_y.predicted)))\nprint(\"Recall \" +str(metrics.recall_score(pred_y.actual,pred_y.predicted)))\nprint(\"ROC AUC \" +str(metrics.roc_auc_score(pred_y.actual,pred_y.predicted)))\nprint(\"f1 score \" +str(metrics.f1_score(pred_y.actual,pred_y.predicted)))\n#the Recall score is not that much great. As we see that the data is quite imbalanced lets try to balance the data and then check the accuracy and recall score.","595bc878":"#Building model by rebalancing the data\nlogreg1 = LogisticRegression(class_weight='balanced')\nlogreg1.fit(train_x,train_y)","417c2d06":"list(zip(feature_columns, logreg1.coef_[0]))","40685670":"pred_y = pd.DataFrame({'actual': test_y,'predicted':logreg1.predict(test_x)})\npred_y = pred_y.reset_index()\npred_y.head()","ff55b93c":"#confusion Matrix\ncm = metrics.confusion_matrix(pred_y.actual,pred_y.predicted,[1,0])\ncm","dd978128":"sns.heatmap(cm, annot=True, xticklabels=['churn','not_churn'], yticklabels = ['churn','not_churn'], fmt='.1f')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","65e2a049":"#Different parameter checking\nprint(\"Accuracy \" +str(metrics.accuracy_score(pred_y.actual,pred_y.predicted)))\nprint(\"Precision \" +str(metrics.precision_score(pred_y.actual,pred_y.predicted)))\nprint(\"Recall \" +str(metrics.recall_score(pred_y.actual,pred_y.predicted)))\nprint(\"ROC AUC \" +str(metrics.roc_auc_score(pred_y.actual,pred_y.predicted)))\nprint(\"f1 score \" +str(metrics.f1_score(pred_y.actual,pred_y.predicted)))\n\n#As we see that Recall score increases rapidly as we balanced the data.","1359f3a1":"#How good the model is\n\npred_prob_y = pd.DataFrame(logreg1.predict_proba(test_x))\npred_prob_y.columns = ['Not Churn','Churn']\npred_prob_y.head()","90ff9983":"predicted = pd.concat([pred_y,pred_prob_y],axis=1)\npredicted","a3362f9f":"#let's Plot graph\n\nsns.distplot(predicted[predicted.actual==0]['Churn'],color='g')\nsns.distplot(predicted[predicted.actual==1]['Churn'],color='r')","dd78d3ce":"auc_score = metrics.roc_auc_score(pred_y.actual,pred_y.predicted)\nauc_score","b75cde83":"#Finding the appropriate cutoff probability\nfpr, tpr, thresholds = metrics.roc_curve( predicted.actual,\n                                     predicted.Churn,\n                                     drop_intermediate = False )\n\nplt.figure(figsize=(6, 4))\nplt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\nplt.plot([0, 1], [0, 1])\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate or [1 - True Negative Rate]')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","c4ecc01a":"print(thresholds[0:10])\nprint(fpr[0:5])\nprint(tpr[0:10])","f1e040da":"cutoff_prob = thresholds[(np.abs(tpr-0.75)).argmin()]\ncutoff_prob","fea5bbd8":"predicted['new_label'] = predicted.Churn.apply(lambda x : 0 if x<0.57 else 1 )","bdfec15c":"predicted","49f37339":"#confusion Matrix\ncm = metrics.confusion_matrix(predicted.actual,predicted.new_label,[1,0])\ncm\nsns.heatmap(cm, annot=True, xticklabels=['churn','not_churn'], yticklabels = ['churn','not_churn'], fmt='.1f')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","9f9d3735":"### Exploratory Analysis","923dabd5":"#### So we can see that there are total 21 variables in which 13 are categorical, 6 are boolean and 2 numericals, 0 missing values. Pandas Profiling Report gives the information about all variables"}}