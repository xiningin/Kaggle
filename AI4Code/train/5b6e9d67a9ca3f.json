{"cell_type":{"17930883":"code","25e4557b":"code","f2f7f061":"code","74413b5c":"code","10136eb0":"code","b945a3a3":"code","9dc835f6":"code","b8152d60":"code","bae4af7e":"code","7f267f54":"code","b4d217ed":"code","914fcf9a":"code","c4c50c68":"code","cd36e623":"code","3294b7a0":"code","a9db516c":"code","cec4bc11":"code","1a3578e2":"code","b62ea101":"code","2b04a141":"code","a0c06d16":"code","36a8f221":"code","3f36bba9":"code","b87abcdc":"code","484319a8":"code","e04a8340":"code","28ed6d7c":"code","1ba1c123":"code","64ac14aa":"code","6db5c926":"code","be723fad":"code","392a62ca":"code","b99917f9":"code","8aac98ee":"code","338a0ff8":"code","0e457bd8":"code","0dbc6a60":"code","903f8b2b":"code","51298518":"code","431c04a5":"code","0606db12":"code","17d74779":"code","16e92629":"markdown","afb9e708":"markdown","c98416d2":"markdown","f302d682":"markdown","1398b78f":"markdown","f69449cd":"markdown","7622248e":"markdown","95344fde":"markdown","6b3f1b0d":"markdown","c84246a1":"markdown","4eb57a54":"markdown","7dd756ac":"markdown","5572c0c1":"markdown","161b8f28":"markdown","26d503ee":"markdown","433123a2":"markdown"},"source":{"17930883":"import io\nimport openpyxl\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","25e4557b":"crime_rate_ds = pd.read_csv('..\/input\/crime-index\/crime_index_by_country.csv', sep=\",\")\neducation_index_ds = pd.read_csv('..\/input\/crime-index\/education_index_by_country.csv', sep=\",\")\nunemployment_rate_ds = pd.read_csv('..\/input\/crime-index\/unemployment_rate_by_country.csv', sep=\",\")\nincome_equality_ds = pd.read_csv('..\/input\/crime-index\/countries_by_income_equality.csv', sep=\",\", encoding= 'unicode_escape')\ngdp_ds = pd.read_csv('..\/input\/crime-index\/countries_by_gpd_(ppp).csv', sep=\",\", encoding= 'unicode_escape')\nlatitude_ds = pd.read_csv('..\/input\/crime-index\/countries_by_latitude.csv', sep=\",\", encoding= 'unicode_escape')\narea_ds = pd.read_csv('..\/input\/crime-index\/countries_by_area.csv', sep=\",\", encoding= 'unicode_escape')\npopulation_ds = pd.read_csv('..\/input\/crime-index\/countries_by_population_(united nations).csv', sep=\",\", encoding= 'unicode_escape')","f2f7f061":"#Checking datasets samples\n\npd.set_option(\"display.max_rows\", 100)\npd.set_option(\"display.max_columns\", 100)\npd.options.display.float_format=\"{:,.2f}\".format\ncrime_rate_ds.sample(n=10, random_state=0)","74413b5c":"education_index_ds.sample(n=10, random_state=0)","10136eb0":"unemployment_rate_ds.sample(n=10, random_state=0)","b945a3a3":"income_equality_ds.sample(n=10, random_state=0)","9dc835f6":"gdp_ds.sample(n=10, random_state=0)","b8152d60":"latitude_ds.sample(n=10, random_state=0)","bae4af7e":"area_ds.sample(n=10, random_state=0)","7f267f54":"population_ds.sample(n=10, random_state=0)","b4d217ed":"#Checking datasets basic statistical data by feature\n\ncrime_rate_ds.describe(include=\"all\")","914fcf9a":"education_index_ds.describe(include=\"all\")","c4c50c68":"unemployment_rate_ds.describe(include=\"all\")","cd36e623":"income_equality_ds.describe(include=\"all\")","3294b7a0":"gdp_ds.describe(include=\"all\")","a9db516c":"latitude_ds.describe(include=\"all\")","cec4bc11":"area_ds.describe(include=\"all\")","1a3578e2":"population_ds.describe(include=\"all\")","b62ea101":"#1\n\njoined1_ds = pd.merge(crime_rate_ds[[\"Country\", \"Crime Index\"]], education_index_ds[[\"Country\",\"Education index\"]], on=\"Country\", how=\"left\")\njoined2_ds = pd.merge(joined1_ds, unemployment_rate_ds[[\"Country\",\"Last\"]], on=\"Country\", how=\"left\")\njoined3_ds = pd.merge(joined2_ds, income_equality_ds[[\"Country\", \"World Bank\u00a0Gini\"]], on=\"Country\", how=\"left\")\njoined4_ds = pd.merge(joined3_ds, gdp_ds[[\"Country\/Territory\", \"(millions of current Int$)\"]], left_on=\"Country\", right_on=\"Country\/Territory\", how=\"left\")\njoined5_ds = pd.merge(joined4_ds, latitude_ds[[\"name\", \"latitude\"]], left_on=\"Country\", right_on=\"name\", how=\"left\")\njoined6_ds = pd.merge(joined5_ds, area_ds[[\"Country\", \"km2\"]], on=\"Country\", how=\"left\")\nfinal_ds = pd.merge(joined6_ds, population_ds[[\"Country\/Territory\", \"Population (2019)\"]], left_on=\"Country\", right_on=\"Country\/Territory\", how=\"left\")\nfinal_ds.drop([\"Country\/Territory_x\", \"Country\/Territory_y\", \"name\"], axis = \"columns\", inplace = True)\nfinal_ds.rename({\"Crime Index\":\"Crime_Index\", \"Education index\":\"Education_Index\", \"Last\":\"Unemployment_Rate\", \"World Bank\u00a0Gini\":\"Gini_Coefficient\", \"(millions of current Int$)\":\"GDP\", \"km2\":\"Area\", \"latitude\":\"Latitude\", \"Population (2019)\":\"Population\"}, axis=1, inplace=True)\n\nfinal_ds","2b04a141":"#2\n\nfinal_ds[\"GDP\"] = final_ds[\"GDP\"].str.replace(',','').astype(float)\nfinal_ds[\"Area\"] = final_ds[\"Area\"].str.replace(',','').astype(float)\nfinal_ds[\"Population\"] = final_ds[\"Population\"].str.replace(',','').astype(float)","a0c06d16":"#3\n\nfinal_ds[\"GDP_per_Capta\"] = final_ds[\"GDP\"] \/ final_ds[\"Population\"]\nfinal_ds[\"Population_Density\"] = final_ds[\"Area\"] \/ final_ds[\"Population\"]\nfinal_ds.reset_index(drop=True) #in ordet to consider in final_ds the new created columns","36a8f221":"#4\n\nfinal_ds[\"Crime_Index_range\"] = np.where(final_ds.Crime_Index>=70, \"70+\", np.where(final_ds.Crime_Index>=60, \"60-70\", np.where(final_ds.Crime_Index>=50, \"50-60\", np.where(final_ds.Crime_Index>=40, \"40-50\", np.where(final_ds.Crime_Index>=30, \"30-40\", np.where(final_ds.Crime_Index>=20, \"20-30\", \"20-\"))))))\nfinal_ds[\"Education_Index_range\"] = np.where(final_ds.Education_Index>=0.9, \"0.9+\", np.where(final_ds.Education_Index>=0.8, \"0.8-0.9\", np.where(final_ds.Education_Index>=0.7, \"0.7-0.8\", np.where(final_ds.Education_Index>=0.6, \"0.6-0.7\", np.where(final_ds.Education_Index>=0.5, \"0.5-0.6\", np.where(final_ds.Education_Index>=0.4, \"0.4-0.5\", \"0.4-\"))))))\nfinal_ds[\"Unemployment_Rate_range\"] = np.where(final_ds.Unemployment_Rate>=30, \"30+\", np.where(final_ds.Unemployment_Rate>=25, \"25-30\", np.where(final_ds.Unemployment_Rate>=20, \"20-25\", np.where(final_ds.Unemployment_Rate>=15, \"15-20\", np.where(final_ds.Unemployment_Rate>=10, \"10-15\", np.where(final_ds.Unemployment_Rate>=5, \"5-10\", \"5-\"))))))\nfinal_ds[\"Gini_Coefficient_range\"] = np.where(final_ds.Gini_Coefficient>=60, \"60+\", np.where(final_ds.Gini_Coefficient>=50, \"50-60\", np.where(final_ds.Gini_Coefficient>=40, \"40-50\", np.where(final_ds.Gini_Coefficient>=30, \"30-40\", np.where(final_ds.Gini_Coefficient>=20, \"20-30\", np.where(final_ds.Gini_Coefficient>=10, \"10-20\", \"10-\"))))))\nfinal_ds[\"Latitude_range\"] = np.where(final_ds.Latitude>=60, \"60+\", np.where(final_ds.Latitude>=50, \"50-60\", np.where(final_ds.Latitude>=40, \"40-50\", np.where(final_ds.Latitude>=30, \"30-40\", np.where(final_ds.Latitude>=20, \"20-30\", np.where(final_ds.Latitude>=10, \"10-20\", \"10-\"))))))\nfinal_ds[\"GDP_per_Capta_range\"] = np.where(final_ds.GDP_per_Capta>=0.1, \"0.1+\", np.where(final_ds.GDP_per_Capta>=0.08, \"0.08-0.1\", np.where(final_ds.GDP_per_Capta>=0.06, \"0.06-0.08\", np.where(final_ds.GDP_per_Capta>=0.04, \"0.04-0.06\", np.where(final_ds.GDP_per_Capta>=0.02, \"0.02-0.04\", np.where(final_ds.GDP_per_Capta>=0.01, \"0.01-0.02\", \"0.01-\"))))))\nfinal_ds[\"Population_Density_range\"] = np.where(final_ds.Population_Density>=0.45, \"0.45+\", np.where(final_ds.Population_Density>=0.4, \"0.4-0.45\", np.where(final_ds.Population_Density>=0.35, \"0.35-0.4\", np.where(final_ds.Population_Density>=0.3, \"0.3-0.35\", np.where(final_ds.Population_Density>=0.25, \"0.25-0.3\", np.where(final_ds.Population_Density>=0.1, \"0.1-0.25\", \"0.1-\"))))))","3f36bba9":"#5\n\nfinal_ds[\"Latitude\"] = abs(final_ds[\"Latitude\"])","b87abcdc":"#6\n\nfinal_ds.dropna(inplace=True)","484319a8":"#7\n\nfinal_ds.sort_values(by=[\"Country\"], inplace=True)\n\nfinal_ds.to_excel(\"final_ds_clean.xlsx\")","e04a8340":"#Checking a dataset sample\n\npd.set_option(\"display.max_rows\", 100)\npd.set_option(\"display.max_columns\", 100)\nfinal_ds.sample(n=10, random_state=0)","28ed6d7c":"#Checking dataset info by feature\n\nfinal_ds.info(verbose=True, null_counts=True)","1ba1c123":"#Checking the existence of zeros in rows\n\n(final_ds==0).sum(axis=0).to_excel(\"zeros_per_feature.xlsx\")\n(final_ds==0).sum(axis=0)","64ac14aa":"#Checking the existence of duplicated rows\n\nfinal_ds.duplicated().sum()","6db5c926":"#Checking basic statistical data by feature\n\npd.options.display.float_format=\"{:,.2f}\".format\nfinal_ds.describe(include=\"all\")","be723fad":"#Plotting Numerical Variables\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"Crime Index Distribution\", fontsize=15)\nsns.distplot(final_ds[\"Crime_Index\"], ax=ax[0])\nsns.boxplot(final_ds[\"Crime_Index\"], ax=ax[1])\nsns.violinplot(final_ds[\"Crime_Index\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"Education Index Distribution\", fontsize=15)\nsns.distplot(final_ds[\"Education_Index\"], ax=ax[0])\nsns.boxplot(final_ds[\"Education_Index\"], ax=ax[1])\nsns.violinplot(final_ds[\"Education_Index\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"Unemployment Rate Distribution\", fontsize=15)\nsns.distplot(final_ds[\"Unemployment_Rate\"], ax=ax[0])\nsns.boxplot(final_ds[\"Unemployment_Rate\"], ax=ax[1])\nsns.violinplot(final_ds[\"Unemployment_Rate\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"Gini Coefficient Distribution\", fontsize=15)\nsns.distplot(final_ds[\"Gini_Coefficient\"], ax=ax[0])\nsns.boxplot(final_ds[\"Gini_Coefficient\"], ax=ax[1])\nsns.violinplot(final_ds[\"Gini_Coefficient\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"GDP Distribution\", fontsize=15)\nsns.distplot(final_ds[\"GDP\"], ax=ax[0])\nsns.boxplot(final_ds[\"GDP\"], ax=ax[1])\nsns.violinplot(final_ds[\"GDP\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"Latitude Distribution\", fontsize=15)\nsns.distplot(final_ds[\"Latitude\"], ax=ax[0])\nsns.boxplot(final_ds[\"Latitude\"], ax=ax[1])\nsns.violinplot(final_ds[\"Latitude\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"Area Distribution\", fontsize=15)\nsns.distplot(final_ds[\"Area\"], ax=ax[0])\nsns.boxplot(final_ds[\"Area\"], ax=ax[1])\nsns.violinplot(final_ds[\"Area\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"Population Distribution\", fontsize=15)\nsns.distplot(final_ds[\"Population\"], ax=ax[0])\nsns.boxplot(final_ds[\"Population\"], ax=ax[1])\nsns.violinplot(final_ds[\"Population\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"GDP per Capta Distribution\", fontsize=15)\nsns.distplot(final_ds[\"GDP_per_Capta\"], ax=ax[0])\nsns.boxplot(final_ds[\"GDP_per_Capta\"], ax=ax[1])\nsns.violinplot(final_ds[\"GDP_per_Capta\"], ax=ax[2])\n\nfig, ax = plt.subplots(1,3)\nfig.suptitle(\"Population Density Distribution\", fontsize=15)\nsns.distplot(final_ds[\"Population_Density\"], ax=ax[0])\nsns.boxplot(final_ds[\"Population_Density\"], ax=ax[1])\nsns.violinplot(final_ds[\"Population_Density\"], ax=ax[2])","392a62ca":"# Visualizing Crime Rate by country\n\nplotly_country_codes = pd.read_csv('..\/input\/crime-index\/plotly_countries_and_codes.csv', sep=\",\")\nfinal_plotly_ds = pd.merge(final_ds, plotly_country_codes[[\"COUNTRY\", \"CODE\"]], left_on=\"Country\", right_on=\"COUNTRY\", how=\"left\")\n\nimport plotly.express as px\nfig = px.choropleth(final_plotly_ds, locations=\"CODE\",\n                    color=\"Crime_Index\",\n                    hover_name=\"Country\",\n                    color_continuous_scale=px.colors.sequential.Plasma)\nfig.show()","b99917f9":"#Alternatively using Profile Report to see variables statistics and correlations\n\n# from pandas_profiling import ProfileReport\n# profile = ProfileReport(final_ds, title=\"Crime Index\")\n# profile.to_file(output_file=\"Crime_Index.html\")","8aac98ee":"#Plotting Bar Charts, also considering all numerical to categorical variables created before\n\nfig, axarr = plt.subplots(2, 3, figsize=(20, 12))\nsns.countplot(x=\"Education_Index_range\", hue=\"Crime_Index_range\", data=final_ds, ax=axarr[0][0])\nsns.countplot(x=\"Unemployment_Rate_range\", hue=\"Crime_Index_range\", data=final_ds, ax=axarr[0][1])\nsns.countplot(x=\"Gini_Coefficient_range\", hue=\"Crime_Index_range\", data=final_ds, ax=axarr[0][2])\nsns.countplot(x=\"Latitude_range\", hue=\"Crime_Index_range\", data=final_ds, ax=axarr[1][0])\nsns.countplot(x=\"GDP_per_Capta_range\", hue=\"Crime_Index_range\", data=final_ds, ax=axarr[1][1])\nsns.countplot(x=\"Population_Density_range\", hue=\"Crime_Index_range\", data=final_ds, ax=axarr[1][2])\n\n#Deleting original categorical columns\n\nfinal_ds.drop([\"Country\", \"Crime_Index_range\", \"Education_Index_range\", \"Unemployment_Rate_range\", \"Gini_Coefficient_range\", \"Latitude_range\", \"GDP_per_Capta_range\", \"Population_Density_range\"], axis=1, inplace=True)\n\n#Plotting a Heatmap\n\nfig, ax = plt.subplots(1, figsize=(25,25))\nsns.heatmap(final_ds.corr(), annot=True, fmt=\",.2f\")\nplt.title(\"Heatmap Correlation\", fontsize=20)\nplt.tick_params(labelsize=12)\nplt.xticks(rotation=90)\nplt.yticks(rotation=45)\n\n#Plotting a Pairplot\n\nsns.pairplot(final_ds)","338a0ff8":"#Plotting a Feature Importance\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom matplotlib import pyplot\n#Defining Xs and y\nX = final_ds.drop([\"Crime_Index\"], axis=1)\ny = final_ds[\"Crime_Index\"]\n#Defining the model\nmodel = RandomForestRegressor().fit(X, y)\n#Getting importance\nimportance = model.feature_importances_\n#Summarizing feature importance\nfor i,v in enumerate(importance):\n    print(\"Feature:{0:} - Score:{1:,.4f}\".format(X.columns[i], v))\n#Plotting feature importance\npd.Series(model.feature_importances_[::-1], index=X.columns[::-1]).plot.barh(figsize=(25,25))","0e457bd8":"#Defining Xs and y\n\nX = final_ds[[\"Latitude\", \"Gini_Coefficient\", \"GDP_per_Capta\", \"Education_Index\", \"Population_Density\", \"Unemployment_Rate\"]]\ny = final_ds[[\"Crime_Index\"]]\n\n#Scaling all features\n\nfrom sklearn.preprocessing import MinMaxScaler\nsc_X = MinMaxScaler()\nX_scaled = sc_X.fit_transform(X)\nX_scaled = pd.DataFrame(X_scaled)\n\n#Setting train\/test split\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=0)","0dbc6a60":"#Creating a Polynomial Regression model and checking its Metrics\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n\n#Creating a Linear Regressor\nlin_regressor = LinearRegression()\n\n#Trying different polynomial degrees\ndegrees = [1, 2, 3, 4, 5]\nprint(\"Testing degrees:\")\nfor a in degrees:\n    poly = PolynomialFeatures(degree=a)\n    X_train_degree = poly.fit_transform(X_train)\n    X_test_degree = poly.fit_transform(X_test)\n    model_pr = lin_regressor.fit(X_train_degree, y_train)\n    y_preds_train = model_pr.predict(X_train_degree)\n    y_preds_test = model_pr.predict(X_test_degree)\n    score_train = r2_score(y_train, y_preds_train)\n    score_test = r2_score(y_test, y_preds_test)\n    mse_train = mean_squared_error(y_train, y_preds_train)\n    mse_test = mean_squared_error(y_test, y_preds_test)\n    print(\"Train: Degree:{0:,.0f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a, score_train, mse_train, np.sqrt(mse_train)))\n    print(\"Test : Degree:{0:,.0f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a, score_test, mse_test, np.sqrt(mse_test)))       \nprint(\"\")\n\n#Choosing the best polynomial degree\nchosen_degree = 1\npoly = PolynomialFeatures(degree=chosen_degree)\n\n#Working on X_train & X_test in the polynomial chosen degree\nX_train_degree = poly.fit_transform(X_train)\nX_test_degree = poly.fit_transform(X_test)\n\n#Fitting to the Linear Regressor\nmodel_pr = lin_regressor.fit(X_train_degree, y_train)\nprint(f\"Linear Regression Intercept: {model_pr.intercept_}\")\nprint(f\"Linear Regression Coefficients: {model_pr.coef_}, \\n\")\n\n#Getting the predictions & Metrics\ny_preds_train = model_pr.predict(X_train_degree)\ny_preds_test = model_pr.predict(X_test_degree)\nscore_train = r2_score(y_train, y_preds_train)\nscore_test = r2_score(y_test, y_preds_test)\nmse_train = mean_squared_error(y_train, y_preds_train)\nmse_test = mean_squared_error(y_test, y_preds_test)\nprint(\"Chosen degree:\")\nprint(\"Train: Degree:{0:,.0f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(chosen_degree, score_train, mse_train, np.sqrt(mse_train)))\nprint(\"Test : Degree:{0:,.0f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(chosen_degree, score_test, mse_test, np.sqrt(mse_test)))   \n\n#Visualizing y_pred in the dataset\nX_degree = poly.fit_transform(X_scaled)\ny_pred_all = model_pr.predict(X_degree)\nfinal_ds[\"Crime_Index_predicted\"] = y_pred_all\nfinal_ds.to_excel(\"model_pr.xlsx\")","903f8b2b":"#Creating a Ridge Regression model and checking its Metrics\n\nfrom sklearn.linear_model import Ridge\n\n#Trying different alphas\nalphas = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\nprint(\"Testing alphas:\")\nfor a in alphas:\n    model_ridge = Ridge(alpha=a, normalize=True).fit(X_train, y_train) \n    y_preds_train = model_ridge.predict(X_train)\n    y_preds_test = model_ridge.predict(X_test)\n    score_train = r2_score(y_train, y_preds_train)\n    score_test = r2_score(y_test, y_preds_test)\n    mse_train = mean_squared_error(y_train, y_preds_train)\n    mse_test = mean_squared_error(y_test, y_preds_test)\n    print(\"Train: Alpha:{0:,.6f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a, score_train, mse_train, np.sqrt(mse_train)))\n    print(\"Test : Alpha:{0:,.6f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a, score_test, mse_test, np.sqrt(mse_test)))\nprint(\"\")\n\n#Choosing the best alpha\na_final = 0.4\nmodel_ridge = Ridge(alpha=a_final, normalize=True).fit(X_train, y_train) \ny_preds_train = model_ridge.predict(X_train)\ny_preds_test = model_ridge.predict(X_test)\nscore_train = r2_score(y_train, y_preds_train)\nscore_test = r2_score(y_test, y_preds_test)\nmse_train = mean_squared_error(y_train, y_preds_train)\nmse_test = mean_squared_error(y_test, y_preds_test)\nprint(f\"Linear Regression Intercept: {model_ridge.intercept_}\")\nprint(f\"Linear Regression Coefficients: {model_ridge.coef_}, \\n\")\nprint(\"Chosen alpha:\")\nprint(\"Train: Alpha:{0:,.6f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a_final, score_train, mse_train, np.sqrt(mse_train)))\nprint(\"Test : Aplha:{0:,.6f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a_final, score_test, mse_test, np.sqrt(mse_test)))\n\n#Plotting\nx_ax = range(len(X_test))\nplt.scatter(x_ax, y_test, s=5, color=\"blue\", label=\"original\")\nplt.plot(x_ax, y_preds_test, lw=0.8, color=\"red\", label=\"predicted\")\nplt.legend()\n\n#Visualizing y_pred in the dataset\ny_pred_all = model_ridge.predict(X_scaled)\nfinal_ds[\"Crime_Index_predicted\"] = y_pred_all\nfinal_ds.to_excel(\"model_ridge.xlsx\")","51298518":"#Creating a Lasso Regression model and checking its Metrics\n\nfrom sklearn.linear_model import Lasso\n\n#Trying different alphas\nalphas = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\nprint(\"Testing alphas:\")\nfor a in alphas:\n    model_lasso = Lasso(alpha=a, normalize=True).fit(X_train,y_train) \n    y_preds_train = model_lasso.predict(X_train)\n    y_preds_test = model_lasso.predict(X_test)\n    score_train = r2_score(y_train, y_preds_train)\n    score_test = r2_score(y_test, y_preds_test)\n    mse_train = mean_squared_error(y_train, y_preds_train)\n    mse_test = mean_squared_error(y_test, y_preds_test)\n    print(\"Train: Alpha:{0:,.6f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a, score_train, mse_train, np.sqrt(mse_train)))\n    print(\"Test : Alpha:{0:,.6f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a, score_test, mse_test, np.sqrt(mse_test)))\nprint(\"\")\n\n#Choosing the best alpha\na_final = 0.1\nmodel_lasso = Lasso(alpha=a_final, normalize=True).fit(X_train,y_train) \ny_preds_train = model_lasso.predict(X_train)\ny_preds_test = model_lasso.predict(X_test)\nscore_train = r2_score(y_train, y_preds_train)\nscore_test = r2_score(y_test, y_preds_test)\nmse_train = mean_squared_error(y_train, y_preds_train)\nmse_test = mean_squared_error(y_test, y_preds_test)\nprint(f\"Linear Regression Intercept: {model_lasso.intercept_}\")\nprint(f\"Linear Regression Coefficients: {model_lasso.coef_}, \\n\")\nprint(\"Chosen alpha:\")\nprint(\"Train: Alpha:{0:,.6f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a_final, score_train, mse_train, np.sqrt(mse_train)))\nprint(\"Test : Aplha:{0:,.6f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a_final, score_test, mse_test, np.sqrt(mse_test)))\n\n#Plotting\nx_ax = range(len(X_test))\nplt.scatter(x_ax, y_test, s=5, color=\"blue\", label=\"original\")\nplt.plot(x_ax, y_preds_test, lw=0.8, color=\"red\", label=\"predicted\")\nplt.legend()\n\n#Visualizing y_pred in the dataset\ny_pred_all = model_lasso.predict(X_scaled)\nfinal_ds[\"Crime_Index_predicted\"] = y_pred_all\nfinal_ds.to_excel(\"model_lasso.xlsx\")","431c04a5":"#Creating a XGBoost Regression model and checking its Metrics\n\nfrom xgboost import XGBRegressor\n\n#Trying different depths\ndepths = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nprint(\"Testing depths:\")\nfor a in depths:\n    model_xgb = XGBRegressor(max_depth=a, random_state=0).fit(X_train,y_train) \n    y_preds_train = model_xgb.predict(X_train)\n    y_preds_test = model_xgb.predict(X_test)\n    score_train = r2_score(y_train, y_preds_train)\n    score_test = r2_score(y_test, y_preds_test)\n    mse_train = mean_squared_error(y_train, y_preds_train)\n    mse_test = mean_squared_error(y_test, y_preds_test)\n    print(\"Train: Depth:{0:,.0f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a, score_train, mse_train, np.sqrt(mse_train)))\n    print(\"Test : Depth:{0:,.0f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a, score_test, mse_test, np.sqrt(mse_test)))\nprint(\"\")\n\n#Choosing the best depth\na_final = 5\nmodel_xgb = XGBRegressor(max_depth=a_final, random_state=0).fit(X_train,y_train) \ny_preds_train = model_xgb.predict(X_train)\ny_preds_test = model_xgb.predict(X_test)\nscore_train = r2_score(y_train, y_preds_train)\nscore_test = r2_score(y_test, y_preds_test)\nmse_train = mean_squared_error(y_train, y_preds_train)\nmse_test = mean_squared_error(y_test, y_preds_test)\nprint(\"Chosen depth:\")\nprint(\"Train: Depth:{0:,.0f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a_final, score_train, mse_train, np.sqrt(mse_train)))\nprint(\"Test : Depth:{0:,.0f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(a_final, score_test, mse_test, np.sqrt(mse_test)))\n\n#Plotting\nx_ax = range(len(X_test))\nplt.scatter(x_ax, y_test, s=5, color=\"blue\", label=\"original\")\nplt.plot(x_ax, y_preds_test, lw=0.8, color=\"red\", label=\"predicted\")\nplt.legend()\n\n#Visualizing y_pred in the dataset\ny_pred_all = model_xgb.predict(X_scaled)\nfinal_ds[\"Crime_Index_predicted\"] = y_pred_all\nfinal_ds.to_excel(\"model_xgb.xlsx\")","0606db12":"#Creating a Deep Learning Regression model and checking its Metrics\n\nfrom keras import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\n\n#Creating a model\nmodel_dl = Sequential()\n\n#Input and First Hidden Layer\nmodel_dl.add(Dense(units=256, activation=\"relu\", input_dim=X_train.shape[1]))\n#Second Hidden Layer\nmodel_dl.add(Dense(units=256, activation=\"relu\"))\n#Third Hidden Layer\nmodel_dl.add(Dense(units=256, activation=\"relu\"))\n#Output Layer\nmodel_dl.add(Dense(units=1))\n\n#Compiling the neural network\nmodel_dl.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n\n#Fitting to the model\nmodel_dl.fit(X_train,y_train, callbacks=[EarlyStopping(patience=10),ReduceLROnPlateau(monitor=\"val_loss\",min_lr=0.01)], epochs=60)\n\n#Getting the predictions & Metrics\ny_preds_train = model_dl.predict(X_train)\ny_preds_test = model_dl.predict(X_test)\nscore_train = r2_score(y_train, y_preds_train)\nscore_test = r2_score(y_test, y_preds_test)\nmse_train = mean_squared_error(y_train, y_preds_train)\nmse_test = mean_squared_error(y_test, y_preds_test)\nprint(\"Train: R2:{0:,.3f}, MSE:{1:,.2f}, RMSE:{2:,.2f}\".format(score_train, mse_train, np.sqrt(mse_train)))\nprint(\"Test : R2:{0:,.3f}, MSE:{1:,.2f}, RMSE:{2:,.2f}\".format(score_test, mse_test, np.sqrt(mse_test)))\n\n#Plotting\nx_ax = range(len(X_test))\nplt.scatter(x_ax, y_test, s=5, color=\"blue\", label=\"original\")\nplt.plot(x_ax, y_preds_test, lw=0.8, color=\"red\", label=\"predicted\")\nplt.legend()\n\n#Visualizing y_pred in the dataset\ny_pred_all = model_dl.predict(X_scaled)\nfinal_ds[\"Crime_Index_predicted\"] = y_pred_all\nfinal_ds.to_excel(\"model_dl.xlsx\")","17d74779":"#Entering Xs\n\n# lat = float(input(\"Enter the Latitude: \"))\n# gini_coef = float(input(\"Enter the Gini Coefficient: \"))\n# gdp_capta = float(input(\"Enter the GDP per Capta: \"))\n# educ_index = float(input(\"Enter the Education Index: \"))\n# pop_dens = float(input(\"Enter the Population Density: \"))\n# unemp_rate = float(input(\"Enter the Unemployment rate (%): \"))\n\n#Defining Xs\n\n# X_mod_dep = pd.DataFrame({\"Latitude\": [lat], \"Gini_Coefficient\": [gini_coef], \"GDP_per_Capta\": [gdp_capta], \"Education_Index\": [educ_index], \"Population_Density\": [pop_dens], \"Unemployment_Rate\": [unemp_rate]})\n#Example for Canada\nX_mod_dep = pd.DataFrame({\"Latitude\": [56.13], \"Gini_Coefficient\": [33.8], \"GDP_per_Capta\": [0.051], \"Education_Index\": [0.89], \"Population_Density\": [0.266], \"Unemployment_Rate\": [8.9]})\n\n#Appending X_mod_dep to original X dataframe, so we can scale it all together next\n\nX_with_X_mode_dep = X.append(X_mod_dep)\n\n#Scaling all features\n\nfrom sklearn.preprocessing import MinMaxScaler\nsc_X = MinMaxScaler()\nX_scaled = sc_X.fit_transform(X_with_X_mode_dep)\nX_scaled = pd.DataFrame(X_scaled)\n\n#Recovering X_mod_dep row in dataframe after scaling\n\nX_mod_dep = X_scaled.tail(1)\n\n#Predicting results\n\nprint(f\"Predicted Crime Index = {model_dl.predict(X_mod_dep)}.\")","16e92629":"# 4. Data Preliminary Exploration","afb9e708":"# 9.1 Polynomial Regression","c98416d2":"# 9. Machine Learning Algorithms Implementation & Assessment","f302d682":"# 3. Data Collection","1398b78f":"# 2. Importing basic libraries","f69449cd":"# 7. Correlations Analysis & Features Selection","7622248e":"# 11. Conclusions\n\nIF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!\n\nIn this project we went through all the process from defining the objective, collecting data, exploring features and distributions, treating data, understanding correlations, selecting relevant features, data modelling and presenting 5 different algorithms with metrics to select the best to predict the Crime Index to analyze. The most correlated variable to Crime Index is the Gini Index, showing how imporant is for a country the wealth equality, followed by Latitude, Education Index, GDP per Capta and Unemployment Rate. The chosen model was Deep Learning for bringing the lowest prediction error (R2 around 48%), altough it\u00b4s still very high and we\u00b4d need more data to build a more accurate model. The idea next is building a dataset by City, so we could have more data to train the model.","95344fde":"# 10. Model Deployment","6b3f1b0d":"# 9.5 Deep Learning Regression","c84246a1":"# 9.4 XGBoost Regression","4eb57a54":"# 9.3 Lasso Regression","7dd756ac":"# 5. Data Preparation\n\n    We\u00b4ll perform the following:\n\n    1. Join all datasets, bringing only selected columns and renaming some of them to more intuitive names\n\n\n    2. Remove all \",\" in numeric fields and change them to float (we need to remove \",\" for thousands separation so Python can understand it as numeric)\n\n\n    3. Create calculated columns (\"GDP per Capta\" and \"Population Density\")\n\n\n\n    4. Convert numerical variables to categorical ranges:    \n        * 4.1 Crime Index\n        * 4.2 Education Index\n        * 4.3 Unemployment Rate (%)\n        * 4.4 Gini Coefficient\n        * 4.5 Latitude\n        * 4.6 GDP per Capta\n        * 4.7 Population Density\n\n\n    5. Change Latitude to absolute values (it only matters to us the absolute distance to Earths\u00b4s Equator)\n\n\n    6. Drop all remaining null rows\n\n\n    7. Sort final dataset by Country\n\n\n    * No duplicated rows found\n    * No outliers found","5572c0c1":"# 9.2 Ridge Regression","161b8f28":"# 8. Data Modelling","26d503ee":"# 6. Data Exploration","433123a2":"# 1. Introduction: Business Goal & Problem Definition\n\nThe goal of this project is to study and predict the Crime Index by country by analyzing the variables below. Have you always been curious on how facts about Education, Unemployment, Income Equality, GDP per capta, Popupation density and even Latitude can affect how violent a country can be? So please stay with me on this project and let\u00b4s check it out together :-)\n\nIF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!\n\n* Education Index - source: Human Development Index (https:\/\/en.wikipedia.org\/wiki\/Education_Index)\n* Unemployment Rate - source: Trading Economics (https:\/\/tradingeconomics.com\/country-list\/unemployment-rate)\n* Income Equality - source: World Bank Gini (https:\/\/en.wikipedia.org\/wiki\/List_of_countries_by_income_equality)\n* GDP (Gross Domestic Product) PPP (Purchasing Power Parity) - source: World Bank (https:\/\/en.wikipedia.org\/wiki\/List_of_countries_by_GDP_(PPP))\n* Latitude Average - source: Google dataset (https:\/\/developers.google.com\/public-data\/docs\/canonical\/countries_csv)\n* Area - source: United Nations Statistics Division (https:\/\/simple.wikipedia.org\/wiki\/List_of_countries_by_area)\n* Population - source: United Nations Statistics Division (https:\/\/en.wikipedia.org\/wiki\/List_of_countries_by_population_(United_Nations))\n* Per capita gross domestic product (GDP): it will be calculated\n* Population density: it will be calculated\n* -> The Crime Index datased can be found in https:\/\/www.numbeo.com\/crime\/rankings_by_country.jsp"}}