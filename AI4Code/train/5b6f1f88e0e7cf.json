{"cell_type":{"be9600dc":"code","14ad8125":"code","c6d604aa":"code","3745ce92":"code","0b1da7d5":"code","c1d85731":"code","d71e37b0":"code","08c9a68b":"code","32495798":"code","796988c5":"code","38237379":"code","f81622e2":"code","08e075c9":"code","aa1fde13":"code","8e202f0e":"code","e687ae39":"code","3d9786bc":"code","21f12219":"code","44b4941a":"code","fe6f313a":"code","41513814":"code","061e804e":"code","4a8c8527":"code","c5f95728":"code","c28267a0":"code","90da8258":"code","f13a77cd":"code","b8c634f5":"code","fa3e4237":"code","765e3588":"code","42da6a25":"code","79cbf84a":"code","ef4927a6":"code","dfb7242c":"code","d4437128":"code","48c8fca7":"code","2712a4f1":"code","62f56d95":"code","9647d9e6":"code","9c1c3865":"code","998906e5":"code","3cca3830":"markdown","dc758207":"markdown","04fabdd6":"markdown","6bc46e9d":"markdown","b2d38fa8":"markdown","1f5d4b11":"markdown","0ac5f69e":"markdown","a5c365fe":"markdown","28affa62":"markdown","eb3db34c":"markdown","8b7bbd71":"markdown","16359e89":"markdown","ea4217f8":"markdown","b076039c":"markdown","06ec6374":"markdown","bcaded23":"markdown","58b4c4e2":"markdown","c5f42472":"markdown","0dcc1d0f":"markdown","a9a99073":"markdown","1b904193":"markdown","1986fd69":"markdown","a7855d18":"markdown","b1609ab0":"markdown","9969e413":"markdown","4d4feb52":"markdown","61e8abf8":"markdown","a8109af8":"markdown","63670331":"markdown","8b6556a7":"markdown","af4da3ec":"markdown","067fc52d":"markdown","a5d3bce1":"markdown","5a75e0ae":"markdown","80c1680c":"markdown","c82fe2ec":"markdown","8a310ec3":"markdown","f6993cb8":"markdown","1352e39e":"markdown","cf5881a6":"markdown","8d70d85f":"markdown","4db45dca":"markdown","1305133f":"markdown","ba9187be":"markdown","e3ca0d29":"markdown","ba0fe326":"markdown","2536513b":"markdown","76278d68":"markdown","291722ce":"markdown","afdffd36":"markdown"},"source":{"be9600dc":"pip install openpyxl","14ad8125":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c6d604aa":"df = pd.read_excel('\/kaggle\/input\/dry-bean-dataset-uci\/Dry_Bean_Dataset.xlsx')\ndf.head()","3745ce92":"df.dtypes","0b1da7d5":"df.isnull().sum()","c1d85731":"sns.boxplot(x=\"Class\", y=\"Perimeter\", data=df)","d71e37b0":"sns.boxplot(x=\"Class\", y=\"ConvexArea\", data=df)","08c9a68b":"selected_features = list(df.columns)[0:6]","32495798":"df[selected_features]","796988c5":"sm = pd.plotting.scatter_matrix(df[selected_features], figsize=(20,20))","38237379":"df['Class'].value_counts()","f81622e2":"from sklearn.model_selection import train_test_split","08e075c9":"df.iloc[:,df.columns != \"Class\"].shape","aa1fde13":"df[\"Class\"].shape","8e202f0e":"X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,df.columns != \"Class\"], \n                                                    df[\"Class\"],\n                                                    test_size=0.2, random_state=42)    ","e687ae39":"X_train.shape[0],X_test.shape[0]","3d9786bc":"X_train.describe()","21f12219":"from sklearn.preprocessing import StandardScaler","44b4941a":"sd_scaler = StandardScaler()","fe6f313a":"X_train_sd = sd_scaler.fit_transform(X_train)\nX_test_sd = sd_scaler.transform(X_test)","41513814":"X_train_sd_df = pd.DataFrame(X_train_sd,\n                          index=X_train.index,\n                          columns= X_train.columns)","061e804e":"X_train_sd_df.describe()","4a8c8527":"from sklearn.svm import SVC","c5f95728":"svc = SVC(C=1.0,kernel='rbf',gamma='auto')","c28267a0":"svc.fit(X_train_sd,y_train)","90da8258":"from sklearn.pipeline import Pipeline","f13a77cd":"svc_rbf = Pipeline([\n(\"scaler\", StandardScaler()),\n(\"svc_rbf\",SVC(C=1.0,kernel='rbf',gamma='auto') )])","b8c634f5":"svc_rbf.fit(X_train,y_train)","fa3e4237":"from sklearn.linear_model import SGDClassifier","765e3588":"sgdc = SGDClassifier()\nsgdc.fit(X_train_sd,y_train)","42da6a25":"from sklearn.metrics import confusion_matrix, plot_confusion_matrix","79cbf84a":"plt.rcParams[\"figure.figsize\"] = (7,7)\nplot_confusion_matrix(svc,X_test_sd,y_test)","ef4927a6":"plt.rcParams[\"figure.figsize\"] = (6,6)\nplot_confusion_matrix(sgdc,X_test_sd,y_test)","dfb7242c":"round(svc.score(X_test_sd,y_test) *100)","d4437128":"round(sgdc.score(X_test_sd,y_test) * 100)","48c8fca7":"from sklearn.metrics import f1_score","2712a4f1":"print('f1 score for SVC')\nround(f1_score(y_test,svc.predict(X_test_sd),average='weighted'),3)","62f56d95":"print('f1 score for SGDC')\nround(f1_score(y_test,sgdc.predict(X_test_sd),average='weighted'),3)","9647d9e6":"from sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_val_score\nimport random\n\nrandom.seed(1)","9c1c3865":"svc_rbf = make_pipeline( StandardScaler(),\n                        SVC(C=1.0,kernel='rbf',gamma='auto') )\nsvc_cv_score = cross_val_score(svc_rbf, df.iloc[:,df.columns != \"Class\"], df[\"Class\"], cv=10)\nprint('Cross validation score for support vector classifier',round(svc_cv_score.mean()*100,3))\n","998906e5":"sgdc_cv = make_pipeline( StandardScaler(),\n                        SGDClassifier() )\nsgdc_cv_score = cross_val_score(sgdc_cv, df.iloc[:,df.columns != \"Class\"], df[\"Class\"], cv=10)\n\nprint('Cross validation score for support vector classifier',round(sgdc_cv_score.mean()*100,3))\n","3cca3830":"The diagonal number is the number of correct classification, which from 240 to 481.\n\nFor Barbunya, SVC classified 240 labels correctly, where 14, 1 and 6 as Casli, Seker and Sira respectively.\n\nFor Bombay, surprisingly, all the classification was right. Notice that Bombay has the *lowest amount of data*, it might the reason we got such high accuracy in this class.\n\nFor Cali, SVC classified 300 labels correctly, where 11, 4,1 and 6 as Barbunya, Horoz, Seker and Sira respectively.\n\nFor Dermanson, which has the largest number of instances and 621 instances in total. And hence, the model wrongly predicted 44 instances as Sira, which is a quite hight number, and 6 instances as Seker.\n\nFor Horoz, there are 2,5,4,6 instances wrongly predicted as Barbunya, Cali, Dermason and Sira respectively. And, 391 instances are predicted correctly.\n\nFor Seker, there are 3,9,8 instances wrongly predicted as Barbunya, Dermason and Sira respectively. And, 393 instances are predicted correctly.\n\nFor Sira, there are 1,45,5,4 instances wrongly predicted as Barbunya, Dermason, Horoz, Seker respectively. And, 481 instances are predicted correctly.","dc758207":"The training set has 10888 instances, whereas there are 2723 instances in the test set.","04fabdd6":"Scatter matrix by 'Area', 'Perimeter','MajorAxisLength', 'MinorAxisLength', 'AspectRation' and 'Eccentricity'.","6bc46e9d":"The diagonal number is the number of correct classification, which from 231 to 465.\n\nFor Barbunya, SGDC classified 231 labels correctly, where 17, 2,1 and 10 as Casli,horoz, Seker and Sira respectively.\n\nFor Bombay, surprisingly, all the classification was right, *same as the SVC model*. \n\nFor Cali, SGDC classified 301 labels correctly,*(slightly higher than SVC)*, where 7,5 and 4 as Barbunya, Horoz and Sira respectively.\n\nFor Dermanson, which has the largest number of instances and 598 instances in total.*(Smaller than SVC)* And hence, the model wrongly predicts 59 instances as Sira, which is a quite hight number and *higher than the number in SVC*, and 13 instances as Seker, and 1 as Horoz.\n\nFor Horoz, there are 2,8 and 5 instances wrongly predicted as Cali, Dermason and Sira respectively. And, 393 instances are predicted correctly.\n\nFor Seker, there are 5,5,10 instances wrongly predicted as Barbunya, Dermason and Sira respectively. And, 393 instances are predicted correctly.\n\nFor Sira, there are 1,1,56,8,5 instances wrongly predicted as Barbunya, Cali,Dermason, Horoz, Seker respectively. And, 481 instances are predicted correctly.","b2d38fa8":"1. Inspect whether difference on classes would affects perimeter and convex area of the bean.\n\nThe graph below shows that Bombay has the highest perimeter and convex area. \n\nThe perimeters are different across class of bean.","1f5d4b11":"After fit_trainsform ,the data frame will become an array.\n\nConsidering reability, we convert the array back to a data frame.","0ac5f69e":"Now, we read the data set and display the first 5 rows by using head. ","a5c365fe":"AS we can see from the above results, SVC performs slightly better than sgdc.\n\nAnd hence, the confusion matrix shows that SVM misclassifies 44 HOROZ as BARBUNYA.","28affa62":"* SGDClassifier ","eb3db34c":"C=1.0 means we are using l2 regularization. Value of coefficents for the hyperplane can be zero. In fact, it is doing feature extraction by reducting the dimensions. L2-SVM is differentiable and imposes a bigger loss for points which violate the margin. \n\nGamma acts like a regularization hyperparameter, using auto to avoid manual setting and overfitting and underfitting.\n\nUsing rbf to do non-linearly separate. The decision boundary might not be linearly separable. RBF kernel is a function whose value depends on the distance from the origin or from some point. And hence, one good reason to use RBF kernel are that they work well in practice and they are relatively easy to calibrate, as opposed to other kernels.","8b7bbd71":"*Compare by f1 score*","16359e89":"Dermason has the highest number.","ea4217f8":"Classification Task Example","b076039c":"Both Models made similar mistake. When predicting Dermason and Sira, both models classify most of the labels correctly, but there are a significant amount of labels that were wrongly classified as Sira and Dermason. And hence, the misclassification number is higher in SGDC classificier.","06ec6374":"Get data summary before conduct the scaling.","bcaded23":"visualize  the confusion matrix","58b4c4e2":"*SVC Classifier*","c5f42472":"The Pipeline will scale the data for us before training the model and make prediction.","0dcc1d0f":"The F1 score of SVC is higher than SGDC.","a9a99073":"Use the Support Vector Classifier implemented in the sklearn.svm.SVC class to perform oneversus-one binary classification on the training set. ","1b904193":"# Data Visualization","1986fd69":"Fit the model, using default seting for sgdc model. It is a regularized linear model with stochastic gradient descent. By default, it fits a linear support vector machine (SVM). As a linear classifier, it is expected to be less fliexible (at least for the decision boundary). The classification might be doing terrible in non-linear data.","a7855d18":"*Compare by accuracy*","b1609ab0":"We use fit_transform() on the train data so that we learn the parameters of scaling on the train data and in the same time we scale the train data. We only use transform() on the test data because we use the scaling paramaters learned on the train data to scale the test data.\n\nUsing transform() on the test data based on the fit_transform() values\/information from the training data.","9969e413":"We scale the average cross validation score by times it by 100, so the highest score is 100, the closer the better.\n\nAs we can see here, support vector classifier has a slightly higher cross validation score here. So, we could say that we expect support vector classifier would perform better on unseen data.","4d4feb52":"# Feature Scaling","61e8abf8":"# Compare SVC and SGDC classifier","a8109af8":"There are some linear relationship across the variables. \n\nPostive relationship:\n\n    1. Area vs Perimeter\n    2. Area vs Major Axis length\n    3. Area vs Minor Axis length\n    4. Perimeter vs Major Axis length\n    5. Perimeter vs Minor Axis length\n    6. Major Axis length vs Minor Axis length\n    \nLog function(expotential fucntion)\n    \n    1. Eccentricity vs Aspect Ration\n\n\nFor Aspect ration and eccentricity, there are two or more groups when they put together with area, perimeter, major axis length and minor axis lenght.\n    \nThere are some graphs with 2 obvious distinct clusters as well, these might be helpful for clustering analysis. But this notebook is going to demonstrate how to implement a classifier, clustering is out of scope.\n","63670331":"The overall accuracy of SVC is 93%, which is 1% higher than the sgdc model.","8b6556a7":"The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. In the multi-class and multi-label case, this is the average of the F1 score of each class with weighting depending on the average parameter.\n\nPrecision is the accuracy of the positive predictions; recall is the ratio of positive instances that are correctly detected by the classifier. ","af4da3ec":"The row\/instances we have is 13611, with 16 features for prediction. And the 17 feature is the class we want to predict.","067fc52d":"Use a 80\/20 split. 80% of the data be the training set and 20% be the test set. Import train_test_split from sklearn.","a5d3bce1":"This notebook demonstarte how to build classification models with python.\n\nFirst, we inspect the data, and perform visualization to discover whether there is any insight between the predictors. The details are written in that section.\n\nSecond, train test split is performed. We split the data into two set, which is training set and test set. And then, feature scaling is performed.\n\nFinally, a support vector classifier and sgdc classificier are built. Confusion matrix, accuracy, F1 score and cross-validation are used to evaluate the performance. And we conclude that, support vector classifier perform better.","5a75e0ae":"Alternative way to build this SVM","80c1680c":"Cross-validation is used to estimate the performance of a machine learning model on unseen data. It train on multiple train-test splits, we use 10 as k here as it normally can generate good result. Cross-validation gives you a better indication of how well your model will perform on unseen data. \n\nThe models will be trained 10 times. Each time of training, the data with spilt into 10 folds, 9 folds will be used to train the model. The remaining 1 fold is hold-out set, which will be used to test the model performance in that time of training.\n\nIn short, cross-validation is a better indicator to compare models performance on unseen dataset than simply train-test split. Therefore, we will have a try here.","c82fe2ec":"# Model building","8a310ec3":"The maximum value of Area is much more higher than the third quarter, there should be outlier or outliers. Convex Area and Major axis length have the similar characteristic as well. \n\nWe are going to use standardScaler to standarized the data. ","f6993cb8":"# Train test split","1352e39e":"# Read the data","cf5881a6":"Most of the columns are numerical features.","8d70d85f":"*Confusion Matrix*","4db45dca":"Fit the model.","1305133f":"# Summary","ba9187be":"This clas\u2010 sifier has the advantage of being capable of handling very large datasets efficiently. This is in part because SGD deals with training instances independently, one at a time","e3ca0d29":"# Model selection by cross-validation","ba0fe326":"Check whehter there are missing values.\n\nNo missing values at all.","2536513b":"There are 10888 training instances and 2723 test instances.","76278d68":"*Confusion Matrix of SVC*","291722ce":"# Number of instancs of each class","afdffd36":"*SGDC Classifier*"}}