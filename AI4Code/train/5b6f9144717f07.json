{"cell_type":{"ab95aa67":"code","916a8dcd":"code","fe13853d":"code","826e10f5":"code","6e8a8c0f":"code","f54b2d7a":"code","4a70715e":"code","dbfb11a9":"code","1a08c7a6":"code","fd5f7569":"code","028f3d0d":"code","988bdc48":"code","c2feec9b":"code","4acbe3bb":"code","7810fe1d":"code","67049728":"code","e48ae8bb":"code","a1968f22":"code","5da837fd":"code","47113dcd":"code","38a3c898":"code","3f99c07e":"code","9f269b79":"code","0bca2e48":"code","85c7cf6a":"code","f37bf7c0":"code","c13c23f5":"code","c3946e5a":"code","0ecd6435":"code","bb24cc7e":"code","3b90da0d":"code","521df0a1":"code","74fac8ec":"code","8020530f":"code","19f9bdb8":"code","7f0ac2e6":"code","8ede38af":"code","01cb7ae6":"code","b6f5b758":"code","009bc929":"code","386cfb87":"code","2ab102ac":"code","6ba93a66":"code","4769e470":"code","d8efa7d0":"code","73709a8c":"code","b8ce36bc":"code","c5f5a47b":"code","d86eb9ca":"code","8d1ad827":"code","8358c0df":"code","0fc996de":"code","c1c75376":"code","73b86824":"markdown","82fbb147":"markdown","d6210f61":"markdown","477d1928":"markdown"},"source":{"ab95aa67":"from sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import ExtraTreeClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\nfrom sklearn import preprocessing\nfrom scipy.stats import norm\nimport matplotlib.pylab as pylab\nimport matplotlib.pyplot as plt\nfrom pandas import get_dummies\nimport matplotlib as mpl\nfrom scipy import stats\nimport xgboost as xgb\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport warnings\nimport sklearn\nimport scipy\nimport numpy\nimport json\nimport sys\nimport csv\nimport os","916a8dcd":"warnings.filterwarnings('ignore')\n%matplotlib inline","fe13853d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","826e10f5":"df_red=pd.read_csv(\"\/kaggle\/input\/wine-quality-selection\/winequality-red.csv\")\ndf_white=pd.read_csv(\"\/kaggle\/input\/wine-quality-selection\/winequality-white.csv\")","6e8a8c0f":"df_white.info()","f54b2d7a":"df_red.info()","4a70715e":"df_red.describe()","dbfb11a9":"df_white.describe()","1a08c7a6":"# Combining the red and white wine data\ndf_wine = df_red.append(df_white)\nprint(df_wine.shape)","fd5f7569":"df_wine.describe()","028f3d0d":"# Features for the wine data\nsns.set()\npd.DataFrame.hist(df_wine, figsize = [15,15], color='green')\nplt.show()","988bdc48":"colormap = plt.cm.viridis\nplt.figure(figsize=(12,12))\nplt.title('Correlation of Features', y=1.05, size=15)\nsns.heatmap(df_wine.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)\n","c2feec9b":"dependent_all=df_wine['quality']\nindependent_all=df_wine.drop(['quality'],axis=1)","4acbe3bb":"x_train,x_test,y_train,y_test=train_test_split(independent_all,dependent_all,test_size=0.3,random_state=100)","7810fe1d":"xgboost = xgb.XGBClassifier(max_depth=3,n_estimators=300,learning_rate=0.05)","67049728":"xgboost.fit(x_train,y_train)","e48ae8bb":"#XGBoost modelon the train set\nXGB_prediction = xgboost.predict(x_train)\nXGB_score= accuracy_score(y_train,XGB_prediction)\nXGB_score","a1968f22":"#XGBoost model on the test\nXGB_prediction = xgboost.predict(x_test)\nXGB_score= accuracy_score(y_test,XGB_prediction)\nXGB_score","5da837fd":"rfc2=RandomForestClassifier()\nrfc2.fit(x_train,y_train)\n#model on train using all the independent values in df\nrfc_prediction = rfc2.predict(x_train)\nrfc_score= accuracy_score(y_train,rfc_prediction)\nprint(rfc_score)\n#model on test using all the indpendent values in df\nrfc_prediction = rfc2.predict(x_test)\nrfc_score= accuracy_score(y_test,rfc_prediction)\nprint(rfc_score)","47113dcd":"log =LogisticRegression()\nlog.fit(x_train,y_train)\n#model on train using all the independent values in df\nlog_prediction = log.predict(x_train)\nlog_score= accuracy_score(y_train,log_prediction)\nprint(log_score)\n#model on train using all the independent values in df\nlog_prediction = log.predict(x_test)\nlog_score= accuracy_score(y_test,log_prediction)\nprint(log_score)","38a3c898":"dec=DecisionTreeClassifier()\ndec.fit(x_train,y_train)\n#model on train using all the independent values in df\ndec_prediction = dec.predict(x_train)\ndec_score= accuracy_score(y_train,dec_prediction)\nprint(dec_score)\n#model on test using all the independent values in df\ndec_prediction = dec.predict(x_test)\ndec_score= accuracy_score(y_test,dec_prediction)\nprint(dec_score)","3f99c07e":"etc=ExtraTreeClassifier()\netc.fit(x_train,y_train)\n#model on train using all the independent values in df\netc_prediction = etc.predict(x_train)\netc_score= accuracy_score(y_train,etc_prediction)\nprint(etc_score)\n#model on test using all the independent values in df\netc_prediction = etc.predict(x_test)\netc_score= accuracy_score(y_test,etc_prediction)\nprint(etc_score)","9f269b79":"ada =AdaBoostClassifier()\nada.fit(x_train,y_train)\n#model on train using all the independent values in df\nada_prediction = ada.predict(x_train)\nada_score= accuracy_score(y_train,ada_prediction)\nprint(ada_score)\n#model on test using all the independent values in df\nada_prediction = ada.predict(x_test)\nada_score= accuracy_score(y_test,ada_prediction)\nprint(ada_score)","0bca2e48":"bca =BaggingClassifier()\nbca.fit(x_train,y_train)\n#model on train using all the independent values in df\nbca_prediction = bca.predict(x_train)\nbca_score= accuracy_score(y_train,bca_prediction)\nprint(bca_score)\n#model on test using all the independent values in df\nbca_prediction = bca.predict(x_test)\nbca_score= accuracy_score(y_test,bca_prediction)\nprint(bca_score)","85c7cf6a":"estimator = [] \nestimator.append(('LR',  \n                  LogisticRegression(solver ='lbfgs',  \n                                     multi_class ='multinomial',  \n                                     max_iter = 200))) \nestimator.append(('SVC', SVC(gamma ='auto', probability = True))) \nestimator.append(('DTC', DecisionTreeClassifier()))","f37bf7c0":"vc=VotingClassifier(estimators = estimator, voting ='hard') \nvc.fit(x_train,y_train)\n#model on train using all the independent values in df\nvc_prediction = vc.predict(x_train)\nvc_score= accuracy_score(y_train,vc_prediction)\nprint(vc_score)\n#model on test using all the independent values in df\nvc_prediction = vc.predict(x_test)\nvc_score= accuracy_score(y_test,vc_prediction)\nprint(vc_score)","c13c23f5":"vc=VotingClassifier(estimators = estimator, voting ='soft') \nvc.fit(x_train,y_train)\n#model on train using all the independent values in df\nvc_prediction = vc.predict(x_train)\nvc_score= accuracy_score(y_train,vc_prediction)\nprint(vc_score)\n#model on test using all the independent values in df\nvc_prediction = vc.predict(x_test)\nvc_score= accuracy_score(y_test,vc_prediction)\nprint(vc_score)","c3946e5a":"gbc=GradientBoostingClassifier()\ngbc.fit(x_train,y_train)\n#model on train using all the independent values in df\ngbc_prediction = gbc.predict(x_train)\ngbc_score= accuracy_score(y_train,gbc_prediction)\nprint(gbc_score)\n#model on test using all the independent values in df\ngbc_prediction =gbc.predict(x_test)\ngbc_score= accuracy_score(y_test,gbc_prediction)\nprint(gbc_score)","0ecd6435":"ettc=ExtraTreesClassifier()\nettc.fit(x_train,y_train)\n#model on train using all the independent values in df\nettc_prediction = ettc.predict(x_train)\nettc_score= accuracy_score(y_train,ettc_prediction)\nprint(ettc_score)\n#model on test using all the independent values in df\nettc_prediction =ettc.predict(x_test)\nettc_score= accuracy_score(y_test,ettc_prediction)\nprint(ettc_score)","bb24cc7e":"sgdc=SGDClassifier()\nsgdc.fit(x_train,y_train)\n#model on train using all the independent values in df\nsgdc_prediction = sgdc.predict(x_train)\nsgdc_score= accuracy_score(y_train,sgdc_prediction)\nprint(sgdc_score)\n#model on test using all the independent values in df\nsgdc_prediction =sgdc.predict(x_test)\nsgdc_score= accuracy_score(y_test,sgdc_prediction)\nprint(sgdc_score)","3b90da0d":"pac=PassiveAggressiveClassifier()\npac.fit(x_train,y_train)\n#model on train using all the independent values in df\npac_prediction = pac.predict(x_train)\npac_score= accuracy_score(y_train,pac_prediction)\nprint(pac_score)\n#model on test using all the independent values in df\npac_prediction =pac.predict(x_test)\npac_score= accuracy_score(y_test,pac_prediction)\nprint(pac_score)","521df0a1":"rc=RidgeClassifier()\nrc.fit(x_train,y_train)\n#model on train using all the independent values in df\nrc_prediction = rc.predict(x_train)\nrc_score= accuracy_score(y_train,rc_prediction)\nprint(rc_score)\n#model on test using all the independent values in df\nrc_prediction =rc.predict(x_test)\nrc_score= accuracy_score(y_test,rc_prediction)\nprint(rc_score)","74fac8ec":"clf = RandomForestClassifier()\ngrid_values = {'max_features':['auto','sqrt','log2'],'max_depth':[None, 10, 5, 3, 1],\n              'min_samples_leaf':[1, 5, 10, 20, 50]}\nclf","8020530f":"grid_clf = GridSearchCV(clf, param_grid=grid_values, cv=10, scoring='accuracy')\ngrid_clf.fit(x_train, y_train) # fit and tune model","19f9bdb8":"grid_clf.best_params_","7f0ac2e6":"clf = RandomForestClassifier().fit(x_train, y_train)","8ede38af":"y_pred = clf.predict(x_test)","01cb7ae6":"print('Training Accuracy :: ', accuracy_score(y_train, clf.predict(x_train)))\nprint('Test Accuracy :: ', accuracy_score(y_test, y_pred))","b6f5b758":"df_wine","009bc929":"df_wine_unsupervised=df_wine.drop(['quality'],axis=1)","386cfb87":"df_wine_unsupervised.dtypes","2ab102ac":"from scipy import stats","6ba93a66":"df_wine_z_score=stats.zscore(df_wine_unsupervised, axis = 1)","4769e470":"cols = list(df_wine_unsupervised.columns)\ndf_wine_unsupervised[cols]\n# now iterate over the remaining columns and create a new zscore column\nfor col in cols:\n    col_zscore = col + '_zscore'\n    df_wine_unsupervised[col_zscore] = (df_wine_unsupervised[col] - df_wine_unsupervised[col].mean())\/df_wine_unsupervised[col].std(ddof=0)\ndf_wine_unsupervised.head()","d8efa7d0":"df_wine_unsupervised.columns","73709a8c":"x_norm=df_wine_unsupervised[['fixed acidity_zscore',\n       'volatile acidity_zscore', 'citric acid_zscore',\n       'residual sugar_zscore', 'chlorides_zscore',\n       'free sulfur dioxide_zscore', 'total sulfur dioxide_zscore',\n       'density_zscore', 'pH_zscore', 'sulphates_zscore', 'alcohol_zscore']]","b8ce36bc":"from sklearn.cluster import DBSCAN","c5f5a47b":"model=DBSCAN()\nmodel.fit(x_norm)\nlabels=model.labels_","d86eb9ca":"from sklearn.cluster import KMeans\nmodel = KMeans(n_clusters=8)\nmodel.fit(x_norm)\nlabels=model.labels_","8d1ad827":"df_wine_unsupervised['predicted_quality']=labels","8358c0df":"df_wine_unsupervised","0fc996de":"df_wine_unsupervised['quality']=df_wine['quality']","c1c75376":"import pandas as pd\n%matplotlib inline\n#do code to support model\n#\"data\" is the X dataframe and model is the SKlearn object\n\nfeats = {} # a dict to hold feature_name: feature_importance\nfor feature, importance in zip(x_train.columns, rfc2.feature_importances_):\n    feats[feature] = importance #add the name\/value pair \n\nimportances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\nimportances.sort_values(by='Gini-importance').plot(kind='bar', rot=45)","73b86824":"## Supervised learning","82fbb147":"(please upvote if you like)","d6210f61":"# # Unsupervised Learning","477d1928":"# **Wine Quality Prediction **"}}