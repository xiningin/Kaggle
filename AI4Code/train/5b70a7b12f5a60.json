{"cell_type":{"f75e1812":"code","2dc822fe":"code","99688f76":"code","e10a3933":"code","74ca5b60":"code","9fa45ccb":"code","0f6ef279":"code","8596bd23":"code","cc306e08":"code","fc233cbf":"code","cde89f24":"code","ef134399":"code","59131c21":"code","ff5c865a":"code","282c77a8":"code","7a56e7d0":"code","dce401f2":"code","a3f08235":"code","5a758b29":"code","22d63bb0":"code","f387b491":"markdown","6ff72995":"markdown","0f9c515d":"markdown","3792d46f":"markdown"},"source":{"f75e1812":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2dc822fe":"import pandas as pd\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nfrom xgboost import XGBRegressor","99688f76":"train = pd.read_csv('\/kaggle\/input\/learn-together\/train.csv')\ntrain.shape","e10a3933":"train.columns.tolist()","74ca5b60":"test = pd.read_csv('\/kaggle\/input\/learn-together\/test.csv')\ntest.shape","9fa45ccb":"test.columns.tolist()","0f6ef279":"plt.figure(figsize=(16, 9))\nsns.scatterplot(x=\"Horizontal_Distance_To_Hydrology\", y=\"Elevation\",\n                hue=\"Cover_Type\", alpha=.8, palette=\"rainbow\", data=train)","8596bd23":"plt.figure(figsize=(16, 9))\nsns.scatterplot(x=\"Horizontal_Distance_To_Roadways\", y=\"Elevation\",\n                hue=\"Cover_Type\", alpha=.8, palette=\"rainbow\", data=train)","cc306e08":"plt.figure(figsize=(16, 9))\nsns.scatterplot(x=\"Horizontal_Distance_To_Fire_Points\", y=\"Elevation\",\n                hue=\"Cover_Type\", alpha=.8, palette=\"rainbow\", data=train)","fc233cbf":"plt.figure(figsize=(16, 9))\nsns.swarmplot(x=\"Cover_Type\", y=\"Elevation\",\n            palette='rainbow', data=train)","cde89f24":"features = ['Elevation', 'Aspect', 'Slope',\n            'Horizontal_Distance_To_Hydrology',\n            'Vertical_Distance_To_Hydrology',\n            'Horizontal_Distance_To_Roadways',\n            'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n            'Horizontal_Distance_To_Fire_Points']\nX = train[features]","ef134399":"sns.pairplot(X)","59131c21":"plt.figure(figsize=(16, 9))\nsns.heatmap(X.corr(), annot=True, cmap = sns.diverging_palette(10, 220, as_cmap=True))","ff5c865a":"X = train.drop(['Id', 'Cover_Type'], axis=1)\ny = train.Cover_Type\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)","282c77a8":"rf_model = RandomForestClassifier(n_estimators=500)\nrf_model.fit(x_train, y_train)\nrf_pred = rf_model.predict(x_test)\n\nprint(mean_absolute_error(y_test, rf_pred))","7a56e7d0":"rf_preds = rf_model.predict(test.drop('Id', axis=1))\n\noutput = pd.DataFrame({'Id': test.Id,\n                       'Cover_Type': rf_preds})\noutput.to_csv('rfc_submission.csv', index=False)","dce401f2":"forest_model = RandomForestRegressor(random_state=1)\nforest_model.fit(x_train, y_train)\nforest_pred = forest_model.predict(x_test)\n\nprint(mean_absolute_error(y_test, forest_pred))","a3f08235":"forest_preds = forest_model.predict(test.drop('Id', axis=1))\n\noutput = pd.DataFrame({'Id': test.Id,\n                       'Cover_Type': forest_preds.round(0)})\noutput.to_csv('forest_submission.csv', index=False)","5a758b29":"XGB_model = XGBRegressor(n_estimators=500)\nXGB_model.fit(x_train, y_train)\nXGB_pred = XGB_model.predict(x_test)\n\nprint(mean_absolute_error(y_test, XGB_pred))","22d63bb0":"XGB_preds = XGB_model.predict(test.drop('Id', axis=1))\n\noutput = pd.DataFrame({'Id': test.Id,\n                       'Cover_Type': XGB_preds.round(0).astype(int)})\noutput.to_csv('XGB_submission.csv', index=False)","f387b491":"**Random Forest Classifier**","6ff72995":"**XGBRegressor**","0f9c515d":"**Building the model**","3792d46f":"**Random Forest Regressor**"}}