{"cell_type":{"e748d567":"code","5e4e0899":"code","d9d3015e":"code","74fd40ff":"code","be6cfabe":"code","1e030354":"code","a529fa96":"code","983a8f02":"code","ae590583":"code","1b1dd5f0":"code","fc9664c9":"code","698d3254":"code","1bef6aa6":"code","362ff1f4":"code","e94e4375":"code","1160c9f4":"code","ab4a4a6c":"code","51535714":"code","9ea206df":"code","31c08e23":"code","6754a039":"code","740c04e3":"markdown","294c1fc3":"markdown","2b7bb62d":"markdown","204fec09":"markdown"},"source":{"e748d567":"%%capture\n!pip install openpyxl","5e4e0899":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","d9d3015e":"DATA_PATH = '\/kaggle\/input\/ocular-disease-recognition-odir5k\/ODIR-5K\/ODIR-5K\/data.xlsx'\nIMG_DIR = '\/kaggle\/input\/ocular-disease-recognition-odir5k\/ODIR-5K\/ODIR-5K\/Training Images\/'","74fd40ff":"main_df = pd.read_excel(DATA_PATH)\nprint(main_df.shape)\nmain_df.head()","be6cfabe":"IMG_SIZE = 512","1e030354":"def crop(image): \n    # Remove vertical black borders (the image must be already normalized)\n    sums = image.sum(axis=0)\n    sums = sums.sum(axis=1)\n    filter_arr = []\n    for s in sums:\n        if s == 0:\n            filter_arr.append(False)\n        else:\n            filter_arr.append(True)\n    image = image[:, filter_arr]\n    \n    # Crop to a square shape\n    h = image.shape[0]\n    w = image.shape[1]    \n    \n    if h < w:\n        x = (w - h)\/\/2\n        image = image[:, x:x+h, :]        \n    elif h > w:\n        x = (h - w)\/\/2\n        image = image[x:x+w, :, :]           \n    else:\n        pass\n    \n    return image","a529fa96":"def preprocess_image(file_name):\n    image = cv2.imread(os.path.join(IMG_DIR, file_name))\n    \n    norm_img = np.zeros(image.shape)\n    norm_img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    \n    image = crop(norm_img)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    \n    return image\n\ndef preprocess_patient(patient_id):\n    left_eye_file = str(patient_id) + '_left.jpg'\n    right_eye_file = str(patient_id) + '_right.jpg'\n    image = cv2.hconcat([preprocess_image(left_eye_file), preprocess_image(right_eye_file)]) \n    return image","983a8f02":"# example\npatient_id = main_df.iloc[7]['ID']\nimage = preprocess_patient(patient_id)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nplt.imshow(image)","ae590583":"images = {}\nfor i in tqdm(range(main_df.shape[0])):\n    patient_id = main_df.iloc[i]['ID']\n    image = preprocess_patient(patient_id)\n    images[patient_id] = image","1b1dd5f0":"output_dir = \"ocular\"\nimg_dir = os.path.join(output_dir, 'images')\nos.makedirs(output_dir)\nos.makedirs(img_dir)","fc9664c9":"os.listdir('\/kaggle\/working')","698d3254":"os.listdir(output_dir)","1bef6aa6":"for i in tqdm(images.keys()):\n    out_file_path = os.path.join(img_dir, str(i)+'.jpg')\n    cv2.imwrite(out_file_path, images[i])","362ff1f4":"total_files = 0\nfor base, dirs, files in os.walk(img_dir):\n    for Files in files:\n        total_files += 1\n\ntotal_files","e94e4375":"# example\npatient_id = 0\nimage = cv2.imread(os.path.join(img_dir, str(patient_id)+'.jpg'))\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nplt.imshow(image)","1160c9f4":"# fix the comma-like symbol\nfor i in range(main_df.shape[0]):\n    corrected_l = main_df.iloc[i]['Left-Diagnostic Keywords'].replace('\uff0c', ', ')  \n    main_df.loc[i, 'Left-Diagnostic Keywords'] = corrected_l\n    corrected_r = main_df.iloc[i]['Right-Diagnostic Keywords'].replace('\uff0c', ', ')  \n    main_df.loc[i, 'Right-Diagnostic Keywords'] = corrected_r\n\nmain_df.head()","ab4a4a6c":"main_df.to_csv(os.path.join(output_dir, 'data.csv'), index=False)","51535714":"os.listdir(output_dir)","9ea206df":"df = pd.read_csv(os.path.join(output_dir, 'data.csv'))\ndf.tail()","31c08e23":"!zip -r ocular_512x1024.zip .\/ocular","6754a039":"!rm -R ocular","740c04e3":"# Create CSV","294c1fc3":"I intend to feed the network 2 images at a time - left and right eye together. This would make more sense from the medical point of view, but also this way i will be able to use labeled columns directly (they do not specify which eye was affected). <br>\nIf i wanted to use one image at a time, i would have to search \"Left-Diagnostic Keywords\" and \"Right-Diagnostic Keywords\" columns for specific keywords. In some cases this wouldn't be a problem: e.g. cataract is always a \"cataract\", but complex diseases like diabetes could manifest differently, different terms could be used to describe the same thing, or even the same term could be written differently by different doctors: e.g. \"nonproliferative\" and \"non proliferative\".<br><br>\n\nIn this dataset, we have a significant dispersion of image sizes (height: 188 - 3456, width: 250 - 5184) with something like 150 images under 1000px size and 10 images under 200px. Most of the images are horizontal or square, but there are also 114 images that are vertical<br>\n(these numbers come from my notebook on file structure exploration: https:\/\/www.kaggle.com\/annaszal\/ocular-files)<br><br>\n\nSince small images make a rather small fraction of the whole set, i am going to choose size as to better preserve information, the small ones will get upscaled. I'm also going to remove black borders and crop all images to a square, then concatenate left and right images into one. I suppose i could stack the two images in channel dimension instead of dealing with non-square input, or create a new dimension, but i can still do that after i load the concatenated images, so it is more of a personal preference at this point.","2b7bb62d":"# Create image files","204fec09":"# Ocular Disease Recognition - Preprocessing"}}