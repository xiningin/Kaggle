{"cell_type":{"cd3bcece":"code","fd77af12":"code","b5fa9a9c":"code","6b33d081":"code","506cfd9d":"code","f96876cb":"code","4bdd337e":"code","d5d1d119":"code","550c5e93":"code","ff27f0da":"code","8dfa35fb":"code","0f0847de":"code","e76a96e5":"code","c019a3d2":"code","5714218a":"code","7a78a293":"code","2d2d9f25":"code","bfeff60a":"code","c80d4f33":"code","2cf78b9c":"code","1a49989a":"markdown"},"source":{"cd3bcece":"#All the required imports \nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport pandas as pd\nfrom glob import glob\nfrom matplotlib import pyplot as plt\nfrom PIL import Image as im\nfrom array import *\nimport math\nimport numpy as np\nimport os\nimport cv2\nfrom sklearn import preprocessing","fd77af12":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5fa9a9c":"#train and test dir in google drive \ntest_dir='..\/input\/drive-retinal-vessel-segmentation-pixelwise\/DRIVE_Modified\/Modified_dataset_test'\ntrain_dir='..\/input\/drive-retinal-vessel-segmentation-pixelwise\/DRIVE_Modified\/Modified_dataset_train'\n\ntraining_data = (glob(train_dir+'\/img*.csv'))\ntesting_data = (glob(test_dir+'\/img*.csv'))\n","6b33d081":"print('Number of training imgs= '+str(len(training_data)) +'\\t'+'Number of testing imgs= '+str(len(testing_data)))","506cfd9d":"#test and train file iterator \n\n\nfinal_training_data = pd.concat((pd.read_csv( file).assign(filename = file) \n                                for file in training_data), ignore_index = True)\n\n\nfinal_testing_data = pd.concat((pd.read_csv(file).assign(filename = file) \n                                for file in testing_data), ignore_index = True)","f96876cb":"x_train=final_training_data[['R','G','B']].values\ny_train =( final_training_data['truth labels'].values\/255)\nx_test=final_testing_data[['R','G','B']].values\ny_test = (final_testing_data['truth labels'].values)\/255\n\n","4bdd337e":"\n\nx_train_scaled = x_train\/255\nx_test_scaled = x_test\/255\n\n","d5d1d119":"!pip install -U imbalanced-learn","550c5e93":"import imblearn\nimblearn.__version__\n","ff27f0da":"from imblearn.over_sampling import ADASYN\nfrom imblearn.over_sampling import SMOTE\nadasyn = ADASYN()\nsmote=SMOTE()\nx_train_scaled_oversampled, y_train = smote.fit_resample(x_train_scaled, y_train)\n\n\n","8dfa35fb":"\ntest_file_img_pth='..\/input\/drive-retinal-vessel-segmentation-pixelwise\/DRIVE_Modified\/Modified_dataset_test\/img1.csv'\ntrain_file_img_pth='..\/input\/drive-retinal-vessel-segmentation-pixelwise\/DRIVE_Modified\/Modified_dataset_train\/img1.csv'\n\n\ntest_img=pd.read_csv(test_file_img_pth)\ntrain_img=pd.read_csv(train_file_img_pth)\n\ntest_img_1=test_img[['R','G','B']].values\ntest_img_1_scaled=test_img_1\/255\ntrain_img_1=train_img[['R','G','B']].values\ntrain_img_1_scaled=train_img_1\/255\n\ntest_img_1_label=(test_img['truth labels'].values\/255)\n\ntrain_img_1_label=(train_img['truth labels'].values)\/255\n","0f0847de":"#oversampling on one img data\nfrom imblearn.over_sampling import ADASYN\nadasyn = ADASYN()\nx_train_scaled_oversampled_1, y_train_1 = adasyn.fit_resample(train_img_1_scaled, train_img_1_label)","e76a96e5":"from sklearn.neural_network import MLPClassifier\n\nmodel=MLPClassifier(hidden_layer_sizes=(16,32,32,64), activation='relu', solver='adam',\n                    alpha=0.001, batch_size=128, learning_rate= 'adaptive', \n                    learning_rate_init=0.001, max_iter=25, \n                    shuffle=True, random_state=420, verbose=2, \n                    warm_start=False,early_stopping=True, \n                    validation_fraction=0.1, beta_1=0.99, beta_2=0.9999, \n                    epsilon=1e-08, n_iter_no_change=5)\n","c019a3d2":"model.fit(x_train_scaled_oversampled,y_train)","5714218a":"print(\"Training set score: %f\" % model.score(x_train_scaled_oversampled, y_train))\nprint(\"Test set score: %f\" % model.score(x_test_scaled, y_test))","7a78a293":"y_train.shape","2d2d9f25":"new_final = []\nresult = model.predict(test_img_1_scaled)\n# result=(result > 0.5)\n# result","bfeff60a":"plt.imshow(test_img['truth labels'].to_numpy().reshape((584,565),order='C'),cmap='gray')","c80d4f33":"test_prediction = result.reshape((584,565),order='C')\nplt.imshow(test_prediction,cmap='gray')","2cf78b9c":"result.sum()","1a49989a":"#Oversampling of training data\n"}}