{"cell_type":{"f5703e58":"code","fe816177":"code","5d8a5e74":"code","1084a79f":"code","f2191fbe":"code","6a320be1":"code","afcdf85b":"code","5811896c":"code","5b00108b":"code","6fe61dab":"code","6bb11916":"code","58989d1c":"code","6388e8df":"code","09219093":"code","9902eca4":"code","e9cfc7c4":"code","cd25b8f1":"code","531ec4d0":"code","e62634aa":"code","3c7c00de":"code","b8e4f968":"code","d42eefaf":"code","8cfa6c5b":"code","98c9b59c":"code","25ae26b2":"code","84f8a688":"code","a1681e61":"code","c3902c74":"code","7ae6bede":"code","0e38d2e8":"code","3962ea82":"code","31b235b3":"code","8c0a1a05":"code","f839af1c":"markdown","313e694e":"markdown","5b80bafd":"markdown","307fafb2":"markdown","d20a75e0":"markdown","edff4822":"markdown","d96636b7":"markdown","06899414":"markdown","f768cae1":"markdown","fe03e2df":"markdown","67b6483b":"markdown","3e7789b6":"markdown","89033e09":"markdown"},"source":{"f5703e58":"import math, keras, bcolz\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm import tqdm_notebook\nfrom pathlib import Path\n%matplotlib inline","fe816177":"np.random.seed(34)\ntrain_path = Path('..\/input\/train\/')\ncat_imgs, dog_imgs = [], []\nfor e in train_path.iterdir():\n    if 'cat' in e.name: cat_imgs.append(e)\n    else              : dog_imgs.append(e)\n        \n# Hacemos una permutacion de los archivos para que esten en desorden\ncat_imgs, dog_imgs = np.random.permutation(cat_imgs).tolist(), np.random.permutation(dog_imgs).tolist()\nn_cat, n_dog = len(cat_imgs), len(dog_imgs)\nn_cat, n_dog","5d8a5e74":"# Vamos a usar 5000 imagenes para el validation set\nn_val = 5000\nn_train = n_cat + n_dog - n_val\ntrain_files = cat_imgs[:-(n_val\/\/2)] + dog_imgs[:-(n_val\/\/2)]\nval_files = cat_imgs[-(n_val\/\/2):] + dog_imgs[-(n_val\/\/2):]","1084a79f":"# Definimos una funcion para leer una imagen y hacer el preprocesamiento\nfrom keras.applications.resnet50 import preprocess_input\nimg_size = 224\n\ndef read_img(path):\n    x = Image.open(path)\n    x = x.resize((img_size, img_size))\n    x = np.asarray(x, np.float32)\n    return x","f2191fbe":"from keras.applications.resnet50 import ResNet50\nfrom keras.models import Model\n\nbase_model = ResNet50(include_top=False, input_shape=(img_size,img_size,3))\nbase_model = Model(base_model.input, base_model.layers[-2].output)\nbase_model.trainable = False\nbase_model.summary()","6a320be1":"base_model.input, base_model.output","afcdf85b":"from keras.models import Sequential\nfrom keras.layers import GlobalAvgPool2D, Input, Conv2D, BatchNormalization, Activation\nfrom keras.optimizers import Adam\n\nm_in = Input((7, 7, 2048))\nx = Conv2D(1024, 1, padding='same', activation='relu', kernel_initializer='he_uniform', use_bias=False)(m_in)\nx = BatchNormalization()(x)\nx = Conv2D(2, 1, padding='same')(x)\nx = GlobalAvgPool2D()(x)\nx = Activation('softmax')(x)\ntop_model = Model(m_in, x)\n\ntop_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\ntop_model.summary()","5811896c":"final_model = Sequential([base_model, top_model])\nfinal_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\nfinal_model.summary()","5b00108b":"class DataSequence(keras.utils.Sequence):\n    def __init__(self, files, batch_size):\n        self.files = files\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return int(np.ceil(len(self.files) \/ float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        batch = self.files[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_x = np.ndarray((self.batch_size, img_size, img_size, 3), np.float32)\n        for i,f in enumerate(batch): batch_x[i] = read_img(f)\n        return preprocess_input(batch_x)","6fe61dab":"train_seq = DataSequence(train_files, 100)\nval_seq = DataSequence(val_files, 100)","6bb11916":"precomputed_train = bcolz.carray(np.zeros((n_train, 7, 7, 2048), np.float32), chunklen=1, mode='w', rootdir='tmp_train')\nprecomputed_val = bcolz.carray(np.zeros((n_val, 7, 7, 2048), np.float32), chunklen=1, mode='w', rootdir='tmp_val')","58989d1c":"y_train = np.zeros((n_train), np.int8)\ny_val = np.zeros((n_val), np.int8)\ny_train[n_train\/\/2:] = 1\ny_val[n_val\/\/2:] = 1","6388e8df":"for i,batch in tqdm_notebook(enumerate(train_seq), total=len(train_seq)):\n    precomputed_train[i*100:(i+1)*100] = base_model.predict_on_batch(batch)\n    if i == len(train_seq): break","09219093":"for i,batch in tqdm_notebook(enumerate(val_seq), total=len(val_seq)):\n    precomputed_val[i*100:(i+1)*100] = base_model.predict_on_batch(batch)\n    if i == len(val_seq): break    ","9902eca4":"# Ahora podemos usar un batch_size mas grande, ya que los features son mas peque\u00f1os\n# que las imagenes.\nlog = top_model.fit(precomputed_train, y_train, epochs=10, batch_size=256, validation_data=[precomputed_val, y_val])","e9cfc7c4":"def show_results(log):\n    fig, axes = plt.subplots(1, 2, figsize=(14,4))\n    ax1, ax2 = axes\n    ax1.plot(log.history['loss'], label='train')\n    ax1.plot(log.history['val_loss'], label='validation')\n    ax1.set_xlabel('epoch'); ax1.set_ylabel('loss')\n    ax2.plot(log.history['acc'], label='train')\n    ax2.plot(log.history['val_acc'], label='validation')\n    ax2.set_xlabel('epoch'); ax2.set_ylabel('accuracy')\n    for ax in axes: ax.legend()","cd25b8f1":"show_results(log)","531ec4d0":"test_path = Path('..\/input\/test\/')\ntest_files = list(test_path.iterdir())","e62634aa":"def get_class(path):\n    # Cargar la imagen del path\n    img = Image.open(path)\n    \n    # Cambiar el tama\u00f1o de la imagen\n    img_resized = img.resize((224, 224))\n    \n    # Cambiar a formato numpy y preprocesar\n    x = np.asarray(img_resized, np.float32)[None]\n    x = preprocess_input(x)\n    \n    # Obtener predicciones\n    y = final_model.predict(x)\n    \n    # Decodear predicciones\n    pred = 'cat' if np.argmax(y) == 0 else 'dog'\n    \n    # Mostrar la imagen\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(f'pred = {pred}', size=14)\n    plt.show()\n    \n    return","3c7c00de":"for _ in range(3):\n    sample = np.random.choice(test_files)\n    get_class(sample)","b8e4f968":"preds_val = top_model.predict(precomputed_val, batch_size=256, verbose=1)\npreds_val.shape","d42eefaf":"pred_classes = np.argmax(preds_val, axis=1)\nidxs = np.where(y_val != pred_classes)[0]\nerrors = np.min(preds_val[idxs], axis=1)\nidxs = idxs[np.argsort(errors)]","8cfa6c5b":"fig, axes = plt.subplots(3, 4, figsize=(18,12))\nfor ax, idx in zip(axes.flatten(), idxs):\n    ax.imshow(Image.open(val_files[idx]))\n    ax.set_title(f'''real label = {'dog' if idx > n_val\/2 else 'cat'}\npred label = {'dog' if pred_classes[idx] == 1 else 'cat'}\nerror = {1 - np.min(preds_val[idx]):.4f}''')\n    ax.axis('off')\nplt.tight_layout()","98c9b59c":"# Vamos a crear un modelo para capturar una capa intermedia, ademas del output\nmap_model = Model(top_model.layers[0].input, [top_model.layers[-3].output, top_model.layers[-1].output])","25ae26b2":"import cv2\n\ndef get_feature_map(path):\n    img = Image.open(path)\n    img_resized = img.resize((224, 224))\n    x = np.asarray(img_resized, np.float32)[None]\n    x = preprocess_input(x)\n    precomputed = base_model.predict(x)\n    fmap, y = map_model.predict(precomputed)\n    pred = np.argmax(y)\n    fmap = cv2.resize(fmap[0,:,:,pred], img.size)\n    fig, axes = plt.subplots(1, 2, figsize=(18,10))\n    for ax in axes:\n        ax.imshow(img)\n        ax.axis('off')\n        title = f\"pred = {'cat' if pred == 0 else 'dog'}\"\n        if sample.name[:3] == 'cat' or sample.name[:3] == 'dog':\n            title += f'\\nreal = {sample.name[:3]}'\n        ax.set_title(title, size=14)\n\n    axes[0].imshow(fmap, cmap=plt.cm.RdGy_r, alpha=0.75)\n    plt.show()\n    \n    return","84f8a688":"for _ in range(5):\n    sample = np.random.choice(val_files)\n    get_feature_map(sample)","a1681e61":"for i in np.random.permutation(idxs)[:5]:\n    sample = val_files[i]\n    get_feature_map(sample)","c3902c74":"# Obtener resultados del test set\nimport pandas as pd\n\ntest_path = Path('..\/input\/test\/')\ntest_files = list(test_path.iterdir())\n\nclass TestDataSequence(DataSequence):\n    def __getitem__(self, idx):\n        batch = self.files[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_x = np.ndarray((self.batch_size, img_size, img_size, 3), np.float32)\n        batch_ids = np.zeros((self.batch_size), np.int16)\n        for i,f in enumerate(batch):\n            batch_x[i] = read_img(f)\n            batch_ids[i] = int(f.stem)\n        return preprocess_input(batch_x), batch_ids\n\ntest_seq = TestDataSequence(test_files, 250)","7ae6bede":"preds, ids = [], []\n\nfor i,batch in tqdm_notebook(enumerate(test_seq), total=len(test_seq)):\n    y_ = final_model.predict_on_batch(batch[0])\n    preds += np.argmax(y_, axis=1).tolist()\n    ids += batch[1].tolist()\n    if i == len(test_seq): break    ","0e38d2e8":"results = pd.DataFrame({'id': ids, 'label': preds}).sort_values('id').drop_duplicates()\nresults.head()","3962ea82":"results.to_csv('submission.csv', index=False)","31b235b3":"from IPython.display import FileLink\nFileLink('submission.csv')","8c0a1a05":"# Eliminamos los archivos temporales del kernel\n!rm -r tmp_train\n!rm -r tmp_val","f839af1c":"## Veamos las imagenes que habiamos identificado con errores","313e694e":"# Usando el modelo completo en el test set","5b80bafd":"# Creamos el modelo clasificador","307fafb2":"# Weak Localization","d20a75e0":"# Juntamos los 2 modelos","edff4822":"# Cargando las imagenes","d96636b7":"https:\/\/www.kaggle.com\/c\/dogs-vs-cats-redux-kernels-edition","06899414":"## Veamos imagenes del validation set","f768cae1":"# Kaggle submission","fe03e2df":"# Entrenar a partir de los features extraidos","67b6483b":"# Cargamos una red entrenada\nVamos a cargar la red **ResNet50** ya entrenada, pero sin incluir las capas densas, ya que vamos a adaptar la red a nuestro caso espec\u00edfico.","3e7789b6":"# Precompute","89033e09":"# Veamos los puntos de falla"}}