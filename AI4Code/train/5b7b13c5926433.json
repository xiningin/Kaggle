{"cell_type":{"ebd8c895":"code","7b2354b7":"code","f5bb14ee":"code","b8f4efbc":"code","c70d8cd6":"code","17447503":"code","c96b4599":"code","8d074343":"code","65547beb":"code","297f575f":"code","96fe9ca8":"code","2ac6d3db":"code","f0e7e066":"code","96ab91fd":"markdown","4f1023aa":"markdown","f4797d95":"markdown","8fcd8bb1":"markdown","9578bc97":"markdown","026ce05b":"markdown","c24c616d":"markdown"},"source":{"ebd8c895":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout, GRU\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport numpy as np\nimport os\ntf.random.set_seed(101)\n","7b2354b7":"df = pd.read_csv('\/kaggle\/input\/cryptocurrencypricehistory\/coin_Ethereum.csv')\ndf = df.dropna()\ndf = df.sort_values('Date').reset_index(drop=True)","f5bb14ee":"df.head()","b8f4efbc":"df = df.drop(['Open', 'High', 'Low', 'Volume', 'Marketcap','Volume', 'Symbol', 'Name', 'SNo'], axis = 1)\ndf['Close'] = df['Close'].astype(float)\ndf['Date'] = df['Date'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\nlast_date = df['Date'].iloc[-1]\ndf['Date'] = df['Date'].apply(datetime.timestamp)","c70d8cd6":"sc = MinMaxScaler(feature_range = (0, 1))\ndf_scaled = sc.fit_transform(df)","17447503":"window = 60\nX = []\ny = []\nfor i in range(window, len(df_scaled)):\n    X.append(np.reshape(df_scaled[i-window:i,0], (window, 1)))\n    y.append(df_scaled[i,1])\n\nX = np.stack(X)\ny = np.stack(y)","c96b4599":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, shuffle = False)","8d074343":"model = models.Sequential()\nmodel.add(LSTM(units = 100, use_bias=True, activation = 'relu', return_sequences = True, input_shape = (X_train.shape[1], 1)))\n# model.add(Dropout(0.2))\nmodel.add(GRU(units = 50, activation = 'relu', return_sequences = True, use_bias=True))\n# model.add(Dropout(0.2))\nmodel.add(LSTM(units = 10, use_bias=True))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units = 1))\n","65547beb":"model.compile(optimizer = 'Adamax', loss = 'mse', metrics = 'mae')\nhistory = model.fit(X_train, y_train, epochs = 100, batch_size = 32, verbose=1)","297f575f":"plt.rcParams[\"figure.figsize\"] = (15,8) # plotsize\nplt.plot(history.history['mae'], color = '#F77800', linewidth=2) #plothistory\nplt.grid(color='#ADADAD', linestyle='--', linewidth=1) # setup grid\nplt.xlabel('Epoch', fontsize = 20) # x label\nplt.ylabel('Mean absolute error', fontsize = 20) # y label","96fe9ca8":"Train_predicted_values = model.predict(X_train)\nTrain_predicted = [[],[]]\n\nfor i in range(len(X_train)):\n    Train_predicted[0].append(df_scaled[i+window, 0])\n    Train_predicted[1].append(Train_predicted_values[i])\n\nTrain_predicted = np.array(Train_predicted).T\nTrain_inversed_values = sc.inverse_transform(Train_predicted)\nTrain_inversed_values = pd.DataFrame(Train_inversed_values)\nTrain_inversed_values[0] = Train_inversed_values[0].apply(lambda x: datetime.fromtimestamp(x))\n\n\nTest_predicted_values = model.predict(X_test)\nTest_predicted = [[],[]]\n\nfor i in range(len(X_test)):\n    Test_predicted[0].append(df_scaled[i+window+len(X_train), 0])\n    Test_predicted[1].append(Test_predicted_values[i])\n\nTest_predicted = np.array(Test_predicted).T\nTest_inversed_values = sc.inverse_transform(Test_predicted)\nTest_inversed_values = pd.DataFrame(Test_inversed_values)\nTest_inversed_values[0] = Test_inversed_values[0].apply(lambda x: datetime.fromtimestamp(x))\n\nMSE = mean_squared_error(Test_inversed_values[1], y_test)\nMAE = mean_absolute_error(Test_inversed_values[1], y_test)\nprint(f\"MSE:{MSE}\\nMAE:{MAE}\")","2ac6d3db":"plt.rcParams[\"figure.figsize\"] = (22,10) # plotsize\nplt.rcParams['axes.facecolor'] = '#ffffff'\nplt.grid(color='#ADADAD', linestyle='-.', linewidth=1)\nplt.plot(df['Date'].apply(datetime.fromtimestamp), df['Close'], color = '#0DD527', linewidth=2, label = \"ETH data\")\nplt.plot(Train_inversed_values[0],Train_inversed_values[1], color = '#F77800', linewidth=2, label = \"Train data\")\nplt.plot(Test_inversed_values[0],Test_inversed_values[1], color = '#0F97FF', linewidth=2, label = \"Test data\")\nplt.legend(fontsize='x-large')\nplt.show()","f0e7e066":"days = 60\nend_date = last_date + timedelta(days)\ntime_range = pd.date_range(start=last_date,end=end_date)\ntimestamp_time_range = time_range.to_series().apply(datetime.timestamp).values\nvals = [0]*len(time_range)\ndata_for_scaling = np.array([timestamp_time_range, vals]).T\nscaled_forecast = sc.transform(data_for_scaling)\nscaled_forecast = np.concatenate((df_scaled, scaled_forecast), axis=0)\n\nX_forecast_part = []\nfor i in range(len(df_scaled)-window, len(scaled_forecast)):\n    X = np.reshape(scaled_forecast[i-window:i,0], (window, 1))\n    X_forecast_part.append(X)\n\nX_forecast_part = np.stack(X_forecast_part)\n\nforecast = model.predict(X_forecast_part)\nforecast_arr = [[], []]\n\nfor j in range(window, len(forecast)):\n    forecast_arr[0].append(scaled_forecast[j, 0])\n    forecast_arr[1].append(forecast[j-window])\n\nforecast_predicted_arr = np.array(forecast_arr, dtype=np.float64).T\nforecast_inversed_values = sc.inverse_transform(forecast_predicted_arr)\nforecast = pd.DataFrame(forecast_inversed_values)\n\n\nplt.grid(color='#ADADAD', linestyle='-.', linewidth=1)\nplt.plot(df['Date'].apply(datetime.fromtimestamp), df['Close'], color = '#0DD527', linewidth=2, label = \"ETH data\")\nplt.plot(Train_inversed_values[0],Train_inversed_values[1], color = '#F77800', linewidth=2, label = \"Train data\")\nplt.plot(Test_inversed_values[0],Test_inversed_values[1], color = '#0F97FF', linewidth=2, label = \"Test data\")\nplt.plot(time_range,forecast[1], color = '#00FFA9', linewidth=2, label = \"forecast\")\nplt.legend(fontsize='x-large')\nplt.show()","96ab91fd":"# LSTM+GRU model architecture","4f1023aa":"# Forecasting on existing dataset","f4797d95":"# Data preprocessing part","8fcd8bb1":"# Generating of sequences with certain period of days","9578bc97":"# N days forecast","026ce05b":"# Representation of collected Ehterium data ","c24c616d":"# **Splitting data to train test parts**"}}