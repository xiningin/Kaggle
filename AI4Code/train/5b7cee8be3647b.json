{"cell_type":{"e4f2b11f":"code","65b7468c":"code","269cb677":"code","49d369a4":"code","b6a15870":"code","cc62e3cc":"code","cb87d188":"code","557a7e23":"code","f741abc8":"code","8a9ca7d8":"code","308af433":"code","cd34a55a":"code","1f132279":"code","17dfc7da":"code","dd9a0d04":"code","92f9016f":"code","bb9842c0":"code","d94504b5":"code","5ad9c62c":"code","ade2c0ea":"code","e3bb539e":"code","1d436fd5":"code","3dd520fd":"code","70210052":"code","bf1e7340":"code","ce57fc92":"code","dd7d94e3":"code","83243478":"code","59562e73":"code","319aeae5":"code","b0efca66":"code","11e09a9e":"code","49283686":"code","ffbf663e":"code","ef8da166":"code","3ce63ef5":"code","79cae076":"code","1b868ebd":"code","32d24127":"code","d38e3ef1":"code","ce94b71b":"code","a808dbd6":"code","71bcafac":"markdown","5962189a":"markdown","d30de8ed":"markdown","d2cc9d12":"markdown","7cd3fa74":"markdown","2ccc7f81":"markdown","9fe5cc08":"markdown","3079fc52":"markdown","c9b66780":"markdown","2313c5da":"markdown","525ce03d":"markdown","9de8aece":"markdown"},"source":{"e4f2b11f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom skimage import color\nimport matplotlib.image as mpimg\nimport matplotlib.patches as patches\nimport albumentations as alb","65b7468c":"train_path = '\/kaggle\/input\/global-wheat-detection\/train.csv'\ntrain_img_path = '\/kaggle\/input\/global-wheat-detection\/train'","269cb677":"#read the csv file\ntrain = pd.read_csv(train_path)\ntrain.head()","49d369a4":"sns.countplot(train['source'])","b6a15870":"#separating x,y,w,h into separate columns for convenience\nbboxes = np.stack(train['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep = ',')))\nfor i, col in enumerate(['x_min', 'y_min', 'w', 'h']):\n    train[col] = bboxes[:,i]","cc62e3cc":"#dropping the bbox column as it is not needed now\ntrain.drop(columns = ['bbox'], inplace = True)","cb87d188":"#calculate box areas to check for anomaly boxes\ntrain['box_area'] = train['w']*train['h']","557a7e23":"#display head of new dataframe\ntrain.head()","f741abc8":"#number of unique images in the dataframe\nlen(train['image_id'].unique())","8a9ca7d8":"#number of images in the training directory\nlen(os.listdir(train_img_path))","308af433":"#obtaining a list of all images which have no wheat heads in them\nunique_imgs_wbox = list(train['image_id'].unique())\nall_unique_imgs = os.listdir(train_img_path)\nno_wheat_imgs = [img_id for img_id in all_unique_imgs if img_id not in unique_imgs_wbox]\nlen(no_wheat_imgs)","cd34a55a":"#append .jpg to image ids for easier handling\ntrain['image_id'] = train['image_id'].apply(lambda x: str(x) + '.jpg')","1f132279":"def get_all_bboxes(df, image_id, count = False):\n    '''function that gets all bboxes for a given image id'''\n    bboxes = []\n    for _,row in df[df.image_id == image_id].iterrows():\n        bboxes.append([row.x_min, row.y_min, row.w, row.h])\n    if count:\n        return bboxes, len(bboxes)\n    else:\n        return bboxes\n\ndef select_img(n, wheat = True):\n    '''function to randomly select image ids from the dataframe and return it as a list'''\n    if wheat:\n        img_ids = train.sample(n = n, random_state = 0)['image_id']\n        return list(img_ids)\n    else:\n        img_ids = np.random.choice(no_wheat_imgs, n)\n        return list(img_ids)\n        \n\ndef plot_imgs(df, ids, bbox = False):\n    '''function to plot an even number of images'''\n    n = len(ids)\n    fig, ax = plt.subplots(2, n\/\/2, figsize = (40,30))\n    for i, im_id in enumerate(ids):\n        img = mpimg.imread(os.path.join(train_img_path, im_id))\n        ax[i\/\/(n\/\/2)][i%(n\/\/2)].imshow(img)\n        ax[i\/\/(n\/\/2)][i%(n\/\/2)].axis('off')\n        if bbox:\n            bboxes = get_all_bboxes(df, im_id)\n            for bbox in bboxes:\n                rect = patches.Rectangle((bbox[0],bbox[1]),bbox[2],bbox[3],linewidth=2,edgecolor='r',facecolor='none')\n                ax[i\/\/(n\/\/2)][i%(n\/\/2)].add_patch(rect)\n        else:\n            pass        \n    plt.tight_layout()\n    plt.show()","17dfc7da":"plot_imgs(train, select_img(6))","dd9a0d04":"plot_imgs(train, select_img(6, wheat = False))","92f9016f":"plot_imgs(train, select_img(6), bbox = True)","bb9842c0":"print('Mean box area is: ', train['box_area'].mean())","d94504b5":"print('Max box area is: ', train['box_area'].max())","5ad9c62c":"print('Min box area is: ', train['box_area'].min())","ade2c0ea":"#large ids\nlarge_ids = train[train['box_area'] > 170000].image_id\nplot_imgs(train, large_ids, bbox = True)","e3bb539e":"#small ids\nsmall_ids = train[train['box_area']<15].image_id\nplot_imgs(train, small_ids, bbox = True)","1d436fd5":"def get_brightness(image):\n    image = color.rgb2gray(image)\n    return np.mean(image)*255","3dd520fd":"#get brightness of each image and append to dataframe\nbrightness_array = []\nimage_list = list(train['image_id'].unique())\nfor img in image_list:\n    image = mpimg.imread(os.path.join(train_img_path, img))\n    brightness = get_brightness(image)\n    brightness_array.append(brightness)\n\ndf = pd.DataFrame({'image_id': image_list,\n                         'brightness': brightness_array})","70210052":"df.head()","bf1e7340":"#bright ids\nbright_ids = df[df['brightness'] > 130].image_id\nplot_imgs(train, bright_ids[0:6], bbox = True)","ce57fc92":"#dark ids\ndark_ids = df[df['brightness'] < 24].image_id\nplot_imgs(train, dark_ids, bbox = True)","dd7d94e3":"print('Mean Brightness is: ', df['brightness'].mean())","83243478":"print('Max Brightness is: ', df['brightness'].max())","59562e73":"print('Min Brightness is: ', df['brightness'].min())","319aeae5":"plt.hist(df['brightness'])","b0efca66":"#getting boxes per image\nbox_count = []\nfor img in image_list:\n    _, count = get_all_bboxes(train, img, count = True)\n    box_count.append(count)\n    \ndf['count'] = box_count","11e09a9e":"df.head()","49283686":"#more boxes\nmore_ids = df[df['count'] > 95].image_id\nplot_imgs(train, more_ids[0:8], bbox = True)","ffbf663e":"#less ids \nless_ids = df[df['count']<10].image_id\nplot_imgs(train, less_ids[0:8], bbox = True)","ef8da166":"print('Mean box count is: ', df['count'].mean())","3ce63ef5":"print('Max box count is: ', df['count'].max())","79cae076":"print('Min box count is: ', df['count'].min())","1b868ebd":"plt.hist(df['count'])","32d24127":"#describing transforms and the probability of their application \ntransforms = alb.Compose([\n    alb.HorizontalFlip(p = 0.5),\n    alb.VerticalFlip(p = 0.5),\n    alb.RandomBrightness(p = 0.2),\n    alb.RandomContrast(p = 0.2),\n    alb.CLAHE(p = 0.5),\n    alb.RandomSizedBBoxSafeCrop(512, 512, erosion_rate = 0.0, interpolation = 1, p = 0.5),\n], p=1.0, bbox_params=alb.BboxParams(format='coco', label_fields=['category']))","d38e3ef1":"def apply(transforms, df, n_transforms = 5):\n    '''function to apply and view transforms'''\n    #randomly choose an image\n    img_id = select_img(4) \n    bboxes = get_all_bboxes(df, img_id[3])\n    fig,ax = plt.subplots(1, n_transforms + 1, figsize = (40,30))\n    image = mpimg.imread(os.path.join(train_img_path, img_id[3]))\n    ax[0].imshow(image)\n    ax[0].set_title('Original')\n    ax[0].axis('off')\n    for bbox in bboxes:\n        rect = patches.Rectangle((bbox[0],bbox[1]),bbox[2],bbox[3],linewidth=2,edgecolor='r',facecolor='none')\n        ax[0].add_patch(rect)\n    \n    #apply transforms one by one and plot\n    for i in range(n_transforms):\n        parameters = {\n            'image': np.asarray(image),\n            'bboxes': bboxes,\n            'category': np.ones(len(bboxes))\n        }\n        augmented = transforms(**parameters)\n        boxes_aug = augmented['bboxes']\n        image_aug = augmented['image']\n        ax[i+1].imshow(image_aug)\n        ax[i+1].axis('off')\n        ax[i+1].set_title('augmented ' + str(i + 1))\n        for bbox in boxes_aug:\n            rect = patches.Rectangle((bbox[0],bbox[1]),bbox[2],bbox[3],linewidth=2,edgecolor='r',facecolor='none')\n            ax[i+1].add_patch(rect)\n    plt.tight_layout()\n    plt.show()","ce94b71b":"apply(transforms, train)","a808dbd6":"apply(transforms, train, 4)","71bcafac":"Most of these boxes look alright :), however a small fraction of them are nothing but tiny specks. ","5962189a":"## Plotting training images with bounding boxes","d30de8ed":"## Plotting images which don't have wheat heads in them","d2cc9d12":"## Plotting some training images...","7cd3fa74":"Link to the training notebook <a href = \"https:\/\/www.kaggle.com\/daenys2000\/fasterrcnn-pytorch\">Faster RCNN<\/a>","2ccc7f81":"## Visualising the differences in box sizes\nThe difference in the maximum box are and minimum box area is huge! There are definitely some anomaly boxes which must be removed during training","9fe5cc08":"## Number of boxes on an image?","3079fc52":"## Sources","c9b66780":"Data Augmentation is needed because the dataset is small, data augmentation would enable us to train a more robust model.Using the albumentations library, it is easy to augment data for object detection tasks","2313c5da":"Some of these boxes are huge and aren't correct, they must be removed while training","525ce03d":"this implies that images with no objects are not in the dataframe","9de8aece":"## Visualising the difference in brightness of the image\nSome images are quite dark, and some are quite bright. Let's see how extreme these ends go."}}