{"cell_type":{"f524bedd":"code","b99dec12":"code","8e732893":"code","7bd67e5e":"code","57191d2d":"code","70bd424b":"code","2e1228b1":"code","1c56cd32":"code","aa3ca226":"code","b4aebb7f":"code","b57bbe75":"code","93115c8e":"code","c9ed42dc":"code","7cfe827b":"code","8e9ac6a4":"code","22d04239":"code","a1dcd1a2":"code","546f37a0":"code","5458a60e":"code","705f97bc":"markdown","ac7691c1":"markdown","00b6b1f1":"markdown","350cb412":"markdown","7638be35":"markdown"},"source":{"f524bedd":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b99dec12":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns # seaborne is a package built on top of matplotlib.\nsns.set() # activate seaborn to override all the matplotlib graphics\n\nimport statsmodels.api as sm","8e732893":"raw_df = pd.read_csv(\"..\/input\/star-categorization-giants-and-dwarfs\/Star39552_balanced.csv\")\nraw_df","7bd67e5e":"df = raw_df[['B-V', 'Amag', 'TargetClass']]\ndf","57191d2d":"df.describe(include='all')","70bd424b":"# Select Target\ny = df['TargetClass']\n\n# Select Features\nx = df[['B-V','Amag']]","2e1228b1":"# Splitting the data into train dataset and test dataset\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state=0)","1c56cd32":"# Data normalization\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()","aa3ca226":"x_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","b4aebb7f":"from sklearn.linear_model import LogisticRegression\n\nstar_predictor = LogisticRegression(random_state=0)","b57bbe75":"# Start model training\nstar_predictor.fit(x_train, y_train)","93115c8e":"print('the score on train dataset is') \nprint(star_predictor.score(x_train, y_train))","c9ed42dc":"y_pred = star_predictor.predict(x_test)","7cfe827b":"# Confusion Matrix\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix : \\n\", cm)\n\n","8e9ac6a4":"# Model evaluation\n\nfrom sklearn.metrics import accuracy_score\n\nprint(\"Accuracy : \", accuracy_score(y_test, y_pred))","22d04239":"star_predictor.coef_","a1dcd1a2":"star_predictor.intercept_","546f37a0":"#Make Prediction\n\nfeature = [[1.130,15.792525]]\n\nstar_predictor.predict(feature)  # Target Class is 0 -> Dwarf","5458a60e":"#Make Prediction\n\nfeature = [[0.227,17.159748]]\n\nstar_predictor.predict(feature)  # Target Class is 1 -> Giant","705f97bc":"That's it! You can try to play with the Dataset and try to improve the score.","ac7691c1":"# Select Features\n\nIn the Previous notebook I have already picked Amag and B-V as Selected Features, so let's drop the unwanted features.","00b6b1f1":"# Simple Logistic Regression on StarDataset\n\nIn this notebook, I will try to perform a Simple Logistic Regression on this Star Dataset.\n\nI use this Notebook just to give you some idea on how to play with this dataset.\n\nWe will use some simple features to predict if a star is giant or dwarfs.\n\nPrevious Notebook:\n[Preprocessing the StarDataset](https:\/\/www.kaggle.com\/vinesmsuic\/preprocessing-the-stardataset)\n\nDataSet Link:\n[Star Dataset: Stellar Classification [Beginner]](https:\/\/www.kaggle.com\/vinesmsuic\/star-categorization-giants-and-dwarfs)","350cb412":"* Vmag - Visual Apparent Magnitude of the Star\n* Plx - Distance Between the Star and the Earth\n* e_Plx - Standard Error of Plx (Drop the Row if you find the e_Plx is too high!)\n* B-V - B-V color index. (A hot star has a B-V color index close to 0 or negative, while a cool star has a B-V color index close to 2.0. Other stars are somewhere in between.)\n* SpType - Stellar classification. (Roman Numerals >IV are giants. Otherwise are dwarfs)\n* Amag - Absolute Magnitude of the Star.\n* TargetClass - Whether the Star is Dwarf (0) or Giant (1)\n","7638be35":"Use a Logistic Regression From Sklearn"}}