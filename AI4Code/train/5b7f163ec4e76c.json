{"cell_type":{"c6f806e9":"code","15e51879":"code","4176b33e":"code","98afd5ca":"code","74586ad1":"code","19a205b2":"code","fd96e717":"code","e83c69d9":"code","c12a52bb":"code","af7cb19f":"code","6ca17219":"code","ca516a60":"code","b861f685":"code","f0329865":"code","c8706aec":"code","af8e030b":"code","84599135":"code","05fcfb82":"code","926af8a6":"code","2827cb53":"code","321483d0":"code","9ae20d0d":"code","0601fbaa":"code","f5612b26":"markdown","80335069":"markdown"},"source":{"c6f806e9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","15e51879":"import matplotlib.pyplot as plt\nimport pandas_datareader as web\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nimport math","4176b33e":"df = pd.read_csv('\/kaggle\/input\/tesla-stock-price\/Tesla.csv - Tesla.csv.csv')","98afd5ca":"df.info()","74586ad1":"df['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date',inplace=True)","19a205b2":"df.shape #1692 rows and 7 columns that the data frame have ","fd96e717":"#plotting the data\nplt.figure(figsize=(16,8))\nplt.title('Close Price History')\nplt.plot(df['Close'], color='red')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD', fontsize = 18)\nplt.show()","e83c69d9":"# create a new data frame with only 'Close column'\ndata = df.filter(['Close'])\ndataset = data.values #convert the data frame to a numpy array\ntraining_data_len = math.ceil(len(dataset)*.8)  # number of rows to train the model on\ntraining_data_len","c12a52bb":"#scale the data\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\nscaled_data","af7cb19f":"#create the training dataset\n#create the scaled training dataset\n\ntrain_data = scaled_data[0:training_data_len, :]\n#Split the data into x_train, y_train datasets\nx_train = []\ny_train = []\nfor i in range(60,len(train_data)):\n    x_train.append(train_data[i-60:i, 0])\n    y_train.append(train_data[i,0])\n    if i<=60:\n        print(x_train)\n        print(y_train)\n        print()","6ca17219":"#convert the x_train and y_train  to numppy array\nx_train,y_train = np.array(x_train), np.array(y_train)","ca516a60":"#reshape the data\nx_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))\nx_train.shape","b861f685":"#Buil the LSTM model\nmodel =Sequential()\nmodel.add(LSTM(50,return_sequences=True, input_shape=(x_train.shape[1],1)))\nmodel.add(LSTM(50, return_sequences= False))\nmodel.add(Dense(25))\nmodel.add(Dense(1))","f0329865":"#Complie the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')","c8706aec":"#Train the model\nmodel.fit(x_train,y_train, batch_size=1, epochs=10)","af8e030b":"#create the testing data sets\n#create a new array containing scale values from index 1543 to 2003\ntest_data= scaled_data[training_data_len-60:, :]\n#create the data sets x_test and y_test\nx_test = []\ny_test = dataset[training_data_len:,:]\nfor i in range(60,len(test_data)):\n    x_test.append(test_data[i-60:i,0])","84599135":"#convert the data to a numpy array\nx_test = np.array(x_test)","05fcfb82":"#reshape the data\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1],1))\nx_test.shape","926af8a6":"#predicting the data\npredictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)","2827cb53":"#get the root mean square error(RMSE)\nrmse = np.sqrt(np.mean(predictions - y_test)**2)\nrmse","321483d0":"#plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Predictions'] = predictions\n#Visialization the data\nplt.figure(figsize=(16,8))\nplt.title('Model')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price' ,fontsize=18)\nplt.plot(train['Close'],linewidth=3.5)\nplt.plot(valid[['Close','Predictions']],linewidth=3.5)\nplt.legend(['Train','Valid','Predictions'], loc='upper_center')","9ae20d0d":"#show the valid and predicted price\nvalid","0601fbaa":"#get the quote\ntesla_quote = pd.read_csv('\/kaggle\/input\/tesla-stock-price\/Tesla.csv - Tesla.csv.csv')\n#Create new data frame\nnew_df = tesla_quote.filter(['Close'])\n#get the last 60 days closing price values and convert the dataframe to an array\nlast_60_days = new_df[-60:].values\n#scaled the data to be values between 0 and 1\nlast_60_days_scaled = scaler.transform(last_60_days)\n#create an empty list\nX_test = []\n#append the past 60 days \nX_test.append(last_60_days_scaled)\n#convert the X_test data set to a numpy array\nX_test = np.array(X_test)\n#Reshape the data\nX_test = np.reshape(X_test,(X_test.shape[0], X_test.shape[1],1))\n#get the predicted scaled price\npred_price= model.predict(X_test)\n#undo the scalling\npred_price = scaler.inverse_transform(pred_price)\npred_price","f5612b26":"If you like it please vote:)","80335069":"Today, We will predict tesla stock price. Let's start!"}}