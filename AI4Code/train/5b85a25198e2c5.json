{"cell_type":{"811288a3":"code","4df32105":"code","7d467679":"code","1a2b20af":"code","acc8f848":"code","b6af7c85":"code","a3ae4b4a":"code","28253a76":"code","d6f1b504":"code","5d2ded84":"code","9f53b968":"code","cb87e6e0":"code","d0116e01":"code","1ffb9dcc":"code","12f3ea08":"code","8613f448":"code","182a1270":"code","b5fc1243":"code","27a980da":"code","4ddd4053":"code","5de784fd":"code","4c52560d":"code","e9d3385c":"code","11c07037":"markdown","5e4da338":"markdown","06b78614":"markdown","9b5258fb":"markdown","144ed0c0":"markdown","ecdc6261":"markdown","3182777c":"markdown","a2f93a8f":"markdown","56a5daa0":"markdown","7c53a03c":"markdown","c695b5a7":"markdown","fbc061f8":"markdown","17a28e9a":"markdown","44aa9311":"markdown","2427369e":"markdown","da2b5645":"markdown","fb4b01d2":"markdown","d72ca5fc":"markdown"},"source":{"811288a3":"# Data Manipulation and Linear Algebra\nimport pandas as pd\nimport numpy as np\n\n# Plots\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nimport matplotlib.pyplot as plt\n\n# Machine Learning\nfrom sklearn.model_selection import StratifiedShuffleSplit, cross_val_score, cross_val_predict\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn import linear_model, neighbors, ensemble, tree\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore')","4df32105":"data = pd.read_csv(\"..\/input\/clothessizeprediction\/final_test.csv\")\ndata","7d467679":"data.isnull().sum()","1a2b20af":"data[[\"size\"]].value_counts()","acc8f848":"plt.figure(figsize=(10, 6), dpi=80)\nsns.countplot(y=data[\"size\"])\nplt.show()","b6af7c85":"data.describe()","a3ae4b4a":"data[\"age\"] = data[\"age\"].replace(0, np.nan)\ndata[\"age\"] = data[\"age\"].fillna(data[\"age\"].median())","28253a76":"data[data[\"size\"] == \"XXL\"].isnull().sum()","d6f1b504":"data.dropna(inplace=True)\ndata.isnull().sum()","5d2ded84":"data.reset_index(drop=True, inplace=True)","9f53b968":"fig, axes = plt.subplots(figsize=(20, 10), nrows=3, ncols=3)\n\ncolors = [\"#5bde54\",\"#de5454\", \"#db53d5\"]\n\n# Histograms\ncol_no = 0\nfor col in data.columns[:-1]:\n    sns.histplot(x=col, data=data, ax=axes[0, col_no], bins=20, color=colors[col_no])\n    sns.kdeplot(x=col, data=data, ax=axes[1, col_no], color=colors[col_no])\n    sns.boxplot(x=col, data=data, ax=axes[2, col_no], color=colors[col_no])\n    col_no += 1","cb87e6e0":"data[\"size\"].value_counts()","d0116e01":"labels = list(data[\"size\"].value_counts().index)\n\nplt.figure(figsize=(6, 8), dpi=80)\nplt.pie(data[\"size\"].value_counts(), autopct='%.1f%%', labels=labels)\nplt.title(\"Distribution of Size\")\nplt.show()","1ffb9dcc":"plt.figure(figsize=(8, 6), dpi=80)\nsns.heatmap(data.corr(), annot=True)\nplt.show()","12f3ea08":"data[\"height_bins\"] = pd.qcut(data[\"height\"], q=6)\ndata[\"weight_bins\"] = pd.qcut(data[\"weight\"], q=10)\ndata[\"age_bins\"] = pd.qcut(data[\"age\"], q=10)\n\ndata.drop([\"weight\", \"age\", \"height\"], axis=1, inplace=True)\ndata","8613f448":"split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(data, data['size']):\n    train = data.loc[train_index]\n    test = data.loc[test_index]","182a1270":"train.shape, test.shape","b5fc1243":"X_train = train.drop(\"size\", axis=1)\ny_train = train[\"size\"]\n\nX_test = test.drop(\"size\", axis=1)\ny_test = test[\"size\"]","27a980da":"X_train = pd.get_dummies(X_train).values\nX_test = pd.get_dummies(X_test).values","4ddd4053":"MLA_compare = pd.DataFrame()\n\ndef MLA_testing(MLA, X_train, X_test):\n    row_index = 0\n    for classifier in MLA:\n        # Training The Model\n        classifier.fit(X_train, y_train)\n\n        # KFold Accuracies on Training Data\n        kfold_accuracy = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs=-1)\n        \n        # Prediction on Testing Data\n        y_pred = cross_val_predict(estimator = classifier, X = X_test, y = y_test, cv = 10, n_jobs=-1)\n        \n        # Accuracy for y_test and y_pred\n        classifier_accuracy_score = accuracy_score(y_test, y_pred)\n\n        # Saving Data in Dataframe\n        MLA_name = classifier.__class__.__name__\n        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n        MLA_compare.loc[row_index, 'Accuracy Score'] = classifier_accuracy_score*100\n        MLA_compare.loc[row_index, 'K-Fold Accuracy'] = kfold_accuracy.mean()*100\n\n        print(MLA_name, \"Done\")\n        row_index+=1","5de784fd":"MLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.RandomForestClassifier(n_jobs=-1),\n    \n    #GLM\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(n_jobs=-1),\n\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n]\n\nMLA_testing(MLA=MLA, X_train=X_train, X_test=X_test)","4c52560d":"MLA_compare = MLA_compare.sort_values(by=\"Accuracy Score\", ascending=False).reset_index(drop=True)\nMLA_compare","e9d3385c":"xgb_clf = tree.DecisionTreeClassifier()\n\n# Training the XGBClassifier\nxgb_clf.fit(X_train, y_train)\n\n# KFold Accuracy Score\nkfold_accuraies = cross_val_score(xgb_clf, X_train, y_train, cv=10, n_jobs=-1)\nprint(\"KFold Accuracies:\", kfold_accuraies)\nprint(\"Mean KFold Accuracy:\", kfold_accuraies.mean())\n\n# Predicting Size for Testing Data\ny_pred = cross_val_predict(xgb_clf, X_test, y_test, cv=10, n_jobs=-1)\nprint(y_pred)\n\n# Accuracy Score\nprint(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n\n# Confusion Matrix\nplt.figure(figsize=(12, 8), dpi=80)\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\")\nplt.show()","11c07037":"# Machine Learning - Multiple Model Testing","5e4da338":"## Comparing Models","06b78614":"# Preparing Data","9b5258fb":"## Bining all Features","144ed0c0":"# Using DecisionTreeClassifier","ecdc6261":"# Loading Data","3182777c":"## Dropping Records with Null Values\n#### Since we have a lot of data we can safely drop records with null values","a2f93a8f":"## Dataframe to store all the accuracy scores for Comparison and Analysis","56a5daa0":"# Import Necessary Libraries","7c53a03c":" - As You can observe from Box Plot there are a lot of outliers \n - Weight and Age of People is right skewed","c695b5a7":"## Stratified Train Test Split\n### Evenly Spreading the Dependent Variable \"size\" in train and test set","fbc061f8":"## Reseting the Index","17a28e9a":"#### Age cannot be 0 so replacing age == 0 with np.nan","44aa9311":"## Checking for Null values","2427369e":"# Preprocessing","da2b5645":"## Checking for null values for XXL size","fb4b01d2":"## OneHotEncoding","d72ca5fc":"# EDA"}}