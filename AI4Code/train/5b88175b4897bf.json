{"cell_type":{"cdce9c2d":"code","f738db87":"code","bbeb494e":"code","05be9550":"code","d765cc8a":"code","58128130":"code","7879942c":"code","56bcbd84":"code","c89d18b8":"code","187b7d89":"code","df7242a3":"code","c5d225b2":"code","7014ab27":"code","f0077d13":"code","74bde700":"code","0f448e4e":"code","78e7e711":"code","419f3891":"code","369e11aa":"code","4307f467":"code","aa6ce431":"code","f8d76b08":"code","c0bc2a63":"code","0689f9f0":"code","01df970f":"code","38d909b0":"code","91c8aff1":"code","2fa70bb9":"code","b9944002":"code","5a71c85e":"code","3ad8df91":"code","91fdfc81":"code","96622b70":"markdown","e6c93f99":"markdown","51ba6a75":"markdown","f44e33f7":"markdown","53c91250":"markdown","e6fd1d79":"markdown","31098349":"markdown","5b54d86d":"markdown","65706513":"markdown","73c94170":"markdown"},"source":{"cdce9c2d":"gpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\nif gpu_info.find('failed') >= 0:\n  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator,')\n  print('and then re-execute this cell.')\nelse:\n  print(gpu_info)","f738db87":"from google.colab import drive\ndrive.mount('\/content\/drive', force_remount=True)","bbeb494e":"from psutil import virtual_memory\nram_gb = virtual_memory().total \/ 1e9\nprint('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n\nif ram_gb < 20:\n  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n  print('re-execute this cell.')\nelse:\n  print('You are using a high-RAM runtime!')","05be9550":"import zipfile\nwith zipfile.ZipFile('\/content\/drive\/MyDrive\/Retinal_Disease\/retinal_disease.zip', 'r') as zip_ref:\n    zip_ref.extractall('\/content')","d765cc8a":"import sys\nprint(sys.executable)\nprint(sys.version)\nprint(sys.version_info)","58128130":"#Importation of packages and datasets\nimport os \nfrom tqdm import tqdm\nfrom glob import glob\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport numpy as np\nimport tensorflow as tf\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\n\nprint(os.getcwd())\npath_cwd = os.getcwd()\n\nX_train = pd.read_csv('\/content\/Training_Labels.csv')\nX_val = pd.read_csv('\/content\/Validation_Labels.csv')\nX_test = pd.read_csv('\/content\/Test_Labels.csv')","7879942c":"X_train.head()","56bcbd84":"X_train.describe()\n#No missing value","c89d18b8":"#reconstituion link image + drop ID feature\nX_train['filename'] = X_train.apply(lambda x : \"\/content\/Training\/\" +str(x['ID']) + \".png\", axis=1)\nX_val['filename'] = X_val.apply(lambda x : \"\/content\/Validation\/\" +str(x['ID']) + \".png\", axis=1)\nX_test['filename'] = X_test.apply(lambda x : \"\/content\/Test\/\" +str(x['ID']) + \".png\", axis=1)\n\nX_train = X_train.drop('ID', axis=1)\nX_val = X_val.drop('ID', axis=1)\nX_test = X_test.drop('ID', axis=1)","187b7d89":"print(X_train.head(1))\nprint(X_train.shape)\n#46 class + risk evaluation (47 features)","df7242a3":"#datasets\nX_train_img = X_train['filename']\nX_val_img = X_val['filename']\ny_train = X_train.drop(['filename'], axis=1)\ny_val = X_val.drop(['filename'], axis=1)\n\nprint('shape of X_train:', X_train_img.shape)\nprint('shape of Validation:', X_val_img.shape)\nprint('shape of y_train:', y_train.shape)\nprint('shape of y_val:', y_val.shape)","c5d225b2":"#Plot some random images\nimport cv2\nimport random\ndef plotImages():\n    i=1\n    plt.figure(figsize=(15,10))\n    for r in random.sample(glob(path_cwd + '\/Training\/**'), 15):\n      plt.subplot(3,5,i)\n      img = cv2.imread(r)\n      img = tf.reverse(img, axis=[-1])\n      img =  tf.image.adjust_contrast(img, 1.5)\n      plt.imshow(img)\n      i+=1\n      plt.axis('off')","7014ab27":"plotImages() #Seems we have to convert to RGB format","f0077d13":"IMG_SHAPE = (300, 450)\nBATCH_SIZE = 64","74bde700":"@tf.function\n\n#Fonction pour prprocessing des images\ndef scale_down(img):\n    img = tf.cast(img, dtype=tf.float32)\n    img = tf.image.resize(img, (300, 450), method='nearest')\n    img = (img \/ 255)\n    \n    return img\n\n#Preprocessing du jeu d'entrainement\ndef preprocessing_data(img):\n   \n    #Lecture et d\u00e9codage des images:\n    img = tf.io.read_file(img)\n    img = tf.io.decode_png(img, channels=3)\n\n    #adjust contrast\n    img =  tf.image.adjust_contrast(img, 1.35)\n\n    #Resize\n    img = scale_down(img)\n\n    return img\n","0f448e4e":"#Datasets preprocessing\nAUTO = tf.data.experimental.AUTOTUNE\n\ny_train = np.array(y_train).astype('float32')\ny_val = np.array(y_val).astype('float32')\n\ndataset_train = tf.data.Dataset.from_tensor_slices((X_train_img, y_train))\ndataset_val = tf.data.Dataset.from_tensor_slices((X_val_img, y_val))\n\ndataset_train=(dataset_train\n               .shuffle(1000)\n               .map(lambda x, y: [preprocessing_data(x), y], num_parallel_calls=AUTO)\n               .batch(BATCH_SIZE, drop_remainder=True)\n               .prefetch(AUTO)\n               )\n\ndataset_val=(dataset_val\n             .map(lambda x, y: [preprocessing_data(x), y], num_parallel_calls=AUTO)\n             .batch(BATCH_SIZE, drop_remainder=True)\n             .prefetch(AUTO)\n             )\n\n\nprint(dataset_train)\nprint(dataset_val)","78e7e711":"def visualize(original, augmented):\n    fig = plt.figure()\n    plt.subplot(1,2,1)\n    plt.title('Original image')\n    plt.imshow(original)\n    plt.axis('off')\n\n    plt.subplot(1,2,2)\n    plt.title('Augmented image')\n    plt.imshow(augmented)\n    plt.axis('off')\n","419f3891":"image, label = next(iter(dataset_train))\nimage, label = image.numpy()[0], label.numpy()[0]\n\n\nflipped = tf.image.flip_left_right(image)\nflipped =  tf.image.adjust_contrast(flipped, 1.35)\nvisualize(image, flipped)","369e11aa":"#API keras preparation\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, Dropout, BatchNormalization, Activation, MaxPool2D, Dense, Flatten, GlobalAvgPool2D\nfrom keras import backend as K\nfrom tensorflow.keras.applications import VGG16\nvgg16 = VGG16()\n\n#for layer in xception.layers:\n#    print(layer.name, layer)","4307f467":"shape = (250, 400,3)\n\ndef Layers(inputs, trainable=False):\n    global vgg16_model\n    vgg16_model = VGG16(weights='imagenet',\n                        include_top=False,\n                        input_tensor=inputs)\n    \n    if trainable == True:\n        for layer in vgg16_model.layers:\n            layer.trainable = True\n            \n    else:\n        vgg16_model.trainable = False\n            \n    return vgg16_model.output\n    \n        \ndef Build_VGG16(trainable=False):\n    \n    inputs = Input(shape=shape)\n    vgg16 = Layers(inputs, trainable)\n\n    conv1 = Flatten()(vgg16_model.output)\n    \n    dense2 = Dense(256,activation='relu')(conv1)\n    dense2 = Dropout(rate=0.2)(dense2)\n    \n    dense3 = Dense(128,activation='relu')(dense2)\n    dense3 = Dropout(rate=0.2)(dense3)\n    \n    model = Dense(46,activation= 'sigmoid')(dense3)\n    \n    return Model(inputs=inputs, outputs = model)\n\nmodel = Build_VGG16()\nmodel.summary()","aa6ce431":"class LossLearningRateScheduler(tf.keras.callbacks.History):\n    \"\"\"\n    base_lr: the starting learning rate\n    lookback_epochs: the number of epochs in the past to compare with the loss function at the current epoch to determine if progress is being made.\n    decay_threshold \/ decay_multiple: if loss function has not improved by a factor of decay_threshold * lookback_epochs, then decay_multiple will be applied to the learning rate.\n    spike_epochs: list of the epoch numbers where you want to spike the learning rate.\n    spike_multiple: the multiple applied to the current learning rate for a spike.\n    \"\"\"\n\n    def __init__(self, base_lr, lookback_epochs, spike_epochs = None, spike_multiple = 10, decay_threshold = 0.002, decay_multiple = 0.7, loss_type = 'val_loss'):\n\n        super(LossLearningRateScheduler, self).__init__()\n        self.base_lr = base_lr\n        self.lookback_epochs = lookback_epochs\n        self.spike_epochs = spike_epochs\n        self.spike_multiple = spike_multiple\n        self.decay_threshold = decay_threshold\n        self.decay_multiple = decay_multiple\n        self.loss_type = loss_type\n\n\n    def on_epoch_begin(self, epoch, logs=None):\n\n        if len(self.epoch) > self.lookback_epochs:\n            current_lr = tf.keras.backend.get_value(self.model.optimizer.lr)\n            target_loss = self.history[self.loss_type] \n            loss_diff =  target_loss[-int(self.lookback_epochs)] - target_loss[-1]\n\n\n            if loss_diff <= np.abs(target_loss[-1]) * (self.decay_threshold * self.lookback_epochs):\n                print(' '.join(('Changing learning rate from', str(current_lr), 'to', str(current_lr * self.decay_multiple))))\n                tf.keras.backend.set_value(self.model.optimizer.lr, current_lr * self.decay_multiple)\n                current_lr = current_lr * self.decay_multiple\n\n            else:\n                print(' '.join(('Learning rate:', str(current_lr))))\n\n            if self.spike_epochs is not None and len(self.epoch) in self.spike_epochs:\n                print(' '.join(('Spiking learning rate from', str(current_lr), 'to', str(current_lr * self.spike_multiple))))\n                tf.keras.backend.set_value(self.model.optimizer.lr, current_lr * self.spike_multiple)\n\n        else:\n            print(' '.join(('Setting learning rate to', str(self.base_lr))))\n            tf.keras.backend.set_value(self.model.optimizer.lr, self.base_lr)\n\n        return tf.keras.backend.get_value(self.model.optimizer.lr)\n\ncallback_lr = LossLearningRateScheduler(base_lr=0.001, lookback_epochs=2)","f8d76b08":"#Re-Weighting classes binary crossentropy\n\ndef dyn_weighted_bincrossentropy(true, pred):\n\n    # get the total number of inputs\n    num_pred = K.sum(K.cast(pred < 0.5, true.dtype)) + K.sum(true)\n    # get weight of values in 'pos' category\n    zero_weight =  K.sum(true)\/ num_pred +  K.epsilon() \n    # get weight of values in 'false' category\n    one_weight = K.sum(K.cast(pred < 0.5, true.dtype)) \/ num_pred +  K.epsilon()\n    # calculate the weight vector\n    weights =  (1.0 - true) * zero_weight +  true * one_weight \n    # calculate the binary cross entropy\n    bin_crossentropy = K.binary_crossentropy(true, pred)\n    # apply the weights\n    weighted_bin_crossentropy = weights * bin_crossentropy \n\n    return K.mean(weighted_bin_crossentropy)\n\n\ndef weighted_bincrossentropy(true, pred, weight_zero = 0.25, weight_one = 1):\n\n    # calculate the binary cross entropy\n    bin_crossentropy = K.binary_crossentropy(true, pred)\n    # apply the weights\n    weights = true * weight_one + (1. - true) * weight_zero\n    weighted_bin_crossentropy = weights * bin_crossentropy \n\n    return K.mean(weighted_bin_crossentropy)","c0bc2a63":"from tensorflow.keras.metrics import AUC\npr_metric = AUC(curve='PR', num_thresholds=5000, from_logits=True, name='pr_metric') # The higher the threshold value, the more accurate it is calculated.\nroc_metric = AUC(curve='ROC', num_thresholds=5000, from_logits=True, name='roc_metric') \n","0689f9f0":"model.compile(loss=dyn_weighted_bincrossentropy,\n              optimizer =tf.keras.optimizers.Adam(),\n              metrics= [roc_metric, pr_metric])\n\n#weighted_binary_crossentropy","01df970f":"tf.keras.utils.plot_model(model, 'retinal_output_model.png', show_shapes=True, dpi=100)","38d909b0":"history = model.fit(dataset_train,\n                    validation_data=dataset_val,\n                    epochs=15, \n                    verbose=1, \n                   callbacks=callback_lr)","91c8aff1":"from keras.models import model_from_json\n\nmodel_archtecture = model.to_json()\n\nwith open('retinal_model.json', 'w') as json_file:\n    json_file.write(model_archtecture)\n\nmodel.save('.\/retinal_model')\nmodel.save_weights('.\/retinal_model.h5')","2fa70bb9":" !zip -r \/content\/retinal_model.zip \/content\/retinal_model","b9944002":"#preparation and preprocesing\nX_test_path = X_test['filename']\ny_test = X_test.drop(['filename'], axis=1)\ny_test = np.array(y_test).astype('float32')\n\nprint('shape of X_test:', X_test_img.shape)\nprint('shape of y_test:', y_test.shape)\n\nX_test_img  = []\nfor filepath in tqdm(X_test_path):\n\n  #Read and decode\n  img = tf.io.read_file(filepath)\n  img = tf.io.decode_png(img, channels=3)\n\n  #adjust contrast\n  img =  tf.image.adjust_contrast(img, 1.5)\n\n  #Resize\n  img = scale_down(img)\n  X_test_img.append([img])\n","5a71c85e":"#transform to array numpy\nX_test_img = np.array(X_test_img)\nX_test_img = X_test_img[:,0,:,:]\nX_test_img.shape","3ad8df91":"y_pred = model.predict(X_test_img)","91fdfc81":"from sklearn.metrics import roc_auc_score\n\nauc_scores = []\nfor i in range(46):\n  try:\n    auc = roc_auc_score(y_test[:,i], y_pred[:,i])\n    auc_scores.append(auc)\n  except:\n    pass\n\n\ndef Average(lst):\n    return sum(lst) \/ len(lst)\n  \navg_auc = Average(auc_scores)\n  \n# Printing average of the list\nprint(\"Average auc score available classes =\", round(avg_auc, 2),'%')","96622b70":"## Global architecture VGG16:\n________________________________________________________________________________\n<img src=\"https:\/\/datascientest.com\/wp-content\/uploads\/2021\/04\/illu_VGG-02.png\" alt=\"data2\" align=\"top\" style=\"width: 800px;\">\n","e6c93f99":"## Preprocessing images","51ba6a75":"**Packages and data preprocessing**","f44e33f7":"**Notebook and GPU preparation with Google Colab**","53c91250":"```\nfrom keras.utils.data_utils import Sequence\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.tensorflow import balanced_batch_generator\n\n\nclass BalancedDataGenerator(Sequence):\n    \"\"\"ImageDataGenerator + RandomOversampling\"\"\"\n    def __init__(self, x, y, datagen, batch_size=64):\n        self.datagen = datagen\n        self.batch_size = min(batch_size, x.shape[0])\n        datagen.fit(x)\n        self.gen, self.steps_per_epoch = balanced_batch_generator(x.reshape(x.shape[0], -1), y, sampler=RandomOverSampler(), batch_size=self.batch_size, keep_sparse=True)\n        self._shape = (self.steps_per_epoch * batch_size, *x.shape[1:])\n        \n    def __len__(self):\n        return self.steps_per_epoch\n\n\n    def __getitem__(self, idx):\n        x_batch, y_batch = self.gen.__next__()\n        x_batch = x_batch.reshape(-1, *self._shape[1:])\n        return self.datagen.flow(x_batch, y_batch, batch_size=self.batch_size).next()\n\nbalanced_gen = BalancedDataGenerator(X_train_path, y_train, train_generator, batch_size=64)\n#balanced_gen_val = BalancedDataGenerator(X_val, y_val, train_generator, batch_size=64)\nsteps_per_epoch = balanced_gen.steps_per_epoch\n\n```\n\n","e6fd1d79":"\n\n*   use a LR function to adapt Gradient\n*   Class imbalanced, we create a loss fonction to adjust weight \n\n","31098349":"<img src=\"https:\/\/i.ibb.co\/pxFk0TG\/composition.jpg\" alt=\"data\" style=\"width: 300px;\">","5b54d86d":"## Predictions and ROC\/PR curves on X_test","65706513":"## Retinal Multi Disease Classification\n<img src=\"https:\/\/i.ibb.co\/6szKmbL\/Folder-Organisation.jpg\" alt=\"data\" style=\"width: 800px;\">","73c94170":"## Classification model"}}