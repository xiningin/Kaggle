{"cell_type":{"89db19f2":"code","e7ef3d87":"code","891303ad":"code","f3ca7eff":"code","63dcdee2":"code","73dd0191":"code","82a1958c":"code","dc767aea":"code","aed59428":"code","2d6b8c50":"code","12d1b47a":"code","0a13237c":"code","9a836bca":"code","a0f62a84":"code","e8dba9f4":"code","dfe4908e":"code","e213c285":"code","60b69c92":"code","9e720898":"code","ee9aa5ef":"code","546ec606":"code","79a6ac71":"code","785e3e9b":"code","ca303d00":"code","7235d021":"markdown","1aef785b":"markdown","be1cfb05":"markdown","c6a72d67":"markdown","054db75e":"markdown","6af7382a":"markdown","12c9f1e8":"markdown","c56fb957":"markdown","4f4cf21a":"markdown","ca4d4d3c":"markdown","2d24990b":"markdown","9f301cf6":"markdown","3865fa17":"markdown","3d386c4e":"markdown","87acd52c":"markdown","eed2d264":"markdown","64b7d3a2":"markdown","03a8f082":"markdown","efe10a58":"markdown","5967fefc":"markdown","732c7738":"markdown"},"source":{"89db19f2":"import tensorflow.compat.v1 as tf\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nfrom scipy.io import loadmat\nimport os\nfrom pywt import wavedec\nfrom functools import reduce\nfrom scipy import signal\nfrom scipy.stats import entropy\nfrom scipy.fft import fft, ifft\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow import keras as K\nimport matplotlib.pyplot as plt\nimport scipy\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold,cross_validate\nfrom tensorflow.keras.layers import Dense, Activation, Flatten, concatenate, Input, Dropout, LSTM, Bidirectional,BatchNormalization,PReLU,ReLU,Reshape\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.models import Sequential, Model, load_model\nimport matplotlib.pyplot as plt;\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.decomposition import PCA\nfrom tensorflow import keras\nfrom sklearn.model_selection import cross_val_score\nfrom tensorflow.keras.layers import Conv1D,Conv2D,Add\nfrom tensorflow.keras.layers import MaxPool1D, MaxPooling2D\nimport seaborn as sns","e7ef3d87":"data = pd.read_csv(\"..\/input\/confused-eeg\/EEG_data.csv\")\nprint(data.info())","891303ad":"demo_data = pd.read_csv('..\/input\/confused-eeg\/demographic_info.csv')\ndemo_data","f3ca7eff":"demo_data = demo_data.rename(columns = {'subject ID': 'SubjectID'})\ndata = data.merge(demo_data,how = 'inner',on = 'SubjectID')\ndata.head()","63dcdee2":"data = pd.get_dummies(data)","73dd0191":"import pandas_profiling as pp\npp.ProfileReport(data)","82a1958c":"plt.figure(figsize = (15,15))\ncor_matrix = data.corr()\nsns.heatmap(cor_matrix,annot=True)","dc767aea":"data.drop(columns = ['SubjectID','VideoID','predefinedlabel'],inplace=True)","aed59428":"y= data.pop('user-definedlabeln')\nx= data","2d6b8c50":"x.iloc[:1000,:11].plot(figsize = (15,10))","12d1b47a":"x = StandardScaler().fit_transform(x)","0a13237c":"pd.DataFrame(x).iloc[:1000,:11].plot(figsize = (15,10))","9a836bca":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.15)","a0f62a84":"x_train.shape, x_test.shape,y_train.shape,y_test.shape","e8dba9f4":"x_train = np.array(x_train).reshape(-1,17,1)\nx_test = np.array(x_test).reshape(-1,17,1)\n","dfe4908e":"x_train.shape,x_test.shape,y_train.shape,y_test.shape","e213c285":"inputs = tf.keras.Input(shape=(17,1))\n\nDense1 = Dense(64, activation = 'relu',kernel_regularizer=keras.regularizers.l2())(inputs)\n\n#Dense2 = Dense(128, activation = 'relu',kernel_regularizer=keras.regularizers.l2())(Dense1)\n#Dense3 = Dense(256, activation = 'relu',kernel_regularizer=keras.regularizers.l2())(Dense2)\n\nlstm_1=  Bidirectional(LSTM(256, return_sequences = True))(Dense1)\ndrop = Dropout(0.3)(lstm_1)\nlstm_3=  Bidirectional(LSTM(128, return_sequences = True))(drop)\ndrop2 = Dropout(0.3)(lstm_3)\n\nflat = Flatten()(drop2)\n\n#Dense_1 = Dense(256, activation = 'relu')(flat)\n\nDense_2 = Dense(128, activation = 'relu')(flat)\noutputs = Dense(1, activation='sigmoid')(Dense_2)\n\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.summary()","60b69c92":"tf.keras.utils.plot_model(model)","9e720898":"def train_model(model,x_train, y_train,x_test,y_test, save_to, epoch = 2):\n\n        opt_adam = keras.optimizers.Adam(learning_rate=0.001)\n\n        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n        mc = ModelCheckpoint(save_to + '_best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n        lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * np.exp(-epoch \/ 10.))\n        \n        model.compile(optimizer=opt_adam,\n                  loss=['binary_crossentropy'],\n                  metrics=['accuracy'])\n        \n        history = model.fit(x_train,y_train,\n                        batch_size=20,\n                        epochs=epoch,\n                        validation_data=(x_test,y_test),\n                        callbacks=[es,mc,lr_schedule])\n        \n        saved_model = load_model(save_to + '_best_model.h5')\n        \n        return model,history","ee9aa5ef":"model,history = train_model(model, x_train, y_train,x_test, y_test, save_to= '.\/', epoch = 100) ","546ec606":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","79a6ac71":"y_pred =model.predict(x_test)\ny_pred = np.array(y_pred >= 0.5, dtype = np.int)\nconfusion_matrix(y_test, y_pred)","785e3e9b":"y_pred","ca303d00":"print(classification_report(y_test, y_pred))","7235d021":"## Reading EEG data along with Subject Demographics.","1aef785b":"The loss function used will be 'Binary CrossEntropy'. We will be using callback functions like Early_Stopping to avoid overfitting and lr_scheduler to change the learning rate while model trains.","be1cfb05":"It was mentioned in the Description of the Dataset that features like 'VideoID' and 'SubjectID'. The SubjectID and VideoID will provide hinderance while model training as there are 10 clips for 10 students and these 1-2 min clips are divided ino parts of 0.5 sec samples. So Model will most probably learn based on IDs but we want it to learn on based of EEG recordings, ethinicity and gender and age parameters.","c6a72d67":"### Combining the 2 CSV files on SubjectID","054db75e":"### One hot encoding categorical variables","6af7382a":"## Reshaping the data as required by the model","12c9f1e8":"## Defining necessary features for model training","c56fb957":"2. Classification Report","4f4cf21a":"## Analyzing the results.","ca4d4d3c":"### Dividing into Training and Validation sets","2d24990b":"We will be training for 100 epochs starting with learning_rate = 0.001 and batch_size = 20.","9f301cf6":"Before Normalization","3865fa17":"The scale of some EEG features were wide, so we use Z-score normalization.","3d386c4e":"## Plotting the Training and Validation Accuracy along with losses","87acd52c":"After Normalization","eed2d264":"## Understanding the Variables and relationships between them.","64b7d3a2":"## Importing necessary libraries","03a8f082":"## Please upvote if you found it useful :)","efe10a58":"The Categorical variables here include 'Ethnicity', 'Gender'.","5967fefc":"1. Confusion Matrix","732c7738":"## Defining the Model's architecture"}}