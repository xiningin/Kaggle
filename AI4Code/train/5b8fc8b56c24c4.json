{"cell_type":{"8592e1d9":"code","f37f50a3":"code","f69f581a":"code","a0b32958":"code","660f59fa":"code","6318fdcc":"code","b30f9d0c":"code","5b3a9c86":"code","12f740ea":"code","4a163b2c":"code","a6ecd951":"code","4b7d8ffa":"code","444db241":"code","36290026":"code","fe6cdb12":"code","0d5e97ec":"code","cd4b7ab4":"code","fd4c9916":"code","1180e6aa":"code","31862036":"code","51e90be7":"code","b93caeca":"code","ff6a1557":"code","ac2a4367":"code","632590a8":"code","aab7d9f1":"code","cc60964e":"code","fb29d538":"code","cb4772c4":"code","cdff0c46":"code","0ca2e8fd":"code","55555379":"code","53eb9e3e":"code","b3ea6626":"code","095997ea":"code","78250c8b":"code","363f8f6f":"code","bbde9201":"code","f697422a":"code","d79b608e":"code","a3f16a4a":"code","67056534":"code","c40b6dda":"code","98669573":"markdown","f0b75eba":"markdown","3b7eb3ed":"markdown","4c3084f8":"markdown","57795319":"markdown","df7dcd78":"markdown","e2a6a596":"markdown","5729b7e0":"markdown","4dedd321":"markdown","fcd75d83":"markdown","142d1049":"markdown","41539120":"markdown","7be811be":"markdown","ac8129bf":"markdown","5bec2086":"markdown","6594455c":"markdown","bb28efc4":"markdown","cd0982d7":"markdown","8d316376":"markdown","4646affd":"markdown"},"source":{"8592e1d9":"import os\nprint(os.listdir('..\/input\/images'))","f37f50a3":"print(os.listdir('..\/input\/birds2\/birds2'))","f69f581a":"dataPath = '..\/input\/birds2\/birds2\/'","a0b32958":"# Load the original model\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nmodel = MobileNetV2()","660f59fa":"import numpy as np\nfrom PIL import Image\n\ndef prepare_image(filepath):\n    img = Image.open(filepath)\n    img_resized = img.resize((224,224))\n    return np.asarray(img_resized)","6318fdcc":"import matplotlib.pyplot as plt\ntestPath = '..\/input\/images\/'","b30f9d0c":"# choose a test image\nimageFile = testPath+'German_Shepherd.jpg'\nplt.imshow(prepare_image(testPath+'German_Shepherd.jpg'))","5b3a9c86":"# Load original trained model\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nmodel = MobileNetV2()","12f740ea":"from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n\n# check model prediction\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nresults = decode_predictions(predictions)\nprint(results)","4a163b2c":"# choose another test image\nimageFile = testPath+'blue_tit.jpg'\nplt.imshow(prepare_image(testPath+'blue_tit.jpg'))","a6ecd951":"# check model prediction\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nresults = decode_predictions(predictions)\nprint(results)","4b7d8ffa":"import glob\ndirList = glob.glob(dataPath+'*') # list of all directories in dataPath\ndirList.sort() # sorted in alphabetical order\nprint(dirList)","444db241":"Y_data = []\nfor i in range(len(dirList)):\n    fileList = glob.glob(dirList[i]+'\/*.jpg')\n    [Y_data.append(i) for file in fileList]\nprint(Y_data)","36290026":"X_data = []\nfor i in range(len(dirList)):\n    fileList = glob.glob(dirList[i]+'\/*.jpg')\n    [X_data.append(prepare_image(file)) for file in fileList]\n\nX_data = np.asarray(X_data)\nprint(X_data.shape)","fe6cdb12":"## random shuffle\nfrom sklearn.utils import shuffle\nX_data, Y_data = shuffle(X_data, Y_data, random_state=0)","0d5e97ec":"print(Y_data)","cd4b7ab4":"# randomly select a picture to show\nimport random\ntestNum = random.randint(0,len(X_data)-1)\nprint(testNum)\n\nplt.imshow(X_data[testNum])","fd4c9916":"labels = os.listdir(dataPath)\nprint(labels)\n\nnum_classes = len(labels)\nprint(num_classes)","1180e6aa":"# counting number of pictures of each class\nequilibre = []\n[equilibre.append(Y_data.count(i)) for i in range(len(labels))]\nprint(equilibre)","31862036":"# plot the circle of value counts in dataset\nplt.figure(figsize=(5,5))\nmy_circle=plt.Circle( (0,0), 0.5, color='white')\nplt.pie(equilibre, labels=labels, colors=['red','green'],autopct='%1.1f%%')\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()","51e90be7":"X_train = X_data \/ 255.0\nprint(X_train.shape)","b93caeca":"from tensorflow.keras.utils import to_categorical\nY_train = to_categorical(Y_data)\nprint(Y_train.shape)","ff6a1557":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense","ac2a4367":"base_model=MobileNetV2(input_shape=(224,224,3),weights='imagenet',include_top=False) ","632590a8":"x=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x) # FC layer 1\nx=Dense(64,activation='relu')(x)   # FC layer 2\nout=Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n\nmodel=Model(inputs=base_model.input,outputs=out)","aab7d9f1":"# show all layers no. & name\nfor i,layer in enumerate(model.layers):\n    print(i,layer.name)","cc60964e":"# set extra layers to trainable \n#for layer in model.layers[:155]:\n#    layer.trainable=False\n#for layer in model.layers[155:]:\n#    layer.trainable=True\n\nbase_model.trainable = False\n\nmodel.summary()","fb29d538":"# Compile Model\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])","cb4772c4":"# Train Model (target is loss <0.01)\nbatch_size = 10\nnum_epochs = 10\nhistory = model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs)","cdff0c46":"# Save Model\nmodel.save('tl_birds2.h5')","0ca2e8fd":"# select one bird picture to test\nimageFile = testPath+'blue_tit.jpg'\nplt.imshow(prepare_image(imageFile))","55555379":"# test model\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nmaxindex = int(np.argmax(predictions))\nprint(predictions[0][maxindex],labels[maxindex])","53eb9e3e":"# select another picture to test \nimageFile=testPath+'pica_pica.jpg'\nplt.imshow(prepare_image(imageFile))","b3ea6626":"# test model\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nmaxindex = int(np.argmax(predictions))\nprint(predictions[0][maxindex],labels[maxindex])","095997ea":"# select a untrained picture to test the model\nimageFile=testPath+'crow.jpg'\nplt.imshow(prepare_image(imageFile))","78250c8b":"# test model\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nmaxindex = int(np.argmax(predictions))\nprint(predictions[0][maxindex],labels[maxindex])","363f8f6f":"# select another untrained picture to test\nimageFile=testPath+'German_Shepherd.jpg'\nplt.imshow(prepare_image(imageFile))","bbde9201":"# test model\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nmaxindex = int(np.argmax(predictions))\nprint(predictions[0][maxindex],labels[maxindex])","f697422a":"from sklearn.metrics import confusion_matrix\n\nY_pred = model.predict(X_train) # check the train dataset\ny_pred = np.argmax(Y_pred,axis=1)\n#y_label= [labels[k] for k in y_pred]\ncm = confusion_matrix(Y_data, y_pred)\nprint(cm)","d79b608e":"from sklearn.metrics import classification_report\nprint(classification_report(Y_data, y_pred, target_names=labels))","a3f16a4a":"# plot confusion matrix\nfig, ax = plt.subplots()\nax.matshow(cm,cmap='Blues')\n\nfor (i, j), z in np.ndenumerate(cm):\n    ax.text(j, i, '{:d}'.format(z), ha='center', va='center')\n\nplt.show()","67056534":"import itertools\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n        \n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","c40b6dda":"plot_confusion_matrix(cm, \n                      normalize=False,\n                      target_names = labels,\n                      title=\"Confusion Matrix, not Normalized\")","98669573":"## Test MobileNetV2 model","f0b75eba":"## Classification Report","3b7eb3ed":"## Build Model\n","4c3084f8":"*Confirm the model don't recognize Blue Tit !*","57795319":"![image.png](attachment:image.png)","df7dcd78":"## Confusion Matrix","e2a6a596":"## Prepare Data","5729b7e0":"## Save Model","4dedd321":"*Confirm the model recognize German Shepherd !*","fcd75d83":"## Dataset = birds2 (blue_tit, pica_pica)","142d1049":"### Data Normalization","41539120":"### Load MobileNetV2 model","7be811be":"## Test Model","ac8129bf":"### test the original model \nto confirm its recognition of a dog and a bird","5bec2086":"### Plot Confusion Matrix","6594455c":"# Image Classification\n## MobileNetV2 transfer learning","bb28efc4":"### set for transfer learning","cd0982d7":"### Shuffle Data","8d316376":"## Train Model","4646affd":"### add Fully-Connected Layers"}}