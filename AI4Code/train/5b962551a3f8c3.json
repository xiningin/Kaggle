{"cell_type":{"ca761960":"code","0cba6aa7":"code","afaad1a8":"code","3a39f41a":"code","9fd00e89":"code","21ff71f0":"code","96f05876":"code","abac0656":"code","84038245":"code","1f6dc612":"code","d5cd10ed":"code","aeb73f92":"code","cc1b2b6e":"code","4e089cd5":"code","7f8ddf1e":"code","9a7adc00":"code","1df50121":"code","4bd53c01":"code","f85183fe":"code","bd6d6d6e":"code","8f36d173":"code","eb04e861":"markdown","2acbd6b7":"markdown"},"source":{"ca761960":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical","0cba6aa7":"directory = '..\/input\/english-handwritten-characters-dataset\/Img'\nfiles=os.listdir(directory)\nprint(files[0:5])\nprint(len(files))","afaad1a8":"# filename and image data\ndatafile=[]\ndata=[]\nfor file in files:\n    image=load_img(os.path.join(directory,file),grayscale=False,color_mode='rgb',target_size=(100,100))\n    image=img_to_array(image)\n    image=image\/255.0\n    data+=[image]\n    datafile+=[file]\nprint(datafile[0:5])\nprint(len(datafile))","3a39f41a":"data1=np.array(data)\nprint(data1.shape)","9fd00e89":"# filename and label\nengl=pd.read_csv('..\/input\/english-handwritten-characters-dataset\/english.csv')\nengl.head()","21ff71f0":"factlabel=pd.factorize(engl['label'])\n\nprint(factlabel[0])\nprint(factlabel[1])","96f05876":"labelfile=[]\nfor item in engl['image']:\n    labelfile+=[item[4:]]\nengl['file']=labelfile\nengl['labeln']=factlabel[0]\n\nprint(engl.head())","abac0656":"# set labels in image data order\nengl2=[]\nfor item in datafile:\n    engl2+=[engl['labeln'][engl['file']==item].values[0]]\n    \nprint(engl2[0:5])\nprint(datafile[0:5])","84038245":"labels1=to_categorical(engl2)\nlabels2=np.array(labels1)\n\nprint(\"Data Shape:{}\\nLabels shape: {}\".format(data1.shape,labels2.shape))","1f6dc612":"from sklearn.model_selection import train_test_split\ntrainx,testx,trainy,testy=train_test_split(data1,labels2,test_size=0.2,random_state=44)","d5cd10ed":"print(trainx.shape)\nprint(testx.shape)\nprint(trainy.shape)\nprint(testy.shape)","aeb73f92":"datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=20,zoom_range=0.2,\n                    width_shift_range=0.2,height_shift_range=0.2,shear_range=0.1,fill_mode=\"nearest\")","cc1b2b6e":"pretrained_model1 = tf.keras.applications.InceptionResNetV2(input_shape=(100,100,3),include_top=False,weights='imagenet',pooling='avg')\npretrained_model2 = tf.keras.applications.DenseNet121(input_shape=(100,100,3),include_top=False,weights='imagenet',pooling='avg')\npretrained_model3 = tf.keras.applications.DenseNet201(input_shape=(100,100,3),include_top=False,weights='imagenet',pooling='avg')\npretrained_model4 = tf.keras.applications.EfficientNetB0(input_shape=(100,100,3),include_top=False,weights='imagenet',pooling='avg')\npretrained_model5 = tf.keras.applications.EfficientNetB7(input_shape=(100,100,3),include_top=False,weights='imagenet',pooling='avg')\n\npretrained_model1.trainable = False\npretrained_model2.trainable = False\npretrained_model3.trainable = False\npretrained_model4.trainable = False\npretrained_model5.trainable = False","4e089cd5":"inputs1 = pretrained_model1.input\ninputs2 = pretrained_model2.input\ninputs3 = pretrained_model3.input\ninputs4 = pretrained_model4.input\ninputs5 = pretrained_model5.input\n\nx1 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model1.output)\noutputs1 = tf.keras.layers.Dense(62, activation='softmax')(x1)\nx2 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model2.output)\noutputs2 = tf.keras.layers.Dense(62, activation='softmax')(x2)\nx3 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model3.output)\noutputs3 = tf.keras.layers.Dense(62, activation='softmax')(x3)\nx4 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model4.output)\noutputs4 = tf.keras.layers.Dense(62, activation='softmax')(x4)\nx5 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model5.output)\noutputs5 = tf.keras.layers.Dense(62, activation='softmax')(x5)\n\nmodel1 = tf.keras.Model(inputs=inputs1, outputs=outputs1)\nmodel2 = tf.keras.Model(inputs=inputs2, outputs=outputs2)\nmodel3 = tf.keras.Model(inputs=inputs3, outputs=outputs3)\nmodel4 = tf.keras.Model(inputs=inputs4, outputs=outputs4)\nmodel5 = tf.keras.Model(inputs=inputs5, outputs=outputs5)","7f8ddf1e":"#model1.summary()\n#model2.summary()\n#model3.summary()\n#model4.summary()\n#model5.summary()","9a7adc00":"model1.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel2.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel3.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel4.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel5.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhis1=model1.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=20)\nhis2=model2.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=20)\nhis3=model3.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=20)\nhis4=model4.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=20)\nhis5=model5.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=20)","1df50121":"y_pred1=model1.predict(testx)\ny_pred2=model2.predict(testx)\ny_pred3=model3.predict(testx)\ny_pred4=model4.predict(testx)\ny_pred5=model5.predict(testx)\n\npred1=np.argmax(y_pred1,axis=1)\npred2=np.argmax(y_pred2,axis=1)\npred3=np.argmax(y_pred3,axis=1)\npred4=np.argmax(y_pred4,axis=1)\npred5=np.argmax(y_pred5,axis=1)\n\nground = np.argmax(testy,axis=1)\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(ground,pred1))\nprint(classification_report(ground,pred2))\nprint(classification_report(ground,pred3))\nprint(classification_report(ground,pred4))\nprint(classification_report(ground,pred5))","4bd53c01":"get_acc1 = his1.history['accuracy']\nget_acc2 = his2.history['accuracy']\nget_acc3 = his3.history['accuracy']\nget_acc4 = his4.history['accuracy']\nget_acc5 = his5.history['accuracy']\n\nepochs = range(len(get_acc1))\n\nplt.plot(epochs, get_acc1, 'b', label='InceptionResNetV2')\nplt.plot(epochs, get_acc2, 'g', label='DenseNet121')\nplt.plot(epochs, get_acc3, 'y', label='DenseNet201')\nplt.plot(epochs, get_acc4, 'm', label='EfficientNetB0')\nplt.plot(epochs, get_acc5, 'c', label='EfficientNetB7')\n\nplt.title('Accuracy comparison')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","f85183fe":"get_loss1 = his1.history['loss']\nget_loss2 = his2.history['loss']\nget_loss3 = his3.history['loss']\nget_loss4 = his4.history['loss']\nget_loss5 = his5.history['loss']\n\nepochs = range(len(get_loss1))\n\nplt.plot(epochs, get_loss1, 'b', label='InceptionResNetV2')\nplt.plot(epochs, get_loss2, 'g', label='DenseNet121')\nplt.plot(epochs, get_loss3, 'y', label='DenseNet201')\nplt.plot(epochs, get_loss4, 'm', label='EfficientNetB0')\nplt.plot(epochs, get_loss5, 'c', label='EfficientNetB7')\n\nplt.title('Loss comparison')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","bd6d6d6e":"value_acc1 = his1.history['val_accuracy']\nvalue_acc2 = his2.history['val_accuracy']\nvalue_acc3 = his3.history['val_accuracy']\nvalue_acc4 = his4.history['val_accuracy']\nvalue_acc5 = his5.history['val_accuracy']\n\nepochs = range(len(value_acc1))\n\nplt.plot(epochs, value_acc1, 'b', label='InceptionResNetV2')\nplt.plot(epochs, value_acc2, 'g', label='DenseNet121')\nplt.plot(epochs, value_acc3, 'y', label='DenseNet201')\nplt.plot(epochs, value_acc4, 'm', label='EfficientNetB0')\nplt.plot(epochs, value_acc5, 'c', label='EfficientNetB7')\n\nplt.title('Validation accuracy comparison')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","8f36d173":"val_loss1 = his1.history['val_loss']\nval_loss2 = his2.history['val_loss']\nval_loss3 = his3.history['val_loss']\nval_loss4 = his4.history['val_loss']\nval_loss5 = his5.history['val_loss']\n\nepochs = range(len(val_loss1))\n\nplt.plot(epochs, val_loss1, 'b', label='InceptionResNetV2')\nplt.plot(epochs, val_loss2, 'g', label='DenseNet121')\nplt.plot(epochs, val_loss3, 'y', label='DenseNet201')\nplt.plot(epochs, val_loss4, 'm', label='EfficientNetB0')\nplt.plot(epochs, val_loss5, 'c', label='EfficientNetB7')\n\nplt.title('Validation loss comparison')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","eb04e861":"# Handwritten Character Keras Application Comparison2\n### Keras applications ('InceptionResNetV2','DenseNet121','DenseNet201','EfficientNetB0' and 'EfficientNetB7') were compared on English handwritten characters images.\n[https:\/\/keras.io\/api\/applications\/](https:\/\/keras.io\/api\/applications\/)","2acbd6b7":"#### cf. Former Notebook \"Handwritten Character Keras Application Comparison\"\nComparison among 'MobileNetV2', 'ResNet50', 'VGG16', 'DenseNet121', 'Xception' and 'InceptionV3'\n\nhttps:\/\/www.kaggle.com\/stpeteishii\/handwritten-character-keras-application-comparison"}}