{"cell_type":{"0b4cde31":"code","44a4aa18":"code","0d6b9d12":"code","95bd4df5":"code","901b30b2":"code","52cdf3aa":"code","967c1e99":"code","d0067429":"code","bc40fc48":"code","413acb83":"code","2855758d":"code","3f7b383d":"code","1a75b465":"code","97297385":"code","db61553a":"code","fd8be02c":"code","075721a1":"code","51803cd0":"code","7900f6ee":"code","17a5b1ed":"code","05344b4b":"code","89f20ae0":"code","d28df0c5":"code","612835bf":"code","ca71e605":"code","fc16d283":"code","74dad43f":"code","2e95d78f":"code","64208246":"markdown","29a599fb":"markdown","1b46cb21":"markdown","54d68a48":"markdown","44b9e97c":"markdown","f2846589":"markdown","f3b9c5a1":"markdown","cbb975ce":"markdown","7b3c1e1c":"markdown","cb5809b6":"markdown","2ff51287":"markdown","3cf5d2b8":"markdown","0eaf03b9":"markdown"},"source":{"0b4cde31":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","44a4aa18":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nplt.style.use('fivethirtyeight')","0d6b9d12":"data = pd.read_csv(\"..\/input\/pizza-price-prediction\/pizza_v1.csv\")\ndata.head(10)","95bd4df5":"data.info()","901b30b2":"# shape of data\ndata.shape","52cdf3aa":"data.isnull().any()","967c1e99":"# replace the of yes or no into 1,0\n\ndata = data.replace([\"yes\",\"no\"],[1,0])\ndata.head()","d0067429":"##checing varities in company\ndata['company'].value_counts()","bc40fc48":"# plot varities in company\n\nplt.figure(figsize=(5,5))\ndata['company'].value_counts().plot(kind='pie',autopct='%.2f')\nplt.title('Companies involved')\nplt.ylabel('')\nplt.show()","413acb83":"# replace the of A, B, C, E or no into 0,1,2,3,4\n\ndata = data.replace(['A','B','C','D','E'],[0,1,2,3,4])\ndata['company']","2855758d":"data['price_rupiah'].dtype\nprice = []\nfor item in data['price_rupiah']:\n    price.append(int(item.replace('Rp','').replace(',','')))\ndata['price_rupiah'] = price\ndata.head()","3f7b383d":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ndata['topping']=labelencoder.fit_transform(data['topping'])\ndata['variant']=labelencoder.fit_transform(data['variant'])\ndata['size']=labelencoder.fit_transform(data['size'])\ndata.head()","1a75b465":"data.corr()","97297385":"corr = data.corr()\nsns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.figure(figsize=(10,5))\na = sns.heatmap(corr, annot=True, fmt='.1f', cmap='YlGnBu')\nrotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\nroty = a.set_yticklabels(a.get_yticklabels(), rotation=30)","db61553a":"data.hist(figsize=(14,14))\nplt.show()","fd8be02c":"x = (data.loc[:, data.columns !='price_rupiah'])\ny = (data.loc[:, data.columns =='price_rupiah'])","075721a1":"from tensorflow.keras.utils import to_categorical\none_hot_labels = to_categorical(y)","51803cd0":"one_hot_labels","7900f6ee":"x.describe()","17a5b1ed":"import sklearn\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,one_hot_labels,test_size=.30,random_state=1)","05344b4b":"mean = x_train.mean(axis=0)\nx_train-= mean\nstd = x_train.std(axis=0)\nx_train\/= std\nx_test-= mean\nx_test\/= std","89f20ae0":"from keras import models\nfrom tensorflow.keras import Sequential \nfrom tensorflow.keras.layers import Dense\nimport tensorflow\nnetwork = models.Sequential()\nnetwork.add(Dense(32, activation='relu', input_shape=(x_train.shape[1],)))\nnetwork.add(Dense(8, activation='relu'))\nnetwork.add(Dense(1))","d28df0c5":"network.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])","612835bf":"history=network.fit(x_train, y_train, epochs=10, verbose=1)","ca71e605":"network.evaluate(x_test,y_test)","fc16d283":"result_1=network.predict(x_test)\nresult_1","74dad43f":"history_dict=history.history\nhistory_dict.keys()","2e95d78f":"loss = history_dict['loss']\nmae = history_dict['mae']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss,\"go\",label='Training loss')\nplt.plot(epochs, mae, 'r', label='mae')\nplt.title('mae and  loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.legend()\nplt.grid()\nplt.show()","64208246":"# Split data into 70% training and 30% testing ","29a599fb":"# Create Model ","1b46cb21":"# Normalize the train data","54d68a48":"# ","44b9e97c":"# re-format price_rupiah column","f2846589":"# evaluate(x_test,y_test)","f3b9c5a1":"# Load Data","cbb975ce":"# Slicing","7b3c1e1c":"# Getting the statistical info","cb5809b6":"# ","2ff51287":"# Correlation","3cf5d2b8":"# now just converting categorical data to numeric data","0eaf03b9":"# Check missing value"}}