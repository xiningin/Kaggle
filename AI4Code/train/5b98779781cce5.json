{"cell_type":{"08b01e4a":"code","83a59d9a":"code","4947e7c3":"code","4df0cee5":"code","26e8bdbd":"code","92d347af":"code","dfb6917e":"code","5ee812c5":"code","68cb56bf":"code","0aac49f0":"code","2b8facd0":"code","de3022ed":"code","5f9fc718":"code","8cef0f55":"code","8abc05cb":"code","23d158ac":"code","4260b298":"code","9229a0d4":"code","3a190a99":"code","20d19e2e":"code","9563e9c1":"code","5a220c68":"code","7899054e":"markdown","7267778c":"markdown","480e633a":"markdown","5700be4f":"markdown","3d3e3a59":"markdown","d2e097fe":"markdown","bce45ac1":"markdown","3cf2c88b":"markdown","b3bdb5e2":"markdown","cf21b33f":"markdown","9fb356d1":"markdown","f028c305":"markdown","3288f862":"markdown","aece89fb":"markdown"},"source":{"08b01e4a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","83a59d9a":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import LearningRateScheduler","4947e7c3":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","4df0cee5":"train.head(10)","26e8bdbd":"test.head(10)","92d347af":"# Checking missing values\nsns.heatmap(train.isnull())\n","dfb6917e":"sns.heatmap(test.isnull())","5ee812c5":"X_train=train.iloc[:,1:]\nY_train=train.iloc[:,0]\ng=sns.countplot(Y_train)\n","68cb56bf":"X_train=X_train\/255.0\ntest=test\/255.0","0aac49f0":"\nX_train = X_train.values.reshape(-1, 28, 28, 1)\ntest = test.values.reshape(-1, 28, 28, 1)","2b8facd0":"X_train.shape","de3022ed":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(X_train,Y_train,test_size=0.2)","5f9fc718":"data_gen = ImageDataGenerator(\n            rotation_range=12,\n            width_shift_range=0.12,\n            height_shift_range=0.12,\n            shear_range=0.12,\n            validation_split=0.2,)","8cef0f55":"data_gen.fit(x_train)\ndata_gen.fit(x_test)","8abc05cb":"\ny_train = to_categorical(y_train, num_classes=10)\ny_test = to_categorical(y_test, num_classes=10)","23d158ac":"model = Sequential()\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), activation=\"relu\", input_shape=(28,28,1)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","4260b298":"model.summary()","9229a0d4":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","3a190a99":"# defining model parameters \nbatch_size = 64\nepochs = 15\n# Fit the Model\nhistory = model.fit_generator(data_gen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, \n                              validation_data = (x_test, y_test), verbose=1, \n                              steps_per_epoch=x_train.shape[0] \/\/ batch_size,\n                              \n                             )\n\n ","20d19e2e":"plt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.title(\"Model Loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend();","9563e9c1":"pred = np.argmax(model.predict(test), axis=1)\n    \nsub_df = {'ImageId':list(range(1, len(test) + 1)),'Label':pred}\nsubmission = pd.DataFrame(sub_df).astype('int')\nsubmission.head()","5a220c68":"submission.to_csv('submission.csv', index=False)","7899054e":"Encoding our outing into 10 differents categories","7267778c":"Checking model is working","480e633a":"Spliting the data into train and validation.","5700be4f":"Train and test images (28px x 28px) has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.\n\nKeras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices.","3d3e3a59":"We now have a model framework with about 199k parameters. Next, we need to compile it. We'll try using the 'Adam' optomizer function, which will adapt the learning rate, along with categorical crossentropy for loss (becuase we are looking for categorical classification), and measure accuracy.","d2e097fe":"Checking the null value in the dataset.Using seaborn to plot if there is any null values ","bce45ac1":"Importing Dataset","3cf2c88b":"Checking that the dataset we have is balanced or not.Since the data is well balanced upon the 10 categories given to us so we don't need to upsample or downsample the classes.","b3bdb5e2":"As seen above, these are datasets of pixels by image, with each row representing a seperate image of 784 pixels (likely 28 high X 28 wide). The training set contains 42000 images, while the testing set contains 28000. This appears to be monohromatic, as there is only one layer. Were they not black and white, we could expect three different sets of values for each pixel, representing RGB","cf21b33f":"Pretty standard configuration: 0 is black, 255 is white. We should adjust the values so they fall between 0 and 1, which makes it easier for the model to handle later. We should also reshape and re-type the data to the required format. Let's wrap it all up in a function.\nSo we normailize the data so that we get values between 0 and 1 so model can converge faster.","9fb356d1":"Making a simple CNN model to train and make predictions on the MINST digits dataset.Upvote if u like \nImporting Libraries","f028c305":"The first is the convolutional (Conv2D) layer. It is like a set of learnable filters. I choosed to set 16 filters for the firsts conv2D layer and 32 filters for the two last ones. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n\nThe CNN can isolate features that are useful everywhere from these transformed images (feature maps).\n\nThe second important layer in CNN is the pooling (MaxPool2D) layer. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting. We have to choose the pooling size (i.e the area size pooled each time) more the pooling dimension is high, more the downsampling is important.\n\nCombining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image.\n\nDropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting.\n\n'relu' is the rectifier (activation function max(0,x). The rectifier activation function is used to add non linearity to the network.\n\nThe Flatten layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional\/maxpool layers. It combines all the found local features of the previous convolutional layers.\n\nIn the end i used the features in two fully-connected (Dense) layers which is just artificial an neural networks (ANN) classifier. In the last layer(Dense(10,activation=\"softmax\")) the net outputs distribution of probability of each class.","3288f862":"These images are very small. Also, if you go look at images of what these numbers look like (sorry for not including examples in here), you'll see that all of the numbers are fairly standard: right side up, not mirrored, not too tilted, etc. Thus, we shouldn't need to do too much to avoid overfitting; we'll just shift things around, rotate slightly, and zoom a bit.\nNow we do data augumentation.It is a technique to increase the size of the dataset by applying various rotations and various other factors so that model can train on more images to get high accuracy.","aece89fb":"All that's left is to train it. We'll choose 15 epochs and a batch size of 64. The images are pretty small, so this shouldn't take too long.I have run this model for 15 epochs you can run for 30 epoch for best result."}}