{"cell_type":{"3ad156be":"code","4a00c97e":"code","95bb095b":"code","ea58598e":"code","0f84e904":"code","b4785f82":"code","b40130a9":"code","19f83292":"code","0d944bb8":"code","95035560":"code","b8bbfd4d":"code","898d9bb8":"code","e8e4b971":"code","5f8020ed":"code","791e5d8e":"code","89324479":"code","f4d75f00":"code","e9452d8d":"code","62970149":"code","6fffdc8b":"code","4f9850fe":"code","7f4e7614":"code","86c7b034":"code","abb9fae4":"code","ca63d580":"code","27590866":"code","70e8e2de":"code","ef451653":"code","89d90612":"code","423a0aaa":"code","9922d90c":"code","ae033f42":"code","b6c1d548":"code","6a7ad886":"code","428e4e1e":"code","69542295":"code","046fe0af":"code","19565847":"code","a7a5fb43":"code","4292c413":"code","07e258ad":"code","9d573e91":"code","fb42b461":"code","c67949a5":"code","78b02873":"code","45b8f89a":"code","f513ecb2":"code","12c97f50":"code","cbd58bbf":"code","43e597bb":"code","25800d63":"code","6a6f6aa1":"code","7f4c7079":"code","79e29010":"code","799384db":"code","96470669":"code","9038819d":"markdown","6ddf2558":"markdown","e29f7a5a":"markdown","da8ba036":"markdown","600b2c84":"markdown","dd5fe702":"markdown","2aa585cb":"markdown","511135d3":"markdown","4fa750f1":"markdown","cab23976":"markdown","e0f889fd":"markdown","e802d5eb":"markdown","02e7e494":"markdown","27b71a47":"markdown","175db9a6":"markdown","8f268fca":"markdown","6fa7df0a":"markdown","82e8519b":"markdown","103f789e":"markdown","5ec9b6f5":"markdown","fa2f808b":"markdown","e9fb6c0c":"markdown","eb129359":"markdown","8fecd6a3":"markdown","7adac4d1":"markdown","e6387655":"markdown","cb5ebe2c":"markdown","4112dde8":"markdown","712e841d":"markdown","d62fe748":"markdown","ac3b1763":"markdown","4a93913f":"markdown","7edccce9":"markdown","8aab3279":"markdown","39174009":"markdown"},"source":{"3ad156be":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4a00c97e":"import matplotlib.pyplot as plt\nplt.style.use('seaborn-darkgrid')\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","95bb095b":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","ea58598e":"train_data.head()","0f84e904":"test_data.head()","b4785f82":"print('Shape of train data:',train_data.shape)\nprint('Shape of test data:',test_data.shape)","b40130a9":"print(train_data.info())","19f83292":"print(test_data.info())","0d944bb8":"g = sns.FacetGrid(train_data, col = 'Survived', row = 'Pclass', size = 4, aspect = 1.5)\ng.map(plt.hist, 'Age', bins=20)\ng.add_legend();","95035560":"plt.figure(figsize = (16, 9))\ng = sns.FacetGrid(train_data, col = 'Survived', size = 4, aspect = 1.5)\ng.map(plt.hist, 'Age', bins = 20)\nplt.show()","b8bbfd4d":"g = sns.FacetGrid(train_data, row = 'Embarked', size = 4, aspect = 1.5)\ng.map(sns.pointplot, 'Pclass', 'Survived', 'Sex')\ng.add_legend()","898d9bb8":"g = sns.FacetGrid(train_data, row = 'Embarked', col = 'Survived', size = 4, aspect = 1.5)\ng.map(sns.barplot, 'Sex', 'Fare')\ng.add_legend()","e8e4b971":"target = train_data['Survived']\ntrain_data.drop(['Survived'], axis = 1, inplace = True)","5f8020ed":"full_data = pd.concat([train_data, test_data], axis = 0)","791e5d8e":"print('Shape of Complete Data:',full_data.shape)","89324479":"plt.figure(figsize = (16,9))\nsns.distplot(full_data['Age'])\nplt.title(\"Distribution of Passenger's Age on Titanic\")\nplt.show()","f4d75f00":"plt.figure(figsize = (17,5))\nplt.subplot(1,4,1)\nsns.countplot(target)\nplt.title('Number of Passengers Survived and Not Survived')\nplt.subplot(1,4,2)\nsns.countplot(full_data['Pclass'])\nplt.title('Number of Pclasses in the complete Dataset')\nplt.subplot(1,4,3)\nsns.countplot(full_data['Sex'])\nplt.title('Number of M\/F in the complete Dataset')\nplt.subplot(1,4,4)\nsns.countplot(full_data['Embarked'])\nplt.title('Boarding ports in the complete Dataset')\nplt.tight_layout()","e9452d8d":"plt.figure(figsize = (16,5))\nplt.subplot(1,2,1)\nsns.countplot(full_data['SibSp'])\nplt.title('Number of Siblings or Spouse Aboard')\nplt.subplot(1,2,2)\nsns.countplot(full_data['Parch'])\nplt.title('Number of Parents or Children Aboard')\nplt.show()","62970149":"full_data.info()","6fffdc8b":"full_data.drop(['PassengerId', 'Ticket', 'Cabin', 'Fare'], axis = 1, inplace = True)","4f9850fe":"full_data.head()","7f4e7614":"# Need to install this package by typing 'pip install nameparser' on the console.\n# OR\n%pip install nameparser\nfrom nameparser import HumanName\nfull_data['Name_Title'] = full_data['Name'].apply(lambda x: HumanName(x).title)\nprint(full_data.Name_Title.value_counts())\nunique_title = list(full_data.Name_Title.value_counts().index)","86c7b034":"full_data.drop(['Name'], axis = 1, inplace = True)","abb9fae4":"top_title = ['Mr.','Miss.','Mrs.','Master.']","ca63d580":"full_data['Name_Title'].replace(to_replace = list(set(unique_title) - set(top_title)),\n                 value = 'Special', inplace = True)\n# full_data.replace({'Name_Title':{'Mr.': 0, 'Miss.': 1, 'Mrs.': 2, 'Master.': 3, 'Special': 4}}, inplace = True)","27590866":"full_data.head()","70e8e2de":"full_data.replace({'Sex': {'male': 0, 'female': 1}}, inplace = True)","ef451653":"full_data.head()","89d90612":"full_data.isnull().sum()[full_data.isnull().sum() > 0].sort_values(ascending = False)","423a0aaa":"guess_ages = np.zeros((2,3))\nfor i in range(0, 2):\n    for j in range(0, 3):\n        guess_df = full_data[(full_data['Sex'] == i) & (full_data['Pclass'] == j+1)]['Age'].dropna()\n\n        age_guess = guess_df.median()\n\n        # Convert random age float to nearest .5 age\n        guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n\nfor i in range(0, 2):\n    for j in range(0, 3):\n        full_data.loc[ (full_data.Age.isnull()) & (full_data.Sex == i) & (full_data.Pclass == j+1),'Age'] = guess_ages[i,j]\n\nfull_data['Age'] = full_data['Age'].astype(int)","9922d90c":"full_data['Embarked'].fillna(full_data['Embarked'].mode()[0], inplace = True)","ae033f42":"full_data.isnull().sum()[full_data.isnull().sum() > 0].sort_values(ascending = False)","b6c1d548":"full_data.info()","6a7ad886":"full_data['Family'] = full_data['SibSp'] + full_data['Parch'] + 1","428e4e1e":"full_data.head()","69542295":"full_data.loc[full_data['Family'] == 1, 'Family'] = 'Alone'\nfull_data.loc[full_data['Family'] == 2, 'Family'] = 'Partner'\nfull_data.loc[(full_data['Family'] != 'Alone') & (full_data['Family'] != 'Partner'), 'Family'] = 'More'","046fe0af":"# full_data.loc[full_data['Family_size'] == 1, 'Alone'] = 1\n# full_data.loc[full_data['Family_size'] != 1, 'Alone'] = 0\n# full_data['Alone'] = full_data['Alone'].astype(int)","19565847":"full_data.drop(['SibSp', 'Parch'], axis = 1, inplace = True)\nprint('Types of Passengers Travelling:',full_data.Family.value_counts())\nfull_data.head(10)","a7a5fb43":"pd.cut(full_data.Age, 8)","4292c413":"full_data.loc[ full_data['Age'] <= 10, 'Age'] = 0\nfull_data.loc[(full_data['Age'] > 10) & (full_data['Age'] <= 20), 'Age'] = 1\nfull_data.loc[(full_data['Age'] > 20) & (full_data['Age'] <= 30), 'Age'] = 2\nfull_data.loc[(full_data['Age'] > 30) & (full_data['Age'] <= 40), 'Age'] = 3\nfull_data.loc[(full_data['Age'] > 40) & (full_data['Age'] <= 50), 'Age'] = 4\nfull_data.loc[(full_data['Age'] > 50) & (full_data['Age'] <= 60), 'Age'] = 5\nfull_data.loc[(full_data['Age'] > 60) & (full_data['Age'] <= 70), 'Age'] = 6\nfull_data.loc[ full_data['Age'] > 70, 'Age'] = 7","07e258ad":"full_data.head()","9d573e91":"dummy_df = pd.get_dummies(full_data, columns = ['Pclass', 'Embarked', 'Name_Title', 'Family'], drop_first = True)","fb42b461":"dummy_df.head()","c67949a5":"train = dummy_df[:len(train_data)]\ntest = dummy_df[len(train_data):]","78b02873":"print('Shape of Training Data',train.shape)\nprint('Shape of Testing Data',test.shape)","45b8f89a":"# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(train, target, test_size = 0.2)","f513ecb2":"from sklearn.ensemble import RandomForestClassifier\n\nrf_clf = RandomForestClassifier(n_estimators = 100)\n\nrf_clf.fit(train, target)\nrf_pred = rf_clf.predict(test)\nprint('Accuracy Score:',round(rf_clf.score(train, target)*100,2))\n","12c97f50":"from sklearn.svm import SVC\n\nsvc_clf = SVC(C = 2, kernel = 'rbf')\n\nsvc_clf.fit(train, target)\nsvc_pred = svc_clf.predict(test)\nprint('Accuracy Score:',round(svc_clf.score(train, target)*100,2))","cbd58bbf":"from sklearn.ensemble import AdaBoostClassifier\n\nada_clf = AdaBoostClassifier(n_estimators = 100)\n\nada_clf.fit(train, target)\nada_pred = ada_clf.predict(test)\nprint('Accuracy Score:',round(ada_clf.score(train, target)*100,2))","43e597bb":"from lightgbm import LGBMClassifier\n\nlgbm_clf = LGBMClassifier(n_estimators = 400)\n\nlgbm_clf.fit(train, target)\nlgbm_pred = lgbm_clf.predict(test)\nprint('Accuracy Score:',round(lgbm_clf.score(train, target)*100,2))","25800d63":"from xgboost import XGBClassifier\n\nxgb_clf = XGBClassifier(n_estimators = 200)\n\nxgb_clf.fit(train, target)\nxgb_pred = xgb_clf.predict(test)\nprint('Accuracy Score:',round(xgb_clf.score(train, target)*100,2))","6a6f6aa1":"from sklearn.ensemble import StackingClassifier\n\nbase_estimators = [('lgbm',lgbm_clf),\n                  ('rf',rf_clf)]\n\nstc_clf = StackingClassifier(estimators = base_estimators, final_estimator = svc_clf)\n\nstc_clf.fit(train, target)\nstc_pred = stc_clf.predict(test)\nprint('Accuracy Score:',round(stc_clf.score(train, target)*100,2))","7f4c7079":"from sklearn.ensemble import VotingClassifier\n\nestimators = [('rf',rf_clf),\n             ('xgb',xgb_clf),\n             ('lgbm',lgbm_clf)]\n\nvot_clf = VotingClassifier(estimators = estimators, voting = 'soft')\n\nvot_clf.fit(train, target)\nvot_pred = vot_clf.predict(test)\nprint('Accuracy Score:',round(vot_clf.score(train, target)*100,2))","79e29010":"submit_data = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nsubmit_data.head()","799384db":"submit_data['Survived'] = rf_pred\nsubmit_data.head()","96470669":"submit_data.to_csv('output.csv', index = False)","9038819d":"Seperating the top titles.","6ddf2558":"Lets move to Modelling.","e29f7a5a":"Now, I will make use of dummy variables.","da8ba036":"#### Findings\n* People in 3rd Pclsas were not able to survive while People of 1st Pclass survived the most.\n* People with age from 20 to 30 were not able to Survive and they belong to 3rd Pclass. Whereas people with age 30 to 40 survived from 1st Pclass.\n* People with age 15 to 30 of 3rd Pclass survived too.\n* All children below 10 from 2nd Pclass were able to survive.\netc...","600b2c84":"## Upvote if you like my work.\n#### There is still alot to do in this notebook which I will keep updating.\n### Let me know the different Findings you get from the above Visualizations??\n### And What Algorithm do you think will work Best on this Data??","dd5fe702":"Replacing the values in the title column.","2aa585cb":"Lets do some Imputation Work.","511135d3":"Lets see the data.","4fa750f1":"#### Missing in Testing Data\n* Age (can be filled)\n* Fare (only 1 value)\n* Cabin (with lots of values)","cab23976":"Series is empty implies no missing values left in the set.","e0f889fd":"Family_size of 1 represents that he or she traveled alone on Titanic. I think alone traveller has lower chance of survival than the one with family. So I can do one thing to convert the columns 'SibSp', 'Parch' and 'Family_size' into a single column which can define whether the traveller was alone on the deck or not.","e802d5eb":"All columns are complete except 2. So need to impute values in the columns 'Age' and 'Embarked'.","02e7e494":"So most of the passengers are of age from roughly 20 to 40. Still we have to impute values in this column as there are lots of missing values in this column and this column with no doubt plays an important role in the Survival.","27b71a47":"I will create a new column which reprents the size of family. It will be made with the help of 'SibSp' and 'Parch'.","175db9a6":"I will first drop columns Which I don't think will be correlated to the target column.","8f268fca":"Next I will convert 'Sex' to the more acceptable form.","6fa7df0a":"#### Findings\nI got alot from this graph as findings.\n* Females have higher surviving rate than males.\n* Male who embarked from Cherbourg has high surviving rate as compared to male embarked from other ports.\netc...","82e8519b":"I am starting with the interesting plot. I am plotting the 'Age' feature with the 'Pclass' and seperating them according to their 'Survival' output.","103f789e":"Next, I will divide the Age column into parts. I think it will help in computation when I will use models on this dataset. It will be easier to find the splitting value for tree algorithms.\nThis division can be used as experiment, like we can use different size of groups. I am dividing Age into 8 parts and assign value 0 to 7 to these.","5ec9b6f5":"* I don't think Columns like 'PassengerId' and 'Ticket' plays a very important role in Survival.\n* There are lots of null values in 'Cabin' column so I think removing it, is the best. We could have used it because by this we could know the best chance of Survival due to the position of the cabin on the ship but I don't know the structure of titanic so that is why I am removing it.\n* There is only 2 null values in 'Embarked' column so that will work.\n* *'Fare' also have just one null value but I think it is correlated to 'Pclass' so removal of this feature could be done sa feature reduction.*\n* 'Name' is the magic column I think, so I will keep it.\n* Columns like 'Age' and 'Sex' will play an important role in Survival so I will keep them.\n* Columns like 'SibSp' and 'Parch' can also be used to get a new column of family size.","fa2f808b":"So the last line of the output matters, now the Age is simply divided into 8 groups with each group has people belonging to 10 years of span.","e9fb6c0c":"#### Findings\n* From the above Graph it is clear that most of the People aboard were of age ranging from 20 to 40.\n* Only 1 old person survived with aged 79 that too from 1st Pclass (from previous plot).\netc...","eb129359":"#### Findings\n* Fare from Queenstown port is lower than other ports.\n* High fare passengers have better surviving rate.\n* Fare could be the correlating feature for survival (WOW!!). High Fare could be the indication of 1st Pclass which I already explored, and they have higher surviving rate.","8fecd6a3":"Most of the names are starting with Mr, Miss, Mrs and Master. I will replace all other values with 'Special'.\nThe information from the 'Name' column is extracted and as there does not seem to have other information from this column so I am deleting the 'Name' column from the dataset.","7adac4d1":"I will Preprocess the whole Dataset at the same time.","e6387655":"Now, as I have finished the preprocessing part so lets move into the modelling but before that I am getting my training and testing set back.","cb5ebe2c":"#### Findings\n* Most of the passengers didn't survive. As only around ~330 people survived from 891.\n* Most of the passengers were from Pclass = 3.\n* Most of the passengers were Male.\n* Most of the passengers aboard from Southampton.","4112dde8":"Lets take a quick look on our data.","712e841d":"To impute Age in the dataset I will not just impute it with mena or median beacause that will make the distribution of age abnormal. Rather I will try to guess their age with the help of Gender and Pclass.\nThanks to https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\/ notebook for the idea.","d62fe748":"Lets visualize our data with respect to our target variable that is 'Survival'.","ac3b1763":"Getting Survival in the seperate variable called 'target'.","4a93913f":"I will combine both training and testing set for some more Exploring and then I will use this complete set for PreProcessing as well.","7edccce9":"#### Findings\n* Most of the people were traveling alone.\n* Siblings or spouses were on the deck.\n* There were very few who was traveling with there family.","8aab3279":"Lets take care of the first column which distract me the most is 'Name'.\nThis column as it is I don't think has any other information but the title before every name. So, lets take these titles out from avery name of the dataset.","39174009":"#### Missing in Training Data\n* Age (can be filled)\n* Cabin (with lots of values)\n* Embarked (with 2 values)"}}