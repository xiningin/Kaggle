{"cell_type":{"fbe923ca":"code","e02082eb":"code","415cceed":"code","e563191a":"code","04d355b7":"code","4dc184da":"code","6f68a73f":"code","202e24e0":"code","7421da2a":"code","2a3cafbc":"code","48a97f6f":"code","5962c17d":"code","39ddd306":"code","cfb49f52":"code","bff1e681":"code","40a73fc0":"code","77eac301":"code","6f129fc7":"code","3dc6b3cc":"code","9d2268a9":"code","ff7da529":"code","e2c223e3":"code","9e464593":"code","3fb47b25":"markdown","3ec18a62":"markdown","499be87b":"markdown","b5dd09fe":"markdown","1b263023":"markdown","9ffab37b":"markdown"},"source":{"fbe923ca":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport torch\nimport torchvision\nimport PIL\n\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\ntorch.__version__, torchvision.__version__","e02082eb":"# Check GPU\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","415cceed":"# For data augementation\n# https:\/\/discuss.pytorch.org\/t\/anything-like-transformer-for-tensordataset\/928\/4\n\n# Need to turn on Internet\n# https:\/\/www.kaggle.com\/questions-and-answers\/36982#466931\n\n!pip install git+https:\/\/github.com\/ncullen93\/torchsample","e563191a":"import torchsample\ntorchsample.__version__","04d355b7":"def rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))","4dc184da":"def predict(net, loader, record_y=False):\n\n    y_pred_list = []\n    with torch.no_grad():\n\n        total_loss = 0.0\n        total_sample = 0\n        for i, data in enumerate(loader, 0):\n            inputs, labels = data[0].to(device), data[1].to(device)\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            \n            current_sample = len(labels)\n            total_sample += current_sample\n            total_loss += loss.item() * current_sample\n\n            if record_y:\n                y_pred_list.append(outputs.cpu().numpy())\n                \n    avg_loss = total_loss \/ total_sample\n    print(f\"Average loss: {avg_loss}\")\n    \n    if record_y:\n        y_pred = np.concatenate(y_pred_list)\n        return y_pred\n    else:\n        return avg_loss","6f68a73f":"%time ds = xr.open_dataset('..\/input\/galaxy-zoo-cleaned\/galaxy_train.nc')\nds","202e24e0":"%%time\nX = ds['image_train'].transpose('sample', 'channel', 'x' ,'y').data  # pytorch use channel-first, unlike Keras\ny = ds['label_train'].data\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X, y, test_size=0.2, random_state=0)","7421da2a":"# Without data augmentation\ntrainset = torch.utils.data.TensorDataset(\n    torch.from_numpy(X_train), torch.from_numpy(y_train)\n)\n\n# # With Data augmentation \n# # tips from http:\/\/benanne.github.io\/2014\/04\/05\/galaxy-zoo.html\n# transform = torchsample.transforms.Compose([\n#     torchsample.transforms.Rotate(90),\n#     torchsample.transforms.RandomFlip(),\n#     # torchsample.transforms.Translate(0.04)  # translation decreases performance!\n# ])\n\n# trainset = torchsample.TensorDataset(\n#     torch.from_numpy(X_train), torch.from_numpy(y_train),\n#     input_transform = transform\n# )\n\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size=32, shuffle=True, num_workers=2\n)\n\nevalset = torch.utils.data.TensorDataset(\n    torch.from_numpy(X_valid), torch.from_numpy(y_valid)\n)\n\nevalloader = torch.utils.data.DataLoader(\n    evalset, batch_size=32, shuffle=False, num_workers=2\n)","2a3cafbc":"dataiter = iter(trainloader)\ndata = dataiter.next()\ninputs, labels = data[0].to(device), data[1].to(device)\ninputs.shape, labels.shape  # batch, channel, x, y","48a97f6f":"from torchvision.models.resnet import _resnet, BasicBlock\n\ndef resnet10(pretrained=False, progress=True, **kwargs):\n    # Apapted from https:\/\/github.com\/pytorch\/vision\/blob\/9cdc8144a1b462fecee4b2efe0967ba172708c4b\/torchvision\/models\/resnet.py#L227\n    return _resnet('resnet10', BasicBlock, [1, 1, 1, 1], pretrained, progress,\n                   **kwargs)\n\nnet = resnet10(pretrained=False, num_classes=37)\n# net = torchvision.models.resnet.resnet18(pretrained=False, num_classes=37)","5962c17d":"%time net.to(device)\n;","39ddd306":"net(inputs).shape","cfb49f52":"%%time\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(net.parameters())\n\nprint_freq = 400  # print loss per that many steps\n\ntrain_history = []\neval_history = []\nfor epoch in range(20):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        # inputs, labels = data\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % print_freq == print_freq-1:\n            print('[%d, %5d] loss: %.4f' %\n                  (epoch + 1, i + 1, running_loss \/ print_freq))\n            running_loss = 0.0\n            \n    print('Training loss:')\n    train_loss = predict(net, trainloader, record_y=False)\n    train_history.append(train_loss)\n    print('Validation loss:')\n    eval_loss = predict(net, evalloader, record_y=False)\n    eval_history.append(eval_loss)\n    print('-- new epoch --')\n\nprint('Finished Training')","bff1e681":"df_history = pd.DataFrame(\n    np.stack([train_history, eval_history], axis=1), \n    columns=['train_loss', 'val_loss'],\n)\ndf_history.index.name = 'epoch'\ndf_history","40a73fc0":"plt.rcParams['font.size'] = 14\ndf_history.plot(grid=True, marker='o', ylim=[0, None], linewidth=3.0, alpha=0.8)\nplt.title('ResNet-10 on Galaxy Zoo (no data augmentation)')\nplt.savefig('training_history.png', dpi=144, bbox_inches='tight')","77eac301":"# save loss history\ndf_history.to_csv('train_history.csv')","6f129fc7":"!head train_history.csv","3dc6b3cc":"%%time\ny_valid_pred = predict(net, evalloader, record_y=True)","9d2268a9":"rmse(y_valid, y_valid_pred)","ff7da529":"r2_score(y_valid, y_valid_pred)","e2c223e3":"%time torch.save(net.state_dict(), '.\/trained_resnet.pt')","9e464593":"ls -lh trained_resnet.pt","3fb47b25":"# Evaluation","3ec18a62":"# Examine learning curve","499be87b":"# Util functions","b5dd09fe":"# Save trained model","1b263023":"# Fit model","9ffab37b":"# Prepare training data"}}