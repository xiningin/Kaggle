{"cell_type":{"53610568":"code","5df19356":"code","5b575af6":"code","e7d90ab0":"code","e543b8fd":"code","2cf63e80":"code","21532860":"code","3b3538fd":"code","4d74774d":"code","b2385b7f":"code","2de0335d":"code","cbd5080e":"code","0efa9be2":"markdown","c14b68b3":"markdown","a8af7b84":"markdown","3910fad1":"markdown","0465165a":"markdown","802aec3a":"markdown","58bc8ebf":"markdown","c13a7036":"markdown","6f5960fc":"markdown","a60a6ccf":"markdown"},"source":{"53610568":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5df19356":"train, test = pd.read_csv(\"\/kaggle\/input\/mldl-minor-project\/df_train.csv\"), pd.read_csv(\"\/kaggle\/input\/mldl-minor-project\/df_test.csv\")","5b575af6":"train.info()","e7d90ab0":"train.describe()","e543b8fd":"train.head()","2cf63e80":"'''\nThis part is to be done by you and is actually optional but highly recommended\n'''","21532860":"from sklearn.model_selection import train_test_split as tts\ntrain, dev = tts(train, test_size=0.2, random_state=69)","3b3538fd":"X_train, y_train = train.drop(['Id', 'Cover_Type'], axis=1), train['Cover_Type']\nX_dev, y_dev = dev.drop(['Id', 'Cover_Type'], axis=1), dev['Cover_Type']\nX_test = test.drop(['Id'], axis=1)","4d74774d":"'''\nPreprocess your data here, apply all the preprocessing to X_train, X_test, X_dev\n'''","b2385b7f":"'''\nHere I am using the simplest classifier, which will have bad results, improvements are to be done by you\n'''\n\n# Check sklearn and different models as discussed in class\nfrom sklearn.dummy import DummyClassifier\n\nmodel = DummyClassifier()\nmodel.fit(X_train, y_train)\ntrain_pred = model.predict(X_train)\ndev_pred = model.predict(X_dev)\ntest_pred = model.predict(X_test)","2de0335d":"from sklearn.metrics import accuracy_score\nprint(\"Accuracy on training data = %0.2f\" % accuracy_score(y_true=y_train, y_pred=train_pred))\nprint(\"Accuracy on development data = %0.2f\" % accuracy_score(y_true=y_dev, y_pred=dev_pred))","cbd5080e":"submission = pd.read_csv('\/kaggle\/input\/mldl-minor-project\/sample_submission.csv')\nsubmission['Cover_Type']=test_pred\nsubmission.to_csv('submission.csv', index=False)","0efa9be2":"# Check the data info\nAll columns are int type, No null entries","c14b68b3":"# Submitting your predictions","a8af7b84":"# Visualisation","3910fad1":"# Separate your X and Y values","0465165a":"# Split your training data to train and dev","802aec3a":"### The predictions suck as of now\n##### Which is the way it was intended, dummy classifiers are random baselines, ie the worst model","58bc8ebf":"# Create your model, fit and predict","c13a7036":"# Preprocess your data","6f5960fc":"# Loading the data\nUse pandas read functionality","a60a6ccf":"### Go to save version, commit, save and run all"}}