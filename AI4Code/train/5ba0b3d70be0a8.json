{"cell_type":{"6bcec9c7":"code","0a8a316a":"code","20bfeabf":"code","62d21c47":"code","44f259d6":"code","f7b38e69":"code","d14c5596":"code","c0b319c2":"code","31f8c95f":"code","37048fb9":"code","41135e9f":"code","2fd422e4":"code","73793ed8":"code","8c8e5f2f":"code","98bc3cf3":"code","35699c9b":"code","1ded3054":"code","7d09cd2a":"code","3c3af4e6":"code","6968dd45":"code","20d81512":"code","ab63e178":"code","698ffb6d":"code","b0f9314d":"code","af607286":"code","f680e3fb":"code","7cf0d620":"code","e86c062a":"code","1fc8ff23":"code","df8a7665":"code","029836c9":"code","486c149f":"code","12db52c7":"code","70a76c36":"code","8fd04e70":"code","c6a2c57f":"code","42dad53b":"code","6ffbffb4":"code","aacda0a6":"markdown","cced3061":"markdown","b5e56bdb":"markdown","83edd6e5":"markdown","373e03c7":"markdown","45033b22":"markdown","aa53fa4d":"markdown","a635ca34":"markdown","509adb2c":"markdown","50b1790d":"markdown","811d0333":"markdown","11ccbbfb":"markdown","e8ec0195":"markdown","0c569bb1":"markdown","cd2fb46e":"markdown","67f5f87c":"markdown","7be8f4bf":"markdown","779e1288":"markdown","63ab6a28":"markdown","0981898a":"markdown","9342ca26":"markdown","a831b66f":"markdown","f394f98a":"markdown","b9890163":"markdown","4258d979":"markdown","4e98b17b":"markdown"},"source":{"6bcec9c7":"import pandas as pd\nimport numpy as np\nimport cudf\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom cuml.metrics import r2_score\nfrom cuml.metrics import mean_squared_error\nfrom cuml.ensemble import RandomForestRegressor\n\nsns.set_palette('husl')","0a8a316a":"train = cudf.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/train.csv\")\ntest = cudf.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/test.csv\")\nsample_submission = cudf.read_csv('..\/input\/tabular-playground-series-feb-2021\/sample_submission.csv')","20bfeabf":"train.tail(3)","62d21c47":"test.tail(3)","44f259d6":"sample_submission.tail(3)","f7b38e69":"train.shape , test.shape ","d14c5596":"train.columns","c0b319c2":"train.describe()","31f8c95f":"train.info()","37048fb9":"np.sum(train.isna())","41135e9f":"sns.pairplot(train.to_pandas().sample(500))","2fd422e4":"df_train_sample=train.to_pandas().sample(1000) #visulize only 1000 samples ","73793ed8":"plt.figure(figsize=(27,25))\nplt.subplot(4, 3 , 1)\ndf_train_sample.cat0.value_counts().plot.pie(explode= (0.05 , 0), autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14},\n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT0');\n\nplt.subplot(4 , 3 , 2)\ndf_train_sample.cat1.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT1');\n\n\nplt.subplot(4 , 3 , 3)\ndf_train_sample.cat2.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT2');\n\nplt.subplot(4 , 3 , 4)\ndf_train_sample.cat3.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT3');\n\nplt.subplot(4, 3 , 5)\ndf_train_sample.cat4.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT4');\n\nplt.subplot(4 , 3 , 6)\ndf_train_sample.cat5.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT5');\n\nplt.subplot(4 , 3 , 7)\ndf_train_sample.cat6.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT6');\n\nplt.subplot(4 , 3 , 8)\ndf_train_sample.cat7.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT7');\n\nplt.subplot(4 , 3 , 9)\ndf_train_sample.cat8.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT8');\n\n\nplt.subplot(4 , 3 , 10)\ndf_train_sample.cat9.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT9')","8c8e5f2f":"sns.histplot(data=df_train_sample, x=\"target\").set(title = 'Distribution the target');","98bc3cf3":"np.sum(train.isna())","35699c9b":"trainp = train.to_pandas()\nfig=plt.figure(figsize=(25,11))\ncol=['id','target']\nsns.boxplot(data=trainp.drop(columns=col,axis=1))\nplt.title('Train Outliers Before Cleaning')\nplt.show()","1ded3054":"before = len(train)\nprint('Data length before removing the outliers = ', before)","7d09cd2a":"train= train[(train['cont0']>train['cont0'].quantile(.05))&\n      (train['cont2']>train['cont2'].quantile(.05))&\n      (train['cont2']<train['cont2'].quantile(.95))&\n      (train['cont6']<train['cont6'].quantile(.95))&\n      (train['cont8']<train['cont8'].quantile(.95))&     \n      (train['target']<train['target'].quantile(.95))&\n      (train['target']>train['target'].quantile(.05))]\ntrain","3c3af4e6":"fig=plt.figure(figsize=(25,11))\ncol=['id','target']\nsns.boxplot(data=train.to_pandas().drop(columns=col,axis=1))\nplt.title('Train Outliers After Cleaning')\nplt.show()","6968dd45":"after = len(train) #after removing outliers \nprint('Data length after removing the outliers = ', after)","20d81512":"train.to_pandas().corr() #to know the suitable fetures to be split","ab63e178":"from cuml.preprocessing import train_test_split\n\nX = train.drop('target', axis=1)\nX = cudf.get_dummies(X)\n\ny = train.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)","698ffb6d":"from sklearn.preprocessing import StandardScaler\nstandrd = StandardScaler()\ncol=X_train.columns\nX_train = standrd.fit_transform(X_train.to_pandas()) # Switching between pandas & rapids\nX_test = standrd.transform(X_test.to_pandas()) # Switching between pandas & rapids\nprint('The scaled data are:')\nX_train,X_test","b0f9314d":"# Switching between pandas & rapids\nt= pd.DataFrame(X_train)\nX_train=cudf.DataFrame.from_pandas(t)","af607286":"# Switching between pandas & rapids \nt_test= pd.DataFrame(X_test)\nX_test=cudf.DataFrame.from_pandas(t_test)","f680e3fb":"def baseline_model(n_preds, pred):\n    return cudf.Series([pred for n in range(n_preds)])","7cf0d620":"baseline_preds = baseline_model(len(y_test), np.mean(y_train))\nprint('Baseline Predections Are:')\nbaseline_preds","e86c062a":"bl_mse = mean_squared_error(y_true=y_test,y_pred=baseline_preds,squared=False)\nprint('Baseline Mean Squared Error = ', bl_mse)","1fc8ff23":"for n in X_train.columns:\n    X_train[n]=X_train[n].astype(np.float32)","df8a7665":"rfr =RandomForestRegressor()","029836c9":"rfr.fit(X_train, y_train)\nprint('Fit completed.')","486c149f":"pred_rfr = rfr.predict(X_test)\nprint('Random Forest Regressor Predections Are:')\npred_rfr","12db52c7":"rfr_rmse =mean_squared_error(y_true=y_test.astype(np.float64),\n                   y_pred=pred_rfr.astype(np.float64),\n                   squared=False)\nprint('Random Forest Regressor Mean Squared Error = ', rfr_rmse)","70a76c36":"# Switching Between pandas and rapids\nX_train_pandas=X_train.to_pandas()\ny_train_pandas=y_train.to_pandas()\n\n# X_train_tcd=cudf.DataFrame.from_pandas(t)","8fd04e70":"# from sklearn.ensemble import RandomForestRegressor\n# rfr  = RandomForestRegressor() \n\n# from sklearn.model_selection import GridSearchCV\n# p_grid = {'max_features': ['auto', 'sqrt', 'log2']}\n# grid = GridSearchCV(rfr, p_grid,cv=10)","c6a2c57f":"# grid.fit(X_train_pandas, y_train_pandas)\n# print('Fit completed.')","42dad53b":"# best = grid.best_params_\n# print('The best parameters for the model are:', best)","6ffbffb4":"%%time\n\n# data load\ntrain = cudf.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/train.csv\")\ntest = cudf.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/test.csv\")\nsample_submission = cudf.read_csv('..\/input\/tabular-playground-series-feb-2021\/sample_submission.csv')\n\n# data prep\nX = train.drop('target', axis=1)\nX = cudf.get_dummies(X)\n\ny = train.target\n\ntest = cudf.get_dummies(test)\ntest['cat6_G'] = 0  # fix lack of Gs in test data\nfor n in X.columns:\n    X[n]=X[n].astype(np.float32)\n# modeling\nrfr = RandomForestRegressor()\nrfr.fit(X,y)\n \nrf_preds =rfr.predict(test)\n\n# save results & submit\nsample_submission['target'] = rf_preds\n\nsample_submission.to_csv('submission.csv', index=False)","aacda0a6":"# **Project Specifications**","cced3061":"# EDA","b5e56bdb":"# **Model Selection**","83edd6e5":"* Getting the Dummies and Split Data:","373e03c7":"## Data Cleaning","45033b22":"## Data Splitting","aa53fa4d":"### Checking for Null Values","a635ca34":"* We noticed that the Mean Squared Error (MSE) has decreased after removing the outliers and scaling the data.\n* Also, we tried different parametes inside the Random Forest Regressor model to have the best result.\n* MSE Before: around 0.7351\n* MSE After: around 0.7322\n\nHowever,\n* We tried to obtain the GridSearchCV to decrease the MSE of the used model (Random Forest Regressor).\n* The fiiting of the GridSearchCV took so long, and the notebook's CPU became full and bussy.\n* So, we decided to remain on the last result that we came with for the Random Forest Regressor model and with the same parameters that we used.","509adb2c":"* We want to see the difference after removing the outliers:","50b1790d":"# To submit the result in Kaggle","811d0333":"### About the Above Histogram:\n* The distibution of the target show that it's reaching its highest values between 8 and 9.\n* We think that there are some outliers near 4 and 5.","11ccbbfb":"# **Data Loading**","e8ec0195":"## TPS Feb 2021\nStarter Notebook\n\n### Deleverables\n1. EDA\n    - What's going on?\n    - Show me the data...\n2. Model\n    - Baseline...\n    - Simple...\n    - Evaluation...\n    - Improvement...\n3. RAPIDS Bonus\n    - Apply RAPIDS ([Starter Notebook](https:\/\/www.kaggle.com\/tunguz\/tps-feb-2021-rapids-starter))\n    - Replace pandas with cuDF & sklearn with cuML\n    \n    \n#### Troubleshooting\n- [Data](https:\/\/www.kaggle.com\/c\/tabular-playground-series-feb-2021\/data)\n- [Overview](https:\/\/www.kaggle.com\/c\/tabular-playground-series-feb-2021\/overview)\n- [RF Starter Notebook](https:\/\/www.kaggle.com\/warobson\/tps-feb-2021-rf-starter)\n- [ML repo on GitHub](https:\/\/github.com\/gumdropsteve\/intro_to_machine_learning)\n- [Most simple RAPIDS Notebook submission](https:\/\/www.kaggle.com\/warobson\/simple-rapids-live) (Has stuff like `train_test_split()` with cuml..)","0c569bb1":"## Baseline Model","cd2fb46e":"### Checking for Outliers","67f5f87c":"# Data Visulization","7be8f4bf":"### About the Above Box Plot:\n* We noticed increasing in the outliers, but we assumed that these became closer after removing the selected outliers.","779e1288":"## Data Exploring","63ab6a28":"## Grid SearchCV","0981898a":"## Random Forest Regressor Model","9342ca26":"### About the Above Pie Charts:\n* We noticed that A values are the highest amount in most of the columns among all other values. \n* CAT9 & CAT8 are having large diversities in thier values, especially CAT9 ","a831b66f":"# **Data Modeling**","f394f98a":"## Data Scaling","b9890163":"# Data Optimization","4258d979":"# **Weekend Project (TPS)**\n## Machine Learning Section (week 3)\n\n### Group Members:\n* Shaima Alharbia\n* Shaikha AlBilais","4e98b17b":"# **Libraries Importing**"}}