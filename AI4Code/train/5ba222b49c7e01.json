{"cell_type":{"f190372b":"code","20a41df6":"code","ab2d1732":"code","304571b5":"code","e7a42a55":"code","9b23fa0c":"code","3eed7297":"code","80f05e4a":"code","42c3b084":"code","e8b71836":"code","f471aa6b":"code","f59555c7":"code","078cc326":"code","d67c66c7":"code","c746bf26":"code","e9d1c759":"code","dcffbdca":"code","2199e60b":"code","ba5a9b12":"code","f779c3f8":"code","92f24a1e":"code","da8427ec":"code","53e9608b":"code","aaa7c7f1":"code","cca03e7d":"code","9ebc14a0":"code","ae90f7f2":"code","99f6463f":"code","6c9afbf3":"code","2569d10a":"code","a53aea2e":"code","1d4bfba1":"code","e13e4a03":"code","d6bfa7b4":"code","2b1f98dd":"code","b6150627":"code","d23cc0ef":"code","492809b9":"code","1d7d3570":"code","6071e5d9":"code","34cddfd1":"code","b21afccf":"code","0512d196":"code","3f53f06a":"code","838aa5fb":"code","9f72faf2":"code","f1e7c08c":"code","38578c3a":"code","72460f85":"code","4698eacb":"code","c8c018b4":"code","d6149f8a":"code","9dcf68b7":"code","7cc2efc1":"code","e151d2f9":"code","52d01b1a":"code","0850a530":"code","33e7dfa9":"code","099ce75d":"code","7bd482d4":"code","198c8462":"markdown","16c752f4":"markdown","8591f0e3":"markdown","e0861475":"markdown","99549feb":"markdown","c0962671":"markdown","723b274c":"markdown","47fcf702":"markdown","2353f61f":"markdown","d4a41e8e":"markdown","d7bad65a":"markdown","d6ee9005":"markdown","066226b7":"markdown","c155214e":"markdown","c194aa90":"markdown","ebe4ceec":"markdown","ddfa7630":"markdown","4ef024e3":"markdown","a9cb3634":"markdown","489abdf5":"markdown","d126e135":"markdown","c153fad8":"markdown","a824c812":"markdown","f6b771c1":"markdown","f7ed7087":"markdown","5f01b615":"markdown","dc76c3d4":"markdown","31f05906":"markdown","d65e21d3":"markdown","1890700a":"markdown","27318b57":"markdown","acd7f906":"markdown","7f84e406":"markdown"},"source":{"f190372b":"! pip install simpletransformers","20a41df6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%pylab inline ","ab2d1732":"sub = pd.read_csv('..\/input\/dataset\/sample_submission.csv')\nsub.head(1)","304571b5":"train = pd.read_csv('..\/input\/dataset\/train.csv')\ntrain.head()","e7a42a55":"train.language.value_counts()","9b23fa0c":"train.language.value_counts(dropna=False).plot(kind='bar', color='red', rot=0)\nplt.xlabel('language')\n\nsns.despine()\nprint(\"Number of Tuples with data in Hindi Language =\",sum(train.language == 'hindi'))\nprint(\"Number of Tuples with data in Tamil Language =\",sum(train.language == 'tamil'))","3eed7297":"test = pd.read_csv('..\/input\/dataset\/test.csv')\ntest.head()","80f05e4a":"len(test)","42c3b084":"print(\"We have\", train.shape[0], \"Tuples in the train set\", \n      test.shape[0], \"in the test set.\")\nprint(\"In total we have\", train.shape[0] + test.shape[0], \"tuples.\")","e8b71836":"## Computing NaN percentage of each feature (attribute).\ntrain_nan = (train.isnull().sum() \/ train.shape[0]) * 100\nprint(train_nan)","f471aa6b":"## Compute NaN percentage of each feature (attribute).\ntest_nan = (test.isnull().sum() \/ test.shape[0]) * 100\nprint(test_nan)","f59555c7":"train_missing = train.isna()\ntrain_missing.head(10)","078cc326":"test1_missing = test.isna()\ntest1_missing.head()","d67c66c7":"train.columns","c746bf26":"test.columns","e9d1c759":"df = pd.DataFrame(train)\ndf[['question','answer_text']]","dcffbdca":"import transformers","2199e60b":"model_checkpoint = '..\/input\/xlmrobertalargesquad2'\nbatch_size = 4","ba5a9b12":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","f779c3f8":"train['num_tokens_context'] = train['context'].apply(lambda t: len(tokenizer(t)['input_ids']))","92f24a1e":"train['num_tokens_context'].hist()","da8427ec":"max_length = 384 \ndoc_stride = 128 ","53e9608b":"pad_on_right = tokenizer.padding_side == \"right\"","aaa7c7f1":"def prepare_train_features(examples):\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n\n    tokenized_examples[\"start_positions\"] = []\n    tokenized_examples[\"end_positions\"] = []\n\n    for i, offsets in enumerate(offset_mapping):\n        input_ids = tokenized_examples[\"input_ids\"][i]\n        cls_index = input_ids.index(tokenizer.cls_token_id)\n\n        sequence_ids = tokenized_examples.sequence_ids(i)\n\n        sample_index = sample_mapping[i]\n        answers = examples[\"answers\"][sample_index]\n        if len(answers[\"answer_start\"]) == 0:\n            tokenized_examples[\"start_positions\"].append(cls_index)\n            tokenized_examples[\"end_positions\"].append(cls_index)\n        else:\n            start_char = answers[\"answer_start\"][0]\n            end_char = start_char + len(answers[\"text\"][0])\n\n            token_start_index = 0\n            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n                token_start_index += 1\n\n            token_end_index = len(input_ids) - 1\n            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n                token_end_index -= 1\n\n            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n                tokenized_examples[\"start_positions\"].append(cls_index)\n                tokenized_examples[\"end_positions\"].append(cls_index)\n            else:\n                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n                    token_start_index += 1\n                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n                while offsets[token_end_index][1] >= end_char:\n                    token_end_index -= 1\n                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n\n    return tokenized_examples","cca03e7d":"from datasets import Dataset","9ebc14a0":"def convert_answers(r):\n    start = r[0]\n    text = r[1]\n    return {\n        'answer_start': [start],\n        'text': [text]\n    }","ae90f7f2":"train = train.sample(frac=1, random_state=42)\ntrain['answers'] = train[['answer_start', 'answer_text']].apply(convert_answers, axis=1)","99f6463f":"df_train = train[:-64].reset_index(drop=True)\ndf_valid = train[-64:].reset_index(drop=True)","6c9afbf3":"train_dataset = Dataset.from_pandas(df_train)\nvalid_dataset = Dataset.from_pandas(df_valid)","2569d10a":"train_dataset[0]","a53aea2e":"tokenized_train_ds = train_dataset.map(prepare_train_features, batched=True, remove_columns=train_dataset.column_names)\ntokenized_valid_ds = valid_dataset.map(prepare_train_features, batched=True, remove_columns=train_dataset.column_names)","1d4bfba1":"from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)","e13e4a03":"%env WANDB_DISABLED=True","d6bfa7b4":"args = TrainingArguments(\n    f\"chaii-qa\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=3e-5,\n    gradient_accumulation_steps=8,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=1,\n    weight_decay=0.01,\n)","2b1f98dd":"from transformers import default_data_collator\n\ndata_collator = default_data_collator","b6150627":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=tokenized_train_ds,\n    eval_dataset=tokenized_valid_ds,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","d23cc0ef":"#trainer.train()","492809b9":"trainer.save_model(\"chaii-bert-trained\")","1d7d3570":"def prepare_validation_features(examples):\n    \n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    \n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    \n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n\n    tokenized_examples[\"example_id\"] = []\n\n    for i in range(len(tokenized_examples[\"input_ids\"])):\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        context_index = 1 if pad_on_right else 0\n\n\n        sample_index = sample_mapping[i]\n        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n\n        \n        tokenized_examples[\"offset_mapping\"][i] = [\n            (o if sequence_ids[k] == context_index else None)\n            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n        ]\n\n    return tokenized_examples","6071e5d9":"validation_features = valid_dataset.map(\n    prepare_validation_features,\n    batched=True,\n    remove_columns=valid_dataset.column_names\n)","34cddfd1":"len(validation_features)","b21afccf":"validation_features","0512d196":"valid_feats_small = validation_features.map(lambda example: example, remove_columns=['example_id', 'offset_mapping'])\nvalid_feats_small","3f53f06a":"raw_predictions = trainer.predict(valid_feats_small)","838aa5fb":"max_answer_length = 30","9f72faf2":"import collections\n\nexamples = valid_dataset\nfeatures = validation_features\n\nexample_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\nfeatures_per_example = collections.defaultdict(list)\nfor i, feature in enumerate(features):\n    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)","f1e7c08c":"from tqdm.auto import tqdm\n\ndef postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n    all_start_logits, all_end_logits = raw_predictions\n    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n    features_per_example = collections.defaultdict(list)\n    for i, feature in enumerate(features):\n        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n\n    predictions = collections.OrderedDict()\n\n    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n\n    for example_index, example in enumerate(tqdm(examples)):\n        feature_indices = features_per_example[example_index]\n\n        min_null_score = None # Only used if squad_v2 is True.\n        valid_answers = []\n        \n        context = example[\"context\"]\n        for feature_index in feature_indices:\n            start_logits = all_start_logits[feature_index]\n            end_logits = all_end_logits[feature_index]\n            offset_mapping = features[feature_index][\"offset_mapping\"]\n\n            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n            if min_null_score is None or min_null_score < feature_null_score:\n                min_null_score = feature_null_score\n\n            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    if (\n                        start_index >= len(offset_mapping)\n                        or end_index >= len(offset_mapping)\n                        or offset_mapping[start_index] is None\n                        or offset_mapping[end_index] is None\n                    ):\n                        continue\n                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n                        continue\n\n                    start_char = offset_mapping[start_index][0]\n                    end_char = offset_mapping[end_index][1]\n                    valid_answers.append(\n                        {\n                            \"score\": start_logits[start_index] + end_logits[end_index],\n                            \"text\": context[start_char: end_char]\n                        }\n                    )\n        \n        if len(valid_answers) > 0:\n            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n        else:\n            best_answer = {\"text\": \"\", \"score\": 0.0}\n        \n        predictions[example[\"id\"]] = best_answer[\"text\"]\n\n    return predictions","38578c3a":"final_predictions = postprocess_qa_predictions(valid_dataset, validation_features, raw_predictions.predictions)","72460f85":"references = [{\"id\": ex[\"id\"], \"answer\": ex[\"answers\"]['text'][0]} for ex in valid_dataset]","4698eacb":"def jaccard(row): \n    str1 = row[0]\n    str2 = row[1]\n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))","c8c018b4":"res = pd.DataFrame(references)\nres['prediction'] = res['id'].apply(lambda r: final_predictions[r])\nres['jaccard'] = res[['answer', 'prediction']].apply(jaccard, axis=1)\nres.head(40)","d6149f8a":"res.jaccard.mean()","9dcf68b7":"test_dataset = Dataset.from_pandas(test)","7cc2efc1":"test_features = test_dataset.map(\n    prepare_validation_features,\n    batched=True,\n    remove_columns=test_dataset.column_names\n)","e151d2f9":"test_feats_small = test_features.map(lambda example: example, remove_columns=['example_id', 'offset_mapping'])\ntest_feats_small","52d01b1a":"test_predictions = trainer.predict(test_feats_small)","0850a530":"test_features.set_format(type=test_features.format[\"type\"], columns=list(test_features.features.keys()))","33e7dfa9":"final_test_predictions = postprocess_qa_predictions(test_dataset, test_features, test_predictions.predictions)","099ce75d":"sub['PredictionString'] = sub['id'].apply(lambda r: final_test_predictions[r])\nsub.head()","7bd482d4":"sub.to_csv('submission.csv', index=False)","198c8462":"**Saving the trained model as chaii-bert-trained**","16c752f4":"**Calling Training argument function and storing it in args variable**","8591f0e3":"# 5DMACP14 Hindi and Tamil Question Answering Model\n\n01FE20BCS403 Vikas Byahatti\n\n01FE20BCS418 Nitin Shetty\n\n01FE20BCS409 Ganesh Dalabanjan\n\n01FE20BCS410 Allauddin Khan","e0861475":"**Printing the predicted strings**","99549feb":"**Preparing the validation sets**","c0962671":"**Checking if there exists missing data in data sets**","723b274c":"**Storing the prediction in raw_prediction**","47fcf702":"**Displaying the question and answer_text attribute explicitely**","2353f61f":"**Mapping all the validation set into validation features**","d4a41e8e":"# Calculating the jaccard value","d7bad65a":"**Saving the Model**","d6ee9005":"# Preparing Train Attributes for the model (Preprocessing)","066226b7":"**Listing out the columns in train dataset**","c155214e":"**Counting total number of tuples in Hindi and Tamil Languages**","c194aa90":"**Calling Trainer function and storing it in trainer variable**","ebe4ceec":"**Reading Train Dataset**","ddfa7630":"**Storing Predictions after processing into final prediction**","4ef024e3":"**Tokenizing train and validation sets**","a9cb3634":"**Printing Total Number of tuples in both test and train dataset**","489abdf5":"**Setting the maximum length for tokens**","d126e135":"**Creating Predictionstring attribute for submission file and storing the predictions in it**","c153fad8":"# Reading Test Dataset\n\n**In test, we have just 5 examples, and similar columns like in train except that we don't have answer_text and answer_start** ","a824c812":"# Importing Packages required for Running the model","f6b771c1":"**Listing out the columns in test dataset**","f7ed7087":"**Training the model**","5f01b615":"**Our goal is to predict answers to real questions about Wikipedia articles. We will use chaii-1, a new question answering dataset with question-answer pairs. The dataset covers Hindi and Tamil, collected without the use of translation. It provides a realistic information-seeking task with questions written by native-speaking expert data annotators.**","dc76c3d4":"**The above graph shows the context length for range of tuples**","31f05906":"# Generating Submission.csv file as per the template provided in the competition","d65e21d3":"**Prediction for test dataset and storing in test_predictions**","1890700a":"**Calculating the mean value of jaccard**","27318b57":"**Total Number of Tuples in Test Dataset**","acd7f906":"**Representation of number of tuples in each language in Graph**","7f84e406":"**Reading Sample Submission File**"}}