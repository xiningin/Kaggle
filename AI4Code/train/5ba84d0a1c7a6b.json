{"cell_type":{"2854ee4a":"code","3952df23":"code","f0402ee8":"code","0d534fc2":"code","ab860e8a":"code","943f8c17":"code","3a31c6a1":"code","1613af75":"code","cb392234":"code","367e4b9f":"markdown","3111955f":"markdown","392c3f28":"markdown","7e9d047c":"markdown","fd04e205":"markdown"},"source":{"2854ee4a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\n\n%matplotlib inline\npd.set_option('display.max_columns', None)\npd.options.display.notebook_repr_html = True\npd.options.display.precision = 3\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV","3952df23":"train = pd.read_csv(\"..\/input\/train_V2.csv\")\ntest = pd.read_csv(\"..\/input\/test_V2.csv\")","f0402ee8":"def preprocess_pubg_data(df, label = True, frac = 1):\n    \"\"\"\n    Do all preprocess in this function\n    \n    parameter\n    ---\n    label: whether df includes label column\n    frac: sampling (0-1)\n    \n    return\n    ---\n    gid: groupID (correspond to each row of X)\n    X: features\n    y: target variable (if train = True)\n    \"\"\"\n    \n    # filter features\n    df = df.drop([\"Id\", \"matchId\"], axis=1)\n    df = df.drop([\"numGroups\"], axis=1)\n    df = df.drop([\"vehicleDestroys\", \"maxPlace\", \"roadKills\", \"teamKills\", \"rankPoints\", \"killPoints\", \"winPoints\", \"matchDuration\"], axis=1)\n    \n    # add features\n    df[\"moveDistance\"] = df.loc[:, df.columns.str.endswith(\"Distance\")].apply(np.sum, axis=1)\n    \n    # aggregate in team\n    df_team = df.groupby(\"groupId\").agg([\"min\", \"mean\", \"max\"])\n    \n    # remove NA\n    df_team = df_team.dropna()\n    \n    # sampling\n    df_team = df_team.sample(frac = frac, random_state = 123)\n    gid = df_team.index.ravel()\n    \n    # return\n    if label:\n        X = df_team.drop(\"winPlacePerc\", axis=1).values\n        y = df_team[\"winPlacePerc\"][\"max\"].values\n\n        return gid, X, y\n    \n    else:\n        X = df_team.values\n        \n        return gid, X","0d534fc2":"gid_train, X_train, y_train = preprocess_pubg_data(train, frac = 0.01)\ngid_test, X_test = preprocess_pubg_data(test, False)","ab860e8a":"param = {\"n_estimators\": [1000], \n         \"max_features\": [10, 20, 40],\n         \"max_depth\": [5, 10, None]}","943f8c17":"reg = GridSearchCV(estimator=RandomForestRegressor(),\n             param_grid=param, cv=3, n_jobs=1, scoring=\"r2\",\n              return_train_score=False)","3a31c6a1":"%%time\ncv_result = reg.fit(X_train, y_train)","1613af75":"def my_predict(model, X_test):\n    pred = model.predict(X_test)\n\n    global test\n    id_list = test.loc[:,[\"Id\", \"groupId\"]]\n    \n    predict = pd.DataFrame({\"groupId\": gid_test, \"winPlacePerc\": pred})\n    submission = pd.merge(id_list, predict, how=\"left\", on=\"groupId\").drop([\"groupId\"], axis=1)\n    \n    return submission","cb392234":"submission = my_predict(reg, X_test)\nsubmission.to_csv(\"submission.csv\", index=False)","367e4b9f":"# Prediction","3111955f":"# Strategy\n\n* Set probem as regression (0-1)\n* Predict all format matches in single model\n* Because standing is defined by team (not each person), predict ranking in team unit.\n* Select `RandomforestRegressor` as baseline algorithm\n* Some feature enginerring (add\/filter features)\n* While outlier treatment will be needed for higher accuracy, I won't do in baseline model construction.","392c3f28":"# Training","7e9d047c":"# feature extraction\n\n* remove useless features\n* add some features\n* aggregate in team (min, mean, max)","fd04e205":"# import & load data"}}