{"cell_type":{"12a897d8":"code","19ced653":"code","43445c07":"code","2f8dfdce":"code","a097401f":"code","b1a93c78":"code","bc0ef19c":"code","98ba8e57":"code","605ac85c":"code","73be6221":"code","1a9e223d":"code","38702014":"code","045c9270":"code","31ceae71":"code","37a8951e":"code","eda9d6d1":"code","120dab0f":"code","44d7806e":"code","32ce57ae":"code","d6d0b2e6":"code","216ee6d5":"code","fd216610":"code","018bd54f":"code","602b260a":"code","2e70faf7":"code","e9f7f8d0":"code","bd2a518c":"code","dcbdb3e5":"code","2ae80dda":"code","e9ec66f7":"code","761e2bb0":"code","1402c299":"code","c042ce6d":"code","3fef0908":"code","bf2a60d9":"code","d5a5f22b":"code","07901ad3":"code","476db45b":"markdown","4f21c37f":"markdown","e0e7a69a":"markdown","ea64665d":"markdown","e8e31041":"markdown","6bcfac19":"markdown","696c83e6":"markdown","3be9639b":"markdown","9cddb1b7":"markdown","5703dce2":"markdown","f2c724ff":"markdown","2e54cc61":"markdown","88c05307":"markdown","26f91937":"markdown","a325cacd":"markdown","6fc9af9f":"markdown","9d6ad0e2":"markdown","40de7613":"markdown","7ba2e070":"markdown","57d25f02":"markdown","8fa0c618":"markdown","02a37fe4":"markdown","a7035d05":"markdown","a5130081":"markdown"},"source":{"12a897d8":"from IPython.display import YouTubeVideo\nYouTubeVideo('hXYd0WRhzN4', width=800, height=450)","19ced653":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pydicom, numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport json\nfrom PIL import Image\nfrom IPython.display import display\nimport os\nimport plotly.graph_objects as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom plotly.offline import init_notebook_mode\nfrom plotly.offline import iplot\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\nfrom tensorflow.keras.applications import DenseNet121\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold\n\nimport cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","43445c07":"train_df = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')\ntest_df = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/test.csv')\nsubs_df = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/sample_submission.csv')\n\nimage_path = '..\/input\/siim-isic-melanoma-classification\/train\/'\n\nprint('The size of training data : {}'.format(train_df.shape))\nprint('The size of testing data : {}'.format(test_df.shape))","2f8dfdce":"train_df.head()","a097401f":"a = np.mean(train_df.target)\nprint('The Distribution of Training dataset : {}'.format(a))","b1a93c78":"plt.figure(figsize = (17,7))\npercent_missing = train_df.isnull().sum() \/ (train_df.shape[0])*100\npercent_missing.iplot(kind = 'bar',color ='blue')","bc0ef19c":"train_df.describe()","98ba8e57":"print(\"The total patient ids are {}, from those the unique ids are {}\".format(train_df['patient_id'].count(),train_df['patient_id'].value_counts().shape[0] ))","605ac85c":"benign_gender = train_df.groupby(['benign_malignant']).count()['sex'].to_frame()\nbenign_gender.head()","73be6221":"#target and age\nplt.figure(figsize = (17,7))\nsns.boxplot(x = train_df['target'], y = train_df['age_approx'])","1a9e223d":"feature_list = ['sex','age_approx','anatom_site_general_challenge'] \nfor i in feature_list: \n    train_df[i].value_counts(normalize=True).to_frame().iplot(kind='bar',\n                                                      yTitle='Percentage', \n                                                      linecolor='black', \n                                                      opacity=0.7,\n                                                      color='blue',\n                                                      theme='pearl',\n                                                      bargap=0.8,\n                                                      gridcolor='white',                                                     \n                                                      title=f'<b>Distribution of {i} in train set.<\/b>')\n\n    test_df[i].value_counts(normalize=True).to_frame().iplot(kind='bar',\n                                                      yTitle='Percentage', \n                                                      linecolor='black', \n                                                      opacity=0.7,\n                                                      color='green',\n                                                      theme='pearl',\n                                                      bargap=0.8,\n                                                      gridcolor='white',                                                     \n                                                      title=f'<b>Distribution of {i} in test set.<\/b>')","38702014":"im = train_df['image_name'].values\ndisplay(im)","045c9270":"plt.figure(figsize=(17,6))\n\nimage_dir = '..\/input\/siim-isic-melanoma-classification\/'\n\nimg = [np.random.choice(im + '.jpg') for i in range(10)]\nimg_dir = image_dir + '\/jpeg\/train'\n\nfor i in range(9):\n    plt.subplot(3,3, i+1)\n    images = plt.imread(os.path.join(img_dir, img[i]))\n    plt.imshow(images)","31ceae71":"malignant = train_df[train_df['benign_malignant']=='malignant']\nbenign = train_df[train_df['benign_malignant']=='benign']\n\nprint(malignant)\nprint(benign)","37a8951e":"malignant.head(5)","eda9d6d1":"benign.head(5)","120dab0f":"im_malignant = malignant['image_name'].values\nimage_dir = '..\/input\/siim-isic-melanoma-classification\/'\n\nimg = [np.random.choice(im_malignant + '.jpg') for i in range(10)]\nimg_dir = image_dir + '\/jpeg\/train'\nplt.figure(figsize=(17,17))\n\nfor i in range(9):\n    plt.subplot(3,3, i+1)\n    images = plt.imread(os.path.join(img_dir, img[i]))\n    plt.imshow(images)\n    plt.axis('off')\nplt.tight_layout()\nprint(\"Random Malignant Images are Displayed!!\")","44d7806e":"im_benign = benign['image_name'].values\nimage_dir = '..\/input\/siim-isic-melanoma-classification\/'\n\nimg = [np.random.choice(im_benign + '.jpg') for i in range(10)]\nimg_dir = image_dir + '\/jpeg\/train'\nplt.figure(figsize=(17,17))\n\nfor i in range(9):\n    plt.subplot(3,3, i+1)\n    images = plt.imread(os.path.join(img_dir, img[i]))\n    plt.imshow(images)\n    plt.axis('off')\nplt.tight_layout()\nprint('Random Benign Images are displayed!!')","32ce57ae":"plt.imshow(pydicom.dcmread(image_path + list(train_df['image_name'])[1] + '.dcm').pixel_array)\nplt.savefig('x.jpg')","d6d0b2e6":"plt.figure(figsize=(17,17))\n\nfor i in range(9):\n    plt.subplot(3,3, i+1)\n    images = pydicom.dcmread(image_path + train_df[train_df['benign_malignant']=='benign']['image_name'][i] + '.dcm')\n    plt.imshow(images.pixel_array)\n    plt.axis('off')\nprint(\"--- Benign DICOM Images ---\")\nplt.tight_layout()","216ee6d5":"plt.figure(figsize = (10,10))\ndata = train_df.benign_malignant.value_counts()\ndata.iplot(kind = 'bar', color='blue', title = 'Data Imbalance')","fd216610":"plt.figure(figsize = (20,15))\nsns.boxplot(x = train_df['diagnosis'], y = train_df['age_approx'])","018bd54f":"img = im_benign[0] + '.jpg'\nf = plt.figure(figsize=(15,10))\nf.add_subplot(1,2,1)\n\nimages = plt.imread(os.path.join(img_dir, img))\nplt.imshow(images, cmap='gray')\nplt.axis('off')\nplt.colorbar()\nplt.title('Benign Images')\n\nf.add_subplot(1,2,2)\n_= plt.hist(images[:, :, 0].ravel(), bins = 256, color = 'red', alpha = 0.5)\n_ = plt.hist(images[:, :, 1].ravel(), bins = 256, color = 'Green', alpha = 0.5)\n_ = plt.hist(images[:, :, 2].ravel(), bins = 256, color = 'Blue', alpha = 0.5)\n_ = plt.xlabel('Intensity Value')\n_ = plt.ylabel('Count')\n_ = plt.legend(['Red_Channel', 'Green_Channel', 'Blue_Channel'])\nplt.show()","602b260a":"img = im_malignant[0] + '.jpg'\nf = plt.figure(figsize=(15,10))\nf.add_subplot(1,2,1)\n\nimages = plt.imread(os.path.join(img_dir, img))\nplt.imshow(images, cmap='gray')\nplt.axis('off')\nplt.colorbar()\nplt.title('Malignant Images')\n\nf.add_subplot(1,2,2)\n_= plt.hist(images[:, :, 0].ravel(), bins = 256, color = 'red', alpha = 0.5)\n_ = plt.hist(images[:, :, 1].ravel(), bins = 256, color = 'Green', alpha = 0.5)\n_ = plt.hist(images[:, :, 2].ravel(), bins = 256, color = 'Blue', alpha = 0.5)\n_ = plt.xlabel('Intensity Value')\n_ = plt.ylabel('Count')\n_ = plt.legend(['Red_Channel', 'Green_Channel', 'Blue_Channel'])\nplt.show()","2e70faf7":"from sklearn import model_selection","e9f7f8d0":"#using the train.csv data\ntrain_df['kfold'] = -1\ntrain_df = train_df.sample(frac=1).reset_index(drop=True)\ny = train_df.target.values\nkf = model_selection.StratifiedKFold(n_splits=10)\n\nfor f, (t_, v_) in enumerate(kf.split(X=train_df, y=y)):\n    train_df.loc[v_, 'kfold'] = f\n\ntrain_df.to_csv(\"train_folds.csv\", index=False)","bd2a518c":"def train(fold):\n    train_path = \"..\/input\/siic-isic-224x224-images\/train\/\"\n    df = pd.read_csv('\/kaggle\/working\/train_folds.csv')\n    train_batch = 32\n    valid_batch = 16\n    epochs = 30\n    \n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n\n    model = DenseNet121(pretrained=\"imagenet\", include_top=False)\n\n    train_aug = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)\n    \n    valid_aug = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)\n    \n\n    train_images = df_train.image_name.values.tolist()\n    train_images = [os.path.join(train_path, i + \".png\") for i in train_images]\n    train_targets = df_train.target.values\n\n    valid_images = df_valid.image_name.values.tolist()\n    valid_images = [os.path.join(training_path, i + \".png\") for i in valid_images]\n    valid_targets = df_valid.target.values\n\n    train_dataset = train_aug.flow_from_directory(\n        image_paths=train_images,\n        targets=train_targets,\n        resize=None\n    )\n    \n    \n\n    valid_dataset = valid_aug.flow_from_directory(\n        image_paths=valid_images,\n        targets=valid_targets,\n        resize=None\n     )\n\n    optimizer = tensorflow.keras.optimizers.Adam(model.parameters(), lr=1e-4)\n    scheduler = tensorflow.keras.callbacks.ReduceLROnPlateau(\n        monitor = 'val_loss',\n        patience=3,\n        min_lr = 0.001,\n        mode=\"max\"\n    )\n    es = EarlyStopping(patience=5, mode=\"max\")\n\n    for epoch in range(epochs):\n        train_loss = Engine.train(train_dataset, model, optimizer)\n        predictions, valid_loss = Engine.evaluate(\n             valid_dataset, model\n        )\n        predictions = np.vstack((predictions)).ravel()\n        auc = metrics.roc_auc_score(valid_targets, predictions)\n        print(f\"Epoch = {epoch}, AUC = {auc}\")\n        scheduler.step(auc)\n\n        es(auc, model, model_path=f\"model_fold_{fold}.bin\")\n        if es.early_stop:\n            print(\"Early stopping\")\n            break\n","dcbdb3e5":"import xgboost as xgb","2ae80dda":"train_df['sex'] = train_df['sex'].fillna('na')\ntrain_df['age_approx'] = train_df['age_approx'].fillna(0)\ntrain_df['anatom_site_general_challenge'] = train_df['anatom_site_general_challenge'].fillna('na')\n\ntest_df['sex'] = test_df['sex'].fillna('na')\ntest_df['age_approx'] = test_df['age_approx'].fillna(0)\ntest_df['anatom_site_general_challenge'] = test_df['anatom_site_general_challenge'].fillna('na')","e9ec66f7":"train_df['sex'] = train_df['sex'].astype(\"category\").cat.codes +1\ntrain_df['anatom_site_general_challenge'] = train_df['anatom_site_general_challenge'].astype(\"category\").cat.codes +1\ntrain_df.head()","761e2bb0":"test_df['sex'] = test_df['sex'].astype(\"category\").cat.codes +1\ntest_df['anatom_site_general_challenge'] = test_df['anatom_site_general_challenge'].astype(\"category\").cat.codes +1\ntest_df.head()","1402c299":"x_train = train_df[['sex', 'age_approx','anatom_site_general_challenge']]\ny_train = train_df['target']\n\n\nx_test = test_df[['sex', 'age_approx','anatom_site_general_challenge']]\n#y_test = test_df['target']\n\n\ntrain_DMatrix = xgb.DMatrix(x_train, label= y_train)\ntest_DMatrix = xgb.DMatrix(x_test)","c042ce6d":"model = xgb.XGBClassifier()\nmodel.fit(x_train, y_train)","3fef0908":"y_pred = model.predict(x_test)\ny_pred","bf2a60d9":"subs_df.target = model.predict_proba(x_test)[:,1]\nsub_tabular = subs_df.copy()","d5a5f22b":"subs_df.to_csv('submissions.csv', index = False)\nprint('Successfull!!')","07901ad3":"subs_df.head()","476db45b":"***Based on above value it is an binary classification type dataset***","4f21c37f":"# Display Benign and Malignant images","e0e7a69a":"# Histograms\nLet's visualize the image intensities using histogram ","ea64665d":"References\n\n1. https:\/\/www.kaggle.com\/redwankarimsony\/power-of-metadata-xgboost-cnn-ensemble\/comments","e8e31041":"**Benign Images**","6bcfac19":"# Dataset\nI have made this project as part of [SIIM-ISIC-Melanoma-Classification competition](https:\/\/www.kaggle.com\/c\/siim-isic-melanoma-classification)\n\n# Process Flow of Project so far\n1. Importing Libraries\n2. Exploring the Dataset\n3. Data Visualisation using libraries like [plotly](https:\/\/plotly.com\/python\/)\n4. DICOM Image Preprocessing, libraries used were pydicom and PIL\n5. Creating Folds \n6. XGBoost based predictions\n\n***for DICOM Preprocessing I refered two notebooks***\n1. https:\/\/www.kaggle.com\/nxrprime\/siim-d3-js-eda-augmentations-model-seresunet\n2. https:\/\/www.kaggle.com\/parulpandey\/melanoma-classification-eda-starter","696c83e6":"# Displaying Images","3be9639b":"# Data Imbalance","9cddb1b7":"# Neural Networks","5703dce2":"# Target and Age\n**Here I have used box-plot tool of seaborn library to visualize the distribution of age data in the target columns**","f2c724ff":"# Submissions","2e54cc61":"# Introduction\n\n# Melanoma Analysis Notebook\n\nHere is part of my notebook in GitHub repository do refer it and star it or fork it as per your convinience!!\nhttps:\/\/github.com\/digs1998\/Melanoma-Analysis","88c05307":"**Benign**","26f91937":"# XGBoost","a325cacd":"**Checking if Patient-ID were duplicated**","6fc9af9f":"# DICOM Images","9d6ad0e2":"**Malignant Images**","40de7613":"**Malignant**","7ba2e070":"# Visualizing Missing values","57d25f02":"**Benign Images**","8fa0c618":"# Basic Introduction on Melanoma Cancer","02a37fe4":"# Diagnosis and Age","a7035d05":"# Create Folds\nWe first create folds for Stratified Kfold model selection so that the ratio of positive to negative cases remain constant.\nYou can get more information from [here](https:\/\/www.youtube.com\/watch?v=WaCFd-vL4HA)","a5130081":"# Loading Datasets"}}