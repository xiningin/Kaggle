{"cell_type":{"6ce40633":"code","0653c219":"code","6a091f26":"code","eba49fd6":"code","4cbf8536":"code","ffc7f828":"code","570727e3":"code","aa6a2de4":"code","c47e40a1":"code","4e1854eb":"code","eefbd53c":"code","840e4f29":"code","b07d7d99":"code","f4ef39d4":"code","a45b1113":"code","8279453c":"code","f285eade":"code","a67d166a":"code","075b6f75":"code","050506f4":"code","38832507":"code","3da134ec":"code","c36d4248":"code","b570ea76":"code","408daa1a":"code","021aa75b":"code","a07b9936":"code","ea60d1f7":"code","52eaf601":"markdown","99904331":"markdown","e8c4a90d":"markdown","f49e9e40":"markdown"},"source":{"6ce40633":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0653c219":"len(os.listdir('\/kaggle\/input\/fruits\/fruits-360\/Training'))","6a091f26":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","eba49fd6":"fruit1 = plt.imread('\/kaggle\/input\/fruits\/fruits-360\/Training\/Granadilla\/r_255_100.jpg')\n\nfruit2 = plt.imread('\/kaggle\/input\/fruits\/fruits-360\/Training\/Pear Monster\/r_305_100.jpg')","4cbf8536":"plt.imshow(fruit1)","ffc7f828":"plt.imshow(fruit2)","570727e3":"fruit1.shape","aa6a2de4":"train_path = '\/kaggle\/input\/fruits\/fruits-360\/Training\/'\ntest_path = '\/kaggle\/input\/fruits\/fruits-360\/Test\/'","c47e40a1":"IMAGE_SHAPE = (100,100,3)","4e1854eb":"from keras.models import Sequential\nfrom keras.layers import Dense,Activation,Flatten,Conv2D,MaxPool2D,Dropout\nfrom keras.preprocessing.image import ImageDataGenerator ","eefbd53c":"model = Sequential()\nmodel.add(Conv2D(input_shape=(100, 100, 3), filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(units=4096,activation='relu'))\nmodel.add(Dense(units=4096,activation='relu'))\nmodel.add(Dense(units=131,activation='softmax'))\nmodel.summary()\n","840e4f29":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'] )","b07d7d99":"train_data_generator = ImageDataGenerator(\n    rescale=1.0\/255,\n    shear_range=0.2,\n    rotation_range=10, # rotation\n    width_shift_range=0.2, # horizontal shift\n    height_shift_range=0.2, # vertical shift\n    zoom_range=0.2, # zoom\n    horizontal_flip=True, # horizontal flip\n    brightness_range=[0.2,1.2])\n\ntest_data_generator = ImageDataGenerator(rescale=1.0\/255)\n\n","f4ef39d4":"train_data = train_data_generator.flow_from_directory(train_path,\n                                                      target_size=[100,100],\n                                                      batch_size=64,\n                                                      class_mode='categorical')\n\ntest_data = train_data_generator.flow_from_directory(test_path,\n                                                    target_size=[100,100],\n                                                    batch_size=64,\n                                                    class_mode='categorical')","a45b1113":"history = model.fit_generator(train_data,\n                              validation_data=test_data,\n                              epochs=1,\n                              steps_per_epoch=len(train_data),\n                              validation_steps=len(test_data))","8279453c":"print(history.history.keys())","f285eade":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","a67d166a":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","075b6f75":"from keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\n\nfrom keras.applications import ResNet50\nfrom keras.applications import inception_v3\nfrom keras.models import Model","050506f4":"vgg16 = VGG16(include_top=False,\n    weights='imagenet',\n    input_shape=(100,100,3))\nvgg16.summary()","38832507":"for layer in vgg16.layers:\n    layer.trainable=False","3da134ec":"x = Flatten()(vgg16.output)\nx = Dense(512,activation='relu')(x)\nx = Dense(512,activation='relu')(x)\n\nprediction = Dense(131,activation='softmax')(x)\nmodel = Model(inputs=vgg16.input, outputs=prediction)\nmodel.summary()","c36d4248":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","b570ea76":"train_data_generator = ImageDataGenerator(\n    rescale=1.0\/255,\n    shear_range=0.2,\n    rotation_range=10, # rotation\n    width_shift_range=0.2, # horizontal shift\n    height_shift_range=0.2, # vertical shift\n    zoom_range=0.2, # zoom\n    horizontal_flip=True, # horizontal flip\n    brightness_range=[0.2,1.2])\n\ntest_data_generator = ImageDataGenerator(rescale=1.0\/255)","408daa1a":"train_data = train_data_generator.flow_from_directory(train_path,\n                                                      target_size=[100,100],\n                                                      batch_size=64,\n                                                      class_mode='categorical')\n\ntest_data = train_data_generator.flow_from_directory(test_path,\n                                                    target_size=[100,100],\n                                                    batch_size=64,\n                                                    class_mode='categorical')","021aa75b":"history = model.fit_generator(train_data,\n                             validation_data=test_data,\n                             epochs=20,\n                             steps_per_epoch=len(train_data),\n                             validation_steps=len(test_data))","a07b9936":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","ea60d1f7":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","52eaf601":"### Using VGG16","99904331":"### We have images of diffrent fruit with dimensons 100x100","e8c4a90d":"### We will use VGG16 to classify the fruits","f49e9e40":"### We have 131 diffrent types of fruit"}}