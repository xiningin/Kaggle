{"cell_type":{"65585071":"code","27d2395f":"code","c79c78ab":"code","66505133":"code","604e5402":"code","644ad912":"code","517c5c14":"code","84d75c47":"code","e87968f6":"code","8348d45e":"code","9fe648ff":"code","8e17cb12":"code","8857d64c":"code","ef6551e1":"code","8669e73b":"code","00ca418c":"code","c8048a95":"code","6734126b":"code","412f25a7":"code","e2f8a326":"code","b83e8569":"code","a030c45f":"code","7d688be6":"code","764ee2bf":"code","95565c63":"code","134d45e9":"code","f28d4581":"code","f07422cb":"code","b91f4521":"code","08e8427b":"code","9db1c40a":"code","c01fec29":"code","f92cb7d9":"code","bafcea18":"code","e9aab60e":"code","f65453d8":"code","7edbf4f6":"markdown","b800e3b9":"markdown","068a7d85":"markdown","c248e735":"markdown","21a77e04":"markdown","93cd968c":"markdown","a0baa592":"markdown","862b748b":"markdown","7a50fe00":"markdown","c16b6b99":"markdown","1a6ee2fd":"markdown","bdf9da4a":"markdown","7d592d9b":"markdown","50c13b50":"markdown","88d6e8ff":"markdown","6d0314f1":"markdown","4dba66b5":"markdown","4b0bae6d":"markdown","c15886e4":"markdown","bcd04967":"markdown","22e2ae48":"markdown","08cbcadb":"markdown","0c953b69":"markdown","e329862b":"markdown","47129350":"markdown","f8bf3de2":"markdown","60248fe5":"markdown","80c3f36d":"markdown","13df811e":"markdown","f606ba14":"markdown","722aad08":"markdown"},"source":{"65585071":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')","27d2395f":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nsns.set()\n%matplotlib inline","c79c78ab":"from sklearn.preprocessing import StandardScaler\nscaler= StandardScaler()","66505133":"import scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import AgglomerativeClustering","604e5402":"crime = pd.read_csv(\"..\/input\/usarrests\/USArrests.csv\")","644ad912":"#peeking at the dataset\n\ncrime.head(5)","517c5c14":"# Let's see how many rows and columns we got!\n\ncrime.shape","84d75c47":"#Let's see some facts here\n\ncrime.info()","e87968f6":"# Let's get some statistics summary\n\ncrime.describe()","8348d45e":"crime.isnull().sum()","9fe648ff":"# Renaming the column as Unnmaed doesn't make sense.\n\ncrime = crime.rename(columns={'Unnamed: 0':'State'})","8e17cb12":"crime.head()","8857d64c":"plt.figure(figsize=(20,5))\ncrime.groupby('State')['Murder'].max().plot(kind='bar')","ef6551e1":"plt.figure(figsize=(20,5))\ncrime.groupby('State')['Assault'].max().plot(kind='bar')","8669e73b":"plt.figure(figsize=(20,5))\ncrime.groupby('State')['Rape'].max().plot(kind='bar')","00ca418c":"plt.figure(figsize=(20,5))\ncrime.groupby('State')['UrbanPop'].max().plot(kind='bar')","c8048a95":"plt.figure(figsize=(10,5))\nplt.scatter('UrbanPop','Murder',data=crime)\nplt.xlabel('Urban Population')\nplt.ylabel('Murder Rate')","6734126b":"plt.figure(figsize=(10,5))\nplt.scatter('UrbanPop','Rape',data=crime)\nplt.xlabel('Urban Population')\nplt.ylabel('Rape Rate')","412f25a7":"plt.figure(figsize=(10,5))\nplt.scatter('UrbanPop','Assault',data=crime)\nplt.xlabel('Urban Population')\nplt.ylabel('Assault Rate')","e2f8a326":"data = crime.iloc[:,1:].values","b83e8569":"scaled_data = scaler.fit_transform(data)","a030c45f":"plt.figure(figsize=(20,5))\nplt.title(\"Crime Rate Dendograms\")\ndend = sch.dendrogram(sch.linkage(scaled_data, method='single'))\nplt.xlabel('Crime Rate')\nplt.ylabel('Euclidean distances')","7d688be6":"plt.figure(figsize=(20,5))\nplt.title(\"Crime Rate Dendograms\")\ndend = sch.dendrogram(sch.linkage(scaled_data, method='complete'))\nplt.xlabel('Crime Rate')\nplt.ylabel('Euclidean distances')","764ee2bf":"plt.figure(figsize=(20,5))\nplt.title(\"Crime Rate Dendograms\")\ndend = sch.dendrogram(sch.linkage(scaled_data, method='average'))\nplt.xlabel('Crime Rate')\nplt.ylabel('Euclidean distances')","95565c63":"# With Ward method\nplt.figure(figsize=(20,8))\ndendrogram = sch.dendrogram(sch.linkage(data, method  = \"ward\"))\nplt.title('Dendrogram')\nplt.xlabel('Crime Rate')\nplt.ylabel('Euclidean distances')\nplt.show()","134d45e9":"# Fit the Agglomerative Clustering\n \nAC = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage ='ward')","f28d4581":"# Fit and predict to have the cluster labels.\ny_pred =AC.fit_predict(data)\ny_pred","f07422cb":"# Fetch the cluster labels\ncrime['cluster labels']= y_pred","b91f4521":"# Let's see which State falls in which cluster\ncrime[['State','cluster labels']]","08e8427b":"plt.figure(figsize=(10,5))\nsns.boxplot(x='cluster labels', y='Murder', data=crime)","9db1c40a":"plt.figure(figsize=(10,5))\nsns.boxplot(x='cluster labels', y='Rape', data=crime)","c01fec29":"plt.figure(figsize=(10,5))\nsns.boxplot(x='cluster labels', y='Assault', data=crime)","f92cb7d9":"Safe_Zone= crime.groupby('cluster labels')['State'].unique()[0]\nSafe_Zone","bafcea18":"Danger_Zone= crime.groupby('cluster labels')['State'].unique()[1]\nDanger_Zone","e9aab60e":"Moderate_Zone= crime.groupby('cluster labels')['State'].unique()[2]\nModerate_Zone","f65453d8":"plt.figure(figsize=(10,5))\nplt.scatter(data[y_pred==0, 0], data[y_pred==0, 1], s=100, c='red', label ='Safe_Zone')\nplt.scatter(data[y_pred==1, 0], data[y_pred==1, 1], s=100, c='blue', label ='Danger_Zone')\nplt.scatter(data[y_pred==2, 0], data[y_pred==2, 1], s=100, c='green', label ='Moderate_Zone')\nplt.legend()\nplt.show()","7edbf4f6":"## Content\nThis data set contains statistics, in arrests per 100,000 residents\nfor assault, murder, and rape in each of the 50 US states in 1973.\nAlso given is the percent of the population living in urban areas.This is a systematic approach for identifying and analyzing patterns and trends in crime using USArrest dataset. ","b800e3b9":"<h2 style='height:40px;text-align:center;font-size:30px;background-color:red;border:20px;color:white'>Violent Crime Rates By US State<h2>\n","068a7d85":"#### The hierarchy class has a dendrogram method which takes the value returned by the linkage method of the same class. The linkage method takes the dataset and the method to minimize distances as parameters.","c248e735":"## Observations:\n\n* Highest UrbanPop Rate : Nevada and Alaska.\n* Lowest UrbanPop Rate  : Maine, North Dakota,Vermont,Connecticut,New Hampshire, Wisconsin,Rhode Island and West Virginia","21a77e04":"## 4) UrbanPop : Percent Urban Population","93cd968c":"### We have 50 rows and 5 columns.","a0baa592":"**Ward** method is actually a method that tries to minimize the variance within each cluster. In K-means when we were trying to minimize the wcss to plot our elbow method chart, here it\u2019s almost the same the only difference is that instead of minimizing wcss we are minimizing the within-cluster variants. That is the variance within each cluster.","862b748b":"## **Observations**:\n\n* Highest Murder Rate : Georgia and Missisippi\n* Lowest Murder Rate : Idaho , Iowa, Maine, New Hampshire, North Dakota, Vermont and Wisconsin.","7a50fe00":"## How do we determine the optimal number of clusters from this diagram? \n\nWe look for the largest distance that we can vertically without crossing any horizontal line and this one is the red framed line on the above diagram. Let\u2019s count the number of lines on the diagram and determine the optimal number of clusters. Cluster number will be 3 for this dataset.","c16b6b99":"### Let's check for missing values.","1a6ee2fd":"### Our dataset consists of crime rates for Murder, Assault, UrbanPop and Rape","bdf9da4a":"![Cyber-Crime-Complaint.jpg.jpg](attachment:Cyber-Crime-Complaint.jpg.jpg)","7d592d9b":"## 3) Average Linkage: \n    \nThe distance between 2 clusters is defined as the average distance between every point of one cluster to every other point of the other cluster.","50c13b50":"## 2) Complete Linkage:\n\nThe distance between 2 clusters is defined as the maximum distance between any 2 points in the clusters","88d6e8ff":"## I hope the time you spent reading this Kernel helped you understand the Hierarchial Clustering!\n\nShare your views in comments :)","6d0314f1":"## Import the Desired Libraries:","4dba66b5":"## Types Of Hierarchical Clustering:\n\nThere are two types of hierarchical clustering: \n\n* **Agglomerative**: The data points are clustered using a bottom-up approach starting with individual data points.\n* **Divisive**: The top-down approach is followed where all the data points are treated as one big cluster and the clustering process involves dividing the one big cluster into several small clusters.","4b0bae6d":"### We have no missing values!","c15886e4":"## What is Hierarchical Clustering?\n\nHierarchical clustering is a type of unsupervised machine learning algorithm used to cluster unlabeled data points. Like K-means clustering, hierarchical clustering also groups together the data points with similar characteristics.One of the major considerations in using the K-means algorithm is deciding the value of K beforehand. The hierarchical clustering algorithm does not have this restriction.The output of the hierarchical clustering algorithm is quite different from the K-mean algorithm as well. It results in an inverted tree-shaped structure, called the **dendrogram**.","bcd04967":"## 1) Murder Rate","22e2ae48":"## Types of Linkages:","08cbcadb":"## 3) Rape Rate","0c953b69":"## Reading and Understanding the Data","e329862b":"## **Observations**:\n\n* Highest Assualt Rate : Florida and North California.\n* Lowest Assualt Rate : Hawaii, North Dakota, Vermont , New Hampshire and Wisconsin.","47129350":"## **Observations**:\n\n* The Cities in the Cluster-0 seems to be Safe-Zone where there are relativley less Murders,Assaults and Rapes.\n* The Cities in Cluster-1 seems to have higher crime rates and can be regarded as Danger-Zone.\n* The Cities in Cluster-3 seems to have moderate crime rates when compared to other zones and can be called as Moderate-Zone\n","f8bf3de2":"![Hierarchical-Clustering-Analysis.png](attachment:Hierarchical-Clustering-Analysis.png)","60248fe5":"#### The single linkage type will produce dendrograms which are not structured properly, whereas complete or average linkage will produce clusters which have a proper tree-like structure.","80c3f36d":"## Steps to Perform Hierarchical Clustering:\n\nFollowing are the steps involved in **agglomerative clustering**:\n\n* At the start, treat each data point as one cluster. Therefore, the number of clusters at the start will be K, while K is an integer representing the number of data points.\n* Form a cluster by joining the two closest data points resulting in K-1 clusters.\n* Form more clusters by joining the two closest clusters resulting in K-2 clusters.\n* Repeat the above three steps until one big cluster is formed.\n* Once single cluster is formed, dendrograms are used to divide into multiple clusters depending upon the problem. We will study the concept of dendrogram in detail in an upcoming section.","13df811e":"## 2) Assault Rate","f606ba14":"## 1) Single Leakage:\n\nThe distance between 2 clusters is defined as the shortest distance between points in the two clusters","722aad08":"![thank-you-page-examples.jpg](attachment:thank-you-page-examples.jpg)"}}