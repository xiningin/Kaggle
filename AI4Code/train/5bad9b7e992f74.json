{"cell_type":{"4ca52868":"code","1069a173":"code","16b4b9a7":"code","b11378ce":"code","c4a5befc":"code","c80f64c8":"code","13971f9a":"code","ea4941dd":"code","f0a84fc5":"code","febf8441":"code","e8d73e53":"code","42dc0d6f":"code","edc65b2f":"code","846009ec":"code","f914bb01":"code","c89f0d8c":"code","190169aa":"code","e1ad9319":"code","1d106800":"code","c7df41de":"code","76af68e1":"code","a5a2ff1a":"code","f788b411":"code","29fd8544":"code","0bc962b3":"code","ac9b7f5f":"code","8afce7ba":"code","1cabb0ff":"code","f180d8a5":"code","17356a55":"code","2fd459a4":"code","e6446177":"code","29f729ca":"code","68ec7ac7":"code","6e20a8af":"code","2f48868b":"markdown","37a08aa1":"markdown","ba14a77f":"markdown","2bbb8ca2":"markdown","02ec9ff9":"markdown","9607cb92":"markdown","db06bd49":"markdown","945169c1":"markdown","5323aa35":"markdown","0a2c7228":"markdown","d5dca85b":"markdown","d53e78de":"markdown","20ecfc73":"markdown","966d55f0":"markdown","4d7dd4b6":"markdown","d5859130":"markdown","1a0eafab":"markdown","48aeb999":"markdown","47cbb28f":"markdown","9b60477d":"markdown","d8d19282":"markdown","fe17d580":"markdown","1f6f0458":"markdown","f35d5c47":"markdown","b906c983":"markdown","a9594490":"markdown","eb9281d1":"markdown","1f0e73e3":"markdown","7d81bd2e":"markdown","f43fcb5e":"markdown","ff4eb042":"markdown","a84086bb":"markdown","08d9426c":"markdown","f982f6a9":"markdown","5864367c":"markdown","483cc850":"markdown","e67c5a5d":"markdown","0aa6caf7":"markdown","b6d2544f":"markdown","4ea0cf3c":"markdown","00a3a7e7":"markdown","f0b2bd6e":"markdown","967aabf9":"markdown","d9b28512":"markdown","bb235c36":"markdown","6b91bf6b":"markdown","c5083ab2":"markdown","33113b9d":"markdown","c030b51d":"markdown","b7c03103":"markdown","d479c07b":"markdown"},"source":{"4ca52868":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1069a173":"!pip install --upgrade --quiet pip\n!pip install -U --quiet tensorflow_hub\n!pip install -U --quiet tensorflow_datasets\nprint('Done!')","16b4b9a7":"import time\nimport numpy as np\nimport matplotlib.pylab as plt\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\ntfds.disable_progress_bar()\n\nfrom tensorflow.keras import layers\nprint('Done!')","b11378ce":"try: # detect TPUs\n    tpu = None\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept Exception as e: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","c4a5befc":"(train_examples, val_examples), info = tfds.load(\n    'cats_vs_dogs',\n    split=['train[:80%]', 'train[80%:]'],\n    as_supervised=True,\n    with_info=True\n)\nprint('Done!')","c80f64c8":"print(f'type info is:',type(info))\ninfo","13971f9a":"def format_image(image, label):\n  # `hub` image modules exepct their data normalized to the [0,1] range.\n    image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))\/255.0\n    return  image, label\n\nnum_examples = info.splits['train'].num_examples\n\nif strategy.num_replicas_in_sync == 8:\n    print('Using TPU')\n    BATCH_SIZE = 16 * strategy.num_replicas_in_sync\nelse:\n    print('Using GPU or None')\n    BATCH_SIZE = 32\n\nIMAGE_RES = 224\n\ntrain_batches = train_examples.cache().shuffle(num_examples\/\/4).map(format_image).batch(BATCH_SIZE).prefetch(1)\nvalidation_batches = val_examples.cache().map(format_image).batch(BATCH_SIZE).prefetch(1)\nprint('Done!')","ea4941dd":"URL = \"https:\/\/tfhub.dev\/google\/tf2-preview\/mobilenet_v2\/feature_vector\/4\"\nfeature_extractor = hub.KerasLayer(URL,\n                                   input_shape=(IMAGE_RES, IMAGE_RES,3))\nprint('Done!')","f0a84fc5":"feature_extractor.trainable = False","febf8441":"model = tf.keras.Sequential([\n    feature_extractor,\n    layers.Dense(2, activation='sigmoid')\n])\n\nmodel.summary()","e8d73e53":"model.compile(\n  optimizer='adam', \n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])\n\nEPOCHS = 3\nhistory = model.fit(train_batches,\n                    epochs=EPOCHS,\n                    validation_data=validation_batches)","42dc0d6f":"class_names = np.array(info.features['label'].names)\nclass_names","edc65b2f":"image_batch, label_batch = next(iter(train_batches.take(1)))\nimage_batch = image_batch.numpy()\nlabel_batch = label_batch.numpy()\n\n# Make some predictions\npredicted_batch = model.predict(image_batch)\n\n# Make it a flat array\npredicted_batch = tf.squeeze(predicted_batch).numpy()\n\n# Get the IDs of the highest prediction class\npredicted_ids = np.argmax(predicted_batch, axis=-1)\n\n# Get thir corresponding class names\npredicted_class_names = class_names[predicted_ids]\npredicted_class_names","846009ec":"print(\"Labels: \", label_batch)\nprint(\"Predicted labels: \", predicted_ids)","f914bb01":"# Let's plot them\n\nplt.figure(figsize=(10,9))\nfor n in range(30):\n    plt.subplot(6,5,n+1)\n    plt.imshow(image_batch[n])\n    color = \"blue\" if predicted_ids[n] == label_batch[n] else \"red\"\n    plt.title(predicted_class_names[n].title(), color=color)\n    plt.axis('off')\n    _ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")","c89f0d8c":"t = time.time()\n\nexport_path_keras = \".\/mobileNet\/{}.h5\".format(int(t))\nprint(export_path_keras)\n\nmodel.save(export_path_keras)","190169aa":"os.listdir()","e1ad9319":"os.listdir('mobileNet')","1d106800":"reloaded = tf.keras.models.load_model(\n  export_path_keras,\n    \n  # `custom_objects` tells keras how to load a `hub.KerasLayer`\n  custom_objects={'KerasLayer': hub.KerasLayer})\n\nreloaded.summary()","c7df41de":"result_batch = model.predict(image_batch)\nreloaded_result_batch = reloaded.predict(image_batch)","76af68e1":"(abs(result_batch - reloaded_result_batch)).max()","a5a2ff1a":"EPOCHS = 3\nhistory = reloaded.fit(train_batches,\n                    epochs=EPOCHS,\n                    validation_data=validation_batches)","f788b411":"t = time.time()\n\nexport_path_reloaded = \".\/mobileNet_reloaded\/{}.h5\".format(int(t))\nprint(export_path_reloaded)\n\nreloaded.save(export_path_reloaded)","29fd8544":"t = time.time()\n\nexport_path_sm = \".\/saved_model\/{}\".format(int(t))\nprint(export_path_sm)\n\ntf.saved_model.save(reloaded, export_path_sm)","0bc962b3":"os.listdir(export_path_sm)","ac9b7f5f":"os.listdir(export_path_sm+'\/variables')","8afce7ba":"reloaded_sm = tf.saved_model.load(export_path_sm)\nprint(f'type reloaded-savem-model is: {type(reloaded_sm)}')","1cabb0ff":"reloaded_result_batch = reloaded.predict(image_batch)\nreload_sm_result_batch = reloaded_sm(image_batch, training=False).numpy()","f180d8a5":"(abs(reloaded_result_batch - reload_sm_result_batch)).max()","17356a55":"try:\n    reloaded_sm.summary()\nexcept Exception as e:\n    print(e)","2fd459a4":"reload_sm_keras = tf.keras.models.load_model(\n  export_path_sm,\n  custom_objects={'KerasLayer': hub.KerasLayer})\n\nreload_sm_keras.summary()","e6446177":"# first making the same prediction with the reloaded savedModel\nreload_sm_result_batch = reloaded_sm(image_batch, training=False).numpy()\n\n# Then with the reloaded savedModel transformed to a keras model\nreload_sm_keras_result_batch = reload_sm_keras.predict(image_batch)","29f729ca":"abs(reload_sm_result_batch - reload_sm_keras_result_batch).max()","68ec7ac7":"!zip -r model.zip {export_path_sm}","6e20a8af":"!ls","2f48868b":"**To see what's in the variables folder, we can do...**","37a08aa1":"# Part 2: Transfer Learning with TensorFlow Hub\n\nWe will now use TensorFlow Hub to do Transfer Learning.","ba14a77f":"**Run an image batch through the model and convert the indices to class names.**","2bbb8ca2":"## Concepts that will be covered in this Notebook\n\n1. Saving models in HDF5 format for Keras\n2. Saving models in the TensorFlow SavedModel format\n3. Loading models\n4. Download models to Local Disk\n","02ec9ff9":"**The difference in output should be zero:**","9607cb92":"**From here you can download it to your local file and use as you wish...**","db06bd49":"## WARNING:\n\nThe code cell below fails to run on TPU and also fails in Colab. It's an issue from Google.\n<br>So Better use GPU for this notebook","945169c1":"**We can check that the reloaded model and the previous model give the same result**","5323aa35":"# Part 7: Loading the SavedModel as a Keras Model\n\nThe object returned by `tf.saved_model.load` is not a Keras object (i.e. doesn't have `.fit`, `.predict`, `.summary`, etc. methods). Therefore, you can't simply take your `reloaded_sm` model and keep training it by running `.fit`. To be able to get back a full keras model from the Tensorflow SavedModel format we must use the `tf.keras.models.load_model` function. This function will work the same as before, except now we pass the path to the folder containing our SavedModel.","0a2c7228":"**Let's look at the true labels and predicted ones.**","d5dca85b":"**First we re-save it as a keras .h5 model...**","d53e78de":"**Once again, let's use the `reloaded_sm_keras` (reloaded Keras model from our SavedModel) to make predictions on a batch of images.**","20ecfc73":"# Part 6: Load SavedModel","966d55f0":"**We can check that the reloaded Keras model and the previous model give the same result.**","4d7dd4b6":"# TensorFlow Hub","d5859130":"## WARNING:\n\n### The code cell to download feature vectors from TF-Hub fails to run on TPU and also fails in Colab. It's an issue from Google.<br>So Better use GPU for this entire notebook","1a0eafab":"## Attach a classification head\n\nNow wrap the hub layer in a `tf.keras.Sequential` model, and add a new classification layer.","48aeb999":"# Part 8:  Download your model","47cbb28f":"**The images in the Dogs vs. Cats dataset are not all the same size. So, we need to reformat all images to the resolution expected by MobileNet (224, 224)**","9b60477d":"**We can check that the reloaded SavedModel and the previous reloaded model give the same result.**","d8d19282":"#### Proven to be the same exact model once again!","fe17d580":"For example try running reloaded_sm.summary() below will return an error","1f6f0458":"### Now, let's use the `reloaded_sm` (reloaded SavedModel) to make predictions on a batch of images.","f35d5c47":"**As we can see, the result is 0.0, which indicates that both models are indeed the same model.**","b906c983":"# Part 3: Save as Keras **`.h5`** model\n\nNow that we've trained the model,  we can save it as an HDF5 file, which is the format used by Keras. Our HDF5 file will have the extension '.h5', and it's name will correpond to the current time stamp.","a9594490":"* We've seen how to download models from TensorFlow-Hub and use these models for Transfer-learning.\n\n* Models so downloaded are called feature-vectors since they typically do not contain their original classifier head, but come with only hidden-layers so we can affix our own classifier head and recompile and train these models.\n\n* We've alse seen how to save these models as keras mdels in .h5 files\n\n* And how to reload these and even use them for further training\n\n* We also saw how to export these keras models to TensorFlow savedModels format, which are distib=nct from any underlying building codes and accessible by other frameworks outside python.\n\n* We also saw how to load these TensorFlow savedModel types and how to use them for training too.\n\n* feel free to explore other amazing pre-trained models from Tensorflow hub for your ML and DL tasks.","eb9281d1":"We will use TensorFlow Datasets to load the  Cats vs Dogs dataset.","1f0e73e3":"[TensorFlow Hub](http:\/\/tensorflow.org\/hub) is an online repository of already trained TensorFlow models that you can use.\nThese models can either be used as is, or they can be used for Transfer Learning.\n\nTransfer learning is a process where you take an existing trained model, and extend it to do additional work. This involves leaving the bulk of the model unchanged, while adding and retraining the final layers, in order to get a different set of possible outputs.\n\nHere, you can see all the models available in [TensorFlow Module Hub](https:\/\/tfhub.dev\/).\n","7d81bd2e":"You can also export a whole model to the TensorFlow SavedModel format. SavedModel is a standalone serialization format for Tensorflow objects, supported by TensorFlow serving as well as TensorFlow implementations other than Python. A SavedModel contains a complete TensorFlow program, including weights and computation. It does not require the original model building code to run, which makes it useful for sharing or deploying (with TFLite, TensorFlow.js, TensorFlow Serving, or TFHub).\n\nThe SavedModel files that we'd create contain:\n\n* **A TensorFlow checkpoint containing the model weights.**\n* **A SavedModel proto containing the underlying Tensorflow graph. Separate graphs are saved for prediction (serving), train, and evaluation. If the model wasn't compiled before, then only the inference graph gets exported.**\n* **The model's architecture config, if available.**\n\n\nLet's save our improved `reloaded_model` (which has now topped 99% accuracy) as a TensorFlow SavedModel. To do this we will use the `tf.saved_model.save()` function. This functions takes in the model we want to save and the path to the folder where we want to save our model. \n\nThis function will create a folder where you will find an `assets` folder, a `variables` folder, and the `saved_model.pb` file. ","f43fcb5e":"**Freeze the variables in the feature extractor layer, so that the training only modifies the final classifier layer.**","ff4eb042":"# Part 5: Export as SavedModel\n","a84086bb":"Let's see the type and details of the info document","08d9426c":"**Next, we export it as a savedModel object**","f982f6a9":"If you get a pip dependency error running the cell below, just re-run it!","5864367c":"### Check for TPU","483cc850":"# Saving and Loading Models\n\nIn this tutorial we will learn how we can take a trained model, save it, and then load it back to keep training it or use it to perform inference. In particular, we will use transfer learning to train a classifier to classify images of cats and dogs. We will then take our trained model and save it as an HDF5 file, which is the format used by Keras. We will then load this model, use it to perform predictions, and then continue to train the model. Finally, we will save our trained model as a TensorFlow SavedModel and then we will download it to a local disk, so that it can later be used for deployment in different platforms.","e67c5a5d":"# Part 1: Load the Cats vs. Dogs Dataset","0aa6caf7":"# Part 9: Conclusion","b6d2544f":"**Now, let's load our SavedModel and use it to make predictions. We use the `tf.saved_model.load()` function to load our SavedModels. The object returned by `tf.saved_model.load` is 100% independent of the code that created it.**","4ea0cf3c":"# Part 4:  Load the Keras `.h5` Model\n\nWe will now load the model we just saved into a new model called `reloaded`. We will need to provide the file path and the `custom_objects` parameter. This parameter tells keras how to load the `hub.KerasLayer` from the `feature_extractor` we used for transfer learning.","00a3a7e7":"# Keep Training\n\n**Besides making predictions, we can also take our `reloaded` model and keep training it. To do this, you can just train the `reloaded` as usual, using the `.fit` method.**","f0b2bd6e":"**As we can see from the type above, the reloaded-saved-model is not a keras application**","967aabf9":"#### Let's reload the saved-model instance as a keras model","d9b28512":"**You can later recreate the same model from this file, even if you no longer have access to the code that created the model.**\n\n**This file includes:**\n\n- The model's architecture\n- The model's weight values (which were learned during training)\n- The model's training config (what you passed to `compile`), if any\n- The optimizer and its state, if any (this enables you to restart training where you left off)","bb235c36":"## Check the predictions\n\nGet the ordered list of class names.","6b91bf6b":"You can download the SavedModel to your local disk by creating a zip file. We wil use the `-r` (recursice) option to zip all subfolders. ","c5083ab2":"**The zip file is saved in the current working directory. You can see what the current working directory is by running:**","33113b9d":"**At around 99% training and validation accuracy, our transfer-learning trained model of the MobileNetv2 class is doing remarkably well**","c030b51d":"## Train the model\n\nWe now train this model like any other, by first calling `compile` followed by `fit`.","b7c03103":"### Imports","d479c07b":"### As we can see, the result is 0.0, which indicates that both models made the same predictions on the same batch of images.\n\n"}}