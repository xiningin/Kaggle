{"cell_type":{"8f667b68":"code","6b79423f":"code","2e9f8832":"code","6194b7bb":"code","72348dff":"code","2462d3cb":"code","b1d7f472":"code","972d3056":"code","c415b8ab":"code","6f63ad0c":"code","43753c5a":"code","1e83dca7":"code","41bc3152":"code","3e4506fe":"code","f2959e88":"code","4a66b1b3":"code","7bcfe421":"code","3ded370a":"code","981ca696":"code","9687a1e5":"code","86cdf4ab":"code","316e0f3f":"code","c68ac79f":"code","81d45cb0":"code","7d997522":"code","516f8bff":"code","f73a6373":"code","3a911f3c":"code","d9f1518a":"code","1ef80de5":"code","7641cca9":"code","c92cafe2":"code","29327651":"code","6004fd45":"code","4fc5d916":"code","4fdd1798":"code","ba9fc1a9":"code","f9c182ab":"code","6f00b498":"code","0aff2f9d":"code","7ddad922":"code","2a234ed5":"code","2a5a14f7":"code","d64fba6a":"code","4e3e213f":"code","1604cc14":"code","8fd77067":"code","f7425e15":"code","02c3dc92":"code","cc4407a4":"code","329259bf":"code","4b1c7cc7":"code","b28b4c7b":"code","3b0a20c2":"code","6833ce47":"code","b2203773":"code","b3b73f9a":"code","960737fc":"markdown","2366649e":"markdown","838a0290":"markdown","a5d2b530":"markdown","fc5d5614":"markdown","0a2f2cfb":"markdown","2c123cb2":"markdown","2d6d3705":"markdown","c83db342":"markdown","732e9a6c":"markdown","16774532":"markdown","f159fdba":"markdown","a627e853":"markdown","4e72453d":"markdown","8984b3d6":"markdown","58adb306":"markdown","d1433ece":"markdown","b3884911":"markdown","252d4f7c":"markdown","b94178a3":"markdown","583a3b65":"markdown","bd551e65":"markdown","8b0307a0":"markdown","fab9c2b8":"markdown","5930521f":"markdown","06cac1d0":"markdown","3300551c":"markdown","4aaa81ea":"markdown","1d5a6b16":"markdown","c2e4bdc1":"markdown","e1c75160":"markdown","102ea490":"markdown","f1029cda":"markdown","4d62cc53":"markdown","de63772a":"markdown","fd3b6740":"markdown","da1153d6":"markdown","855524dc":"markdown","12d3cb2b":"markdown","ebdc8289":"markdown","0221ba51":"markdown","b96e0515":"markdown","ed79f28a":"markdown","3b8798da":"markdown","8d63ea9c":"markdown","93d934e9":"markdown","4b27fd82":"markdown","69981226":"markdown","22154559":"markdown","10f7c2cd":"markdown","3d7fd92f":"markdown","5bc41d1d":"markdown"},"source":{"8f667b68":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6b79423f":"# Import the basic libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\n\n# Import the data processing and model evaluation libraries \nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, cross_val_predict\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, precision_recall_curve\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\n\n# Import the models\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","2e9f8832":"df = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","6194b7bb":"df.head()","72348dff":"df.info()","2462d3cb":"# Summary of numerical features\n\ndf.describe()","b1d7f472":"# Histograms for all numerical features \n\ndf.hist(figsize = (20,15), color='pink')","972d3056":"# Shuffle the entire data\n\ndf = shuffle(df)\n\n# Split the test set out of the data\n\ndf_train_01, df_test = train_test_split(df, test_size=0.2, random_state=42)\n\n# Create a train and validation set\n\ndf_train, df_validation = train_test_split(df_train_01, test_size=0.2, random_state=42)","c415b8ab":"# The features with the highest correlation values will be used as input features for creating a model.\n\ndf_train.corr()","6f63ad0c":"mask = np.triu(np.ones_like(df_train.corr(), dtype=np.bool))\n\nf, ax = plt.subplots(figsize=(15, 10))\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(df_train.corr(), cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","43753c5a":"# Distribution of Anaemia vs Heart failure \n\nfig, ax = plt.subplots()\nsns.distplot(df[df['DEATH_EVENT']==0]['anaemia'], hist=False, label = 'No heart failure')\nsns.distplot(df[df['DEATH_EVENT']==1]['anaemia'], hist=False, label = 'Heart failure')","1e83dca7":"# Proportion of Anaemic vs. Non-anaemic people who undergo heart failure \n\ndf_ad = df_train.groupby('anaemia')['DEATH_EVENT'].value_counts().to_frame()\n\nprint('Proportion of Non-anaemic people who have Heart failure:', ((df_ad.loc[(0, 1), :]\/((df_ad.loc[(0, 0), :]) + (df_ad.loc[(0, 1), :])))*100).values) # proportion of non anaemic people who have heart failure\nprint('Proportion of Anaemic people who have Heart failure:', ((df_ad.loc[(1, 1), :]\/((df_ad.loc[(1, 0), :]) + (df_ad.loc[(1, 1), :])))*100).values) # proportion of anaemic people who have heart failure ","41bc3152":"# Anaemia, Heart failure and other categorical risk factors\n\nfig, ax = plt.subplots(1,4, figsize=(20,5))\nx=0\n\n# Ordinal variables such as high blood pressure, diabetes and smoking are mapped on Y axis and hue is kept as anaemia for better interpretation \nfor variable in ['high_blood_pressure', 'diabetes', 'smoking']:\n    sns.barplot(x='DEATH_EVENT', y=variable, hue='anaemia' , data=df_train, ax=ax[x])\n    x+=1\n\n# Sex is a nominal variable. Hence, anaemia is mapped on y axis and hue is kept as sex for better interpretation\nsns.barplot(x='DEATH_EVENT', y='anaemia', hue='sex' , data=df_train, ax=ax[3])","3e4506fe":"# Correlation values \n\nfor variable in ['high_blood_pressure', 'diabetes', 'smoking']:\n    for x in [0,1]:\n        print('For patients with anaemia = ', x, 'correlation of', variable, 'with heart failure is', \n              ((df_train[df_train['anaemia']==x]).corr()[variable]['DEATH_EVENT']))\n        \nfor x in [0,1]:\n    print('For patients with sex = ', x, 'correlation of anaemia with heart failure is', ((df_train[df_train['sex']==x]).corr()['anaemia']['DEATH_EVENT']))\n        ","f2959e88":"# Correlation values\n\nfig, ax = plt.subplots(1,3, figsize=(20,8))\nx=0\n\nfor variable in ['creatinine_phosphokinase', 'platelets', 'serum_sodium']:\n    sns.boxplot(y=variable, x='DEATH_EVENT', hue='anaemia', showfliers=False, data=df_train, ax=ax[x])\n    x+=1","4a66b1b3":"# Correlation values \n\nfor variable in ['creatinine_phosphokinase', 'platelets', 'serum_sodium']:\n    for x in [0,1]:\n        print('For patients with anaemia =', x, 'correlation of heart failure and', variable, 'is',\n              ((df_train[df_train['anaemia']==x]).corr()[variable]['DEATH_EVENT']))","7bcfe421":"# Distribution of High blood pressure vs Heart failure \n\nfig, ax = plt.subplots()\nsns.distplot(df[df['DEATH_EVENT']==0]['high_blood_pressure'], hist=False, label = 'No heart failure')\nsns.distplot(df[df['DEATH_EVENT']==1]['high_blood_pressure'], hist=False, label = 'Heart failure')","3ded370a":"# Correlation values\n\ndf_ad = df_train.groupby('high_blood_pressure')['DEATH_EVENT'].value_counts().to_frame()\n\nprint('Proportion of people without high BP people who have Heart failure:', ((df_ad.loc[(0, 1), :]\/((df_ad.loc[(0, 0), :]) + (df_ad.loc[(0, 1), :])))*100).values) \nprint('Proportion of people with high BP who have Heart failure:', ((df_ad.loc[(1, 1), :]\/((df_ad.loc[(1, 0), :]) + (df_ad.loc[(1, 1), :])))*100).values) ","981ca696":"# High BP, Heart failure and other categorical risk factors\n\nfig, ax = plt.subplots(1,4, figsize=(20,5))\nx=0\n\n# Ordinal variables such as anaemia, diabetes and smoking are mapped on Y axis and hue is kept as high BP for better interpretation \nfor variable in ['anaemia', 'diabetes', 'smoking']:\n    sns.barplot(x='DEATH_EVENT', y=variable, hue='high_blood_pressure' , data=df_train, ax=ax[x])\n    x+=1\n\n# Sex is a nominal variable. Hence, high BP is mapped on y axis and hue is kept as sex for better interpretation\nsns.barplot(x='DEATH_EVENT', y='high_blood_pressure', hue='sex' , data=df_train, ax=ax[3])","9687a1e5":"# Correlation values \n\nfor variable in ['anaemia', 'diabetes', 'smoking']:\n    for x in [0,1]:\n        print('For patients with high_blood_pressure = ', x, 'correlation of', variable, 'with heart failure is', \n              ((df_train[df_train['high_blood_pressure']==x]).corr()[variable]['DEATH_EVENT']))\n        \nfor x in [0,1]:\n    print('For patients with sex = ', x, 'correlation of high_blood_pressure with heart failure is', ((df_train[df_train['sex']==x]).corr()['high_blood_pressure']['DEATH_EVENT']))\n        ","86cdf4ab":"# High BP, Heart failure and other numerical risk factors \n\nfig, ax = plt.subplots(1,3, figsize=(20,8))\nx=0\n\nfor variable in ['creatinine_phosphokinase', 'platelets', 'serum_sodium']:\n    sns.boxplot(y=variable, x='DEATH_EVENT', hue='high_blood_pressure', showfliers=False, data=df_train, ax=ax[x])\n    x+=1","316e0f3f":"# Correlation values\n\nfor variable in ['creatinine_phosphokinase', 'platelets', 'serum_sodium']:\n    for x in [0,1]:\n        print('For patients with high_blood_pressure =', x, 'correlation of heart failure and', variable, 'is',\n              ((df_train[df_train['high_blood_pressure']==x]).corr()[variable]['DEATH_EVENT']))","c68ac79f":"# Distribution of High blood pressure vs Heart failure \n\nfig, ax = plt.subplots()\nsns.distplot(df[df['DEATH_EVENT']==0]['diabetes'], hist=False, label = 'No heart failure')\nsns.distplot(df[df['DEATH_EVENT']==1]['diabetes'], hist=False, label = 'Heart failure')","81d45cb0":"# Correlation values\n\ndf_ad = df_train.groupby('diabetes')['DEATH_EVENT'].value_counts().to_frame()\n\nprint('Proportion of people without diabetes people who have Heart failure:', ((df_ad.loc[(0, 1), :]\/((df_ad.loc[(0, 0), :]) + (df_ad.loc[(0, 1), :])))*100).values) \nprint('Proportion of people with diabetes who have Heart failure:', ((df_ad.loc[(1, 1), :]\/((df_ad.loc[(1, 0), :]) + (df_ad.loc[(1, 1), :])))*100).values) ","7d997522":"# Diabetes, Heart failure and other categorical risk factors\n\nfig, ax = plt.subplots(1,4, figsize=(20,5))\nx=0\n\n# Ordinal variables such as high blood pressure, anaemia and smoking are mapped on Y axis and hue is kept as diabetes for better interpretation \nfor variable in ['anaemia', 'high_blood_pressure', 'smoking']:\n    sns.barplot(x='DEATH_EVENT', y=variable, hue='diabetes' , data=df_train, ax=ax[x])\n    x+=1\n\n# Sex is a nominal variable. Hence, diabetes is mapped on y axis and hue is kept as sex for better interpretation\nsns.barplot(x='DEATH_EVENT', y='diabetes', hue='sex' , data=df_train, ax=ax[3])","516f8bff":"# Correlation values \n\nfor variable in ['anaemia', 'high_blood_pressure', 'smoking']:\n    for x in [0,1]:\n        print('For patients with diabetes = ', x, 'correlation of', variable, 'with heart failure is', \n              ((df_train[df_train['diabetes']==x]).corr()[variable]['DEATH_EVENT']))\n        \nfor x in [0,1]:\n    print('For patients with sex = ', x, 'correlation of diabetes with heart failure is', ((df_train[df_train['sex']==x]).corr()['diabetes']['DEATH_EVENT']))","f73a6373":"# Diabetes, Heart failure and other numerical risk factors \n\nfig, ax = plt.subplots(1,3, figsize=(20,8))\nx=0\n\nfor variable in ['creatinine_phosphokinase', 'platelets', 'serum_sodium']:\n    sns.boxplot(y=variable, x='DEATH_EVENT', hue='diabetes', showfliers=False, data=df_train, ax=ax[x])\n    x+=1","3a911f3c":"# Correlation values\n\nfor variable in ['creatinine_phosphokinase', 'platelets', 'serum_sodium']:\n    for x in [0,1]:\n        print('For patients with diabetes =', x, 'correlation of heart failure and', variable, 'is',\n              ((df_train[df_train['diabetes']==x]).corr()[variable]['DEATH_EVENT']))","d9f1518a":"# Distribution of Smoking vs Heart failure \n\nfig, ax = plt.subplots()\nsns.distplot(df[df['DEATH_EVENT']==0]['smoking'], hist=False, label = 'No heart failure')\nsns.distplot(df[df['DEATH_EVENT']==1]['smoking'], hist=False, label = 'Heart failure')","1ef80de5":"# Correlation values\n\ndf_ad = df_train.groupby('smoking')['DEATH_EVENT'].value_counts().to_frame()\n\nprint('Proportion of non-smokers who have Heart failure:', ((df_ad.loc[(0, 1), :]\/((df_ad.loc[(0, 0), :]) + (df_ad.loc[(0, 1), :])))*100).values) \nprint('Proportion of smokers who have Heart failure:', ((df_ad.loc[(1, 1), :]\/((df_ad.loc[(1, 0), :]) + (df_ad.loc[(1, 1), :])))*100).values) ","7641cca9":"# Smoking, Heart failure and other categorical risk factors\n\nfig, ax = plt.subplots(1,4, figsize=(20,5))\nx=0\n\n# Ordinal variables such as high blood pressure, anaemia and diabetes are mapped on Y axis and hue is kept as smoking for better interpretation \nfor variable in ['anaemia', 'high_blood_pressure', 'diabetes']:\n    sns.barplot(x='DEATH_EVENT', y=variable, hue='smoking' , data=df_train, ax=ax[x])\n    x+=1\n\n# Sex is a nominal variable. Hence, smoking is mapped on y axis and hue is kept as sex for better interpretation\nsns.barplot(x='DEATH_EVENT', y='smoking', hue='sex' , data=df_train, ax=ax[3])","c92cafe2":"# Correlation values \n\nfor variable in ['anaemia', 'high_blood_pressure', 'diabetes']:\n    for x in [0,1]:\n        print('For patients with smoking = ', x, 'correlation of', variable, 'with heart failure is', \n              ((df_train[df_train['smoking']==x]).corr()[variable]['DEATH_EVENT']))\n        \nfor x in [0,1]:\n    print('For patients with sex = ', x, 'correlation of smoking with heart failure is', ((df_train[df_train['sex']==x]).corr()['smoking']['DEATH_EVENT']))","29327651":"# Smoking, Heart failure and other numerical risk factors \n\nfig, ax = plt.subplots(1,3, figsize=(20,8))\nx=0\n\nfor variable in ['creatinine_phosphokinase', 'platelets', 'serum_sodium']:\n    sns.boxplot(y=variable, x='DEATH_EVENT', hue='smoking', showfliers=False, data=df_train, ax=ax[x])\n    x+=1","6004fd45":"# Correlation values\n\nfor variable in ['creatinine_phosphokinase', 'platelets', 'serum_sodium']:\n    for x in [0,1]:\n        print('For patients with smoking =', x, 'correlation of heart failure and', variable, 'is',\n              ((df_train[df_train['smoking']==x]).corr()[variable]['DEATH_EVENT']))","4fc5d916":"# Distribution of Sex vs Heart failure \n\nfig, ax = plt.subplots()\nsns.distplot(df[df['DEATH_EVENT']==0]['sex'], hist=False, label = 'No heart failure')\nsns.distplot(df[df['DEATH_EVENT']==1]['sex'], hist=False, label = 'Heart failure')","4fdd1798":"# Correlation values\n\ndf_ad = df_train.groupby('sex')['DEATH_EVENT'].value_counts().to_frame()\n\nprint('Proportion of females who have Heart failure:', ((df_ad.loc[(0, 1), :]\/((df_ad.loc[(0, 0), :]) + (df_ad.loc[(0, 1), :])))*100).values) \nprint('Proportion of males who have Heart failure:', ((df_ad.loc[(1, 1), :]\/((df_ad.loc[(1, 0), :]) + (df_ad.loc[(1, 1), :])))*100).values) ","ba9fc1a9":"# Relation between smoking, heart failure and other categorical risk factors has already been explored in the previous sections","f9c182ab":"# Sex, Heart failure and other numerical risk factors \n\nfig, ax = plt.subplots(1,3, figsize=(20,8))\nx=0\n\nfor variable in ['creatinine_phosphokinase', 'platelets', 'serum_sodium']:\n    sns.boxplot(y=variable, x='DEATH_EVENT', hue='sex', showfliers=False, data=df_train, ax=ax[x])\n    x+=1","6f00b498":"# Correlation values\n\nfor variable in ['creatinine_phosphokinase', 'platelets', 'serum_sodium']:\n    for x in [0,1]:\n        print('For patients with sex =', x, 'correlation of heart failure and', variable, 'is',\n              ((df_train[df_train['sex']==x]).corr()[variable]['DEATH_EVENT']))","0aff2f9d":"# Shuffling\n\ndf_train = shuffle(df_train)\ndf_validation = shuffle(df_validation)","7ddad922":"# Standard scaling of training data\nX_train = df_train.copy()[['time', 'ejection_fraction', 'serum_creatinine', 'age']]\n\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\n\ny_train = df_train['DEATH_EVENT']","2a234ed5":"# Standard scaling of validation data\nX_validation = df_validation.copy()[['time', 'ejection_fraction', 'serum_creatinine', 'age']]\n\nscaler = StandardScaler()\n\nX_validation = scaler.fit_transform(X_validation)\n\ny_validation = df_validation['DEATH_EVENT']","2a5a14f7":"### Model fitting and Evaluation","d64fba6a":"# SGDclassifier and performance analysis\n\nsgd_clf = SGDClassifier()\n\n# Fit the model on training data\nsgd_clf.fit(X_train, y_train)\n\n# Predict the values for validation data\ny_validation_pred = sgd_clf.predict(X_validation)\n\n# Confusion matrix for validation data predictions\nprint('Confusion matrix for validation data:' '\\n', confusion_matrix(y_validation, y_validation_pred))\n\n# Accuracy score for validation data predictions \nacc_score = accuracy_score(y_validation, y_validation_pred)\nprint('Accuracy score for validation data:', acc_score)\n      \n# Precision score for validation data predictions \npre_score = precision_score(y_validation, y_validation_pred)\nprint('Precision score for validation data:', pre_score)\n      \n# Recall score for validation data predictions \nrec_score = recall_score(y_validation, y_validation_pred)\nprint('Recall score for validation data:', rec_score)\n\naccu_scores = []\nrec_scores = []\naccu_scores.append(acc_score)\nrec_scores.append(rec_score)","4e3e213f":"# Logistic regression and performance analysis\n\nlogreg = LogisticRegression()\n\n# Fit the model on training data\nlogreg.fit(X_train, y_train)\n\n# Predict the values for validation data\ny_validation_pred = logreg.predict(X_validation)\n\n# Confusion matrix for validation data predictions\nprint('Confusion matrix for validation data:' '\\n', confusion_matrix(y_validation, y_validation_pred))\n\n# Accuracy score for validation data predictions \nacc_score = accuracy_score(y_validation, y_validation_pred)\nprint('Accuracy score for validation data:', acc_score)\n      \n# Precision score for validation data predictions \npre_score = precision_score(y_validation, y_validation_pred)\nprint('Precision score for validation data:', pre_score)\n      \n# Recall score for validation data predictions \nrec_score = recall_score(y_validation, y_validation_pred)\nprint('Recall score for validation data:', rec_score)\n\naccu_scores.append(acc_score)\nrec_scores.append(rec_score)","1604cc14":"# Selecting the right hyperparameter\n\naccuracyscores = []\nrecallscores = []\n\nfor c in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n    svc = SVC(C=c, random_state=0, kernel='rbf')\n    svc.fit(X_train, y_train)\n    y_validation_pred = svc.predict(X_validation)\n    accuracyscores.append(accuracy_score(y_validation, y_validation_pred))\n    recallscores.append(recall_score(y_validation, y_validation_pred))\n\nplt.plot([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], accuracyscores, label='accuracy')\nplt.plot([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], recallscores, label='recall')\nplt.legend()\n","8fd77067":"# SVC and performance analysis\n\nsvc = SVC(C=1.0, random_state=0, kernel='rbf')\n\n# Fit the model on training data\nsvc.fit(X_train, y_train)\n\n# Predict the values for validation data\ny_validation_pred = svc.predict(X_validation)\n\n# Confusion matrix for validation data predictions\nprint('Confusion matrix for validation data:' '\\n', confusion_matrix(y_validation, y_validation_pred))\n\n# Accuracy score for validation data predictions \nacc_score = accuracy_score(y_validation, y_validation_pred)\nprint('Accuracy score for validation data:', acc_score)\n      \n# Precision score for validation data predictions \npre_score = precision_score(y_validation, y_validation_pred)\nprint('Precision score for validation data:', pre_score)\n      \n# Recall score for validation data predictions \nrec_score = recall_score(y_validation, y_validation_pred)\nprint('Recall score for validation data:', rec_score)\n\naccu_scores.append(acc_score)\nrec_scores.append(rec_score)","f7425e15":"# Selecting the right hyperparameter\n\naccuracyscores = []\nrecallscores = []\n\nfor neighbors in range(3,10):\n    knn = KNeighborsClassifier(n_neighbors=neighbors, metric='minkowski')\n    knn.fit(X_train, y_train)\n    y_validation_pred = knn.predict(X_validation)\n    accuracyscores.append(accuracy_score(y_validation, y_validation_pred))\n    recallscores.append(recall_score(y_validation, y_validation_pred))\n\nplt.plot(list(range(3,10)), accuracyscores, label='accuracy')\nplt.plot(list(range(3,10)), recallscores, label='recall')\nplt.legend()","02c3dc92":"# KNN and performance analysis\n\nknn = KNeighborsClassifier(n_neighbors=5)\n\n# Fit the model on training data\nknn.fit(X_train, y_train)\n\n# Predict the values for validation data\ny_validation_pred = knn.predict(X_validation)\n\n# Confusion matrix for validation data predictions\nprint('Confusion matrix for validation data:' '\\n', confusion_matrix(y_validation, y_validation_pred))\n\n# Accuracy score for validation data predictions \nacc_score = accuracy_score(y_validation, y_validation_pred)\nprint('Accuracy score for validation data:', acc_score)\n      \n# Precision score for validation data predictions \npre_score = precision_score(y_validation, y_validation_pred)\nprint('Precision score for validation data:', pre_score)\n      \n# Recall score for validation data predictions \nrec_score = recall_score(y_validation, y_validation_pred)\nprint('Recall score for validation data:', rec_score)\n\naccu_scores.append(acc_score)\nrec_scores.append(rec_score)","cc4407a4":"# Selecting the right hyperparameter\n\naccuracyscores = []\nrecallscores = []\n\nfor leaves in range(2,10):\n    dt = DecisionTreeClassifier(max_leaf_nodes = leaves, random_state=0, criterion='entropy')\n    dt.fit(X_train, y_train)\n    y_validation_pred = dt.predict(X_validation)\n    accuracyscores.append(accuracy_score(y_validation, y_validation_pred))\n    recallscores.append(recall_score(y_validation, y_validation_pred))\n\nplt.plot(list(range(2,10)), accuracyscores, label='accuracy')\nplt.plot(list(range(2,10)), recallscores, label='recall')\nplt.legend()","329259bf":"# Decision tree and performance analysis\n\ndt = DecisionTreeClassifier(max_leaf_nodes = 4, random_state=0, criterion='entropy')\n\n# Fit the model on training data\ndt.fit(X_train, y_train)\n\n# Predict the values for validation data\ny_validation_pred = dt.predict(X_validation)\n\n# Confusion matrix for validation data predictions\nprint('Confusion matrix for validation data:' '\\n', confusion_matrix(y_validation, y_validation_pred))\n\n# Accuracy score for validation data predictions \nacc_score = accuracy_score(y_validation, y_validation_pred)\nprint('Accuracy score for validation data:', acc_score)\n      \n# Precision score for validation data predictions \npre_score = precision_score(y_validation, y_validation_pred)\nprint('Precision score for validation data:', pre_score)\n      \n# Recall score for validation data predictions \nrec_score = recall_score(y_validation, y_validation_pred)\nprint('Recall score for validation data:', rec_score)\n\naccu_scores.append(acc_score)\nrec_scores.append(rec_score)","4b1c7cc7":"# Selecting the right hyperparameter\n\naccuracyscores = []\nrecallscores = []\n\nfor estimators in range(10,30):\n    rf = RandomForestClassifier(n_estimators = estimators, random_state=0, criterion='entropy')\n    rf.fit(X_train, y_train)\n    y_validation_pred = rf.predict(X_validation)\n    accuracyscores.append(accuracy_score(y_validation, y_validation_pred))\n    recallscores.append(recall_score(y_validation, y_validation_pred))\n\nplt.plot(list(range(10,30)), accuracyscores, label='accuracy')\nplt.plot(list(range(10,30)), recallscores, label='recall')\nplt.legend()","b28b4c7b":"# Random forest and performance analysis\n\nrf = RandomForestClassifier(n_estimators = 26, random_state=0, criterion='entropy')\n\n# Fit the model on training data\nrf.fit(X_train, y_train)\n\n# Predict the values for validation data\ny_validation_pred = rf.predict(X_validation)\n\n# Confusion matrix for validation data predictions\nprint('Confusion matrix for validation data:' '\\n', confusion_matrix(y_validation, y_validation_pred))\n\n# Accuracy score for validation data predictions \nacc_score = accuracy_score(y_validation, y_validation_pred)\nprint('Accuracy score for validation data:', acc_score)\n      \n# Precision score for validation data predictions \npre_score = precision_score(y_validation, y_validation_pred)\nprint('Precision score for validation data:', pre_score)\n      \n# Recall score for validation data predictions \nrec_score = recall_score(y_validation, y_validation_pred)\nprint('Recall score for validation data:', rec_score)\n\naccu_scores.append(acc_score)\nrec_scores.append(rec_score)","3b0a20c2":"# Plotting the accuracy and recall scores for all models\n\nList = ['SGDRegressor', 'LogisticRegression', 'SVC', 'KNN', 'DecisionTree', 'RandomForest']\n\nplt.figure(figsize=(20,15))\nplt.plot(List, accu_scores, label='accuracy')\nplt.plot(List, rec_scores, label='recall')\nplt.legend()\n\nplt.xlabel(\"Classifier Models\", fontsize = 20 )\nplt.ylabel(\"% of Accuracy\/Recall\", fontsize = 20)\nplt.title(\"Accuracy\/Recall of different Classifier Models\", fontsize = 20)\n\nplt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)","6833ce47":"# Preparing the test data\n\nX_test = df_test.copy()[['time', 'ejection_fraction', 'serum_creatinine', 'age']]\nX_test = scaler.fit_transform(X_test)\n\ny_test = df_test['DEATH_EVENT']","b2203773":"# Predict test values using SVC\n\n# Predict y values\ny_test_pred = svc.predict(X_test)\n\n# Confusion matrix for test data predictions\nprint('Confusion matrix for test data:' '\\n', confusion_matrix(y_test, y_test_pred))\n\n# Accuracy score for test data predictions \nprint('Accuracy score for test data:', accuracy_score(y_test, y_test_pred))\n      \n# Precision score for test data predictions \nprint('Precision score for test data:', precision_score(y_test, y_test_pred))\n      \n# Recall score for test data predictions \nprint('Recall score for test data:', recall_score(y_test, y_test_pred))","b3b73f9a":"# Predict test values using KNN\n\n# Predict y values\ny_test_pred = knn.predict(X_test)\n\n# Confusion matrix for test data predictions\nprint('Confusion matrix for test data:' '\\n', confusion_matrix(y_test, y_test_pred))\n\n# Accuracy score for test data predictions \nprint('Accuracy score for test data:', accuracy_score(y_test, y_test_pred))\n      \n# Precision score for test data predictions \nprint('Precision score for test data:', precision_score(y_test, y_test_pred))\n      \n# Recall score for test data predictions \nprint('Recall score for test data:', recall_score(y_test, y_test_pred))","960737fc":"The features with their correlation values are as follows:\n\ntime - -0.50 - very high<br>\n\nage - 0.34 - high;<br>\nserum_creatinine - 0.26 - high<br>\nejection fraction - -0.21 - high<br>\n\nserum_sodium - -0.16 - moderate<br>\nhigh blood pressure - 0.13 - moderate<br>\n\nsmoking - -0.09 - low<br>\nanaemia - 0.08 - low<br>\ncreatine_phosphokinase - 0.06 - low<br>\n\nplatelets - -0.02 - very low<br>\nsex - -0.01 - very low<br>\n\ndiabetes - -0.009 - negligible<br>\n\nBased on the correlation data, time, serum_creatinine, ejection_fraction, and age are the most correlated features with death event. Hence, these features will be used as inputs for modelling. ","2366649e":"The dataset contains 12 features which can be used to predict heart failure - an event associated with CVD which is the number 1 cause of death globally.\n\nThe study from which this dataset is derived claims that heart failure can be predicted from serum creatinine level and ejection fraction alone. Hence, these 2 will be major features of interest for the below analysis.\n\nHowever, the study also includes features such as diabetes, anaemia etc. which are considered as major risk factors for CVD. Hence, this analysis will also try to derive insights regarding the significance of such factors and see if they play a role in predicting CVD as well.\n\nIn this analysis, Recall will be as important as Accuracy and more important than Precision. This is because it is more important to identify all patients who are at risk of heart failure even if it leads to a mis-identification of some patients (who are not at risk) as at risk of heart failure. ","838a0290":"1. Risk of heart failure increases with increasing Age, increasing serum creatinine levels, decreasing followup time and decreasing ejection fraction.\n2. Females are more vulnerable than males to heart failure. The risk to females increases even further if they are anaemic or if they smoke.\n3. Patients with anaemia, diabetes or high blood pressure are at a higher risk of heart failure than patients who do not have these ailments.\n4. Smokers are at a higher risk of heart failure than non-smokers. Further, smoking also increases the risk posed by high BP and diabetes for heart failure.","a5d2b530":"From the distplot, we can see that more proportion of anaemic patients suffer from heart failure vis-a-vis non-anaemic patients. Though it is not determined whether this difference is statistically significant or not and the difference is not controlled for other risk factors, a general trend can be inferred that anaemic patients are at a higher risk for heart failure than non-anaemic patients.","fc5d5614":"There are no missing values. There are no text based, sound based, date based values. Only 299 values, very small by ML standards.","0a2f2cfb":"### Take a quick look at the data structure","2c123cb2":"### KNN","2d6d3705":"Smokers with high BP or diabetes are at a higher risk of heart failure than smokers who don't have both these ailments. \n\nFemales who smoke have higher incidence of heart failure than non-smoking females.","c83db342":"More proportion of people with high BP undergo heart failure than people without high BP.","732e9a6c":"C = 0.7, 0.8, 0.9 and 1.0 gives the highest accuracy and recall. Let us use higher value of C to ensure high accuracy.","16774532":"### Evaluation on test data","f159fdba":"### Random forest","a627e853":"### Scope for improvement","4e72453d":"### Introduction","8984b3d6":"There aren't any significant insights here.","58adb306":"### Logistic Regression","d1433ece":"##### Diabetes and heart failure","b3884911":"### Create train, test and validation sets","252d4f7c":"### Final model","b94178a3":"Non-smokers are at more of a risk of heart failure than smokers. There must be some other risk factors at play here. ","583a3b65":"Smokers who undergo heart failure have lower level of serum sodium than those who don't undergo heart failure. ","bd551e65":"### SVC","8b0307a0":"1. Discrete variables - Age, time <br>\n2. Continuous variables - creatinine_phosphokinase, ejection_fraction, platelets, serum_creatinine, serum_sodium <br>\n3. Binary variables - anaemia, diabetes, high blood pressure, sex, smoking, death event","fab9c2b8":"##### Anaemia and heart failure ","5930521f":"### Notes","06cac1d0":"### Import the data","3300551c":"I have taken references for some of the code from notebook on this dataset shared by Sanchita Karmakar. Thank you. ","4aaa81ea":"High creatinine-phosphokinase levels, low platelets level or low serum sodium level are indicators of possible heart failure for non-anaemic patients.","1d5a6b16":"### Import the libraries","c2e4bdc1":"Females seem to have a higher correlation between creatinine phosphokinase and platelets and heart failure than males. \n","e1c75160":"##### Smoking and heart failure","102ea490":"1. Some features such as age, creatine_phosphokinase, serum_creatinine have tail heavy distributions. Methods should be explored to handle these features in a more appropriate manner.\n2. Sophisticated techniques such as PCA can be used for feature selection.\n3. Grid search methods should be used to further fine tune the models to improve accuracy and recall. 4. Recall can also be improved using Precision vs Recall curve or ROC curve. ","f1029cda":"No new insights here.","4d62cc53":"Proportionately, more people with diabetes undergo heart failure than those without diabetes. ","de63772a":"KNN and SVC models have the highest accuracy but low recall. Decision tree and SGD models have highest recall but very low accuracy. Let us evaluate the test data on KNN and SVC. ","fd3b6740":"### SGD Classifier","da1153d6":"1. The features have widely different scales. Scaling will be needed.\n\n2. Some distributions are tail heavy - Age, creatine_phosphokinase, serum_creatinine.","855524dc":"n_estimators = 24, 26, 27, 28 has highest accuracy and recall. Lets use n_estimators = 26.","12d3cb2b":"### Feature selection","ebdc8289":"### EDA and feature engineering\nLet us do a thorough data analysis and find out if any new interesting features can be created out of less important features of the data.","0221ba51":"##### Sex and heart failure","b96e0515":"Leaves = 2 has the highest accuracy but very low recall. Leaves = 4 has slightly lower accuracy but much better recall. Lets use max_leaf_nodes = 4.","ed79f28a":"Patients without diabetes who undergo heart failure have a higher level of creatinine_phosphokinase and lower level of serum sodium and platelets than patients who don't undergo heart failure. ","3b8798da":"From the bar plots, it can be seen that patients who undergo heart failure have higher BP in general. Specifically,\n\n1. For patients without high BP, anaemia is a good indicator of heart failure.  \n2. Patients with high BP, especially females, are at a higher risk of heart failure than patients patients without high BP.","8d63ea9c":"### Major Insights","93d934e9":"### Data transformation","4b27fd82":"### Decision Tree","69981226":"KNN model has an accuracy of 85% on test data and it seems a better fit to identify potential heart failures for the study. Since Recall, too, is important in this case and SVC model has better recall than KNN (though with lower accuracy), usage of SVC model can also be explored for this study.\n\nA better approach will be to apply grid search techniques to further improvise the KNN model and improve its accuracy as well as recall.","22154559":"Proportionately, more females undergo heart failure than males. ","10f7c2cd":"From the barplots and correlation values, we can see that, in general, anaemic patients have higher chance of heart failure than non-anaemic ones.\n\n1. For males, having anaemia or not does not seem to impact heart failure event. Females who are anaemic undergo heart failure more than non-anaemic ones. Thus, anaemia is an important risk factor especially for females.\n2. Both anaemic and non-anaemic patients who undergo heart failure have higher blood pressure than those who don't undergo heart failure. \n\nA logical jump can be made that anaemia is in itself a good indicator of heart failure, irrespective of high or low BP. However, if a patient does not have anaemia, high blood pressure is a good indicator of heart failure. ","3d7fd92f":"n_neighbors = 5 has the highest accuracy and recall.","5bc41d1d":"##### High blood pressure and heart failure "}}