{"cell_type":{"51f1196f":"code","c85f148a":"code","3a15fb19":"code","649fab2b":"code","4f9fb296":"code","bc4fb88d":"code","f6255629":"code","388a20fb":"code","12d5cba6":"code","0f0d3583":"code","da5d4e75":"code","12113d85":"code","d49e08d0":"code","85b46fc3":"code","eb11aef3":"code","67f5b978":"code","857ca261":"code","efff1518":"code","d1f75d14":"code","97ebdbff":"markdown","b4fdd2b0":"markdown","b6d56b08":"markdown","55ddd75c":"markdown","a306a161":"markdown","b3161cfd":"markdown","9531a353":"markdown","f5f911f1":"markdown","befc5457":"markdown","bedfba1c":"markdown","99b3440c":"markdown","f7abcc66":"markdown","1051bbac":"markdown","7241f255":"markdown","7f43eb8d":"markdown","b326d32b":"markdown","3b3874e2":"markdown","d30d5590":"markdown","681e9d22":"markdown","7ca6942e":"markdown","4942f147":"markdown"},"source":{"51f1196f":"import numpy as np        # Fundamental package for linear algebra and multidimensional arrays\nimport pandas as pd       # Data analysis and manipultion tool\n\n# To ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","c85f148a":"# In read_csv() function, we have passed the location to where the files are located in the UCI website. The data is separated by ';'\n# so we used separator as ';' (sep = \";\")\nred_wine_data = pd.read_csv(\"..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")","3a15fb19":"# Red Wine\nred_wine_data.head() ","649fab2b":"red_wine_data.columns","4f9fb296":"# Basic statistical details about data\nred_wine_data.describe()","bc4fb88d":"red_wine_data.quality.value_counts().plot(kind = 'bar')","f6255629":"# Input\/independent variables\nX = red_wine_data.drop('quality', axis = 1)   # her we are droping the quality feature as this is the target and 'X' is input features, the changes are not \n                                              # made inplace as we have not used 'inplace = True'\n\ny = red_wine_data.quality             # Output\/Dependent variable","388a20fb":"# Let's check the shapes of X and y\nprint(\"Shape: \", X.shape, \"Dimension: \", X.ndim)\nprint(\"Shape: \", y.shape, \"Dimension: \", y.ndim)","12d5cba6":"# import train_test_split\nfrom sklearn.model_selection import train_test_split","0f0d3583":"# split the data\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state = 42)\n\n# X_train: independent\/input feature data for training the model\n# y_train: dependent\/output feature data for training the model\n# X_test: independent\/input feature data for testing the model; will be used to predict the output values\n# y_test: original dependent\/output values of X_test; We will compare this values with our predicted values to check the performance of our built model.\n \n# test_size = 0.30: 30% of the data will go for test set and 70% of the data will go for train set\n# random_state = 42: this will fix the split i.e. there will be same split for each time you run the code","da5d4e75":"# import Logistic Regression from sklearn.linear_model\nfrom sklearn.linear_model import LogisticRegression","12113d85":"log_model = LogisticRegression()","d49e08d0":"# Fit the model\nlog_model.fit(X_train, y_train)","85b46fc3":"predictions = log_model.predict(X_test)","eb11aef3":"y_test.values","67f5b978":"predictions","857ca261":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, predictions)","efff1518":"from sklearn.metrics import accuracy_score","d1f75d14":"accuracy_score(y_test, predictions)","97ebdbff":"Let's see target variable 'quality'.","b4fdd2b0":"## Understanding Data\nLet's see how our data looks.","b6d56b08":"## Building Model\nNow we are finally ready, and we can train the model.\n\nFirst, we need to import our model - Logistic Regression (again, using the sklearn library).\n\nThen we would feed the model both with the data (X_train) and the answers for that data (y_train)","55ddd75c":"### !!!Warning\nDifferent columns in this dataset are in different scales. One may get 'ConvergenceWarning' here while fitting the model. Please ignore this for here. If you want to get rid of this error then scale your data.","a306a161":"**Point to be noted:**\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)\n\nIf you clearly observe the above output that you got after fitting the model, there is an argument called 'multi_class' which is 'auto' by default. If you go back and see the insurance data, the argument 'multi_class' was still 'auto'. Here 'auto' does automatic selection of binary and multinomial. If the data is binary classification 'auto' does binary classification, and if the data is multi classification, 'auto' does multi classification. \n\nNote: You can also change 'auto' to 'ovr'. Here 'ovr' does only binary classificaion.\n\nFurther details: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegression.html","b3161cfd":"## Loading Libraries\nAll Python capabilities are not loaded to our working environment by default (even they are already installed in your system). So, we import each and every library that we want to use.\n\nIn data science, numpy and pandas are most commonly used libraries. Numpy is required for calculations like means, medians, square roots, etc. Pandas is used for data processin and data frames. We chose alias names for our libraries for the sake of our convenience (numpy --> np and pandas --> pd).","9531a353":"We had discussed in the earlier notebook that input variable must be a 2D array and target of 1D array.","f5f911f1":"## Thanks for reading the Notebook!!!**","befc5457":"### Model Performance\nWe can also check how accurate our model is performing using the 'accuracy_score' class from 'sklearn.metrics'.","bedfba1c":"Again if you observe here, the class wise false positives (above the main diagonal) and the class wise false negatives (below the main diagonal) are almost symmetrical. So, the accuracy score is an important metric here.","99b3440c":"Our model is predicting 54.37% correct results.","f7abcc66":"# Introducing Multi - class Logistic Regression\nWe have already learned about logistic regression in [this notebook](https:\/\/www.kaggle.com\/manishkc06\/binary-class-logistic-regression-beginner-s-intro) and build logistic regression model on insurance data in [this notebook](https:\/\/www.google.com\/url?q=https:\/\/github.com\/dphi-official\/ML_Models\/blob\/master\/Logistic_Regression\/logistic_regression.ipynb&sa=D&ust=1592317719569000&usg=AFQjCNGLPKpHwzSZWpRTauOb8vUv7cEmVA). In the earlier notebook we had build binary logistic regression as the target variable (i.e. bought_insurance) in insurance data has two classes 1 (bought insurance) and 0 (didn't buy insurance). In this notebook we will talk about multi - class logistic regression.\n\n**Multi - class Logistic Regression:** Here the target variable has more than two possible classes\/categories. For example, salary of an employee can be categorized as **'low', 'medium' and 'high'**. There are two types of multi - class logistic regression:\n\n1. **Multinomial Logistic Regression:** \nThe target variable has three or more classes\/categories which are not in any particular order. So, there are three or more nominal categories. \nExamples: Fruits (apple, mango, orange and banana), profession (e.g., with five groups: surgeon, doctor, nurse, dentist, therapist)\n\n2. **Ordinal Logistic Regression:**\nThe target variable has three or more ordinal categories. So, there is intrinsic order involved with the categories. \nFor example, the student performance can be categorized as poor, average, good and excellent, the salary of an employee can be categorized as **'low', 'medium' and 'high'**\n\n## Agenda\n*  About Dataset\n*  Loading Libraries and Data\n*  Understanding the Data\n*  Separating Input and Output Variables\n*  Splitting Data into Train and Test Sets\n*  Build Model\n*  Prediction\n*  Check Model Performace\n\n\n## About Dataset\nI hope all of you guys remembered the wine dataset on which we have done exploratory data analysis. Here we will take only red wine data. Given different physiochemical tests, we want to predict the quality of wine in range 1 to 10.\n\n","1051bbac":"We have already done the EDA part of this dataset in our earlier notebook. So we will not dive into EDA more here. Let's separate the independent and dependent variables.","7241f255":"### Splitting the data into Train and Test Set\nWe want to check the performance of the model that we built. For this purpose, we always split (both input and output data) the given data into training set which will be used to train the model, and test set which will be used to check how accurately the model is predicting outcomes.\n\nFor this purpose we have a class called 'train_test_split' in the 'sklearn.model_selection' module.","7f43eb8d":"### Prediction\nNow logistic regression model (i.e. log_model) is trained using X_train and y_trian data. Let's predict the target value (i.e. the quality of wine) for the X_test data. We use \"predict()\" method for prediction.","b326d32b":"### Separating Input Features and Output Features\nBefore building any machine learning model, we always separate the input variables and output variables. Input variables are those quantities whose values are changed naturally in an experiment, whereas output variable is the one whose values are dependent on the input variables. So, input variables are also known as independent variables as its values are not dependent on any other quantity, and output variable\/s are also known as dependent variables as its values are dependent on other variable i.e. input variables. Like here in this data, we can see that whether a person will buy insurance or not is dependent on the age of that person\n\nBy convention input variables are represented with 'X' and output variables are represented with 'y'.","3b3874e2":"We can observe here more wines are of average quality than poor quality and good quality. This is what we had observed in our EDA notebook of wine data.","d30d5590":"## Loading Data\nPandas module is used for reading files. We have our data in '.csv' format. We will use 'read_csv()' function for loading the data.","681e9d22":"The training happens in the third line (the \"fit\" function).","7ca6942e":"We already have actual target values (i.e. y_test) for X_test. Let's compare y_test and the predicted value for X_test by our log_model.","4942f147":"### Different attributes\n**Input variables (based on physicochemical tests):**\n1. fixed acidity\n2. volatile acidity\n3. citric acid\n4. residual sugar\n5. chlorides\n6. free sulfur dioxide\n7. total sulfur dioxide\n8. density\n9.  pH\n10.  sulphates\n11.  alcohol\n**Output variable (based on sensory data):**\n12. quality (score between 0 and 10)"}}