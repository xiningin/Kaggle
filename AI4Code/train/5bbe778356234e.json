{"cell_type":{"10ddc514":"code","940107ca":"code","2719dbe6":"code","64d4ac20":"code","d88366f0":"code","018d19a5":"code","fc4f2c6f":"code","eb494512":"code","34fd9938":"code","b82dea70":"code","3c5cbaa6":"code","b2e7c1c4":"code","fd96a0cb":"code","e8408007":"code","f871a2a2":"code","c643d85f":"code","ca94fb83":"code","8a8a531a":"code","c829c3c1":"code","da58fe1f":"code","8984ec1e":"code","bd11f423":"code","33098b6c":"code","5b47195c":"code","d37bfc54":"code","05337497":"markdown","71db2ed0":"markdown","62258133":"markdown","60fafc1d":"markdown","e976b7d2":"markdown","b47f4429":"markdown","aa1f48fa":"markdown","37e63291":"markdown","e31a73b2":"markdown","3c2d1f7e":"markdown","f125c75b":"markdown","2ab8542c":"markdown","3f0d9dbe":"markdown","8d5895eb":"markdown","a0ad638b":"markdown","ba0e295a":"markdown"},"source":{"10ddc514":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import datasets, linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n\nlabelencoder = LabelEncoder()\n%matplotlib inline\n\nfrom sklearn.datasets import load_boston\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","940107ca":"def dummyEncode(df):\n    columnsToEncode = list(df.select_dtypes(include=['category','object']))\n    le = LabelEncoder()\n    for feature in columnsToEncode:\n        try:\n            df[feature] = le.fit_transform(df[feature])\n        except:\n            print('Error encoding '+feature)\n    return df","2719dbe6":"train_data = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntrain_data.head()","64d4ac20":"test_data = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntest_data.head()","d88366f0":"cols = train_data.columns[:40] # first 30 columns\ncolours = ['#000099', '#ffff00'] # specify the colours - yellow is missing. blue is not missing.\nsns.heatmap(train_data[cols].isnull(), cmap=sns.color_palette(colours))","018d19a5":"cols = train_data.columns[40:80] # first 30 columns\ncolours = ['#000099', '#ffff00'] # specify the colours - yellow is missing. blue is not missing.\nsns.heatmap(train_data[cols].isnull(), cmap=sns.color_palette(colours))","fc4f2c6f":"cols = train_data.columns[:50]\nplt.figure(figsize = (16,5))\nsns.heatmap(train_data[cols].corr(), annot = True, cmap= 'coolwarm', fmt='.2g')","eb494512":"data = [train_data['Id'],train_data['SalePrice'], train_data['LotArea'], train_data['LotFrontage'],train_data['SaleType'],train_data['Condition2'], train_data['TotalBsmtSF'], train_data['1stFlrSF']]\nheaders = [\"Id\",\"SalePrice\",\"LotArea\",\"LotFrontage\",\"SaleType\",\"Condition\", \"TotalBasementSF\",\"1stFlrSF\"]\ntrain = pd.concat(data, axis=1, keys=headers)\ntrain.head()","34fd9938":"train = dummyEncode(train)\ntrain.head()","b82dea70":"cols = test_data.columns[0:40] # first 30 columns\ncolours = ['#000099', '#ffff00'] # specify the colours - yellow is missing. blue is not missing.\nsns.heatmap(test_data[cols].isnull(), cmap=sns.color_palette(colours))","3c5cbaa6":"data = [train_data['Id'],test_data['LotArea'], test_data['LotFrontage'],test_data['SaleType'],test_data['Condition2'], test_data['TotalBsmtSF'], test_data['1stFlrSF']]\nheaders = [\"Id\",\"LotArea\",\"LotFrontage\",\"SaleType\",\"Condition\", \"TotalBasementSF\",\"1stFlrSF\"]\ntest = pd.concat(data, axis=1, keys=headers)\ntest.head()","b2e7c1c4":"test = dummyEncode(train)\ntest.head()","fd96a0cb":"med_train = train['LotFrontage'].median()\nprint(med_train)\ntrain['LotFrontage'] = train['LotFrontage'].fillna(med_train)\n\ntrain['PrecFrontage'] = train['LotFrontage']\/train['LotArea'] * 100\n\nmed_test = test['LotFrontage'].median()\nprint(med_test)\ntest['LotFrontage'] = test['LotFrontage'].fillna(med_test)\n\ntest['PrecFrontage'] = test['LotFrontage'] \/ test['LotArea'] * 100\n\ntrain.head()","e8408007":"palette = sns.color_palette(\"bright\", 8)\nsns.relplot(x=\"SaleType\", y=\"LotArea\", hue=\"Condition\", data=train, legend = 'full', palette=palette)\n\n","f871a2a2":"ax1 = train.plot.scatter(x='LotArea',\n                      y='SalePrice',\n                      c='DarkBlue')","c643d85f":"\n#palette = sns.color_palette(\"bright\",7)\nsns.relplot(x=\"TotalBasementSF\", y=\"1stFlrSF\", hue=\"SalePrice\", data=train)","ca94fb83":"dataset = pd.get_dummies(train, columns = [\"TotalBasementSF\", \"1stFlrSF\", \"LotArea\", \"SalePrice\"])\n\n#train_final = dataset[:len(train_data)]\n#test_final = dataset[len(test_data):]\n\ny=train['SalePrice']\nX=train.drop('SalePrice', axis=1)\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 473, random_state = 2)","8a8a531a":"model_1 = RandomForestClassifier(n_estimators=100)\nmodel_1.fit(X_train, y_train)\n\npredict1 = model_1.predict(X_val)\nacuracy1 = accuracy_score(predict1, y_val)\nprint('Accuracy: ', acuracy1)","c829c3c1":"#model_2 = GradientBoostingClassifier(n_estimators=200, max_depth=3, learning_rate=0.05)\n#model_2.fit(X_train, y_train)\n\n#predict2 = model_2.predict(X_val)\n#acuracy2 = accuracy_score(predict2, y_val)\n#print('Accuracy: ', acuracy2)","da58fe1f":"model_3 = LogisticRegression(random_state=0)\nmodel_3.fit(X_train, y_train)\n\npredict3 = model_3.predict(X_val)\nacuracy3 = accuracy_score(predict3, y_val)\nprint('Accuracy: ', acuracy3)","8984ec1e":"model_4 =  DecisionTreeClassifier()\nmodel_4.fit(X_train, y_train)\n\npredict4 = model_4.predict(X_val)\nacuracy4 = accuracy_score(predict4, y_val)\nprint('Accuracy: ', acuracy4)","bd11f423":"df = pd.DataFrame({'Random Forest': acuracy1, 'Logistic': acuracy3, ' Decision Tree': acuracy4} , index=[0])\ndf.rename(index={0:'Accuracy'}, inplace=True)\ndf","33098b6c":"y_train = train['SalePrice']\nX_train = train[['Id','LotArea', 'TotalBasementSF', '1stFlrSF']]\n\nX_test = test[['Id','LotArea', 'TotalBasementSF', '1stFlrSF']]\nselected_columns = X_train[['Id','LotArea',  'TotalBasementSF', '1stFlrSF']]\ndf1 = selected_columns.copy()\n\ny_train = y_train.reindex(X_test.index)\nX_train = X_train.reindex(X_test.index)\ndf1 = X_test.reindex(X_test.index)","5b47195c":"final_model = RandomForestClassifier(n_estimators=100)\nfinal_model.fit(df1, y_train)\n\nnewId = test.Id +1460\n\nfinal_predictions = final_model.predict(X_test)\noutput = pd.DataFrame({'Id': newId, 'SalePrice': final_predictions})\nfinal_accuracy = accuracy_score(final_predictions, y_train)\nprint('Accuracy: ', final_accuracy)\n\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","d37bfc54":"output","05337497":"<a id = \"forest\"><\/a>\n### Random Forest","71db2ed0":"<a id = \"logistic\"><\/a>\n### Logistic Regression","62258133":"<a id = \"models\"><\/a>\n## Models","60fafc1d":"<a id = 'cleaning'><\/a>\n# Data Cleaning","e976b7d2":"# House Price Analysis","b47f4429":"<a id = \"decision\"><\/a>\n### Decision Tree","aa1f48fa":"<a id = \"submission\"><\/a>\n# Submission","37e63291":"<a id = \"train\"><\/a>\n## Train Data","e31a73b2":"<a id = \"visual\"><\/a>\n## Visualizations","3c2d1f7e":"<a id = \"analysis\"><\/a>\n# Analysis","f125c75b":"<a id = \"test\"><\/a>\n## Test Data","2ab8542c":"<a id = \"final\"><\/a>\n# Final Accuracies","3f0d9dbe":"## Table of Contents\n\n\n* [Import Libraries](#import)\n* [Data Cleaning](#cleaning)\n    - [Train](#train)\n    - [Test](#test)\n* [Feature Engineering](#feature)\n* [Analysis](#analysis)\n    - [Visualizations](#visual)\n    - [Models](#models)\n        - [Random Forest](#random)\n        - [Gradient](#gradient)\n        - [Logistic](#logistic)\n        - [Decision Tree](#decision)\n    - [Final Accuracies](#final)\n* [Submisson](#submission)  ","8d5895eb":"<a id = 'feature'><\/a>\n# Feature Engineering","a0ad638b":"<a id = 'import'><\/a>\n# Import","ba0e295a":"<a id = \"gradient\"><\/a>\n### Gradient Regression"}}