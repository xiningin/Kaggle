{"cell_type":{"4ec608fb":"code","c486d9d3":"code","0f80dd85":"code","a2c32fd3":"code","78c22e3a":"code","cef0e1fa":"code","cb6ef095":"code","c7643abe":"code","d7a65f19":"code","e910eb0e":"code","4eeedc09":"code","11acdbc5":"code","66641c3a":"code","3795fc2b":"code","2932a802":"code","8658b063":"code","6896881d":"code","97c8bd95":"markdown","183cb4ba":"markdown","a291a41c":"markdown","66b08da2":"markdown","ea0ae49c":"markdown"},"source":{"4ec608fb":"import pandas as pd\nimport numpy as np\nimport os\nimport pickle\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\n\nimport tensorflow as tf","c486d9d3":"train_df = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ntest_df = pd.read_csv('..\/input\/lish-moa\/test_features.csv')\n\ntrain_target_df = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\nsample_sub = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')","0f80dd85":"train_df.head()","a2c32fd3":"train_target_df.head()","78c22e3a":"# we don't need sig_id as our target col\ntarget_cols = train_target_df.columns[1:]\nN_TARGETS = len(target_cols)","cef0e1fa":"def seed_everything(seed):\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)","cb6ef095":"sample_sub.head()","c7643abe":"# multi log loss function\ndef multi_log_loss(y_true, y_pred):\n    losses = []\n    for col in y_true.columns:\n        losses.append(log_loss(y_true.loc[:, col], y_pred.loc[:, col]))\n    return np.mean(losses)","d7a65f19":"# pre-processing\ndef clean_df(data):\n    data['cp_type'] = (data['cp_type'] == 'trt_cp').astype(int)\n    data['cp_dose'] = (data['cp_dose'] == 'D2').astype(int)\n    return data","e910eb0e":"X_train = clean_df(train_df.drop([\"sig_id\"], axis=1))\nX_test = clean_df(test_df.drop(['sig_id'], axis=1))\ny_train = train_target_df.drop(['sig_id'], axis=1)\nN_FEATURES = X_train.shape[1]","4eeedc09":"# basic setup\nSEED = 1234\nEPOCHS = 28\nBATCH_SIZE = 128\nFOLDS = 5\nREPEATS = 5\nLR = 0.0005\nN_TARGETS = len(target_cols)","11acdbc5":"def build_model(n_hidden=3, n_neurons=10, learning_rate=3e-3, input_shape=N_FEATURES, activation=\"relu\", optimizer=\"adam\"):\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n\n    for layer in range(n_hidden):\n        if layer == 1:\n            model.add(tf.keras.layers.Dropout(0.2))\n        elif layer == 2:\n            model.add(tf.keras.layers.Dropout(0.5))\n        if activation == \"selu\":\n            model.add(tf.keras.layers.Dense(n_neurons, activation = \"selu\", kernel_initializer=\"lecun_normal\"))\n        elif activation == \"elu\":\n            model.add(tf.keras.layers.Dense(n_neurons, activation = \"elu\", kernel_initializer = \"he_normal\", kernel_regularizer = tf.keras.regularizers.l2(0.01)))\n        else:\n            model.add(tf.keras.layers.Dense(n_neurons, activation = activation))\n\n\n    model.add(tf.keras.layers.Dense(N_TARGETS, activation = \"sigmoid\"))\n    if optimizer == \"sgd\":\n        optimizer = tf.keras.optimizers.SGD(lr=learning_rate, momentum=0.9)\n    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n    return model\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)","66641c3a":"def build_train(resume_models = None, repeat_number = 0, folds = 5, skip_folds = 0):\n    \n    models = []\n    oof_preds = y_train.copy()\n    \n\n    kfold = KFold(folds, shuffle = True)\n    for fold, (train_ind, val_ind) in enumerate(kfold.split(X_train)):\n        print('\\n')\n        print('-'*50)\n        print(f'Training fold {fold + 1}')\n        \n        cb_lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'binary_crossentropy', factor = 0.4, patience = 2, verbose = 1, min_delta = 0.0001, mode = 'auto')\n        checkpoint_path = f'repeat:{repeat_number}_Fold:{fold}.hdf5'\n        cb_checkpt = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True, save_weights_only = True, mode = 'min')\n\n        model = build_model(n_hidden=4, learning_rate=0.001, n_neurons=200, optimizer=\"adam\", activation=\"relu\")\n        model.fit(X_train.values[train_ind],\n              y_train.values[train_ind],\n              validation_data=(X_train.values[val_ind], y_train.values[val_ind]),\n              callbacks = [cb_lr_schedule, cb_checkpt],\n              epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=2\n             )\n        model.load_weights(checkpoint_path)\n        oof_preds.loc[val_ind, :] = model.predict(X_train.values[val_ind])\n        models.append(model)\n\n    return models, oof_preds","3795fc2b":"models = []\noof_preds = []\n# seed everything\nseed_everything(SEED)\nfor i in range(REPEATS):\n    m, oof = build_train(repeat_number = i, folds=FOLDS)\n    models = models + m\n    oof_preds.append(oof)","2932a802":"mean_oof_preds = y_train.copy()\nmean_oof_preds.loc[:, target_cols] = 0\nfor i, p in enumerate(oof_preds):\n    print(f\"Repeat {i + 1} OOF Log Loss: {multi_log_loss(y_train, p)}\")\n    mean_oof_preds.loc[:, target_cols] += p[target_cols]\n\nmean_oof_preds.loc[:, target_cols] \/= len(oof_preds)\nprint(f\"Mean OOF Log Loss: {multi_log_loss(y_train, mean_oof_preds)}\")\nmean_oof_preds.loc[X_train['cp_type'] == 0, target_cols] = 0\nprint(f\"Mean OOF Log Loss (ctl adjusted): {multi_log_loss(y_train, mean_oof_preds)}\")","8658b063":"test_preds = sample_sub.copy()\ntest_preds[target_cols] = 0\nfor model in models:\n    test_preds.loc[:,target_cols] += model.predict(X_test)\ntest_preds.loc[:,target_cols] \/= len(models)\ntest_preds.loc[X_test['cp_type'] == 0, target_cols] = 0\ntest_preds.to_csv('submission.csv', index=False)","6896881d":"test_preds.head()","97c8bd95":"## Model architecture","183cb4ba":"## Evaluating the model","a291a41c":"Based on this amazing starter notebook by David Warren.\n\nhttps:\/\/www.kaggle.com\/ravy101\/drug-moa-tf-keras-starter","66b08da2":"## Generating submission after KFold","ea0ae49c":"# First competition, first submission"}}