{"cell_type":{"9d76b2e9":"code","64938c4c":"code","45c356ba":"code","424890cb":"code","e6fcb173":"code","8f797cc8":"code","8ab0dbce":"code","00568ec5":"code","6a795174":"code","685ba291":"code","f3117823":"code","f3d108c1":"code","259288e8":"code","31cd11df":"code","cd9160d0":"code","76bf0b43":"code","561452b3":"code","a4551ebd":"code","5cde345d":"code","75933e6c":"code","7ef96505":"code","b79853a2":"code","5b341b32":"markdown","175aafe2":"markdown","322f25d4":"markdown","3c1c8770":"markdown","ea2a97c2":"markdown","d09320c9":"markdown","7e35b70a":"markdown","619496e1":"markdown"},"source":{"9d76b2e9":"import pandas as pd\nimport numpy as np\nimport scipy.stats as stats\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport shap\nimport eli5\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('fivethirtyeight')\n%matplotlib inline\n\nshap.initjs()\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","64938c4c":"df = pd.read_csv('\/kaggle\/input\/usedcarscatalog\/cars.csv')\ndf.shape","45c356ba":"from sklearn.model_selection import train_test_split \n\nX = df.drop('price_usd', axis=1)\ny = df['price_usd']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","424890cb":"print(\"Number of cars in X_train dataset: \", X_train.shape) \nprint(\"Number of cars in y_train dataset: \", y_train.shape) \nprint(\"Number of cars in X_test dataset: \", X_test.shape) \nprint(\"Number of cars in y_test dataset: \", y_test.shape)","e6fcb173":"df.info()","8f797cc8":"%%time\n# create train_pool object\nfrom catboost import CatBoostRegressor\nfrom catboost import Pool\nfrom catboost import MetricVisualizer\n\n\n\ncat_features=['manufacturer_name', \n              'model_name', \n              'transmission', \n              'color', \n              'engine_fuel',\n              'engine_has_gas',\n              'engine_type', \n              'body_type', \n              'has_warranty', \n              'state', \n              'drivetrain',\n              'is_exchangeable', \n              'location_region',\n              'feature_0',\n              'feature_1',\n              'feature_2',\n              'feature_3',\n              'feature_4',\n              'feature_5',\n              'feature_6',\n              'feature_7',\n              'feature_8',\n              'feature_9',]\n\ntrain_pool = Pool(\n    data=X_train, \n    label=y_train,\n    cat_features = cat_features\n)\n\n# create validation_pool object\nvalidation_pool = Pool(\n    data=X_test, \n    label=y_test,\n    cat_features = cat_features\n)","8ab0dbce":"%%time\n\n# pretty basic model, max_depth=10 give slightly better results\ncbs = CatBoostRegressor(iterations=4000,\n                         learning_rate=0.012,\n                         loss_function='MAE',\n                         max_depth=10, \n                         early_stopping_rounds=200,\n                         cat_features = cat_features)\n\n# we are passing categorical features as parameters here\ncbs.fit(\n    train_pool,\n    eval_set=validation_pool,\n    verbose=False,\n    plot=True \n);","00568ec5":"test_predictions = cbs.predict(X_test).flatten()\n\nerror = (test_predictions - y_test)\n\nplt.figure(figsize=(10,10))\nplt.scatter(y_test, \n            test_predictions, \n            c=error,\n            s=1.9,\n            cmap='hsv'\n            )\nplt.colorbar()\nplt.xlabel('True Values [price_usd]')\nplt.ylabel('Predictions [price_usd]')\nplt.axis('equal')\nplt.axis('square')\nplt.xlim([0, plt.xlim()[1]])\nplt.ylim([0, plt.ylim()[1]])\nplt.show()","6a795174":"error = test_predictions - y_test\n# print(type(error))\n\nplt.figure(figsize=(10,10))\nplt.scatter(y_test, \n            test_predictions, \n            c=error,\n            s=2,\n            cmap='hsv',\n            )\nplt.colorbar()\nplt.xlabel('True Values [price_usd]')\nplt.ylabel('Predictions [price_usd]')\nplt.axis('equal')\nplt.axis('square')\nplt.xlim([0, 30000])\nplt.ylim([0, 30000])\nplt.show()","685ba291":"plt.figure(figsize=(10,10))\nplt.hist2d(y_test, test_predictions, (500,500),cmap=plt.cm.jet)\nplt.colorbar()\nplt.xlim([0, 30000])\nplt.ylim([0, 30000])\nplt.show()","f3117823":"plt.figure(figsize=(16,7))\nplt.hist(error, bins = 300, rwidth=0.9)\nplt.xlabel('Predictions Error [price_usd]')\n_ = plt.ylabel('Count')\nplt.xlim([-8000, 8000])\nplt.show()","f3d108c1":"%%time\n\nimportance_types = ['PredictionValuesChange',\n                    'LossFunctionChange'\n                   ]\n\n\nfor importance_type in importance_types:\n    print(importance_type)\n    print(cbs.get_feature_importance(data=train_pool, \n                                     type=importance_type))\n    print('\\n\\n\\n\\n')","259288e8":"%%time\n\nimport shap\nshap.initjs()\n\nshap_values = cbs.get_feature_importance(Pool(X_test, \n                                              label=y_test,\n                                              cat_features=cat_features), \n                                         type=\"ShapValues\")\nprint(type(shap_values))\n\nexpected_value = shap_values[0,-1]\nprint(expected_value)\n\nshap_values = shap_values[:,:-1]","31cd11df":"shap.summary_plot(shap_values, X_test, max_display=X_test.shape[1])","cd9160d0":"shap.dependence_plot(ind='year_produced', interaction_index='year_produced',\n                     shap_values=shap_values, \n                     features=X_test,  \n                     display_features=X_test)","76bf0b43":"shap.dependence_plot(ind='odometer_value', interaction_index='odometer_value',\n                     shap_values=shap_values, \n                     features=X_test,  \n                     display_features=X_test)","561452b3":"shap.dependence_plot(ind='engine_capacity', interaction_index='engine_capacity',\n                     shap_values=shap_values, \n                     features=X_test,  \n                     display_features=X_test)","a4551ebd":"shap.dependence_plot(ind='number_of_photos', interaction_index='number_of_photos',\n                     shap_values=shap_values, \n                     features=X_test,  \n                     display_features=X_test)","5cde345d":"shap.dependence_plot(ind='duration_listed', interaction_index='duration_listed',\n                     shap_values=shap_values, \n                     features=X_test,  \n                     display_features=X_test, show=False)\nplt.show()","75933e6c":"shap.dependence_plot(ind='up_counter', interaction_index='up_counter',\n                     shap_values=shap_values, \n                     features=X_test,  \n                     display_features=X_test, show=False)\nplt.show()","7ef96505":"shap.force_plot(expected_value, shap_values[:1000,:], X_test.iloc[:1000,:])","b79853a2":"for i in range(20,30):\n    print('Sample', i, 'from the test set:')\n    display(shap.force_plot(expected_value, shap_values[i,:], X_test.iloc[i,:]))\n    print('Listed_price -------------------------------------->', y_test.iloc[i])\n    print('parameters:\\n', X_test.iloc[i,:])\n    print('\\n\\n\\n\\n\\n\\n\\n')","5b341b32":"### Explore feature importances","175aafe2":"# Gradient Boosting on Decision Trees using CatBoost\nCatBoost library by Yandex provides excellent categorical features support. Will train a CatBoost Regressor model to predict the price of a car based on its parameters.","322f25d4":"**Load the dataset**","3c1c8770":"Instantiate **CatBoostRegressor** and train it.","ea2a97c2":"# Conclusion\nI've built a very basic but descently performing catboost model that successfully predicts the prices. Sometimes the predicted price is much lower than the actual listed price in the catalog and in these cases there is usually a lone duration_listed value which means the car is overpriced. ","d09320c9":"### Create a simple train-test split (no folds for now)","7e35b70a":"### Explore the predictions","619496e1":"### Explore model behavior and SHAP values for samples in test dataset"}}