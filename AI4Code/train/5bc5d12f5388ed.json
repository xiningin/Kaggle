{"cell_type":{"3950fbb3":"code","c9bd09bf":"code","71c7c7dd":"code","599070ae":"code","b7e007f4":"code","88cb64e0":"code","d3a5bee9":"code","8d7d1221":"code","754749c8":"code","0432ace6":"code","4fe7ec9e":"code","fab76e50":"code","67336db9":"code","d0848389":"code","90685fb3":"code","57039bd7":"code","4006c759":"code","fe4316c3":"code","fcb5c0d7":"code","3878f3af":"code","2b786021":"code","0b930037":"code","b06359bd":"code","20505b89":"code","f0e953b2":"code","0abb88b8":"code","99ce7b56":"code","2fc14a88":"code","c7b018ad":"code","a015ce5b":"code","d62e729d":"code","b79e62c2":"code","ae6cb370":"code","869f2777":"code","9bf935af":"code","6822ab12":"code","64666347":"code","006a81a7":"code","6eccf8a0":"code","bdbe0bc9":"code","1fd58790":"code","4566960f":"code","4ddff239":"code","d2c67167":"code","86c1eda9":"code","3fba42fb":"code","b07e3911":"code","cc8a1b18":"code","0b68a762":"code","a64f968f":"code","a2cd6b61":"code","4d2622f8":"markdown"},"source":{"3950fbb3":"#Final submission score is 0.67,which needs to be improved.","c9bd09bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.tree import ExtraTreeClassifier\nfrom sklearn.svm import SVC\nfrom statistics import variance\nfrom sklearn.feature_selection import VarianceThreshold\n\n\n\n\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","71c7c7dd":"test = pd.read_csv(\"..\/input\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/train.csv\")","599070ae":"train.sample()\n","b7e007f4":"train.head()","88cb64e0":"#check for missing values\ntrain.info()","d3a5bee9":"sns.heatmap(train.isnull(),cbar = False)","8d7d1221":"distance=pd.DataFrame(train,columns = ['Horizontal_Distance_To_Hydrology','Horizontal_Distance_To_Roadways',\n                                      'Hillshade_Noon','Horizontal_Distance_To_Fire_Points'])\n\n\n\nfor column in distance:\n    plt.figure()\n    distance.boxplot([column])","754749c8":"#Soil_Type7,Soil_Type15 has 0 standard deviation\n#train = train.drop([\"Soil_Type7\",\"Soil_Type15\"],axis = 1)\n#test = test.drop([\"Soil_Type7\",\"Soil_Type15\"],axis = 1)","0432ace6":"#Cover type is the target to be predicted.\n#Train test split\nx_train,x_test,y_train,y_test=  train_test_split(train.drop('Cover_Type',axis = 1),train['Cover_Type'],test_size = 0.3,random_state = 17)","4fe7ec9e":"#Building logistic regression model\nlogreg = LogisticRegression()\nlogreg.fit(x_train,y_train)","fab76e50":"#Predicting logistic regression results\nlogreg.predict(x_test)","67336db9":"#Logistic regression test scores\nscore = logreg.score(x_test, y_test)\nprint(score)","d0848389":"#Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier","90685fb3":"tree_model = DecisionTreeClassifier()\nensemble_model = RandomForestClassifier()\n","57039bd7":"tree_model.fit(x_train,y_train)","4006c759":"ensemble_model.fit(x_train,y_train)","fe4316c3":"tree_predict=tree_model.predict(x_test)\ntree_model.score(x_test,y_test)","fcb5c0d7":"ensemble_predict= ensemble_model.predict(test)\nprint (ensemble_predict)\nensemble_model.score(x_test,y_test)","3878f3af":"#of the 3 algorithms applied to the dataset,ensemble model works better with a score of 0.84\n","2b786021":"submission.shape","0b930037":"x_test.shape\ntest.shape\n","b06359bd":"#current public score is 0.66,this should be improved\n#checking the variance of each feature\ntrain1 = train\ntest1 = test\nsel = VarianceThreshold(threshold=(.8 * (1 - .8)))\nsel.fit_transform(train1)\n\ntrain1.head(40)\n\n#this is based on this article ,https:\/\/scikit-learn.org\/stable\/modules\/feature_selection.html\n#could see no rows being removed in the data set,as all of them have valid values,non null.\n","20505b89":"tree_model.fit","f0e953b2":"tree_model.predict(test1)\ntree_model.score(x_test,y_test)","0abb88b8":"pd.DataFrame([train.mean(), train.std(), train.var()], index=['Mean', 'Std. dev', 'Variance'])\n","99ce7b56":"#Getting feature importance after running the data through a ensemble model classifier","2fc14a88":"x=pd.DataFrame(ensemble_model.feature_importances_,\n             index=x_train.columns, columns=['Importance']).sort_values(\n    by='Importance', ascending=False)[:10]\nprint(x)","c7b018ad":"#Modelling based on important features alone\ntrain2 = train\ntest2 = test\ntrain_imp = train2[['Id','Elevation','Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points',\n                    'Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Hillshade_9am',\n                    'Aspect','Hillshade_3pm',\n                    'Wilderness_Area4','Cover_Type']]\n\n","a015ce5b":"x_train_imp,x_test_imp,y_train_imp,y_test_imp=  train_test_split(train_imp.drop('Cover_Type',axis = 1),train_imp['Cover_Type'],\n                                                                 test_size = 0.3,random_state = 17)\n","d62e729d":"logreg1 = LogisticRegression()\nlogreg1.fit(x_train_imp,y_train_imp)\nlogreg1.predict(x_test_imp)\nlogreg1.score(x_test_imp,y_test_imp)","b79e62c2":"tree_model1 =DecisionTreeClassifier()\ntree_model1.fit(x_train_imp,y_train_imp)\ntree_predict=tree_model1.predict(x_test_imp)\ntree_model1.score(x_test_imp,y_test_imp)","ae6cb370":"ensemble_1 = RandomForestClassifier()\nensemble_1.fit(x_train_imp,y_train_imp)\nensemble_predict= ensemble_1.predict(x_test_imp)\nprint (ensemble_predict)\nensemble_1.score(x_test_imp,y_test_imp)","869f2777":"pd.DataFrame(tree_model.feature_importances_,index = x_train.columns,columns=['Importance']).sort_values(\n    by = 'Importance',ascending = False)[:10]","9bf935af":"#Both the models have same important features,also these important features completely ignores the soil type feature.\n#This should be included,except Soil_Type7,Soil_Type15 has lower standard deviation.\n\n","6822ab12":"#Modelling based on important features alone\ntrain = train.drop([\"Soil_Type7\",\"Soil_Type15\",\"Wilderness_Area1\",\"Wilderness_Area2\",\"Wilderness_Area3\",\"Slope\",\n                  \"Hillshade_Noon\"],axis = 1)\ntest = test.drop([\"Soil_Type7\",\"Soil_Type15\",\"Wilderness_Area1\",\"Wilderness_Area2\",\"Wilderness_Area3\",\"Slope\",\n                  \"Hillshade_Noon\"],axis = 1)\ntrain3 = train\ntest3 = test\n\ntrain[:10]\n#train_imp = train3[train]\n\n#[['Id','Elevation','Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points',\n #                   'Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Hillshade_9am',\n  #                  'Aspect','Hillshade_3pm',\n   #                 'Wilderness_Area4','Cover_Type']]","64666347":"x_train_3,x_test_3,y_train_3,y_test_3=  train_test_split(train3.drop('Cover_Type',axis = 1),train3['Cover_Type'],\n                                                                 test_size = 0.3,random_state = 17)\n","006a81a7":"logreg2 = LogisticRegression()\nlogreg2.fit(x_train_3,y_train_3)\nlogreg2.predict(x_test_3)\nlogreg2.score(x_test_3,y_test_3)","6eccf8a0":"tree_model2 =DecisionTreeClassifier()\ntree_model2.fit(x_train_3,y_train_3)\ntree_predict2=tree_model2.predict(x_test_3)\ntree_model2.score(x_test_3,y_test_3)\ntree_test_pred = tree_model2.predict(test)","bdbe0bc9":"ensemble_2 = RandomForestClassifier()\nensemble_2.fit(x_train_3,y_train_3)\nensemble_predict2= ensemble_2.predict(x_test_3)\nprint (ensemble_predict2)\nensemble_2.score(x_test_3,y_test_3)\nensemble_test_pred = ensemble_2.predict(test)\n","1fd58790":"#Naive Bayes Model","4566960f":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train_3,y_train_3)\nnb.predict(x_test_3)\nnb.score(x_test_3,y_test_3)","4ddff239":"#SGDClassifier,very low performance","d2c67167":"sgd = SGDClassifier(loss = 'modified_huber',shuffle = True,random_state = 171)\nsgd.fit(x_train_3,y_train_3)\nsgd.predict(x_train_3)\nsgd.score(x_test_3,y_test_3)","86c1eda9":"sgd = SGDClassifier(loss = 'log',shuffle = True,random_state = 171)\nsgd.fit(x_train_3,y_train_3)\nsgd.predict(x_train_3)\nsgd.score(x_test_3,y_test_3)","3fba42fb":"sgd = SGDClassifier(shuffle = True,random_state = 171)\nsgd.fit(x_train_3,y_train_3)\nsgd.predict(x_train_3)\nsgd.score(x_test_3,y_test_3)","b07e3911":"submission = pd.DataFrame({'Id':test.Id,'Cover_Type':ensemble_test_pred})\nsubmission.head()\nsubmission.to_csv('submission.csv',index = False)","cc8a1b18":"submission_tree = pd.DataFrame({'Id':test.Id,'Cover_Type':tree_test_pred})\nsubmission_tree.head()\nsubmission_tree.to_csv('submission2.csv',index = False)","0b68a762":"#Extra tree classifier is a tree based model for classification problems\net = ExtraTreeClassifier()\net.fit(x_train_3,y_train_3)\net.predict(x_train_3)\net.score(x_test_3,y_test_3)","a64f968f":"from sklearn.semi_supervised import LabelPropagation\nlb = LabelPropagation()\nlb.fit(x_train_3,y_train_3)\nlb.predict(x_train_3)\nlb.score(x_test_3,y_test_3)","a2cd6b61":"from sklearn.neighbors import KNeighborsClassifier\nknng =KNeighborsClassifier()\nknng.fit(x_train_3,y_train_3)\nknng.predict(x_train_3)\nknng.score(x_test_3,y_test_3)","4d2622f8":"There are no missing numbers in the map."}}