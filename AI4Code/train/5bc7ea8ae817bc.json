{"cell_type":{"2c9500fc":"code","623e377c":"code","9f5cba61":"code","23c1aebd":"code","a4ae529e":"code","ecf29e71":"code","5228be08":"code","6704db08":"code","a485c2dd":"code","914f5ed9":"code","86725939":"code","56369a01":"code","781c8009":"code","a26f2f20":"code","998d300e":"code","ce003e32":"code","654bc5ee":"code","12dfeb0c":"code","1956735b":"code","2f0082e7":"code","b5d18395":"code","7624fcb4":"code","ea43999f":"code","377e1a80":"code","86b2fd60":"code","8e913afc":"code","3f5e3765":"code","e6d4baf6":"code","426bec67":"code","d52603c6":"code","b83be71b":"code","f2655836":"code","3c67d648":"code","dd7275f1":"code","48521746":"markdown","6349155b":"markdown","a9a1ede3":"markdown","2cb0125e":"markdown","aade92c9":"markdown","fb0d1d1a":"markdown","d6e53bf9":"markdown","29e30305":"markdown","f07ac656":"markdown","dfaa96f8":"markdown","a7eeab6f":"markdown","67390982":"markdown","8423bc79":"markdown","f505da41":"markdown","90d4dabe":"markdown","5ad0cbf5":"markdown","e33b4538":"markdown"},"source":{"2c9500fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","623e377c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n#sns.set_style ('dark')\n\n#sns.set_palette('RdYlGn')\ncolors = ['#B90276','#50237F', '#005691', '#008ECF','#E20015', '#00A8B0', '#78BE20', '#006249', '#525F6B']\n\nsns.set_palette(sns.color_palette(colors))","9f5cba61":"data = pd.read_csv('\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv', sep = ',')\ndf = pd.DataFrame(data)\ndf.head()","23c1aebd":"df.info()","a4ae529e":"df['bmi'] = df['bmi'].fillna(method = 'ffill')","ecf29e71":"df.bmi.shape","5228be08":"df.columns","6704db08":"df.age = df.age.astype(int)\n#df.avg_glucose_level = df.avg_glucose_level.astype(int)","a485c2dd":"object1 = df.select_dtypes(include = ['object']).columns","914f5ed9":"othercol = df.select_dtypes(include = ['float64']).columns","86725939":"for col in object1:\n    print(col ,'\\n', df[col].unique(),'\\n')","56369a01":"plt.title('Count of Stroke')\nsns.countplot(x ='stroke',  data = df)","781c8009":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nplt.title('Age & Gender Count')\nsns.histplot(x ='age',  data = df, hue = 'gender')\nplt.subplot(2,2,2)\nplt.title('Affect of Age BMI on Stroke')\nsns.scatterplot(x = 'age', y = 'bmi', hue = 'stroke', data = df)\nplt.subplot(2,2,3)\nplt.title('Which Gender has more chances of stroke')\nsns.countplot(x = 'gender', hue ='stroke', data = df)\nplt.subplot(2,2,4)\nplt.title('Count of Gender')\nsns.histplot(x='gender', data = df)\nplt.show()","a26f2f20":"plt.figure(figsize=(20,15))\nplt.subplot(3,3,1)\nplt.title('Gender & Avg Glucose Level & Stroke')\nsns.boxplot(x ='gender',y='avg_glucose_level', hue = 'stroke', data = df)\n\nplt.subplot(3,3,2)\nplt.title('How many of them smoke')\nsns.countplot(x = 'gender', hue = 'smoking_status', data = df)\n\nplt.subplot(3,3,3)\nplt.title('Which Residence_type has more chances of stroke')\nsns.countplot(x = 'Residence_type', hue ='stroke', data = df)\n\nplt.subplot(3,3,4)\nplt.title('Count of Gender with Residence type')\nsns.histplot(x='Residence_type', data = df, hue = 'gender')\n\nplt.subplot(3,3,5)\nplt.title('Which Residence type is smoking')\nsns.histplot(x='Residence_type', data = df, hue = 'smoking_status')\n\n\nplt.subplot(3,3,6)\nplt.title('Married or Unmarried')\nsns.countplot(x='gender', data = df, hue = 'ever_married')\n\nplt.subplot(3,3,7)\nplt.title('Ever Worked?')\nsns.countplot(x='gender', data = df, hue = 'work_type')\n\nplt.subplot(3,3,8)\nplt.title('Having Hypertension?')\nsns.countplot(x='gender',data = df, hue = 'hypertension')\n\nplt.subplot(3,3,9)\nplt.title('Having heart_disease?')\nsns.scatterplot(x='age', y = 'bmi',data = df, hue = 'heart_disease')\nplt.show()","998d300e":"i = 1\nplt.figure(figsize = (10,15))\nfor col in object1:\n    plt.subplot(3,2,i)\n    sns.countplot(x = 'stroke',hue = df[col] , data = df)\n    i +=1","ce003e32":"plt.figure(figsize=(10,7))\nfor col in object1:\n    g = sns.FacetGrid(df, col=col, hue=\"stroke\")\n    g.map(sns.kdeplot, \"age\",alpha=.7)\n    plt.figure(figsize=(15,7))\n    g.add_legend()","654bc5ee":"import matplotlib.pyplot as plt\nimport pandas as pd\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(15,9))\nax = fig.add_subplot(121, projection = '3d')\n\nx = df['age']\ny = df['hypertension']\nz = df['bmi']\n\nax.scatter(x, y, z)\nax.set_xlabel(\"Age\")\nax.set_ylabel(\"Hypertension\")\nax.set_zlabel(\"BMI\")\nplt.title(\"AGE, Hypertension & BMI\")\n\nax = fig.add_subplot(122, projection = '3d')\n\nx = df['age']\ny = df['heart_disease']\nz = df['bmi']\n\nax.scatter(x, y, z)\nax.set_xlabel(\"Age\")\nax.set_ylabel(\"heart_disease\")\nax.set_zlabel(\"BMI\")\nplt.title(\"AGE, Heart Disease & BMI\")\n\nplt.show()","12dfeb0c":"fig = px.scatter_3d(df, x='age', y='avg_glucose_level', z='bmi',color='stroke')\nfig.update_traces(marker=dict(size=2))\nfig.show()\n","1956735b":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncol = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\nfor col in col:\n    df[col] = le.fit_transform(df[col])\n","2f0082e7":"df1 = df.drop(['id'],1)\nplt.figure(figsize= (12,8))\ncorr = df1.corr()\nsns.heatmap(corr, linewidth=0.7, annot =True, cmap = 'coolwarm')\n","b5d18395":"X = df1.drop(['stroke'], 1)\ny = df1.stroke","7624fcb4":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y , random_state =43, test_size = 0.2)","ea43999f":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n\nrfc = RandomForestClassifier()\n\n# fit the predictor and target\nrfc.fit(X_train, y_train)\n\n# predict\nrfc_predict = rfc.predict(X_test)# check performance\nprint('ROCAUC score:',roc_auc_score(y_test, rfc_predict))\nprint('Accuracy score:',accuracy_score(y_test, rfc_predict))\nprint('F1 score:',f1_score(y_test, rfc_predict))","377e1a80":"# import library\nfrom imblearn.under_sampling import RandomUnderSampler\n\nrus = RandomUnderSampler(random_state=42, replacement=True)# fit predictor and target variable\nX_rus, y_rus = rus.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus , random_state =43, test_size = 0.2)\n\n","86b2fd60":"rfc.fit(X_train, y_train)\n\n# predict\nrfc_predict = rfc.predict(X_test)# check performance\nprint('ROCAUC score:',roc_auc_score(y_test, rfc_predict))\nprint('Accuracy score:',accuracy_score(y_test, rfc_predict))\nprint('F1 score:',f1_score(y_test, rfc_predict))","8e913afc":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, f1_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import roc_auc_score , plot_roc_curve\n\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error\nrf = RandomForestClassifier()\nad = AdaBoostClassifier(base_estimator =rf)\ndt = DecisionTreeClassifier()\nkn = KNeighborsClassifier()\n#gnb = GaussianProcessClassifier()\nsvc = SVC()\n\nmodels = [rf,ad, dt, kn, svc]\nfor model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    mod = model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    scores = cross_val_score(model, X, y, cv=5).mean().round(3)\n    f1score = metrics.f1_score(y_test, y_pred).round(3)\n    #accuracy = metrics.classification_report(y_test, y_pred)\n    print(model, '\\n', 'mean_score:',scores, '\\n', 'ROCAUC score:',roc_auc_score(y_test, y_pred).round(3),'\\n',\"F1_SCORE:\", f1score,'\\n' )\n   ","3f5e3765":"y_pred_ada = ad.predict(X_test)","e6d4baf6":"prediction = pd.DataFrame(y_pred_ada, columns= ['Predicted'])\nprediction['ID'] = df['id']\nprediction.head()","426bec67":"from yellowbrick.classifier import class_prediction_error\nvisualizer = class_prediction_error(AdaBoostClassifier(n_estimators=100), X_train, y_train)\nvisualizer.show()","d52603c6":"from yellowbrick.classifier import classification_report\nvisualizer = classification_report(AdaBoostClassifier(n_estimators=100), X_train, y_train)\nvisualizer.show()\n","b83be71b":"from yellowbrick.classifier import confusion_matrix\nvisualizer = confusion_matrix(AdaBoostClassifier(n_estimators=100), X_train, y_train)\nvisualizer.show()","f2655836":"from yellowbrick.classifier import roc_auc\nvisualizer = roc_auc(AdaBoostClassifier(n_estimators=100), X_train, y_train)\nvisualizer.show()\n","3c67d648":"from yellowbrick.classifier import discrimination_threshold\nvisualizer = discrimination_threshold(AdaBoostClassifier(n_estimators=100), X_train, y_train)\nvisualizer.show()","dd7275f1":"prediction.to_csv('submission.csv', index = False)","48521746":"# Under Sampling the Data & fitting it to our Model\n","6349155b":"# Without under sampling we get a very high score of accuracy, as our data mostly contains less number of people who have stroke. ML models work well when they have \"Balanced Data\"","a9a1ede3":"# Adaboost Classifier gives better F1 Score  compared to other models","2cb0125e":"# If you have come so far please do not forget to vote, Thank you !!","aade92c9":"# Corelation plot\n***As such I do not see any corelation with stroke***","fb0d1d1a":"# Visualization","d6e53bf9":"***under-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information.***","29e30305":"***Under sampling improves the F1 Score***","f07ac656":"# Without under or over Sampling","dfaa96f8":"# Attribute Information\n1) id: unique identifier\n\n2) gender: \"Male\", \"Female\" or \"Other\"\n\n3) age: age of the patient\n\n4) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n\n5) heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n\n6) ever_married: \"No\" or \"Yes\"\n\n7) work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n\n8) Residence_type: \"Rural\" or \"Urban\"\n\n9) avg_glucose_level: average glucose level in blood\n\n10) bmi: body mass index\n\n11) smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n\n12) stroke: 1 if the patient had a stroke or 0 if not\n\n*Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient","a7eeab6f":"# 3D Visualization","67390982":"# Prediction with id's","8423bc79":"# Fitting the undersampled data on multiple models","f505da41":"# Filling missing values with ffill method","90d4dabe":"# What does our target data contain\nits highly \"Imbalanced\"","5ad0cbf5":"# Label Encoder fitting on categorical data","e33b4538":"# Reading the data"}}