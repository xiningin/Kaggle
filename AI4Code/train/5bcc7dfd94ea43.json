{"cell_type":{"5dbab109":"code","bc220ced":"code","1b4963fe":"code","de9ec401":"code","2255933b":"code","a4565d9c":"code","0add7b19":"code","c37edb5c":"code","72e494e2":"code","cc171f78":"code","34d94222":"code","37af4744":"code","a2dfbfd6":"code","f5d85e88":"code","15fc4d3c":"code","12f0c97f":"code","b1b14ccc":"code","f7564865":"code","10be514b":"code","01ead3ff":"code","7ba095ef":"code","70540b8f":"code","f8148add":"code","7726d879":"code","e63d1d06":"code","43510bd2":"code","2cadbe34":"code","981b3dd6":"code","d8047590":"code","fa6d5716":"code","53784a15":"code","9473dd30":"code","dafb11df":"code","afaab64e":"code","1e823f60":"code","c9334fc5":"code","95ec0d6a":"code","bacfe326":"code","3173e151":"code","4f54ac96":"markdown","0d3bb851":"markdown","20937238":"markdown","fb96d91a":"markdown","864dfc98":"markdown","9060e463":"markdown","274a63a9":"markdown","1a3438e4":"markdown","51bd4d4b":"markdown","5c8d0018":"markdown","4d4ae9b5":"markdown","8dddc787":"markdown","a488b58a":"markdown","38711455":"markdown","817b1098":"markdown","4fe5d40b":"markdown","33e3dfe5":"markdown","5dd51cc4":"markdown","152b40c6":"markdown","c7c23fd2":"markdown","f4f1f978":"markdown","fd598854":"markdown","481427df":"markdown","c4e18904":"markdown","30fe23cf":"markdown","93ee9713":"markdown","cdff77c5":"markdown","8df0141a":"markdown","2c221b43":"markdown","9bc37899":"markdown","6713c3ff":"markdown","d730f9c8":"markdown"},"source":{"5dbab109":"# Importing prerequisites\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport warnings\n\n%matplotlib inline\npd.set_option(\"display.max_rows\", None,\"display.max_columns\", None)\nwarnings.simplefilter(action='ignore')\nplt.style.use('seaborn')","bc220ced":"# Reading cat data.csv\ndf_main = pd.read_csv('..\/input\/vehicle-dataset-from-cardekho\/car data.csv')","1b4963fe":"df_main.head()","de9ec401":"df_main.shape","2255933b":"df_main.info()","a4565d9c":"# Checking numerical stats\ndf_main.describe()","0add7b19":"# Checking for missing values\ndf_main.isna().sum()","c37edb5c":"df_main['Age'] = 2020 - df_main['Year']\ndf_main.drop('Year',axis=1,inplace = True)","72e494e2":"df_main.rename(columns = {'Selling_Price':'Selling_Price(lacs)','Present_Price':'Present_Price(lacs)',\n                          'Owner':'Past_Owners'},inplace = True)","cc171f78":"df_main.columns","34d94222":"cat_cols = ['Fuel_Type','Seller_Type','Transmission','Past_Owners']\ni=0\nwhile i < 4:\n    fig = plt.figure(figsize=[10,4])\n    #ax1 = fig.add_subplot(121)\n    #ax2 = fig.add_subplot(122)\n    \n    #ax1.title.set_text(cat_cols[i])\n    plt.subplot(1,2,1)\n    sns.countplot(x=cat_cols[i], data=df_main)\n    i += 1\n    \n    #ax2.title.set_text(cat_cols[i])\n    plt.subplot(1,2,2)\n    sns.countplot(x=cat_cols[i], data=df_main)\n    i += 1\n    \n    plt.show()","37af4744":"num_cols = ['Selling_Price(lacs)','Present_Price(lacs)','Kms_Driven','Age']\ni=0\nwhile i < 4:\n    fig = plt.figure(figsize=[13,3])\n    #ax1 = fig.add_subplot(121)\n    #ax2 = fig.add_subplot(122)\n    \n    #ax1.title.set_text(num_cols[i])\n    plt.subplot(1,2,1)\n    sns.boxplot(x=num_cols[i], data=df_main)\n    i += 1\n    \n    #ax2.title.set_text(num_cols[i])\n    plt.subplot(1,2,2)\n    sns.boxplot(x=num_cols[i], data=df_main)\n    i += 1\n    \n    plt.show()","a2dfbfd6":"df_main[df_main['Present_Price(lacs)'] > df_main['Present_Price(lacs)'].quantile(0.99)]","f5d85e88":"df_main[df_main['Selling_Price(lacs)'] > df_main['Selling_Price(lacs)'].quantile(0.99)]","15fc4d3c":"df_main[df_main['Kms_Driven'] > df_main['Kms_Driven'].quantile(0.99)]","12f0c97f":"sns.heatmap(df_main.corr(), annot=True, cmap=\"RdBu\")\nplt.show()","b1b14ccc":"df_main.corr()['Selling_Price(lacs)']","f7564865":"df_main.pivot_table(values='Selling_Price(lacs)', index = 'Seller_Type', columns= 'Fuel_Type')","10be514b":"df_main.pivot_table(values='Selling_Price(lacs)', index = 'Seller_Type', columns= 'Transmission')","01ead3ff":"df_main.drop(labels='Car_Name',axis= 1, inplace = True)","7ba095ef":"df_main.head()","70540b8f":"df_main = pd.get_dummies(data = df_main,drop_first=True) \n# drop_first is set to True, to avoid \"Dummy Trap\"","f8148add":"df_main.head()","7726d879":"# Separating target variable and its features\ny = df_main['Selling_Price(lacs)']\nX = df_main.drop('Selling_Price(lacs)',axis=1)","e63d1d06":"from sklearn.model_selection import train_test_split","43510bd2":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\nprint(\"x train: \",X_train.shape)\nprint(\"x test: \",X_test.shape)\nprint(\"y train: \",y_train.shape)\nprint(\"y test: \",y_test.shape)","2cadbe34":"from sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_score","981b3dd6":"CV = []\nR2_train = []\nR2_test = []\n\ndef car_pred_model(model,model_name):\n    # Training model\n    model.fit(X_train,y_train)\n            \n    # R2 score of train set\n    y_pred_train = model.predict(X_train)\n    R2_train_model = r2_score(y_train,y_pred_train)\n    R2_train.append(round(R2_train_model,2))\n    \n    # R2 score of test set\n    y_pred_test = model.predict(X_test)\n    R2_test_model = r2_score(y_test,y_pred_test)\n    R2_test.append(round(R2_test_model,2))\n    \n    # R2 mean of train set using Cross validation\n    cross_val = cross_val_score(model ,X_train ,y_train ,cv=5)\n    cv_mean = cross_val.mean()\n    CV.append(round(cv_mean,2))\n    \n    # Printing results\n    print(\"Train R2-score :\",round(R2_train_model,2))\n    print(\"Test R2-score :\",round(R2_test_model,2))\n    print(\"Train CV scores :\",cross_val)\n    print(\"Train CV mean :\",round(cv_mean,2))\n    \n    # Plotting Graphs \n    # Residual Plot of train data\n    fig, ax = plt.subplots(1,2,figsize = (10,4))\n    ax[0].set_title('Residual Plot of Train samples')\n    sns.distplot((y_train-y_pred_train),hist = False,ax = ax[0])\n    ax[0].set_xlabel('y_train - y_pred_train')\n    \n    # Y_test vs Y_train scatter plot\n    ax[1].set_title('y_test vs y_pred_test')\n    ax[1].scatter(x = y_test, y = y_pred_test)\n    ax[1].set_xlabel('y_test')\n    ax[1].set_ylabel('y_pred_test')\n    \n    plt.show()","d8047590":"from sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\ncar_pred_model(lr,\"Linear_regressor.pkl\")","fa6d5716":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Creating Ridge model object\nrg = Ridge()\n# range of alpha \nalpha = np.logspace(-3,3,num=14)\n\n# Creating RandomizedSearchCV to find the best estimator of hyperparameter\nrg_rs = RandomizedSearchCV(estimator = rg, param_distributions = dict(alpha=alpha))","53784a15":"car_pred_model(rg_rs,\"ridge.pkl\")","9473dd30":"from sklearn.linear_model import Lasso\nfrom sklearn.model_selection import RandomizedSearchCV\n\nls = Lasso()\nalpha = np.logspace(-3,3,num=14) # range for alpha\n\nls_rs = RandomizedSearchCV(estimator = ls, param_distributions = dict(alpha=alpha))","dafb11df":"car_pred_model(ls_rs,\"lasso.pkl\")","afaab64e":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\n\nrf = RandomForestRegressor()\n\n# Number of trees in Random forest\nn_estimators=list(range(500,1000,100))\n# Maximum number of levels in a tree\nmax_depth=list(range(4,9,4))\n# Minimum number of samples required to split an internal node\nmin_samples_split=list(range(4,9,2))\n# Minimum number of samples required to be at a leaf node.\nmin_samples_leaf=[1,2,5,7]\n# Number of fearures to be considered at each split\nmax_features=['auto','sqrt']\n\n# Hyperparameters dict\nparam_grid = {\"n_estimators\":n_estimators,\n              \"max_depth\":max_depth,\n              \"min_samples_split\":min_samples_split,\n              \"min_samples_leaf\":min_samples_leaf,\n              \"max_features\":max_features}\n\nrf_rs = RandomizedSearchCV(estimator = rf, param_distributions = param_grid)","1e823f60":"car_pred_model(rf_rs,'random_forest.pkl')","c9334fc5":"print(rf_rs.best_estimator_)","95ec0d6a":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\n\ngb = GradientBoostingRegressor()\n\n# Rate at which correcting is being made\nlearning_rate = [0.001, 0.01, 0.1, 0.2]\n# Number of trees in Gradient boosting\nn_estimators=list(range(500,1000,100))\n# Maximum number of levels in a tree\nmax_depth=list(range(4,9,4))\n# Minimum number of samples required to split an internal node\nmin_samples_split=list(range(4,9,2))\n# Minimum number of samples required to be at a leaf node.\nmin_samples_leaf=[1,2,5,7]\n# Number of fearures to be considered at each split\nmax_features=['auto','sqrt']\n\n# Hyperparameters dict\nparam_grid = {\"learning_rate\":learning_rate,\n              \"n_estimators\":n_estimators,\n              \"max_depth\":max_depth,\n              \"min_samples_split\":min_samples_split,\n              \"min_samples_leaf\":min_samples_leaf,\n              \"max_features\":max_features}\n\ngb_rs = RandomizedSearchCV(estimator = gb, param_distributions = param_grid)","bacfe326":"car_pred_model(gb_rs,\"gradient_boosting.pkl\")","3173e151":"Technique = [\"LinearRegression\",\"Ridge\",\"Lasso\",\"RandomForestRegressor\",\"GradientBoostingRegressor\"]\nresults=pd.DataFrame({'Model': Technique,'R Squared(Train)': R2_train,'R Squared(Test)': R2_test,'CV score mean(Train)': CV})\ndisplay(results)","4f54ac96":"<a id=\"4\"><\/a>\n# 4. Data Preparation","0d3bb851":"Converting categorical columns into integers using 1-hot encoding.","20937238":"Renaming columns for better clarity","fb96d91a":"# Description\n\nThis dataset contains information about used cars listed on www.cardekho.com\nThis data can be used for a lot of purposes such as price prediction to exemplify the use of linear regression in Machine Learning.\nThe columns in the given dataset are as follows:\n\n    name\n    year\n    selling_price\n    km_driven\n    fuel\n    seller_type\n    transmission\n    Owner\n\nFor used motorcycle datasets please go to https:\/\/www.kaggle.com\/nehalbirla\/motorcycle-dataset","864dfc98":"<a id=\"4_a\"><\/a>\n##  a) Creating  dummies for categorical features","9060e463":"#### Thanks for reading !! \n\n\n- Addition to this you can also check my github repository, where i have created an end-to-end ML Project using above dataset and deployed it on cloud.\n \n LinK : https:\/\/github.com\/rppradhan08\/Car_Price_Prediction\n\n- Please do share your feedback.","274a63a9":"<a id=\"5\"><\/a>\n# 5. Model Creation\/Evaluation","1a3438e4":"Checking average selling price of vehicle based on its Seller type and Fuel type","51bd4d4b":"### 2) Ridge","5c8d0018":"<a id='3'><\/a>\n# 3. Exploratory Data Analysis (EDA)","4d4ae9b5":"### 5) Gradient Boosting","8dddc787":"<a id=\"6\"><\/a>\n# Conclusion:\n\n- Present price and resale price are highly correlated, as observed in EDA.\n- Age of the vehicle seems to show negative correlation with selling price.\n- Past_Owners and Kms_Driven are showing very less correlation with selling price.\n- Automatic vehicles fetch higher resale price compared to manual ones.\n- Ensemble techniques like Random Forest and Gradient Boosting produce better results than linear models, however they have more tendency to overfit.","a488b58a":"<b>Inferences:<\/b> Diesel Vehicles fetch higher price compared to petrol & CNG for both sellers.","38711455":"<a id=\"3_a\"><\/a>\n## a) Univariate Analysis","817b1098":"## a) Applying regression models\n- Linear Regression (OLS)\n- Ridge Regression\n- Lasso Regression\n- Random Forest Regression\n- Gradient Boosting regression","4fe5d40b":"**Checking outliiers in Present_Price, Selling_Price and Kms_Driven**","33e3dfe5":"We can check best seletion of hyperparmeters for our model using below command.","5dd51cc4":"Extracting Age of car using Year column","152b40c6":"<b>Inferences:<\/b> Automatic vehicles fetch higher resale price compared to manual ones.","c7c23fd2":"<a id=\"3_b\"><\/a>\n## b) Bivariate\/Multi-Variate Analysis","f4f1f978":"<b>Inferences:<\/b>\n- Present price and resale price are highly correlated, as observed in EDA.\n- Age of the vehicle seems to show negative correlation with selling price.\n- Past_Owners and Kms_Driven seems to show very less correlation with selling price.","fd598854":"# Steps Involved:\n\n\n- [Reading and Understanding the Dataset](#1)\n- [Data Preporcessing](#2)\n- [Exploratory Data Analysis (EDA)](#3)\n    - [Univariate Analysis](#3_a)\n    - [Bivariate\/Multi-Variate Analysis](#3_b)\n- [Data Preparation ](#4)\n    - [Creating dummies for categorical features](#4_a)\n    - [Performing Train-Test split](#4_b)\n- [Model Creation\/Evaluation](#5)\n- [Conclusion](#6)","481427df":"<a id='1'><\/a>\n# 1. Reading and Understanding the Dataset","c4e18904":"<a id='2'><\/a>\n# 2. Data Preprocessing","30fe23cf":"Dropping Car_Name column","93ee9713":"##### Plotting numerical columns","cdff77c5":"##### Plotting Categorical Columns","8df0141a":"### 4) Random Forest","2c221b43":"Checking average selling price of vehicle based on its Seller type and Transmission","9bc37899":"### 3) Lasso","6713c3ff":"### 1) Standard Linear Regression or Ordinary Least Squares","d730f9c8":"<a id=\"4_b\"><\/a>\n## b) Performing Train-Test Split"}}