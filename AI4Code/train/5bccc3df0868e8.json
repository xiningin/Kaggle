{"cell_type":{"a36391c9":"code","614a8815":"code","09b89bdb":"code","c764692f":"code","3f747014":"code","41ddb432":"code","8eee014e":"code","6bb8e969":"code","ed2f7879":"code","54d243a0":"code","fd3d5694":"code","cca5dcb5":"code","cd2149b8":"code","bc14ff7f":"code","2a74d7dd":"code","4ef96e6f":"code","bf61467d":"code","6db95eb3":"code","426aac30":"code","00fc623b":"code","a4f880da":"code","d8bcdba2":"code","5cabc923":"code","058853ce":"code","4e2c676f":"code","8ce843b8":"code","d7777841":"code","a8425a18":"code","7669d0f2":"code","77e83b94":"code","97e9615f":"code","a231ebb2":"code","c47eb314":"code","70eca53c":"code","34c10127":"code","ead0c291":"code","64799785":"code","7af10c12":"code","26ed60e7":"code","1badd0eb":"code","4a1a6cab":"code","20fba48b":"code","98d4afd2":"code","8ce12c94":"code","02750000":"code","0a2184fa":"code","7b7ea6cc":"code","421a64b5":"code","1bc66825":"code","6107d80c":"code","6d033e37":"code","ff07423f":"code","6333afba":"code","55b864de":"code","ae6f90fd":"code","60a79939":"code","05420797":"code","fe2617ca":"code","dfd90cc3":"code","52e3d74c":"code","5375e378":"code","ca0d3df5":"code","bfb23f30":"code","ed37b5d3":"code","3498b2ef":"code","f88b51ce":"code","94764076":"code","c921c7cd":"code","c455bba0":"code","d5eaaa9d":"code","78551941":"code","a2a019bd":"code","4e139a02":"code","dbaacae3":"code","125ace90":"code","49af74c7":"code","e8ef2e52":"code","0f60e2e1":"code","f69bae8f":"code","b72c9f7a":"code","9aecf9c6":"code","1e406f63":"code","20771389":"code","3bcaab69":"code","ab4e1ae4":"code","35e3a66a":"code","f1ad435d":"code","56f9bdee":"code","9a4690dd":"code","9c4cf5be":"code","299d8c5e":"markdown","725c17c9":"markdown","4ab07ee7":"markdown","f8b2c4a0":"markdown","77223926":"markdown","3fc5a638":"markdown","af7cb223":"markdown","44a62b7f":"markdown","99440dfa":"markdown","3ca7a07c":"markdown","d751181d":"markdown","8d51a4b6":"markdown","47b0994a":"markdown","b5e24604":"markdown","c4ed736e":"markdown","4fc10f3a":"markdown","906246b1":"markdown","7c7d1bec":"markdown","ad064c64":"markdown","9a63c5da":"markdown","6ac08daa":"markdown","12bc867e":"markdown","c37cd1e8":"markdown","c2292240":"markdown","234df89d":"markdown","5e74bc30":"markdown","215171f6":"markdown","81492924":"markdown","6861eb7f":"markdown","a847dda7":"markdown","c72006d4":"markdown","fea7eeac":"markdown","9bdb82b8":"markdown","c264e1e5":"markdown","45875e32":"markdown","fdae04b6":"markdown","0bfe7bdc":"markdown","044147f9":"markdown","7494d791":"markdown","849aa973":"markdown","fdbb4b9e":"markdown","79c48cd5":"markdown","c1668d3f":"markdown"},"source":{"a36391c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","614a8815":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn as sn\nfrom matplotlib.patches import Patch\nimport numpy\nimport numpy as np\nimport pandas as pd","09b89bdb":"# Da ich alle Warnungen machgegangen bin, und sie nicht nutzlich sind, schalte ich an der Stelle sie aus. Ansonsten kann dieses Code deaktiviert werden.\nimport warnings\nwarnings.filterwarnings(\"ignore\")","c764692f":"# Laden des Trainingsdatensatzes\ndf_train= pd.read_csv('\/kaggle\/input\/dataanalyticschallenge61\/TrainData.csv', sep=';', encoding='latin-1')\ndf_train.head()","3f747014":"df_train.info() ","41ddb432":"# \u00dcberpr\u00fcfen, ob es im Datensatz Duplikate gibt\ndf_train[df_train['Stammnummer'].duplicated()].count()","8eee014e":"# Deskriptive Kennzahlen von nummerischen Variablen\ndf_train.describe()","6bb8e969":"# Liste der kategorischen Variablen ausgeben lassen\nlist(df_train.select_dtypes(include='object'))","ed2f7879":"# Pr\u00fcfung nach Missings in den Kategorien\nprint(#df_train['Geschlecht'].value_counts(),\n       df_train['Art der Anstellung'].value_counts(),\n      #df_train['Familienstand'].value_counts(),\n       df_train['Schulabschlu\u00df'].value_counts(),\n      #df_train['Ausfall Kredit'].value_counts(),\n      #df_train['Haus'].value_counts(), \n      #df_train['Kredit'].value_counts(),\n       df_train['Kontaktart'].value_counts(),\n       df_train['Ergebnis letzte Kampagne'].value_counts(),)","54d243a0":"# Zuordnung von den F\u00e4llen aus der Kategorie unbekannt zu Arbeitern\ndf_train['Art der Anstellung']=df_train[['Art der Anstellung']].replace(to_replace=r'Unbekannt',\n                                                            value= 'Arbeiter', regex=True)\n#Check der Ergebnisse. Keine Kategorie unbekannt vorhanden.\n#Kategorie Arbeiter hat 212 F\u00e4lle mehr. Perfekt!\ndf_train['Art der Anstellung'].value_counts()","fd3d5694":"# hier werden die F\u00e4lle aus 'Unbekannt' den F\u00e4llen 'Abitur' zugeschrieben\nfor i in range(31480):\n    if df_train['Schulabschlu\u00df'][i]==\"Unbekannt\":\n        df_train['Schulabschlu\u00df'][i] = \"Abitur\"       \n\n#Check: Perfekt!\nprint(df_train['Schulabschlu\u00df'].value_counts())","cca5dcb5":"# Hier werden absolute und prozentuelle H\u00e4ufigkeiten der Kategorien in 'Kontaktart' ausgegeben.\nprint(df_train['Kontaktart'].value_counts(), '\\n', df_train['Kontaktart'].value_counts(normalize=True)*100)\n","cd2149b8":"# Berechnung von absoluter Anzahl (20%) von F\u00e4llen, die Festnetz zugeschrieben werden sollen.\n20*9079\/100","bc14ff7f":"# hier sollten aus 'Unbekannt' so viele F\u00e4lle 'Handy' zugeschrieben, dass 1815 F\u00e4lle in 'Unbekannt' \u00fcbrig bleiben.\nfor i in range(25510):\n    if df_train['Kontaktart'][i]==\"Unbekannt\":\n        df_train['Kontaktart'][i] = \"Handy\"       \n\n#Check: Perfekt!\nprint(df_train['Kontaktart'].value_counts())","2a74d7dd":"# hier sollten die restliche 1815 an 'Festnetz' gehen.\nfor i in range(31480):\n    if df_train['Kontaktart'][i]==\"Unbekannt\":\n        df_train['Kontaktart'][i] = \"Festnetz\"       \n\n#Check: Perfekt!\nprint(df_train['Kontaktart'].value_counts())","4ef96e6f":"df_train['Ergebnis letzte Kampagne'].value_counts()","bf61467d":"# wie oben erw\u00e4hnt, wird hier missings mit dem Wert '0' ersetzt\ndf_train['Tage seit letzter Kampagne'].fillna(value=0, inplace=True)","6db95eb3":"# Wie oben beschlossen werden am Ende dieses Abschnitts die unn\u00f6tigen Variablen entfernt\ndf_train=df_train.drop('Ergebnis letzte Kampagne', axis=1)\ndf_train=df_train.drop('Tag', axis=1)\ndf_train=df_train.drop('Anruf-ID', axis=1)","426aac30":"# es sollten keine Missings mehr im Trainingsdatensatz vorzufinden sein\ndf_train.info()","00fc623b":"df_train.head()","a4f880da":"# Hier wird berechnet, wie hoch  die Anteile des Abschlusses \u00fcber die Monate waren. \n# Damit wird eine neue numerische Variable generiert, die kategorischen Variablen 'Monat' ersetzen wird. \n# Dies wird Datahandling um einiges leichter machen. Wird zus\u00e4tzliche Dummy-Variable f\u00fcr jeden Monat vermieden.\nja=df_train['Zielvariable']=='ja'\nabgeschlossen= df_train[ja]\nabgeschlossen.head()\ndf_train['Abschluss nach Monat']=abgeschlossen['Monat'].value_counts()\nabgeschlossen['Monat'].value_counts()","d8bcdba2":"# Generieren neuer Variable 'Abschluss nach Monat'\n\nfor i in range(31480):\n    if df_train['Monat'][i]==\"may\":\n        df_train['Abschluss nach Monat'][i] = 639\n    elif df_train['Monat'][i]==\"aug\":\n        df_train['Abschluss nach Monat'][i] = 457\n    elif df_train['Monat'][i]==\"jul\":\n        df_train['Abschluss nach Monat'][i] = 451\n    elif df_train['Monat'][i]==\"jun\":\n        df_train['Abschluss nach Monat'][i] = 400\n    elif df_train['Monat'][i]==\"apr\":\n        df_train['Abschluss nach Monat'][i] = 389\n    elif df_train['Monat'][i]==\"feb\":\n        df_train['Abschluss nach Monat'][i] = 324\n    elif df_train['Monat'][i]==\"nov\":\n        df_train['Abschluss nach Monat'][i] = 284\n    elif df_train['Monat'][i]==\"oct\":\n        df_train['Abschluss nach Monat'][i] = 224\n    elif df_train['Monat'][i]==\"sep\":\n        df_train['Abschluss nach Monat'][i] = 190\n    elif df_train['Monat'][i]==\"mar\":\n        df_train['Abschluss nach Monat'][i] = 184\n    elif df_train['Monat'][i]==\"jan\":\n        df_train['Abschluss nach Monat'][i] = 93\n    elif df_train['Monat'][i]==\"dec\":\n        df_train['Abschluss nach Monat'][i] = 65\n#Check\nprint(df_train['Abschluss nach Monat'])","5cabc923":"# Datentyp 'float64' in 'int64' umwandeln.\ndf_train['Abschluss nach Monat']= df_train['Abschluss nach Monat'].astype(int)","058853ce":"# Illustration der Unterschiede \u00fcber Monate\nfig, ax = plt.subplots(figsize=(10,6))\n\nmon =['may', 'aug','jul', 'jun',\n      'apr','feb','nov','oct',\n      'sep','mar', 'jan', 'dec']\nsns.barplot(x=\"Monat\", y=\"Abschluss nach Monat\", data=df_train, order= mon, alpha=0.7, ax=ax)\nplt.close(2);","4e2c676f":"# Hier wird 'Kontostand' nach den Kategorien von 'Art der Anstellung' gruppiert und je Kategorie aufsummiert\n# Als Ergebnis erhalten wir besseren \u00dcberblick auf die Kategorien, denn ad hoc w\u00fcrde man z. B. die 'Arbeiter' nicht in h\u00f6here Einkommenskategorien einordnen\ndf_train['Kontostand'].groupby(df_train['Art der Anstellung']).aggregate(np.sum).sort_values()","8ce843b8":"liste=['NaN'] *31480\ndf_train['Erwerbsniveau']=liste\n\n\nfor i in range(31480):\n    if df_train['Art der Anstellung'][i]== 'Student':\n        df_train['Erwerbsniveau'][i] = 'niedrige'\n    elif df_train['Art der Anstellung'][i]== 'Hausfrau':\n        df_train['Erwerbsniveau'][i] = 'niedrige'\n    elif df_train['Art der Anstellung'][i]== 'Arbeitslos':\n        df_train['Erwerbsniveau'][i] = 'niedrige'\n    elif df_train['Art der Anstellung'][i]== 'Gr\u00fcnder':\n        df_train['Erwerbsniveau'][i] = 'niedrige'\n    elif df_train['Art der Anstellung'][i]== 'Selbst\u00e4ndig':\n        df_train['Erwerbsniveau'][i] = 'niedrige'\n    elif df_train['Art der Anstellung'][i]== 'Rentner':\n        df_train['Erwerbsniveau'][i] = 'mittlere'\n    elif df_train['Art der Anstellung'][i]== 'Dienstleistung':\n        df_train['Erwerbsniveau'][i] = 'mittlere'\n    elif df_train['Art der Anstellung'][i]== 'Verwaltung':\n        df_train['Erwerbsniveau'][i] = 'mittlere'\n    elif df_train['Art der Anstellung'][i]=='Arbeiter':\n        df_train['Erwerbsniveau'][i] = 'h\u00f6here'\n    elif df_train['Art der Anstellung'][i]=='Technischer Beruf':\n        df_train['Erwerbsniveau'][i] = 'h\u00f6here'\n    elif df_train['Art der Anstellung'][i]== 'Management':\n        df_train['Erwerbsniveau'][i] = 'h\u00f6here'\n    \n#Check: Perfekt\nprint(df_train['Erwerbsniveau'].value_counts())","d7777841":"# Da aus den Variablen 'Art der Anstellung' und 'Monat' neue Variablen generiert wurden, er\u00fcbrigen sich sie an dieser Stelle\ndf_train=df_train.drop('Art der Anstellung', axis=1)\ndf_train=df_train.drop('Monat', axis=1)","a8425a18":"# Check\ndf_train.info()","7669d0f2":"fig, ax = plt.subplots(figsize=(10,6))\n\nsns.countplot(\"Zielvariable\", data=df_train, alpha=0.7, ax=ax)\nax.set_title('Verteilung von Zielvariable')\nplt.close(2);\n\n#prozentwerte\np=df_train[df_train[\"Zielvariable\"] == 'ja'].count() \/ df_train[\"Zielvariable\"].count() *100\nprint(\"Prozentueller Anteil von abgeschlossenen Marketingkampagnen:\", \n      p.iloc[0])\np1=df_train[df_train[\"Zielvariable\"] == 'nein'].count() \/ df_train[\"Zielvariable\"].count() *100\nprint(\"Prozentueller Anteil von nichtabgeschlossenen Marketingkampagnen:\", \n      p1.iloc[0])\n   ","77e83b94":"# Verteilung der nummerischen Variablen\ndf_train.loc[:,['Alter','Dauer', 'Kontostand', \n                'Anzahl der Ansprachen', 'Anzahl Kontakte letzte Kampagne']].hist(bins=50, figsize=(20,15));","97e9615f":"# Korrelation nummerischer .hist(bins=50, figsize=(20,15))ariablen\ncorr_matrix = df_train.loc[:,['Alter','Dauer', 'Kontostand', 'Anzahl der Ansprachen',\n                              'Anzahl Kontakte letzte Kampagne']].corr()\n#print(corr_matrix)\nsn.heatmap(corr_matrix, annot=True);","a231ebb2":"fig, ax = plt.subplots(2,2)\n\nsns.countplot(x=\"Geschlecht\", hue=\"Zielvariable\", data=df_train,  alpha=0.8, ax=ax[0,0]).set_title(\"Geschlecht\")\nplt.close(2)\n\nsns.countplot(x=\"Erwerbsniveau\", hue=\"Zielvariable\", data=df_train, alpha=0.8, ax=ax[0,1]).set_title(\"Erwerbsniveau\")\nplt.close(2)\n\nsns.countplot(x=\"Familienstand\", hue=\"Zielvariable\", data=df_train, alpha=0.8, ax=ax[1,0])\nplt.close(2)\n\nsns.countplot(x=\"Schulabschlu\u00df\", hue=\"Zielvariable\", data=df_train, alpha=0.8, ax=ax[1,1])\nplt.close(2);\n \n\n#print percentages of passengers with none, one, two, three or five children or parents that survive\nprint(\"Prozentueller Anteil von  Frauen, die abgeschlossen haben:\", \n      df_train[\"Zielvariable\"][df_train[\"Geschlecht\"] == 'w'].value_counts(normalize = True)[1]*100)\n\nprint(\"Prozentueller Anteil von M\u00e4nner, die abgeschlossen haben:\", \n      df_train[\"Zielvariable\"][df_train[\"Geschlecht\"] == 'm'].value_counts(normalize = True)[1]*100)","c47eb314":"# Entfernen von 'Geschlecht'\ndf_train=df_train.drop('Geschlecht', axis=1)","70eca53c":"fig, ax = plt.subplots(2,2)\n\nsns.countplot(x=\"Ausfall Kredit\", hue=\"Zielvariable\", data=df_train,  alpha=0.8, ax=ax[0,0]).set_title(\"Ausfall Kredit\")\nplt.close(2)\n\nsns.countplot(x=\"Haus\", hue=\"Zielvariable\", data=df_train,  alpha=0.8, ax=ax[0,1]).set_title(\"Haus\")\nplt.close(2)\n\nsns.countplot(x=\"Kredit\", hue=\"Zielvariable\", data=df_train,  alpha=0.8, ax=ax[1,0])\nplt.close(2)\n\nsns.countplot(x=\"Kontaktart\", hue=\"Zielvariable\", data=df_train,  alpha=0.8, ax=ax[1,1])\nplt.close(2)\n","34c10127":"fig, ax = plt.subplots(figsize=(10,6))\n\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='ja'][\"Dauer\"], shade=True, \n            color=\"blue\", label=\"abgeschlossen\", alpha=0.5, ax=ax)\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='nein'][\"Dauer\"], shade=True, \n             color=\"green\", label=\"nicht abgeschlossen\", alpha=0.4, ax=ax)\n\nax2 = plt.axes([0.35, 0.42, .4, .3], facecolor='w')\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='ja'][\"Dauer\"], shade=True, \n            color=\"blue\", label=\"abgeschlossen\", alpha=0.5, ax=ax2)\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='nein'][\"Dauer\"], shade=True, \n             color=\"green\", label=\"nicht abgeschlossen\", alpha=0.4, ax=ax2)\nax2.set_xlim([-1, 1750])\nax2.set_title('Zoom');","ead0c291":"fig, ax = plt.subplots(figsize=(10,6))\n\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='ja'][\"Alter\"], shade=True, \n            color=\"blue\", label=\"abgeschlossen\", alpha=0.5, ax=ax)\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='nein'][\"Alter\"], shade=True, \n             color=\"green\", label=\"nicht abgeschlossen\", alpha=0.4, ax=ax)\n\nax2 = plt.axes([0.59, 0.43, .3, .3], facecolor='w')\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='ja'][\"Alter\"], shade=True, \n            color=\"blue\", label=\"abgeschlossen\", alpha=0.5, ax=ax2)\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='nein'][\"Alter\"], shade=True, \n             color=\"green\", label=\"nicht abgeschlossen\", alpha=0.4, ax=ax2)\nax2.set_xlim([15,60])\nax2.set_title('Zoom');","64799785":"fig, ax = plt.subplots(figsize=(10,6))\n\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='ja'][\"Kontostand\"], shade=True, \n            color=\"blue\", label=\"abgeschlossen\", alpha=0.5, ax=ax)\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='nein'][\"Kontostand\"], shade=True, \n             color=\"green\", label=\"nicht abgeschlossen\", alpha=0.4, ax=ax)\n\nax2 = plt.axes([0.34, 0.37, .5, .4], facecolor='w')\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='ja'][\"Kontostand\"], shade=True, \n            color=\"blue\", label=\"abgeschlossen\", alpha=0.5, ax=ax2)\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='nein'][\"Kontostand\"], shade=True, \n             color=\"green\", label=\"nicht abgeschlossen\", alpha=0.4, ax=ax2)\nax2.set_xlim([-7000,10000])\nax2.set_title('Zoom');","7af10c12":"fig, ax = plt.subplots(figsize=(10,6))\n\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='ja'][\"Anzahl der Ansprachen\"], shade=True, \n            color=\"blue\", label=\"abgeschlossen\", alpha=0.5, ax=ax)\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='nein'][\"Anzahl der Ansprachen\"], shade=True, \n             color=\"green\", label=\"nicht abgeschlossen\", alpha=0.4, ax=ax)\n\nax2 = plt.axes([0.3, 0.4, .4, .3], facecolor='w')\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='ja'][\"Anzahl der Ansprachen\"], shade=True, \n            color=\"blue\", label=\"abgeschlossen\", alpha=0.5, ax=ax2)\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='nein'][\"Anzahl der Ansprachen\"], shade=True, \n             color=\"green\", label=\"nicht abgeschlossen\", alpha=0.4, ax=ax2)\nax2.set_xlim([0,10])\nax2.set_title('Zoom');","26ed60e7":"fig, ax = plt.subplots(figsize=(10,6))\n\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='ja'][\"Anzahl Kontakte letzte Kampagne\"], shade=True, \n            color=\"blue\", label=\"abgeschlossen\", alpha=0.5, ax=ax)\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='nein'][\"Anzahl Kontakte letzte Kampagne\"], shade=True, \n             color=\"green\", label=\"nicht abgeschlossen\", alpha=0.4, ax=ax)\n\nax2 = plt.axes([0.3, 0.36, .4, .4], facecolor='w')\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='ja'][\"Anzahl Kontakte letzte Kampagne\"], shade=True, \n            color=\"blue\", label=\"abgeschlossen\", alpha=0.5, ax=ax2)\nsns.kdeplot(df_train[df_train[\"Zielvariable\"]=='nein'][\"Anzahl Kontakte letzte Kampagne\"], shade=True, \n             color=\"green\", label=\"nicht abgeschlossen\", alpha=0.4, ax=ax2)\nax2.set_xlim([-0.9,12])\nax2.set_title('Zoom');","1badd0eb":"df_train.head()","4a1a6cab":"# Zielvariable wird 0\/1 kodiert\nd = {'nein': 0, 'ja': 1}\ndf_train['Zielvariable'] = df_train['Zielvariable'].map(d)","20fba48b":"# trennen von abh\u00e4ngiger (Ziel)variable von den unabh\u00e4ngigen Variablen und entfernen von 'Stammnummer'\nX= df_train.drop(['Zielvariable', 'Stammnummer'], axis=1)\ny_train= df_train['Zielvariable']\n# Check\ny_train.value_counts()","98d4afd2":"# \u00dcberpr\u00fcfen, ob alles geklappt hat.\nX.head()","8ce12c94":"#notwendige Bibliotheken f\u00fcr Datentransformation laden\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import OneHotEncoder","02750000":"# Dieser Funktion wird eine Liste der gew\u00fcnschten Variablennammen \u00fcbergeben und \n# diese wird nur die Variablen aus dem Datensatz aufnehmen,\n# deren Namen in der Liste vorkommt.\n\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self,X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names].values","0a2184fa":"# Definieren der Namenslisten von Variablen, die dem DataFrameSelector \u00fcbergeben werden soll.\nnum_X=list(X.select_dtypes(include='int64'))\ncat_X=list(X.select_dtypes(include='object'))\nprint(\"\",\"Numerische:\", num_X, len(num_X), \"\\n\",\n      \"Kategorische:\", cat_X, len(cat_X),)","7b7ea6cc":"# num_pip ist eine Pipeline, die nummerischen Daten transformiert.\nnum_pip = Pipeline([\n    ('selector', DataFrameSelector(num_X)),\n    ('pt', PowerTransformer(method= 'yeo-johnson', standardize=True))\n])\n\n# cat_pip ist eine Pipeline, die kategorischen Daten transformiert.\ncat_pip = Pipeline([\n    ('selector', DataFrameSelector(cat_X)),\n    ('ohe', OneHotEncoder(sparse=False))\n])\n\n# voll_pip ist eine Hauptpipeline, die num_pip und cat_pip enth\u00e4lt.\n# Dieser wird gesamtes Trainingsdatensatz \u00fcbergeben und daraus kommt,\n# die transformierten Daten, die bereit f\u00fcr Machine Learning Algorithmen sind. \nvoll_pip= FeatureUnion(transformer_list=[\n    ('num_pip_train', num_pip),\n    ('cat_pip_train', cat_pip)\n])","421a64b5":"# Transformieren des Trainingsdatensatzes\nX_train= voll_pip.fit_transform(X)\nX_train.shape","1bc66825":"# Einbinden des Testdatensatzes.\ndf_test= pd.read_csv('\/kaggle\/input\/dataanalyticschallenge61\/TestData.csv', sep=';', encoding='latin-1')\ndf_test.head()","6107d80c":"# \u00dcberblick verschaffen.\ndf_test.info()","6d033e37":"print(#df_test['Geschlecht'].value_counts(),\n       df_test['Art der Anstellung'].value_counts(),\n      #df_test['Familienstand'].value_counts(),\n       df_test['Schulabschlu\u00df'].value_counts(),\n      #df_test['Ausfall Kredit'].value_counts(),\n      #df_test['Haus'].value_counts(), \n      #df_test['Kredit'].value_counts(),\n       df_test['Kontaktart'].value_counts())","ff07423f":"# Bei dieser Variablen im Gegensatz zu Trainingsdatensatz ist die meistvertretene Kategorie 'Management'\ndf_test['Art der Anstellung']=df_test[['Art der Anstellung']].replace(to_replace=r'Unbekannt',\n                                                            value= 'Management', regex=True)\n#Check der Ergebnisse. Keine Kategorie unbekannt vorhanden.\n#Kategorie Management hat 76 F\u00e4lle mehr. Perfekt!\ndf_test['Art der Anstellung'].value_counts()","6333afba":"# Hier wird eine leere Variable 'Erwerbsniveau' in df_test generiert.\nliste=['NaN'] *13731\ndf_test['Erwerbsniveau']=liste\n\n# Leere 'Erwerbsniveau' wird in drei Kategorien zusammengefasst.\nfor i in range(13731):\n    if df_test['Art der Anstellung'][i]== 'Student':\n        df_test['Erwerbsniveau'][i] = 'niedrige'\n    elif df_test['Art der Anstellung'][i]== 'Hausfrau':\n        df_test['Erwerbsniveau'][i] = 'niedrige'\n    elif df_test['Art der Anstellung'][i]== 'Arbeitslos':\n        df_test['Erwerbsniveau'][i] = 'niedrige'\n    elif df_test['Art der Anstellung'][i]== 'Gr\u00fcnder':\n        df_test['Erwerbsniveau'][i] = 'niedrige'\n    elif df_test['Art der Anstellung'][i]== 'Selbst\u00e4ndig':\n        df_test['Erwerbsniveau'][i] = 'niedrige'\n    elif df_test['Art der Anstellung'][i]== 'Rentner':\n        df_test['Erwerbsniveau'][i] = 'mittlere'\n    elif df_test['Art der Anstellung'][i]== 'Dienstleistung':\n        df_test['Erwerbsniveau'][i] = 'mittlere'\n    elif df_test['Art der Anstellung'][i]== 'Verwaltung':\n        df_test['Erwerbsniveau'][i] = 'mittlere'\n    elif df_test['Art der Anstellung'][i]=='Arbeiter':\n        df_test['Erwerbsniveau'][i] = 'h\u00f6here'\n    elif df_test['Art der Anstellung'][i]=='Technischer Beruf':\n        df_test['Erwerbsniveau'][i] = 'h\u00f6here'\n    elif df_test['Art der Anstellung'][i]== 'Management':\n        df_test['Erwerbsniveau'][i] = 'h\u00f6here'\n    \n#Check: Perfekt\nprint(df_test['Erwerbsniveau'].value_counts())","55b864de":"# Generieren leere Variable 'Abschluss nach Monat'\nliste=['NaN'] *13731\ndf_test['Abschluss nach Monat']=liste\n\n# Leere 'Abschluss nach Monat' wird mit aufsummierten H\u00e4ufigkeiten von 'Abgeschlossen' f\u00fcr jeweiligen Monat bef\u00fcllt.\nfor i in range(13731):\n    if df_test['Monat'][i]==\"may\":\n        df_test['Abschluss nach Monat'][i] = 639\n    elif df_test['Monat'][i]==\"aug\":\n        df_test['Abschluss nach Monat'][i] = 457\n    elif df_test['Monat'][i]==\"jul\":\n        df_test['Abschluss nach Monat'][i] = 451\n    elif df_test['Monat'][i]==\"jun\":\n        df_test['Abschluss nach Monat'][i] = 400\n    elif df_test['Monat'][i]==\"apr\":\n        df_test['Abschluss nach Monat'][i] = 389\n    elif df_test['Monat'][i]==\"feb\":\n        df_test['Abschluss nach Monat'][i] = 324\n    elif df_test['Monat'][i]==\"nov\":\n        df_test['Abschluss nach Monat'][i] = 284\n    elif df_test['Monat'][i]==\"oct\":\n        df_test['Abschluss nach Monat'][i] = 224\n    elif df_test['Monat'][i]==\"sep\":\n        df_test['Abschluss nach Monat'][i] = 190\n    elif df_test['Monat'][i]==\"mar\":\n        df_test['Abschluss nach Monat'][i] = 184\n    elif df_test['Monat'][i]==\"jan\":\n        df_test['Abschluss nach Monat'][i] = 93\n    elif df_test['Monat'][i]==\"dec\":\n        df_test['Abschluss nach Monat'][i] = 65\n\n#Check: Perfekt!\nprint(df_test['Abschluss nach Monat'])","ae6f90fd":"# Datentyp von 'Abschluss nach Monat' wird in 'int64' umgewandelt\ndf_test['Abschluss nach Monat']=df_test['Abschluss nach Monat'].astype(int)","60a79939":"# mit dieser Schleife werden die F\u00e4lle von 'Unbekannt' der Kategorie 'Abitur' zugeschrieben.\nfor i in range(13731):\n    if df_test['Schulabschlu\u00df'][i]==\"Unbekannt\":\n        df_test['Schulabschlu\u00df'][i] = \"Abitur\"       \n\n#Check: Perfekt!\nprint(df_test['Schulabschlu\u00df'].value_counts())","05420797":"# Hier werden absolute und prozentuelle H\u00e4ufigkeiten der Kategorien in 'Kontaktart' ausgegeben.\nprint(df_test['Kontaktart'].value_counts(), '\\n', df_test['Kontaktart'].value_counts(normalize=True)*100)","fe2617ca":"# Berechnung von absoluter Anzahl von F\u00e4llen, die Festnetz zugeschrieben werden sollen\n20*3941\/100","dfd90cc3":"# nach dieser Schleife sollten 1815 F\u00e4lle bei der Kategorie 'Unbekannt' \u00fcbrig bleiben\nfor i in range(10900):\n    if df_test['Kontaktart'][i]==\"Unbekannt\":\n        df_test['Kontaktart'][i] = \"Handy\"       \n\n#Check: 'Unbekannt' sollte also 788 F\u00e4lle aufweisen. Perfekt!\nprint(df_test['Kontaktart'].value_counts())","52e3d74c":"# nach dieser Schleife sollten 1815 F\u00e4lle bei der Kategorie 'Unbekannt' \u00fcbrig bleiben\nfor i in range(13731):\n    if df_test['Kontaktart'][i]==\"Unbekannt\":\n        df_test['Kontaktart'][i] = \"Festnetz\"       \n\n#Check: Perfekt!\nprint(df_test['Kontaktart'].value_counts())","5375e378":"#Entfernen von den unnotigen Variablen\ndf_test=df_test.drop('Ergebnis letzte Kampagne', axis=1)\ndf_test=df_test.drop('Art der Anstellung', axis=1)\ndf_test=df_test.drop('Geschlecht', axis=1)\ndf_test=df_test.drop('Tag', axis=1)\ndf_test=df_test.drop('Monat', axis=1)\ndf_test=df_test.drop('Anruf-ID', axis=1)\ndf_test=df_test.drop('Zielvariable', axis=1)","ca0d3df5":"# Check\ndf_test.info()","bfb23f30":"#Entfernen erstmal von Stammnummer, da sie nichts inhaltliches beitragen, sie werden aber ganz am Ende mit gesch\u00e4tzten Wahrscheinlichkeiten kombiniert\nX_test= df_test.drop('Stammnummer', axis=1)\nX_test.head()","ed37b5d3":"# Erstellen der Listen von Variablennamen f\u00fcr DataFrameSelector\nnum_X_test=list(X_test.select_dtypes(include='int64'))\ncat_X_test=list(X_test.select_dtypes(include='object'))\nprint(\"\",\"Numerische:\", num_X_test, len(num_X_test), \"\\n\",\n      \"Kategorische:\", cat_X_test, len(cat_X_test),)","3498b2ef":"# num_pip ist eine Pipeline, die nummerischen Daten transformiert.\nnum_pip_test = Pipeline([\n    ('selector', DataFrameSelector(num_X_test)),\n    ('pt', PowerTransformer(method= 'yeo-johnson', standardize=True))\n])\n\n# cat_pip ist eine Pipeline, die kategorischen Daten transformiert.\ncat_pip_test = Pipeline([\n    ('selector', DataFrameSelector(cat_X_test)),\n    ('ohe', OneHotEncoder(sparse=False))\n])\n\n\n# voll_pip ist eine Hauptpipeline, die num_pip und cat_pip enth\u00e4lt.\n# Dieser wird gesamtes Trainingsdatensatz \u00fcbergeben und daraus kommt,\n# die transformierten Daten, die bereit f\u00fcr Machine Learning Algorithmen sind. \nvolle_pipeline_test= FeatureUnion(transformer_list=[\n    ('num_pipeline_test', num_pip_test),\n    ('cat_pipeline_test', cat_pip_test),\n])","f88b51ce":"# Transformieren des Testdatensatzes\nX_test= volle_pipeline_test.fit_transform(X_test)\nX_test.shape","94764076":"# Aufbereitete Trainings- und Testdatens\u00e4tze\nprint(\"\", X_train.shape, '\\n',\n      X_test.shape)","c921c7cd":"# Einbinden notwendiger Bibliotheken.\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom statistics import mean ","c455bba0":"from sklearn.linear_model import LogisticRegression\n\n# Logistische Regression mit Solver= lbfgs\nlr_lbfgs = LogisticRegression(random_state = 0, solver= 'lbfgs')\n# Berechnen von Wahrscheinlichkeiten \ny_prob_lbfgs=cross_val_predict(lr_lbfgs, X_train, y_train, cv=5, method=\"predict_proba\")\n# Scores berechnen mit 5 fache Validierung\ny_score_lbfgs=cross_val_score(lr_lbfgs, X_train, y_train, cv=5, scoring='roc_auc',)\n# Speichern der Wahrscheinlichkeiten f\u00fcr 'Abgeschlossen' also f\u00fcr 1\ny_prob_lbfgs=y_prob_lbfgs[:,1]\nfpr_lbfgs, tpr_lbfgs, thresholds = roc_curve(y_train, y_prob_lbfgs)\n# Scores Mittelwert ausgeben lassen\nprint(\"Mittelwert von Scores\",\n     mean(y_score_lbfgs))","d5eaaa9d":"# Logistische Regression mit Solver= newton-cg\nlr_newton = LogisticRegression(random_state = 0, solver= 'newton-cg')\ny_prob_newton=cross_val_predict(lr_newton, X_train, y_train, cv=5, method=\"predict_proba\")\ny_score_newton=cross_val_score(lr_newton, X_train, y_train, cv=5, scoring='roc_auc',)\ny_prob_newton=y_prob_newton[:,1]\nfpr_newton, tpr_newton, thresholds = roc_curve(y_train, y_prob_newton)\nprint(\"Mittelwert von Scores\",\n      mean(y_score_newton))","78551941":"# Logistische Regression mit Solver= saga\nlr_saga = LogisticRegression(random_state = 0, solver= 'saga')\ny_prob_saga=cross_val_predict(lr_saga, X_train, y_train, cv=5, method=\"predict_proba\")\n# Scores berechnen mit 5 fache Validierung\ny_score_saga=cross_val_score(lr_saga, X_train, y_train, cv=5, scoring='roc_auc',)\ny_prob_saga=y_prob_saga[:,1]\nfpr_saga, tpr_saga, thresholds = roc_curve(y_train, y_prob_saga)\n# 5 Scores ausgeben lassen\nprint(\"Mittelwert von Scores\",\n      mean(y_score_saga))","a2a019bd":"\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0,1], [0,1], '--', color= 'red', label= \"Null-Modell\")\n    plt.axis([0,1, 0,1])\n    plt.xlabel('Anteil falsche Positiven')\n    plt.ylabel('Anteil richtige Positiven')","4e139a02":"# Vergleich der Logit-Modelle\nplt.plot(fpr_newton, tpr_newton, \"-\", color=\"green\", label= \"Solver= newton-cg\")\nplt.plot(fpr_saga, tpr_saga, \"-\", color=\"orange\", label= \"Solver= saga\")\nplot_roc_curve(fpr_lbfgs, tpr_lbfgs, \"Solver= lbfgs\")\nplt.title(\"Logistische Regressionen mit diversen Solvern\")\nplt.legend(loc=\"lower right\")\nplt.show();","dbaacae3":"# Mittelwerte von roc_auc-scores\nprint(\"\", \"Mittelwerte von 5-fach validierte roc_auc_scores:\", \"\\n\",\n      \"lbfgs\",\"\", mean(y_score_lbfgs), \"\\n\",\n      \"newton\", mean(y_score_newton), \"\\n\",\n      \"saga\", \" \",mean(y_score_saga))","125ace90":"from sklearn.tree import DecisionTreeClassifier\n\n# Entscheidungsb\u00e4ume mit default Parametern\ndt = DecisionTreeClassifier(random_state = 0)\ny_proba_dt=cross_val_predict(dt, X_train, y_train, cv=5, method=\"predict_proba\")\ny_score_dt=cross_val_score(dt, X_train, y_train, cv=5) \ny_proba_dt= y_proba_dt[:,1]\nfpr_dt, tpr_dt, thresholds = roc_curve(y_train, y_proba_dt)\nprint(\"Mittelwert von Scores\",\n      mean(y_score_dt))","49af74c7":"# Entscheidungsb\u00e4ume mit mit Criterion gini und max_depth= 7\ndt_gini = DecisionTreeClassifier(random_state = 0, criterion=\"gini\", max_depth= 7)\ny_proba_gini=cross_val_predict(dt_gini, X_train, y_train, cv=5, method=\"predict_proba\")\ny_score_gini=cross_val_score(dt_gini, X_train, y_train, cv=5) \ny_proba_gini= y_proba_gini[:,1]\nfpr_dt_gini, tpr_dt_gini, thresholds = roc_curve(y_train, y_proba_gini)\nprint(\"Mittelwert von Scores\",\n      mean(y_score_gini))","e8ef2e52":"# Entscheidungsb\u00e4ume mit Criterion entropy und max_depth= 7\ndt_entr = DecisionTreeClassifier(random_state = 0, criterion=\"entropy\", max_depth=7)\ny_proba_entr=cross_val_predict(dt_entr, X_train, y_train, cv=5, method=\"predict_proba\")\ny_score_entr=cross_val_score(dt_entr, X_train, y_train, cv=5) \ny_proba_entr=y_proba_entr[:,1]\nfpr_dt_entr, tpr_dt_entr, thresholds = roc_curve(y_train, y_proba_entr)\nprint(\"Mittelwert von Scores\",\n      mean(y_score_entr))","0f60e2e1":"plt.plot(fpr_dt_entr, tpr_dt_entr, \"-.\", color=\"green\", label= \"Criterion= Entropy, max=7\")\nplt.plot(fpr_dt, tpr_dt, \"-\", color=\"orange\", label= \"Criterion= Gini\")\nplot_roc_curve(fpr_dt_gini, tpr_dt_gini, \"Criterion= Gini, max=7\")\nplt.title(\"Entscheidungsb\u00e4ume \\n mit diversen Criterion und max_depth\")\nplt.legend(loc=\"lower right\")\nplt.show();","f69bae8f":"# Mittelwerte von roc_auc-scores\nprint(\"\", \"Mittelwerte von 5-fach validierte roc_auc_scores:\", \"\\n\",\n      \"gini\",\"           \", mean(y_score_dt), \"\\n\",\n      \"gini, depth=7\", \"  \",mean(y_score_gini), \"\\n\",\n      \"entropy, depth=7\", mean(y_score_entr))","b72c9f7a":"from sklearn.ensemble import RandomForestClassifier\n\n# Random forest mit default Parametern\nrf_gini = RandomForestClassifier(random_state = 0, criterion=\"gini\") \ny_proba_rf_gini=cross_val_predict(rf_gini, X_train, y_train, cv=5, method=\"predict_proba\")\ny_score_rf_gini=cross_val_score(rf_gini, X_train, y_train, cv=5) \ny_proba_rf_gini=y_proba_rf_gini[:,1]\nfpr_rf_gini, tpr_rf_gini, thresholds = roc_curve(y_train, y_proba_rf_gini)\nprint(\"Mittelwert von Scores\",\n      mean(y_score_rf_gini))","9aecf9c6":"# Random forest mit Criterion gini und max_depth= 7\nrf_depth15 = RandomForestClassifier(random_state = 0, criterion=\"gini\", max_depth= 15) \ny_proba_rf_depth15=cross_val_predict(rf_depth15, X_train, y_train, cv=5, method=\"predict_proba\")\ny_score_rf_depth15=cross_val_score(rf_depth15, X_train, y_train, cv=5) \ny_proba_rf_depth15=y_proba_rf_depth15[:,1]\nfpr_rf_depth15, tpr_rf_depth15, thresholds = roc_curve(y_train, y_proba_rf_depth15)\nprint(\"Mittelwert von Scores\",\n      mean(y_score_rf_depth15))","1e406f63":"# Random forest mit Criterion entropy und max_depth= 7\nrf_entr = RandomForestClassifier(random_state = 0,criterion=\"entropy\", max_depth= 15) \ny_proba_rf_entr=cross_val_predict(rf_entr, X_train, y_train, cv=5, method=\"predict_proba\")\ny_score_rf_entr=cross_val_score(rf_entr, X_train, y_train, cv=5) \ny_proba_rf_entr=y_proba_rf_entr[:,1]\nfpr_rf_entr, tpr_rf_entr, thresholds = roc_curve(y_train, y_proba_rf_entr)\nprint(\"Mittelwert von Scores\",\n      mean(y_score_rf_entr))","20771389":"plt.plot(fpr_rf_depth15, tpr_rf_depth15, \"-\", color=\"orange\", label= \"Criterion= Gini\")\nplt.plot(fpr_rf_entr, tpr_rf_entr, \"-.\", color=\"green\", label= \"Criterion= Entropy, max_depth=7\")\nplot_roc_curve(fpr_rf_depth15, tpr_rf_depth15, \"Criterion= Gini, max_depth=15\")\nplt.title(\"Random Forest Modelle \\n mit diversen Criterion und max_depth\")\nplt.legend(loc=\"lower right\")\nplt.show();","3bcaab69":"# Mittelwerte von roc_auc-scores\nprint(\"\", \"Mittelwerte von 5-fach validierte roc_auc_scores:\", \"\\n\",\n      \"gini\",\"            \", mean(y_score_rf_gini), \"\\n\",\n      \"gini, depth=15\", \"  \",mean(y_score_rf_depth15), \"\\n\",\n      \"entropy, depth=15\", mean(y_score_rf_entr))","ab4e1ae4":"# Hier werden die drei beibehaltenen Modelle (Logistische Regression, Entscheidungsb\u00e4ume und Random Forest) miteinander verglichen. \nplt.plot(fpr_saga, tpr_saga, \"-\", color=\"orange\", label= \"Logistische Regression\")\nplt.plot(fpr_dt_gini, tpr_dt_gini, \"-.\", color=\"green\", label= \"Entscheidungsb\u00e4ume\")\nplot_roc_curve(fpr_rf_depth15, tpr_rf_depth15, \"Random Forest\")\nplt.title(\"Visualisierung des Modellvergleichs\")\nplt.legend(loc=\"lower right\")\nplt.show();","35e3a66a":"# Mittelwerte von roc_auc-scores\nprint(\"\", \"Mittelwerte von 5-fach validierte roc_auc_scores:\", \"\\n\",\n      \"Logistische Regression\", mean(y_score_saga), \"\\n\",\n      \"Entscheidungsb\u00e4ume\", \"   \",mean(y_score_gini), \"\\n\",\n      \"Random Forest\", \"        \",mean(y_score_rf_depth15))","f1ad435d":"# Random forest mit Criterion gini und max_depth= 7\nrf_depth15 = RandomForestClassifier(random_state = 0, criterion=\"gini\", max_depth= 15) \nrf_depth15.fit(X_train, y_train) \n#y_train_proba_rf=cross_val_predict(rf, X_train, y_train, cv=5, method=\"predict_proba\")\ny_proba = rf_depth15.predict_proba(X_test)","56f9bdee":"# Laden des L\u00f6sungstamplates.\nsubmission= pd.read_csv(\"\/kaggle\/input\/dataanalyticschallenge61\/Lsungstemplate.csv\", sep=\",\",  encoding='latin-1')\nsubmission.head()","9a4690dd":"# Hinzuf\u00fcgen der gesch\u00e4tzten Wahrscheinlichkeiten zu Submission.\nsubmission[\"Expected\"]=pd.DataFrame(y_proba[:,1])\nsubmission.head()","9c4cf5be":"# Speichern der L\u00f6sungsdatensatzes.\n#submission.to_csv( \"submission.csv\", index=False)","299d8c5e":"# 6. Training von Machine Learning Algorithmen","725c17c9":"# 2. Einbinden des Trainingsdatensatzes","4ab07ee7":"- Genauso wie beim Trainingsdatensatz weisen die Variablen **Art der Anstellung, Schulabschlu\u00df** und **Kontaktart** auch hier die Kategorie **Unbekannt**. Sie werden genauso behandelt, wie beim Trainingsdatensatz.","f8b2c4a0":"## Logistic Regression","77223926":"- Genauso wie bei Entscheidungsb\u00e4ume wurden auch mit Rendom Forest Classifier drei Modelle gerechnet. Einmal mit default Parametern (Criterion gini), diesem wurde im zweiten Modell max_depth= 15 hinzugef\u00fcgt und drittes Modell wurden mit folgenden Parametern: Criterion entropy und max_depth= 15 berechnet.\n- Beim Modellvergleich sind kaum Unterschiede festzustellen. Es gibt keine visuellen Unterschiede. Betrachtet man die Zahlen von roc_auc, ist das Modell mit Criterion gini und max_depth= 15 bei der 4. Nachkommastelle etwas besser. Deshalb wird das genannte Modell behalten.","3fc5a638":"- Diesen Histogrammen kann entnommen werden, dass zum einen die Variablen unterschiedliche Skalierung aufweisen und zum anderen sind die Variablen **Dauer, Kontostand, Anzahl der Ansprachen, Anzahl Kontakte letzte Kampagne** ziemlich stark rechtsschief verteilt. In dem Schritt **4. Vorbereitung des Trainingsdatensatzes** werde ich diese Variablen so transformieren, dass sie ann\u00e4hrend normalverteilt sein werden, ansonsten k\u00f6nnten Machine Learning Algorithmen bei der Vorhersage in  Schwierigkeiten geraten.\n- **Alter** zeigt auch eine eher leichte rechtschiefe, k\u00f6nnte sich aber eher unproblematisch erweisen.","af7cb223":"- Verteilung der Zielvariable \u00fcber Geschlecht zeigt keine sichtbare Unterschiede zwischen M\u00e4nner und Frauen. Der prozentuelle Unterschied ist nur bei Nachkommastelle festzustellen. Dementsprechend kann davon ausgegangen werden, dass das Geschlecht kein Faktor sein wird.\n- Bei den anderen Variablen **Erwerbsniveau, Famillienstand** und **Schulabschlu\u00df** verh\u00e4lt es sich anders. Augenscheinlich ist die Zielvariable unterschiedlich verteilt \u00fcber die Auspr\u00e4gungen der genannten Variablen. Dies deutet auf einen Zusammenhang hin. Die Unterschiede sind deutlicher bei **Nichtabschlussen** (*Blaue Balken*).","44a62b7f":"- F\u00fcr die Variablen **Stammnummer, Tag** und **Anruf-ID** werden die deskriptiven Kennzahlen selbstverst\u00e4ndlich nicht ber\u00fccksichtigt, da sie in diesem Kontext keinen Sinn in sich tragen.\n- Die Variablen **Dauer, Alter** und **Kontostand** weisen keine gro\u00dfen Auff\u00e4lligkeiten bei der Betrachtung von deskriptiven Kennzahlen auf. Obwohl k\u00f6nnte man meinen, dass std bei **Dauer** und **Kontostand** ziemlich gro\u00df ausf\u00e4llt.\n- Bei den Variablen **Anzahl der Ansprachen** und **Anzahl Kontakte letzte Kampagne** f\u00e4llt auf, dass sie sehr wahrscheinlich Ausrei\u00dfer beinhalten, denn bis zum 3. Quartil haben sie niedrige Werte  (3.000000 und 0.000000) und bei max sehr h\u00f6he Werte (63.000000 und 275.000000).  Dieser Umstand sollte in dem **Schritt 4** (Aufereitung des Trainingsdatensatzes) ber\u00fccksichtigt werden.","99440dfa":"- Die Verteilung \u00fcber die Kategorien ist sehr \u00e4hnlich bei dieser Variablen mit dem Trainingsdatensatz. Deswegen wird genauso vorgegangen. Also 20% der F\u00e4lle von **Unbekannt** gehen an **Festnetz** und 80% an **Handy**","3ca7a07c":"## 3.1 Berechnung neuer unabh\u00e4ngiger Variablen","d751181d":"## 3.2 Visualisierung m\u00f6glicher Zusammenh\u00e4nge mit Zielvariable","8d51a4b6":"- die Verteilung von **Zielvariable** ist sehr ungleich! **Nichtabgeschlossen 88% \/ Abgeschlossen 12%**.\n- Das wird sehr wahrscheinlich dazu f\u00fchren, dass die Klassifikationsalgorithen bei neue Daten (Testdatensatz) **Nichtabgeschlossen** besser sch\u00e4tzen wird als **Abgeschlossen**.","47b0994a":"# 5. Aufbereitung des Testdatensatzes","b5e24604":"- Neue Variable zeigt tats\u00e4chlich augenscheinliche Unterschiede. An dieser Stelle wurde ich nach M\u00f6glichkeit in dem Unternehmen nachfragen, ob sie eher im Fr\u00fchling und Sommer mit ihren Marketingkampagnen aktiv sind. Die wenigeren Abschlusse im Herbst und Winter k\u00f6nnten darauf zur\u00fcckzuf\u00fchren sein, bevor die Eigenschaften der Kunden und Kundinnen in Betracht gezogen werden.","c4ed736e":"# 7. Modellvergleich","4fc10f3a":"# Ablaufschritte \n********************************\n## 1. Problemstellung \n## 2. Einbinden des Trainingsdatensatzes\n#### 2.1 \u00dcberblick auf Trainingsdatensatz\n#### 2.2 Tracking und Behandlung von Missings\n## 3. Explorative Datenanalyse (EDA) und Variablenselektion \n#### 3.1 Berechnung neuer unabh\u00e4ngiger Variablen\n#### 3.2 Visualisierung m\u00f6glicher Zusammenh\u00e4nge mit Zielvariable\n## 4. Aufereitung des Trainingsdatensatzes \n## 5. Aufbereitung des Testdatensatzes\n## 6. Training von Machine Learning Algorithmen\n## 7. Modellvergleich ","906246b1":"- Die Abbildung zeigt eindeutig, dass meiste Erfolge hat man, wenn man Kunden und Kundinnen eimal anspricht, gefolgt von zweimal, dreimal und viermal Ansprachen. ","7c7d1bec":"- Pr\u00fcfung der Umsetzung des Vorhabens:\n**may, oct, jun, jun, may**\n**639, 224, 400, 400, 639**\n-- Perfekt!\n\n- Damit wurde eine neue Variable berechnet, die m\u00f6glichen Differenzen \u00fcber Monate in den Abschlussen aufdecken kann\n","ad064c64":"- Bei allen vier Variablen sind sichtbare Unterschiede festzustellen.","9a63c5da":" ## 2.1 \u00dcberblick auf Trainingsdatensatz","6ac08daa":"- Der Datensatz enth\u00e4lt Informationen \u00fcber **31480 Kunden und Kundinnen** und **20 Variablen insgesamt**, inklusive Zielvariable. \n- Es gibt keine Duplikate vorzufinden. Missings sind nur bei der Variable **Tage seit letzter Kampagne** zu vermerken, n\u00e4mlich 25742. Im n\u00e4chsten Abschnitt gilt es, die Quelle und Art dieser Missings zu bestimmen. \n- Es gibt **11 kategoriale** und **9 nummerische Variablen**. Diese Eigenschaft der Variablen muss bei der Analyse selbsverst\u00e4ndlich beachtet werden.\n- Zielvariable ist eine kategoriale Variable mit 2 Auspr\u00e4gungen **ja= Abgeschlossen** und **nein= Nischtabgeschlossen**. Damit kann man schon vorwegnehmen, dass es sich um eine Klassifikationsproblem handelt. ","12bc867e":"# Random Forest","c37cd1e8":"- In diesem Abschnitt werden die Variablen miteinander kombieniert, sprich neue Variablen berechnet und die m\u00f6gliche Zusammenh\u00e4nge mit Zielvariable grafisch gest\u00fctzt illustriert.","c2292240":"## 3. Explorative Datenanalyse (EDA) und Variablenselektion ","234df89d":"#                       **Ende**","5e74bc30":"# 4. Aufbereitung des Trainingsdatensatzes \n","215171f6":"- Check nach Missings bei den kategorischen Variablen hat sich ergeben, dass folgende Variablen **Art der Anstellung, Schulabschlu\u00df, Kontaktart** und **Ergebnis letzte Kampagne** die Kategorie **Unbekannt** aufweisen. Da diese Kategorie inhaltlich wenig aussagt, wird als Missings behandelt.\n- Die Variable **Ergebnis letzte Kampagne** hat sogar Kategorien **Sonstiges** und **Unbekannt**. Die beiden Kategorien machen schon \u00fcber 85% der gesamten Variable aus. Beibehaltung dieser Variable in der weiteren Analyse wird sehr wahrscheinlich zur Verzerrung der Ergebnisse beitrage, da nur \u00fcber 15% der Kunden und Kundinnen Informationen vorhanden ist. Aus diesem Grund wird auch diese Variable aus der Analyse entfernt.\n- Die Variablen **Art der Anstellung** und **Schulabschlu\u00df** weisen verh\u00e4ltnism\u00e4ssig geringe Anzahl der F\u00e4lle in der Kategorie **Unbekannt** auf. Aus diesem Grund w\u00e4re es in Ordnung, wenn diese Kategorie einer anderen h\u00e4ufigste Kategorie (Modus) in der jeweiligen Variablen hinzugef\u00fcgt wird.\n- Als n\u00e4chstes ist die Variable **Kontaktart** zu betrachten. Hier weist die Kategorie **Unbekannt** 9079 F\u00e4lle auf. Da es sich um die Daten aus einer Call-Center handelt, kann mit Sicherheit davon ausgegangen werden, dass es sich bei **Unbekannt** um telefonische Kontakte handelt. **Unbekannt** betr\u00e4gt 28,84% der gesamten F\u00e4lle. Es wurde Sinn machen, diese F\u00e4lle auf die anderen Kategorien proportional zu \u00fcbertragen, so dass 80% aus 9079 auf die Kategorie **Handy** geht und 20% auf **Festnetz**. Diese gew\u00e4hlte Verteilung ist nicht zuf\u00e4llig. **Handy** hat meiste F\u00e4lle und **Festnetz** eher weniger. Aus diesem Grund finde ich diese Verteilung gerecht und sinnvoll.\n- Dazu werden noch **Tag** und **Anruf-ID** aus der Analyse entfernt, da sie nichts inhaltliches beitragen k\u00f6nnen (meiner Meinung nach).","81492924":"- Grafik zeigt deutlich, dass Dauer des Anrufs einen Einfluss darauf hat, ob der\/die Kunde\/in Kampgne abschlisst oder nicht. Ab 400 Sekunden (Es ist nicht eindeutig festzustellen, wie diese Variable gemessen ist, aber ich gehe mal aus Sekunden aus, denn f\u00fcr Minuten w\u00e4ren diese Zahlen zu viel und f\u00fcr Milisekunden zu wenig) f\u00e4ngt ein Bereich auf der Grafik an, in dem abgeschlossene Kampagnen anteilig den Nichtabgeschlossenen \u00fcbersteigen.","6861eb7f":"## Entscheidungsb\u00e4ume","a847dda7":"- Betrachtet man die Variable **Ergebnis letzte Kampagne**, l\u00e4sst sich vermuten, dass die hohe Anzahl von Missings bei der Variable **Tage seit letzter Kampagne** geht auf die Tatsache zur\u00fcck, dass diese Leute einfach nicht kontaktiert wurden. Dementsprechend wurde es Sinn machen die Missings in diesem Fall mit dem Wert **0** zu ersetzen. Damit ergibts sich die M\u00f6glichkeit diese Variable in der Analyse beizubehalten.","c72006d4":"- Die Altersgruppe von 28 bis 40 Jahre sind am Meisten repr\u00e4sentiert in der Stichprobe, dementsprechend wird meistens diese Altersgruppe wegen Managementkampagne angesprochen.\n- Diese Altersgruppe repr\u00e4sentiert gleichzeitig Kundschaft, die meiste Kampagnen abschliesst, aber auch diejenigen, die nicht eine Kampagne nicht abschliessen.\n- Bemerkenswert ist die Tatsache, die in der Abbildung zum Schein kommt, dass bei den Altersgruppen 28 und j\u00fcnger und 61 und \u00e4lter der Anteil abgeschlossene Managementkampagnen den Nichtabgeschlossenen \u00fcbersteigt","fea7eeac":"# 1. Problemstellung ","9bdb82b8":"- Es gibt keine gro\u00dfe Korrelation zwischen den unabh\u00e4ngigen Variablen zu verzeichnen. Es l\u00e4sst sich darauf vertrauen, dass Multikolinearit\u00e4t kein Thema in dieser Analyse sein wird. ","c264e1e5":"- Insights nummerischer Daten zeigten, dass sie unterschiedlicher Skallierung haben und nicht ann\u00e4hrend normalverteilt sind. In diesem Unterkapitel wird diese zwei Tatsachen Rechnung getragen, indem PowerTransformer mit der Methode von Yeo-Johnson und Standardisierung verwendet wird. Damit werden die Daten vergleichbare Skallierung und ann\u00e4hrende Normalverteilung erhalten.","45875e32":"- Es werden f\u00fcr die Aufbereitung des Testdatensatzes genau die Schritte durchgef\u00fchrt, die f\u00fcr Trainingsdatensatz durchgef\u00fchrt wurde.  Damit wird gew\u00e4hrleistet, dass die Trainings- und Testdatens\u00e4tze vergleichbar sind","fdae04b6":"- Die Variable **Kontostand** enth\u00fcllt auf den ersten Blick die Tatsache, dass die bisherigen Kampagnen bei den Kunden und Kundinnen mit mehr als 2000 Euro Minus Kontostand nicht erfolgreich waren. Es illustriert aber gleichzeitig, dass es sich lohnt, die Kunden und Kundinnen mit dem Kontostand von -2000 und weiter oben (in den Plus)  \u00fcber aktuelle Managementkampagnen anzusprechen.","0bfe7bdc":"- Es wurden drei Logit-Modelle gerechnet mit unterschiedlichen Parametern. Die Modelle zeigen allerdings keine sonderbare Unterschiede auf. \n- Vergleicht man deren Durchschnittswerte von 5 fach validierte roc_auc_scores ist das Modell mit dem Solver 'saga' bei 6. Nachkommastelle etwas besser. Nur aus diesem Grund wird f\u00fcr dieses Modell aus Logitmodellen entschieden.","044147f9":"- Merkw\u00fcrdigerweise zeigt **Anzahl Kontakte letzte Kampagne**, dass der meiste Erfolg  bei dem letzten Kampangne dann verzeichnet wurde, wenn Kunden und Kundinnen gar nicht angesprochen wurden. An dieser Stelle w\u00fcrde ich mich gerne bei den Autoren dem letzten Kampagne erk\u00fcndigen, ob sie diese Kampagnen zusammen mit etwas anderem gestartet haben oder auf andere Mittel f\u00fcr Kontakte als Anruf genutzt haben usw. Ansonsten l\u00e4sst es sich nicht erschlie\u00dfen, warum bei 0 Kontakt mit Kunden und Kundinnen so viel Erfolg erzielt wurde.\n- Ansonsten l\u00e4sst sich erkennen, mit der h\u00f6heren Anzahl von Anrufen die Wahrscheinlichkeit des Abschliessens abnimmt. Nichtdestotrotz ab Anzahl 2 die Abgeschlossenen \u00fcbersteigen anteilig den Nichtabgeschlossenen.","7494d791":"- Der visuelle Modellvergleich zeigt, dass das Modell **Random Forest** schon bessere Vorhersagen liefert als die anderen Modelle.\n- Die Werte von roc_auc zeigen, dass Entscheidungsb\u00e4ume und Random Forest besser sind, aber der Unterschied zwischen diesen beiden Modellen f\u00e4llt zu G\u00fcnsten von Entscheidungsb\u00e4umen bei der 3.Nachkommastelle.\n\n- **Entscheidung:** In Anlehnung an ROC-AUC-Curve wird schlussendlich f\u00fcr **Random Forest** entschieden!","849aa973":"- Bei Entscheidungsb\u00e4umen wurden auch drei Modelle mit unterschiedlichen Parametern gerechnet. Erstes Modell hat default Parameter (Criterion gini), beim zweiten Modell wurde max_depth= 7 hinzugef\u00fcgt und Modell drei wurde mit Criterion entropy und max_depth=15 gerechnet.\n- Der Vergleich zeigt, dass das Modell mit default Parametern sich eindeutig schlechter abschneidet als die Anderen.\n- Die letzten beiden Modelle zeigen allerdings keine gro\u00dfe Unterschiede. Wenn man die Werte von roc_auc betrachtet, bei 3. Nachkommastelle ist das Modell mit Criterion gini und max_depth= 7 etwas besser. Aus diesem Grund wird dieses Modell erstmal beibehalten.","fdbb4b9e":"- Betrachtet man die Kategorien von **Art der Anstellung** und deren Kontostand, f\u00e4llt drei Gr\u00fcppen der **Erw\u00e4rbst\u00e4tigen** auf, niedrige(**Student, Hausfrau, Arbeitslos, Gr\u00fcnder** und **Selbstst\u00e4ndig**), mittlere(**Dienstleistung, Rentner** und **Verwaltung**) und h\u00f6he(**Technischer Beruf, Arbeiter** und **Management**). Angelehnt an dieser Erkenntnis aus den Daten, werde ich eine neue Variable aus **Art der Anstellung** generieren, in der diese Kategorien in der drei genannten Kategorien zusammengefasst werden.\n- **Anmerkung:** dass Kontostand kein genaues Einkommen wiederspiegelt, ist mir bewusst, kann man auch andere Bankkonten haben. Hilft aber in diesem Kontext diese Kategorien inhaltlich besser zu sortieren.","79c48cd5":"- Das Ziel dieser Analyse ist ein m\u00f6glichst gutes Prognosemodell f\u00fcr eine Marketingkampagne f\u00fcr eine neues Produkt **\"MedTrust\"** zu erstellen und die **Abschlusswahrscheinlichkeiten** vorauszusagen.","c1668d3f":" ## 2.2 Tracking und Behandlung von Missings"}}