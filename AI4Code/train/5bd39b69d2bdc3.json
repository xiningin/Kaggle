{"cell_type":{"b47d0a72":"code","5f6da5c8":"code","eaa76adf":"code","def709c9":"code","c6720a59":"code","731c41cd":"code","e5823797":"code","d751f268":"code","0ec448e2":"code","97e1621b":"code","d15f7be0":"code","ac3b3d90":"code","66044e05":"code","27c3bcc0":"code","5eb387ac":"code","88afe573":"code","0da6cc61":"code","549556ae":"code","648a9269":"code","9bca5c46":"code","c9fd27d6":"code","9b63ad23":"markdown","4f2f1396":"markdown","ef5c6260":"markdown","20c78274":"markdown","7562ea3f":"markdown","51c99f3d":"markdown","872db9c3":"markdown","e7ea7e2e":"markdown","57db7b54":"markdown","45fae18a":"markdown","c0e21ce9":"markdown","af7197ee":"markdown","a94c14b3":"markdown","0496bf91":"markdown","e4c43ffe":"markdown","080eb4df":"markdown","8a863d0a":"markdown","3e079657":"markdown","1672ce40":"markdown","1d4e813c":"markdown"},"source":{"b47d0a72":"import geopandas as gpd #see this for installing geopandas https:\/\/www.youtube.com\/watch?v=LNPETGKAe0c\nimport numpy as np\nimport pandas as pd\nimport folium\nfrom folium.plugins import TimeSliderChoropleth\nimport branca.colormap as cm","5f6da5c8":"corona_df=pd.read_csv(\"\/kaggle\/input\/covid_data_til_19_May.csv\")\ncorona_df.head()","eaa76adf":"country = gpd.read_file(\"\/kaggle\/input\/bangladesh.json\")","def709c9":"country=country[[\"id\",\"NAME_2\",\"geometry\"]]","c6720a59":"country[\"geometry\"] = country[\"geometry\"].simplify(0.01, preserve_topology = False)\ncountry.head()","731c41cd":"country = country.rename(columns={'NAME_2': 'Zilla'})\ncountry.head()","e5823797":"def correct_date(date_str):\n    list_dates = date_str.split(\"\/\")\n    day = list_dates[0]\n    month = list_dates[1]\n    year = list_dates[2]\n    \n    if len(day) == 1:\n        day = \"0\" + day\n    if len(month) == 1:\n        month = \"0\" + month\n        \n    return \"\/\".join([day, month, year])","d751f268":"corona_df[\"Date\"] = corona_df[\"Date\"].apply(correct_date)","0ec448e2":"corona_df = corona_df[corona_df.Cases != 0]","97e1621b":"sorted_df = corona_df.sort_values(['Zilla', \n                     'Date']).reset_index(drop=True)","d15f7be0":"sum_df = sorted_df.groupby(['Zilla', 'Date'], as_index=False).sum()","ac3b3d90":"joined_df = sum_df.merge(country, on='Zilla')","66044e05":"joined_df['log_Confirmed'] = np.log10(joined_df['Cases'])","27c3bcc0":"joined_df['date_sec'] = pd.to_datetime(joined_df['Date'],format='%d\/%m\/%Y')\njoined_df['date_sec']=[(joined_df['date_sec'][i]).timestamp() for i in range(0,joined_df['date_sec'].shape[0])]\njoined_df['date_sec'] = joined_df['date_sec'].astype(int).astype(str)","5eb387ac":"joined_df = joined_df[['Zilla','Date', 'date_sec', 'log_Confirmed', 'geometry']]","88afe573":"max_colour = max(joined_df['log_Confirmed'])\nmin_colour = min(joined_df['log_Confirmed'])\ncmap = cm.linear.OrRd_09.scale(min_colour, max_colour)\njoined_df['colour'] = joined_df['log_Confirmed'].map(cmap)","0da6cc61":"zilla_list = joined_df['Zilla'].unique().tolist()\nzilla_idx = range(len(zilla_list))\nstyle_dict = {}\nfor i in zilla_idx:\n    zilla = zilla_list[i]\n    result = joined_df[joined_df['Zilla'] == zilla]\n    inner_dict = {}\n    for _, r in result.iterrows():\n        inner_dict[r['date_sec']] = {'color': r['colour'], 'opacity': 0.8}\n    style_dict[str(i)] = inner_dict","549556ae":"zilla_df = joined_df[['geometry']]\nzilla_gdf = gpd.GeoDataFrame(zilla_df)\nzilla_gdf = zilla_gdf.drop_duplicates().reset_index()","648a9269":"slider_map = folium.Map(location = (23.6850, 90.3563), zoom_start = 6.5,tiles='cartodbpositron')\n\n_ = TimeSliderChoropleth(\n    data=zilla_gdf.to_json(),\n    styledict=style_dict,\n\n).add_to(slider_map)\n\n_ = cmap.add_to(slider_map)\ncmap.caption = \"Log of number of confirmed cases\"","9bca5c46":"slider_map","c9fd27d6":"#slider_map.save(outfile='Time_mapping.html')","9b63ad23":"# we filtered out some of the unnecessary columns,here \"NAME_2 represent Zilla","4f2f1396":"# Finally, we create our map and add a colorbar","ef5c6260":"# In order to map our data, we need a shapefile. A shapefile is a geospatial vector data format. The shapefile format can spatially describe vector features such as points, lines, and polygons.In our case, zillas are represented as polygons","20c78274":"# Import necessary Libraries","7562ea3f":"#  Using the pandas library, we can read in the data\n","51c99f3d":"# This line is to make our data loading and visulization faster","872db9c3":"# We can now select the columns needed for the map\n","e7ea7e2e":"# To make the format of date consistance throughtout the dataframe.We created a function for formating the dates ","57db7b54":"# We are going to plot the log of the number of confirmed cases for each zilla,as there are a couple of zillas, such as Dhaka and Narayanganj,with a lot more cases compared to other zillas","45fae18a":"# we construct our style dictionary","c0e21ce9":"# we define a colour map in terms of the log of the number of confirmed cases","af7197ee":"# we need to match with the column name of our corona database.So,we renamed it","a94c14b3":"# Then we need to make a dataframe containing the features for each zilla:","0496bf91":"Thank you","e4c43ffe":"# We also need to convert the Date to unix time in nanoseconds","080eb4df":"# Now we can join the data and the shapefile together","8a863d0a":"# ref:https:\/\/www.jumpingrivers.com\/blog\/interactive-maps-python-covid-19-spread\/\n# data:https:\/\/public.tableau.com\/profile\/masud.parvez7954#!\/vizhome\/COVID-19_15848570974940\/Con-GISChange?publish=yes\n# data:http:\/\/103.247.238.81\/webportal\/pages\/covid19.php","3e079657":"# If any of the zilla has more than one entry on single date,we took the sum of them","1672ce40":"# Some zillas are included in the data despite having zero confirmed cases. So we remove these:","1d4e813c":"# We then sort our data by date and reset the index"}}