{"cell_type":{"98819123":"code","04c5e8a2":"code","9f083ca6":"code","e8115b29":"code","eb28e4e5":"code","63f001d9":"code","24a2e1ac":"code","7d666f46":"code","cf6531ba":"code","fb9d17a5":"code","1924ea13":"code","1c02e6d9":"code","9c76a96c":"code","d3b131c1":"code","88c1bf28":"code","641dfc3d":"code","c89b73c8":"code","bf1da65c":"code","5f391e65":"code","2ea616ee":"code","43d22498":"code","388c8de1":"code","ccb10a1f":"code","5d12f7c9":"code","187bc097":"code","cbc7bd6c":"code","b632d1bd":"code","80fcd088":"code","0737898a":"code","b3924556":"code","b8fad3ea":"code","115392b2":"code","fca5074c":"code","52839540":"code","dd90bb55":"code","abc62084":"code","d1125f4c":"code","300a8f3c":"code","c28e7159":"code","5b3aa993":"code","ba4cc55f":"code","674a92f7":"code","e6cda1c7":"code","d2124dbc":"code","c35dfcdb":"code","c56aa11d":"code","2f8ee38b":"code","4d4b2e67":"code","c1412179":"code","935c5152":"code","ced1d78a":"code","3f234899":"code","e8f06e39":"code","786e54e7":"code","36b75472":"code","534dc571":"code","3a08e031":"code","e88a3cfa":"code","c821e240":"code","0f9cc7c7":"code","bb3fffad":"code","010ebece":"code","dc0389d6":"code","61f13d5a":"code","65347620":"code","49228dea":"code","26e25884":"code","9368dac9":"code","aa15d448":"code","5c306ca6":"code","33215c98":"code","d24b1c47":"code","1621872a":"code","6fbc65da":"code","460adfc0":"code","11d09938":"code","cd7a7634":"code","ba2b9578":"code","5924afcc":"code","f71f4272":"code","3a69f6d2":"code","40ccd60a":"markdown","a962dadc":"markdown","d68c0f75":"markdown","11b0deeb":"markdown","f2ab9b5a":"markdown","8d31a04a":"markdown","d277d7fd":"markdown","aba7310d":"markdown","0630a72e":"markdown","af060078":"markdown","7e443bb2":"markdown","8f287231":"markdown","d4731c43":"markdown","76d68f63":"markdown","a5294ddd":"markdown","e182cce5":"markdown","a9040863":"markdown","358dbf69":"markdown","6b8a23b4":"markdown","f944dfe0":"markdown","91ad9bc6":"markdown","ac61e450":"markdown","8635e9b9":"markdown","af690433":"markdown","c7634240":"markdown","18e6b673":"markdown","b708e51c":"markdown","b1e16de0":"markdown","90bc5f20":"markdown","59482b44":"markdown","7025c350":"markdown","6f33a5bd":"markdown","f60712ca":"markdown","8af18b53":"markdown","9f9a7d76":"markdown","f3786e6f":"markdown","5d2806fb":"markdown","229fad46":"markdown","d1e7e6fe":"markdown","f9aec0cb":"markdown","242cd074":"markdown","5d42fbe2":"markdown","e1a7e647":"markdown","7a87f0f4":"markdown"},"source":{"98819123":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","04c5e8a2":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom collections import Counter","9f083ca6":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nIDtest = test[\"PassengerId\"]","e8115b29":"train.head()","eb28e4e5":"print(\"trainig data shape\",train.shape)\nprint(\"testing data shape\",test.shape)","63f001d9":"numerical_features=[features for features in train.columns if train[features].dtype!='O' ]","24a2e1ac":"for feature in numerical_features:\n    print(feature)","7d666f46":"# detect outliers from Age, SibSp , Parch and Fare\n\n\ndef detect_outliers(train,n,features):\n\n    outlier_indices = []\n    \n    \n    for col in features:\n        \n        # gonna use IQR method for detecting and deleting outliers\n        \n        # 1st quartile (25%)\n        Q1 = np.percentile(train[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(train[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = train[(train[col] < Q1 - outlier_step) | (train[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n# detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])\n","cf6531ba":"train.loc[Outliers_to_drop] # Show the outliers rows","fb9d17a5":"# Drop outliers\ntrain = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)","1924ea13":"# before that remember the length of train data\nprint(\"shape of train data:\",train.shape)","1c02e6d9":"dataset =  pd.concat([train, test], axis=0).reset_index(drop=True)","9c76a96c":"dataset.head()\n","d3b131c1":"print(dataset.shape)","88c1bf28":"# Fill empty and NaNs values with NaN\ndataset = dataset.fillna(np.nan)\n\n# Check for Null values\ndataset.isnull().sum()","641dfc3d":"# Infos\ntrain.info()\ntrain.isnull().sum()","c89b73c8":"test.isnull().sum()","bf1da65c":"#Age\ng = sns.FacetGrid(train,col=\"Survived\")\ng = g.map(sns.distplot,\"Age\")","5f391e65":"# Explore Age distibution \ng = sns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 0) & (train[\"Age\"].notnull())], color=\"Red\", shade = True)\ng = sns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 1) & (train[\"Age\"].notnull())], ax =g, color=\"Blue\", shade= True)\ng.set_xlabel(\"Age\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"Not Survived\",\"Survived\"])","2ea616ee":"#  Parch feature vs Survived\ng  = sns.catplot(x=\"Parch\",y=\"Survived\",data=train,kind=\"bar\", size = 6 , palette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","43d22498":"#SibSp vs survival\n\n# Explore SibSp feature vs Survived\ng = sns.catplot(x=\"SibSp\",y=\"Survived\",data=train,kind=\"bar\", size = 6 , \npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","388c8de1":"dataset[\"Fare\"].isnull().sum()","ccb10a1f":"#Fill Fare missing values with the median value\ndataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].median())","5d12f7c9":"# Explore Fare distribution \ng = sns.distplot(dataset[\"Fare\"],color='R')","187bc097":"dataset['Fare']=dataset['Fare'].map(lambda i: np.log(i) if i > 0 else 0)","cbc7bd6c":"g = sns.distplot(dataset[\"Fare\"], color=\"b\")\n","b632d1bd":"g = sns.barplot(x=\"Sex\",y=\"Survived\",data=train)\ng = g.set_ylabel(\"Survival Probability\")\n","80fcd088":"pd.DataFrame(train.groupby('Sex')['Survived'].mean())","0737898a":"# Explore Pclass vs Survived\ng = sns.catplot(x=\"Pclass\",y=\"Survived\",data=train,kind=\"bar\", size = 6 , \npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","b3924556":"# Explore Pclass vs Survived by Sex\ng = sns.catplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train,\n                   size=6, kind=\"bar\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","b8fad3ea":"print(\"No of null Vales in Embarked Feature are\",dataset[\"Embarked\"].isnull().sum())\nprint(\"the most repeating category in Embarked Feature is:\",dataset[\"Embarked\"].mode())","115392b2":"#Fill Embarked nan values of dataset set with 'S' most frequent value\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")","fca5074c":"# Explore Embarked vs Survived \ng = sns.catplot(x=\"Embarked\", y=\"Survived\",  data=train,\n                   size=6, kind=\"bar\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","52839540":"# Explore Pclass vs Embarked \ng = sns.factorplot(\"Pclass\", col=\"Embarked\",  data=train,\n                   size=6, kind=\"count\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"Count\")","dd90bb55":"# Explore Age vs Sex, Parch , Pclass and SibSP\ng = sns.catplot(y=\"Age\",x=\"Sex\",data=dataset,kind=\"box\")\ng = sns.catplot(y=\"Age\",x=\"Sex\",hue=\"Pclass\", data=dataset,kind=\"box\")\ng = sns.catplot(y=\"Age\",x=\"Parch\", data=dataset,kind=\"box\")\ng = sns.catplot(y=\"Age\",x=\"SibSp\", data=dataset,kind=\"box\")","abc62084":"# convert Sex into categorical value 0 for male and 1 for female\ndataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})","d1125f4c":"g = sns.heatmap(dataset[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(),cmap=\"BrBG\",annot=True)","300a8f3c":"# Filling missing value of Age \n\n## Fill Age with the median age of similar rows according to Pclass, Parch and SibSp\n# Index of NaN age rows\nindex_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\n\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].median()\n    age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) & (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred) :\n        dataset['Age'].iloc[i] = age_pred\n    else :\n        dataset['Age'].iloc[i] = age_med\n","c28e7159":"g = sns.catplot(x=\"Survived\", y = \"Age\",data = train, kind=\"box\")\ng = sns.catplot(x=\"Survived\", y = \"Age\",data = train, kind=\"violin\")","5b3aa993":"dataset[\"Name\"].head()","ba4cc55f":"# Get Title from Name\ndataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\ndataset['Title']=dataset_title\n\n\n","674a92f7":"dataset.head()","e6cda1c7":"g = sns.countplot(x=\"Title\",data=dataset)\ng = plt.setp(g.get_xticklabels(), rotation=45) ","d2124dbc":"# Convert to categorical values Title \ndataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ndataset[\"Title\"] = dataset[\"Title\"].astype(int)","c35dfcdb":"g = sns.countplot(dataset[\"Title\"])\ng = g.set_xticklabels([\"Master\",\"Miss\/Ms\/Mme\/Mlle\/Mrs\",\"Mr\",\"Rare\"])","c56aa11d":"g = sns.catplot(x=\"Title\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_xticklabels([\"Master\",\"Miss-Mrs\",\"Mr\",\"Rare\"])\ng = g.set_ylabels(\"survival probability\")","2f8ee38b":"# Drop Name variable\ndataset.drop(labels = [\"Name\"], axis = 1, inplace = True)","4d4b2e67":"# Create a family size descriptor from SibSp and Parch\ndataset[\"Fsize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1","c1412179":"g = sns.catplot(x=\"Fsize\",y=\"Survived\",data = dataset,kind='bar')\ng = g.set_ylabels(\"Survival Probability\")","935c5152":"# Create new feature of family size\ndataset['Single'] = dataset['Fsize'].map(lambda s: 1 if s == 1 else 0)\ndataset['SmallF'] = dataset['Fsize'].map(lambda s: 1 if  s == 2  else 0)\ndataset['MedF'] = dataset['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ndataset['LargeF'] = dataset['Fsize'].map(lambda s: 1 if s >= 5 else 0)","ced1d78a":"g = sns.catplot(x=\"Single\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.catplot(x=\"SmallF\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.catplot(x=\"MedF\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.catplot(x=\"LargeF\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")","3f234899":"# convert to indicator values Title and Embarked \ndataset = pd.get_dummies(dataset, columns = [\"Title\"])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")","e8f06e39":"dataset.head()","786e54e7":"dataset.shape","36b75472":"dataset[\"Cabin\"].isnull().sum()","534dc571":"dataset[\"Cabin\"].head()","3a08e031":"dataset[\"Cabin\"].describe()","e88a3cfa":"dataset[\"Cabin\"][dataset[\"Cabin\"].notnull()].head()","c821e240":"# Replace the Cabin number by the type of cabin 'X' if not\ndataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])","0f9cc7c7":"g = sns.countplot(dataset[\"Cabin\"],order=['A','B','C','D','E','F','G','T','X'])","bb3fffad":"g = sns.catplot(y=\"Survived\",x=\"Cabin\",data=dataset,kind=\"bar\",order=['A','B','C','D','E','F','G','T','X'])\ng = g.set_ylabels(\"Survival Probability\")","010ebece":"dataset = pd.get_dummies(dataset, columns = [\"Cabin\"],prefix=\"Cabin\")","dc0389d6":"dataset[\"Ticket\"].head()","61f13d5a":"## Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X. \n\nTicket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ndataset[\"Ticket\"] = Ticket\ndataset[\"Ticket\"].head()","65347620":"dataset = pd.get_dummies(dataset, columns = [\"Ticket\"], prefix=\"T\")","49228dea":"# Create categorical values for Pclass\ndataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")\n","26e25884":"dataset.head()","9368dac9":"# Drop useless variables \ndataset.drop(labels = [\"PassengerId\"], axis = 1, inplace = True)","aa15d448":"dataset.head()","5c306ca6":"## Separate train dataset and test dataset\n\ntrain = dataset[:881]\ntest = dataset[881:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","33215c98":"## Separate train features and label \n\ntrain[\"Survived\"] = train[\"Survived\"].astype(int)\n\nY_train = train[\"Survived\"]\n\nX_train = train.drop(labels = [\"Survived\"],axis = 1)","d24b1c47":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n\nsns.set(style='white', context='notebook', palette='deep')","1621872a":"# Cross validate model with Kfold stratified cross val\nkfold = StratifiedKFold(n_splits=10)","6fbc65da":"# Modeling step Test differents algorithms \nrandom_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\n\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train, y = Y_train, scoring = \"accuracy\", cv = kfold, n_jobs=-1))","460adfc0":"cv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())","11d09938":"cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\n                       \"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n                       \"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\n                        \"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})","cd7a7634":"cv_res","ba2b9578":"g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","5924afcc":"cv_res.nlargest(5,\"CrossValMeans\")","f71f4272":"# Gradient boosting tunning\n\nGBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1] \n              }\n\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsGBC.fit(X_train,Y_train)\n\nGBC_best = gsGBC.best_estimator_\n\n# Best score\ngsGBC.best_score_","3a69f6d2":"test_Survived = pd.Series(gsGBC.predict(test), name=\"Survived\")\n\nresults = pd.concat([IDtest,test_Survived],axis=1)\n\nresults.to_csv(\"sub_titanic.csv\",index=False)","40ccd60a":"### Name\/Title","a962dadc":"**We can see that Age and Cabin have the Missing values,we should visualize the Age and Cabin feature to check whether they are important or not,if they are not important we can simply drop the missing value rows.**\n****Dont consider Survived features missing values b cause since we have combined train and test data and test data doesnt have survived column it shows as 418 missing values.****","d68c0f75":"**We see that surviaval probability for small families is high **","11b0deeb":"Indeed, the third class is the most frequent for passenger coming from Southampton (S) and Queenstown (Q), whereas Cherbourg passengers are mostly in first class which have the highest survival rate.","f2ab9b5a":"*Joining the train and test data*","8d31a04a":"## Ticket","d277d7fd":"Factorplots of family size categories show that Small and Medium families have more chance to survive than single passenger and large families.","aba7310d":"# Modeling","0630a72e":"Skewness is clearly reduced after the log transformation","af060078":"### Embarked","7e443bb2":"**Now Lets check the Numerical Features**","8f287231":"Since we have one missing value , i decided to fill it with the median value which will not have an important effect on the prediction.","d4731c43":"**When we superimpose the two densities , we cleary see a peak correponsing (between 0 and 5) to babies and very young childrens.**","76d68f63":"As we can see, Fare distribution is very skewed. This can lead to overweigth very high values in the model, even if it is scaled.\n\nIn this case, it is better to transform it with the log function to reduce this skew.","a5294ddd":"## Simple modeling\n### Cross validate models\n**I compared 10 popular classifiers and evaluate the mean accuracy of each of them by a stratified kfold cross validation procedure.**\n\n* SVC\n* Decision Tree\n* AdaBoost\n* Random Forest\n* Extra Trees\n* Gradient Boosting\n* Multiple layer perceprton (neural network)\n* KNN\n* Logistic regression\n* Linear Discriminant Analysis","e182cce5":"The Name feature contains information on passenger's title.\n\nSince some passenger with distingused title may be preferred during the evacuation, it is interesting to add them to the model.","a9040863":"### Pclass","358dbf69":"The correlation map confirms the factorplots observations except for Parch. Age is not correlated with Sex, but is negatively correlated with Pclass, Parch and SibSp.\n\nIn the plot of Age in function of Parch, Age is growing with the number of parents \/ children. But the general correlation is negative.\n\nSo, i decided to use SibSP, Parch and Pclass in order to impute the missing ages.\n\nThe strategy is to fill Age with the median age of similar rows according to Pclass, Parch and SibSp.","6b8a23b4":"### Fare","f944dfe0":"It seems that passengers having a lot of siblings\/spouses have less chance to survive\n\nSingle passengers (0 SibSP) or with two other persons (SibSP 1 or 2) have more chance to survive","91ad9bc6":"It is clearly obvious that Male have less chance to survive than Female.\n\nSo Sex, might play an important role in the prediction of the survival.","ac61e450":"# Visualization\n### Visualising the Numerical Features:\n","8635e9b9":"# Data Analysis And Preprocessing The Data","af690433":"### Cabin","c7634240":"It could mean that tickets sharing the same prefixes could be booked for cabins placed together. It could therefore lead to the actual placement of the cabins within the ship.\n\nTickets with same prefixes may have a similar class and survival.\n\nSo i decided to replace the Ticket feature column by the ticket prefixe. Which may be more informative.","18e6b673":"The first letter of the cabin indicates the Desk, i choosed to keep this information only, since it indicates the probable location of the passenger in the Titanic.","b708e51c":"\"Women and children first\"\n\nIt is interesting to note that passengers with rare title have more chance to survive.","b1e16de0":"It seems that passenger coming from Cherbourg (C) have more chance to survive.\n\nMy hypothesis is that the proportion of first class passengers is higher for those who came from Cherbourg than Queenstown (Q), Southampton (S).\n\nLet's see the Pclass distribution vs Embarked","90bc5f20":"we can see that 1st class passengers are older than 2nd class passengers who are also older than 3rd class passengers.\n\n*Moreover, the more a passenger has parents\/children the older he is and the more a passenger has siblings\/spouses the younger he is.*","59482b44":"## Age\n\nAs we see, Age column contains 256 missing values in the whole dataset.\n\nLets look at the most correlated features with Age (Sex, Parch , Pclass and SibSP).","7025c350":"We can observe from the graph that children of age 0-5 have high chances to survive.","6f33a5bd":"Small families have more chance to survive, more than single (Parch 0), medium (Parch 3,4) and large families (Parch 5,6 ).","f60712ca":"## Family size\n**We can imagine that large families will have more difficulties to evacuate, looking for theirs sisters\/brothers\/parents during the evacuation. So, i choosed to create a \"Fize\" (family size) feature which is the sum of SibSp , Parch and 1 (including the passenger).**","8af18b53":"### **Lets Have the list of Numerical Features**","9f9a7d76":"I decided to choose the  GradientBoosting for modeling the data.","f3786e6f":"No difference between median value of age in survived and not survived subpopulation.\n\nBut in the violin plot of survived passengers, we still notice that very young passengers have higher survival rate.\/","5d2806fb":"# Feature Engineering\n## Filling Missing Values","229fad46":"**We can see that Mr,Mrs,Miss,Master are most repeated and remaining are very less repeated like Rev,Dr Col etc so we can dump these kind of less repeated into Most repeated Titles**","d1e7e6fe":"# Check for null and missing values","f9aec0cb":"### Detect and Delete Outliers","242cd074":"The passenger survival is not the same in the 3 classes. First class passengers have more chance to survive than second class and third class passengers.","5d42fbe2":"## Sex","e1a7e647":"Because of the low number of passenger that have a cabin, survival probabilities have an important standard deviation and we can't distinguish between survival probability of passengers in the different desks.\n\nBut we can see that passengers with a cabin have generally more chance to survive than passengers without (X).\n\nIt is particularly true for cabin B, C, D, E and F.","7a87f0f4":"We can tell by looking at the graph that females have more probability to survive."}}