{"cell_type":{"c4d93a18":"code","45d418a6":"code","c54fa219":"code","6145b3ac":"code","e88391cd":"code","9dc80a29":"code","dbc2d3ae":"code","68ba6b0c":"code","8580fd7a":"code","a7506bbc":"code","1630a96b":"code","80e74835":"code","a6f3384b":"code","737ba225":"code","60b34d7d":"code","8f31178b":"code","a6f8420a":"code","90ba7f47":"code","fda5126e":"code","256e9310":"code","9a5192e9":"code","df4522ea":"code","15ccbafa":"code","1e95948c":"code","7c10f2b7":"code","9bcb0212":"code","f9173fb4":"code","5f6c9b9c":"markdown","cdf55af0":"markdown","b96ad046":"markdown","981afa7a":"markdown","5ccf3b11":"markdown","9f03ed40":"markdown","9fd3664c":"markdown"},"source":{"c4d93a18":"import pandas as pd\nimport numpy as np\n\ntrain = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv', index_col = 'row_id')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv', index_col = 'row_id')","45d418a6":"display(train['country'].unique())\ndisplay(train['store'].unique())\ndisplay(train['product'].unique())","c54fa219":"def get_ts_dict(df):\n    country_list = ['Finland', 'Norway', 'Sweden']\n    store_list = ['KaggleMart', 'KaggleRama']\n    product_list = ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']\n\n    time_series_dict = {}\n    for country in country_list:\n        for store in store_list:\n            for product in product_list:\n                selected_pd = df.loc[(df['country'] == country) & (df['store'] == store) & \n                                     (df['product'] == product), ['date', 'num_sold']]\n                key = country + '_' + store + '_' + product\n                time_series_dict[key] = selected_pd\n    return time_series_dict","6145b3ac":"train['date'] = pd.to_datetime(train['date'])\ntest['date'] = pd.to_datetime(test['date'])\n\nts_dict = get_ts_dict(train)\nkey_list = list(ts_dict.keys())","e88391cd":"def ts_plot(ts_dict, key_list, figsize=(24, 24)):\n    import datetime as dt\n    \n    ncols = 2\n    nrows = round(len(key_list) \/ ncols)\n    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n    plt.subplots_adjust(hspace=1.5)\n    \n    index = 0\n    for row in range(nrows):\n        for col in range(ncols):\n            try:\n                key = key_list[index]\n                df = ts_dict[key]\n            except:\n                axes[row][col].set_visible(False)\n                index += 1\n                continue\n            \n            sns.lineplot(data=df, x='date', y='num_sold', ax=axes[row][col])\n            axes[row][col].set_title(key)\n            x_label = pd.date_range(start=min(df['date']), end=max(df['date']), freq='3M').astype(str)\n            axes[row][col].set_xticks(x_label)\n            axes[row][col].set_xticklabels(x_label, rotation=90)\n            for year in df['date'].dt.year:\n                axes[row][col].axvline(x = dt.datetime(year, 12, 30), ymin = 0, ymax = 1,\n                                       color ='red', linestyle='--')\n            index += 1\n    plt.show()","9dc80a29":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nts_plot(ts_dict, key_list)","dbc2d3ae":"def plot_periodogram(ts, detrend='linear', ax=None, title=''):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"1Y\") \/ pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual (1)\",\n            \"Semiannual (2)\",\n            \"Quarterly (4)\",\n            \"Bimonthly (6)\",\n            \"Monthly (12)\",\n            \"Biweekly (26)\",\n            \"Weekly (52)\",\n            \"Semiweekly (104)\",\n        ],\n        rotation=90,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram - \" + title)\n    return ax","68ba6b0c":"df_finland_mart_mug = ts_dict['Finland_KaggleMart_Kaggle Mug'].copy()\ndf_finland_mart_hat = ts_dict['Finland_KaggleMart_Kaggle Hat'].copy()\ndf_finland_mart_sticker = ts_dict['Finland_KaggleMart_Kaggle Sticker'].copy()","8580fd7a":"import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nfig, axes = plt.subplots(3, 1, figsize=(16, 8))\nplt.subplots_adjust(hspace=1.5)\nplot_periodogram(df_finland_mart_mug['num_sold'], ax=axes[0], title='finland_mart_mug')\nplot_periodogram(df_finland_mart_hat['num_sold'], ax=axes[1], title='finland_mart_hat')\nplot_periodogram(df_finland_mart_sticker['num_sold'], ax=axes[2], title='finland_mart_sticker')\nplt.show()","a7506bbc":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\nfourier_order = 1\nfourier = CalendarFourier(freq=\"A\", order=fourier_order)\n\ndp = DeterministicProcess(\n    index=df_finland_mart_mug['date'],\n    constant=False,               # dummy feature for bias (y-intercept)\n    order=1,                     # trend (order 1 means linear)\n    seasonal=True,               # weekly seasonality (indicators)\n    additional_terms=[fourier],  # annual seasonality (fourier)\n    drop=True                   # drop terms to avoid collinearity\n)\n\ntrain_ts_mug = dp.in_sample()\ntrain_ts_mug","1630a96b":"fig, ax = plt.subplots(figsize=(16,8))\nsns.lineplot(x=df_finland_mart_mug['date'], y=df_finland_mart_mug['num_sold'], label='mug', ax=ax)\n\ntrain_ts_mug['total_wave'] = 0\nfor i in range(fourier_order):\n    train_ts_mug['total_wave'] = (train_ts_mug['total_wave'] + \n                                  train_ts_mug[f'sin({i+1},freq=A-DEC)'] + train_ts_mug[f'cos({i+1},freq=A-DEC)'])\ntrain_ts_mug['total_wave'] *= 20\ntrain_ts_mug['total_wave'] +=200\n\nshift_num = 38\ntrain_ts_mug['total_wave'] = train_ts_mug['total_wave'].shift(-shift_num)\nsns.lineplot(x=train_ts_mug.index, y=train_ts_mug['total_wave'], label='ts', ax=ax, linewidth=3)\n\nplt.show()","80e74835":"fourier_order = 1\nfourier = CalendarFourier(freq=\"A\", order=fourier_order)\n\ndp = DeterministicProcess(\n    index=df_finland_mart_hat['date'],\n    constant=False,               # dummy feature for bias (y-intercept)\n    order=1,                     # trend (order 1 means linear)\n    seasonal=True,               # weekly seasonality (indicators)\n    additional_terms=[fourier],  # annual seasonality (fourier)\n    drop=True                   # drop terms to avoid collinearity\n)\n\ntrain_ts_hat = dp.in_sample()","a6f3384b":"fig, ax = plt.subplots(figsize=(16,8))\nsns.lineplot(x=df_finland_mart_hat['date'], y=df_finland_mart_hat['num_sold'], label='hat', ax=ax)\n\ntrain_ts_hat['total_wave'] = 0\nfor i in range(fourier_order):\n    train_ts_hat['total_wave'] = (train_ts_hat['total_wave'] + \n                                  train_ts_hat[f'sin({i+1},freq=A-DEC)'] + train_ts_hat[f'cos({i+1},freq=A-DEC)'])\ntrain_ts_hat['total_wave'] *= 50\ntrain_ts_hat['total_wave'] +=350\n\ntrain_ts_hat['total_wave'] = train_ts_hat['total_wave'].shift(shift_num)\nsns.lineplot(x=train_ts_hat.index, y=train_ts_hat['total_wave'], label='ts', ax=ax, linewidth=3)\n\nplt.show()","737ba225":"def feature_eng(df):\n    import holidays\n    import datetime\n    \n    #### Date\n    df['date'] = pd.to_datetime(df['date'])\n    df['week']= df['date'].dt.week\n    df['year'] = 'Y' + df['date'].dt.year.astype(str)\n    df['quarter'] = 'Q' + df['date'].dt.quarter.astype(str)\n    df['day'] = df['date'].dt.day\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df.loc[(df.date.dt.is_leap_year) & (df.dayofyear >= 60),'dayofyear'] -= 1\n    df['weekend'] = df['date'].dt.weekday >=5\n    df['weekday'] = 'WD' + df['date'].dt.weekday.astype(str)\n    df['month']= 'M' + df['date'].dt.month.astype(str)\n    \n    #### Peak\n    df['MM-DD'] = df['date'].dt.strftime('%m-%d')\n    df['peak'] = 0\n    df.loc[df['MM-DD'] == '12-26', 'peak'] = 0.25\n    df.loc[df['MM-DD'] == '12-27', 'peak'] = 0.50\n    df.loc[df['MM-DD'] == '12-28', 'peak'] = 0.75\n    df.loc[df['MM-DD'] == '12-29', 'peak'] = 1\n    df.loc[df['MM-DD'] == '12-30', 'peak'] = 1\n    df.loc[df['MM-DD'] == '12-31', 'peak'] = 1\n    df.loc[df['MM-DD'] == '01-01', 'peak'] = 0.75\n    df.loc[df['MM-DD'] == '01-02', 'peak'] = 0.50\n    df.loc[df['MM-DD'] == '01-03', 'peak'] = 0.25\n    \n    #### Till The Next Holiday\n    def get_country_holidays(country, years_list):\n        festivities = holidays.CountryHoliday(country, years=years_list)\n        festivities_df = pd.DataFrame.from_dict(festivities, orient='index').reset_index().rename(columns={'index':'date', 0:'festivity_name'})\n        festivities_df['date'] = pd.to_datetime(festivities_df['date'])\n        if country == 'Sweden':\n            festivities_df = festivities_df[festivities_df['festivity_name']!='S\u00f6ndag']\n\n        additional_dates = [[pd.to_datetime(f'{year}-12-24'), 'Christmas Eve'] for year in years_list]\n        additional_dates += [[pd.to_datetime(f'{year}-12-29'), 'Peak in sales 1\/2'] for year in years_list]\n        additional_dates += [[pd.to_datetime(f'{year}-12-30'), 'Peak in sales 2\/2'] for year in years_list]\n        additional_dates += [[pd.to_datetime(f'{year}-12-31'), 'Saint Sylvester'] for year in years_list]\n        additional_dates += [[pd.to_datetime(f'{year}-01-01'), 'New Year'] for year in years_list]\n        additional_festivities_df = pd.DataFrame(additional_dates, columns=['date', 'festivity_name'])    \n\n        festivities_df = festivities_df.append(additional_festivities_df, ignore_index=True)\n        return festivities_df.sort_values('date')\n\n    def days_till_next_holiday(country, date):\n        country_holidays_dates = get_country_holidays(country, [date.year, date.year+1])['date']\n        next_date = min([holidays_date for holidays_date in country_holidays_dates if holidays_date >= date])\n        return (next_date - date).days\n    \n    df['days_till_next_holiday'] = df.apply(lambda x: days_till_next_holiday(x['country'], x['date']), axis=1)\n    \n    #### Seasonality\n    date_range = pd.date_range(start=min(df['date'] + datetime.timedelta(days=-60)), \n                               end=max(df['date'] + datetime.timedelta(days=60)), freq='D')\n    fourier = CalendarFourier(freq=\"A\", order=1)\n    dp = DeterministicProcess(\n            index=date_range,\n            constant=False,               # dummy feature for bias (y-intercept)\n            order=1,                     # trend (order 1 means linear)\n            seasonal=True,               # weekly seasonality (indicators)\n            additional_terms=[fourier],  # annual seasonality (fourier)\n            drop=True                   # drop terms to avoid collinearity\n    )\n    ts_features = dp.in_sample()\n    ts_features['wave'] = ts_features['sin(1,freq=A-DEC)'] + ts_features['cos(1,freq=A-DEC)']\n    ts_features['wave_mug'] = ts_features['wave'].shift(-shift_num)\n    ts_features['wave_mug_lag1'] = ts_features['wave'].shift(-shift_num - 1)\n    ts_features['wave_mug_lag2'] = ts_features['wave'].shift(-shift_num - 2)\n    ts_features['wave_mug_lag3'] = ts_features['wave'].shift(-shift_num - 3)\n    ts_features['wave_hat'] = ts_features['wave'].shift(shift_num)\n    ts_features['wave_hat_lag1'] = ts_features['wave'].shift(shift_num - 1)\n    ts_features['wave_hat_lag2'] = ts_features['wave'].shift(shift_num - 2)\n    ts_features['wave_hat_lag3'] = ts_features['wave'].shift(shift_num - 3)\n    ts_features.drop(['sin(1,freq=A-DEC)', 'cos(1,freq=A-DEC)'], inplace=True, axis=1)\n    df = df.merge(ts_features, left_on='date', right_index=True)\n    \n    #### GDP\n    gdp_df = pd.read_csv('..\/input\/gdp-data-2014-to-2019-finland-norway-sweden\/GDP_data_2014_to_2019_Finland_Norway_Sweden.csv', sep=';')\n    gdp_df.columns = ['year', 'Finland', 'Norway', 'Sweden']\n\n    gdp_melt_df = pd.melt(gdp_df, id_vars=['year'], value_vars=['Finland', 'Norway', 'Sweden'], var_name='country', value_name='gdp')\n    gdp_melt_df['year'] = 'Y' + gdp_melt_df['year'].astype(str)\n    df = df.merge(gdp_melt_df, how='left', on=['year', 'country'])\n    \n    #### DGP Percentage Change Between Years\n    gdp_df['Finland'] = gdp_df['Finland'].pct_change()\n    gdp_df['Norway'] = gdp_df['Norway'].pct_change()\n    gdp_df['Sweden'] = gdp_df['Sweden'].pct_change()\n    \n    gdp_melt_df = pd.melt(gdp_df, id_vars=['year'], value_vars=['Finland', 'Norway', 'Sweden'], var_name='country', value_name='gdp_pct')\n    gdp_melt_df['year'] = 'Y' + gdp_melt_df['year'].astype(str)\n    df = df.merge(gdp_melt_df, how='left', on=['year', 'country'])\n    \n    df.drop(columns=['date', 'MM-DD'],inplace=True) \n    return df","60b34d7d":"train_test = pd.concat([train, test])\ntrain_test = feature_eng(train_test)\n\ntrain_new = train_test.iloc[:len(train), :]\ntest_new = train_test.iloc[len(train):, :]\ntest_new.drop(['num_sold'], axis=1, inplace=True)","8f31178b":"train_new","a6f8420a":"%%capture\n!pip install pycaret[full]","90ba7f47":"NUM_FEATURES = list(test_new.loc[:,test_new.dtypes==np.int].columns)\nNUM_FEATURES_2 = list(test_new.loc[:,test_new.dtypes==np.float].columns)\nNUM_FEATURES.extend(NUM_FEATURES_2)\n\nFEATURES = list(test_new.columns)\nCAT_FEATURES = [feature for feature in FEATURES if feature not in NUM_FEATURES]\n\nprint(CAT_FEATURES)\nprint(NUM_FEATURES)","fda5126e":"from pycaret.regression import *\n\nreg = setup(data = train_new,\n            target = 'num_sold',\n            normalize = True, #normalisation helps some algorithms\n            normalize_method = 'robust', #resilient to outliers\n            transform_target = True, #applies transformation to target column\n            transform_target_method = 'box-cox',\n            data_split_shuffle = False, #so that we do not use \"future\" observations to predict \"past\" observations\n            create_clusters = True,\n            feature_interaction = True,\n            categorical_features = CAT_FEATURES,\n            numeric_features = NUM_FEATURES,\n            session_id = 42,\n            use_gpu = False,\n            silent = True,\n            fold = 10,\n            n_jobs = -1)","256e9310":"# Credit to https:\/\/www.kaggle.com\/c\/web-traffic-time-series-forecasting\/discussion\/36414\ndef SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) \/ 200.0\n    diff = np.abs(y_true - y_pred) \/ denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)\n\nadd_metric('SMAPE', 'SMAPE', SMAPE, greater_is_better=False)","9a5192e9":"N = 3\ntop = compare_models(sort = 'SMAPE', n_select = N)","df4522ea":"#tuned_top = [tune_model(i, optimize = 'SMAPE', choose_better=True, n_iter=100) for i in top]","15ccbafa":"blend = blend_models(top, optimize='SMAPE')\npredict_model(blend);","1e95948c":"final_blend = finalize_model(blend)\npredict_model(final_blend);","7c10f2b7":"plot_model(final_blend, plot='error')","9bcb0212":"import gc\ngc.collect()\nunseen_predictions_blend = predict_model(final_blend, data=test_new)\nunseen_predictions_blend.head()","f9173fb4":"gc.collect()\n\nassert(len(test.index)==len(unseen_predictions_blend))\n\nsub = pd.DataFrame(list(zip(test.index, unseen_predictions_blend.Label)),columns = ['row_id', 'num_sold'])\n\nsub.to_csv('submission.csv', index = False)\n\nprint(sub)","5f6c9b9c":"## Mug","cdf55af0":"# Data Preparation","b96ad046":"# Introduction\n\nHey, thanks for viewing my Kernel!\n\nIf you like my work, please, leave an upvote: it will be really appreciated and it will motivate me in offering more content to the Kaggle community ! \ud83d\ude0a","981afa7a":"# Feature Engineering","5ccf3b11":"# Time Series Analysis","9f03ed40":"## Hat","9fd3664c":"# Modeling"}}