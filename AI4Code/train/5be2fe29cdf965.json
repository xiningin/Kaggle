{"cell_type":{"7bfc7316":"code","afde3519":"code","780b5912":"code","fb9eaaef":"code","b81e3139":"code","bca5c705":"code","ee88efe4":"code","803f0784":"code","88e6c815":"code","8c9b6475":"code","9aab73ea":"code","40aeab83":"code","314489d7":"code","c8fc87f5":"code","d87f911d":"code","1ad5b48c":"code","20f0d5bf":"code","c7dcf83f":"code","30bda3d4":"code","4c426963":"code","ed1128e4":"code","df28a6ac":"code","62e0f99a":"code","1c1a2ceb":"markdown","7ab0ded9":"markdown","b2e1b930":"markdown","fb7e051f":"markdown","bc58b766":"markdown","6d02d746":"markdown","1a8c1561":"markdown","19b54c0b":"markdown","7f037760":"markdown","1928b3c3":"markdown","6e72b6c0":"markdown","4f10ed66":"markdown","14a08930":"markdown","106d8b48":"markdown","03f2bf3a":"markdown","38c21460":"markdown"},"source":{"7bfc7316":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FormatStrFormatter\nfrom matplotlib.ticker import FuncFormatter, MaxNLocator\nimport matplotlib.transforms as transforms\nimport seaborn as sns\nimport altair as alt\nimport plotly.express as px\nimport plotly.graph_objects as go\nsns.set(style='white', context='notebook', palette='deep')\n%matplotlib inline\n\nresults = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv', low_memory=False, skiprows=[1])","afde3519":"# importing country codes from Gitbut resource\ncountries = pd.read_csv('..\/input\/countries\/all\/all.csv')\ncountries.rename(columns={'name':'Country','alpha-3':'Country_Code','region':'Region','sub-region':'Sub-Region'}, inplace=True)\ncountries.drop(columns=['country-code','alpha-2','iso_3166-2','intermediate-region','region-code','sub-region-code','intermediate-region-code'], inplace=True)","780b5912":"# renaming some countries to look up country codes from Github resource\ndef cntry(results):\n    if results['Q3'] == 'Russia':\n        return 'Russian Federation'\n    elif results['Q3'] == 'Iran, Islamic Republic of...':\n        return \"Iran (Islamic Republic of)\"\n    elif results['Q3'] == 'South Korea':\n        return \"Korea (Democratic People's Republic of)\"\n    elif results['Q3'] == 'Taiwan':\n        return \"Taiwan, Province of China\"\n    elif results['Q3'] == 'Republic of Korea':\n        return \"Korea, Republic of\"\n    else:\n        return results['Q3']\n\nresults['Country'] = results.apply(cntry, axis=1)\n\n# look up country codes, region and subregion\nresults = results.merge(countries, on='Country', how='left')\n\n# rename selected questions\nresults['Age'] = results['Q1']\nresults['Gender'] = np.where((results['Q2'] == 'Man') | (results['Q2'] == 'Woman'), results['Q2'], 'Non-Binary')\nresults['Profession'] = results['Q5']\nresults['Education'] = results['Q4']\nresults['Background'] = results['Q6']\n\n# rename responses in Q38\nQ38_short ={'Basic statistical software (Microsoft Excel, Google Sheets, etc.)':'Excellers',\n           'Advanced statistical software (SPSS, SAS, etc.)':'SSPS_SAS',\n           'Business intelligence software (Salesforce, Tableau, Spotfire, etc.)':'BI_software',\n           'Local development environments (RStudio, JupyterLab, etc.)':'IDElers',\n           'Cloud-based data software & APIs (AWS, GCP, Azure, etc.)':'Cloud_based_tools',\n           'Other':'Other'}\n\nresults['Tools'] = results['Q38'].map(Q38_short)\n\n# rename columns for multi choice questions and change responses to binary\nresults = results.rename(columns={'Q7_Part_1':'Q7_Python',\n                                  'Q7_Part_2':'Q7_R',\n                                  'Q7_Part_3':'Q7_SQL',\n                                  'Q7_Part_4':'Q7_C',\n                                  'Q7_Part_5':'Q7_C++',\n                                  'Q7_Part_6':'Q7_Java',\n                                  'Q7_Part_7':'Q7_Javascript',\n                                  'Q7_Part_8':'Q7_Julia',\n                                  'Q7_Part_9':'Q7_Swift',\n                                  'Q7_Part_10':'Q7_Bash',\n                                  'Q7_Part_11':'Q7_MATLAB',\n                                  'Q7_Part_12':'Q7_None',\n                                  'Q7_OTHER':'Q7_Other'})\n\nresults['Q7_Python'] = np.where((results['Q7_Python'] == 'Python'),1,0)\nresults['Q7_R'] = np.where((results['Q7_R'] == 'R'),1,0)\nresults['Q7_SQL'] = np.where((results['Q7_SQL'] == 'SQL'),1,0)\nresults['Q7_C'] = np.where((results['Q7_C'] == 'C'),1,0)\nresults['Q7_C++'] = np.where((results['Q7_C++'] == 'C++'),1,0)\nresults['Q7_Java'] = np.where((results['Q7_Java'] == 'Java'),1,0)\nresults['Q7_Javascript'] = np.where((results['Q7_Javascript'] == 'Javascript'),1,0)\nresults['Q7_Julia'] = np.where((results['Q7_Julia'] == 'Julia'),1,0)\nresults['Q7_Swift'] = np.where((results['Q7_Swift'] == 'Swift'),1,0)\nresults['Q7_Bash'] = np.where((results['Q7_Bash'] == 'Bash'),1,0)\nresults['Q7_MATLAB'] = np.where((results['Q7_MATLAB'] == 'MATLAB'),1,0)\nresults['Q7_None'] = np.where((results['Q7_None'] == 'None'),1,0)\nresults['Q7_Other'] = np.where((results['Q7_Other'] == 'Other'),1,0)\n\nresults = results.rename(columns={'Q9_Part_1':'Q9_JupyterLab',\n                                  'Q9_Part_2':'Q9_RStudio',\n                                  'Q9_Part_3':'Q9_VisualStudio',\n                                  'Q9_Part_4':'Q9_VSCode',\n                                  'Q9_Part_5':'Q9_PyCharm',\n                                  'Q9_Part_6':'Q9_Spyder',\n                                  'Q9_Part_7':'Q9_Notepad++',\n                                  'Q9_Part_8':'Q9_Sublime_Text',\n                                  'Q9_Part_9':'Q9_Vim_Emacs',\n                                  'Q9_Part_10':'Q9_MATLAB',\n                                  'Q9_Part_11':'Q9_None',\n                                  'Q9_OTHER':'Q9_Other'})\n\nresults['Q9_JupyterLab'] = np.where(pd.isnull(results['Q9_JupyterLab']),0,1)\nresults['Q9_RStudio'] = np.where(pd.isnull(results['Q9_RStudio']),0,1)\nresults['Q9_VisualStudio'] = np.where(pd.isnull(results['Q9_VisualStudio']),0,1)\nresults['Q9_VSCode'] = np.where(pd.isnull(results['Q9_VSCode']),0,1)\nresults['Q9_PyCharm'] = np.where(pd.isnull(results['Q9_PyCharm']),0,1)\nresults['Q9_Spyder'] = np.where(pd.isnull(results['Q9_Spyder']),0,1)\nresults['Q9_Notepad++'] = np.where(pd.isnull(results['Q9_Notepad++']),0,1)\nresults['Q9_Sublime_Text'] = np.where(pd.isnull(results['Q9_Sublime_Text']),0,1)\nresults['Q9_Vim_Emacs'] = np.where(pd.isnull(results['Q9_Vim_Emacs']),0,1)\nresults['Q9_MATLAB'] = np.where(pd.isnull(results['Q9_MATLAB']),0,1)\nresults['Q9_None'] = np.where(pd.isnull(results['Q9_None']),0,1)\nresults['Q9_Other'] = np.where(pd.isnull(results['Q9_Other']),0,1)\n\nresults = results.rename(columns={'Q14_Part_1':'Q14_Matplotlib',\n                        'Q14_Part_2':'Q14_Seaborn',\n                        'Q14_Part_3':'Q14_Plotly',\n                        'Q14_Part_4':'Q14_Ggplot',\n                        'Q14_Part_5':'Q14_Shiny',\n                        'Q14_Part_6':'Q14_D3',\n                        'Q14_Part_7':'Q14_Altair',\n                        'Q14_Part_8':'Q14_Bokeh',\n                        'Q14_Part_9':'Q14_Geoplotlib',\n                        'Q14_Part_10':'Q14_Folium',\n                        'Q14_Part_11':'Q14_None',\n                        'Q14_OTHER':'Q14_Other'})\n\nresults['Q14_Matplotlib'] = results['Q14_Matplotlib'].apply(lambda x: 1 if not pd.isnull(x) else 0)\nresults['Q14_Seaborn'] = results['Q14_Seaborn'].apply(lambda x: 1 if not pd.isnull(x) else 0)\nresults['Q14_Plotly'] = results['Q14_Plotly'].apply(lambda x: 1 if not pd.isnull(x) else 0)\nresults['Q14_Ggplot'] = results['Q14_Ggplot'].apply(lambda x: 1 if not pd.isnull(x) else 0)\nresults['Q14_Shiny'] = results['Q14_Shiny'].apply(lambda x: 1 if not pd.isnull(x) else 0)\nresults['Q14_D3'] = results['Q14_D3'].apply(lambda x: 1 if not pd.isnull(x) else 0)\nresults['Q14_Altair'] = results['Q14_Altair'].apply(lambda x: 1 if not pd.isnull(x) else 0)\nresults['Q14_Bokeh'] = results['Q14_Bokeh'].apply(lambda x: 1 if not pd.isnull(x) else 0)\nresults['Q14_Geoplotlib'] = results['Q14_Geoplotlib'].apply(lambda x: 1 if not pd.isnull(x) else 0)\nresults['Q14_Folium'] = results['Q14_Folium'].apply(lambda x: 1 if not pd.isnull(x) else 0)\nresults['Q14_None'] = results['Q14_None'].apply(lambda x: 1 if not pd.isnull(x) else 0)\nresults['Q14_Other'] = results['Q14_Other'].apply(lambda x: 1 if not pd.isnull(x) else 0)\n\nresults = results.rename(columns={'Q23_Part_1':'Q23_Analyze_and_understand_data',\n                                  'Q23_Part_2':'Q23_Build_run_data_infrastructure',\n                                  'Q23_Part_3':'Q23_Build_prototypes_to_explore_ML',\n                                  'Q23_Part_4':'Q23_Build_run_ML_service',\n                                  'Q23_Part_5':'Q23_Experiment_to_improve_existing_ML',\n                                  'Q23_Part_6':'Q23_Research_to_advance_ML',\n                                  'Q23_Part_7':'Q23_None_of_the_above',\n                                  'Q23_OTHER':'Q23_Other'})\n\nresults['Q23_Analyze_and_understand_data'] = np.where(pd.isnull(results['Q23_Analyze_and_understand_data']),0,1)\nresults['Q23_Build_run_data_infrastructure'] = np.where(pd.isnull(results['Q23_Build_run_data_infrastructure']),0,1)\nresults['Q23_Build_prototypes_to_explore_ML'] = np.where(pd.isnull(results['Q23_Build_prototypes_to_explore_ML']),0,1)\nresults['Q23_Build_run_ML_service'] = np.where(pd.isnull(results['Q23_Build_run_ML_service']),0,1)\nresults['Q23_Experiment_to_improve_existing_ML'] = np.where(pd.isnull(results['Q23_Experiment_to_improve_existing_ML']),0,1)\nresults['Q23_Research_to_advance_ML'] = np.where(pd.isnull(results['Q23_Research_to_advance_ML']),0,1)\nresults['Q23_None_of_the_above'] = np.where(pd.isnull(results['Q23_None_of_the_above']),0,1)\nresults['Q23_Other'] = np.where(pd.isnull(results['Q23_Other']),0,1)\n\nresults = results.rename(columns={'Q31_A_Part_1':'Q31_Amazon_QuickSight',\n                                  'Q31_A_Part_2':'Q31_Microsoft_Power_BI',\n                                  'Q31_A_Part_3':'Q31_Google_Data_Studio',\n                                  'Q31_A_Part_4':'Q31_Looker',\n                                  'Q31_A_Part_5':'Q31_Tableau',\n                                  'Q31_A_Part_6':'Q31_Salesforce',\n                                  'Q31_A_Part_7':'Q31_Einstein_Analytics',\n                                  'Q31_A_Part_8':'Q31_Qlik',\n                                  'Q31_A_Part_9':'Q31_Domo',\n                                  'Q31_A_Part_10':'Q31_TIBCO_Spotfire',\n                                  'Q31_A_Part_11':'Q31_Alteryx',\n                                  'Q31_A_Part_12':'Q31_Sisense',\n                                  'Q31_A_Part_13':'Q31_SAP_Analytics_Cloud',\n                                  'Q31_A_Part_14':'Q31_None',\n                                  'Q31_A_OTHER':'Q31_Other'})\n\nresults['Q31_Amazon_QuickSight'] = np.where(pd.isnull(results['Q31_Amazon_QuickSight']),0,1)\nresults['Q31_Microsoft_Power_BI'] = np.where(pd.isnull(results['Q31_Microsoft_Power_BI']),0,1)\nresults['Q31_Google_Data_Studio'] = np.where(pd.isnull(results['Q31_Google_Data_Studio']),0,1)\nresults['Q31_Looker'] = np.where(pd.isnull(results['Q31_Looker']),0,1)\nresults['Q31_Tableau'] = np.where(pd.isnull(results['Q31_Tableau']),0,1)\nresults['Q31_Salesforce'] = np.where(pd.isnull(results['Q31_Salesforce']),0,1)\nresults['Q31_Einstein_Analytics'] = np.where(pd.isnull(results['Q31_Einstein_Analytics']),0,1)\nresults['Q31_Qlik'] = np.where(pd.isnull(results['Q31_Qlik']),0,1)\nresults['Q31_Domo'] = np.where(pd.isnull(results['Q31_Domo']),0,1)\nresults['Q31_Alteryx'] = np.where(pd.isnull(results['Q31_Alteryx']),0,1)\nresults['Q31_Sisense'] = np.where(pd.isnull(results['Q31_Sisense']),0,1)\nresults['Q31_SAP_Analytics_Cloud'] = np.where(pd.isnull(results['Q31_SAP_Analytics_Cloud']),0,1)\nresults['Q31_None'] = np.where(pd.isnull(results['Q31_None']),0,1)\nresults['Q31_Other'] = np.where(pd.isnull(results['Q31_Other']),0,1)\n\nresults = results.rename(columns={'Q37_Part_1':'Q37_Coursera',\n                                  'Q37_Part_2':'Q37_edX',\n                                  'Q37_Part_3':'Q37_Kaggle_Learn_Courses',\n                                  'Q37_Part_4':'Q37_DataCamp',\n                                  'Q37_Part_5':'Q37_Fast.ai',\n                                  'Q37_Part_6':'Q37_Udacity',\n                                  'Q37_Part_7':'Q37_Udemy',\n                                  'Q37_Part_8':'Q37_LinkedIn_Learning',\n                                  'Q37_Part_9':'Q37_Cloud_cert_programs',\n                                  'Q37_Part_10':'Q37_University',\n                                  'Q37_Part_11':'Q37_None',\n                                  'Q37_OTHER':'Q37_Other'})\n\nresults['Q37_Coursera'] = np.where(pd.isnull(results['Q37_Coursera']),0,1)\nresults['Q37_edX'] = np.where(pd.isnull(results['Q37_edX']),0,1)\nresults['Q37_Kaggle_Learn_Courses'] = np.where(pd.isnull(results['Q37_Kaggle_Learn_Courses']),0,1)\nresults['Q37_DataCamp'] = np.where(pd.isnull(results['Q37_DataCamp']),0,1)\nresults['Q37_Fast.ai'] = np.where(pd.isnull(results['Q37_Fast.ai']),0,1)\nresults['Q37_Udacity'] = np.where(pd.isnull(results['Q37_Udacity']),0,1)\nresults['Q37_Udemy'] = np.where(pd.isnull(results['Q37_Udemy']),0,1)\nresults['Q37_LinkedIn_Learning'] = np.where(pd.isnull(results['Q37_LinkedIn_Learning']),0,1)\nresults['Q37_Cloud_cert_programs'] = np.where(pd.isnull(results['Q37_Cloud_cert_programs']),0,1)\nresults['Q37_University'] = np.where(pd.isnull(results['Q37_University']),0,1)\nresults['Q37_None'] = np.where(pd.isnull(results['Q37_None']),0,1)\nresults['Q37_Other'] = np.where(pd.isnull(results['Q37_Other']),0,1)\n\n# change salary ranges to numeric based on upper range\nresults[['Q24','Upper']] = results['Q24'].str.split('-',n=1,expand=True)\nresults['Upper'] = results['Upper'].str.replace(',', '').astype(float)","fb9eaaef":"# preview dataframe\nresults.head()","b81e3139":"# fill null values for Tools with 'No response'\nresults['Tools'].fillna('No response', inplace=True)\n\n# filter dataframe on Excel and Jupyter users only\nresults_short = results[results.Tools.str.contains(\"Excellers|IDElers\")]\n\nxls_results = results[results['Tools'].str.contains(\"Excellers\") == True]\n\nide_results = results[results['Tools'].str.contains(\"IDElers\") == True]","bca5c705":"# define colour schemes\ndeep_colors=['#ceecb3','#9cdba5','#6fc9a3','#4CA699','#44829b','#3e528f','#4C3C6C','#362b4d','#271a2c']\ndeep_colors2=['#ceecb3','#6fc9a3','#4CA699','#44829b','#4C3C6C','#271a2c']\ndeep_2 = ['#9cdba5','#44829b']\ndeep_2a = ['#4CA699','#4C3C6C']","ee88efe4":"# Show breakdown of responses for question 38 \"What is the primary tool that you use at work or school to analyze data?\"\nresults.groupby('Tools')['Tools'].count().to_frame().rename(columns={'Tools':'Responses'}).sort_values(by='Responses', ascending=False)","803f0784":"# Breakdown of Q38 responses (data analysis tools) excl. null values\nchart = results.loc[(results['Tools'] != 'No response')].groupby('Tools')['Tools'].count()\npie, ax = plt.subplots(figsize=(10,6), subplot_kw=dict(aspect=\"equal\"))\nlabels = chart.keys()\n\nax.set_title(\"Figure 1: Breakdown of most frequently used data analysis tools\", size=14, weight=\"bold\")\nplt.pie(x=chart, autopct=\"%.1f%%\", labels=labels, colors=deep_colors, pctdistance=0.8, labeldistance=1.1, textprops={'fontsize': 11, 'color':\"black\"})\npie.savefig(\"DAtoolsPieChart.png\")","88e6c815":"# data analysis tools used by gender\ndf = pd.crosstab(results['Tools'].loc[(results['Tools'] !='No response')],results['Gender'])\ndf.plot(kind='pie',subplots=True,figsize=(16, 6),legend=False,wedgeprops=dict(width=0.5),autopct=\"%.1f%%\",\n        pctdistance=0.8, labeldistance=1.1, colors=deep_colors, radius=0.9,textprops={'fontsize': 9, 'color':\"black\"})\nplt.title(\"Figure 2: Breakdown of most frequently used data analysis tools by gender\", size=14, weight=\"bold\", ha='right')\nplt.savefig(\"Gender_DAtools_Pie.png\")","8c9b6475":"# Age pyramid Excellers vs IDElers\nAge = pd.crosstab(results['Age'],results['Tools']).apply(lambda c: c\/c.sum(), axis=0).round(3)*100\nAge['Diff'] = Age['Excellers']-Age['IDElers']\nAge.reset_index(inplace=True)\n\nAge = Age.loc[(Age['Age'] != 'No response')]\nAge[['Age','Excellers','IDElers']]\n\nAges = Age['Age']\nnum_Ages = len(Ages)\n\nxls = Age['Excellers']\nide = Age['IDElers']\n\npos = np.arange(num_Ages)+0.5\n\nfig = plt.figure(facecolor='white', edgecolor='none', figsize=(10,6))\nax_xls = fig.add_axes([0.05,0.1,0.42,0.8])\nax_ide = fig.add_axes([0.53,0.1,0.40,0.8])\n        \nax_xls.xaxis.set_ticks_position('top')\nax_ide.xaxis.set_ticks_position('top')\n\nax_xls.barh(pos, xls, align='center', color='#4CA699')\nax_xls.set_yticks([])\nax_xls.set_xlim(0,25)\nax_xls.invert_xaxis()\nax_xls.grid(False)\n\nax_ide.barh(pos, ide, align='center', color='#4C3C6C')\nax_ide.set_yticks([])\nax_ide.set_xlim(0,25)\nax_ide.grid(False)\n\ntransform = transforms.blended_transform_factory(fig.transFigure, ax_ide.transData)\nfor i, label in enumerate(Ages):\n    ax_ide.text(0.5, i+0.5, label, ha='center', va='center', fontsize=12, transform = transform)\n\nax_ide.set_title('IDElers', x=0.16, y=1.025, fontsize=13, weight='bold', pad=20)\nax_xls.set_title('Excellers', x=0.725, y=1.025, fontsize=13, weight='bold', pad=20)\n\nplt.suptitle(\"Figure 3: Age profile of Excellers and IDElers\", size=14, weight=\"bold\", ha='right', y=1.1)\n\nplt.show()\nfig.savefig(\"Age_pyramid.png\")","9aab73ea":"Age_Tools = pd.crosstab(results_short['Tools'], results_short['Q1']).apply(lambda r: r\/r.sum(), axis=1).cumsum(axis=1)\nplt.figure(figsize=(16,2))\nsns.heatmap(Age_Tools, cmap='mako_r', annot=True, fmt='.1%', annot_kws={\"size\":11})\nplt.title('Figure 3a: Cumulative age profile of Excellers and IDElers', weight='bold', pad=20, size=14)\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks(np.arange(2)+0.5,('Excellers','IDElers'), rotation=0, fontsize=\"10\", va=\"center\")\nplt.show()","40aeab83":"ME_list = ['Egypt','Iran (Islamic Republic of)', 'Iraq','Saudi Arabia','Yemen','Syria','Jordan','United Arab Emirates',\n           'Israel','Lybia','Lebanon','Oman','Palestine (West Bank and Gaza Strip)','Kuwait','Qatar','Bahrain']\n\nresults.loc[results['Country'].isin(ME_list), 'Region'] = 'Middle East'\nregion = pd.crosstab(index=[results['Region'],results['Country']], columns=results['Tools'],\n                     values=results['Tools'], aggfunc='count').fillna(0).apply(lambda r: r\/r.sum(), axis=1).round(3)*100\nchart = region['Excellers']\n\nax = chart.sort_index(level=0).unstack().transpose().plot(kind='bar', stacked=True, figsize=(15,6), legend=False, color=deep_colors2)\n\nplt.legend(loc='upper left', bbox_to_anchor=(1.01,1.01))\nplt.xlabel('')\nthreshold = region['Excellers'].mean()\n\nchart2 = chart.reset_index()\n\nthresh_AF = chart2['Excellers'].loc[(chart2['Region']=='Africa')].mean()\nthresh_AM = chart2['Excellers'].loc[(chart2['Region']=='Americas')].mean()\nthresh_AS = chart2['Excellers'].loc[(chart2['Region']=='Asia')].mean()\nthresh_EU = chart2['Excellers'].loc[(chart2['Region']=='Europe')].mean()\nthresh_ME = chart2['Excellers'].loc[(chart2['Region']=='Middle East')].mean()\nthresh_OC = chart2['Excellers'].loc[(chart2['Region']=='Oceania')].mean()\n\nn = -1\nnAF = n+chart2['Excellers'].loc[(chart2['Region']=='Africa')].count()\nnAM = nAF+chart2['Excellers'].loc[(chart2['Region']=='Americas')].count()\nnAS = nAM+chart2['Excellers'].loc[(chart2['Region']=='Asia')].count()\nnEU = nAS+chart2['Excellers'].loc[(chart2['Region']=='Europe')].count()\nnME = nEU+chart2['Excellers'].loc[(chart2['Region']=='Middle East')].count()\nnOC = nME+chart2['Excellers'].loc[(chart2['Region']=='Oceania')].count()\n\nmAF = int(chart2['Excellers'].loc[(chart2['Region']=='Africa')].mean())\nmAM = int(chart2['Excellers'].loc[(chart2['Region']=='Americas')].mean())\nmAS = int(chart2['Excellers'].loc[(chart2['Region']=='Asia')].mean())\nmEU = int(chart2['Excellers'].loc[(chart2['Region']=='Europe')].mean())\nmME = int(chart2['Excellers'].loc[(chart2['Region']=='Middle East')].mean())\nmOC = int(chart2['Excellers'].loc[(chart2['Region']=='Oceania')].mean())\n\nax.plot([n, nAF+0.5], [thresh_AF, thresh_AF], color='#ceecb3', linestyle='--', linewidth=1.5)\nax.plot([nAF+0.5, nAM+0.5], [thresh_AM, thresh_AM], color='#6fc9a3', linestyle='--', linewidth=1.5)\nax.plot([nAM+0.5, nAS+0.5], [thresh_AS, thresh_AS], color='#4CA699', linestyle='--', linewidth=1.5)\nax.plot([nAS+0.5, nEU+0.5], [thresh_EU, thresh_EU], color='#44829b', linestyle='--', linewidth=1.5)\nax.plot([nEU+0.5, nME+0.5], [thresh_ME, thresh_ME], color='#4C3C6C', linestyle='--', linewidth=1.5)\nax.plot([nME+0.5, nOC+0.5], [thresh_OC, thresh_OC], color='#271a2c', linestyle='--', linewidth=1.5)\n\nplt.ylim(0,45)\nplt.annotate(f\"mean:{mAF}%\", xy=((n+nAF)\/2, mAF), xytext=((n+nAF)\/2,mAF+3), ha='center', size=12,arrowprops=dict(facecolor='#ceecb3'))\nplt.annotate(f\"mean:{mAM}%\", xy=((nAF+nAM)\/2, mAM), xytext=((nAF+nAM)\/2,mAM+3), ha='center', size=12, arrowprops=dict(facecolor='#6fc9a3'))\nplt.annotate(f\"mean:{mAS}%\", xy=((nAM+nAS)\/2, mAS), xytext=((nAM+nAS)\/2,mAS+3), ha='center', size=12, arrowprops=dict(facecolor='#4CA699'))\nplt.annotate(f\"mean:{mEU}%\", xy=((nAS+nEU)\/2, mEU), xytext=((nAS+nEU)\/2,mEU+3), ha='center', size=12, arrowprops=dict(facecolor='#44829b'))\nplt.annotate(f\"mean:{mME}%\", xy=((nEU+nME)\/2, mME), xytext=((nEU+nME)\/2,mME+3), ha='center', size=12, arrowprops=dict(facecolor='#4C3C6C'))\nplt.annotate(f\"mean:{mOC}%\", xy=((nME+nOC)\/2+0.5, mOC), xytext=((nME+nOC)\/2+0.5,mOC+3), size=12, arrowprops=dict(facecolor='#271a2c'))\n\nplt.title('Figure 4: Breakdown of Excel uptake rates by Region and Country', size=14, weight='bold',pad=15)\n\nplt.grid(False)","314489d7":"# Excel uptake by country\ntools_cntry = pd.crosstab(results_short['Country'],results_short['Tools']).reset_index()\ncntry = results.groupby('Country')['Tools'].count().to_frame()\nPct_tools_cntry = cntry.merge(tools_cntry, on='Country', how='left')\nPct_tools_cntry.rename(columns={'Tools':'Total'}, inplace=True)\nPct_tools_cntry['Pct_xls'] = (Pct_tools_cntry['Excellers']\/Pct_tools_cntry['Total']).round(3)*100\nPct_tools_cntry['Pct_ide'] = (Pct_tools_cntry['IDElers']\/Pct_tools_cntry['Total']).round(3)*100\nPct_tools_cntry['Pct_diff'] = Pct_tools_cntry['Pct_xls']-Pct_tools_cntry['Pct_ide']\nPct_tools_cntry = Pct_tools_cntry.merge(countries, on='Country', how='left')\n\nfig = px.choropleth(data_frame=Pct_tools_cntry,\n                    locations='Country_Code',\n                    color='Pct_xls',\n                    color_continuous_scale=deep_colors,\n                    range_color=(0, 40),\n                    hover_name='Country', \n                    title='Figure 4a: Percentage of Excellers amongst total respondents per country')\nfig.show()","c8fc87f5":"cntry_df = results.groupby('Country')['Age'].count().to_frame()\nxls = xls_results.groupby('Country')['Age'].count().to_frame()\ntop_xls_cnty = cntry_df.merge(xls['Age'], on='Country', how='left')\ntop_xls_cnty.rename(columns={'Age_x':'Total', 'Age_y':'xls'}, inplace=True)\ntop_xls_cnty['Pct'] = (top_xls_cnty['xls']\/top_xls_cnty['Total']).round(3)*100\ntop_xls_cnty.reset_index(inplace=True)\n\ncntry_list = top_xls_cnty['Country'].unique()\n\n# threshold code based on https:\/\/stackoverflow.com\/questions\/28129606\/how-to-create-a-matplotlib-bar-chart-with-a-threshold-line\nthreshold = top_xls_cnty['Pct'].mean()\nvalues = top_xls_cnty['Pct']\nx = range(len(values))\n\nabove_threshold = np.maximum(values - threshold, 0)\nbelow_threshold = np.minimum(values, threshold)\n\nfig, ax = plt.subplots(figsize=(16,6))\np1 = ax.bar(x, below_threshold, 0.5, color='#6fc9a3')\np2 = ax.bar(x, above_threshold, 0.5, color=\"firebrick\", bottom=below_threshold)\n\nlabels = list(cntry_list)\n\ndef format_fn(tick_val, tick_pos):\n    if int(tick_val) in x:\n        return labels[int(tick_val)]\n    else:\n        return ''\nax.xaxis.set_major_formatter(FuncFormatter(format_fn))\nax.xaxis.set_major_locator(MaxNLocator(55))\n\nN = 55\nind = np.arange(N)\nplt.xticks(ind, rotation=90)\n\nplt.ylabel(\"Percentage of Excel users\")\nplt.ylim(0,45)\nplt.grid(False)\nplt.xlim(-1,55)\nax.plot([-1, 55], [threshold, threshold], \"k--\", linewidth=1)\n\ndef add_value_labels(ax, spacing=5):\n\n    for rect1,rect2 in zip(p1,p2):\n        h1 = rect1.get_height()\n        h2 = rect2.get_height()\n        plt.text(rect1.get_x()+rect1.get_width()\/2., h1+h2, \"%d%%\" % (h1+h2), ha ='center', va='bottom',\n                fontsize=8)\n        \nadd_value_labels(ax)\n\nplt.title('Figure 4b: Breakdown of Excel uptake rates by country of residence', size=14, weight='bold',pad=15)\n\nfig.savefig(\"threshold-plot.png\")","d87f911d":"software_edu = pd.crosstab(results['Tools'],results['Education']).apply(lambda r: (r\/r.sum())*100, axis=1).round(1).reset_index()\nsoftware_edu = software_edu[software_edu.Tools.str.contains(\"Excellers|IDElers\")]\n\nedu = ['Tools','I prefer not to answer','No formal education past high school', \"Some college\/university study without earning a bachelor\u2019s degree\", \n       'Professional degree', \"Bachelor\u2019s degree\", \"Master\u2019s degree\",'Doctoral degree']\n\nsoftware_edu = software_edu.reindex(edu, axis=\"columns\")\nsoftware_edu.set_index('Tools', inplace=True)\n\nsns.set_style('whitegrid')\nplt.figure(figsize=(12,4))\nax = software_edu.plot(kind='bar', stacked=False, figsize=(16,6), color=deep_colors, legend=False)\nlegend = plt.legend(frameon=False, loc='upper left')\nplt.xlabel('')\nplt.ylabel(\"Percent of Respondents\", size=12)\nplt.ylim(0,55)\nax.grid(False)\n\nfor p in ax.patches[1:]:\n    h = p.get_height()\n    x = p.get_x()+p.get_width()\/2.\n    if h != 0:\n        ax.annotate(\"%g\" % p.get_height(), xy=(x,h), xytext=(0,4), rotation=90, size=11, weight='bold',\n                   textcoords=\"offset points\", ha=\"center\", va=\"bottom\")\nplt.title('Figure 5: Education levels of Excellers and IDElers', size=14, weight='bold',pad=15)\nplt.show()","1ad5b48c":"prof_tools = pd.crosstab(results['Profession'],results['Tools'], margins=True, margins_name='Total').iloc[:-1].reset_index()\nprof_tools['Pct_xls'] = (prof_tools['Excellers']\/prof_tools['Total'])*100\nprof_tools['Pct_ide'] = (prof_tools['IDElers']\/prof_tools['Total'])*100\n\nax = prof_tools[['Profession','Pct_xls','Pct_ide']].loc[(prof_tools['Profession'] != 'No response')].set_index('Profession').sort_values(by='Pct_xls', ascending=False).plot(kind='bar', figsize=(16,6), color=deep_2a, legend=False)\nplt.xlabel(\"Profession\")\nplt.ylabel(\"Percentage of users\")\nplt.grid(False)\nplt.ylim(0,60)\nplt.legend(loc='upper left')\n\ndef add_value_labels(ax, spacing=5):\n\n    for rect in ax.patches:\n        y_value = rect.get_height()\n        x_value = rect.get_x() + rect.get_width() \/ 2\n \n        space = spacing\n        va = 'bottom'\n\n        if y_value < 0:\n            space *= -1\n            va = 'top'\n\n        label = \"{:.1f}\".format(y_value)\n\n        ax.annotate(\n            label,(x_value, y_value),xytext=(0, space),textcoords=\"offset points\",ha='center',rotation=90,va=va)\n\nadd_value_labels(ax)\n\nplt.title('Figure 6: Breakdown of professions by Excellers and IDElers', size=14, weight='bold',pad=15)\nplt.savefig(\"Roles-plot.png\")","20f0d5bf":"Q23_list = ['Q23_Analyze_and_understand_data','Q23_Build_run_data_infrastructure','Q23_Build_prototypes_to_explore_ML',\n           'Q23_Build_run_ML_service','Q23_Experiment_to_improve_existing_ML','Q23_Research_to_advance_ML',\n           'Q23_None_of_the_above','Q23_Other']\n\ntask = results_short.groupby(\"Tools\")[Q23_list].sum().apply(lambda r: r\/r.sum(), axis=1).round(3)*100\n\nax = task.plot(kind='bar',stacked=False, color=deep_colors, figsize=(10,6))\nplt.grid(False)\nplt.legend(loc='upper left', bbox_to_anchor=(1.05, 1))\nplt.ylabel('Percent of users')\nplt.xlabel('')\nplt.ylim(0,35)\n\ndef add_value_labels(ax, spacing=5):\n\n    for rect in ax.patches:\n        y_value = rect.get_height()\n        x_value = rect.get_x() + rect.get_width() \/ 2\n \n        space = spacing\n        va = 'bottom'\n\n        if y_value < 0:\n            space *= -1\n            va = 'top'\n\n        label = \"{:.1f}\".format(y_value)\n\n        ax.annotate(\n            label,(x_value, y_value),xytext=(0, space),textcoords=\"offset points\",ha='center',rotation=90,va=va)                      \n\nadd_value_labels(ax)\n\nplt.title('Figure 7: Breakdown of main works tasks for Excellers and IDElers', size=14, weight='bold',pad=15)\nplt.savefig(\"Tasks-plot.png\")","c7dcf83f":"sal = pd.crosstab(results['Upper'],results['Tools']).apply(lambda c: c\/c.sum(), axis=0).cumsum(axis=0).round(3)*100\nsal.reset_index()\nsal['Diff'] = sal['Excellers']-sal['IDElers']\n\nax = sal[['Excellers','IDElers']].plot(kind='line',figsize=(16,8), color=deep_2a, legend=False)\nplt.xlabel(\"Upper Salary Range\")\nplt.title(\"Figure 8: Cumulative percentage point difference in salaries between Excellers and IDElers\", size=14, weight='bold',pad=15)\nplt.ylabel(\"Percentage Points\")\nax.grid(False)\nplt.legend()\nax.axhline(y=80, color='darkgray', linewidth=1, linestyle='--')\nax.set_xlim(0,500000)\nplt.annotate(\"$59,999 US\", xy=(60000, 80), xytext=(60000,90), size=12, arrowprops=dict(facecolor='#4CA699', lw=1))\nplt.annotate(\"$79,999 US\", xy=(80000, 80), xytext=(80000,70), size=12, arrowprops=dict(facecolor='#4C3C6C', lw=1))   \nplt.show()","30bda3d4":"software_exp = pd.crosstab(results_short['Tools'],results_short['Background'].dropna()).apply(lambda r: r\/r.sum(), axis=1).round(3)*100\nexp = ['I have never written code', '< 1 years', '1-2 years', '3-5 years', '5-10 years', '10-20 years', '20+ years']\n\nsoftware_exp = software_exp.reindex(exp, axis=\"columns\")\n\nax = software_exp.transpose().plot(kind='bar', color=deep_2, legend=False, figsize=(16,6), grid=False)\nplt.xlabel(\"Percent of respondents\")\nplt.ylabel('Coding experience')\nplt.ylim(0,35)\nplt.legend(loc='upper right')\n\ndef add_value_labels(ax, spacing=5):\n\n    for rect in ax.patches:\n        y_value = rect.get_height()\n        x_value = rect.get_x() + rect.get_width() \/ 2\n \n        space = spacing\n        va = 'bottom'\n\n        if y_value < 0:\n            space *= -1\n            va = 'top'\n\n        label = \"{:.1f}\".format(y_value)\n\n        ax.annotate(\n            label,(x_value, y_value),xytext=(0, space),textcoords=\"offset points\",ha='center',rotation=90,va=va)                      \n\nadd_value_labels(ax)\nplt.title('Figure 9: Coding experience of Excellers vs IDElers', size=14, weight='bold',pad=15)\nplt.savefig(\"Experience_plot.png\")","4c426963":"# create lists for multi choice questions\nQ7_list = ['Q7_Python','Q7_R','Q7_SQL','Q7_C','Q7_C++','Q7_Java','Q7_Javascript','Q7_Julia','Q7_Swift','Q7_Bash','Q7_MATLAB',\n          'Q7_None','Q7_Other']\nQ9_list = ['Q9_JupyterLab','Q9_RStudio','Q9_VisualStudio','Q9_VSCode','Q9_PyCharm','Q9_Spyder','Q9_Notepad++','Q9_Sublime_Text',\n          'Q9_Vim_Emacs','Q9_MATLAB','Q9_None','Q9_Other']\nQ14_list = ['Q14_Matplotlib','Q14_Seaborn','Q14_Plotly','Q14_Ggplot','Q14_Shiny','Q14_D3','Q14_Altair','Q14_Bokeh',\n            'Q14_Geoplotlib','Q14_Folium','Q14_Other']\nQ31_list = ['Q31_Amazon_QuickSight','Q31_Microsoft_Power_BI','Q31_Google_Data_Studio','Q31_Looker','Q31_Tableau',\n            'Q31_Salesforce','Q31_Einstein_Analytics','Q31_Qlik','Q31_Domo','Q31_TIBCO_Spotfire','Q31_Alteryx','Q31_Sisense',\n            'Q31_SAP_Analytics_Cloud','Q31_None','Q31_Other']","ed1128e4":"Plang = results_short.groupby('Tools')[Q7_list].sum().apply(lambda r: r\/r.sum(), axis=1).round(3)\nIDE = results_short.groupby('Tools')[Q9_list].sum().apply(lambda r: r\/r.sum(), axis=1).round(3)\nvis_tool = results_short.groupby('Tools')[Q14_list].sum().apply(lambda r: r\/r.sum(), axis=1).round(3)\nBI_tool = results_short.groupby('Tools')[Q31_list].sum().apply(lambda r: r\/r.sum(), axis=1).round(3)\n\nfig, (axis1,axis2,axis3,axis4) = plt.subplots(1,4)\nfig.suptitle('Figure 10: Programming and Tool usage of Excellers and IDElers', fontsize=14, weight='bold', y=1.8, x=0.8)\n\nax1 = sns.heatmap(Plang.transpose(), cmap='mako_r', annot=True, fmt='.1%', cbar=False, ax=axis1)\nax2 = sns.heatmap(IDE.transpose(), cmap='mako_r', annot=True, fmt='.1%', cbar=False, ax=axis2)\nax3 = sns.heatmap(vis_tool.transpose(), cmap='mako_r', annot=True, fmt='.1%', cbar=False, ax=axis3)\nax4 = sns.heatmap(BI_tool.transpose(), cmap='mako_r', annot=True, fmt='.1%', cbar=False, ax=axis4)\n\nax1.set_title('Programming languages')\nax2.set_title('IDE used')\nax3.set_title('Visualisation libraries used')\nax4.set_title('BI tools')\n\naxis1.set_position([0.2,1.0, 0.5, 0.6])\naxis2.set_position([1.2,1.0, 0.5, 0.6])\naxis3.set_position([0.2,0.0, 0.5, 0.6])\naxis4.set_position([1.2,0.0, 0.5, 0.6])","df28a6ac":"Q37_list = ['Q37_Coursera','Q37_edX','Q37_Kaggle_Learn_Courses','Q37_DataCamp','Q37_Fast.ai','Q37_Udacity','Q37_Udemy',\n            'Q37_LinkedIn_Learning','Q37_Cloud_cert_programs','Q37_University','Q37_None','Q37_Other']\n\nlearn = results_short.groupby('Tools')[Q37_list].sum().apply(lambda r: r\/r.sum(), axis=1).round(3)\nplt.figure(figsize=(16,2))\nsns.heatmap(learn, cmap='mako_r', annot=True, fmt='.1%',annot_kws={\"size\":11})\nplt.title('Figure 11: Learning resources used by Excellers and IDElers', weight='bold', pad=15, size=14)\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks(np.arange(2)+0.5,('Excellers','IDElers'), rotation=0, fontsize=\"10\", va=\"center\")\nplt.show()","62e0f99a":"recomm = pd.crosstab(results_short['Tools'],results_short['Q8']).apply(lambda r: r\/r.sum(), axis=1)\nplt.figure(figsize=(16,2))\nsns.heatmap(recomm, cmap='mako_r', annot=True, fmt='.1%',annot_kws={\"size\":11})\nplt.title('Figure 12: Number 1 Programming Language recommended by Excellers and IDElers', weight='bold', pad=15, size=14)\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks(np.arange(2)+0.5,('Excellers','IDElers'), rotation=0, fontsize=\"10\", va=\"center\")\nplt.show()","1c1a2ceb":"#### Learning\nFinally we look at learning resources used by Excellers and IDElers as well as their recommendations in terms of what programming language to learn first for aspiring data scientists.\n\n##### Learning resources used\nCoursera is the most popular learning resource among both groups (21% and 22%, respectively, fig 11) followed by Kaggle and Udemy. A slightly higher share of IDElers made use of university courses compared to Excellers.\n\n##### Programming language recommended\nPython was by far the most recommended programming language to learn with over 81% of respondents from both groups selecting it as the top choice (fig 12). In second place was R, however, only ranking 0.1%pt ahead of SQL for Excellers.","7ab0ded9":"### 3. Summary of findings\n\nBased on the 2020 DS & ML survey, 'Excelling' Kagglers are:\n* marginally older than those using Local IDEs as their main tool for data analysis;\n* they are pretty similar in terms of gender, with women having a marginally stronger tendency to use Excel and BI tools to analyse data;\n* in terms of country of residence, Excellers are slightly more likely to reside in Middle Eastern countries, however, there was quite a bit of variance between individual countries within regions; the Philippines (39%), Saudi Arabia (35%) and Peru (34%) had the highest proportion of Excel users while the Netherlands (9%), Germany (11%), Switzerland and Poland (14% each) had the lowest;\n* while equally likely to have a Bachelor's or Master's degree (39% each), Excellers had an overall smaller share of Master's and Doctoral degrees compared to IDElers;\n* in terms of profession, Excellers were more likely to be Project\/Product Managers, Business Analysts, DBA\/Database engineers or have 'Other' roles; not surprisingly, a high share of IDElers were more likely to be Data Scientists, Statisticians, Machine Learning Engineers, Research Scientists and Data Engineers\n* as expected data analysis was a key taks for both groups, however, IDElers had a higher share of machine learning related tasks, while'Excellers' had a higher share of tasks that are unrelated to DS\/ML, with 14% selecting 'None of the above';\n* in terms of salary, IDElers were more likely to have a higher annual income than Excellers with 80% of the latter earning up to 60,000 USD p.a. while 80% of IDElers earn up to 80,000 USD p.a.;\n* overall, Excellers were less experienced coders, with 54% having less than 2 years of coding experience, 31% having less than 1 year experience and 10% having never written code;\n* Python was the most frequently used programming language for both groups, followed by SQL. R, on the other hand, was more prevalent amongst IDElers while C and C++ where slightly more prevalent amongst Excellers, as were Java and Javascript;\n* in terms of IDEs, JupyterLab ranked highest for both groups, followed by VSCode. RStudio was used more frequently by IDElers, while VisualStudio and Notepad++ were more commonly used by Excellers;\n* Matplotlib was by far the most frequently used visualisation libary for both groups, followed by Seaborn. While Plotly ranked third for Excellers, GGplot ranked slightly higher for IDElers, which is again not surprising considering their usage of R;\n* Microsoft Power Bi and Tableau ranked highest for both groups, however, Power Bi came in first for Excellers, while Tableau ranked highest for IDElers\n* Coursera was the most popular learning resource for both groups, followed by Kaggle and Udemy. A slightly higher share of IDElers made use of university courses compared to Excellers; \n* Python was by far the most recommended programming language to learn with over 81% of respondents from both groups selecting it as the top choice. R and SQL came in second and third for both groups, however, there was only a marginal difference of 0.1%pt between R and SQL for Excellers compared to a 4.4%pt difference for IDElers. \n\n\n","b2e1b930":"#### Country of residence\nIn regards to regional differences, I found that Middle Eastern countries had a higher Excel uptake (on average 26% of respondents, fig 4). However, there were considerable differences amongst countires within regions. The highest percentage of Excellers was found in the Philippines with 39% of respondents choosing Excel as most often used data analysis tool (figs 4a,4b). In second place was Saudia Arabia (36%), followed by Peru (35%), which had by far the highest percentage of Excellers within the Americas. The lowest uptake rates were seen in the Netherlands (9%) and Germany (11%), followed by Switzerland and Poland (14% each).\nIt's important to keep in mind that some countries had a relatively small number of respondents overall so these numbers are based on a small data set and not necessarily representative.\nIn addition to a grouped bar chart by region and a geoplot I added a bar chart with a threshold to easily identify which countries had more or less Excellers than average (credit to this post for the threshold chart https:\/\/stackoverflow.com\/questions\/28129606\/how-to-create-a-matplotlib-bar-chart-with-a-threshold-line).","fb7e051f":"### Experience and knowledge of tools and programming languages\n\nIn this section we will look at overall coding experience, as well as knowledge of different programming languages and frequently used tools, including IDEs, visualisation libraries, and BI tools.\n\n#### Coding experience overall\n\nNot surprisingly, Excellers indicated to have less coding experience compared to IDElers, with 54% having less than 2 years experience compared to 34% of IDElers (fig 9). In fact, 31% of Excellers had less than 1 year of coding experience and 10% indicated they had never written any code. \nThe most frequent response for IDElers was 3-5 years experience (28% of respondents), compared to 1-2 years for Excellers (23%). ","bc58b766":"### Work life\nIn this section we'll be looking at the differences in roles (i.e. profession), salary and work tasks between Excellers and IDElers.\n\n#### Profession\nHere, we are trying to understand which professions are most likely to use Excel or IDEs for data analysis. Not surprisingly, 52% of data scientists use local IDEs and only 11% use Excel (fig 6). As expected there is also a strong tendency to use local IDEs for statisticians, data engineers, ML engineers and research scientists. Excel, on the other hand, is more likely to be used for data analysis purposes by Product\/and Project Managers, Business Analysts and 'Other' professions. I personally would be keen to see a further breakdown of these 'Other' professions. I wonder how many of them work in Finance...perhaps that's something to consider for future surveys :-)","6d02d746":"Out of the 20,036 respondents, 6,746 chose not to answer question 38 \"What is the primary tool that you use at work or school to analyze data?\" After accounting for missing values, Excellers rank second with 4,223 respondents selecting Excel and similar tools as their main tool for data analysis. This is over 5 times higher than BI tools or SSPS\/SAS, which rank third and fourth with 798 and 781 responses, respectively. ","1a8c1561":"### 4. Conclusion\nThe 2020 Kaggle DS & ML survey shows that Excel remains a key tool for data analysis. At the same time, it appears that many Excel users are only just starting out on their programming journey so time will tell whether Excel will remain their tool of choice once they get more proficient in coding.\nI will certainly try and use less Excel and more IDEs going forward! I just need to think about how I can get my team on board...\nIn any case, it seems to me as though the lines between roles, tasks and tools are getting blurrier with tools and programming languages being used by a growing variety of audiences. For now, I would expect Excellers on Kaggle to stick around and maybe even increase in numbers as more individuals and companies\/industries turn to DS\/ML or simply automation of processes. Perhaps future surveys could add the type of industry respondents work in. This would certainly make it easier for me to convince my team that Python has a place in finance. And as an added bonus it would allow those on the hunt for a job to see where the opportunities are :-)","19b54c0b":"### Demographics\n\nIn this section we will be looking at the overall demographics of our Excellers and IDElers, including their gender, age, country of residence and education. \n\n#### Gender\nAs a first step I looked at the differences in data analysis tools used by gender. I have broken the category gender into \"Man\", \"Woman\" and \"Non-binary\", which includes the answer choices \"Prefer not to say\" and \"Prefer not to self-describe\" due to the low number of responses. \nOverall, the patterns across the three groups are similar (fig 2), with Local IDEs used most frequently (40%+), followed by Excel (between 28% and 35%). Women appear to have a slightly smaller uptake of Local IDEs, with a higher share of Excel and BI software. The Non-binary group has the lowest uptake for Excel or BI tools and the highest share of 'Other' data analysis tools. ","7f037760":"#### Education\nIn regards to education, Excellers appear to be equally likely to have a Bachelor's or Master's degree (39% each, fig 5), whereas IDElers had a higher share of Master's degrees (44%) compared to BAs (31%). Doctoral degrees were more common amongst IDElers (16%, compared to 9% of Excellers).","1928b3c3":"#### Salaries\n\nIn terms of salaries it appears that IDElers are more likely to have a higher annual income than Excellers with 80% of the latter earning up to 60,000 USD p.a. while 80% of IDElers earn up to 80,000 USD p.a. (fig 8).","6e72b6c0":"### 2. Exploratory Data Analysis","4f10ed66":"In percentage terms, 32% of survey respondents use Excel (or similar tools) as their main data analysis tool (fig 1). I did not even expect to see any mention of Excel in a data science and machine learning survey, let alone ranking second and miles ahead of tools like SSPS, SAS and BI software. \nSo, let's take a closer look at the profile of these 32% of respondents.","14a08930":"#### Frequently used Programming languages and data analysis & visualisation tools\n\n##### Programming languages\nPython was the most frequently used programming language for both groups (33% of respondents each), followed by SQL (15% and 16%, respectively, fig 10). R, on the other hand, was more prevalent amongst IDElers with 12% of respondents indicating to use it regularly compared to 5% of Excellers. Interestingly, C and C++ where slightly more prevalent amongst Excellers, as were Java and Javascript. \n\n##### IDEs\nIn terms of IDEs, JupyterLab ranked highest for both groups (25% and 29%, respectively, fig10) followed by VSCode. In line with the use of programming languages, RStudio was more frequently used by IDElers, while VisualStudio and Notepad++ were more commonly used by Excellers.\n\n##### Visualisation libraries\nMatplotlib was by far the most frequently used visualisation libaries for both groups (41% and 33%, respectively, fig 10) followed by Seaborn. While Plotly ranked third for Excellers, GGplot ranked slightly higher for IDElers, which is again not surprising considering their usage of R. \n\n##### BI tools\nMicrosoft Power Bi and Tableau ranked highest for both groups, however, Power Bi came in first for Excellers (20%, fig 10), while Tableau ranked highest for IDElers (21%). Google Data Studio ranked third for both groups with 6%. All other BI tools appear to be hardly used. It is worth noting that 39% of respondents in both groups chose 'None' as their answer to question 31A, which I found quite surprising. ","106d8b48":"#### Tasks\nQuestion 23 of the survey asked respondents to \"Select any activities that make up an important part of your role at work: (Select all that apply)\". As expected, data analysis is a key work activity for both Excellers and IDElers and the response 'Analyze and understand data' was the most selected choice for both groups (fig 7). In saying that, there was a 6%pt difference between both groups with IDElers spending relatively more time on other tasks, namely 'Build prototypes to explore applying machine learning to new areas', which ranked second for this group at 19%, and 'Experimentation and iteration to improve existing ML models', which came in third at 15%. Excellers on the other hand scored higher on 'None of the above' with 14%, indicating that a larger component of their work has nothing to do with data science and machine learning related tasks.","03f2bf3a":"### Age\nNext, I looked at the age profile of Excellers vs IDElers. The age pyramid (fig 3) for both groups is pretty balanced and it's a little difficult to tell which group is older or younger by looking at the chart. Therefore, I looked for different ways to represent the data and found that a heatmap based on cumulative data (fig 3a) was the easiest to read. While still subtle in terms of difference, the below heatmap shows more clearly that Excellers are slightly older with only 76% under the age of 40 compared to 79% of IDElers. Note: the age pyramid (i.e. tornado chart) is based on this code found in the matplotlib discussion forum https:\/\/discourse.matplotlib.org\/t\/tornado-chart\/17058\/3","38c21460":"## Who 'Excels' on Kaggle??\n\n### Contents\n1. Introduction\n    * Overview\n    * Background\n    * Main focus of this notebook's EDA\n\n2. Exploratory Data Analysis\n    * Overview\n    * Demographics\n    * Work life\n    * Knowledge of programming languages and frequently used tools\n    * Learning\n\n3. Summary of findings\n\n4. Conclusion\n\n### 1. Introduction\n\n#### Overview\nAccording to Q38 of the 2020 DS & ML survey, a large number of Kagglers use Excel as their main tool for data analysis. In fact, Excel ranked second with 32% of responses - miles ahead of all other answer choices apart from Local development environments (IDEs), which came in first with 46% of responses. \nThis notebook takes a closer look at these \"Excelling\" Kagglers by exploring and contrasting their profiles with those of IDE users.  \n\n#### Background\n\nI started my Python journey in November 2020, mostly because I wanted some intellectual stimulation while being on parental leave. Not that looking after a tiny human who spends their time looping through a continuous 'sleep, feed, poop' cycle isn't fun... I just felt like I needed another project to keep me sane. That's when I came across a podcast that talked about Python for data analysis and visualisation and I was intrigued.\n\nI work in finance\/commercial analysis so I've been working with Excel my entire working life (I would rather not say publically how many years that is, so let's just say I'm 'relatively experienced'). I also have a passion for data analysis and visualisation. Hence, one of the first questions I felt like digging into in the 2020 DS & ML survey was Q38 \"What is the primary tool that you use at work or school to analyze data?\"\n\nWhen I looked at the responses I was quite surprised to see 'Basic statistical software (Microsoft Excel, Google Sheets, etc.)' ranking in second place, and by a long shot! \nTo be honest I was pleased to see this because it made me feel like I'm not alone out there in terms of being an Excel user who also codes or at a minimum wants to code. And it gives me the courage to keep going with Python.\n\nAnyhow, I decided to dig a little deeper to understand who those \"Excelling\" Kagglers are and how they differ from Local dev environment users. For the purposes of this exercise I will call these two groups \"Excellers\" and \"IDElers\".\n\nTo practice what I've learnt so far I've had a play with different chart types and visualisation libraries along the way.\n\nPlease keep scrolling if you'd like to see what I found out...\n\n#### Main focus of this notebook's EDA \nUnderstand the profile of \"Excellers\" on Kaggle and how they differ (or not) from \"IDElers\". To investigate this question I have looked at the following points:\n\n1. How do Excellers and IDElers differ demographically? (age, country of residence, gender, education)\n2. How do they differ in terms of their work? (roles, tasks, salary)\n3. How do they differ in terms of experience? (experience, programming languages and frequently used tools)\n4. How do they differ in terms of learning new skills (resources used and recommendations)\n\n##### Last but not least\nPlease keep in mind I have only been coding with Python for about 8 weeks so please be kind. If my notebook looks inconsistent or messy at times it is partly because I am trying different approaches for learning purposes and partly because I have no clue what I'm doing (lol). Any suggestions on how I can do things better\/more efficiently are most welcome!\n"}}