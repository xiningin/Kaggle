{"cell_type":{"bf684d37":"code","d4903ee1":"code","bae795dc":"code","76c0ddb2":"code","0798836e":"code","e583d2c8":"code","c449aaa8":"code","2149e39c":"code","73260044":"code","76abc2d9":"code","50eea355":"code","ed460387":"code","98ce2007":"code","576b9dcc":"code","fe426e35":"code","203b8ac3":"code","87dca781":"code","3b157dfb":"code","2c6ff810":"markdown","36ba0827":"markdown","825f3371":"markdown","42f15fb8":"markdown","0685c4e4":"markdown","34f5d809":"markdown","60be6dae":"markdown","0360c41d":"markdown","906ef4f4":"markdown","be01855b":"markdown","087c5698":"markdown","e53b280f":"markdown","f43e6246":"markdown","7554b774":"markdown","795c4a3b":"markdown","c099b1b5":"markdown","e3a7e601":"markdown","1b7ab4d4":"markdown","a1ae9d67":"markdown","c25976b0":"markdown","2a8ac2a5":"markdown","0bba9bed":"markdown","77341c7b":"markdown"},"source":{"bf684d37":"!pip install tensorflow==2.2.0","d4903ee1":"import tensorflow as tf\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport itertools\n\nprint(tf.__version__)","bae795dc":"cifar10 = tf.keras.datasets.cifar10\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()","76c0ddb2":"y_train = y_train.flatten()\ny_test = y_test.flatten()","0798836e":"classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\nplt.figure(figsize=(10,7))\np = sns.countplot(y_train.flatten())\np.set(xticklabels=classes)","e583d2c8":"np.isnan(x_train).any()","c449aaa8":"np.isnan(x_test).any()","2149e39c":"input_shape = (32, 32, 3)\n\nx_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)\nx_train=x_train \/ 255.0\nx_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)\nx_test=x_test \/ 255.0","73260044":"y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\ny_test = tf.one_hot(y_test.astype(np.int32), depth=10)","76abc2d9":"y_train[0]","50eea355":"plt.imshow(x_train[100])\nprint(y_train[100])","ed460387":"batch_size = 32\nnum_classes = 10\nepochs = 50","98ce2007":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, 3, padding='same', input_shape=x_train.shape[1:], activation='relu'),\n    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Dropout(0.25),\n\n    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Dropout(0.25),\n\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(num_classes, activation='softmax'),\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-06),\n            loss='categorical_crossentropy', metrics=['acc'])\n","576b9dcc":"history = model.fit(x_train, y_train, batch_size=batch_size,\n                    epochs=epochs)","fe426e35":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training Loss\")\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='b', label=\"Training Accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","203b8ac3":"test_loss, test_acc = model.evaluate(x_test, y_test)","87dca781":"# Predict the values from the validation dataset\ny_pred = model.predict(x_test)\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_test,axis = 1)\n# compute the confusion matrix\nconfusion_mtx = tf.math.confusion_matrix(y_true, y_pred_classes)","3b157dfb":"plt.figure(figsize=(12, 9))\nc = sns.heatmap(confusion_mtx, annot=True, fmt='g')\nc.set(xticklabels=classes, yticklabels=classes)","2c6ff810":"## 2.2 Check for NaN Values","36ba0827":"## 2.4 Label Encoding\n\nThe labels for the training and the testing dataset are currently categorical and is not continuous. To include categorical dataset in our model, our labels should be converted to one-hot encodings.\n\nFor example, ```2``` (bird) becomes ```[0,0,1,0,0,0,0,0,0,0]``` and ```7``` (horse) becomes ```[0,0,0,0,0,0,0,1,0,0]```.\n\nRun the following cell to transform the labels into one-hot encodings","825f3371":"## 4.3 Confusion Matrix\n\nRun the following cell to compute our confusion matrix using TensorFlow.","42f15fb8":"## 3.2 Fit the Training Data\n\nTesting the model on a validation dataset prevents overfitting of the data. We specified a 10% validation and 90% training split.","0685c4e4":"## 2.3 Normalization and Reshaping\n\nSince the values in our ```x_train``` dataset are 32x32 color images, our input shape must be specified so that our model will know what is being inputed.\n\nThe first convolution layer expects a single 50000x32x32x3 tensor instead of 50000 32x32x3 tensors.\n\nModels generally run better on normalized values. The best way to normalize the data depends on each individual dataset. For the CIFAR10 dataset, we want each value to be between 0.0 and 1.0. As all values originally fall under the 0.0-255.0 range, divide by 255.0.\n\nRun the following cell to define the ```input_shape``` and to normalize and reshape the data.","34f5d809":"# 1. Introduction\n\nThis tutorial is an introduction to Convolutional Neural Networks using TensorFlow 2.x Keras API. The dataset that we will work it is the Cifar10 dataset, a dataset of images from 10 different classes, and we will use a Sequential CNN to identify the class of an image.\n\nThis model reaches ~80% accuracy.\n\nTo prepare our notebook, run the next cell to import the necessary packages. Change the accelerator from ```None``` to ```GPU``` on the right.","60be6dae":"Adapted from [GitHub Keras Example](https:\/\/github.com\/keras-team\/keras\/blob\/master\/examples\/cifar10_cnn.py)\n\n\nTensorFlow 1.x --> TensorFlow 2.x","0360c41d":"The image is an image of a ship. The one-hot encoding vector holds the value of the ship class.\n","906ef4f4":"Classes:\n    0. airplane\n    1. automobile\n    2. bird\n    3. cat\n    4. deer\n    5. dog\n    6. frog\n    7. horse\n    8. ship\n    9. truck","be01855b":"There are no NaN values in our dataset. There is no need to preprocess the data to deal with NaN's.","087c5698":"## 2.1 Load Data\n\nOur first step is to load the data and divide it into a training and testing dataset. The CIFAR10 dataset can be downloaded directly from TensorFlow and has already been divided. Run the next cell to import the data.\n\n``` x_train ``` is the dataset of 32x32 color images of objects that the model will be trained on.\n\n```y_train``` is the dataset of labels that correspond to ```x_train```. \n\n``` x_test ``` is the dataset of 32x32 color images of objects that the model will be tested on.\n\n```y_test``` is the dataset of labels that correspond to ```x_test```. ","e53b280f":"## 4.2 Predict Results\n","f43e6246":"Run the following cell to build the model. The model contains various layers stacked on top of each other. The output of one layer feeds into the input of the next layer.\n\nConv2D layers are convolutions. Each filter (32 in the first two convolution layers and 64 in the next two convolution layers) transforms a part of the image (5x5 for the first two Conv2D layers and 3x3 for the next two Conv2D layers). The transformation is applied on the whole image.\n\nMaxPool2D is a downsampling filter. It reduces a 2x2 matrix of the image to a single pixel with the maximum value of the 2x2 matrix. The filter aims to conserve the main features of the image while reducing the size.\n\nDropout is a regularization layer. In our model, 25% of the nodes in the layer are randomly ignores, allowing the network to learn different features. This prevents overfitting.\n\n```relu``` is the rectifier, and it is used to find nonlinearity in the data. It works by returning the input value if the input value >= 0. If the input is negative, it returns 0.\n\nFlatten converts the tensors into a 1D vector.\n\nThe Dense layers are an artificial neural network (ANN). The last layer returns the probability that an image is in each class (one for each digit).\n\nAs this model aims to categorize the images, we will use a ```categorical_crossentropy``` loss function. ","7554b774":"## 3.1 Define the Model\n\nRun the following cell to define ```batch_size```, ```num_classes```, and ```epochs```. Try changing the values and test how different values affect the accuracy of the CNN model.","795c4a3b":"# 2. Data Preprocessing\n\nBefore building any ML model, it is important to preprocess the data. In fact, data preprocessing will generally take up the most time in any ML pipeline. The following module goes over the steps to preprocess the CIFAR10 dataset for our purposes.","c099b1b5":"## 2.5 Visualize Data\n\nRun the following cell to visualize an image in our dataset.","e3a7e601":"## 4.1 Loss and Accuracy Curves\n\nRun the following cell to evaluate the loss and accuracy of our model","1b7ab4d4":"Run the following cell to plot the confusion matrix. We see that our model classifies frogs pretty well, with 900 out of the 1000 frog images heving been classified correctly. We can also see that there is relatively high confusion between cats and dogs.","a1ae9d67":"# 3. CNN\n\nIn this module, we will build our CNN model.","c25976b0":"# 4. Evaluate the Model","2a8ac2a5":"The accuracy increases over time and the loss decreases over time. However, the accuracy of our validation set seems to slightly decrease towards the end even thought our training accuracy increased. Running the model for more epochs might cause our model to be susceptible to overfitting.","0bba9bed":"Our model runs pretty well, with an accuracy of ~80% on our testing data.","77341c7b":"Run the following code to see how many images are in each class. We see that each class has 5000 images. Having an even distribution of images is helpful for our model as it will have enough images to learn about the features for each class."}}