{"cell_type":{"0b60cae3":"code","67312afd":"code","02a53307":"code","b6cb7edb":"code","ef8690a0":"code","6b86d917":"code","eef1ce05":"code","3b8bab6a":"code","f296a16e":"markdown","0aef8db8":"markdown","a01656d0":"markdown"},"source":{"0b60cae3":"import os\nimport cv2\nimport glob2\nimport pydicom\nfrom tqdm import tqdm_notebook as tqdm\nimport zipfile\nimport io\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom skimage import exposure\nimport sys\nsys.path.insert(0, '..\/input\/siim-acr-pneumothorax-segmentation\/')\nfrom mask_functions import *","67312afd":"sz = 640\nsz0 = 1024\nPATH_TRAIN = '..\/input\/siim-dicom-images\/siim-original\/dicom-images-train\/'\nPATH_TEST = '..\/input\/siim-dicom-images\/siim-original\/dicom-images-test\/'\ntrain_out = 'train.zip'\ntest_out = 'test.zip'\nmask_out = 'masks.zip'\ntrain = glob2.glob(os.path.join(PATH_TRAIN, '**\/*.dcm'))\ntest = glob2.glob(os.path.join(PATH_TEST, '**\/*.dcm'))","02a53307":"df = pd.read_csv('..\/input\/siim-dicom-images\/train-rle.csv').set_index('ImageId')\nidxs = set(df.index)\ntrain_names = []\nfor f in train: #remove images without labels\n    name = f.split('\/')[-1][:-4]\n    if name in idxs: train_names.append(f)","b6cb7edb":"def convert_images(filename, arch_out, sz=sz):\n    ds = pydicom.read_file(str(filename))\n    img = ds.pixel_array\n    img = cv2.resize(img, (sz, sz))\n    img = exposure.equalize_adapthist(img) # contrast correction\n    x_tot = img.mean() #image statistics\n    x2_tot = (img**2).mean()\n    img = ((img*255)).clip(0,255).astype(np.uint8)\n    output = cv2.imencode('.png',img)[1]\n    name = filename.split('\/')[-1][:-4] + '.png'\n    arch_out.writestr(name, output)\n    return x_tot, x2_tot\n\ndef get_stats(stats): # get dataset statistics \n    x_tot, x2_tot = 0.0, 0.0\n    for x, x2 in stats:\n        x_tot += x\n        x2_tot += x2\n    \n    img_avr =  x_tot\/len(stats)\n    img_std =  np.sqrt(x2_tot\/len(stats) - img_avr**2)\n    print('mean:',img_avr, ', std:', img_std)","ef8690a0":"trn_stats = []\nwith zipfile.ZipFile(train_out, 'w') as arch:\n    for fname in tqdm(train_names, total=len(train_names)):\n        trn_stats.append(convert_images(fname,arch))\n\ntest_stats = []        \nwith zipfile.ZipFile(test_out, 'w') as arch:\n    for fname in tqdm(test, total=len(test)):\n        test_stats.append(convert_images(fname,arch))","6b86d917":"get_stats(trn_stats)\nget_stats(test_stats)","eef1ce05":"mask_coverage = []\nmask_count = 0\nwith zipfile.ZipFile(mask_out, 'w') as arch:\n    for idx in tqdm(idxs):\n        masks = df.loc[idx,' EncodedPixels']\n        img = np.zeros((sz0,sz0))\n        #do conversion if mask is not \" -1\"\n        if(type(masks) != str or (type(masks) == str and masks != ' -1')):\n            if(type(masks) == str): masks = [masks]\n            else: masks = masks.tolist()\n            mask_count +=1\n            for mask in masks:\n                img += rle2mask(mask, sz0, sz0).T\n        mask_coverage.append(img.mean())\n        img = cv2.resize(img, (sz, sz))\n        output = cv2.imencode('.png',img)[1]\n        name = idx + '.png'\n        arch.writestr(name, output)\n\nprint('mask coverage:', np.mean(mask_coverage)\/255, ', mask count:', mask_count)","3b8bab6a":"idx = 736\nwith zipfile.ZipFile(train_out, 'r') as arch:\n    fname = sorted(arch.namelist())[idx]\n    flags = cv2.IMREAD_GRAYSCALE\n    img = cv2.imdecode(np.frombuffer(arch.read(fname), np.uint8), flags)\n    \nwith zipfile.ZipFile(mask_out, 'r') as arch:\n    fname = sorted(arch.namelist())[idx]\n    flags = cv2.IMREAD_GRAYSCALE\n    mask = cv2.imdecode(np.frombuffer(arch.read(fname), np.uint8), flags)\n    \nplt.figure()\nplt.imshow(Image.fromarray(img))\nplt.imshow(Image.fromarray(mask), alpha=0.2)\nplt.show()","f296a16e":"> ### Write images","0aef8db8":"### Read image","a01656d0":"### Write masks"}}