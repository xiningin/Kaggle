{"cell_type":{"69e1b094":"code","b4a28e46":"code","1394825d":"code","ee3e874b":"code","19567db1":"code","4391cc68":"code","d3ff5e33":"code","78fd5be1":"code","82bcb297":"code","0a106c24":"code","09ff5d24":"code","ac955357":"code","60b5f8ee":"markdown","c0824162":"markdown","a9090a8a":"markdown","475a9d4b":"markdown","53eeb1a2":"markdown","b25df349":"markdown","a833089a":"markdown","def5936b":"markdown"},"source":{"69e1b094":"# importing required librarires\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics","b4a28e46":"#Reading data set (csv format file)\ndataset = pd.read_csv('\/kaggle\/input\/student\/student_scores.csv')\n# finding how many rows and columns in dataset (rows, columns)\ndataset.shape\n","1394825d":"# Visualize the dataset , head gives first 5 rows as output\ndataset.head()","ee3e874b":"#describe use to get insights of the dataset\ndataset.describe()","19567db1":"#2-D plot on the x axis and y-axis to visualize the dataset\ndataset.plot(x='Hours', y='Scores', style='o')\nplt.title('Hours vs Percentage')\nplt.xlabel('Hours Studied')\nplt.ylabel('Percentage Score')\nplt.show()","4391cc68":"X = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, 1].values","d3ff5e33":"#using Scikit-Learn's built-in train_test_split() method\n#The below script splits 80% of the data to training set while 20% of the data to test set. \n#The test_size variable is where we actually specify the proportion of test set.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","78fd5be1":"# Training the Algorithm\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n#retrieve the intercept:\nprint(regressor.intercept_)","82bcb297":"#Retrieving the slope (coefficient of x)\nprint(regressor.coef_)","0a106c24":"#Making Predictions\n#The y_pred is a numpy array that contains all the predicted values for the input values in the X_test series.\ny_pred = regressor.predict(X_test)","09ff5d24":"#To compare the actual output values for X_test with the predicted values\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\ndf","ac955357":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","60b5f8ee":"**Though our model is not very precise, the predicted percentages are close to the actual ones.**","c0824162":"**Evaluating the Algorithm**\nThe final step is to evaluate the performance of algorithm. This step is particularly important to compare how well different algorithms perform on a particular dataset. For regression algorithms, three evaluation metrics are commonly used:\n1. Mean Absolute Error (MAE) is the mean of the absolute value of the errors\n\n2. Mean Squared Error (MSE) is the mean of the squared errors \n\n3. Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors","a9090a8a":"**Linear Regression with Python Scikit Learn**","475a9d4b":"Here in above graph we can see the positive linear relation between the number of hours studied and percentage of score.","53eeb1a2":"It means, if a student studies one hour more than they previously studied for an exam, they can expect to achieve an increase of 9.91% in the score achieved by the student previously.","b25df349":"**Data Preparation**\nThe attributes are stored in the X variable. We specified \"-1\" as the range for columns since we wanted our attribute set to contain all the columns except the last one, which is \"Scores\". Similarly the y variable contains the labels. We specified 1 for the label column since the index for \"Scores\" column is 1. Remember, the column indexes start with 0, with 1 being the second column. In the next section, we will see a better way to specify columns for attributes and labels.","a833089a":"**What is Linear Regression:**\nLinear regression is a basic and commonly used type of predictive analysis.  The overall idea of regression is to examine two things: (1) does a set of predictor variables do a good job in predicting an outcome (dependent) variable?  (2) Which variables in particular are significant predictors of the outcome variable, and in what way do they\u2013indicated by the magnitude and sign of the beta estimates\u2013impact the outcome variable?  These regression estimates are used to explain the relationship between one dependent variable and one or more independent variables.  The simplest form of the regression equation with one dependent and one independent variable is defined by the formula y = c + b*x, where y = estimated dependent variable score, c = constant, b = regression coefficient, and x = score on the independent variable.\n\n","def5936b":"**Conclusion:**\nYou can see that the value of root mean squared error is 4.64, which is less than 10% of the mean value of the percentages of all the students i.e. 51.48 (This value can be seen in describe code section). This means that our algorithm did a decent job.\n\n"}}