{"cell_type":{"c48437d8":"code","1f8b4aeb":"code","5d6333f8":"code","054ca1fb":"code","06076e56":"code","5e43cf1a":"code","c27d75c8":"code","9cae724a":"code","73065bf2":"code","6dd9d8f0":"code","d8b5d2c1":"code","c9b8fdb2":"code","806aafbc":"code","67021d73":"markdown","d494a646":"markdown","6704d74f":"markdown","02da6d51":"markdown","a048af05":"markdown","4e1b08f9":"markdown","cfe8eb58":"markdown","7dee05ee":"markdown","d6c43a78":"markdown","eca40371":"markdown","83845d98":"markdown"},"source":{"c48437d8":"import math\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom  scipy import ndimage\nfrom tqdm.notebook import tqdm","1f8b4aeb":"data_dir='..\/input\/seti-breakthrough-listen\/'","5d6333f8":"train_df_old = pd.read_csv(data_dir + \"old_leaky_data\/train_labels_old.csv\")\ntrain_df_old[\"path\"] = train_df_old[\"id\"].apply(lambda x: f\"{data_dir}old_leaky_data\/train_old\/{x[0]}\/{x}.npy\")\ntrain_df_old.head()\ntest_df_old = pd.read_csv(data_dir + \"old_leaky_data\/test_labels_old.csv\")\ntest_df_old[\"path\"] = test_df_old[\"id\"].apply(lambda x: f\"{data_dir}old_leaky_data\/test_old\/{x[0]}\/{x}.npy\")\n\ntrain_df = pd.read_csv(data_dir + \"train_labels.csv\")\ntrain_df[\"path\"] = train_df[\"id\"].apply(lambda x: f\"{data_dir}train\/{x[0]}\/{x}.npy\")\ntrain_df.head()\ntest_df = pd.read_csv(data_dir + \"sample_submission.csv\")\ntest_df[\"path\"] = test_df[\"id\"].apply(lambda x: f\"{data_dir}test\/{x[0]}\/{x}.npy\")","054ca1fb":"def normalize_t(x):\n    x = (x - np.mean(x, axis=2, keepdims=True)) \/ np.std(x, axis=2, keepdims=True)\n    return x\n\n\ndef normalize_f(x):\n    x = (x - np.mean(x, axis=1, keepdims=True)) \/ np.std(x, axis=1, keepdims=True)\n    return x\n\n\ndef normalize_tf(x):\n    x = (x - np.mean(x, axis=2, keepdims=True)) \/ np.std(x, axis=2, keepdims=True)\n    x = (x - np.mean(x, axis=1, keepdims=True)) \/ np.std(x, axis=1, keepdims=True)\n    return x\n\n\ndef normalize_ft(x):\n    x = (x - np.mean(x, axis=1, keepdims=True)) \/ np.std(x, axis=1, keepdims=True)\n    x = (x - np.mean(x, axis=2, keepdims=True)) \/ np.std(x, axis=2, keepdims=True)\n    return x","06076e56":"def generate_template(img, min_x, max_x, min_y, max_y, threshold=0.5):\n    img = img[[0, 2, 4], :, :]\n    plt.figure()\n    plt.imshow(img.mean(axis=0))\n    img = normalize_ft(img)\n    img = img[:, min_x:max_x, min_y:max_y]\n    # for i in range(3):\n    #    plt.figure()\n    #    plt.imshow(img[i])\n    img = np.clip(img, 0, 3)\n    img = ndimage.median_filter(img, 3)\n    # for i in range(3):\n    #    plt.figure()\n    #    plt.imshow(img[i])\n    img = img.mean(axis=0)\n    img_b = img.copy()\n    img_b[img_b > threshold] = 1\n    img_b[img_b < threshold] = 0\n    plt.figure()\n    plt.imshow(img)\n    #plt.figure()\n    #plt.imshow(img_b)\n    return img, img_b","5e43cf1a":"kaggle_file_path = data_dir + \"old_leaky_data\/train_old\/2\/2503d7f6e5c4.npy\"\nalien_file_path = data_dir + \"old_leaky_data\/train_old\/4\/4f7bb8cf2d15.npy\"\nrocket_file_path = data_dir + \"old_leaky_data\/train_old\/6\/6c12bab0aeb4.npy\"\n\nimage = np.load(kaggle_file_path).astype(np.float32)\nkaggle_template, kaggle_template_b = generate_template(image, 15, 70, 20, 170, 0.5)\nimage = np.load(alien_file_path).astype(np.float32)\nalien_template, alien_template_b = generate_template(image, 60, 110, 50, 110, 0.5)\nimage = np.load(rocket_file_path).astype(np.float32)\nrocket_template, rocket_template_b = generate_template(image, 55, 120, 45, 110, 0.5)","c27d75c8":"def template_matching(img, template, threshold, verbose=True):\n    img = img[[0, 2, 4], :, :]\n    img = normalize_ft(img)\n    img = np.clip(img, 0, 3)\n    #omit to speed up in kaggle notebook\n    #img = ndimage.median_filter(img, 3)\n    img = img.mean(axis=0)\n    w, h = template.shape[::-1]\n    # methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n    #        'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n    method = eval(\"cv2.TM_SQDIFF_NORMED\")\n\n    # Apply template Matching\n    res = cv2.matchTemplate(img, template, eval(\"cv2.TM_SQDIFF_NORMED\"))\n    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n    if min_val < threshold and verbose:\n        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n        if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n            top_left = min_loc\n        else:\n            top_left = max_loc\n        bottom_right = (top_left[0] + w, top_left[1] + h)\n\n        cv2.rectangle(img, top_left, bottom_right, 1, 2)\n\n        print(min_val)\n        print(image_path)\n        plt.subplot(121), plt.imshow(res, cmap=\"gray\")\n        plt.title(\"Matching Result\"), plt.xticks([]), plt.yticks([])\n        plt.subplot(122), plt.imshow(img)\n        plt.title(\"Detected Point\"), plt.xticks([]), plt.yticks([])\n        plt.show()\n    return min_val","9cae724a":"threshold = 0.7\n\nmin_vals = []\nfor image_path in tqdm(train_df[\"path\"].values):\n    img = np.load(image_path).astype(np.float32)\n    min_val = template_matching(img, kaggle_template, threshold=threshold)\n    min_vals.append(min_val)\n\nfor image_path in tqdm(test_df[\"path\"].values):\n    img = np.load(image_path).astype(np.float32)\n    min_val = template_matching(img, kaggle_template, threshold=threshold)\n    min_vals.append(min_val)\n\nfor image_path in tqdm(train_df_old[\"path\"].values):\n    img = np.load(image_path).astype(np.float32)\n    min_val = template_matching(img, kaggle_template, threshold=threshold)\n    min_vals.append(min_val)\n\nfor image_path in tqdm(test_df_old[\"path\"].values):\n    img = np.load(image_path).astype(np.float32)\n    min_val = template_matching(img, kaggle_template, threshold=threshold)\n    min_vals.append(min_val)\n    \nmin_vals = np.concatenate([min_vals])\nplt.figure()\n_ = plt.hist(min_vals, bins=100)","73065bf2":"threshold = 0.35\n\nmin_vals = []\nfor image_path in tqdm(train_df[\"path\"].values):\n    img = np.load(image_path).astype(np.float32)\n    min_val = template_matching(img, alien_template, threshold=threshold)\n    min_vals.append(min_val)\n\n\nfor image_path in tqdm(test_df[\"path\"].values):\n    img = np.load(image_path).astype(np.float32)\n    min_val = template_matching(img, alien_template, threshold=threshold)\n    min_vals.append(min_val)\n\nfor image_path in tqdm(train_df_old[\"path\"].values):\n    img = np.load(image_path).astype(np.float32)\n    min_val = template_matching(img, alien_template, threshold=threshold)\n    min_vals.append(min_val)\n\nfor image_path in tqdm(test_df_old[\"path\"].values):\n    img = np.load(image_path).astype(np.float32)\n    min_val = template_matching(img, alien_template, threshold=threshold)\n    min_vals.append(min_val)\n    \nmin_vals = np.concatenate([min_vals])\nplt.figure()\n_ = plt.hist(min_vals, bins=100)","6dd9d8f0":"threshold = 0.6\n\nmin_vals = []\nfor image_path in tqdm(train_df[\"path\"].values):\n    img = np.load(image_path).astype(np.float32)\n    min_val = template_matching(img, rocket_template, threshold=threshold)\n    min_vals.append(min_val)\n\n\nfor image_path in tqdm(test_df[\"path\"].values):\n    img = np.load(image_path).astype(np.float32)\n    min_val = template_matching(img, rocket_template, threshold=threshold)\n    min_vals.append(min_val)\n\nfor image_path in tqdm(train_df_old[\"path\"].values):\n    img = np.load(image_path).astype(np.float32)\n    min_val = template_matching(img, rocket_template, threshold=threshold)\n    min_vals.append(min_val)\n\nfor image_path in tqdm(test_df_old[\"path\"].values):\n    img = np.load(image_path).astype(np.float32)\n    min_val = template_matching(img, rocket_template, threshold=threshold)\n    min_vals.append(min_val)\n    \nmin_vals = np.concatenate([min_vals])\nplt.figure()\n_ = plt.hist(min_vals, bins=100)","d8b5d2c1":"def easter_egg_postprocessing(sub_df, templates, thresholds, data_dir='..\/input\/seti-breakthrough-listen\/'):\n    processed_df = sub_df.copy()\n    processed_df[\"path\"] = processed_df[\"id\"].apply(\n        lambda x: f\"{data_dir}test\/{x[0]}\/{x}.npy\"\n    )\n    for cnt, row in tqdm(enumerate(processed_df[[\"id\", \"target\", \"path\"]].values)):\n        # id = str(row[0])\n        # target = float(row[1])\n        path = str(row[2])\n        img = np.load(path).astype(np.float32)\n        for i in range(len(thresholds)):\n            min_val = template_matching(img, templates[i], threshold=thresholds[i])\n            if min_val < thresholds[i]:\n                print('path: '+path+', target: '+str(processed_df.loc[cnt, \"target\"])+' -> 1')\n                processed_df.loc[cnt, \"target\"] = 1\n    processed_df = processed_df.drop([\"path\"], axis=1)\n    return processed_df","c9b8fdb2":"# sub_df = pd.read_csv(\"..\/input\/seti-e-t-resnet18d-baseline\/submission.csv\")\n# processed_df = easter_egg_postprocessing(\n#     sub_df,\n#     [kaggle_template, alien_template, rocket_template],\n#     [0.5, 0.3, 0.5],\n#     data_dir\n# )\n# processed_df.to_csv(\"sample_submission.csv\", index=False)","806aafbc":"egg_paths=['..\/input\/seti-breakthrough-listen\/old_leaky_data\/train_old\/2\/2503d7f6e5c4.npy', \n           '..\/input\/seti-breakthrough-listen\/old_leaky_data\/train_old\/8\/805a7f4cac38.npy', \n           '..\/input\/seti-breakthrough-listen\/old_leaky_data\/test_old\/e\/e05a5e667d06.npy', \n           '..\/input\/seti-breakthrough-listen\/old_leaky_data\/train_old\/4\/4f7bb8cf2d15.npy', \n           '..\/input\/seti-breakthrough-listen\/old_leaky_data\/test_old\/1\/1397c4ab0e5c.npy', \n           '..\/input\/seti-breakthrough-listen\/old_leaky_data\/test_old\/1\/1725ceec6de4.npy', \n           '..\/input\/seti-breakthrough-listen\/old_leaky_data\/train_old\/6\/6c12bab0aeb4.npy', \n           '..\/input\/seti-breakthrough-listen\/old_leaky_data\/test_old\/1\/1e6e43ddc15a.npy', \n           '..\/input\/seti-breakthrough-listen\/old_leaky_data\/test_old\/7\/72bc12d576e2.npy']\n\negg_ids=['2503d7f6e5c4', \n        '805a7f4cac38', \n        'e05a5e667d06', \n        '4f7bb8cf2d15', \n        '1397c4ab0e5c', \n        '1725ceec6de4', \n        '6c12bab0aeb4', \n        '1e6e43ddc15a', \n        '72bc12d576e2']","67021d73":"# Use Easter Egg Detector for postprocessing\nI use the results of [the current public best notebook](https:\/\/www.kaggle.com\/ttahara\/seti-e-t-resnet18d-baseline).","d494a646":"# Detect 'Kaggle' Eggs\nHere, I use a bit liberal threshold to search optimal value.","6704d74f":"# Generate templates from known easter Eggs\nI use normalization technique from this [notebook](https:\/\/www.kaggle.com\/agentauers\/seti21-normalization-of-data) and median filter to generate template.","02da6d51":"# Detect Easter Eggs with Template Matching\n\nHere, I detect the eater eggs with template matching. \n\nWith this technique, I could detect four eggs in train set (all of them are known) and five eggs in test set (two of them are known). I noticed that the numbers of kaggle, alien, and rocket easter eggs are all three. So, there are three types of eggs, and the number of each type is three. I suspect that there are members of [Earth-Trisolaris Organization (ETO)](https:\/\/en.wikipedia.org\/wiki\/The_Three-Body_Problem_(novel)) in SETI.\n\nI also introduce a postprocessing function to use this detecter. Unfortunately the LB score did not change (0.97 -> 0.97), but I think it would be better than nothing.\n\nI use some codes, data, and ideas from follow notebooks and webpages. Thank you.\n* https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/241522\n* https:\/\/www.kaggle.com\/sherlockkay\/visualize-rocket\n* https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/241076\n* https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/241411\n* https:\/\/www.kaggle.com\/abebe9849\/visualization-of-oof?scriptVersionId=63001313&cellId=13\n* https:\/\/www.kaggle.com\/agentauers\/seti21-normalization-of-data\n* http:\/\/labs.eecs.tottori-u.ac.jp\/sd\/Member\/oyamada\/OpenCV\/html\/py_tutorials\/py_imgproc\/py_template_matching\/py_template_matching.html (Japanese)\n* https:\/\/www.kaggle.com\/ttahara\/seti-e-t-resnet18d-baseline\n\n[Update, 20210715] [After the competition relaunch](https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/253079), I re-run the script as shown below. I could not find any easter eggs in the new dataset. I am very happy if anyone correct me if I am wrong.","a048af05":"The path of eggs are from follwoing notebooks.\n\n* https:\/\/www.kaggle.com\/sherlockkay\/visualize-rocket\n* https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/241076\n* https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/241411","4e1b08f9":"I think optimal threshold would be 0.5 for kaggle and rocket, 0.3 for alien.\nMy detector would be suffered from [Pareidolia](https:\/\/en.wikipedia.org\/wiki\/Pareidolia).","cfe8eb58":"# Detect eggs with template matching\nTemplate matching is based on cv2.TM_SQDIFF_NORMED. Please note that the smaller output value is better. I use the code from  [here (in japanese sorry)](http:\/\/labs.eecs.tottori-u.ac.jp\/sd\/Member\/oyamada\/OpenCV\/html\/py_tutorials\/py_imgproc\/py_template_matching\/py_template_matching.html)\n","7dee05ee":"# Detect Rocket Eggs\nHere, I use a bit liberal threshold to search optimal value.","d6c43a78":"# Detect Alien Eggs\nHere, I use a bit liberal threshold to search optimal value.","eca40371":"Here is a list of the eggs my detector found (including known ones).","83845d98":"Should I omit eggs in train set when training NN models?\n\nAny comments are welcome."}}