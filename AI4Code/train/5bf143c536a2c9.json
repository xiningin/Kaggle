{"cell_type":{"b8f5d718":"code","ed6c9c9c":"code","38569d5c":"code","4e57f032":"code","4d6bc31c":"code","1400b1a9":"code","d6732896":"code","045f5873":"code","036f1c19":"code","fc1ba7a8":"code","fc1da817":"code","93a2a544":"code","4e3e675b":"code","9241369a":"code","80b766b9":"code","fb29be80":"code","77f7ce16":"code","1bf486f4":"code","2468bb8b":"code","66aa224b":"code","2114a3b5":"code","9dd59704":"code","0ff07539":"code","6ddc499d":"code","6c285228":"code","40488760":"code","f8c971cc":"code","1ffeeb9c":"code","5f9024a1":"markdown","d9c502fb":"markdown","ae499590":"markdown","10822df2":"markdown","86dd5141":"markdown","0b790c1a":"markdown","ba5f5d89":"markdown","04c59de3":"markdown","3c061b68":"markdown","29153206":"markdown","dfd2a4aa":"markdown","353e0d47":"markdown","fed87fb2":"markdown","7e5733e8":"markdown","941b4f5d":"markdown","4a85511f":"markdown","6a8612c8":"markdown","82a04509":"markdown","f6609638":"markdown","ddb0b059":"markdown","af51bf1d":"markdown","4b364c08":"markdown","6b1fa6c2":"markdown","bc114470":"markdown"},"source":{"b8f5d718":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ed6c9c9c":"#Visualization\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap \n#Libraries for ML\nfrom sklearn.preprocessing import StandardScaler #Standardizasyon i\u00e7in\nfrom sklearn.model_selection import train_test_split, GridSearchCV #GridSearchCV: KNN ile ilgili en iyi parametreleri belirlemek\nfrom sklearn.metrics import accuracy_score ,confusion_matrix #Sonu\u00e7 de\u011ferlendirme\nfrom sklearn.neighbors import KNeighborsClassifier,LocalOutlierFactor #Trainin algoritmas\u0131 ve NCA ve Outlier de\u011ferler i\u00e7in\nfrom sklearn.decomposition import PCA #PCA i\u00e7in\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport itertools\nplt.style.use('fivethirtyeight')\nimport seaborn as sns\n# import warnings\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n","38569d5c":"data = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndata.head()","4e57f032":"print('Shape of dataset is' + str(data.shape))","4d6bc31c":"data.info()","1400b1a9":"#Checking for null values\ndata.isnull().sum()","d6732896":"data[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = data[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].replace(0, np.nan)\ndata.isnull().sum()\n","045f5873":"from scipy.stats import skew\nfor col in data.drop('Outcome', axis = 1).columns:\n    print(\"Skewness for the column {} is {}\".format(col, data[col].skew()))","036f1c19":"data['Insulin'] = data['Insulin'].fillna(data['Insulin'].median()) # Filling null values with the median.\n\nfor col in ['Glucose', 'BloodPressure', 'SkinThickness', 'BMI']:\n    data[col] = data[col].fillna(data[col].mean())","fc1ba7a8":"data.isnull().sum()","fc1da817":"corr_data = data.corr() \nsns.clustermap(corr_data,annot= True,cmap = \"YlGnBu\",fmt = '.2f')\nplt.title('Correlation Between Features')\nplt.show();","93a2a544":"\nfig=data.hist(figsize = (20,20), color='#09FBD3',alpha=0.7, rwidth=0.85)\n","4e3e675b":"sns.set(style=\"whitegrid\")\nlabels = ['Non-Diabetic', 'Diabetic']\nsizes = data['Outcome'].value_counts(sort = True)\n\ncolors = [\"#09FBD3\",\"#FDF200\"]\nexplode = (0.05,0) \n \nplt.figure(figsize=(7,7))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90,)\n\nplt.title('Non-Diabetic vs Diabetic')\nplt.show()","9241369a":"plt.style.use('ggplot') # TO GET AN IDEA OF OUTLIERS \n\nf, ax = plt.subplots(figsize=(11, 15))\n\nax.set_facecolor('#09FBD3')\nax.set(xlim=(-.05, 200))\nplt.ylabel('Variables')\nplt.title(\"Overview\")\nax = sns.boxplot(data = data, \n  orient = 'h', \n  palette = 'Set2',)","80b766b9":"def distplot(col_name):\n    \n    plt.figure()\n    sns.set(style=\"whitegrid\")\n    ax = sns.distplot(data[col_name][data.Outcome == 1], color =\"gold\", rug = True)\n    sns.distplot(data[col_name][data.Outcome == 0], color =\"#09FBD3\",rug = True)\n    plt.legend(['Diabetic', 'Healthy'])","fb29be80":"\nsns.set(style='whitegrid')  \ng = sns.scatterplot(x='Glucose', y='Age', data=data, hue='Outcome', palette='pastel', legend=True)\nplt.legend(title='Result', loc='upper left', labels=['Healthy' , 'Diabetic'])\nplt.show(g)\n\n","77f7ce16":"pallete = {0: \"#09FBD3\", 1: \"gold\"}\nsns.boxplot(x = 'Outcome', y = 'Glucose', boxprops=dict(alpha=.5), data = data, palette = pallete)\nplt.title('Glucose vs Outcome')\nplt.show()","1bf486f4":"distplot('Glucose')","2468bb8b":"distplot('Pregnancies')","66aa224b":"sns.jointplot(x='Insulin',y='Glucose', data=data, kind = 'reg', color = '#09FBD3')\nplt.show()","2114a3b5":"distplot('Insulin')","9dd59704":"distplot('BloodPressure')","0ff07539":"pallete = {0: \"#09FBD3\", 1: \"gold\"}\nsns.boxplot(x = 'Outcome', y = 'BMI', boxprops=dict(alpha=.5), data = data, palette = pallete)\n\nplt.title('BMI vs Outcome')\nplt.show()","6ddc499d":"df = data\nzero  = df[df['Outcome']==0]   #zero values in outcome column\none = df[df['Outcome']==1]  # one values in outcome column\nfrom sklearn.utils import resample\n#minority class that 1, we need to upsample\/increase that class so that there is no bias\n#n_samples = 500 means we want 500 sample of class 1, since there are 500 samples of class 0\ndf_minority_upsampled = resample(one, replace = True, n_samples = 500) \n#concatenate\ndf = pd.concat([zero, df_minority_upsampled])\n\nfrom sklearn.utils import shuffle\ndf = shuffle(df) # shuffling so that there is particular sequence","6c285228":"from sklearn.model_selection import train_test_split\n#Splitting train and test data\nX = df.drop('Outcome', axis = 1)\ny = df['Outcome']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 42, stratify = y)\n\n\n#Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nfeatures= X.columns\nX[features] = sc.fit_transform(X[features])","40488760":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\n\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n","f8c971cc":"lr = LogisticRegression(random_state=42)\n\nknn = KNeighborsClassifier()\n\ndt = DecisionTreeClassifier()\n\nrf = RandomForestClassifier()\n\nXGB = XGBClassifier()\nsvc = SVC()\n\n\n\n\n\n\n\n\n","1ffeeb9c":"classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn),\n               ('Decision Tree', dt), ('Random Forest', rf),('XGBoost',XGB),('SVM',svc)]\n\nfor classifier_name, classifier in classifiers:\n \n    # Fit clf to the training set\n    classifier.fit(X_train, y_train)    \n   \n    # Predict y_pred\n    y_pred = classifier.predict(X_test)\n    accuracy = accuracy_score(y_test,y_pred)\n    \n\n   \n    # Evaluate clf's accuracy on the test set\n    print('{:s} : {:.2f}'.format(classifier_name, accuracy))","5f9024a1":"> Diabetes increases risk of high blood pressure","d9c502fb":"BMI","ae499590":"<a id = '1.0'><\/a>\n<p style = \"font-size : 30px; color :#090f01 ;font-family : 'Chalkduster',fantasy;  \"><strong>Exploratory Data Analysis :-<\/strong><\/p>","10822df2":"<p style = \"font-size : 50px; color : #020b1a ; font-family : 'Chalkduster',fantasy; text-align : center; background-color : #b0f75e; border-radius: 5px 5px;\"><strong>Diabetes Prediction<\/strong><\/p>\n","86dd5141":"> Young people are generally healthier ans have less glucose concentration.","0b790c1a":"Insulin increases with incerase of glucose level","ba5f5d89":"> Diabetes is a disease that occurs when your blood glucose, also called blood sugar, is too high. Blood glucose is your main source of energy and comes from the food you eat. Insulin, a hormone made by the pancreas, helps glucose from food get into your cells to be used for energy. Sometimes your body doesn\u2019t make enough\u2014or any\u2014insulin or doesn\u2019t use insulin well. Glucose then stays in your blood and doesn\u2019t reach your cells.\nOver time, having too much glucose in your blood can cause health problems. Although diabetes has no cure, you can take steps to manage your diabetes and stay healthy.","04c59de3":"> Columns like Pregnancies, Glucose, BloodPressure, SkinThickness and BMI are not that much skewed. We can fill null values with the mean for these columns, but for columns like Insulin and DiabetesPedigreeFunction, we will have to replace them will median due to the effect of skewness","3c061b68":"Since some features are supposed to have zero value ,we replace it with","29153206":"<a id = '1.0'><\/a>\n<p style = \"font-size : 30px; color :#090f01 ;font-family : 'Chalkduster',fantasy;  \"><strong>Modelling :-<\/strong><\/p>","dfd2a4aa":"<a id = '1.0'><\/a>\n<p style = \"font-size : 30px; color :#090f01 ;font-family : 'Chalkduster',fantasy;  \"><strong>Reading Data :-<\/strong><\/p>","353e0d47":"> Diabetic People tend to have slightly higher Insulin level.","fed87fb2":"> It can be seen that the Median BMI of the Diabetic People is greater than the Median BMI of the Non-Diabetic people.","7e5733e8":"Pregnencies","941b4f5d":"BLood Pressure","4a85511f":"Glucose vs Age","6a8612c8":"Decision Tree based models prove to be more effecient in this classification problem.","82a04509":"<a id = '1.0'><\/a>\n<p style = \"font-size : 30px; color :#090f01 ;font-family : 'Chalkduster',fantasy;  \"><strong>Importing required libraries :-<\/strong><\/p>","f6609638":"> CORRELATION MATRIX:Variables within a dataset can be related for lots of reasons. It can be useful in data analysis and modeling to better understand the relationships between variables. The statistical relationship between two variables is referred to as their correlation.","ddb0b059":"Insulin","af51bf1d":">Both plots show that diabetic people tend to have a much higher glucose level.","4b364c08":"> It can be said that number of pregnancies is high for the diabetic people","6b1fa6c2":"<a id = '1.0'><\/a>\n<p style = \"font-size : 30px; color :#090f01 ;font-family : 'Chalkduster',fantasy;  \"><strong>Variables: :-<\/strong><\/p>\n<ul>\n    <li style = \"color : #03506f; font-size : 18px; font-family: system-ui;\"><strong>Pregnancies: Number of times pregnant<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family: system-ui;\"><strong>Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family: system-ui;\"><strong>BloodPressure: Diastolic blood pressure (mm Hg)<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px;font-family: system-ui;\"><strong>SkinThickness: Triceps skin fold thickness (mm)<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family: system-ui;\"><strong>Insulin: 2-Hour serum insulin (mu U\/ml)<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family: system-ui;\"><strong>BMI: Body mass index (weight in kg\/(height in m)^2)<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px;font-family: system-ui;\"><strong>DiabetesPedigreeFunction: Diabetes pedigree functionr<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family: system-ui;\"><strong>Age: Age (years)<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family: system-ui;\"><strong>Cabin : Cabin Number<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family: system-ui;;\"><strong>Outcome: Class variable (0 or 1)<\/strong><\/li>\n<\/ul>\n\u200b","bc114470":"> Why do we need scaling?\nFeature scaling is essential for machine learning algorithms that calculate distances between data. If not scale, the feature with a higher value range starts dominating when calculating distances,"}}