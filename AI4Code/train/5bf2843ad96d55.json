{"cell_type":{"e0faf16b":"code","4343c64d":"code","ccc42fd1":"code","0970f72a":"code","2159e6e2":"code","4d81a459":"code","35be8326":"code","3044a68b":"code","099427e6":"code","5aadb285":"code","57370410":"code","75dc7e56":"code","82d0f4b5":"code","95610df5":"code","ff183904":"code","a5295529":"code","0f900177":"code","74c48afe":"code","3244548b":"code","ce5cd452":"code","36dce89f":"code","3492b168":"code","9ddaedd5":"code","ffe841c3":"code","5cf0cdfd":"code","6b9317e1":"code","6e12b798":"code","edb7796f":"code","2decb267":"markdown","b2da09da":"markdown","506a2ecc":"markdown","22eb3e1d":"markdown","bfb731ef":"markdown","f295c872":"markdown","ce5dfdf1":"markdown","e4b178af":"markdown","85f18526":"markdown"},"source":{"e0faf16b":"import glob\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats","4343c64d":"df = pd.read_csv('..\/input\/best-artworks-of-all-time\/artists.csv')\ndf = df.drop(columns=['bio', 'wikipedia'])","ccc42fd1":"artists_hist_dict = {}\nfor ii in glob.glob('..\/input\/best-artworks-of-all-time\/images\/images\/*'):\n    blue_hist = []\n    red_hist = []\n    green_hist = []\n    for j in glob.glob(ii + '\/*'):\n        img = cv2.imread(j)\n        for i, col in enumerate(['b', 'g', 'r']):\n            hist = cv2.calcHist([img], [i], None, [256], [0, 256])\n            if col=='b':\n                blue_hist.append(hist)\n            elif col=='g':\n                green_hist.append(hist)\n            elif col=='r':\n                red_hist.append(hist)\n\n    blue_hist = sum(blue_hist)\/len(blue_hist)\n    green_hist = sum(green_hist)\/len(green_hist)\n    red_hist = sum(red_hist)\/len(red_hist)\n    artists_hist_dict[j.split('\/')[-2]] = [blue_hist, green_hist, red_hist]","0970f72a":"equivalent_artists = []\nfor i in artists_hist_dict:\n    score_max = 0\n    for j in artists_hist_dict:\n        score = 0\n        if i!=j:\n            for k,l in zip(artists_hist_dict[j], artists_hist_dict[i]):     \n                score = score + cv2.compareHist(k, l, cv2.HISTCMP_CORREL)\n                score = score\/3.0\n            if score > score_max:\n                score_max = score\n                similar_artist = j\n    equivalent_artists.append((i,similar_artist, score_max))","2159e6e2":"def plot(artist_1,  artist_2, title_of_plot):\n    blue_hist1, green_hist1, red_hist1 = artists_hist_dict[artist_1]\n    blue_hist2, green_hist2, red_hist2 = artists_hist_dict[artist_2]\n    fig, axs = plt.subplots(2,figsize=(5,5))\n    fig.tight_layout()\n    #fig.suptitle('score :' + title_of_plot )\n    axs[0].title.set_text(artist_1)\n    axs[0].plot(blue_hist1, color = 'b')\n    axs[0].plot(green_hist1, color = 'g')\n    axs[0].plot(red_hist1, color = 'r')\n    axs[1].title.set_text(artist_2)\n    axs[1].plot(blue_hist2, color = 'b')\n    axs[1].plot(green_hist2, color = 'g')\n    axs[1].plot(red_hist2, color = 'r')","4d81a459":"for i in equivalent_artists:\n    plot(i[0], i[1], str(i[2]))","35be8326":"all_artwork = []\nall_labels = []\nfor ii in glob.glob('..\/input\/best-artworks-of-all-time\/images\/images\/*'):\n    for j in glob.glob(ii + '\/*'):\n        all_artwork.append(cv2.resize(cv2.imread(j), (128,128)))\n        all_labels.append(ii.split('\/')[-1])","3044a68b":"all_artwork = np.asarray(all_artwork)","099427e6":"import gc\ngc.collect()","5aadb285":"from keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nimport keras","57370410":"inputs = Input(shape=(128,128,3))\n##--encoder--##\nconv = Conv2D(8, kernel_size=3, activation='relu')(inputs)\nconv = MaxPooling2D(pool_size=(2, 2))(conv)\nconv = Conv2D(8, kernel_size=3, activation='relu')(conv)\nconv = Conv2D(8, kernel_size=3, activation='relu')(conv)\nconv = MaxPooling2D(pool_size=(2, 2))(conv)\nconv = Conv2D(16, kernel_size=3, activation='relu')(conv)\n###\ndeconv = Conv2DTranspose(16, kernel_size=3, activation='relu')(conv)\ndeconv = UpSampling2D(size=(2, 2),interpolation='nearest')(deconv)\ndeconv = Conv2DTranspose(8, kernel_size=3, activation='relu')(deconv)\ndeconv = Conv2DTranspose(8, kernel_size=3, activation='relu')(deconv)\ndeconv = UpSampling2D(size=(2, 2),interpolation='nearest')(deconv)\ndeconv = Conv2DTranspose(8, kernel_size=3, activation='relu')(deconv)\n##--get--back--image--##\nimg = Conv2DTranspose(3, kernel_size=3, activation='relu')(deconv)\n\nmodel = Model(inputs=inputs, outputs=img)","75dc7e56":"model.summary()","82d0f4b5":"optimizer = Adam(lr = 0.0001)\nmodel.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])","95610df5":"gc.collect()","ff183904":"history_model = model.fit(all_artwork\/255.0,  all_artwork\/255.0, shuffle= True, epochs = 50,  batch_size=8,verbose=1)\nprint(history_model)","a5295529":"for ind, layer in enumerate(model.layers):\n    print(ind,\" \",layer.name)","0f900177":"import random\nfor i in [random.randint(0, len(all_artwork)) for i in range(10)]:\n    original_art_works =all_artwork[i]\n    plt.title('original')\n    plt.imshow(original_art_works)\n    plt.show()\n    reconstructed_art_works = np.squeeze(model.predict(np.asarray([original_art_works\/255.0])))\n    plt.title('reconstruction')\n    plt.imshow(reconstructed_art_works)\n    plt.show()","74c48afe":"model_output = model.get_layer(model.layers[6].name).output\nget_latent_vector = Model(inputs=model.input, outputs=model_output)","3244548b":"gc.collect()","ce5cd452":"latent_vectors = []\nlatent_labels = []\nall_artwork = []\nfor ii in glob.glob('..\/input\/best-artworks-of-all-time\/images\/images\/*'):\n    for j in glob.glob(ii + '\/*'):\n        all_artwork.append(cv2.resize(cv2.imread(j), (128,128)))\n        latent_vectors.append(np.squeeze(get_latent_vector.predict(np.asarray([cv2.resize(cv2.imread(j), (128,128))\/255.0]))))\n        latent_labels.append(ii.split('\/')[-1])","36dce89f":"import random\n\nc = list(zip(all_artwork,  latent_vectors, latent_labels))\n\nrandom.shuffle(c)\n\nall_artwork, latent_vectors, latent_labels = zip(*c)","3492b168":"gc.collect()","9ddaedd5":"lv = []\nfor i in range(len(latent_vectors)):\n    lv.append(np.reshape(latent_vectors[i],  (27*27*16)))","ffe841c3":"latent_labels = np.asarray(latent_labels)","5cf0cdfd":"import pandas as pd\nimport seaborn as sn\nfrom sklearn.manifold import TSNE\ntsne_model = TSNE(n_components=2, random_state=0,  perplexity=100, learning_rate=10.0)\ndata = tsne_model.fit_transform(np.asarray(lv[0:2000]))\nprint(data.shape)\ntsne_data = np.vstack((data.T, latent_labels[0:2000])).T\ntsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\ng = sn.FacetGrid(tsne_df, hue=\"label\",  size=10).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\ng.set(xticklabels=[], yticklabels=[])\nplt.show()","6b9317e1":"lv1 = []\nfor i in range(len(all_artwork)):\n    lv1.append(np.reshape(all_artwork[i],  (128*128*3)))","6e12b798":"import pandas as pd\nimport seaborn as sn\nfrom sklearn.manifold import TSNE\ntsne_model = TSNE(n_components=2, random_state=0,  perplexity=100, learning_rate=10.0)\ndata = tsne_model.fit_transform(np.asarray(lv1[0:2000])\/255.0)\nprint(data.shape)\ntsne_data = np.vstack((data.T, latent_labels[0:2000])).T\ntsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\ng = sn.FacetGrid(tsne_df, hue=\"label\",  size=10).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\ng.set(xticklabels=[], yticklabels=[])\nplt.show()","edb7796f":"import matplotlib.pyplot as plt\n\nfor kk in range(3):\n    plt.imshow(all_artwork[kk])\n    plt.show()\n    fig, ax = plt.subplots(nrows=4, ncols=4, figsize = (10,10))\n\n    i = 0\n    for row in ax:\n        for col in row:\n            col.imshow(latent_vectors[kk][:,:,i])\n            i = i+1\n\n    plt.show()","2decb267":"The aim of the encoder is so that we can get a compressed representation,  \nlater we will apply T-SNE to see if the compressions are distributed like the training data or not.","b2da09da":"The model we have created is very small, and with very few parameters, our aim is to just create a model which compresses images, we dont aim for a great reconstructor, we just want to extract features from the model.","506a2ecc":"****From here we will try to make an autoencoder**** ","22eb3e1d":"****We will try to find out similarity between paintings and also how machine learning algorithms do it****","bfb731ef":"Here we will try to create the histogram of all of the paintings of an artist, so a type of average histogram, We are doing this because we want to see if we can find similarity based on this feature, after this we will move forward to machine learning.","f295c872":"Importing our dataset","ce5dfdf1":"Let's find closest artists based on histogram","e4b178af":"Let's see what features did our compressed feature even extracts","85f18526":"Let;s get the compressed feature from the model"}}