{"cell_type":{"517224b0":"code","6282e037":"code","738cf488":"code","f21524aa":"code","c444333c":"code","ac8053d3":"code","8fcc1355":"code","942315ca":"code","0bf96d12":"code","16141991":"code","75719112":"code","330f4b1b":"code","e8662c94":"code","ff3edd74":"code","1a94b128":"code","0bdda324":"code","bb4801a8":"code","c49dde13":"code","09d3cd18":"code","92baad99":"code","8036d352":"code","e4a01996":"code","7b9fe7e8":"code","a42ec3c8":"code","ad512ceb":"code","6c28c01a":"code","45619a65":"code","98128743":"code","9742d10a":"code","2a601b7a":"code","a3a40f18":"code","9806141c":"code","652fd40a":"code","de4c5f52":"code","98fe7b93":"code","13467e0f":"code","a629722b":"code","88de56e8":"code","76da2a13":"code","4b290b44":"code","0605472f":"code","a7fa7078":"code","36dfab6b":"code","3418f7a7":"code","32cd66d3":"code","e7a41bc7":"code","a5769dda":"code","02826ba2":"code","7f6a2099":"code","09faba05":"code","3493fa6d":"code","3b579d8a":"code","953ebcf5":"code","cd7bf119":"code","4c1d14c5":"markdown","c588174d":"markdown","22c59cfc":"markdown","869b32f7":"markdown","5ad39afd":"markdown","fd64969b":"markdown","a63f73a3":"markdown","6ff83f21":"markdown","7dd47ad0":"markdown","2cf25b80":"markdown","f61add3f":"markdown","2203c1a4":"markdown","f53868b7":"markdown","99d55d52":"markdown","f73cae7c":"markdown","f82ff61a":"markdown","5855521e":"markdown","89f00eb1":"markdown","50a09c73":"markdown","dfe1b8fe":"markdown","48c86ba9":"markdown","78eb4f7f":"markdown","f48fe9de":"markdown","3e032af4":"markdown","e0d241f9":"markdown","23bb4d25":"markdown","02db8012":"markdown","246f1ccc":"markdown","f744b8f2":"markdown","55435336":"markdown","ad491a4b":"markdown","04784cc8":"markdown","1dce45ef":"markdown","0d75adb2":"markdown","1fad9e10":"markdown","1cab9e92":"markdown"},"source":{"517224b0":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6282e037":"from matplotlib import pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, roc_auc_score, recall_score, make_scorer, plot_confusion_matrix, confusion_matrix, accuracy_score\nfrom scipy.stats import uniform\n","738cf488":"sns.set()","f21524aa":"import plotly.express as px\ndef plot_histogram(dataframe, column, color: ['Discrete feature', '`None` if you only look at single continuous feature'], bins, title,width,height):\n    figure = px.histogram(\n                          dataframe,\n                          column,\n                          color=color,\n                          nbins=bins,\n                          title=title,\n                          width=width,\n                          height=height\n                          )\n    figure.show()","c444333c":"df = pd.read_csv('\/kaggle\/input\/kickstarter-projects\/ks-projects-201801.csv')","ac8053d3":"df.info()","8fcc1355":"df = df.sample(10000, random_state=42).reset_index().drop('index', axis=1)","942315ca":"df.head()","0bf96d12":"df[(df['pledged'] != df['usd pledged']) & (df['currency'] == 'USD')].head()","16141991":"df[(df['pledged'] != df['usd_pledged_real']) & (df['currency'] == 'USD')]","75719112":"df.drop(['usd pledged'],axis=1,inplace=True)","330f4b1b":"df['state'].value_counts()","e8662c94":"#First we remove all the entries where state = undefined OR state = live\n\nundef = df[df['state'] == 'undefined'].index\nlive = df[df['state'] == 'live'].index\n\ndf.drop(undef,axis=0,inplace=True)\ndf.drop(live,axis=0,inplace=True)\n\n\ndf['state'] = df['state'].map({'successful': 'successful',\n                               'failed': 'failed',\n                               'canceled': 'failed',\n                                'suspended': 'failed'})","ff3edd74":"df['state'].value_counts()","1a94b128":"df['state'].isnull().sum()","0bdda324":"suc_plus_fail = df['usd_goal_real'].describe().astype(int)\nsuc_plus_fail.name = 'All projects'\n\n\nsuccess = df[df['state'] =='successful']['usd_goal_real'].describe().astype(int)\nsuccess.name = 'Successful projects'\n\n\nfail = df[df['state'] =='failed']['usd_goal_real'].describe().astype(int)\nfail.name = 'Failed projects'\n\n\n\npd.concat([suc_plus_fail, success, fail],axis=1)\n","bb4801a8":"A = df[df['usd_goal_real'] - df['usd_pledged_real'] <= 0]\nA2= pd.Series([A[A['state'] == 'failed'].count()[0], A[A['state'] == 'successful'].count()[0]],index=['Fail','Success'])\nplt.figure(figsize=(10,15))\nplt.pie(A2.values,labels=A2.index)\nplt.title('All projects that received the desired amount of money')\nplt.show()","c49dde13":"df['Goal_minus_pledged'] = df['usd_goal_real'] - df['usd_pledged_real']","09d3cd18":"df['country'].value_counts()","92baad99":"crosst = pd.crosstab(df['country'],df['state'])\ncrosst['% of succ. projects'] = crosst['successful']\/crosst.sum(axis=1)\ncrosst.sort_values(by=['% of succ. projects'],inplace=True,ascending=False)\ncrosst.head(10)","8036d352":"df['backers'].describe().astype(int)","e4a01996":"sns.distplot(np.log(df[df['state'] == 'successful']['backers']+1), label='Success')\nsns.distplot(np.log(df[df['state'] == 'failed']['backers']+1), label='Fail')\nplt.legend()\nplt.show()","7b9fe7e8":"ccc = df['main_category'].value_counts()\npx.pie(ccc, #DataFrame or Series\n       names=ccc.index #Labels\n       ,values=ccc.values, #Values (Count)\n       title='Distribution of the main category')","a42ec3c8":"B = pd.crosstab(df['main_category'],df['state'])\nB['% of success'] = B['successful']\/B.sum(axis=1)\nB.sort_values(by='% of success', ascending=False,inplace=True)\nB","ad512ceb":"px.bar(B, x=B.index, y='% of success',\n       title='Proportion of successful projects for each category')","6c28c01a":"pd.to_datetime(df['launched']).hist(bins=60)\nplt.title(\"Distribution of time for when projects were started\")\nplt.show()","45619a65":"time = pd.to_datetime(df['launched'])\ntime[time < pd.to_datetime('2010\/01\/01')].sort_values().head(3)","98128743":"df[pd.to_datetime(df['launched']) < pd.to_datetime('2000\/01\/01')]","9742d10a":"#Remove the outlier to make the visualizations easier.\ndf1 = df.drop([6688],axis=0)\ndf1[df1['ID'] == 462917959]","2a601b7a":"df1['launched'] = pd.to_datetime(df1['launched'])\ndf1['launched'].min()","a3a40f18":"df1['days from 2008 to launch'] = (df1['launched'] - pd.to_datetime('2008\/01\/01')).apply(lambda x: x.days)","9806141c":"sns.distplot(df1[df1['state'] == 'successful']['days from 2008 to launch'], label='Success')\nsns.distplot(df1[df1['state'] == 'failed']['days from 2008 to launch'], label='Failure')\nplt.legend()","652fd40a":"df1['Deadline-launch'] = (pd.to_datetime(df1['deadline']) - pd.to_datetime(df1['launched'])).apply(lambda x: x.days)\ndf1['Deadline-launch'].describe()","de4c5f52":"plt.figure(figsize=(5,5))\nsns.distplot(df1['Deadline-launch'])\nplt.show()","98fe7b93":"plt.figure(figsize=(5,5))\nsns.distplot(df1[df1['state'] == 'successful']['Deadline-launch'], label='Success')\nsns.distplot(df1[df1['state'] == 'failed']['Deadline-launch'], label='Failure')\nplt.legend()\nplt.show()","13467e0f":"df.drop([6688],axis=0,inplace=True)\ndf['days from 2008 to launch'] = (pd.to_datetime(df['launched']) - pd.to_datetime('2008\/01\/01')).apply(lambda x: x.days)","a629722b":"df.head(1)","88de56e8":"X = df[['main_category', 'backers', 'usd_goal_real','Goal_minus_pledged', 'days from 2008 to launch']]\nX = pd.get_dummies(X) #One-hot encode `main_category`\ny = df['state']\nX.head()","76da2a13":"#Transform `backers`\n\nthr = X['backers'].mean() + X['backers'].std()*3 \nX['backers'] = X['backers'].apply(lambda x: x if x <= thr else thr+100)\nX['backers'] = np.log(X['backers']+1)\n\n\n#Transform `usd_goal_real`\nthr = X['usd_goal_real'].mean() + X['usd_goal_real'].std()*3\nclip_value = int(X[X['usd_goal_real'] <= thr]['usd_goal_real'].max() + 100 )\nX['usd_goal_real'] = np.log(X['usd_goal_real'].apply(lambda x: x if x <= thr else clip_value))\n\n#Transform `Goal-minus-pledged' (firstly by clipping), then robustly scaling AFTER splitting into train test\n\nup_thr = X['Goal_minus_pledged'].quantile(0.95)\ndown_thr = X['Goal_minus_pledged'].quantile(0.03) \n\ndef transform_gmp(x):\n    if down_thr <= x <= up_thr:\n        return x\n    elif x < down_thr:\n        return int(down_thr-100)\n    elif x > up_thr:\n        return int(up_thr+100)\nX['Goal_minus_pledged'] = X['Goal_minus_pledged'].apply(transform_gmp) ","4b290b44":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import StandardScaler\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, random_state=11)\n\ndays_scale = StandardScaler()\nX_train['days from 2008 to launch'] = days_scale.fit_transform(X_train['days from 2008 to launch'].values.reshape(-1,1))\nX_test['days from 2008 to launch'] = days_scale.transform(X_test['days from 2008 to launch'].values.reshape(-1,1))\n\n\ndiff_scale = RobustScaler() #Goal_minus_pledged\nX_train['Goal_minus_pledged'] = diff_scale.fit_transform(X_train['Goal_minus_pledged'].values.reshape(-1,1))\nX_test['Goal_minus_pledged'] = diff_scale.transform(X_test['Goal_minus_pledged'].values.reshape(-1,1))","0605472f":"#Naive Bayes\nnb_clf = GaussianNB().fit(X_train,y_train)\nprint(classification_report(y_true=y_test, y_pred=nb_clf.predict(X_test)))\nplot_confusion_matrix(nb_clf, X_test, y_test)","a7fa7078":"log_random_state = None\nlog_clf = LogisticRegression(random_state=log_random_state).fit(X_train, y_train)\nprint(classification_report(y_true=y_test, y_pred=log_clf.predict(X_test)))\nplot_confusion_matrix(log_clf, X_test, y_test)\n","36dfab6b":"MIN = 1 #Min number of neighbors\nMAX = 30 #Max number of neighbors\nknn_estimator = KNeighborsClassifier()\nknn_clf = GridSearchCV(knn_estimator,\n                       {'n_neighbors': range(MIN,MAX+1)}\n                       ,scoring='accuracy').fit(X_train, y_train)\nprint(f\"Best estimator: {knn_clf.best_estimator_}\")\nprint(classification_report(y_true=y_test, y_pred=knn_clf.predict(X_test)))\nplot_confusion_matrix(knn_clf, X_test, y_test)","3418f7a7":"tree_clf = tree.DecisionTreeClassifier().fit(X_train, y_train)\nprint(classification_report(y_true=y_test, y_pred=tree_clf.predict(X_test)))\nplot_confusion_matrix(tree_clf, X_test, y_test)","32cd66d3":"rf_clf = RandomForestClassifier(random_state=13).fit(X_train,y_train)\n\nprint(classification_report(y_true=y_test, y_pred=rf_clf.predict(X_test)))\nplot_confusion_matrix(rf_clf, X_test, y_test)","e7a41bc7":"df = pd.read_csv('\/kaggle\/input\/kickstarter-projects\/ks-projects-201801.csv')\n\n#Removing outliers in `launched`\nind = df[pd.to_datetime(df['launched']) < pd.to_datetime('2009\/01\/01')].index\ndf.drop(ind,axis=0,inplace=True)\n\n\n#Remove 'usd_pledged'\ndf.drop(['usd pledged'],axis=1,inplace=True)\n\n\n#\n#First we remove all the entries where state = undefined OR state = live\n\nundef = df[df['state'] == 'undefined'].index\nlive = df[df['state'] == 'live'].index\n\ndf.drop(undef,axis=0,inplace=True)\ndf.drop(live,axis=0,inplace=True)\n\n\ndf['state'] = df['state'].map({'successful': 'successful',\n                               'failed': 'failed',\n                               'canceled': 'failed',\n                                'suspended': 'failed'})\n\n\ndf['Goal_minus_pledged'] = df['usd_goal_real'] - df['usd_pledged_real']\ndf['days from 2008 to launch'] = (pd.to_datetime(df['launched']) - pd.to_datetime('2008\/01\/01')).apply(lambda x: x.days)","a5769dda":"X = df[['main_category', 'backers', 'usd_goal_real','Goal_minus_pledged', 'days from 2008 to launch']]\nX = pd.get_dummies(X) #One-hot encode `main_category`\ny = df['state']\nX.head()","02826ba2":"#Transform `backers`\n\nthr = X['backers'].mean() + X['backers'].std()*3 \nX['backers'] = X['backers'].apply(lambda x: x if x <= thr else thr+100)\nX['backers'] = np.log(X['backers']+1)\n\n\n#Transform `usd_goal_real`\nthr = X['usd_goal_real'].mean() + X['usd_goal_real'].std()*3\nclip_value = int(X[X['usd_goal_real'] <= thr]['usd_goal_real'].max() + 100 )\nX['usd_goal_real'] = np.log(X['usd_goal_real'].apply(lambda x: x if x <= thr else clip_value))\n\n#Transform `Goal-minus-pledged' (firstly by clipping), then robustly scaling AFTER splitting into train test\n\nup_thr = X['Goal_minus_pledged'].quantile(0.95)\ndown_thr = X['Goal_minus_pledged'].quantile(0.03) \n\ndef transform_gmp(x):\n    if down_thr <= x <= up_thr:\n        return x\n    elif x < down_thr:\n        return int(down_thr-100)\n    elif x > up_thr:\n        return int(up_thr+100)\nX['Goal_minus_pledged'] = X['Goal_minus_pledged'].apply(transform_gmp) ","7f6a2099":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import StandardScaler\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, random_state=11)\n\ndays_scale = StandardScaler()\nX_train['days from 2008 to launch'] = days_scale.fit_transform(X_train['days from 2008 to launch'].values.reshape(-1,1))\nX_test['days from 2008 to launch'] = days_scale.transform(X_test['days from 2008 to launch'].values.reshape(-1,1))\n\n\ndiff_scale = RobustScaler() #Goal_minus_pledged\nX_train['Goal_minus_pledged'] = diff_scale.fit_transform(X_train['Goal_minus_pledged'].values.reshape(-1,1))\nX_test['Goal_minus_pledged'] = diff_scale.transform(X_test['Goal_minus_pledged'].values.reshape(-1,1))","09faba05":"#Naive Bayes\nnb_clf = GaussianNB().fit(X_train,y_train)\nprint(classification_report(y_true=y_test, y_pred=nb_clf.predict(X_test)))\nplot_confusion_matrix(nb_clf, X_test, y_test)","3493fa6d":"log_random_state = None\nlog_clf = LogisticRegression(random_state=log_random_state,max_iter=300).fit(X_train, y_train)\nprint(classification_report(y_true=y_test, y_pred=log_clf.predict(X_test)))\nplot_confusion_matrix(log_clf, X_test, y_test)","3b579d8a":"knn_clf = KNeighborsClassifier().fit(X_train,y_train)\nprint(classification_report(y_true=y_test, y_pred=knn_clf.predict(X_test)))\nplot_confusion_matrix(knn_clf, X_test, y_test)","953ebcf5":"tree_clf = tree.DecisionTreeClassifier().fit(X_train, y_train)\nprint(classification_report(y_true=y_test, y_pred=tree_clf.predict(X_test)))\nplot_confusion_matrix(tree_clf, X_test, y_test)","cd7bf119":"rf_clf = RandomForestClassifier(random_state=13).fit(X_train, y_train)\n\nprint(classification_report(y_true=y_test, y_pred=rf_clf.predict(X_test)))\nplot_confusion_matrix(rf_clf, X_test, y_test)","4c1d14c5":"# The data set is quite large, so we will explore the random sample (10k). After we explore the sample and fit the models on it, we will retrain the models on the whole dataset (using the same features and transformations)","c588174d":"The `main_category` also seems to be a good predictor. Notably, 60% of the projects with the `main_category` valued `dance` are sucessful.","22c59cfc":"We see that the distributions are rouhgly the same.","869b32f7":"# Now let's look at the features","5ad39afd":"# Naive Bayes (whole dataset)","fd64969b":"We see that ALMOST ALL projects that reached the financial goal (i.e `usd_goal_real` - `usd_pledged_real` = 0)  SUCCEEDED (3602 out of 3638). So it seems that the differece between `usd_goal_real` and `usd_pledged_real` might be a good predictor. Hence we create one more feature, namely `goal-minus-pledged`","a63f73a3":"# Feature: backers","6ff83f21":"# Decision tree (whole dataset)","7dd47ad0":"# Decision tree (sample)","2cf25b80":"# Scaling continuous features","f61add3f":" Based on the data given, we want to predict whether the project will fail or succeed. Hence `state` will be our label. Let's check the distribution","2203c1a4":"Check the new distribution","f53868b7":"# Feature: launched","99d55d52":"# Feature: main_category","f73cae7c":"We will merge `failed` with `suspendeded` and `canceled`\n\n\nFurhermore, we will remove entries with `live` and `undefined`","f82ff61a":"From what I understood, `usd pledged` is supposed to represent the amount that has already beeen pledged (in USD). Furthemore, `pledged` is supposed to represent the amount that has already pledged in the currency that is specified in the column `currency`. Therefore, it seems that all entries with value `USD` in the column `currency` must have same value in both `pledged` and `usd pledged`. Let's check it","5855521e":"# Logistic (sample)","89f00eb1":"# So far we've been working with the sample. Let's try training and testing our model on the whole dataset (using the same features and transformations as above)","50a09c73":"# Random Forest (sample)","dfe1b8fe":"# Random Forest (whole dataset)","48c86ba9":" Projects initiated in the countries `SG` and `N,0\"` (whatever it means) seem to be having the highest probability of success. However, since the sample is fairly small for those countries, we cannot say for sure whether it is just a random chance or there is some other reason that may explain why projects from `SG` and `N,0\"` seem to be more successful","78eb4f7f":"The pattern is quite clear: the more backers there are, the more chances of the project being successful.","f48fe9de":"We see that there is no discrepancy. It seems that `usd_pledged` may contain some incorrect inputs (and on the top of that, it is likely that `usd pledged` and `usd_pledged_real` represent the same feature). For now, we remove `usd pledged`.","3e032af4":" From the table above, we see that there is discrepancy between `pledged` and `usd_pledged` (for entries that have `USD` in the column `currency`). Let's run the same test for features `pledged` and `usd_pledged_real`","e0d241f9":"We see that the distributions of the launch times of the successful and failed projects do differ. ","23bb4d25":"# KNN (whole dataset)","02db8012":"From the table above we see that the distribution for the feature `usd_goal_real`  differs quite starkly between `failed` and `successful` projects. Notably, failed projects tend to set way larger goal (which is shown by higher mean and WAY higher standard deviation).","246f1ccc":"# KNN (sample)","f744b8f2":"We see that most projects are launched after 2010. However, there is one outlier, namely one project launched in 1970. We will remove it.","55435336":"Let's see how the difference between time of the launch and the deadline affects the success rate","ad491a4b":"# Logistic (whole dataset)","04784cc8":"# Feature: country","1dce45ef":"# We will be using following features:\n1. main_category\n2. backers\n3. usd_goal_real\n4. Goal_minus_pledged (Synthetic feature derived after obtaining difference between amount that has been set as a GOAL and the amount that has already been pledged)\n5. days from 2008 to launch (Synthetic feature derived after SUBTRACTING `2008\/01\/01` from each entry in the feature `launched`)","0d75adb2":"We want to look at the distribution of the launched (using histogram). Furthermore, we might want to use it as a feature when training model. However, as things stand, we can't do it. `launched` is of type `datetime`, but we need numeric type. Hence we will do some transformation first. First note that the earliest date is 2009-04-27. So we will create a new feature, `days from 2008 to launch`, where each value represents the NUMBER of days from `2008\/01\/01` to the date of the launch of the project. (note that `2008\/01\/01` is arbitrary, we could've chosen any date). The main motivation behind the transformation is that this way we can convert type `datetime` into `numeric` **WITHOUT** losing any important information (which could've been lost if we used another approaches (for example for each datetime entry just extract year). The only disadvantage of our approach is that we slightly lose interpretability.","1fad9e10":"# Feature: usd_goal_real","1cab9e92":"# Naive Bayes (sample)"}}