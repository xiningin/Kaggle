{"cell_type":{"05153f86":"code","8c8e2d24":"code","389d31f3":"code","98f3a8f1":"code","d573a825":"code","8733738e":"code","bb231e33":"code","3b3f7ce1":"code","f7b97f5a":"code","dad7a788":"code","bbf10416":"code","86189e89":"code","0fe16dba":"code","749803e6":"code","aaf7e303":"code","479cfedf":"code","ff39b69e":"code","1d777ff9":"code","22c3059b":"code","b1196b46":"code","7eb0fa53":"code","92c083fb":"code","358801e1":"code","80c198f5":"code","a448f398":"code","02432076":"code","3efc8a07":"code","67fbe8bc":"code","a4ddef95":"code","b502238e":"code","6677d1a0":"code","6fde150d":"code","7efd45ac":"markdown","7077fbf4":"markdown","0e622379":"markdown","d0154c87":"markdown","a2f8e602":"markdown","076e4ba3":"markdown","e1c56313":"markdown","a55f1164":"markdown","c4b5451d":"markdown","36529392":"markdown","c6cf2101":"markdown","b96e4057":"markdown","14bbb361":"markdown","5e1638b7":"markdown","c5bb4aa7":"markdown","4f56dada":"markdown","91473f8b":"markdown","e45dd639":"markdown","399ca6eb":"markdown","4dd5cc40":"markdown","2bb9b5a3":"markdown","b5eb1a0e":"markdown","89a1d74a":"markdown","98eea586":"markdown","0c87cdce":"markdown","c15f2721":"markdown","5fdf39c9":"markdown","45a3c928":"markdown","8cb37431":"markdown","f160f7be":"markdown","000439c2":"markdown","783892de":"markdown","f6f4c2da":"markdown","a2e83992":"markdown","285ec7da":"markdown","dca45725":"markdown","af7642cb":"markdown","cec0b0bf":"markdown","903147ed":"markdown"},"source":{"05153f86":"import pandas as pd\nimport json\nimport datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport nltk\nimport numpy as np\nimport statsmodels.api as sm\n\n#nltk.download('punkt')\n#nltk.download('stopwords')\n\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom nltk import sent_tokenize, word_tokenize\nfrom nltk.tokenize import RegexpTokenizer\nfrom scipy import stats\n\n%matplotlib inline","8c8e2d24":"columns =  ['views', 'likes', 'dislikes', 'comment_count', 'trending_date', 'category_name', 'duration', \n            'tags', 'tags_rate', 'title', 'channel_title', 'tags_positive', 'tags_neutral', 'tags_negative',\n            'title_rate', 'title_positive', 'title_neutral', 'title_negative', 'publish_time']\n\ntrends = pd.read_csv('..\/input\/youtube-new\/USvideos.csv', parse_dates=['publish_time'], index_col='video_id')\nduration = pd.read_csv('..\/input\/extras\/USvideos_duration.csv',usecols=['video_id', 'duration'], index_col='video_id')\nsentimental = pd.read_csv('..\/input\/extras\/US_sentimental.csv', index_col='video_id')\ncreators = pd.read_csv('..\/input\/extras\/USchannels.csv', index_col='video_id',)\n\ndf = pd.merge(trends, duration, how='outer', on=['video_id'])\ndf = df.merge(sentimental, how='outer', on=['video_id'])\n\ndf.head(5)","389d31f3":"# import category description\ncategory_file = '..\/input\/youtube-new\/US_category_id.json'\n\nmap_category = {}\nwith open(category_file) as jsonfile:\n    categories = json.load(jsonfile)\n    \nfor item in categories['items']:\n    map_category[int(item['id'])] = item[\"snippet\"][\"title\"]\n\ndf['category_name'] = df['category_id'].map(map_category)\ndf['category_name'] = df['category_name'].astype('category')\n\ndf.dropna(inplace=True)\n\ndf.info()","98f3a8f1":"# fix trendind_date field\ndf['trending_date'] = df['trending_date'].apply(lambda dt: datetime.datetime.strptime(dt, '%y.%d.%m'))\n\ndf.info()\n\n#df['trending_date'].head(10)\n#dt='17.14.11'\n\n#print (datetime.datetime.strptime(dt, '%y.%d.%m'))\n\n\n","d573a825":"# Considering only the last record for each video for the summary analysis. \ndf_unique = df[columns].sort_values(by='trending_date',ascending=False).groupby(by='video_id').first()\n\ndf_unique.head(5)","8733738e":"# adding tag length column\ndf_unique['tags_length'] = df_unique['tags'].map(lambda tag: len(tag.split('|')))\ndf_unique.head(5)","bb231e33":"### Remove NaN values from creators Dataframe\n\ncreators.dropna(inplace=True)","3b3f7ce1":"total_videos = df_unique.shape[0]\n\nmax_views = df_unique['views'].max()\nsum_views = df_unique['views'].sum()\navg_views = df_unique['views'].mean()\nmed_views = df_unique['views'].median()\nmin_views = df_unique['views'].min()\nstd_views = df_unique['views'].std()\ntrend_min = df_unique['trending_date'].min()\ntrend_max = df_unique['trending_date'].max()\nchannels  = df_unique['channel_title'].nunique()\n\nsummary_data = [{\n    'Videos'             : total_videos,\n    'Channels'           : channels,\n    'Max of Views'       : max_views,    \n    'Average of Views'   : avg_views,\n    'Median of Views'    : med_views,\n    'Minimum of Views'   : min_views,\n    'Standard Deviation' : std_views,\n    'Start date'         : trend_min,\n    'End date'           : trend_max,\n    'Total of Views'     : sum_views\n}]\n\nvideos_summary = pd.DataFrame(data=summary_data, columns=list(summary_data[0].keys()))\nvideos_summary['Videos'] = videos_summary['Videos'].map('{:,}'.format)\nvideos_summary['Channels'] = videos_summary['Channels'].map('{:,}'.format)\nvideos_summary['Max of Views'] = videos_summary['Max of Views'].map('{:,}'.format)\nvideos_summary['Total of Views'] = videos_summary['Total of Views'].map('{:,}'.format)\nvideos_summary['Average of Views'] = videos_summary['Average of Views'].map('{:,.0f}'.format)\nvideos_summary['Median of Views'] = videos_summary['Median of Views'].map('{:,.0f}'.format)\nvideos_summary['Minimum of Views'] = videos_summary['Minimum of Views'].map('{:,.0f}'.format)\nvideos_summary['Standard Deviation'] = videos_summary['Standard Deviation'].map('{:,.0f}'.format)\n\nvideos_summary","f7b97f5a":"# Views distribution\n\nfig = plt.figure(figsize=(15, 5))\nax = fig.add_subplot(1, 1, 1)\n\nsns.set_style(\"dark\")\nsns.set(font_scale=0.9)\n\nax = sns.distplot(a=np.log10(df_unique['views'].values),label='Number of Views',hist=True, kde=True, rug=False, bins=100,ax=ax)\n\nax.set_title('Univariate Views Distribution', fontsize=15)\nax.set_xlabel('Views\\n(log10 base)')\nax.set_ylabel('Observations')\nax.set_yscale('linear')\nax.set_xlim(auto=True)\nax.set_ylim(auto=True)\n\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_001.png')\nplt.tight_layout()\nplt.show()","dad7a788":"quanties = [0.01, 0.10, 0.20, 0.30, 0.40, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]\nseries_quanties = df_unique['views'].quantile(quanties)\n\nrecord = {}\n\nfor item in series_quanties.items():    \n    record[str(int(item[0]*100)) + '%'] = f'{item[1]:,.0f}'\n    \npd.DataFrame(data=[record], columns=list(record.keys())) ","bbf10416":"sns.set(font_scale=0.9)\n\nts_trend = df_unique['trending_date'].value_counts().reset_index().rename(columns={'index' : 'Date', 'trending_date' : 'Videos'})\nts_trend['rate_change'] = ts_trend['Videos'].diff()\n\nfig = plt.figure(figsize=(15, 5))\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\n\nax1 = sns.lineplot(x=ts_trend['Date'], y=ts_trend['Videos'], color='blue', ax=ax1)\nax2 = sns.lineplot(x=ts_trend['Date'], y=ts_trend['rate_change'], color='darkred', ax=ax2)\n\nax1.set_xlim(auto=True)\nax1.set_ylim(auto=True)\n\nax1.set_title('Total of Trending Video Over Time', fontsize=15)\nax1.set_xlabel('Trending Date')\nax1.set_ylabel('Total of Videos')\n\nax2.set_xlim(auto=True)\nax2.set_ylim(auto=True)\n\nax2.set_title('Rate of Change Over Time', fontsize=15)\nax2.set_xlabel('Trending Date')\nax2.set_ylabel('Total of Videos')\n\nplt.tight_layout()\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_002.png')\nplt.show()","86189e89":"df_publish = df_unique[['trending_date', 'publish_time']].copy(deep=True)\ndf_publish['time_taken'] = (df_publish['trending_date'] - df_publish['publish_time']).dt.days\ncond = df_publish['time_taken'] > 0\n\ndf_publish_summary = df_publish[cond].groupby(by='trending_date', as_index=False).agg({\n                                                                                    'time_taken' : ['min', 'mean', 'max']\n                                                                                })\nfig = plt.figure(figsize=(20, 5))\nsns.set(font_scale=0.8)\n\nax1 = fig.add_subplot(1, 3, 1)\nax2 = fig.add_subplot(1, 3, 2)\nax3 = fig.add_subplot(1, 3, 3)\n\n\nax1 = sns.lineplot(x=df_publish_summary['trending_date'], y=df_publish_summary['time_taken']['min'], color='yellow', ax=ax1)\nax1.set_xlim(auto=True)\nax1.set_ylim(auto=True)\n\nax1.set_title('Minimum Tike Taken', fontsize=15)\nax1.set_xlabel('Trending Date')\nax1.set_ylabel('Days')\n\nax2 = sns.lineplot(x=df_publish_summary['trending_date'], y=df_publish_summary['time_taken']['mean'], color='blue', ax=ax2)\nax2.set_xlim(auto=True)\nax2.set_ylim(auto=True)\n\nax2.set_title('Average Tike Taken', fontsize=15)\nax2.set_xlabel('Trending Date')\nax2.set_ylabel('Days')\n\nax2 = sns.lineplot(x=df_publish_summary['trending_date'], y=df_publish_summary['time_taken']['max'], color='red', ax=ax3)\nax2.set_xlim(auto=True)\nax2.set_ylim(auto=True)\n\nax2.set_title('Max Tike Taken', fontsize=15)\nax2.set_xlabel('Trending Date')\nax2.set_ylabel('Days')\n\nplt.tight_layout()\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_003.png')\nplt.show()","0fe16dba":"df_category = df_unique[['category_name', 'views']].groupby(by='category_name', as_index=False).agg({'views' : ['count', 'sum']})\n\nfig = plt.figure(figsize=(15, 7))\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nsns.set(font_scale=0.7)\n\nax1.bar(df_category['category_name'], df_category['views']['sum'],align=\"center\", alpha=0.6, orientation='vertical',log=True)\nax1.set_title('Max Views per Category', fontsize=15)\nax1.set_xlabel('Category')\nax1.set_ylabel('Views')\nax1.set_xticklabels(df_category['category_name'], rotation='vertical')\nax1.set_xlim(auto=True)\nax1.set_ylim(auto=True)\n\n\nax2.pie(x=df_category['views']['count'], labels=df_category['category_name'], shadow=True, startangle=90, autopct='%1.1f%%',labeldistance=1.0,pctdistance=0.7)\nax2.set_title('Total of Videos Per Category', fontsize=15)\nax2.axis('equal')\nax2.set_xlim(auto=True)\nax2.set_ylim(auto=True)\n\nplt.tight_layout()\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_004.png')\nplt.show()","749803e6":"fig = plt.figure(figsize=(15, 7))\nax = fig.add_subplot(1, 1, 1)\n\nax = sns.boxplot(x=df_unique['category_name'], y=df_unique['views'], width=0.5,palette=\"colorblind\", data=df_unique,showfliers=True,showmeans=True,ax=ax)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n\nax.set_xlim(auto=True)\nax.set_ylim(auto=True)\n\nax.set_title('Number of Views per Category Distribution', fontsize=15)\nax.set_xlabel('Category')\nax.set_ylabel('Views')\nax.set_yscale('log')\n\n\nplt.tight_layout()\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_005.png')\nplt.show()","aaf7e303":"columns = ['views', 'likes', 'dislikes', 'comment_count', 'duration', 'tags_length']\ndf_corr = df_unique[columns].corr()\n\nfig = plt.figure(figsize=(15, 7))\nax = fig.add_subplot(1, 1, 1)\n\nax.set_title('Correlation coefficient between Views, Likes, Dislikes, Comments, Duration\\nCoefficient Range : [-1.0 to 1.0]', fontsize=15)\n\nax = sns.heatmap(df_corr, annot=True, fmt='.2f',vmin=-1.0, vmax=1.0, cmap='YlGnBu', center=0, linewidths=.5)\n\nplt.tight_layout()\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_012.png')\n\nplt.show()","479cfedf":"df_ratio = df_unique.groupby(by='category_name',as_index=False).agg({\n    'likes'         : ['sum'],\n    'dislikes'      : ['sum'],\n    'views'         : ['sum'],\n    'comment_count' : ['sum']\n})\n\nfig = plt.figure(figsize=(15, 10))\nax1 = fig.add_subplot(2, 2, 1)\nax2 = fig.add_subplot(2, 2, 2)\nax3 = fig.add_subplot(2, 2, 3)\nax4 = fig.add_subplot(2, 2, 4)\n\n\nax1.bar(df_ratio['category_name'], df_ratio['likes']['sum'] \/ df_ratio['dislikes']['sum'],align=\"center\", alpha=0.6, orientation='vertical',log=False)\nax1.set_title('Likes - Dislikes Ratio', fontsize=15)\nax1.set_xlabel('Category')\nax1.set_ylabel('Likes \/ Dislikes')\nax1.set_xticklabels(df_ratio['category_name'], rotation='vertical')\nax1.set_xlim(auto=True)\nax1.set_ylim(auto=True)\n\n\nax2.bar(df_ratio['category_name'], df_ratio['dislikes']['sum'] \/ df_ratio['views']['sum'],align=\"center\", alpha=0.6, orientation='vertical',log=True, color='r')\nax2.set_title('Dislikes - Views Ratio', fontsize=15)\nax2.set_xlabel('Category')\nax2.set_ylabel('Disikes \/ Views')\nax2.set_xticklabels(df_ratio['category_name'], rotation='vertical')\nax2.set_xlim(auto=True)\nax2.set_ylim(auto=True)\n\nax3.bar(df_ratio['category_name'], df_ratio['likes']['sum'] \/ df_ratio['views']['sum'],align=\"center\", alpha=0.6, orientation='vertical',log=True, color='g')\nax3.set_title('Likes - Views Ratio', fontsize=15)\nax3.set_xlabel('Category')\nax3.set_ylabel('Likes \/ Views')\nax3.set_xticklabels(df_ratio['category_name'], rotation='vertical')\nax3.set_xlim(auto=True)\nax3.set_ylim(auto=True)\n\nax4.bar(df_ratio['category_name'], df_ratio['views']['sum'] \/ df_ratio['comment_count']['sum'],align=\"center\", alpha=0.6, orientation='vertical',log=False, color='y')\nax4.set_title('Views - Comments Ratio', fontsize=15)\nax4.set_xlabel('Category')\nax4.set_ylabel('Views \/ Comments')\nax4.set_xticklabels(df_ratio['category_name'], rotation='vertical')\nax4.set_xlim(auto=True)\nax4.set_ylim(auto=True)\n\nplt.tight_layout()\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_006.png')\nplt.show()","ff39b69e":"fig = plt.figure(figsize=(25, 12))\nstopwords_list = list(stopwords.words('english'))\n\ndef normalize_data(tag):    \n    tag_word = tag.str.lower().str.cat(sep=' ')\n    tag_word = re.sub('[^A-Za-z]+', ' ', tag_word)\n    tokens = word_tokenize(tag_word)\n    filter_sentence = [word for word in tokens if not word in stopwords_list]\n    filter_one_chr = [word for word in filter_sentence if len(word) > 2]\n    \n    return [word for word in filter_one_chr if not word.isdigit()]\n    \ndef plot_word_cloud(word_data, x, y, i, title):\n    ax = fig.add_subplot(x, y, i)\n    \n    cloud = WordCloud(background_color = 'white', max_words = 100,  max_font_size = 50)\n    cloud.generate(' '.join(word_data))\n    \n    ax.imshow(cloud,interpolation='bilinear')\n    ax.set_title(label=title, fontsize=15)\n    ax.axis('off')\n\nindex = 1\n\nfor category in df_unique['category_name'].unique():    \n    cond = df_unique['category_name'] == category\n    plot_word_cloud(normalize_data(df_unique[cond]['tags']), 4,4, index, category)\n    index = index + 1\n    \nplt.tight_layout()\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_007.png')\nplt.show() ","1d777ff9":"df_sentimental = df[['category_name','tags_rate', 'views']].groupby(by=['tags_rate', 'category_name'], as_index=False).count()\n\ncond1 = df_sentimental['tags_rate'] == 'Positive'\ncond2 = df_sentimental['tags_rate'] == 'Neutral'\ncond3 = df_sentimental['tags_rate'] == 'Negative'\n\ndf_positive = df_sentimental[cond1][['category_name', 'views']] \ndf_positive.set_index(keys=['category_name'], inplace=True)\ndf_positive.fillna(value=0, inplace=True)\n\ndf_neutral = df_sentimental[cond2][['category_name', 'views']] \ndf_neutral.set_index(keys=['category_name'], inplace=True)\ndf_neutral.fillna(value=0, inplace=True)\n\ndf_negative = df_sentimental[cond3][['category_name', 'views']] \ndf_negative.set_index(keys=['category_name'], inplace=True)\ndf_negative.fillna(value=0, inplace=True)\n\ndf_total = df_positive + df_neutral + df_negative\n\ndf_total['perc_positive'] = (df_positive['views'] \/ df_total['views'])*100\ndf_total['perc_neutral'] = (df_neutral['views'] \/ df_total['views'])*100\ndf_total['perc_negative'] = (df_negative['views'] \/ df_total['views'])*100\ndf_total.reset_index(drop=False, inplace=True)\n\nfig = plt.figure(figsize=(15, 7))\nax1 = fig.add_subplot(1, 2, 1)\n\nax1.bar(df_total['category_name'], df_total['perc_positive'], align=\"center\", width=0.8, alpha=0.6, orientation='vertical',log=False, label='Positive', color='b')\nax1.bar(df_total['category_name'], df_total['perc_neutral'], align=\"center\", width=0.8, alpha=0.6, orientation='vertical',log=False, label='Neutral', color='y', bottom=df_total['perc_positive'])\nax1.bar(df_total['category_name'], df_total['perc_negative'], align=\"center\", width=0.8, alpha=0.6, orientation='vertical',log=False, label='Negative', color='r', bottom=df_total['perc_positive']+df_total['perc_neutral'])\n\nax1.set_title('Sentimental Analysys of Videos Tags', fontsize=15)\nax1.set_xlabel('Category')\nax1.set_ylabel('Sentimental Count')\nax1.set_xticklabels(df_total['category_name'], rotation='vertical')\nax1.set_xlim(auto=True)\nax1.set_ylim(auto=True)\nax1.legend()\n\n\ndf_sentimental_title = df[['category_name','title_rate', 'views']].groupby(by=['title_rate', 'category_name'], as_index=False).count()\n\ncond1 = df_sentimental_title['title_rate'] == 'Positive'\ncond2 = df_sentimental_title['title_rate'] == 'Neutral'\ncond3 = df_sentimental_title['title_rate'] == 'Negative'\n\ndf_positive_title = df_sentimental_title[cond1][['category_name', 'views']] \ndf_positive_title.set_index(keys=['category_name'], inplace=True)\ndf_positive_title.fillna(value=0, inplace=True)\n\ndf_neutral_title = df_sentimental_title[cond2][['category_name', 'views']] \ndf_neutral_title.set_index(keys=['category_name'], inplace=True)\ndf_neutral_title.fillna(value=0, inplace=True)\n\ndf_negative_title = df_sentimental_title[cond3][['category_name', 'views']] \ndf_negative_title.set_index(keys=['category_name'], inplace=True)\ndf_negative_title.fillna(value=0, inplace=True)\n\ndf_total_title = df_positive_title + df_neutral_title + df_negative_title\n\ndf_total_title['perc_positive'] = (df_positive_title['views'] \/ df_total_title['views'])*100\ndf_total_title['perc_neutral'] = (df_neutral_title['views'] \/ df_total_title['views'])*100\ndf_total_title['perc_negative'] = (df_negative_title['views'] \/ df_total_title['views'])*100\ndf_total_title.reset_index(drop=False, inplace=True)\n\nax2 = fig.add_subplot(1, 2, 2)\n\nax2.bar(df_total_title['category_name'], df_total_title['perc_positive'], align=\"center\", width=0.8, alpha=0.6, orientation='vertical',log=False, label='Positive', color='b')\nax2.bar(df_total_title['category_name'], df_total_title['perc_neutral'], align=\"center\", width=0.8, alpha=0.6, orientation='vertical',log=False, label='Neutral', color='y', bottom=df_total_title['perc_positive'])\nax2.bar(df_total_title['category_name'], df_total_title['perc_negative'], align=\"center\", width=0.8, alpha=0.6, orientation='vertical',log=False, label='Negative', color='r', bottom=df_total_title['perc_positive']+df_total_title['perc_neutral'])\n\nax2.set_title('Sentimental Analysys of Videos Title', fontsize=15)\nax2.set_xlabel('Category')\nax2.set_ylabel('Sentimental Count')\nax2.set_xticklabels(df_total['category_name'], rotation='vertical')\nax2.set_xlim(auto=True)\nax2.set_ylim(auto=True)\nax2.legend()\n\nplt.tight_layout()\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_008.png')\nplt.show()","22c3059b":"cond = df_unique['title_rate'] == 'Positive'\ndf1 = df_unique[cond][['title_positive','views', 'title_rate']]\ndf1.rename(columns={ 'title_positive' : 'score', \n                     'title_rate' : 'sentiment'\n                   },inplace=True)\n\ncond = df_unique['title_rate'] == 'Neutral'\ndf2 = df_unique[cond][['title_neutral','views', 'title_rate']]\ndf2.rename(columns={ 'title_neutral' : 'score', \n                     'title_rate' : 'sentiment'\n                   },inplace=True)\n\ncond = df_unique['title_rate'] == 'Negative'\ndf3 = df_unique[cond][['title_negative','views', 'title_rate']]\ndf3.rename(columns={ 'title_negative' : 'score', \n                     'title_rate' : 'sentiment'\n                   },inplace=True)\n\nsns.set(font_scale=2)\ndf_regplot = pd.concat([df1, df2, df3])\n\nkws = dict(s=50, linewidth=.5, edgecolor=\"w\")\n\nax = sns.lmplot(x='score', y='views', col='sentiment', data=df_regplot, aspect=1.3, height=8,\n                legend=True, hue='sentiment', markers='+',col_wrap=3)\n\nax.set(xlim=(0, 101))\nax.set(xscale='linear', yscale='log')\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_013.png')\n\n\nplt.tight_layout()\nplt.show()","b1196b46":"# y={0:.1f}x+{1:.1f}\n\nsummary_data = []\n\nslope, intercept, r_value, p_value, std_err = stats.linregress(x=np.log10(df1['score']), y=np.log10(df1['views']))\nsummary_data.append({'Score': 'Positive', 'Slope' : slope, 'Y-Intercept': intercept})\n\nslope, intercept, r_value, p_value, std_err = stats.linregress(x=np.log10(df2['score']), y=np.log10(df2['views']))\nsummary_data.append({'Score': 'Neutral', 'Slope' : slope, 'Y-Intercept': intercept})\n\nslope, intercept, r_value, p_value, std_err = stats.linregress(x=np.log10(df3['score']), y=np.log10(df3['views']))\nsummary_data.append({'Score': 'Negative', 'Slope' : slope, 'Y-Intercept': intercept})\n\n\npd.DataFrame(data=summary_data, columns=list(summary_data[0].keys()))","7eb0fa53":"model = sm.OLS(endog=np.log10(df1['views']), exog=np.log10(df1['score']))\nfit = model.fit()\nfit.summary()","92c083fb":"model = sm.OLS(endog=np.log10(df2['views']), exog=np.log10(df2['score']))\nfit = model.fit()\nfit.summary()","358801e1":"model = sm.OLS(endog=np.log10(df3['views']), exog=np.log10(df3['score']))\nfit = model.fit()\nfit.summary()","80c198f5":"cond = df_unique['tags_rate'] == 'Positive'\ndf1 = df_unique[cond][['tags_positive','views', 'tags_rate']]\ndf1.rename(columns={ 'tags_positive' : 'score', \n                     'tags_rate' : 'sentiment'\n                   },inplace=True)\n\ncond = df_unique['tags_rate'] == 'Neutral'\ndf2 = df_unique[cond][['tags_neutral','views', 'tags_rate']]\ndf2.rename(columns={ 'tags_neutral' : 'score', \n                     'tags_rate' : 'sentiment'\n                   },inplace=True)\n\ncond = df_unique['tags_rate'] == 'Negative'\ndf3 = df_unique[cond][['tags_negative','views', 'tags_rate']]\ndf3.rename(columns={ 'tags_negative' : 'score', \n                     'tags_rate' : 'sentiment'\n                   },inplace=True)\n\nsns.set(font_scale=2)\ndf_regplot = pd.concat([df1, df2, df3])\n\nkws = dict(s=50, linewidth=.5, edgecolor=\"w\")\n\nax = sns.lmplot(x='score', y='views', col='sentiment', data=df_regplot, aspect=1.3, height=8,\n                legend=True, hue='sentiment', markers='+',col_wrap=3)\n\nax.set(xlim=(0, 101))\nax.set(xscale='linear', yscale='log')\n\n\nplt.tight_layout()\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_014.png')\n\nplt.show()","a448f398":"# y={0:.1f}x+{1:.1f}\n\nsummary_data = []\n\ncond = (df1['score'] > 0) & (df1['views'] > 0)\nslope, intercept, r_value, p_value, std_err = stats.linregress(x=np.log10(df1[cond]['score']), y=np.log10(df1[cond]['views']))\nsummary_data.append({'Score': 'Positive', \n                     'Slope' : slope, \n                     'Y-Intercept': intercept,\n                     'P-Value' : p_value,\n                     'Standard Error' : std_err\n                    })\n\ncond = (df2['score'] > 0) & (df2['views'] > 0)\nslope, intercept, r_value, p_value, std_err = stats.linregress(x=np.log10(df2[cond]['score']), y=np.log10(df2[cond]['views']))\nsummary_data.append({'Score': 'Neutral', \n                     'Slope' : slope, \n                     'Y-Intercept': intercept,\n                     'P-Value' : p_value,\n                     'Standard Error' : std_err\n                    })\n\ncond = (df3['score'] > 0) & (df3['views'] > 0)\nslope, intercept, r_value, p_value, std_err = stats.linregress(x=np.log10(df3[cond]['score']), y=np.log10(df3[cond]['views']))\nsummary_data.append({'Score': 'Negative', \n                     'Slope' : slope, \n                     'Y-Intercept': intercept,\n                     'P-Value' : p_value,\n                     'Standard Error' : std_err\n                    })\n\npd.DataFrame(data=summary_data, columns=list(summary_data[0].keys()))","02432076":"fig = plt.figure(figsize=(15, 5))\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\nsns.set(font_scale=0.7)\n\n\ndf_top = df_unique[['views', 'title', 'category_name', 'channel_title' ]].nlargest(n=10,columns=['views'])\n\nax1.pie(x=df_top['views'], labels=df_top['title'], shadow=True, startangle=90, autopct='%1.1f%%',labeldistance=1.0,pctdistance=0.7)\nax1.set_title('Total 10 Videos Views', fontsize=12)\nax1.axis('equal')\nax1.set_xlim(auto=True)\nax1.set_ylim(auto=True)\nsns.set(font_scale=0.9)\n\ndf_top_cat = df_top[['category_name', 'views']].groupby('category_name', as_index=False).sum()\nax2.pie(x=df_top_cat['views'], labels=df_top_cat['category_name'], shadow=True, startangle=90, autopct='%1.1f%%',labeldistance=1.0,pctdistance=0.7)\nax2.set_title('Total 10 Categories', fontsize=12)\nax2.axis('equal')\nax2.set_xlim(auto=True)\nax2.set_ylim(auto=True)\nplt.tight_layout()\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_009.png')\nplt.show()","3efc8a07":"cond = (df_unique['category_name'] == 'Music') | (df_unique['category_name'] == 'Entertainment')\ntotal_music_enter = df_unique[cond]['views'].sum()\n\ncond = (df_unique['category_name'] != 'Music') & (df_unique['category_name'] != 'Entertainment')\ntotal_others = df_unique[cond]['views'].sum()\n\nsummary_data = [{\n        'Category' : 'Music & Entertainment',\n        'Views'    : total_music_enter},\n    {\n        'Category' : 'All Others',\n        'Views'    : total_others\n    }\n]\n\ndf_compare = pd.DataFrame(data=summary_data, columns=list(summary_data[0].keys()))\n\nfig = plt.figure(figsize=(15, 5))\nax1 = fig.add_subplot(1, 1, 1)\n\nexplode= (0.1, 0)\ncolors = ['darksalmon','royalblue']\n\n\nax1.pie(x=df_compare['Views'], labels=df_compare['Category'], shadow=True, startangle=90, autopct='%1.1f%%',\n        labeldistance=1.0, pctdistance=0.7, explode=explode, colors=colors)\nax1.set_title('Music & Entertainment Total Views versus All Others Categories', fontsize=12)\nax1.axis('equal')\nax1.set_xlim(auto=True)\nax1.set_ylim(auto=True)\n\nplt.tight_layout()\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_010.png')\n\nplt.show()","67fbe8bc":"size_bins = [-1, 60, 120, 300, 600]\ngroup_names = ['< 1 min', '1-2 min(s)', '2-5 mins', '5-10 mins', '> 10 mins']\ncolor = ['black', 'red', 'green', 'blue', 'cyan']\nsize_bins.append(df_unique['duration'].max()+1)\nvideo_columns = ['duration', 'views']\n\ndf_videos = df_unique[video_columns].copy(deep=True)\ndf_videos['Videos Range'] = pd.cut(df_videos['duration'],size_bins, labels=group_names)\n\ndf_videos_agg  = df_videos.groupby(by='Videos Range', as_index=False).agg({\n                                        'views' : ['sum']\n                                    })\n\nfig = plt.figure(figsize=(14, 5))\nax = fig.add_subplot(1, 1, 1)\n\nax.bar(df_videos_agg['Videos Range'], df_videos_agg['views']['sum'], align=\"center\", alpha=0.6, orientation='vertical', color=color, edgecolor='black')\n\nax.set_title('Total of Views per Video Duration', fontsize=15)\nax.set_ylabel('Views')\nax.set_xlim(auto=True)\nax.set_ylim(auto=True)\nax.set_yscale('linear')\n\nplt.tight_layout()\n#plt.savefig('..\/..\/..\/..\/resources\/images\/plot_011.png')\n\nplt.show()","a4ddef95":"cond = (creators['viewCount'] > 0) & (creators['videoCount'] > 0) & (creators['subscriberCount'] > 0)\n\ncreators_corr = creators[cond][['channel_id', 'subscriberCount', 'videoCount', 'viewCount']].groupby('channel_id').last()\n\ndf1 = creators_corr[['subscriberCount', 'viewCount']].copy(deep=True)\ndf1.rename(columns={'subscriberCount' : 'correlation_count', 'viewCount' : 'views'}, inplace=True)\ndf1['correlation_type'] = 'subscribers'\n\ndf2 = creators_corr[['videoCount', 'viewCount']].copy(deep=True)\ndf2.rename(columns={'videoCount' : 'correlation_count', 'viewCount' : 'views'}, inplace=True)\ndf2['correlation_type'] = 'uploads'\n\ndf_creators_plot = pd.concat([df1, df2])\n\nax = sns.lmplot(x='correlation_count', y='views', col='correlation_type', data=df_creators_plot, aspect=1.3, height=8,\n                legend=True, hue='correlation_type', markers='+',col_wrap=2)\n\nax.set(xscale='log', yscale='log')\n\nplt.tight_layout()\n##plt.savefig('..\/..\/..\/..\/resources\/images\/plot_015.png')\n\nplt.show()\n","b502238e":"# y={0:.1f}x+{1:.1f}\nsummary_data = []\n\nslope, intercept, r_value, p_value, std_err = stats.linregress(x=np.log10(df1['correlation_count']), y=np.log10(df1['views']))\nsummary_data.append({'Correlation': 'subscribers', \n                     'Slope' : slope, \n                     'Y-Intercept': intercept,\n                     'P-Value' : p_value,\n                     'Standard Error' : std_err\n                    })\n\nslope, intercept, r_value, p_value, std_err = stats.linregress(x=np.log10(df2['correlation_count']), y=np.log10(df2['views']))\nsummary_data.append({'Correlation': 'uploads', \n                     'Slope' : slope, \n                     'Y-Intercept': intercept,\n                     'P-Value' : p_value,\n                     'Standard Error' : std_err\n                    })\n\npd.DataFrame(data=summary_data, columns=list(summary_data[0].keys()))","6677d1a0":"model = sm.OLS(endog=np.log10(df1['views']), exog=np.log10(df1['correlation_count']))\nfit = model.fit()\nfit.summary()","6fde150d":"model = sm.OLS(endog=np.log10(df2['views']), exog=np.log10(df2['correlation_count']))\nfit = model.fit()\nfit.summary()","7efd45ac":"**Observation:** The correlation between tags sentiment and views presented not satisfactorily results. A higher score for p-values and standard errors can be examined for this analysis. The hypothesis-test of the existence of a correlation between the sentiment of the tags and the number of views was rejected.","7077fbf4":"#### Correlation between Title Sentiment and Views\n__________________","0e622379":"**Observation:** As we can see, the video duration falls into a range duration of 2-5 minutes. Knowing how long should YouTube videos be is crucial for marketing campaign and producer efforts. Shorter videos demonstrated to be the key to success. Keep people attention for more than 5 minutes is a challenging task. Any decision in terms of video duration must take into consideration shorted videos rather than longer ones.","d0154c87":"**Observation:** According to YouTube, tagging is one of the most important ways to rank your video in YouTube search results: Tags help users find your video when they search the site. When users type keywords related to your tags your video will appear in their search results. Therefore, knowing the most used tags per category can provide excellent insights in order to achieve a higher number of people. Some keywords across the categories were expected such as dog or cat for Pets & Animals categories or Fornite and Pokemon for Gaming categories. Discovering the keyword iPhone as one of the most used keywords for the Shows category still remains a secret for the group members.","a2f8e602":"#### Correlation between Total of Subscribers & Total of Uploads and Views\n________________","076e4ba3":"Correlation between metrics\n______________________\nObserve the correlation between Views, Like, Dislikes, Comments, Duration.","e1c56313":"#### OLS Regression for Negative Sentiment","a55f1164":"#### Music & Entertainment Categories Versus Remainder Population\n____________","c4b5451d":"**Observation:** Examining the sentimental used by videos titles and tags per category can provide us directions regarding how to make to a selected product association with a specific channel or category. Howto & Style and Pets & Animals categories present higher positives score for tags (higher than 60%). In another hand, Nonprofits & Activism category presents the higher positive score but this score is below 50%. This initial analysis brings the following question: Is there any correction between titles and tags sentiments with the number of views?","36529392":"**Observation :** Comparing the probability distribution of the total number of views versus the quantiles split in a range of 10%, we can start predicting some more realistic potential numbers of people that the marketing campaign might achieve using Youtube. Something to notice is the fact the from 70% to 80%, the difference between the total of numbers of views is minimum. Another important fact is 99% of the views represents a total of 25M. Therefore, a total of 225M views is an estimate that should be considered as an outlier.","c6cf2101":"**Observation :** Analyzing the distribution for each category, we can observe that Shows presents what can be considered a normal distribution. Music and Entertainment and Film & Animations categories present a considerable number of outliers. Therefore, predicting data for these categories might be difficult due to the presence of a higher number of outliers.","b96e4057":"#### Views per Category\n__________\nIdentity the performance of the categories areas.","14bbb361":"### Data Cleanup Process\n________________\n","5e1638b7":"**Observation :** Music and entertainment categories dominated the total number of views but comparing these two categories with the total number of trending videos, the game change. Even though the Entertainment category has a higher number of trending videos, this fact does not help in making this category to dominate also the total of views.","c5bb4aa7":"#### Videos Duration\n______________________\nPatterns of video duration","4f56dada":"#### Trending Videos Analysis over Time\n__________\nTime-Series Analysis of Trending Videos behaviors.","91473f8b":"#### Correlation between Tags Sentiment and Views\n_______","e45dd639":"**Observation :** Once the status of a video change from publishing to trending, it means that the potential to reach more people increase on an exponential scale. Observing this behavior can give us insights to plans for deployment dates for the marketing campaign. A higher number of trending videos, higher are the chances to reach more people. No trending videos at all mean that we need to find new ways to reach people. January, April, and May seems to be months of more activity for trending videos. It's important also to observe the rate of change of the trending video. The activity tends to remains constant over time. The numbers of days required for a video change the status from published to trended in December through February in average is huge. There is definitely something causing this phenomenon for these months. January presents two behaviors: a higher number of trending videos and higher time taken for video status change.","399ca6eb":"**Observation:** As we can see, the title sentiment has a strong correlation. As the positive or negative score increases, the number of views also increase. R-squared score presents a result of 0.97 indicating a strong relationship between the two variables. Another really good indicator is the p-value score which is below 0.001. It means that the results were highly significant. Or, in other words, they're very unlikely to have occurred by chance alone.","4dd5cc40":"#### Views Distribution per Category\n______\nIdentity how the numbers of views are distributed across the categories.","2bb9b5a3":"**Observation :** The dataset provides a total of 6.351 videos and 2.198 channels. The timeframe of the dataset covers around eleven months (between Nov-2017 until June-2018). The dataset has the potential to connect our efforts in the marketing campaign with almost 2M people(views) on average. A standard deviation of 7M in additional with the enormous difference between the average and the median gives us the inside how spread out the dataset is. The maximum number of views also give us another inside for potential outlier(s) inside of the dataset. The total number of views is almost 38 times higher than US current population.","b5eb1a0e":"#### Sentimental Analysis\n________\nSentimental analysis for videos titles and tags across categories.","89a1d74a":"**Observation:** The ratio between Likes and Dislikes presents the expected results. Pets & Animals and Shows categories present the higher ratios scores. News & Politics and Nonprofits & Blogs categories present the lowest ratios scores. Another interesting ratio result can be observed in between Views and Comments. Autos & Vehicles, Travel & Events, and Shows categories presents higher ratio scores. Nonprofits & Activism and News & Politics present the lowest ratios score. Higher Likes and Dislikes ratios can be used to measure people satisfaction. More Likes can bring more Views. Higher Views and Comments ratios can be used to explore more direct communication with your audiences. Hearing your audiences opinion is crucial for the business.","98eea586":"#### Used Tags\n_______________\nTop keywords (tags) used per video category.","0c87cdce":"**Trending, time series, and correlation data analysis of Youtube trending videos dataset.**\n\n** My first data analysis project presented at BootCampSpot (Data Analysis 2019)** \n\n**Inspirations:**\n+ YouTube Trending Videos Project\n    https:\/\/www.kaggle.com\/datasnaek\/youtube-new\n    \n+ Alexis Gardin Analysis\n    https:\/\/www.kaggle.com\/alexisgardin\/youtube-video-analysis-si4\/report\n    \n+ Yanni Papadakis Analysis\n    https:\/\/www.kaggle.com\/yanpapadakis\/trending-youtube-video-metadata-analysis    \n    \n____________","c15f2721":"#### Univariate Views Distribution Versus Quanties Distribution\n______\nIn-deep analysis of the dataset[](http:\/\/)","5fdf39c9":"**Observation:** Youtube is a territory dominated by Music & Entertainment. Any kind of association with these categories has the potential to bring an enormous number of views. As we can see, people tend to love to use Youtube to watch Music and Entertainment videos. It's clear also to see that they tend to watch the same video several times. Retaining people attention is difficult and knowing where to explore this kind of behavior can potentially lead to success.","45a3c928":"#### Days Taken for Video Classification\n_______\n","8cb37431":"#### OLS Regression for Subscribers","f160f7be":"#### Ratios per Categories\n________________\nRatios across several metrics.","000439c2":"#### Data Analysis Process\n____________","783892de":"**Observation:** Views and Likes presents are a strong correlation which was expected. Not surprisingly the correlation between views and comments is not so strong due to the fact that not the majority of the viewers make comments of a video. Another not so strong correlation is between Views and Dislikes which tells us that might have more factors involved that make a person dislike a video. The biggest surprise in this correlation analysis is the weaker correction between Views and Video Duration. The result was unexpected by all members of the group. All additional studies that were performed by the group indicated us a strong correlation between Views and Video duration but this hypothesis proved to be wrong at least for trending videos.","f6f4c2da":"**Observation:** As expected, the correlation between subscribers and views is strong. The same behavior can be examined for the correlation between uploads and views. R-squared score presents a result of 0.98 indicating a strong relationship between the two variables. Another really good indicator is the p-value score which is below 0.001. Therefore, the number of subscriber of a channel and the total of uploads has a direct relationship with the number of views. As one variable increase, the other also increases.","a2e83992":"#### OLS Regression for Neutral Sentiment","285ec7da":"#### Top 10 Creators & Categories\n_______","dca45725":"#### Summary Information\n> ______________\nHigh-level summary information related to videos trending dataset.","af7642cb":"#### OLS Regression for Positive Sentiment","cec0b0bf":"#### OLS Regression for Uploads","903147ed":"> ### Dependencies\n______"}}