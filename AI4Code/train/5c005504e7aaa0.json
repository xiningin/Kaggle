{"cell_type":{"84645e5e":"code","d8094599":"code","e0b8b774":"code","3e7b8532":"code","bc920e0f":"code","0c1be047":"code","2a4d6dfa":"code","c7aba396":"code","c4077fce":"code","db65844f":"code","36f39ee3":"code","be815522":"code","f0f6414d":"code","fd41b396":"code","cf0ce604":"code","dbf5b077":"code","475b8e8e":"code","cb3a9e70":"markdown","72f212e2":"markdown","ec4c5cd5":"markdown","6ef6be7b":"markdown","e4dd78b3":"markdown","a367ee52":"markdown","efab1dec":"markdown","97c24a89":"markdown","2c748f4c":"markdown","dd5cdb60":"markdown","23fd32cd":"markdown","8cf185a6":"markdown","2ae26d0b":"markdown","9a6be1ac":"markdown","2d3c04a1":"markdown"},"source":{"84645e5e":"#colab\n# from google.colab import drive\n# drive.mount('\/content\/drive')","d8094599":"!pip install catboost\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#--------------------------------#\n\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import KFold, train_test_split","e0b8b774":"train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntrain","3e7b8532":"test = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')\ntest","bc920e0f":"print(train.isnull().sum().max())\nprint(test.isnull().sum().max())","0c1be047":"train.isnull().sum().plot()","2a4d6dfa":"test.isnull().sum().plot()","c7aba396":"plt.figure(figsize=(12,6))\nsns.countplot(train['target'])","c4077fce":"scores_logloss = []\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\ntrain_x = train.drop(columns = 'target')\ntrain_y = train['target']","db65844f":"for tr_idx, va_idx in kf.split(train_x):\n  tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n  tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n\n  xgb = XGBClassifier(eta = 0.05,\n    max_depth = 10,\n    subsample = 0.8,\n    colsample_bytree = 0.7,\n    objective = 'reg:logistic',\n    eval_metric = 'auc',\n    tree_method = 'gpu_hist', \n    predictor = 'gpu_predictor')\n  \n  xgb.fit(tr_x, tr_y, verbose = True)\n  xgb_pred = xgb.predict_proba(va_x)\n\n  logloss = log_loss(va_y, xgb_pred)\n  scores_logloss.append(logloss)\n  print(logloss)\n\nlogloss_xgb = np.mean(scores_logloss)\nlogloss_xgb","36f39ee3":"for tr_idx, va_idx in kf.split(train_x):\n  tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n  tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n\n  cat = CatBoostClassifier(depth=8,\n                         iterations=1000,\n                         learning_rate=0.02,                    \n                         eval_metric='MultiClass',\n                         loss_function='MultiClass',\n                         bootstrap_type= 'Bernoulli',\n                         leaf_estimation_method='Gradient',\n                         random_state=123,\n                         task_type='GPU')\n  \n  cat.fit(tr_x, tr_y, verbose = False)\n  cat_pred = cat.predict_proba(va_x)\n\n  logloss = log_loss(va_y, cat_pred)\n  scores_logloss.append(logloss)\n  print(logloss)\n\nlogloss_cat = np.mean(scores_logloss)\nlogloss_cat","be815522":"tr_x, val_x, tr_y, val_y = train_test_split(train_x, train['target'], test_size=0.2, random_state = 42)","f0f6414d":"xgb.fit(train_x, train_y, verbose = True)","fd41b396":"cat.fit(tr_x, tr_y, eval_set=(val_x, val_y), verbose = 10, early_stopping_rounds=30)","cf0ce604":"result_xgb = xgb.predict_proba(test)\nresult_cat = cat.predict_proba(test)\nresult_esn = (result_cat+result_xgb)\/2","dbf5b077":"sub = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv')\ncol = sub.columns[1:]\nresult = pd.DataFrame(result_esn)\nresult.columns = col\nresult['id'] = result.index+200000\nresult","475b8e8e":"result.to_csv('sub.csv', index=False)","cb3a9e70":"# **Model**","72f212e2":"# **Import Library**","ec4c5cd5":"## **Used Library**\n\n### **Basic Library**\n*   **Numpy**\n*   **Pandas**\n*   **Seaborn**\n*   **Matplotlib**\n\n### **Model Library**\n\n\n*   **CatBoost**\n*   **XGBoost**\n*   **Sklearn**","6ef6be7b":"## **Ensemble**","e4dd78b3":"### **XGBoost**","a367ee52":"## **Data Read**","efab1dec":"### **CatBoost Fit**","97c24a89":"## **Checking Missing Values**\n\n### **There are no missing values**","2c748f4c":"### **XGBoost Fit**","dd5cdb60":"## **Validation**","23fd32cd":"## **Target is skewed!!**\n\n### **\u2192 Need to use K-Fold validation**\n\n","8cf185a6":"# **Data Load**\n\n*   **Train Data**\n*   **Test Data**\n\n**Train Data & Test Data have lots of features! \\\nSo, we need to check NAN values & target's distribution**","2ae26d0b":"## **Fitting**","9a6be1ac":"### **Train Data Split**","2d3c04a1":"### **CatBoost**"}}