{"cell_type":{"7f64dc0a":"code","5d1b195b":"code","0db472f0":"code","f364f34b":"code","669d8de3":"code","756b6c5b":"code","2772f93a":"code","e1f117cf":"code","d302a5d9":"code","de1716eb":"code","dd40882e":"code","d6dcb57a":"code","8cb363b9":"code","1382b7cc":"code","c1429a9b":"markdown"},"source":{"7f64dc0a":"# Imports\nimport numpy as np\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\nfrom keras import backend\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\n\nfrom scipy.optimize import fmin_l_bfgs_b","5d1b195b":"# Hyperparams\nITERATIONS = 10\nCHANNELS = 3\nIMAGE_SIZE = 500\nIMAGE_WIDTH = IMAGE_SIZE\nIMAGE_HEIGHT = IMAGE_SIZE\nIMAGENET_MEAN_RGB_VALUES = [123.68, 116.779, 103.939]\nCONTENT_WEIGHT = 0.02\nSTYLE_WEIGHT = 4.5\nTOTAL_VARIATION_WEIGHT = 0.995\nTOTAL_VARIATION_LOSS_FACTOR = 1.25","0db472f0":"# Paths\ninput_image_path = \"input.png\"\nstyle_image_path = \"style.png\"\noutput_image_path = \"output.png\"\ncombined_image_path = \"combined.png\"\n\n# San Francisco\nsan_francisco_image_path = \"https:\/\/www.economist.com\/sites\/default\/files\/images\/print-edition\/20180602_USP001_0.jpg\"\n\n# Warsaw by Tytus Brzozowski, http:\/\/t-b.pl\ntytus_image_path = \"http:\/\/meetingbenches.com\/wp-content\/flagallery\/tytus-brzozowski-polish-architect-and-watercolorist-a-fairy-tale-in-warsaw\/tytus_brzozowski_13.jpg\"","f364f34b":"#Input visualization \ninput_image = Image.open(BytesIO(requests.get(san_francisco_image_path).content))\ninput_image = input_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\ninput_image.save(input_image_path)\ninput_image","669d8de3":"# Style visualization \nstyle_image = Image.open(BytesIO(requests.get(tytus_image_path).content))\nstyle_image = style_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\nstyle_image.save(style_image_path)\nstyle_image","756b6c5b":"# Data normalization and reshaping from RGB to BGR\ninput_image_array = np.asarray(input_image, dtype=\"float32\")\ninput_image_array = np.expand_dims(input_image_array, axis=0)\ninput_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\ninput_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\ninput_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\ninput_image_array = input_image_array[:, :, :, ::-1]\n\nstyle_image_array = np.asarray(style_image, dtype=\"float32\")\nstyle_image_array = np.expand_dims(style_image_array, axis=0)\nstyle_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\nstyle_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\nstyle_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\nstyle_image_array = style_image_array[:, :, :, ::-1]\n","2772f93a":"# Model\ninput_image = backend.variable(input_image_array)\nstyle_image = backend.variable(style_image_array)\ncombination_image = backend.placeholder((1, IMAGE_HEIGHT, IMAGE_SIZE, 3))\n\ninput_tensor = backend.concatenate([input_image,style_image,combination_image], axis=0)\nmodel = VGG16(input_tensor=input_tensor, include_top=False)","e1f117cf":"def content_loss(content, combination):\n    return backend.sum(backend.square(combination - content))\n\nlayers = dict([(layer.name, layer.output) for layer in model.layers])\n\ncontent_layer = 'block2_conv2'\nlayer_features = layers[content_layer]\ncontent_image_features = layer_features[0, :, :, :]\ncombination_features = layer_features[2, :, :, :]\n\nloss = backend.variable(0.)\nloss += CONTENT_WEIGHT * content_loss(content_image_features,\n                                      combination_features)","d302a5d9":"def gram_matrix(x):\n    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n    gram = backend.dot(features, backend.transpose(features))\n    return gram","de1716eb":"def compute_style_loss(style, combination):\n    style = gram_matrix(style)\n    combination = gram_matrix(combination)\n    size = IMAGE_HEIGHT * IMAGE_WIDTH\n    return backend.sum(backend.square(style - combination)) \/ (4. * (CHANNELS ** 2) * (size ** 2))\n\nstyle_layers = [\"block1_conv2\", \"block2_conv2\", \"block3_conv3\", \"block4_conv3\", \"block5_conv3\"]\nfor layer_name in style_layers:\n    layer_features = layers[layer_name]\n    style_features = layer_features[1, :, :, :]\n    combination_features = layer_features[2, :, :, :]\n    style_loss = compute_style_loss(style_features, combination_features)\n    loss += (STYLE_WEIGHT \/ len(style_layers)) * style_loss","dd40882e":"def total_variation_loss(x):\n    a = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, 1:, :IMAGE_WIDTH-1, :])\n    b = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, :IMAGE_HEIGHT-1, 1:, :])\n    return backend.sum(backend.pow(a + b, TOTAL_VARIATION_LOSS_FACTOR))\n\nloss += TOTAL_VARIATION_WEIGHT * total_variation_loss(combination_image)","d6dcb57a":"outputs = [loss]\noutputs += backend.gradients(loss, combination_image)\n\ndef evaluate_loss_and_gradients(x):\n    x = x.reshape((1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n    outs = backend.function([combination_image], outputs)([x])\n    loss = outs[0]\n    gradients = outs[1].flatten().astype(\"float64\")\n    return loss, gradients\n\nclass Evaluator:\n\n    def loss(self, x):\n        loss, gradients = evaluate_loss_and_gradients(x)\n        self._gradients = gradients\n        return loss\n\n    def gradients(self, x):\n        return self._gradients\n\nevaluator = Evaluator()","8cb363b9":"x = np.random.uniform(0, 255, (1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)) - 128.\n\nfor i in range(ITERATIONS):\n    x, loss, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.gradients, maxfun=20)\n    print(\"Iteration %d completed with loss %d\" % (i, loss))\n    \nx = x.reshape((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\nx = x[:, :, ::-1]\nx[:, :, 0] += IMAGENET_MEAN_RGB_VALUES[2]\nx[:, :, 1] += IMAGENET_MEAN_RGB_VALUES[1]\nx[:, :, 2] += IMAGENET_MEAN_RGB_VALUES[0]\nx = np.clip(x, 0, 255).astype(\"uint8\")\noutput_image = Image.fromarray(x)\noutput_image.save(output_image_path)\noutput_image","1382b7cc":"# Visualizing combined results\ncombined = Image.new(\"RGB\", (IMAGE_WIDTH*3, IMAGE_HEIGHT))\nx_offset = 0\nfor image in map(Image.open, [input_image_path, style_image_path, output_image_path]):\n    combined.paste(image, (x_offset, 0))\n    x_offset += IMAGE_WIDTH\ncombined.save(combined_image_path)\ncombined","c1429a9b":"Check out corresponding Medium article:\n\n[Style Transfer - Styling Images with Convolutional Neural Networks](https:\/\/towardsdatascience.com\/style-transfer-styling-images-with-convolutional-neural-networks-7d215b58f461)"}}