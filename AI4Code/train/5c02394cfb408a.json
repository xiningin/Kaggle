{"cell_type":{"caa2fd03":"code","1d5fc3fb":"code","e4578f12":"code","ed5c089a":"code","de639b2a":"code","41247c44":"code","af1ae245":"code","201543ab":"code","693885ee":"code","a10fc4fe":"code","1549891c":"code","59cde77e":"code","4484bc67":"code","a187ba08":"code","1cf8a15e":"code","7aec30f3":"code","97c15477":"code","b3bf0922":"code","d8fb3ff0":"code","92337e7f":"code","bd25963d":"code","04083446":"code","f65e99ea":"code","abe0c1c3":"code","2bc3bfa0":"code","dcd0e0da":"code","8ea77070":"code","1c5e461e":"code","12a22f3c":"code","58266e5e":"code","fe72395c":"code","704d20e0":"code","0ff73b01":"code","da205b69":"code","5c3d994b":"code","66a88b35":"code","99567f6b":"code","39c8ffa0":"code","1322289e":"markdown","2765d221":"markdown","e49fbb56":"markdown","c6b1be38":"markdown","eb803a5f":"markdown","647ee94e":"markdown","91d5e085":"markdown","ab76c259":"markdown","c632ff40":"markdown","10ded4ec":"markdown","40aea9db":"markdown","5bbc0e10":"markdown","69a691fb":"markdown","7739de0f":"markdown","0de58bf1":"markdown","b224d5e4":"markdown","d72f7c4e":"markdown","d57605dc":"markdown","53a3a4ea":"markdown","5c577758":"markdown","b274593b":"markdown","988d4e9f":"markdown","4a3128f7":"markdown","2eaa47c0":"markdown","40f96dde":"markdown","ce7f792a":"markdown","3b73a343":"markdown","7fd2ba60":"markdown","50886512":"markdown","3abac39b":"markdown","b52f6c34":"markdown"},"source":{"caa2fd03":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom matplotlib import pyplot\n\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\nimport warnings                                                                 \nwarnings.filterwarnings('ignore') \n\n# allow plots to appear directly in the notebook\n%matplotlib inline\n\nfrom subprocess import check_output\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor","1d5fc3fb":"#data = pd.read_csv('https:\/\/raw.githubusercontent.com\/insaid2018\/Term-2\/master\/Projects\/avocado.csv', index_col=0)\ndata = pd.read_csv(\"..\/input\/avocado.csv\")\ndata.drop(\"Unnamed: 0\", axis=1,inplace=True)\nnames = ['Date', 'AveragePrice', 'TotalVolume', 'Small', 'Large', 'XLarge', 'TotalBags', 'SmallBags', 'LargeBags', 'XLargeBags', 'Type', 'Year' ,'Region']\ndata = data.rename(columns=dict(zip(data.columns, names)))\ndata.head()","e4578f12":"data.info()","ed5c089a":"data.describe(include='all')","de639b2a":"data.Type.unique()","41247c44":"data.Year.unique()","af1ae245":"sns.boxplot(y=\"Type\", x=\"AveragePrice\", data=data, palette = 'pink')","201543ab":"label = LabelEncoder()\ndicts = {}\n\nlabel.fit(data.Type.drop_duplicates()) \ndicts['Type'] = list(label.classes_)\ndata.Type = label.transform(data.Type)","693885ee":"cols = ['AveragePrice','Type','Year','TotalVolume','TotalBags']\ncm = np.corrcoef(data[cols].values.T)\nsns.set(font_scale = 1.7)\nhm = sns.heatmap(cm,cbar = True, annot = True,square = True, fmt = '.2f', annot_kws = {'size':15}, yticklabels = cols, xticklabels = cols)","a10fc4fe":"sns.pairplot(data, x_vars=['Small', 'Large', 'XLarge'], y_vars='TotalVolume', size=5, aspect=1, kind='reg')","1549891c":"sns.pairplot(data, x_vars=['SmallBags', 'LargeBags', 'XLargeBags'], y_vars='TotalBags', size=5, aspect=1, kind='reg')","59cde77e":"plt.figure(figsize=(12,20))\nsns.set_style('whitegrid')\nsns.pointplot(x='AveragePrice',y='Region',data=data, hue='Year',join=False)\nplt.xticks(np.linspace(1,2,5))\nplt.xlabel('Region',{'fontsize' : 'large'})\nplt.ylabel('AveragePrice',{'fontsize':'large'})\nplt.title(\"Yearly Average Price in Each Region\",{'fontsize':20})","4484bc67":"plt.figure(figsize=(12,20))\nsns.set_style('whitegrid')\nsns.pointplot(x='AveragePrice', y='Region', data=data, hue='Type',join=False)\nplt.xticks(np.linspace(1,2,5))\nplt.xlabel('Region',{'fontsize' : 'large'})\nplt.ylabel('AveragePrice',{'fontsize':'large'})\nplt.title(\"Type Average Price in Each Region\",{'fontsize':20})","a187ba08":"X=data[['AveragePrice', 'Small', 'Large', 'XLarge', 'SmallBags', 'LargeBags', 'XLargeBags']] #feature columns\ny=data.Type #predictor variable\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n\nprint(\"X Train Shape \",X_train.shape)\nprint(\"Y Train Shape \",y_train.shape)\n\nprint(\"X Test Shape \",X_test.shape)\nprint(\"Y Test Shape \",y_test.shape)","1cf8a15e":"#Logistic Regression model\nlogreg = LogisticRegression()\nlogreg.fit(X_train,y_train)\n\ny_pred_train = logreg.predict(X_train)  \ny_pred_test = logreg.predict(X_test)  \n\n#Acuuracy score\nprint('Accuracy score for Logistic Regression test data is:', accuracy_score(y_test,y_pred_test))\n\nprint('----------------------------------------------------------------------------------------')\n\n#Confusion matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred_test))\nconfusion_matrix.index = ['organic','Conventional']\nconfusion_matrix.columns = ['Predicted organic','Predicted Conventional']\nprint(\"Confusion matrix for logistic regression model\")\nprint(confusion_matrix)\n\nprint('----------------------------------------------------------------------------------------')\n\n#AUC ROC Curve\nprobs = logreg.predict_proba(X_test)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","7aec30f3":"#Randomforest classifier\nrfclass = RandomForestClassifier(random_state = 0)\nrfclass.fit(X_train, y_train)\n\ny_pred_train = rfclass.predict(X_train)\ny_pred_test = rfclass.predict(X_test)\n\n#Accuracy score\nprint('Accuracy score for test data using Random Forest :', accuracy_score(y_test,y_pred_test))\n\nprint('----------------------------------------------------------------------------------------')\n\n#Confusion matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred_test))\nconfusion_matrix.index = ['organic','Conventional']\nconfusion_matrix.columns = ['Predicted organic','Predicted Conventional']\nprint(\"Confusion matrix for Random forest model\")\nprint(confusion_matrix)\n\nprint('----------------------------------------------------------------------------------------')\n\n#AUC ROC Curve\nprobs = rfclass.predict_proba(X_test)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","97c15477":"data.drop(['Date', 'TotalVolume', 'TotalBags', 'Region', 'Year'], axis = 1,inplace = True)","b3bf0922":"data.columns","d8fb3ff0":"scaler = StandardScaler().fit(data)\ndata_avocado_scaler = scaler.transform(data)\ndata_avocado = pd.DataFrame(data_avocado_scaler)\ndata_avocado.columns = ['AveragePrice', 'Small', 'Large', 'XLarge', 'SmallBags', 'LargeBags', 'XLargeBags', 'Type']\ndata_avocado.head()","92337e7f":"feature_cols = ['Small', 'Large', 'XLarge', 'SmallBags', 'LargeBags', 'XLargeBags', 'Type']\nX = data_avocado[feature_cols]","bd25963d":"y = data_avocado.AveragePrice","04083446":"def split(X,y):\n    return train_test_split(X, y, test_size=0.20, random_state=1)","f65e99ea":"X_train, X_test, y_train, y_test=split(X,y)\nprint('Train cases as below')\nprint('X_train shape: ',X_train.shape)\nprint('y_train shape: ',y_train.shape)\nprint('\\nTest cases as below')\nprint('X_test shape: ',X_test.shape)\nprint('y_test shape: ',y_test.shape)","abe0c1c3":"def linear_reg( X, y, gridsearch = False):\n    \n    X_train, X_test, y_train, y_test = split(X,y)\n    \n    from sklearn.linear_model import LinearRegression\n    linreg = LinearRegression()\n    \n    if not(gridsearch):\n        linreg.fit(X_train, y_train) \n\n    else:\n        from sklearn.model_selection import GridSearchCV\n        parameters = {'normalize':[True,False], 'copy_X':[True, False]}\n        linreg = GridSearchCV(linreg,parameters, cv = 10)\n        linreg.fit(X_train, y_train)                                                           # fit the model to the training data (learn the coefficients)\n        print(\"Mean cross-validated score of the best_estimator : \", linreg.best_score_)  \n        \n        y_pred_test = linreg.predict(X_test)                                                   # make predictions on the testing set\n\n        RMSE_test = (metrics.mean_squared_error(y_test, y_pred_test))                          # compute the RMSE of our predictions\n        print('RMSE for the test set is {}'.format(RMSE_test))\n\n    return linreg","2bc3bfa0":"linreg = linear_reg(X,y)","dcd0e0da":"linreg.score(X,y)","8ea77070":"print('Intercept:',linreg.intercept_)                                           # print the intercept \nprint('Coefficients:',linreg.coef_)","1c5e461e":"feature_cols.insert(0,'Intercept')\ncoef = linreg.coef_.tolist()\ncoef.insert(0, linreg.intercept_)","12a22f3c":"eq1 = zip(feature_cols, coef)\n\nfor c1,c2 in eq1:\n    print(c1,c2)","58266e5e":"y_pred_train = linreg.predict(X_train)","fe72395c":"y_pred_test = linreg.predict(X_test)","704d20e0":"MAE_train = metrics.mean_absolute_error(y_train, y_pred_train)\nMAE_test = metrics.mean_absolute_error(y_test, y_pred_test)\n\nprint('MAE for training set is {}'.format(MAE_train))\nprint('MAE for test set is {}'.format(MAE_test))\n\nprint('----------------------------------------------------------------------------------------')\n\nMSE_train = metrics.mean_squared_error(y_train, y_pred_train)\nMSE_test = metrics.mean_squared_error(y_test, y_pred_test)\n\nprint('MSE for training set is {}'.format(MSE_train))\nprint('MSE for test set is {}'.format(MSE_test))\n\nprint('----------------------------------------------------------------------------------------')\n\nRMSE_train = np.sqrt( metrics.mean_squared_error(y_train, y_pred_train))\nRMSE_test = np.sqrt(metrics.mean_squared_error(y_test, y_pred_test))\n\nprint('RMSE for training set is {}'.format(RMSE_train))\nprint('RMSE for test set is {}'.format(RMSE_test))","0ff73b01":"print(\"Model Evaluation for Linear Regression Model\")\n\nprint('----------------------------------------------------------------------------------------')\n\nyhat = linreg.predict(X_train)\nSS_Residual = sum((y_train-yhat)**2)\nSS_Total = sum((y_train-np.mean(y_train))**2)\nr_squared = 1 - (float(SS_Residual))\/SS_Total\nadjusted_r_squared = 1 - (1-r_squared)*(len(y_train)-1)\/(len(y_train)-X_train.shape[1]-1)\nprint(\"r_squared for train data \",r_squared, \" and adjusted_r_squared for train data\",adjusted_r_squared)\n\nprint('----------------------------------------------------------------------------------------')\n\nyhat = linreg.predict(X_test)\nSS_Residual = sum((y_test-yhat)**2)\nSS_Total = sum((y_test-np.mean(y_test))**2)\nr_squared = 1 - (float(SS_Residual))\/SS_Total\nadjusted_r_squared = 1 - (1-r_squared)*(len(y_test)-1)\/(len(y_test)-X_test.shape[1]-1)\nprint(\"r_squared for test data \",r_squared, \" and adjusted_r_squared for test data\",adjusted_r_squared)","da205b69":"feature_cols = ['Small', 'SmallBags', 'Type']\nX1 = data_avocado[feature_cols]  \ny1 = data_avocado.AveragePrice\nlinreg=linear_reg(X1,y1, gridsearch = True)","5c3d994b":"feature_cols = ['Large', 'LargeBags', 'Type']\nX1 = data_avocado[feature_cols]  \ny1 = data_avocado.AveragePrice\nlinreg=linear_reg(X1,y1, gridsearch = True)","66a88b35":"feature_cols = ['XLarge', 'XLargeBags', 'Type']\nX1 = data_avocado[feature_cols]  \ny1 = data_avocado.AveragePrice\nlinreg=linear_reg(X1,y1, gridsearch = True)","99567f6b":"from sklearn.ensemble import RandomForestRegressor\nmodel2 = RandomForestRegressor(random_state = 0)\nmodel2.fit(X_train, y_train)\ny_pred_train = model2.predict(X_train)\ny_pred_test = model2.predict(X_test) ","39c8ffa0":"print(\"Model Evaluation for Random Forest Regressor \")\nRMSE_train = np.sqrt( metrics.mean_squared_error(y_train, y_pred_train))\nRMSE_test = np.sqrt(metrics.mean_squared_error(y_test, y_pred_test))\n\nprint('RMSE for training set is {}'.format(RMSE_train),' and RMSE for test set is {}'.format(RMSE_test))\n\nprint('----------------------------------------------------------------------------------------')\n\nyhat = model2.predict(X_train)\nSS_Residual = sum((y_train-yhat)**2)\nSS_Total = sum((y_train-np.mean(y_train))**2)\nr_squared = 1 - (float(SS_Residual))\/SS_Total\nadjusted_r_squared = 1 - (1-r_squared)*(len(y_train)-1)\/(len(y_train)-X_train.shape[1]-1)\nprint(\"r_squared for train data \",r_squared, \" and adjusted_r_squared for train data\",adjusted_r_squared)\n\nprint('----------------------------------------------------------------------------------------')\n\nyhat = model2.predict(X_test)\nSS_Residual = sum((y_test-yhat)**2)\nSS_Total = sum((y_test-np.mean(y_test))**2)\nr_squared = 1 - (float(SS_Residual))\/SS_Total\nadjusted_r_squared = 1 - (1-r_squared)*(len(y_test)-1)\/(len(y_test)-X_test.shape[1]-1)\nprint(\"r_squared for test data \",r_squared, \" and adjusted_r_squared for test data\",adjusted_r_squared)","1322289e":"From the above analysis we can say that __RMSE value 0.6095__ is lower between the three. __Lesser the RMSE value better would be the model.__","2765d221":"* Columns like Type of avocado, size and bags have impact on Average Price, __lesser the RMSE value__ accurate the model is, when we consider Small Hass in Small Bags.\n* Random forest Classifier has more accuracy than Logistic regression model for this dataset , accuracy is 0.99 it may also denote it is overfitting as it even classifies the outliers perfectly.\n* Random forest classifier model predicts the __type of Avocado__ more accurately than Logistic regression model. \n* Random Forest Regressor model predicts the __average price__ more accurately than linear regression model.","e49fbb56":"### 5. Predicting Average Price of Avocado","c6b1be38":"## Table of Content\n\n1. [Problem Statement](#section1)<br>\n2. [Data Loading and Description](#section2)<br>\n3. [Exploratory Data Analysis](#section3)<br>\n    - 3.1 [Type of Avocado vs Average Price](#section301)<br>\n    - 3.2 [Total Volume vs Small, Large and XLarge](#section302)<br>\n    - 3.3 [Total Bags vs Small Bags, Large Bags and XLarge Bags](#section303)<br>\n    - 3.4 [Region Vs Year distribution](#section304)<br>\n    - 3.5 [Region Vs AveragePrice distribution](#section305)<br>\n4. [Classifying Type of Avocado](#section4)<br>\n    - 4.1 [Using Logistic Regression](#section401)<br>\n    - 4.2 [Using Random forest classifier](#section402)<br>\n5. [Predicting Average Price of Avocado](#section5)<br>\n    - 5.1 [Using Linear Regression model](#section501)<br>\n    - 5.2 [Model Evaluation for Linear Regression Model](#section502)<br>\n    - 5.3 [Evaluation of Linear Regression Model using different columns](#section503)<br>\n    - 5.4 [Using Random Forest Regressor](#section504)<br>\n    - 5.5 [Model Evaluation for Random Forest Regressor](#section505)<br>\n6. [Conclusion](#section6)<br>","eb803a5f":"We can see there is a strong relation between TotalBags and TotalVolume ie, 0.96 and also Type and AveragePrice ie, 0.62.<br> Other than that there is weak realation.","647ee94e":"From the data we have four years of data, we can use different years for analysis.<br>\nwe can divide our whole dataset into Organic and Conventional types.","91d5e085":"### 3.5. Region Vs AveragePrice distribution\nFrom the graph we can say that Organic Type Avocado prices are high in HartfordSpringfield and Sanfrancisco region.<br>\nFor Conventional Type we have an average price < 1.50$.","ab76c259":"We are calculating __Linear Regression__ model with same type of data.","c632ff40":"__Y = -0.002 - (Small `*` 0.313) + (Large `*` 0.320) - (XLarge `*` 0.123) + (SmallBags `*` 0.061) - (LargeBags `*` 0.073) + (XLargeBags `*` 0.076) + Type `*` 0.605__\n<br>\nFrom the above equation __XLarge__ and __LargeBags__ are being __negative__. ie. If the value of __XLarge__ and __LargeBags__ decreases, the __Y__ value will increase and vise-versa.","10ded4ec":"<a id=section1><\/a> \n## 1. Problem Statement !\n\n\"The __Avocado__ dataset we are classifying __Organic & Conventional Type__ and prediting the __Average price__ using Regression model from year __2015, 2016, 2017 and 2018 data.__\"\n","40aea9db":"We are calculting Average price of Avocado considering columns:<br> __['AveragePrice', 'Small', 'Large', 'XLarge', 'SmallBags', 'LargeBags', 'XLargeBags', 'Type']__ <br>","5bbc0e10":"### 3.2. Total Volume vs Small, Large and XLarge","69a691fb":"### 4.1. Using Logistic Regression","7739de0f":"From the above boxplot we can say that Organic fruit price is more as compared to conventional fruit.","0de58bf1":"### 5.3. Evaluation of Linear Regression Model using different columns","b224d5e4":"### 5.2. Model Evaluation for Linear Regression Model","d72f7c4e":"### 5.4. Using Random Forest Regressor","d57605dc":"There is a strong co-relation between TotalVolume Vs Small and TotalBags Vs SmallBags.<br>\nWe can say weak co-relation between TotalVolume Vs XLarge and TotalBags Vs XLargeBags.<br>\nLarge and LargeBags comes in the middle.","53a3a4ea":"## 4. Classifying Type of Avocado","5c577758":"### 3.4. Region Vs Year distribution\nFrom the graph we can say that in year 2017 the HartfordSpringfield region being the maximum consumption of Avocado.","b274593b":"### 4.2. Using Random forest classifier","988d4e9f":"We can see there is no null values. We have 18249 records.<br>\nNo need to add values on the provided data.","4a3128f7":"### 6. Conclusion","2eaa47c0":"## 3. Exploratory Data Analysis","40f96dde":"### 5.5. Model Evaluation for Random Forest Regressor","ce7f792a":"If we compare RMSE and MSE value, we can conclude that RMSE is greater than MSE. ","3b73a343":"### 3.3. Total Bags vs Small Bags, Large Bags and XLarge Bags","7fd2ba60":"Calculating __Mean Absolute error__, __Mean Squared error__, __Root Mean Squared error__","50886512":"### 5.1. Using Linear Regression model","3abac39b":"<a id=section2><\/a> \n## 2. Data Loading and Description\nThe Avocado dataset includes consumption of fruit in different regions of USA from 2015 till 2018 years of data.\n* We have two types of Avocado available\n1. Organic (Healthy)\n2. Conventional","b52f6c34":"### 3.1. Type of Avocado vs Average Price "}}