{"cell_type":{"a6faa6f4":"code","80c8057f":"code","3342f093":"code","edfd4f4c":"code","d59268c5":"code","83a18b2c":"code","04e46933":"code","12e832ac":"code","01e98ae2":"code","26080474":"code","1187b437":"code","bcb9edb0":"code","15498c00":"code","10c444c7":"code","70b97eab":"code","871ed064":"code","40c59f05":"code","cba91471":"code","30dc72e0":"code","fe9ab99e":"code","dc1d1f7a":"code","9ac1bf78":"code","c007b1ef":"markdown","957b0bd9":"markdown","f782a804":"markdown","cfdc8bf8":"markdown","a6835a5d":"markdown","6c781de4":"markdown","47df9ab5":"markdown","0551bea9":"markdown","57c38ace":"markdown","d6218105":"markdown","7ae7783b":"markdown","c800867c":"markdown"},"source":{"a6faa6f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        df_path = os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","80c8057f":"# Importing libraries for analysis in alphabetical order\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.graph_objects as go\n\nfrom sklearn import metrics \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n# show matplotlib charts in cells\n%matplotlib inline\n\n\n# Set display options to not include scientific notation \npd.options.display.float_format = '{:.2f}'.format","3342f093":"#Upload data\ndata_s = pd.read_csv(df_path)","edfd4f4c":"data_s.head()","d59268c5":"data_s.info()","83a18b2c":"#Remove the columns\ndata_s.drop(['Unnamed: 0', 'index', 'Founded','Revenue','Competitors', 'Easy Apply'], axis=1, inplace=True)","04e46933":"data_s.rename(columns={\"Job Description\": \"Description\"}, inplace=True)","12e832ac":"#Replacing -1 with nan\ndata_s[\"Size\"] = data_s[\"Size\"].replace(\"Unknown\", -1)\ndata_s.replace(['-1'], [np.nan], inplace=True)\ndata_s.replace(['-1.0'], [np.nan], inplace=True)\ndata_s.replace([-1], [np.nan], inplace=True)\n\ndata_s.isnull().sum()","01e98ae2":"#separate columns of Salary Estimate as minimum and maximum salary\n\ndf_salary = data_s['Salary Estimate'].str.split(\"-\",expand=True,)\n\nminimum_salary = df_salary[0]\nminimum_salary = minimum_salary.str.replace('K',' ')\n\n\nmaximum_salary = df_salary[1].str.replace('(Glassdoor est.)', ' ')\nmaximum_salary = maximum_salary.str.replace('(', ' ')\nmaximum_salary = maximum_salary.str.replace(')', ' ')\nmaximum_salary = maximum_salary.str.replace('K', ' ')\nmaximum_salary = maximum_salary.str.replace('Employer est.', ' ')\nmaximum_salary = maximum_salary.str.replace('Per Hour', ' ')\n\nmaximum_salary = maximum_salary.str.replace('$', ' ').fillna(0).astype(int)\nminimum_salary = minimum_salary.str.replace('$', ' ').fillna(0).astype(int)","26080474":"data_s['Minimum Salary'] = minimum_salary\ndata_s['Maximum Salary'] = maximum_salary\n\ndata_s.drop('Salary Estimate',axis = 1,inplace = True)","1187b437":"#Cleaned company name\ndata_s['Company Name'] = data_s['Company Name'].str.replace('\\n.*', ' ')","bcb9edb0":"maximum_salary.value_counts()","15498c00":"# cleaning  position name in job title\ndata_s['Job Title'] = data_s['Job Title'].str.replace('Sr.', 'Senior')\ndata_s['Job Title'] = data_s['Job Title'].str.replace('SeniorData Analyst', 'Senior Data Analyst')\ndata_s['Job Title'] = data_s['Job Title'].str.replace('SeniorData Scientist', 'Senior Data Scientist')\ndata_s['Job Title'] = data_s['Job Title'].str.replace('12 month Roster', ' ')\ndata_s['Job Title'] = data_s['Job Title'].str.replace('Direct Hire', ' ')\n","10c444c7":"# categorization for company sizes\nsmall =  [\"1 to 50 employees\", \"51 to 200 employees\"]\nmedium = [\"201 to 500 employees\", '501 to 1000 employees']\nlarge = ['10000+ employees', '1001 to 5000 employees', '5001 to 10000 employees']\n\n\n#small\ndata_s[\"Size\"] = data_s[\"Size\"].replace(small, \"Small\") \n#Medium\ndata_s[\"Size\"] = data_s[\"Size\"].replace(medium, \"Medium\")\n#Large\ndata_s[\"Size\"] = data_s[\"Size\"].replace(large, \"Large\")\n\n","70b97eab":"#Cleaning the Size column\ndata_s[\"Size\"].value_counts()","871ed064":"data_s.head()","40c59f05":"# groub by title and number of posts and get only the top 10\nby_title = data_s.groupby(by=['Job Title'], as_index=False).agg({'Company Name' :'count'}).sort_values(by=['Company Name'], ascending=False).head(10)\n\n# rename company name to Number of posts\nby_title.rename(columns={\"Company Name\": \"Number of Posts\"}, inplace=True)\nby_title","cba91471":"# choosing colors\ntop_color = \"#0952CB\"\nnone_top_color = \"#85929E\"\n# set the background to white\nsns.set_theme(style=\"white\")\n# create chart and adding palette colors on top 3\nchart = sns.catplot(\n    data=by_title, \n    x=\"Number of Posts\", \n    y='Job Title', \n    kind=\"bar\",\n    height= 7,\n    aspect=2,\n    legend=False,\n    palette={\n        \"Data Scientist\": top_color,\n        \"Data Engineer\" : top_color,\n        \"Data Analyst\":   top_color,\n       \"Senior Data Scientist\": none_top_color,\n        \"Senior Data Analyst\"\t: none_top_color,\n        \"Senior Data Engineer\"\t: none_top_color,\n        \"Machine Learning Engineer\"\t: none_top_color,\n        \"Big Data Engineer\"\t: none_top_color,\n        \"Business Intelligence Analyst\"\t: none_top_color,\n        \"Lead Data Scientist\": none_top_color,\n        }  \n    )\nchart.set(ylabel=None, xlim=(0,300))\n","30dc72e0":"# group by the size of the companies to get small and medium and large\ncompany_size = data_s.groupby(by=\"Size\", as_index=False)['Company Name'].count()","fe9ab99e":"# create variables for data and labels and colors\npie_data = company_size.loc[:,'Company Name']\npie_labels = company_size.loc[:,'Size']\npie_color=['#0b3160','#6b9db6', '#169fb7'] \n\n\n\n# Make figure and axes\nfig, axes  = plt.subplots(1, 1)\n\n\n# Adapt radius and text size for a smaller pie\npatches, texts, autotexts = axes.pie(pie_data, \n                                     labels=pie_labels,\n                                     colors=pie_color,\n                                     autopct='%.0f%%',\n                                     textprops={'size': 22, 'color': 'black'},\n                                     shadow=True, \n                                     radius=2,\n                                     startangle=70, # change the angle to make small on the right side\n                                     wedgeprops=dict(width=1.21), # create donut chart\n                                     explode=(0,0,0.4) # make the small standout\n                                     \n                                     )\n\n\nplt.setp(autotexts, size=22, weight=\"bold\", color=\"white\")\nplt.show()\n\nfig.savefig(\"size\")","dc1d1f7a":"company_size","9ac1bf78":"#importing wordcloud lib\n\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n# Create a list of word and navigate what colomn\ntext= data_s.Description[0]\n\n\n\n# \nwordcloud = WordCloud(\n    background_color=\"white\",  \n    max_words=2000, # set it to 2000 words\n    colormap='Dark2', # choosing color set\n    height=1500, \n    width=3000,\n\n# stoping some words that do not have meanining\n    stopwords=['Length','nTachyon','nData','dtype','re','mi','Us','Noom','and', 'At','Name','seeks','com','Sapphire',\"nAt\",'ABOUT', \"a\",\n               \"HOPPER\", 'WWW','Decode_M','Description', 'Decode', 'nDescription', 'nhttps', 'we', 'on', 'is', 'DescriptionThe','UCB','nInterpret','use','The','resul', 'mission','Job'\n               'inte', 'scientifically', 'will', 'lives','Help','proven', \"patients '\", \"patients'\",'With', 'to', 'of', 'in','for', 'our', 'as', 'over', 'has', 'from', 'you', 'other', 'THIS' ]\n               \n               ).generate(str(text))\n\n\n                       \nplt.figure(figsize=[15,15])\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.margins(x=0, y=0)\nplt.show()","c007b1ef":"### Business Questions:\n- What are the top 10 data science postions?\n- which size of company that demand data scientists?\n- What are the most used words in the job description that data scientit need to consider in the future?","957b0bd9":"## Summary\nAs we notice that most demanded postions in data science are data scientit, engineering and analyst following them with seniors data scientists, analysis and engineering. We also saw that large size companies demanding data scientists with 49% of the job posts which imply that big companies need data expersts due to their big data they have. From the word cloud, we can see the words complex, experience, travel, business and product are assoicated with data science positions.","f782a804":"# Question 3","cfdc8bf8":"# **Data Visualization**","a6835a5d":"# Question 1","6c781de4":"## The dataset require a lot of cleanning and processing in order start analysis. \n\nInitial Review on the data:\n1. it has duplicate indexes\n2. Job Title has many duplicate name with strings attached\n3. Salary needs cleaning and removing strings and converting to numbers\n4. Company Name: has strings attached maybe from HTML.\n5. a lot of meaningles -1 in columns","47df9ab5":"# **Dataset Information**\n\nThis dataset was created by picklesueat and contains more than 3900 job listing for data scientist positions, with features such as:\nSalary Estimate\nLocation\nCompany Rating\nJob Description\nand more.\nReference: https:\/\/www.kaggle.com\/andrewmvd\/data-scientist-jobs\n","0551bea9":"# Cleaning and Preparing Process","57c38ace":"# Question 2","d6218105":"# Data Exploration Analysis","7ae7783b":"# Set Up and Load Data","c800867c":"Dataset Column and Row\n"}}