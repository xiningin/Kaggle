{"cell_type":{"17a54117":"code","6ce9e17b":"code","7ea47e5c":"code","757836f5":"code","e3419c91":"code","f14791e5":"code","4b295096":"code","67407155":"code","1c78239e":"code","10de530e":"code","c11914c5":"code","da21a1c3":"markdown"},"source":{"17a54117":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6ce9e17b":"data = pd.read_table('..\/input\/labeledTrainData.tsv')\ndata.head()","7ea47e5c":"data.info()","757836f5":"data['review'][0]","e3419c91":"from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom gensim.models import word2vec\n\nstemmer = PorterStemmer()\nlemma = WordNetLemmatizer()\nstop_words = stopwords.words('english')","f14791e5":"import re\n\ndef clean_review(review):\n    clean_words = []\n    \n    review = stemmer.stem(review)\n    review = lemma.lemmatize(review)\n    \n    words = word_tokenize(review)\n    for word in words:\n        word = word.lower()\n        word = re.sub(\"[0-9]|(\\.|\\\/|,|;|@|#|\\$|\\&|\\^|\\*|\\(|\\)|-|_|\\+|=|\\?|!|)\", \"\", word)\n        if word not in stop_words:\n            clean_words.append(word)\n    return clean_words","4b295096":"rv1 = data['review'][0]\n# type(rv1)\n# words = clean_review(rv1)\n# print(words)\ndata['review_cleaned'] = data['review'].apply(clean_review)","67407155":"import logging\n\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)","1c78239e":"num_features = 300  # Word vector dimensionality\nmin_word_count = 40 # Minimum word count\nnum_workers = 4     # Number of parallel threads\ncontext = 10        # Context window size\ndownsampling = 1e-3 # (0.001) Downsample setting for frequent words\n\n\nmodel = word2vec.Word2Vec(data['review_cleaned'],\\\n                          workers=num_workers,\\\n                          size=num_features,\\\n                          min_count=min_word_count,\\\n                          window=context,\n                          sample=downsampling)\n\n# To make the model memory efficient\nmodel.init_sims(replace=True)\n\n# Saving the model for later use. Can be loaded using Word2Vec.load()\nmodel_name = \"imdb_word2vec\"\nmodel.save(model_name)","10de530e":"model.wv.doesnt_match(\"france england germany washington\".split())","c11914c5":"model.wv.most_similar(\"plane\")","da21a1c3":"### We need to broadcast a cleaning function into those reviews. Let's start by doing that."}}