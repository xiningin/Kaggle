{"cell_type":{"9a620823":"code","97847fc6":"code","7ed425e3":"code","e96eaa0e":"code","aed5e755":"code","683e6668":"code","b3a813a6":"code","11859c3b":"code","78e4733d":"code","0e1ece2e":"code","050c7e2e":"code","0953b8fc":"code","48234613":"code","a80691a3":"code","4715d308":"code","0cc9a44d":"markdown","a46e788f":"markdown","2e173b0d":"markdown","5beb47b5":"markdown","5eba9f39":"markdown","2823842d":"markdown","cf92147b":"markdown","818f06e7":"markdown","427df7e1":"markdown","8f14a1a4":"markdown","ea50febb":"markdown","3527f8f9":"markdown","3912c0ed":"markdown","5f5fa556":"markdown","28436da4":"markdown","32d1569b":"markdown","97e65271":"markdown","89507751":"markdown"},"source":{"9a620823":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pickle\nimport matplotlib.pyplot as plt\nfrom timeit import default_timer as timer\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(os.listdir('..\/input'))\n\n# Listing all added utility scripts\nprint()\nprint(os.listdir('..\/usr\/lib'))\n\n# Any results you write to the current directory are saved as output.\n","97847fc6":"import utility_scripts_for_traffic_signs\n\n# Showing description of the functions inside utility\nprint(help(utility_scripts_for_traffic_signs))\n\n# Showing module's attributes\nprint(dir(utility_scripts_for_traffic_signs))\n","7ed425e3":"# Defining list with numers for the files' datasets to load from\nn = [2, 3, 7, 8]\n\n# Defining list with preprocessed methods for datasets\nm = ['RGB + \/255 + Mean', 'RGB + \/255 + Mean + STD', 'LHE + \/255 + Mean', 'LHE + \/255 + Mean + STD']\n\n# Defining dictionary for saving datasets in\ndata = {}\n\n# Going through all of the four datasets' files\nfor i in n:\n    # Opening file for reading in binary mode\n    with open('..\/input\/traffic-signs-preprocessed\/data' + str(i) + '.pickle', 'rb') as f:\n        data[i] = pickle.load(f, encoding='latin1')  # dictionary type\n\n    # Preparing y_train and y_validation for using in Keras\n    data[i]['y_train'] = to_categorical(data[i]['y_train'], num_classes=43)\n    data[i]['y_validation'] = to_categorical(data[i]['y_validation'], num_classes=43)\n\n    # Making channels come at the end\n    data[i]['x_train'] = data[i]['x_train'].transpose(0, 2, 3, 1)\n    data[i]['x_validation'] = data[i]['x_validation'].transpose(0, 2, 3, 1)\n    data[i]['x_test'] = data[i]['x_test'].transpose(0, 2, 3, 1)\n\n# Showing loaded datasets from the files\n# All has to be the same\nii = 0  # index of methods' name\nfor i in n:\n    print('data' + str(i) + '.pickle ->', m[ii])\n    for k, j in data[i].items():\n        if k == 'labels':\n            print(k + ':', len(j))\n        else: \n            print(k + ':', j.shape)\n    print()\n    ii += 1\n","e96eaa0e":"%matplotlib inline\n\n# Visualizing some examples of training data\nsome_examples = data[2]['x_train'][:49, :, :, :]\nprint(some_examples.shape)  # (49, 32, 32, 3)\n\n# Plotting\nfig = plt.figure()\ngrid = utility_scripts_for_traffic_signs.convert_to_grid(some_examples)\nplt.imshow(grid.astype('uint8'))\nplt.axis('off')\nplt.gcf().set_size_inches(15, 15)\nplt.title('Some training examples', fontsize=18)\nplt.show()\nplt.close()\n\n# Saving plot\nfig.savefig('some_training_examples.png')\nplt.close()\n","aed5e755":"%matplotlib inline\n\n# Loading original RGB Traffic Sign without any processing\nwith open('..\/input\/traffic-signs-preprocessed\/data0.pickle', 'rb') as f:\n        data0 = pickle.load(f, encoding='latin1')  # dictionary type\n\n# Making channels come at the end\ndata0['x_train'] = data0['x_train'].transpose(0, 2, 3, 1)\n\n# Getting example\nexample0 = data0['x_train'][2, :, :, :]\nprint(example0.shape)  # (32, 32, 3)\n\n\n\n# Defining dictionary for saving four examples in\nexample = {}\n\n# Examples with 3-channeled images\nexample[2] = data[2]['x_train'][2, :, :, :]\nexample[3] = data[3]['x_train'][2, :, :, :]\nprint(example[2].shape, example[3].shape)  # (32, 32, 3) (32, 32, 3)\n\n# Examples with 1-channeled images\nexample[7] = data[7]['x_train'][2, :, :, 0]\nexample[8] = data[8]['x_train'][2, :, :, 0]\nprint(example[7].shape, example[8].shape)  # (32, 32) (32, 32)\n\n\n\n# Getting labels' names from the file\n# Defining list for saving labels in order from 0 to 42\nlabels = []\n\n# Reading 'csv' file and getting labels\nr = pd.read_csv('..\/input\/traffic-signs-preprocessed\/label_names.csv')\n# Going through all names\nfor name in r['SignName']:\n    # Adding from every row second column with name of the label\n    labels.append(name)\n\n\n\n# Plotting examples of one traffic sign preprocessed in four different ways\nplt.rcParams['figure.figsize'] = (12.0, 12.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['font.family'] = 'Times New Roman'\n\nfig = plt.figure()\n\n# Plotting original example\nplt.subplot(2, 4, 1)  # rows, columns, current index of the plot\nplt.imshow(example0)\nplt.xlabel('RGB', fontsize=15)\nplt.ylabel(labels[np.argmax(data[2]['y_train'][2])], fontsize=15)\nplt.xticks([])\nplt.yticks([])\n\n# Going through all of the four examples\nk = 5  # Setting index for the plots\nii = 0  # Setting index for getting method's name\nfor i in n:\n    plt.subplot(2, 4, k)  # rows, columns, current index of the plot\n    if i == 7 or i == 8:\n        plt.imshow(example[i], cmap='gray')\n    else:\n        plt.imshow(example[i])\n    plt.xlabel(m[ii], fontsize=15)\n    plt.ylabel(labels[np.argmax(data[2]['y_train'][2])], fontsize=15)\n    plt.xticks([])\n    plt.yticks([])\n    k += 1\n    ii += 1\n\n# Adjusting height between subplots\nplt.subplots_adjust(hspace=0)\nplt.tight_layout()\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('one_ts_from_different_datasets.png')\nplt.close()\n","683e6668":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=9, padding='same', activation='relu', input_shape=(32, 32, 3)))\nmodel.add(MaxPool2D(pool_size=2))\n\nmodel.add(Conv2D(64, kernel_size=7, padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=2))\n\nmodel.add(Conv2D(128, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=2))\n\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(43, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","b3a813a6":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\nepochs = 20\n\nh = model.fit(data[2]['x_train'][:100], data[2]['y_train'][:100],\n              batch_size=5, epochs = epochs,\n              validation_data = (data[2]['x_validation'], data[2]['y_validation']),\n              callbacks=[annealer], verbose=1)\n\nprint()\nprint('Epochs={0:d}, Train accuracy={1:.5f}, \\\n      Validation accuracy={2:.5f}'.\\\n      format(epochs, max(h.history['accuracy']), max(h.history['val_accuracy'])))\n","11859c3b":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 5.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\n\nfig = plt.figure()\n\nplt.plot(h.history['accuracy'], '-o', linewidth=3.0)\nplt.plot(h.history['val_accuracy'], '-o', linewidth=3.0)\nplt.title('Overfitting small data for RGB dataset[2]', fontsize=22)\nplt.legend(['train', 'validation'], loc='upper left', fontsize='xx-large', borderpad=2)\nplt.xlabel('Epoch', fontsize=22)\nplt.ylabel('Accuracy', fontsize=22)\nplt.tick_params(labelsize=18)\nplt.show()\n\n# Saving the plot\nfig.savefig('Overfitting_dataset_2.png')\nplt.close()\n","78e4733d":"# Defining dictionary for models\nmodel = {}\n\n# Building four models\nfor i in n:\n    model[i] = Sequential()\n    \n    if i == 7 or i == 8:\n        model[i].add(Conv2D(32, kernel_size=9, padding='same', activation='relu', input_shape=(32, 32, 1)))\n    else:\n        model[i].add(Conv2D(32, kernel_size=9, padding='same', activation='relu', input_shape=(32, 32, 3)))\n        \n    model[i].add(MaxPool2D(pool_size=2))\n\n    model[i].add(Conv2D(64, kernel_size=7, padding='same', activation='relu'))\n    model[i].add(MaxPool2D(pool_size=2))\n\n    model[i].add(Conv2D(128, kernel_size=3, padding='same', activation='relu'))\n    model[i].add(MaxPool2D(pool_size=2))\n\n    model[i].add(Flatten())\n    model[i].add(Dense(500, activation='relu'))\n    model[i].add(Dense(43, activation='softmax'))\n\n    model[i].compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","0e1ece2e":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\nepochs = 5\n\n# Defining dictionary for saving history results\nh = {}\n\nfor i in n:\n    h[i] = model[i].fit(data[i]['x_train'], data[i]['y_train'],\n                        batch_size=5, epochs = epochs,\n                        validation_data = (data[i]['x_validation'], data[i]['y_validation']),\n                        callbacks=[annealer], verbose=0)\n    \n    print('Model trained on dataset{0}.pickle, epochs={1:d}, training accuracy={2:.5f}, validation accuracy={3:.5f}'.format(i, epochs, max(h[i].history['accuracy']), max(h[i].history['val_accuracy'])))\n","050c7e2e":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 15.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams[\"font.family\"] = 'Times New Roman'\n\nfig = plt.figure()\n\n# Plotting history of training accuracy\nplt.subplot(2, 1, 1)\nplt.plot(h[2].history['accuracy'], '-o', linewidth=3.0)\nplt.plot(h[3].history['accuracy'], '-s', linewidth=3.0)\nplt.plot(h[7].history['accuracy'], '-D', linewidth=3.0)\nplt.plot(h[8].history['accuracy'], '-D', linewidth=3.0)\nplt.legend(['dataset2', 'dataset3', 'dataset7', 'dataset8'], loc='lower right', fontsize='xx-large', borderpad=2)\nplt.xlabel('Epoch', fontsize=22, fontname='Times New Roman')\nplt.ylabel('Training Accuracy', fontsize=22, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.9, 1.0)\nplt.xlim(0.5, 5.3)\nplt.tick_params(labelsize=18)\n# plt.title('Accuracy for different datasets', fontsize=20)\n\n# Plotting history of validation accuracy\nplt.subplot(2, 1, 2)\n# plt.gca().set_title('Validation accuracy')\nplt.plot(h[2].history['val_accuracy'], '-o', linewidth=3.0)\nplt.plot(h[3].history['val_accuracy'], '-s', linewidth=3.0)\nplt.plot(h[7].history['val_accuracy'], '-D', linewidth=3.0)\nplt.plot(h[8].history['val_accuracy'], '-D', linewidth=3.0)\nplt.legend(['dataset2', 'dataset3', 'dataset7', 'dataset8'], loc='lower right', fontsize='xx-large', borderpad=2)\nplt.xlabel('Epoch', fontsize=22, fontname='Times New Roman')\nplt.ylabel('Validation Accuracy', fontsize=22, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.75, 1.0)\nplt.xlim(0.5, 5.3)\nplt.tick_params(labelsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('models_accuracy.png')\nplt.close()\n\n\n# Showing values of training accuracy for different datasets\nfor i in n:\n    print('dataset{0}.pickle training accuracy = {1:.5f}'.\\\n          format(i, np.max(h[i].history['accuracy'])))\n\n# Showing values of validation accuracy for different datasets\nprint()\nfor i in n:\n    print('dataset{0}.pickle validation accuracy = {1:.5f}'.\\\n          format(i, np.max(h[i].history['val_accuracy'])))\n","0953b8fc":"# Going through all of the four models\nfor i in n:\n    temp = model[i].predict(data[i]['x_test'])\n    temp = np.argmax(temp, axis=1)\n\n    # We compare predicted class with correct class for all input images\n    # And calculating mean value among all values of following numpy array\n    # By saying 'testing_accuracy == data[i]['y_test']' we create numpy array with True and False values\n    # 'np.mean' function will return average of the array elements\n    # The average is taken over the flattened array by default\n    temp = np.mean(temp == data[i]['y_test'])\n    \n    print('dataset{0}.pickle testing accuracy = {1:.5f}'.format(i, temp))\n","48234613":"# Getting scores from forward pass of one input image\n# Scores is given for each image with 43 numbers of predictions for each class\n# Measuring at the same time execution time\n\n# Going through all of the four models\nfor i in n:\n    start = timer()\n    temp = model[i].predict(data[i]['x_test'][:1, :, :, :])\n    end = timer()\n    \n    print('dataset{0}.pickle classification time = {1:.5f}'.format(i, end - start))\n","a80691a3":"%matplotlib inline\n\nplt.rcParams['figure.figsize'] = (15.0, 15.0) # Setting default size of the plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams[\"font.family\"] = 'Times New Roman'\n\n# Going through all of the four models\nk = 1  # Setting index for the plots\nii = 0  # Setting index for getting method's name\nfor i in n:\n    # Preparing image for predicting from test dataset\n    x_input = data[i]['x_test'][100:101, :, :, :]\n    # print(x_input.shape)  # (1, 32, 32, 3) or (1, 32, 32, 1)\n    \n    y_input = data[i]['y_test'][100:101]\n    # print(y_input)  # [3]\n    \n    # Plotting input image\n    plt.subplot(1, 4, k)  # rows, columns, current index of the plot\n    if i == 7 or i == 8:\n        plt.imshow(x_input[0, :, :, 0], cmap='gray')\n    else:\n        plt.imshow(x_input[0])\n    plt.xlabel(m[ii], fontsize=14)\n    plt.ylabel(labels[y_input[0]], fontsize=14)\n    plt.xticks([])\n    plt.yticks([])\n    k += 1\n    ii += 1\n    \n    # Getting scores from forward pass of input image\n    scores = model[i].predict(x_input)\n    # print(scores[0].shape)  # (43,)\n\n    # Scores is given for image with 43 numbers of predictions for each class\n    # Getting only one class with maximum value\n    prediction = np.argmax(scores)\n    print('Predicted classId for model trained on dataset{0}.pickle: {1}'.format(i, prediction))\n\n    # Printing label for classified Traffic Sign\n    print('Predicted label:', labels[prediction])\n    \n    print()\n\n\n# Showing the plot\nplt.show()\n","4715d308":"for i in n:\n    name = 'model-dataset' + str(i) + '.h5'\n    model[i].save(name)\n\n# # Saving model locally without committing\n# from IPython.display import FileLink\n\n# FileLink('model-dataset2.h5')\n","0cc9a44d":"# \ud83d\udca1 Training with different datasets","a46e788f":"# \u26d4\ufe0f Preprocessing Traffic Signs for Classification with CNN","2e173b0d":"# \ud83d\udeb3 Showing one Traffic Sign from different datasets","5beb47b5":"# \ud83e\uddee Calculating accuracy with testing datasets","5eba9f39":"# \ud83c\udfd7\ufe0f Building model of CNN with Keras for RGB dataset[2]","2823842d":"## \ud83e\udd0f Overfitting small data for RGB dataset[2]","cf92147b":"## \ud83d\udcc8 Plotting history results for overfitting small data for RGB dataset[2]","818f06e7":"# \ud83d\uddbc\ufe0f Predicting with one image from test dataset","427df7e1":"# \ud83c\udf93 Related course for classification tasks","8f14a1a4":"## \ud83d\udcf0 Related Paper\nSichkar V. N. Effect of various dimension convolutional layer filters on traffic sign classification accuracy. *Scientific and Technical Journal of Information Technologies, Mechanics and Optics*, 2019, vol. 19, no. 3, pp. DOI: 10.17586\/2226-1494-2019-19-3-546-552 (Full-text available on ResearchGate here: [Effect of various dimension convolutional layer filters on traffic sign classification accuracy](https:\/\/www.researchgate.net\/publication\/334074308_Effect_of_various_dimension_convolutional_layer_filters_on_traffic_sign_classification_accuracy))\n\n\u2217  Test online with custom Traffic Sign here: https:\/\/valentynsichkar.name\/traffic_signs.html","ea50febb":"# \u231b Calculating time for classification","3527f8f9":"# \ud83d\udcc2 Loading datasets: data2.pickle, data3.pickle, data7.pickle, data8.pickle","3912c0ed":"# \ud83d\udcab Showing some training examples","5f5fa556":"# \ud83c\udfd7\ufe0f Building set of models of CNN with Keras","28436da4":"# \ud83d\udcbe Saving models","32d1569b":"**Design**, **Train** & **Test** deep CNN for Image Classification.\n\n**Join** the course & enjoy new opportunities to get deep learning skills:\n\n\n[https:\/\/www.udemy.com\/course\/convolutional-neural-networks-for-image-classification\/](https:\/\/www.udemy.com\/course\/convolutional-neural-networks-for-image-classification\/?referralCode=12EE0D74A405BF4DDE9B)\n\n\n![](https:\/\/github.com\/sichkar-valentyn\/1-million-images-for-Traffic-Signs-Classification-tasks\/blob\/main\/images\/slideshow_classification.gif?raw=true)","97e65271":"# \ud83d\udce5 Importing needed libraries","89507751":"# \ud83d\udcc8 Plotting comparison results for accuracy"}}