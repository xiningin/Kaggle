{"cell_type":{"7f8bba44":"code","bc12e6fa":"code","a7842e25":"code","6f09b5c5":"code","4c090180":"code","6328fc2b":"code","f56c34bf":"code","e50af322":"code","9899493e":"code","cd3e4b6d":"code","b5a328b3":"code","a64a44ea":"code","9398c4a2":"code","b32dcc4b":"code","d819dd5e":"code","0906e2b1":"code","2da07599":"code","e9c47650":"code","42b47b34":"code","83c37955":"code","70ceb82d":"code","26802e1f":"code","145e8633":"code","d94c65f6":"code","eff0c08d":"markdown"},"source":{"7f8bba44":"from matplotlib import pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\nimport random \nimport os\nimport cv2\nimport gc\nfrom tqdm.auto import tqdm\n\n\nimport numpy as np\nimport keras\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.models import clone_model\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import plot_model\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport datetime as dt\nnow = dt.datetime.now\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bc12e6fa":"num_classes = {\n    'grapheme_root': 168,\n    'vowel_diacritic': 11,\n    'consonant_diacritic': 7\n}","a7842e25":"def resize(df, size=64, need_progress_bar=True):\n    resized = {}\n    for i in range(df.shape[0]):\n        image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\n        resized[df.index[i]] = image.reshape(-1)\n    resized = pd.DataFrame(resized).T\n    return resized","6f09b5c5":"train_data = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/train.csv')\n\ntrain_data =  pd.merge(pd.read_parquet(f'\/kaggle\/input\/bengaliai-cv19\/train_image_data_0.parquet'), train_data, on='image_id').drop(['image_id'], axis=1)\n\ntrain_labels = train_data[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic','grapheme']]\n\ntrain_data = train_data.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic','grapheme'], axis=1)\n\ntrain_data = resize(train_data)\/255\n\ntrain_data = train_data.values.reshape(-1, 64, 64, 1)\n\ntrain_data = np.repeat(train_data[..., np.newaxis], 3, -1)","4c090180":"model = load_model(os.path.join(\"..\/input\/transferlearningmodel\", 'GraphemeDenseNet121.h5'))","6328fc2b":"dense_net = keras.applications.densenet.DenseNet121(weights=\"imagenet\", include_top=False)","f56c34bf":"dense_net.summary()","e50af322":"for layer in dense_net.layers:\n    layer.trainable = False","9899493e":"avg = layers.GlobalAveragePooling2D()(dense_net.output)\noutput = layers.Dense(num_classes['grapheme_root'], activation=\"softmax\")(avg)\nmodel = keras.Model(inputs=dense_net.input, outputs=output)","cd3e4b6d":"batch_size = 32\nepochs = 10","b5a328b3":"Y_train = train_labels[\"grapheme_root\"]\nY_train = pd.get_dummies(Y_train).values\nx_train, x_test, y_train, y_test = train_test_split(train_data, Y_train, test_size=0.1, random_state=123)\ny_train = tf.cast(y_train, tf.int32)\ny_test = tf.cast(y_test, tf.int32)\n#     datagen = ImageDataGenerator(rotation_range=5)\ndatagen = ImageDataGenerator()\ncheckpoint_cb = ModelCheckpoint(\"{}.h5\".format(\"grapheme_root\"), save_best_only=True)\nearly_stopping_cb = EarlyStopping(patience=3, restore_best_weights=True)\nhistory = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), \n                                           epochs = epochs, validation_data = (x_test, y_test), callbacks=[checkpoint_cb, early_stopping_cb])\ngrapheme_root = keras.models.load_model(\"{}.h5\".format(target))","a64a44ea":"def train_model(model, train_data, train_labels, target, batch_size, epochs):\n    labels = train_labels[target]\n    labels = pd.get_dummies(labels).values\n    x_train, x_test, y_train, y_test = train_test_split(train_data, labels, test_size=0.1, random_state=123)\n    y_train = tf.cast(y_train, tf.int32)\n    y_test = tf.cast(y_test, tf.int32)\n    print('x_train shape:', x_train.shape)\n    print(x_train.shape[0], 'train samples')\n    print(x_test.shape[0], 'test samples')\n\n    model.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])\n\n    datagen = ImageDataGenerator()\n    checkpoint_cb = ModelCheckpoint(\"{}.h5\".format(target), save_best_only=True)\n    early_stopping_cb = EarlyStopping(patience=3, restore_best_weights=True)\n    t = now()\n    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), \n                                               epochs = epochs, validation_data = (x_test, y_test), callbacks=[checkpoint_cb, early_stopping_cb])\n    \n    model = keras.models.load_model(\"{}.h5\".format(target))\n    print('Training time: %s' % (now() - t))\n    score = model.evaluate(x_test, y_test, verbose=0)\n    print('Test score:', score[0])\n    print('Test accuracy:', score[1])","9398c4a2":"feature_layers = [\n    Conv2D(32, 5, activation=\"relu\", padding=\"same\", input_shape=[64, 64, 1]),\n    layers.BatchNormalization(momentum=0.15),\n    MaxPooling2D(2),\n    Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n    Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n    MaxPooling2D(2),\n    Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n    Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n    MaxPooling2D(2),\n    Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n    Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n    MaxPooling2D(2),\n    Flatten(),\n]\n\nclassification_layers = [\n    Dense(1024),\n    Activation('relu'),\n    Dropout(0.5),\n    Dense(1024),\n    Activation('relu'),\n    Dropout(0.5),\n    Dense(num_classes['grapheme_root']),\n    Activation('softmax')\n]","b32dcc4b":"model_grapheme_root = Sequential(feature_layers + classification_layers)","d819dd5e":"batch_size = 32\nepochs = 10","0906e2b1":"train_model(model_grapheme_root, train_data, train_labels, 'grapheme_root', batch_size, epochs)","2da07599":"classification_layers = [\n    Dense(1024),\n    Activation('relu'),\n    Dropout(0.5),\n    Dense(512),\n    Activation('relu'),\n    Dropout(0.5),\n    Dense(num_classes['vowel_diacritic']),\n    Activation('softmax')\n]","e9c47650":"# freeze feature layers and rebuild model\nfor l in feature_layers:\n    l.trainable = False\n\nmodel_vowel_diacritic = Sequential(feature_layers + classification_layers)\n\n# transfer: train dense layers for new classification task\ntrain_model(model_vowel_diacritic, train_data, train_labels, 'vowel_diacritic', batch_size, epochs)","42b47b34":"model_dict = {\n    'grapheme_root': Sequential(),\n    'vowel_diacritic': Sequential(),\n    'consonant_diacritic': Sequential()\n}\n\nfor model_type, model in model_dict.items():\n    model.add(Conv2D(32, 5, activation=\"relu\", padding=\"same\", input_shape=[64, 64, 1]))\n    model.add(layers.BatchNormalization(momentum=0.15))\n    model.add(MaxPooling2D(2))\n    model.add(Conv2D(64, 3, activation=\"relu\", padding=\"same\"))\n    model.add(Conv2D(64, 3, activation=\"relu\", padding=\"same\"))\n    model.add(MaxPooling2D(2))\n    model.add(Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n    model.add(Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n    model.add(MaxPooling2D(2))\n    model.add(Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n    model.add(Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n    model.add(MaxPooling2D(2))\n    model.add(Flatten())\n    model.add(Dense(1024, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(512, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    if model_type == 'grapheme_root':\n        model.add(layers.Dense(168, activation='softmax', name='root_out'))\n    elif model_type == 'vowel_diacritic':\n        model.add(layers.Dense(11, activation='softmax', name='vowel_out'))\n    elif model_type == 'consonant_diacritic':\n        model.add(layers.Dense(7, activation='softmax', name='consonant_out'))\n\n    model.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])","83c37955":"# del Y_train\n# del x_train\n# del x_test\n# del y_train\n# del y_test\n# gc.collect()","70ceb82d":"keras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)\nmodel_types = ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']\nfor target in model_types:\n    Y_train = train_labels[target]\n    Y_train = pd.get_dummies(Y_train).values\n    x_train, x_test, y_train, y_test = train_test_split(train_data, Y_train, test_size=0.1, random_state=123)\n    y_train = tf.cast(y_train, tf.int32)\n    y_test = tf.cast(y_test, tf.int32)\n#     datagen = ImageDataGenerator(rotation_range=5)\n    datagen = ImageDataGenerator()\n    checkpoint_cb = ModelCheckpoint(\"{}.h5\".format(target), save_best_only=True)\n    early_stopping_cb = EarlyStopping(patience=3, restore_best_weights=True)\n    history = model_dict[target].fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), \n                                               epochs = epochs, validation_data = (x_test, y_test), callbacks=[checkpoint_cb, early_stopping_cb])\n    history_list.append(history)\n    model_dict[target] = keras.models.load_model(\"{}.h5\".format(target))\n    \n    del Y_train\n    del x_train\n    del x_test\n    del y_train\n    del y_test\n    gc.collect()","26802e1f":"plt.figure()\nfor i in range(3):\n    plt.plot(np.arange(0, len(history_list[i].history['accuracy'])), history_list[i].history['accuracy'], label='train_accuracy')\n    plt.plot(np.arange(0, len(history_list[i].history['accuracy'])), history_list[i].history['val_accuracy'], label='val_accuracy')\n    plt.title(model_types[i])\n    plt.xlabel('Epoch #')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.show()","145e8633":"preds_dict = {\n    'grapheme_root': [],\n    'vowel_diacritic': [],\n    'consonant_diacritic': []\n}","d94c65f6":"target=[] # model predictions placeholder\nrow_id=[] # row_id place holder\nfor i in range(4):\n    print(\"Parquet: {}\".format(i))\n    df_test_img = pd.read_parquet('\/kaggle\/input\/bengaliai-cv19\/test_image_data_{}.parquet'.format(i)) \n    df_test_img.set_index('image_id', inplace=True)\n\n    X_test = resize(df_test_img, need_progress_bar=False)\/255\n    X_test = X_test.values.reshape(-1, 64, 64, 1)\n\n    for i, p in preds_dict.items():\n        model = keras.models.load_model(\"{}.h5\".format(i))\n        preds = model.predict(X_test)\n        preds_dict[i] = np.argmax(preds, axis=1)\n\n    for k,id in enumerate(df_test_img.index.values):  \n        for i,comp in enumerate(model_types):\n            id_sample=id+'_'+comp\n            row_id.append(id_sample)\n            target.append(preds_dict[comp][k])\n            \n    del df_test_img\n    del X_test\n    gc.collect()\n\ndf_sample = pd.DataFrame(\n    {\n        'row_id': row_id,\n        'target':target\n    },\n    columns = ['row_id','target'] \n)\ndf_sample.to_csv('submission.csv',index=False)\ndf_sample.head()","eff0c08d":"Work conducted by: Jason Katz, David Kebudi, Naina Wodon, and Michael Harder"}}