{"cell_type":{"f5a500e1":"code","f1216d90":"code","5d1633e2":"code","7fb5584d":"code","33bac12c":"code","e3dda1d2":"markdown","ce6cacfb":"markdown","6b8c708c":"markdown","1cf50729":"markdown","eef958a8":"markdown"},"source":{"f5a500e1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy.io import loadmat\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm # Colormaps\nimport matplotlib.gridspec as gridspec\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nimport seaborn as sns\n\nsns.set_style('darkgrid')\nnp.random.seed(42)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f1216d90":"def univariate_normal(x, mean, variance):\n    \"\"\"pdf of the univariate normal distribution.\"\"\"\n    return ((1. \/ np.sqrt(2 * np.pi * variance)) * \n            np.exp(-(x - mean)**2 \/ (2 * variance)))","5d1633e2":"# Plot different Univariate Normals\nx = np.linspace(-3, 5, num=150)\nfig = plt.figure(figsize=(5, 3))\nplt.plot(\n    x, univariate_normal(x, mean=0, variance=1), \n    label=\"$\\mathcal{N}(0, 1)$\")\nplt.plot(\n    x, univariate_normal(x, mean=2, variance=3), \n    label=\"$\\mathcal{N}(2, 3)$\")\nplt.plot(\n    x, univariate_normal(x, mean=0, variance=0.2), \n    label=\"$\\mathcal{N}(0, 0.2)$\")\nplt.xlabel('$x$', fontsize=13)\nplt.ylabel('density: $p(x)$', fontsize=13)\nplt.title('Univariate normal distributions')\nplt.ylim([0, 1])\nplt.xlim([-3, 5])\nplt.legend(loc=1)\nfig.subplots_adjust(bottom=0.15)\nplt.show()\n#","7fb5584d":"def multivariate_normal(x, d, mean, covariance):\n    \"\"\"pdf of the multivariate normal distribution.\"\"\"\n    x_m = x - mean\n    return (1. \/ (np.sqrt((2 * np.pi)**d * np.linalg.det(covariance))) * \n            np.exp(-(np.linalg.solve(covariance, x_m).T.dot(x_m)) \/ 2))","33bac12c":"# Plot bivariate distribution\ndef generate_surface(mean, covariance, d):\n    \"\"\"Helper function to generate density surface.\"\"\"\n    nb_of_x = 100 # grid size\n    x1s = np.linspace(-5, 5, num=nb_of_x)\n    x2s = np.linspace(-5, 5, num=nb_of_x)\n    x1, x2 = np.meshgrid(x1s, x2s) # Generate grid\n    pdf = np.zeros((nb_of_x, nb_of_x))\n    # Fill the cost matrix for each combination of weights\n    for i in range(nb_of_x):\n        for j in range(nb_of_x):\n            pdf[i,j] = multivariate_normal(\n                np.matrix([[x1[i,j]], [x2[i,j]]]), \n                d, mean, covariance)\n    return x1, x2, pdf  # x1, x2, pdf(x1,x2)\n\n# subplot\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8,4))\nd = 2  # number of dimensions\n\n# Plot of independent Normals\nbivariate_mean = np.matrix([[0.], [0.]])  # Mean\nbivariate_covariance = np.matrix([\n    [1., 0.], \n    [0., 1.]])  # Covariance\nx1, x2, p = generate_surface(\n    bivariate_mean, bivariate_covariance, d)\n# Plot bivariate distribution\ncon = ax1.contourf(x1, x2, p, 100, cmap=cm.YlGnBu)\nax1.set_xlabel('$x_1$', fontsize=13)\nax1.set_ylabel('$x_2$', fontsize=13)\nax1.axis([-2.5, 2.5, -2.5, 2.5])\nax1.set_aspect('equal')\nax1.set_title('Independent variables', fontsize=12)\n\n# Plot of correlated Normals\nbivariate_mean = np.matrix([[0.], [1.]])  # Mean\nbivariate_covariance = np.matrix([\n    [1., 0.8], \n    [0.8, 1.]])  # Covariance\nx1, x2, p = generate_surface(\n    bivariate_mean, bivariate_covariance, d)\n# Plot bivariate distribution\ncon = ax2.contourf(x1, x2, p, 100, cmap=cm.YlGnBu)\nax2.set_xlabel('$x_1$', fontsize=13)\nax2.set_ylabel('$x_2$', fontsize=13)\nax2.axis([-2.5, 2.5, -1.5, 3.5])\nax2.set_aspect('equal')\nax2.set_title('Correlated variables', fontsize=12)\n\n# Add colorbar and title\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.7])\ncbar = fig.colorbar(con, cax=cbar_ax)\ncbar.ax.set_ylabel('$p(x_1, x_2)$', fontsize=13)\nplt.suptitle('Bivariate normal distributions', fontsize=13, y=0.95)\nplt.show()\n#","e3dda1d2":"### Univariate normal distribution\n\nThe normal distribution, also known as the Gaussian distribution, is so called because its based on the Gaussian function. This distribution is defined by two parameters: the mean $\\mu$, which is the expected value of the distribution, and the standard deviation $\\sigma$, which corresponds to the expected deviation from the mean. The square of the standard deviation is typically referred to as the variance $\\sigma^2$. We denote this distribution as:\n\n$$\n\\mathcal{N}(\\mu, \\sigma^2)\n$$\nGiven this mean and variance we can calculate the probility densitiy function (pdf) of the normal distribution with the normalised Gaussian function. For a value $x$ the density is:\n\n$$\np(x \\mid \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp{ \\left( -\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)}\n$$\nWe call this distribution the univariate normal because it consists of only one random normal variable. Three examples of univariate normal distributions with different mean and variance are plotted in the next figure:","ce6cacfb":"More about this here:\nhttps:\/\/github.com\/john77eipe\/peterroelants.github.io\/blob\/master\/notebooks\/misc\/multivariate-normal-primer.ipynb","6b8c708c":"### Multivariate normal distribution\n\nThe multivariate normal distribution is a multidimensional generalisation of the one-dimensional normal distribution. It represents the distribution of a multivariate random variable that is made up of multiple random variables that can be correlated with eachother.\n\nLike the normal distribution, the multivariate normal is defined by sets of parameters: the mean vector $\\mathbf{\\mu}$, which is the expected value of the distribution; and the covariance matrix $\\Sigma$, which measures how dependend two random variables are and how they change together. We denote the covariance between variable $X$ and $Y$ as $C(X,Y)$.\n\nThe multivariate normal with dimensionality $d$ has a joint probability density given by:\n\n$$\np(\\mathbf{x} \\mid \\mathbf{\\mu}, \\Sigma) = \\frac{1}{\\sqrt{(2\\pi)^d \\lvert\\Sigma\\rvert}} \\exp{ \\left( -\\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu})^T \\Sigma^{-1} (\\mathbf{x} - \\mathbf{\\mu}) \\right)}\n$$\nWhere $\\mathbf{x}$ a random vector of size $d$, $\\mathbf{\\mu}$ is the mean vector, $\\Sigma$ is the (symmetric, positive definite) covariance matrix (of size $d \\times d$), and $\\lvert\\Sigma\\rvert$ its determinant. We denote this multivariate normal distribution as:\n\n$$\n\\mathcal{N}(\\mathbf{\\mu}, \\Sigma)\n$$","1cf50729":"Examples of two bivariate normal distributions are plotted below.\n\nThe figure on the left is a bivariate distribution with the covariance between $x_1$ and $x_2$ set to $0$ so that these 2 variables are independent:\n\n$$\n\\mathcal{N}\\left(\n\\begin{bmatrix}\n0 \\\\\n0\n\\end{bmatrix}, \n\\begin{bmatrix}\n1 &amp; 0 \\\\\n0 &amp; 1 \n\\end{bmatrix}\\right)\n$$\nThe figure on the right is a bivariate distribution with the covariance between $x_1$ and $x_2$ set to be different than $0$ so that both variables are correlated. Increasing $x_1$ will increase the probability that $x_2$ will also increase:\n\n$$\n\\mathcal{N}\\left(\n\\begin{bmatrix}\n0 \\\\\n1\n\\end{bmatrix}, \n\\begin{bmatrix}\n1 &amp; 0.8 \\\\\n0.8 &amp; 1\n\\end{bmatrix}\\right)\n$$","eef958a8":"Following notes are from:\nhttps:\/\/towardsdatascience.com\/andrew-ngs-machine-learning-course-in-python-anomaly-detection-1233d23dba95\n\nMore about gaussian process:\nhttps:\/\/github.com\/john77eipe\/peterroelants.github.io\/tree\/master\/notebooks\/gaussian_process"}}