{"cell_type":{"5bbfcde3":"code","b6880164":"code","65aa7d96":"code","be77d36e":"code","ee9dadbf":"code","0724cf27":"code","7eeab37d":"code","8fdbf56c":"code","84d4357f":"code","7fd7a953":"code","826dd44a":"code","b6c6e058":"code","251b949e":"code","5020d3ac":"code","0e2c12d0":"code","b56d5660":"code","d584c458":"code","d4424da3":"markdown","d878dd22":"markdown","18a96b28":"markdown","cb69ff02":"markdown","76a027d0":"markdown"},"source":{"5bbfcde3":"!git clone https:\/\/github.com\/ultralytics\/yolov5  # clone repo\n!pip install -r yolov5\/requirements.txt  # install dependencies\n%cd yolov5\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\nfrom utils.google_utils import gdrive_download  # to download models\/datasets\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","b6880164":"%cd ..","65aa7d96":"# Download wheat and labels\ngdrive_download('1XqetalfvoOpgYK2YsyHmMu85qEHTgjGN','WheatYolo.zip')  # dataset","be77d36e":"!mv ..\/input\/wheatyaml\/yolov5xnc1.yaml .\/","ee9dadbf":"%cd yolov5\n!ls","0724cf27":"%%time\n!python train.py --img 416 --batch 16 --epochs 2 --data '..\/data.yaml' --cfg '..\/yolov5xnc1.yaml' --weights '' --name tutorial --nosave --cache","7eeab37d":"# start tensorboard\n# launch after training \n# log saves in the folder \"runs\"\n#%load_ext tensorboard\n#%tensorboard --logdir runs\n#if Kaggle ever fixes issue with tensorboard uncomment the two lines above. ","8fdbf56c":"Image(filename='runs\/exp0_tutorial\/train_batch1.jpg', width=900)  # view augmented training mosaics","84d4357f":"Image(filename='runs\/exp0_tutorial\/test_batch0_gt.jpg', width=900)  # view test image labels","7fd7a953":"Image(filename='runs\/exp0_tutorial\/test_batch0_pred.jpg', width=900)  # view test image predictions","826dd44a":"# trained weights are saved by default in our weights folder\n%ls","b6c6e058":"!python detect.py --source ..\/test\/images --weights 'runs\/exp0_tutorial\/weights\/last_tutorial.pt' --img 416 --conf 0.5","251b949e":"!ls","5020d3ac":"%cd inference\/output\/","0e2c12d0":"!ls","b56d5660":"Image(filename='2fd875eaa_jpg.rf.dd1d8cd790ac7bd4fa42b63bd6b6293b.jpg', width=900)","d584c458":"Image(filename='348a992bb_jpg.rf.1d04a696a55ee0ae7737b687d63f7af6.jpg', width=900)","d4424da3":"This is a starter kernel based on @ultralytics demo with COCO\n\nJust a quick note. You will see a download with my gdrive. I have already made the labels outside of Kaggle. I wanted to match the ultralytics version here with real data. If you have questions \/ suggestions please comment. ","d878dd22":"The yaml file below is my adjusted version yolo5x yaml file where you have to change the nc: 1  \nYou can upload the yaml file yourself just change the nc:\nhttps:\/\/github.com\/ultralytics\/yolov5\/blob\/master\/models\/yolov5x.yaml\n\nThat dataset should also be public. ","18a96b28":"# Run Inference with Trained Weights\n\nRun inference with a pretrained checkpoint on contents of test\/images folder","cb69ff02":"All training results are saved to runs\/exp0 for the first experiment, then runs\/exp1, runs\/exp2 etc. for subsequent experiments.\n\nI just set basic img size, batch and epochs. These are for you to tweak. ","76a027d0":"# Visualize the training data\n\n> After training starts, view `train*.jpg` images to see training images, labels and augmentation effects."}}