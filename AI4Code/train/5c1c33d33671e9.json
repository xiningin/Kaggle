{"cell_type":{"743d4068":"code","955357ba":"code","88fc4257":"code","653bca95":"code","9ae38f36":"code","5501cbf9":"code","4217a4f0":"code","0ce44b7a":"code","c755ff62":"code","60ed1760":"code","62fedbc8":"code","50dac20d":"code","f5626211":"code","c70231c4":"code","50b3f6fe":"code","f240ae09":"code","24df4413":"code","658b2f23":"code","89e53573":"markdown","c13c135a":"markdown","7ffefa5a":"markdown","02cb9208":"markdown","c79c1539":"markdown","e4ee8d6a":"markdown","dd5bc094":"markdown"},"source":{"743d4068":"!pip install '\/kaggle\/input\/mmdetectionv2140\/pycocotools-2.0.2\/pycocotools-2.0.2' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/mmpycocotools-12.0.3\/mmpycocotools-12.0.3' --no-deps","955357ba":"import sklearn\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport json\nimport glob\nimport pycocotools\nfrom pycocotools import mask\nimport random\nimport cv2\nimport re","88fc4257":"IMG_WIDTH = 704\nIMG_HEIGHT = 520","653bca95":"def rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists \"\"\"\n    return [item for sublist in nested_list for item in sublist]\n\n\ndef load_json_to_dict(json_path):\n    \"\"\" tbd \"\"\"\n    with open(json_path) as json_file:\n        data = json.load(json_file)\n    return data","9ae38f36":"def get_img_and_mask(img_path, annotation, width, height):\n    \"\"\" Capture the relevant image array as well as the image mask \"\"\"\n    img_mask = np.zeros((height, width), dtype=np.uint8)\n    for i, annot in enumerate(annotation): \n        img_mask = np.where(rle_decode(annot, (height, width))!=0, i, img_mask)\n    img = cv2.imread(img_path)[..., ::-1]\n    return img[..., 0], img_mask\n\ndef plot_img_and_mask(img, mask, invert_img=True, boost_contrast=True):\n    \"\"\" Function to take an image and the corresponding mask and plot\n    \n    Args:\n        img (np.arr): 1 channel np arr representing the image of cellular structures\n        mask (np.arr): 1 channel np arr representing the instance masks (incrementing by one)\n        invert_img (bool, optional): Whether or not to invert the base image\n        boost_contrast (bool, optional): Whether or not to boost contrast of the base image\n        \n    Returns:\n        None; Plots the two arrays and overlays them to create a merged image\n    \"\"\"\n    plt.figure(figsize=(20,10))\n    \n    plt.subplot(1,3,1)\n    _img = np.tile(np.expand_dims(img, axis=-1), 3)\n    \n    # Flip black-->white ... white-->black\n    if invert_img:\n        _img = _img.max()-_img\n        \n    if boost_contrast:\n        _img = np.asarray(ImageEnhance.Contrast(Image.fromarray(_img)).enhance(16))\n        \n    plt.imshow(_img)\n    plt.axis(False)\n    plt.title(\"Cell Image\", fontweight=\"bold\")\n    \n    plt.subplot(1,3,2)\n    _mask = np.zeros_like(_img)\n    _mask[..., 0] = mask\n    plt.imshow(mask, cmap='rainbow')\n    plt.axis(False)\n    plt.title(\"Instance Segmentation Mask\", fontweight=\"bold\")\n    \n    merged = cv2.addWeighted(_img, 0.75, np.clip(_mask, 0, 1)*255, 0.25, 0.0,)\n    plt.subplot(1,3,3)\n    plt.imshow(merged)\n    plt.axis(False)\n    plt.title(\"Cell Image w\/ Instance Segmentation Mask Overlay\", fontweight=\"bold\")\n    \n    plt.tight_layout()\n    plt.show()","5501cbf9":"def polygonFromMask(maskedArr, idx):\n  # adapted from https:\/\/github.com\/hazirbas\/coco-json-converter\/blob\/master\/generate_coco_json.py\n  contours, _ = cv2.findContours(maskedArr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n  segmentation = []\n  valid_poly = 0\n  for contour in contours:\n  # Valid polygons have >= 6 coordinates (3 points)\n     if contour.size >= 6:\n        segmentation.append(contour.astype(float).flatten().tolist())\n        valid_poly += 1\n  if valid_poly == 0:\n     raise ValueError(idx)\n  return [segmentation]","4217a4f0":"train_df = pd.read_csv('..\/input\/sartorius-cell-instance-segmentation\/train.csv')","0ce44b7a":"lines = []\nfor f in train_df.itertuples():\n    lines.append('..\/input\/sartorius-cell-instance-segmentation\/train\/' + f[1] + '.png')\nlins = pd.Series(lines, name='img_path')\ntrain_df = pd.concat([train_df, lins], axis=1)","c755ff62":"tmp_df = train_df.drop_duplicates(subset=[\"id\", \"img_path\"]).reset_index(drop=True)\ntmp_df[\"annotation\"] = train_df.groupby(\"id\")[\"annotation\"].agg(list).reset_index(drop=True)\ntrain_df = tmp_df.copy()","60ed1760":"train_df, val_df = train_test_split(train_df, train_size=0.95, random_state=0)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","62fedbc8":"categories = {\"cort\": 2, \"shsy5y\": 1, \"astro\": 3}","50dac20d":"output_json_dict = {\n    \"images\": [],\n    \"annotations\": [],\n    \"categories\": []\n}","f5626211":"category_dict = {\"id\": 1, \"name\": \"shsy5y\", \"supercategory\": \"none\"}\noutput_json_dict[\"categories\"].append(category_dict)\ncategory_dict = {\"id\": 2, \"name\": \"cort\", \"supercategory\": \"none\"}\noutput_json_dict[\"categories\"].append(category_dict)\ncategory_dict = {\"id\": 3, \"name\": \"astro\", \"supercategory\": \"none\"}\noutput_json_dict[\"categories\"].append(category_dict)","c70231c4":"def get_img_and_annot_info(df, annot_id_start=1):\n    for f in df.itertuples():\n        image_id = f[0]\n        file_path = f[-1]\n        width = f[3]\n        height = f[4]\n        category = categories[f[5]]\n#         img, mk = get_img_and_mask(file_path, f[2], width, height)\n        image_info = {\n            \"id\": image_id,\n            \"width\": width,\n            \"height\": height,\n            \"file_name\": file_path,\n        }\n        output_json_dict['images'].append(image_info)\n        for annot in np.unique(f[2]):\n#             print(annot)\n#             img, annotation = get_img_and_mask(file_path, annot, width, height)\n            annotation = rle_decode(annot, (IMG_HEIGHT, IMG_WIDTH))\n#             print(np.unique(annotation))\n            _, count = np.unique(annotation, return_counts=True)\n#             print(annotation.shape)\n            annot_mask = annotation.astype(np.bool)\n#             print(annot_mask)\n            annot_mask = np.asfortranarray(annot_mask)\n#             print(np.unique(annot_mask))\n            Rs = mask.encode(annot_mask)\n            Rs['counts'] = Rs['counts'].decode('utf-8')\n#             print(Rs)\n            bbox = mask.toBbox(Rs)\n            bbox_list = []\n            for element in bbox:\n                bbox_list.append(int(element))\n#             print(bbox_list)\n#             print(Rs)\n            annot_dict = {\n                \"category_id\": category,\n                \"segmentation\": Rs,\n                \"area\": int(mask.area(Rs)),\n                \"bbox\": bbox_list,\n                \"id\": annot_id_start,\n                \"image_id\": image_id,\n                \"iscrowd\": 0}\n            output_json_dict[\"annotations\"].append(annot_dict)\n            annot_id_start += 1","50b3f6fe":"# def get_img_and_annot_info(df, annot_id_start=1):\n#     for f in df.itertuples():\n#         image_id = f[0]\n#         file_path = f[-1]\n#         width = f[3]\n#         height = f[4]\n#         category = categories[f[5]]\n#         img, mk = get_img_and_mask(file_path, f[2], width, height)\n#         image_info = {\n#             \"id\": image_id,\n#             \"width\": width,\n#             \"height\": height,\n#             \"file_name\": file_path,\n#         }\n#         output_json_dict['images'].append(image_info)\n#         for annot in np.unique(mk):\n#             annotation = []\n#             if annot != 0:\n#                 annot_mask = mk == annot\n#                 _, count = np.unique(annot_mask, return_counts=True)\n#                 if count[1] >= 6 and (image_id != 270 and annot != 220) and (image_id!= 300 and annot != 16): #Doesn't give valid annotation otherwise\n#                     annot_mask = np.expand_dims(annot_mask, axis=2)\n#                     annot_mask = np.asfortranarray(annot_mask)\n#                     Rs = mask.encode(annot_mask)\n#                     assert len(Rs) == 1\n#                     coco_seg = Rs[0]\n#                     bbox = mask.toBbox(coco_seg)\n#                     bbox_list = []\n#                     for element in bbox:\n#                         bbox_list.append(int(element))\n#                     polygon_seg = mask.decode(coco_seg)\n#                     polygon_segm = polygonFromMask(polygon_seg, image_id)\n#                     annot_dict = {\n#                         \"category_id\": category,\n#                         \"segmentation\": polygon_segm[0],\n#                         \"area\": int(mask.area(coco_seg)),\n#                         \"bbox\": bbox_list,\n#                         \"id\": annot_id_start,\n#                         \"image_id\": image_id,\n#                         \"iscrowd\": 0}\n#                     output_json_dict[\"annotations\"].append(annot_dict)\n#                     annot_id_start += 1","f240ae09":"get_img_and_annot_info(train_df)\nwith open('train_dataset.json', 'w') as f:\n    output_json = json.dumps(output_json_dict)\n    f.write(output_json)","24df4413":"output_json_dict = {\n    \"images\": [],\n    \"annotations\": [], \n    \"categories\": []\n}\n\ncategory_dict = {\"id\": 1, \"name\": \"shsy5y\", \"supercategory\": \"none\"}\noutput_json_dict[\"categories\"].append(category_dict)\ncategory_dict = {\"id\": 2, \"name\": \"cort\", \"supercategory\": \"none\"}\noutput_json_dict[\"categories\"].append(category_dict)\ncategory_dict = {\"id\": 3, \"name\": \"astro\", \"supercategory\": \"none\"}\noutput_json_dict[\"categories\"].append(category_dict)","658b2f23":"get_img_and_annot_info(val_df)\nwith open('val_dataset.json', 'w') as f:\n    output_json = json.dumps(output_json_dict)\n    f.write(output_json)","89e53573":"# **Install PyCocoTools**","c13c135a":"# **Create Coco Json File**","7ffefa5a":"# **References**","02cb9208":"https:\/\/www.kaggle.com\/dschettler8845\/sartorius-segmentation-eda-and-baseline\n\nhttps:\/\/www.kaggle.com\/ihelon\/cell-segmentation-run-length-decoding\n\nhttps:\/\/www.kaggle.com\/stainsby\/fast-tested-rle\n\nhttps:\/\/www.kaggle.com\/paulorzp\/run-length-encode-and-decode\n\nhttps:\/\/www.kaggle.com\/awsaf49\/sartorius-mmdetection-infer\n\nhttps:\/\/www.kaggle.com\/awsaf49\/sartorius-mmdetection-train\n\nhttps:\/\/www.kaggle.com\/evancofsky\/sartorius-torch-lightning-mask-r-cnn\/notebook","c79c1539":"https:\/\/www.kaggle.com\/vexxingbanana\/sartorius-mmdetection-training\n\nhttps:\/\/www.kaggle.com\/vexxingbanana\/mmdetection-neuron-inference","e4ee8d6a":"# **Helper Functions**","dd5bc094":"# **Train and Inference Notebooks**"}}