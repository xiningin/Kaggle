{"cell_type":{"fd4b0ca1":"code","f78e087e":"code","d0b556bc":"code","0bac3dfe":"code","1e9a142e":"code","c6713b2e":"code","15e0bc89":"code","5b3fd3ba":"code","e895ceaf":"code","3fd45dfd":"code","6583de87":"code","7e625da5":"code","6756eff8":"code","ed344363":"code","ea215241":"code","bb045df2":"code","a8026b54":"code","ffec1d87":"code","e6e6a9b2":"code","f6e85a4a":"code","b0496175":"code","56bc30a3":"code","adf4ddec":"code","a4419d11":"code","74695a61":"code","c33b46d1":"code","8f4b985a":"code","1ce0007b":"code","0d73d074":"code","dc9e9d8c":"code","aca01d53":"code","7bd34911":"code","9899cabe":"code","23f82e93":"code","b2b1d31e":"code","536aeaa3":"code","f1ed51df":"code","22e63e6c":"code","48d73572":"code","0027b1ff":"code","0948663d":"code","f135c850":"code","23e2c5ca":"code","1d5746f5":"code","6412c725":"code","3f5062ae":"code","aa0db224":"code","7ec4dd23":"code","dc777060":"code","ccec7369":"code","7348b927":"code","d745a64e":"code","8909e9f2":"code","cfa12bd3":"code","1655a85e":"code","e9ff62dc":"code","a5a76d1f":"code","3e68c2e0":"code","b349d26a":"code","50efe3c1":"code","4dcf1441":"code","95cf6af6":"code","a7e24c7b":"code","f39369c7":"code","0df9c9f7":"code","b9d951bb":"code","89c7daf5":"code","e9137860":"code","7e252a1f":"code","595dc74a":"code","8eca73be":"code","5b31bd77":"code","fe3e7e32":"code","394c3ea5":"markdown","f5db40c2":"markdown","8060adcc":"markdown","e6e8bfa1":"markdown","b73184cf":"markdown","92c4a82a":"markdown"},"source":{"fd4b0ca1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SimpleRNN, SpatialDropout1D\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f78e087e":"data = pd.read_csv(\"\/kaggle\/input\/twitter-airline-sentiment\/Tweets.csv\")","d0b556bc":"data.head()","0bac3dfe":"data.shape","1e9a142e":"data = data[data['airline_sentiment_confidence'] > 0.6]","c6713b2e":"data.shape","15e0bc89":"data = data[['text', 'airline_sentiment']]\ndata.head()","5b3fd3ba":"def clean_train_data(x):\n    text = x\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text) # remove square brackets\n    text = re.sub(r'[^\\w\\s]','',text) # remove punctuation\n    text = re.sub('\\w*\\d\\w*', '', text) # remove words containing numbers\n    text = re.sub('\\n', '', text)\n    return text","e895ceaf":"data['text'] = data.text.apply(lambda x : clean_train_data(x))\ndata.head()","3fd45dfd":"all_cat_data = data.copy()","6583de87":"data = data[data['airline_sentiment'] != 'neutral']\ndata.head()","7e625da5":"print(len(data[data['airline_sentiment'] == 'positive']))\nprint(len(data[ data['airline_sentiment'] == 'negative']))\nprint(len(data[ data['airline_sentiment'] == 'neutral']))\n","6756eff8":"model1_data = data.copy()","ed344363":"max_features = 2000\ntoken = Tokenizer(num_words=max_features, split = ' ')\ntoken.fit_on_texts(data['text'].values)\n\nX = token.texts_to_sequences(data['text'].values)\nX = pad_sequences(X)","ea215241":"X.shape","bb045df2":"embed_dim = 128\nlstm_out = 196\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, embed_dim, input_length = X.shape[1]))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(2, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","a8026b54":"Y = pd.get_dummies(data['airline_sentiment']).values","ffec1d87":"X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.33, random_state=42)","e6e6a9b2":"batch_size = 32\nhistory = model.fit(X_train, y_train, epochs=10, batch_size=batch_size, verbose=2)","f6e85a4a":"# score = model.predict(X_test)\nscore, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=2)\nprint('score', score)\nprint('accuracy', acc)","b0496175":"text = ['i would recommend it if you have no other options']\ntext = token.texts_to_sequences(text)\ntext = pad_sequences(text, maxlen=28, dtype='int32', value=0)\nres = model.predict(text, batch_size=1,verbose = 2)\nres","56bc30a3":"if np.argmax(res[0]) == 0:\n    print(\"Negetive Comment\")\nelif np.argmax(res[0]) == 1:\n    print(\"Psetive Comment\")","adf4ddec":"ms_data = all_cat_data.copy()","a4419d11":"ms_data.head()","74695a61":"num_of_rows = 4000\nshuffled = ms_data.reindex(np.random.permutation(ms_data.index))\nnt = shuffled[shuffled['airline_sentiment'] == 'neutral'][:num_of_rows]\nng = shuffled[shuffled['airline_sentiment'] == 'negative'][:num_of_rows]\nps = shuffled[shuffled['airline_sentiment'] == 'positive'][:num_of_rows]\ncombine_data = pd.concat([nt, ng, ps], ignore_index=True)\ncombine_data = combine_data.reindex(np.random.permutation(combine_data.index))\ncombine_data['label'] = 0\ncombine_data.head()","c33b46d1":"print(len(combine_data[combine_data['airline_sentiment'] == 'neutral']))\nprint(len(combine_data[combine_data['airline_sentiment'] == 'negative']))\nprint(len(combine_data[combine_data['airline_sentiment'] == 'positive']))","8f4b985a":"ms_data = combine_data.copy()","1ce0007b":"print(len(ms_data[ms_data['airline_sentiment'] == 'neutral']))\nprint(len(ms_data[ms_data['airline_sentiment'] == 'negative']))\nprint(len(ms_data[ms_data['airline_sentiment'] == 'positive']))","0d73d074":"ms_data.loc[ms_data['airline_sentiment'] == 'neutral', 'label'] = 0\nms_data.loc[ms_data['airline_sentiment'] == 'negative', 'label'] = 1\nms_data.loc[ms_data['airline_sentiment'] == 'positive', 'label'] = 2","dc9e9d8c":"ms_data.head(10)","aca01d53":"from keras.utils import to_categorical","7bd34911":"labels = to_categorical(ms_data['label'], num_classes=3)","9899cabe":"labels.shape","23f82e93":"labels[:10]","b2b1d31e":"max_features = 3000\nmax_len = 130\nms_token = Tokenizer(num_words=max_features)\nms_token.fit_on_texts(ms_data['text'].values)\nms_sequences = ms_token.texts_to_sequences(ms_data['text'].values)\nX = pad_sequences(ms_sequences, maxlen=max_len)","536aeaa3":"word_index = ms_token.word_index\nprint('Found %s unique tokens.' % len(word_index))","f1ed51df":"y = labels","22e63e6c":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=42)","48d73572":"embed_dim = 128\nlstm_out = 96","0027b1ff":"ms_model = Sequential()\nms_model.add(Embedding(max_features, embed_dim, input_length = X.shape[1]))\nms_model.add(SpatialDropout1D(0.7))\nms_model.add(LSTM(64, dropout=0.7, recurrent_dropout=0.7))\nms_model.add(Dense(3, activation='softmax'))\nms_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n\nms_model.summary()","0948663d":"from keras.callbacks import EarlyStopping","f135c850":"batch_size = 50\nms_history = ms_model.fit(X_train, y_train, epochs=20, batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',patience=7, min_delta=0.0001)])","23e2c5ca":"loss, accuracy = ms_model.evaluate(X_test, y_test)\nprint(\"loss\", loss)\nprint(\"accuracy\", accuracy)","1d5746f5":"text = ['i would recommend it if you have no other options']\ntext = token.texts_to_sequences(text)\ntext = pad_sequences(text, maxlen=max_len)\nres = ms_model.predict(text)\nres","6412c725":"if np.argmax(res) == 0:\n    print(\"neutral Comment\")\nelif np.argmax(res) == 1:\n    print(\"Negetive Comment\")\nelif np.argmax(res) == 2:\n    print(\"positive Comment\")","3f5062ae":"em_data = all_cat_data.copy()","aa0db224":"em_data.head()","7ec4dd23":"# em_data = em_data[em_data['airline_sentiment'] != 'neutral']\n# em_data.head()","dc777060":"num_of_rows = 4000\nshuffled = em_data.reindex(np.random.permutation(em_data.index))\nnt = shuffled[shuffled['airline_sentiment'] == 'neutral'][:num_of_rows]\nng = shuffled[shuffled['airline_sentiment'] == 'negative'][:num_of_rows]\nps = shuffled[shuffled['airline_sentiment'] == 'positive'][:num_of_rows]\ncombine_data = pd.concat([nt, ng, ps], ignore_index=True)\ncombine_data = combine_data.reindex(np.random.permutation(combine_data.index))\ncombine_data['label'] = 0\ncombine_data.head()","ccec7369":"print(len(combine_data[combine_data['airline_sentiment'] == 'neutral']))\nprint(len(combine_data[combine_data['airline_sentiment'] == 'negative']))\nprint(len(combine_data[combine_data['airline_sentiment'] == 'positive']))","7348b927":"ms_data = combine_data.copy()","d745a64e":"print(len(ms_data[ms_data['airline_sentiment'] == 'neutral']))\nprint(len(ms_data[ms_data['airline_sentiment'] == 'negative']))\nprint(len(ms_data[ms_data['airline_sentiment'] == 'positive']))","8909e9f2":"ms_data.loc[ms_data['airline_sentiment'] == 'neutral', 'label'] = 0\nms_data.loc[ms_data['airline_sentiment'] == 'negative', 'label'] = 1\nms_data.loc[ms_data['airline_sentiment'] == 'positive', 'label'] = 2","cfa12bd3":"ms_data.head(10)","1655a85e":"from keras.utils import to_categorical","e9ff62dc":"labels = to_categorical(ms_data['label'], num_classes=3)","a5a76d1f":"labels.shape","3e68c2e0":"labels[:10]","b349d26a":"# Y = pd.get_dummies(em_data['airline_sentiment']).values","50efe3c1":"xtrain, xvalid, ytrain, yvalid = train_test_split(ms_data.text.values, labels, \n                                                  stratify=labels, \n                                                  random_state=42, \n                                                  test_size=0.2, shuffle=True)","4dcf1441":"from tqdm import tqdm","95cf6af6":"embeddings_index = {}\nf = open('\/kaggle\/input\/glove840b300dtxt\/glove.840B.300d.txt','r',encoding='utf-8')\nfor line in tqdm(f):\n    values = line.split(' ')\n    word = values[0]\n    coefs = np.asarray([float(val) for val in values[1:]])\n    embeddings_index[word] = coefs\n    \nf.close()","a7e24c7b":"# token = Tokenizer(num_words=None)\n# word_index = token.word_index","f39369c7":"# using keras tokenizer here\ntoken = Tokenizer(num_words=None)\nmax_len = 1500\n\ntoken.fit_on_texts(list(xtrain) + list(xvalid))\nxtrain_seq = token.texts_to_sequences(xtrain)\nxvalid_seq = token.texts_to_sequences(xvalid)\n\n#zero pad the sequences\nxtrain_pad = pad_sequences(xtrain_seq, maxlen=max_len)\nxvalid_pad = pad_sequences(xvalid_seq, maxlen=max_len)\n\nword_index = token.word_index\n# word_index","0df9c9f7":"# word_index","b9d951bb":"embedding_matrix = np.zeros((len(word_index) + 1, 300))\nfor word, i in tqdm(word_index.items()):\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","89c7daf5":"# embedding_matrix","e9137860":"from keras.layers import Bidirectional","7e252a1f":"embed_dim = 128\nmodel = Sequential()\nmodel.add(Embedding(\n    len(word_index) + 1,\n    300,\n    weights=[embedding_matrix],\n    input_length=embed_dim,\n    trainable=False\n))\nmodel.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\nmodel.add(Dense(3, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","595dc74a":"# model.fit(xtrain_pad, ytrain, nb_epoch=5, batch_size=10)\nbatch_size = 32\nhistory = model.fit(xtrain_pad, ytrain, epochs=5, batch_size=batch_size)","8eca73be":"# score = model.predict(X_test)\nscore, acc = model.evaluate(xvalid_pad, yvalid, batch_size=batch_size)\nprint('score', score)\nprint('accuracy', acc)","5b31bd77":"text = ['i would recommend it if you have no other options']\ntext = token.texts_to_sequences(text)\ntext = pad_sequences(text, maxlen=28, dtype='int32', value=0)\nres = model.predict(text, batch_size=1,verbose = 2)\nres","fe3e7e32":"if np.argmax(res) == 0:\n    print(\"neutral Comment\")\nelif np.argmax(res) == 1:\n    print(\"Negetive Comment\")\nelif np.argmax(res) == 2:\n    print(\"positive Comment\")","394c3ea5":"# 2 class sentiment Analysis","f5db40c2":"## data preprocessing","8060adcc":"# Acknowledgement:\n* https:\/\/www.kaggle.com\/ngyptr\/multi-class-classification-with-lstm\n* https:\/\/www.kaggle.com\/tanulsingh077\/deep-learning-for-nlp-zero-to-transformers-bert\n* https:\/\/www.kaggle.com\/ngyptr\/lstm-sentiment-analysis-keras","e6e8bfa1":"## token","b73184cf":"# Multiclass Sentiment Analysis","92c4a82a":"# Another Solution with Embedding Glove"}}