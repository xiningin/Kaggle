{"cell_type":{"4719d30c":"code","d9c2631e":"code","bf0c194f":"code","459fb9d0":"code","3f06ba2f":"code","a100796a":"code","0ee3864c":"code","11abd1b8":"code","92e1a45a":"code","312fe574":"code","c5432032":"code","4dccc219":"code","e50b01dd":"code","428f782d":"code","820de7e7":"code","05fe0e9c":"code","cf0f0de6":"code","b927820a":"code","45674b03":"code","40b0402b":"code","c0ae2cb5":"code","f2e9c695":"code","85ae8558":"code","b9e5258d":"code","fe53762b":"code","f5a2aad9":"code","ec964256":"code","3821a85a":"code","3dbd0530":"code","8afc2287":"code","8d1f0f01":"code","f37ce361":"code","5af08d60":"code","fa4b700c":"code","098f8eb1":"code","6b432b55":"code","9f3abc27":"code","81dd71c7":"code","934f75a9":"code","ef947531":"code","d628cf59":"code","aab65dbc":"code","d6545826":"code","c1617390":"code","d4116753":"code","04982a99":"code","971f8419":"code","e84641c4":"code","929d03de":"code","23f875a8":"code","a93c4677":"markdown","37af9e1c":"markdown","46a28d1e":"markdown","acc6b712":"markdown","683b4d0e":"markdown","af1e1ceb":"markdown","271241d5":"markdown","76c50634":"markdown","c8789f14":"markdown","ca9aeba9":"markdown","84e8d90e":"markdown","4f996ce9":"markdown","814dafa0":"markdown","5a717764":"markdown","c663381f":"markdown","5722db32":"markdown","7cb2243a":"markdown","92731e47":"markdown","97e39fea":"markdown","c5004443":"markdown","a3037267":"markdown","1a935f71":"markdown","d41c0347":"markdown","a3d6ae91":"markdown","a8820f86":"markdown","50fb35b8":"markdown","ca066900":"markdown"},"source":{"4719d30c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport os","d9c2631e":"train_df = pd.read_csv('..\/input\/car-crashes-severity-prediction\/train.csv')\ntest_df = pd.read_csv('..\/input\/car-crashes-severity-prediction\/test.csv')\nweather_df = pd.read_csv('..\/input\/car-crashes-severity-prediction\/weather-sfcsv.csv')","bf0c194f":"pd.set_option('display.max_column', 100)\n# train data\nprint(\"The shape of the train dataset is {}.\\n\\n\".format(train_df.shape))\ntrain_df.head()","459fb9d0":"#test data\nprint(\"The shape of the test dataset is {}.\\n\\n\".format(test_df.shape))\ntest_df.head()","3f06ba2f":"# weather data\nprint(\"The shape of the weather dataset is {}.\\n\\n\".format(weather_df.shape))\nweather_df.head()","a100796a":"train_df.info()","0ee3864c":"test_df.info()","11abd1b8":"weather_df.info()","92e1a45a":"print('the shape of weather data before dropping duplicates : ', weather_df.shape)\nweather_df = weather_df.drop_duplicates(['Year','Month','Day', 'Hour'], keep='last')\nprint('the shape of weather data after dropping duplicates : ', weather_df.shape)","312fe574":"for df in [train_df, test_df] :\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n","c5432032":"for df in [train_df, test_df] :\n    df['Year'] = df['timestamp'].dt.strftime('%Y').astype(int)\n    df['Month'] = df['timestamp'].dt.strftime('%m').astype(int)\n    df['Day'] = df['timestamp'].dt.strftime('%d').astype(int)\n    df['Hour'] = df['timestamp'].dt.strftime('%H').astype(int)\n    df['time'] = df['timestamp'].dt.strftime('%Y-%m-%d')\n","4dccc219":"import xml.etree.ElementTree as Xet\n  \ncols = [\"date\"]\nrows = []\n  \n# Parsing the XML file\nxmlparse = Xet.parse('\/kaggle\/input\/car-crashes-severity-prediction\/holidays.xml')\nroot = xmlparse.getroot()\nfor i in root:\n    date = i.find(\"date\").text\n    rows.append({\"date\": date })\n    \n    \nholidays_df = pd.DataFrame(rows, columns=cols)\nholidays_df.head()","e50b01dd":"holiday_set = set(holidays_df['date'])\nfor df in [train_df, test_df] :    \n    df['is_holiday'] = df['time'].isin(holiday_set).astype(int)\n    ","428f782d":"train_df = pd.merge(train_df, weather_df, left_on = ['Year', 'Month', 'Day', 'Hour'], right_on = ['Year', 'Month', 'Day', 'Hour'])\ntest_df = pd.merge(test_df, weather_df, left_on = ['Year', 'Month', 'Day', 'Hour'], right_on = ['Year', 'Month', 'Day', 'Hour'])","820de7e7":"train_df.head()","05fe0e9c":"test_df.head()","cf0f0de6":"train_df.describe().T","b927820a":"boolean_columns = ['Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Stop', 'Amenity', 'Side', 'Selected']\ndef col_values(data, col) :    \n    return data[col].value_counts()\nfor col in boolean_columns :\n    print('Column Name : ', col)\n    print(col_values(train_df, col))\n    print(\"====================\")       ","45674b03":"train_df.isnull().sum()","40b0402b":"test_df.isnull().sum()","c0ae2cb5":"columns_2_drop = ['Bump', 'Give_Way', 'No_Exit', 'Roundabout', 'Wind_Chill(F)', 'Precipitation(in)', 'Selected', 'time', 'timestamp']\nfor df in [train_df, test_df] :\n    df.drop(columns = columns_2_drop, axis = 1, inplace = True)","f2e9c695":"train_df['ID'].duplicated().sum()","85ae8558":"# correlation matrix and heatmap to stand on important features\ncorr_matrix = train_df.corr()\nmask = np.triu(np.ones_like(corr_matrix,dtype = bool))\nplt.figure(figsize = (20,10))\nsns.heatmap(corr_matrix, fmt = '0.1f', cmap = 'Blues', mask = mask, annot = True)\nplt.title(\"Correlation Analysis\");","b9e5258d":"corr_matrix['Severity']","fe53762b":"'''plt.scatter(data = train_df, x = 'Temperature(F)', y = 'Humidity(%)')\nplt.xlabel('Temperature(F)')\nplt.ylabel('Humidity(%)')\nplt.title('Temp VS Humidity');'''","f5a2aad9":"# imputing nan in Wind_Speed(mph) by a random sample\n'''for df in [train_df, test_df] :  \n    random_sample = df['Wind_Speed(mph)'].dropna().sample(df['Wind_Speed(mph)'].isnull().sum())\n    random_sample.index = df[df['Wind_Speed(mph)'].isnull()].index\n    df.loc[df['Wind_Speed(mph)'].isnull(), 'Wind_Speed(mph)'] = random_sample'''\nfor df in [train_df,test_df]:\n    df['Wind_Speed(mph)'].fillna(df['Wind_Speed(mph)'].dropna().mean(), inplace = True)\n    \n#train_df['Wind_Speed(mph)'].fillna(train_df['Wind_Speed(mph)'].dropna().mean(), inplace = True)\n       ","ec964256":"train_df.isnull().sum()","3821a85a":"# dropping some records with nulls\ntrain_df.dropna(inplace = True)\ntrain_df.isnull().sum()","3dbd0530":"train_df['Severity'].value_counts()","8afc2287":"sns.countplot(data = train_df, x = 'Severity');","8d1f0f01":"plt.scatter(data = train_df, x = 'Lat', y = 'Lng')\nplt.xlabel('Latitude')\nplt.ylabel('Longitude')\nplt.title('Locations of car crashes');","f37ce361":"#sns.boxplot(train_df['Distance(mi)'])\nnp.sum(train_df['Distance(mi)'] > 2)","5af08d60":"train_df = train_df[train_df['Distance(mi)'] < 2]\nplt.hist(train_df['Distance(mi)'])","fa4b700c":"plt.hist(train_df['Lat'])","098f8eb1":"np.sum(train_df['Lat'] < 37.7)","6b432b55":"train_df = train_df[train_df['Lat'] > 37.7]","9f3abc27":"plt.hist(train_df['Lng']);","81dd71c7":"plt.hist(train_df['Temperature(F)'])","934f75a9":"plt.hist(train_df['Humidity(%)'])","ef947531":"plt.hist(train_df['Wind_Speed(mph)']);","d628cf59":"train_df.head()","aab65dbc":"'''weather_dict = {'Clear' : 1,'Fair':2,'Fair \/ Windy':2,'Mist':3,'Patches of Fog':4, 'Shallow Fog':5, 'Fog':6,'Fog \/ Windy':6, 'Scattered Clouds':7,'Smoke':8, 'Haze':8\n      , 'Overcast':9, 'Cloudy':10, 'Cloudy \/ Windy':10, 'Partly Cloudy':11, 'Partly Cloudy \/ Windy':11,'Mostly Cloudy':12\n      , 'Mostly Cloudy \/ Windy':12, 'Light Drizzle':13, 'Light Rain \/ Windy':14, 'Light Rain':14, 'Rain':15, 'Rain \/ Windy':15\n      ,'Heavy Rain':16, 'Squalls':17, 'Light Thunderstorms and Rain':17}\nfor df in [train_df, test_df] :\n    df['Weather_Condition'] = df['Weather_Condition'].map(weather_dict) \n   '''\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\nfor df in [train_df, test_df] :\n    df['Weather_Condition'] = label_encoder.fit_transform(df['Weather_Condition'])\n","d6545826":"idx = train_df['Weather_Condition'].value_counts().sort_values(ascending = True).index\nidx","c1617390":"train_df = pd.get_dummies(train_df)\ntest_df = pd.get_dummies(test_df)\n","d4116753":"from sklearn.preprocessing import PolynomialFeatures\npoly_feat = PolynomialFeatures(degree = 2, include_bias = False)\nfor df in [train_df, test_df] :\n    location_data = df[['Lng', 'Lat']]\n    train_poly = poly_feat.fit_transform(location_data)\n    df['new_Lng'] = train_poly[:, 2]\n    df['Lng_Lat'] = train_poly[:, 3]\n    df['new_Lat'] = train_poly[:, 4]\ntest_df.head()","04982a99":"from sklearn.model_selection import train_test_split\n\ntrain_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42) # Try adding `stratify` here\n\nX_train = train_data.drop(columns=['ID','Severity'])\ny_train = train_data['Severity']\n\nX_val = val_data.drop(columns=['ID','Severity'])\ny_val = val_data['Severity']","971f8419":"from sklearn.ensemble import RandomForestClassifier\n\n# Create an instance of the classifier\nclassifier = RandomForestClassifier(max_depth=2,random_state=0)\n\n# Train the classifier\nclassifier = classifier.fit(X_train, y_train)","e84641c4":"#print(\"The accuracy of the classifier on the training set is \", (classifier.score(X_train, y_train)))\nprint(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))","929d03de":"X_test = test_df.drop(columns=['ID'])\n\ny_test_predicted = classifier.predict(X_test)\n\ntest_df['Severity'] = y_test_predicted\n\ntest_df.head()","23f875a8":"test_df[['ID', 'Severity']].to_csv('\/kaggle\/working\/submission.csv', index=False)","a93c4677":"# Adding holiday feature to train and test data","37af9e1c":"## Encoding Categorical Variables","46a28d1e":"# import libraries","acc6b712":"## Correlation Matrix","683b4d0e":"## Splitting Data","af1e1ceb":"## Data Is Ready For The Model","271241d5":"## Dropping some features","76c50634":"## Polynomial Features","c8789f14":"> columns [Bump, Give_Way, No_Exit, Roundabout, Selected] should be dropped as it has one unique value","ca9aeba9":"## Submission File Generation","84e8d90e":"## Location of car crashes","4f996ce9":"## showing the merged data","814dafa0":"# Exploring data","5a717764":"## Handling Missing Values","c663381f":"> so car crashes of severity 2 and 3 are the most common","5722db32":"there is huge number of nulls in [Wind_Chill(F), Precipitation(in)] features so they will be dropped also","7cb2243a":"## Severity investigating","92731e47":"## Fixing data type of timestamp","97e39fea":"## Handling Outliers","c5004443":"# Get holidays date as dataframe from hoidays xml","a3037267":"## Dropping duplicates in weather dataset","1a935f71":"# Merging wheather data with test and train data","d41c0347":"# Get The Data","a3d6ae91":"> no nulls in train and test data but there is many nulls in weather data","a8820f86":"## expand timestamp ","50fb35b8":"## Further Investigating New Data","ca066900":"## Random Forest Classifier"}}