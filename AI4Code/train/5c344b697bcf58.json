{"cell_type":{"8cace1ea":"code","5380aa2b":"code","ff27b6bf":"code","0711122f":"code","dd443d82":"code","9c5a8861":"code","bb503e08":"code","8bfa0ec1":"code","f2f368d5":"code","76791de9":"code","925aa868":"code","70df8ecc":"code","14dcec54":"code","3b1b30b8":"code","4569f6eb":"code","80f98fa6":"code","ee7dbfa3":"code","84627e9c":"code","fda46299":"code","72f09c5e":"code","696dd55f":"code","2686bc8c":"code","9d01fee9":"code","3de087ea":"code","7c2a5c12":"code","458624e5":"code","db604f18":"code","c93a4d4d":"code","5901b941":"code","98a75733":"code","d81d3bb6":"code","de3d766a":"code","014758b2":"code","2958e657":"code","78925b39":"markdown","283d3ace":"markdown","ef84cd03":"markdown","6e006086":"markdown","0714eae2":"markdown","54b4e143":"markdown","76069bf2":"markdown","997eda11":"markdown","ced045e6":"markdown","909e7ab9":"markdown","df7f4636":"markdown","7213584f":"markdown","dcadcc51":"markdown","bf73e5e9":"markdown","aa579591":"markdown","2c70787b":"markdown","0f84c93c":"markdown","dade6ade":"markdown","43d88861":"markdown"},"source":{"8cace1ea":"import numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.models import Sequential, load_model\nfrom tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate\nfrom tensorflow.python.keras.applications.vgg16 import VGG16\nfrom tensorflow.python.keras import optimizers\n\nimport plotly.offline as py\nimport plotly.graph_objs as go\npy.init_notebook_mode(connected=True)\n\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n\nimport warnings\nwarnings.filterwarnings('ignore')","5380aa2b":"# CONSTANTS\nSIZE = 28\nLABELS = 10\nCHANNELS = 1","ff27b6bf":"def digits(data, labels=None, random=False, xy=None):\n    if xy is None: x, y = 20, min(10, len(data) \/\/ 20 +1)\n    else: x, y = xy\n    fig, ax = plt.subplots(y, x, figsize = (x, y))\n    if x==1: indeces = np.arange(y)\n    elif y==1: indeces = np.arange(x)\n    else: indeces = [(i,j) for i in np.arange(y) for j in np.arange(x)]\n    for i, index in enumerate(indeces[:len(data)]):\n        if random: i = np.random.randint(0, len(data))\n        ax[index].matshow(data.reshape(-1, SIZE, SIZE)[i], cmap=cm.gray_r)\n        if labels: ax[index].set_title(\"Label: {}\".format(labels[i]))\n    for index in indeces: ax[index].axis('off')\n    plt.subplots_adjust(wspace=0, hspace=0)\n    plt.show()","0711122f":"def plotter(history):\n    at, av, lt, lv = zip(*history)\n    fig = plt.figure(figsize=(15, 8)); ax1 = fig.add_subplot(221); ax2 = fig.add_subplot(222)\n\n    ax1.plot(np.arange(0, len(at), 1), at,\".-\", color='#2A6EA6', label=\"Training: {0:.2f}%\".format(at[-1]))\n    ax1.plot(np.arange(0, len(av), 1), av,\".-\", color='#FFA933', label=\"Validation: {0:.2f}%\".format(av[-1]))\n    ax1.grid(True); ax1.legend(loc=\"lower right\"); ax1.set_title(\"Accuracy per epoch\")\n\n    ax2.plot(np.arange(0, len(lt), 1), lt,\".-\", color='#2A6EA6', label=\"Training: {0:.2f}\".format(lt[-1]))\n    ax2.plot(np.arange(0, len(lv), 1), lv,\".-\", color='#FFA933', label=\"Validation: {0:.2f}\".format(lv[-1]))\n    ax2.grid(True); ax2.legend(loc=\"upper right\"); ax2.set_title(\"Cost per epoch\")\n    plt.show()","dd443d82":"def plotCertainty(data, predictions, probabilities):\n    fig1, ax1 = plt.subplots(1, 10, figsize = (20, 2))\n    fig2, ax2 = plt.subplots(1, 10, figsize = (20, 2))\n    for t in np.arange(10):\n        ax1[t].matshow(data.reshape(-1, SIZE, SIZE)[t], cmap=cm.gray_r)\n        ax1[t].get_yaxis().set_visible(False); ax1[t].get_xaxis().set_visible(False)\n        ax2[t].set_title(\"Prediction: {}\".format(predictions[t]))\n        ax2[t].plot(probabilities[t], lw=2)\n        ax2[t].set_title(\"Prediction: {}\".format(predictions[t]))\n        ax2[t].get_yaxis().set_visible(False); ax2[t].set_ylim([0, 1]); ax2[t].grid(True)\n    plt.show()","9c5a8861":"data = pd.read_csv('\/kaggle\/input\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/test.csv')\nlabels = data.pop('label')","bb503e08":"data.tail()","8bfa0ec1":"labels.head()","f2f368d5":"digits(data.values, random=True)","76791de9":"print('Training set', data.shape, labels.shape)\nprint('Testing set', test.shape)","925aa868":"data = data.values.reshape(-1, SIZE, SIZE, CHANNELS)\ntestX = test.values.reshape(-1, SIZE, SIZE, CHANNELS)\nlabels = pd.get_dummies(labels).values","70df8ecc":"print('Training set', data.shape, labels.shape)\nprint('Testing set', testX.shape)","14dcec54":"from sklearn.model_selection import train_test_split\ntrainX, validX, trainY, validY = train_test_split(data, labels, train_size=32000, random_state=100)","3b1b30b8":"print('Training set:', trainX.shape, trainY.shape)\nprint('Validation set:', validX.shape, validY.shape)\nprint('Testing set:', testX.shape)","4569f6eb":"trainAugmenter = ImageDataGenerator(\n        rotation_range=5,\n        width_shift_range=0.08,\n        height_shift_range=0.08,\n        shear_range=0.08,\n        zoom_range=(0.92, 1.08),\n        horizontal_flip=False)\nvalidAugmenter = ImageDataGenerator()\ntestAugmenter = ImageDataGenerator()","80f98fa6":"BATCHSIZE = 128","ee7dbfa3":"trainGenerator = trainAugmenter.flow(trainX, trainY, BATCHSIZE)\nvalidGenerator = validAugmenter.flow(validX, validY, BATCHSIZE)\ntestGenerator = testAugmenter.flow(testX, None, BATCHSIZE)","84627e9c":"for batchX, batchY in trainGenerator:\n    digits(batchX)\n    break","fda46299":"NUMFILTERS = 16\nFILTER = 3\nACTIVATION = 'tanh'\nDROPOUT = 0.5","72f09c5e":"model = Sequential([\n    Conv2D(NUMFILTERS, (FILTER, FILTER), padding='same', activation=ACTIVATION, input_shape=(trainX.shape[1:])),\n    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n\n    Conv2D(NUMFILTERS*2, (FILTER, FILTER), padding='same', activation=ACTIVATION),\n    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n\n    Conv2D(NUMFILTERS*4, (FILTER, FILTER), padding='same', activation=ACTIVATION),\n    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n\n    Conv2D(NUMFILTERS*8, (FILTER, FILTER), padding='same', activation=ACTIVATION),\n    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n\n    Flatten(),\n    Dropout(DROPOUT),\n    Dense(trainY.shape[1]*6, activation=ACTIVATION),\n    Dropout(DROPOUT),\n    Dense(trainY.shape[1]*2, activation=ACTIVATION),\n    Dropout(DROPOUT),\n    Dense(trainY.shape[1], activation='softmax'),\n])","696dd55f":"model.compile(optimizer=optimizers.Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","2686bc8c":"EPOCHS = 50","9d01fee9":"model.fit_generator(trainGenerator, epochs=EPOCHS, validation_data=validGenerator)","3de087ea":"x = np.arange(EPOCHS)+1\nhistory = model.history.history\n\ndata = [\n    go.Scatter(x=x, y=history[\"acc\"], name=\"Train Accuracy\", marker=dict(size=5), yaxis='y2'),\n    go.Scatter(x=x, y=history[\"val_acc\"], name=\"Valid Accuracy\", marker=dict(size=5), yaxis='y2'),\n    go.Scatter(x=x, y=history[\"loss\"], name=\"Train Loss\", marker=dict(size=5)),\n    go.Scatter(x=x, y=history[\"val_loss\"], name=\"Valid Loss\", marker=dict(size=5))\n]\nlayout = go.Layout(title=\"Model Training Evolution\", font=dict(family='Palatino'), \n                   xaxis=dict(title='Epoch', range=[0,EPOCHS]),\n                   yaxis1=dict(title=\"Loss\", domain=[0, 0.45]), \n                   yaxis2=dict(title=\"Accuracy\", domain=[0.55, 1]))\npy.iplot(go.Figure(data=data, layout=layout), show_link=False)","7c2a5c12":"print(model.evaluate(trainX, trainY))\nprint(model.evaluate(validX, validY))","458624e5":"validProbs = model.predict(validX)\nvalidPreds = validProbs.argmax(axis=1)\nvalidTruth = validY.argmax(axis=1)\nconfusionmatrix = pd.crosstab(validPreds, validTruth, normalize=False)","db604f18":"trace = go.Heatmap(x=np.arange(10), y=np.arange(10), z=confusionmatrix.values,\n                   colorscale = [[0,\"#ffffff\"], [0.1,\"#000000\"], [1,\"#000000\"]],\n                   colorbar = dict(ticksuffix='', thickness=15, len=1))\nlayout = go.Layout(font=dict(family='Palatino'), height=500, width=600,\n                   margin = go.layout.Margin(l=50, r=30, b=30, t=50), \n                   xaxis=dict(title=\"Truth\", dtick=1, side='top'), \n                   yaxis=dict(title=\"Prediction\", dtick=1, autorange='reversed'))\npy.iplot(go.Figure(data=[trace], layout=layout), show_link=False)","c93a4d4d":"digits(validX[(validTruth==4)&(validPreds==9)])","5901b941":"digits(validX[(validTruth==9)&(validPreds==8)])","98a75733":"order = (-validProbs.max(axis=1)).argsort()","d81d3bb6":"plotCertainty(validX[order[-10:]], validPreds[order[-10:]], validProbs[order[-10:]])","de3d766a":"plotCertainty(validX[order[:10]], validPreds[order[:10]], validProbs[order[:10]])","014758b2":"probabilities = model.predict(testX)\npredictions = probabilities.argmax(axis=1)","2958e657":"submission = pd.DataFrame({\"ImageId\":np.arange(1, len(predictions)+1), \"Label\":predictions})\nsubmission.to_csv(\"submissionMnist.csv\", index=False)\nsubmission.head()","78925b39":"<h1>Content<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Visualizer-Methods\" data-toc-modified-id=\"Visualizer-Methods-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Visualizer Methods<\/a><\/span><\/li><li><span><a href=\"#Data-Import\" data-toc-modified-id=\"Data-Import-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Data Import<\/a><\/span><\/li><li><span><a href=\"#Data-Preproccessing\" data-toc-modified-id=\"Data-Preproccessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Data Preproccessing<\/a><\/span><\/li><li><span><a href=\"#Conv-Net-with-TensorFlow\" data-toc-modified-id=\"Conv-Net-with-TensorFlow-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Conv Net with TensorFlow<\/a><\/span><\/li><li><span><a href=\"#Conv-Net-with-Keras\" data-toc-modified-id=\"Conv-Net-with-Keras-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Conv Net with Keras<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Data-Generator\" data-toc-modified-id=\"Data-Generator-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;<\/span>Data Generator<\/a><\/span><\/li><li><span><a href=\"#Model-Architecture\" data-toc-modified-id=\"Model-Architecture-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;<\/span>Model Architecture<\/a><\/span><\/li><li><span><a href=\"#Model-Training\" data-toc-modified-id=\"Model-Training-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;<\/span>Model Training<\/a><\/span><\/li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;<\/span>Model Evaluation<\/a><\/span><\/li><li><span><a href=\"#Error-Analysis\" data-toc-modified-id=\"Error-Analysis-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;<\/span>Error Analysis<\/a><\/span><\/li><li><span><a href=\"#Test-Predictions\" data-toc-modified-id=\"Test-Predictions-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;<\/span>Test Predictions<\/a><\/span><\/li><\/ul><\/li><\/ul><\/div>","283d3ace":"### Model Training\nLet's train.","ef84cd03":"The effect of data augmentation is hardly noticeable for is, but greatly improves the number of samples to train on. ","6e006086":"---\n\n## Conv Net with Keras","0714eae2":"I noticed that it helps to manually set the learning rate lower than the default rate.","54b4e143":"# Achieving 99% on MNIST\n\nIn this notebook the MNIST dataset is classified by means of a convolutional network with Keras, achieving 99% on the testing set.\n\nTopics include data augmentation and error analysis.","76069bf2":"This function prints some digits.","997eda11":"### Error Analysis\nError analysis gives us great insight in the way the model is making its errors. Often, it shows data quality issues.","ced045e6":"---\n## Data Preproccessing\nThe next step is to reformat the data into a TensorFlow-friendly shape.\n- Convolutions need the image data formatted as a cube (width by height by #channels)\n- Labels need to be 1-hot encodings.","909e7ab9":"### Data Generator\nThis generator performs slight transformations on the digits, augmenting our data.","df7f4636":"---\n## Data Import\nFirst, we need to import the data.","7213584f":"<img src=\"http:\/\/i.imgur.com\/tx9e64t.jpg\">\n\n---","dcadcc51":"Apparently, most errors come from predicting images of 9's as 4's. Some of the errors seem understandable.","bf73e5e9":"### Model Evaluation\nLet's plot the training evolution.","aa579591":"### Model Architecture\n\nWe choose four convolutional layers and three dense layers.","2c70787b":"Here are images of 9's predicted as 8's.","0f84c93c":"---\n\n## Visualizer Methods\nThese are some helper functions.","dade6ade":"### Test Predictions\nFinally, let's predict the test set.","43d88861":"We can also plot the most uncertain, and most certain predictions. Ones don't seem to be the problem."}}