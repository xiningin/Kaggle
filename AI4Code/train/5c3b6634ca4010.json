{"cell_type":{"f62ecc05":"code","d9e94574":"code","98bc67b9":"code","24b7ca87":"code","52a1fc9a":"code","1c71a528":"code","29eb79a3":"code","2b98ddd0":"code","a9b133f2":"code","77e03eb6":"code","0e242e84":"code","925d8467":"code","ce760b1c":"code","ebbaf8ac":"code","31b37a88":"code","2c0ff704":"code","c68334b0":"code","56d16c28":"code","0d3febd3":"markdown","84642bee":"markdown","be9e22e1":"markdown","e3805de7":"markdown","cbf9aa2b":"markdown","b14e508c":"markdown","7dc2264f":"markdown"},"source":{"f62ecc05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d9e94574":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler","98bc67b9":"#Read the data\ncust_data = pd.read_csv('..\/input\/CustomerLoanData.csv')","24b7ca87":"#sample the data\ncust_data.head()","52a1fc9a":"#Dimension of Data\ncust_data.shape","1c71a528":"#Column ames of data\ncust_data.columns","29eb79a3":"#Structure of Data\ncust_data.dtypes","2b98ddd0":"#summary of data\ncust_data.describe()","a9b133f2":"trainx,testx,trainy,testy = train_test_split(cust_data.iloc[:,:-1],cust_data.iloc[:,-1],test_size=0.3,random_state=1)\nprint(cust_data.shape)\nprint(trainx.shape)\nprint(testx.shape)","77e03eb6":"cat_cols = [\"edu\",\"securities\",\"cd\",\"online\",\"cc\",\"infoReq\"]\nnum_cols = trainx.columns.difference(cat_cols)\nnum_cols","0e242e84":"trainx[cat_cols] = trainx[cat_cols].apply(lambda x: x.astype('category'))\ntrainx[num_cols] = trainx[num_cols].apply(lambda x: x.astype('float'))\ntrainx.dtypes","925d8467":"trainx.isnull().sum()","ce760b1c":"num_data = trainx.loc[:,num_cols]\ncat_data = trainx.loc[:,cat_cols]","ebbaf8ac":"# Numeric columns imputation\nimp = SimpleImputer(missing_values=np.nan, strategy='mean')\nnum_data = pd.DataFrame(imp.fit_transform(num_data),columns=num_cols)\n\n# Categorical columns imputation\nimp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\ncat_data = pd.DataFrame(imp.fit_transform(cat_data),columns=cat_cols)\n\n\nprint(num_data.isnull().sum())\nprint(cat_data.isnull().sum())","31b37a88":"standardizer = StandardScaler()\nstandardizer.fit(num_data)\nnum_data= pd.DataFrame(standardizer.transform(num_data),columns=num_cols)\n\ntrainx = pd.concat([num_data,cat_data], axis=1)\n","2c0ff704":"bins = [trainx.ccAvg.min(),np.median(trainx.ccAvg),trainx.ccAvg.max()]\ngroup_names = ['low', 'high']\ntrainx['cat_cc'] = pd.cut(trainx['ccAvg'],bins, labels=group_names)\ntrainx.head()","c68334b0":"trainx=pd.get_dummies(trainx,columns=cat_cols.extend(['cat_cc']))","56d16c28":"trainx.head()","0d3febd3":"**2. Train & Test split**","84642bee":"7.Creating Dummies","be9e22e1":"6. Binning","e3805de7":"3.Data tyoe Conversion","cbf9aa2b":"4. Imputation","b14e508c":"1a. Data pre processing - \n\n1. Read the data 'train.csv'\n\n->Split the data into train and test\n\n2. Do the folowing pre processing steps on train:\n-> Find the un wanted columns and remove them from train\n\n-> Identify the column types and convert them appropriately\n\n-> Impute the data\n\n-> Standardize the data\n\n-> Get dummies\n\n\n3. Do the following preprocessing on test data:\n-> Keeping only the required columns\n\n-> Convert the data types\n\n\n-> Impute the data\n\n-> Standardize the data\n\nGet dummies","7dc2264f":"5.Standardization"}}