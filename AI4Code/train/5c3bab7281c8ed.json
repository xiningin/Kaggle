{"cell_type":{"89ccff5c":"code","9f7641a2":"code","163be05a":"code","0f2806a3":"code","6f6dd5df":"code","c833a199":"code","c44b5786":"code","7f70dce1":"code","f54ba220":"code","21c4b82d":"code","054651f6":"code","528a8dad":"code","edc9722d":"code","96558c67":"code","9631040d":"code","133293d6":"code","c3497385":"code","4c978c37":"code","72351bcc":"code","fa888081":"code","da785f53":"code","b7fe6944":"code","29342960":"code","68f32c8e":"code","e348d18b":"code","f97e57af":"code","4f885a0a":"code","0d72159c":"code","60ae76df":"code","6c0d2f79":"code","b550c508":"code","95bf39fd":"code","d6dad075":"code","3d3655b2":"code","4172f271":"code","1b017580":"code","40c3bbcd":"code","6769ebd0":"code","126fe038":"code","576f892b":"code","6d894323":"code","b0e51ad9":"code","e3157e2c":"code","1478077a":"code","8c98cb4b":"code","836ad5c2":"code","a5bd0c4d":"code","3a2ba5aa":"code","d90f97e6":"code","28170da4":"code","6cda2de9":"code","4dd1f0d3":"code","d87868fa":"code","2b50c107":"code","2ccb8c9b":"code","1471b6f9":"code","f50590ec":"code","7bea9a4e":"code","69d8942a":"code","b46ae0f2":"code","1bf5799a":"code","ca616931":"code","053da568":"code","f9b3e968":"code","fbe7b23d":"code","79508350":"code","a3d8264f":"code","277f3847":"code","7f058d8a":"code","50e0da06":"code","6b905ba1":"code","1c25195f":"code","4fd8bde1":"code","f93993ea":"code","d2be396f":"code","bf34d17d":"code","28c358fe":"code","35e3a1cc":"code","2dcc6a3f":"code","05ff6e40":"code","1cd398dc":"code","ec5d6137":"code","5244d8a4":"code","42047030":"code","679e4b9f":"code","e7f6d7fe":"code","b9fb1a6b":"code","81137b26":"code","e1a1978c":"code","7b6ba1e4":"code","dc2f1a21":"code","b0fc6901":"code","c913b5b4":"code","b6da81b2":"code","3c3b35dd":"code","3a4063d6":"code","694895eb":"code","a1905a86":"code","633a3dc6":"code","88334b44":"code","fb3bb5db":"code","15ad9f11":"code","4bd9391e":"code","84346e7c":"code","340417ae":"code","13f856ef":"code","fc2a318c":"code","0240aa8b":"code","6a53e6f1":"code","af2fdcdb":"code","0398bc9b":"code","b97e632e":"code","2b3b99a0":"code","cde9b9a3":"markdown","f03944af":"markdown","3c766a0e":"markdown","4d6a666b":"markdown","a4f107ec":"markdown","ba420a0d":"markdown","ed37f0e6":"markdown","582eeef5":"markdown","255a0e4e":"markdown","656652ac":"markdown","898cf6a3":"markdown","402346a1":"markdown","afae0582":"markdown","1e354d7b":"markdown","afb08fc6":"markdown","9cf13174":"markdown","9cbb06fe":"markdown","a6409147":"markdown","67c97c96":"markdown","79b86714":"markdown","a7a07c01":"markdown","9aa43aef":"markdown","45b5224c":"markdown","4c475b22":"markdown","fbee15a3":"markdown","640e2135":"markdown","46c9c198":"markdown","f959af6e":"markdown","bd0f9d65":"markdown","925a57a9":"markdown","2d3464f8":"markdown","425a06cf":"markdown","15cbad8d":"markdown","52aae049":"markdown","c7328b4e":"markdown","56b1ac13":"markdown","17d97fa3":"markdown","8c20b0ee":"markdown","e9a2a7dc":"markdown","0864fabb":"markdown","958bba1c":"markdown","669ba7f2":"markdown","d8670483":"markdown","ba455ff5":"markdown","779608d9":"markdown","7a01174c":"markdown","35cee425":"markdown","7220999c":"markdown","a55113ad":"markdown","f295de9e":"markdown","b5aa5218":"markdown","df23c2d5":"markdown","89e6d8ac":"markdown","e48ae366":"markdown","db15e544":"markdown","2cc8e1ce":"markdown","978ba1f0":"markdown","132228bf":"markdown","5c4d2cde":"markdown","03bf200d":"markdown","dc11296b":"markdown","5fcbc141":"markdown","9c6697f8":"markdown","b65a36f4":"markdown","edb5090e":"markdown","e8e01e34":"markdown","86b343ac":"markdown","d0a23970":"markdown","3599ebad":"markdown","34255d5a":"markdown","5790209a":"markdown","2147b213":"markdown","c507bd94":"markdown","1b13e305":"markdown","81539856":"markdown","9ce313ae":"markdown","f498a418":"markdown"},"source":{"89ccff5c":"!pip --disable-pip-version-check install sparklines > \/dev\/null","9f7641a2":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os, sys\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.io as pio\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport re\nimport glob\nimport dask.dataframe as dd\nfrom sklearn.preprocessing import MinMaxScaler\nimport datetime\nfrom pandas.tseries.offsets import MonthBegin\nfrom operator import attrgetter\nimport sparklines\nimport base64\nfrom itertools import combinations\nfrom io import BytesIO\nfrom IPython.display import HTML\nfrom plotly.subplots import make_subplots\nfrom warnings import filterwarnings\n\npd.set_option('MAX_ROWS', None)\npd.set_option('MAX_COLUMNS', None)\npd.set_option('display.max_colwidth', None)\npio.templates.default = \"none\"\nfilterwarnings('ignore')","163be05a":"# path of the data\npath = r'\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/'","0f2806a3":"# read the data\ndistricts = pd.read_csv(os.path.join(path, 'districts_info.csv'))","6f6dd5df":"# shape\ndistricts.shape","c833a199":"# data types\ndistricts.dtypes","c44b5786":"# missing values\ndistricts.isnull().mean()","7f70dce1":"# duplicates?\ndistricts.duplicated().sum()","f54ba220":"# change the data type\ndistricts['district_id'] = districts['district_id'].astype(str)","21c4b82d":"# count of districts by State\ndistricts.groupby('state')['district_id'].size().sort_values(ascending=False)","054651f6":"# count of locale\ndistricts['locale'].value_counts(dropna=False)","528a8dad":"# count of percent black\/hispanic students\ndistricts['pct_black\/hispanic'].value_counts(dropna=False)","edc9722d":"# count of percent free\/reduced meals\ndistricts['pct_free\/reduced'].value_counts(dropna=False)","96558c67":"# count of county connections ratio\ndistricts['county_connections_ratio'].value_counts(dropna=False)","9631040d":"# count of per person total expenditure\ndistricts['pp_total_raw'].value_counts(dropna=False)","133293d6":"# number of districts\ndistricts['district_id'].nunique()","c3497385":"def split_range(row):\n    \"\"\"\n    Split the range related features\n    in the Districts dataset, and compute\n    the midpoint\n    \"\"\"\n    if pd.isna(row):\n        return row\n    matched = re.search(r'\\[(.*?),\\s?(.*?)\\[', row)\n    lb = float(matched.group(1))\n    ub = float(matched.group(2))\n    return (lb + ub)\/2","4c978c37":"# create new features\ndistricts['pct_mean_black_hispanic'] = districts['pct_black\/hispanic'].apply(split_range)\ndistricts['pct_mean_free'] = districts['pct_free\/reduced'].apply(split_range)\ndistricts['county_connections_mean_ratio'] = districts['county_connections_ratio'].apply(split_range)\ndistricts['median_pp_total_raw'] = districts['pp_total_raw'].apply(split_range)","72351bcc":"# apply min max scaling due to the wide ranges\nminmax = MinMaxScaler()\ndistricts['scaled_black'] = minmax.fit_transform(districts['pct_mean_black_hispanic'].values.reshape(-1, 1))\ndistricts['scaled_free'] = minmax.fit_transform(districts['pct_mean_free'].values.reshape(-1, 1))\ndistricts['scaled_internet'] = minmax.fit_transform(districts['county_connections_mean_ratio'].values.reshape(-1, 1))\ndistricts['scaled_investment'] = minmax.fit_transform(districts['median_pp_total_raw'].values.reshape(-1, 1))","fa888081":"# check top 5 records\ndistricts.head()","da785f53":"# 5 point summary\ndistricts.describe()","b7fe6944":"# read the products dataset\nproducts = pd.read_csv(os.path.join(path, 'products_info.csv'))","29342960":"# top 5 products\nproducts.head()","68f32c8e":"# number of records\nproducts.shape","e348d18b":"# missing values\nproducts.isnull().mean()","f97e57af":"# data types\nproducts.dtypes","4f885a0a":"# duplicates?\nproducts.duplicated().sum()","0d72159c":"# number of unique URLs\nproducts['URL'].nunique()","60ae76df":"# number of unique Providers\nproducts['Provider\/Company Name'].nunique()","6c0d2f79":"# count of products for top 5 Providers\nproducts['Provider\/Company Name'].value_counts()[:5]","b550c508":"# number of unique sectors\nproducts['Sector(s)'].nunique()","95bf39fd":"# count of top 5 sectors\nproducts['Sector(s)'].value_counts()","d6dad075":"# number of Primary Essential functions\nproducts['Primary Essential Function'].nunique()","3d3655b2":"# count of top 5 Primary Essential functions\nproducts['Primary Essential Function'].value_counts()[:5]","4172f271":"def create_engagement_dataset(path, file='*.csv'):\n    \"\"\"\n    Create engagement dataset\n    \"\"\"\n    all_df = []\n    for f in glob.glob(os.path.join(path, file)):\n        df = pd.read_csv(f, parse_dates=['time'])\n        df['district_id'] = f.split('\/')[-1].split('.')[0]\n        # df['log_engagement_index'] = np.log1p(df['engagement_index'])\n        # df['scaled_access'] = minmax.fit_transform(df['pct_access'].values.reshape(-1, 1))\n        # df['scaled_engagement'] = minmax.fit_transform(df['engagement_index'].values.reshape(-1, 1))\n        df['usage_month'] = df['time'].dt.to_period('M')\n        df['is_pandemic'] = np.where(df['time'] <= datetime.datetime.strptime('2020-07-31', '%Y-%m-%d'), 0, 1)\n        all_df.append(df)\n    return pd.concat(all_df, ignore_index=True)","1b017580":"%%time\neng_path = r'engagement_data'\ndaily_eng_df = create_engagement_dataset(os.path.join(path, eng_path))","40c3bbcd":"# top 5 engagement records\ndaily_eng_df.head()","6769ebd0":"# number of records\ndaily_eng_df.shape","126fe038":"# number of missing\ndaily_eng_df.isnull().mean()","576f892b":"# duplicates?\ndaily_eng_df.duplicated().sum()","6d894323":"# 5 point summary\ndaily_eng_df.describe()","b0e51ad9":"# drop records with no engagement\ndaily_eng_df.dropna(inplace=True)","e3157e2c":"# number of records after removing\n# null engagements\ndaily_eng_df.shape","1478077a":"# merge daily engagement data and products\ndaily_eng_df = daily_eng_df.merge(products, \n            left_on=['lp_id'], right_on=['LP ID'], how='left')","8c98cb4b":"# unique product ids in products but not in engagement data\nlen(set(products['LP ID']).difference(set(daily_eng_df['lp_id'])))","836ad5c2":"# unique product ids in the daily engagement data but not in products\nlen(set(daily_eng_df['lp_id']).difference(set(products['LP ID'])))","a5bd0c4d":"# top 5 engagement and products\ndaily_eng_df.head()","3a2ba5aa":"daily_eng_df['scaled_access'] = minmax.fit_transform(daily_eng_df['pct_access'].values.reshape(-1, 1))\ndaily_eng_df['scaled_engagement'] = minmax.fit_transform(daily_eng_df['engagement_index'].values.reshape(-1, 1))","d90f97e6":"daily_eng_df = daily_eng_df.merge(districts[['district_id', 'state', 'locale']], \n                                 left_on=['district_id'], right_on=['district_id'], how='left')","28170da4":"# %%time\n# # merge daily engagement data and districts\n# dist_cols = ['district_id', 'state', 'locale', 'pct_mean_black_hispanic', 'pct_mean_free', 'county_connections_mean_ratio', 'median_pp_total_raw',\n#                                 'scaled_black', 'scaled_internet', 'scaled_investment', 'scaled_free']\n# daily_eng_df = daily_eng_df.merge(districts[dist_cols], \n#             left_on=['district_id'], right_on=['district_id'], how='left')","6cda2de9":"# unique district ids in districts  but not in engagement data\n# len(set(districts['district_id']).difference(set(daily_eng_df['district_id'])))","4dd1f0d3":"# unique district ids in the daily engagement data but not in districts dataframe\n# len(set(daily_eng_df['district_id']).difference(set(districts['district_id'])))","d87868fa":"# top 5 engagement, products and districts\ndaily_eng_df.head()","2b50c107":"def create_table_bar_chart(df, var, bar_color=None, title=None):\n    \"\"\"\n    Create a tabular bar chart\n    \"\"\"\n    HTML(\n        pd.DataFrame(df[var]\\\n            .value_counts(normalize=True))\\\n            .style\\\n            .format('{:.0%}')\\\n            .set_table_styles([{\n            'selector': 'caption',\n            'props': [\n                ('font-size', '16px')\n            ]\n            }])\\\n          .set_caption(title)\\\n          .set_properties(padding='10px', border='2px solid white')\\\n          .bar(color=bar_color)\n    )","2ccb8c9b":"# create_table_bar_chart(daily_eng_df, 'state', bar_color=bar_color, title='Percentage of recorded engagements by State')\nbar_color = '#FF7F7F'\npd.DataFrame(daily_eng_df['state'].value_counts(normalize=True)).style\\\n                                                              .format('{:.0%}')\\\n                                                              .set_table_styles([{\n                                                                'selector': 'caption',\n                                                                'props': [\n                                                                    ('font-size', '16px')\n                                                                ]\n                                                            }])\\\n                                                             .set_caption('Share of daily engagements by State')\\\n                                                             .set_properties(padding='10px', border='2px solid white')\\\n                                                             .bar(color=bar_color)\n","1471b6f9":"# top 5 districts in terms of number of engagements recorded\npd.DataFrame(daily_eng_df.groupby(['state','district_id']).size())\\\n            .sort_values(0, ascending=False)[:5]\\\n            .rename(columns={0: 'count'})\\\n            .style\\\n             .set_table_styles([{\n                                'selector': 'caption',\n                                'props': [\n                                    ('font-size', '16px')\n                                ]\n                            }])\\\n            .set_caption('Top 5 districts - Number of daily engagements')\\\n            .set_properties(padding='10px', border='2px solid white')\\\n            .bar(color=bar_color)","f50590ec":"# bottom 5 districts in terms of number of engagements recorded\npd.DataFrame(daily_eng_df.groupby(['state','district_id']).size())\\\n            .sort_values(0, ascending=False)[-5:]\\\n            .rename(columns={0: 'count'})\\\n            .style\\\n             .set_table_styles([{\n                                'selector': 'caption',\n                                'props': [\n                                    ('font-size', '16px')\n                                ]\n                            }])\\\n            .set_caption('Bottom 5 districts - Number of daily engagements')\\\n            .set_properties(padding='10px', border='2px solid white')\\\n            .bar(color=bar_color)","7bea9a4e":"# time-series plot of mean monthly engagement_index \noverall_mean_eng_df = daily_eng_df[['time', 'pct_access', 'engagement_index']].copy()\noverall_mean_eng_df.set_index('time', inplace=True)\noverall_mean_eng_df = overall_mean_eng_df.resample('1M').mean()\noverall_mean_eng_df.index = overall_mean_eng_df.index - MonthBegin(1)\nfig = px.line(overall_mean_eng_df, y='engagement_index',\n              title='Mean monthly engagement index across all districts')\nfig.update_xaxes(dtick=\"M1\",\n                 tickformat=\"%b\\n%Y\")\n","69d8942a":"# time-series plot of mean monthly percent access\nfig = px.line(overall_mean_eng_df, y='pct_access',\n              title='Mean monthly percent of access across all districts')\nfig.update_xaxes(dtick=\"M1\",\n                 tickformat=\"%b\\n%Y\")\n","b46ae0f2":"def create_data_for_various_plots(df, field, freq='1D', \n                                eng_cols=None,\n                                agg_var = None, \n                                is_state_level=False,\n                                is_district_level=False,\n                                other_df=None,\n                                ):\n    \"\"\"\n    Create data to plot scatter plot\n    This is to show daily\/monthly engagement\n    \"\"\"\n    if is_state_level:\n        df = df[eng_cols].groupby(['state']).agg(agg_var).reset_index()\n        return df.merge(other_df, left_on=['state'],\n                     right_on=['state'], how='left')\n    else:\n        df = df[eng_cols].groupby(['state', 'district_id']).agg(agg_var).reset_index()\n        return df.merge(other_df, left_on=['state', 'district_id'],\n                     right_on=['state', 'district_id'], how='left')\n#     else:\n#         # daily at the time level\n#         if not is_state_level:\n#             return df.groupby(pd.Grouper(key=field, freq=freq)).mean()\n#         else:\n#             # daily at the state level\n#             df = df[eng_cols].groupby(['time', 'state']).agg(agg_var).reset_index()","1bf5799a":"# aggregate the district-wise characteristtics at the State level\nstates_agg = districts.groupby(['state']).agg({'pct_mean_black_hispanic': np.mean,\n                                               'pct_mean_free': np.mean,\n                                    'county_connections_mean_ratio': np.mean,\n                                    'median_pp_total_raw': np.mean,\n                                    'scaled_black': np.mean,\n                                    'scaled_free': np.mean,\n                                    'scaled_internet': np.mean,\n                                    'scaled_investment': np.mean}).reset_index()","ca616931":"%%time\n# prepare state level engagement data for analysis of state-wise characteristics\ndist_cols = ['state', 'pct_mean_black_hispanic', 'pct_mean_free', 'county_connections_mean_ratio', 'median_pp_total_raw',\n            'scaled_black', 'scaled_free', 'scaled_investment']\neng_cols = ['time', 'state', 'pct_access', 'engagement_index', 'scaled_access', 'scaled_engagement']\nstate_level_data_df = create_data_for_various_plots(daily_eng_df, 'time',\n                                                      eng_cols = eng_cols,\n                                                      agg_var = {'pct_access': np.mean,\n                                                                'engagement_index': np.mean,\n                                                                'scaled_access': np.mean,\n                                                                'scaled_engagement': np.mean},\n                                                      is_state_level=True,\n                                                      other_df=states_agg[dist_cols])","053da568":"%%time\n# prepare district level data for analysis of district-wise characteristics\ndistrict_level_data_df = create_data_for_various_plots(daily_eng_df, 'time',\n                                                      eng_cols = eng_cols + ['district_id'],\n                                                      agg_var = {'pct_access': np.mean,\n                                                                'engagement_index': np.mean,\n                                                                'scaled_access': np.mean,\n                                                                'scaled_engagement': np.mean},\n                                                      is_district_level=True,\n                                                      other_df=districts[dist_cols + ['district_id']],\n                                                      )","f9b3e968":"# aggregate the district features by state and melt the dataframe\n# monthly_state_data_df = state_level_data_df.groupby('state').mean().reset_index()\nstate_level_data_melted_df  = pd.melt(state_level_data_df, id_vars=['state'], value_vars=['scaled_access', 'scaled_engagement', \n                                                             'scaled_black', 'scaled_free', \n                                                             'scaled_investment'], \n            value_name='feature_value', var_name='feature_parameter')\n# sort the dataframe in descending order of mean value for each feature_parameter\nstate_level_data_melted_df = state_level_data_melted_df.groupby(['feature_parameter'])['state', \\\n                                                           'feature_value']\\\n                                                        .apply(lambda x: x.sort_values('feature_value', ascending=False))\\\n                                                        .reset_index()\\\n                                                        .drop(['level_1'], axis=1)\ncols = ['scaled_access', 'scaled_engagement', 'scaled_black',\n       'scaled_free', 'scaled_investment']\n# add column to capture the mean value for each parameter\nfor col in cols:\n    mean_col_value = state_level_data_melted_df.query(f'feature_parameter == \"{col}\"')['feature_value'].mean()\n    \n    subset_df = state_level_data_melted_df.query(f'feature_parameter == \"{col}\"')\n    idx = subset_df['feature_value'].apply(lambda x: 'Above mean' if x > mean_col_value else 'Below mean').index\n    state_level_data_melted_df.loc[idx, 'color'] = subset_df['feature_value'].apply(lambda x: 'Above mean' if x > mean_col_value else 'Below mean')\n# rename the feature_parameter\nmap_labels = {\n    'scaled_access': 'Percent access of at least one page load event',\n    'scaled_engagement': 'Page load events per 1000 students',\n    'scaled_black': 'Percent of reported Hispanic\/Black students',\n    'scaled_free': 'Percent of free\/reduced price meal',\n    'scaled_investment': 'Median per pupil expenditure'\n}\nstate_level_data_melted_df['new_feature_parameter'] = state_level_data_melted_df['feature_parameter'].replace(map_labels)","fbe7b23d":"def make_subplots_for_bar_charts(df, series,\n                  colors=['rgb(255, 0, 0)', '#2ca02c'],\n                  title=None\n                 ):\n    \"\"\"\n    Helper function to plot scatter charts using subplots\n    \"\"\"\n    fig = px.bar(df, x=series, y='feature_value', facet_col='new_feature_parameter', facet_col_wrap=2, \n                facet_row_spacing=0.3, facet_col_spacing=0.1, height=1200, width=900, color='color', \n                 color_discrete_map={'Above mean': colors[1],\n                                    'Below mean': colors[0]})\n    fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n    fig.layout.xaxis2.update(matches=None)\n    fig.update_xaxes(matches=None, showticklabels=True)\n    fig.update_yaxes(matches=None, showticklabels=True)\n    fig.update_yaxes(visible=False, showticklabels=False)\n    fig.update_layout(showlegend=False, title=title)\n    for axis in fig.layout:\n        if type(fig.layout[axis]) == go.layout.YAxis:\n            fig.layout[axis].title.text = ''\n        if type(fig.layout[axis]) == go.layout.XAxis:\n            fig.layout[axis].title.text = ''\n    fig.show()","79508350":"make_subplots_for_bar_charts(state_level_data_melted_df, 'state',\n                             title='Bar charts displaying district features by State'\n                 )","a3d8264f":"cols_compare = ['pct_access', 'engagement_index', 'pct_mean_black_hispanic',\n               'pct_mean_free', 'median_pp_total_raw', 'county_connections_mean_ratio']\ndist_corr = district_level_data_df[cols_compare].corr()\nN = len(dist_corr.columns)\nX = dist_corr.columns.tolist()\nmask = np.zeros_like(dist_corr, dtype = np.bool)\nmask[np.triu_indices_from(mask)] = True\ndist_corr=dist_corr.mask(mask)\nhovertext = [[f'corr({X[i]}, {X[j]}) = {dist_corr.values[i][j]:.0%}' if i > j else '' for j in range(N)] for i in range(N)]\nheat = go.Heatmap(z=dist_corr,\n                  x=X,\n                  y=X,\n                  xgap=1, ygap=1,\n                  colorscale='rdylgn',\n                  colorbar_thickness=20,\n                  colorbar_ticklen=3,\n                  hovertext=hovertext,\n                  hoverinfo='text'\n                   )\n\n\ntitle = 'Correlation plot for district level features'               \n\nlayout = go.Layout(title_text=title, title_x=0.5, \n                   width=800, height=800,\n                   xaxis_showgrid=False,\n                   yaxis_showgrid=False,\n                   yaxis_automargin=True,\n                   xaxis_automargin=True,\n                   yaxis_autorange='reversed')\n   \nfig=go.Figure(data=[heat], layout=layout)        \nfig.show() ","277f3847":"def create_parallel_coord(df, states):\n\n    fig = go.Figure(data=\n                    go.Parcoords(\n                    line = dict(color=df['district_id'],\n                              colorscale = [[0,'purple'],[0.5,'lightseagreen'],[1,'gold']]),\n                    dimensions = list([\n                        dict(\n                                label = 'Districts', values = df['district_id']),\n                        dict(range = [0, 1],\n                                label = 'Black\/Hispanic', values = df['scaled_black']),\n                        dict(range = [0, 1],\n                                label = 'Discounted meal', values = df['scaled_free']),\n#                         dict(range = [0, .2],\n#                                 label = 'Internet', values = df['scaled_internet']),\n                        dict(range = [0, 1],\n                                constraintrange = [0, .5], \n                                label = 'Investment', values = df['scaled_investment']),\n                        dict(range = [0, .2],\n                                label = 'Access', values = df['scaled_access']),\n                        dict(range = [0, .007],\n                                label = 'Engagement', values = df['scaled_engagement']),\n\n                    ])\n        )\n    )\n\n\n    fig.update_layout(title=f'Relationship between the district features in the state of {state}')\n    fig.show()","7f058d8a":"state = 'New York'\ndistrict_level_data_df['district_id'] = district_level_data_df['district_id'].astype('int32')\ncreate_parallel_coord(district_level_data_df.query(f'state == \"{state}\"'), state)","50e0da06":"state = 'District Of Columbia'\ncreate_parallel_coord(district_level_data_df.query(f'state == \"{state}\"'), state)","6b905ba1":"state = 'Michigan'\ncreate_parallel_coord(district_level_data_df.query(f'state == \"{state}\"'), state)","1c25195f":"state = 'Texas'\ncreate_parallel_coord(district_level_data_df.query(f'state == \"{state}\"'), state)","4fd8bde1":"def data_for_sparkline(df, grp_var, time_var, max_time='2020-12',\n                              min_time='2020-01',\n                              agg_var=None,\n                              is_state=False,\n                              is_district=False,\n                              is_product=False, \n                              is_product_eng=False,\n                              is_product_combo=False,\n                              is_product_combo_eng=False,\n                              is_multi_level=False, \n                              cust_sparkline=True):\n    \"\"\"\n    Create data for sparkline\n    \"\"\"\n    tmp_df = df.copy()\n    if is_state:\n        g = tmp_df.groupby(grp_var).agg({agg_var: np.sum,})\n        g = g.groupby(level=[0]).apply(lambda x: x\/x.sum()).reset_index()\n    elif is_district:\n        g = tmp_df.groupby(grp_var).agg({agg_var: np.sum,})\n        g = g.groupby(level=[0, 1]).apply(lambda x: x\/x.sum()).reset_index()\n    elif is_product:\n        g = tmp_df.groupby(grp_var).size()\n        if is_multi_level:\n            g = g.groupby(level=[0, 1]).apply(lambda x: x\/x.sum()).reset_index().rename(columns={0: 'usage_value'})\n        else:\n            g = g.groupby(level=[0]).apply(lambda x: x\/x.sum()).reset_index().rename(columns={0: 'usage_value'})\n    elif is_product_eng:\n        g = tmp_df.groupby(grp_var).agg({agg_var: np.sum,})\n        if is_multi_level:\n            g = g.groupby(level=[0, 1]).apply(lambda x: x\/x.sum()).reset_index().rename(columns={0: 'usage_value'})\n        else:\n            g = g.groupby(level=[0]).apply(lambda x: x\/x.sum()).reset_index().rename(columns={0: 'usage_value'})\n    elif is_product_combo:\n        g = tmp_df.groupby(grp_var).size()\n        if is_multi_level:\n            g = g.groupby(level=[0, 1, 2]).apply(lambda x: x\/x.sum()).reset_index().rename(columns={0: 'usage_value'})\n        else:\n            g = g.groupby(level=[0, 1]).apply(lambda x: x\/x.sum()).reset_index().rename(columns={0: 'usage_value'})\n    elif is_product_combo_eng:\n        g = tmp_df.groupby(grp_var).agg({agg_var: np.sum,})\n        if is_multi_level:\n            g = g.groupby(level=[0, 1, 2]).apply(lambda x: x\/x.sum()).reset_index().rename(columns={0: 'usage_value'})\n        else:\n            g = g.groupby(level=[0, 1]).apply(lambda x: x\/x.sum()).reset_index().rename(columns={0: 'usage_value'})\n    \n    # grp_mean = g.iloc[:, -1].mean() # compute mean for the last column\n    g['usage_month'] = g['usage_month'].astype(str)\n    g = g.pivot_table(index=grp_var[:-1], columns='usage_month', fill_value=0)\n    g.columns = g.columns.droplevel() # drop usage_value\n    g = g.rename_axis(None, axis=1) # remove usage_month\n    if cust_sparkline:\n        g['trend'] = g.apply(custom_sparkline, axis=1)\n    else:\n        g['trend'] = g.apply(lambda x: sparklines.sparklines(x)[0], axis=1)\n    g['growth'] = np.round((g[max_time] \/ g[min_time]) ** (1\/12) - 1, 2)\n    g['growth'] = g['growth'].replace(np.inf, 0).replace(np.nan, 0)\n    return g","f93993ea":"def highlight_table(row, threshold=.05):\n    \"\"\"\n    Helper function to highlight cells\n    in a Pandas dataframe\n    \"\"\"\n    if isinstance(row[0], str): return\n    return [\n        'background-color: #FF7F7F; color: white' if cell <= threshold\n        else 'background-color: green; color: white'\n        for cell in row\n    ]","d2be396f":"def custom_sparkline(data, figsize=(3, 0.25), **kwags):\n    \"\"\"\n    Create a sparkline chart\n    https:\/\/github.com\/iiSeymour\/sparkline-nb\/blob\/master\/sparkline-nb.ipynb\n    \"\"\"\n    data = list(data)\n    fig, ax = plt.subplots(1, 1, figsize=figsize, **kwags)\n    ax.plot(data)\n    for k, v in ax.spines.items():\n        v.set_visible(False)\n    \n    ax.set_xticks([])\n    ax.set_yticks([])\n    \n    plt.plot(len(data)-1, data[len(data)-1], 'r.', linewidth=2)\n    \n    # ax.fill_between(range(len(data)), data, len(data)*[min(data)], alpha=0.1)\n    \n    img = BytesIO()\n    plt.savefig(img, transparent=True, dpi=100, bbox_inches='tight')\n    # img.seek(0)\n    plt.close()\n    \n    return f'<img src=\"data:image\/png;base64,{base64.b64encode(img.getvalue()).decode()}\"\/>'\n    # return display(HTML(df.to_html(escape=False))","bf34d17d":"%%time\n# subset the daily engagement data to analyze the month on month\n# mean engagement at state level\ntmp_df = daily_eng_df[['state', 'district_id', 'usage_month', 'scaled_engagement', 'scaled_access']].copy()\nstate_wise_mom_engagement_growth = data_for_sparkline(tmp_df, ['state', 'usage_month'], 'time', max_time='2020-12',\n                              min_time='2020-01',\n                              agg_var='scaled_engagement',\n                              is_state=True,\n                              cust_sparkline=False)","28c358fe":"# mean_eng_threshold = daily_eng_df.groupby(['state'.mean()\ngrad_cols = state_wise_mom_engagement_growth.columns.drop(['trend', 'growth']).tolist()\nstate_wise_mom_engagement_growth.sort_values(['growth', 'state'], ascending=[False, True], kind='mergesort').style\\\n                                            .format('{:.1%}', subset=['growth'])\\\n                                            .format('{:.1%}', subset=state_wise_mom_engagement_growth.columns.drop(['trend', 'growth']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in engagement index by State')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n  #                                          .apply(highlight_table, args=(state_eng_mean, ), axis=0)\\","35e3a1cc":"%%time\n# subset the daily engagement data to analyze the month on month\n# mean engagement\nstate_wise_mom_pct_access_growth = data_for_sparkline(tmp_df, ['state', 'usage_month'], 'time', max_time='2020-12',\n                              min_time='2020-01',\n                              agg_var='scaled_access',\n                              is_state=True,\n                              cust_sparkline=False)","2dcc6a3f":"# mean_access_threshold = daily_eng_df['scaled_access'].mean()\nstate_wise_mom_pct_access_growth.sort_values(['growth', 'state'], ascending=[False, True], kind='mergesort').style\\\n                                            .format('{:.1%}', subset=['growth'])\\\n                                            .format('{:.1%}', subset=state_wise_mom_pct_access_growth.columns.drop(['trend', 'growth']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in percentage of access by State')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n #                                           .apply(highlight_table, args=(state_eng_mean, ), axis=0)","05ff6e40":"%%time\n# subset the daily engagement data to analyze the month on month\n# mean engagement at state level\ndistrict_wise_mom_engagement_growth = data_for_sparkline(tmp_df, ['state', 'district_id', 'usage_month'], 'time', max_time='2020-12',\n                              min_time='2020-01',\n                              agg_var='scaled_engagement',\n                              is_district=True,\n                              cust_sparkline=False)","1cd398dc":"# mean_eng_threshold = daily_eng_df['scaled_engagement'].mean()\ndistrict_wise_mom_engagement_growth.sort_values(['growth', 'state'], ascending=[False, True], kind='mergesort')[:10].style\\\n                                            .format('{:.1%}', subset=['growth'])\\\n                                            .format('{:.1%}', subset=district_wise_mom_engagement_growth.columns.drop(['trend', 'growth']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in engagement index of top 10 Districts')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n #                                           .apply(highlight_table, args=(mean_dist_eng, ), axis=0)","ec5d6137":"district_wise_mom_engagement_growth.sort_values(['growth', 'state'], ascending=[False, True], kind='mergesort')[-10:].style\\\n                                            .format('{:.1%}', subset=['growth'])\\\n                                            .format('{:.1%}', subset=district_wise_mom_engagement_growth.columns.drop(['trend', 'growth']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in engagement index of bottom 10 Districts')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n #                                           .apply(highlight_table, args=(mean_dist_eng, ), axis=0)","5244d8a4":"# filter the null values in the LP ID and state level\nlp_daily_eng_df = daily_eng_df[(daily_eng_df['LP ID'].notnull()) & (daily_eng_df['state'].notnull())].reset_index(drop=True)","42047030":"lp_daily_eng_df.shape","679e4b9f":"lp_daily_eng_df.isnull().mean()","e7f6d7fe":"monthly_product_usage = lp_daily_eng_df.groupby(['time'])['LP ID'].size()\n#monthly_product_usage.set_index('time', inplace=True)\nmonthly_product_usage = monthly_product_usage.resample('1M').sum() \/ monthly_product_usage.sum()\nmonthly_product_usage.index = monthly_product_usage.index - MonthBegin(1)","b9fb1a6b":"# plot the monthly share of product usage\nfig = px.line(monthly_product_usage, y='LP ID', title='Monthly frequency of product usage', \n       )\nmax_yaxis = monthly_product_usage.max()\nfig.update_yaxes(tickformat=\".0%\",\n                range=[0, np.round(max_yaxis, 2)],\n                )\nfig.update_xaxes(dtick=\"M1\",\n                 tickformat=\"%b\\n%Y\")","81137b26":"# distribution before removal of missing product_id and state\ndaily_eng_df['Product Name'].value_counts(normalize=True)[:10]","e1a1978c":"pd.DataFrame(lp_daily_eng_df['Product Name']\\\n            .value_counts(normalize=True))[:10]\\\n            .style\\\n            .format('{:.0%}')\\\n            .set_table_styles([{\n                'selector': 'caption',\n                'props': [\n                    ('font-size', '16px')\n                ]\n             }])\\\n            .set_caption('Share of top 10 daily used products')\\\n            .set_properties(padding='10px', border='2px solid white')\\\n            .bar(color=bar_color)","7b6ba1e4":"pd.DataFrame(lp_daily_eng_df['Provider\/Company Name']\\\n            .value_counts(normalize=True))[:10]\\\n            .style\\\n            .format('{:.0%}')\\\n            .set_table_styles([{\n                'selector': 'caption',\n                'props': [\n                    ('font-size', '16px')\n                ]\n             }])\\\n            .set_caption('Share of top 10 Provider\/Company Name')\\\n            .set_properties(padding='10px', border='2px solid white')\\\n            .bar(color=bar_color)","dc2f1a21":"pd.DataFrame(lp_daily_eng_df['Sector(s)']\\\n            .value_counts(normalize=True))[-10:]\\\n            .style\\\n            .format('{:.0%}')\\\n            .set_table_styles([{\n                'selector': 'caption',\n                'props': [\n                    ('font-size', '16px')\n                ]\n             }])\\\n            .set_caption('Share of Sector(s)')\\\n            .set_properties(padding='10px', border='2px solid white')\\\n            .bar(color=bar_color)","b0fc6901":"pd.DataFrame(lp_daily_eng_df['Primary Essential Function']\\\n            .value_counts(normalize=True))[:10]\\\n            .style\\\n            .format('{:.0%}')\\\n            .set_table_styles([{\n                'selector': 'caption',\n                'props': [\n                    ('font-size', '16px')\n                ]\n             }])\\\n            .set_caption('Share of top 10 Primary Essential Function')\\\n            .set_properties(padding='10px', border='2px solid white')\\\n            .bar(color=bar_color)","c913b5b4":"%%time\nproduct_usage_df = data_for_sparkline(lp_daily_eng_df, ['Product Name', 'usage_month'], 'time', max_time='2020-12',\n                              min_time='2020-01',\n                              is_product=True,\n                              is_multi_level=False,\n                              cust_sparkline=False)","b6da81b2":"product_usage_df.sort_values(['growth', 'Product Name'], ascending=[False, True], kind='mergesort')[:10].style\\\n                                            .format('{:.1%}', subset=product_usage_df.columns.drop(['trend']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in frequency of usage of top 10 products')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n#                                            .apply(highlight_table, args=(mean_prod_state_usage,))","3c3b35dd":"product_usage_df[product_usage_df.index.str.contains('Google')].sort_values(['growth', 'Product Name'], ascending=[False, True], kind='mergesort')[:20].style\\\n                                            .format('{:.1%}', subset=product_usage_df.columns.drop(['trend']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in frequency of usage of top 20 Google products')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n#                                            .apply(highlight_table, args=(mean_prod_state_usage,))","3a4063d6":"product_usage_df.sort_values(['growth', 'Product Name'], ascending=[False, True], kind='mergesort')[-10:].style\\\n                                            .format('{:.1%}', subset=product_usage_df.columns.drop(['trend']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in frequency of usage of bottom 10 products')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)","694895eb":"%%time\nproduct_eng_usage_df = data_for_sparkline(lp_daily_eng_df, ['Product Name', 'usage_month'], 'time', max_time='2020-12',\n                              min_time='2020-01',\n                              agg_var='engagement_index',\n                              is_product_eng=True,\n                              is_multi_level=False,\n                              cust_sparkline=False)","a1905a86":"product_eng_usage_df.sort_values(['growth', 'Product Name'], ascending=[False, True], kind='mergesort')[:10].style\\\n                                            .format('{:.1%}', subset=product_eng_usage_df.columns.drop(['trend']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in engagement of top 10 products')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n#                                            .apply(highlight_table, args=(mean_prod_state_usage,))","633a3dc6":"product_eng_usage_df[product_eng_usage_df.index.str.contains('Google')].sort_values(['growth', 'Product Name'], ascending=[False, True], kind='mergesort')[:20].style\\\n                                            .format('{:.1%}', subset=product_eng_usage_df.columns.drop(['trend']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in engagement of top 20 Google products')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n#                                            .apply(highlight_table, args=(mean_prod_state_usage,))","88334b44":"%%time\nproduct_usage_state_wise_time_df = data_for_sparkline(lp_daily_eng_df, ['state', 'Product Name', 'usage_month'], 'time', max_time='2020-12',\n                              min_time='2020-01',\n                              is_product_combo=True,\n                              is_multi_level=False,\n                              cust_sparkline=False)","fb3bb5db":"product_usage_state_wise_time_df.sort_values(['growth', 'state'], ascending=[False, True], kind='mergesort')[:10].style\\\n                                            .format('{:.1%}', subset=product_usage_state_wise_time_df.columns.drop(['trend']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in frequency of usage of top 10 States and their products used')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n#                                            .apply(highlight_table, args=(mean_prod_dist_usage,))","15ad9f11":"%%time\nproduct_usage_eng_state_wise_time_df = data_for_sparkline(lp_daily_eng_df, ['state', 'Product Name', 'usage_month'], 'time', max_time='2020-12',\n                              min_time='2020-01',\n                              agg_var='engagement_index',\n                              is_product_combo_eng=True,\n                              is_multi_level=False,\n                              cust_sparkline=False)","4bd9391e":"product_usage_eng_state_wise_time_df.sort_values(['growth', 'state'], ascending=[False, True], kind='mergesort')[:10].style\\\n                                            .format('{:.1%}', subset=product_usage_eng_state_wise_time_df.columns.drop(['trend']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in engagement of top 10 States and their products used')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n#                                            .apply(highlight_table, args=(mean_prod_dist_usage,))","84346e7c":"google_products = ['Google Docs', 'Google Sheets', 'Google Forms', 'Google Drive', 'Google Classroom']\nproduct_usage_eng_state_wise_time_df.query('`Product Name` == @google_products').sort_values(['growth', 'Product Name'], ascending=[False, True])[:10].style\\\n                                            .format('{:.1%}', subset=product_usage_eng_state_wise_time_df.columns.drop(['trend']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in engagement of top 5 Google products by States')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n#                                            .apply(highlight_table, args=(mean_prod_dist_usage,))","340417ae":"# add this line to the State health card\nmost_preferred_product_statewise = product_usage_eng_state_wise_time_df.reset_index().groupby('state').apply(lambda x: x.nlargest(1, ['growth']))[['state', 'Product Name', 'growth']]\nmost_preferred_product_statewise = most_preferred_product_statewise.rename(columns={'state': 'dummy'}).reset_index(drop=True).rename(columns={'dummy': 'state'})","13f856ef":"%%time\nprimary_func_usage_df = data_for_sparkline(lp_daily_eng_df, ['Primary Essential Function', 'usage_month'], 'time', max_time='2020-12',\n                              min_time='2020-01',\n                              agg_var='engagement_index',\n                              is_product_eng=True,\n                              is_multi_level=False,\n                              cust_sparkline=False)","fc2a318c":"primary_func_usage_df.sort_values(['growth', 'Primary Essential Function'], ascending=[False, True], kind='mergesort')[:10].style\\\n                                            .format('{:.1%}', subset=primary_func_usage_df.columns.drop(['trend']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in engagement of top 10 essential functions')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n#                                            .apply(highlight_table, args=(mean_prod_state_usage,))","0240aa8b":"%%time\nprimary_func_eng_usage_df = data_for_sparkline(lp_daily_eng_df, ['state', 'Primary Essential Function', 'usage_month'], 'time', max_time='2020-12',\n                              min_time='2020-01',\n                              agg_var='engagement_index',\n                              is_product_combo_eng=True,\n                              is_multi_level=False,\n                              cust_sparkline=False)","6a53e6f1":"primary_func_eng_usage_df.sort_values(['growth', 'Primary Essential Function'], ascending=[False, True], kind='mergesort')[:10].style\\\n                                            .format('{:.1%}', subset=primary_func_eng_usage_df.columns.drop(['trend']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in engagement of top 10 States and their preferred primary essential function')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n#                                            .apply(highlight_table, args=(mean_prod_state_usage,))","af2fdcdb":"primary_func_eng_usage_df.query('`Primary Essential Function` == \"LC - Sites, Resources & Reference - Streaming Services\"')\\\n                                            .sort_values(['growth', 'Primary Essential Function'], ascending=[False, True], kind='mergesort')[:10].style\\\n                                            .format('{:.1%}', subset=primary_func_eng_usage_df.columns.drop(['trend']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in engagement of top 10 States and their use of LC - Sites, Resources & References - Streaming Services')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n#                                            .apply(highlight_table, args=(mean_prod_state_usage,))","0398bc9b":"primary_func_eng_usage_df.query('`Primary Essential Function` == \"SDO - Learning Management Systems (LMS)\"')\\\n                                            .sort_values(['growth', 'Primary Essential Function'], ascending=[False, True], kind='mergesort')[:10].style\\\n                                            .format('{:.1%}', subset=primary_func_eng_usage_df.columns.drop(['trend']))\\\n                                            .set_table_styles([{\n                                                'selector': 'caption',\n                                                'props': [\n                                                    ('font-size', '16px')\n                                                ]\n                                            }])\\\n                                            .set_caption('Share in engagement of top 10 States and their use of SDO - Learning Management Systems (LMS)')\\\n                                            .set_properties(padding='10px', border='2px solid white')\\\n                                            .background_gradient(cmap='RdYlGn', subset=grad_cols, axis=1)\\\n                                            .background_gradient(cmap='RdYlGn', subset=['growth'], axis=0)\n#                                            .apply(highlight_table, args=(mean_prod_state_usage,))","b97e632e":"def prepare_report_card(df, merge_df, states_agg_df, best_prod_df):\n    \"\"\"\n    Prepare a summary report card\n    showing how each State performed\n    # create a report card for the states\n    # calculate the count of districts by state\n    # calculate the count of healthy districts\n    # calculate proportion of healthy districts\n    # merge dataframe to capture monthly engagement growth\n    # merge dataframe to capture district features\n    \"\"\"\n\n    tmp_report_card = df.loc[:, 'growth'].reset_index().copy()\n    tmp_report_card['total_healthy'] = tmp_report_card['growth'].apply(lambda x: 1 if x > 0 else 0)\n    state_report_card = pd.DataFrame(tmp_report_card.groupby('state').size()).merge(pd.DataFrame(tmp_report_card.groupby('state')['total_healthy'].sum()), left_index=True, \n                                                          right_index=True).reset_index().rename(columns={0: 'total_districts'})\n    state_report_card['percent_healthy'] = state_report_card['total_healthy'] \/ state_report_card['total_districts']\n    state_report_card = state_report_card.merge(merge_df.loc[:, 'growth'], left_on='state', right_index=True)\n    \n    dist_cols = ['state', 'pct_mean_black_hispanic', 'pct_mean_free', 'county_connections_mean_ratio', 'median_pp_total_raw']\n\n    state_report_card = state_report_card.merge(states_agg_df[dist_cols], left_on='state', right_on='state')\n    state_report_card = state_report_card.reindex(columns=dist_cols + ['total_districts', 'total_healthy', 'percent_healthy', 'growth'])\n    state_report_card.rename(columns={'growth': 'monthly_engagement_growth_rate'}, inplace=True)\n    \n#     state_report_card = state_report_card.merge(prod_df.loc[:, 'growth'], left_on='state', right_index=True)\n#     state_report_card = state_report_card.rename(columns={'growth': 'monthly_product_usage_growth_rate'})\n    state_report_card = state_report_card.merge(best_prod_df, left_on='state', right_on='state')\n    state_report_card.rename(columns={'Product Name': 'preferred_product', \n                                     'growth': 'monthly_product_engagement_rate'}, inplace=True)\n    state_report_card = state_report_card.reindex(columns=dist_cols + ['total_districts', 'total_healthy', 'percent_healthy', \n                                                                       'preferred_product',\n                                                                       'monthly_product_engagement_rate',\n                                                                       'monthly_engagement_growth_rate'])\n    return state_report_card","2b3b99a0":"state_report_card = prepare_report_card(district_wise_mom_engagement_growth,\n                                       state_wise_mom_engagement_growth,\n                                       states_agg,\n                                       most_preferred_product_statewise)\nstate_report_card\\\n            .sort_values('monthly_engagement_growth_rate', ascending=False)\\\n            .set_index('state')\\\n            .style\\\n            .format('{:.1%}', subset=['pct_mean_black_hispanic', 'pct_mean_free', \n                                      'percent_healthy', 'monthly_engagement_growth_rate',\n                                     'monthly_product_engagement_rate'])\\\n            .format('{:.0f}', subset=['median_pp_total_raw'])\\\n            .set_table_styles([{\n                                'selector': 'caption',\n                                'props': [\n                                    ('font-size', '16px')\n                                ]\n                            }])\\\n            .set_caption('State health report card, Jan 2020 - Dec 2020')\\\n            .set_properties(padding='10px', border='2px solid white')\\\n            .bar(align='mid', color=bar_color)","cde9b9a3":"1) Weak performing districts can learn from their stronger counterparts in that State to find out what they did differently that helped them navigate the pandemic relatively better.\n\n2) Teachers should be financially incentivised to upskill.\n\n3) Teachers should divide the classroom into teams, and organize online quizzes, brainstorming sessions using various online tools, etc. Teachers should leverage the help of highly motivated students\nto help support the slow learners. Such students should be rewarded via the school's grading system.\n\n4) Local companies should support such schools by orgnanising online hackathons with attractive prizes to encourage student participation.","f03944af":"## Problem Statement\n\nThe COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States. In the Spring of 2020, most states and local governments across the U.S. closed educational institutions to stop the spread of the virus. In response, schools and teachers have attempted to reach students remotely through distance learning tools and digital platforms. Until today, concerns of the exacaberting digital divide and long-term learning loss among America\u2019s most vulnerable learners continue to grow.","3c766a0e":"**What do we observe**\n\n1) With respect to the mean monthly `engagement_index` for Google products. Some of the products such as Google Sheets, Google Docs and Google Forms have seen a postive growth rate. However, this hasn't been\nuniform throughout the year.","4d6a666b":"## State-wise characteristics\n\nAnalyse the state and district-wise characteristics","a4f107ec":"### Share in engagement index of best products","ba420a0d":"## Top 10 Primary Essential Function","ed37f0e6":"### Preprocessing of Districts","582eeef5":"<a id=correlation_matrix><\/a>","255a0e4e":"**Districts**\n\n\n1) There are 233 districts across 23 States in the Districts dataset.\n\n2) Connecticut has the maximum number of districts - 30. There is a non uniform distribution of districts across States.\n\n3) Except for the `distirct_id`, there is data missing across the other features, which ranges from 24% (`state`, `locale`) to 49% (`pp_total_raw`). \n\n4) The other features describe the percentage of black\/hispanic, free\/reduced meals, `county_connections_ratio` and total expenditure per person at\na district level. These values are provided as ranges.\n\n5) After taking the midpoint from the ranged values, we can see that the `pct_mean_black_hispanic` and `pct_mean_free` fields range from 10% - 90%.\n\n6) The Internet connection represented by `county_connections_mean_ratio` doesn't show much variation; it is mostly at a ratio of 0.59, which an exception at 1.5.\n\n7) Investment - `median_pp_total_raw` ranges from \\\\$5000 - \\\\$33,000, with a mean of ~\\\\$12,400.\n\n**Products**\n\n1) There are 372 products in use.\n\n2) There are 290 `Provider\/Company Name` offering their services across 5 `Sectors`.\n\n3) There are 35 `Primary Essential Function` provided by these companies; the most common\nfunction is LC - Digital Learning Platforms.\n\n**Engagement**\n\n1) There are approximately ~ 22 million engagements for the entire period from 2020-01-01 to 2020-12-31.\n\n2) 24% of the `engagement_index` is missing, and a very small fraction of `lp_id` product_ids are missing.\n\n3) The `pct_access` ranges from 0% - 100%, and the `engagement_index` varies from 100 - 213K.","656652ac":"**What do we observe**\n\n1) The 2 reported districts appear to have very low `pct_access` and `engagement_index` values during the year.","898cf6a3":"## Potential solutions","402346a1":"## Districts","afae0582":"**What do we observe**\n\n1) Mostly Google related products appear to be frequently used by the students. However its share is very small. Additionally, all the top 10 products\nhave similar shares.","1e354d7b":"**What do we observe**\n\n1) This makes sense given that most teachers in their schools would have spent time conducting live classrooms.\n\n2) Some States such as Michigan, Illinois, Florida, California and Massachusetts saw relatively lower usage right after school closures. Most of their engagement happened during the last 4 months in that year. This is unlike that observed in States such as Wisconsin, Connecticut, New York, Indiana, and New Jersey that showed relatively better engagement right after school closure.","afb08fc6":"## References","9cf13174":"**What do we observe**\n\n1) New York (NY) shows engagement with Google Sheets and Google Docs for most part of the year except for sometime in January and during months of June and July. A similar pattern is noted for Wisoncnin with Google Classroom.\n\n2) For States such as Michigan, Tennessee, their usage of the products occurred mostly during the last 4 months of the year.","9cbb06fe":"[EdWeek](https:\/\/www.edweek.org\/leadership\/the-coronavirus-spring-the-historic-closing-of-u-s-schools-a-timeline\/2020\/07)\n\n[Correlation Plot](https:\/\/community.plotly.com\/t\/correlation-plot-with-mask\/29185)\n\n[Subplots](https:\/\/plotly.com\/python\/subplots\/)\n\n[Bar Color Change](https:\/\/community.plotly.com\/t\/plotly-express-bar-colour-change\/36210)\n\n[Pandas Sort](https:\/\/realpython.com\/pandas-sort-python\/)","a6409147":"## State report card","67c97c96":"### Percent access growth rate of at least one page load event - State level","79b86714":"<a id=top10_freq_prod_usage><\/a>","a7a07c01":"**What do we observe**\n\n1) The top 3 States with the highest growth rate of students having accessed at least one page load event, are: New York (7%), District Of Columbia (6%) and Michigan (4%). However, we can see with the State of DC, the `pct_access` was relatively lower in the first half, excluding June and July, compared to its peers.\n\n2) The other States display some healthy access activity during the first quarter before waning during the second and third quarter.","9aa43aef":"## Top 10 products used","45b5224c":"**What do we observe**\n\n1) Google Docs, Google Drive, Google Classrooms and Google Forms that appeared to have a higher share in terms of frequency of usage actually have had no change in growth in the last 12 months. However, what is worth noting is that\ntheir monthly usage rate has been mostly uniform unlike Microsoft Office 365 and Pandora which saw a spike in usage  rates only in the last 4 months, which explains the very high growth rate.","4c475b22":"## Summary","fbee15a3":"**How is the data prepared**\n\n1) Each row sums to 100%; it represents the share of `engagement_index` for a State during the period from Jan-Dec.\n\n2) The mean monthly `engagement_index` growth is computed using the formula - Growth rate = (Present value \/ Past value) 1\/N - 1 for N=12.\n\n3) The gradient color scheme automatically highlights the cells depending on the size of the value.\n\n**What do we observe**\n\n1) Schools were on the learning platform before the pandemic as evidenced by the engagement numbers in the first quarter. However, their share of `engagement_index`was relatively lower.\n\n2) District Of Columbia (DC) has the highest `engagement_index` growth rate of 15%, closely followed by New York at 14%. It must be noted though that, looking at the humps in the trend graph, most of DCs growth came in the last 4 months.\n\n3) While some States couldn't deal with the stress induced by the pandemic, other States such as New York, Illinois, and Connecticut, to name a few, showed positive signs of engagement, but all States eventually succumbed between the 2nd and 3rd quarter.\n\n4) Most States showed some uptick in engagement rates towards the last quarter as shown in the positive growth rates.\n\n5) States such as Minnesota and North Dakota had among the lowest engagement growth rates.\n","640e2135":"**What do we observe**\n\n1) New York and District Of Columbia are comparable in terms of similar median expendiure per pupil. However, District Of Columbia has a relatively better district health, and a comparable monthly engagement growth rate compared with New York.\n\n2) In terms of having a high percentage of Black\/Hispanic students, the top 2 States are:a) District Of Columbia and b) Arizona at 77% and 90%, each, respectively.\n\n3) With respect to offering free\/reduced price meals, the highest percentage of students come from the following States: Michigan, Florida, Indiana, and Minnesota. Of these, Michigan has a relatively better monthly engagement growth rate. However, all of these States have done a reasonable job in ensuring their districts showed reasonably healthy engagement.\n\n4) Connecticut and Utah have the highest number of districts. However, Connecticut has done a better job in growing its monthly engagement rate at 9% relative to Utah's 7% during the same period.\n\n5) SeeSaw: The Learning Journal is the most popular product across most States based on `engagement_index`.","46c9c198":"### Summary of the 3 datasets","f959af6e":"### Correlation of district features","bd0f9d65":"**What do we observe**\n\n1) Content Management products - Video conferencing and Screen sharing has seen the most growth off all primary essential functions. Schools started using it right after the schools shutdown towards the end of March. There was some\nengagement in April and May, but there was disruption during June and July. Subsequently, its growth picked up nicely in the last 4 months of that year.","925a57a9":"**What we observe**\n\n1) For the top 10 districts, the first 2-3 months have seen a slow adoption of digital technology. For districts such as 9536 (IL), (8520, 2257)(NY),\nthere was some engagement activity, going by the humps observed in the trend graph, before all the districts turned red towards the end of the 2nd quarter and the start of the 3rd quarter. However, they have\nall managed to pick up pace in the last quarter.\n\n2) It appears that some districts despite the call for lockdown were able to cope with the shock relatively better than other districts during April and May. However, all of them showed remarkable improvement in the last 4 months.\n","2d3464f8":"**What do we observe**\n\n1) The frequency of usage patterns are very diverse across the top 10 States.\n\n2) Products such as Microsoft Office 365, Jamboard and Pandora were used heavily in States such as Connecticut, Illinois and Utah with a high growth rate. These products\nstarted seeing usage as early as April, and they continued with double digit shares for the rest of that year.\n\n3) Other States such as New York, Connecticut and Indiana, especially with respect to their usage of Jamboard reveal that it experienced its most use in December.","425a06cf":"Create new features using the ranged field","15cbad8d":"**How is the data prepared**\n\n1) Daily engagements are aggregated at the State and district level and, the mean `engagement_index` for each State and district is computed; this is joined with the district dataframe to capture the district features.\n\n**What do we observe**\n\n1) Not all district features are strong correlated.\n\n2) The only relationships that stand out are: `pct_access` versus `engagement_index`. b) `engagement_index` versus `median_pp_total_raw`. c) `pct_mean_free` versus `pct_mean_black_hispanic`. All of these relationships\nare positively correlated.\n\n3) There is a moderately strong positive correlation between `pct_access` and `county_connections_means_ratio`.","52aae049":"**How is the data prepared**\n\n1) Daily engagements are aggregated at the State level and the mean `engagement_index` for each State is computed; this is joined with the district dataframe to capture the district features.\n\n2) The conditional formatting is applied using the mean `engagement_index` - if it is above the mean, green is used to represent the State, otherwise red is used.\n\n**What do we observe**\n\n1) Utah may have the highest share of daily engagements, however, with respect to the `pct_access` and `engagement_index` features, they are below the mean.\n\n2) States such as North Dakota has a higher than average `pct_access`, but the `engagement_index` is below the overall States mean. This is because it has data for the first 3 months only.\n\n3) Arizona has the highest mean `engagement_index` and `pct_access` of all States; it also has only one district captured in this dataset.\n\n4) Minnesota, Indiana, and Michigan, in that order, have the highest percentage of free\/reduced meal price of all States.\n\n5) New York, District Of Columbia, and New Jersey, in that order have the highest median per pupil expenditure of all States.\n\n6) Quite a number of states haven't reported figures for percentage of reported Black\/Hispanic students, percent of free\/reduced mean price and median per pupil expenditure.","c7328b4e":"<a id=share_eng_top_10_states_and_prod><\/a>","56b1ac13":"<a id=State-wise_monthly_share_of_engagement_index><\/a>","17d97fa3":"**What do we observe**\n\n1) We have data for only 3 districts in this State. District 6500 is the only one with the highest `pct_access` and `engagement_index` metrics of all districts in DC.","8c20b0ee":"### Preprocessing of  engagements\n\n1) Merge daily engagements with districts and products.","e9a2a7dc":"## Share in engagement of top 10 Primary Essential functions","0864fabb":"## Engagements\n\nParse the engagement data which is captured at the district level\non a daily basis for the last one year.","958bba1c":"**What do we observe**\n\n1) A contrasting picture emerges when we look at share in engagement of top 10 States and their products used. Some of the States such as Connecticut, Illinois, Utah, Indiana and North Carolina don't appear at all.\n\n2) Jamboard appears to have found traction in one or more NY districts only in December.\n\n3) Seasaw: The Learning Journal seemed to be a popular learning tool, across several States, during the last quarter in 2020.\n\n4) Microsoft Office 365 doesn't feature in the top 10 across any of the States, implying that there is little correlation between frequency of using a given product and its engagement.","669ba7f2":"**What do we observe**\n\n1) In contrast, most of the bottom 10 districts seem to have little to no engagement data starting from end of the first half and continuing on to the second half of the year; this could be attributed due to several reasons:\n\n    a) Challenge with teachers and\/or students not attending class due to personal emergencies and the general chaos we were all living in.\n\n    b) Challenges with internet speed and\/or the usage of digital learning medium.\n\n    c) Issues with the learning platform not recording data. \n\n    d) Limited intervention from the School and district operations management team.","d8670483":"The pandemic threw everyones life out of gear for most part of last year, including the current year. While some countries are still in lockdown, others are emerging cautiously out of it while ensuring its population are vaccinated. In the US,\nonly 27 states were closed according to [Edweek](https:\/\/www.edweek.org\/leadership\/the-coronavirus-spring-the-historic-closing-of-u-s-schools-a-timeline\/2020\/07). It was not until March 25 that all US publicschools were ordered to shutdown; this\nimpacted the morale of both students and teachers, and it took another month before online learning became almost the defacto way of learning going forward.\n\n1) The [mean monthly engagement index](#mean_monthly_engagement_index) shows that news of the closure lowered the mean monthly `enagement_index`, which was at its peak in April, until it reached its lowest in July. However, we notice a reveral right after July; the mean `engagement_index` peaks in October before declining slightly for the rest of 2020.\n\n2) The scars of COVID-19 pandemic are here to stay. Governments, Corporations, and the public in general will continue to practice COVID appropriate behaviour for years to come. In that light, we have seen that some US States [engagement growth](#State-wise_monthly_share_of_engagement_index) such as New York, Connecticut, etc. were able to cope relatively better than others such as Ohio, Wisconsin and Minnesota during the pandemic. Yet others such as District of Columbia, Texas saw positive engagement rates during the last 4 months in 2020. This tells us that some States were better prepared. Even if things return to normal, schools will be better prepared to switch to online learning with minimal disruption; this will be supported by much improved technology in the future.\n\n3) The experience with respect to usage of various digital technology is quite varied during 2020. Just based on frequency of product usage, this is what we see [frequency of usage](#top_10_product_share_frequency). When we include the State dimension, and make a comparison between [share in frequency of usage by State and Product](#top10_freq) and [engagement share by State and Product](#share_eng_top_10_states_and_prod), a different picture emerges - one which reveals a weak correlation between frequency of using a given product and its engagement. The tables show that usage pattern varies significantly. Some States show a lot of activity with certain products during the last 4 months, while others have shown activity during April and May, including during the last 4 months. Yet others have only shown activity during the first quarter, and none later.\n\n4) There is a strong positive correlation between `pct_access` and `engagement_index` and between `pct_mean_free` and `pct_mean_black_hispanic` respectively [correlation between district features](#correlation_matrix); this is reinforced by these [parallel coordinate charts](#parallel_coord). By geography, the most preferred essential function, [share of top 10 essential functions by State](#CM_top10_by_state) regardless of ethnicity, is CM - Virtual Classroom.\n\n5) By looking at the table [share of engagement for top 10 States and their use of SDO-LMS](#top10_SDO), there is some indication to show that early intervention by the school districts helps with improving the engagement rates [State health report](#state_report); Wisconsin might be an outlier. As shown in the table the intervention in the month of Jan was very low, however, the last 4 months saw some activity which boosted its SDO growth but this wasn't enough to improve the overall engagement growth rate.\n","ba455ff5":"## Engagement index share by State and District over time","779608d9":"**What do we observe**\n\n`engagement_index` - the total page load events per 1000 students for a given product on a given day\n\n1) Schools were given orders to shut down in March. However, from this chart, it took a while before engagement waned. The month\nof July witnessed the lowest `engagement_index` of 50 page load events per 1000 students. However, we see a reversal in this trend, which peaks in Septemeber, and dipped slightly\ntowards the final quarter in that year.","7a01174c":"<a id=parallel_coord><\/a>","35cee425":"### Share in frequency of usage and engagement by State and Product","7220999c":"**How was the data prepared**\n\n1) The records with missing product_id and State were filtered out for this part of the analysis; this resulted in filtering 57% of the data. The loss of data doesn't change the overall distribution in terms of frequency of usage\nsignificantly.\n\n**What do we observe**\n\n1) There was an adoption of digital learning technologies prior to the start of the pandemic, which appears to have peaked at about the time schools were asked to shutdown in late March. As expected, usage dips to its lowest in July, and \nthen peaks to about 10% in October, before dipping in the last two months.","a55113ad":"## Top sectors","f295de9e":"## Products characteristics","b5aa5218":"**What do we observe**\n\n1) Barring the first quarter, Microsoft Office 365 showed phenomenal growth in the frequency of its usage during 2020; this is followed by Pandora and Jamboard in that order.\n\n2) GoToMeeting and WebEx appear to be choice of tool for online meetings as opposed to Zoom, which is popular with the corporate world.\n\n3) Surprisingly, Google products don't show up here despite occuring in the top 10 frequently used products.","df23c2d5":"### Data preparation\n\n1) 24% of the missing `engagement_index` records were removed before merging with Products.\n\n2) The Engagements dataset was merged with Products on `lp_id` and `LP ID`, which resulted in 8818 products ids not being mapped to their\ncorresponding lookup in the products dataframe. In the Engagements dataset, 7923 product ids are not mapped.\n\n3) Only the State column from Districts dataset was merged to the Engagements and Products to avoid unnecessary increase\nin memory usage.\n","89e6d8ac":"## Products","e48ae366":"**What do we observe**\n\n1) Looking at the School and Districts operations - Learning Management Systems (LMS), which is in the top 10 essential functions based on engagement growth, we can see that States such as Wisconsin, District Of Columbia, New York, Connecticut, and to a lesser extent California and Illiniois had some interactions during the latter half of the first quarter and second quarter, whereas, States such as Texas, Michigan and Tennesse saw this interactions happen mostly in the last 4 months of that year.","db15e544":"<a id=CM_top10_by_state><\/a>","2cc8e1ce":"<a id=state_report> <\/a>","978ba1f0":"**What do we observe**\n\n1) The chart shows how the various district level features interact with one another. All the features, execept for the `distrct_id` were scaled to deal with the outliers.\n\n2) District 9536 stands out here; it has both a high percentage of reported Black\/Hispanics students and a high percentage of students eligible for free\/reduced price lunch measl. The dsitrict, however, has no reported\nper pupil expenditure, but its `pct_access` and `engagement_index` metrics are the best of the lot.\n","132228bf":"**What do we observe**\n\n1) Slicing the data to look at only \"LC - Sites, Resources & Reference - Streaming Services\", the second most popular function in terms of engagement growth rate, what we see is that all the States have engaged with this essential function\nmostly during the last 4 months of that year.","5c4d2cde":"**What do we observe**\n\n1) The pattern here is similar to what we observe for State of Michigan.","03bf200d":"<a id=top_10_product_share_frequency><\/a>","dc11296b":"<a id=correlation_matrix><\/a>","5fcbc141":"<a id=mean_monthly_engagement_index><\/a>","9c6697f8":"**How is the data prepared**\n\n1) This dataset summarizes the following attributes:\n\n    a) district features\n\n    b) the total number of districts\n\n    c) total healthy districts, which is based on whether that district experienced a positive engagement rate or not in 2020\n\n    d) the most popular product used based on engagement growth\n\n    e) mean monthly product eneagement rate, and\n\n    f) mean monthly engagement growth rate\n\nAll of these attributes are collected at the State level and joined together; these are sorted in descending order based on mean monthly engagement growth rate.","b65a36f4":"**What do we observe**\n\n1) With respect to share in enagement, there is not much difference among the top 4 products except Jamboard losing 3rd place to Seesaw: The Learning Journal. Zoom, relative to WebEx and GoToMeetings has had a higher\nengagement growth rate among the students and teachers.","edb5090e":"**What do we observe**\n\n`pct_access` - Percentage of students in the district have at least one page-load event of a given product and on a given day\n\n1) The `pct_access` is at its highest in January. From here onwards, it drops gradually witnessing a steep decline starting from May onwards hitting its nadir in July. Just like\nwith `engagement_index`, there is a reversal in this trend peaking in Septemeber, and dipping towards the last quarter of 2020.","e8e01e34":"## District-wise correlations","86b343ac":"<a id=top10_SDO><\/a>","d0a23970":"The analysis takes a look at the various dimensions and their interplay with respect to district dynamics and product characteristics - during Jan2020 - Dec2020,\nto understand which districts weathered the storm relatively better, and which ones were severely crippled for one or the other reasons.","3599ebad":"## Share in frequency of usage of best and worst products over time","34255d5a":"## Engagement index growth comparison - District level","5790209a":"## Deep dive","2147b213":"## Top 10 providers","c507bd94":"**What do we observe**\n\n1) Google, hands down, has the largest share of products to offer on the learning platform.","1b13e305":"**What do we observe**\n\n1) There is a lot of variation within a State itself. For example, district - 8784 in Illinois has the highest registered number of daily engagements ~233K. However, in contrast, another district 5042 in the same state\nhas one of the lowest number of engagements - ~5K.","81539856":"## Share in engagement by State and Primary Essential functions over time","9ce313ae":"**What do we observe**\n\n1) Learning Curriculum (LC) appears to be most frequently uses essential function on the platform.","f498a418":"**What do we observe**\n\n1) Utah, Connecticut and Illinois are the top 3 states that showed a relatively better daily engagement share compared to the rest of the States.\n\n2) Some of the poor performing States are: New Hampshire, Arizona, Minnesota and North Dakota."}}