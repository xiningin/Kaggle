{"cell_type":{"e811a272":"code","6871f34d":"code","92a9aac3":"code","473bc107":"code","754cf609":"code","874b869c":"code","9fb26450":"code","e662352a":"markdown","387baf03":"markdown","aee1298b":"markdown"},"source":{"e811a272":"import os\nimport matplotlib.pyplot as plt\nimport glob\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom keras.layers import Dense, Dropout, Reshape, Conv1D, BatchNormalization, Activation, AveragePooling1D, GlobalAveragePooling1D, Lambda, Input, Concatenate, Add, UpSampling1D, Multiply\nfrom keras.models import Model\nfrom keras.objectives import mean_squared_error\nfrom keras import backend as K\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau,LearningRateScheduler\nfrom keras.initializers import random_normal\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.callbacks import Callback\n\nfrom sklearn.metrics import cohen_kappa_score, f1_score\nfrom sklearn.model_selection import KFold, train_test_split","6871f34d":"df_train = pd.read_csv(\"..\/input\/liverpool-ion-switching\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/liverpool-ion-switching\/test.csv\")\n\n# I don't use \"time\" feature\ntrain_input = df_train[\"signal\"].values.reshape(-1,4000,1)#number_of_data:1250 x time_step:4000\ntrain_input_mean = train_input.mean()\ntrain_input_sigma = train_input.std()\ntrain_input = (train_input-train_input_mean)\/train_input_sigma\ntest_input = df_test[\"signal\"].values.reshape(-1,10000,1)#\ntest_input = (test_input-train_input_mean)\/train_input_sigma\n\n#train_target = df_train[\"open_channels\"].values.reshape(-1,4000,1)#regression\ntrain_target = pd.get_dummies(df_train[\"open_channels\"]).values.reshape(-1,4000,11)#classification\n\nidx = np.arange(train_input.shape[0])\ntrain_idx, val_idx = train_test_split(idx, random_state = 111,test_size = 0.2)\n\nval_input = train_input[val_idx]\ntrain_input = train_input[train_idx] \nval_target = train_target[val_idx]\ntrain_target = train_target[train_idx] \n\nprint(\"train_input:{}, val_input:{}, train_target:{}, val_target:{}\".format(train_input.shape, val_input.shape, train_target.shape, val_target.shape))","92a9aac3":"def cbr(x, out_layer, kernel, stride, dilation):\n    x = Conv1D(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    return x\n\ndef se_block(x_in, layer_n):\n    x = GlobalAveragePooling1D()(x_in)\n    x = Dense(layer_n\/\/8, activation=\"relu\")(x)\n    x = Dense(layer_n, activation=\"sigmoid\")(x)\n    x_out=Multiply()([x_in, x])\n    return x_out\n\ndef resblock(x_in, layer_n, kernel, dilation, use_se=True):\n    x = cbr(x_in, layer_n, kernel, 1, dilation)\n    x = cbr(x, layer_n, kernel, 1, dilation)\n    if use_se:\n        x = se_block(x, layer_n)\n    x = Add()([x_in, x])\n    return x  \n\ndef mynet(input_shape=(None,1)):\n    layer_n = 64\n    kernel_size = 7\n    depth = 2\n\n    input_layer = Input(input_shape)    \n    input_layer_1 = AveragePooling1D(5)(input_layer)\n    input_layer_2 = AveragePooling1D(25)(input_layer)\n    \n    ########## Encoder\n    x = cbr(input_layer, layer_n, kernel_size, 1, 1)#1000\n    for i in range(depth):\n        x = resblock(x, layer_n, kernel_size, 1)\n    out_0 = x\n\n    x = cbr(x, layer_n*2, kernel_size, 5, 1)\n    for i in range(depth):\n        x = resblock(x, layer_n*2, kernel_size, 1)\n    out_1 = x\n\n    x = Concatenate()([x, input_layer_1])    \n    x = cbr(x, layer_n*3, kernel_size, 5, 1)\n    for i in range(depth):\n        x = resblock(x, layer_n*3, kernel_size, 1)\n    out_2 = x\n\n    x = Concatenate()([x, input_layer_2])    \n    x = cbr(x, layer_n*4, kernel_size, 5, 1)\n    for i in range(depth):\n        x = resblock(x, layer_n*4, kernel_size, 1)\n    \n    ########### Decoder\n    x = UpSampling1D(5)(x)\n    x = Concatenate()([x, out_2])\n    x = cbr(x, layer_n*3, kernel_size, 1, 1)\n\n    x = UpSampling1D(5)(x)\n    x = Concatenate()([x, out_1])\n    x = cbr(x, layer_n*2, kernel_size, 1, 1)\n\n    x = UpSampling1D(5)(x)\n    x = Concatenate()([x, out_0])\n    x = cbr(x, layer_n, kernel_size, 1, 1)    \n\n    #regressor\n    #x = Conv1D(1, kernel_size=kernel_size, strides=1, padding=\"same\")(x)\n    #out = Activation(\"sigmoid\")(x)\n    #out = Lambda(lambda x: 12*x)(out)\n    \n    #classifier\n    x = Conv1D(11, kernel_size=kernel_size, strides=1, padding=\"same\")(x)\n    out = Activation(\"softmax\")(x)\n    \n    model = Model(input_layer, out)\n    \n    return model\n\n\ndef augmentations(input_data, target_data):\n    #flip\n    if np.random.rand()<0.5:    \n        input_data = input_data[::-1]\n        target_data = target_data[::-1]\n\n    return input_data, target_data\n\n\ndef Datagen(input_dataset, target_dataset, batch_size, is_train=False):\n    x=[]\n    y=[]\n  \n    count=0\n    idx_1 = np.arange(len(input_dataset))\n    #idx_2 = np.arange(len(input_dataset))\n    np.random.shuffle(idx_1)\n    #np.random.shuffle(idx_2)\n\n    while True:\n        for i in range(len(input_dataset)):\n            input_data = input_dataset[idx_1[i]]\n            target_data = target_dataset[idx_1[i]]\n            #input_data_mix = input_dataset[idx_2[i]]\n            #target_data_mix = target_dataset[idx_2[i]]\n\n            if is_train:\n                input_data, target_data = augmentations(input_data, target_data)\n                #input_data_mix, target_data_mix = augmentations(input_data_mix, target_data_mix)\n                \n            x.append(input_data)\n            y.append(target_data)\n            count+=1\n            if count==batch_size:\n                x=np.array(x, dtype=np.float32)\n                y=np.array(y, dtype=np.float32)\n                inputs = x\n                targets = y       \n                x = []\n                y = []\n                count=0\n                yield inputs, targets\n\nclass macroF1(Callback):\n    def __init__(self, model, inputs, targets):\n        self.model = model\n        self.inputs = inputs\n        self.targets = np.argmax(targets, axis=2).reshape(-1)\n\n    def on_epoch_end(self, epoch, logs):\n        pred = np.argmax(self.model.predict(self.inputs), axis=2).reshape(-1)\n        f1_val = f1_score(self.targets, pred, average=\"macro\")\n        print(\"val_f1_macro_score: \", f1_val)\n                \ndef model_fit(model, train_inputs, train_targets, val_inputs, val_targets, n_epoch, batch_size=32):\n    hist = model.fit_generator(\n        Datagen(train_inputs, train_targets, batch_size, is_train=True),\n        steps_per_epoch = len(train_inputs) \/\/ batch_size,\n        epochs = n_epoch,\n        validation_data=Datagen(val_inputs, val_targets, batch_size),\n        validation_steps = len(val_inputs) \/\/ batch_size,\n        callbacks = [lr_schedule, macroF1(model, val_inputs, val_targets)],\n        shuffle = False,\n        verbose = 1\n        )\n    return hist\n\n\ndef lrs(epoch):\n    if epoch<35:\n        lr = learning_rate\n    elif epoch<50:\n        lr = learning_rate\/10\n    else:\n        lr = learning_rate\/100\n    return lr\n","473bc107":"K.clear_session()\nmodel = mynet()\n\n\nlearning_rate=0.0005\nn_epoch= 260\nbatch_size=32\n\nlr_schedule = LearningRateScheduler(lrs)\n\n\nmodel.compile(loss=categorical_crossentropy, \n              optimizer=Adam(lr=learning_rate), \n              metrics=[\"accuracy\"])\n\n# hist = model_fit(model, train_input, train_target, val_input, val_target, n_epoch, batch_size)","754cf609":"hist = model_fit(model, train_input, train_target, val_input, val_target, n_epoch, batch_size)","874b869c":"pred = np.argmax((model.predict(val_input)+model.predict(val_input[:,::-1,:])[:,::-1,:])\/2, axis=2).reshape(-1)\ngt = np.argmax(val_target, axis=2).reshape(-1)\nprint(\"SCORE_oldmetric: \", cohen_kappa_score(gt, pred, weights=\"quadratic\"))\nprint(\"SCORE_newmetric: \", f1_score(gt, pred, average=\"macro\"))","9fb26450":"pred = np.argmax((model.predict(test_input)+model.predict(test_input[:,::-1,:])[:,::-1,:])\/2, axis=2).reshape(-1)\n\ndf_sub = pd.read_csv(\"..\/input\/liverpool-ion-switching\/sample_submission.csv\", dtype={'time':str})\ndf_sub.open_channels = np.array(np.round(pred,0), np.int)\ndf_sub.to_csv(\"submission.csv\",index=False)","e662352a":"## Training","387baf03":"## Import Library","aee1298b":"## Predict and Submit\n"}}