{"cell_type":{"16d3bacf":"code","f6d353d9":"code","174bc10c":"code","6e6429ed":"code","d7722cfa":"code","f8b702c3":"code","761f4376":"code","c1a60a3f":"code","4c6fed5a":"code","8cf89cdf":"code","8ec7881c":"code","5c5116be":"code","71b5b198":"code","3b13cdb0":"code","a6503712":"code","f522eedf":"markdown"},"source":{"16d3bacf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        f = os.path.join(dirname, filename)\n        print(f)\n        if 'data_final.csv' in f: df = pd.read_csv(f)\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f6d353d9":"df.head()","174bc10c":"df.Race_ID.size","6e6429ed":"df.describe()","d7722cfa":"df.info()","f8b702c3":"# Copy paste from orig notebook (features selected by OP not myself)\n# Features\nfeatures = ['Trap', 'BSP', 'Time_380', 'Finish_Recent', 'Finish_All', 'Stay_380',\\\n            'Races_All','Odds_Recent','Odds_380', 'Distance_Places_All', 'Dist_By',\\\n            'Races_380', 'Last_Run','Early_Time_380', 'Early_Recent' ,\\\n            'Distance_All', 'Wins_380', 'Grade_380','Finish_380','Early_380',\\\n            'Distance_Recent', 'Wide_380', 'Favourite']\n# Target\ntarget = ['Finished']\nprint('using {} features'.format(len(features)))","761f4376":"all_labels = df[target].values\nx_features = df[features].values","c1a60a3f":"y = []\nfor i in range(0, len(all_labels), 6):\n    y.append([all_labels[i:i+6]])\ny = np.array(y).reshape(2001, 6)\nx = []\nfor i in range(0, len(x_features), 6):\n    x.append([x_features[i:i+6:]])\nx = np.array(x).reshape(2001, 6, -1)","4c6fed5a":"# six runners per race\nlen(x[0])","8cf89cdf":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","8ec7881c":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)","5c5116be":"model = Sequential()\nmodel.add(BatchNormalization(input_shape=x_train.shape[1:]))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(6, activation='softmax'))\nmodel.compile(loss='mse',\n              optimizer=Adam(),\n              metrics=['accuracy'])\nmodel.summary()","71b5b198":"model.fit(x_train, y_train, epochs=800)","3b13cdb0":"# evaluate the model on TRAINING DATA\naccuracy = model.evaluate(x_train, y_train)\nprint('    Training Model Accuracy:    ' + str(round(accuracy[1])) + '%')","a6503712":"# evaluate the model on TRAINING DATA\naccuracy = model.evaluate(x_test, y_test)\nprint('    Training Model Accuracy:    ' + str(round(accuracy[1])) + '%')","f522eedf":"### Conclusion\n\nThere is too little data to get an accurate prediction, according to OP market predicts 20.9% we have predicted with 27.43 after 800 epochs, with some simple maths maybe we can win some money ;)"}}