{"cell_type":{"97143eb1":"code","627a8024":"code","2cd39edb":"code","f28fe749":"code","e76beb76":"code","d98b1c4c":"code","fec522b7":"code","eca50898":"code","6f54f803":"code","3a60961b":"code","eb634d53":"code","78b20740":"code","5fb063bc":"code","9a0ac468":"code","d82f825c":"code","19617248":"code","95d51d7f":"code","52a6096a":"code","9a669253":"code","abb2a8e0":"code","5243c368":"code","c2af60a1":"code","338ebad0":"code","0ef12504":"code","47965ec8":"code","fc3a0c5e":"code","b9f982a1":"code","72862c1a":"code","c1512ddb":"code","e49b6318":"code","0eaf650c":"code","254f9e45":"code","0a988220":"code","8eca8ed2":"code","92e871a4":"code","3b6f7ed3":"code","f65d34cf":"code","8f556f82":"code","88b99f95":"code","c1429115":"code","6983e544":"code","ab1ea9f8":"code","17355c9d":"code","aae629ab":"markdown","c079e5f9":"markdown","16456d61":"markdown","8ce76cb0":"markdown","e2882da4":"markdown","ae3eace5":"markdown","c8516468":"markdown","2ca43cb4":"markdown","0fa96f2c":"markdown","aa533c33":"markdown","b48d8bc9":"markdown"},"source":{"97143eb1":"!pip install pyspark","627a8024":"from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as f\nfrom pyspark.ml import classification\nfrom pyspark.ml import evaluation\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml import feature\nfrom pyspark.ml import Pipeline","2cd39edb":"spark = SparkSession.builder.appName('ml_app').master(\"local[*]\").getOrCreate()","f28fe749":"col_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \n             \"education-num\", \"marital-status\", \"occupation\", \n             \"relationship\", \"race\", \"sex\", \"capital-gain\", \n             \"capital-loss\", \"hours-per-week\", \"native-country\", \n             \"earnings\"]","e76beb76":"# Import data\ndf = spark.read.csv(\"..\/input\/adult-census-income\/adult.csv\", header=False, inferSchema=True, ignoreLeadingWhiteSpace=True)","d98b1c4c":"df = df.filter(\"_c0 != 'age'\")\ndf = df.select(*[f.col(old).alias(new) for old, new in zip(df.columns, col_names)]).drop(\"fnlwgt\").dropna(\"any\")","fec522b7":"# Replace \"?\" with None. Credit: Amit Rawat\n# def questionmark_as_null(x):\n#     return f.when(f.col(x) != \"?\", f.col(x)).otherwise(None)\n\n# exprs = [questionmark_as_null(x).alias(x) if x in col_names else x for x in df.columns]\n# df = df.select(*exprs).dropna(\"any\")","eca50898":"# Exemplary record\ndf.show(1, vertical=True)","6f54f803":"# Split data to training and evaluation set\ndf_t, df_e = df.randomSplit([0.7, 0.3], 1990)","3a60961b":"# One way with RFormula\nrf = feature.RFormula(formula=\"earnings ~ .\", featuresCol='featuresRaw')\nrfModel = rf.fit(df_t)\n\ndf_train = rfModel.transform(df_t)\ndf_eval = rfModel.transform(df_e)\n\nscaler = feature.StandardScaler(inputCol=\"featuresRaw\", outputCol=\"features\")\nscal_mod = scaler.fit(df_train)\ndf_train = scal_mod.transform(df_train)\ndf_eval = scal_mod.transform(df_eval)","eb634d53":"# Second option - pipeline\nnum_cols = [c for c, t in df_t.dtypes if t != \"string\"]\ncateg_cols = [c for c, t in df_t.dtypes if t == \"string\" and c != \"earnings\"]\ncateg_cols_idx = [c + \"Idx\" for c in categ_cols]\ncateg_cols_vect = [c + \"Vect\" for c in categ_cols]\n\nindexer = feature.StringIndexer(inputCol=\"earnings\", outputCol=\"label\")\nindexers = [feature.StringIndexer(inputCol=o, outputCol=n).setHandleInvalid(\"skip\") for o, n in zip(categ_cols, categ_cols_idx)]\nOHencoder = feature.OneHotEncoderEstimator(inputCols=categ_cols_idx, outputCols=categ_cols_vect)\nvectAssembler = feature.VectorAssembler(inputCols = num_cols + categ_cols_vect, outputCol = \"featuresRaw\")\nscaler = feature.StandardScaler(inputCol=\"featuresRaw\", outputCol=\"features\")\n\npipe = Pipeline(stages=[indexer] + indexers + [OHencoder, vectAssembler, scaler])\npipeModel = pipe.fit(df_t)\n\ndf_train = pipeModel.transform(df_t)\ndf_eval = pipeModel.transform(df_e)","78b20740":"df_train = df_train.select(\"label\", \"features\")\ndf_eval = df_eval.select(\"label\", \"features\")\n\n# df_train.cache()\n# df_eval.cache()","5fb063bc":"print(\"Train:\")\ndf_train.groupBy(\"label\").count().show()\nprint(\"Eval:\")\ndf_eval.groupBy(\"label\").count().show()","9a0ac468":"lr = classification.LogisticRegression(maxIter=1000)\nlrModel = lr.fit(df_train)\n\nlrModel.coefficients","d82f825c":"lrModel.intercept","19617248":"trainingSummary = lrModel.summary\n\n# FPR: False Positive Rate \/ TPR: True Posite Rate\ntrainingSummary.roc.show(120)","95d51d7f":"trainingSummary.roc.toPandas()","52a6096a":"trainingSummary.pr.show(120)","9a669253":"trainingSummary.areaUnderROC","abb2a8e0":"trainingSummary.accuracy","5243c368":"trainingSummary.predictions.show()","c2af60a1":"# Predict on evaluation set\nlrModel.transform(df_eval).show()","338ebad0":"svm = classification.LinearSVC(maxIter=1000)\nsvmModel = svm.fit(df_train)\n\nsvmModel.coefficients","0ef12504":"svmModel.intercept","47965ec8":"svmModel.transform(df_eval).show()","fc3a0c5e":"tree = classification.DecisionTreeClassifier()\ntreeModel = tree.fit(df_train)\n\ntreeModel.depth","b9f982a1":"treeModel.numNodes","72862c1a":"print(treeModel.toDebugString)","c1512ddb":"treeModel.transform(df_eval).show()","e49b6318":"forest = classification.RandomForestClassifier()\nforestModel = forest.fit(df_train)\n\nforestModel.featureImportances","0eaf650c":"print(forestModel.toDebugString)","254f9e45":"forestModel.transform(df_eval).show()","0a988220":"gbt = classification.GBTClassifier()\ngbtModel = gbt.fit(df_train)\n\ngbtModel.featureImportances","8eca8ed2":"print(gbtModel.toDebugString)","92e871a4":"gbtModel.transform(df_eval).show()","3b6f7ed3":"bayes = classification.NaiveBayes()\nbayesModel = bayes.fit(df_train)\n\nbayesModel.transform(df_eval).show()","f65d34cf":"mlp = classification.MultilayerPerceptronClassifier(maxIter=1000, layers=[475,40,2])\nmlpModel = mlp.fit(df_train)\n\nmlpModel.layers","8f556f82":"mlpModel.weights","88b99f95":"mlpModel.transform(df_eval).show()","c1429115":"models = [(lrModel, \"logistic regression\"), \n          (svmModel, \"svm\"), \n          (treeModel, \"desicion tree\"), \n          (forestModel, \"random forest\"), \n          (gbtModel, \"gradient boost\"), \n          (bayesModel, \"naive bayes\"), \n          (mlpModel, \"mlp\")]","6983e544":"evaluator = evaluation.BinaryClassificationEvaluator()\n\nfor model, name in models:\n    print(f\"AUC of {name}: {evaluator.evaluate(model.transform(df_eval))}\")","ab1ea9f8":"def calculate_acc(df, label=\"label\", prediction=\"prediction\"):\n    temp = df.select(f.when(df[label] == df[prediction], 1).otherwise(0).alias(\"same\"))\n    return temp.select(f.avg(\"same\")).collect()[0][0]\n\nfor model, name in models:\n    print(f\"Accuracy of {name}: {calculate_acc(model.transform(df_eval))}\")","17355c9d":"spark.stop()","aae629ab":"Naive Bayes Classifier","c079e5f9":"Gradient-Boosted Trees","16456d61":"Multilayer perceptron classifier","8ce76cb0":"Logistic Regression","e2882da4":"<br>\n# Evaluation","ae3eace5":"Support Vector Machine","c8516468":"Random Forest","2ca43cb4":"That's it. If you like it, please upvote. Thank you","0fa96f2c":"# Earnings classification example\n\n**Dataset:** Adult Census Income <br>\n**Source:** https:\/\/archive.ics.uci.edu\/ml\/index.php <br>\n**Goal:** Determine whether a person makes over $50K a year. \n<br>\n<br>\n<br>\n\n**Models tested:**\n* Logistic Regression\n* SVM\n* Desicion Tree\n* Random Forest\n* Gradient-Boosted Tree\n* Naive Bayes Classifier\n* Multilayer Perceptron Classifier","aa533c33":"Calculate model accuracy","b48d8bc9":"Desicion Tree Classifier"}}