{"cell_type":{"527714d4":"code","ade12ee2":"code","00a64b37":"code","78af3357":"code","35ec1433":"code","067bfe9d":"code","0a207005":"code","32741ee1":"code","b79863aa":"code","af01a833":"code","12d72dd0":"code","1c1620dc":"code","79223dd4":"code","6cacb888":"code","c6c845ed":"code","c76ca8bc":"code","aedf3f6d":"code","a1b04a4e":"code","665713e9":"markdown","12702f38":"markdown","a7eff6c2":"markdown","98fff2f2":"markdown","d386a040":"markdown","cfd6e212":"markdown","1baea036":"markdown","c11b2383":"markdown","f973cad8":"markdown","3464973d":"markdown"},"source":{"527714d4":"# 786\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.graph_objs as go\n\nimport plotly as py\nfrom plotly import tools\nfrom plotly.offline import iplot\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ade12ee2":"dt = pd.read_csv(\"..\/input\/pakistan-corona-virus-citywise-data\/PK COVID-19-30apr.csv\", encoding = \"ISO-8859-1\", parse_dates=[\"Date\"])\nprint(\"Data Dimensions are: \", dt.shape)\nprint(dt.head)","00a64b37":"dt.info()","78af3357":"dt['Travel_history'].unique\ndt['Travel_history'].fillna('Unknown',  inplace=True)","35ec1433":"dt = dt.sort_values('Date')\ndt['Deaths']=dt['Deaths'].astype(int)\ndt['Cases']=dt['Cases'].astype(int)\ndt['Recovered']=dt['Recovered'].astype(int)\n\ndt.loc[dt.Province == \"khyber Pakhtunkhwa\", \"Province\"] = \"Khyber Pakhtunkhwa\"\ndt.loc[dt.Travel_history == \"Tableegi Jamaat\", \"Travel_history\"] = \"Tableeghi Jamaat\"","067bfe9d":"pdc = dt.groupby('Date')['Cases'].sum().reset_index()\npdd = dt.groupby('Date')['Deaths'].sum().reset_index()#.drop('Date', axis=1)\npdr = dt.groupby('Date')['Recovered'].sum().reset_index()#.reset_index()#.drop('Date', axis=1)\n\np = pd.DataFrame(pdc) \np['Deaths'] = pdd['Deaths']\np['Recovered'] = pdr['Recovered']\n\n#Cumulative Sum\np['Cum_Cases'] = p['Cases'].cumsum() \np['Cum_Deaths'] = p['Deaths'].cumsum()\np['Cum_Recovered'] = p['Recovered'].cumsum()\n\ndel pdc, pdd, pdr \np.head()\n","0a207005":"p['Dateofmonth'] = p['Date'].dt.day\np['Month'] = p['Date'].dt.month\np['Week'] = p['Date'].dt.week\np['Dayofweek'] = p['Date'].dt.dayofweek # 0 = monday.\np['Weekdayflg'] = (p['Dayofweek'] \/\/ 5 != 1).astype(float)\np['Month'] = p['Date'].dt.month\np['Quarter'] = p['Date'].dt.quarter\np['Dayofyear'] = p['Date'].dt.dayofyear\np.head(10)","32741ee1":"fig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=p['Date'], y=p['Cases'],\n                    mode='lines+markers',\n                    name='Cases'))\nfig.add_trace(go.Scatter(x=p['Date'], y=p['Deaths'],\n                    mode='lines+markers',\n                    name='Deaths'))\nfig.add_trace(go.Scatter(x=p['Date'], y=p['Recovered'],\n                    mode='lines+markers',\n                    name='Recoveries'))\n\nfig.show()","b79863aa":"fig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=p['Date'], y=p['Cum_Cases'],\n                    mode='lines+markers',\n                    name='Cases'))\nfig.add_trace(go.Scatter(x=p['Date'], y=p['Cum_Deaths'],\n                    mode='lines+markers',\n                    name='Deaths'))\nfig.add_trace(go.Scatter(x=p['Date'], y=p['Cum_Recovered'],\n                    mode='lines+markers',\n                    name='Recoveries'))\n\nfig.show()","af01a833":"px.scatter(p, x= 'Date', y = 'Cases', trendline = \"ols\")","12d72dd0":"from sklearn.ensemble import RandomForestClassifier\n#model = RandomForestClassifier(n_estimators=200)\nmodel = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                      max_depth=None, max_features='auto', max_leaf_nodes=None, \n                      n_estimators=250, random_state=None, n_jobs=1, verbose=0)","1c1620dc":"input_col = [#'Date',\n# 'Cases',\n# 'Deaths',\n# 'Recovered',\n# 'Cum_Cases',\n# 'Cum_Deaths',\n# 'Cum_Recovered',\n 'Dateofmonth',\n 'Month',\n 'Week',\n 'Dayofweek',\n 'Weekdayflg',\n 'Quarter',\n 'Dayofyear']\n\noutput_cols = ['Cases', 'Deaths', 'Cum_Cases', 'Cum_Deaths'] ","79223dd4":"X = p[input_col]\nY1 = p[output_cols[0]]","6cacb888":"# Date Range for Prediction\npred_dates = np.arange('2019-05', '2019-06', dtype='datetime64[D]')\npred_range = pred_dates[0:6]\npred = pd.DataFrame(pred_range, columns=['Date'])\npred['Dateofmonth'] = pred['Date'].dt.day\npred['Month'] = pred['Date'].dt.month\npred['Week'] = pred['Date'].dt.week\npred['Dayofweek'] = pred['Date'].dt.dayofweek # 0 = monday.\npred['Weekdayflg'] = (pred['Dayofweek'] \/\/ 5 != 1).astype(float)\npred['Month'] = pred['Date'].dt.month\npred['Quarter'] = pred['Date'].dt.quarter\npred['Dayofyear'] = pred['Date'].dt.dayofyear\n#pred.info()","c6c845ed":"model.fit(X,Y1)","c76ca8bc":"X_test = pred[input_col]\nprd = model.predict(X_test)","aedf3f6d":"pred['Predicted_Cases'] = prd","a1b04a4e":"pred","665713e9":"Travel history has less records, we will fill NAs with Unknown","12702f38":"Let's have a look at scatter plot of cases with OLS trendline.","a7eff6c2":"## Prediction with Random Forest","98fff2f2":"## Data Loading & Preparation","d386a040":"Type casting variables and fixing one Province value","cfd6e212":"### Few new features extracted","1baea036":"## Exploratory Analysis","c11b2383":"# Covid Forcaste with Quick Random Forest\n**Hello Everyone, **\n\nHere is our very first kernel on forecast model building. We have setup everything and built one quick and basic model without validation yet.\nWe will follow following steps when times permits. \nFuture Steps: \n* Model validation and Calibration\n* ARIMA | Moving Average Model | Exponential smoothing | Holt linear \n* LightGBM, XGBoost\n* Prediction with Weather Data\n* Prediction with Weather Data + Health Data\n\nIf you have questions or comments, please leave in comments section. If you find this kernel useful, please upvote! \n\n**Thank you**","f973cad8":"#### Daily Cases vs Deaths vs Recoveries","3464973d":"#### Cumulative Sums of Daily Cases vs Deaths vs Recoveries"}}