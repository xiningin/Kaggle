{"cell_type":{"369f9fc7":"code","e55d382f":"code","0dee09bb":"code","71a0a846":"code","ab19bd91":"code","814fac4e":"code","690df217":"code","6641f428":"code","6692fcf8":"code","d9f4042b":"code","26ce6f14":"code","b2bf8c67":"code","c52b6b0b":"code","87e94efb":"code","e2c17aa2":"code","e5945e99":"code","39f285e4":"code","e3e65467":"code","da067ea2":"code","17f6d349":"code","beb2f9ed":"code","206de3c8":"code","60108d2c":"code","4edbbdb5":"code","b8d658d4":"code","d39f48fc":"code","8ac740ae":"code","5d9d6629":"code","bd990f4a":"code","880504d7":"code","a2af3a33":"code","bdfc1a8e":"code","9970c9b7":"code","3a110489":"code","bb524703":"code","ce134eb4":"code","c3429cd9":"code","5d26d73f":"code","899f25e5":"code","0201c53c":"code","00e4cebe":"code","cfc9ecbf":"code","5d567205":"code","dc80e3b7":"code","1efb535f":"code","e1cca6bb":"code","3f9d5819":"code","879b75f5":"code","d6123a93":"code","db380d88":"code","07b1196a":"code","03b0180d":"code","c497acc5":"code","08877276":"code","dff94578":"code","bfbf0ee0":"code","38e69631":"code","3a49771d":"code","58adf222":"code","bed7c87c":"code","0d069594":"code","65394cc6":"code","30540a26":"code","115508c2":"code","be3ced21":"code","2bbdd9c2":"code","00ad27ba":"code","94e21d34":"code","dfccf795":"code","27e8db8e":"code","88e37f3b":"code","2237ee37":"markdown"},"source":{"369f9fc7":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt \nimport matplotlib\n%matplotlib inline \nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\n","e55d382f":"df1 = pd.read_csv(\"..\/input\/bengaluru-house-price-data\/Bengaluru_House_Data.csv\")\ndf1.head()\n","0dee09bb":"df1.shape","71a0a846":"df1.groupby('area_type')['area_type'].agg('count')","ab19bd91":"#Remove unnecessary columns \ndf2 = df1.drop(['area_type','society','balcony','availability'],axis='columns')\ndf2.head()","814fac4e":"df2.isnull().sum()","690df217":"df3 = df2.dropna()\ndf3.isnull().sum()","6641f428":"df3.shape","6692fcf8":"#Finding the unique values and get only numeric values \ndf3['size'].unique()","d9f4042b":"#Create bhk column to store values\ndf3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))","26ce6f14":"df3.head()","b2bf8c67":"df3['bhk'].unique()","c52b6b0b":"df3[df3.bhk > 20]","87e94efb":"df3.total_sqft.unique()","e2c17aa2":"def is_float(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True\n    ","e5945e99":"df3[~df3['total_sqft'].apply(is_float)].head()","39f285e4":"def convert_sqft_to_num(x):\n    tokens = x.split('-')\n    if len(tokens) == 2:\n        return (float(tokens[0]) + float(tokens[1]))\/2\n    try:\n        return float(x)\n    except:\n        return None","e3e65467":"convert_sqft_to_num('21345')","da067ea2":"convert_sqft_to_num('2100-2456')","17f6d349":"convert_sqft_to_num('34.56sq.Meter')","beb2f9ed":"df4 = df3.copy()\ndf4['total_sqft'] = df4['total_sqft'].apply(convert_sqft_to_num)\ndf4.head(3)","206de3c8":"df4.loc[30]","60108d2c":"(2100+2850)\/2","4edbbdb5":"df4.head(3)","b8d658d4":"df5 = df4.copy()\ndf5['price_per_sqft'] = df5['price']*100000\/df5['total_sqft']\ndf5.head()","d39f48fc":"#dimentionality problems ....1 location has number of times \nlen(df5.location.unique())","8ac740ae":"df5.location = df5.location.apply(lambda x: x.strip())\n\nlocation_stats = df5.groupby('location')['location'].agg('count').sort_values(ascending=False)\nlocation_stats","5d9d6629":"len(location_stats[location_stats<=10])","bd990f4a":"location_stats_lessthan_10 = location_stats[location_stats<=10]\nlocation_stats_lessthan_10","880504d7":"len(df5.location.unique())","a2af3a33":"#convert all the less than 10 locatioons to other...\ndf5.location = df5.location.apply(lambda x: 'other' if x in location_stats_lessthan_10 else x )\nlen(df5.location.unique())","bdfc1a8e":"df5.head(10)","9970c9b7":"#600\/6   sqft\/bhk normally 300 sqft for 1 removing ouliers\n\ndf5[df5.total_sqft\/df5.bhk<300].head()\n","3a110489":"df5.shape","bb524703":"#removing ouliers and copy into 6\ndf6 = df5[~(df5.total_sqft\/df5.bhk<300)]\ndf6.shape","ce134eb4":"df6.price_per_sqft.describe()","c3429cd9":"#find meand and sd\ndef remove_pps_outlier(df):\n    df_out = pd.DataFrame()\n    for key, subdf in df.groupby('location'):\n        m = np.mean(subdf.price_per_sqft)\n        st= np.std(subdf.price_per_sqft)\n        reduce_df = subdf[(subdf.price_per_sqft > (m-st)) & (subdf.price_per_sqft <=(m+st))]\n        df_out = pd.concat([df_out,reduce_df],ignore_index=True)\n    return df_out\ndf7 = remove_pps_outlier(df6)\ndf7.shape","5d26d73f":"def plot_scatter_chart(df,location):   \n    bhk2 = df[(df.location==location) & (df.bhk==2)]\n    bhk3 = df[(df.location==location) & (df.bhk==3)]\n    matplotlib.rcParams['figure.figsize'] = (15,10)\n    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n    plt.xlabel(\"Total Square Feet Area\")\n    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n    plt.title(location)\n    plt.legend()\n    \nplot_scatter_chart(df7,\"Rajaji Nagar\")","899f25e5":"plot_scatter_chart(df7,\"Hebbal\")","0201c53c":"%%HTML\nWe should also remove properties where for same location, the price of (for example) 3 bedroom apartment is less than 2 bedroom apartment (with same square ft area). What we will do is for a given location, we will build a dictionary of stats per bhk, i.e.\n\n{\n    '1' : {\n        'mean': 4000,\n        'std: 2000,\n        'count': 34\n    },\n    '2' : {\n        'mean': 4300,\n        'std: 2300,\n        'count': 22\n    },    \n}\nNow we can remove those 2 BHK apartments whose price_per_sqft is less than mean price_per_sqft of 1 BHK apartment","00e4cebe":"\ndef remove_bhk_outliers(df):\n    exclude_indices = np.array([])\n    for location, location_df in df.groupby('location'):\n        bhk_stats = {}\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            bhk_stats[bhk] = {\n                'mean': np.mean(bhk_df.price_per_sqft),\n                'std': np.std(bhk_df.price_per_sqft),\n                'count': bhk_df.shape[0]\n            }\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            stats = bhk_stats.get(bhk-1)\n            if stats and stats['count']>5:\n                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n    return df.drop(exclude_indices,axis='index')\ndf8 = remove_bhk_outliers(df7)\n# df8 = df7.copy()\ndf8.shape","cfc9ecbf":"##Plot same scatter chart again to visualize price_per_sqft for 2 BHK and 3 BHK properties\nplot_scatter_chart(df8,\"Rajaji Nagar\")\n","5d567205":"plot_scatter_chart(df8,\"Hebbal\")","dc80e3b7":"\nimport matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\nplt.hist(df8.price_per_sqft,rwidth=0.8)\nplt.xlabel(\"Price Per Square Feet\")\nplt.ylabel(\"Count\")","1efb535f":"#Outlier Removal Using Bathrooms Feature\ndf8.bath.unique()","e1cca6bb":"\nplt.hist(df8.bath,rwidth=0.8)\nplt.xlabel(\"Number of bathrooms\")\nplt.ylabel(\"Count\")","3f9d5819":"df8[df8.bath>10]","879b75f5":"#It is unusual to have 2 more bathrooms than number of bedrooms in a home\n\ndf8[df8.bath>df8.bhk+2]","d6123a93":"df9 = df8[df8.bath<df8.bhk+2]\ndf9.shape","db380d88":"df9.head(2)","07b1196a":"#drop for size and price per sqft\ndf10 = df9.drop(['size','price_per_sqft'],axis='columns')\ndf10.head(3)","03b0180d":"#Use One Hot Encoding For Location\n\ndummies = pd.get_dummies(df10.location)\ndummies.head(3)","c497acc5":"df11 = pd.concat([df10,dummies.drop('other',axis='columns')],axis='columns')\ndf11.head()","08877276":"#drop location \n\ndf12 = df11.drop('location',axis='columns')\ndf12.head(2)","dff94578":"#Build a Model Now...\ndf12.shape","bfbf0ee0":"#take price into y rest is x axis\n\nX = df12.drop(['price'],axis='columns')\nX.head(3)","38e69631":"X.shape","3a49771d":"Y = df12.price\nY.head(3)","58adf222":"len(Y)","bed7c87c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,random_state=10)","0d069594":"from sklearn.linear_model import LinearRegression\nlr_clf = LinearRegression()\nlr_clf.fit(X_train,y_train)\nlr_clf.score(X_test,y_test)\n","65394cc6":"#Use K Fold cross validation to measure accuracy of our LinearRegression model\n\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\n\ncv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n\ncross_val_score(LinearRegression(), X, Y, cv=cv)\n","30540a26":"#We can see that in 5 iterations we get a score above 80% all the time. This is pretty good but we want to test few other algorithms for regression to see if we can get even better score. We will use GridSearchCV for this purpose","115508c2":"#Find best model using GridSearchCV\n\n#Find best model using GridSearchCV\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef find_best_model_using_gridsearchcv(X,Y):\n    algos = {\n        'linear_regression' : {\n            'model': LinearRegression(),\n            'params': {\n                'normalize': [True, False]\n            }\n        },\n        'lasso': {\n            'model': Lasso(),\n            'params': {\n                'alpha': [1,2],\n                'selection': ['random', 'cyclic']\n            }\n        },\n        'decision_tree': {\n            'model': DecisionTreeRegressor(),\n            'params': {\n                'criterion' : ['mse','friedman_mse'],\n                'splitter': ['best','random']\n            }\n        }\n    }\n    scores = []\n    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n    for algo_name, config in algos.items():\n        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n        gs.fit(X,Y)\n        scores.append({\n            'model': algo_name,\n            'best_score': gs.best_score_,\n            'best_params': gs.best_params_\n        })\n\n    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n\nfind_best_model_using_gridsearchcv(X,Y)","be3ced21":"#Based on above results we can say that LinearRegression gives the best score. Hence we will use that.\n\n#Test the model for few properties\n\ndef predict_price(location,sqft,bath,bhk):    \n    loc_index = np.where(X.columns==location)[0][0]\n\n    x = np.zeros(len(X.columns))\n    x[0] = sqft\n    x[1] = bath\n    x[2] = bhk\n    if loc_index >= 0:\n        x[loc_index] = 1\n\n    return lr_clf.predict([x])[0]","2bbdd9c2":"predict_price('1st Phase JP Nagar',1000, 2, 2)","00ad27ba":"predict_price('1st Phase JP Nagar',1000, 3, 3)","94e21d34":"predict_price('Indira Nagar',1000, 2, 2)","dfccf795":"predict_price('Indira Nagar',1000, 3, 3)","27e8db8e":"#Export the tested model to picke file..\nimport pickle\nwith open('banglore_home_prices_model.pickle','wb') as f:\n    pickle.dump(lr_clf,f)\n","88e37f3b":"#Export location and column information to a file that will be useful later on in our prediction application\nimport json\ncolumns = {\n    'data_columns' : [col.lower() for col in X.columns]\n}\nwith open(\"columns.json\",\"w\") as f:\n    f.write(json.dumps(columns))","2237ee37":"#identify the null values\ndf2.isnull().sum"}}