{"cell_type":{"20cdac9a":"code","6dbf8cfc":"code","0a9a8966":"code","b2d11edd":"code","fff2b2df":"code","66adb574":"code","ced2eeb9":"code","6994e3fd":"code","9fd74b1b":"code","944c3a80":"code","a37fdbc0":"markdown","7a194713":"markdown","853a639d":"markdown","38be06ff":"markdown","6c8208dd":"markdown"},"source":{"20cdac9a":"# Credits: https:\/\/github.com\/keras-team\/keras\/blob\/master\/examples\/mnist_cnn.py\n\nfrom __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train \/= 255\nx_test \/= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nhistory =  model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","6dbf8cfc":"def plt_dynamic(x, vy, ty, ax, colors=['b']):\n    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n    ax.plot(x, ty, 'r', label=\"Train Loss\")\n    plt.legend()\n    plt.grid()\n    fig.canvas.draw()","0a9a8966":"import matplotlib.pyplot as plt\n\nfig,ax = plt.subplots(1,1)\nax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n\n# list of epoch numbers\nx = list(range(1,epochs+1))\n\nvy = history.history['val_loss']\nty = history.history['loss']\nplt_dynamic(x, vy, ty, ax)","b2d11edd":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape, padding='same'))\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\nmodel.add(Conv2D(128, kernel_size=(3, 3),activation='relu', padding='same'))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nhistory = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","fff2b2df":"fig,ax = plt.subplots(1,1)\nax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n\n# list of epoch numbers\nx = list(range(1,epochs+1))\n\nvy = history.history['val_loss']\nty = history.history['loss']\nplt_dynamic(x, vy, ty, ax)","66adb574":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=input_shape, padding='same'))\nmodel.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\nmodel.add(Conv2D(96, kernel_size=(5, 5),activation='relu', padding='same'))\nmodel.add(Conv2D(128, (5, 5), activation='relu', padding='same'))\nmodel.add(Conv2D(224, kernel_size=(5, 5),activation='relu', padding='same'))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nhistory = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","ced2eeb9":"fig,ax = plt.subplots(1,1)\nax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n\n# list of epoch numbers\nx = list(range(1,epochs+1))\n\nvy = history.history['val_loss']\nty = history.history['loss']\nplt_dynamic(x, vy, ty, ax)","6994e3fd":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(7, 7), activation='relu', input_shape=input_shape, padding='same'))\nmodel.add(Conv2D(64, (7, 7), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\nmodel.add(Conv2D(96, kernel_size=(7, 7),activation='relu', padding='same'))\nmodel.add(Conv2D(128, (7, 7), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\nmodel.add(Conv2D(224, kernel_size=(7, 7),activation='relu', padding='same'))\nmodel.add(Conv2D(512, kernel_size=(7, 7),activation='relu', padding='same'))\nmodel.add(Conv2D(512, kernel_size=(7, 7),activation='relu', padding='same'))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nhistory = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","9fd74b1b":"fig,ax = plt.subplots(1,1)\nax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n\n# list of epoch numbers\nx = list(range(1,epochs+1))\n\nvy = history.history['val_loss']\nty = history.history['loss']\nplt_dynamic(x, vy, ty, ax)","944c3a80":"from prettytable import PrettyTable\n\ntable = PrettyTable()\ntable.field_names = ['# Conv Layers', 'Filter Size', 'Test Loss', 'Test Accuracy']\ntable.add_row([3, '(3, 3)', 0.0259, 0.992])\ntable.add_row([5, '(5, 5)', 0.0187, 0.9955])\ntable.add_row([7, '(7, 7)', 0.0237, 0.994])\nprint(table)","a37fdbc0":"## Model 2:\nArchitecture:-\nInput (28,28,1) ->(5, 5) Conv, 32 -> (5, 5) Conv, 64 -> Pool\/2 ->(5, 5) Conv, 96 -> (5, 5) Conv, 128 -> (5, 5) Conv, 224 ->\nDropout (0.3) -> Flatten -> Dense, 256 -> Dropout (0.5) -> Softmax\n\n","7a194713":"## Model 1:\nArchitecture:-\nInput (28,28,1) ->(3, 3) Conv, 32 -> (3, 3) Conv, 64 -> Pool\/2 ->(3, 3) Conv, 128 ->Dropout (0.25) -> Flatten -> Dense, 256 -> Dropout (0.5) -> Softmax","853a639d":"## Conclustion:","38be06ff":"## Assignment","6c8208dd":"## Model 3:\nArchitecture:-\nInput (28,28,1) ->(7, 7) Conv, 32 -> (7, 7) Conv, 64 -> Pool\/2 ->(7, 7) Conv, 96 -> (7, 7) Conv, 128 -> Pool\/2 ->(7, 7) Conv, 224 -> (7, 7) Conv, 256 -> (7, 7) Conv, 256 ->Dropout (0.3) -> Flatten -> Dense, 256 -> Dropout (0.5) -> Softmax"}}