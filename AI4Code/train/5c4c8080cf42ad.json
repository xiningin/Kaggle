{"cell_type":{"847e9817":"code","135e85da":"code","173f7dab":"code","8a9bf5cc":"code","53a9e6d4":"code","25defa67":"code","b1f3e434":"code","6114c536":"code","53da54b6":"code","c9721bb5":"code","e953f97b":"code","a099c691":"code","f0e72aba":"code","ea755f90":"code","37b801bb":"code","7f166872":"code","0b155287":"code","ac8e58f4":"code","2ecc8488":"code","57577b02":"code","1b881ca9":"code","4a809624":"code","d8147b2d":"code","dc82bf9d":"code","08bd7630":"code","439f8aaa":"code","8f77f18f":"code","367ecd6b":"code","f56cc8e9":"code","f5516d96":"code","b9936e2d":"code","a4c5dd2d":"code","6acb1604":"code","021bacdf":"code","f0018fc4":"code","d08b2e4a":"code","5f3b44b7":"markdown","26939223":"markdown","90352b9b":"markdown","bdd793ad":"markdown","2adcc27a":"markdown","829bb72c":"markdown","9b14fad6":"markdown","00f8f015":"markdown","dce1eb67":"markdown","ef3faeae":"markdown","e00da090":"markdown","10349bbe":"markdown","5b2a9621":"markdown","fddebc93":"markdown","bd331906":"markdown","27446875":"markdown","c695dbe0":"markdown","657e260d":"markdown","1c90ce73":"markdown","5bfb9127":"markdown","c9f32892":"markdown","d34b26ac":"markdown","1d392c25":"markdown","9a50d045":"markdown","18faaa01":"markdown","a0719159":"markdown"},"source":{"847e9817":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","135e85da":"# Let us import the libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\n#data visualization\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns # data visualization\nimport bokeh as bk\nimport seaborn as sns\nimport matplotlib.pylab as plt\nimport plotly.express as px\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport gc\n\n\n# Machine Learning Algo\/Models\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB","173f7dab":"from tqdm import tqdm\n\n# Load data\ntrain_df = pd.read_csv(\"..\/input\/widsdatathon2021\/TrainingWiDS2021.csv\")\ntest_df = pd.read_csv(\"..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")\ndata_dictionary_df = pd.read_csv(\"..\/input\/widsdatathon2021\/DataDictionaryWiDS2021.csv\")\nsample_sub_df = pd.read_csv(\"..\/input\/widsdatathon2021\/SampleSubmissionWiDS2021.csv\")\nsol_temp_df = pd.read_csv(\"..\/input\/widsdatathon2021\/SolutionTemplateWiDS2021.csv\")\n\n# Drop first column because it is identical to index\ntrain_df.drop(\"Unnamed: 0\", axis = 1, inplace = True)\ntest_df.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n\ntrain_df.head().style.set_caption('Sample of training data')\ntest_df.head().style.set_caption('Sample of test data')\ndata_dictionary_df.head().style.set_caption('Sample of Data Dictionary data')\nsample_sub_df.head().style.set_caption('Sample of Sample Submission data')\nsol_temp_df.head().style.set_caption('Sample of Solution Template data')\ndata_dictionary_df.head(100).style.set_caption('Sample of Data Dictionary data')\ndata_dictionary_df.tail(100).style.set_caption('Sample of Data Dictionary data')\n\n","8a9bf5cc":"train_df.columns\n","53a9e6d4":"date = 0\nn_features = 180\n\nfeatures = [f'feature_{i}' for i in range(0, n_features)]\nfig = px.histogram(train_df, x=features, \n                   animation_frame=train_df.columns, range_y=[0, 600], range_x=[-7, 7])\nfig.show()","25defa67":"train_df.info(verbose=True, null_counts=True)","b1f3e434":"# Number of each type of column\ntrain_df.dtypes.value_counts()","6114c536":"# Number of unique classes in each object column\ntrain_df.select_dtypes('object').apply(pd.Series.nunique, axis = 0)","53da54b6":"#Missing Value Counts\n\nmis_val = train_df.isnull().sum()\n# Percentage of missing values\nmis_val_percent = 100 * train_df.isnull().sum() \/ len(train_df)\n# Make a table with the results\nmis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n# Rename the columns\nmis_val_table_ren_columns = mis_val_table.rename(\ncolumns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n# Sort the table by percentage of missing descending\nmis_val_table_ren_columns = mis_val_table_ren_columns[\n    mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n    '% of Total Values', ascending=False).round(1)\n        \n# Print some summary information\nprint (\"Your selected dataframe has \" + str(train_df.shape[1]) + \" columns.\\n\"  +\n       \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n       \" columns that have missing values.\")\n# Missing values for training data\nmis_val_table_ren_columns[:20].style.background_gradient(cmap='Blues')\n","c9721bb5":"\nplt.figure(figsize=(10,6))\nplt.title(\"Ethnicity vs People suffering from Diabetes\")\nsns.lineplot(train_df[\"ethnicity\"],train_df[\"diabetes_mellitus\"])\nplt.xlabel(\"Ethnicity\")\nplt.ylabel(\"Number of People Suffering from Diabetes\")\n","e953f97b":"plt.figure(figsize=(10,6))\nplt.title(\"BMI vs People suffering from Diabetes\")\nsns.lineplot(train_df[\"bmi\"],train_df[\"diabetes_mellitus\"])\nplt.xlabel(\"BMI\")\nplt.ylabel(\"Number of People Suffering from Diabetes\")\n","a099c691":"\nplt.figure(figsize=(10,6))\nplt.title(\"Height vs People suffering from Diabetes\")\nsns.lineplot(train_df[\"height\"],train_df[\"diabetes_mellitus\"])\nplt.xlabel(\"Height\")\nplt.ylabel(\"Number of People Suffering from Diabetes\")","f0e72aba":"colors_list = ['#5cb85c','#5bc0de','#d9534f']\n# Normalize result\nresult_pct = train_df[\"gender\"].value_counts(normalize=True)*100\nax = result_pct.plot(kind='bar',figsize=(15,4),width = 0.8,color = colors_list,edgecolor=None)\nax.set_title(\"Gender vs People suffering from Diabetes\")\nax.set_ylim([0, 100])\nax.set_ylabel('Percentage of Patients[%]', fontsize=14)\nax.set_xticklabels(['Male', 'Female'], fontsize=14, rotation=0)\n#plt.legend(labels=train_df.columns,fontsize= 14)\nplt.xticks(fontsize=14)\nfor spine in plt.gca().spines.values():\n    spine.set_visible(False)\nplt.yticks([])\n\n# Add this loop to add the annotations\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height() \/ 100 \n    x, y = p.get_xy() \n    ax.annotate(f'{height:00.00%}', (x + width\/2, y + height*50.02), ha='center')\n\nplt.show()","ea755f90":"train_df[\"gender\"] = train_df[\"gender\"].fillna(\"Unknown\")\ntrain_df[\"ethnicity\"] = train_df[\"ethnicity\"].fillna(\"Other\/Unknown\")\n\ntest_df[\"gender\"] = test_df[\"gender\"].fillna(\"Unknown\")\ntest_df[\"ethnicity\"] = test_df[\"ethnicity\"].fillna(\"Other\/Unknown\")","37b801bb":"train_df1 = train_df.fillna(train_df.median())\ntrain_df1","7f166872":"train_df1.isnull().sum()","0b155287":"import plotly.express as px\nfig = px.histogram(train_df1[['age','gender','hospital_admit_source','bmi']].head(10000), #.dropna(), \n                   x=\"age\", y=\"hospital_admit_source\", color=\"gender\",\n                   marginal=\"violin\", # or violin, rug\n                   hover_data=train_df1[['age','gender','hospital_admit_source','bmi']].columns)\nfig.show()","ac8e58f4":"p = sns.catplot(x = 'diabetes_mellitus', hue = 'ethnicity', data = train_df1, kind = 'count')\nplt.show()","2ecc8488":"p = sns.catplot(x = 'diabetes_mellitus', hue = 'gender', data = train_df1, kind = 'count')\nplt.show()","57577b02":"plot_vals= ['aids', 'cirrhosis','hepatic_failure', 'immunosuppression', \n            'leukemia', 'lymphoma','solid_tumor_with_metastasis', 'diabetes_mellitus']\n\nfor pl in plot_vals:\n    p = sns.catplot(x = pl, hue = 'gender', data = train_df1, kind = 'count')\n    plt.show()\n","1b881ca9":"from catboost import Pool, cv, CatBoostClassifier, CatBoostRegressor\n","4a809624":"from pandas_profiling import ProfileReport\n","d8147b2d":"trainprofile = ProfileReport(train_df1,'EDA')\ntrainprofile","dc82bf9d":"## Print the categorical columns\nprint([c for c in train_df1.columns \n       if (1<train_df1[c].nunique()) & \n       (train_df1[c].dtype != np.number)& \n       (train_df1[c].dtype != int) ])","08bd7630":"categorical_cols =  ['hospital_id',\n 'ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type']","439f8aaa":"## Handle na values\ntrain_df1[categorical_cols] = train_df1[categorical_cols].fillna(\"\")\ntest_df[categorical_cols] = test_df[categorical_cols].fillna(\"\")\n\ntrain_df1[categorical_cols].isna().sum()\n","8f77f18f":"TARGET_COL = \"diabetes_mellitus\"\n\n## Train Test split and remove Target values\nX_train = train_df1.drop([TARGET_COL],axis=1)\ny_train = train_df1[TARGET_COL]","367ecd6b":"## catBoost Pool object\ntrain_pool = Pool(data=X_train,label = y_train,cat_features=categorical_cols)","f56cc8e9":"model_basic = CatBoostClassifier(verbose=False,iterations=500,learning_rate=0.1, task_type=\"GPU\",)\nmodel_basic.fit(train_pool, plot=True,silent=True)\nprint(model_basic.get_best_score())","f5516d96":"### hyperparameter tuning example grid for catboost : \ngrid = {'learning_rate': [0.04, 0.1],\n        'depth': [7, 11],\n         'l2_leaf_reg': [1, 3,9],\n        \"iterations\": [500],\n       \"custom_metric\":['Logloss', 'AUC']}\n\nmodel = CatBoostClassifier()\n\n## can also do randomized search - more efficient typically, especially for large search space - `randomized_search`\ngrid_search_result = model.grid_search(grid, \n                                      train_pool,\n                                      plot=True,\n                                      refit = True, #  refit best model on all data\n                                      partition_random_seed=42)\n\nprint(model.get_best_score())","b9936e2d":"test_df[TARGET_COL] = model.predict(test_df,prediction_type='Probability')[:,1]","a4c5dd2d":"test_df[[\"encounter_id\",\"diabetes_mellitus\"]].to_csv(\"submission.csv\",index=False)","6acb1604":"obj_cols = [columns for columns in train_df.columns if train_df[columns].dtypes == 'object']\nnum_cols = [columns for columns in train_df.columns if train_df[columns].dtypes != 'object']\nprint(obj_cols)\nprint(num_cols)","021bacdf":"fig = px.imshow(train_df[num_cols].corr())\nfig.show()","f0018fc4":"sns.pairplot(train_df1[num_cols], hue=\"lymphoma\")\n\nfig=sns.PairGrid(data=train_df1[num_cols])\nfig.map_upper(sns.scatterplot, data=train_df1[num_cols], color='fuchsia',alpha=0.5)\nfig.map_lower(sns.kdeplot, data=train_df1[num_cols], cmap='Spectral')\nfig.map_diag(sns.scatterplot, data=train_df1[num_cols], color='navy',alpha=0.7)\n\nsns.heatmap(data=train_df[num_cols], annot=True, fmt='g')","d08b2e4a":"status","5f3b44b7":"### Let us explore a line plot on Ethnicity","26939223":"### Let us try a plotly histogram","90352b9b":"### What are the object data types and how many unique elements are there? ","bdd793ad":"### Load the Datasets\n#### Drop unwanted columns\n#### Define data dictionary captions\n#### Let us examine the head and tail of the dictionary","2adcc27a":"### Let us finetune the parameters","829bb72c":"### Let us explore a line plot on Height","9b14fad6":"### Let us import Catboost Libraries","00f8f015":"## Let us define all the libaries for usage","dce1eb67":"### Let us explore a line plot on BMI","ef3faeae":"### What are the data types in use? ","e00da090":"### Let us get the best score","10349bbe":"### Let us set the target column for training","5b2a9621":"### Let us check correlated chart","fddebc93":"### Let us try some seaborn pairplots, pairgrids and heatmaps","bd331906":"### Fill the predicted values to submission file","27446875":"### Let us try some Seaborn Category plots","c695dbe0":"### Find the empty value count in categorical columns and fill blanks.","657e260d":"### Let us print Categorical Columns","1c90ce73":"#### How does the histogram look like for the taining dataset for the features? ","5bfb9127":"## WIDS Datathon Kernel\n\n### Let us first initiate the Kaggle environments","c9f32892":"### Let us explore the columns","d34b26ac":"#### Let us perform some missing value analysis ","1d392c25":"## Let us fill blank values with standard summary","9a50d045":"### Get the prediction values","18faaa01":"## Try a Pandas ProfileReport Summary","a0719159":"### Let us explore a barchart on Gender comparison"}}