{"cell_type":{"bf536b87":"code","afb3831e":"code","4ace0a96":"code","dbf349f6":"code","7265d846":"code","49417ce6":"code","39bc3333":"code","9f137a09":"code","e94a3b87":"code","3e4b64f2":"code","f620ac01":"code","b807f14f":"code","2bef6a44":"code","54715528":"code","dd5f099e":"code","0514aa14":"code","86f51ddd":"code","0200c6be":"code","a0767107":"code","7dc16d4d":"code","10e02f61":"code","23d268df":"code","a16d4327":"code","33df1d5a":"code","50664a06":"code","e7296882":"code","d3c098d7":"code","5669be2e":"code","c02ce671":"code","2a4dadab":"code","a8cabbb4":"code","9f2b4e51":"code","ca8c63fb":"code","cec5494e":"code","7a648cf1":"code","2d1acfb0":"code","8d07f9a6":"code","ed98aa56":"code","14a9bf5f":"markdown","3f80dd58":"markdown","956a5870":"markdown","a71d09cd":"markdown"},"source":{"bf536b87":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","afb3831e":"df_bcell=pd.read_csv(\"..\/input\/epitope-prediction\/input_bcell.csv\")\ndf_covid=pd.read_csv(\"..\/input\/epitope-prediction\/input_covid.csv\")\ndf_sars=pd.read_csv(\"..\/input\/epitope-prediction\/input_sars.csv\")","4ace0a96":"df_bcell.head()","dbf349f6":"df_bcell.tail()","7265d846":"df_bcell.isna().sum()","49417ce6":"df_bcell.dtypes","39bc3333":"from sklearn.preprocessing import LabelEncoder\nlabelEncoder_Y=LabelEncoder()\ndf_bcell.iloc[:,0]=labelEncoder_Y.fit_transform(df_bcell.iloc[:,0].values)\ndf_bcell.iloc[:,1]=labelEncoder_Y.fit_transform(df_bcell.iloc[:,1].values)\ndf_bcell.iloc[:,4]=labelEncoder_Y.fit_transform(df_bcell.iloc[:,4].values)","9f137a09":"df_bcell.head()","e94a3b87":"df_bcell.dtypes","3e4b64f2":"#visualize the correlation\nplt.figure(figsize=(10,10))\nsns.heatmap(df_bcell.corr(), annot=True,fmt=\".0%\")\nplt.show()","f620ac01":"df_covid.head()","b807f14f":"df_covid.tail()","2bef6a44":"df_covid.isna().sum()","54715528":"df_covid.dtypes","dd5f099e":"from sklearn.preprocessing import LabelEncoder\nlabelEncoder_Y=LabelEncoder()\ndf_covid.iloc[:,0]=labelEncoder_Y.fit_transform(df_covid.iloc[:,0].values)\ndf_covid.iloc[:,1]=labelEncoder_Y.fit_transform(df_covid.iloc[:,1].values)\ndf_covid.iloc[:,4]=labelEncoder_Y.fit_transform(df_covid.iloc[:,4].values)","0514aa14":"df_covid.head()","86f51ddd":"df_covid.dtypes","0200c6be":"#visualize the correlation\nplt.figure(figsize=(10,10))\nsns.heatmap(df_covid.corr(), annot=True,fmt=\".0%\")\nplt.show()","a0767107":"df_sars.head()","7dc16d4d":"df_sars.tail()","10e02f61":"df_sars.isna().sum()","23d268df":"df_sars.dtypes","a16d4327":"from sklearn.preprocessing import LabelEncoder\nlabelEncoder_Y=LabelEncoder()\ndf_sars.iloc[:,0]=labelEncoder_Y.fit_transform(df_sars.iloc[:,0].values)\ndf_sars.iloc[:,1]=labelEncoder_Y.fit_transform(df_sars.iloc[:,1].values)\ndf_sars.iloc[:,4]=labelEncoder_Y.fit_transform(df_sars.iloc[:,4].values)","33df1d5a":"df_sars.head()","50664a06":"df_sars.dtypes","e7296882":"#visualize the correlation\nplt.figure(figsize=(10,10))\nsns.heatmap(df_sars.corr(), annot=True,fmt=\".0%\")\nplt.show()","d3c098d7":"#Split the data set into independent(x) and dependent (y) data sets\nx=df_bcell.iloc[:,1:14].values\ny=df_bcell.iloc[:,0].values.reshape(-1,1)\nx_test  = df_sars.drop(\"parent_protein_id\",axis=1).copy()","5669be2e":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.469,random_state=42)","c02ce671":"#scale the data(feature scaling)\nfrom sklearn.preprocessing import StandardScaler\n\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.fit_transform(x_test)","2a4dadab":"x_train.shape","a8cabbb4":"x_test.shape","9f2b4e51":"y_train.shape","ca8c63fb":"y_test.shape","cec5494e":"def models(x_train,y_train):\n  #Logistic Regression Model\n  from sklearn.linear_model import LogisticRegression\n  log=LogisticRegression(random_state=42)\n  log.fit(x_train,y_train)\n  \n  #Decision Tree\n  from sklearn.tree import DecisionTreeClassifier\n  tree=DecisionTreeClassifier(criterion='entropy',random_state=0)\n  tree.fit(x_train,y_train)\n  \n  #Random Forest Classifier\n  from sklearn.ensemble import RandomForestClassifier\n  forest = RandomForestClassifier(n_estimators=15,criterion=\"entropy\",random_state=0)\n  forest.fit(x_train,y_train)\n\n  #Print the models accuracy on the training data\n  print(\"[0]Logistic Regression Training Accuracy:\",log.score(x_train,y_train))\n  print(\"[1]Decision Tree Classifier Training Accuracy:\",tree.score(x_train,y_train))\n  print(\"[2]Random Forest Classifier Training Accuracy:\",forest.score(x_train,y_train))\n  \n  return log,tree,forest","7a648cf1":"#Getting all of the models\nmodel = models(x_train,y_train)","2d1acfb0":"#test model accuracy on confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\n\nfor i in range(len(model)):\n  print(\"Model \", i)\n  cm =confusion_matrix(y_test,model[i].predict(x_test))\n\n  TP=cm[0][0]\n  TN=cm[1][1]\n  FN=cm[1][0]\n  FP=cm[0][1]\n\n  print(cm)\n  print(\"Testing Accuracy = \", (TP+TN) \/ (TP+TN+FN+FP))\n  print()","8d07f9a6":"#show another way to get metrics of the models\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nfor i in range(len(model) ):\n  print(\"Model \",i)\n  print( classification_report(y_test,model[i].predict(x_test)))\n  print( accuracy_score(y_test,model[i].predict(x_test)))\n  print()","ed98aa56":"pred=model[2].predict(x_test)\nprint(pred)","14a9bf5f":"# COVID","3f80dd58":"# BCELL","956a5870":"# BCELL VS SARS","a71d09cd":"# SARS"}}