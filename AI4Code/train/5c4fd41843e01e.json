{"cell_type":{"0b764d09":"code","c4048280":"code","afd0d771":"code","5fbd3dcc":"code","451cdbe1":"code","e5392bcb":"code","3ef17162":"code","37133ac7":"code","8e401244":"code","ef6f7d23":"code","0d4d9aa4":"code","ad6bf15c":"code","5f75d634":"code","ac35f0ec":"code","44698555":"markdown","728723a6":"markdown","1065e2f0":"markdown","1c68a90d":"markdown","5c8acd9b":"markdown"},"source":{"0b764d09":"#Importing Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","c4048280":"#Loading Train_Set\ndf_train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndf_train.head()","afd0d771":"#Split pixel data & label\nX_train = df_train.iloc[:,1:].values\ny_train = df_train.iloc[:,0].values","5fbd3dcc":"#Visual of the 1st image\nfirst_image = X_train[0].reshape(28,28)\nplt.imshow(first_image,cmap='gist_gray')","451cdbe1":"print(X_train.shape)\nprint(X_train.min())\nprint(X_train.max())","e5392bcb":"#Change dimension of all the images\n#For a single image, instead of the pixels being in an array(784,1) we prefer it in the format (28,28)\n#For 42000 images ~ (42000,28,28) and For gray scale ~ (42000,28,28,1)\n#Had it been a coloured image, the dimesion would have been ~ (42000,28,28,3)[3 for RGB]\n#To normalize the magnitudes of the pixels we diivide all the pixels by 255\nX_train = X_train.reshape(-1,28,28,1)\/255\nprint(X_train.shape)\nprint(X_train.min())\nprint(X_train.max())","3ef17162":"#One_Hot_Encode (using Keras API instead of sklearn)\ny_train = tf.keras.utils.to_categorical(y_train)\nprint(y_train)","37133ac7":"#Initialise CNN\ncnn = tf.keras.models.Sequential()","8e401244":"#Convolution Layer\ncnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=5,activation='relu',input_shape=[28,28,1]))\n\n#Max-Pooling\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n\n#Second Conolution Layer\ncnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=5,activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))","ef6f7d23":"#Flattening\ncnn.add(tf.keras.layers.Flatten())\n\n#Fully Connected Layer\ncnn.add(tf.keras.layers.Dense(units=128,activation='relu'))\n\n#Hidden Layer\ncnn.add(tf.keras.layers.Dense(units=128,activation='relu'))\n\n#Output Layer\ncnn.add(tf.keras.layers.Dense(units=10,activation='softmax'))\n\n#Compilation\ncnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","0d4d9aa4":"#Training the Model\ncnn.fit(X_train,y_train,batch_size=32,epochs=5)","ad6bf15c":"#Loading the Test Set\nX_test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","5f75d634":"#Prediction\ny_prob = cnn.predict(X_test.iloc[:,:].values.reshape(-1,28,28,1)\/255)\npred_digit = np.argmax(y_prob, axis=1)\npred_digit = pd.Series(pred_digit,name='Label')\nprint(pred_digit)","ac35f0ec":"#Submission for Kaggle Competition\npred = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),pred_digit],axis = 1)\npred.to_csv(\"submission.csv\",index=False)","44698555":"# B. Building the Convolution Neural Networks","728723a6":"**Accuracy achieved 98.93%**","1065e2f0":"# Prediction & Evaluation","1c68a90d":"# A. Data Processing","5c8acd9b":"# **Digit Recognition using Convolution Neural Networks. Achieved an accuracy of 98.93%**"}}