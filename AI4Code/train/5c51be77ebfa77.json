{"cell_type":{"eb5c9aca":"code","4e8848f1":"code","aaea9427":"code","f5f8c957":"code","2c6cda11":"code","30a5d682":"code","e6f38414":"code","3ec74468":"code","00efba66":"code","e74d41e4":"code","7e9f803d":"code","658fa130":"code","d827c037":"code","36f300f6":"code","28a743ce":"code","7bb9c0a3":"code","562a0d2d":"code","c3c4d738":"code","b05ba975":"code","34c86696":"code","48737d77":"code","e86b39b0":"code","f8aeae22":"code","89766e6f":"code","a4573559":"code","3fc54535":"code","e457a2fe":"code","c9b7c996":"code","9bdb7cf8":"code","1766e648":"code","1baa6341":"code","84e90dbd":"code","92fea328":"code","a5652a03":"code","9a2e4d1e":"code","44153841":"code","6987b51b":"code","9303577f":"code","fffe8886":"code","64b61565":"code","a73c670e":"code","a2688239":"code","c265e65b":"code","3e93411f":"code","8b55e7e8":"markdown","1646a392":"markdown","14a6924d":"markdown","0ececddb":"markdown","5f4c03d7":"markdown","3bd4c7cb":"markdown","aae905cb":"markdown","07ae4685":"markdown","dedf4b8d":"markdown","3b4a44ee":"markdown","e15eec7c":"markdown","11887206":"markdown"},"source":{"eb5c9aca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4e8848f1":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport plotly.express as px\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\nimport lightgbm as lgb\nfrom lightgbm import plot_importance\nimport xgboost as xgb\n\n\n\nplt.style.use('seaborn')\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","aaea9427":"df_train = pd.read_csv('\/kaggle\/input\/santander-customer-transaction-prediction\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/santander-customer-transaction-prediction\/test.csv')","f5f8c957":"df_train.head(10)","2c6cda11":"df_train.tail()","30a5d682":"df_test.head()","e6f38414":"df_test.tail()","3ec74468":"col_features = df_train.drop(['ID_code','target'],axis=1)","00efba66":"df_train.shape","e74d41e4":"df_train.describe()","7e9f803d":"df_train.info()","658fa130":"f, ax = plt.subplots(1,2,figsize=(10,4))\n\ndf_train['target'].value_counts().plot.pie(\n    explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True\n)\n\nsns.countplot('target', data=df_train, ax=ax[1])\n\nplt.show()","d827c037":"null_value = df_train.isnull().sum().sort_values(ascending = False)\nnull_percent = round(df_train.isnull().sum().sort_values(ascending = False)\/len(df_train)*100, 2)\n\npd.concat([null_value,null_percent], axis=1,keys=['Null values','Percent'])","36f300f6":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per row in the train and test set\")\n\nsns.distplot(df_train[col_features.columns].mean(axis=1),color=\"black\", kde=True,bins=120, label='train')\nsns.distplot(df_test[col_features.columns].mean(axis=1),color=\"red\", kde=True,bins=120, label='test')\n\nplt.legend()\nplt.show()","28a743ce":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per column in the train and test set\")\n\nsns.distplot(df_train[col_features.columns].mean(),color=\"black\", kde=True,bins=120, label='train')\nsns.distplot(df_test[col_features.columns].mean(),color=\"red\", kde=True,bins=120, label='test')\n\nplt.legend()\nplt.show()","7bb9c0a3":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of std values per rows in the train and test set\")\n\nsns.distplot(df_train[col_features.columns].std(axis=1),color=\"blue\",kde=True,bins=120, label='train')\nsns.distplot(df_test[col_features.columns].std(axis=1),color=\"green\", kde=True,bins=120, label='test')\n\nplt.legend()\nplt.show()","562a0d2d":"train_df_0 = df_train[df_train['target'] == 0]\ntrain_df_1 = df_train[df_train['target'] == 1]\n\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of skew values per row in the train set\")\n\nsns.distplot(train_df_0[col_features.columns].skew(axis=1),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(train_df_1[col_features.columns].skew(axis=1),color=\"blue\", kde=True,bins=120, label='target = 1')\n\nplt.legend()\nplt.show()","c3c4d738":"train_df_0 = df_train[df_train['target'] == 0]\ntrain_df_1 = df_train[df_train['target'] == 1]\n\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of skew values per column in the train set\")\n\nsns.distplot(train_df_0[col_features.columns].skew(),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(train_df_1[col_features.columns].skew(),color=\"blue\", kde=True,bins=120, label='target = 1')\n\nplt.legend()\nplt.show()","b05ba975":"df_train.drop('ID_code', axis=1, inplace=True)\ndf_test.drop('ID_code', axis=1, inplace=True)","34c86696":"df_train.head(10)","48737d77":"X = df_train.drop(['target'], axis=1)\ny = df_train['target']","e86b39b0":"scaler = StandardScaler()\nX_scaler = scaler.fit_transform(X)\nX_scaler_df = pd.DataFrame(X_scaler, columns=X.columns)","f8aeae22":"pca = PCA(n_components=2)\nx_scaler_pca = pca.fit_transform(X_scaler)\nx_scaler_pca_df = pd.DataFrame(x_scaler_pca)","89766e6f":"test_scaler = StandardScaler()\ntrans_test_scaler = test_scaler.fit_transform(df_test)\ntrans_test_scaler_df = pd.DataFrame(trans_test_scaler, columns=df_test.columns)","a4573559":"x_scaler_pca_df.head()","3fc54535":"pca.explained_variance_ratio_","e457a2fe":"sum(pca.explained_variance_ratio_)","c9b7c996":"x_scaler_pca_df['target'] = y","9bdb7cf8":"plt.scatter(x_scaler_pca_df.loc[:, 0], x_scaler_pca_df.loc[:, 1], c=y,  cmap=\"copper_r\")\n\nplt.axis('off')\n\nplt.colorbar()\n\nplt.show()","1766e648":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)","1baa6341":"print(\"Train Dataset shape {} \/ {}\".format(x_train.shape, y_train.shape))\nprint(\"Test Dataset shape {} \/ {}\".format(x_test.shape, y_test.shape))","84e90dbd":"train_data = lgb.Dataset(x_train, label=y_train)\nval_data = lgb.Dataset(x_test, label=y_test)\nparams = {\n    'n_estimators': 5000,\n    'num_leaves': 20,\n    'max_depth': -1,\n    'min_data_in_leaf': 80,\n    'learning_rate': 0.01,\n    'boosting': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'Is_training_metric': True,\n    'n_jobs': -1\n}","92fea328":"model = lgb.train(params,\n                  train_data,\n                  valid_sets=val_data, \n                  valid_names=['train','valid'],\n                  early_stopping_rounds=100)","a5652a03":"submission = pd.read_csv('\/kaggle\/input\/santander-customer-transaction-prediction\/sample_submission.csv')","9a2e4d1e":"submission.head()","44153841":"target = model.predict(df_test)","6987b51b":"submission['target'] = target","9303577f":"submission.head()","fffe8886":"submission.to_csv('submission.csv', index=False)","64b61565":"scaler_submission = pd.read_csv('\/kaggle\/input\/santander-customer-transaction-prediction\/sample_submission.csv')","a73c670e":"scaler_submission.head()","a2688239":"scaler_target = model.predict(trans_test_scaler_df)","c265e65b":"scaler_submission['target'] = scaler_target","3e93411f":"scaler_submission.to_csv('scaler_submission.csv', index=False)","8b55e7e8":"# Now Preprocessing Part","1646a392":"# Now Predict","14a6924d":"# Now Some Visualization ","0ececddb":"# Now Some EDA Part","5f4c03d7":"# Now Part Modeling","3bd4c7cb":"# Now Standard Scaler the data","aae905cb":"# Now See head and tail of the dataset","07ae4685":"# Now Test Data Standard Scaler the data","dedf4b8d":"# Now Feature Egineering","3b4a44ee":"# Now Submission Part","e15eec7c":"# Now Check Null Values","11887206":"# Now Import Some Important Libs for this Project"}}