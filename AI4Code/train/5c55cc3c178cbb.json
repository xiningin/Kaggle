{"cell_type":{"36264d63":"code","69c1b564":"code","bec96154":"code","a4d81909":"code","771badb6":"code","8694ccef":"code","cd5b7cab":"code","9098d5e4":"code","72ee0ab5":"code","3f94e43b":"code","8b4a2e1a":"code","adbc4906":"code","bdb68844":"code","8baceb10":"code","e6dd5047":"code","72ff6804":"code","79c5a3e5":"code","3e06eafa":"code","980b1bca":"code","7a62479a":"markdown","3f92db07":"markdown","31a9dd25":"markdown","139a17c5":"markdown","db59c488":"markdown","8038b598":"markdown","8248e922":"markdown","e5c41902":"markdown","282b6f9c":"markdown"},"source":{"36264d63":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","69c1b564":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPool2D,BatchNormalization","bec96154":"train_df = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_df = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","a4d81909":"train_df.head(5)","771badb6":"test_df.head(5)","8694ccef":"print(train_df.shape)","cd5b7cab":"print(test_df.shape)","9098d5e4":"X = train_df.drop('label',axis=1)\ny = train_df['label']\nX = X.values.reshape(-1,28,28,1)\nX = X\/255\ny = to_categorical(y)\nprint(plt.imshow(X[2][:,:,0]))\nprint(str(y[1]))","72ee0ab5":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=123)","3f94e43b":"datagen = ImageDataGenerator(zoom_range = 0.1, width_shift_range = 0.1, height_shift_range = 0.1, rotation_range = 10) ","8b4a2e1a":"model = Sequential()","adbc4906":"model = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size = (5, 5), activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(strides = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 64, kernel_size = (5, 5), activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(strides = (2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1024, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = 'softmax'))","bdb68844":"model.compile(optimizer='adam',metrics=['accuracy'],loss='categorical_crossentropy')","8baceb10":"reduction_lr = ReduceLROnPlateau(monitor='val_accuracy',patience=2, verbose=1, factor=0.2, min_lr=0.00001)","e6dd5047":"hist = model.fit_generator(datagen.flow(X_train,y_train,batch_size=32),epochs=20,validation_data = (X_test,y_test),callbacks=[reduction_lr])","72ff6804":"loss = pd.DataFrame(model.history.history)\nloss[['loss', 'val_loss']].plot()\nloss[['accuracy', 'val_accuracy']].plot()","79c5a3e5":"final_loss, final_acc = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))","3e06eafa":"test_df = test_df.values.reshape(-1, 28, 28, 1) \/ 255\ny_pred = model.predict(test_df, batch_size = 64)\n\ny_pred = np.argmax(y_pred,axis = 1)\ny_pred = pd.Series(y_pred,name=\"Label\")\ny_pred","980b1bca":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),y_pred],axis = 1)\nsubmission.to_csv(\"submission.csv\",index=False)","7a62479a":"**Submission**","3f92db07":"**If You find This is useful,please UPVOTE.**","31a9dd25":"**Building Model**","139a17c5":"**Training a Model**","db59c488":"**Importing libraries**","8038b598":"**Compiling Model**","8248e922":"**Spliting into train and test set**","e5c41902":"**Testing a Model**","282b6f9c":"**Reducing Learning Rate**"}}