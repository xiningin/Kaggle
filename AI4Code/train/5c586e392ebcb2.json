{"cell_type":{"30b75291":"code","db5d19cc":"code","f6c89aff":"code","63f090d4":"code","25e1df7b":"code","88f713dc":"code","2d06d751":"code","962dfe48":"code","9cc4a23b":"code","2be671aa":"code","49794be1":"code","fba68b92":"code","b6425803":"code","285d8237":"code","dbd415fa":"code","6dd749a3":"code","d15e953b":"code","a0fc27da":"code","21be6e9d":"code","d1fd6aa6":"code","36e84014":"code","14d573e9":"code","3bde8cc4":"code","27662bda":"code","c055d77a":"code","10dbaf46":"code","6d2210ca":"code","ebde52a0":"code","b37e3369":"code","712f3dce":"code","641ee88a":"code","b4e42c02":"code","057c746c":"code","c1929258":"code","5c8d8e53":"code","1851d9df":"markdown","64c19006":"markdown","5de4e966":"markdown","7a61886b":"markdown","545722bb":"markdown","94ed1168":"markdown","7f3f84b0":"markdown","cccf08ac":"markdown","ddf377ae":"markdown","06b9c724":"markdown","c29251bb":"markdown","8ff2b888":"markdown","1e686b6a":"markdown"},"source":{"30b75291":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _ , filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","db5d19cc":"import seaborn as sns, pandas as pd, numpy as np, matplotlib.pyplot as plt\n","f6c89aff":"train = pd.read_csv('..\/input\/dry-beans-classification-iti-ai-pro-intake01\/train.csv',index_col = 'ID')\ntest = pd.read_csv('..\/input\/dry-beans-classification-iti-ai-pro-intake01\/test.csv',index_col = 'ID')","63f090d4":"train.head()","25e1df7b":"train.dtypes\n","88f713dc":"train.isnull().sum()","2d06d751":"train.info()","962dfe48":"train.describe()","9cc4a23b":"train.corr()","2be671aa":"import missingno as no\nno.bar(train)","49794be1":"plt.figure(figsize=(14,8))\nplt.style.use('seaborn-darkgrid')\nsns.countplot(x=train.y, palette='Set2')\nplt.show()","fba68b92":"plt.figure(figsize=(10,8))\nsns.scatterplot(x=train.roundness , y=train['ConvexArea'], hue=train.y )\nplt.show()","b6425803":"plt.figure(figsize=(18,6))\nsns.violinplot(x=train.y, y=train.Compactness, palette='Dark2')\nplt.show()","285d8237":"COLUMNS = train.columns.tolist()\nfeature_cols = COLUMNS[:-1]\nCOLUMNS","dbd415fa":"fig, ax_list = plt.subplots(nrows=4, ncols=4, sharey=False, figsize=(36,36))\nax_list = ax_list.flatten()\nfor name, ax in zip(feature_cols, ax_list):\n     g = sns.histplot(train, x=name, bins=10, ax=ax).set(title=name)","6dd749a3":"feature_columns = [col for col in train.columns if col not in ['y']]\n\nskew_columns = (train[feature_columns].skew().sort_values(ascending=False))\nskew_columns = skew_columns.loc[skew_columns > 0.7]\nskew_columns","d15e953b":"col= ['ShapeFactor4', 'Solidity', 'Eccentricity', 'roundness']  \nfrom sklearn.preprocessing import PowerTransformer\npower = PowerTransformer(method='yeo-johnson', standardize=True)\nfor c in col:\n    train[c] = power.fit_transform(train[[c]])\n    test[c] = power.transform(test[[c]])\n    \n\n    ","a0fc27da":"from sklearn.preprocessing import StandardScaler\n\nfor col in skew_columns.index.tolist():\n    train[col] = np.log1p(train[col])\n    test[col] = np.log1p(test[col])\n    \n\nsc = StandardScaler()\ntrain[feature_columns] = sc.fit_transform(train[feature_columns])\ntest[feature_columns]  = sc.transform(test[feature_columns])","21be6e9d":"fig, ax_list = plt.subplots(nrows=4, ncols=4, sharey=False, figsize=(36,36))\nax_list = ax_list.flatten()\nfor name, ax in zip(feature_cols, ax_list):\n     g = sns.histplot(train, x=name, bins=10, ax=ax).set(title=name)","d1fd6aa6":"x = train.drop(['y'], axis=1)\ny = train.y","36e84014":"from sklearn.ensemble import ExtraTreesClassifier\nmodel = ExtraTreesClassifier()\nmodel.fit(x,y)\nprint(model.feature_importances_)","14d573e9":"feat_imp = pd.Series(model.feature_importances_, index=x.columns)\nfeat_imp.nlargest(10).plot(kind='barh')","3bde8cc4":"x.columns","27662bda":"# x.drop(['Perimeter'],inplace =True,axis = 1)\n# test.drop(['Perimeter'],inplace =True,axis = 1)\n","c055d77a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report","10dbaf46":"from sklearn.neural_network import MLPClassifier\n\n# Create an instance of the classifier\nclassifier = MLPClassifier(random_state=0,max_iter=1000,alpha=0.115)\n\n\n# Train the classifier\nclassifier = classifier.fit(x, y)","6d2210ca":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(\n  classifier, x, y, cv=7, scoring='f1_micro')\nscores.mean()","ebde52a0":"print(\"The accuracy of the classifier on the training set is \", (classifier.score(x, y)))","b37e3369":"y_train_pred = classifier.predict(x)\nfrom sklearn.metrics import f1_score\nf1_score(\n        y, \n        y_train_pred, \n        average='micro'\n    )","712f3dce":"y_test_predicted = classifier.predict(test)","641ee88a":"from sklearn.svm import SVC\nfrom sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier\nmodel = SVC(C=1,\n        gamma=0.4,\n             )\n\nsvm_model = OneVsOneClassifier(model)\n\n\nsvm_model.fit(x, y)\n","b4e42c02":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(\n  svm_model, x, y, cv=5, scoring='f1_micro')\nscores.mean()","057c746c":"y_train_pred = svm_model.predict(x)\nfrom sklearn.metrics import f1_score\nf1_score(\n        y, \n        y_train_pred, \n        average='micro'\n    )","c1929258":"from sklearn.metrics import classification_report\nprint('Results on the test set:')\nprint(classification_report(y, y_train_pred))","5c8d8e53":"y_test = svm_model.predict(test)\n\noutput = pd.DataFrame({'ID': test.index,\n                      'y': y_test})\noutput.to_csv('submission.csv', index=False)","1851d9df":"#### MLP","64c19006":"#### submission","5de4e966":"##### the distribution looks quite normal now, Great!","7a61886b":"#### Apply transformation to long-tailed columns","545722bb":"#### EDA","94ed1168":"#### Data exploration","7f3f84b0":"#### SVM","cccf08ac":"#### Reading the Data","ddf377ae":"#### Apply transformation to skewed columns and scaling all the data ","06b9c724":"#### Importing libraries","c29251bb":"#### Feature Importance\n","8ff2b888":"#### Splitting the Data","1e686b6a":"#### Model and CV"}}