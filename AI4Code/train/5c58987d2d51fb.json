{"cell_type":{"1d3805dc":"code","46625d7e":"code","5d132bb2":"code","baaefbbf":"code","e51e6577":"code","647ce3ce":"code","85d767fb":"code","4e4bf052":"code","475c118d":"code","b99ab6fb":"code","0a50f364":"code","8171fe8e":"code","7c34b1dd":"code","9c9688fc":"code","18c01e0b":"code","44af04fc":"code","c94af568":"code","da701f07":"code","6c677652":"code","0956cd47":"code","abd13414":"code","e75bf173":"code","9060396f":"code","ead052ce":"code","2cb4265a":"code","8f309f9c":"code","11594bc3":"code","09e87156":"code","38e6ccaa":"code","73e7b0bb":"code","80b8e694":"code","f7b01b9a":"code","bc307043":"code","934ca013":"code","2a632e8c":"code","ca100440":"code","c9b1f515":"code","0cef4f39":"code","fa4d2abd":"code","a7038fe2":"code","ca41eef0":"code","620e797d":"code","3977e303":"code","afcc6618":"code","47cd0bd6":"code","3c77dffd":"code","b2157854":"code","b1c826b2":"code","3cabb27c":"code","6d262918":"code","b27c6ea5":"code","5111ed9e":"code","20ff4652":"code","42c57a3c":"code","266b076b":"code","dfbba73c":"code","e5060c06":"markdown","7ee9a900":"markdown","a90f372d":"markdown","c19fc368":"markdown","96ab68e6":"markdown","5dd34606":"markdown","8d91dfcc":"markdown","25ff7fea":"markdown","a79e846d":"markdown","d3d69439":"markdown","83516def":"markdown","b6de97b2":"markdown","df4807b1":"markdown","c0e1dd1c":"markdown","e8d31fed":"markdown","e9077896":"markdown","e7f1c2c6":"markdown","e61fe43c":"markdown","cf0a0259":"markdown","1272d47a":"markdown","e9cae0ce":"markdown","36f5e0f9":"markdown","c2d969af":"markdown","07ba9549":"markdown","0562f3c8":"markdown","977b7b8e":"markdown","4582a98e":"markdown","482e8d1a":"markdown","8fbb1f70":"markdown","d4ea1153":"markdown"},"source":{"1d3805dc":"# Import packages:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import ParameterSampler","46625d7e":"# Import Data\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\ntrain.head()","5d132bb2":"test.head()","baaefbbf":"# Feature Engineering: \ndef feature_engineering(df):\n    \n    # Convert click_time to type date_time: \n    df['date'] = pd.to_datetime(df['click_time'])\n    \n    # Extruct features from date and time: \n    df['day'] = df['date'].dt.dayofweek.astype('uint16')\n    df['hour'] = df['date'].dt.hour.astype('uint8')\n    df['min'] = df['date'].dt.minute.astype('uint8')\n    df['sec'] = df['date'].dt.second.astype('uint8')\n    \n    # Drop unused column:\n    df.drop(['click_time'], axis= 1, inplace=True)\n    \n    # Convert categorical features to type category: \n    cols = ['app', 'device', 'os', 'channel']\n    for col in cols:\n        \n        df[col] = df[col].astype('category')\n        \n    return df","e51e6577":"# Apply Feature engineering: \ntrain = feature_engineering(train)\ntest = feature_engineering(test)","647ce3ce":"train","85d767fb":"# A function that adds another feature to the data:\n# feature that counts number of clicks per ip and attaches the number of clicks to the ip's row:\ndef add_clicks(df):\n    # Count clicks per ip: \n    num_clicks_ip = df.groupby('ip').size().reset_index()\n    \n    # Change column name: \n    num_clicks_ip = num_clicks_ip.rename(columns = {0:'clicks'})\n    \n    # Append clicks column to data frame by meging on 'ip': \n    return pd.merge(df, num_clicks_ip, on = 'ip', how = 'left')","4e4bf052":"# A function that concatinates the training and test data and computes number of clicks.\n# then, separates it back to train and test:\ndef concat_and_split(train, test):\n    train_copy = train.copy()\n    test_copy = test.copy()\n    df_merged = pd.merge(left = train_copy, right = test_copy, how='outer')\n    df_merged = add_clicks(df_merged)\n    train_copy['clicks'] = df_merged['clicks'][0:len(train_copy)].tolist()\n    test_copy['clicks'] = df_merged['clicks'][len(train_copy)::].tolist()\n    return train_copy, test_copy","475c118d":"plt.figure(figsize = (12,9))\ntrain.date.hist(bins = 1000, label = 'Train')\ntest.date.hist(bins = 500, color = 'red', label = 'Test')\nplt.xticks(rotation='vertical')\nplt.legend()\nplt.title('Date Time histogram of train and test sets')\nplt.show()","b99ab6fb":"# Form the plot above we can easily see that there is a large area of missing data. \n# Maybe we can lay only on the training data that is closer to the test data --> the data that \n# is after 08\/11\/2017 - we can use this date for splitting the data: \ndate_thresh = train[train.date > '2017-11-08']['date'].min()\n\nprint(f'The date and time in which the data continue after the break is: {date_thresh}')","0a50f364":"# A function that splits the training data and saves only the final part according to threshold: \ndef split_data(df, thresh):\n    return df[(df.date > thresh)]","8171fe8e":"# A function for downsampling the training data labeled as \"is_attributed\" == 0:\ndef downsample(df, n=500000, seed=1):\n    \n    # apply downsampling on the training data by randomly omit samples that are labeled \n    # is_attributed == 0 --> this way we narrow the size of the data for computational issues \n    # and also fixing a bit the extreme imbalanced ratio between is_attributed 0\/1:\n    \n    # random sample without replacement from ['is_attributed'] == 0 part\n    df_downsampled = df[df['is_attributed'] == 0].sample(n=n, random_state = seed, replace = False)\n    \n    # concat with ['is_attributed'] == 1 part and return fixed data:\n    return pd.concat([df_downsampled, df[df['is_attributed'] == 1]])","7c34b1dd":"# Helper function to create X, y from data frame ready to train:\ndef convert_train(df):\n    \n    df = df.sort_values('date')\n    \n    # Obtain labels: \n    y = df['is_attributed'].values\n    \n    # Drop unused columns and obtain features:\n    cols = ['ip', 'attributed_time', 'is_attributed', 'date']\n    X = df.drop(columns = cols).values\n    \n    return X, y","9c9688fc":"# Helper function to create X from data frame ready to test:\ndef convert_test(df):\n      \n    # Drop unused columns and obtain features:\n    cols = ['click_id', 'ip', 'date']\n    X = df.drop(columns = cols).values\n    \n    return X","18c01e0b":"# Create dataset with number of clicks feature: \ntrain_clicks, test_clicks = concat_and_split(train, test)","44af04fc":"# Create two more data sets:\n# Split data and use only the part of 09\/11, do it for both train and train_clicks:\ntrain_split = split_data(train, date_thresh)\ntrain_clicks_split = split_data(train_clicks, date_thresh)","c94af568":"# So now we have 4 training data sets, let's downsample them all:\ntrain = downsample(train)\ntrain_clicks = downsample(train_clicks)\ntrain_split = downsample(train_split)\ntrain_clicks_split = downsample(train_clicks_split)","da701f07":"# let's review the training data sets we created: \nimport random\ndatas = {'train' : train, 'train_clicks' : train_clicks,\n         'train_split' : train_split, 'train_clicks_split' : train_clicks_split}\nplt.style.use(\"bmh\")\nplt.figure(figsize=(12,10))\nfor i,d in enumerate(datas):\n    plt.subplot(2,2,i+1)\n    datas[d].date.hist(bins = 1000, color = 'k')\n    plt.xticks(rotation='vertical')\n    N = len(datas[d])\n    R = len(datas[d][datas[d]['is_attributed'] == 1]) \/ len(datas[d][datas[d]['is_attributed'] == 0])\n    plt.title(f' Training dataset spread: {d} \\nNum samples: {N} \\nis_attributed ratio: {R}')\nplt.tight_layout()\nplt.show()","6c677652":"X, y = convert_train(train)\nX_clicks, y_clicks = convert_train(train_clicks)\nX_split, y_split = convert_train(train_split)\nX_clicks_split, y_clicks_split = convert_train(train_clicks_split)\n\n### only for later use, let's convert the test set aswell: \n### Remember - the validation is not done on the test set, but with cross validation\n\n# We need a test set with and without click feature: \nX_test = convert_test(test)\nX_test_clicks = convert_test(test_clicks)","0956cd47":"# Helper function that given a model and dataset creates train \/ validation split,\n# fits the model, and computes the auc score: \ndef fit_and_auc_score(model, X, y, X_Test, is_splitted = False, return_model = False):\n    \n    if not is_splitted:\n        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=42)\n    # If the data is splitted and only the final part remains, we want to keep the order of the\n    # data, so it will be similar to the real test data. \n    # when we do not perform the split, the time line is already very messy so it doesn't matter..\n    # In this case we will use the random train_test_split... \n    else: \n        s = int(X.shape[0]*0.8)\n        X_train = X[0:s,:]\n        X_val = X[s::,:]\n        y_train = y[0:s]\n        y_val = y[s::] \n        \n    model.fit(X_train, y_train)\n    \n    y_proba = model.predict_proba(X_train)\n    y_val_proba = model.predict_proba(X_val)\n    \n    model.fit(X, y)\n    \n    # If return_model is True we return the model for late use.. \n    if return_model:\n        return roc_auc_score(y_train, y_proba[:,1]), roc_auc_score(y_val, y_val_proba[:,1]), model\n        \n    return roc_auc_score(y_train, y_proba[:,1]), roc_auc_score(y_val, y_val_proba[:,1]), model.predict_proba(X_Test)","abd13414":"DT = DecisionTreeClassifier()","e75bf173":"# Simple data:\nDT_auc_train, DT_auc_val, DT_test = fit_and_auc_score(DT, X, y, X_test)\nprint(f'train auc: {DT_auc_train}, validation auc: {DT_auc_val}')","9060396f":"# Data with clicks:\nDT_auc_train_clicks, DT_auc_val_clicks, DT_test_clicks = fit_and_auc_score(DT, X_clicks, y_clicks, X_test_clicks)\nprint(f'train auc: {DT_auc_train_clicks}, validation auc: {DT_auc_val_clicks}')","ead052ce":"# Splitted data:\nDT_auc_train_split, DT_auc_val_split, DT_test_split = fit_and_auc_score(DT, X_split, y_split, X_test)\nprint(f'train auc: {DT_auc_train_split}, validation auc: {DT_auc_val_split}')","2cb4265a":"# Splitted data with clicks:\nDT_auc_train_clicks_split, DT_auc_val_clicks_split, DT_test_clicks_split = fit_and_auc_score(DT, X_clicks_split, y_clicks_split, X_test_clicks)\nprint(f'train auc: {DT_auc_train_clicks_split}, validation auc: {DT_auc_val_clicks_split}')","8f309f9c":"RF = RandomForestClassifier()","11594bc3":"# Simple data:\nRF_auc_train, RF_auc_val, RF_test = fit_and_auc_score(RF, X, y, X_test)\nprint(f'train auc: {RF_auc_train}, validation auc: {RF_auc_val}')","09e87156":"# Data with clicks:\nRF_auc_train_clicks, RF_auc_val_clicks, RF_test_clicks = fit_and_auc_score(RF, X_clicks, y_clicks, X_test_clicks)\nprint(f'train auc: {RF_auc_train_clicks}, validation auc: {RF_auc_val_clicks}')","38e6ccaa":"# Splitted data:\nRF_auc_train_split, RF_auc_val_split, RF_test_split = fit_and_auc_score(RF, X_split, y_split, X_test, is_splitted = True)\nprint(f'train auc: {RF_auc_train_split}, validation auc: {RF_auc_val_split}')","73e7b0bb":"# Splitted data with clicks:\nRF_auc_train_clicks_split, RF_auc_val_clicks_split, RF_test_clicks_split = fit_and_auc_score(RF, X_clicks_split, y_clicks_split, X_test_clicks, is_splitted = True)\nprint(f'train auc: {RF_auc_train_clicks_split}, validation auc: {RF_auc_val_clicks_split}')","80b8e694":"AD = AdaBoostClassifier()","f7b01b9a":"# Simple data:\nAD_auc_train, AD_auc_val, AD_test = fit_and_auc_score(AD, X, y, X_test)\nprint(f'train auc: {AD_auc_train}, validation auc: {AD_auc_val}')","bc307043":"# Data with clicks:\nAD_auc_train_clicks, AD_auc_val_clicks, AD_test_clicks = fit_and_auc_score(AD, X_clicks, y_clicks, X_test_clicks)\nprint(f'train auc: {AD_auc_train_clicks}, validation auc: {AD_auc_val_clicks}')","934ca013":"# Splitted data:\nAD_auc_train_split, AD_auc_val_split, AD_test_split = fit_and_auc_score(AD, X_split, y_split, X_test,is_splitted = True)\nprint(f'train auc: {AD_auc_train_split}, validation auc: {AD_auc_val_split}')","2a632e8c":"# Splitted data with clicks:\nAD_auc_train_clicks_split, AD_auc_val_clicks_split, AD_test_clicks_split = fit_and_auc_score(AD, X_clicks_split, y_clicks_split, X_test_clicks, is_splitted = True)\nprint(f'train auc: {AD_auc_train_clicks_split}, validation auc: {AD_auc_val_clicks_split}')","ca100440":"def create_submission(test, probas, name):\n    sub_df = test.copy()\n    sub_df['Expected'] = probas[:,1]\n    sub_df = sub_df[['click_id','Expected']]\n    sub_df = sub_df.rename(columns = {'click_id' : 'Id'})\n    sub_df['Id'] = sub_df['Id'].astype('int64')\n    sub_df.to_csv(name + '.csv', index=False)","c9b1f515":"# Creating a sample submission for Kaggle, we will use the 'RF_test_clicks_split' Run. \ncreate_submission(test, RF_test_clicks_split, 'RF_test_clicks_split')","0cef4f39":"# Creating a sample submission for Kaggle, we will use the 'RF_test_clicks_split' Run. \ncreate_submission(test, AD_test_clicks_split, 'AD_test_clicks_split')","fa4d2abd":"# Record results of kaggle submission:\nsummary_results = {'RF_test_clicks_split':{'train auc': RF_auc_train_clicks_split,\n                                           'validation auc': RF_auc_val_clicks_split,\n                                           'kaggle auc': 0.96727}, \n                  'AD_test_clicks_split':{'train auc': AD_auc_train_clicks_split,\n                                           'validation auc': AD_auc_val_clicks_split,\n                                           'kaggle auc': 0.96396}}","a7038fe2":"# This time we will use a splitted data (only the last day) and than add clicks, and for finish we down sample the data:\n\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\n\n# Apply Feature engineering: \ntrain = feature_engineering(train)\ntest = feature_engineering(test)\n\n# First split the data and use only the last day:\ntrain = split_data(train, date_thresh)\n\n# Only after that add the total clicks with concating the test data:\ntrain, test = concat_and_split(train, test)\n\n# decrease the number of samples: \ntrain_downsample = downsample(train)\n\n# Convert to numpy:\nX, y = convert_train(train_downsample)\n\n# We need a test set with and without click feature: \nX_test = convert_test(test)\n","ca41eef0":"# imports:\nfrom xgboost import XGBClassifier","620e797d":"XG = XGBClassifier(eval_metric = 'auc', use_label_encoder = False, subsample = 0.8)","3977e303":"# Splitted data with clicks:\nXG_auc_train, XG_auc_val, XG_test = fit_and_auc_score(XG, X, y, X_test, is_splitted = True)\nprint(f'train auc: {XG_auc_train}, validation auc: {XG_auc_val}')","afcc6618":"# Creating a sample submission for Kaggle, we will use the 'XG_test_clicks_split' Run. \ncreate_submission(test, XG_test, 'XG_test')","47cd0bd6":"# Define different hyperparameters to search on: \nparams = {'eta' : [0.2, 0.3, 0.4, 0.5],\n          'gamma' : [0, 1, 5, 10],\n          'max_depth' : [4, 5, 6, 7, 8],\n          'max_delta_step' : [0, 1, 2],\n          'subsample' : [0.6, 0.8, 1]}\n\n# Create a list of 30 randomly selected sets of hyperparameter. \nparam_list = list(ParameterSampler(params, n_iter = 30)) ","3c77dffd":"# Define a dictionary to store the results:\nXGBoost_Result = {}\n\n# Run over the different hyperparams sets:\nfor i in range(len(param_list)): \n    \n    # Get hyperparam set for iteration:\n    params = param_list[i]\n    \n    # Define XGBoost model\n    XG = XGBClassifier(eval_metric = 'auc', use_label_encoder = False)                          \n    \n    # Assign hyperparameters to model\n    XG.set_params(**params)\n    \n    # Obtain the scores of train and validation, and the probas of final model\n    auc_train, auc_val, y_hat = fit_and_auc_score(XG, X, y, X_test, is_splitted = True)\n    \n    # Assign results in dictionary:\n    XGBoost_Result[i] = {'param': params, 'auc_train': auc_train, 'auc_val' : auc_val, 'y_hat' : y_hat}\n    \n    print(f'Finished iteration: {i}, Train score = {auc_train}, Val score = {auc_val}')","b2157854":"def time_delta(train, test):\n    \n    # Merge train and test: \n    df_merged = pd.merge(left = train, right = test, how='outer')\n    \n    # Unique ip's\n    ips = df_merged['ip'].unique()\n    \n    # Create empty columns: \n    df_merged['d_up'] = 0\n    df_merged['d_down'] = 0\n    \n    # sort values by date:\n    df_merged = df_merged.sort_values('date')\n    \n    n = len(ips)\n    i = 1\n    \n    # Run over IP and calculate the time delta before and after each click: \n    for ip in ips:\n        ip_group = df_merged[df_merged['ip'] == ip]['date']\n        df_merged.loc[df_merged['ip'] == ip,'d_up'] = (ip_group - ip_group.shift()).dt.total_seconds()\n        df_merged.loc[df_merged['ip'] == ip,'d_down'] = df_merged[df_merged['ip'] == ip]['d_up'].shift(-1)\n        \n        # Only for logging: \n        print(f' {(100*i) \/ n}% Process id done')\n        i += 1\n        \n    # Fill missing values with 0 (missing values will be initial values in delta after and final value in delta before)\n    df_merged[['d_up','d_down']] = df_merged[['d_up','d_down']].fillna(0)\n    \n    # Assign to train and test: \n    train = df_merged[0:len(train)]\n    test = df_merged[len(train)::]\n    \n    return train, test","b1c826b2":"train = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\n\n# Apply Feature engineering: \ntrain = feature_engineering(train)\ntest = feature_engineering(test)\n\n# First, add the total clicks with concating the test data:\ntrain, test = concat_and_split(train, test)\n\n# Add new feature:\ntrain, test = time_delta(train, test)\n\n# # Because it takes long time to compute the feature engineering, we save the created datasets:\n# train.to_csv('trains_featured2.csv', index=False)\n# test.to_csv('test_featured2.csv', index=False)\n\n# split the data and use only the last day:\ntrain_split = split_data(train, date_thresh)\n\n# decrease the number of samples: \ntrain_downsample = downsample(train_split)\n\n# Drop column 'click_id' that was added in the merging step:\ntrain_downsample = train_downsample.drop('click_id', axis = 1)\ntest = test.drop(columns = ['attributed_time' , 'is_attributed'])\n\n# Convert to numpy:\nX, y = convert_train(train_downsample)\n\n# We need a test set with and without click feature: \nX_test = convert_test(test)","3cabb27c":"# Upload saved datasets:  \ntrain = pd.read_csv('trains_featured.csv')\ntest = pd.read_csv('test_featured.csv')\n\n# Drop column 'click_id' that was added in the merging step:\ntrain = train.drop('click_id', axis = 1)\ntest = test.drop(columns = ['attributed_time' , 'is_attributed'])\n\n# Convert to numpy:\nX, y = convert_train(train)\n\n# We need a test set with and without click feature: \nX_test = convert_test(test)","6d262918":"# Define a dictionary to store the results:\nXGBoost_F_Result = {}\n\n# Run over the different hyperparams sets:\nfor i in range(len(param_list)): \n    \n    # Get hyperparam set for iteration:\n    params = param_list[i]\n    \n    # Define XGBoost model\n    XG = XGBClassifier(eval_metric = 'auc', use_label_encoder = False)                          \n    \n    # Assign hyperparameters to model\n    XG.set_params(**params)\n    \n    # Obtain the scores of train and validation, and the probas of final model\n    auc_train, auc_val, y_hat = fit_and_auc_score(XG, X, y, X_test, is_splitted = True)\n    \n    # Assign results in dictionary:\n    XGBoost_F_Result[i] = {'param': params, 'auc_train': auc_train, 'auc_val' : auc_val, 'y_hat' : y_hat}\n    \n    print(f'Finished iteration: {i}, Train score = {auc_train}, Val score = {auc_val}')","b27c6ea5":"from catboost import CatBoostClassifier\n\nCat = CatBoostClassifier()\n\nparams = {'depth':[6, 8, 10],\n          'iterations':[100, 200, 300],\n          'learning_rate':[0.001, 0.01, 0.03, 0.1], \n          'l2_leaf_reg':[1, 3, 10]}\n\nparam_list = list(ParameterSampler(params, n_iter = 30)) ","5111ed9e":"# Define a dictionary to store the results:\nCatBoost_F_Result = {}\n\n# Run over the different hyperparams sets:\nfor i in range(len(param_list)): \n    \n    # Get hyperparam set for iteration:\n    params = param_list[i]\n    \n    # Define XGBoost model\n    Cat = CatBoostClassifier(verbose=False)                          \n    \n    # Assign hyperparameters to model\n    Cat.set_params(**params)\n    \n    # Obtain the scores of train and validation, and the probas of final model\n    auc_train, auc_val, y_hat = fit_and_auc_score(Cat, X, y, X_test, is_splitted = True)\n    \n    # Assign results in dictionary:\n    CatBoost_F_Result[i] = {'param': params, 'auc_train': auc_train, 'auc_val' : auc_val, 'y_hat' : y_hat}\n    \n    print(f'Finished iteration: {i}, Train score = {auc_train}, Val score = {auc_val}')","20ff4652":"# Upload saved datasets:  \ntrain = pd.read_csv('trains_featured.csv')\ntest = pd.read_csv('test_featured.csv')\n\n# Drop column 'click_id' that was added in the merging step:\ntrain = train.drop('click_id', axis = 1)\ntest = test.drop(columns = ['attributed_time' , 'is_attributed'])","42c57a3c":"def create_ensemble(train, n_models, X_test, param_dict, n_param_iter = 10, is_splitted = True):\n    \n    # \n    ensemble_dic = {}\n\n    for m in range(n_models):\n\n        # Downsample data to 1:1\n        train_downsampled = downsample(train, n = 15000, seed = np.random.randint(100))\n\n        # Convert to numpy:\n        X, y = convert_train(train_downsampled)\n\n        # Create a list of 30 randomly selected sets of hyperparameter. \n        param_list = list(ParameterSampler(param_dict, n_iter = n_param_iter))\n\n        # Define a dictionary to store the results:\n        XGBoost_Result = {}\n        vals = []\n\n        # Run over the different hyperparams sets:\n        print(f'Model no.: {m}\\n')\n        for i in range(n_param_iter): \n            ensemble_dic[m] = {}\n            # Get hyperparam set for iteration:\n            params = param_list[i]\n\n            # Define XGBoost model\n            XG = XGBClassifier(eval_metric = 'auc', use_label_encoder = False)                          \n\n            # Assign hyperparameters to model\n            XG.set_params(**params)\n\n            # Obtain the scores of train and validation, and the probas of final model\n            auc_train, auc_val, model = fit_and_auc_score(XG, X, y, X_test, is_splitted = is_splitted, return_model = True)\n\n            vals.append(auc_val)\n\n            # Assign results in dictionary:\n            XGBoost_Result[i] = {'model' : model, 'param': params, 'auc_train': auc_train, 'auc_val' : auc_val, 'y_hat' : y_hat}\n\n            print(f'iteration: {i}, Train score = {auc_train}, Val score = {auc_val}')\n\n        # Choose best model for this dataset: \n        # By finding the index of the best validations score: \n        best_ind = np.argmax(vals)\n        \n        # Assing best model to dictionary:\n        best_model = XGBoost_Result[best_ind]['model']\n        ensemble_dic[m]['best_model'] = best_model\n        \n        # Assign best model's params to dictionary:\n        ensemble_dic[m]['best_params'] = XGBoost_Result[best_ind]['param']\n        \n        # Predict probabilities using best model to X_test:\n        ensemble_dic[m]['predictions'] = best_model.predict_proba(X_test)\n        \n        # Keep track of run: \n        print(f'\\nBest model was acheived in iteration no.{best_ind}')\n    \n    return ensemble_dic","266b076b":"def ensemble_predict(ensemble_dic, n_models):\n    # Get number of test samples: \n    probas_shape = ensemble_dic[0]['predictions'].shape\n    \n    # create empty probas matrix:\n    ensemble_probas = np.zeros((probas_shape[0], probas_shape[1], n_models))\n    \n    # append probas of different models to matrix\n    for i in range(n_models):\n        ensemble_probas[:,:,i] = ensemble_dic[i]['predictions']\n    \n    # compute mean probas (like voting but with probabilities... )\n    return np.mean(ensemble_probas, axis = 2)","dfbba73c":"# Define different hyperparameters to search on: \nparam_dict = {'eta' : [0.1, 0.2, 0.3, 0.4, 0.5],\n          'gamma' : [0, 1, 5, 10, 25],\n          'max_depth' : [4, 5, 6, 7, 8, 9],\n          'max_delta_step' : [0, 1, 2],\n          'subsample' : [0.6, 0.7, 0.8, 0.9, 1]}\n\n# Create a function that creates a dictionary of n models trained on differen datasets: \nn_param_iter = 30\nn_models = 5\n\n# Test Set:\nX_test = convert_test(test)\n\nensemble_dic = create_ensemble(train, n_models, X_test, param_dict, n_param_iter = n_param_iter)\nensemble_test = ensemble_predict(ensemble_dic, n_models)\n\n# Creating a sample submission for Kaggle:\ncreate_submission(test, ensemble_test, 'ensemble_test')","e5060c06":"#### Add clicks\n\nAnother feature engineering - We define a function that counts the number of clicks each user clicked and attach it to the user's row. \nAlso we define a wrapper function for the add_click function, that takes the train and test datasets, merge them, applies the add_click function on the merged dataframe and then splits them back to the train and test sets. \n\nThere can be a problem of data leakage with this type of operation, But since the test set is a continuation of the training set, this information can greatly add to the estimation algorithm.\n\nIn a real world data challenge, we would probably won't have the opportunity to do so, but since this is a kaggle compatition, we allow ourselves.  ","7ee9a900":"#### Tackeling the problen with Ensemble methods: \n\nNow we will try a different method, since the data is so large, computing feature engineering takes too long, we saved a downsampled dataset we already created, and we will use it.  \n\nThe new method tries to tackle the problem and to increase the accuracy by using Ensembling method of several models where each model will be trained on a different data set - where each dataset contains the whole 'Fraud' samples and a downsampled quantity of 'Non fraud' samples. Therefore we will have a balanced data of 50-50 fraud\/non-fraud samples in each dataset, making every model use a different random set of the non fraud samples.    \n\nWe will write the stacking algorithm that computes the final results by our own.","a90f372d":"#### Ada Boost:","c19fc368":"#### Random Forest:","96ab68e6":"#### Feature Engineering\nThe following function defines some basic feature engineering such as date time conversion to day\/ hour\/ minute\/ second, drops unnecessary columns and converts some categorical features to type 'category'. We will apply this function on both train and test sets.   ","5dd34606":"Upload the data once again: ","8d91dfcc":"We will create different training sets according to the different functions above, and we'll explore if different changes in the data actually make change in the validation accuracy. ","25ff7fea":"#### Future work\n\n - Trying different feature engineering.\n - Other types of models.\n - Different train sample sizes.\n - Hyperparameter tuning for selected models.\n - Try ensemble methods by combining different models.  ","a79e846d":"Now, after creating 4 tpyes of training sets, lest convert them to numpy array to be ready before modeling: \n\n#### Convert to Numpy: ","d3d69439":"#### XGboost Randomized Hyperparameter search:","83516def":"## Work Summary: \n\nAfter a comprehensive EDA, we started the modeling stage. \n\n- The first step was creating a feature engineering funcion that convert click_time to a 'date_time' type, extract features from date and time and convert categorical features to type 'category'.\n\n\n- We Added a 'clicks' feature function that concatenates the training and test datasets and counts the total clicks per ip, and than splits the data again to train and test. \n\n\n- We explored the samples range through time and we noticed a huge space with missing data. As a result we wrote a function that splits the data and uses only the later part of the data as the training data ('2017-11-09 13:00:19'  - '2017-11-09 14:59:59')\n\n\n- Since the data is huge and very imbalanced we wrote a function that downsamples the data. Only the samples with is_atrributed = 0 are downsampled while the is_attributed = 1 samples are maintained. \n\n\n- We created 4 types of training data - with and without the clicks feature, and for each one - with or without splits. \n\n\n- We ran a sample run for each of the 4 training sets, using 3 different models: Decision Tree, Random forest and Adaboost. \n\n\n- For the splitted data sets we used a validation set which is composed of the final part of the data set, while in the non splitted datasets we used a validation set that is a random sub-set of the training set. \n\n\n- After reviewing the validation sets scores we saw that the best performance is obtained from the splitted data while using the 'clicks' feature. So from now on we will use only this training set. \n\n\n- We tried XGBoost classifier on the training data with the default parameters. \n\n\n- We found better hyperparameters using a random hyperparameter search. \n\n\n- To increase the accuracy we wrote a new feature engineering function - 'time_delta' which adds time delta before and after each click. (This function takes a very long time to compute - more than 24 hours on our computers, so we saved a sample of the data and used it for later runs).\n\n\n- After applying the new features we ran the XGBoost random hyperparameters tuning again and checked the results.\n\n\n- We wanted also to examine the CatBoost algorithm, so we ran a similar random hyperparameter tuning run for this model (suited to it), but the scores were lower. So we chose to continue with the XGBoost. \n\n\n- For the last part, we built am ensemble model, that uses 5 different XGBoost models with different hyperparameters, (each was chosen with random search). Each model was trained on a different part of the dataset - by using the downsampling function, we maintained the 'is_attributed = 1' samples and randomly selected 'is_attribute = 0' samples that each model will be trained on a balanced data. \n\n\n- The last part increased our accuracy a bit and acheived our best results, also submitted to Kaggle (0.98034). ","b6de97b2":"#### Proccess data for modeling\n\nAfter defining different feature engineering functions, and data reductions, the last part is to drop final unnecessary columns and convert data to numpy type - ready for modeling. ","df4807b1":"We Acheived a better results with a  run using the hyperparam 'subsample = 0.8'.","c0e1dd1c":"#### Downsampling\n\nSince the data is very imbalanced - 99.75% \/ 0.25% is the ratio between labeled = 0 \/ labeled = 1, in the \"is_attributed\" column which is the prediction column, and also from computational issues of running time, we decided to downsample the data using random sampler without replacement. This is done to the training set (original or spliitted) ","e8d31fed":"#### Modeling stage:","e9077896":"#### Appending results in a dictionary","e7f1c2c6":"### Task 3: \nAll of the work above was submitted as part of Task 2. From here on we will try to optimize our model by trying new models, hyperparameter tuning and maybe combine different mdoels into an ensemble model. \nAlso, we can try to think of more feature engineering. ","e61fe43c":"Since we want to explore 5 different hyperparameter, in which each hyperparameter has 3-5 different values, we end up with an extreme number of combinations. \nIn order to gain good insight on the different hyperparameter tuning, we will use a random sampler for sets of hyperparameter - and we'll generate 30 different sets.\nAfter generating these sets we will test them on the two types of training data sets - X_clicks and X_clicks_split. ","cf0a0259":"#### Spliting the data\n\nWe first define the threshold which will split the data, and than define a function that gets a dataframe and splits it in the given threhold point. ","1272d47a":"#### Submission","e9cae0ce":"All the models above acheived better score with the datasets containing the the feature 'clicks', so we will continue use the two training datasets - X_clicks and X_clicks_split. ","36f5e0f9":"We can see that the Cat Boost algorithm is not as good as the XGboost. Let's stick with the XGboost.  ","c2d969af":"Before we continue, we would like to explore more the distribution of usage along the time range, to do so we will plot an histogram of the date column, for the train and test datasets. Maybe we don't need to train the model over all the data.. we will check it out soon, but first let's explore the graph: ","07ba9549":"We notice a very strange behaviour of the training data.\nThere is a large empty interval in the middle, and also a small break at the beginning of the day 07\/11. \n\nLater on, in the modeling stage we will try training the models with two types of training set, the first one will be comprised from the whole range of the training set, and the second will contain samples from the last part (after 12:00 of the 09\/11).","0562f3c8":"#### Run the following cell only if train and test datasets were saved on the disc:  ","977b7b8e":"#### Decision Tree:","4582a98e":"#### CatBoost:","482e8d1a":"Algorithm: \n - upload data\n - write a function that iterate for n XGboost models:\n    - downsamples the data to 1:1\n    - use different seed for each non froad examples generator\n    - generate random param set\n    - run 15 random combinations of param set and select the best model. \n - after we have n models that are trained on different param sets and different data set assemble all models by averaging the final results of all n models. ","8fbb1f70":"#### XGboost:","d4ea1153":"#### New Feature Engineering - Add time delta before and after each click "}}