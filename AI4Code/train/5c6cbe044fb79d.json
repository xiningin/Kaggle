{"cell_type":{"b16a0467":"code","9fee8b48":"code","4254f563":"code","a2e338db":"code","8c36913a":"code","d02e4e76":"code","5b35788f":"code","1205c776":"code","b64497b8":"code","a2001ed7":"code","1c2d7e4a":"code","fc6c8b6b":"code","b108caaf":"code","27ba4276":"code","5e4eed77":"code","b300b311":"code","c0957e0f":"code","f5e7cde8":"code","e5a25493":"code","6d70d456":"code","5731e492":"code","9069c3d2":"code","1b07e6b4":"code","3e66f21e":"code","601f7547":"code","e153a950":"code","a51b54f6":"code","d2010787":"markdown","6a470858":"markdown","76b10eda":"markdown","46760bed":"markdown","06f935f8":"markdown","2a019b6c":"markdown","54897b74":"markdown","c1c2101b":"markdown","32851357":"markdown","6a9b76f7":"markdown","d2da9ffc":"markdown"},"source":{"b16a0467":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\nplt.style.use('ggplot') \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","9fee8b48":"items  = pd.read_csv('..\/input\/items.csv')\ntrain = pd.read_csv('..\/input\/sales_train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nitem_category = pd.read_csv('..\/input\/item_categories.csv')\nshops = pd.read_csv('..\/input\/shops.csv')","4254f563":"def eda(data):\n    print(\"----------Top-5- Record----------\")\n    print(data.head(5))\n    print(\"-----------Information-----------\")\n    print(data.info())\n    print(\"-----------Data Types-----------\")\n    print(data.dtypes)\n    print(\"----------Missing value-----------\")\n    print(data.isnull().sum())\n    print(\"----------Null value-----------\")\n    print(data.isna().sum())\n    print(\"----------Shape of Data----------\")\n    print(data.shape)\n\ndef graph_insight(data):\n    print(set(data.dtypes.tolist()))\n    df_num = data.select_dtypes(include = ['float64', 'int64'])\n    df_num.hist(figsize=(16, 16), bins=50, xlabelsize=8, ylabelsize=8);\n    \ndef drop_duplicate(data, subset):\n    print('Before drop shape:', data.shape)\n    before = data.shape[0]\n    data.drop_duplicates(subset,keep='first', inplace=True) #subset is list where you have to put all column for duplicate check\n    data.reset_index(drop=True, inplace=True)\n    print('After drop shape:', data.shape)\n    after = data.shape[0]\n    print('Total Duplicate:', before-after)","a2e338db":"# sales train insights\neda(train)\ngraph_insight(train)","8c36913a":"# Drop Duplicate Data\nsubset = ['date', 'date_block_num', 'shop_id', 'item_id','item_cnt_day']\ndrop_duplicate(train, subset = subset)","d02e4e76":"# test insight\neda(test)\ngraph_insight(test)","5b35788f":"eda(items)\ngraph_insight(items)","1205c776":"eda(item_category)\n# graph_insight(item_category)","b64497b8":"eda(shops)\n# graph_insight(shops)","a2001ed7":"def unresanable_data(data):\n    print(\"Min Value:\",data.min())\n    print(\"Max Value:\",data.max())\n    print(\"Average Value:\",data.mean())\n    print(\"Center Point of Data:\",data.median())","1c2d7e4a":"# -1 and 307980 looks like outliers, let's delete them\nprint('before train shape:', train.shape)\ntrain = train[(train.item_price > 0) & (train.item_price < 300000)]\nprint('after train shape:', train.shape)","fc6c8b6b":"train.groupby('date_block_num').sum()['item_cnt_day'].hist(figsize = (20,4))\nplt.title('Sales per month histogram')\nplt.xlabel('Price')\n\nplt.figure(figsize = (20,4))\nsns.tsplot(train.groupby('date_block_num').sum()['item_cnt_day'])\nplt.title('Sales per month')\nplt.xlabel('Price')","b108caaf":"unresanable_data(train['item_price'])\ncount_price = train.item_price.value_counts().sort_index(ascending=False)\nplt.subplot(221)\ncount_price.hist(figsize=(20,6))\nplt.xlabel('Item Price', fontsize=20);\nplt.title('Original Distiribution')\n\nplt.subplot(222)\ntrain.item_price.map(np.log1p).hist(figsize=(20,6))\nplt.xlabel('Item Price');\nplt.title('log1p Transformation')\ntrain.loc[:,'item_price'] = train.item_price.map(np.log1p)","27ba4276":"#unresanable_data(train['date_block_num'])\ncount_price = train.date_block_num.value_counts().sort_index(ascending=False)\nplt.subplot(221)\ncount_price.hist(figsize=(20,5))\nplt.xlabel('Date Block');\nplt.title('Original Distiribution')\n\ncount_price = train.shop_id.value_counts().sort_index(ascending=False)\nplt.subplot(222)\ncount_price.hist(figsize=(20,5))\nplt.xlabel('shop_id');\nplt.title('Original Distiribution')\n\ncount_price = train.item_id.value_counts().sort_index(ascending=False)\nplt.subplot(223)\ncount_price.hist(figsize=(20,5))\nplt.xlabel('item_id');\nplt.title('Original Distiribution')","5e4eed77":"item_category.head()","b300b311":"l = list(item_category.item_category_name)\nl_cat = l\n\nfor ind in range(1,8):\n    l_cat[ind] = 'Access'\n\nfor ind in range(10,18):\n    l_cat[ind] = 'Consoles'\n\nfor ind in range(18,25):\n    l_cat[ind] = 'Consoles Games'\n\nfor ind in range(26,28):\n    l_cat[ind] = 'phone games'\n\nfor ind in range(28,32):\n    l_cat[ind] = 'CD games'\n\nfor ind in range(32,37):\n    l_cat[ind] = 'Card'\n\nfor ind in range(37,43):\n    l_cat[ind] = 'Movie'\n\nfor ind in range(43,55):\n    l_cat[ind] = 'Books'\n\nfor ind in range(55,61):\n    l_cat[ind] = 'Music'\n\nfor ind in range(61,73):\n    l_cat[ind] = 'Gifts'\n\nfor ind in range(73,79):\n    l_cat[ind] = 'Soft'\n\n\nitem_category['cats'] = l_cat\nitem_category.head()","c0957e0f":"train['date'] = pd.to_datetime(train.date,format=\"%d.%m.%Y\")\ntrain.head()","f5e7cde8":"## Pivot by monht to wide format\np_df = train.pivot_table(index=['shop_id','item_id'], columns='date_block_num', values='item_cnt_day',aggfunc='sum').fillna(0.0)\np_df.head()","e5a25493":"## Join with categories\ntrain_cleaned_df = p_df.reset_index()\ntrain_cleaned_df['shop_id']= train_cleaned_df.shop_id.astype('str')\ntrain_cleaned_df['item_id']= train_cleaned_df.item_id.astype('str')\n\nitem_to_cat_df = items.merge(item_category[['item_category_id','cats']], how=\"inner\", on=\"item_category_id\")[['item_id','cats']]\nitem_to_cat_df[['item_id']] = item_to_cat_df.item_id.astype('str')\n\ntrain_cleaned_df = train_cleaned_df.merge(item_to_cat_df, how=\"inner\", on=\"item_id\")\n\n\n# Encode Categories\nfrom sklearn import preprocessing\n\nnumber = preprocessing.LabelEncoder()\ntrain_cleaned_df[['cats']] = number.fit_transform(train_cleaned_df.cats)\ntrain_cleaned_df = train_cleaned_df[['shop_id', 'item_id', 'cats'] + list(range(34))]\ntrain_cleaned_df.head()","6d70d456":"import xgboost as xgb\nparam = {'max_depth':10, \n         'subsample':1,\n         'min_child_weight':0.5,\n         'eta':0.3, \n         'num_round':1000, \n         'seed':1,\n         'silent':0,\n         'eval_metric':'rmse'}\n\nprogress = dict()\nxgbtrain = xgb.DMatrix(train_cleaned_df.iloc[:,  (train_cleaned_df.columns != 33)].values, train_cleaned_df.iloc[:, train_cleaned_df.columns == 33].values)\nwatchlist  = [(xgbtrain,'train-rmse')]\n\nbst = xgb.train(param, xgbtrain)\npreds = bst.predict(xgb.DMatrix(train_cleaned_df.iloc[:,  (train_cleaned_df.columns != 33)].values))\nfrom sklearn.metrics import mean_squared_error \nrmse = np.sqrt(mean_squared_error(preds,train_cleaned_df.iloc[:, train_cleaned_df.columns == 33].values))\nprint(rmse)","5731e492":"xgb.plot_importance(bst)","9069c3d2":"apply_df = test\napply_df['shop_id']= apply_df.shop_id.astype('str')\napply_df['item_id']= apply_df.item_id.astype('str')\n\napply_df = test.merge(train_cleaned_df, how = \"left\", on = [\"shop_id\", \"item_id\"]).fillna(0.0)\napply_df.head()","1b07e6b4":"# Move to one month front\nd = dict(zip(apply_df.columns[4:],list(np.array(list(apply_df.columns[4:])) - 1)))\n\napply_df  = apply_df.rename(d, axis = 1)","3e66f21e":"preds = bst.predict(xgb.DMatrix(apply_df.iloc[:, (apply_df.columns != 'ID') & (apply_df.columns != -1)].values))","601f7547":"# Normalize prediction to [0-20]\npreds = list(map(lambda x: min(20,max(x,0)), list(preds)))\nsub_df = pd.DataFrame({'ID':apply_df.ID,'item_cnt_month': preds })\nsub_df.describe()","e153a950":"sub_df.head(20)","a51b54f6":"sub_df.to_csv('Submission_Predict Sales.csv',index=False)","d2010787":"## Functions","6a470858":"# 2. Sales Per Month Count","76b10eda":"### 4.Item Category","46760bed":"### 5. Shops","06f935f8":"\n# Model Building","2a019b6c":"# Map the Items","54897b74":"# Convert Date Column data type from object to Date ","c1c2101b":"# Distribution Checking","32851357":"# 1. Check All Data Exploration Analysis\n\n### 1. Sales Train Data","6a9b76f7":"### 3.Item","d2da9ffc":"### 2. Test Data"}}