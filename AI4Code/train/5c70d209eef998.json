{"cell_type":{"fa8a7fbb":"code","db459595":"code","654f8654":"code","6e2d6fa9":"code","3fa7ad8c":"code","28ce33d7":"code","6a773660":"code","0a7b08d6":"code","1958e181":"code","9bf27d25":"code","8f582a8e":"code","cf1098df":"code","365eba9c":"code","7b374d6f":"code","3c78ab28":"code","bedeaf33":"code","46a24c66":"code","0f0958c0":"code","3b70071c":"code","a65fdafa":"code","78164c42":"code","fac69bfd":"code","9c1952aa":"code","c94d1370":"markdown","730e06a6":"markdown","acdea27d":"markdown","5d9b7d34":"markdown","5f71f7f6":"markdown","3d8138ae":"markdown"},"source":{"fa8a7fbb":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","db459595":"df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf.head()","654f8654":"df.info()","6e2d6fa9":"df.isnull().sum() * 100 \/ len(df)","3fa7ad8c":"def substrings_in_string(big_string, substrings):\n    for substring in substrings:\n        if big_string is np.NaN or big_string.find(substring) != -1:\n            return substring\n    print(big_string)\n    return np.nan","28ce33d7":"#replacing all titles with mr, mrs, miss, master\ndef replace_titles(x):\n    title=x['Title']\n    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n        return 'Mr'\n    elif title in ['Countess', 'Mme']:\n        return 'Mrs'\n    elif title in ['Mlle', 'Ms']:\n        return 'Miss'\n    elif title =='Dr':\n        if x['Sex']=='Male':\n            return 'Mr'\n        else:\n            return 'Mrs'\n    else:\n        return title","6a773660":"from sklearn.base import BaseEstimator, TransformerMixin\n\n\nclass CusttomAttribTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self \n    \n    def transform(self, X):\n        title_list = ['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev', 'Dr','Ms', \n            'Mlle','Col', 'Capt', 'Mme', 'Countess', 'Don', 'Jonkheer']\n        X['Title'] = X['Name'].map(lambda x: substrings_in_string(x, title_list))\n        X['Title'] = X.apply(replace_titles, axis=1)\n        \n        cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\n        X['Deck'] = X['Cabin'].map(lambda x: substrings_in_string(x, cabin_list))\n        X['Family_Size'] = X['SibSp'] + X['Parch']\n        X = X.drop(columns=['Cabin', 'Name', 'Parch', 'SibSp', 'Sex'])\n        X[['Deck', 'Title']] = OrdinalEncoder().fit_transform(X[['Deck', 'Title']])\n        imp = SimpleImputer(missing_values=np.nan, strategy='median')\n        X[\"Age\"] = imp.fit_transform(X[[\"Age\"]])\n        X[\"Age\"] = pd.cut(X[\"Age\"], bins=[0., 18, 30, 40, 50, 90], labels=[1, 2, 3, 4, 5])\n\n        return X","0a7b08d6":"from sklearn.model_selection import train_test_split\n\ny = df['Survived']\nX = df.drop(['Survived'], axis=1)\n\n\n# Divide data into training and validation subsets\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                                random_state=0)","1958e181":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n\n\ncategorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n                    df[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('ordinal', OrdinalEncoder())\n])\n\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaling', MinMaxScaler())\n])\n\n\n# custom_columns = ['Name', 'SibSp', 'Parch', 'Cabin', 'Sex', 'Age']\n# categorical_cols = [c for c in categorical_cols if c not in custom_columns]\n# numerical_cols = [c for c in numerical_cols if c not in custom_columns]\n\nmy_cols = numerical_cols + categorical_cols\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n#         ('custom', CusttomAttribTransformer(), custom_columns),\n        ('num', SimpleImputer(strategy='median'), numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n# cols = ['Age', 'Title', 'Deck', 'Family_Size'] + my_cols","9bf27d25":"X_train_full = pd.DataFrame(preprocessor.fit_transform(X_train_full), columns=my_cols)\nX_valid_full = pd.DataFrame(preprocessor.fit_transform(X_valid_full), columns=my_cols)","8f582a8e":"X_train_full","cf1098df":"X_train_full.corr()","365eba9c":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data = pd.DataFrame(preprocessor.transform(test_data), columns=my_cols)\ntest_data.head()","7b374d6f":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import mean_absolute_error","3c78ab28":"print(X_valid_full.shape, y_valid.shape)\n","bedeaf33":"my_model = LogisticRegression()\nmy_model.fit(X_train_full, y_train)\npredictions = my_model.predict(X_valid_full)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))","46a24c66":"my_model = SVC()\nmy_model.fit(X_train_full, y_train)\npredictions = my_model.predict(X_valid_full)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))","0f0958c0":"my_model = RandomForestClassifier()\nmy_model.fit(X_train_full, y_train)\npredictions = my_model.predict(X_valid_full)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))","3b70071c":"my_model = ExtraTreesClassifier()\nmy_model.fit(X_train_full, y_train)\npredictions = my_model.predict(X_valid_full)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))","a65fdafa":"my_model = KNeighborsClassifier()\nmy_model.fit(X_train_full, y_train)\npredictions = my_model.predict(X_valid_full)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))","78164c42":"my_model = DecisionTreeClassifier()\nmy_model.fit(X_train_full, y_train)\npredictions = my_model.predict(X_valid_full)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))","fac69bfd":"my_model = RandomForestClassifier()\nmy_model.fit(X_train_full.append(X_valid_full), y_train.append(y_valid)) \npredictions = my_model.predict(test_data)","9c1952aa":"output = pd.DataFrame({'PassengerId': test_data.PassengerId.astype(int), 'Survived': predictions.round().astype(int)})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","c94d1370":"# Importing datasets","730e06a6":"Checking attributes and their types","acdea27d":"**Name** column doesn't look like a useful attribute. Let's susbstitue them with **titles**. \n\nLet's also select the **Deck** instead of **Cabin**.\n\nAlso **family size** is a better feature combining sibsp and parch.\n\nCode taken from [here](https:\/\/triangleinequality.wordpress.com\/2013\/09\/08\/basic-feature-engineering-with-the-titanic-data\/):","5d9b7d34":"# Now Let's check some models","5f71f7f6":"# Data Engineering","3d8138ae":"Getting the percentage of missing values:"}}