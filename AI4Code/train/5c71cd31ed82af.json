{"cell_type":{"35cb7656":"code","57a06e85":"code","a6c052f0":"code","f018b878":"code","48d6242e":"code","ecaa7bce":"code","ff3a45eb":"code","6d2d2b61":"code","688d0859":"code","d77c5b54":"code","ace73f17":"code","ead3bb9b":"code","cd0c3df5":"code","a38f43ef":"code","67c39459":"code","20191ccd":"code","3db1bcad":"markdown","228159ed":"markdown","007a62ff":"markdown","fa593c90":"markdown","db93cfbf":"markdown","52e40a1c":"markdown","9f363a43":"markdown","670601fc":"markdown","8910b878":"markdown","1e178aa3":"markdown","1807fbf8":"markdown","2d3c349e":"markdown","63ebbec8":"markdown","612c74c3":"markdown","f76805d0":"markdown"},"source":{"35cb7656":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import ModelCheckpoint\n","57a06e85":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\ny_train = train['label']\nX_train = train.drop(labels = [\"label\"], axis = 1)\n\nprint(X_train.shape)\nprint(test.shape)\ntrain.head()\n","a6c052f0":"print(np.where(pd.isnull(X_train)))\nprint(np.where(pd.isnull(y_train)))\nprint(np.where(pd.isnull(test)))\n\ncounts = y_train.value_counts()\nprint(counts)","f018b878":"plt.figure()\nsns.barplot(counts.index, counts.values)\nplt.title('Frequency of each digit class')\nplt.xlabel('Digits')\nplt.ylabel('Number of occurrences')\nplt.show()","48d6242e":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","ecaa7bce":"# display the first four training images to gain an understanding\n# of the data\nfig, axis = plt.subplots(2,2)\naxis[0,0].imshow(X_train[0,:,:,0], cmap = plt.get_cmap('gray'))\n# axis[0,0].set_title(\"First Image\")\naxis[0,0].axis(\"off\")\n\naxis[0,1].imshow(X_train[1,:,:,0], cmap = plt.get_cmap('gray'))\n# axis[0,1].set_title(\"Second Image\")\naxis[0,1].axis(\"off\")\n\naxis[1,0].imshow(X_train[2,:,:,0], cmap = plt.get_cmap('gray'))\n# axis[1,0].set_title(\"Third Image\")\naxis[1,0].axis(\"off\")\n\naxis[1,1].imshow(X_train[3,:,:,0], cmap = plt.get_cmap('gray'))\n# axis[1,1].set_title(\"Fourth Image\")\naxis[1,1].axis(\"off\")\n\nplt.suptitle(\"Some training examples\")\nplt.show()\n","ff3a45eb":"X_train.astype('float32')\ntest.astype('float32')\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\n\n# one hot encode the labels of the training data\ny_train = to_categorical(y_train)\nprint(y_train.shape)","6d2d2b61":"random_seed = 42\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n                                                  test_size = 0.10,\n                                                  random_state = random_seed)","688d0859":"def baseline_cnn(num_classes=10):\n    model = Sequential()\n\n    model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'same',input_shape = (28,28,1)))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.20))\n\n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    return model","d77c5b54":"def cnn(num_classes=10):\n    model = Sequential()\n\n    model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'same',input_shape = (28,28,1)))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.20))\n\n\n    model.add(Conv2D(filters = 64, kernel_size = (2,2), padding = 'same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 64, kernel_size = (2,2), padding = 'same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.20))\n\n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    return model","ace73f17":"learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',\n                                            patience = 5,\n                                            verbose = 1,\n                                            factor = 0.8,\n                                            min_lr = 0.00001)","ead3bb9b":"datagen = ImageDataGenerator(rotation_range = 20,\n                             zoom_range = 0.2,\n                             width_shift_range = 0.1,\n                             height_shift_range = 0.1,\n                             fill_mode = 'constant',\n                             cval = 0.0)\ndatagen.fit(X_train)\nfor X_batch, y_batch in datagen.flow(X_train, y_train, batch_size = 16):\n    for i in range(16):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(X_batch[i,:,:,0], cmap = plt.get_cmap('gray'))\n        plt.axis('off')\n    plt.show()\n    break","cd0c3df5":"batch_size = 86\nepochs = 100\n\n# Comment baseline_model and history_baseline if only the larger CNN needs to be run\n#baseline_model = baseline_cnn(y_train.shape[1])\n#history_baseline = baseline_model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n#                    validation_data=(X_val, y_val),\n#                    epochs = epochs,\n#                    steps_per_epoch = X_train.shape[0] \/\/ batch_size,\n#                    callbacks = [learning_rate_reduction],\n#                    verbose=2)","a38f43ef":"model = cnn(y_train.shape[1])\nhistory = model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n                    validation_data=(X_val, y_val),\n                    epochs = epochs,\n                    steps_per_epoch = X_train.shape[0] \/\/ batch_size,\n                    callbacks = [learning_rate_reduction],\n                    verbose=2)","67c39459":"try:\n    baseline_model\nexcept NameError: \n    baseline_model = None\n\nif baseline_model is None:\n    fig, axis = plt.subplots(1,2,figsize=[10,5])\n    axis[0].plot(history.history['acc'])\n    axis[0].plot(history.history['val_acc'])\n    axis[0].set_title('Model Accuracy')\n    axis[0].set_xlabel('epoch')\n    axis[0].set_ylabel('accuracy')\n    axis[0].legend(['acc','val_acc'], loc='lower right')\n\n    axis[1].plot(history.history['loss'])\n    axis[1].plot(history.history['val_loss'])\n    axis[1].set_title('Model Loss')\n    axis[1].set_xlabel('epoch')\n    axis[1].set_ylabel('accuracy')\n    axis[1].legend(['acc','val_acc'], loc='lower right')\nelse:\n    fig, axis = plt.subplots(2,2,figsize=[15,10])\n    axis[0,0].plot(history_baseline.history['acc'])\n    axis[0,0].plot(history_baseline.history['val_acc'])\n    axis[0,0].set_title('Baseline model accuracy')\n    axis[0,0].set_xlabel('epoch')\n    axis[0,0].set_ylabel('accuracy')\n    axis[0,0].legend(['acc','val_acc'], loc='lower right')\n\n    axis[0,1].plot(history_baseline.history['loss'])\n    axis[0,1].plot(history_baseline.history['val_loss'])\n    axis[0,1].set_title('Baseline model Loss')\n    axis[0,1].set_xlabel('epoch')\n    axis[0,1].set_ylabel('accuracy')\n    axis[0,1].legend(['acc','val_acc'], loc='lower right')\n\n    axis[1,0].plot(history.history['acc'])\n    axis[1,0].plot(history.history['val_acc'])\n    axis[1,0].set_title('Model Accuracy')\n    axis[1,0].set_xlabel('epoch')\n    axis[1,0].set_ylabel('accuracy')\n    axis[1,0].legend(['acc','val_acc'], loc='lower right')\n\n    axis[1,1].plot(history.history['loss'])\n    axis[1,1].plot(history.history['val_loss'])\n    axis[1,1].set_title('Model Loss')\n    axis[1,1].set_xlabel('epoch')\n    axis[1,1].set_ylabel('accuracy')\n    axis[1,1].legend(['acc','val_acc'], loc='lower right')\n\n    plt.show()\n","20191ccd":"prediction = model.predict(test)\nprediction = np.argmax(prediction, axis =1)\ndataframe = pd.read_csv(\"..\/input\/sample_submission.csv\") \nlist_of_images = dataframe.ImageId.values\nname = 'submission'\nsubmission = pd.DataFrame({'ImageId':list_of_images})\nsubmission['Label'] = prediction\nsubmission.to_csv(f'{name}.csv',index=False)","3db1bcad":"Importing the relevant libraries.","228159ed":"Generate the csv file for submission to Kaggle using the larger CNN model.","007a62ff":"## Training the model\nNext, we can call the baseline model and run it with data augmentation for 100 epochs to evaluate the accuracy. We can then run the deeper CNN and compare the performance of the two models created.","fa593c90":"Reshape the list of pixel values into a 28x28 matrix for use within the CNN and to display images. Images in the MNIST are in gray scale so rather than the three RGB colour channels there is only one channel.","db93cfbf":" Define the learning rate annealer to reduce the learning rate when training the model.","52e40a1c":"In order to improve the performance of the CNN, we augment the data using ImageDataGenerator to create additional images when training the model. Some examples of the augmented images are also shown.","9f363a43":"Check for missing values and class imbalance. Using the isnull() function, it can be observed that there are no null or missing values in this dataset because the output array is empty. The value_counts() function can be used to determine the unique counts of a class. This function arranges the counts in descending order so from the output it can be seen that class with digit 1 occurs most frequently with a count of 4684. From the bar plot it can be seen that the frequency with which each digit occurs is fairly consistent.","670601fc":"Display some of the training images to check what the handwritten characters look like. It can be seen that there is variation in the handwritten digits, e.g. the rotated 1.","8910b878":"Next the training and test data is normalized so that pixels are in between 0 to 1 rather than 0 to 255 and the labels of the training data are one hot encoded. One hot encoding maps numbered classes (0-9) to binary vectors e.g. class with digit 1 will be mapped to [0, 1, 0, 0, 0, 0, 0, 0, 0, 0].","1e178aa3":"Split the data into training and validation set for fitting a model using the sklearn train_test_split. In order to build a robust model, we need a validation set to test the model's accuracy as it learns information about the data. For this kernel, the data is split into a 90\/10 split, i.e., 90% of data is used for testing and 10% data is used for validation. The random seed is also set so that the splits can be reproduced if required.","1807fbf8":"## Creating the model\nA baseline model and a deeper model are defined next and compiled with the categorical cross entropy loss function and adam as the optimizer. Convolutional layers are used along with the relu activation function followed by batch normalization and maxpooling. The baseline model consists of one convolutional layer Conv2D as opposed to four convolutional layers in the deeper CNN. ","2d3c349e":"## Submitting the results","63ebbec8":"\n## Introduction\nThis dataset has 42000 training samples ranging over ten classes (0-9) of hand written digits. The test set consists of 28000 unlabelled samples that need to be labelled from 0-9. The samples are listed as a list of 784 values which can be reshaped into a 28x28 matrix in order to give an image. Such a problem is usually solved using a Convolutional Neural Network (CNN) which preserves the spatial information within images. In a traditional feed forward neural network, an image would have to be flattened i.e. in this case we would use the 784 values along with a bias value as an input to the network. However, in CNNs small squares of information from the 28x28 image scene are convolved with kernels\/filters and this information is then used to build a model. Such a structure is robust to distortions such as those caused due to shifts and translations in the scene.\n\nI tried a shallow baseline Convolutional Neural Network followed by a deeper model to check the level of improvement. The score of > 0.994 is achieved using the larger model structure so the baseline_model function call can be commented if only the main model needs to be run.\n\nUpdate: The baseline_model in this kernel is currently commented.\n\n* Data Preprocessing\n * Loading the data\n * Missing values and class imbalance\n * Visualizing the images\n * Creating the validation data set\n* Defining the models\n * Baseline model\n * Deeper CNN model\n * Learning rate scheduler\n * Data augmentation\n* Training the model\n* Evaluating the models\n * Plotting accuracy and loss\n* Generating the submission file\n\n\n\n","612c74c3":"## Data Preprocessing\nNext, the MNIST data is loaded using the Pandas library. It can be seen from the data frames that there are 42000 training examples, 28000 samples in the test data and 784 pixel values. ","f76805d0":"## Evaluating the model\nPlot the accuracy and loss of the models for the 100 epochs."}}