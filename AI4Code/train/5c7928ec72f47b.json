{"cell_type":{"502d88f7":"code","b63dcfb2":"code","964973e0":"code","00547cf4":"code","f7569cc9":"code","8d6e2870":"code","70d5a29c":"code","04bf9f43":"code","1d0d1be6":"code","0d38530d":"code","7794ae41":"code","e8ec98c6":"code","ef961107":"code","d4a05a6b":"code","15f64155":"code","92c7b0a8":"code","92b36bc9":"code","ee548769":"code","03e8b363":"code","a618ad8a":"code","07c53b11":"markdown","db5c770a":"markdown","e220b976":"markdown","8aaeee97":"markdown","b6eba42d":"markdown","1d98457c":"markdown","8a167a46":"markdown","cc9211bb":"markdown","f8bdf3c5":"markdown","2af61289":"markdown","ee8ee9f7":"markdown","f2f1d9a3":"markdown","88d5b9b9":"markdown","0035df93":"markdown"},"source":{"502d88f7":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as py\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom wordcloud import WordCloud\n\ninit_notebook_mode(connected=True) \n\nimport warnings\nwarnings.filterwarnings('ignore')","b63dcfb2":"df_train = pd.read_csv(\"..\/input\/data-science-bowl-2019\/train.csv\", parse_dates=[\"timestamp\"])\ndf_train_labels = pd.read_csv(\"..\/input\/data-science-bowl-2019\/train_labels.csv\")\ndf_specs = pd.read_csv(\"..\/input\/data-science-bowl-2019\/specs.csv\")\ndf_sample_submission = pd.read_csv(\"..\/input\/data-science-bowl-2019\/sample_submission.csv\")\ndf_test = pd.read_csv(\"..\/input\/data-science-bowl-2019\/test.csv\", parse_dates=[\"timestamp\"])","964973e0":"df_train.info()","00547cf4":"df_test.info()","f7569cc9":"print(\"Train Set Total Row Number: {0} \\nTrain Set Total Col Number: {1}\".format(df_train.shape[0], df_train.shape[1]))","8d6e2870":"print(\"Test Set Total Row Number: {0} \\nTest Set Total Col Number: {1}\".format(df_test.shape[0], df_test.shape[1]))","70d5a29c":"df_train.head()","04bf9f43":"print(df_train.loc[:, df_train.isnull().any()].isnull().sum())","1d0d1be6":"df_train.describe().T","0d38530d":"train_types = df_train[\"type\"].value_counts()\ntest_types = df_test[\"type\"].value_counts()","7794ae41":"fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n\nfig.add_trace(\n    go.Pie(values=train_types, labels=train_types.index.tolist(), name=\"Train\" , hole=.3),\n    1, 1)\n\nfig.add_trace(\n    go.Pie(values=test_types, labels=test_types.index.tolist(), name=\"Test\" , hole=.3),\n    1, 2)\n\nfig.update_traces(hoverinfo='label+percent+value', textinfo='percent', textfont_size=17, textposition=\"inside\",\n                  marker=dict(colors=['gold', 'mediumturquoise', 'darkorange', 'plum'],  \n                              line=dict(color='#000000', width=2)))\n\nfig.update_layout(\n    title_text=\"Media Type of The Game or Video\",\n    height=500, width=800,\n    annotations=[dict(text='Train', x=0.18, y=0.5, font_size=20, showarrow=False),\n                 dict(text='Test', x=0.82, y=0.5, font_size=20, showarrow=False)])\n\nfig.show()","e8ec98c6":"train_worlds = df_train[\"world\"].value_counts()\ntest_worlds = df_test[\"world\"].value_counts()","ef961107":"fig = make_subplots(rows=1, cols=2, specs=[[{'type':'xy'}, {'type':'xy'}]])\n\nfig.add_trace(\n    go.Bar(y=train_worlds.values, x=train_worlds.index),\n    row=1, col=1)\n\nfig.add_trace(\n    go.Bar(y=test_worlds.values, x=test_worlds.index),\n    row=1, col=2)\n\nfig.update_layout(\n    title_text=\"World of Apps\",\n    height=500, width=800, showlegend=False)\n\nfig['layout']['xaxis1'].update(title='Train')\nfig['layout']['xaxis2'].update(title='Test')\n\nfig.show()","d4a05a6b":"eventbyinstallation = df_train.groupby([\"installation_id\"])[\"event_code\"].nunique()\n\nfig = px.histogram(x=eventbyinstallation,\n                   title='Unique Event Code Count by Installation Id',\n                   opacity=0.8,\n                   color_discrete_sequence=['indianred'])\n\nfig.update_layout(\n    yaxis_title_text='',\n    xaxis_title_text='',\n    height=500, width=800)\n\nfig.update_traces(marker_line_color='rgb(8,48,107)',\n                  marker_line_width=1.5, opacity=0.8\n                 )\n\nfig.show()","15f64155":"event_id_by_ins_id_1 = df_train.groupby([\"installation_id\"])[\"event_id\"].agg(\"count\")[df_train.groupby([\"installation_id\"])[\"event_id\"].agg(\"count\")<2000]\nevent_id_by_ins_id_2 = df_train.groupby([\"installation_id\"])[\"event_id\"].agg(\"count\")[df_train.groupby([\"installation_id\"])[\"event_id\"].agg(\"count\")>=2000]\n\nfig = make_subplots(rows=1, cols=2)\n\ntrace1 = go.Histogram(x=event_id_by_ins_id_1,\n                      marker_color='#FF9999',\n                      opacity=0.2,\n                      nbinsx=40)\n\ntrace2 = go.Histogram(x=event_id_by_ins_id_2,\n                      marker_color='#9999CC',\n                      opacity=0.75,\n                      nbinsx=40)\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\n\n\nfig.update_layout(\n    height=500, width=800, showlegend=False,\n    title='Event Count by Installation Id')\n\nfig['layout']['xaxis1'].update(title='Part 1: 0-5k')\nfig['layout']['xaxis2'].update(title='Part 2: 5k-60k')\n\nfig.update_traces(marker_line_color='rgb(8,48,107)',\n                  marker_line_width=1.5, opacity=0.8\n                 )\n\nfig.show()","92c7b0a8":"df_events = df_train.loc[:,['timestamp', 'event_id','game_time']]\ndf_events[\"date\"] = df_events['timestamp'].dt.date","92b36bc9":"event_count = df_events.groupby(['date'])['event_id'].agg('count')\ngame_time_sum = df_events.groupby(['date'])['game_time'].agg('sum')\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=event_count.index, y=event_count.values,\n                         line=dict(color='firebrick', width=3)))\n\nfig.update_layout(title='Event Counts By Date',\n                   xaxis_title='Date',\n                   yaxis_title='Count',\n                   width=750, height=400)\n\nfig.show()\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=game_time_sum.index, y=game_time_sum.values,\n                         line=dict(color='midnightblue', width=3)))\n\nfig.update_layout(title='Total Game Time By Date',\n                   xaxis_title='Date',\n                   yaxis_title='Total',\n                   width=750, height=400)\n\nfig.show()","ee548769":"df_events[\"weekdays\"] = df_events['timestamp'].dt.weekday_name\n\ngametime_wdays = df_events.groupby(['weekdays'])['game_time'].agg('sum')\ngametime_wdays = gametime_wdays.T[['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']]\n\nfig = px.bar(x=gametime_wdays.index, y=gametime_wdays.values)\n\nfig.update_traces(marker_color='mediumvioletred', marker_line_color='rgb(8,48,107)',\n                  marker_line_width=2, opacity=0.7)\n\nfig.update_layout(title='Total Game Time By Day',\n                   xaxis_title='Weekdays',\n                   yaxis_title='Total',\n                   width=600, height=400\n                 )\n\nfig.show()","03e8b363":"title_words = []\n\nfor i in df_test[\"title\"]:\n    for j in i.split(\" \"):\n        title_words.append(j) ","a618ad8a":"plt.subplots(figsize=(14,7))\nwc=wordcloud = WordCloud(collocations=False,\n                          background_color='black',\n                          width=512,\n                          height=384\n                         ).generate(\" \".join(title_words)\n                                   )\n\nplt.imshow(wc)\nplt.axis('off')\nplt.title(\"Frequented Words in Title\", fontsize=18)\nplt.imshow(wc.recolor(colormap= 'viridis', random_state=2), alpha=0.90)\n\nplt.show()","07c53b11":"<a id=\"1\"><\/a> <br>\n# Importing Libraries and Loading Dataset","db5c770a":"There aren't any null values in all the dataset.","e220b976":"When I made the chart in one piece, the values that were too much dominated those with less. So for a better visual, I had to split the histogram chart into two parts. \n\nThe first part shows the distribution of those with a total installation_id of less than 2000 while the second section shows those more than 2000.","8aaeee97":"There is an important issue about installation_ids. The training set contains many installation_ids which never took assessments, whereas every installation_id in the test set made an attempt on at least one assessment.","b6eba42d":"<a id=\"2\"><\/a> <br>\n# EDA & Data Visualization","1d98457c":"\"CRYSTALCAVES\" and \"TREETOPCITY\" ratio has varied on test and train dataset. But they are still close to each other.","8a167a46":"<img src=\"https:\/\/i.ibb.co\/t2wvB6F\/Meas.png\" width=\"700\"> ","cc9211bb":"#### To be continued... If you like the kernel, Please upvote.","f8bdf3c5":"## 2019 Data Science Bowl","2af61289":"*In this dataset, you are provided with game analytics for the PBS KIDS Measure Up! app. In this app, children navigate a map and complete various levels, which may be activities, video clips, games, or assessments. Each assessment is designed to test a child's comprehension of a certain set of measurement-related skills.*","ee8ee9f7":"There are close distribution between train and test dataset. The difference is that train dataset has 10 times more data than test dataset. It can be viewed by hovering the pie chart.","f2f1d9a3":"There are nearly 11.5 M rows in Train dataset. ","88d5b9b9":"<a id=\"3\"><\/a> <br>\n# Ending","0035df93":"**Content**\n1. [Importing Libraries and Loading Dataset](#1)\n1. [EDA & Data Visualization](#2)\n1. [Ending](#3)"}}