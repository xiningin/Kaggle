{"cell_type":{"5a2fce1b":"code","fc141c84":"code","b82a9a71":"code","8c3848fa":"code","4d8a5905":"code","33689d78":"code","11961c47":"code","3efabab0":"code","52cae8fc":"code","52437477":"code","dccc9445":"code","08b4cdc7":"code","3d927acc":"code","569c723c":"code","c90ae8fb":"code","17056936":"code","14c99989":"code","a54133d3":"code","c01fe55e":"code","d4561af6":"code","c0364b65":"code","2021a391":"code","82773be6":"code","9a0eecfa":"code","79b234e1":"code","969e0b53":"code","201cef73":"code","99694f6d":"code","42361091":"code","f4325b0d":"code","9872e842":"code","057f4457":"code","6f0103fe":"code","7c9de3c5":"code","481dee64":"code","3989abf9":"code","81859bc2":"code","ef182c9e":"code","2eaad4ae":"code","84b71680":"code","2168c5ca":"code","6a6735ca":"code","5a354c8f":"code","55476f19":"code","38546677":"code","e82428e0":"code","ce06ad53":"code","20d07037":"code","fa21517c":"code","d324a61b":"code","52574de3":"code","7150a9cd":"code","f66ce532":"code","2fb7ca73":"code","5c6980f2":"code","b4edb21f":"code","c8750971":"code","058e66b0":"code","10ca7def":"code","5c8d7f3a":"code","b01b65a5":"code","ffc50526":"code","067bb5dd":"code","eec836c1":"code","a1f58453":"code","5c4bb010":"code","3e47e00a":"code","7881d1df":"code","e184335c":"code","767d35da":"code","a6a0c625":"code","91e017c9":"code","5fee2293":"code","35c75546":"code","cb2c863b":"code","415f173d":"code","952eb1f9":"code","8e21c7eb":"code","f19be5bd":"code","deac1ae0":"code","235973ea":"code","308a1658":"code","12662ee5":"code","f9427cf4":"code","52f7f25d":"code","aab7c208":"code","47262162":"code","b8aca35f":"code","91ff897f":"code","f25bd96b":"code","819be0a6":"code","b8893435":"code","5b47ba3e":"code","9d044de8":"code","302d7a90":"code","900ee7cf":"code","25e356e3":"code","ad56556a":"code","032a4368":"code","6941f131":"code","84bcf05b":"code","6fb81da4":"code","948994d1":"code","c0d05f04":"code","377c3011":"code","84410390":"code","26e678f7":"code","d8a013ab":"code","31661bd4":"code","fe312968":"code","23ca13c7":"code","0d4c8836":"code","7c2e4b85":"code","0b8e8d3c":"code","ac10364e":"code","19be09b2":"code","8a2dacb6":"markdown","d39ec074":"markdown","801a280f":"markdown","df65958c":"markdown","2273f390":"markdown","69f312cf":"markdown","5cbb3533":"markdown","a8cf02ec":"markdown","ca6e5348":"markdown","08474b0a":"markdown","d695bd11":"markdown","df3958dd":"markdown","2051b2f0":"markdown","a013daa0":"markdown","3b8da8ff":"markdown","636c9d49":"markdown","6eb33ec2":"markdown","ee29de99":"markdown","eadb131f":"markdown","178df78b":"markdown","544c1d9f":"markdown","0dd35760":"markdown","951bdc1a":"markdown","507f68b3":"markdown"},"source":{"5a2fce1b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nsns.color_palette()\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","fc141c84":"df_train = pd.read_csv(\"..\/input\/train.csv\")","b82a9a71":"df_train.head()","8c3848fa":"df_test = pd.read_csv(\"..\/input\/test.csv\")","4d8a5905":"df_test.head()","33689d78":"df_train.shape, df_test.shape","11961c47":"df_train.columns","3efabab0":"df_test.columns","52cae8fc":"df_train.describe()","52437477":"df_test.describe()","dccc9445":"df_train.info()","08b4cdc7":"df_test.info()","3d927acc":"df_train['Survived'].value_counts()","569c723c":"fig, ax = plt.subplots(figsize=(8, 8))\nsns.countplot(x='Survived', data=df_train)\nax.set_title('Survived Distribution')\nax.set_xlabel('Survived')\nax.set_ylabel('Count')\nplt.show()","c90ae8fb":"df_train['Sex'].value_counts()","17056936":"df_test['Sex'].value_counts()","14c99989":"fig, ax = plt.subplots(figsize=(8,8))\nsns.countplot(x='Sex', data=df_train)\nax.set_title('Distribution by Sex')\nax.set_xlabel('Sex')\nax.set_ylabel('Count')\nplt.show()","a54133d3":"df_train[df_train['Survived'] == 1]['Sex'].value_counts()","c01fe55e":"df_train[df_train['Survived'] == 0]['Sex'].value_counts()","d4561af6":"fig, ax = plt.subplots(figsize=(8,8))\nsns.countplot(x='Sex', data=df_train, hue='Survived')\nax.set_title('Survival by sex of traveller', fontsize=15)\nax.set_xlabel('Sex', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","c0364b65":"df_train['Sex'] = df_train['Sex'].map({'female': 0, 'male': 1})","2021a391":"df_test['Sex'] = df_test['Sex'].map({'female': 0, 'male': 1})","82773be6":"df_train['Pclass'].value_counts()","9a0eecfa":"fig, ax = plt.subplots(figsize=(8,8))\nsns.countplot(x='Pclass', data=df_train)\nax.set_title('Passenger Distribution by class', fontsize=15)\nax.set_xlabel('Class', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","79b234e1":"df_train[df_train['Survived'] == 1]['Pclass'].value_counts()","969e0b53":"fig, ax = plt.subplots(figsize=(8, 8))\nsns.countplot(x=\"Pclass\", data=df_train, hue='Survived')\nax.set_title('Survival by class')\nax.set_xlabel('Class')\nax.set_ylabel('Count')\nplt.show()","201cef73":"df_train['Salutation'] = df_train['Name'].transform(lambda x : x.split(',')[1].split('.')[0])\ndf_train['Salutation'] = df_train['Salutation'].transform(lambda x: x.str.strip())","99694f6d":"df_train['Salutation'].value_counts()","42361091":"df_test['Salutation'] = df_test['Name'].transform(lambda x : x.split(',')[1].split('.')[0])\ndf_test['Salutation'] = df_test['Salutation'].transform(lambda x: x.str.strip())","f4325b0d":"df_test['Salutation'].value_counts()","9872e842":"df_train['Salutation'] = df_train['Salutation'].replace(['Ms', 'Mlle'], 'Miss')","057f4457":"df_test['Salutation'] = df_test['Salutation'].replace(['Ms', 'Mlle'], 'Miss')","6f0103fe":"df_train['Salutation'] = df_train['Salutation'].replace('Mme', 'Mrs')","7c9de3c5":"df_train['Salutation'] = df_train['Salutation'].replace(['Dr', 'Rev', 'Col', 'Major', 'Sir', 'Don', \n                        'Jonkheer', 'the Countess', 'Capt', 'Lady', 'Dona'], 'Other')","481dee64":"df_test['Salutation'] = df_test['Salutation'].replace(['Dr', 'Rev', 'Col', 'Major', 'Sir', 'Don', \n                        'Jonkheer', 'the Countess', 'Capt', 'Lady', 'Dona'], 'Other')","3989abf9":"df_train['Salutation'].value_counts()","81859bc2":"fig, ax = plt.subplots(figsize=(10, 10))\nsns.countplot(x='Salutation', data=df_train)\nax.set_title('Salutation\/Title Distribution', fontsize=15)\nax.set_xlabel('Salutation', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","ef182c9e":"fig, ax = plt.subplots(figsize=(10, 10))\nsns.countplot(x='Salutation', data=df_train, hue='Survived')\nax.set_title('Salutation\/Title Distribution', fontsize=15)\nax.set_xlabel('Salutation', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","2eaad4ae":"df_test['Salutation'].value_counts()","84b71680":"fig, ax = plt.subplots(figsize=(10, 10))\nsns.countplot(x='Salutation', data=df_test)\nax.set_title('Salutation\/Title Distribution', fontsize=15)\nax.set_xlabel('Salutation', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","2168c5ca":"df_train['Salutation'] = df_train['Salutation'].map({'Mr':0, 'Mrs':1, 'Miss':2, 'Master':3, 'Other':4})","6a6735ca":"df_test['Salutation'] = df_test['Salutation'].map({'Mr':0, 'Mrs':1, 'Miss':2, 'Master':3, 'Other':4})","5a354c8f":"df_train['Is_Alone'] = 0\nfor index, item in df_train.iterrows():\n    if item['Parch'] ==0 and item['SibSp'] == 0:\n        df_train.loc[index, 'Is_Alone'] = 1","55476f19":"df_train['Is_Alone'].value_counts()","38546677":"fig, ax = plt.subplots(figsize=(10,10))\nsns.countplot(x='Is_Alone', data=df_train)\nax.set_title('Lone Travellers Distribution', fontsize=15)\nax.set_xlabel('Is_Alone', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","e82428e0":"fig, ax = plt.subplots(figsize=(8, 8))\nsns.countplot(x='Is_Alone', data=df_train, hue='Survived')\nax.set_title('Survival of Passengers travelled alone', fontsize=15)\nax.set_xlabel('Is_Alone', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","ce06ad53":"df_test['Is_Alone'] = 0\nfor index, item in df_test.iterrows():\n    if item['Parch'] ==0 and item['SibSp'] == 0:\n        df_test.loc[index, 'Is_Alone'] = 1","20d07037":"fig, ax = plt.subplots(figsize=(10,10))\nsns.countplot(x='Is_Alone', data=df_test)\nax.set_title('Lone Travellers Distribution - Test', fontsize=15)\nax.set_xlabel('Is_Alone', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","fa21517c":"df_train['Cabin'] = df_train['Cabin'].transform(lambda x: 0 if pd.isnull(x) else 1)","d324a61b":"df_train['Cabin'].value_counts()","52574de3":"fig, ax = plt.subplots(figsize=(8,8))\nsns.countplot(x='Cabin', data=df_train)\nax.set_title('Cabin Distribution', fontsize=15)\nax.set_xlabel('Has Cabin', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","7150a9cd":"fig, ax = plt.subplots(figsize=(8, 8))\nsns.countplot(x='Cabin', data=df_train, hue='Survived')\nax.set_title('Survival of travellers with Cabin', fontsize=15)\nax.set_xlabel('Cabin', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","f66ce532":"df_test['Cabin'] = df_test['Cabin'].transform(lambda x: 0 if pd.isnull(x) else 1)\ndf_test['Cabin'].value_counts()","2fb7ca73":"fig, ax = plt.subplots(figsize=(8,8))\nsns.countplot(x='Cabin', data=df_test)\nax.set_title('Cabin Distribution', fontsize=15)\nax.set_xlabel('Has Cabin', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","5c6980f2":"df_train['Embarked'] = df_train['Embarked'].fillna('S')","b4edb21f":"df_train['Embarked'].value_counts()","c8750971":"fig, ax = plt.subplots(figsize=(10, 10))\nsns.countplot(x='Embarked', data=df_train)\nax.set_title('Embarked Distribution')\nax.set_xlabel('Embarked')\nax.set_ylabel('Count')\nplt.show()","058e66b0":"fig, ax = plt.subplots(figsize=(10, 10))\nsns.countplot(x='Embarked', data=df_train, hue='Survived')\nax.set_title('Embarked Distribution')\nax.set_xlabel('Embarked')\nax.set_ylabel('Count')\nplt.show()","10ca7def":"df_test['Embarked'].value_counts()","5c8d7f3a":"fig, ax = plt.subplots(figsize=(10, 10))\nsns.countplot(x='Embarked', data=df_test)\nax.set_title('Embarked Distribution')\nax.set_xlabel('Embarked')\nax.set_ylabel('Count')\nplt.show()","b01b65a5":"df_train['Embarked'] = df_train['Embarked'].map({'C':0, 'S':1, 'Q':2})\ndf_test['Embarked'] = df_test['Embarked'].map({'C':0, 'S':1, 'Q':2})","ffc50526":"df_train.drop('Ticket', inplace=True, axis=1)","067bb5dd":"df_test.drop('Ticket', inplace=True, axis=1)","eec836c1":"df_test['Fare'].describe()","a1f58453":"df_test['Fare'] = df_test['Fare'].fillna(df_test['Fare'].median())","5c4bb010":"pd.qcut(df_train['Fare'], 4).unique()","3e47e00a":"df_train.loc[df_train['Fare'] <= 7.91, 'Fare'] = 0\ndf_train.loc[((df_train['Fare'] > 7.91) & (df_train['Fare'] <= 14.454)), 'Fare'] = 1\ndf_train.loc[((df_train['Fare'] > 14.454) & (df_train['Fare'] <= 31)), 'Fare'] = 2\ndf_train.loc[df_train['Fare'] > 31, 'Fare'] = 3","7881d1df":"df_test.loc[df_test['Fare'] <= 7.91, 'Fare'] = 0\ndf_test.loc[((df_test['Fare'] > 7.91) & (df_test['Fare'] <= 14.454)), 'Fare'] = 1\ndf_test.loc[((df_test['Fare'] > 14.454) & (df_test['Fare'] <= 31)), 'Fare'] = 2\ndf_test.loc[df_test['Fare'] > 31, 'Fare'] = 3","e184335c":"df_train['Fare'] = df_train['Fare'].astype('int')\ndf_test['Fare'] = df_test['Fare'].astype('int')\ndf_train['Fare'].value_counts()","767d35da":"fig, ax = plt.subplots(figsize=(10, 10))\nsns.countplot(x='Fare', data=df_train)\nax.set_title('Fare Distribution', fontsize=15)\nax.set_xlabel('Fare', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","a6a0c625":"fig, ax = plt.subplots(figsize=(10, 10))\nsns.countplot(x='Fare', data=df_train, hue='Survived')\nax.set_title('Fare Distribution', fontsize=15)\nax.set_xlabel('Fare', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","91e017c9":"df_train['Age'].isna().sum()","5fee2293":"df_test['Age'].isna().sum()","35c75546":"age_avg   = df_train['Age'].mean()\nage_std  = df_train['Age'].std()\nage_null_count = df_train['Age'].isnull().sum()\n\nage_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\ndf_train['Age'][np.isnan(df_train['Age'])] = age_null_random_list\ndf_train['Age'] = df_train['Age'].astype(int)\n    \npd.cut(df_train['Age'], 5).unique()","cb2c863b":"df_train.loc[df_train['Age']<=16, 'Age'] = 0\ndf_train.loc[((df_train['Age']>16)&(df_train['Age']<=32)), 'Age'] = 1\ndf_train.loc[((df_train['Age']>32)&(df_train['Age']<=48)), 'Age'] = 2\ndf_train.loc[((df_train['Age']>48)&(df_train['Age']<=64)), 'Age'] = 3\ndf_train.loc[df_train['Age']>64, 'Age'] = 4","415f173d":"age_avg   = df_test['Age'].mean()\nage_std  = df_test['Age'].std()\nage_null_count = df_test['Age'].isnull().sum()\n\nage_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\ndf_test['Age'][np.isnan(df_test['Age'])] = age_null_random_list\ndf_test['Age'] = df_test['Age'].astype(int)","952eb1f9":"df_test.loc[df_test['Age']<=16, 'Age'] = 0\ndf_test.loc[((df_test['Age']>16)&(df_test['Age']<=32)), 'Age'] = 1\ndf_test.loc[((df_test['Age']>32)&(df_test['Age']<=48)), 'Age'] = 2\ndf_test.loc[((df_test['Age']>48)&(df_test['Age']<=64)), 'Age'] = 3\ndf_test.loc[df_test['Age']>64, 'Age'] = 4","8e21c7eb":"df_test.head()","f19be5bd":"df_train.drop('Name', axis=1, inplace=True)","deac1ae0":"df_test.drop('Name', axis=1, inplace=True)","235973ea":"df_train.head()","308a1658":"df_test.head()","12662ee5":"df_train.dtypes","f9427cf4":"df_test.dtypes","52f7f25d":"PassengerId = df_test['PassengerId'].ravel()\ny_all = df_train['Survived'].ravel()","aab7c208":"df_train.drop('PassengerId', axis=1, inplace=True)\ndf_test.drop('PassengerId', axis=1, inplace=True)","47262162":"X_all = df_train.iloc[:, 1:]\nX_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)","b8aca35f":"fig, ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(X_all.corr(), annot=True)\nax.set_title('Correlation of training set')\nplt.show()","91ff897f":"fig, ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(df_test.corr(), annot=True)\nax.set_title('Correlation of test set')\nplt.show()","f25bd96b":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import make_scorer, accuracy_score\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC","819be0a6":"acc_scorer = make_scorer(accuracy_score)\n'''\nclf = RandomForestClassifier()\nrf_params = {\n    \"n_estimators\": [100, 300, 500, 1000],\n    \"bootstrap\": [True, False],\n    \"criterion\": ['gini', 'entropy'],\n    \"warm_start\": [True, False],\n    \"max_depth\": [2, 4, 6],\n    \"max_features\": ['sqrt', 'log2'],\n    \"min_samples_split\": [2, 4, 6],\n    \"min_samples_leaf\": [2, 4, 6]\n}\n\nclf = ExtraTreesClassifier()\nxt_params = {\n    \"n_estimators\":[100, 300, 500, 1000],\n    \"bootstrap\": [True, False],\n    \"criterion\": ['gini', 'entropy'],\n    \"warm_start\": [True, False],\n    \"max_depth\": [2, 4, 6],\n    \"max_features\": ['sqrt', 'log2'],\n    \"min_samples_split\": [2, 4, 6],\n    \"min_samples_leaf\": [2, 4, 6]\n}\n\nclf = AdaBoostClassifier()\nad_params = {\n    \"n_estimators\":[100, 300, 500, 1000],\n    \"learning_rate\": [0.1, 0.3, 0.5, 0.75, 1]\n}\nclf = GradientBoostingClassifier()\ngb_params = {\n    \"n_estimators\":[100, 300, 500, 1000],\n    \"learning_rate\": [0.1, 0.3, 0.5, 0.75, 1],\n    \"warm_start\": [True, False],\n    \"max_depth\": [2, 4, 6],\n    \"max_features\": ['sqrt', 'log2'],\n    \"min_samples_split\": [2, 4, 6],\n    \"min_samples_leaf\": [2, 4, 6]\n}\nclf = SVC()\nsv_params = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [0.01, 0.1, 1, 10, 100]},\n                    {'kernel': ['linear'], 'C': [0.01, 0.1, 1, 10, 100]}]'''","b8893435":"#grid_search = GridSearchCV(clf, param_grid=sv_params, scoring=acc_scorer)\n#grid_search.fit(X_train, y_train)","5b47ba3e":"#grid_search.best_estimator_","9d044de8":"rf_clf = RandomForestClassifier(bootstrap=False, class_weight=None,\n            criterion='entropy', max_depth=6, max_features='log2',\n            max_leaf_nodes=None, min_impurity_decrease=0.0,\n            min_impurity_split=None, min_samples_leaf=4,\n            min_samples_split=4, min_weight_fraction_leaf=0.0,\n            n_estimators=300, n_jobs=None, oob_score=False,\n            random_state=42, verbose=0, warm_start=True)\n\net_clf = ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n           max_depth=6, max_features='sqrt', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=2, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n           oob_score=False, random_state=42, verbose=0, warm_start=False)\n\nad_clf = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n          learning_rate=0.1, n_estimators=300, random_state=42)\n\ngb_clf = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n              learning_rate=0.1, loss='deviance', max_depth=2,\n              max_features='log2', max_leaf_nodes=None,\n              min_impurity_decrease=0.0, min_impurity_split=None,\n              min_samples_leaf=2, min_samples_split=2,\n              min_weight_fraction_leaf=0.0, n_estimators=300,\n              n_iter_no_change=None, presort='auto', random_state=42,\n              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n              verbose=0, warm_start=False)\n\nsv_clf = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n  max_iter=-1, probability=False, random_state=42, shrinking=True,\n  tol=0.001, verbose=False)","302d7a90":"rf_clf.fit(X_train, y_train)\net_clf.fit(X_train, y_train)\nad_clf.fit(X_train, y_train)\ngb_clf.fit(X_train, y_train)\nsv_clf.fit(X_train, y_train)","900ee7cf":"rf_rank = rf_clf.feature_importances_\net_rank = et_clf.feature_importances_\nad_rank = ad_clf.feature_importances_\ngb_rank = gb_clf.feature_importances_","25e356e3":"df_feature_importance = pd.DataFrame({\n    'Features': X_all.columns,\n    'Random_Forest': rf_rank,\n    'Extra_Trees': et_rank,\n    'AdaBoost': ad_rank,\n    'Gradient_Boost': gb_rank\n})","ad56556a":"df_feature_importance","032a4368":"fig, ax=plt.subplots(figsize=(10, 8))\nsns.barplot(x=df_feature_importance['Features'], y=df_feature_importance['Random_Forest'])\nax.set_title('Random Forest Feature Importance', fontsize=12)\nax.set_ylabel('Feature Importance', fontsize=12)\nax.set_xlabel('Column Name', fontsize=12)\nplt.show()","6941f131":"fig, ax=plt.subplots(figsize=(10, 8))\nsns.barplot(x=df_feature_importance['Features'], y=df_feature_importance['Extra_Trees'])\nax.set_title('Extra Trees Feature Importance', fontsize=12)\nax.set_ylabel('Feature Importance', fontsize=12)\nax.set_xlabel('Column Name', fontsize=12)\nplt.show()","84bcf05b":"fig, ax=plt.subplots(figsize=(10, 8))\nsns.barplot(x=df_feature_importance['Features'], y=df_feature_importance['AdaBoost'])\nax.set_title('AdaBoost Feature Importance', fontsize=12)\nax.set_ylabel('Feature Importance', fontsize=12)\nax.set_xlabel('Column Name', fontsize=12)\nplt.show()","6fb81da4":"fig, ax=plt.subplots(figsize=(10, 8))\nsns.barplot(x=df_feature_importance['Features'], y=df_feature_importance['Gradient_Boost'])\nax.set_title('Gradient Boosting Importance', fontsize=12)\nax.set_ylabel('Feature Importance', fontsize=12)\nax.set_xlabel('Column Name', fontsize=12)\nplt.show()","948994d1":"rf_pred = rf_clf.predict(X_test)\net_pred = et_clf.predict(X_test)\nad_pred = ad_clf.predict(X_test)\ngb_pred = gb_clf.predict(X_test)\nsv_pred = sv_clf.predict(X_test)","c0d05f04":"print('Random Forest Accuracy: {0:.2f}'.format(accuracy_score(y_test, rf_pred) * 100))\nprint('Extra Trees Accuracy: {0:.2f}'.format(accuracy_score(y_test, et_pred) * 100))\nprint('AdaBoost Accuracy: {0:.2f}'.format(accuracy_score(y_test, ad_pred) * 100))\nprint('Gradient Boosting Accuracy: {0:.2f}'.format(accuracy_score(y_test, gb_pred) * 100))\nprint('SVM Accuracy: {0:.2f}'.format(accuracy_score(y_test, sv_pred) * 100))","377c3011":"def KFold_pred(clf, X_all, y_all):\n    outcomes = []\n    test_scores = []\n    kf = KFold(n_splits=5, random_state=42, shuffle=False)\n    for i, (train_index, test_index) in enumerate(kf.split(X_all)):\n        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n        y_train, y_test = y_all[train_index], y_all[test_index]\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        acc = accuracy_score(y_pred, y_test)\n        outcomes.append(acc)\n        print('Fold {0} accuracy {1:.2f}'.format(i, acc))\n    mean_accuracy = np.mean(outcomes)\n    return mean_accuracy","84410390":"rf_pred = KFold_pred(rf_clf, X_all, y_all)\nprint('Random Forest 5 folds mean accuracy: {0:.2f}'.format(rf_pred))\net_pred = KFold_pred(et_clf, X_all, y_all)\nprint('Extra Trees 5 folds mean accuracy: {0:.2f}'.format(et_pred))\nad_pred = KFold_pred(ad_clf, X_all, y_all)\nprint('AdaBoost 5 folds mean accuracy: {0:.2f}'.format(ad_pred))\ngb_pred = KFold_pred(gb_clf, X_all, y_all)\nprint('Gradient Boosting 5 folds mean accuracy: {0:.2f}'.format(gb_pred))\nsv_pred = KFold_pred(sv_clf, X_all, y_all)\nprint('SVM 5 folds mean accuracy: {0:.2f}'.format(sv_pred))","26e678f7":"def oof_pred(clf, X_all, y_all, df_test):\n    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n    oof_train = np.zeros(X_all.shape[0])\n    oof_test = np.zeros(df_test.shape[0])\n    oof_test_kf = np.empty((kf.get_n_splits(), df_test.shape[0]))\n    for i, (train_index, test_index) in enumerate(kf.split(X_all)):\n        X_train = X_all.values[train_index]\n        y_train = y_all[train_index]\n        X_test = X_all.values[test_index]\n        y_test = y_all[test_index]\n        \n        clf.fit(X_train, y_train)\n        oof_train[test_index] = clf.predict(X_test)\n        oof_test_kf[i, :] = clf.predict(df_test)\n    oof_test = oof_test_kf.mean(axis=0)\n    return oof_train, oof_test","d8a013ab":"rf_oof_train, rf_oof_test = oof_pred(rf_clf, X_all, y_all, df_test)\net_oof_train, et_oof_test = oof_pred(et_clf, X_all, y_all, df_test)\nad_oof_train, ad_oof_test = oof_pred(ad_clf, X_all, y_all, df_test)\ngb_oof_train, gb_oof_test = oof_pred(gb_clf, X_all, y_all, df_test)\nsv_oof_train, sv_oof_test = oof_pred(sv_clf, X_all, y_all, df_test)","31661bd4":"base_level_train = pd.DataFrame({\n    'Random_Forest':rf_oof_train,\n    'Extra_Trees': et_oof_train,\n    'AdaBoost': ad_oof_train,\n    'Gradient_Boost':gb_oof_train,\n    'Support_Vector':sv_oof_train\n})","fe312968":"base_level_train.head()","23ca13c7":"fig, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(base_level_train.corr(), annot=True)\nplt.show()","0d4c8836":"base_level_test = pd.DataFrame({\n    'Random_Forest':rf_oof_test,\n    'Extra_Trees': et_oof_test,\n    'AdaBoost': ad_oof_test,\n    'Gradient_Boost':gb_oof_test,\n    'Support_Vector':sv_oof_test\n})","7c2e4b85":"base_level_test.head()","0b8e8d3c":"import xgboost as xgb\nxg_clf = xgb.XGBClassifier(\n n_estimators= 2000,\n max_depth= 4,\n min_child_weight= 2,\n #gamma=1,\n gamma=0.9,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread= -1,\n scale_pos_weight=1)","ac10364e":"xg_clf.fit(base_level_train, y_all)\npredictions = xg_clf.predict(base_level_test)","19be09b2":"output = pd.DataFrame({ 'PassengerId' : PassengerId, 'Survived': predictions.astype(int) })\noutput.to_csv('titanic-predictions.csv', index = False)\noutput.tail()","8a2dacb6":"Let's check fare feature. Since the std deviation is high and the feature is continuous, let's fill the null value with median.","d39ec074":"Check survived travellers whi travelled alone","801a280f":"Let's extract salutation from Name","df65958c":"# Model Creation","2273f390":"There are 891 records in train set and 418 in test set. Age, Cabin has null values in train set. Age, Cabin and Fare(1 record) has null values in test set.","69f312cf":"Survival of travellers who had cabin","5cbb3533":"Let's map Fare to 4 quartiles using qcut.","a8cf02ec":"Let's deal with Ticket feature. Ticket feature does not have any important information. So let's drop this feature.","ca6e5348":"Analyse Survived","08474b0a":"Male and Female distribution","d695bd11":"Identify the lone travellers. Travellers with 0 Parch and 0 SibSp are lone travellers.","df3958dd":"We can group the above salutations to **Mr**, **Miss**(Miss, Ms, Mlle), **Mrs**(Mrs, Mme), **Master,** **Other**(Dr, Rev, Col, Major, Sir, Don, Jonkheer, the Countess, Capt, Lady, Dona)","2051b2f0":"The more the fare more people survived. Now finally let's deal with Age.","a013daa0":"**Grid Search:**\n1. Random Forest \n2. Extra Trees \n3. AdaBoost \n4. Gradient Boosting\n5. SVM","3b8da8ff":"Distribution by Class","636c9d49":"The train and test set - Get the shape, columns, description of the columns.","6eb33ec2":"With Random Forest OOF values I got a public score of 0.80861. Let's use these outputs as new features and classify using LightGBM and XGBoost to check the improvement. ","ee29de99":"Let's deal with travellers who had cabin. Let's change the cabin feature to 1 for travellers with cabin and zero for others.","eadb131f":"Age feature has too many null values. Let's fill the values by taking the mean and stddev. [Inspiration taken from Titanic best working Classifier](https:\/\/www.kaggle.com\/sinakhorami\/titanic-best-working-classifier)","178df78b":"# Let's build some classifiers","544c1d9f":"Let's store the PassengerId for submitting predictions. Survived column for training ","0dd35760":"Check the mean value of predictions of a classifier using KFold","951bdc1a":"**Out of fold average** : Out of fold average for the training and test set which will be used later for stacking","507f68b3":"Let's handle embarked. Fill 2 null values with mode ('S')"}}