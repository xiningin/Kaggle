{"cell_type":{"df3c23d0":"code","025a3309":"code","05fdebd9":"code","7f07e65f":"code","306c70e6":"code","6e078871":"code","a9f80390":"code","db7b5b77":"code","b16eac2f":"code","030d7381":"code","5eb0140b":"code","e66b8d05":"code","4048d385":"code","f757c872":"code","f2613dfe":"code","87dbef68":"code","8551b0e8":"code","df1aa617":"code","6d6ff537":"code","4c060eb5":"code","d564696d":"code","e30dd144":"code","165962e2":"code","b512af57":"markdown","4d2fa0d6":"markdown","4bf1ef93":"markdown","e85d4c71":"markdown","c067c5c1":"markdown","97bae5a5":"markdown","55c00dae":"markdown"},"source":{"df3c23d0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","025a3309":"import torch\nimport fastai\nfrom fastai.tabular.all import *\nfrom fastai.text.all import *\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\nfrom fastai import *\n\nimport time\nfrom datetime import datetime\n\nprint(f'Notebook last run on {datetime.fromtimestamp(time.time()).strftime(\"%Y-%m-%d, %H:%M:%S UTC\")}')\nprint('Using fastai version ',fastai.__version__)\nprint('And torch version ',torch.__version__)","05fdebd9":"def plot_fastai_results(learn):\n    '''\n    Plots sensitivity, speficificty, prevalence, accuracy, and confusion matrix for a fastai model named \"learn\".\n    Some portions are adapted from https:\/\/github.com\/fastai\/fastai\/blob\/master\/nbs\/61_tutorial.medical_imaging.ipynb\n    '''\n    interp = Interpretation.from_learner(learn)\n    interp = ClassificationInterpretation.from_learner(learn)\n    interp.plot_confusion_matrix(figsize=(7,7))\n    losses,idxs = interp.top_losses()\n    len(dls.valid_ds)==len(losses)==len(idxs)\n    upp, low = interp.confusion_matrix()\n    tn, fp = upp[0], upp[1]\n    fn, tp = low[0], low[1]\n    sensitivity = tp\/(tp + fn)\n    print('Sensitivity: ',sensitivity)\n    specificity = tn\/(fp + tn)\n    print('Specificity: ',specificity)\n    #val = dls.valid_ds.cat\n    prevalance = 15\/50\n    print('Prevalance: ',prevalance)\n    accuracy = (sensitivity * prevalance) + (specificity * (1 - prevalance))\n    print('Accuracy: ',accuracy)","7f07e65f":"tfms = aug_transforms(max_rotate=25)","306c70e6":"len(tfms)","6e078871":"from PIL import Image\n\nimage = Image.open(\"..\/input\/goblin-portraits\/images\/0078f2ae5ef488769386.jpg\")\nimage","a9f80390":"# importing all the required libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport skimage.io as io\nfrom skimage.transform import rotate, AffineTransform, warp\nfrom skimage.util import random_noise\nfrom skimage.filters import gaussian\nimport matplotlib.pyplot as plt\nimport PIL.Image\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms","db7b5b77":"def imshow(img, transform):\n    \"\"\"helper function to show data augmentation\n    :param img: path of the image\n    :param transform: data augmentation technique to apply\"\"\"\n    \n    img = PIL.Image.open(img)\n    fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n    ax[0].set_title(f'original image {img.size}')\n    ax[0].imshow(img)\n    img = transform(img)\n    ax[1].set_title(f'transformed image {img.size}')\n    ax[1].imshow(img)","b16eac2f":"loader_transform = transforms.Resize((140, 140))\n\nimshow('..\/input\/goblin-portraits\/images\/0078f2ae5ef488769386.jpg', loader_transform)","030d7381":"print('Rotated Image')\n#rotating the image by 45 degrees\nrotated = rotate(image, angle=45, mode = 'wrap')\n#plot the rotated image\nio.imshow(rotated)","5eb0140b":"#flip image up-to-down\nflipUD = np.flipud(image)\n\nplt.imshow(flipUD)\nplt.title('Up Down Flipped')","e66b8d05":"#Hue can be described of as the shade of the colors in an image\n\nimg = PIL.Image.open('..\/input\/goblin-portraits\/images\/0078f2ae5ef488769386.jpg')\nfig, ax = plt.subplots(2, 2, figsize=(16, 10))\n\n# brightness\nloader_transform1 = transforms.ColorJitter(brightness=2)\nimg1 = loader_transform1(img)\nax[0, 0].set_title(f'brightness')\nax[0, 0].imshow(img1)\n\n# contrast\nloader_transform2 = transforms.ColorJitter(contrast=2)\nimg2 = loader_transform2(img)\nax[0, 1].set_title(f'contrast')\nax[0, 1].imshow(img2)\n\n# saturation\nloader_transform3 = transforms.ColorJitter(saturation=2)\nimg3 = loader_transform3(img)\nax[1, 0].set_title(f'saturation')\nax[1, 0].imshow(img3)\nfig.savefig('color augmentation', bbox_inches='tight')\n\n# hue\nloader_transform4 = transforms.ColorJitter(hue=0.2)\nimg4 = loader_transform4(img)\nax[1, 1].set_title(f'hue')\nax[1, 1].imshow(img4)\n\nfig.savefig('color augmentation', bbox_inches='tight')","4048d385":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","f757c872":"from fastai.vision.all import *\nfrom fastai.imports import *\nfrom fastai.vision.data import *\nfrom fastai import *\nimport numpy as np\nimport fastai\nimport matplotlib.pyplot as plt","f2613dfe":"path = Path(\"\/kaggle\/input\/goblin-portraits\/images\")\npath.ls()","87dbef68":"np.random.seed(42)\ndata = ImageDataLoaders.from_folder(path, train=\".\", valid_pct=0.2, item_tfms=RandomResizedCrop(512, min_scale=0.75),\n                                    bs=32,batch_tfms=[*aug_transforms(size=256, max_warp=0), Normalize.from_stats(*imagenet_stats)],num_workers=0)","8551b0e8":"data.show_batch(nrows=3, figsize=(7,8))","df1aa617":"data.show_batch(nrows=2, figsize=(7,8))","6d6ff537":"data.show_batch(nrows=1, figsize=(7,8))","4c060eb5":"path2 = Path('\/kaggle\/input\/goblin-portraits\/images\/')\ndls = ImageDataLoaders.from_folder(path, train='train',\n                                   item_tfms=Resize(224),valid_pct=0.2,\n                                   bs=64,seed=0)\ndls.show_batch()","d564696d":"#learn = cnn_learner(dls, resnet34, metrics=accuracy, model_dir='\/kaggle\/tmp\/model\/')\n#learn.lr_find()\n#learn.fine_tune(5)\n#learn.show_results()","e30dd144":"#plot_fastai_results(learn=learn)","165962e2":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#2B3A67','#42a7f5','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Mar\u00edlia Prata, not a DS. Stick around, I will be right back. @mpwolke' )","b512af57":"#Code from Unnat Antani  https:\/\/www.kaggle.com\/unnatantani\/flower-classification-using-fastai","4d2fa0d6":"#get_transforms Now is aug_transforms.  But I am still looking for an open_image replacement so that I can open a Single image.","4bf1ef93":"#Code from Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/fastai-v2-with-image-text-and-tabular-data","e85d4c71":"![](https:\/\/media2.giphy.com\/media\/BHNVC6suWIKs\/200w.webp?cid=ecf05e47wb2oak6u4jxxfy4gogfjmcklykpg2ra9bo536zgw&rid=200w.webp)","c067c5c1":"#Codes by Naim Mhedhbi https:\/\/www.kaggle.com\/naim99\/data-augmentation-techniques","97bae5a5":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcQgCMv_1Vbk7rcpGlJtqy636vO6yj3RMtwWUw&usqp=CAU)redbubble.com","55c00dae":"#That's insane, The pneumothorax from Paul has nothing to do with the Goblins. Therefore the Confusion Matrix does not belong here.\n\n#That snippet above took so long that is why I miss my previous code with no classification,just images."}}