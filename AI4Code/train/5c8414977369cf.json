{"cell_type":{"c7491b16":"code","85ed169f":"code","8ad729a6":"code","87848350":"code","e975050d":"code","d5ae4ed5":"code","77bc00a3":"code","68ea5eb9":"code","aa7857ca":"code","70317b9b":"code","31401892":"code","bd2d9da5":"code","a88ed897":"code","c67efee5":"code","0df06dd5":"code","58681ba8":"code","4c27d3c5":"code","955b6321":"code","74472587":"markdown","c011ad7d":"markdown","3a9b1d0c":"markdown","3b86ddc9":"markdown","584fabcb":"markdown","ab3fe720":"markdown","2414ffed":"markdown","f227f5c8":"markdown","118706e5":"markdown","911e9a1a":"markdown","1fa91098":"markdown","aaf81ded":"markdown","e016c919":"markdown","e53d8a62":"markdown"},"source":{"c7491b16":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import metrics\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.optimizers import *\nimport plotly.express as px\nimport plotly.figure_factory as ff","85ed169f":"df=pd.read_csv('\/kaggle\/input\/car-price-prediction\/CarPrice_Assignment.csv', index_col='car_ID')\ndf.head(10)","8ad729a6":"df.info()","87848350":"df.describe()","e975050d":"df.isnull().sum()","d5ae4ed5":"df.duplicated(subset=df.columns).sum()","77bc00a3":"encoder = LabelEncoder()\n\ndf['fueltype'] = encoder.fit_transform(df['fueltype'])\ndf['aspiration'] = encoder.fit_transform(df['aspiration'])\ndf['doornumber'] = encoder.fit_transform(df['doornumber'])\ndf['carbody'] = encoder.fit_transform(df['carbody'])\ndf['drivewheel'] = encoder.fit_transform(df['drivewheel'])\ndf['enginelocation'] = encoder.fit_transform(df['enginelocation'])\ndf['enginetype'] = encoder.fit_transform(df['enginetype'])\ndf['cylindernumber'] = encoder.fit_transform(df['cylindernumber'])\ndf['fuelsystem'] = encoder.fit_transform(df['fuelsystem'])","68ea5eb9":"del df['CarName']","aa7857ca":"X = df[df.columns[:-1]]\ny = np.array(df['price'])","70317b9b":"scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\n\nX = scaler.fit_transform(X)","31401892":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)","bd2d9da5":"model1 = LinearRegression()\nmodel1.fit(X_train,y_train)\n\nprint(\"Score: \", round(model1.score(X_test,y_test)*100,3), \"%\")","a88ed897":"model2 = DecisionTreeRegressor()\nmodel2.fit(X_train, y_train)\n\nprint(\"Score: \", round(model2.score(X_test, y_test)*100,3),\"%\") #better than previous one","c67efee5":"model3 = RandomForestRegressor(max_depth=7)\nmodel3.fit(X_train, y_train)\n\nprint(\"Score: \", round(model3.score(X_test, y_test)*100,3),\"%\") #even better","0df06dd5":"model4 = Sequential()\nmodel4.add(InputLayer(input_shape=(23,)))\n    \nmodel4.add(Dense(128,activation=\"relu\",kernel_initializer=\"normal\"))\nmodel4.add(Dense(128,activation=\"relu\",kernel_initializer=\"normal\"))\nmodel4.add(Dense(64,activation=\"relu\",kernel_initializer=\"normal\"))\nmodel4.add(Dense(32,activation=\"relu\",kernel_initializer=\"normal\"))\n\n\noptim = Adam(\n    learning_rate=0.00055,\n    beta_1=0.9,\n    beta_2=0.999,\n    epsilon=1e-07,\n    amsgrad=False,\n    name=\"Adam\",\n)\n\nmodel4.add(Dense(1,activation=\"linear\",kernel_initializer=\"normal\"))\nmodel4.compile(loss=\"mse\",optimizer= optim,metrics=\"mae\")","58681ba8":"model4.fit(X_train,y_train,batch_size=16,epochs=1000,validation_data=(X_test,y_test))","4c27d3c5":"predictions = model4.predict(X_test)\n\nprint(\"Score: \",metrics.r2_score(y_test,predictions)*100)","955b6321":"random_index = np.random.randint(0,X_test.shape[0])\n\n\nprint(\"Prediction made by Random Forest Regressor:\")\nprint(\"\\t\\tPredicted price:  \", np.round(model3.predict(X_test[random_index:random_index+1])[0],3))\nprint(\"\\t\\tActual price:  \", np.round(y_test[random_index],3))\n\nprint(\"Prediction made by Neural Networks:\")\nprint(\"\\t\\tPredicted price:  \", np.round(model4.predict(X_test[random_index:random_index+1])[0][0],3))\nprint(\"\\t\\tActual price:  \", np.round(y_test[random_index],3))","74472587":"<h3> Data processing <\/h3>","c011ad7d":"<h4> Sample Demonstration <\/h4>","3a9b1d0c":"As we can see, there is no missing data","3b86ddc9":"<h3> Reading and a bit exploring data <\/h3>","584fabcb":"<p style=\"font-family:verdana;font-size: 120%\"> In conclusion, results show that in this particular problem Random Forest Regressor best predicts car price; however, I still want to believe that we can achieve the same results (may be even better) with Neural Networks. In my case I have used simple one, but it can be extended and tuned. At any rate, what makes Random Forest algorithm in this case extremely powerfull is that it does great job first of all in price prediction and unlike Neural Networks, it is light weight, so for this particular problem with such amount of data it is trained faster <\/p>","ab3fe720":"Decision Tree Regressor","2414ffed":"<h3> Trying different regression techniques<\/h3>","f227f5c8":"Simple Linear Regression","118706e5":"As we can see mean average error oscillates (mainly) between 1200-1300 , most probably there are lots of local minimums at which network stacks. I am pretty sure model can be improved after some tuning, but for now let me live current results like that. ","911e9a1a":"No duplicate values as well. Let's make the following:\n\n1) Drop unnecessary columns <br>\n2) Change columns with string data to integer <br>\n3) Perform feature scaling <br>\n4) Split data for train and test <br>","1fa91098":"<h3>Making necessary imports<\/h3>","aaf81ded":"Random Forest Regressor","e016c919":"Lets as an example take Random Forest Regressor and Neural Network models to compare result for random test sample.","e53d8a62":"<h4> Neural Networks <\/h4>"}}