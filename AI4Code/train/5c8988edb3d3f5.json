{"cell_type":{"4a9cecf3":"code","07237446":"code","58fc3eac":"code","bb7b5fc0":"code","0ad9a94f":"code","9c5bc431":"code","9cbcb808":"code","b8a698d4":"code","5222a623":"code","ee1b813a":"code","219313db":"code","c924c95c":"code","2e80d4a0":"code","30f04e0c":"code","42037301":"code","66bff5ae":"code","decbaaa8":"code","d5ebbe55":"code","b6a1ac4d":"code","0019e3ec":"code","a3a66fb4":"code","da955f29":"code","2b57c297":"code","52f4a4d8":"code","0f3e9604":"code","14b30030":"markdown","316c0d3b":"markdown","ccb00097":"markdown","ff6fd2fc":"markdown","bf55ecb3":"markdown"},"source":{"4a9cecf3":"# Importing useful libraries\n\n# Import data sets, Preprocessing and Feature Engineering\nimport pandas as pd\n# Linear Algebra operations\nimport numpy as np\n\n# Exploratory Data Analysis\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\n\n# Models and Model evaluation\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.pipeline import Pipeline\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\n\n# To measure execution time\nimport time","07237446":"# Load train and test datasets\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","58fc3eac":"train.head()","bb7b5fc0":"test.head()","0ad9a94f":"train.describe()","9c5bc431":"test.describe()","9cbcb808":"# Show class imbalance\ntrain.Survived.value_counts()","b8a698d4":"msno.matrix(train,figsize=(10,10))\ntrain.isnull().sum()\/train.shape[0]","5222a623":"msno.matrix(test,figsize=(10,10))\ntest.isnull().sum()\/test.shape[0]","ee1b813a":"# Check if Sex and passenger class matter to survive rate\ng = sns.catplot(x=\"Sex\", \n                hue=\"Pclass\", \n                col=\"Survived\",\n                data=train, kind=\"count\",\n                height=4, aspect=.7)","219313db":"# concat train and test sets\ntrain['train'] = 1\ntest['train'] = 0\ndata = train.append(test, ignore_index=True)","c924c95c":"# Fill columns with few missing values\ndata.Fare = data.Fare.fillna(0)\n\n# Fill Embarked with the most common value\ndata.Embarked = data.Embarked.fillna(data.Embarked.mode()[0])","2e80d4a0":"# Title Mapping\ndata[\"Title\"] = data[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\ndata.Title.unique()\n\n# Create features with family size and mother status\ndata['FamilySize'] = data.SibSp + data.Parch + 1\ndata['Mother'] = np.where((data.Title=='Mrs') & (data.Parch >0),1,0)\n\n\n# map gender and boys by title as Master represents mostly boys\ntitles = {\n        \"Mr\" :         \"man\",\n        \"Mme\":         \"woman\",\n        \"Ms\":          \"woman\",\n        \"Mrs\" :        \"woman\",\n        \"Master\" :     \"boy\",\n        \"Mlle\":        \"woman\",\n        \"Miss\" :       \"woman\",\n        \"Capt\":        \"man\",\n        \"Col\":         \"man\",\n        \"Major\":       \"man\",\n        \"Dr\":          \"man\",\n        \"Rev\":         \"man\",\n        \"Jonkheer\":    \"man\",\n        \"Don\":         \"man\",\n        \"Sir\" :        \"man\",\n        \"Countess\":    \"woman\",\n        \"Dona\":        \"woman\",\n        \"Lady\" :       \"woman\"\n    } \n\ndata[\"Gender\"] = data[\"Title\"].map(titles)","30f04e0c":"# Fill missing age values with median by title\ndata[\"Age\"].fillna(data.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\n\n# divide age column into a range of values\ncut_points = [-1,0,5,12,18,35,60,100]\nlabel_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\ndata[\"Age_categories\"] = pd.cut(data[\"Age\"], cut_points, labels=label_names)","42037301":"data.head()","66bff5ae":"# Creating dummy variables for categories\ndummable = ['Mother', 'Gender', 'Age_categories', 'FamilySize', 'Sex', 'Pclass', 'Embarked']\n\nfor col in dummable:\n  dummies = pd.get_dummies(data[col],prefix=col, drop_first=False)\n  data = pd.concat([data, dummies], axis=1)\n  data = data.drop(col, 1)","decbaaa8":"# generate test and train datasets with important variables\ntrain_df = data[data['train'] == 1].drop(['Cabin', 'Name', 'PassengerId', 'Ticket', 'Title', 'train', 'SibSp', 'Parch'], 1)\ntest_df = data[data['train'] == 0].drop(['Cabin', 'Name', 'PassengerId', 'Ticket', 'Title', 'train', 'Survived', 'SibSp', 'Parch'], 1)","d5ebbe55":"train_df.shape","b6a1ac4d":"# Global Variables\nseed = 42\nnum_folds = 10\nscoring = {'Accuracy': make_scorer(accuracy_score)}\n\n# train and test\nX = train_df.drop(\"Survived\", axis=1)\ny = train_df[\"Survived\"]\nX_test = test_df\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.1, random_state = seed)","0019e3ec":"pipe = Pipeline(steps = [(\"clf\",XGBClassifier())])\nsearch_space = [\n                {\"clf\":[RandomForestClassifier()],\n                 \"clf__n_estimators\": [100],\n                 \"clf__criterion\": [\"entropy\"],\n                 \"clf__max_leaf_nodes\": [64],\n                 \"clf__random_state\": [seed]\n                 },\n                {\"clf\":[LogisticRegression()],\n                 \"clf__solver\": [\"liblinear\"]\n                 },\n                {\"clf\":[XGBClassifier()],\n                 \"clf__n_estimators\": [50,100],\n                 \"clf__max_depth\": [4],\n                 \"clf__learning_rate\": [0.001, 0.01,0.1],\n                 \"clf__random_state\": [seed],\n                 \"clf__subsample\": [1.0],\n                 \"clf__colsample_bytree\": [1.0],\n                 \n                 }\n                ]\n\n# create grid search\nkfold = StratifiedKFold(n_splits=num_folds,random_state=seed)\n\n# return_train_score=True\n# official documentation: \"computing the scores on the training set can be\n# computationally expensive and is not strictly required to\n# select the parameters that yield the best generalization performance\".\ngrid = GridSearchCV(estimator=pipe, \n                    param_grid=search_space,\n                    cv=kfold,\n                    scoring=scoring,\n                    return_train_score=True,\n                    n_jobs=-1,\n                    refit=\"Accuracy\")\n\ntmp = time.time()\n\n# fit grid search\nbest_model = grid.fit(X_train,y_train)\n\nprint(\"CPU Training Time: %s seconds\" % (str(time.time() - tmp)))","a3a66fb4":"print(\"Best: %f using %s\" % (best_model.best_score_,best_model.best_params_))","da955f29":"result = pd.DataFrame(best_model.cv_results_)\nresult.head()","2b57c297":"predict_first = best_model.best_estimator_.predict(X_valid)\nprint(accuracy_score(y_valid, predict_first))","52f4a4d8":"predict_final = best_model.best_estimator_.predict(X_test)","0f3e9604":"submission = test[['PassengerId']].copy()\nsubmission['Survived'] = np.rint(predict_final).astype(int)\nprint(submission)\nsubmission.to_csv('submission.csv', index=False)\n","14b30030":"Getting Data and Libraries","316c0d3b":"Prepare submission","ccb00097":"Train and evaluate models","ff6fd2fc":"EDA","bf55ecb3":"Preprocessing and Feature Engineering"}}