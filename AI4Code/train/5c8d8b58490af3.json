{"cell_type":{"d85c4465":"code","13de0d5c":"code","1b783533":"code","8d592c3b":"code","d5b05f37":"code","aa67b26d":"code","7615caaa":"code","298c3b1f":"code","bf4e658a":"code","e151c474":"code","fcf081f6":"code","6c5706a7":"code","47a64888":"code","7ed1d233":"code","f1518b53":"code","78b7da15":"code","67d3a28b":"code","a624646d":"code","32acb2c3":"code","06383e1d":"code","69156229":"code","d019d564":"code","5a0f048d":"code","5ab629fe":"code","036eed25":"code","e3427bf8":"code","b4f83cb9":"code","59eefd3d":"code","fd7ed35b":"code","b476baa7":"code","6500ea96":"code","8b2d915d":"code","eb08e23c":"code","e3755d73":"code","822ac273":"code","613d455b":"code","1e8bfba6":"code","40d5c1ae":"code","2e90c627":"code","20089784":"code","72f85a58":"code","9a3902de":"code","8a839848":"code","bf25b9a9":"code","eb6f1210":"code","c02867b7":"code","70a875df":"markdown","4661f9c5":"markdown","85b040e1":"markdown","c6cfaf46":"markdown","ba827c08":"markdown","c88713bb":"markdown","6f512884":"markdown","e591c144":"markdown","b383aa08":"markdown","c925f05b":"markdown","6d3d7442":"markdown","5a24022a":"markdown","4ee88a3d":"markdown","595814fb":"markdown","1538746e":"markdown","1b85866c":"markdown","13531bcd":"markdown","9ea066d7":"markdown","d3e75f69":"markdown","d5c43a05":"markdown","a2353443":"markdown","c80cd044":"markdown"},"source":{"d85c4465":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","13de0d5c":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nadult=pd.read_csv('\/kaggle\/input\/adult-income-dataset\/adult.csv')\nadult.head()","1b783533":"for col in adult.columns:\n    c=(adult[col].isnull().sum()\/adult.shape[0])*100\n    print(col,c)","8d592c3b":"s=(adult.dtypes=='object')\ncategorical=list(s[s].index)\ncategorical\n","d5b05f37":"# from sklearn.preprocessing import LabelEncoder\n# encoder=LabelEncoder()\n# for cols in categorical:\n#     adult[cols]=encoder.fit_transform(adult[cols])","aa67b26d":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.subplots(figsize=(10,10))\nsns.heatmap(adult.corr(),vmin=-1)\nplt.show()","7615caaa":"adult[adult.columns[14]]=pd.Categorical(adult[adult.columns[14]]).codes\nadult[adult.columns[14]]","298c3b1f":"w=(adult.dtypes!='object')\nnot_cat=list(w[w].index)[:6]\nnot_cat","bf4e658a":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nadult[not_cat]=scaler.fit_transform(adult[not_cat])","e151c474":"adult.head()","fcf081f6":"adult.describe()","6c5706a7":"count=adult[adult.columns[1]].value_counts()\ncount.plot.bar(title=adult.columns[1])","47a64888":"work_output=pd.DataFrame()\nwork_output[0]=adult[adult[adult.columns[14]]==0][adult.columns[1]].value_counts()\nwork_output[1]=adult[adult[adult.columns[14]]==1][adult.columns[1]].value_counts()\nwork_output.plot.bar(title=\"work and output\")\n# for p in w_o.patches:\n#     w_o.annotate(str(p.get_height()),(p.get_x()*1.005,p.get_height()*1.005))","7ed1d233":"val=((work_output[1]\/(work_output[0]+work_output[1]))*100)\nprint(val)\nprint(adult[adult.columns[1]].unique())","f1518b53":"adult[adult.columns[1]]=pd.Categorical(adult[adult.columns[1]],categories=[adult[adult.columns[1]].unique()[8],adult[adult.columns[1]].unique()[7],adult[adult.columns[1]].unique()[5],adult[adult.columns[1]].unique()[1],adult[adult.columns[1]].unique()[2],adult[adult.columns[1]].unique()[0],adult[adult.columns[1]].unique()[4],adult[adult.columns[1]].unique()[3],adult[adult.columns[1]].unique()[6]],ordered=True).codes\nadult.describe()","78b7da15":"count1=adult[adult.columns[3]].value_counts()\ncount1.plot.bar(title=\"univariate education annalysis\")","67d3a28b":"eo=pd.DataFrame()\neo[0]=adult[adult[adult.columns[14]]==0][adult.columns[3]].value_counts()\neo[1]=adult[adult[adult.columns[14]]==1][adult.columns[3]].value_counts()\neo.plot.bar(title=\"education and output bivariate annalysis\",figsize=(20,10))","a624646d":"ch=(eo[1]\/(eo[1]+eo[0]))*100\nprint(ch)\nprint(adult[adult.columns[3]].unique())","32acb2c3":"adult[adult.columns[3]]=pd.Categorical(adult[adult.columns[3]],categories=[\" Preschool\", \" 1st-4th\" ,\" 5th-6th\",\" 11th\" ,\" 9th\",\" 7th-8th\",\n                                                                           \" 10th\",\" 12th\",\" HS-grad\",\" Some-college\",\" Assoc-acdm\",\" Assoc-voc\",\n                                                                           \" Bachelors\",\" Masters\",\" Prof-school\",\" Doctorate\"\n                                                                          ],ordered=True).codes","06383e1d":"adult.head()","69156229":"count2=adult[adult.columns[6]].value_counts()\ncount2.plot.bar(title=\"occupation\",figsize=(10,7))","d019d564":"occup=pd.DataFrame()\noccup[0]=adult[adult[adult.columns[14]]==0][adult.columns[6]].value_counts()\noccup[1]=adult[adult[adult.columns[14]]==1][adult.columns[6]].value_counts()\noccup.plot.bar(title=\"education and output\",figsize=(20,10))\n# occup.plot.bar(title=\"occupation and output\")\n#adult[adult.columns[1]].unique()[4]","5a0f048d":"p1=(occup[1]\/(occup[0]+occup[1]))*100\nd=p1.sort_values().index\nd","5ab629fe":"adult[adult.columns[6]]=pd.Categorical(adult[adult.columns[6]],categories=d,ordered=True).codes\nadult.describe()","036eed25":"adult.head(20)","e3427bf8":"adult[adult.columns[13]].unique()","b4f83cb9":"adult[adult.columns[13]]=adult[adult.columns[13]].replace(\"United-States\",1)\nadult[adult.columns[13]]=adult[adult.columns[13]].replace(adult[adult.columns[13]].unique()[1:],0)\n\n# adult[adult[adult.columns[13]]==\" United-States\"][adult.columns[13]]=0\n# adult.iloc[(adult[adult.columns[13]]!=\" United-States\"),adult.columns[13]]=0\nadult[adult.columns[13]]","59eefd3d":"print(adult[adult.columns[13]].value_counts())\nadult.head()","fd7ed35b":"adult.describe()","b476baa7":"t=(adult.dtypes==object)\na=list(t[t].index)\na","6500ea96":"from sklearn.preprocessing import OneHotEncoder\nencoder=OneHotEncoder(sparse=False)\npo=pd.DataFrame(encoder.fit_transform(adult[a]))","8b2d915d":"adult.drop(a,inplace=True,axis=1)","eb08e23c":"adult.head()","e3755d73":"data=pd.concat([adult,po],axis=1)\n\ndata.head()","822ac273":"from sklearn.model_selection import StratifiedShuffleSplit\nsplits=StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\nfor train_index,test_index in splits.split(data,data[data.columns[10]]):\n    train_data=data.iloc[train_index]\n    test_data=data.iloc[test_index]\ny_train=train_data[train_data.columns[10]]\ny_test=test_data[test_data.columns[10]]\nx_train=pd.concat([train_data.iloc[:,:10],train_data.iloc[:,11:]],axis=1)\nx_test=test_data.drop(test_data.columns[10],axis=1)\n","613d455b":"from sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression(tol=0.01)\nmodel.fit(x_train,y_train)","1e8bfba6":"from sklearn.metrics import classification_report\nprint('classification report for test_data in logistic regression \\n',classification_report(y_test,model.predict(x_test)))","40d5c1ae":"\nprint('classification report for train_data in logistic regression \\n',classification_report(y_train,model.predict(x_train)))","2e90c627":"from sklearn.ensemble import RandomForestClassifier\nmodel1=RandomForestClassifier(max_depth=7)\nmodel1.fit(x_train,y_train)","20089784":"from sklearn.metrics import classification_report\nprint('classification report for test_data in RandomForestClassification \\n',classification_report(y_test,model1.predict(x_test)))","72f85a58":"\nprint('classification report for train_data in RandomForestClassification \\n',classification_report(y_train,model1.predict(x_train)))","9a3902de":"from sklearn.tree import DecisionTreeClassifier\nmodel2=DecisionTreeClassifier(max_depth=7)\nmodel2.fit(x_train,y_train)\nprint('classification report for test_data in DecisionTreeClassification \\n',classification_report(y_test,model1.predict(x_test)))","8a839848":"\nprint('classification report for train_data in DecisionTreeClassification \\n',classification_report(y_train,model2.predict(x_train)))","bf25b9a9":"from sklearn.neighbors import KNeighborsClassifier\nmodel3=KNeighborsClassifier()\nmodel3.fit(x_train,y_train)","eb6f1210":"\nprint('classification report for test_data in KNeighborsClassification \\n',classification_report(y_test,model3.predict(x_test)))","c02867b7":"\nprint('classification report for train_data in KNeighborsClassification \\n',classification_report(y_train,model3.predict(x_train)))","70a875df":"### checking percentage of education  for each type as output as 1 out of total output","4661f9c5":"### Assigning values to the categorical data according to how it effects the income","85b040e1":"### finding list of non-categorical columns name","c6cfaf46":"### scaling-down the non-categorical features","ba827c08":"### checking percentage of work-class  for each type as output as 1 out of total output","c88713bb":"# Selecting best model ","6f512884":"# conclusion:-\n### After annalysing different model we can conclude that RandomForestClassifier works well in this case as we could observe that accuracy is high as well as f1 scores for each categories are greater as compared with other models ","e591c144":"### Finding the columns whose data type is object that means columns which are categoricals","b383aa08":"### one-hot encodings to categorical data","c925f05b":"### Assigning values to the categorical data according to how it effects the income","6d3d7442":"### Importing pandas,matplotlib and seaborn. And adding data","5a24022a":"### finding correlations all non categorical data","4ee88a3d":"### Bivariate annalysis of work-class and output","595814fb":"### converting output data to binary form if income <=50k :0 and if income>50k :1","1538746e":"### Assigning values to the categorical data according to how it effects the income","1b85866c":"# dealing with large number of unique value of country ","13531bcd":"# Education vs output","9ea066d7":"### Finding percentage of null values in each column","d3e75f69":"### As value_counts of output is not equal StratifiedShuffleSplit is used for train test splits","d5c43a05":"# occupation column annalysis\n","a2353443":"### univariate annalysis of work-class\n","c80cd044":"### checking percentage of occupation  for each type as output as 1 out of total output"}}