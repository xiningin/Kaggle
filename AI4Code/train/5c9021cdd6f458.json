{"cell_type":{"e80b4583":"code","26213f06":"code","5fee8e0c":"code","4400b462":"code","03f3d54a":"code","439792ec":"code","9f430055":"code","a320418b":"code","2dc4c1b3":"code","6d39bc36":"code","ae6ac196":"code","f89b182a":"code","7171ac7f":"code","99adc552":"code","f88c0219":"code","4e64370c":"code","ecf9f247":"code","9deaa27b":"code","6f9da073":"code","5261a0cd":"code","9705d8e6":"code","d82ead49":"code","bf458a14":"code","1ab68df2":"code","8ab22882":"code","9af2d602":"code","2df3e736":"code","456ad261":"code","901ecd91":"code","e6c6ed5f":"code","0d36c764":"code","ed7519f7":"code","6f74ca77":"code","bdad212a":"code","6ec2ced0":"code","273b3ff0":"code","14f95da9":"code","ef210f9f":"code","6889abf3":"code","a993b1d1":"code","324b6172":"markdown","90aa6918":"markdown","30d94b6f":"markdown","859d7b73":"markdown","d8e1fa70":"markdown","13c1a347":"markdown","fa6e1130":"markdown","c7f1c37e":"markdown","af4c1325":"markdown","a5214507":"markdown","c3344494":"markdown","c4713557":"markdown"},"source":{"e80b4583":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","26213f06":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","5fee8e0c":"import pandas as pd\n \ndata=pd.read_csv(\"..\/input\/bigmart-sales-data\/Test.csv\")\ndata.head(10)","4400b462":"X=data.iloc[:,:10]\nY=data.iloc[:,-1]\n","03f3d54a":"data.shape","439792ec":"data.isnull().values.any()","9f430055":"data.isnull().sum()","a320418b":"test=data\ntest.head(2)","2dc4c1b3":"train = pd.read_csv('..\/input\/bigmart-sales-data\/Train.csv')\ntrain.head(2)","6d39bc36":"train.shape,test.shape","ae6ac196":"train.columns","f89b182a":"test.columns","7171ac7f":"train['source']='train'\ntest['source']='test'\ntest['Item_Outlet_Sales']=0\n\ndata = pd.concat([train, test], sort = False)\nprint(train.shape, test.shape, data.shape)","99adc552":"data['Item_Outlet_Sales'].describe()","f88c0219":"sns.distplot(data['Item_Outlet_Sales'])","4e64370c":"data.dtypes","ecf9f247":"categorial_f=data.select_dtypes(include=[np.object])\ncategorial_f.head(2)","9deaa27b":"numerical_features = data.select_dtypes(include=[np.number])\nnumerical_features.head(2)","6f9da073":"data.apply(lambda x: sum(x.isnull()))","5261a0cd":"data.apply(lambda x:len(x.unique()))","9705d8e6":"for col in categorial_f:\n    print('\\n%s column:' %col)\n    print(data[col].value_counts())","d82ead49":"plt.figure(figsize = (10,9))\n\nplt.subplot(311)\nsns.boxplot(x='Outlet_Size', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\n\nplt.subplot(312)\nsns.boxplot(x='Outlet_Location_Type', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\n\nplt.subplot(313)\nsns.boxplot(x='Outlet_Type', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\n\nplt.subplots_adjust(wspace = 0.2, hspace = 0.4,top = 1.5)\n\nplt.show()","bf458a14":"\nplt.figure(figsize = (14,9))\n\nplt.subplot(211)\nax = sns.boxplot(x='Outlet_Identifier', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\nax.set_title(\"Outlet_Identifier vs. Item_Outlet_Sales\", fontsize=15)\nax.set_xlabel(\"\", fontsize=12)\nax.set_ylabel(\"Item_Outlet_Sales\", fontsize=12)\n\nplt.subplot(212)\nax = sns.boxplot(x='Item_Type', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\nax.set_title(\"Item_Type vs. Item_Outlet_Sales\", fontsize=15)\nax.set_xlabel(\"\", fontsize=12)\nax.set_ylabel(\"Item_Outlet_Sales\", fontsize=12)\n\nplt.subplots_adjust(hspace = 0.9, top = 0.9)\nplt.setp(ax.get_xticklabels(), rotation=45)\n\nplt.show()","1ab68df2":"item_avg_weight = data.pivot_table(values='Item_Weight', index='Item_Identifier')\n\nmissing_values = data['Item_Weight'].isnull()\nprint('Missing values: %d' %sum(missing_values))\n\ndata.loc[missing_values,'Item_Weight']  = data.loc[missing_values,'Item_Identifier'].apply(lambda x: item_avg_weight.at[x,'Item_Weight'])\nprint('Missing values after immputation %d' %sum(data['Item_Weight'].isnull()))","8ab22882":"plt.figure(figsize = (14,9))\n\nplt.subplot(211)\n\nplt.subplot(211)\nax = sns.boxplot(x='Outlet_Establishment_Year', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\nax.set_title(\"Outlet_Establishment_Year with. Item_Outlet_Sales\", fontsize=15)\nax.set_xlabel(\"Outlet_Establishment_Year\", fontsize=12)\nax.set_ylabel(\"Item_Outlet_Sales\", fontsize=12)","9af2d602":"data.Item_Weight.isnull().sum()\n","2df3e736":"data['Item_Visibility'].replace(0.00000,np.nan)#first fill by nam for simplicity\ndata['Item_Visibility'].fillna(data.groupby('Item_Identifier')['Item_Visibility'].transform('mean'))\ndata['Item_Visibility'].fillna(data.groupby('Item_Identifier')['Item_Visibility'].transform('mean'))\ndata.Item_Visibility.isnull().sum()","456ad261":"data['Item_Fat_Content']=data['Item_Fat_Content'].replace({'low fat':'Low Fat','reg':'Regular','LF':'Low Fat'})\ndata.Item_Fat_Content.value_counts()","901ecd91":"data['Outlet_Size']","e6c6ed5f":"from sklearn.preprocessing import LabelEncoder\nnumber=LabelEncoder()\nvar_mod=['Item_Fat_Content','Outlet_Location_Type','Outlet_Type','Item_Type']\ndata['Outlet']=number.fit_transform(data['Outlet_Identifier'])\ndata['Identifier']=number.fit_transform(data['Item_Identifier'])\ndata['Item_Fat']=number.fit_transform(data['Item_Fat_Content'])\ndata['Outlet_Typ']=number.fit_transform(data['Outlet_Type'])\ndata['Outlet_Location']=number.fit_transform(data['Outlet_Location_Type'])\ndata['Item_Typ']=number.fit_transform(data['Item_Type'])\ndata[\"Year\"]=number.fit_transform(data['Outlet_Establishment_Year'])\n","0d36c764":"data.head(2)","ed7519f7":"X=data[data.columns[13:20]]\nX.head(2)","6f74ca77":"y=data[data.columns[11]]\ny","bdad212a":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error","6ec2ced0":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)\nprint(X_train.shape,y_train.shape)","273b3ff0":"print( X_test.shape, y_test.shape)","14f95da9":"Linear_Model=LinearRegression(normalize=True)","ef210f9f":"Linear_Model.fit(X_train,y_train)\nLinear_Model.predict(X_test)\n","6889abf3":"print (Linear_Model.score(X_test, y_test))","a993b1d1":"from sklearn.tree import DecisionTreeRegressor\ndecisiontree = DecisionTreeRegressor(random_state=0)\nmodel=decisiontree.fit(X_train,y_train)\nmodel.predict(X_test)\nprint (model.score(X_test, y_test))\n","324b6172":"This is quite low. Use another model.","90aa6918":"Now we will load training data","30d94b6f":"It means we are having ,so to see how many?","859d7b73":"Lets look at numerical and categoriacal features","d8e1fa70":"See how many rows are having null values?","13c1a347":"Missing values","fa6e1130":"See how many rows and cols?\n","c7f1c37e":"tHIS IS quite good\n","af4c1325":"see columns of both train and test","a5214507":"WHICH ARE FEATURES AND TARGET?","c3344494":"We need to predict Item_Outlet_Sales for given test data\n\nlets first merge the train and test data for Exploratory Data Analysis","c4713557":"Loading the data"}}