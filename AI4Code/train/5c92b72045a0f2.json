{"cell_type":{"a783525b":"code","92ed97b9":"code","0205dbcd":"code","37c9b33e":"code","e33e6d00":"code","0b0b91a7":"code","8c73671e":"code","7d765b7c":"code","fa7135ec":"markdown","f948c88a":"markdown","1b7cef5a":"markdown","8690eec8":"markdown","f0e133c0":"markdown","c25c888a":"markdown","54a9afa2":"markdown","3f7fe0b2":"markdown","d72c0b2f":"markdown","a6b91efd":"markdown","7f1d424e":"markdown","0449e4bb":"markdown","d2ff13f6":"markdown","24321705":"markdown","e98a52b8":"markdown","59960440":"markdown","f8cd55f3":"markdown","1e87291e":"markdown","73359710":"markdown","493889de":"markdown","3efffeac":"markdown","6c598f79":"markdown","5b173ac6":"markdown"},"source":{"a783525b":"#Numpy is used so that we can deal with array's, which are necessary for any linear algebra\n# that takes place \"under-the-hood\" for any of these algorithms.\n\nimport numpy as np\n\n\n#Pandas is used so that we can create dataframes, which is particularly useful when\n# reading or writing from a CSV.\n\nimport pandas as pd\n\n\n#Matplotlib is used to generate graphs in just a few lines of code.\n\nimport matplotlib.pyplot as plt\n\n#Sklearn is a very common library that allows you to implement most basic ML algorithms.\n#LabelEncoder, OneHotEncoder, and ColumnTransfomer are necessary since we have a field of categorical data.\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n#Train_test_split will allow us to quickly split our dataset into a training set and a test set.\n\nfrom sklearn.model_selection import train_test_split\n\n\n#LinearRegression is the class of the algorithm we will be using.\n\nfrom sklearn.linear_model import LinearRegression\n\n\n#This will allow us to evaluate our fit using the R^2 score. \n\nfrom sklearn.metrics import r2_score\n\n","92ed97b9":"#read dataset from csv\ndataset = pd.read_csv('..\/input\/50-startups\/50_Startups.csv')\n\n#set independent variable using all rows, and all columns except for the last one.\nX = dataset.iloc[:, :-1].values\n\n#set the dependent variable using all rows, but ony the last column.\ny = dataset.iloc[:, 4].values\n\n#Lets look at our data\ndataset\n","0205dbcd":"#create an object of the class LabelEncoder\nlabelencoder = LabelEncoder()\n\n# Country column\nct = ColumnTransformer([(\"State\", OneHotEncoder(), [3])], remainder = 'passthrough')\nX = ct.fit_transform(X)\n\n#We need to omit one of the columns to avoid the dummy variable trap.\nX = X[:, 1:]\n\n#take a look at X now.\nX","37c9b33e":"#This will create x and y variables for training and test sets.\n#Here we are using 25% of our examples for the test set.\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n","e33e6d00":"#this sets the object regressor to the class of LinearRegression from the Sklearn library.\nregressor = LinearRegression()\n\n#this fits the model to our training data.\nregressor.fit(X_train, y_train)","0b0b91a7":"#Predict on our test set.\ny_pred = regressor.predict(X_test)","8c73671e":"#calculate the R^2 score\nscore = r2_score(y_test, y_pred)\n\n#print out our score properly formatted as a percent.\nprint(\"R^2 score:\", \"{:.0%}\".format(score))","7d765b7c":"#Prediction for a business in CA, with R&D of 160,000, Admin of 130,000 and Marketing of 300,000.\nprint(regressor.predict([[1, 0, 160000, 130000, 300000]]))","fa7135ec":"However, in multiple regression, we have multiple independent variables that impact the dependent variable.\n\n![image.png](attachment:image.png)","f948c88a":"With our imports complete, we now read in the data using Pandas.\n\nWe will set a independent variable (X) and a dependent variable (y).","1b7cef5a":"Next we have to deal with our categorial column.  (State).\n\nWe will do this by \"OneHotEncoding\" it, which turns each value into 0 or 1 for processing.","8690eec8":"Because we have 4 independent variables, (technically more because of the onehotencoding) this would be impossible to visualize.  So we will skip the step of visualization. \n\nSo instead we will move on directly to the R^2 score, which tells us how much of the variation in our dependent variable can be explained by our independent variable.","f0e133c0":"Next, we must select which independent variables to include; striking a balance between quality of fit and number of variables. This balance is called \u201cparsimony\u201d.\n\n![image.png](attachment:image.png)","c25c888a":"## Conceptual Overview\n\nLike Simple Linear Regression, multiple regression is also a \u201csupervised\u201d \u201cregression\u201d algorithm.\n\n![image.png](attachment:image.png)\n","54a9afa2":"Now, its time to load the model","3f7fe0b2":"With our data loaded, we now need to split the data into training and test sets.","d72c0b2f":"Note: In this code I **did not** check the 4 assumptions of Multi Linear Regression or complete a selection algorithm for our independent variables.  \n\nThese steps significantly complicate the code and in my opinion make it unreadable for beginners.  Additionally, testing the assumptions takes some interpretation.\n\nIf you plan on applying this to establish significance between variables, you would have to complete additional work to do so.  But if you just want to build a prediction, this code will work just fine. \n","a6b91efd":"We can now apply this trained model to novel examples to predict their profit.  ","7f1d424e":"Overall, Multiple Regression is very applicable to real world problems, however, practitioners must test the assumptions and apply parsimony for valid conclusions to be made.","0449e4bb":"With our model built, we can now use it for generating predictions.\n\nWe will use our test set so we can see how well it did.","d2ff13f6":"> # Enough to be Dangeous: Multiple Linear Regression\n\n> ### This is the 2nd notebook of my **\"Enough to be Dangeous\"** notebook series\n\nSee the other notebooks here:\n\n[Simple Linear regression](https:\/\/www.kaggle.com\/thaddeussegura\/enough-to-be-dangeous-simple-linear-regression)\n\n[Polynomial regression](https:\/\/www.kaggle.com\/thaddeussegura\/enough-to-be-dangerous-polynomial-regression)\n\n\n ","24321705":"Regression meaning we predict a numerical value, instead of a \u201cclass\u201d.\n\n![image.png](attachment:image.png)","e98a52b8":"Supervised meaning we use labeled data to train the model.\n\n![image.png](attachment:image.png)","59960440":"![image.png](attachment:image.png)","f8cd55f3":"We use an \u201cF-test\u201d to find the \u201cp-value\u201d which tells us the probability that our observations are due only to chance. Typically, the findings are \u201csignificant\u201d if p < 5%\n\n![image.png](attachment:image.png)\n","1e87291e":"Once we\u2019ve completed the regression, we evaluate the fit with the \u201cR^2 score\u201d which tells us how closely our prediction matched the data.\n\n![image.png](attachment:image.png)\n","73359710":"> ### This notebook is separated into two parts:\n\n**1) Conceptual Overview:**  I will introduce the topic in 200 words or less.\n\n**2) Implementation:**  I will implement the algorithm in as few lines as possible.","493889de":"Least Squares is still used, but instead of fitting a line to our data, we fit a (n-1) dimensional plane. (Ex: 3D data -> 2D plane.)\n\n![image.png](attachment:image.png)","3efffeac":"Before applying Multiple Regression, we must test 4 specific assumptions, which can be done with any statistical software.\n\n![image.png](attachment:image.png)","6c598f79":"## Implementation\n\nIn this section I will implement the code in its simplest verison so that it is understandable if you are brand new to machine learning. \n\nBelow we will use the attributes of 50 start ups to predict their profit.\n\n**The independent variables are**:\n* R&D Spend \n* Administrative Spend \n* Marketing Spend \n* State of operation.\n    \n**The dependent variable is** profit. \n    \nThe first step is to start with \"imports\". These are \"libraries\" of pre-written code that will help us significantly.","5b173ac6":"There are multiple approaches to making this decision, such as \u201cbackward elimination\u201d and \u201cforward selection\u201d.\n\n![image.png](attachment:image.png)"}}