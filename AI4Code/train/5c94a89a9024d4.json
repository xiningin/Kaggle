{"cell_type":{"faca408f":"code","c1fd26ff":"code","b6a932ae":"code","284f56ce":"code","952dc52e":"code","2b12ddd1":"code","8c7d7481":"code","1fec5558":"code","1474bb3b":"code","9c8ef9db":"code","36383cec":"code","d51c7257":"code","08367c52":"code","7465caf2":"markdown","79720315":"markdown","bee76a28":"markdown","965daa79":"markdown","fec7c2a1":"markdown","28bcc41a":"markdown","b869bb67":"markdown","1a743e51":"markdown","dfe7ab8b":"markdown","807d5d86":"markdown","e03480f8":"markdown","c61cb215":"markdown","8ca14327":"markdown","685dbd94":"markdown"},"source":{"faca408f":"# pip install needed packages\n!pip install chart_studio\n\n# Import the needed packages\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport chart_studio.plotly as py\nfrom plotly.subplots import make_subplots\nimport cufflinks as cf\n%matplotlib inline\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\ncf.go_offline()","c1fd26ff":"# Import all the needed files for the analysis\nproduct = pd.read_csv('\/kaggle\/input\/dunnhumby-the-complete-journey\/product.csv')\ntransaction_data = pd.read_csv('\/kaggle\/input\/dunnhumby-the-complete-journey\/transaction_data.csv')","b6a932ae":"transaction_data.head()","284f56ce":"transaction_data.shape","952dc52e":"# Create Daily aggregate data for product trends\ntransaction_data = transaction_data[['household_key','DAY','PRODUCT_ID', 'QUANTITY','SALES_VALUE']] \\\n            .merge(product[['PRODUCT_ID','COMMODITY_DESC']], on='PRODUCT_ID')\n\n# Remove blanks and 'COUPON\/MISC ITEMS', and '(CORP USE ONLY)' in the COMMODITY_DESC field as they won't be helpful in the analysis anyway\ntransaction_data = transaction_data[~transaction_data['COMMODITY_DESC'].isin(['',' ','COUPON\/MISC ITEMS','(CORP USE ONLY)'])] \n\n# Do a daily summary with the following metrics: sales, quantity, number of households\ndaily_sales = transaction_data.groupby(['COMMODITY_DESC', 'DAY']) \\\n            .agg({'SALES_VALUE':'sum', 'QUANTITY':'sum', 'household_key':pd.Series.nunique}) \\\n            .rename(columns = {'household_key':'HOUSEHOLDS'}) \\\n            .reset_index()\n\ndaily_sales.head()","2b12ddd1":"# Prepare dataframes\ndf_top5 = daily_sales[['COMMODITY_DESC','SALES_VALUE']]\\\n            .groupby(['COMMODITY_DESC']).sum().reset_index()\ndf_top5 = df_top5[df_top5['COMMODITY_DESC'] != ''].sort_values(by = 'SALES_VALUE', ascending=False)[:5] \\\n            .sort_values(by = 'SALES_VALUE')","8c7d7481":"# Bar Charts Using Plotly Express\nfig = px.bar(x = df_top5.SALES_VALUE, \n             y = df_top5.COMMODITY_DESC,\n             labels = {\n                 'y' : 'Commodities',\n                 'x' : 'Sales'\n             },\n             title = 'Top 5 Commodities by Sales',\n             template = 'simple_white')\nfig.show()","1fec5558":"# Prepare dataframe for quantity\ndf_top5_quantity = daily_sales[['COMMODITY_DESC','QUANTITY']]\\\n            .groupby(['COMMODITY_DESC']).sum().reset_index()\ndf_top5_quantity = df_top5_quantity[df_top5_quantity['COMMODITY_DESC'] != ''] \\\n            .sort_values(by = 'QUANTITY', ascending=False)[:5]\n\ndf_top5 = df_top5.sort_values(by = 'SALES_VALUE', ascending=False)[:5]","1474bb3b":"# Add the 2 traces\ntrace1 = go.Bar(\n            x = df_top5.COMMODITY_DESC,\n            y = df_top5.SALES_VALUE,\n            name = 'Sales $')\n\ntrace2 = go.Bar(\n            x = df_top5_quantity.COMMODITY_DESC,\n            y = df_top5_quantity.QUANTITY,\n            name = 'Quantity')\n\n# Set-up subplots\nfig = make_subplots(rows=1, cols=2, subplot_titles=(\"Sales $\", \"Quantity\"))\n\nfig.add_trace(\n    trace1,\n    row=1, col=1\n)\n\nfig.add_trace(\n    trace2,\n    row=1, col=2\n)\n\nfig.update_layout(height=600, width=800, template = 'simple_white', title_text=\"Top 5 Commodities in Sales and Quantity\")\n\nfig.show()","9c8ef9db":"# Prepare dataset\nlist_top5_sales = df_top5['COMMODITY_DESC']\n\ndaily_sales_top5 = daily_sales[daily_sales['COMMODITY_DESC'] \\\n                               .isin(list_top5_sales)] \\\n                                [['COMMODITY_DESC', 'SALES_VALUE', 'DAY']] \\\n                               .groupby(['COMMODITY_DESC','DAY']).sum().reset_index()\n\n# Plot\nfig = px.line(daily_sales_top5, \n              x = daily_sales_top5.DAY, \n              y = daily_sales_top5.SALES_VALUE,\n             color = daily_sales_top5.COMMODITY_DESC,\n             title = 'Daily Sales for the Top 5 Commodities',\n             template = 'simple_white')\n\nfig.show()","36383cec":"fig = px.box(daily_sales_top5, \n              x = daily_sales_top5.COMMODITY_DESC, \n              y = daily_sales_top5.SALES_VALUE,\n             color = daily_sales_top5.COMMODITY_DESC,\n             title = 'Sales Distribution for the Top 5 Commodities',\n             template = 'simple_white')\nfig.show()","d51c7257":"# Do a summary with the following metrics: sales, quantity, number of households\nsales_agg = transaction_data.groupby(['COMMODITY_DESC']) \\\n            .agg({'SALES_VALUE':'sum', 'QUANTITY':'sum', 'household_key':pd.Series.nunique}) \\\n            .rename(columns = {'household_key':'HOUSEHOLDS'}) \\\n            .reset_index()","08367c52":"fig = px.scatter(sales_agg, \n                 x='QUANTITY', \n                 y='SALES_VALUE',\n                 size='HOUSEHOLDS', \n                 color='COMMODITY_DESC',\n                 hover_name='COMMODITY_DESC',\n                 size_max=60,\n                 title = 'Sales, Volume, and Household Counts for Various Consumer Commodities',\n                 template = 'simple_white')\nfig.update_layout(showlegend=False)\nfig.add_annotation(text='Sizes of the bubbles represent the number of households buying the product',\n                  xref='paper', yref='paper',\n                  x=-0.02, y=1.11, showarrow=False)\nfig.show()","7465caf2":"**Interpretation:** Softdrinks appeared to have the biggest variation, with a number of outliers pulling up the average value. Beef also has a big variation with some outliers present.","79720315":"### Chart 4: BOX PLOTS (Distribution of the Top 5 Commodities)","bee76a28":"The next step is to perform data transformations to prepare for all the subsequent plotting. ","965daa79":"### Chart 1: BAR CHART (Top 5 Commodities in terms of Sales)","fec7c2a1":"### Chart 3: LINE CHARTS (Daily Sales for the Top 5 Commodities)","28bcc41a":"## II. Plotly Charts","b869bb67":"### Chart 2: SIDE BY SIDE BAR CHARTS (Top 5 Commodities in terms of Sales, and Top 5 in terms of Quantity)","1a743e51":"**Interpretation:** Softdrinks is the top commodity in terms of sales, with 328K dollars over the time period covered. Beef comes next, with 312K sales in the time period covered.  ","dfe7ab8b":"## I. Data Transformations and Cleaning","807d5d86":"**Interpretation:** Fuels and Breads appeared in the top 5 when quantity was considered. On the other hand, Beef and Meat Dinners were removed from the top categories. Meat \/ Beef are high value purchases, making them top commodities, sales-wise. Meanwhile, Soft drinks remain to be the top commodity whether value or volume of purchases is considered. ","e03480f8":"**Interpretation:** Softdrinks pulls away from the other categories in terms of quantity, although it is almost at par with Beef in terms of sales value. Softdrinks is highly volume-driven - it sells good because of the sheer number of purchases, while Beef is obviously a price-driven commodity.  ","c61cb215":"First, we examine the dataset. The transactions dataset contains 2.6M transactions, with 12 fields.","8ca14327":"It's very difficult to see the patterns this way, and computing for moving averages may help to visualize the data better.","685dbd94":"### Chart 5: BUBBLE CHART (Sales, Quantity, and Number of Households Buying)  "}}