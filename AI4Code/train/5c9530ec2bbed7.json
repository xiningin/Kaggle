{"cell_type":{"e67423c1":"code","10f22eb9":"code","883a84fd":"code","c0b5c2cc":"code","bb3080e8":"code","e6e5e583":"code","80f47a60":"code","0dedc2ed":"code","b607054c":"markdown"},"source":{"e67423c1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\ntf.enable_eager_execution()\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","10f22eb9":"#get data\ntrain_paths=[]\ntrain_labels=[]\nfor root,dir,files in os.walk(\"..\/input\/train\"):\n    for file in files:\n        train_paths.append(os.path.join(root,file))\n        train_labels.append(root.split(\"\/\")[-1])\n\ntest_paths=[]\nfor root,dir,files in os.walk(\"..\/input\/test\"):\n    for file in files:\n        test_paths.append(os.path.join(root,file))\n        \nprint(train_paths[:5])\nprint(test_paths[:5])","883a84fd":"#function to preprocess images and labels\ndef preprocess_image(image,image_shape=[192,192]):\n  image = tf.image.decode_jpeg(image, channels=3)\n  image = tf.image.resize(image, image_shape)\n  image \/= 255.0  # normalize to [0,1] range\n  return image\n\n\ndef load_and_preprocess_image(file,image_shape):\n    image = tf.io.read_file(file)\n    return preprocess_image(image,image_shape)\n\nlabs2index={'cbb':0, 'cbsd':1, 'cgm':2, 'cmd':3, 'healthy':4}\nindex2labs={0:'cbb', 1:'cbsd', 2:'cgm', 3:'cmd', 4:'healthy'}\ndef process_labels(lab):\n    print(lab)\n    return tf.one_hot(lab,depth=len(labs2index))","c0b5c2cc":"#create tensorflow data objects\ntrain_ds = tf.data.Dataset.from_tensor_slices(train_paths)\ntest_ds=tf.data.Dataset.from_tensor_slices(test_paths)\ntrain_image_ds = train_ds.map(lambda x:load_and_preprocess_image(x,image_shape=[192,192]),num_parallel_calls=AUTOTUNE)\ntest_image_ds=test_ds.map(lambda x:load_and_preprocess_image(x,image_shape=[192,192]),num_parallel_calls=AUTOTUNE)\n\ntrain_label_ds=tf.data.Dataset.from_tensor_slices([labs2index[i] for i in train_labels]).map(process_labels,num_parallel_calls=AUTOTUNE)\nimage_label_ds=tf.data.Dataset.zip((train_image_ds,train_label_ds))\n\nBATCH_SIZE = 32\n\n# Setting a shuffle buffer size as large as the dataset ensures that the data is\n# completely shuffled.\nds = image_label_ds.shuffle(buffer_size=len(train_paths))\nds = ds.repeat()\nds = ds.batch(BATCH_SIZE)\n# `prefetch` lets the dataset fetch batches, in the background while the model is training.\nds = ds.prefetch(buffer_size=AUTOTUNE)\n\nds_test=test_image_ds.batch(BATCH_SIZE)\nprint(ds)\nprint(test_ds)","bb3080e8":"#use pretrained model\nmobile_net = tf.keras.applications.MobileNetV2(input_shape=(192, 192, 3), include_top=False)\n#mobile_net.trainable=False\n\ndef change_range(image,label):\n  return 2*image-1, label\n\nkeras_ds = ds.map(change_range)\nkeras_test=ds_test.map(lambda x:2*x-1)\n\n\n#image_batch, label_batch = next(iter(keras_ds))\n\nmodel = tf.keras.Sequential([\n  mobile_net,\n  tf.keras.layers.GlobalAveragePooling2D(),\n  tf.keras.layers.Dense(len(labs2index),activation=tf.nn.softmax)])\n\nmodel.compile(optimizer=tf.train.AdamOptimizer(),\n              loss=tf.keras.losses.categorical_crossentropy,\n              metrics=[\"accuracy\"])\nprint(model.summary())","e6e5e583":"#fit model for 50 epochs\nmodel.fit(keras_ds, epochs=50, steps_per_epoch=176)\n\n","80f47a60":"#make predictions\ntest_predictions=model.predict(keras_test,steps=int(np.ceil(len(test_paths)\/BATCH_SIZE)))\npredictions=np.argmax(test_predictions,axis=1)","0dedc2ed":"#make submission\nmy_submission = pd.DataFrame({'Category':[index2labs[j] for j in predictions],'Id':[i.split(\"\/\").pop() for i in test_paths]})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)\nprint(my_submission.head())","b607054c":"# Classification using pretrained models\nThis kernel follows tensorflow documentation on loading datasets: https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/data\/Dataset"}}