{"cell_type":{"6469c7bb":"code","70c53902":"code","3e0f0e86":"code","16de0f80":"code","6a1475f0":"code","f1ff64aa":"code","47bee1d2":"code","9aa7bfbb":"code","b755aedb":"code","a80ef6a8":"code","6d6078d3":"markdown","c5e50902":"markdown","ef4a5283":"markdown","36660ab2":"markdown","a0ea87b9":"markdown","46f57a82":"markdown","91ec4185":"markdown"},"source":{"6469c7bb":"#Necessary libraries are imported here\nimport numpy as np \nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose\nprint(tf.__version__)","70c53902":"#Here we check is GPU is available for training or not Or whether the tensorflow version can utilize gpu \nphysical_devices = tf.config.list_physical_devices('GPU') \nprint(\"Number of GPUs :\", len(physical_devices)) \nprint(\"Tensorflow GPU :\",tf.test.is_built_with_cuda())","3e0f0e86":"if len(physical_devices)>0:\n    device=\"\/GPU:0\"\nelse:\n    device=\"\/CPU:0\"","16de0f80":"fileList=[]\nfl=[]\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        fileList.append(os.path.join(dirname, filename))\nfor i in fileList:\n    if i.endswith('.jpg'):\n        fl.append(i)\nfileList=np.array(fl)","6a1475f0":"from PIL import Image\nfl=[]\nfor filename in fileList:\n    \n    try:\n      img = Image.open(filename)# open the image file\n      img.verify() # verify that it is, in fact an image\n      fl.append(filename)\n    except Exception:\n        print(\"Bad File\",filename)\nfileList=np.array(fl)\nnp.random.shuffle(fileList)","f1ff64aa":"#The image size is kept at 400 x 400,\n#and also we normalize the input image data so that each pixel value lies in 0~1 range\nIMG_SIZE=(256,256)\nbatch=1\ndef decode_img(x):\n    x=tf.io.read_file(x)\n    x=tf.image.decode_jpeg(x,channels=3)\n    x=tf.image.resize(x,IMG_SIZE)\n    return x\n\ndef rgb_to_gs(x):\n    gs = tf.image.rgb_to_grayscale(x)\n    gs=tf.math.divide(gs,255)\n    return gs\n\n\ndef create_dataset(filename_list):\n    df=tf.data.Dataset.from_tensor_slices(filename_list)\n    im=df.map(decode_img)\n    gs=im.map(rgb_to_gs)\n    df=tf.data.Dataset.zip((gs,im))\n    df=df.batch(batch)\n    df=df.prefetch(tf.data.experimental.AUTOTUNE)\n    return df\n#These are the actual objects representing the input pipeline for Training and Testing\ntrain_df=create_dataset(fileList[:int(len(fileList)*0.8)])\ntest_df=create_dataset(fileList[int(len(fileList)*0.8):])","47bee1d2":"from tensorflow.keras.layers import Input,Conv2D,Add,Conv2DTranspose\nip=Input(shape=(256, 256,1))\nx=Conv2D(128,5,padding='same',activation='relu')(ip)\nx1=Conv2D(32,1,padding='same',activation='relu')(x)\nx2=Conv2D(32,3,padding='same',activation='relu')(x)\nx2=Conv2D(32,3,padding='same',activation='relu')(x2)\n\n\nx=Add()([x2,x1])\nx11=Conv2D(32,1,padding='same',activation='relu')(x)\nx21=Conv2D(32,3,padding='same',activation='relu')(x)\nx21=Conv2D(32,3,padding='same',activation='relu')(x21)\nx=Add()([x21,x11])\nx11=Conv2D(32,1,padding='same',activation='relu')(x)\nx21=Conv2D(32,3,padding='same',activation='relu')(x)\nx21=Conv2D(32,3,padding='same',activation='relu')(x21)\nx=Add()([x21,x11])\nx11=Conv2D(32,1,padding='same',activation='relu')(x)\nx21=Conv2D(32,3,padding='same',activation='relu')(x)\nx21=Conv2D(32,3,padding='same',activation='relu')(x21)\nx=Add()([x21,x11])\n\nx=Conv2DTranspose(32,3,padding='same',activation='relu')(x)\nx=Add()([x,x11])\nx=Conv2DTranspose(32,3,padding='same',activation='relu')(x)\n\nx=Add()([x,x1])\nx=Conv2DTranspose(32,5,padding='same',activation='relu')(x)\n\nx=Add()([x,x1])\nx=Conv2DTranspose(64,7,padding='same',activation='relu')(x)\nx=Conv2DTranspose(16,7,padding='same',activation='relu')(x)\nx=Conv2DTranspose(64,7,padding='same',activation='relu')(x)\nx=Conv2DTranspose(16,7,padding='same',activation='relu')(x)\nx=Conv2DTranspose(3,7,padding='same')(x)\nmodel=Model(inputs=ip,outputs=x)\nmodel.compile(optimizer = tf.keras.optimizers.Adam(), loss ='MSE')\nmodel.summary()","9aa7bfbb":"with tf.device(device):\n    model.fit(train_df,\n            validation_data=test_df,\n              epochs=15)","b755aedb":"model.save(\"ImageColourizationTFV2_256x256.h5\")","a80ef6a8":"ds_iter=iter(test_df)\nfor im_no in range(4):\n    fig,axis=plt.subplots(1,3,figsize=(25, 80))\n    x,y=next(ds_iter)\n    yhat=model.predict(x)\n    axis[0].imshow(x.numpy().reshape(256,256),cmap='gray')\n    axis[0].axis('off')\n    axis[0].set_title(\"Input Image\", fontsize=30)\n    axis[1].imshow(np.array(yhat[0],dtype=int).astype(int))\n    axis[1].axis('off')\n    axis[1].set_title(\"Model Prediction\", fontsize=30)\n    axis[2].imshow(np.array(y[0]).astype(int))\n    axis[2].axis('off')\n    axis[2].set_title(\"Original Image\", fontsize=30)","6d6078d3":"# Model Creation \nIn the next cell we utilize the sequential api of keras to create a model capable of coloring B&W images.","c5e50902":"# Creating an Input PipeLine for the model\nHere we utilize the Tensorflow Dataset api to create a flexible input pipeline for the model","ef4a5283":"# Image Colourization Machine Learning Algorithm\nThis notebook utilizes the Tensorflow library to impolement an AutoEncoder which converts landscape images from black and white to RGB.","36660ab2":"# Saving the model","a0ea87b9":"# Data Cleaning\nIn the next cell we create a numpy array of all the filenames and their paths.\nAfter that we use the Python Imaging Library to check for corrupted images and remove them from the file list","46f57a82":"# Looking at Training Results \nHere we isolate a batch of test data and use it to see how well our model performs on real world data.","91ec4185":"# Training the model\nHere we train the model for 15 epochs "}}