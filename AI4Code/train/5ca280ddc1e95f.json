{"cell_type":{"f48bda5a":"code","d7391962":"code","bef9c86e":"code","813787a4":"code","65343ac6":"code","567e4356":"code","29138876":"code","34dcd7a2":"code","5268dc23":"code","e66e921c":"code","6a68b361":"code","d18c0bcc":"markdown","8ac3ef74":"markdown","35ae91e4":"markdown","f8b0f8da":"markdown","8445f1f0":"markdown"},"source":{"f48bda5a":"import numpy as np\nimport pandas as pd\nimport pydicom\nimport time\n\nimport torch\nimport torchvision\nimport torchvision.transforms as T\nfrom collections import defaultdict, deque\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\n\nimport cv2\nimport os\n\nfrom PIL import Image\nfrom skimage import exposure\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d7391962":"path = '..\/input\/vinbigdata-chest-xray-abnormalities-detection\/'\ndf = pd.read_csv(path + 'train.csv')\ndf.head()","bef9c86e":"# replace NaN by 0\ndf = df.fillna(0)","813787a4":"class XrayDataset(object):\n    def __init__(self, df, path, transforms=None):\n        # select only those classes that have boxes\n        self.df = df[df['class_name'] != 'No finding']\n        self.transforms = transforms\n        self.categories = df['class_name'].unique()\n        self.idx_to_categories = {k:v for k,v in enumerate(self.categories)}\n        self.categories_to_idx = {v:k for k,v in enumerate(self.categories)}\n        self.images_paths = path + \"train\/\" + df['image_id'] + \".dicom\"\n        self.boxes = self.df[['x_min','y_min','x_max','y_max']]\n        \n    def __len__(self):\n        return len(self.images_paths)\n    \n    \n    def get_image(self, dicom):\n        intercept = dicom.RescaleIntercept if \"RescaleIntercept\" in dicom else 0.0\n        slope = dicom.RescaleSlope if \"RescaleSlope\" in dicom else 1.0\n        image = apply_voi_lut(dicom.pixel_array, dicom)\n        if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n            image = np.amax(image) - image\n        \n        if slope != 1:\n            image = slope * image.astype(np.float64)\n            image = image.astype(np.int16)\n            \n        image = np.stack([image, image, image])\n        image = image - np.min(image)\n\n        image = image \/ image.max()\n        image = exposure.equalize_hist(image)\n        image = image.astype('float32')\n\n        image = image.transpose(1,2,0)\n        \n        return image\n    \n    def __getitem__(self, idx):\n        dicom = pydicom.read_file(self.images_paths.iloc[idx])\n        img = self.get_image(dicom)\n        \n        boxes = np.expand_dims(self.boxes.iloc[idx].values, axis=0)\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        \n        target = {}\n        target['boxes'] = torch.tensor(boxes)\n        target['labels'] = torch.tensor([self.categories_to_idx[self.df.iloc[idx].class_name]])\n        target['area'] = torch.as_tensor(area, dtype=torch.float32)\n        target['iscrowd'] = torch.zeros((self.df.iloc[idx].shape[0],), dtype=torch.int64)\n        \n        if self.transforms is not None:\n            img = self.transforms(img)\n        \n        return img, target","65343ac6":"def get_transform(train, dim_size):\n    transforms = []\n    transforms.append(T.ToTensor())\n    if train:\n        transforms.append(T.Resize(dim_size))\n        transforms.append(T.RandomHorizontalFlip(0.5))\n    return T.Compose(transforms)","567e4356":"dim_size = (256, 256)\nxrayds = XrayDataset(df, path, get_transform(train=True, dim_size=dim_size))\n\nimg, target = xrayds[100]\nplt.imshow(img.permute(1, 2, 0))","29138876":"num_classes = len(xrayds.categories)\n\ndataset = XrayDataset(df, path, get_transform(train=True, dim_size=dim_size))\ndataset_test = XrayDataset(df, path, get_transform(train=True, dim_size=dim_size))\n\n# use only 100 dicom files for demo\nnr_dicom = 100\nindices = torch.randperm(nr_dicom).tolist()\ndataset = torch.utils.data.Subset(dataset, indices)\n\n\ndef collate_fn(batch):\n    return list(zip(*batch))\n\n# define training and validation data loaders\ndata_loader = torch.utils.data.DataLoader(\n    dataset, batch_size=2, shuffle=True, num_workers=4,\n    collate_fn=collate_fn)","34dcd7a2":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n\n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\nmodel = model.to(device)","5268dc23":"params = [p for p in model.parameters() if p.requires_grad]\n\noptimizer = torch.optim.SGD(params, lr=0.0001,\n                            momentum=0.9, weight_decay=0.0001)\n\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                               step_size=3,\n                                               gamma=0.1)","e66e921c":"loss_epoch = []\nfor epoch in range(5):\n    \n    loss_iteration = []\n    for i, (images, targets) in enumerate(data_loader):\n        \n        images = list(image.to(device).type(torch.cuda.FloatTensor) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        loss_dict = model(images, targets)\n\n        losses = sum(loss for loss in loss_dict.values())\n        loss_value = losses.item()\n        loss_iteration.append(loss_value)\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n\n        if i % 10 == 0:\n            print(\"Epoch:{:4d}, Iteration:{:4d}, Loss:{:4.4f}\"\n                  .format(epoch, i, loss_iteration[-1]))\n            \n    loss_epoch.append(np.array(loss_iteration).mean())\n    \n    if lr_scheduler is not None:\n        lr_scheduler.step()","6a68b361":"plt.figure(figsize=(14,7))\nplt.xlabel('Epoch', fontsize=15)\nplt.ylabel('Loss', fontsize=15)\nplt.title(\"Mean Loss per Epoch\", fontsize=15)\nplt.plot(loss_epoch)","d18c0bcc":"<h2 align=center style=\"color:red; border:1px dotted red\">Chest X-ray - Faster RCNN<\/h2>","8ac3ef74":"<h2 align=center style=\"color:red; border:1px dotted red\">Training<\/h2>","35ae91e4":"<h2 align=center style=\"color:red; border:1px dotted red\">Analyze<\/h2>","f8b0f8da":"<pre>\n\n                 .=.\n         .---._.-.=.-._.---.\n        \/ ':-(_.-: :-._)-:` \\\n       \/ \/' (__.-: :-.__) `\\ \\\n      \/ \/  (___.-` '-.___)  \\ \\\n     \/ \/   (___.-'^`-.___)   \\ \\\n    \/ \/    (___.-'=`-.___)    \\ \\\n   \/ \/     (____.'=`.____)     \\ \\\n  \/ \/       (___.'=`.___)       \\ \\\n (_.;       `---'.=.`---'       ;._)\n<\/pre>\n\n### By Alin Cijov","8445f1f0":"<h2 align=center style=\"color:red; border:1px dotted red\">Dataset<\/h2>"}}