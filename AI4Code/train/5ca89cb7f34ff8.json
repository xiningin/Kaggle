{"cell_type":{"da60e711":"code","88eccdb1":"code","33de0be4":"code","2618efcc":"code","dd861f18":"code","89b61518":"code","f0225ead":"code","c68ee303":"code","cc3e932d":"code","4b3ef3a4":"code","d35cdf7d":"code","55540134":"code","515e119e":"code","6faec438":"code","d6ce230e":"code","d259db27":"code","1f5567c9":"code","185470ec":"code","4e847fa6":"code","30502808":"code","9d7c49a1":"code","452a64a9":"code","a684e2d5":"code","a704f8c1":"code","2ed9dc1f":"code","6dda958e":"code","6467a87b":"code","3290ccd1":"code","8e1a9ca1":"code","34400e7f":"code","fdfca3bd":"code","9866d6d0":"code","de44005e":"code","e994b8b2":"code","90c2eec5":"code","364fe206":"code","9d05f784":"code","84524dcc":"code","482349b3":"code","5ffe7688":"code","4837f838":"code","d99ccb0c":"code","daba7644":"code","0594b75e":"code","7b99cf32":"code","f5945d18":"code","f1594740":"code","066ec2e4":"code","b9c4ef23":"code","5aaf6de3":"code","cfb69cc2":"code","5a649b56":"code","424012a4":"code","89f1ee6a":"code","8b235594":"code","4ccfd7f9":"code","c71f239a":"code","91df4788":"code","e0df7ef5":"code","1b2aff88":"code","253ccb03":"code","eba9741d":"code","0323e3b7":"code","a9df6532":"code","ed7c2f57":"code","1e5dc95e":"code","bc59d2c4":"code","b634c1a2":"markdown","a7f692e5":"markdown","6fb5404d":"markdown","c4d239aa":"markdown","a6ab8ed8":"markdown","046170a4":"markdown","6f1aa4ff":"markdown","d1e1089b":"markdown","8c806f46":"markdown","64c80600":"markdown","da62dd02":"markdown","58cc1d5f":"markdown","52b92537":"markdown","8fd5a5ec":"markdown","ebf82dd5":"markdown","8ef58212":"markdown","32ed05f1":"markdown","323a9dea":"markdown","9526bdaa":"markdown"},"source":{"da60e711":"import numpy as np \nimport pandas as pd\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.offline as pyo\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nimport warnings\n\nwarnings.simplefilter(\"ignore\")\n%matplotlib inline\npyo.init_notebook_mode()\nsns.set()","88eccdb1":"conda install openpyxl","33de0be4":"train_data = pd.read_excel('\/kaggle\/input\/flight-fare-prediction-mh\/Data_Train.xlsx')\ntrain_data.head(10)","2618efcc":"pd.set_option('display.max_columns',None)","dd861f18":"train_data.info()","89b61518":"train_data.shape","f0225ead":"train_data.isnull().sum()","c68ee303":"train_data.dropna(inplace=True)","cc3e932d":"train_data.isnull().sum()","4b3ef3a4":"train_data['Duration'].value_counts()","d35cdf7d":"train_data.dtypes","55540134":"train_data['Journey_Day'] = pd.to_datetime(train_data.Date_of_Journey, format=\"%d\/%m\/%Y\").dt.day\ntrain_data['Journey_month'] = pd.to_datetime(train_data[\"Date_of_Journey\"], format=\"%d\/%m\/%Y\").dt.month\ntrain_data.head(10)","515e119e":"train_data.drop(columns=['Date_of_Journey'],inplace=True)\ntrain_data","6faec438":"train_data[\"Dep_hour\"] = pd.to_datetime(train_data['Dep_Time']).dt.hour\ntrain_data['Dep_min'] = pd.to_datetime(train_data['Dep_Time']).dt.minute\ntrain_data.drop(columns=['Dep_Time'],inplace=True)\ntrain_data","d6ce230e":"#Arrival time is when plane pulls up to the gate \ntrain_data[\"Arrival_hour\"] = pd.to_datetime(train_data['Arrival_Time']).dt.hour\ntrain_data['Arrival_min'] = pd.to_datetime(train_data['Arrival_Time']).dt.minute\ntrain_data.drop(columns=['Arrival_Time'],inplace=True)\ntrain_data","d259db27":"# Feature engineering on Duration column\n\nduration = list(train_data['Duration'])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:\n        if \"h\" in duration[i]:\n            duration[i] = duration[i].strip() + \" 0m\"\n        else:\n            duration[i] = \"0h \" + duration[i]\n\nduration_hours = []\nduration_mins = []\n\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep='h')[0]))\n    duration_mins.append(int(duration[i].split(sep='m')[0].split()[-1]))","1f5567c9":"train_data['Duration_hours'] = duration_hours\ntrain_data['Duration_mins'] = duration_mins\ntrain_data.drop(columns=['Duration'],inplace=True)\ntrain_data.head(10)","185470ec":"train_data['Airline'].value_counts()","4e847fa6":"# Airline vs Price\nsns.catplot(y='Price',x='Airline',data=train_data.sort_values('Price',ascending=False),kind='boxen',height=10,aspect=3)\nplt.show()","30502808":"# As airline is nominal categorical data we will perform One-Hot Encoding\nAirline = train_data[['Airline']]\nAirline = pd.get_dummies(Airline,drop_first=True)\nAirline.head()","9d7c49a1":"#Source or Departure airport\ntrain_data['Source'].value_counts()","452a64a9":"sns.catplot(\n    y='Price',\n    x='Source',\n    data=train_data.sort_values('Price',ascending=False),\n    kind='boxen',\n    height=10,\n    aspect=3\n)\nplt.show()","a684e2d5":"Source = train_data[['Source']]\nSource = pd.get_dummies(Source,drop_first=True)\nSource.head()","a704f8c1":"# Destination Airport\ntrain_data['Destination'].value_counts()","2ed9dc1f":"Destination = train_data[['Destination']]\nDestination = pd.get_dummies(Destination,drop_first=True)\nDestination.head()","6dda958e":"# Route\ntrain_data['Route']","6467a87b":"temp_df = train_data['Additional_Info'].value_counts().rename_axis('Additional_info').reset_index(name='counts')\ntemp_df","3290ccd1":"fig = px.pie(\n             temp_df, \n             values='counts', \n             names='Additional_info', \n             title='Percentage of each category present in Additional Info',\n             template='plotly_dark'\n            )\nfig.show()","8e1a9ca1":"temp_df = train_data['Total_Stops'].value_counts().rename_axis('Total_Stops').reset_index(name='counts')\ntemp_df","34400e7f":"fig = px.pie(\n             temp_df, \n             values='counts', \n             names='Total_Stops', \n             title='Percentage of the number of stops in flights',\n             template='plotly_dark'\n            )\nfig.show()","fdfca3bd":"train_data.drop(columns=['Route','Additional_Info'],inplace=True)\ntrain_data","9866d6d0":"train_data.replace({\n    'non-stop' : 0,\n    '1 stop' : 1,\n    '2 stops' : 2,\n    '3 stops' : 3,\n    '4 stops' : 4\n}, inplace = True)\ntrain_data.head()","de44005e":"#  Concatenate dataframe\ndata_train = pd.concat([train_data, Airline, Source, Destination],axis=1)\ndata_train.head()","e994b8b2":"data_train.drop(columns=['Airline','Source','Destination'],inplace=True)\ndata_train.head()","90c2eec5":"data_train.shape","364fe206":"test_data = pd.read_excel(\"\/kaggle\/input\/flight-fare-prediction-mh\/Test_set.xlsx\")\ntest_data.head()","9d05f784":"# Preprocessing of Test Data\nprint('Test Data Info')\nprint(\"-\"*75)\nprint(test_data.info())\n\nprint()\nprint()\n\nprint(\"Null values :\")\nprint(\"-\"*75)\ntest_data.dropna(inplace=True)\nprint(test_data.isnull().sum())\n\n#EDA\n\n#Date of Journey\ntest_data['Journey_Day'] = pd.to_datetime(test_data.Date_of_Journey, format=\"%d\/%m\/%Y\").dt.day\ntest_data['Journey_month'] = pd.to_datetime(test_data[\"Date_of_Journey\"], format=\"%d\/%m\/%Y\").dt.month\ntest_data.drop(columns=['Date_of_Journey'],inplace=True)\n\n#Dep Time\ntest_data[\"Dep_hour\"] = pd.to_datetime(test_data['Dep_Time']).dt.hour\ntest_data['Dep_min'] = pd.to_datetime(test_data['Dep_Time']).dt.minute\ntest_data.drop(columns=['Dep_Time'],inplace=True)\n\n#Arrival Time\ntest_data[\"Arrival_hour\"] = pd.to_datetime(test_data.Arrival_Time).dt.hour\ntest_data[\"Arrival_min\"] = pd.to_datetime(test_data.Arrival_Time).dt.minute\ntest_data.drop(columns=[\"Arrival_Time\"], inplace = True)\n\n#Duration\nduration = list(test_data[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n        if \"h\" in duration[i]:\n            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n        else:\n            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n\nduration_hours = []\nduration_mins = []\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration\n\n# Adding Duration column to test set\ntest_data[\"Duration_hours\"] = duration_hours\ntest_data[\"Duration_mins\"] = duration_mins\ntest_data.drop([\"Duration\"], axis = 1, inplace = True)\n\n# Categorical data\n\nprint(\"Airline\")\nprint(\"-\"*75)\nprint(test_data[\"Airline\"].value_counts())\nAirline = pd.get_dummies(test_data[\"Airline\"], drop_first= True)\n\nprint()\n\nprint(\"Source\")\nprint(\"-\"*75)\nprint(test_data[\"Source\"].value_counts())\nSource = pd.get_dummies(test_data[\"Source\"], drop_first= True)\n\nprint()\n\nprint(\"Destination\")\nprint(\"-\"*75)\nprint(test_data[\"Destination\"].value_counts())\nDestination = pd.get_dummies(test_data[\"Destination\"], drop_first = True)\n\n# Additional_Info contains almost 80% no_info\n# Route and Total_Stops are related to each other\ntest_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)\n\n# Replacing Total_Stops\ntest_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n\n# Concatenate dataframe --> test_data + Airline + Source + Destination\ndata_test = pd.concat([test_data, Airline, Source, Destination], axis = 1)\n\ndata_test.drop(columns=[\"Airline\", \"Source\", \"Destination\"], inplace = True)\n\nprint()\nprint()\n\nprint(\"Shape of test data : \", data_test.shape)","84524dcc":"data_test.head()","482349b3":"data_train.columns","5ffe7688":"X = data_train.drop(columns=['Price'])\nX.head()","4837f838":"y = data_train['Price']\ny.head()","d99ccb0c":"#Correlation matrix\n\nplt.figure(figsize=(18,18))\nsns.heatmap(train_data.corr(),annot=True,cmap=\"RdYlGn\")\n\nplt.show()","daba7644":"from sklearn.ensemble import ExtraTreesRegressor\nselection = ExtraTreesRegressor()\nselection.fit(X,y)","0594b75e":"print(selection.feature_importances_)","7b99cf32":"plt.figure(figsize=(12,8))\nfeat_importances = pd.Series(selection.feature_importances_,index=X.columns)\nfeat_importances.nlargest(20).plot(kind='barh')\nplt.show()","f5945d18":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)","f1594740":"from sklearn.ensemble import RandomForestRegressor\nreg_rf = RandomForestRegressor()\nreg_rf.fit(X_train,y_train)","066ec2e4":"y_pred = reg_rf.predict(X_test)\ny_pred","b9c4ef23":"reg_rf.score(X_train,y_train)","5aaf6de3":"reg_rf.score(X_test,y_test)","cfb69cc2":"sns.distplot(y_test-y_pred)\nplt.show()","5a649b56":"plt.scatter(y_test,y_pred,alpha=0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"y_pred\")\nplt.show()","424012a4":"from sklearn import metrics\nprint('MAE:',metrics.mean_absolute_error(y_test,y_pred))\nprint('MSE:',metrics.mean_squared_error(y_test,y_pred))\nprint('RMSE:',np.sqrt(metrics.mean_absolute_error(y_test,y_pred)))","89f1ee6a":"metrics.r2_score(y_test,y_pred)","8b235594":"from sklearn.model_selection import RandomizedSearchCV","4ccfd7f9":"#Create the random grid\n\nn_estimators = [int(x) for x in np.linspace(start=100,stop=1200,num=12)]\nmax_features = ['auto','sqrt']\nmax_depth = [int(x) for x in np.linspace(5,30,num=6)]\nmin_samples_split = [2,5,10,15,100]\nmin_samples_leaf = [1,2,5,10]\n\nrandom_grid = {\n    'n_estimators':n_estimators,\n    'max_features':max_features,\n    'max_depth':max_depth,\n    'min_samples_split':min_samples_split,\n    'min_samples_leaf':min_samples_leaf\n}","c71f239a":"rf_random = RandomizedSearchCV(estimator=reg_rf,param_distributions=random_grid,scoring='neg_mean_squared_error',n_iter=10,cv=5,verbose=2,n_jobs=1)","91df4788":"rf_random.fit(X_train,y_train)","e0df7ef5":"rf_random.best_params_","1b2aff88":"prediction = rf_random.predict(X_test)","253ccb03":"plt.figure(figsize=(8,8))\nsns.distplot(y_test-prediction)\nplt.show()","eba9741d":"plt.figure(figsize=(8,8))\nplt.scatter(y_test,prediction,alpha=0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"y_pred\")\nplt.show()","0323e3b7":"print('MAE:',metrics.mean_absolute_error(y_test,prediction))\nprint('MSE:',metrics.mean_squared_error(y_test,prediction))\nprint('RMSE:',np.sqrt(metrics.mean_absolute_error(y_test,prediction)))","a9df6532":"import pickle\nfile = open('flight_rf.pkl','wb')\npickle.dump(rf_random,file)","ed7c2f57":"model = open('flight_rf.pkl','rb')\nforest = pickle.load(model)","1e5dc95e":"y_prediction = forest.predict(X_test)\ny_prediction","bc59d2c4":"metrics.r2_score(y_test, y_prediction)","b634c1a2":"## Hyper-Parameter Tuning","a7f692e5":"## Saving the model","6fb5404d":"## Preprocessing the Test Data set","c4d239aa":"From the above output snippet we can clarify that almost 80% of the column has no additional information","a6ab8ed8":"## Fitting the model using Random Forest","046170a4":"#### Analysis on Duration column\n\n> As we know that in Duration column there are values like 4h 45m, 3h or 45m we need to convert into the format of hours and minutes that is like x hours y mins. So if the value is like 45m than we can write 0h 45m and the exact process is performed for hours also.\n\n> Below, I have first transformed the column into x hours y mins format and than I have extracted the hours & minutes from it separately to make a new column. Afterwards we can remove the whole transformed column which is of no need.","6f1aa4ff":"## Name: Jay Shah\n## Date: 26-10-2021\n\n### Flight Fare Price Prediction Using Random Forest Regressor","d1e1089b":"## Exploratory Data Analysis","8c806f46":"> There is no need of Route column as total stops column is present.\n\n> Almost 80% of the data in Additional_Info is No_info.","64c80600":"## Handling Categorical Data\n\n1. Nominal data --> Data are not in any order --> OneHotEncoder is used in this case\n2. Ordinal data --> Data are in order --> Labelencoder is used in this case\n","da62dd02":"From the above output snippet we know that there are only 2 missing values and therefore, I have decided to drop those values as it won't affect much to the dataset.","58cc1d5f":"In the above output snippet, we have extracted the journey day and month from the Date_of_Journey column and hence we can remove that column only as it is of no use.","52b92537":"> Here we will remove the string from Total_stops column and replace it with the number.","8fd5a5ec":"From the above output snippet, we can verify that slightly more than half of the flights have 1 stop.","ebf82dd5":"#### Analysis on arrival time column\n > The exact process is performed as that of departure time column.","8ef58212":"* From the above output column we know that Date_of_Journey is a object data type.\n\n* Therefore, we have to convert this datatype into timestamp so as to use this column properly for prediction.\n\n* We will require pandas to_datetime to convert object data type to datetime object.","32ed05f1":"#### Analysis on departure time column\n\n> We will extract the hours and minutes from departure time column and afterwards we will remove the original column.","323a9dea":"## Feature Selection\n\nFinding out the best feature which will contribute and have good relation with the target variable.\nFollowing are some of the feature selection methods,\n\n1. Heatmap\n2. feature_importance_\n3. SelectKBest\n\nHere we are going to use Feature Importance method by fitting the data using ExtraTreesRegressor.","9526bdaa":"> From the above graph we can clearly say that the price of Jet Airways is high whereas the price of other flights available is pretty low when comoared to Jet Airways."}}