{"cell_type":{"3dc83989":"code","551f4571":"code","e13d8b0a":"code","0fff7b16":"code","1da1978d":"code","e3a75007":"code","ace5b7cc":"code","c7c3cc45":"code","99aae242":"code","6790b076":"code","4557972b":"code","8ac346a4":"code","f67ac702":"code","822ffd67":"code","1b5e807d":"code","31a1d0a6":"code","d42af05e":"code","6e0710e8":"code","076520fc":"code","b519967a":"code","27d3e118":"code","5a5e88fa":"code","52df909d":"code","73bfe7dd":"code","521077d7":"code","48c03491":"code","68db7c9c":"code","2451b5fe":"code","661fd407":"code","4b36aaa0":"code","9239c64f":"markdown","787c14ac":"markdown","712ad637":"markdown","af8180fe":"markdown","fde25615":"markdown","80b98cc1":"markdown","8eb4be85":"markdown","cf015381":"markdown","b14db89f":"markdown","5b75dd43":"markdown","b21b9d8a":"markdown","7fc6d7b8":"markdown","abf6aa3f":"markdown","21713089":"markdown","437d9d2a":"markdown","5573b3d6":"markdown","602854ac":"markdown","d84dd1db":"markdown","be38027c":"markdown","8d4fb754":"markdown","58041af5":"markdown"},"source":{"3dc83989":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\npd.options.display.max_columns = 50\nimport warnings\nwarnings.filterwarnings('ignore')\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","551f4571":"%matplotlib inline\nimport plotly.express as px\n\nfrom collections import Counter\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport holoviews as hv\nfrom holoviews import opts\n\nimport datashader as ds, datashader.transfer_functions as tf, numpy as np\nfrom datashader import spatial\nimport holoviews.operation.datashader as hd\nfrom holoviews.operation import decimate\n\nfrom functools import partial\nimport datashader as ds\nfrom datashader.utils import export_image\nfrom seaborn import color_palette\nfrom holoviews.element.tiles import StamenTerrain, EsriTerrain\n\nhv.extension('bokeh')","e13d8b0a":"input_path = \"..\/input\/birdclef-2021\"\n\nhv_opts = dict(cmap='jet', \n               bgcolor='aqua',\n                fontsize={'xticks':7.7, 'yticks':7},\n                xrotation=90,\n                xaxis='top',\n                yaxis='left',\n                height=2200,\n                width=1300,\n                colorbar=True,\n                tools=['hover'])\n\nhv_bar = dict(fontsize={'xticks':7.7, 'yticks':7},\n#               xrotation=90,\n                xaxis='top',\n                yaxis='left',\n                height=2700,\n                width=800,\n                show_grid=True,\n                invert_axes=True,\n                tools=['hover'])\n\nhv_subplot = dict(fontsize={'xticks':7.7, 'yticks':7},\n#               xrotation=90,\n#                 xaxis='top',\n                yaxis='left',\n                height=300,\n                width=1100,\n                show_grid=True,\n                  shared_axes=False,\n#                 invert_axes=True,\n                tools=['hover'])\n\nhv_spectra = dict(height=250,\n                  width=550,\n                  show_grid=True,\n                  xaxis=None,\n                  yaxis=None,\n                  tools=['hover'])","0fff7b16":"#check audio files per bird-type\naudio_path = os.path.join(input_path, \"train_short_audio\/\")\naudio_dist = {}\nfor bird_type in os.listdir(audio_path):\n    len_audio = len(os.listdir(audio_path + os.sep + f\"{bird_type}\"))\n    audio_dist[bird_type] = len_audio\n\naudio_df = pd.DataFrame.from_dict(audio_dist, orient='index', \\\n                                  columns=['Audio_Count']).reset_index(drop=False).rename(columns={'index':'Bird_Type'})\n\n\naudio_df.info()","1da1978d":"hv.Bars(audio_df.sort_values(by='Audio_Count', ascending=False)).opts(**hv_bar, color='lightpink',\n                                                                      title='Audio File Distribution For Different Birds.')","e3a75007":"train_df = pd.read_csv('..\/input\/birdclef-2021\/train_metadata.csv')\ntrain_df.head()","ace5b7cc":"train_df.info()","c7c3cc45":"lat_long_df = train_df[['longitude', 'latitude', 'primary_label', 'scientific_name']]\nlat_long_df.replace('Not specified', np.NaN, inplace=True)\nlat_long_df.replace('?', np.NaN, inplace=True)\nlat_long_df.dropna(axis=0, inplace=True)\nlat_long_df['longitude'] = lat_long_df['longitude'].apply(lambda x: float(x))\nlat_long_df['latitude'] = lat_long_df['latitude'].apply(lambda x: float(x))\n\n#generate Web Mercator format for Latitude and Longitude..\nfrom datashader.utils import lnglat_to_meters as webm\nlat_long_webm = list(lat_long_df[['longitude', 'latitude']].apply(lambda x: webm(*x), axis=1).values)\nlat_long_df.loc[:, 'long_wemr'] = [i[0] for i in lat_long_webm]\nlat_long_df.loc[:, 'lat_wemr'] = [i[1] for i in lat_long_webm]","99aae242":"decimate.max_samples=10\nx_range,y_range = (-19230442.03453801,  19831389.17363642), (-6933173.79129572, 15142823.60169782)\n\nplot_width  = int(1300)\nplot_height = int(800)\n\nunique_values = lat_long_df['scientific_name'].unique()\ncolors = ['#%02x%02x%02x' % (a, b, c) for a,b,c in np.round(255*np.array(color_palette('plasma',n_colors=len(unique_values)))).astype(int)]\ncolor_key = {val:color for val,color in zip(unique_values,colors)}","6790b076":"tiles = StamenTerrain().redim.range(x=tuple(x_range), y=tuple(y_range))\nlat_longs = hv.Points(lat_long_df, ['long_wemr', 'lat_wemr']).opts(size=5, alpha=0.7)\n\nshade = hd.datashade(lat_longs,\n                     aggregator=ds.count_cat('scientific_name'),\n                     color_key=color_key)\n\ntiles * hd.dynspread(shade).opts(width=plot_width,\n                                  height=plot_height,\n                                  xaxis=None, yaxis=None)","4557972b":"import librosa\nimport random\n\ndef get_file(n=1, species=5):\n    ran_samples = {}\n    \n    for species in list(audio_dist.keys())[:5]:\n        species_samples = os.listdir(audio_path + os.sep + species)\n        ran_samples[species] = random.sample(species_samples, n).pop()\n    \n    return [audio_path + sp + os.sep + file for sp, file in ran_samples.items()]\n    \n\nsample_files = get_file(n=1,species=5)\nprint(sample_files)","8ac346a4":"tempogram_info = {}\nchromagram_info = {}\nspectral_bandwidth_info = {}\ntonnetz_info = {}\nmfcc_info = {}\npoly_info = {}\nspec_contrast_info = {}\nfourier_tempo_info = {}\n\n\nfor file in sample_files:\n    data, sr = librosa.load(file)\n    \n    chromagram_info[file] = librosa.feature.chroma_stft(data, sr=sr)\n    spectral_bandwidth_info[file] = librosa.feature.spectral_bandwidth(data, sr=sr)\n    tonnetz_info[file] = librosa.feature.tonnetz(data, sr=sr)\n    mfcc_info[file] = librosa.feature.mfcc(data, sr=sr)\n    poly_info[file] = librosa.feature.poly_features(data, win_length=15, sr=sr)\n    spec_contrast_info[file] = librosa.feature.spectral_contrast(data, sr=sr)\n    \n    #declare onset strength with hop length for rythmic features aka tempogram..\n    oenv = librosa.onset.onset_strength(y=data, sr=sr, hop_length=512)\n    fourier_tempo_info[file] = np.abs(librosa.feature.fourier_tempogram(onset_envelope=oenv,\n                                                                        sr=sr,\n                                                                        hop_length=512))\n    tempogram_info[file] = librosa.feature.tempogram(onset_envelope=oenv,\n                                                     sr=sr,\n                                                     hop_length=512)","f67ac702":"def plot_features(features_dict, title='Chromagram'):\n    layout = []\n\n    for k,v in features_dict.items():\n        species, files = k.split(\"\/\")[-2:]\n        gram = hv.Image(features_dict[k]).opts(**hv_spectra, cmap='plasma',\n                                               title=f\"{species.capitalize()}-{files.capitalize()} || {title}\")\n\n        layout.append(gram)\n    \n    plot = hv.Layout(layout).cols(2)\n\n    return plot","822ffd67":"plot_features(chromagram_info)","1b5e807d":"plot_features(tonnetz_info, title='Tonnetz - Tonal Centroid.')","31a1d0a6":"plot_features(mfcc_info, title='MFCCs.')","d42af05e":"plot_features(poly_info, title='Poly Feats. window size 15')","6e0710e8":"plot_features(spec_contrast_info, title='Spectral Contrast.')","076520fc":"plot_features(tempogram_info, title='Auto-Correlation Tempogram')","b519967a":"plot_features(fourier_tempo_info, title='Fourier Tempogram.')","27d3e118":"#let's use one audio file\n\nsample_audio = sample_files[0]\nsample_audio, rate = librosa.load(sample_audio)\n\n#spectrogram ..\nsample_stft = np.abs(librosa.stft(sample_audio))\n#decompose the spectrogram such that components.dot(activations)..\ncomps, acts = librosa.decompose.decompose(sample_stft, n_components=32)\n\n#reconstructed...\nstft_recons = comps.dot(acts)","5a5e88fa":"stft_glyph = hv.Raster(librosa.amplitude_to_db(sample_stft,\n                                               ref=np.max)).opts(**hv_subplot,\n                                                                              cmap='plasma',\n                                                                              title=\"Spectrogram\")\n\n#decompose..\ncomps_glyph = hv.Raster(librosa.amplitude_to_db(comps,\n                                                ref=np.max)).opts(**hv_subplot,\n                                                                         cmap='plasma',\n                                                                         title='Components')\nacts_glyph = hv.Image(acts).opts(**hv_subplot,\n                                 cmap='plasma',\n                                 title='Activations')\n\n#reconstruct..\nstft_recons_glyph = hv.Raster(librosa.amplitude_to_db(stft_recons,\n                                                      ref=np.max)).opts(**hv_subplot,\n                                                                                     cmap='plasma',\n                                                                                     title='Reconstructed Spectogram | [coms.dot(actss)]')\n\nhv.Layout(stft_glyph + comps_glyph + acts_glyph + stft_recons_glyph).cols(1) ","52df909d":"cat_unique_df = train_df.select_dtypes(include='object').nunique().reset_index().rename(columns={'index':'Column_Name',\n                                                                                 0 : 'Unique_values'}).sort_values(by='Unique_values')\nhv.Bars(cat_unique_df).opts(**hv_bar, color='aqua', title='Unique Values For Each Catergorical Variable.')","73bfe7dd":"int_unique_df = train_df.select_dtypes(include=['int', 'float']).nunique().reset_index().rename(columns={'index':'Column_Name',\n                                                                                                   0 : 'Unique_values'}).sort_values(by='Unique_values')\nhv.Bars(int_unique_df).opts(**hv_subplot,\n                            color='lightgreen',\n#                             height=500,\n                            title='Unique Values For Each Integer\/Float Variable.')","521077d7":"hv.Bars(train_df['scientific_name'].value_counts()).opts(**hv_bar, color='orange', title='Distribution of scientific_name.')","48c03491":"hv.Bars(train_df['primary_label'].value_counts()).opts(**hv_bar, color='aqua', title='Distribution of primary_label.')","68db7c9c":"hv.Bars(train_df['rating'].value_counts()).opts(**hv_subplot, color='lightblue', title='Distribution of Ratings.')","2451b5fe":"hv.Bars(train_df['common_name'].value_counts()).opts(**hv_bar, color='lightblue', title='Distribution of Common Name.')","661fd407":"df_date = train_df.groupby(\"date\")[\"scientific_name\"].count().reset_index().rename(columns = {\"species\": \"recordings\"})\ndf_date.date = pd.to_datetime(df_date.date, errors = \"coerce\")\ndf_date[\"weekday\"] = df_date.date.dt.day_name()\ndf_date.dropna(inplace = True)\nper_day_records = df_date.groupby('weekday', as_index=False).sum().sort_values(by='weekday')","4b36aaa0":"sub_1 = hv.Curve(data=df_date).opts(**hv_subplot, color='darkgrey', title='Yearwise Recordings')\nsub_2 = hv.Bars(data=per_day_records).opts(**hv_subplot, color='grey', title='Daywise Recordings')\nhv.Layout([sub_1, sub_2]).cols(1)","9239c64f":"# Audio Data - Feature Extraction using Librosa[[](http:\/\/)](http:\/\/)\n\nLet's extract some features using Librosa library from the audio signals","787c14ac":"# Rhythm Features\n\n## [Tempogram](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.tempogram.html#id1) - Computes the Auto-Correlation tempogram","712ad637":"### Common Name","af8180fe":"### Scientific Name","fde25615":"# Audio Files Check","80b98cc1":"## [Fourier Tempogram](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.fourier_tempogram.html#librosa.feature.fourier_tempogram) - Computes the Fourier Tempogram","8eb4be85":"# Unique Values Check","cf015381":"# Spectrogram","b14db89f":"# [Tonnetz](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.tonnetz.html#librosa.feature.tonnetz) - Computes the tonal centroid features (tonnetz)","5b75dd43":"# [Poly-Features](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.poly_features.html#librosa.feature.poly_features) - Coefficients of fitting an nth-order polynomial to the columns of a spectrogram.","b21b9d8a":"# [Chromagram](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.chroma_stft.html#librosa.feature.chroma_stft) - Compute a chromagram from a waveform","7fc6d7b8":"### Primary Label","abf6aa3f":"# [Spectral Contrast](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.spectral_contrast.html#librosa.feature.spectral_contrast) - Computes Spectral Contrast","21713089":"# [Data Shading](https:\/\/holoviews.org\/index.html) - Using Lat & Long Information","437d9d2a":"# Train Data","5573b3d6":"# Variable Distributions","602854ac":"### Ratings","d84dd1db":"### Float Types","be38027c":"### Categorical Types","8d4fb754":"# [MFCC](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.mfcc.html#librosa.feature.mfcc) - Mel-frequency cepstral coefficients (MFCCs)","58041af5":"Looks like `scientific_name` and `primary_label` has similar Distribution."}}