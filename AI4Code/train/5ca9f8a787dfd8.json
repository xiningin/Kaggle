{"cell_type":{"e3b72a4c":"code","ceadaac3":"code","ae86e1ca":"code","9b930738":"code","a5b2272d":"code","7b0c299e":"code","4ec314c1":"code","a2b0aa05":"code","5dbf83a2":"code","e2942492":"code","8f425ddf":"code","254797d0":"code","22c723bd":"code","37f2b4b7":"code","4ffff8ed":"code","828aa20c":"markdown","920e1ba9":"markdown","d60dff32":"markdown","16037fcc":"markdown"},"source":{"e3b72a4c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ceadaac3":"import matplotlib.pyplot as plt\n\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, Dropout, LSTM, Bidirectional\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split","ae86e1ca":"df = pd.read_csv('..\/input\/names-for-gender-prediction\/name_gender_1950-2018.csv', names=['name', 'gender'])\n\ndf['name'] = df['name'].apply(lambda x: str(x).lower())\ndf = df[[len(e)>1 for e in df.name]]\ndf = df.drop_duplicates()\n\nnames = df['name'].apply(lambda x: x.lower())\ngender = df['gender']\n\ndf.head()","9b930738":"plt.hist([len(a) for a in names], bins=30)\nplt.title('Length of the names')\nplt.show()","a5b2272d":"maxlen = 20\nlabels = 2","7b0c299e":"# Class balance\nprint('Male : ' + str(sum(gender=='M')))\nprint('Female : ' + str(sum(gender=='F')))","4ec314c1":"vocab = set(' '.join([str(i) for i in names]))\nvocab.add('END')\nlen_vocab = len(vocab)","a2b0aa05":"char_index = dict((c, i) for i, c in enumerate(vocab))\nprint(char_index)","5dbf83a2":"X = []\ny = []\n\n# Builds an empty line with a 1 at the index of character\ndef set_flag(i):\n    tmp = np.zeros(len_vocab);\n    tmp[i] = 1\n    return list(tmp)\n\n# Truncate names and create the matrix\ndef prepare_X(X):\n    new_list = []\n    trunc_train_name = [str(i)[0:maxlen] for i in X]\n    for i in trunc_train_name:\n        tmp = [set_flag(char_index[j]) for j in str(i)]\n        for k in range(0,maxlen - len(str(i))):\n            tmp.append(set_flag(char_index['END']))\n        new_list.append(tmp)\n    return new_list\n\nX = prepare_X(names.values)\n\n# Label Encoding of y\ndef prepare_y(y):\n    new_list = []\n    for i in y:\n        if i == 'M':\n            new_list.append([1,0])\n        else:\n            new_list.append([0,1])\n    return new_list\n\ny = prepare_y(gender)","e2942492":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)","8f425ddf":"model = Sequential()\nmodel.add(Bidirectional(LSTM(128, return_sequences=True), backward_layer=LSTM(128, return_sequences=True, go_backwards=True), input_shape=(maxlen,len_vocab)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Bidirectional(LSTM(32)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(2, activation='softmax', activity_regularizer=l2(0.001)))\n\nmodel.summary()","254797d0":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","22c723bd":"callback = EarlyStopping(monitor='val_loss', patience=5)\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, verbose=1, min_delta=1e-4, mode='max')","37f2b4b7":"epochs = 30\nbatch_size = 256\nhistory = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test), callbacks=[callback, reduce_lr])","4ffff8ed":"# Plot model accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Training', 'Test'])\n\nplt.show()\n\n# Plot model loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Training', 'Test'])\n\nplt.show()","828aa20c":"# References\n* [Character-Level LSTMs for Gender Classification from Name](https:\/\/maelfabien.github.io\/machinelearning\/NLP_7\/)\n* [Deep learning gender from name -LSTM Recurrent Neural Networks](https:\/\/towardsdatascience.com\/deep-learning-gender-from-name-lstm-recurrent-neural-networks-448d64553044)\n* [Choosing the right Hyperparameters for a simple LSTM using Keras](https:\/\/towardsdatascience.com\/choosing-the-right-hyperparameters-for-a-simple-lstm-using-keras-f8e9ed76f046)","920e1ba9":"# Algorithm","d60dff32":"# LSTM Model","16037fcc":"# Data Collection\nUsed \"National data\" from [the US Social Security Administration](https:\/\/www.ssa.gov\/oact\/babynames\/limits.html)."}}