{"cell_type":{"e7d28f3c":"code","da2c3d55":"code","cdc2255d":"code","d7d58581":"code","168b3ca4":"code","c4d3ecd9":"code","eb648150":"code","06c9325a":"code","d8b06088":"code","53bcac5b":"code","5782b64f":"code","0f7c6758":"code","6f9a697e":"code","e5c23fc4":"code","b40538a6":"code","124e44d9":"code","710d4592":"code","a563137f":"code","d50a5e29":"code","b8bda68a":"code","733fff62":"code","05ed98f1":"code","6f39023b":"code","26964523":"code","c2c076f4":"code","f9124574":"code","92b72c11":"code","cd0e667a":"code","6fd1b328":"code","3a2a1d16":"code","0a233d89":"code","b0c1a9e1":"code","3934aa14":"code","6cfb782c":"code","19dc1e47":"code","a4440df3":"code","8f8b26a0":"code","279f49b2":"code","f635006a":"code","d9b5e7a7":"code","4c2f2353":"code","4ccac230":"code","b561ffce":"markdown","d2f8c23a":"markdown","5eda2809":"markdown","4e54e431":"markdown","22d0202c":"markdown","ae9ed38f":"markdown","ea211a6e":"markdown","99e50d31":"markdown","3875773f":"markdown","fd37e377":"markdown","388836af":"markdown","96e86b85":"markdown","c5e7cacf":"markdown","1ec38276":"markdown","0a939f22":"markdown","9c9c4dc0":"markdown"},"source":{"e7d28f3c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport seaborn\n\nimport re\n\nfrom collections import Counter\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da2c3d55":"df = pd.read_csv('\/kaggle\/input\/data-analyst-jobs\/DataAnalyst.csv')\n\n#Dropping Unnecessary Columns\ndf = df.drop(columns=['Unnamed: 0'], axis=1)","cdc2255d":"df.info()","d7d58581":"df.head()","168b3ca4":"print('Feature\\t\\t\\tNon-Null Count')\nprint('-------                 --------------')\nfor feature in df.columns: \n    print('{}\\t{:>12}'.format(feature, df[feature][df[feature]!=-1].count()))","c4d3ecd9":"df['Company Name'].unique()","eb648150":"# Code from https:\/\/www.kaggle.com\/nerdscoding\/data-analyst-jobs-dataset-eda-with-plotly\ndf['Company Name'] = df['Company Name'].apply(lambda x: re.sub(r'\\n.*','',str(x)))","06c9325a":"df['Company Name'].unique()","d8b06088":"df[df['Rating']==-1]","53bcac5b":"df['Rating'] = df['Rating'].replace({-1: 0})","5782b64f":"for row in range(df.shape[0]): #df.shape[0]\n#     print(df.loc[row, 'Salary Estimate'])\n    lower, upper = df.loc[row, 'Salary Estimate'].split('-')\n    try: \n        upper = int(\"\".join(re.findall('\\d+', upper))) * 1000\n    except: \n        upper = 0\n    try:\n        lower = int(\"\".join(re.findall('\\d+', lower))) * 1000\n    except: \n        lower = 0\n#     print('{} {}'.format(upper, lower))\n    df.loc[row, 'Upper Salary Estimate'] = upper\n    df.loc[row, 'Lower Salary Estimate'] = lower","0f7c6758":"df['Location'].unique()","6f9a697e":"# Create new features of states and cities\ntmp_split = df['Location'].str.split(',', expand=True)\ndf['City'] = tmp_split[0]\ndf['Country\/ State'] = tmp_split[1].str.strip()","e5c23fc4":"df['Size'].unique()","b40538a6":"df['Size'] = df['Size'].replace({'-1': 'Unknown'})","124e44d9":"df['Size'].unique()","710d4592":"plt.rcParams[\"figure.figsize\"] = (20,10)\ndf['Company Name'].value_counts().sort_values(ascending=False).head(25).plot.bar()\nplt.title('Companies with the Most Jobs Offered')\nplt.show()\ndf['Company Name'].value_counts().sort_values(ascending=False).head(5)","a563137f":"# Junior data analyst\njunior_jobs = df[df['Job Title'].str.contains(r'Data Analyst', na=True) & ~df['Job Title'].str.contains(r'Senior', na=True)]\nsenior_jobs = df[df['Job Title'].str.contains(r'Senior', na=True)]","d50a5e29":"junior_jobs.shape","b8bda68a":"plt.rcParams[\"figure.figsize\"] = (10,5)\nplt.title('Level of Data Analyst Jobs')\nplt.bar(['Junior', 'Senior'], [junior_jobs.shape[0], senior_jobs.shape[0]], 0.5)\nplt.show()","733fff62":"junior_jobs['Job Description']","05ed98f1":"junior_desc = []\nfor row in junior_jobs['Job Description'].to_list(): \n    row_content = row.split()\n    row_content = [x.strip('.') for x in row_content]\n    row_content = [x.strip(',') for x in row_content]\n    for word in row_content: \n        junior_desc.append(word.lower())\n\njunior_desc_counts = Counter(junior_desc) ","6f39023b":"junior_desc_counts.most_common(20)","26964523":"stopping_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'us', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'and\/or',\n                 'including', 'include', 'job', 'using', 'ability', 'across', 'related', 'provide', 'within', 'ensure', 'use', 'may', 'must', 'one', 'perform', 'also', 'meet', 'plus', 'impact', 'making', 'take', 'used']\nstopping_words_with_first_cap = [stopping_word[0].upper() + stopping_word[1:] for stopping_word in stopping_words]\n\nfor stopping_word in stopping_words: \n    del junior_desc_counts[stopping_word]\n\nfor stopping_word in stopping_words_with_first_cap: \n    del junior_desc_counts[stopping_word]\n\npunctuations = ['\u2022', '-', '\u00b7', 'A', '&', '+', '\/', '\u2013']\nfor punctuation in punctuations: \n    del junior_desc_counts[punctuation]","c2c076f4":"junior_desc_counts.most_common(5)","f9124574":"plt.rcParams[\"figure.figsize\"] = (25,10)\nplt.title('Common Words in Junior Data Analyst Jobs')\n\nselected = junior_desc_counts.most_common(20)\nlabels = [x[0] for x in selected]\nvalues = [x[1] for x in selected]\nplt.bar(labels, values)\nplt.show()","92b72c11":"senior_desc = []\nfor row in senior_jobs['Job Description'].to_list(): \n    row_content = row.split()\n    row_content = [x.strip('.') for x in row_content]\n    row_content = [x.strip(',') for x in row_content]\n    for word in row_content: \n        senior_desc.append(word.lower())\n\nsenior_desc_counts = Counter(senior_desc) \n\nfor stopping_word in stopping_words: \n    del senior_desc_counts[stopping_word]\n\nfor stopping_word in stopping_words_with_first_cap: \n    del senior_desc_counts[stopping_word]\n\nfor punctuation in punctuations: \n    del senior_desc_counts[punctuation]","cd0e667a":"senior_desc_counts.most_common(20)","6fd1b328":"plt.rcParams[\"figure.figsize\"] = (25,10)\nplt.title('Common Words in Senior Data Analyst Jobs')\n\nselected = senior_desc_counts.most_common(20)\nlabels = [x[0] for x in selected]\nvalues = [x[1] for x in selected]\nplt.bar(labels, values)\nplt.show()","3a2a1d16":"skills_keyword = ['sql', 'excel', 'microsoft', 'python', 'analytics', 'programming', 'code', 'modeling', 'r', 'visualization'\n                  , 'statistics', 'statistical'\n                  , 'report', 'reporting', 'communication', 'documentation', 'tableau'\n                 , 'strategies', 'management']","0a233d89":"junior_skill_counts = []\nsenior_skill_counts = []\n\nfor data in skills_keyword: \n    junior_skill_counts.append(junior_desc_counts[data])\n    senior_skill_counts.append(senior_desc_counts[data])\n\n","b0c1a9e1":"plt.rcParams[\"figure.figsize\"] = (25,10)\n\nbar_width = 0.35 #Width of the bar\n\njunior_bar = plt.bar(np.arange(len(skills_keyword)), junior_skill_counts, bar_width, color='royalblue', label='Junior level')\nsenior_bar = plt.bar(np.arange(len(skills_keyword))+bar_width, senior_skill_counts, bar_width, color='seagreen', label='Senior level')\nplt.xticks(np.arange(len(skills_keyword)), skills_keyword, rotation='vertical')\n\nplt.title('Skills mentioned in Data Analysts Job Ads')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()","3934aa14":"plt.rcParams[\"figure.figsize\"] = (8,6)\nplt.boxplot([df['Lower Salary Estimate'],df['Upper Salary Estimate']], labels=['Min. Salary', 'Max. Salary'])\n\nplt.title('Salary Distribution')\nplt.show()","6cfb782c":"plt.rcParams[\"figure.figsize\"] = (30,6)\n\n# df.groupby('Industry')['Lower Salary Estimate']\ndf.boxplot(column='Lower Salary Estimate', by='Industry')\n\nplt.title('Lower Salary Estimate by Industry')\nplt.xticks(rotation='vertical')\nplt.show()","19dc1e47":"plt.rcParams[\"figure.figsize\"] = (25,6)\n\n# df.groupby('Industry')['Lower Salary Estimate']\ndf.boxplot(column='Upper Salary Estimate', by='Industry')\n\nplt.title('Upper Salary Estimate by Industry')\nplt.xticks(rotation='vertical')\nplt.show()","a4440df3":"lowest_ind = df.groupby('Industry')['Lower Salary Estimate'].mean().idxmax()\nlowest_ind_val = df.groupby('Industry')['Lower Salary Estimate'].mean().max()\nprint('The lowest expectedly paid industry is {} with ${}'.format(lowest_ind, lowest_ind_val))","8f8b26a0":"highest_ind = df.groupby('Industry')['Upper Salary Estimate'].mean().idxmax()\nhighest_ind_val = df.groupby('Industry')['Upper Salary Estimate'].mean().max()\nprint('The highest expectedly paid industry is {} with ${}'.format(highest_ind, highest_ind_val))","279f49b2":"plt.rcParams[\"figure.figsize\"] = (25,6)\n\ndf.boxplot(column='Rating', by='Industry')\n\nplt.title('Ratings by Industry')\nplt.xticks(rotation='vertical')\nplt.show()","f635006a":"print('Top 5 Average Rating by Industries')\ndf.groupby('Industry')['Rating'].mean().sort_values(ascending=False).head(5)","d9b5e7a7":"df.boxplot(column='Rating', by='Country\/ State')\n\nplt.title('Ratings by Industry')\nplt.xticks(rotation='vertical')\nplt.show()","4c2f2353":"plt.rcParams[\"figure.figsize\"] = (25,6)\n\ndf.groupby('Country\/ State')['Lower Salary Estimate'].mean().plot.bar()\n\nplt.title('Min.Expected Salary by State')\nplt.xlabel('State\/ Country')\nplt.ylabel('USD')\nplt.show()","4ccac230":"plt.rcParams[\"figure.figsize\"] = (25,6)\n\ndf.groupby('Country\/ State')['Upper Salary Estimate'].mean().plot.bar()\n\nplt.title('Max.Expected Salary by State')\nplt.xlabel('State\/ Country')\nplt.ylabel('USD')\nplt.show()","b561ffce":"We will ignore on treating missing data in founding year since we are visualising the data (instead of doing a machine learning). ","d2f8c23a":"There are couple of them are in their ratings. Let's find out why. ","5eda2809":"## Data Cleaning","4e54e431":"From the dataset it seems likely that the companies have no rating given (It is not compulsory). Given that providing 0 ratings are not common by users, we can safely assume the missing values are 0.","22d0202c":"## Industry and Salary Distribution","ae9ed38f":"Finding a data analyst job during COVID-19 pandemic? This dataset from GlassDoor was created by picklesueat. It contains more than 2000 job listing for data analyst positions. \n\nThe purpose of this notebook is to find out what are the jobs offered in the market. ","ea211a6e":"## What is the Min and Max Salary Distribution?","99e50d31":"What are the most prominent words in the description of the junior level?","3875773f":"Let's treat the missing data in company name. ","fd37e377":"### Does Location Matter?","388836af":"## Which Industry has the Best Rating?","96e86b85":"The most common words are the stopping words, we should clear them for analysis. ","c5e7cacf":"It means there are no significant difference in working in different locations. ","1ec38276":"## Visualisation","0a939f22":"### Skill Sets Needed","9c9c4dc0":"The dataset does not have missing data, but they are encoded as `'-1'`. So we need to find them out. "}}