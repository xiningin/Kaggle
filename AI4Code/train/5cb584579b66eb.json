{"cell_type":{"53b5ada9":"code","c9911069":"code","985d6b2d":"code","0253000f":"code","0a26a085":"code","9089ee5a":"code","d7840068":"code","a2dc4542":"code","b1f23ad7":"code","a66071fe":"code","e8c2e3e2":"code","452502e3":"code","eb768b10":"code","ab739a12":"code","b121757e":"code","2387da8a":"code","76c2b6dc":"code","3bf59a37":"code","d7afefed":"code","1d762982":"code","dbc159fa":"code","978b7c6f":"code","99457145":"markdown","ddfac433":"markdown","e409dbec":"markdown"},"source":{"53b5ada9":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport warnings\nwarnings.filterwarnings('ignore')","c9911069":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntrain_data.shape, test_data.shape","985d6b2d":"train_labels = train_data['label']\ndel train_data['label']\ntrain_labels.shape, train_data.shape","0253000f":"# sns.countplot(train_labels)\nlabel, count = np.unique(train_labels, return_counts = True)\nprint(train_labels.value_counts())\nprint('-'*50)\nprint('There are', train_labels.isnull().sum() ,'null values in labels')\nprint('-'*50)\nsns.barplot(label, count)","0a26a085":"# converting the data to a grayscale and 28*28 image\ntrain_data = train_data \/ 255.0\ntest_data = test_data \/ 255.0\nx_train = train_data.values.reshape(-1, 28, 28, 1)\nx_test = test_data.values.reshape(-1, 28, 28,1)","9089ee5a":"# one hot encoding labels\ny_train = to_categorical(train_labels, 10)","d7840068":"# split data to training and validation sets (validation = 10% of the data)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 1)\nx_train.shape, y_train.shape, x_val.shape, y_val.shape","a2dc4542":"fig = plt.figure(figsize = (8, 8))\nrow = 3\ncol = 4\nfor i in range(row*col):\n    fig.add_subplot(row, col, i+1)\n    plt.imshow(x_train[i][:, :, 0])\nplt.show()","b1f23ad7":"model = Sequential()\n# set 1\nmodel.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'SAME', activation = 'relu', input_shape = (28, 28, 1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'SAME', activation = 'relu'))\nmodel.add(MaxPool2D(2, 2))\nmodel.add(Dropout(0.25))\n\n# set 2\nmodel.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'SAME', activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'SAME', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = (2, 2), strides = (2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = 'relu')) # hidden later\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = 'softmax')) # output layer","a66071fe":"# optimizer = Adam(learning_rate=0.001)\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","e8c2e3e2":"# compile the model\nmodel.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])","452502e3":"# setting up an annealer\nLR_reducer = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3, verbose=1, min_lr=0.00001)","eb768b10":"# define epochs and batch size\nepochs = 30\nbatch_size = 86","ab739a12":"image_data = ImageDataGenerator(\n                featurewise_center = False,\n                samplewise_center = False,\n                featurewise_std_normalization = False,\n                samplewise_std_normalization = False,\n                zca_whitening = False,\n                rotation_range = 10,\n                width_shift_range = 0.1,\n                height_shift_range = 0.1,\n                zoom_range = 0.1,\n                horizontal_flip = False,\n                vertical_flip= False\n            )","b121757e":"# fit the training data on ImageData Generator\nimage_data.fit(x_train)","2387da8a":"# fit the model\ntrain_generator = image_data.flow(x_train, y_train, batch_size = batch_size)\ntrained_model = model.fit_generator(train_generator, epochs=epochs, validation_data=(x_val, y_val), verbose=1, steps_per_epoch=len(x_train)\/\/batch_size,\n                   callbacks=[LR_reducer])","76c2b6dc":"# printing training and validation loss and accuracy\nfig, ax = plt.subplots(2, 1)\nax[0].plot(trained_model.history['loss'], color = 'b', label = 'Training Loss')\nax[0].plot(trained_model.history['val_loss'], color = 'r', label = 'Validation Loss')\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(trained_model.history['accuracy'], color = 'b', label = 'Training Accuracy')\nax[1].plot(trained_model.history['val_accuracy'], color = 'r', label = 'Validation Accuracy')\nlegend = ax[1].legend(loc='best', shadow=True)","3bf59a37":"# printing confusion matrix\nval_pred = model.predict(x_val)\nval_pred_classes = np.argmax(val_pred, axis = 1)\nval_true_classes = np.argmax(y_val, axis = 1)\nresults = confusion_matrix(val_true_classes, val_pred_classes)\nprint(results)","d7afefed":"# printing some errorneous data\nerror_data = (val_pred_classes - val_true_classes != 0)\nerror_pred = val_pred[error_data]\nerror_pred_classes = val_pred_classes[error_data]\nerror_true = y_val[error_data]\nerror_true_classes = val_true_classes[error_data]\nerror_x_val = x_val[error_data]\nprint('Number of wrong predcitions in validation data = ', error_data.sum())\nfig = plt.figure(figsize = (8, 8))\nrow = 3\ncol = 4\nfor i in range(row*col):\n    fig.add_subplot(row, col, i+1)\n    plt.imshow(error_x_val[i][:, :, 0])\n    plt.title('Predicted Label: ' + str(error_pred_classes[i]) + '\\nTrue Label: ' + str(error_true_classes[i]))\nplt.show()","1d762982":"results = model.predict(x_test)\nresults_classes = np.argmax(results, axis = 1)","dbc159fa":"result_data = {'ImageID': [i for i in range(1, len(results_classes)+1)],\n              'Label': results_classes\n              }\nresults_df = pd.DataFrame(result_data)\nresults_df.head()","978b7c6f":"results_df.to_csv('MNIST_data_output_using_CNN_30_epochs.csv', index = False)","99457145":"### Defining CNN Model\n\n* Define a sequential model\n* \n* -----------------------------------------SET 1-------------------------------------------------\n* Layer1 => conv2D -> filters = 32, filter_size = 5*5, padding = Same, activation function = relu \n* Layer2 => conv2D -> filters = 32, filter_size = 5*5, padding = Same, activation function = relu \n* Layer3 => Maxpool Layer -> 2*2\n* Layer4 => Dropout -> prob = 0.25\n\n* -----------------------------------------SET 2-------------------------------------------------\n* Layer5 => conv2D -> filters = 64, filter_size = 3*3, padding = Same, activation function = relu \n* Layer6 => conv2D -> filters = 64, filter_size = 3*3, padding = Same, activation function = relu \n* Layer7 => Maxpool Layer -> 2 \\* 2, stride = 2 \\* 2\n* Layer8 => Dropout -> prob = 0.25\n* ----------------------------------------------------------------------------------------------- \n* Layer9 => Faltten\n* Layer10 => Dense -> filters = 256, activation = relu (hidden layer)\n* Layer11 => Dropout -> prob = 0.50\n* Layer12 => Dense -> filters = 10, activation = softmax (output layer)","ddfac433":"### Data Augmentation\n* Approaches that alter the training data in ways that change the array representation while keeping the label same are known as data augmentation techniques - grayscale, flip horizontal\/vertical, zoom, random crops, rotations, translations, etc.\n* We can increase the ammount of training data by x2 or x3 by using data augmentation techniques","e409dbec":"* We use optimizer to optimize the cost and to find the minima in most efficient way\n* ADAM vs RMSProp -> both can be compared"}}