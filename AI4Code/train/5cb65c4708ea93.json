{"cell_type":{"ce259eb1":"code","73fe9e80":"code","dc724f11":"code","6b516029":"code","55517cab":"code","ebbce467":"code","16680dcc":"code","a17cdee2":"code","2556adf6":"markdown"},"source":{"ce259eb1":"!pip install -U deep_translator\n!pip install nltk\n","73fe9e80":"# Import the following libraries into your environment\/script\n\nimport pandas as pd\nimport numpy as np\n#from deep_translator import GoogleTranslator\nimport nltk\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nimport os\nfrom nltk.tokenize import word_tokenize\n","dc724f11":"# Function to read a file, with filename\/path as input\n\ndef read_file(file):\n  try:\n    with open(file) as f:\n      lines = f.read()\n      list_lines=lines.split('\\n')\n      list_lines\n      print('')\n      print('---------------------------------')\n      print('File has been successfully read!')\n      token = 1\n      return list_lines, token\n  except Exception:\n    pass\n    print('')\n    print('---------------------------------')\n    print('File can not be read! check for correct path name or file name.....')\n    print('---------------------------------')\n    print('Run the function again ....')\n    return 4, 0\n\n","6b516029":"# Function to translate file into English language\n\ndef translate(list_lines):\n  trans_text=[]\n  print('')\n  print('')\n  print('Your files are being translated, kindly wait for a moment!')\n  print('')\n  print('--------------')\n  for i in range(0,len(list_lines)):\n      try:\n          translated = GoogleTranslator(source='auto', target='en').translate(list_lines[i])\n          #print(translated)\n          trans_text.append(translated)\n      except Exception:\n          pass\n          #print(list_lines[i])\n          trans_text.append(list_lines[i])\n  \n  return trans_text\n","55517cab":"# Code to determine if a sentence is interrogative \n\ndef question_function(sentence):\n  helpingv=['am','are','be','been','being','can','could','dare','did','do','should','would','going','had','has','have','is','may','might','must','need',\n         'ought','shall','was','were','will']\n  subjects=['JJ','JJR','JJS','NN','NNS','NNP','NNPS','PRP','PRP$']\n  Wh=['who','whom','whose','where','why','when','what','which','how']\n  count=[]\n  c=0\n  sentence = sentence.lower()\n  token = word_tokenize(sentence)\n  if(sentence.find('?')>0): # 1st Condition: If question mark is present \n    c=c+1\n    #print(c)\n  elif(token[-1]=='?'): # 2nd Condition: Ends with question mark\n    c=c+1\n    #print(c)\n  elif(token[0]=='who' or token[0]=='whom' or token[0]=='whose' or token[0]=='where'or token[0]=='why' or token[0]=='when' or token[0]=='what' or token[0]=='which' or token[0]=='how' or token[0]=='is'or token[0]=='are'):\n\n    #3rd Condition: Begins with Wh question words\n    c=c+1\n    #print(c)\n\n  else: #4th Condition: If auxiliary verb preceeds subject (mostly noun\/adjective)\n    for word in range(0,len(token)):\n      if(token[word]=='i'):\n        token[word]='I' # Converting to uppercase I because otherwise, the library doesn\u2019t consider small i to be a noun\n      else:\n        continue\n    token_tag = nltk.pos_tag(token)\n    tags=[]\n    for tag in range(0,len(token_tag)):\n      tags.append(token_tag[tag][1])\n    #print(tags)\n    for word in range(0,len(token)):\n      for verb in range(0,len(helpingv)):\n        if(token[word]==helpingv[verb]):\n          count.append(word)\n        else:\n          continue\n    #print(count)\n    for i in count:\n      for subject in subjects:\n        if(tags[i+1]==subject):\n          c=c+1\n        else:\n          continue\n\n  return c # c = 0 means it is not a question according to my algorithm\n\n  \n  \n \n  \n\n\n\n","ebbce467":"# Coverts file into final output and saves text file called solution\n\ndef file_conversion(df):\n  textfile=''\n  for sentences in df:\n    output = question_function(sentences)\n    if(output>0):\n      txt = sentences.ljust(60)+'yes'\n      print(txt)\n      textfile = textfile + '\\n' + txt  \n\n    else:\n      txt = sentences.ljust(60)+'no'\n      print(txt)\n      textfile = textfile + '\\n' + txt \n\n  file1 = open('solution.txt',\"w\") \n  file1.writelines(textfile) \n  file1.close()\n  print('')\n  print('')\n  print('Your file has been saved in the environment\/ respective root directory ')\n  print('')\n  print('')\n  ","16680dcc":"# Code to Execute Complete Problem Statement\n\ndef main_function():\n  print('Enter file name if uploaded in the environment, else enter file path:')\n  lines, token = read_file(input())\n  c=0\n  if (token==1):\n    while(c==0):\n      print('Do you want to translate your file into English if not, for better results ?')\n      print('')\n      print('1. Yes')\n      print('2. No')\n      print('')\n      print('Enter your choice (number): ---> ')\n      s=int(input())\n      print('')\n      print('')\n      if(s==1):\n        df = translate(lines)\n        print('')\n        print('Your text file has successfully been translated!')\n        print('-----------')\n        file_conversion(df)\n        c=1\n\n\n      elif(s==2):\n        print('You have chosen NOT to translate your file')\n        print('-----------')\n        print('')\n        file_conversion(lines)\n        c=1\n\n      else:\n        print('')\n        print('you have entered an invalid input')\n        print('kindly enter 1 or 2 to proceed...........')\n        print('')\n        c=0\n  else:\n    print('invalid input')","a17cdee2":"# RUN THIS BLOCK TO SEE FULL WORKING \n\nmain_function()","2556adf6":"Things to make sure:\n\n1. File should be in defined **Assignment Format**\n\n2. File should be of **.txt** extension \n\n3. Make sure file is uploaded into **the environment** (jupyter notebook, googlecolab) if path is not work. File path can easily be found out by dragging respective file in the **terminal window** of your system.\n\n4. To run this code the **below two libraries** must be installed \n\n5. Kindly execute **all functional blocks in order **\n\n6. **question_function **(sentence) can be used to execute **individual sentences** as well.\n\n***P.S.***\n\nThis script has solely been written for position of data analyst at convin and I, **Akarsh Singh**, attest this work to be of my own effort.\n\n\n"}}