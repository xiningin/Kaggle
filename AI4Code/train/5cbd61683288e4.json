{"cell_type":{"d7cd029c":"code","fa748571":"code","bd4d7b3d":"code","526a8759":"code","3095ed86":"code","910a8382":"code","1bea0a72":"code","a56263b3":"code","9e1689b5":"code","52ab14a6":"code","906dd8c9":"code","5a8c1f1e":"markdown","28f586a9":"markdown","9887d805":"markdown","f0500dba":"markdown","b1de7e70":"markdown","39e27266":"markdown","7f1dc2f0":"markdown","7e32d66f":"markdown","a40d8c62":"markdown","40170ebf":"markdown","bc50eb76":"markdown","eac395c3":"markdown","4bbd7d7a":"markdown","3aefa8d0":"markdown"},"source":{"d7cd029c":"import numpy as np, pandas as pd, time, os, gc\nfrom datetime import datetime, date \n\nfrom sklearn import *\nfrom sklearn.metrics import *\nfrom sklearn.preprocessing import LabelEncoder\n\nimport lightgbm as lgb\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n#from sklearn.metrics import accuracy_score\n#from sklearn.metrics import roc_auc_score\n#from sklearn.metrics import confusion_matrix\n#from sklearn.metrics import mean_squared_error\n#from sklearn import model_selection\n\nfrom multiprocessing import Pool\nimport seaborn as sns, matplotlib, matplotlib.pyplot as plt\n#print(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.","fa748571":"from kaggle.competitions import twosigmanews\nif 'env' not in globals():\n    env = twosigmanews.make_env()","bd4d7b3d":"inputMarketObservationFilter = [\"volume\", \"close\", \"open\", \n                                \"returnsClosePrevRaw1\", \"returnsOpenPrevRaw1\", \n                                \"returnsClosePrevMktres1\", \"returnsOpenPrevMktres1\", \n                                \"returnsClosePrevRaw10\", \"returnsOpenPrevRaw10\", \n                                \"returnsClosePrevMktres10\", \"returnsOpenPrevMktres10\"]\n\ninputNewsObservationFilter = [\"relevance\", \"sentimentNegative\", \"sentimentNeutral\", \"sentimentPositive\"]\n\nparamLagFeatures = ['returnsClosePrevMktres10','returnsClosePrevMktres1']\nparamLagFrequencies = [3,7,14]","526a8759":"def PreloadMarketTrainingRaw():\n    mandatoryColumns =  [\"time\", \"assetCode\", \"universe\", 'returnsOpenNextMktres10']\n    returnColumns = mandatoryColumns + inputMarketObservationFilter\n    marketRaw = env.get_training_data()[0][returnColumns]\n\n    #marketRaw['time'] = marketRaw.time.dt.date\n    marketRaw['volume'] = pd.to_numeric(marketRaw.volume, errors='coerce', downcast='integer')\n    marketRaw['universe'] = pd.to_numeric(marketRaw.universe, errors='coerce', downcast='integer')\n    real = {c: 'float16' for c in marketRaw.columns if c not in ['assetCode', 'time', \"volume\", \"universe\"]}\n    return marketRaw.astype(real)\n\ndef PreloadNewsTrainingRaw():\n    mandatoryColumns =  [\"time\", \"assetCodes\"]\n    returnColumns = mandatoryColumns + inputNewsObservationFilter\n    newsRaw = env.get_training_data()[1][returnColumns]\n    #newsRaw['time'] = newsRaw.time.dt.date\n    return newsRaw","3095ed86":"def ConsolidateMarket(inputMarket):\n    mandatoryColumns =  [\"time\", \"assetCode\"]\n    cols = mandatoryColumns + inputMarketObservationFilter\n    \n    # append target when available\n    if 'returnsOpenNextMktres10' in inputMarket.columns:\n        cols = cols + ['returnsOpenNextMktres10']\n    \n    output = inputMarket[cols].reset_index()\n    output['time'] = output.time.dt.date\n    \n    output['returnsClose'] = (output['close'] \/ output['open'])-1\n    #output['volume'] = pd.to_numeric(output.volume, errors='coerce', downcast='integer')\n    #output['returnsClose'] = pd.to_numeric(output.returnsClose, errors='coerce', downcast='float')\n    output.dropna(axis=0, inplace=True)\n   \n    dropColumns = [\"close\", \"open\", \"index\"]\n    output.drop(dropColumns, axis=1, inplace=True)\n\n    aggregations = ['mean']\n    gp = output.groupby(['assetCode', 'time']).agg(aggregations)\n    gp.columns = pd.Index([\"{}\".format(e[0]) for e in gp.columns.tolist()])\n    gp.reset_index(inplace=True)\n    \n    real = {c: 'float16' for c in output.columns if c not in ['assetCode', 'time', \"universe\", \"volume\"]}\n    return gp.astype(real)\n","910a8382":"# helper function to decompose assetcodes\ndef MetaBuildNewsAssetCodeIndex(inputNews):\n    codes = []\n    indexes = []\n    for i, values in inputNews['assetCodes'].iteritems():\n        explode = values.split(\", \")\n        codes.extend(explode)\n        repeat_index = [int(i)]*len(explode)\n        indexes.extend(repeat_index)\n    output = pd.DataFrame({'ID': indexes, 'assetCode': codes})\n    output[\"ID\"] = pd.to_numeric(output[\"ID\"], errors='coerce', downcast='integer')\n    del codes, indexes\n    gc.collect()\n    return output\n\n\n# denormalising assetcodes into assetCode column which serves as foreign key to market assetCode\ndef MetaBuildIndexedNews(inputNews):\n    inputNews['ID'] = inputNews.index.copy()\n    inputNews['assetCodes'] = inputNews['assetCodes'].apply(lambda x: x[1:-1].replace(\"'\", \"\"))\n    # Merge news on unstacked assets\n    output = MetaBuildNewsAssetCodeIndex(inputNews).merge(inputNews, how='left', on='ID')\n    output.drop(['ID', 'assetCodes'], axis=1, inplace=True)\n    return output\n\n\n## Comine multiple news reports for same assets on same day.\ndef MetaGroupByDay(inputNews):\n    aggregations = ['mean']\n    gp = inputNews.groupby(['assetCode', 'time']).agg(aggregations)\n    gp.columns = pd.Index([\"{}\".format(e[0]) for e in gp.columns.tolist()])\n    gp.reset_index(inplace=True)\n    # Set datatype to float16\n    real = {c: 'float16' for c in gp.columns if c not in ['assetCode', 'time', 'volume']}\n    return gp.astype(real)","1bea0a72":"# putting it all together\ndef ConsolidateNews(inputNews):\n    mandatoryColumns =  [\"time\", \"assetCodes\"]\n    cols = mandatoryColumns + inputNewsObservationFilter\n    \n    output = inputNews[cols].reset_index()\n    output['time'] = output.time.dt.date\n    \n    output[\"SentimentCoefficient\"] = (output.sentimentPositive - output.sentimentNegative) * (1-output.sentimentNeutral)\n\n    \n    dropColumns = [\"index\", \"sentimentPositive\", \"sentimentNegative\", \"sentimentNeutral\"]\n    output.drop(dropColumns, axis=1, inplace=True)\n    \n    idxn = MetaBuildIndexedNews(output)\n    output = MetaGroupByDay(idxn)\n    \n    return output\n","a56263b3":"def ConsolidateMarketNews(inputMarketRaw, inputNewsRaw):   \n        return ConsolidateMarket(inputMarketRaw).merge(ConsolidateNews(inputNewsRaw), how='left', on=['time','assetCode']).fillna(0)","9e1689b5":"### Variation 2: template processing using Sentiment\n\ndef V2Ingest(inputMarketRaw,inputNewsRaw):\n    cmn = ConsolidateMarketNews(inputMarketRaw, inputNewsRaw)\n    \n    ## enter transformationlogic here \n    cmn[\"SentimentWeighted\"] = cmn.relevance * cmn.SentimentCoefficient\n    ## adjust derived features to transformation logic\n    \n    derivedFeatures = ['returnsClose', 'returnsOpenPrevMktres10', 'SentimentWeighted']\n    \n    outputFeatureSet = cmn[derivedFeatures]\n    outputTag = [] # target label for training, assetCode for prediction\n    \n    if 'returnsOpenNextMktres10' in cmn.columns:\n        outputTag = (cmn.returnsOpenNextMktres10 >= 0).astype('int8')\n    else:\n        outputTag = cmn.assetCode\n    \n    return outputFeatureSet, outputTag\n\n# Training\nfeatureSet, target = V2Ingest(PreloadMarketTrainingRaw(), PreloadNewsTrainingRaw())\n\n#featureSet.head()\n#target.describe()\n## best parameters found.\nV2Model = LGBMClassifier(\n    objective='binary',\n    boosting='gbdt',\n    learning_rate = 0.05,\n    max_depth = 8,\n    num_leaves = 80,\n    n_estimators = 400,\n    bagging_fraction = 0.8,\n    feature_fraction = 0.9)\n    #reg_alpha = 0.2,\n    #reg_lambda = 0.4)\n    \nV2Model.fit(featureSet, target)","52ab14a6":"%%time\ndays = env.get_prediction_days()\nn_days = 0\n\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days += 1\n    print(n_days,end=' ')\n    \n    # adjust block to select VxIngest and models\n    featureSet, assetCode = V2Ingest(market_obs_df, news_obs_df)\n    preds = V2Model.predict_proba(featureSet)[:, 1] * 2 - 1\n    \n    sub = pd.DataFrame({'assetCode': assetCode, 'confidence': preds})\n    predictions_template_df = predictions_template_df.merge(sub, how='left').drop(\n        'confidenceValue', axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n\n    env.predict(predictions_template_df)\n\nprint('Prediction Complete!')","906dd8c9":"env.write_submission_file()\nprint(\"submission written\")","5a8c1f1e":"## TEST\nnraw = PreloadNewsTrainingRaw()\nnraw.head()\nnraw.info()\nmraw = PreloadMarketTrainingRaw()\nmraw.head()\nmraw.info()","28f586a9":"# Training","9887d805":"### Test\ncNews = ConsolidateNews(PreloadNewsTrainingRaw())\ncNews.head()\ncNews.info()\ndel cMarket, cNews\ngc.collect()","f0500dba":"### Variation 1: template processing using Sentiment\n\ndef V1Ingest(inputMarketRaw,inputNewsRaw):\n    cmn = ConsolidateMarketNews(inputMarketRaw, inputNewsRaw)\n    \n    ## enter transformationlogic here \n    \n    ## adjust derived features to transformation logic\n    derivedFeatures = ['returnsClose', 'returnsOpenPrevMktres10', 'returnsClosePrevMktres10', 'SentimentCoefficient']\n    \n    outputFeatureSet = cmn[derivedFeatures]\n    outputTag = [] # target label for training, assetCode for prediction\n    \n    if 'returnsOpenNextMktres10' in cmn.columns:\n        outputTag = (cmn.returnsOpenNextMktres10 >= 0).astype('int8')\n    else:\n        outputTag = cmn.assetCode\n    \n    return outputFeatureSet, outputTag\n\n# Training\nfeatureSet, target = V1Ingest(PreloadMarketTrainingRaw(), PreloadNewsTrainingRaw())\n\n#featureSet.head()\n#target.describe()\n## best parameters found.\nV1Model = LGBMClassifier(\n    objective='binary',\n    boosting='gbdt',\n    learning_rate = 0.05,\n    max_depth = 8,\n    num_leaves = 80,\n    n_estimators = 400,\n    bagging_fraction = 0.8,\n    feature_fraction = 0.9)\n    #reg_alpha = 0.2,\n    #reg_lambda = 0.4)\n    \nV1Model.fit(featureSet, target)","b1de7e70":"## Ingest Variations","39e27266":"# Prediction\n","7f1dc2f0":"## Test\nmarketNews = ConsolidateMarketNews(PreloadMarketTrainingRaw(), PreloadNewsTrainingRaw())\nmarketNews.head()\nmarketNews.info()\n","7e32d66f":"# Script Parameters","a40d8c62":"# Preload Functions\nPurpose: Save Memory","40170ebf":"## NEWS Processing","bc50eb76":"## Market Processing","eac395c3":"### TEST\n\ncMarket = ConsolidateMarket(PreloadMarketTrainingRaw())\ncMarket.head()\ncMarket.info()\n","4bbd7d7a":"### Test\nac = MetaBuildNewsAssetCodeIndex(cNews)\nac.head()\nac.info()\n\nacidx = MetaBuildNewsAssetCodeIndex(cNews)\nacidx\n\nnewsByDay = MetaGroupByDay(cMarket)\nnewsByDay.tail()\nnewsByDay.info()","3aefa8d0":"# Data Preparation Functions for Training"}}