{"cell_type":{"7199a2d8":"code","e90a6869":"code","13de0b9c":"code","4d448b12":"code","4363d84a":"code","81e007bd":"code","37dbe5d0":"code","e5b1c4a0":"code","4f80a40c":"code","9cac6770":"code","9e928fba":"code","ba878a1c":"code","5fa38c9e":"code","88aa8abd":"code","a789e40d":"code","6f4ce808":"code","2626338b":"markdown","9753edde":"markdown","8040593e":"markdown","5bca3a34":"markdown","a9afadc3":"markdown","56c842ba":"markdown","58ed0ba4":"markdown"},"source":{"7199a2d8":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","e90a6869":"data = pd.read_json('..\/input\/news-category-dataset\/News_Category_Dataset_v2.json', lines=True)","13de0b9c":"data","4d448b12":"data.info()","4363d84a":"mapping = dict(enumerate(data['category'].unique()))\nLABEL_MAPPING = {value: key for key, value in mapping.items()}\nLABEL_MAPPING","81e007bd":"NUM_CLASSES = len(LABEL_MAPPING)\nprint(\"# of classes:\", NUM_CLASSES)","37dbe5d0":"def get_sequences(texts, tokenizer, train=True, max_seq_length=0):\n    sequences = tokenizer.texts_to_sequences(texts)\n    \n    if train == True:\n        max_seq_length = np.max(list(map(lambda x: len(x), sequences)))\n    \n    sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n    \n    return sequences","e5b1c4a0":"def preprocess_inputs(df, label_mapping=None):\n    df = df.copy()\n    \n    # Use only the headline and category columns\n    df = df.loc[:, ['headline', 'category']]\n    \n    # Sample 1000 examples from each category\n    category_samples = []\n    \n    for category in df['category'].unique():\n        category_slice = df.query(\"category == @category\")\n        category_samples.append(category_slice.sample(1000, random_state=1))\n    df = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\n    \n    # Map the labels to integers\n    df['category'] = df['category'].replace(label_mapping)\n    \n    # Split df into X and y\n    y = df['category']\n    X = df['headline']\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Fit a tokenizer\n    tokenizer = Tokenizer(num_words=10000)\n    tokenizer.fit_on_texts(X_train)\n    \n    # Get sequence data\n    X_train = get_sequences(X_train, tokenizer, train=True)\n    X_test = get_sequences(X_test, tokenizer, train=False, max_seq_length=X_train.shape[1])\n    \n    return X_train, X_test, y_train, y_test","4f80a40c":"X_train, X_test, y_train, y_test = preprocess_inputs(data, label_mapping=LABEL_MAPPING)","9cac6770":"X_train.shape","9e928fba":"y_train","ba878a1c":"inputs = tf.keras.Input(shape=(X_train.shape[1],))\n\nembedding = tf.keras.layers.Embedding(\n    input_dim=10000,\n    output_dim=64\n)(inputs)\n\nflatten = tf.keras.layers.Flatten()(embedding)\n\ndense_1 = tf.keras.layers.Dense(128, activation='relu')(flatten)\ndense_2 = tf.keras.layers.Dense(128, activation='relu')(dense_1)\n\noutputs = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(dense_2)\n\n\nmodel = tf.keras.Model(inputs, outputs)\n\nprint(model.summary())\ntf.keras.utils.plot_model(model)","5fa38c9e":"model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","88aa8abd":"print(\"Test Accuracy: {:.2f}%\".format(model.evaluate(X_test, y_test, verbose=0)[1] * 100))","a789e40d":"y_pred = np.argmax(model.predict(X_test), axis=1)\n\ncm = confusion_matrix(y_test, y_pred)\nclr = classification_report(y_test, y_pred, target_names=list(LABEL_MAPPING.keys()))\n\nplt.figure(figsize=(20, 20))\nsns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)\nplt.xticks(ticks=np.arange(NUM_CLASSES) + 0.5, labels=list(LABEL_MAPPING.keys()), rotation=90)\nplt.yticks(ticks=np.arange(NUM_CLASSES) + 0.5, labels=list(LABEL_MAPPING.keys()), rotation=0)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","6f4ce808":"print(\"Classification Report:\\n----------------------\\n\", clr)","2626338b":"# Modeling","9753edde":"# Results","8040593e":"# Training","5bca3a34":"# Task for Today  \n\n***\n\n## News Category Prediction  \n\nGiven *headlines of news articles*, let's try to predict the **category** of the article.\n\nWe will use a TensorFlow\/Keras neural network with word embeddings to make our predictions.","a9afadc3":"# Getting Started","56c842ba":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/9N6CU9nFKdQ","58ed0ba4":"# Preprocessing"}}