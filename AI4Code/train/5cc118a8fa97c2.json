{"cell_type":{"3affae7a":"code","50fab565":"code","f778c9d7":"code","9c15236f":"code","0501c34f":"code","bdefd177":"code","49cfc281":"code","ee5ca79d":"code","f34957f9":"code","1b3b654a":"code","2205c229":"code","73ab081c":"code","6a904663":"code","742ce28b":"markdown","cbd12e42":"markdown","a2b2def2":"markdown","cfa10b07":"markdown","096d8075":"markdown","b72820f1":"markdown","2b17b5d4":"markdown","3c4216fd":"markdown","a8e3c5be":"markdown","80ff967a":"markdown","fb383f2f":"markdown","c2578a4f":"markdown"},"source":{"3affae7a":"import os\nimport json\nimport numpy as np\nfrom pathlib import Path\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nfrom matplotlib import animation, rc\nfrom IPython.display import HTML\n\nrc('animation', html='jshtml')\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","50fab565":"data_path = Path('\/kaggle\/input\/abstraction-and-reasoning-challenge')\ntrain_path = data_path \/ 'training'\nvalid_path = data_path \/ 'evaluation'\ntest_path = data_path \/ 'test'\n\ntrain_tasks = { task.stem: json.load(task.open()) for i, (task) in enumerate(train_path.iterdir()) } \n# asks = { task.stem: json.load(task.open()) for i, (task) in enumerate(train_path.iterdir())} \n# train_tasks['db3e9e38'] = asks['db3e9e38']\nvalid_tasks = { task.stem: json.load(task.open()) for i, (task) in enumerate(valid_path.iterdir()) } \n","f778c9d7":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n    \ndef plot_pictures(pictures, labels):\n    fig, axs = plt.subplots(1, len(pictures), figsize=(2*len(pictures),32))\n    for i, (pict, label) in enumerate(zip(pictures, labels)):\n        axs[i].imshow(np.array(pict), cmap=cmap, norm=norm)\n        axs[i].set_title(label)\n    plt.show()\n    \ndef plot_sample(sample, predict=None):\n    if predict is None:\n        plot_pictures([sample['input'], sample['output']], ['Input', 'Output'])\n    else:\n        plot_pictures([sample['input'], sample['output'], predict], ['Input', 'Output', 'Predict'])\n        \ndef inp2img(inp):\n    inp = np.array(inp)\n    img = np.full((10, inp.shape[0], inp.shape[1]), 0, dtype=np.uint8)\n    for i in range(10):\n        img[i] = (inp==i)\n    return img\n\ndef input_output_shape_is_same(task):\n    return all([np.array(el['input']).shape == np.array(el['output']).shape for el in task['train']])\n\n\ndef calk_score(task_test, predict):\n    return [int(np.equal(sample['output'], pred).all()) for sample, pred in zip(task_test, predict)]","9c15236f":"task = train_tasks[\"db3e9e38\"][\"train\"]\nfor sample in task:\n    plot_sample(sample)","0501c34f":"class CAModel(nn.Module):\n    def __init__(self, num_states):\n        super(CAModel, self).__init__()\n        self.transition = nn.Sequential(\n            nn.Conv2d(num_states, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, num_states, kernel_size=1)\n        )\n        \n    def forward(self, x, steps=1):\n        for _ in range(steps):\n            x = self.transition(torch.softmax(x, dim=1))\n        return x","bdefd177":"def solve_task(task, max_steps=10):\n    model = CAModel(10).to(device)\n    num_epochs = 100\n    criterion = nn.CrossEntropyLoss()\n    losses = np.zeros((max_steps - 1) * num_epochs)\n\n    for num_steps in range(1, max_steps):\n        optimizer = torch.optim.Adam(model.parameters(), lr=(0.1 \/ (num_steps * 2)))\n        \n        for e in range(num_epochs):\n            optimizer.zero_grad()\n            loss = 0.0\n\n            for sample in task:\n                # predict output from input\n                x = torch.from_numpy(inp2img(sample[\"input\"])).unsqueeze(0).float().to(device)\n                y = torch.tensor(sample[\"output\"]).long().unsqueeze(0).to(device)\n                y_pred = model(x, num_steps)\n                loss += criterion(y_pred, y)\n                \n                # predit output from output\n                # enforces stability after solution is reached\n                y_in = torch.from_numpy(inp2img(sample[\"output\"])).unsqueeze(0).float().to(device)\n                y_pred = model(y_in, 1) \n                loss += criterion(y_pred, y)\n\n            loss.backward()\n            optimizer.step()\n            losses[(num_steps - 1) * num_epochs + e] = loss.item()\n    return model, num_steps, losses\n                \n@torch.no_grad()\ndef predict(model, task):\n    predictions = []\n    for sample in task:\n        x = torch.from_numpy(inp2img(sample[\"input\"])).unsqueeze(0).float().to(device)\n        pred = model(x, 100).argmax(1).squeeze().cpu().numpy()\n        predictions.append(pred)\n    return predictions\n    \ntask = train_tasks[\"db3e9e38\"][\"train\"]\nmodel, num_steps, losses = solve_task(task)","49cfc281":"plt.plot(losses)","ee5ca79d":"predictions = predict(model, task)\nfor i in range(len(task)):\n    plot_sample(task[i], predictions[i])","f34957f9":"test = train_tasks[\"db3e9e38\"][\"test\"]\npredictions = predict(model, test)\nfor i in range(len(test)):\n    plot_sample(test[i], predictions[i])","1b3b654a":"def animate_solution(model, sample):\n    x = torch.from_numpy(inp2img(sample[\"input\"])).unsqueeze(0).float().to(device)\n\n    @torch.no_grad()\n    def animate(i):\n        pred = model(x, i)\n        im.set_data(pred.argmax(1).squeeze().cpu().numpy())\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(x.argmax(1).squeeze().cpu().numpy(), cmap=cmap, norm=norm)\n    return animation.FuncAnimation(fig, animate, frames=100, interval=120)\n    \nanim = animate_solution(model, train_tasks[\"db3e9e38\"][\"test\"][0])\nHTML(anim.to_jshtml())","2205c229":"def evaluate(tasks):\n    result = []\n    predictions = []\n    for idx, task in tqdm(tasks.items()):\n        if input_output_shape_is_same(task):\n            model, _, _ = solve_task(task[\"train\"])\n            pred = predict(model, task[\"test\"])\n            score = calk_score(task[\"test\"], pred)\n        else:\n            pred = [el[\"input\"] for el in task[\"test\"]]\n            score = [0] * len(task[\"test\"])\n\n        predictions.append(pred)\n        result.append(score)\n    return result, predictions","73ab081c":"train_result, train_predictions = evaluate(train_tasks)\ntrain_solved = [any(score) for score in train_result]\n\ntotal = sum([len(score) for score in train_result])\nprint(f\"solved : {sum(train_solved)} from {total} ({sum(train_solved)\/total})\")","6a904663":"for task, prediction, solved in tqdm(zip(train_tasks.values(), train_predictions, train_solved)):\n    if solved:\n        for i in range(len(task['train'])):\n            plot_sample(task['train'][i])\n            \n        for i in range(len(task['test'])):\n            plot_sample(task['test'][i], prediction[i])","742ce28b":"Fantastic! The coolest part now is that we can animate our solution to see the CA in action:","cbd12e42":"## The Model\n\nThe model consists of a single 3x3 convolutional layer, followed by a 1x1 convolutional layer, just like my last notebook. Here `num_states` represents how many values a single cell could have; in this case 10, one for each color. Down the road, we may want to add a hidden state, concatinating it to the input, then removing it from the output.\n\nThe foward pass of the model will repeatedly pass the grid state through the CA transition for `steps` number of times.","a2b2def2":"$n$ is incremented every 100 epochs, so we can see that it reaches a good solution after 3 steps (epoch 300).","cfa10b07":"## More Tasks\n\nNow that we know we can train a CA for one task, will it work on others?","096d8075":"We can see that the CA quickly gets to a solution and then stabilizes.","b72820f1":"That's all for now, thanks for reading!","2b17b5d4":"We solve many of the tasks within the training set using our Neural Cellular Automata model! I did test on the validation set as well, and it correctly solved 17 of the tasks. There are a number of ways this model could be improved. Please let me know if you'd be interested in collaboration!\n\n## Solved Tasks","3c4216fd":"## First Task: db3e9e38\n\nThe task we'll first try is relitively straight foward; given a central orange \"pillar\", form stairs of alternating blue and orange in each direction. `arseny-n` showed that this could be solved with a CA consisting of three rules.","a8e3c5be":"## Training\n\nThis \"recurrent CNN\" can be quite to difficult to train. After trying a few ideas, this seemed to be the best approach that I encountered:\n\n* For every value $n$ = $1, ..., N$:\n    1. Train the model with $n$ `steps` to produce the output from input\n    2. Train the model with 1 `steps` to produce output from output\n        * This enforces that the CA stabilizes after reaching a solution\n        \nIn this way the model will try to get as close to a solution as possible in 1 step, then try to get closer in the next step, and so on until $N$ steps. For now I will use $N = 10$ = `max_steps`. I will also set the learning rate to decay with each additional step: $LR = 0.1 \/ (n * 2) $","80ff967a":"In my [previous notebook](https:\/\/www.kaggle.com\/teddykoker\/training-cellular-automata-part-i-game-of-life) we explored how we could use a CNN to create a cellular automata (CA) by recurrently passing the state of the grid through itself. Now we'll solve one of the tasks [arseny-n](https:\/\/www.kaggle.com\/arsenynerinovsky\/cellular-automata-as-a-language-for-reasoning) solved with a hard coded CA by learning the CA instead!","fb383f2f":"It works! Now lets see if it generalized to the test question:","c2578a4f":"Now lets see if it at least correctly outputs the training set. To be save we'll give the model $n=100$ steps:"}}