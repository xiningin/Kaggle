{"cell_type":{"3e04f562":"code","f6c23f52":"code","3bb46a65":"code","fc2cbaf4":"code","92f7982c":"code","45309bfb":"code","ac89ec30":"code","5add30b6":"code","23114622":"markdown","85307a76":"markdown","e154b0ad":"markdown","3b9dad75":"markdown","f7acce67":"markdown","55263394":"markdown"},"source":{"3e04f562":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt; plt.rcdefaults()\nimport random\nimport cv2","f6c23f52":"train_data = pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/test.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/sample_submission.csv')\n\ntrain_data.rename(columns={\n    'anatom_site_general_challenge': 'area', \n    'benign_malignant': 'class',\n    'target': 'label'\n}, inplace=True)\ntrain_data.head()","3bb46a65":"print('unique patient ids: ' + str(len(train_data.patient_id.unique())))\n\nfig, axs = plt.subplots(3,2)\nplt.subplots_adjust(left=0.2, bottom=0.2, right=2, top=2.2, wspace=0.4, hspace=1)\nplt.xticks(rotation=45)\n\ntrain_data['class'].value_counts().plot(kind='bar', ax=axs[0][0],legend=True, rot=65, title='class')\ntrain_data['area'].value_counts().plot(kind='bar', ax=axs[0][1], legend=True, rot=65, title='area')\ntrain_data['age_approx'].value_counts().plot(kind='bar', ax=axs[1][1], legend=True, rot=65, title='age')\ntrain_data['diagnosis'].value_counts().plot(kind='bar', ax=axs[1][0], legend=True, rot=65, title='diagnosis')\ntrain_data['sex'].value_counts().plot(kind='bar', ax=axs[2][1], legend=True, rot=65, title='sex')\n\n\n# Since most of the values is unknown for diagnosis, generating a separate chart for non unknowns\nnon_na_diagnosis = train_data[['diagnosis']]\nnon_na_diagnosis = non_na_diagnosis[non_na_diagnosis.diagnosis != 'unknown']\n\nnon_na_diagnosis['diagnosis'].value_counts().plot(kind='bar', \n                                                  ax=axs[2][0], legend=True, rot=65, title='Known Diagnosis')\n\nfor ax in fig.axes:\n    plt.xticks(rotation=75)\n\n\nplt.show()\n","fc2cbaf4":"train_data.describe()","92f7982c":"TRAIN_IMAGES_PATH = '\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train'\ndef plot_images(dataframe, labels, image_count=6):\n    \"\"\"\n    Plots image_count random images in a subplot containing 3 columns. Note that before using this function generally,\n    please set the TRAIN_IMAGES_PATH global variable to the location where images are stored.\n    \n    Parameters\n    ----------\n    dataframe: DataFrame containing just one column which contains image names found under TRAIN_IMAGES_PATH\n    image_count: Minimum Number of images to display. Will round of to nearest multiple of 3 since images are \n                displayed in 3 columns and show those images.\n    \"\"\"\n    assert dataframe.shape[1] == 1\n    assert labels.shape[1] == 1\n    size = len(dataframe)\n    while image_count % 3 != 0:\n        image_count = image_count + 1 \n\n    image_column = dataframe.columns[0]\n    label_column = labels.columns[0]\n    row_count = (int) (image_count\/3)\n    fig, ax = plt.subplots(row_count, 3, figsize=(15,15))\n    for i in range(row_count):\n        for j in range(3):\n            index = random.randint(0, size-1)\n            tuple_index = (i, j) if row_count > 1 else j\n            img_path = TRAIN_IMAGES_PATH + '\/' + dataframe.iloc[index][image_column]\n            ax[tuple_index].imshow(cv2.imread(img_path))\n            ax[tuple_index].set_title('Image: {}, label: {}'.format(index, labels.iloc[index][label_column]))\n    fig.show()\n    \n# Sample usage\ntrain_data['image_name_jpg'] = train_data['image_name'].apply(lambda val : val + '.jpg').values\nplot_images(train_data[['image_name_jpg']], train_data[['class']], 9)\n\n# Since most of the data is benign, random selection doesn't generate any malignant observations\n# Lets pick some of them and show as well\nmalignant_data = train_data.loc[train_data['class'] == 'malignant']\nplot_images(malignant_data[['image_name_jpg']], malignant_data[['class']], 9)\n\n","45309bfb":"# Analysing what percentage of a patient's images has cancer detected if the individual is affected at least\n# in one of the image\naffected_patients = malignant_data[['patient_id']].values\n\naffected = {}\nunaffected = {}\n\nfor index, row in train_data.iterrows():\n    patient_id = row.patient_id\n    if patient_id in affected_patients:\n        if row['class'] == 'malignant':\n            if patient_id not in affected:\n                affected[patient_id] = 0\n            current_count = affected[patient_id]\n            affected[patient_id] = current_count + 1\n        else:\n            if patient_id not in unaffected:\n                unaffected[patient_id] = 0\n            current_count = unaffected[patient_id]\n            unaffected[patient_id] = current_count + 1\n\naffected_patients_ratio = pd.DataFrame(columns=['patient_id', 'affected_count', 'unaffected_count'])\n\nindex = 0\nfor key in affected:\n    patient_id = key\n    unaffected_count = unaffected[key] if key in unaffected else 0\n    affected_patients_ratio.loc[index] = [patient_id] + [affected[key]] + [unaffected_count]\n    index = index + 1\n    \n        \naffected_patients_ratio.head()","ac89ec30":"affected_patients_ratio['percentage_affected_images'] = affected_patients_ratio.apply(\n    lambda row : int(100 * row.affected_count \/ (row.affected_count + row.unaffected_count)), axis=1)\n\naffected_patients_ratio.head()","5add30b6":"affected_patients_ratio['percentage_affected_images'].value_counts(sort=False).plot(\n    kind='bar', legend=True, title='percentage', sort_columns=True)","23114622":"# Results\nFollowing top of the head conclusions can be drawn from the tabular data:\n1. Lot more \"benign\" classes than \"malignant\". Will need to oversample the malignant class during training. Try [SMOTE](https:\/\/towardsdatascience.com\/deep-learning-unbalanced-training-data-solve-it-like-this-6c528e9efea6).\n2. Lots of data for middle aged and older aged patients. This is the expectation since skin cancer is less common in young individuals.\n3. Vast proportion of the images, approx. 50% is from torso. Next steps, check if these also have a higher chance of being malignant.\n","85307a76":"Unlike most other Computer vision problems, this problem is more interesting because it has non-image features as well like \"area\", \"sex\", \"age\" and context ie. \"patient_id\".","e154b0ad":"# Summary of analysis\nThere is not enough organized information around what percentage of a patient's images are going to be malignant if at least one of the images is malignant. However, few things we can note from the plot above:\n1. A farily good proportion of affected patients have only under 10% of their images marked as malignant.\n2. There are a good proportion of patients for whom either 20%, or 25% or 33% images are marked as malignant.\n\nIn final summary, if a patient has cancer, it is not certain that most of the images are going to be marked as malignant.","3b9dad75":"# Summary of visualizing images\n1. It is hard for non-experts to infer based on images what is malignant and what is not. Might be non trivial to compute avoidable bias.\n2. For data augmentation, the following functions should be applicable.\n* Horizontal and vertical flipping.\n* Rotations to different degrees.\n* Brightness changes.\n* Zooming in.","f7acce67":"# Final key takeways\n1. When training the CNN for image classification, an oversampling technique is going to be required. The malignant class has severe under representation in the training data.\n2. Fortunately, looking at some sample images, it seems that most common data augmentation methods are going to be applicable.\n3. Contextual inference will have some value but cannot be a strong signal, ie. if a patience has cancer, doesn't necessarily imply that majority of the images are going to be marked as malignant.\n\n**I hope you can find at least little bit of information in this notebook useful, if yes please don't forget to upvote it :)**\n\nI am new to kaggle and learning, so thought of sharing this early analysis to help speed up other beginners.","55263394":"# Melanoma analysis for beginners\n[![Melanoma.jpg](attachment:Melanoma.jpg)]"}}