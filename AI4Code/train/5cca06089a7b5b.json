{"cell_type":{"5656c0c7":"code","b5c52017":"code","9fc639cf":"code","a97d3685":"code","0860e209":"code","cd0ffc96":"code","a5a957b6":"code","3246c844":"code","c206443b":"code","c9fe9177":"code","b96c90a0":"code","7e008c44":"code","d30011d1":"code","ef2f8578":"code","2d7033ac":"code","ae791486":"code","dd077aca":"code","cccf474b":"code","d65059a4":"code","d1559b48":"markdown","149e835f":"markdown","206e3f51":"markdown","511525f4":"markdown","55e6cd07":"markdown","953824e9":"markdown","7eb4d6ac":"markdown","e91ae69f":"markdown","773d3612":"markdown","c0b58c42":"markdown","011a7c46":"markdown","0ef94c1f":"markdown","8dc526b5":"markdown","35289db2":"markdown","24dfff93":"markdown","7225a690":"markdown"},"source":{"5656c0c7":"# Uncomment the command below if PyTorch is not installed\n# !conda install pytorch cpuonly -c pytorch -y","b5c52017":"import torch","9fc639cf":"# Number\n\nt1 = torch.tensor(4.)\nt1","a97d3685":"t1.dtype","0860e209":"# Vector\nt2 = torch.tensor([1., 2, 3, 4])\nt2","cd0ffc96":"# Matrix\nt3 = torch.tensor([[5., 6], \n                   [7, 8], \n                   [9, 10]])\nt3","a5a957b6":"# 3-dimensional array\nt4 = torch.tensor([\n    [[11, 12, 13], \n     [13, 14, 15]], \n    [[15, 16, 17], \n     [17, 18, 19.]]])\nt4","3246c844":"print(t1)\nt1.shape","c206443b":"print(t2)\nt2.shape","c9fe9177":"print(t3)\nt3.shape","b96c90a0":"print(t4)\nt4.shape","7e008c44":"# Create tensors.\nx = torch.tensor(3.)\nw = torch.tensor(4., requires_grad=True)\nb = torch.tensor(5., requires_grad=True)\nx, w, b","d30011d1":"# Arithmetic operations\ny = w * x + b\ny","ef2f8578":"# Compute derivatives\ny.backward()","2d7033ac":"# Display gradients\nprint('dy\/dx:', x.grad)\nprint('dy\/dw:', w.grad)\nprint('dy\/db:', b.grad)","ae791486":"import numpy as np\n\nx = np.array([[1, 2], [3, 4.]])\nx","dd077aca":"# Convert the numpy array to a torch tensor.\ny = torch.from_numpy(x)\ny","cccf474b":"x.dtype, y.dtype","d65059a4":"# Convert a torch tensor to a numpy array\nz = y.numpy()\nz","d1559b48":"# **Tensors**\n\nAt its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix or any n-dimensional array. Let's create a tensor with a single number:","149e835f":"As expected, dy\/dw has the same value as x i.e. 3, and dy\/db has the value 1. Note that x.grad is None, because x doesn't have requires_grad set to True.\n\nThe \"grad\" in w.grad stands for gradient, which is another term for derivative, used mainly when dealing with matrices.","206e3f51":"Here's how we create an array in Numpy:","511525f4":"Tensors can have any number of dimensions, and different lengths along each dimension. We can inspect the length along each dimension using the .shape property of a tensor.","55e6cd07":"# Interoperability with Numpy\n\n**Numpy** is a popular open source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays, and has a large ecosystem of supporting libraries:\n\n* **Matplotlib** for plotting and visualization\n* **OpenCV** for image and video processing\n* **Pandas** for file I\/O and data analysis\n\nInstead of reinventing the wheel, PyTorch interoperates really well with Numpy to leverage its existing ecosystem of tools and libraries.","953824e9":"Let's try creating slightly more complex tensors:","7eb4d6ac":"We can convert a PyTorch tensor to a Numpy array using the .numpy method of a tensor.","e91ae69f":"As expected, y is a tensor with the value 3 * 4 + 5 = 17. What makes PyTorch special is that we can automatically compute the derivative of y w.r.t. the tensors that have requires_grad set to True i.e. w and b. To compute the derivatives, we can call the .backward method on our result y.","773d3612":"(4.) is a shorthand for (4.0). It is used to indicate to Python (and PyTorch) that you want to create a floating point number. We can verify this by checking the dtype attribute of our tensor:","c0b58c42":"The interoperability between PyTorch and Numpy is really important because most datasets you'll work with will likely be read and preprocessed as Numpy arrays","011a7c46":"# Tensor operations and gradients\nWe can combine tensors with the usual arithmetic operations. Let's look an example:","0ef94c1f":"The derivates of y w.r.t the input tensors are stored in the .grad property of the respective tensors.","8dc526b5":"Let's verify that the numpy array and torch tensor have similar data types.","35289db2":"We've created 3 tensors x, w and b, all numbers. w and b have an additional parameter requires_grad set to True. We'll see what it does in just a moment.\n\nLet's create a new tensor y by combining these tensors:","24dfff93":"We can convert a Numpy array to a PyTorch tensor using torch.from_numpy.","7225a690":"# Further Reading\n\nTensors in PyTorch support a variety of operations, and what we've covered here is by no means exhaustive. You can learn more about tensors and tensor operations here: https:\/\/pytorch.org\/docs\/stable\/tensors.html\n\nYou can take advantage of the interactive Jupyter environment to experiment with tensors and try different combinations of operations discussed above. Here are some things to try out:\n\nWhat if one or more x, w or b were matrices, instead of numbers, in the above example? What would the result y and the gradients w.grad and b.grad look like in this case?\n\nWhat if y was a matrix created using torch.tensor, with each element of the matrix expressed as a combination of numeric tensors x, w and b?\n\nWhat if we had a chain of operations instead of just one i.e. y = x * w + b, z = l * y + m, w = c * z + d and so on? What would calling w.grad do?\n\nIf you're interested, you can learn more about matrix derivates on Wikipedia (although it's not necessary for following along with this series of tutorials): https:\/\/en.wikipedia.org\/wiki\/Matrix_calculus #Derivatives_with_matrices"}}