{"cell_type":{"730b9dd1":"code","8326039a":"code","69ff78f4":"code","59e4b907":"code","8abbe7d1":"code","ffa2a156":"code","5976fd72":"code","ebb8f0a5":"code","d988aac5":"code","58c2d838":"code","c610d030":"code","d8fb0409":"markdown"},"source":{"730b9dd1":"import os\nimport sys\nos.listdir('..\/input\/segmentations-models-pytorch-7fa1020')\n\n!pip install --no-deps ..\/input\/segmentations-models-pytorch-7fa1020\/pretrainedmodels-0.7.4-py3-none-any.whl\n!pip install --no-deps ..\/input\/segmentations-models-pytorch-7fa1020\/segmentation_models_pytorch-0.0.1-py3-none-any.whl","8326039a":"import pdb\nimport os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset\nfrom albumentations import (Normalize, Compose)\nfrom albumentations.torch import ToTensor\nimport torch.utils.data as data\n\nfrom segmentation_models_pytorch import Unet, FPN, PSPNet","69ff78f4":"sample_submission_path = '..\/input\/severstal-steel-defect-detection\/sample_submission.csv'\ntest_data_folder = \"..\/input\/severstal-steel-defect-detection\/test_images\"\n\npath_to_model = '..\/input\/check-fpn-resnet34\/\/model_fpn_test_0.pth'\n\ndevice = torch.device(\"cuda\")","59e4b907":"SEED = 1322\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\n\ntorch.cuda.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\n# torch.backends.cudnn.enabled = False \n# torch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True","8abbe7d1":"#https:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","ffa2a156":"class TestDataset(Dataset):\n    '''Dataset for test prediction'''\n    def __init__(self, root, df, mean, std):\n        self.root = root\n        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n        self.fnames = df['ImageId'].unique().tolist()\n        self.num_samples = len(self.fnames)\n        self.transform = Compose(\n            [\n                Normalize(mean=mean, std=std, p=1),\n                ToTensor(),\n            ]\n        )\n\n    def __getitem__(self, idx):\n        fname = self.fnames[idx]\n        path = os.path.join(self.root, fname)\n        image = cv2.imread(path)\n        images = self.transform(image=image)[\"image\"]\n        return fname, images\n\n    def __len__(self):\n        return self.num_samples","5976fd72":"def post_process(probability, threshold, min_size):\n    '''Post processing of each predicted mask, components with lesser number of pixels\n    than `min_size` are ignored'''\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((256, 1600), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n            \n    return predictions, num","ebb8f0a5":"# initialize test dataloader\nnum_workers = 2\nbatch_size = 4\n\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n\ndf = pd.read_csv(sample_submission_path)\n\ntestset = DataLoader(\n    TestDataset(test_data_folder, df, mean, std),\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True\n)","d988aac5":"# Initialize mode and load trained weights\ndef load_fpn_model(path_to_model):\n    device = torch.device(\"cuda\")\n    model = FPN(\"resnet34\", encoder_weights=None, classes=4, activation=None)\n    model.to(device)\n    model.eval()\n    state = torch.load(path_to_model, map_location=lambda storage, loc: storage)\n    model.load_state_dict(state[\"state_dict\"])\n    \n    return model","58c2d838":"thres = 0.5\nmin_size = 2000\n\nmodel = load_fpn_model(path_to_model)\npredictions = []\n\nfor i, batch in enumerate(tqdm(testset)):\n    fnames, images = batch\n    \n    batch_preds = torch.sigmoid(model(images.to(device)))\n    batch_preds = batch_preds.detach().cpu().numpy()\n    \n    for fname, preds in zip(fnames, batch_preds):\n        for cls, pred in enumerate(preds):\n            pred, num = post_process(pred, thres, min_size)\n            rle = mask2rle(pred)\n            name = fname + f\"_{cls+1}\"\n            predictions.append([name, rle])\n\n# save predictions to submission.csv\ndf = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\ndf.to_csv(\"submission.csv\", index=False)","c610d030":"df.head(100)","d8fb0409":"This kernel uses slightly modified code (commented torchnet usage) of the [segmentation models pytorch repo](https:\/\/github.com\/qubvel\/segmentation_models.pytorch) (head is 7fa1020) which is enough for inference using your custom weights. Have tested it with Unet and FPN. \n\nBase version of this kernel is this [one](https:\/\/www.kaggle.com\/feifanliang\/unet-pytorch-inference-kernel).\n\nThis version evaluates some my weights of the FPN with resnet34 encoder."}}