{"cell_type":{"4a368ed7":"code","7f2aef7a":"code","7b86786b":"code","ddf03567":"code","65d0d5da":"code","9bc5d509":"code","9a6b0f33":"code","bc6c4614":"code","39c3f33c":"code","4013965b":"code","49d9e1f3":"code","2a73524b":"code","e38e7b52":"code","dda3cb36":"code","0bb55b2f":"code","22362450":"code","5ea9ef1d":"code","804d3de8":"code","20a1234e":"markdown","ae5fdf8c":"markdown","9bb5881e":"markdown","6f7918c7":"markdown","c4ab982d":"markdown","628f4b04":"markdown","8b8d51d7":"markdown","b1f68c23":"markdown","b05e1670":"markdown","0d6ab3f6":"markdown","c1210b44":"markdown","d260d0ab":"markdown","4bb8c2af":"markdown","ae73e498":"markdown","ae46bdbd":"markdown","c8a4b1f9":"markdown","951f7d22":"markdown"},"source":{"4a368ed7":"# Ignore Warnings.\nimport warnings\nwarnings.filterwarnings(\"ignore\")","7f2aef7a":"# Status can be the following types:\n# TD \u2013 Tropical cyclone of tropical depression intensity (< 34 knots)\n# TS \u2013 Tropical cyclone of tropical storm intensity (34-63 knots)\n# HU \u2013 Tropical cyclone of hurricane intensity (> 64 knots)\n# EX \u2013 Extratropical cyclone (of any intensity)\n# SD \u2013 Subtropical cyclone of subtropical depression intensity (< 34 knots)\n# SS \u2013 Subtropical cyclone of subtropical storm intensity (> 34 knots)\n# LO \u2013 A low that is neither a tropical cyclone, a subtropical cyclone, nor an extratropical cyclone (of any intensity)\n# WV \u2013 Tropical Wave (of any intensity)\n# DB \u2013 Disturbance (of any intensity)","7b86786b":"\n# Import the libraries.\n\n# Import pandas.\nimport pandas as pd\n# Import numpy.\nimport numpy as np\n# Import matplotlib.\nimport matplotlib.pyplot as plt\n# Import seaborn.\nimport seaborn as sns\n# Import regular expression.\nimport re\n# import datetime.\nimport datetime as dt\n# Import the data.\ndf = pd.read_csv('\/kaggle\/input\/hurricane-database\/pacific.csv')\n# Convert date column as datetime.\ndf['Date'] = pd.to_datetime(df['Date'] , format= '%Y%m%d')\n\n# I want to create columns Latitude Hemisphere and Longitude Hemisphere with code 0 = N , 1 = S & 0 = E , 1 = W.\ndef hemisphere(coord):\n        hem = re.findall(r'[NSWE]' , coord)[0]\n        if hem == 'N' or hem == 'E':\n            return 0\n        else:\n            return 1\n\n# Creating the column Latitude_Hemisphere.    \ndf['Latitude_Hemisphere'] = df['Latitude'].apply(hemisphere)\ndf['Longitude_Hemisphere'] = df['Longitude'].apply(hemisphere)\ndf['Latitude_Hemisphere'] = df['Latitude_Hemisphere'].astype('category')\ndf['Longitude_Hemisphere'] = df['Longitude_Hemisphere'].astype('category')\n\n# Convert the latitude and longitude Column to numeric type.\ndf['Latitude'] =  df['Latitude'].apply(lambda x: re.match('[0-9]{1,3}.[0-9]{0,1}' , x)[0])\ndf['Longitude'] =   df['Longitude'].apply(lambda x: re.match('[0-9]{1,3}.[0-9]{0,1}' , x)[0])\n\n# The missing values are given by -999. So , we need to fill them appropriately.\n\n# Show the count of missing values and fill them with mean.\nfor column in df.columns:\n    missing_cnt = df[column][df[column] == -999].count()\n    print('Missing Values in column {col} = '.format(col = column) , missing_cnt )\n    if missing_cnt!= 0:\n#         print('in ' , column)\n        mean = round(df[column][df[column] != -999 ].mean())\n#         print(\"mean\",mean)\n        index = df.loc[df[column] == -999 , column].index\n#         print(\"index\" , index )\n        df.loc[df[column] == -999 , column] = mean\n#         print(df.loc[index , column])\n        \n# Restructure the dataframe for visibility and remove columns ID and Event.        \ndf =  df[['ID', 'Name', 'Date', 'Time', 'Event', 'Status', 'Latitude', 'Latitude_Hemisphere' , \n       'Longitude', 'Longitude_Hemisphere' ,'Maximum Wind', 'Minimum Pressure', 'Low Wind NE',\n       'Low Wind SE', 'Low Wind SW', 'Low Wind NW', 'Moderate Wind NE',\n       'Moderate Wind SE', 'Moderate Wind SW', 'Moderate Wind NW',\n       'High Wind NE', 'High Wind SE', 'High Wind SW', 'High Wind NW']]\n\n# Change all time to format HHMM.\ndf['Time'] = df['Time'].astype('object')\ndef hhmm(time):\n    time = str(time)\n    digits = re.findall(r'\\d', time)\n    t = ''\n    if len(digits) == 1:\n        t ='0{i}00'.format(i =time)\n    elif len(digits) == 2:\n        t = '{i}00'.format(i =time)\n    elif len(digits) == 3:\n        t = '0{i}'.format(i =time)\n    else:\n        t = time\n    return t\n# Apply the function.\ndf['Time'] = df['Time'].apply(hhmm)\n\n# Convert the column into Datetime.\ndf['Time'] = pd.to_datetime(df['Time'] , format='%H%M').dt.time\n\n\n# Convert the status column to categorical.\ndf['Status'] = df['Status'].astype('category')\n\ndata = df.drop(columns = ['ID' , 'Event'])","ddf03567":"# Display the data.\ndata.head(10)","65d0d5da":"# Find the top ten cyclones which have occured the maximum number of times.\nlst = [x.strip() for x in data.groupby('Name').count().sort_values(by = 'Date' , ascending = False).index[:10]]\nval = data.groupby('Name').count().sort_values(by = 'Date' , ascending = False)[:10]['Date'].values\nfont = {'family' : 'monospace',\n        'weight' : 'bold',\n        'size'   : 22}\nplt.rc('font', **font)\nfig , ax = plt.subplots()\nfig.set_size_inches(12,12)\nax.pie(  labels = lst , x = val , autopct='%.1f%%' , explode = [0.1 for x in range(10)])\nplt.title(' Top Ten Hurricanes by Frequency.' , fontsize = 30)\nplt.show()","9bc5d509":"data['Month'] = data['Date'].apply(lambda x: x.month)\ndata['Year'] = data['Date'].apply(lambda x: x.year)\nmnt = ['Jan' , 'Feb' , 'Mar' , 'Apr' , 'May' , 'June' , 'July' , 'Aug' , 'Sep','Oct' , 'Nov' , 'Dec']\ntemp = data.groupby('Month').count()\ntemp.loc[4] = 0\ntemp = temp.sort_values(by = 'Month' , ascending = False)\nfont = {'family' : 'monospace',\n        'weight' : 'bold',\n        'size'   : 22}\nplt.rc('font', **font)\nplt.figure(figsize = (10,10))\nsns.set_style(\"whitegrid\")\nax = sns.barplot(x = temp.index , y = 'Date' , data=temp , palette = 'RdBu' )\nplt.xticks([0,1,2,3,4,5,6,7,8,9,10,11] , mnt , rotation = 90)\nplt.ylabel('Frequency')\nplt.title('Frequency of Cyclones by Month.')","9a6b0f33":"# Year-Wise Frequency of Hurricanes.\ntemp = data.groupby('Year').count().sort_values(by = 'Month' , ascending = False)\nplt.figure(figsize= (12,12))\nsns.lineplot(x = temp.index , y = 'Month' , data = temp , label = 'Frequency')\nplt.ylabel('Frequency')\nplt.title('Year Wise Frequency of Hurricanes.')\nplt.show()","bc6c4614":"# Probability Distribution Function of Frequency.\ntemp = data.groupby('Year').count().sort_values(by = 'Date' , ascending = False)\nplt.figure(figsize=(15,15))\nsns.distplot(temp['Date'].values , norm_hist = True , axlabel = 'Probability Distribution of Frequency of Cyclones.')","39c3f33c":"## Frequency of Cyclones by Category\n# TD \u2013 Tropical cyclone of tropical depression intensity (< 34 knots)\n# TS \u2013 Tropical cyclone of tropical storm intensity (34-63 knots)\n# HU \u2013 Tropical cyclone of hurricane intensity (> 64 knots)\n# EX \u2013 Extratropical cyclone (of any intensity)\n# SD \u2013 Subtropical cyclone of subtropical depression intensity (< 34 knots)\n# SS \u2013 Subtropical cyclone of subtropical storm intensity (> 34 knots)\n# LO \u2013 A low that is neither a tropical cyclone, a subtropical cyclone, nor an extratropical cyclone (of any intensity)\n# WV \u2013 Tropical Wave (of any intensity)\n# DB \u2013 Disturbance (of any intensity)\ntemp = data.groupby('Status').count().sort_values(by = 'Date' , ascending = False)\nfig , ax = plt.subplots()\nfig.set_size_inches(12,12)\nsns.barplot(y = list(temp.index) , x = 'Date' , data = temp, palette= 'pastel' )\nplt.xlabel('Frequency')\nplt.ylabel('Catehory')\nplt.title('Category wise Frequency Distribution of Cyclones.')\nplt.show()\n","4013965b":"# Import Decision Tree Classifier.\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Import train-test split.\nfrom sklearn.model_selection import train_test_split\n\n# Import accuracy Score.\nfrom sklearn.metrics import accuracy_score\n\n#Import Recall Score.\nfrom sklearn.metrics import recall_score \n\n#Import Precision Score.\nfrom sklearn.metrics import precision_score \n\n# Form the model.\ndt = DecisionTreeClassifier(min_samples_leaf=50 , criterion='entropy')\n\n\n# Set the dependent and independent variables.\nx_train = data[['Latitude', 'Latitude_Hemisphere',\n       'Longitude', 'Longitude_Hemisphere', 'Maximum Wind', 'Minimum Pressure',\n       'Low Wind NE', 'Low Wind SE', 'Low Wind SW', 'Low Wind NW',\n       'Moderate Wind NE', 'Moderate Wind SE', 'Moderate Wind SW',\n       'Moderate Wind NW', 'High Wind NE', 'High Wind SE', 'High Wind SW',\n       'High Wind NW' , 'Month' , 'Year']]\ny_train = data['Status']\n\n\n# Perform the Kfold validation.\n\n# Import the KFold library.\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=10 , shuffle= True , random_state=42 )\n\ndt_scores = []\ndt_recall_scores = []\ndt_precision_scores = []\nfor tr , ts in kf.split(x_train):\n    xtr = x_train.loc[tr]\n    ytr = y_train.loc[tr]\n    xts = x_train.loc[ts]\n    yts = y_train.loc[ts]\n    dt.fit(xtr , ytr)\n    y_pred = dt.predict(xts) \n    dt_scores.append(accuracy_score(yts, y_pred)) \n    dt_recall_scores.append(recall_score(yts , y_pred , average = 'weighted'))\n    dt_precision_scores.append(precision_score(yts , y_pred , average = 'weighted'))\n# dt.fit(x_train, y_train)\n# y_pred = dt.predict(x_test)\n# accuracy_score(y_test, y_pred)\ndt_scr = {'accuracy' : np.mean(dt_scores) , 'recall': np.mean(dt_recall_scores) , 'precision' :  np.mean(dt_precision_scores) }\nprint('Accuracy score for Decision Tree is :' , dt_scr['accuracy'])\nprint('Recall score for Decision Tree is :' , dt_scr['recall'])\nprint('Precision score for Decision Tree is :' , dt_scr['precision'])\n\n","49d9e1f3":"# Import Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\n# First I want to determine the important features.\nrf = RandomForestClassifier(oob_score=True , n_estimators=1000)\nrf.fit(x_train , y_train)\nfeatures = pd.Series(rf.feature_importances_ , index= x_train.columns).sort_values(ascending=False)\nfeatures","2a73524b":"# Top ten most important features.\nfeatures.index[:5]","e38e7b52":"# Set the dependent and independent variables.\nx_trainf = data[features.index[:5]]\ny_train = data['Status']\n\n# Perform the Kfold validation.\n\n# Import the KFold library.\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=10 , shuffle= True , random_state=42 )\n\ndt_scores = []\ndt_recall_scores = []\ndt_precision_scores = []\nfor tr , ts in kf.split(x_trainf):\n    xtr = x_trainf.loc[tr]\n    ytr = y_train.loc[tr]\n    xts = x_trainf.loc[ts]\n    yts = y_train.loc[ts]\n    dt.fit(xtr , ytr)\n    y_pred = dt.predict(xts) \n    dt_scores.append(accuracy_score(yts, y_pred)) \n    dt_recall_scores.append(recall_score(yts , y_pred , average = 'weighted'))\n    dt_precision_scores.append(precision_score(yts , y_pred , average = 'weighted'))\n# dt.fit(x_train, y_train)\n# y_pred = dt.predict(x_test)\n# accuracy_score(y_test, y_pred)\ndt_scr5 = {'accuracy' : np.mean(dt_scores) , 'recall': np.mean(dt_recall_scores) , 'precision' :  np.mean(dt_precision_scores) }\nprint('Accuracy score for Decision Tree is :' , dt_scr['accuracy'])\nprint('Recall score for Decision Tree is :' , dt_scr['recall'])\nprint('Precision score for Decision Tree is :' , dt_scr['precision'])","dda3cb36":"# Here instead of cross validation we will be using oob score as a measure of accuracy.\n# I will hyper tuning the parameter: No of Trees.\n\ntrees  = [10, 20 , 50, 100,200,500,1000,1200]\nmaxn_five = {}\nmaxn = {}\nfor i in trees:\n    rf = RandomForestClassifier(n_estimators=i , oob_score=True)\n    rf.fit(x_trainf , y_train)\n    print('Obb Score for {x} trees: and taking top five features '.format(x = i) , rf.oob_score_)\n    maxn_five[i] = rf.oob_score_\n    rf.fit(x_trainf , y_train)\n    print('Obb Score for {x} trees: and taking all the features '.format(x = i) , rf.oob_score_)\n    maxn[i] = rf.oob_score_","0bb55b2f":"# Split the data into training and testing.\nx_trains , x_tests , y_trains, y_tests  = train_test_split(x_trainf, y_train, test_size=0.33, random_state=42)\n# Set n to the feature of maximum oob score.\nn = 0\nfor i in maxn_five:\n    if max(maxn_five.values()) == maxn_five[i]:\n        n= i\n# Set n_estimators to n.\nrf = RandomForestClassifier(oob_score=True , n_estimators=n)\nrf.fit(x_trains , y_trains)\ny_pred_rf = rf.predict(x_tests[features.index[:5]])\nscores_rf = {'accuracy': accuracy_score(y_tests , y_pred_rf) ,'recall' : recall_score(y_tests , y_pred_rf , average='weighted') ,'precision' : precision_score(y_tests , y_pred_rf , average='weighted') }\nprint('Scores for Random Forest with n = ' , n , ' and using features ',  features.index[:5] , ' are : ')\nprint('Accuracy: ' , scores_rf['accuracy'])\nprint('Recall: ' , scores_rf['recall'])\nprint('Precision: ' , scores_rf['precision'])\n\n# n_All = 0\n# for i in maxn:\n#     if max(maxn.values()) == maxn[i]:\n#         n_All= i\n# # Set n_estimators to n.\n# rf = RandomForestClassifier(oob_score=True , n_estimators=n_All)\n# rf.fit(x_train , y_train)\n# y_pred_rf_all = rf.predict(x_test)\n# scores_rf_all = {'accuracy': accuracy_score(y_test , y_pred_rf) ,'recall' : recall_score(y_test , y_pred_rf , average='weighted') ,'precision' : precision_score(y_test , y_pred_rf , average='weighted') }\n# print('Scores for Random Forest with n = ' , n_All , ' and using all features ' , ' are : ')\n# print('Accuracy: ' , scores_rf_all['accuracy'])\n# print('Recall: ' , scores_rf_all['recall'])\n# print('Precision: ' , scores_rf_all['precision'])","22362450":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb5 = GaussianNB()\nacc_s = [] \nrcl_s = [] \nps_scr = []\nacc_s_5 = [] \nrcl_s_5 = [] \nps_scr_5 = []\nfor tr, ts in kf.split(x_train):\n    xtr = x_train.loc[tr]\n    ytr = y_train.loc[tr]\n    xts = x_train.loc[ts]\n    yts = y_train.loc[ts]\n    xtr5 = x_trainf.loc[tr]\n    xts5 = x_trainf.loc[ts]\n\n    \n    # Accuracy , Precision and recall with all features.\n   \n    nb.fit(xtr , ytr)\n    y_nb_pred = nb.predict(xts)\n    acc_s.append(accuracy_score(yts , y_nb_pred))\n    rcl_s.append(recall_score(yts , y_nb_pred , average = 'weighted'))\n    ps_scr.append(precision_score(yts , y_nb_pred , average = 'weighted'))\n    \n#     Accuracy , Precision and recall with top five features.\n    nb5.fit(xtr5 , ytr)\n    y_nb5_pred = nb5.predict(xts5)\n    acc_s_5.append(accuracy_score(yts , y_nb5_pred))\n    rcl_s_5.append(recall_score(yts , y_nb5_pred , average = 'weighted'))\n    ps_scr_5.append(precision_score(yts , y_nb5_pred , average = 'weighted'))\n    \nnb_scores = {'accuracy':np.mean(acc_s) , 'recall':np.mean(rcl_s) , 'precision':np.mean(ps_scr)}\nnb5_scores = {'accuracy':np.mean(acc_s_5) , 'recall':np.mean(rcl_s_5) , 'precision':np.mean(ps_scr_5)}\nprint('Naive Bayes results for top five features for Accuracy ' , nb5_scores['accuracy'] , 'Recall: ' , nb5_scores['recall'], 'and Precision: ' , nb5_scores['precision'] )\nprint('Naive Bayes results for all features for Accuracy ' , nb_scores['accuracy'] , 'Recall: ' , nb_scores['recall'], 'and Precision: ' , nb_scores['precision'] )","5ea9ef1d":"# Import SVM.\nfrom sklearn import svm\nmdl5 = svm.SVC()\nacc_s_5 = [] \nrcl_s_5 = [] \nps_scr_5 = []\n\n# Split the data into train and test.\nxtr5, xts5 , ytr , yts = train_test_split(x_trainf , y_train , test_size = 0.25 , random_state = 42)\n\n# Train the model.\nmdl5.fit(xtr5 , ytr)\ny_mdl5_pred = nb5.predict(xts5)\nacc_s_5.append(accuracy_score(yts , y_mdl5_pred))\nrcl_s_5.append(recall_score(yts , y_mdl5_pred , average = 'weighted'))\nps_scr_5.append(precision_score(yts , y_mdl5_pred , average = 'weighted'))\n\n# for tr, ts in kf.split(x_train):\n#     ytr = y_train.loc[tr]\n#     yts = y_train.loc[ts]\n#     xtr5 = x_trainf.loc[tr]\n#     xts5 = x_trainf.loc[ts]\n\n# #   Accuracy , Precision and recall with top five features.\n#     mdl5.fit(xtr5 , ytr)\n#     y_mdl5_pred = nb5.predict(xts5)\n#     acc_s_5.append(accuracy_score(yts , y_mdl5_pred))\n#     rcl_s_5.append(recall_score(yts , y_mdl5_pred , average = 'weighted'))\n#     ps_scr_5.append(precision_score(yts , y_mdl5_pred , average = 'weighted'))\n    \nsvm_scores = {'accuracy':np.mean(acc_s_5) , 'recall':np.mean(rcl_s_5) , 'precision':np.mean(ps_scr_5)}\nprint('SVM results for top five features for Accuracy ' , svm_scores['accuracy'] , 'Recall: ' , svm_scores['recall'], 'and Precision: ' , svm_scores['precision'] )\n","804d3de8":"## Comparing the algorithms.\nres = {'DecisionTree':dt_scr5['accuracy'] , 'RandomForest': scores_rf['accuracy'] , 'GaussianNB': nb5_scores['accuracy'] , 'SVM':svm_scores['accuracy']}\nmax_res = max(res.values())\nmax_index = ''\nfor i in res:\n    if res[i] == max_res:\n        max_index = i\nprint('The most effictive algorithm is :' , max_index , 'with accuracy: ' , res[max_index])        \n","20a1234e":"### We can see that the overall score with top five features is significantly greater than the overall score with all the features. Hence , we can see that feature selection is very important for Naive Bayes.","ae5fdf8c":"## 1. Decision Tree.","9bb5881e":"## Clean the data.","6f7918c7":"## 3. Naive Bayes Algorithm.","c4ab982d":"## As we can see the Top five features('Maximum Wind', 'Minimum Pressure', 'Latitude', 'Year', 'Longitude') give the same accuracy as when we get choosing all the features.","628f4b04":"## Creating a decision tree for top ten most important features.","8b8d51d7":"## Frequency of Hurricanes by Month.","b1f68c23":"## 2 . Random Forest","b05e1670":"## Year Wise Frequency of Hurricanes.","0d6ab3f6":"### We can see that the overall score with top five features is significantly greater than the overall score with all the features. Hence , we can see that feature selection is very important for SVM.","c1210b44":"## Top ten cyclones which occured the maximum number of times.","d260d0ab":"## Frequency of Cyclones by category.","4bb8c2af":"## 4. Support Vector Algorithm.","ae73e498":"## 2. Random Forest.","ae46bdbd":" # Classification model. ","c8a4b1f9":"# Hurricans and Typhoons Classification.\n\n## Objectives:\n1. Clean the data.\n2. Statistical Analysis of data.\n - *Find Top ten hurricanes by frequency.*\n - *Find frequency of hurricanes by month.*\n - *Find frequency of hurricanes by year.*\n - *Find frequency of hurricanes by category.*\n3. Classification into Hurricanes or Typhoons using Logistic Regression, Decision Tree, Random Forrest , Naive Bayes and SVM.\n - *Perform Feature selection using Random Forest.* \n - *Compare the prediction by Decision Tree Model performance using all the features and top five features.* \n - *Find the prediction accuracy of Random Forest Model model using the top five features.* \n - *Compare the prediction by Naive Bayes Model performance using all the features and top five features.* \n - *Find the prediction accuracy of SVM model using the top five features.* \n - *Show which model has performed the best.* ","951f7d22":"## Statististical Analysis of the data."}}