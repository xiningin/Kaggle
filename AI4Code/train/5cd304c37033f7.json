{"cell_type":{"3e3e2ad4":"code","0546af97":"code","9964a08e":"code","8d268374":"code","0117c11f":"code","f724d418":"code","7af79a8c":"markdown","15192aeb":"markdown","ecacb286":"markdown","74eec08e":"markdown"},"source":{"3e3e2ad4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\nimport tensorflow as tf\nrand_state = 42\ntf.set_random_seed(rand_state)\nnp.random.seed(rand_state)\n\nfrom skimage import exposure\nimport cv2\nimport glob\nimport time\nimport matplotlib.pyplot as plt\nfrom keras.utils.vis_utils import plot_model","0546af97":"def rotateImage(img, angle):\n    (rows, cols, ch) = img.shape\n    M = cv2.getRotationMatrix2D((cols\/2,rows\/2), angle, 1)\n    return cv2.warpAffine(img, M, (cols,rows))\n    \n    \ndef loadBlurImg(path, imgSize):\n    img = cv2.imread(path)\n    angle = np.random.randint(0, 360)\n    img = rotateImage(img, angle)\n    img = cv2.blur(img,(5,5))\n    img = cv2.resize(img, imgSize)\n    return img\n\ndef loadImgClass(classPath, classLable, classSize, imgSize):\n    x = []\n    y = []\n    \n    for path in classPath:\n        img = loadBlurImg(path, imgSize)        \n        x.append(img)\n        y.append(classLable)\n        \n    while len(x) < classSize:\n        randIdx = np.random.randint(0, len(classPath))\n        img = loadBlurImg(classPath[randIdx], imgSize)\n        x.append(img)\n        y.append(classLable)\n        \n    return x, y\n\ndef loadData(img_size, classSize, hotdogs, notHotdogs):    \n    imgSize = (img_size, img_size)\n    xHotdog, yHotdog = loadImgClass(hotdogs, 0, classSize, imgSize)\n    xNotHotdog, yNotHotdog = loadImgClass(notHotdogs, 1, classSize, imgSize)\n    print(\"There are\", len(xHotdog), \"hotdog images\")\n    print(\"There are\", len(xNotHotdog), \"not hotdog images\")\n    \n    X = np.array(xHotdog + xNotHotdog)\n    y = np.array(yHotdog + yNotHotdog)\n    \n    return X, y\n\ndef toGray(images):\n    # rgb2gray converts RGB values to grayscale values by forming a weighted sum of the R, G, and B components:\n    # 0.2989 * R + 0.5870 * G + 0.1140 * B \n    # source: https:\/\/www.mathworks.com\/help\/matlab\/ref\/rgb2gray.html\n    \n    images = 0.2989*images[:,:,:,0] + 0.5870*images[:,:,:,1] + 0.1140*images[:,:,:,2]\n    return images\n\ndef normalizeImages(images):\n    # use Histogram equalization to get a better range\n    # source http:\/\/scikit-image.org\/docs\/dev\/api\/skimage.exposure.html#skimage.exposure.equalize_hist\n    images = (images \/ 255.).astype(np.float32)\n    \n    for i in range(images.shape[0]):\n        images[i] = exposure.equalize_hist(images[i])\n    \n    images = images.reshape(images.shape + (1,)) \n    return images\n\ndef preprocessData(images):\n    grayImages = toGray(images)\n    return normalizeImages(grayImages)","9964a08e":"from keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nsize = 32\nclassSize = 20000\n\n\nhotdogs = glob.glob('..\/input\/seefood\/train\/hot_dog\/**\/*.jpg', recursive=True) + \\\nglob.glob('..\/input\/seefood\/test\/hot_dog\/**\/*.jpg', recursive=True) \n\nnotHotdogs = glob.glob('..\/input\/seefood\/train\/not_hot_dog\/**\/*.jpg', recursive=True) + \\\nglob.glob('..\/input\/seefood\/test\/not_hot_dog\/**\/*.jpg', recursive=True)\n\nscaled_X, y = loadData(size, classSize, hotdogs, notHotdogs)\nscaled_X = preprocessData(scaled_X)\ny = to_categorical(y)\n\n\nn_classes=2\nprint(\"y shape\", y.shape)\nX_train, X_test, y_train, y_test = train_test_split(scaled_X, y, \n                                                    test_size=0.2, \n                                                    random_state=rand_state)\n\nprint(\"train shape X\", X_train.shape)\nprint(\"train shape y\", y_train.shape)\nprint(\"Test shape X:\", X_test.shape)\nprint(\"Test shape y: \", y_test.shape)\n\ninputShape = (size, size, 1)","8d268374":"def plot_history(history):\n    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n    \n    if len(loss_list) == 0:\n        print('Loss is missing in history')\n        return \n    \n    ## As loss always exists\n    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n    \n    ## Loss\n    plt.figure(1)\n    for l in loss_list:\n        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n    for l in val_loss_list:\n        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n    \n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    ## Accuracy\n    plt.figure(2)\n    for l in acc_list:\n        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n    for l in val_acc_list:    \n        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()","0117c11f":"import keras\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\nfrom keras.layers.normalization import BatchNormalization\n\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 kernel_initializer='he_normal',\n                 input_shape=inputShape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.Adam(lr=1e-4),\n              metrics=['accuracy'])\n\nstart = time.time()\n\nmodel.summary()\n# Set callback functions to early stop training and save the best model so far\ncallbacks = [EarlyStopping(monitor='val_loss', patience=3),\n             ModelCheckpoint(filepath='model.h5', monitor='val_acc', save_best_only=True)]\n\nhistory = model.fit(X_train, y_train,\n                      batch_size=32,\n                      epochs=100, \n                      callbacks=callbacks,\n                      verbose=0,\n                      validation_data=(X_test, y_test))\n\nend = time.time()\nprint('Execution time: ', end-start)\n\nplot_history(history)","f724d418":"hotdogs = glob.glob('..\/input\/seefood\/test\/hot_dog\/**\/*.jpg', recursive=True) \nnotHotdogs = glob.glob('..\/input\/seefood\/test\/not_hot_dog\/**\/*.jpg', recursive=True)\n\nscaled_X_test, y_test = loadData(size, 250, hotdogs, notHotdogs)\nscaled_X_test = preprocessData(scaled_X_test)\n\n#get the predictions for the test data\npredicted_classes = model.predict_classes(scaled_X_test)\n\n# setup the true classes: just 250 hotdogs followed by 250 not hotdogs\ny_true = np.concatenate((np.zeros((250,)), np.ones((250,))))\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_true, predicted_classes, target_names=['hotdog', 'not hotdog']))","7af79a8c":"# Results  \n\nWe are simply going to evaluate this model on the original test set (500 of each class).","15192aeb":"# Introduction  \n\n\"What would you say if I told you there is a app on the market that tell you if you have a hotdog or not a hotdog. It is very good and I do not want to work on it any more. You can hire someone else.\" - Jian-Yang, [Silicon Valley](https:\/\/www.youtube.com\/watch?v=ACmydtFDTGs)\n\nSounds simple enough, right? It's actually a little more complex, referring to the theory behind convolutional neural networks (CNN) and their applications in image classification. However, Keras makes it relatively easy to setup and evaluate a CNN!  \n\nThe objective of this project is simple: given a picture, does it contain a hot dog or not?\n\n## Data\n\nThis data was extracted from the Food 101 dataset. A full version of the dataset is available [here](https:\/\/www.kaggle.com\/dansbecker\/food-101). This is a binary classification task, while not very interesting a similar approach can be taken to extend this to multiple food categories. Note that multiple terms can refer to what is essentially the same object, in this case the difference appears to primarily be regional: a frankfurter, wienerwurst or hot dog. Thanks to [DanB](https:\/\/www.kaggle.com\/dansbecker) for extracting the dataset ([kaggle](https:\/\/www.kaggle.com\/dansbecker\/hot-dog-not-hot-dog)) \n\nTo simplify this project, the data is completely balanced: 50% hot dog images and 50% not hot dog images. We will then use 498 images to train our model, and 500 labeled images to test it on.\n\n**Data augmentation**:  \nNeural networks perform much better when fed large amounts of data, and we only have 500 images for each class. We could just download more images from a source like ImageNet, but I will just augment this data set: add random rotation and or blur to our existing images to get 20,000 images for each class. **I also resize the images to 32 x 32, normalizeded them and performed histogram [equalization](https:\/\/en.wikipedia.org\/wiki\/Histogram_equalization)[](http:\/\/).**","ecacb286":"I made a few tweaks to the model, specifically:\n  1. [Adam](https:\/\/machinelearningmastery.com\/adam-optimization-algorithm-for-deep-learning\/) optimization algorithm\n  2. learning rate to 0.0001\n  3. Initialize weights using [He Normal](https:\/\/medium.com\/@prateekvishnu\/xavier-and-he-normal-he-et-al-initialization-8e3d7a087528)\n  4. early stopping\n\nEarlier models that I built (using this architecture) suffered from really bad overfitting, but rescaling the input images, and augmenting the data to get 40 times as many images fixed this problem.\n\nOur best model occurred at epoch 95 and achieved an accuracy of **97.6**%. This model also slightly underfit the data (not such a bad thing here). With GPU support enabled, training took 631 seconds (for 100 epochs). In comparison, it took 2376 seconds to train the same model for 60 epochs on my local machine (without CUDA support), a speedup of 6.2X.","74eec08e":"# Convolutional Neural Network (CNN)  \n\nI am using the architecture (network) outlined [here](https:\/\/www.kaggle.com\/bugraokcu\/cnn-with-keras)."}}