{"cell_type":{"980509c0":"code","221743b5":"code","5044cde1":"code","43b6d7f4":"code","af8bd227":"code","74c199f4":"code","07dd9fed":"code","89134f5a":"code","bd1cf39c":"code","1d0993ee":"code","4ce61aa9":"code","f42e257a":"code","f3d3b8d4":"code","a9cf20eb":"code","8489ae40":"code","88287401":"code","01b47179":"code","20ee6a81":"code","cd87af16":"code","1cba969a":"code","e1150a0b":"code","b1532135":"code","2370ff0c":"code","419feff1":"markdown","576d03b0":"markdown","c95a7284":"markdown","c47e60b4":"markdown","7cf75326":"markdown","7dd8d4df":"markdown","074fb972":"markdown","e8633a77":"markdown","d360abaf":"markdown","77ba86d0":"markdown","77c7a2e2":"markdown","e1e5144c":"markdown","2341b37b":"markdown","87171954":"markdown","ea397955":"markdown","70b23bad":"markdown","e605213e":"markdown","17a92d6d":"markdown","2aa8cc78":"markdown","9a9c04b2":"markdown"},"source":{"980509c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import RobustScaler\nfrom collections import Counter\nfrom sklearn.model_selection import cross_val_score\nimport re\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import Adam\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","221743b5":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","5044cde1":"#The Columns\ntrain.columns","43b6d7f4":"train.head()","af8bd227":"train.describe()","74c199f4":"train.info()","07dd9fed":"sns.countplot(train[\"Survived\"], palette = [\"black\",\"gray\"])\nplt.show()\nprint(train.Survived.value_counts())","89134f5a":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3st quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier Step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces \n        outlier_indices.extend(outlier_list_col)\n        \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2) \n    \n    return multiple_outliers","bd1cf39c":"train.loc[detect_outliers(train,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","1d0993ee":"train = train.drop(detect_outliers(train,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]),axis = 0).reset_index(drop=True)","4ce61aa9":"def preprocess(data):\n    \n    data.Cabin.fillna('0', inplace = True)\n    data.loc[data.Cabin.str[0] == 'A', 'Cabin'] = 1\n    data.loc[data.Cabin.str[0] == 'B', 'Cabin'] = 2\n    data.loc[data.Cabin.str[0] == 'C', 'Cabin'] = 3\n    data.loc[data.Cabin.str[0] == 'D', 'Cabin'] = 4\n    data.loc[data.Cabin.str[0] == 'E', 'Cabin'] = 5\n    data.loc[data.Cabin.str[0] == 'F', 'Cabin'] = 6\n    data.loc[data.Cabin.str[0] == 'G', 'Cabin'] = 7\n    data.loc[data.Cabin.str[0] == 'T', 'Cabin'] = 8\n    \n    data['Sex'].replace('female', 1, inplace =True)\n    data['Sex'].replace('male', 2, inplace =True)\n    \n    data['Embarked'].replace('S', 1, inplace =True)\n    data['Embarked'].replace('C', 2, inplace =True)\n    data['Embarked'].replace('Q', 3, inplace =True)\n    \n    data['Age'].fillna(data['Age'].median(), inplace = True)\n    data['Fare'].fillna(data['Fare'].median(), inplace = True)\n    data['Embarked'].fillna(data['Embarked'].median(), inplace = True)\n    \n    return data","f42e257a":"def group_titles(data):\n    \n    data['Names'] = data['Name'].map(lambda x: len(re.split(' ', x)))\n    data['Title'] = data['Name'].map(lambda x: re.search(', (.+?) ', x).group(1))\n    data['Title'].replace('Master.', 0, inplace = True)\n    data['Title'].replace('Mr.', 1, inplace = True)\n    data['Title'].replace(['Ms.', 'Mlle.', 'Miss.'], 2, inplace = True)\n    data['Title'].replace(['Mme.', 'Mrs.'], 3, inplace = True)\n    data['Title'].replace(['Dona.', 'Lady.', 'the Countess.', 'Capt.', 'Col.', 'Don.', 'Dr.', 'Major.', 'Rev.', 'Sir.', 'Jonkheer.', 'the'], 4, inplace = True)\n    \n    \n    ","f3d3b8d4":"def data_subset(data):\n    \n    features = ['Pclass', 'SibSp', 'Parch', 'Sex', 'Names', 'Title', 'Age', 'Cabin', 'Fare', 'Embarked']\n    lenght_features = len(features)\n    subset = data[features].fillna(0)\n    \n    return subset, lenght_features","a9cf20eb":"def create_model(train_set_size, input_lenght, num_epochs, batch_size, x_test, y_test):\n    \n    model = Sequential()\n    model.add(Dense(32, activation = 'relu', input_dim = input_lenght))\n    model.add(Dense(16, activation = \"relu\"))\n    model.add(Dense(8, activation = \"relu\"))\n    model.add(Dense(4, activation = \"relu\"))\n    model.add(Dense(1, activation = \"sigmoid\"))\n    \n    lr = .001\n    adam0 = Adam(lr = lr)\n    \n    model.compile(loss = \"binary_crossentropy\", optimizer = adam0, metrics= ['accuracy'])\n    \n    hist = model.fit(X_train[:train_set_size], Y_train[:train_set_size], validation_data=(x_test,y_test), epochs=num_epochs, batch_size=batch_size, verbose=-1)\n    \n    return model, hist\n    \n","8489ae40":"def plots(history):\n    plt.plot(history.history[\"loss\"],label = \"Train Loss\")\n    plt.plot(history.history[\"val_loss\"],label = \"Validation Loss\")\n    plt.legend()\n    plt.show()\n    plt.figure()\n    plt.plot(history.history[\"accuracy\"],label = \"Train Accuracy\")\n    plt.plot(history.history[\"val_accuracy\"],label = \"Validation Accuracy\")\n    plt.legend()\n    plt.show()","88287401":"def test(batch_size):\n        \n    test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n    test_ids = test['PassengerId']\n\n    test = preprocess(test)\n    group_titles(test)\n    testdata, _ = data_subset(test)\n\n    X_test = np.array(testdata).astype(float)\n\n    output = model.predict(X_test, batch_size=batch_size, verbose=0)\n    output = output.reshape((418,))\n\n    test_data = pd.DataFrame()\n    test_data[\"PassengerId\"] = test_ids\n    test_data[\"Survived\"] = output\n    \n    return test_data","01b47179":"preprocess(train)\ngroup_titles(train)\n\n\nnum_epochs = 100\nbatch_size = 16\n\ntraindata, lengh_features = data_subset(train)\n\nY_train = np.array(train['Survived']).astype(int)\nX_train = np.array(traindata).astype(float)\n\ntrain_set_size = int(.85 * len(X_train))\n\nX_validation = X_train[train_set_size:]\nY_validation = Y_train[train_set_size:]\n\nmodel, history_model = create_model(train_set_size, lengh_features, num_epochs, batch_size, X_validation, Y_validation)\n\n\nloss_and_metrics = model.evaluate(X_validation, Y_validation, batch_size=batch_size)\nprint (\"loss_and_metrics\")","20ee6a81":"plots(history_model)","cd87af16":"predict_data = test(batch_size)\npredict_data","1cba969a":"new_pred = []\nfor i in predict_data[\"Survived\"]:\n    \n    if i >=0.6:\n        new_pred.append(1)\n    else:\n        new_pred.append(0)","e1150a0b":"test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_ids = test['PassengerId']","b1532135":"predict_survived = pd.DataFrame()\npredict_survived['PassengerId'] = test_ids\npredict_survived['Survived'] = new_pred\npredict_survived","2370ff0c":"plt.figure()\nsns.countplot(new_pred)\nplt.show()","419feff1":"<h2 style = \"background-image: linear-gradient(200deg, gray, black);color:white;border:0\">Import Libraries<\/h2>","576d03b0":"<a id ='2' ><\/a>\n<h2 style = \"background-image: linear-gradient(200deg, gray, black);color:white;border:0\">Outlier Detection <\/h2>\n\n<ul>\n    <li  style = \"color:gray\" > <p style = \"color:black;font-weight:bold\" > We write a function to detect outliers in our data. <\/p> <\/li>\n    <li  style = \"color:black\" > <p style = \"color:black;font-weight:bold\" > We remove outliers in our data that we detected using the function. <\/p> <\/li>\n<\/ul>","c95a7284":"<ul>\n    <li  style = \"color:gray\" > <p style = \"color:black;font-weight:bold\" > yes, we made our decimal values 0 or 1.<\/p> <\/li>\n<\/ul>","c47e60b4":"<a id ='6' ><\/a>\n<h2 style = \"background-image: linear-gradient(200deg, gray, black);color:white;border:0\">CONCLUSION<\/h2>\n\n<ul>\n    <li  style = \"color:gray\" > <p style = \"color:black;font-weight:bold\" > First of all, thank you very much for looking up here. I am waiting for your suggestions and good wishes. <\/p> <\/li>\n    <li>\u2693 Titanic - EDA - Visualization - Prediction \u2693 : <a href = 'https:\/\/www.kaggle.com\/rafetcan\/titanic-eda-visualization-prediction'> https:\/\/www.kaggle.com\/rafetcan\/titanic-eda-visualization-prediction <\/a> <\/li>\n<\/ul>","7cf75326":"<ul>\n    <li  style = \"color:gray\" > <p style = \"color:black;font-weight:bold\" > yes, it is time to use these functions we have created. <\/p> <\/li>\n    <li  style = \"color:black\" > <p style = \"color:black;font-weight:bold\" > We send our train data to the functions we have created. <\/p> <\/li>\n    <li  style = \"color:gray\" > <p style = \"color:black;font-weight:bold\" > We determine our num_epochs and batch_size values. <\/p> <\/li>\n<\/ul>","7dd8d4df":"<a id ='5' ><\/a>\n<h2 style = \"background-image: linear-gradient(200deg, gray, black);color:white;border:0\">Prediction<\/h2>\n\n<ul>\n    <li  style = \"color:gray\" > <p style = \"color:black;font-weight:bold\" > Yes, we make predictions using the model we have created so far. While performing this process, we will make use of the function we created earlier. <\/p> <\/li>\n<\/ul>","074fb972":"<ul>\n    <li  style = \"color:gray\" > <p style = \"color:black;font-weight:bold\" > We visualize the acc and loss values \u200b\u200bof our model that we have created. <\/p> <\/li>\n<\/ul>","e8633a77":"<ul>\n    <li  style = \"color:gray\" > <p style = \"color:black;font-weight:bold\" > We will send our data to our model and the function we set as input_dim. <\/p> <\/li>\n<\/ul>","d360abaf":"<center><h1 style = \"background-image: linear-gradient(200deg, gray, black);color:white;border:0\">Introduction<\/h1><\/center>\n\n<p style = \"color:black;font-weight:500;text-indent:20px;font-size:16px\">The sinking of Titanic is one the most notorious shipwredcks in the history , In 1912, during her voyage, the titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.<\/p>\n\n<p style = \"color:black;font-weight:500;text-indent:20px;font-size:16px\">First, we will simply examine our data.Later, we will prepare your data using functions, different from what we do normally this time.We will train the data we have prepared using the ANN model.We will examine them by drawing the acc and loss graphs of our model that we have trained.Finally, we will complete the project by performing the estimation process. <\/p>\n    \n\n<h2 style = \"background-image: linear-gradient(200deg, gray, black);color:white;border:0\">Content :<\/h2>\n\n<ul>\n    <li style = \"color:black;font-size:15px\"> <a href = \"#1\" style = \"color:black;font-weight:bold\"> Load and Check Data <\/a> <\/li>\n    <li style = \"color:gray;font-size:15px\"> <a href = \"#2\" style = \"color:black;font-weight:bold\"> Outlier Detection <\/a> <\/li>   \n    <li style = \"color:black;font-size:15px\"> <a href = \"#3\" style = \"color:black;font-weight:bold\">  Preparing the Data <\/a> <\/li>\n    <li style = \"color:gray;font-size:15px\"> <a href = \"#4\" style = \"color:black;font-weight:bold\">  Visualization <\/a> <\/li>\n    <li style = \"color:black;font-size:15px\"> <a href = \"#5\" style = \"color:black;font-weight:bold\">  Prediction <\/a> <\/li>\n    <li style = \"color:gray;font-size:15px\"> <a href = \"#6\" style = \"color:black;font-weight:bold\">  CONCLUSION <\/a> <\/li>\n <\/ul>","77ba86d0":"<ul>\n    <li  style = \"color:gray\" > <p style = \"color:black;font-weight:bold\" > Let's start with the preprocess function first. <\/p> <\/li>\n    <li  style = \"color:black\" > <p style = \"color:black;font-weight:bold\" > The cabin in our data consists of string values, we change it to int values. <\/p> <\/li>\n    <li  style = \"color:gray\" > <p style = \"color:black;font-weight:bold\" > We do the same for gender. <\/p> <\/li>\n     <li  style = \"color:black\" > <p style = \"color:black;font-weight:bold\" > We also convert embarked values to int values. <\/p> <\/li>\n    <li  style = \"color:gray\" > <p style = \"color:black;font-weight:bold\" > Finally, if age, embarked and fare have null values, we fill them with medians. <\/p> <\/li>\n<\/ul> \n","77c7a2e2":"![titanic.jpeg](attachment:titanic.jpeg)","e1e5144c":"<a id ='1' ><\/a>\n<h2 style = \"background-image: linear-gradient(200deg, gray, black);color:white;border:0\">Load and Check Data <\/h2>","2341b37b":"<ul>\n    <li  style = \"color:black\" > <p style = \"color:black;font-weight:bold\" > We write our function that we create and train our model. <\/p> <\/li>\n<\/ul>","87171954":"<ul>\n    <li  style = \"color:black\" > <p style = \"color:black;font-weight:bold\" > Finally, we took a look at the predictions we made by visualizing them.<\/p> <\/li>\n<\/ul>","ea397955":"<ul>\n    <li  style = \"color:black\" > <p style = \"color:black;font-weight:bold\" > Here we see some null values. We will not consider these in this project. If you want to see how we populate null values \u200b\u200bin titanic data, you can check it out <a href = \"https:\/\/www.kaggle.com\/rafetcan\/titanic-eda-visualization-prediction\"> here <\/a>. <\/p> <\/li>\n<\/ul>","70b23bad":"<ul>\n    <li  style = \"color:black\" > <p style = \"color:black;font-weight:bold\" > As you can see, our estimation results came. but now decimal values. We convert them to values \u200b\u200b0 and 1 by setting a limit value. We set this limit value as 0.6 as you can see below. <\/p> <\/li>\n<\/ul>","e605213e":"<a id ='4' ><\/a>\n<h2 style = \"background-image: linear-gradient(200deg, gray, black);color:white;border:0\">Visualization<\/h2>\n\n<ul>\n    <li  style = \"color:black\" > <p style = \"color:black;font-weight:bold\" > We visualize our loss and acc values by sending them to the function we created above. <\/p> <\/li>\n<\/ul>","17a92d6d":"<ul>\n    <li  style = \"color:black\" > <p style = \"color:black;font-weight:bold\" > we write a function to test the model we have created. <\/p> <\/li>\n<\/ul>","2aa8cc78":"<ul>\n    <li  style = \"color:black\" > <p style = \"color:black;font-weight:bold\" > By using the group_titles function, we create a new property by editing the name property in our data. <\/p> <\/li>\n<\/ul>","9a9c04b2":"<a id ='3' ><\/a>\n<h2 style = \"background-image: linear-gradient(200deg, gray, black);color:white;border:0\">Preparing the Data <\/h2>\n\n<ul>\n    <li  style = \"color:black\" > <p style = \"color:black;font-weight:bold\" > In this section, we will make our data suitable for our model. <\/p> <\/li>\n<\/ul>"}}