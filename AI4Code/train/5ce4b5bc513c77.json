{"cell_type":{"ca0638eb":"code","822978aa":"code","d127bed3":"code","8ff56d0a":"code","4ae470a3":"code","971d2568":"code","28863901":"code","c856a58d":"code","9e486418":"code","ce722732":"code","92305477":"code","f5c4d643":"code","1aa4f180":"code","635bcbd9":"code","99512cfb":"code","8f170cfe":"code","a178cc47":"code","aa92c9f9":"code","1fd30e0c":"code","aaecca79":"code","adb324a4":"code","93b7bd12":"code","a71a36bf":"code","f9022c2e":"code","5c9424ba":"code","0a4ac283":"code","8522ee36":"code","ec0bfe9b":"code","a8bb8cfb":"code","55a42da8":"code","2d199f41":"code","3d39a28d":"code","96e6f700":"code","946d39ab":"code","fcc5ee6b":"code","44bf53fc":"code","70dc628a":"code","0b4521a0":"code","f180f9d6":"code","16aa7056":"code","fa8e6b65":"code","93ef836f":"code","9a5c5412":"code","944e02f8":"code","c6b7b395":"code","b6725c9e":"code","5ba7221f":"code","7a21728a":"code","af5cb2dd":"code","78a0b7a9":"code","68752350":"code","b5e6169b":"code","d1e48cbe":"code","0ba5cd1b":"code","e05425ea":"code","d086f2f5":"code","961f15b6":"code","c631a38a":"code","e1f9b5fe":"code","1f11bbac":"code","83caecf0":"markdown","9ea42d48":"markdown","926e8d43":"markdown","817e64e6":"markdown","dd2fc573":"markdown","2347329a":"markdown","81549007":"markdown","24264245":"markdown","0f48c5a5":"markdown","3a5592ea":"markdown","f4ac0dff":"markdown","7fe968a6":"markdown","30afef74":"markdown","97b00da1":"markdown","2c98e6c5":"markdown","2e33d95a":"markdown","ff66945e":"markdown","e80bc104":"markdown","865fd3fa":"markdown","d290577a":"markdown","26000e61":"markdown","3d850ff1":"markdown","44fb508c":"markdown"},"source":{"ca0638eb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom tqdm import tqdm_notebook\nimport random\n\nimport xgboost as xgb\n#import lightgbm as lgb\n\nfrom sklearn.decomposition import PCA, IncrementalPCA,SparsePCA, KernelPCA, FastICA, TruncatedSVD \n\nimport os\nimport time\nimport datetime\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(os.listdir(\"..\/input\/ieee-fraud-detection\/\"))\n\nimport gc","822978aa":"!rm -r \/opt\/conda\/lib\/python3.6\/site-packages\/lightgbm\n!git clone --recursive https:\/\/github.com\/Microsoft\/LightGBM","d127bed3":"!apt-get install -y -qq libboost-all-dev","8ff56d0a":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=\/usr\/local\/cuda\/lib64\/libOpenCL.so -DOpenCL_INCLUDE_DIR=\/usr\/local\/cuda\/include\/ ..\nmake -j$(nproc)","4ae470a3":"!cd LightGBM\/python-package\/;python3 setup.py install --precompile","971d2568":"!mkdir -p \/etc\/OpenCL\/vendors && echo \"libnvidia-opencl.so.1\" > \/etc\/OpenCL\/vendors\/nvidia.icd\n!rm -r LightGBM","28863901":"import lightgbm as lgb\nprint(\"LightGBM version:\", lgb.__version__)","c856a58d":"!nvidia-smi","9e486418":"def reduce_mem_usage(props):\n    start_mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings\n            \n            # Print current column type\n            print(\"******************************\")\n            print(\"Column: \",col)\n            print(\"dtype before: \",props[col].dtype)\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(props[col]).all():  # case if row has NA value, then return False, also inverse returns True.\n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                props[col] = props[col].astype(np.float32)\n            \n            # Print new column type\n            print(\"dtype after: \",props[col].dtype)\n            print(\"******************************\")\n    \n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n    return props","ce722732":"%%time\ndf_train_tr = pd.read_csv('..\/input\/ieee-fraud-detection\/train_transaction.csv')\ndf_train_id = pd.read_csv('..\/input\/ieee-fraud-detection\/train_identity.csv')","92305477":"%%time\ndf_train_tr = reduce_mem_usage(df_train_tr)\ndf_train_id = reduce_mem_usage(df_train_id)","f5c4d643":"%%time\ndf_test_tr = pd.read_csv('..\/input\/ieee-fraud-detection\/test_transaction.csv')\ndf_test_id = pd.read_csv('..\/input\/ieee-fraud-detection\/test_identity.csv')","1aa4f180":"%%time\ndf_test_tr = reduce_mem_usage(df_test_tr)\ndf_test_id = reduce_mem_usage(df_test_id)","635bcbd9":"submission = pd.read_csv('..\/input\/ieee-fraud-detection\/sample_submission.csv')","99512cfb":"%%time\ndf_train = pd.merge(df_train_tr, df_train_id, on = 'TransactionID', how = 'left')\ndf_test = pd.merge(df_test_tr, df_test_id, on = 'TransactionID', how = 'left')","8f170cfe":"del df_train_id, df_train_tr, df_test_id, df_test_tr\ngc.collect()","a178cc47":"df = pd.concat([df_train, df_test], axis=0, sort=False)\ndf.reset_index(inplace=True)","aa92c9f9":"del df_train, df_test\ngc.collect()","1fd30e0c":"def missing_data(df) :\n    count = df.isnull().sum()\n    percent = (df.isnull().sum()) \/ (df.isnull().count()) * 100\n    total = pd.concat([count, percent], axis=1, keys = ['Count', 'Percent'])\n    types = []\n    for col in df.columns :\n        dtypes = str(df[col].dtype)\n        types.append(dtypes)\n    total['dtypes'] = types\n    \n    return np.transpose(total)","aaecca79":"missing_data(df)","adb324a4":"num_cols = [col for col in df.columns if df[col].dtype not in ['object']]\ndf[num_cols].describe()","93b7bd12":"cat_cols = [col for col in df.columns if df[col].dtype in ['object']]\ndf[cat_cols].describe()","a71a36bf":"for col in cat_cols :\n    \n    print('-' * 50)\n    print('# col : ', col)\n    #print(df[df.index < 590540]['isFraud'].groupby(df[col]).sum(),df[df.index < 590540]['isFraud'].groupby(df[col]).count())\n    print(100*df[df.index < 590540]['isFraud'].groupby(df[col]).sum()\/\n          df[df.index < 590540]['isFraud'].groupby(df[col]).count()) ","f9022c2e":"for col in cat_cols :\n    uniq = np.unique(df[col].astype(str))\n    print('-' * 100)\n    print('# col {}, n_uniq {}, uniq {}'.format(col, len(uniq), uniq))\n","5c9424ba":"\"\"\"\n kernel died\n\"\"\"\n#%%time \n#cor = df[num_cols].astype(float).corr()\n#cor = pd.DataFrame(cor)\n#cor = cor['isFraud']\n#cor = pd.DataFrame(cor)\n#cor = cor[cor['isFraud'] > 0.2]\n#cor_columns_over_zero_dot_tree = cor.index.tolist()","0a4ac283":"#del cor\n#gc.collect()","8522ee36":"#colormap = plt.cm.RdBu\n#plt.figure(figsize = (20,20))\n#plt.title('Correlation Analysis of Numeric Columns', y = 1.05, size = 15)\n#sns.heatmap(df[cor_columns_over_zero_dot_tree].astype(float).corr(), linewidths = 0.1, vmax = 1.0, square = True,\n#            cmap = colormap, linecolor = 'white', annot = True)","ec0bfe9b":"df['V39_V51_V52_cor'] = df['V39'] + df['V51'] + df['V52']\ndf['V40_V51_V52_cor'] = df['V40'] + df['V51'] + df['V52']\ndf['V44_V86_V87_cor'] = df['V44'] + df['V86'] + df['V87']\ndf['V45_V86_V87_cor'] = df['V45'] + df['V86'] + df['V87']\ndf['V86_V190_V199_V246_V257_cor'] = df['V86'] + df['V190'] + df['V199'] + df['V246'] + df['V257']\ndf['V87_V257_cor'] = df['V87'] + df['V257']\ndf['V148_V149_V154_V155_V156_V157_V158_cor'] = df['V148'] + df['V149'] + df['V154'] + df['V155'] + df['V156']+ df['V157'] + df['V158']\ndf['V170_V171_V188_V200_V201_cor'] = df['V170'] + df['V171'] + df['V188'] + df['V200'] + df['V201']\ndf['V171_V189_V200_V201_cor'] = df['V171'] + df['V189'] + df['V200'] + df['V201']\ndf['V188_V189_V200_V201_V242_V244_cor'] = df['V188'] + df['V189'] + df['V200'] + df['V201'] + df['V242'] + df['V244']\ndf['V189_V200_V201_V242_V233_V244_cor'] = df['V189'] + df['V200'] + df['V201'] + df['V242'] + df['V243'] + df['V244']\ndf['V190_V199_V228_V233_cor'] = df['V190'] + df['V199'] + df['V228'] + df['V233']\ndf['V199_V228_V230_V246_V257_V258_cor'] = df['V199'] + df['V228'] + df['V230'] + df['V246'] + df['V257'] + df['V258']\ndf['V200_V201_V244_cor'] = df['V200'] + df['V201'] + df['V244']\ndf['V201_V242_V244_cor'] = df['V201'] + df['V242'] + df['V244']\ndf['V228_V230_V246_V257_V258_cor'] = df['V228'] + df['V230'] + df['V246'] + df['V257'] + df['V258']\ndf['V230_V246_V257_V258_cor'] = df['V230'] + df['V246'] + df['V257'] + df['V258']\ndf['V242_V243_V244_cor'] = df['V242'] + df['V243'] + df['V244']\ndf['V243_V244_cor'] = df['V243'] + df['V244']\ndf['V246_V257_V258_cor'] = df['V246'] + df['V257'] + df['V258']","a8bb8cfb":"START_DATE = '2019-01-01'\nstartdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\ndf[\"Date\"] = df['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n\ndf['TransactionDT_Weekdays'] = df['Date'].dt.dayofweek\ndf['TransactionDT_Days'] = df['Date'].dt.day\ndf['TransactionDT_Hours'] = df['Date'].dt.hour\n\ndf.drop(columns='Date', inplace=True)","55a42da8":"def change_value_P_emaildomain(x) :\n    if x in ['gmail.com', 'icloud.com', 'mail.com' , 'outlook.es', 'protonmail.com'] :\n        return x\n    else :\n        return 'etc'\n    \ndf.loc[:,'P_emaildomain'] = df['P_emaildomain'].apply(lambda x : change_value_P_emaildomain(x))","2d199f41":"def change_value_R_emaildomain(x) :\n    if x in ['gmail.com', 'icloud.com', 'mail.com', 'netzero.net', 'outlook.com', 'outlook.es', 'protonmail.com'] :\n        return x\n    else :\n        return 'etc'\n    \ndf.loc[:,'R_emaildomain'] = df['R_emaildomain'].apply(lambda x : change_value_R_emaildomain(x))","3d39a28d":"def change_value_id_30(x) :\n    if x in ['Android 4.4.2', 'Android 5.1.1' 'iOS 11.0.1' 'iOS 11.1.0', 'iOS 11.4.0', 'other'] :\n        return x\n    else :\n        return 'etc'\n\ndf.loc[:,'id_30'] = df['id_30'].apply(lambda x : change_value_id_30(x))","96e6f700":"def change_value_id_31(x) :\n    if x in ['Lanix\/Ilium', 'Mozilla\/Firefox' 'comodo' 'icedragon', 'opera', 'opera generic'] :\n        return x\n    else :\n        return 'etc'\n\ndf.loc[:,'id_31'] = df['id_31'].apply(lambda x : change_value_id_31(x))","946d39ab":"def change_value_id_33(x) :\n    if x in ['1024x552', '1364x768' '1440x759' '1916x901', '1920x975', '2076x1080', '640x360'] :\n        return x\n    else :\n        return 'etc'\n\ndf.loc[:,'id_33'] = df['id_33'].apply(lambda x : change_value_id_33(x))","fcc5ee6b":"tmp = 100*df[df.index < 590540]['isFraud'].groupby(df['DeviceInfo']).sum()\/df[df.index < 590540]['isFraud'].groupby(df['DeviceInfo']).count()\n\nDevice_Info = []\n\nfor i in tqdm_notebook(range(len(tmp))) :\n    if tmp[i] == 100.0 :\n        Device_Info.append(tmp.index[i])\n\ndef change_value_DeviceInfo(x) :\n    if x in Device_Info :\n        return x\n    else :\n        return 'etc'\n\ndf.loc[:,'DeviceInfo'] = df['DeviceInfo'].apply(lambda x : change_value_DeviceInfo(x))","44bf53fc":"df_num = df.select_dtypes(exclude = ['object'])\ndf_cat = df.select_dtypes(include = ['object'])","70dc628a":"pca_temp = df_num.drop(columns = ['isFraud', 'index', 'TransactionID', 'TransactionDT']).fillna(df_num.min()-1)\npca = PCA(n_components=5)\npca_X = pca.fit_transform(pca_temp)\n\nfor i in range(5) :\n    df_num['PCA_' + str(i+1)] = pca_X[:,i]","0b4521a0":"del df, pca_temp\ngc.collect()","f180f9d6":"df_cat_one_hot = pd.get_dummies(df_cat)","16aa7056":"pca_temp_cat = df_cat_one_hot.fillna(df_cat_one_hot.min()-1)\npca_cat = PCA(n_components=5)\npca_X_cat = pca_cat.fit_transform(pca_temp_cat)\n\nfor i in range(5) :\n    df_cat_one_hot['PCA_cat_' + str(i+1)] = pca_X_cat[:,i]","fa8e6b65":"del pca_temp_cat\ngc.collect()","93ef836f":"df_total = pd.concat([df_num, df_cat_one_hot], axis=1)\ndf_total.shape","9a5c5412":"df_total.drop(columns = ['TransactionID', 'index'], inplace=True)","944e02f8":"del df_num, df_cat\ngc.collect()","c6b7b395":"df_train = df_total[df_total.index < 590540]\ndf_test = df_total[df_total.index >= 590540]","b6725c9e":"y = pd.DataFrame(df_train['isFraud'])\nX = df_train.drop(columns=['isFraud'])\nX_test = df_test.drop(columns=['isFraud'])","5ba7221f":"X.shape, y.shape, X_test.shape","7a21728a":"del df_train, df_test, df_total\ngc.collect()","af5cb2dd":"np.unique(y['isFraud'])","78a0b7a9":"index_array = np.arange(len(X))\nval_index = index_array[random.sample(range(0,X.shape[0]), X.shape[0]\/\/5)]\ntrain_index = np.delete(index_array[:X.shape[0]], val_index, axis=0)\nlen(train_index), len(val_index)","68752350":"X_train, X_val = X.iloc[train_index], X.iloc[val_index]\ny_train, y_val = y.iloc[train_index], y.iloc[val_index]","b5e6169b":"%%time\nprediction_test_fold = []\n\nparam = {'booster' : 'gbtree',\n         'max_depth' : 14,\n         'nthread' : -1,\n         'num_class' : 1,\n         'objective' : 'binary:logistic',\n         'silent' : 1,\n         'eval_metric' : 'auc',\n         'eta' : 0.01,\n         'tree_method' : 'gpu_hist',\n         'min_child_weight' : 0,\n         'colsample_bytree' : 0.8,\n         'colsample_bylevel' : 0.8,\n         'seed' : 2019}\n\n\n\n    \nprint(\"Train Shape :\", X_train.shape,\n      \"Validation Shape :\", X_val.shape,\n      \"Test Shape :\", X_test.shape)\n    \ndtrn = xgb.DMatrix(X_train, label=y_train, feature_names = X.columns)\ndval = xgb.DMatrix(X_val, label = y_val, feature_names = X.columns)\ndtst = xgb.DMatrix(X_test, feature_names = X.columns)\n    \nxgb1 = xgb.train(param, dtrn, num_boost_round=10000, evals = [(dtrn, 'train'), (dval, 'eval')],\n                 early_stopping_rounds = 200, verbose_eval=200)\n                 \nprediction_XGB = xgb1.predict(dtst)\n#prediction_test_fold.append(prediction_XGB)\n\nprediction_val_XGB = xgb1.predict(xgb.DMatrix(X_val, feature_names = X.columns))","d1e48cbe":"for i in range(2):\n    \n    if i == 0 :\n        plt.figure(figsize = (25,6))\n        plt.title('Validation Evaluation of XGBoost', y = 1.05, size = 15)\n        plt.plot(y_val.reset_index()['isFraud'], '.', label = 'Real Validation Value', color = 'blue')\n        plt.plot(prediction_val_XGB, '.', label = 'Predicted Validation Value', color = 'red')\n        plt.legend()\n        plt.show()\n    \n    else :\n        plt.figure(figsize = (25,6))    \n        plt.title('Error Evaluation of LightGBM', y = 1.05, size = 15)\n        plt.plot(y_val.reset_index()['isFraud'] - prediction_val_XGB, '.', label = 'Error', color = 'green')\n        plt.legend()\n        plt.show()","0ba5cd1b":"del dtrn, dval, dtst, xgb1\ngc.collect()","e05425ea":"%%time\n\nparams = {'num_leaves': 500,\n          'min_child_weight': 0.03,\n          'feature_fraction': 0.35,\n          'bagging_fraction': 0.35,\n          'min_data_in_leaf': 100,\n          'objective': 'binary',\n          'max_depth': 14,\n          'learning_rate': 0.01,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 10,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': 0.2,\n          'reg_lambda': 0.6,\n          'random_state': 50,\n          'device': 'gpu',\n          'gpu_platform_id': 0,\n          'gpu_device_id': 0\n         }\n\n\ndtrain = lgb.Dataset(X_train, label=y_train)\ndvalid = lgb.Dataset(X_val, label=y_val)\n\nmodel = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=100, early_stopping_rounds=200)\n    \n\nprediction_LGB = model.predict(X_test)\nprediction_val_LGB = model.predict(X_val)","d086f2f5":"for i in range(2):\n    \n    if i == 0 :\n        plt.figure(figsize = (25,6))\n        plt.title('Validation Evaluation of XGBoost', y = 1.05, size = 15)\n        plt.plot(y_val.reset_index()['isFraud'], '.', label = 'Real Validation Value', color = 'blue')\n        plt.plot(prediction_val_LGB, '.', label = 'Predicted Validation Value', color = 'red')\n        plt.legend()\n        plt.show()\n    \n    else :\n        plt.figure(figsize = (25,6))    \n        plt.title('Error Evaluation of LightGBM', y = 1.05, size = 15)\n        plt.plot(y_val.reset_index()['isFraud'] - prediction_val_LGB, '.', label = 'Error', color = 'green')\n        plt.legend()\n        plt.show()","961f15b6":"submission['isFraud'] = np.nan\nsubmission.head()","c631a38a":"submission['isFraud'] = (0.5 * prediction_XGB) + (0.5 * prediction_LGB)\n#submission['isFraud'] = prediction_LGB\nsubmission.head()","e1f9b5fe":"submission[submission['isFraud'] > 0.1]","1f11bbac":"submission.to_csv('sample_submission_after_Feature_Engineering11.csv', index = False)","83caecf0":"### 3) Feature Values Filtering in Categorical Columns","9ea42d48":"### 3) XGBoost Fitting","926e8d43":"## 2. Reading Data SET","817e64e6":"## 4. Feature Engineering","dd2fc573":"## 0. Context","2347329a":"#### 4) LightGBM Fitting","81549007":"### 5) Submission to Score Board","24264245":"### 1) Correlation Analysis of Numeric Values","0f48c5a5":"- From above on, Usage of RAM is 3.8GB","3a5592ea":"## 1. Loading Library","f4ac0dff":"## 3. EDA","7fe968a6":"- In this competition you are predicting the probability that an online transaction is fraudulent, as denoted by the binary target isFraud.\n\n- The data is broken into two files identity and transaction, which are joined by TransactionID. Not all transactions have corresponding identity information.","30afef74":"### 1) Check Missing Data","97b00da1":"- Loading Library\n- Read Data SET\n- EDA\n- Preprocessing\n* Feature Engineering\n- Modeling\n- Evaluation","2c98e6c5":"* Install LightGBM GPU VERSION","2e33d95a":"### 3) Check Categorical Columns Properties","ff66945e":"### 1) PreProcessing","e80bc104":"## 5. Modeling","865fd3fa":"### 1) Reduce Memory using down sizing Data SET","d290577a":"### 2) Feature Slicing in Time Series Data","26000e61":"- In this competition you are predicting the probability that an online transaction is fraudulent, as denoted by the binary target isFraud.\n\n- The data is broken into two files identity and transaction, which are joined by TransactionID. Not all transactions have corresponding identity information.\n------------------------------\n- *Categorical Features - Transaction\n- ProductCD\n- card1 - card6\n- addr1, addr2\n- P_emaildomain\n- R_emaildomain\n- M1 - M9\n------------------------------\n- *Categorical Features - Identity\n- DeviceType\n- DeviceInfo id_12 - id_38\n------------------------------\n- The TransactionDT feature is a timedelta from a given reference datetime (not an actual timestamp).","3d850ff1":"### 2) Train \/ Validation Split","44fb508c":"### 2) Check Numeric Columns Properties"}}