{"cell_type":{"450a9a19":"code","a5a5d607":"code","f079a7ad":"code","799facd0":"code","dba056cc":"code","1dc6b7c0":"code","faf5c09b":"code","3d15cc38":"code","b80673fd":"code","4944f6ab":"code","2828a13f":"code","4945d9f6":"code","4b4f7d4e":"code","ff3df3af":"code","2f3eed6a":"code","887e5c95":"code","b3052b85":"code","4a9dcc22":"code","50f325cc":"code","b0f9ea1e":"code","9f169ce7":"code","5859e262":"code","e45ca849":"code","7f370a2b":"code","ab8cf7d1":"code","10beb7d6":"code","cf5fcc31":"code","acde862e":"code","6d771983":"code","fe9c6f78":"code","343eeb18":"code","eadb224b":"code","75e421c6":"code","1100dda8":"code","4467cf6d":"code","0fb9bf94":"markdown","89e6cb06":"markdown","2cabd694":"markdown","d31b618a":"markdown","cfb07090":"markdown","48af6319":"markdown","d1001956":"markdown","e7179426":"markdown","0d702050":"markdown","d6a8ce54":"markdown","9228f589":"markdown","0d4ffd33":"markdown","d1a484ff":"markdown","6343fcff":"markdown","0921af12":"markdown","5bf2d6b7":"markdown","e4b445a0":"markdown","e43a02ca":"markdown","9c276dda":"markdown"},"source":{"450a9a19":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","a5a5d607":"#import zipfile\n#zip_file = zipfile.ZipFile('retail-data-analytics.zip', 'r')\n#zip_file.namelist()","f079a7ad":"features=pd.read_csv('..\/input\/Features data set.csv')\nsales=pd.read_csv('..\/input\/sales data-set.csv')\nstores=pd.read_csv('..\/input\/stores data-set.csv')","799facd0":"features['Date'] = pd.to_datetime(features['Date'])\nsales['Date'] = pd.to_datetime(sales['Date'])","dba056cc":"print(features.shape)\nprint(sales.shape)\nprint(stores.shape)\n\nprint(sales[0:1].Date, sales[-1:].Date)\n\nprint(features[0:1].Date, features[-1:].Date)","1dc6b7c0":"df=pd.merge(sales,features, on=['Store','Date', 'IsHoliday'], how='left')\ndf=pd.merge(df,stores, on=['Store'], how='left')\n\ndf=df.fillna(0)\ndf['Temperature'] = (df['Temperature']- 32) * 5.\/9.\n\ntypes_encoded, types =df['Type'].factorize()\ndf['Type'] = types_encoded\n\ndf.head()","faf5c09b":"print('training_data duplicated:{}'.format(df.duplicated().sum()))\ndf.drop_duplicates(inplace=True)","3d15cc38":"df.describe()","b80673fd":"tab_info = pd.DataFrame(df.dtypes).T.rename(index={0:'column Type'}) \ntab_info = tab_info.append(pd.DataFrame(df.isnull().sum()).T.rename(index={0:'null values (nb)'}))\ntab_info = tab_info.append(pd.DataFrame(df.isnull().sum()\/df.shape[0]*100).T.\n                                       rename(index={0: 'null values (%)'}))\ntab_info","4944f6ab":"df[['Date', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', \n    'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']].plot(x='Date', subplots=True, figsize=(20,15))\nplt.show()","2828a13f":"df_average_sales_week = df.groupby(by=['Date'], as_index=False)['Weekly_Sales'].sum()\ndf_average_sales = df_average_sales_week.sort_values('Weekly_Sales', ascending=False)\n\nplt.figure(figsize=(20,5))\nplt.plot(df_average_sales_week.Date, df_average_sales_week.Weekly_Sales)\nplt.show()","4945d9f6":"# The more remunerative weeks\ndf_average_sales.head()","4b4f7d4e":"# The least remunerative weeks\ndf_average_sales[::-1].head()","ff3df3af":"# The least remunerative weeks\ndf_average_sales[::-1].head()","2f3eed6a":"ts = df_average_sales_week.set_index('Date')\n#ts = ts.resample('H').ffill()\n#ts = ts.resample('W').sum()","887e5c95":"# The least remunerative weeks\ndf_average_sales[::-1].head()","b3052b85":"# Top performing type of stores in term of sales\ndf_top_stores = df.groupby(by=['Type'], as_index=False)['Weekly_Sales'].sum()\ndf_top_stores.sort_values('Weekly_Sales', ascending=False)","4a9dcc22":"# Top performing stores in term of sales\ndf_top_stores = df.groupby(by=['Store'], as_index=False)['Weekly_Sales'].sum()\ndf_top_stores.sort_values('Weekly_Sales', ascending=False)[:3]","50f325cc":"from statsmodels.graphics.tsaplots import acf, pacf, plot_acf, plot_pacf\n\nfig, axes = plt.subplots(1,2, figsize=(20,5))\nplot_acf(ts, lags=100, ax=axes[0])\nplot_pacf(ts, lags=100, ax=axes[1])\nplt.show()","b0f9ea1e":"from sklearn.linear_model import LinearRegression\n\ndef fit_ar_model(ts, orders):\n    \n    X=np.array([ ts.values[(i-orders)].squeeze() if i >= np.max(orders) else np.array(len(orders) * [np.nan]) for i in range(len(ts))])\n    \n    mask = ~np.isnan(X[:,:1]).squeeze()\n    \n    Y= ts.values\n    \n    lin_reg=LinearRegression()\n    \n    lin_reg.fit(X[mask],Y[mask])\n    \n    print(lin_reg.coef_, lin_reg.intercept_)\n\n    print('Score factor: %.2f' % lin_reg.score(X[mask],Y[mask]))\n    \n    return lin_reg.coef_, lin_reg.intercept_\n    \ndef predict_ar_model(ts, orders, coef, intercept):\n    return np.array([np.sum(np.dot(coef, ts.values[(i-orders)].squeeze())) + intercept  if i >= np.max(orders) else np.nan for i in range(len(ts))])","9f169ce7":"orders=np.array([1,6,52])\ncoef, intercept = fit_ar_model(ts,orders)\npred=pd.DataFrame(index=ts.index, data=predict_ar_model(ts, orders, coef, intercept))\nplt.figure(figsize=(20,5))\nplt.plot(ts, 'o')\nplt.plot(pred)\nplt.show()","5859e262":"diff=(ts['Weekly_Sales']-pred[0])\/ts['Weekly_Sales']\n\nprint('AR Residuals: avg %.2f, std %.2f' % (diff.mean(), diff.std()))\n \nplt.figure(figsize=(20,5))\nplt.plot(diff, c='orange')\nplt.grid()\nplt.show()","e45ca849":"df20=df.where( df['Store'] == 20)\ndf20=df20.dropna()\ndf20=df20.groupby(by=['Date'], as_index=False)['Weekly_Sales'].sum()\ndf20 = df20.set_index('Date')\ndf20.head()","7f370a2b":"plt.figure(figsize=(20,5))\nplt.plot(df20.index, df20.values)\nplt.show()","ab8cf7d1":"fig, axes = plt.subplots(1,2, figsize=(20,5))\nplot_acf(df20.values, lags=100, alpha=0.05, ax=axes[0])\nplot_pacf(df20.values, lags=100, alpha=0.05, ax=axes[1])\nplt.show()","10beb7d6":"orders=np.array([1,6,29,46,52])\ncoef, intercept = fit_ar_model(df20,orders)\npred=pd.DataFrame(index=df20.index, data=predict_ar_model(df20, orders, coef, intercept))\nplt.figure(figsize=(20,5))\nplt.plot(df20, 'o')\nplt.plot(pred)\nplt.show()","cf5fcc31":"diff=(df20['Weekly_Sales']-pred[0])\/df20['Weekly_Sales']\n\nprint('AR Residuals: avg %.2f, std %.2f' % (diff.mean(), diff.std()))\n \nplt.figure(figsize=(20,5))\nplt.plot(diff, c='orange')\nplt.grid()\nplt.show()","acde862e":"dfext=df.where( df['Store'] == 20)\ndfext=dfext.dropna()\ndfext=dfext.groupby(by=['Date'], as_index=False)[['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', \n                                                  'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']].mean()\ndfext = dfext.set_index('Date')\ndfext.head()","6d771983":"dfext.describe()","fe9c6f78":"dfext['shifted_sales'] = df20.shift(-1)\ndfext.head()","343eeb18":"import seaborn as sns\ncorr = dfext.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(corr, \n            annot=True, fmt=\".3f\",\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)\nplt.show()","eadb224b":"corr['shifted_sales'].sort_values(ascending=False)","75e421c6":"def fit_ar_model_ext(ts, orders, ext, fitter=LinearRegression()):\n    \n    X=np.array([ ts.values[(i-orders)].squeeze() if i >= np.max(orders) else np.array(len(orders) * [np.nan]) for i in range(len(ts))])\n    \n    X = np.append(X, ext.values, axis=1)\n    \n    mask = ~np.isnan(X[:,:1]).squeeze()\n    \n    Y= ts.values\n    \n    fitter.fit(X[mask],Y[mask].ravel())\n    \n    print(fitter.coef_, fitter.intercept_)\n\n    print('Score factor: %.2f' % fitter.score(X[mask],Y[mask]))\n    \n    return fitter.coef_, fitter.intercept_\n    \ndef predict_ar_model_ext(ts, orders, ext, coef, intercept):\n\n    X=np.array([ ts.values[(i-orders)].squeeze() if i >= np.max(orders) else np.array(len(orders) * [np.nan]) for i in range(len(ts))])\n    \n    X = np.append(X, ext.values, axis=1)\n    \n    return np.array( np.dot(X, coef.T) + intercept)","1100dda8":"#dfexte=dfext.drop(['shifted_sales'], axis=1)\ndfexte=dfext[['Unemployment','Fuel_Price','CPI','Temperature',\n              'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']]\n\norders=np.array([1,6,29,46,52])\ncoef, intercept = fit_ar_model_ext(df20,orders,dfexte)\npred_ext=pd.DataFrame(index=df20.index, data=predict_ar_model_ext(df20, orders, dfexte, coef, intercept))\nplt.figure(figsize=(20,5))\nplt.plot(df20, 'o')\nplt.plot(pred)\nplt.plot(pred_ext)\nplt.show()","4467cf6d":"diff=(df20['Weekly_Sales']-pred[0])\/df20['Weekly_Sales']\ndiff_ext=(df20['Weekly_Sales']-pred_ext[0])\/df20['Weekly_Sales']\n\nprint('AR Residuals: avg %.2f, std %.2f' % (diff.mean(), diff.std()))\nprint('AR wiht Ext Residuals: avg %.2f, std %.2f' % (diff_ext.mean(), diff_ext.std()))\n \nplt.figure(figsize=(20,5))\nplt.plot(diff, c='orange', label='w\/o external variables')\nplt.plot(diff_ext, c='green', label='w\/ external variables')\nplt.legend()\nplt.grid()\nplt.show()","0fb9bf94":"This particular store shows additional seasonalities from week 29 and 46 which will be included in the AR model.","89e6cb06":"![](http:\/\/)The external variables available have some correlation with the 1-day lagged sales time series. This means that they have some degree of predictive power at 1 day and can be used to improve our model. The 'MarkDown' and the 'Temperature' being the most correlated and anti-correlate variables respectively.","2cabd694":"# Gain some graphical insight","d31b618a":"# Merge the data in a unique DataFrame","cfb07090":"### Look for predictive power from external variables","48af6319":"# Get more insights","d1001956":"# Model definition\nSince the AR model implemented in the statsmodels library allows to include only consecutive seasonality terms, I implement the model manually. In this way I can use non consecutive seasonality terms like weeks 1, 6, 52 as observed from the correlation analysis.  ","e7179426":"# Forecast of the store-wise sales volume\nDevelop the forecast model for the store number 20, which shows the highest sales volume.","0d702050":"# Forecast of the total sales volume","d6a8ce54":"# To do next:\n\n* Apply the forecast model with external informations on each store and sum the result to forcast the total sales volume","9228f589":"# Check data and features","0d4ffd33":"# Import the data","d1a484ff":"Given the seasonality observed from the ACF and the PACF function, the AR model is implemented including seasonality from weeks (1,6,52).","6343fcff":"The predictive model has an R^2 score factor of 0.41 (max score for perfect prediction would be 1). The residual distribution is centered in 0 with an STD of 7%.","0921af12":"I used the retail data analytics to test a simple auto regressive (AR) model to forecast the sales volume using sales only and sales + external information. While the data might be used to draw many insights on this retail business, here I focus only on implementing the AR model to forecast the sales volume.","5bf2d6b7":"![](http:\/\/)The predictive model has an R^2 score factor of 0.34 (max score for perfect prediction would be 1.). The residual distribution is centered in 0 with an STD of 8%.","e4b445a0":"Sum the weekely sales from every shop to get the total weekly sales volume of the retail chain ","e43a02ca":"The model including the external variables improve the accuracy of the prediction by more than 40% ( R^2 score: 0.58 w.r.t 0.34). The standard deviation of the residual improve by about 30% (7% w.r.t. 8%).","9c276dda":"Plot some of the variable present in the data frame such as temperature, fuel price, CPI, unemployment rate, ..."}}