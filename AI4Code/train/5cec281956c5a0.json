{"cell_type":{"90469cd9":"code","a22a23a6":"code","de26b4cc":"code","b3e587c3":"code","025aedd9":"code","1fe15fd2":"code","b69c8b92":"code","b6169e32":"code","38de8007":"code","e9c57ee8":"code","f375c049":"code","8e7fe98c":"code","72ddf673":"code","ecdb95b3":"code","7badd01f":"code","e084e9ff":"code","b85f65f7":"code","f41d4af2":"code","88c0736e":"code","80767fcd":"code","cdef3d9a":"code","8f109763":"code","ae86c381":"code","d29ae44e":"code","07f727fb":"code","aa882668":"code","5431a49a":"code","4b9bff6d":"code","229a8253":"code","f775c31b":"code","6247bffa":"code","ab0d2275":"code","dea513bf":"code","97edb579":"code","deb322e0":"code","346966d3":"code","506e6a9c":"code","68328f3c":"code","00c7a1db":"code","34a15ce8":"code","4ffcbc5f":"code","cd5cb57b":"code","7f5ea7c5":"code","77134f22":"code","eeecaa3b":"code","07b5a28d":"code","d9b996f9":"code","e25edffc":"code","483d479b":"code","fb055d94":"code","1a712757":"code","36a69d29":"code","227fe66a":"code","a27d7793":"code","ca909a88":"code","4d8265db":"code","878c4401":"code","35df0b6c":"code","bfa8dfe2":"code","9f762842":"code","67fc91fe":"code","54bbc7f5":"code","a599630e":"code","939d6fe3":"code","921f2320":"code","b7b0e8e9":"code","9e40a03e":"code","2ee7a952":"code","74079185":"code","a43a2036":"code","da2936c2":"code","46846bd7":"code","f0bd9a59":"code","df9fc286":"code","5b2d3690":"code","c74ef24e":"code","b6f08704":"code","de1b6f5e":"code","50dffaa6":"code","d5703f5f":"code","0f544361":"code","ee6df5bf":"code","00c205ba":"code","8431d2ed":"code","26b422a7":"code","49f7e261":"code","bd4c9c3b":"code","311b646e":"code","2c261ada":"code","588d564f":"code","dc82fd70":"code","943bea1c":"code","60aba868":"code","0f9b1a46":"code","37620a43":"code","beebe9fe":"code","1109ad18":"code","ab9bf8b7":"code","21bc18af":"code","ce9549cc":"code","3645e3cf":"code","33d62190":"code","ad7537d4":"code","2ec3cbcd":"code","da7acd8f":"code","a6bd78c0":"code","27ecd3c6":"code","92971e0d":"code","24af2f52":"code","1cf8dff2":"code","7563ad1a":"code","8f139002":"code","b6632865":"code","cd77ee53":"code","1fdb3114":"code","38e603e8":"code","88654302":"code","3e8a0ea8":"code","d03897ce":"code","c5a2fb95":"code","ad45963b":"code","606e592d":"code","4d32a0c7":"code","9cfb51e5":"code","d24a7d24":"code","82e8c711":"code","569f5dd3":"code","33ef59a0":"code","ccc4325e":"code","1c7953e4":"code","0edeec70":"code","aabb8a75":"code","ef42d250":"code","a056ca94":"code","94a161c7":"code","bc20d734":"code","d2ed73b3":"code","faaf695b":"markdown","d4a64662":"markdown","877e4070":"markdown","e25a80d1":"markdown","23732ce9":"markdown","c814b31f":"markdown","4036b3fc":"markdown","c3aba3fe":"markdown","660e4a5c":"markdown","59fab0ca":"markdown","1fd862f4":"markdown","77381d50":"markdown","a8aa4832":"markdown","cced9bbd":"markdown","295a14fa":"markdown","0a29909c":"markdown","bf933dd2":"markdown","db6d0851":"markdown","8bf69078":"markdown","e61e5c85":"markdown","d8f7d6ed":"markdown"},"source":{"90469cd9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport math\nimport matplotlib\n\n# For versioning\n\n# Print Versions for sharing Projects\nprint(\"Pandas Version : Pandas {}\".format(pd.__version__))\n\nprint(f\"Pandas Version : Pandas {pd.__version__}\") # print(\"Pandas Version : Pandas {}\" ,pd.__version__ )\nprint(f\"Numpy Version : Numpy {np.__version__}\")\nprint(f\"Matplotlib Version : Matplotlib {matplotlib.__version__}\")\nprint(f\"Seaborn Version : Seaborn {sns.__version__}\")\n\n# Magic Functions for In-Notebook Display\n\n%matplotlib inline","a22a23a6":"df = pd.read_csv('..\/input\/creditcardata\/creditcard.csv')","de26b4cc":"df.shape","b3e587c3":"df.head()","025aedd9":"df.tail()","1fe15fd2":"pd.options.display.max_rows = 100\npd.options.display.max_columns = 100","b69c8b92":"df.head()","b6169e32":"df['Class'].value_counts()","38de8007":"df['Amount'].max()","e9c57ee8":"df['Amount'].describe()","f375c049":"df[['Time','Amount','Class']].describe().T","8e7fe98c":"plt.figure(figsize=(8,6))\nplt.title('Distribution of Transaction Amount', fontsize=14)\nsns.distplot(df['Amount'], bins=100)\nplt.show()","72ddf673":"plt.subplots(figsize=(6,4))\nsns.distplot(df[df['Class'] == 1]['Amount'], bins=100)\nplt.title(\"Distribution of Fraud Transactions\")\nplt.show()","ecdb95b3":"sns.distplot(df[df['Class'] == 0]['Amount'], bins=100)\nplt.title(\"Distribution of Genuine Transactions\")\n\nplt.show()","7badd01f":"df[\"Class\"].value_counts().plot(kind = 'pie',explode=[0, 0.1],figsize=(6, 6),autopct='%1.1f%%',shadow=True)\nplt.title(\"Fraudulent and Non-Fraudulent Distribution\",fontsize=20)\nplt.legend([\"Fraud\", \"Genuine\"])\nplt.show()","e084e9ff":"print(\"Fraud Transaction distribution : \\n\",df[(df['Class'] == 1)]['Amount'].value_counts().head())\nprint(\"\\n\")\nprint(\"Maximum amount of fraud transaction - \",df[(df['Class'] == 1)]['Amount'].max())\nprint(\"Minimum amount of fraud transaction - \",df[(df['Class'] == 1)]['Amount'].min())","b85f65f7":"plt.figure(figsize=(8,6))\nplt.title('Distribution of Transaction Time', fontsize=14)\nsns.distplot(df['Time'], bins=100)\nplt.show()","f41d4af2":"fig, axs = plt.subplots(ncols=2, figsize=(16,4))\n\nsns.distplot(df[(df['Class'] == 1)]['Time'], bins=100, color='red', ax=axs[0])\naxs[0].set_title(\"Distribution of Fraud Transactions\")\n\nsns.distplot(df[(df['Class'] == 0)]['Time'], bins=100, color='green', ax=axs[1])\naxs[1].set_title(\"Distribution of Genuine Transactions\")\n\nplt.show()","88c0736e":"fig, axs = plt.subplots(nrows=2,sharex=True,figsize=(16,6))\n\nsns.scatterplot(x='Time',y='Amount', data=df[df['Class']==1], ax=axs[0])\naxs[0].set_title(\"Distribution of Fraud Transactions\")\n\nsns.scatterplot(x='Time',y='Amount', data=df[df['Class']==0], ax=axs[1])\naxs[1].set_title(\"Distribution of Genue Transactions\")\n\nplt.show()","80767fcd":"plt.figure(figsize = (8,4) , dpi = 100)\nsns.boxplot(x =\"Class\",y=\"Amount\", data=df) \nplt.show()","cdef3d9a":"def indicies_of_outliers(x): \n    q1, q3 = np.percentile(x, [25, 75]) \n    iqr = q3 - q1 \n    lower_bound = q1 - (iqr * 3) \n    upper_bound = q3 + (iqr * 3)\n    \n    \n    return np.where((x > upper_bound) | (x < lower_bound))","8f109763":"indicies_of_outliers(df['Amount'])","ae86c381":"q1,q3 = np.percentile(df['Amount'], [25, 75])","d29ae44e":"q1","07f727fb":"q3","aa882668":"iqr=q3-q1\niqr","5431a49a":"lower_bound = q1 - (iqr * 3)\nlower_bound","4b9bff6d":"len(indicies_of_outliers(df['Amount'])[0])","229a8253":"len(df)","f775c31b":"len(indicies_of_outliers(df['Amount'])[0])\/len(df)","6247bffa":"# Can't afford to lose 6.7% of data so we are going to remove outlier through different way, Max Value reduction","ab0d2275":"df[df.index.isin(list(indicies_of_outliers(df['Amount'])[0]))]","dea513bf":"df[df.index.isin(list(indicies_of_outliers(df['Amount'])[0]))]['Class'].value_counts(normalize = True)","97edb579":"df.head()","deb322e0":"def outlier_removal(max_val):\n    print(\"Values Lost on the basis of MAX based Removal : {}\".format(len(df[(df['Class']==0) &(df['Amount']>max_val)])))\n    \n    print(\"Proportion of Data Lost : {}\".format(len(df[(df['Class']==0) &(df['Amount']>max_val)])\/len(df)))\n    \n    temp_df = df[df['Amount']<max_val] # Outlier Removed DF\n    print(temp_df['Class'].value_counts(normalize = True))","346966d3":"outlier_removal(df[df['Class']==1]['Amount'].max())","506e6a9c":"q=df[(df['Amount']>2125.87)]['Amount']","68328f3c":"df=df.drop(q.index)","00c7a1db":"df.shape","34a15ce8":"df.head()","4ffcbc5f":"df['Class'].value_counts()","cd5cb57b":"plt.figure(figsize = (8,4) , dpi = 100)\nsns.boxplot(x =\"Class\",y=\"Amount\",\n                 data=df)\nplt.show()","7f5ea7c5":"df.isnull().sum()","77134f22":"print(len(df.drop_duplicates()))\nprint(len(df[df.duplicated()]))","eeecaa3b":"df=df.drop_duplicates()","07b5a28d":"df.shape","d9b996f9":"df.columns = df.columns.str.lower()","e25edffc":"df.reset_index(inplace = True , drop = True)","483d479b":"fig, axs = plt.subplots(ncols=2,figsize=(12,6))\n\nsns.distplot(df['amount'], bins=100, ax=axs[0])\naxs[0].set_title(\"Amount Distribution\")\n\nsns.boxplot(x='class', y='amount',data = df, ax=axs[1])\naxs[1].set_title(\"Dsitribution of Amount wrt Class\")\nplt.show()","fb055d94":"df['class'].value_counts(normalize=True)","1a712757":"# Converting time from second to hour\ndf['time'] = df['time'].apply(lambda sec : (sec\/3600))","36a69d29":"# Calculating hour of the day\ndf['hour'] = df['time']%24   # 2 days of data\ndf['hour'] = df['hour'].apply(lambda x : math.floor(x))","227fe66a":"# Calculating First and Second day\ndf['day'] = df['time']\/24   # 2 days of data\ndf['day'] = df['day'].apply(lambda x : 1 if(x==0) else math.ceil(x))","a27d7793":"df[['time','hour','day','amount','class']]","ca909a88":"# calculating fraud transaction daywise\ndayFrdTran = df[(df['class'] == 1)]['day'].value_counts()\n# calculating genuine transaction daywise\ndayGenuTran = df[(df['class'] == 0)]['day'].value_counts()\n# calculating total transaction daywise\ndayTran = df['day'].value_counts()\n\nprint(\"No of transaction Day wise:\")\nprint(dayTran)\n\nprint(\"\\n\")\n\nprint(\"No of fraud transaction Day wise:\")\nprint(dayFrdTran)\n\nprint(\"\\n\")\n\nprint(\"No of genuine transactions Day wise:\")\nprint(dayGenuTran)\n\nprint(\"\\n\")\n\nprint(\"Percentage of fraud transactions Day wise:\")\nprint((dayFrdTran\/dayTran)*100)","4d8265db":"# Time plots \nfig , axs = plt.subplots(nrows = 1 , ncols = 2 , figsize = (15,8))\n\nsns.distplot(df[df['class']==0]['time'].values , color = 'green' , ax = axs[0])\naxs[0].set_title('Genuine Transactions')\n\nsns.distplot(df[df['class']==1]['time'].values , color = 'red' ,ax = axs[1])\naxs[1].set_title('Fraud Transactions')\n\nfig.suptitle('Comparison between Transaction Frequencies vs Time for Fraud and Genuine Transactions')\nplt.show()","878c4401":"# Let's see if we find any particular pattern between time ( in hours ) and Fraud vs Genuine Transactions\n\nplt.figure(figsize=(12,10))\n\nsns.distplot(df[df['class'] == 0][\"hour\"], color='green') # Genuine - green\nsns.distplot(df[df['class'] == 1][\"hour\"], color='red') # Fraudulent - Red\n\nplt.title('Fraud vs Genuine Transactions by Hours', fontsize=15)\nplt.xlim([0,25])\nplt.show()","35df0b6c":"df.hist(figsize = (25,25))\nplt.show()","bfa8dfe2":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\ndf['ScaledAmount']=scaler.fit_transform(df[['amount']])\ndf['ScaledAmount'].tail()","9f762842":"df['ScaledTime']=scaler.fit_transform(df[['time']])\ndf['ScaledTime'].tail()","67fc91fe":"df[['time','ScaledTime','amount','ScaledAmount','class']].tail()","54bbc7f5":"df","a599630e":"y = df['class'].values\n\nX = df.drop(columns = (['time','ScaledTime','amount','hour','day','class']))","939d6fe3":"X","921f2320":"from sklearn.linear_model import LogisticRegression # Importing Classifier Step\nfrom sklearn.model_selection import train_test_split","b7b0e8e9":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) # Sequence for splitting\n\n\nlogreg = LogisticRegression() # () towards the end\nlogreg.fit(X_train, y_train) ","9e40a03e":"logreg.get_params()","2ee7a952":"y_pred = logreg.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\n\n\nprint(accuracy_score(y_pred , y_test))","74079185":"pd.Series(y_pred).value_counts()","a43a2036":"pd.Series(y_test).value_counts()","da2936c2":"101\/153","46846bd7":"from sklearn.metrics import confusion_matrix\ncnf_matrix = confusion_matrix(y_test , y_pred)\n\ncnf_matrix","f0bd9a59":"sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","df9fc286":"91\/153","5b2d3690":"pd.Series(y_test).value_counts()","c74ef24e":"pd.Series(y_pred).value_counts()","b6f08704":"101\/153","de1b6f5e":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_test , y_pred) \n","50dffaa6":"y_pred_proba = logreg.predict_proba(X_test)\ny_pred_proba","d5703f5f":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\ny_pred_proba = logreg.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","0f544361":"# Accuracy Score - 99.91%\n# Recall Value - 59.48%\n# Roc- Auc Score - 79.73%","ee6df5bf":"from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\nfrom imblearn.over_sampling import SMOTE, ADASYN\nfrom imblearn.under_sampling import RandomUnderSampler","00c205ba":"from collections import Counter # counter takes values returns value_counts dictionary\nfrom sklearn.datasets import make_classification\n\nprint('Original dataset shape %s' % Counter(y))\n\nrus = RandomUnderSampler(random_state=42)\nX_res, y_res = rus.fit_resample(X, y)\n\nprint('Resampled dataset shape %s' % Counter(y_res))","8431d2ed":"X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=0)\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)","26b422a7":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(y_pred , y_test))","49f7e261":"y_pred_proba = logreg.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","bd4c9c3b":"from imblearn.over_sampling import RandomOverSampler","311b646e":"print('Original dataset shape %s' % Counter(y))\nrandom_state = 42\n\nrus = RandomOverSampler(random_state=random_state)\n\nX_res, y_res = rus.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))\n","2c261ada":"X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=0)\nlogreg = LogisticRegression()\n\nlogreg.fit(X_train, y_train)","588d564f":"y_pred = logreg.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_pred , y_test))  # Accuracy is surely reducedd , let's look at the roc curve now\n","dc82fd70":"y_pred_proba = logreg.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","943bea1c":"from imblearn.over_sampling import SMOTE, ADASYN","60aba868":"print('Original dataset shape %s' % Counter(y))\n\nrus = SMOTE(random_state=42)\n\nX_res, y_res = rus.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))","0f9b1a46":"X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=0)\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","37620a43":"y_pred = logreg.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_pred , y_test))  # Accuracy is surely reducedd , let's look at the roc curve now","beebe9fe":"y_pred_proba = logreg.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","1109ad18":"print('Original dataset shape %s' % Counter(y))\n\nrus = ADASYN(random_state=42)\n\nX_res, y_res = rus.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))","ab9bf8b7":"X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=0)\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","21bc18af":"y_pred = logreg.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_pred , y_test))  # Accuracy is surely reducedd , let's look at the roc curve now","ce9549cc":"y_pred_proba = logreg.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","3645e3cf":"rus = RandomUnderSampler(random_state=42)\nX_under, y_under = rus.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_under))","33d62190":"rus = RandomOverSampler(random_state=42)\nX_over, y_over = rus.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_over))","ad7537d4":"rus = SMOTE(random_state=42)\nX_smote, y_smote = rus.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_smote))","2ec3cbcd":"from sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","da7acd8f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n\ndte = DecisionTreeClassifier()\ndte.fit( X_train, y_train )\n\n\n\n\ny_pred = dte.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = dte.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","a6bd78c0":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","27ecd3c6":"# Undersampled data with Decision Tree Classifiers\n\nX_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.3, random_state=0)\ndte = DecisionTreeClassifier()\ndte.fit(X_train, y_train)\n\ny_pred = dte.predict(X_test)\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = dte.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","92971e0d":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","24af2f52":"# Oversampled data with Decision Tree Classifiers # Best model after Classifier - DTE\n\nX_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.3, random_state=0)\ndte = DecisionTreeClassifier()\ndte.fit(X_train, y_train)\n\ny_pred = dte.predict(X_test)\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = dte.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","1cf8dff2":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","7563ad1a":"# SMOTE data with Decision Tree Classifiers\n\nX_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.3, random_state=0)\ndte = DecisionTreeClassifier()\ndte.fit(X_train, y_train)\n\ny_pred = dte.predict(X_test)\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = dte.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","8f139002":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","b6632865":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nrfc = RandomForestClassifier()\nrfc.fit( X_train, y_train )\n\ny_pred = rfc.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))","cd77ee53":"y_pred_proba = rfc.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","1fdb3114":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","38e603e8":"X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.3, random_state=0)\nrfc = RandomForestClassifier()\nrfc.fit( X_train, y_train )\n\ny_pred = rfc.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = rfc.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","88654302":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","3e8a0ea8":"X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.3, random_state=0)\nrfc = RandomForestClassifier()\nrfc.fit( X_train, y_train )\n\ny_pred = rfc.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = rfc.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","d03897ce":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","c5a2fb95":"X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.3, random_state=0)\nrfc = RandomForestClassifier()\nrfc.fit( X_train, y_train )\n\ny_pred = rfc.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = rfc.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","ad45963b":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","606e592d":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nsvm = SVC()\nsvm.fit( X_train, y_train )\n\ny_pred = svm.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))","4d32a0c7":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","9cfb51e5":"X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.3, random_state=0)\nsvm = SVC()\nsvm.fit( X_train, y_train )\n\ny_pred = svm.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = rfc.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","d24a7d24":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","82e8c711":"X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.3, random_state=0)\nsvm = SVC()\nsvm.fit( X_train, y_train )\n\ny_pred = svm.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = rfc.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","569f5dd3":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","33ef59a0":"X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.3, random_state=0)\nsvm = SVC()\nsvm.fit( X_train, y_train )\n\ny_pred = svm.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = rfc.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","ccc4325e":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","1c7953e4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nknc = KNeighborsClassifier()\nknc.fit( X_train, y_train )\n\ny_pred = knc.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = rfc.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","0edeec70":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","aabb8a75":"X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.3, random_state=0)\nknc = KNeighborsClassifier()\nknc.fit( X_train, y_train )\n\ny_pred = knc.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = rfc.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","ef42d250":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","a056ca94":"X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.3, random_state=0)\nknc = KNeighborsClassifier()\nknc.fit( X_train, y_train )\n\ny_pred = knc.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = rfc.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","94a161c7":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","bc20d734":"X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.3, random_state=0)\nknc = KNeighborsClassifier()\nknc.fit( X_train, y_train )\n\ny_pred = knc.predict(X_test)\n\nprint(accuracy_score(y_pred , y_test))\n\ny_pred_proba = rfc.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","d2ed73b3":"cnf_matrix = confusion_matrix(y_test , y_pred)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","faaf695b":"# Importing Libraries","d4a64662":"# Decision Tree Classifier with Baseline, Under Sampled, Over Sampled and Smote","877e4070":"# Null detection","e25a80d1":"# Importing Different Models","23732ce9":"# Scaling of Amount and Time","c814b31f":"# Data Visulization","4036b3fc":"# We were able to accurately identify fraudulent credit card transactions using a random forest model with oversampling technique. We, therefore, chose the random forest model with oversampling technique as the better model, which obtained recall score of 99.98% on the test set with least error ( i.e 10 misclassification)","c3aba3fe":"# Random Forest Classifier with Under Sampled, Over Sampled and Smote","660e4a5c":"# Under sampled, Over Sampled and Smote with LR ","59fab0ca":"# Duplicate Data Removal","1fd862f4":"# Cross Validation and Baseline Modelling through Logistic Regression","77381d50":"# Outlier Removal","a8aa4832":"# Feature Enginering","cced9bbd":"# Best Model - Over Sampled Random Forest Classifier","295a14fa":"# Initializing Under,Over and Smote","0a29909c":"# Exploratory Data Analysis","bf933dd2":"# Importing Dataset","db6d0851":"# Outlier Detection","8bf69078":"# KNeighbors Classifier with Under Sampled, Over Sampled and Smote","e61e5c85":"# Data Imbalance","d8f7d6ed":"# Support Vector Classifier with Under Sampled, Over Sampled and Smote"}}