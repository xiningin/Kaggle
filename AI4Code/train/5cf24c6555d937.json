{"cell_type":{"666beb60":"code","eeb3b8dd":"code","96c502ba":"code","ffd88cd8":"code","e2ecc11f":"code","933d17cc":"code","a89aa4a5":"code","b37fbb94":"code","14c546fc":"code","046cc013":"code","a07ae750":"code","8a8a4eb1":"code","3bd9992d":"code","3d0b8c47":"code","8220617f":"code","1b57d9e3":"markdown","13e2b5e7":"markdown","a7ee8982":"markdown","b065ab15":"markdown","a0eb1b93":"markdown","36576bc7":"markdown","ae6c0f02":"markdown","7032576f":"markdown","037bdf7d":"markdown"},"source":{"666beb60":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport warnings\n\nimport catboost as cb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\n\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier\n\nfrom sklearn.metrics import accuracy_score\n\n\nwarnings.filterwarnings('ignore')\n","eeb3b8dd":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","96c502ba":"print(train.info())\nprint(\"\\n\",\"Percentage of NAN Values:\",\"\\n\")\nprint(train.isnull().sum() * 100 \/ len(train))\n\ntrain.head(15)","ffd88cd8":"train = pd.read_csv('..\/input\/titanic\/train.csv')\n\n\n#Factorize Sex\ndef factorize_var(train):\n    change = {'female':0,'male':1}\n    train['sex'] = train['Sex'].map(change)\n    changeE = {'S':0,'C':1,'Q':2}\n    train['embarked'] = train['Embarked'].map(changeE)\n    \ndef family_size(train):\n    train['family_size'] = train['SibSp'] + train['Parch'] + 1\n\ndef alone(train):\n    train['alone'] = 0\n    train.loc[ (train['family_size'] == 1) ,'alone'] = 1\n\ndef fill_age(train):\n    from sklearn.ensemble import RandomForestRegressor\n    cols = [ 'Pclass', 'SibSp',\n           'Parch', 'Fare',  'sex', 'embarked', 'family_size', 'alone']\n    X_age = train[train['Age'] > 0][cols]\n    y_age = train[train['Age'] > 0][\"Age\"]\n    X_age_test = train[train['Age'] == 0][cols]\n    x_train,x_test,y_train,y_test = train_test_split(X_age,y_age,test_size = 0.2,random_state = 42)\n    model = RandomForestRegressor()\n    model.fit(x_train, y_train)\n    predicted_age = model.predict(X_age_test)\n    train.loc[train['Age'] == 0 , \"Age\"] =  predicted_age \ndef scale(train):\n    from sklearn.preprocessing import QuantileTransformer\n    quantile = QuantileTransformer()\n    train[\"Age\"] =quantile.fit_transform(train[\"Age\"].to_numpy().reshape((train[\"Age\"].shape[0],1)))\n    train[\"Fare\"] =quantile.fit_transform(train[\"Fare\"].to_numpy().reshape((train[\"Fare\"].shape[0],1)))\n\n    \n\n    \n\n    \n    \n    \n    \ndef processing(train):\n    train = train.drop(columns=['Cabin'])\n    train = train[~(train['Embarked'].isna())]\n    train[\"Age\"].fillna(0 , inplace=True)\n    train[\"Fare\"].fillna(0 , inplace=True)\n\n\n    factorize_var(train)\n    family_size(train)\n    alone(train)\n    fill_age(train)\n    scale(train)\n    \n    \n    return train\n    \n    \n\ntrain = processing(train)\ntrain\n    ","e2ecc11f":"train.info()","933d17cc":"fig,axis = plt.subplots(1, 6, figsize=(24, 4))\n\ncolumns_0 = ['Pclass','Sex','Embarked','SibSp','Parch','alone']\ni= 0\nfor col in columns_0:   \n    \n    sns.countplot(data=train, x= col ,hue='Survived' , ax = axis[i])\n    axis[i].set_title(f'Survived vs {col}')\n    i = i + 1","a89aa4a5":"fig,axis = plt.subplots(1, 3 ,figsize=(24, 5))\nsns.boxplot(x='Survived', y='Age', data=train, palette='Set3', ax = axis[0])\naxis[0].set_title(f'Survived vs Age')\n\nsns.boxplot(x='Survived', y='Fare', data=train, palette='Set3', ax = axis[1])\naxis[1].set_title(f'Survived vs Fare')\n\nsns.scatterplot(data=train, x='Age', y='Fare', hue='Survived', ax = axis[2])\naxis[1].set_title(f'Age vs Fare vs Survived')\n","b37fbb94":"fig,axis = plt.subplots(1, 2, figsize=(24, 9))\n\nsns.heatmap(train.corr(), annot=True,cmap='vlag', ax = axis[0])\naxis[0].set_title('Pearson')\nsns.heatmap(train.corr(method='spearman'), annot=True,cmap='vlag', ax = axis[1])\naxis[1].set_title('Spearman')\n# sns.heatmap(train.corr(method='kendall'), annot=True,cmap='vlag', ax = axis[2])\n# axis[2].set_title('Kendall')","14c546fc":"Features = [ 'Pclass',  'Age', 'SibSp',\n       'Parch', 'Fare',  'sex', 'embarked', 'family_size', 'alone']\n\nX = train[Features]\ny = train[\"Survived\"]\n\n\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.23 ,random_state = 96)\nmodel_lr = LogisticRegression(C= 5  ,penalty='l2',solver='liblinear')\nmodel_lr.fit(x_train, y_train)\ny_pred = model_lr.predict(x_test)\n\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)*100}')\n# for i in range (1,151):\n#     size = i *0\n#     print(size)","046cc013":"Features = [ 'Pclass',  'Age', 'SibSp',\n       'Parch', 'Fare',  'sex', 'embarked', 'family_size', 'alone']\n\nX = train[Features]\ny = train[\"Survived\"]\n\n\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.21 ,random_state = 96)\n\nknn = KNeighborsClassifier(n_neighbors= 12 ,algorithm='ball_tree',n_jobs=-1 , leaf_size = 30 )\nknn.fit(x_train, y_train)\n\ny_pred = knn.predict(x_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)*100}')","a07ae750":"Features = [ 'Pclass',  'Age', 'SibSp',\n       'Parch', 'Fare',  'sex', 'embarked', 'family_size', 'alone']\n\nX = train[Features]\ny = train[\"Survived\"]\n\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.21 ,random_state = 96)\n\nforest = RandomForestClassifier(n_estimators = 25 , random_state= 88 , min_samples_split = 2 , min_samples_leaf = 5,criterion='entropy')\nforest.fit(x_train, y_train)\n\ny_pred = forest.predict(x_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)*100}')","8a8a4eb1":"Features = [ 'Pclass',  'Age', 'SibSp',\n       'Parch', 'Fare',  'sex', 'embarked', 'family_size', 'alone']\n\nX = train[Features]\ny = train[\"Survived\"]\n\n# for i in range(1,10):\n#     size = i \n#     print(size)\n#     x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.21 ,random_state = 96)\n\n#     svc = SVC(C = 1 , kernel= 'poly' , degree = size)\n\n#     svc.fit(x_train, y_train)\n\n#     y_pred = svc.predict(x_test)\n#     print(f'Accuracy: {accuracy_score(y_test, y_pred)*100}')\n    \nsvc = SVC(C = 1 , kernel= 'poly' , degree = 4)\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)*100}')\n","3bd9992d":"Features = [ 'Pclass',  'Age', 'SibSp',\n       'Parch', 'Fare',  'sex', 'embarked', 'family_size', 'alone']\n\nX = train[Features]\ny = train[\"Survived\"]\n\n\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.21 ,random_state = 96)\n\nrnd_clf = RandomForestClassifier(n_estimators = 25 , random_state= 88 , min_samples_split = 2 , min_samples_leaf = 5,criterion='entropy')\nsvm_clf = SVC(C = 1 , kernel= 'poly' , degree = 4)\n\nknn_clf = KNeighborsClassifier(n_neighbors= 12 ,algorithm='ball_tree',n_jobs=-1 , leaf_size = 30 )\n\n\nvoting_clf = VotingClassifier(\n    estimators=[ ('rf', rnd_clf), ('svc', svm_clf),('knn',knn_clf)],\n    voting='hard')\n\nvoting_clf.fit(x_train, y_train)\ny_pred = voting_clf.predict(x_test)\n\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)*100}')\n","3d0b8c47":"   \nFeatures = [ 'Pclass',  'Age', 'SibSp',\n       'Parch', 'Fare',  'sex', 'embarked', 'family_size', 'alone']\n\nX = train[Features]\ny = train[\"Survived\"]\n\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.23 ,random_state = 96)\ncat_model = cb.CatBoostClassifier(depth=2,iterations= 1000,\n                    learning_rate= 0.03 ,l2_leaf_reg=0.0025, silent=True)\ncat_model.fit(x_train, y_train)\nprint(\"Accuracy: \",cat_model.score(x_test, y_test) * 100)\n\n","8220617f":"test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest.head()\ntest = processing(test)\nx_test  = test[Features]\npred = svc.predict(x_test)\n\nsubmission_file = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsubmission_file['Survived'] = pred\nsubmission_file.to_csv('gender_submission.csv', index=False)","1b57d9e3":"#  Building the model","13e2b5e7":"**Catboost**","a7ee8982":"# Feature Engineering","b065ab15":"**KNN**","a0eb1b93":"**Random Forest**","36576bc7":"**SVM**","ae6c0f02":"# Data Exploration","7032576f":"**Logestic Regression**","037bdf7d":"**Voting**"}}