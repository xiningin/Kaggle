{"cell_type":{"1ae3a49a":"code","196d60bf":"code","7efefcb8":"code","0b241f80":"code","591fd375":"code","b90db608":"code","7bbce15e":"code","00352df7":"code","f92a8250":"code","5ac69864":"code","eb5d926f":"code","44040c65":"code","4fb953ab":"code","628723d9":"code","fcfbabf4":"code","98174293":"code","32014eba":"code","e9fa33fc":"code","59b81aee":"code","0fa1eaab":"markdown","da07d46b":"markdown","109358b1":"markdown","970fb297":"markdown","682daf20":"markdown"},"source":{"1ae3a49a":"\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport os, cv2, random\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization\n","196d60bf":"import os\nprint(os.listdir(\"..\/input\"))","7efefcb8":"import zipfile\n\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n    \nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\",\"r\") as z:\n    z.extractall(\".\")","0b241f80":"train_image_list=os.listdir(\"train\")\ntest_image_list=os.listdir(\"test1\")","591fd375":"image_width=128\nimage_height=128\nimage_channels=3\nimage_size=(image_width,image_height)","b90db608":"filenames = train_image_list\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'cat':\n        categories.append(0)\n    else:\n        categories.append(1)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","7bbce15e":"df.head()","00352df7":"label=[]\nfor img in train_image_list:\n  label.append(img.split(\".\")[0])\nsns.countplot(label,palette=\"pastel\")\n\nplt.title(\"cats and dogs\")","f92a8250":"n =5\nfig, axes = plt.subplots(1, n, figsize=(20,20))\nfor i in range(n):\n    directory=random.choice(os.listdir(\".\/train\/\"))\n    img=cv2.imread(\".\/train\/\"+directory)\n    axes[i].imshow(img)\n    axes[i].axis(\"off\")\nplt.show()","5ac69864":"model=Sequential()\n\n#convolutional layer\n\nmodel.add(Conv2D(32,(3,3),activation=\"relu\",input_shape=(image_width,image_height,image_channels)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n#convolutional layer\nmodel.add(Conv2D(64,(3,3),activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n#convolutional layer\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#Flattening\nmodel.add(Flatten())\nmodel.add(Dense(512,activation=\"relu\"))\nmodel.add(BatchNormalization())\n\nmodel.add(Dense(2,activation=\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])","eb5d926f":"df[\"category\"]=df[\"category\"].replace({0:\"cat\",\n                                      1:\"dog\"})","44040c65":"train_df,validate_df=train_test_split(df,test_size=0.3,random_state=42)\ntrain_df=train_df.reset_index(drop=True)\nvalidate_df=validate_df.reset_index(drop=True)","4fb953ab":"total_train=train_df.shape[0]\ntotal_validate=train_df.shape[0]\nbatch_size=32","628723d9":"train_datagen=ImageDataGenerator(\nrotation_range=15,\nrescale=1.\/255,\nshear_range=0.1,\nzoom_range=0.2,\nhorizontal_flip=True,\nwidth_shift_range=0.1,\nheight_shift_range=0.1)\n\ntrain_generator=train_datagen.flow_from_dataframe(\ntrain_df,\n\"train\",\nx_col=\"filename\",\ny_col=\"category\",\ntarget_size=image_size,\nclass_mode=\"categorical\",\nbatch_size=batch_size)","fcfbabf4":"validation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"train\", \n    x_col='filename',\n    y_col='category',\n    target_size=image_size,\n    class_mode='categorical',\n    batch_size=batch_size\n)","98174293":"img_sample=random.choice(os.listdir(\"train\"))\nsample=cv2.imread(\"train\"+img_sample)\n\nexample_df = train_df.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"train\", \n    x_col='filename',\n    y_col='category',\n    target_size=image_size,\n    class_mode='categorical'\n)","32014eba":"plt.figure(figsize=(15,15))\nn=9\nfor i in range(n):\n    plt.subplot(3,3,i+1)\n    for X_batch, Y_batch in example_generator:\n        image=X_batch[0]\n        plt.imshow(image)\n        plt.axis(\"off\")\n        break\n        \nplt.tight_layout()\nplt.show()","e9fa33fc":"epochs=50\nhistory = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size\n)","59b81aee":"plt.plot(history.history[\"accuracy\"])\nplt.title(\"model accuracy\")\nplt.ylabel(\"accuracy\")\nplt.xlabel(\"epoch\")\nplt.legend([\"Train\"],loc=\"upper left\")","0fa1eaab":"# sample image","da07d46b":"# Fit the model","109358b1":"# \u0130mport library","970fb297":"# Build Model","682daf20":"# sample image"}}