{"cell_type":{"9960ab82":"code","6421ad50":"code","231344e8":"code","65168f6c":"code","36bd488b":"code","e77e31f8":"code","e0d7e190":"code","62363ebe":"code","d4ecd9ca":"code","e99d0546":"code","d087934e":"code","56fa5e63":"code","946055a1":"code","32883b89":"markdown","8dea8111":"markdown","2d99f84f":"markdown","4a7b14fc":"markdown","0e7576f8":"markdown","2ca41136":"markdown","cb00ebfb":"markdown","66c5f302":"markdown","d6a7185c":"markdown","03c912a0":"markdown","1f5350d4":"markdown","4659ccd1":"markdown"},"source":{"9960ab82":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6421ad50":"import numpy as np \nimport pandas as pd \nimport random \nimport matplotlib.pyplot as plt \nimport tensorflow as tf \nimport math \nimport pandas_datareader as data_reader \n\nfrom tqdm import tqdm_notebook , tqdm \nfrom collections import deque ","231344e8":"class AI_Trader():\n  \n  def __init__(self, state_size, action_space=3, model_name=\"AITrader\"): #Stay, Buy, Sell\n    \n    self.state_size = state_size\n    self.action_space = action_space\n    self.memory = deque(maxlen=2000)\n    self.inventory = []\n    self.model_name = model_name\n    \n    self.gamma = 0.95\n    self.epsilon = 1.0\n    self.epsilon_final = 0.01\n    self.epsilon_decay = 0.995\n    \n    self.model = self.model_builder()\n    \n  def model_builder(self):\n    \n    model = tf.keras.models.Sequential()\n    \n    model.add(tf.keras.layers.Dense(units=32, activation='relu', input_dim=self.state_size))\n    \n    model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n    \n    model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n    \n    model.add(tf.keras.layers.Dense(units=self.action_space, activation='linear'))\n    \n    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=0.001))\n    \n    return model\n  \n  def trade(self, state):\n    \n    if random.random() <= self.epsilon:\n      return random.randrange(self.action_space)\n    \n    actions = self.model.predict(state)\n    return np.argmax(actions[0])\n  \n  \n  def batch_train(self, batch_size):\n    \n    batch = []\n    for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n      batch.append(self.memory[i])\n      \n    for state, action, reward, next_state, done in batch:\n      reward = reward\n      if not done:\n        reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n        \n      target = self.model.predict(state)\n      target[0][action] = reward\n      \n      self.model.fit(state, target, epochs=1, verbose=0)\n      \n    if self.epsilon > self.epsilon_final:\n      self.epsilon *= self.epsilon_decay\n            \n        ","65168f6c":"def sigmoid(x):\n    return 1\/(1 + math.exp(-x))","36bd488b":"def stock_price_format(n):\n    if n < 0 :\n        return '- $ {:2f}'.format(abs(n))\n    else :\n        return '$ {:2f}'.format(abs(n))","e77e31f8":"def dataset_loader(stock_name):\n    \n    dataset = data_reader.DataReader(stock_name , data_source = 'yahoo')\n    \n    start_date = str(dataset.index[0]).split()[0]\n    end_date = str(dataset.index[-1]).split()[0]\n    \n    close = dataset['Close']\n    return close  ","e0d7e190":"# this is for example purpose for apple stocks \n\n\ndataset_for_example = data_reader.DataReader('AAPL' , data_source = 'yahoo')\ndataset_for_example\n","62363ebe":"def state_creator(data, timestep, window_size):\n  \n  starting_id = timestep - window_size + 1\n  \n  if starting_id >= 0:\n    windowed_data = data[starting_id:timestep+1]\n  else:\n    windowed_data = - starting_id * [data[0]] + list(data[0:timestep+1])\n    \n  state = []\n  for i in range(window_size - 1):\n    state.append(sigmoid(windowed_data[i+1] - windowed_data[i]))\n    \n  return np.array([state])","d4ecd9ca":"stock_name = 'AAPL'\ndata = dataset_loader(stock_name)\n\ndata ","e99d0546":"window_size = 10 \nepisodes = 1000\n\nbatch_size = 32\ndata_samples = len(data) - 1 \n","d087934e":"trader = AI_Trader(window_size)","56fa5e63":"trader.model.summary()","946055a1":" \n for episode in range(1, episodes + 1):\n  \n  print(\"Episode: {}\/{}\".format(episode, episodes))\n  \n  state = state_creator(data, 0, window_size + 1)\n  \n  total_profit = 0\n  trader.inventory = []\n  \n  for t in tqdm(range(data_samples)):\n    \n    action = trader.trade(state)\n    \n    next_state = state_creator(data, t+1, window_size + 1)\n    reward = 0\n    \n    if action == 1: #Buying\n      trader.inventory.append(data[t])\n      print(\"AI Trader bought: \", stock_price_format(data[t]))\n      \n    elif action == 2 and len(trader.inventory) > 0: #Selling\n      buy_price = trader.inventory.pop(0)\n      \n      reward = max(data[t] - buy_price, 0)\n      total_profit += data[t] - buy_price\n      print(\"AI Trader sold: \", stock_price_format(data[t]), \" Profit: \" + stock_price_format(data[t] - buy_price) )\n      \n    if t == data_samples - 1:\n      done = True\n    else:\n      done = False\n      \n    trader.memory.append((state, action, reward, next_state, done))\n    \n    state = next_state\n    \n    if done:\n      print(\"########################\")\n      print(\"TOTAL PROFIT: {}\".format(total_profit))\n      print(\"########################\")\n    \n    if len(trader.memory) > batch_size:\n      trader.batch_train(batch_size)\n      \n  if episode % 10 == 0:\n    trader.model.save(\"ai_trader_{}.h5\".format(episode))","32883b89":"# training loop ( # this training process will take time )","8dea8111":"# data set preprocessing ","2d99f84f":"## sigmoid ","4a7b14fc":"# building the AI trader network","0e7576f8":"# loading a dataset ","2ca41136":"# Training the AI trader","cb00ebfb":"## setting the hyper parameters ","66c5f302":"# dataset loader ","d6a7185c":"## price format function ","03c912a0":"## defining the trader model ","1f5350d4":"# state creator ","4659ccd1":"# importing the libararies "}}