{"cell_type":{"a409f557":"code","1fe402d0":"code","82790e25":"code","795f0438":"code","7ca2f2b2":"code","ae901cdd":"code","b44af2cb":"code","7139aed6":"code","95ba8b11":"code","0c98596e":"code","2194b336":"code","d48f9ffe":"code","ffb6101d":"code","1d5358eb":"code","c4db91ee":"code","089c9bca":"code","14f184a1":"code","bd92bbed":"code","efc4a154":"code","6cae8c6b":"code","9487b4a9":"code","f25ee107":"code","243eafbe":"code","f5ed13e8":"markdown","dbf75f53":"markdown","4b674f14":"markdown","f3c45e2e":"markdown","123fee6a":"markdown","1609f1bd":"markdown","b2197cea":"markdown","4f76ecaf":"markdown","57a9fdd4":"markdown","00dc0389":"markdown","18a90647":"markdown","f53b310a":"markdown"},"source":{"a409f557":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1fe402d0":"datrn = pd.read_csv('..\/input\/train.csv')\ndatst = pd.read_csv('..\/input\/test.csv')","82790e25":"datsub = pd.read_csv('..\/input\/gender_submission.csv')","795f0438":"datrn.head()","7ca2f2b2":"datst.head()","ae901cdd":"outcome = datrn['Survived']\ndata = datrn.drop('Survived',axis=1)","b44af2cb":"data.head()","7139aed6":"def accuracy_score(truth, pred):\n    \"\"\" Returns accuracy score for input truth and predictions. \"\"\"\n    \n    # Ensure that the number of predictions matches number of outcomes\n    if len(truth) == len(pred): \n        \n        # Calculate and return the accuracy as a percent\n        return \"Predictions have an accuracy of {:.2f}%.\".format((truth == pred).mean()*100)\n    \n    else:\n        return \"Number of predictions does not match number of outcomes!\"","95ba8b11":"import warnings\nwarnings.filterwarnings(\"ignore\", category = UserWarning, module = \"matplotlib\")\n#\n# Display inline matplotlib plots with IPython\nfrom IPython import get_ipython\nget_ipython().run_line_magic('matplotlib', 'inline')\n###########################################\nimport matplotlib.pyplot as plt\n\ndef filter_data(data, condition):\n    \"\"\"\n    Remove elements that do not match the condition provided.\n    Takes a data list as input and returns a filtered list.\n    Conditions should be a list of strings of the following format:\n      '<field> <op> <value>'\n    where the following operations are valid: >, <, >=, <=, ==, !=\n    \n    Example: [\"Sex == 'male'\", 'Age < 18']\n    \"\"\"\n\n    field, op, value = condition.split(\" \")\n    \n    # convert value into number or strip excess quotes if string\n    try:\n        value = float(value)\n    except:\n        value = value.strip(\"\\'\\\"\")\n    \n    # get booleans for filtering\n    if op == \">\":\n        matches = data[field] > value\n    elif op == \"<\":\n        matches = data[field] < value\n    elif op == \">=\":\n        matches = data[field] >= value\n    elif op == \"<=\":\n        matches = data[field] <= value\n    elif op == \"==\":\n        matches = data[field] == value\n    elif op == \"!=\":\n        matches = data[field] != value\n    else: # catch invalid operation codes\n        raise Exception(\"Invalid comparison operator. Only >, <, >=, <=, ==, != allowed.\")\n    \n    # filter data and outcomes\n    data = data[matches].reset_index(drop = True)\n    return data\n\ndef survival_stats(data, outcomes, key, filters = []):\n    \"\"\"\n    Print out selected statistics regarding survival, given a feature of\n    interest and any number of filters (including no filters)\n    \"\"\"\n    \n    # Check that the key exists\n    if key not in data.columns.values :\n        print(\"'{}' is not a feature of the Titanic data. Did you spell something wrong?\".format(key))\n        return False\n\n    # Return the function before visualizing if 'Cabin' or 'Ticket'\n    # is selected: too many unique categories to display\n    if(key == 'Cabin' or key == 'PassengerId' or key == 'Ticket'):\n        print(\"'{}' has too many unique categories to display! Try a different feature.\".format(key))\n        return False\n\n    # Merge data and outcomes into single dataframe\n    all_data = pd.concat([data, outcomes.to_frame()], axis = 1)\n    \n    # Apply filters to data\n    for condition in filters:\n        all_data = filter_data(all_data, condition)\n\n    # Create outcomes DataFrame\n    all_data = all_data[[key, 'Survived']]\n    \n    # Create plotting figure\n    plt.figure(figsize=(8,6))\n\n    # 'Numerical' features\n    if(key == 'Age' or key == 'Fare'):\n        \n        # Remove NaN values from Age data\n        all_data = all_data[~np.isnan(all_data[key])]\n        \n        # Divide the range of data into bins and count survival rates\n        min_value = all_data[key].min()\n        max_value = all_data[key].max()\n        value_range = max_value - min_value\n\n        # 'Fares' has larger range of values than 'Age' so create more bins\n        if(key == 'Fare'):\n            bins = np.arange(0, all_data['Fare'].max() + 20, 20)\n        if(key == 'Age'):\n            bins = np.arange(0, all_data['Age'].max() + 10, 10)\n        \n        # Overlay each bin's survival rates\n        nonsurv_vals = all_data[all_data['Survived'] == 0][key].reset_index(drop = True)\n        surv_vals = all_data[all_data['Survived'] == 1][key].reset_index(drop = True)\n        plt.hist(nonsurv_vals, bins = bins, alpha = 0.6,\n                 color = 'red', label = 'Did not survive')\n        plt.hist(surv_vals, bins = bins, alpha = 0.6,\n                 color = 'green', label = 'Survived')\n    \n        # Add legend to plot\n        plt.xlim(0, bins.max())\n        plt.legend(framealpha = 0.8)\n    \n    # 'Categorical' features\n    else:\n       \n        # Set the various categories\n        if(key == 'Pclass'):\n            values = np.arange(1,4)\n        if(key == 'Parch' or key == 'SibSp'):\n            values = np.arange(0,np.max(data[key]) + 1)\n        if(key == 'Embarked'):\n            values = ['C', 'Q', 'S']\n        if(key == 'Sex'):\n            values = ['male', 'female']\n\n        # Create DataFrame containing categories and count of each\n        frame = pd.DataFrame(index = np.arange(len(values)), columns=(key,'Survived','NSurvived'))\n        for i, value in enumerate(values):\n            frame.loc[i] = [value, \\\n                   len(all_data[(all_data['Survived'] == 1) & (all_data[key] == value)]), \\\n                   len(all_data[(all_data['Survived'] == 0) & (all_data[key] == value)])]\n\n        # Set the width of each bar\n        bar_width = 0.4\n\n        # Display each category's survival rates\n        for i in np.arange(len(frame)):\n            nonsurv_bar = plt.bar(i-bar_width, frame.loc[i]['NSurvived'], width = bar_width, color = 'r')\n            surv_bar = plt.bar(i, frame.loc[i]['Survived'], width = bar_width, color = 'g')\n\n            plt.xticks(np.arange(len(frame)), values)\n            plt.legend((nonsurv_bar[0], surv_bar[0]),('Did not survive', 'Survived'), framealpha = 0.8)\n\n    # Common attributes for plot formatting\n    plt.xlabel(key)\n    plt.ylabel('Number of Passengers')\n    plt.title('Passenger Survival Statistics With \\'%s\\' Feature'%(key))\n    plt.show()\n\n    # Report number of passengers with missing values\n    if sum(pd.isnull(all_data[key])):\n        nan_outcomes = all_data[pd.isnull(all_data[key])]['Survived']\n        print(\"Passengers with missing '{}' values: {} ({} survived, {} did not survive)\".format( \\\n              key, len(nan_outcomes), sum(nan_outcomes == 1), sum(nan_outcomes == 0)))","0c98596e":"survival_stats(data, outcome, 'Sex')","2194b336":"survival_stats(data, outcome, 'Age', [\"Sex == 'female'\"])","d48f9ffe":"survival_stats(data, outcome, \"Age\",[\"Sex == 'male'\",\"Embarked == 'C'\"])","ffb6101d":"survival_stats(data, outcome, \"Age\",[\"Sex == 'male'\",\"Embarked == 'S'\"])","1d5358eb":"def predict(data):\n    \"\"\" Model with multiple features. Makes a prediction with an accuracy of at least 80%. \"\"\"\n    \n    predictions = []\n    for _, passenger in data.iterrows():\n        # Remove the 'pass' statement below \n        # and write your prediction conditions here\n        if passenger['Sex'] == 'female':\n            if passenger['Embarked']== 'C'  and passenger['Pclass'] <=3 :predictions.append(1)\n            elif passenger['Embarked']== 'S' and passenger['Pclass'] <3:predictions.append(1)\n            else:\n                if (passenger['SibSp'] <2) and (passenger['Parch']<2): \n                    predictions.append(1)\n                else:\n                    predictions.append(0)\n        elif passenger['Sex']=='male' and passenger['Age']<15:\n            if passenger['SibSp'] < 3 and passenger['Embarked']=='S':predictions.append(1)\n            elif passenger['Embarked']=='C':predictions.append(1)\n            else:predictions.append(0)\n        else:predictions.append(0)\n    \n    # Return our predictions\n    return pd.Series(predictions)","c4db91ee":"pred = predict(data)","089c9bca":"print(accuracy_score(outcome,pred))","14f184a1":"predtst = predict(datst)","bd92bbed":"Past = datst.iloc[:,0]","efc4a154":"Past.head()","6cae8c6b":"dst = []\ni=0\nwhile i<len(predtst):\n    dst.append((Past[i],predtst[i]))\n    i+=1","9487b4a9":"d = pd.DataFrame(dst,columns=['PassengerId','Survived'])","f25ee107":"d.head()","243eafbe":"d.to_csv('gender_submission.csv',index=False)","f5ed13e8":"# Defining Visualization Functions","dbf75f53":"# Building The Model","4b674f14":"## Wow we got an accuracy of 83.16% without using any machine Learning Techinque, which is really great","f3c45e2e":"\n\nExamining the survival statistics, the majority of males younger than 10 survived the ship sinking, whereas most males age 10 or older did not survive the ship sinking. ","123fee6a":"Examining the survival statistics, a large majority of males did not survive the ship sinking. However, a majority of females did survive the ship sinking.","1609f1bd":"# Understanding the Data\n\n- Survived: Outcome of survival (0 = No; 1 = Yes)\n- Pclass: Socio-economic class (1 = Upper class; 2 = Middle class; 3 = Lower class)\n- Name: Name of passenge\n- Sex: Sex of the passenger\n- Age: Age of the passenger (Some entries contain NaN)\n- SibSp: Number of siblings and spouses of the passenger aboard\n- Parch: Number of parents and children of the passenger aboard\n- Ticket: Ticket number of the passenger\n- Fare: Fare paid by the passenger\n- Cabin Cabin number of the passenger (Some entries contain NaN)\n- Embarked: Port of embarkation of the passenger (C = Cherbourg; Q = Queenstown; S = Southampton)\n","b2197cea":"# Titanic Prediction Without Using Machine Learning\nUsing some conditional Statements, we can Predict the surviours in this problems and get nearly 85% accuracy without using machine learning","4f76ecaf":"# Loading the Requried Packages","57a9fdd4":"# Defining an accuracy function","00dc0389":"# Loading the Data","18a90647":"From the visualizations it is evident that Embarked playes an important role in predicting the survivours","f53b310a":"# Preparing the Submission File"}}