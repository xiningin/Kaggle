{"cell_type":{"283e3dad":"code","3df075de":"code","b1fc47be":"code","3eeeda48":"code","b086a859":"code","7972e9dd":"code","f37b3052":"code","4a9a0878":"code","3793c8fa":"code","66094c3c":"code","01c53370":"code","2ca198ac":"code","8f89782f":"code","f232df70":"code","f3fdcae9":"code","af9d22a3":"code","9843a152":"code","0f2ad4e4":"code","eac8969c":"markdown","1459f58b":"markdown","4d83fe82":"markdown","4d7bb7d0":"markdown","a9bbcf74":"markdown","fe45c0ad":"markdown","095a757c":"markdown","17c6d1da":"markdown"},"source":{"283e3dad":"# Core\nimport numpy as np \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# Machine Learning and Hyperparameter Tuning\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntrain_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')\n\ntrain_data.head()","3df075de":"features = ['Sex', 'Pclass', 'SibSp', 'Parch', 'Embarked']\n\nfor i in range(len(features)):\n    survived = train_data[train_data['Survived']==1][features[i]].value_counts()\n    dead = train_data[train_data['Survived']==0][features[i]].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(8,5))","b1fc47be":"features= [ 'Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\n\nx = train_data[features]\ny = train_data['Survived']\n\ntest_x = test_data[features]\n\nx.head()","3eeeda48":"# Check Null values in features\n\nx.isnull().sum()","b086a859":"# Fill Null Data\n\nx['Age'] = x['Age'].fillna(x['Age'].median())\nx['Embarked']= x['Embarked'].fillna(x['Embarked'].value_counts().index[0])\n\ntest_x['Age'] = test_x['Age'].fillna(test_x['Age'].median())\ntest_x['Fare'] = test_x['Fare'].fillna(test_x['Fare'].median())\n\nx.isnull().sum()","7972e9dd":"# Encode Categorical Data\n\nLE = LabelEncoder()\n\nx['Sex'] = LE.fit_transform(x['Sex'])\nx['Embarked'] = LE.fit_transform(x['Embarked'])\n\ntest_x['Sex'] = LE.fit_transform(test_x['Sex'])\ntest_x['Embarked'] = LE.fit_transform(test_x['Embarked'])\n\nprint(x.head())","f37b3052":"# Check Null Values in target\n\ny.isnull().sum()","4a9a0878":"# Split data\n\nx_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.1, random_state =0)","3793c8fa":"# Random Forest - Hyperparameter Tuning\n\nRFClassifier = RandomForestClassifier()\nn_estimators = range(10, 150)\n## Search grid for optimal parameters\nparam_grid = {\"n_estimators\" : n_estimators}\n\nmodel_rf = GridSearchCV(RFClassifier, param_grid = param_grid, cv=5, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\nmodel_rf.fit(x_train,y_train)\n\n# Best score\nprint(model_rf.best_score_)\n\n#best estimator\nmodel_rf.best_estimator_","66094c3c":"# Random Forest\n\nRFClassifier = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=66, n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)\nRFClassifier.fit(x_train,y_train)\nRFClassifier.score(x_test,y_test)","01c53370":"# Decision Tree - Hyperparameter Tuning\n\nDTClassifier = DecisionTreeClassifier()\nmin_samples_leaf = range(1, 1000)\n\n## Search grid for optimal parameters\nparam_grid = {\"min_samples_leaf\" :min_samples_leaf}\n\nmodel_dt = GridSearchCV(DTClassifier, param_grid = param_grid, cv=5, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\nmodel_dt.fit(x_train,y_train)\n\n# Best score\nprint(model_dt.best_score_)\n\n#best estimator\nmodel_dt.best_estimator_","2ca198ac":"# Decision Tree\n\nDTClassifier = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=10, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')\nDTClassifier.fit(x_train,y_train)\nDTClassifier.score(x_test, y_test)","8f89782f":"# knn - Hyperparameter Tuning\n\nKNClassifier = KNeighborsClassifier()\nn_neigh = range(10, 600)\n\n## Search grid for optimal parameters\nparam_grid = {\"n_neighbors\" :n_neigh}\n\nmodel_kn = GridSearchCV(KNClassifier, param_grid = param_grid, cv=5, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\nmodel_kn.fit(x_train,y_train)\n\n# Best score\nprint(model_kn.best_score_)\n\n#best estimator\nmodel_kn.best_estimator_","f232df70":"##knn\n\nKNClassifier = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n           weights='uniform')\nKNClassifier.fit(x_train,y_train)\nKNClassifier.score(x_test, y_test)","f3fdcae9":"# XGBClassifier\n\nxgbClassifier = XGBClassifier(colsample_bylevel= 0.9,\n                    colsample_bytree = 0.8, \n                    gamma=0.99,\n                    max_depth= 5,\n                    min_child_weight= 1,\n                    n_estimators= 10,\n                    nthread= 4,\n                    random_state= 2,\n                    silent= True)\nxgbClassifier.fit(x_train,y_train)\nxgbClassifier.score(x_test,y_test)","af9d22a3":"# Support Vector Machines\n\nSVCClassifier = SVC(gamma='auto')\nSVCClassifier.fit(x_train,y_train)\nSVCClassifier.score(x_test, y_test)","9843a152":"# Predict\n\nprediction = xgbClassifier.predict(test_x)","0f2ad4e4":"# Submit\nsubmission = pd.DataFrame({'PassengerId': test_data.PassengerId,\n                           'Survived': prediction})\nsubmission.to_csv('submission.csv', index=False)","eac8969c":"Preparing the Data","1459f58b":"Now use the test_x from test_data for prediction\n\nBest model: XGBClassifier","4d83fe82":"Machine Learning and Hyper-Parameters Tuning (TO BE CONTINUED...)","4d7bb7d0":"Checking, Transforming and Cleaning Data","a9bbcf74":"Important Data: Sex, Age, Fare, SibSp, Parch, Embarked?, Pclass\n\nUnimportant Data: PassengerId, Name, Ticket, Cabin?, Fare","fe45c0ad":"Submission","095a757c":"Separate Features from Target","17c6d1da":"Visualize Data"}}