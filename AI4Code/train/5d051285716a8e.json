{"cell_type":{"4ab56fbd":"code","228a6f35":"code","d98cfd39":"code","7b20683e":"code","628cb38b":"code","28c4d59a":"code","2a75432c":"code","bff93235":"code","8da30998":"code","7baf7d8d":"code","f4729f04":"code","25e221d9":"markdown","ddd0e181":"markdown","99fe4735":"markdown","68dea9da":"markdown","68929635":"markdown","f06d78c6":"markdown","08eb2fae":"markdown","b653bfe3":"markdown","9fe246db":"markdown","3c7216d7":"markdown","7a4e61f9":"markdown","486cbe0b":"markdown","cf8c8888":"markdown","45a4e65d":"markdown","c7acd43e":"markdown","4117fdb2":"markdown","fc9f177c":"markdown","249fcd85":"markdown","03ed601c":"markdown","c23dcab4":"markdown","a9c0bb1c":"markdown","fc80be7a":"markdown","7c2dd108":"markdown","f4d55290":"markdown","931af8a8":"markdown","45373592":"markdown","b73ee466":"markdown","85a1097b":"markdown","e00938ce":"markdown","5eb34a90":"markdown","03617687":"markdown","652df807":"markdown","8dc00caa":"markdown","b74fae0f":"markdown","146a4532":"markdown","cc22536a":"markdown","690d7ebf":"markdown","eaa7706c":"markdown","76135017":"markdown","d5cd8baa":"markdown","5bd10840":"markdown"},"source":{"4ab56fbd":"import numpy as np\nimport matplotlib.pylab as plt\n\n\n# Any file will do here:\nx = np.load(\"..\/input\/g2net-gravitational-wave-detection\/train\/0\/0\/0\/00000e74ad.npy\")\n\n\n\nfig, axes = plt.subplots(x.shape[0], 1, figsize=(12, 8))\nfor i, ax in enumerate(axes):\n    ax.plot(x[i, :])\nfig.suptitle(f\"Time series\")\n","228a6f35":"import torch\nfrom torch.fft import fft\n\n# The FFT results are complex numbers.\nfft_x = fft(torch.from_numpy(x[0]))\n\n# Plot the module. \n \nfig = plt.figure(figsize=(12, 8))\nplt.plot(np.abs(fft_x).reshape(-1))","d98cfd39":"import librosa\nfrom librosa.display import specshow\nimport numpy as np\n\n\nstft_x = librosa.stft(x[0, :])\nspectrogram_x = np.abs(stft_x) ** 2\n\n\nfig, ax = plt.subplots(figsize=(15, 3))\n\n\n\n\nspectrogram_x = librosa.amplitude_to_db(spectrogram_x, ref=np.max)\n\nim = specshow(spectrogram_x, y_axis='log', x_axis='time', ax=ax)\n\nfig.colorbar(im, format='%+2.0f dB')\n\n","7b20683e":"!pip install nnAudio","628cb38b":"import torch\nfrom nnAudio.Spectrogram import CQT1992v2\nimport matplotlib.pylab as plt\nimport numpy as np\n\n# sr is the sampling rate, it is 2048 Hz\n# fmax is half the sampling rate\n\ncqt_transform = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=64)\n\ndef run_cqt_transform(x: np.array) -> torch.Tensor:\n    # We stack the passed x since there are 3\n    # time series per file.\n    x = np.hstack(x)\n    # Normalize (is there a better way?)\n    x = x \/ np.max(x)\n    x = torch.from_numpy(x).float()\n    return cqt_transform(x)\n\n\nimg = run_cqt_transform(x)[0]\n\nfig, ax = plt.subplots(figsize=(12, 8)) \nax.imshow(img)\nax.set_title(f\"CQT\")","28c4d59a":"!git clone https:\/\/github.com\/ar4\/PyTorchWavelets.git > \/dev\/null\n%cd PyTorchWavelets\n!pip install -r requirements.txt > \/dev\/null\n!python setup.py install > \/dev\/null","2a75432c":"#\u00a0There is a notebook that explains how to do it.\nfrom wavelets_pytorch.transform import WaveletTransform, WaveletTransformTorch# PyTorch version\n\n\ndt = 0.1         # sampling frequency\ndj = 0.125       # scale distribution parameter\n\n# Batch of signals to process\n# batch = [batch_size x signal_length]\n\n# Initialize wavelet filter banks (scipy and torch implementation)\nwa_scipy = WaveletTransform(dt, dj)\n#\u00a0Doesn't work yet?\nwa_torch = WaveletTransformTorch(dt, dj, cuda=True)\n\n# Performing wavelet transform (and compute scalogram)\ncwt_torch = wa_torch.cwt(torch.tensor(x[0], device=\"cuda:0\").to(torch.float32))","bff93235":"cwt_torch","8da30998":"#\u00a0Use the following: from scipy.cluster.vq import whiten","7baf7d8d":"from scipy.signal import welch","f4729f04":"fs = 10e5\n\nf, Pxx_den = welch(x[0, :], fs, nperseg=1024)\n\nplt.semilogy(f, Pxx_den)\n\n\nplt.xlabel('frequency (Hz)')\n\nplt.ylabel('PSD ($V^{2}\/Hz$)')\n\nplt.show()","25e221d9":"In this competition, I have discovered some new signal processing transformations (CQT mainly)\nand have explored again ones I konw already (CWT, STFT, and so on). \n\nSo I have decided to take this opportunity as a refresher and share what I have learned.\n\nNotice that most of the implementations will be using PyTorch.\n\nLet's go!","ddd0e181":"Here are scipy methods: https:\/\/scipy-lectures.org\/intro\/scipy\/auto_examples\/plot_spectrogram.html#generate-a-chirp-signal\n\n\nhttps:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.signal.welch.html#scipy.signal.welch\n\nLet's see what this gives to the original signal.\n\n\n","99fe4735":"For that we will use some code samples from\nthis script: https:\/\/pytorch.org\/tutorials\/beginner\/audio_preprocessing_tutorial.html","68dea9da":"Next step, we need to move from Fourier transform to discrete Fourier transform (or DFT for short).","68929635":"# From Fourier transform to DFT and FFT","f06d78c6":"## PSD implementation","08eb2fae":"Spectrogram: https:\/\/en.wikipedia.org\/wiki\/Spectrogram","b653bfe3":"Not too  much to see. So we need better representations.","9fe246db":"The next transformation won't strictly speaking based on Fourier transform but\non similar ideas. It uses [wavelets](https:\/\/en.wikipedia.org\/wiki\/Wavelet) as the basis. \n\nThis is the CWT, short for continuous wavelet transform.","3c7216d7":"# CQT","7a4e61f9":"[PSD](https:\/\/en.wikipedia.org\/wiki\/Spectral_density) is short for power spectral density.","486cbe0b":"If you want even more details, check the following [notebook](https:\/\/www.kaggle.com\/yassinealouini\/what-is-mfcc) I made few months ago.\n\n\nIt explains in more details how Mel spectrogram and MFCCs are computed and how to use them. \n\nNotice that, in short, they are made from STFT as well and the big difference is that\nit is made from a spectrum of a spectrum (a [cepstrum](https:\/\/en.wikipedia.org\/wiki\/Cepstrum)).","cf8c8888":"From the STFT, we get a spectrogram: $ \\mathrm{spectrogram}(t,\\omega)=\\left|\\mathrm{STFT}(t,\\omega)\\right|^2 $","45a4e65d":"The first \"clever\" thing that has been done is to try to decompose the temporal signal\ninto a sum of functions that varies with frequencies. \n\nTo find these functions, we will use the Fourier transform. \n\nLet's see how it is computed and implemented in practice now.","c7acd43e":"# Spectrogram: time vs frequency","4117fdb2":"Alright, now that we know how to get frequencies, it is time to plot them vs timestamps.","fc9f177c":"# Whitening","249fcd85":"Looks much better: here at least we can see something!\n    \nCan we do better? Let's try another transformation and check.","03ed601c":"Using the following PyTorch library: https:\/\/github.com\/tomrunia\/PyTorchWavelets\n=> hard to install!!!","c23dcab4":"Let's start with the king of transformations: the [Fourier Transform](https:\/\/en.wikipedia.org\/wiki\/Fourier_transform). \n\nLet's suppose we have a temporal signal $x(t)$, i.e. a sequence of values that change over time. \n\n\nFor that, let's use one of the competition's signal. Notice that we get \nthree signals (one from each observatory) for the price of one file. Neat!","a9c0bb1c":"For the code part, we will use the PyTorch [FFT](https:\/\/pytorch.org\/docs\/stable\/fft.html) module.","fc80be7a":"# What about STFT?","7c2dd108":"Here is how to implement PSD using PyTorch.","f4d55290":"# What about PSD?","931af8a8":"## Definition","45373592":"Now, let's see how it can be coded. ","b73ee466":"# Fourier transform: some theory","85a1097b":"We can use nnaudio, librosa, or even PyTorch. Here is the code: \n\n\nhttps:\/\/pytorch.org\/docs\/stable\/generated\/torch.stft.html\n\nhttps:\/\/librosa.org\/doc\/latest\/generated\/librosa.stft.html\n\nhttps:\/\/kinwaicheuk.github.io\/nnAudio\/v0.1.5\/_autosummary\/nnAudio.Spectrogram.STFT.html","e00938ce":"This is still a **WIP**\n","5eb34a90":"# Mel and MFCC","03617687":"# Scalogram: same thing but for wavelets","652df807":"# CWT","8dc00caa":"Here is how to implement it: ","b74fae0f":"One additional useful method is whitening of the signal. To do so.","146a4532":"# How to do this with PyTorch?","cc22536a":"Here is how it is defined for a signal $x(t)$: \n    \n    \n$\\hat{f}(\\xi) = \\int_{-\\infty}^{\\infty} x(t)\\ e^{-2\\pi i t \\xi}\\,dt$\n\n\nthe resulting function is a complex valued one in the frequency domain.","690d7ebf":"# Before we start","eaa7706c":"As you can see, some patterns seem to be hidden within the signal. So the next question is: how can we extract these efficiently?","76135017":"# Fourier Transform","d5cd8baa":"Here is how it is defined and computed in few steps:\n\n1. We start by computing the short-term Fourier transform (STFT in short): this is a Fourier transform with a moving window over the signal. As a window function, we often use the Hann or Hamming windows. Finally, notice that we will use the discrete version of the STFT. The equation should be:\n\n$X[k,m] = \\sum_{n=0}^{N-1} W[n-m] x[n] e^{-j 2 \\pi k n\/N}.$\n\n2. We introduce the quality factor Q using the following formula: $Q = \\frac{f_k}{\\delta f_k}.$\n\n3. Now, the window length for the k-th bin is no longer fixed (N) by will vary depending on the filter (we use the previous definition to get a simplified expression):\n\n$N[k] = \\frac{f_\\text{s}}{\\delta f_k} = \\frac{f_\\text{s}}{f_k} Q.$\n\n4. The digital frequency $\\frac{2 \\pi k}{N}$ is also changed and the window function now depends on $k$ as well (via the window length $N[k]$)\n\n5. Finaly, replacing the different elements in the original formula, we get:\n\n$X[k] = \\frac{1}{N[k]} \\sum_{n=0}^{N[k]-1} W[k,n] x[n] e^{\\frac{-j2 \\pi Qn}{N[k]}}. $","5bd10840":"STFT stands for short-term Fourier transform. It is computed by taking moving\nwindows.\n\n\n\nHere is the forumula:  $ and here is how to compute it in more details: \n\n1. Take \n2. Compute the DFT\n    \n    \nFor the implementation, we will be using `librosa.stft`"}}