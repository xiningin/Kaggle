{"cell_type":{"35158acd":"code","8b9217db":"code","6180b9a6":"code","4bcac87e":"code","e1f3172b":"code","08af0fc6":"code","d00e655f":"code","62e11b44":"code","5613cd21":"code","448ad31b":"code","4bc31a0a":"code","9ed4b4a6":"code","902b352a":"code","74015bb0":"code","52aa0d5f":"code","5da01021":"code","ce358959":"markdown","1e098c51":"markdown","4492558f":"markdown","8a3a3707":"markdown","054f99d3":"markdown","da7396d6":"markdown","4ad12c85":"markdown","e28aeef4":"markdown","b54807dc":"markdown"},"source":{"35158acd":"import matplotlib.pyplot as plt\nfrom PIL import Image\nfrom random import randint\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nimport urllib\nimport cv2","8b9217db":"import torch\nimport torchvision\n\nimport torchvision.transforms as T\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor","6180b9a6":"base_path = '..\/input\/google-landmarks-dataset\/'\n\n# load train data\ndf_train = pd.read_csv(base_path + 'train.csv')\nprint(df_train.head())\n\n# load boxes data and merge into one\ndf_boxes_split1 = pd.read_csv(base_path + 'boxes_split1.csv')\ndf_boxes_split2 = pd.read_csv(base_path + 'boxes_split2.csv')\ndf_boxes = pd.concat([df_boxes_split1, df_boxes_split2])\n\nprint(df_boxes.head())","4bcac87e":"# merge train and boxes on id\ndf_train = pd.merge(df_train, df_boxes, on='id',  how='right')\ndf_train.head()","e1f3172b":"def get_transform(train):\n    transforms = []\n    if train:\n        # random horizontal flip with 50% probability\n        transforms.append(T.RandomHorizontalFlip(0.5))\n    return T.Compose(transforms)","08af0fc6":"class GoogleLandmarks(Dataset):\n    def __init__(self, df, transforms):\n        self.df = df\n        self.dim = (512, 512)\n        self.transforms = transforms\n        self.ids = np.unique(df['landmark_id'].values)\n        self.ids_dic = {v:k for k,v in enumerate(self.ids)}\n    \n    def url_to_image(self, url, dim):\n        try:\n            resp = urllib.request.urlopen(url)\n        except:\n            return np.array([])\n        image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n        if(image.size != 0):\n            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n            image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n            image = Image.fromarray(np.uint8(image))\n            if(image):\n                image = self.transforms(image)\n        else:\n            image = Image.fromarray(image)\n        return T.ToTensor()(image)\n    \n    def get_rect(self, boxes):\n        try:\n            y = boxes[0]\n            x = boxes[1]\n            h = boxes[2] - boxes[0]\n            w = boxes[3] - boxes[1]\n        except:\n            return None\n        return plt.Rectangle((x, y), w, h, color='y', alpha=0.3)\n    \n    def draw_bbox(self, img, rect):\n        fig, ax = plt.subplots()\n        plt.imshow(img.permute(1, 2, 0))\n        if(rect):\n            ax.add_patch(rect)\n    \n    def format_boxes(self, boxes, dim):\n        return (np.array(boxes.split(' ')).astype(np.float32) * dim[0]).astype(np.int64)\n    \n    def __getitem__(self, idx):\n        id = self.df.iloc[idx].id\n        landmarkid = self.df.iloc[idx].landmark_id\n        url = self.df[self.df.id == id].url.values[0]\n        boxes = self.df[self.df.id == id].box.values[0]\n        \n        \n        # format boxes\n        boxes = self.format_boxes(boxes, self.dim)\n        \n        labels = np.eye(len(self.ids))[self.ids_dic[landmarkid]]\n        \n        target = {}\n        target[\"boxes\"] = torch.as_tensor([boxes], dtype=torch.int64)\n        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n        target[\"image_id\"] = torch.tensor([idx])\n        target[\"area\"] = (boxes[3] - boxes[1]) * (boxes[2] - boxes[0])\n        target[\"iscrowd\"] = torch.zeros((1,), dtype=torch.int64)\n        \n        image = self.url_to_image(url, self.dim)\n        \n        if(len(image) == 0):\n            return None, None\n        \n        return image, target\n        \n    def __len__(self):\n        return len(self.ids)","d00e655f":"# select 10 ids randomly\nidxes = [randint(0, len(df_train) - 1) for i in range(10)]\n\n# select only 10 landmarks\nids_of_landmarks = df_train['landmark_id'][idxes].values\n\n# subset of training data with 10 landmarks\ndf = df_train[df_train['landmark_id'].isin(ids_of_landmarks)]\n\n# google dataset\ngoogle_ds = GoogleLandmarks(df, get_transform(train=True))","62e11b44":"image, target = google_ds[0]","5613cd21":"rect = google_ds.get_rect(target['boxes'][0])\ngoogle_ds.draw_bbox(image, rect)","448ad31b":"def collate_fn(batch):\n    return tuple(zip(*batch))","4bc31a0a":"data_loader = torch.utils.data.DataLoader(\n        google_ds, batch_size=8, shuffle=True, num_workers=4,\n        collate_fn=collate_fn)","9ed4b4a6":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","902b352a":"model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n\nnum_classes = 2\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\nmodel = model.to(device)","74015bb0":"params = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.0005, momentum=0.9, weight_decay=0.0005)\n\n# and a learning rate scheduler\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)","52aa0d5f":"total_errors = []\nfor epoch in range(10):\n    losses_arr = []\n\n    for images, targets in data_loader:\n\n        images = list(image.to(device) for image in images if image is not None)\n        targets = [{k: torch.as_tensor(v).detach().to(device) for k, v in t.items()} for t in targets if t is not None]\n\n        optimizer.zero_grad()\n\n        loss_dict = model(images, targets)\n        losses = sum(loss for loss in loss_dict.values())\n        losses_arr.append(losses.item())\n\n        losses.backward()\n        optimizer.step()\n\n        # update the learning rate\n        # lr_scheduler.step()\n        \n    total_errors.append(np.mean(np.array(losses_arr)))\n    if epoch % 1 == 0:\n        print(\"Epoch:{0:3d}, Loss:{1:1.3f}\".format(epoch, total_errors[-1]))","5da01021":"plt.plot(total_errors)","ce358959":"# Google Landmarks Dataset","1e098c51":"# Google Landmarks Faster R-CNN","4492558f":"# Augmentations","8a3a3707":"# Training","054f99d3":"# Draw an image with Bounding Boxes","da7396d6":"# Create DataLoader","4ad12c85":"# Evaluate Loss","e28aeef4":"# Prepare Data","b54807dc":"# Create Faster RCNN Model with Resnet50"}}