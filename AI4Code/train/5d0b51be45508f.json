{"cell_type":{"45e5de32":"code","560ec3df":"code","e68fb032":"code","8c8742b1":"code","b62f0847":"code","f6cf364c":"code","47ad1d1c":"code","39a0f9da":"code","cc2ac0b9":"code","4f66f818":"code","d9d042fa":"code","5266dc51":"code","a2708508":"code","78d0a565":"code","2ee181ff":"code","6e8b2bfc":"code","5c8328d1":"code","8e5a0586":"code","0355bc9b":"code","e93a3746":"code","929867c2":"code","b7bbca19":"code","268f09ca":"code","9a7678af":"code","f2351a3e":"code","7f696dd1":"code","ce23059f":"code","1bac6600":"code","c9d3b5d8":"code","776f317c":"code","153ede40":"code","cc38f6d6":"code","49c617d5":"code","ab9cae29":"code","63f01d7d":"code","035cf3e7":"code","78468eda":"code","fec6d442":"code","f3a05070":"code","a771e410":"code","f1a990e4":"code","391f64dc":"code","7b34a1aa":"code","fc215fe6":"code","a760e57d":"code","522aee90":"code","3748f52e":"markdown","7324386e":"markdown","d50b82d9":"markdown","b3057c97":"markdown"},"source":{"45e5de32":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","560ec3df":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\n%matplotlib inline\nimport os","e68fb032":"my_data_dir = '\/kaggle\/input\/fruit-recognition\/'","8c8742b1":"os.listdir(my_data_dir)","b62f0847":"apple = my_data_dir+'Apple\/'+'Total Number of Apples'\npeach = my_data_dir+'Peach'\ncarambola = my_data_dir+'Carambola'\nkiwi = my_data_dir+'Kiwi\/'+'Total Number of Kiwi fruit'\ntomatoes = my_data_dir+'Tomatoes'\npersimmon = my_data_dir+'Persimmon'\nplum = my_data_dir+'Plum'\nguava = my_data_dir+'Guava\/'+'guava total final'\npear = my_data_dir+'Pear'\nmango = my_data_dir+'Mango'\nmuskmelon = my_data_dir+'muskmelon'\nbanana = my_data_dir+'Banana'\npomegranate = my_data_dir+'Pomegranate'\npitaya = my_data_dir+'Pitaya'\norange = my_data_dir+'Orange'","f6cf364c":"A_img= apple+'\/'+'Apple 03441.png'","47ad1d1c":"A_img","39a0f9da":"os.listdir(apple)","cc2ac0b9":"an_A_img = imread(A_img)","4f66f818":"plt.imshow(an_A_img)","d9d042fa":"os.listdir(apple)","5266dc51":"dim1 = []\ndim2 = []\nfor image_filename in os.listdir(apple):\n    \n    img = imread(apple+'\/'+image_filename)\n    d1,d2,colors = img.shape\n    dim1.append(d1)\n    dim2.append(d2)","a2708508":"sns.jointplot(dim1,dim2)","78d0a565":"np.mean(dim1)","2ee181ff":"np.mean(dim2)","6e8b2bfc":"image_shape = (283,383,3)","5c8328d1":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","8e5a0586":"# help(ImageDataGenerator)","0355bc9b":"image_gen = ImageDataGenerator(rotation_range=20, # rotate the image 20 degrees\n                               width_shift_range=0.10, # Shift the pic width by a max of 5%\n                               height_shift_range=0.10, # Shift the pic height by a max of 5%\n                               rescale=1\/255, # Rescale the image by normalzing it.\n                               shear_range=0.1, # Shear means cutting away part of the image (max 10%)\n                               zoom_range=0.1, # Zoom in by 10% max\n                               horizontal_flip=True, # Allo horizontal flipping\n                               fill_mode='nearest' # Fill in missing pixels with the nearest filled value\n                              )","e93a3746":"image_gen.flow_from_directory(my_data_dir)","929867c2":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D","b7bbca19":"model = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=image_shape, activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Flatten())\n\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\n\n# Dropouts help reduce overfitting by randomly turning neurons off during training.\n# Here we say randomly turn off 50% of neurons.\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(15))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","268f09ca":"model.summary()","9a7678af":"from tensorflow.keras.callbacks import EarlyStopping","f2351a3e":"early_stop = EarlyStopping(patience=2)","7f696dd1":"batch_size = 64","ce23059f":"train_image_gen = image_gen.flow_from_directory(my_data_dir,\n                                               target_size=image_shape[:2],\n                                                color_mode='rgb',\n                                               batch_size=batch_size,\n                                               class_mode='categorical')","1bac6600":"train_image_gen.class_indices","c9d3b5d8":"import warnings\nwarnings.filterwarnings('ignore')","776f317c":"results = model.fit_generator(train_image_gen,epochs=2,callbacks=[early_stop])","153ede40":"from tensorflow.keras.models import load_model\nmodel.save('fruit.h5')","cc38f6d6":"metrics = pd.DataFrame(model.history.history)","49c617d5":"metrics.plot()","ab9cae29":"from tensorflow.keras.preprocessing import image","63f01d7d":"#pred_probabilities = model.predict_generator(train_image_gen)","035cf3e7":"apple = apple+'\/'+os.listdir(apple)[1]","78468eda":"my_image = image.load_img(apple,target_size=image_shape)","fec6d442":"my_image","f3a05070":"type(my_image)","a771e410":"my_image = image.img_to_array(my_image)","f1a990e4":"type(my_image)","391f64dc":"my_image.shape","7b34a1aa":"my_image = np.expand_dims(my_image, axis=0)","fc215fe6":"my_image.shape","a760e57d":"model.predict(my_image)","522aee90":"train_image_gen.class_indices","3748f52e":"# APPLE","7324386e":"## WOW! 91 percent accuracy :O","d50b82d9":"## Recall 0 is the index for apple so that is a perfect job","b3057c97":"## Lets Predict on an image"}}