{"cell_type":{"d5f2099d":"code","0c6376cc":"code","a52b77e1":"code","66399cb3":"code","17562f28":"code","f11675da":"code","9d55cb7c":"code","fe8ad95b":"code","55616da6":"code","bf0f0f3e":"code","798611c1":"code","c56a8319":"markdown"},"source":{"d5f2099d":"# Creating the CUDA environment\n\nfrom torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'","0c6376cc":"# Working with the data and creating the test train split\n\nfrom sklearn.model_selection import train_test_split\n\ntrain = pd.read_csv('..\/input\/digit-recognizer\/train.csv', dtype=np.float32)\ntargets_numpy = train.label.values\n\nfeatures_numpy = train.loc[:,train.columns != \"label\"].values\/255 # normalization\n\n# train test split. Size of train data is 80% and size of test data is 20%. \nfeatures_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n                                                                             targets_numpy,\n                                                                             test_size = 0.2,\n                                                                             random_state = 42) ","a52b77e1":"# create feature and targets tensor for train set. \nfeaturesTrain = torch.from_numpy(features_train)\ntargetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n\n# create feature and targets tensor for test set.\nfeaturesTest = torch.from_numpy(features_test)\ntargetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long","66399cb3":"# batch_size, epoch and iteration\nbatch_size = 100\nn_iters = 10000\nnum_epochs = n_iters \/ (len(features_train) \/ batch_size)\nnum_epochs = int(num_epochs)\n\n# Pytorch train and test sets\ntrain = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\ntest = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n\n# data loader\ntrain_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\ntest_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n","17562f28":"import matplotlib.pyplot as plt\n\n# visualize one of the images in data set\nplt.imshow(features_numpy[10].reshape(28,28))\nplt.axis(\"off\")\nplt.title(str(targets_numpy[10]))\nplt.savefig('graph.png')\nplt.show()","f11675da":"# Defining the model network\n\nclass Model(torch.nn.Module):\n\n    ## Initialize\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = torch.nn.Conv2d(1,16,kernel_size=5)\n        self.conv2 = torch.nn.Conv2d(16,32,kernel_size=5)\n        self.l1 = torch.nn.Linear(32 * 4 * 4, 10)\n\n        self.max = torch.nn.MaxPool2d(2)\n\n    ## Forward\n    def forward(self, x):\n        x = torch.nn.functional.relu(self.max(self.conv1(x)))\n        x = torch.nn.functional.relu(self.max(self.conv2(x)))\n        x = x.view(x.size(0), -1)\n        x = self.l1(x)\n        return torch.nn.functional.log_softmax(x)\n\nmodel = Model()\nmodel.to(device)","9d55cb7c":"# Define the loss function and optimizer\n\ncriterion = torch.nn.CrossEntropyLoss(reduction='mean')\noptimus = torch.optim.SGD(model.parameters(), lr = 0.1, momentum=0.05)","fe8ad95b":"# CNN model training\ncount = 0\nloss_list = []\niteration_list = []\naccuracy_list = []\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        \n        inputs = images.view(100,1,28,28).to(device)\n        labels = labels.to(device)\n        \n        # Clear gradients\n        optimus.zero_grad()\n        \n        # Forward propagation\n        outputs = model(inputs)\n        \n        # Calculate softmax and ross entropy loss\n        loss = criterion(outputs, labels)\n        \n        # Calculating gradients\n        loss.backward()\n        \n        # Update parameters\n        optimus.step()\n        \n        count += 1\n        \n        if count % 50 == 0:\n            # Calculate Accuracy         \n            correct = 0\n            total = 0\n            # Iterate through test dataset\n            for images, labels in test_loader:\n                \n                inputs = images.view(100,1,28,28).to(device)\n                labels = labels.to(device)\n                # Forward propagation\n                outputs = model(inputs)\n                \n                # Get predictions from the maximum value\n                predicted = torch.max(outputs.data, 1)[1]\n                \n                # Total number of labels\n                total += len(labels)\n                \n                correct += (predicted == labels).sum()\n            \n            accuracy = 100 * correct \/ float(total)\n            \n            # store loss and iteration\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n        if count % 500 == 0:\n            # Print Loss\n            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))","55616da6":"# Now we are going to work on the test data set. Model.eval and test dataloader\n\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv', dtype=np.float32)\nfeatures_numpy = test.loc[:,test.columns != \"label\"].values\/255 # normalization\nfeaturestest = torch.from_numpy(features_numpy)","bf0f0f3e":"model.eval()\npredicted = []\nfor i in range(0,featurestest.shape[0]):\n    inputs = featurestest[i].view(1,1,28,28).to(device)\n    output = model(inputs)\n    predicted.append(torch.max(output.data, 1)[1].item())","798611c1":"a= np.array(range(1,len(predicted)+1))\nb=np.array(predicted)\ndf = pd.DataFrame({'ImageId':a,'Label':b})\ndf.to_csv('submission.csv', index=False)","c56a8319":"# Import the stock libraries\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset"}}