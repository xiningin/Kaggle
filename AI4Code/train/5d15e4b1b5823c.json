{"cell_type":{"73ce87c1":"code","6c8b50f4":"code","5efa2116":"code","c6488a46":"code","f54bca83":"code","99265640":"code","ea8be33a":"code","2bb61019":"code","f7bd7174":"code","a86fe9e1":"code","ffd0be3e":"code","fd5f58c0":"code","99447810":"code","46ff9367":"code","c2b1de5f":"code","9a1b3009":"code","641fec8f":"code","1a58908d":"code","5819b39a":"code","cbde0291":"code","bc256cb0":"code","6f0d8c4e":"code","900967e1":"code","ba9a3656":"code","d2d8f533":"code","abc96eab":"code","80a1b04d":"code","b05af199":"code","2784bc35":"code","1065e26a":"code","84f077b5":"code","fc883bbd":"code","05ef5c6f":"code","03f4b21f":"code","ff7830c5":"code","c6881f0f":"code","29be7a35":"code","e8d582c6":"code","63086be6":"code","0d072904":"code","668b3c5f":"code","c1195d83":"code","1d2fea24":"code","51f957bb":"code","b00e772a":"code","91ecdb4e":"code","e2c5376e":"code","a2ead5e2":"code","335d9f11":"code","aec9b883":"code","42056116":"code","a7b254fb":"code","51f31855":"code","d44528b6":"code","07009a2f":"code","cf94e8c8":"code","a38f1a6e":"code","02a5179a":"code","aaee014a":"code","81fc0ee9":"code","bae71aaf":"markdown","a44a4fdd":"markdown","63ca4d52":"markdown","943e77d4":"markdown","c5f755f2":"markdown","ac690bd1":"markdown","c321d910":"markdown","bc6dfe78":"markdown","90e6762a":"markdown","4170c153":"markdown","eed05b6b":"markdown","327025b1":"markdown","a8b8b9a9":"markdown","0e61f9a2":"markdown","0dd48484":"markdown","cbbe8d6e":"markdown","4f32f240":"markdown","ac246955":"markdown","0a6efa91":"markdown","965efa4b":"markdown","b4c17263":"markdown","b50361df":"markdown"},"source":{"73ce87c1":"from scipy.io import loadmat\nimport numpy as np, os, sys, joblib\nimport re\nfrom os.path import dirname, join as pjoin\nimport matplotlib.pyplot as plt","6c8b50f4":"input_directory = '\/kaggle\/input\/pacpvc-classification-assignment'","5efa2116":"# path dell'ecg di un paziente\nmat_fname = pjoin(input_directory, 'S001_128.mat')\nprint(mat_fname)","c6488a46":"# contenuto del file selezionato\ncontent=loadmat(mat_fname)\ncontent","f54bca83":"# la voce ecg contiene 2 vettori, uno per derivazione\nleads=content['ecg']\nprint(leads)\nprint(len(leads))","99265640":"# seleziono la prima derivazione\nlead_1=np.array(leads[:,1])\nprint('prima derivazione ',lead_1)\n\n# indici dei primi tot campioni\npos=np.array(list(range(0,400)))\nprint('indici ', pos)\nprint('lungheza: ',len(pos))\n\nbeat=lead_1[pos]\nprint('lunghezza battito: ',len(beat))\nprint(beat)\n","ea8be33a":"# Frequenza di campionamento e sample time\nFs=128\nT=1\/Fs \nprint(T)","2bb61019":"# definisco l'asse del tempo per il battito che ho estratto\n# (dovrebbe essere un vettore di numeri ogni 0.0078 secondi)\nt=np.array(list(range(0,len(beat)))) * T\nprint(t)","f7bd7174":"plt.figure(figsize=(20, 20))\nplt.plot(t,beat)\n\nplt.show()\n# guardo i battiti","a86fe9e1":"mat_fname = pjoin(input_directory, 'S001_128_ann.mat')\nprint(mat_fname)\n\ncontent=loadmat(mat_fname)\nprint(content)","ffd0be3e":"labels=content['labels']\nprint(labels)\nprint(len(labels))\n\n# Ogni label \u00e8 associata a un picco.\n# La posizione del picco \u00e8 nell'altro file _rpk","fd5f58c0":"mat_fname = pjoin(input_directory, 'S001_128_rpk.mat')\nprint(mat_fname)\n\ncontent=loadmat(mat_fname)\nprint(content)","99447810":"peaks=content['rpeaks']\nprint(peaks)\nprint(len(peaks))","46ff9367":"plt.figure(figsize=(20, 20))\nplt.plot(beat)\nplt.plot(peaks[0],beat[peaks[0]], 'o')\nplt.plot(peaks[1],beat[peaks[1]], 'o')\nplt.plot(peaks[2],beat[peaks[2]], 'o')\nplt.plot(peaks[3],beat[peaks[3]], 'o')\nplt.plot(peaks[4],beat[peaks[4]], 'o')\n\n\nplt.show()\n\n# Non sembrano ben identificati... sar\u00e0 un problema? \u00e8 un mio errore? \n# sono spostati a destra di un tot. chiss\u00e0...","c2b1de5f":"directory = os.listdir(input_directory)\nprint(len(directory))\n","9a1b3009":"ann = 'ann'\np = 'rpk'\n# gli altri sono ecg","641fec8f":"for fname in directory:\n    if os.path.isfile(input_directory + os.sep + fname):\n        # Full path\n        \n        f = (input_directory + os.sep + fname)\n        print(f)\n    \n       ","1a58908d":"#data={'Patient':[]}","5819b39a":"# ci sono 3 tipi d file per ciascun paziente che salvo nelle 3 variabili diverse\nann=[]\nrpk=[]\nsigna=[]\n\nfor f in os.listdir(input_directory): # this command creates a list with all files are there\n    g = os.path.join(input_directory, f)\n    if re.search(r'\\w*ann.mat\\b', f): # se il nome del file contiene 'ann' signfica che \u00e8 quello dei label per cui lo\n                                      # salvo nella variabile ann che conterr\u00e0 solo i file che terminano per ann.mat\n                                      # per fare questo utilizzo le regex e quindi la libreria re\n        ann.append(g)\n        \n    elif re.search(r'\\w*rpk.mat\\b', f):\n        rpk.append(g)\n        \n    else:\n        signa.append(g)\n        ","cbde0291":"# sorting the elements\nsigna = sorted(signa)\nann=sorted(ann)\nrpk=sorted(rpk)\n\n","bc256cb0":"#il contenuto di ciascun tipo di file lo salvo nelle 3 vairabili che conterranno rispettivamente: \necg_signals = [] # save all 2-leads signals for the 105 patients in this list\nR_labels=[] # 105 vettori con i labels dei picchi \nR_loc=[] # 105 vettori con gli indici dei picchi\n\n\nfor i in range (0,len(ann)):\n    x=loadmat(ann[i]) # dal load, se printate x vedrete che \u00e8 un dict che contiene diverse cose tra cui un valore chiamato 'labels'\n                      # ch eocntiene la lista dei labels\n    R_labels.append(x['labels'])\n    labels= [list(i) for i in R_labels]\n#print(labels)\n#print(len(labels))","6f0d8c4e":"print(R_labels)","900967e1":"# stessa cosa per i picchi\nfor i in range (0,len(rpk)):\n    x=loadmat(rpk[i])\n    R_loc.append(x['rpeaks'])\n\n#print(R_loc)\nprint(len(R_loc))","ba9a3656":"signa","d2d8f533":"# estrai id pazienti\nidx=[]\n\nfor f in signa: # this command creates a list with all files are there\n    m = re.search('S(.+?)_', f)\n    if m:\n        idx.append(m.group(1))\n    \nprint(len(idx))    ","abc96eab":"#estrai Fs \nfreq=[]\nfor f in signa: # this command creates a list with all files are there\n    m = re.search('_(.+?).mat', f)\n    if m:\n        freq.append(m.group(1))\n    \nprint(len(freq)) ","80a1b04d":"# Crea il dataframe: assegna nel dataframe le liste (separando le leads)\nimport pandas as pd\n\ncol_name=['ID','Fs','lead1','lead2','pos','label']\ndata={'ID':idx, 'Fs':freq}\ndf=pd.DataFrame(data)","b05af199":"df['pos']=R_loc","2784bc35":"len(R_labels)","1065e26a":"df['label']=R_labels","84f077b5":"df.head()","fc883bbd":"df['pos']","05ef5c6f":"ecg_signals = []\nL1 = []\nL2 = []\n\nfor i in range (0,len(signa)):\n    x=loadmat(signa[i])\n    leads=x['ecg']\n    ecg_signals.append(x['ecg']) # contiene entrambe le derivazioni\n    L1.append(np.array(leads[:,0]))\n    L2.append(np.array(leads[:,1]))","03f4b21f":"print('Derivazioni:')\nprint(ecg_signals[0])\nprint('\\nLead 1:')\nprint(L1[0])\nprint('\\nlead 2:')\nprint(L2[0])","ff7830c5":"df['lead1'] = L1\ndf['lead2'] = L2","c6881f0f":"df[0:10]","29be7a35":"# Per andare a prendere una derivazione dal dataframe:\nprint(df.lead1[0])","e8d582c6":"# Label distribution\nlab = np.array(df.label)\n\n# Conteggio delle labels su tutto il dataset\nnormal=0\npac=0\npvc=0\n\nfor i in range (lab.size):\n    for j in range (lab[i].size):       \n        if lab[i][j] == 'N':\n            normal=normal+1\n        elif lab[i][j] == 'S':\n            pac=pac+1\n        elif lab[i][j] == 'V':\n            pvc=pvc+1\n            \nclasses = ['N','S','V']\npos = np.arange(len(classes))\n\nplt.bar(pos, [normal, pac, pvc])\nplt.xticks(pos, classes)\nplt.title('classes occurances')\nplt.show()\n\nprint('Normal: ', normal)\nprint('\\nPAC: ', pac)\nprint('\\nPVC: ', pvc)\n# Sono molto sbilanciate!\n\n# Possiamo usare i pesi durante il training","63086be6":"import scipy.signal\n\nd1 = np.array(df.lead1)\nd2 = np.array(df.lead2)\nf = np.array(df.Fs)\n\nfor i in range (d1.size):\n    signal_freq = int(f[i])\n  \n    if signal_freq == 250:\n        secs = int(len(d1[i])\/250) # Number of seconds in signal X\n        samps = secs * 128   # Number of samples to downsample\n        d1[i] = scipy.signal.resample(d1[i], samps)\n        d2[i] = scipy.signal.resample(d2[i], samps)","0d072904":"(len(d1[90])\/250)","668b3c5f":"# Filtro Butterworth\nfrom scipy.signal import butter, lfilter\n\ndef bandpass_filter(data, lowcut, highcut, signal_freq, filter_order):\n        \"\"\"\n        Method responsible for creating and applying Butterworth filter.\n        :param deque data: raw data\n        :param float lowcut: filter lowcut frequency value\n        :param float highcut: filter highcut frequency value\n        :param int signal_freq: signal frequency in samples per second (Hz)\n        :param int filter_order: filter order\n        :return array: filtered data\n        \"\"\"\n        nyquist_freq = 0.5 * signal_freq\n        low = lowcut \/ nyquist_freq\n        high = highcut \/ nyquist_freq\n        b, a = butter(filter_order, [low, high], btype=\"band\")\n        y = lfilter(b, a, data)\n        return y\n\n    ","c1195d83":"# Altro filtro FIR\nfrom scipy.signal import kaiserord, lfilter, firwin, freqz, filtfilt\n\ndef filter_fir(x, lowcut, highcut, signal_freq):\n    \n    nyq_rate = signal_freq \/ 2.0\n    width = 5.0\/nyq_rate\n    ripple_db = 60.0\n    \n    N, beta = kaiserord(ripple_db, width)\n    \n    taps = firwin(N, [lowcut, highcut], nyq=nyq_rate, window=('kaiser', beta), pass_zero=False)\n    #filtered_x = lfilter(taps, 1.0, x)\n    filtered_x = filtfilt(taps, 1.0, x) # uso filtfilt per non avere il delay\n        \n    return filtered_x\n    ","1d2fea24":"#data = #Preso da df\nlowcut = 2.0 # Provo anche con 2 Hz e con 0.5 Hz, con 2 sembra meglio in termini di baseline. \nhighcut = 20.0 # da 35 a 20 Hz\n#signal freq = # Preso dal df\n\nfilter_order = 3 # Questo posso cambiarlo! 3 va bene, serve per iir","51f957bb":"# Preparo i dati che mi servono per filtrare\n\nfiltered1 = [] # liste che contengono i segnali filtrati da butterwoth\nfiltered2 = []\n\n#filt_both1 =[] # segnali filtrati da FIR\n\nfor i in range (d1.size):\n    signal_freq = int(f[i])\n        \n    data = d1[i]\n    butter1 = bandpass_filter(data, lowcut, highcut, signal_freq, filter_order)\n    filtered1.append(butter1)\n    \n    #both1 = filter_fir(butter1, lowcut, highcut, signal_freq)\n    #filt_both1.append(both1)\n    \n    data = d2[i]\n    filtered2.append(bandpass_filter(data, lowcut, highcut, signal_freq, filter_order))\n    \n    \n ","b00e772a":"# Visualizza filtrato e originale\npos=np.array(list(range(300,1000)))\n\n#beat_both = filt_both1[0][pos]\nbeat_butter = filtered1[1][pos]\n\n#plt.plot(beat_both) # Con il fir ho un delay\nplt.plot(beat_butter)\n#plt.plot(d1[8][pos])","91ecdb4e":"plt.plot(d1[1])","e2c5376e":"plt.plot(filtered1[0])","a2ead5e2":"# Qua si pu\u00f2 vedere come un minimo la baseline \u00e8 aggiustata: la blu \u00e8 quella filtrata\npos=np.array(list(range(500,2000)))\n\nbeat = filtered1[0][pos]\n\n#plt.plot(beat)\nplt.plot(d1[0][pos])","335d9f11":"R_loc[1][1][0]","aec9b883":"from decimal import Decimal\n# RR intervals\nRR_prima = []\nRR_dopo = []\n\nfor i in range(len(R_loc)):\n    RR_0 = np.nan\n    RR_prima.append(RR_0)\n    for j in range(1, len(R_loc[i])):\n        RR_pre = R_loc[i][j][0] - R_loc[i][j-1][0]\n        RR_prima.append(RR_pre)\n    for k in range(0, len(R_loc[i])-1):\n        RR_post = R_loc[i][k+1][0] - R_loc[i][k][0]\n        RR_dopo.append(RR_post) \n    RR_end =  np.nan\n    RR_dopo.append(RR_end)\n","42056116":"#RR_dopo.count(np.nan)\n# len(RR_dopo) (ci sono 105 nan)","a7b254fb":"#\u00a0dRR\ndRR_prima = []\ndRR_dopo = []\nfor i in range(0,len(RR_prima)-1):\n    dRR_pre = RR_prima[i+1] - RR_prima[i]\n    dRR_post = RR_dopo[i+1] - RR_dopo[i]\n    dRR_prima.append(dRR_pre)\n    dRR_dopo.append(dRR_post)\n# AGGIUNGO NAN ALLA FINE MA NON SO SE E' GIUSTO, FORSE BISOGNA AGGIUNGERLI DA QUALCHE ALTRA PARTE, POI ANDRANNO SOSTITUITI CON QUALCOSA\ndRR_prima.append(np.nan)\ndRR_dopo.append(np.nan)\n","51f31855":"len(dRR_dopo)","d44528b6":"# FAI ATTENZIONE CHE PERDIAMO 3 BATTITI all'inizio e 3 alla fine\n# Mean RR considerando windows di 3\nmean_RR = []\nfor i in range(len(R_loc)): \n    mean_RR.append(np.nan)\n    mean_RR.append(np.nan)\n    mean_RR.append(np.nan)\n    for j in range(3, len(R_loc[i])-3):\n        RR_3 = abs(R_loc[i][j][0] - R_loc[i][j-1][0])\n        RR_2 = abs(R_loc[i][j-1][0] - R_loc[i][j-2][0])\n        RR_1 = abs(R_loc[i][j-2][0] - R_loc[i][j-3][0])\n    \n        RR_4 = abs(R_loc[i][j+1][0] - R_loc[i][j][0])\n        RR_5 = abs(R_loc[i][j+2][0] - R_loc[i][j+1][0])\n        RR_6 = abs(R_loc[i][j+3][0] - R_loc[i][j+2][0])\n        RR_mean = (RR_1+RR_2+RR_3+RR_4+RR_5+RR_6)\/6\n        mean_RR.append(RR_mean)\n    mean_RR.append(np.nan)\n    mean_RR.append(np.nan)\n    mean_RR.append(np.nan)\n        ","07009a2f":"mean_RR","cf94e8c8":"# Quanti picchi ci sono in ogni segnale?\nlab = np.array(df.label)\nfor i in range (lab.size):\n    print(len(df.label[i]))","a38f1a6e":"norm= np.moveaxis(filtered1[8], -1, 0)\n\nplt.plot(filtered1[8])\n#plt.plot(norm)","02a5179a":"# Normalizzo il segnale \n\nM = filtered1[0].max()\nm = filtered1[0].min()\n\nfilt_norm = (filtered1[8] - m)\/(M-m)","aaee014a":"beat_norm = filt_norm[pos]\nplt.plot(beat_norm)\n#plt.plot(d1[0][pos])","81fc0ee9":"# Ricavo misure RR\n\n# Ho le posizioni in termini di sample, voglio avere RR come tempi: \n# posizione_r * 1\/Fs = tempo_r\n\n# RRP \u00e8 la differenza tra R e il precedente, posso avere un vettore che contiene tutti gli RRP\n\n# RRN \u00e8 la differenza tra R e il successivo\n\n# MEAN \u00e8 la media delle ampiezze 25 campioni prima e 25 dopo il picco R --> questo \u00e8 influenzato dalla Fs\n\n\n","bae71aaf":"### 3) Posizione picchi","a44a4fdd":"### Prima di tutto ricordati di:\n\n* controllare il bilanciamento delle classi\n* Si pu\u00f2 fare un resampling, ovvero riportare i segnali alla stessa frequenza di campionamento (250 Hz)\n* filtrare (highpass: 2.0 Hz e lowpass: 20Hz)\n\n* Dividi in battiti\n#### SPLITTING TRAIN-VALIDATION-TEST\n* normalizzare con i parametri del training","63ca4d52":"## Resampling","943e77d4":"### 2) Labels","c5f755f2":"# AGGIUNTE (26\/01)","ac690bd1":"## Normalizzazione e standardizzazione\n\nIdea:\n* Normalizzare il segnale per ogni paziente\n* Calcolo features temporali sul segnale intero del paziente (RRN, RRP, RR medio...),(avremo dei missing data per il primo e l'ultimo battito, possiamo metterci la media.)\n* Dividere in battiti\n* Assegnare ad ogni battito le features temporali calcolate in precedenza \n* Split train-test battiti gi\u00e0 normalizzati\n* Calcolo normalizzazione features temporali su train\n* Applico al test la normalizzazione\n","c321d910":"#### Ora abbiamo i primi tot battiti, il punto in cui sono presenti i picchi e a che classe corrisponde il picco. Proviamo a plottarli","bc6dfe78":"## Creiamo il dataframe","90e6762a":"## Extract dataset","4170c153":"## Bilanciamento classi","eed05b6b":"# Assignment notes (10\/12)\n\nIntroduction:\nPAC\/PVC: random contraction in the ventricule or in the atrium, we can detect them with ECG.\n\nPVC --> shape is different (higher)\nPAC --> rhythm is different (RR interval shorter) and shape is similar.\n\nThey are normal events but some research associate them to other problems such as the beginning of atrial fibrillation development, stroke (PAC), or ventricular disfunction (connectivity\/tissues fibrosis) (PVC). \n\nObjective: \nBeat classifier NSR, PVC, PAC\ninput: 2-leads ecg and R-peaks position.\noutput: N\/V\/S annotations for each R-peak.\n\nDatabase:\n105 patients, different Fs, 2-leads ecg, labels, peaks positions.\nID_Fs_typefile.mat \ntypefile: \n\"ann\" contains annotations\n\"rpk\" contains the peak position\n\"\" is the ecg signal\n\nWhat information distinguish PAC and PVC? \n\nReport:\npaper format (intro, material, methods (explain the choices), reuslts, discussion, conclusions)\n\nSubmission (report + code) before the exam (1week), they give us the test set (no labels) and we have to make predictions and deliver them THE NEXT DAY! Then they give us the scoring and in the exam we will justify the choices and talk about the scoring final values.","327025b1":"## Filtraggio","a8b8b9a9":"# Preprocessing \n","0e61f9a2":"## Features extraction\n* Previous RR interval: per un battito guarda la distanza temporale dal picco precedente\n* Next RR interval: stessa cosa ma guardando la distanza dal successivo\n* Media aritmetica di 50 ampiezze centrate sul picco R ??\n* Media delle durate su tot picchi\n\n\n* Estrarre i singoli battiti (vedi note sul procedimento), questa \u00e8 una feature perch\u00e8 contiene la forma di un battito.\n","0dd48484":"## Import libraries","cbbe8d6e":"## HRV features:\n- RR intervals (i-1, i+1) ok\n- dRR: RR-RR (i-1, i+1) ok \n- Media, std degli RR in finestra temporale (3 samples prima, 3 samples dopo) ok media\n- Std di dRR in finestra temporale (1 min precedente, 2 min centrato) ","4f32f240":"### Aggiungo il segnale ecg","ac246955":"#### Idee\n\nDataFrame:\nNumero paziente\nVettore posizione battiti\nVettore labels ('N':0, 'V':1, 'S': 2) <--- encoding\necg lead 1 e lead 2\n\nInfo aggiuntive:\nHeart rate: calcolata come differenza (in secondi quindi * 1\/Fs) tra picchi R. \n\nCome distinguere la morfologia? Si pu\u00f2 fare come a laboratorio estraendo i battiti e facendo cross correlazione? \n\nSi pu\u00f2 usare deep learning? Rivedi esercitazioni","0a6efa91":"# Esploriamo i dati\n\n### 1) Segnale ecg","965efa4b":"## Set the directory","b4c17263":"# Estrazione Features","b50361df":"# La prima parte \u00e8 uguale al notebook \"Import_data\""}}