{"cell_type":{"74de6d87":"code","757e2d8e":"code","dd64d8a9":"code","f8f3ea47":"code","4a90092c":"code","16beb5ba":"code","639bc295":"code","694f27e6":"code","972363ea":"code","9c2da9ed":"code","7a224b4a":"code","143f6eeb":"code","2e9f400d":"code","1cd332ec":"code","d22754f5":"code","a8eea45e":"code","163334af":"markdown","9cdaaa0d":"markdown","34ad1313":"markdown","ebe43a93":"markdown","794c1636":"markdown","9d23382b":"markdown","b86754a4":"markdown"},"source":{"74de6d87":"import tensorflow.keras as keras\nfrom keras.applications import *\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom keras import layers\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.callbacks import History\nimport matplotlib.pyplot as plt\nimport numpy as np\nRANDOM_SEED = 123","757e2d8e":"datagen = ImageDataGenerator(\n    rescale = 1.0\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip = True,\n    validation_split=0.1\n)\n\nbatch_size = 64\nnum_classes = 2\nimage_size = 200","dd64d8a9":"train_generator = datagen.flow_from_directory(\n    '..\/input\/colorectal-cancer\/data\/train',\n    target_size = (image_size,image_size),\n    batch_size = batch_size,\n    class_mode = 'binary',\n    #subset ='training'\n    \n)\n\ndev_generator = datagen.flow_from_directory(\n    '..\/input\/colorectal-cancer\/data\/test',\n    target_size = (image_size,image_size),\n    batch_size = batch_size,\n    class_mode = 'binary'\n    #subset ='validation'\n)","f8f3ea47":"sample = train_generator.next();\nplt.imshow(sample[0][0])\ntrain_generator.reset()","4a90092c":"INIT_LR = 0.001\n","16beb5ba":"base_model = tf.keras.applications.VGG16(input_shape=(200,200,3),include_top=False,weights=\"imagenet\")","639bc295":"# Freezing Layers\n\nfor layer in base_model.layers[:-8]:\n    layer.trainable=False","694f27e6":"from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation\nfrom keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D","972363ea":"# Building Model\n\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(BatchNormalization())\n#model.add(GlobalAveragePooling2D())\nmodel.add(Flatten())\n#model.add(Dropout(0.1))\n#model.add(Dense(32,kernel_initializer='he_uniform'))\n#model.add(BatchNormalization())\n#model.add(Activation('relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(128,kernel_initializer='he_uniform', activation='relu'))\n#model.add(BatchNormalization())\n#model.add(Activation('relu'))\n#model.add(Dropout(0.5))\nmodel.add(Dense(256,kernel_initializer='he_uniform' , activation='relu'))\nmodel.add(Dropout(0.1))\n#model.add(BatchNormalization())\n#model.add(Activation('relu'))\nmodel.add(Dense(1,activation='sigmoid'))","9c2da9ed":"model.summary()","7a224b4a":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\nImage(filename='convnet.png')","143f6eeb":"model = Sequential()\nmodel.add(Conv2D(64,(5,5)\n        ,input_shape=(image_size,image_size,3)\n        ,activation='relu'))\n\nmodel.add(Conv2D(64,(5,5)\n        ,input_shape=(image_size,image_size,3)\n        ,activation='relu'))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.25))\n\nmodel.add(Conv2D(128,(3,3)\n        ,input_shape=(image_size,image_size,3)\n        ,activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.2))\n\nmodel.add(Conv2D(256,(3,3)\n        ,input_shape=(image_size,image_size,3)\n        ,activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.3))\n\nmodel.add(Conv2D(512,(3,3)\n        ,input_shape=(image_size,image_size,3)\n        ,activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.3))\n\nmodel.add(Conv2D(512,(3,3)\n        ,input_shape=(image_size,image_size,3)\n        ,activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\nmodel.add(Dense(1,activation='sigmoid'))\n\n#model.compile(loss='binary_crossentropy',\n #             optimizer= 'SGD',\n  #            metrics=['accuracy'])\nmodel.summary()","2e9f400d":"opt = tf.keras.optimizers.Adam(0.00001)\nmodel.compile(optimizer=opt,loss='binary_crossentropy', metrics=['accuracy'])\n","1cd332ec":"history = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    \n    epochs=5,\n    validation_data=dev_generator,\n    validation_steps=20\n)","d22754f5":"#showing results and model accuracy \nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n#epochs=5\nepochs_range = range(5)\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","a8eea45e":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)","163334af":"### Visualize\nLet us inspect an image from the dataset.","9cdaaa0d":"### Input Data\nUsing `flow_from_directory` from keras lets us easily import the images into our script. It automatically lables the images according to the folder names.","34ad1313":"### Define the Model\nThe model is as follows.","ebe43a93":"# Colorectal Classification using CNN\n\nThis kernel is a demonstration of using CNN with keras on tensorflow to classify if an image of a cell has Malaria or not.","794c1636":"### Data Augmentation\nHere, I use `ImageDataGenerator` from keras.","9d23382b":"### Visualize the results","b86754a4":"### Time to Train!"}}