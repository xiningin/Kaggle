{"cell_type":{"6a4313a2":"code","91ea6ad6":"code","de3a7a41":"code","614207e9":"code","db25d7d3":"code","216d9963":"code","4d8590b4":"code","39407cef":"code","936313ad":"code","4862b65d":"code","6cd49503":"code","d9690db5":"code","58a4f6cd":"code","7f923c96":"code","8c5e50fc":"code","a3a0505b":"code","e9476cab":"code","981504db":"code","d7591edf":"code","6a67a6ae":"code","4f84f838":"code","9be128ee":"code","b0466748":"code","e8d88512":"markdown","af923c94":"markdown","0105af44":"markdown","9f549820":"markdown","25fea621":"markdown","0cd8c9a3":"markdown","eb089ea3":"markdown","2ef92830":"markdown"},"source":{"6a4313a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","91ea6ad6":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nimport sklearn.metrics as metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\nimport warnings\nwarnings.filterwarnings('ignore')","de3a7a41":"train_data_path = \"..\/input\/covid19-image-dataset\/Covid19-dataset\/train\"\ntest_data_path = \"..\/input\/covid19-image-dataset\/Covid19-dataset\/test\"","614207e9":"img = plt.imread(os.path.join(train_data_path, \"Covid\/01.jpeg\"))\nplt.imshow(img)\nheight, width, dim = img.shape\nplt.title('Covid')\nprint(\"size of image (h x w)\",height,width)","db25d7d3":"img = plt.imread(os.path.join(train_data_path, \"Viral Pneumonia\/01.jpeg\"))\nplt.imshow(img)\nheight, width, dim = img.shape\nplt.title('Viral Pneumonia')\nprint(\"size of image (h x w)\",height,width)","216d9963":"img = plt.imread(os.path.join(train_data_path, \"Normal\/01.jpeg\"))\nplt.imshow(img)\nheight, width, dim = img.shape\nplt.title('Normal')\nprint(\"size of image (h x w)\",height,width)","4d8590b4":"##image augmentaion\ntrain = ImageDataGenerator(rescale=1.\/255,\n                    rotation_range=20,\n                    horizontal_flip=True,\n                    shear_range = 0.2,\n                    fill_mode = 'nearest')\ntrain_dataset = train.flow_from_directory(train_data_path,\n                                          target_size=(150,150),\n                                          batch_size = 32,\n                                          class_mode = 'categorical',shuffle=True)","39407cef":"train_dataset.classes","936313ad":"train_dataset.class_indices","4862b65d":"import plotly.express as px\ntraining_total_image_covid = len(train_dataset.classes[train_dataset.classes==0])\ntraining_total_image_normal = len(train_dataset.classes[train_dataset.classes==1])\ntraining_total_image_pneumonia = len(train_dataset.classes[train_dataset.classes==2])\ntotal_data_training = [training_total_image_covid,training_total_image_normal,training_total_image_pneumonia]\nlabel_class = ['Covid','Normal','Viral Pneumonia']\nfig = px.bar(x=label_class, y=total_data_training,labels={'x':'Clasification Images','y':'Total Data'},width=800, height=400,title=\"Train Images Dataset\")\nfig.show()","6cd49503":"benchmark_model = Sequential()\n# Input here is 4D array (batchsize, height, width, channels) - we have already created the train_generator with batch size 32\n# 32 Images of size each 150x150 with 3 color channels will be input into this layer\nbenchmark_model.add(Conv2D(128, kernel_size=7, activation='relu', input_shape=(150,150,3)))\nbenchmark_model.add(MaxPool2D(pool_size=(4,4), strides=(2,2)))\nbenchmark_model.add(Conv2D(64, kernel_size=5, activation='relu'))\nbenchmark_model.add(MaxPool2D(pool_size=(4,4), strides=(2,2)))\nbenchmark_model.add(Flatten())\nbenchmark_model.add(Dense(128,activation='relu'))\nbenchmark_model.add(Dense(3,activation='softmax'))\nbenchmark_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\nbenchmark_model.summary()","d9690db5":"from keras.utils.vis_utils import plot_model\nplot_model(benchmark_model)","58a4f6cd":"early_stopping = EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta=0,\n    patience=0,\n    verbose=0,\n    mode=\"auto\",\n    baseline=None,\n    restore_best_weights=False,\n)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=0.001)\nmodelcheck = ModelCheckpoint('best_model.hdf5', monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')","7f923c96":"history = benchmark_model.fit(train_dataset, \n                    epochs=50,\n                    callbacks=[modelcheck,reduce_lr,early_stopping],\n                    batch_size=32)","8c5e50fc":"akurasi = history.history['acc']\nloss = history.history['loss']","a3a0505b":"plt.title('Nilai Akurasi Training')\nsns.lineplot(data=akurasi)\nplt.xlabel('Epoch')\nplt.ylabel('Nilai Akurasi')","e9476cab":"plt.title('Nilai Loss Training')\nsns.lineplot(data=loss)\nplt.xlabel('Epoch')\nplt.ylabel('Nilai Loss')","981504db":"import numpy as np\ntest = ImageDataGenerator(rescale=1\/255)                                       \ntest_dataset = test.flow_from_directory(test_data_path,target_size=(150, 150),batch_size=32,shuffle=False)\ntest_steps_per_epoch = np.math.ceil(test_dataset.samples \/ test_dataset.batch_size)\n\npredictions = benchmark_model.predict(test_dataset, steps=test_steps_per_epoch)\npredicted_classes = np.argmax(predictions, axis=1)","d7591edf":"true_classes = test_dataset.classes\nclass_labels = list(test_dataset.class_indices.keys()) ","6a67a6ae":"report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\nprint(report)","4f84f838":"conf_matrix = confusion_matrix(true_classes, predicted_classes)\nplt.figure(figsize = (7,7))\nsns.heatmap(conf_matrix, annot=True)","9be128ee":"print('Precision: %.3f' % precision_score(true_classes, predicted_classes,average='micro'))\nprint('Recall: %.3f' % recall_score(true_classes, predicted_classes,average='micro'))\nprint('Accuracy: %.3f' % accuracy_score(true_classes, predicted_classes))","b0466748":"test_total_image_covid = len(true_classes[true_classes==0])\ntest_total_image_normal = len(true_classes[true_classes==1])\ntest_total_image_pneumonia = len(true_classes[true_classes==2])\ntotal_data_test = [test_total_image_covid,test_total_image_normal,test_total_image_pneumonia]\nlabel_class = ['Covid','Normal','Viral Pneumonia']\nfig = px.bar(x=label_class, y=total_data_test,labels={'x':'Clasification Images','y':'Total Data'},width=800, height=400,title=\"Test Images Dataset\")\nfig.show()","e8d88512":"### Train Model","af923c94":"### Using CallBack","0105af44":"### Data Path for Data Test and Data Train","9f549820":"### Doing Classification on Test Dataset using Model","25fea621":"### Build Model","0cd8c9a3":"### Show Images That Contain in Dataset","eb089ea3":"### Import Library ","2ef92830":"### Image Preparation for Model"}}