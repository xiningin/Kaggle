{"cell_type":{"a2a5d671":"code","e8ef8cc5":"code","024a484d":"code","7d0a564a":"code","7173e917":"code","992ecfa3":"code","3e5547ba":"code","301c4ed7":"code","e8d63cf0":"code","c77c16a9":"code","c7ba1a2c":"code","b567b9fb":"code","68116b5c":"code","99066195":"code","3ddcf152":"code","88132e06":"code","8802a30b":"code","c025cdcd":"code","1f9dd4b8":"code","75ef5cc1":"code","864f3471":"code","84f6d3b5":"code","3cd9f42b":"code","92d8745a":"code","9a01abd1":"code","1f9695f6":"code","78f0806d":"code","336ba026":"code","0c17331e":"code","58ac1678":"code","23107b01":"markdown","3a7875f1":"markdown","3e2e0645":"markdown","0e946dbb":"markdown"},"source":{"a2a5d671":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e8ef8cc5":"#load the dataset\ntrain=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ngender_submission=pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n","024a484d":"#importing libraary\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,f1_score,confusion_matrix\nfrom sklearn.preprocessing import OneHotEncoder,StandardScaler,PowerTransformer,MinMaxScaler\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\n%matplotlib inline","7d0a564a":"#check train shpae and data\ntrain.shape","7173e917":"train.head()","992ecfa3":"#check test shape\ntest.shape","3e5547ba":"# In test data Survived column are not present\ntest.head()","301c4ed7":"#checking gender submission data shape and data\ngender_submission.shape","e8d63cf0":"gender_submission.head()","c77c16a9":"#get the \"survived\" column from gender_submission dataset and add this to the test.csv dataset so that combine the train and test dataset\nnew_gender=gender_submission[\"Survived\"]\ntest.insert(1,column=\"Survived\",value=new_gender)\ntest.head()","c7ba1a2c":"#combining the train and test dataset\ndf=pd.concat([train,test])\ndf.shape","b567b9fb":"#too musch null value in Age and Cabin columns\ndf.isnull().sum()","68116b5c":"df.info()","99066195":"df.describe()","3ddcf152":"#checking co_relation among columns\ndf.corr()","88132e06":"sns.heatmap(df.corr())","8802a30b":"#dropping unwanted columns\ndf=df.drop([\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"],axis=1)\ndf.head()","c025cdcd":"#get features and terget columns\nY=df.Survived\nX=df.drop([\"Survived\"],axis=1)\nX.head()","1f9dd4b8":"#pipe1 impute all the missing values,\"num_imputer\" impute the numerical values and \"cat_imputer\" impute categorical columns\n#pipe2 encode all the categorical variable into numerical(dummy vaeiable) variable\n#pipe3 scaled all the columns \npipe1=ColumnTransformer(transformers=[(\"num_imputer\",SimpleImputer(strategy=\"mean\"),['Age',\"Fare\"]),\n                                      (\"cat_imputer\",SimpleImputer(strategy=\"most_frequent\"),[6])]\n                                        ,remainder=\"passthrough\")\npipe2=ColumnTransformer(transformers=[(\"ohe\",OneHotEncoder(sparse=False,drop=\"first\"),[2,4])]\n                                                    ,remainder =\"passthrough\")\npipe3=ColumnTransformer(transformers=[(\"scalr\",StandardScaler(),[0,1,2,3,4,5,6,7])]\n                                                        ,remainder =\"passthrough\")\npipe=Pipeline([(\"pipe1\",pipe1),(\"pipe2\",pipe2)])\nnew=pd.DataFrame(pipe.fit_transform(X))\nnew.head()","75ef5cc1":"#Here Age column is noramlly ditributed but Fare column is right skewd ,lets check and fixed it\nplt.figure(figsize=(14,4))\nplt.subplot(121)\nsns.distplot(new[3],color= \"g\")\nplt.title(\"Age\")\nplt.xlabel(\"age\")\nplt.show()\n\nprint(\"Age skewness is :\",new[3].skew())","864f3471":"#lets check the Fare col distribution\nplt.figure(figsize=(14,4))\nplt.subplot(121)\nsns.distplot(new[4],color= \"r\")\nplt.title(\"Fare\")\nplt.xlabel(\"Fare\")\n\nplt.show()\n\nprint(\"Fare col skewness:\",new[4].skew())","84f6d3b5":"new","3cd9f42b":"#Fare col is right skewed so we fixed it by normal distribution \npipe4=ColumnTransformer(transformers=[(\"skew\",PowerTransformer(standardize=False),[4])]\n                        ,remainder =\"passthrough\")\n\nnew=pd.DataFrame(pipe4.fit_transform(new))\n\n#after transforming the fare col by power transformer ,lets check the distribution\nplt.figure(figsize=(14,4))\nplt.subplot(121)\nsns.distplot(new[0],color= \"r\")\nplt.title(\"after tranform Fare\")\nplt.xlabel(\"Fare\")\nplt.show()\n\nprint(\"Fare col skewness:\",new[0].skew())","92d8745a":"xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size = 0.2, random_state = 42)\n#build a final pipeline \npipe_f=Pipeline([(\"pipe1\",pipe1),(\"pipe2\",pipe2) ,(\"pipe4\",pipe4),(\"pipe3\",pipe3)])\n#fit with the data\nxtrain=pd.DataFrame(pipe_f.fit_transform(xtrain))\nxtest=pd.DataFrame(pipe_f.transform(xtest))","9a01abd1":"print(\"xtrain shape\",xtrain.shape)\nprint(\"xtest shape\",xtest.shape)","1f9695f6":"#knn classifier\nknn=KNeighborsClassifier(n_neighbors= 7,weights='uniform')\nknn.fit(xtrain,ytrain)\nypred_knn=knn.predict(xtest)\nprint(\"KNN accuracy score:\",accuracy_score(ytest,ypred_knn))\nprint(\"confusion metrics:\",confusion_matrix(ytest,ypred_knn))","78f0806d":"#support vector machine\nsvc=SVC()\nsvc.fit(xtrain,ytrain)\nypred_svc=svc.predict(xtest)\nprint(\"SVC accuracy score:\",accuracy_score(ytest,ypred_svc))\nprint(\"confusion metrics:\",confusion_matrix(ytest,ypred_svc))","336ba026":"#random forest\nrf=RandomForestClassifier(n_estimators=150, max_depth=8,max_samples=0.75 )\nrf.fit(xtrain,ytrain)\nypred_rf=rf.predict(xtest)\nprint(\"Randome forest accuracy score:\",accuracy_score(ytest,ypred_rf))\nprint(\"confusion metrics:\",confusion_matrix(ytest,ypred_rf))","0c17331e":"#ada boost algotithm\nada=AdaBoostClassifier()\nada.fit(xtrain,ytrain)\nypred_ada=ada.predict(xtest)\nprint(\"Ada boost accuracy score:\",accuracy_score(ytest,ypred_ada))\nprint(\"confusion metrics:\",confusion_matrix(ytest,ypred_ada))","58ac1678":"#Gradiant boosting algorithm\ngbc=GradientBoostingClassifier(criterion =\"mse\", learning_rate= 0.05,loss=\"exponential\",n_estimators= 300)\ngbc.fit(xtrain,ytrain)\nypred_gbc=gbc.predict(xtest)\nprint(\"Gradiant Boost accuracy score:\",accuracy_score(ytest,ypred_gbc))\nprint(\"confusion metrics:\",confusion_matrix(ytest,ypred_gbc))","23107b01":"# Building and evaluate the models","3a7875f1":"# feature Engineering","3e2e0645":"# our most robust model is ada boost classifier ","0e946dbb":"# train test split"}}