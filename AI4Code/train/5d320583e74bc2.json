{"cell_type":{"2bd0908a":"code","06e7c08f":"code","5444b5b5":"code","1649d66f":"code","15e9fb8d":"code","f6f77c47":"code","d10240f7":"code","20c1268f":"code","dd306109":"code","7205e2a7":"code","b65a91e9":"code","11d67e91":"code","b949baa2":"code","334f4025":"code","dc4ea656":"code","ad2ec9d7":"code","e2b31306":"code","d56301cb":"markdown","d5858d91":"markdown","7a8bdf4d":"markdown","51769073":"markdown","4d2ac38c":"markdown","117cd555":"markdown","4900000d":"markdown","0e28565b":"markdown","f0b8c3d5":"markdown","6531a5fe":"markdown","19b3e3b8":"markdown","64e79451":"markdown","b2892725":"markdown","64d3dde2":"markdown","8b07a181":"markdown","9c55f4bf":"markdown","09acd95d":"markdown","3e7ab973":"markdown","afd68087":"markdown","22874841":"markdown","7e036200":"markdown","dd784908":"markdown","cbc22574":"markdown","5cd2a2c0":"markdown","20c3d100":"markdown","acbd5ccf":"markdown","80b16cc6":"markdown","ba033b62":"markdown","41fead4c":"markdown","3304f407":"markdown","825d1636":"markdown","5a1f07e7":"markdown","bd5b8b61":"markdown","8300ac86":"markdown","bf333a0f":"markdown","dcc9c49f":"markdown","85adff41":"markdown"},"source":{"2bd0908a":"import pandas as pd\nimport pylab as pl\nimport numpy as np\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline \nimport matplotlib.pyplot as plt","06e7c08f":"#Click here and press Shift+Enter\n!wget -O cell_samples.csv https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/ML0101ENv3\/labs\/cell_samples.csv","5444b5b5":"cell_df = pd.read_csv(\"cell_samples.csv\")\ncell_df.head()","1649d66f":"#refer the DataSlicing and Mathplotlib Notebooks for details about ploting and slicing the data\nax = cell_df[cell_df['Class'] == 4][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='DarkBlue', label='malignant');\ncell_df[cell_df['Class'] == 2][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='Yellow', label='benign', ax=ax);\nplt.show()","15e9fb8d":"cell_df.dtypes","f6f77c47":"cell_df = cell_df[pd.to_numeric(cell_df['BareNuc'], errors='coerce').notnull()]\ncell_df['BareNuc'] = cell_df['BareNuc'].astype('int')\ncell_df.dtypes","d10240f7":"feature_df = cell_df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']]\nX = np.asarray(feature_df)\nX[0:5]","20c1268f":"cell_df['Class'] = cell_df['Class'].astype('int')\ny = np.asarray(cell_df['Class'])\ny [0:5]","dd306109":"X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","7205e2a7":"from sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, y_train) ","b65a91e9":"yhat = clf.predict(X_test)\nyhat [0:5]","11d67e91":"from sklearn.metrics import classification_report, confusion_matrix\nimport itertools","b949baa2":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","334f4025":"# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, yhat, labels=[2,4])\nnp.set_printoptions(precision=2)\n\nprint (classification_report(y_test, yhat))\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Benign(2)','Malignant(4)'],normalize= False,  title='Confusion matrix')","dc4ea656":"from sklearn.metrics import f1_score\nf1_score(y_test, yhat, average='weighted') ","ad2ec9d7":"from sklearn.metrics import jaccard_similarity_score\njaccard_similarity_score(y_test, yhat)","e2b31306":"import pandas as pd\nimport pylab as pl\nimport numpy as np\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline \nimport matplotlib.pyplot as plt\n!wget -O cell_samples.csv https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/ML0101ENv3\/labs\/cell_samples.csv\ncell_df = pd.read_csv(\"cell_samples.csv\")\ncell_df.head()\nax = cell_df[cell_df['Class'] == 4][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='DarkBlue', label='malignant');\ncell_df[cell_df['Class'] == 2][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='Yellow', label='benign', ax=ax);\nplt.show()\ncell_df.dtypes\ncell_df = cell_df[pd.to_numeric(cell_df['BareNuc'], errors='coerce').notnull()]\ncell_df['BareNuc'] = cell_df['BareNuc'].astype('int')\ncell_df.dtypes\nfeature_df = cell_df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']]\nX = np.asarray(feature_df)\nX[0:5]\ncell_df['Class'] = cell_df['Class'].astype('int')\ny = np.asarray(cell_df['Class'])\ny [0:5]\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)\nfrom sklearn import svm\nclf = svm.SVC(kernel='linear')\nclf.fit(X_train, y_train) \nyhat = clf.predict(X_test)\nyhat [0:5]\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\ncnf_matrix = confusion_matrix(y_test, yhat, labels=[2,4])\nnp.set_printoptions(precision=2)\n\nprint (classification_report(y_test, yhat))\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Benign(2)','Malignant(4)'],normalize= False,  title='Confusion matrix')\nfrom sklearn.metrics import f1_score\nf1_score(y_test, yhat, average='weighted') \nfrom sklearn.metrics import jaccard_similarity_score\njaccard_similarity_score(y_test, yhat)","d56301cb":"Name: Aayushi Agrawal\nRoll no: A202\nSAP ID: 70011118003","d5858d91":"<h1>Table of contents<\/h1>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ol>\n        <li><a href=\"#load_dataset\">Load the Cancer data<\/a><\/li>\n        <li><a href=\"#modeling\">Modeling<\/a><\/li>\n        <li><a href=\"#evaluation\">Evaluation<\/a><\/li>\n        <li><a href=\"#practice\">Practice<\/a><\/li>\n    <\/ol>\n<\/div>\n<br>\n<hr>","7a8bdf4d":"Here in the above code we are trying jaccard index which is good for accuracy.","51769073":"Lets try jaccard index for accuracy:","4d2ac38c":"In the above code we are droping the rows which contains non numerical value in the BareNuc column.","117cd555":"In this notebook, you will use SVM (Support Vector Machines) to build and train a model using human cell records, and classify cells to whether the samples are benign or malignant.\n\nAs we discussed in the class SVM is to map data to a high-dimensional feature space so that data points can be categorized, even when the data are not otherwise linearly separable. A separator between the categories is found, then the data is transformed in such a way that the separator could be drawn as a hyperplane. Following this, characteristics of new data can be used to predict the group to which a new record should belong.","4900000d":"<h2 id=\"load_dataset\">Load the Cancer data<\/h2>\nThe example is based on a dataset that is publicly available from the UCI Machine Learning Repository (Asuncion and Newman, 2007)[http:\/\/mlearn.ics.uci.edu\/MLRepository.html]. The dataset consists of several hundred human cell sample records, each of which contains the values of a set of cell characteristics. The fields in each record are:\n\n|Field name|Description|\n|--- |--- |\n|ID|Clump ID|\n|Clump|Clump thickness|\n|UnifSize|Uniformity of cell size|\n|UnifShape|Uniformity of cell shape|\n|MargAdh|Marginal adhesion|\n|SingEpiSize|Single epithelial cell size|\n|BareNuc|Bare nuclei|\n|BlandChrom|Bland chromatin|\n|NormNucl|Normal nucleoli|\n|Mit|Mitoses|\n|Class|Benign or malignant|\n\n<br>\n<br>\n\nFor the purposes of this example, we're using a dataset that has a relatively small number of predictors in each record. To download the data, we will use `!wget` (We studied it in last Lab) to download it from IBM Object Storage.  \n","0e28565b":"In the above code we are importing the f1_score from sklearn.metrics.","f0b8c3d5":"In the above code we are loading the data from the cell_samples.csv file. But here it looks like there is no data to show due to the empty data error in output. ","6531a5fe":"In the above code we are computing confusion matrix and plotting non normalized confusion matrix.","19b3e3b8":"The SVM algorithm offers a choice of kernel functions for performing its processing. Basically, mapping data into a higher dimensional space is called kernelling. The mathematical function used for the transformation is known as the\u00a0kernel\u00a0function, and can be of different types, such as:\n\n    1.Linear\n    2.Polynomial\n    3.Radial basis function (RBF)\n    4.Sigmoid\nEach of these functions has its characteristics, its pros and cons, and its equation, but as there's no easy way of knowing which function performs best with any given dataset, we usually choose different functions in turn and compare the results. Let's just use the default, RBF (Radial Basis Function) for this lab.","64e79451":"\n<h1 align=center><font size=\"5\"> Machine Learning (IT):  Sem V <\/font><\/h1>\n<h1 align=center><font size=\"5\"> SVM (Support Vector Machines)<\/font><\/h1>\n","b2892725":"The above code is the explanation for the plotting of the confussion matrix.","64d3dde2":"You can refer <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.to_numeric.html\">Pandas Documentation <\/a> of to_numeric for more details.  \n\n* pandas.to_numeric(arg, errors='raise', downcast=None)\n\n* Convert argument to a numeric type.\n\nThe default return dtype is float64 or int64 depending on the data supplied. Use the downcast parameter to obtain other dtypes.\n\n   Parameters\n\n1. args : Scalar, list, tuple, 1-d array, or Series\n2. errors : {\u2018ignore\u2019, \u2018raise\u2019, \u2018coerce\u2019}, default \u2018raise\u2019\n            If \u2018raise\u2019, then invalid parsing will raise an exception.\n            If \u2018coerce\u2019, then invalid parsing will be set as NaN.\n            If \u2018ignore\u2019, then invalid parsing will return the input.\n        downcast{\u2018integer\u2019, \u2018signed\u2019, \u2018unsigned\u2019, \u2018float\u2019}, default None\n\nIf not None, and if the data has been successfully cast to a numerical dtype (or if the data was numeric to begin with), downcast that resulting data to the smallest numerical dtype possible according to the following rules:\n\n  \u2018integer\u2019 or \u2018signed\u2019: smallest signed int dtype (min.: np.int8)\n\n  \u2018unsigned\u2019: smallest unsigned int dtype (min.: np.uint8)\n\n  \u2018float\u2019: smallest float dtype (min.: np.float32)\n","8b07a181":"<h2 id=\"practice\">Practice<\/h2>\nCan you rebuild the model, but this time with a __linear__ kernel? You can use __kernel='linear'__ option, when you define the svm. How the accuracy changes with the new kernel function?","9c55f4bf":"You can also easily use the __f1_score__ from sklearn library:","09acd95d":"It looks like the __BareNuc__ column includes some values that are not numerical. We can drop those rows: ","3e7ab973":"Okay, we split our dataset into train and test set:","afd68087":"In the above code we are importing svm from sklearn. In the next line sklearn.svm.SVC which short for support vector classifier. And here we are using the kernel trick to fit the data.","22874841":"In the above code we are spliting the data  into train and test set. Printing the both sets one by one by considering  X and y variables. test size for 0.2 and random_state value as 4.","7e036200":"Now the model is ready in the above code to predict the new values.","dd784908":"<h2 id=\"modeling\">Modeling (SVM with Scikit-learn)<\/h2>","cbc22574":"So in the above code we are importing classification report and confusion matrix from sklearn.metrics.","5cd2a2c0":"Now we are taking the numerical values in the class and then taking all the values in the array y.","20c3d100":"## Train\/Test dataset","acbd5ccf":"<h2>Thanks for completing this lesson!<\/h2>\n<h4>Author:  Santosh Bothe <\/a><\/h4>\n<hr>\n\n<p>Copyright &copy; 2020 ML Class IEDC Shirur.","80b16cc6":"After being fitted, the model can then be used to predict new values:","ba033b62":"The ID field contains the patient identifiers. The characteristics of the cell samples from each patient are contained in fields Clump to Mit. The values are graded from 1 to 10, with 1 being the closest to benign.\n\nThe Class field contains the diagnosis, as confirmed by separate medical procedures, as to whether the samples are benign (value = 2) or malignant (value = 4).\n\nLets look at the distribution of the classes based on Clump thickness and Uniformity of cell size:","41fead4c":"In the above code we are plotting and slicing the data. We are considering a class with taking the input values for kind,x,y,color and label. And after taking the inputs we are using plt.show() to show the plotting in the output that we created. ","3304f407":"Lets first look at columns data types:","825d1636":"np.asarray() function is used when we want to convert input to an array. Input can be lists, lists of tuples, tuples, tuples of tuples, tuples of lists and ndarrays. Syntax : numpy.asarray (arr, dtype=None, order=None). \n\nIn the above code we are converting the inputs like Clump,UnifSize,UnifShape,MargAdh,SingEpiSize,BareNuc,BlandChrom,NormNucl,Mit into an array X.","5a1f07e7":"Here as an output we are taking the cell_samples.csv file in the above code.","bd5b8b61":"<h2 id=\"evaluation\">Evaluation<\/h2>","8300ac86":"We want the model to predict the value of Class (that is, benign (=2) or malignant (=4)). As this field can have one of only two possible values, we need to change its measurement level to reflect this.","bf333a0f":"## Data pre-processing and selection","dcc9c49f":"In the above code we are calling the pandas as pd,pylab as pl, numpy as np and scipy.optimize as opt from now onwards to make the code simple to write. Next we are importing preprocessing from sklearn.The sklearn.preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators. Same way we are importing train_test_split from sklearn.model_selection. \n\n%matplotlib is a magic function in IPython. %matplotlib inline sets the backend of matplotlib to the 'inline' backend. With this backend, the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it. The resulting plots will then also be stored in the notebook document.\n\nIn the last code we are calling matplotlib.pyplot as plt to make the code simple.","85adff41":"### Load Data From CSV File  "}}