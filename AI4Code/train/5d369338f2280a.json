{"cell_type":{"f83f770d":"code","134f8459":"code","d72f1c15":"code","e75c08e1":"code","5a7cc891":"code","f8e71a60":"code","60084b08":"code","bc65a36c":"code","21f96f0d":"code","67c16944":"code","e44c47fa":"code","3313628c":"code","5644b2bb":"code","1e5bfd98":"code","c352e9ba":"code","280dd0bd":"code","4102f3c7":"code","37e16639":"markdown","564b5202":"markdown"},"source":{"f83f770d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib\n\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\n%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ninput_dir = \"\/kaggle\/input\/house-prices-advanced-regression-techniques\/\"\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","134f8459":"train = pd.read_csv(f\"{input_dir}\/train.csv\")\ntest = pd.read_csv(f\"{input_dir}\/test.csv\")","d72f1c15":"train.head()\ntest.head()","e75c08e1":"all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n                      test.loc[:,'MSSubClass':'SaleCondition']))","5a7cc891":"matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)\nprices = pd.DataFrame({\"price\":train[\"SalePrice\"], \"log(price + 1)\":np.log1p(train[\"SalePrice\"])})\nprices.hist()","f8e71a60":"#log transform the target:\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n\n#log transform skewed numeric features:\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\nskewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\n\nall_data[skewed_feats] = np.log1p(all_data[skewed_feats])","60084b08":"all_data = pd.get_dummies(all_data)\nall_data.head()","bc65a36c":"#filling NA's with the mean of the column:\nall_data = all_data.fillna(all_data.mean())","21f96f0d":"#creating matrices for sklearn:\nX_train = all_data[:train.shape[0]]\nX_test = all_data[train.shape[0]:]\ny = train.SalePrice","67c16944":"from sklearn.linear_model import Ridge, Lasso, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\nfrom sklearn.model_selection import cross_val_score\ndef rmse_cv(model):\n    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n    return(rmse)","e44c47fa":"# Train and evaluate Ridge model\nmodel_ridge = Ridge(alpha=0.1)\nmodel_ridge.fit(X_train, y)\ny_pred = model_ridge.predict(X_test)\nprint(y_pred)\ny_pred = np.expm1(y_pred)\ny_pred\nX_test.index = X_test.reset_index().index+1461\nsub_df = pd.DataFrame({\"Id\":X_test.index, \"SalePrice\":y_pred})\nsub_df.SalePrice.hist()\nsub_df.to_csv(\"\/kaggle\/working\/sub1.csv\", index=False)\n##First submission RMSE = 0.13565","3313628c":"alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\ncv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() \n            for alpha in alphas]\ncv_ridge = pd.Series(cv_ridge, index = alphas)\ncv_ridge.plot(title = \"Ridge Validation\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")\nplt.show()\nprint(f\"Best: a={cv_ridge.index[cv_ridge.argmin()]}, rmse={cv_ridge.min()}\")","5644b2bb":"alphas = [0.0002,0.0005,0.001,0.005, 0.01,0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\ncv_lasso = [rmse_cv(Lasso(alpha = alpha)).mean() \n            for alpha in alphas]\ncv_lasso = pd.Series(cv_lasso, index = alphas)\ncv_lasso.plot(title = \"lasso Validation\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")\nplt.show()\nprint(f\"Best: a={cv_lasso.index[cv_lasso.argmin()]}, rmse={cv_lasso.min()}\")","1e5bfd98":"## Part 4\ncoeffs = [Lasso(alpha = alpha).fit(X_train, y).coef_ for alpha in alphas]\nl0_norms = np.count_nonzero(coeffs, axis=1)\nprint(l0_norms)\nplt.plot(l0_norms, alphas)\nplt.title('l0 norm for varying alphas')\nplt.xlabel('alpha')\nplt.ylabel('l0 norm')\nplt.xlim(0, 75)\nplt.show()","c352e9ba":"## Part 5\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.pipeline import make_pipeline\nestimators = [\n    ('Ridge Regression', Ridge(alpha=0.1)),\n    ('Lasso', Lasso(alpha=0.0005))\n]\n\nregr = StackingRegressor(estimators=estimators, final_estimator=Ridge())\nregr.fit(X_train, y)\ny_pred_stack = regr.predict(X_test)\nprint(y_pred_stack)\ny_pred_stack = np.expm1(y_pred_stack)\ny_pred_stack\nX_test.index = X_test.reset_index().index+1461\nsub_df = pd.DataFrame({\"Id\":X_test.index, \"SalePrice\":y_pred_stack})\nsub_df.SalePrice.hist()\nsub_df.to_csv(\"\/kaggle\/working\/sub2.csv\", index=False)\n\n# second submission RMSE: 0.12486","280dd0bd":"## Part 6\nimport xgboost as xgb\n\nmodel_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train, y)\n\ndtrain = xgb.DMatrix(X_train, label = y)\ndtest = xgb.DMatrix(X_test)\n\nparams = {\"max_depth\":2, \"eta\":0.1}\nmodel = xgb.cv(params, dtrain,  num_boost_round=500, early_stopping_rounds=100)\n\nmodel_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1)\nmodel_xgb.fit(X_train, y)\n\nxgb_preds = np.expm1(model_xgb.predict(X_test))\nlasso_preds = np.expm1(model_lasso.predict(X_test))\n\npreds = 0.8*lasso_preds + 0.2*xgb_preds\n\nsolution = pd.DataFrame({\"id\":test.Id, \"SalePrice\":preds})\nsolution.to_csv(\"xgb_sol.csv\", index = False)\n\n## Score Submission: 0.12315","4102f3c7":"## Part 7\nparams = {\"max_depth\":2, \"eta\":0.1}\nmodel = xgb.cv(params, dtrain,  num_boost_round=500, early_stopping_rounds=100)\n\nmodel_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1)\nmodel_xgb.fit(X_train, y)\n\nxgb_preds = np.expm1(model_xgb.predict(X_test))\nlasso_preds = np.expm1(model_lasso.predict(X_test))\n\npreds = 0.7*lasso_preds + 0.3*xgb_preds\n\nsolution = pd.DataFrame({\"id\":test.Id, \"SalePrice\":preds})\nsolution.to_csv(\"optimized_sol.csv\", index = False)\n\n## Score Submission: 0.12299","37e16639":"Ridge Regression","564b5202":"Data Preprocessing"}}