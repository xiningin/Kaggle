{"cell_type":{"76dce81f":"code","5ff6455b":"code","6a585791":"code","1662f2d7":"code","7e47acde":"code","8226cc2f":"code","82e34808":"code","0d621edf":"code","e2a00fb5":"code","db851a0e":"code","fa30761d":"code","86bba52e":"markdown","54610c14":"markdown","fe812c8f":"markdown","656b3669":"markdown","0341d305":"markdown","ebe4b0bc":"markdown","264b88d2":"markdown","9562fb39":"markdown","e088561e":"markdown","3d239090":"markdown"},"source":{"76dce81f":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","5ff6455b":"train=pd.read_csv('\/kaggle\/input\/classification-of-images\/dataset\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/classification-of-images\/dataset\/test.csv')\ntrain.head()","6a585791":"\nClass_map={'Food':0,'Attire':1,'Decorationandsignage':2,'misc':3}\ninverse_map={0:'Food',1:'Attire',2:'Decorationandsignage',3:'misc'}\ntrain['Class']=train['Class'].map(Class_map)","1662f2d7":"train['Class']","7e47acde":"train_img=[]\ntrain_label=[]\nj=0\npath='\/kaggle\/input\/classification-of-images\/dataset\/Train Images'\nfor i in tqdm(train['Image']):\n    final_path=os.path.join(path,i)\n    img=cv2.imread(final_path)\n    img=cv2.resize(img,(150,150))\n    img=img.astype('float32')\n    train_img.append(img)\n    train_label.append(train['Class'][j])\n    j=j+1","8226cc2f":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(train_img)\n\n","82e34808":"test_img=[]\npath='\/kaggle\/input\/classification-of-images\/dataset\/Test Images'\nfor i in tqdm(test['Image']):\n    final_path=os.path.join(path,i)\n    img=cv2.imread(final_path)\n    img=cv2.resize(img,(150,150))\n    img=img.astype('float32')\n    test_img.append(img)","0d621edf":"train_img=np.array(train_img)\ntest_img=np.array(test_img)\ntrain_label=np.array(train_label)\nprint(train_img.shape)\nprint(test_img.shape)\nprint(train_label.shape)","e2a00fb5":"from tensorflow.keras.applications.vgg16 import VGG16\n\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n","db851a0e":"base_model=VGG16(include_top=False, weights='imagenet',input_shape=(150,150,3), pooling='avg')\n\nmodel=Sequential()\nmodel.add(base_model)\n\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(4,activation='softmax'))\n\n\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n\nbase_model.trainable=False\n\nreduce_learning_rate = ReduceLROnPlateau(monitor='loss',\n                                         factor=0.1,\n                                         patience=2,\n                                         cooldown=2,\n                                         min_lr=0.00001,\n                                         verbose=1)\n\ncallbacks = [reduce_learning_rate]\n    \n\n\nmodel.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.fit_generator(datagen.flow(train_img, to_categorical(train_label,4), batch_size=32),\n                    epochs=20,callbacks=callbacks)","fa30761d":"labels = model.predict(test_img)\nprint(labels[:4])\nlabel = [np.argmax(i) for i in labels]\nclass_label = [inverse_map[x] for x in label]\nprint(class_label[:3])\nsubmission = pd.DataFrame({ 'Image': test.Image, 'Class': class_label })\nsubmission.head(10)\nsubmission.to_csv('submission.csv', index=False)","86bba52e":"# If you think this notebook is worth reading and has gained some knowledge from this,please consider upvoting my kernel.Your appreciation means a lot to me","54610c14":"# Import required library","fe812c8f":"train and test data set","656b3669":"# Thank you...","0341d305":"# If you like my kernel please consider upvoting it\n\n","ebe4b0bc":"# Vgg16 model","264b88d2":"convert categorical to numerical for training model","9562fb39":"# predict for test dataset","e088561e":"# Don't hesitate to give your suggestions in the comment section****","3d239090":"# Image agumentation"}}