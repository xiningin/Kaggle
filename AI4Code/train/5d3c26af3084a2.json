{"cell_type":{"12d9b8e1":"code","6abf2b8c":"code","6a5ef65b":"code","32c21fb7":"code","c296bf34":"code","bd952a14":"code","dd06f961":"code","2762a369":"code","12070448":"code","16b144b3":"code","c87a0500":"code","9e4a5b69":"code","147a574f":"code","9d2efae1":"code","b436ca8c":"code","fceaf85d":"code","fee4c0b6":"code","2223bb7b":"code","edf615a0":"code","c4224aab":"code","d94bd7b4":"code","eb16f8fe":"markdown","c3e333c6":"markdown","2d384208":"markdown"},"source":{"12d9b8e1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","6abf2b8c":"# Reading csv file\n\nds = pd.read_csv('\/kaggle\/input\/question-classification\/Question_Classification_Dataset.csv')\nds.head()","6a5ef65b":"# Droping the other Columns because we deel with only Category0\n\nds.drop(['Unnamed: 0','Category1','Category2'], axis=1, inplace=True)\nds","32c21fb7":"# Counting the target values of Category0\n\nds['Category0'].value_counts()","c296bf34":"ds.info","bd952a14":"# Importing Necessary Libraries\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Printing the Count plot of the target values of Category0\n\nsns.countplot(ds['Category0'])\nplt.xlabel('Classes')","dd06f961":"# Encoding the Target Labels\n\nfrom sklearn.preprocessing import LabelEncoder\n\nCategory0_n = LabelEncoder()\nds['Category0_n'] = Category0_n.fit_transform(ds['Category0'])\nds","2762a369":"# Habilitate the data for spliting into train and test data\n\nx = ds['Questions']\ny = ds['Category0_n']\ny = y.to_numpy()","12070448":"x","16b144b3":"y","c87a0500":"# Spliting the data into train and test data\n\nfrom sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(x,y, test_size = 0.2)","9e4a5b69":"x_train.shape , y_train.shape","147a574f":"# Converting the textual data into the form of sequence arrays\n\nmax_words = 1100\nmax_len = 200\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\n\ntok = Tokenizer(num_words=max_words)  # Initializing the Tokenizer\ntok.fit_on_texts(x_train)             # fit the train model \nseq = tok.texts_to_sequences(x_train) # Converting Text to Sequence array\nseq_matrix = sequence.pad_sequences(sequences=seq, maxlen=max_len)   \n\nseq_matrix","9d2efae1":"# Converting test data set into text sequence array for testing...!\n\ntest_seq = tok.texts_to_sequences(x_test)\ntest_seq_matrix = sequence.pad_sequences(test_seq, maxlen=max_len)\n\ntest_seq_matrix","b436ca8c":"# Importing the necessary libraries\n\nimport keras\nimport tensorflow as tf","fceaf85d":"# RNN Model \n\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Embedding(input_dim=max_words, output_dim=6, input_length=max_len))\nmodel.add(tf.keras.layers.LSTM(64, activation='tanh'))\n\nmodel.add(tf.keras.layers.Dense(220, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.5))\n\nmodel.add(tf.keras.layers.Dense(6, activation='softmax'))\n\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(seq_matrix,y_train, batch_size=60, epochs=10, validation_split=0.2)","fee4c0b6":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuacy')\nplt.legend(['Acc','Val'], loc = 'upper left')","2223bb7b":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Loss','Val'], loc = 'upper left')","edf615a0":"from sklearn.metrics import accuracy_score,confusion_matrix\n\ny_pred = model.predict_classes(test_seq_matrix)\nprint('Accuracy Score : ',accuracy_score(y_test,y_pred))","c4224aab":"cm = confusion_matrix(y_test,y_pred)\nprint('Confusion Matrix :\\n',cm)","d94bd7b4":"plt.figure(figsize=(7,5))\nsns.heatmap(cm,annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('truth')","eb16f8fe":"# RNN","c3e333c6":"# Learning Curves","2d384208":"# **Confusion Matrix**"}}