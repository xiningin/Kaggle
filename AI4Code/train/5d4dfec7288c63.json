{"cell_type":{"d5d932f5":"code","6fca4b85":"code","2e3537af":"code","6f31c9eb":"code","f106c425":"code","7ce95807":"code","ca8db2c8":"code","5b50ecc9":"code","c7851a99":"code","422b1a19":"code","d86a5806":"code","9e56f8c4":"code","637b8cad":"code","77064685":"code","87cbeb55":"markdown","d13e7b7c":"markdown","7a5a8dff":"markdown","c33c45d3":"markdown","fdaf5ab5":"markdown","c7862f99":"markdown"},"source":{"d5d932f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport time \nimport mxnet as mx\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom mxnet import nd, autograd, gluon, init\nfrom mxnet.gluon import data as gdata, loss as gloss, nn\nfrom sklearn.model_selection import train_test_split\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6fca4b85":"#data processing, cited from https:\/\/www.kaggle.com\/karanjakhar\/facial-keypoint-detection\nTrain_Dir = '..\/input\/training\/training.csv'\nTest_Dir = '..\/input\/test\/test.csv'\nlookid_dir = '..\/input\/IdLookupTable.csv'\ntrain_data = pd.read_csv(Train_Dir)  \ntest_data = pd.read_csv(Test_Dir)\nlookid_data = pd.read_csv(lookid_dir)\nos.listdir('..\/input')\n#fill null with the previous values in that row\ntrain_data.fillna(method = 'ffill',inplace = True)\n# fill the missing values in some images\nimag = []\nfor i in range(0,7049):\n    img = train_data['Image'][i].split(' ')\n    img = ['0' if x == '' else x for x in img]\n    imag.append(img)\n#reshape the face images in [96,96]\nimage_list = np.array(imag,dtype = 'float')\n# train data\nX_train = image_list.reshape(-1,96,96)\n#\ntraining = train_data.drop('Image',axis = 1)\ny_train = []\nfor i in range(0,7049):\n    y = training.iloc[i,:]\n    y_train.append(y)\n#y data\nY_train = np.array(y_train,dtype = 'float')","2e3537af":"fig = plt.figure(figsize=(10, 10))\nfor i in range(9):\n    ax=fig.add_subplot(3,3,i+1)\n    ax.imshow(X_train[i+1],cmap='gray')\nplt.show()","6f31c9eb":"# # keras model from  https:\/\/www.kaggle.com\/karanjakhar\/facial-keypoint-detection\n# from keras.layers import Conv2D,Dropout,Dense,Flatten\n# from keras.models import Sequential\n\n# model = Sequential([Flatten(input_shape=(96,96)),\n#                          Dense(128, activation=\"relu\"),\n#                          Dropout(0.1),\n#                          Dense(64, activation=\"relu\"),\n#                          Dense(30)\n#                          ])\n\n# model.compile(optimizer='adam', \n#               loss='mean_squared_error',\n#               metrics=['mae'])\n# model.fit(X_train,y_train,epochs = 500,batch_size = 128,validation_split = 0.2)\n\n# timag = []\n# for i in range(0,1783):\n#     timg = test_data['Image'][i].split(' ')\n#     timg = ['0' if x == '' else x for x in timg] \n#     timag.append(timg)\n    \n# timage_list = np.array(timag,dtype = 'float')\n# X_test = timage_list.reshape(-1,96,96)\n# pred = model.predict(X_test)","f106c425":"\ndef log_test(net,test_iter,ctx):\n    test_l = 0\n    for X,y in test_iter:\n        X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n        l = loss(net(X),y)\n    test_l = l.mean().asscalar()\n    return test_l\n\ndef train(net, X_train, Y_train,num_epochs, trainer, batch_size, ctx):\n    train_files,val_files = train_test_split(range(len(X_train)),test_size=0.1,shuffle=True)\n    train_data,train_label = nd.array(X_train[train_files]),nd.array(Y_train[train_files])\n    val_data,val_label = nd.array(X_train[val_files]),nd.array(Y_train[val_files])\n    train_iter = gdata.DataLoader(gdata.ArrayDataset(train_data,train_label),batch_size,shuffle=True)\n    test_iter = gdata.DataLoader(gdata.ArrayDataset(val_data,val_label),batch_size)\n    train_ls,test_ls=[],[]\n    print('train on:',ctx)\n    for epoch in range(num_epochs):\n        start = time.time()\n        train_sum_l =0\n        for X,y in train_iter:\n#             print(X.shape)\n            X, y = X.expand_dims(axis=1).as_in_context(ctx), y.as_in_context(ctx)\n            with autograd.record():\n                l = loss(net(X),y)\n            l.backward()\n            trainer.step(batch_size)\n        train_loss = loss(net(train_data.expand_dims(axis=1).as_in_context(ctx)),train_label.as_in_context(ctx)).mean().asscalar()\n        train_ls.append(train_loss)\n        print()\n        if val_files:\n            test_ls.append(loss(net(val_data.expand_dims(axis=1).as_in_context(ctx)),val_label.as_in_context(ctx)).mean().asscalar())\n        else:\n            test_ls.append(train_loss)\n        print('epoch %d, train loss %.4f, test loss %.3f, time %.1f sec' % (epoch + 1,train_ls[-1], test_ls[-1], time.time() - start))\n    return train_ls, test_ls","7ce95807":"from mxnet.gluon.model_zoo import vision\n#use gpu for training\nctx=mx.gpu(0)\nresnet = vision.resnet34_v1(pretrained=False, ctx=mx.cpu())","ca8db2c8":"fine_net = resnet.features\n# fine_net.add(nn.Conv2D(64,7,strides=(2,2),padding=(3,3)),resnet18.features[1:])\nfine_net.add(nn.Dense(30))\n","5b50ecc9":"lr, num_epochs = 0.001, 500\nbatch_size=128\nloss = gloss.L2Loss()\nnet = fine_net\n# fine-tuning\n# net[0].initialize(force_reinit=True,ctx=ctx, init=init.Xavier())\n# net[2].initialize(force_reinit=True,ctx=ctx, init=init.Xavier())\n# net[0].collect_params().setattr('lr_mult', 10)\n# net[2].collect_params().setattr('lr_mult', 10)\nnet.initialize(force_reinit=True,ctx=ctx, init=init.Xavier())\nnet.collect_params().reset_ctx(ctx)\ntrainer = gluon.Trainer(net.collect_params(),'adam',{'learning_rate':lr})","c7851a99":"train_ls,test_ls = train(net, X_train, Y_train,num_epochs, trainer, batch_size, ctx)","422b1a19":"# train_ls,test_ls = train(net, X_train, Y_train,500, trainer, batch_size, ctx)\nnet.save_parameters('fine_tune_resnet34_20190616_adam.params')\n%matplotlib inline\nplt.plot(range(num_epochs),train_ls)\nplt.plot(range(num_epochs),test_ls)\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['train','test'])\nplt.show()","d86a5806":"#preparing test data, cited from https:\/\/www.kaggle.com\/karanjakhar\/facial-keypoint-detection\ntimag = []\nfor i in range(len(test_data)):\n    timg = test_data['Image'][i].split(' ')\n    timg = ['0' if x == '' else x for x in timg]\n    timag.append(timg)\ntimage_list = np.array(timag,dtype = 'float')\nX_test = timage_list.reshape(-1,96,96)\nplt.imshow(X_test[0],cmap = 'gray')\nplt.show()\n","9e56f8c4":"Y_test = net(nd.array(X_test).expand_dims(axis=1).as_in_context(ctx))\nY_test[0]","637b8cad":"# pred=Y_test.asnumpy().flatten()\n# rowid= pd.Series(range(1,len(pred)+1),name = 'RowId')\n# loc = pd.Series(pred,name = 'Location')\n# submission = pd.concat([rowid,loc],axis = 1)\n# submission.to_csv('resnet18_submission_1.csv',index = False)","77064685":"lookid_list = list(lookid_data['FeatureName'])\nimageID = list(lookid_data['ImageId']-1)\npre_list = list(Y_test.asnumpy())\nrowid = lookid_data['RowId']\nrowid=list(rowid)\nfeature = []\nfor f in list(lookid_data['FeatureName']):\n    feature.append(lookid_list.index(f))\npreded = []\nfor x,y in zip(imageID,feature):\n    # sometimes preded will be larger than 96\n    preded.append(pre_list[x][y] if pre_list[x][y]<96 else 96) \nrowid = pd.Series(rowid,name = 'RowId')\nloc = pd.Series(preded,name = 'Location')\nsubmission = pd.concat([rowid,loc],axis = 1)\nsubmission.to_csv('resnet18_submission_0616.csv',index = False)","87cbeb55":"2, Generate a resnet34 model","d13e7b7c":"5, make a submission","7a5a8dff":"3,Train the net","c33c45d3":" $L = \\frac{1}{2} \\sum_i \\vert {pred}_i - {label}_i \\vert^2.$\n","fdaf5ab5":"4, Predict the test data","c7862f99":"1, Prepare the data"}}