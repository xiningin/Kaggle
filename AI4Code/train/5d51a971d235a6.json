{"cell_type":{"e4dc6641":"code","184f59c8":"markdown","2a0b685b":"markdown","b0fd2e78":"markdown","5d5cdb83":"markdown","d9a44fca":"markdown","e1cfda05":"markdown","7a671674":"markdown","710f1226":"markdown","c387f141":"markdown","884ee281":"markdown","3190fd47":"markdown","9a146c7c":"markdown","3b68782c":"markdown","35c13a35":"markdown","cc4957d2":"markdown","d9e620d7":"markdown","aa2083e2":"markdown","69670efb":"markdown","7d9efffb":"markdown","aef79384":"markdown","7e61bde1":"markdown","13131406":"markdown","6b8b7ef5":"markdown","bd80023b":"markdown","044f6956":"markdown","9ee5503f":"markdown","1a846da2":"markdown","720d9655":"markdown","00000efc":"markdown"},"source":{"e4dc6641":"import numpy\nfrom pandas import read_csv\nfrom sklearn.utils import resample\nfrom sklearn.metrics import accuracy_score\nfrom matplotlib import pyplot\n%matplotlib inline\n\n# load dataset\nx = numpy.array([180,162,158,172,168,150,171,183,165,176]) \n\n\n# configure bootstrap\nn_iterations = 1000\nn_size = int(len(x))\n\n# run bootstrap\nmedians = list()\nfor i in range(n_iterations):\n    # prepare train and test sets\n    s = resample(x, n_samples=n_size);\n    m = numpy.median(s);\n    #print(m)\n    medians.append(m)\n\n# plot scores\npyplot.hist(medians)\npyplot.show()\n\n# confidence intervals\nalpha = 0.95\np = ((1.0-alpha)\/2.0) * 100\nlower =  numpy.percentile(medians, p)\n\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupper =  numpy.percentile(medians, p)\nprint('%.1f confidence interval %.1f and %.1f' % (alpha*100, lower, upper))\n\n","184f59c8":"## Now, The Case when bootsrap is needed:\u00b6","2a0b685b":"If we want a resampled data set of size 5, then we roll the 10-sided die 5 times and choose\nthe corresponding elements from the list of data. If the 5 rolls are\n\n5, 3, 6, 6, 1\nthen the resample is\n3, 2, 3, 3, 1.","b0fd2e78":"Suppose we have data x1, x2, x3,.....xn.\n\nIf we knew the data was drawn from N(\u00b5, \u03c32) with the unknown mean \u00b5 and known variance\n\u03c32 then we have seen that\n\n [$\\bar{x}$ - 1.96$\\frac{\\sigma}{\\sqrt{n}}$, $\\bar{x}$ + 1.96$\\frac{\\sigma}{\\sqrt{n}}$]\n \n is a 95% confidence interval for \u00b5","5d5cdb83":"If we have sample data of size n\n\n$x_1, x_2, . . . , x_n$\n\nthen we denote a resample of size m by adding a star to the symbols\n\n$x^*_1, x^*_2, . . . , x^*_m$\n\n\nSimilarly, just as $\\bar{x}$ is the mean of the original data, we write $\\bar{x^*}$ for the mean of the\nresampled data.","d9a44fca":"Because $F^\u2217$ is derived strictly from data we call it the empirical distribution of the data.\nWe will also call it the resampling distribution. Notice that we always know $F^\u2217$ explicitly.\nIn particular the expected value of $F^\u2217$ is just the sample mean $\\bar{x}$.","e1cfda05":"# 6. Why the resample is the same size as the original sample","7a671674":"Thanks...","710f1226":"**Bootstrap- By one's own efforts to improve one's life or circumstances, rather than relying on others.**","c387f141":"The empirical bootstrap proceeds by resampling from the data. We continue the dice\nexample above\n\n1, 1, 2, 3, 3, 3, 3, 4, 7, 7","884ee281":"| value x | 1 | 2 | 3 | 4 | 7 |\n| --- | --- | --- | --- | --- | --- |\n| p(x) | 2\/10 | 1\/10 | 4\/10 | 1\/10 | 2\/10 |","3190fd47":"# 4. Resampling","9a146c7c":"# Empirical bootstrap based Confidence Interval:\n# 1. Introduction:","3b68782c":"Suppose we have n data points\n\n$x_1, x_2, . . . , x_n$\n\ndrawn from a distribution F. An empirical bootstrap sample is a resample of the same size\n\n$x^*_1, x^*_2, . . . , x^*_m$\n\nYou should think of the latter as a sample of size n drawn from the empirical distribution $F^\u2217$. For any statistic v computed from the original sample data, we can define a statistic $v^*$\nby the same formula but computed instead using the resampled data. With this notation\nwe can state the bootstrap principle.\n\n\n## The bootstrap principle\n\nThe bootstrap setup is as follows:\n\n1. $x_1, x_2, . . . , x_n$ is a data sample drawn from a distribution F.\n\n2. u is a statistic computed from the sample.\n\n3. $F^*$ is the empirical distribution of the data (the resampling distribution).\n\n4. $x^*_1, x^*_2, . . . , x^*_n$ is a resample of the data of the same size as the original sample.\n\n5. $u^*$ is the statistic computed from the resample.\n\n**Then the bootstrap principle says that:**\n\n1. $F^\u2217$ \u2248 F.\n\n2. The variation of u is well-approximated by the variation of $u^*$.\n\nOur real interest is in point 2: we can approximate the variation of u by that of $u^*$ . We\nwill exploit this to estimate the size of confidence intervals.\n","35c13a35":"| value x | 1 | 2 | 3 | 4 | 7 |\n| --- | --- | --- | --- | --- | --- |\n| true p(x) | 1\/8 | 1\/8 | 1\/8 | 1\/8 | 1\/8 |\n| p(x) | 2\/10 | 1\/10 | 4\/10 | 1\/10 | 2\/10 |","cc4957d2":"**If you didn't understand it correctly please let me know, I will go more in depth.**","d9e620d7":"# 3. The empirical distribution of data:","aa2083e2":"This is straightforward: the variation of the statistic u will depend on the size of the sample.\nIf we want to approximate this variation we need to use resamples of the same size.","69670efb":"# Now, theory is enough, lets explore it in practical way: let's calculate CI using median..","7d9efffb":"The empirical distribution of data is simply the distribution that you see in the data. Let\u2019s\nillustrate this with an example.\n\nSuppose we roll an 8-sided die 10 times and get the following data, written\nin increasing order: 1, 1, 2, 3, 3, 3, 3, 4, 7, 7\n\nThen, for example, the probability of drawing a 3 is 4\/10 and the probability\nof drawing a 4 is 1\/10. The full empirical distribution can be put in a probability table\n\n","aef79384":"**Notation.** If we label the true distribution the data is drawn from as F, then we\u2019ll label\nthe empirical distribution of the data as F\u2217. If we have enough data then the law of large\nnumbers tells us that $F^*$ should be a good approximation of F.\n","7e61bde1":"In statistics to sample from a set is to choose elements from that set. In a random sample\nthe elements are chosen randomly. There are two common methods for random sampling.\n\n**Sampling without replacement**- Suppose we draw 10 cards at random from a deck of 52 cards without putting any of the\ncards back into the deck between draws. This is called sampling without replacement or\nsimple random sampling. With this method of sampling our 10 card sample will have no\nduplicate cards.\n\n**Sampling with replacement**- Now suppose we draw 10 cards at random from the deck, but after each draw we put the\ncard back in the deck and shuffle the cards. This is called sampling with replacement. With\nthis method, the 10 card sample might have duplicates.","13131406":"# 5. The empirical bootstrap","6b8b7ef5":"Label the 10 data points x1, x2, . . . , x10. To resample is to draw a number j from the\nuniform distribution on {1, 2, . . . , 10} and take xj as our resampled value. In this case we\ncould do so by rolling a 10-sided die. For example, if we roll a 6 then our resampled value\nis 3, the 6th element in our list.","bd80023b":"**Notes: 1.** Because we are sampling with replacement, the same data point can appear\nmultiple times when we resample.\n2. Also because we are sampling with replacement, we can have a resample data set of any\nsize we want, e.g. we could resample 1000 times.","044f6956":"In fact, the bootstrap handles other statistics as easily as it handles the mean.\nFor example: the median, other percentiles or the trimmed mean. These are statistics\nwhere, even for normal distributions, it can be difficult to compute a confidence interval\nfrom theory alone.","9ee5503f":"- The key idea is to perform computations on the data itself\nto estimate the variation of statistics that are themselves computed from the same data.\nThat is, the data is \u2018pulling itself up by its own bootstrap.\n\n- Our main application of the bootstrap will be to estimate the variation of point estimates;\nthat is, to estimate confidence intervals.\n\n- Though remarkably simple to implement, the bootstrap would not be feasible without\nmodern computing power.","1a846da2":"# 2. Sampling:","720d9655":"Now suppose the data is drawn from some completely unknown distribution.\n\nTo have a name we\u2019ll call this distribution F and its (unknown) mean \u00b5. We can still use the sample\nmean x as a point estimate of \u00b5. But how can we find a confidence interval for \u00b5 around\nx? Our answer will be to use the bootstrap!","00000efc":"## The Case when bootsrap is not needed:"}}