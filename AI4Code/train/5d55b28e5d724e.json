{"cell_type":{"840932d9":"code","7b8289bb":"code","4317edfd":"code","add7c1ff":"code","8ab182e7":"code","2f524a27":"code","91b95d5b":"code","7e78e4bf":"code","3a96ba11":"code","883c4073":"code","0d4815a0":"code","0926b07b":"code","48875d10":"code","d718dc65":"code","a8b0347a":"code","f6c16642":"code","d3ac75b4":"markdown"},"source":{"840932d9":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","7b8289bb":"\nbatch_size = 256\nimg_height = 256\nimg_width = 256","4317edfd":"train_ds = tf.keras.preprocessing.image_dataset_from_directory('..\/input\/plant-disease\/dataset\/train',\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","add7c1ff":"test_ds = tf.keras.preprocessing.image_dataset_from_directory('..\/input\/plant-disease\/dataset\/test',\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","8ab182e7":"class_names = train_ds.class_names\nprint(class_names)","2f524a27":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    \n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","91b95d5b":"for image_batch, labels_batch in train_ds:\n    \n      print(image_batch.shape)\n      print(labels_batch.shape)\n      break","7e78e4bf":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\ntest_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)","3a96ba11":"normalization_layer = layers.experimental.preprocessing.Rescaling(1.\/255)\n","883c4073":"num_classes = 10\n\nmodel = Sequential([\n  layers.experimental.preprocessing.Rescaling(1.\/255, input_shape=(img_height, img_width, 3)),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","0d4815a0":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","0926b07b":"model.summary()","48875d10":"epochs=10\nhistory = model.fit(\n  train_ds,\n  validation_data=test_ds,\n  epochs=epochs\n)","d718dc65":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')","a8b0347a":"\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","f6c16642":"tf.keras.models.save_model(model,'prediction.hdf5')","d3ac75b4":"Because there's not enough memory and RAM, I couldn't keep running the code, but if I keep working, it's going to work."}}