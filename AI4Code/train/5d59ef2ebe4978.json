{"cell_type":{"a7aa6db8":"code","bd0704ac":"code","8a7e1e8e":"code","558b8a9d":"code","64727a17":"code","4cda9d1a":"code","c048b441":"code","edfdba16":"code","7c206113":"code","084be405":"code","db3873e2":"code","cbb5b250":"code","2314d7c7":"code","f3850a9b":"code","0cfa0075":"code","d869d835":"code","b4408bba":"code","972b0957":"code","7b1661cc":"code","3d80f082":"code","2dc34df6":"code","45706ced":"code","0ff269b8":"code","60f10395":"code","8bda4375":"code","99c42cc0":"code","469d6948":"code","21335dcd":"code","42b3d06e":"code","bcdae1c9":"code","6026c0f1":"code","812cf472":"code","c1ff9f18":"code","ff607238":"code","9ec3f427":"markdown","d563c013":"markdown","43953620":"markdown","355ab0b6":"markdown","54f260e0":"markdown","c7f977a4":"markdown","b0ea1777":"markdown","09e25484":"markdown"},"source":{"a7aa6db8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc","bd0704ac":"dtypes = {\n    \"row_id\": \"int64\",\n    \"timestamp\": \"int64\",\n    \"user_id\": \"int32\",\n    \"content_id\": \"int16\",\n    \"content_type_id\": \"int16\",\n    \"task_container_id\": \"int16\",\n    \"user_answer\": \"int8\",\n    \"answered_correctly\": \"int8\",\n    \"prior_question_elapsed_time\": \"float32\", \n    \"prior_question_had_explanation\": \"boolean\"\n}\n\ndata = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/train.csv\", dtype=dtypes)","8a7e1e8e":"data.info()","558b8a9d":"data.isnull().sum()","64727a17":"temp_ =data.loc[(data.prior_question_elapsed_time.isnull()) & (data.timestamp != 0)]","4cda9d1a":"temp_.content_type_id.value_counts().plot(kind = 'pie', autopct = '%0.3f')\nplt.title(\"Content Type when timestamp not equal to zero and prior_question_elapsed_time is null\")","c048b441":"sns.distplot(temp_.timestamp)","edfdba16":"# temp_.loc[(temp_.content_type_id == 1)]\ndata.loc[(data.timestamp == 0) & (data.prior_question_elapsed_time == 0)]","7c206113":"data.loc[((data.user_id == 369317294) & (data.prior_question_elapsed_time.isnull())) | ((data.user_id == 369317294) & (data.timestamp == 0))]","084be405":"temp_ =data.loc[data.prior_question_elapsed_time == 0]\nplt.figure(figsize = (8, 20))\nplt.subplot(121)\nplt.subtitles('when prior_question_elapsed_time')\nplt.title(\"Is 0\")\ntemp_.answered_correctly.value_counts().plot(kind = 'pie', autopct = '%0.3f')\nplt.subplot(122)\nplt.title('Is null')\ndata.loc[(data.prior_question_elapsed_time.isnull()) & (data.content_type_id == 0)].answered_correctly.value_counts().plot(kind = 'pie', autopct = '%0.3f')","db3873e2":"gc.collect()","cbb5b250":"prior_q_e_time = data.loc[data.prior_question_elapsed_time.isnull()]","2314d7c7":"prior_q_e_time.head()","f3850a9b":"data['prior_question_elapsed_time'] = data['prior_question_elapsed_time'].fillna(0)","0cfa0075":"data['prior_question_had_explanation'] = data['prior_question_had_explanation'].fillna(0)","d869d835":"data['prior_question_had_explanation'] = data['prior_question_had_explanation'].replace({True : 1, False : 0})","b4408bba":"gc.collect()","972b0957":"question_data = pd.read_csv(r'..\/input\/riiid-test-answer-prediction\/questions.csv')","7b1661cc":"question_data.loc[question_data.tags.isnull()]","3d80f082":" from collections import Counter\n    \ntags = question_data['tags'].loc[question_data['part'] == 6]\ntags = tags.loc[tags.isnull() == False]\ntags = tags.str.split(' ')\ntags = [j for i in tags.values for j in i]\ntotal_count = len(tags)\ntags = Counter(tags)\nx = list(tags.keys())\ny = np.array(list(tags.values()))\ny = y \/ total_count","2dc34df6":"plt.figure(figsize=(15, 15))\nplt.barh(x, y)\nplt.vlines(x=0.5, ymin = '179', ymax = len(tags), color = 'red',  linestyles = 'dashed')\nplt.title('Count of Invidual tags in part - 6')\nplt.xlabel('Count')\nplt.ylabel('Tag')","45706ced":"data.loc[data['content_id'] == 10033]","0ff269b8":"temp_ = data.iloc[62750278 - 5 :62750278 + 5, :]","60f10395":"temp_.merge(question_data, left_on = 'content_id', right_on = 'question_id')","8bda4375":"data.loc[(data.user_id == 1333688829) & ((data.task_container_id == 1126) | (data.task_container_id == 1128))].merge(question_data, left_on = 'content_id', right_on = 'question_id')","99c42cc0":"temp_ = data.loc[(data.user_id == 1333688829) & (data.content_type_id == 0)].merge(question_data, left_on = 'content_id', right_on = 'question_id')\ntags = temp_['tags'].loc[temp_['part'] == 6]\ntags = tags.loc[tags.isnull() == False]\ntags = tags.str.split(' ')\ntags = [j for i in tags.values for j in i]\ntotal_count = len(tags)\ntags = Counter(tags)\nx1 = list(tags.keys())\ny1 = np.array(list(tags.values()))\ny1 = y1 \/ total_count","469d6948":"answer = temp_['answered_correctly'].loc[temp_.part == 6]\nplt.pie(answer.value_counts(), labels = [1, 0], autopct = '%0.2f')\nplt.legend()","21335dcd":"lecture_data = pd.read_csv('..\/input\/riiid-test-answer-prediction\/lectures.csv')","42b3d06e":"lecture_data.isnull().sum()","bcdae1c9":"temp_ = question_data.merge(lecture_data, left_on = 'question_id', right_on = 'lecture_id', how = 'outer')\ntemp_.loc[temp_.question_id == 10033]","6026c0f1":"temp_.loc[temp_.lecture_id.isnull() == False].head()","812cf472":"question_data.tags = question_data.tags.fillna(-1)","c1ff9f18":"first_interaction = data.groupby('user_id').first()","ff607238":"plt.figure(figsize = (12, 20))\nax  = plt.subplot(121)\nfirst_interaction.answered_correctly.value_counts().plot(kind = 'pie', ax = ax, autopct='%1.3f%%', startangle=270, fontsize=17)\nax = plt.subplot(122)\nfirst_interaction.content_type_id.value_counts().plot(kind = 'pie', ax = ax, autopct='%1.3f%%', startangle=270, fontsize=17)","9ec3f427":"34% unique content_id's are used","d563c013":"## prior_question_elapsed_time","43953620":"Work on progress....","355ab0b6":"Main Problem wheater we want to remove the nan tag question from both train and question dataset or we want to mark it with -1.\n\nIn my perspective i decided to mark the tag as -1.","54f260e0":"## Anlysing the First Interaction of each User","c7f977a4":"The Distribution of Taget feature (when prior_question_elapsed_time is equal to zero ) is equal to the Distribution of Target Feature (when prior_question_elapsed_time is Nan) so in my perspection it won't affect when we replace Nan value with 0 when content type id = 0 and -1 when content type id = 1","b0ea1777":"There is only one nan value in tags columns of the question dataset. To find the best value of in place of nan tag done some comparition with train andlecture dataset. Such question was asked only once in the whole train dataset and it was asked inbetween part 5 question but the nan tag question is belong to part - 6.\n\nQuestions that asked before and after nan tag question is of tag \"8\" from that we can suspect that it may belongs to tag 8 but there is no evidence that it is.\n\nI check wheather the question and lecture dataset that has same id also have same tags, but it is not same.\n\nIn other hand, when i check the distribution of the tag part - 6 question that asked to the user_id \"1333688829\" is almost same as the distribution of part-6 questions in question \ndataset.","09e25484":"## Null Values"}}