{"cell_type":{"8c859f47":"code","c58c8841":"code","def68066":"code","626e32b4":"code","ee8efbf4":"code","6310d8f3":"code","2f5cbbf8":"code","08717256":"code","767b714c":"code","c2d9dc18":"code","325ff92c":"code","cf52dd70":"code","6b23a103":"code","3e7ec16f":"code","8dd90f92":"code","7c89c666":"code","34fa827e":"code","99da3228":"code","04ee2036":"code","e424f22c":"code","39b9140b":"code","54c3af6e":"markdown","7ba9614f":"markdown","0471d3af":"markdown","e9e3c46c":"markdown","55ae5c69":"markdown","2746efe7":"markdown","98fa859c":"markdown","0c81ae9a":"markdown","905c4d7a":"markdown","88fc9c99":"markdown","a9c54323":"markdown","b61a61d9":"markdown","4a6946d6":"markdown","52226e15":"markdown","7642002c":"markdown","8c698657":"markdown","eee86d02":"markdown","b3abdfed":"markdown","ad64725c":"markdown","3d093ccb":"markdown","0c156729":"markdown"},"source":{"8c859f47":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c58c8841":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras import layers,models,applications,preprocessing,optimizers\nimport cv2","def68066":"train_data = []\ntrain_labels = []\ntest_data = []\ntest_labels = []\nIMG_SIZE = 160\ndef get_images(path):\n    cfiles = os.listdir(os.path.join(path,'cats'))\n    dfiles = os.listdir(os.path.join(path,'dogs'))\n    data = []\n    labels = []\n    for i in dfiles:\n        try:\n            imgpath = os.path.join(path,'dogs') \n            img = cv2.imread(os.path.join(imgpath,i))\n            img = tf.image.resize(img,(IMG_SIZE,IMG_SIZE))\n            data.append(img)\n            labels.append(1)\n        except:\n            pass\n    for i in cfiles:\n        try:\n            imgpath = os.path.join(path,'cats') \n            img = cv2.imread(os.path.join(imgpath,i))\n            img = tf.image.resize(img,(IMG_SIZE,IMG_SIZE))\n            data.append(img)\n            labels.append(0)\n        except:\n            pass\n    return data, labels\n\ntrain_data, train_labels = get_images('\/kaggle\/input\/cat-and-dog\/training_set\/training_set')\ntest_data, test_labels = get_images('\/kaggle\/input\/cat-and-dog\/test_set\/test_set')","626e32b4":"len(train_data),len(train_labels),len(test_data),len(test_labels)","ee8efbf4":"train_data = tf.data.Dataset.from_tensor_slices((train_data,train_labels))\ntest_data = tf.data.Dataset.from_tensor_slices((test_data,test_labels))","6310d8f3":"def format_example(image,label):\n    image = tf.cast(image,dtype = tf.float32)\n    image = (image \/ 255) - 1\n    image = tf.image.resize(image,(IMG_SIZE,IMG_SIZE))\n    return image, label\ntrain_data = train_data.map(format_example)\ntest_data = test_data.map(format_example)","2f5cbbf8":"BATCH_SIZE = 32\nSHUFFLE_BUFFER_SIZE = 2000\ntrain_data = train_data.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\ntest_data = test_data.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)","08717256":"IMG_SHAPE = (IMG_SIZE,IMG_SIZE,3)\nbase_model = tf.keras.applications.MobileNetV2(input_shape = IMG_SHAPE,\n        include_top = False,weights = '..\/input\/mobilenet-v2-keras-weights\/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5')\n\nbase_model.trainable = False\nbase_model.summary()","767b714c":"for image_batch, label_batch in train_data.take(1):\n    pass\nprint(image_batch.shape)","c2d9dc18":"print(base_model(image_batch).shape)","325ff92c":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nprint(global_average_layer(base_model(image_batch)).shape)","cf52dd70":"hidden_layer = tf.keras.layers.Dense(32,activation = 'relu')\nprint(hidden_layer(global_average_layer(base_model(image_batch))).shape)","6b23a103":"prediction_layer = tf.keras.layers.Dense(1)\nprint(prediction_layer(hidden_layer(global_average_layer(base_model(image_batch)))).shape)","3e7ec16f":"model = tf.keras.Sequential([\n     base_model,\n     global_average_layer,\n     hidden_layer,\n     prediction_layer\n])","8dd90f92":"base_learning_rate = 0.0001\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(lr = base_learning_rate),\n              loss = 'binary_crossentropy', metrics = ['accuracy'])","7c89c666":"model.summary()","34fa827e":"callbacks = tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')","99da3228":"num_train = 2000\nnum_test = 1000\ninitial_epochs = 20\nsteps_per_epochs = round(num_train) \/\/  BATCH_SIZE\nvalidation_steps = 4\n\nloss0, accuracy0 = model.evaluate(test_data, steps = validation_steps)","04ee2036":"history = model.fit(train_data,epochs = 10,callbacks = [callbacks],validation_data = test_data)","e424f22c":"model.load_weights('best_model.h5')","39b9140b":"model.evaluate(test_data)","54c3af6e":"Checking training batches shape","7ba9614f":"Checking the output shape from the basemodel(mobilenet v2)","0471d3af":"adding global average layer to convert output from the base model feedable to hidden layer","e9e3c46c":"Checking their length","55ae5c69":"Loading training data  and test data into lists","2746efe7":"Making the data into batches and shuffling them","98fa859c":"adding model checkpoint callback","0c81ae9a":"Formatting the data","905c4d7a":"Importing libaries","88fc9c99":"Training the model","a9c54323":"summary","b61a61d9":"Converting training data and test data into tensorflow dataset objects","4a6946d6":"predicting from the best model","52226e15":"fixing the learning rate and compiling the model","7642002c":"loading weights from the saved best model","8c698657":"we got 76% accuracy.","eee86d02":"Hidden layer to train","b3abdfed":"Initializing the  model with the above layers","ad64725c":"prediction layer to predict","3d093ccb":"calculating the steps per epochs","0c156729":"Intializing the mobilenet v2 with pretrained weights"}}