{"cell_type":{"0fa96d15":"code","4a8e6d93":"code","37000660":"code","c5bc3191":"code","7ebd17f4":"code","cf5d5ddf":"code","bae727f8":"code","fa95ee55":"code","519bbbae":"code","eebccaf2":"code","915ca801":"code","781b2047":"code","e6bb2ea0":"code","2141441e":"code","5a4887b7":"code","0de12573":"code","858392d9":"code","4db7b90b":"code","d57fe7ca":"code","f28b4f58":"code","3c768748":"code","a615391e":"code","6bcc20d3":"code","9dc530a7":"code","03b819ce":"code","856c468b":"code","8a79d6f6":"code","f1556394":"code","d577d8be":"code","9afbadbf":"code","ac106834":"code","b105b587":"code","f8584779":"code","31c38e78":"markdown","71cb67e3":"markdown","b2279315":"markdown","568c785e":"markdown","fe7a6b92":"markdown","ac98a1f9":"markdown","b4f81443":"markdown","700db3b3":"markdown","a1b70d79":"markdown","b69395ee":"markdown","0a494c04":"markdown","58e45adf":"markdown","05498892":"markdown","3d9a12da":"markdown","b53a844d":"markdown","8dcee74a":"markdown"},"source":{"0fa96d15":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport json\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4a8e6d93":"from sklearn.model_selection import train_test_split\n\nREVIEWS_LIMIT = 2000 #100000 #300000\n\ndef load_rows(filepath, nrows = None, func = None) -> pd.DataFrame :\n    with open(filepath) as json_file:\n        count = 0\n        objs = []\n        line = json_file.readline()\n        while (nrows is None or count < nrows) and line:\n            count += 1\n            obj = json.loads(line)\n            if func != None :\n                func(obj)\n            objs.append(obj)\n            line = json_file.readline()\n        return pd.DataFrame(objs)\n    \n# Aggiunge la classe della recensione\ndef add_sentiment(obj) :\n    if (obj[\"stars\"] <= 3):\n        obj[\"label\"] = 0\n    else:\n        obj[\"label\"] = 1\n        \nreviews = load_rows('..\/input\/yelp-dataset\/yelp_academic_dataset_review.json', REVIEWS_LIMIT, add_sentiment)\nprint('Review objects loaded. Count = {}'.format(reviews.shape[0]))\n\nreviews['text_length'] = reviews['text'].apply(lambda x:len(x.split()))\n\n# 80% train, 20% test\nreviews_train, reviews_test = train_test_split(reviews, test_size = 0.2)\n\n# Solo text, label\nreviews_train = reviews_train[['text', 'label']]\nreviews_test = reviews_test[['text', 'label']]\ndisplay(reviews_train.head(2))\ndisplay(reviews_test.head(2))\n\n#with pd.option_context('display.max_colwidth', None):\n#  display(reviews_train)","37000660":"display(reviews.head())\nreviews.stars.value_counts().plot(kind='pie', autopct='%1.0f%%')","c5bc3191":"reviews.label.value_counts().plot(kind='pie', autopct='%1.0f%%')","7ebd17f4":"import seaborn as sns\n\na = sns.FacetGrid(data = reviews, col = 'label', hue = 'label', palette='plasma', height=5)\na.map(sns.histplot, \"text_length\")\nreviews.groupby('label').mean()['text_length']","cf5d5ddf":"reviews.groupby('label').mean()","bae727f8":"from tqdm import tqdm\nimport re\nimport copy\nimport nltk\nfrom nltk.corpus import stopwords \nfrom nltk.stem import WordNetLemmatizer\n\npd.options.mode.chained_assignment = None  # default='warn'\n\ndef contractions(sent):\n    sent = re.sub(r\"ain't\", \"am not\", sent)\n    sent = re.sub(r\"aren't\", \"are not\", sent)\n    sent = re.sub(r\"can't\", \"can not\", sent)\n    sent = re.sub(r\"can't've\", \"can not have\", sent)\n    sent = re.sub(r\"'cause\", \"because\", sent)\n    sent = re.sub(r\"could've\", \"could have\", sent)\n    sent = re.sub(r\"couldn't\", \"could not\", sent)\n    sent = re.sub(r\"couldn't've\", \"could not have\", sent)\n    sent = re.sub(r\"doesn't\", \"does not\", sent)\n    sent = re.sub(r\"hadn't\", \"had not\", sent)\n    sent = re.sub(r\"hadn't've\", \"had not have\", sent)\n    sent = re.sub(r\"hasn't\", \"has not\", sent)\n    sent = re.sub(r\"haven't\", \"have not\", sent)\n    sent = re.sub(r\"he'd\", \"he had\", sent)\n    sent = re.sub(r\"he'd've\", \"he would have\", sent)\n    sent = re.sub(r\"he'll\", \"he will\", sent)\n    sent = re.sub(r\"he'll've\", \"he will have\", sent)\n    sent = re.sub(r\"he's\", \"he has\", sent)\n    sent = re.sub(r\"how'd\", \"how did\", sent)\n    sent = re.sub(r\"how'd'y\", \"how do you\", sent)\n    sent = re.sub(r\"how'll\", \"how will\", sent)\n    sent = re.sub(r\"how's\", \"how has\", sent)\n    sent = re.sub(r\"i'd\", \"i had\", sent)\n    sent = re.sub(r\"i'd've\", \"i would have\", sent)\n    sent = re.sub(r\"i'll\", \"i shall\", sent)\n    sent = re.sub(r\"i'll've\", \"i shall have\", sent)\n    sent = re.sub(r\"i'm\", \"i am\", sent)\n    sent = re.sub(r\"i've\", \"i have\", sent)\n    sent = re.sub(r\"isn't\", \"is not\", sent)\n    sent = re.sub(r\"it'd\", \"it had\", sent)\n    sent = re.sub(r\"it'd've\", \"it would have\", sent)\n    sent = re.sub(r\"it'll\", \"it shall\", sent)\n    sent = re.sub(r\"it'll've\", \"it shall have\", sent)\n    sent = re.sub(r\"it's\", \"it is\", sent)\n    sent = re.sub(r\"let's\", \"let us\", sent)\n    sent = re.sub(r\"ma'am\", \"madam\", sent)\n    sent = re.sub(r\"mayn't\", \"may not\", sent)\n    sent = re.sub(r\"might've\", \"might have\", sent)\n    sent = re.sub(r\"mightn't\", \"might not\", sent)\n    sent = re.sub(r\"mightn't've\", \"might not have\", sent)\n    sent = re.sub(r\"must've\", \"must have\", sent)\n    sent = re.sub(r\"mustn't\", \"must not\", sent)\n    sent = re.sub(r\"mustn't've\", \"must not have\", sent)\n    sent = re.sub(r\"needn't\", \"need not\", sent)\n    sent = re.sub(r\"needn't've\", \"need not have\", sent)\n    sent = re.sub(r\"o'clock\", \"of the clock\", sent)\n    sent = re.sub(r\"oughtn't\", \"ought not\", sent)\n    sent = re.sub(r\"oughtn't've\", \"ought not have\", sent)\n    sent = re.sub(r\"shan't\", \"shall not\", sent)\n    sent = re.sub(r\"sha'n't\", \"shall not\", sent)\n    sent = re.sub(r\"shan't've\", \"shall not have\", sent)\n    sent = re.sub(r\"she'd\", \"she had\", sent)\n    sent = re.sub(r\"she'd've\", \"she would have\", sent)\n    sent = re.sub(r\"she'll\", \"she shall\", sent)\n    sent = re.sub(r\"she'll've\", \"she shall have\", sent)\n    sent = re.sub(r\"she's\", \"she has\", sent)\n    sent = re.sub(r\"should've\", \"should have\", sent)\n    sent = re.sub(r\"shouldn't\", \"should not\", sent)\n    sent = re.sub(r\"shouldn't've\", \"should not have\", sent)\n    sent = re.sub(r\"so've\", \"so have\", sent)\n    sent = re.sub(r\"so's\", \"so as\", sent)\n    sent = re.sub(r\"that'd\", \"that would\", sent)\n    sent = re.sub(r\"that'd've\", \"that would have\", sent)\n    sent = re.sub(r\"that's\", \"that has\", sent)\n    sent = re.sub(r\"there'd\", \"there had\", sent)\n    sent = re.sub(r\"there'd've\", \"there would have\", sent)\n    sent = re.sub(r\"there's\", \"there has\", sent)\n    sent = re.sub(r\"they'd\", \"they had\", sent)\n    sent = re.sub(r\"they'd've\", \"they would have\", sent)\n    sent = re.sub(r\"they'll\", \"they shall\", sent)\n    sent = re.sub(r\"they'll've\", \"they shall have\", sent)\n    sent = re.sub(r\"they're\", \"they are\", sent)\n    sent = re.sub(r\"they've\", \"they have\", sent)\n    sent = re.sub(r\"to've\", \"to have\", sent)\n    sent = re.sub(r\"wasn't\", \"was not\", sent)\n    sent = re.sub(r\"we'd\", \"we had\", sent)\n    sent = re.sub(r\"we'd've\", \"we would have\", sent)\n    sent = re.sub(r\"we'll\", \"we will\", sent)\n    sent = re.sub(r\"we'll've\", \"we will have\", sent)\n    sent = re.sub(r\"we're\", \"we are\", sent)\n    sent = re.sub(r\"we've\", \"we have\", sent)\n    sent = re.sub(r\"weren't\", \"were not\", sent)\n    sent = re.sub(r\"what'll\", \"what shall\", sent)\n    sent = re.sub(r\"what'll've\", \"what shall have\", sent)\n    sent = re.sub(r\"what're\", \"what are\", sent)\n    sent = re.sub(r\"what's\", \"what has\", sent)\n    sent = re.sub(r\"what've\", \"what have\", sent)\n    sent = re.sub(r\"when's\", \"when has\", sent)\n    sent = re.sub(r\"when've\", \"when have\", sent)\n    sent = re.sub(r\"where'd\", \"where did\", sent)\n    sent = re.sub(r\"where's\", \"where has\", sent)\n    sent = re.sub(r\"where've\", \"where have\", sent)\n    sent = re.sub(r\"who'll\", \"who shall\", sent)\n    sent = re.sub(r\"who'll've\", \"who shall have\", sent)\n    sent = re.sub(r\"who's\", \"who has\", sent)\n    sent = re.sub(r\"who've\", \"who have\", sent)\n    sent = re.sub(r\"why's\", \"why has\", sent)\n    sent = re.sub(r\"why've\", \"why have\", sent)\n    sent = re.sub(r\"will've\", \"will have\", sent)\n    sent = re.sub(r\"won't\", \"will not\", sent)\n    sent = re.sub(r\"won't've\", \"will not have\", sent)\n    sent = re.sub(r\"would've\", \"would have\", sent)\n    sent = re.sub(r\"wouldn't\", \"would not\", sent)\n    sent = re.sub(r\"wouldn't've\", \"would not have\", sent)\n    sent = re.sub(r\"y'all\", \"you all\", sent)\n    sent = re.sub(r\"y'all'd\", \"you all would\", sent)\n    sent = re.sub(r\"y'all'd've\", \"you all would have\", sent)\n    sent = re.sub(r\"y'all're\", \"you all are\", sent)\n    sent = re.sub(r\"y'all've\", \"you all have\", sent)\n    sent = re.sub(r\"you'd\", \"you had\", sent)\n    sent = re.sub(r\"you'd've\", \"you would have\", sent)\n    sent = re.sub(r\"you'll\", \"you shall\", sent)\n    sent = re.sub(r\"you'll've\", \"you shall have\", sent)\n    sent = re.sub(r\"how's\", \"how has\", sent)\n    sent = re.sub(r\"you're\", \"you are\", sent)\n    sent = re.sub(r\"you've\", \"you have\", sent)\n    sent = re.sub(r\"didn't\", \"did not\", sent)\n    sent = re.sub(r\"don't\", \"do not\", sent)\n    sent = re.sub(r\"'\",\"\",sent)\n    sent = re.sub(r\". . .\",\"\",sent)\n    return(sent)\n\n## Function for removing unwanted text\ndef processing(data_1):\n \n    for index, row in tqdm(data_1.iterrows()):\n        stri = \"\"\n## Code to remove digit with word pattern\n        cle = re.sub(r'([\\d]+[a-zA-Z]+)|([a-zA-Z]+[\\d]+)', \"\", row[\"text\"])\n## Code to remove only digit patter\n        cle = re.sub(r\"(^|\\s)(\\-?\\d+(?:\\.\\d)*|\\d+|[\\d]+[A-Za-z]+)\",\" \", cle.lower())\n## Code to remove every symbols except characters\n        cle = re.sub('[^A-Za-z\\']+', \" \", cle)\n## Code for concatinating strings\n        stri = stri + cle\n## Code for calling contraction function\n        stri = contractions(stri)\n        data_1[\"text\"][index] = stri\n    return(data_1)\n\n## Function for stopwords removal and lemitizing the word\ndef lema_stopw(data_l):\n    var2 = copy.deepcopy(data_l)\n    lemmatizer = WordNetLemmatizer()\n    stop_words = set(stopwords.words('english')) - set(['no', 'not'])\n    for index, row in tqdm(var2.iterrows()):\n        sent = ''\n        for e in row[\"text\"].split():\n            if e not in stop_words:\n                e = lemmatizer.lemmatize(e, pos =\"a\")\n                sent = ' '.join([sent,e])\n        var2[\"text\"][index] = sent\n    return(var2)\n\nreviews_train = processing(reviews_train)\nreviews_test = processing(reviews_test)\nreviews_train.head(5)","fa95ee55":"reviews_train = lema_stopw(reviews_train)\nreviews_test = lema_stopw(reviews_test)\nreviews_train.head(5)","519bbbae":"# Text vectorization\n# Bigram Counts\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom joblib import dump, load # used for saving and loading sklearn objects\n\n\nbigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\nbigram_vectorizer.fit(reviews_train['text'].values)\n\n\nX_train_bigram = bigram_vectorizer.transform(reviews_train['text'].values)\nX_test_bigram = bigram_vectorizer.transform(reviews_test['text'].values)\n\n# Bigram Tf-Idf\n\nbigram_tf_idf_transformer = TfidfTransformer()\nbigram_tf_idf_transformer.fit(X_train_bigram)\n\nX_train_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_train_bigram)\ny_train = reviews_train['label'].values\n\nX_test_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_test_bigram)\ny_test = reviews_test['label'].values\n","eebccaf2":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import train_test_split\nfrom scipy.sparse import csr_matrix\nimport numpy as np\n\nsgd_classifier = SGDClassifier(class_weight='balanced', alpha= 0.0001, loss= 'hinge')\n\ndef train_and_show_scores(classifier: SGDClassifier, X: csr_matrix, y: np.array, title: str) -> None:\n    X_train, X_valid, y_train, y_valid = train_test_split(\n        X, y, train_size=0.75, stratify=y\n    )\n    classifier.fit(X_train, y_train)\n    print(X_train.shape)\n    train_score = classifier.score(X_train, y_train)\n    valid_score = classifier.score(X_valid, y_valid)\n    print(f'{title}\\nTrain score: {round(train_score, 2)} ; Validation score: {round(valid_score, 2)}\\n')\n\ntrain_and_show_scores(sgd_classifier, X_train_bigram, y_train, 'Bigram Counts')\ntrain_and_show_scores(sgd_classifier, X_train_bigram_tf_idf, y_train, 'Bigram Tf-Idf')","915ca801":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import SGDClassifier\nfrom scipy.stats import uniform\nimport time\n    \nparams = {\n    \"loss\" : [\"hinge\"],\n    \"alpha\" : [0.00001, 0.0001, 0.001, 0.01],\n    \"penalty\" : [\"l2\", \"l1\", \"none\", \"elasticnet\"],\n    \"class_weight\": ['balanced']\n}\n\ngrid_search_bigram = GridSearchCV(\n    estimator= SGDClassifier(n_jobs=-1),\n    cv=5,\n    param_grid = params,\n    scoring='f1',\n    verbose=1,\n    return_train_score = True\n)\n\ngrid_search_tf_idf = GridSearchCV(\n    estimator= SGDClassifier(n_jobs=-1),\n    cv=5,\n    param_grid = params,\n    scoring='f1',\n    verbose=1,\n    return_train_score = True\n)\n\nstart_time = time.time()\ngrid_search_bigram.fit(X_train_bigram, y_train)\nprint(\"--- Ended in %s minutes ---\" % ((time.time() - start_time)\/60))\n\nstart_time = time.time()\ngrid_search_tf_idf.fit(X_train_bigram_tf_idf, y_train)\nprint(\"--- Ended in %s minutes ---\" % ((time.time() - start_time)\/60))\n\nprint(f'\\nSGD SVM Bigram Counts')\nprint(f'Best params: {grid_search_bigram.best_params_}')\nprint(f'Best f1 score: {grid_search_bigram.best_score_}')\n#print(f'Results: {grid_search_bigram}')\nprint(f'\\nSGD SVM Bigram Tf-Idf')\nprint(f'Best params: {grid_search_tf_idf.best_params_}')\nprint(f'Best f1 score: {grid_search_tf_idf.best_score_}')\n#print(f'Results: {grid_search_tf_idf.cv_results_}')\n\nsgd_svm_classifier_bigram = grid_search_bigram.best_estimator_\nsgd_svm_classifier_tf_idf = grid_search_tf_idf.best_estimator_\n    \n","781b2047":"# Salvataggio del classificatore con iperparametri migliori\n\n#!mkdir 'classifiers'\n#dump(sgd_classifier, 'classifiers\/sgd_classifier.joblib')\n\n# sgd_classifier = load('classifiers\/sgd_classifier.joblib')","e6bb2ea0":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import SGDClassifier\nfrom scipy.stats import uniform\n\nparams = {\n    \"loss\" : [\"log\"],\n    \"alpha\" : [0.00001, 0.0001, 0.001, 0.01],\n    \"penalty\" : [\"l2\", \"l1\", \"none\", \"elasticnet\"],\n    \"class_weight\":['balanced']\n}\n\ngrid_search_bigram = GridSearchCV(\n    estimator= SGDClassifier(n_jobs=-1),\n    cv=5,\n    param_grid = params,\n    scoring='f1',\n    verbose=1,\n    return_train_score = True\n)\n\ngrid_search_tf_idf = GridSearchCV(\n    estimator= SGDClassifier(n_jobs=-1),\n    cv=5,\n    param_grid = params,\n    scoring='f1',\n    verbose=1,\n    return_train_score = True\n)\n\nstart_time = time.time()\ngrid_search_bigram.fit(X_train_bigram, y_train)\nprint(\"--- Ended in %s minutes ---\" % ((time.time() - start_time)\/60))\n\nstart_time = time.time()\ngrid_search_tf_idf.fit(X_train_bigram_tf_idf, y_train)\nprint(\"--- Ended in %s minutes ---\" % ((time.time() - start_time)\/60))\n\nprint(f'\\nSGD Log Bigram Counts')\nprint(f'Best params: {grid_search_bigram.best_params_}')\nprint(f'Best f1 score: {grid_search_bigram.best_score_}')\n#print(f'Results: {grid_search_bigram.cv_results_}')\nprint(f'\\nSGD Log Bigram Tf-Idf')\nprint(f'Best params: {grid_search_tf_idf.best_params_}')\nprint(f'Best f1 score: {grid_search_tf_idf.best_score_}')\n#print(f'Results: {grid_search_tf_idf.cv_results_}')\n\nsgd_log_classifier_bigram = grid_search_bigram.best_estimator_\nsgd_log_classifier_tf_idf = grid_search_tf_idf.best_estimator_","2141441e":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\ndef evaluate(y_test,y_pred):\n    print(\"Precision Score of the model:\", precision_score(y_test,y_pred)*100)\n    print(\"Recall Score of the model:\", recall_score(y_test,y_pred)*100)\n    print(\"Acuracy score of the model:\",accuracy_score(y_test,y_pred)*100)\n    print(\"F1 score of the model:\",f1_score(y_test,y_pred)*100)\n    \ndef set_labels(cf_matrix):\n    group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n    group_counts = [\"{0:0.0f}\".format(value) for value in\n                    cf_matrix.flatten()]\n    group_percentages = [\"{0:.2%}\".format(value) for value in\n                         cf_matrix.flatten()\/np.sum(cf_matrix)]\n    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n              zip(group_names,group_counts,group_percentages)]\n    labels = np.asarray(labels).reshape(2,2)\n    return labels","5a4887b7":"from sklearn.metrics import plot_precision_recall_curve\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sn\n\n\nprint(\"SGD SVM Bigram\")\n\ny_pred = sgd_svm_classifier_bigram.predict(X_test_bigram)\nprint(classification_report(y_test, y_pred))\ncf_matrix =confusion_matrix(y_test, y_pred)\nsn.heatmap(cf_matrix, annot=set_labels(cf_matrix), fmt=\"\")","0de12573":"evaluate(y_test, y_pred)","858392d9":"disp = plot_precision_recall_curve(sgd_svm_classifier_bigram, X_test_bigram, y_test)\ndisp.ax_.set_title(f'SVM Bigram Precision-Recall curve')","4db7b90b":"print(\"SGD SVM Bigram Tf-Idf\")\ny_pred = sgd_svm_classifier_tf_idf.predict(X_test_bigram_tf_idf)\nprint(classification_report(y_test, y_pred))\ncf_matrix = confusion_matrix(y_test, y_pred)\nsn.heatmap(cf_matrix, annot=set_labels(cf_matrix), fmt=\"\")","d57fe7ca":"disp = plot_precision_recall_curve(sgd_svm_classifier_tf_idf, X_test_bigram_tf_idf, y_test)\ndisp.ax_.set_title(f'SVM Tf-Idf Precision-Recall curve')","f28b4f58":"print(\"SGD Logistic regression Bigram\")\ny_pred = sgd_log_classifier_bigram.predict(X_test_bigram)\nprint(classification_report(y_test, y_pred))\ncf_matrix =confusion_matrix(y_test, y_pred)\nsn.heatmap(cf_matrix, annot=set_labels(cf_matrix), fmt=\"\")","3c768748":"disp = plot_precision_recall_curve(sgd_log_classifier_bigram, X_test_bigram, y_test)\ndisp.ax_.set_title(f'Logistic Regression Bigram Precision-Recall curve')","a615391e":"print(\"SGD Logistic regression Bigram Tf-Idf\")\ny_pred = sgd_log_classifier_tf_idf.predict(X_test_bigram_tf_idf)\nprint(classification_report(y_test, y_pred))\ncf_matrix =confusion_matrix(y_test, y_pred)\nsn.heatmap(cf_matrix, annot=set_labels(cf_matrix), fmt=\"\")","6bcc20d3":"disp = plot_precision_recall_curve(sgd_log_classifier_tf_idf, X_test_bigram_tf_idf, y_test)\ndisp.ax_.set_title(f'Logistic Regression Bigram Tf-Idf Precision-Recall curve')","9dc530a7":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom scipy.stats import uniform\n\nparams = {\n    \"class_weight\":['balanced'],\n    'n_estimators': [400, 700],\n    'max_depth' : [8, 16, 32]\n}\n\ngrid_search_rf_bigram = GridSearchCV(\n    estimator= RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True),\n    cv=5,\n    param_grid = params,\n    scoring='f1',\n    verbose=1,\n    return_train_score = True\n)\n\ngrid_search_rf_tf_idf = GridSearchCV(\n    estimator= RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True),\n    cv=5,\n    param_grid = params,\n    scoring='f1',\n    verbose=1,\n    return_train_score = True\n)\n\nstart_time = time.time()\ngrid_search_rf_bigram.fit(X_train_bigram, y_train)\nprint(\"--- Ended in %s minutes ---\" % ((time.time() - start_time)\/60))\n\nstart_time = time.time()\ngrid_search_rf_tf_idf.fit(X_train_bigram_tf_idf, y_train)\nprint(\"--- Ended in %s minutes ---\" % ((time.time() - start_time)\/60))\n\nprint(f'\\nRandom Forest Bigram Counts')\nprint(f'Best params: {grid_search_rf_bigram.best_params_}')\nprint(f'Best f1 score: {grid_search_rf_bigram.best_score_}')\n#print(f'Results: {grid_search_bigram.cv_results_}')\nprint(f'\\Random Forest Bigram Tf-Idf')\nprint(f'Best params: {grid_search_rf_tf_idf.best_params_}')\nprint(f'Best f1 score: {grid_search_rf_tf_idf.best_score_}')\n#print(f'Results: {grid_search_tf_idf.cv_results_}')\n\nrandom_forest_bigram = grid_search_rf_bigram.best_estimator_\nrandom_forest_tf_idf = grid_search_rf_tf_idf.best_estimator_","03b819ce":"from sklearn.metrics import plot_precision_recall_curve\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sn\n\nprint(\"Random Forest Bigram\")\ny_pred = random_forest_bigram.predict(X_test_bigram)\nprint(classification_report(y_test, y_pred))\ncf_matrix =confusion_matrix(y_test, y_pred)\nsn.heatmap(cf_matrix, annot=set_labels(cf_matrix), fmt=\"\")","856c468b":"disp = plot_precision_recall_curve(random_forest_bigram, X_test_bigram, y_test)\ndisp.ax_.set_title(f'Random Forest Bigram Precision-Recall curve')","8a79d6f6":"print(\"Random Forest Tf-Idf\")\ny_pred = random_forest_tf_idf.predict(X_test_bigram_tf_idf)\nprint(classification_report(y_test, y_pred))\ncf_matrix =confusion_matrix(y_test, y_pred)\nsn.heatmap(cf_matrix, annot=set_labels(cf_matrix), fmt=\"\")","f1556394":"disp = plot_precision_recall_curve(random_forest_tf_idf, X_test_bigram_tf_idf, y_test)\ndisp.ax_.set_title(f'Random Forest Bigram Tf-Idf Precision-Recall curve')","d577d8be":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom scipy.stats import uniform\n\n\n# loss, learning rate, initial learning rate, penalty and alpha\n\nparams = {\n    \"n_neighbors\" : [3, 5, 10],\n    \"weights\" : [\"uniform\", \"distance\"]\n}\n\ngrid_search_knn_bigram = GridSearchCV(\n    estimator= KNeighborsClassifier(n_jobs=-1),\n    cv=5,\n    param_grid = params,\n    scoring='f1',\n    verbose=1,\n    return_train_score = True\n)\n\ngrid_search_knn_tf_idf = GridSearchCV(\n    estimator= KNeighborsClassifier(n_jobs=-1),\n    cv=5,\n    param_grid = params,\n    verbose=1,\n    scoring=\"f1\",\n    return_train_score = True\n)\n\nstart_time = time.time()\ngrid_search_knn_bigram.fit(X_train_bigram, y_train)\nprint(\"--- Ended in %s minutes ---\" % ((time.time() - start_time)\/60))\n\nstart_time = time.time()\ngrid_search_knn_tf_idf.fit(X_train_bigram_tf_idf, y_train)\nprint(\"--- Ended in %s minutes ---\" % ((time.time() - start_time)\/60))\n\nprint(f'\\nKNN Bigram')\nprint(f'Best params: {grid_search_knn_bigram.best_params_}')\nprint(f'Best score: {grid_search_knn_bigram.best_score_}')\n\nprint(f'\\nKNN Bigram Tf-Idf')\nprint(f'Best params: {grid_search_knn_tf_idf.best_params_}')\nprint(f'Best score: {grid_search_knn_tf_idf.best_score_}')\n\nknn_classifier_bigram = grid_search_knn_bigram.best_estimator_\nknn_classifier_tf_idf = grid_search_knn_tf_idf.best_estimator_","9afbadbf":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sn\n\nprint(\"KNN Bigram\")\ny_pred = knn_classifier_bigram.predict(X_test_bigram)\n\nprint(classification_report(y_test, y_pred))\ncf_matrix =confusion_matrix(y_test, y_pred)\nsn.heatmap(cf_matrix, annot=set_labels(cf_matrix), fmt=\"\")","ac106834":"disp = plot_precision_recall_curve(knn_classifier_bigram, X_test_bigram, y_test)\ndisp.ax_.set_title(f'KNN Bigram Precision-Recall curve')","b105b587":"print(\"KNN Bigram Tf-Idf\")\ny_pred = knn_classifier_tf_idf.predict(X_test_bigram)\n\nprint(classification_report(y_test, y_pred))\ncf_matrix =confusion_matrix(y_test, y_pred)\nsn.heatmap(cf_matrix, annot=set_labels(cf_matrix), fmt=\"\")","f8584779":"disp = plot_precision_recall_curve(knn_classifier_tf_idf, X_test_bigram, y_test)\ndisp.ax_.set_title(f'KNN Bigram Tf-Idf Precision-Recall curve')","31c38e78":"## Random Forest","71cb67e3":"## KNN: Grid search CV","b2279315":"Distribuzione delle recensioni","568c785e":"# 4. Estrazione delle features\n\nGli algoritmi di apprendimento automatico funzionano solo con valori numerici. Infatti, \u00e8 necessario rappresentare il testo con numeri o vettori di numeri. Un modo per farlo \u00e8 utilizzare il modello **Bag-of-words**, in cui un pezzo di testo (documento) \u00e8 rappresentato da un vettore dei conteggi delle parole di un vocabolario in quel documento. Questo modello non tiene conto delle regole grammaticali o dell'ordinamento delle parole; tutto ci\u00f2 che considera \u00e8 la frequenza delle parole. \n\n* Con l'utilizzo del **bigramma** si prendono in considerazione i conteggi di ogni combinazione di *n* parole del vocabolario che appare in un dato documento.\n\n* Con l'utilizzo della **Term Frequency, Inverse Document Frequency** (TF-IDF) possiamo ottenere risultati leggermente migliori del conteggio delle parole. TF-IDF misura l'importanza di una particolare parola rispetto a un documento e all'intero corpus.\n\n***Frequenza del termine***\n\n    La frequenza del termine \u00e8 la misura dei conteggi di ogni parola in un documento rispetto a tutte le parole nello stesso documento. \n\n    TF(w) = (numero di volte in cui la parola w appare in un documento) \/ (numero totale di parole nel documento)\n\n***Frequenza documento inversa*** \n\n    IDF \u00e8 una misura dell'importanza di una parola, prendendo in considerazione la frequenza della parola in tutto il corpus.\n\n    Misura quanto sia importante una parola per il corpus.\n\n    IDF(w) = log(numero totale di documenti \/ numero di documenti con w  dentro)\n \nInfine, per calcolare TF-IDF, moltiplichiamo questi due fattori: TF e IDF.\n\n**TF-IDF(w) = TF(w) x IDF(w)**\n\n\n# Vettorizzazione del testo\n\nPer la vettorizzazione del testo saranno utilizzate le classi Scikit-Learn (CountVectorizer e TfidfTransformer). \n\nUtilizzeremo queste classi per trasformare i nostri file in matrici bigram (utilizzando sia i conteggi che i valori tf-idf). Ogni riga nelle matrici rappresenter\u00e0 un documento (recensione) nel nostro set di dati e ogni colonna rappresenter\u00e0 i valori associata ad ogni combinazione di massimo 2 parole del vocabolario (bigrammi).\n\n**CountVectorizer** ha un parametro *ngram_rangeche* prevede una tupla di dimensione 2 che controlla quali n-grammi includere. \nDopo aver costruito un oggetto CountVectorizer, dovremmo chiamare il metodoto .fit() con il testo effettivo come parametro, in modo che possa apprendere le statistiche richieste della nostra raccolta di documenti. \nQuindi, chiamando il metodo .transform() con la nostra raccolta di documenti, restituisce la matrice per l'intervallo di n-grammi specificato. \n\nCome suggerisce il nome della classe, questa matrice conterr\u00e0 solo i conteggi. Per ottenere i valori tf-idf, si dovr\u00e0 utilizzare la classe **TfidfTransformer**. Possiede i metodi .fit() e .transform() che vengono usati in modo simile a quelli della CountVectorizer, ma prendono come input la matrice dei conteggi ottenuta nel passaggio precedente e restituiranno una matrice con valori tf-idf. \n\nDovremmo usare .fit() solo sui dati di addestramento; Quando vogliamo valutare il punteggio del test o ogni volta che vogliamo fare una previsione, dovremmo usare questi oggetti per trasformare i dati prima di inserirli nel nostro classificatore.","fe7a6b92":"Dal grafico sopra troviamo le distribuzioni di densit\u00e0 e gli istogrammi delle lunghezze del testo per le recensioni che sono state contrassegnate come positive (1) e negative (0). Si nota come le recensioni negative o neutre contengono circa 150 parole, mentre quelle positive hanno in medi circa 100 parole.","ac98a1f9":"# 2. Dataset\n\nPer avere chiaro il bilanciamento tra recensioni positive o negative, \u00e8 necessario effettuare una valutazione dei dati. Come si pu\u00f2 vedere dal diagramma a torta, le recensioni sono in maggior misura positive. Negli step successivi, provvederemo a bilanciare il dataset al fine di otterenere una equa distribuzione dei dati\nper tutte le classi, in modo tale che gli errori provenienti dalle diverse classi,\novvero dalla classe maggioritaria e dalla classe minoritaria, abbiano lo stesso peso.","b4f81443":"## SVM-Grid search CV","700db3b3":"## KNN: Test","a1b70d79":"# 5. Modelli\nSuccessivamente all\u2019estrazione delle features i dati sono pronti per essere utilizzati con algoritmi di classificazione. Sono presenti in letteratura lavori gi\u00e0 esistenti che si focalizzano sulla distinzione binaria di frasi positive o negative. Altri lavori sono incentrati ad avere una risposta pi\u00f9 accurata, classificando la recensione su una scala numerica. Come \u00e8 stato descritto precedentemente, il dataset \u00e8 stato categorizzato utilizzando la valutazione presente nella recensione, se minore o uguale a 3 la recensione \u00e8 stata etichettata come negativa, altrimenti se maggiore di 3 positiva. Questa classificazione in letteratura \u00e8 descritta come Sentiment Polarity Analisys. I modelli sono stati generati dai seguenti classificatori: \n- Support Vector Machine (SVM)\n- Logistic Regression \n- K-nearest neighbors (KNN)\n","b69395ee":"# 3. Preprocessamento \n\n**Rimozione punteggiatura e Stop-Word**\n\nLe stop-word sono le parole pi\u00f9 comuni in qualsiasi linguaggio naturale. Ai fini dell'analisi dei dati di testo e della creazione di modelli NLP, queste parole non significative potrebbero non aggiungere molto valore al significato del documento. La rimozione delle stopword non \u00e8 una regola rigida in NLP. Dipende dal compito su cui stiamo lavorando. Per attivit\u00e0 come la classificazione del testo, in cui il testo deve essere classificato in diverse categorie, le parole non significative vengono rimosse o escluse dal testo in modo che sia possibile dare maggiore attenzione a quelle parole che definiscono il vero significato del testo.\n\nPer la rimozione delle parole non significative, viene utilizzata la libreria NLTK (Natural Language Toolkit). Le parole pi\u00f9 comuni come \u201cI\u201d, \u201cam\u201d etc sono state scartate come menzionato in precedenza. Tuttavia alcune parole come \u201cnot,\u201dnon\u201d etc non vanno scartate poich \u0301e essendo parole che definiscono il sentimento di una recensione. Rimuovendo si rischia di convertire una frase dal significato negativo in uno positivo, come ad esempio nella frase \u201cnot good\u201d si rischia di lasciare solo la parola \u201cgood\u201d. Abbiamo effettuato anche il processo di \u201cLemmatization\u201d utilizzando sempre la libreria NTLK. Questo metodo trasforma le parole nel loro lemma. Ad esempio la parola \u201cWorking\u201d sar\u00e0 trasformata in \u201cwork\u201d. Questo processo ci aiuter\u00e0 nella analisi corretta delle parole che sono presenti nelle recensioni che poi verranno contrassegnate in maniera binaria in base al loro sentimento.\n\n**Stemming**\n\nLo stemming \u00e8 una fase di pre-elaborazione nelle applicazioni di Text Mining, nonch\u00e8 un requisito molto comune delle funzioni di elaborazione del linguaggio naturale. In effetti, \u00e8 molto importante nella maggior parte dei sistemi di recupero delle informazioni. Lo scopo principale dello stemming \u00e8 ridurre diverse forme grammaticali di una parola come il suo nome, aggettivo, verbo, avverbio ecc., alla sua forma radice. Possiamo dire che l\u2019obiettivo \u00e8 ridurre le forme flessive e talvolta le forme derivate di una parola a una forma base comune.","0a494c04":"# 5.2 Regressione logistica con discesa stocastica del gradiente","58e45adf":"# **Riconoscimento automatico di una review positiva o negativa**\n\nLa seguente implementazione consistente in un classificatore in grado di distinguere recensioni di attivit\u00e0 commerciali come positive o negative. Per questo, \u00e8 stato utilizzato il dataset \u201dYelp Open Dataset\u201d. \nE\u2019 stato utilizzato un set di dati comprendente 600 mila reviews su cui \u00e8 stata effettuata pre-elaborazione del testo. E\u2019 stata confrontata l\u2019efficacia di diversi modelli di apprendimento (SVM, Regressione logistica, Random Forest e KNN) per la previsione del sentimento degli utenti (negativo o positivo).\nL\u2019approccio principale utilizzato in questo documento consiste nel definire le tecniche di pre-processamento dei dati ed estrazione dell features. In seguito, sono stati addestrati diversi classificatori lineari e sono stati comparati i risultati ottenuti.\n","05498892":"# 5.1 Classificatore SVM con discesa stocastica del gradiente","3d9a12da":"# 5.3 Classificatore KNN","b53a844d":"# 1. Preparazione e divisione del dataset\nDopo che il set di dati \u00e8 stato scaricato ed estratto dall'archivio, \u00e8 stato trasformato in una forma pi\u00f9 adatta per alimentarlo in un modello di apprendimento automatico per la formazione. Inizieremo combinando tutti i dati delle revisioni in 2 data frame *pandas* che rappresentano i set di dati del train (80%) e del test (20%): **rewiews_train** e **rewiews_test**.\n\nNei Data Frame \u00e8 stata aggiunta una nuova colonna \"**label**\" dove le recensioni positive (star > 3) avranno valore \"1\" e le recensioni negative (star >= 3) avranno valore \"0\".","8dcee74a":"## SGDC: Test"}}