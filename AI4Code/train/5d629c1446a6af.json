{"cell_type":{"1f044935":"code","298a034f":"code","9e6e2bbc":"code","24e6e956":"code","f7cb17ce":"code","aa218f71":"code","c2fe6ee4":"code","77c1cd56":"code","fba944c6":"code","9cba177a":"code","cd9f0d5d":"code","7e44c299":"code","a17cebf1":"code","0271ad0a":"code","520d1207":"code","c8203f00":"code","3dc09d78":"code","9f389024":"markdown","557e4b98":"markdown","58f6c5b5":"markdown","3f338005":"markdown","d75692b1":"markdown","4427f0ce":"markdown","24befa51":"markdown","9a7e46db":"markdown","6f812a56":"markdown","301d1dd1":"markdown","c29b4daa":"markdown","bfcc7efd":"markdown","0b211056":"markdown","18170309":"markdown","749e308c":"markdown","9354676a":"markdown","a63e2cec":"markdown","14654042":"markdown","6fc2e70e":"markdown","211e9138":"markdown","1033f760":"markdown","e771bbf4":"markdown","e6fa8fc5":"markdown","92c0564f":"markdown","f7e9e9ea":"markdown","b043ec3b":"markdown","64fc8128":"markdown"},"source":{"1f044935":"%%html\n<iframe name=\"ngram_chart\" \n        src=\"https:\/\/books.google.com\/ngrams\/interactive_chart?content=avocado&year_start=1800&year_end=2018&corpus=15&smoothing=3&share=&direct_url=t1%3B%2Cavocado%3B%2Cc0\" \n        width=900 height=300 marginwidth=0 marginheight=0 hspace=0 vspace=0 frameborder=0 scrolling=no style=\"float:right\">\n<\/iframe>","298a034f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, LabelBinarizer, OneHotEncoder\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import average_precision_score\n\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 12, 8\nsns.set(font_scale = 1.7)","9e6e2bbc":"# import the csv\ndf = pd.read_csv('..\/input\/avocado.csv')","24e6e956":"# examine example data\ndf.head()","f7cb17ce":"# examine the entire set\ndf.info()","aa218f71":"# drop unnecessary columns\ndf = df.drop(['Unnamed: 0'], axis=1)\n\n# clean up the headers\nmapping = {\"Date\": \"date\", \n           \"AveragePrice\": \"average_price\",\n           \"Total Volume\": \"total_volume\",\n           \"Total Bags\": \"total_bags\",\n           \"Small Bags\": \"small_bags\",\n           \"Large Bags\": \"large_bags\",\n           \"XLarge Bags\": \"xlarge_bags\"}\ndf = df.rename(columns=mapping)\n\n# parse the dates\ndf['date'] = pd.to_datetime(df['date'])\n\n# encode the categorial 'type' and 'region'\nle = LabelEncoder()\ndf['type_encoded'] = le.fit_transform(df['type'])\ndf['region_encoded'] = le.fit_transform(df['region'])","c2fe6ee4":"# iterate the types\nfor typ in df['type'].unique():\n    print(typ)","77c1cd56":"# plot the distribution of price by type\nfor typ in df['type'].unique():\n    sns.distplot( df[\"average_price\"][df['type']==typ], label=typ)\nplt.legend()","fba944c6":"# plot the time series of average price\ntraces = []\nfor typ in df['type'].unique():\n    tmp = df[df['type']==typ]\n    tmp = tmp.groupby(['date'], as_index=False)['average_price'].mean()\n    traces.append(go.Scatter(x=tmp['date'], y=tmp['average_price'], name=typ))\niplot(traces)","9cba177a":"print(df['region'].unique())\nprint(len(df['region'].unique()))","cd9f0d5d":"# create a temporary dataset sorted by the average-average_price in each region\ntmp = df.copy()\ntmp2 = tmp.groupby(['region'], as_index = False)['average_price'].mean()\ntmp2 = tmp2.rename(index=str, columns={\"average_price\": \"mean_average_price\"})\ntmp3 = pd.merge(tmp,tmp2[['region','mean_average_price']], how='left', on='region')\ntmp3 = tmp3.sort_values('mean_average_price')\n\n# create a seaborn facet grid plot\nsns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)}, font_scale = 7.0)\npal = sns.cubehelix_palette(len(df['region'].unique()), rot=-.30, light=.7)\ng = sns.FacetGrid(tmp3, row=\"region\", hue=\"region\", aspect=30, palette=pal)\n\ng.map(sns.kdeplot, \"average_price\", clip_on=False, shade=True, alpha=1.0, lw=1.5, bw=.2)\ng.map(sns.kdeplot, \"average_price\", clip_on=False, color=\"w\", lw=2, bw=.2)\ng.map(plt.axhline, y=0, lw=2, clip_on=False)\n\ndef label(x, color, label):\n    ax = plt.gca()\n    ax.text(0, .2, label, fontweight=\"bold\", color=color,ha=\"left\", va=\"center\", transform=ax.transAxes)\n\ng.map(label, \"region\")\ng.fig.subplots_adjust(hspace=-.25)\ng.set_titles(\"\")\ng.set(yticks=[])\ng.despine(bottom=True, left=True)\nplt.show()","7e44c299":"# create a temporary data frame with only the numeric fields for exploration\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ntmp = df.select_dtypes(include=numerics)\ntmp = tmp.drop(['year', 'region_encoded', 'type_encoded'], axis=1)","a17cebf1":"# pair plot the relationship between numeric features\nsns.set(style=\"ticks\", font_scale = 2.0, color_codes=True)\nsns.pairplot(tmp)","0271ad0a":"# heat map of the correlation coefficients between numeric features\nrcParams['figure.figsize'] = 12, 8\nsns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)}, font_scale = 1.7)\ncm = np.corrcoef(tmp.values.T)\nhm = sns.heatmap(cm, cbar = True, annot = True,square = True, fmt = '.2f',\n                 annot_kws = {'size':15}, yticklabels = list(tmp), xticklabels = list(tmp))","520d1207":"# binarize the categorical 'region'\nlb = LabelBinarizer()\ntrns = lb.fit_transform(df['region'].values)\ntmp = pd.DataFrame(trns, columns = [\"region_\"+str(int(i)) for i in range(trns.shape[1])])\ndf = pd.concat([df, tmp], axis=1)\n\n# choose features to train against\nx = df.drop(['type', 'type_encoded', 'region', 'region_encoded', 'date'], axis = 1)\nprint( \"Using features: \", list(x))\n\n# choose output variable\ny = df['type_encoded']\n\n# get test and train sets\nx_train,x_test,y_train,y_test = train_test_split(x, y, random_state = 0)\n\n# train 3 different classifier models\nlr =  LogisticRegression(penalty='l1', tol=0.0001).fit(x_train, y_train)\nsv = SVC(gamma='auto').fit(x_train, y_train) \nrf =  RandomForestClassifier(n_estimators = 100, random_state = 0, max_features = 2).fit(x_train, y_train)\n\n# print the model accuracies\nprint(\"a logistic regression classifier gives a test data score of {:.4f}\".format(lr.score(x_test,y_test)))\nprint(\"a support vector classifier give a test data score of {:.4f}\".format(sv.score(x_test,y_test)))\nprint(\"a random forest classifier gives a test data score of {:.4f}\".format(rf.score(x_test,y_test)))","c8203f00":"# print starting dimensionality\nprint(x_train.shape)\n\n# use PCA to reduce the dimensionality\npca = PCA(n_components=5, whiten=True) ## quite a drastic number I guess but lets see if that works! also, removes linear correlation\nX_train_scaled_reduced = pca.fit_transform(x_train)\nX_test_scaled_reduced = pca.fit_transform(x_test)\n\n# print resulting dimensionality\nprint(X_train_scaled_reduced.shape)\n\n# print the explained variance\nprint(pca.explained_variance_ratio_.cumsum())","3dc09d78":"# re-train the 3 different classifier models\nlr =  LogisticRegression(penalty='l1', tol=0.0001).fit(X_train_scaled_reduced, y_train)\nsv = SVC(gamma='auto',  kernel='linear', tol=0.001).fit(X_train_scaled_reduced, y_train) \nrf =  RandomForestClassifier(n_estimators = 100, random_state = 0, max_features = 2).fit(X_train_scaled_reduced, y_train)\n\n# print the model accuracies\nprint(\"a logistic regression classifier gives a test data score of {:.4f}\".format(lr.score(X_test_scaled_reduced,y_test)))\nprint(\"a support vector classifier give a test data score of {:.4f}\".format(sv.score(X_test_scaled_reduced,y_test)))\nprint(\"a random forest classifier gives a test data score of {:.4f}\".format(rf.score(X_test_scaled_reduced,y_test)))","9f389024":"From the above we can see that the average price of organic avocados has been consistently higher than conventional avocados, but also the price of both types of avocado spiked in September 2017, which can easily be explained with a quick google search ... [avocado Prices Climb to an Even Crazier All-time High](http:\/\/www.grubstreet.com\/2017\/09\/avocado-prices-climb-to-their-all-time-highest.html)","557e4b98":"We can see that there is a clear difference in the average price distribution of convetional and organic avocados, with organic avocados being significantly more expensive. ","58f6c5b5":"<center>[https:\/\/books.google.com\/ngrams\/](https:\/\/books.google.com\/ngrams\/graph?content=avocado&case_insensitive=on&year_start=1800&year_end=2008&corpus=15&smoothing=3&share=&direct_url=t4%3B%2Cavocado%3B%2Cc0%3B%2Cs0%3B%3Bavocado%3B%2Cc0%3B%3BAvocado%3B%2Cc0%3B%3BAVOCADO%3B%2Cc0)<\/center>","3f338005":"### --- Feature exploration - regions","d75692b1":"Given that the type of avocoda is such a distinguishing feature we should be able to use machine learning to build a strong classifier of avocado type","4427f0ce":"### --- Machine learning - classifying avocado type","24befa51":"### --- Feature exploration - the numeric variables","9a7e46db":"### --- Feature exploration - conventional vs organic","6f812a56":"What a great result on the first try, in particular for the random forest model. However the support vector classifier is clearly having some trouble reaching the same lofty heights at the other models. Let's see if we can use dimensionality reduction to improve the support vector model.","301d1dd1":"From a first look at the data we can see that there is a mix of data types and header formats, but most importantly we can see that there are no null values - which is good news.","c29b4daa":"<img src=\"https:\/\/www.wellandgood.com\/wp-content\/uploads\/2018\/06\/Stocksy-Avocado-flat-lay-Marti-Sans.jpg\" width=\"500px\"\/>","bfcc7efd":"### --- ** Let's get started!**","0b211056":"Many thanks to Justin Kiggins for adding this great dataset. In this notebook I'll take a quick look at some of the features and their correlations and do a bit of machine learning and price forecasting, and for those of you who need convincing that this is important work - take a look at this Google n-gram highlighting the meteoric rise in avocado popularity...","18170309":"> *Avocados are a naturally nutrient-dense food and contain nearly 20 vitamins and minerals.Also known as an alligator pear or butter fruit, the versatile avocado is the only fruit that provides a substantial amount of healthy monounsaturated fatty acids.*","749e308c":"Here we have tidied up the data a little, converts to dates from strings to datetimes and added encoding for the categorical variables using *LabelEncoder*","9354676a":"Looking at the regions in the dataset...","a63e2cec":"### --- Wrangle the data","14654042":"Printing the cumulative sum of the explained variance we can see that in reducing from 64 to 5 dimensions we can still explain 99.99% of the variance in the data. Lets see how fitting against the 5 dimensions does...","6fc2e70e":"... we can see 54 distinct regions. Now let's look at the distribution of the average price of avocados as a function of region...","211e9138":"Using a *Seaborn - pair plot* we can clearly see a lot of correlation between many of the variables, we can summarise this using a heat map of the correlation coefficients between the same variables","1033f760":"Lets examine the relationship between the numeric features isolated in the temporary data frame","e771bbf4":"<img src=\"http:\/\/newsletter.deltaphilambda.org\/wp-content\/uploads\/2016\/07\/avocado-carrot-768x506.png\" width=\"750px\"\/>","e6fa8fc5":"Clearly the reduced dimensionality has degraded the logistic regression and random forest models (though they still perform remarkably well off so few dimensions) but the support vector classifier has improved enormously thanks to the dimensionality reductions","92c0564f":"Lets look at the two *types* of avocado in the dataset...","f7e9e9ea":"The heatmap shows that the average price of the avocados is not strongly correlated to any of the other numeric features, but that those other numeric features are all strongly correlated to each other. ","b043ec3b":"# **Bravo - cado!** ","64fc8128":"### --- Import and examine the data"}}