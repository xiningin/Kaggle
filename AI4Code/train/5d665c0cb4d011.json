{"cell_type":{"bd7b2421":"code","531d71a0":"code","1468e1f9":"code","ef6ec398":"code","85127a1f":"code","593fe4b6":"code","08b8bcb3":"code","4cd05316":"code","1232f0b8":"code","3aa259f8":"code","32773e34":"code","dd7aed31":"code","396a8080":"code","c166dd79":"code","a6bd0b31":"code","08985077":"code","9b09c93c":"code","e971656c":"code","70aec94a":"code","ec9918c5":"code","a314b2c6":"code","c9046680":"code","d2a836a6":"code","18ad9fb8":"code","d5143a40":"code","286a2743":"code","0e04853e":"code","1f5a0d12":"code","3c59f099":"code","ac942080":"code","6eaba7d7":"code","acb3e174":"code","2b751cf3":"code","6c384971":"code","011ea428":"code","1486e72c":"code","11607b3b":"code","a428b76a":"code","f654f367":"code","6719da4d":"code","c9f460c0":"code","e20220e1":"code","d5b58514":"code","3be49078":"code","4ead099b":"code","09104388":"code","2dc65c42":"code","6549174a":"code","2e3430c6":"code","8febc03e":"code","284c4c25":"code","5cc94563":"code","0e00a6f0":"code","43bbab2c":"code","79af0fd7":"code","656a5168":"code","aab1d29e":"code","e78fa147":"code","2e640af1":"code","01262b6e":"code","4045c990":"code","1816d8f6":"code","bd17f8ec":"code","b9630884":"code","9c0f5db2":"code","5d02046d":"code","be873bf2":"code","15c5ea4a":"code","aedaee97":"code","b06e2dde":"code","fe0a65bd":"code","0150b6e6":"code","0915f70a":"code","1e1cafc1":"code","1ee2d98b":"code","496d4482":"code","f7038cf1":"code","ba31908c":"code","28d6fd74":"code","b449c855":"code","1b191766":"code","3ee25465":"code","bc5624e5":"code","4340159b":"code","f439f89c":"code","fd3f8b69":"code","55e5a2ca":"code","8ec2eb6e":"code","d842a215":"code","acf55194":"code","ccb3dcfa":"code","a58a1348":"code","2b164db4":"code","af531efa":"code","f04da5e4":"code","9ec86303":"code","5e1c9356":"code","b59c2738":"code","9937ac5c":"code","64f3c611":"code","962cc6d0":"code","7493cc7c":"code","09e68d68":"code","5704f4f1":"code","bf006a08":"code","83319205":"code","a52abad8":"code","c8914d84":"code","caa02693":"code","c0494561":"code","94637746":"code","08c07cee":"code","bd717d68":"code","3d9d975d":"code","4c865e70":"code","83eaeef3":"code","74244cfa":"code","4773548c":"code","b92bfdb6":"markdown","2e9ba948":"markdown","bc63b683":"markdown","cf2c7362":"markdown","d73fafca":"markdown","41587ec3":"markdown"},"source":{"bd7b2421":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","531d71a0":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom math import sin, cos, pi\nfrom tqdm.notebook import tqdm\n\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom os import listdir\nfrom os.path import join, dirname, abspath\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nfrom os import listdir\nfrom os.path import join, dirname, abspath\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import MaxPooling2D, Conv2D\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom json import dumps, load\nfrom numpy import array\nfrom os import environ\nfrom os.path import join\nfrom sys import argv\nfrom skimage.color import rgb2gray","1468e1f9":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom math import sin, cos, pi\nimport cv2\nfrom tqdm.notebook import tqdm\n\nfrom tensorflow.python.keras.layers.advanced_activations import LeakyReLU\nfrom tensorflow.python.keras.models import Sequential, Model\nfrom tensorflow.python.keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D\nfrom tensorflow.python.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.python.keras.optimizers import Adam","ef6ec398":"path = '..\/input\/00_test_img_input\/train\/images'\ngt = '..\/input\/00_test_img_input\/train\/gt.csv'","85127a1f":"from PIL import Image\njpgfile = Image.open(\"..\/input\/00_test_img_input\/train\/images\/00020.jpg\")\nkeypoints = res.get('00020.jpg')","593fe4b6":"jpgfile","08b8bcb3":"fig, axis = plt.subplots()\nplot_sample(jpgfile, keypoints, axis, 'sad')","4cd05316":"def plot_sample(image, keypoint, axis, title):\n    axis.imshow(image)\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker='x', s=20)\n    plt.title(title)","1232f0b8":"jpgfile","3aa259f8":"from skimage.color import rgb2gray\nrgb2gray(np.asarray(jpgfile))\nfig, axis = plt.subplots()\nplot_sample(rgb2gray(np.asarray(jpgfile)), keypoints, axis, 'asd')","32773e34":"def read_csv(filename):\n    res = {}\n    with open(filename) as fhandle:\n        next(fhandle)\n        for line in fhandle:\n            parts = line.rstrip('\\n').split(',')\n            coords = array([float(x) for x in parts[1:]], dtype='float64')\n            res[parts[0]] = coords\n    return res\nres = read_csv(gt)","dd7aed31":"res","396a8080":"\ndef convert_y_to_fit(y, x_sizes):\n    y_new = np.empty(y.shape)\n    y[y < 0] = 0\n    for i in range(y_new.shape[0]):\n        y_new[i, :: 2] = y[i, :: 2] \/ x_sizes[i, 1] * 96.\n        y_new[i, 1:: 2] = y[i, 1:: 2] \/ x_sizes[i, 0] * 96.\n\n    return y_new\n\ndef convert_y_back(y, x_sizes):\n    y_new = np.empty(y.shape)\n    y[y < 0] = 0\n    for i in range(y_new.shape[0]):\n        y_new[i, :: 2] = y[i, :: 2] * x_sizes[i, 1] \/ 96.\n        y_new[i, 1:: 2] = y[i, 1:: 2] * x_sizes[i, 0] \/ 96.\n\n    return y_new","c166dd79":"file_name = listdir(path)\nfile_name","a6bd0b31":"fasd = listdir(path)\nfasd","08985077":"def read_images_gt(img_path, size, gt_file=None):\n    file_name = listdir(img_path)\n    n = len(file_name)\n    x = np.empty((n, size, size))\n    sizes = np.empty((n, 2))\n    y = None\n    if gt_file is not None:\n        y = np.empty((len(gt_file), 28), dtype=int)\n\n    for i in range(n):\n        img = imread(join(img_path, file_name[i]))\n        if len(img.shape) == 3:\n            img = rgb2gray(img)\n\n        x[i] = resize(img, (size, size))\n        sizes[i, 0] = img.shape[0]\n        sizes[i, 1] = img.shape[1]\n        if gt_file is not None:\n            y[i] = gt_file.get(file_name[i])\n\n    x = normalize_x(x)\n    x = x.reshape((x.shape[0], size, size, 1))\n\n    if gt_file is not None:\n        y = convert_y_to_fit(y, sizes)\n\n    return x, y, sizes","9b09c93c":"file_name = listdir(path)\nimg = imread(join(path, file_name[3]))\n#img = np.dot(img[..., :3], [0.299, 0.587, 0.114])\ny = res.get(file_name[3])","e971656c":"fig, axis = plt.subplots()\nplot_sample(img, y, axis, \"Sample image & keypoints\")","70aec94a":"x, y, sizes = read_images_gt(path, 96, res)","ec9918c5":"len(file_name)","a314b2c6":"def plot_sample(image, keypoint, axis, title):\n    image = image.reshape(96,96)\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker='x', s=20)\n    plt.title(title)\n","c9046680":"fig, axis = plt.subplots()\nplot_sample(x[4517], y[4517], axis, \"Sample image & keypoints\")","d2a836a6":"train_x, train_y = x, y ","18ad9fb8":"def left_right_flip(images, keypoints):\n    flipped_keypoints = []\n    flipped_images = np.flip(images, axis=2)   # Flip column-wise (axis=2)\n    for idx, sample_keypoints in enumerate(keypoints):\n        flipped_keypoints.append([96.-coor if idx%2==0 else coor for idx,coor in enumerate(sample_keypoints)])    # Subtract only X co-ordinates of keypoints from 96 for horizontal flipping\n    return flipped_images, flipped_keypoints","d5143a40":"def left_right_flip(images, keypoints):\n    flipped_keypoints = []\n    flipped_images = np.flip(images, axis=2)   # Flip column-wise (axis=2)\n    for idx, sample_keypoints in enumerate(keypoints):\n        flipped_keypoints.append([96.-coor if idx%2==0 else coor for idx,coor in enumerate(sample_keypoints)])    # Subtract only X co-ordinates of keypoints from 96 for horizontal flipping\n    return flipped_images, flipped_keypoints\n\nflipped_train_images, flipped_train_keypoints = left_right_flip(x, y)\nprint(\"Shape of flipped_train_images: {}\".format(np.shape(flipped_train_images)))\nprint(\"Shape of flipped_train_keypoints: {}\".format(np.shape(flipped_train_keypoints)))\ntrain_x = np.concatenate((train_x, flipped_train_images))\ntrain_y = np.concatenate((train_y, flipped_train_keypoints))\nfig, axis = plt.subplots()\nplot_sample(flipped_train_images[3], flipped_train_keypoints[3], axis, \"Horizontally Flipped\") ","286a2743":"print(train_y.shape)\nprint(train_x.shape)","0e04853e":"rotation_angles = [7, 14]    # Rotation angle in degrees (includes both clockwise & anti-clockwise rotations)\npixel_shifts = [12] \nsample_image_index = 3","1f5a0d12":"def rotate_augmentation(images, keypoints):\n    rotated_images = []\n    rotated_keypoints = []\n    print(\"Augmenting for angles (in degrees): \")\n    for angle in rotation_angles:    # Rotation augmentation for a list of angle values\n        for angle in [angle,-angle]:\n            print(f'{angle}', end='  ')\n            M = cv2.getRotationMatrix2D((48,48), angle, 1.0)\n            angle_rad = -angle*pi\/180.     # Obtain angle in radians from angle in degrees (notice negative sign for change in clockwise vs anti-clockwise directions from conventional rotation to cv2's image rotation)\n            # For train_images\n            for image in images:\n                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n            # For train_keypoints\n            for keypoint in keypoints:\n                rotated_keypoint = keypoint - 48.    # Subtract the middle value of the image dimension\n                for idx in range(0,len(rotated_keypoint),2):\n                    # https:\/\/in.mathworks.com\/matlabcentral\/answers\/93554-how-can-i-rotate-a-set-of-points-in-a-plane-by-a-certain-angle-about-an-arbitrary-point\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += 48.   # Add the earlier subtracted value\n                rotated_keypoints.append(rotated_keypoint)\n            \n    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints","3c59f099":"def rotate_augmentation(images, keypoints):\n    rotated_images = []\n    rotated_keypoints = []\n    print(\"Augmenting for angles (in degrees): \")\n    for angle in rotation_angles:    # Rotation augmentation for a list of angle values\n        for angle in [angle,-angle]:\n            print(f'{angle}', end='  ')\n            M = cv2.getRotationMatrix2D((48,48), angle, 1.0)\n            angle_rad = -angle*pi\/180.     # Obtain angle in radians from angle in degrees (notice negative sign for change in clockwise vs anti-clockwise directions from conventional rotation to cv2's image rotation)\n            # For train_images\n            for image in images:\n                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n            # For train_keypoints\n            for keypoint in keypoints:\n                rotated_keypoint = keypoint - 48.    # Subtract the middle value of the image dimension\n                for idx in range(0,len(rotated_keypoint),2):\n                    # https:\/\/in.mathworks.com\/matlabcentral\/answers\/93554-how-can-i-rotate-a-set-of-points-in-a-plane-by-a-certain-angle-about-an-arbitrary-point\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += 48.   # Add the earlier subtracted value\n                rotated_keypoints.append(rotated_keypoint)\n            \n    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints\n\n\nrotated_train_images, rotated_train_keypoints = rotate_augmentation(x, y)\nprint(\"\\nShape of rotated_train_images: {}\".format(np.shape(rotated_train_images)))\nprint(\"Shape of rotated_train_keypoints: {}\\n\".format(np.shape(rotated_train_keypoints)))\ntrain_x = np.concatenate((train_x, rotated_train_images))\ntrain_y = np.concatenate((train_y, rotated_train_keypoints))\nfig, axis = plt.subplots()\nplot_sample(rotated_train_images[sample_image_index], rotated_train_keypoints[sample_image_index], axis, \"Rotation Augmentation\")","ac942080":"print(train_y.shape)\nprint(train_x.shape)","6eaba7d7":"def alter_brightness(images, keypoints): \n    altered_brightness_images = []\n    inc_brightness_images = np.clip(images*1.2, 0.0, 1.0)    # Increased brightness by a factor of 1.2 & clip any values outside the range of [-1,1]\n    dec_brightness_images = np.clip(images*0.6, 0.0, 1.0)    # Decreased brightness by a factor of 0.6 & clip any values outside the range of [-1,1]\n    altered_brightness_images.extend(inc_brightness_images)\n    altered_brightness_images.extend(dec_brightness_images)\n    return altered_brightness_images, np.concatenate((keypoints, keypoints))","acb3e174":"def alter_brightness(images, keypoints):\n    altered_brightness_images = []\n    inc_brightness_images = np.clip(images*1.2, 0.0, 1.0)    # Increased brightness by a factor of 1.2 & clip any values outside the range of [-1,1]\n    dec_brightness_images = np.clip(images*0.6, 0.0, 1.0)    # Decreased brightness by a factor of 0.6 & clip any values outside the range of [-1,1]\n    altered_brightness_images.extend(inc_brightness_images)\n    altered_brightness_images.extend(dec_brightness_images)\n    return altered_brightness_images, np.concatenate((keypoints, keypoints))\n\n\naltered_brightness_train_images, altered_brightness_train_keypoints = alter_brightness(x, y)\nprint(f\"Shape of altered_brightness_train_images: {np.shape(altered_brightness_train_images)}\")\nprint(f\"Shape of altered_brightness_train_keypoints: {np.shape(altered_brightness_train_keypoints)}\")\ntrain_x = np.concatenate((train_x, altered_brightness_train_images))\ntrain_y = np.concatenate((train_y, altered_brightness_train_keypoints))\nfig, axis = plt.subplots()\nplot_sample(altered_brightness_train_images[sample_image_index], altered_brightness_train_keypoints[sample_image_index], axis, \"Increased Brightness\") \nfig, axis = plt.subplots()\nplot_sample(altered_brightness_train_images[len(altered_brightness_train_images)\/\/2+sample_image_index], altered_brightness_train_keypoints[len(altered_brightness_train_images)\/\/2+sample_image_index], axis, \"Decreased Brightness\") ","2b751cf3":"print(train_y.shape)\nprint(train_x.shape)","6c384971":"def build_model(image_size, output_size):\n    model = Sequential()\n\n    # Input dimensions: (None, 96, 96, 1)\n    model.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=image_size))\n    model.add(LeakyReLU(alpha = 0.1))\n    model.add(BatchNormalization())\n    # Input dimensions: (None, 96, 96, 32)\n    model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha = 0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2)))\n\n    # Input dimensions: (None, 48, 48, 32)\n    model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha = 0.1))\n    model.add(BatchNormalization())\n    # Input dimensions: (None, 48, 48, 64)\n    model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha = 0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2)))\n\n    # Input dimensions: (None, 24, 24, 64)\n    model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha = 0.1))\n    model.add(BatchNormalization())\n    # Input dimensions: (None, 24, 24, 96)\n    model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha = 0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2)))\n\n    # Input dimensions: (None, 12, 12, 96)\n    model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha = 0.1))\n    model.add(BatchNormalization())\n    # Input dimensions: (None, 12, 12, 128)\n    model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha = 0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2)))\n\n    # Input dimensions: (None, 6, 6, 128)\n    model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n    model.add(LeakyReLU(alpha = 0.1))\n    model.add(BatchNormalization())\n    # Input dimensions: (None, 6, 6, 256)\n    model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n    model.add(LeakyReLU(alpha = 0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2)))\n\n    # Input dimensions: (None, 3, 3, 256)\n    model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha = 0.1))\n    model.add(BatchNormalization())\n    # Input dimensions: (None, 3, 3, 512)\n    model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha = 0.1))\n    model.add(BatchNormalization())\n\n    # Input dimensions: (None, 3, 3, 512)\n    model.add(Flatten())\n    model.add(Dense(512,activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(28))\n    model.summary()\n    return model","011ea428":"NUM_EPOCHS = 75\nBATCH_SIZE = 128","1486e72c":"%%time\n\n# Define necessary callbacks\ncheckpointer = ModelCheckpoint(filepath = 'best_model.hdf5', monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'acc'])\n\n# Train the model\nhistory = model.fit(train_x, train_y, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_split=0.05, callbacks=[checkpointer])","11607b3b":"features = []\nk = 5\nfor i in range(k):\n    features.append((x[i * 6000 \/\/ k: (i + 1) * 6000 \/\/ k], y[i * 6000 \/\/ k: (i + 1) * 6000 \/\/ k], sizes[i * 6000 \/\/ k: (i + 1) * 6000 \/\/ k]))","a428b76a":"features[2][1].shape","f654f367":"def compute_metric(detected, values, img_shapes):\n    res = 0.0\n    for i in range(len(values)):\n        n_rows, n_cols = img_shapes[i]\n        coords = detected[i]\n        diff = (coords - values[i])\n        diff[::2] \/= n_cols\n        diff[1::2] \/= n_rows\n        diff *= 100\n        res += (diff ** 2).mean()\n    return res \/ len(values)","6719da4d":"res_s = []\nfor i in range(1, 2):\n    train_feat = []\n    train_labels = []\n    test = features[i]\n    for j in range(k):\n        if j == i:\n            continue\n        train_feat.append(features[i][0])\n        train_labels.append(features[i][1])\n    train_feat = np.concatenate(train_feat)\n    train_labels = np.concatenate(train_labels)\n    x_tmp = train_feat\n    y_tmp = train_labels\n    model = get_model()\n    flipped_train_images, flipped_train_keypoints = left_right_flip(x_tmp, y_tmp)\n    train_feat = np.concatenate((train_feat, flipped_train_images))\n    train_labels = np.concatenate((train_labels, flipped_train_keypoints))\n    \n    rotated_train_images, rotated_train_keypoints = rotate_augmentation(x_tmp, y_tmp)\n    train_feat = np.concatenate((train_feat, rotated_train_images))\n    train_labels = np.concatenate((train_labels, rotated_train_keypoints))\n    \n    altered_brightness_train_images, altered_brightness_train_keypoints = alter_brightness(x_tmp, y_tmp)\n    train_feat = np.concatenate((train_feat, altered_brightness_train_images))\n    train_labels = np.concatenate((train_labels, altered_brightness_train_keypoints))\n    \n    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'acc'])\n\n    # Train the model\n    model.fit(train_feat, train_labels, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE)\n    pred_y = model.predict(test[0])\n    pred_y = convert_y_back(pred_y, test[2])\n    new_test = convert_y_back(test[1], test[2])\n    res_s.append(compute_metric(pred_y, new_test, test[2]))\n    print(res_s[len(res_s) - 1])\n    ","c9f460c0":"def build_model(image_size):\n    model = Sequential()\n    model.add(Conv2D(32, 3, input_shape=(image_size, image_size, 1)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(64, 2))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, 2))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.3))\n\n    model.add(Flatten())\n    model.add(Dense(1000))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1000))\n    model.add(Activation('relu'))\n    model.add(Dense(28))\n\n    return model","e20220e1":"path = '..\/input\/00_test_img_input\/train\/images'\ngt = '..\/input\/00_test_img_input\/train\/gt.csv'","d5b58514":"def read_csv(filename):\n    res = {}\n    with open(filename) as fhandle:\n        next(fhandle)\n        for line in fhandle:\n            parts = line.rstrip('\\n').split(',')\n            coords = array([float(x) for x in parts[1:]], dtype='float64')\n            res[parts[0]] = coords\n    return res\nres = read_csv(gt)","3be49078":"def normalize_x(x):\n    average = np.mean(x, axis=0)\n    for i in range(x.shape[0]):\n        x[i] -= average\n\n    d1 = np.abs(x.max(axis=0))\n    d2 = np.abs(x.min(axis=0))\n    d = np.maximum(d1, d2)\n    for i in range(x.shape[0]):\n        x[i] = (x[i] + d) \/ (2 * d)\n\n    return x\n","4ead099b":"def read_images_gt(img_path, size, gt_file=None):\n    file_name = listdir(img_path)\n    n = len(file_name)\n    x = np.empty((n, size, size))\n    sizes = np.empty((n, 2))\n    y = None\n    if gt_file is not None:\n        y = np.empty((len(gt_file), 28), dtype=int)\n    images = []\n    for i in range(n):\n        #print(file_name[i])\n        img = imread(join(img_path, file_name[i]))\n        if len(img.shape) == 3:\n            img = rgb2gray(img)\n        #images.append(img)\n        sizes[i, 0] = img.shape[0]\n        sizes[i, 1] = img.shape[1]\n        x[i] = resize(img, (size, size))\n        if gt_file is not None:\n            y[i] = gt_file.get(file_name[i])\n\n    x = normalize_x(x)\n    x = x.reshape((x.shape[0], size, size, 1))\n\n    if gt_file is not None:\n        new_y = convert_y_to_fit(y, sizes)\n\n    return x, new_y, sizes, y","09104388":"scale = 0.75\nx, y, sizes, real_y = read_images_gt(path, 96, res)\n","2dc65c42":"train_x = x[:int(len(x) * scale)]\ntrain_y = y[:int(len(y) * scale)]\nsizes_train = sizes[:int(len(sizes) * scale)]\nreal_train = real_y[:int(len(real_y) * scale)]","6549174a":"print(train_x.shape)\nprint(train_y.shape)\nprint(sizes_train.shape)\nprint(real_train.shape)","2e3430c6":"test_x = x[int(len(x) * scale):]\ntest_sizes = sizes[int(len(sizes) * scale):]\ntest_y = real_y[int(len(real_y) * scale):]\ntest_nonreal_y = y[int(len(y) * scale):]","8febc03e":"print(test_x.shape)\nprint(test_sizes.shape)\nprint(test_y.shape)","284c4c25":"tmp_x = train_x\ntmp_y = train_y\ntmp_sizes = sizes_train","5cc94563":"def left_right_flip(images, keypoints):\n    flipped_keypoints = []\n    flipped_images = np.flip(images, axis=2)   # Flip column-wise (axis=2)\n    for idx, sample_keypoints in enumerate(keypoints):\n        flipped_keypoints.append([96.-coor if idx%2==0 else coor for idx,coor in enumerate(sample_keypoints)])    # Subtract only X co-ordinates of keypoints from 96 for horizontal flipping\n    return flipped_images, flipped_keypoints\n\nflipped_train_images, flipped_train_keypoints = left_right_flip(tmp_x, tmp_y)\nprint(\"Shape of flipped_train_images: {}\".format(np.shape(flipped_train_images)))\nprint(\"Shape of flipped_train_keypoints: {}\".format(np.shape(flipped_train_keypoints)))\ntrain_x = np.concatenate((train_x, flipped_train_images))\ntrain_y = np.concatenate((train_y, flipped_train_keypoints))\nsizes_train = np.concatenate((sizes_train,tmp_sizes))\nfig, axis = plt.subplots()\nplot_sample(flipped_train_images[3], flipped_train_keypoints[3], axis, \"Horizontally Flipped\") ","0e00a6f0":"print(train_x.shape)\nprint(train_y.shape)","43bbab2c":"rotation_angles = [12]    # Rotation angle in degrees (includes both clockwise & anti-clockwise rotations)\npixel_shifts = [12] \nsample_image_index = 3","79af0fd7":"def rotate_augmentation(images, keypoints, sizes):\n    rotated_images = []\n    rotated_keypoints = []\n    new_sizes = []\n    cnt = 0\n    print(\"Augmenting for angles (in degrees): \")\n    for angle in rotation_angles:    # Rotation augmentation for a list of angle values\n        for angle in [angle,-angle]:\n            cnt = 0\n            print(f'{angle}', end='  ')\n            M = cv2.getRotationMatrix2D((48,48), angle, 1.0)\n            angle_rad = -angle*pi\/180.     # Obtain angle in radians from angle in degrees (notice negative sign for change in clockwise vs anti-clockwise directions from conventional rotation to cv2's image rotation)\n            # For train_images\n            for image in images:\n                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n                new_sizes.append(sizes[cnt])\n                cnt = cnt + 1\n            # For train_keypoints\n            for keypoint in keypoints:\n                rotated_keypoint = keypoint - 48.    # Subtract the middle value of the image dimension\n                for idx in range(0,len(rotated_keypoint),2):\n                    # https:\/\/in.mathworks.com\/matlabcentral\/answers\/93554-how-can-i-rotate-a-set-of-points-in-a-plane-by-a-certain-angle-about-an-arbitrary-point\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += 48.   # Add the earlier subtracted value\n                rotated_keypoints.append(rotated_keypoint)\n                \n            \n    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints, new_sizes\n\n\nrotated_train_images, rotated_train_keypoints, rotation_sizes = rotate_augmentation(tmp_x, tmp_y, tmp_sizes)\nprint(\"\\nShape of rotated_train_images: {}\".format(np.shape(rotated_train_images)))\nprint(\"Shape of rotated_train_keypoints: {}\\n\".format(np.shape(rotated_train_keypoints)))\ntrain_x = np.concatenate((train_x, rotated_train_images))\ntrain_y = np.concatenate((train_y, rotated_train_keypoints))\nsizes_train = np.concatenate((sizes_train, rotation_sizes))\nfig, axis = plt.subplots()\nplot_sample(rotated_train_images[sample_image_index], rotated_train_keypoints[sample_image_index], axis, \"Rotation Augmentation\")","656a5168":"print(train_x.shape)\nprint(train_y.shape)\nprint(sizes_train.shape)","aab1d29e":"def alter_brightness(images, keypoints):\n    altered_brightness_images = []\n    inc_brightness_images = np.clip(images*1.2, 0.0, 1.0)    # Increased brightness by a factor of 1.2 & clip any values outside the range of [-1,1]\n    dec_brightness_images = np.clip(images*0.6, 0.0, 1.0)    # Decreased brightness by a factor of 0.6 & clip any values outside the range of [-1,1]\n    altered_brightness_images.extend(inc_brightness_images)\n    altered_brightness_images.extend(dec_brightness_images)\n    return altered_brightness_images, np.concatenate((keypoints, keypoints))\n\n\naltered_brightness_train_images, altered_brightness_train_keypoints = alter_brightness(tmp_x, tmp_y)\nprint(f\"Shape of altered_brightness_train_images: {np.shape(altered_brightness_train_images)}\")\nprint(f\"Shape of altered_brightness_train_keypoints: {np.shape(altered_brightness_train_keypoints)}\")\ntrain_x = np.concatenate((train_x, altered_brightness_train_images))\ntrain_y = np.concatenate((train_y, altered_brightness_train_keypoints))\nsizes_train = np.concatenate((sizes_train, tmp_sizes))\nsizes_train = np.concatenate((sizes_train, tmp_sizes))\nfig, axis = plt.subplots()\nplot_sample(altered_brightness_train_images[sample_image_index], altered_brightness_train_keypoints[sample_image_index], axis, \"Increased Brightness\") \nfig, axis = plt.subplots()\nplot_sample(altered_brightness_train_images[len(altered_brightness_train_images)\/\/2+sample_image_index], altered_brightness_train_keypoints[len(altered_brightness_train_images)\/\/2+sample_image_index], axis, \"Decreased Brightness\") ","e78fa147":"print(train_x.shape)\nprint(train_y.shape)\nprint(sizes_train.shape)","2e640af1":"def shift_images(images, keypoints, sizes):\n    shifted_images = []\n    shifted_keypoints = []\n    new_sizes = []\n    for shift in pixel_shifts:    # Augmenting over several pixel shift values\n        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n            M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n            for image, keypoint, size in zip(images, keypoints, sizes):\n                shifted_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n                    shifted_images.append(shifted_image.reshape(96,96,1))\n                    shifted_keypoints.append(shifted_keypoint)\n                    new_sizes.append(size)\n    shifted_keypoints = np.clip(shifted_keypoints,0.0,96.0)\n    return shifted_images, shifted_keypoints, new_sizes\n\nshifted_train_images, shifted_train_keypoints, shifted_sizes = shift_images(tmp_x, tmp_y, tmp_sizes)\nprint(f\"Shape of shifted_train_images: {np.shape(shifted_train_images)}\")\nprint(f\"Shape of shifted_train_keypoints: {np.shape(shifted_train_keypoints)}\")\ntrain_x = np.concatenate((train_x, shifted_train_images))\ntrain_y = np.concatenate((train_y, shifted_train_keypoints))\nsizes_train = np.concatenate((sizes_train, shifted_sizes))\nfig, axis = plt.subplots()\nplot_sample(shifted_train_images[sample_image_index], shifted_train_keypoints[sample_image_index], axis, \"Shift Augmentation\")","01262b6e":"print(train_x.shape)\nprint(train_y.shape)\nprint(sizes_train.shape)","4045c990":"train_y_sh = convert_y_back(train_y, sizes_train)","1816d8f6":"model = build_model()\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'acc'])\n\n# Train the model\nhistory = model.fit(train_x, train_y, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE)","bd17f8ec":"image_size = 96\n#train_x, train_y, _ = read_images_gt(train_img_path, image_size, train_gt)\n\nstart = 0.1\nstop = 0.001\nn_epoch = 100\nlearning_rate = np.linspace(start, stop, n_epoch)\n\nmodel = build_model(image_size)\nsgd = SGD(lr=start, momentum=0.90, nesterov=True)\nmodel.compile(loss='mse', optimizer=sgd)\nchange_lr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\nearly_stop = EarlyStopping(patience=5)\nhistory = model.fit(train_x[:3000], train_y[:3000], epochs=n_epoch, callbacks=[change_lr, early_stop])","b9630884":"test_preds = model.predict(test_x)\n\n","9c0f5db2":"def plot_sample(image, keypoint, axis, title):\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker='x', s=20)\n    plt.title(title)\n","5d02046d":"i = 170\nfig, axis = plt.subplots()\nplot_sample(test_x[i], test_preds[i], axis, \"salan\")","be873bf2":"i = 171\nfig, axis = plt.subplots()\nplot_sample(test_x[i], test_preds[i], axis, \"salan\")","15c5ea4a":"test_sizes[6]","aedaee97":"pred_y[3]","b06e2dde":"pred_y = convert_y_back(test_preds, test_sizes)","fe0a65bd":"test_preds[170]","0150b6e6":"test_nonreal_y[170]","0915f70a":"i = 173\nn_rows,n_cols = test_sizes[i]\nnew_cords = convert_y_back(test_nonreal_y, test_sizes)\ncoords = new_cords[i]\ndiff = (coords - test_y[i])\ndiff[::2] \/= n_cols\ndiff[1::2] \/= n_rows\ndiff *= 100\nprint((diff ** 2).mean())","1e1cafc1":"def compute_metric(detected, values, img_shapes):\n        res = 0.0\n        for i in range(len(values)):\n            n_rows,n_cols = img_shapes[i]\n            coords = detected[i]\n            diff = (coords - values[i])\n            diff[::2] \/= n_cols\n            diff[1::2] \/= n_rows\n            diff *= 100\n            res += (diff ** 2).mean()\n        return res \/ len(values)","1ee2d98b":"print(compute_metric(pred_y, test_y, test_sizes))","496d4482":"test_sizes[3]","f7038cf1":"path = '..\/input\/00_test_img_input\/train\/images'\ngt = '..\/input\/00_test_img_input\/train\/gt.csv'","ba31908c":"import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nfrom os import listdir\nfrom os.path import join, dirname, abspath\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import MaxPooling2D, Conv2D\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n","28d6fd74":"\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nfrom os import listdir\nfrom os.path import join, dirname, abspath\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import MaxPooling2D, Conv2D\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\ndef build_model(image_size):\n    model = Sequential()\n    model.add(Conv2D(32, 3, input_shape=(image_size, image_size, 1)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(64, 2))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, 2))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.3))\n\n    model.add(Flatten())\n    model.add(Dense(1000))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1000))\n    model.add(Activation('relu'))\n    model.add(Dense(28))\n\n    return model\n\n\ndef train_detector(train_x, train_y, fast_train=False):\n    image_size = 96\n    #train_x, train_y, _ = read_images_gt(train_img_path, image_size, train_gt)\n\n    start = 0.1\n    stop = 0.001\n    n_epoch = 100\n    learning_rate = np.linspace(start, stop, n_epoch)\n\n    model = build_model(image_size)\n    sgd = SGD(lr=start, momentum=0.90, nesterov=True)\n    model.compile(loss='mse', optimizer=sgd)\n\n    if fast_train:\n        model.fit(train_x, train_y, batch_size=200, epochs=1, verbose=0)\n\n    else:\n        change_lr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n        early_stop = EarlyStopping(patience=5)\n        generator = ImageDataGenerator()\n        history = model.fit_generator(generator.flow(train_x, train_y), steps_per_epoch=800, epochs=n_epoch, validation_data=(train_x, train_y), callbacks=[change_lr, early_stop])\n        #model.save('facepoints_model.hdf5')\n        #plot_loss(history.history['loss'], history.history['val_loss'])\n\n    return model\n\n\ndef detect(model, test_x, sizes):\n    image_size = 96\n    #test_x, _, sizes = read_images_gt(test_img_path, image_size)\n\n    pred_y = model.predict(test_x)\n    #pred_y = convert_y_after_detect(pred_y, sizes)\n\n    return pred_y\n\n\ndef read_images_gt(img_path, size, gt_file=None):\n    file_name = listdir(img_path)\n    n = len(file_name)\n    x = np.empty((n, size, size))\n    sizes = np.empty((n, 2))\n    y = None\n    if gt_file is not None:\n        y = np.empty((len(gt_file), 28), dtype=int)\n    images = []\n    for i in range(n):\n        #print(file_name[i])\n        img = imread(join(img_path, file_name[i]))\n        if len(img.shape) == 3:\n            img = rgb2gray(img)\n        #images.append(img)\n        sizes[i, 0] = img.shape[0]\n        sizes[i, 1] = img.shape[1]\n        x[i] = resize(img, (size, size))\n        if gt_file is not None:\n            y[i] = gt_file.get(file_name[i])\n\n    x = normalize_x(x)\n    x = x.reshape((x.shape[0], size, size, 1))\n\n    if gt_file is not None:\n        new_y = convert_y_to_fit(y, sizes)\n\n    return x, new_y, sizes, y\n\ndef normalize_x(x):\n    average = np.mean(x, axis=0)\n    for i in range(x.shape[0]):\n        x[i] -= average\n\n    d1 = np.abs(x.max(axis=0))\n    d2 = np.abs(x.min(axis=0))\n    d = np.maximum(d1, d2)\n    for i in range(x.shape[0]):\n        x[i] = (x[i] + d) \/ (2 * d)\n\n    return x\n\n\ndef convert_y_to_fit(y, x_sizes):\n    y_new = np.empty(y.shape)\n    y[y < 0] = 0\n    for i in range(y_new.shape[0]):\n        y_new[i, :: 2] = y[i, :: 2] \/ x_sizes[i, 1]\n        y_new[i, 1:: 2] = y[i, 1:: 2] \/ x_sizes[i, 0]\n    y_new *= 2\n    y_new -= 1\n\n    return y_new\n\ndef convert_y_after_detect(y, x_sizes):\n    y_new = np.empty(y.shape)\n    y += 1\n    y \/= 2\n    for i in range(y_new.shape[0]):\n        y_new[i, :: 2] = y[i, :: 2] * x_sizes[i, 1]\n        y_new[i, 1:: 2] = y[i, 1:: 2] * x_sizes[i, 0]\n    y_new = y_new.astype(int)\n    return y_new\n\ndef plot_loss(loss, val_loss, file_name=join(dirname(abspath('\/home\/vsevolod\/\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b')), 'history.png')):\n    plt.plot(np.arange(len(loss)), np.array(loss), linewidth=3, label='train')\n    plt.plot(np.arange(len(val_loss)), np.array(val_loss), linewidth=3, label='valid')\n    plt.grid()\n    plt.legend()\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.yscale('log')\n    plt.savefig(file_name)\n\nclass ImageDataGenerator(ImageDataGenerator):\n    def next(self):\n        X_batch, y_batch = super(ImageDataGenerator, self).next()\n        size = 96\n        batch_size = X_batch.shape[0]\n        indices = np.random.choice(batch_size, batch_size \/ 2, replace=False)\n\n        for i in indices:\n            operation = np.random.choice(4, p=np.array((1\/8, 3\/8, 3\/8, 1\/8)))\n\n            if operation == 0:\n                X_batch[i] = X_batch[i, :, ::-1, :]\n                y_batch[i, ::2] = y_batch[i, ::2] * -1\n\n            if operation == 1:\n                angle = np.arange(5, 25, 5)[random.randint(0, 4)]\n                M = cv2.getRotationMatrix2D((size \/\/ 2, size \/\/ 2), angle, 1.0)\n                X_batch[i, :, :, 0] = cv2.warpAffine(X_batch[i, :, :, 0], M, (size, size))\n\n                tmp = y_batch[i]\n                tmp = (tmp + 1) \/ 2 * size\n                tmp = tmp.reshape((tmp.size \/\/ 2, 2))\n                ones = np.ones(shape=(tmp.shape[0], 1))\n                points_ones = np.hstack([tmp, ones])\n                tmp = M.dot(points_ones.T).T\n                tmp = tmp.reshape(tmp.size)\n                tmp = tmp \/ size * 2 - 1\n                tmp[tmp < -1] = -1\n                tmp[tmp > 1] = 1\n                y_batch[i] = tmp\n\n            if operation == 2:\n                angle = np.arange(5, 25, 5)[random.randint(0, 4)]\n                M = cv2.getRotationMatrix2D((size \/\/ 2, size \/\/ 2), -angle, 1.0)\n                X_batch[i, :, :, 0] = cv2.warpAffine(X_batch[i, :, :, 0], M, (size, size))\n\n                tmp = y_batch[i]\n                tmp = (tmp + 1) \/ 2 * size\n                tmp = tmp.reshape((tmp.size \/\/ 2, 2))\n                ones = np.ones(shape=(tmp.shape[0], 1))\n                points_ones = np.hstack([tmp, ones])\n                tmp = M.dot(points_ones.T).T\n                tmp = tmp.reshape(tmp.size)\n                tmp = tmp \/ size * 2 - 1\n                tmp[tmp < -1] = -1\n                tmp[tmp > 1] = 1\n                y_batch[i] = tmp\n\n            if operation == 3:\n                tmp = y_batch[i]\n                tmp = (tmp + 1) \/ 2 * size\n                tmp = tmp.reshape((tmp.size \/\/ 2, 2))\n                max_x = tmp[0].max()\n                max_y = tmp[1].max()\n                min_x = tmp[0].min()\n                min_y = tmp[1].min()\n                if max_x - min_x < size - 1 and max_y - min_y < size - 1:\n                    new_size = random.randint(max(max_x - min_x, max_y - min_y), size - 1)\n                    x = random.randint(max(0, max_x - new_size), min_x)\n                    y = random.randint(max(0, max_y - new_size), min_y)\n                    X_batch[i, :, :, 0] = resize(X_batch[i, y: y + new_size, x: x + new_size, 0], (size, size))\n                    tmp[0] -= x\n                    tmp[1] -= y\n                    tmp = tmp.reshape(tmp.size)\n                    tmp = tmp \/ new_size * 2 - 1\n                    y_batch[i] = tmp\n\n        return X_batch, y_batch","b449c855":"def train_detector(train_x, train_y, fast_train=False):\n    image_size = 96\n    #train_x, train_y, _ = read_images_gt(train_img_path, image_size, train_gt)\n\n    start = 0.1\n    stop = 0.001\n    n_epoch = 100\n    learning_rate = np.linspace(start, stop, n_epoch)\n\n    model = build_model(image_size)\n    sgd = SGD(lr=start, momentum=0.90, nesterov=True)\n    model.compile(loss='mse', optimizer=sgd)\n\n    if fast_train:\n        model.fit(train_x, train_y, batch_size=200, epochs=1, verbose=0)\n\n    else:\n        change_lr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n        early_stop = EarlyStopping(patience=5)\n        generator = ImageDataGenerator()\n        history = model.fit_generator(generator.flow(train_x, train_y), steps_per_epoch=500, epochs=n_epoch, validation_data=(train_x, train_y), callbacks=[change_lr, early_stop])\n        #model.save('facepoints_model.hdf5')\n        #plot_loss(history.history['loss'], history.history['val_loss'])\n\n    return model\n\n\ndef detect(model, test_x, sizes):\n    image_size = 96\n    #test_x, _, sizes = read_images_gt(test_img_path, image_size)\n\n    pred_y = model.predict(test_x)\n    #pred_y = convert_y_after_detect(pred_y, sizes)\n\n    return pred_y","1b191766":"def read_csv(filename):\n    res = {}\n    with open(filename) as fhandle:\n        next(fhandle)\n        for line in fhandle:\n            parts = line.rstrip('\\n').split(',')\n            coords = array([float(x) for x in parts[1:]], dtype='float64')\n            res[parts[0]] = coords\n    return res\nres = read_csv(gt)","3ee25465":"scale = 0.75\nx, y, sizes, real_y = read_images_gt(path, 96, res)","bc5624e5":"train_x = x[:int(len(x) * scale)]\ntrain_y = y[:int(len(y) * scale)]\nsizes_train = sizes[:int(len(sizes) * scale)]\nreal_train = real_y[:int(len(real_y) * scale)]\nprint(train_x.shape)\nprint(train_y.shape)\nprint(sizes_train.shape)\nprint(real_train.shape)","4340159b":"test_x = x[int(len(x) * scale):]\ntest_sizes = sizes[int(len(sizes) * scale):]\ntest_y = real_y[int(len(real_y) * scale):]\ntest_nonreal_y = y[int(len(y) * scale):]","f439f89c":"def convert_y_to_fit(y, x_sizes):\n    y_new = np.empty(y.shape)\n    y[y < 0] = 0\n    for i in range(y_new.shape[0]):\n        y_new[i, :: 2] = y[i, :: 2] \/ x_sizes[i, 1]\n        y_new[i, 1:: 2] = y[i, 1:: 2] \/ x_sizes[i, 0]\n    y_new *= 2\n    y_new -= 1\n\n    return y_new\n\ndef convert_y_after_detect(y, x_sizes):\n    y_new = np.empty(y.shape)\n    y += 1\n    y \/= 2\n    for i in range(y_new.shape[0]):\n        y_new[i, :: 2] = y[i, :: 2] * x_sizes[i, 1]\n        y_new[i, 1:: 2] = y[i, 1:: 2] * x_sizes[i, 0]\n    y_new = y_new.astype(int)\n    return y_new","fd3f8b69":"train_sh_fit = convert_y_to_fit(train_y_sh, sizes_train)","55e5a2ca":"train_sh_fit","8ec2eb6e":"model = train_detector(train_x, train_y)","d842a215":"pred_Y = detect(model, test_x, test_sizes)","acf55194":"last_preds = convert_y_after_detect(pred_Y, test_sizes)","ccb3dcfa":"def compute_metric(detected, values, img_shapes):\n    res = 0.0\n    for i in range(len(values)):\n        n_rows, n_cols = img_shapes[i]\n        coords = detected[i]\n        diff = (coords - values[i])\n        diff = diff.astype(float)\n        diff[::2] \/= n_cols\n        diff[1::2] \/= n_rows\n        diff *= 100\n        res += (diff ** 2).mean()\n    return res \/ len(values)","a58a1348":"compute_metric(last_preds, test_y, test_sizes)","2b164db4":"def alter_brightness(image, keypoints, alpha):\n    bright_image = np.clip(image*alpha, 0.0, 1.0)    # Increased brightness by a factor of 1.2 & clip any values outside the range of [-1,1]\n    return bright_image, keypoints","af531efa":"def shift_images(image, keypoints, shift_x, shift_y): \n    M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n    shifted_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n    shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n    if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n        return (shifted_image, shifted_keypoint)\n    return (None, None)\n\n","f04da5e4":"import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nfrom os import listdir\nfrom os.path import join, dirname, abspath\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import MaxPooling2D, Conv2D\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n","9ec86303":"\nimport time\nimport glob\nimport numpy as np\nimport skimage.io as skimio\nimport skimage.transform as skimtr\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential\nfrom keras.layers import (\n    Conv2D, MaxPooling2D, Flatten,\n    Dense, Dropout\n)\nfrom keras.optimizers import SGD\nfrom keras.callbacks import (\n    EarlyStopping, ModelCheckpoint\n)\n\n\nIMG_EDGE_SIZE = 100\nIMG_SHAPE = (IMG_EDGE_SIZE, IMG_EDGE_SIZE)\n\nGSCALE = True\nINPUT_SHAPE = (*IMG_SHAPE, 1 if GSCALE else 3)  # input layer shape\n\nY_BIAS = 50  # IMG_EDGE_SIZE \/ 2\nY_NORM = 10  # IMG_EDGE_SIZE \/ 2\nMIN_ROTATION_ANGLE = 5  # in degrees\nMAX_ROTATION_ANGLE = 15  # in degrees\n\n\ndef rotate_img(img, y, alphas):\n    # alpha = 2 * MAX_ROTATE_ANGLE * (np.random.rand() - 0.5)\n    alpha = np.random.choice(alphas)\n    alpha_rad = np.radians(alpha)\n    rot_mat = np.array([[np.cos(alpha_rad), -np.sin(alpha_rad)],\n                        [np.sin(alpha_rad), np.cos(alpha_rad)]])\n    bias = img.shape[0] \/ 2\n    return (\n        skimtr.rotate(img, alpha),\n        (y - bias).reshape(-1, 2).dot(rot_mat).ravel() + bias\n    )\n\n\ndef cut_img(img, y):\n    h = img.shape[0]\n    lt = int(np.ceil(min(np.random.randint(0.05 * h, 0.15 * h), y.min())))\n    rb = int(np.ceil(max(np.random.randint(0.85 * h, 0.95 * h), y.max())))\n    return img[lt: rb, lt: rb], y - lt\n\n\ndef flip_img(img, y):\n    y_ = y.copy()\n    y_[::2] = img.shape[1] - y_[::2] - 1\n    return (\n        img[:, ::-1],\n        y_.reshape(-1, 2)[\n            [3, 2, 1, 0, 9, 8, 7, 6, 5, 4, 10, 13, 12, 11]\n        ].ravel()\n    )\n\n\ndef load_data(img_dir, gt, input_shape, output_size=28, test=False, test_k = 1500):\n    print(\"STARTED LOADING DATA\")\n    _start = time.time()\n\n    N = len(gt) - test_k\n    rotations_num = 4\n    cut_num = 1\n    brightness_num = 4\n\n    start_flipped = N\n    start_rotation = start_flipped + N\n    start_cut = start_rotation + rotations_num * N\n    start_brightness = start_cut + cut_num * N\n    if not test:\n        N = 2 * N + rotations_num * N + cut_num * N + brightness_num * N # one N for flipped imgs\n    #if not test:\n        \n    X = np.empty((N, *input_shape))\n    y = np.empty((N, output_size)) if not test else None\n    scales = []\n    test_scales = []\n    X_test = np.empty((test_k, *input_shape))\n    y_test = np.empty((test_k, output_size)) if not test else None\n    test_fn = []\n    for i, (fn, y_raw) in enumerate(gt.items()):\n        if i >= 4500:\n            img = skimio.imread(img_dir + '\/' + fn, as_gray=GSCALE)\n            scale_y = 1.0 * img.shape[0] \/ input_shape[0]\n            scale_x = 1.0 * img.shape[1] \/ input_shape[1]\n            test_scales += [(scale_x, scale_y, fn)] \n            \n            X_test[i - 4500] = skimtr.resize(img, input_shape, mode='reflect')\n\n            if not test:\n                # Original image\n                y[i - 4500][::2] = y_raw[::2] \/ scale_x\n                y[i - 4500][1::2] = y_raw[1::2] \/ scale_y\n            continue\n            \n        img = skimio.imread(img_dir + '\/' + fn, as_gray=GSCALE)\n        #print(img)\n        #input1 = input()\n        scale_y = 1.0 * img.shape[0] \/ input_shape[0]\n        scale_x = 1.0 * img.shape[1] \/ input_shape[1]\n        scales += [(scale_x, scale_y, fn)]\n\n        X[i] = skimtr.resize(img, input_shape, mode='reflect')\n\n        if not test:\n            # Original image\n            y[i][::2] = y_raw[::2] \/ scale_x\n            y[i][1::2] = y_raw[1::2] \/ scale_y\n\n            # Flipped image\n            X[start_flipped + i], y[start_flipped + i] = flip_img(X[i], y[i])\n\n            # Rotated images\n            for r in range(rotations_num):\n                indx = start_rotation + rotations_num * i + r\n                if r == 0:\n                    alphas = list(\n                        range(-MAX_ROTATION_ANGLE, -MIN_ROTATION_ANGLE + 1))\n                else:\n                    alphas = list(\n                        range(MIN_ROTATION_ANGLE, MAX_ROTATION_ANGLE + 1))\n                X[indx], y[indx] = rotate_img(X[i], y[i], alphas)\n\n            # Cutted images\n            for c in range(cut_num):\n                indx = start_cut + cut_num * i + c\n                if y_raw.min() < 0:\n                    X[indx], y[indx] = X[i], y[i]\n                else:\n                    img_c, y_c = cut_img(img, y_raw)\n                    scale = 1.0 * img_c.shape[0] \/ input_shape[0]\n                    X[indx] = skimtr.resize(img_c, input_shape, mode='reflect')\n                    y[indx] = y_c \/ scale\n            random_range = [(1.1, 1.4), (0.5, 0.8), (1.1, 1.4), (0.5, 0.8)]\n            #brightness images\n            for c in range(brightness_num):\n                indx = start_brightness + brightness_num * i + c\n                random_range_c = random_range[c]\n                img_c, y_c = alter_brightness(X[i], y[i], random.uniform(random_range_c[0], random_range_c[1]))\n                X[indx] = img_c\n                y[indx] = y_c\n\n    if not test:\n        y = (y - Y_BIAS) \/ Y_NORM\n        \n    if not test:\n        y_test = (y_test - Y_BIAS) \/ Y_NORM\n\n    mean = np.mean(X, axis=0)\n    std = (np.mean(X ** 2, axis=0) - mean ** 2) ** 0.5\n    X = (X - mean) \/ std\n    \n    mean = np.mean(X_test, axis=0)\n    std = (np.mean(X_test ** 2, axis=0) - mean ** 2) ** 0.5\n    X_test = (X_test - mean) \/ std\n\n    print(\"FINISHED LOADING DATA:\", time.time() - _start)\n\n    return X, y, scales, X_test, y_test, test_scales\n\n\ndef build_model(image_size, output_size):\n    model = Sequential()\n    #Added\n    model.add(Conv2D(16, 3, input_shape=image_size))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.1))\n    \n    model.add(Conv2D(32, 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(64, 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.3))\n    \n    model.add(Flatten())\n    model.add(Dense(1000))\n    model.add(Activation('relu'))\n    model.add(Dense(1000))\n    model.add(Dropout(0.5))\n    model.add(Activation('relu'))\n    model.add(Dense(28))\n    \n    return model\n\n\ndef train_detector(X, y, fast_train=False):\n    input_shape = INPUT_SHAPE  # input layer shape\n    train_gt = res\n    output_size = len(list(train_gt.values())[0])\n    if fast_train:\n        keys = list(train_gt.keys())[:10]\n        train_gt = {key: train_gt[key] for key in keys}\n\n    #X, y, _ = load_data(train_img_dir, train_gt, input_shape, output_size)\n    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n\n    # Model config.\n    epochs = 1 if fast_train else 350\n    patience = 50  # stop if err has not been updated patience time\n    early_stop = EarlyStopping(patience=patience)\n\n    # SGD config.\n    sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n\n    # Model setup\n    model = build_model(input_shape, output_size)\n    model.compile(loss='mean_squared_error', optimizer=sgd)\n\n    checkpoint_callback = ModelCheckpoint(filepath='mod1el.hdf5',\n                                          monitor='val_loss',\n                                          save_best_only=True,\n                                          mode='auto')\n\n    # Model training\n    start_time = time.time()\n    print('start_time: {}'.format(time.strftime('%H:%M:%S')))\n    model.fit(\n        X_tr, y_tr,\n        epochs=epochs,\n        validation_data=(X_te, y_te),\n        callbacks=[early_stop, checkpoint_callback]\n    )\n    print('end_time: {}, duration(min): {}'.format(time.strftime('%H:%M:%S'),\n          (time.time()-start_time) \/ 60.))\n\n    return model\n\n\ndef detect(model, test_img_dir):\n    gt = {}\n    for fname in glob.glob1(test_img_dir, '*.jpg'):\n        gt[fname] = None\n\n    X, _, scales = load_data(test_img_dir, gt, INPUT_SHAPE, test=True)\n    y_pred = model.predict(X) * Y_NORM + Y_BIAS\n\n    y_scaled = {}\n    for i in range(len(scales)):\n        scale_x, scale_y, fn = scales[i]\n        y = y_pred[i]\n        y[::2] = y[::2] * scale_x\n        y[1::2] = y[1::2] * scale_y\n        y_scaled[fn] = y\n\n    return y_scaled","5e1c9356":"X, y, _, X_test, y_test, test_scales = load_data(path, res, INPUT_SHAPE, 28)","b59c2738":"X.shape","9937ac5c":"print('Done')","64f3c611":"for t in _:\n    if t[2] in test_scales[2]:\n        print('x')","962cc6d0":"def detect(model, X,scales):\n    gt = {}\n    for i in scales:\n        fname = i[2]\n        gt[fname] = None\n\n    #X, _, scales = load_data(test_img_dir, gt, INPUT_SHAPE, test=True)\n    y_pred = model.predict(X) * Y_NORM + Y_BIAS\n\n    y_scaled = {}\n    for i in range(len(scales)):\n        scale_x, scale_y, fn = scales[i]\n        y = y_pred[i]\n        y[::2] = y[::2] * scale_x\n        y[1::2] = y[1::2] * scale_y\n        y_scaled[fn] = y\n\n    return y_scaled","7493cc7c":"model = train_detector(X, y)","09e68d68":"train_gt = res","5704f4f1":"from tensorflow.keras.models import load_model\nmodel = load_model('mod1el.hdf5')","bf006a08":"\ntest_y = detect(model, X_test, test_scales)","83319205":"def compute_metric(detected, gt, img_shapes):\n    res = 0.0\n    for filename, coords in detected.items():\n        n_rows, n_cols = img_shapes[filename]\n        diff = (coords - gt[filename]) \n        diff[::2] \/= n_cols\n        diff[1::2] \/= n_rows\n        diff *= 100\n        res += (diff ** 2).mean()\n    return res \/ len(detected.keys())","a52abad8":"def read_img_shapes(gt_dir):\n        img_shapes = {}\n        with open(join(gt_dir, 'img_shapes.csv')) as fhandle:\n            next(fhandle)\n            for line in fhandle:\n                parts = line.rstrip('\\n').split(',')\n                filename = parts[0]\n                n_rows, n_cols = map(int, parts[1:])\n                img_shapes[filename] = (n_rows, n_cols)\n        return img_shapes","c8914d84":"img_shapes = read_img_shapes('..\/input\/00_test_img_gt')","caa02693":"compute_metric(test_y, res, img_shapes)","c0494561":"enumerate(res.items())","94637746":"import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nfrom os import listdir\nfrom os.path import join, dirname, abspath\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import MaxPooling2D, Conv2D\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nimport time\nimport glob\nimport numpy as np\nimport skimage.io as skimio\nimport skimage.transform as skimtr\nfrom sklearn.model_selection import train_test_split\nfrom numpy import array\n\nfrom keras.models import Sequential\nfrom keras.layers import (\n    Conv2D, MaxPooling2D, Flatten,\n    Dense, Dropout\n)\nfrom keras.optimizers import SGD\nfrom keras.callbacks import (\n    EarlyStopping, ModelCheckpoint\n)\n\nIMG_EDGE_SIZE = 100\nIMG_SHAPE = (IMG_EDGE_SIZE, IMG_EDGE_SIZE)\n\nGSCALE = True\nINPUT_SHAPE = (*IMG_SHAPE, 1 if GSCALE else 3)  # input layer shape\n\nY_BIAS = 50  # IMG_EDGE_SIZE \/ 2\nY_NORM = 10  # IMG_EDGE_SIZE \/ 2\nMIN_ROTATION_ANGLE = 5  # in degrees\nMAX_ROTATION_ANGLE = 15  # in degrees\n\n\ndef rotate_img(img, y, alphas):\n    # alpha = 2 * MAX_ROTATE_ANGLE * (np.random.rand() - 0.5)\n    alpha = np.random.choice(alphas)\n    alpha_rad = np.radians(alpha)\n    rot_mat = np.array([[np.cos(alpha_rad), -np.sin(alpha_rad)],\n                        [np.sin(alpha_rad), np.cos(alpha_rad)]])\n    bias = img.shape[0] \/ 2\n    return (\n        skimtr.rotate(img, alpha),\n        (y - bias).reshape(-1, 2).dot(rot_mat).ravel() + bias\n    )\n\n\ndef cut_img(img, y):\n    h = img.shape[0]\n    lt = int(np.ceil(min(np.random.randint(0.05 * h, 0.15 * h), y.min())))\n    rb = int(np.ceil(max(np.random.randint(0.85 * h, 0.95 * h), y.max())))\n    return img[lt: rb, lt: rb], y - lt\n\n\ndef flip_img(img, y):\n    y_ = y.copy()\n    y_[::2] = img.shape[1] - y_[::2] - 1\n    return (\n        img[:, ::-1],\n        y_.reshape(-1, 2)[\n            [3, 2, 1, 0, 9, 8, 7, 6, 5, 4, 10, 13, 12, 11]\n        ].ravel()\n    )\n\n\ndef alter_brightness(image, keypoints, alpha):\n    bright_image = np.clip(image*alpha, 0.0, 1.0) \n    return bright_image, keypoints\n\ndef shift_images(image, keypoints, shift_x, shift_y): \n    M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n    shifted_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n    shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n    if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n        return (shifted_image, shifted_keypoint)\n    return (None, None)\n\ndef load_data(img_dir, gt, input_shape, output_size=28, test=False):\n    N = len(gt)\n    rotations_num = 3\n    cut_num = 1\n    brightness_num = 3\n\n    start_flipped = N\n    start_rotation = start_flipped + N\n    start_cut = start_rotation + rotations_num * N\n    start_brightness = start_cut + cut_num * N\n    if not test:\n        N = 2 * N + rotations_num * N + cut_num * N + brightness_num * N \n\n        \n    X = np.empty((N, *input_shape))\n    y = np.empty((N, output_size)) if not test else None\n    scales = []\n    test_fn = []\n    for i, (fn, y_raw) in enumerate(gt.items()):\n        img = skimio.imread(img_dir + '\/' + fn, as_gray=GSCALE)\n        #print(img)\n        #input1 = input()\n        scale_y = 1.0 * img.shape[0] \/ input_shape[0]\n        scale_x = 1.0 * img.shape[1] \/ input_shape[1]\n        scales += [(scale_x, scale_y, fn)]\n\n        X[i] = skimtr.resize(img, input_shape, mode='reflect')\n\n        if not test:\n            # Original image\n            y[i][::2] = y_raw[::2] \/ scale_x\n            y[i][1::2] = y_raw[1::2] \/ scale_y\n\n            # Flipped image\n            X[start_flipped + i], y[start_flipped + i] = flip_img(X[i], y[i])\n\n            # Rotated images\n            for r in range(rotations_num):\n                indx = start_rotation + rotations_num * i + r\n                if r == 0:\n                    alphas = list(\n                        range(-MAX_ROTATION_ANGLE, -MIN_ROTATION_ANGLE + 1))\n                else:\n                    alphas = list(\n                        range(MIN_ROTATION_ANGLE, MAX_ROTATION_ANGLE + 1))\n                X[indx], y[indx] = rotate_img(X[i], y[i], alphas)\n\n            # Cutted images\n            for c in range(cut_num):\n                indx = start_cut + cut_num * i + c\n                if y_raw.min() < 0:\n                    X[indx], y[indx] = X[i], y[i]\n                else:\n                    img_c, y_c = cut_img(img, y_raw)\n                    scale = 1.0 * img_c.shape[0] \/ input_shape[0]\n                    X[indx] = skimtr.resize(img_c, input_shape, mode='reflect')\n                    y[indx] = y_c \/ scale\n            random_range = [(1.1, 1.4), (0.5, 0.8), (1.1, 1.4), (0.5, 0.8)]\n            #brightness images\n            for c in range(brightness_num):\n                indx = start_brightness + brightness_num * i + c\n                random_range_c = random_range[c]\n                img_c, y_c = alter_brightness(X[i], y[i], random.uniform(random_range_c[0], random_range_c[1]))\n                X[indx] = img_c\n                y[indx] = y_c\n\n    if not test:\n        y = (y - Y_BIAS) \/ Y_NORM\n        \n\n    mean = np.mean(X, axis=0)\n    std = (np.mean(X ** 2, axis=0) - mean ** 2) ** 0.5\n    X = (X - mean) \/ std\n\n    return X, y, scales\n\n\ndef build_model(image_size, output_size):\n    model = Sequential()\n    #Added\n    model.add(Conv2D(16, 3, input_shape=image_size))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.1))\n    \n    model.add(Conv2D(32, 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(64, 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.3))\n    \n    model.add(Flatten())\n    model.add(Dense(1000))\n    model.add(Activation('relu'))\n    model.add(Dense(1000))\n    model.add(Dropout(0.5))\n    model.add(Activation('relu'))\n    model.add(Dense(28))\n    \n    return model\n\n\ndef train_detector(train_gt, train_img_dir, fast_train=False):\n    input_shape = INPUT_SHAPE  # input layer shape\n    train_gt = res\n    output_size = len(list(train_gt.values())[0])\n    if fast_train:\n        keys = list(train_gt.keys())[:10]\n        train_gt = {key: train_gt[key] for key in keys}\n\n    X, y, _ = load_data(train_img_dir, train_gt, input_shape, output_size)\n    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n\n    # Model config.\n    epochs = 1 if fast_train else 350\n    patience = 50  # stop if err has not been updated patience time\n    early_stop = EarlyStopping(patience=patience)\n\n    # SGD config.\n    sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n\n    # Model setup\n    model = build_model(input_shape, output_size)\n    model.compile(loss='mean_squared_error', optimizer=sgd)\n\n    checkpoint_callback = ModelCheckpoint(filepath='facepoints_model.hdf5',\n                                          monitor='val_loss',\n                                          save_best_only=True,\n                                          mode='auto')\n\n    model.fit(\n        X_tr, y_tr,\n        epochs=epochs,\n        validation_data=(X_te, y_te),\n        callbacks=[early_stop, checkpoint_callback]\n    )\n\n    return model\n\n\ndef detect(model, test_img_dir):\n    gt = {}\n    for fname in glob.glob1(test_img_dir, '*.jpg'):\n        gt[fname] = None\n\n    X, _, scales = load_data(test_img_dir, gt, INPUT_SHAPE, test=True)\n    y_pred = model.predict(X) * Y_NORM + Y_BIAS\n\n    y_scaled = {}\n    for i in range(len(scales)):\n        scale_x, scale_y, fn = scales[i]\n        y = y_pred[i]\n        y[::2] = y[::2] * scale_x\n        y[1::2] = y[1::2] * scale_y\n        y_scaled[fn] = y\n\n    return y_scaled","08c07cee":"path = '..\/input\/00_test_img_input\/train\/images'\ngt = '..\/input\/00_test_img_input\/train\/gt.csv'\ndef read_csv(filename):\n    res = {}\n    with open(filename) as fhandle:\n        next(fhandle)\n        for line in fhandle:\n            parts = line.rstrip('\\n').split(',')\n            coords = array([float(x) for x in parts[1:]], dtype='float64')\n            res[parts[0]] = coords\n    return res\nres = read_csv(gt)","bd717d68":"train_detector(res, path)","3d9d975d":"test_path = '..\/input\/00_test_img_input\/test\/images'","4c865e70":"from tensorflow.keras.models import load_model\nmodel = load_model('facepoints_model.hdf5')","83eaeef3":"preds = detect(model, test_path)","74244cfa":"def compute_metric(detected, gt, img_shapes):\n    res = 0.0\n    for filename, coords in detected.items():\n        n_rows, n_cols = img_shapes[filename]\n        diff = (coords - gt[filename])\n        diff[::2] \/= n_cols\n        diff[1::2] \/= n_rows\n        diff *= 100\n        res += (diff**2).mean()\n    return res\/len(detected.keys())","4773548c":"compute_metric(preds, res, img_shapes)","b92bfdb6":"True test","2e9ba948":"For cv-gml","bc63b683":"\u0417\u0414\u0435\u0441\u044c \u043a\u043e\u043d\u0435\u0447\u043d\u044b\u0439 \u043f\u0440\u043e\u0434\u0443\u043a\u0442","cf2c7362":"\u0417\u0434\u0435\u0441\u044c \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0438 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f","d73fafca":"<a id ='ospanoff'>check ospanoff<\/a>","41587ec3":"Check shankina"}}