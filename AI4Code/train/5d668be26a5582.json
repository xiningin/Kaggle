{"cell_type":{"c38ea38e":"code","fbd1a985":"code","cc5e3b57":"code","a1d6c68c":"code","031c5af5":"code","e9ed2faa":"code","e0def146":"code","e168c707":"code","fb355521":"code","59f48b29":"code","dfe1fec9":"code","b13dea89":"code","f51c99a6":"code","d1b4fcbb":"code","41494fbf":"code","282cf1d0":"code","cf38a8e5":"code","c2395b65":"code","2ae76fd4":"code","ca93efba":"code","47c004c7":"code","cddb2ef3":"code","a514b742":"code","fda59356":"code","242cf8e4":"code","9b469733":"code","26b954ed":"code","5501cc85":"code","6093c283":"code","74c62016":"code","21f94398":"code","1d90bf73":"code","22d02212":"code","0ec48988":"code","a313b2fc":"code","90737c24":"code","471f1f33":"code","4e8ddce7":"code","88b4fb8f":"code","5fa1ba10":"code","c00e7fbd":"code","6deafb85":"code","51b1656f":"code","f6560300":"code","58623e05":"code","2ebf3396":"code","6d590550":"code","360f41a4":"code","25eeca7a":"code","ff6ec598":"code","604e8cc9":"code","70892550":"markdown","4b3ccbb7":"markdown","2167ccbf":"markdown","987d6e1d":"markdown","8bf1e062":"markdown","f3dddd20":"markdown","9f935bd1":"markdown","ab255c18":"markdown","84844e86":"markdown","36295273":"markdown","c46c028e":"markdown","661ffbad":"markdown","bbbc01d0":"markdown","8b3581cb":"markdown","25ca0926":"markdown","56d858f8":"markdown","004c2c6e":"markdown","dca58c24":"markdown","2a79b058":"markdown","75104558":"markdown","b9bbf2d6":"markdown","ed8384e0":"markdown","dddd2ba0":"markdown","26b90487":"markdown","dd9558b7":"markdown","632477d2":"markdown","57b626da":"markdown","4276d95a":"markdown","2c5bf81f":"markdown","85ebf550":"markdown","0510c9a8":"markdown"},"source":{"c38ea38e":"import zipfile as z\nzip_ref = z.ZipFile(\"..\/input\/restaurant-revenue-prediction\/train.csv.zip\", \"r\") #the source path is given\nzip_ref.extractall(\".\/\") #the destination part is given\n\nzip_ref.close()","fbd1a985":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n","cc5e3b57":"df=pd.read_csv(\".\/train.csv\")\ndf","a1d6c68c":"df.shape","031c5af5":"df.columns","e9ed2faa":"df.isna().sum()","e0def146":"df.info()","e168c707":"#The ID column is irrelevant so we will drop them.\ndf=df.drop('Id',axis=1)\ndf","fb355521":"df['Open Date'] = pd.to_datetime(df['Open Date'])\ndf","59f48b29":"df['month']=[x.month for x in df['Open Date']]","dfe1fec9":"df['year']=[x.year for x in df['Open Date']]","b13dea89":"df=df.drop(['Open Date'],axis=1)\ndf","f51c99a6":"plt.figure(figsize=(15,6))\nsns.countplot(df['month'])","d1b4fcbb":"df.groupby('month')['revenue'].mean()","41494fbf":"plt.figure(figsize=(15,6))\nsns.barplot('month','revenue',data=df)","282cf1d0":"plt.figure(figsize=(15,6))\nsns.countplot(df['year'])","cf38a8e5":"df.groupby('year')['revenue'].mean()","c2395b65":"plt.figure(figsize=(15,6))\nsns.barplot('year','revenue',data=df)","2ae76fd4":"df['Type'].value_counts()","ca93efba":"ty={'FC':0,'IL':1,'DT':2}\ndf['Type'] = df['Type'].map(ty)","47c004c7":"df","cddb2ef3":"df['City Group'].value_counts()","a514b742":"cg={'Big Cities':0,'Other':1}\ndf['City Group'] = df['City Group'].map(cg)\n","fda59356":"df","242cf8e4":"a=df['City'].value_counts()","9b469733":"b=a.index","26b954ed":"c={}\nfor i,j in enumerate(b):\n  c.update({j:i})\n  print(c)","5501cc85":"c","6093c283":"df['City'] = df['City'].map(c)\ndf","74c62016":"df.info()","21f94398":"from sklearn.model_selection import train_test_split\nx=df.drop('revenue',axis=1)\ny=df['revenue']\nX_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.30)","1d90bf73":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","22d02212":"from sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost import XGBRegressor","0ec48988":"lr = LinearRegression() #create the object of the model\nlr=lr.fit(X_train,y_train)","a313b2fc":"from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score","90737c24":"pred = lr.predict(X_test)\ns=mean_absolute_error(y_test,pred)\ns1=mean_squared_error(y_test,pred)\ns2=r2_score(y_test,pred)\n\nprint(\"The MAE with the linear regressor is: \"+str(s))\nprint(\"The MsE with the linear regressor is: \"+str(s1))\nprint(\"The R2_Score with the linear regressor is: \"+str(s2))","471f1f33":"dtr = DecisionTreeRegressor() #create the object of the model\ndtr=dtr.fit(X_train,y_train)","4e8ddce7":"pred = dtr.predict(X_test)\ns=mean_absolute_error(y_test,pred)\ns1=mean_squared_error(y_test,pred)\ns2=r2_score(y_test,pred)\n\nprint(\"The MAE with the DT regressor is: \"+str(s))\nprint(\"The MsE with the DT regressor is: \"+str(s1))\nprint(\"The R2_Score with the DT regressor is: \"+str(s2))","88b4fb8f":"r = RandomForestRegressor() #create the object of the model\nr=r.fit(X_train,y_train)","5fa1ba10":"pred = r.predict(X_test)\ns=mean_absolute_error(y_test,pred)\ns1=mean_squared_error(y_test,pred)\ns2=r2_score(y_test,pred)\n\nprint(\"The MAE with the RF regressor is: \"+str(s))\nprint(\"The MsE with the RF regressor is: \"+str(s1))\nprint(\"The R2_Score with the RF regressor is: \"+str(s2))","c00e7fbd":"knn=KNeighborsRegressor()\nknn=knn.fit(X_train,y_train)","6deafb85":"pred = knn.predict(X_test)\ns=mean_absolute_error(y_test,pred)\ns1=mean_squared_error(y_test,pred)\ns2=r2_score(y_test,pred)\n\nprint(\"The MAE with the KNN regressor is: \"+str(s))\nprint(\"The MsE with the KNN regressor is: \"+str(s1))\nprint(\"The R2_Score with the KNN regressor is: \"+str(s2))","51b1656f":"xgb=XGBRegressor()\nxgb=xgb.fit(X_train,y_train)","f6560300":"pred = xgb.predict(X_test)\ns=mean_absolute_error(y_test,pred)\ns1=mean_squared_error(y_test,pred)\ns2=r2_score(y_test,pred)\n\nprint(\"The MAE with the XGB regressor is: \"+str(s))\nprint(\"The MsE with the XGB regressor is: \"+str(s1))\nprint(\"The R2_Score with the XGB regressor is: \"+str(s2))","58623e05":"import zipfile as z\nzip_ref = z.ZipFile(\"..\/input\/restaurant-revenue-prediction\/test.csv.zip\", \"r\") #the source path is given\nzip_ref.extractall(\".\/\") #the destination part is given\n\nzip_ref.close()","2ebf3396":"test_df=pd.read_csv(\".\/test.csv\")\ntest_df.info()","6d590550":"test_df.fillna(0)\ntest_df['Open Date'] = pd.to_datetime(test_df['Open Date'])\ntest_df['month']=[x.month for x in test_df['Open Date']]\ntest_df['year']=[x.year for x in test_df['Open Date']]\ntest_df=test_df.drop(['Open Date'],axis=1)\n\nty1={'FC':0,'IL':1,'DT':2, 'MB':3}\ntest_df['Type'] = test_df['Type'].map(ty1)\ntest_df['City Group'] = test_df['City Group'].map(cg)\n\n\na=test_df['City'].value_counts()\nb = a.index\nc={}\nfor i,j in enumerate(b):\n  c.update({j:i})\ntest_df['City'] = test_df['City'].map(c)\n\ntest_df","360f41a4":"test_id = test_df['Id'].tolist()\ntest_df.drop('Id',axis=1, inplace=True)\ntest_df.info()","25eeca7a":"predictions = r.predict(test_df)","ff6ec598":"submission = pd.DataFrame(test_id,columns=['Id'])\nsubmission['Prediction'] = predictions\nsubmission.reset_index(drop=True,inplace=True)\nsubmission","604e8cc9":"submission.to_csv('.\/submission.csv', index=False)","70892550":"The first task will be to **split the dataset** into train set and test set.","4b3ccbb7":"# **Building the Model**","2167ccbf":"From the above plot we can look at the occurence of various months in the dataset. We have the most data for the last 5 months. The highest of them is from **August** and **December**. Now let's see in which month did we have the most revenue. For this let us to find the **mean of the revenue** for each month.","987d6e1d":"From here we see that **4 of the features are object type** which the model can not understand. So they need to be **encoded**. \n\nApart from that, Another observation is that we don't need to use the feature 'ID' as it's anyway **not going to give us any insight of the revenue**. So we will simply drop it.","8bf1e062":"This says that the dataset has 137 rows and 43 columns. Sumply meaning, there are 137 data points in the datatset and there are 43 features, one of them is target feature.\n","f3dddd20":"Now we will **drop 'Open Date'** as well, as we have extracted all the information from it and now its of no use to us.","9f935bd1":"# **Importing important libraries**","ab255c18":"There are 3 distinct values in the feature **'Type'**. We can encode the values as this:\n\n**FC as 0;**\n\n\n**IL as 1;**\n\n**DT as 2;**\n\nThe order or the numbers can be anything.","84844e86":"## K-Neighbors Regressor","36295273":"This says there are no Missing Values. ","c46c028e":"Here we are extracting the **month** from the feature **'Open Date'**.","661ffbad":"From here we can see that the most of the data is from the years **2008-2013**. Out of them the most of the data is from the year 2011. The other years are contruibuting really less on the basis of number of data. This is also going to affect the results as well.\n","bbbc01d0":"# **Data Analysis & Data Visualization**","8b3581cb":"From here we can see that the month **January gave the most revenue** to the restraunts. **September** and **October** followed January. Let's try to plot a bargraph with the same and visualize the same trends.","25ca0926":"## Linear Regression","56d858f8":"So these bargraphs are giving out the same information. Now lets try to do same kind of stuffs for the newly generated feature **'year'**.","004c2c6e":"From all the models, **RFregressor** gave the **minimum error**, So thats the best model and should be chosen as the final model.","dca58c24":"# **Data Preprocessing.**","2a79b058":"Out of all the years, the highest revenue was generated in the year **2000** and after that **1999** and **2005**.","75104558":"Now let's try to **visualize the trends** in month and year to understand how they affect the revenue.","b9bbf2d6":"# Testing","ed8384e0":"# **Unzipping the Dataset**","dddd2ba0":"Before moving ahead, let us import all the models from sklearn","26b90487":"Now everything looks just fine. So we can go ahead with the data and start model building.","dd9558b7":"Here manually creating the dictionary is inefficient. So we will store the city names in a list and then use the element as the **key** of the dictionary and the index of each element as its **key values**. ","632477d2":"Here we are extracting the **year** from the feature **'Open Date'**.","57b626da":"Let's check the dimension of train and test set.","4276d95a":"Now let us convert the 'Open Date' feature in **datetime format** so that we can extract the month and year from it. We want to do this because the date doesn't give us any insight of the revenue. But the **month and year surely does.**","2c5bf81f":"## Random Forest Regressor","85ebf550":"## Decision Tree Regressor","0510c9a8":"## XGB Regressor"}}