{"cell_type":{"cc9ea4b0":"code","581b07aa":"code","4cfadcc6":"code","1ffed9b2":"code","aa1acd6c":"code","38843313":"code","1a78e4f2":"code","3cd5467d":"code","f5075ced":"code","6b812fee":"code","2a518732":"code","42b33dc6":"code","e058790f":"code","ae4fab0f":"code","dda9879f":"code","4eeb5771":"code","0e1731fb":"code","9d138451":"code","f4ba3fbe":"code","8eb98c14":"code","a76c3ddc":"code","0483f755":"code","d9b7ab94":"code","7cb205ba":"code","a3049294":"code","d1ed3ff1":"code","415548c9":"code","1ea3961b":"code","0ef09f1b":"code","699526ea":"code","0db56013":"code","9cfa4dfa":"code","2bfcd9d8":"code","5e47137e":"code","9aeaaf3f":"code","b024a397":"code","b277dfe2":"code","b604d50b":"code","95411402":"code","c26c069f":"code","77d33716":"code","eb383002":"code","0024746c":"code","150e4e8f":"code","8dd0df6c":"code","b7fb0d43":"code","1ce9daad":"code","1668e057":"code","f2cf390b":"code","bd1620c7":"code","ef6d3a56":"code","fffc47cf":"code","dde7717c":"code","f0439688":"code","88619df6":"code","b914b333":"code","da2128bc":"code","8412ce82":"code","712bc2f6":"code","c8ad53c1":"markdown","7f2ee7d4":"markdown","484ea0f0":"markdown","e3d4f9cd":"markdown","0acf67c5":"markdown","e97fff74":"markdown"},"source":{"cc9ea4b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","581b07aa":"# Importando os dados\ntrain = pd.read_csv('\/kaggle\/input\/big-mart-sales-prediction-datasets\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/big-mart-sales-prediction-datasets\/test.csv')\ntest2 = test.copy()\ntrain.shape, test.shape","4cfadcc6":"# Verificando os tipos\ntrain.info()","1ffed9b2":"# Verificando valores \u00fanicos em cada coluna\ntrain.nunique()","aa1acd6c":"# Verificando os valores nulos\ntrain.isna().sum()","38843313":"test.isna().sum()","1a78e4f2":"#Imputando valores das notas a partir da m\u00e9dia\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\n\nimputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\nimputer.fit(test[['Item_Weight']])\ntest['Item_Weight'] = imputer.transform(test[['Item_Weight']]).ravel()","3cd5467d":"test.isna().sum()","f5075ced":"# Analisando a vari\u00e1vel target\ntrain['Item_Outlet_Sales'].describe()","6b812fee":"# Item_Fat_Content tem valores em excesso\ntrain['Item_Fat_Content'].unique()","2a518732":"# Criando um dicion\u00e1rio para mapear todos os registros em 'low' ou 'regular'\nitem_fat = {'Low Fat':'low', 'Regular':'regular', 'LF':'low', 'reg':'regular','low fat':'low'}\n\ntrain['Item_Fat_Content'] = train['Item_Fat_Content'].map(item_fat)\ntest['Item_Fat_Content'] = test['Item_Fat_Content'].map(item_fat)\n\n# Verificando\ntrain['Item_Fat_Content'].unique()","42b33dc6":"# Verificando Outlet_Size\ntrain['Outlet_Size'].unique()","e058790f":"# Verificando Outlet_Location_Type\ntrain['Outlet_Location_Type'].unique()","ae4fab0f":"# Verificando Outlet_Type\ntrain['Outlet_Type'].unique()","dda9879f":"# Verificando Item_Type\ntrain['Item_Type'].unique()","4eeb5771":"# Verificando Outlet_Identifier\ntrain['Outlet_Identifier'].unique()","0e1731fb":"# Quantos valores \u00fanicos de Item_Identifier\ntrain['Item_Identifier'].nunique()","9d138451":"# As colunas 'Item_Weight' e 'Outlet_Size' possuem valores nulos\n\n# Vamos usar a m\u00e9dia para imputar valores em Item_Weight\ntrain['Item_Weight'].fillna(train['Item_Weight'].mean(), inplace=True)\n\n# Vamos usar a moda para imputar valores em Outlet_Size\ntrain['Outlet_Size'].fillna(train['Outlet_Size'].mode()[0], inplace=True)","f4ba3fbe":"# Precisamos codificar as vari\u00e1veis categ\u00f3ricas\ntrain.dtypes","8eb98c14":"test.columns","a76c3ddc":"test.dtypes","0483f755":"# Vamos codificar as colunas categ\u00f3ricas usando one hot encoding\ncat_cols = ['Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n\ntrain = pd.get_dummies(train, columns=cat_cols)\ntest = pd.get_dummies(test, columns=cat_cols)\n\ntrain.shape","d9b7ab94":"from pandas.plotting import scatter_matrix\nlista_numerico = ['Item_Weight','Item_Visibility','Item_MRP','Item_Outlet_Sales']\nscatter_matrix(train[lista_numerico], figsize=(12,8))","7cb205ba":"# Verificando as colunas\ntrain.info()","a3049294":"# Separando o dataframe\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\ntrain, valid = train_test_split(train, random_state=42)\n\ntrain.shape, valid.shape","d1ed3ff1":"# Obtendo as colunas para treinamento\nfeatures = [c for c in train.columns if c not in ['Item_Identifier', 'Item_Outlet_Sales']]\n\nfeatures","415548c9":"#MODELO 1 - Random Forest Regressor\n\nfrom sklearn.ensemble import RandomForestRegressor\n'''\nrf_padrao = RandomForestRegressor(n_estimators=200, n_jobs=-1, random_state=42)\nrf_padrao.fit(train[features], train['Item_Outlet_Sales'])\n'''\n\nrf_padrao = RandomForestRegressor(random_state=42,n_jobs=-1)\n\nrf_param = {\n    'n_estimators': [100, 150, 200, 250],\n    'max_depth': [2, 5, 10],\n    'min_impurity_decrease': [0.01, 0.02, 0.0005]\n}\n\n# Instanciando o GridSearch\nrf_grid = GridSearchCV(rf_padrao, rf_param, cv=5, scoring='neg_mean_squared_error')\n\nrf_grid.fit(train[features], train['Item_Outlet_Sales'])\n\n","1ea3961b":"pd.DataFrame(rf_grid.cv_results_)","0ef09f1b":"# Imprime os par\u00e2metros que produziram o \".best_score_\".\nrf_grid.best_params_","699526ea":"# Imprimindo o best_score\nrf_grid.best_score_","0db56013":"# Obtendo os valores de predi\u00e7\u00e3o\nrf_top = rf_grid.best_estimator_\nrf_top.fit(train[features], train['Item_Outlet_Sales'])\npreds_rf = rf_top.predict(valid[features])\n#preds_rf = rf_padrao.predict(valid[features])","9cfa4dfa":"# Calculando a m\u00e9trica\nfrom sklearn.metrics import mean_squared_error\n\nrmse_rf = mean_squared_error(valid['Item_Outlet_Sales'], preds_rf, squared=False)\n\nrmse_rf","2bfcd9d8":"#Fazendo previs\u00e3o dos dados de teste\npreds_rf = rf_top.predict(test[features])\n\n#Exporta CSV para submiss\u00e3o\ndf_rf = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_rf['Item_Outlet_Sales'] = preds_rf\ndf_rf = df_rf.set_index('Item_Identifier')\ndf_rf.to_csv('predict_rf_grid.csv')\n\n#Your score for this submission is : 1216.9112751262633. (sem grid search)\n#Your score for this submission is : 1158.731421792914. (com grid search)","5e47137e":"#MODELO 2 GRADIENTE BOOSTING REGRESSOR\n\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n# Executando o modelo\ngbr_padrao = GradientBoostingRegressor(n_estimators=200, random_state=42)\n\ngbr_padrao.fit(train[features], train['Item_Outlet_Sales'])\n\n# Obtendo os valores de predi\u00e7\u00e3o\npreds_gbr = gbr_padrao.predict(valid[features])\n\n# Calculando a m\u00e9trica\nrmse_gbr = mean_squared_error(valid['Item_Outlet_Sales'], preds_gbr, squared=False)\n\nrmse_gbr","9aeaaf3f":"#Fazendo previs\u00e3o dos dados de teste\npreds_gbr = gbr_padrao.predict(test[features])\n\n#Exporta CSV para submiss\u00e3o\ndf_gbr = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_gbr['Item_Outlet_Sales'] = preds_gbr\ndf_gbr['Item_Outlet_Sales'] = df_gbr['Item_Outlet_Sales'].abs()\ndf_gbr = df_gbr.set_index('Item_Identifier')\ndf_gbr.to_csv('predict_gbr.csv')\n\n#Your score for this submission is : 1159.1857291211495.","b024a397":"#MODELO 3 - ADA BOOST\n\nfrom sklearn.ensemble import AdaBoostRegressor\n\n# Executando o modelo\nada_padrao = AdaBoostRegressor(n_estimators=200, random_state=42)\n\nada_padrao.fit(train[features], train['Item_Outlet_Sales'])\n\n# Obtendo os valores de predi\u00e7\u00e3o\npreds_ada = ada_padrao.predict(valid[features])\n\n# Calculando a m\u00e9trica\nrmse_ada = mean_squared_error(valid['Item_Outlet_Sales'], preds_ada, squared=False)\n\nrmse_ada","b277dfe2":"#Fazendo previs\u00e3o dos dados de teste\npreds_ada = ada_padrao.predict(test[features])\n\n#Exporta CSV para submiss\u00e3o\ndf_ada = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_ada['Item_Outlet_Sales'] = preds_ada\ndf_ada = df_ada.set_index('Item_Identifier')\ndf_ada.to_csv('predict_ada.csv')\n\n#Your score for this submission is : 1274.4715496142203.","b604d50b":"#MODELO 4 XGBOOST\n\nfrom xgboost import XGBRegressor\n\nxgb = XGBRegressor(n_estimators=200, learning_rate=0.01, random_state=42, use_label_encoder=True)\nxgb.fit(train[features], train['Item_Outlet_Sales'])\n\n# Obtendo os valores de predi\u00e7\u00e3o\npreds_xgb = xgb.predict(valid[features])\n\n# Calculando a m\u00e9trica\nrmse_xgb = mean_squared_error(valid['Item_Outlet_Sales'], preds_xgb, squared=False)\n\nrmse_xgb","95411402":"#Fazendo previs\u00e3o dos dados de teste\npreds_xgb = xgb.predict(test[features])\n\n#Exporta CSV para submiss\u00e3o\ndf_xgb = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_xgb['Item_Outlet_Sales'] = preds_xgb\ndf_xgb = df_xgb.set_index('Item_Identifier')\ndf_xgb.to_csv('predict_xgb.csv')\n\n#Your score for this submission is : 1210.7015987804687.","c26c069f":"#MODELO 5 CATBOOST\n\nfrom catboost import CatBoostRegressor\n\ncbc = CatBoostRegressor(random_state=42)\ncbc.fit(train[features], train['Item_Outlet_Sales'])\n\n# Obtendo os valores de predi\u00e7\u00e3o\npreds_cbc = cbc.predict(valid[features])\n\n# Calculando a m\u00e9trica\nrmse_cbc = mean_squared_error(valid['Item_Outlet_Sales'], preds_cbc, squared=False)\n\nrmse_cbc","77d33716":"#Fazendo previs\u00e3o dos dados de teste\npreds_cbc = cbc.predict(test[features])\n\n#Exporta CSV para submiss\u00e3o\ndf_cbc = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_cbc['Item_Outlet_Sales'] = preds_cbc\ndf_cbc['Item_Outlet_Sales'] = df_cbc['Item_Outlet_Sales'].abs()\ndf_cbc = df_cbc.set_index('Item_Identifier')\ndf_cbc.to_csv('predict_cbc.csv')\n\n#Your score for this submission is : 1178.8013859348143.","eb383002":"# Usaremos o VotingRegressor\nfrom sklearn.ensemble import VotingRegressor","0024746c":"# Definindo nossos estimadores\nestimators = [('rf_padrao', rf_padrao),('gbr_padrao',gbr_padrao),('ada_padrao', ada_padrao),('xgb',xgb),('cbc',cbc)]\n\n# Criando o VotingRegressor\nensemble1 = VotingRegressor(estimators=estimators, n_jobs=-1)\n\nensemble1.fit(train[features], train['Item_Outlet_Sales'])\n\n# Obtendo os valores de predi\u00e7\u00e3o\npreds_ens = ensemble1.predict(valid[features])\n\n# Calculando a m\u00e9trica\nrmse_ens = mean_squared_error(valid['Item_Outlet_Sales'], preds_ens, squared=False)\n\nrmse_ens","150e4e8f":"#Fazendo previs\u00e3o dos dados de teste\npreds_ens = ensemble1.predict(test[features])\n\n#Exporta CSV para submiss\u00e3o\ndf_ens = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_ens['Item_Outlet_Sales'] = preds_ens\ndf_ens = df_ens.set_index('Item_Identifier')\ndf_ens.to_csv('predict_ens.csv')\n\n#Your score for this submission is : 1165.5169672609384.","8dd0df6c":"train.info()","b7fb0d43":"!pip install pycaret==2.3.3","1ce9daad":"from pycaret.regression import *","1668e057":"setup1 = setup(data = train, \n               target = 'Item_Outlet_Sales',\n               ignore_features=['Item_Identifier'],\n               normalize = True,\n               silent = True)","f2cf390b":"models()","bd1620c7":"#top3 = compare_models(sort='MSE',n_select = 3)","ef6d3a56":"#Modelo Automl 2 - GBR Regressor\ngbr = create_model('gbr')\ntuned_gbr = tune_model(gbr, optimize = 'MSE')\nevaluate_model(tuned_gbr)","fffc47cf":"pred_gbr = predict_model(tuned_gbr, data = test)","dde7717c":"#Exporta CSV para submiss\u00e3o\ndf_gbr_automl = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_gbr_automl['Item_Outlet_Sales'] = pred_gbr['Label'].abs()\ndf_gbr_automl.to_csv('predict_gbr_automl.csv', index=False)\n#Your score for this submission is : 1188.967426151422.","f0439688":"#Modelo Automl 3 - Linear Regressor\n#* apesar do RF ser um dos top3, n\u00e3o rodou ou demorou demais para rodar.\nlr = create_model('lr')\ntuned_lr = tune_model(lr, optimize = 'MSE')\nevaluate_model(tuned_lr)","88619df6":"pred_lr = predict_model(tuned_lr, data = test)","b914b333":"#Exporta CSV para submiss\u00e3o\ndf_lr_automl = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_lr_automl['Item_Outlet_Sales'] = pred_lr['Label'].abs()\ndf_lr_automl.to_csv('predict_lr_automl.csv',index=False)\n#Your score for this submission is : 718068.0997139865.","da2128bc":"#Modelo Automl 1 - Huber Regressor\nhuber = create_model('huber')\ntuned_huber = tune_model(huber, optimize = 'MSE')\nevaluate_model(tuned_huber)","8412ce82":"pred_huber = predict_model(tuned_huber, data = test)","712bc2f6":"#Exporta CSV para submiss\u00e3o\ndf_huber_automl = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_huber_automl['Item_Outlet_Sales'] = pred_huber['Label'].abs()\ndf_huber_automl.to_csv('predict_huber_automl.csv', index=False)\n#Your score for this submission is : 1225.881995053679.","c8ad53c1":"## Tratamento de Dados","7f2ee7d4":"# Auto ML","484ea0f0":"# Criando nosso pr\u00f3prio Ensemble de M\u00e9todos","e3d4f9cd":"# IESB - CIA035 - Aula 07 - Ensemble de Modelos\n\n## Dados\nhttps:\/\/datahack.analyticsvidhya.com\/contest\/practice-problem-big-mart-sales-iii\/","0acf67c5":"Thu, Dec-02-2021, 04:53:55 AM\trf grid\t1158.73142179291\t---\t Download\t\nThu, Dec-02-2021, 03:42:21 AM\tlr automl\t718068.099713987\t---\t Download\t\nThu, Dec-02-2021, 03:39:31 AM\tlr automl\t718068.099713987\t---\t Download\t\nThu, Dec-02-2021, 03:34:41 AM\thuber automl\t1225.88199505368\t---\t Download\t\nThu, Dec-02-2021, 03:34:10 AM\tgbr automl\t1188.96742615142\t---\t Download\t\nSun, Oct-17-2021, 02:58:37 AM\tpredict cbc\t1178.80138593481\t---\t Download\t\nSun, Oct-17-2021, 02:57:34 AM\tpredict gbr\t1159.18572912115\t---\t Download\t\nSun, Oct-17-2021, 02:29:57 AM\tpredict ens\t1165.51696726094\t---\t Download\t\nSun, Oct-17-2021, 02:27:37 AM\tpredict xgb\t1210.70159878047\t---\t Download\t\nSun, Oct-17-2021, 02:25:31 AM\tpredict ada\t1274.47154961422\t---\t Download\t\nSun, Oct-17-2021, 02:17:39 AM\tpredict rf\t1216.91127512626\t---\t Download\t","e97fff74":"## Modelo inicial"}}