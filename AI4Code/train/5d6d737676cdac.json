{"cell_type":{"278357a7":"code","c8a823c8":"code","a1e99bae":"code","50e6dbd9":"code","0c677faf":"code","05f91123":"markdown","b60609a7":"markdown","dd993dee":"markdown","dd098398":"markdown"},"source":{"278357a7":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.metrics import precision_score, f1_score, recall_score, accuracy_score\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn import svm\n%matplotlib inline\nimport tensorflow as tf\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow import keras as kr\n\nprint(\"TF version \", tf.__version__)\n\nprint(os.listdir(\"..\/input\"))\n\ntrain_df = pd.read_csv(\"..\/input\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/test.csv\")\n\nY_train = train_df['target'] # keep labels\nX_train = train_df.iloc[:,2:train_df.shape[1]].values # dataframe to numpy array\nX_test = test_df.iloc[:,1:test_df.shape[1]].values # dataframe to numpy array\n\ng = sns.countplot(train_df['target']) # label count","c8a823c8":"mmscaler = MinMaxScaler()\nX_train = mmscaler.fit_transform(X_train)\nX_train.shape\n\n# pca = PCA(n_components=12)\n# X_train = pca.fit_transform(X_train)  \n# X_train.shape","a1e99bae":"kmodel = kr.models.Sequential()\nkmodel.add(kr.layers.Dense(32, input_dim=np.size(X_train,1), activation='relu'))\nkmodel.add(kr.layers.Dense(32, activation='relu'))\nkmodel.add(kr.layers.Dense(16, activation='relu'))\nkmodel.add(kr.layers.Dense(1, activation='sigmoid'))\n# model.summary()\n\nkmodel.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n\n\nBATCH_SIZE = 32\nEPOCHS = 50\nLOGS = 0\nVALIDATION_SPLIT = 0.1\n\nhistory = kmodel.fit(X_train,Y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT, verbose=LOGS, shuffle=True, class_weight=None, sample_weight=None) # train\n\"\"\" PLOT TRAIN HISTORY \"\"\"\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","50e6dbd9":"from sklearn.linear_model import LogisticRegression\n\nimport warnings\nfrom sklearn.exceptions import DataConversionWarning\nwarnings.filterwarnings(action='ignore', category=DataConversionWarning)\n\n\n# mmscaler = MinMaxScaler()\nX_test = mmscaler.fit_transform(X_test)\n\n\nmodel = LogisticRegression(C=.9, penalty='l1', solver='saga',max_iter = 100, warm_start=True)\n\n_ = model.fit(X_train,Y_train) \npredicted = model.predict(X_test)\n\n# seed = 8\n# np.random.seed(seed)\n# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n\n# # for name, model in models:\n# cvscores = []\n# i = 0\n# for train, test in kfold.split(X_train, Y_train):\n\n#     _ = model.fit(X_train[train],Y_train[train]) # train\n#     predicted = model.predict(X_train[test])\n#     i += 1\n#     cvscores.append(np.mean(predicted == Y_train[test]) * 100)\n#     #print('iter ',str(i))\n\n# print(\"%.2f%% (+\/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n\n","0c677faf":"predicted.shape\n\nout = pd.Series(predicted,name=\"target\")\n\nout = pd.concat([test_df['id'],out],axis = 1)\n#g = sns.countplot(out['target']) # label count\nout.to_csv('dont_overfit_it.csv',index=False, sep=',')","05f91123":"**Logistic Regression** with 10cf Validation","b60609a7":"**Keras Feed Forward NN**","dd993dee":"**Normalize Data**","dd098398":"Append Results to csv"}}