{"cell_type":{"45de52b1":"code","b0a2a1be":"code","96a58427":"code","0a3228e0":"code","7e64e752":"code","4471f767":"code","354ed2ba":"code","c97421e1":"code","920d2f34":"code","02112c98":"code","33c909d4":"code","1869a020":"code","237b709f":"code","3dabf761":"code","a2d72b11":"code","8a897ce8":"code","26c6ef44":"code","91dd0704":"code","9bcc4bdd":"code","7407ea09":"markdown","7a426d3f":"markdown","2ef27813":"markdown","799bb2f9":"markdown","b59a32c1":"markdown","aedff77a":"markdown","9d7e7f72":"markdown","1abd9692":"markdown","7332558d":"markdown","24a18bae":"markdown","d5f77fbc":"markdown","e58835e6":"markdown","6a476b3b":"markdown","2d0e9c5e":"markdown","5c639542":"markdown","234293d4":"markdown","1b9f60e9":"markdown","e3a5231d":"markdown","826238e5":"markdown","eaddb013":"markdown","10775eed":"markdown","fdddaef5":"markdown","58dbe991":"markdown","f39d3119":"markdown","a381acb0":"markdown","20e1331b":"markdown","3cecc2e3":"markdown","c5a98d47":"markdown","b16cae2e":"markdown","5294adb3":"markdown","ce9d893b":"markdown","4060c7db":"markdown","5961c27a":"markdown","01b7e4c2":"markdown","cd222f50":"markdown"},"source":{"45de52b1":"import os\nimport numpy as np\n\nimport pandas as pd\nfrom tqdm import tqdm\ntqdm.pandas()\n\nfrom nltk import word_tokenize, pos_tag\nfrom collections import Counter\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","b0a2a1be":"DATA_LEN = 1804874\nSAMPLE_SIZE = 100000","96a58427":"rows = np.arange(0, DATA_LEN)\nskip_rows = list(np.random.choice(rows[1:], DATA_LEN - SAMPLE_SIZE, replace=False))","0a3228e0":"data = pd.read_csv('..\/input\/train.csv', skiprows=skip_rows)","7e64e752":"pos_tags = data['comment_text'].progress_apply(lambda x: pos_tag(word_tokenize(x)))\ntargets = data['target']","4471f767":"print(pos_tags[0])","354ed2ba":"tags = []\nfor i, tag in enumerate(pos_tags):\n    pos_tags[i] = list(map(list, tag))\n    tags.append(np.array(pos_tags[i])[:, 1])\nflat_tags = np.concatenate([tag for tag in tags])","c97421e1":"counts = [dict(Counter(tag)) for tag in tags]","920d2f34":"def count_pos(tag_dict, tag_name):\n    if tag_name in tag_dict:\n        return tag_dict[tag_name]\n    else:\n        return 0","02112c98":"all_tags = set(flat_tags)\ndf = pd.DataFrame(np.zeros((SAMPLE_SIZE, 3)))\ndf.columns = ['count_dict', 'pos_feature', 'target']\ndf.count_dict = counts\ndf.target = targets","33c909d4":"all_tags","1869a020":"def visualize_count_feature(tag):\n    df.pos_feature = [count_pos(counts[i], tag) for i in range(SAMPLE_SIZE)]\n    df.pos_feature = df.pos_feature.mask(df.pos_feature == 0, np.nan) # Ignore sample when tag not present in sentence\n\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.distplot(ax=ax, a=[count for count in df.pos_feature.loc[df.target<0.5] if count==count], color='darkorange', label='non-toxic', hist=False)\n    sns.distplot(ax=ax, a=[count for count in df.pos_feature.loc[df.target>0.5] if count==count], color='navy', label='toxic', hist=False)\n    plt.title('\" ' + tag + ' \" ' + 'PoS tag count', fontsize=16, color='maroon')\n\n    plt.show()","237b709f":"visualize_count_feature('CC')","3dabf761":"visualize_count_feature('CD')","a2d72b11":"visualize_count_feature('DT')","8a897ce8":"visualize_count_feature('IN')","26c6ef44":"visualize_count_feature('POS')","91dd0704":"visualize_count_feature('VBD')\nvisualize_count_feature('VBG')\nvisualize_count_feature('VBZ')\nvisualize_count_feature('VBP')","9bcc4bdd":"visualize_count_feature('UH')","7407ea09":"## What is Part of Speech Tagging ?","7a426d3f":"### All tags present in the data","2ef27813":"<center><b><font size=4>PLEASE UPVOTE THIS KERNEL IF YOU LIKE IT<\/font><\/b><\/center>","799bb2f9":"### Convert 2D tuples in *pos_tags* to lists\nAs we can see above, the word-tag pairs are stored as tuples. We convert them to lists for easier manipulation with numpy","b59a32c1":"### Define size of train data and sample size","aedff77a":"### \"IN\" or Preposition Tag","9d7e7f72":"### Calculate count features from the PoS tags\nWe calculate features such as the number of times each tag occurs in each sentence","1abd9692":"### \"CC\" or Coordinating Conjunction Tag","7332558d":"Above we have the PoS tags for the first comment in the sample. Each word is given a tag based on whether they are verbs, pronouns, nouns etc.","24a18bae":"### \"VBD\", \"VBG\" and \"VBZ\" : Simple Past, Present-Participle and 3rd Person Verb Tag\n### *AND*\n### \"VBP\" : Simple Present Tag","d5f77fbc":"### \"POS\" or Possessive Ending Tag","e58835e6":"The orange and blue distributions are pretty much the same, except the fact that the orange one is more skewed to the left and has a lower mean (the orange peak on the left is higher than its blue counterpart). This means that interjections are generally used more in toxic comments. This is because people generally use interjections to express strong emotions (especially negative emotions like anger, hate etc) as in sh*t, f**k and other swear words as well, and strong negative emotions are generally more prevalent in toxic comments.","6a476b3b":"<center><img src=\"https:\/\/i.imgur.com\/CtyQ8Ag.png\" width=\"250px\"><\/center>","2d0e9c5e":"The orange distribution is similar to the blue one, but the orange distribution seems to have a greater rightward skew. This shows that non-toxic comments generally have more determiners than toxic ones. This again comes down to the fact that non-toxic comments generally have more complete language.","5c639542":"### Define function to visualize count features with KDE distribution plots","234293d4":"### That's it ! Thanks for reading my kernel. I hope you found it useful :)","1b9f60e9":"The orange distribution again has higher peaks than the blue distribution. Also, the orange distribution is more skewed to the right. This means that non-toxic comments generally have more numbers than toxic comments. This is probably brcause a person trying to share an idea or say something useful is more likely to use numbers (dates, math etc) than someone trying to insult some person, faith etc. ","e3a5231d":"## Preparing ground for analysis","826238e5":"### Create a pandas dataframe containing the PoS features dictionary and leave a dummy column for the tags.  ","eaddb013":"Part of Speech Tagging is the process of associating each word in a piece of text with a particular tag, which represents the type of word it is, i.e. proper noun, comparative adjective, interjection etc. For example, the word \"Michael\" is a singular proper noun, so its PoS tag would be NNP, which is the NLTK tag for singular proper noun. Another example is the word \"smartest\". It is a superlative adjective, so its PoS tag would be JJS, which is the NLTK tag for superlative adjective.\n\nHere are all the PoS tags supported by NLTK :\n\n* CC coordinating conjunction\n\n* CD cardinal digit\n\n* DT determiner\n\n* EX existential there (like: \u201cthere is\u201d \u2026 think of it like \u201cthere exists\u201d)\n\n* FW foreign word\n\n* IN preposition\/subordinating conjunction\n\n* JJ adjective \u2018big\u2019\n\n* JJR adjective, comparative \u2018bigger\u2019\n\n* JJS adjective, superlative \u2018biggest\u2019\n\n* LS list marker 1)\n\n* MD modal could, will\n\n* NN noun, singular \u2018desk\u2019\n\n* NNS noun plural \u2018desks\u2019\n\n* NNP proper noun, singular \u2018Harrison\u2019\n\n* NNPS proper noun, plural \u2018Americans\u2019\n\n* PDT predeterminer \u2018all the kids\u2019\n\n* POS possessive ending parent\u2019s\n\n* PRP personal pronoun I, he, she\n\n* PRP$ possessive pronoun my, his, hers\n\n* RB adverb very, silently,\n\n* RBR adverb, comparative better\n\n* RBS adverb, superlative best\n\n* RP particle give up\n\n* TO, to go \u2018to\u2019 the store.\n\n* UH interjection, errrrrrrrm\n    \n* VB verb, base form take\n\n* VBD verb, past tense took\n\n* VBG verb, gerund\/present participle taking\n\n* VBN verb, past participle taken\n\n* VBP verb, sing. present, non-3d take\n\n* VBZ verb, 3rd person sing. present takes\n\n* WDT wh-determiner which\n\n* WP wh-pronoun who, what\n\n* WP$ possessive wh-pronoun whose\n\n* WRB wh-abverb where, when\n\nNow since we know what PoS tagging is, let's apply it on all the comments in the train data (actually only a sample) and see if we can extract useful insights from these PoS features !","10775eed":"Since these are count features, the probability density is concentrated around integers. The peaks of the orange distribution at the integers are higher than those of the blue distribution. This is compensated by the lower valleys of the orange curve. This means that non-toxic comments generally have more CCs than toxic comments. This is probably because a coordinating conjunction is generally a part of speech used when you are trying to communicate an idea or a perspective, and not just a low-level personal attack or insult. Communicating ideas requires joining more phrases in more complex ways, requiring more conjunctions.","fdddaef5":"## PoS Count Features Analysis\n#### *Note : I have left out tags that don't provide useful insights*","58dbe991":"#### *Note : Non-toxic in orange and Toxic in blue*","f39d3119":"The orange distribution has much greater peaks than the blue one in the first three plots. This again shows that **verbs in any other form other than the simple present tense tend to be used a lot more in non-toxic comments**. I think this is because toxic comments are generally talking about how bad or wrong something or somenone is **right now** in the simple present, like \"ur a shi**y comment\". They do not talk much in the past or future. This is probably why the gap in peaks is much smaller in 4th plot than the first three plots.    ","a381acb0":"## Introduction\n### In this kernel, I will explore the comments in the dataset with Part of Speech (PoS) tagging and see how the distributions of PoS features differ between toxic and non-toxic comments.\n","20e1331b":"### \"UH\" Interjection Tag","3cecc2e3":"### Randomly select rows to skip during loading of the train data (we load only 100k comments and leave the remainder of the data)","c5a98d47":"### Load data while skipping pre-decided rows","b16cae2e":"The orange distribution seems to be more left-skewed than the blue distribution. It also looks like it has earlier peaks and a lower mean. This means that non-toxic comments generally have less possesive endings like \"parent's\", \"children's\" etc. I am not sure why this is the case. You're free to share your ideas in the comments below.","5294adb3":"### Import necessary libraries for data manipulation, tokenization and PoS Tagging","ce9d893b":"Again, the orange distribution is similar to the blue one, but the orange seems to have greater rightward skew. This shows that non-toxic comments generally have more determiners than toxic ones. This again comes down to the fact that non-toxic comments generally have more complete language. ","4060c7db":"### Tokenize all comments in the sample and generate PoS tags for them using NLTK. We use TQDM for the progress bar.","5961c27a":"### Define helper function to deal with the case of a tag not being there in a sentence and avoid a *KeyError*.","01b7e4c2":"### \"CD\" or Cardinal Digits Tag","cd222f50":"### \"DT\" or Determiner Tag"}}