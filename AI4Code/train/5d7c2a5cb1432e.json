{"cell_type":{"208b1fd4":"code","2ba3c3fd":"code","040aba8d":"code","81e0a956":"code","e348553a":"code","983d45bc":"code","dc4dd208":"code","5ee6483c":"code","406d59e2":"code","4f8e0b2e":"code","c41636e7":"code","3890c297":"code","0a24a273":"markdown","688a29e3":"markdown","be1a0eb0":"markdown","b09d1e8c":"markdown","9ecedbca":"markdown","33b2ff4f":"markdown","fa872cb2":"markdown","0cf30dca":"markdown","2958fdb1":"markdown","95201031":"markdown"},"source":{"208b1fd4":"!pip install spacy_cld","2ba3c3fd":"import numpy as np \nimport pandas as pd\nimport spacy\nfrom spacy_cld import LanguageDetector\n\n\nimport langdetect\nimport langid\n\nimport os\nprint(os.listdir(\"..\/input\"))","040aba8d":"devoxxfr = pd.read_csv('..\/input\/keyword-DevoxxFR.csv')\ndevoxxfr.head()","81e0a956":"tweets    = devoxxfr['tweets']","e348553a":"\"\"\"\nresult = str(result[0])[:2] : keeping the most dominant language wich is situated \nin the 1st index, and we store the first 2 characters\n\"\"\"\n\nlanguages_langdetect = []\n\n# the try except blook because there is some tweets contain links\nfor line in tweets:\n    try:\n        result = langdetect.detect_langs(line)\n        result = str(result[0])[:2]\n    except:\n        result = 'unknown'\n    \n    finally:\n        languages_langdetect.append(result)","983d45bc":"nlp = spacy.load('en')\nlanguage_detector = LanguageDetector()\nnlp.add_pipe(language_detector)","dc4dd208":"\"\"\"\ndoc._.languages returns : list of str\nlike : ['fr'] -> french\n       ['en'] -> english\n       [] -> empty\n       ['fr','en'] -> french (the most dominant in a tweet) and english (least dominant)\n\"\"\"\n\ntweets          = devoxxfr['tweets']\nlanguages_spacy = []\n\nfor e in tweets:\n    doc = nlp(e)\n    # cheking if the doc._.languages is not empty\n    # then appending the first detected language in a list\n    if(doc._.languages):\n        languages_spacy.append(doc._.languages[0])\n    # if it is empty, we append the list by unknown\n    else:\n        languages_spacy.append('unknown')","5ee6483c":"devoxxfr['languages_spacy'] = languages_spacy\ndevoxxfr['languages_langdetect'] = languages_langdetect","406d59e2":"devoxxfr.head()","4f8e0b2e":"devoxxfr['languages_spacy'].value_counts()","c41636e7":"devoxxfr['languages_langdetect'].value_counts()","3890c297":"devoxxfr.to_csv('devoxxfr-languages.csv',index=False)","0a24a273":"# <a id=\"e\">5. Conclusion<\/a>","688a29e3":"<li>spacy returns 1582 en tweets <\/li>\n<li>langdetect returns 1018 en tweets<\/li>","be1a0eb0":"# <a id=\"d\">4. Implementation with spacy <\/a>","b09d1e8c":"# <a id=\"a\">1. Needed libraries<\/a>","9ecedbca":"### adding a column in the dataframe containing the language of the tweet","33b2ff4f":"#### the code below is needed in the next sections :","fa872cb2":"<a href=\"#a\">1. Needed Libraries<\/a><br>\n<a href=\"#b\">2. Dataset<\/a><br>\n<a href=\"#c\">3. Implementation with langdetect<\/a><br>\n<a href=\"#d\">4. Implementation with spacy<\/a><br>\n<a href=\"#e\">5. Conclusion<\/a><br>","0cf30dca":"# <a id=\"b\">2. Dataset<\/a>","2958fdb1":"<li>our main goal is to keep english tweets collected from twitter about Devoxx France event<\/li>\n<li> the tweets in our dataset are expressed in many languages such as french, english... <\/li>","95201031":"# <a id=\"c\">3. Implementation with langdetect <\/a>"}}