{"cell_type":{"5543ea10":"code","d3d15844":"code","b67c1446":"code","348204c4":"code","ae9e2235":"code","3edf9ea5":"code","71bb6514":"code","879f5542":"code","383673d2":"code","b78f0571":"code","218a8aae":"code","dc582cb4":"code","ffb340b2":"code","19f568dd":"markdown","45754710":"markdown","7ed8e72e":"markdown","47f82cfa":"markdown","ce0a3ec8":"markdown","2caa2efd":"markdown","df320007":"markdown","daa221a5":"markdown","dbdb87a3":"markdown","6b081cd5":"markdown","15d67f35":"markdown","8fd86a87":"markdown","47e441c3":"markdown","783a8980":"markdown","df41066b":"markdown","0e027102":"markdown","64be93d3":"markdown","8b8f093c":"markdown","1ef3bbd5":"markdown","c5d16292":"markdown","17c6c8a2":"markdown","836b9c18":"markdown","ab03793b":"markdown","befe73f2":"markdown","42e4cb6c":"markdown"},"source":{"5543ea10":"#Importing the basic librarires\n\nimport os\nimport math\nimport scipy\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import randint\nfrom scipy.stats import loguniform\nfrom IPython.display import display\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [10,6]\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\n!pip install openpyxl","d3d15844":"#Importing the dataset\n\ndf = pd.read_excel('..\/input\/customer-segmentation-dataset\/Online Retail.xlsx')\n\noriginal_df = df.copy(deep=True)\ndisplay(df.head())\n\nprint('\\n\\033[1mInference:\\033[0m The Datset consists of {} features & {} samples.'.format(df.shape[1], df.shape[0]))","b67c1446":"#Creating MRF Table Strategy\n\ndf_s = df.sample(10000, random_state=42)\ndf_s[\"InvoiceDate\"] = df_s[\"InvoiceDate\"].dt.date\ndf_s[\"TotalSum\"] = df_s[\"Quantity\"] * df_s[\"UnitPrice\"]\nsnapshot_date = max(df_s.InvoiceDate) + datetime.timedelta(days=1)\ncustomers = df_s.groupby(['CustomerID']).agg({'InvoiceDate': lambda x: (snapshot_date - x.max()).days,\n                                            'InvoiceNo': 'count','TotalSum': 'sum'})\ncustomers.rename(columns = {'InvoiceDate': 'Recency','InvoiceNo': 'Frequency',\n                            'TotalSum': 'MonetaryValue'}, inplace=True)\n#customers = customers[customers.MonetaryValue>0]\ndisplay(customers.head())","348204c4":"#Checking the dtypes of all the columns\n\ncustomers.info()","ae9e2235":"#Checking the stats of all the columns\n\ndisplay(customers.describe())","3edf9ea5":"#Understanding the RFM Distribution\n\nprint('\\033[1mRMF Variables Distribution'.center(100))\n\nn=3\nnf = [i for i in customers.columns]\n\nplt.figure(figsize=[15,3*math.ceil(len(nf)\/n)])\nfor c in range(len(nf)):\n    plt.subplot(math.ceil(len(nf)\/n),n,c+1)\n    sns.distplot(customers[nf[c]])\nplt.tight_layout()\nplt.show()\n\n# plt.figure(figsize=[15,3*math.ceil(len(nf)\/n)])\n# for c in range(len(nf)):\n#     plt.subplot(math.ceil(len(nf)\/n),n,c+1)\n#     customers.boxplot(nf[c])\n# plt.tight_layout()\n# plt.show()","71bb6514":"# Testing Transformations\n\ncutomers_logT = customers.copy(deep=True)\ncutomers_sqrtT = customers.copy(deep=True)\ncutomers_cbrtT = customers.copy(deep=True)\ncutomers_bxcxT = customers.copy(deep=True)\n\nfor i in customers.columns:\n    cutomers_logT[i] = np.log(customers[i])\n    cutomers_sqrtT[i] = np.sqrt(customers[i])\n    cutomers_cbrtT[i] = np.cbrt(customers[i])\n    if i!='MonetaryValue':\n        cutomers_bxcxT[i] = stats.boxcox(customers[i])[0]\n\n# plt.figure(figsize=[15,3*math.ceil(len(nf)\/n)])\n# for c in range(len(nf)):\n#     plt.subplot(math.ceil(len(nf)\/n),n,c+1)\n#     sns.distplot(customers[nf[c]])\n#     plt.title('Original - {}'.format(nf[c]))\n# plt.tight_layout()\n# plt.show()\n\nplt.figure(figsize=[15,3*math.ceil(len(nf)\/n)])\nfor c in range(len(nf)):\n    plt.subplot(math.ceil(len(nf)\/n),n,c+1)\n    sns.distplot(cutomers_logT[nf[c]])\n    plt.title('Log Transformed - {}'.format(nf[c]))\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=[15,3*math.ceil(len(nf)\/n)])\nfor c in range(len(nf)):\n    plt.subplot(math.ceil(len(nf)\/n),n,c+1)\n    sns.distplot(cutomers_sqrtT[nf[c]])\n    plt.title('Sqrt Transformed - {}'.format(nf[c]))\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=[15,3*math.ceil(len(nf)\/n)])\nfor c in range(len(nf)-1):\n    plt.subplot(1,3,c+1)\n    sns.distplot(cutomers_bxcxT[nf[c]])\n    plt.title('BoxCox Transformed - {}'.format(nf[c]))\nplt.subplot(1,3,3)\nsns.distplot(cutomers_cbrtT[nf[2]])\nplt.title('Cube Root Transformed - {}'.format(nf[2]))\nplt.tight_layout()\nplt.show()","879f5542":"#Applying the selected Transformations\n\ncustomers_fix = pd.DataFrame()\ncustomers_fix[\"Recency\"] = stats.boxcox(customers['Recency'])[0]\ncustomers_fix[\"Frequency\"] = stats.boxcox(customers['Frequency'])[0]\ncustomers_fix[\"MonetaryValue\"] = pd.Series(np.cbrt(customers['MonetaryValue'])).values\ncustomers_fix.tail()","383673d2":"#Applying Standardization\n\nscaler = StandardScaler()\nscaler.fit(customers_fix)\ncustomers_normalized = scaler.transform(customers_fix)\n\nprint(customers_normalized.mean(axis = 0).round(2)) # [0. -0. 0.]\nprint(customers_normalized.std(axis = 0).round(2)) # [1. 1. 1.]","b78f0571":"# Building KMeans Algorithm on the dataset\n\nsse = {}\nfor k in range(1, 11):\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(customers_normalized)\n    sse[k] = kmeans.inertia_ # SSE to closest cluster centroid\n\n#Elbow Plot    \nplt.title('The Elbow Method')\nplt.xlabel('k')\nplt.ylabel('SSE')\nsns.pointplot(x=list(sse.keys()), y=list(sse.values()))\nplt.show()","218a8aae":"#Final Model\n\nmodel = KMeans(n_clusters=3, random_state=42)\nmodel.fit(customers_normalized)\n\ncustomers[\"Cluster\"] = model.labels_\ncustomers.groupby('Cluster').agg({\n    'Recency':'mean',\n    'Frequency':'mean',\n    'MonetaryValue':['mean', 'count']}).round(2)","dc582cb4":"# Visualising the Cluster Chartecteristics\n\ndf_normalized = pd.DataFrame(customers_normalized, columns=['Recency', 'Frequency', 'MonetaryValue'])\ndf_normalized['ID'] = customers.index\ndf_normalized['Cluster'] = model.labels_\n# Melt The Data\ndf_nor_melt = pd.melt(df_normalized.reset_index(),\n                      id_vars=['ID', 'Cluster'],\n                      value_vars=['Recency','Frequency','MonetaryValue'],\n                      var_name='Attribute',\n                      value_name='Value')\ndf_nor_melt.head()\n# Visualize it\nsns.lineplot('Attribute', 'Value', hue='Cluster', data=df_nor_melt)\nplt.show()","ffb340b2":"#<<<------------------------------------------------THE END--------------------------------------------------------->>>","19f568dd":"---","45754710":"## <center> 2. Exploratory Data Analysis (EDA)","7ed8e72e":"---","47f82cfa":"## <center> Stractegic Plan of Action:","ce0a3ec8":"**Insights:** By using this plot, we know how each segment differs. It describes more than we use the summarized table.\nWe infer that cluster 0 is frequent, spend more, and they buy the product recently. Therefore, it could be the cluster of a loyal customer.\nThen, the cluster 1 is less frequent, less to spend, but they buy the product recently. Therefore, it could be the cluster of new customer.\nFinally, the cluster 2 is less frequent, less to spend, and they buy the product at the old time. Therefore, it could be the cluster of churned customers.","2caa2efd":"---","df320007":"**Inference:** By overserving the plots, it is clear that Recency & Frequency shows more symmetrical form with box-cox transform. Since Monetart Value cannot be represented with Box-cox as it contains negative values, hence we shall use cube root transformation for it.","daa221a5":"### Here are some of the key outcomes of the project:\n- The Dataset was large enough summing around 5.4 lakh samples & we used a 10k subsamples for creation of the model. \n- For the segmentation we used RMF Technique to create working table as it is most common segmentation technique.\n- Visualising the distribution of data & their relationships, helped us to get some insights on the relationship between the feature-set.\n- Appropriate Transformations were applied on the data to satisfy the key assumptions. Followed by Standardization.\n- K Means algorithm was applied and appropriate cluster number was selected using Elbow Plot.\n- The results were interepreted by calculating the cluster means & it was visualised with help of snake plot.","dbdb87a3":"---","6b081cd5":"---","15d67f35":"---","8fd86a87":"## <center>1. Data Exploration","47e441c3":"---","783a8980":"## <center> 3. Data Preprocessing","df41066b":"**Inference:** The stats seem to be fine, let us gain more undestanding by visualising the dataset.","0e027102":"## <center>  Project Outcomes & Conclusions","64be93d3":"**Inference:** The data does not meet the assumptions where the variables are not squewed and have same mean & variance. Let us try to transform the data. Some of the common transorms are:\n* Log Transform\n* Sqrt Trasform\n* Box-Cox Transform","8b8f093c":"## <center> 5. Predictive Modeling","1ef3bbd5":"---","c5d16292":"# <center> \u2605 AI \/ ML Project - Customer Segmentation \u2605\n#### <center> ***Domain: Bussiness & Marketing***","17c6c8a2":"---","836b9c18":"**We aim to solve the problem statement by creating a plan of action, Here are some of the necessary steps:**\n1. Data Exploration\n2. Exploratory Data Analysis (EDA)\n3. Data Pre-processing\n4. Data Manipulation\n5. Predictive Modelling\n6. Project Outcomes & Conclusion","ab03793b":"### Description:\n\nA company that selling some of the product, and you want to know how well does the selling performance of the product.You have the data that can we analyze, but what kind of analysis that we can do?Well, we can segment customers based on their buying behavior on the market.\nKeep in mind that the data is really huge, and we can not analyze it using our bare eye. We will use machine learning algorithms and the power of computing for it.\n\nThis project will show you how to cluster customers on segments based on their behavior using the K-Means algorithm in Python.\nI hope that this project will help you on how to do customer segmentation step-by-step from preparing the data to cluster it.\n\n\n### Acknowledgements:\nThis dataset has been referred from UCI ML Repository:\nhttps:\/\/archive.ics.uci.edu\/ml\/datasets\/online+retail\n\n### Objective:\n- Understand the Dataset & cleanup (if required).\n- Build clustering model to segment the customer based similarity.\n- Also fine-tune the hyperparameters & compare the evaluation metrics of vaious classification algorithms.","befe73f2":"## <center> 4. Data Manipulation","42e4cb6c":"<center><img src=\"https:\/\/raw.githubusercontent.com\/Masterx-AI\/Project_Customer_Segmentation_\/main\/customer_segmentation.png\" style=\"width: 600px;\"\/>"}}