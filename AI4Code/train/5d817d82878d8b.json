{"cell_type":{"79fcac6a":"code","fb1e68e5":"code","4f6e95ee":"code","a4fe553f":"code","96ad5269":"code","5e374f2d":"code","91891131":"code","34f0ba16":"code","0456db77":"code","2521c38d":"code","c33bee74":"code","f2836db4":"code","17dc3d79":"code","82da8cf8":"code","994d74aa":"code","ee43f0bd":"code","7d6997e7":"code","651db200":"code","c3b4ba24":"code","3bce37e9":"code","9c4312f3":"code","c5a6afe8":"code","0392ac35":"code","9740d020":"code","951ebcd7":"code","0ecb8d4a":"code","1447e6d5":"code","86e04927":"code","f686b068":"code","7e104b7b":"code","eef53b6e":"code","49282697":"code","d1c67b75":"markdown","95b1ead8":"markdown","201dec5a":"markdown","49594a82":"markdown","e64dcde8":"markdown","2212dd6c":"markdown","08857b85":"markdown","180430a1":"markdown","d1073372":"markdown","f7400dcf":"markdown"},"source":{"79fcac6a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport glob # to find files\n\n# Seaborn library for bar chart\nimport seaborn as sns\n\n# Libraries for TensorFlow\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import models, layers\n\n# Library for Transfer Learning\nfrom tensorflow.keras.applications import VGG16\nfrom keras.applications.vgg16 import preprocess_input\n\nprint(\"Importing libraries completed.\")","fb1e68e5":"path = '..\/input\/chest-xray-pneumonia\/chest_xray\/'\n\n# train directory\ntrain_folder=path+\"train\/\"\ntrain_normal_dir=train_folder+\"NORMAL\/\"\ntrain_pneu_dir=train_folder+\"PNEUMONIA\/\"\n# test directory\ntest_folder=path+\"test\/\"\ntest_normal_dir=test_folder+\"NORMAL\/\"\ntest_pneu_dir=test_folder+\"PNEUMONIA\/\"\n# validation directory\nval_folder=path+\"val\/\"\nval_normal_dir=val_folder+\"NORMAL\/\"\nval_pneu_dir=val_folder+\"PNEUMONIA\/\"\n\n# variables for image size\nimg_width=196\nimg_height=196\n\n# variable for model\nbatch_size=64\nepochs=10\n\nprint(\"Variable declaration completed.\")\n","4f6e95ee":"# Train Dataset\ntrain_class_names=os.listdir(train_folder)\nprint(\"Train class names: %s\" % (train_class_names))\n# print(\"\\n\")\n\n# Test Dataset\ntest_class_names=os.listdir(test_folder)\nprint(\"Test class names: %s\" % (test_class_names))\n# print(\"\\n\")\n\n# Validation Dataset\nval_class_names=os.listdir(val_folder)\nprint(\"Validation class names: %s\" % (val_class_names))","a4fe553f":"# find all files, our files has extension jpeg\ntrain_normal_cases = glob.glob(train_normal_dir + '*jpeg')\ntrain_pneu_cases = glob.glob(train_pneu_dir + '*jpeg')\n\ntest_normal_cases = glob.glob(test_normal_dir + '*jpeg')\ntest_pneu_cases = glob.glob(test_pneu_dir + '*jpeg')\n\nval_normal_cases = glob.glob(val_normal_dir + '*jpeg')\nval_pneu_cases = glob.glob(val_pneu_dir + '*jpeg')\n\n# create lists for train, test & validation cases, create labels as well\ntrain_list = []\ntest_list = []\nval_list = []\n\nfor x in train_normal_cases:\n    train_list.append([x, \"Normal\"])\n    \nfor x in train_pneu_cases:\n    train_list.append([x, \"Pneumonia\"])\n    \nfor x in test_normal_cases:\n    test_list.append([x, \"Normal\"])\n    \nfor x in test_pneu_cases:\n    test_list.append([x, \"Pneumonia\"])\n    \nfor x in val_normal_cases:\n    val_list.append([x, \"Normal\"])\n    \nfor x in val_pneu_cases:\n    val_list.append([x, \"Pneumonia\"])\n\n# create dataframes\ntrain_df = pd.DataFrame(train_list, columns=['image', 'Diagnos'])\nprint(train_df.shape)\ntest_df = pd.DataFrame(test_list, columns=['image', 'Diagnos'])\nprint(test_df.shape)\nval_df = pd.DataFrame(val_list, columns=['image', 'Diagnos'])\nprint(val_df.shape)","96ad5269":"# plotting the Train, Test and Validation image data\n\nplt.figure(figsize=(20,5))\n\nplt.subplot(1,3,1)\nsns.countplot(train_df['Diagnos'])\nplt.title('Train data')\n\nplt.subplot(1,3,2)\nsns.countplot(test_df['Diagnos'])\nplt.title('Test data')\n\nplt.subplot(1,3,3)\nsns.countplot(val_df['Diagnos'])\nplt.title('Validation data')\n\nplt.show()\n","5e374f2d":"plt.figure(figsize=(20,8))\nfor i,img_path in enumerate(train_df[train_df['Diagnos'] == \"Pneumonia\"][0:4]['image']):\n    plt.subplot(2,4,i+1)\n    plt.axis('off')\n    img = plt.imread(img_path)\n    plt.imshow(img, cmap='gray')\n    plt.title('Pneumonia')\n    \nfor i,img_path in enumerate(train_df[train_df['Diagnos'] == \"Normal\"][0:4]['image']):\n    plt.subplot(2,4,4+i+1)\n    plt.axis('off')\n    img = plt.imread(img_path)\n    plt.imshow(img, cmap='gray')\n    plt.title('Normal')","91891131":"# Declaring variables\nx=[] # to store array value of the images\ny=[] # to store the labels of the images\n\nfor folder in os.listdir(train_folder):\n    image_list=os.listdir(train_folder+\"\/\"+folder)\n    for img_name in image_list:\n        # Loading images\n        img=image.load_img(train_folder+\"\/\"+folder+\"\/\"+img_name,target_size=(img_width,img_height))\n        \n        # Converting to arrary\n        img=image.img_to_array(img)\n        \n        # Transfer Learning: this is to apply preprocess of VGG16 model to our images before passing it to VGG16\n        img=preprocess_input(img) #  Optional step\n        \n        # Appending the arrarys\n        x.append(img) # appending image array\n        y.append(train_class_names.index(folder)) # appending class index to the array\n        \nprint(\"Preparing Training Dataset Completed.\")","34f0ba16":"# Preparing validation images data (image array and class name) for processing\n\n# Declaring variables\nval_images=[]\nval_images_Original=[]\nval_image_label=[] # to store the labels of the images\n\nfor folder in os.listdir(val_folder):\n    image_list=os.listdir(val_folder+\"\/\"+folder)\n    for img_name in image_list:\n        # Loading images\n        img=image.load_img(val_folder+\"\/\"+folder+\"\/\"+img_name,target_size=(img_width,img_height))\n        \n        # Converting to arrarys\n        img=image.img_to_array(img)\n        \n        # Saving original images, will be used just for display at the end\n        val_images_Original.append(img.copy())\n        \n        # Transfer Learning: this is to apply preprocess of VGG16 to our images before passing it to VGG16\n        img=preprocess_input(img) #  Optional step\n        \n        # Appending arrays\n        val_images.append(img) # appending image array\n        val_image_label.append(val_class_names.index(folder))\n        \nprint(\"Preparing Validation Dataset Completed.\")","0456db77":"# Declaring variables\ntest_images=[]\ntest_images_Original=[]\ntest_image_label=[] # to store the labels of the images\n\nfor folder in os.listdir(test_folder):\n    image_list=os.listdir(test_folder+\"\/\"+folder)\n    for img_name in image_list:\n        # Loading images\n        img=image.load_img(test_folder+\"\/\"+folder+\"\/\"+img_name,target_size=(img_width,img_height))\n        \n        # Converting to arrarys\n        img=image.img_to_array(img)\n        \n        # Saving original images, will be used just for display at the end\n        test_images_Original.append(img.copy())\n        \n        # Transfer Learning: this is to apply preprocess of VGG16 to our images before passing it to VGG16\n        img=preprocess_input(img) #  Optional step\n        \n        # Appending arrays\n        test_images.append(img) # appending image array\n        test_image_label.append(test_class_names.index(folder))\n        \nprint(\"Preparing Test Dataset Completed.\")\n","2521c38d":"# Training Dataset\nprint(\"Training Dataset:\")\n\nx=np.array(x) # Converting to np arrary to pass to the model\nprint(x.shape)\n\ny=to_categorical(y) # onehot encoding of the labels\n# print(y)\nprint(y.shape)\n\n# ===========\n\n# Test Dataset\nprint(\"Test Dataset:\")\n\ntest_images=np.array(test_images) \nprint(test_images.shape)\n\ntest_image_label=to_categorical(test_image_label) # onehot encoding of the labels)\nprint(test_image_label.shape)\n\n# ===========\n\n# Validation Dataset\nprint(\"Validation Dataset:\")\n\nval_images=np.array(val_images) \nprint(val_images.shape)\n\nval_image_label=to_categorical(val_image_label) # onehot encoding of the labels)\nprint(val_image_label.shape)","c33bee74":"from tensorflow.keras.applications import VGG16\n\n# initializing model with weights='imagenet'i.e. we are carring its original weights\nmodel_vgg16=VGG16(weights='imagenet')\nmodel_vgg16.summary()","f2836db4":"input_layer=layers.Input(shape=(img_width,img_height,3))\nmodel_vgg16=VGG16(weights='imagenet',input_tensor=input_layer,include_top=False)\nmodel_vgg16.summary()","17dc3d79":"last_layer=model_vgg16.output # we are taking last layer of the model\n\n# Add flatten layer: we are extending Neural Network by adding flattn layer\nflatten=layers.Flatten()(last_layer) \n\n# Add dense layer to the final output layer\noutput_layer=layers.Dense(2,activation='softmax')(flatten)\n\n# Creating modle with input and output layer\nmodel=models.Model(inputs=input_layer,outputs=output_layer)\n\n# Summarize the model\nmodel.summary()","82da8cf8":"print(\"We are making all the layers intrainable except the last layer. \\n\")\nfor layer in model.layers[:-1]:\n    layer.trainable=False","994d74aa":"from sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=5)","ee43f0bd":"model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n\nprint(\"Model compilation completed.\")","7d6997e7":"history=model.fit(xtrain,ytrain,epochs=10,batch_size=batch_size,verbose=True,validation_data=(xtest,ytest))","651db200":"model.save(\"pnuemonia1.h5\")","c3b4ba24":"accuracy = history.history['accuracy']\nval_accuracy  = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']","3bce37e9":"plt.figure(figsize=(15,10))\n\nplt.subplot(2, 2, 1)\nplt.plot(accuracy, label = \"Training accuracy\")\nplt.plot(val_accuracy, label=\"Validation accuracy\")\nplt.ylim(0.8, 1)\nplt.legend()\nplt.title(\"Training vs validation accuracy\")\n\n\nplt.subplot(2,2,2)\nplt.plot(loss, label = \"Training loss\")\nplt.plot(val_loss, label=\"Validation loss\")\nplt.ylim(0, 0.5)\nplt.legend()\nplt.title(\"Training vs validation loss\")\n\nplt.show()\n","9c4312f3":"def Get_Xray_Type(argument):\n    switcher = {\n        \"NORMAL\": \"Normal\",\n        \"PNEUMONIA\": \"Pneumonia\",\n    }\n    return switcher.get(argument, \"Invalid X-ray\")\ndef predict(img_name):\n    img=image.load_img(img_name,target_size=(img_width,img_height))\n    img=image.img_to_array(img)\n    plt.imshow(img.astype('int32'))\n    plt.show()\n    img=preprocess_input(img)\n#     plt.imshow(img.astype('int32'))\n#     plt.show()\n    prediction=model.predict(img.reshape(1,img_width,img_height,3))\n    output=np.argmax(prediction)\n    print(train_class_names[output] + \": \" + Get_Xray_Type(train_class_names[output]))\n\n","c5a6afe8":"predict('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/person1000_bacteria_2931.jpeg')","0392ac35":"predict('..\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL\/NORMAL2-IM-1436-0001.jpeg')","9740d020":"predict('..\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA\/person1949_bacteria_4880.jpeg')","951ebcd7":"val_predictions=[]\n\nfor img in val_images:\n    prediction=model.predict(img.reshape(1,img_width,img_height,3))\n    output=np.argmax(prediction)\n    val_predictions.append(output)","0ecb8d4a":"val_predictions","1447e6d5":"val_image_labels=[]\nfor i in val_image_label:\n    val_image_labels.append(int(i[1]))\nval_image_labels    ","86e04927":"import seaborn as sn\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(val_image_labels, val_predictions)\nsn.heatmap(cm, annot=True,cmap=\"Blues\", annot_kws={\"size\": 16})","f686b068":"val_predictions=[]\n\nfor img in x:\n    prediction=model.predict(img.reshape(1,img_width,img_height,3))\n    output=np.argmax(prediction)\n    val_predictions.append(output)","7e104b7b":"val_image_labels=[]\nfor i in y:\n    val_image_labels.append(int(i[1]))","eef53b6e":"import seaborn as sn\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(val_image_labels, val_predictions)\nsn.heatmap(cm, annot=True,cmap=\"Blues\", annot_kws={\"size\": 16})","49282697":"from sklearn.metrics import classification_report\nprint(classification_report(val_image_labels, val_predictions))","d1c67b75":"# Preparing training image data","95b1ead8":"# Fitting the model","201dec5a":"# Verfying the data","49594a82":"# Train the model","e64dcde8":"# Plotting raw images","2212dd6c":"# prepare data for visualization","08857b85":"# Building a model","180430a1":"# Importing Libraries","d1073372":"# Visualization","f7400dcf":"# Declaring Variables"}}