{"cell_type":{"fb35521d":"code","88dedb5e":"code","a515ddd4":"code","926c3fb8":"code","6638bb3d":"code","6447f0ca":"code","ee5bf064":"code","16668366":"markdown","5cc31f4b":"markdown","8d4110c6":"markdown"},"source":{"fb35521d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","88dedb5e":"dfS08_question= pd.read_csv('..\/input\/S08_question_answer_pairs.txt',  sep=\"\\t\")","a515ddd4":"dfS08_question= pd.read_csv('..\/input\/S08_question_answer_pairs.txt',  sep=\"\\t\")\ndfS08_question.drop(labels=['ArticleTitle', 'DifficultyFromQuestioner', 'DifficultyFromAnswerer', 'ArticleFile', 'Answer'], axis=1, inplace=True)\ndfS08_question.head()","926c3fb8":"import nltk\nimport numpy as np\nfrom nltk.tokenize import sent_tokenize\n\ndfS08_question.to_csv(\".\/csvfile.txt\", sep=\";\", index=False, header=False)\nprint(os.listdir(\".\"))\n\nrawText = np.genfromtxt(\".\/csvfile.txt\", dtype='str', delimiter=';', usecols=np.arange(0,1))\ncsvFile.shape\n","6638bb3d":"from nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nimport string\nfrom nltk.corpus import wordnet\n\nstopwords_list = stopwords.words('english')\n\nlemmatizer = WordNetLemmatizer()\n\ndef my_tokenizer(doc):\n    words = word_tokenize(doc)\n    \n    pos_tags = pos_tag(words)\n    \n    non_stopwords = [w for w in pos_tags if not w[0].lower() in stopwords_list]\n    \n    non_punctuation = [w for w in non_stopwords if not w[0] in string.punctuation]\n    \n    lemmas = []\n    for w in non_punctuation:\n        if w[1].startswith('J'):\n            pos = wordnet.ADJ\n        elif w[1].startswith('V'):\n            pos = wordnet.VERB\n        elif w[1].startswith('N'):\n            pos = wordnet.NOUN\n        elif w[1].startswith('R'):\n            pos = wordnet.ADV\n        else:\n            pos = wordnet.NOUN\n        \n        lemmas.append(lemmatizer.lemmatize(w[0], pos))\n\n    return lemmas\n    \n    ","6447f0ca":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer(tokenizer=my_tokenizer)\n\ntfs = tfidf_vectorizer.fit_transform(rawText)\n\nprint(tfs.shape)","ee5bf064":"from sklearn.metrics.pairwise import cosine_similarity\nwhile True:\n    answer = input(\"Digite sua pesquisa\")\n    if answer == 'Sair':\n        break\n    elif answer !='Sair':\n        query_vect = tfidf_vectorizer.transform([answer])\n        positions = cosine_similarity(query_vect, tfs)[0]\n        print('O texto mais proximo localizado foi: ', rawText[np.argmax(positions)])\n        ","16668366":"**Aqui come\u00e7a o chatbot, quando se esta em modo de edi\u00e7\u00e3o do kaggle \u00e9 possivel entrar com as perguntas e receber a frase mais similar como resposta.**","5cc31f4b":"**Convertendo o Dataframe para txt para depois importar como array de texto ja dentro do Numpy**","8d4110c6":"**Excluindo as colunas que nao contem as perguntas**"}}