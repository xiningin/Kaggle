{"cell_type":{"b62a54bb":"code","4b99206b":"code","a02a6fb4":"code","bc2cc351":"code","d3d31c0a":"code","da009951":"code","58ed5726":"code","601cf95a":"code","022dbefa":"code","d012c9ca":"code","7b885768":"code","d4afcdca":"code","fa68fbfa":"code","953b21ba":"code","283f89e2":"code","976eadad":"code","2798e0ad":"code","0147fce5":"code","cd9c4e6f":"code","2edb8410":"code","48357aff":"code","09130979":"code","c257be74":"code","6fe4bd2c":"code","0b78a2e5":"code","9bd52cb2":"code","522f9d88":"code","ec6fe2e1":"code","f9e806a4":"code","f625526d":"code","15a7f172":"code","4f366d12":"code","de5e0c25":"code","1544c988":"code","d14b9542":"code","0b497638":"code","3c0f9cbd":"code","03b170b0":"code","db95149b":"code","72d36e5b":"code","619aa1cc":"code","85de76d4":"code","7999bf84":"code","ec5a9cb0":"code","15b18c00":"code","ab38ca41":"code","becfb9a0":"code","29b3bb8d":"code","8264f952":"code","18b20a76":"code","d48f2d51":"code","2e256688":"code","f7ad24bb":"code","f812842a":"code","7a9566e3":"code","c1b71a22":"code","7dc93fca":"code","6f1694be":"code","e2887cf1":"code","352dd468":"code","9c97ba13":"code","49ab6b8a":"code","a99741eb":"code","d576e87c":"code","3efb5b0f":"code","10122652":"code","ec223375":"code","2606f84d":"code","d1251142":"code","a5ddfa78":"code","4ac66cab":"code","59339f90":"code","d1ad7159":"code","c9d2d89a":"code","8ac30fd0":"code","4919cb5e":"code","1d7f7407":"code","48e6fb66":"code","e784287e":"code","f23201fd":"markdown","b97ca21f":"markdown","4ceb9d51":"markdown","e8a0e309":"markdown","83597126":"markdown","3d164fad":"markdown","1f305a72":"markdown","70a65b86":"markdown","93598927":"markdown","86f25289":"markdown","a93e4ac1":"markdown","47a0c229":"markdown","89caba8f":"markdown","0a9345c6":"markdown","22a8f525":"markdown","acd25e54":"markdown","b0b48c37":"markdown","6f01fe64":"markdown","b637eeed":"markdown","f0154630":"markdown","b56bfbb2":"markdown","fd9b7da2":"markdown","a4ef85a5":"markdown","426bc3af":"markdown","b991be5c":"markdown","d48c6d05":"markdown","964b8acf":"markdown","f6567828":"markdown","0d9093ad":"markdown","551aae45":"markdown","2b21f2c1":"markdown","d7da0589":"markdown","8cd6660d":"markdown","6a66c36c":"markdown","1ab4e4da":"markdown","38e4eeb8":"markdown","b54015bc":"markdown"},"source":{"b62a54bb":"import numpy as np # vector manipulation\nimport pandas as pd # dataframe manipulation\n\nfrom sklearn.model_selection import train_test_split # spliting train and test dataset\nfrom sklearn.linear_model import LinearRegression # linear regression\nfrom sklearn.tree import DecisionTreeRegressor # decision tree\nfrom sklearn.ensemble import RandomForestRegressor # random forest\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\nimport matplotlib.pyplot as plt # plotting\n\n%matplotlib inline\n\nimport warnings # just for ignoring annoying warnings\nwarnings.filterwarnings('ignore')","4b99206b":"TARGET = 'SalePrice'","a02a6fb4":"dataset = pd.read_csv('..\/input\/train.csv')","bc2cc351":"dataset.head()","d3d31c0a":"dataset.shape","da009951":"desc = dataset.describe()\ndesc","58ed5726":"count = desc.iloc[0]\ncount = count[count == dataset.shape[0]]\nnum_columns = count.index.values\n\nnum_columns","601cf95a":"for column in num_columns:\n    plt.title(column)\n    plt.scatter(dataset[column], dataset[TARGET])\n    plt.show()","022dbefa":"selected = [\n    'GarageArea',       # Garage\n    'GarageCars', \n    'TotRmsAbvGrd',     # Above Ground\n    'LotArea',          # Area\n    'OverallQual',      # Quality\n    'OverallCond',\n    'TotalBsmtSF',      # Second Floor\n    '1stFlrSF', \n    '2ndFlrSF',\n    'YearBuilt',        # Year\n    'YearRemodAdd'\n]","d012c9ca":"corr = dataset[selected + [TARGET]].corr()\ncorr","7b885768":"corr_saleprice = corr['SalePrice']\ncorr_saleprice","d4afcdca":"corr_saleprice[corr_saleprice > 0.60]","fa68fbfa":"linear_features = [\n    'GarageArea',\n    'GarageCars',\n    'OverallQual',\n    'TotalBsmtSF',\n    '1stFlrSF'\n]","953b21ba":"linear_dataset = dataset[linear_features]","283f89e2":"y = dataset[TARGET]","976eadad":"X_train, X_test, y_train, y_test = train_test_split(linear_dataset, y, test_size=0.30, random_state=42)","2798e0ad":"model = LinearRegression().fit(X_train, y_train)","0147fce5":"model.score(X_test, y_test)","cd9c4e6f":"cat_dataset = dataset.drop(num_columns, axis=1)\ncat_dataset.head()","2edb8410":"count = cat_dataset.isna().sum()\ncount = count[count > 0]\ncount","48357aff":"cat_dataset = cat_dataset.drop(count.index.values, axis=1)\ncat_dataset.head()","09130979":"for col in cat_dataset.columns:\n    print(cat_dataset[col].value_counts())\n    print(\"\\n\")","c257be74":"cat_features = [\n    'MSZoning',\n    'LandContour',\n    'LotShape',\n    'LotConfig',\n    'HouseStyle',\n    'Foundation',\n    'HeatingQC',\n    'ExterQual',\n    'KitchenQual',\n    'SaleCondition'\n]","6fe4bd2c":"sel_dataset = cat_dataset[cat_features]\nsel_dataset.head()","0b78a2e5":"# MSZoning : RL or not RL\nsel_dataset['MSZoning'] = np.where(sel_dataset['MSZoning'] == 'RL', 1, 0)\nsel_dataset.head()","9bd52cb2":"sel_dataset['LandContour'] = np.where(sel_dataset['LandContour'] == 'Lvl', 1, 0)\nsel_dataset.head()","522f9d88":"sel_dataset['LotShape'] = np.where(sel_dataset['LotShape'] == 'Reg', 1, 0)\nsel_dataset.head()","ec6fe2e1":"conditions = [\n    sel_dataset['LotConfig'] == 'Inside',\n    sel_dataset['LotConfig'] == 'Corner'\n]\n\nchoices = [2, 1]\n\nsel_dataset['LotConfig'] = np.select(conditions, choices, default=0)\nsel_dataset.head()","f9e806a4":"conditions = [\n    (sel_dataset['HouseStyle'] == '2Story') | (sel_dataset['HouseStyle'] == '1Story') \n]\n\nchoices = [1]\n\nsel_dataset['HouseStyle'] = np.select(conditions, choices, default=0)\nsel_dataset.head()","f625526d":"conditions = [\n    (sel_dataset['Foundation'] == 'PConc'), \n    (sel_dataset['Foundation'] == 'CBlock') \n]\n\nchoices = [2, 1]\n\nsel_dataset['Foundation'] = np.select(conditions, choices, default=0)\nsel_dataset.head()","15a7f172":"conditions = [\n    (sel_dataset['HeatingQC'] == 'Ex'), \n    (sel_dataset['HeatingQC'] == 'TA'),\n    (sel_dataset['HeatingQC'] == 'Gd')\n]\n\nchoices = [3, 2, 1]\n\nsel_dataset['HeatingQC'] = np.select(conditions, choices, default=0)\nsel_dataset.head()","4f366d12":"conditions = [\n    (sel_dataset['ExterQual'] == 'TA'), \n    (sel_dataset['ExterQual'] == 'Gd')\n]\n\nchoices = [2, 1]\n\nsel_dataset['ExterQual'] = np.select(conditions, choices, default=0)\nsel_dataset.head()","de5e0c25":"conditions = [\n    (sel_dataset['KitchenQual'] == 'TA'), \n    (sel_dataset['KitchenQual'] == 'Gd')\n]\n\nchoices = [2, 1]\n\nsel_dataset['KitchenQual'] = np.select(conditions, choices, default=0)\nsel_dataset.head()","1544c988":"conditions = [\n    (sel_dataset['SaleCondition'] == 'Normal')\n]\n\nchoices = [1]\n\nsel_dataset['SaleCondition'] = np.select(conditions, choices, default=0)\nsel_dataset.head()","d14b9542":"y = dataset[TARGET]","0b497638":"X_train, X_test, y_train, y_test = train_test_split(sel_dataset, y, test_size=0.30, random_state=42)","3c0f9cbd":"model = DecisionTreeRegressor().fit(X_train, y_train)","03b170b0":"model.score(X_test, y_test)","db95149b":"both_dataset = pd.concat([linear_dataset, sel_dataset], axis=1, sort=False)\nboth_dataset.head()","72d36e5b":"X_train, X_test, y_train, y_test = train_test_split(both_dataset, y, test_size=0.30, random_state=42)","619aa1cc":"model = RandomForestRegressor().fit(X_train, y_train)\nmodel.score(X_test, y_test)","85de76d4":"one_hot = OneHotEncoder().fit(sel_dataset)","7999bf84":"oh_dataset = one_hot.transform(sel_dataset)\noh_dataset = pd.DataFrame(oh_dataset.toarray())","ec5a9cb0":"both_dataset = pd.concat([linear_dataset, oh_dataset], axis=1, sort=False)","15b18c00":"X_train, X_test, y_train, y_test = train_test_split(both_dataset, y, test_size=0.30, random_state=42)","ab38ca41":"model = RandomForestRegressor().fit(X_train, y_train)\nmodel.score(X_test, y_test)","becfb9a0":"scaler = StandardScaler()","29b3bb8d":"scaler.fit(linear_dataset)","8264f952":"scaled_dataset = scaler.transform(linear_dataset)\nscaled_dataset = pd.DataFrame(scaled_dataset)","18b20a76":"both_dataset = pd.concat([scaled_dataset, oh_dataset], axis=1, sort=False)","d48f2d51":"X_train, X_test, y_train, y_test = train_test_split(both_dataset, y, test_size=0.30, random_state=42)","2e256688":"model = RandomForestRegressor().fit(X_train, y_train)\nmodel.score(X_test, y_test)","f7ad24bb":"y_log = np.log(y)","f812842a":"X_train, X_test, y_train, y_test = train_test_split(both_dataset, y_log, test_size=0.30, random_state=42)","7a9566e3":"model = RandomForestRegressor().fit(X_train, y_train)\nmodel.score(X_test, y_test)","c1b71a22":"model.get_params()","7dc93fca":"params = {\n    'bootstrap': [True, False],\n    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n    'max_features': ['auto', 'sqrt'],\n    'min_samples_leaf': [1, 2, 4],\n    'min_samples_split': [2, 5, 10],\n    'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n}","6f1694be":"f_model = RandomizedSearchCV(model, params, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)","e2887cf1":"f_model.fit(X_train, y_train)","352dd468":"f_model.score(X_test, y_test)","9c97ba13":"import pickle","49ab6b8a":"with open('model.pkl', 'wb') as f:\n    pickle.dump(f_model, file=f)","a99741eb":"dataset = pd.read_csv('..\/input\/test.csv')\ndataset.head()","d576e87c":"X_linear = dataset[linear_features] \nX_cat = dataset[cat_features]","3efb5b0f":"X_cat['MSZoning'] = np.where(X_cat['MSZoning'] == 'RL', 1, 0)\nX_cat['LandContour'] = np.where(X_cat['LandContour'] == 'Lvl', 1, 0)\nX_cat['LotShape'] = np.where(X_cat['LotShape'] == 'Reg', 1, 0)\n\nconditions = [\n    X_cat['LotConfig'] == 'Inside',\n    X_cat['LotConfig'] == 'Corner'\n]\n\nchoices = [2, 1]\n\nX_cat['LotConfig'] = np.select(conditions, choices, default=0)\n\nconditions = [\n    (X_cat['HouseStyle'] == '2Story') | (X_cat['HouseStyle'] == '1Story') \n]\n\nchoices = [1]\n\nX_cat['HouseStyle'] = np.select(conditions, choices, default=0)\n\nconditions = [\n    (X_cat['Foundation'] == 'PConc'), \n    (X_cat['Foundation'] == 'CBlock') \n]\n\nchoices = [2, 1]\n\nX_cat['Foundation'] = np.select(conditions, choices, default=0)\n\nconditions = [\n    (X_cat['HeatingQC'] == 'Ex'), \n    (X_cat['HeatingQC'] == 'TA'),\n    (X_cat['HeatingQC'] == 'Gd')\n]\n\nchoices = [3, 2, 1]\n\nX_cat['HeatingQC'] = np.select(conditions, choices, default=0)\n\nconditions = [\n    (X_cat['ExterQual'] == 'TA'), \n    (X_cat['ExterQual'] == 'Gd')\n]\n\nchoices = [2, 1]\n\nX_cat['ExterQual'] = np.select(conditions, choices, default=0)\n\n\nconditions = [\n    (X_cat['KitchenQual'] == 'TA'), \n    (X_cat['KitchenQual'] == 'Gd')\n]\n\nchoices = [2, 1]\n\nX_cat['KitchenQual'] = np.select(conditions, choices, default=0)\n\nconditions = [\n    (X_cat['SaleCondition'] == 'Normal')\n]\n\nchoices = [1]\n\nX_cat['SaleCondition'] = np.select(conditions, choices, default=0)","10122652":"X_cat.head()","ec223375":"X_cat = one_hot.transform(X_cat)\nX_cat = pd.DataFrame(X_cat.toarray())","2606f84d":"X_linear = scaler.transform(X_linear)\nX_linear = pd.DataFrame(X_linear)","d1251142":"X = pd.concat([X_linear, X_cat], axis=1, sort=False)","a5ddfa78":"X.head()","4ac66cab":"X = X.fillna(0)","59339f90":"y_final = f_model.predict(X)","d1ad7159":"y_final = np.exp(y_final)","c9d2d89a":"y_final = pd.DataFrame({'SalePrice': y_final})","8ac30fd0":"y_final.head()","4919cb5e":"y.head()","1d7f7407":"Ids = dataset['Id']\nIds.head()","48e6fb66":"submission = pd.concat([Ids, y_final], axis=1, sort=False)\nsubmission.head()","e784287e":"submission.to_csv('.\/submission.csv', index=False)","f23201fd":"From those, let's select the most interesting in terms of variance","b97ca21f":"### Testing the Selected Linear Variables","4ceb9d51":"Seeing how the variables relate with each other","e8a0e309":"#### LotShape","83597126":"### Changing categorical variables into numerical","3d164fad":"#### HouseStyle","1f305a72":"Lets select only those with colinearity above 0.6","70a65b86":"Looking at those plots we can see that these variables show the most colinerarity with SalePrice.","93598927":"We can see that only from the linear features we already achieved a good result.","86f25289":"#### HeatingQC","a93e4ac1":"#### LandContour","47a0c229":"#### ExterQual","89caba8f":"#### Scaling the target variable","0a9345c6":"### Data Exploration","22a8f525":"# House Prices: Advanced Regression Techniques\n\n[Link to the Kaggle Competition](https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques)\n\nAuthor: Diego Rodrigues [@polaroidz](https:\/\/github.com\/polaroidz)","acd25e54":"In order to see which of the linear variables are more interesting for some type of regression, we will plot them in relation to SalePrice and notice which of them are more colinear","b0b48c37":"## Importing and Loading Data","6f01fe64":"#### KitchenQual","b637eeed":"### Measuring Perfomance on the Test Dataset","f0154630":"#### One-Hot encoding categorical variables ","b56bfbb2":"The result isn't great as expected, but good enough to indicate that we are getting somewhere.","fd9b7da2":"So, we have 81 variables.","a4ef85a5":"#### Scalling our numerical variables","426bc3af":"#### LotConfig","b991be5c":"Good enough accuracy for now.","d48c6d05":"#### Foundation","964b8acf":"#### MSZoning","f6567828":"Seems legit","0d9093ad":"Dropping missing values","551aae45":"### Testing both selected categorical and numerical variables","2b21f2c1":"### Selecting Categorial Variables","d7da0589":"The target variable on our dataset is called SalePrice","8cd6660d":"From these 81, we have 38 numerical variables. Great! Lets Start with those","6a66c36c":"Lets see the value counting for each of the selected categorical variables","1ab4e4da":"#### Grid Searching Model Parameters","38e4eeb8":"#### SaleCondition","b54015bc":"### Testing the selected categorical variables"}}