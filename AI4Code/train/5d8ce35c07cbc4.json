{"cell_type":{"a4d89f82":"code","ec4ee791":"code","279c755a":"code","7d09d9bf":"code","c7903cae":"code","a40a86c5":"code","3010c0c4":"code","0a58cabc":"code","7bc822c0":"code","1b5402a9":"code","157a86c4":"code","f88c1a0c":"code","5f790686":"code","d6e92099":"code","6f802533":"code","89903185":"code","c3e678bb":"code","a0a21b93":"code","4af3f3e1":"code","14f8132e":"code","b2130e33":"code","7d328c4e":"code","fc607530":"code","e29698c3":"code","1c3c6e40":"code","782779ac":"code","bc60963e":"code","87bce6db":"code","a9b1174f":"code","2312a569":"code","213519f3":"code","12e4bd9a":"code","ce5220a9":"code","12adb6eb":"code","ce2c29ef":"code","61751e56":"code","debb53aa":"code","d8de4c6f":"code","e21cc672":"code","9b7e1b8e":"code","6faf35c5":"code","1a1804ca":"code","886fe20a":"code","919d56f5":"code","231bca02":"code","4a907eb2":"code","88158173":"code","51127179":"code","8aefdc12":"markdown","c7983d56":"markdown","855b9b46":"markdown","2a1f2cd2":"markdown","6e0ba549":"markdown","e1a5151c":"markdown","4143eb17":"markdown","f8acd9fa":"markdown","ec0c552e":"markdown","6a982fb5":"markdown","11d615ae":"markdown","a57c3a7b":"markdown","8074c8fc":"markdown","79874075":"markdown","f9d75122":"markdown","da490e2f":"markdown","6398a37e":"markdown","73b35808":"markdown","6b9bf601":"markdown","457974c8":"markdown","02dc4d97":"markdown","da3755b1":"markdown","c9c1c8a2":"markdown","b9e129fb":"markdown","365a0e9f":"markdown","6f93f30c":"markdown","b3418aa5":"markdown","6b3f6a6e":"markdown","58bbfae7":"markdown","d141ff5b":"markdown","dd2fc9a5":"markdown","070a6c12":"markdown","2d894ba6":"markdown","aa8e063b":"markdown","2d134d46":"markdown","a4619acc":"markdown","0ec8639b":"markdown","c9262429":"markdown","0940cbf5":"markdown","cd13c8a7":"markdown","ca76fe40":"markdown","d35f6b42":"markdown","364d6c41":"markdown","001b51d4":"markdown","51cbfc0f":"markdown","e1f662d3":"markdown","4d29fc06":"markdown","4c6cbe6d":"markdown","88e0436f":"markdown","ef577992":"markdown"},"source":{"a4d89f82":"!pip install sidetable","ec4ee791":"import os\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\ninit_notebook_mode(connected=True)\npd.set_option('display.max_columns', 5000)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n#os.mkdir('\/kaggle\/working\/individual_charts\/')\nimport matplotlib.pyplot as plt\n# Load the data\n#Will come in handy to wrap the lengthy texts\nimport textwrap\n#useful libraries and functions\nimport sidetable as stb\nfrom itertools import repeat\n#Libraries that give a different visual possibilities\nfrom pandas import option_context \nfrom plotly.subplots import make_subplots\n\ndef long_sentences_seperate(sentence, width=30):\n    try:\n        splittext = textwrap.wrap(sentence,width)\n        text = '<br>'.join(splittext)#whitespace is removed, and the sentence is joined\n        return text\n    except:\n        return sentence\n\ndef load_csv(base_dir,file_name):\n    \"\"\"Loads a CSV file into a Pandas DataFrame\"\"\"\n    file_path = os.path.join(base_dir,file_name)\n    df = pd.read_csv(file_path,low_memory=False,encoding='ISO-8859-1')\n    return df    \n\nbase_dir_2020 = '\/kaggle\/input\/kaggle-survey-2020'\nfile_name_2020 = 'kaggle_survey_2020_responses.csv'\nsurvey_df_2020 = load_csv(base_dir_2020,file_name_2020)\nresponses_df_2020 = survey_df_2020[1:]\nsurvey_df_2020.to_csv('2020_kaggle_ds_and_ml_survey_responses_only.csv',index=False)\n\nbase_dir_2021 = '\/kaggle\/input\/kaggle-survey-2021\/'\nfile_name_2021 = 'kaggle_survey_2021_responses.csv'\nsurvey_df_2021 = load_csv(base_dir_2021,file_name_2021)\nresponses_df_2021 = survey_df_2021[1:]\nsurvey_df_2021.to_csv('2021_kaggle_ds_and_ml_survey_responses_only.csv',index=False)\n\nprint('Total Number of Responses 2020: ',responses_df_2020.shape[0])\nprint('Total Number of Responses 2021: ',responses_df_2021.shape[0])","279c755a":"#Kagglers demographics\n\nr_dgc_2021 = responses_df_2021.loc[:,['Q1','Q2','Q3','Q4','Q5','Q6','Q20','Q21','Q22',\n                                      'Q25','Time from Start to Finish (seconds)']]\nr_dgc_2020 = responses_df_2020.loc[:,['Q1','Q2','Q3','Q4','Q5','Q6','Q20','Q21','Q22',\n                                      'Q25','Time from Start to Finish (seconds)']]\nr_dgc_2021['Finish_time'] = r_dgc_2021['Time from Start to Finish (seconds)'].astype('int')\nr_dgc_2020['Finish_time'] = r_dgc_2020['Time from Start to Finish (seconds)'].astype('int')","7d09d9bf":"#Idea is to groupby and count the number of occurences of the people with set of characters. This way the \n#demographics can be rendered quantitatively\ndg_c_2021 = r_dgc_2021.groupby(['Q1','Q2','Q3','Q4','Q5','Q6','Q20','Q21','Q22','Q25'])['Finish_time'].count().reset_index()\ndg_c_2020 = r_dgc_2020.groupby(['Q1','Q2','Q3','Q4','Q5','Q6','Q20','Q21','Q22','Q25'])['Finish_time'].count().reset_index()\ndg_c_2021['year'] = 2021\ndg_c_2020['year'] = 2020","c7903cae":"dg_c_2021.columns = ['Age','Gender','Country','Education','Employment','Experience','Industry','Total_Employee',\n                     'Datascientists','salary','Numbers','Year']\ndg_c_2020.columns = ['Age','Gender','Country','Education','Employment','Experience','Industry','Total_Employee',\n                     'Datascientists','salary','Numbers','Year']","a40a86c5":"#Need to get the counts based on the Gender, and age. \nvisual_1_grp = dg_c_2021.groupby(['Age','Gender'])['Numbers'].sum().reset_index()\nvisual_1 = px.bar(data_frame=visual_1_grp,x='Gender',y='Numbers',color='Age',\n                  barmode='group',title='Kagglers Age and Gender distribution')\nvisual_1.show()\ndel visual_1_grp #Removing the unwanted DF immediately","3010c0c4":"visual_2_grp = dg_c_2020.groupby('Country')['Numbers'].sum().reset_index()\nvisual_2_grp.Country = visual_2_grp.Country.apply(lambda x : long_sentences_seperate(x,7))\nvisual_2 = px.treemap(data_frame=visual_2_grp,path=['Country'],names='Country',\n                      values = 'Numbers',title='Participating Nations')\nvisual_2.show()\ndel visual_2_grp","0a58cabc":"visual_3_grp = dg_c_2021.groupby(['Country','Gender'])['Numbers'].sum().reset_index()\nvisual_3 = px.choropleth(visual_3_grp, locations=\"Country\",color='Numbers',\n                         locationmode='country names',animation_frame='Gender',\n                        title = 'Participation based on the Countries & Gender')\nvisual_3.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nvisual_3.show()\ndel visual_3_grp","7bc822c0":"#Function takes the dataframe and groups and counts the number of values in each column, based on the \"column\"\n#that is required for analysis. The counting column will be the 'Time from Start to Finish (seconds)' since \n#this cell will have some value.\ndef cols_counter(df,base_col,question_col,category):\n    col_part = [] #Initialising the cols of interest\n    for col in df.columns:\n        if question_col in col:\n            col_part.append(col) #till here same as group cols\n    \n    col_part.append('Time from Start to Finish (seconds)')\n    col_part.append(base_col)\n    temp_df = df[col_part]# creating temp dataframe to get only the replies that are required for the visual in question\n    \n    ret_df = pd.DataFrame()# initialising the dataframe that will contain the replies counted.\n    \n    for col_cnt in temp_df.columns: #Starting the loop for the counting and dataframe collection\n        if ((col_cnt != base_col) and (col_cnt != 'Time from Start to Finish (seconds)')):\n            temp_replies = temp_df.groupby([col_cnt,base_col])['Time from Start to Finish (seconds)'].count().reset_index()\n            temp_replies.columns = ['Reply_Choices','base_col','Counts']\n            temp_replies['category'] = category\n        #col_vals.append(temp_edu[cols].unique()[0])\n        ret_df = pd.concat([temp_replies,ret_df]) #appending to the returning df\n\n    return ret_df","1b5402a9":"from pandas import option_context #Helpful in seeing the questions that can help to answer\n\nwith option_context('display.max_colwidth', 400,'display.max_rows',600):\n    display(survey_df_2021.iloc[:2,175:250].T)","157a86c4":"Q7_df = cols_counter(responses_df_2021,base_col='Q4',question_col='Q7',category='Statistical softwares')\nQ9_df = cols_counter(responses_df_2021,base_col='Q4',question_col='Q9',category='IDEs')\nQ10_df = cols_counter(responses_df_2021,base_col='Q4',question_col='Q10',category='Cloud Platforms')\nQ27_df = cols_counter(responses_df_2021,base_col='Q4',question_col='Q27',category='Cloud Products')\nQ34_df = cols_counter(responses_df_2021,base_col='Q4',question_col='Q34',category='BI softwares')","f88c1a0c":"Q32_A_df = cols_counter(responses_df_2021,base_col='Q4',question_col='Q32_A',category='Databases')","5f790686":"visual_4_grp = pd.concat([Q34_df,Q27_df,Q10_df,Q9_df,Q7_df]) # Concatenate the choices\nvisual_4_grp = visual_4_grp[~(visual_4_grp.Reply_Choices == 'None')] #remove the None value choices,since they don't add","d6e92099":"visual_4 = px.bar(data_frame=visual_4_grp,x='Counts',color='base_col',y='category',\n                 title = 'Distribution of Software & Education',height=500)\n\nvisual_4.update_layout(legend=dict(x=0,y=-1.5,traceorder=\"reversed\",\n                                   title_font_family=\"Times New Roman\",\n                                   font=dict(family=\"Courier\",size=12,color=\"black\"),\n                                   bgcolor=\"white\",\n                                   bordercolor=\"Black\",\n                                   borderwidth=2),\n                      yaxis={'categoryorder':'total descending'})\nvisual_4.show()\ndel visual_4_grp","6f802533":"visual_grp_5 = dg_c_2021.groupby(['Age','Employment'])['Numbers'].sum().reset_index()\nvisual_5 = px.bar(data_frame=visual_grp_5,y='Employment',x='Numbers',color='Age',\n                  barmode='stack',title='Kagglers Age and Profession distribution')\nvisual_5.update_layout(yaxis={'categoryorder':'total ascending'})\nvisual_5.show()\ndel visual_grp_5 #Removing the unwanted DF immediately","89903185":"visual_grp_6 = dg_c_2021.groupby(['Experience'])['Numbers'].sum().reset_index()\nvisual_6 = px.bar(data_frame=visual_grp_6,y='Experience',x='Numbers'\n                  ,title='Kagglers Experience distribution',text='Numbers')\nvisual_6.update_traces(marker_color='rgb(150,202,25)') #This brings in the color for the bars\nvisual_6.update_layout(yaxis={'categoryorder':'total descending'})\nvisual_6.show()\ndel visual_grp_6 #Removing the unwanted DF immediately","c3e678bb":"visual7 = responses_df_2021.loc[:,['Q25','Time from Start to Finish (seconds)']]\nvisual_grp_7 = visual7.groupby('Q25')['Time from Start to Finish (seconds)'].count().reset_index()\nvisual_7 = px.bar(data_frame=visual_grp_7,y='Q25',x='Time from Start to Finish (seconds)'\n                  ,title='Kagglers Salary distribution')\nvisual_7.update_layout(yaxis={'categoryorder':'total ascending'})\nvisual_7.show()\ndel visual_grp_7,visual7 #Removing the unwanted DF immediately","a0a21b93":"visual_grp_8 = dg_c_2021.groupby(['Employment','salary'])['Numbers'].count().reset_index()\nvisual_8 = px.bar(data_frame=visual_grp_8,y='salary',x='Numbers',color='Employment',\n                  title='Salary based on profession distribution')\nvisual_8.update_layout(yaxis={'categoryorder':'total ascending'},height=800)\nvisual_8.show()\ndel visual_grp_8 #Removing the unwanted DF immediately","4af3f3e1":"visual_grp_9 = dg_c_2021.groupby(['Industry','Total_Employee'])['Numbers'].count().reset_index()\nvisual_9 = px.bar(data_frame=visual_grp_9,x='Industry',y='Numbers',color='Total_Employee',\n                  title='Industry & Total Employee distribution')\nvisual_9.update_layout(legend=dict(x=0,y=-0.5,traceorder=\"reversed\",orientation=\"h\"),#This makes Legend Horizontal\n                       xaxis={'categoryorder':'total ascending'},width=1000,height=800)\nvisual_9.show()\ndel visual_grp_9 #Removing the unwanted DF immediately","14f8132e":"visual_grp_10 = Q32_A_df.groupby(['Reply_Choices'])['Counts'].sum().reset_index()\nvisual_10 = px.bar(data_frame=visual_grp_10,x='Counts',y='Reply_Choices',\n                   title='Database usage distribution')\nvisual_10.update_layout(yaxis={'categoryorder':'total ascending'},height=700)\nvisual_10.show()\ndel visual_grp_10 #Removing the unwanted DF immediately","b2130e33":"visual_grp_11 = Q34_df.groupby(['Reply_Choices'])['Counts'].sum().reset_index()\nvisual_11 = px.bar(data_frame=visual_grp_11,x='Counts',y='Reply_Choices',\n                   title='Business Intelligence usage distribution')\nvisual_11.update_layout(yaxis={'categoryorder':'total ascending'},height=700)\nvisual_11.show()\ndel visual_grp_11 #Removing the unwanted DF immediately","7d328c4e":"visual_grp_12 = dg_c_2021.groupby(['Country','Gender'])['Numbers'].sum().reset_index()\ntable_12 = pd.pivot_table(data=visual_grp_12,index='Country',columns='Gender',values='Numbers').fillna('-').reset_index()\ntable_12.sort_values(by='Man',ascending=False,inplace=True)\ntable_12.head()","fc607530":"header = visual_grp_12.Gender.unique()\nheader = np.insert( header, 0, 'country') #This took considerable trial and error to understand\nvisual_12 = make_subplots(rows=2, cols=1,\n                          vertical_spacing=0.1,\n                          specs=[[{\"type\": \"Bar\"}],[{\"type\": \"table\"}]])\n\nvisual_12.add_trace(go.Table(header=dict(values=header,\n                                         font=dict(size=10),\n                                         align=\"left\"),\n                             cells=dict(values=[table_12[k].tolist() for k in table_12.columns],\n                                        align = \"left\")),row=2, col=1)\nfor k in table_12.columns[1:]:\n    visual_12.add_trace(go.Bar(x=table_12.Country,y=table_12[k],name=k),row=1, col=1)                                                \n\nvisual_12.update_layout(height=800,showlegend=False,\n                        title_text=\"Countrywise Distribution\",barmode='stack')\nvisual_12.show() \ndel visual_grp_12","e29698c3":"visual_13_grp = dg_c_2021.groupby('Country')['Numbers'].sum().reset_index()\nvisual_13 = px.scatter_geo(visual_13_grp, locations=\"Country\",color='Country',\n                         locationmode='country names',size='Numbers')\nvisual_13.update_layout(legend=dict(orientation=\"h\",yanchor=\"bottom\",y=1.02,xanchor=\"right\",x=1),\n                        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},width = 1000)\nvisual_13.show()\ndel visual_13_grp","1c3c6e40":"visual_14_grp = dg_c_2020.groupby(['Country','Gender'])['Numbers'].sum().reset_index()\nvisual_14_grp.Country = visual_14_grp.Country.apply(lambda x : long_sentences_seperate(x,7))\nvisual_14 = px.treemap(data_frame=visual_14_grp,path=['Country','Gender'],names='Country',\n                      values = 'Numbers',color='Gender',title='Participating Nations with Gender distribution')\nvisual_14.update_layout(height=1000,width=1000)\nvisual_14.show()\ndel visual_14_grp","782779ac":"visual_15_grp = dg_c_2020.groupby('Country')['Numbers'].sum().reset_index()\nvisual_15_grp.sort_values(by='Numbers',ascending=False,inplace=True)\nvisual_15_grp.Country = visual_15_grp.Country.apply(lambda x : long_sentences_seperate(x,7))\n\n\nvisual_15 = make_subplots(rows=1, cols=2,\n                          horizontal_spacing=0.1,\n                          specs=[[{\"type\": \"table\"},{\"type\": \"funnel\"}]])\n\nvisual_15.add_trace(go.Table(header=dict(values=visual_15_grp.columns,\n                                         font=dict(size=10),\n                                         align=\"left\"),\n                             cells=dict(values=[visual_15_grp[k].tolist() for k in visual_15_grp.columns],\n                                        align = \"left\")),row=1, col=1)\nvisual_15.add_trace(go.Funnel(y=visual_15_grp.Country,x=visual_15_grp.Numbers,\n                              textposition = \"inside\",textinfo = \"value+percent initial\",\n                              opacity = 0.95,\n                              connector = {\"line\": {\"color\": \"white\", \"dash\": \"dot\", \"width\": 3}}),row=1,col=2)\nvisual_15.update_layout(height=1000,width=1000)\nvisual_15.show()\ndel visual_15_grp","bc60963e":"visual_grp_16 = dg_c_2021.groupby(['Country','Employment'])['Numbers'].sum().reset_index()\nvisual_pie_16 = dg_c_2021.groupby('Employment')['Numbers'].sum().reset_index()\ntable_16 = pd.pivot_table(data=visual_grp_16,index='Country',columns='Employment',values='Numbers').fillna('-').reset_index()\ntable_16.sort_values(by='Data Scientist',ascending=False,inplace=True)\ntable_16.head()","87bce6db":"# The below visual took considerable amount of effort to learn. The other challenge will be, in bringing \n# treemaps inside the subplots. The treemap creation is easier in plotly express, but in Graph Objects, is \n# very labour intensive, and less intuitive\nvisual_16 = make_subplots(rows=2, cols=2,\n                          horizontal_spacing=0.1,\n                          specs=[[{\"type\": \"scatter\", \"colspan\": 2},None],\n                                 [{\"type\": \"pie\"}, {\"type\": \"funnel\"}]])\n\nvisual_16.add_trace(go.Pie(labels=visual_pie_16.Employment,values=visual_pie_16.Numbers,hole=0.3),row=2,col=1)\nvisual_pie_16.sort_values(by='Numbers',ascending=False,inplace=True)\n\nvisual_16.add_trace(go.Funnel(y=visual_pie_16.Employment,x=visual_pie_16.Numbers),row=2,col=2)\n\nfor k in table_16.columns[1:]:\n    visual_16.add_trace(go.Scatter(x=table_16.Country,y=table_16[k],fill='tozeroy',mode='none',name=k),row=1,col=1)\n\nvisual_16.update_layout(height=1000,width=1000)\n\nvisual_16.show()","a9b1174f":"#Cleaning up the data\ndg_c_2021.loc[dg_c_2021.Education.str.contains('without'),'Education'] = 'Without_Degree'\ndg_c_2021.loc[dg_c_2021.Education.str.contains('Bachelor'),'Education'] = 'Bachelor_Degree'\ndg_c_2021.loc[dg_c_2021.Education.str.contains('Master'),'Education'] = 'Masters_Degree'\ndg_c_2021.loc[dg_c_2021.Education.str.contains('without'),'Education'] = 'Without_Degree'\n\n#Getting the data ready for feeding into the charting function\nvisual_17_p1 = dg_c_2021.groupby(['Experience','Employment'])['Numbers'].sum().reset_index()\nvisual_17_p2 = dg_c_2021.groupby(['Experience','Education'])['Numbers'].sum().reset_index()\nvisual_17_p3 = dg_c_2021.groupby(['Education','Employment'])['Numbers'].sum().reset_index()\nvisual_17_p4 = dg_c_2021.groupby('Employment')['Numbers'].sum().reset_index()\n\n#changing the dataframe orientation to make graphing easier\ntable_p1_17 = pd.pivot_table(data=visual_17_p1,index='Experience',columns='Employment',\n                             values='Numbers').fillna('-').reset_index()\ntable_p1_17.sort_values(by='Data Scientist',ascending=False,inplace=True)\n\ntable_p2_17 = pd.pivot_table(data=visual_17_p2,index='Experience',columns='Education',\n                             values='Numbers').fillna('-').reset_index()\ntable_p2_17.sort_values(by='Bachelor_Degree',ascending=False,inplace=True)\ntable_p3_17 = pd.pivot_table(data=visual_17_p3,index='Education',columns='Employment',\n                             values='Numbers').fillna('-').reset_index()\ntable_p3_17.sort_values(by='Business Analyst',ascending=False,inplace=True)","2312a569":"visual_17 = make_subplots(rows=2,cols=2,specs=[[{'type':'scatter'},{'type':'bar'}],\n                                           [{'type':'bar'},{'type':'scatter'}]])\n\nfor cols in table_p2_17.columns[1:]:\n    visual_17.add_trace(go.Bar(x=table_p2_17.Experience,\n                           y=table_p2_17[cols],name=cols),row=1,col=2)\n    \nfor exp in table_p1_17.columns[1:]:\n    visual_17.add_trace(go.Scatter(x=table_p1_17.Experience,\n                               y=table_p1_17[exp],\n                               fill='tozeroy',mode='none',\n                                name=exp),row=1,col=1)\n    \nfor exp in table_p3_17.columns[1:]:\n    visual_17.add_trace(go.Scatter(x=table_p3_17.Education,\n                               y=table_p3_17[exp],\n                               fill='tozeroy',mode='none',\n                                name=exp),row=2,col=2)\n\nvisual_17.add_trace(go.Bar(y=visual_17_p4.Numbers,\n                          x=visual_17_p4.Employment),row=2,col=1)\n\nvisual_17.update_layout(height = 1000, width = 1000,showlegend=False)\ndel visual_17_p4,visual_17_p3,visual_17_p2,visual_17_p1,table_p1_17,table_p2_17,table_p3_17\nvisual_17.show()","213519f3":"visual_grp_18 = dg_c_2021.groupby(['Country','Experience'])['Numbers'].sum().reset_index()\nvisual_lin_18 = dg_c_2021.groupby(['Employment','Country'])['Numbers'].sum().reset_index()\ntable_18_1 = pd.pivot_table(data=visual_grp_18,index='Country',columns='Experience',values='Numbers').fillna('-').reset_index()\ntable_18_1.sort_values(by='1-3 years',ascending=False,inplace=True)\ntable_18_1 = table_18_1[:12]\nlocation = table_18_1.Country\ntable_18_2 = pd.pivot_table(data=visual_lin_18,index='Employment',columns='Country',values='Numbers').fillna('-').reset_index()\ntable_18_2 = table_18_2[location].sum()\ntable_18_2 = table_18_2[1:]","12e4bd9a":"# Adding the 2nd axis for the employment\nvisual_18 = make_subplots(specs=[[{\"secondary_y\": True}]])\n\nfor cols in table_18_1.columns[1:]:\n    visual_18.add_trace(go.Bar(x=table_18_1.Country,y=table_18_1[cols],name=cols),secondary_y=False)\n    \nvisual_18.add_trace(go.Line(x=table_18_2.index,y=table_18_2.values,\n                            orientation='h',name='Employment'),secondary_y=True)\n# Set x-axis title\nvisual_18.update_xaxes(title_text=\"Country\")\n\n# Set y-axes titles\nvisual_18.update_yaxes(title_text=\"<b>Experience<\/b> yaxis title\", secondary_y=False)\nvisual_18.update_yaxes(title_text=\"<b>Employment<\/b> yaxis title\", secondary_y=True)\n\nvisual_18.update_layout(width =1000, height = 1000)\ndel visual_grp_18,visual_lin_18\nvisual_18.show()","ce5220a9":"visual_grp_19 = dg_c_2021.groupby(['Country','Experience'])['Numbers'].sum().reset_index()\nvisual_grp_19.sort_values(by='Numbers',ascending=False,inplace=True)\ngrp_19_total = visual_grp_19.groupby(['Country', 'Experience']).agg({'Numbers': ['sum']}).stb.subtotal().stb.flatten()\ngrp_19_total = grp_19_total.sort_values(by='Country')\n\n# Need to create sub_data to get the countries total.\nsubtotal = grp_19_total[grp_19_total.Experience.str.contains('subtotal')]\nsubtotal.sort_values(by='Numbers_sum',ascending=True,inplace=True)\nsubtotal = subtotal[-15:]\nsub_data = grp_19_total[grp_19_total.Country.isin(subtotal.Country)]\n\n#After selecting the top 15 countries, then merge them\nmerge_19 = pd.merge(left=subtotal,right=sub_data,left_on='Country',right_on='Country',how='left')\nmerge_19.loc[(~merge_19.Experience_y.str.contains('subtotal')),\n              'Numbers_sum_x'] = merge_19.loc[(~merge_19.Experience_y.str.contains('subtotal')),\n                                               'Numbers_sum_y']\nmerge_19.drop(['Numbers_sum_y','Experience_x'],axis=1,inplace=True)                                          ","12adb6eb":"#Have to thank towardsdatascience for the below code idea. Had been trying figure this out for 2 hrs... \n#https:\/\/towardsdatascience.com\/waterfall-charts-with-plotly-43822918e9eb\n\nconditionlist = [(merge_19.Experience_y.str.contains('subtotal')),\n                 (~merge_19.Experience_y.str.contains('subtotal'))]\n\nchoicelist   = ['total', 'relative']\n\nmerge_19['measure'] = np.select(conditionlist, choicelist)","ce2c29ef":"#Seriously UK is more stylish to pronounce, and compact too.\nmerge_19.loc[merge_19.Country.str.contains('Kingdom'),'Country']='UK'\nmerge_19.loc[merge_19.Country.str.contains('Kingdom'),'Experience_y']='UK - subtotal'","61751e56":"visual_19  = go.Figure()\nmerge_19 = merge_19[merge_19.Country == 'India'].sort_values(by='Numbers_sum_x',ascending=True)\nvisual_19.add_trace(go.Waterfall(x = merge_19['Experience_y'], y = merge_19['Numbers_sum_x'],\n                                 measure = merge_19['measure'],\n                                 text = merge_19['Numbers_sum_x'],textposition = 'outside',\n                                 decreasing = {\"marker\":{\"color\":\"crimson\",\"line\":{\"color\":\"lightsalmon\",\"width\":2}}},\n                                 increasing = {\"marker\":{\"color\":\"forestgreen\",\"line\":{\"color\":\"lightgreen\", \"width\":2}}},\n                                 totals     = {\"marker\":{\"color\":\"mediumblue\"}}\n               ))\nvisual_19.update_layout(title_text = \"Waterfall of the Experience in major countries\",\n                        title_font = dict(size=25,family='Verdana',\n                                          color='darkred'),height =1000,width = 1000)\nvisual_19.update_xaxes(title = 'Experience Numbers')\nvisual_19.update_yaxes(title = 'Countries')\nvisual_19.show()","debb53aa":"#Sankey charts can show interesting data\/group\/material flows. Here we wish to see, how the community \n#bifurcates into many categories. To begin with the how it flows into multiple gender\nvisual_grp_20 = dg_c_2021.groupby('Gender')['Numbers'].sum().reset_index()\nvisual_grp_20 = visual_grp_20.stb.subtotal().reset_index()\nvisual_grp_20['index'] = range(0,6)\nvisual_grp_20.loc[visual_grp_20.index == 5,'Gender'] = 'Total_Community'","d8de4c6f":"#Creating Source and Targets\nsource = []\nsource.extend(repeat(visual_grp_20.index[5],5))\n\ntarget = [0,1,2,3,4]\n\nvalue = visual_grp_20.Numbers.values[:-1]\n\nlabel = visual_grp_20.Gender.values\n\nlink = dict(source = source, target = target, value = value)\nnode = dict(label = label, pad=50, thickness=5)\n#Building the chart Json file\ndata = go.Sankey(link = link,node=node)\n#print(data)\n\nvisual_20 = go.Figure(data)","e21cc672":"visual_20.show()","9b7e1b8e":"#Creating level two of the Sankey Chart\nvisual_grp_20_a = dg_c_2021.groupby(['Gender','Education'])['Numbers'].sum().reset_index()\nvisual_grp_20_a = visual_grp_20_a.stb.subtotal().reset_index()\n#Cleaning long names\nvisual_grp_20_a.loc[visual_grp_20_a.Education == 'Some college\/university study without earning a bachelor\u00e2\\x80\\x99s degree','Education'] = 'Some_College'\nvisual_grp_20_a.loc[visual_grp_20_a.Education == 'No formal education past high school','Education'] = 'High_School'\nvisual_grp_20_a.loc[visual_grp_20_a.Education == 'I prefer not to answer','Education'] = 'Not_Answered'\nvisual_grp_20_a.loc[visual_grp_20_a.Gender == 'Prefer to self-describe','Gender'] = 'Self_described'","6faf35c5":"#Creating labels\ngen = visual_grp_20_a.Gender.unique()\nedu = visual_grp_20_a.Education.unique()\n#Building the Source \nlabel = list(edu)+list(gen)\nlabel.append('Total')\n\n#Creating Sources & Targets\nsource = [8,8,8,8,8,8,8,\n          9,9,9,9,9,9,9,\n          10,10,10,10,10,10,10,\n          11,11,11,11,11,11,11,\n          12,12,12,12,12,12,12]\ntarget = [0,1,2,3,4,5,6,\n          0,1,2,3,4,5,6,\n          0,1,2,3,4,5,6,\n          0,1,2,3,4,5,6,\n          0,1,2,3,4,5,6]","1a1804ca":"value = visual_grp_20_a.Numbers.values[:-1]\n#Appending the total of the entire community","886fe20a":"#Thickness of the flow path between the source and target depends on the value that is indexed. \nlink = dict(source = source, target = target, value = value)\nnode = dict(label = label, pad=50, thickness=5)\ndata = go.Sankey(link = link,node=node)\n#print(data)\nvisual_20_a = go.Figure(data)","919d56f5":"visual_20_a.show()\ndel visual_grp_20, visual_grp_20_a","231bca02":"#Creating the tail node data.\nvisual_grp_21 = dg_c_2021.groupby(['Employment','salary'])['Numbers'].sum().reset_index()\n#Collecting the source_node data from the dataframes and building the values list\nemp_val = dg_c_2021.groupby('Employment')['Numbers'].sum().reset_index()\nvalues = list(visual_grp_21.Numbers.values) + list(emp_val.Numbers.values) \n#Building the labels list\nemp = visual_grp_21.Employment.unique()\nsal = visual_grp_21.salary.unique()\n#print(len(emp),len(sal))\nlabel = list(emp)+list(sal)","4a907eb2":"#Building the Source and Target Lists\nsource = list()\nfor val in range(0,13):\n    source.extend(repeat(val,26))\n\ntarget = list()\nfor val in range(13,25):\n    tar_part = list(np.arange(13,26))\n    target = target + tar_part\n\n#Building the color palette and making the dictionary for the source and target nodes\ncolor_s = ['#EBBAB5', '#FEF3C7', '#A6E3D7', '#CBB4D5','#f4a460','#bc8f8f','#cd853f',\n          '#ffa500','#ba55d3','#90ee90','#f08080','#7cfc00','#ff6347']\ncol_link = dict(zip(visual_grp_21.Employment.unique(),color_s))\n\n#The default node colors are sufficient, but the links can be made more interesting. How many links are there?\n#There are 6 sources, and 26 outgoing links, that is 6*26 = 156. That is huge... Automate!!\n#Depending on the source, the links can be colored. Register that in the dataframe itself\n\nfor employ in col_link:\n    visual_grp_21.loc[visual_grp_21.Employment == employ,'color'] =  col_link[employ]\n\ncolor_link = visual_grp_21.color.values","88158173":"#Thickness of the flow path between the source and target depends on the value that is indexed. \nlink = dict(source = source, target = target, value = values,color=color_link)\nnode = dict(label = label, pad=50, thickness=5)\n\n#Building the Sankey chart JSON file\ndata = go.Sankey(link = link,node=node)\n#print(data)  Can be used to see the json file\n\nvisual_21 = go.Figure(data)\n\n#Adding the styles, colors to the graph sheet, along with the heading.\nvisual_21.update_layout(hovermode = 'x',title=\"Designation and their Salaries\",\n    font=dict(size = 10, color = 'white'),height=800,\n    paper_bgcolor='#fffafa')\nvisual_21.show()","51127179":"visual_grp_22 = Q10_df.groupby(['Reply_Choices'])['Counts'].sum().reset_index()\nvisual_22 = px.bar(data_frame=visual_grp_22,x='Counts',y='Reply_Choices',\n                   title='Cloud Computing Usage Distribution')\nvisual_22.update_layout(yaxis={'categoryorder':'total ascending'},height=700)\nvisual_22.show()\ndel visual_grp_22 #Removing the unwanted DF immediately","8aefdc12":" [Back to Contents](#cont)","c7983d56":" [Back to Contents](#cont)","855b9b46":" [Back to Contents](#cont)","2a1f2cd2":" [Back to Contents](#cont)","6e0ba549":" [Back to Contents](#cont)","e1a5151c":" [Back to Contents](#cont)","4143eb17":" [Back to Contents](#cont)","f8acd9fa":"The above visual is showing the counts based on education level, and the following products usage. \nWill be needing an helper function to get the necessary replies collected, and then aggregate them. \n\ncols_counter() function is written for the same. The function takes the source_dataframe, name of the column that will be the base,the question number that we are looking to query and what category it will belong to.\n\nStatistical programes used : can be found using the Q7 (Statistical Softwares)\n\nIDEs used : Q9 (IDEs)\n\nCloud Computing platform : Q10 (Cloud Platforms)\n\nCloud Computing products: Q27 (Cloud Products)\n\nBusiness Insight : Q34 (BI softwares)\n","ec0c552e":" [Back to Contents](#cont)","6a982fb5":"# <a id=\"vis_17\">Visual 17 : Subplots of multiple demographic spread<\/a>","11d615ae":" [Back to Contents](#cont)","a57c3a7b":"# <a id=\"vis_22\">Visual 22: Primary Cloud Computing Services used<\/a>","8074c8fc":" [Back to Contents](#cont)","79874075":"# <a id=\"vis_20\">Visual 20: Sankey Chart to see the flow of Kagglers in Gender<\/a>","f9d75122":" [Back to Contents](#cont)","da490e2f":"# <a id=\"vis_21\">Visual 21: Continuing with Sankey Chart with multiple Levels<\/a>","6398a37e":"# <a id=\"cont\">Contents<\/a>\n\nPS: Introduction, Purpose and the learnings are hidden in above cell, unhide to see the same...\n\n1. [Visual-1 : Distribution of the Kagglers by Gender and Age](#vis_1)\n2. [Visual-2 : Participating Nations](#vis_2)\n3. [Visual 3: Global Participation Based on Gender : Choropleth Map](#vis_3)\n4. [Visual-4 : Distribution of Software & Education](#vis_4)\n5. [Visual_5: Distribution of Profession with respect to Age](#vis_5)\n6. [Visual_6: Distribution of Machine Learning Experience](#vis_6)\n7. [Visual 7: Salary Range](#vis_7)\n8. [Visual_8 Salary Distribution based on the profession](#vis_8)\n9. [Visual 9: Kagglers and their Industry types](#vis_9)\n10. [Visual 10: Primary Databased tools use Distribution](#vis_10)\n11. [Visual 11 : Distribution of Business Intelligence tools](#vis_11)\n12. [Visual 12 : Population Distribution with the rendering of Table in same chart](#vis_12)\n13. [Visual 13: Global map of Kaggle participants](#vis_13)\n14. [Visual 14 : Treemap of the Kaggler distribution based on the Gender](#vis_14)\n15. [Visual 15: Funnel Chart of Country citizen participation](#vis_15)\n16. [Visual 16 : Mix of Treemap, Ribbon chart, Funnel and Pie charts](#vis_16)\n17. [Visual 17 : Subplots of multiple demographic spread](#vis_17)\n18. [Visual 18: Count of Employment and Gender by Country and Experience](#vis_18)\n19. [Visual 19: Trying the waterfall Chart (Will add Dropdown option for the countries)](#vis_19)\n20. [Visual 20: Sankey Chart to see the flow of Kagglers in Gender](#vis_20)\n21. [Visual 21: Continuing with Sankey Chart with multiple Levels](#vis_21)\n22. [Visual 22: Cloud computing usage Distribution](#vis_22)\n\nThe data creation step for the chart is laborious, if not planned from the beginning. Once we plan the sankey chart is a breath taking visual","73b35808":"# <a id=\"vis_9\">Visual 9: Kagglers and their Industry types<\/a> ","6b9bf601":"# <a id=\"vis_1\"> Visual-1 : Distribution of the Kagglers by Gender and Age<\/a>","457974c8":"# Appendix\n\n\nThere are 22 visuals (as of 9th Jan) lined up using the Kaggle 2021 survey data. Visuals were created to show, how easy it is to make, BI visualisation very easily with Python and Plotly. How well did it work?\n\nIt is phenomenal to see the visualisation come to life with a bit of programming knowledge. Most of the single plot visuals were walk in the park. The challenge arises when the subplots needed to be rendered. \n\nTreemap is super easy when using Plotly Express, but to render it as a subplot the Graph Objects have to be used. That is a biggest challenge that has taken most of time. Me being a beginner in Programming made it further challenging. (This is a work in progress)\n\nThe data is also useful for providing many quora answers, with data. Many out there, are still at the beginning stages of learning the power of Data. Need to thank Kaggle for sharing this data openly, so we can contribute by mining it.","02dc4d97":"# <a id=\"vis_15\">Visual 15: Funnel Chart of Country citizen participation<\/a>","da3755b1":" [Back to Contents](#cont)","c9c1c8a2":" [Back to Contents](#cont)","b9e129fb":" [Back to Contents](#cont)","365a0e9f":"# <a id=\"vis_3\"> Visual 3: Global Participation Based on Gender : Choropleth Map<\/a> ","6f93f30c":"# <a id=\"vis_16\">Visual 16 : Mix of Treemap, Ribbon chart, Funnel and Pie charts<\/a>","b3418aa5":"# <a id=\"vis_5\">Visual_5: Distribution of Profession with respect to Age<\/a>","6b3f6a6e":" [Back to Contents](#cont)","58bbfae7":"# <a id=\"vis_4\"> Visual-4 : Distribution of Software & Education<\/a> ","d141ff5b":"# <a id=\"vis_11\">Visual 11 : Distribution of Business Intelligence tools<\/a>","dd2fc9a5":" [Back to Contents](#cont)","070a6c12":"# <a id=\"vis_19\">Visual 19: Trying the waterfall Chart (Will add Dropdown option for the countries)<\/a>","2d894ba6":" [Back to Contents](#cont)","aa8e063b":"# <a id=\"vis_6\"> Visual 6 : Distribution of Machine Learning Experience<\/a>","2d134d46":"# <a id=\"vis_12\">Visual 12 : Population Distribution with the rendering of Table in same chart<\/a>","a4619acc":" [Back to Contents](#cont)","0ec8639b":"# <a id=\"vis_8\"> Visual_8 Salary Distribution based on the profession<\/a>","c9262429":" [Back to Contents](#cont)","0940cbf5":"# <a id=\"vis_18\">Visual 18: Count of Employment and Gender by Country and Experience<\/a>","cd13c8a7":"< updated the waterfall and sankey charts >\n    \n# Introduction\n\nInspiration for this notebook came from three places. One is to master the visualisation libraries, next is to learn story telling with the data, and finally the strong urge to match the visualisation that has been created using other BI\/ Visualisation tool. \n\n# Layout\n\nThe notebook will have simple pattern. The powerBI\/ Excel tool charts carry so much space, so I have removed them. The notebook cells are independent, so each cell can render the visual by themselves, after couple of initial cells are executed. The visual heading provides the info on the chart type. \n\n# Purpose\n\nTo achieve mastery, lot of training is required. The silver-bullet is getting feedback. This Data visualisation exercise will provide the necessary training. The feedback can be seen in the way graphs and charts render, and share the story that is hidden inside the data.\n\nLets dive in to the Kaggle survey 2021 and 2020 data keyboard first.\n\n# What you will Learn???\n\n1) Building Gorgeous Sankey Charts\n\n2) Waterfall charts using dataframes, and plotly\n\n3) Slicing and Dicing the datasets like a Pro (Inspired by PowerBI & Tableau Chart notebook)\n\n4) Relate to Funnel chart with ease\n\n5) Bring Multiple charts on to a single frame using Graph_objects \n\nlast but not the least, \n\n6) Learning to creat links in the within notebook to send the readers to \"exotic\" destinations in notebook (It took me 3 versions saving to understand it correctly and implement)\n\n7) Writing long code sections by stitching & commenting the experiments done on code snippets in seperate cells(You will see this, for many complicated looking charts. I did this to share my strategy to those new to Visualisation with Python and plotly)\n\nRare charts like Funnel, Sankey and Waterfall charts are seldom used by many new users. Stories these charts tell can be spell bindng. (click on [Visual 21](#vis_21) for a sneek peek). I felt, it is due to the lack of examples,that triggers ones imagination. I got the imagination from @Rahman notebook here.\nhttps:\/\/www.kaggle.com\/kalilurrahman\/2021-kaggle-mlds-survey-a-perspective?kernelSessionId=79811250\n\nThe charts rendered using PowerBI & Tableau is elegant, and must be easier to use. The challenge is when you really want to add some tweak, or a story anchor inside the chart. Plotly and Python's Pandas can be excellent work horses. Even in a hands of layman, with basic programming knowledge. \n\nThis notebook can be a quick reference. The code is not \"function\" friendly. It took some time to write the graphing commands directly. When certain option needs to be added, creates redundant complexity. You will find lot of tid-bits strewn in the code written for the plots... Enjoy","ca76fe40":"# <a id=\"vis_13\">Visual 13: Global map of Kaggle participants<\/a>","d35f6b42":" [Back to Contents](#cont)","364d6c41":" [Back to Contents](#cont)","001b51d4":" [Back to Contents](#cont)","51cbfc0f":"# <a id=\"vis_2\"> Visual-2 : Participating Nations<\/a>","e1f662d3":"# <a id=\"vis_10\">Visual 10: Primary Databased tools use Distribution<\/a>","4d29fc06":" [Back to Contents](#cont)","4c6cbe6d":"# <a id=\"vis_14\">Visual 14 : Treemap of the Kaggler distribution based on the Gender<\/a>","88e0436f":" [Back to Contents](#cont)","ef577992":"# <a id=\"vis_7\">Visual 7: Salary Range<\/a>"}}