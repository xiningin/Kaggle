{"cell_type":{"73b31143":"code","1a120586":"code","0e04da6b":"code","0cbbd79d":"code","f273b6d2":"code","d9e4eaf6":"code","e1b40ce8":"code","a1207922":"code","66a3b959":"code","9378e949":"code","adbdff9f":"code","b55846a7":"code","d914d952":"code","d51b1115":"code","fa3738d2":"code","18138a3c":"code","a44270ca":"markdown","18e1f510":"markdown","1f4cc600":"markdown","f1f28afe":"markdown","719c441e":"markdown","4211f441":"markdown","1c36ad7b":"markdown","b19f8408":"markdown"},"source":{"73b31143":"import numpy as np\nimport pandas as pd\nimport time","1a120586":"def create_list():\n    start_time = time.time()\n    \n    list = [x for x in range(100000)]\n    \n    print(f'time required : {time.time() - start_time}')\n    print(f'memory required : {list.__sizeof__()}')","0e04da6b":"def create_nparray():\n    start_time = time.time()\n    \n    array = np.array([x for x in range(100000)])\n    \n    print(f'time required : {time.time() - start_time}')\n    print(f'memory required : {array.__sizeof__()}')","0cbbd79d":"print('list ------------')\ncreate_list()\n\nprint('numpy.array ------------')\ncreate_nparray()","f273b6d2":"def create_64bits():\n    start_time = time.time()\n    \n    array = np.random.rand(100000)\n    \n    print(f'time required : {time.time() - start_time}')\n    print(f'memory required : {array.__sizeof__()}')","d9e4eaf6":"def create_32bits():\n    start_time = time.time()\n    \n    array = np.random.rand(100000).astype(np.float32)\n    \n    print(f'time required : {time.time() - start_time}')\n    print(f'memory required : {array.__sizeof__()}')","e1b40ce8":"def create_16bits():\n    start_time = time.time()\n    \n    array = np.random.rand(100000).astype(np.float16)\n    \n    print(f'time required : {time.time() - start_time}')\n    print(f'memory required : {array.__sizeof__()}')","a1207922":"print('64 bits ------------')\ncreate_64bits()\n\nprint('32 bits ------------')\ncreate_32bits()\n\nprint('16 bits ------------')\ncreate_16bits()","66a3b959":"array_accuracy = np.array([\n    12345678901234567890,     # big num\n    0.000000000000123456,     # small num\n    12345.67890123456789      # both\n])\n\n\nfor np_type in [np.float64, np.float32, np.float16]:\n    print(f'{np_type}')\n    array = array_accuracy.astype(np_type)\n    \n    for i in range(3):\n        print(array[i])\n\n# delete memory\ndel array_accuracy","9378e949":"print(np.iinfo(np.int64))\nprint(np.finfo(np.float16))","adbdff9f":"def reduce_mem_usage(df):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                       df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    return df","b55846a7":"# For example\n\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\n\nprint('original data ---------')\nprint(f'memory required : {train.__sizeof__()}')\n\ntrain.info()","d914d952":"\nstart_time = time.time()\ntrain = reduce_mem_usage(train)\n\nprint('reduce_mem_usage--------')\nprint(f'time required : {time.time() - start_time}')\nprint(f'memory required : {train.__sizeof__()}')\n\ntrain.info()","d51b1115":"# Read data\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\nprint(f'memory required : {train.__sizeof__()}')\n\n# Create pickle file\nstart_time = time.time()\n\ntrain.to_pickle('train_intermediate.pkl')\nprint(f'time required : {time.time() - start_time}')\n\ndel train","fa3738d2":"import pickle\nimport bz2\nPROTOCOL = pickle.HIGHEST_PROTOCOL\n\nclass ZpkObj:\n    def __init__(self, obj):\n        self.zpk_object = bz2.compress(pickle.dumps(obj, PROTOCOL), 9)\n    \n    def load(self):\n        return pickle.loads(bz2.decompress(self.zpk_object))","18138a3c":"# Read data\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\n\nprint('original data ---------')\nprint(f'memory required : {train.__sizeof__()}')\n\n# Compress\nstart_time = time.time()\ntrain = ZpkObj(train)\n\nprint('compressing ---------')\nprint(f'time required : {time.time() - start_time}')\nprint(f'memory required : {train.__sizeof__()}')\n\n# Solve\nstart_time = time.time()\ntrain = train.load()\n\nprint('solving ------------')\nprint(f'time required : {time.time() - start_time}')\nprint(f'memory required : {train.__sizeof__()}')","a44270ca":"You can also compress the data on memory.  \nYou must compress and solve data, as with the creation and loading of intermediate files.","18e1f510":"* np.float64  \n  It can handle numbers up to 16 digits.\n* np.float32  \n  It can handle numbers up to 7 digits.\n* np.float16  \n  It can handle numbers up to 4 digits.  \n  \nWe need to select the digits depending on the data.  \nYou can use `np.iinfo()` \/ `np.finfo()` method to check the maximum and minimum values of the data type.","1f4cc600":"## 1. Compare list to numpy array","f1f28afe":"As an example, use data from the Titanic.  \nIf you want to use the data in a separate process, you can extract it temporarily to a pickle file.","719c441e":"## 3. Create an intermediate file","4211f441":"Compare accuracy","1c36ad7b":"## 2. Change to 32 bits","b19f8408":"The following functions are used to convert all DataFrames as a whole."}}