{"cell_type":{"5d31b6b1":"code","a34c28bf":"code","bd961174":"code","eb9d4137":"code","34619fd5":"code","bc9c4550":"code","784d4838":"code","12e9a53c":"code","4a25b796":"code","b15441de":"code","bf4b8319":"code","49718453":"code","22961340":"code","e93cc69f":"code","b7c21214":"code","8ef6aacb":"code","f7cff7e6":"code","42e52985":"code","4b6076cc":"code","68e8ce6f":"code","7643efca":"code","53647b41":"code","614344c0":"code","ca8eb6db":"code","e7a9e7a3":"code","726b9bf4":"code","f6b9037e":"code","a614ec45":"code","b93fd068":"code","b9e1bb81":"code","eaa95de5":"code","4ac48f1a":"code","c0bb17b3":"code","03d2eacc":"code","ea421b3a":"markdown","c6690a1c":"markdown"},"source":{"5d31b6b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a34c28bf":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n","bd961174":"train.head() # for the name variable we can change it do it only has Miss or Mrs etc \n","eb9d4137":"print(train.shape)\nhas_null = train.isnull().sum()\nhas_null[has_null>0] # we see most are missing for cabin so we can just drop it ","34619fd5":"#first 891 are train\ndata = pd.concat([train,test ],ignore_index=True) #put them together so we can make changes together\ndata = data.drop(['Cabin'], axis=1)\nhas_null = data.isnull().sum()\nhas_null[has_null>0] #we ignore the missing feature for survived since they are all from the test set","bc9c4550":"data['Name']","784d4838":"#We see that every status ends with a dot\n\n#for name in data['Name']:\n#    by_comma = name.split(',')\n#    name = by_comma[1]\n#    name = name.split('.')[0].strip()\n\ndata['Status'] = data['Name'].str.extract(' ([A-Za-z]+\\.)')\ndata= data.drop(['Name','Ticket'], axis=1) #Ticket is the Ticket Number and this information does not seem relevent so we can drop it\ndata['Status']","12e9a53c":"print(data['Status'].unique())\ndata.head() ","4a25b796":"#fill missing age with mean of each status\ndata[\"Age\"] = data.groupby(\"Status\").transform(lambda x: x.fillna(x.mean()))","b15441de":"embark_mode = data['Embarked'].mode()[0]\nfare_mean = data['Fare'].mean()\nprint(embark_mode)\nprint(fare_mean)\ndata['Embarked']= data['Embarked'].fillna(embark_mode)\ndata['Fare'] = data['Fare'].fillna(fare_mean)","bf4b8319":"has_null = data.isnull().sum()\nhas_null[has_null>0] #So the only null is Survived which would all be in the test set which will later be seperated","49718453":"#now to deal with categorical variables\ndata = pd.get_dummies(data, columns = ['Sex', 'Status', 'Embarked'], drop_first = True)\ndata","22961340":"#now we seperatet the train and test data set recall first 891 rows are train data rest would be test data\ndf_train = data.iloc[:891,:]\ndf_test = data.iloc[891:,:]\nhas_null = df_train.isnull().sum()\nhas_null[has_null>0] # no missing survived features","e93cc69f":"print(df_test.shape)\nhas_null = df_test.isnull().sum()\nhas_null[has_null>0] #so all Survived missing as it should be so we can drop it","b7c21214":"df_test= df_test.drop(['Survived'], axis=1)\n","8ef6aacb":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score","f7cff7e6":"Y = df_train['Survived']\nX = df_train.drop(['Survived'], axis=1)\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state = 0)","42e52985":"#from sklearn.ensemble import RandomForestClassifier\n\n#rfc = RandomForestClassifier()\n#rfc.fit(X_train,Y_train)","4b6076cc":"#rfc_pred = rfc.predict(X_test)\n#r2_score(Y_test, rfc_pred)","68e8ce6f":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors= 7, weights='distance')\n\n#Train the model using the training sets\nknn.fit(X_train, Y_train)\n\n#Predict the response for test dataset\ny_pred = knn.predict(X_test)\nfrom sklearn import metrics\n\nmetrics.accuracy_score(Y_test, y_pred)","7643efca":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=42, n_estimators=700, max_leaf_nodes=32)\nrfc.fit(X_train, Y_train)\ny_pred = rfc.predict(X_test)\nmetrics.accuracy_score(Y_test, y_pred)","53647b41":"from xgboost import XGBClassifier\nxgb =  XGBClassifier(max_depth = 3, n_estimators = 700,learning_rate=0.02)\nxgb.fit(X_train, Y_train)\ny_pred = xgb.predict(X_test)\nmetrics.accuracy_score(Y_test, y_pred)","614344c0":"from sklearn.ensemble import GradientBoostingClassifier\ngbc =  GradientBoostingClassifier(learning_rate=0.11)\ngbc.fit(X_train, Y_train)\ny_pred = gbc.predict(X_test)\nmetrics.accuracy_score(Y_test, y_pred)","ca8eb6db":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nada =  AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),n_estimators=200)\nada.fit(X_train, Y_train)\ny_pred = ada.predict(X_test)\nmetrics.accuracy_score(Y_test, y_pred)","e7a9e7a3":"pred_xgb = xgb.predict(df_test)\npred_knn = knn.predict(df_test)\npred_ada = ada.predict(df_test)\npred_gbc = gbc.predict(df_test)\npred_rfc = rfc.predict(df_test)\n#use all 5 or all but knn and ada model since we want odd number of classifier and those 2 have the lowest accuracy","726b9bf4":"Models = {'XGB': pred_xgb, \n        'ADA': pred_ada, \n        'RFC': pred_rfc} \n\ndf = pd.DataFrame(Models, columns= ['XGB', 'ADA','RFC'])","f6b9037e":"df","a614ec45":"final = df.mode(axis=1)","b93fd068":"pred_xgb.shape","b9e1bb81":"predicted_survival = final.astype(int)\npredicted_survival","eaa95de5":"ans= np.reshape(predicted_survival, (418,))\nans = ans.values\nans =ans.reshape((418,))\nans","4ac48f1a":"ans.shape","c0bb17b3":"Y_test.shape","03d2eacc":"\nsubmission = pd.DataFrame(columns=['PassengerId', 'Survived'])\nsubmission['PassengerId'] = df_test['PassengerId']\nsubmission['Survived'] = ans\nsubmission.to_csv('submissions.csv', header=True, index=False)","ea421b3a":"**Part 2: Fit the model**\n\n#Classifiers to try ideas:\n\n-Gradient Boosting Classifier\n\n-Random Forest Classifier\n\n-XGB Classifer\n\n-KNN","c6690a1c":"> **Part 1: Feature Engineering**"}}