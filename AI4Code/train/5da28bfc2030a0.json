{"cell_type":{"4b51a913":"code","f4098891":"code","a463fdfa":"code","157f389d":"code","6518df04":"code","108a0b65":"code","d99791af":"code","e684d327":"code","307edf37":"code","9e6529e9":"code","f975a0a7":"code","13df6061":"code","01d37446":"code","a5562da9":"code","b939de90":"code","78c866d5":"code","7effdb41":"code","836db113":"code","74b13659":"code","4467eae0":"code","d1d98459":"code","b8e3b747":"code","2beb4da4":"code","a5067f70":"code","ebf21626":"code","d813d3fe":"code","f630c9fa":"code","a4a5e105":"code","e29f0211":"code","d54e8dce":"code","f5e28aa1":"code","9f232fc9":"code","aae14692":"code","04739584":"code","75857030":"code","b55d8b8b":"code","300dad3d":"code","775648cd":"code","a3d4a7fe":"code","61e6369c":"code","e12ce4d3":"code","9eb283a6":"code","b5fc9f39":"code","c7457894":"code","ce548983":"code","165e5329":"code","0d3c0b12":"code","7edfe179":"code","4259bfb1":"code","5bd51713":"code","8d8c97f7":"code","0fe65d9a":"markdown","767ea430":"markdown"},"source":{"4b51a913":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4098891":"from tensorflow.keras.datasets import mnist","a463fdfa":"(X_train,y_train),(X_test,y_test)=mnist.load_data()","157f389d":"X_train.shape","6518df04":"single_image=X_train[0]","108a0b65":"single_image.shape","d99791af":"single_image","e684d327":" plt.imshow(single_image)","307edf37":"y_train","9e6529e9":"from tensorflow.keras.utils import to_categorical","f975a0a7":"y_train.shape","13df6061":"y_example=to_categorical(y_train)","01d37446":"y_example.shape","a5562da9":"y_example[0]","b939de90":"y_cat_test=to_categorical(y_test,num_classes=10)","78c866d5":"y_cat_train=to_categorical(y_train,10)","7effdb41":"single_image.max()","836db113":"single_image.min()","74b13659":"X_train=X_train\/255","4467eae0":"X_test=X_test\/255","d1d98459":"scaled_image=X_train[0]","b8e3b747":"scaled_image","2beb4da4":"scaled_image.max()","a5067f70":"plt.imshow(scaled_image)","ebf21626":"X_train.shape","d813d3fe":"#batch_size,width,height,color_channels\nX_train=X_train.reshape(60000,28,28,1)","f630c9fa":"X_test=X_test.reshape(10000,28,28,1)","a4a5e105":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten","e29f0211":"model = Sequential()\n\n# CONVOLUTIONAL LAYER\nmodel.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(28, 28, 1), activation='relu'))\n#model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(28, 28, 1), activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128,activation=\"relu\"))\n\n\n#Output Layer SOFTMAX--> MULTI CLASS\n\nmodel.add(Dense(10,activation=\"softmax\"))\n\n#keras.io\/metrics\nmodel.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",\n             metrics=[\"accuracy\"])","d54e8dce":"model.summary()","f5e28aa1":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop=EarlyStopping(monitor=\"val_loss\",patience=1)","9f232fc9":"model.fit(X_train,y_cat_train,epochs=10,validation_data=(X_test,y_cat_test),callbacks=[early_stop])","aae14692":"model.metrics_names","04739584":"losses = pd.DataFrame(model.history.history)","75857030":"losses.head()","b55d8b8b":"losses[['accuracy','val_accuracy']].plot()","300dad3d":"losses[['loss','val_loss']].plot()","775648cd":"print(model.metrics_names)\nprint(model.evaluate(X_test,y_cat_test,verbose=0))","a3d4a7fe":"from sklearn.metrics import classification_report,confusion_matrix","61e6369c":"predictions = model.predict_classes(X_test)","e12ce4d3":"y_cat_test.shape","9eb283a6":"y_cat_test[0]","b5fc9f39":"predictions[0]","c7457894":"y_test","ce548983":"print(classification_report(y_test,predictions))","165e5329":"confusion_matrix(y_test,predictions)","0d3c0b12":"import seaborn as sns","7edfe179":"plt.figure(figsize=(10,6))\nsns.heatmap(confusion_matrix(y_test,predictions),annot=True)\n# https:\/\/github.com\/matplotlib\/matplotlib\/issues\/14751","4259bfb1":"my_number = X_test[0]","5bd51713":"plt.imshow(my_number.reshape(28,28))","8d8c97f7":"# SHAPE --> (num_images,width,height,color_channels)\nmodel.predict_classes(my_number.reshape(1,28,28,1))","0fe65d9a":"Looks like the CNN performed quite well!","767ea430":"# Predicting a given image"}}