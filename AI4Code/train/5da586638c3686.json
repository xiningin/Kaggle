{"cell_type":{"503e25d2":"code","d65b8a4d":"code","a83f3f22":"code","9dc75729":"code","1dcf80c2":"code","c7718b37":"code","be97e23c":"code","8321566a":"code","314dad42":"code","a6ad0cba":"code","24671049":"code","39315304":"code","00647d36":"code","0815c753":"code","02bf5b51":"code","acafd719":"code","b4e3f10f":"code","ea1a4cca":"code","ef61d0d9":"code","fca6722e":"code","e2ac2e07":"code","8cf2fe74":"code","e1156ed5":"code","8ee0dbad":"code","6d7e53b9":"code","94459718":"code","b229ddbe":"code","0b557fcd":"code","69d5092b":"code","83abe4ad":"code","3152aa05":"code","6f865169":"code","ee50e43f":"code","baeeab55":"code","f9bc93ef":"code","d2eeff67":"code","574f8fb9":"code","677dd5dc":"code","6d477240":"code","d921f031":"code","576ebd75":"code","d89adfbc":"code","6b30fb9d":"code","fd674351":"markdown","472dc25c":"markdown","d17a87cf":"markdown","6fe6e36d":"markdown","fce90f50":"markdown","0542ee69":"markdown","431977f4":"markdown","ffefa684":"markdown","79fc6d14":"markdown","8b4efc65":"markdown","454af313":"markdown","63d2f95a":"markdown","88df8c2e":"markdown","ebf467fb":"markdown","83d3de9f":"markdown","cdc445d0":"markdown"},"source":{"503e25d2":"import os\nimport gc\nimport glob\nimport itertools\nimport collections\nimport joblib\n\nfrom PIL import Image\nfrom PIL import ImageFile\n# sometimes, you will have images without an ending bit\n# this takes care of those kind of (corrupt) images\nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport cv2\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nimport numpy as np\nimport torch\nimport imagehash\n\nimport matplotlib.pyplot as plt\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\npd.set_option('max_columns', None)\nDEBUG = False\nSEED=56\n%matplotlib inline","d65b8a4d":"train = pd.read_csv(\"..\/input\/rakuten-multimodal-colour-extraction\/X_train.csv\", usecols=[\"image_file_name\", \"item_name\", \"item_caption\"])\ntest = pd.read_csv(\"..\/input\/rakuten-multimodal-colour-extraction\/X_test.csv\", usecols=[\"image_file_name\", \"item_name\", \"item_caption\"])\ntarget = pd.read_csv('..\/input\/rakuten-multimodal-colour-extraction\/y_train.csv', usecols=['color_tags'])\ntrain = pd.concat([train, target], axis=1)\n\nif DEBUG:\n    train = train.sample(n=1000, random_state=SEED).reset_index(drop=True)\n    test = test.sample(n=10000, random_state=SEED).reset_index(drop=True)\ndef get_file_paths(image_id):\n    return f\"..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{image_id}\"\ntrain['file_paths'] = train['image_file_name'].apply(get_file_paths)\ntest['file_paths'] = test['image_file_name'].apply(get_file_paths)\ntrain['id'] = train['image_file_name'].apply(lambda x:x.split('.')[0])\ntest['id'] = test['image_file_name'].apply(lambda x:x.split('.')[0])\n\nclean_tags = lambda x: [e.replace(\"'\", \"\")  for e in x[1:-1].split(', ')]\n\ntrain['color_tags'] = train['color_tags'].apply(clean_tags)\n\n\ndel target\n_ = gc.collect()","a83f3f22":"train.head()","9dc75729":"train.shape","1dcf80c2":"# Remove '_' from file image name\ntrain['image_file_name_cleaned'] = train['image_file_name'].apply(lambda x: x.replace(\"_\", \"\"))\ntest['image_file_name_cleaned'] = test['image_file_name'].apply(lambda x: x.replace(\"_\", \"\"))","c7718b37":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = 'rakuten-multimodal-colour-extraction-cleaned\/images\/images\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","be97e23c":"%%time\nempty_images = []\nfor path in tqdm(train['file_paths'].values):\n    \n    try:\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    except:\n        imageid = path.split('\/')[-1].split('.')[0]\n        empty_images.append(imageid)","8321566a":"train_new = train[~train[\"id\"].isin(empty_images)]\ntrain_new = train_new.reset_index(drop=True)","314dad42":"train_new.shape","a6ad0cba":"def run():\n\n    funcs = [\n        imagehash.average_hash,\n        imagehash.phash,\n        imagehash.dhash,\n        imagehash.whash,\n    ]\n    \n    imgids = []\n    hashes = []\n   \n\n    for path in tqdm(train_new['file_paths'].values):\n\n        image = Image.open(path)\n        imageid = path.split('\/')[-1].split('.')[0]\n        imgids.append(imageid)\n        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\n\n        \n\n    return imgids, np.array(hashes)\nif DEBUG == True:\n    %time imageids, hashes_all = run()\n    hashes_all = torch.Tensor(hashes_all.astype(np.int_)).to(device)\n    %time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()\/256 for i in tqdm(range(hashes_all.shape[0]))])","24671049":"def show_pairs(data, lower_sim=0.0, upper_sim=1.0, max_shown=100):\n    indices1 = np.where((sims > lower_sim) & (sims <= upper_sim))\n    indices2 = np.where(indices1[0] != indices1[1])\n    dups = {tuple(sorted([imageids[index1], imageids[index2]])): sims[index1, index2] \n                for index1, index2 in zip(indices1[0][indices2], indices1[1][indices2])}\n    print('Found %d pairs' % len(dups))\n    \n    cnt = 1\n    for (id1, id2), sim in dups.items():\n        path1 = f'..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{id1}.jpg'\n        path2 = f'..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{id2}.jpg'\n        image1 = data[data['image_file_name'] == id1]['color_tags']\n        image2 = data[data['image_file_name'] == id2]['color_tags']\n\n        image1 = Image.open(path1)\n        image2 = Image.open(path2)\n        \n        \n        fig, axes = plt.subplots(nrows=1, ncols=2)\n        fig.set_size_inches(12, 6)\n        axes[0].title.set_text(f'color_tags: {image1} \\n ID: {id1}')\n        axes[0].imshow(image1)\n        axes[1].title.set_text(f'color_tags: {image2} \\n ID: {id2}')\n        axes[1].imshow(image2)\n        fig.suptitle(f'Simularity: {sim}')\n        plt.show()\n        \n        if cnt >= max_shown:\n            break\n        \n        cnt += 1\n    \n    return dups","39315304":"%%time\nif DEBUG == True:\n    dups = show_pairs(train_new, 0.985, 1.0, max_shown=50)\n    dups","00647d36":"id_image = '203443_11508012_1'\nimage_path = f'..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{id_image}.jpg'\nimage = Image.open(image_path)\nwhash_id = str(imagehash.whash(image))\nremove_dup1 = []\n\nfor path in tqdm(train_new['file_paths'].values):\n    \n    image = Image.open(path)\n    imageid = path.split('\/')[-1].split('.')[0]\n    whash = str(imagehash.whash(image))\n    if whash_id == whash:\n        remove_dup1.append(imageid)","0815c753":"len(remove_dup1)","02bf5b51":"id_image = '284888_10999001_1'\nimage_path = f'..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{id_image}.jpg'\nimage = Image.open(image_path)\nwhash_id = str(imagehash.whash(image))\nremove_dup2 = []\n\nfor path in tqdm(train_new['file_paths'].values):\n    \n    image = Image.open(path)\n    imageid = path.split('\/')[-1].split('.')[0]\n    whash = str(imagehash.whash(image))\n    if whash_id == whash:\n        remove_dup2.append(imageid)","acafd719":"len(remove_dup2)","b4e3f10f":"id_image = '220897_10345754_1'\nimage_path = f'..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{id_image}.jpg'\nimage = Image.open(image_path)\nwhash_id = str(imagehash.whash(image))\nremove_dup3 = []\n\nfor path in tqdm(train_new['file_paths'].values):\n    \n    image = Image.open(path)\n    imageid = path.split('\/')[-1].split('.')[0]\n    whash = str(imagehash.whash(image))\n    if whash_id == whash:\n        remove_dup3.append(imageid)","ea1a4cca":"len(remove_dup3)","ef61d0d9":"id_image = '284888_10876002_1'\nimage_path = f'..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{id_image}.jpg'\nimage = Image.open(image_path)\nwhash_id = str(imagehash.whash(image))\nremove_dup4 = []\n\nfor path in tqdm(train_new['file_paths'].values):\n    \n    image = Image.open(path)\n    imageid = path.split('\/')[-1].split('.')[0]\n    whash = str(imagehash.whash(image))\n    if whash_id == whash:\n        remove_dup4.append(imageid)","fca6722e":"len(remove_dup4)","e2ac2e07":"id_image = '334847_10001441_1'\nimage_path = f'..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{id_image}.jpg'\nimage = Image.open(image_path)\nwhash_id = str(imagehash.whash(image))\nremove_dup5 = []\n\nfor path in tqdm(train_new['file_paths'].values):\n    \n    image = Image.open(path)\n    imageid = path.split('\/')[-1].split('.')[0]\n    whash = str(imagehash.whash(image))\n    if whash_id == whash:\n        remove_dup5.append(imageid)","8cf2fe74":"len(remove_dup5)","e1156ed5":"id_image = '193564_10031200_1'\nimage_path = f'..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{id_image}.jpg'\nimage = Image.open(image_path)\nwhash_id = str(imagehash.whash(image))\nremove_dup6 = []\n\nfor path in tqdm(train_new['file_paths'].values):\n    \n    image = Image.open(path)\n    imageid = path.split('\/')[-1].split('.')[0]\n    whash = str(imagehash.whash(image))\n    if whash_id == whash:\n        remove_dup6.append(imageid)","8ee0dbad":"len(remove_dup6)","6d7e53b9":"remove_dup = remove_dup1+remove_dup2+remove_dup3+remove_dup4+remove_dup5+remove_dup6\ntrain_new = train[~train['id'].isin(remove_dup)]\ntrain_new = train_new.reset_index(drop=True)\ndel remove_dup, remove_dup1, remove_dup2, remove_dup3, remove_dup4, remove_dup5\n_ = gc.collect()","94459718":"train_new.shape","b229ddbe":"def clean_resize_image(path):\n    \n    imageid = path.split('\/')[-1].split('.')[0]\n    imageid = imageid.replace(\"_\", \"\")\n    \n    try:\n        \n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (128, 128))\n        cv2.imwrite(f'rakuten-multimodal-colour-extraction-cleaned\/images\/images\/{imageid}.jpg', image)\n        \n    except:\n        pass","0b557fcd":"_ = joblib.Parallel(n_jobs=-1)(\n    joblib.delayed(clean_resize_image)(file_path) for file_path in tqdm(train['file_paths'].values)\n)","69d5092b":"train_new['item_caption'] = train_new['item_caption'].fillna(\"not found\")\ntest['item_caption']  = test['item_caption'].fillna(\"not found\")","83abe4ad":"train_new.shape","3152aa05":"%%time\ntrain['item_caption_cleaned'] = \"a\"\nfor i in tqdm(range(train.shape[0])):\n    if train['item_caption'][i] == 'not found':\n        train['item_caption_cleaned'][i] = f'\u30a2\u30a4\u30c6\u30e0\u540d{train.item_name[i]}\u306e\u753b\u50cf\u304c\u3042\u308a\u307e\u305b\u3093'\n    else:\n        train['item_caption_cleaned'][i] = train.item_name[i]\n        \ntest['item_caption_cleaned'] = \"a\"\nfor i in tqdm(range(test.shape[0])):\n    if test['item_caption'][i] == 'not found':\n        test['item_caption_cleaned'][i] = f'\u30a2\u30a4\u30c6\u30e0\u540d{test.item_name[i]}\u306e\u753b\u50cf\u304c\u3042\u308a\u307e\u305b\u3093'\n    else:\n        test['item_caption_cleaned'][i] = test.item_name[i]","6f865169":"def run_test():\n\n    funcs = [\n        imagehash.average_hash,\n        imagehash.phash,\n        imagehash.dhash,\n        imagehash.whash,\n    ]\n    \n    imgids = []\n    hashes = []\n   \n\n    for path in tqdm(test['file_paths'].values):\n\n        try:\n            image = Image.open(path)\n        except:\n            continue\n        imageid = path.split('\/')[-1].split('.')[0]\n        imgids.append(imageid)\n        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\n\n        \n\n    return imgids, np.array(hashes)\nif DEBUG == True:\n    %time imageids, hashes_all = run_test()\n    hashes_all = torch.Tensor(hashes_all.astype(np.int_)).to(device)\n    %time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()\/256 for i in tqdm(range(hashes_all.shape[0]))])","ee50e43f":"def show_pairs(data, lower_sim=0.0, upper_sim=1.0, max_shown=100):\n    indices1 = np.where((sims > lower_sim) & (sims <= upper_sim))\n    indices2 = np.where(indices1[0] != indices1[1])\n    dups = {tuple(sorted([imageids[index1], imageids[index2]])): sims[index1, index2] \n                for index1, index2 in zip(indices1[0][indices2], indices1[1][indices2])}\n    print('Found %d pairs' % len(dups))\n    \n    cnt = 1\n    for (id1, id2), sim in dups.items():\n        path1 = f'..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{id1}.jpg'\n        path2 = f'..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{id2}.jpg'\n        #image1 = data[data['image_file_name'] == id1]['color_tags']\n        #image2 = data[data['image_file_name'] == id2]['color_tags']\n\n        image1 = Image.open(path1)\n        image2 = Image.open(path2)\n        \n        \n        fig, axes = plt.subplots(nrows=1, ncols=2)\n        fig.set_size_inches(12, 6)\n        axes[0].title.set_text(f'color_tags: \\n ID: {id1}')\n        axes[0].imshow(image1)\n        axes[1].title.set_text(f'color_tags: \\n ID: {id2}')\n        axes[1].imshow(image2)\n        fig.suptitle(f'Simularity: {sim}')\n        plt.show()\n        \n        if cnt >= max_shown:\n            break\n        \n        cnt += 1\n    \n    return dups","baeeab55":"if DEBUG:\n    test_dups = show_pairs(test, 0.985, 1.0, max_shown=50)\n    test_dups","f9bc93ef":"%%time\nempty_images_test = []\nfor path in tqdm(test['file_paths'].values):\n    \n    try:\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    except:\n        imageid = path.split('\/')[-1].split('.')[0]\n        empty_images_test.append(imageid)","d2eeff67":"len(empty_images_test)","574f8fb9":"id_image = '333354_10004065_1'\nimage_path = f'..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{id_image}.jpg'\nimage = Image.open(image_path)\nwhash_id = str(imagehash.whash(image))\nremove_dup_test = []\n\nfor path in tqdm(test['file_paths'].values):\n    \n    try:\n        image = Image.open(path)\n    except:\n        continue\n    imageid = path.split('\/')[-1].split('.')[0]\n    whash = str(imagehash.whash(image))\n    if whash_id == whash:\n        remove_dup_test.append(imageid)","677dd5dc":"id_image = '203443_11497543_1'\nimage_path = f'..\/input\/rakuten-multimodal-colour-extraction\/images\/images\/{id_image}.jpg'\nimage = Image.open(image_path)\nwhash_id = str(imagehash.whash(image))\nremove_empty_test = []\n\nfor path in tqdm(test['file_paths'].values):\n    \n    image = Image.open(path)\n    imageid = path.split('\/')[-1].split('.')[0]\n    whash = str(imagehash.whash(image))\n    if whash_id == whash:\n        remove_empty_test.append(imageid)","6d477240":"path.index","d921f031":"empty_images_test = np.array(list(set(empty_images_test+remove_empty_test)))\nremove_dup_test = np.array(remove_dup_test)\nnp.save('rakuten-multimodal-colour-extraction-cleaned\/dup_test', remove_dup_test)\nnp.save('rakuten-multimodal-colour-extraction-cleaned\/empty_test', empty_images_test)","576ebd75":"test['predictions'] = None\nfor i in range(test.shape[0]):\n    test['predictions'][i] = [i for i in range(19)]","d89adfbc":"for i in range(empty_images_test.shape[0]):\n    test.loc[test['id'] == i, 'predictions'] = ['White']","6b30fb9d":"train_new.to_csv('rakuten-multimodal-colour-extraction-cleaned\/cleaned_train.csv', index=False)\ntest.to_csv('rakuten-multimodal-colour-extraction-cleaned\/cleaned_test.csv', index=False)","fd674351":"# Resize images","472dc25c":"# Calculate hash values of every train image","d17a87cf":"# Duplicates for test data","6fe6e36d":"# Create new Dataset","fce90f50":"# Remove duplicate image id 334847_10001441_1","0542ee69":"# Remove duplicate image id 284888_10876002_1","431977f4":"# Remove duplicate image id 193564_10031200_1","ffefa684":"# Clean Image description","79fc6d14":"# Remove empty and gif Images","8b4efc65":"# Directory settings","454af313":"# Remve duplicate image id 284888_10999001_1","63d2f95a":"# Remove duplicate image id 220897_10345754_1","88df8c2e":"# P\u00f6stprocess Test dat","ebf467fb":"# Load data","83d3de9f":"# Library","cdc445d0":"# Remve duplicate image id 203443_11508012_1"}}