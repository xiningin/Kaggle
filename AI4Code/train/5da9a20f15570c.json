{"cell_type":{"7235bb6f":"code","da006852":"code","af741bff":"code","312b09b5":"code","12fdcf32":"code","e5d945d3":"code","3ada4845":"code","56b12629":"code","d7c44875":"code","500e20ae":"code","f167db16":"code","fa75a4de":"code","46d5f03e":"code","9adcd646":"code","a69eaefa":"code","d355210d":"code","67d8fd06":"code","35971ac6":"code","2a6a15d6":"code","6bb98162":"code","e4134898":"code","ea843b3c":"code","d1cf3aff":"code","52bdb0b9":"code","2f1efd64":"code","b203c20e":"code","3869504f":"code","ef874434":"code","b64ec042":"code","c5849e8b":"code","74bd4ce0":"code","f1faf3a5":"code","5aede898":"code","5a9c6526":"code","720e271f":"code","9c263178":"code","1a7252bd":"code","2259c2ac":"code","611a339f":"code","85c97c02":"code","5ea559b4":"code","94b7e304":"code","92899eb4":"code","5483c55a":"markdown","6edabcf3":"markdown","68404954":"markdown","15e70e76":"markdown","b6b7c43c":"markdown","621b1f2b":"markdown","9f792651":"markdown"},"source":{"7235bb6f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport os\nfrom scipy.io.wavfile import read\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio\nimport pathlib\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\nfrom sklearn.metrics import roc_curve, RocCurveDisplay, auc\n\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\n\nfrom sklearn.utils.class_weight import compute_class_weight\n\n\n# Pandas settings to display more dataset rows and columns\npd.set_option('display.max_rows', 150)\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', None)\npd.set_option('display.float_format', lambda x: '%.5f' % x)","da006852":"# Fixing random seeds for repeatability\ntf.random.set_seed(42)\nnp.random.seed(42)","af741bff":"# Scanning test and train data folders and creating filename lists\ntest_filenames = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/id-rd-test-dataset\/Testing_Data_MLTASK\/Testing_Data'):\n    for filename in filenames:\n        test_filenames.append(os.path.join(dirname, filename))\ntest_filenames.sort()\nprint(f\"Files in the test data folder: {len(test_filenames)}\")\nprint(test_filenames[:5])\n\nspoof_filenames = []\nhuman_filenames = []\nfiles = 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/id-rd-test-dataset\/training_data\/Training_Data\/spoof'):\n    for filename in filenames:\n        spoof_filenames.append(os.path.join(dirname, filename))\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/id-rd-test-dataset\/training_data\/Training_Data\/human'):\n    for filename in filenames:\n        human_filenames.append(os.path.join(dirname, filename))\n    \nprint(f\"\\nFiles in the train spoof data folder: {len(spoof_filenames)}\")\nprint(spoof_filenames[:5])\nprint(f\"\\nFiles in the train human data folder: {len(human_filenames)}\")\nprint(human_filenames[:5])","312b09b5":"# An example of a real human voice\nAudio(human_filenames[0])","12fdcf32":"# An example of a generated human voice\nAudio(spoof_filenames[0])","e5d945d3":"# Reading data from a WAVE file using scipy function and plotting it\nsample_rate, audio = read(human_filenames[0])\nplt.plot(audio)","3ada4845":"# # Determining maximum sample audio length\n# all_filenames = pd.concat([pd.Series(human_filenames), pd.Series(spoof_filenames), pd.Series(test_filenames)])\n# all_filenames.reset_index(inplace=True, drop=True)\n\n# audio_len = []\n# sample_rates = []\n# for filename in all_filenames:\n#     sample_rate, audio = read(filename)\n#     audio_len.append(len(audio))\n#     sample_rates.append(sample_rate)\n\n# max_audio_length = max(audio_len)\n\n# print(f\"Maximum audio length in train and test data is: {max_audio_length}\")\n# print(f\"Sample rates values distribution:\")\n# pd.Series(sample_rates).value_counts()","56b12629":"# Setting maximum audio length which is 3 sec for 16000 sample rate\nmax_audio_length = 48000","d7c44875":"def get_audio_spectrogram(filename, max_audio_length=max_audio_length):\n    \"\"\"\n    Decodes a file using given filename and cuts it or adds a pad depending on maximum length set. \n    Then transforms the audio data into a spectrogram. Returns both audio spectrogram data.\n    \"\"\"\n    \n    audio, sample_rate = tf.audio.decode_wav(tf.io.read_file(filename))\n    audio = tf.squeeze(audio, axis=-1)\n    audio = tf.cast(audio, tf.float32)\n    \n    if len(audio) < max_audio_length:\n        zeros = tf.zeros(max_audio_length - len(audio))\n        audio = tf.concat([audio, zeros], 0)\n    else: \n        audio = audio[:max_audio_length]\n    \n    spectrogram = tf.signal.stft(audio, frame_length=256, frame_step=128)\n    spectrogram = tf.abs(spectrogram)\n\n    return audio, spectrogram","500e20ae":"def plot_spectrogram(spectrogram, ax):\n    \"\"\"\n    Converts frequencies to log scale and transpose so that the time is\n    represented in the x-axis (columns). An epsilon is added to avoid log of zero.\n    \"\"\"\n    log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n    height = log_spec.shape[0]\n    width = log_spec.shape[1]\n    X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n    Y = range(height)\n    ax.pcolormesh(X, Y, log_spec)","f167db16":"# Getting a spectrogram\naudio, spectrogram = get_audio_spectrogram(human_filenames[0])\n\n# Plotting audio data (waveform) and spectrogram of a part of a given file.\nfig, axes = plt.subplots(2, figsize=(12, 8))\ntimescale = np.arange(audio.shape[0])\naxes[0].plot(timescale, audio.numpy())\naxes[0].set_title('Waveform')\naxes[0].set_xlim([0, 16000])\nplot_spectrogram(spectrogram.numpy(), axes[1])\naxes[1].set_title('Spectrogram')\naxes[1].set_xlim([0, 16000])\nplt.show()","fa75a4de":"# Creating a dataframe of filenames and labels for train data\ntrain_df = pd.DataFrame(columns=[\"filename\", \"label\"])\ntrain_df[\"filename\"] = human_filenames\ntrain_df[\"label\"] = np.ones(len(human_filenames)).astype(int)\n\nspoof_df = pd.DataFrame(columns=[\"filename\", \"label\"])\nspoof_df[\"filename\"] = spoof_filenames\nspoof_df[\"label\"] = np.zeros(len(spoof_filenames)).astype(int)\n\ntrain_df = pd.concat([train_df, spoof_df], axis=0)\ntrain_df.reset_index(inplace=True, drop=True)\ntrain_df","46d5f03e":"# Data split into train and valid\n# train, valid = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df[\"label\"])\nskf = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\nfor num, (train_idx, valid_idx) in enumerate(skf.split(train_df, train_df[\"label\"])):\n    if num == 4:\n        train = train_df.loc[train_idx].copy()\n        valid = train_df.loc[valid_idx].copy()\ntrain[\"label\"].value_counts()[0] \/ train[\"label\"].value_counts()[1]","9adcd646":"# Checking if hte proportion of labels is the same after splitting\ntrain_df[\"label\"].value_counts()[0] \/ train_df[\"label\"].value_counts()[1]","a69eaefa":"train","d355210d":"valid","67d8fd06":"# Creating tensors from dataframes\ntrain_pre_ds = tf.data.Dataset.from_tensor_slices((tf.constant(train[\"filename\"]), tf.constant(train[\"label\"])))\nvalid_pre_ds = tf.data.Dataset.from_tensor_slices((tf.constant(valid[\"filename\"]), tf.constant(valid[\"label\"])))\n# For test data there are no labels so it is filled with zeros to maitain the same tensor shape\ntest_pre_ds = tf.data.Dataset.from_tensor_slices((tf.constant(test_filenames), tf.constant(tf.zeros(len(test_filenames)))))\n\n# Checking the results\nfor element in train_pre_ds.take(3):\n    print(element)\nfor element in valid_pre_ds.take(3):\n    print(element)\nfor element in test_pre_ds.take(3):\n    print(element)","35971ac6":"def get_spectrogram_and_label(filename, label, max_audio_length=max_audio_length):\n    \"\"\"\n    Decodes a file using given filename and cuts it or adds a pad depending on maximum length set. \n    Then transforms the audio data into a spectrogram. Returns both spectrogram data and a given label.\n    \"\"\"\n    audio, sample_rate = tf.audio.decode_wav(tf.io.read_file(filename))\n    audio = tf.squeeze(audio, axis=-1)\n\n    audio = tf.cast(audio, tf.float32)\n    \n    if len(audio) < max_audio_length:\n        zeros = tf.zeros(max_audio_length - len(audio))\n        audio = tf.concat([audio, zeros], 0)\n    else: \n        audio = audio[:max_audio_length]\n    \n    spectrogram = tf.signal.stft(audio, frame_length=255, frame_step=128)\n    spectrogram = tf.abs(spectrogram)\n    spectrogram = tf.expand_dims(spectrogram, -1)\n    \n    return spectrogram, label","2a6a15d6":"# Transforming tensors into spectrogram-label pairs.\ntrain_ds = train_pre_ds.map(get_spectrogram_and_label)\nvalid_ds = valid_pre_ds.map(get_spectrogram_and_label)\ntest_ds = test_pre_ds.map(get_spectrogram_and_label)\n\nprint(f\"Train length: {len(train_ds)}\\nValid length:{len(valid_ds)}\\nTest length:{len(test_ds)}\")\n\n# Checking results\nfor element in train_ds.take(1):\n    print(element)\nfor element in valid_ds.take(1):\n    print(element) \nfor element in test_ds.take(1):\n    print(element)","6bb98162":"# Plotting random spectrograms from the train dataset\nrows = 5\ncols = 5\nn = rows*cols\nfig, axes = plt.subplots(rows, cols, figsize=(16, 16))\nfor i, (spectrogram, label) in enumerate(train_ds.take(n)):\n    r = i \/\/ cols\n    c = i % cols\n    ax = axes[r][c]\n    plot_spectrogram(np.squeeze(spectrogram.numpy()), ax)\n    ax.set_title(label.numpy())\n    ax.axis('off')\n\nplt.show();","e4134898":"# Getting tensor shape \nfor spectrogram, _ in train_ds.take(1):\n    input_shape = spectrogram.shape\nprint(input_shape)","ea843b3c":"# Making batches\nbatch_size = 32\ntrain_ds = train_ds.batch(batch_size)\nvalid_ds = valid_ds.batch(batch_size)","d1cf3aff":"# Computing label class weights to be used as NN parameter\nclass_weights = compute_class_weight(class_weight=\"balanced\", classes=[0, 1], y=train_df[\"label\"].values)\nclass_weights_dict={}\nfor label in [0, 1]:\n    class_weights_dict[label] = class_weights[label]\nclass_weights_dict","52bdb0b9":"%%time\n\n# Setting up normalization layer\nnorm_layer = preprocessing.Normalization()\nnorm_layer.adapt(train_ds.map(lambda x, _: x))","2f1efd64":"# Setting up model layers\nmodel = models.Sequential([\n    layers.Input(shape=input_shape),\n    preprocessing.Resizing(64, 64), \n    norm_layer,\n    layers.Conv2D(32, 5, activation='relu', padding=\"same\"),\n    layers.Conv2D(32, 5, activation='relu', padding=\"same\"),\n    layers.MaxPooling2D(2),\n    layers.Conv2D(64, 3, activation='relu', padding=\"same\"),\n    layers.Conv2D(64, 3, activation='relu', padding=\"same\"),\n    layers.MaxPooling2D(2),\n    layers.Conv2D(128, 3, activation='relu', padding=\"same\"),\n    layers.Conv2D(128, 3, activation='relu', padding=\"same\"),\n    layers.MaxPooling2D(2),\n    layers.Conv2D(256, 3, activation='relu', padding=\"same\"),\n    layers.Conv2D(256, 3, activation='relu', padding=\"same\"),\n    layers.MaxPooling2D(2),\n    layers.Flatten(),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1, activation=\"sigmoid\"),\n])\n\nmodel.summary()","b203c20e":"# Number of training epochs\nEPOCHS = 22\n\n# Reducing learning rate during training\nnum_train_steps = int(len(train_ds) \/ 32) * EPOCHS\ndecay_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n      initial_learning_rate=0.001,\n      decay_steps=num_train_steps,\n      end_learning_rate=0.00005)\n\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate = decay_schedule),\n    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n    metrics=['AUC', 'FalsePositives', 'FalseNegatives', 'BinaryAccuracy'],\n)","3869504f":"%%time\nhistory = model.fit(\n                    train_ds,\n                    validation_data=valid_ds,  \n                    epochs=EPOCHS,\n                    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=10, restore_best_weights=True),\n                    class_weight=class_weights_dict\n                    )","ef874434":"metrics = history.history\nplt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\nplt.legend(['loss', 'val_loss'])\nplt.show()","b64ec042":"metrics = history.history\nplt.plot(history.epoch, metrics['auc'], metrics['val_auc'])\nplt.legend(['auc', 'val_auc'])\nplt.show()","c5849e8b":"metrics = history.history\nplt.plot(history.epoch, \n         metrics['val_false_positives'], metrics['val_false_negatives'])\nplt.legend(['val_false_positives', 'val_false_negatives'])\nplt.show()","74bd4ce0":"metrics = history.history\nplt.plot(history.epoch, \n         metrics['binary_accuracy'], metrics['val_binary_accuracy'])\nplt.legend(['BinaryAccuracy', 'val_BinaryAccuracy'])\nplt.show()","f1faf3a5":"%%time\ny_preds = model.predict(valid_ds)\ny_preds[:10]","5aede898":"# Firs 10 audio files to compare with first 10 predictions above\nfor i in range(10):\n    display(Audio(valid.iloc[i][\"filename\"]))","5a9c6526":"# Checking amount of predictions per label\nprint((y_preds > 0.5).sum(), (y_preds < 0.5).sum())\npd.Series(y_preds.flatten()).hist(bins=20)","720e271f":"# Distribution of true labels\ny_true = valid[\"label\"].copy()\ny_true.value_counts()","9c263178":"# Calculating EER (Equal error rate)\nfpr, tpr, threshold = roc_curve(y_true, y_preds)\nfnr = 1 - tpr\nEER = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\nEER","1a7252bd":"# Plotting ROC curve\nroc_auc = auc(fpr, tpr)\nroc_auc_plot = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\nroc_auc_plot.plot()  \nplt.show()  ","2259c2ac":"# Creating a sorted list of test filenames without filepaths\ntest_pred_filenames = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/id-rd-test-dataset\/Testing_Data_MLTASK\/Testing_Data'):\n    for filename in filenames:\n        test_pred_filenames.append(filename)\ntest_pred_filenames.sort()","611a339f":"%%time\n# Dropping test labels (which are all zeros) and transforming audio data to numpy array\ntest_audio = []\n\nfor audio, _ in test_ds:\n    test_audio.append(audio.numpy())\n\ntest_audio = np.array(test_audio)","85c97c02":"%%time\n# Getting test predictions\ntest_preds = model.predict(test_audio)\nlen(test_preds)","5ea559b4":"# Plotting test predictions distribution\nprint((test_preds > 0.5).sum(), (test_preds < 0.5).sum())\npd.Series(test_preds.flatten()).hist(bins=20)","94b7e304":"# Creating and saving predictions dataframe\npredictions = pd.DataFrame(columns=[\"filename\", \"score\"])\npredictions[\"filename\"] = pd.Series(test_pred_filenames)\npredictions[\"score\"] = test_preds\n\npredictions.to_csv('test_predictions.csv', index=False, header=False)\npredictions.head(10)","92899eb4":"# First 10 audio files to compare with predictions\nfor i in range(10):\n    display(Audio(test_filenames[i]))","5483c55a":"# **Model building and training**","6edabcf3":"The goal is to train a model capable to predict if a given audio is a real human speech or a generated one.","68404954":"Plotting loss and metrics:","15e70e76":"# **Making test predictions and results submission**","b6b7c43c":"# **Valid predictions estimation**","621b1f2b":"# **Train, valid and test datasets preprocessing**","9f792651":"# **Data loading and checking**"}}