{"cell_type":{"ec375637":"code","f5409bd1":"code","969ec44d":"code","5abb3992":"code","f3bb58ab":"code","44857b4a":"code","11ed0d43":"code","90e6041c":"code","9ba6eb00":"code","592fb1bc":"code","5c13bf0c":"code","1e8b75dc":"code","ab0e83a2":"code","3ce37855":"code","feb0fcdd":"code","80b79747":"code","0ccc03da":"code","ac867ef6":"code","575f0345":"code","34c36a27":"code","27ce8702":"code","a2845a56":"code","6b8a0d4e":"code","2787e150":"code","0505ad61":"code","73383f11":"code","929f8475":"code","4a1ed27b":"markdown","3f4d1f30":"markdown"},"source":{"ec375637":"# importing all the libraries needed \nimport numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport sklearn\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nfrom sklearn import datasets, linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\n#For date time functions\nfrom datetime import datetime\nfrom datetime import timedelta\nimport math\n\n# Importing the most popular regression libraries.\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, ridge_regression, Lasso, SGDRegressor, Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV","f5409bd1":"train_data=pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/train.csv.zip',parse_dates=True)\nsample_submission=pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/sampleSubmission.csv.zip')\nfeatures_data=pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/features.csv.zip',parse_dates=True)\nstores_data=pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/stores.csv')\ntest_data=pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/test.csv.zip')","969ec44d":"from fbprophet import Prophet\nimport tqdm.notebook as tq\ndf = pd.DataFrame()\nfor i in tq.tqdm(range(1,46)):\n    model=Prophet()\n    filled=features_data[((features_data['Store']==i) & (features_data['Date']<'2013-05-03'))][['Date','CPI']]\n    tserie = filled.rename(columns = {'Date': 'ds', 'CPI': 'y'}, inplace = False)\n    tserie =tserie.sort_values(by=['ds'])\n    tserie['ds'] = pd.to_datetime(tserie['ds'])\n    model.fit(tserie)\n    future_dates=model.make_future_dataframe(periods=13,freq = 'W',include_history =True)\n    future_dates['ds'] = future_dates['ds'].apply(lambda x: x + timedelta(days=5))\n    prediction=model.predict(future_dates)\n    df=df.append(prediction)\n\ndf.reset_index(drop=True)\nfeatures_data['CPI1']=np.nan\nfor i,j in enumerate(df['yhat']):\n    features_data['CPI1'].iloc[i]=j\n\nfeatures_data=features_data.drop(['CPI'],axis=1)\nfeatures_data = features_data.rename(columns = {'CPI1': 'CPI'})","5abb3992":"from fbprophet import Prophet\nimport tqdm.notebook as tq\ndf = pd.DataFrame()\nfor i in tq.tqdm(range(1,46)):\n    model=Prophet()\n    filled=features_data[((features_data['Store']==i) & (features_data['Date']<'2013-05-03'))][['Date','Unemployment']]\n    tserie = filled.rename(columns = {'Date': 'ds', 'Unemployment': 'y'}, inplace = False)\n    tserie =tserie.sort_values(by=['ds'])\n    tserie['ds'] = pd.to_datetime(tserie['ds'])\n    model.fit(tserie)\n    future_dates=model.make_future_dataframe(periods=13,freq = 'W',include_history =True)\n    future_dates['ds'] = future_dates['ds'].apply(lambda x: x + timedelta(days=5))\n    prediction=model.predict(future_dates)\n    df=df.append(prediction)\n\ndf.reset_index(drop=True)\nfeatures_data['Unemployment1']=np.nan\nfor i,j in enumerate(df['yhat']):\n    features_data['Unemployment1'].iloc[i]=j\n\nfeatures_data=features_data.drop(['Unemployment'],axis=1)\nfeatures_data = features_data.rename(columns = {'Unemployment1': 'Unemployment'})","f3bb58ab":"stores = stores_data.merge(features_data, on ='Store' , how = 'left')\nfinal_data_train = train_data.merge(stores, on = ['Store', 'Date', 'IsHoliday'], how = 'left')","44857b4a":"stores = stores_data.merge(features_data, on ='Store' , how = 'left')\nfinal_data_test = test_data.merge(stores, on = ['Store', 'Date', 'IsHoliday'], how = 'left')","11ed0d43":"print(final_data_train.shape)\nprint(final_data_test.shape)","90e6041c":"def markdown_imputation(final_data):    \n    final_data.loc[final_data.MarkDown1.isnull() ,'MarkDown1']= 0\n    final_data.loc[final_data.MarkDown2.isnull() ,'MarkDown2']= 0\n    final_data.loc[final_data.MarkDown3.isnull() ,'MarkDown3']= 0\n    final_data.loc[final_data.MarkDown4.isnull() ,'MarkDown4']= 0\n    final_data.loc[final_data.MarkDown5.isnull() ,'MarkDown5']= 0\n    return final_data","9ba6eb00":"def weekly_sales_imputation(final_data):    \n    final_data[final_data.Weekly_Sales<0]\n    print('before removing negative weekly sales ,shape of final dataframe is :',final_data.shape)\n    final_data=final_data[final_data.Weekly_Sales>=0]\n    print('after removing negative weekly sales ,shape of final dataframe is :',final_data.shape)\n    return final_data","592fb1bc":"def train_temp_bins(final_data):\n    temp_100_110_f=final_data[((final_data.Temperature>100) & (final_data.Temperature< 110))].Weekly_Sales.sum()\n    temp_90_100_f=final_data[((final_data.Temperature>90) & (final_data.Temperature< 100))].Weekly_Sales.sum()\n    temp_80_90_f=final_data[((final_data.Temperature>80) & (final_data.Temperature< 90))].Weekly_Sales.sum()\n    temp_70_80_f=final_data[((final_data.Temperature>70) & (final_data.Temperature< 80))].Weekly_Sales.sum()\n    temp_60_70_f=final_data[((final_data.Temperature>60) & (final_data.Temperature< 70))].Weekly_Sales.sum()\n    temp_50_60_f=final_data[((final_data.Temperature>50) & (final_data.Temperature< 60))].Weekly_Sales.sum()\n    temp_40_50_f=final_data[((final_data.Temperature>40) & (final_data.Temperature< 50))].Weekly_Sales.sum()\n    temp_30_40_f=final_data[((final_data.Temperature>30) & (final_data.Temperature< 40))].Weekly_Sales.sum() \n    temp_0_30_f=final_data[((final_data.Temperature>0) & (final_data.Temperature< 30))].Weekly_Sales.sum()   \n    temp_less_than_0_f=final_data[((final_data.Temperature>-10) & (final_data.Temperature< 0))].Weekly_Sales.sum()\n    final_data['Temp_bins'] = np.nan\n    final_data.loc[((final_data.Temperature>-10) & (final_data.Temperature<0)) ,'Temp_bins']= temp_less_than_0_f\n    final_data.loc[((final_data.Temperature>0) & (final_data.Temperature< 30)) ,'Temp_bins']= temp_0_30_f\n    final_data.loc[((final_data.Temperature>30) & (final_data.Temperature< 40)) ,'Temp_bins']= temp_30_40_f\n    final_data.loc[((final_data.Temperature>40) & (final_data.Temperature< 50)) ,'Temp_bins']= temp_40_50_f\n    final_data.loc[((final_data.Temperature>50) & (final_data.Temperature< 60)) ,'Temp_bins']= temp_50_60_f\n    final_data.loc[((final_data.Temperature>60) & (final_data.Temperature< 70)) ,'Temp_bins']= temp_60_70_f\n    final_data.loc[((final_data.Temperature>70) & (final_data.Temperature< 80)) ,'Temp_bins']= temp_70_80_f\n    final_data.loc[((final_data.Temperature>80) & (final_data.Temperature< 90)) ,'Temp_bins']= temp_80_90_f\n    final_data.loc[((final_data.Temperature>90) & (final_data.Temperature< 100)),'Temp_bins']= temp_90_100_f\n    final_data.loc[((final_data.Temperature>100) & (final_data.Temperature< 110)),'Temp_bins']= temp_100_110_f\n    final_data.loc[final_data.Temp_bins.isnull() ,'Temp_bins']= 0\n    list1=[temp_less_than_0_f,temp_0_30_f,temp_30_40_f,temp_40_50_f,temp_50_60_f,temp_60_70_f,temp_70_80_f,temp_80_90_f,temp_90_100_f,temp_100_110_f]\n    return final_data,list1","5c13bf0c":"def test_temp_bins(final_data,list1):\n    final_data['Temp_bins'] = np.nan\n    final_data.loc[((final_data.Temperature>-10) & (final_data.Temperature<0)) ,'Temp_bins']= list1[0]\n    final_data.loc[((final_data.Temperature>0) & (final_data.Temperature< 30)) ,'Temp_bins']= list1[1]\n    final_data.loc[((final_data.Temperature>30) & (final_data.Temperature< 40)) ,'Temp_bins']= list1[2]\n    final_data.loc[((final_data.Temperature>40) & (final_data.Temperature< 50)) ,'Temp_bins']= list1[3]\n    final_data.loc[((final_data.Temperature>50) & (final_data.Temperature< 60)) ,'Temp_bins']= list1[4]\n    final_data.loc[((final_data.Temperature>60) & (final_data.Temperature< 70)) ,'Temp_bins']= list1[5]\n    final_data.loc[((final_data.Temperature>70) & (final_data.Temperature< 80)) ,'Temp_bins']= list1[6]\n    final_data.loc[((final_data.Temperature>80) & (final_data.Temperature< 90)) ,'Temp_bins']= list1[7]\n    final_data.loc[((final_data.Temperature>90) & (final_data.Temperature< 100)),'Temp_bins']= list1[8]\n    final_data.loc[((final_data.Temperature>100) & (final_data.Temperature< 110)),'Temp_bins']= list1[9]\n    final_data.loc[final_data.Temp_bins.isnull() ,'Temp_bins']= 0\n    return final_data","1e8b75dc":"def split(final_data):\n    final_data['Date'] = pd.to_datetime(final_data['Date'])\n    final_data['Year'] = final_data['Date'].dt.year\n    final_data['Month']= final_data['Date'].dt.month\n    final_data['Week'] = final_data['Date'].dt.week\n    final_data['Day']  = final_data['Date'].dt.day\n    return final_data","ab0e83a2":"import datetime\ndef days_from_christmas_for_train(x):\n    if x['Year']== 2010 :\n        diff=datetime.datetime(2010, 12, 31)-x['Date']\n        return diff.days\n    if ((x['Year']== 2011) and (x['Date']< datetime.datetime(2011, 12, 30))):\n        diff=datetime.datetime(2011, 12, 30)-x['Date']\n        return diff.days\n    else:\n        return 0","3ce37855":"import datetime\ndef days_from_christmas_for_test(x):\n    if x['Year']== 2010 :\n        diff=datetime.datetime(2010, 12, 31)-x['Date']\n        return diff.days\n    if ((x['Year']== 2011) and (x['Date']< datetime.datetime(2011, 12, 30))):\n        diff=datetime.datetime(2011, 12, 30)-x['Date']\n        return diff.days\n    if ((x['Year']== 2012) and (x['Date']< datetime.datetime(2012, 12, 28))):\n        diff=datetime.datetime(2012, 12, 28)-x['Date']\n        return diff.days\n    if ((x['Year']== 2013) and (x['Date']< datetime.datetime(2013, 12, 27))):\n        diff=datetime.datetime(2013, 12, 27)-x['Date']\n        return diff.days\n    else:\n        return 0   ","feb0fcdd":"def days_from_thanksgiving_for_train(x):\n    if ((x['Year']== 2010) and (x['Date']< datetime.datetime(2010, 11, 26))):\n        diff=datetime.datetime(2010, 11, 26)-x['Date']\n        return diff.days\n    if ((x['Year']== 2011) and (x['Date']< datetime.datetime(2011, 11, 25))):\n        diff=datetime.datetime(2011, 11, 25)-x['Date']\n        return diff.days\n    else:\n        return 0","80b79747":"def days_from_thanksgiving_for_test(x):\n    if ((x['Year']== 2010) and (x['Date']< datetime.datetime(2010, 11, 26))):\n        diff=datetime.datetime(2010, 11, 26)-x['Date']\n        return diff.days\n    if ((x['Year']== 2011) and (x['Date']< datetime.datetime(2011, 11, 25))):\n        diff=datetime.datetime(2011, 11, 25)-x['Date']\n        return diff.days\n    if ((x['Year']== 2012) and (x['Date']< datetime.datetime(2012, 11, 23))):\n        diff=datetime.datetime(2012, 11, 23)-x['Date']\n        return diff.days\n    if ((x['Year']== 2013) and (x['Date']< datetime.datetime(2013, 11, 29))):\n        diff=datetime.datetime(2013, 11, 29)-x['Date']\n        return diff.days\n    else:\n        return 0","0ccc03da":"def holiday_type(x):\n    if   (x['IsHoliday']== 1) & (x['Week']==6):\n        return 1 #SuperBowl\n    elif (x['IsHoliday']== 1) & (x['Week']==36):\n        return 2 #LaborDay\n    elif (x['IsHoliday']== 1) & (x['Week']==47):\n        return 3 #Thanksgiving\n    elif (x['IsHoliday']== 1) & (x['Week']==52):\n        return 4 #Christmas\n    else:\n        return 0","ac867ef6":"def holiday_label(final_data):\n    final_data.loc[(final_data.IsHoliday==True) ,'IsHoliday']= 1\n    final_data.loc[(final_data.IsHoliday==False) ,'IsHoliday']= 0\n    return final_data","575f0345":"def type_label(final_data):\n    final_data.loc[(final_data.Type=='A') ,'Type']= 1\n    final_data.loc[(final_data.Type=='B') ,'Type']= 2\n    final_data.loc[(final_data.Type=='C') ,'Type']= 3\n    return final_data","34c36a27":"import holidays\ndef holiday_in_week_train(final_data):\n    dates =[]\n    for ptr in holidays.US(years = 2010).items():\n        dates.append(ptr[0])\n    for ptr in holidays.US(years = 2011).items():\n        dates.append(ptr[0])\n    for ptr in holidays.US(years = 2012).items():\n        dates.append(ptr[0])\n    holiday_count=[] \n    for index, row in final_data.iterrows():\n        dat = final_data['Date'][index]\n        dt=[]\n        for i in range(0,5):\n            dt.append(dat - datetime.timedelta(days = i))\n        for i in range(1,3):\n            dt.append(dat + datetime.timedelta(days = i))\n        count = 0\n        for date in dates:\n            if date in dt:\n                count +=1\n        holiday_count.append(count)\n    return holiday_count  ","27ce8702":"import holidays\ndef holiday_in_week_test(final_data):\n    dates =[]\n    for ptr in holidays.US(years = 2010).items():\n        dates.append(ptr[0])\n    for ptr in holidays.US(years = 2011).items():\n        dates.append(ptr[0])\n    for ptr in holidays.US(years = 2012).items():\n        dates.append(ptr[0])\n    for ptr in holidays.US(years = 2013).items():\n        dates.append(ptr[0])\n    holiday_count=[] \n    for index, row in final_data.iterrows():\n        dat = final_data['Date'][index]\n        dt=[]\n        for i in range(0,5):\n            dt.append(dat - datetime.timedelta(days = i))\n        for i in range(1,3):\n            dt.append(dat + datetime.timedelta(days = i))\n        count = 0\n        for date in dates:\n            if date in dt:\n                count +=1\n        holiday_count.append(count)\n    return holiday_count","a2845a56":"final_data_train=markdown_imputation(final_data_train)\nfinal_data_train=weekly_sales_imputation(final_data_train)\nfinal_data_train,list1=train_temp_bins(final_data_train)\nfinal_data_train=split(final_data_train)\nfinal_data_train['diff_from_christmas'] = final_data_train.apply(days_from_christmas_for_train, axis=1)  \nfinal_data_train['days_from_thanksgiving'] = final_data_train.apply(days_from_thanksgiving_for_train, axis=1)  \nfinal_data_train['IsHoliday_bins'] = final_data_train.apply(holiday_type, axis=1)\nfinal_data_train=holiday_label(final_data_train)\nfinal_data_train=type_label(final_data_train)\nfinal_data_train['Holidays'] = np.array(holiday_in_week_train(final_data_train))","6b8a0d4e":"final_data_test=markdown_imputation(final_data_test)\nfinal_data_test=test_temp_bins(final_data_test,list1)\nfinal_data_test=split(final_data_test)\nfinal_data_test['diff_from_christmas'] = final_data_test.apply(days_from_christmas_for_test, axis=1) \nfinal_data_test['days_from_thanksgiving'] = final_data_test.apply(days_from_thanksgiving_for_test, axis=1)   \nfinal_data_test['IsHoliday_bins'] = final_data_test.apply(holiday_type, axis=1)\nfinal_data_test=holiday_label(final_data_test)\nfinal_data_test=type_label(final_data_test)\nfinal_data_test['Holidays'] = np.array(holiday_in_week_test(final_data_test))","2787e150":"final_data_train=final_data_train.reset_index(drop=True)","0505ad61":"from sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBClassifier, XGBRegressor\nfinal_data_train=final_data_train[['Store','Dept','IsHoliday','Size','Week','Type','Year','Weekly_Sales','Holidays','Day']]\nfinal_data_test=final_data_test[['Store','Dept','IsHoliday','Size','Week','Type','Year','Holidays','Day']]\n# final_data_train['Date']=pd.to_numeric(pd.to_datetime(final_data_train['Date']))\n# final_data_test['Date'] = pd.to_numeric(pd.to_datetime(final_data_test['Date']))\nfinal_data_train['IsHoliday']=final_data_train['IsHoliday'].astype('bool')\nfinal_data_test['IsHoliday']=final_data_test['IsHoliday'].astype('bool')\nfinal_data_train['Type']=final_data_train['Type'].astype('int')\nfinal_data_test['Type']=final_data_test['Type'].astype('int')\ny = final_data_train['Weekly_Sales']\nX = final_data_train.drop(['Weekly_Sales'], axis=1)\nrf_Model = RandomForestRegressor(n_estimators= 140,max_depth=27,n_jobs = -1)\nrf_Model.fit(X, y)\ny_hat= rf_Model.predict(final_data_test)","73383f11":"sample_submission['Weekly_Sales']  = list(y_hat)","929f8475":"sample_submission.to_csv('submission.csv',index = False)","4a1ed27b":"## Training data preprocessing and generating new features","3f4d1f30":"## Test data preprocessing and generating new features"}}