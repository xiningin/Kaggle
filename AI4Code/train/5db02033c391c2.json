{"cell_type":{"fa6f3498":"code","6481f285":"code","ec1dd95f":"code","f78c7777":"code","a2da538c":"code","7b6d5bb3":"code","00a10364":"code","d37ebd8f":"code","4d23bb36":"code","592187c2":"code","f3dc5afd":"code","1439d565":"code","270a048a":"code","f00bb61e":"code","c68041ea":"code","7ce9a587":"code","d0cd6f75":"code","a36f2c07":"code","476e5f8f":"code","460a9a1c":"code","dee71afc":"code","6ff8d2fd":"code","1d8ccaf3":"code","f2491c93":"code","666977e2":"code","ec4c0b95":"code","0b69ea51":"code","5ae9ac63":"markdown","3ab472e6":"markdown","7ecf34e3":"markdown","abd96211":"markdown","5722f0e0":"markdown","ddc38205":"markdown","592e54c1":"markdown","c5940b3c":"markdown","e9c37b48":"markdown","752f21a2":"markdown","d39e98bf":"markdown","663ab10f":"markdown","f049b6e0":"markdown","8a154d66":"markdown","595b7b5b":"markdown","7497befb":"markdown","d61965a6":"markdown","4b57c89f":"markdown","4b6a0000":"markdown","8b0fc9ee":"markdown","bd98468d":"markdown","1cc463ab":"markdown","aacca3a1":"markdown","fda80aa0":"markdown","eedbe077":"markdown","cc97fba1":"markdown","dca46d01":"markdown","e5c62d8a":"markdown","6e16fb1d":"markdown","ee2113c2":"markdown","ef244540":"markdown","e9179f48":"markdown","23fe2ec6":"markdown","a6f85994":"markdown","290d5df5":"markdown","bf8757a8":"markdown","14510c72":"markdown","0504d728":"markdown","ba3f8984":"markdown","bed22743":"markdown"},"source":{"fa6f3498":"import gc\nimport os\nimport pdb\nimport time\nimport glob\nimport sys\nimport math\nimport random\nimport wandb\nimport math\n\nimport numpy as np\nimport pandas as pd\n\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nplt.rcParams.update({'font.size': 18})\nplt.style.use('fivethirtyeight')\n\nimport seaborn as sns\nimport matplotlib\nfrom termcolor import colored\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport re\nimport folium\n# import textstat\nfrom scipy import stats\nfrom colorama import Fore, Back, Style, init\nfrom bs4 import BeautifulSoup\n\nimport scipy as sp\n\nimport random\nimport networkx as nx\nfrom pandas import Timestamp\nfrom collections import defaultdict\n\nfrom PIL import Image\nfrom IPython.display import SVG\n\nimport requests\nfrom IPython.display import HTML\n\nimport matplotlib.cm as cm\n\nfrom tqdm import tqdm\ntqdm.pandas()\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nimport transformers\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom tokenizers import BertWordPieceTokenizer\n\nfrom sklearn import metrics\nfrom sklearn.utils import shuffle\nfrom gensim.models import Word2Vec\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_extraction.text import TfidfVectorizer,\\\n                                            CountVectorizer,\\\n                                            HashingVectorizer\n\nfrom nltk.stem.wordnet import WordNetLemmatizer \nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import TweetTokenizer  \n\nimport nltk\nfrom textblob import TextBlob\n\nfrom nltk.corpus import wordnet\nfrom nltk.corpus import stopwords\nfrom nltk import WordNetLemmatizer\n# from polyglot.detect import Detector\nfrom nltk.stem import WordNetLemmatizer\nfrom wordcloud import WordCloud, STOPWORDS\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import OneCycleLR\n    \n# NLP\nfrom transformers import AutoTokenizer, AutoModel\n\nstopword=set(STOPWORDS)\n\nlem = WordNetLemmatizer()\ntokenizer=TweetTokenizer()","6481f285":"import wandb\nwandb.login()","ec1dd95f":"class config:\n    DIRECTORY_PATH = \"\/kaggle\/input\/jigsaw-multilingual-toxic-comment-classification\"\n    TRAIN_PATH = DIRECTORY_PATH + \"\/jigsaw-toxic-comment-train.csv\"\n    \n# Device Optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')","f78c7777":"# wandb config\nWANDB_CONFIG = {\n     'competition': 'Jigsaw', \n              '_wandb_kernel': 'neuracort'\n    }","a2da538c":"train = pd.read_csv(config.TRAIN_PATH)","7b6d5bb3":"train.head()","00a10364":"train.info()","d37ebd8f":"print(f\"Training Dataset Shape: {colored(train.shape, 'yellow')}\")","4d23bb36":"for col in train.columns:\n    print(col + \":\" + colored(str(len(train[col].unique())), 'yellow'))","592187c2":"def nonan(x):\n    if type(x) == str:\n        return x.replace(\"\\n\", \"\")\n    else:\n        return \"\"\n\ntext = ' '.join([nonan(abstract) for abstract in train[\"comment_text\"]])\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(text)\nfig = px.imshow(wordcloud)\nfig.update_layout(title_text='Common words in comments')","f3dc5afd":"def get_language(text):\n    return Detector(\"\".join(x for x in text if x.isprintable()), quiet=True).languages[0].name\n\ntrain[\"lang\"] = train[\"comment_text\"].progress_apply(get_language)","1439d565":"lang_list = sorted(list(set(train[\"lang\"])))\ncounts = [list(train[\"lang\"]).count(cont) for cont in lang_list]\ndf = pd.DataFrame(np.transpose([lang_list, counts]))\ndf.columns = [\"Language\", \"Count\"]\ndf[\"Count\"] = df[\"Count\"].apply(int)\n\ndf_en = pd.DataFrame(np.transpose([[\"English\", \"Non-English\"], [max(counts), sum(counts) - max(counts)]]))\ndf_en.columns = [\"Language\", \"Count\"]\n\nfig = px.bar(df_en, x=\"Language\", y=\"Count\", title=\"Language of comments\", color=\"Language\", text=\"Count\")\nfig.update_layout(template=\"plotly_white\")\nfig.data[0].marker.line.color = 'rgb(0, 0, 0)'\nfig.data[0].marker.line.width = 0.5\nfig.data[1].marker.line.color = 'rgb(0, 0, 0)'\nfig.data[1].marker.line.width = 0.5\nfig.data[0].textfont.color = \"black\"\nfig.data[0].textposition = \"outside\"\nfig.data[1].textfont.color = \"black\"\nfig.data[1].textposition = \"outside\"\nfig","270a048a":"fig = px.bar(df.query(\"Language != 'English' and Language != 'un'\").query(\"Count >= 50\"),\n             y=\"Language\", x=\"Count\", title=\"Language of non-English comments\", template=\"plotly_white\", color=\"Language\", text=\"Count\", orientation=\"h\")\nfig.update_traces(marker=dict(line=dict(width=0.75,\n                                        color='black')),  textposition=\"outside\")\nfig.update_layout(showlegend=False)\nfig","f00bb61e":"def new_len(x):\n    if type(x) is str:\n        return len(x.split())\n    else:\n        return 0\n\ntrain[\"comment_words\"] = train[\"comment_text\"].apply(new_len)\nnums = train.query(\"comment_words != 0 and comment_words < 200\").sample(frac=0.1)[\"comment_words\"]\nfig = ff.create_distplot(hist_data=[nums],\n                         group_labels=[\"All comments\"],\n                         colors=[\"coral\"])\n\nfig.update_layout(title_text=\"Comment words\", xaxis_title=\"Comment words\", template=\"simple_white\", showlegend=False)\nfig.show()","c68041ea":"df = pd.DataFrame(np.transpose([lang_list, train.groupby(\"lang\").mean()[\"comment_words\"]]))\ndf.columns = [\"Language\", \"Average_comment_words\"]\ndf[\"Average_comment_words\"] = df[\"Average_comment_words\"].apply(float)\ndf = df.query(\"Average_comment_words < 500\")\nfig = go.Figure(go.Bar(x=df[\"Language\"], y=df[\"Average_comment_words\"]))\n\nfig.update_layout(xaxis_title=\"Language\", yaxis_title=\"Average comment words\", title_text=\"Average comment words vs. language\", template=\"plotly_white\")\nfig.show()","7ce9a587":"def polarity(x):\n    if type(x) == str:\n        return SIA.polarity_scores(x)\n    else:\n        return 1000\n    \nSIA = SentimentIntensityAnalyzer()\ntrain[\"polarity\"] = train[\"comment_text\"].progress_apply(polarity)","d0cd6f75":"fig = go.Figure(go.Histogram(x=[pols[\"neg\"] for pols in train[\"polarity\"] if pols[\"neg\"] != 0], marker=dict(\n            color='seagreen')\n    ))\n\nfig.update_layout(xaxis_title=\"Negativity sentiment\", title_text=\"Negativity sentiment\", template=\"simple_white\")\nfig.show()","a36f2c07":"data_dir = '..\/input\/jrstc-train-folds'\ntrain_file_path = os.path.join(data_dir, 'validation_data_5_folds.csv')\ntrain_df = pd.read_csv(train_file_path)\n\nparams = {\n    'device': device,\n    'debug': False,\n    'checkpoint': 'roberta-base',\n    'output_logits': 768,\n    'max_len': 256,\n    'num_folds': 1,\n    'batch_size': 16,\n    'dropout': 0.2,\n    'num_workers': 2,\n    'epochs': 1,\n    'lr': 2e-5,\n    'margin': 0.7,\n    'scheduler_name': 'OneCycleLR',\n    'max_lr': 5e-5,                 # OneCycleLR\n    'pct_start': 0.1,               # OneCycleLR\n    'anneal_strategy': 'cos',       # OneCycleLR\n    'div_factor': 1e3,              # OneCycleLR\n    'final_div_factor': 1e3,        # OneCycleLR\n    'no_decay': True\n}\n\nif params['debug']:\n    train_df = train_df.sample(frac=0.01)\n    print('Reduced training Data Size for Debugging purposes')","476e5f8f":"def text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?:\/\/\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text\n\ntqdm.pandas()\ntrain_df['less_toxic'] = train_df['less_toxic'].progress_apply(text_cleaning)\ntrain_df['more_toxic'] = train_df['more_toxic'].progress_apply(text_cleaning)","460a9a1c":"class MetricMonitor:\n    def __init__(self, float_precision=4):\n        self.float_precision = float_precision\n        self.reset()\n\n    def reset(self):\n        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n\n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n\n        metric[\"val\"] += val\n        metric[\"count\"] += 1\n        metric[\"avg\"] = metric[\"val\"] \/ metric[\"count\"]\n\n    def __str__(self):\n        return \" | \".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric[\"avg\"],\n                    float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )","dee71afc":"def get_scheduler(optimizer, scheduler_params=params):\n    if scheduler_params['scheduler_name'] == 'CosineAnnealingWarmRestarts':\n        scheduler = CosineAnnealingWarmRestarts(\n            optimizer,\n            T_0=scheduler_params['T_0'],\n            eta_min=scheduler_params['min_lr'],\n            last_epoch=-1\n        )\n    elif scheduler_params['scheduler_name'] == 'OneCycleLR':\n        scheduler = OneCycleLR(\n            optimizer,\n            max_lr=scheduler_params['max_lr'],\n            steps_per_epoch=int(df_train.shape[0] \/ params['batch_size']) + 1,\n            epochs=scheduler_params['epochs'],\n            pct_start=scheduler_params['pct_start'],\n            anneal_strategy=scheduler_params['anneal_strategy'],\n            div_factor=scheduler_params['div_factor'],\n            final_div_factor=scheduler_params['final_div_factor'],\n        )\n    return scheduler","6ff8d2fd":"class BERTDataset:\n    def __init__(self, more_toxic, less_toxic, max_len=params['max_len'], checkpoint=params['checkpoint']):\n        self.more_toxic = more_toxic\n        self.less_toxic = less_toxic\n        self.max_len = max_len\n        self.checkpoint = checkpoint\n        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n        self.num_examples = len(self.more_toxic)\n\n    def __len__(self):\n        return self.num_examples\n\n    def __getitem__(self, idx):\n        more_toxic = str(self.more_toxic[idx])\n        less_toxic = str(self.less_toxic[idx])\n\n        tokenized_more_toxic = self.tokenizer(\n            more_toxic,\n            add_special_tokens=True,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_attention_mask=True,\n            return_token_type_ids=True,\n        )\n\n        tokenized_less_toxic = self.tokenizer(\n            less_toxic,\n            add_special_tokens=True,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_attention_mask=True,\n            return_token_type_ids=True,\n        )\n\n        ids_more_toxic = tokenized_more_toxic['input_ids']\n        mask_more_toxic = tokenized_more_toxic['attention_mask']\n        token_type_ids_more_toxic = tokenized_more_toxic['token_type_ids']\n\n        ids_less_toxic = tokenized_less_toxic['input_ids']\n        mask_less_toxic = tokenized_less_toxic['attention_mask']\n        token_type_ids_less_toxic = tokenized_less_toxic['token_type_ids']\n\n        return {'ids_more_toxic': torch.tensor(ids_more_toxic, dtype=torch.long),\n                'mask_more_toxic': torch.tensor(mask_more_toxic, dtype=torch.long),\n                'token_type_ids_more_toxic': torch.tensor(token_type_ids_more_toxic, dtype=torch.long),\n                'ids_less_toxic': torch.tensor(ids_less_toxic, dtype=torch.long),\n                'mask_less_toxic': torch.tensor(mask_less_toxic, dtype=torch.long),\n                'token_type_ids_less_toxic': torch.tensor(token_type_ids_less_toxic, dtype=torch.long),\n                'target': torch.tensor(1, dtype=torch.float)}","1d8ccaf3":"class ToxicityModel(nn.Module):\n    def __init__(self, checkpoint=params['checkpoint'], params=params):\n        super(ToxicityModel, self).__init__()\n        self.checkpoint = checkpoint\n        self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n        self.layer_norm = nn.LayerNorm(params['output_logits'])\n        self.dropout = nn.Dropout(params['dropout'])\n        self.dense = nn.Sequential(\n            nn.Linear(params['output_logits'], 128),\n            nn.SiLU(),\n            nn.Dropout(params['dropout']),\n            nn.Linear(128, 1)\n        )\n\n    def forward(self, input_ids, token_type_ids, attention_mask):\n        _, pooled_output = self.bert(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n        pooled_output = self.layer_norm(pooled_output)\n        pooled_output = self.dropout(pooled_output)\n        preds = self.dense(pooled_output)\n        return preds","f2491c93":"def train_fn(train_loader, model, criterion, optimizer, epoch, params, scheduler=None):\n    metric_monitor = MetricMonitor()\n    model.train()\n    stream = tqdm(train_loader)\n    \n    for i, batch in enumerate(stream, start=1):\n        ids_more_toxic = batch['ids_more_toxic'].to(device)\n        mask_more_toxic = batch['mask_more_toxic'].to(device)\n        token_type_ids_more_toxic = batch['token_type_ids_more_toxic'].to(device)\n        \n        ids_less_toxic = batch['ids_less_toxic'].to(device)\n        mask_less_toxic = batch['mask_less_toxic'].to(device)\n        token_type_ids_less_toxic = batch['token_type_ids_less_toxic'].to(device)\n        \n        target = batch['target'].to(device)\n\n        logits_more_toxic = model(ids_more_toxic, token_type_ids_more_toxic, mask_more_toxic)\n        logits_less_toxic = model(ids_less_toxic, token_type_ids_less_toxic, mask_less_toxic)\n        \n        loss = criterion(logits_more_toxic, logits_less_toxic, target)\n        \n        metric_monitor.update('Loss', loss.item())\n        \n        loss.backward()\n        optimizer.step()\n            \n        if scheduler is not None:\n            scheduler.step()\n        \n        optimizer.zero_grad()\n        stream.set_description(f\"Epoch: {epoch:02}. Train. {metric_monitor}\")","666977e2":"def validate_fn(val_loader, model, criterion, epoch, params):\n    metric_monitor = MetricMonitor()\n    model.eval()\n    stream = tqdm(val_loader)\n    all_loss = []\n    with torch.no_grad():\n        for i, batch in enumerate(stream, start=1):\n            ids_more_toxic = batch['ids_more_toxic'].to(device)\n            mask_more_toxic = batch['mask_more_toxic'].to(device)\n            token_type_ids_more_toxic = batch['token_type_ids_more_toxic'].to(device)\n            \n            ids_less_toxic = batch['ids_less_toxic'].to(device)\n            mask_less_toxic = batch['mask_less_toxic'].to(device)\n            token_type_ids_less_toxic = batch['token_type_ids_less_toxic'].to(device)\n            \n            target = batch['target'].to(device)\n\n            logits_more_toxic = model(ids_more_toxic, token_type_ids_more_toxic, mask_more_toxic)\n            logits_less_toxic = model(ids_less_toxic, token_type_ids_less_toxic, mask_less_toxic)\n            \n            loss = criterion(logits_more_toxic, logits_less_toxic, target)\n            all_loss.append(loss.item())\n            \n            metric_monitor.update('Loss', loss.item())\n            \n            stream.set_description(f\"Epoch: {epoch:02}. Valid. {metric_monitor}\")\n            \n    return np.mean(all_loss)","ec4c0b95":"best_models_of_each_fold = []","0b69ea51":"gc.collect()\nfor fold in range(params['num_folds']):\n    print(f'******************** Training Fold: {fold+1} ********************')\n    current_fold = fold\n    df_train = train_df[train_df['kfold'] != current_fold].copy()\n    df_valid = train_df[train_df['kfold'] == current_fold].copy()\n\n    train_dataset = BERTDataset(\n        df_train.more_toxic.values,\n        df_train.less_toxic.values\n    )\n    valid_dataset = BERTDataset(\n        df_valid.more_toxic.values,\n        df_valid.less_toxic.values\n    )\n\n    train_dataloader = DataLoader(\n        train_dataset, batch_size=params['batch_size'], shuffle=True,\n        num_workers=params['num_workers'], pin_memory=True\n    )\n    valid_dataloader = DataLoader(\n        valid_dataset, batch_size=params['batch_size']*2, shuffle=False,\n        num_workers=params['num_workers'], pin_memory=True\n    )\n    \n    model = ToxicityModel()\n    model = model.to(params['device'])\n    criterion = nn.MarginRankingLoss(margin=params['margin'])\n    if params['no_decay']:\n        param_optimizer = list(model.named_parameters())\n        no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n        optimizer_grouped_parameters = [\n            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n        ]\n        optimizer = optim.AdamW(optimizer_grouped_parameters, lr=params['lr'])\n    else:\n        optimizer = optim.AdamW(model.parameters(), lr=params['lr'])\n    scheduler = get_scheduler(optimizer)\n\n    # Training and Validation Loop\n    best_loss = np.inf\n    best_epoch = 0\n    best_model_name = None\n    \n    # Initialize W&B\n    run = wandb.init(project='Jigsaw-RoBerta', config= WANDB_CONFIG)\n    \n    for epoch in range(1, params['epochs'] + 1):\n        train_fn(train_dataloader, model, criterion, optimizer, epoch, params, scheduler)\n        valid_loss = validate_fn(valid_dataloader, model, criterion, epoch, params)\n        if valid_loss <= best_loss:\n            best_loss = valid_loss\n            best_epoch = epoch\n            if best_model_name is not None:\n                os.remove(best_model_name)\n            torch.save(model.state_dict(), f\"{params['checkpoint']}_{epoch}_epoch_f{fold+1}.pth\")\n            best_model_name = f\"{params['checkpoint']}_{epoch}_epoch_f{fold+1}.pth\"\n            \n        wandb.log({'valid_loss': valid_loss})\n        \n    # Close W&B run\n    wandb.finish()\n\n    # Print summary of this fold\n    print('')\n    print(f'The best LOSS: {best_loss} for fold {fold+1} was achieved on epoch: {best_epoch}.')\n    print(f'The Best saved model is: {best_model_name}')\n    best_models_of_each_fold.append(best_model_name)\n    del df_train, df_valid, train_dataset, valid_dataset, train_dataloader, valid_dataloader, model\n    _ = gc.collect()\n    torch.cuda.empty_cache()","5ae9ac63":"## **<span style=\"color:orange;\">Average Comment Words vs Language<\/span>**","3ab472e6":"> - [Jigsaw Multilingual Toxicity : EDA + Models](https:\/\/www.kaggle.com\/tarunpaparaju\/jigsaw-multilingual-toxicity-eda-models)\n> - [Pytorch RoBERTa Ranking Baseline JRSTC [Train]](https:\/\/www.kaggle.com\/manabendrarout\/pytorch-roberta-ranking-baseline-jrstc-train)\n>\n>---","7ecf34e3":"<a id=\"utilities\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Utilities<\/center><\/h2>","abd96211":"## **<span style=\"color:orange;\">Training Function<\/span>**","5722f0e0":"<a id=\"model\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Model<\/center><\/h2>","ddc38205":"<a id=\"standard-nlp-exploration\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Standard NLP Exploration<\/center><\/h2>","592e54c1":"## **<span style=\"color:orange;\">Column-wise Unique Values<\/span>**","c5940b3c":"## **<span style=\"color:orange;\">Metric Monitor<\/span>**","e9c37b48":"Let us quickly have a brief look upon the dataset. Hope to not encounter any NULL values!","752f21a2":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:maroon; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>If you find this notebook useful, do give me an upvote, it helps to keep up my motivation. This notebook will be updated frequently so keep checking for furthur developments.<\/center><\/h3>","d39e98bf":"## **<span style=\"color:orange;\">Description<\/span>**\n\nIn this competition, we will be asking you to score a set of about fourteen thousand comments. Pairs of comments were presented to expert raters, who marked one of two comments more harmful \u2014 each according to their own notion of toxicity. In this contest, when you provide scores for comments, they will be compared with several hundred thousand rankings. Your average agreement with the raters will determine your individual score. In this way, we hope to focus on ranking the severity of comment toxicity from innocuous to outrageous, where the middle matters as much as the extremes.\n\n## **<span style=\"color:orange;\">Evaluation Criteria<\/span>**\n\nSubmissions are evaluated on Average Agreement with Annotators. For the ground truth, annotators were shown two comments and asked to identify which of the two was more toxic. Pairs of comments can be, and often are, rated by more than one annotator, and may have been ordered differently by different annotators.\n  \nFor each of the approximately 200,000 pair ratings in the ground truth test data, we use your predicted toxicity score to rank the comment pair. The pair receives a 1 if this ranking matches the annotator ranking, or 0 if it does not match.\n  \nThe final score is the average across all the pair evaluations.\n  \nPlease note the following:\n  \n- score is not constrained to any numeric range (e.g., you can predict [0, 1] or [-999, 999]).\n- There is no tie breaking; tied comment scores will always be evaluated as 0. You could consider using something like scipy.stats.rankdata to force unique value.","663ab10f":"## **<span style=\"color:orange;\">English vs Non English Comments<\/span>**","f049b6e0":"<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Contents<\/center><\/h2>","8a154d66":"## **<span style=\"color:orange;\">Comment Word Distribution<\/span>**","595b7b5b":"<a id=\"weights-and-biases\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Weights and Biases (W&B)<\/center><\/h2>","7497befb":"## **<span style=\"color:orange;\">Wordcloud<\/span>**","d61965a6":"--- \n\n## **<span style=\"color:orange;\">Let's have a Talk!<\/span>**\n> ### Reach out to me on [LinkedIn](https:\/\/www.linkedin.com\/in\/ishandutta0098)\n\n---","4b57c89f":"## **<span style=\"color:orange;\">Dataset Head and Info<\/span>**","4b6a0000":"<a id=\"toxicity-and-polarity\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Toxicity and Polarity<\/center><\/h2>","8b0fc9ee":"<a id=\"references\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>References<\/center><\/h2>","bd98468d":"## **<span style=\"color:orange;\">Scheduler<\/span>**","1cc463ab":"1. [Competition Overview](#competition-overview)    \n2. [Libraries](#libraries)  \n3. [Weights and Biases](#weights-and-biases)  \n4. [Global Config](#global-config)  \n5. [Load Datasets](#load-datasets) \n6. [Tabular Exploration](#tabular-exploration)\n7. [Standard NLP Exploration](#standard-nlp-exploration)\n8. [Toxicity and Polarity](#toxicity-and-polarity)\n9. [Model Config](#model-config)\n10. [Utilities](#utilities)\n11. [Dataset Class](#dataset-class)\n12. [Model](#model)\n13. [Engine](#engine)\n14. [Run](#run)\n14. [References](#references)","aacca3a1":"**Weights & Biases** is the machine learning platform for developers to build better models faster. \n\nYou can use W&B's lightweight, interoperable tools to \n- quickly track experiments, \n- version and iterate on datasets, \n- evaluate model performance, \n- reproduce models, \n- visualize results and spot regressions, \n- and share findings with colleagues. \n\nSet up W&B in 5 minutes, then quickly iterate on your machine learning pipeline with the confidence that your datasets and models are tracked and versioned in a reliable system of record.\n\nIn this notebook I will use Weights and Biases's amazing features to perform wonderful visualizations and logging seamlessly. ","fda80aa0":"<center><img src = \"https:\/\/i.imgur.com\/1sm6x8P.png\" width = \"750\" height = \"500\"\/><\/center>  ","eedbe077":"<a id=\"libraries\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Libraries<\/center><\/h2>","cc97fba1":"## **<span style=\"color:orange;\">Dataset Size<\/span>**","dca46d01":"<h1><center>\ud83e\udde9Jigsaw\ud83e\udde9: All Competition EDA at One Place<\/center><\/h1>\n                                                      \n<center><img src = \"https:\/\/jigsaw.google.com\/static\/images\/social-share.jpg?cache=df11f5c\" width = \"750\" height = \"500\"\/><\/center>                                                                            ","e5c62d8a":"Aha! There are no NULL values, so we are good to go.","6e16fb1d":"## **<span style=\"color:orange;\">Text Preprocessing<\/span>**","ee2113c2":"<a id=\"competition-overview\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Competition Overview<\/center><\/h2>","ef244540":"<a id=\"run\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Run<\/center><\/h2>","e9179f48":"## **<span style=\"color:orange;\">Bar chart of non-English languages<\/span>**","23fe2ec6":"<a id=\"tabular-exploration\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Tabular Exploration<\/center><\/h2>","a6f85994":"<a id=\"load-datasets\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Load Datasets<\/center><\/h2>","290d5df5":"<a id=\"model-config\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Model Config<\/center><\/h2>","bf8757a8":"## **<span style=\"color:orange;\">Validation Function<\/span>**","14510c72":"<h1><center>More Plots and Models coming soon!<\/center><\/h1>\n\n<center><img src = \"https:\/\/static.wixstatic.com\/media\/5f8fae_7581e21a24a1483085024f88b0949a9d~mv2.jpg\/v1\/fill\/w_934,h_379,al_c,q_90\/5f8fae_7581e21a24a1483085024f88b0949a9d~mv2.jpg\" width = \"750\" height = \"500\"\/><\/center> ","0504d728":"<a id=\"dataset-class\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Dataset Class<\/center><\/h2>","ba3f8984":"<a id=\"global-config\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Global Config<\/center><\/h2>","bed22743":"<a id=\"engine\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Engine<\/center><\/h2>"}}