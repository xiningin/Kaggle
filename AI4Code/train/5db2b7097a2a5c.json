{"cell_type":{"34c04900":"code","5e446421":"code","b2d58665":"code","2ad245b1":"code","ce5d852c":"code","c2cf5082":"code","91850880":"code","a4729abf":"code","0bf5931c":"code","9deb27cc":"code","c6c45430":"code","9c331a44":"code","89d1552b":"code","ed0c5214":"code","e60cef7a":"code","1ac62503":"code","0dbbd3a5":"code","82923249":"markdown","3771a89e":"markdown","22d1ced8":"markdown","e66ed95b":"markdown","b5d2137d":"markdown","b902ab65":"markdown","7bbd01c2":"markdown","085bbc60":"markdown","e61fa4e2":"markdown","97612ae8":"markdown","3afb64a2":"markdown","09535b30":"markdown","ad73a3b9":"markdown","dfa5fb2c":"markdown"},"source":{"34c04900":"# install BERT\n!pip install -q tensorflow-text\n\n# install AdamW optimizer\n!pip install -q tf-models-official\n\nimport os\nimport shutil\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text\nfrom official.nlp import optimization  # to create AdamW optmizer\n\nimport matplotlib.pyplot as plt\n\ntf.get_logger().setLevel('ERROR')","5e446421":"url = 'https:\/\/ai.stanford.edu\/~amaas\/data\/sentiment\/aclImdb_v1.tar.gz'\n\ndataset = tf.keras.utils.get_file('\/kaggle\/working\/aclImdb_v1.tar.gz', url,\n                                  untar=True, cache_dir='.',\n                                  cache_subdir='')\n\ndataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n\ntrain_dir = os.path.join(dataset_dir, 'train')\n\n# remove unused folders to make it easier to load the data\nremove_dir = os.path.join(train_dir, 'unsup')\nshutil.rmtree(remove_dir)","b2d58665":"path = '\/kaggle\/working\/aclImdb\/'\nAUTOTUNE = tf.data.AUTOTUNE\nbatch_size = 32\nseed = 42\n\nraw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    path + 'train',\n    batch_size=batch_size,\n    validation_split=0.2,\n    subset='training',\n    seed=seed)\n\nclass_names = raw_train_ds.class_names\ntrain_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\nval_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    path + 'train',\n    batch_size=batch_size,\n    validation_split=0.2,\n    subset='validation',\n    seed=seed)\n\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\ntest_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    path + 'test',\n    batch_size=batch_size)\n\ntest_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)","2ad245b1":"bert_model_name = 'small_bert\/bert_en_uncased_L-4_H-512_A-8' \n\nmap_name_to_handle = {\n    'bert_en_uncased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_L-12_H-768_A-12\/3',\n    'bert_en_cased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_cased_L-12_H-768_A-12\/3',\n    'bert_multi_cased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_multi_cased_L-12_H-768_A-12\/3',\n    'small_bert\/bert_en_uncased_L-2_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-2_H-128_A-2\/1',\n    'small_bert\/bert_en_uncased_L-2_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-2_H-256_A-4\/1',\n    'small_bert\/bert_en_uncased_L-2_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-2_H-512_A-8\/1',\n    'small_bert\/bert_en_uncased_L-2_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-2_H-768_A-12\/1',\n    'small_bert\/bert_en_uncased_L-4_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-4_H-128_A-2\/1',\n    'small_bert\/bert_en_uncased_L-4_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-4_H-256_A-4\/1',\n    'small_bert\/bert_en_uncased_L-4_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-4_H-512_A-8\/1',\n    'small_bert\/bert_en_uncased_L-4_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-4_H-768_A-12\/1',\n    'small_bert\/bert_en_uncased_L-6_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-6_H-128_A-2\/1',\n    'small_bert\/bert_en_uncased_L-6_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-6_H-256_A-4\/1',\n    'small_bert\/bert_en_uncased_L-6_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-6_H-512_A-8\/1',\n    'small_bert\/bert_en_uncased_L-6_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-6_H-768_A-12\/1',\n    'small_bert\/bert_en_uncased_L-8_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-8_H-128_A-2\/1',\n    'small_bert\/bert_en_uncased_L-8_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-8_H-256_A-4\/1',\n    'small_bert\/bert_en_uncased_L-8_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-8_H-512_A-8\/1',\n    'small_bert\/bert_en_uncased_L-8_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-8_H-768_A-12\/1',\n    'small_bert\/bert_en_uncased_L-10_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-10_H-128_A-2\/1',\n    'small_bert\/bert_en_uncased_L-10_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-10_H-256_A-4\/1',\n    'small_bert\/bert_en_uncased_L-10_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-10_H-512_A-8\/1',\n    'small_bert\/bert_en_uncased_L-10_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-10_H-768_A-12\/1',\n    'small_bert\/bert_en_uncased_L-12_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-12_H-128_A-2\/1',\n    'small_bert\/bert_en_uncased_L-12_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-12_H-256_A-4\/1',\n    'small_bert\/bert_en_uncased_L-12_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-12_H-512_A-8\/1',\n    'small_bert\/bert_en_uncased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-12_H-768_A-12\/1',\n    'albert_en_base':\n        'https:\/\/tfhub.dev\/tensorflow\/albert_en_base\/2',\n    'electra_small':\n        'https:\/\/tfhub.dev\/google\/electra_small\/2',\n    'electra_base':\n        'https:\/\/tfhub.dev\/google\/electra_base\/2',\n    'experts_pubmed':\n        'https:\/\/tfhub.dev\/google\/experts\/bert\/pubmed\/2',\n    'experts_wiki_books':\n        'https:\/\/tfhub.dev\/google\/experts\/bert\/wiki_books\/2',\n    'talking-heads_base':\n        'https:\/\/tfhub.dev\/tensorflow\/talkheads_ggelu_bert_en_base\/1',\n}\n\nmap_model_to_preprocess = {\n    'bert_en_uncased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'bert_en_cased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_cased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-2_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-2_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-2_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-2_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-4_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-4_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-4_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-4_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-6_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-6_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-6_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-6_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-8_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-8_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-8_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-8_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-10_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-10_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-10_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-10_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-12_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-12_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-12_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'small_bert\/bert_en_uncased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'bert_multi_cased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_multi_cased_preprocess\/3',\n    'albert_en_base':\n        'https:\/\/tfhub.dev\/tensorflow\/albert_en_preprocess\/2',\n    'electra_small':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'electra_base':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'experts_pubmed':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'experts_wiki_books':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n    'talking-heads_base':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3',\n}\n\ntfhub_handle_encoder = map_name_to_handle[bert_model_name]\ntfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n\nprint(f'BERT model selected           : {tfhub_handle_encoder}')\nprint(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')","ce5d852c":"bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)","c2cf5082":"text_test = ['this is such an amazing movie!']\ntext_preprocessed = bert_preprocess_model(text_test)\n\nprint(f'Keys       : {list(text_preprocessed.keys())}')\nprint(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\nprint(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\nprint(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\nprint(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')","91850880":"bert_model = hub.KerasLayer(tfhub_handle_encoder)","a4729abf":"bert_results = bert_model(text_preprocessed)\n\nprint(f'Loaded BERT: {tfhub_handle_encoder}')\nprint(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\nprint(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :4]}')\nprint(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\nprint(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :4]}')","0bf5931c":"def build_classifier_model():\n    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n    encoder_inputs = preprocessing_layer(text_input)\n    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n    outputs = encoder(encoder_inputs)\n    net = outputs['pooled_output']\n    net = tf.keras.layers.Dropout(0.1)(net)\n    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n    return tf.keras.Model(text_input, net)","9deb27cc":"classifier_model = build_classifier_model()\nbert_raw_result = classifier_model(tf.constant(text_test))\nprint(tf.sigmoid(bert_raw_result))","c6c45430":"loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\nmetrics = tf.metrics.BinaryAccuracy()","9c331a44":"epochs = 5\nsteps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\nnum_train_steps = steps_per_epoch * epochs\nnum_warmup_steps = int(0.1*num_train_steps)\n\ninit_lr = 3e-5\noptimizer = optimization.create_optimizer(init_lr=init_lr,\n                                          num_train_steps=num_train_steps,\n                                          num_warmup_steps=num_warmup_steps,\n                                          optimizer_type='adamw')","89d1552b":"classifier_model.compile(optimizer=optimizer,\n                         loss=loss,\n                         metrics=metrics)","ed0c5214":"print(f'Training model with {tfhub_handle_encoder}')\nhistory = classifier_model.fit(x=train_ds,\n                               validation_data=val_ds,\n                               epochs=epochs)","e60cef7a":"loss, accuracy = classifier_model.evaluate(test_ds)\n\nprint(f'Loss: {loss}')\nprint(f'Accuracy: {accuracy}')","1ac62503":"history_dict = history.history\nprint(history_dict.keys())\n\nacc = history_dict['binary_accuracy']\nval_acc = history_dict['val_binary_accuracy']\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(acc) + 1)\nfig = plt.figure(figsize=(10, 6))\nfig.tight_layout()\n\nplt.subplot(2, 1, 1)\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'r', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\n# plt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(2, 1, 2)\nplt.plot(epochs, acc, 'r', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')","0dbbd3a5":"def print_my_examples(inputs, results):\n  result_for_printing = \\\n    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n                         for i in range(len(inputs))]\n  print(*result_for_printing, sep='\\n')\n  print()\n\n\nexamples = [\n    'this is such an amazing movie!',\n    'The movie was great!',\n    'The movie was meh.',\n    'The movie was okish.',\n    'The movie was terrible...'\n]\n\noriginal_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n\nprint('Results from the model in memory:')\nprint_my_examples(examples, original_results)","82923249":"## Loss function","3771a89e":"<pre><b>\n          |~\n           |.---.\n          .'_____`. \/\\\n          |~xxxxx~| ||\n          |_  #  _| ||\n     .------`-#-'-----.\n    (___|\\_________\/|_.`.\n     \/  | _________ | | |\n    \/   |\/   _|_   \\| | |\n   \/   \/X|  __|__  |\/ `.|\n  (  --< \\\\\/    _\\\\\/\/|_ |`.\n  `.    ~----.-~=====,:=======\n    ~-._____\/___:__(``\/| |\n      |    |      XX|~ | |\n       \\__\/======| \/|  `.|\n       |_\\|\\    \/|\/_|    )\n       |_   \\__\/   _| .-'\n       | \\ .'||`. \/ |(_|\n    LS |  ||.'`.||  |   )\n       |  `'|  |`'  |  \/\n       |    |  |    |\\\/\n      \nIMDB BERT Text Classification\n<\/b><\/pre>","22d1ced8":"# Using the BERT model","e66ed95b":"## Optimizer","b5d2137d":"# Test the model","b902ab65":"# Model training","7bbd01c2":"# Preprocessing data","085bbc60":"## Evaluate the model","e61fa4e2":"# Define your model","97612ae8":"## Loading the BERT model and training","3afb64a2":"# Plot the accuracy and loss over time","09535b30":"## Choose a BERT model to fine-tune","ad73a3b9":"## Training","dfa5fb2c":"## Bert preprocessing"}}