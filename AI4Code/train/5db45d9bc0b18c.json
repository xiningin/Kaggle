{"cell_type":{"197c1a3f":"code","e8aebcc0":"code","01fa4d6f":"code","5a53f9ac":"code","62f8e100":"code","2704bc75":"code","f9177c8b":"code","1a4005c4":"code","cd95bbf0":"code","b606a60c":"code","218f1fa5":"code","ed15be1a":"code","993370af":"code","45edb30a":"code","cb3fe08f":"code","ba08c6c3":"code","9e26a144":"code","fafa1b09":"code","21c8b40f":"code","676d7988":"code","32e1132b":"code","1c79ae84":"code","4c012bad":"code","dff3dbf3":"code","42a2a045":"code","bc66a610":"code","2cd9fda5":"code","cb58a39a":"code","c4dfd129":"code","0df7e84f":"code","e4789cdd":"code","7a199c35":"code","fe4888b5":"code","e5a274f7":"code","2fb497c6":"code","a1a6ceab":"code","30466250":"code","c09bb1fa":"code","0617eb67":"code","51d7fdc4":"code","802b7fea":"code","901c5a16":"code","8be8f484":"code","e38da3b4":"code","793b86e3":"code","a984382f":"code","a036d3c3":"code","7ff5c7cd":"code","270b6b63":"code","c54fb59f":"code","67385dc5":"code","e26cf503":"code","6699e848":"code","59cae5c8":"code","7ab7005f":"code","df882a2e":"code","91d53177":"code","0792bcee":"code","bddee75f":"code","9f6dcf4f":"code","65f92ab9":"code","1dbf629e":"code","121f246c":"code","50408350":"code","d3466a28":"code","0729aae4":"markdown","d66c169e":"markdown","c99c107f":"markdown","86186570":"markdown","e998019f":"markdown","2832cee4":"markdown","22292e2d":"markdown","e83807dd":"markdown","e3575918":"markdown","070d05fa":"markdown"},"source":{"197c1a3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e8aebcc0":"!pip install ..\/input\/mmcoco\/mmpycocotools\/","01fa4d6f":"from collections import defaultdict\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport PIL\nfrom PIL import Image\nimport shutil\nimport csv\nimport threading\nfrom threading import Thread\nimport sqlite3\nimport datetime\nfrom tqdm import tqdm\nfrom itertools import groupby\nfrom pycocotools import mask as mutils\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\nimport pickle\nimport cv2\nfrom multiprocessing import Pool\nimport matplotlib.pyplot as plt\nimport json\nfrom multiprocessing import Process, Queue","5a53f9ac":"train = pd.read_csv('..\/input\/hpa-single-cell-image-classification\/train.csv')\ntrain.head()","62f8e100":"# \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u0441\u0442\u043e\u043b\u0431\u0435\u0446 \u0441 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u043b\u0435\u0439\u0431\u043b\u043e\u0432 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\ntrain['label_count'] = train['Label'].apply(lambda x: len(x.split(\"|\")))\ntrain.head()","2704bc75":"# \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043e\u0434\u0438\u043d\u043e\u0447\u043d\u044b\u0445 \u043b\u0435\u0439\u0431\u043b\u043e\u0432\na = train[train['label_count'] == 1]['label_count'].count()\na","f9177c8b":"#\u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u043e\u0441\u0442\u0430\u0432\u043d\u044b\u0445 \u043b\u0435\u0439\u0431\u043b\u043e\u0432\nb = train[train['label_count'] > 1]['label_count'].count()\nb","1a4005c4":"#now lets compare between single vs multi label distribution\n# \u0442\u0435\u043f\u0435\u0440\u044c \u0434\u0430\u0432\u0430\u0439\u0442\u0435 \u0441\u0440\u0430\u0432\u043d\u0438\u043c \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043f\u043e \u043e\u0434\u043d\u043e\u0439 \u0438 \u043f\u043e \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u043c \u043c\u0435\u0442\u043a\u0430\u043c\nlabels = train[\"Label\"].apply(lambda x: x.split(\"|\"))\nlabels_count = defaultdict(int)\n\n# Update the counter \nfor label in labels:\n    if len(label) > 1:\n        for l in label:\n            labels_count[LABELS[int(l)]]+=1\n    else:\n        labels_count[LABELS[int(label[0])]]+=1\n        \nplt.figure(figsize=(10, 8))\nplt.xticks(rotation=45)\nplt.title(\"Target counts\")\nsns.barplot(list(labels_count.keys()),list(labels_count.values()))\nplt.show()","cd95bbf0":"train['Label'].value_counts()","b606a60c":"massive = []\nfor i in range(18):\n    f = len(train[train['Label'] == f'{i}'])\n    massive.append(f)\n    print(f'{i} - {f}')\nsum = 0\n\nsum = 0\nfor i in massive:\n    sum += int(i)\nprint(sum)","218f1fa5":"d = len(train[train['Label'] == '11'])\nd","ed15be1a":"h = train.loc[train.Label == '11']\nh","993370af":"# \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0441 \u043b\u0435\u0439\u0431\u043b\u043e\u043c 11\ndef show_image():\n    sns.reset_orig()\n    #get image id\n    im_id = 'b6a469d8-bbad-11e8-b2ba-ac1f6b6435d0'\n\n    cdict1 = {'red':   ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0)),\n\n             'green': ((0.0,  0.0, 0.0),\n                       (0.75, 1.0, 1.0),\n                       (1.0,  1.0, 1.0)),\n\n             'blue':  ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0))}\n\n    cdict2 = {'red':   ((0.0,  0.0, 0.0),\n                       (0.75, 1.0, 1.0),\n                       (1.0,  1.0, 1.0)),\n\n             'green': ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0)),\n\n             'blue':  ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0))}\n\n    cdict3 = {'red':   ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0)),\n\n             'green': ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0)),\n\n             'blue':  ((0.0,  0.0, 0.0),\n                       (0.75, 1.0, 1.0),\n                       (1.0,  1.0, 1.0))}\n\n    cdict4 = {'red': ((0.0,  0.0, 0.0),\n                       (0.75, 1.0, 1.0),\n                       (1.0,  1.0, 1.0)),\n\n             'green': ((0.0,  0.0, 0.0),\n                       (0.75, 1.0, 1.0),\n                       (1.0,  1.0, 1.0)),\n\n             'blue':  ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0))}\n\n    plt.register_cmap(name='greens', data=cdict1)\n    plt.register_cmap(name='reds', data=cdict2)\n    plt.register_cmap(name='blues', data=cdict3)\n    plt.register_cmap(name='yellows', data=cdict4)\n\n    #get each image channel as a greyscale image (second argument 0 in imread)\n    # \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u043a\u0430\u0436\u0434\u044b\u0439 \u043a\u0430\u043d\u0430\u043b \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043a\u0430\u043a \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0432 \u043e\u0442\u0442\u0435\u043d\u043a\u0430\u0445 \u0441\u0435\u0440\u043e\u0433\u043e (\u0432\u0442\u043e\u0440\u043e\u0439 \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442 0 \u0432 imread)\n    green = cv2.imread('..\/input\/hpa-single-cell-image-classification\/train\/{}_green.png'.format(im_id), 0)\n    red = cv2.imread('..\/input\/hpa-single-cell-image-classification\/train\/{}_red.png'.format(im_id), 0)\n    blue = cv2.imread('..\/input\/hpa-single-cell-image-classification\/train\/{}_blue.png'.format(im_id), 0)\n    yellow = cv2.imread('..\/input\/hpa-single-cell-image-classification\/train\/{}_yellow.png'.format(im_id), 0)\n\n\n    #display each channel separately\n    # \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0430\u0442\u044c \u043a\u0430\u0436\u0434\u044b\u0439 \u043a\u0430\u043d\u0430\u043b \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e\n    fig, ax = plt.subplots(nrows = 2, ncols=2, figsize=(15, 15))\n    ax[0, 0].imshow(green, cmap=\"greens\")\n    ax[0, 0].set_title(\"Protein of interest\", fontsize=18)\n    ax[0, 1].imshow(red, cmap=\"reds\")\n    ax[0, 1].set_title(\"Microtubules\", fontsize=18)\n    ax[1, 0].imshow(blue, cmap=\"blues\")\n    ax[1, 0].set_title(\"Nucleus\", fontsize=18)\n    ax[1, 1].imshow(yellow, cmap=\"yellows\")\n    ax[1, 1].set_title(\"Endoplasmic reticulum\", fontsize=18)\n    for i in range(2):\n        for j in range(2):\n            ax[i, j].set_xticklabels([])\n            ax[i, j].set_yticklabels([])\n            ax[i, j].tick_params(left=False, bottom=False)\n    plt.show()\n    \n\nshow_image()","45edb30a":"my_dict = {}\nwith open(\"..\/input\/hpa-single-cell-image-classification\/train.csv\",\"r\") as f:\n    cr = csv.reader(f, delimiter=',', lineterminator='\\n')\n    next(f, None)\n    for row in cr:\n        if len(row[1]) <= 2 and int(row[1]) < 18:\n            a = row[1].strip('\", ')\n            my_dict.setdefault(row[0].strip('\" '),[]).append(a)\nwith open(\".\/train_1.csv\", \"w\") as f:\n    writer = csv.writer(f,delimiter=',')\n    writer.writerow(('ID', 'Label'))\n    for i,j in my_dict.items():\n        d=\" \"\n        t = d.join(j)\n        writer.writerow([i]+[t])","cb3fe08f":"con = sqlite3.connect('.\/bas.db')\ncursorObj = con.cursor()\ncursorObj.execute('CREATE TABLE IF NOT EXISTS tabel(id INTEGER PRIMARY KEY AUTOINCREMENT, IDS REAL not NULL, LABEL REAL not NULL)')\ncon.commit()\nwith open(\".\/train_1.csv\",\"r\") as fg:\n    cr = csv.reader(fg, delimiter=',', lineterminator='\\n')\n    next(fg, None)\n    for a, b in cr:\n        cursorObj.execute(\"INSERT INTO tabel(IDS, LABEL) VALUES (?,?)\", (a, b))  # \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0431\u0435\u0437 id - \u043e\u043d \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u0441\u044f \u0441\u0430\u043c\ncon.commit()\ncursorObj.close()\ncon.close()","ba08c6c3":"con = sqlite3.connect('.\/bas.db')\ncursorObj = con.cursor()\ndatas = {}\nfor i in range(18):\n    cursorObj.execute(f\"SELECT DISTINCT id, IDS, LABEL FROM tabel WHERE LABEL= '{i}' LIMIT 200\")\n    rows = cursorObj.fetchall()\n    for a, b, c in rows[0:180]:\n        if c == 0.0:\n            v = '18'\n            d = '1'\n            datas.setdefault(b.strip('\" '),[]).append([v, d])\n        else:   \n            d = '1'\n            datas.setdefault(b.strip('\" '),[]).append([c, d])\n    for f, g, h in rows[181:200]:\n        if h == 0.0:\n            y = '18'\n            i = '2'\n            datas.setdefault(g.strip('\" '),[]).append([y, i])\n        else:\n            i = '2'\n            datas.setdefault(g.strip('\" '),[]).append([h, i])\ncon.commit()\ncursorObj.close()\ncon.close() \n\nwith open(\".\/train_2.csv\", \"w\") as f:\n    writer = csv.writer(f, delimiter=',')\n    writer.writerow(('id', 'label', 'val_tr'))\n    for k,l in datas.items():\n        q = int(l[0][0])\n        r = l[0][1]\n        writer.writerow([k]+[q]+[r])","9e26a144":"!mkdir .\/otbor","fafa1b09":"paths = pd.read_csv('.\/train_2.csv')\nfiles = '..\/input\/hpa-single-cell-image-classification\/train\/'\noutp = '.\/otbor\/'\nimagepaths = paths['id']\nimagepaths.head()","21c8b40f":"for i, path in tqdm(enumerate(imagepaths)):\n    img_a  = f'{files}{path}_red.png'\n    img_b  = f'{files}{path}_green.png'\n    img_c  = f'{files}{path}_blue.png'\n    img_d  = f'{files}{path}_yellow.png'\n    shutil.copy2(img_a, outp)\n    shutil.copy2(img_b, outp)\n    shutil.copy2(img_c, outp)\n    shutil.copy2(img_d, outp)","676d7988":"# for RGB images\n# \u0434\u043b\u044f RGB images\nfor i, path in tqdm(enumerate(imagepaths)):\n    img_a  = f'{files}{path}.jpg'\n    shutil.copy2(img_a, outp)","32e1132b":"paths_m = pd.read_csv('..\/input\/train-rgb-200\/train_2.csv')\nfiles_m = '..\/input\/train-rgb-200\/xotb_200_m'\noutp_m = '.\/otbor_m\/'\nimagepaths = paths_m['id']\nimagepaths.head()","1c79ae84":"for i, path in tqdm(enumerate(imagepaths)):\n    img_m  = f'{files_m}{path}.npz'\n    shutil.copy2(img_m, outp_m)","4c012bad":"%%bash\ncd .\/\nzip -r .\/otbor_m .\/*","dff3dbf3":"from IPython.display import FileLink\nFileLink(r'.\/otbor_m.zip')","42a2a045":"cell_dir = '..\/input\/otbor200\/xotb_200_m\/'\nim_dir = '..\/input\/otbor200\/xotb_200\/'\ntr = pd.read_csv('.\/train_2.csv')\n#out_dir = '.\/otbor_m'","bc66a610":"tr.head()","2cd9fda5":"tr['label'].value_counts()","cb58a39a":"tr.loc[tr['id']=='b6a469d8-bbad-11e8-b2ba-ac1f6b6435d0']","c4dfd129":"tr_set = tr.loc[tr['val_tr']== 1]\ntr_set.head()","0df7e84f":"tr_set.label.value_counts()","e4789cdd":"val_set = tr.loc[tr['val_tr']== 2]","7a199c35":"val_set['label'].value_counts()","fe4888b5":"# Class 0 has been moved to number 18 (important). remember to return it to number 0 after checking the model\n# \u041a\u043b\u0430\u0441\u0441 0 \u0431\u044b\u043b \u043f\u0435\u0440\u0435\u043c\u0435\u0449\u0435\u043d \u043d\u0430  \u043d\u043e\u043c\u0435\u0440 18 (\u0432\u0430\u0436\u043d\u043e). \u043d\u0435 \u0437\u0430\u0431\u044b\u0442\u044c \u0432\u0435\u0440\u043d\u0443\u0442\u044c \u0435\u0433\u043e \u043d\u0430 \u043d\u043e\u043c\u0435\u0440 0 \u043f\u043e\u0441\u043b\u0435 \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438 \u043c\u043e\u0434\u0435\u043b\u0438\nlabels = {\n0: \"back\",\n1: \"Nuclear membrane\",\n2: \"Nucleoli\",\n3: \"Nucleoli fibrillar center\",\n4: \"Nuclear speckles\",\n5: \"Nuclear bodies\",\n6: \"Endoplasmic reticulum\",\n7: \"Golgi apparatus\",\n8: \"Intermediate filaments\",\n9: \"Actin filaments\",\n10: \"Microtubules\",\n11: \"Mitotic spindle\",\n12: \"Centrosome\",\n13: \"Plasma membrane\",\n14: \"Mitochondria\",\n15: \"Aggresome\",\n16: \"Cytosol\",\n17: \"Vesicles and punctate cytosolic patterns\",\n18: \"Nucleoplasm\"\n}","e5a274f7":"now = datetime.datetime.now()\n\ndata = dict(\n    images=[\n        # license, url, file_name, height, width, date_captured, id\n    ],\n    type='instances',\n    annotations=[\n        # segmentation, area, iscrowd, image_id, bbox, category_id, id\n    ],\n    categories=[\n        # supercategory, id, name\n    ],\n)","2fb497c6":"class_name_to_id = {}\nfor i, each_label in enumerate(labels):\n    class_name = each_label\n    class_id = i\n    class_name_to_id[class_name] = class_id\n    data['categories'].append(dict(\n        supercategory=None,\n        id=class_id,\n        name=str(class_name),\n    ))","a1a6ceab":"data","30466250":"# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u044b \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 API:\n# encode - \u041a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0434\u0432\u043e\u0438\u0447\u043d\u044b\u0435 \u043c\u0430\u0441\u043a\u0438 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e RLE.\n# decode - \u0434\u0435\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0434\u0432\u043e\u0438\u0447\u043d\u044b\u0435 \u043c\u0430\u0441\u043a\u0438, \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e RLE.\n# merge - \u0432\u044b\u0447\u0438\u0441\u043b\u0438\u0442\u044c \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0435 \u0438\u043b\u0438 \u043f\u0435\u0440\u0435\u0441\u0435\u0447\u0435\u043d\u0438\u0435 \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u043c\u0430\u0441\u043e\u043a.\n# iou - \u0432\u044b\u0447\u0438\u0441\u043b\u0438\u0442\u044c \u043f\u0435\u0440\u0435\u0441\u0435\u0447\u0435\u043d\u0438\u0435 \u043f\u043e \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u044e \u043c\u0430\u0441\u043e\u043a.\n# area - \u0420\u0430\u0441\u0447\u0435\u0442\u043d\u0430\u044f \u043e\u0431\u043b\u0430\u0441\u0442\u044c \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u043c\u0430\u0441\u043e\u043a.\n# toBbox - \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0438\u0432\u0430\u044e\u0449\u0438\u0435 \u0440\u0430\u043c\u043a\u0438, \u043e\u043a\u0440\u0443\u0436\u0430\u044e\u0449\u0438\u0435 \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043c\u0430\u0441\u043a\u0438.\n# frPyObjects - \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u043c\u043d\u043e\u0433\u043e\u0443\u0433\u043e\u043b\u044c\u043d\u0438\u043a\u0430, bbox \u0438 \u043d\u0435\u0441\u0436\u0430\u0442\u043e\u0433\u043e RLE \u0432 \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0443\u044e \u043c\u0430\u0441\u043a\u0443 RLE.\n\n#  Rs     = encode( masks )\n#  masks  = decode( Rs )\n#  R      = merge( Rs, intersect=false )\n#  o      = iou( dt, gt, iscrowd )\n#  a      = area( Rs )\n#  bbs    = toBbox( Rs )\n#  Rs     = frPyObjects( [pyObjects], h, w )\n\n# In the API the following formats are used:\n#  Rs      - [dict] Run-length encoding of binary masks\n#  R       - dict Run-length encoding of binary mask\n#  masks   - [hxwxn] Binary mask(s) (must have type np.ndarray(dtype=uint8) in column-major order)\n#  iscrowd - [nx1] list of np.ndarray. 1 indicates corresponding gt image has crowd region to ignore\n#  bbs     - [nx4] Bounding box(es) stored as [x y w h]\n#  poly    - Polygon stored as [[x1 y1 x2 y2...],[x1 y1 ...],...] (2D list)\n#  dt,gt   - May be either bounding boxes or encoded masks\n# Both poly and bbs are 0-indexed (bbox=[0 0 1 1] encloses first pixel).","c09bb1fa":"train_out_file = '.\/train_annotations.json'\nval_out_file = '.\/val_annotations.json'\ndata_val = data.copy()\ndata_val['images'] = []\ndata_val['annotations'] = []\ndata_train = data.copy()\ndata_train['images'] = []\ndata_train['annotations'] = []","0617eb67":"# print utility from public notebook\n# \u0443\u0442\u0438\u043b\u0438\u0442\u0430 \u043f\u0435\u0447\u0430\u0442\u0438 \u0438\u0437 \u043e\u0431\u0449\u0435\u0434\u043e\u0441\u0442\u0443\u043f\u043d\u043e\u0439 \u0437\u0430\u043f\u0438\u0441\u043d\u043e\u0439 \u043a\u043d\u0438\u0436\u043a\u0438\ndef print_masked_img(image_id, mask):\n    img = load_RGBY_image(image_id, im_dir)\n    \n    plt.figure(figsize=(35, 35))\n    plt.subplot(1, 3, 1)\n    plt.imshow(img)\n    plt.title('Image')\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(mask)\n    plt.title('Mask')\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(img)\n    plt.imshow(mask, alpha=0.6)\n    plt.title('Image + Mask')\n    plt.axis('off')\n    plt.show()\n    \n# image loader, using rgb only here\n# \u0437\u0430\u0433\u0440\u0443\u0437\u0447\u0438\u043a \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439, \u0437\u0434\u0435\u0441\u044c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u0442\u043e\u043b\u044c\u043a\u043e rgb\ndef load_RGBY_image(image_id, train_or_test = im_dir, image_size=None):\n    stacked_images = read_img(image_id, train_or_test, image_size)\n    #red = read_img(image_id, \"red\", train_or_test, image_size)\n    #green = read_img(image_id, \"green\", train_or_test, image_size)\n    #blue = read_img(image_id, \"blue\", train_or_test, image_size)\n    #yellow = read_img(image_id, \"yellow\", train_or_test, image_size)\n    #stacked_images = np.transpose(np.array([red, green, blue]), (1,2,0))\n    return stacked_images\n\n# \n# def read_img(image_id, color, train_or_test = im_dir, image_size=None):\ndef read_img(image_id, im_dir, image_size=None):\n    filename = f'{im_dir}\/{image_id}.jpg'\n    #filename = f'{im_dir}\/{image_id}_{color}.png'\n    assert os.path.exists(filename), f'not found {filename}'\n    img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n    if image_size is not None:\n        img = cv2.resize(img, (image_size, image_size))\n    if img.max() > 255:\n        img_max = img.max()\n        img = (img\/255).astype('uint8')\n    return img","51d7fdc4":"image_id = '0051ccbc-bbbb-11e8-b2ba-ac1f6b6435d0'\ncell_mask = np.load('..\/input\/otbor200\/xotb_200_m\/0051ccbc-bbbb-11e8-b2ba-ac1f6b6435d0.npz')['arr_0']\nprint_masked_img(image_id, cell_mask)","802b7fea":"MAX_GREEN = 64 # filter out dark green cells # \u043e\u0442\u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432\u0430\u0442\u044c \u0442\u0435\u043c\u043d\u043e-\u0437\u0435\u043b\u0435\u043d\u044b\u0435 \u043a\u043b\u0435\u0442\u043a\u0438\ndef get_rles_from_mask(image_id, class_id):\n    mask = np.load(f'{cell_dir}\/{image_id}.npz')['arr_0']\n    rle_list = []\n    mask_ids = np.unique(mask)\n    for val in mask_ids:\n        #print(val)\n        if val == 0:\n            continue\n        binary_mask = np.where(mask == val, 1, 0).astype(np.uint8)\n        rle = coco_rle_encode(binary_mask)\n        rle_list.append(rle)\n    return rle_list, mask.shape[0], mask.shape[1]\n\ndef coco_rle_encode(mask):\n    rle = {'counts': [], 'size': list(mask.shape)}\n    counts = rle.get('counts')\n    for i, (value, elements) in enumerate(groupby(mask.ravel(order='F'))):\n        if i == 0 and value == 1:\n            counts.append(0)\n        counts.append(len(list(elements)))\n    return rle\n\n# make annotation helper called multi processes\n# \u0434\u0435\u043b\u0430\u0435\u043c \u043f\u043e\u043c\u043e\u0449\u043d\u0438\u043a \u043f\u043e \u0430\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u0438, \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u043c\u044b\u0439 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u043c\u0438 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430\u043c\u0438\ndef mk_ann(idx):\n    image_id = tr_set.iloc[idx].id\n    class_id = tr_set.iloc[idx].label\n    anno = coco_json(image_id, class_id)\n    return anno, idx, image_id","901c5a16":"# convert segmentation mask image to run length encoding\n# \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043c\u0430\u0441\u043a\u0438 \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0432 \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u043a\u0443 \u0434\u043b\u0438\u043d\u044b \u043f\u0440\u043e\u0433\u043e\u043d\u0430\n# this part would take several DAYS, depends on your CPU power. below is an easier and faster way\n# \u044d\u0442\u0430 \u0447\u0430\u0441\u0442\u044c \u0437\u0430\u0439\u043c\u0435\u0442 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0414\u041d\u0415\u0419, \u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u043c\u043e\u0449\u043d\u043e\u0441\u0442\u0438 \u0432\u0430\u0448\u0435\u0433\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440\u0430. \u043d\u0438\u0436\u0435 \u0431\u043e\u043b\u0435\u0435 \u043f\u0440\u043e\u0441\u0442\u043e\u0439 \u0438 \u0431\u044b\u0441\u0442\u0440\u044b\u0439 \u0441\u043f\u043e\u0441\u043e\u0431\ndef coco_json(image_id, class_id):\n    #for idx in range(len(tr_set)):\n#         image_id = tr_set.iloc[idx].ID\n#         class_id = tr_set.iloc[idx].Label\n    rles, height, width = get_rles_from_mask(image_id, class_id)\n    if len(rles) == 0:\n        ## Add Images to annotation\n        data_train['images'].append(dict(\n            file_name = image_id+'.jpg',\n            width = width,\n            height = height,\n            date_captured=None,\n            id=idx))\n        data_train['annotations'].append(dict())\n    else:\n        data_train['images'].append(dict(\n                file_name = image_id+'.jpg',\n                width = width,\n                height = height,\n                date_captured=None,\n                id=idx))\n        rles = mutils.frPyObjects(rles, height, width)\n        bboxes = mutils.toBbox(rles)\n    #     bboxes[:, 2] += bboxes[:, 0]\n    #     bboxes[:, 3] += bboxes[:, 1]\n        for bb, rl in zip(bboxes, rles):\n            w = bb[2]\n            h = bb[3]\n            bbox =[\n                    bb[0],\n                    bb[1],\n                    w,\n                    h]\n            area = (w)*(h)\n            data_train['annotations'].append(dict(id=len(data_train['annotations']),\n                                                  area=area, \n                                                  bbox=bbox,\n                                                  iscrowd= 0, #1,\n                                                  image_id=idx,\n                                                  category_id=int(class_id)))\n                                                  #segmentation = rl ))\n        return data_train\n\n\n#     with open(train_out_file, 'w') as f:\n#         json.dump(data_train, f, indent=4)","8be8f484":"# this part would take several hours, depends on your CPU power.\nMAX_THRE = 4 # set your avarable CPU count.\np = Pool(processes=MAX_THRE)\nannos = []\nlen_df = len(tr_set)\nfor anno, idx, image_id in p.imap(mk_ann, range(len(tr_set))):\n    if len(anno['annotations']) > 0:\n        annos.append(anno)","e38da3b4":"data_train","793b86e3":"with open(f'.\/custom_trn1.pkl', 'wb') as f:\n    pickle.dump(data_train, f)","a984382f":"with open(train_out_file, 'w') as f:\n    json.dump(data_train, f, indent=4)","a036d3c3":"cell_dir = '..\/input\/otbor200\/xotb_200_m'","7ff5c7cd":"# convert segmentation mask image to run length encoding\n# \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043c\u0430\u0441\u043a\u0438 \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0432 \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u043a\u0443 \u0434\u043b\u0438\u043d\u044b \u043f\u0440\u043e\u0433\u043e\u043d\u0430\nMAX_GREEN = 64 # filter out dark green cells # \u043e\u0442\u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432\u0430\u0442\u044c \u0442\u0435\u043c\u043d\u043e-\u0437\u0435\u043b\u0435\u043d\u044b\u0435 \u043a\u043b\u0435\u0442\u043a\u0438\ndef get_rles_from_mask(image_id, class_id):\n    mask = np.load(f'{cell_dir}\/{image_id}.npz')['arr_0']\n    #if class_id != '18':\n        #green_img = read_img(image_id, 'green')\n    rle_list = []\n    mask_ids = np.unique(mask)\n    for val in mask_ids:\n        if val == 0:\n            continue\n        binary_mask = np.where(mask == val, 1, 0).astype(bool)\n        #if class_id != '18':\n            #masked_img = green_img * binary_mask\n            #print(val, green_img.max(),masked_img.max())\n            #f masked_img.max() < MAX_GREEN:\n                #continue\n        rle = coco_rle_encode(binary_mask)\n        rle_list.append(rle)\n    return rle_list, mask.shape[0], mask.shape[1]\n\ndef coco_rle_encode(mask):\n    rle = {'counts': [], 'size': list(mask.shape)}\n    counts = rle.get('counts')\n    for i, (value, elements) in enumerate(groupby(mask.ravel(order='F'))):\n        if i == 0 and value == 1:\n            counts.append(0)\n        counts.append(len(list(elements)))\n    return rle\n\n# mmdet custom dataset generator\n# mmdet \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u0441\u043a\u0438\u0445 \u043d\u0430\u0431\u043e\u0440\u043e\u0432 \u0434\u0430\u043d\u043d\u044b\u0445\ndef mk_mmdet_custom_data(image_id, class_id):\n    rles, height, width = get_rles_from_mask(image_id, class_id)\n    if len(rles) == 0:\n        return {\n            'file_name': image_id+'.jpg',\n            'width': width,\n            'height': height,\n            'ann': {}\n        }\n    rles = mutils.frPyObjects(rles, height, width)\n    bboxes = mutils.toBbox(rles) \n    bboxes[:, 2] += bboxes[:, 0] # voc format\n    bboxes[:, 3] += bboxes[:, 1] # voc format\n    return {\n        'file_name': image_id+'.jpg',\n        'width': width,\n        'height': height,\n        'ann':\n            {\n                'bboxes': np.array(bboxes, dtype=np.float32),\n                'labels': np.zeros(len(bboxes)), # dummy data.(will be replaced later) # \u0444\u0438\u043a\u0442\u0438\u0432\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435. (\u0431\u0443\u0434\u0443\u0442 \u0437\u0430\u043c\u0435\u043d\u0435\u043d\u044b \u043f\u043e\u0437\u0436\u0435)\n                'masks': rles\n            }\n    }","270b6b63":"# make annotation helper called multi processes\n# \u0434\u0435\u043b\u0430\u0435\u043c \u043f\u043e\u043c\u043e\u0449\u043d\u0438\u043a \u043f\u043e \u0430\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u0438, \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u043c\u044b\u0439 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u043c\u0438 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430\u043c\u0438\ndef mk_ann(idx):\n    image_id = val_set.iloc[idx].id\n    class_id = val_set.iloc[idx].label\n    anno = mk_mmdet_custom_data(image_id, class_id)\n   # img = load_RGBY_image(image_id, im_dir)\n   # cv2.imwrite(f'{out_dir}\/{image_id}.jpg', img)\n    return anno, idx, image_id","c54fb59f":"# this part would take several hours, depends on your CPU power.\nMAX_THRE = 4 # set your avarable CPU count.\np = Pool(processes=MAX_THRE)\nannos = []\nlen_df = len(val_set)\nfor anno, idx, image_id in p.imap(mk_ann, range(len(val_set))):\n    if len(anno['ann']) > 0:\n        annos.append(anno)\n    print(f'{idx+1}\/{len_df}, {image_id}')","67385dc5":"lbl_cnt_dict = val_set.set_index('id').to_dict()['label']\ntrn_annos = []\nval_annos = []\n#val_len = int(len(annos)*0.01)\nfor idx in range(len(annos)):\n    ann = annos[idx]\n    filename = ann['file_name'].replace('.jpg','').replace('.png','')\n    #label_ids = lbl_cnt_dict[filename]\n    label_id = lbl_cnt_dict[filename]\n    len_ann = len(ann['ann']['bboxes'])\n    bboxes = ann['ann']['bboxes']\n    masks = ann['ann']['masks']\n    # asign image level labels to each cells\n    # \u043f\u0440\u0438\u0441\u0432\u043e\u0438\u0442\u044c \u043c\u0435\u0442\u043a\u0438 \u0443\u0440\u043e\u0432\u043d\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u044f\u0447\u0435\u0439\u043a\u0435\n    # print(label_ids)\n    # for cnt, label_id in tqdm(enumerate(label_ids.split('|'))):\n          #label_id = int(label_id)\n#     if cnt == 0:\n    ann['ann']['labels'] = np.full(len_ann, label_id)\n#     else:\n#     ann['ann']['bboxes'] = np.concatenate([ann['ann']['bboxes'],bboxes])\n#     ann['ann']['labels'] = np.concatenate([ann['ann']['labels'],np.full(len_ann, label_id)])\n#     ann['ann']['masks'] = ann['ann']['masks'] + masks    \n#     if idx < val_len:\n#         val_annos.append(ann)\n#     else:\n    trn_annos.append(ann)","e26cf503":"with open(f'.\/coco_val.pkl', 'wb') as f:\n    pickle.dump(trn_annos, f)","6699e848":"with open(f'.\/coco_train.pkl', 'wb') as f:\n    pickle.dump(trn_annos, f)","59cae5c8":"sum = 0\nfor i in range(len(objects)):\n    d = int(objects[i]['ann']['labels'][0])\n    sum += 1\nprint(sum)","7ab7005f":"# Read the annotations\nfile_path = \"..\/input\/pickles1\/mmdet_val.pkl\"\nwith open(file_path, 'rb') as f:\n    data = pickle.load(f)\nprint(data[0])","df882a2e":"mask_list = data[0]['ann']['bboxes'][0]\n#mask_list = mask_list.decode(\"utf-8\")\n#mask_list.dumps()\n#mask_list.item(0)\nmask_list.tolist()\n#label = data[0]['ann']['labels'].tolist()\n#label","91d53177":"rls = data[0]['ann']['masks']\nrls = mutils.decode(rls)\nrls","0792bcee":"rls = data[0]['ann']['masks'][0]\nrlsa = mutils.decode(rls) #.astype(bool)\nrlsa\n#a = rls[0].tolist()\n#np.count_nonzero(a)","bddee75f":"for idx in range(5):\n    image_id = data[0]['file_name'].replace('.jpg','').replace('.png','')\n    rls = data[0]['ann']['masks'][idx]\n    rlsa = mutils.decode(rls)\n    print_masked_img(image_id, rlsa)","9f6dcf4f":"color = (255,0,0)\nimgs = []\n\nimage_id = data[0]['file_name'].replace('.jpg','').replace('.png','')\nprint(image_id)\nrls = data[0]['ann']['bboxes'][2].tolist()\n#x,y,w,h = rls\nx = rls[0]\ny = rls[1]\nh = rls[2]\nw = rls[3]\na = int(x)\nb = int(y)\nc = int(h)\nd = int(w)\nprint(f'{x},{y},{h},{w}')\nimg = read_img(image_id, im_dir)\nfr = cv2.rectangle(img,(x,y),(h,w),color,2)\nwindow_name = 'image'\nplt.figure(figsize=(25, 25))\nplt.subplot(1, 3, 1)\nplt.imshow(fr)\nplt.title('Image')\nplt.axis('off')","65f92ab9":"train_set = pd.read_pickle('data\/coco_trn1a.pkl')\nvalid_set = pd.read_pickle('data\/coco__val_ful1a.pkl')\ntrain_out_file = 'data\/train_annotations.json'\nval_out_file = 'data\/val_annotations.json'\ndata_valid = data.copy()\ndata_valid['images'] = []\ndata_valid['annotations'] = []\ndata_train = data.copy()\ndata_train['images'] = []\ndata_train['annotations'] = []","1dbf629e":"# \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043c\u0430\u0441\u043a\u0438 \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0432 \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u043a\u0443 \u0434\u043b\u0438\u043d\u044b \u043f\u0440\u043e\u0433\u043e\u043d\u0430\n# this part would take several hours, depends on your CPU power.\n# this part would take several hours, depends on your CPU power.\nfor idx, var in tqdm(enumerate(valid_set)):\n    # print(f'{idx} - {var}')\n#for idx in range(len(tr_set)):\n    image_id = valid_set[idx]['file_name']\n    class_id = valid_set[idx]['ann']['labels'][0]\n    width = valid_set[idx]['width']\n    height = valid_set[idx]['height']\n    data_valid['images'].append(dict(\n            file_name = image_id,\n            width = width,\n            height = height,\n            date_captured=None,\n            id=idx))\n    bboxes = valid_set[idx]['ann']['bboxes'].astype(float)\n    #rls = tr_set[idx]['ann']['masks']['counts']\n    #rlsa = mutils.decode(rls)\n    for i, bb in enumerate(bboxes):\n        # print(f'{bb} - {i}')\n    #for bb, rl in zip(bboxes, rles):\n        x = float(bb[0])\n        y = float(bb[1])\n        w = float(bb[2])-x\n        h = float(bb[3])-y\n        bbox =[x, y, w, h]\n        #bbox = np.array(bbox, dtype=np.float64)\n        #print(bb)\n        area = (w)*(h)\n        #print(f'{bb[0]} {bb[1]} {w} {h} {area}')\n        data_valid['annotations'].append(dict(id=len(data_valid['annotations']),\n                                              area=area, \n                                              bbox=bbox,\n                                              iscrowd= 0, #1,\n                                              image_id=idx,\n                                              category_id=int(class_id)))\n                                              #segmentation = rl ))\n        #return data_valid","121f246c":"with open(val_out_file, 'w') as f:\n    json.dump(data_valid, f, indent=4)","50408350":"# \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043c\u0430\u0441\u043a\u0438 \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0432 \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u043a\u0443 \u0434\u043b\u0438\u043d\u044b \u043f\u0440\u043e\u0433\u043e\u043d\u0430\n# this part would take several hours, depends on your CPU power.\n# this part would take several hours, depends on your CPU power.\nfor idx, var in tqdm(enumerate(train_set)):\n    # print(f'{idx} - {var}')\n#for idx in range(len(tr_set)):\n    image_id = train_set[idx]['file_name']\n    class_id = train_set[idx]['ann']['labels'][0]\n    width = train_set[idx]['width']\n    height = train_set[idx]['height']\n    data_train['images'].append(dict(\n            file_name = image_id,\n            width = width,\n            height = height,\n            date_captured=None,\n            id=idx))\n    bboxes = train_set[idx]['ann']['bboxes'].astype(float)\n    #rls = tr_set[idx]['ann']['masks']['counts']\n    #rlsa = mutils.decode(rls)\n    for i, bb in enumerate(bboxes):\n        # print(f'{bb} - {i}')\n    #for bb, rl in zip(bboxes, rles):\n        x = float(bb[0])\n        y = float(bb[1])\n        w = float(bb[2])-x\n        h = float(bb[3])-y\n        bbox =[x, y, w, h]\n        #bbox = np.array(bbox, dtype=np.float64)\n        #print(bb)\n        area = (w)*(h)\n        #print(f'{bb[0]} {bb[1]} {w} {h} {area}')\n        data_train['annotations'].append(dict(id=len(data_train['annotations']),\n                                              area=area, \n                                              bbox=bbox,\n                                              iscrowd= 0, #1,\n                                              image_id=idx,\n                                              category_id=int(class_id)))\n                                              #segmentation = rl ))\n        #return data_train","d3466a28":"with open(train_out_file, 'w') as f:\n    json.dump(data_train, f, indent=4)","0729aae4":"    pickle set\n    faster way\n    \u0431\u043e\u043b\u0435\u0435 \u0431\u044b\u0441\u0442\u0440\u044b\u0439 \u0441\u043f\u043e\u0441\u043e\u0431","d66c169e":"    Selecting images for training\n    \u041e\u0442\u0431\u0438\u0440\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438","c99c107f":"    my first published notebook\n    if you find an error, write","86186570":"    val_set change to tr_set 4 cells above to create train annotations\n      val_set \u043f\u043e\u043c\u0435\u043d\u044f\u0442\u044c \u043d\u0430 tr_set \u0432 4 \u044f\u0447\u0435\u0439\u043a\u0430\u0445 \u0432\u044b\u0448\u0435, \u0447\u0442\u043e\u0431\u044b \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u0430\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u0438 \u0434\u043b\u044f train","e998019f":"    Create a selection from images with 1 label\n    \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u0438\u0437 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0441 1 \u043c\u0435\u0442\u043a\u043e\u0439","2832cee4":"repeat the same with val_set","22292e2d":"        based on:\n\n1. http:\/\/www.kaggle.com\/its7171\/mmdetection-for-segmentation-training\n1. https:\/\/www.kaggle.com\/sreevishnudamodaran\/vinbigdata-fusing-bboxes-coco-dataset\n1. https:\/\/www.kaggle.com\/anandsm7\/hpa-starter-pytorch-eda-classification-nfnets","e83807dd":"   Create annotations for training a model","e3575918":"    replace val_set with tr_set to create train annotations\n    \u0437\u0430\u043c\u0435\u043d\u0438\u0442\u044c val_set \u043d\u0430 tr_set \u0447\u0442\u043e\u0431\u044b \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u0430\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u0438 \u0434\u043b\u044f train","070d05fa":"    Create annotation files\n    \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u0444\u0430\u0439\u043b\u044b \u0430\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u0439"}}