{"cell_type":{"028d2ed9":"code","f6d65be7":"code","19b15534":"code","fb7864e4":"code","3f7c2b9b":"code","ac395f4f":"code","6295db9d":"code","e855fa77":"code","24c09945":"code","2defc71c":"code","4d13dd1c":"code","f8e62418":"code","ae78f59d":"code","bfa6da18":"code","d61a00b2":"code","8cbb8185":"code","ede7f637":"code","3d61b7c4":"code","81491914":"markdown","ca57ed12":"markdown","e423e7aa":"markdown","be7edef2":"markdown","8f363b11":"markdown","76c9e6fb":"markdown","5f212521":"markdown"},"source":{"028d2ed9":"# \/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv\n# \/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv\n# \/kaggle\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\n\n#!pip install klib","f6d65be7":"import pandas as pd\nimport numpy as np\nimport klib\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgbm","19b15534":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')","fb7864e4":"train=klib.data_cleaning(train)\ntest = klib.data_cleaning(test)","3f7c2b9b":"X = train.drop('claim',axis=1)\ny = train.claim\n\nX.drop('id', axis=1, inplace=True)\ntest.drop('id', axis=1, inplace=True)\n\nfeatures = X.columns","ac395f4f":"from sklearn.preprocessing import RobustScaler\n\nscaler = RobustScaler()\n\nX[features] = scaler.fit_transform(X)\ntest[features] = scaler.transform(test)","6295db9d":"for feat in features:\n    md = X[feat].median()\n    X[feat].fillna(md, inplace=True)\n    test[feat].fillna(md, inplace=True)","e855fa77":"X.head()","24c09945":"# Feature selection\n\n# from sklearn.feature_selection import SelectKBest, f_classif\n# feat_selector = SelectKBest(f_classif, k=100) # k = hyperparameter\n# _ = feat_selector.fit(X, y)\n\n# selected_features = features[feat_selector.get_support()]\n\n# X = X[selected_features]\n# test = test[selected_features]","2defc71c":"def train_lgbm(X_train, X_val, y_train, y_val):\n    lgb_train = lgbm.Dataset(X_train, label=y_train)\n    lgb_eval = lgbm.Dataset(X_val, label=y_val, reference=lgb_train)\n    \n    params = {\n        'objective': 'binary',\n        'metric': 'auc',\n        'is_unbalance': 'true',\n        'boosting': 'gbdt',\n        'num_leaves': 31,\n        'feature_fraction': 0.5,\n        'bagging_fraction': 0.5,\n        'bagging_freq': 20,\n        'learning_rate': 0.05,\n        'verbose': 0,\n        'device': 'gpu'\n    }\n    model = lgbm.train(\n        params,\n        lgb_train,\n        num_boost_round=2000,\n        valid_sets=lgb_eval,\n        early_stopping_rounds=100,\n        verbose_eval=100)\n    \n    return model","4d13dd1c":"from catboost import CatBoostClassifier\ndef train_catboost(X_train, X_val, y_train, y_val):\n    \n    clf = CatBoostClassifier(iterations=1000,\n                            task_type=\"GPU\",\n                            random_seed=42,\n                            learning_rate=0.2,\n                            custom_loss=['AUC'])\n    \n    clf.fit(X_train, y_train,\n            eval_set=(X_val, y_val),\n            early_stopping_rounds=100,\n            verbose_eval=100)\n    return clf","f8e62418":"from xgboost import XGBClassifier\ndef train_xgboost(X_train, X_val, y_train, y_val):\n    clf = XGBClassifier(n_estimators=500,\n                        use_label_encoder=False,\n                        learning_rate=0.2,\n                        tree_method='gpu_hist',\n                        gpu_id=0,\n                        eval_metric='auc')\n    \n    _ = clf.fit(X_train, y_train)\n    return clf","ae78f59d":"K = 3\nsplit = StratifiedKFold(random_state=1, n_splits=K, shuffle=True)","bfa6da18":"lgbm_submit_preds = np.zeros(len(test))\n\nfor i, (train_idx, val_idx) in enumerate(split.split(X, y)):\n    \n    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n    \n    model = train_lgbm(X_train, X_val, y_train, y_val)\n    \n    val_preds = model.predict(X_val, num_iteration=model.best_iteration)\n    test_preds = model.predict(test, num_iteration=model.best_iteration)\n    \n    val_auc = roc_auc_score(y_val, val_preds)\n    print(f'\\nAUC score for validation set is {val_auc}\\n')\n    \n    lgbm_submit_preds+=test_preds\/K\n\n    \ndel model","d61a00b2":"cat_submit_preds = np.zeros(len(test))\n\nfor i, (train_idx, val_idx) in enumerate(split.split(X, y)):\n    \n    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n    \n    model = train_catboost(X_train, X_val, y_train, y_val)\n    \n    val_preds = model.predict_proba(X_val)[:,1]\n    test_preds = model.predict_proba(test)[:,1]\n    \n    val_auc = roc_auc_score(y_val, val_preds)\n    print(f'\\nAUC score for validation set is {val_auc}\\n')\n    \n    cat_submit_preds+=test_preds\/K\n\ndel model","8cbb8185":"xgb_submit_preds = np.zeros(len(test))\n\nfor i, (train_idx, val_idx) in enumerate(split.split(X, y)):\n    \n    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n    \n    model = train_xgboost(X_train, X_val, y_train, y_val)\n    \n    val_preds = model.predict_proba(X_val)[:,1]\n    test_preds = model.predict_proba(test)[:,1]\n    \n    val_auc = roc_auc_score(y_val, val_preds)\n    print(f'\\nAUC score for validation set is {val_auc}\\n')\n    \n    xgb_submit_preds+=test_preds\/K\n\ndel model","ede7f637":"final_preds = (lgbm_submit_preds + cat_submit_preds + xgb_submit_preds)\/3\nsubmission['claim'] = final_preds \nsubmission.to_csv(\"output_normal.csv\", index=False)","3d61b7c4":"final_preds2 = (lgbm_submit_preds**2 + cat_submit_preds**2 + xgb_submit_preds**2)\/3\nsubmission['claim'] = final_preds2 \nsubmission.to_csv(\"output_powerof2.csv\", index=False)","81491914":"## LGBM","ca57ed12":"### Filling missing values","e423e7aa":"# XGBoost","be7edef2":"# Catboost","8f363b11":"## Submission","76c9e6fb":"## Modeling","5f212521":"# Feature Engineering"}}