{"cell_type":{"a10c69aa":"code","44bf03c3":"code","c1a8e4d9":"code","68ab4fcd":"code","474375c8":"code","b155e9ca":"code","88901ca2":"code","491a5e25":"code","e403fd8a":"code","3acd27b9":"code","6c6d18cc":"code","cb7f28fc":"code","6b6d6a9e":"markdown","ac4b19a1":"markdown","184d6d8a":"markdown","cd27b054":"markdown","171116b9":"markdown","0a97c3eb":"markdown","e5609b1c":"markdown","d788ac55":"markdown","4588b681":"markdown","554c4610":"markdown"},"source":{"a10c69aa":"import numpy as np \nimport pandas as pd \nimport re\n\nimport numpy as np \nimport requests\nfrom PIL import Image\nfrom io import BytesIO \n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\nfrom collections import Counter\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(12,8)})\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","44bf03c3":"df = pd.read_csv('\/kaggle\/input\/nietzsches-bibliography\/Nietzsche_works_corpus.csv')\ndf.head()","c1a8e4d9":"# Isolate the book wanted: Beyond Good and Evil\nbge = df[df['book_title']=='Beyond Good and Evil']['text_clean'][0]\ntokens = word_tokenize(bge)\n# items to be removed\nremoved = {'project', 'gutenberg', 'ebook', 'it', 's', 'the', 'and'}\ntokens = [ele for ele in tokens if ele not in removed]","68ab4fcd":"freq = Counter(tokens)\nsorted_freq = dict(sorted(freq.items(), key=lambda x: x[1], reverse=True))\ntop_25_words = list(sorted_freq.keys())[:25]\ntop_25_freq = list(sorted_freq.values())[:25]\nsns.barplot(y=top_25_words, x=top_25_freq)","474375c8":"def plot_cloud(wordcloud):\n    # Set figure size\n    plt.figure(figsize=(12, 8))\n    # Display image\n    plt.imshow(wordcloud) \n    # No axis details\n    plt.axis(\"off\");\n    \n\nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, \n                      background_color='black', colormap='Set2', \n                      collocations=False, stopwords = STOPWORDS)\nwordcloud.generate_from_frequencies(sorted_freq)\nplot_cloud(wordcloud)","b155e9ca":"def read_img_from_url(url):\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n    img_matrix = np.array(img)\n    return img_matrix\n\ndef read_txt_from_url(url, *size):\n    text = requests.get(url).text\n    wc = WordCloud(background_color=\"white\", max_words=100 , max_font_size=100, width=size[0], height=size[1], random_state=42)\n    wc.generate(text)\n    return wc.to_array()\n    \nimg_url = \"https:\/\/nearemmaus.files.wordpress.com\/2014\/01\/nietzsche_by_vanjamrgan.jpg\"\nimg_matrix = read_img_from_url(img_url)\n\nstopwords = set(STOPWORDS)\nstopwords.add(\"said\")\n\nwc = WordCloud(width = 3000, height = 2000, random_state=1, \n              background_color='black', colormap='Reds', \n              collocations=False, stopwords = STOPWORDS, mask=img_matrix)\n\n# generate word cloud\nwc.generate_from_frequencies(sorted_freq)\n\n# show\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.figure()\nplt.show()","88901ca2":"stemmer = PorterStemmer()\nstemmed_words = [stemmer.stem(word) for word in tokens]\nstemmed_words[100:120]","491a5e25":"lemmatizer = WordNetLemmatizer()\nlemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\nlemmatized_words[100:120]","e403fd8a":"words_tags = nltk.pos_tag(tokens)\nwords_tags[:20]","3acd27b9":"from nltk.draw.dispersion import dispersion_plot\nfrom nltk.text import Text\n# inaugural_tokens=inaugural.words()\ntext = Text(tokens)\ndispersion_plot(text, top_25_words, ignore_case=True, title='Beyond Good and Evil top 25 words Plot')","6c6d18cc":"from nltk import FreqDist\nfrom nltk.corpus import stopwords\nfrequency_distribution = FreqDist(tokens)\nfrequency_distribution.most_common(20)","cb7f28fc":"frequency_distribution.plot(20, cumulative=True)","6b6d6a9e":"# Lemmatizing","ac4b19a1":"# Frequency Distribution with NLTK","184d6d8a":"# Word Frequency","cd27b054":"## 1- Simple","171116b9":"# Stemming","0a97c3eb":"# Dispersion Plot","e5609b1c":"## 2 - With a mask image of Nietzsche","d788ac55":"# Tagging words in the text","4588b681":"# Word Cloud","554c4610":"# Importing the dataset"}}