{"cell_type":{"0f9eb09a":"code","5a54e508":"code","407a4389":"code","a19c810c":"code","927b8092":"code","85c35589":"code","2bbc4311":"code","947e112e":"markdown","7b05d187":"markdown","16fa5fdf":"markdown","e7860bed":"markdown","ba96597d":"markdown","7bd3c472":"markdown","344ef0e3":"markdown","6caa65f3":"markdown","6b595875":"markdown"},"source":{"0f9eb09a":"!pip install d2l > d2l_install.out\nimport collections\nimport re\nfrom d2l import torch as d2l","5a54e508":"#@save\nd2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt',\n                                '090b5e7e70c295757f55df93cb0a180b9691891a')\n\ndef read_time_machine():  #@save\n    \"\"\"Load the time machine dataset into a list of text lines.\"\"\"\n    with open(d2l.download('time_machine'), 'r') as f:\n        lines = f.readlines()\n    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n\nlines = read_time_machine()\nprint(f'# text lines: {len(lines)}')\nprint(lines[0])\nprint(lines[10])","407a4389":"def tokenize(lines, token='word'):  #@save\n    \"\"\"\u5c06\u6587\u672c\u884c\u62c6\u5206\u4e3a\u5355\u8bcd\u6216\u5b57\u7b26\u6807\u8bb0\u3002\"\"\"\n    if token == 'word':\n        return [line.split() for line in lines]\n    elif token == 'char':\n        return [list(line) for line in lines]\n    else:\n        print('\u9519\u8bef\uff1a\u672a\u77e5\u4ee4\u724c\u7c7b\u578b\uff1a' + token)\n\ntokens = tokenize(lines)\nfor i in range(11):\n    print(tokens[i])","a19c810c":"class Vocab:  #@save\n    \"\"\"\u6587\u672c\u8bcd\u8868\"\"\"\n    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n        if tokens is None:\n            tokens = []\n        if reserved_tokens is None:\n            reserved_tokens = []\n        # \u6309\u51fa\u73b0\u9891\u7387\u6392\u5e8f\n        counter = count_corpus(tokens)\n        self.token_freqs = sorted(counter.items(), key=lambda x: x[1],\n                                  reverse=True)\n        # \u672a\u77e5\u6807\u8bb0\u7684\u7d22\u5f15\u4e3a0\n        self.unk, uniq_tokens = 0, ['<unk>'] + reserved_tokens\n        uniq_tokens += [\n            token for token, freq in self.token_freqs\n            if freq >= min_freq and token not in uniq_tokens]\n        self.idx_to_token, self.token_to_idx = [], dict()\n        for token in uniq_tokens:\n            self.idx_to_token.append(token)\n            self.token_to_idx[token] = len(self.idx_to_token) - 1\n\n    def __len__(self):\n        return len(self.idx_to_token)\n\n    def __getitem__(self, tokens):\n        if not isinstance(tokens, (list, tuple)):\n            return self.token_to_idx.get(tokens, self.unk)\n        return [self.__getitem__(token) for token in tokens]\n\n    def to_tokens(self, indices):\n        if not isinstance(indices, (list, tuple)):\n            return self.idx_to_token[indices]\n        return [self.idx_to_token[index] for index in indices]\n\ndef count_corpus(tokens):  #@save\n    \"\"\"Count token frequencies.\"\"\"\n    # \u8fd9\u91cc\u7684 `tokens` \u662f1D\u5217\u8868\u62162D\u5217\u8868\n    if len(tokens) == 0 or isinstance(tokens[0], list):\n        # \u5c06\u4ee4\u724c\u5217\u8868\u5c55\u5e73\n        tokens = [token for line in tokens for token in line]\n    return collections.Counter(tokens)","927b8092":"vocab = Vocab(tokens)\nprint(list(vocab.token_to_idx.items())[:10])","85c35589":"for i in [0, 10]:\n    print('words:', tokens[i])\n    print('indices:', vocab[tokens[i]])","2bbc4311":"def load_corpus_time_machine(max_tokens=-1):  #@save\n    \"\"\"\u8fd4\u56de\u65f6\u5149\u673a\u5668\u6570\u636e\u96c6\u7684\u4ee4\u724c\u7d22\u5f15\u548c\u8bcd\u6c47\u8868\u3002\"\"\"\n    lines = read_time_machine()\n    tokens = tokenize(lines, 'char')\n    vocab = Vocab(tokens)\n    # \u56e0\u4e3a\u65f6\u5149\u673a\u5668\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e00\u4e2a\u6587\u672c\u884c\u4e0d\u4e00\u5b9a\u662f\u4e00\u4e2a\u53e5\u5b50\u6216\u6bb5\u843d\uff0c\n    # \u6240\u4ee5\u5c06\u6240\u6709\u6587\u672c\u884c\u5c55\u5e73\u5230\u4e00\u4e2a\u5217\u8868\u4e2d\n    corpus = [vocab[token] for line in tokens for token in line]\n    if max_tokens > 0:\n        corpus = corpus[:max_tokens]\n    return corpus, vocab\n\ncorpus, vocab = load_corpus_time_machine()\nlen(corpus), len(vocab)","947e112e":"# \u6587\u672c\u9884\u5904\u7406\n:label:`sec_text_preprocessing`\n\n\u6211\u4eec\u56de\u987e\u548c\u8bc4\u4f30\u4e86\u5e8f\u5217\u6570\u636e\u7684\u7edf\u8ba1\u5de5\u5177\u548c\u9884\u6d4b\u6311\u6218\u3002\u8fd9\u4e9b\u6570\u636e\u53ef\u4ee5\u6709\u591a\u79cd\u5f62\u5f0f\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6b63\u5982\u6211\u4eec\u5c06\u5728\u672c\u4e66\u7684\u8bb8\u591a\u7ae0\u8282\u4e2d\u91cd\u70b9\u4ecb\u7ecd\u7684\u90a3\u6837\uff0c\u6587\u672c\u662f\u5e8f\u5217\u6570\u636e\u6700\u5e38\u89c1\u4f8b\u5b50\u3002\u4f8b\u5982\uff0c\u4e00\u7bc7\u6587\u7ae0\u53ef\u4ee5\u7b80\u5355\u5730\u770b\u4f5c\u662f\u4e00\u4e2a\u5355\u8bcd\u5e8f\u5217\uff0c\u751a\u81f3\u662f\u4e00\u4e2a\u5b57\u7b26\u5e8f\u5217\u3002\u4e3a\u4e86\u65b9\u4fbf\u6211\u4eec\u5c06\u6765\u5bf9\u5e8f\u5217\u6570\u636e\u7684\u5b9e\u9a8c\uff0c\u6211\u4eec\u5c06\u5728\u672c\u8282\u4e2d\u4e13\u95e8\u89e3\u91ca\u6587\u672c\u7684\u5e38\u89c1\u9884\u5904\u7406\u6b65\u9aa4\u3002\u901a\u5e38\uff0c\u8fd9\u4e9b\u6b65\u9aa4\u5305\u62ec\uff1a\n\n1. \u5c06\u6587\u672c\u4f5c\u4e3a\u5b57\u7b26\u4e32\u52a0\u8f7d\u5230\u5185\u5b58\u4e2d\u3002\n1. \u5c06\u5b57\u7b26\u4e32\u62c6\u5206\u4e3a\u6807\u8bb0\uff08\u5982\uff0c\u5355\u8bcd\u548c\u5b57\u7b26\uff09\u3002\n1. \u5efa\u7acb\u4e00\u4e2a\u8bcd\u6c47\u8868\uff0c\u5c06\u62c6\u5206\u7684\u6807\u8bb0\u6620\u5c04\u5230\u6570\u5b57\u7d22\u5f15\u3002\n1. \u5c06\u6587\u672c\u8f6c\u6362\u4e3a\u6570\u5b57\u7d22\u5f15\u5e8f\u5217\uff0c\u4ee5\u4fbf\u6a21\u578b\u53ef\u4ee5\u8f7b\u677e\u5730\u5bf9\u5176\u8fdb\u884c\u64cd\u4f5c\u3002\n","7b05d187":"## \u5c0f\u7ed3\n\n* \u6587\u672c\u662f\u5e8f\u5217\u6570\u636e\u7684\u4e00\u79cd\u91cd\u8981\u5f62\u5f0f\u3002\n* \u4e3a\u4e86\u5bf9\u6587\u672c\u8fdb\u884c\u9884\u5904\u7406\uff0c\u6211\u4eec\u901a\u5e38\u5c06\u6587\u672c\u62c6\u5206\u4e3a\u6807\u8bb0\uff0c\u6784\u5efa\u8bcd\u6c47\u8868\u5c06\u6807\u8bb0\u5b57\u7b26\u4e32\u6620\u5c04\u4e3a\u6570\u5b57\u7d22\u5f15\uff0c\u5e76\u5c06\u6587\u672c\u6570\u636e\u8f6c\u6362\u4e3a\u6807\u8bb0\u7d22\u5f15\u4ee5\u4f9b\u6a21\u578b\u64cd\u4f5c\u3002\n\n## \u7ec3\u4e60\n\n1. \u6807\u8bb0\u5316\u662f\u4e00\u4e2a\u5173\u952e\u7684\u9884\u5904\u7406\u6b65\u9aa4\u3002\u5b83\u56e0\u8bed\u8a00\u800c\u5f02\u3002\u5c1d\u8bd5\u627e\u5230\u53e6\u5916\u4e09\u79cd\u5e38\u7528\u7684\u6587\u672c\u6807\u8bb0\u65b9\u6cd5\u3002\n1. \u5728\u672c\u8282\u7684\u5b9e\u9a8c\u4e2d\uff0c\u5c06\u6587\u672c\u6807\u8bb0\u4e3a\u5355\u8bcd\uff0c\u5e76\u66f4\u6539 `Vocab` \u5b9e\u4f8b\u7684 `min_freq` \u53c2\u6570\u3002\u8fd9\u5bf9\u8bcd\u6c47\u91cf\u6709\u4f55\u5f71\u54cd\uff1f\n","16fa5fdf":"\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u5c06\u6bcf\u4e00\u884c\u6587\u672c\u8f6c\u6362\u6210\u4e00\u4e2a\u6570\u5b57\u7d22\u5f15\u5217\u8868\u3002\n","e7860bed":"\u6211\u4eec\u4f7f\u7528\u65f6\u5149\u673a\u5668\u6570\u636e\u96c6\u4f5c\u4e3a\u8bed\u6599\u5e93\u6765\u6784\u5efa\u8bcd\u6c47\u8868\u3002\u7136\u540e\uff0c\u6211\u4eec\u6253\u5370\u524d\u51e0\u4e2a\u5e38\u89c1\u6807\u8bb0\u53ca\u5176\u7d22\u5f15\u3002\n","ba96597d":"## \u8bfb\u53d6\u6570\u636e\u96c6\n\n\u4e3a\u4e86\u5f00\u59cb\uff0c\u6211\u4eec\u4eceH.G.Well\u7684[*\u65f6\u5149\u673a\u5668*](http:\/\/www.gutenberg.org\/ebooks\/35)\u4e2d\u52a0\u8f7d\u6587\u672c\u3002\u8fd9\u662f\u4e00\u4e2a\u76f8\u5f53\u5c0f\u7684\u8bed\u6599\u5e93\uff0c\u53ea\u670930000\u591a\u4e2a\u5355\u8bcd\uff0c\u4f46\u5bf9\u4e8e\u6211\u4eec\u60f3\u8981\u8bf4\u660e\u7684\u76ee\u6807\u6765\u8bf4\uff0c\u8fd9\u8db3\u591f\u4e86\u3002\u73b0\u5b9e\u4e2d\u7684\u6587\u6863\u96c6\u5408\u53ef\u80fd\u4f1a\u5305\u542b\u6570\u5341\u4ebf\u4e2a\u5355\u8bcd\u3002\u4e0b\u9762\u7684\u51fd\u6570\u5c06\u6570\u636e\u96c6\u8bfb\u53d6\u5230\u6587\u672c\u884c\u7ec4\u6210\u7684\u5217\u8868\u4e2d\uff0c\u5176\u4e2d\u6bcf\u884c\u90fd\u662f\u4e00\u4e2a\u5b57\u7b26\u4e32\u3002\u4e3a\u7b80\u5355\u8d77\u89c1\uff0c\u8fd9\u91cc\u6211\u4eec\u5ffd\u7565\u6807\u70b9\u7b26\u53f7\u548c\u5927\u5199\u3002\n","7bd3c472":"## \u8bcd\u6c47\n\n\u6807\u8bb0\u7684\u5b57\u7b26\u4e32\u7c7b\u578b\u4e0d\u65b9\u4fbf\u6a21\u578b\u4f7f\u7528\uff0c\u56e0\u4e3a\u6a21\u578b\u9700\u8981\u8f93\u5165\u6570\u5b57\u3002\u73b0\u5728\uff0c\u8ba9\u6211\u4eec\u6784\u5efa\u4e00\u4e2a\u5b57\u5178\uff0c\u901a\u5e38\u4e5f\u53eb\u505a*\u8bcd\u8868*\uff08Vocabulary\uff09\u6765\u5c06\u5b57\u7b26\u4e32\u6807\u8bb0\u6620\u5c04\u5230\u4ece0\u5f00\u59cb\u7684\u6570\u5b57\u7d22\u5f15\u4e2d\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u9996\u5148\u7edf\u8ba1\u8bad\u7ec3\u96c6\u4e2d\u6240\u6709\u6587\u6863\u4e2d\u7684\u552f\u4e00\u6807\u8bb0\uff0c\u5373*\u8bed\u6599*\uff08corpus\uff09\uff0c\u7136\u540e\u6839\u636e\u6bcf\u4e2a\u552f\u4e00\u6807\u8bb0\u7684\u51fa\u73b0\u9891\u7387\u4e3a\u5176\u5206\u914d\u4e00\u4e2a\u6570\u5b57\u7d22\u5f15\u3002\u5f88\u5c11\u51fa\u73b0\u7684\u6807\u8bb0\u901a\u5e38\u88ab\u79fb\u9664\uff0c\u8fd9\u53ef\u4ee5\u964d\u4f4e\u590d\u6742\u6027\u3002\u8bed\u6599\u5e93\u4e2d\u4e0d\u5b58\u5728\u6216\u5df2\u5220\u9664\u7684\u4efb\u4f55\u6807\u8bb0\u90fd\u5c06\u6620\u5c04\u5230\u4e00\u4e2a\u7279\u6b8a\u7684\u672a\u77e5\u6807\u8bb0 \u201c&lt;unk&gt;\u201d \u3002\u6211\u4eec\u53ef\u4ee5\u9009\u62e9\u6dfb\u52a0\u4fdd\u7559\u4ee4\u724c\u7684\u5217\u8868\uff0c\u4f8b\u5982\u201c&lt;pad&gt;\u201d\u8868\u793a\u586b\u5145\uff1b\u201c&lt;bos&gt;\u201d\u8868\u793a\u5e8f\u5217\u7684\u5f00\u59cb\uff1b\u201c&lt;eos&gt;\u201d\u8868\u793a\u5e8f\u5217\u7684\u7ed3\u675f\u3002\n","344ef0e3":"## \u628a\u6240\u6709\u7684\u4e1c\u897f\u653e\u5728\u4e00\u8d77\n\n\u4f7f\u7528\u4e0a\u8ff0\u51fd\u6570\uff0c\u6211\u4eec\u5c06\u6240\u6709\u5185\u5bb9\u6253\u5305\u5230 `load_corpus_time_machine` \u51fd\u6570\u4e2d\uff0c\u8be5\u51fd\u6570\u8fd4\u56de `corpus`\uff08\u6807\u8bb0\u7d22\u5f15\u5217\u8868\uff09\u548c `vocab`\uff08\u65f6\u5149\u673a\u5668\u8bed\u6599\u5e93\u7684\u8bcd\u6c47\u8868\uff09\u3002\u6211\u4eec\u5728\u8fd9\u91cc\u6240\u505a\u7684\u4fee\u6539\u662f\uff1a\n- 1\u3001\u6211\u4eec\u5c06\u6587\u672c \u6807\u8bb0\u5316\u4e3a\u5b57\u7b26\uff0c\u800c\u4e0d\u662f\u5355\u8bcd\uff0c\u4ee5\u7b80\u5316\u540e\u9762\u90e8\u5206\u4e2d\u7684\u8bad\u7ec3\uff1b\n- 2\u3001`corpus`\u662f\u5355\u4e2a\u5217\u8868\uff0c\u800c\u4e0d\u662f\u6807\u8bb0\u5217\u8868\u5d4c\u5957\uff0c\u56e0\u4e3a\u65f6\u5149\u673a\u5668\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e2a\u6587\u672c\u884c\u4e0d\u4e00\u5b9a\u662f\u53e5\u5b50\u6216\u6bb5\u843d\u3002\n","6caa65f3":"[Discussions](https:\/\/discuss.d2l.ai\/t\/2094)\n","6b595875":"## \u6807\u8bb0\u5316\n\n\u4ee5\u4e0b `tokenize` \u51fd\u6570\u5c06\u5217\u8868\u4f5c\u4e3a\u8f93\u5165\uff0c\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u662f\u6587\u672c\u5e8f\u5217\uff08\u5982\uff0c\u6587\u672c\u884c\uff09\u3002\u6bcf\u4e2a\u6587\u672c\u5e8f\u5217\u88ab\u62c6\u5206\u6210\u4e00\u4e2a\u6807\u8bb0\u5217\u8868\u3002*\u6807\u8bb0*\uff08token\uff09\u662f\u6587\u672c\u7684\u57fa\u672c\u5355\u4f4d\u3002\u6700\u540e\u8fd4\u56de\u4e00\u4e2a\u6807\u8bb0\u5217\u8868\uff0c\u5176\u4e2d\u6bcf\u4e2a\u6807\u8bb0\u90fd\u662f\u4e00\u4e2a\u5b57\u7b26\u4e32\uff08string\uff09\u3002\n"}}