{"cell_type":{"9fa2c824":"code","95780735":"code","29cb9a22":"code","468147cd":"code","e96fa394":"code","3c2bb7a3":"code","96312ef1":"code","8463d1bd":"code","7b584be0":"code","15265ced":"code","91859e3a":"code","72fbbbb6":"code","8f47e98e":"code","449e0215":"code","a28f3e97":"code","89bedb4e":"code","0bc1003e":"code","9f1a85d6":"code","93a0d0d5":"code","5d9bea73":"code","b488caf3":"code","7be3a429":"code","ead872c3":"code","52680280":"code","249afe8b":"code","f20edab2":"markdown","bf8562b3":"markdown","1e5ceefc":"markdown","4dcae576":"markdown","099678b3":"markdown","b4407616":"markdown","80285114":"markdown","a94ffdca":"markdown","af8e074c":"markdown","9c4576d5":"markdown","eb87244b":"markdown","152478c3":"markdown","4fa0beb1":"markdown","b0f826cb":"markdown","d8c4672d":"markdown","3d24f177":"markdown","35c5ab84":"markdown","0390f778":"markdown"},"source":{"9fa2c824":"!pip install -q tensorflow==2.6.0","95780735":"import tensorflow as tf\nimport numpy as np\nfrom sklearn import metrics\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","29cb9a22":"class Config:\n    batch_size = 256\n    epochs = 5\n    embed_dim = 256\n    validation_split = 0.15\n    maxlen = 30\n    vocab_size = 15000\n    labels = np.array([\"English\", \"Spanish\"])\n    num_classes = len(labels)\n    model_path = \"model.tf\"\nconfig = Config()","468147cd":"data = pd.read_csv(\"\/kaggle\/input\/englishspanish-translation-dataset\/data.csv\")","e96fa394":"data.head()","3c2bb7a3":"english_data = pd.DataFrame({\"sentence\": data[\"english\"], \"label\": 0})\nspanish_data = pd.DataFrame({\"sentence\": data[\"spanish\"], \"label\": 1})\nall_data = pd.concat([english_data, spanish_data], axis=0)","96312ef1":"vectorizer = layers.TextVectorization(\n    max_tokens=config.vocab_size, \n    output_sequence_length=config.maxlen\n)\nvectorizer.adapt(all_data[\"sentence\"])","8463d1bd":"sentences = list(all_data.iloc[np.random.choice(all_data.shape[0], 10)][\"sentence\"])\nprint(sentences)","7b584be0":"vectorizer(sentences)","15265ced":"train, test = train_test_split(all_data, shuffle=True, test_size=config.validation_split, random_state=42)\ntrain.shape, test.shape","91859e3a":"train_ds = tf.data.Dataset.from_tensor_slices((train[\"sentence\"], train[\"label\"])).batch(config.batch_size)\ntrain_ds = train_ds.shuffle(256).take(train.shape[0] \/\/ config.batch_size).cache().repeat(1).prefetch(16)","72fbbbb6":"test_ds = tf.data.Dataset.from_tensor_slices((test[\"sentence\"], test[\"label\"])).batch(config.batch_size)\ntest_ds = test_ds.take(test.shape[0] \/\/ config.batch_size).cache().repeat(1).prefetch(16)","8f47e98e":"for x, y in train_ds.take(1):\n    print(x.shape, y.shape)\n    print(x[:10])\n    print(y[:10])","449e0215":"def get_model():\n    model = keras.Sequential([\n        layers.Input((None, ), dtype=\"string\"),\n        vectorizer,\n        layers.Embedding(config.vocab_size, config.embed_dim),\n        layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n        layers.LSTM(64),\n        layers.GaussianDropout(0.3),\n        layers.Dense(config.num_classes, activation=\"softmax\")\n    ])\n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    return model","a28f3e97":"model = get_model()","89bedb4e":"keras.utils.plot_model(model, show_shapes=True)","0bc1003e":"history = model.fit(train_ds, epochs=config.epochs, validation_data=test_ds)","9f1a85d6":"pd.DataFrame(history.history).plot()","93a0d0d5":"y_pred = model.predict(test_ds)\ny_pred = np.argmax(y_pred, axis=-1)\ny_pred.shape","5d9bea73":"cm = metrics.confusion_matrix(test[\"label\"][:y_pred.shape[0]], y_pred)\nsns.heatmap(cm, annot=True, cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.show()","b488caf3":"cls_report = metrics.classification_report(test[\"label\"][:y_pred.shape[0]], y_pred)\nprint(cls_report)","7be3a429":"model.save_weights(config.model_path, save_format=\"tf\")","ead872c3":"model = get_model()\nmodel.load_weights(config.model_path)","52680280":"sentences = test.iloc[np.random.choice(test.shape[0], 30)][\"sentence\"]\nresults = config.labels[np.argmax(model.predict(sentences), axis=-1)]","249afe8b":"for sentence, result in zip(sentences, results):\n    print(\"\\\"%s\\\" is a %s sentence.\"%(sentence, result))","f20edab2":"## Model Development","bf8562b3":"## Conclusion\nThis Model can achive an extremely high accuracy with nearly 100% in classfiying both English and Spanish Sentences with only a few samples miss-classified. That's great.","1e5ceefc":"### Confusion Matrix","4dcae576":"## Overview\nIn this notebook I will:\n* Build a simple Language Classification Model with Bidirectional-LSTM Model.\n* Use [TextVectorization](https:\/\/keras.io\/api\/layers\/preprocessing_layers\/text\/text_vectorization\/) Layer to do text preprocessing easily.\n* Repalce common Dropout layer with [GaussianDropout](https:\/\/keras.io\/api\/layers\/regularization_layers\/gaussian_dropout\/). \n* Evaluate this Model's performance using not only accuarcy, but also confusion matrix and classification report.","099678b3":"## Loading data","b4407616":"## Make Predictions","80285114":"### Train test split","a94ffdca":"## Model Training","af8e074c":"# English-Spanish Classification: Bidirectional-LSTM","9c4576d5":"### Create a TextVectorization layer","eb87244b":"Choose a few samples to understand inputs and outputs of this layer.","152478c3":"## Setup","4fa0beb1":"### Loss & Accuracy over time","b0f826cb":"### Visualize the architecture","d8c4672d":"## Save the Model","3d24f177":"## Model Evaluation","35c5ab84":"### Classification Report","0390f778":"## Table of Contents\n* Overview\n* Setup\n* Loading data\n* Model Development\n* Model Evaluation\n* Save the Model\n* Conclusion"}}