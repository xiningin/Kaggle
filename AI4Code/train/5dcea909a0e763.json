{"cell_type":{"00b64477":"code","02e0b7e6":"code","c9985144":"code","0907697e":"code","4ef5c9a4":"code","1fe0e540":"code","df5b40ae":"code","4de0501e":"code","8f1eeb01":"code","96916206":"code","af900c55":"code","0eb9abfe":"code","0239d952":"code","5fb1006a":"code","211043f9":"code","824040c4":"code","c9143488":"code","83e13bf0":"code","14493e93":"code","c0bd21aa":"code","3147a879":"code","cf26254d":"code","51628101":"code","1e37ef94":"code","a6ef0cb0":"code","1342ace2":"code","e87c4317":"code","b1f22641":"code","4a71f243":"markdown","1d04d1a4":"markdown","df05775e":"markdown","028c383f":"markdown"},"source":{"00b64477":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold, learning_curve, KFold, cross_validate\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, BaggingRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n# Ensemble Models\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom catboost import CatBoostRegressor\nfrom vecstack import stacking\nimport pickle\nfrom sklearn.linear_model import Ridge, Lasso, ElasticNet\nfrom sklearn import preprocessing\nimport optuna","02e0b7e6":"df_train = pd.read_csv(\"..\/input\/futureskills-prime-hackathon\/Hackathon_train_V2 (1).csv\", sep=';')\ndf_test = pd.read_csv(\"..\/input\/futureskills-prime-hackathon\/Hackathon_test_V2.csv\", sep=';')","c9985144":"df_train.isnull().sum()","0907697e":"df_train.head()","4ef5c9a4":"df = pd.concat([df_train,df_test],axis=0,sort=False)\ndf.drop(['gross'], axis=1, inplace=True)","1fe0e540":"df.isnull().sum()","df5b40ae":"df.info()","4de0501e":"df['countries_launched_in'].fillna(df['countries_launched_in'].mode()[0], inplace = True)\ndf['countries_launched_in'] = df['countries_launched_in'].astype(int)\ndf['director_facebook_likes'].fillna(df['director_facebook_likes'].mode()[0], inplace=True)\ndf['actor_1_facebook_likes'].fillna(df['actor_1_facebook_likes'].mode()[0], inplace=True)\ndf['content_rating'].fillna(df['content_rating'].mode()[0], inplace=True)\ndf['num_user_for_reviews'].fillna(df['num_user_for_reviews'].mode()[0], inplace=True)\ndf['budget'].fillna(df['budget'].mode()[0], inplace=True)\ndf['num_voted_users'].fillna(df['num_voted_users'].mode()[0], inplace=True)\ndf['duration'].fillna(df['duration'].mode()[0], inplace=True)\ndf['num_critic_for_reviews'].fillna(df['num_critic_for_reviews'].mode()[0], inplace=True)\ndf.picture_type  = df.picture_type .fillna('NONE')\ndf.language  = df.language.fillna('NONE')\ndf.origin_country  = df.origin_country.fillna('NONE')","8f1eeb01":"df['mean_actor_fb_likes'] = (df['actor_1_facebook_likes'] + df['actor_2_facebook_likes'] + df['actor_3_facebook_likes'])\/3\ndf['mean_all_fb_likes'] = (df['director_facebook_likes'] + df['movie_facebook_likes'] + df['actor_1_facebook_likes'] + df['actor_2_facebook_likes'] + df['actor_3_facebook_likes'])\/5\ndf['mean_user_reviews'] = (df['num_voted_users'] + df['num_user_for_reviews'])\/2","96916206":"df.head()","af900c55":"not_features = [] \ncols = list(df.columns)\nfeatures = [feat for feat in cols if feat not in not_features]","0eb9abfe":"object_cols = [col for col in df[features].columns if df[features].dtypes[col]=='object']\nprint(object_cols)","0239d952":"for obj in object_cols:\n    #Content Rating is ordered hence skipping\n    if obj == 'content_rating':\n        pass\n    else:\n        le=LabelEncoder()\n        cat = list(df[obj])\n        le.fit(cat)\n        df[obj] = le.transform(df[obj])","5fb1006a":"Oe = OrdinalEncoder()\nOe.fit(df[['content_rating']])\ndf[['content_rating']] = Oe.transform(df[['content_rating']])","211043f9":"df['std'] = df.std(axis=1)\ndf['var'] = df.var(axis=1)","824040c4":"columns = list(df.columns)\nfor item in df.columns:\n    if item == 'movie_ID':\n        pass\n    else:\n        df_mean = df[item].mean()\n        df_std = df[item].std()\n        df[item] = (df[item] - df_mean) \/ df_std","c9143488":"df.head()","83e13bf0":"train = df[:7050]\ntest = df[7050:]","14493e93":"train_targets = df_train['gross']","c0bd21aa":"train['gross'] = df_train['gross']\ntrain.head()","3147a879":"train[\"kfold\"] = -1\n# initialize stratified k-fold\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\nfor fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=train)):\n    train.loc[valid_indicies, \"kfold\"] = fold","cf26254d":"target = ['gross']\nnot_features = ['user_id', 'kfold', 'gross']\ncols = list(train.columns)\nfeatures = [feat for feat in cols if feat not in not_features]","51628101":"#Linear Regression\nscores = []\nfor fold in range(5):\n    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n    xvalid = train[train.kfold == fold].reset_index(drop=True)\n\n    ytrain = xtrain['gross']\n    yvalid = xvalid['gross']\n    \n    xtrain = xtrain[features]\n    xvalid = xvalid[features]\n    \n    model = LinearRegression()\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(\"R2 score is: \", r2_score(yvalid, preds_valid))\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","1e37ef94":"# catboost\ndef run(trial):\n    fold = 0\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True)\n    iterations = trial.suggest_int(\"iterations\", 1000, 10000)\n    l2_leaf_reg = trial.suggest_float(\"l2_leaf_reg\", 0.1, 15)\n    depth = trial.suggest_int(\"depth\", 1, 7)\n\n    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n    xvalid = train[train.kfold == fold].reset_index(drop=True)\n\n    ytrain = xtrain['gross']\n    yvalid = xvalid['gross']\n    \n    xtrain = xtrain[features]\n    xvalid = xvalid[features]\n\n    model = CatBoostRegressor(\n        random_state=RANDOM_SEED,\n        learning_rate=learning_rate,\n        l2_leaf_reg=l2_leaf_reg,\n        depth=depth\n       \n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    print(\"R2 score is: \", r2_score(yvalid, preds_valid))\n    r2 = r2_score(yvalid, preds_valid)\n    return r2","a6ef0cb0":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(run, n_trials=200)\nstudy.best_params","1342ace2":"best_params = {'learning_rate': 0.16998194364103733,\n 'iterations': 7000,\n 'l2_leaf_reg': 1.9778307194400808,\n 'depth': 7}","e87c4317":"# catboost\nscores = []\nfor fold in range(5):\n\n    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n    xvalid = train[train.kfold == fold].reset_index(drop=True)\n\n    ytrain = xtrain['gross']\n    yvalid = xvalid['gross']\n    \n    xtrain = xtrain[features]\n    xvalid = xvalid[features]\n\n    model = CatBoostRegressor(**best_params)\n    \n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    print(\"R2 score is: \", r2_score(yvalid, preds_valid))\n    r2 = r2_score(yvalid, preds_valid)\n    print(fold, r2)\n    scores.append(r2)","b1f22641":"test['Cat_preds'] = model.predict(test)","4a71f243":"# Modeling","1d04d1a4":"# *Linear Regression*","df05775e":"## I tried few more ensembling models like Xgboost, Lightgbm, catboost out of which Catboost gave me the best model, hence I have written the code for it","028c383f":"# Optuna for Catboost"}}