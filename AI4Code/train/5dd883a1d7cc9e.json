{"cell_type":{"a8ae17f1":"code","93bd5717":"code","b2da4033":"code","b5cb935c":"code","66209d32":"code","971c6a74":"code","4192d863":"code","100ff884":"code","ac41de2f":"code","e75dcb3c":"code","0da8dc03":"code","797a4076":"code","25d23e79":"code","e99712a9":"code","adfe4675":"code","7cb0107b":"code","da8eec50":"code","91882a2b":"code","4ecaeba9":"code","ef89c22f":"code","2143b1cd":"code","a43be97e":"code","9d93897c":"code","8867e72d":"code","f1ba4b91":"code","800f8efe":"code","a3ab5c40":"code","4dabe79d":"code","35237480":"code","84ff6f81":"code","825c3968":"code","4b5a7849":"code","887ae2a0":"code","8b2449ee":"code","414810bc":"code","a976cc98":"code","247e8542":"code","1da781df":"code","94ce225c":"code","3e1d3e56":"code","6785cec5":"code","86605c1c":"code","3a9ea2cb":"code","3e7b2989":"code","e2a20caa":"code","5672215a":"code","f6d78a06":"code","fe6174ef":"code","c246f6c6":"code","d7f7761d":"code","a63430d2":"code","44db57c5":"code","95feeef5":"code","8b28a71b":"code","bb3b2839":"code","76676b4b":"code","b1d08f7e":"code","2e958da0":"code","fe44ef23":"code","e00e52ee":"code","8efa7df2":"code","b66c2508":"code","5f0f7391":"code","cde5770f":"code","4acd95b9":"code","6d18afcd":"code","459ac2e2":"code","3d616a56":"code","cb43d004":"code","ebb2cc59":"markdown","fbb2a9e8":"markdown","22d2f2b7":"markdown","d3a5ddbd":"markdown","93681a32":"markdown","d883d79a":"markdown","0398baa1":"markdown","de0693b7":"markdown","ea84521b":"markdown","06e8a558":"markdown","c6f79e97":"markdown","1d6dc8a7":"markdown","f9c71684":"markdown","f2007e3e":"markdown","eea5f073":"markdown","5111dfd4":"markdown","1379afad":"markdown","a527a933":"markdown"},"source":{"a8ae17f1":"import numpy as np\nimport scipy as sp\nimport pandas as pd","93bd5717":"df = pd.read_csv('..\/input\/pre-eda-ta\/pre_eda_.csv', index_col=None)\ndf = df.drop('Unnamed: 0',axis=1)\ndf.head()","b2da4033":"print(list(df.columns))","b5cb935c":"df = df.drop(['policy_code','pymnt_plan'],axis=1)","66209d32":"df.shape","971c6a74":"#splitting categorical and continuous features\ncontinuous_features=[value for value in list(df._get_numeric_data().columns) if value not in [\"is_charged_off\",\"issue_d\"]]\ncategorical_features=[value for value in df.columns if value not in [*continuous_features,\"is_charged_off\",\"issue_d\"]]\ntarget_label=\"is_charged_off\"","4192d863":"df[(df.dti < 0)]","100ff884":"df = df[(df.dti >= 0)]","ac41de2f":"df['earliest_cr_line'] = df['earliest_cr_line'].astype('datetime64[ns]')","e75dcb3c":"df['ecl_year'] = pd.DatetimeIndex(df['earliest_cr_line']).year\ndf['ecl_month'] = pd.DatetimeIndex(df['earliest_cr_line']).month","0da8dc03":"df= df.drop('earliest_cr_line',axis=1)","797a4076":"df['issue_d'] = df['issue_d'].astype('datetime64[ns]')","25d23e79":"def outlier_treatment(datacolumn):\n    sorted(datacolumn)\n    Q1,Q3 = np.percentile(datacolumn , [25,75])\n    IQR = Q3 - Q1\n    lower_range = Q1 - (1.5 * IQR)\n    upper_range = Q3 + (1.5 * IQR)\n    return lower_range,upper_range","e99712a9":"def check_outlier(col):\n    l,u = outlier_treatment(df[col])\n    print(\"----\",col,\"----\")\n    print(\"Batas atas: \", u)\n    print(\"Batas bawah: \", l)\n    print(len(df[(df[col] < l) | (df[col] > u)]))\n    print()","adfe4675":"def remove_outlier(df,col):\n    l,u = outlier_treatment(df[col])\n    print(\"----\",col,\"----\")\n    print(\"Batas atas: \", u)\n    print(\"Batas bawah: \", l)\n    df_out = df[(df[col] >= l) & (df[col] <= u)]\n    return df_out","7cb0107b":"outlier_features = ['acc_open_past_24mths', 'annual_inc',  'mo_sin_old_il_acct', 'mths_since_recent_bc', 'num_il_tl', 'total_bal_ex_mort']","da8eec50":"for col in outlier_features:\n    check_outlier(col)\n    print(df[col].skew())","91882a2b":"df_out = df.copy()","4ecaeba9":"df_out = df.copy()\nfor col in outlier_features:\n    check_outlier(col)\n    df_out = remove_outlier(df_out,col)","ef89c22f":"df.shape","2143b1cd":"df_out.shape","a43be97e":"df = df_out.copy()","9d93897c":"df.shape","8867e72d":"df['emp_length'].describe","f1ba4b91":"df['is_newly_employed'] = np.where((df['emp_length'] == '< 1 year') | (df['emp_length'] == '2 years') | (df['emp_length'] == '3 years'),'Yes','No')","800f8efe":"jobs_in_risk = ['Agent','Bartender','Chef','Cook','Customer Service','Driver','driver','Flight Attendant','Instructor','Mechanic','mechanic','Pilot','Property Manager','Realtor','Receptionist','Sales','sales','Sales Representative','Server','server','Truck Driver','truck driver','Truck driver']","a3ab5c40":"df['is_industry_prone'] = np.where(df['emp_title'].isin(jobs_in_risk),'Yes','No')","4dabe79d":"df.columns","35237480":"df['salary'] = pd.cut(df.annual_inc,10,labels=[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\"])\ndf['dti_'] = pd.cut(df.dti,10,labels=[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\"])\ndf['int_rate_'] = pd.cut(df.int_rate,10,labels=[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\"])\ndf['fico'] = pd.cut(df.last_fico_range_high,10,labels=[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\"])\ndf['balance'] = pd.cut(df.avg_cur_bal,10,labels=[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\"])\ndf['installment_'] = pd.cut(df.installment,10,labels=[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\"])","84ff6f81":"#splitting categorical and continuous features\ncontinuous_features=[value for value in list(df._get_numeric_data().columns) if value not in [\"is_charged_off\",\"issue_d\"]]\ncategorical_features=[value for value in df.columns if value not in [*continuous_features,\"is_charged_off\",\"issue_d\"]]\ntarget_label=\"is_charged_off\"","825c3968":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf[categorical_features] = df[categorical_features].apply(lambda col: le.fit_transform(col))","4b5a7849":"def split_data(df):\n    print(df.columns)\n    #test train split time\n    from sklearn.model_selection import train_test_split\n    y = df[target_label].values #target\n    X = df.drop([target_label],axis=1).values #features\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n                                                    random_state=42, stratify=None, shuffle=False)\n\n    print(\"train-set size: \", len(y_train),\n      \"\\ntest-set size: \", len(y_test))\n    print(\"charged-off cases in test-set: \", sum(y_test)\/len(y_test)*100,\"%\")\n    return X_train, X_test, y_train, y_test","887ae2a0":"# def split_data(df):\n#     print(df.columns)\n#     #test train split time\n#     from sklearn.model_selection import train_test_split\n#     y = df[target_label].values #target\n#     X = df.drop([target_label],axis=1).values #features\n#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n#                                                     random_state=42, stratify=y)\n\n#     print(\"train-set size: \", len(y_train),\n#       \"\\ntest-set size: \", len(y_test))\n#     print(\"charged-off cases in test-set: \", sum(y_test)\/len(y_test)*100,\"%\")\n#     return X_train, X_test, y_train, y_test","8b2449ee":"# droplist = ['zip_code']\n# df = df.drop(droplist,axis=1)","414810bc":"df_cat = df.drop(continuous_features,axis=1)\ndf_cat.sort_values(by='issue_d')\ndf_cat = df_cat.drop(\"issue_d\",axis=1)\nX_c, X_test_c, y_c, y_test_c = split_data(df_cat)","a976cc98":"df_con = df.drop(categorical_features,axis=1)\ndf_con.sort_values(by='issue_d')\ndf_con = df_con.drop(\"issue_d\",axis=1)\nX_g, X_test_g, y_g, y_test_g = split_data(df_con)","247e8542":"df.sort_values(by='issue_d')\ndf = df.drop(\"issue_d\",axis=1)\nX, X_test, y, y_test = split_data(df)","1da781df":"del df_cat\ndel df_con","94ce225c":"import imblearn\nfrom collections import Counter\nfrom matplotlib import pyplot\nfrom numpy import where\nfrom imblearn.over_sampling import SMOTE","3e1d3e56":"oversample = SMOTE()","6785cec5":"counter = Counter(y)\nprint('before: ',counter)\nX_train, y_train = oversample.fit_resample(X, y)\n# summarize the new class distribution\ncounter = Counter(y_train)\nprint('after: ',counter)","86605c1c":"counter = Counter(y_c)\nprint('before y categorical: ',counter)\nX_train_c, y_train_c = oversample.fit_resample(X_c, y_c)\n# summarize the new class distribution\ncounter = Counter(y_train_c)\nprint('after categorical: ',counter)","3a9ea2cb":"counter = Counter(y_g)\nprint('before y Gaussian: ',counter)\nX_train_g, y_train_g = oversample.fit_resample(X_g, y_g)\n# summarize the new class distribution\ncounter = Counter(y_train_g)\nprint('after Gaussian: ',counter)","3e7b2989":"pip install mixed-naive-bayes","e2a20caa":"from mixed_naive_bayes import MixedNB\nfrom sklearn import metrics\nimport scikitplot as skplt\nfrom sklearn.metrics import confusion_matrix,auc,roc_auc_score\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.naive_bayes import GaussianNB, CategoricalNB \nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nimport time","5672215a":"def get_predictions(clf, X_train, y_train, X_test, y_test):\n    # create classifier\n    clf = clf\n    # fit it to training data\n    start = time.time()\n    clf.fit(X_train,y_train)\n    stop = time.time()\n    print(f\"Training time: {stop - start} s\")\n    train_time = stop - start\n    # predict using test data\n    start = time.time()\n    y_pred = clf.predict(X_test)\n    # Compute predicted probabilities: y_pred_prob\n    y_pred_prob = clf.predict_proba(X_test)\n    stop = time.time()\n    print(f\"Prediction time: {stop - start} s\")\n    pred_time = stop - start\n    #for fun: train-set predictions\n    train_pred = clf.predict(X_train)\n    print('train-set confusion matrix:\\n', confusion_matrix(y_train,train_pred)) \n    metrics.plot_roc_curve(clf, X_test, y_test)\n    return y_pred, y_pred_prob, pred_time, train_time","f6d78a06":"def print_scores(y_test,y_pred,y_pred_prob,pred_time,train_time):\n    cm1= confusion_matrix(y_test,y_pred)\n    print('test-set confusion matrix:\\n', confusion_matrix(y_test,y_pred)) \n    print(\"accuracy score: \", accuracy_score(y_test,y_pred))\n    print(\"precision score: \", precision_score(y_test,y_pred))\n    \n    print(\"recall score: \", recall_score(y_test,y_pred))\n    print(\"specificity score: \", cm1[0,0]\/(cm1[0,0]+cm1[0,1]))\n    print(\"ROC AUC: {}\".format(roc_auc_score(y_test, y_pred_prob[:,1])))\n    print(\"f1 score: \", f1_score(y_test,y_pred))\n    print (\"-------------------\")\n    print_metrics(y_test,y_pred,y_pred_prob,pred_time,train_time)\n    print (\"-------------------\")\n    print_cm(cm1)","fe6174ef":"def apply_model(clf, X_train, y_train, X_test, y_test):\n    start = time.time()\n    y_pred, y_pred_prob, pred_time, train_time = get_predictions(clf, X_train, y_train, X_test, y_test)\n    stop = time.time()\n    print_scores(y_test,y_pred,y_pred_prob,pred_time,train_time)","c246f6c6":"def predict(clf,X_test, y_test):\n    #predict using test data\n    start = time.time()\n    y_pred = clf.predict(X_test)\n    # Compute predicted probabilities: y_pred_prob\n    y_pred_prob = clf.predict_proba(X_test)\n    stop = time.time()\n    print(f\"Prediction time: {stop - start} s\")\n    metrics.plot_roc_curve(clf, X_test, y_test)\n    skplt.metrics.plot_cumulative_gain(y_test, y_pred_prob)\n    plt.show()\n    pred_time= stop - start\n    return y_pred, y_pred_prob, pred_time","d7f7761d":"def test_model(clf, X_test, y_test):\n    start = time.time()\n    y_pred, y_pred_prob, pred_time = predict(clf, X_test, y_test)\n    stop = time.time()\n    train_time = 999999\n    print_scores(y_test,y_pred,y_pred_prob,pred_time, train_time)","a63430d2":"scoring = ['accuracy','precision','recall','roc_auc','f1']","44db57c5":"def print_metrics(y_test,y_pred,y_pred_prob,pred_time,train_time):\n    cm1= confusion_matrix(y_test,y_pred)\n    text = \"\"\"\\hline\n\\\\textbf{{Accuracy}}  & : {0:.3f} & \\\\textbf{{Specificity}} & : {1:.3f} \\\\\\\\ \\hline\n\\\\textbf{{Precision}} & : {2:.3f} & \\\\textbf{{ROC\/AUC}}     & : {3:.3f} \\\\\\\\ \\hline\n\\\\textbf{{Recall}}    & : {4:.3f} & \\\\textbf{{F1 Score}}    & : {5:.3f} \\\\\\\\ \\hline\n\\\\textbf{{Training Time}} & \\multicolumn{{1}}{{r|}}{{: {6:.3f} s}} & \\\\textbf{{Prediction Time}} & \\multicolumn{{1}}{{r|}} {{: {7:.3f} s}} \\\\\\\\ \\hline\n\\end{{tabular}}\n\\end{{table}}\"\"\".format(accuracy_score(y_test,y_pred),cm1[0,0]\/(cm1[0,0]+cm1[0,1]),precision_score(y_test,y_pred),roc_auc_score(y_test, y_pred_prob[:,1]),recall_score(y_test,y_pred),f1_score(y_test,y_pred),train_time,pred_time)\n    print(text)","95feeef5":"def print_cm(cm1):\n    text = \"\"\"\\\\hline\n\\\\multicolumn{{2}}{{|l|}}{{\\\\cellcolor[HTML]{{EFEFEF}}}}                   & \\\\multicolumn{{2}}{{c|}}{{\\\\cellcolor[HTML]{{EFEFEF}}\\\\textbf{{Prediction}}}} \\\\\\\\ \\\\cline{{3-4}} \n\\\\multicolumn{{2}}{{|l|}}{{\\\\multirow{{-2}}{{*}}{{\\\\cellcolor[HTML]{{EFEFEF}}}}}} & \\\\textbf{{Fully Paid (0)}}        & \\\\textbf{{Charged-off (1)}}        \\\\\\\\ \\\\hline\n\\\\multicolumn{{1}}{{|c|}}{{\\\\cellcolor[HTML]{{EFEFEF}}}} &\n  \\\\textbf{{Fully Paid (0)}} &\n  \\\\cellcolor[HTML]{{FFFFFF}}\\\\textbf{{{}}} &\n  \\\\cellcolor[HTML]{{FFFFFF}}\\\\textbf{{{}}} \\\\\\\\ \\\\cline{{2-4}} \n\\\\multicolumn{{1}}{{|c|}}{{\\\\multirow{{-2}}{{*}}{{\\\\cellcolor[HTML]{{EFEFEF}}\\\\textbf{{Actual}}}}}} &\n  \\\\textbf{{Charged-off (1)}} &\n  \\\\cellcolor[HTML]{{FFFFFF}}\\\\textbf{{{}}} &\n  \\\\cellcolor[HTML]{{FFFFFF}}\\\\textbf{{{}}} \\\\\\\\ \\\\hline\n\\\\end{{tabular}}\n\\\\end{{table}}\"\"\".format(cm1[0,0],cm1[0,1],cm1[1,0],cm1[1,1])\n    print(text)","8b28a71b":"apply_model(GaussianNB(), X_train_g, y_train_g, X_test_g, y_test_g)","bb3b2839":"grid_param_g = {\n    'priors': [(0.8,0.2),(0.7,0.3),(0.75,0.25),(0.725,0.275),(None)],\n    'var_smoothing': [1e-3,1e-4,1e-5,1e-6,1e-7]\n}","76676b4b":"classifier = GaussianNB()\ngd_sr_g = GridSearchCV(estimator=classifier,\n                     param_grid=grid_param_g,\n                     scoring=scoring,refit='roc_auc',\n                     cv=10,\n                     n_jobs=-1)","b1d08f7e":"gd_sr_g.fit(X_train_g, y_train_g)","2e958da0":"allscores=gd_sr_g.cv_results_\nscore = pd.DataFrame(allscores,columns=['param_priors','param_var_smoothing','mean_fit_time','mean_test_accuracy','mean_test_precision','mean_test_recall','mean_test_roc_auc','mean_test_f1'])\nscore","fe44ef23":"best_parameters = gd_sr_g.best_params_\nprint(best_parameters)","e00e52ee":"score.to_csv('gnb_res.csv')\nallscore=pd.DataFrame(allscores)\nallscore.to_csv('all_gnb_res.csv')","8efa7df2":"test_model(gd_sr_g,X_test_g,y_test_g)","b66c2508":"apply_model(CategoricalNB(), X_train_c, y_train_c, X_test_c, y_test_c)","5f0f7391":"grid_param_c = {\n    'alpha': [0.25,0.5,0.75,1]\n    ,'fit_prior': [True,False]\n    ,'class_prior': [(0.8,0.2),(0.7,0.3),(0.75,0.25),(0.725,0.275),(None)]\n}","cde5770f":"classifier = CategoricalNB()\ngd_sr = GridSearchCV(estimator=classifier,\n                     param_grid=grid_param_c,\n                     scoring=scoring,refit='roc_auc',\n                     cv=10,\n                     n_jobs=-1)","4acd95b9":"gd_sr.fit(X_train_c, y_train_c)","6d18afcd":"allscores=gd_sr.cv_results_\nscore = pd.DataFrame(allscores,columns=['param_alpha','param_class_prior','param_fit_prior','mean_fit_time','mean_test_accuracy','mean_test_precision','mean_test_recall','mean_test_roc_auc','mean_test_f1'])\nscore","459ac2e2":"best_parameters = gd_sr.best_params_\nprint(best_parameters)","3d616a56":"score.to_csv('cnb_res.csv')\nallscore=pd.DataFrame(allscores)\nallscore.to_csv('all_cnb_res.csv')","cb43d004":"test_model(gd_sr,X_test_c,y_test_c)\n\n# # %% [markdown]\n# # # Mixed\n\n# # %% [code]\n# df=df.drop('is_charged_off',axis=1)\n\n# # %% [code]\n# def idx_cat(df):\n#     q = []\n#     n = []\n#     for col in categorical_features:\n#         print(col,' ',df.columns.get_loc(col),' ',df[col].nunique())\n#         q.append(df.columns.get_loc(col)) \n#         n.append(df[col].nunique()) \n#     return q,n\n\n# # %% [code]\n# idx, nmax = idx_cat(df)\n\n# # %% [code]\n# classifier = MixedNB(categorical_features=idx,max_categories=nmax)\n\n# # %% [code]\n# apply_model(MixedNB(categorical_features=idx,max_categories=nmax), X_train, y_train, X_test, y_test)\n\n# # %% [markdown]\n# # ## Pencarian Parameter Terbaik: Grid Search\n\n# # %% [code]\n# grid_param_m = {\n#     'categorical_features': idx, \n#     'max_categories': nmax, \n#     'alpha': [0.25,0.5,0.75,None],\n#     'priors': [0.7,0.3],\n#     'var_smoothing': [1e-9,2e-9]\n# }\n\n# # %% [code]\n# classifier = MixedNB()\n# gd_sr = GridSearchCV(estimator=classifier,\n#                      param_grid=grid_param_m,\n#                      scoring=scoring,refit='accuracy',\n#                      cv=5,\n#                      n_jobs=-1)\n\n# # %% [code]\n# gd_sr.fit(X_train, y_train)","ebb2cc59":"## Feature Engineering\nfitur **is_poverty_prone** yaitu kategori tingkat ekonomi yang rawan untuk jatuh miskin pada saat krisis terjadi. Seseorang dianggap rawan miskin is_industry_prone, is_newly_employed","fbb2a9e8":"## Handling Imbalance Data","22d2f2b7":"Tanpa Tuning Parameter","d3a5ddbd":"# Initial Modelling","93681a32":"## GridSearch","d883d79a":"# Categorical","0398baa1":"## Penghapusan Fitur\ndrop policy_code,payment plan","de0693b7":"## Modifikasi Data Khusus","ea84521b":"## Outlier Handling\nacc_open_past_24mths, annual_inc, delinq_amnt, mo_sin_old_il_acct, mths_since_recent_bc, num_accts_ever_120_pd, num_il_tl, num_tl_90g_dpd_24m, total_bal_ex_mort,delinq_2yrs","06e8a558":"**dti**","c6f79e97":"# Gaussian","1d6dc8a7":"# Data Preprocessing","f9c71684":"## Encoding Categorical Data\nusing label encoding","f2007e3e":"# Modelling","eea5f073":"# Import Modules","5111dfd4":"## Pembagian Dataset Latih dan Uji\n80% latih, 20% uji","1379afad":"# Input Data","a527a933":"ecl"}}