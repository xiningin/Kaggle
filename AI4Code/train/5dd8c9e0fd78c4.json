{"cell_type":{"d0ab8ab7":"code","29a04ec8":"code","693d361f":"code","8c58cd17":"code","4c2a9f3c":"code","f8a1e360":"code","37653d46":"code","fc0003a7":"code","3b03c396":"code","53e41d9e":"code","5372d57f":"code","4b8f74fd":"code","c711e092":"code","7ebe437e":"code","e5417df8":"code","8b67a5d9":"code","8f1e095d":"code","5670ce92":"code","ea8690fc":"markdown","a9776390":"markdown","7934c573":"markdown","176c0d2c":"markdown","74e93e74":"markdown","0e23010d":"markdown","cae46935":"markdown","152f2f15":"markdown","259d7ad2":"markdown","fbde8bf3":"markdown"},"source":{"d0ab8ab7":"import pandas as pd\n\n# load the training dataset\ndata = pd.read_csv('..\/input\/microsoftchallenge2\/real_estate.csv')\ndata.head()","29a04ec8":"data.describe()","693d361f":"data.isnull().sum()","8c58cd17":"import matplotlib.pyplot as plt\n%matplotlib inline\ndata.boxplot(column='price_per_unit',vert=False)","4c2a9f3c":"# Remove Outlier\ndata = data[data['price_per_unit'] < 70]\ndata.boxplot(column='price_per_unit',vert=False)","f8a1e360":"X, y = data[data.columns[1:-1]].values, data[data.columns[-1]].values","37653d46":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\nprint ('Training Set: %d rows\\nTest Set: %d rows' % (X_train.shape[0], X_test.shape[0]))","fc0003a7":"### ORDINARY LEAST SQUARE ###\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression().fit(X_train, y_train)\nprint('intercept:', model.intercept_)\nprint('slope:', model.coef_)","3b03c396":"import numpy as np","53e41d9e":"predictions = model.predict(X_test)\nnp.set_printoptions(suppress=True)\nprint('Predicted labels: ', np.round(predictions)[:10])\nprint('Actual labels   : ', y_test[:10])","5372d57f":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Predictions vs Actual')\n\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","4b8f74fd":"from sklearn.metrics import mean_squared_error, r2_score\n\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\n\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\n\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)","c711e092":"### LASSO ###\nfrom sklearn.linear_model import Lasso\nmodel = Lasso().fit(X_train, y_train)\n\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Predictions vs Actuals')\n\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","7ebe437e":"### DECISSION TREE ###\n\nfrom sklearn.tree import DecisionTreeRegressor\nmodel = DecisionTreeRegressor().fit(X_train, y_train)\n\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Predictions vs Actuals')\n\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","e5417df8":"### RANDOM FOREST ###\n\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor().fit(X_train, y_train)\n\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Predictions vs Actuals')\n\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","8b67a5d9":"### GRADIENT BOOSTING ###\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nmodel = GradientBoostingRegressor().fit(X_train, y_train)\n\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Predictions vs Actuals')\n\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","8f1e095d":"### GRADIENT BOOSTING (WITH GRID SEARCH APPROACH) ###\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer, r2_score\n\nalg = GradientBoostingRegressor()\n\nparams = {\n 'learning_rate': [0.1, 0.5, 1.0],\n 'n_estimators' : [50, 100, 150]\n}\n\nscore = make_scorer(r2_score)\ngridsearch = GridSearchCV(alg, params, scoring=score, cv=3, return_train_score=True)\ngridsearch.fit(X_train, y_train)\nprint(\"Best parameter combination:\", gridsearch.best_params_, \"\\n\")\n\nmodel = gridsearch.best_estimator_\n\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Predictions vs Actuals')\n\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","5670ce92":"X_new = np.array([[16.2,289.3248,5,24.98203,121.54348],\n                  [13.6,4082.015,0,24.94155,121.5038]])\npredict = model.predict(X_new)\nprint('Predictions:')\nfor prediction in predict:\n    print(round(prediction,2))","ea8690fc":"### Evaluate the Trained Model","a9776390":"Setelah mencoba beberapa model, diperoleh model dengan **Gradient Boosting (with Grid Search Approach)** memiliki nilai RMSE paling kecil, yakni 5.98, dan R2 paling besar, yakni 69%. Sehingga model tersebut akan digunakan untuk memprediksi data baru.","7934c573":"### Predict New Data","176c0d2c":"### Train a Regression Model","74e93e74":"The data consists of the following variables:\n\n- **transaction_date** - the transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.)\n- **house_age** - the house age (in years)\n- **transit_distance** - the distance to the nearest light rail station (in meters)\n- **local_convenience_stores** - the number of convenience stores within walking distance\n- **latitude** - the geographic coordinate, latitude\n- **longitude** - the geographic coordinate, longitude\n- **price_per_unit** house price of unit area (3.3 square meters)\n\n## Train a Regression Model\n\nYour challenge is to explore and prepare the data, identify predictive features that will help predict the **price_per_unit** label, and train a regression model that achieves the lowest Root Mean Square Error (RMSE) you can achieve (which must be less than **7**) when evaluated against a test subset of data.\n\nAdd markdown and code cells as required to create your solution.","0e23010d":"### Data Exploration","cae46935":"# Regression Challenge\n\nBy: Muhammad Alwy Shihab (Fresh Graduate of Statistics, Unpad)\n\nPredicting the selling price of a residential property depends on a number of factors, including the property age, availability of local amenities, and location.\n\nIn this challenge, you will use a dataset of real estate sales transactions to predict the price-per-unit of a property based on its features. The price-per-unit in this data is based on a unit measurement of 3.3 square meters.\n\n> **Citation**: The data used in this exercise originates from the following study:\n>\n> *Yeh, I. C., & Hsu, T. K. (2018). Building real estate valuation models with comparative approach through case-based reasoning. Applied Soft Computing, 65, 260-271.*\n>\n> It was obtained from the UCI dataset repository (Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository]([http:\/\/archive.ics.uci.edu\/ml). Irvine, CA: University of California, School of Information and Computer Science).\n\n## Review the data\n\nRun the following cell to load the data and view the first few rows.","152f2f15":"## ANSWER","259d7ad2":"## Use the Trained Model\n\nSave your trained model, and then use it to predict the price-per-unit for the following real estate transactions:\n\n| transaction_date | house_age | transit_distance | local_convenience_stores | latitude | longitude |\n| ---------------- | --------- | ---------------- | ------------------------ | -------- | --------- |\n|2013.167|16.2|289.3248|5|24.98203|121.54348|\n|2013.000|13.6|4082.015|0|24.94155|121.50381|","fbde8bf3":"### Try Another Model"}}