{"cell_type":{"9c64b43a":"code","b96c642b":"code","8c4c3b3f":"code","5f8cf452":"code","3514337a":"code","dfcdbef6":"code","0f6db036":"code","ca8cdb26":"code","a9030e8f":"code","927b680b":"code","dc539b7f":"code","6fb8a4ad":"code","6611a44c":"code","74fd2471":"code","b1734d74":"code","5b840255":"markdown"},"source":{"9c64b43a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b96c642b":"# Get the data\ndata = pd.read_csv('\/kaggle\/input\/salary\/Salary.csv')\ndata.head()","8c4c3b3f":"# Discover and visualize the data to gain insights.\ndata.info()\n\n# Insights\n# 1. No null values\n# 2. Years of experience is float but salary is integer","5f8cf452":"# Discover and visualize the data to gain insights.\nplt.plot(data['YearsExperience'],data['Salary'],'.')\nplt.show()\n\n# Insights:\n#  1. I\/p and O\/p has linear model, linear regression can be good and simple option","3514337a":"# Discover and visualize the data to gain insights.\nplt.hist(data['YearsExperience'],bins=4)\nplt.show()\n\n#Insights:\n# 1. We have high number of data points for YearsExperience in range 1 to 4 yrs\n# 2. To create test dataset, random sampling should be avoided as it can create sample bias\n# 3. We will use stratified sampling, which tries to keep same distribution profile as actual data. ","dfcdbef6":"# Prepare the data for Machine Learning algorithms.\n\n# Splitting data into train and test data (using stratified sampling)\ndata[\"YearsExp_dist\"] = pd.cut(data[\"YearsExperience\"],bins=[0.0, 2.5, 4.0, 7.5, 11.0, np.inf],labels=[1, 2, 3, 4,5])\ndata[\"YearsExp_dist\"].hist()\n# We will use below distribution for stratified sampling","0f6db036":"# Using scikit for stratified sampling\nfrom sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) # split into 80%-20% ratio\nfor train_index, test_index in split.split(data, data[\"YearsExp_dist\"]):\n    train_set = data.loc[train_index]\n    test_set = data.loc[test_index]\ntype(train_set)\nplt.plot(train_set['YearsExperience'],train_set['Salary'],'g*',test_set['YearsExperience'],test_set['Salary'],'r*')\nplt.xlabel(\"YearsExperience\")\nplt.ylabel(\"Salary\")\nplt.legend(['train_set','test_set'])\n","ca8cdb26":"#Only for curiosity, lets also try random sampling for splitting train and test data \nfrom sklearn.model_selection import train_test_split\nrandom_sampling_train_set, random_sampling_test_set = train_test_split(data, test_size=0.2,random_state=14)\nplt.plot(random_sampling_train_set['YearsExperience'],random_sampling_train_set['Salary'],'g*',random_sampling_test_set['YearsExperience'],random_sampling_test_set['Salary'],'r*')\nplt.xlabel(\"YearsExperience\")\nplt.ylabel(\"Salary\")\nplt.legend(['train_set','test_set'])\n# If we compare o\/p of stratified sampling to random sampling's o\/p, the stratified sampling gives well distributed test set. \n# Though due to linear relationship this may not be problem, but in case of non-linear data this can create problem","a9030e8f":"X_train = train_set.drop(['YearsExp_dist','Salary'],axis=1)\ny_train = train_set.drop(['YearsExperience','YearsExp_dist'],axis=1)\nX_test  = test_set.drop(['YearsExp_dist','Salary'],axis=1)\ny_test = test_set.drop(['YearsExperience','YearsExp_dist'],axis=1)\n#X_train.head()\n#y_train.head()","927b680b":"# Training our model using Linear regression\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\nlin_reg.predict(X_test)","dc539b7f":"# Model\n# Intecept and coeff of the line\nprint('Intercept of the model:',lin_reg.intercept_)\nprint('Coefficient of the line:',lin_reg.coef_) ","6fb8a4ad":"# Checking performance over Training dataset\nfrom sklearn.metrics import mean_squared_error\ny_train_predictions = lin_reg.predict(X_train)\nlin_mse = mean_squared_error(y_train, y_train_predictions)\nlin_rmse_train = np.sqrt(lin_mse)\nlin_rmse_train","6611a44c":"# Performance plot\nplt.plot(X_train,y_train,'r*',X_train,y_train_predictions,'g*')","74fd2471":"# Checking performance over Test dataset\nfrom sklearn.metrics import mean_squared_error\ny_predictions = lin_reg.predict(X_test)\nlin_mse = mean_squared_error(y_test, y_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","b1734d74":"# Performance plot\nplt.plot(X_test,y_test,'r*',X_test,y_predictions,'g*')","5b840255":"Steps we will follow:\n1. Get the data.\n3. Discover and visualize the data to gain insights.\n4. Prepare the data for Machine Learning algorithms.\n5. Select a model and train it.\n6. Fine-tune your model.\n7. Present your solution.\n8. Launch, monitor, and maintain your system."}}