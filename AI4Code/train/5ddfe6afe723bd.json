{"cell_type":{"a87319d1":"code","c681ad45":"code","5f2c5f81":"code","5832cf4f":"code","b2357a66":"code","6b736af5":"code","cece28e4":"code","92c1e085":"code","9306d937":"markdown"},"source":{"a87319d1":"!apt-get install zip\nimport pandas as pd\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torchvision.models as models\n\nfrom os import listdir\nfrom os.path import isfile, join\n\nfrom PIL import Image","c681ad45":"TRAIN_CSV = '..\/input\/humpback-whale-identification\/train.csv'\nTRAIN = '..\/input\/humpback-whale-identification\/train'\nTEST = '..\/input\/humpback-whale-identification\/test'\nBBOX = '..\/input\/generating-whale-bounding-boxes-ba9082\/bounding_boxes.csv'\n\nTRAIN_CROPPED = 'output\/humpback-whale-identification-cropped\/train'\nTEST_CROPPED  = 'output\/humpback-whale-identification-cropped\/test'","5f2c5f81":"train_csv = pd.read_csv(TRAIN_CSV)\nprint(train_csv[:10])","5832cf4f":"bbox = pd.read_csv(BBOX)\nprint(bbox[:10])","b2357a66":"!mkdir -p 'output\/humpback-whale-identification-cropped\/train'\n\ntrain_total = train_csv.shape[0]\ntrain_count = 0\n\nprint_every = 50\n\nfor row in train_csv.iterrows():\n    train_count += 1\n    res = row[1]['Image']\n    path = os.path.join(TRAIN, res)\n    dst = os.path.join(TRAIN_CROPPED, res)\n    img = Image.open(path).convert('RGB')\n    bbox_row = bbox[bbox['Image'] == res].iloc[0]\n    x0, y0, x1, y1 = bbox_row['x0'], bbox_row['y0'], bbox_row['x1'], bbox_row['y1']\n    img = img.crop((x0, y0, x1, y1))\n    img.save(dst, 'jpeg')\n    \n    if train_count % print_every == 0:\n        print(\"Cropping Training Set -> {:3.2f}%\".format((train_count\/train_total) * 100), end=\"\\r\")\n\nprint(\"Cropping Training Set -> 100%\", end=\"\\r\")","6b736af5":"!zip -rm train_cropped.zip output\/humpback-whale-identification-cropped\/train","cece28e4":"!mkdir -p 'output\/humpback-whale-identification-cropped\/test'\n\ntest_count = 0\n\nprint_every = 50\n\nfiles = [f for f in listdir(TEST) if isfile(join(TEST, f))]\ntest_total = len(files)\n\nfor res in files:\n    test_count += 1\n    path = os.path.join(TEST, res)\n    dst = os.path.join(TEST_CROPPED, res)\n    img = Image.open(path).convert('RGB')\n    bbox_row = bbox[bbox['Image'] == res].iloc[0]\n    x0, y0, x1, y1 = bbox_row['x0'], bbox_row['y0'], bbox_row['x1'], bbox_row['y1']\n    img = img.crop((x0, y0, x1, y1))\n    img.save(dst, 'jpeg')\n    \n    if test_count % print_every == 0:\n        print(\"Cropping Testing Set -> {:3.2f}%\".format((test_count\/test_total) * 100), end=\"\\r\")\n\nprint(\"Cropping Testing Set -> 100%\", end=\"\\r\")","92c1e085":"!zip -rm test_cropped.zip output\/humpback-whale-identification-cropped\/test","9306d937":"Reference\n\n* Awesome Kernel, thanks @martinpiotte :\u00a0https:\/\/www.kaggle.com\/martinpiotte\/bounding-box-model\n* cropping.model:\u00a0https:\/\/www.kaggle.com\/martinpiotte\/bounding-box-model\/output\n* Data:\u00a0https:\/\/www.kaggle.com\/c\/humpback-whale-identification\/data\n* Bounding Boxes generation: https:\/\/www.kaggle.com\/suicaokhoailang\/generating-whale-bounding-boxes"}}