{"cell_type":{"755dda8e":"code","f97de370":"code","89744f9c":"code","e981c78f":"code","efb707f6":"code","87390420":"code","e1fdfeeb":"code","072d74ad":"code","128f7175":"code","0159db2c":"code","13eb09b4":"code","05e6ca06":"code","006e5062":"code","280d3ccd":"code","57502bda":"code","898bf963":"code","c9c8075b":"code","f5b3418f":"code","ccec3297":"code","22839e62":"code","03235bef":"code","8acc3c8c":"code","5b8957b1":"code","00d88929":"code","a677eba0":"code","36ae3d17":"code","4b3526a2":"code","f099d765":"code","81f0b79a":"code","8a9a95df":"code","76b31b4f":"code","cb1d6632":"code","baf49b38":"code","940e60ce":"code","12cf2f96":"code","deaeb223":"code","7092f8cc":"code","d1608289":"code","8a0d2235":"code","425b4a2b":"code","6af2f23c":"code","07fd4c0e":"code","dd43262c":"code","87100469":"code","06ff782b":"code","b2fe61fa":"code","3259e5d7":"code","2e71c44f":"code","1d0edce2":"code","3dd30e07":"code","6dc9bd09":"markdown","edac986e":"markdown","89146d0d":"markdown","1fcbb553":"markdown","33e26bfd":"markdown","154190ef":"markdown"},"source":{"755dda8e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk(\"\/kaggle\/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f97de370":"trainData = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrainData","89744f9c":"trainData.info()","e981c78f":"trainData.isnull().sum()","efb707f6":"testData = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntestData","87390420":"testData.info()","e1fdfeeb":"testData.isnull().sum()","072d74ad":"genderSubmissionData = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")\ngenderSubmissionData","128f7175":"survivedSample = trainData[\"Survived\"] == 1\nsurvivedData = trainData[survivedSample]\nsurvivedData","0159db2c":"deadSample = trainData[\"Survived\"] == 0\ndeadData = trainData[deadSample]\ndeadData","13eb09b4":"trainData[\"Survived\"].value_counts().plot.pie(autopct=\"%1.1f%%\")","05e6ca06":"sns.heatmap(data=trainData.corr(), annot=True, cmap=\"YlGnBu\")","006e5062":"sns.countplot(data=trainData, x=\"Sex\", hue=\"Survived\")","280d3ccd":"sns.countplot(data=trainData, y=\"Pclass\", hue=\"Survived\")","57502bda":"sns.factorplot(data=trainData, x=\"Pclass\", y=\"Survived\", hue=\"Sex\")","898bf963":"f,ax=plt.subplots(1,2, figsize=(10,5))\nsns.distplot(a=survivedData[\"Age\"], color=\"green\", ax=ax[0])\nsns.distplot(a=deadData[\"Age\"], color=\"red\", ax=ax[1])","c9c8075b":"sns.violinplot(data=trainData, x=\"Sex\", y=\"Age\", hue=\"Survived\", split=True)","f5b3418f":"sns.violinplot(data=trainData, x=\"Pclass\", y=\"Age\", hue=\"Survived\", split=True)","ccec3297":"sns.countplot(data=trainData, y=\"Embarked\", hue=\"Survived\")","22839e62":"sns.countplot(data=trainData, x=\"SibSp\", hue=\"Survived\")","03235bef":"sns.countplot(data=trainData, x=\"Parch\", hue=\"Survived\")","8acc3c8c":"f,ax=plt.subplots(1,2, figsize=(10,5))\nsns.distplot(a=survivedData[\"Fare\"], color=\"green\", ax=ax[0])\nsns.distplot(a=deadData[\"Fare\"], color=\"red\", ax=ax[1])","5b8957b1":"sns.relplot(data=trainData, x=\"Ticket\", y=\"Fare\", hue=\"Survived\")","00d88929":"def fillEmbarked(tmpData):\n    tmpData[\"Embarked\"] = tmpData[\"Embarked\"].fillna(\"S\")\n\nfillEmbarked(trainData)\ntrainData","a677eba0":"def makeTitleName(inputData):\n    inputData = [inputData]\n\n    for dataset in inputData:\n        dataset[\"Title\"] = dataset[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n\n    for dataset in inputData:\n        dataset[\"Title\"] = dataset[\"Title\"].replace([\"Lady\", \"Countess\",\"Capt\", \"Col\", \"Don\", \"Dr\", \"Major\",\n                                                     \"Rev\", \"Sir\", \"Jonkheer\", \"Dona\"], \"Etc\")\n\n        dataset[\"Title\"] = dataset[\"Title\"].replace(\"Mlle\", \"Miss\")\n        dataset[\"Title\"] = dataset[\"Title\"].replace(\"Ms\", \"Miss\")\n        dataset[\"Title\"] = dataset[\"Title\"].replace(\"Mme\", \"Mrs\")\n\nmakeTitleName(trainData)     \npd.crosstab(trainData[\"Title\"], trainData[\"Sex\"])","36ae3d17":"trainData.groupby(\"Title\")[\"Age\"].mean()","4b3526a2":"def fillAge(age, title):\n    if age > 0:\n        return age\n    else:\n        if title == \"Master\":\n            return 5\n        elif title == \"Miss\":\n            return 22\n        elif title == \"Mr\":\n            return 33\n        elif title == \"Mrs\":\n            return 36\n        else:\n            return 46\n    \n\ntrainData[\"Age\"] = trainData.apply(lambda x: fillAge(x[\"Age\"], x[\"Title\"]), axis = 1)\ntrainData","f099d765":"def makeAgeBand(tmpData):\n    tmpData[\"AgeBand\"]=pd.cut(x=tmpData[\"Age\"], bins=5, labels=[0, 1, 2, 3, 4])\n\ntrainData = trainData.astype({\"Age\": \"int\"})\n\nmakeAgeBand(trainData)\ntrainData","81f0b79a":"def makeFareBand(tmpData):\n    tmpData[\"FareBand\"]=pd.qcut(x=tmpData[\"Fare\"], q=4, labels=[0, 1, 2, 3])\n\nmakeFareBand(trainData)\ntrainData","8a9a95df":"trainData[\"FamilySize\"] = trainData.apply(lambda x: x[\"SibSp\"] + x[\"Parch\"] + 1, axis = 1)\ntrainData","76b31b4f":"trainData[\"IsAlone\"] = trainData.apply(lambda x: 1 if x[\"FamilySize\"] == 1 else 0, axis = 1)\ntrainData","cb1d6632":"trainData.groupby(\"Pclass\")[\"Fare\"].mean()","baf49b38":"testData.groupby(\"Pclass\")[\"Fare\"].mean()","940e60ce":"# def fillFare(tmpData):\n#     tmpData.loc[(tmpData[\"Fare\"].isnull())&(tmpData[\"Pclass\"]==1),\"Age\"] = 84.1\n#     tmpData.loc[(tmpData[\"Fare\"].isnull())&(tmpData[\"Pclass\"]==2),\"Age\"] = 20.6\n#     tmpData.loc[(tmpData[\"Fare\"].isnull())&(tmpData[\"Pclass\"]==3),\"Age\"] = 13.6\n\ndef fillFare(fare, pclass):\n    if fare > 0:\n        return fare\n    else:\n        if pclass == 1:\n            return 84.0\n        elif pclass == 2:\n            return 20.0\n        else:\n            return 13.0\n    \n\ntestData[\"Fare\"] = testData.apply(lambda x: fillFare(x[\"Fare\"], x[\"Pclass\"]), axis = 1)\nmakeTitleName(testData)\ntestData[\"Age\"] = testData.apply(lambda x: fillAge(x[\"Age\"], x[\"Title\"]), axis = 1)\nmakeAgeBand(testData)\nmakeFareBand(testData)\ntestData[\"FamilySize\"] = testData.apply(lambda x: x[\"SibSp\"] + x[\"Parch\"] + 1, axis = 1)\ntestData[\"IsAlone\"] = testData.apply(lambda x: 1 if x[\"FamilySize\"] == 1 else 0, axis = 1)\ntestData","12cf2f96":"sns.countplot(data=trainData, x=\"Title\", hue=\"Survived\")","deaeb223":"sns.factorplot(data=trainData, x=\"AgeBand\", y=\"Survived\")","7092f8cc":"sns.factorplot(data=trainData, x=\"FareBand\", y=\"Survived\")","d1608289":"sns.countplot(data=trainData, x=\"FamilySize\", hue=\"Survived\")","8a0d2235":"sns.countplot(data=trainData, x=\"IsAlone\", hue=\"Survived\")","425b4a2b":"# tmp = trainData\n# tmp.drop(['Name','Age','Ticket','Fare','Cabin','PassengerId'],axis=1,inplace=True)\nsns.heatmap(data=trainData.corr(), annot=True, cmap=\"YlGnBu\")","6af2f23c":"# PassengerId Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked Title AgeBand FareBand FamilySize IsAlone\n\ny = trainData[\"Survived\"]\n# features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\", \"Title\", \"AgeBand\", \"FareBand\", \"FamilySize\", \"IsAlone\"]\nX = pd.get_dummies(trainData[features])\nX_test = pd.get_dummies(testData[features])\nX\n\n# imputed_X = pd.DataFrame(SimpleImputer().fit_transform(X))\n# imputed_X_test = pd.DataFrame(SimpleImputer().fit_transform(X_test))\n# imputed_X.columns = X.columns\n# imputed_X_test.columns = X_test.columns\n# imputed_X","07fd4c0e":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.linear_model import LinearRegression\n\nLinearRegression_model = LinearRegression()\nLinearRegression_model.fit(X, y)\nLinearRegression_predict = LinearRegression_model.predict(X_test)\n# LinearRegression_output = pd.DataFrame({\"fullParking\": LinearRegression_predict})\nLinearRegression_mae = mean_absolute_error(LinearRegression_predict, genderSubmissionData[\"Survived\"])\n\nprint(\"Validation MAE for Linear Regression Model: {}\".format(LinearRegression_mae))","dd43262c":"from sklearn.tree import DecisionTreeRegressor\n\nDecisionTreeRegressor_model = DecisionTreeRegressor(random_state=0)\nDecisionTreeRegressor_model.fit(X, y)\nDecisionTreeRegressor_predict = DecisionTreeRegressor_model.predict(X_test)\nDecisionTreeRegressor_mae = mean_absolute_error(DecisionTreeRegressor_predict, genderSubmissionData[\"Survived\"])\n\nprint(\"Validation MAE for Decision Tree Regressor Model: {}\".format(DecisionTreeRegressor_mae))","87100469":"from sklearn.ensemble import RandomForestRegressor\n\nRandomForestRegressor_model = RandomForestRegressor()\nRandomForestRegressor_model.fit(X, y)\nRandomForestRegressor_predict = RandomForestRegressor_model.predict(X_test)\nRandomForestRegressor_mae = mean_absolute_error(RandomForestRegressor_predict, genderSubmissionData[\"Survived\"])\n\nprint(\"Validation MAE for Random Forest Regressor Model: {}\".format(RandomForestRegressor_mae))","06ff782b":"from sklearn.ensemble import RandomForestClassifier\n\nRandomForestClassifier_model = RandomForestClassifier()\nRandomForestClassifier_model.fit(X, y)\nRandomForestClassifier_predict = RandomForestClassifier_model.predict(X_test)\nRandomForestClassifier_mae = mean_absolute_error(RandomForestClassifier_predict, genderSubmissionData[\"Survived\"])\n\nprint(\"Validation MAE for Random Forest Classifier Model: {}\".format(RandomForestClassifier_mae))","b2fe61fa":"from xgboost import XGBRegressor\n\nXGBRegressor_model = XGBRegressor()\nXGBRegressor_model.fit(X, y)\nXGBRegressor_predict = XGBRegressor_model.predict(X_test)\nXGBRegressor_mae = mean_absolute_error(XGBRegressor_predict, genderSubmissionData[\"Survived\"])\n\nprint(\"Validation MAE for XGB Regressor Model: {}\".format(XGBRegressor_mae))","3259e5d7":"from sklearn import svm\n\nSVC_model = svm.SVC()\nSVC_model.fit(X,y)\nSVC_predict = SVC_model.predict(X_test)\nSVC_mae = mean_absolute_error(SVC_predict, genderSubmissionData[\"Survived\"])\n\nprint(\"Validation MAE for Support Vector Classification Model: {}\".format(SVC_mae))","2e71c44f":"# from sklearn.model_selection import cross_val_score\n# from sklearn.pipeline import Pipeline\n# from sklearn.impute import SimpleImputer\n\n# def getN_estimatorsScore(n_estimators):\n#     RandomForestClassifier_pipeline = Pipeline(steps=[\n#         (\"preprocessor\", SimpleImputer()),\n#         (\"model\", RandomForestClassifier(n_estimators=n_estimators))\n#     ])\n\n#     scores = -1 * cross_val_score(RandomForestClassifier_pipeline, X, y,\n#                                   cv=5,\n#                                   scoring=\"neg_mean_absolute_error\")\n#     return scores.mean()\n\n# def getMaxDepthScore(max_depth):\n#     RandomForestClassifier_pipeline = Pipeline(steps=[\n#         (\"preprocessor\", SimpleImputer()),\n#         (\"model\", RandomForestClassifier(max_depth=max_depth))\n#     ])\n\n#     scores = -1 * cross_val_score(RandomForestClassifier_pipeline, X, y,\n#                                   cv=5,\n#                                   scoring=\"neg_mean_absolute_error\")\n#     return scores.mean()\n\n# def getRandomStateScore(random_state):\n#     RandomForestClassifier_pipeline = Pipeline(steps=[\n#         (\"preprocessor\", SimpleImputer()),\n#         (\"model\", RandomForestClassifier(random_state=random_state))\n#     ])\n\n#     scores = -1 * cross_val_score(RandomForestClassifier_pipeline, X, y,\n#                                   cv=5,\n#                                   scoring=\"neg_mean_absolute_error\")\n#     return scores.mean()\n\n\n# n_estimatorsResults = {}\n# for i in range(1,9):\n#     n_estimatorsResults[50*i] = getN_estimatorsScore(50*i)\n# n_estimators_best = min(n_estimatorsResults, key=n_estimatorsResults.get)\n\n# maxDepthResults = {}\n# for i in range(1,9):\n#     maxDepthResults[50*i] = getMaxDepthScore(50*i)\n# maxDepth_best = min(maxDepthResults, key=maxDepthResults.get)\n\n# randomStateResults = {}\n# for i in range(1,9):\n#     randomStateResults[50*i] = getRandomStateScore(50*i)\n# randomState_best = min(randomStateResults, key=randomStateResults.get)\n\n# RandomForestClassifier_pipeline = Pipeline(steps=[\n#     (\"preprocessor\", SimpleImputer()),\n#     (\"model\", RandomForestClassifier(n_estimators=n_estimators_best,\n#                                      max_depth=maxDepth_best,\n#                                      random_state=randomState_best))\n# ])\n# best_scores = -1 * cross_val_score(RandomForestClassifier_pipeline, X, y,\n#                               cv=5,\n#                               scoring=\"neg_mean_absolute_error\")\n\n# print(\"Best estimators:\", n_estimators_best)\n# print(\"Best max depth:\", maxDepth_best)\n# print(\"Best random state:\", randomState_best)\n# print(\"Average MAE score:\", best_scores.mean())","1d0edce2":"# my_model = RandomForestClassifier(n_estimators=n_estimators_best,\n#                                   max_depth=maxDepth_best,\n#                                   random_state=randomState_best)\nmy_model = svm.SVC()\nmy_model.fit(X, y)\nmy_predict = my_model.predict(X_test)\nmy_mae = mean_absolute_error(my_predict, genderSubmissionData[\"Survived\"])\n\nprint(\"Validation MAE for Random Forest Classifier Model: {}\".format(my_mae))","3dd30e07":"output = pd.DataFrame({\"PassengerId\": testData[\"PassengerId\"], \"Survived\": my_predict})\noutput.to_csv(\"my_submission.csv\", index=False)\nprint(\"Your submission was successfully saved!\")","6dc9bd09":"# Show data & missing data","edac986e":"### Fill NaN & Wrangle data\nFill `NaN` Data.\nWrangling data and view graphs for survived data using `Seaborn`.\n\nReference of wrangle data is [here](https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions).","89146d0d":"### Predict","1fcbb553":"### Make trainning data and Model","33e26bfd":"### Find Best Argument","154190ef":"### Data Visualization\nView graphs for survived data using `Seaborn`"}}