{"cell_type":{"cbf283d3":"code","d890123b":"code","9ca65c44":"code","0a8265b4":"code","8e3e6abf":"code","4b56c10d":"code","3a4fed1d":"code","77ff7e94":"code","1de3bc7f":"markdown","b63e871b":"markdown","5fa7596a":"markdown"},"source":{"cbf283d3":"#-------Import Dependencies-------#\n%matplotlib inline\nimport pandas as pd\nimport os,shutil,math,scipy,cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.metrics import confusion_matrix,roc_curve,auc\n\nfrom PIL import Image\nfrom PIL import Image as pil_image\nfrom time import time\nfrom PIL import ImageDraw\nfrom glob import glob\nfrom tqdm import tqdm\nfrom skimage.io import imread\nfrom IPython.display import SVG\n\nfrom scipy import misc,ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.ndimage import imread\n\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.preprocessing.image import save_img\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.applications.vgg19 import VGG19,preprocess_input\nfrom keras.applications.xception import Xception\nfrom keras.applications.nasnet import NASNetMobile\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\nfrom keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam,SGD\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler","d890123b":"def show_final_history(history):\n    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('acc')\n    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()","9ca65c44":"augs = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,  \n    zoom_range=0.2,        \n    horizontal_flip=True,\n    validation_split=0.3)  \n\ntrain_gen = augs.flow_from_directory(\n    '..\/input\/cell_images\/cell_images',\n    target_size = (50,50),\n    batch_size=16,\n    class_mode = 'categorical',\n    subset='training')\n\nval_gen = augs.flow_from_directory(\n    '..\/input\/cell_images\/cell_images',\n    target_size=(50,50),\n    batch_size=16,\n    class_mode='categorical',\n    subset='validation')","0a8265b4":"def ConvBlock(model, layers, filters,name):\n    for i in range(layers):\n        model.add(SeparableConv2D(filters, (3, 3), activation='relu',name=name))\n        model.add(BatchNormalization())\n        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n    \ndef FCN():\n    model = Sequential()\n    model.add(Lambda(lambda x: x, input_shape=(50, 50, 3)))\n    ConvBlock(model, 1, 64,'block_1')\n    ConvBlock(model, 1, 128,'block_2')\n    ConvBlock(model, 1, 256,'block_3')\n    ConvBlock(model, 1, 512,'block_4')\n    model.add(Flatten())\n    model.add(Dense(1024,activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(2,activation='sigmoid'))\n    return model\n\nmodel = FCN()\nmodel.summary()\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","8e3e6abf":"#-------Callbacks-------------#\nbest_model_weights = '.\/base.model'\ncheckpoint = ModelCheckpoint(\n    best_model_weights,\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    mode='min',\n    save_weights_only=False,\n    period=1\n)\nearlystop = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.001,\n    patience=10,\n    verbose=1,\n    mode='auto'\n)\ntensorboard = TensorBoard(\n    log_dir = '.\/logs',\n    histogram_freq=0,\n    batch_size=16,\n    write_graph=True,\n    write_grads=True,\n    write_images=False,\n)\n\ncsvlogger = CSVLogger(\n    filename= \"training_csv.log\",\n    separator = \",\",\n    append = False\n)\n\n#lrsched = LearningRateScheduler(step_decay,verbose=1)\n\nreduce = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=40,\n    verbose=1, \n    mode='auto',\n    cooldown=1 \n)\n\ncallbacks = [checkpoint,tensorboard,csvlogger,reduce]","4b56c10d":"opt = SGD(lr=1e-4,momentum=0.99)\nopt1 = Adam(lr=2e-4)\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=opt,\n    metrics=['accuracy']\n)\n    \nhistory = model.fit_generator(\n    train_gen, \n    steps_per_epoch  = 1000, \n    validation_data  = val_gen,\n    validation_steps = 1000,\n    epochs = 20, \n    verbose = 1,\n    callbacks=callbacks\n)","3a4fed1d":"show_final_history(history)\nmodel.load_weights(best_model_weights)\nmodel_score = model.evaluate_generator(val_gen,steps=50)\nprint(\"Model Test Loss:\",model_score[0])\nprint(\"Model Test Accuracy:\",model_score[1])\nmodel.save('malaria.h5')","77ff7e94":"!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = '.\/logs' # Here you have to put your log directory\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 8080 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('.\/ngrok http 8080 &')\n! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","1de3bc7f":"# Data Augmentation\n\n### Data Augmentation is perfect when you have little data. It also prevents the model from seeing the exact images multiple times","b63e871b":"# Import All Necessary Libraries ","5fa7596a":"# Custom Function To Display Training Results\n\n### I created this function that will make it very easy to visualize the training data"}}