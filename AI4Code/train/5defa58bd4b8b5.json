{"cell_type":{"1435e518":"code","da584f4c":"code","174e79d7":"code","f1d2f0f4":"code","0848b5e0":"code","d3b29e71":"code","09e7b482":"code","9258e50b":"code","b05b7b6c":"code","493d35b8":"code","db5718d3":"code","97663e9b":"code","f6709f4c":"code","a93d7b15":"code","b2280924":"code","b820ccbb":"code","294ff343":"code","066d9aab":"code","edf7c3a7":"code","3f4ddcfb":"code","92187dc4":"code","456df5a4":"code","2d9c1387":"code","0a2c8c6e":"code","dc053789":"code","224b20b4":"code","62541caa":"markdown","add66733":"markdown"},"source":{"1435e518":"import numpy as np\nimport pandas as pd\nimport gc\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Flatten,\\\n Conv2D, MaxPooling2D,BatchNormalization\nimport cv2","da584f4c":"data= pd.read_csv(\"..\/input\/skin-cancer-mnist-ham10000\/hmnist_28_28_RGB.csv\")","174e79d7":"y= data['label'].copy()\nX = data.drop('label', axis=1).copy()","f1d2f0f4":"label_mapping = {\n    0: 'nv',\n    1: 'mel',\n    2: 'bkl',\n    3: 'bcc',\n    4: 'akiec',\n    5: 'vasc',\n    6: 'df'\n}","0848b5e0":"X= X\/255\nX","d3b29e71":"X=np.array(X)\nX.shape","09e7b482":"X=X.reshape(-1,28,28,3)\nprint(X.shape)","9258e50b":"## Index Inputs to be augumented\n## 3 5 0 1\nfor i in range (10015):\n    if(y[i]== 3 or y[i]==1 or y[i]== 5 or y[i]== 0):\n        \n        ## horizontal flip\n        hFlip= np.fliplr(X[i])\n        X= np.append(X, np.array([hFlip]), axis= 0)\n        y= np.append(y,[y[i]])\n        \n        ## horizontal flip-> vertical flip\n        \n        hVFlip= np.flipud(X[-1])\n        X= np.append(X, np.array([hVFlip]), axis=0)\n        y= np.append(y, [y[i]])\n        \n        ## vertical flip\n        vFlip= np.flipud(X[i])\n        X= np.append(X, np.array([vFlip]), axis=0)\n        y= np.append(y,[y[i]])\n        \nprint(\"done\")","b05b7b6c":"X_train,X_test,y_train,y_test= train_test_split(X,y,train_size=0.83)\nprint(\"done\")","493d35b8":"def plot_sample(X,y,index):\n    plt.figure(figsize= (15,2))\n    plt.imshow(X_train[index])\n    plt.xlabel(label_mapping[y[index]])","db5718d3":"plot_sample(X_train,y_train,783)","97663e9b":"model = Sequential()\n\nmodel.add(Conv2D(filters= 32, input_shape= (28,28,3),activation='relu',kernel_size= (3,3)))\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Conv2D(filters= 64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Conv2D(filters= 128, kernel_size= (3,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\n\n###dense layers\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(7, activation='softmax'))\n\nprint(model.summary())","f6709f4c":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","a93d7b15":"model.fit(X_train,y_train, epochs = 20)","b2280924":"model_acc= model.evaluate(X_test, y_test)","b820ccbb":"y_true = np.array(y_test)\n\ny_pred = model.predict(X_test)\ny_pred = np.array(list(map(lambda x: np.argmax(x), y_pred)))","294ff343":"cm = confusion_matrix(y_true, y_pred)\nclr = classification_report(y_true, y_pred, target_names=label_mapping.values())","066d9aab":"plt.figure(figsize=(10, 10))\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cbar=False, cmap='Blues')\n\nplt.xticks(np.arange(7) + 0.5, label_mapping.values())\nplt.xlabel(\"Predicted\")\n\nplt.yticks(np.arange(7) + 0.5, label_mapping.values())\nplt.ylabel(\"Actual\")\n\nplt.title(\"Confusion Matrix\")\n\nplt.show()","edf7c3a7":"print(clr)","3f4ddcfb":"# modified alex net\n\nmodel_alex = Sequential()\n\n# 1st Convolutional Layer\nmodel_alex.add(Conv2D(filters=64, input_shape=(28,28,3), kernel_size=(3,3), activation='relu'))\n# model.add(Activation('relu'))\n# Pooling\nmodel_alex.add(MaxPooling2D(2,2))\n# Batch Normalisation before passing it to the next layer\nmodel_alex.add(BatchNormalization())\n\n# 2nd Convolutional Layer\nmodel_alex.add(Conv2D(filters=128, kernel_size=(3,3),activation='relu'))\n# model.add(Activation('relu'))\n# Pooling\nmodel_alex.add(MaxPooling2D(2,2))\n# Batch Normalisation\nmodel_alex.add(BatchNormalization())\n\n# 3rd Convolutional Layer\nmodel_alex.add(Conv2D(filters=256, kernel_size=(3,3),activation='relu'))\n# model.add(Activation('relu'))\n# Batch Normalisation\nmodel_alex.add(BatchNormalization())\n\n# 4th Convolutional Layer\n# model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n# model.add(Activation('relu'))\n# # Batch Normalisation\n# model.add(BatchNormalization())\n\n# 5th Convolutional Layer\n# model1.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1),activation='relu')))\n# # model.add(Activation('relu'))\n# # Pooling\n# model1.add(MaxPooling2D((2,2)))\n# # Batch Normalisation\n# model1.add(BatchNormalization())\n\n# Passing it to a dense layer\nmodel_alex.add(Flatten())\n# 1st Dense Layer\nmodel_alex.add(Dense(4096, activation='relu'))\n# model.add(Activation('relu'))\n# Add Dropout to prevent overfitting\n# model_alex.add(Dropout(0.4))\n# Batch Normalisation\nmodel_alex.add(BatchNormalization())\n\n# 2nd Dense Layer\nmodel_alex.add(Dense(1024,activation='relu'))\n# model1.add(Activation('relu'))\n# Add Dropout\n# model_alex.add(Dropout(0.4))\n# Batch Normalisation\nmodel_alex.add(BatchNormalization())\n\n# 3rd Dense Layer\nmodel_alex.add(Dense(512,activation='relu'))\n# model.add(Activation('relu'))\n# Add Dropout\n# model_alex.add(Dropout(0.4))\n# Batch Normalisation\nmodel_alex.add(BatchNormalization())\n\n# Output Layer\nmodel_alex.add(Dense(7, activation='softmax'))\n# model1.add(Activation('softmax'))\n\nmodel_alex.summary()\n\ntf.keras.utils.plot_model(model_alex)","92187dc4":"model_alex.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nbatch_size= 32\nepochs= 20\n\nhistory= model_alex.fit(X_train,y_train, validation_split=0.2,\n                    batch_size= batch_size,\n                    epochs=epochs,\n                    callbacks=[\n                      tf.keras.callbacks.EarlyStopping(\n                      monitor='val_loss',\n                      patience=3,\n                      restore_best_weights=True\n                      )\n                  ]\n                  )","456df5a4":"model_acc_alex = model_alex.evaluate(X_test, y_test, verbose=0)[1]\n\nprint(\"Test Accuracy: {:.3f}%\".format(model_acc_alex * 100))","2d9c1387":"y_true = np.array(y_test)\n\ny_pred = model.predict(X_test)\ny_pred = np.array(list(map(lambda x: np.argmax(x), y_pred)))","0a2c8c6e":"cm = confusion_matrix(y_true, y_pred)\nclr = classification_report(y_true, y_pred, target_names=label_mapping.values())","dc053789":"plt.figure(figsize=(10, 10))\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cbar=False, cmap='Blues')\n\nplt.xticks(np.arange(7) + 0.5, label_mapping.values())\nplt.xlabel(\"Predicted\")\n\nplt.yticks(np.arange(7) + 0.5, label_mapping.values())\nplt.ylabel(\"Actual\")\n\nplt.title(\"Confusion Matrix\")\n\nplt.show()","224b20b4":"print(clr)","62541caa":"# Adhoc Model","add66733":"# Let's try for some modification in Alex Net "}}