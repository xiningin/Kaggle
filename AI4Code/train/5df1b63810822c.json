{"cell_type":{"905197b9":"code","6f603659":"code","e01adc2d":"code","183858b5":"code","161911ee":"code","712f1a96":"code","3d56c99d":"code","00eb72a5":"code","e1a814dd":"code","2c590a6e":"code","2745d9a6":"code","cdadc503":"code","28b93b19":"code","f9be5301":"code","b1961303":"code","a4737197":"code","a098115d":"code","9f3bbae5":"code","cbc9ea3f":"code","d2f66859":"code","85f9b498":"code","4b763c78":"code","fa1da0f4":"code","ee25bda9":"code","7cbec45e":"code","dc7420c5":"code","eed9708e":"code","c1facaac":"code","496cd862":"code","9795faaf":"code","ae5313d6":"markdown","6b7b91ac":"markdown","a9f91e15":"markdown","27bf9a4f":"markdown","ef1ba210":"markdown","d9478de9":"markdown","391de22d":"markdown","1a42e5ed":"markdown","f1be1f8b":"markdown","256f8dba":"markdown","85f64c23":"markdown","72595ab0":"markdown","3334c0cd":"markdown","19b2bc07":"markdown","7f8ae1ae":"markdown","d96e12b8":"markdown","aa97f5b6":"markdown","bd22d735":"markdown","360727cb":"markdown","43b506f4":"markdown","19d1d230":"markdown","b4ac3f08":"markdown","0d7f65a2":"markdown","e71cf7f3":"markdown","b468d953":"markdown"},"source":{"905197b9":"import numpy as np # linear algebra\nimport pandas as pd # data processing\n\n\nimport seaborn as sns # data visualization\nimport matplotlib.pyplot as plt # data visualization\n\nfrom sklearn import metrics # metrics\nfrom sklearn.preprocessing import OneHotEncoder # encoding\n\nfrom sklearn.model_selection import train_test_split # dividing data\n\n# models\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC","6f603659":"df = pd.read_csv('..\/input\/bike-buyers\/bike_buyers.csv')\ndf.head()","e01adc2d":"print('Rows: %s\\nColumns: %s' % df.shape)","183858b5":"# some columns have missing data\ndf.info()","161911ee":"# statistical description\ndf.describe()","712f1a96":"df['Purchased Bike'].value_counts()","3d56c99d":"df[['Age', 'Income']].hist(bins=12, figsize=(17, 5));","00eb72a5":"df[['Income']].boxplot(figsize=(12,6));","e1a814dd":"df[['Age']].boxplot(figsize=(12,6));","2c590a6e":"fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(nrows=3, ncols=2, figsize=(20, 15))\nsns.countplot(x='Gender', hue='Purchased Bike',data=df,ax=ax1);\nsns.countplot(x='Marital Status', hue='Purchased Bike',data=df, ax=ax2, edgecolor='0.4');\nsns.countplot(x='Education', hue='Purchased Bike',data=df,ax=ax3, edgecolor='0.4');\nsns.countplot(x='Occupation', hue='Purchased Bike',data=df, ax=ax4, edgecolor='0.4');\nsns.countplot(x='Cars', hue='Purchased Bike',data=df, ax=ax5, edgecolor='0.4');\nsns.countplot(x='Children', hue='Purchased Bike',data=df, ax=ax6, edgecolor='0.4');","2745d9a6":"df['Age'].fillna(df['Age'].median(), inplace=True) \ndf['Income'].fillna(df['Income'].median(), inplace=True)\ndf['Cars'].fillna(df['Cars'].median(), inplace=True)\ndf['Children'].fillna(df['Children'].median(), inplace=True)\ndf['Home Owner'].fillna(df['Home Owner'].mode()[0], inplace=True)\ndf['Marital Status'].fillna(df['Marital Status'].mode()[0], inplace=True)\ndf['Gender'].fillna(df['Gender'].mode()[0], inplace=True)","cdadc503":"df['Children'] = df['Children'].astype('int')\ndf['Cars'] = df['Cars'].astype('int')\ndf['Age'] = df['Age'].astype('int')","28b93b19":"map_rep = {'Gender' : {'Female' : 0, 'Male' : 1},\n'Purchased Bike' : {'No' : 0, 'Yes' : 1},\n'Marital Status' : {'Single' : 0, 'Married' : 1 },\n'Home Owner' : {'No' : 0, 'Yes' : 1},\n'Education' : {'Partial High School' : 0, 'High School' : 1, 'Partial College' : 2, 'Bachelors' : 3, 'Graduate Degree' : 4},\n'Commute Distance' : {'0-1 Miles' : 4, '1-2 Miles' : 3, '2-5 Miles' : 2, '5-10 Miles' : 1, '10+ Miles' : 0 }\n}\n\ndf.replace(map_rep, inplace=True)\ndf.head()","f9be5301":"x_region = OneHotEncoder().fit_transform(df['Region'].values.reshape(-1, 1)).toarray()\nx_ocuppation = OneHotEncoder().fit_transform(df['Occupation'].values.reshape(-1, 1)).toarray()\nx_region, x_ocuppation\n\ndf = pd.concat([df, pd.DataFrame(x_region, columns=['Region_1', 'Region_2', 'Region_3']), \n               pd.DataFrame(x_ocuppation, columns=['Occu_1', 'Occu_2', 'Occu_3', 'Occu_4', 'Occu_5'])], axis=1)\ndf.head()","b1961303":"df= df.drop(['ID', 'Region', 'Occupation'], axis=1)","a4737197":"corr_matriz = df.iloc[:, :10].corr()\n\ncorr_matriz['Purchased Bike'].sort_values(ascending=False)","a098115d":"plt.figure(figsize=(12, 7))\nsns.heatmap(corr_matriz, mask=np.triu(corr_matriz), annot=True, cmap='viridis');","9f3bbae5":"y = df['Purchased Bike']\nX = df.drop(['Purchased Bike'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37, stratify=y)","cbc9ea3f":"X_train_mm =  (X_train - X_train.min())\/(X_train.max() - X_train.min())\nX_test_mm = (X_test - X_train.min())\/(X_train.max() - X_train.min())","d2f66859":"X_train_std = (X_train - X_train.mean())\/X_train.std()\nX_test_std = (X_test - X_train.mean())\/X_train.std()","85f9b498":"scalers = ['no scalling', 'MinMax', 'Std']\n\nresults = []\nfor scaler in scalers:\n    if scaler == 'MinMax':\n        X_train_, X_test_ = X_train_mm, X_test_mm\n    elif scaler == 'Std':\n        X_train_, X_test_ = X_train_std, X_test_std\n    else:\n        X_train_, X_test_ = X_train, X_test\n\n    for k in list(range(3, 76, 2)):\n        knn = KNeighborsClassifier(n_neighbors=k)\n        knn.fit(X_train_, y_train)\n        y_pred = knn.predict(X_test_)\n        acuracia = metrics.accuracy_score(y_test, y_pred)\n        result = { 'k' : k, 'weight': 'no weight', 'scaler': scaler, 'accuracy': acuracia}\n        results.append(result)\n\n        knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n        knn.fit(X_train_, y_train)\n        y_pred = knn.predict(X_test_)\n        acuracia = metrics.accuracy_score(y_test, y_pred)\n        result = { 'k' : k, 'weight': 'distance', 'scaler': scaler, 'accuracy': acuracia}\n        results.append(result)","4b763c78":"df_r = pd.DataFrame(results)\n\ndf_r.nlargest(10, 'accuracy')","fa1da0f4":"a = df_r[(df_r['weight'] == 'no weight') & (df_r['scaler'] == 'no scalling')]\nb = df_r[(df_r['weight'] == 'no weight') & (df_r['scaler'] == 'MinMax')]\nc = df_r[(df_r['weight'] == 'no weight') & (df_r['scaler'] == 'Std')]\nd = df_r[(df_r['weight'] == 'distance') & (df_r['scaler'] == 'no scalling')]\ne = df_r[(df_r['weight'] == 'distance') & (df_r['scaler'] == 'MinMax')]\nf = df_r[(df_r['weight'] == 'distance') & (df_r['scaler'] == 'Std')]","ee25bda9":"def func_plot(score, title):   \n    plt.figure(figsize=(12, 7))\n    plt.plot(range(3, 76, 2), score, color='green', marker='o')\n    plt.grid()\n    plt.title(f'KNN ({title}) ', fontsize=18)\n    plt.xlabel('Number of neighbors (K)', fontsize=15)\n    #plt.yticks(np.arange(0.45, 0.6, 0.02))\n    plt.xticks(np.arange(0, 77, 5))\n    plt.ylabel('Accuracy', fontsize=15);","7cbec45e":"func_plot(a['accuracy'].values, 'no scalling')\nfunc_plot(b['accuracy'].values, 'Min-Max')\nfunc_plot(c['accuracy'].values, 'Standardization')","dc7420c5":"func_plot(d['accuracy'].values, 'no scalling')\nfunc_plot(e['accuracy'].values, 'Min-max')\nfunc_plot(f['accuracy'].values, 'Standardization')","eed9708e":"knn = KNeighborsClassifier(n_neighbors=43, weights='distance')\nknn.fit(X_train_std, y_train)\ny_pred = knn.predict(X_test_std)\nmetrics.plot_confusion_matrix(knn, X_test_std, y_test);\nplt.title('Confusion Matrix');","c1facaac":"print(metrics.classification_report(y_test, y_pred))","496cd862":"# Decision Tree\ntree = DecisionTreeClassifier()\ntree = tree.fit(X_train_std, y_train)\ny_pred_tr = tree.predict(X_test_std)\n\n#Random Forest\nforest = RandomForestClassifier()\nforest.fit(X_train_std, y_train) \ny_pred_fr = forest.predict(X_test_std)\n\n# Logistic Regression\nlogistic = LogisticRegression()\nlogistic.fit(X_train_std, y_train)\ny_pred_log = logistic.predict(X_test_std)\n\n# SVC\nsvc = SVC()\nsvc.fit(X_train_std, y_train)\ny_pred_svc = svc.predict(X_test_std)","9795faaf":"print(f'Decision Tree:{metrics.accuracy_score(y_test, y_pred_tr)}')\nprint(f'Random Forest:{metrics.accuracy_score(y_test, y_pred_fr)}')\nprint(f'Logistic Regression:{metrics.accuracy_score(y_test, y_pred_log)}')\nprint(f'SVC:{metrics.accuracy_score(y_test, y_pred_svc)}')","ae5313d6":"### MinMax Scaler\n\nThe formula for min-max scale is:\n$$ x = \\frac{x - min(x)}{max(x) - min(x)} $$","6b7b91ac":"### Drop features","a9f91e15":"## Results","27bf9a4f":"### Dividing data into training and testing data","ef1ba210":"### One Hot Encoding\n","d9478de9":"### Confusion Matrix","391de22d":"## Data visualization\n### Age and income frequency distribution","1a42e5ed":"## Importing Libraries","f1be1f8b":"## KNN","256f8dba":"### Classification report\n","85f64c23":"## Data Description","72595ab0":"### Applying other models","3334c0cd":"### Correlation","19b2bc07":"### Discretization","7f8ae1ae":"## Bike Buyers Dataset \n\nThis dataset has details of 1000 users from different backgrounds and whether or not they buy a bike.\n\n### Features\n- ID\n- Marital Status\n- Gender\n- Income\n- Children\n- Education\n- Occupation\n- Home Owner\n- Cars\n- Commute Distance\n- Region\n- Age\n- Purchased Bike","d96e12b8":"### Grouped Bar Graphs","aa97f5b6":"### Boxplot\n\nUsing the graph allows you to assess the symmetry and distribution of data, and also provides perspective\nvisual of the presence or absence of discrepant data (outliers).","bd22d735":"## Feature Scalling","360727cb":"## Preview\n### Results without weighting","43b506f4":"### Standardization \nStandardization is defined as:\n$$ x = \\frac{x - mean(x)}{\\sigma(x)} $$","19d1d230":"### Results with weighting","b4ac3f08":"## Data Transformation\n### Missing Values Handling","0d7f65a2":"## Reading the data","e71cf7f3":"### Type change","b468d953":"### Accuracy"}}