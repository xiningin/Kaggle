{"cell_type":{"140a1c71":"code","d00188ef":"code","47ad2499":"code","4e8ecc33":"code","606f967f":"code","216229d4":"code","3eabd3d2":"code","a04f30d1":"code","391930eb":"code","c68b39cb":"code","fad3ec6e":"code","e8e6c058":"code","6a833022":"code","11681faf":"code","85164a2a":"code","be620076":"code","00d7e91e":"code","412cd35a":"code","d7821b6a":"code","e3cbf16c":"code","e658249b":"code","05ae7dad":"code","3e4395a5":"code","82d56144":"code","ddf91d67":"code","bc782186":"code","c168e681":"code","70fe77ee":"code","c07a9cda":"code","acf27bae":"code","61b32ddb":"code","fa6ac280":"code","28c9751b":"code","3fbe97fd":"code","0740dc47":"code","0df5f9b1":"code","357ce8a5":"code","e2943c8a":"code","9af5384c":"markdown"},"source":{"140a1c71":"!pip install timm","d00188ef":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"ggplot\")\n\nimport torch\nimport torch.nn as nn\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn, optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torchvision import datasets, models, transforms  \nfrom torch.utils.data.sampler import SubsetRandomSampler  \nfrom torch.utils.data import Dataset, DataLoader\n\nimport pandas as pd\nimport torch.nn.functional as F\nimport os\n\nfrom tqdm import tqdm\nimport tqdm.notebook as tq\n\nimport time\nimport json\nimport copy\nimport gc\nimport os\nimport time\nimport random\nfrom datetime import datetime\n\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nfrom sklearn import model_selection, metrics\n\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport timm\n","47ad2499":"timm.list_models()","4e8ecc33":"def seed_everything(seed):\n    \"\"\"\n    Seeds basic parameters for reproductibility of results\n    \n    Arguments:\n        seed {int} -- Number of the seed\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\nseed_everything(1001)","606f967f":"DATA_PATH = \"..\/input\/dont-stop-until-you-drop\"\nTEST_PATH = \"..\/input\/dont-stop-until-you-drop\/images\/test_images\"\nTRAIN_PATH = \"..\/input\/dont-stop-until-you-drop\/images\/train_images\"\nMODEL_PATH = (\n    \"..\/input\/vit-base-models-pretrained-pytorch\/jx_vit_base_p16_224-80ecf9dd.pth\"\n)\n\n# model specific global variables\nIMG_SIZE = 224\ny_col = 'class_6'\nx_col = 'image_id'\n\nparams = {\n    'seed': 42,\n    'model': 'swin_base_patch4_window12_384',\n    'size' : IMG_SIZE,\n    'inp_channels': 1,\n  \n    'lr': 1e-4,\n    'weight_decay': 1e-6,\n \n    'epochs': 40,\n    \n    'name': 'CosineAnnealingLR',\n    'T_max': 10,\n    'min_lr': 1e-6,\n    'num_tta':1\n}","216229d4":"df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\ndf.head()","3eabd3d2":"claas_num = len(df[y_col].unique())","a04f30d1":"df[y_col].value_counts().plot(kind=\"bar\")\n","391930eb":"train_df, valid_df = model_selection.train_test_split(\n    df, test_size=0.2, random_state=42, stratify=df[y_col].values\n)","c68b39cb":"class CaDataset(torch.utils.data.Dataset):\n    \"\"\"\n    Helper Class to create the pytorch dataset\n    \"\"\"\n\n    def __init__(self, df, data_path=DATA_PATH, mode=\"train\", transforms=None):\n        super().__init__()\n        self.df_data = df.values\n        self.data_path = data_path\n        self.transforms = transforms\n        self.mode = mode\n        self.data_dir = TRAIN_PATH if mode == \"train\" else TEST_PATH\n\n    def __len__(self):\n        return len(self.df_data)\n\n    def __getitem__(self, index):\n        if self.mode == 'testnolabel':\n            img_name = self.df_data[index]\n            #print(img_name)\n        else:\n            img_name, label = self.df_data[index]\n        img_path = os.path.join( self.data_dir, img_name)\n        \n        img = Image.open(img_path).convert(\"L\")#RGB\n\n        if self.transforms is not None:\n            image = self.transforms(img)\n        if self.mode == 'train':\n            return image , label\n        else:\n            return image","fad3ec6e":"#oversampling using wighted class\nimport numpy as np\nfrom torch.utils.data.sampler import WeightedRandomSampler\n\ncounts = np.bincount(train_df[y_col])\nprint(counts)\nlabels_weights = 1. \/ counts\nprint(labels_weights)\nweights = labels_weights[train_df[y_col]]\nprint(weights)\nsampler = WeightedRandomSampler(torch.DoubleTensor(weights), len(weights))","e8e6c058":"labels_weights","6a833022":"labels_weights[train_df[y_col]]","11681faf":"counts2 = np.bincount(valid_df[y_col])\nlabels_weights2 = 1. \/ counts2\nweights2 = labels_weights2[valid_df[y_col]]\nsampler2 = WeightedRandomSampler(torch.DoubleTensor(weights2), len(weights2))","85164a2a":"transforms_train = transforms.Compose(\n    [\n          transforms.Resize((IMG_SIZE, IMG_SIZE)),\n     transforms.RandomRotation(15),\n        #transforms.RandomHorizontalFlip(),\n        #transforms.RandomVerticalFlip(),\n        transforms.RandomResizedCrop(IMG_SIZE),\n        transforms.RandomAffine(degrees=40, scale=(.9, 1.1), shear=0),\n        transforms.RandomPerspective(distortion_scale=0.2),\n        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n        transforms.GaussianBlur(3),\n        transforms.ToTensor(),\n       transforms.Normalize((0.5,), (0.5,))  #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n    ]\n)\n\n\ntransforms_valid = transforms.Compose(\n    [\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n    ]\n)\n","be620076":"BATCH_SIZE = 32","00d7e91e":"train_dataset = CaDataset(train_df, transforms=transforms_train)\nvalid_dataset = CaDataset(valid_df, transforms=transforms_valid)","412cd35a":"len(valid_dataset)","d7821b6a":"train_loader =  DataLoader( dataset=train_dataset,\n        batch_size=BATCH_SIZE,\n      \n        drop_last=True,\n       shuffle=False  ,sampler = sampler)\nvalid_loader =    DataLoader(  dataset=valid_dataset,\n        batch_size=BATCH_SIZE,\n        \n        drop_last=True,\n        shuffle=False ,sampler = sampler2)\ndataloaders = {'train':train_loader, 'valid':valid_loader}\ndataset_sizes = {'train':len(train_dataset), 'valid':len(valid_dataset) }\n\n\n\n ","e3cbf16c":"next(iter(train_loader))[1]","e658249b":"class timmofNet(nn.Module):\n    def __init__(self, model_name , out_features ,\n                 inp_channels , pretrained=True , typo='head'):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained,\n                                       in_chans=inp_channels)\n        #print(self.model)\n        if typo == 'classifier':\n            n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Linear(n_features, out_features, bias=True)            \n        else:\n            n_features = self.model.head.in_features\n            self.model.head = nn.Linear(n_features, out_features, bias=True)    \n    \n    def forward(self, x):\n        x = self.model(x)\n        return x\n","05ae7dad":"'''\nmodel = torch.hub.load('facebookresearch\/deit:main', 'deit_base_patch16_224', pretrained=True)\ni = 0\nfor child in model.blocks.children():\n    if i < 5:\n        for param in child.parameters():\n            param.requires_grad = False\n    else:\n        for param in child.parameters():\n            param.requires_grad = True\n    i +=1\n\n'''\n\nmodel = timmofNet( model_name='swin_base_patch4_window7_224', out_features=claas_num, inp_channels=1, pretrained=True)\n\n\n#model = timmofNet( model_name='efficientnet_b1', out_features=claas_num, inp_channels=1, pretrained=True,typo='classifier')\n","3e4395a5":"model","82d56144":"criterion =  nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n\nsched = lr_scheduler.ReduceLROnPlateau(optimizer,mode='min', factor=0.5, patience=2 , verbose=True)\neps= params['epochs']","ddf91d67":"def train_model(model, criteria, optimizer, scheduler,    \n                                      num_epochs=25, device='cuda'):\n    model.cuda()\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    best_loss = np.Inf\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                #scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n \n            # Iterate over data.\n            for img , labels in dataloaders[phase]:\n                inputs = img.to(device)\n                #labels = labels.view(labels.shape[0],1)\n                labels = labels.to(device)\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    #preds = torch.round(torch.sigmoid(outputs))\n                    #print(outputs)\n                    #print(torch.max(outputs,1))\n                    _,preds = torch.max(outputs,1)\n                    loss = criterion(outputs, labels)\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n            if phase == 'valid':\n                scheduler.step(epoch_loss)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'valid' and epoch_loss < best_loss:\n                best_acc = epoch_acc\n                best_loss = epoch_loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n                torch.save(model.state_dict(), 'bestwight-phase1-ep-'+str(epoch)+'.pth')\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","bc782186":"gpu = torch.cuda.is_available()\n","c168e681":"device = torch.device(\"cuda\" if gpu else \"cpu\")   # use CPU or GPU\n","70fe77ee":"model_ft = train_model(model, criterion, optimizer, sched, eps, device)\n","c07a9cda":"#torch.save(model.state_dict(), 'swin-40epochsepoch-bestwight-oversamplining.pth')\n\n\n                                 \n                                                     ","acf27bae":"transforms_valid = transforms.Compose(\n    [\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))#transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        #transforms.Grayscale(num_output_channels=1)\n    ]\n)","61b32ddb":"\ntorch.save(model_ft.state_dict(), 'swin-40-40epochsepoch-bestwight-oversamplining.pth')\n","fa6ac280":"# upload the test class in the submission.csv file\nimg_folder= '\/kaggle\/input\/dont-stop-until-you-drop\/images\/test_images\/'\nsubmission_list = []\nfinal_list = []\nfor test_image in os.listdir(img_folder):\n\n    final_list.append((test_image,0))\n\ntest_df = pd.DataFrame(final_list,columns = ['image_id','class_6'])\nprint(test_df.head())\n\n#convert into .csv\ntest_df.to_csv('testdata.csv', index=False)","28c9751b":"\n#test = pd.read_csv(os.path.join(DATA_PATH, \"sample_submission.csv\"))\ntest_dataset = CaDataset(test_df,mode='test' , transforms=transforms_valid)\ntest_loader =    DataLoader(  dataset=test_dataset,\n        batch_size=BATCH_SIZE,pin_memory=True,\n        \n        drop_last=False ,shuffle=False)","3fbe97fd":"def inference(models, test_loader, device):\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        for model in models:\n            model.eval()\n            with torch.no_grad():\n                y_preds1 = model(images)\n                #y_preds2 = model(images.flip(-1))\n            #y_preds = (y_preds1 + y_preds2 ) \/ 2\n            _,preds = torch.max(y_preds1,1)\n            avg_preds.append(preds.to('cpu').numpy())\n        #avg_preds = np.mean(avg_preds, axis=0)\n        for ittm2 in avg_preds:\n            #print(ittm)        \n            for ittm in ittm2:\n                #print(ittm)\n                probs.append(ittm)\n    #probs = np.concatenate(probs)\n    return probs","0740dc47":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodels = [model_ft.to(device)  ]","0df5f9b1":"predictions = inference(models, test_loader, device)\n","357ce8a5":"predictions","e2943c8a":"test_df['class_6'] = predictions\ntest_df.to_csv('submission-man004eps.csv', index=False)\ntest_df.head()","9af5384c":"#### this solution due to internet problem and less computional rescources was not submited during the 4 hours so we late submited it and not recoreded  in our score  .. still you can run the solution and get (88.5%)\n"}}