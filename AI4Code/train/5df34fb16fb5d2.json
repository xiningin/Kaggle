{"cell_type":{"13aca2a0":"code","8105afe0":"code","be57f470":"code","c16ec4ae":"code","e2237f69":"code","36420e59":"code","7614591a":"code","6a39e5d1":"code","14c1b55b":"code","41736b64":"code","65b3ce79":"code","9b130353":"code","25b970a3":"code","82c08a05":"code","3842aa59":"code","1e21e972":"code","de622e8c":"code","48f40c2d":"code","b6375dca":"code","5f54e9ac":"code","bae1b063":"code","50914b69":"code","2908b835":"code","625bbf09":"code","acdba292":"code","5baab31a":"code","b07a03fe":"code","4179368b":"code","65c73905":"code","afab4718":"code","51c14d8c":"code","a4e03423":"code","733fd3c5":"code","031706c0":"code","5b583aa7":"code","f07d060d":"markdown","75d99d82":"markdown","ff9788f9":"markdown","dfc7cd07":"markdown","70577e58":"markdown","3fe3fbea":"markdown","c44f9107":"markdown","fded4d0b":"markdown","9bfc523d":"markdown","1ecd5c3d":"markdown","57df0d4a":"markdown","6ab988b2":"markdown","e9ff552b":"markdown","4b7ed2c1":"markdown","65fcf800":"markdown","8cd8aa05":"markdown","77c633aa":"markdown"},"source":{"13aca2a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8105afe0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import r2_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline \n\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.gridspec import GridSpec\n\n#Plotly\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\n#Some styling\nsns.set_style(\"darkgrid\")\nplt.style.use(\"fivethirtyeight\")\n\n#Subplots\nfrom plotly.subplots import make_subplots\n\n","be57f470":"train_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","c16ec4ae":"train_data.head()","e2237f69":"print('Train Data :>',train_data.shape)\nprint('-'*123)\nprint('Test Data :>',test_data.shape)","36420e59":"print('Train Data :>',train_data.info())\nprint('-' * 123)\nprint('Test Data :>',test_data.info())","7614591a":"# Descriptive measure of data\ntrain_data.describe(include='all')","6a39e5d1":"train_data.isna().sum().sort_values(ascending=False)","14c1b55b":"# First we create a list of missing values by each feature \ntemp = list(train_data.isna().sum())\n# them we create a list of columns and their missing values as inner list to a separate list\nlst=[]\ni=0\nfor col in train_data.columns:\n    insert_lst = [col,temp[i]]\n    lst.append(insert_lst)\n    i+=1\n\n# finally create a dataframe\ntemp_train_data = pd.DataFrame(data=lst,columns=['Column_Name','Missing_Values'])","41736b64":"fig = px.bar(temp_train_data.sort_values(by='Missing_Values'),x='Missing_Values',y='Column_Name',\n             orientation='h',height=1500,width=900,color='Missing_Values',text='Missing_Values')\nfig.update_traces(textposition='outside')\nfig.show()","65b3ce79":"# The following columns have missing values\ntemp_train_data[temp_train_data['Missing_Values']>0].sort_values(by='Missing_Values',\n                                                 ascending=False).reset_index(drop=True).style.background_gradient(cmap='Reds')","9b130353":"columns_name = []\nfor i in train_data.columns:\n    if train_data[i].isna().sum()\/len(train_data)*100 >=10:\n        columns_name.append(i)\nprint(columns_name)# List of columns which has >=10% missing data      ","25b970a3":"# Droping columns in train data\ntrain_data = train_data.drop(columns=columns_name,axis = 1)\ntrain_data.sample(5)","82c08a05":"train_data.SalePrice.describe()","3842aa59":"fig = make_subplots(rows=1,cols=2)\n\nfig.add_trace(go.Histogram(x=train_data['SalePrice']),row=1,col=1)\nfig.add_trace(go.Box(y=train_data['SalePrice'],boxpoints='all',line_color='orange'),row=1,col=2)\n\nfig.update_layout(height=500, showlegend=False,title_text='SalePrice Distribution and Box Plot')","1e21e972":"# checking the skewness\ntrain_data.skew().sort_values(ascending=False)","de622e8c":"plt.figure(figsize=(100,90))\nsns.heatmap(train_data.corr(),annot = True,fmt=\".1f\",annot_kws={'size':48})\n# Returns correlation among fatures which obervations","48f40c2d":"fig = px.histogram(train_data, x=\"SalePrice\", color='OverallQual',barmode=\"overlay\",title=\"Overall Quality of the house\")\nfig.update_layout(height=500)\nfig.show()\n\nfig = px.histogram(train_data, x=\"SalePrice\", color='OverallCond',barmode=\"overlay\",title=\"Overall Condition of the house\")\nfig.update_layout(height=500)\nfig.show()","b6375dca":"feature_data = train_data.drop(columns=['SalePrice'],axis=1)\ntarget_data =train_data.SalePrice ","5f54e9ac":"# int and Float columns\nint_float_data = feature_data.select_dtypes(include=['int','float'])","bae1b063":"# categorical columns\ncat_data = feature_data.select_dtypes(include=['object'])","50914b69":"# creating sub-pipeline \nfloat_int_pipeline = make_pipeline(SimpleImputer(strategy='median'),MinMaxScaler())\ncat_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'),OrdinalEncoder())","2908b835":"# transforming columns (preprocessing)\npreprocessor = make_column_transformer(\n    (float_int_pipeline,int_float_data.columns),\n    (cat_pipeline,cat_data.columns)\n)","625bbf09":"# using LinearRegression\npipeline = make_pipeline(preprocessor, LinearRegression())","acdba292":"trainX, testX, trainY, testY = train_test_split(feature_data, target_data)","5baab31a":"pipeline.fit(feature_data, target_data)","b07a03fe":"pipeline.score(testX,testY) # using LinearRegression wwe geting 0.69","4179368b":"# now using RandomForestClassifier\npipeline = make_pipeline(preprocessor, RandomForestClassifier()) ","65c73905":"pipeline.fit(feature_data, target_data)","afab4718":"pipeline.score(testX,testY) # For this data set the RandomForestClassifier is best model to predict","51c14d8c":"# Now check the mean_squared_error\ny_pred = pipeline.predict(testX)","a4e03423":"mean_squared_error(testY, y_pred)","733fd3c5":"r2_score(testY, y_pred)","031706c0":"y_pred = pipeline.predict(test_data)\nsubmission = pd.DataFrame({'Id': test_data.index,'SalePrice': y_pred})","5b583aa7":"submission.to_csv(\"house_prices_submission.csv\", index=False)","f07d060d":"### Correlation between different features","75d99d82":"* Our target feature is a continuous variable with values ranging from 34900 to 755000.\n* The average sale price of all the houses in our dataset is 180921.","ff9788f9":"### Creating Pipeline model","dfc7cd07":"#### Target Feature\n* SalePrice","70577e58":"This doesn't help us much, let's try to visualize the number of missing values in each feature","3fe3fbea":"* Skewness tells us about the symmetry in a distribution.\n* If Skewness is equal to zero , It is a symmetrical distribution.\n* And If Skewness is less than or more than zero then it is a non-symmetrical distribution.\n* If value is less than zero , distribution is left skewed and value is more than zero , distribution is right skewed.\n* In our above data,\n    1. LotArea\n    2. LowQualFinSF\n    3. SsnPorchPoolArea\n    4. MiscVal\n* Are highly positively,right skewed.","c44f9107":"### Finding the missing value of train data\n* Removing the missing data","fded4d0b":"* Out of the 18 columns with missing values,\n* Three are numerical features LotFrontage,MasVnrArea and GarageYrBlt\n* And the rest are categorical features.","9bfc523d":"* **SalePrice** is our target variable. We have to predict the best price of house","1ecd5c3d":"* Sale Price has a right skewed distribution.\n* The median sale price of our dataset is 163000 which is less than the average value i.e because of right skewed distribution.\n* We can see some of the houses have sale price more than 4,00,000.","57df0d4a":"### Training Data \n* There are total 1460 observation with 81 columns\/variable\/features.\n* There are both numerical and categorical data.\n\n### Test Data\n* There are total 1459 observation with 80 columns\/variable\/features.\n* The missing variable is **SalePrice** as it is the target column that we want to predict.\n* There are both numerical and categorical data.\n","6ab988b2":"### Importing House prices data set","e9ff552b":"### creating feature data and target data","4b7ed2c1":"* **BsmtUnfSF, 2ndFlrSF, OverallCond, TotRmsAbvGrd, HalfBath, Fireplaces, BsmtFullBath, OverallQual, MoSold, BedroomAbvGr, GarageArea, YrSold, FullBath, Id, GarageCars, YearRemodAdd, YearBuilt, GarageYrBlt** Variables are nearly Symmetical in shape\n\n\n### Outliers \n* **MiscVal, PoolArea, LotArea, 3SsnPorch, LowQualFinSF, KitchenAbvGr, BsmtFinSF2, ScreenPorch, BsmtHalfBath, EnclosedPorch, MasVnrArea, OpenPorchSF, LotFrontage, SalePrice, BsmtFinSF1, WoodDeckSF, TotalBsmtSF, MSSubClass, 1stFlrSF, GrLivArea** Variables are positively skewed (asymmetrical in shape)\n","65fcf800":"* The above information tells us\n\n* Our dataset features consists of three datatypes\n    1. float\n    2. integer\n    3. object\n* Of which total numerical features are 38\n* And categorical features are 43.\n* But if we look closely , we see that some of the data types are incorrect.\n * For ex :- MSSubClass,OverallQual and OverallCond should be object data types.\n* Also we don't have complete data for all of our features","8cd8aa05":"### **Skewness**\n* Describe how are distributed\n* It is measure of shape : Symmetrical or Asymmetrical","77c633aa":"### Importing Some Usefull libraris"}}