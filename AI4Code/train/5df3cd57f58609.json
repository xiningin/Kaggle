{"cell_type":{"08e41fbe":"code","6dd6d3be":"code","ab3fce6a":"code","1f915ae7":"code","eed40567":"code","570520dd":"code","b4b0c704":"code","0597b19e":"code","ee84c021":"code","4aa7c34d":"code","b03c60a1":"code","7f8b2b7b":"code","0006d811":"code","840345aa":"code","c73fe35a":"code","20b370f2":"code","a5e1e22d":"code","d6fdf4d3":"code","ca2b1610":"code","d19432ee":"code","0b33d182":"code","5167e3a0":"code","4537f2cf":"code","fae514b8":"code","6123edf5":"code","c2355f1a":"code","b5f9b839":"code","2d667a84":"code","15658f60":"code","bddfef0e":"code","637550b7":"code","1a715fda":"code","2fe9d8dd":"code","4e1711d0":"code","6a712067":"code","4a61064b":"code","23a1647a":"markdown","6ba0852f":"markdown","a66a8866":"markdown","98acab8f":"markdown","7f5958df":"markdown","79613bc0":"markdown","a3872281":"markdown","b1f2c021":"markdown","fa4bad36":"markdown","01919cb2":"markdown","a6a83782":"markdown","c7029ae5":"markdown","62a8fe84":"markdown","6a875f69":"markdown","6fb3402b":"markdown","5776fe5a":"markdown","9d0898d3":"markdown","e378efed":"markdown","2e21c7e2":"markdown","76327641":"markdown","d954bfb5":"markdown","ea6a7020":"markdown","25f5ed6f":"markdown","0898032f":"markdown","be984025":"markdown","aaa6ab14":"markdown","254b30f4":"markdown","5a1066ba":"markdown","becf6cd8":"markdown","943db4e0":"markdown","75667420":"markdown","535a2195":"markdown","36c52105":"markdown","214aaeae":"markdown","721a392b":"markdown","bb4b6e10":"markdown","813f8af2":"markdown","17c5199f":"markdown","fa6ba4fb":"markdown","c74165d2":"markdown","eef5ff6a":"markdown","9811608f":"markdown","609e3ffa":"markdown"},"source":{"08e41fbe":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport re\nimport math\n\nsns.set()\npd.set_option('display.max_columns', None)","6dd6d3be":"import re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle\nimport numpy as np\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport pandas as pd\nfrom sklearn import feature_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn import neighbors\n\nNUTRIGRADE_COLORS = {\n    'A': 'forestgreen',\n    'B': 'lawngreen',\n    'C': 'gold',\n    'D': 'darkorange',\n    'E': 'firebrick'\n}\n\nNUTRIGRADE_XTICKS = {\n    'A': 'A [-15;0[',\n    'B': 'B [0;3[',\n    'C': 'C [3;11[',\n    'D': 'D [11;19[',\n    'E': 'E [19;40]'\n}\n\ndef get_nutriscore_letter(score):\n    ''' Returns the nutrigrade letter according to the numeric nutriscore '''\n    if score < 0:\n        return 'A'\n    elif score < 3:\n        return 'B'\n    elif score < 11:\n        return 'C'\n    elif score < 19: \n        return 'D'\n    else:\n        return 'E'\n    \ndef get_nutritional_columns(data, exclude_starts=[]):\n    ''' Explore the data columns to return the columns names that seems to be nutritional columns '''\n    if len(exclude_starts) > 0:\n        regexp = '^(?!'\n        for index, start in enumerate(exclude_starts):\n            if index > 0:\n                regexp = regexp + '|'\n            regexp = regexp + '(' + start + ')'\n        regexp = regexp + ').*_100g$'\n    else:\n        regexp = '^.*_100g$'\n            \n    return [x for x in data.columns.values if re.match(regexp, x)]\n\n\ndef get_variables_with_filling_percentage(filled_data, min=0, max=100):\n    ''' Return the filled data with only a certain percentages of filling\n    \n        Parameters:\n        filled_data (pd.series): the list of all the variables with one column containing their filling percentage\n        min (int): the minimum filling percentage to keep (included)\n        max (int): the maximum fulling percentage to keep (excluded except if = 100%)\n\n        Returns:\n        pd.series: the filtered variables\n    '''\n    # Avoid excluding 100% filled variables \n    if max == 100:\n        max = 101\n    plot_variables = filled_data.to_frame()\n    plot_variables = plot_variables[(plot_variables[0] >= min) & (plot_variables[0] < max)]\n    \n    return plot_variables\n\n\ndef plot_variables_filling_percentage(filled_data, min=0, max=100, ax=None, color=\"blue\"):\n    ''' Plot the horizontal bar chart of the variables with a filling percentage between min and max \n        \n        Parameters:\n            filled_data (list) : a list containing the data name and filling percentages\n            min (int) : the minimum percentage to display (included)\n            max (int) : the maximum percentage to display (excluded)\n            ax (plt.Axes) : the plt axe on which plot\n            color (string) : the color of the bars\n    '''\n    if ax == None:\n        ax = plt.gca()\n    \n    plot_variables = get_variables_with_filling_percentage(filled_data, min, max)\n    \n    # Plotting the results\n    plot_variables.plot(kind='barh', \n                        xlim=(min,max),\n                        fontsize=15,\n                        ax=ax,\n                        color=color)\n    ax.set_title(\"Variables with a filling percentage between \" + str(min) + \"% and \" + str(max) + \"%\", fontsize=20)\n    ax.set_xlabel(\"Filling percentage (France data only)\", fontsize=20)\n    ax.tick_params(axis=\"y\", direction=\"out\", labelcolor=color)\n    ax.invert_yaxis()\n    \ndef extract_country_code(tag):\n    ''' Extract the 2-letters country code at the beginning of a tag string\n        \n        Parameters:\n            tag (string)\n    '''\n    tag_parts = tag.split(':')\n    if len(tag_parts) > 1 and re.match('^[a-z]{2}$', tag_parts[0]):\n        return tag_parts[0]\n    return math.nan","ab3fce6a":"data = pd.read_csv('..\/input\/enopenfoodfactsorgproducts\/en.openfoodfacts.org.products.csv', sep='\\t', low_memory=False)","1f915ae7":"# Defining a variable that will show how many lines we remove with each filter\napplied_filters = {'Initial dataset': len(data)}\n\n# Filtering data\ndata['sold_in_france'] = data['countries'].str.contains('(?:France)|(?::fr)', case=False, regex=True)\n\n# Visualizing on a pie chart the ratio of products sold in France\ntotal_french_products = len(data[data['sold_in_france'] == True])\ntotal_not_french_products = len(data) - total_french_products\n\npie, ax = plt.subplots(figsize=[10,8])\nplt.pie(x=[total_french_products, total_not_french_products], \n        autopct=\"%.2f%%\", \n        labels=[\"Products sold in France\", \"Products not sold in France\"], \n        colors=['limegreen', 'darkgrey'],\n        explode=[0.02]*2,\n        textprops={'size': 18})\nplt.title(\"Ratio of all products that are sold in France\", fontsize=14)\n\ndata_france = data[data['sold_in_france'] == True].copy()\n\napplied_filters['French products'] = len(data_france)","eed40567":"# Let's show the ditribution of our variables filling to get the best ones\nfilled_data = data_france.notnull().sum()\nfilled_data = filled_data * 100 \/ len(data_france)\nfilled_data = filled_data.sort_values(ascending=False)\n\n# We plot the distribution of the filling percentage on a histogramm \nplt.figure(figsize=(15,7))\nsns.histplot(filled_data, bins=10, color=\"crimson\")\nplt.title(\"Distribution of variables according to their fill percentage (France)\", size=20)\nplt.xlabel(\"Filling percentage\", size=16)\nplt.ylabel(\"Number of variables\", size=16)\naxes = plt.gca()\naxes.set_xlim([0,100])\naxes.set_ylim([0,None])","570520dd":"fig, axes = plt.subplots(figsize=(25,20), nrows=2, ncols=2)\nfig.suptitle('Variables grouped by their filling percentages', fontsize=25, y=0.95)\nfig.subplots_adjust(hspace=0.2, wspace=0.4)\n\n\nplot_variables_filling_percentage(filled_data, 80, 100, ax=axes[0][0], color=\"green\")\nplot_variables_filling_percentage(filled_data, 60, 80, ax=axes[0][1], color=\"goldenrod\")\nplot_variables_filling_percentage(filled_data, 30, 60, ax=axes[1][0], color=\"peru\")\nplot_variables_filling_percentage(filled_data, 10, 30, ax=axes[1][1], color=\"brown\")","b4b0c704":"pnns = (pd.concat([data_france['pnns_groups_1'], data_france['pnns_groups_2']])).value_counts()\n\n# The *2 factor is present because we concatenate 2 PNNS columns so we have twice the lenght of the initial DF\npnns = pnns * 100 \/ (len(data_france) * 2)\n\npnns_plot_size = 30\npnns[:pnns_plot_size].plot(kind='barh', figsize=(20,10))\nplt.gcf().suptitle(str(pnns_plot_size) + \" most used keywords in the PNNS columns\", fontsize=20, y=0.92)\nplt.gca().set_xlabel(\"% of products using this PNNS keyword\", fontsize=16)\nplt.gca().invert_yaxis()","0597b19e":"data_france.loc[data_france['pnns_groups_1'] == 'unknown', 'pnns_groups_1'] = np.nan\ndata_france.loc[data_france['pnns_groups_2'] == 'unknown', 'pnns_groups_2'] = np.nan\n\n# The average filling percentage of PNNS columns should be around 40% now\n100 * (data_france['pnns_groups_1'].notnull().sum() + data_france['pnns_groups_2'].notnull().sum()) \/ (2 * len(data_france))","ee84c021":"display_variables = ['url', 'product_name', 'image_small_url']\ncategory_variables = ['main_category', 'categories', 'categories_tags']\nlabel_variables = ['labels', 'labels_tags']\nnutriscore_variables = ['nutrition-score-fr_100g', 'nutriscore_score', 'nutriscore_grade']\ncalculation_variables = ['energy_100g', 'saturated-fat_100g', 'sugars_100g', 'proteins_100g', 'fat_100g',\n                        'carbohydrates_100g', 'salt_100g', 'sodium_100g', 'energy-kcal_100g', 'fiber_100g']","4aa7c34d":"data_france.loc[:, 'nutriscore_grade'] = data_france['nutriscore_grade'].str.upper()\nnutriscore_data = data_france[nutriscore_variables]\npairplot = sns.pairplot(nutriscore_data, \n             x_vars=[\"nutrition-score-fr_100g\", \"nutriscore_score\"],\n             y_vars=[\"nutrition-score-fr_100g\"],\n             hue='nutriscore_grade', \n             hue_order=['A', 'B', 'C', 'D', 'E'],\n             palette=NUTRIGRADE_COLORS,\n             height=5)\npairplot.fig.suptitle('Nutrition score distribution and correlation to nutriscore_score column', y=1.05, fontsize=18)","b03c60a1":"len(data_france[(data_france['nutriscore_score'].notnull()) & (data_france['nutrition-score-fr_100g'].isnull())])","7f8b2b7b":"categories_data = data_france[category_variables].dropna(how=\"all\")\ncategories_data","0006d811":"split_tags_count = (categories_data['categories_tags'].str.split(',', expand=True).stack().value_counts()).to_frame()\nsplit_tags_count.columns = ['Nb of products']\n\n# A tag could be used twice in a product but we do not consider this case below\nsplit_tags_count['% of products'] = 100 * split_tags_count ['Nb of products'] \/ len(data_france)\nsplit_tags_count","840345aa":"fig, ax = plt.subplots(figsize=(15,8))\nfig.tight_layout(pad=5.0)\n\n# Repartition of keywords by number of uses \nsplit_tags_count['% of products'].plot(kind=\"hist\", ax=ax, color=\"dodgerblue\", logy=True, bins=100)\nax.set_title(\"Repartition of categories tags use (logarithmic scale)\", fontsize=18)\nax.set_xlabel(\"Percentage of use\", fontsize=15)\nax.set_ylabel(\"Number of keywords\", fontsize=15)","c73fe35a":"# Counting the percentage of tags used by less than 0.0002% of the keywords\nonce_percentage = round(100 * len(split_tags_count[split_tags_count['Nb of products'] == 1]) \/ len(split_tags_count),2)\nprint(\"Percentage of tags used only once : \" + str(once_percentage) + \"%\")","20b370f2":"print(\"Number of categories in the main_category column : \" + str(len(data_france['main_category'].unique())))\n\ncategories_count = categories_data['main_category'].value_counts().to_frame()\nonce_percentage = round(100 * len(categories_count[categories_count['main_category'] == 1]) \/ len(categories_count),2)\nprint(\"Percentage of main_categories used only once : \" + str(once_percentage) + \"%\")\n\n# Preparing a pie chart to show how many categories are used more than the given threshold\nUSE_THRESHOLD=3\npie_chart_data = {\n    'Used only once': len(categories_count[categories_count['main_category'] == 1]),\n    'Used less than ' + str(USE_THRESHOLD) + ' times' : len(categories_count[(categories_count['main_category'] > 1) & (categories_count['main_category'] < USE_THRESHOLD)]),\n    'Used more than ' + str(USE_THRESHOLD) + ' times' : len(categories_count[categories_count['main_category'] >= USE_THRESHOLD])\n}\n\nfig = plt.figure(figsize=(8,8))\nplt.suptitle(\"Usable categories for mean values calculations\", fontsize=20, y=0.92)\nplt.pie(pie_chart_data.values(), \n        labels=pie_chart_data.keys(), \n        autopct=\"%.1f%%\", \n        explode=[0.01]*3, \n        colors=[\"firebrick\", \"darkorange\", \"green\"],\n        textprops={'size': 18})","a5e1e22d":"data_france['organic'] = data_france['labels'].str.contains('(?:organic)|(?:bio)', case=False, regex=True)\ntotal_organic_products = len(data_france[data_france['organic'] == True])\ntotal_non_organic_products = len(data_france[data_france['organic'] == False])\ntotal_null_organic_products = len(data_france[data_france['organic'].isnull() == True])\n\nplt.figure(figsize=(8,8))\nplt.pie([total_organic_products, total_non_organic_products, total_null_organic_products],\n        autopct=\"%.2f%%\", \n        labels=[\"Organic\", \"Non organic\", \"N\/A\"], \n        colors=['limegreen', 'orange', 'darkgrey'],\n        explode=[0.02]*3,\n        textprops={'size': 15})","d6fdf4d3":"energy_data = data_france[['energy_100g', 'energy-kcal_100g']].copy()\nenergy_data['ratio'] = energy_data['energy_100g'] \/ energy_data['energy-kcal_100g']\nenergy_data[(energy_data['energy_100g'].notnull()) & (energy_data['energy-kcal_100g'].notnull())]","ca2b1610":"ratio = energy_data[(energy_data['ratio'].notnull()) & (energy_data['ratio'] != np.inf)]['ratio'].mean()\ndata_france.loc[(data_france['energy_100g'].notnull()) & (data_france['energy-kcal_100g'].isnull()), 'energy-kcal_100g'] = data_france['energy_100g'] \/ ratio","d19432ee":"# Plotting salt\/sodium linear relation\nsalt_sodium_data = data_france[(data_france['salt_100g'] <= 100) & (data_france['sodium_100g'] <= 100)].filter(['salt_100g', 'sodium_100g']).dropna(how=\"any\")\n\nfig = plt.figure(figsize=(15,8))\nplt.gca().set_title(\"Linear relation between salt and sodium\", fontsize=20)\nplt.gca().set_xlabel(\"Salt for 100g (g)\", fontsize=16)\nplt.gca().set_ylabel(\"Sodium for 100g (g)\", fontsize=16)\nsns.scatterplot(x=salt_sodium_data['salt_100g'], y=salt_sodium_data['sodium_100g'], color=\"black\")\n\n# Calculating the ratio and merging the column into the salt columns\nsalt_sodium_ratio = data_france['sodium_100g'].mean() \/ data_france['salt_100g'].mean()\ndata_france.loc[(data_france['sodium_100g'].notnull()) & (data_france['salt_100g'].isnull()), 'salt_100g'] = data_france['sodium_100g'] \/ salt_sodium_ratio","0b33d182":"final_columns = ['url',\n                 'product_name',\n                 'image_small_url',\n                 'main_category',\n                 'categories_tags',\n                 'organic',\n                 'nutrition-score-fr_100g',\n                 'saturated-fat_100g',\n                 'sugars_100g',\n                 'proteins_100g',\n                 'fat_100g',\n                 'carbohydrates_100g',\n                 'salt_100g',\n                 'energy-kcal_100g',\n                 'fiber_100g']\ndata_france = data_france.filter(final_columns, axis=1)","5167e3a0":"len(data_france['main_category'].unique())","4537f2cf":"def plot_columns_boxplots(data, columns=[], ncols=2, color=\"dodgerblue\"):\n    if len(columns) == 0:\n        columns = data.columns.values\n        \n    if len(columns) == 1:\n        plt.figure(figsize=(9,3))\n        sns.boxplot(x=data[columns[0]], color=color)\n        \n    else:\n        fig, axs = plt.subplots(figsize=(20,20), ncols=ncols, nrows=math.ceil(len(columns) \/ ncols))\n        for index, column in enumerate(columns):\n            row_index = math.floor(index \/ ncols)\n            col_index = index % ncols\n            sns.boxplot(x=data[column], ax=axs[row_index][col_index], color=color)","fae514b8":"plot_columns_boxplots(data_france, columns=['nutrition-score-fr_100g'])","6123edf5":"# This line is apart to make sure its data doesn't change while re-running the cell below\ndata_before = data_france['energy-kcal_100g'].copy()","c2355f1a":"# Removing values above 900 kcal\ndata_france.loc[data_france['energy-kcal_100g'] > 900, 'energy-kcal_100g'] = np.nan\n\n# Plotting the boxplots before and after the cleaning\nfig, axs = plt.subplots(figsize=(20,4), ncols=2, nrows=1)\nfig.suptitle('Evolution of energy distribution before and after cleaning', fontsize=18, y=1.05)\naxs[0].set_title('Before cleaning', fontsize=15)\naxs[1].set_title('After cleaning', fontsize=15)\nsns.boxplot(x=data_before, ax=axs[0], color=\"firebrick\")\nsns.boxplot(x=data_france['energy-kcal_100g'], ax=axs[1], color=\"green\")","b5f9b839":"# We store the data before cleaning for display and comparison\nnutritional_columns = get_nutritional_columns(data_france)\nnutri_data_before = data_france[nutritional_columns].copy()","2d667a84":"# Creating a new columns containing the total weight of all nutrients\nnutrient_columns = get_nutritional_columns(data_france, exclude_starts=['sugars', 'saturated', 'energy', 'nutrition'])\ndata_france['total_nutrients'] = data_france[nutrient_columns].sum(axis=1)\nnutri_data_before['total_nutrients'] = nutri_data_before[nutrient_columns].sum(axis=1)\n\n# Preparing the plot\nfig, axs = plt.subplots(figsize=(20,4), ncols=2)\nfig.suptitle('Evolution of nutrients total before and after cleaning', fontsize=18)\nfig.tight_layout(pad=1.0)\n\n# Plotting the data before cleaning\naxs[0].set_title(\"Before cleaning\", fontsize=15)\naxs[0].set_xlabel(\"Sum of nutrients weights (g)\", fontsize=13)\nsns.boxplot(x=nutri_data_before['total_nutrients'], color=\"firebrick\", ax=axs[0]) \n\n# Removing the aberrant values (inf to 0 or sup to 100)\ndata_france = data_france[(data_france['total_nutrients'] <= 100) & (data_france['total_nutrients'] >= 0)]\n\n# Plotting the boxplot after cleaning\nsns.boxplot(x=data_france['total_nutrients'], color=\"green\", ax=axs[1]) \naxs[1].set_title(\"After cleaning\", fontsize=15)\naxs[1].set_xlabel(\"Sum of nutrients weights (g)\", fontsize=13)\n\n# Removing the useless column\ndata_france = data_france.drop('total_nutrients', axis=\"columns\")\n\n# Saving the new data length for filter history\napplied_filters['Total nutrients \\n > 100g'] = len(data_france)","15658f60":"# First of all we convert the nutritional \/ nutriscore columns to numeric values\nnutritional_columns = get_nutritional_columns(data_france, exclude_starts=['nutrition', 'energy'])\ndata_france[nutritional_columns] = data_france[nutritional_columns].apply(pd.to_numeric)\n\n# Preparing the plot\nfig, axs = plt.subplots(figsize=(20,4*len(nutritional_columns)), ncols=2, nrows=len(nutritional_columns))\nfig.suptitle('Evolution of nutritional data before and after cleaning', fontsize=18, y=0.95)\nfig.tight_layout(pad=5.0)\n\n# Then we clean them\nfor index, column in enumerate(nutritional_columns):\n    data_france.loc[data_france[column] > 100, column] = np.nan\n    data_france.loc[data_france[column] < 0, column] = np.nan\n    \n    axs[index][0].set_title(column + ' before cleaning', fontsize=15)\n    sns.boxplot(x=nutri_data_before[column], ax=axs[index][0], color=\"firebrick\")\n    \n    axs[index][1].set_title(column + ' after cleaning', fontsize=15)\n    sns.boxplot(x=data_france[column], ax=axs[index][1], color=\"green\") ","bddfef0e":"# We removed the column \"url\" that is 100% filled\nsubset_columns = data_france.columns.values.tolist()\nsubset_columns.remove('url')\ndata_france = data_france.dropna(how=\"all\", subset=subset_columns)\n\n# Saving the new data length for filter history\napplied_filters['Empty lines'] = len(data_france)","637550b7":"data_france = data_france[(data_france['product_name'].notnull()) & (data_france['product_name'].str.contains('^\\s*$') == False)]\n\n# Saving the new data length for filter history\napplied_filters['No product name'] = len(data_france)","1a715fda":"nutritional_columns = get_nutritional_columns(data_france, exclude_starts=['nutrition', 'energy'])\nnutritional_columns_no_fiber = get_nutritional_columns(data_france, exclude_starts=['nutrition', 'energy', 'fiber'])\n\nmissing_nutritional_info = data_france[nutritional_columns].isna().sum(axis=1).to_frame()\nmissing_nutritional_info.columns = ['missing values']\n\nmissing_nutritional_info_no_fiber = data_france[nutritional_columns_no_fiber].isna().sum(axis=1).to_frame()\nmissing_nutritional_info_no_fiber.columns = ['missing values']\n\ncolors = [\"limegreen\", \"forestgreen\", \"olive\", \"orange\", \"orangered\", \"firebrick\", \"firebrick\", \"firebrick\"]\n\nfig, axes = plt.subplots(figsize=(20,6), ncols=2)\nfig.suptitle(\"Repartition of missing nutritional values\", fontsize=18)\nfig.tight_layout(pad=2, w_pad=5)\n\naxes[0].set_title(\"With fibers_100g column\", fontsize=15)\nmissing_nutritional_info.value_counts().sort_index().plot(kind=\"bar\", logy=False, color=colors, ax=axes[0])\n\naxes[1].set_title(\"Without fibers_100g column\", fontsize=15)\nmissing_nutritional_info_no_fiber.value_counts().sort_index().plot(kind=\"bar\", logy=False, color=colors, ax=axes[1])\n\nfor ax in axes:\n    ax.set_xlabel(\"Nb of missing nutritional informations\", fontsize=16)\n    ax.set_ylabel(\"Number of products\", fontsize=16)\n    ax.set_ylim(ymin=100, ymax=600000)\n    \nfor index, value in enumerate(missing_nutritional_info.value_counts().sort_index()):\n    axes[0].set_xticklabels(labels=range(len(missing_nutritional_info.value_counts())), rotation=0)\n    axes[0].text(index-0.2, value, str(round(100*value\/len(data_france),1)) + \"%\", color=colors[index])\n    \nfor index, value in enumerate(missing_nutritional_info_no_fiber.value_counts().sort_index()):\n    axes[1].set_xticklabels(labels=range(len(missing_nutritional_info_no_fiber.value_counts())), rotation=0)\n    axes[1].text(index-0.2, value, str(round(100*value\/len(data_france),1)) + \"%\", color=colors[index])","2fe9d8dd":"data_france['missing_nutritional_values'] = data_france[nutritional_columns_no_fiber].isna().sum(axis=1)\ndata_france = data_france[data_france['missing_nutritional_values'] < 3]\ndata_france = data_france.drop('missing_nutritional_values', axis=\"columns\")\n\n# Saving the new data length for filter history\napplied_filters['Too many \\nmissing info'] = len(data_france)","4e1711d0":"data_france = data_france[(data_france['main_category'].notnull()) | (data_france['categories_tags'].notnull())]\n\n# Saving the new data length for filter history\napplied_filters['No category\/tags'] = len(data_france)","6a712067":"fig = plt.figure(figsize=(18,9))\nfig.suptitle(\"Evolution of dataset size after cleaning operations\", fontsize=20, y=0.93)\nfig.gca().set_ylim(ymin=0, ymax=1900000)\nfig.gca().set_ylabel(\"Dataset size (millions of rows)\", fontsize=16)\nplt.plot(applied_filters.keys(), applied_filters.values(), linewidth=4, color=\"firebrick\", marker=\"o\", markersize=10)\nplt.xticks(fontsize=15)","4a61064b":"exported_data = data_france.copy(deep=True).reset_index().drop('index', axis=\"columns\")\nexported_data.to_csv('.\/off_cleaned_data.csv', sep='\\t')\n\nprint(str(len(exported_data)) + \" lines have been exported successfully.\")","23a1647a":"Our choice is good, and there is no need to merge the 2 columns.","6ba0852f":"## 8. Exporting the cleaned data<a name=\"export\"><\/a>","a66a8866":"### 5.3 Looking for organic label<a name=\"organic_label\"><\/a>\nFor organic labels, we are going to add a boolean column at True if the labels contains \"organic\" or \"bio\" (to match both french and english organic names)","98acab8f":"## 6. Treating atypical and aberrant values<a name=\"aberrant_atypical\"><\/a>","7f5958df":"## 4. Pre-selecting our variables<a name=\"preselection\"><\/a>\nWe use the [variables liste](https:\/\/world.openfoodfacts.org\/data\/data-fields.txt) available on the OFF website.\n\nTo create our application, we would like to have these kinds of variables : \n* The **product name** \n* Various **nutritional information** to create our spider charts\n* The **labels** to find an eventual organic label\n* The **product french nutriscore** to compare products\n* The **product categories** in order to understand which kind of product \n* Eventually a **product image** to make the display more ","79613bc0":"### 6.3 Energy column<a name=\"atypical_energies\"><\/a>\nThe energy in kcal is defined by the composition of the product : \n* 1 gram of carbohydrats = 4 kcal\n* 1 gram of proteins = 4 kcal\n* 1 gram of alcohol = 7 kcal\n* 1 gram of fat = 9 kcal\n\nIt means that the most calorific products are the ones that contains only fat (oil, for example) and would contains 900 kcal for 100g.\nSo we can **clean all the values that are above 900 kcal**.","a3872281":"# DS - P3 - 1\/2 :: Dataset cleaning","b1f2c021":"**Conclusion** : most of the variables are less than 10% filled, so they are very uninteresting for our analysis.\n\nNow let's have a look at the most filled variables of the dataset.\n\n### 4.2 Exploring data filling \/ NaN values","fa4bad36":"What can we notice here ?\n\n* The boxplots for fats\/saturated fats, proteins, and cabohydrates\/sugars contains manu outliers but it's not surprising, because there exists many highly-sweet, highly-fat and higly-proteined products.\n* The boxplots for salt is strange, because higly-salted product (more than 40% of salt) are mainly salt-based or bouillon products, and they are not as common as the boxplot can let us think. \n* Same thing for fiber boxplot : higly-fibered products (more than 40%) are very unusual so they shouldn't be that abundant.\n\n**Conclusion** : for the moment, we let all this atypical values in the dataset and we will decide what we do about it later.","01919cb2":"**80-100% filled columns** : \n* all the variables that are 100% filled are mostly technicial variables of OpenFoodFacts (product code, datetimes, editors, ...)\n* the **pnns** variables contains food categories created by the french government but it seems strange that they are as much filled. We are going to check it.\n* we have, as we wanted to, a **product name**, an **url** and an **image_url** (which is as filled as the **image_small_url** that we can use to lightened the application results load.\n\n**60-80% filled columns** : \n* the product ingredient image url, which are not useful for our application\n* many nutritional information that can be used to display our nutritional spider charts\n\nBut the question is : **do all the nutritional informations are present here** ? We can notice that they all ends with \"**_100g**\" so let's find all variables with this pattern that are not present in the list above.\n\n**30-60% filled columns** : \n* there are a **main_category**, a **categories** and a **categories_tags** variables that can be really helpful if the *pnns* variables are not filled enough\n* we find again the **nutrition-score-fr_100g** we met before, along with a **nutriscore_score** and a **nutriscore_grade** that should be linked\n* the **labels** in order to find out, for example, some organic products\n* somes variables can inform us about the presence of **ingredients from palm oil** that we could use to discriminate 2 products (find out which one is more healthy)\n\n**16-30% filled columns** :\n\nEven if these columns are not filled enough, one of them is interesting and could be helpful for the rest of our analysis : \n* the **fiber_100** that we will include in our spider chart only if it is provided\n\nNow let's check the values inside the pnns columns.","a6a83782":"The use of each keyword is very various, between 12% and 0.0001%. We now would like to know how they are distributed","c7029ae5":"### 4.1 Exploring the percentages of missing values for each column\nLet's calculate the percentage of filled values for every variable of the dataset.","62a8fe84":"There is not atypical values for the nutrition score, they are all between -15 and 40 which is the normal definition of it.","6a875f69":"### 6.2 French nutrition score column<a name=\"atypical_nutriscores\"><\/a>","6fb3402b":"### 5.4 Comparing energy columns<a name=\"energy-columns\"><\/a>\nIn this part we are going to compare the two energy columns : one in kilo-Joule (kJ) and one in kilo-calorie (kcal).\n\nThe definition of the kcal is : **1 kcal = 4.184 kJ** so let's see if we can find this ratio between our columns :","5776fe5a":"These 2 columns seem to be linked by **a fixed ratio around 4.18** as expected.\n\nWe are going to merge them into the *energy-kcal_100g* column using the mean ratio of the entire set, then we'll keep only this column.","9d0898d3":"## 2. Notebook initialisation and data loading<a name=\"init\"><\/a>","e378efed":"### 5.7 Comparing salt and sodium columns<a name=\"salt_sodium\"><\/a>\nWe kept both **sodium and salt** columns, but normally only one should be useful, because the sodium in a product is brought by the salt (salt contains 40% of sodium).\n\nWe are going to check that by plotting the sodium quantity as a function of the salt quantity, and then merging the 2 columns by keeping the average ratio between them.","2e21c7e2":"#### Removing products where sum of nutrients is too high\n\nWe can impute missing nutritional values. But when the sum of all nutritional values is aberrant, we cannot determine which column contains a bad value. That why I decided to remove all columns where the sum of all nutrients is greater than 100g.\n\nIn that purpose, we don't use \"saturated fats\" (which are already included in the fats) and \"sugars\" (which are alreadu included in the carbohydrates).","76327641":"## 3. Keeping french products only<a name=\"french\"><\/a>\nThe goal of our application is to suggest similar products. Moreover we want to use the french nutriscore as much as possible. That's why we decide here to **keep only the french products** for our study.\n\nTo achieve that, let's we have a look to the **countries** column and we can notice that each country can be present on at least 2 different forms that are case insensitive : \n* The country name itself : \"France\" or \"france\"\n* The country code (\"fr\" for France) following another country name\/code (separated by a colon) : \"en:fr\" for example.\n\nSo we use regular expressions to isolate these 2 cases and filter our countries to keep french products only.","d954bfb5":"These charts give us many informations.\n* The **nutriscore_score and and nutrition-score-fr_100g are the same**. We notice a perfect straight line between both, with a 45\u00b0 angle and a 0 origin value. It means that our 2 columns have the same values.\n\n\n* We also notice the different colors on these straight lines that **confirm the french nutriscore grade slices** : \n * **Grade A** : from -15 to -1\n * **Grade B** : from 0 to 2\n * **Grace C** : from 3 to 10\n * **Grade D** : from 11 to 18\n * **Grade E** : from 19 to 40\n \n \n* The 2 histograms shows the **nutriscore_grade errors** : the different colors should be perfectly separated according to the slices above, but we can see that they are not.\n\n\n**CONCLUSION** : we can keep only one of these 3 columns, and **we will keep the nutrition-score-fr_100g** as it a little more filled. We will reassign a nutriscore-grade using the official nutriscore slices.\n\nBut before removing the *nutriscore_score* columns, let's check if they are some products for which this column is filled and not the *nutrition-score-fr_100g* : ","ea6a7020":"## 7. Treating missing values<a name=\"missing_values\"><\/a>\n### 7.1 Removing completely empty lines<a name=\"missing_empty_lines\"><\/a>","25f5ed6f":"We notice here a **very important thing** : as the *fiber_100g* column is very poorly filled (around 83% of NaN) it introduces at least one missing nutritional value in 83% of the product. We can see that without the fiber column, **75% of the product have all their nutritional informations completed**.\n\nThat's why **we keep the fibers column** for our application (it will allow us to display it for product posessing it) but **we will ignore it in the exploratory analysis** (second notebook).\n\nOn the other hand, we can **remove all the products with 3 missing nutritional values or more** (without the fiber) because we already know we won't be able to impute them all without introducing a bias.","0898032f":"#### Validating the PNNS columns","be984025":"### 7.2 Removing products with no product name <a name=\"empty_product_names\"><\/a>\nThese columns cannot contains aberrant values because they are only used for display, but they can contain missing values. \nFor URL and image URL it's not a problem, but **we do want to have a product name** for our application.\nThat's why I decide to **remove all the product that don't have a product name (NaN or empty string)**","aaa6ab14":"#### Studying main_category values","254b30f4":"### 5.2 Selecting one or many category column<a name=\"categories\"><\/a>\nWe pre-selected many category columns, now we would like to explore them and see if one of them seems better than the others.\n\nFirst of let's compare their filling percentages : we notice that the **categories** are all filled ad approximately 45% which is pretty good. \n\nNow let's have a look at what's inside these columns : ","5a1066ba":"### 5.1 Comparing nutritional score indicators<a name=\"nutriscores\"><\/a>","becf6cd8":"### 6.4 Nutritional columns<a name=\"atypical_nutritional\"><\/a>\nWe call here \"nutritional columns\" all the columns containing a nutritional information for 100g of product, including the french nutriscore.","943db4e0":"#### Studying categories_tags values","75667420":"## 5. Analysing our pre-selected variables<a name=\"preselection-analysis\"><\/a>\nIn this part, we will try to answer these questions :\n* **Are all the 3 \"nutriscore\" columns essential** or can we reduce them to keep only one of them ?\n* Same question for the categories and labels ?\n* Can we **determine the percentage of fibers by using the other columns** ?","535a2195":"## Table of content\n\n1. **[Application idea](#app_idea)**\n2. **[Initialization and data loading](#init)**\n3. **[Filtering on french products](#french)**\n4. **[Pre-selecting variables](#preselection)**\n5. **[Analysing the pre-selected variables](#preselection-analysis)**\n    1. [Nutritional scores](#nutriscores)\n    2. [Categories and tags columns](#categories)\n    3. [Organic label](#organic_label)\n    4. [Energy columns](#energy-columns)\n    5. [Salt and sodium columns](#salt_sodium)\n6. **[Treating aberrant and atypical values](#aberrant_atypical)**\n    1. [Nutritional scores](#atypical_nutriscores)\n    2. [Energy column](#atypical_energies)\n    3. [Nutritional columns](#atypical_nutritional)\n7. **[Treating missing values](#missing_values)**\n    1. [Removing empty lines](#missing_empty_lines)\n    2. [Removing product with no name](#empty_product_names)\n    3. [Nutritional columns](#empty_nutritional)\n    4. [Other columns](#missing_others)\n8. **[Exporting data](#export)**","36c52105":"### 6.1 Filtering data columns\nFirst of all, now we have selected our final columns, we can filter the dataframe :","214aaeae":"So **53% of the tags are used only by one product**. We keep them anyway because we have no interest in replacing them by NaN.","721a392b":"We notice that the \"**unknown**\" keyword it used 80% of the time. So, in fact, the PNNS variables are 80% empty, so we are going to replace the \"unknown\" values by NaN values for the rest of the analysis.","bb4b6e10":"### 7.6 Summary of data cleaning\nHere is a plot summarizing all the cleaning process we went through on this file : \n","813f8af2":"This time again, most of the categories are used only by one product in our dataset.\n\nWe keep them anyway but we have to keep that in mind for the treatment of missing values using main category means.","17c5199f":"#### Removing aberrant values per column\nIn this part, we are going to boxplot all nutritional columns, before and after removing the aberrant values (we set them to NaN).\n\nWe consider as aberrant a value lower than 0g or higher than 100g.","fa6ba4fb":"### 4.3 Final list of the pre-selected variables","c74165d2":"### 7.4 Removing product with neither a category nor tags <a name=\"missing_categories\"><\/a>\nBecause we are going to use it to pre-select the similar products to improve calculation time.","eef5ff6a":"### 7.5 Filling other missing values <a name=\"missing_others\"><\/a>\nThere are still 2 process to fill missing values, but we will apply them **after the exploratory analysis of the second notebook** in order to no \n* Filling missing nutritional values using the mean values of products with the same main category\n* Filling missing nutriscore\/nutrigrade using a k-NN model","9811608f":"### 7.3 Removing product with too many missing nutritional data <a name=\"empty_nutritional\"><\/a>\nThe nutritional data are essential to our application idea because : \n* we will use it to **calculate the missing nutrition scores** using a KNN algorithm.\n* we will **display them in a spider chart** to easily compare the selected similar products.\n\nBut we don't have to remove any line having one missing nutritional information because we can impute them using linear regression between columns.\n\nThe idea here is to check how many missing nutritional values we have over the 7 selected ones and choose which rows to remove.","609e3ffa":"## 1. Application idea <a name=\"app_idea\"><\/a>\nThe idea here is to create an app that, from a given product, will : \n* Suggest similar products but organic (if it's possible) or with a better nutriscore.\n* Display all the products nutritional information using spider charts (more complete than just the score)."}}