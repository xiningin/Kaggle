{"cell_type":{"fe1ca8d4":"code","90035c47":"code","6a481956":"code","4d1f63e3":"code","722c35a6":"code","f53b9297":"code","b797886e":"code","75c12b93":"code","61ff9034":"code","44a248d0":"code","9e5d8dae":"code","ab37abca":"code","6021539f":"code","6e1a3d7a":"code","42360e25":"code","dd059aa9":"code","13832398":"code","f2a53f0f":"code","de442183":"code","803334e5":"code","157603d9":"code","24bebc8e":"markdown","a8eba6c6":"markdown","08807bf6":"markdown","a98e1437":"markdown"},"source":{"fe1ca8d4":"import numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.layers as tfl\nfrom tensorflow.data import Dataset as ds\nfrom keras.layers import LeakyReLU\n\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.cluster import KMeans\n\nfrom PIL import Image\nimport os\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nnp.random.seed(0)\ntf.random.set_seed(0)","90035c47":"strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","6a481956":"train = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/train.csv')\ntrain['path'] = '\/kaggle\/input\/petfinder-pawpularity-score\/train\/' + train['Id'] + '.jpg'\ntrain.head(3)","4d1f63e3":"test = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/test.csv')\ntest['path'] = '\/kaggle\/input\/petfinder-pawpularity-score\/test\/' + test['Id'] + '.jpg'","722c35a6":"def size_and_shape(row):\n    img = Image.open(row['path'])\n    return pd.Series([img.size[0], img.size[1], os.path.getsize(row['path'])])","f53b9297":"scale = MinMaxScaler()\n\ntrain[['width', 'height', 'size']] = pd.DataFrame(scale.fit_transform(train.apply(size_and_shape, axis=1).values))\ntest[['width', 'height', 'size']] = pd.DataFrame(scale.transform(test.apply(size_and_shape, axis=1).values))","b797886e":"k = KMeans(8, random_state=0)\n\ntrain['cluster'] = k.fit_predict(train.drop(['Id', 'Pawpularity', 'path'], axis=1))\ntest['cluster'] = k.predict(test.drop(['Id', 'path'], axis=1))","75c12b93":"p = PCA(random_state=0)\n\ntrain = train.join(pd.DataFrame(p.fit_transform(train.drop(['Id', 'Pawpularity', 'path'], axis=1))))\ntest = test.join(pd.DataFrame(p.transform(test.drop(['Id', 'path'], axis=1))))","61ff9034":"train, val= train_test_split(train, test_size=0.2, random_state=0)","44a248d0":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nIMG_SIZE = 299\nBATCH_SIZE = 64","9e5d8dae":"train = train[['Pawpularity']].join(train.drop('Pawpularity', axis=1))\nval = val[['Pawpularity']].join(val.drop('Pawpularity', axis=1))","ab37abca":"def process_data(path, meta, augment=False, label=True):\n    img = tf.io.decode_jpeg(tf.io.read_file(path), channels=3)\n    img = tf.cast(img, dtype=tf.float32)\n    img = tf.image.central_crop(img, 1.0)\n    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n#     img = keras.applications.efficientnet.preprocess_input(img)\n    img = keras.applications.inception_resnet_v2.preprocess_input(img)\n    img = tf.cast(img, dtype=tf.float64)\n    \n    if augment:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_brightness(img, 0.1)\n        img = tf.image.random_saturation(img, 0.9, 1.1)\n        img = tf.image.random_contrast(img, 0.9, 1.1)\n        \n    if label:\n        return (img, meta[1:]), meta[0]\n\n    return (img, meta), 0","6021539f":"# train_ds = tf.data.Dataset.from_tensor_slices((train['path'], train.drop(['path', 'Id'], axis=1).astype(float))).map(lambda x,y: process_data(x, y, True)).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n# val_ds = tf.data.Dataset.from_tensor_slices((val['path'], val.drop(['path', 'Id'], axis=1).astype(float))).map(process_data).batch(BATCH_SIZE).prefetch(AUTOTUNE)\ntest_ds = ds.from_tensor_slices((test['path'], test.drop(['path', 'Id'], axis=1).astype(float))).map(lambda x,y: process_data(x, y, False, False)).batch(BATCH_SIZE).prefetch(AUTOTUNE)","6e1a3d7a":"# eff_model = keras.models.load_model('\/kaggle\/input\/keras-applications-models\/EfficientNetB7.h5')\neff_model = keras.models.load_model('..\/input\/keras-applications-models\/InceptionResNetV2.h5')\neff_model.trainable = False\n\ndef get_model():\n    img_input = tfl.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    meta_input = tfl.Input(shape=(32,))\n    X = eff_model(img_input)\n    X = tfl.BatchNormalization()(X)\n    con = tfl.concatenate([X, meta_input])\n    X = tfl.Dense(64, activation='relu')(con)\n    X = tfl.Dense(64, activation='relu')(X)\n    X = tfl.Dropout(0.3)(X)\n    out = tfl.Dense(1)(X)\n    model = keras.Model(inputs=[img_input, meta_input], outputs=out)\n    \n    return model","42360e25":"model = get_model()","dd059aa9":"tf.keras.utils.plot_model(model, show_shapes=True)","13832398":"k = 5\nfold = KFold(k,shuffle=True)","f2a53f0f":"models = []\nhistories = []\n\ndef rmse(y_true, y_pred):\n    return tf.sqrt(tf.reduce_mean((y_true -  y_pred) ** 2))\n\nfor i, (t_ids, v_ids) in enumerate(fold.split(train)):\n    \n    keras.backend.clear_session()\n\n    print(\"\\n\\n===========================================================================================\\n\")\n    train_ds = ds.from_tensor_slices((train.iloc[t_ids]['path'], train.iloc[t_ids].drop(['path', 'Id'], axis=1).astype(float))).map(lambda x,y: process_data(x, y, True)).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    \n    val_ds = ds.from_tensor_slices((train.iloc[v_ids]['path'], train.iloc[v_ids].drop(['path', 'Id'], axis=1).astype(float))).map(process_data).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    \n    model = get_model()\n    \n    checkpoint_path = \"model_%d.h5\"%(i)\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        checkpoint_path, \n        save_best_only=True\n    )\n    \n    early_stop = keras.callbacks.EarlyStopping(\n        patience=3,\n        verbose=1,\n        restore_best_weights=True)\n    \n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n        factor=0.1,\n        verbose=1,\n        patience=2,\n        min_lr=1e-7\n    )\n    \n#     callbacks = [checkpoint, early_stop, reduce_lr]\n#     callbacks = [checkpoint, early_stop]\n\n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=1e-3,\n        decay_steps=1000,\n        decay_rate=0.9,\n        staircase=True)\n    \n    model.compile(keras.optimizers.Adam(\n        learning_rate=lr_schedule), \n        loss='mse', \n        metrics=[keras.metrics.RootMeanSquaredError()])\n\n    history = model.fit(train_ds,\n                        validation_data=val_ds,\n                        epochs=20,\n                        callbacks=[early_stop])\n\n    models.append(model)\n    histories.append(history)","de442183":"# preds = model.predict(test_ds)\npreds = models[0].predict(test_ds)\/k\n\nfor i in range(1,k):\n    preds += models[i].predict(test_ds)\/k","803334e5":"preds","157603d9":"test['Pawpularity'] = preds\ntest[['Id', 'Pawpularity']].to_csv('submission.csv', index=False)","24bebc8e":"# Feature Engineering","a8eba6c6":"# Build the model","08807bf6":"# Read data","a98e1437":"# Import libraries"}}