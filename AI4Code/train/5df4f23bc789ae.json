{"cell_type":{"26a548a7":"code","948ca631":"code","39cda454":"code","1b2e553b":"code","0b5d8030":"code","83bf33c1":"code","3871f876":"code","7d1fded0":"code","94f27de1":"code","fb00ecd4":"code","6863143d":"markdown","455aa54e":"markdown","812f7cf9":"markdown","7e77d02d":"markdown","944c8414":"markdown","278b5d3d":"markdown","f233071f":"markdown","bd5657ed":"markdown","e64050d8":"markdown","9517727e":"markdown"},"source":{"26a548a7":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport time\nimport tensorflow as tf\n\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Reshape, Conv2DTranspose, LeakyReLU\nfrom keras.utils.np_utils import to_categorical   \n\n# Main TFGAN library.\ntfgan = tf.contrib.gan\n\ntf.set_random_seed(0)\ntf.reset_default_graph()","948ca631":"#Define Generator \ndef basic_generator(noise):\n    \"\"\"Simple generator to produce MNIST images.\n\n    Args:\n        noise: A single Tensor representing noise.\n\n    Returns:\n        A generated image in the range [-1, 1].\n    \"\"\"\n    channels_after_reshape = 256\n\n    net = Dense(1024, activation='elu')(noise)\n    net = Dense(7 * 7 * channels_after_reshape, activation='elu')(net)\n    net = Reshape([7, 7, channels_after_reshape])(net)\n    net = Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\", activation='elu')(net)\n    net = Conv2DTranspose(32, kernel_size=4, strides=2, padding=\"same\", activation='elu')(net)\n    # Make sure that generator output is in the same range as `inputs`\n    # ie [-1, 1].\n    net = Conv2D(1, kernel_size=4, activation = 'tanh', padding='same')(net)\n    return net\n\n\n\n#Define Discriminator \ndef basic_discriminator(img, unused_conditioning):\n    leaky = LeakyReLU(0.2)\n    \"\"\"Discriminator network on MNIST digits.\n\n    Args:\n        img: Real or generated image. Should be in the range [-1, 1].\n        unused_conditioning: The TFGAN API can help with conditional GANs, which\n            would require extra `condition` information to both the generator and the\n            discriminator. Since this example is not conditional, we do not use this\n            argument.\n\n    Returns:\n        Logits for the probability that the image is real.\n    \"\"\"\n    net = Conv2D(64, kernel_size=4, strides=2)(img)\n    net = leaky(net)\n    net = Conv2D(64, kernel_size=4, strides=2)(net)\n    net = leaky(net)\n    net = Conv2D(64, kernel_size=4)(net)\n    net = leaky(net)\n\n    net = Flatten()(net)\n    net = Dense(1024)(net)\n    net = leaky(net)\n    net = Dense(1, activation='linear')(net)\n    return net\n ","39cda454":"def visualize_training_generator(train_step_num, start_time, plottables, undo_normalization=False):\n    \"\"\"Visualize generator outputs during training.\n\n    Args:\n        train_step_num: The training step number. A python integer.\n        start_time: Time when training started. The output of `time.time()`. A\n            python float.\n        plottables: Data to plot. Numpy array or list of numpy arrays,\n            usually from an evaluated TensorFlow tensor.\n    \"\"\"\n    print('Training step: %i' % train_step_num)\n    time_since_start = (time.time() - start_time) \/ 60.0\n    print('Time since start: %f m' % time_since_start)\n    print('Steps per min: %f' % (train_step_num \/ time_since_start))\n    if type(plottables) == list:\n        plottables = np.dstack(plottables)\n    plottables = np.squeeze(plottables)\n    if undo_normalization:\n        plottables = ((plottables * 128) + 128).astype(np.uint8)\n\n    plt.figure(figsize=(10,10))\n    plt.axis('off')\n    plt.imshow(plottables)\n    plt.show()\n\n\ndef visualize_digits(tensor_to_visualize):\n    \"\"\"Visualize an image once. Used to visualize generator before training.\n    \n    Args:\n        tensor_to_visualize: An image tensor to visualize. A python Tensor.\n    \"\"\"\n    queues = tf.contrib.slim.queues\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        with queues.QueueRunners(sess):\n            images_np = sess.run(tensor_to_visualize)\n    plt.axis('off')\n    plt.imshow(np.squeeze(images_np))\n","1b2e553b":"train_fname = '..\/input\/fashionmnist\/fashion-mnist_train.csv'\n# Size of each image\nimg_rows, img_cols, depth = 28, 28, 3\n\n#10 labels\nnum_classes = 10\n\nbatch_size = 32\n\nraw = pd.read_csv(train_fname)\nnum_images = raw.shape[0]\nx_as_array = raw.values[:,1:]\n# Reshape from 1 vector into an image. Last dimension shows it is greyscale, which is 1 channel\nx_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)\n# Optimization with default params is better when vals scaled to [-1, 1]\nimage_array = ((x_shaped_array - 128)\/ 128).astype(np.float32)\n# set up target\nlabels_array = to_categorical(raw.values[:,0], num_classes=10)\n\n# following lines create the iterator\/stream of tensors consumed in model training\ndef dataset_to_stream(inp, batch_size):\n    with tf.device('\/cpu:0'):\n        batched = inp.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\n        data_feeder = batched.repeat().make_one_shot_iterator().get_next()\n    return data_feeder\n\nmy_dataset = tf.data.Dataset.from_tensor_slices((image_array))\nbatched_dataset = dataset_to_stream(my_dataset, batch_size)\n\n\n# Sanity check that we're getting images.\ncheck_real_digits = tfgan.eval.image_reshaper(\n    dataset_to_stream(my_dataset, 20), num_cols=10)\nvisualize_digits(check_real_digits)","0b5d8030":"batched_dataset.shape","83bf33c1":"noise_dims = 120\ngan_model = tfgan.gan_model(\n    basic_generator,\n    basic_discriminator,\n    real_data=batched_dataset,\n    generator_inputs=tf.random_normal([batch_size, noise_dims]))","3871f876":"# Example of classical loss function.\n#vanilla_gan_loss = tfgan.gan_loss(\n#    gan_model,\n#    generator_loss_fn=tfgan.losses.minimax_generator_loss,\n#    discriminator_loss_fn=tfgan.losses.minimax_discriminator_loss)\n\n# Wasserstein loss (https:\/\/arxiv.org\/abs\/1701.07875) with the \n# gradient penalty from the improved Wasserstein loss paper \n# (https:\/\/arxiv.org\/abs\/1704.00028).\nimproved_wgan_loss = tfgan.gan_loss(\n    gan_model,\n    generator_loss_fn=tfgan.losses.wasserstein_generator_loss,\n    discriminator_loss_fn=tfgan.losses.wasserstein_discriminator_loss,\n    gradient_penalty_weight=1.0)","7d1fded0":"generator_optimizer = tf.train.AdamOptimizer(0.0002, beta1=0.5)\ndiscriminator_optimizer = tf.train.AdamOptimizer(0.0001, beta1=0.5)\ngan_train_ops = tfgan.gan_train_ops(\n    gan_model,\n    improved_wgan_loss,\n    generator_optimizer,\n    discriminator_optimizer)","94f27de1":"images_to_eval = 10\n\n# For variables to load, use the same variable scope as in the train job.\nwith tf.variable_scope('Generator', reuse=True):\n    eval_images = gan_model.generator_fn(tf.random_normal([images_to_eval, noise_dims]))\n\n# Reshape eval images for viewing.\ngenerated_data_to_visualize = tfgan.eval.image_reshaper(eval_images[:images_to_eval,...], num_cols=10)","fb00ecd4":"\ntrain_step_fn = tfgan.get_sequential_train_steps()\n\nglobal_step = tf.train.get_or_create_global_step()\n\nn_batches = 30001\nwith tf.train.SingularMonitoredSession() as sess:\n    start_time = time.time()\n    for i in range(n_batches):\n        train_step_fn(sess, gan_train_ops, global_step, train_step_kwargs={})\n        if i % 3000 == 0:\n            digits_np = sess.run([generated_data_to_visualize])\n            visualize_training_generator(i, start_time, digits_np)","6863143d":"# Model\nDefine the GANModel tuple using the TFGAN library function. For the simplest case, we need the following:\n\n- A generator function that takes input noise and outputs generated images\n- A discriminator function that takes images and outputs a probability of being real or fake\n- Real images\n- A noise vector to pass to the generator","455aa54e":"# Set Up Progress Tracking\n\nThis helps us see the evolution in image quality as the GAN is being trained. Specifically, the code below takes a sample of images and shapes them into something that can be viewed.","812f7cf9":"## Function to visualise image ","7e77d02d":"# Imports","944c8414":"### Optimizer Settings\n\nThe choice of optimizer and settings has been the subject of a lot of guesswork and iteration. When getting started, it's likely not a good use of time to fiddle with these. This also may be ","278b5d3d":"## Generator and Discriminator functions","f233071f":"# GAN MODEL \n\nThanks to Dan. The basic structure and functions of this notebook is taken from [Dans' notebok](http:\/\/https:\/\/www.kaggle.com\/dansbecker\/running-your-first-gan) and the [TFGAN git repository](http:\/\/https:\/\/github.com\/tensorflow\/tensorflow\/tree\/master\/tensorflow\/contrib\/gan)\n\nThe notebook is still under progress. I will update(scoring, losses, etc) and explain in more detail in some time. As of now you can still fork and play around by changing things. ","bd5657ed":"# Train Steps\n for-loop for clarity","e64050d8":"# Data Input Pipeline","9517727e":"# Losses and Optimization\nWe next set up the GAN model losses.\n\nLoss functions are an active area of research. The losses library provides some well-known or successful loss functions, such as the original minimax, Wasserstein, and improved Wasserstein losses."}}