{"cell_type":{"4db68ada":"code","cb606d13":"code","f0d94d14":"code","2a145280":"code","6e9df7f9":"code","888b3847":"code","3ce89d8c":"code","19559848":"code","e99e283e":"code","ff6e54fb":"code","4d2cfd93":"code","fad857ac":"code","8ab2b992":"code","509a0b3e":"code","8daa8f18":"code","f0e21f6c":"code","69c123ee":"code","e02d3cfa":"code","18dd2a6d":"code","4aa0758e":"code","f633249c":"code","7bf3f774":"code","c42cd94f":"code","9f98f09e":"code","a55497f0":"code","3be23e6a":"code","2cf3031d":"code","2b40ddec":"code","94e66fca":"code","55a7bfba":"code","a77899aa":"code","364a1b30":"markdown","d8aa8706":"markdown","9ded3fa0":"markdown","7c73756e":"markdown","322cb9c0":"markdown","b6df0a8d":"markdown","9ab869bc":"markdown","2727ba26":"markdown","6412981e":"markdown","eeff6bfc":"markdown","2d9b5422":"markdown","826d3672":"markdown","3d2c2c28":"markdown"},"source":{"4db68ada":"import os\nimport json\nimport gc\n\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\n# from tf.keras.callbacks import Callback, ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint","cb606d13":"train_df = pd.read_csv('..\/input\/severstal-steel-defect-detection\/train.csv')\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntrain_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n\nprint(train_df.shape)\ntrain_df.head()","f0d94d14":"mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\nmask_count_df.sort_values('hasMask', ascending=False, inplace=True)\nprint(mask_count_df.shape)\nmask_count_df.head()","2a145280":"sub_df = pd.read_csv('..\/input\/severstal-steel-defect-detection\/sample_submission.csv')\nsub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntest_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])\ntest_imgs.head()","6e9df7f9":"non_missing_train_idx = mask_count_df[mask_count_df['hasMask'] > 0]\nnon_missing_train_idx.head()","888b3847":"def load_img(code, base, resize=True):\n    path = f'{base}\/{code}'\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    if resize:\n        img = cv2.resize(img, (256, 256))\n    \n    return img\n\ndef validate_path(path):\n    if not os.path.exists(path):\n        os.makedirs(path)","3ce89d8c":"BATCH_SIZE = 64\ndef create_test_gen():\n    return ImageDataGenerator(rescale=1\/255.).flow_from_dataframe(\n        test_imgs,\n        directory='..\/input\/severstal-steel-defect-detection\/test_images',\n        x_col='ImageId',\n        class_mode=None,\n        target_size=(256, 256),\n        batch_size=BATCH_SIZE,\n        shuffle=False\n    )\n\ntest_gen = create_test_gen()","19559848":"remove_model = load_model('..\/input\/severstal-predict-missing-masks\/model.h5')\nremove_model.summary()","e99e283e":"test_missing_pred = remove_model.predict_generator(\n    test_gen,\n    steps=len(test_gen),\n    verbose=1\n)\n\ntest_imgs['allMissing'] = test_missing_pred\ntest_imgs.head()","ff6e54fb":"filtered_test_imgs = test_imgs[test_imgs['allMissing'] < 0.5]\nprint(filtered_test_imgs.shape)\nfiltered_test_imgs.head()","4d2cfd93":"filtered_mask = sub_df['ImageId'].isin(filtered_test_imgs[\"ImageId\"].values)\nfiltered_sub_df = sub_df[filtered_mask].copy()\nnull_sub_df = sub_df[~filtered_mask].copy()\nnull_sub_df['EncodedPixels'] = null_sub_df['EncodedPixels'].apply(\n    lambda x: ' ')\n\nfiltered_sub_df.reset_index(drop=True, inplace=True)\nfiltered_test_imgs.reset_index(drop=True, inplace=True)\n\nprint(filtered_sub_df.shape)\nprint(null_sub_df.shape)\n\nfiltered_sub_df.head()","fad857ac":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return mask.reshape(height, width).T\n\ndef build_masks(rles, input_shape):\n    depth = len(rles)\n    masks = np.zeros((*input_shape, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, input_shape)\n    \n    return masks\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","8ab2b992":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='..\/input\/severstal-steel-defect-detection\/train_images',\n                 batch_size=32, dim=(256, 1600), n_channels=1,\n                 n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}\/{im_name}\"\n            img = self.__load_grayscale(img_path)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) \/ 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) \/ 255.\n\n        return img","509a0b3e":"BATCH_SIZE = 16\n\ntrain_idx, val_idx = train_test_split(\n    non_missing_train_idx.index,  # NOTICE DIFFERENCE\n    random_state=2019, \n    test_size=0.15\n)\n\ntrain_generator = DataGenerator(\n    train_idx, \n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)\n\nval_generator = DataGenerator(\n    val_idx, \n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)","8daa8f18":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","f0e21f6c":"# def build_model(input_shape):\n#     inputs = Input(input_shape)\n\n#     c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\n#     c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n#     p1 = MaxPooling2D((2, 2)) (c1)\n\n#     c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n#     c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n#     p2 = MaxPooling2D((2, 2)) (c2)\n\n#     c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n#     c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n#     p3 = MaxPooling2D((2, 2)) (c3)\n\n#     c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n#     c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n#     p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n#     c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (p4)\n#     c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)\n#     p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n\n#     c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (p5)\n#     c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (c55)\n\n#     u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n#     u6 = concatenate([u6, c5])\n#     c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n#     c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\n#     u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n#     u71 = concatenate([u71, c4])\n#     c71 = Conv2D(32, (3, 3), activation='relu', padding='same') (u71)\n#     c61 = Conv2D(32, (3, 3), activation='relu', padding='same') (c71)\n\n#     u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n#     u7 = concatenate([u7, c3])\n#     c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n#     c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\n#     u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n#     u8 = concatenate([u8, c2])\n#     c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n#     c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\n#     u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n#     u9 = concatenate([u9, c1], axis=3)\n#     c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n#     c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\n#     outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\n#     model = Model(inputs=[inputs], outputs=[outputs])\n#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n    \n#     return model","69c123ee":"def conv_block(inputs, conv_type, kernel, kernel_size, strides, padding='same', relu=True):\n    if(conv_type == 'ds'):\n        x = tf.keras.layers.SeparableConv2D(kernel, kernel_size, padding=padding, strides = strides)(inputs)\n    else:\n        x = tf.keras.layers.Conv2D(kernel, kernel_size, padding=padding, strides = strides)(inputs)  \n  \n    x = tf.keras.layers.BatchNormalization()(x)\n  \n    if (relu):\n        x = tf.keras.activations.relu(x)\n  \n    return x\n\n# Input Layer\nnum_classes=4\ninput_layer = tf.keras.layers.Input(shape=(256, 1600, 1), name = 'input_layer')\n\nlds_layer = conv_block(input_layer, 'conv', 32, (3, 3), strides = (2, 2))\nlds_layer = conv_block(lds_layer, 'ds', 48, (3, 3), strides = (2, 2))\nlds_layer = conv_block(lds_layer, 'ds', 64, (3, 3), strides = (2, 2))\n\ndef _res_bottleneck(inputs, filters, kernel, t, s, r=False):\n    \n    \n    tchannel = tf.keras.backend.int_shape(inputs)[-1] * t\n\n    x = conv_block(inputs, 'conv', tchannel, (1, 1), strides=(1, 1))\n\n    x = tf.keras.layers.DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.activations.relu(x)\n\n    x = conv_block(x, 'conv', filters, (1, 1), strides=(1, 1), padding='same', relu=False)\n\n    if r:\n        x = tf.keras.layers.add([x, inputs])\n    return x\n\ndef bottleneck_block(inputs, filters, kernel, t, strides, n):\n    x = _res_bottleneck(inputs, filters, kernel, t, strides)\n  \n    for i in range(1, n):\n        x = _res_bottleneck(x, filters, kernel, t, 1, True)\n\n    return x\n\ndef pyramid_pooling_block(input_tensor, bin_sizes):\n    concat_list = [input_tensor]\n    w = 8\n    h = 50\n\n    for bin_size in bin_sizes:\n        x = tf.keras.layers.AveragePooling2D()(input_tensor)\n        x = tf.keras.layers.Conv2D(128, 3, 2, padding='same')(input_tensor)\n        x = tf.keras.layers.Lambda(lambda x: tf.image.resize(x, (w,h)))(x)\n#         print(x.shape)\n\n        concat_list.append(x)\n    print(\"abccc:\",concat_list)\n\n    return tf.keras.layers.concatenate(concat_list)\n\ngfe_layer = bottleneck_block(lds_layer, 64, (3, 3), t=6, strides=2, n=3)\ngfe_layer = bottleneck_block(gfe_layer, 96, (3, 3), t=6, strides=2, n=3)\ngfe_layer = bottleneck_block(gfe_layer, 128, (3, 3), t=6, strides=1, n=3)\ngfe_layer = pyramid_pooling_block(gfe_layer, [2,4,6,8])\n\nff_layer1 = conv_block(lds_layer, 'conv', 128, (1,1), padding='same', strides= (1,1), relu=False)\n\nff_layer2 = tf.keras.layers.UpSampling2D((4, 4))(gfe_layer)\nff_layer2 = tf.keras.layers.DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same')(ff_layer2)\nff_layer2 = tf.keras.layers.BatchNormalization()(ff_layer2)\nff_layer2 = tf.keras.activations.relu(ff_layer2)\nff_layer2 = tf.keras.layers.Conv2D(128, 1, 1, padding='same', activation=None)(ff_layer2)\n\nff_final = tf.keras.layers.add([ff_layer1, ff_layer2])\nff_final = tf.keras.layers.BatchNormalization()(ff_final)\nff_final = tf.keras.activations.relu(ff_final)\n\nclassifier = tf.keras.layers.SeparableConv2D(128, (3, 3), padding='same', strides = (1, 1), name = 'DSConv1_classifier')(ff_final)\nclassifier = tf.keras.layers.BatchNormalization()(classifier)\nclassifier = tf.keras.activations.relu(classifier)\n\nclassifier = tf.keras.layers.SeparableConv2D(128, (3, 3), padding='same', strides = (1, 1), name = 'DSConv2_classifier')(classifier)\nclassifier = tf.keras.layers.BatchNormalization()(classifier)\nclassifier = tf.keras.activations.relu(classifier)\n\n\nclassifier = conv_block(classifier, 'conv', num_classes, (1, 1), strides=(1, 1), padding='same', relu=False)\n\nclassifier = tf.keras.layers.Dropout(0.3)(classifier)\n\nclassifier = tf.keras.layers.UpSampling2D((8, 8))(classifier)\nclassifier = tf.keras.activations.softmax(classifier)\n\nfast_scnn = tf.keras.Model(inputs = input_layer , outputs = classifier, name = 'Fast_SCNN')\noptimizer = tf.keras.optimizers.SGD(lr=0.001)\nfast_scnn.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[dice_coef])","e02d3cfa":"# model = build_model((256, 1600, 1))\n# model.summary()","18dd2a6d":"fast_scnn.summary()","4aa0758e":"# checkpoint = ModelCheckpoint(\n#     'model.h5', \n#     monitor='val_loss', \n#     verbose=0, \n#     save_best_only=True, \n#     save_weights_only=False,\n#     mode='auto'\n# )\n\nhistory = fast_scnn.fit_generator(\n    train_generator,\n    validation_data=val_generator,\n    use_multiprocessing=False,\n    workers=1,\n    epochs=10\n)","f633249c":"# fast_scnn.save(\"model.h5\")","7bf3f774":"# history = fast_scnn.fit_generator(\n#     train_generator,\n#     validation_data=val_generator,\n#     use_multiprocessing=False,\n#     workers=1,\n#     epochs=20\n# )","c42cd94f":"img=cv2.imread(\"..\/input\/severstal-steel-defect-detection\/train_images\/ac2b13f3f.jpg\",0)\nimg=img.reshape((1,256,1600,1))\na=fast_scnn.predict(img)\nd=build_masks(a,(256,1600))\nd=d.reshape((256,1600))","9f98f09e":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","a55497f0":"imgplot = plt.imshow(d)","3be23e6a":"# with open('history.json', 'w') as f:\n#     json.dump(history.history, f)\n\n# history_df = pd.DataFrame(history.history)\n# history_df[['loss', 'val_loss']].plot()\n# history_df[['dice_coef', 'val_dice_coef']].plot()","2cf3031d":"# fast_scnn.load_weights('model.h5')\ntest_df = []\n\nfor i in range(0, filtered_test_imgs.shape[0], 300):\n    batch_idx = list(\n        range(i, min(filtered_test_imgs.shape[0], i + 300))\n    )\n    \n    test_generator = DataGenerator(\n        batch_idx,\n        df=filtered_test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='..\/input\/severstal-steel-defect-detection\/test_images',\n        target_df=filtered_sub_df,\n        batch_size=1,\n        n_classes=4\n    )\n    \n    batch_pred_masks = fast_scnn.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n    \n    for j, b in tqdm(enumerate(batch_idx)):\n        filename = filtered_test_imgs['ImageId'].iloc[b]\n        image_df = filtered_sub_df[filtered_sub_df['ImageId'] == filename].copy()\n        \n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks)\n        \n        image_df['EncodedPixels'] = pred_rles\n        test_df.append(image_df)\n        \n    gc.collect()","2b40ddec":"test_df = pd.concat(test_df)\nprint(test_df.shape)\ntest_df.head()","94e66fca":"final_submission_df = pd.concat([test_df, null_sub_df])\nprint(final_submission_df.shape)\nfinal_submission_df.head()","55a7bfba":"final_submission_df[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission.csv', index=False)","a77899aa":"# os.listdir() ","364a1b30":"# Preprocessing","d8aa8706":"## Predict masks on non-discarded images","9ded3fa0":"# About this kernel\n\n* **Preprocessing**: Discard all of the training data that have all 4 masks missing. We will only train on images that have at least 1 mask, so that our classifier does not overfit on empty masks.\n* **Step 1 - Discard Images**: Use the DenseNet classifier trained in [this kernel](https:\/\/www.kaggle.com\/xhlulu\/severstal-steel-predict-missing-masks) to predict all of the test images that will have all 4 masks missing. We will automatically set the RLEs of those images to null.\n* **Step 2 - U-Net**: Train the same model from [Simple Keras U-Net Boilerplate](https:\/\/www.kaggle.com\/xhlulu\/severstal-simple-keras-u-net-boilerplate) on the \"filtered\" training data. Then, perform inference only on test images that were not discarded in step 1.\n* **Submission**: We will now combine the dataframe containing the discarded test images with the dataframe containing test images predicted in step 2, and submit everything.\n\n\n## Changelog\n* V8: Changed sign of the `missing_model` threshold, since we are only keeping the ones with low probability of having no defect.\n* V9: Fixed import for the discarding CNNs, which was updated to DenseNet.\n\n\n## References\n* Data generator: https:\/\/stanford.edu\/~shervine\/blog\/keras-how-to-generate-data-on-the-fly\n* RLE encoding and decoding: https:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode\n* Architecture: https:\/\/www.kaggle.com\/jesperdramsch\/intro-chest-xray-dicom-viz-u-nets-full-data\n* Mask encoding: https:\/\/www.kaggle.com\/c\/siim-acr-pneumothorax-segmentation\/data\n* Step 1 Original Kernel: https:\/\/www.kaggle.com\/xhlulu\/severstal-steel-predict-missing-masks\n* Step 2 Original Kernel: https:\/\/www.kaggle.com\/xhlulu\/severstal-simple-keras-u-net-boilerplate","7c73756e":"Now, we combine results from the predicted masks with the rest of images that our first CNN classified as having all 4 masks missing.","322cb9c0":"# Step 2: Keras U-Net\n\nMost of the stuff below is hidden, since it's copied from my previous kernels.","b6df0a8d":"## Evaluation","9ab869bc":"# Submission","2727ba26":"## Data Generator","6412981e":"# Step 1: Remove test images without defects\n\nMost of the stuff below is hidden, since it's copied from my previous kernels.","eeff6bfc":"## Utility Functions","2d9b5422":"`filtered_sub_df` contains all of the images with at least one mask. `null_sub_df` contains all the images with exactly 4 missing masks.","826d3672":"## Model","3d2c2c28":"Beware: Messy code below!"}}