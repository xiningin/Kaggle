{"cell_type":{"9f8164e1":"code","e9256c3b":"code","dc0d19f9":"code","d1347e17":"code","30d74c66":"code","003724bd":"code","5897c15a":"code","b4553307":"code","eeb4f86e":"code","ae903a49":"code","c7c86d73":"code","4da6c1c5":"code","6a8af045":"code","3c8afa3d":"code","17de2d74":"code","9364a4aa":"code","b276d7e6":"code","6d44dea5":"code","ebac2d7c":"code","86008820":"code","1e230cc9":"code","ed7e7bca":"code","b42af063":"code","0ec6376c":"code","25856699":"code","763a62e7":"code","200b7128":"code","ea724dde":"code","878221e6":"code","37a39883":"code","cdfbf523":"code","48ed23d3":"code","150d110c":"code","e7bc6ce1":"code","ecf96c40":"code","df547da2":"code","0c8299e9":"code","8640d243":"code","a6d1caee":"code","de854669":"code","9bf8a2fb":"code","685b328a":"code","595a4638":"code","c97a885f":"code","f74dae70":"code","8c8e47c3":"code","767c853e":"code","fe477d39":"code","bfa733b4":"code","da1dc659":"code","dba34484":"code","2d9bb232":"code","c700a3fe":"code","93ed271f":"code","0ebc74eb":"code","c9ec4cb4":"code","800e1ed0":"code","9db51fab":"code","777b56e0":"code","f046ef21":"code","b640615a":"code","3c17695c":"code","a6c20c3f":"code","bc7e25ff":"code","254eeaf4":"code","30f54704":"code","47fde093":"code","f71dd734":"code","45aee5a3":"code","22fedf8a":"code","b85e4413":"code","dacc460b":"code","20b00cb0":"code","a7eac36c":"code","9b541fd5":"code","6b42ba78":"code","b7355bc0":"code","fc155b2e":"code","f40f3fd1":"code","19676893":"code","4c9be1ad":"code","3bc35579":"code","5ce0a58f":"code","7561e537":"code","8c6b540d":"code","3348e2bd":"code","9517dc84":"code","8bc3e91e":"code","3edfdff6":"code","7377fcf7":"code","4159d3c1":"code","c3fe40f4":"code","73732dbc":"code","7092e167":"code","23cca641":"code","af3f6a75":"code","262ea021":"code","04d844ce":"code","d3fef841":"code","30a116ba":"code","5be5ef5e":"code","51a30419":"code","73941031":"code","af5e4104":"code","ae54459a":"markdown","457e11e8":"markdown","103f4eae":"markdown","192aaecc":"markdown","b9ea1a37":"markdown","36a59c54":"markdown","de354a2a":"markdown","fa2a937e":"markdown","9fabf4ff":"markdown","02dfe7d0":"markdown","a36da834":"markdown","4dbb7c35":"markdown","ff3b2082":"markdown","78f6a33f":"markdown","13570903":"markdown","fd7ad782":"markdown","446c0f9d":"markdown","4ff03784":"markdown","a510f32c":"markdown","5558d2a5":"markdown","10e3bab7":"markdown","bc97ad1b":"markdown","bc146672":"markdown","0fb2bc8b":"markdown","5b4d2089":"markdown","3abb9d89":"markdown","ddd51c08":"markdown","140ea0c6":"markdown","566d53c8":"markdown","8e03b54b":"markdown","01539269":"markdown","b5451082":"markdown","50bdce4d":"markdown","8c8554eb":"markdown","859d9a42":"markdown","7644073b":"markdown","17265c17":"markdown","4da4f170":"markdown","41a17177":"markdown","ebcad6bf":"markdown","4aea6afa":"markdown","da1896f2":"markdown","6a600a14":"markdown","c251fdfc":"markdown","555aa88b":"markdown","1c94129d":"markdown","ffe17dc8":"markdown","fc7ff009":"markdown","709254bc":"markdown","3f8f6396":"markdown","8efc5df4":"markdown","a487d5f9":"markdown","e72645a2":"markdown","6e86422c":"markdown","bb385487":"markdown","6a22f010":"markdown","57e68070":"markdown","5305b2a8":"markdown","de5bb26e":"markdown","eea51e60":"markdown","5cfc5857":"markdown","ca77e0f0":"markdown","de70c577":"markdown","a15acc73":"markdown","f4e27848":"markdown","9405c561":"markdown","534914f9":"markdown","71a4efaf":"markdown","eb35643d":"markdown","fccb8af5":"markdown","3423c3b5":"markdown","33c0e9a6":"markdown","f0e117d2":"markdown","7abeca5e":"markdown","104189eb":"markdown","12e5c730":"markdown","cc1f29ae":"markdown","3e6009fd":"markdown","a2a8f50c":"markdown","15b37775":"markdown","28254126":"markdown","f275ce5b":"markdown","67107727":"markdown","52f3ea55":"markdown","3ac43a28":"markdown","132cd3f8":"markdown","7f0812c7":"markdown","8346c00f":"markdown","7ae12482":"markdown","bb76edfd":"markdown","13014472":"markdown","6df637aa":"markdown","ddc8c6a0":"markdown","74ee3acc":"markdown","729e1fe3":"markdown","d8dbd614":"markdown","cada8a92":"markdown","f1e34c6e":"markdown","b14efc7c":"markdown","b25eaa9a":"markdown","493fdb10":"markdown","229e0a82":"markdown","a95f1445":"markdown","cd2560a9":"markdown"},"source":{"9f8164e1":"# config\nfrom numpy.random import seed\nseed(1)\nfrom tensorflow.compat.v1 import set_random_seed\nset_random_seed(2)\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n# libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom scipy.stats import ttest_ind\n\n# sklearn tools\nfrom sklearn import preprocessing\n\n# sklearn models\nfrom sklearn.ensemble import AdaBoostRegressor\n\n# deep model\nnp.random.seed(0)\nimport tensorflow as tf\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)","e9256c3b":"data = pd.read_csv(r'..\/input\/winning-deck-results\/winning_deck_results.csv')\npd.DataFrame(data.dtypes).transpose()\ndata.head(3)","dc0d19f9":"data.loc[:,'won'] = data.won.str.contains('True').replace({True:1,False:0})","d1347e17":"# all \"x\" columns\ncard_column_names = list(filter(lambda column: column[0:1]=='x', list(data.columns)))\n\nwith warnings.catch_warnings():\n    warnings.simplefilter('ignore')\n    for column in card_column_names:\n        data.loc[:,column] = pd.Categorical(data[column])","30d74c66":"fig, axes = plt.subplots(1,2,figsize=[16,3])\n\n_= sns.countplot(x='won', data=data, ax=axes[0], palette={0:'darkgrey',1:'lightblue'})\n_= sns.boxplot(x='won', y='num_moves', hue='won', data=data, ax=axes[1], palette={0:'darkgrey',1:'lightblue'}, width=1.6)\n_=axes[0].set_title('Won\/Lost (count)')\n_=axes[1].set_title('Won\/Lost (num_moves)')\n_=axes[1].set_xlim(-1,2)\nfor ax in axes:\n    ax.yaxis.grid(True)","003724bd":"details = data.groupby('won')['num_moves'].agg([len,min, max, np.mean]).\\\n    rename(columns={'len':'Num','min':'MinMoves','max':'MaxMoves', 'mean':'MeanMoves'})\ndetails.MeanMoves = details.MeanMoves.transform(int)\ndetails['Ratio'] = details.Num.transform(lambda x:x\/len(data))\ndetails","5897c15a":"train_pct = 0.75\ndata_rows = data.shape[0]\ntrain_rows = int(np.ceil(data_rows * train_pct))\ntraining_index = data.sample(train_rows, random_state=0).index\n\ndef split_train_test(df):\n    train = df.loc[training_index]\n    test = df.loc[~df.index.isin(training_index)]\n    return train, test","b4553307":"def array_with_dummies(df, columns):\n    array = np.array(pd.get_dummies(df.loc[:, columns], drop_first=True, sparse=True))\n    return array","eeb4f86e":"def make_deep_model(training_array):\n    num_input_features = training_array[0].size\n    num_hidden_neurons = min(num_input_features\/\/2, 13)\n\n    deep_model = tf.keras.models.Sequential([\n      tf.keras.layers.Dense(num_input_features, activation='relu'),\n      tf.keras.layers.Dense(num_hidden_neurons, activation='sigmoid'),\n      tf.keras.layers.Dense(3),\n      tf.keras.layers.Dropout(rate=0.2, seed=0),\n      tf.keras.layers.Dense(2, activation='softmax')\n    ])\n\n    deep_model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return deep_model","ae903a49":"def chart_predictions(model, test_array, fitted_model):\n\n    probas = model.predict_proba(test_array)[:,1]\n    num_moves = y_test_regress\n    won = y_test\n    if str(model.name)[:10] == 'sequential':\n        model_name = 'Deep Model'\n    else: model_name = 'Sklearn Model'\n\n    fig, axes = plt.subplots(1, 2, figsize=[16, 4])    \n    _=fig.suptitle('{} (inputs: {})'.format(model_name, str(test_array.shape[1])), fontsize=12)\n    _=axes[0].plot(fitted_model.history['accuracy'], label='train', color='royalblue', linewidth=2, marker='o')\n    _=axes[0].plot(fitted_model.history['val_accuracy'], label='validate', color='gray', linewidth=2, marker='o')\n    _=axes[0].set_xlabel('Training Epoch')\n    _=axes[0].set_ylabel('Accuracy (ratio)')\n    _=axes[0].set_title('Training')\n    _=axes[0].legend()\n    _=axes[0].set_xticks([0,1,2,3,4])\n    _=axes[0].set_xticklabels(['1','2','3','4','5'])\n    _=axes[0].set_ylim([.6,1.05])\n\n    _=axes[1].scatter(probas, num_moves, c=won, s=1, cmap='coolwarm_r', label='blue:won, red:lost')\n    _=axes[1].set_xlabel('Probability Won (predicted)')\n    _=axes[1].set_ylabel('Num Moves (actual)')\n    _=axes[1].set_title('Test Predictions')\n    _=axes[1].legend()","c7c86d73":"def deep_model_and_chart(train_x, train_y, test_x, test_y, baseline=0):\n    deep_model = make_deep_model(train_x)\n    fitted_model=deep_model.fit(train_x, train_y, epochs=5, verbose=0, validation_split=.10)\n    \n    model_accuracy = deep_model.evaluate(test_x, test_y, verbose=0)[1]\n    baseline = max(baseline, len(test.loc[test.won==0]) \/ len(test))  #ratio of LOST in test set\n\n    print('Accuracy: {:.4f}'.format(model_accuracy))\n    print('     vs. baseline: {:.4f}'.format(model_accuracy - baseline))\n    chart_predictions(deep_model, test_x, fitted_model)","4da6c1c5":"adaboostregressor = AdaBoostRegressor(random_state = 0,loss='linear')\n\ndef chart_regression(model, test_array):\n    predicted_moves = model.predict(test_array)\n    num_moves = y_test_regress\n    won = y_test\n    model_name = adaboostregressor.__str__()\n    model_name = model_name[:model_name.index('(')]\n    _=plt.scatter(predicted_moves, num_moves, c=won, s=1, cmap='coolwarm_r')\n    _=plt.xlabel('Num Moves (predicted)')\n    _=plt.ylabel('Num Moves (actual)')\n    _=plt.xlim(0, 160)\n    _=plt.ylim(0, 160)\n    _=plt.title('{} (inputs: {})'.format(model_name, str(test_array.shape[1])))\n\ndef regress_and_chart(train_x, train_y, test_x, test_y):\n    _=adaboostregressor.fit(train_x, train_y)\n    R2 = adaboostregressor.score(test_x, test_y)\n    \n    print('R^2: {}'.format(round(R2, 2)))\n    chart_regression(adaboostregressor, test_x)    ","6a8af045":"def chart_column_stats(column_name_str, title_str, xlabel_str):\n    won_mean = data.loc[data.won==1, column_name_str].mean()\n    won_std = data.loc[data.won==1, column_name_str].std()\n    lost_mean = data.loc[data.won==0, column_name_str].mean()\n    lost_std = data.loc[data.won==0, column_name_str].std()\n    ttest = ttest_ind(data.loc[data.won==1, column_name_str], data.loc[data.won==0, column_name_str])\n    ftest = (won_std ** 2) \/ (lost_std ** 2)\n    print('Mean Difference | p: {:.2f} | F: {:.3f}'.format(ttest[1], ftest))\n\n    won_color, lost_color = 'blue','darkgrey'\n    diffs = data.loc[:, column_name_str]\n    num_moves = data.loc[:, 'num_moves']\n    won = data.loc[:, 'won']\n    won = data.loc[:, 'won'].transform(lambda x: won_color if x==1 else lost_color)\n    plot=plt.scatter(diffs, num_moves, c=won, s=1, alpha=.5)\n    plot=plt.xlabel(xlabel_str)\n    plot=plt.ylabel('Num Moves (actual)')\n\n    plot=plt.axvline(x=lost_mean, color=lost_color, linewidth=1)\n    plot=plt.axvline(x=lost_mean-lost_std, color=lost_color, linewidth=1, linestyle='--')\n    plot=plt.axvline(x=lost_mean+lost_std, color=lost_color, linewidth=1, linestyle='--')\n\n    plot=plt.axvline(x=won_mean, color=won_color, linewidth=1)\n    plot=plt.axvline(x=won_mean-won_std, color=won_color, linewidth=1, linestyle='--')\n    plot=plt.axvline(x=won_mean+won_std, color=won_color, linewidth=1, linestyle='--')\n\n    plot=plt.title(title_str,fontsize=15)","3c8afa3d":"_=data.loc[:,data.columns.isin(card_column_names)].mean().plot(kind='bar',color='grey',figsize=[16,2], alpha=0.5, ylim=[24,28], label='avg')\n_=data.loc[data.won==1,data.columns.isin(card_column_names)].mean().plot(kind='bar',color='blue', alpha=0.9, label='won')\n_=data.loc[data.won==0,data.columns.isin(card_column_names)].mean().plot(kind='bar',color='yellow', alpha=0.5, label='lost')\n_=plt.legend(bbox_to_anchor=(1, .6))\n_=plt.axhline(y=26.5, color='r', linestyle='--', linewidth=0.7)\n_=plt.xlabel('Deck Position')\n_=plt.ylabel('Card Index (avg)')\n_=plt.title('Avg Card Index per Position (E(X)=26.5)')","17de2d74":"divergent_column_names = ['x7','x22','x25','x34','x41','x44','x48','x51']","9364a4aa":"initial_exposed_column_names = ['x0','x7','x13','x18','x22','x25','x27']\ninitial_playpile_column_names = ['x30','x33','x36','x39','x42','x45','x48','x51']\n\nfiltered_column_names = initial_exposed_column_names.copy()\nfiltered_column_names.extend(initial_playpile_column_names)","b276d7e6":"numrows=9\nax_row = 0\nax_col = -1\ntickrange=[0,7,13,20,26,33,39,46]\nxticklabels=['2S','9S','2C','9C','2H','9H','2D','9D']\nyticklabels=['2-Spades','9-Spades','2-Clubs','9-Clubs','2-Hearts','9-Hearts','2-Diamonds','9-Diamonds']\n\nfig, axes = plt.subplots(nrows=numrows, ncols=6, figsize=[24,4*numrows],sharey=True)\n_=fig.suptitle(t='FactoryDeck index per pair of deck positions (darker=more won)', fontsize=25, y=(1-(.011*numrows)))\n\nx = 'x0'\nfor column in card_column_names[:]:\n    if int(column[1:]) == 0:\n        continue\n    y = column\n    \n    if ax_col == 5:\n        ax_row+=1\n        ax_col=0\n    else: \n        ax_col+=1        \n    ax = axes[ax_row][ax_col]\n\n    _=ax.scatter(x=data[x], y=data[y], c=data['won'], cmap='binary', s=10, alpha=.6)\n    _=ax.set_xticks(tickrange)\n    _=ax.set_xticklabels(xticklabels)\n    _=ax.set_yticks(tickrange)\n    _=ax.set_yticklabels(yticklabels)\n    _=ax.set_title(label='{} - {}'.format(x[1:], y[1:]), fontdict={'fontsize':20})","6d44dea5":"train, test = split_train_test(data)\ntrain.shape, test.shape","ebac2d7c":"fig, axes = plt.subplots(1,2,figsize=[16,3],constrained_layout=True)\n\n_= sns.countplot(x='won', data=train, ax=axes[0], palette={0:'darkgrey',1:'lightblue'})\n_= sns.countplot(x='won', data=test, ax=axes[1], palette={0:'darkgrey',1:'lightblue'})\n_=axes[0].set_title('Train')\n_=axes[1].set_title('Test')\n\ntrain_win_ratio = train.won.mean()\ntest_win_ratio = test.won.mean()\n\nprint('TRAIN - Won: {:.4f}  Lost: {:.4f}'.format(train_win_ratio, (1-train_win_ratio)))\nprint('TEST - Won: {:.4f}  Lost: {:.4f}'.format(test_win_ratio, (1-test_win_ratio)))\nprint('Diff in win means: {:.4f}'.format(abs(train_win_ratio - test_win_ratio)))\nprint('    p value that Diff is random: {:.4f}'.format(ttest_ind(train.won, test.won)[1]))","86008820":"fig, axes = plt.subplots(1,2,figsize=[16,3],constrained_layout=True)\n\n_= sns.boxplot(x='won', y='num_moves', hue='won', data=train, ax=axes[0], palette={0:'darkgrey',1:'lightblue'}, width=1.6)\n_= sns.boxplot(x='won', y='num_moves', hue='won', data=test, ax=axes[1], palette={0:'darkgrey',1:'lightblue'}, width=1.6)\n\nfor ax in axes:\n    _=ax.set_xlim(-1,2)\n    _=ax.yaxis.grid(True)\n_=axes[0].set_title('Train')\n_=axes[1].set_title('Test')\n\nprint('p value that num_moves Diff is random: {:.4f}'.format(ttest_ind(train.num_moves, test.num_moves)[1]))","1e230cc9":"X_train = array_with_dummies(train, data.columns.isin(card_column_names))\nX_train_filtered = array_with_dummies(train, data.columns.isin(filtered_column_names))\nX_train_divergent = array_with_dummies(train, data.columns.isin(divergent_column_names))\n\ny_train = np.array(train.loc[:,(train.columns=='won')].iloc[:,0])","ed7e7bca":"X_test = array_with_dummies(test, data.columns.isin(card_column_names))\nX_test_filtered = array_with_dummies(test, data.columns.isin(filtered_column_names))\nX_test_divergent = array_with_dummies(test, data.columns.isin(divergent_column_names))\n\ny_test = np.array(test.loc[:,(test.columns=='won')].iloc[:,0])","b42af063":"y_train_regress = np.array(train.loc[:,(train.columns=='num_moves')].iloc[:,0])\ny_test_regress = np.array(test.loc[:,(test.columns=='num_moves')].iloc[:,0])","0ec6376c":"X_train.shape, X_test.shape\nX_train_filtered.shape, X_test_filtered.shape\nX_train_divergent.shape, X_test_divergent.shape\n\ny_train.shape, y_test.shape\ny_train_regress.shape, y_test_regress.shape","25856699":"deep_model_and_chart(X_train, y_train, X_test, y_test)","763a62e7":"deep_model_and_chart(X_train_filtered,y_train,X_test_filtered,y_test)","200b7128":"deep_model_and_chart(X_train_divergent,y_train,X_test_divergent,y_test)","ea724dde":"regress_and_chart(X_train, y_train_regress, X_test, y_test_regress)","878221e6":"regress_and_chart(X_train_filtered, y_train_regress, X_test_filtered, y_test_regress)","37a39883":"regress_and_chart(X_train_divergent, y_train_regress, X_test_divergent, y_test_regress)","cdfbf523":"# card indexes corresponding to various categories.\naces = [13, 26, 39, 52]\nkings = [12, 25, 38, 51]\nblack = list(range(1,27))\nevens = [1,3,5,7,9,11,14,16,18,20,22,24,27,29,31,33,35,37,40,42,44,46,48,50]","48ed23d3":"data.loc[:, 'i_exposed_aces'] = data.loc[:, filtered_column_names].\\\n            transform(lambda x: x.isin(aces)).replace({True:1, False:0}).sum(axis=1)\ndata.loc[:, 'i_pile_kings'] =   data.loc[:, initial_exposed_column_names].\\\n            transform(lambda x: x.isin(kings)).replace({True:1, False:0}).sum(axis=1)\ndata.loc[:, 'i_pile_blacks'] =  data.loc[:, initial_exposed_column_names].\\\n            transform(lambda x: x.isin(black)).replace({True:1, False:0}).sum(axis=1)\ndata.loc[:, 'i_pile_evens'] =   data.loc[:, initial_exposed_column_names].\\\n            transform(lambda x: x.isin(evens)).replace({True:1, False:0}).sum(axis=1)","150d110c":"important_card_column_names = list(filter(lambda x:x[0:2]=='i_', list(data.columns)))\nimportant_card_column_names","e7bc6ce1":"num_plots = len(important_card_column_names)\n\nfig, axes = plt.subplots(1,num_plots,sharey=True,figsize=[16,4])\nax = 0\nfor column in important_card_column_names:\n    sns_plot = sns.countplot(x=column, hue='won', palette = {0:'darkgrey',1:'lightblue'},data=data, ax=axes[ax])\n    ax+=1","ecf96c40":"for column in important_card_column_names:\n    mean = data[column].mean()\n    std = data[column].std()\n    data.loc[:, column] = data.loc[:,column].transform(lambda x: (x-mean)\/std)","df547da2":"train, test = split_train_test(data)\ntrain.shape, test.shape","0c8299e9":"X_train_important_column_features = np.array(train.loc[:, data.columns.isin(important_card_column_names)])\nX_test_important_column_features = np.array(test.loc[:, data.columns.isin(important_card_column_names)])\n\nX_train_important_column_features.shape, X_test_important_column_features.shape","8640d243":"poly = preprocessing.PolynomialFeatures(degree=4, interaction_only=True)\nX_train_poly_important_column_features = poly.fit_transform(X_train_important_column_features, y_train)\nX_test_poly_important_column_features = poly.fit_transform(X_test_important_column_features, y_test)\n\nX_train_poly_important_column_features.shape, X_test_poly_important_column_features.shape","a6d1caee":"deep_model_and_chart(X_train_important_column_features, y_train, X_test_important_column_features, y_test)","de854669":"deep_model_and_chart(X_train_poly_important_column_features, y_train, X_test_poly_important_column_features, y_test)","9bf8a2fb":"regress_and_chart(X_train_important_column_features, y_train_regress,\\\n                  X_test_important_column_features, y_test_regress)","685b328a":"regress_and_chart(X_train_poly_important_column_features, y_train_regress,\\\n                  X_test_poly_important_column_features, y_test_regress)","595a4638":"# our factory deck order is Two through Ace repeated 4 times.\ncard_values = list(range(2,14))\ncard_values.append(1)\ncard_values = card_values * 4\n\n# our factory deck order is Spades, Clubs, Hearts, Diamonds, 13 each.\ncard_suits = ([1]*13) + ([2]*13) + ([3]*13) + ([4]*13)\n\n\ncard_indexes = range(1,53)\n\n# dictionaries\ncardval_dict = dict(zip(card_indexes,card_values))\ncardsuit_dict = dict(zip(card_indexes,card_suits))","c97a885f":"x_columns = list(filter(lambda x:x[0:1]=='x', list(data.columns)))\nfor col in x_columns:\n    newcol = 'val_'+ col[1:]\n    data.loc[:, newcol] = pd.Categorical(data.loc[:, col].transform(lambda x:cardval_dict[x]))\n\nvalue_column_names = list(filter(lambda x:x[0:4]=='val_', list(data.columns)))\nprint('sample of new value_columns: {}'.format(value_column_names[0:5]))","f74dae70":"for col in x_columns:\n    newcol = 'suit_'+ col[1:]\n    data.loc[:, newcol] = pd.Categorical(data.loc[:, col].transform(lambda x:cardsuit_dict[x]))\n\nsuit_column_names = list(filter(lambda x:x[0:5]=='suit_', list(data.columns)))\nprint('sample of new suit_columns: {}'.format(suit_column_names[0:5]))","8c8e47c3":"value_and_suit_column_names = []\nvalue_and_suit_column_names.extend(value_column_names)\nvalue_and_suit_column_names.extend(suit_column_names)","767c853e":"_=data.loc[:,data.columns.isin(value_column_names)].mean().plot(kind='bar',color='grey',figsize=[16,2], alpha=0.5, ylim=[5,8], label='avg')\n_=data.loc[data.won==1,data.columns.isin(value_column_names)].mean().plot(kind='bar',color='blue', alpha=0.9, label='won')\n_=data.loc[data.won==0,data.columns.isin(value_column_names)].mean().plot(kind='bar',color='yellow', alpha=0.5, label='lost')\n_=plt.axhline(y=7, color='r', linestyle='--', linewidth=0.7)\n_=plt.legend(bbox_to_anchor=(1, .6))\n_=plt.xlabel('Deck Position')\n_=plt.ylabel('Card Value (avg)')\n_=plt.title('Avg Card Value per Position (E(X)=7)')","fe477d39":"divergent_value_column_names = ['val_3','val_4','val_6','val_24','val_25','val_27','val_28']\ndivergent_suit_column_names = ['suit_3','suit_4','suit_6','suit_24','suit_25','suit_27','suit_28']\ndivergent_value_and_suit_column_names = divergent_value_column_names.copy()\ndivergent_value_and_suit_column_names.extend(divergent_suit_column_names)","bfa733b4":"train, test = split_train_test(data)","da1dc659":"X_train_recode = array_with_dummies(train, data.columns.isin(value_and_suit_column_names))\nX_test_recode = array_with_dummies(test, data.columns.isin(value_and_suit_column_names))\nX_train_recode.shape\nX_test_recode.shape","dba34484":"X_train_recode_divergent = array_with_dummies(train, data.columns.isin(divergent_value_and_suit_column_names))\nX_test_recode_divergent = array_with_dummies(test, data.columns.isin(divergent_value_and_suit_column_names))\nX_train_recode_divergent.shape\nX_test_recode_divergent.shape","2d9bb232":"deep_model_and_chart(X_train_recode, y_train, X_test_recode, y_test)","c700a3fe":"deep_model_and_chart(X_train_recode_divergent, y_train, X_test_recode_divergent, y_test)","93ed271f":"regress_and_chart(X_train_recode, y_train_regress, X_test_recode, y_test_regress)","0ebc74eb":"regress_and_chart(X_train_recode_divergent, y_train_regress, X_test_recode_divergent, y_test_regress)","c9ec4cb4":"numrows=9\nax_row = 0\nax_col = -1\ntickrange=range(1,14)\nxticklabels=['A','','','','','','7','','','','','','K']\nyticklabels=['Ace','2','3','4','5','6','7','8','9','10','Jack','Queen','King']\n\nfig, axes = plt.subplots(nrows=numrows, ncols=6, figsize=[24,4*numrows], sharey=True)\n_=fig.suptitle(t='Ace-to-King values per pair of deck positions (darker=more won)', fontsize=25, y=.905)\n\nx = 'val_0'\nfor column in value_column_names:\n    if int(column[4:]) == 0:\n        continue\n    y = column\n    \n    if ax_col == 5:\n        ax_row+=1\n        ax_col=0\n    else: \n        ax_col+=1        \n    ax = axes[ax_row][ax_col]\n    \n    _=ax.scatter(x=data[x], y=data[y], c=data['won'], cmap='binary', s=80, alpha=.6)\n    _=ax.set_xticks(tickrange)\n    _=ax.set_xticklabels(xticklabels)\n    _=ax.set_yticks(tickrange)\n    _=ax.set_yticklabels(yticklabels)\n\n    _=ax.set_title(label='{} - {}'.format(x[4:], y[4:]), fontdict={'fontsize':20})\n","800e1ed0":"for col in value_column_names[:51]:\n    this_col_num = int(col[4:])\n    for other in value_column_names[this_col_num+1:]:\n        other_col_num = int(other[4:])\n\n        new_col_name = 'val_diff_'+str(this_col_num)+'_'+str(other_col_num)\n        data.loc[:,new_col_name] = pd.Categorical(data.loc[:,col].astype('int') - data.loc[:,other].astype('int'))","9db51fab":"val_diff_column_names = list(filter(lambda x: x[0:8]=='val_diff',list(data.columns)))\n\ndata.loc[:0,data.columns.isin(value_column_names)]\ndata.loc[:0,data.columns.isin(val_diff_column_names)]","777b56e0":"train, test = split_train_test(data)\n\nX_train_val_diffs = array_with_dummies(train, data.columns.isin(val_diff_column_names[:len(val_diff_column_names)\/\/6]))\nX_test_val_diffs = array_with_dummies(test, data.columns.isin(val_diff_column_names[:len(val_diff_column_names)\/\/6]))\n\nX_train_val_diffs.shape, X_test_val_diffs.shape","f046ef21":"deep_model_and_chart(X_train_val_diffs, y_train, X_test_val_diffs, y_test)","b640615a":"regress_and_chart(X_train_val_diffs, y_train_regress, X_test_val_diffs, y_test_regress)","3c17695c":"num_rows = 0\nfirst_value_column = value_column_names[0]\n\nfor row in data.index:\n    num_rows += 1\n    num_contiguous_values = 0\n    current_value = 0\n    previous_value = 0\n    for column in value_column_names:\n        current_value = data.loc[row, column]\n        if ((column != first_value_column) & (abs(current_value - previous_value)==1)):\n            num_contiguous_values += 1\n        previous_value = current_value\n    data.loc[row, 'z_num_contiguous_values'] = num_contiguous_values\nnum_rows","a6c20c3f":"contiguous_mean = data.loc[:, 'z_num_contiguous_values'].mean()\ncontiguous_std = data.loc[:, 'z_num_contiguous_values'].std()\n\ndata.loc[:, 'z_num_contiguous_values'] = data.loc[:, 'z_num_contiguous_values'].\\\n    transform(lambda x: (x - contiguous_mean) \/ contiguous_std)","bc7e25ff":"assert abs(data.loc[:, 'z_num_contiguous_values'].mean() - 0)  < 0.0001\nassert abs(data.loc[:, 'z_num_contiguous_values'].std() - 1) < 0.00001","254eeaf4":"h1_deck_position_names = []\nh2_deck_position_names = []\n\nfor col in value_column_names:\n    if int(col[4:]) < 26:\n        h1_deck_position_names.append(col)\n    else:\n        h2_deck_position_names.append(col)","30f54704":"data.loc[:, 'z_sum_h1_values'] = data.loc[:, data.columns.isin(h1_deck_position_names)].sum(axis=1)\ndata.loc[:, 'z_sum_h2_values'] = data.loc[:, data.columns.isin(h2_deck_position_names)].sum(axis=1)\n\ndata['z_diff_h1_h2_values'] = (data['z_sum_h1_values'] - data['z_sum_h2_values'])","47fde093":"diff_h1_h2_mean = data['z_diff_h1_h2_values'].mean()\ndiff_h1_h2_std = data['z_diff_h1_h2_values'].std()\n\ndata.loc[:, 'z_diff_h1_h2_values'] = data.loc[:, 'z_diff_h1_h2_values'].\\\n    transform(lambda x: (x - diff_h1_h2_mean) \/ diff_h1_h2_std)","f71dd734":"assert abs(data.loc[:, 'z_diff_h1_h2_values'].mean() - 0) < 0.0001\nassert abs(data.loc[:, 'z_diff_h1_h2_values'].std() - 1) < 0.0001","45aee5a3":"even_deck_position_names = []\nodd_deck_position_names = []\n\nfor col in list(data.columns):\n    if col[0:1] == 'x':\n        if int(col[1:]) % 2 == 0:\n            odd_deck_position_names.append(col)\n        else:\n            even_deck_position_names.append(col)","22fedf8a":"data.loc[:, 'z_sum_evens_indexes'] = data.loc[:, data.columns.isin(even_deck_position_names)].sum(axis=1)\ndata.loc[:, 'z_sum_odds_indexes'] = data.loc[:, data.columns.isin(odd_deck_position_names)].sum(axis=1)\n\ndata['z_diff_even_odd_indexes'] = (data['z_sum_evens_indexes'] - data['z_sum_odds_indexes'])","b85e4413":"diff_even_odd_mean = data['z_diff_even_odd_indexes'].mean()\ndiff_even_odd_std = data['z_diff_even_odd_indexes'].std()\n\ndata.loc[:, 'z_diff_even_odd_indexes'] = data.loc[:, 'z_diff_even_odd_indexes'].\\\n    transform(lambda x: (x - diff_even_odd_mean) \/ diff_even_odd_std)","dacc460b":"assert abs(data.loc[:, 'z_diff_even_odd_indexes'].mean() - 0) < 0.0001\nassert abs(data.loc[:, 'z_diff_even_odd_indexes'].std() - 1) < 0.0001","20b00cb0":"h1_deck_position_names = []\nh2_deck_position_names = []\n\nfor col in card_column_names:\n    if int(col[1:]) < 26:\n        h1_deck_position_names.append(col)\n    else:\n        h2_deck_position_names.append(col)","a7eac36c":"data.loc[:, 'z_sum_h1_indexes'] = data.loc[:, data.columns.isin(h1_deck_position_names)].sum(axis=1)\ndata.loc[:, 'z_sum_h2_indexes'] = data.loc[:, data.columns.isin(h2_deck_position_names)].sum(axis=1)\n\ndata['z_diff_h1_h2_indexes'] = (data['z_sum_h1_indexes'] - data['z_sum_h2_indexes'])","9b541fd5":"diff_h1_h2_mean = data['z_diff_h1_h2_indexes'].mean()\ndiff_h1_h2_std = data['z_diff_h1_h2_indexes'].std()\n\ndata.loc[:, 'z_diff_h1_h2_indexes'] = data.loc[:, 'z_diff_h1_h2_indexes'].\\\n    transform(lambda x: (x - diff_h1_h2_mean) \/ diff_h1_h2_std)","6b42ba78":"assert abs(data.loc[:, 'z_diff_h1_h2_indexes'].mean() - 0) < 0.0001\nassert abs(data.loc[:, 'z_diff_h1_h2_indexes'].std() - 1) < 0.0001  ","b7355bc0":"num_rows = 0\nfirst_card_column = card_column_names[0]\n\nfor row in data.index[:]:\n    num_rows += 1\n    current_value = 0\n    previous_value = 0\n    this_diff = 0\n    running_diff = 0\n    for column in card_column_names:\n        current_value = data.loc[row, column]\n        this_diff = previous_value - current_value\n        if (column != first_card_column):\n            running_diff += this_diff\n        previous_value = current_value\n    data.loc[row, 'z_running_diff_indexes'] = running_diff\nnum_rows","fc155b2e":"running_column_mean = data.loc[:, 'z_running_diff_indexes'].mean()\nrunning_column_std = data.loc[:, 'z_running_diff_indexes'].std()\n\ndata.loc[:, 'z_running_diff_indexes'] = data.loc[:, 'z_running_diff_indexes'].\\\n    transform(lambda x: (x - running_column_mean) \/ running_column_std)","f40f3fd1":"assert abs(data.loc[:, 'z_running_diff_indexes'].mean() - 0)  < 0.0001\nassert abs(data.loc[:, 'z_running_diff_indexes'].std() - 1) < 0.00001","19676893":"deck_profile_column_names = \\\n    ['z_num_contiguous_values', 'z_diff_h1_h2_values', 'z_diff_even_odd_indexes',\\\n     'z_diff_h1_h2_indexes', 'z_running_diff_indexes']\ndeck_profile_column_names","4c9be1ad":"chart_column_stats('z_num_contiguous_values',\\\n                   title_str='Value Balance - contiguous vs chunky',\\\n                   xlabel_str='Number of contiguous positions (standardized)')","3bc35579":"chart_column_stats('z_diff_h1_h2_values',\\\n                   title_str='Value Balance - Top Half vs Bottom Half',\\\n                   xlabel_str='H1 minus H2 Card Values (standardized)')","5ce0a58f":"chart_column_stats('z_diff_even_odd_indexes',\\\n                   title_str='Color Balance - Every other card',\\\n                   xlabel_str='Even - Odd Deck Indexes (standardized)')","7561e537":"chart_column_stats('z_diff_h1_h2_indexes',\\\n                   title_str='Color Balance - Top Half vs Bottom Half',\\\n                   xlabel_str='H1 - H2 Deck Indexes (standardized)')","8c6b540d":"chart_column_stats('z_running_diff_indexes',\\\n                   title_str='Index Balance - column-wise subtraction method',\\\n                   xlabel_str='Running Column-Wise Index Diff (standardized)')","3348e2bd":"train, test = split_train_test(data)","9517dc84":"X_train_deck_profile = np.array(train.loc[:, data.columns.isin(deck_profile_column_names)])\nX_test_deck_profile = np.array(test.loc[:, data.columns.isin(deck_profile_column_names)])","8bc3e91e":"X_train_poly_deck_profile = poly.fit_transform(X_train_deck_profile, y_train)\nX_test_poly_deck_profile = poly.fit_transform(X_test_deck_profile, y_test)\nX_train_poly_deck_profile.shape\nX_test_poly_deck_profile.shape","3edfdff6":"deep_model_and_chart(X_train_deck_profile, y_train, X_test_deck_profile, y_test)","7377fcf7":"deep_model_and_chart(X_train_poly_deck_profile, y_train, X_test_poly_deck_profile, y_test)","4159d3c1":"regress_and_chart(X_train_deck_profile, y_train_regress, X_test_deck_profile, y_test_regress)","c3fe40f4":"regress_and_chart(X_train_poly_deck_profile, y_train_regress, X_test_poly_deck_profile, y_test_regress)","73732dbc":"_=plt.hist(data.loc[data.won==0].num_moves,bins=50, label='lost', color='darkgrey')\n_=plt.hist(data.loc[data.won==1].num_moves,bins=50, label='won', color='lightblue')\n_=plt.axvline(x=14, color='red', linewidth=.8, linestyle='--')\n_=plt.xlabel('# moves')\n_=plt.legend()\n_=plt.title('Histogram num_moves')","7092e167":"data.loc[data.num_moves<14, 'fun'] = 0\ndata.loc[data.num_moves>=14, 'fun'] = 1","23cca641":"train, test = split_train_test(data)","af3f6a75":"y_train_fun = np.array(train.loc[:,(train.columns=='fun')].iloc[:,0])\ny_test_fun = np.array(test.loc[:,(test.columns=='fun')].iloc[:,0])\n\ny_train_fun.shape, y_test_fun.shape","262ea021":"print('New baseline (fun == 1 in the test set): {}'.format(len(test.loc[test.fun==1])\/len(test)))","04d844ce":"deep_model_and_chart(X_train, y_train_fun, X_test, y_test_fun, baseline=.9356)","d3fef841":"deep_model_and_chart(X_train_deck_profile, y_train_fun, X_test_deck_profile, y_test_fun, baseline=.9356)","30a116ba":"deep_model_and_chart(X_train_important_column_features,y_train_fun,X_test_important_column_features,\\\n                     y_test_fun,baseline=.9356)","5be5ef5e":"add_noisy_explanatory = True\n\nif add_noisy_explanatory:\n    import random\n    random.seed(0)\n\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore')\n        \n        # ensure num_moves is not already modified by re-importing raw values saved earlier\n        train.loc[:,'num_moves'] = y_train_regress\n        test.loc[:,'num_moves'] = y_test_regress\n        \n        # randomly modify 'num_moves' in the training & testing sets.\n        train_sample_row_indexes = train.num_moves.sample(len(train.num_moves)\/\/1).index\n        test_sample_row_indexes = test.num_moves.sample(len(test.num_moves)\/\/1).index\n        \n        train.loc[train_sample_row_indexes, 'num_moves'] = train.loc[train_sample_row_indexes, 'num_moves'].\\\n            transform(lambda x: x*(random.choice(np.linspace(.85,1.15,num=5))))\n        test.loc[test_sample_row_indexes, 'num_moves'] = test.loc[test_sample_row_indexes, 'num_moves'].\\\n            transform(lambda x: x*(random.choice(np.linspace(.85,1.15,num=5))))","51a30419":"X_train_gut_check = \\\n    np.array(train.loc[:, (train.columns.isin(card_column_names))|(train.columns == 'num_moves')], dtype='float')\nX_test_gut_check = \\\n    np.array(test.loc[:, (test.columns.isin(card_column_names))|(test.columns == 'num_moves')], dtype='float')\n\nX_train_gut_check.shape\nX_test_gut_check.shape","73941031":"deep_model_and_chart(X_train_gut_check, y_train, X_test_gut_check, y_test)","af5e4104":"regress_and_chart(X_train_gut_check, y_train_regress, X_test_gut_check, y_test_regress)","ae54459a":"#### 8.2 Create input arrays","457e11e8":"AdaBoostRegressor on 'num_moves'","103f4eae":"<div style='text-align: right; font-size: 12pt'>Brian Markley - Mar 8th, 2020<\/div>","192aaecc":"# Predicting Winning Solitaire Decks\nAnalysis with Tensorflow and AdaBoostRegressor","b9ea1a37":"    Average card index per deck position in winning and losing decks.","36a59c54":"#### 7.2 Add feature: value balance between halves of the deck","de354a2a":"#### 6.2 Create value offset features\nFor each of the first 51 cards, build a new column storing its value difference from each subsequent card. ~~Normalize between [-1, 1] by dividing by 12.~~","fa2a937e":"#### 9.1 Degrade num_moves feature with random noise","9fabf4ff":"#### 5.4 Create input arrays","02dfe7d0":"#### 3.3 Visualize index differences between specific positions in the deck","a36da834":"#### 2.4 Chart statistics","4dbb7c35":"#### 5.5 Run models","ff3b2082":"#### 7.1 Add feature: number of contiguous values","78f6a33f":"## 10. Conclusions and Questions","13570903":"---","fd7ad782":"## 1. Import","446c0f9d":"---","4ff03784":"## 8. Model: Identify Quick Losers\n\nIs it possible to at least identify those nearly unplayable decks which lose after a short number of moves?\n\nPerhaps a user would find value in avoiding decks which don't justify the time it takes to shuffle.","a510f32c":"##### transform won\/lost as integer","5558d2a5":"   * <b>How common are contiguous card values?<\/b> \n          Sum number of contiguous values (next card value higher or lower by ONE) throughout deck.\n          ex. A perfectly contiguous deck might ensure dependent cards (contiguous ones) aren't far from each other.\n\n   * <b>How well are values balanced between the two halves of the deck?<\/b> \n          Sum card values for each half.\n          ex. If h1 low and h2 high, the low-value piles (mostly comprised of h1) might be tough targets for high-\n          value playing deck (mostly comprised of h2).\n\n   * <b>How is the color spread among alternating cards?<\/b> \n          Sum indexes for even and odd deck positions. The abs(difference) in these sums is maximized when the cards \n          perfectly alternate between red and black. Perhaps this alternation could discourage 'stuck' states where \n          all visible cards are the same color.\n\n   * <b>How is the color balanced between the two halves of the deck?<\/b> \n          Sum indexes for each half. Indexes 1-26 are black cards and 27-52 are red. If h1 \n          entirely black and h2 entirely red then perhaps the black piles would be easier targets for the red\n          playpile. Perhaps large difference between index-sums of the piles leads to easier targets.\n   * <b>How is the color balanced from top to bottom continuously?<\/b> \n          Collect a running sum of the index difference between each deck position to get a more precise \n          'fingerprint' of the index order of each deck. Since this method records the ordering within each deck \n          half as well, it may inform whether bunches of value differerences are helpful.  ","10e3bab7":"#### 5.1 Dictionaries for val and suit","bc97ad1b":"AdaBoostRegressor on 'num_moves'","bc146672":"#### 3.4 Create input arrays","0fb2bc8b":"#### 3.5 Run models","5b4d2089":"#### 1.4 High Level Summary\n    Approximately 19% are winning decks, and the \"num_moves\" field clearly distinguishes winners from losers.","3abb9d89":"Not expanding this beyond initial x0 card, as spot checking others also does not suggest obvious patterns.","ddd51c08":"Summarize among cards on top of the initial 7 piles, and those exposed in the 1st cycle through play deck.\n\n1. number of <b>aces<\/b> exposed (<i>perhaps high number is helpful, since all playable<\/i>)\n\n2. number of <b>kings<\/b> in pile tops (<i>perhaps high number hurtful, since can't play on other cards<\/i>)\n\n3. ratio of <b>red \/ black<\/b> cards in pile tops. (<i>Better if all one color, or balanced 50\/50? If all same color, none can play on each other initially<\/i>)\n\n4. ratio of <b>even \/ odd<\/b> cards in pile tops. (<i>Better if all same, or if balanced? If all same, none can play on each other initially<\/i>)","140ea0c6":"#### 4.2 Visualize","566d53c8":"#### 9.2 Create input arrays","8e03b54b":"    Train\/Test Details","01539269":"No obvious win\/lose ratio differences based on these factors.","b5451082":"## 9. Model: Gut Check\n\nAdd a noisy explanatory column to see if models can properly classify won\/lost when at least one column has predictive ability.","50bdce4d":"#### 1.3 Clean, Transform","8c8554eb":"## 7. Model: Deck Statistics","859d9a42":"#### 2.1 Prep input arrays","7644073b":"##### Make arrays","17265c17":"<b><span style=\"color:indian red; font-size:14pt\">No signal.<\/span><\/b>","4da4f170":"#### 1.2 Data","41a17177":"##### Make arrays","ebcad6bf":"#### 4.4 Create input arrays","4aea6afa":"##### AdaBoostRegressor - 'num_moves'","da1896f2":"<b><span style=\"color:indian red; font-size:14pt\">No signal.<\/span><\/b>","6a600a14":"    Do certain cards often appear at a given offset from each other in winning decks? (e.g. if the top card ('x0') is a red 3-of-hearts (index 28), is it common in winning decks for the 20th card ('x19') to be a black 4 (index 3 or 16)?) \n\n    I may expect to see diagonal lines where value\/color combinations relate to other value\/color combinations at specific depths from that card location.","c251fdfc":"## 5. Model: Card Values and Suits","555aa88b":"#### 4.1 Create features","1c94129d":"#### 7.4 Add feature: color balance between halves of the deck","ffe17dc8":"Polynomial versions.","fc7ff009":"<b><span style=\"color:indian red; font-size:14pt\">No signal.<\/span><\/b>","709254bc":"    Center and distribution match between Won and Lost so no useful signal on these feature sets.","3f8f6396":"#### 6.3 Create filter to identify new features","8efc5df4":"#### 2.3 Regression","a487d5f9":"    Create feature of deck positions guaranteed to be exposed in every game (pile tops and initial every-third).","e72645a2":"##### transform categorical columns","6e86422c":"#### 6.5 Run models","bb385487":"#### 4.5 Run models","6a22f010":"#### 3.1 Add feature: deck positions where avg card diverges in winning decks","57e68070":"1. [Import](#1.-Import)\n    - 1.1 [libraries](#1.1-Libraries)\n    - 1.2 [data](#1.2-Data)\n    - 1.3 [clean and transform](#1.3-Clean,-Transform)\n    - 1.4 [summarize](#1.4-High-Level-Summary)\n\n2. [Define Utility Functions](#2.-Define-Utility-Functions)\n    - 2.1 [prep input arrays with dummies](#2.1-Prep-input-arrays)\n    - 2.2 [deep model](#2.2-Deep-model)\n    - 2.3 [regression](#2.3-Regression)\n    - 2.4 [chart statistics](#2.4-Chart-statistics)\n\n3. [Model: Raw Card Indexes (naiive)](#3.-Model:-Raw-Card-Indexes)\n    - 3.1 [add feature: filter to deck positions where avg card diverges in winning decks](#3.1-Add-feature:-deck-positions-where-avg-card-diverges-in-winning-decks)\n    - 3.2 [add feature: filter to deck positions which are initially exposed in game play](#3.2-Add-feature:-deck-positions-which-are-initially-exposed-in-game-play)\n    - 3.3 [visualize index differences between specific positions in the deck](#3.3-Visualize-index-differences-between-specific-positions-in-the-deck)\n    - 3.4 [create input arrays](#3.4-Create-input-arrays)\n    - 3.5 [run models](#3.5-Run-models)\n\n4. [Model: Summarize Important Initial Deck Positions](#4.-Model:-Summarize-Important-Deck-Positions)\n    - 4.1 [create features (#exposed aces, #pile top kings, #pile top blacks, and #pile top evens)](#4.1-Create-features)\n    - 4.2 [visualize](#4.2-Visualize)\n    - 4.3 [normalize](#4.3-Normalize)\n    - 4.4 [create input arrays](#4.4-Create-input-arrays)\n    - 4.5 [run models](#4.5-Run-models)\n\n5. [Model: Card Values and Suits](#5.-Model:-Card-Values-and-Suits)\n    - 5.1 [dictionaries for val and suit](#5.1-Dictionaries-for-val-and-suit)\n    - 5.2 [create new columns](#5.2-Create-new-columns)\n    - 5.3 [add feature: deck positions where avg card diverges in winning decks](#5.3-Add-feature:-deck-positions-where-avg-card-diverges-in-winning-decks)\n    - 5.4 [create input arrays](#5.4-Create-input-arrays)\n    - 5.5 [run models](#5.5-Run-models)\n\n6. [Model: Value offsets between deck positions](#6.-Model:-Value-offsets-between-deck-positions)\n    - 6.1 [visualize card values between pairs of positions.](#6.1-Visualize-card-values-between-pairs-of-positions.)\n    - 6.2 [create value offset features](#6.2-Create-value-offset-features)\n    - 6.3 [create filter to identify new features](#6.3-Create-filter-to-identify-new-features)\n    - 6.4 [create input arrays](#6.4-Create-input-arrays)\n    - 6.5 [run models](#6.5-Run-models)\n\n7. [Model: Deck Statistics](#7.-Model:-Deck-Statistics)\n    - 7.1 [add feature: number of contiguous values](#7.1-Add-feature:-number-of-contiguous-values)\n    - 7.2 [add feature: value balance between halves of the deck](#7.2-Add-feature:-value-balance-between-halves-of-the-deck)\n    - 7.3 [add feature: color balance between alternating cards](#7.3-Add-feature:-color-balance-between-alternating-cards)\n    - 7.4 [add feature: color balance between halves of the deck](#7.4-Add-feature:-color-balance-between-halves-of-the-deck)\n    - 7.5 [add feature: color balance from top to bottom continuously](#7.5-Add-feature:-color-balance-from-top-to-bottom-continuously)\n    - 7.6 [create filter for new features](#7.6-Create-filter-for-new-features)\n    - 7.7 [summarize and visualize](#7.7-Summarize-and-visualize)\n    - 7.8 [create input arrays](#7.8-Create-input-arrays)\n    - 7.9 [run models](#7.9-Run-models)\n\n8. [Model: Identify Quick Losers](#8.-Model:-Identify-Quick-Losers)\n    - 8.1 [find minimum move threshold for a 'fun' deck](#8.1-Find-minimum-move-threshold-for-a-'fun'-deck)\n    - 8.2 [create input arrays](#8.2-Create-input-arrays)\n    - 8.3 [run models](#8.3-Run-models)\n\n9. [Model: Gut Check](#9.-Model:-Gut-Check)\n    - 9.1 [degrade num_moves with random noise](#9.1-Degrade-num_moves-feature-with-random-noise)\n    - 9.2 [create input arrays (with noisy num_moves added)](#9.2-Create-input-arrays)\n    - 9.3 [run models](#9.3-Run-models)\n\n10. [Conclusions and Questions](#-10.-Conclusions-and-Questions)","5305b2a8":"#### 6.4 Create input arrays\nBecause of memory constraints on my hardware, I am using only a fraction of the 1,326 val_diff columns to create dummy variables and model.","de5bb26e":"#### 8.1 Find minimum move threshold for a 'fun' deck","eea51e60":"# Contents","5cfc5857":"## 3. Model: Raw Card Indexes","ca77e0f0":"##### index columns","de70c577":"## 4. Model: Summarize Important Deck Positions","a15acc73":"#### 3.2 Add feature: deck positions which are initially exposed in game play","f4e27848":"    Poor regression. R^2 very near 0, so explains little to none of variation.","9405c561":"##### make new filters","534914f9":"    Initially plotting only the top card against the other 51 deck positions doesn't reveal a clear relationship. Not expanding to all pair-wise comparisons since spot checking those also doesn't reveal any patterns.","71a4efaf":"##### Tensorflow","eb35643d":"##### values columns","fccb8af5":"After losing several hands of Solitaire in a row I've often wondered how sensitive the initial shuffle is to small changes. If I were to move a single card from the top to the middle, might I change a deck from a losing deck to a winning one? Or, is the winning nature in a shuffle more broad? Are there general qualities of a shuffled deck that will lead to a win regardless of a tiny change or two, like how well dispersed are the colors, or whether the card values alternate even to odd, or are bunched up in high and low value bunches.\n\nIf I could find generalization in winning decks and predict when new decks would win, the answer would be <span style='color:lightseagreen'><b>\"A. General Qualities Win\"<\/b><\/span>, but if I found no statistical similarities in winning decks, the answer would be <span style='color:lightseagreen'><b>\"B. Specific Order Wins\"<\/b><\/span>.\n\n## Data & Process: \nI created a Solitaire [program][1] in python to play Solitaire and produce 10K decks of training data with a <b>card ID<\/b> (1-52) for each of the 52 locations in a shuffled deck (e.g. column x0 = top card, x51 = bottom card), a <b>won<\/b> flag (true|false), and the <b>num_moves<\/b> (1-156) played until the deck was either won or lost.\n\nI targeted the <b>won<\/b> column with a simple Deep Model and the <b>num_moves<\/b> column with a regressor, and found NO generalizable features that helped predict either target, leading me to conclude that <span style='color:lightseagreen'><b>\"B. Specific Order Wins.\"<\/b><\/span>\nI would love to hear suggestions, and I have some specific questions at the end of the notebook. Thanks for taking a look!\n\n[1]: https:\/\/github.com\/countingpigeons\/winningdeck\/","3423c3b5":"#### 2.2 Deep model","33c0e9a6":"Baseline (ratio LOST in the test set) = .8176.\n\n<b><span style=\"color:lightseagreen\">Split looks good.<\/span><\/b> ","f0e117d2":"Tensorflow","7abeca5e":"#### 7.9 Run models","104189eb":"#### 9.3 Run models","12e5c730":"## 2. Define Utility Functions","cc1f29ae":"Tensorflow","3e6009fd":"#### 8.3 Run models","a2a8f50c":"#### 6.1 Visualize card values between pairs of positions.\nI may expect to see dark diagonal lines if certain values often appear a certain offset away in winning decks. I do <b>NOT<\/b> see this however, as this first set of charts appear pretty random.","15b37775":"Tensorflow","28254126":"## 6. Model: Value offsets between deck positions","f275ce5b":"#### 7.6 Create filter for new features","67107727":"#### 7.8 Create input arrays","52f3ea55":"AdaBoostRegressor on 'num_moves'","3ac43a28":"#### 5.2 Create new columns","132cd3f8":"#### 7.3 Add feature: color balance between alternating cards","7f0812c7":"#### 4.3 Normalize","8346c00f":"<b><span style='color:indian red; font-size:14pt'>No Signal.<\/span><\/b>","7ae12482":"#### 7.5 Add feature: color balance from top to bottom continuously","bb76edfd":"    Create feature of deck positions where winning decks diverge from expected 26.5 (blue peaks above\/below red line)","13014472":"<b><span style=\"color:indian red; font-size:14pt\">No signal.<\/span><\/b>\nNo 'fun' generalization found for these sets of training data. Model always predicts 'fun'.","6df637aa":"##### split train & test","ddc8c6a0":"##### Split train\/test","74ee3acc":"AdaBoostRegressor on 'num_moves'","729e1fe3":"<b><span style=\"color:lightseagreen; font-size:14pt\">Signal found.<\/span><\/b>\n\nThe deep model has no problem predicting won\/lost when a degraded num_moves field is added to the original 52 card index columns.","d8dbd614":"<b>RE-CODE<\/b> the input data to reflect card <b>VALUES<\/b> and <b>SUITS<\/b> instead of indexes in a factory deck.\n  \n1. create 52 <b>card value<\/b> columns with values (1-13).\n2. create 52 <b>card suit<\/b> columns with values (1-4). e.g. (\"x0_val\" [1-13], \"x0_suit\" [1-4], \"X1_val\" ...)","cada8a92":"<b><span style=\"color:indian red; font-size:14pt\">No signal.<\/span><\/b>\nStill predicting LOSE for all decks.","f1e34c6e":"#### 5.3 Add feature: deck positions where avg card diverges in winning decks","b14efc7c":"alternate y for regression on 'num_moves'","b25eaa9a":"Tensorflow","493fdb10":"### Conclusions:\n\nI believe winning decks are unique and win through sufficiently complex processes (minimum of 115 moves) that their initial states are indistiguishable.\n* Although a trained TensorFlow classifier could fully memorize the 7500 training decks and correctly classify 100% of samples pulled from within, it could not generalize to new decks with any of my feature sets.\n* The t-tests of the winning and losing means across all 'deck quality' features suggest no difference between winning and losing decks.\n* I also tried to identify just \"unplayable\" decks (those which lose after a small number of moves), with the theory that they may be a more specialized subset, but also found no signal.\n* My personal experience agrees, in that I often find a WIN comes down to a single 'linchpin' card that either breaks a logjam or fails to appear when I need it. This deck would look statistically indistiguishable from a deck where that linchpin card is offset by a single card.\n* As a final gut-check of my model, I added in a noise-degraded copy of the <b>num_moves<\/b> feature to the training data and showed 99% accuracy in classification.\n\n### Ways to improve?:\n\nI would love to hear thoughts on whether successful prediction sounds possible, and how I might improve. \n\nSome problems I see are:\n* My Solitaire playing algorithm only achieves ~18% success but research shows humans should be able to achieve [~43%][1]. If I improve the algorithm, perhaps the wider pool of winnable decks might be more generalizable? Alternatively, since I'm already winning the 'easiest' decks, I might expect this could actually hurt generalizability, since it would add more marginal decks that take more complex game play to win.\n* I am new to deep models and am using a simple input layer. Perhaps this problem would lend itself to a differently shaped input layer representing card value, suit, and location for each card, and convolutional filters akin to vision problems?\n\n[1]: http:\/\/www.jupiterscientific.org\/sciinfo\/KlondikeSolitaireReport.html","229e0a82":"#### 7.7 Summarize and visualize","a95f1445":"Polynomial versions.","cd2560a9":"#### 1.1 Libraries"}}