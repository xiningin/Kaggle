{"cell_type":{"18468749":"code","ef281836":"code","d56bf072":"code","512e2a9b":"code","32f59283":"code","894da807":"code","1ae450a0":"code","ae716a0a":"code","ff9396c6":"code","4f32500b":"code","4066499d":"code","8c0c4c12":"code","09cc86f7":"code","71d95bcb":"markdown","597a2180":"markdown","dee1e436":"markdown","959cbd25":"markdown","c14847bb":"markdown","e25b9896":"markdown","487001d0":"markdown","621d9ccc":"markdown","09987fb4":"markdown","b2f5aedf":"markdown","95090303":"markdown","8b5a796c":"markdown","36156fb0":"markdown","91cc4164":"markdown","d1069dfa":"markdown","0aaf78bd":"markdown","4c480033":"markdown","b45b8999":"markdown","47cc7a35":"markdown"},"source":{"18468749":"!pip install pyvis","ef281836":"from pyvis.network import Network\nimport networkx as nx\nimport pandas as pd\nfrom IPython.display import IFrame","d56bf072":"from pyvis.network import Network\nimport networkx as nx\nimport pandas as pd\nimport sys\n\nVERSION_DIR='\/kaggle\/input\/cord19\/drug_submission_v2.3\/'\nCONETZ_NETWORK_FILE = VERSION_DIR+'conetz.tsv'\nCONETZ_SP_NETWORK_FILE = VERSION_DIR+'conetz_specialized.tsv'\nNETWORK_FILE = CONETZ_SP_NETWORK_FILE\nENTITY_NAME_FILE = VERSION_DIR+'resources\/entity_name.tsv'\nENT_METADATA_FILE = VERSION_DIR+'resources\/entity_metadata.csv'\nent_name=None\nent_id_name=None\nent_name_id={}\nenttype_map=None\nent_cmap=None\nent_srcmap=None\nconnected_nodes=False\nnotebook_mode=True\noverlap_ents=None\nnet_options = {\n  \"nodes\": {\n    \"borderWidth\": 0,\n    \"borderWidthSelected\": 1,\n    \"scaling\": {\n      \"min\": 46\n    }\n  },\n  \"edges\": {\n    \"color\": {\n      \"inherit\": True\n    },\n    \"shadow\": {\n      \"enabled\": True\n    },\n    \"smooth\": True\n  },\n  \"interaction\": {\n    \"hover\": True,\n    \"navigationButtons\": True\n  },\n  \"physics\": {\n    \"enabled\": True,\n    \"forceAtlas2Based\": {\n      \"gravitationalConstant\": -208,\n      \"springLength\": 30\n    },\n    \"minVelocity\": 0.05,\n    \"timestep\":0.1,\n    \"solver\": \"forceAtlas2Based\"\n  }\n}","512e2a9b":"def getEntityMaps():\n    ent_meta_map = pd.read_csv(ENT_METADATA_FILE, sep=',')\n    enttype_map = ent_meta_map[['entid','enttype','entsource']]\n    \n    ent_name_df = pd.read_csv(ENTITY_NAME_FILE, sep='\\t', converters={'TypeId':str})\n    ent_name_df.TypeId=ent_name_df.TypeId.str.upper()\n    ent_name_df.Synonym=ent_name_df.Synonym.str.upper()\n    ent_name_df.DictId = ent_name_df.DictId.map(enttype_map.set_index('entid')['enttype'])\n    \n    ent_name = ent_name_df.set_index('Synonym').to_dict()\n    overlap_ents = ent_name_df[ent_name_df.Synonym.isin(ent_name_df.Synonym[ent_name_df.Synonym.duplicated()])]\n    ent_id_name = ent_name_df.set_index(['TypeId','DictId']).to_dict()\n    \n    ent_color = ent_meta_map[['enttype','entcolor']]\n    ent_cmap = ent_color.set_index('enttype').to_dict(orient='index')\n    \n    ent_source = ent_meta_map[['enttype','entsource']]\n    ent_srcmap = ent_source.set_index('enttype').to_dict(orient='index')\n    return enttype_map, ent_name, ent_id_name, overlap_ents, ent_cmap, ent_srcmap\n\ndef getNetwork():\n    nw = pd.read_csv(NETWORK_FILE,sep='\\t',converters={'src_ent':str, 'target_ent':str})\n    nw.src_type = nw.src_type.map(enttype_map.set_index('entid')['enttype'])\n    nw.target_type = nw.target_type.map(enttype_map.set_index('entid')['enttype'])\n    nw.src_ent=nw.src_ent.str.upper()\n    nw.target_ent=nw.target_ent.str.upper()\n    return nw\n\ndef buildQueryCriteria(src_ents, source_ent_types=None, target_ents=None, target_ent_types=None, \n                       queryByEntityName=True, topk=50, topkByType=None, connected_nodes=False, \n                       indirect_links=None, inference=False):\n    # Normalize it upper-case\n    src_ents = [i.strip().upper() for i in src_ents]\n    \n    criteria = {'src_ents' : src_ents,\n                'src_ent_types': source_ent_types,\n                'target_ents': target_ents,\n                'target_ent_types': target_ent_types,\n                'query_entname' : queryByEntityName,\n                'topk' : topk,\n                'topkByType' : topkByType,\n                'connected_nodes' : connected_nodes,\n                'indirect_links' : indirect_links,\n                'inference':inference\n                }\n    return criteria\n\ndef queryByEntityTypes(nw, src_ent_types, target_ent_types):\n    #Fetch the network\n    qnw=None\n    if(src_ent_types is not None):\n        qnw = nw[nw.src_type.isin(src_ent_types)]\n    if(target_ent_types is not None):\n        qnw = nw[nw.target_type.isin(target_ent_types)]\n    if(qnw is None):\n        qnw=nw\n    return qnw\n\ndef queryByEntityID(nw, src_ents, target_ents=None):\n    #Fetch the network\n    qnw = nw[nw.src_ent.isin(src_ents)]\n    if(target_ents is not None):\n        target_ents = [i.strip().upper() for i in target_ents]\n        qnw = nw[nw.target_ent.isin(target_ents)]\n    return qnw\n\ndef getEntityIds(ents):\n    # Normalize it upper-case\n    for i in ents:\n        if(i not in ent_name['TypeId']):\n            print('Term Error : Oops! Query term ['+i+'] NOT Found ')\n            print('Suggestion : Please use Type ID as query from the source DB stated in the metadata OR remove the term')\n            sys.exit(0)\n        ov = overlap_ents[overlap_ents.Synonym==i]\n        if len(ov)>1:\n            print('Entity Conflict Error : Oops! Found more than one entity type for the query term '+i)\n            print('Suggestion : Please use one of the following Type IDs as query to resolve the conflict \\n\\tand search by setting QueryByName=False : ')\n            for idx in ov.index:\n                print('\\tFor '+ov.DictId[idx]+' Dictionary; use : QueryTerms=[\\''+ov.TypeId[idx]+'\\']')\n            sys.exit(0)\n    \n    print(' Querying by Entity Name ..')\n        \n    #Get the entity triplet for the entities\n    typeids = [ent_name['TypeId'][i] for i in ents]\n    dictids = [ent_name['DictId'][i] for i in ents]\n    #Update Entity Name to Entity\/Node ID for reference\n    for i in range(len(ents)):\n        ent_name_id[ents[i]]=getNodeID(typeids[i], dictids[i])\n    return typeids, dictids\n\n\ndef queryByEntityName(nw, src_ents, target_ents=None):\n    typeids, dictids = getEntityIds(src_ents)\n    qnw = nw[nw.src_ent.isin(typeids) & (nw.src_type.isin(dictids))]\n    if(target_ents is not None):\n        target_ents = [i.upper() for i in target_ents]\n        typeids, dictids = getEntityIds(target_ents)\n        \n        qnw = nw[(nw.src_ent.isin(typeids)) & (nw.src_type.isin(dictids))]\n    return qnw\n\ndef queryTopk(nw, topk, topkByType):\n    qnw=None\n    if(topkByType!=None):\n        qnw = nw.groupby(['src_ent','target_type']).head(topkByType)\n    else:\n        qnw = nw.groupby(['src_ent','target_type']).head(topk)\n    return qnw\n\ndef queryInferredEdges(nw):\n    qnw = nw[nw.debug=='I']\n    return qnw\n\ndef queryNetwork(nw, criteria):\n    # Use the criteria to query the network by entity name\n    qnw=None\n    \n    if(criteria['query_entname']==True):\n        qnw = queryByEntityName(nw, criteria['src_ents'], target_ents=criteria['target_ents'])\n    else:\n        qnw = queryByEntityID(nw, criteria['src_ents'], target_ents=criteria['target_ents'])\n    \n    # Display only inferred edges\n    if(criteria['inference']==True):\n        qnw = queryInferredEdges(qnw)\n    else:\n        qnw = qnw[qnw.debug!='I']\n    \n    # Query by entity types\n    qnw = queryByEntityTypes(qnw, criteria['src_ent_types'], criteria['target_ent_types'])\n    \n    # Display only Top-k entites\n    qnw = queryTopk(qnw, criteria['topk'], criteria['topkByType'])\n    \n    return qnw\n\ndef getEntityNames(src, target):\n    src_name = ent_id_name['Synonym'][src]\n    target_name = ent_id_name['Synonym'][target]\n    return src_name, target_name\n\ndef getNodeID(typeid, dictid):\n    return typeid+'-'+dictid[:2]\n\ndef buildNodeAttributes(e):\n    # Build Node attributes - node_id, node_label, node_title, node_color \n    src_label, target_label = getEntityNames((e[0],e[1]), (e[2],e[3]))\n    \n    # Build src node\n    src_id = getNodeID(e[0], e[1])\n    src_title=\"<b>\"+src_label+\"<\/b><br><i>\"+e[1]+\"<br>\"+e[0]+\"<\/i><br>\"+ent_srcmap[e[1]]['entsource']\n    src_color=ent_cmap[e[1]]['entcolor']\n    \n    # Build target node\n    target_id = getNodeID(e[2], e[3])\n    target_title=\"<b>\"+target_label+\"<\/b><br><i>\"+e[3]+\"<br>\"+e[2]+\"<\/i><br>\"+ent_srcmap[e[3]]['entsource']\n    target_color=ent_cmap[e[3]]['entcolor']\n    \n    return (src_id, src_label, src_title, src_color), (target_id, target_label, target_title, target_color)\n\ndef edgeAttributes(ent1, ent2, edge_props):\n    #Build edge attributes\n    edge_title = '<b>'+ent1+' --- '+ent2+'<\/b><br>Article Evidence(s) :<br>'\n    \n    if('I' in edge_props):\n        num_arts=0\n        edge_title+='<b>Inferred from GCAS <\/b><\/i>'\n    else:\n        edge_prop_arr = edge_props.split(sep=',')\n        num_arts = int(edge_prop_arr[0])-3\n        art_type=''\n        for i in range(3, len(edge_prop_arr)):\n            art=edge_prop_arr[i].replace(\"[\",\"\")\n            art=art.replace(\"]\",\"\")\n            if(\"FT_\" in art):\n                art=art.replace(\"FT_\",\"\")\n                art_type='CORD_UID :'\n            else:\n                art_type='PUBMED_ID :'\n            edge_title+=art_type+'<i>'+art+'<\/i><br>'\n        if(num_arts>5):\n            edge_title+='and <i><b>'+str(num_arts)+'<\/b> more articles ...<\/i>'\n    \n    return edge_title\n\ndef buildGraph(G, criteria, filters=False):\n    #Define Network layout\n    net = Network(height=\"1024px\", width=\"100%\", bgcolor=\"white\", font_color=\"black\", notebook=notebook_mode)\n    net.options=net_options\n    \n    #Convert networkx G to pyvis network\n    edges = G.edges(data=True)\n    nodes = G.nodes(data=True)\n    if len(edges) > 0:\n        for e in edges:\n            snode_attr=nodes[e[0]]\n            tnode_attr=nodes[e[1]]            \n            net.add_node(e[0], snode_attr['label'], title=snode_attr['title'], color=snode_attr['color'])\n            net.add_node(e[1], tnode_attr['label'], title=tnode_attr['title'], color=tnode_attr['color'])\n            if(criteria['inference']==True):\n                net.add_edge(e[0], e[1], width=2, title=e[2]['title'])\n            else:\n                net.add_edge(e[0], e[1], value=e[2]['value'], title=e[2]['title'])\n    return net    \n\ndef applyGraphFilters(G, criteria):\n    \n    fnodes={}\n    # Filter1 - Connected nodes\n    if(criteria['connected_nodes']):    \n        bic = nx.biconnected_components(G)\n        for i in bic:\n            if(len(i)>2):\n                fnodes=i.union(fnodes)\n    \n        # Get the sub-graph after applying the filter(s)\n        G=G.subgraph(fnodes)\n    \n    # Filter2 - 'indirect_links'\n    il_dicts = criteria['indirect_links']\n    if(il_dicts is not None):    \n        snode = il_dicts['source_node'] if ('source_node' in il_dicts) else criteria['src_ents'][0]\n        snode = ent_name_id[snode.upper()]\n        #Depth=Hops+1\n        depth=(il_dicts['hops']+1) if('hops' in il_dicts) else 2\n        \n        if('target_nodes' in il_dicts):\n            tnodes = il_dicts['target_nodes']\n        elif(criteria['target_ents'] is not None):\n            tnodes = criteria['target_ents']\n        else:\n            tnodes=criteria['src_ents']        \n        tnodes = [ ent_name_id[i.upper()] for i in  tnodes]\n    \n        # Traverse k-hops from source to target nodes.            \n        paths_between_generator = nx.all_simple_paths(G, source=snode, target=tnodes, cutoff=depth)\n        indirect_paths=[]\n        i=0\n        for k, path in enumerate(paths_between_generator):\n            #if(len(path)==depth+1):\n            ce=[]\n            #print(path)\n            for j, e in enumerate(path):\n                if j+1 <= len(path)-1:\n                    ce.append((path[j], path[j+1]))\n            indirect_paths.extend(ce)\n        G=G.edge_subgraph(indirect_paths)\n    return G\n\ndef run(criteria):\n    \n    print('Building CoNetz from '+NETWORK_FILE)\n    \n    # Load the entire network\n    nw_df = getNetwork()\n\n    # Query the network with the defined search criteria\n    qnw = queryNetwork(nw_df, criteria)\n    \n    # Build association network using the query result\n    sources = qnw['src_ent']\n    source_types=qnw['src_type']\n    targets = qnw['target_ent']\n    target_types=qnw['target_type']\n    weights = qnw['score']\n    stats = qnw['debug']\n    edge_data = zip(sources, source_types, targets, target_types, weights, stats)\n\n    G=nx.Graph()\n    for e in edge_data:\n        snode, tnode = buildNodeAttributes(e)\n        G.add_node(snode[0], label=snode[1], title=snode[2], color=snode[3])\n        G.add_node(tnode[0], label=tnode[1], title=tnode[2], color=tnode[3])\n        G.add_edge(snode[0], tnode[0], value=e[4], title=edgeAttributes(snode[1],tnode[1], e[5]))\n\n    applyFilter = (criteria['connected_nodes'] or criteria['indirect_links'])\n    if(applyFilter):\n        G=applyGraphFilters(G, criteria)\n\n    net = buildGraph(G, criteria, filters=applyFilter)\n    if(criteria['inference']==True):\n        net.options['edges']['dashes']=True\n    else:\n        net.options['edges']['dashes']=False\n\n    nassocs = len(G.edges())\n    print(' Number of Associations in the Network -->'+str(nassocs))\n    if(nassocs==0):\n        print(' No Associations found for the query, Please change your Query ')\n        sys.exit(0)\n    \n    return net","32f59283":"# Prepare Entity Maps\nenttype_map, ent_name, ent_id_name, overlap_ents, ent_cmap, ent_srcmap = getEntityMaps()\n#Display Entity Types\nenttype_map","894da807":"QueryTerms=['C000657245']\ncriteria = buildQueryCriteria(QueryTerms, topkByType=15, queryByEntityName=False)\ncriteria\nnet = run(criteria)\nnet.show(\"cord19_ex1.html\")","1ae450a0":"QueryTerms=['C000657245']\ncriteria = buildQueryCriteria(QueryTerms,target_ent_types=['DRUGS','CHEMICALS'], topkByType=15, queryByEntityName=False)\ncriteria\nnet = run(criteria)\nnet.show(\"cord19_ex2.html\")","ae716a0a":"QueryTerms=['naproxen', 'clarithromycin', 'minocycline', 'covid-19']\ncriteria = buildQueryCriteria(QueryTerms, topkByType=10)\ncriteria\nnet = run(criteria)\nnet.show(\"cord19_ex3.html\")","ff9396c6":"QueryTerms=['naproxen', 'clarithromycin', 'minocycline', 'covid-19']\ncriteria = buildQueryCriteria(QueryTerms, topkByType=10, connected_nodes=True)\ncriteria\nnet = run(criteria)\nnet.show(\"cord19_ex4.html\")","4f32500b":"QueryTerms=['covid-19']\ncriteria = buildQueryCriteria(QueryTerms,target_ent_types=['DISEASE','DRUGS'], topkByType=10)\nprint(criteria)\nnet = run(criteria)\nnet.show(\"cord19_ex5.html\")","4066499d":"QueryTerms=['baricitinib','covid-19', 'ace2']\ncriteria = buildQueryCriteria(QueryTerms, topkByType=15, target_ent_types=['HGNC','DRUGS','GENE_SARS-CoV-2','ORGANISM', 'CHEMICALS', 'VIROLOGY TERMS', 'DISEASE'],\n                              indirect_links={'source_node':'covid-19', 'target_nodes':['baricitinib'], 'hops':3})\ncriteria\nnet = run(criteria)\nnet.show(\"cord19_ex6.html\")","8c0c4c12":"QueryTerms=['C000657245','D017963', 'NS8_WCPV', 'GO:0019079', 'HGNC:14512']\ncriteria = buildQueryCriteria(QueryTerms, topkByType=20, queryByEntityName=False, connected_nodes=True)\ncriteria\nnet = run(criteria)\nnet.show(\"cord19_ex7.html\")","09cc86f7":"QueryTerms=['C000657245']\ncriteria = buildQueryCriteria(QueryTerms, topkByType=40, queryByEntityName=False, inference=True)\ncriteria\nnet = run(criteria)\nnet.show(\"cord19_inference.html\")","71d95bcb":"## Analysis of Novel Drug Predictions for COVID-19\n\nThe top-40 link-predicted drugs for COVID-19 in the network are shown in Figure 3. We investigate these drugs as potential drug re-purposing candidates for COVID-19. Towards this, we perform network exploration around some of these link-predicted drugs to understand their possible mechanisms. We also identify and describe literature evidence that could support these predictions. While we provide analysis for a few of the 40 drugs, a similar analysis can be done for all 40 or any top-K drugs of ones choice. Our goal here is to illustrate the potential of the network and also enable domain experts to explore the network to generate their own hypotheses.\n\nWe now highlight some drugs connected by indirect edges to COVID-19 disease in the network. The caveat here is that since these are not direct connections, there is no reference article that talks about them. One could think of them as putative suggestions! Some text from MEDLINE abstracts about these drugs is also shown.\n\n**Ingavirin (pentanedioic acid - imidazolyl ethanamide drug combination)**\n* PMID:27876718 states \"Research objective was to study the efficacy of Ingavirin for prevention of recurrent herpetic stomatitis in employees of Kazan city industrial enterprises frequently suffering from acute respiratory viral infections. The obtained data allow to recommend ingavirin for prevention of recurrent herpetic stomatitis.\"\n* PMID:21033471 states \"Despite obvious success in the vaccine development and chemotherapy of influenza, it remains a poorly controlled infection leading to emergence of new pandemic variants of the virus with high morbidity and mortality. We investigated the protective activity of Ingavirin against the lethal influenza A (H1N1) 2009 virus infection on albino mice. Oral use of Ingavirin resulted in sharp decreasing of the mortality (index of protection up to 57%), slight decreasing of the infectious titer of the virus in the lungs ( up to 40-fold), normalizing of the body weight dynamics and the lung tissue structure vs. the placebo-treated control. The degree of the bronchial epithelium damage was also strongly decreased. The results allow to consider Ingavirin as an effective antiviral against the current pandemic influenza virus.\"\n\n**Pocapavir**\n* PMID:25229269 states \"Pocapavir (V-073) is an investigational drug candidate being developed for poliovirus indications, but also has variable antiviral activity against nonpolio enteroviruses. We describe the first use of pocapavir in treating a case of severe neonatal enteroviral sepsis due to Coxsackievirus B3.\"\n\n**R 125489 (laninamivir)**\n* PMID:28869418 says \"Laninamivir octanoate is a recently developed inhaled neuraminidase inhibitor for treating influenza virus infection\"\n* PMID:30935767 says \"Four neuraminidase (NA) inhibitors and an RNA synthesis inhibitor were recently approved and are currently in clinical use for influenza. Among NA inhibitors, oseltamivir phosphate (OSE, Tamiflu\u00ae) and zanamivir are approved worldwide, whereas peramivir and laninamivir octanoate (LAN, Inavir\u00ae) are regionally approved for human use\"\n* PMID:22028647 says \"The 2009 H1N1 influenza pandemic (pH1N1) led to record sales of neuraminidase ( NA) inhibitors, which has contributed significantly to the recent increase in oseltamivir-resistant viruses. Therefore, development and careful evaluation of novel NA inhibitors is of great interest. Recently, a highly potent NA inhibitor, laninamivir, has been approved for use in Japan.\"\n* A recent article \"PMID:32251791, A first Case of Meningitis\/Encephalitis associated with SARS-Coronavirus-2\"(not in the corpus) mentions Laninamivir in the context of meningitis in a COVID-19 patient.\n\n**Peficitinib (an oral Janus Kinase Inhibitor)**\n* PMID:31093950 says \"Peficitinib [Smyraf\u00ae (Astellas Pharma)] is a Janus kinase (JAK)1, JAK2, JAK3 and tyrosine kinase (Tyk)2 (pan-JAK) inhibitor recently approved in Japan for the treatment of rheumatoid arthritis. Inhibition of JAK suppresses the activation of cytokine signalling pathways involved in inflammation and joint destruction in rheumatoid arthritis.\"\n* PMID:31181818 mentions \"Conclusion: Peficitinib suppressed the JAK- STAT pathway in RA FLS and also suppressed monocyte chemotaxis and proliferation of FLS through inhibition of inflammatory cytokines\"\n\n**Paritaprevir**\n* PMID:32108916 says \"Elimination of the virus with direct-acting antivirals (DAAs) may modify host immune response via altering these immune checkpoint receptors' expression. We conducted a prospective study to analyze changes in TIM-3, PD-1 and their ligands galectin-9, PD-L1 expression by peripheral blood T cell subpopulations, NK cell subpopulations, and monocytes by multicolor flow cytometry in 14 CHC patients successfully treated with 12 weeks of dasabuvir, ombitasvir, and paritaprevir\/ ritonavir plus ribavirin.Our data suggest that DAA treatment not only inhibits viral replication but may alter host adaptive and innate immune responses.\"\n* PMID:28680834 says \"DAAs inhibit specific HCV non-structural proteins (NS) that are vital for its replication. Boceprevir, telaprevir, simeprevir, asunaprevir, grazoprevir and paritaprevir are NS3\/4A inhibitors.\"\n* In fact, a recent article \"PMID:32266873, Targeting SARS-CoV-2: A Systematic Drug Repurposing Approach to Identify Promising Inhibitors Against 3C-like Proteinase and 2'-O-RiboseMethyltransferase.\"(not in the corpus) mentions Paritaprevir as a potential drug COVID-19, thus showing the potential value of inference!\n\n#### For detailed analysis, please refer to our chemrxiv submission at https:\/\/chemrxiv.org\/articles\/Text_and_Network-Mining_for_COVID-19_Intervention_Studies\/12234564","597a2180":"# DISCUSSION\nOur contributions are multi-fold:\n1. Build a pair-wise association network covering a comprehensive set of biomedical entity types extracted from the provided corpus. We also experimented with augmenting the provided corpus with related MEDLINE abstracts.\n2. Mine for novel inferred associations from the whole MEDLINE and augment the network with these to help in better identification of good drug and vaccine targets.\n3. Provide an intuitive and interactive graphical exploration of the network using PyVis. We provide a Jupyter notebook for this. To illustrate the utility of the notebook, we have included a set of use cases for exploring the network using PyVis and NetworkX library.\n4. To answer specific as well as general questions pertinent to this task.\n\nThe network captures associations between different entities in the augmented corpus described earlier. The network nodes correspond to the biological entities and the edges correspond to the associations. The edges are weighted where the edge weight denote the strength of association (correlation strength in this network) between the entity pair. The inferred associations from MEDLINE are also included in the network with additional flags. The entities span a comprehensive set of entity types, namely HUMAN_GENE, GENE_SARS, GENE_MERS, GENE_COVID, PHENOTYPE, CHEMICALS, DRUGS, DISEASE, SYMPTOM, GOPROC, GOFUNC, GOLOC, CELLTYPE, TISSUE, ANATOMY, ORGANISM, COUNTRIES, ETHICS TERMS, NON-PHARMA INTERVENTION, SURVEILLANCE TERMS, VACCINE TERMS, VIROLOGY TERMS and EARTH SCIENCE TERMS.\n\nThe network is compatible with the NetworkX package. User can identify a network node (biological entity) either by its \"term name\" or the entity ID in its source DB The ID here is its public ID as present in the public data source from which its source dictionary was built. For instance, the Human Gene dictionary was built using HGNC. Hence, in order to query for \"ACE2\", one could either search using the the common term name \"ACE2\" or its HGNC ID \"HGNC:13557\". We have listed the public data sources for each of the entity types which would help the user to figure out the entity ID\/term name to be used for querying. There are few terms in the dictionaries that are inserted manually. These terms can be searched only by the term name. Furthermore, dictionaries for COUNTRIES, ETHICS TERMS, NON-PHARMA INTERVENTION, SURVEILLANCE TERMS, VACCINE TERMS, VIROLOGY TERMS and EARTH SCIENCE TERMS have been built from public sources as well as with some manual updates specifically for this CORD19 challenge. Hence, searching the network for these entity types can be done preferably through querying using term name rather than IDs as few of the network entities have only internal IDs and no public IDs.\n\nAn important aspect to be noted is the absence of normalization when building this network, resulting in a potential bias. This is because the provided corpus is highly specific to \"COVID-19\" disease articles. Though the associations are extracted based on co-occurrences of the entities in these articles, their association strength could be biased due to the limited nature of the corpus. In the subsequent releases, we would be broadening the scope of the network and also be incorporating weight normalizations based on a more comprehensive collection of articles.\n\nIn future, associations from high quality and heterogeneous curated data with sufficient coverage can be considered for augmenting the network derived solely from text-mining. These could be from sources such as IntAct **(4)**. Of course, experiments would need to be done to analyse the effects of addition of such curated associations to text-mined associations in these kinds of networks.\n\n## REFERENCES\n1. Joseph T, Saipradeep VG, Raghavan GS, Srinivasan R, Rao A, Kotte S, Sivadasan N. TPX: Biomedical literature search made easy. Bioinformation 8(12): 578-80 (2012).\n2. Rao A, Vg S, Joseph T, Kotte S, Sivadasan N, Srinivasan R. Phenotype-driven gene prioritization for rare diseases using graph convolution on heterogeneous networks. BMC Med Genomics. 2018 Jul 6;11(1):57.\n3. Rao A, Joseph T, Saipradeep VG, Kotte S, Sivadasan N, Srinivasan R. PRIORI-T: a tool for rare disease gene prioritization using MEDLINE. PLOS One (In Press).\n4. Hermjakob H et al., IntAct: an open source molecular interaction database. Nucleic Acids Res. 2004; 32(Database issue): D452\u2013D455.","dee1e436":"***\n#### Search by text term : Connecting nodes\/associations for Covid19, Naproxen, Clarithromycin and Minocycline","959cbd25":"Define your Queries - Query by Keyword (text term)","c14847bb":"***\n#### Search by text term : Top-15 Diseases and Drugs for Covid19","e25b9896":"### The Code below accepts user's input and build the search criteria.  \n*Copy the Below code into a code cell to execute it offline on your desktop\/laptop. \nTo execute the code with multiple queries, rerun the code cell using Shift+Enter*\n\n```python\n\nqry_str = input(\"Please enter the source Entities (separted by comma):\\n\")\nqterms=qry_str.split(',')\n\nqname = input(\"Query By Entity Name :[Y\/N] \\n\")\nqent_name= True if(\"Y\"==qname.upper()) else False\n\nprint('Enter Optional parameters ')\n\ntgt_qt = input(\"\\t Please enter the target Entity Types (separted by comma):\\n\")\ntent_types=tgt_qt.split(',') if(tgt_qt!='') else None\n\ntk_str = input(\"\\tRestrict the network to Top-k entities :(press enter for default : 15) \\n\")\ntk = int(tk_str) if(tk_str!='') else 15\n\ntke_str = input(\"\\tRestrict the network to Top-k entities for each Type :] \\n\")\ntke = int(tke_str) if(tke_str!='') else None\n    \nie = input(\"\\tShow only inferred edges from GCAS : [Y\/N] \\n\")\ninf= True if(\"Y\"==ie.upper()) else False\n\ncn = input(\"\\tShow only connected nodes in the network : [Y\/N] \\n\")\ncnodes= True if(\"Y\"==cn.upper()) else False\n\ncriteria = buildQueryCriteria(qterms, target_ent_types=tent_types, topk=tk, topkByType=tke, queryByEntityName=qent_name, inference=inf, connected_nodes=cnodes)\n\nnet = run(criteria)\nnet.show(\"cord19_user_qry.html\")\n```","487001d0":"Helper Functions","621d9ccc":"Import all the needed python libraries","09987fb4":"### Query the CoNetz with your own Queries","b2f5aedf":"***\n#### Search by MeshID : Top-15 Drugs and Chemicals for Covid19","95090303":"Define global variables","8b5a796c":"Previously, we had highlighted Drugs Associated with COVID-19 from Literature. \n1. **Well-known** drug re-purposing candidates for COVID-19 in CoNetz include **remdesivir, hydroxychloroquine and lopinavir-ritonavir combination, as well as convalescent plasma therapy** to were seen to be strongly associated with COVID-19 disease node. \n2. **Lesser known** drug leads such as **ciclesonide, baricitinib, fedratinib, tocilizumab and arbidol** are also connected to the COVID-19 node. \n3. **Alternative medicines** mentioned in literature in the context of COVID-19 include **astragali radix, shufeng jiedu and lianhuaqingwen.** \n\nThe Top-15 chemicals and drugs directly associated with COVID-19 disease are shown in the above **Figure**. This shows the presence of high quality association neighbors in the network within the top-K neighborhood. Let's look at evidences for some of these chemicals and drugs:\n\n**Tocilizumab**: Supported by PMID:32240462, CORD_UID:yy7abob9, PMID:32241792, PMID:32222713, PMID:32209313 and PMID:32243501\n* PMID:32209313: New therapeutic opportunities for COVID-19 patients with Tocilizumab: Possible correlation of interleukin-6 receptor inhibitors with osteonecrosis of the jaw\n* PMID:32240462: Coronavirus disease 2019 (COVID-19): a clinical update. The efficacy of some promising antivirals, convalescent plasma transfusion, and tocilizumab needs to be investigated by ongoing clinical trials.\n\n**Arbidol**: Supported by PMID:32147628, PMID:32171872, CORD_UID:zwqci59h, CORD_UID:5pfusktn, PMID:32037389, CORD_UID:7e8zlt3t\n* PMID:32147628 Several drugs such as chloroquine, arbidol, remdesivir, and favipiravir are currently undergoing clinical studies to test their efficacy and safety in the treatment of coronavirus disease 2019 (COVID-19) in China; some promising results have been achieved thus far.\n\n**Convalescent plasma**: Supported by PMID:32240549, PMID:32219429, PMID:32240462, PMID:32219428, PMID:32220178, PMID:32240545\n* PMID:32219428 In this preliminary uncontrolled case series of 5 critically ill patients with COVID-19 and ARDS, administration of convalescent plasma containing neutralizing antibody was followed by improvement in their clinical status.\n* PMID:32240549  The recent Coronavirus Disease 2019 (COVID-19) pandemic caused by SARS-CoV-2 has prompted not only a search for effective anti-viral treatment and spread control measures, but also a reconsideration of the use of convalescent plasma for COVID-19 treatment [5, 6].\n\n**Chloroquine**: Supported by PMID:32219882, PMID:32217113, PMID:32219357, PMID:32074550, PMID:32179150, PMID:32212513\n* PMID:32179150 Chloroquine, remdesivir, lopinavir, ribavirin or ritonavir have shown efficacy to inhibit coronavirus in vitro.\n\n***\n**Prominent Alternative Medicine Chemicals and Drugs**\n* **Shufeng jiedu**, supported by articles CORD_UID:0xhho1sh, CORD_UID:k2ixwz9w, CORD_UID:msohf5oa, PMID:32037389, CORD_UID:ptnmtvzj and CORD_UID:athjtu2j\n* **Lianhuaqingwen**, supported by CORD_UID:szsb1oan, CORD_UID:bep0xtxa, PMID:31996494, PMID:32205232, CORD_UID:x23ej29m and CORD_UID:h72w22rm\n","36156fb0":"***\n#### Multi-hop queries\n\nNeighbourhood network constructed based on the query with entity terms (baricitinib, covid-19 and ace2) and with three additional filters, namely,\n1. Only entity types ( 'HGNC','DRUGS','GENE_SARS-CoV-2','ORGANISM', 'CHEMICALS', 'VIROLOGY TERMS', 'DISEASE'),\n1. For each query entity, restrict it's neighbourhood to the Top-15 neighbours for each of the filtered entity types and\n1. Retain only those entities in the neighbourhood that appear in a multi-hop (simple) path (no more than 3 hops) from 'covid-19' to 'baricitinib'.","91cc4164":"Correlations from the full-text article **\"38d6gb7o\"** from the CORD-19 corpus show:\n* **Azithromycin---COVID-19**\n\"Similarly, antibiotics like azithromycin have also been mooted as treatments for COVID-19.\"\n\"While this too remains to be demonstrated, we note that Azithromycin has off-target activity against human mitochondrial ribosomes, components of which interact with the SARS-CoV-2 Nsp8 protein (MRPS5, MRPS27, MRPS2, and MRPS25).\"\n* This second sentence also gives us **Azithromycin---mitochondrial ribosomes, Azithromycin---MRPS27** and **Nsp8---MRPS27** edges\n* Finally, viral replication---COVID-19 is got from the paragraph \".................stress granules and host translation shutoff 55 . This functionality seems to benefit viral ....are targeted by several SARS-CoV-2 viral proteins. Interestingly, ...  ....stress granules and host translation shutoff. This functionality seems to benefit viral replication, as stress granules are inhibitory to replication of MERS-CoV 56 and other viruses\"\n\nA separate search of PubMed results in some abstracts not in the corpus that support the correlations mentioned above:\n* From **PMID:32229706**: \"Similarly, two proposed therapeutics for the treatment of COVID-19 infection are **Azithromycin** and Quercetin, both drugs with significant senolytic activity. As Azithromycin and Doxycycline are both commonly used antibiotics that **inhibit viral replication** and IL-6 production, we may want to consider this general class of antibiotics that functionally inhibits cellular protein synthesis as a side-effect, for the treatment and prevention of COVID-19 disease.\"\n* From **PMID:30918070**: \"Replacement of a conserved Lys residue with Ala abolished the in vitro RNA-binding and TATase activities of **nsp8** and caused a nonviable phenotype when the corresponding mutation was introduced into the HCoV-229E genome, confirming that these activities are mediated by **nsp8** and critical for **viral replication**. While confirming the critical role of nsp8 in coronavirus replication, the study amends the list of activities mediated by coronavirus nsp8 proteins in the absence of other proteins.\"\n* From **PMID:30135128**: \"We also hypothesize that the primase-like protein **Nsp8** and the Nsp7\/**Nsp8** complex may interact with Nsp15 and affect enzymatic activity. This contributes to the understanding of the association of **Nsp15** with the **viral replication** and transcription machinery.\"","d1069dfa":"***\n#### Search by MeshID : Covid19 Top-15 Entities","0aaf78bd":"Install needed packages","4c480033":"***\n#### Search by multiple text terms : Top-15 Entities for Covid19 with Naproxen, Clarithromycin and Minocycline","b45b8999":"***\n#### Using Sub-Networks to understand Drug mechanisms and Disease action\n\nWe now show the utility of connections between different entity types using sub-networks. These could provide a deeper understanding of drug mechanisms, disease action etc. An important caveat to analysing such sub-networks - each edge or connection was derived from a particular paragraph of the article(s) in the corpus - hence the correlation is only in that context.\n\nLet's take the example where we look for connections between the drug azithromycin, non-structural proteins - Nsp8, Nsp15, human mitochondrial ribosomal protein S27 (MRPS27) and their possible role in viral repliction\/viral genome replication: ","47cc7a35":"***\n# CoNetz\n***\n## HIGHLIGHTS\nThis submission used the power of network based analysis for rapid identification of potential new drugs and vaccines. Text and network mining techniques are employed to build a comprehensive network of relations between a vast variety of biological entities. The tools allow easy exploration and visualization of the network for generation of leads. The submission utilizes both the CORD-19 corpus as well as all of MEDLINE.\n\n \n\nSome of the immediate insights derived in the context of COVID 19:\n1. Drugs such as Ciclesonide, Selamectin, Baricitinib, Fedratinib, Tocilizumab, Arbidol and Chloroquine, as well as Convalescent plasma therapy.\n2. Prominent alternative medicines such as Astragali radix, Shufeng jiedu and Lianhuaqingwen.\n3. Novel leads for re-purposing including Ingavirin (pentanedioic acid-imidazolyl ethanamide combination), Pocapavir, R 125489 (Laninamivir), Peficitinib (an oral Janus Kinase Inhibitor) and Paritaprevir.\n\nSeveral use cases to explore leads are illustrated. We encourage the community to leverage the power of this network and its easy to use Python interface, for this task and beyond.\n\n## INTRODUCTION\nSince the outbreak of the COVID-19 pandemic, there has been a massive pursuit by the research community to find drugs to treat this disease as well as discover vaccines against the disease. A large number of research papers have been published to this end, peer-reviewed as well as those posted in preprint repositories such as bioRxiv (www.bioRxiv.org) and medRxiv (www.medRxiv.org). In addition, a large number of peer-reviewed papers on earlier coronavirus-related diseases such as SARS and MERS are also available.\n\nThe COVID-19 Open Research Dataset (CORD-19 corpus) consists of abstracts and full-text articles on COVID-19, SARS-CoV-2, and related coronaviruses. This freely available dataset is provided to the global research community via this Kaggle challenge to apply recent advances in natural language processing (NLP) and other related techniques to generate insights in support of the ongoing fight against this infectious disease.\n\nAt a specific level, it means we have to help uncover **\"*unknown known*\"** entities such as drugs and vaccines that are maybe unknown to the larger set of researchers but mentioned in specific scientific article(s) part of the CORD-19 dataset. Our goal is to help the medical research community uncover these \"unknown known\" entities through a combination of text-mining and network analyses.\n\n## APPROACH SUMMARY\n### Association Network Creation\nWe had earlier built a framework for NLP called TPX, a web-based text-mining tool that supports real-time entity assisted search and navigation of the MEDLINE repository whilst continuing to use PubMed as the underlying search engine **(1)**. TPX is a modular and versatile biomedical text-mining framework. For instance, we recently built PRIORI-T **(2)**, a pipeline for phenotype-driven rare disease gene prioritization, by re-purposing specific modules of TPX. The modules include:\n1. Dictionary Curation module\n2. Annotator for entity annotations\n3. MEDLINE Processor\n4. Network Creation module, to build a heterogeneous network of the correlations extracted by the Correlation Extraction module\n5. Network Augmentation module, to augment the network with novel links inferred using a graph convolution-based approach\n\nWe re-purposed TPX for the COVID-19 Open Research Dataset Challenge (CORD-19) as follows:\n1.  We took the provided CORD19 dataset corpus and filtered these for unique full-text articles. We used the Corpus Processor module of TPX to process this corpus. We also considered the complete MEDLINE abstracts which was used by the network augmentation module to augment the network with inferred novel connections.\n2.  The Annotator module of TPX performed the annotation on the corpus based on the following dictionaries: HUMAN_GENE, GENE_SARS, GENE_MERS, GENE_COVID, PHENOTYPE, CHEMICALS, DRUGS, DISEASE, SYMPTOM, GOPROC, GOFUNC, GOLOC, CELLTYPE, TISSUE, ANATOMY, ORGANISM, COUNTRIES, ETHICS TERMS (general terms related to human ethics), NON-PHARMA INTERVENTION (terms related to non-pharmaceutical intervention), SURVEILLANCE TERMS (general terms related to disease surveillance), VACCINE TERMS, VIROLOGY TERMS (general terms used in virology studies) and EARTH SCIENCE TERMS.\n3.  We then used the Correlation Extraction module to extract out correlations amongst these entity types and\n4.  These correlations extracted by the Correlation Extraction module are then used by the Network Creation module to build a network called **TCS\\_COVID\\_NETWORK**. This network can is queried to obtain information and pointers from the corpus.\n\nThus, the TCS\\_COVID\\_NETWORK serves as a knowledge base that could help the COVID-19 research community to obtain pointers for useful relations spanning several entity types through a combination of text-mining and network analyses. We have uploaded the network in Kaggle for download and use by the community for solving some of text mining related questions that are posed in this Kaggle challenge\n\n### PyVis Visualization\nWe then used PyVis, a Python-based library for constructing and visualizing an intuitive and interactive exploration of TCS\\_COVID\\_NETWORK. The Jupyter notebook provides details on this. For instructive purpose and to exhibit the utility of the network-based approach, we have included a set of use cases. These use cases show different ways of exploring the network using PyVis and NetworkX library to find useful insights. These cases are by no means exhaustive. However, the PyVis and NetworkX functionalities can be easily used to provide and\/or build richer exploration features using our underlying network.\n\nThe Figure below depicts the overall approach.\n\n![Kaggle_pipeline_initial.png](attachment:Kaggle_pipeline_initial.png)\n\n## APPROACH DETAILS\n### Corpus preprocessing and augmentation\n\n**CORD-19 corpus preprocessing**\nAs part of the corpus-preprocessing we removed unwanted characters such as white spaces and html codes. We de-duplicated the corpus to remove duplicate articles.\n\n**Incorrectly annotated COVID19 articles:**: We found that the sentence *\"publicly funded repositories, such as the WHO COVID database with rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.\"* was included at the begining of 380 articles sourced from Elsevier in the corpus. Many of these articles are actually not relevant to COVID-19 and seem to have come into the corpus because of this one sentence. In such articles, there is only a single mention of COVID-19 in the above sentence. We removed this sentence from the articles.\n\nWhile in the previous version of our submission, only the \"title\" and \"abstract\" sections, we now process the COMPLETE corpus of full-text of articles. Only **Foreign Language Articles** were excluded from the corpus. The CORD-19 corpus contains full-text foreign language articles, including those in Spanish, French and German. While these did not adversely affect the overall quality of TCS\\_COVID\\_NETWORK, a few false-positives were observed. Hence, we excluded a total of 854 such foreign language articles.\n\nAfter the clean-up, we segregated the article text into various spans, which included sentence, section, paragraph and the full article.\n\n**Augmenting the corpus with related MEDLINE abstracts**: While the provided CORD-19 corpus is an excellent source of COVID-19 articles, we experimented to see if there are any related MEDLINE abstracts that could possibly be added to the corpus to improve the precision and recall. Towards this, we filtered the entire tagged MEDLINE for abstracts containing the terms \"coronavirus infection\", SARS, MERS or COVID-19 or their synonyms. As a result, we identified a subset of MEDLINE abstracts that could be used to augment the CORD-19 corpus. **To reiterate**: the provided CORD-19 corpus is the principal data source for our submission. However, we found additional useful COVID-19 related abstracts in MEDLINE.\n\n### NER Annotator\nWe used lexicon (dictionary)-based NER annotator to tag the text. The annotator takes care of local abbreviations.\n\nAfter tagging, we used the **Conflict Resolver** to resolve conflicts arising from the same text getting annotated by different dictionaries. The order followed was \"DISEASE\" > \"SYMPTOM\" > \"PHENOTYPE\" > \"HGNC\" > \"GENE-COVID\" >\"GENE-SARS\" >\"GENE-MERS\" > \"VACCINETERMS\" > \"DRUGS\" > \"CHEMICALS\" > \"GO_PROCESS\" > \"GO_FUNCTION\" > \"GO_LOCATION\" > \"CELLTYPE\" > \"TISSUE\" > \"ANATOMY\" > \"VIROLOGYTERMS\" > \"NONPHARMAINTERVENTIO\" > \"SURVEILLANCETERMS\" > \"ETHICSTERMS\" > \"COUNTRIES\" > \"EARTHSCIENCETERMS\"\n\n### Correlation Extraction\nThe Correlation Extraction module uses the Pearson correlation coefficient to compute pairwise correlations between entities identified by the Annotator. To compute the pair-wise correlation for a pair, we used the standard Pearson correlation expression. These probability values are estimated from the corpus. We experimented with computing pair-wise correlations using different text spans: sentence, paragraph, section and article. Based on our evaluation, we found the correlations computed at the paragraph level to strike a good balance of precision and recall. We used these associations to build the basic TCS\\_COVID\\_NETWORK. Here, the biological entities are the nodes and the pair-wise correlations are represented using undirected weighted edges where the edge weight corresponds to the correlation strength.\n\n### Network Augmentation\nThe correlation-based network was further augmented with additional inferred novel links using a graph convolution based technique. These links have no co-occurrence-based support from the corpus. However, such novel links are equally crucial in identifying important drugs, genes etc.,for the drug development, repurposing and vaccine development tasks. We had previously developed a graph convolution-based association inferencing algorithm GCAS (Graph Convolution based Association Scoring) in the context of network-based study of rare-diseases **(3)**. Our approach is motivated by the recent progress in spectral graph convolutions, where association inferencing is viewed as a mult-step signal propagation over the network by convolving the network with a filter.\n\nOne of the primary goals of our submission is to provide a high quality and a user friendly network-based abstraction of the given corpus to explore interesting connections between several entity types. However, capturing novel connections are equally crucial for identifying useful targets for drugs and vaccines. We believe that to achieve this, we need to go beyond the provided corpus and consider the complete MEDLINE and other data sources. Our network augmentation task is a step in this direction. Our final framework would thus capture highly relevant relations from COVID-19 related corpus and would also mine for additional novel associations from the whole of MEDLINE. Both these knowledge bases are then combined to complement each other so as to amplify the signal and to reduce the overall noise.\n\nIn the current submission, we have combined these knowledge bases (networks) in a simple manner. We however exhibit its use through some interesting use cases. Future submissions would provide enhancements to improve the overall quality.\n\n## RESULTS\nWe now describe how this network can be used to answer some of the questions posed in the challenge using a network exploration  and PyVis visualization approach."}}