{"cell_type":{"3dfefdda":"code","0680e2ee":"code","a00e2089":"code","344c8198":"code","263c7bd3":"code","f4b83ae9":"code","9243644f":"code","5d022389":"code","3abb3dbf":"code","7ebf17ba":"code","87b93d0d":"code","ecbbf16d":"code","d3091a46":"code","9da76240":"code","acf8f160":"code","5a0ffa13":"code","c7906961":"code","5c412fb6":"code","6e2cecef":"code","681fc0a8":"code","ad25600c":"code","60eeb400":"markdown","0c84d61f":"markdown","023802c9":"markdown","f8217b51":"markdown","5752e371":"markdown","dcff8108":"markdown"},"source":{"3dfefdda":"import tensorflow as tf\nimport numpy as np\nimport os\nimport glob\nimport matplotlib.pyplot as plt\n%matplotlib inline","0680e2ee":"img = glob.glob('..\/input\/cityscapes\/Cityspaces\/images\/train\/*\/*.png') # tf.io.glob.glob\nlabel = glob.glob('..\/input\/cityscapes\/Cityspaces\/gtFine\/train\/*\/*_gtFine_labelIds.png')\nimg_names = [path.split('\/train\/')[1].split('_leftImg8bit.png')[0] for path in img]\nlabel = ['..\/input\/cityscapes\/Cityspaces\/gtFine\/train\/' + name + '_gtFine_labelIds.png' for name in img_names]\n\nlen(img)","a00e2089":"index = np.random.permutation(2975)\nimg = np.array(img)[index]\nlabel = np.array(label)[index]\n\nimg[:5], label[:5]","344c8198":"val_img = glob.glob('..\/input\/cityscapes\/Cityspaces\/images\/val\/*\/*.png') # tf.io.glob.glob\nval_label = glob.glob('..\/input\/cityscapes\/Cityspaces\/gtFine\/val\/*\/*_gtFine_labelIds.png')\nimg_names = [path.split('\/val\/')[1].split('_leftImg8bit.png')[0] for path in val_img]\nval_label = ['..\/input\/cityscapes\/Cityspaces\/gtFine\/val\/' + name + '_gtFine_labelIds.png' for name in img_names]\n\nlen(val_img), len(val_label)","263c7bd3":"train_ds = tf.data.Dataset.from_tensor_slices((img, label))\nval_ds = tf.data.Dataset.from_tensor_slices((val_img, val_label))","f4b83ae9":"def read_png(img):\n    img = tf.io.read_file(img)\n    img = tf.image.decode_png(img, channels=3)\n    return img\n    \ndef read_png_label(img):\n    img = tf.io.read_file(img)\n    img = tf.image.decode_png(img, channels=1)\n    return img","9243644f":"def rand_crop(img, label):\n    concat_img = tf.concat([img, label], axis=-1)\n    concat_img = tf.image.resize(concat_img, [280, 560], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    crop_img = tf.image.random_crop(concat_img, [256, 256, 4])\n    return crop_img[:, :, :3], crop_img[:, :, 3:]\n\ndef norm(img, label):\n    img = tf.cast(img, tf.float32)\/127.5-1\n    label = tf.cast(label, tf.int32)\n    return img, label","5d022389":"def load_img_train(img, label):\n    img = read_png(img)\n    label = read_png_label(label)\n    \n    img, label = rand_crop(img, label)\n    \n    if tf.random.uniform(()) > 0.5:\n        img = tf.image.flip_left_right(img)\n        label = tf.image.flip_left_right(label)\n    return norm(img, label)\n\ndef load_img_val(img, label):\n    img = read_png(img)\n    label = read_png_label(label)\n    \n    img = tf.image.resize(img, [256, 256])\n    label = tf.image.resize(label, [256, 256])\n    return norm(img, label)","3abb3dbf":"BATCH_SIZE = 32\nBUFFER_SIZE = 300\nsteps_per_epoch = 2975 \/\/ BATCH_SIZE\nvalidation_steps = 500 \/\/ BATCH_SIZE\nauto = tf.data.experimental.AUTOTUNE\n\ntrain_ds = train_ds.map(load_img_train, num_parallel_calls=auto)\nval_ds = val_ds.map(load_img_val, num_parallel_calls=auto)","7ebf17ba":"for img, label in val_ds.take(1):\n    plt.subplot(1, 2, 1)\n    plt.imshow((img + 1)\/2)\n    plt.subplot(1, 2, 2)\n    plt.imshow(np.squeeze(label))","87b93d0d":"train_ds = train_ds.cache().repeat().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(auto)\nval_ds = val_ds.cache().batch(BATCH_SIZE)","ecbbf16d":"def create_model():\n    inputs = tf.keras.layers.Input(shape=(256, 256, 3))\n    \n    x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(inputs)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n    x = tf.keras.layers.BatchNormalization()(x) # 256*256*64\n    \n    x1 = tf.keras.layers.MaxPooling2D(padding='same')(x) # 128*128*64\n    \n    x1 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x1)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x1 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x1)\n    x1 = tf.keras.layers.BatchNormalization()(x1)  # 128*128*128\n    \n    x2 = tf.keras.layers.MaxPooling2D(padding='same')(x1) # 64*64*128\n    \n    x2 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x2)\n    x2 = tf.keras.layers.BatchNormalization()(x2)\n    x2 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x2)\n    x2 = tf.keras.layers.BatchNormalization()(x2)  # 64*64*256\n    \n    x3 = tf.keras.layers.MaxPooling2D(padding='same')(x2) # 32*32*256\n    \n    x3 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu')(x3)\n    x3 = tf.keras.layers.BatchNormalization()(x3)\n    x3 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu')(x3)\n    x3 = tf.keras.layers.BatchNormalization()(x3)  # 32*32*512\n    \n    x4 = tf.keras.layers.MaxPooling2D(padding='same')(x3) # 16*16*512\n    \n    x4 = tf.keras.layers.Conv2D(1024, 3, padding='same', activation='relu')(x4)\n    x4 = tf.keras.layers.BatchNormalization()(x4)\n    x4 = tf.keras.layers.Conv2D(1024, 3, padding='same', activation='relu')(x4)\n    x4 = tf.keras.layers.BatchNormalization()(x4)  # 16*16*1024\n    \n    x5 = tf.keras.layers.Conv2DTranspose(512, 2, strides=2, padding='same', activation='relu')(x4)\n    x5 = tf.keras.layers.BatchNormalization()(x5)  # 32*32*512\n    \n    x6 = tf.concat([x3, x5], axis=-1) # 32*32*1024\n    \n    x6 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu')(x6)\n    x6 = tf.keras.layers.BatchNormalization()(x6)\n    x6 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu')(x6)\n    x6 = tf.keras.layers.BatchNormalization()(x6)  # 32*32*512\n    \n    x7 = tf.keras.layers.Conv2DTranspose(256, 2, strides=2, padding='same', activation='relu')(x6)\n    x7 = tf.keras.layers.BatchNormalization()(x7)  # 64*64*256\n    \n    x8 = tf.concat([x2, x7], axis=-1) # 64*64*512\n    \n    x8 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x8)\n    x8 = tf.keras.layers.BatchNormalization()(x8)\n    x8 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x8)\n    x8 = tf.keras.layers.BatchNormalization()(x8)  # 64*64*256\n    \n    x9 = tf.keras.layers.Conv2DTranspose(128, 2, strides=2, padding='same', activation='relu')(x8)\n    x9 = tf.keras.layers.BatchNormalization()(x9)  # 128*128*128\n    \n    x10 = tf.concat([x1, x9], axis=-1) # 128*128*256\n    \n    x10 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x10)\n    x10 = tf.keras.layers.BatchNormalization()(x10)\n    x10 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x10)\n    x10 = tf.keras.layers.BatchNormalization()(x10)  # 128*128*128\n    \n    x11 = tf.keras.layers.Conv2DTranspose(64, 2, strides=2, padding='same', activation='relu')(x10)\n    x11 = tf.keras.layers.BatchNormalization()(x11)  # 256*256*64\n    \n    x12 = tf.concat([x, x11], axis=-1) # 256*256*128\n    \n    x12 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x12)\n    x12 = tf.keras.layers.BatchNormalization()(x12)\n    x12 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x12)\n    x12 = tf.keras.layers.BatchNormalization()(x12)  # 256*256*64\n    \n    outputs = tf.keras.layers.Conv2D(34, 1, activation='softmax')(x12) # 256*256*34\n    \n    return tf.keras.Model(inputs=inputs, outputs=outputs)","d3091a46":"model = create_model()\nmodel.summary()","9da76240":"tf.keras.utils.plot_model(model)","acf8f160":"# tf.keras.metrics.MeanIoU(num_classes=34) <- One-Hot Coding\n\nclass MeanIoU(tf.keras.metrics.MeanIoU):\n    def __call__(self, y_true, y_pred, sample_weight=None):\n        y_pred = tf.argmax(y_pred, axis=-1)\n        return super().__call__(y_true, y_pred, sample_weight=sample_weight)","5a0ffa13":"model.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy', \n              metrics=['acc'])","c7906961":"history = model.fit(train_ds, steps_per_epoch=steps_per_epoch, validation_data=val_ds, validation_steps=validation_steps, epochs=50)","5c412fb6":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure()\nplt.plot(range(50), loss, 'r', label='Training Loss')\nplt.plot(range(50), val_loss, 'bo', label='Validation Loss')\nplt.title('Training & Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\n\nplt.legend()\nplt.show()","6e2cecef":"num = 3\n\nfor img, label in val_ds.take(1):\n    pred_label = model.predict(img)\n    pred_label = tf.argmax(pred_label, axis=-1)\n    pred_label = pred_label[..., tf.newaxis]\n    \n    plt.figure(figsize=(10, 10))\n    for i in range(num):\n        plt.subplot(num, 3, i*num+1)\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(img[i]))\n        plt.subplot(num, 3, i*num+2)\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(label[i]))\n        plt.subplot(num, 3, i*num+3)\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(pred_label[i]))","681fc0a8":"for img, label in train_ds.take(1):\n    pred_label = model.predict(img)\n    pred_label = tf.argmax(pred_label, axis=-1)\n    pred_label = pred_label[..., tf.newaxis]\n    \n    plt.figure(figsize=(10, 10))\n    for i in range(num):\n        plt.subplot(num, 3, i*num+1)\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(img[i]))\n        plt.subplot(num, 3, i*num+2)\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(label[i]))\n        plt.subplot(num, 3, i*num+3)\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(pred_label[i]))","ad25600c":"model.save('MyUNet.h5')","60eeb400":"## Analysis of the Training","0c84d61f":"## Data Augmentation\n\n1. tf.image.flip_left_right()\n2. crop (tf.concat()) \n\netc. (Randomly)","023802c9":"## Define the U-Net Model","f8217b51":"**Pre-Shuffle the Data so as to Reduce the Buffer Size (for smaller-Size CPU & GPU)**","5752e371":"## Compile the Model","dcff8108":"## Read the Datasets"}}