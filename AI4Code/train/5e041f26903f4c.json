{"cell_type":{"fcbeb036":"code","e57cd8ef":"code","5f7a7fd1":"code","56789127":"code","651c4498":"code","2d652370":"code","65c037e0":"code","5d06b3c4":"code","5f208723":"code","7c417c55":"code","3a908010":"code","6be7d14c":"code","e9b541b0":"code","6857ffe8":"code","34b9f858":"code","7e1d0e78":"code","ae34a16f":"code","b4bf7194":"code","4510a868":"code","9954bc6b":"code","1482c1ab":"code","99037054":"code","934e688c":"code","a7d737d1":"code","9b5b6534":"code","2f2e74c2":"code","da21162a":"code","8b0bb568":"code","e2fb9456":"code","a4476274":"markdown","09bb3ff5":"markdown","e49c780e":"markdown","06f95f57":"markdown","96245d8b":"markdown","bdddd9ac":"markdown","6de2f3c3":"markdown","ebd4b986":"markdown","43985d0d":"markdown"},"source":{"fcbeb036":"# Setup plotting\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\n# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('animation', html='html5')\n\n# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.deep_learning_intro.ex5 import *\n\n# Setup AI libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nsns.set()\nfrom scipy.stats import skew\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.model_selection import GroupShuffleSplit\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\nfrom keras.callbacks import EarlyStopping\nfrom keras.metrics import RootMeanSquaredError\nfrom keras.optimizers import Adam\nfrom keras_tuner.tuners import RandomSearch","e57cd8ef":"# load data\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n\ny = train.pop('SalePrice').values # store the target for later\ndata = pd.concat([train,test],axis=0,sort=False)\ndata","5f7a7fd1":"# EDA\n\n# removing unnecessary features\ndata = data.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n\n# adding new features based on combinations of existing ones\ndata['YrBltAndRemod']=data['YearBuilt']+data['YearRemodAdd']\ndata['TotalSF']=data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']\ndata['Total_sqr_footage'] = data['BsmtFinSF1'] + data['BsmtFinSF2'] + data['1stFlrSF'] + data['2ndFlrSF']\ndata['Total_porch_sf'] = data['OpenPorchSF'] + data['3SsnPorch'] + data['EnclosedPorch'] + data['ScreenPorch'] + data['WoodDeckSF']\ndata['Total_Bathrooms'] = data['FullBath'] + (0.5 * data['HalfBath']) + data['BsmtFullBath'] + (0.5 * data['BsmtHalfBath'])\n\n# adding has\/hasnot features based on existing ones\ndata['haspool'] = data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\ndata['has2ndfloor'] = data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ndata['hasgarage'] = data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\ndata['hasbsmt'] = data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\ndata['hasfireplace'] = data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","56789127":"# default handling for missing values\n'''\n# get missing values\nmissing_values = data.isnull().sum()\nmissing_values = missing_values[missing_values > 0].sort_values(ascending = False)\nNAN_col = list(missing_values.to_dict().keys())\n\n# handle missing values\nfor col in NAN_col:\n    if data[col].dtype == 'object':\n        data[col].fillna('Unknown',inplace=True)\n    else:\n        data[col].fillna(data[col].mean(),inplace=True)\ndata\n'''","651c4498":"# Fill NANs\n\n# Filling columns with their most suitable values\ndata['Functional'] = data['Functional'].fillna('Typ')\ndata['Electrical'] = data['Electrical'].fillna(\"SBrkr\")\ndata['KitchenQual'] = data['KitchenQual'].fillna(\"TA\")\n\n# Where NANs mean 0\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    data[col] = data[col].fillna(0)\n\n# Filling these with mode() - the most frequent value in these columns\ndata['Exterior1st'] = data['Exterior1st'].fillna(data['Exterior1st'].mode()[0])\ndata['Exterior2nd'] = data['Exterior2nd'].fillna(data['Exterior2nd'].mode()[0])\ndata['SaleType'] = data['SaleType'].fillna(data['SaleType'].mode()[0])\n\n# Fill according to their grouping\ndata['MSZoning'] = data.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\ndata['LotFrontage'] = data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n\n# Replace remaining categorical NANs with 'None'\nobjects = []\nfor i in data.columns:\n    if data[i].dtype == object:\n        objects.append(i)\ndata.update(data[objects].fillna('None'))\n\n# Replace remaining numerical NANs with 0\nnum_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumericals = []\nfor i in data.columns:\n    if data[i].dtype in num_dtypes:\n        numericals.append(i)\ndata.update(data[numericals].fillna(0))","2d652370":"'''\n# get the numeric and categorical features\nall_feats = data.dtypes.index.tolist()\nfeatures_num = data.dtypes[data.dtypes != \"object\"].index.tolist()\nfeatures_cat = list(set(all_feats) - set(features_num))\n\n# handle unknown category values in the validation dataset (could have done instead handle_unknown='ignore', but would miss out on data points)\nunique_cats = list()\nfor cat in features_cat:\n    unique_cats.append(list(data[cat].unique()))\n\n# prepare to transform the data\npreprocessor = make_column_transformer(\n    (StandardScaler(), features_num),\n    (OneHotEncoder(categories=unique_cats), features_cat),\n)\n'''","65c037e0":"# Fix skewed numerical values with boxcox transform\nskew_features = data[numericals].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nfor i in skew_index:\n    data[i] = boxcox1p(data[i], boxcox_normmax(data[i] + 1))","5d06b3c4":"# convert numerical category features to categorical features (eg. years; quasi binary stuff like nr rooms, fireplaces, garage cars, &c)\ndata['MSSubClass'] = data['MSSubClass'].astype(str)\ndata['YrSold'] = data['YrSold'].astype(str)\ndata['MoSold'] = data['MoSold'].astype(str)\ndata['GarageYrBlt'] = data['GarageYrBlt'].astype(str)\ndata['GarageCars'] = data['GarageCars'].astype(str)\ndata['YrBltAndRemod'] = data['YrBltAndRemod'].astype(str)\ndata['YearBuilt'] = data['YearBuilt'].astype(str)\ndata['YearRemodAdd'] = data['YearRemodAdd'].astype(str)\ndata['Total_Bathrooms'] = data['Total_Bathrooms'].astype(str)\ndata['FullBath'] = data['FullBath'].astype(str)\ndata['HalfBath'] = data['HalfBath'].astype(str)\ndata['BsmtFullBath'] = data['BsmtFullBath'].astype(str)\ndata['BsmtHalfBath'] = data['BsmtHalfBath'].astype(str)\ndata['TotRmsAbvGrd'] = data['TotRmsAbvGrd'].astype(str)\ndata['BedroomAbvGr'] = data['BedroomAbvGr'].astype(str)\ndata['KitchenAbvGr'] = data['KitchenAbvGr'].astype(str)\ndata['Fireplaces'] = data['Fireplaces'].astype(str)","5f208723":"# one hot encoding\ndata = pd.get_dummies(data)","7c417c55":"# separate the train n test data\ntrain = data[:train.shape[0]].copy()\ntest = data[train.shape[0]:].copy()\ntrain['SalePrice'] = y\ntrain","3a908010":"# Find top features\ntop_features = train.corr()[['SalePrice']].sort_values(by=['SalePrice'],ascending=False).head(30)\nplt.figure(figsize=(5,10))\nsns.heatmap(top_features,cmap='rainbow',annot=True,annot_kws={\"size\": 16},vmin=-1)","6be7d14c":"def plot_data(col, discrete=False):\n    if discrete:\n        fig, ax = plt.subplots(1,2,figsize=(14,6))\n        sns.stripplot(x=col, y='SalePrice', data=train, ax=ax[0])\n        sns.countplot(train[col], ax=ax[1])\n        fig.suptitle(str(col) + ' Analysis')\n    else:\n        fig, ax = plt.subplots(1,2,figsize=(12,6))\n        sns.scatterplot(x=col, y='SalePrice', data=train, ax=ax[0])\n        sns.distplot(train[col], kde=False, ax=ax[1])\n        fig.suptitle(str(col) + ' Analysis')","e9b541b0":"plot_data('OverallQual', True)","6857ffe8":"clf = IsolationForest(max_samples = 100, random_state = 42)\nclf.fit(train)\ny_noano = clf.predict(train)\ny_noano = pd.DataFrame(y_noano, columns = ['Top'])\ny_noano[y_noano['Top'] == 1].index.values\n\ntrain = train.iloc[y_noano[y_noano['Top'] == 1].index.values]\ntrain.reset_index(drop = True, inplace = True)\nprint(\"Number of Outliers:\", y_noano[y_noano['Top'] == -1].shape[0])\nprint(\"Number of rows without outliers:\", train.shape[0])","34b9f858":"# scale the training features\nx = train.copy()\nx.drop(['SalePrice'],axis=1,inplace=True)\ny = train['SalePrice'].values\n\nscaler = StandardScaler()\nx = scaler.fit_transform(x)","7e1d0e78":"'''\n# hand-built model\ninput_shape = x.shape[1]\n\nmodel = keras.Sequential([\n    layers.Dense(256, activation='relu', input_shape=[input_shape]),\n    layers.Dropout(0.3),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(32, activation='relu'),\n    layers.Dense(1),\n])\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.01),\n    loss='mse'\n)\n\n# early stopping\nearly_stop = EarlyStopping(\n    patience=20,\n    restore_best_weights=True\n)\n'''","ae34a16f":"'''\nfitted = model.fit(\n    x=x,\n    y=y,\n    validation_split=0.2,\n    batch_size=128,\n    epochs=500,\n    callbacks=[early_stop],\n    verbose=0\n)\n\nhistory_df = pd.DataFrame(fitted.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot();\nprint(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))\n'''","b4bf7194":"'''def build_model(hp):\n    model = keras.Sequential()\n    model.add(layers.Dense(units=hp.Int('dense_0', min_value=32 , max_value=512 , step=32), activation='relu', input_shape=[x.shape[1]]))\n    for i in range(hp.Int('layers', 1, 9)):\n        model.add(layers.Dense(units=hp.Int(f'dense_{i+1}', min_value=32 , max_value=512 , step=32), activation='relu'))\n        #model.add(layers.Dropout(hp.Float(f'dropout_{i}', 0, 0.5, step=0.1)))\n    model.add(layers.Dense(1))\n    \n    model.compile(\n        optimizer=Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n        loss='mse',\n        metrics=['mse']\n    )\n    return model\n\ntuner = RandomSearch(\n    build_model,\n    objective='val_mse',\n    max_trials=10,\n    executions_per_trial=3,\n    directory='model_dir',\n    project_name='House_Price_Prediction')\ntuner.search_space_summary()'''","4510a868":"#tuner.search(x[1100:],y[1100:],batch_size=128,epochs=200,validation_data=(x[:1100],y[:1100]))\n#model = tuner.get_best_models(1)[0]","9954bc6b":"#model.summary()","1482c1ab":"#tuner.results_summary()","99037054":"'''# recreating the tuned model\ninput_shape = x.shape[1]\n\ntuned_model = keras.Sequential([\n    layers.Dense(128, activation='relu', input_shape=[input_shape]),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(480, activation='relu'),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(448, activation='relu'),\n    layers.Dense(256, activation='relu'),\n    layers.Dense(32, activation='relu'),\n    layers.Dense(1),\n])\n\ntuned_model.compile(\n    optimizer=Adam(learning_rate=0.01),\n    loss='mse',\n    metrics=['mse']\n)\n\n# early stopping\nearly_stop = EarlyStopping(\n    patience=20,\n    restore_best_weights=True\n)'''","934e688c":"'''# recreating the tuned model after EDA\ninput_shape = x.shape[1]\n\ntuned_model = keras.Sequential([\n    layers.Dense(416, activation='relu', input_shape=[input_shape]),\n    layers.Dense(224, activation='relu'),\n    layers.Dense(480, activation='relu'),\n    layers.Dense(320, activation='relu'),\n    layers.Dense(320, activation='relu'),\n    layers.Dense(320, activation='relu'),\n    layers.Dense(416, activation='relu'),\n    layers.Dense(192, activation='relu'),\n    layers.Dense(256, activation='relu'),\n    layers.Dense(1),\n])\n\ntuned_model.compile(\n    optimizer=Adam(learning_rate=0.01),\n    loss='mse',\n    metrics=['mse']\n)\n\n# early stopping\nearly_stop = EarlyStopping(\n    patience=20,\n    restore_best_weights=True\n)'''","a7d737d1":"'''tuned_fitted = tuned_model.fit(\n    x=x,\n    y=y,\n    validation_split=0.25,\n    batch_size=128,\n    epochs=500,\n    callbacks=[early_stop],\n    verbose=0\n)'''","9b5b6534":"'''tuned_history_df = pd.DataFrame(tuned_fitted.history)\ntuned_history_df.loc[:, ['loss', 'val_loss']].plot();\nprint(\"Minimum validation loss: {0:.3g}\".format(tuned_history_df['val_loss'].min()))'''","2f2e74c2":"#tuned_model.evaluate(x,y)","da21162a":"'''\n    RETUNE THE MODEL AFTER EVERY CHANGE TO THE DATASET\n\n    No EDA:\n        - Minimum validation loss: 1.74e+09\n    EDA:\n        - Minimum validation loss: 1.98e+09\n'''","8b0bb568":"'''\nx_test = scaler.transform(test)\nresult = tuned_model.predict(x_test)\nresult = pd.DataFrame(result,columns=['SalePrice'])\nresult.head()\nresult['Id'] = test['Id']\nresult = result[['Id','SalePrice']]\nresult\n'''","e2fb9456":"#result.to_csv('submission.csv',index=False)","a4476274":"### Outliers","09bb3ff5":"# House Prices with Keras\n\nSolving the house prices prediction problem with a keras neural network custom solution, inspired by this [notebook](https:\/\/www.kaggle.com\/pratiyushmishra\/house-predictions-keras\/data#Prediction-&-Evaluation) and the EDA from this [kernel](https:\/\/www.kaggle.com\/niteshx2\/top-50-beginners-stacking-lgb-xgb\/notebook#Now-,-we-are-getting-started-with-the-process-of-modelling).\n\nThe neural network is built using keras_tuner's RandomSearch.\n\n### Future Improvements If Necessary\n- Improved EDA\n    - classifying some numerical features as categorical\n    - labelling categorical NANs differently according to the most suitable values for each column\n    - adding relevant columns (eg. HasPool=1 if PoolArea>0)\n    - removing data outliers\n","e49c780e":"## Dependencies","06f95f57":"### Apply model to test data","96245d8b":"## Pre Processing\n\n#### Possible Improvements:\n- handling outliers with Isolation Forest","bdddd9ac":"#### Building the actual model using keras_tuner:","6de2f3c3":"The hand-built model built below was never used afterwards, as the tuned model surpassed it.","ebd4b986":"## Model","43985d0d":"For time saving, the model has been tuned beforehand, resulting in the model recreated below."}}