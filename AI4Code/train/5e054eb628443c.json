{"cell_type":{"6a5a2fb3":"code","a041a8f2":"code","53fa58d1":"code","42976bd7":"code","322d6b9a":"code","68979221":"code","3ea11b4a":"code","0549c5b3":"code","4b26405f":"code","49b32ff0":"code","a52f5a28":"code","0400ba1c":"code","85a4ff83":"code","021e7e2b":"code","00ffaad8":"code","68b0f75d":"code","dc246a89":"code","1144c211":"code","d69e4fe9":"code","e9c16570":"code","ea6aead7":"code","2e329819":"code","a19181b8":"code","6df1e27d":"code","a10dd651":"code","82e086fc":"code","65b085b2":"code","0902346c":"code","8fcfc897":"code","4a4005b6":"code","026ad466":"markdown","a6e3d7f0":"markdown","47e9a6b2":"markdown","5891a797":"markdown","8fc6eae6":"markdown"},"source":{"6a5a2fb3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport nltk\nimport string\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom sklearn.linear_model import LogisticRegressionCV,SGDClassifier\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import TreebankWordTokenizer\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom sklearn.svm import SVC\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom wordcloud import WordCloud\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n# Any results you write to the current directory are saved as output.","a041a8f2":"train_df = pd.read_csv('..\/input\/train.csv')","53fa58d1":"train_df.head()","42976bd7":"train_df['president'].value_counts().plot(kind = 'bar')\nplt.show()","322d6b9a":"train_data = []\nfor i, row in train_df.iterrows():\n    for text in row['text'].split('.'):\n        train_data.append([row['president'], text])\ntrain_data = pd.DataFrame(train_data, columns=['president', 'text'])","68979221":"train_data['president'].value_counts().plot(kind = 'bar')\nplt.show()","3ea11b4a":"train_data.head()","0549c5b3":"def remove_punctuation_numbers(text):\n    punc_numbers = string.punctuation + '0123456789'\n    return ''.join([l for l in text if l not in punc_numbers])","4b26405f":"def tokeniser(text):\n    return TreebankWordTokenizer().tokenize(text)","49b32ff0":"def lemmetizer(tokens):\n    wordnet_lemmatizer = WordNetLemmatizer()\n    return [wordnet_lemmatizer.lemmatize(word) for word in tokens]","a52f5a28":"def remove_stop_words(tokens):\n    return [t for t in tokens if t not in set(stopwords.words('english'))]","0400ba1c":"def data_cleaner(text):\n    text = text.lower()\n    text = remove_punctuation_numbers(text)\n    lst = tokeniser(text)\n    lst = remove_stop_words(lst)\n    return ' '.join(lemmetizer(lst))","85a4ff83":"train_data['clean_text'] = train_data['text'].apply(data_cleaner)","021e7e2b":"train_data.head()","00ffaad8":"for pres in train_data['president'].unique():\n    words =[]\n    for sentence in train_data[train_data['president'] == pres].clean_text:\n        words.extend(tokeniser(sentence))\n    \n    wordcloud = WordCloud().generate_from_frequencies(frequencies=Counter(words))\n    plt.figure(figsize=(12,8))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title(pres)\n    plt.show()","68b0f75d":"train_data.president = train_data.president.map({'deKlerk':0,'Mandela':1,\n                                                'Mbeki':2, 'Motlanthe':3,\n                                                'Zuma': 4, 'Ramaphosa':5})","dc246a89":"X = train_data.clean_text\ny = train_data.president\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.33,\n                                                    random_state=0,\n                                                    stratify=y)","1144c211":"vect = CountVectorizer(ngram_range=(1,2))","d69e4fe9":"X_train_ = vect.fit_transform(X_train)","e9c16570":"log = LogisticRegressionCV(dual=False, penalty='l2', multi_class='multinomial')","ea6aead7":"log.fit(X_train_, y_train)","2e329819":"print(accuracy_score(y_train, log.predict(X_train_)))","a19181b8":"print(accuracy_score(y_test, log.predict(vect.transform(X_test))))","6df1e27d":"test_data = pd.read_csv('..\/input\/test.csv')","a10dd651":"test_data.head()","82e086fc":"test_data.text = test_data.text.apply(data_cleaner)","65b085b2":"test_data['president'] = log.predict(vect.transform(test_data.text))","0902346c":"test_data.drop('text', axis=1, inplace=True,)","8fcfc897":"test_data.head()","4a4005b6":"test_data.to_csv('Thapelo_log.csv',index=False)","026ad466":"##### Data cleaning","a6e3d7f0":"According to most, if not all languages, sentences are distinguished by a period. So let's split the sentences by a period.","47e9a6b2":" ######  Lets have a look at how many of the different  we have data for","5891a797":"#### Lets see if we can reveal words that are moslty used by each president.","8fc6eae6":"#######To the modelling we go!!!!!"}}