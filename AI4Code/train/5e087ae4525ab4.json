{"cell_type":{"d9dccbb1":"code","e6bed549":"code","1ee7daf5":"code","70c661a9":"code","647a636e":"code","a9f13ceb":"code","486d331c":"code","8e3276ff":"code","0563672b":"code","9c447650":"code","d701a70c":"code","5bd595ef":"code","dd6d0d61":"code","8a3f25b9":"code","5425a7e1":"code","4891f233":"code","7bcd09e5":"code","f24fac69":"code","2987c97c":"code","6994cb19":"code","2d7d0c4d":"code","43c2fbe5":"code","60b26515":"code","62cb3530":"code","597b751f":"code","9651b6d1":"code","0b053626":"code","5dcd062d":"code","90c1e91c":"code","3c86ccdb":"code","e9e555d9":"code","5f9e6d21":"code","8139b08e":"code","9070186c":"code","f13d4407":"code","db3be4ed":"code","6923fc98":"code","440534f6":"code","4d3af062":"code","a5d25cd9":"code","3120bdfd":"code","7426ca0f":"code","db17013c":"code","8907b720":"code","016335c8":"code","ce95629d":"code","4447e9e5":"code","36460ae4":"code","05737358":"code","fc5865fd":"code","28e1fa95":"code","5adc076e":"code","d20d13f8":"code","539a0a3d":"code","6a6d2211":"code","0f073ff7":"code","241c84c9":"code","310a720e":"code","f416a13f":"code","a8068d92":"code","a58deb14":"code","6d80d922":"code","a8d1fe55":"code","3e8ed98a":"code","8a53459a":"code","77c9e10f":"code","60980632":"code","e83fb387":"code","1c934a4b":"code","5f24679c":"code","3c6cd2a7":"code","058ef53c":"code","3bef9ea6":"code","c278b801":"code","76d76000":"code","b0ed2dca":"code","d21ddf4f":"code","55841c24":"code","de606a85":"code","31835c23":"code","c0459a03":"markdown","424f5640":"markdown","5d96a44b":"markdown","a98a596c":"markdown","fd694afb":"markdown","33f88499":"markdown","9e9107e7":"markdown","3fb90759":"markdown","9cee3884":"markdown","673c61cf":"markdown","fe0f7b10":"markdown","7236ec70":"markdown","cb794337":"markdown","5a029747":"markdown","9ec2d74d":"markdown","c9fdc22e":"markdown","736baf20":"markdown","905db530":"markdown","b9ef17a9":"markdown","96898e18":"markdown","b9141a36":"markdown","4e5776f4":"markdown","9f1bd3b9":"markdown","0b080661":"markdown","d12d97aa":"markdown","633c3f5d":"markdown","c823919a":"markdown","098980b2":"markdown","aff878cf":"markdown","66c753dc":"markdown","5532b14b":"markdown","b3f469b0":"markdown","04f29145":"markdown","e467cbc8":"markdown","645d0b6b":"markdown","db38a50e":"markdown","937b5c28":"markdown","e12a04f4":"markdown","b9b5ce8d":"markdown","df347008":"markdown","be7a7d20":"markdown","13365de7":"markdown","2f88366b":"markdown","2ca37a79":"markdown","dabb76d5":"markdown","ad082007":"markdown","099c9ed9":"markdown","c95fad65":"markdown","b9cb1683":"markdown","97936309":"markdown","a2d7ba01":"markdown","ea7d2646":"markdown","a3c6ef6d":"markdown","9027c11b":"markdown"},"source":{"d9dccbb1":"import gc\nimport os\nimport warnings\nimport operator\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nfrom wordcloud import WordCloud, STOPWORDS\nimport gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom nltk.stem import WordNetLemmatizer, SnowballStemmer\nfrom nltk.stem.porter import *\nimport nltk\nfrom gensim import corpora, models\nimport pyLDAvis\nimport pyLDAvis.gensim\nfrom keras.preprocessing.text import Tokenizer\n\npyLDAvis.enable_notebook()\nnp.random.seed(2018)\nwarnings.filterwarnings('ignore')","e6bed549":"%%time\nJIGSAW_PATH = \"..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/\"\ntrain = pd.read_csv(os.path.join(JIGSAW_PATH,'train.csv'), index_col='id')\ntest = pd.read_csv(os.path.join(JIGSAW_PATH,'test.csv'), index_col='id')","1ee7daf5":"train.head()","70c661a9":"test.head()","647a636e":"print(\"Train and test shape: {} {}\".format(train.shape, test.shape))","a9f13ceb":"plt.figure(figsize=(12,6))\nplt.title(\"Distribution of target in the train set\")\nsns.distplot(train['target'],kde=True,hist=False, bins=120, label='target')\nplt.legend(); plt.show()","486d331c":"def plot_features_distribution(features, title):\n    plt.figure(figsize=(12,6))\n    plt.title(title)\n    for feature in features:\n        sns.distplot(train.loc[~train[feature].isnull(),feature],kde=True,hist=False, bins=120, label=feature)\n    plt.xlabel('')\n    plt.legend()\n    plt.show()","8e3276ff":"features = ['severe_toxicity', 'obscene','identity_attack','insult','threat']\nplot_features_distribution(features, \"Distribution of additional toxicity features in the train set\")","0563672b":"features = ['asian', 'black', 'jewish', 'latino', 'other_race_or_ethnicity', 'white']\nplot_features_distribution(features, \"Distribution of race and ethnicity features values in the train set\")","9c447650":"features = ['female', 'male', 'transgender', 'other_gender']\nplot_features_distribution(features, \"Distribution of gender features values in the train set\")","d701a70c":"features = ['bisexual', 'heterosexual', 'homosexual_gay_or_lesbian', 'other_sexual_orientation']\nplot_features_distribution(features, \"Distribution of sexual orientation features values in the train set\")","5bd595ef":"features = ['atheist','buddhist',  'christian', 'hindu', 'muslim', 'other_religion']\nplot_features_distribution(features, \"Distribution of religion features values in the train set\")","dd6d0d61":"features = ['intellectual_or_learning_disability', 'other_disability', 'physical_disability', 'psychiatric_or_mental_illness']\nplot_features_distribution(features, \"Distribution of disability features values in the train set\")","8a3f25b9":"def plot_count(feature, title,size=1):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(train))\n    g = sns.countplot(train[feature], order = train[feature].value_counts().index[:20], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()   ","5425a7e1":"plot_count('rating','rating')","4891f233":"plot_count('funny','funny votes given',3)","7bcd09e5":"plot_count('wow','wow votes given',3)","f24fac69":"plot_count('sad','sad votes given',3)","2987c97c":"plot_count('likes','likes given',3)","6994cb19":"plot_count('disagree','disagree given',3)","2d7d0c4d":"features = ['sexual_explicit']\nplot_features_distribution(features, \"Distribution of sexual explicit values in the train set\")","43c2fbe5":"stopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=50,\n        max_font_size=40, \n        scale=5,\n        random_state=1\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(10,10))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","60b26515":"show_wordcloud(train['comment_text'].sample(20000), title = 'Prevalent words in comments - train data')","62cb3530":"show_wordcloud(train.loc[train['insult'] < 0.25]['comment_text'].sample(20000), \n               title = 'Prevalent comments with insult score < 0.25')","597b751f":"show_wordcloud(train.loc[train['insult'] > 0.75]['comment_text'].sample(20000), \n               title = 'Prevalent comments with insult score > 0.75')","9651b6d1":"show_wordcloud(train.loc[train['threat'] < 0.25]['comment_text'], \n               title = 'Prevalent words in comments with threat score < 0.25')","0b053626":"show_wordcloud(train.loc[train['threat'] > 0.75]['comment_text'], \n               title = 'Prevalent words in comments with threat score > 0.75')","5dcd062d":"show_wordcloud(train.loc[train['obscene']< 0.25]['comment_text'], \n               title = 'Prevalent words in comments with obscene score < 0.25')","90c1e91c":"show_wordcloud(train.loc[train['obscene'] > 0.75]['comment_text'], \n               title = 'Prevalent words in comments with obscene score > 0.75')","3c86ccdb":"show_wordcloud(train.loc[train['target'] > 0.75]['comment_text'], \n               title = 'Prevalent words in comments with target score > 0.75')","e9e555d9":"show_wordcloud(train.loc[train['target'] < 0.25]['comment_text'], \n               title = 'Prevalent words in comments with target score < 0.25')","5f9e6d21":"def preprocess(text):\n    result = []\n    for token in gensim.utils.simple_preprocess(text):\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2:\n            result.append(token)\n    return result","8139b08e":"comment_sample = train['comment_text'][:1].values[0]\nprint('Original comment: {}'.format(comment_sample))\nprint('Tokenized comment: {}'.format(preprocess(comment_sample)))","9070186c":"%%time\npreprocessed_comments = train['comment_text'].sample(200000).map(preprocess)","f13d4407":"preprocessed_comments.sample(3)","db3be4ed":"%%time\ndictionary = gensim.corpora.Dictionary(preprocessed_comments)\ndictionary.filter_extremes(no_below=10, no_above=0.5, keep_n=75000)","6923fc98":"%%time\nbow_corpus = [dictionary.doc2bow(doc) for doc in preprocessed_comments]\ntfidf = models.TfidfModel(bow_corpus)\ncorpus_tfidf = tfidf[bow_corpus]","440534f6":"%%time\nlda_model = gensim.models.LdaMulticore(corpus_tfidf, num_topics=20,\n                                    id2word=dictionary, passes=2, workers=2)","4d3af062":"topics = lda_model.print_topics(num_words=5)\nfor i, topic in enumerate(topics[:10]):\n    print(\"Train topic {}: {}\".format(i, topic))","a5d25cd9":"bd5 = bow_corpus[5]\nfor i in range(len(bd5)):\n    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bd5[i][0], dictionary[bd5[i][0]],bd5[i][1]))","3120bdfd":"for index, score in sorted(lda_model[bd5], key=lambda tup: -1*tup[1]):\n    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 5)))","7426ca0f":"vis = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)","db17013c":"pyLDAvis.save_html(vis, \"LDAVis_train.html\")","8907b720":"#vis","016335c8":"def topic_sentences(ldamodel=lda_model, corpus=bow_corpus, \\\n                        texts=preprocessed_comments):\n    # initialization\n    sent_topics_df = pd.DataFrame()\n\n    # get main topic in each comment\n    for i, row in enumerate(ldamodel[corpus]):\n        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n        # get the dominanttopic, % contribution and keywords for each document\n        for j, (topic_num, prop_topic) in enumerate(row):\n            if j == 0:  # => dominant topic\n                wp = ldamodel.show_topic(topic_num)\n                topic_keywords = \", \".join([word for word, prop in wp])\n                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4),\\\n                                                                topic_keywords]), ignore_index=True)\n            else:\n                break\n    text = pd.Series(texts)\n    sent_topics_df = pd.concat([sent_topics_df, text], axis=1)\n    return(sent_topics_df)","ce95629d":"topic_sents_keywords = topic_sentences(ldamodel=lda_model, corpus=bow_corpus, \\\n                                                  texts=preprocessed_comments)\ndominant_topic =topic_sents_keywords.reset_index()\ndominant_topic.columns = ['Comment', 'Dominant Topic', 'Topic Percent Contribution', 'Keywords','Text']\ndominant_topic.head(5)","4447e9e5":"%%time\npreprocessed_comments = test['comment_text'].map(preprocess)\ndictionary = gensim.corpora.Dictionary(preprocessed_comments)\ndictionary.filter_extremes(no_below=10, no_above=0.5, keep_n=75000)\nbow_corpus = [dictionary.doc2bow(doc) for doc in preprocessed_comments]\ntfidf = models.TfidfModel(bow_corpus)\ncorpus_tfidf = tfidf[bow_corpus]","36460ae4":"%%time\nlda_model = gensim.models.LdaMulticore(corpus_tfidf, num_topics=20,\n                                    id2word=dictionary, passes=2, workers=2)","05737358":"topics = lda_model.print_topics(num_words=5)\nfor i, topic in enumerate(topics[:10]):\n    print(\"Test topic {}: {}\".format(i, topic))","fc5865fd":"vis = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)\npyLDAvis.save_html(vis, \"LDAVis_test.html\")","28e1fa95":"#vis","5adc076e":"EMBED_SIZE = 300 # size of word vector; this should be set to 300 to match the embedding source\nMAX_FEATURES = 100000 # how many unique words to use (i.e num rows in embedding vector)\nMAXLEN = 220 # max length of comments text","d20d13f8":"def build_vocabulary(texts):\n    \"\"\"\n    credits to: https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-when-using-embeddings \n    credits to: https:\/\/www.kaggle.com\/anebzt\/quora-preprocessing-model\n    input: list of list of words\n    output: dictionary of words and their count\n    \"\"\"\n    sentences = texts.apply(lambda x: x.split()).values\n    vocab = {}\n    for sentence in tqdm_notebook(sentences):\n        for word in sentence:\n            try:\n                vocab[word] += 1\n            except KeyError:\n                vocab[word] = 1\n    return vocab","539a0a3d":"# populate the vocabulary\ndf = pd.concat([train ,test], sort=False)\nvocabulary = build_vocabulary(df['comment_text'])","6a6d2211":"# display the first 10 elements and their count\nprint({k: vocabulary[k] for k in list(vocabulary)[:10]})","0f073ff7":"def load_embeddings(file):\n    \"\"\"\n    credits to: https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-when-using-embeddings \n    credits to: https:\/\/www.kaggle.com\/anebzt\/quora-preprocessing-model\n    input: embeddings file\n    output: embedding index\n    \"\"\"\n    def get_coefs(word,*arr): \n        return word, np.asarray(arr, dtype='float32')\n    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n    return embeddings_index","241c84c9":"%%time\nGLOVE_PATH = '..\/input\/glove840b300dtxt\/'\nprint(\"Extracting GloVe embedding started\")\nembed_glove = load_embeddings(os.path.join(GLOVE_PATH,'glove.840B.300d.txt'))\nprint(\"Embedding completed\")","310a720e":"len(embed_glove)","f416a13f":"def embedding_matrix(word_index, embeddings_index):\n    '''\n    credits to: https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-when-using-embeddings \n    credits to: https:\/\/www.kaggle.com\/anebzt\/quora-preprocessing-model\n    input: word index, embedding index\n    output: embedding matrix\n    '''\n    all_embs = np.stack(embeddings_index.values())\n    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n    EMBED_SIZE = all_embs.shape[1]\n    nb_words = min(MAX_FEATURES, len(word_index))\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, EMBED_SIZE))\n    for word, i in tqdm_notebook(word_index.items()):\n        if i >= MAX_FEATURES:\n            continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\n    return embedding_matrix","a8068d92":"def check_coverage(vocab, embeddings_index):\n    '''\n    credits to: https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-when-using-embeddings \n    credits to: https:\/\/www.kaggle.com\/anebzt\/quora-preprocessing-model\n    input: vocabulary, embedding index\n    output: list of unknown words; also prints the vocabulary coverage of embeddings and the % of comments text covered by the embeddings\n    '''\n    known_words = {}\n    unknown_words = {}\n    nb_known_words = 0\n    nb_unknown_words = 0\n    for word in tqdm_notebook(vocab.keys()):\n        try:\n            known_words[word] = embeddings_index[word]\n            nb_known_words += vocab[word]\n        except:\n            unknown_words[word] = vocab[word]\n            nb_unknown_words += vocab[word]\n            pass\n    print('Found embeddings for {:.3%} of vocabulary'.format(len(known_words)\/len(vocab)))\n    print('Found embeddings for {:.3%} of all text'.format(nb_known_words\/(nb_known_words + nb_unknown_words)))\n    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n    return unknown_words","a58deb14":"print(\"Verify the intial vocabulary coverage\")\noov_glove = check_coverage(vocabulary, embed_glove)","6d80d922":"oov_glove[:10]","a8d1fe55":"def add_lower(embedding, vocab):\n    '''\n    credits to: https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-when-using-embeddings \n    credits to: https:\/\/www.kaggle.com\/anebzt\/quora-preprocessing-model\n    input: vocabulary, embedding matrix\n    output: modify the embeddings to include the lower case from vocabulary\n    '''\n    count = 0\n    for word in tqdm_notebook(vocab):\n        if word in embedding and word.lower() not in embedding:  \n            embedding[word.lower()] = embedding[word]\n            count += 1\n    print(f\"Added {count} words to embedding\")","3e8ed98a":"train['comment_text'] = train['comment_text'].apply(lambda x: x.lower())\ntest['comment_text'] = test['comment_text'].apply(lambda x: x.lower())","8a53459a":"print(\"Check coverage for vocabulary with lower case\")\noov_glove = check_coverage(vocabulary, embed_glove)\nadd_lower(embed_glove, vocabulary) # operates on the same vocabulary\noov_glove = check_coverage(vocabulary, embed_glove)","77c9e10f":"oov_glove[:10]","60980632":"contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}\nlen(contraction_mapping)","e83fb387":"def known_contractions(embed):\n    '''\n    credits to: https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-when-using-embeddings \n    credits to: https:\/\/www.kaggle.com\/anebzt\/quora-preprocessing-model\n    input: embedding matrix\n    output: known contractions (from embeddings)\n    '''\n    known = []\n    for contract in tqdm_notebook(contraction_mapping):\n        if contract in embed:\n            known.append(contract)\n    return known","1c934a4b":"print(\"Known contractions in GloVe embeddings:\")\nprint(known_contractions(embed_glove))","5f24679c":"def clean_contractions(text, mapping):\n    '''\n    credits to: https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-when-using-embeddings \n    credits to: https:\/\/www.kaggle.com\/anebzt\/quora-preprocessing-model\n    input: current text, contraction mappings\n    output: modify the comments to use the base form from contraction mapping\n    '''\n    specials = [\"\u2019\", \"\u2018\", \"\u00b4\", \"`\"]\n    for s in specials:\n        text = text.replace(s, \"'\")\n    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n    return text","3c6cd2a7":"train['comment_text'] = train['comment_text'].apply(lambda x: clean_contractions(x, contraction_mapping))\ntest['comment_text'] = test['comment_text'].apply(lambda x: clean_contractions(x, contraction_mapping))","058ef53c":"df = pd.concat([train ,test], sort=False)\nvocab = build_vocabulary(df['comment_text'])\nprint(\"Check embeddings after applying contraction mapping\")\noov_glove = check_coverage(vocab, embed_glove)","3bef9ea6":"oov_glove[:10]","c278b801":"punct_mapping = \"\/-'?!.,#$%\\'()*+-\/:;<=>@[\\\\]^_`{|}~\" + '\"\"\u201c\u201d\u2019' + '\u221e\u03b8\u00f7\u03b1\u2022\u00e0\u2212\u03b2\u2205\u00b3\u03c0\u2018\u20b9\u00b4\u00b0\u00a3\u20ac\\\u00d7\u2122\u221a\u00b2\u2014\u2013&'\npunct_mapping += '\u00a9^\u00ae` <\u2192\u00b0\u20ac\u2122\u203a \u2665\u2190\u00d7\u00a7\u2033\u2032\u00c2\u2588\u00bd\u00e0\u2026\u201c\u2605\u201d\u2013\u25cf\u00e2\u25ba\u2212\u00a2\u00b2\u00ac\u2591\u00b6\u2191\u00b1\u00bf\u25be\u2550\u00a6\u2551\u2015\u00a5\u2593\u2014\u2039\u2500\u2592\uff1a\u00bc\u2295\u25bc\u25aa\u2020\u25a0\u2019\u2580\u00a8\u2584\u266b\u2606\u00e9\u00af\u2666\u00a4\u25b2\u00e8\u00b8\u00be\u00c3\u22c5\u2018\u221e\u2219\uff09\u2193\u3001\u2502\uff08\u00bb\uff0c\u266a\u2569\u255a\u00b3\u30fb\u2566\u2563\u2554\u2557\u25ac\u2764\u00ef\u00d8\u00b9\u2264\u2021\u221a'\n\ndef unknown_punct(embed, punct):\n    '''\n    credits to: https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-when-using-embeddings \n    credits to: https:\/\/www.kaggle.com\/anebzt\/quora-preprocessing-model\n    input: current text, contraction mappings\n    output: unknown punctuation\n    '''\n    unknown = ''\n    for p in punct:\n        if p not in embed:\n            unknown += p\n            unknown += ' '\n    return unknown","76d76000":"print(\"Find unknown punctuation:\")\nprint(unknown_punct(embed_glove, punct_mapping))","b0ed2dca":"puncts = {\"\u2018\": \"'\", \"\u00b4\": \"'\", \"\u00b0\": \"\", \"\u20ac\": \"e\", \"\u2014\": \"-\", \"\u2013\": \"-\", \"\u2019\": \"'\", \"_\": \"-\", \"`\": \"'\", '\u201c': '\"', '\u201d': '\"', '\u201c': '\"', \"\u00a3\": \"e\", '\u221e': 'infinity', '\u03b8': 'theta', '\u00f7': '\/', '\u03b1': 'alpha', '\u2022': '.', '\u00e0': 'a', '\u2212': '-', '\u03b2': 'beta', '\u2205': '', '\u00b3': '3', '\u03c0': 'pi', '\u2026': ' '}\n\ndef clean_special_chars(text, punct, mapping):\n    '''\n    credits to: https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-when-using-embeddings \n    credits to: https:\/\/www.kaggle.com\/anebzt\/quora-preprocessing-model\n    input: current text, punctuations, punctuation mapping\n    output: cleaned text\n    '''\n    for p in mapping:\n        text = text.replace(p, mapping[p])\n    for p in punct:\n        text = text.replace(p, f' {p} ') \n    return text","d21ddf4f":"train['comment_text'] = train['comment_text'].apply(lambda x: clean_special_chars(x, punct_mapping, puncts))\ntest['comment_text'] = test['comment_text'].apply(lambda x: clean_special_chars(x, punct_mapping, puncts))","55841c24":"%%time\ndf = pd.concat([train ,test], sort=False)\nvocab = build_vocabulary(df['comment_text'])\nprint(\"Check coverage after punctuation replacement\")\noov_glove = check_coverage(vocab, embed_glove)","de606a85":"oov_glove[:10]","31835c23":"%%time\ntokenizer = Tokenizer(num_words=MAX_FEATURES)\ntokenizer.fit_on_texts(list(train))\ntrain = tokenizer.texts_to_sequences(train)\ntest = tokenizer.texts_to_sequences(test)","c0459a03":"## <a id='47'>Tokenize<\/a>\n\nWe apply tokenization for train and test. ","424f5640":"We show now the most frequent words for comments with threat score bellow **0.25** and above **0.75**.","5d96a44b":"To access this page, select **Output** from the side menu of this Notebook.  \nSelect Press **Download** button next to the **LDAVis_train.html** item to display the widget.\n\nTo display this graph widget in the Notebook you will need to uncomment the next cell.","a98a596c":"# <a id='3'>Data exploration<\/a>  \n\nThe comments are stored in `train` and `test` in `comment_text` column.  \nAdditionally, in `train` we have flags for the presence in the comments of a certain sensitive topic.\nThe topic is related to five categories: race or ethnicity, gender, sexual orientation, religion, disability, as following:\n* **race or ethnicity**: asian, black, jewish, latino, other_race_or_ethnicity, white  \n* **gender**: female, male, transgender, other_gender  \n* **sexual orientation**: bisexual, heterosexual, homosexual_gay_or_lesbian, other_sexual_orientation  \n* **religion**: atheist,buddhist,  christian, hindu, muslim, other_religion  \n* **disability**: intellectual_or_learning_disability, other_disability, physical_disability, psychiatric_or_mental_illness  \n\nWe also have few article\/comment identification information:\n* created_date  \n* publication_id   \n* parent_id  \n* article_id \n\nSeveral user feedback information associated with the comments are provided:\n* rating  \n* funny  \n* wow  \n* sad  \n* likes  \n* disagree  \n* sexual_explicit  \n\nIn the datasets are also 2 fields relative to annotations:\n* identity_annotator_count  \n* toxicity_annotator_count\n\n\n","fd694afb":"To access this page, select **Output** from the side menu of this Notebook.  \nSelect Press **Download** button next to the **LDAVis_test.html**  item to display the widget.\n\nTo display this graph widget in the Notebook you will need to uncomment the next cell.","33f88499":"Let's check the initial coverage of vocabulary.","9e9107e7":"Let's print the top 10 topics, each with 5 words.","3fb90759":"## Load data","9cee3884":"## <a id='42'>Embedding index and embedding matrix<\/a>\n\nLet's build the embedding index (this is a dictionary with keys the embeddings and the values are arrays of their embedding representations) and embedding matrix (a matrix representation of the embeddings).  \n","673c61cf":"Let's show now the prevalent words in comments with target (toxicity)  score under **0.25** and over **0.75**.","fe0f7b10":"## <a id='33'>Feedback information<\/a>\n\nLet's show the feedback values distribution.","7236ec70":"And let's represent similarly the distribution of the additional toxicity features.","cb794337":"# <a id='4'>Prepare the model<\/a>  \n\nIn preparation for the model using Deep Learning, there are two rules formulated by @christofhenkel [8][9]:\n* Don't use standard preprocessing steps like stemming or stopword removal when you have pre-trained embeddings  \n* Get your vocabulary as close to the embeddings as possible   \n\n","5a029747":"Let's check the most important topics per each comment.","9ec2d74d":"We can observe that most of the remaining include contractions and words with punctuation. We continue with removing contractions.\n\n## <a id='45'>Remove contractions<\/a> \n\nContractions are modified forms of words and expressions. We will map, using the following dictionary, the contracted forms on words existent in embeddings.\n\n","c9fdc22e":"Let's generate a bag-of-words from the dictioanry and the corpus of comments (documents). \nThen, we generate a corpus and apply TF-IDF.","736baf20":"##  <a id='31'>Target feature<\/a>\n\nLet's check the distribution of `target` value in the train set.","905db530":"Let's rebuid the vocabulary after replacing the punctuation and check again the coverage.","b9ef17a9":"Embedding only cover ~15% of the vocabulary and this accounts for 89.6% from the entire comments texts.  \nLet's check what kind of words are missing from the embeddings.","96898e18":"We save the pyLDAvis graph as a html page. ","b9141a36":"Let's check the size of embeeding structure loaded.","4e5776f4":"Let's show few documents preprocessed.","9f1bd3b9":"Most of the missing words are punctuation and upper case words. Let's remove punctuation and apply lowerisation (i.e. turn all words to lowercase).\n\n## <a id='44'>Transform to lowercase<\/a>","0b080661":"<h1><center><font size=\"6\">Jigsaw EDA<\/font><\/center><\/h1>\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/7\/75\/Jigsaw.svg\" width=\"300\"><\/img>\n\n<br>\n\n# <a id='0'>Content<\/a>\n\n- <a href='#1'>Introduction<\/a>  \n- <a href='#2'>Prepare the data analysis<\/a>  \n- <a href='#3'>Data exploration<\/a>   \n    - <a href='#31'>Target feature<\/a>   \n    - <a href='#32'>Sensitive topics features<\/a>   \n    - <a href='#33'>Feedback information<\/a>   \n    - <a href='#34'>Comments data wordclouds<\/a>   \n    - <a href='#35'>Comments data topic modelling<\/a>  \n- <a href='#4'>Prepare the model<\/a>    \n    - <a href='#41'>Build vocabulary<\/a>   \n    - <a href='#42'>Embedding index and embedding matrix<\/a>   \n    - <a href='#43'>Check coverage<\/a>   \n    - <a href='#44'>Transform to lowercase<\/a>   \n    - <a href='#45'>Remove contractions<\/a>   \n    - <a href='#46'>Remove punctuation<\/a>  \n    - <a href='#47'>Tokenize<\/a>  \n- <a href='#5'>Conclusions<\/a>      \n- <a href='#6'>References<\/a>   ","d12d97aa":"# <a id='5'>Conclusions<\/a>  \n\nWe applied succesively several techniques to improve the vocabulary coverage with GloVe for the entire corpus of texts in `comment_text`, as following:\n* transform to lowercase;  \n* remove contractions;  \n* remove punctuation;  \n\n\nBy just using these simple text transformation, we were able to found embeddings for 54.401% of vocabulary and for 99.718% of all text, from the orginial coverage, before these processings, of 15% of the vocabularyand 89.6% from all text.","633c3f5d":"Let's now create the embeeding matrix using the word index and the embeeding index created. We are using the MAX_FEATURES to limit the number of features thus the size of embeeding matrix. ","c823919a":"Let's check again the words not included in embeddings.","098980b2":"Now we will apply preprocess on a sample of 200000 comments.","aff878cf":"## <a id='35'>Comments data topic modelling<\/a>\n\n\n\n### Train data\n\nLet's perform topic modelling on a subset of the comments from train data.","66c753dc":"# <a id='6'>References<\/a>  \n\n[1] https:\/\/www.kaggle.com\/c\/jigsaw-unintended-bias-in-toxicity-classification\/  \n[2] https:\/\/towardsdatascience.com\/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24  \n[3] https:\/\/towardsdatascience.com\/improving-the-interpretation-of-topic-models-87fd2ee3847d  \n[4] https:\/\/www.aclweb.org\/anthology\/W14-3110   \n[5] https:\/\/www.objectorientedsubject.net\/2018\/08\/experiments-on-topic-modeling-pyldavis\/  \n[6] https:\/\/www.kaggle.com\/errearanhas\/topic-modelling-lda-on-elon-tweets  \n[7] https:\/\/en.wikipedia.org\/wiki\/Latent_Dirichlet_allocation  \n[8] https:\/\/www.kaggle.com\/anebzt\/quora-preprocessing-model  \n[9] https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-when-using-embeddings  \n\n\n\n","5532b14b":"Let's show the prevalent words in the train set (we will use a **20,000** comments sample and show top **50** words).","b3f469b0":"Let's create now a dictionary. We set also some filters.","04f29145":"## <a id='34'>Comments data wordclouds<\/a>\n\nLet's show the wordcloud of frequent used words in the comments. A maximum of 50 words are shown.","e467cbc8":"## <a id='41'>Build vocabulary<\/a>  \n\nWe start with building the vocabulary. First we set few constants, as following:  \n* **EMBED_SIZE** - embedding size - the size of word vector - should match the embedding source (GloVe);  \n* **MAX_FEATURES** - Maximum number of features - the number of unique words to use or number of rows in the embedding vector;  \n* **MAXLEN** - The maximum length of comments text","645d0b6b":"The following function is from [8][9]. It builds the vocabulary by browsing all comments, splits in sentences, sentences in words. An accumulator is created, with the value associated to each word equal with the accumulated value.","db38a50e":"### Test data\n\nLet's repeat the same procedure for topic modelling but for test data now.","937b5c28":"Let's represent the first 10 topics, each with 5 words.","e12a04f4":"## <a id='43'>Check coverage<\/a>\n\nWith the following function, we check coverage of embeddings for the vocabulary created from the train and test dataset. We will sue this function repeatedly after each pre-processing operation.","b9b5ce8d":"Let's use the LDA model to predict the type of topic for one document. \nWe select one specific document (with index 5).","df347008":"We extracted the topics using LDA.\nLet's represent the topics using the `pyLDAvis` tool.","be7a7d20":"It seems that, with lowercase transformation and contraction treatment, the improvement in termns of coverage is not significant. Punctuation, which we didn't treated yet, seems to be really important.\n\n## <a id='46'>Remove punctuation<\/a>  \n\nWe remove as well punctuation.","13365de7":"## <a id='32'>Sensitive topics features<\/a>\n\nLet's check now the distribution of sensitive topics features values.","2f88366b":"We are now ready to create a model. Stay tuned!","2ca37a79":"Let's now run LDA (Latent Dirichelet Allocation algorithm) with the result of TF-IDF applied to the bag-of-words corpus to generate 20 topics.","dabb76d5":"Let's verify the processor for one comment.","ad082007":"We will build again the vocabulary and check again the coverage.","099c9ed9":"# <a id='2'>Prepare the data analysis<\/a>  \n\n## Load packages","c95fad65":"We concatenate train and test and build an unique vocabulary with both datasets.","b9cb1683":"We save the pyLDAvis graph as a html page.","97936309":"There is a significant improvement by extracting punctuation. 99.7% from the text is covered by the embeddings and 57% of the vocabulary. Punctuation appears to be very important.","a2d7ba01":"# <a id='1'>Introduction<\/a>  \n\n## Competition objective\n\nThe competition objective is to build models that detect toxicity and reduce unwanted bias. \nFor example, if a certain minority name is frequently associated with toxic comments, some models might associate the presence of the minority name in a message that is not toxic wiht toxicity and wrongly classify the comment as toxic.\n\n## Background\n\nAt the end of 2017 the Civil Comments platform shut down and chose make their ~2m public comments from their platform available in a lasting open archive so that researchers could understand and improve civility in online conversations for years to come. Jigsaw sponsored this effort and extended annotation of this data by human raters for various toxic conversational attributes.\n\n## References\n\nPlease consult the <a href='#5'>References<\/a> section for the datasets, Kernels and articles used in this Kernel. Special mention for tje Kernels of @anebzt [8] and @christofhenkel [9].\n","ea7d2646":"Let's show the wordcloud of frequent words used in comments with obscene **score < 0.25** and obscene **score > 0.75**.","a3c6ef6d":"Let's check the first 10 elements of the vocabulary.","9027c11b":"Let's show now the frequent used words in comments for which insult score under **0.25** and above **0.75**."}}