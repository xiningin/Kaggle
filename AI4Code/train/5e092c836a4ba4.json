{"cell_type":{"4dba60c2":"code","f233743d":"code","53c17f6c":"code","5110fb0a":"code","05782c5d":"code","9cc0999c":"code","73978638":"code","870c3951":"code","3d4df1fa":"code","6acc75ec":"code","752d5989":"code","fb418392":"code","4d78f1f1":"code","0dfe1d15":"code","7e0f4ecc":"code","5b62b473":"code","eaa73e4b":"code","90cdaeb3":"code","b8fde512":"code","e67708aa":"code","13d0b613":"code","d94ce2a1":"code","bba1b9c6":"code","14003736":"code","a7e97955":"code","bf90a67c":"code","4c82348d":"code","ab0dcff4":"code","3f84a7d8":"code","26c46047":"code","320fff00":"code","704a2f04":"code","f3a5d609":"code","bb90e05f":"code","6a9dc47b":"code","67e7eba4":"code","6916243a":"code","1bb4403e":"code","11dfc49d":"code","b3fb1081":"code","9fd0ddad":"code","ca09395c":"code","188e688d":"code","ae8eb1f8":"code","b24a1bfc":"code","bda5afd2":"code","77236a9c":"code","c812ab3e":"code","a595d464":"code","e2a3846f":"code","b2010915":"markdown","f2a2513c":"markdown","6c261979":"markdown","452a44f6":"markdown","0ce72867":"markdown","e061ae14":"markdown","49e893ea":"markdown","664119d4":"markdown","4eefdbf1":"markdown","5f0d36c8":"markdown","01efa563":"markdown","2745150a":"markdown","e504a1d7":"markdown","7c21a4c6":"markdown","2c9d561f":"markdown","ba93b2c3":"markdown","55f05298":"markdown","0065ffad":"markdown","106558df":"markdown"},"source":{"4dba60c2":"from google.colab import drive\ndrive.mount('\/content\/gdrive')","f233743d":"! pip install -q kaggle","53c17f6c":"from google.colab import files\nfiles.upload()","5110fb0a":"! mkdir ~\/.kaggle","05782c5d":"! cp kaggle.json ~\/.kaggle\/","9cc0999c":"! chmod 600 ~\/.kaggle\/kaggle.json","73978638":"# Uncomment the following to test if everything's okay by running this command.\n# !kaggle datasets list","870c3951":"!kaggle competitions download -c eurecom-aml-2021-challenge-1","3d4df1fa":"! mkdir train","6acc75ec":"! unzip train_features.csv.zip -d train","752d5989":"! unzip train_targets.csv.zip -d train","fb418392":"! mkdir test","4d78f1f1":"! unzip test_features.csv.zip -d test","0dfe1d15":"#import the necssary libraries\nimport os\nfrom datetime import datetime\nfrom datetime import time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc \nfrom matplotlib.ticker import FuncFormatter\nimport seaborn as sns\nimport matplotlib.patches as mpatches","7e0f4ecc":"X_dtype = {\n    'ID'                   : int,\n    'YEAR'                 : int,  \n    'MONTH'                : int,  \n    'DAY'                  : int,  \n    'DAY_OF_WEEK'          : int,  \n    'AIRLINE'              : str, \n    'FLIGHT_NUMBER'        : str,  \n    'TAIL_NUMBER'          : str, \n    'ORIGIN_AIRPORT'       : str, \n    'DESTINATION_AIRPORT'  : str, \n    'SCHEDULED_DEPARTURE'  : str,  \n    'DEPARTURE_TIME'       : str, \n    'DEPARTURE_DELAY'      : float,\n    'TAXI_OUT'             : str, \n    'WHEELS_OFF'           : str,\n    'SCHEDULED_TIME'       : float,\n    'AIR_TIME'             : float,\n    'DISTANCE'             : int,\n    'SCHEDULED_ARRIVAL'    : str,\n    'DIVERTED'             : int,  \n    'CANCELLED'            : int,  \n    'CANCELLATION_REASON'  : str\n}\n\ny_dtype = {\n    'ID'                   : int,\n    \"ARRIVAL_DELAY\"        : float\n}\n","5b62b473":"X_train_df = pd.read_csv(\"..\/input\/eurecom-aml-2021-challenge-1\/data\/train_features.csv\", dtype=X_dtype)\ny_train_df = pd.read_csv(\"..\/input\/eurecom-aml-2021-challenge-1\/data\/train_targets.csv\", dtype=y_dtype)\n\nairlines_df = pd.read_csv('..\/input\/eurecom-aml-2021-challenge-1\/data\/airlines.csv').rename({'AIRLINE': 'AIRLINE_NAME'}, axis='columns')\nairports_df = pd.read_csv('..\/input\/eurecom-aml-2021-challenge-1\/data\/airports.csv').rename({'AIRPORT': 'AIRPORT_NAME'}, axis='columns')","eaa73e4b":"def null_rows(data = None):\n    rows_with_nan = []\n    for index, row in data.iterrows():\n        is_nan_series = row.isnull()\n        if is_nan_series.any():\n            rows_with_nan.append(index)\n    return rows_with_nan","90cdaeb3":"def data_probing(data = None, n=5):\n    print(\"---------- Head ----------\")\n    display(data.head(n))\n    print(\"\\n---------- Shape ----------\")\n    print(\"Number of Rows: {}\\nNumber of Columns: {}\".format(data.shape[0], data.shape[1]))\n    print(\"\\n---------- Null Values ----------\")\n    print(data.isnull().sum())\n    print(\"\\n---------- Rows with null values ----------\")\n    rows_with_null = [data.iloc[[index]] for index in null_rows(data)]\n    for row in rows_with_null:\n        display(row)","b8fde512":"data_probing(airports_df)","e67708aa":"data_probing(airlines_df)","13d0b613":"def parse_hhmm(x):\n    if x == '2400':\n        x = '0000'\n    x =  x[:-2] + ':' + x[-2:]\n    return x\n\nX_train_df.SCHEDULED_DEPARTURE = X_train_df.SCHEDULED_DEPARTURE.apply(parse_hhmm)\nX_train_df.DEPARTURE_TIME = X_train_df.DEPARTURE_TIME.apply(parse_hhmm)\nX_train_df.SCHEDULED_ARRIVAL = X_train_df.SCHEDULED_ARRIVAL.apply(parse_hhmm)","d94ce2a1":"X_train_df.SCHEDULED_DEPARTURE = pd.to_datetime(X_train_df['SCHEDULED_DEPARTURE'],format= '%H:%M' ).dt.time\nX_train_df.DEPARTURE_TIME = pd.to_datetime(X_train_df['DEPARTURE_TIME'],format= '%H:%M' ).dt.time\nX_train_df.SCHEDULED_ARRIVAL = pd.to_datetime(X_train_df['SCHEDULED_ARRIVAL'],format= '%H:%M' ).dt.time","bba1b9c6":"X_train_df.head(5)","14003736":"# Merge feature dataframe and target dataframe for data exploration\ndf_train_merged = pd.merge(X_train_df, y_train_df, on='ID')","a7e97955":"# Create new columns used for data exploration\ndf_train_merged['DELAYED'] = (df_train_merged.ARRIVAL_DELAY > 0)\ndf_train_merged['DATE'] = pd.to_datetime(df_train_merged[['YEAR', 'MONTH', 'DAY']])","bf90a67c":"def unique_values(data):\n    unique_tuple = data.unique()\n    return (unique_tuple, len(unique_tuple))","4c82348d":"time_compare = time(18, 0, 0)\nprint(\"How many unique origin airports?\\nThere are {} origin airports\\n\".format(unique_values(df_train_merged['ORIGIN_AIRPORT'])[1]))\nprint(\"How many unique destination airports?\\nThere are {} destination airports\\n\".format(unique_values(df_train_merged['DESTINATION_AIRPORT'])[1]))\nprint(\"How many carriers?\\nThere are {} carriers\\n\".format(unique_values(df_train_merged['AIRLINE'])[1]))\nprint(\"How many flights that have a scheduled departure time later than 18h00?\\nThere are {} flights later then 18h00\\n\".format((X_train_df['SCHEDULED_DEPARTURE'] > time_compare).sum()))","ab0dcff4":"# How many flights in each month of the year?\nplt.rcParams[\"figure.figsize\"] = (15,7)\nval = df_train_merged.MONTH.value_counts().sort_index()\nx = val.index\ny = val.values\nmonths = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul',\n          'Aug', 'Sept', 'Oct', 'Nov', 'Dec']\n\ndef millions(x, pos):\n    'The two args are the value and tick position'\n    return '%1.1fM' % (x*1e-6)\n\nformatter = FuncFormatter(millions)\n\nfig, ax = plt.subplots()\n\nplt.xlabel('Month')\nplt.ylabel('Number of flights')\nplt.title('Number of flights in a month')\nplt.bar(x, y, width=0.35, color=['#239CD3'])\nplt.plot(x,y, '-ok')\nplt.xticks(x, months)\nax.yaxis.set_major_formatter(formatter)\nplt.show()\nplt.close()","3f84a7d8":"# Is there any relationship between the number of flights and the days of week?\nplt.rcParams[\"figure.figsize\"] = (15,7)\nval = df_train_merged.DAY_OF_WEEK.value_counts().sort_index()\nx = val.index\ny = val.values\nplt.plot(x,y, '-o')\nplt.xlabel('Days of WEEK')\nplt.ylabel('Number of Flights')\nplt.xticks(x, ['SUNDAY', 'MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY'])\nplt.title('Number of Flights in a Day Of Week')\nfor a,b in zip(x, y): \n    plt.annotate(str(b), (a,b),ha='right', va='bottom', fontsize=14)\nplt.show()","26c46047":"#busiest airports by inbound and outbound traffic\nplt.rcParams[\"figure.figsize\"] = (18,10)\ntotal = df_train_merged.ORIGIN_AIRPORT.value_counts()[:20]+df_train_merged.DESTINATION_AIRPORT.value_counts()[:20]\nlabels = total.index\ntotal = total.values\n\n#getting the delayed flights\norigin_del = pd.DataFrame(df_train_merged.groupby('ORIGIN_AIRPORT').DELAYED.sum()).reset_index().sort_values('DELAYED', ascending=False)\ndest_del = pd.DataFrame(df_train_merged.groupby('DESTINATION_AIRPORT').DELAYED.sum()).reset_index().sort_values('DELAYED', ascending=False)\ntotal_del_airports = origin_del.merge(dest_del, left_on='ORIGIN_AIRPORT', right_on='DESTINATION_AIRPORT').head(20)\ntotal_del = (total_del_airports.DELAYED_x+total_del_airports.DELAYED_x).values\nsns.set_theme(style=\"whitegrid\")\nbar1 = sns.barplot(x=labels,  y=total, color='red')\n\nbar2 = sns.barplot(x=labels, y=total_del, color='black')\n\n# add legend\ntop_bar = mpatches.Patch(color='red', label='Total_flights')\nbottom_bar = mpatches.Patch(color='black', label='Delayed_flights')\n\nplt.ylabel('NUMBER OF FLIGHTS', fontsize=18)\nplt.xlabel('Airports', fontsize=18)\nplt.title('TOTAL FLIGHTS VS DELAYED FLIGHTS  of AIRLINE', fontsize=18)\nplt.legend(handles=[top_bar, bottom_bar], fontsize=18)\n# show the graph\nplt.show()","320fff00":"#pd.merge(airlines_df, train_df.AIRLINE.value_counts(), left_on='IATA', right_on=train_df.AIRLINE.index)\ncounts = pd.DataFrame(df_train_merged.AIRLINE.value_counts()).reset_index()\ndelayed_counts = pd.DataFrame(df_train_merged.groupby('AIRLINE').DELAYED.sum()).reset_index()\ndelayed_counts.columns =  ['IATA_CODE', 'DELAYED']\n\ncounts.columns = ['IATA_CODE', 'fleet']\ncounts = counts.merge(delayed_counts, on='IATA_CODE', how='inner')\ntotal = counts.merge(airlines_df, on='IATA_CODE', how='inner')\nlabels = total.AIRLINE_NAME\nt_f = total.fleet\nd_f = total.DELAYED\nsns.set_theme(style=\"whitegrid\")\nbar1 = sns.barplot(x=labels,  y=t_f, color='darkblue')\n\nbar2 = sns.barplot(x=labels, y=d_f, color='lightblue')\n\n# add legend\ntop_bar = mpatches.Patch(color='darkblue', label='Total_flights')\nbottom_bar = mpatches.Patch(color='lightblue', label='Delayed_flights')\n\nplt.xticks(rotation=-80)\nplt.ylabel('NUMBER OF FLIGHTS', fontsize=18)\nplt.xlabel('Airlines', fontsize=18)\nplt.title('TOTAL FLIGHTS VS DELAYED FLIGHTS  of AIRLINE', fontsize=18)\nplt.legend(handles=[top_bar, bottom_bar], fontsize=18)\n# show the graph\nplt.show()","704a2f04":"def parse_hour(x):\n    return x.hour\n\ndf_train_merged['SCHEDULED_DEPARTURE_HOUR'] = df_train_merged.SCHEDULED_DEPARTURE.apply(parse_hour)","f3a5d609":"# What is the percentage of delayed flights (over total flights) for different hours of the day?\nval = df_train_merged.groupby(df_train_merged.SCHEDULED_DEPARTURE_HOUR)['DELAYED'].agg(\"mean\")\nx = val.index\ny = val.values\nhour_interval = ['00:00-1:00', '01:00-2:00', '02:00-3:00', '03:00-4:00', '04:00-5:00', '05:00-6:00', '06:00-7:00', '07:00-8:00', '08:00-9:00', '09:00-10:00', '10:00-11:00', '11:00-12:00', '12:00-13:00', '13:00-14:00', '14:00-15:00', '15:00-16:00', '16:00-17:00', '17:00-18:00', '18:00-19:00', '19:00-20:00', '20:00-21:00', '21:00-22:00', '22:00-23:00', '23:00-00:00' ]\n\ndef millions(x, pos):\n    'The two args are the value and tick position'\n    return '%1.1f' % (x*100)\n\nformatter = FuncFormatter(millions)\n\nfig, ax = plt.subplots()\n\nplt.xlabel('Interval')\nplt.ylabel('Percentage of delayed flights')\nplt.title('Number of flights in a given hour of a day')\nplt.bar(x, y, width=0.35, color=['#239CD3'])\nplt.plot(x,y, '-ok')\nplt.xticks(x, hour_interval, rotation=45)\nax.yaxis.set_major_formatter(formatter)\nplt.show()\nplt.close()","bb90e05f":"def parse_dep_delay(x):\n    return abs(x)\n\ndf_train_merged['DEPARTURE_DELAY_ABS'] = df_train_merged.DEPARTURE_DELAY.apply(parse_dep_delay)","6a9dc47b":"# Which hours of the day are characterized by the longest flight delay?\ndf_train_merged.groupby(df_train_merged.SCHEDULED_DEPARTURE_HOUR)['DEPARTURE_DELAY_ABS'].agg(\"mean\").sort_values()","67e7eba4":"X_dtype = {\n    'ID'                   : int,\n    'YEAR'                 : int,  \n    'MONTH'                : int,  \n    'DAY'                  : int,  \n    'DAY_OF_WEEK'          : int,  \n    'AIRLINE'              : str, \n    'FLIGHT_NUMBER'        : str,  \n    'TAIL_NUMBER'          : str, \n    'ORIGIN_AIRPORT'       : str, \n    'DESTINATION_AIRPORT'  : str, \n    'SCHEDULED_DEPARTURE'  : str,  \n    'DEPARTURE_TIME'       : str, \n    'DEPARTURE_DELAY'      : float,\n    'TAXI_OUT'             : str, \n    'WHEELS_OFF'           : str,\n    'SCHEDULED_TIME'       : float,\n    'AIR_TIME'             : float,\n    'DISTANCE'             : int,\n    'SCHEDULED_ARRIVAL'    : str,\n    'DIVERTED'             : int,  \n    'CANCELLED'            : int,  \n    'CANCELLATION_REASON'  : str\n}\n\ny_dtype = {\n    'ID'                   : int,\n    \"ARRIVAL_DELAY\"        : float\n}\n\nX_train_df = pd.read_csv(\"..\/input\/eurecom-aml-2021-challenge-1\/data\/train_features.csv\", dtype=X_dtype)\ny_train_df = pd.read_csv(\"..\/input\/eurecom-aml-2021-challenge-1\/data\/train_targets.csv\", dtype=y_dtype)","6916243a":"#droping certain colums\ndef drop_col(df, columns, inplace=True):\n  df.drop(columns=columns, inplace=inplace)","1bb4403e":"columns = ['ID','DIVERTED','CANCELLED','CANCELLATION_REASON', 'FLIGHT_NUMBER', 'TAIL_NUMBER', 'WHEELS_OFF']","11dfc49d":"drop_col(X_train_df, columns)\ndrop_col(y_train_df, ['ID'])","b3fb1081":"#label encoding columns with categorical values\nfrom sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\ndef encoding(df):\n  for col in df.columns:\n    if df[col].dtype == 'object':\n      df[col] = encoder.fit_transform(df[col])\n\nencoding(X_train_df)","9fd0ddad":"X_train_df.head()","ca09395c":"X_train_df.info()","188e688d":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom math import sqrt","ae8eb1f8":"x_train, x_test, y_train, y_test = train_test_split(X_train_df, y_train_df, test_size = 0.2, random_state=0)","b24a1bfc":"model = RandomForestRegressor(n_estimators=20, criterion='mse', bootstrap=True)\nmodel.fit(x_train, y_train)","bda5afd2":"Y_pred = model.predict(x_test)","77236a9c":"model.score(x_test, y_test)","c812ab3e":"mean_squared_error(y_test, Y_pred)**0.5","a595d464":"def plot_feature_importance(importance,names,model_type):\n\n  #Create arrays from feature importance and feature names\n  feature_importance = np.array(importance)\n  feature_names = np.array(names)\n\n  #Create a DataFrame using a Dictionary\n  data={'feature_names':feature_names,'feature_importance':feature_importance}\n  fi_df = pd.DataFrame(data)\n\n  #Sort the DataFrame in order decreasing feature importance\n  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n\n  #Define size of bar plot\n  plt.figure(figsize=(10,8))\n  #Plot Searborn bar chart\n  sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n  #Add chart labels\n  plt.title(model_type + 'FEATURE IMPORTANCE')\n  plt.xlabel('FEATURE IMPORTANCE')\n  plt.ylabel('FEATURE NAMES')","e2a3846f":"plot_feature_importance(model.feature_importances_,X_train_df.columns,'RANDOM FOREST')","b2010915":"# Why we chose this model?\n\nHere in this project we chose to work with Random Forest beacuse of the following reasons:\n\n\n*   An important aspect of a data science project is the interpretability of the data. Models are generally a black-box to interpret our data. There is always a trade-off between the accuracy and interpretability of model. So we had to find the right balance between them. Here Random Forest prevails. Here trees work together to accurately represent feature importance of the decision trees.\n*   Essentially trees are weak classifiers with high bias. But even upon increasing the numbers of trees in random forest, it splits over the features randomly, and then by means of bootsrapped aggregation(bagging), it reduces the overall variance of the model. Thus it maintains the Bias-Variance tradeoff. \n*    Normalization of the data is not required as it uses the rule based approach of the decison trees.\n\n\nHere in this project, we are working on the prediction of the airline delay. Thus we wanted to potray on what factors the model decides why the certain flights are delayed. Thus using the \"Feature Imporance\" feature of the Random Forest we displayed which of the features are quintessential to its decision making.","f2a2513c":"# Data Preprocessing\n","6c261979":"**Note:** The number of flights running in a given month of the year, it can be observed that, the months of june, july and December, have high traffic, which is plausible because of the holiday seasons in those month.Infact, it is obviuos for airlines to run more flights during the holidays season, as the demand to travel is high.","452a44f6":"## Connecting Google Drive \ud83d\udd10","0ce72867":"## Data Wrangling \ud83d\udd17","e061ae14":"**Note:** There are NULL values present in airports_df in the column \"LATITUDE\" and \"LONGITUDE\".","49e893ea":"**Note:** Considering the 1st day is sunday and so on, we can see that the number of flights increasing as days progress from sunday to Thursday as we move from one week to another. Then there is a decrease in the number of flights in the friday which is starting of the weekend, and then there is increase again on saturday.","664119d4":"Based on this we can say that the model comes to a decision based on these parameters, which help us say by certainty the reason why a flight might be delayed, which is our target prediction. ","4eefdbf1":"# Algorithmic Machine Learning \ud83e\udde0\n## AML-Challenge_1_Baseline \ud83e\uddd1\ud83c\udffb\u200d\ud83d\udcbb\n\n![alt text](https:\/\/drive.google.com\/uc?export=view&id=1Uxqe7gHt6GTLjZxIXd2WAjgIvPnMkKad)\n\nProfessor : Pietro MICHIARDI \ud83d\udc68\ud83c\udffb\u200d\ud83c\udfeb\n\n**Team 7\ufe0f\u20e3 :**   \nSourish GHOSH   \nShree hari BOYALLA  \nTanmay CHAKRABORTY  \nUtkarsh TREHAN  \n","5f0d36c8":"**Note:** There are NULL values present in X_train_df in the column \"CANCELLATION_REASON\". Other datasets have no NULL values in them.","01efa563":"# Model","2745150a":"Top 20 busiest aiports by traffic(Arrival+Departure). It can also, be seen that, the airport that has highest traffic also has more flights delayed. ","e504a1d7":"The number of flights run by each carrier and the percentage of them delayed is shown. Its quite evident that, more the flights a carrier runs, there are more delays, which could be because of the fact that more flights that are run, more maintence delays and scheduling conflicts etc.","7c21a4c6":"## Data Acquisition \u2b07\ufe0f","2c9d561f":"The most busiest hours are in the evening, which can be seen from the trend in the graph above.","ba93b2c3":"# Conclusion ","55f05298":"As we can see the most important features are \"DEPARTURE_DELAY\", \"AIR_TIME\", \"TAXI_OUT\", \"SCHEDULED_TIME\", and \"DISTANCE\". ","0065ffad":"## Data Analysis \ud83d\udcc8\ud83d\udcc9\ud83d\udcca\n\n**Basic queries:**  \n1. How many unique origin airports?  \n2. How many unique destination airports?  \n3. How many carriers?  \n4. How many flights that have a scheduled departure time later than 18h00?  \n\n**Statistics on flight volume: this kind of statistics are helpful to reason about delays. Indeed, it is plausible to assume that \"the more flights in an airport, the higher the probability of delay\".**\n\n1. How many flights in each month of the year?  \n2. Is there any relationship between the number of flights and the days of week?  \n3. How many flights in different days of months and in different hours of days?  \n4. Which are the top 20 busiest airports (this depends on inbound and outbound traffic)?  \n5. Which are the top 20 busiest carriers?  \n\n**Statistics on the fraction of delayed flights**\n1. What is the percentage of delayed flights (over total flights) for different hours of the day?  \n2. Which hours of the day are characterized by the longest flight delay?\n3. What are the fluctuation of the percentage of delayed flights over different time granularities?  \n4. What is the percentage of delayed flights which depart from one of the top 20 busiest airports?  \n5. What is the percentage of delayed flights which belong to one of the top 20 busiest carriers?  ","106558df":"The longest flight delay hour is 20:00 with an average delay of 19.895, it can also be observed,that this is also one of the busiest hours in a given day in terms of flight traffic."}}