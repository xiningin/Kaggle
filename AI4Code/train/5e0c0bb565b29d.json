{"cell_type":{"5b5143c4":"code","a380ce96":"code","f4459c12":"code","80bc6ece":"code","52e73b2f":"code","3d0f160a":"code","e4b7d8e9":"code","38bc5941":"code","0aafe96c":"code","fcc81567":"code","513b08af":"code","1df0f208":"code","560e8d7f":"code","ba1f3f3f":"code","0b52cee4":"code","726aabcc":"code","bc4a9c01":"code","20bbe814":"code","4576797d":"code","c8007b46":"code","0ccbfe79":"code","bcecb078":"code","1af0002d":"code","4c74ec46":"code","e9e95c12":"code","79d36093":"code","3e008e66":"code","f4bed853":"code","c1b40346":"code","545be941":"code","1e1ba1bb":"code","9b3d5721":"code","71f5d2f0":"code","6085ac67":"code","06e548ff":"code","eb64e9e6":"markdown","e2d24ff8":"markdown","11b7a5d8":"markdown","7f6d7c79":"markdown","4b1c3a1c":"markdown","923e3b00":"markdown","ca77363d":"markdown","a94a0a2f":"markdown","e6b514b7":"markdown","342d2ee0":"markdown","a5762989":"markdown","4de79cc6":"markdown","969227f5":"markdown","ca52ccc3":"markdown","333730eb":"markdown","61ac8f59":"markdown","1cf1cb4e":"markdown","b03ce728":"markdown","93b58220":"markdown","41e27fbb":"markdown","52e27562":"markdown","890c5a77":"markdown","3f54b1dc":"markdown","6de5a646":"markdown"},"source":{"5b5143c4":"import numpy as np\nimport pandas as pd\n\nimport os\nimport random\nfrom operator import itemgetter\nimport cv2\nimport copy\nimport time\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.image import imread\nimport seaborn as sns\n\nimport torch\nimport torchvision\nfrom torchvision.datasets import ImageFolder\n\nfrom torchvision.utils import make_grid\nimport torchvision.transforms as transform\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom sklearn.model_selection import train_test_split\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torchvision.utils import make_grid\nimport torch.nn.functional as F\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","a380ce96":"example_train_path = '..\/input\/fruits\/fruits-360\/Training\/'\npath = '..\/input\/fruits\/fruits-360'","f4459c12":"img = mpimg.imread(example_train_path + \"Apple Braeburn\/0_100.jpg\")\nprint(\"Shape:\", img.shape)\nplt.imshow(img);","80bc6ece":"def plotHist(img):\n  plt.figure(figsize=(10,5))\n  plt.subplot(1,2,1)\n  plt.imshow(img, cmap='gray')\n  plt.axis('off')\n  histo = plt.subplot(1,2,2)\n  histo.set_ylabel('Count')\n  histo.set_xlabel('Pixel Intensity')\n  plt.hist(img.flatten(), bins=10, lw=0, color='r', alpha=0.5)\n\nplotHist(img)","52e73b2f":"transformer = transform.Compose([transform.ToTensor(),\n                                transform.Normalize([0.6840562224388123, 0.5786514282226562, 0.5037682056427002],\n                                                    [0.3034113645553589, 0.35993242263793945, 0.39139702916145325])\n                                ])","3d0f160a":"bs = 50\n\ntraining = ImageFolder(path+'\/Training', transform=transformer)\n\ntrainset, valset = train_test_split(training, test_size=0.05, shuffle=True, random_state=9)\n\nloaders = {\n            'train':DataLoader(trainset, batch_size=bs, num_workers=4, pin_memory=False), #, num_workers=4, pin_memory=False\n            'val': DataLoader(valset, batch_size=bs, num_workers=4, pin_memory=False)\n          }\n\ndataset_sizes = {\n                 'train':len(trainset), \n                 'val':len(valset)\n                }","e4b7d8e9":"channels = 3\n\nfor channel in range(channels):\n    for x in ['train', 'val']:\n        #number of pixels in the dataset = number of all pixels in one object * number of all objects in the dataset\n        num_pxl = dataset_sizes[x]*100*100\n    \n        #we go through the butches and sum up the pixels of the objects, \n        #which then divide the sum by the number of all pixels to calculate the average\n        total_sum = 0\n        for batch in loaders[x]:\n            layer = list(map(itemgetter(channel), batch[0]))\n            layer = torch.stack(layer, dim=0)\n            total_sum += layer.sum()\n        mean = total_sum \/ num_pxl\n\n        #we calculate the standard deviation using the formula that I indicated above\n        sum_sqrt = 0\n        for batch in loaders[x]: \n            layer = list(map(itemgetter(channel), batch[0]))\n            sum_sqrt += ((torch.stack(layer, dim=0) - mean).pow(2)).sum()\n        std = torch.sqrt(sum_sqrt \/ num_pxl)\n        \n        print(f'|channel:{channel+1}| {x} - mean: {mean}, std: {std}')\n","38bc5941":"x, y = next(iter(loaders['train']))\nx.mean(),  x.std()","0aafe96c":"x, y = next(iter(loaders['train']))\nimg_norm = x[0].permute(1,2,0).numpy()\nplotHist(img_norm)","fcc81567":"len(training.classes)","513b08af":"dic = {}\n\nfor classes in training.classes:\n    for filename in os.listdir(path+'\/Training\/'+classes):\n        dic[classes] = [len([os.path.join(path+'\/Training\/'+classes, filename) for filename in os.listdir(path+'\/Training\/'+classes)])]\n\n    \ntrain_samplesize = pd.DataFrame.from_dict(dic)","1df0f208":"train_samplesize","560e8d7f":"figure_size = plt.rcParams[\"figure.figsize\"]\nfigure_size[0] = 40\nfigure_size[1] = 20\nplt.rcParams[\"figure.figsize\"] = figure_size\n\nsns.barplot(data=train_samplesize)\n\nindex = np.arange(len(training.classes))\n\nplt.xlabel('Fruits', fontsize=25)\nplt.ylabel('Count of Fruits', fontsize=25)\nplt.xticks(index, training.classes, fontsize=15, rotation=90)\nplt.title('Training Set Distrubution', fontsize=35)\nplt.show()","ba1f3f3f":"# Function for plotting samples\ndef plot_samples(samples):  \n    fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(15,12))\n    i = 0\n    for row in range(5):\n         for col in range(5):\n                img = mpimg.imread(samples[i][0][0])\n                ax[row][col].imshow(img)\n                ax[row][col].axis('off')\n                ax[row][col].set_title(samples[i][1], fontsize=15)\n                i+=1\n  \n\nrand_samples = [] \nfor _ in range(25): \n    classes = random.choice(training.classes)\n    rand_samples.append([random.sample([os.path.join(path+'\/Training\/'+classes, filename) for filename in os.listdir(path+'\/Training\/'+classes)], 1), classes]) \nrand_samples[0]\nplot_samples(rand_samples)\nplt.suptitle('Training Set Samples', fontsize=30)\nplt.show()","0b52cee4":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1) \n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds)), preds","726aabcc":"#save the losses for further visualization\nlosses = {'train':[], 'val':[]}\naccuracies = {'train':[], 'val':[]}","bc4a9c01":"def train(seed, epochs, model):\n    \n  print('Creating a model {}...'.format(seed))\n\n  model.to(device)  \n  criterion = nn.CrossEntropyLoss()\n  if seed==2 or seed==3:\n    optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n  else:\n    optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n\n  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)\n  since = time.time()\n  best_model = copy.deepcopy(model.state_dict())\n  best_acc = 0.0\n  for epoch in range(epochs):\n    for phase in ['train', 'val']:\n      if phase == 'train':\n        model.train()\n      else:\n        model.eval()\n      \n      running_loss = 0.0\n      running_corrects = 0.0\n\n      for inputs, labels in loaders[phase]:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        with torch.set_grad_enabled(phase=='train'):\n          outp = model(inputs)\n          _, pred = torch.max(outp, 1)\n          loss = criterion(outp, labels)\n        \n          if phase == 'train':\n            loss.backward()\n            optimizer.step()\n            \n\n        running_loss += loss.item()*inputs.size(0)\n        running_corrects += torch.sum(pred == labels.data)\n\n      if phase == 'train':\n          acc = 100. * running_corrects.double() \/ dataset_sizes[phase]\n          scheduler.step(acc)\n\n      epoch_loss = running_loss \/ dataset_sizes[phase]\n      epoch_acc = running_corrects.double()\/dataset_sizes[phase]\n      losses[phase].append(epoch_loss)\n      accuracies[phase].append(epoch_acc)\n      if phase == 'train':\n        print('Epoch: {}\/{}'.format(epoch+1, epochs))\n      print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n    \n      if phase == 'val':\n        print('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n        print('=='*31)\n      if phase == 'val' and epoch_acc > best_acc:\n        best_acc = epoch_acc\n        best_model = copy.deepcopy(model.state_dict())\n    #scheduler.step() \n  time_elapsed = time.time() - since\n  print('CLASSIFIER TRAINING TIME {}m {}s'.format(time_elapsed\/\/60, time_elapsed%60))\n  print('=='*31)\n\n\n  model.load_state_dict(best_model)\n\n  for param in model.parameters():\n        param.requires_grad=True\n\n  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)  \n  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=2, verbose=True)\n  #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)\n  for epoch in range(epochs):\n    for phase in ['train', 'val']:\n      if phase == 'train':\n        model.train()\n      else:\n        model.eval()\n      \n      running_loss = 0.0\n      running_corrects = 0.0\n\n      for inputs, labels in loaders[phase]:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        with torch.set_grad_enabled(phase=='train'):\n          outp = model(inputs)\n          _, pred = torch.max(outp, 1)\n          loss = criterion(outp, labels)\n        \n          if phase == 'train':\n            loss.backward()\n            optimizer.step()\n        \n        running_loss += loss.item()*inputs.size(0)\n        running_corrects += torch.sum(pred == labels.data)\n\n      if phase == 'train':\n        acc = 100. * running_corrects.double() \/ dataset_sizes[phase]\n        scheduler.step(acc)\n\n      epoch_loss = running_loss \/ dataset_sizes[phase]\n      epoch_acc = running_corrects.double()\/dataset_sizes[phase]\n      losses[phase].append(epoch_loss)\n      accuracies[phase].append(epoch_acc)\n      if phase == 'train':\n        print('Epoch: {}\/{}'.format(epoch+1, epochs))\n      print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n    \n      if phase == 'val':\n        print('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n        print('=='*31)    \n      if phase == 'val' and epoch_acc > best_acc:\n        best_acc = epoch_acc\n        best_model = copy.deepcopy(model.state_dict())\n    #scheduler.step() \n  time_elapsed = time.time() - since\n  print('ALL NET TRAINING TIME {}m {}s'.format(time_elapsed\/\/60, time_elapsed%60))\n  print('=='*31)\n\n  model.load_state_dict(best_model)\n  return model","20bbe814":"densenet121_0 = torchvision.models.densenet121(pretrained=True)\nfor param in densenet121_0.parameters():\n  param.requires_grad=False\n\ndensenet121_0.classifier = nn.Linear(in_features=densenet121_0.classifier.in_features, out_features=len(training.classes), bias=True)","4576797d":"densenet121_1 = torchvision.models.densenet121(pretrained=True)\nfor param in densenet121_1.parameters():\n  param.requires_grad=False\n\ndensenet121_1.classifier = nn.Linear(in_features=densenet121_1.classifier.in_features, out_features=len(training.classes), bias=True)","c8007b46":"googlenet = torchvision.models.googlenet(pretrained=True)\nfor param in googlenet.parameters():\n  param.grad_requires = False\n\ngooglenet.fc = nn.Linear(in_features=googlenet.fc.in_features, out_features=len(training.classes), bias=True)","0ccbfe79":"resnet101 = torchvision.models.resnet101(pretrained=True)\nfor param in resnet101.parameters():\n  param.grad_requires = False\n\nresnet101.fc = nn.Linear(in_features=resnet101.fc.in_features, out_features=len(training.classes), bias=True)","bcecb078":"vgg19_bn = torchvision.models.vgg19_bn(pretrained=True)\nfor param in vgg19_bn.parameters():\n  param.grad_requires = False\n\nvgg19_bn.classifier[6] = nn.Linear(4096, len(training.classes), bias=True)","1af0002d":"num_models = 5\nepochs = 10\n\nmodels = [densenet121_0, densenet121_1, googlenet, resnet101, vgg19_bn]\n\nfor seed in range(num_models):\n   train(seed=seed, epochs=epochs, model=models[seed])","4c74ec46":"fig, ax = plt.subplots(5, 2, figsize=(15, 15))\nmodelname = ['DenseNet_0', 'DenseNet_1', 'GooglNet', 'ResNet101', 'VGG16 with BN']\n\nepochs=10\n\ni=0\n\nfor row in range(5):\n\n  epoch_list = list(range(1,epochs*2+1))\n\n  ax[row][0].plot(epoch_list, accuracies['train'][i:20+i], '-o', label='Train Accuracy')\n  ax[row][0].plot(epoch_list, accuracies['val'][i:20+i], '-o', label='Validation Accuracy')\n  ax[row][0].plot([epochs for x in range(20)],  np.linspace(min(accuracies['train'][i:20+i]).cpu(), max(accuracies['train'][i:20+i]).cpu(), 20), color='r', label='Unfreeze net')\n  ax[row][0].set_xticks(np.arange(0, epochs*2+1, 5))\n  ax[row][0].set_ylabel('Accuracy Value')\n  ax[row][0].set_xlabel('Epoch')\n  ax[row][0].set_title('Accuracy {}'.format(modelname[row]))\n  ax[row][0].legend(loc=\"best\")\n\n  ax[row][1].plot(epoch_list, losses['train'][i:20+i], '-o', label='Train Loss')\n  ax[row][1].plot(epoch_list, losses['val'][i:20+i], '-o',label='Validation Loss')\n  ax[row][1].plot([epochs for x in range(20)], np.linspace(min(losses['train'][i:20+i]), max(losses['train'][i:20+i]), 20), color='r', label='Unfreeze net')\n  ax[row][1].set_xticks(np.arange(0, epochs*2+1, 5))\n  ax[row][1].set_ylabel('Loss Value')\n  ax[row][1].set_xlabel('Epoch')\n  ax[row][1].set_title('Loss {}'.format(modelname[row]))\n  ax[row][1].legend(loc=\"best\")\n  fig.tight_layout()\n  fig.subplots_adjust(top=1.5, wspace=0.3)\n\n  i+=20","e9e95c12":"class Ensemble(nn.Module):\n    def __init__(self, device):\n        super(Ensemble,self).__init__()\n        # you should use nn.ModuleList. Optimizer doesn't detect python list as parameters\n        self.models = nn.ModuleList(models)\n        \n    def forward(self, x):\n        # it is super simple. just forward num_ models and concat it.\n        output = torch.zeros([x.size(0), len(training.classes)]).to(device)\n        for model in self.models:\n            output += model(x)\n        return output\n","79d36093":"model =  Ensemble(device)","3e008e66":"def validation_step(batch):\n        images,labels = batch\n        images,labels = images.to(device),labels.to(device)\n        out = model(images)                                      \n        loss = F.cross_entropy(out, labels)                    \n        acc,preds = accuracy(out, labels)                       \n        \n        return {'val_loss': loss.detach(), 'val_acc':acc.detach(), \n                'preds':preds.detach(), 'labels':labels.detach()}","f4bed853":" def test_prediction(outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()           \n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()             \n        # combine predictions\n        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()] \n        # combine labels\n        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]  \n        \n        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(),\n                'test_preds': batch_preds, 'test_labels': batch_labels}","c1b40346":"@torch.no_grad()\ndef test_predict(model, test_loader):\n    model.eval()\n    # perform testing for each batch\n    outputs = [validation_step(batch) for batch in test_loader] \n    results = test_prediction(outputs)                          \n    print('test_loss: {:.4f}, test_acc: {:.4f}'\n          .format(results['test_loss'], results['test_acc']))\n    \n    return results['test_preds'], results['test_labels']","545be941":"testset = ImageFolder(path+'\/Test', \n                           transform=transformer)","1e1ba1bb":"test_dl = DataLoader(testset, batch_size=256)\nmodel.to(device)\npreds,labels = test_predict(model, test_dl)","9b3d5721":"def norm_out(img):\n    \n    img = img.permute(1,2,0)\n    mean = torch.FloatTensor([0.6840562224388123, 0.5786514282226562, 0.5037682056427002])\n    std = torch.FloatTensor([0.3034113645553589, 0.35993242263793945, 0.39139702916145325])\n    \n    img = img*std + mean\n        \n    return np.clip(img,0,1)","71f5d2f0":"fig, ax = plt.subplots(figsize=(8,12), ncols=2, nrows=4)\n\nfor row in range(4):\n    i = np.random.randint(0, high=len(testset))\n    img,label = testset[i]\n    \n    m = nn.Softmax(dim=1)\n    percent = m(model(img.to(device).unsqueeze(0)))\n    predmax3percent = torch.sort(percent[0])[0][-3:]\n    predmax3inds = torch.sort(percent[0])[1][-3:]\n    classes = np.array([training.classes[predmax3inds[-3]], training.classes[predmax3inds[-2]],training.classes[predmax3inds[-1]]])\n    class_name = training.classes\n\n    ax[row][0].imshow(norm_out(img))\n    ax[row][0].set_title('Real : {}'.format(class_name[label]))\n    ax[row][0].axis('off')\n    ax[row][1].barh(classes, predmax3percent.detach().cpu().numpy())\n    ax[row][1].set_aspect(0.1)\n    ax[row][1].set_yticks(classes)\n    ax[row][1].set_title('Predicted Class: {} ({}%)'.format(training.classes[predmax3inds[-1]], round((predmax3percent[-1]*100).item(), 2)))\n    ax[row][1].set_xlim(0, 1.)\n    plt.tight_layout()","6085ac67":"report = classification_report(labels, preds,\n                               output_dict=True,\n                               target_names=training.classes)\nreport_df = pd.DataFrame(report).transpose()","06e548ff":"pd.set_option(\"display.max_rows\", None)\nreport_df.head(134)","eb64e9e6":"***I am always happy to receive any feedback. What do you think can be changed and what can be removed?***","e2d24ff8":"# **4. Test**","11b7a5d8":"**Here you can see the main metrics for each individual class**","7f6d7c79":"**Visualization of training. As we can see, after defrosting, the indicators have improved**","4b1c3a1c":"Train function structure:\n\n1. **Classifier Training**\n2. **Network-wide Training**","923e3b00":"# **0. Importing Libraries**","ca77363d":"**Let's write some functions that will help us make predictions and load the test data**","a94a0a2f":"**Show example from data and size**","e6b514b7":"**So we can see the number of classes, there are really a lot of them**","342d2ee0":"**Launching training**","a5762989":"# **1. Data loading and preparation\u00b6**\n**Paths**","4de79cc6":"**Uploading models**","969227f5":"**Let's look at the data itself, which we will need to work with**","ca52ccc3":"**To visualize the data qualitatively, we need to normalize it back, that is, to return the pixel brightness distribution to its original state. This is what the function below does**","333730eb":"**Let's write a model class that contains 5 already trained models**","61ac8f59":"**Normalize and load the data**","1cf1cb4e":"**Sometimes the data is normalized in advance, but as you can see in the graph, this is not the case, so the data will have to be normalized**","b03ce728":"# **4. Metrics**","93b58220":"**Let's see how confident the network is in its predictions, as you can see, the network has trained well and gives confident predictions**","41e27fbb":"# **3. Training**\n**I will use an ensemble of pre-trained models, the idea is this: I first train only the classifier on 10 epochs, then unfreeze the network and train all together for another 10 epochs**","52e27562":"**Learning history for further visualization**","890c5a77":"**Since information is always better perceived visually, I will make a graph with the distribution of classes**","3f54b1dc":"**Let's write the accuracy function so that we don't have to write it several times**","6de5a646":"**Let's check the average and standard deviation of the images for each channel. As we can observe, the standard deviation is near one, and the mean is near zero, which is what we need**"}}