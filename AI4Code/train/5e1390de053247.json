{"cell_type":{"16ced45d":"code","bbb05907":"code","34cecf0c":"code","db76f04a":"code","17837e5e":"code","97293c27":"code","2f7330d4":"code","0e7a8931":"code","f2631990":"code","93d5a521":"code","fa838ae3":"code","6982673f":"code","27e58ef0":"code","376141e4":"code","904608f9":"code","82ea7c78":"code","c0090765":"code","7e85a8b0":"code","a27fcb83":"code","11c9b291":"code","5dd20520":"code","e3dd95dd":"code","1ac2b778":"code","513db524":"code","98b7b872":"code","c427a6f8":"code","81def536":"code","6d8e28e9":"markdown","327157c1":"markdown","0ac0d39a":"markdown","1ce83695":"markdown","2e23d01f":"markdown","f7ca3abc":"markdown","f6c87d78":"markdown","80ea3acd":"markdown","3cb6c9bb":"markdown","347e4611":"markdown","20d71a49":"markdown","c2463b39":"markdown","d2cd0c97":"markdown","f1ed6fc6":"markdown","c9d84c21":"markdown","9072b310":"markdown","e017f7fc":"markdown"},"source":{"16ced45d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bbb05907":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","34cecf0c":"# read train\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")","db76f04a":"train.head()","17837e5e":"train.shape","97293c27":"train.head()","2f7330d4":"# read test\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","0e7a8931":"print(test.shape)\ntest.head()","f2631990":"# put label into y_train variable\nY_train = train[\"label\"]\n# Drop label column\nX_train = train.drop(labels = [\"label\"],axis =1)","93d5a521":"# visualize number of digits classes\nplt.figure(figsize= (15, 7))\ng = sns.countplot(Y_train, palette= \"icefire\")\nplt.title(\"number of digit classes\")\nY_train.value_counts()","fa838ae3":"x_train = X_train.values.reshape(-1,28,28,1)","6982673f":"plt.figure(figsize=(12,10))\nx, y = 15, 5\nfor i in range(75):  \n    plt.subplot(y, x, i+1)\n    plt.imshow(x_train[i],interpolation='nearest')\nplt.show()","27e58ef0":"# Normalize the data\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",test.shape)","376141e4":"# Reshape\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",test.shape)","904608f9":"# Label Encoding \nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nY_train = to_categorical(Y_train, num_classes = 10)","82ea7c78":"# Split the train and the validation set for the fitting\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_test shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_test shape\",Y_val.shape)","c0090765":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","7e85a8b0":"model = Sequential()\n#\nmodel.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n# fully connected\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","a27fcb83":"# Define the optimizer\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","11c9b291":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","5dd20520":"epochs = 10  # for better result increase the epochs\nbatch_size = 250","e3dd95dd":"# data augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=0.5,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.5, # Randomly zoom image 5%\n        width_shift_range=0.5,  # randomly shift images horizontally 5%\n        height_shift_range=0.5,  # randomly shift images vertically 5%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","1ac2b778":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val), steps_per_epoch=X_train.shape[0] \/\/ batch_size)","513db524":"# plot the loss accuracy curves for training and validation\nplt.plot(history.history[\"val_loss\"], color = \"b\", label= \"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","98b7b872":"# confusion matrix\nimport seaborn as sns\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","c427a6f8":"preds = model.predict(test)\npreds = np.argmax(preds,axis = 1)\n\noutput = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\")\noutput['Label'] = preds\noutput.to_csv('\/kaggle\/working\/submission.csv',index=False)","81def536":"output","6d8e28e9":"* normalize = gray Normalization  \n    * We perform a grayscale normalization to reduce the effect of illumination's differences.\n    * If we perform normalization, CNN works faster.\n* Reshape\n    * Train and test images (28 x 28)\n    * We reshape all data to 28x28x1 3D matrices.\n    * Keras needs an extra dimension in the end which correspond to channels. Our images are gray scaled so it use only one channel.\n* Label Encoding\n    * Encode labels to one hot vectors\n        * 2 => [0,0,1,0,0,0,0,0,0,0]\n        * 4 => [0,0,0,0,1,0,0,0,0,0]","327157c1":"### Data Augmentation\n* To avoid overfitting problem, we need to expand artificially our handwritten digit dataset\n* Alter the training data with small transformations to reproduce the variations of digit.\n* For example, the number is not centered The scale is not the same (some who write with big\/small numbers) The image is rotated.\n* <a href=\"https:\/\/ibb.co\/k24CUp\"><img src=\"https:\/\/preview.ibb.co\/nMxXUp\/augment.jpg\" alt=\"augment\" border=\"0\"><\/a>","0ac0d39a":"## Implement Pytorch","1ce83695":"## Loading Dataset","2e23d01f":"### Compile Model\n* categorical crossentropy\n* We make binary cross entropy at previous parts and in machine learning tutorial\n* At this time we use categorical crossentropy. That means that we have multi class.\n* <a href=\"https:\/\/ibb.co\/jm1bpp\"><img src=\"https:\/\/preview.ibb.co\/nN3ZaU\/cce.jpg\" alt=\"cce\" border=\"0\"><\/a>","f7ca3abc":"### Full Connection\n* Neurons in a fully connected layer have connections to all activations in the previous layer\n* Artificial Neural Network\n* <a href=\"https:\/\/ibb.co\/hsS14p\"><img src=\"https:\/\/preview.ibb.co\/evzsAU\/fullyc.jpg\" alt=\"fullyc\" border=\"0\"><\/a>","f6c87d78":"## Fit the Model","80ea3acd":"### What is Convolution Operation?\n* We have some image and feature detector(3*3)\n* Feature detector does not need to be 3 by 3 matrix. It can be 5 by 5 or 7 by 7.\n* Feature detector = kernel = filter\n* Feauture detector detects features like edges or convex shapes. Example, if out input is dog, feature detector can detect features like ear or tail of the dog.\n* feature map = conv(input image, feature detector). Element wise multiplication of matrices.\n* feature map = convolved feature\n* Stride = navigating in input image.\n* We reduce the size of image. This is important bc code runs faster. However, we lost information. \n* We create multiple feature maps bc we use multiple feature detectors(filters).\n* Lets look at gimp. Edge detect: [0,10,0],[10,-4,10],[0,10,0]\n* <a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/image.ibb.co\/m4FQC9\/gec.jpg\" alt=\"gec\" border=\"0\"><\/a>\n* After having convolution layer we use ReLU to break up linearity. Increase nonlinearity. Because images are non linear.\n* <a href=\"https:\/\/ibb.co\/mVZih9\"><img src=\"https:\/\/preview.ibb.co\/gbcQvU\/RELU.jpg\" alt=\"RELU\" border=\"0\"><\/a>","3cb6c9bb":"# Train Test Split","347e4611":"### Same Padding\n* As we keep applying conv layers, the size of the volume will decrease faster than we would like. In the early layers of our network, we want to preserve as much information about the original input volume so that we can extract those low level features.\n* input size and output size are same.\n* <a href=\"https:\/\/ibb.co\/jUPkUp\"><img src=\"https:\/\/preview.ibb.co\/noH5Up\/padding.jpg\" alt=\"padding\" border=\"0\"><\/a>","20d71a49":"### Create Model\n* conv => max pool => dropout => conv => max pool => dropout => fully connected (2 layer)\n* Dropout: Dropout is a technique where randomly selected neurons are ignored during training\n* <a href=\"https:\/\/ibb.co\/jGcvVU\"><img src=\"https:\/\/preview.ibb.co\/e7yPPp\/dropout.jpg\" alt=\"dropout\" border=\"0\"><\/a>","c2463b39":"## Convolutional Neural Networks (CNN)","d2cd0c97":"### Flattening\n* <a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/image.ibb.co\/c7eVvU\/flattenigng.jpg\" alt=\"flattenigng\" border=\"0\"><\/a>","f1ed6fc6":"## Convolutional Neural Network \n* CNN is used for image classification, object detection \n* <a href=\"https:\/\/ibb.co\/kV1j9p\"><img src=\"https:\/\/preview.ibb.co\/nRkBpp\/gec2.jpg\" alt=\"gec2\" border=\"0\"><\/a>","c9d84c21":"## Implementing with Keras","9072b310":"### Epochs and Batch Size\n* Say you have a dataset of 10 examples (or samples). You have a **batch size** of 2, and you've specified you want the algorithm to run for 3 **epochs**. Therefore, in each epoch, you have 5 **batches** (10\/2 = 5). Each batch gets passed through the algorithm, therefore you have 5 iterations **per epoch**.\n* reference: https:\/\/stackoverflow.com\/questions\/4752626\/epoch-vs-iteration-when-training-neural-networks","e017f7fc":"* We split the data into train and test sets\n* test size is 10%\n* train size is 90%"}}