{"cell_type":{"44218559":"code","f8d47ade":"code","072eac63":"code","1704d2f5":"code","8d5c173e":"code","70617315":"code","768683d9":"code","030eaac9":"code","0513bf3e":"code","07d85032":"code","805524f9":"code","c162d404":"code","71857be1":"code","61ff3a82":"code","db3ca49a":"code","90bff64b":"code","0a414051":"code","2101cbe3":"code","6c21a55b":"code","5b225a51":"code","6ba1fbb3":"code","7be5b146":"code","f01cbb64":"code","a6272486":"code","3b0467b2":"code","73b71f92":"code","b99e678f":"code","a988ea2a":"code","b2db240a":"code","f9732f5e":"code","e7508709":"code","409f8a63":"code","12014bf1":"code","137f4677":"code","99fd3c13":"code","ac578f55":"code","54449668":"code","5d800c4a":"code","569bb840":"code","f3781033":"code","30471af0":"code","7dc9f0e8":"code","83f958e9":"code","f2f44174":"markdown","0b4b5d41":"markdown","b3b48677":"markdown","13a218a9":"markdown","015fc272":"markdown","c2387e41":"markdown","519d85d4":"markdown","ff06e5bf":"markdown","d0c4212b":"markdown","bb7abc50":"markdown","4a6233b1":"markdown","67a73682":"markdown","003bd419":"markdown","d9d491ff":"markdown","6db5059a":"markdown","33e79a59":"markdown","9c1ef296":"markdown","a9323485":"markdown","2142d08f":"markdown","b7df9c12":"markdown","c0bf786b":"markdown","407997e3":"markdown","8a51a811":"markdown","bab15cf6":"markdown","6c9add20":"markdown","1f171e64":"markdown","37f9538a":"markdown"},"source":{"44218559":"!pip install visualkeras","f8d47ade":"import plotly.offline as pyo\npyo.init_notebook_mode()","072eac63":"import numpy as np\nfrom keras.utils import plot_model\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2 \nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfrom sklearn import preprocessing\nimport random\nimport tensorflow as tf","1704d2f5":"def Create_Directory_DataFrame():\n    df =pd.DataFrame(columns=['Class','Location'])\n    basedir = '..\/input\/chest-xray-pneumonia\/chest_xray\/'\n    category = ['val','test','train']\n    for choice in category:\n        for folder in os.listdir(basedir+choice+'\/'):\n            for Class in os.listdir(basedir+choice+'\/'+folder+'\/'):\n                    df = df.append({'Class':folder,'Location':basedir+choice+'\/'+folder+'\/'+Class},ignore_index=True)\n    df = df.sample(frac = 1) \n    return df\n\ndf = Create_Directory_DataFrame()","8d5c173e":"print(df.shape)\ndf.head()","70617315":"count = 1\nf = plt.figure(figsize=(50,13))\nfor Class in df['Class'].unique():\n    seg = df[df['Class']==Class]\n    address =  seg.sample().iloc[0]['Location']\n    img = cv2.imread(address,0)\n    ax = f.add_subplot(1, 2,count)\n    ax = plt.imshow(img)\n    ax = plt.title(Class,fontsize= 30)\n    count = count + 1\nplt.suptitle(\"X -Ray Samples\", size = 32)\nplt.show()","768683d9":"img.shape","030eaac9":"from tqdm import tqdm\ntrain_image = []\nfor location in tqdm(df.iloc[:]['Location']):\n    img = cv2.imread(location,0)\n    img = cv2.resize(img, (64,64), interpolation = cv2.INTER_AREA)\n    img = img.reshape(64,64,1)\n    train_image.append(img)\nX = np.array(train_image)","0513bf3e":"from sklearn.preprocessing import OneHotEncoder\ny = np.array(df.iloc[:]['Class'])\ny = y.reshape(y.shape[0],1)\nenc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(y)\ny = enc.transform(y).toarray()\nprint(enc.categories_)","07d85032":"print('Data   :   '+str(X.shape))\nprint('Output :   '+str(y.shape))","805524f9":"print(X[0].reshape(64,64))","c162d404":"plt.figure(figsize=(25,8))\nplt.imshow(X[0].reshape(64,64))\nplt.title(enc.inverse_transform(y[0].reshape(1,2))[0][0],size = 20)\nplt.show()","71857be1":"y[0]","61ff3a82":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)","db3ca49a":"print('Train data    :'+str(X_train.shape))\nprint('Test data     :'+str(X_test.shape))\nprint('Train Output  :'+str(y_train.shape))\nprint('Test Output   :'+str(y_test.shape))","90bff64b":"COUNT_NORMAL =  df[df['Class']== 'NORMAL'].count()[0]\nCOUNT_PNEUMONIA =  df[df['Class']== 'PNEUMONIA'].count()[0]\nTRAIN_IMG_COUNT = X_train.shape[0]\nprint('NORMAL Images :  '+str(COUNT_NORMAL))\nprint('PNEUMONIA Images :  '+str(COUNT_PNEUMONIA))\ninitial_bias = np.log([COUNT_PNEUMONIA\/COUNT_NORMAL])\nprint(initial_bias)\nweight_for_0 = (1 \/ COUNT_NORMAL)*(TRAIN_IMG_COUNT)\/2.0 \nweight_for_1 = (1 \/ COUNT_PNEUMONIA)*(TRAIN_IMG_COUNT)\/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","0a414051":"import visualkeras\nvisualkeras.layered_view(model)","2101cbe3":"model.summary()","6c21a55b":"plot_model(model, to_file='model.png',show_shapes=True)","5b225a51":"def conv_block(filters):\n    block = tf.keras.Sequential([\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D()\n    ]\n    )\n    return block\ndef dense_block(units, dropout_rate):\n    block = tf.keras.Sequential([\n        tf.keras.layers.Dense(units, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(dropout_rate)\n    ])\n    return block\ndef build_model(act):\n    model = tf.keras.Sequential([\n        tf.keras.Input(shape=(64,64, 1)),\n        \n        tf.keras.layers.Conv2D(16, 3, activation=act, padding='same'),\n        tf.keras.layers.Conv2D(16, 3, activation=act, padding='same'),\n        tf.keras.layers.MaxPool2D(),\n        \n        conv_block(32),\n        conv_block(64),\n        \n        conv_block(128),\n        tf.keras.layers.Dropout(0.2),\n        \n        conv_block(256),\n        tf.keras.layers.Dropout(0.2),\n        \n        tf.keras.layers.Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        \n        tf.keras.layers.Dense(2, activation='sigmoid')\n    ])\n    return model","6ba1fbb3":"def wrap(Training_Output_Results , Opt , Act ,  history):\n    epoch  = len(history.history['loss'])\n    epochs = list(np.arange(1,epoch + 1,1))\n    Optimizer = np.repeat(Opt,epoch).tolist()\n    Activation = np.repeat(Act,epoch).tolist()\n    cumiliated_res = {}\n    cumiliated_res['Epochs']=epochs\n    cumiliated_res['Optimizer']=Optimizer\n    cumiliated_res['Activation_Function']=Activation\n    cumiliated_res['Train_Loss']=history.history['loss']\n    cumiliated_res['Train_Accuracy']=history.history['accuracy']\n    cumiliated_res['Train_Precision']=history.history['precision']\n    cumiliated_res['Train_Recall']=history.history['recall']\n    cumiliated_res['Val_Loss']=history.history['val_loss']\n    cumiliated_res['Val_Accuracy']=history.history['val_accuracy']\n    cumiliated_res['Val_Precision']=history.history['val_precision']\n    cumiliated_res['Val_Recall']=history.history['val_recall']\n    convertDictionary = pd.DataFrame(cumiliated_res)\n    Training_Output_Results = Training_Output_Results.append(convertDictionary)\n    return Training_Output_Results","7be5b146":"Optimisers = ['RMSprop','Adam','Adadelta','Adagrad']\nActivation_function =['relu','sigmoid','softmax','tanh','softsign','selu','elu']","f01cbb64":"Training_Output_Results =pd.DataFrame(columns=['Epochs','Optimizer','Activation_Function','Train_Loss','Train_Accuracy','Train_Precision','Train_Recall',                                             'Val_Loss','Val_Accuracy','Val_Precision','Val_Recall'])\ndef Optimise_verify(Training_Output_Results):\n    for opt in Optimisers:\n        model = build_model(Activation_function[0])\n        METRICS = [\n                'accuracy',\n                tf.keras.metrics.Precision(name='precision'),\n                tf.keras.metrics.Recall(name='recall')\n        ]  \n        model.compile(\n                optimizer=opt,\n                loss='categorical_crossentropy',\n                metrics=METRICS\n            )\n        history = model.fit(X_train, y_train, epochs=100, validation_split=0.3, batch_size=15,verbose=1,shuffle=True)\n        Training_Output_Results = wrap(Training_Output_Results , opt,Activation_function[0],history)\n        print('---------------------Round for '+opt+' Completed-----------------------------------------')\n    return Training_Output_Results\n    \n    \nTraining_Output_Results = Optimise_verify(Training_Output_Results)","a6272486":"Training_Output_Results=Training_Output_Results.sample(frac = 1) \nprint(Training_Output_Results.shape)\nTraining_Output_Results.to_csv('Optimizer_64*64_data.csv', index = False) \nTraining_Output_Results.head()","3b0467b2":"Training_Output_Results =pd.DataFrame(columns=['Epochs','Optimizer','Activation_Function','Train_Loss','Train_Accuracy','Train_Precision','Train_Recall',\n                                              'Val_Loss','Val_Accuracy','Val_Precision','Val_Recall'])\ndef Activation_verify(Training_Output_Results):\n    for act in Activation_function:\n        model = build_model(act)\n        METRICS = [\n                'accuracy',\n                tf.keras.metrics.Precision(name='precision'),\n                tf.keras.metrics.Recall(name='recall')\n        ]  \n        model.compile(\n                optimizer=Optimisers[0],\n                loss='categorical_crossentropy',\n                metrics=METRICS\n            )\n        history = model.fit(X_train, y_train, epochs=100, validation_split=0.3, batch_size=15,verbose=0,shuffle=True)\n        Training_Output_Results = wrap(Training_Output_Results , Optimisers[0],act,history)\n        print('---------------------Round for '+act+' Completed-----------------------------------------')\n    return Training_Output_Results\n    \n    \nTraining_Output_Results = Activation_verify(Training_Output_Results)","73b71f92":"Training_Output_Results=Training_Output_Results.sample(frac = 1) \nprint(Training_Output_Results.shape)\n\nTraining_Output_Results.to_csv('Activation_64*64_data.csv', index = False)\nTraining_Output_Results.head()","b99e678f":"opt = pd.read_csv('.\/Optimizer_64*64_data.csv')\nact = pd.read_csv('.\/Activation_64*64_data.csv')","a988ea2a":"import plotly.express as px\nimport plotly.io as pio\nimport statsmodels.api as sm\nscatterplot = px.scatter(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Train_Accuracy\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Accuracy',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\npyo.iplot(scatterplot, filename = 'Opt_train_acc')","b2db240a":"scatterplot = px.scatter(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Train_Loss\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Loss',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_train_loss')","f9732f5e":"scatterplot = px.scatter(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Train_Precision\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Precision',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_train_prec')","e7508709":"scatterplot = px.scatter(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Train_Recall\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Recall',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_train_recall')","409f8a63":"scatterplot = px.scatter(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Val_Accuracy\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Validation Accuracy',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_val_acc')","12014bf1":"scatterplot = px.scatter(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Val_Precision\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Validation Precision',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_val_prec')","137f4677":"scatterplot = px.scatter(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Val_Recall\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Validation Recall',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_val_recall')","99fd3c13":"scatterplot = px.scatter(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Val_Loss\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Validation Loss',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_val_loss')","ac578f55":"import plotly.express as px\nimport plotly.io as pio\nimport statsmodels.api as sm\nscatterplot = px.scatter(\n    data_frame=act,\n    x=\"Epochs\",\n    y=\"Train_Accuracy\",\n    color=\"Activation_Function\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    #facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    #facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Accuracy',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Act_train_acc')","54449668":"import plotly.express as px\nimport plotly.io as pio\nimport statsmodels.api as sm\nscatterplot = px.scatter(\n    data_frame=act,\n    x=\"Epochs\",\n    y=\"Train_Loss\",\n    color=\"Activation_Function\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    #facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    #facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Loss',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Act_train_loss')","5d800c4a":"import plotly.express as px\nimport plotly.io as pio\nimport statsmodels.api as sm\nscatterplot = px.scatter(\n    data_frame=act,\n    x=\"Epochs\",\n    y=\"Train_Precision\",\n    color=\"Activation_Function\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    #facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    #facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Precision',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Act_train_prec')","569bb840":"import plotly.express as px\nimport plotly.io as pio\nimport statsmodels.api as sm\nscatterplot = px.scatter(\n    data_frame=act,\n    x=\"Epochs\",\n    y=\"Train_Recall\",\n    color=\"Activation_Function\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    #facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    #facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Recall',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Act_train_rec')","f3781033":"def Plot(history , name , model):\n    model.save(name+'.h5')\n    epochs = range(1,len(history.history['loss']) + 1)\n    epochs = list(epochs)\n    fig = make_subplots(rows=2, cols=4,subplot_titles=(\"Train Loss\", \"Train Accuracy\" , \"Train Precision\",\"Train Recall\", \"Validation Loss\", \"Validation Accuracy\",\n                                                      \"Validation Precision\",\"Validation Recall\"))\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['loss']), row=1, col=1)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['accuracy']), row=1, col=2)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['precision']), row=1, col=3)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['recall']), row=1, col=4)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['val_loss']), row=2, col=1)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['val_accuracy']), row=2, col=2)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['val_precision']), row=2, col=3)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['val_recall']), row=2, col=4)\n    fig.update_layout(showlegend=False,height=1000, width=1200, title_text=name)\n    pyo.iplot(fig, filename = 'Act_train_rec')","30471af0":"model = build_model('relu')\nMETRICS = [\n                'accuracy',\n                tf.keras.metrics.Precision(name='precision'),\n                tf.keras.metrics.Recall(name='recall')\n]  \nmodel.compile(\n                optimizer='adam',\n                loss='categorical_crossentropy',\n                metrics=METRICS\n        )\nhistory = model.fit(X_train, y_train, epochs=100, validation_split=0.3, batch_size=15,verbose=1,shuffle=True)","7dc9f0e8":"Plot(history , 'model_layered_5',model)","83f958e9":"y_pred = model.evaluate(X_test , y_test,verbose =1)","f2f44174":"Loss is again similarly correlated to acuracy thus not clear distinction here also","0b4b5d41":"# Correct for data imbalance","b3b48677":"1. To make our model more modular and easier to understand, let's define some blocks. As we're building a convolution neural network, we'll create a convolution block and a dense layer block.\n2. The following method will define the function to build our model for us. The Dropout layers are important as they \"drop out,\" hence the name, certain nodes to reduce the likelikhood of the model overfitting. We want to end the model with a Dense layer of one node, as this will be the output that determines if an X-ray shows an image of pneumonia.\n\n\nSince there are only two possible labels for the image, we will be using the binary_crossentropy loss. When we fit the model, identify the class weights. Because we are using a TPU, training will be relatively quick.\n\nFor our metrics, we want to include precision and recall as they will provide use with a more informed picture of how good our model is. Accuracy tells us what fractions are the labels are correct. Since our data is not balanced, accuracy might give a skewed sense of a good model (i.e. a model that always predicts PNEUMONIA will be 74% accurate but is not a good model).\n\nPrecision is the number of true positives (TP) over the sum of TP and false positives (FP). It shows what fraction of labeled positives are actually correct.\n\nRecall is the number of TP over the sum of TP and false negatves (FN). It shows what fraction of actual positives are correct.","13a218a9":"Mostly all Activation functions achieve 99% accuracy thus not much to choose from ","015fc272":"# Loading Data","c2387e41":"## Activation Function","519d85d4":"# Segmentation in Traing and Test Data Sets","ff06e5bf":"### Note : \nhere on we are trying to build vivid model analytics with different optimizers and Activation Function.\nFun fact each epoch for 128*128*3 image takes 8s thus for a total of 11 trainings 11*8*100\/60 = 146 hours of GPU time\nHence we have chosen 64*64*3 which takes just under 3 sec per epoch which is much effective and more economical\nHowever higher resolution should be depicted for compercial use\n","d0c4212b":"After witnessing all the graphs Adam is the better choice than RMSprop by just a little","bb7abc50":"## Optimizer Analytics","4a6233b1":"## Optimizer","67a73682":"# Sample Proceeding","003bd419":"# MODEL","d9d491ff":"The weight for class 0 (Normal) is a lot higher than the weight for class 1 (Pneumonia). Because there are less normal images, each normal image will be weighted more to balance the data as the CNN works best when the training data is balanced.","6db5059a":"# Data Creation","33e79a59":"We saw earlier in this notebook that the data was imbalanced, with more images classified as pneumonia than normal. We will correct for that in this following section.","9c1ef296":"Very Slight Variation Relu , Selu , elu and tanh all produce  97% recall and thus can be utilised","a9323485":"# Final Results","2142d08f":"Completely in correlation to the above results we are able to deduce that RMSPROP or Adam is quite a good fit","b7df9c12":"# Ploting","c0bf786b":"# Final Model","407997e3":"Precision too stays closely in sync to what we have prior seen as RMSPROP and Adam are the best with 99.8 and 99.6% respectively","8a51a811":"Here we can first time see slight variation in results RMSprop with 94.4% recall and Adam with 97%, based on this Adam stands slightly better choice","bab15cf6":"## Activation Analytics","6c9add20":"Validation Accuracy to have a similar conclusion rather where RMSprop starting from 56.26 rises to 95.6 and Adam too right at 96.5 %","1f171e64":"# Visualize Data","37f9538a":"Adelta gives the minimum accuracy however RMSPROP and ADAMstand right at 99%"}}