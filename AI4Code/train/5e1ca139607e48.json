{"cell_type":{"e4cd5aa3":"code","636b11ff":"code","7112cdda":"code","7b05657d":"code","25bd9870":"code","e927fdef":"code","412bda6d":"code","5af467ac":"code","da3490d1":"code","7e37b04b":"code","0581e5a6":"code","cd75bd43":"code","16ff905b":"code","9f5aebaf":"code","bc58499a":"code","ccd1eb44":"code","99d53ae6":"code","88976615":"code","c414e208":"code","191a885d":"code","ef683008":"code","3e1b8b02":"code","2d668ccf":"code","4dc9ff93":"code","17b5307e":"code","1e17bbc6":"code","efdd5580":"code","149732fd":"code","e8d5d2aa":"code","45a74ca2":"code","d2dbf60a":"code","d84f0f58":"code","12456edb":"code","fe462bf0":"code","d70f73fb":"code","ebbdbba1":"code","7d93b43d":"code","a989cac4":"code","34d084c0":"code","1e4187a3":"code","ffa9750c":"code","0fd8d066":"code","ffba3510":"code","3147c44a":"code","3b5a8352":"code","d2129452":"code","ffbf5493":"code","0280690a":"code","00ada6e6":"markdown","68004f0c":"markdown","fdc74b6f":"markdown","ff1c8db4":"markdown","bf335810":"markdown","f0459682":"markdown","70649d24":"markdown","8695066f":"markdown","e5eed33a":"markdown","5a105817":"markdown","49cdba55":"markdown","8221f039":"markdown","96af9e2e":"markdown","ee9866ae":"markdown","d1bd6f61":"markdown","be7e806f":"markdown","8cc17f63":"markdown","2689c3b6":"markdown","964ae694":"markdown","c04e8a95":"markdown","a719d46f":"markdown","19f024b2":"markdown","6207d2b6":"markdown","57381e7d":"markdown","a09694d8":"markdown","e91d564b":"markdown","3fca2888":"markdown","54fa2b26":"markdown","575422e6":"markdown","ad35b631":"markdown","09b6b7d6":"markdown","0ea55db8":"markdown","d14a1a27":"markdown","8d17bbd2":"markdown","67a2491a":"markdown","2fb8ccc7":"markdown","caf8087e":"markdown","0bfee2c6":"markdown","45e7d591":"markdown","f64a1640":"markdown","83c4d8d8":"markdown","51fea599":"markdown","1098a913":"markdown","f8d27d46":"markdown","87fbbd4e":"markdown","10fb22b7":"markdown","7fb42e0c":"markdown","6906e5ef":"markdown"},"source":{"e4cd5aa3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","636b11ff":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# for Q-Q plots\nimport scipy.stats as stats\n\nfrom sklearn.metrics import roc_auc_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\n\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","7112cdda":"train=pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","7b05657d":"train.head()","25bd9870":"train.shape","e927fdef":"train.Class.value_counts()","412bda6d":"plt.figure(figsize=(5,5))\nsns.countplot(train.Class)\nplt.show()","5af467ac":"train.drop_duplicates(inplace=True)","da3490d1":"train.shape","7e37b04b":"284807-283726","0581e5a6":"train.Class.value_counts()","cd75bd43":"train.isnull().sum().sort_values(ascending=False)","16ff905b":"train.describe()","9f5aebaf":"train[train['Class'] ==1][['Time','Class']]","bc58499a":"## Time can be dropped, as it does not contribute in Analysis\n\n#train.drop('Time', axis=1 , inplace=True)","ccd1eb44":"plt.figure(figsize=(30,30))\nsns.heatmap(train.corr(),annot=True, vmax=1.0, vmin=-1.0, mask=np.tril(train.corr()))\nplt.ylim(0,30);","99d53ae6":"y=train['Class']\ntrain.drop('Class', axis=1, inplace=True)","88976615":"def evaluate_model(x_train, x_test, y_train,y_test):\n    clf=RandomForestClassifier()\n    clf.fit(x_train,y_train)\n    y_pred=clf.predict(x_test)\n    print('ROC_VALUE : ',roc_auc_score(y_test,y_pred),'\\n')\n    print('classification_report : ','\\n',classification_report(y_test,y_pred),'\\n')\n    print('confusion_matrix : ','\\n',confusion_matrix(y_test,y_pred))","c414e208":"x_train, x_test, y_train,y_test= train_test_split(train,y, test_size=0.2, random_state=123)","191a885d":"evaluate_model(x_train, x_test, y_train,y_test)","ef683008":"x_train, x_test, y_train,y_test= train_test_split(train,y, test_size=0.2, random_state=123)","3e1b8b02":"clf=RandomForestClassifier()","2d668ccf":"performance = []","4dc9ff93":"for feat in x_train.columns:\n    \n    clf.fit(x_train[feat].to_frame(),y_train)  # Fit only 1 feature at a time and record the roc_auc value.\n    y_pred = clf.predict(x_test[feat].to_frame())\n    performance.append(roc_auc_score(y_test,y_pred))","17b5307e":"performance","1e17bbc6":"roc_values = pd.Series(performance)\nroc_values.index = x_train.columns\nroc_values.sort_values(ascending=False).plot.bar(figsize=(20, 5))\nplt.ylabel('roc-auc');","efdd5580":"impt_feat = list(roc_values[roc_values>0.51].index)","149732fd":"impt_feat","e8d5d2aa":"X_train = x_train[impt_feat]","45a74ca2":"X_test = x_test[impt_feat]","d2dbf60a":"X_train.head()","d84f0f58":"evaluate_model(X_train, X_test, y_train,y_test)","12456edb":"from sklearn.feature_selection import SelectFromModel","fe462bf0":"x_train, x_test, y_train,y_test= train_test_split(train,y, test_size=0.2, random_state=123)","d70f73fb":"sel_ = SelectFromModel(RandomForestClassifier(n_estimators=50, random_state=123))\n\nsel_.fit(x_train, y_train)","ebbdbba1":"selected_feat = x_train.columns[(sel_.get_support())]","7d93b43d":"selected_feat","a989cac4":"X_train = x_train[selected_feat]","34d084c0":"X_test = X_test[selected_feat]","1e4187a3":"evaluate_model(X_train, X_test, y_train,y_test)","ffa9750c":"x_train, x_test, y_train,y_test= train_test_split(train,y, test_size=0.2, random_state=123)","0fd8d066":"from sklearn.linear_model import Lasso, LogisticRegression","ffba3510":"sel_ = SelectFromModel(LogisticRegression(C=0.5, penalty='l1', solver='liblinear', random_state=123))\n\nsel_.fit(x_train, y_train)","3147c44a":"selected_feat = x_train.columns[(sel_.get_support())]","3b5a8352":"(selected_feat)","d2129452":"X_train = x_train[selected_feat]","ffbf5493":"X_test = x_test[selected_feat]","0280690a":"evaluate_model(X_train, X_test, y_train,y_test)","00ada6e6":"We can see the Precision is showing as 0.95 for class 1.\n\nWhat thats mean is, model predicted as Class 1 (or Fraud transaction)  for total (82+4) = 86 records , but out of 86, 82 is correct prediction. That's give the precision as 82\/86 ~ 0.95.","68004f0c":"Here i will be using Random forest for features selection and will be using only those features for model training.","fdc74b6f":"We can see the Precision is showing as 0.95 for class 1.\n\nWhat thats mean is, model has predicted as Class 1 (or Fraud transaction)  for total (82+4) = 86 records , but out of 86 , 82 is correct prediction. That's give the precision as 82\/86 ~ 0.95","ff1c8db4":"#### Note:- Here we need to focus on maximazing the Recall. As we do not want to miss out any fraud transaction.\nWhat i mean by this is, we need to minimize the count of transaction that is actually a fraud but model predicted as not fraud.","bf335810":"So, We can see the recall is given as 0.80 for class 1.\n\nWhat thats mean is, There are total (21+82) = 103 actual fraud transaction. But out of 103, our model has predicted only 82 as fraud transactions. That's give the recall as 82\/103 ~ 0.80.","f0459682":"Recall :- It indicates out of actual total positive class , how many class model predicted correctly.","70649d24":"## Model 0:-","8695066f":"Luckly..! There is no null value for any feature.","e5eed33a":"So, We can see the recall is given as 0.80 for class 1.\n\nWhat thats mean is, There are total (21+82) = 103 actual fraud transaction. But out of 103, our model has predicted only 82 as fraud transactions. That's give the recall as 82\/103 ~ 0.80.","5a105817":"\n\nAnd actually this is the parameter we need to work on to improve the model performance. So that the model can predict more and more fraud transactions.","49cdba55":"Precision :- It indicate out of total prediction of positive class how many of them is actually correct prediction.","8221f039":"But in this problem case We need not focus on how many Class 1 (or Fraud transaction) is predicted. Instead we need to focus on out of ACTUAL total fraud transaction, how many of them our model has predicted correctly. \n\nAnd that we will get from Recall.","96af9e2e":"Do not see any pattern in time and Class features.","ee9866ae":"from above plot we can see most of the value is around 0.50. So, I will consider only those features which have roc_auc > 0.51.","d1bd6f61":"Still the dataset is highly imbalanced.","be7e806f":"Now, Lets jump to prepare different model check performace.","8cc17f63":"Here, what i will do is, will consider 1 feature at a time and create a model to predict the roc_auc value.\nAnd later i will consider only those features for training the model which has roc_auc value greater than some threshold.","2689c3b6":"So, here we can see the dataset is highly imbalanced. Out of 284807 transactions only 492 transactions are recorded as fraud.","964ae694":"NOTE : - Below we will be focusing on Class 1, as class 1 corresponds to Fraud transaction.","c04e8a95":"Hi There..!","a719d46f":"Here, We can observe that even though the accuracy is showing 1.0, still the model is not THE BEST. \n\nNow lets talk about Precision and Recall.","19f024b2":"Now let's check if there are any null values present for any feature.","6207d2b6":"So, We can see the recall is given as 0.80 for class 1.\n\nWhat thats mean is, There are total (21+82) = 103 actual fraud transaction. But out of 103, our model has predicted only 82 as fraud transactions. That's give the recall as 82\/103 ~ 0.80.","57381e7d":"First we will import some important libraries","a09694d8":"I know it may sound very confusing now (that's why it is named as confusion matrix.--  kidding). It will get clear once we start evaluating the model.","e91d564b":"## Model 2:-","3fca2888":"## Model 1:-  ","54fa2b26":"So, Here we will be using confusion_matrix, classification_report, precision and recall for model performance evaluation.","575422e6":"Read the Dataset.","ad35b631":"Now, Quickly check some important info about our features using Describe method.","09b6b7d6":"So, One last thing, we should not blindly focus only on Precision and recall alone based on the given problem. There is one more parameter in Classification report i.e. f1_score, We can evaluate the model performance based on f1-score as well.","0ea55db8":"Let's see the distribution of Class.","d14a1a27":"That's it for now..!!","8d17bbd2":"Now, Let's plot the heatmap to check the correlation between any features.","67a2491a":"## Model 3:- \n#### LASSO","2fb8ccc7":"Ok Now, let's check if there are any duplicate records exist.","caf8087e":"So Yes, there were around 1081 duplicate records present and we dropped those.","0bfee2c6":"But before that we need to discuss about which evaluation parameter to use for the model performance. As we cannot use Accuracy here since the dataet is highly imbalanced.\nWhat that mean is, even if i blindly predict Class = 0 for all the records i will get a accuracy of more than 99%, but we will be missing to identify the fraud (And Identifing fraud is our main objective here).","45e7d591":"What is Precision and recall here:-","f64a1640":"So, there are total 284807 number of records and we have total 31 features including one target variable i.e 'Class'.","83c4d8d8":"## Now lets create few more models by doing some kind of features selection","51fea599":"Thank You...!","1098a913":"Lets create a model by considering all the featues.","f8d27d46":"Today we will solving oe of the most famous problem Credit card fraud detection.\nLet's Start....!","87fbbd4e":"We can see the Precision is showing as 0.93 for class 1.\n\nWhat thats mean is, model predicted as Class 1 (or Fraud transaction)  for total (80+6) = 86 records , but out of 86, 80 is correct prediction. That's give the precision as 80\/86 ~ 0.93","10fb22b7":"Ok....! So we do not see any much of correaltion between any 2 features.","7fb42e0c":"We can see the Precision is showing as 0.96 for class 1.\n\nWhat thats mean is, model predicted as Class 1 (or Fraud transaction)  for total (82+3) = 85 records , but out of 85, 82 is correct prediction. That's give the precision as 82\/85 ~ 0.96","6906e5ef":"So, We can see the recall is given as 0.78 for class 1.\n\nWhat thats mean is, There are total (23+80) = 103 actual fraud transaction. But out of 103, our model has predicted only 80 as fraud transactions. That's give the recall as 80\/103 ~ 0.78."}}