{"cell_type":{"116fc62c":"code","021c31fe":"code","8e5767f7":"code","f43e0594":"code","a02bb321":"code","0f1d269d":"code","be7cb984":"code","8cbea37d":"code","9f2b1945":"code","08fc274f":"code","4ce2cb85":"code","96cad98c":"code","72314e5c":"code","9b40b365":"code","3aadf3f6":"code","dc4849aa":"code","66f09ac8":"code","af0597c8":"code","8ffa04a4":"code","b4f6e99b":"code","2325cae2":"code","826b7928":"code","3ff6f4c3":"code","0e7ef640":"code","a15e78d4":"code","5cc5c62b":"code","a128648d":"code","eea4ebed":"code","85e20b0f":"code","0fe9a578":"code","ebcdb370":"code","be9bef09":"code","eee997d6":"code","07944c97":"code","20c143fd":"code","7f4ebde0":"markdown","70e6b7e4":"markdown","272fdce2":"markdown","8c554f92":"markdown","ee011851":"markdown","de9507d2":"markdown","1ccf712c":"markdown","dbce5e7d":"markdown","0890cb7b":"markdown"},"source":{"116fc62c":"# IMPORTING LIBRARY\nimport pandas as pd","021c31fe":"# OUR DATA FRAME\ndf= pd.read_csv('..\/input\/fake-news-dataset\/fakenews_train.csv')\ndf.head()","8e5767f7":"# DROPPING NaN VALUES\ndf=df.dropna()","f43e0594":"## GETTING INDEPENDENT FEATURES\nx= df.drop('label',axis=1)","a02bb321":"# DEPENDENT FEATURE OR TARGET FEATURE\ny=df['label']","0f1d269d":"# LOOKING AT THE SHAPE OF OUR IINDEPENDENT FEATURES DATASET\nx.shape","be7cb984":"# LOOKING AT THE SHAPE OF OUR DEPENDENT FEATURE\ny.shape","8cbea37d":"# IMPORTING MORE NECESSARY LIBRARIES\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense","9f2b1945":"# vocabularry size\nvoc_size=5000","08fc274f":"# COPYING OUR INDEPENDENT FEATURE DATASET 'x' INTO NEW VARIABLE 'messages'\nmessages= x.copy()","4ce2cb85":"# RESETTING THE INDEX VALUES\nmessages.reset_index(inplace=True)","96cad98c":"# IMPORTING LIBRARIES FOR NATURAL LANGUAGE PROCESSING\nimport nltk\nimport re\nfrom nltk.corpus import stopwords","72314e5c":"# DOWNLOADING THE STOPWORDS\nnltk.download('stopwords')","9b40b365":"# TEXT PREPROCESSING--> STEMMING, REMOVAL OF STOP WORDS, CONVERTING INTO LOWER CASE\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","3aadf3f6":"# LOOKING AT OUR FINAL CORPUS\ncorpus","dc4849aa":"from tensorflow.keras.preprocessing.text import one_hot","66f09ac8":"onehot_repr= [one_hot(words,voc_size)for words in corpus]\nprint(onehot_repr)","af0597c8":"# SETTING OUR SENTENCE LENGTH = 20\nsent_length=20\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\nprint(embedded_docs)","8ffa04a4":"len(embedded_docs)","b4f6e99b":"## CREATING OUR LSTM MODEL\nembedding_vector_features= 40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length)) # making embedding layer\nmodel.add(LSTM(100))  # one LSTM Layer with 100 neurons\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","2325cae2":"# CONVERTING X AND Y INTO ARRAYS\nimport numpy as np\nx_final= np.array(embedded_docs)\ny_final= np.array(y)","826b7928":"# SPLITTING THE DATA INTO TRAINING AND TEST SETS\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x_final,y_final,test_size=0.33,random_state=0)","3ff6f4c3":"# FITTING NTO THE MODEL\nmodel.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10,batch_size=64)","0e7ef640":"# OUR PREDICTION VARIABLE\ny_pred= model.predict_classes(x_test)","a15e78d4":"y_pred","5cc5c62b":"# IMPORTING LIBRARIES TO SEE THE ACCURACY\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n# PRINTING CONFUSION MATRIX\ncm= confusion_matrix(y_test,y_pred)\nprint(cm)","a128648d":"# ACCURACY SCORE\nac= accuracy_score(y_test,y_pred)\nprint(ac)","eea4ebed":"from tensorflow.keras.layers import Dropout\n","85e20b0f":"## CREATING MODEL WITH DROPOUT LAYER\nembedding_vector_features= 40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length)) # making embedding layer\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))  # one LSTM Layer with 100 neurons\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","0fe9a578":"# CONVERTING X AND Y VARIABLES INTO ARRAYS\nimport numpy as np\nx_final= np.array(embedded_docs)\ny_final= np.array(y)","ebcdb370":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x_final,y_final,test_size=0.33,random_state=0)","be9bef09":"# FITTING INTO THE MODEL\nmodel.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10,batch_size=64)","eee997d6":"# PREDICTION MODEL\ny_pred= model.predict_classes(x_test)","07944c97":"from sklearn.metrics import confusion_matrix, accuracy_score\n\n# PRINTING CONFUSION MATRIX\ncmm= confusion_matrix(y_test,y_pred)\nprint(cmm)","20c143fd":"# ACCURACY SCORE\nac= accuracy_score(y_test,y_pred)\nprint(ac)","7f4ebde0":"# EMBEDDING REPRESENTATION","70e6b7e4":"# MODEL TRAINING","272fdce2":"# FAKE NEWS CLASSIFIER USING LSTM\n\nIN THIS NOTEBOOK WE WILL CLASSIFY WHETHER THE NEWS IS FAKE OR NOT USING LSTM MODEL.\n\n1--> REAL\n\n0--> FAKE\n\nWE WILL PERFORM SOME TEXT PREPROCESSING( STEMMING, REMOVAL OF STOP WORDS, CONVERTING TEXT INTO VECTORS)\n\nTHEN WE WILL BUILD OUR LSTM MODEL TO CLASSIFY THE NEWS","8c554f92":"##### ACCURACY SCORE= 91.43 %","ee011851":"# ONE HOT REPRESENTATION","de9507d2":" ##### ACCURACY SCORE AFTER ADDING DROPOUT LAYER= 91.05%\n\n\n ##### OUR ACCURACY DECREASED A LITTLE IN THIS CASE AFTER ADDING DROPOUT LAYER","1ccf712c":"# NATURAL LANGUAGE PROCESSING","dbce5e7d":"# CREATING OUR LSTM MODEL","0890cb7b":"# ADDING DROPOUT LAYER"}}