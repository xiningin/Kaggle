{"cell_type":{"cd04a99c":"code","e13563f3":"code","2a4b36b2":"code","c3a377fd":"code","e14b8676":"code","7a78acc0":"code","809a3978":"code","19757730":"code","e57a0277":"code","e0402aca":"code","01f21208":"code","393c8667":"code","3a6bd0a7":"code","6ee5fce4":"code","a71430d3":"code","b5b50769":"code","8920b260":"code","a3fe34b9":"code","cbf3002c":"code","42ab72b6":"code","e2d2d9a8":"code","88c1bcef":"code","43da34ce":"code","cbf432f8":"markdown","5262f7ba":"markdown","ee1a8f3c":"markdown","4dff891a":"markdown","ed64e736":"markdown","8db9851a":"markdown","85c9b539":"markdown","35a66abc":"markdown","842db219":"markdown","3fd1c3ef":"markdown","73a982ee":"markdown","6e21efef":"markdown","8c6c74b1":"markdown","94b09d18":"markdown","b0d3ae42":"markdown","a098fd2e":"markdown","236146e4":"markdown","47b9ccf5":"markdown","160ec5ed":"markdown"},"source":{"cd04a99c":"import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\nfrom skimage.filters import threshold_local\nfrom PIL import Image","e13563f3":"# Sample file out of the dataset\nfile_name = '\/kaggle\/input\/personal-receipt-collection\/20201007_110604.jpg'\nimg = Image.open(file_name)\nimg.thumbnail((800,800), Image.ANTIALIAS)\nimg","2a4b36b2":"def opencv_resize(image, ratio):\n    width = int(image.shape[1] * ratio)\n    height = int(image.shape[0] * ratio)\n    dim = (width, height)\n    return cv2.resize(image, dim, interpolation = cv2.INTER_AREA)","c3a377fd":"def plot_rgb(image):\n    plt.figure(figsize=(16,10))\n    return plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))","e14b8676":"def plot_gray(image):\n    plt.figure(figsize=(16,10))\n    return plt.imshow(image, cmap='Greys_r')","7a78acc0":"image = cv2.imread(file_name)\n# Downscale image as finding receipt contour is more efficient on a small image\nresize_ratio = 500 \/ image.shape[0]\noriginal = image.copy()\nimage = opencv_resize(image, resize_ratio)","809a3978":"# Convert to grayscale for further processing\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nplot_gray(gray)","19757730":"# Get rid of noise with Gaussian Blur filter\nblurred = cv2.GaussianBlur(gray, (5, 5), 0)\nplot_gray(blurred)","e57a0277":"# Detect white regions\nrectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\ndilated = cv2.dilate(blurred, rectKernel)\nplot_gray(dilated)","e0402aca":"edged = cv2.Canny(dilated, 100, 200, apertureSize=3)\nplot_gray(edged)","01f21208":"cv2.__version__","393c8667":"# Detect all contours in Canny-edged image\ncontours, hierarchy = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\nimage_with_contours = cv2.drawContours(image.copy(), contours, -1, (0,255,0), 3)\nplot_rgb(image_with_contours)","3a6bd0a7":"# Get 10 largest contours\nlargest_contours = sorted(contours, key = cv2.contourArea, reverse = True)[:10]\nimage_with_largest_contours = cv2.drawContours(image.copy(), largest_contours, -1, (0,255,0), 3)\nplot_rgb(image_with_largest_contours)","6ee5fce4":"# approximate the contour by a more primitive polygon shape\ndef approximate_contour(contour):\n    peri = cv2.arcLength(contour, True)\n    return cv2.approxPolyDP(contour, 0.032 * peri, True)","a71430d3":"def get_receipt_contour(contours):    \n    # loop over the contours\n    for c in contours:\n        approx = approximate_contour(c)\n        # if our approximated contour has four points, we can assume it is receipt's rectangle\n        if len(approx) == 4:\n            return approx","b5b50769":"get_receipt_contour(largest_contours)","8920b260":"receipt_contour = get_receipt_contour(largest_contours)\nimage_with_receipt_contour = cv2.drawContours(image.copy(), [receipt_contour], -1, (0, 255, 0), 2)\nplot_rgb(image_with_receipt_contour)","a3fe34b9":"def contour_to_rect(contour):\n    pts = contour.reshape(4, 2)\n    rect = np.zeros((4, 2), dtype = \"float32\")\n    # top-left point has the smallest sum\n    # bottom-right has the largest sum\n    s = pts.sum(axis = 1)\n    rect[0] = pts[np.argmin(s)]\n    rect[2] = pts[np.argmax(s)]\n    # compute the difference between the points:\n    # the top-right will have the minumum difference \n    # the bottom-left will have the maximum difference\n    diff = np.diff(pts, axis = 1)\n    rect[1] = pts[np.argmin(diff)]\n    rect[3] = pts[np.argmax(diff)]\n    return rect \/ resize_ratio","cbf3002c":"def wrap_perspective(img, rect):\n    # unpack rectangle points: top left, top right, bottom right, bottom left\n    (tl, tr, br, bl) = rect\n    # compute the width of the new image\n    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n    # compute the height of the new image\n    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n    # take the maximum of the width and height values to reach\n    # our final dimensions\n    maxWidth = max(int(widthA), int(widthB))\n    maxHeight = max(int(heightA), int(heightB))\n    # destination points which will be used to map the screen to a \"scanned\" view\n    dst = np.array([\n        [0, 0],\n        [maxWidth - 1, 0],\n        [maxWidth - 1, maxHeight - 1],\n        [0, maxHeight - 1]], dtype = \"float32\")\n    # calculate the perspective transform matrix\n    M = cv2.getPerspectiveTransform(rect, dst)\n    # warp the perspective to grab the screen\n    return cv2.warpPerspective(img, M, (maxWidth, maxHeight))","42ab72b6":"scanned = wrap_perspective(original.copy(), contour_to_rect(receipt_contour))\nplt.figure(figsize=(16,10))\nplt.imshow(scanned)","e2d2d9a8":"def bw_scanner(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    T = threshold_local(gray, 21, offset = 5, method = \"gaussian\")\n    return (gray > T).astype(\"uint8\") * 255","88c1bcef":"result = bw_scanner(scanned)\nplot_gray(result)","43da34ce":"output = Image.fromarray(result)\noutput.save('result.png')","cbf432f8":"Great! We are done with locating a receipt!","5262f7ba":"Kaggle provides this notebook with OpenCV 4.4.0, so we are using the most recent implementation of `findContours`","ee1a8f3c":"# About me\n\nThis notebook is published under the **Data Science DJ** initiative with the goal of giving you distilled pieces of valuable information, short and concise, easy to comprehend. \n\nI spend a few hours every day to write a single post about a single concept. You can find them by:\n\n* [Joining my Telegram channel](https:\/\/t.me\/datasciencedj)\n* [Following my LinkedIn tag](https:\/\/www.linkedin.com\/feed\/hashtag\/?keywords=datasciencedj)\n\nIf this work gives you joy, or maybe even inspiration, please consider contributing to my [Patreon account](https:\/\/www.patreon.com\/datasciencedj).\nThank you!\n\n","4dff891a":"Now we can make use of helper methods defined to get a perspective version of the receipt:","ed64e736":"Following helper methods are inspired by [Adrian Rosebrock blog](https:\/\/www.pyimagesearch.com\/). You can find more details in the resources section.","8db9851a":"# Step 2: Cropping and perspective restoration\n\nWe will make use of `cv2.warpPerspective` to restore perspective of the receipt. We have to do some preparations though:\n* convert contour into a rectangle-like coordinate array consisting of clockwise ordered points: top-left, top-right, bottom-right, bottom-left\n* use rectangle points to calculate destination points of the \"scanned\" view\n* feed destination points into `cv2.getPerspectiveTransform` to calculate transformation matrix\n* and finally use `cv2.warpPerspective` to restore the perspective!","85c9b539":"Now the final part - obtain black and white scanner effect with the color transformation:","35a66abc":"# Resources\n1. [How to Build a Kick-Ass Mobile Document Scanner in Just 5 Minutes](https:\/\/www.pyimagesearch.com\/2014\/09\/01\/build-kick-ass-mobile-document-scanner-just-5-minutes\/) by Adrian Rosebrock\n2. [Building a Pokedex in Python: OpenCV and Perspective Warping](https:\/\/www.pyimagesearch.com\/2014\/05\/05\/building-pokedex-python-opencv-perspective-warping-step-5-6\/) by Adrian Rosebrock","842db219":"# Step 1: Receipt Contour Detection\nIn order to find receipt contour, standart edge detection preprocessing is applied:\n* Convert image to grayscale\n* Aplly Gaussian filter 5x5 to get rid of noise\n* Run Canny edge detector","3fd1c3ef":"Receipt images used in this notebook come from a tiny [personal receipt dataset](https:\/\/www.kaggle.com\/dmitryyemelyanov\/personal-receipt-collection). Let's check out one of them:","73a982ee":"To find the contour of receipt we will make use of two simple heuristics: \n* receipt is the largest contour whithin image\n* receipt is expected to be of a rectangular shape \n\nWe will start with the first heuristic by getting TOP largest contours.","6e21efef":"Edged image is a suitable input for the contour detection, which is kindly provided by OpenCV:\n> Please be careful with older versions of OpenCV, as findContours works differently for versions < 3.0","8c6c74b1":"> It is also important to get down to just four contour points, as we will need them for perspective restoration","94b09d18":"We will use `approxPolyDP` for approximating more primitive contour shape consisting of as few points as possible. It takes perimeter as one of the arguments, so we have to calculate it with `arcLength`. Let's define a helper method that does the approximation: ","b0d3ae42":"# Receipt OCR notebook series: Problem definition\n\n> Given a arbitrary photo containing a receipt, extract grand total\n\n![](https:\/\/storage.googleapis.com\/www.forwardit.lv\/kaggle\/receipt_home_kaggle.png)\n\nWe will break down this problem into smaller tasks:\n\n1. **Get a scanned version of receipt by restoring perspective**\n2. Apply OCR to find all texts within image\n3. Find grand total as the largest number among recognized texts\n\n> One should remember that some tasks could be solved with traditional computer vision algorithms\n\nThis work aims to address a common pitfall among machine learning practitioners: trying to solve simple problems with the complex tools. ","a098fd2e":"Let's define some utility methods:","236146e4":"# About this notebook\n\nThis is a **part one notebook** in the *Receipt OCR with OpenCV* series and will cover the first step of the process: getting a scanned version of the receipt. In order to complete this task we will:\n* Locate receipt contour on the photo\n* Crop image to the receipt contour\n* Apply perspective restoration\n\nLet's get started!","47b9ccf5":"We are done with the first part of the *Receipt OCR with OpenCV* series! \n\nLet's recap:\n* At first, we have applied OpenCV preprocessing to get rid of noise and detect contours\n* Next, we used heuristics and contour approximation methods to find contour of the receipt\n* Finally, we used perspective transformation to obtain top-down view of the receipt\n\nThe transformed image is ready for Optical Character Recognition (OCR) which is covered in the [next notebook of the series](https:\/\/www.kaggle.com\/dmitryyemelyanov\/receipt-ocr-part-2-text-recognition-by-tesseract).","160ec5ed":"This allows us to find a rectangle by looking whether the number of approximated contour points is 4:"}}