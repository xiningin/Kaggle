{"cell_type":{"97f02a6d":"code","09d27be9":"code","9cc0fcdc":"code","4e473bbc":"code","f820c342":"code","2cd95c7c":"code","0e50c907":"code","2a52b6d3":"code","ffe39542":"code","ce87bd73":"code","5f0a137f":"code","b63f9a78":"code","7fb53088":"code","cfb8425a":"code","0e67ed3d":"code","59b761be":"code","0dac5623":"code","b3c84dca":"code","a280b4cd":"code","013cf332":"code","31575373":"code","cb43d13a":"code","1e12ce03":"code","63b9cc59":"code","41d0c718":"code","51718f31":"code","f2dc2ecd":"code","0fb25f7c":"code","b7f4d6ed":"code","41e55a1d":"code","24a1e5fe":"code","e0efdab8":"code","0bad929f":"code","48e0cbaf":"code","798d806a":"code","bc8c460d":"code","59beeaec":"code","0563b7ec":"code","9dbb737f":"code","a48be2bd":"code","80e49d2e":"code","6bc39cee":"code","77283096":"code","7bb0406f":"code","871d870c":"code","afaa4a42":"code","05eba2d8":"code","a878d774":"code","6e861568":"code","833b417e":"code","818a96cc":"code","37357936":"code","fa1c9f15":"code","52561642":"code","657b24d2":"code","f5c97dcb":"code","f28662ad":"code","4023607a":"code","fc9b1288":"code","54cc76e6":"code","c6fac7bc":"code","5818e607":"code","124501ea":"code","56a30007":"code","ecfe3efb":"code","58ce5ba4":"code","09c058cc":"code","1698286e":"code","cc2dfd52":"markdown","a1053c25":"markdown","af0e579f":"markdown","630dc079":"markdown","eca07528":"markdown","6521c3a8":"markdown","e50fa51a":"markdown","a93eb6c4":"markdown","3c65d2c8":"markdown","930ae966":"markdown","8eee3cfd":"markdown","8731883e":"markdown","50401a70":"markdown","a010aad6":"markdown","0fe9f3c5":"markdown","be58c82e":"markdown","763ffbc4":"markdown","c603fd8d":"markdown","2d5ee78b":"markdown","47abbf6b":"markdown","9e459c0a":"markdown","19e4a49e":"markdown","c69e7436":"markdown","4df7770d":"markdown","794bb66b":"markdown","1b523a32":"markdown","2c044ecb":"markdown","90a200b8":"markdown","b395ac91":"markdown","1502dae0":"markdown","73bf2a33":"markdown","d0ca9378":"markdown","a9ac212f":"markdown","7b83dbe4":"markdown","3155fe8b":"markdown","e06172f7":"markdown","f46a2ae3":"markdown","aa2a2322":"markdown","da430704":"markdown","cb856620":"markdown","1251fe52":"markdown","a3fde609":"markdown","f4e8bab6":"markdown","e101c567":"markdown","9d9ea89e":"markdown","8c2b3604":"markdown","cf8e6269":"markdown","7e8f1c12":"markdown","ba68dfad":"markdown","78c8d472":"markdown","293e01b1":"markdown","7196a371":"markdown","79b3f163":"markdown","c0be0ada":"markdown","b1ebd973":"markdown","e38ee9dd":"markdown","5e76bfd4":"markdown","30e0ea3a":"markdown","eb256603":"markdown","55438bfa":"markdown","c94933cb":"markdown","d8f04c4a":"markdown","fb17a5c6":"markdown","86296656":"markdown","7586f7ea":"markdown","9760a128":"markdown","5616b7f9":"markdown","33a9fce6":"markdown","7003cc20":"markdown","7e6a375f":"markdown","9bc9a668":"markdown","0f934196":"markdown","72c8aa63":"markdown","5d258692":"markdown","a89addf2":"markdown"},"source":{"97f02a6d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","09d27be9":"%matplotlib inline    \n# To make data visualisations display in Jupyter Notebooks \n\nimport numpy as np    # linear algebra \nimport pandas as pd    # Data processing, Input & Output load    \nimport matplotlib.pyplot as plt    # Visualization & plotting\nimport datetime\n\nimport xgboost as xgb\nfrom sklearn.svm import SVC    # supervised learning methods used for classification, regression \nfrom sklearn.ensemble import GradientBoostingClassifier    # GBM algorithm\nfrom sklearn.ensemble import RandomForestClassifier    # Random Forest Algorithm\nfrom sklearn.linear_model import LogisticRegression    # Logistic Regression Algorithm\n\nfrom xgboost.sklearn import XGBClassifier    # Extreme Gradient Boosting\nfrom xgboost import plot_importance    # Plotting Important Variables\n\nimport joblib  #Joblib is a set of tools to provide lightweight pipelining in Python (Avoid computing twice the same thing)\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n                                    # GridSearchCV - Implements a \u201cfit\u201d and a \u201cscore\u201d method\n                                    # train_test_split - Split arrays or matrices into random train and test subsets\n                                    # cross_val_score - Evaluate a score by cross-validation     \n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import f1_score, precision_score, accuracy_score, roc_auc_score, recall_score, roc_curve\nfrom sklearn.metrics import make_scorer, confusion_matrix, classification_report   # Differnt metrics to evaluate the model\nimport pandas_profiling as pp    # simple and fast exploratory data analysis of a Pandas Dataframe\n\nimport warnings    # To avoid warning messages in the code run\nwarnings.filterwarnings('ignore')","9cc0fcdc":"def plot_roc_auc_curve(y_train_actual, train_pred_prob, y_test_actual, test_pred_prob, *args):\n    '''\n    Generate train and test roc curve\n    '''\n      \n    AUC_Train = roc_auc_score(y_train_actual, train_pred_prob)\n    AUC_Test = roc_auc_score(y_test_actual, test_pred_prob)\n    \n    if len(args) == 0:\n        print(\"Train AUC = \", AUC_Train)\n        print(\"Test AUC = \", AUC_Test)\n        fpr_train, tpr_train, thresholds = roc_curve(y_train_actual, train_pred_prob)\n        fpr_test, tpr_test, thresholds = roc_curve(y_test_actual, test_pred_prob)\n        roc_plot(fpr_train, tpr_train, fpr_test, tpr_test)\n        \n    else:\n        AUC_Valid = roc_auc_score(args[0], args[1])\n        print(\"Train AUC = \", AUC_Train)\n        print(\"Test AUC = \", AUC_Test)\n        print(\"Validation AUC = \", AUC_Valid)\n        fpr_train, tpr_train, thresholds = roc_curve(y_train_actual, train_pred_prob)\n        fpr_test, tpr_test, thresholds = roc_curve(y_test_actual, test_pred_prob)\n        fpr_val, tpr_val, thresholds = roc_curve(args[0], args[1])\n        roc_plot(fpr_train, tpr_train, fpr_test, tpr_test, fpr_val, tpr_val)        ","4e473bbc":"def roc_plot(fpr_train, tpr_train, fpr_test, tpr_test, *args):\n    '''\n    Generate roc plot\n    '''\n    \n    fig = plt.plot(fpr_train, tpr_train, label = 'Train')\n    fig = plt.plot(fpr_test, tpr_test, label = 'Test')\n    \n    if len(args) == 0:\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.0])\n        plt.title(\"ROC curve using \")\n        plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n        plt.ylabel(\"True Positive Rate (Sensitivity)\")\n        plt.legend(loc = 'lower right')\n        plt.grid(True)\n        plt.show()\n    \n    else:\n        fig = plt.plot(args[0], args[1], label = 'Validation')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.0])\n        plt.title(\"ROC curve using \")\n        plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n        plt.ylabel(\"True Positive Rate (Sensitivity)\")\n        plt.legend(loc = 'lower right')\n        plt.grid(True)\n        plt.show()","f820c342":"data = pd.read_csv('\/kaggle\/input\/travel-insurance-prediction-data\/TravelInsurancePrediction.csv')\n\n# Copying the original data into a new python variable object data_new\ndata_new = data.copy()\n\nprint(\"Data Shape - \", data_new.shape)\n\ndata_new.head()","2cd95c7c":"data_new.describe()","0e50c907":"data_new.describe(include = np.object)","2a52b6d3":"data_new.info()","ffe39542":"pp.ProfileReport(data_new)","ce87bd73":"Target = 'TravelInsurance'\npd.crosstab(data_new[Target], columns = 'Normalized', normalize = True)","5f0a137f":"data_new.isnull().sum()","b63f9a78":"print(\"Unique values Employment Type count: \", data_new['Employment Type'].nunique())\nprint(\"Employment Type values: \", data_new['Employment Type'].unique())\npd.value_counts(data_new['Employment Type'])","7fb53088":"print(\"Unique values GraduateOrNot count: \", data_new['GraduateOrNot'].nunique())\nprint(\"GraduateOrNot values: \", data_new['GraduateOrNot'].unique())\npd.value_counts(data_new['GraduateOrNot'])","cfb8425a":"print(\"Unique values FamilyMembers count: \", data_new['FamilyMembers'].nunique())\nprint(\"FamilyMembers values: \", data_new['FamilyMembers'].unique())\npd.value_counts(data_new['FamilyMembers'])","0e67ed3d":"print(\"Unique values ChronicDiseases count: \", data_new['ChronicDiseases'].nunique())\nprint(\"ChronicDiseases values: \", data_new['ChronicDiseases'].unique())\npd.value_counts(data_new['ChronicDiseases'])","59b761be":"print(\"Unique values FrequentFlyer count: \", data_new['FrequentFlyer'].nunique())\nprint(\"FrequentFlyer values: \", data_new['FrequentFlyer'].unique())\npd.value_counts(data_new['FrequentFlyer'])","0dac5623":"print(\"Unique values EverTravelledAbroad count: \", data_new['EverTravelledAbroad'].nunique())\nprint(\"EverTravelledAbroad values: \", data_new['EverTravelledAbroad'].unique())\npd.value_counts(data_new['EverTravelledAbroad'])","b3c84dca":"print(\"Unique values TravelInsurance count: \", data_new['TravelInsurance'].nunique())\nprint(\"TravelInsurance values: \", data_new['TravelInsurance'].unique())\npd.value_counts(data_new['TravelInsurance'])","a280b4cd":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['Employment Type']), \n        labels = ['Private Sector\/Self Employed', 'Government Sector'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Employment Types', fontsize = 18, fontweight = 'bold')\nplt.show()","013cf332":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['GraduateOrNot']), \n        labels = ['Yes', 'No'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Graduates & Non-Graduates', fontsize = 18, fontweight = 'bold')\nplt.show()","31575373":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['FamilyMembers']), \n        labels = [4, 5, 3, 6, 7, 2, 8, 9],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Family Members Count', fontsize = 18, fontweight = 'bold')\nplt.show()","cb43d13a":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['ChronicDiseases']), \n        labels = [0, 1],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of People With Or Without Chronic Disease', fontsize = 18, fontweight = 'bold')\nplt.show()","1e12ce03":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['FrequentFlyer']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Frequent & Non-Frequent Flyers', fontsize = 18, fontweight = 'bold')\nplt.show()","63b9cc59":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['EverTravelledAbroad']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Abroad & Non-Abroad Flyers', fontsize = 18, fontweight = 'bold')\nplt.show()","41d0c718":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['TravelInsurance']), \n        labels = [0, 1],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of People With Or Without TravelInsurance', fontsize = 18, fontweight = 'bold')\nplt.show()","51718f31":"num_cols = data_new.select_dtypes(include = [np.number]).columns.tolist()\nobj_cols = data_new.select_dtypes(exclude = [np.number]).columns.tolist()","f2dc2ecd":"num_cols = data_new.drop(['Unnamed: 0', 'TravelInsurance'], axis = 1).select_dtypes(include = [np.number]).columns.tolist()","0fb25f7c":"print('Numeric Columns \\n', num_cols)\nprint('Non-Numeric Columns \\n', obj_cols)","b7f4d6ed":"num_cols_viz = ['Age', 'AnnualIncome']\n\nfig, axes = plt.subplots(1, 1, sharex = False, sharey = False, figsize = (15, 15))\ndata_new.loc[:, [Target]+num_cols_viz].boxplot(by = Target, ax = axes, return_type = 'axes');","41e55a1d":"obj_cols_viz = obj_cols + ['FamilyMembers', 'ChronicDiseases']\nfig, axes = plt.subplots(len(obj_cols_viz), sharex = False, sharey = False, figsize = (15, 50))\n\nfor i in range(0, len(obj_cols_viz)):\n    pd.crosstab(data_new[obj_cols_viz[i]], data_new[Target]).plot(kind = 'bar', stacked = True, grid = False, ax = axes[i])","24a1e5fe":"data_new = data_new.drop(\"Unnamed: 0\", axis = 1)\ndata_new.head()","e0efdab8":"encoding_list = ['Employment Type', 'GraduateOrNot', 'FrequentFlyer', 'EverTravelledAbroad']\n\nlabel_encoding_list = []\none_hot_encoding_list = []\n\nfor i in range (0, len(encoding_list)):\n    if(len(data_new[f'{encoding_list[i]}'].unique()) == 2):\n        label_encoding_list.append(encoding_list[i])\n    else:\n        one_hot_encoding_list.append(encoding_list[i])\n        \n    print(f'Unique Values for {encoding_list[i]}', data_new[f'{encoding_list[i]}'].unique())","0bad929f":"# Numerical columns data\ndata_new_num = data_new[num_cols + ['TravelInsurance']]\n\n# Categorical columns data\ndata_new_cat = data_new[obj_cols]\n\n# Creating dummies\ndata_new_cat_dummies = pd.get_dummies(data_new_cat)\nprint(data_new_cat_dummies.shape)\ndata_new_cat_dummies.head()","48e0cbaf":"data_new_final = pd.concat([data_new_num, data_new_cat_dummies], axis = 1)\nprint(data_new_final.shape)\ndata_new_final.head()","798d806a":"data_new_final.isnull().sum(axis = 0)","bc8c460d":"X = data_new_final.drop(['TravelInsurance'], axis = 1)\ny = data_new_final['TravelInsurance']","59beeaec":"X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.3, random_state = 100) \n\nprint('Train Shape: ', X_train.shape)\nprint('Test Shape: ', X_test.shape)","0563b7ec":"model_parameters = {'n_estimators': [10, 50, 100, 200, 500, 750, 1000], 'max_depth': [3, 5, 10],\n                    'min_samples_leaf': [np.random.randint(1,10)], 'max_features': [None, 'sqrt', 'log2']}","9dbb737f":"model = GradientBoostingClassifier(random_state = 10)\ngscv_GBM = GridSearchCV(estimator = model, \n                        param_grid = model_parameters, \n                        cv = 5, \n                        verbose = 1, \n                        n_jobs = -1,\n                        scoring = 'roc_auc')\n\ngscv_GBM.fit(X_train, y_train)","a48be2bd":"print('The best parameters are -', gscv_GBM.best_params_)","80e49d2e":"final_mod_GBM = GradientBoostingClassifier(**gscv_GBM.best_params_)\nfinal_mod_GBM.fit(X_train, y_train)","6bc39cee":"train_pred = final_mod_GBM.predict(X_train)\ntest_pred = final_mod_GBM.predict(X_test)","77283096":"print('Classification report for train data is : \\n',\n      classification_report(y_train, train_pred))\nprint('Classification report for test data is : \\n',\n      classification_report(y_test, test_pred))","7bb0406f":"final_mod_GBM.variables = X_train.columns","871d870c":"joblib.dump(final_mod_GBM, 'best_model_GBM.joblib')","afaa4a42":"plt.subplots(figsize = (10, 5))\ntrain_prob = final_mod_GBM.predict_proba(X_train)[:, 1]\ntest_prob = final_mod_GBM.predict_proba(X_test)[:, 1]\n\nplot_roc_auc_curve(y_train, train_prob, y_test, test_prob)","05eba2d8":"y_pred = final_mod_GBM.predict(X_test)\npredictions = [round(value) for value in y_pred]","a878d774":"accuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","6e861568":"log_reg = LogisticRegression(solver = 'liblinear')\nlog_reg.fit(X_train, y_train)","833b417e":"train_pred = log_reg.predict(X_train)\ntest_pred = log_reg.predict(X_test)","818a96cc":"print('Classification report for train data is : \\n',\n      classification_report(y_train, train_pred))\nprint('Classification report for test data is : \\n',\n      classification_report(y_test, test_pred))","37357936":"log_reg.variables = X_train.columns","fa1c9f15":"joblib.dump(log_reg, 'best_model_log_reg.joblib')","52561642":"plt.subplots(figsize = (10, 5))\ntrain_prob = log_reg.predict_proba(X_train)[:, 1]\ntest_prob = log_reg.predict_proba(X_test)[:, 1]\n\nplot_roc_auc_curve(y_train, train_prob, y_test, test_prob)","657b24d2":"y_pred = log_reg.predict(X_test)\npredictions = [round(value) for value in y_pred]","f5c97dcb":"accuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","f28662ad":"model_parameters = {'n_estimators': [10, 50, 100, 200, 500, 750, 1000], 'max_depth': [3, 5, 10],\n                    'min_samples_leaf': [np.random.randint(1,10)], 'max_features': [None, 'sqrt', 'log2']}","4023607a":"model = RandomForestClassifier(random_state = 10)\ngscv_randfor = GridSearchCV(estimator = model, \n                        param_grid = model_parameters, \n                        cv = 5, \n                        verbose = 1, \n                        n_jobs = -1,\n                        scoring = 'roc_auc')\n\ngscv_randfor.fit(X_train, y_train)","fc9b1288":"print('The best parameters are -', gscv_randfor.best_params_)","54cc76e6":"final_mod_randfor = GradientBoostingClassifier(**gscv_randfor.best_params_)\nfinal_mod_randfor.fit(X_train, y_train)","c6fac7bc":"train_pred = final_mod_randfor.predict(X_train)\ntest_pred = final_mod_randfor.predict(X_test)","5818e607":"print('Classification report for train data is : \\n',\n      classification_report(y_train, train_pred))\nprint('Classification report for test data is : \\n',\n      classification_report(y_test, test_pred))","124501ea":"final_mod_randfor.variables = X_train.columns","56a30007":"joblib.dump(final_mod_randfor, 'best_model_randfor.joblib')","ecfe3efb":"plt.subplots(figsize = (10, 5))\ntrain_prob = log_reg.predict_proba(X_train)[:, 1]\ntest_prob = log_reg.predict_proba(X_test)[:, 1]\n\nplot_roc_auc_curve(y_train, train_prob, y_test, test_prob)","58ce5ba4":"y_pred = log_reg.predict(X_test)\npredictions = [round(value) for value in y_pred]","09c058cc":"accuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","1698286e":"print('The best model is Gradient Boosting model')","cc2dfd52":"### Following are the insights gathered from the stacked bar charts\n\n* <b>Private Sector\/Self Employed persons have higher chances to opt for a Travel Insurance as compared to Government Sector employees<\/b>.\n* <b>Graduate persons have higher chances to opt for a Travel Insurance<\/b>.\n* <b>Frequent Flyers have higher chances to opt for a Travel Insurance<\/b>.\n* <b>Persons travelling abroad have higher chances to opt for a Travel Insurance<\/b>.\n* <b>So, overall if a person is a Private Sector employee or is Self Employed and is a Graduate and is a Frequent Flyer and has travelled abroad and has higher income has higher chances to opt for a Travel Insurance<\/b>.","a1053c25":"### e) Displaying model prediction and classification report","af0e579f":"* Let's drop the columns which we won't be using.","630dc079":"### g) Saving the best model","eca07528":"### d) ChronicDiseases","6521c3a8":"* Let's check if there are any null variables in the <b>data_new<\/b> dataset.","e50fa51a":"* Let's first plot the boxplot of each numerical variable w.r.t our target variable.","a93eb6c4":"## 7. Feature Engineering","3c65d2c8":"### c) Saving the variables used in the model","930ae966":"### c) Displaying the best parameters","8eee3cfd":"## 8.3) Model 3 - Random Forest Classifier","8731883e":"## 5. Data Profiling Report","50401a70":"### i) Making predictions for test data","a010aad6":"## 7.2) Creating Model Dataset","0fe9f3c5":"* As variable <b>Unnamed: 0<\/b> has no correlation with any other variables, we can drop this variable.","be58c82e":"## 9) Displaying Best Model","763ffbc4":"### Following are the insights gathered from the data_new dataframe\n\n1. <b>71.31%<\/b> people are either <b>Private Sector Employees<\/b> or are <b>Self Employed<\/b>.\n2. <b>28.69%<\/b> people are <b>Government Sector Employees<\/b>.\n3. <b>85.15%<\/b> people are <b>Graduates<\/b>.\n4. <b>14.85%<\/b> people are <b>Non-Graduates<\/b>.\n5. <b>25.42%<\/b> people have <b>4 Family Members<\/b> in their house including them.\n6. <b>2.77%<\/b> people have <b>9 Family Members<\/b> in their house including them.\n5. <b>21%<\/b> people are <b>Frequent Flyers<\/b>.\n6. <b>79%<\/b> people are <b>Non-Frequent Flyers<\/b>.\n7. <b>72.22%<\/b> people don't suffer from any <b>Chronic Disease<\/b>.\n8. <b>27.78%<\/b> people suffer from some <b>Chronic Disease<\/b>.\n9. <b>19.12%<\/b> people are <b>Abroad Travellers<\/b>.\n10. <b>80.88%<\/b> people are <b>Non-Abroad Travellers<\/b>.\n11. <b>64.27%<\/b> people have <b>No Travel Insurance<\/b>.\n12. Only <b>35.73%<\/b> people have <b>Travel Insurance<\/b>.","c603fd8d":"### b) Using GridSearch Cross Validation to find out the best parameters","2d5ee78b":"### d) Refitting the model with best parameters","47abbf6b":"### b) Displaying model prediction and classification report","9e459c0a":"### e) FrequentFlyer","19e4a49e":"### g) Evaluating prediction accuracy for test data","c69e7436":"## 3. Importing Dataset","4df7770d":"### e) Displaying model prediction and classification report","794bb66b":"### b) GraduateOrNot","1b523a32":"### j) Evaluating prediction accuracy for test data","2c044ecb":"## 4. Let's Understand Our Data","90a200b8":"### b) Using GridSearch Cross Validation to find out the best parameters","b395ac91":"## 8.2) Model 2 - Logistic Regression","1502dae0":"### Following are the insights gathered from the boxplots\n\n* <b>The \"AnnualIncome\" boxplot shows that greater the AnnualIncome, higher the chance of a person opting for a Travel Insurance<\/b>.","73bf2a33":"### b) Creating Dummy Variables","d0ca9378":"## 2. Analysis of each category of the numerical variables of num_cols dataframe w.r.t Target variable - TravelInsurance.","a9ac212f":"## 7.1) Dropping Least Important Variable","7b83dbe4":"### g) TravelInsurance","3155fe8b":"### a) Define model parameters to be tuned","e06172f7":"### d) Saving the best model","f46a2ae3":"* We have approximately <b>64%<\/b> of <b>0's<\/b> and <b>365%<\/b> of <b>1's<\/b> in our data.","aa2a2322":"## 6. EDA(Exploratory Data Analysis)","da430704":"### e) Model Evaluation","cb856620":"### c) FamilyMembers","1251fe52":"### c) Concatenating columns - numeric and dummies","a3fde609":"### d) Refitting the model with best parameters","f4e8bab6":"2. Now, let's get the summary for categorical data","e101c567":"### h) Model Evaluation","9d9ea89e":"## 1. Data Categorization","8c2b3604":"## 8) Applying Different Models On Train & Test Data","cf8e6269":"## 2. Defining Functions For Plotting ROC_AUC Curve & ROC_Plot","7e8f1c12":"### f) Making predictions for test data","ba68dfad":"### g) Saving the best model","78c8d472":"## a) Analysis of unique values & their counts for categorical variables of the data_new dataset.","293e01b1":"* The entire dataset contains <b>1987<\/b> rows and <b>10<\/b> columns.","7196a371":"### f) Saving the variables used in the model","79b3f163":"### b) Performing Train, Test & Split","c0be0ada":"### f) Saving the variables used in the model","b1ebd973":"### a) Applying logistic regression","e38ee9dd":"### a) Define model parameters to be tuned","5e76bfd4":"### f) EverTravelledAbroad","30e0ea3a":"### j) Evaluating prediction accuracy for test data","eb256603":"## b) Analysis of percentage unique values for categorical variables of the data_new dataset.","55438bfa":"### a) Separating the target variable - TravelInsurance from the data_new_final dataframe","c94933cb":"* We would categorize the existing variables of our existing dataframe into <b>numerical<\/b> and <b>categorical<\/b> variables.","d8f04c4a":"### i) Making predictions for test data","fb17a5c6":"### a) Employment Type","86296656":"### h) Model Evaluation","7586f7ea":"### c) Displaying the best parameters","9760a128":"### a) Finding unique values of each object variable of data_new dataframe","5616b7f9":"### d) Null value check in the final dataset before model run","33a9fce6":"## 8.1) Model 1 - GBM (Gradient Boosting)","7003cc20":"## 6.2) Bivariate Analysis","7e6a375f":"## 1. Importing Necessary Libraries","9bc9a668":"## 7.3) Splitting the newly created model data into train and test data","0f934196":"## 3. Analysis of each category of the categorical variables of obj_cols dataframe w.r.t Target variable - TravelInsurance.","72c8aa63":"* We shall first do the <b>Univariate Analysis<\/b> by analysing the data w.r.t our <b>Target Variable - TravelInsurance<\/b>.","5d258692":"1. First, let's get the summary of the numerical data","a89addf2":"## 6.1) Univariate Analysis"}}