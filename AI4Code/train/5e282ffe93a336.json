{"cell_type":{"2d8be460":"code","90eeea04":"code","01794c75":"code","51a3a80f":"code","33115d96":"code","f8f6dcf5":"code","6c13268a":"code","b008e57d":"code","f1eacba3":"code","8a995470":"code","c12176da":"code","fe037481":"code","c9399ce2":"code","bccf10f7":"code","c6b0212d":"code","abcf6779":"code","284fa604":"code","00d73d27":"code","40d6637c":"code","6146013b":"code","3593a696":"code","d459ac23":"code","bbc60c6d":"code","b7475482":"code","e9d971f5":"code","a0e6aadd":"code","541452ac":"code","1489dde7":"markdown","46270900":"markdown","30e06be3":"markdown","66f7a699":"markdown","1e3bc906":"markdown","e4a973cc":"markdown","2a71daa1":"markdown","f636f92d":"markdown","c177f973":"markdown","62825678":"markdown","d131cc26":"markdown","42da3e3a":"markdown","c5e44836":"markdown","9aa8669c":"markdown","b130d5ac":"markdown","bfde52e0":"markdown"},"source":{"2d8be460":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport math\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import make_scorer, accuracy_score","90eeea04":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","01794c75":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ngender_submission = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","51a3a80f":"train_data","33115d96":"train_data[['Last','First']] = train_data.Name.str.split(pat=',', expand=True)\ntrain_data[['Title','First']] = train_data.First.str.split(pat='.', n=1, expand=True)\ntrain_data[['Title']] = train_data.Title.str.replace(' ', '')\nprint(train_data.Title.unique())\ntrain_data = train_data.drop(['First', 'Last', 'Name'], axis=1)\n\ntest_data[['Last','First']] = test_data.Name.str.split(pat=',', expand=True)\ntest_data[['Title','First']] = test_data.First.str.split(pat='.', n=1, expand=True)\ntest_data[['Title']] = test_data.Title.str.replace(' ', '')\ntest_data = test_data.drop(['First', 'Last', 'Name'], axis=1)","f8f6dcf5":"first_c = train_data.loc[train_data['Pclass'] == 1]\nsecond_c = train_data.loc[train_data['Pclass'] == 2]\nthird_c = train_data.loc[train_data['Pclass'] == 3]\n\nfirst_c_dat = first_c.groupby('Title').PassengerId.nunique().to_frame('count').reset_index()\nsecond_c_dat = second_c.groupby('Title').PassengerId.nunique().to_frame('count').reset_index()\nthird_c_dat = third_c.groupby('Title').PassengerId.nunique().to_frame('count').reset_index()\nthird_c_dat","6c13268a":"fig, ax = plt.subplots(figsize=(15, 5), ncols=3)\n\nfirst_c_titles = first_c_dat[\"Title\"].tolist()\nfirst_c_count = first_c_dat[\"count\"].tolist()\nax[0].bar(first_c_titles, first_c_count, align='center', color=\"bisque\", edgecolor=\"black\")\n#ax[0].set(xticks=range(10), xlim=[-1, 10])\nax[0].set_title('Titles in first class')\nax[0].set_ylabel(\"count\")\nax[0].set_xlabel(\"Title\")\n\nsecond_c_titles = second_c_dat[\"Title\"].tolist()\nsecond_c_count = second_c_dat[\"count\"].tolist()\nax[1].bar(second_c_titles, second_c_count, align='center', color=\"burlywood\", edgecolor=\"black\")\n#ax[1].set(xticks=range(10), xlim=[-1, 10])\nax[1].set_title('Titles in second class')\nax[1].set_xlabel(\"Title\")\n\nthird_c_titles = third_c_dat[\"Title\"].tolist()\nthird_c_count = third_c_dat[\"count\"].tolist()\nax[2].bar(third_c_titles, third_c_count, width=0.8, align='center', color=\"darkgoldenrod\", edgecolor=\"black\")\n#ax[2].set(xticks=range(10), xlim=[-1, 10])\nax[2].set_title('Titles in third class')\nax[2].set_xlabel(\"Title\")\nplt.setp(ax[0].xaxis.get_majorticklabels(), rotation=-90 )\nplt.setp(ax[1].xaxis.get_majorticklabels(), rotation=-40 )\nplt.show()","b008e57d":"print(train_data.SibSp.unique())\nprint(train_data.Parch.unique())","f1eacba3":"sibsp_dat = train_data.groupby(['SibSp', 'Survived']).PassengerId.nunique().to_frame('count').reset_index()\nsibsp_surv = sibsp_dat.loc[sibsp_dat['Survived'] == 1]\nsibsp_dec = sibsp_dat.loc[sibsp_dat['Survived'] == 0]\n\nind = np.arange(9)\nplt.bar(sibsp_surv['SibSp'].tolist(), sibsp_surv['count'], width=0.5, label='Survived', color=\"palegreen\", edgecolor=\"black\")\nplt.bar([x + 0.5 for x in sibsp_dec['SibSp'].tolist()], sibsp_dec['count'], width=0.5, label='Deceased', color=\"lightcoral\", edgecolor=\"black\")\nplt.legend(loc='best')\nplt.xlabel(\"number of siblings and spouses on board\")\nplt.ylabel('count')\nplt.title('Number of siblings\/spouses on board vs survival')\nplt.xticks(ind + 0.5 \/ 2, ('0', '1', '2', '3', '4', '5', '6', '7', '8'))\nplt.show()","8a995470":"parch_dat = train_data.groupby(['Parch', 'Survived']).PassengerId.nunique().to_frame('count').reset_index()\nparch_surv = parch_dat.loc[parch_dat['Survived'] == 1]\nparch_dec = parch_dat.loc[parch_dat['Survived'] == 0]\n\nind = np.arange(7)\nplt.bar(parch_surv['Parch'].tolist(), parch_surv['count'], width=0.5, label='Survived', color=\"palegreen\", edgecolor=\"black\")\nplt.bar([x + 0.5 for x in parch_dec['Parch'].tolist()], parch_dec['count'], width=0.5, label='Deceased', color=\"lightcoral\", edgecolor=\"black\")\nplt.legend(loc='best')\nplt.xlabel(\"number of parents and children on board\")\nplt.ylabel('count')\nplt.title('Number of parents\/children on board vs survival')\nplt.xticks(ind + 0.5 \/ 2, ('0', '1', '2', '3', '4', '5', '6'))\nplt.semilogy()\nplt.show()","c12176da":"# print(train_data.Ticket.unique())\n# print(train_data.Fare.unique())\n# print(train_data.Cabin.unique())","fe037481":"train_data['Floor'] = train_data['Cabin'].astype(str).str[0]\ntrain_data = train_data.drop(['Cabin'], axis=1)\n\ntest_data['Floor'] = test_data['Cabin'].astype(str).str[0]\ntest_data = test_data.drop(['Cabin'], axis=1)","c9399ce2":"def f(x):\n    if x['Pclass'] == 1 and x['Floor'] == 'n': return 'C'\n    elif x['Pclass'] == 2 and x['Floor'] == 'n': return 'E'\n    elif x['Pclass'] == 3 and x['Floor'] == 'n': return 'F'\n    else: return x['Floor']\n\ncabin_dat = train_data.groupby(['Pclass', 'Floor']).PassengerId.count().to_frame('Count').reset_index()\nprint(cabin_dat)\n# 1: C\n# 2: E\n# 2: F\ntrain_data['Floor'] = train_data.apply(f, axis=1)\ntest_data['Floor'] = test_data.apply(f, axis=1)\n\ncabin_dat = train_data.groupby(['Pclass', 'Floor']).PassengerId.count().to_frame('Count').reset_index()\nprint(cabin_dat)","bccf10f7":"fare_dat = train_data.groupby(by=['Pclass', pd.cut(train_data['Fare'], bins=np.linspace(-10, 540, 54))]).PassengerId.count().to_frame('count').reset_index()\nfir_fare_dat = fare_dat.loc[fare_dat['Pclass'] == 1]\nsec_fare_dat = fare_dat.loc[fare_dat['Pclass'] == 2]\nthi_fare_dat = fare_dat.loc[fare_dat['Pclass'] == 3]\n# 1: 0-512.3292\n# 2: 10-73.50\n# 3: 0-69.55\n\nfig, ax = plt.subplots(figsize=(15, 5), ncols=3)\n\n# first_c_fare = [lambda x: x.left in fir_fare_dat[\"Fare\"]]\nfirst_c_fare = fir_fare_dat[\"Fare\"].tolist()\nfirst_c_fare = [x.right for x in first_c_fare] \nfirst_c_count = fir_fare_dat[\"count\"].tolist()\nax[0].bar(first_c_fare, first_c_count, width=10, align='edge', color=\"bisque\", edgecolor=\"black\")\nax[0].set(xticks=range(0, 540, 50), xlim=[0, 540])\nax[0].set_title('Fare in first class')\nax[0].set_ylabel(\"count\")\nax[0].set_xlabel(\"Fare\")\n\nsecond_c_fare = sec_fare_dat[\"Fare\"].tolist()\nsecond_c_fare = [x.right for x in second_c_fare] \nsecond_c_count = sec_fare_dat[\"count\"].tolist()\nax[1].bar(second_c_fare, second_c_count, width=10, align='edge', color=\"burlywood\", edgecolor=\"black\")\nax[1].set_title('Fare in second class')\nax[1].set_xlabel(\"Fare\")\n\nthird_c_fare = thi_fare_dat[\"Fare\"].tolist()\nthird_c_fare = [x.right for x in third_c_fare] \nthird_c_count = thi_fare_dat[\"count\"].tolist()\nax[2].bar(third_c_fare, third_c_count, width=10, align='edge', color=\"darkgoldenrod\", edgecolor=\"black\")\nax[2].set_title('Fare in third class')\nax[2].set_xlabel(\"Fare\")\nplt.show()","c6b0212d":"train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(\"S\")\ntest_data[\"Embarked\"] = test_data[\"Embarked\"].fillna(\"S\")\n\nemb_dat = train_data.groupby(['Embarked', 'Survived']).PassengerId.nunique().to_frame('count').reset_index()\nemb_surv = emb_dat.loc[emb_dat['Survived'] == 1]\nemb_dec = emb_dat.loc[emb_dat['Survived'] == 0]\n\nind = np.arange(3)\nplt.bar(ind, emb_surv['count'], width=0.5, label='Survived', color=\"palegreen\", edgecolor=\"black\")\nplt.bar(ind + 0.5, emb_dec['count'], width=0.5, label='Deceased', color=\"lightcoral\", edgecolor=\"black\")\nplt.legend(loc='best')\nplt.xlabel(\"Entry Port\")\nplt.ylabel('count')\nplt.title('Entry port and chance of survival')\nplt.xticks(ind + 0.5 \/ 2, ('Cherbourg', 'Queenstown', 'Southampton'))\nplt.show()","abcf6779":"# Filling in missing age data\ndef age(x, mu, sigma):\n    return np.random.randint(low=mu-sigma, high=mu+sigma)\n\ntrain_mean, train_std = train_data['Age'].std(), train_data['Age'].std()\ntrain_data['Age'] = train_data.apply(age, args=(train_mean, train_std), axis=1)\ntest_mean, test_std = test_data['Age'].std(), test_data['Age'].std()\ntest_data['Age'] = test_data.apply(age, args=(test_mean, test_std), axis=1)\n# convert from float to int\ntrain_data['Age'] = train_data['Age'].astype(int)\ntest_data['Age'] = test_data['Age'].astype(int)\n\n# Missing Fare data\n#13.91 was the average fare for the one passenger in the test df riding third class and embarked at Southhampton\ntest_data[\"Fare\"][np.isnan(test_data[\"Fare\"])] = 13.91\n\n# Drop extra columns\n# train_data = train_data.drop(['Ticket', 'PassengerId'], axis=1)\n# test_data = test_data.drop(['Ticket', 'PassengerId'], axis=1)\n\n# Floor has an order and may be changed to numerical values\ndef floor(x):\n    new_floors = {\"T\": 7, \"A\": 6, \"B\": 5, \"C\": 4, \"D\": 3, \"E\": 2, \"F\": 1, \"G\": 0}\n    return new_floors[x.Floor]\n\ntrain_data['Floor'] = train_data.apply(floor, axis=1)\ntest_data['Floor'] = test_data.apply(floor, axis=1)\n\n# One Hot Encoding for Sex, Embarked, and Title because there is no order to these categories.\nsex_dum_train = pd.get_dummies(train_data['Sex'])\nsex_dum_test = pd.get_dummies(test_data['Sex'])\ntrain_data = train_data.join(sex_dum_train)\ntest_data = test_data.join(sex_dum_test)\n\nembark_dum_train = pd.get_dummies(train_data['Embarked'])\nembark_dum_test = pd.get_dummies(test_data['Embarked'])\ntrain_data = train_data.join(embark_dum_train)\ntest_data = test_data.join(embark_dum_test)\n\ntitle_dum_train = pd.get_dummies(train_data['Title'])\ntitle_dum_test = pd.get_dummies(test_data['Title'])\ntrain_data = train_data.join(title_dum_train)\ntest_data = test_data.join(title_dum_test)\n\n# Drop extra columns\ntrain_data = train_data.drop(['Ticket', 'PassengerId', 'Sex', 'Embarked', 'Title'], axis=1)\ntest_data = test_data.drop(['Ticket', 'PassengerId', 'Sex', 'Embarked', 'Title'], axis=1)\n\n\n# columns in training data must match the columns in testing data\n# test needs a Capt, Don, Jonkheer, Lady, Major, Mlle, Mme, Sir, theCountess  column; train needs a Dona column\ntest_data['Capt'] = 0\ntest_data['Don'] = 0\ntest_data['Jonkheer'] = 0\ntest_data['Lady'] = 0\ntest_data['Major'] = 0\ntest_data['Mlle'] = 0\ntest_data['Mme'] = 0\ntest_data['Sir'] = 0\ntest_data['theCountess'] = 0\n\ntrain_data['Dona'] = 0","284fa604":"fold0, fold1 = np.array_split(train_data, 2) \nfold0_tar, fold1_tar = fold0['Survived'], fold1['Survived']\nfold0, fold1 = fold0.drop(['Survived'], axis=1), fold1.drop(['Survived'], axis=1)\nfold_list = [{\"data\": fold0, \"target\": fold0_tar}, {\"data\": fold1, \"target\": fold1_tar}] ","00d73d27":"def get_random_grid():\n    # 'n_estimators': 1600, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': None, 'bootstrap': True\n    \n    # Number of trees in random forest\n    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n    # Number of features to consider at every split\n    max_features = ['auto', 'sqrt']\n    # Maximum number of levels in tree\n    max_depth = [int(x) for x in np.linspace(18, 24, num = 7)]\n    max_depth.append(None)\n    # Minimum number of samples required to split a node\n    min_samples_split = [2, 5, 10]\n    # Minimum number of samples required at each leaf node\n    min_samples_leaf = [1, 2, 4]\n    # Method of selecting samples for training each tree\n    bootstrap = [True, False]\n\n    # Create the random grid\n    random_grid = {'n_estimators': n_estimators,\n                   'max_features': max_features,\n                   'max_depth': max_depth,\n                   'min_samples_split': min_samples_split,\n                   'min_samples_leaf': min_samples_leaf,\n                   'bootstrap': bootstrap}\n\n    print(random_grid)\n    return random_grid\n\ndef random_search(train_data, target_data):\n    weights_list = []\n    clf = RandomForestClassifier(bootstrap=True, n_estimators=200, max_depth=7, \n                                 random_state=0)\n    random_grid = get_random_grid()\n    clf_random = RandomizedSearchCV(estimator=clf, param_distributions=random_grid,\n                          n_iter = 200, #scoring='neg_mean_absolute_error', \n                          cv = 3, verbose=2, random_state=42, n_jobs=-1,\n                          return_train_score=True)\n\n    clf_random.fit(train_data, target_data)  \n    return clf_random.cv_results_\n#     predictions = clf_random.predict()\n#     accuracy = accuracy_score(target_data, predictions)\n#     return weights_list, accuracy\n#         # print(clf.predict([[0, 0, 0, 0]]))\n\ndef train(train_data, target_data, parameters):\n#     clf = RandomForestClassifier(bootstrap=True, max_depth=22, random_state=0, n_estimators=1200, \n#                                  min_samples_split=2, min_samples_leaf=2, max_features='auto')\n    clf = RandomForestClassifier(**parameters)\n    kf = KFold(n_splits=10)\n    outcomes = []\n    fold = 0\n    for train_index, test_index in kf.split(train_data):\n        fold += 1\n        X_train, X_test = train_data.values[train_index], train_data.values[test_index]\n        y_train, y_test = target_data.values[train_index], target_data.values[test_index]\n        clf.fit(X_train, y_train)\n        predictions = clf.predict(X_test)\n        accuracy = accuracy_score(y_test, predictions)\n        outcomes.append(accuracy)\n        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \n    mean_outcome = np.mean(outcomes)\n    print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n    return clf","40d6637c":"X = train_data.drop(['Survived'], axis=1)\ny = train_data['Survived']\nrandom_results = random_search(X, y)","6146013b":"def report(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        top_result = True\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")\n            if top_result:\n                best_params = results['params'][candidate]\n    return best_params\n\nbest_parameters = report(random_results)","3593a696":"results = train(X, y, best_parameters)","d459ac23":"weights_list = results.feature_importances_","bbc60c6d":"train_data.columns.shape[0]\nweights_list.shape","b7475482":"fig, ax = plt.subplots(figsize=(15, 5), ncols=1)\n\ncolumns = np.arange(weights_list.shape[0])\nax.bar(columns, weights_list, align='center', color=\"lightcyan\", edgecolor=\"black\")\nax.set(xticks=range(29))\nax.set_title('Weights for first fold')\nax.set_ylabel(\"count\")\nax.set_xlabel(\"Title\")\nax.set_xticklabels(train_data.columns.tolist())\n\n# columns = np.arange(weights_list[1].shape[0])\n# ax[1].bar(columns, weights_list[1], align='center', color=\"lightcyan\", edgecolor=\"black\")\n# #ax[1].set(xticks=range(10), xlim=[-1, 10])\n# ax[1].set_title('Weights for second fold')\n# ax[1].set_xlabel(\"Title\")\n# ax[1].set(xticks=range(29))\n# ax[1].set_xticklabels(train_data.columns.tolist())\n\n# for plot in ax:\n#     plt.sca(plot)\nplt.xticks(rotation=90)\nplt.show()","e9d971f5":"test_predictions = results.predict(test_data)  ","a0e6aadd":"test_predictions\noutput = gender_submission.assign(Survived=test_predictions)\noutput","541452ac":"output.to_csv('submission.csv', index=False)","1489dde7":"# Does the number of family on board make a difference in survival?\nChecking for a correlation to see if this is dependent variable. If there is no correlation then the model may try to learn incorrect weights.","46270900":"# Extracting a person's title from their name as a new feature.","30e06be3":"It appears that these features do make a difference. Larger families had a less chance of survival. Or perhaps this is a case of one or two large families that did not survive. \n\nThese features could also be modified to a binary feature to see if accuracy is improved. SibSp=0 if <5, and SibSp=1 if >5.\n\nThe features will be kept the same for now, but may be modified or dropped in the future.","66f7a699":"Most of the passengers boarded from Southampton, but only about 35% of those passengers survived. Meanwhile more passengers survived than not when they boarded at Cherbourg.","1e3bc906":"# Last few adjustments to the data","e4a973cc":"# Embarked and survival rates","2a71daa1":"It is interesting that fare does not correlate with class at all.","f636f92d":"# Ticket, fare, and Cabin number.\nThese features may be helpful or they may be redundant. ","c177f973":"Some of these titles are for upper class or royalty so that might helpful and will be kept as a categorical variable. \n\nThe first and last names of the passengers will be dropped. It may be interesting to categorize names into different ethnicities or homelands and see if the origin of the name makes a difference on survival, but that will be left as an excersice for the reader. :p","62825678":"# Preparing the data","d131cc26":"# Random Forest","42da3e3a":"There are a lot of features here, and they may not all be helpful to train on. \n\n**PassengerID:** random assigned ID for each passenger. (Not helpful)\n\n**Survived:** 0=No, 1=Yes (helpful, binary)\n\n**Pclass:** 1st, 2nd, or 3rd class (helpful, ordinal)\n\n**Name:** name of passenger (maybe helpful, categorical)\n\n**Sex:** sex of passenger (helpful, binary)\n\n**Age:** age of passenger (helpful, continuous)\n\n**SibSp:** # of siblings and\/or spouses also on the Titanic (maybe helpful, continuous)\n\n**Parch:** # of parents and\/or children also on the Titanic (maybe helpful, continuous)\n\n**Ticket:** ticket number (maybe helpful)\n\n**Fare:** passenger fare (helpful, continuous)\n\n**Cabin:** cabin # (maybe helpful)\n\n**Embarked:** port C = Cherbourg, Q = Queenstown, S = Southampton (maybe helpful, categorical)\n\nLet's see if there are correlations with any of the features that aren't clear whether they are helpful or not.","c5e44836":"# Training the model\nThe training data will be split into two folds for some preliminary testing before the final test.","9aa8669c":"# Adjusting Cabin Feature\nThe cabin number will be dropped and only the floor letter will be kept.\n\nAll unknown floor letters will be changed to the median of the passenger's class group. They might be changed later to be their own three groups.","b130d5ac":"What columns are predicted to be the most important?","bfde52e0":"Ticket numbers have an optional prefix describing where they are bought, and adjacent numbers may be helpful to find family members or other people in the party. They will be left alone for now.\n\nFare could be split into a few groups so that someone who paid 7.25 for a ticket is in the same group as someone who paid 7.50, but will remain unchanged for now.\n\nCabin has some missing data. The letter is helpful because A, B, and C are for the first class and they are closer to the life boats. E, F, and G are closer to the bottom and are for third class passengers. The level can be used, but more work needs to be done to find the missing cabin numbers."}}