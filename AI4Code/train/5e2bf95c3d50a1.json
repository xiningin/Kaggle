{"cell_type":{"d7020f16":"code","225dc1a2":"code","a5cf2cea":"code","c9496928":"code","1a970b40":"code","e2b33c16":"code","78d8c347":"code","5888a4bb":"code","d5b4df5c":"code","f95869e3":"code","bab53993":"code","10cd9156":"code","c2d50336":"code","64c2a94e":"code","2fe56b8c":"code","3a9c57ff":"code","d63edbcf":"code","0bff3c71":"code","d59fb24e":"code","0c318329":"code","75b37e7e":"code","5b5d47c3":"code","98f5f12d":"code","3b57f9a8":"code","b91839a0":"code","92a3857d":"code","ed6c031c":"code","f999a2b3":"markdown","0d3b739f":"markdown","8c3942d3":"markdown","e464f818":"markdown","36730acd":"markdown","f7f3e0ca":"markdown","4eba2e5a":"markdown","01d3c169":"markdown","e2ae8e5f":"markdown","07b9dbc6":"markdown","c2ba3f40":"markdown","322e4de2":"markdown","3d5bfbc2":"markdown","008b78d3":"markdown","0ee05776":"markdown","749cfae9":"markdown","2e9d513d":"markdown","f94da00b":"markdown"},"source":{"d7020f16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport plotly.express as px\nimport plotly.io as pio\n\npd.set_option('display.max_columns',None)\npd.set_option('display.max_rows',None)\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","225dc1a2":"df = pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()","a5cf2cea":"df.info()","c9496928":"n = msno.bar(df,color='gold')","1a970b40":"df.isnull().sum()","e2b33c16":"df.drop(['id','Unnamed: 32'],axis=1,inplace=True)","78d8c347":"plt.rcParams['figure.figsize']=(10,8)\nplt.style.use(\"classic\")\ncolor = ['yellowgreen','gold']\ndf['diagnosis'].value_counts().plot.bar(color=color)","5888a4bb":"plt.rcParams['figure.figsize']=(10,8)\nplt.style.use(\"classic\")\ncolor = ['yellowgreen','gold']\nlabels =['Malignant','Benign']\ndf['diagnosis'].value_counts().plot.pie(y=\"diagnosis\",colors=color,explode=(0,0.08),startangle=50,shadow=True,autopct=\"%0.1f%%\")\nplt.legend(labels,loc='best')\nplt.axis('on');","d5b4df5c":"pio.templates.default = 'plotly_dark'\ndef create_hist(xval,color):\n    fig = px.histogram(df,x=xval,color=color,title=xval,color_discrete_sequence = ['yellowgreen','gold'],width=600,height=300)\n    fig.show()","f95869e3":"create_hist('radius_mean','diagnosis')\ncreate_hist('texture_mean','diagnosis')\ncreate_hist('perimeter_mean','diagnosis')\ncreate_hist('area_mean','diagnosis')\ncreate_hist('smoothness_mean','diagnosis')\n","bab53993":"pio.templates.default = 'plotly_dark'\ndef create_scatter(xval,yval):\n    fig = px.scatter(df,x=xval,y=yval,color='diagnosis',title =xval +\" \"+\"vs\"+\" \"+ yval, color_discrete_sequence = ['yellowgreen','gold'],width=600,height=300)\n    fig.show()\n    \ncreate_scatter('radius_mean','texture_mean')\ncreate_scatter('texture_mean','perimeter_mean')\ncreate_scatter('perimeter_mean','area_mean')\ncreate_scatter('area_mean','smoothness_mean')\ncreate_scatter('smoothness_mean','compactness_mean')\n","10cd9156":"create_scatter('radius_worst','texture_worst')\ncreate_scatter('texture_worst','perimeter_worst')\ncreate_scatter('perimeter_worst','area_worst')\ncreate_scatter('area_worst','smoothness_worst')\ncreate_scatter('smoothness_worst','compactness_worst')\n","c2d50336":"pio.templates.default = 'plotly_dark'\ndef create_3dscatter(xval,yval,zval):\n    fig = px.scatter_3d(df,x=xval,y=yval,z=zval,color='diagnosis',title =xval +\" \"+\"vs\"+\" \"+ yval+\" \"+\"vs\"+\" \"+ zval, color_discrete_sequence = ['yellowgreen','gold','lightcoral'])\n    fig.show()\n    \ncreate_3dscatter('radius_worst','texture_worst','perimeter_worst')\ncreate_3dscatter('area_worst','smoothness_worst','compactness_worst')","64c2a94e":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nx = df.drop('diagnosis',axis=1)\ny = df['diagnosis']\nle = LabelEncoder()\ny = le.fit_transform(y)\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0,stratify=y)","2fe56b8c":"x_train.shape,x_test.shape","3a9c57ff":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","d63edbcf":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv1D,MaxPool1D,Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam","0bff3c71":"x_train = x_train.reshape(455,30,1)\nx_test = x_test.reshape(114,30,1);","d59fb24e":"x_train.shape","0c318329":"epochs=50\nmodel = Sequential()\nmodel.add(Conv1D(filters=32,kernel_size=2,activation='relu',input_shape=(30,1)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv1D(filters=64,kernel_size=2,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1,activation='sigmoid'))","75b37e7e":"model.summary()","5b5d47c3":"model.compile(optimizer=Adam(lr=0.00005),loss='binary_crossentropy',metrics=['accuracy'])","98f5f12d":"history = model.fit(x_train,y_train,epochs=60,validation_data=(x_test,y_test),verbose=1)","3b57f9a8":"history.history","b91839a0":"epoch_range= range(1,61)\nplt.plot(epoch_range,history.history['accuracy'])\nplt.plot(epoch_range,history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel(\"Epochs\")\nplt.ylabel('Accuracy')\nplt.legend(['Train','Val'],loc='upper left')\nplt.show()\n\nepoch_range= range(1,61)\nplt.plot(epoch_range,history.history['loss'])\nplt.plot(epoch_range,history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel('Loss')\nplt.legend(['Train','Val'],loc='upper left')\nplt.show()","92a3857d":"from mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import accuracy_score,confusion_matrix\ny_pred = model.predict_classes(x_test)\naccuracy_score(y_test,y_pred)","ed6c031c":"mat = confusion_matrix(y_test,y_pred)\nclasses_name=['Malignant','Benign']\nplot_confusion_matrix(mat,figsize=(10,8),class_names=classes_name,show_normed=True)\nplt.xticks(rotation=0);","f999a2b3":">Comparing 3 variables","0d3b739f":">Compiling the Model","8c3942d3":">Building CNN","e464f818":">Plotting Confusion Matrix","36730acd":">Import necessary Libraries for Building CNN","f7f3e0ca":">Train the Model","4eba2e5a":"> Checking is there any Null values or Not","01d3c169":">## Dropping unnecessary Columns","e2ae8e5f":">CNN works with 3 dimensional data.So to work with CNN i'm going to reshape the data into 3 dimensional","07b9dbc6":"><h3>Dataset Information:<\/h3>\n\nFeatures are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\nn the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server:\nftp ftp.cs.wisc.edu\ncd math-prog\/cpo-dataset\/machine-learn\/WDBC\/\n\nAlso can be found on UCI Machine Learning Repository: https:\/\/archive.ics.uci.edu\/ml\/datasets\/Breast+Cancer+Wisconsin+%28Diagnostic%29\n\nAttribute Information:\n\n1) ID number\n2) Diagnosis (M = malignant, B = benign)\n3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\na) radius (mean of distances from center to points on the perimeter)\nb) texture (standard deviation of gray-scale values)\nc) perimeter\nd) area\ne) smoothness (local variation in radius lengths)\nf) compactness (perimeter^2 \/ area - 1.0)\ng) concavity (severity of concave portions of the contour)\nh) concave points (number of concave portions of the contour)\ni) symmetry\nj) fractal dimension (\"coastline approximation\" - 1)\n\nThe mean, standard error and \"worst\" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features. For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.\n\nAll feature values are recoded with four significant digits.\n\nMissing attribute values: none\n\nClass distribution: 357 benign, 212 malignant","c2ba3f40":">Data Scaling","322e4de2":">Worst Cases","3d5bfbc2":">Spliting the dataset into train-test","008b78d3":">Except  texture_mean & perimeter_mean all of the features are Positively Correlated with each other.As the value increases the type of Cancer becomes Benign to Malignant","0ee05776":"---\n\n<h1 style=\"text-align: center;font-size: 40px;\">Breast Cancer Prediction<\/h1>\n<h1 style=\"text-align: center;font-size: 30px;\">(Malignant or Benign)<\/h1>\n\n---","749cfae9":"> ## Visualizations","2e9d513d":">## Import necessary Libraries & read the Data","f94da00b":">Plotting Learning Curve"}}