{"cell_type":{"0ad01d41":"code","121d7340":"code","633b7145":"code","440ce820":"code","376291ae":"code","291c16ff":"code","8bc02bfc":"code","73ac75fe":"code","baa457a3":"code","b327e106":"code","3c5ad334":"code","f8232797":"code","84e71b58":"code","cf3a043c":"code","e8e167b5":"code","0f5832a1":"code","992256e1":"code","61d013be":"code","1321fb6d":"code","d73bbff2":"code","282994d0":"code","e167c7eb":"code","0c416b02":"code","8253105c":"code","09e2ca35":"code","35714f87":"code","befb222b":"code","b3292161":"markdown","a32b37fd":"markdown","dc27b5e9":"markdown","347cc653":"markdown","8292c76d":"markdown","80b48ebd":"markdown","2cd7fb09":"markdown","9a39a98d":"markdown","a8f742bb":"markdown","2bc64d10":"markdown","940caebd":"markdown","1e40fe08":"markdown","5b678bf7":"markdown","e6f9b433":"markdown","51eabc93":"markdown","404a1929":"markdown","e43d6d0d":"markdown","9a15bacd":"markdown","04821159":"markdown","4fd38041":"markdown","d4839f69":"markdown","c403242a":"markdown","038983d3":"markdown","7d75fe78":"markdown","734bfb41":"markdown"},"source":{"0ad01d41":"from sklearn.metrics import confusion_matrix, f1_score,accuracy_score, precision_score, recall_score, roc_auc_score  \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import resample\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom random import randint\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n","121d7340":"Data = pd.read_csv(\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")","633b7145":"print(\"Dataframe Details\")\nprint(\"Total Rows: {}\\nTotal Columns: {}\".format(Data.shape[0],Data.shape[1]))\n\nData.head()","440ce820":"Data.isnull().sum().sort_values(ascending=False)[:5]","376291ae":"bmi = round(Data['bmi'].mean(),1) \nData['bmi'].fillna(bmi, inplace=True)","291c16ff":"Data['age'].fillna(0,inplace=True)\nbins = [0,18,36,54,72,90]\nlabels = ['0-18','18-36','36-54','54-72','72-90']\nData['age'] = pd.cut(Data['age'], bins=bins, labels=labels)\nData.head()","8bc02bfc":"colors = ['Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap',\n          'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', \n          'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', \n          'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', \n          'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', \n          'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', \n          'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', \n          'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', \n          'coolwarm_r', 'copper', 'copper_r', 'crest', 'crest_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'flare', \n          'flare_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', \n          'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', \n          'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'icefire', 'icefire_r', \n          'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'mako', 'mako_r', 'nipy_spectral', 'nipy_spectral_r', \n          'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'rocket', \n          'rocket_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', \n          'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', \n          'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'vlag', 'vlag_r', 'winter', 'winter_r']","73ac75fe":"StrokeAnalysis = Data.copy()\nStrokeAnalysis['hypertension'] = StrokeAnalysis['hypertension'].apply(lambda x : 'Hypertension' if x == 1 else 'No Hypertension') \nStrokeAnalysis['heart_disease'] = StrokeAnalysis['heart_disease'].apply(lambda x : 'Heart Disease' if x == 1 else 'No Heart Disease') \nStrokeAnalysis['stroke'] = StrokeAnalysis['stroke'].apply(lambda x : 'Suffered Stroke' if x == 1 else 'Never Suffered Stroke') \nStrokeAnalysis['ever_married'] = StrokeAnalysis['ever_married'].apply(lambda x : 'Married' if x == 'Yes' else 'Unmarried') \n\nStrokeAnalysis.head()","baa457a3":"value = randint(0, len(colors)-1)\n\nsns.countplot(x = 'stroke',palette = colors[value],data = StrokeAnalysis)\n\nplt.xlabel(\"Patient Type\")\nplt.ylabel(\"Count Of Patients\")","b327e106":"value = randint(0, len(colors)-1)\n\nsns.countplot(x = 'stroke',hue = 'gender',palette = colors[value],data = StrokeAnalysis)\n\nplt.xlabel(\"Patient Type & Gender\")\nplt.ylabel(\"Count Of Patients\")","3c5ad334":"value = randint(0, len(colors)-1)\n\nsns.countplot(x = StrokeAnalysis[StrokeAnalysis['smoking_status'] != 'Unknown']['smoking_status'], hue = 'gender',\n            palette = colors[value],data = StrokeAnalysis)\n\nplt.xlabel(\"Smoking Status\")\nplt.ylabel(\"Count by Gender\")\n","f8232797":"plt.figure(figsize=(10,5))\nplacement = 1\n\nfor i in ['hypertension','heart_disease']:\n    label = []\n    value = []\n    for j in range(len(StrokeAnalysis[i].value_counts().index)):\n        label.append(StrokeAnalysis[i].value_counts().index[j])\n        value.append(StrokeAnalysis[i].value_counts()[j])\n        \n    plt.subplot(1,2,placement)    \n    explode = (0.1, 0.2)\n    plt.pie(value, labels = label,autopct='%1.2f%%',colors=['brown','darksalmon'],shadow=True,explode=explode)\n    plt.title(\"{} VS {}\".format(label[0],label[1]))\n    placement += 1\n    \nplt.tight_layout(pad=0.4)    ","84e71b58":"value = randint(0, len(colors)-1)\n\nplt.figure(figsize=(10,5))\n\nplt.subplot(1,2,1)  \nsns.countplot(x = 'age', hue = 'hypertension',\n            palette = colors[value],data = StrokeAnalysis)\n\nplt.xlabel(\"Hypertension\")\nplt.ylabel(\"Count by age\")\n\nplt.subplot(1,2,2)  \nsns.countplot(x = 'age', hue = 'heart_disease',\n            palette = colors[value],data = StrokeAnalysis)\n\nplt.xlabel(\"Heart Disease\")\nplt.ylabel(\"Count by age\")\n\nplt.tight_layout(pad=0.4)    ","cf3a043c":"value = randint(0, len(colors)-1)\n\nplt.figure(figsize=(10,5))\n\nplt.subplot(1,2,1)  \nsns.countplot(x = 'work_type', hue = 'hypertension',\n            palette = colors[value],data = StrokeAnalysis)\n\nplt.xlabel(\"Hypertension\")\nplt.ylabel(\"Count by age\")\n\nplt.subplot(1,2,2)  \nsns.countplot(x = 'work_type', hue = 'heart_disease',\n            palette = colors[value],data = StrokeAnalysis)\n\nplt.xlabel(\"Heart Disease\")\nplt.ylabel(\"Count by age\")\n\nplt.tight_layout(pad=0.4)    ","e8e167b5":"plt.figure(figsize=(10,6))\nplacement = 1\n\nfor i in ['ever_married','Residence_type']:\n    label = []\n    value = []\n    for j in range(len(StrokeAnalysis[i].value_counts().index)):\n        label.append(StrokeAnalysis[i].value_counts().index[j])\n        value.append(StrokeAnalysis[i].value_counts()[j])\n        \n    plt.subplot(2,2,placement)    \n    explode = (0.1, 0.1)\n    plt.pie(value, labels = label,autopct='%1.2f%%',colors=['darkslategrey','paleturquoise'],shadow=True,explode=explode)\n    plt.title(\"{} VS {}\".format(label[0],label[1]))\n    placement += 1\n    \nplt.tight_layout(pad=0.4)    ","0f5832a1":"value = randint(0, len(colors)-1)\n\nsns.countplot(x = 'Residence_type', hue = 'ever_married', palette = colors[value],data = StrokeAnalysis)\nplt.legend(StrokeAnalysis['ever_married'].unique(), loc =\"upper right\") \nplt.xlabel(\"Residence Type\")\nplt.ylabel(\"Count by Marital Status\")","992256e1":"plt.figure(figsize=(10,5))\n\nplt.subplot(1,2,1) \nlabel = StrokeAnalysis['age'].value_counts().index\nvalue = StrokeAnalysis['age'].value_counts().values\nexplode = (0.2,0,0,0,0.2)\nplt.pie(value, labels = label,autopct='%1.2f%%',colors=['deepskyblue','steelblue','lightslategrey','skyblue','crimson'],shadow=True,explode=explode)\nplt.title(\"Age Bifurcation\")\n\nplt.subplot(1,2,2)  \nlabel = StrokeAnalysis['work_type'].value_counts().index\nvalue = StrokeAnalysis['work_type'].value_counts().values\nexplode = (0.1,0,0,0,1)\nplt.pie(value, labels = label,autopct='%1.2f%%',colors=['deepskyblue','steelblue','lightslategrey','skyblue','crimson'],shadow=True,explode=explode)\nplt.title(\"Work Type Bifurcation\")\n\nplt.tight_layout(pad=0.4)    ","61d013be":"value = randint(0, len(colors)-1)\n\nsns.boxplot(x = 'work_type', y = 'avg_glucose_level', hue = 'Residence_type',palette = colors[value],data = StrokeAnalysis)\nplt.xlabel(\"Residence & Work Type\")\nplt.ylabel(\"Count by Body Mass Index\")","1321fb6d":"value = randint(0, len(colors)-1)\n\nStrokeAnalysis = StrokeAnalysis[StrokeAnalysis['bmi']<50]\nsns.lmplot(x = 'bmi', y = 'avg_glucose_level',palette = colors[value],data = StrokeAnalysis)\nplt.xlabel(\"Body Mass Index\")\nplt.ylabel(\"Average Glucose Level\")","d73bbff2":"value = randint(0, len(colors)-1)\nplt.figure(figsize=(15,5))\n\nplt.subplot(2,2,1)\nplt.title(\"Average Glucose Level with Outliers\")\nsns.boxplot(x = Data['avg_glucose_level'],palette = colors[value])\nplt.xlabel(\"Glucose Level\")\n\nplt.subplot(2,2,2)\nplt.title(\"Body Mass Index with Outliers\")\nsns.boxplot(x = Data['bmi'],palette = colors[value])\nplt.xlabel(\"Body Mass Index\")\n\nplt.subplot(2,2,3)\nplt.title(\"Average Glucose Level without Outliers\")\nData = Data[Data['avg_glucose_level'] < 130] \nsns.boxplot(x = Data['avg_glucose_level'],palette = colors[value])\nplt.xlabel(\"Glucose Level\")\n\nplt.subplot(2,2,4)\nplt.title(\"Body Mass Index without Outliers\")\nData = Data[(Data['bmi'] > 10.3) & (Data['bmi'] < 43)] \nsns.boxplot(x = Data['bmi'],palette = colors[value])\nplt.xlabel(\"Body Mass Index\")\n\nplt.tight_layout(pad=0.6)","282994d0":"encoder = LabelEncoder()\n\ncolumn = ['gender', 'age', 'hypertension', 'ever_married','work_type', 'Residence_type', 'smoking_status']\n\nfor i in column:\n    Data[i] = encoder.fit_transform(Data[i])\n    \nData.head()","e167c7eb":"majority = Data[Data['stroke'] == 0]\nminority = Data[Data['stroke'] == 1]\n\nupsampled = resample(minority, replace=True, n_samples=len(majority))","0c416b02":"StrokeData = pd.concat([majority,upsampled])\nStrokeData = StrokeData.sample(frac=1).reset_index(drop=True)\nStrokeData.head()","8253105c":"X = StrokeData.drop(['id','stroke'],axis=1)\ny = StrokeData['stroke']\n\nDataModels = pd.DataFrame()","09e2ca35":"def TrainandTestwithMinMaxScalar(X,y,algorithm,modelname):\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    \n    norm = MinMaxScaler().fit(X_train)\n\n    X_train = norm.transform(X_train)\n\n    X_test = norm.transform(X_test)\n\n    model = algorithm\n    model.fit(X_train, y_train)\n\n    prediction = model.predict(X_test)\n\n    score = round((accuracy_score(y_test, prediction)*100),2)\n    print(\"\\nModel Score:\",score,\"%\")\n    print(\"Precision:\", precision_score(y_test, prediction))\n    print(\"Recall:\", recall_score(y_test, prediction))\n    print(\"F1 score:\", f1_score(y_test, prediction))\n    print(\"ROC-AUC score:\", roc_auc_score(y_test, prediction))\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, prediction))\n    print()\n    \n    model = {}\n    \n    model['Algorithm'] = modelname\n    model['Model Score'] = str(score) + \"%\"\n    model['Precision'] = round(precision_score(y_test, prediction),2)\n    model['Recall'] = round(recall_score(y_test, prediction),2)\n    model['F1 score'] = round(f1_score(y_test, prediction),2)\n    model['ROC-AUC score'] = round(roc_auc_score(y_test, prediction),2)\n    \n    return model","35714f87":"algorithms = {\"Random Forest\":RandomForestClassifier(),\"Decision Tree\":DecisionTreeClassifier(),\n              \"Logistic Regression\":LogisticRegression(),\"K-Nearest Neighbour\":KNeighborsClassifier(n_neighbors=3),\n              \"Support Vector Classifier\":SVC()}\n\nfor i,j in algorithms.items():\n    print(\"Algorithm Performance: {}\".format(i))\n    \n    model = TrainandTestwithMinMaxScalar(X,y,j,i)\n    DataModels = DataModels.append(model,ignore_index=True)\n    \n    print()    ","befb222b":"DataModels.sort_values(by='F1 score',ascending=False)","b3292161":"A large portion of patients have never smoked in their lifetime, majority being women.","a32b37fd":"We see that the number of patients married are much more. The proportion of rural and urban patients are almost equal.","dc27b5e9":"There is a majority of female patients.","347cc653":"Random Forest and Decision Tree have high precision. The number of false-positive is better handled by Random Forest. Therefore we can use Random Forest to predict whether or not a patient will suffer from a stroke or not.","8292c76d":"Below is the list of a variety of color palette that can be used while creating visuals","80b48ebd":"As we had noted in our analysis our dataset is high imbalanced. Therefore we use the method of resample() to duplicate the records of the class - Suffered from a stroke. We duplicate these class records such that they match up to the number of records of class - Not suffered from a stroke. ","2cd7fb09":"Children and patients who have never worked are likely not to suffer from any underlying conditions.","9a39a98d":"The majority of our patients belong to the age category of 36-54 and most of them work in private sectors.","a8f742bb":"# Data Modeling","2bc64d10":"The propotion of patients with hypertension and heart diseases are very low.","940caebd":"![image.png](attachment:image.png)","1e40fe08":"There is no difference in the marriage rate between rural and urban areas.","5b678bf7":"# Summary of Analysis","e6f9b433":"The number of patients who have suffered a stroke is very less as compared to the data with the ones who haven't suffered.","51eabc93":"# Data Cleaning and Processing","404a1929":"Due to the number of outliers, it becomes very to analyze the data, thus it is necessary to handle these outliers.","e43d6d0d":"It is necessary to shuffle our data such that the algorithms can learn different records as it is served as an input. Once the dataset is shuffled we are good to go.","9a15bacd":"A <b>Brain Stroke<\/b> is a condition when the supply of blood to a portion of the brain is interrupted. This prevents the brain tissues from getting oxygen and nutrients. The brain cells thus begin to die. It is critical and needs to be given immediate treatment. Brain stroke causes several symptoms such as trouble walking, speaking, and understanding, as well as paralysis or numbness of the face, arm, or leg. According to the <b>World Health Organization (W.H.O)<\/b>, about 15 million people suffer stroke worldwide yearly. Out of these 15 million, about 5 million die, and 5 million are permanently paralyzed. High blood pressure is our mortal enemy who is contributing to more than 12.7 million strokes worldwide. \n\nThis notebook aims at building a predictive model that helps in identifying whether a patient is likely to suffer from a brain stroke.\n\nKindly provide an upvote if this notebook was useful. Also, I would greatly appreciate any feedback or suggestions for improvement.\n\nThank-you :)","04821159":"There is no deterministic relationship between Body Mass Index and Average Glucose Level. We have temporarily dealt with the outliers to identify a relationship between them. It is always advisable to deal with these outliers before we train a prediction model.","4fd38041":"----------------------------------------------------------------------------------------------------------","d4839f69":"We observe that patients between the age of 0-18 do not suffer from hypertension or any underlying heart conditions whereas patients above 18 years of age may be suffering from either hypertension, heart conditions, or both. ","c403242a":"- Data for patients suffering from a stroke are much lesser than those who have not suffered a stroke. This imbalance would cause our model to make a wrongful prediction, therefore we will balance our data before data modeling\n- A major portion of the patients are women and it is observed that these patients have not suffered any stroke in the past.\n- As compared to males many female patients do not smoke. The probable reason being that the data captured have a majority of female records  \n- It is observed that patients who formerly smoked are little higher than those who currently continue smoking\n- As per the data patients suffering from hypertension and heart diseases are only 9.75% and 5.40% respectively\n- Patients between the age of 0-18 do not suffer from any conditions, specifically hypertension and heart diseases\n- As a patient grows older it is observed that hypertension due to work-related stress may increase, also creating room for heart diseases\n- We see that the patients working for private sectors are exposed to higher stress levels than the rest of the working class\n- Children and patients who have never worked may not be suffering from any\n  underlying conditions.\n- There is a very minor difference in the proportion of patients living in urban\/rural areas. Whereas a majority of patients have been married (Current marital status unknown)\n- The majority of our patients below to a private working class and are between the ages of 36-54. \n- A very less portion of our patients has never worked. Also, a very less portion of our patients are senior citizens.\n- We observe that there are many outliers in the body mass index and the average glucose level, which needs to be handled before data modeling\n","038983d3":"<h1><center> Stroke Analysis <\/center> <\/h1>","7d75fe78":"# Data Visualization","734bfb41":"Having outliers in the dataset guides the algorithm onto making wrong predictions, that seem just right to the predictive model. Therefore we have eliminated the outliers using a graphical method."}}