{"cell_type":{"320df6ea":"code","40ceb999":"code","74543249":"code","9fa484c7":"code","df94678d":"code","4c08e8f2":"code","77f513da":"code","afb97fdc":"code","b08b5a9a":"code","0448a86a":"code","9d3ff01e":"code","3dbb0d0e":"code","99460b1a":"code","ec97a0df":"markdown","3e1c7eee":"markdown","5ec22455":"markdown","3a617b8e":"markdown","9d5a969b":"markdown","8ab4abc5":"markdown"},"source":{"320df6ea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname)\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","40ceb999":"import tensorflow as tf\nimport keras\nimport keras_preprocessing\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom keras.models import model_from_json\nfrom keras.applications.vgg16 import VGG16","74543249":"base_dir = '\/kaggle\/input\/intel-image-classification\/'\ntraining_dir = base_dir + 'seg_train\/seg_train\/'\ntesting_dir = base_dir + 'seg_test\/seg_test\/'\n\nprint(\"No of Images for class Buildings\",len(os.listdir(training_dir+'buildings')))\nprint(\"No of Images for class glacier\",len(os.listdir(training_dir+'glacier')))\nprint(\"No of Images for class sea\",len(os.listdir(training_dir+'sea')))\nprint(\"No of Images for class mountain\",len(os.listdir(training_dir+'mountain')))\nprint(\"No of Images for class forest\",len(os.listdir(training_dir+'forest')))\nprint(\"No of Images for class street\",len(os.listdir(training_dir+'street')))","9fa484c7":"\ntrain_gen = ImageDataGenerator(\n    rescale = 1.0\/255.0,\n    zoom_range = 0.2,\n    shear_range = 0.2,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    fill_mode = 'nearest',\n    horizontal_flip=True    \n)\n\ntest_gen = ImageDataGenerator(\n    rescale = 1.0\/255.0\n)\n\ntraining_data = train_gen.flow_from_directory(\n    training_dir,\n    batch_size=32,\n    class_mode = 'categorical',\n    color_mode ='rgb',\n    target_size=(150, 150)\n)\n\ntesting_data = test_gen.flow_from_directory(\n    testing_dir,\n    batch_size=32,\n    class_mode = 'categorical',\n    color_mode ='rgb',\n    target_size=(150, 150)\n)","df94678d":"class cnn_callback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epochs, logs={}):\n        if(logs['accuracy']>0.5):\n            print(\"Training Stopped\")\n            self.model.stop_training = True\ncallback = cnn_callback()\n\ndef visualization(history):\n    acc = history.history['acc']\n    loss = history.history['loss']\n    val_acc = history.history['val_acc']\n    val_loss = history.history['val_loss']\n    \n    fig, ax = plt.subplots()\n    ax.plot(acc, label='Training Accuracy')\n    ax.plot(val_acc, label='Validation Accuracy')\n    leg = ax.legend();\n    plt.show()\n    \n    fig, ax = plt.subplots()\n    plt.plot(loss, label='Training Loss')\n    plt.plot(val_loss, label='Validation Loss')\n    leg = ax.legend();\n    plt.show()\n\ndef save_weights(model, name):\n    base_dir = \"\/kaggle\/working\/\"\n    model_dir = base_dir + name\n    \n    # serialize weights to HDF5\n    model.save_weights(model_dir+\".h5\")\n    print(\"Saved model to disk\")\n    \ndef load_weights(model, name):\n    base_dir = \"\/kaggle\/working\/\"\n    model_dir = base_dir + name\n    \n    # load weights into new model\n    model.load_weights(model_dir + \".h5\")\n    print(\"Loaded weights from disk\")\n    return model","4c08e8f2":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(6, (5,5), input_shape=(150, 150, 3), activation='tanh'),\n    tf.keras.layers.AveragePooling2D(2,2),\n    tf.keras.layers.Conv2D(16, (5,5), activation='tanh'),\n    tf.keras.layers.AveragePooling2D(2,2),\n    tf.keras.layers.Conv2D(120, (1,1), activation='tanh'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(84, activation='tanh'),\n    tf.keras.layers.Dense(6, activation='softmax')\n])\nmodel.summary()","77f513da":"#Training the model\nmodel.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\nhistory = model.fit(training_data, epochs = 15, validation_data = testing_data, callbacks=[callback])\nvisualization(history)","afb97fdc":"save_weights(model, 'lenet_5')\nloaded_model = load_weights(model, 'lenet_5')","b08b5a9a":"vgg_16_basedir = '\/kaggle\/input\/vgg16\/'\nvgg16_model = VGG16(input_shape=(150, 150, 3), include_top=False, weights = vgg_16_basedir+'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\nfor layer in vgg16_model.layers:\n    layer.trainable = False\n\n#Checking if the Dense layers were removed.\nprint(vgg16_model.layers[-1])","0448a86a":"model = vgg16_model.output\nmodel = keras.layers.core.Flatten()(model)\nmodel = keras.layers.core.Dense(1024, activation='relu')(model)\nmodel = keras.layers.core.Dropout(0.2)(model)\nmodel = keras.layers.core.Dense(512, activation='relu')(model)\nmodel = keras.layers.core.Dense(6, activation='softmax')(model)\n\nfinal_model = keras.models.Model(inputs = vgg16_model.input, outputs = model)","9d3ff01e":"final_model.summary()","3dbb0d0e":"final_model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['acc'])\nhistory = final_model.fit_generator(training_data, epochs = 15, validation_data = testing_data, callbacks=[callback])\nvisualization(history)","99460b1a":"model_input = keras.layers.Input(shape=(150, 150, 3))\nconv_1 = keras.layers.Conv2D(64, (1,1), activation='relu', padding='same')(model_input)\nconv_3 = keras.layers.Conv2D(64, (3,3), activation='relu', padding='same')(model_input)\nconv_5 = keras.layers.Conv2D(32, (5,5), activation='relu', padding='same')(model_input)\nmax_pooling = keras.layers.MaxPooling2D((2, 2), padding='same')(model_input)\nlayer_1 = keras.layers.merge([conv_1, conv_2, conv_3, max_pooling])","ec97a0df":"### Data Manipulation","3e1c7eee":"### Importing Libraries","5ec22455":"### Inception Networks","3a617b8e":"### LeNet-5 Architecture\n[http:\/\/yann.lecun.com\/exdb\/publis\/pdf\/lecun-01a.pdf](http:\/\/)","9d5a969b":"### VGG-16 Architecture\n[https:\/\/arxiv.org\/pdf\/1409.1556.pdf(http:\/\/)","8ab4abc5":"### Model utility Functions"}}