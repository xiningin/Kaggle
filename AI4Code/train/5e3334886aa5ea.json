{"cell_type":{"3f10bcd5":"code","f5e50592":"code","e4514467":"code","b7b634d0":"code","1c78a645":"code","ed6a94c4":"code","da5e4092":"code","2f6c79b6":"code","67274902":"code","47e94a83":"code","79486aa9":"code","085ac03b":"code","ab084a44":"code","64e66a51":"code","032a1bec":"code","223c08f5":"code","1b4a33c5":"code","7412f48e":"code","c5ea2148":"code","96df2511":"code","a3427aa6":"code","0acd1644":"code","2068bcec":"code","b5afb294":"code","841474df":"code","84a4cf75":"code","499685b4":"code","c3b859e2":"code","ddb734f3":"code","6bd7c628":"code","e5e3c715":"code","6606231b":"code","f581a8f2":"code","327a59d9":"code","070653a8":"code","1fac2b33":"code","2053f59f":"code","6a1b95b1":"markdown","9248da55":"markdown","a393d4b1":"markdown","d238822e":"markdown","f7bd14d1":"markdown","bca1c496":"markdown","c79bbe65":"markdown","f4ba0c15":"markdown","00ee28a6":"markdown","937cf80e":"markdown","84d9eda9":"markdown","36ea773d":"markdown","31f3c8c8":"markdown","c5f64d40":"markdown","1a42c3d2":"markdown","e6f25a70":"markdown","024c3252":"markdown","d50461e9":"markdown"},"source":{"3f10bcd5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5e50592":"#import important libraries\nimport pandas as pd\nfrom sklearn.datasets import fetch_openml\nimport numpy as np\n","e4514467":"train=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntrain.head()","b7b634d0":"train.shape #42,000 rows of data with each row having (28*28=784 features or col with pixel values)","1c78a645":"X=train.iloc[:,1:]\nY=train.label","ed6a94c4":"X.shape","da5e4092":"test=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntest.head()","2f6c79b6":"sum(Y==2)","67274902":"#PLOT images\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = X.loc[3,:].values\nsome_digit_image = some_digit.reshape(28, 28)#reshaping into 2-D image matrix\n\nplt.imshow(some_digit_image)\nplt.axis(\"off\")\nplt.show()","47e94a83":"#Label Encoding : If digit is  2 value true else false\n\n#target value is in integer converting to boolean \ny_is_digit2= (Y==2)\ny_is_digit2","79486aa9":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(X,y_is_digit2,random_state=1)","085ac03b":"y_train","ab084a44":"from sklearn.neighbors import KNeighborsClassifier\nfrom random import seed\n\nseed(123) # setting  random seed for reproducibility \n\n#create instance of Knn classifier\nknn_clf=KNeighborsClassifier(n_neighbors=5,weights='uniform',algorithm='auto')\n\n#knn_clf.fit(X_train,y_train)# this training takes less time since KNN is lazy learning algorithm\n","64e66a51":"#knn_clf.score(X_test,y_test)","032a1bec":"#y_pred_knn=knn_clf.predict(X_test)","223c08f5":"from sklearn.linear_model import SGDClassifier\n\nsgd_clf = SGDClassifier(random_state=42)\nsgd_clf.fit(X_train, y_train)","1b4a33c5":"y_pred_sgd = sgd_clf.predict(X_test)\nsgd_clf.score(X_test,y_test)","7412f48e":"from sklearn.naive_bayes  import GaussianNB\n\ngauss_clf= GaussianNB()\ngauss_clf.fit(X_train,y_train)\n\ngauss_clf.score(X_test,y_test)\n","c5ea2148":"print('The mean of each pixel for True class',gauss_clf.theta_[1].shape)\n\nplt.imshow(gauss_clf.theta_[1].reshape(28,28))\nplt.axis('off')","96df2511":"y_pred_gauss=gauss_clf.predict(X_test)","a3427aa6":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\nscaler=StandardScaler()\nscaler.fit(X_train)   #fit calculates the mean and std dev for each feature in data\nX_train_scaled=scaler.transform(X_train) #transforming the X_train feature inputs\nlogis_clf=LogisticRegression(solver='sag')\nlogis_clf.fit(X_train_scaled,y_train)","0acd1644":"X_test_scaled=scaler.transform(X_test) #scaling the test set note we dont use fit on test set which is wrong since it leads to data leakage\nlogis_clf.score(X_test_scaled,y_test)","2068bcec":"y_pred_logis=logis_clf.predict(X_test)","b5afb294":"from sklearn.svm import SVC\n\nsvc_clf=SVC(random_state=123,class_weight='balanced') #using default kernel 'rbf'\nsvc_clf.fit(X_train,y_train)\n","841474df":"svc_clf.score(X_test,y_test)","84a4cf75":"y_pred_svc=svc_clf.predict(X_test)","499685b4":"#CONFUSION MATRIX \nfrom sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix\nimport matplotlib.pyplot as plt\n\n#Confusion Matrix\nconf_mat=confusion_matrix(y_test,y_pred_logis)\n\n#Display Confusion Matrix\nConfusionMatrixDisplay(conf_mat,display_labels=['Not Digit 2','Is Digit 2'])\nplt.title('Confusion Matrix for KNNeighbors whether a data is digit 2 or not ')\nplt.show()","c3b859e2":"ig, ax = plt.subplots(figsize=(7.5, 7.5))\nax.matshow(conf_mat, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(conf_mat.shape[0]):\n    for j in range(conf_mat.shape[1]):\n        ax.text(x=j, y=i,s=conf_mat[i, j], va='center', ha='center', size='xx-large')\n \nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()","ddb734f3":"ConfusionMatrixDisplay.from_predictions(y_true=y_test ,y_pred=y_pred_logis,cmap='plasma',normalize='true',display_labels=['Not Digit 2','Is Digit 2'])\nplt.title('NOrmalized Confusion Matrix for KNNeighbors based on true values ')\nplt.show()\nprint('Diagonals Represent Recall of each class')","6bd7c628":"#CLassification Metric Report \nfrom sklearn.metrics import classification_report\n\nprint(classification_report(y_test,y_pred_logis))","e5e3c715":"# Calculating F-1 Score for all classifiers since we have imbalanced \n#dataset so F1 score metric more suitable for this case than accuracy\nfrom sklearn.metrics import f1_score\n\n\nscore_df=[y_pred_gauss,y_pred_sgd,y_pred_svc,y_pred_logis]\nf1_scores=[]\nname=['Gauss','SGD','SVC','Logis']\n\nfor score in score_df:\n  print(\"The f1 score\")\n  f1_scores.append(round(f1_score(y_test,score),3))\n  print(f1_scores)\n\n\n","6606231b":"plt.plot(name,f1_scores,'r.-')\nplt.title('F1- Scores of various classifiers')","f581a8f2":"#Cross val score,cross val predict\nfrom sklearn.model_selection import cross_val_score,cross_val_predict\n\nprint(cross_val_score(logis_clf,X_train,y_train))\n\n#y_cross_pred= cross_val_predict(knn_clf,X_test,y_test,method='decision_function')","327a59d9":"y_test_predictions=svc_clf.predict(test)","070653a8":"y_test_predictions","1fac2b33":"ImageId=[i for i in range(1,28001)]\nsubmission=pd.DataFrame({\"ImageId\":ImageId,\"Label\":y_test_predictions},columns=['ImageId','Label'])\n\nsubmission.head()","2053f59f":"submission.to_csv(\".\/submission.csv\",index=False)","6a1b95b1":"## Confusion Matrix\n\n\nA much better way to evaluate the performance of a classifier is to look at the confusion matrix. The general idea is to count the number of times instances of class A are classified as class B. To compute the confusion matrix, you first need to have a set of predictions so that they can be compared to the actual targets. \n\nWe need to have predicted classes from each of our classifiers which we calculated earlier (y_pred_knn ,y_pred_sgd...etc.)","9248da55":"## Precision - Recall Curve\n\nIncreasing precision reduces recall, and vice versa. This is called the precision\/recall trade-off. We can plot PR Curve to decide on the decision threshold based on our requirement of precision \/recall. ","a393d4b1":"## Cross Validation Score\n\nWe can use cross validation to test our model across several folds of data to get better metric for evaluation which is not biased. This comes at a cost of more training time .","d238822e":"## Classification Report\n","f7bd14d1":"## 3) Gaussian Naive Bayes Classifier \n\nNaive Bayes is the most common classifier for binary classification. It is fast and easy to calculate.Naive \u2014 Bayes is a classifier which uses Bayes Theorem. It calculates the probability for membership of a data-point to each class and assigns the label of the class with the highest probability.\n\nFor our MNIST dataset we have continuous features so we can apply Gaussian Naive Bayes which assumes distribution of feature values as Gaussian Distribution .","bca1c496":"## 2) Stochastic Gradient Descent Classifier\n\nThis classifier has the advantage of being **capable of handling very large datasets efficiently**. This is in part because SGD deals with training instances independently, one at a time (which also makes SGD well suited for online learning)","c79bbe65":"# Binary Classification Methods","f4ba0c15":"This notebook is a tutorial on various classifiers that can be used for binary classifications and also we will go through various classification metrics used to evaluate such a classifier.","00ee28a6":"### 7.Weighted Average\nIt is weighted average of precision of each class. \nNa*PrecisionA +Nb*PrecisionB\/ Total elements","937cf80e":"## 4) Logistic Regression Classifier \n\n It it the most common regression classifier .  Like a Linear Regression model, a Logistic Regression model computes a weighted sum of the input features (plus a bias term), but instead of outputting the result directly like the Linear Regression model does, it outputs the logistic or **sigmoid** function output which gives the probability of belonging to a class or not and output range of sigmoid function (0,1)","84d9eda9":"# Classification Evaluation Metrics","36ea773d":"### 6.Macro Average\nIt is average of precision of each class. \nMacro Average =(Precision Class A + Precision Class B)\/2","31f3c8c8":"## 5) Support Vector Machines\n\nSVM is a powerful classifier\/regression algorithms . They are non-parametric and can construct complex decision boundaries. ","c5f64d40":"### 1.Precision\nTP\/TP+FP = calculated wrt to predicted values. \nIt measures \u201cexactness\u201d of our model . How exact or precise it is in predicting  true positive classes out of all classes that were predicted as positive .\n When cost of false positive is high High precision is required. Ex- spam email. \n\n\n### 2.Recall\/Sensitivity\n\nTP\/TP+FN = calculated wrt to true values. \nIt \u201cMeasures \u201d completeness of model . How well our model in capture all positive cases out of all the data points. \nWhen cost of False Negative is high high recal is required .Ex- target customers to accept discount offer.\n\n\n### 3.Specificity\n\nTN\/TN+FP  ==calculated wrt to true values. \n\n\n### 4.Accuracy\n\nDiagonal elements\/Total datapoints = TP+TN\/Total Datapoints\n\n*Not an accurate metric in case of imbalanced\/skewed dataset.* \n\n\n### 5.F-1 Score\nHarmonic Mean of precision and Recall.F1 score is the harmonic mean of precision and recall (Equation 3-3). Whereas the regular mean treats all values equally, the harmonic mean gives much more weight to low values. As a result, the classifier will only get a high F1 score if both recall and precision are high.\n\nF1 score favors classifiers that have similar precision and recall.\n\nIn some contexts you mostly care about precision, and in other contexts you really care about recall. \n","1a42c3d2":"We can see we get best scores for KNN and SVC and worst score for Gaussian Naive Bayes.\n\nThe reason could be that we are analysing pixel points of image and knn and SVC are distance based classifiers which is apt for this case .","e6f25a70":"## Submission CSV\n\nFinally out of all the above classifier we got maximum accuracy for SVC so using it to generate prediction for test.csv for our submission","024c3252":"# 1) K-NEIGHBORS CLASSIFIER \n**KNeighborsClassifier Parameters**<br>\n`n_neighbors` = specify value of k <br>\n`weights`     = (default='uniform')<br>\n\u2018uniform\u2019 : uniform weights. All points in each neighborhood are weighted equally.<br>\n\u2018distance\u2019 : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.<br>\n[callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n\n`algorithm`= (default='auto','kd_tree','ball_tree','brute')\nKDtree,Ball Tree - good effiecient for large datasets ,  \n\nbrute- useful for small datasets and more accurate as considers all datapoints\n\n`metric` = specifies distance metric default='minowski'\n\n\n","d50461e9":"## Normalized Confusion Matrix\nWe can get normalized confusion matrix by using `normalize` argument of ConfusionMatrixDisplay\n\nUsing `normalize` =(default ='None')<br>\n'all'=values divided by total datapoints,<br>\n'true'= each value divided by corresponding total true values for each class , in this diagonal represent recall<br>\n'pred'=each value divided by total predicted value for each class,diagonals represent precision<br>\n"}}