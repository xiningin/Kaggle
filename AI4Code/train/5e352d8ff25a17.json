{"cell_type":{"045799a9":"code","3871edca":"code","64e75d84":"code","778e4982":"code","fe9b508a":"code","93f9ffb5":"code","02737aef":"code","72015a41":"code","1816d66f":"code","50b7cbaf":"code","3bf9d23a":"code","64c82204":"code","97cb39cb":"code","52169493":"code","a3febcce":"code","922adf80":"code","36030939":"code","029c630c":"code","675246e0":"code","1d659f9f":"code","22289ff9":"code","5eedd26b":"code","45edf4f6":"code","ffb3b90a":"code","c5ea0ba7":"code","9b77f36a":"markdown","3f4cee4f":"markdown","48035986":"markdown","efa15e47":"markdown","da8ca138":"markdown","85c4b2c5":"markdown","944014b2":"markdown","9744bdf9":"markdown","36cb3e19":"markdown","645ed9f1":"markdown","953fd1f4":"markdown","0a21e9f7":"markdown","e390eecd":"markdown","56078059":"markdown","f2366bc6":"markdown","e61e3a3a":"markdown","5b379a7a":"markdown","ae441e9f":"markdown","e02f30e4":"markdown","894d6a4a":"markdown","b6185f2c":"markdown","03a24826":"markdown","15800666":"markdown"},"source":{"045799a9":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\n!pip install arch >\/dev\/null\nfrom arch.univariate import ARX, GARCH\n\nfrom statsmodels.api import add_constant, OLS\nfrom statsmodels.tsa.ar_model import AR, ARResults\nfrom statsmodels.tsa.arima_model import ARMA,ARIMA,ARMAResults, ARIMAResults\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.stattools import adfuller, grangercausalitytests, coint\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing, Holt\nfrom statsmodels.tsa.vector_ar.vecm import coint_johansen\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer, PolynomialFeatures\n\nfrom scipy.stats import pearsonr\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_rows', 4000)","3871edca":"def parser(s):\n    return datetime.strptime(s, '%Y-%m-%d %H:%M:%S')\ndf = pd.read_csv(\"..\/input\/cyprus\/China.csv\", parse_dates=['time'],date_parser=parser,index_col='time')\ndf_w = df.resample('W').mean()\ndf_SP = pd.read_csv(\"..\/input\/cyprus\/SP.csv\", parse_dates=['time'],date_parser=parser,index_col='time')\ndf_SP_w = df_SP.resample('W').mean()","64e75d84":"r = pd.merge(df_w, df_SP_w, left_index=True, right_index=True)","778e4982":"r['Ch_log_r'] = r.Ch_close.apply(np.log1p).diff()\nr['SP_log_r'] = r.SP_close.apply(np.log1p).diff()\n\nfor i in range(1, 9):\n    r[f'SP_log_l{str(i)}']  = r.SP_log_r.shift(i)\n    r[f'Ch_log_l{str(i)}'] = r.Ch_log_r.shift(i)\n    r[f'SP_close_l{str(i)}']  = r.SP_close.shift(i)\n    r[f'Ch_close_l{str(i)}']  = r.Ch_close.shift(i) ","fe9b508a":"r.plot(subplots=True, figsize=(19,32))\n#plt.savefig('stocks.png')\nplt.show()","93f9ffb5":"res_ADF = adfuller(r.SP_close, regression='ct')\nprint(f'ADF Statistic: {res_ADF[0]}')\nprint(f'p-value: {res_ADF[1]}')\nprint(f'n_lags: {res_ADF[2]}')\nprint('Critial Values:')\nfor key, value in res_ADF[4].items():\n    \n    print(f'   {key}, {value}')  \nprint(f't_stat: {res_ADF[5]}')","02737aef":"res_ADF = adfuller(r.dropna().SP_log_r, regression='c')\nprint(f'ADF Statistic: {res_ADF[0]}')\nprint(f'p-value: {res_ADF[1]}')\nprint(f'n_lags: {res_ADF[2]}')\nprint('Critial Values:')\nfor key, value in res_ADF[4].items():\n    \n    print(f'   {key}, {value}')  \nprint(f't_stat: {res_ADF[5]}')","72015a41":"result = coint_johansen(r[['SP_close','Ch_close']],0,1)\nprint ('--------------------------------------------------')\nprint ('--> Trace Statistics')\nprint ('variable statistic Crit-90% Crit-95%  Crit-99%')\nfor i in range(len(result.lr1)):\n    print ('r =', i, '\\t', round(result.lr1[i], 4), result.cvt[i, 0], result.cvt[i, 1], result.cvt[i, 2])\nprint ('--------------------------------------------------')\nprint ('--> Eigen Statistics')\nprint ('variable statistic Crit-90% Crit-95%  Crit-99%')\nfor i in range(len(result.lr2)):\n    print ('r =', i, '\\t', round(result.lr2[i], 4), result.cvm[i, 0], result.cvm[i, 1], result.cvm[i, 2])\nprint ('--------------------------------------------------')\nprint ('eigenvectors:\\n', result.evec)\nprint ('--------------------------------------------------')\nprint ('eigenvalues:\\n', result.eig)\nprint ('--------------------------------------------------')","1816d66f":"coint(r.Ch_close,r.SP_close)","50b7cbaf":"r = add_constant(r)\nlr_model = OLS(r.SP_close, r[['const', 'Ch_close']])\nlr_model_fit = lr_model.fit(cov_type='HC0')\nprint(lr_model_fit.summary())","3bf9d23a":"# ADF test on the residuals\nfor i in ['nc', 'c', 'ct']:\n    result = adfuller(lr_model_fit.resid, regression = i)\n    print('ADF Statistic with %s for Closing my_stock_train price: %f' % (i, result[0]))\n    print('p-value: %f' % result[1])\n    print('')","64c82204":"# attaches the residuals to the training data set and shifts them down be one to get them alligned properly to be the\n# lagged residuals of the linear model in the ECM\nr['disequilibrium'] = lr_model_fit.resid\nr.disequilibrium = r.disequilibrium.shift(1)","97cb39cb":"train = r[:-1]\ntest  = r[-1:]","52169493":"train['Ch_close_d'], train['SP_close_d'] = train.Ch_close, train.SP_close\nfor i in ['Ch_close_d', 'SP_close_d', 'SP_close_l1', 'Ch_close_l1', 'SP_close_l2', 'Ch_close_l2', 'SP_close_l3','Ch_close_l3','SP_close_l4', 'Ch_close_l4', 'SP_close_l5',\n       'Ch_close_l5', 'SP_close_l6', 'Ch_close_l6','SP_close_l7', 'Ch_close_l7','SP_close_l8', 'Ch_close_l8']:\n    # difference column i\n    train[i] = train[i].diff()\n\npredictors = [ 'SP_close_l1', 'Ch_close_l1', 'SP_close_l2', 'Ch_close_l2', 'SP_close_l3','Ch_close_l3','SP_close_l4', 'Ch_close_l4', 'SP_close_l5',\n       'Ch_close_l5','SP_close_l6', 'Ch_close_l6','disequilibrium', 'const']\n\n\n# estimates a linear regression of the closing share price on the lagged closing market level\necm_train = OLS(train.dropna().SP_close_d, train.dropna()[predictors])\necm_train_fit = ecm_train.fit(cov_type='HC0')\n\n# prints a summary\nprint(ecm_train_fit.summary())","a3febcce":"predictors = ['disequilibrium',]\n\n# estimates a linear regression of the closing share price on the lagged closing market level\necm_train = OLS(train.dropna().SP_close_d, train.dropna()[predictors])\necm_train_fit = ecm_train.fit(cov_type='HC0')\n\n# prints a summary\nprint(ecm_train_fit.summary())","922adf80":"ecm_pred = ecm_train_fit.predict(test[predictors])\necm_pred = train.SP_close.iloc[-1]+ecm_pred.cumsum()\nmean_squared_error(test.SP_close, ecm_pred)","36030939":"grangercausalitytests(train.dropna()[['Ch_close_d','SP_close_d']],12)","029c630c":"model = VAR(train[['SP_log_r','Ch_log_r']].dropna())\nmodel_fit = model.select_order(maxlags=12)\nmodel_fit.summary()","675246e0":"var_1 = model.fit(1)\nvar_1.summary()","1d659f9f":"irf = var_1.irf(10)\nirf.plot(impulse='Ch_log_r')","22289ff9":"irf.plot_cum_effects(orth=False)","5eedd26b":"model = VAR(train[['SP_log_r','Ch_log_r']].dropna())\nvar_1 = model.fit(1)","45edf4f6":"# Get the lag order\nlag_order = var_1.k_ar\n\n# Input data for forecasting\nforecast_input = train[['Ch_log_r','SP_log_r']].values[-lag_order:]\n\nfc = var_1.forecast(y=forecast_input, steps=1)\ndf_forecast = pd.DataFrame(fc, index=r.index[-1:], columns=['Ch_log_r','SP_log_r'])\ndf_forecast.SP_log_r = train.SP_close.iloc[-1] + df_forecast.SP_log_r.apply(np.expm1).cumsum()\nmean_squared_error(test.SP_close, df_forecast.SP_log_r)","ffb3b90a":"ar = ARX(train.dropna().SP_log_r, x=train.dropna()[['Ch_log_l1',]], constant=False)#,'Ch_log_l2',lags=[1]\nar.fit().summary()","c5ea0ba7":"ar.volatility = GARCH(p=1, o=0, q=0, power=0.5)\nres = ar.fit(disp=\"off\")\nres.summary()","9b77f36a":"Evidence of Granger Causality China on SP at 7, 8 lags at 5% signicance level","3f4cee4f":"In the AR-X - Power ARCH (power: 0.9) Model specification lag 1 of China Futures log_return has significant and positive effect on subsequent log_return of S&P when accounted for lag 1 log_return of S&P and its volatility on weekly data.","48035986":"The Engel-Granger process is estimating the regression of the I(1) target variable on the I(1) independent variable. If the residuals are stationary, there is cointegration. The ADF tests indicate that variables are cointegrated in our sample period.","efa15e47":"https:\/\/arch.readthedocs.io\/en\/latest\/univariate\/generated\/arch.univariate.GARCH.html","da8ca138":"https:\/\/www.statsmodels.org\/stable\/generated\/statsmodels.tsa.stattools.coint.html","85c4b2c5":"## Adding Log-returns and 9 lags","944014b2":"Levels are non-stationary, therefore we can run cointegration test.","9744bdf9":"# Granger Causality in difference weekly data","36cb3e19":"# Aim: \n* To Assess the Hypothesis that Asian markets impacts the US market.\n\n## Importing Libries","645ed9f1":"## Volatility Modeling","953fd1f4":"## Loading and resampling data due to missing values","0a21e9f7":"# Cointegration","e390eecd":"p-value of 0.0004716329545500373 -> reject null hypothesis.\n\nThere is evedince for cointegration between SP and China Futures markets.","56078059":"$$ \\sigma_{t}^{\\lambda}=\\omega\n+ \\sum_{i=1}^{p}\\alpha_{i}\\left|\\epsilon_{t-i}\\right|^{\\lambda}\n+\\sum_{j=1}^{o}\\gamma_{j}\\left|\\epsilon_{t-j}\\right|^{\\lambda}\nI\\left[\\epsilon_{t-j}<0\\right]+\\sum_{k=1}^{q}\\beta_{k}\\sigma_{t-k}^{\\lambda} $$","f2366bc6":"Evidence for cointegration","e61e3a3a":"Log transformed returns are stationary","5b379a7a":"# Merging","ae441e9f":"https:\/\/www.statsmodels.org\/stable\/generated\/statsmodels.tsa.vector_ar.vecm.coint_johansen.html#statsmodels.tsa.vector_ar.vecm.coint_johansen","e02f30e4":"Cointegration is defined as a situation where linear combinations of nonstationary time series are stationary. This implies the existence of a long-run equilibrium between the variables. ","894d6a4a":"## VAR","b6185f2c":"### The model optimised for information criterions","03a24826":"# Augmented Dickey-Fuller unit root test","15800666":"\nThe error-correction term in the ECM must be negative. The lagged residuals from the linear regression represent the deviation from the long-run relationship in the previous period. The intuition is if price is above its long-run equilibrium with the market, the negative coefficient pulls it back down. If it is below the long-run equilibrium, the negatives will cancel out and become positive pulling price back up.\n\n* Reference: https:\/\/github.com\/jkclem\/ECM-in-python\/blob\/master\/ECMs.ipynb\n\nOur model trained on the sample period meets this requirement.\n"}}