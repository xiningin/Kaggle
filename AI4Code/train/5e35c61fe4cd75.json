{"cell_type":{"44b00e22":"code","bd0e79a4":"code","1b78cb03":"code","a58c507c":"code","3f0b546f":"code","e12359b5":"code","3b6e8a77":"code","c48cfe4a":"code","eb90f5a2":"code","12ee3c34":"code","3fc0519e":"markdown","1e98319b":"markdown","6f327388":"markdown","bae9e974":"markdown","1784344b":"markdown","bec7990f":"markdown","dc7e16b4":"markdown","7181890c":"markdown"},"source":{"44b00e22":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","bd0e79a4":"dataset= pd.read_csv(\"..\/input\/movie-metadatacsv\/movie_metadata.csv\")","1b78cb03":"dataset.head()","a58c507c":"from sklearn.impute import SimpleImputer \nX = dataset.iloc[:, 2:3].values \nimputer = SimpleImputer(missing_values=np.nan, strategy='mean') \nimputer = imputer.fit(X[:, :1])\nX[:, :1] = imputer.transform(X[:, :1])\nprint(X)","3f0b546f":"import matplotlib.pyplot as plt\ndataset.hist()\nplt.show()","e12359b5":"from sklearn.preprocessing import LabelEncoder\n\nprint(dataset.head())\nlabelEncoder = LabelEncoder()\nlabelEncoder.fit(dataset['movie_facebook_likes'])\nd = labelEncoder.transform(dataset['movie_facebook_likes'])\nprint(d)","3b6e8a77":"from sklearn.model_selection import train_test_split # used for splitting training and testing data\nX = dataset.iloc[:, :-1].values # attributes to determine dependent variable \/ Class\nY = dataset.iloc[:, -1].values\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\nprint(X_train, X_test, Y_train, Y_test)","c48cfe4a":"dataset.head()\n  \nx = dataset.iloc[:, 2:3].values\nprint (\"\\nOriginal data values : \\n\",  x)\n \nfrom sklearn import preprocessing\nmin_max_scaler = preprocessing.MinMaxScaler(feature_range =(0, 1))\nx_after_min_max_scaler = min_max_scaler.fit_transform(x)\nprint (\"\\nAfter min max Scaling : \\n\", x_after_min_max_scaler)\nStandardisation = preprocessing.StandardScaler()\nx_after_Standardisation = Standardisation.fit_transform(x)\nprint (\"\\nAfter Standardisation : \\n\", x_after_Standardisation)","eb90f5a2":"dataset.info()","12ee3c34":"dataset.drop(['color','director_name'],axis=1,inplace=True)\ndataset","3fc0519e":"# Use the necessary function for handling of categorical data if any\n","1e98319b":"# Show The Datasets","6f327388":"# Import Library","bae9e974":"# Perform data visualizations using matplotlib or seaborn libraries.","1784344b":"# Perform feature Scaling\n","bec7990f":"# Use the necessary function to handling the missing data","dc7e16b4":"# Splitting the dataset into training and testing datasets\n","7181890c":"# Load Datasets from Kaggel"}}