{"cell_type":{"fff1c89b":"code","1dd406b1":"code","ef974ead":"code","b90d1dec":"code","1d87b519":"code","393a68b5":"code","03d0b7da":"code","4643083b":"code","0a040151":"code","c49e6551":"code","8d48cb18":"code","af519ee0":"code","ed910bc6":"code","969d2987":"code","af45598b":"code","5a37fb5a":"code","d9daac83":"code","a2cac2e3":"code","30e725b4":"code","9a52b52d":"code","f74d6a01":"code","71fc2822":"code","97c7b8d9":"code","da315a80":"code","a84ad591":"code","e59e9197":"code","25f9da2d":"code","74c18e83":"code","316dfa99":"code","80b911fd":"code","4674ca86":"code","2cb4ac4e":"code","f6836948":"markdown","fa9e03e0":"markdown","9c1cabc4":"markdown","4e8474f4":"markdown","04823ebd":"markdown","34473853":"markdown","d5cdf205":"markdown","be6c8b9b":"markdown","acab5f69":"markdown","b1157e1b":"markdown","fe876f14":"markdown","1f0bdf0f":"markdown","58d652d6":"markdown","79673977":"markdown"},"source":{"fff1c89b":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nimport warnings\nwarnings.filterwarnings('ignore')","1dd406b1":"df = pd.read_csv('..\/input\/life-expectancy-who\/Life Expectancy Data.csv')\ndf.head()","ef974ead":"df.shape","b90d1dec":"# Statistical info\ndf.describe()","1d87b519":"# Datatypes of Attributes\ndf.info()","393a68b5":"#Fixing column names\ndf.rename(columns = {\" BMI \" :\"BMI\", \n                                  \"Life expectancy \": \"Life_expectancy\",\n                                  \"Adult Mortality\":\"Adult_mortality\",\n                                  \"infant deaths\":\"Infant_deaths\",\n                                  \"percentage expenditure\":\"Percentage_expenditure\",\n                                  \"Hepatitis B\":\"HepatitisB\",\n                                  \"Measles \":\"Measles\",\n                                  \"under-five deaths \": \"Under_five_deaths\",\n                                  \"Total expenditure\":\"Total_expenditure\",\n                                  \"Diphtheria \": \"Diphtheria\",\n                                  \" thinness  1-19 years\":\"Thinness_1-19_years\",\n                                  \" thinness 5-9 years\":\"Thinness_5-9_years\",\n                                  \" HIV\/AIDS\":\"HIV\/AIDS\",\n                                  \"Income composition of resources\":\"Income_composition_of_resources\"}, inplace = True)","03d0b7da":"# check for categorical attributes\ncat_col = []\nfor x in df.dtypes.index:\n    if df.dtypes[x] == 'object':\n        cat_col.append(x)\ncat_col","4643083b":"# Check the unique values in dataset\ndf.apply(lambda x: len(x.unique()))","0a040151":"y = df[\"Life_expectancy\"]\ndf1 = df.drop([\"Life_expectancy\"], axis=1)\n\ncategorical = df1.select_dtypes(include= \"O\")\nnumerical = df1.select_dtypes(exclude= \"O\")","c49e6551":"for feature in categorical.columns:\n    sns.countplot(categorical[feature], dodge=True)\n    plt.show()\n","8d48cb18":"for feature in numerical.columns:\n    sns.distplot(numerical[feature])\n    plt.xticks(fontsize= 12)\n    plt.yticks(fontsize=12)\n    plt.ylabel(\"Count\", fontsize= 13, fontweight=\"bold\")\n    plt.xlabel(feature, fontsize=13, fontweight=\"bold\")\n    plt.show()","af519ee0":"sns.distplot(y)\nplt.ylabel(\"Count\")\nplt.xlabel(\"Life Expectancy\")","ed910bc6":"sns.boxplot(x = df1[\"Status\"], y = y)\nplt.ylabel(\"Life Expectancy\")\nplt.xlabel(\"Status\")\nplt.show()","969d2987":"for feature in numerical.columns:\n    sns.scatterplot(x = numerical[feature], y = y, hue = categorical.Status)\n    plt.xticks(rotation=90)\n    plt.ylabel(\"Life Expectancy\")\n    plt.xlabel(feature)\n    plt.show()","af45598b":"life_numeric_data = df.drop(columns=[\"Year\",\"Country\",\"Status\"])","5a37fb5a":"def outlier_count(col, data = df):\n    \n    print(\"\\n\"+15*'-' + col + 15*'-'+\"\\n\")\n    \n    q75, q25 = np.percentile(data[col], [75, 25])\n    iqr = q75 - q25\n    min_val = q25 - (iqr*1.5)\n    max_val = q75 + (iqr*1.5)\n    outlier_count = len(np.where((data[col] > max_val) | (data[col] < min_val))[0])\n    outlier_percent = round(outlier_count\/len(data[col])*100, 2)\n    print('Number of outliers: {}'.format(outlier_count))\n    print('Percent of data that is outlier: {}%'.format(outlier_percent))","d9daac83":"cont_vars = list(life_numeric_data)\nfor col in cont_vars:\n    outlier_count(col)","a2cac2e3":"# To check the null values\ndef checkna(df):\n    missing_values = df.isna().sum().reset_index()\n    missing_values.columns = [\"Features\", \"Missing_Values\"]\n    missing_values[\"Missing_Percent\"]= round(missing_values.Missing_Values\/len(df)*100,2)\n    return missing_values[missing_values.Missing_Values > 0 ]","30e725b4":"checkna(df)","9a52b52d":"def imputer(df, feature, method):\n    if method == \"mode\":\n        df[feature] = df[feature].fillna(df[feature].mode()[0])\n        \n    elif method == \"median\":\n        df[feature] = df[feature].fillna(df[feature].median())\n        \n    else:\n        df[feature] = df[feature].fillna(df[feature].mean())","f74d6a01":"features_missing= df.columns[df.isna().any()]\nfor feature in features_missing:\n    imputer(df, feature= feature, method= \"mean\")","71fc2822":"y.fillna(y.median(), inplace=True)","97c7b8d9":"checkna(df)","da315a80":"plt.figure(figsize = (24,16))\nsns.heatmap(pd.concat([df,y], axis=1).corr(), annot=True, cmap=\"coolwarm\")","a84ad591":"from sklearn.preprocessing import LabelEncoder\ncolumns = [\"Status\"]\nfor feature in columns:\n    le = LabelEncoder()\n    df[feature] = le.fit_transform(df[feature])","e59e9197":"X = df.drop(['Country', 'Year', 'Infant_deaths', 'Life_expectancy'],1)","25f9da2d":"X.shape","74c18e83":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)","316dfa99":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","80b911fd":"# Function to apply Regression algorithms and return the results of models\n\n# libraries for ML Models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# libraries for model evaluation\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\ndef predictive_models():\n    algorithms = [SVR(), KNeighborsRegressor(), DecisionTreeRegressor(random_state = 0), \n                  RandomForestRegressor(n_estimators = 100, random_state = 0)]\n    \n    algorithm_names = [\"SVR\", \"KNeighbors Regressor\", \"Decision-Tree Regressor\", \"Random-Forest Regressor\"]\n    \n    # Errors for training data\n    Mean_Squared_Error_Training = []\n    Mean_Absolute_Error_Training = []\n    Accuracy_Training = []\n    \n    # Errors for testing data\n    Mean_Squared_Error_Testing = []\n    Mean_Absolute_Error_Testing = []\n    Accuracy_Testing = []\n    \n    # Regression models\n    for i in algorithms:\n        model = i\n        model.fit(X_train,y_train)\n    \n        y_test_predict = model.predict(X_test)\n        y_train_predict = model.predict(X_train)\n            \n        mse_1 = round(mean_squared_error(y_train, y_train_predict),4)\n        mae_1 = round(mean_absolute_error(y_train, y_train_predict),4)\n        \n        mse_2 = round(mean_squared_error(y_test, y_test_predict),4)\n        mae_2 = round(mean_absolute_error(y_test, y_test_predict),4)\n        \n        # Appending the Errors into the list for training data\n        Mean_Squared_Error_Training.append(mse_1)\n        Mean_Absolute_Error_Training.append(mae_1)\n                \n        # Appending the Errors into the list for training data\n        Mean_Squared_Error_Testing.append(mse_2)\n        Mean_Absolute_Error_Testing.append(mae_2)\n        \n    # Creating DataFrame for Logs of Models and their errors    \n    results = pd.DataFrame({\"Models\":algorithm_names,\n                            \"Mean Squared Error Training\":Mean_Squared_Error_Training,\n                            \"Mean Absolute Error Training\":Mean_Absolute_Error_Training,      \n                            \"Mean Squared Error Testing\":Mean_Squared_Error_Testing,\n                            \"Mean Absolute Error Testing\":Mean_Absolute_Error_Testing})\n\n    return results","4674ca86":"results = predictive_models()\nresults","2cb4ac4e":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {'bootstrap': [True], 'max_depth': [5, 10, None], 'max_features': ['auto', 'log2'],\n              'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15]}\nrfr = RandomForestRegressor(random_state = 1)\n\ngrid_search = GridSearchCV(estimator = rfr, param_grid = param_grid, \n                           cv = 5, n_jobs = -1, verbose = 0, return_train_score=True)\ngrid_search.fit(X_train, y_train);\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\nprint(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\nprint(\"Best Parameters:\", best_parameters)","f6836948":"### Feacture Scaling","fa9e03e0":"## Data Preprocessing","9c1cabc4":"##### Imputer\n\n* Univariate feature imputation.\n* The SimpleImputer class provides basic strategies for imputing missing values. Missing values can be imputed with a provided   constant value, or using the statistics (mean, median or most frequent) of each column in which the missing values are located.","4e8474f4":"* NO missing values found","04823ebd":"### Feature Engineering","34473853":"### Correlation Matrix","d5cdf205":"### Graphical EDA","be6c8b9b":"#### Dealing with the Outliers","acab5f69":"### Label Encoding","b1157e1b":"## Exporatory Data Analysis:","fe876f14":"### Importing the libraries","1f0bdf0f":" ### Splitting the dataset into the Training set and Test set","58d652d6":"### Importing the dataset","79673977":"# Life Expectancy"}}