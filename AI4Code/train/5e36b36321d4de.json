{"cell_type":{"f8aad5fe":"code","660a4434":"code","067bede1":"code","ea091a58":"code","4b919239":"code","bc606485":"code","028309c4":"code","0cd913bc":"code","5014de64":"code","1637253a":"code","e1b9bba9":"code","b3939ec3":"code","7ba8034c":"code","e4ceb758":"code","719ab800":"code","74bcf7df":"code","4f64955d":"code","0b97ea17":"code","4fbb6e4e":"code","de503cb4":"code","f6f778b1":"code","c406ec86":"markdown","0be8bbe2":"markdown","ae4ffc41":"markdown","505df67c":"markdown","f15bf5d3":"markdown","ea1e25fc":"markdown","688e59a3":"markdown","acc771e0":"markdown","89a93250":"markdown","316de120":"markdown","019b229b":"markdown"},"source":{"f8aad5fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport cv2\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","660a4434":"train_data = pd.read_csv('..\/input\/landmark-recognition-2020\/train.csv')\n\nprint(\"Training data size:\",train_data.shape)","067bede1":"test_list = glob.glob('..\/input\/landmark-recognition-2020\/test\/*\/*\/*\/*')\ntrain_list= glob.glob('..\/input\/landmark-recognition-2020\/train\/*\/*\/*\/*')","ea091a58":"print( 'Query', len(test_list), ' test images & ', len(train_list), 'train images')","4b919239":"train_data.info()","bc606485":"train_data.head()","028309c4":"sns.set()\nplt.title('Training set: number of images per class(line plot)')\nlandmarks_fold = pd.DataFrame(train_data['landmark_id'].value_counts())\nlandmarks_fold.reset_index(inplace=True)\nlandmarks_fold.columns = ['landmark_id','count']\nax = landmarks_fold['count'].plot(logy=True, grid=True)\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=30)\nax.set(xlabel=\"Landmarks\", ylabel=\"Number of images\")","0cd913bc":"sns.set()\nlandmarks_fold_sorted = pd.DataFrame(train_data['landmark_id'].value_counts())\nlandmarks_fold_sorted.reset_index(inplace=True)\nlandmarks_fold_sorted.columns = ['landmark_id','count']\nlandmarks_fold_sorted = landmarks_fold_sorted.sort_values('landmark_id')\nax = landmarks_fold_sorted.plot.scatter(\\\n     x='landmark_id',y='count',\n     title='Training set: number of images per class(statter plot)')\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=30)\nax.set(xlabel=\"Landmarks\", ylabel=\"Number of images\")","5014de64":"plt.figure(figsize = (8, 2))\nplt.title('Landmark id density plot')\nsns.kdeplot(train_data['landmark_id'], color=\"tomato\", shade=True)\nplt.show()","1637253a":"plt.rcParams[\"axes.grid\"] = True\nf, axarr = plt.subplots(6, 5, figsize=(24, 22))\n\ncurr_row = 0\nfor i in range(30):\n    example = cv2.imread(test_list[i])\n    example = example[:,:,::-1]\n    \n    col = i%6\n    axarr[col, curr_row].imshow(example)\n    if col == 5:\n        curr_row += 1","e1b9bba9":"plt.rcParams[\"axes.grid\"] = True\nf, axarr = plt.subplots(6, 5, figsize=(24, 22))\n\ncurr_row = 0\nfor i in range(30):\n    example = cv2.imread(train_list[i])\n    example = example[:,:,::-1]\n    \n    col = i%6\n    axarr[col, curr_row].imshow(example)\n    if col == 5:\n        curr_row += 1","b3939ec3":"plt.rcParams[\"axes.grid\"] = True\nf, axarr = plt.subplots(6, 5, figsize=(24, 22))\n\ncurr_row = 0\nfor i in range(30):\n    example = cv2.imread(train_list[i])\n    example = example[:,:,::-1]\n    \n    col = i%6\n    axarr[col, curr_row].imshow(example)\n    if col == 5:\n        curr_row += 1","7ba8034c":"train_data['landmark_id'].describe()","e4ceb758":"sns.set()\nprint(train_data.nunique())\ntrain_data['landmark_id'].value_counts().hist()","719ab800":"from scipy import stats\nsns.set()\nres = stats.probplot(train_data['landmark_id'], plot=plt)","74bcf7df":"temp = pd.DataFrame(train_data.landmark_id.value_counts().head(10))\ntemp.reset_index(inplace=True)\ntemp.columns = ['landmark_id', 'count']\ntemp","4f64955d":"sns.set()\n# plt.figure(figsize=(9, 8))\nplt.title('Most frequent landmarks')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"landmark_id\", y=\"count\", data=temp,\n            label=\"Count\")\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=45)\nplt.show()","0b97ea17":"temp = pd.DataFrame(train_data.landmark_id.value_counts().tail(10))\ntemp.reset_index(inplace=True)\ntemp.columns = ['landmark_id', 'count']\ntemp","4fbb6e4e":"sns.set()\n# plt.figure(figsize=(9, 8))\nplt.title('Least frequent landmarks')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"landmark_id\", y=\"count\", data=temp,\n            label=\"Count\")\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=45)\nplt.show()","de503cb4":"dataset_path = '..\/input\/google-image-recognition-tutorial'\nimg_building = cv2.imread(os.path.join(dataset_path, 'building_1.jpg'))\nimg_building = cv2.cvtColor(img_building, cv2.COLOR_BGR2RGB)  # Convert from cv's BRG default color order to RGB\n\norb = cv2.ORB_create()  # OpenCV 3 backward incompatibility: Do not create a detector with `cv2.ORB()`.\nkey_points, description = orb.detectAndCompute(img_building, None)\nimg_building_keypoints = cv2.drawKeypoints(img_building, \n                                           key_points, \n                                           img_building, \n                                           flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS) # Draw circles.\nplt.figure(figsize=(16, 16))\nplt.title('ORB Interest Points')\nplt.imshow(img_building_keypoints); plt.show()","f6f778b1":"def image_detect_and_compute(detector, img_name):\n    \"\"\"Detect and compute interest points and their descriptors.\"\"\"\n    img = cv2.imread(os.path.join(dataset_path, img_name))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    kp, des = detector.detectAndCompute(img, None)\n    return img, kp, des\n    \n\ndef draw_image_matches(detector, img1_name, img2_name, nmatches=50):\n    \"\"\"Draw ORB feature matches of the given two images.\"\"\"\n    img1, kp1, des1 = image_detect_and_compute(detector, img1_name)\n    img2, kp2, des2 = image_detect_and_compute(detector, img2_name)\n    \n    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n    matches = bf.match(des1, des2)\n    matches = sorted(matches, key = lambda x: x.distance) # Sort matches by distance.  Best come first.\n    \n    img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches[:nmatches], img2, flags=2) # Show top 50 matches\n    plt.figure(figsize=(16, 16))\n    plt.title(type(detector))\n    plt.imshow(img_matches); plt.show()\n    \n\norb = cv2.ORB_create()\ndraw_image_matches(orb, 'building_1.jpg', 'building_2.jpg')","c406ec86":"### Most frequent landmark ID","0be8bbe2":"# Train Images Display","ae4ffc41":"# Train data","505df67c":"# Feature Extraction","f15bf5d3":"![](https:\/\/www.usnews.com\/dims4\/USNEWS\/cf1a1c4\/2147483647\/resize\/1200x%3E\/quality\/85\/?url=http%3A%2F%2Fmedia.beam.usnews.com%2F9d%2F9b%2Fd8dc8f3747b9b147d5c0a7fa1888%2F2-angkor-wat-getty.jpg)\nAngkor: Siem Reap, Cambodia","ea1e25fc":"# Train Images Display","688e59a3":"### Least frequent landmark ID","acc771e0":"# Exploration of the Dataset","89a93250":"The found interest points\/features are circled in the image above. As we can see, some of these points are unique to this scene\/building like the points near the top of the two towers. However, others like the ones at the top of the tree may not be distinctive.","316de120":"# Test Images Display","019b229b":"REFERANCES: \n* https:\/\/www.kaggle.com\/seriousran\/google-landmark-retrieval-2020-eda\n* https:\/\/www.kaggle.com\/codename007\/a-very-extensive-landmark-exploratory-analysis\n* https:\/\/www.kaggle.com\/wesamelshamy\/image-feature-extraction-and-matching-for-newbies"}}