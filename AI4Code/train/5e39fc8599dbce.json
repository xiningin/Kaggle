{"cell_type":{"2b8e4293":"code","183cccfe":"code","e7d95bbe":"code","a160eb4f":"code","adee9b7b":"code","8bd44d8c":"code","5809ecc1":"code","87272b4a":"code","89132cd9":"code","de0f6dd2":"markdown","e46cba22":"markdown","4f60d3c2":"markdown","737232c4":"markdown","8e4f23bb":"markdown"},"source":{"2b8e4293":"!pip install git+https:\/\/github.com\/fastai\/fastai2 \n!pip install git+https:\/\/github.com\/fastai\/fastcore","183cccfe":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport fastai\nfrom fastai.vision.all import *\nfrom fastai.callback.fp16 import *","e7d95bbe":"images = Path('\/kaggle\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/')","a160eb4f":"data = ImageDataLoaders.from_folder(path=images, \n                                    train='TRAIN', \n                                    valid='TEST',\n                                    item_tfms=Resize(460),\n                                    batch_tfms=[*aug_transforms(size=224, min_scale=0.75), Normalize.from_stats(*imagenet_stats)],\n                                    seed=42,\n                                    bs=32)","adee9b7b":"data.train.show_batch()","8bd44d8c":"print(data.vocab)","5809ecc1":"learn = cnn_learner(data, resnet34, metrics=error_rate, pretrained=True, model_dir='\/tmp\/models')\nlearn.unfreeze()\nlearn.lr_find()","87272b4a":"learn = cnn_learner(data, resnet34, metrics=error_rate, pretrained=True, model_dir='\/tmp\/models').to_fp16()\nlearn.unfreeze()\nlearn.fit_one_cycle(5, lr_max = 1e-3)","89132cd9":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","de0f6dd2":"As shown in the confusion matrix, the model does a very good job of classifying the blood cells. However, there seems to be some confusion between MONOCYTE and NEUTROPHIL.\n\nAs I do more and more lessons from the fastbook and Aman Arora's study group, I will progressively apply those techniques to improve the performance of the model in the upcoming weeks. \n\nIn the meantime, if you have any suggestions (or) questions, please comment them below. I will try to answer everything with the best of my knowledge\n\nConsider upvoting if you liked the effort!","e46cba22":"**Learning Rate finder**\n\nThe learning rate finder is a handy tool that is provided by fast.ai to find the optimal learning rate for a given problem. \n\nThe idea here to start with a small learning rate, which we are sure that the model would handle. We use that for one mini-batch and find the corresponding loss. Then we increase the learning rate by a certain amount and find the corresponding loss and so on. This process is repeated until the loss starts getting worse\n\nFast.ai does all this for us with the function lr_find(). It computes the loss against a given learning rate, plots and displays them - which makes it easy to select an optimal learning rate\n","4f60d3c2":"**MIXED PRECISION TRAINING**\n\nModel training is a slow process and can generally take a lot of time especially when training large models with large datasets. \n\n(exerpt from fastbook) One technique that can speed things up a lot is mixed-precision training. This refers to using less-precise numbers (half-precision floating point, also called fp16) where possible during training. To enable this, use to_fp16() in the fast.ai learner function","737232c4":"# BLOOD CELL CLASSIFICATION - FAST.AI v2\n\n**Practise based on @aroraaman Weights and Biases study group**\n\nThis notebook is a practise on the concepts learned from the fastbook reading group by Aman Arora - until reading group 3\n\nUpdate - This notebook has now been updated to use concepts from fastbook chapter 5 including but not limited to:\n- Pre-sizing\n- Learning rate finder\n- Mixed precision training","8e4f23bb":"**PRE-SIZING**\n\nIn image data augemntation, the challenge is that, common transforms can create empty spots and corrupt the data - that is, rotating an image by 45 degrees fills creates empty corners in the augmented image. This will not help the model in anyway\n\nTo tackle this, presizing first transforms the images to a larger size (460) and then applies the transforms on the images. The resulting images are then resized to the target size (224) in one go. This reduces the data corruptions"}}