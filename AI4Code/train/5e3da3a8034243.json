{"cell_type":{"fb93be9a":"code","9865ec3f":"code","03c18549":"code","bcaae741":"code","d8d9af30":"code","ff52bed3":"code","0a5ebaa3":"code","cf77cd55":"code","14e9c5a9":"code","f46f8286":"code","73dd9074":"code","34cc8135":"code","e235dada":"code","dc3aae15":"code","f65a5f7a":"markdown","0c052795":"markdown"},"source":{"fb93be9a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport os\nfrom scipy import stats\nfrom pandas import read_csv  \n!pip install merf","9865ec3f":"ap = read_csv('..\/input\/global5221\/global_annual.csv')\nfrom sklearn.impute import SimpleImputer\n# Shuffle your dataset \nap = ap.sample(frac=1)\n\n# Define a size for your train set \ntrain_size = int(0.8* len(ap))\nap_pred = ap.filter (regex=\"pop|nig|trop|ele|wind|temp|ind|GH|road|coun\")\n\n","03c18549":"ap_pred.cc = pd.Categorical(ap_pred.country)\n \nap_pred['country2'] = ap_pred.cc.astype('category').codes.tolist()","bcaae741":"ap_pred= ap_pred.drop(\"country\",axis =1 )","d8d9af30":"\nlist(ap_pred.columns )","ff52bed3":"# Split dataset \nX_train = ap_pred [:train_size]\nX_test  = ap_pred [train_size:]\nY_train = ap.loc[:train_size, [\"value_mean\"]]\nY_test  = ap.loc[train_size:,[\"value_mean\"]]\n\nX_train, X_test, Y_train, Y_test = train_test_split(ap_pred, ap['value_mean'], test_size=0.2, random_state=42)\n ","0a5ebaa3":"from merf import MERF\nimport inspect\nfrom sklearn.ensemble import RandomForestRegressor\ninspect.signature(MERF)\nmerf = MERF(RandomForestRegressor(n_estimators = 1000), max_iterations = 100)\nZ_train = np.ones((len(X_train), 1))\n\nclusters_train = X_train['country2']\nclusters_test= X_test['country2']\nmy_imputer = SimpleImputer()\n\nX_train = my_imputer .fit_transform(X_train)  \nX_test  = my_imputer .fit_transform(X_test)  \nmerf.fit(X_train,  Z_train, clusters_train, Y_train)\n\n\n    ","cf77cd55":"Z_test = np.ones((len(X_test), 1))\ny_hat = merf.predict(X_test, Z_test, clusters_test)\ny_hat","14e9c5a9":"metrics.explained_variance_score(y_hat, Y_test)\n","f46f8286":"metrics.r2_score(y_hat, Y_test)","73dd9074":"from sklearn.ensemble import RandomForestRegressor\n# Instantiate model with 1000 decision trees\nrf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n# Train the model on training data\nrf.fit(X_train, Y_train)\ny_hatrf = rf.predict(X_test)","34cc8135":"metrics.r2_score(y_hatrf, Y_test)","e235dada":"xg_reg = xgb.XGBRegressor(objective = \"reg:squarederror\",booster = \"dart\", learning_rate = 0.007, max_depth =6 , n_estimators = 3000,gamma =5, alpha =2) \nxg_reg.fit(X_train ,Y_train) # predictor at the station and station measurements\ny_hatxgb = xg_reg.predict(X_test) # 1 degree tile\n ","dc3aae15":"metrics.r2_score(y_hatxgb, Y_test)","f65a5f7a":"# compare r and python\ny = ap[\"value_mean\"]\nxg_reg = xgb.XGBRegressor(objective = \"reg:squarederror\",booster = \"dart\", learning_rate = 0.3, max_depth =4 , n_estimators = 20,gamma =5, alpha =2) \nxg_reg.fit(ap_pred,y) # predictor at the station and station measurements\nxg_reg.predict(ap_pred) \na=xg_reg.predict(ap_pred)\nstats.describe(a)","0c052795":"# predict on raster: option1\nresult = []\nfor i in range(0,ap_pred.shape[1]):\n        mapdir = os.path.join(rasterdir, ap_pred.columns[i]) # make sure the name sequence match with the csv file \n        arr = np.array(gdal.Open(mapdir).ReadAsArray()   )\n        \n        result.append(arr)\nresult = np.array(result) \n# either index result or reshape it to 2d, with colums predictor name and rows pixel values, then use xg_reg.predict(matrix2d),   "}}