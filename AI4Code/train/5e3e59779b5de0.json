{"cell_type":{"95bec5c3":"code","fda9d629":"code","ed2cfbc5":"code","a2a5a0ee":"code","ae8b3bf5":"code","751f9f1b":"code","3e8d6c23":"code","99299af4":"code","32324645":"code","99046d4a":"code","4bbeb921":"code","716308da":"code","e1392db9":"code","f4e3aeb7":"code","4fad470f":"code","d5ba7c21":"code","a11b20e6":"code","2533d2ed":"code","bf40c8c5":"code","02f4d14e":"code","cf42badd":"code","5a881f83":"code","88c87ba7":"code","c89fca3a":"code","8691bcef":"code","ee3e0383":"code","f148fd58":"code","a643dacd":"code","ebcb21af":"code","7d79d988":"code","ba50770e":"code","79151c0e":"code","09b113b7":"code","2483a3d0":"code","9c299d24":"code","b673bfad":"code","9b3bbfb4":"code","1ba0935a":"code","08055bb3":"code","272f3598":"code","68eef800":"code","5b2862b6":"code","d2664a1d":"code","c4620e55":"code","58c36149":"code","1463ddb5":"code","81092877":"code","00380cc5":"code","1307dcc1":"code","45e0b9bb":"code","95e599e7":"code","4cd421b8":"code","b1aa1c34":"code","0626e943":"code","15acbc77":"code","66600473":"code","5c45463b":"code","94007162":"code","2eda1d53":"code","fe283e64":"code","80483107":"code","af257b44":"code","cecd830f":"code","b3d4d5cc":"code","f720aa4f":"code","dc566db7":"code","056d417e":"code","9e618045":"code","75237636":"code","71cb61db":"code","b28186f0":"code","3f864982":"code","d0326f7e":"code","27afd5d2":"code","74efac7f":"markdown","8c7c8064":"markdown","7028229b":"markdown","417d4719":"markdown","0636a61a":"markdown","c8bf74fc":"markdown","00524206":"markdown"},"source":{"95bec5c3":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns","fda9d629":"#create dataframe to read dataset\ndf=pd.read_csv('..\/input\/hr-dataset\/hr_employee_churn_data.csv')","ed2cfbc5":"#check the dataframe and its data\ndf.head()","a2a5a0ee":"#check dataframe structure like columns and its datatypes\ndf.info()","ae8b3bf5":"# check the num of rows and columns in dataframe\ndf.shape","751f9f1b":"df.describe()","3e8d6c23":"df['Work_accident'].unique()","99299af4":"df['promotion_last_5years'].unique()","32324645":"# check total employee range based on target column that left\nsns.countplot(x='left',data=df)\nplt.show()\n#Take-away: in the training set, less people left than didn't.it seems there is data imbalance..","99046d4a":"#feature 'salary'\nsns.countplot(x='salary', data=df)\n#take-away: low salaried employee count is high in given dataset as expected","4bbeb921":"#feature 'left' split over the feature 'salary'.\nsns.catplot(x='left', col='salary', kind='count', data=df);\n#Take-away: it seem low salaried employees have high churning rate","716308da":"#feature 'promotion_last_5years'\nsns.countplot(x='promotion_last_5years', data=df)\n#take-away: non promoted emp count is high","e1392db9":"#feature 'left' split over the feature 'promotion_last_5years'.\n#fig = plt.figure(figsize=(15,7))\nsns.catplot(x='left', col='promotion_last_5years', kind='count', data=df);\n#Take-away: it seems non promoted people left more","f4e3aeb7":"#feature 'Work_accident'\nsns.countplot(x='Work_accident', data=df)\n#take-away: have less people who made Work_accident","4fad470f":"#feature 'left' split over the feature 'Work_accident'.\n#fig = plt.figure(figsize=(15,7))\nsns.catplot(x='left', col='Work_accident', kind='count', data=df);\n#Take-away: it seems people left more who did not made accident...we can say it is less imp feature","d5ba7c21":"# satisfaction_level : plot a univariate distribution of observations\nsns.distplot(df['satisfaction_level'])\n#take-away: sl distributed from 0.1 to 1 where it has high count at 0.1","a11b20e6":"#box plot to show distributions with respect to categories\nsns.boxplot(x=\"left\", y= \"average_montly_hours\", data=df)\n#take-away: employee left who has high average_montly_hours value","2533d2ed":"# time_spend_company : plot a univariate distribution of observations\nsns.distplot(df['time_spend_company'])\n#take-away: time_spend_company distributed from 2 to 10 where it has high count at around 3 and low at 9","bf40c8c5":"#box plot to show distributions with respect to categories\nsns.boxplot(x=\"left\", y= \"time_spend_company\", data=df)\n#take-away: employee left who has high time_spend_company value...","02f4d14e":"## Checking for correlation\ncor_mat=df.corr()\nfig = plt.figure(figsize=(15,7))\nsns.heatmap(cor_mat,annot=True)","cf42badd":"## Checking for pairplot\nsns.pairplot(df)","5a881f83":"#create dataframe to read dataset\ndf1=pd.read_csv('..\/input\/hr-dataset\/hr_employee_churn_data.csv')","88c87ba7":"#check the dataframe and its data\ndf1.head()","c89fca3a":"# check the num of rows and columns in dataframe\ndf1.shape","8691bcef":"df1.info()","ee3e0383":"df2=df1.copy()","f148fd58":"df2.drop(['empid'],axis=1,inplace=True)","a643dacd":"df2.head()","ebcb21af":"#handle missing values\ndf2.isnull().sum()","7d79d988":"df2['satisfaction_level'].describe()","ba50770e":"df2['satisfaction_level'].fillna(df2['satisfaction_level'].mean(), inplace=True)","79151c0e":"df2.isnull().sum()","09b113b7":"#handle categorical features..salary using get dummies\ndf2['salary'].unique()","2483a3d0":"salary_dummies = pd.get_dummies(df2['salary'],drop_first=True)","9c299d24":"salary_dummies","b673bfad":"df2=pd.concat([df2,salary_dummies],axis=1)","9b3bbfb4":"df2.head()","1ba0935a":"#drop salary feature as we already applied lable endcoding tech\ndf2.drop(['salary'],axis=1,inplace=True)","08055bb3":"df2.head()","272f3598":"#split dataset into features and label\nX= df2.drop(labels='left',axis=1)\ny= df2['left']","68eef800":"#split dataset into train and test\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=0)","5b2862b6":"len(X_train)","d2664a1d":"len(X_test)","c4620e55":"# will try to use below two models that are RandomForestClassifier and XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV","58c36149":"#create param\nmodel_param = {\n    'RandomForestClassifier':{\n        'model':RandomForestClassifier(),\n        'param':{\n            'n_estimators': [10, 50, 100, 130], \n            'criterion': ['gini', 'entropy'],\n            'max_depth': range(2, 4, 1), \n            'max_features': ['auto', 'log2']\n        }\n    },\n    'XGBClassifier':{\n        'model':XGBClassifier(objective='binary:logistic'),\n        'param':{\n           'learning_rate': [0.5, 0.1, 0.01, 0.001],\n            'max_depth': [3, 5, 10, 20],\n            'n_estimators': [10, 50, 100, 200]\n        }\n    }\n}","1463ddb5":"scores =[]\nfor model_name, mp in model_param.items():\n    model_selection = GridSearchCV(estimator=mp['model'],param_grid=mp['param'],cv=5,return_train_score=False)\n    model_selection.fit(X,y)\n    scores.append({\n        'model': model_name,\n        'best_score': model_selection.best_score_,\n        'best_params': model_selection.best_params_\n    })","81092877":"scores","00380cc5":"#as per above results, xgboost gives best result and hence selecting same to model building...\nmodel_xgb = XGBClassifier(objective='binary:logistic',learning_rate=0.1,max_depth=20,n_estimators=200)","1307dcc1":"model_xgb.fit(X_train,y_train)","45e0b9bb":"model_xgb.score(X_test,y_test)","95e599e7":"X_test.head()","4cd421b8":"X_test[:1]","b1aa1c34":"model_xgb.predict(X_test[:1])","0626e943":"df1.loc[1670]","15acbc77":"#Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,model_xgb.predict(X_test))\ncm","66600473":"#plot the graph\nfrom matplotlib import pyplot as plt\nimport seaborn as sn\nsn.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('True Value')\nplt.show()","5c45463b":"dataset = pd.read_csv('..\/input\/hr-dataset\/hr_employee_churn_data.csv')\ndataset.head()","94007162":"X = dataset.iloc[:, 1:-1].values\ny = dataset.iloc[:, -1].values","2eda1d53":"print(X[0])","fe283e64":"print(y)","80483107":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nX[:, 7] = le.fit_transform(X[:, 7])","af257b44":"X[0]","cecd830f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","b3d4d5cc":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","f720aa4f":"import tensorflow as tf","dc566db7":"ann = tf.keras.models.Sequential()","056d417e":"ann.add(tf.keras.layers.Dense(units=6, activation='relu'))","9e618045":"ann.add(tf.keras.layers.Dense(units=6, activation='relu'))","75237636":"ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","71cb61db":"ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","b28186f0":"ann.fit(X_train, y_train, batch_size = 32, epochs = 100)","3f864982":"dataset.head()","d0326f7e":"y_pred = ann.predict(X_test)\ny_pred = (y_pred > 0.5)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","27afd5d2":"accuracy_score(y_test, y_pred)*100","74efac7f":"# **Step 2**","8c7c8064":"# **Using ANN**","7028229b":"# **Exploring the data**","417d4719":"#  **Model Building**","0636a61a":"# **Split Dataset into Training set and Test set**","c8bf74fc":"**Feature Engineering**","00524206":"# **Model Selection**"}}