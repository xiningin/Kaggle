{"cell_type":{"3a7387b9":"code","b3eb57ef":"code","a5855329":"code","f70b8b06":"code","ba0fd93c":"code","eb046e81":"code","39f2d434":"code","64a46338":"code","9efa14f1":"code","3b275798":"code","f6c8d474":"code","7419eea8":"code","26c3a00e":"code","ecfbf5fe":"code","9872abea":"code","f9509083":"code","2940a6ea":"code","c895677a":"code","dbaaed66":"code","5f970924":"code","020819f2":"code","50416775":"code","bd12e190":"code","75bb6dfb":"code","342e0cee":"code","526e33eb":"code","fa70d76d":"code","00cda46e":"code","db285121":"code","9e49a8f1":"code","98fe57ca":"code","79739266":"code","4e6be959":"code","52938e7b":"code","b3971a4e":"code","64abdf2d":"code","82fd10aa":"code","1044b0ac":"code","9dc853ee":"code","f17925fd":"code","6a170b66":"markdown","15f020bd":"markdown","fbc6b9d4":"markdown","fabf629d":"markdown","9823396c":"markdown","85756d8d":"markdown","6f3737fa":"markdown","393904c8":"markdown"},"source":{"3a7387b9":"#import common libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom scipy.stats import skew, skewtest, norm","b3eb57ef":"train =pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","a5855329":"train.head()","f70b8b06":"train.info()","ba0fd93c":"test.shape","eb046e81":"#Lets take a quick look at distribution of target variable-SalePrice\nfig,ax = plt.subplots(figsize=(8,5))\nsns.distplot(train['SalePrice'],fit=norm,ax=ax)","39f2d434":"print(\"Skew is: %f\" % train['SalePrice'].skew())","64a46338":"#log transform the target\ntrain['SalePrice'] = np.log1p(train['SalePrice'])\n","9efa14f1":"train['SaleCondition'].value_counts()","3b275798":"#Let's look at SalePrice vs living area\nplt.scatter(train['GrLivArea'],train['SalePrice'],color='blue')\nplt.ylabel('SalePrice')\nplt.xlabel('Living Area')","f6c8d474":"#let's remove outliers\ntrain = train[train['GrLivArea']<4500]","7419eea8":"#function to find average price by feature passed as input\ndef avgprice(grpby) :\n    avgprc = pd.DataFrame(train['SalePrice'].groupby(train[grpby]).agg('mean'))\n    return avgprc","26c3a00e":"#let's check average saleprice with respect to neighborhood\n#avgprice = pd.DataFrame(train['SalePrice'].groupby(train['Neighborhood']).agg('mean'))\n#type(avgprice)\nfig,ax = plt.subplots(figsize=(12,5))\nplt.setp(ax.get_xticklabels(), rotation=45)\nsns.barplot(x=avgprice('Neighborhood').index,y=avgprice('Neighborhood')['SalePrice'],ax=ax)\n\n","ecfbf5fe":"#Let's explore the saleprice of house with yearbuilt\n#avgprice_conf = pd.DataFrame(train['SalePrice'].groupby(train['LotConfig']).agg('mean'))\nsns.barplot(x=avgprice('LotConfig').index,y=avgprice('LotConfig')['SalePrice'])\n\n","9872abea":"#lets find the impact of building type on average saleprice\nsns.barplot(x=avgprice('BldgType').index,y=avgprice('BldgType')['SalePrice'])","f9509083":"#lets explore the relationship between zoning classification(MSZoning) and SalePrice\nsns.barplot(x=avgprice('MSZoning').index,y=avgprice('MSZoning')['SalePrice'])","2940a6ea":"sns.distplot(train['YearBuilt'])","c895677a":"combined = pd.concat((train.loc[:,'MSSubClass' :'SaleCondition'],test.loc[:,'MSSubClass' :'SaleCondition']))","dbaaed66":"#Pick the first one - LotFrontage\ncombined['LotFrontage'].value_counts()","5f970924":"plt.scatter(combined['LotFrontage'],combined['LotArea'])","020819f2":"fig,ax = plt.subplots(figsize=(12,8))\nsns.heatmap(combined.corr(),ax=ax)","50416775":"combined = pd.get_dummies(combined)\ncombined = combined.fillna(combined.mean())","bd12e190":"X_train = combined[:train.shape[0]]\nX_test = combined[train.shape[0]:]\ny_train=train['SalePrice']","75bb6dfb":"X_train.head()","342e0cee":"from sklearn.linear_model import LinearRegression,Lasso,Ridge,SGDRegressor,ElasticNet\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import KFold,cross_val_predict,cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nimport xgboost as xgb\nimport lightgbm as lgb\n","526e33eb":"n_folds = 5\ndef rmse_cv(model):\n    #kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train.values)\n    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 10))\n    return(rmse)","fa70d76d":"#linear regression\nlr =LinearRegression()\n# scores = cross_val_score(lr, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n# rmse_scores = np.sqrt(-scores)\nprint(rmse_cv(lr).mean())","00cda46e":"#Ridge regression\nrr = Ridge(alpha=0.2,normalize=True)\n# rr.fit(X_train,y_train)\n# scores = cross_val_score(rr, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n# rmse_scores = np.sqrt(-scores)\nprint(rmse_cv(rr).mean())","db285121":"#Lasso regression\nlsr = Lasso(alpha=0.001)\n# lsr.fit(X_train,y_train)\n# scores = cross_val_score(lsr, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n# rmse_scores = np.sqrt(-scores)\nprint(rmse_cv(lsr).mean())\n","9e49a8f1":"# Seperate out numeric and categorical feature standard scaling\ncols = train.loc[:,'MSSubClass' :'SaleCondition'].columns\ncols_scale = []\n# def str_column_to_float(dataset, column):\n#        for row in dataset:\n#           if (row[column] = float(row[column].strip())\nfor col in cols :\n    if train[col].dtypes != 'O' :\n        cols_scale.append(col)\n\ncols_noscale = list(set(X_train.columns).symmetric_difference(set(cols_scale)))\n#X_train['SaleType_New'].unique()\n#type([0,1])\n#train['PoolQC'].dtypes\n","98fe57ca":"#SGD regression\nsgd = SGDRegressor(random_state=0,max_iter=300,alpha=0.02,penalty='elasticnet',l1_ratio=0.1,\n                   power_t=0.4)\n#X_train1 = pd.DataFrame(StandardScaler().fit_transform(X_train),columns=list(X_train.columns))\nX_train1 = pd.DataFrame(StandardScaler().fit_transform(X_train[cols_scale]),columns=cols_scale)\nX_train2 = pd.concat([X_train1.reset_index(drop=True),X_train[cols_noscale].reset_index(drop=True)],axis=1)\n\n#y_train1 = StandardScaler().fit_transform(y_train)\nsgd.fit(X_train1,y_train)\nscores = cross_val_score(sgd,X_train1,y_train,scoring='neg_mean_squared_error',cv=10)\nrmse_scores = np.sqrt(-scores)\nprint(rmse_scores.mean())","79739266":"#GradientBoosting Regressor\ngdb = GradientBoostingRegressor(n_estimators=400,max_features='sqrt',alpha=0.9)\n# gdb.fit(X_train,y_train)\n# scores = cross_val_score(gdb, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n# rmse_scores = np.sqrt(-scores)\nprint(rmse_cv(gdb).mean())\n","4e6be959":"#RandomForest regressor\nrfr = RandomForestRegressor(n_estimators=100)\n# rfr.fit(X_train,y_train)\n# scores = cross_val_score(rfr, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n# rmse_scores = np.sqrt(-scores)\nprint(rmse_cv(rfr).mean())","52938e7b":"#ElasticNet Regressor\nelnr = ElasticNet(alpha=0.001,l1_ratio=0.3,max_iter=3000)\n# elnr.fit(X_train,y_train)\n# scores = cross_val_score(elnr, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n# rmse_scores=np.sqrt(-scores)\nprint(rmse_cv(elnr).mean())","b3971a4e":"#Kernel-ridge\nkrr = KernelRidge(alpha=0.6,degree=2,kernel='polynomial',coef0=2.7)\nkrr.fit(X_train1,y_train)\nscores = cross_val_score(krr, X_train1, y_train, scoring=\"neg_mean_squared_error\", cv=10)\nrmse_scores=np.sqrt(-scores)\nprint(rmse_scores.mean())\n","64abdf2d":"#Xgb regressor\nxgbr = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\n# xgbr.fit(X_train,y_train)\n# scores = cross_val_score(xgbr, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n# rmse_scores=np.sqrt(-scores)\nprint(rmse_cv(xgbr).mean())","82fd10aa":"#lightgbm regressor\nlgbr = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=700,\n                              max_bin = 55, bagging_fraction = 0.4,\n                              bagging_freq = 5, feature_fraction = 0.23,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n# lgbr.fit(X_train,y_train)\n# scores = cross_val_score(lgbr, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n# rmse_scores=np.sqrt(-scores)\nprint(rmse_cv(lgbr).mean())","1044b0ac":"#function to take average of lasso, LightGBM ,XGB and ElasticNet\ndef averaging_model(model1,model2,model3,model4):\n    model1.fit(X_train,y_train)\n    model2.fit(X_train,y_train)\n    model3.fit(X_train,y_train)\n    model4.fit(X_train,y_train)\n    pred1 = model1.predict(X_test)\n    pred2 = model2.predict(X_test)\n    pred3 = model3.predict(X_test)\n    pred4 = model4.predict(X_test)\n    prediction = pd.DataFrame()\n    prediction['pred1'] = pred1\n    prediction['pred2'] = pred2\n    prediction['pred3'] = pred3\n    prediction['pred4'] = pred4\n    prediction = np.mean(prediction,axis=1)\n    return prediction","9dc853ee":"pred = averaging_model(lsr,lgbr,xgbr,elnr)\n","f17925fd":"test['SalePrice'] =np.expm1(pred) #convert back from log to normal SalePrice\noutput = test[['Id','SalePrice']]\noutput.to_csv('output.csv',index=False)","6a170b66":"Above plot shows that house prices in Northridge, Northridge Heights & Stone Brook area are\ncomparitively higher than other areas.","15f020bd":"SalePrice of building type 1Family detached and Townhouse Inside unit is higher than others.","fbc6b9d4":"We can see from above plot that some outliers are present as for some large living area, \nthe price is very low.","fabf629d":"It is evident from above figure that skew is present in SalePrice.","9823396c":"Here we can see that number of houses built started increasing from around 1950 till 2005-06 and \nafter that it started decreasing sharply after 2008 probably due to worldwide economic crisis.","85756d8d":"## Handle Missing Values","6f3737fa":"The average SalePrice of houses with lotconfig Cul-De-Sac(closed end street) and \nFR3(3 side road facing) are significantly higher than others.","393904c8":"We can see that low density residential areas and floating village residential areas have higher\naverage saleprice as compared to other zoning classifications."}}