{"cell_type":{"2451b6df":"code","8cdc3d2e":"code","b4bd3a73":"code","1dda1d44":"code","86a48ea1":"code","0d7622d0":"code","45ffc87e":"code","195c3643":"code","fb4a4d6b":"code","98739bc2":"code","ad103c5e":"code","e4e2b94e":"code","e7198fe8":"code","e51b876e":"code","fde57282":"code","402996d4":"code","c31143b4":"code","a8407ef1":"code","32c292d2":"code","2ddb73b7":"code","69cd0c24":"code","4cf3972b":"code","a8dda2db":"code","ce44e72c":"code","04629018":"code","c5b9630d":"code","9fab08e9":"code","86a78224":"code","be76e4e6":"code","7e510bbe":"code","63df9fbd":"code","34006e4b":"code","fd11fec0":"code","67737904":"code","18d8d6ca":"code","897ae00c":"code","b4b696f2":"code","f55ccd18":"code","4f4228ea":"code","4d1c6eea":"code","19bbe299":"code","b34fcc7d":"code","5fb4d9df":"code","77587c82":"code","b4f82202":"code","5d476794":"code","0f31ba8f":"code","2c8a3c7a":"code","01d34d46":"markdown","da65837d":"markdown","bc0648c3":"markdown","e92a607c":"markdown","5a816dc0":"markdown","1bf2c3cc":"markdown","dd637179":"markdown","6a8dcb87":"markdown","137f6a0e":"markdown","613a6b32":"markdown","b5c32c9b":"markdown","3d50fd13":"markdown","cb212a97":"markdown","c6d898e6":"markdown","32b3dffe":"markdown","11e7ee2a":"markdown","5ff4ebf8":"markdown","e68b062d":"markdown","e19ea9e7":"markdown","b8c5458b":"markdown","0d52bb43":"markdown"},"source":{"2451b6df":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8cdc3d2e":"data = pd.read_csv(\"\/kaggle\/input\/mall-customers\/Mall_Customers.csv\")\ndata","b4bd3a73":"data_copy = data.copy()","1dda1d44":"import matplotlib.pyplot as plt\nimport seaborn as sns","86a48ea1":"sns.distplot(data['Age'])","0d7622d0":"sns.distplot(data['Spending Score (1-100)'])","45ffc87e":"temp = data.groupby('Genre')['Spending Score (1-100)'].agg(['mean', 'min', 'max'])\ntemp = pd.DataFrame(temp)\ntemp","195c3643":"temp = data.groupby('Age')['Spending Score (1-100)'].agg(['mean', 'min', 'max', 'median'])\ntemp = pd.DataFrame(temp)\ntemp","fb4a4d6b":"data.isnull().sum()","98739bc2":"data.drop('CustomerID', axis=1, inplace=True)","ad103c5e":"from sklearn.preprocessing import KBinsDiscretizer","e4e2b94e":"age_binner = KBinsDiscretizer(n_bins=5, encode='ordinal')\nincome_binner = KBinsDiscretizer(n_bins=5, encode='ordinal')\nscore_binner = KBinsDiscretizer(n_bins=5, encode='ordinal')","e7198fe8":"data['Age_Group'] = age_binner.fit_transform(data['Age'].values.reshape(-1,1)).astype('int64')\ndata['Income_binned'] = income_binner.fit_transform(data['Annual Income (k$)'].values.reshape(-1,1)).astype('int64')\ndata['Spending_Score_Binned'] = score_binner.fit_transform(data['Spending Score (1-100)'].values.reshape(-1,1)).astype('int64')","e51b876e":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\ndata['Genre'] = le.fit_transform(data['Genre'])","fde57282":"X, y = data.drop('Spending Score (1-100)', axis=1), data['Spending Score (1-100)']","402996d4":"from sklearn.preprocessing import RobustScaler, MinMaxScaler","c31143b4":"robust = RobustScaler()\nminmax = MinMaxScaler()\n\nfor col in X.columns:\n  X[col] = robust.fit_transform(X[col].values.reshape(-1,1))\n  X[col] = minmax.fit_transform(X[col].values.reshape(-1,1))","a8407ef1":"y = robust.fit_transform(y.values.reshape(-1,1))\ny = minmax.fit_transform(y.reshape(-1,1))","32c292d2":"from sklearn.model_selection import train_test_split","2ddb73b7":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=56)","69cd0c24":"x_train_, x_val, y_train_, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=56)","4cf3972b":"from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\nfrom sklearn.linear_model import SGDRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR","a8dda2db":"from sklearn.metrics import mean_squared_error, r2_score","ce44e72c":"def model_selection(x_train_, x_val, y_train_, y_val, model):\n  model = model()\n  model.fit(x_train_, y_train_)\n\n  pred = model.predict(x_val)\n\n  acc = r2_score(y_val, pred)\n  error = np.sqrt(mean_squared_error(y_val, pred))\n  train_score = model.score(x_train_, y_train_)\n  val_score = model.score(x_val, y_val)\n\n  print('Acc :', acc*100)\n  print('\\n')\n  print('Error:', error)\n  print('\\n')\n  print('Train Score:', train_score*100)\n  print('\\n')\n  print('Val Score:', val_score*100)\n  print('\\n')\n  print('Is overfitting:', True if train_score>val_score else False)\n  print('\\n')\n  print('Overfitting by:',train_score*100-val_score*100)","04629018":"extratrees = model_selection(x_train_, x_val, y_train_, y_val, ExtraTreesRegressor)\nextratrees","c5b9630d":"gradient = model_selection(x_train_, x_val, y_train_, y_val, GradientBoostingRegressor)\ngradient","9fab08e9":"forest = model_selection(x_train_, x_val, y_train_, y_val, RandomForestRegressor)\nforest","86a78224":"ada = model_selection(x_train_, x_val, y_train_, y_val, AdaBoostRegressor)\nada","be76e4e6":"xgb = model_selection(x_train_, x_val, y_train_, y_val, XGBRegressor)\nxgb","7e510bbe":"tree = model_selection(x_train_, x_val, y_train_, y_val, DecisionTreeRegressor)\ntree","63df9fbd":"extratree = model_selection(x_train_, x_val, y_train_, y_val, ExtraTreeRegressor)\nextratree","34006e4b":"catboost = model_selection(x_train_, x_val, y_train_, y_val, CatBoostRegressor)\ncatboost","fd11fec0":"sgd = model_selection(x_train_, x_val, y_train_, y_val, SGDRegressor)\nsgd","67737904":"neighbour = model_selection(x_train_, x_val, y_train_, y_val, KNeighborsRegressor)\nneighbour","18d8d6ca":"svr = model_selection(x_train_, x_val, y_train_, y_val, SVR)\nsvr","897ae00c":"model = RandomForestRegressor()\nmodel.fit(x_train, y_train)","b4b696f2":"pred = model.predict(x_test)\npred","f55ccd18":"accuracy = r2_score(y_test, pred)\naccuracy*100","4f4228ea":"error = np.sqrt(mean_squared_error(y_test, pred))\nerror","4d1c6eea":"from sklearn.metrics import mean_squared_log_error","19bbe299":"error_log = np.sqrt(mean_squared_log_error(y_test, pred))\nerror_log","b34fcc7d":"overfitting_rate = model.score(x_train, y_train)*100 - model.score(x_test, y_test)*100\noverfitting_rate","5fb4d9df":"X.iloc[98:99]","77587c82":"pred_ = model.predict(X.iloc[98:99])\nprint('Original values:', y[98], 'Predicted value:', pred_)","b4f82202":"X.iloc[199:200]","5d476794":"pred_ = model.predict(X.iloc[199:200])\nprint('Original values:', y[199], 'Predicted value:', pred_)","0f31ba8f":"model.predict([[0.0, 0.3269, 0.03, 0.5, 0.0, 4.0]])","2c8a3c7a":"pred = minmax.inverse_transform(np.array(0.97122449).reshape(1, -1))\npred_ = robust.inverse_transform(pred.reshape(1, -1))\npred_","01d34d46":"**scaling the data**","da65837d":"1. **Feature binning**","bc0648c3":"**creating new features**","e92a607c":"**null values?**","5a816dc0":"# Saving a copy of the datasets","1bf2c3cc":"# Predictions","dd637179":"random value","6a8dcb87":"# Metric check","137f6a0e":"**encoding categorical data to numeric data**","613a6b32":"people between the age of 20-40(estimated from data) spend more money","b5c32c9b":"# Data Processing","3d50fd13":"# Splitting data","cb212a97":"# Splitting training data","c6d898e6":"# EDA","32b3dffe":"# Model Selection","11e7ee2a":"as we can see female spend more money than male","5ff4ebf8":"dropping id column","e68b062d":"I will choose RandomForestRegressor","e19ea9e7":"# Loading the datsets","b8c5458b":"# Predicting with random cols","0d52bb43":"# Model Building and Training"}}