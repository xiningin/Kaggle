{"cell_type":{"55368971":"code","19ecb48d":"code","ebea9a6e":"code","2977e98e":"code","6f6f1e22":"code","2f696233":"code","0377705d":"code","6f4c04f0":"code","9b5d8637":"code","54ba49d4":"code","13d5fac6":"code","2e59db4c":"code","4240ec20":"code","93595a73":"code","0063f29a":"code","62c506d0":"code","ebb1606c":"code","6a7ea2b0":"code","1632c8e1":"code","7907e3ed":"code","4397bc6d":"code","3eb60ded":"code","ab6c1c60":"code","7d675e1a":"code","ccd599ef":"code","326f77e2":"code","53b6c7b1":"code","0157bf6a":"code","50df5981":"code","348662a6":"code","b14d7fc9":"code","dfa47b83":"code","9804b0e2":"code","43d2b2af":"code","c1ad9dc0":"code","af313066":"code","ba873c01":"code","24565a04":"markdown"},"source":{"55368971":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport shap\nimport matplotlib.pyplot as plt\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import cross_validate, train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom itertools import repeat, chain\nrevert_dict = lambda d: dict(chain(*[zip(val, repeat(key)) for key, val in d.items()]))\n        \n%matplotlib inline\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","19ecb48d":"def grouped_shap(shap_vals, features, groups):\n    groupmap = revert_dict(groups)\n    shap_Tdf = pd.DataFrame(shap_vals, columns=pd.Index(features, name='features')).T\n    shap_Tdf['group'] = shap_Tdf.reset_index().features.map(groupmap).values\n    shap_grouped = shap_Tdf.groupby('group').sum().T\n    return shap_grouped","ebea9a6e":"data=pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\nplt.figure(figsize=(10,4))\ndata.Date.value_counts(True).sort_index().cumsum().plot();","2977e98e":"features = data.drop(['Date', 'RainTomorrow'], axis=1).columns.tolist()\ncat_features = data[features].select_dtypes('object').columns.tolist()\ndata['target'] = (data['RainTomorrow']=='Yes').astype(int)\n\ntrain = data.query(\"Date < '2015-01-01'\").dropna(subset=['RainTomorrow'])\ntest  = data.query(\"Date > '2015-01-01'\").dropna(subset=['RainTomorrow'])\n\nclf = CatBoostClassifier(iterations=30)\nclf.fit(train[features].fillna(-99), train['target'], cat_features=cat_features, verbose=False)\n\ntrain_auc = roc_auc_score(train['target'], clf.predict_proba(train[features].fillna(-99))[:,1])\ntest_auc  = roc_auc_score(test['target'],  clf.predict_proba(test[features].fillna(-99))[:,1] )\nprint(\"Train AUC: \", train_auc)\nprint(\"Out-of-time AUC: \", test_auc)","6f6f1e22":"from shap import TreeExplainer\nexp = TreeExplainer(clf)\n\nshap_vals = exp.shap_values(test[features].fillna(-99))\nshap_df = pd.DataFrame(shap_vals, columns=pd.Index(features, name='features'))\nshap.summary_plot(shap_vals, test[features])","2f696233":"shap_vals = exp.shap_values(train[features].fillna(-99))\nshap_df = pd.DataFrame(shap_vals, columns=pd.Index(features, name='features'))\nshap.summary_plot(shap_vals, train[features])","0377705d":"\ngroups_by_time = {\n    '3pm': [f for f in features if '3pm' in f],\n    '9am': [f for f in features if '9am' in f],\n    'not_time_based': [f for f in features if '9am' not in f and '3pm' not in f]\n}\n\ngroups_by_type = {\n    'humidity_and_rain': ['Rainfall',\n                          'Evaporation',\n                          'Humidity9am',\n                          'Humidity3pm',\n                          'RainToday'],\n    'temperature': ['MinTemp',\n                    'MaxTemp',\n                    'Temp9am',\n                    'Temp3pm'],\n    'sun_and_clouds': ['Cloud9am',\n                       'Cloud3pm',\n                       'Sunshine'],\n    'wind_and_pressure': ['WindGustDir',\n                          'WindGustSpeed',\n                          'WindDir9am',\n                          'WindDir3pm',\n                          'WindSpeed9am',\n                          'WindSpeed3pm',\n                          'Pressure9am',\n                          'Pressure3pm'],\n    'location': ['Location']\n}\n\n\nmaptime = revert_dict(groups_by_time)\nmaptype = revert_dict(groups_by_type)","6f4c04f0":"shap_time = grouped_shap(shap_vals, features, groups_by_time)\nshap_type = grouped_shap(shap_vals, features, groups_by_type)","9b5d8637":"shap.summary_plot(shap_time.values, features=shap_time.columns)","54ba49d4":"shap.summary_plot(shap_type.values, features=shap_type.columns)","13d5fac6":"preds = pd.Series(clf.predict_proba(train[features].fillna(-99))[:,1])","2e59db4c":"quintiles = pd.qcut(preds, np.linspace(0,1,6), labels=np.arange(5))","4240ec20":"fig, ax = plt.subplots(1,5, figsize=(36, 7))\nfor q in range(5):\n    plt.sca(ax[q])\n    shap.summary_plot(shap_vals[(quintiles==q).values], \n                      train.loc[(quintiles==q).values, features], \n                      show=False, \n                      plot_size=None, \n                      color_bar=False,\n                      max_display=6)","93595a73":"fig, ax = plt.subplots(1,5, figsize=(36, 6))\nfor q in range(5):\n    plt.sca(ax[q])\n    shap.summary_plot(shap_vals[(quintiles==q).values], \n                      train.loc[(quintiles==q).values, features], \n                      show=False, \n                      plot_size=None, \n                      color_bar=False,\n                      max_display=6)\n    plt.title(f\"Quintile {q} of predictions\")","0063f29a":"biens = np.arange(3)*2+2009\nyear = train.Date.apply(lambda s: s.split('-')[0]).astype(int)\nfig, ax = plt.subplots(1,3, figsize=(36, 10))\nfor i, b in enumerate(biens):\n    plt.sca(ax[i])\n    idx = (year==b).values\n    shap.summary_plot(shap_vals[idx], \n                      train.loc[idx, features], \n                      show=False, \n                      plot_size=None, \n                      color_bar=False)\n    plt.title(f\"Year {b}\")","62c506d0":"train.MaxTemp.plot.hist(bins=100)","ebb1606c":"train.Humidity3pm.plot.hist(bins=100)","6a7ea2b0":"rained_flag = (train.MinTemp > 25).values\nrained_shap = shap_df[rained_flag]\nrained_feats = train.loc[rained_flag, features]\n\nshap.summary_plot(rained_shap.values, rained_feats, show=False)\nplt.title(\"Shap for hot days (minTemp > 25 Celsius) \")","1632c8e1":"rained_flag = (train.MaxTemp < 10).values\nrained_shap = shap_df[rained_flag]\nrained_feats = train.loc[rained_flag, features]\n\nshap.summary_plot(rained_shap.values, rained_feats, show=False)\nplt.title(\"Shap for cold days (maxTemp < 10 Celsius)\")","7907e3ed":"plt.figure(figsize=(9,9))\nfeat_order = shap_df.abs().mean().sort_values().index.drop(\"WindGustDir\").tolist()[::-1]\nsns.heatmap(shap_df.corr().abs().loc[feat_order, feat_order], cbar=False)","4397bc6d":"import seaborn as sns\nsns.clustermap(shap_df.drop(\"WindGustDir\", axis=1).corr().abs())","3eb60ded":"import warnings\ncas = pd.read_csv(\"\/kaggle\/input\/dft-accident-data\/Casualties0515.csv\",  delimiter=',', error_bad_lines=False, warn_bad_lines=False)\nveh = pd.read_csv(\"\/kaggle\/input\/dft-accident-data\/Vehicles0515.csv\",  delimiter=',', error_bad_lines=False, warn_bad_lines=False)\nacc = pd.read_csv(\"\/kaggle\/input\/dft-accident-data\/Accidents0515.csv\", delimiter=',', error_bad_lines=False, warn_bad_lines=False)\ncas['Accident_Index'] = cas['Accident_Index'].astype(str)+'g'\nveh['Accident_Index'] = veh['Accident_Index'].astype(str)+'g'\nacc['Accident_Index'] = acc['Accident_Index'].astype(str)+'g'\ncas = cas.set_index('Accident_Index')\nveh = veh.set_index('Accident_Index')\nacc = acc.set_index('Accident_Index')","ab6c1c60":"joined = (\nacc\n.join(cas, on=[\"Accident_Index\"], how='inner', rsuffix='cas')\n.join(veh, on=[\"Accident_Index\"], how='inner', rsuffix='veh'))","7d675e1a":"obj_cols = joined.select_dtypes('object').columns.tolist()\nfeatures = joined.columns.drop(['Vehicle_Referenceveh', 'Casualty_Severity', 'Accident_Severity']+obj_cols).tolist()\nfeatures =[f for f in features if f!= 'target']\njoined['target'] = (joined.Casualty_Severity<3).astype(int)\njoined['Date'] = pd.to_datetime(joined.Date)","ccd599ef":"groups = {\n    'geografical': [ \n        'Location_Easting_OSGR',\n        'Location_Northing_OSGR',\n        'Longitude',\n        'Latitude',\n        'Junction_Location',\n        'Urban_or_Rural_Area'],\n    \n    'road_specs': [\n        '1st_Road_Class',\n        '1st_Road_Number',\n        'Junction_Detail',\n        'Junction_Control',\n        '2nd_Road_Class',\n        '2nd_Road_Number',\n        'Road_Type',\n        'Speed_limit',\n        'Police_Force',\n        'Local_Authority_(District)'],\n    \n    'accident': [   \n        'Number_of_Vehicles',\n        'Number_of_Casualties',\n        'Pedestrian_Crossing-Human_Control',\n        'Pedestrian_Crossing-Physical_Facilities',\n        'Towing_and_Articulation',\n        'Vehicle_Manoeuvre',\n        'Vehicle_Location-Restricted_Lane',\n        'Skidding_and_Overturning',\n        'Hit_Object_in_Carriageway',\n        'Vehicle_Leaving_Carriageway',\n        'Hit_Object_off_Carriageway',\n        '1st_Point_of_Impact',\n        'Carriageway_Hazards',\n        'Casualty_Reference',\n        'Casualty_Type',\n        'Did_Police_Officer_Attend_Scene_of_Accident'],\n    \n    'conditions': [\n         'Light_Conditions',\n         'Weather_Conditions',\n         'Road_Surface_Conditions',\n         'Special_Conditions_at_Site',\n         'Day_of_Week'],\n    \n    'victim_specs': [\n         'Casualty_Class',\n         'Sex_of_Casualty',\n         'Age_of_Casualty',\n         'Age_Band_of_Casualty',\n         'Pedestrian_Location',\n         'Pedestrian_Movement',\n         'Car_Passenger',\n         'Bus_or_Coach_Passenger',\n         'Pedestrian_Road_Maintenance_Worker',\n         'Casualty_Home_Area_Type'],\n    \n    'driver_specs': [\n        'Journey_Purpose_of_Driver',\n        'Sex_of_Driver',\n        'Age_of_Driver',\n        'Age_Band_of_Driver',\n        'Driver_IMD_Decile',\n        'Driver_Home_Area_Type'],\n    \n    'vehicle_specs': [ \n        'Vehicle_Type',\n        'Was_Vehicle_Left_Hand_Drive?',\n        'Engine_Capacity_(CC)',\n        'Propulsion_Code',\n        'Age_of_Vehicle',\n        'Vehicle_Reference'],\n\n}","326f77e2":"joined.Date.dt.year.value_counts().sort_index()","53b6c7b1":"train = joined.query(\"Date < '2012-01-01'\").dropna(subset=['target'])\ntest  = joined.query(\"Date > '2012-01-01'\").dropna(subset=['target'])\n\nclf = CatBoostClassifier(iterations=30)\nclf.fit(train[features].fillna(-99), train['target'], verbose=False)\n\ntrain_auc = roc_auc_score(train['target'], clf.predict_proba(train[features].fillna(-99))[:,1])\ntest_auc  = roc_auc_score(test['target'],  clf.predict_proba(test[features].fillna(-99))[:,1] )\nprint(\"Train AUC: \", train_auc)\nprint(\"Out-of-time AUC: \", test_auc)","0157bf6a":"from shap import TreeExplainer\nexp = TreeExplainer(clf)\ntest_shap = test.sample(10000)\n\nshap_vals = exp.shap_values(test_shap[features].fillna(-99))\nshap_df = pd.DataFrame(shap_vals, columns=pd.Index(features, name='features'))\nshap.summary_plot(shap_vals, test_shap[features])","50df5981":"shap_grouped = grouped_shap(shap_vals, features, groups)\nshap.summary_plot(shap_grouped.values, feature_names = shap_grouped.columns)","348662a6":"groups = {\n    'geografical': [ \n        'Location_Easting_OSGR',\n        'Location_Northing_OSGR',\n        'Longitude',\n        'Latitude',\n        'Junction_Location',\n        'Urban_or_Rural_Area'],\n    \n    'road_specs': [\n        '1st_Road_Class',\n        '1st_Road_Number',\n        'Junction_Detail',\n        'Junction_Control',\n        '2nd_Road_Class',\n        '2nd_Road_Number',\n        'Road_Type',\n        'Speed_limit',\n        'Police_Force',\n        'Local_Authority_(District)'],\n    \n    'accident_before': [   \n        'Pedestrian_Crossing-Human_Control',\n        'Pedestrian_Crossing-Physical_Facilities',\n        'Towing_and_Articulation',\n        'Vehicle_Manoeuvre',\n        'Vehicle_Location-Restricted_Lane',\n        'Vehicle_Leaving_Carriageway'],\n    \n    'accident_during': [\n        'Number_of_Vehicles',\n        'Number_of_Casualties',\n        'Hit_Object_in_Carriageway',\n        'Hit_Object_off_Carriageway',\n        'Skidding_and_Overturning',\n        '1st_Point_of_Impact'],\n    \n    'accident_after': [\n        'Carriageway_Hazards',\n        'Casualty_Reference',\n        'Casualty_Type',\n        'Did_Police_Officer_Attend_Scene_of_Accident'],\n    \n    'conditions': [\n         'Light_Conditions',\n         'Weather_Conditions',\n         'Road_Surface_Conditions',\n         'Special_Conditions_at_Site',\n         'Day_of_Week'],\n    \n    'victim_specs': [\n         'Casualty_Class',\n         'Sex_of_Casualty',\n         'Age_of_Casualty',\n         'Age_Band_of_Casualty',\n         'Pedestrian_Location',\n         'Pedestrian_Movement',\n         'Car_Passenger',\n         'Bus_or_Coach_Passenger',\n         'Pedestrian_Road_Maintenance_Worker',\n         'Casualty_Home_Area_Type'],\n    \n    'driver_specs': [\n        'Journey_Purpose_of_Driver',\n        'Sex_of_Driver',\n        'Age_of_Driver',\n        'Age_Band_of_Driver',\n        'Driver_IMD_Decile',\n        'Driver_Home_Area_Type'],\n    \n    'vehicle_specs': [ \n        'Vehicle_Type',\n        'Was_Vehicle_Left_Hand_Drive?',\n        'Engine_Capacity_(CC)',\n        'Propulsion_Code',\n        'Age_of_Vehicle',\n        'Vehicle_Reference']\n}\nshap_grouped = grouped_shap(shap_vals, features, groups)\nshap.summary_plot(shap_grouped.values, feature_names = shap_grouped.columns)","b14d7fc9":"unimportant = shap_df.abs().mean()< 1e-3\nunimportant_feats = unimportant[unimportant.values].index.tolist()","dfa47b83":"import seaborn as sns\nplt.figure(figsize=(9,7), dpi=200)\nsns.heatmap(shap_df.drop(unimportant_feats, axis=1).corr(method='spearman').abs())","9804b0e2":"abcorr = shap_df.drop(unimportant_feats, axis=1).corr(method='spearman').abs()\nsns.clustermap(abcorr, figsize=(13,13))","43d2b2af":"highestcorrs = (abcorr**2).sum().sort_values()[-20:].index.tolist()\nsns.clustermap(abcorr.loc[highestcorrs, highestcorrs], figsize=(8,8))","c1ad9dc0":"highestcorrs = (abcorr.replace(1, 0)).max().sort_values()[-20:].index.tolist()\nsns.clustermap(abcorr.loc[highestcorrs, highestcorrs], figsize=(8,8))","af313066":"len(features)","ba873c01":"important = shap_df.abs().mean().sort_values()[-20:].index.tolist()\nsns.clustermap(abcorr.loc[important, important], figsize=(10,10))","24565a04":"# Testing uk accidents data"}}