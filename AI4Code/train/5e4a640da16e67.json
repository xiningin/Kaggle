{"cell_type":{"78ed8801":"code","49c40eac":"code","6c63ffc8":"code","c6c872f7":"code","963afc92":"code","f6f6fcdf":"code","99199911":"code","94e899ed":"code","09b971f6":"code","f91698d4":"code","3025c365":"code","8af2ee4e":"code","a0668824":"code","5cb13d17":"code","1339b51e":"code","d1f1ba01":"code","3d9a36f0":"code","d6545262":"code","3f89f633":"code","38410cdb":"code","2ccbcb42":"code","ab1552f7":"code","698f4fa3":"code","de8b3e5e":"code","733bfea8":"code","95745108":"code","2255efd3":"code","9dd7b438":"code","c1ea4143":"code","be9d363a":"code","5b95d943":"code","ceb5ce2a":"code","c7ef5845":"code","d5b38ff6":"code","ebfe0d6e":"code","c7f8e72e":"code","eaaa47d5":"code","36026626":"code","f8797782":"code","a0d4b8f0":"code","c7cb4aa2":"code","cea299a6":"code","5b8defd5":"code","9e77baf9":"code","d3b9c85f":"code","3ce58d17":"code","39b23f6d":"code","003e8191":"code","366168cb":"code","22bb66e3":"code","d9580bb6":"code","c05ba74f":"code","664d9ad6":"code","8377256a":"code","30756544":"code","edbab4e6":"code","0c772910":"code","b87593e4":"markdown","11f95d4c":"markdown","73099a26":"markdown","f0de7d1b":"markdown","72640303":"markdown","6593a8c3":"markdown","36a80ce1":"markdown","0f51a380":"markdown","0a403bc4":"markdown","b02c7ec5":"markdown","82193bef":"markdown","484331d0":"markdown"},"source":{"78ed8801":"# Importing the Libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","49c40eac":"# loading Dataset\n\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","6c63ffc8":"train_data.head()","c6c872f7":"# Checking Null value\n\nprint(train_data.isnull().sum())\nprint(test_data.isnull().sum())","963afc92":"# Now we need to fill in the missing values in the Embarked feature\n\nprint(\"Number of people embarking in Southampton (S):\")\nsouthampton = train_data[train_data[\"Embarked\"] == \"S\"].shape[0]\nprint(southampton)\n\nprint(\"Number of people embarking in Cherbourg (C):\")\ncherbourg = train_data[train_data[\"Embarked\"] == \"C\"].shape[0]\nprint(cherbourg)\n\nprint(\"Number of people embarking in Queenstown (Q):\")\nqueenstown = train_data[train_data[\"Embarked\"] == \"Q\"].shape[0]\nprint(queenstown)\n\n","f6f6fcdf":"# Filling 2 Null-Values from Embarked from Training Data\n\ntrain_data['Embarked'] = train_data['Embarked'].fillna('S')\n\n# Check for Change\n\ntrain_data.info()","99199911":"# Fetching title from \"Name\" column\n\ntrain_data['Title'] = train_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest_data['Title']  = test_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n","94e899ed":"print(train_data[\"Title\"].value_counts())\nprint(test_data[\"Title\"].value_counts())\n","09b971f6":"# From above data it is evident that there majority of Title are --> Mr, Mrs, Miss, Master. So we will merge others into Rare\nfor i in [train_data, test_data]:\n    i['Title'] =i['Title'].replace(['Lady', 'Countess','Capt','Dr', 'Col','Don', 'Major', 'Jonkheer', 'Dona','Rev'], 'Rare')\n    i['Title'] = i['Title'].replace('Mlle', 'Miss')\n    i['Title'] = i['Title'].replace('Ms', 'Miss')\n    i['Title'] = i['Title'].replace('Mme', 'Mrs')\n    i['Title'] = i['Title'].replace('Sir', 'Mr')\n    \n\n# check for Dr,rev","f91698d4":"a = pd.Categorical(train_data.Title)\na","3025c365":"train_data['Family'] = train_data['SibSp'] + train_data['Parch'] \ntest_data['Family'] = test_data['SibSp'] + test_data['Parch'] ","8af2ee4e":"test_data.head(10)","a0668824":"# Fill null value in fare in test data by the mean\n\nfare_mean =test_data['Fare'].mean()\ntest_data['Fare'] = test_data['Fare'].fillna(fare_mean)\nprint(test_data.isnull().sum())\n","5cb13d17":"# Splitting Fare into 5 parts\ntrain_data['FareBand'] = pd.qcut(train_data['Fare'], 5, labels = [1, 2, 3, 4,5])\ntest_data['FareBand'] = pd.qcut(test_data['Fare'], 5, labels = [1, 2, 3, 4,5])","1339b51e":"# Dropping Ticket,Cabin, Name and Age\n\ntrain_data = train_data.drop(['Ticket','Cabin','Name','SibSp','Parch','Age','Fare'], axis=1)\ntest_data = test_data.drop(['Ticket','Cabin','Name','SibSp','Parch','Age','Fare'], axis=1)\n    ","d1f1ba01":"train_data.head()","3d9a36f0":"test_data.head()","d6545262":"# Survived vs Pclass\n\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train_data)","3f89f633":"# Survived vs Sex\n\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train_data)","38410cdb":"# Survived vs Embarked\n\nsns.barplot(x=\"Embarked\", y=\"Survived\", data=train_data)","2ccbcb42":"# Survived vs Title\n\nsns.barplot(x=\"Title\", y=\"Survived\", data=train_data)","ab1552f7":"# Survived vs Family\n\nsns.barplot(x=\"Family\", y=\"Survived\", data=train_data)\n","698f4fa3":"# Survived vs FareBand\n\nsns.barplot(x=\"FareBand\", y=\"Survived\", data=train_data)","de8b3e5e":"# Analyzing in one chart\n\nfig, ax = plt.subplots(2, 3, figsize = (15, 7)) # Making Subplots\n\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train_data, ax=ax[0,0]);\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train_data, ax=ax[0,1]);\nsns.barplot(x=\"Embarked\", y=\"Survived\", data=train_data, ax=ax[0,2]);\nsns.barplot(x=\"Title\", y=\"Survived\", data=train_data, ax=ax[1,0]);\nsns.barplot(x=\"Family\", y=\"Survived\", data=train_data, ax=ax[1,1]);\nsns.barplot(x=\"FareBand\", y=\"Survived\", data=train_data, ax=ax[1,2]);\n\n\nplt.tight_layout() # you can use this function for clear visualization\nplt.show()","733bfea8":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ntrain_data['Pclass'] = le.fit_transform(train_data['Pclass'])\ntrain_data['Sex'] = le.fit_transform(train_data['Sex'])\ntrain_data['Embarked'] = le.fit_transform(train_data['Embarked'])\ntrain_data['Title'] = le.fit_transform(train_data['Title'])\n\n\ntest_data['Pclass'] = le.fit_transform(test_data['Pclass'])\ntest_data['Sex'] = le.fit_transform(test_data['Sex'])\ntest_data['Embarked'] = le.fit_transform(test_data['Embarked'])\ntest_data['Title'] = le.fit_transform(test_data['Title'])\n","95745108":"train_data","2255efd3":"test_data","9dd7b438":"# Splitting data into X and y axis\n\nX = train_data.iloc[:,2:8].values\ny= train_data.iloc[:,1].values","c1ea4143":"X","be9d363a":"y","5b95d943":"# Splitting data to Train and Test\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=0)","ceb5ce2a":"# Adding layers and activation function\n\nimport tensorflow as tf\nann=tf.keras.models.Sequential()\n\nann.add(tf.keras.layers.Dense(units=6,activation='relu'))\nann.add(tf.keras.layers.Dense(units=6,activation='relu'))\nann.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n\n#Compiling\nann.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])","c7ef5845":"# Training the model\n\nann.fit(X_train,y_train,batch_size=32,epochs=200)","d5b38ff6":"# Prediction on Test data\n\ny_pred = ann.predict(X_test)\ny_pred = (y_pred > 0.5)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","ebfe0d6e":"# Calculating quality for model\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","c7f8e72e":"# KNN:K Nearest Neighbour\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier=KNeighborsClassifier(n_neighbors=5)\nclassifier.fit(X_train,y_train)","eaaa47d5":"# Training the model\ny_pred=classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","36026626":"# Calculating quality for model\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","f8797782":"# Training the model\nfrom sklearn.tree import DecisionTreeClassifier  \nclassifier= DecisionTreeClassifier(criterion='entropy', random_state=0)  \nclassifier.fit(X_train, y_train)  ","a0d4b8f0":"# Predicting the values\ny_pred=classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","c7cb4aa2":"# Calculating quality for model\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","cea299a6":"# Training the model  \nfrom sklearn.naive_bayes import GaussianNB  \nclassifier = GaussianNB()  \nclassifier.fit(X_train, y_train)  ","5b8defd5":"# Predicting the values\ny_pred=classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","9e77baf9":"# Calculating quality for model\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","d3b9c85f":"# Training the model\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg = logreg.fit(X_train,y_train)","3ce58d17":"# Predicting the values\ny_pred=classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","39b23f6d":"# Calculating quality for model\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","003e8191":"# Training the model\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel='rbf', random_state = 1)\nclassifier.fit(X_train,y_train)","366168cb":"# Predicting the values\ny_pred=classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\nfinal_classifier = classifier    # since max quality is for SVM so we have stored this in a final variable","22bb66e3":"# Calculating quality for model\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","d9580bb6":"test_data.head()","c05ba74f":"# In this case maximum quality is for SVM so we will use this algorithm\n\nfin_test_data = test_data.drop('PassengerId',axis=1)","664d9ad6":"final_pred = final_classifier.predict(fin_test_data)\nfinal_pred","8377256a":"#sample_submit = pd.read_csv('..\/input\/wine-m\/sample_submit.csv')\n#sample_submit","30756544":"submit= pd.DataFrame({'PassengerId' : test_data['PassengerId'], 'Survived': final_pred })\nprint(submit.head())","edbab4e6":"filename= 'gender_submission.csv'\nsubmit.to_csv(filename, index=False)\nprint(\"Operation executed sucesfully\")","0c772910":"# Download the CSV file created above\n\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\n\ndef create_download_link(title = \"Download CSV file\", filename = filename):  \n    html = '<a href={filename}>{title}<\/a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe which was saved with .to_csv method\ncreate_download_link(filename=filename)","b87593e4":"### **Here we determine that majority of people belong to \"S\" so we will fill missing value with S","11f95d4c":"## Final Prediction Using most Efficient algorithm","73099a26":"### Applying KNN","f0de7d1b":"### Applying Naive Bayes","72640303":"## ML Models","6593a8c3":"### Saving the results into a csv file \u2705","36a80ce1":"## Applying ANN","0f51a380":"## Lets Plot the graph for all the variables vs Survived to identify the dependent variables","0a403bc4":"### Support Vector Machine","b02c7ec5":"### Logistic Regression","82193bef":"# Model Selection","484331d0":"### Applying Decision Tree"}}