{"cell_type":{"10ababf8":"code","dbfd5175":"code","629b8035":"code","1f5d841a":"code","9bc5cfa2":"code","46ce6216":"code","3dc73565":"code","e69636af":"code","ba198753":"code","35be564e":"code","74dd51bc":"code","daea12ca":"code","e49cd649":"code","217c5a50":"code","27dae0cb":"code","2e4f4161":"code","553b5c37":"code","f465dbe0":"code","e1df0965":"code","08d1d8a8":"code","d6756284":"code","b132b113":"code","b5f5ce74":"code","5a073d9b":"code","3380bb40":"code","b7889fd7":"code","d75a042a":"code","0ee9fbc1":"code","434e52be":"code","a2e6307a":"code","f017e86b":"code","aae05257":"code","7f3a5992":"code","50717fde":"code","fb3ef78e":"code","7d267976":"code","15fdfe4a":"code","ac6e0fb8":"code","10be7148":"code","517ef21d":"code","e59f1629":"code","79919137":"code","fdba5b34":"code","e08a62df":"code","04650378":"markdown","59250393":"markdown","aa976019":"markdown","174b4237":"markdown","af586e5a":"markdown","a29f48af":"markdown","df258af5":"markdown","37958b31":"markdown","17203e3f":"markdown","cc8f30c4":"markdown","1f46fe0a":"markdown","4c63a75c":"markdown","21a10a65":"markdown","04d034d0":"markdown","7ff37907":"markdown","7c8f1c8b":"markdown","39af757b":"markdown","21435ad0":"markdown","be1f4f8b":"markdown","02ada0a7":"markdown","7492dd01":"markdown"},"source":{"10ababf8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n%matplotlib inline \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn\nimport random\nimport matplotlib.pyplot as plt \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","dbfd5175":"#reading the csv's\n\ntrain = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","629b8035":"#Checking the data types of the variables\ntrain.dtypes","1f5d841a":"#Check for missing\/null data to determine a remedy for them\n\ntrain.isnull().sum()","9bc5cfa2":"test.isnull().sum()","46ce6216":"train_df = train.select_dtypes(include = np.number).fillna(train.mean())\ntrain_df.head()","3dc73565":"test_df = test.select_dtypes(include = np.number).fillna(test.mean())\ntest_df.head()","e69636af":"#checking to see if the data is cleaned properly (i.e. all nulls removed\/filled)\ntrain_df.isnull().sum()","ba198753":"test_df.isnull().sum()","35be564e":"#getting a sense of the dataframe\ntest_df.shape","74dd51bc":"train_df.shape","daea12ca":"#note difference in array shape\n\nimport seaborn as sns","e49cd649":"train_df.plot.scatter(x = 'Id', y = ['SalePrice'])","217c5a50":"for cols in train_df.columns[train_df.dtypes != object][:-2].values.reshape((6,6)):\n    sns.pairplot(train_df,y_vars='SalePrice',x_vars =cols,kind='reg')\n    \n\nsns.pairplot(train_df,y_vars='SalePrice',x_vars ='YrSold',kind='reg')","27dae0cb":"train_out = train_df.pop('SalePrice')","2e4f4161":"from sklearn.model_selection import train_test_split","553b5c37":"train_x,x,train_y, y = train_test_split(train_df,train_out, test_size=0.30, random_state=42)","f465dbe0":"train_x.shape,x.shape,train_y.shape,y.shape","e1df0965":"from sklearn.ensemble import RandomForestRegressor","08d1d8a8":"classifier = RandomForestRegressor(n_estimators = 150, max_depth=5)\nclassifier.fit(train_x,train_y)\nclassifier.score(x,y)","d6756284":"value_predict = classifier.predict(x)","b132b113":"plt.scatter(range(len(value_predict)),value_predict,label=\"Predict\")\nplt.scatter(range(len(y)),y,label=\"True Value\")\nplt.legend()","b5f5ce74":"#move from training data to test data\n\nfor i in train_df.columns:\n    if i not in test_df.columns:\n        test_df[i] = 0","5a073d9b":"test_df = test_df[train_df.columns]","3380bb40":"test_predict = classifier.predict(test_df)","b7889fd7":"plt.scatter(range(len(test_predict)),test_predict,label=\"Predict\")\nplt.scatter(range(len(y)),y,label=\"True Value\")\nplt.legend()","d75a042a":"#submission = test[[\"Id\"]].copy()","0ee9fbc1":"#submission[\"SalePrice\"] = test_predict","434e52be":"#submission.to_csv(\"submission.csv\",index = False)","a2e6307a":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LinearRegression\nLinReg = LinearRegression()\n\nX_train, X_test, y_train, y_test = train_test_split(train_df,train_out, test_size=0.30)","f017e86b":"X_train.shape, y_train.shape","aae05257":"X_test.shape, y_test.shape","7f3a5992":"#Linear Regression\nLinReg.fit(X_train, y_train)\ny_predicted = LinReg.predict(X_test)","50717fde":"#Test Accuracy with Mean Squared Error (MSE)\n\nfrom sklearn.metrics import mean_squared_error\n\n\n#Error of Test Data\nprint(mean_squared_error(y_true = y_test, y_pred = LinReg.predict(X_test)))","fb3ef78e":"#Error of Train Data\nprint(mean_squared_error(y_true = y_train, y_pred = LinReg.predict(X_train)))","7d267976":"#R^2 of model will all variables\nLinReg.score(X_test, y_test)","15fdfe4a":"#Scatterplot\nplt.scatter(range(len(y_predicted)),y_predicted,label=\"Predict\")\nplt.scatter(range(len(y)),y,label=\"True Value\")\nplt.legend()","ac6e0fb8":"#Histogram of Residuals\nplt.hist(y_test - y_predicted)","10be7148":"#Scatterplot of variables (Shows Homoscedasticity)\nplt.scatter(y_predicted, y_test - y_predicted)","517ef21d":"print(LinReg.coef_)","e59f1629":"#Linear Regression Prediction of the Sale Price data in X_Test\nsubmission = test_df[['Id']].copy()","79919137":"submission[\"SalePrice\"] = LinReg.predict(test_df)","fdba5b34":"submission.to_csv(\".\/submission.csv\",index = False)","e08a62df":"corr_coef = np.corrcoef(train_df.values.T)\nsns.set(font_scale=.5)\nheat_map = sns.heatmap(corr_coef,\n                cbar=True,\n                annot=True,\n                square=True,\n                fmt='.2f',\n                annot_kws={'size':1},\n                yticklabels=cols,\n                xticklabels=cols)\nplt.show()","04650378":"# **Accuracy of Linear Regression Model**","59250393":"# **Diagnostics (Linear Regression)**","aa976019":"# **Import and Read**","174b4237":"# **Begin Training Model**","af586e5a":"# **Random Forest Regression**","a29f48af":"Note: We get the sum of all NA values from each column. If each column equals zero, then the data is clean and we won't need to worry about the general quality of our test and train dataset","df258af5":"# **Heat Map**","37958b31":"Note: Both datasets had Null values so in the code below we employ a function to allow us to fill each Null value with the mean of all values of that column. And to test if it works we employ the head function to quickly check if previous null values have been cleaned.","17203e3f":"Note: Below we will import the csv files of both the test and train data and read them into their respective objects","cc8f30c4":"Note: We made a scatter plot below of the train dataframe that compares the identifier value to Sales price to better understand the spread of prices, and so that we know how we want to approach a training model.","1f46fe0a":"We opted to try a linear regression in hopes of a better correlation than we experienced with the random forest regression. Ultimately, it appears to be pretty close to the other model we used to determine the sale prices of the the houses.","4c63a75c":"# **Linear Regression Model**","21a10a65":"Note: In another measure to make sure each null value is cleaned we get the count of null values from each column. In this case every column from each dataset has zero null values rendering them clean","04d034d0":"#  **Clean the Data**","7ff37907":"# **Fixing Null Values**","7c8f1c8b":"Group 5: Mike Byrnes, Eman Wasel, Zach Collins, Frazer Workneh, Andy Pineda","39af757b":"# **Null Values fixed; Analysis\/Visualizations**","21435ad0":"Note: R^2 shows what % the model accounts for the variation among Sale Price.","be1f4f8b":"# **Submission (Linear Regression CSV)**","02ada0a7":"Note: The code above creates several more scatter plots using the train dataframe to understand how the sale price of houses correlates with other variables in the dataframe. We demonstrate several instances of some strong, postive correlations and some strong negative correlations","7492dd01":"Here we tried to implement the random forest regression model on the data. We see a pretty good correlation in the predicted vs the true values as shown by the scatter plot above.\nThis model aims to correct overfitting so we utilized in hope of a close result."}}