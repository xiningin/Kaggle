{"cell_type":{"c2d9e29e":"code","69097be3":"code","5c875dcc":"code","5e1608b5":"code","274f5211":"code","c610ad95":"code","f95a19eb":"code","97025ace":"code","14953700":"code","032b6e6f":"code","b54dcb1a":"code","bce5582b":"code","952fe313":"code","874a6899":"code","62981097":"code","24e7d564":"code","1556dfdf":"code","60a20e8c":"code","54b6e673":"code","067a6ffe":"code","c8300a97":"code","16fa0821":"code","9bebcab7":"code","8a475f8a":"code","8d2ea587":"code","39796258":"code","3d514468":"code","4c847018":"code","7eda9cc9":"code","156a99c3":"code","ca788b07":"code","efb9cbc4":"code","290b2f3c":"code","39434c5f":"code","f5cc9662":"code","69dd0241":"code","ae1e601b":"code","ca9e648e":"code","b6e86ea3":"code","941f8050":"code","a5428491":"code","bbcfcb3b":"code","d70efc86":"code","11dc50c5":"code","b9bbde17":"code","675f5abb":"code","de45a6bf":"code","0a7c1e7b":"code","a51a280c":"code","6fb1d68f":"code","079c419f":"code","a861307a":"code","3687743d":"code","7892a01e":"code","cbac039b":"code","0fa3ce21":"markdown","828609c6":"markdown","2c913c7a":"markdown","775db326":"markdown","5a5d44f7":"markdown","de3d01ed":"markdown","24cbc8bc":"markdown","89994f4c":"markdown","34699e09":"markdown","776db85c":"markdown","a83d74b6":"markdown","d7bcdd39":"markdown","cd7464d9":"markdown"},"source":{"c2d9e29e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n#import \nimport numpy as np\nimport pandas as pd\nimport hyperopt\nfrom catboost import Pool, CatBoostClassifier, cv\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","69097be3":"np.random.seed(123)","5c875dcc":"#get the train and test data\n#train_df = pd.read_csv('..\/input\/titanic\/train.csv')\n#test_df = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain_df = pd.read_pickle('..\/input\/titanic-top-3-full-eda-model\/train_x.pkl')\ntrain_y = pd.read_pickle('..\/input\/titanic-top-3-full-eda-model\/train_y.pkl')\ntest_df = pd.read_pickle('..\/input\/titanic-top-3-full-eda-model\/test_x.pkl')\ntest_id = pd.read_pickle('..\/input\/titanic-top-3-full-eda-model\/test_id.pkl')\nanswer = pd.read_pickle('..\/input\/titanic-top-3-full-eda-model\/test_y.pkl')","5e1608b5":"# Show the train data\ntrain_df.info()","274f5211":"# Convert Connected_Survival to int\ntrain_df['Connected_Survival'] = train_df['Connected_Survival'].map({0:0,0.5:1,1:2})    \ntest_df['Connected_Survival'] = test_df['Connected_Survival'].map({0:0,0.5:1,1:2})    ","c610ad95":"# Show how many the null value for each column\ntrain_df.isnull().sum()","f95a19eb":"\"\"\"# Fill nan with mean of the column for age\ntrain_df['Age'].fillna(train_df['Age'].mean(),inplace=True)\ntest_df['Age'].fillna(test_df['Age'].mean(),inplace=True)\n# for the train data, the age, are and embarked has null value, so just make it -999 for it, and Catboost will distinguish it\ntrain_df.fillna(-999,inplace=True)\ntest_df.fillna(-999,inplace=True)\"\"\"","97025ace":"\"\"\"# Convert Age to int\ntrain_df['Age'] = train_df['Age'].round().astype(int)\ntest_df['Age'] = test_df['Age'].round().astype(int)\n# Convert Fare to int\ntrain_df['Fare'] = train_df['Fare'].round().astype(int)\ntest_df['Fare'] = test_df['Fare'].round().astype(int)\"\"\"","14953700":"# Make the data set\n#x = train_df.drop('Survived',axis=1)\n#y = train_df['Survived']\nx = train_df\ny = train_y","032b6e6f":"# Show what the dtype of x, note that the catboost will just make the string object to categorical object inside\nx.dtypes","b54dcb1a":"# Choose the features we want to train, just forget the float data\nselect_features_index = np.where(x.dtypes != float)[0]\nselect_features_index","bce5582b":"# Make the x for train & validation\nx_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.85,random_state=1234)","952fe313":"x_train.head()","874a6899":"y_train.head()","62981097":"# Make the catboost model, use_best_model params will make the model prevent overfitting\nmodel = CatBoostClassifier(eval_metric='Accuracy', use_best_model=True,random_seed=42)","24e7d564":"# Fit model to the data\nmodel.fit(x_train,y_train,cat_features=select_features_index, eval_set=(x_test,y_test))","1556dfdf":"# Since the data is not so big, it is better to use CV for the model, use 10 folds\nparams = model.get_params()\nparams['loss_function']='Logloss'\ncv_data = cv(Pool(x,y,cat_features=select_features_index),params,fold_count=10)","60a20e8c":"# Print all the columns in the cv_data df\ncv_data.columns.values","54b6e673":"# show the accuracy of the model\nprint ('best cv accuracy: {}'.format(max(cv_data['test-Accuracy-mean'])))","067a6ffe":"# Show the model test accuracy, but you have to note that the acc is not the cv acc, so recommend to use the cv acc to evaluate model!\nprint('test accuracy: {:.6f}'.format(accuracy_score(y_test,model.predict(x_test))))","c8300a97":"# Make the submission file, make sure to convert pred to int\npred = model.predict(test_df)\npred = pred.astype(int)\nsubmission = pd.DataFrame({'PassengerId':test_id,'Survived':pred})","16fa0821":"submission.head()","9bebcab7":"# Save the file to directory\nsubmission.to_csv('catboost1.csv',index=False)","8a475f8a":"y_pred = submission['Survived'].values\ny_true = answer['Survived'].values\naccuracy_score(y_true,y_pred)","8d2ea587":"train_df = pd.read_pickle('..\/input\/titanic-top-3-full-eda-model\/train_x.pkl')\ntrain_y = pd.read_pickle('..\/input\/titanic-top-3-full-eda-model\/train_y.pkl')\ntest_df = pd.read_pickle('..\/input\/titanic-top-3-full-eda-model\/test_x.pkl')","39796258":"#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.tools.plotting import scatter_matrix\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n#Configure Visualization Defaults\n#%matplotlib inline = show plots in Jupyter Notebook browser\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')\npylab.rcParams['figure.figsize'] = 12,8","3d514468":"def features_hist(df1,df2,features,height):\n    fig, ax = plt.subplots(nrows=len(features),ncols=1,figsize=(20, height*len(features)))\n    for i,f in enumerate(features):\n        df1.hist(column=f,bins=40,ax=ax[i])\n        if df2.__class__.__name__ == 'DataFrame':\n            df2.hist(column=f,bins=40,ax=ax[i])\n        ax[i].set_title(f)    ","4c847018":"features_hist(train_df,test_df,list(train_df.columns.values),5)","7eda9cc9":"from sklearn.preprocessing import StandardScaler,MinMaxScaler,PowerTransformer\ndef norm_scaler(df,features,covariates,method='standard',scaler=None):\n    if method=='standard' or method=='power2':\n        df_transform = df[features].to_dict(orient='list')\n        df_out = []        \n        for f in features:\n            df_out.append(df_transform[f])\n        if scaler == None:\n            if method =='standard':\n                scaler = StandardScaler()\n            elif method == 'power2':\n                scaler = PowerTransformer()\n            scaler.fit(np.array(df_out).T)\n        df_out = scaler.transform(np.array(df_out).T)\n        df_out = pd.DataFrame(df_out,columns=features)\n    elif method == 'log':\n        df_out = df[features]\n        df_out = df_out.applymap(lambda x: np.log(1+x))\n    elif method == 'power1':\n        df_out = df[features]\n        df_out = df_out.applymap(lambda x: np.sqrt(x+(2\/3)))  \n    for cov in covariates:\n        df_out[cov] = list(df[cov])\n    return df_out, scaler       ","156a99c3":"df_all = pd.concat([train_df,test_df])\ndf_all_n,scaler1 = norm_scaler(df_all,list(train_df.columns.values),[])\ntrain_df_n,scaler = norm_scaler(train_df,list(train_df.columns.values),[],'standard',scaler1)\ntest_df_n,scaler = norm_scaler(test_df,list(train_df.columns.values),[],'standard',scaler1)","ca788b07":"features_hist(train_df_n,test_df_n,list(train_df.columns.values),5)","efb9cbc4":"train_df_n.describe()","290b2f3c":"test_df_n.describe()","39434c5f":"#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    svm.LinearSVC(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    \n    #xgboost: http:\/\/xgboost.readthedocs.io\/en\/latest\/model.html\n    XGBClassifier()    \n    ]","f5cc9662":"# split dataset in cross-validation\ncv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60\/30 split intentionally leaving out 10%\n\n# create table to compare MLA metrics\nMLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\n# create table to compare MLA predictions\nMLA_predict = train_y","69dd0241":"train_y = pd.read_pickle('..\/input\/titanic-top-3-full-eda-model\/train_y.pkl')","ae1e601b":"train_y.shape","ca9e648e":"# index through MLA and save performance to table\nrow_index = 0\nfor alg in MLA:\n\n    #set name and parameters\n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n    \n    #score model with cross validation\n    cv_results = model_selection.cross_validate(alg, train_df_n, train_y, cv=cv_split, return_train_score=True)\n\n    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n    #if this is a non-bias random sample, then +\/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n    \n\n    #save MLA predictions - see section 6 for usage\n    alg.fit(train_df_n, train_y)\n    MLA_predict[MLA_name] = alg.predict(train_df_n)\n    \n    row_index+=1\n\n# print and sort table\nMLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\nMLA_compare\n# MLA_predict","b6e86ea3":"#barplot using https:\/\/seaborn.pydata.org\/generated\/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https:\/\/matplotlib.org\/api\/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')","941f8050":"def plot_feature_importances(model, columns):\n    nr_f = 11\n    imp = pd.Series(data = model.best_estimator_.feature_importances_, \n                    index=columns).sort_values(ascending=False)\n    plt.figure(figsize=(7,5))\n    plt.title(\"Feature importance\")\n    ax = sns.barplot(y=imp.index[:nr_f], x=imp.values[:nr_f], orient='h')","a5428491":"# Baseline model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, train_df, train_y, cv=cv_split, return_train_score=True)\ndtree.fit(train_df, train_y)\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w\/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w\/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w\/bin score 3*std: +\/- {:.2f}\". format(base_results['test_score'].std()*100*3))\n#print(\"BEFORE DT Test w\/bin set score min: {:.2f}\". format(base_results['test_score'].min()*100))\nprint('-'*10)","bbcfcb3b":"param_grid = {'criterion': ['gini', 'entropy'],  #scoring methodology; two supported formulas for calculating information gain - default is gini\n              #'splitter': ['best','random'], #splitting methodology; two supported strategies - default is best\n              'max_depth': [2,4,6,8,10,None], #max depth tree can grow; default is none\n              'min_samples_split': [2,5,10,.03,.05], #minimum subset size BEFORE new split (fraction is % of total); default is 2\n              'min_samples_leaf': [1,5,10,.03,.05], #minimum subset size AFTER new split split (fraction is % of total); default is 1\n              #'max_features': [None, 'auto'], #max features to consider when performing split; default none or all\n              'random_state': [0] #seed or control random number generator: https:\/\/www.quora.com\/What-is-seed-in-random-number-generation\n             }\n\n#choose best model with grid_search: #http:\/\/scikit-learn.org\/stable\/modules\/grid_search.html#grid-search\n#http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_grid_search_digits.html\ntune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split, return_train_score=True)\ntune_model.fit(train_df, train_y)\n\n#print(tune_model.cv_results_.keys())\n#print(tune_model.cv_results_['params'])\nprint('AFTER DT Parameters: ', tune_model.best_params_)\n#print(tune_model.cv_results_['mean_train_score'])\nprint(\"AFTER DT Training w\/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n#print(tune_model.cv_results_['mean_test_score'])\nprint(\"AFTER DT Test w\/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\nprint(\"AFTER DT Test w\/bin score 3*std: +\/- {:.2f}\". format(tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\nprint('-'*10)","d70efc86":"plot_feature_importances(tune_model,train_df.columns)","11dc50c5":"#selected_features = ['Title','Pclass','haveCabin','BigFamily','FareBin']\nselected_features = list(train_df.columns.values)","b9bbde17":"#base model\nprint('BEFORE DT RFE Training Shape Old: ', train_df.shape) \nprint('BEFORE DT RFE Training Columns Old: ', train_df.columns.values)\n\nprint(\"BEFORE DT RFE Training w\/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w\/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w\/bin score 3*std: +\/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n#feature selection\ndtree_rfe = feature_selection.RFECV(dtree, step = 1, scoring = 'accuracy', cv = cv_split)\ndtree_rfe.fit(train_df_n, train_y)\n\n#transform x&y to reduced features and fit new model\n#alternative: can use pipeline to reduce fit and transform steps: http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.pipeline.Pipeline.html\nX_rfe = train_df.columns.values[dtree_rfe.get_support()]\nrfe_results = model_selection.cross_validate(dtree, train_df[X_rfe], train_y, cv  = cv_split, return_train_score=True)\n\n#print(dtree_rfe.grid_scores_)\nprint('AFTER DT RFE Training Shape New: ', train_df[X_rfe].shape) \nprint('AFTER DT RFE Training Columns New: ', X_rfe)\n\nprint(\"AFTER DT RFE Training w\/bin score mean: {:.2f}\". format(rfe_results['train_score'].mean()*100)) \nprint(\"AFTER DT RFE Test w\/bin score mean: {:.2f}\". format(rfe_results['test_score'].mean()*100))\nprint(\"AFTER DT RFE Test w\/bin score 3*std: +\/- {:.2f}\". format(rfe_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n#tune rfe model\nrfe_tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split, return_train_score=True)\nrfe_tune_model.fit(train_df[selected_features], train_y)\n\n#print(rfe_tune_model.cv_results_.keys())\n#print(rfe_tune_model.cv_results_['params'])\nprint('AFTER DT RFE Tuned Parameters: ', rfe_tune_model.best_params_)\n#print(rfe_tune_model.cv_results_['mean_train_score'])\nprint(\"AFTER DT RFE Tuned Training w\/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n#print(rfe_tune_model.cv_results_['mean_test_score'])\nprint(\"AFTER DT RFE Tuned Test w\/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\nprint(\"AFTER DT RFE Tuned Test w\/bin score 3*std: +\/- {:.2f}\". format(rfe_tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\nprint('-'*10)","675f5abb":"#Graph MLA version of Decision Tree: http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = list(train_df.columns.values), class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph","de45a6bf":"def correlation_heatmap(df,absolute):\n    _ , ax = plt.subplots(figsize =(16, 16))\n    \n    if absolute:\n        corr = df.corr().abs()\n        colormap = sns.color_palette(\"Reds\")\n    else:\n        corr = df.corr()\n        colormap = sns.diverging_palette(220, 10, as_cmap = True)\n        \n    _ = sns.heatmap(\n        corr, \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':10 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)","0a7c1e7b":"MLA_predict_values = np.array([x.tolist() for x in MLA_predict[891:].values.tolist()]).T\nMLA_predict2 = pd.DataFrame(data = MLA_predict_values,columns = list(MLA_predict[891:].index))\nMLA_predict2.insert(loc=0,column='Survived',value=train_y)\ncorrelation_heatmap(MLA_predict2,False)","a51a280c":"#why choose one model, when you can pick them all with voting classifier\n#http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.VotingClassifier.html\n#removed models w\/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http:\/\/scikit-learn.org\/stable\/modules\/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassifier()),\n    ('gbc', ensemble.GradientBoostingClassifier()),\n    ('rfc', ensemble.RandomForestClassifier()),\n\n    #Gaussian Processes: http:\/\/scikit-learn.org\/stable\/modules\/gaussian_process.html#gaussian-process-classification-gpc\n    ('gpc', gaussian_process.GaussianProcessClassifier()),\n    \n    #GLM: http:\/\/scikit-learn.org\/stable\/modules\/linear_model.html#logistic-regression\n    ('lr', linear_model.LogisticRegressionCV()),\n    \n    #Navies Bayes: http:\/\/scikit-learn.org\/stable\/modules\/naive_bayes.html\n    ('bnb', naive_bayes.BernoulliNB()),\n    ('gnb', naive_bayes.GaussianNB()),\n    \n    #Nearest Neighbor: http:\/\/scikit-learn.org\/stable\/modules\/neighbors.html\n    ('knn', neighbors.KNeighborsClassifier()),\n    \n    #SVM: http:\/\/scikit-learn.org\/stable\/modules\/svm.html\n    ('svc', svm.SVC(probability=True)),\n    \n    #xgboost: http:\/\/xgboost.readthedocs.io\/en\/latest\/model.html\n   ('xgb', XGBClassifier())\n]\n\n\n# Hard Vote or majority rules\nvote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\nvote_hard_cv = model_selection.cross_validate(vote_hard,train_df_n[selected_features],train_y,cv=cv_split,return_train_score=True)\nvote_hard.fit(train_df_n[selected_features],train_y)\n\nprint(\"Hard Voting Training w\/bin score mean: {:.2f}\". format(vote_hard_cv['train_score'].mean()*100)) \nprint(\"Hard Voting Test w\/bin score mean: {:.2f}\". format(vote_hard_cv['test_score'].mean()*100))\nprint(\"Hard Voting Test w\/bin score 3*std: +\/- {:.2f}\". format(vote_hard_cv['test_score'].std()*100*3))\nprint('-'*10)\n\n\n# Soft Vote or weighted probabilities\nvote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\nvote_soft_cv = model_selection.cross_validate(vote_soft,train_df_n[selected_features],train_y,cv=cv_split,return_train_score=True)\nvote_soft.fit(train_df_n[selected_features],train_y)\n\nprint(\"Soft Voting Training w\/bin score mean: {:.2f}\". format(vote_soft_cv['train_score'].mean()*100)) \nprint(\"Soft Voting Test w\/bin score mean: {:.2f}\". format(vote_soft_cv['test_score'].mean()*100))\nprint(\"Soft Voting Test w\/bin score 3*std: +\/- {:.2f}\". format(vote_soft_cv['test_score'].std()*100*3))\nprint('-'*10)","6fb1d68f":"import time\n\n#WARNING: Running is very computational intensive and time expensive.\n#Code is written for experimental\/developmental purposes and not production ready!\n\n\n#Hyperparameter Tune with GridSearchCV: http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html\ngrid_n_estimator = [10, 50, 100, 300]\ngrid_ratio = [.1, .25, .5, .75, 1.0]\ngrid_learn = [.01, .03, .05, .1, .25]\ngrid_max_depth = [2, 4, 6, 8, 10, None]\ngrid_min_samples = [5, 10, .03, .05, .10]\ngrid_criterion = ['gini', 'entropy']\ngrid_bool = [True, False]\ngrid_seed = [0]\n\n\ngrid_param = [\n            [{\n            #AdaBoostClassifier - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.AdaBoostClassifier.html\n            'n_estimators': grid_n_estimator, #default=50\n            'learning_rate': grid_learn, #default=1\n            #'algorithm': ['SAMME', 'SAMME.R'], #default=\u2019SAMME.R\n            'random_state': grid_seed\n            }],\n       \n    \n            [{\n            #BaggingClassifier - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n            'n_estimators': grid_n_estimator, #default=10\n            'max_samples': grid_ratio, #default=1.0\n            'random_state': grid_seed\n             }],\n\n    \n            [{\n            #ExtraTreesClassifier - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier\n            'n_estimators': grid_n_estimator, #default=10\n            'criterion': grid_criterion, #default=\u201dgini\u201d\n            'max_depth': grid_max_depth, #default=None\n            'random_state': grid_seed\n             }],\n\n\n            [{\n            #GradientBoostingClassifier - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n            #'loss': ['deviance', 'exponential'], #default=\u2019deviance\u2019\n            'learning_rate': [.05], #default=0.1 -- 12\/31\/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n            'n_estimators': [300], #default=100 -- 12\/31\/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n            #'criterion': ['friedman_mse', 'mse', 'mae'], #default=\u201dfriedman_mse\u201d\n            'max_depth': grid_max_depth, #default=3   \n            'random_state': grid_seed\n             }],\n\n    \n            [{\n            #RandomForestClassifier - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n            'n_estimators': grid_n_estimator, #default=10\n            'criterion': grid_criterion, #default=\u201dgini\u201d\n            'max_depth': grid_max_depth, #default=None\n            'oob_score': [True], #default=False -- 12\/31\/17 set to reduce runtime -- The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 146.35 seconds.\n            'random_state': grid_seed\n             }],\n    \n            [{    \n            #GaussianProcessClassifier\n            'max_iter_predict': grid_n_estimator, #default: 100\n            'random_state': grid_seed\n            }],\n        \n    \n            [{\n            #LogisticRegressionCV - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\n            'fit_intercept': grid_bool, #default: True\n            #'penalty': ['l1','l2'],\n            'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], #default: lbfgs\n            'random_state': grid_seed\n             }],\n            \n    \n            [{\n            #BernoulliNB - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB\n            'alpha': grid_ratio, #default: 1.0\n             }],\n    \n    \n            #GaussianNB - \n            [{}],\n    \n            [{\n            #KNeighborsClassifier - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n            'n_neighbors': [1,2,3,4,5,6,7], #default: 5\n            'weights': ['uniform', 'distance'], #default = \u2018uniform\u2019\n            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n            }],\n            \n    \n            [{\n            #SVC - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVC.html#sklearn.svm.SVC\n            #http:\/\/blog.hackerearth.com\/simple-tutorial-svm-parameter-tuning-python-r\n            #'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n            'C': [1,2,3,4,5], #default=1.0\n            'gamma': grid_ratio, #edfault: auto\n            'decision_function_shape': ['ovo', 'ovr'], #default:ovr\n            'probability': [True],\n            'random_state': grid_seed\n             }],\n\n    \n            [{\n            #XGBClassifier - http:\/\/xgboost.readthedocs.io\/en\/latest\/parameter.html\n            'learning_rate': grid_learn, #default: .3\n            'max_depth': [1,2,4,6,8,10], #default 2\n            'n_estimators': grid_n_estimator, \n            'seed': grid_seed  \n             }]   \n        ]\n\n\n# create table to compare MLA metrics\nMLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD','MLA Time']\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\n# index through MLA and save performance to table\nrow_index = 0\n\nstart_total = time.perf_counter() #https:\/\/docs.python.org\/3\/library\/time.html#time.perf_counter\nfor clf, param in zip (vote_est, grid_param): #https:\/\/docs.python.org\/3\/library\/functions.html#zip\n\n    MLA_name = clf[1].__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(clf[1].get_params())\n    \n    start = time.perf_counter()        \n    best_search = model_selection.GridSearchCV(estimator = clf[1], param_grid = param, cv=cv_split, scoring = 'roc_auc', return_train_score=True)\n    best_search.fit(train_df_n[selected_features],train_y)\n    run = time.perf_counter() - start\n    \n    MLA_compare.loc[row_index, 'MLA Time'] = best_search.cv_results_['mean_fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = best_search.cv_results_['mean_train_score'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = best_search.cv_results_['mean_test_score'].mean()   \n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = best_search.cv_results_['mean_test_score'].std()*3 \n\n    best_param = best_search.best_params_\n    print('The best parameter for {} is {} with a runtime of {:.2f} seconds.'.format(clf[1].__class__.__name__, best_param, run))\n    clf[1].set_params(**best_param) \n    \n    row_index += 1\n    \nrun_total = time.perf_counter() - start_total\nprint('Total optimization time was {:.2f} minutes.'.format(run_total\/60))\n\nprint('-'*10)","079c419f":"grid_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\ngrid_hard_cv = model_selection.cross_validate(grid_hard,train_df_n[selected_features],train_y,cv=cv_split,return_train_score=True)\ngrid_hard.fit(train_df_n[selected_features],train_y)\n\nprint(\"Hard Voting w\/Tuned Hyperparameters Training w\/bin score mean: {:.2f}\". format(grid_hard_cv['train_score'].mean()*100)) \nprint(\"Hard Voting w\/Tuned Hyperparameters Test w\/bin score mean: {:.2f}\". format(grid_hard_cv['test_score'].mean()*100))\nprint(\"Hard Voting w\/Tuned Hyperparameters Test w\/bin score 3*std: +\/- {:.2f}\". format(grid_hard_cv['test_score'].std()*100*3))\nprint('-'*10)\n\nrow_index = 12\nMLA_compare.loc[row_index, 'MLA Name'] = 'Hard Voting'\nMLA_compare.loc[row_index, 'MLA Parameters'] = str(grid_hard.get_params())\nMLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = grid_hard_cv['train_score'].mean()\nMLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = grid_hard_cv['test_score'].mean()   \nMLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = grid_hard_cv['test_score'].std()*3 \nMLA_compare.loc[row_index, 'MLA Time'] = grid_hard_cv['fit_time'].mean()\n\n#Soft Vote or weighted probabilities w\/Tuned Hyperparameters\ngrid_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\ngrid_soft_cv = model_selection.cross_validate(grid_soft,train_df_n[selected_features],train_y,cv=cv_split,return_train_score=True)\ngrid_soft.fit(train_df_n[selected_features],train_y)\n\nprint(\"Soft Voting w\/Tuned Hyperparameters Training w\/bin score mean: {:.2f}\". format(grid_soft_cv['train_score'].mean()*100)) \nprint(\"Soft Voting w\/Tuned Hyperparameters Test w\/bin score mean: {:.2f}\". format(grid_soft_cv['test_score'].mean()*100))\nprint(\"Soft Voting w\/Tuned Hyperparameters Test w\/bin score 3*std: +\/- {:.2f}\". format(grid_soft_cv['test_score'].std()*100*3))\nprint('-'*10)\n\nrow_index = 13\nMLA_compare.loc[row_index, 'MLA Name'] = 'Soft Voting'\nMLA_compare.loc[row_index, 'MLA Parameters'] = str(grid_soft.get_params())\nMLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = grid_soft_cv['train_score'].mean()\nMLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = grid_soft_cv['test_score'].mean()   \nMLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = grid_soft_cv['test_score'].std()*3 \nMLA_compare.loc[row_index, 'MLA Time'] = grid_soft_cv['fit_time'].mean()","a861307a":"MLA_compare","3687743d":"def get_best_score(model):\n    print(model.best_score_)    \n    print(model.best_params_)\n    print(model.best_estimator_)\n    return model.best_score_\n\ndef plot_feature_importances(model, columns):\n    nr_f = 10\n    imp = pd.Series(data = model.best_estimator_.feature_importances_, \n                    index=columns).sort_values(ascending=False)\n    plt.figure(figsize=(7,5))\n    plt.title(\"Feature importance\")\n    ax = sns.barplot(y=imp.index[:nr_f], x=imp.values[:nr_f], orient='h')\n\ndef submission(test_set,df_test,model_name,model,best_score,cv_scores):\n    cv_scores[model_name] = best_score\n    pred = model.predict(test_set)\n    submission = pd.DataFrame()\n    submission['PassengerId'] = df_test['PassengerId']\n    submission['Survived'] =pred\n    submission.to_csv('%s.csv' %model_name,index=False)\n    return submission\n\ndef accuracy(submission,answer):\n    y_pred = submission['Survived'].values\n    y_true = answer['Survived'].values\n    return accuracy_score(y_true,y_pred)","7892a01e":"start_total = time.perf_counter()\n\nfor clf, param in zip (vote_est, grid_param):\n    print (clf[1].__class__.__name__)\n    start = time.perf_counter()        \n    best_search = model_selection.GridSearchCV(estimator = clf[1], param_grid = param, cv=cv_split, scoring = 'roc_auc', return_train_score=True)\n    best_search.fit(train_df_n[selected_features],train_y)\n    run = time.perf_counter() - start\n    print('The best parameter is {} with a runtime of {:.2f} seconds.'.format(best_param, run))\n    \n    pred = best_search.predict(test_df_n[selected_features])\n    submission = pd.DataFrame()\n    submission['PassengerId'] = test_id\n    submission['Survived'] =pred\n    submission.to_csv('%s.csv' %clf[0],index=False)\n    \n    print ('Test Accuracy:')\n    print (accuracy(submission,answer))\n    \nrun_total = time.perf_counter() - start_total\nprint('Total optimization time was {:.2f} minutes.'.format(run_total\/60))","cbac039b":"print ('Hard vote')\npred = grid_hard.predict(test_df_n[selected_features])\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = test_id\nsubmission['Survived'] =pred\nsubmission.to_csv('hard_vote.csv',index=False)\n\nprint ('Test Accuracy:')\nprint (accuracy(submission,answer))\n\nprint ('Soft vote')\npred = grid_soft.predict(test_df_n[selected_features])\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = test_id\nsubmission['Survived'] =pred\nsubmission.to_csv('hard_vote.csv',index=False)\n\nprint ('Test Accuracy:')\nprint (accuracy(submission,answer))","0fa3ce21":"### Voting again after Tuning","828609c6":"### Decision Trees Tune HyperParameters","2c913c7a":"**An increase in mean Test score from 80.30 to 88.08!**","775db326":"### Tune Every single model","5a5d44f7":"### Normalise data","de3d01ed":"### Make Submissions","24cbc8bc":"# Part2. Model Ensemble","89994f4c":"### Validate and Implement\nThe next step is to prepare for submission using the validation data.","34699e09":"The distribution between train and test seem to be similar.","776db85c":"### Feature selection through Recursive Feature Elimination using CV","a83d74b6":"### Voting","d7bcdd39":"### Get Test Accuracy","cd7464d9":"### View MLA Performances"}}