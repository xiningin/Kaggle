{"cell_type":{"3bd4a9e0":"code","523da5ff":"code","7bb57ed8":"code","9d894159":"code","613cd1da":"code","67d1ccbd":"code","5c80a83e":"code","13a089a8":"code","dc674cc7":"code","9b0d5b2a":"code","280ee169":"code","2a3de6bc":"code","44edbda9":"code","74e60d08":"code","753f1604":"code","7e7da8f4":"code","4b4b5947":"code","4d0806f2":"code","e1fd3e6b":"code","13aa19a9":"code","0e95a854":"code","d8712169":"code","da58ca53":"code","1f6ab5a1":"code","95f21166":"code","3613ca18":"code","ad59b222":"code","e47281a4":"code","5e3fb956":"code","acecb874":"code","e5c88a90":"code","816e08c4":"code","0bbf999d":"code","8b4228eb":"code","def98e6d":"code","369eeae4":"code","c44360e8":"code","3b156d69":"code","79b9388c":"markdown","51f1e1ae":"markdown","9898e30e":"markdown","96238ff7":"markdown","043cec9d":"markdown","44f57c14":"markdown","004c1e57":"markdown","11a6cb84":"markdown","ddbbc132":"markdown","eeb34ece":"markdown","da93ca92":"markdown","ab3c43b4":"markdown","80e29056":"markdown","460a43a7":"markdown"},"source":{"3bd4a9e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport imgaug.augmenters as iaa\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","523da5ff":"df_train = pd.read_csv('..\/input\/train.csv')","7bb57ed8":"df_train.head()","9d894159":"X_train = df_train.iloc[:, 1:]\nY_train = df_train.iloc[:, 0]","613cd1da":"X_train.head()","67d1ccbd":"X_train.shape","5c80a83e":"Y_train.head()","13a089a8":"X_train = np.array(X_train)\nY_train = np.array(Y_train)","dc674cc7":"def plot_digits(X, y, dim):\n    fig = plt.figure()\n    for i in range(9):\n        plt.subplot(3,3,i+1)\n        plt.tight_layout()\n        plt.imshow(X[i].reshape((dim, dim)), interpolation='none', cmap='gray')\n        plt.title(\"Digit: {}\".format(y[i]))\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()","9b0d5b2a":"plot_digits(X_train, Y_train, 28)","280ee169":"fig, ax = plt.subplots(figsize=(8, 8))\nsns.countplot(Y_train)\nax.set_title(\"Distribution of Digits\", fontsize=12)\nax.set_xlabel(\"Digits\", fontsize=10)\nax.set_ylabel('Count', fontsize=10)\nplt.show()","2a3de6bc":"X_train = X_train\/255.0","44edbda9":"plot_digits(X_train, Y_train, 28)","74e60d08":"X_dev, X_val, Y_dev, Y_val = train_test_split(X_train, Y_train, test_size=0.03, shuffle=True, \\\n                                              random_state=2019)","753f1604":"#Encode Y\ndef yEncode(Y):\n    #T = np.zeros((Y.size, len(set(Y))))\n    #T[np.arange(Y.size), Y] = 1\n    T = pd.get_dummies(Y).values\n    return T\n\nT_dev = yEncode(Y_dev)\nT_val = yEncode(Y_val)","7e7da8f4":"class ImageAugmenter:\n    def __init__(self):\n        self.name = 'ImageAugmenter'\n        \n    def reshape_images(self, img_arr, shape):\n        return img_arr.reshape(shape)\n    \n    def transform_images(self, seq, img_arr, shape):\n        X_img = self.reshape_images(img_arr, (img_arr.shape[0], shape, shape))\n        X_aug = seq.augment_images(X_img)\n        X_aug = self.reshape_images(X_aug, (img_arr.shape[0], shape*shape))\n        return X_aug\n        \n    def fliplr(self, X, shape):\n        seq = iaa.Sequential([\n            iaa.Fliplr(1)\n        ])\n        return self.transform_images(seq, X, shape)\n    \n    def flipud(self, X, shape):\n        seq = iaa.Sequential([\n            iaa.Flipud(1)\n        ])\n        return self.transform_images(seq, X, shape)\n    \n    def scale(self, X, shape):\n        seq = iaa.Sequential([\n            iaa.Affine(\n                scale={\"x\":(0.5, 1.5), \"y\":(0.5, 1.5)}\n            )\n        ])\n        return self.transform_images(seq, X, shape)\n    \n    def translate(self, X, shape):\n        seq = iaa.Sequential([\n            iaa.Affine(\n                translate_percent={\"x\":(-0.2, 0.2), \"y\":(-0.2, 0.2)}\n            )\n        ])\n        return self.transform_images(seq, X, shape)\n    \n    def rotate(self, X, shape):\n        seq = iaa.Sequential([\n            iaa.Affine(\n                rotate=(-45, 45)\n            )\n        ])\n        return self.transform_images(seq, X, shape)\n    \n    def shear(self, X, shape):\n        seq = iaa.Sequential([\n            iaa.Affine(\n                shear=(-10, 10)\n            )\n        ])\n        return self.transform_images(seq, X, shape)\n    \n    def compose(self, X, shape):\n        seq = iaa.Sequential([\n            iaa.Affine(\n            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n            rotate=(-25, 25),\n            shear=(-8, 8)\n            ),\n            iaa.Pepper(1e-5)\n        ])\n        return self.transform_images(seq, X, shape)\n    \n    def augment(self, count, X, Y):\n        X_out = np.copy(X)\n        for i in range(count):\n            #X_scale = self.scale(X, 28)\n            #X_rotate = self.rotate(X, 28)\n            #X_trans = self.translate(X, 28)\n            #X_shear = self.shear(X, 28)\n            X_compose = self.compose(X, 28)\n            #X_out = np.concatenate((X_out, X_scale), axis = 0)\n            #X_out = np.concatenate((X_out, X_rotate), axis = 0)\n            #X_out = np.concatenate((X_out, X_trans), axis = 0)\n            #X_out = np.concatenate((X_out, X_shear), axis = 0)\n            X_out = np.concatenate((X_out, X_compose), axis = 0)\n        Y = np.repeat(Y, (count*1)+1, axis = 0)\n        return X_out, Y","4b4b5947":"X = tf.placeholder(tf.float32, shape=[None, 784], name='x')\ny = tf.placeholder(tf.float32, shape=[None, 10], name='labels')","4d0806f2":"keep_prob_1 = tf.placeholder(tf.float32)\nkeep_prob_2 = tf.placeholder(tf.float32)","e1fd3e6b":"def get_W(name, values):\n    W = tf.Variable(values, name=name)\n    return W","13aa19a9":"def get_b(name, values):\n    b = tf.Variable(values, name=name)\n    return b","0e95a854":"def linear_forward(X, W, b):\n    z = tf.matmul(X, W) + b\n    return z","d8712169":"def activation_forward(X, W, b, activation):\n    z = linear_forward(X, W, b)\n    if activation == 'sigmoid':\n        return tf.nn.sigmoid(z)\n    elif activation == 'softmax':\n        return tf.nn.softmax(z)\n    elif activation == 'tanh':\n        return tf.nn.tanh(z)\n    elif activation == 'relu':\n        return tf.nn.relu(z)","da58ca53":"def fc_layer(X, n_units, name, activation):\n    W = get_W(name, tf.truncated_normal([X.shape[1].value, n_units], stddev=0.1))\n    b = get_b(name, tf.zeros([1, n_units]))\n    return activation_forward(X, W, b, activation)","1f6ab5a1":"dropout_x = tf.nn.dropout(X, keep_prob=keep_prob_1)\nfc1 = fc_layer(dropout_x, 324, 'fc1', 'relu')\ndropout_fc1 = tf.nn.dropout(fc1, keep_prob=keep_prob_2)\nfc2 = fc_layer(dropout_fc1, 100, 'fc2', 'relu')\ndropout_fc2 = tf.nn.dropout(fc2, keep_prob=keep_prob_2)\nfc3 = fc_layer(dropout_fc2, 100, 'fc3', 'relu')\ndropout_fc3 = tf.nn.dropout(fc3, keep_prob=keep_prob_2)\nfc4 = fc_layer(dropout_fc3, 100, 'fc4', 'relu')\ndropout_fc4 = tf.nn.dropout(fc4, keep_prob=keep_prob_2)\nfc5 = fc_layer(dropout_fc4, 225, 'fc5', 'relu')\ndropout_fc5 = tf.nn.dropout(fc5, keep_prob=keep_prob_2)\nout = fc_layer(dropout_fc5, 10, 'out', 'softmax')","95f21166":"epoch = 20\nlearning_rate = 5e-4\nbatch_size = 100","3613ca18":"loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=out))","ad59b222":"print(learning_rate)\ntrain = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)","e47281a4":"equal_pred = tf.equal(tf.argmax(y,1), tf.argmax(out,1))\nacc = tf.reduce_mean(tf.cast(equal_pred, tf.float32))","5e3fb956":"init = tf.global_variables_initializer()","acecb874":"#Create session and initialise global variables\nsess = tf.Session()\nsess.run(init)\naugmenter = ImageAugmenter()\n\nfor i in range(epoch):\n    start_index = 0\n    s = np.arange(X_dev.shape[0])\n    np.random.shuffle(s)\n    X_dev = X_dev[s,:]\n    T_dev = T_dev[s]\n    while start_index < X_dev.shape[0]:\n        end_index = start_index + batch_size\n        if end_index > X_dev.shape[0]:\n            end_index = X_dev.shape[0]\n        x_dev = X_dev[start_index:end_index, :]\n        y_dev = T_dev[start_index:end_index]\n        #x_dev, y_dev = augmenter.augment(1, x_dev, y_dev)\n        #print(x_dev.shape, y_dev.shape)\n        cost, _, accuracy, pred, fc = sess.run([loss, train, acc, out, fc2], \\\n                                    feed_dict={X: x_dev, y:y_dev, keep_prob_1:1, keep_prob_2:1})\n        start_index = end_index\n    t_cost, t_acc = sess.run([loss, acc], \\\n                                       feed_dict={X:X_dev, y:T_dev, keep_prob_1:1, keep_prob_2:1})\n    v_cost, v_acc = sess.run([loss, acc], \\\n                                       feed_dict={X:X_val, y:T_val, keep_prob_1:1, keep_prob_2:1})\n    X_grad, fc1_grad, fc2_grad, fc3_grad, fc4_grad, fc5_grad = \\\n                    sess.run([X, fc1, fc2, fc3, fc4, fc5], \\\n                        feed_dict={X:X_dev, y:T_dev, keep_prob_1:1, keep_prob_2:1})\n    Y_dev = np.argmax(T_dev, axis=1)\n    print(\"Epoch:\", (i+1), \"cost =\", \"{:.5f}\".format(t_cost), \"acc =\", \"{:.5f}\".format(t_acc), \\\n             \"val_cost = {:.5f}\".format(v_cost), \"val_acc = {:.5f}\".format(v_acc))","e5c88a90":"plt.imshow(X_dev[2].reshape((28,28))), np.argmax(T_dev[2])","816e08c4":"X_test = pd.read_csv('..\/input\/test.csv')","0bbf999d":"X_test = np.array(X_test)","8b4228eb":"out_test = sess.run([out], feed_dict={X:X_test, keep_prob_1:1, keep_prob_2:1})","def98e6d":"P_test = np.argmax(out_test[0], axis=1)","369eeae4":"df_out = pd.read_csv('..\/input\/sample_submission.csv')","c44360e8":"df_out['Label'] = P_test","3b156d69":"df_out.to_csv('out.csv', index=False)","79b9388c":"# Plot images","51f1e1ae":"# Graph Functions","9898e30e":"# Network Architecture","96238ff7":"We have almost equal distribution of digits.","043cec9d":"# Normalize Data","44f57c14":"# Hyperparameters","004c1e57":"# Training the model","11a6cb84":"# Placeholders for inputs and dropouts","ddbbc132":"# Initialise all variables","eeb34ece":"# Train Test Split","da93ca92":"# Load input data","ab3c43b4":"# Cost, Accuracy and Optimizer","80e29056":"# Initialise Parameters","460a43a7":"# Augmentation Implementation"}}