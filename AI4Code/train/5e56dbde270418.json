{"cell_type":{"b1be3d97":"code","b5c4fc9c":"code","9cc2274e":"code","59b80709":"code","4fb3a855":"code","87c3c26f":"code","bca376db":"code","051bec28":"code","7e4bd1df":"code","e6b3c434":"code","c822583e":"code","f95158d1":"code","919dbc42":"code","7c268ffb":"code","56144857":"code","24a88406":"code","f07f61a7":"code","a667bb35":"code","ee339fd4":"code","28f83d47":"code","3389a2f6":"code","38e67947":"code","95ace64e":"code","e6618889":"code","6b8ee2f5":"code","5e93c599":"code","2a7b9b58":"code","f97cb92d":"code","d9c625a4":"code","87156f54":"code","f0e896cc":"code","edf0dd7f":"code","382ac63f":"code","c15766ec":"code","6106504f":"code","6faa070a":"code","9c760cd6":"code","cf02811f":"code","f163d24b":"code","49e144f0":"code","8b80272d":"code","bbd4fa84":"code","6004c431":"code","78a6c462":"code","34f2f0f9":"code","a4a6ccc6":"code","2bd3eba6":"code","1673e421":"code","11a62a7a":"code","a96349b4":"code","3522eaab":"code","d82ca4f3":"markdown","53515af1":"markdown","fce92860":"markdown","db5ecd9c":"markdown","6e0416b6":"markdown","ce069b18":"markdown","b3a17229":"markdown","dc5add11":"markdown","b7c6f517":"markdown","259abe67":"markdown","3173a445":"markdown","a3b7ac3f":"markdown","e1ee3b5b":"markdown","cb040937":"markdown","8cacb9e8":"markdown","2746cc6d":"markdown","8bc08d04":"markdown","e46d11ca":"markdown","5d71426d":"markdown","9a1d76df":"markdown","b818250b":"markdown","53d9f6ff":"markdown","2effa741":"markdown","3c362990":"markdown","188e92ee":"markdown","4a3261ee":"markdown","0c6cfcc3":"markdown","29c8b13f":"markdown","fde6d6ec":"markdown","eddfe172":"markdown","0f3a0571":"markdown","6cac3a40":"markdown","606a89f7":"markdown","df77befc":"markdown","0f50218f":"markdown","b487b13d":"markdown"},"source":{"b1be3d97":"!pip install adabelief-tf --upgrade -q","b5c4fc9c":"import sys\nimport os\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n%matplotlib inline\n\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\npy.init_notebook_mode(connected=True)\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import CSVLogger\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom adabelief_tf import AdaBeliefOptimizer\nfrom mlxtend.preprocessing import minmax_scaling \nimport tensorflow as tf\nfrom keras import backend as K\nfrom sklearn.utils import class_weight\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore')","9cc2274e":"df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","59b80709":"df.sample(5)","4fb3a855":"df.describe().T","87c3c26f":"df.isnull().sum()","bca376db":"def highlight_min(s):    \n    is_max = s == s.min()\n    return ['background-color: limegreen' if v else '' for v in is_max]\ndf.describe().T.style.apply(highlight_min, subset=['min'])","051bec28":"df.info()","7e4bd1df":"fig_dims = (10, 8)\nfig, ax = plt.subplots(figsize=fig_dims)\ncorrMatrix = df.corr()\nsns.heatmap(corrMatrix, annot=True, ax=ax, cmap=\"Greens\")","e6b3c434":"df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)","c822583e":"percent_missing = df.isnull().mean().round(4) * 100","f95158d1":"trace = go.Bar(x = percent_missing.index, y = percent_missing.values ,opacity = 0.8, text = percent_missing.values.round(4),  textposition = 'auto',marker=dict(color = '#90EE90',\n        line=dict(color='#000000',width=1.25)))\n\nlayout = dict(title =  \"Missing Values (count & %)\")\n\nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","919dbc42":"col_with_null = ['Glucose', 'BloodPressure','SkinThickness','Insulin', 'BMI']","7c268ffb":"sns.pairplot(df, hue=\"Outcome\", palette=\"viridis\")","56144857":"def median_target(data, var):   \n    temp = data[data[var].notnull()]\n    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n    return temp","24a88406":"def replace_median(data, columns):\n    for i in columns:\n        f = median_target(data, i)\n        display(f)\n        data.loc[(data['Outcome'] == 0 ) & (data[i].isnull()), i] = f[[i]].values[0][0]\n        data.loc[(data['Outcome'] == 1 ) & (data[i].isnull()), i] = f[[i]].values[1][0]","f07f61a7":"replace_median(df, col_with_null)","a667bb35":"df.isnull().sum()","ee339fd4":"features = [i for i in df.columns]","28f83d47":"D = df[(df['Outcome'] != 0)]\nH = df[(df['Outcome'] == 0)]","3389a2f6":"def plot_distribution(data_select, size_bin) :  \n    \n    tmp1 = D[data_select]\n    tmp2 = H[data_select]\n    hist_data = [tmp1, tmp2]\n    \n    group_labels = ['diabetic', 'healthy']\n    colors = ['#00FA9A', '#2F4F4F']\n\n    fig = ff.create_distplot(hist_data, group_labels, colors = colors, show_hist = True, \n                             bin_size = size_bin, curve_type='kde')\n    \n    fig['layout'].update(title = data_select)\n\n    py.iplot(fig)","38e67947":"def plot_outliers(df, feat):\n    \n    trace0 = go.Box(\n        y = df[feat],\n        name = \"All Points\",\n        jitter = 0.3,\n        pointpos = -1.8,\n        boxpoints = 'all',\n        marker = dict(\n            color = 'rgb(32,178,170)'),\n        line = dict(\n            color = 'rgb(32,178,170)')\n    )\n\n    trace1 = go.Box(\n        y = df[feat],\n        name = \"Only Whiskers\",\n        boxpoints = False,\n        marker = dict(\n            color = 'rgb(0,128,128)'),\n        line = dict(\n            color = 'rgb(0,128,128)')\n    )\n\n    trace2 = go.Box(\n        y = df[feat],\n        name = \"Suspected Outliers\",\n        boxpoints = 'suspectedoutliers',\n        marker = dict(\n            color = 'rgb(0,250,154)',\n            outliercolor = '#FF69B4',\n            line = dict(\n                outliercolor = '#FF69B4',\n                outlierwidth = 2)),\n        line = dict(\n            color = 'rgb(0,250,154)')\n    )\n\n    trace3 = go.Box(\n        y = df[feat],\n        name = \"Whiskers and Outliers\",\n        boxpoints = 'outliers',\n        marker = dict(\n            color = 'rgb(47,79,79)'),\n        line = dict(\n            color = 'rgb(47,79,79)')\n    )\n\n    data = [trace0,trace1,trace2,trace3]\n\n    layout = go.Layout(\n        title = \"{} Outliers\".format(feat)\n    )\n\n    fig = go.Figure(data=data,layout=layout)\n    py.iplot(fig)","95ace64e":"def plot_all_feature():\n    for feat in features[:-1]:\n        plot_distribution(feat, 0)\n        plot_outliers(df, feat)\n    plot_outliers(df, features[-1])","e6618889":"plot_all_feature()","6b8ee2f5":"def feat_distribution_corr(feat1, feat2):\n    fig = px.density_contour(df, x=feat1, y=feat2, color=\"Outcome\", \n                             marginal_y=\"rug\", marginal_x=\"histogram\",\n\n                      title= f'{feat1} and {feat2}')\n    fig.show()","5e93c599":"for i in range(len(features)):\n    for z in range(i+1, len(features)):\n        feat_distribution_corr(features[i], features[z])","2a7b9b58":"def removeOutliers(df_out, feature, drop=False):\n\n    valueOfFeature = df_out[feature]\n    \n    # Q1 (25th percentile) for the given feature\n    Q1 = np.percentile(valueOfFeature, 25.)\n\n    # Q3 (75th percentile) for the given feature\n    Q3 = np.percentile(valueOfFeature, 75.)\n    \n    step = 1.5*(Q3-Q1)\n\n    outliers = valueOfFeature[~((valueOfFeature >= Q1 - step) & (valueOfFeature <= Q3 + step))].index.tolist()\n    feature_outliers = valueOfFeature[~((valueOfFeature >= Q1 - step) & (valueOfFeature <= Q3 + step))].values\n\n    # Remove the outliers, if specified\n    print (\"Number of outliers (inc duplicates): {} and outliers: {}\".format(len(outliers), feature_outliers))\n    if drop:\n        good_data = df_out.drop(df_out.index[outliers]).reset_index(drop = True)\n        print (\"New dataset with removed outliers has {} samples with {} features each.\".format(*good_data.shape))\n        return good_data\n    else: \n        print (\"Nothing happens, df.shape = \",df_out.shape)\n        return df_out","f97cb92d":"features","d9c625a4":"df_clean = removeOutliers(df, features[0], True)\nplot_outliers(df_clean, features[0])","87156f54":"df_clean = removeOutliers(df_clean, features[1], True)\nplot_outliers(df_clean, features[1])","f0e896cc":"df_clean = removeOutliers(df_clean, features[2], True)\nplot_outliers(df_clean, features[2])","edf0dd7f":"df_clean = removeOutliers(df_clean, features[3], True)\nplot_outliers(df_clean, features[3])","382ac63f":"df_clean = removeOutliers(df_clean, features[4], True)\nplot_outliers(df_clean, features[4])","c15766ec":"df_clean = removeOutliers(df_clean, features[5], True)\nplot_outliers(df_clean, features[5])","6106504f":"df_clean = removeOutliers(df_clean, features[6], True)\nplot_outliers(df_clean, features[6])","6faa070a":"df_clean = removeOutliers(df_clean, features[7], True)\nplot_outliers(df_clean, features[7])","9c760cd6":"df_clean = removeOutliers(df_clean, features[8], True)\nplot_outliers(df_clean, features[8])","cf02811f":"print('Original df.shape: {},-- New df.shape: {}, -- {} rows removed -- which is {}% of our data'.format(df.shape[0],df_clean.shape[0],\n                                                              df.shape[0]-df_clean.shape[0],\n                                                        (df.shape[0]-df_clean.shape[0])\/df.shape[0]*100))","f163d24b":"fig_dims = (10, 8)\nfig, ax = plt.subplots(figsize=fig_dims)\ncorrMatrix = df_clean.corr()\nsns.heatmap(corrMatrix, annot=True, ax=ax, cmap=\"Greens\")","49e144f0":"scaled_data = minmax_scaling(df_clean, columns=['Pregnancies','Glucose','BloodPressure',\n                                           'SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age'])","8b80272d":"scaled_data","bbd4fa84":"def recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))","6004c431":"def max_metric(history):\n    max_acc = max(history.history['accuracy'])\n    \n    min_loss = min(history.history['loss'])\n    max_val_acc = max(history.history['val_accuracy'])\n    \n    min_val_loss = min(history.history['val_loss'])\n    print(f\"Maximum Accuracy: {max_acc} \\n Minimum Binary CrossEntropy Loss: {min_loss} \\nMaximum Validation Accuracy: {max_val_acc} \\nMaximum Validation Binary CrossEntropy Loss: {min_val_loss} \\n\")","78a6c462":"def plot_this(history):\n    # summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\n    \n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","34f2f0f9":"def build_model():\n    model = tf.keras.Sequential([\n    tf.keras.layers.Dense(8, activation=tf.keras.layers.LeakyReLU(alpha=0.01), input_shape=[len(scaled_data.keys())]),\n    tf.keras.layers.Dense(4, activation=tf.keras.layers.LeakyReLU(alpha=0.0125)),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n  ])\n    \n    optimizer = AdaBeliefOptimizer(learning_rate=1e-3, epsilon=1e-7, rectify=False)\n   \n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])\n    return model\n\nmodel = build_model()","a4a6ccc6":"model.summary()","2bd3eba6":"class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(df_clean['Outcome']),\n                                                 df_clean['Outcome'])","1673e421":"class_weights","11a62a7a":"checkpoint_path = 'NN-{epoch:04d}.hdf5'\ncheckpoint_dir = os.path.dirname(checkpoint_path)\ncheckpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1,\n    save_best_only=True, mode='max', period=1)\nearly_stopping = EarlyStopping(monitor ='val_loss', patience=200, verbose=1)\nlog_csv = CSVLogger('my_logs.csv', separator=',', append=False)\ncallbacks_list = [checkpoint, early_stopping, log_csv]","a96349b4":"history = model.fit(scaled_data, df_clean['Outcome'], validation_split=0.20, batch_size=32, \n          workers=-1, epochs=1000, verbose=2, class_weight={0:0.73484848, 1:1.56451613}, callbacks = callbacks_list)","3522eaab":"max_metric(history)\nplot_this(history)","d82ca4f3":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Create Function For Plotting <\/h4>","53515af1":"\n<li style=\"font-size:100%; font-family:monospace\"><b>checkpoint:<\/b> save model to a specific path base on val_accuracy.<\/li>\n<li style=\"font-size:100%; font-family:monospace\"><b>early_stopping:<\/b> stop the model training if val_loss is not decrease for > 200 epochs<\/li>\n<li style=\"font-size:100%; font-family:monospace\"><b>log_csv:<\/b> create and save model training history to csv file.<\/li>\n","fce92860":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Checkpoint, EarlyStopping, CSVLogger <\/h4>","db5ecd9c":"![image.png](attachment:2d728a5c-9a96-49a3-9043-67974063a9c8.png)","6e0416b6":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Impute Missing Values with Median <\/h4>","ce069b18":"# 1. Data Exploration","b3a17229":"##### Before we begins, I would like to give credits to author of the dataset who has created [this notebook](https:\/\/www.kaggle.com\/vincentlugat\/pima-indians-diabetes-eda-prediction-0-906)","dc5add11":"<li style=\"font-size:100%; font-family:monospace\"><b><\/b>Inter Quartile Range approach to finding the outliers is the most commonly used and most trusted approach used in the research field. IQR = Q3-Q1<\/li>","b7c6f517":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Distribution of Each Feature w.r.t Label <\/h4>","259abe67":"<div class=\"alert alert-block alert-info\"> \ud83d\udccc We'll create functions to impute missing values with median since this dataset contains many outliers as we can see from the graph above<\/div>","3173a445":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Distribution of Two Features w.r.t Label <\/h4>","a3b7ac3f":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Scaling the data for ANN model <\/h4>","e1ee3b5b":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Import and Install Library <\/h4>","cb040937":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Handling Outliers <\/h4>","8cacb9e8":"# 2.1 Feature Distribution","2746cc6d":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Model Evaluation <\/h4>","8bc08d04":"<div class=\"alert alert-block alert-info\"> \ud83d\udccc replace values 0 with np.NaN to plot graph<\/div>","e46d11ca":"<h1 style=\"font-size:300%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Diabetes Prediction using Neural Networks<\/h1>","5d71426d":"<div class=\"alert alert-block alert-info\"> \ud83d\udccc Check correlation once again<\/div>","9a1d76df":"<h1 style=\"font-size:200%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Any feedback and comments are welcome, I'll also be happy to review your notebook if I have time.  Happy Kaggling!<\/h1>","b818250b":"# 2. Data Cleaning","53d9f6ff":"<li style=\"font-size:100%; font-family:monospace\"><b>Three goals of AdaBelief:<\/b> Fast convergence as in adaptive methods, good generalization as in SGD, and training stability. The intuition for AdaBelief is to adapt the stepsize according to the \"belief\" in the current gradient direction. Viewing the exponential moving average (EMA) of the noisy gradient as the prediction of the gradient at the next time step, if the observed gradient greatly deviates from the prediction, we distrust the current observation and take a small step; if the observed gradient is close to the prediction, we trust it and take a large step.<\/li>","2effa741":"<h1 style=\"font-size:300%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> We've come to an end, kindly upvote if you found this helpful and I'll have motivation to keep posting more notebooks. Thanks for reading til the end.\ud83d\ude0a<\/h1>","3c362990":"<div class=\"alert alert-block alert-info\"> \ud83d\udccc To define the outlier base value which is defined above and below datasets's normal range: Upper and Lower bounds, define the upper and the lower bound (1.5*IQR value is considered)<\/div>","188e92ee":"# 3. Modeling","4a3261ee":"<div class=\"alert alert-block alert-info\"> \ud83d\udccc The highlighted value doesn't make sense and may indicates missing values except for the \"Pregnancies\" and \"Outcome\" features<\/div>","0c6cfcc3":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Handling Missing Values <\/h4>","29c8b13f":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Create Function for Model Evaluation <\/h4>","fde6d6ec":"<div class=\"alert alert-block alert-info\"> \ud83d\udccc Here we can ignore the message, since we've updated the adabelief-tf already <\/div>","eddfe172":"# Reference\nAdaBelief:\n\nhttps:\/\/arxiv.org\/abs\/2010.07468\n\nhttps:\/\/towardsdatascience.com\/adabelief-optimizer-fast-as-adam-generalizes-as-good-as-sgd-71a919597af\n\nStatistic: \n\nhttps:\/\/www.geeksforgeeks.org\/detect-and-remove-the-outliers-using-python\/\n\nhttps:\/\/www.pluralsight.com\/guides\/cleaning-up-data-from-outliers\n\nhttps:\/\/towardsdatascience.com\/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\n\nNotebook:\n\nhttps:\/\/www.kaggle.com\/pouryaayria\/a-complete-ml-pipeline-tutorial-acu-86\n\n\n","0f3a0571":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Correlation Matrix <\/h4>","6cac3a40":"<h2 style=\"font-size:250%; font-family:monospace; color:#3CB371;\"><b>What is diabetes?<\/b><h2>\n\n<p style=\"font-size:80%; font-family:monospace\">Diabetes mellitus, commonly known as diabetes, is a metabolic disease that causes high blood sugar. The hormone insulin moves sugar from the blood into your cells to be stored or used for energy. With diabetes, your body either doesn\u2019t make enough insulin or can\u2019t effectively use the insulin it does make.<\/p>\n<p style=\"font-size:80%; font-family:monospace\">So, the objective of this project is to  predict whether or not the patients in the dataset have diabetes<\/p>\n<ul>   \n    <li style=\"font-size:80%; font-family:monospace\">The three main types of diabetes are: <b>type 1 diabetes, type 2 diabetes and gestational diabetes<\/b>.<\/li>\n<\/ul>\n    \n<h2 style=\"font-size:250%; font-family:monospace; color:#3CB371;\"><b>Dataset Information:<\/b><h2>    \n<ul>\n    <li style=\"font-size:80%; font-family:monospace\"><b>Pregnancies:<\/b> Number of times pregnant<\/li>\n    <li style=\"font-size:80%; font-family:monospace\"><b>Glucose:<\/b> Plasma glucose concentration a 2 hours in an oral glucose tolerance test<\/li>\n    <li style=\"font-size:80%; font-family:monospace\"><b>Blood Pressure:<\/b>Diastolic blood pressure (mm Hg)<\/li>\n    <li style=\"font-size:80%; font-family:monospace\"><b>Skin Thickness:<\/b> Triceps skin fold thickness (mm)<\/li>\n    <li style=\"font-size:80%; font-family:monospace\"><b>Insulin:<\/b> 2-Hour Serum Insulin (mu U\/ml)<\/li>\n    <li style=\"font-size:80%; font-family:monospace\"><b>BMI:<\/b> Body Mass Index (weight in kg\/ height in m2)<\/li>\n    <li style=\"font-size:80%; font-family:monospace\"><b>Diabetes Pedigree Function:<\/b>  It provides information about diabetes history in relatives and genetic relationship of those relatives with patients. Higher Pedigree Function means patient is more likely to have diabetes.<\/li>\n    <li style=\"font-size:80%; font-family:monospace\"><b>Age:<\/b>Age (years)<\/li>\n    <li style=\"font-size:80%; font-family:monospace\"><b>Outcome:<\/b> Class Variable (0 or 1) where \u20180\u2019 denotes patient not having diabetes and \u20181\u2019 denotes patient having diabetes.<\/li>\n<\/ul>\n","606a89f7":"<div class=\"alert alert-block alert-info\"> \ud83d\udccc create dataset that separate a person with and without diabetes to plot distribution where \"D\" represents diabetes and \"H\" represents Healthy. Then, create function to plot distribution and detect outliers<\/div>","df77befc":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Train Model <\/h4>","0f50218f":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Build Model <\/h4>","b487b13d":"<h4 style=\"font-size:150%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Class Weights Implementation for Imbalanced Data <\/h4>"}}