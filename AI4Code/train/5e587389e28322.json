{"cell_type":{"d8cc97ee":"code","c71a36b1":"code","0f275122":"code","2c0ab0b4":"code","e5909653":"code","5e5ff213":"code","d36a190b":"code","b42c2511":"code","fbfa371e":"code","ff1ac1ef":"code","00687cab":"code","93df20cb":"code","3d158f57":"code","89ffc7f9":"code","30869f2d":"code","d1604212":"code","89b6e418":"code","be9e4967":"code","138d2fbc":"code","3b82bf20":"code","6d446f03":"code","e3e6aaec":"code","32ac6ecc":"code","d9681da4":"code","20f65a27":"code","d00e0b3a":"code","aa2b5ac9":"code","79bda25f":"code","6758cc0b":"code","c94bd07f":"code","aa635697":"code","b2138940":"code","2c63948b":"code","aef2eab5":"code","8708d1d7":"code","354743a9":"code","27441e32":"code","389951b0":"code","3fc4c673":"code","d500cd13":"code","312e5523":"code","ffad8558":"code","35d04686":"code","feec52d8":"code","dd7b77e0":"code","7b0352fb":"code","2e48e8c2":"code","40e784cb":"code","b045e45e":"code","f0eaf5de":"code","55b3ad3c":"code","d92c9251":"code","944f1990":"code","024b35e9":"code","35132e05":"markdown","014dc30e":"markdown","91071c2c":"markdown","6e9d4ffa":"markdown","bf5f9071":"markdown","5009f632":"markdown","765c3d90":"markdown","4ecc7c7a":"markdown","45628748":"markdown","6c018133":"markdown","25eda948":"markdown","5024c00b":"markdown","1b74a149":"markdown","01cb3578":"markdown"},"source":{"d8cc97ee":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c71a36b1":"# Loading required python packages and libraries\nimport nltk\nimport pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport string\nimport pickle\nimport random\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom wordcloud import WordCloud,STOPWORDS\n\nstopwords = nltk.corpus.stopwords.words('english')\nps = nltk.PorterStemmer()","0f275122":"# Load the csv file using Pandas and print first 5 lines\ndata = pd.read_csv(\"..\/input\/urduromansentiment\/Roman Urdu DataSet.csv\",header=None)\ndata.head()","2c0ab0b4":"# Adding column names\ndata.columns =['body_text','sentiment','unknown']","e5909653":"# Print unique values in column 1 and 2\nprint ('Unique values of the sentiments are', data.sentiment.unique())\nprint ('Unique values of the unknonwn column are', data.unknown.unique())","5e5ff213":"# 'Neative' sentiment will be most likely Negative, so it is replaced accordingly. \ndata[data['sentiment']=='Neative']='Negative'","d36a190b":"# Verify we replaced all the 'Neative'\nprint ('Unique values of the sentiments are', data.sentiment.unique())","b42c2511":"# Checking Null values in the data\ndata.isna().sum()","fbfa371e":"# Dropping the text body row which has a null value\ndata = data.dropna(subset=['body_text'])","ff1ac1ef":"# Last column can be dropped as it does not contain any useful information. Here axis=1, means column. \ndata = data.drop('unknown', axis=1)","00687cab":"data.head()","93df20cb":"data.describe()","3d158f57":"print ('Number of sentiments in each category are as below')\nprint (data.sentiment.value_counts())\n\nprint ('\\nPerecentage sentiments in each category are as below')\nprint (data.sentiment.value_counts()\/data.shape[0]*100)\n\ndata.sentiment.value_counts().plot(kind='bar')","89ffc7f9":"# Dropping neutral sentiment sentences. \ndata = data[data.sentiment != 'Neutral']","30869f2d":"data = data.reset_index(drop=True)","d1604212":"data.head()","89b6e418":"data.sentiment.value_counts().plot(kind='bar')","be9e4967":"data.describe()","138d2fbc":"text_wordcloud = \" \".join(word.lower() for word in data.body_text)\nprint ('There are total {} words in text provided.'.format(len(text_wordcloud)))","3b82bf20":"def freq(str): \n  \n    # Break the string into list of words  \n    str = str.split()          \n    str2 = [] \n  \n    # Loop till string values present in list str \n    for i in str:              \n  \n        # Checking for the duplicacy \n        if i not in str2: \n  \n            # Append value in str2 \n            str2.append(i)  \n              \n    for i in range(0, len(str2)): \n        if(str.count(str2[i])>100): \n            print('Frequency of word,', str2[i],':', str.count(str2[i]))\n            \nfreq(text_wordcloud)","6d446f03":"UrduStopWordList = [line.rstrip('\\n') for line in open('..\/input\/urdustopwords\/stopwords.txt')]\n\nprint (UrduStopWordList)","e3e6aaec":"stopwords_with_urdu = set(STOPWORDS)\nstopwords_with_urdu.update(UrduStopWordList)\n\n\nwordcloud = WordCloud(stopwords=stopwords_with_urdu,\n                      background_color='white',\n                      width=3000,\n                      height=2500\n                     ).generate(text_wordcloud)\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","32ac6ecc":"neg_text_wordcloud = \" \".join(word.lower() for word in data[data['sentiment']=='Negative']['body_text'])\nprint ('There are total {} words in sentences with negative sentiments.'.format(len(neg_text_wordcloud)))","d9681da4":"# Plotting Plotting words in setences with negative sentiment\nwordcloud = WordCloud(stopwords=stopwords_with_urdu,\n                      background_color='white',\n                      width=3000,\n                      height=2500\n                     ).generate(neg_text_wordcloud)\nplt.figure(1,figsize=(12, 12))\nplt.title('Negative Sentiment Words',fontsize = 20)\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","20f65a27":"pos_text_wordcloud = \" \".join(word.lower() for word in data[data['sentiment']=='Positive']['body_text'])\nprint ('There are total {} words in text with positive sentements.'.format(len(pos_text_wordcloud)))","d00e0b3a":"# Plotting words in positive sentiment sentences\n\nwordcloud = WordCloud(stopwords=stopwords_with_urdu,\n                      background_color='white',\n                      width=3000,\n                      height=2500\n                     ).generate(pos_text_wordcloud)\nplt.figure(1,figsize=(12, 12))\nplt.title('Positive Sentiment Words',fontsize = 20)\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","aa2b5ac9":"data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n\npunct = string.punctuation\n\ndef count_punct(text):\n    count = sum([1 for char in text if char in punct])\n    return count\n\ndata['punct_count'] = data['body_text'].apply(lambda x: count_punct(x))\n\ndata.head()","79bda25f":"#Counting emojis in sentences\nemoji = ['\ud83d\ude1d','\ud83d\ude02','\ud83d\ude03','\ud83d\ude04','\ud83d\ude05','\ud83d\ude12','\ud83d\ude09','\ud83d\ude0d','\ud83d\ude11','\ud83d\ude25','\ud83e\udd23','\ud83d\udc83','\ud83d\udc6b','\ud83d\ude1b','\ud83d\ude09','\u2665\ufe0f','\ud83d\ude0d','\ud83d\ude48','\ud83d\udc4a','\ud83e\udd2a','\ud83d\ude18','\ud83e\udd2d','\ud83d\udc94']\n\ndef count_emoji(text):\n    count = sum([1 for char in text if char in emoji])\n    return count\n\ndata['emoji_count'] = data['body_text'].apply(lambda x: count_emoji(x))","6758cc0b":"bins = np.linspace(0, 200, 40)\n\nplt.hist(data['body_len'], bins)\nplt.title('Distribution of word count in body text')\n\nplt.show()","c94bd07f":"bins = np.linspace(0, 200, 40)\nplt.hist(data[data['sentiment']=='Negative']['body_len'], bins, density = True, alpha =0.4, label = 'Negative')\nplt.hist(data[data['sentiment']=='Positive']['body_len'], bins, density = True, alpha =0.4, label = 'Positive')\nplt.legend(loc='upper right')\nplt.title('Distribution of word count in body text by each sentiment')\nplt.show()","aa635697":"bins = np.linspace(0, 20, 10)\n\nplt.hist(data['punct_count'],bins)\nplt.title('Distribution of punctuation count in sentences')\n\nplt.show()","b2138940":"bins = np.linspace(0, 20, 10)\nplt.hist(data[data['sentiment']=='Negative']['punct_count'], bins, density = True, alpha =0.4, label = 'Negative')\nplt.hist(data[data['sentiment']=='Positive']['punct_count'], bins, density = True, alpha =0.4, label = 'Positive')\nplt.legend(loc='upper right')\nplt.title('Distribution of punctuation count in sentences')\nplt.show()","2c63948b":"plt.hist(data['emoji_count'])\nplt.title('Distribution of emoji count in body text')\nplt.show()","aef2eab5":"bins = np.linspace(0, 20, 10)\nplt.hist(data[data['sentiment']=='Negative']['emoji_count'], density = True, alpha =0.4, label = 'Negative')\nplt.hist(data[data['sentiment']=='Positive']['emoji_count'], density = True, alpha =0.4, label = 'Positive')\nplt.legend(loc='upper right')\nplt.title('Distribution of emoji count in sentences')\nplt.show()","8708d1d7":"data.head()","354743a9":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(data[['body_text', 'body_len', 'punct_count','emoji_count']],\\\n                                                    data['sentiment'], test_size=0.2,random_state=42,\\\n                                                    stratify=data['sentiment'])","27441e32":"y_train.describe()","389951b0":"def clean_text(text):\n    #Change each character to lowercase and avoid any punctuation. Finally join word back. \n    text = \"\".join([char.lower() for char in text if char not in string.punctuation])\n    \n    # Use non word characters to split the sentence\n    tokens = re.split('\\W+', text)\n\n    # Remove the stop words - commonly used words such as I, we, you, am, is etc in Urdu language \n    # that do not contribute to sentiment. \n    text = [word for word in tokens if word not in stopwords_with_urdu]\n    return text\n\ndata_clean = data['body_text'].apply(lambda x: clean_text(x))\npd.set_option('max_colwidth', 800)\ndata_clean.head(10)","3fc4c673":"# Function clean_text used to clean the sentiment data before vectorizing to remove stop words and punctuations. \n# min_df is the minimum numbers of documents a word must be present in to be kept.\n# norm is set to l2, to ensure all our feature vectors have a euclidian norm of 1 with norm='l2', but not set\n# ngram_range is set to (1, 2) to consider both unigrams and bigrams  \n\ntfidf_vect = TfidfVectorizer(analyzer=clean_text,ngram_range=(1, 2)) \ntfidf_vect_fit = tfidf_vect.fit(X_train['body_text'])\n\ntfidf_train = tfidf_vect_fit.transform(X_train['body_text'])\ntfidf_test = tfidf_vect_fit.transform(X_test['body_text'])","d500cd13":"X_train_vect = pd.concat([X_train[['body_len', 'punct_count','emoji_count']].reset_index(drop=True), \n           pd.DataFrame(tfidf_train.toarray())], axis=1)\nX_test_vect = pd.concat([X_test[['body_len', 'punct_count','emoji_count']].reset_index(drop=True), \n           pd.DataFrame(tfidf_test.toarray())], axis=1)\n\nX_train_vect.head()","312e5523":"X_train_vect.shape","ffad8558":"from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import precision_recall_fscore_support as score, roc_auc_score\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nfrom mlxtend.plotting import plot_confusion_matrix\n\nimport time","35d04686":"# Grid search on Random Forest Classifier\ndef train_RF(n_est,depth):\n    rf = RandomForestClassifier(n_estimators=n_est, max_depth=depth, n_jobs=-1,class_weight=\"balanced\")\n    rf_model = rf.fit(X_train_vect, y_train)\n    y_pred = rf_model.predict(X_test_vect)\n    precision, recall, fscore, train_support = score(y_test, y_pred, labels='Positive', average='macro')\n    print('Est: {}, Depth: {}, Precision: {} \/ Recall: {} \/ F1 score {}\/ Accuracy: {}'.format(n_est, depth,\\\n                                                            round(precision, 3), round(recall, 3), round(fscore, 3),\\\n                                                            round((y_pred==y_test).sum()\/len(y_pred), 3)))    \nfor n_est in [10,50,150,250]:\n    for depth in [10,20,30,50,None]:\n        train_RF(n_est,depth)","feec52d8":"# n_jobs = -1 for building parallel 150 decision trees. \n# Max_depth = None means it will build decision tree until minminzation of loss\nrf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1,class_weight=\"balanced\",random_state=42)\n\nrf_model = rf.fit(X_train_vect, y_train)\ny_pred_rf = rf_model.predict(X_test_vect)\n\nacc = accuracy_score(y_test, y_pred_rf)\nprecision, recall, fscore, train_support = score(y_test, y_pred_rf, labels='Positive', average='macro')\n\n\nprint('Precision: {} \/ Recall: {} \/ F1 score: {} \/Accuracy: {}'.format(round(precision, 3), round(recall, 3), round(fscore, 3),\\\n                                                                       round(acc,3)))    \nprint ('Accuracy of Random Forest Model is: {}'.format(round(acc,3)))","dd7b77e0":"print ('Labels of the classes are as below. These are required when generate classification report')\nprint (rf.classes_)","7b0352fb":"print ('Classification Report for Random Forest Classifier:\\n',classification_report(y_test, y_pred_rf,digits=3))\n#print ('\\nConfussion matrix for Random Forest Classifier:\\n'),confusion_matrix(y_test,  y_pred_rf,)","2e48e8c2":"cm = confusion_matrix(y_test,y_pred_rf)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Reds)\nplt.xticks(range(2), rf.classes_, fontsize=20)\nplt.yticks(range(2), rf.classes_, fontsize=20)\nplt.show()","40e784cb":"k = random.randint(0,data.shape[0])\nmessage = data['body_text'][k]\nmessage","b045e45e":"data['sentiment'][k]","f0eaf5de":"predict_data = [message]\ndf = pd.DataFrame(predict_data,columns=['body_text'])\ndf['body_len'] = df['body_text'].apply(lambda x: len(x) - x.count(\" \"))\ndf['punct_count'] = df['body_text'].apply(lambda x: count_punct(x))\ndf['emoji_count'] = data['body_text'].apply(lambda x: count_emoji(x))","55b3ad3c":"df","d92c9251":"tfidf_predict = tfidf_vect_fit.transform(df['body_text'])\nX_predict_vect = pd.concat([df[['body_len', 'punct_count','emoji_count']].reset_index(drop=True), \n           pd.DataFrame(tfidf_predict.toarray())], axis=1)","944f1990":"X_predict_vect","024b35e9":"rf_model.predict(X_predict_vect)","35132e05":"### Vectorize text\n\nSentiment text classifier can not directly classify text. Machine learning models mainly expect text to be tranformed into a numerical form. \n\nThis is done by converting sentences into vector of numbers. Each column indicates a word and frequency of words. This process is a way of feature extraction and termed as Bag of Words. It is called bag of words, because it does not track which words comes after another (order of words). ","014dc30e":"### Split into train\/test\n","91071c2c":"# Roman Urdu Sentiment Analysis","6e9d4ffa":"### **Data Exploration**\n\nFrom the data of sentiments, it looks like it is not balanced. There are more neutral comments than positive and negative comments. When the class distribution is unbalanced, accuracy is considered a poor choice of evaluation of classifier. This is due the fact that, it gives high scores to models which just predict the most frequent class.","bf5f9071":"### **Data Cleaning**\n\n* Make all words lowercase\n* Replace any stopwords\n\n**Frequently Used Words**\n\nIt is important to check for frequency of words. This helps to identify any missing stopwods or its variation in spelling. Stopwords are then updated if required. \n\n* First we will create a long list containing all words in the text provided. \n* Unique words are then counted and words with significant number of occurances are reported. \n* Stopwords list is updated.\n* Remaining high frequency words are then visually inspected using wordcloud by each sentiment.\n\nFrom words in worldcloud of each sentiment, it can be noted that there is some overlapp of words between three classes. Though most of the words are different and correct. ","5009f632":"### **GOAL**\n* Train a sentiment classifier (Positive, Negative, Neutral) on a corpus of the provided dataset below. \n* Maximize accuracy of the classifier with a special interest in being able to accurately detect negative sentiment.\n\n### **Data Set Description** \nClassifier model developed below uses a dataset obtained form UCI Machine Learning Repository located <a href=\"http:\/\/archive.ics.uci.edu\/ml\/datasets\/Roman+Urdu+Data+Set\">here<\/a>\n\nThis dataset is authored by Zareen Sharf, from Shaheed Zulfiqar Ali Bhutto Institute of Science and Technology (SZABIST). Data set contains sentences in Urdu languate and it is tagged for sentiements either, Positive, Negative, or Neutral.\n\nSentences in Urdu are written in plain English for word processing rather than native Urdu fonts. Data includes documents from a wide variety of sources, not merely social media, and some of it may be inconsistently\nlabeled.","765c3d90":"**Classification report for Random Forest classifier**","4ecc7c7a":"## **Feature Engineering**\n\nIn this step following new features are introduced.\n\n* Length of text field\n* Number of punctuations in the sentence body \n* TFIDF vectorization used to create vector of words\n\nIt can be noted that length of the sentence changes for different clasess. Punctuation count variation between different class is not significant. Emoji count is small but helps in improving accuracy slightly. ","45628748":"### Building Machine Learning Models","6c018133":"References:\n\n* [The Basics of Sentiment Analysis](https:\/\/monkeylearn.com\/sentiment-analysis\/)\n* [Multiclass Classification Reporting and Interpretation](https:\/\/stackoverflow.com\/questions\/30746460\/how-to-interpret-scikits-learn-confusion-matrix-and-classification-report)\n* <a href =\"https:\/\/8kmiles.com\/blog\/benchmarking-sentiment-analysis-systems\/\">Benchmarking Sentiment Analysis<\/a>\n* <a href=\"https:\/\/www.lynda.com\/Python-tutorials\/NLP-Python-Machine-Learning-Essential-Training\/622075-2.html\">NLP with Python for Machine Learning - Lynda.com Course<\/a>\n* <a href =\"https:\/\/github.com\/haseebelahi\/roman-urdu-stopwords\">Roman Urdu Stopwords<\/a>\n* <a href=\"https:\/\/www.datacamp.com\/community\/tutorials\/wordcloud-python\">Wordcloud in Python<\/a>\n* <a href=\"https:\/\/www.kaggle.com\/parthsharma5795\/comprehensive-twitter-airline-sentiment-analysis\">Airline Twitter Sentiment Analysis<\/a>\n* <a href=\"https:\/\/www.analyticsvidhya.com\/blog\/2018\/07\/hands-on-sentiment-analysis-dataset-python\/\">Hands on Guide to Twitter Sentiment Analysis<\/a>\n* <a href=\"https:\/\/stackoverflow.com\/questions\/31421413\/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case\">Stackoverflow<\/a>\n* <a href=\"https:\/\/towardsdatascience.com\/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1\">Multiclass Metric<\/a>","25eda948":"**Classification Accuracy**\n\nWhen classifying the comments by sentiments into three classes (Negative, Neutral, positive), it is important that negative comments are reported with higher accuracy. Precision and Recall allow us to check the performance of a classifier. \n\n*Precision*:\n* Precision checks out of all reported negative comments, how many are actually negative. So it checks for percentage of correct Negative Sentiments among all reported Negative sentiments\n* General definition of precision for a class is,\n    * Precision = TP\/(TP+FP)\n* If we think of it for Negative sentiments class, \n    * Precision = True Negative Sentiments\/(True Negative Sentiments + Falsely Reported Negative Sentiments)\n\n\n*Recall*:\n* Recall checks for missed positive prediction which are misclassified as false negative. \n* General definition of precision for a class is,\n    * Recall = TP\/(TP+FN)\n* For Negative sentiments class it is, \n    * Recall = True Negative Sentiments\/(True Negative Sentiments + Missed Negative Sentiments in Reported)\n\nWhen classification model improves, precision of reporting negative sentiments goes high. Other class sentiments, which are falsely reported Negative goes down. \n\nFor satisfactory performance of model, it is desired to have both high precision and high recall to get a final high accuracy. F1 score considers both precision and recall and gives a single number to compare. We need to select parameters of the model for which F1 score is high for Negative class.  \n\nFor overall accuracy of classifier, micro score is important. \n\n*How much accuracy is enough?*\n\nGenerally precision of nearly 70% is considered as a good classifier performance. This due to the fact that subtle meaning of words is perceived differently[](https:\/\/mashable.com\/2010\/04\/19\/sentiment-analysis\/) by humans and also can not be captured by machine learning models. \n\nAs per this Wikipedia [source](https:\/\/en.wikipedia.org\/wiki\/Sentiment_analysis): \n> The accuracy of a sentiment analysis system is, in principle, how well it agrees with human judgments. This is usually measured by variant measures based on precision and recall over the two target categories of negative and positive texts. However, according to [research](https:\/\/mashable.com\/2010\/04\/19\/sentiment-analysis\/) human raters typically only agree about 80% of the time (see Inter-rater reliability). Thus, a program which achieves 70% accuracy in classifying sentiment is doing nearly as well as humans, even though such accuracy may not sound impressive\n","5024c00b":"### **Plan of Work** \n\nSentiment analysis involves the following stages. \n\n* Loading and cleaning the data\n* Exploratory data analysis\n* Ommiting stop words or common words\n* Creating new features\n* Plotting most frequently used words\n* Vectorizing sentences to build a matrix\n* Training and testing the machine learning model\n* Evaluating the machine learning model accuracy","1b74a149":"**Predicting with Model**","01cb3578":"### **Data Preprocessing**\n\nIn this step, data is preprocessed or cleaned for missing column names, incorrect values of sentiments, null values present in the text body. "}}