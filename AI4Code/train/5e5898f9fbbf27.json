{"cell_type":{"b37266a7":"code","d7d50096":"code","ec57f931":"code","a408d19a":"code","eb487e95":"code","0066f999":"code","e15e1f82":"code","d897e4f9":"code","7367f631":"code","afd56608":"code","8cfefefd":"code","35eaee40":"code","db4c4913":"code","fa68de7c":"code","e43c935d":"code","47a9a46c":"code","1e456612":"code","17014806":"code","4d666404":"code","d62f7bbc":"code","5c879d5b":"code","27a9d5f6":"code","41af9129":"code","1609b843":"code","16d8c24e":"code","eeecd75c":"code","606a3b6d":"code","c2c9e194":"code","92862ae8":"code","4d0bd70f":"code","bf3f2513":"code","612c7d9f":"code","ab63503e":"code","a03e8228":"code","48914d5f":"code","618808aa":"code","2e6c95fc":"markdown","a3be0bfe":"markdown","8d6426e8":"markdown","bc077d30":"markdown","eb6d04c2":"markdown","a9c8b911":"markdown","daea2368":"markdown","26478b5f":"markdown","821e6b12":"markdown","f2f07967":"markdown","d2850087":"markdown","c39536a0":"markdown","8fea6e8e":"markdown","92585e9b":"markdown","eec45bf0":"markdown","b0e6f280":"markdown","09129bd9":"markdown","d0c3cfef":"markdown","566d5c84":"markdown","2f392c3f":"markdown","e869096e":"markdown","b01e538c":"markdown","24faeaf2":"markdown","f9675e9f":"markdown","a6cdcb86":"markdown","4b2cca95":"markdown","760208e0":"markdown","50480293":"markdown","eb3f994c":"markdown","585cc5b7":"markdown","0b432d2d":"markdown"},"source":{"b37266a7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_row',None)\nsns.set_style('darkgrid') ","d7d50096":"df = pd.read_excel('..\/input\/restaurant-dataxlsx\/Data.xlsx')\ndf.head()","ec57f931":"# Dropping unnecessary columns\ndf = df.drop(['StoreCode','DTS','Month','Date','Year','TicketCode'],axis = 1)\ndf.head()","a408d19a":"# Cheking data type of all columns\ndf.info()","eb487e95":"# Replacing null by '0' as there is no peoples when food orderd online.\ndf['PartySize'] = df['PartySize'].replace(['na'],0)\ndf.head()","0066f999":"# Normalizing text \ndf['MenuCateogry'] = df['MenuCateogry'].str.capitalize()\ndf['MenuItem'] = df['MenuItem'].str.capitalize()\ndf.head()","e15e1f82":"# Dividing data based on Weekday\nweekday = df[df['Day Type']=='Weekday']\nprint(weekday.shape)\nweekday.head()","d897e4f9":"# Dividing data based on Weekend\nweekend = df[df['Day Type']=='Weekend']\nprint(weekend.shape)\nweekend.head()","7367f631":"# Monday - WeekDay\nmonday = weekday.copy()\nmonday['Day'] = weekday['Day'].str.replace('Tuesday','Monday') \n\n# Tuseday - WeekDay\ntuesday = weekday.copy() \n\n# Wednesday - WeekEnd\nwednesday = weekend.copy()\n\n# Thusday - WeekDay\nthursday = weekday.copy()                                         \nthursday['Day'] = thursday['Day'].str.replace('Tuesday','Thursday')\n\n# Friday - WeekDay\nfriday = weekday.copy()                                          \nfriday['Day'] = friday['Day'].str.replace('Tuesday','Friday')\n\n# Saturday - WeekEnd\nsaturday = weekend.copy()                                        \nsaturday['Day'] = saturday['Day'].str.replace('Wednesday','Saturday')\n\n# Sunday - WeekEnd\nsunday = weekend.copy()                                          \nsunday['Day'] = sunday['Day'].str.replace('Wednesday','Sunday')","afd56608":"# Creating data for one week \nweek = []\nweek = pd.concat([tuesday,wednesday,thursday,friday,saturday,sunday,monday,],axis = 0)\nprint(week.shape)\nweek.head()","8cfefefd":"# Creating data for 6 Months with help of above data\nmonths = week.copy()\nx = 0\nwhile x < 25:\n    months = pd.concat([months,week],axis = 0)\n    x = x+1\nmonths.reset_index(drop=True, inplace=True)\nprint(months.shape)\nmonths.head(10)","35eaee40":"months.info()","db4c4913":"# Creating dates for dataframe.\no = pd.date_range(start='1\/1\/2019', periods=(len(months)\/100), freq='D')\ndate = []\nfor i in o:\n    for j in range(100):\n        date.append(i)\ndate = pd.DataFrame(date,columns = ['Date'])\ndate.head()","fa68de7c":"# Concating Dates and Months Dataframe\nfinal = pd.concat([date,months],axis = 1)\nfinal.head()","e43c935d":"# Changing Columns Postions for better understanding\nfinal = final[['Date', 'Shift', 'Day Type', 'Day', 'PartySize', 'MenuCateogry','MenuItem', 'ItemPrice', 'ItemQty']]\nfinal = final.iloc[:18100,:]\nfinal.head()","47a9a46c":"final.info()","1e456612":"df  = final\ndf.head()","17014806":"# Extracting Two Columns for visualization purpose.\nproduct_1 = df[['MenuItem','ItemQty']]\n\n# Combining two rows 'MenuItem' and 'ItemQty' for Analysis and multiplying based on ItemQty\nproduct = product_1.loc[product_1.index.repeat(product_1.ItemQty)].reset_index(drop=True)\nproduct = product[['MenuItem']]\nproduct.head()","4d666404":"#pip install WordCloud  # Kindly install WordCloud package for furthur process \n# Joinining all the reviews into single paragraph  \nspeaker_rev_string1 = \" \".join(product['MenuItem'])\nfrom wordcloud import WordCloud\nwordcloud_sp = WordCloud(width=6000,height=1800).generate(speaker_rev_string1)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.imshow(wordcloud_sp)","d62f7bbc":"p = pd.DataFrame(product_1.groupby(['MenuItem']).sum())\np = p.reset_index()\np.sort_values(by=['ItemQty'], inplace=True,ascending=False)\nplt.figure(figsize=(35,8))\nchart = sns.barplot(x=\"MenuItem\", y=\"ItemQty\", data=p)\nplt.xticks(rotation=90)","5c879d5b":"df = df[['Date','Shift','MenuItem','ItemQty']]\ndf.head()","27a9d5f6":"# Preparing data to use to make Cross Table\nnew = df.loc[df.index.repeat(df.ItemQty)]\nnew = new[['Date','Shift','MenuItem']]\nnew.head(10)","41af9129":"# Shifting Table\ntable = pd.DataFrame(pd.crosstab(new.Date,[new.Shift,new.MenuItem]))\ntable.head()","1609b843":"# Normalizing Table Names.\ntable.columns = table.columns.map('{0[1]}-{0[0]}'.format) \nprint(table.shape)\ntable.head()","16d8c24e":"\nplt.figure(figsize=(5,60))\nplt.rcParams[\"figure.figsize\"] = [35, 8]\ntable.plot(legend = False)\n# We Can see that data follows seasonality","eeecd75c":"Train = table[:int(0.85*(len(table)))]\nTest = table[int(0.85*(len(table))):]\nprint(Train.shape,Test.shape)","606a3b6d":"from statsmodels.tsa.holtwinters import SimpleExpSmoothing \nfrom statsmodels.tsa.holtwinters import Holt \nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing \nimport warnings\nwarnings.filterwarnings('ignore')","c2c9e194":"p = []\nfor i in table.columns:\n    hwe_model_add_add = ExponentialSmoothing(Train[i],seasonal=\"add\",trend=\"add\",seasonal_periods=7).fit()\n    pred_hwe_add_add = hwe_model_add_add.predict(start = Test.index[0],end = Test.index[-1])\n    rmse_hwe_add_add = np.sqrt(np.mean((Test[i]-pred_hwe_add_add)**2))\n    p.append(round(rmse_hwe_add_add,3))\np = pd.DataFrame(p, columns = ['Winter_Exponential_Smoothing_RMSE'])","92862ae8":"q = []\nfor j in table.columns:\n    hw_model = Holt(Train[j]).fit()\n    pred_hw = hw_model.predict(start = Test.index[0],end = Test.index[-1])\n    rmse_hw = np.sqrt(np.mean((Test[j]-pred_hw)**2))\n    q.append(round(rmse_hw,3)) \np['Holt method Model_RMSE']= pd.DataFrame(q, columns = ['Holt method Model_RMSE'])","4d0bd70f":"r = []\nfor o in table.columns:\n    ses_model = SimpleExpSmoothing(Train[o]).fit()\n    pred_ses = ses_model.predict(start = Test.index[0],end = Test.index[-1])\n    rmse_ses = np.sqrt(np.mean((Test[o]-pred_ses)**2))\n    r.append(round(rmse_ses,3)) # 0.49\np['Simple Exponential Mode_RMSE']= pd.DataFrame(r, columns = ['Simple Exponential Mode_RMSE'])","bf3f2513":"p.head()","612c7d9f":"p.sum()","ab63503e":"def Daily_menu_forcasting(table,start_date,end_date):\n    da = pd.date_range(start = start_date, end = end_date , freq='D')\n    for_pred = pd.DataFrame(da,columns = ['Date'] )\n    for_pred = for_pred.set_index('Date')\n    for i in table.columns:\n        hwe_model_add_add = ExponentialSmoothing(table[i],seasonal=\"add\",trend=\"add\",seasonal_periods=7).fit()\n        pred_hwe_add_add = hwe_model_add_add.predict(start = for_pred.index[0],end = for_pred.index[-1])\n        for_pred[i]=((round(pred_hwe_add_add)).astype(int))\n    final_pred =  for_pred\n    p = pd.DataFrame(final_pred.stack())\n    p = p.reset_index()\n    p[['MenuItem','Shift']] = p.level_1.str.split(\"-\",expand=True,)\n    p = p.rename(columns={0: \"ItemQty\"})\n    p = p[['Date','Shift','MenuItem',\"ItemQty\"]]\n    p = p[p['ItemQty'] != 0]\n    # Makind Dataframe with dinner and lunch columns\n    new = p.loc[p.index.repeat(p.ItemQty)]\n    f = pd.DataFrame(pd.crosstab([new.Date,new.MenuItem],[new.Shift]))\n    f = f.reset_index()\n\n    # Shorting Data Frame on the basis top item\n    f['Total orders of Day'] = f.Dinner + f.Lunch\n    f = f.sort_values(['Date', 'Total orders of Day'], ascending=[True, False]).reset_index(drop= True)\n    f\n    Daily_req_FiNal_Ans = f.copy()\n    return Daily_req_FiNal_Ans","a03e8228":"def Daily_top_menu_forcasting(table,start_date,end_date,N=5):\n    da = pd.date_range(start = start_date, end = end_date , freq='D')\n    for_pred = pd.DataFrame(da,columns = ['Date'] )\n    for_pred = for_pred.set_index('Date')\n    for i in table.columns:\n        hwe_model_add_add = ExponentialSmoothing(table[i],seasonal=\"add\",trend=\"add\",seasonal_periods=7).fit()\n        pred_hwe_add_add = hwe_model_add_add.predict(start = for_pred.index[0],end = for_pred.index[-1])\n        for_pred[i]=((round(pred_hwe_add_add)).astype(int))\n    final_pred =  for_pred\n    p = pd.DataFrame(final_pred.stack())\n    p = p.reset_index()\n    p[['MenuItem','Shift']] = p.level_1.str.split(\"-\",expand=True,)\n    p = p.rename(columns={0: \"ItemQty\"})\n    p = p[['Date','Shift','MenuItem',\"ItemQty\"]]\n    p = p[p['ItemQty'] != 0]\n    # Makind Dataframe with dinner and lunch columns\n    new = p.loc[p.index.repeat(p.ItemQty)]\n    f = pd.DataFrame(pd.crosstab([new.Date,new.MenuItem],[new.Shift]))\n    f = f.reset_index()\n\n    # Shorting Data Frame on the basis top item\n    f['Total orders of Day'] = f.Dinner + f.Lunch\n    f = f.sort_values(['Date', 'Total orders of Day'], ascending=[True, False]).reset_index(drop= True)\n    f\n    # Finding Topr product for days.\n    name =((f['Date'].astype(str)).unique()).tolist()\n    t = pd.DataFrame(columns = f.columns)\n    for i in name:\n        v = pd.DataFrame((f[f['Date']==i]).head(N))\n        t = pd.concat([t,v],axis = 0)\n    Daily_top_FiNal_Ans = t.reset_index(drop = True)\n    return(Daily_top_FiNal_Ans)","48914d5f":"all_menu = Daily_menu_forcasting(table,'7\/1\/2019','7\/7\/2019')\nall_menu.head(10) # top manu day wise","618808aa":"# Here N = 8\ntop_8_menu = Daily_top_menu_forcasting(table,'7\/1\/2019','7\/7\/2019',8)\ntop_8_menu.head(10)","2e6c95fc":"Creating data for each day in a week as per the limitations and information we have.","a3be0bfe":"### 3rd Model:- \n**Simple Exponential Mode**","8d6426e8":"After removing unnecessary columns and imputing null values of the dataset, as shown above, We are ready for data preparation as per the pattern provided above.","bc077d30":"### 2. Barplot","eb6d04c2":"### 1st Function:-\nForecast the demand for all items and normalize the arrangement of Dataframe in Lunch and dinner formate.\n\n**Input parameters-**\n\n***table***\u200a-\u200aHistorical Dataframe after modification.\n\n***start_date***\u200a-\u200aFirst date of the period which we want to predict.\n\n**end_date** -\u200aLast date of the period which we want to predict.","a9c8b911":"## Conclusion -\nWe successfully forecast the demand for restaurant food items on the menu for Lunch and dinner for a given time period and also identify top items on the menu. This article shows one of many ways of demand forecasting implementation, according to me it is one of the best ways of handling multivariate forecasting business problems.","daea2368":"## **Implementation -**","26478b5f":"Looking Behavior of above Data","821e6b12":"# Multivariate Time Series Restaurant Demand forecasting","f2f07967":"Sum of RMSE's model wise.","d2850087":"### For total items.","c39536a0":"RMSE Data Frame of each model for each item.","8fea6e8e":"## 3) Model Building\nIn order to build a model firstly, we are modifying some arrangements of the table to facilitate multivariate forecasting.","92585e9b":"### 2nd Model:- \n**Holt Method Model**","eec45bf0":"### For top N items.","b0e6f280":"After creating data for one week now we have to expanding it for 6 months with the same pattern. So we are writing a function for it.","09129bd9":"## Here our Data Preparation is finally completed, we maintain all patterns and consider other constraints so that data matches real-world data.\n### Now we use final data for further Process.","d0c3cfef":"Now final Demand forecasting of items on the menu for future dates (Monday to Sunday, July 1st to July 7th) is.","566d5c84":"### 2nd Function:-\nForecast the demand for top N items and normalize the arrangement of Dataframe in Lunch and dinner formate.\n\n**Input parameters-**\n\n***table***\u200a-\u200aHistorical Dataframe after modification.\n\n***start_date***\u200a-\u200aFirst date of the period which we want to predict.\n\n**end_date**\u200a-\u200aLast date of the period which we want to predict.\n\n**N**\u200a-\u200aNumber of the top items we want. (default n=5)","2f392c3f":"**Splitting Data into Train and Test.**\n\nFor the time series model we can not split our data randomly we should follow seasonilty pattern of data while splitting. So we are splitting as follows.","e869096e":"## 4) Building Functions\nWe are building two different functions first one is to forecast the demand for all items in the menu and the second one is to forecast the demand of the top N item on the menu.\n","b01e538c":"### ***Please upvote if you find this Notbook is helpful and thank you so much for giving your valuable time.***\nfor more information about multivariate time series  and data science please visit\nhttps:\/\/medium.com\/@nilaydeshmukh\n\nMy Linkedin - https:\/\/www.linkedin.com\/in\/nilaydeshmukh\/","24faeaf2":" ## **Business Problem and Limitations -**\n\n Our dataset is for restaurant sales for Tuesday and Wednesday, both lunch and dinner time.\n \nThere are few instances of 'To-Go' orders like Uber Eats in this dataset.\n \nTypical lunch hour is 11:30 AM-2:00 PM, and dinner hour is 6:30 PM-10:00 PM\n \nThe data set is just for Tuesday and Wednesday.\nWe needs to expand and randomize the data for min. of 6 months (Jan. 2019 to June 2019) for all days of the week.\n\nA typical restaurant has high covers (number of customers) on Wednesday, Weekend Dinner, followed by Weekend Lunch, and then relatively low covers for Monday to Friday Lunch.\n \nThe data expansion\/randomization should follow the above pattern for the number of customers.\n\n### **Our Gole\u00a0-**\nPredict the top 'Menu Item' and 'Item Qty' for Lunch and Dinner.\u00a0\nThese predictions need to be for future dates (Monday to Sunday, July 1st to July 7th)","f9675e9f":"### 1. Word Cloud","a6cdcb86":"**Now we are building different models for each item of the menu and make a data frame of respective RMSE to detect which model is best among all.**","4b2cca95":"## **2) Visualization**","760208e0":"### 1st Model:-\n**Winter Exponential Smoothing with Additive Seasonality and Additive Trend Model**","50480293":"For this data, we are using a Data-driven time series model such as smoothing techniques.\n\nImporting libraries necessary for model building","eb3f994c":"## **1) Data Preparation and Preprocessing**","585cc5b7":"As in our dataset, Wednesday is given as weekend and it's only available weekend data, So we are using it as it is for further data preparation.\nNow we are dividing data into two groups first one is a weekday and another one is the weekend.","0b432d2d":"### **From above we can see that Winters Exponential Smoothing with a seasonality of 7 showing less RMSE values as compare to others, So we are selecting it as the final model for our prediction.**"}}