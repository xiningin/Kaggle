{"cell_type":{"cab074e2":"code","c8b36dd9":"code","d22dd974":"code","5dcbc2ba":"code","35b87a9e":"code","a9dd5b52":"code","f051d2d3":"code","e2205ade":"code","e8324269":"code","a2e7c624":"code","74e546eb":"code","75821c2c":"code","79475551":"markdown","b40eb3d3":"markdown"},"source":{"cab074e2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfrom glob import glob\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\n\nimport warnings\nwarnings.filterwarnings('ignore')","c8b36dd9":"path = \"..\/input\/rockpaperscissors\/*\/*.png\"\n\nall_files = glob(path)\n\nlen(all_files)","d22dd974":"images = []\nlabels = []\n\nfor path in all_files:\n    \n    img = load_img(path, target_size=(100,100))\n    img = img_to_array(img, dtype=np.uint8)\n    images.append(img)\n    \n    label = path.split(\"\/\")[-2]\n    labels.append(label)","5dcbc2ba":"images = np.array(images)\n\nlabel_encoder = LabelEncoder()\nlabels = label_encoder.fit_transform(labels)\n\nimages.shape, labels.shape","35b87a9e":"CLASSES = label_encoder.classes_.tolist()\nCLASSES","a9dd5b52":"X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, random_state=1)\n\nX_train.shape, y_train.shape","f051d2d3":"fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(15,15))\naxs = np.ravel(axs)\n\nfor i in range(len(axs)):\n    plt.sca(axs[i])\n    plt.imshow(X_train[i])\n    plt.axis('off')\n    \nplt.show()","e2205ade":"X_train_scaled = X_train \/ 255.0\nX_test_scaled = X_test \/ 255.0\n\ny_train_oh = to_categorical(y_train, num_classes=3)\ny_test_oh = to_categorical(y_test, num_classes=3)","e8324269":"tf.random.set_seed(10)\n\nmodel = Sequential([\n    Conv2D(256, 3, padding='same', activation='relu', input_shape=X_train[0].shape),\n    BatchNormalization(),\n    MaxPooling2D(),\n    Conv2D(256, 3, padding='same', activation='relu', input_shape=X_train[0].shape),\n    BatchNormalization(),\n    MaxPooling2D(),\n    Conv2D(256, 3, padding='same', activation='relu', input_shape=X_train[0].shape),\n    BatchNormalization(),\n    MaxPooling2D(),\n    Conv2D(256, 3, padding='same', activation='relu', input_shape=X_train[0].shape),\n    BatchNormalization(),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(1024, 'relu'),\n    Dropout(0.5),\n    Dense(256, 'relu'),\n    Dropout(0.2),\n    Dense(3, 'softmax')\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(X_train_scaled, y_train_oh, batch_size=32, epochs=10, validation_data=(X_test_scaled, y_test_oh))","a2e7c624":"predictions = model.predict(X_test_scaled).argmax(axis=1)","74e546eb":"confusion_matrix(y_test, predictions)","75821c2c":"model.save(\"RockPaperScissors_100x100_color_99_v1.h5\")","79475551":"## Base Model","b40eb3d3":"## Loading Images"}}