{"cell_type":{"042f39db":"code","e5d0d6e1":"code","2953a022":"code","bb9c9ebd":"code","ff82b961":"code","2b9fbedc":"code","2cd0d37c":"code","141ec09f":"code","df6939b8":"code","d7ca87fb":"code","7d4680dd":"code","bcd6621f":"code","4d87e382":"code","99c41acf":"code","eff898c9":"code","43586e08":"code","24a39979":"code","9a7389c6":"code","2f498d16":"code","f1f59a7a":"code","e94e5a9c":"code","49215649":"code","a30944f0":"code","3af527d3":"code","b3810654":"code","b7c203c9":"code","b1a1d689":"markdown","35235c80":"markdown","432354a4":"markdown","26944fed":"markdown","72b28dc2":"markdown","d6fd6cf4":"markdown","f0eb1c45":"markdown"},"source":{"042f39db":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nimport lightgbm as lgb\nfrom tqdm import tqdm\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestRegressor","e5d0d6e1":"INPUT_PATH = '\/kaggle\/input\/liverpool-ion-switching'\ntrain_df = pd.read_csv(os.path.join(INPUT_PATH, 'train.csv'))\ntest_df = pd.read_csv(os.path.join(INPUT_PATH, 'test.csv'))\nsample_sub_df = pd.read_csv(os.path.join(INPUT_PATH, 'sample_submission.csv'))","2953a022":"sns.set(rc={'figure.figsize':(11,8)})\nsns.set(style=\"whitegrid\")","bb9c9ebd":"train_df.head()","ff82b961":"test_df.head()","2b9fbedc":"sample_sub_df.head()","2cd0d37c":"print(f'Shape of training dataset: {train_df.shape}')\nprint(f'Shape of test dataset: {test_df.shape}')","141ec09f":"train_df.info()","df6939b8":"train_df.nunique()","d7ca87fb":"def print_description(df, column):\n    print(f'Column: {column}: Min: {df[column].min()} Max: {df[column].max()} Mean: {df[column].mean()}')","7d4680dd":"print_description(train_df, 'open_channels')\nprint_description(train_df, 'signal')","bcd6621f":"sns.distplot(train_df['signal'], kde=False)\nplt.show()","4d87e382":"sns.distplot(train_df['open_channels'], kde=False)\nplt.show()","99c41acf":"# Visualize signals of all the different batches\nfig, ax = plt.subplots(nrows=2, ncols=5, figsize=(16, 8))\ncount=0\nfor row in ax:\n    for col in row:\n        col.title.set_text(f'Batch #{count}')\n        col.bar(train_df['open_channels'][count*500000: (count+1)*500000].value_counts().index.values, train_df['open_channels'][count*500000: (count+1)*500000].value_counts().values)\n        count += 1\nplt.show()","eff898c9":"# Visualize signals of all the different batches\nfig, ax = plt.subplots(nrows=2, ncols=5, figsize=(16, 8))\ncount=0\nfor row in ax:\n    for col in row:\n        col.title.set_text(f'Batch #{count}')\n        col.plot(train_df['time'][count*500000: (count+1)*500000], train_df['signal'][count*500000: (count+1)*500000])\n        count += 1\nplt.show()","43586e08":"window_sizes = [50, 100, 1000, 5000, 10000, 25000]\nfor window in window_sizes:\n    train_df[f'rolling_mean{window}'] = train_df['signal'].rolling(window).mean()\n    train_df[f'rolling_std{window}'] = train_df['signal'].rolling(window).std()\n    train_df[f'rolling_min{window}'] = train_df['signal'].rolling(window).min()\n    train_df[f'rolling_max{window}'] = train_df['signal'].rolling(window).max()\n    a = (train_df['signal'] - train_df['rolling_min' + str(window)]) \/ (train_df['rolling_max' + str(window)] - train_df['rolling_min' + str(window)])\n    train_df[\"norm\" + str(window)] = a * (np.floor(train_df['rolling_max' + str(window)]) - np.ceil(train_df['rolling_min' + str(window)]))\n    \ntrain_df = train_df.fillna(train_df.mean())","24a39979":"X_train = train_df.drop(['time', 'open_channels'], axis=1)\nY_train = train_df['open_channels']","9a7389c6":"scaler = StandardScaler()\nscaler.fit(X_train)\nX_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)","2f498d16":"for window in window_sizes:\n    test_df[f'rolling_mean{window}'] = test_df['signal'].rolling(window).mean()\n    test_df[f'rolling_std{window}'] = test_df['signal'].rolling(window).std()\n    test_df[f'rolling_min{window}'] = test_df['signal'].rolling(window).min()\n    test_df[f'rolling_max{window}'] = test_df['signal'].rolling(window).max()\n    a = (test_df['signal'] - test_df['rolling_min' + str(window)]) \/ (test_df['rolling_max' + str(window)] - test_df['rolling_min' + str(window)])\n    test_df[\"norm\" + str(window)] = a * (np.floor(test_df['rolling_max' + str(window)]) - np.ceil(test_df['rolling_min' + str(window)]))\n    \ntest_df = test_df.fillna(test_df.mean())","f1f59a7a":"test_df = test_df.drop('time', axis=1)","e94e5a9c":"test_df = pd.DataFrame(scaler.transform(test_df), columns=test_df.columns)","49215649":"print(f'Shape of training dataset after feature extraction: {X_train.shape}')\nprint(f'Shape of test dataset after feature extraction: {test_df.shape}')\nprint(f'Shape of training labels: {Y_train.shape}')","a30944f0":"folds = 10\nseed = 666\n\nkf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n\nmodels = []\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, Y_train)):\n    x_train = X_train.iloc[train_index]\n    x_val = X_train.iloc[val_index]\n    \n    y_train = Y_train.iloc[train_index]\n    y_val = Y_train.iloc[val_index]\n    \n    rgsr = RandomForestRegressor(n_estimators=16, \n                                 oob_score=True, \n                                 n_jobs=-1,\n                                 verbose=100,\n                                 random_state=seed)\n    rgsr.fit(x_train, y_train)\n    \n    score = rgsr.score(x_val, y_val)\n    \n    print(f'[{fold}] score: {score}')\n    \n    models.append(rgsr)","3af527d3":"predictions = sum([model.predict(test_df) for model in tqdm(models, total=folds)]) \/ folds\npredictions","b3810654":"sample_sub_df['open_channels'] = predictions\nsample_sub_df['open_channels'] = sample_sub_df['open_channels'].apply(lambda x: int(x))  # Converting into int \nsample_sub_df.loc[sample_sub_df['open_channels'] < 0, 'open_channels'] = 0  # Clipping the -ve values\nsample_sub_df.to_csv('submission.csv', index=False, float_format='%.4f')\nsample_sub_df.head()","b7c203c9":"sample_sub_df['open_channels'].unique()","b1a1d689":"### Distribution of Target variable","35235c80":"### Making Predictions","432354a4":"### Feature Extraction","26944fed":"### Defining and training the Model using Cross Validation","72b28dc2":"### Distribution of Signals","d6fd6cf4":"### Batchwise signal distributation","f0eb1c45":"### Batchwise target distribution"}}