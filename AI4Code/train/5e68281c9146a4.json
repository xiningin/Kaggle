{"cell_type":{"3f1384bb":"code","cffa7468":"code","a7a17913":"code","ebd379ff":"code","eb1cf37e":"code","d9d65e35":"code","06c5f747":"code","d55b8a48":"code","7b41b023":"code","554b02ee":"code","23033177":"code","bc9c9d68":"code","f9947043":"code","d070e5f3":"code","963f986e":"code","2ae4ae66":"code","ca41b971":"code","fe681985":"code","733e1adc":"code","40febbac":"code","aed522cc":"code","edb086ed":"code","f8617bd3":"code","127e584c":"code","2d6873e8":"code","e424467f":"code","0dad6a2b":"code","c1aef126":"code","cb550411":"code","85c498e6":"code","c1834bed":"code","b5c1eb99":"code","c6ea88df":"code","b4b8badf":"code","c2936747":"code","5d1ec673":"code","ec4e6729":"code","b3d88d2f":"code","98d814a0":"code","5734c866":"code","2480fa6c":"code","ce35152e":"code","b731375d":"code","37adffba":"code","8c07d8ed":"code","194950f7":"code","ccef85cc":"code","584f9156":"code","277c4c58":"code","7efa1585":"code","33dda80e":"code","39b79226":"code","dc042206":"code","f0cbc90c":"code","3b8753d3":"code","0df157e7":"code","f63d0c43":"code","d265d2d3":"code","c15fbdcb":"code","0bbb1477":"code","0bdd57f8":"code","d0a7af1d":"code","bdc0021f":"code","1ab20992":"code","db32b459":"code","4e1d9cee":"code","308cfe29":"code","35c27046":"code","5d278a1e":"markdown","1ef89e4b":"markdown","d3e0dc28":"markdown","e9f2f5e4":"markdown","47965137":"markdown","cecd1bec":"markdown","4c23bd68":"markdown","c391e99a":"markdown","ec6e90ac":"markdown","b3f67a46":"markdown","69b37f24":"markdown","eb00c4a1":"markdown"},"source":{"3f1384bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nplt.style.use(\"ggplot\")\nimport plotly\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n!pip install chart_studio\nimport chart_studio.plotly as py\nfrom plotly.offline import iplot\nfrom plotly.offline import init_notebook_mode, iplot # plotly offline mode\ninit_notebook_mode(connected=True) \nimport plotly.graph_objs as go # plotly graphical object\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cffa7468":"data1=pd.read_csv(\"..\/input\/uncover\/apple_mobility_trends\/mobility-trends.csv\")\n# great data to make time series !","a7a17913":"print(data1.info())\nprint('')\ndata1.head()","ebd379ff":"data1['date'] = pd.to_datetime(data1['date'], errors='coerce',format='%Y-%m-%d %H:%M') \n#We need to change date features to datetime for time series analysis.\ndata1.info()","eb1cf37e":"data1['year'] = data1['date'].dt.year\ndata1['month'] = data1['date'].dt.month\ndata1['week'] = data1['date'].dt.week\ndata1['day'] = data1['date'].dt.day\ndata1['day_of_week'] = data1['date'].dt.dayofweek\ndata1.head()\n#day of week 0: monday \n#day of week 6: sunday","d9d65e35":"data1=data1.sort_values(by='date') #Sorting data.","06c5f747":"driving=data1.loc[data1[\"transportation_type\"]=='driving']\nwalking=data1.loc[data1[\"transportation_type\"]=='walking']\ntransit=data1.loc[data1[\"transportation_type\"]=='transit']","d55b8a48":"plt.figure(figsize=(12,8))\nax = sns.barplot(x=driving.groupby('week').value.mean().index, \n                 y=driving.groupby('week').value.mean().values, data=driving)\nax.set_title('Mobility in driving')\nax.set_ylabel('Value');","7b41b023":"plt.figure(figsize=(12,8))\nax = sns.barplot(x=walking.groupby('week').value.mean().index, \n                 y=walking.groupby('week').value.mean().values, data=walking)\nax.set_title('Mobility in walking')\nax.set_ylabel('Value');","554b02ee":"plt.figure(figsize=(12,8))\nax = sns.barplot(x=transit.groupby('week').value.mean().index, \n                 y=transit.groupby('week').value.mean().values, data=transit)\nax.set_title('Mobility in transit')\nax.set_ylabel('Value');","23033177":"data1_11=data1.loc[data1[\"week\"]>=11]\ndata1_11.head()","bc9c9d68":"walking_11=walking.loc[walking[\"week\"]>=11]\ndriving_11=driving.loc[driving[\"week\"]>=11]\ntransit_11=transit.loc[transit[\"week\"]>=11]","f9947043":"f, axes = plt.subplots(1, 3, figsize=(10,3))\nsns.barplot(  y=walking_11.groupby('day_of_week').value.mean().values,\n            x= walking_11.groupby('day_of_week').value.mean().index,\n            data=walking_11,  orient='v' , ax=axes[0])\naxes[0].set(xlabel=\"Walking day of week\", ylabel = \"Value\")\nsns.barplot(  y=driving_11.groupby('day_of_week').value.mean().values,\n            x= driving_11.groupby('day_of_week').value.mean().index,\n            data=driving_11,  orient='v' , ax=axes[1])\naxes[1].set(xlabel=\"Driving day of week\")\nsns.barplot(  y=transit_11.groupby('day_of_week').value.mean().values,\n            x= transit_11.groupby('day_of_week').value.mean().index,\n            data=transit_11,  orient='v' , ax=axes[2])\naxes[2].set(xlabel=\"Transit day of week\")\nax.set_title('Mobility in transit')\nax.set_ylabel('Value');","d070e5f3":"daily=data1.resample('D', on = 'date').mean() #daily mean\ndaily=daily[['value']]\nplt.figure(figsize=(25,5))\ndaily.plot(kind = 'line')\nplt.show();","963f986e":"f,ax=plt.subplots(3,1,figsize=(16,9))\n\ndf1 = data1.resample('M', on='date').mean()\ndf1=df1[['value']]\ndf2 = data1.resample('W', on='date').mean()\ndf2=df2[['value']]\ndf3 = data1.resample('D', on='date').mean()\ndf3=df3[['value']]\n\ndf1['value'].plot(ax = ax[0], color = '#DAA520')\nax[0].set_title('Mean Value (monthly)')\nax[0].set_xlabel('')\nax[0].set_ylabel('Mobility Value')\n\ndf2['value'].plot(ax = ax[1], color = '#778899')\nax[1].set_title('Mean Delay (weekly)')\nax[1].set_xlabel('')\nax[1].set_ylabel('Mobility Value')\n\ndf3['value'].plot(ax = ax[2], color = '#FF69B4')\nax[2].set_title('Mean Delay (daily)')\nax[2].set_xlabel('')\nax[2].set_ylabel('Mobility Value')\n\nf.subplots_adjust(hspace=0.6)\nplt.show()","2ae4ae66":"data1=data1[['date','value']]","ca41b971":"trace=go.Scatter(x=list(data1.date), y=list(data1.value), line=dict(color='#990000'))\ndata=[trace]\nlayout=dict(\n    title='Mobility Value',\n    xaxis=dict(\n        rangeselector=dict(\n        buttons=list([\n            dict(step='all')])\n        ),\n        rangeslider=dict(visible=True),\n        type='date'))\nfig=dict(data=data,layout=layout)\n\nimport plotly.io as pio\npio.show(fig)","fe681985":"import fbprophet\n\ndata1=data1.rename(columns={'date':'ds' , 'value' : 'y'})\nfbp=fbprophet.Prophet()\nfbp.fit(data1)","733e1adc":"data1_forecast=fbp.make_future_dataframe(periods=6,freq='W') #adding 6 weeks of data\ndata1_forecast=fbp.predict(data1_forecast)\nfbp.plot(data1_forecast, xlabel='Date', ylabel='Mobility Value')","40febbac":"data2=pd.read_csv(\"..\/input\/uncover\/New_York_Times\/covid-19-county-level-data.csv\")","aed522cc":"data2.head()","edb086ed":"data2['county'].value_counts()[:10]","f8617bd3":"washington=data2.loc[data2['county'] == \"Washington\"]\njefferson=data2.loc[data2['county'] == \"Jefferson\"]\nfranklin=data2.loc[data2['county'] == \"Franklin\"]\njackson=data2.loc[data2['county'] == \"Jackson\"]","127e584c":"washington['date'].min(), washington['date'].max()","2d6873e8":"washington = washington.sort_values('date')\njefferson = jefferson.sort_values('date')\nfranklin = franklin.sort_values('date')\njackson = jackson.sort_values('date')\n\ncol=['county','state','fips']\nwashington.drop(col, axis=1, inplace=True)\njefferson.drop(col, axis=1, inplace=True)\nfranklin.drop(col, axis=1, inplace=True)\njackson.drop(col, axis=1, inplace=True)\n\nwashington=washington.groupby('date')['cases','deaths'].sum().reset_index()\njefferson=jefferson.groupby('date')['cases','deaths'].sum().reset_index()\nfranklin=franklin.groupby('date')['cases','deaths'].sum().reset_index()\njackson=jackson.groupby('date')['cases','deaths'].sum().reset_index()\n\n\nwashington=washington.set_index('date')\njefferson=jefferson.set_index('date')\nfranklin=franklin.set_index('date')\njackson=jackson.set_index('date')","e424467f":"washington.head()","0dad6a2b":"washington.plot(figsize=(10, 4))\nplt.show()","c1aef126":"jefferson.plot(figsize=(10, 4))\nplt.show()","cb550411":"franklin.plot(figsize=(10, 4))\nplt.show()","85c498e6":"jackson.plot(figsize=(10, 4))\nplt.show()","c1834bed":"data3=pd.read_csv(\"..\/input\/uncover\/USAFacts\/confirmed-covid-19-deaths-in-us-by-state-and-county.csv\")\ndata4=pd.read_csv(\"..\/input\/uncover\/USAFacts\/confirmed-covid-19-cases-in-us-by-state-and-county.csv\")","b5c1eb99":"data3_group=data3.groupby(['county_name','state_name','lat','long'])['deaths'].sum().reset_index()\ndata4_group=data4.groupby(['county_name','state_name','lat','long'])['confirmed'].sum().reset_index()\n\n#Inner join\ndata_merge_34=pd.merge(data3_group, data4_group, on=['county_name', 'state_name','lat','long'], how='inner')","c6ea88df":"problem=(data_merge_34[data_merge_34['deaths']>data_merge_34['confirmed']])\nproblem","b4b8badf":"data_merge_34.head()","c2936747":"data_merge_34.info()","5d1ec673":"BBox = (data_merge_34.long.min(),   data_merge_34.long.max(),      \n         data_merge_34.lat.min(), data_merge_34.lat.max())\nprint(BBox)","ec4e6729":"data_merge_34.plot(kind=\"scatter\", x=\"lat\", y=\"long\", alpha=0.1)\nplt.show();","b3d88d2f":"# c is the attribute we'll map onto colors, s is the attribute we'll represent with circle size.\ndata_merge_34.plot(kind=\"scatter\", x=\"lat\", y=\"long\",\n    s=data_merge_34['deaths']\/100, label=\"deaths\",\n    c=\"confirmed\", cmap=plt.get_cmap(\"jet\"),\n    colorbar=True, alpha=1, figsize=(10,7),\n)\nplt.legend()\nplt.show()","98d814a0":"#Mean latitude and longitude for each state\nmean_lat_long=data_merge_34.groupby(['state_name'])['lat','long'].mean().reset_index()\nmean_lat_long.head()","5734c866":"data34=data_merge_34.groupby(['state_name'])['deaths','confirmed'].sum().reset_index()\ndata34.head()","2480fa6c":"a=data34.merge(mean_lat_long, on='state_name', how='left')\na.head()","ce35152e":"import plotly.graph_objects as go\n\na['text'] = a['state_name'] + ','+'confirmed: '+a['confirmed'].astype(str)+','+'deaths'+a['deaths'].astype(str)\n\nfig = go.Figure(data=go.Scattergeo(\n        lon = a['long'],\n        lat = a['lat'],\n        text = a['text'],\n        mode = 'markers',\n        marker_color = a['deaths'],\n        ))\n\nfig.update_layout(\n        title = 'Death and Confirmed Situations by States',\n        geo_scope='usa',\n    )\nfig.show()","b731375d":"import folium\ncenter = [37.0902405, -95.7128906]\nm = folium.Map(location = center,\n               tiles = 'stamenterrain', zoom_start = 4)\n\n#  add Locations to map\nfor lat, long, deaths, confirmed, state_name in zip(a.lat, a.long, a.deaths, a.confirmed, a.state_name):\n    folium.CircleMarker(\n        [lat, long],\n        radius = 5,\n        popup = 'State: {}\\nDeaths: {:.0f}\\nConfirmed: {:.0f}'.format(state_name, deaths,confirmed),\n        fill = True,\n        color = 'Red',\n        fill_color = 'Green',\n        fill_opacity = 0.6\n        ).add_to(m)\n\n#Death and confirmed cases information can be achieved for each state.\nm","37adffba":"data5=pd.read_csv(\"..\/input\/uncover\/einstein\/diagnosis-of-covid-19-and-its-clinical-spectrum.csv\")\ndata5.head()","8c07d8ed":"data5.describe().T","194950f7":"data5.shape","ccef85cc":"data5.size","584f9156":"for c in data5.columns:\n    print(\"----%s----\"%c)\n    print(data5[c].isnull().sum())","277c4c58":"data5.isnull().sum().sum()","7efa1585":"data5 = data5[['patient_id','patient_age_quantile','sars_cov_2_exam_result','patient_addmited_to_regular_ward_1_yes_0_no',\n              'patient_addmited_to_semi_intensive_unit_1_yes_0_no','patient_addmited_to_intensive_care_unit_1_yes_0_no']]","33dda80e":"data5.set_index('patient_id', inplace=True)","39b79226":"data5.rename(columns={\"patient_age_quantile\":\"age_bracket\",\n                      \"sars_cov_2_exam_result\":\"result\",\n                      \"patient_addmited_to_regular_ward_1_yes_0_no\":\"regular_ward\",\n                     \"patient_addmited_to_semi_intensive_unit_1_yes_0_no\":\"semi_intensive\",\n                     \"patient_addmited_to_intensive_care_unit_1_yes_0_no\":\"intensive_care_unit\"},inplace=True)","dc042206":"data5.head()","f0cbc90c":"data5['result'] = data5['result'].apply(lambda x: 0 if x == 'negative' else 1)\ndata5['regular_ward'] = data5['regular_ward'].apply(lambda x: 0 if x == 'f' else 1)\ndata5['semi_intensive'] = data5['semi_intensive'].apply(lambda x: 0 if x == 'f' else 1)\ndata5['intensive_care_unit'] = data5['intensive_care_unit'].apply(lambda x: 0 if x == 'f' else 1)","3b8753d3":"data5.head()","0df157e7":"data5.corr()","f63d0c43":"data5.describe().T","d265d2d3":"fig, ax =plt.subplots(1,4, figsize=(20,3))\nsns.countplot(data5['age_bracket'], ax=ax[0])\nsns.countplot(data5['regular_ward'], ax=ax[1])\nsns.countplot(data5['semi_intensive'], ax=ax[2])\nsns.countplot(data5['intensive_care_unit'], ax=ax[3])\nfig.show()","c15fbdcb":"sns.countplot(data5['result'])","0bbb1477":"x = data5.drop([\"result\"], axis=1)\ny = data5[\"result\"]\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n  \nprint(\"x_train: \", x_train.shape)\nprint(\"y_train: \", y_train.shape)\nprint(\"x_test: \", x_test.shape)\nprint(\"y_test: \", y_test.shape)","0bdd57f8":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nmodel = LogisticRegression()\nmodel.fit(x_train, y_train.ravel())\ny_pred = model.predict(x_test)\nprint(classification_report(y_test, y_pred))","d0a7af1d":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","bdc0021f":"from sklearn.metrics import f1_score\nf1_score(y_test, y_pred)","1ab20992":"print(\"Before SMOTE x_train shape : {}\".format(x_train.shape))\nprint(\"Before SMOTE y_train shape: {} \\n\".format(y_train.shape))\n\nprint(\"Before SMOTE counts of result=1 : {}\".format(sum(y_train == 1)))\nprint(\"Before SMOTE counts of result=0: {} \\n\".format(sum(y_train == 0)))","db32b459":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE(random_state = 1)\nx_train_new, y_train_new = smote.fit_sample(x_train, y_train.ravel())","4e1d9cee":"print(\"After SMOTE x_train shape : {}\".format(x_train_new.shape))\nprint(\"After SMOTE y_train shape: {} \\n\".format(y_train_new.shape))\n  \nprint(\"After SMOTE counts of result=1 : {}\".format(sum(y_train_new == 1)))\nprint(\"After SMOTE counts of result=0 : {}\".format(sum(y_train_new == 0)))","308cfe29":"model_new = LogisticRegression()\nmodel_new.fit(x_train_new, y_train_new.ravel())\ny_pred_new = model_new.predict(x_test)\nprint(classification_report(y_test, y_pred_new))","35c27046":"cm_new = confusion_matrix(y_test, y_pred_new)\nprint(cm_new)","5d278a1e":"We see that recall value has improved even though the accuracy has decreased.","1ef89e4b":"After the 10th week, we can examine the distributions according to the days of the week.","d3e0dc28":"No missing value in data.","e9f2f5e4":"Our target class is imbalanced. So I will use SMOTE.The library imblearn has a class named imblearn.over_sampling.SMOTE which performs over-sampling using SMOTE","47965137":"<a id=\"4\"><\/a> <br>\n**KNN Classifier**","cecd1bec":"[TIME SERIES with using Prophet](#1)\n\n[TIME SERIES VISUALIZATION](#2)\n\n[MAP VISUALIZATION](#3)\n\n[KNN CLASSIFIER WITH IMBALANCED DATA](#4)\n\n","4c23bd68":"*Exported from here : https:\/\/www.openstreetmap.org\/#map=3\/50.46\/-115.84*","c391e99a":"<a id=\"1\"><\/a> <br>\n**TIME SERIES with using Prophet**","ec6e90ac":"We achieved an accuracy close to 90%. However did you notice a low (1%) recall? Recall of minority class 1 is very low.","b3f67a46":"<a id=\"2\"><\/a> <br>\n**TIME SERIES VISUALIZATION**","69b37f24":"![map.png](attachment:map.png)","eb00c4a1":"<a id=\"3\"><\/a> <br>\n**MAP VISUALIZATION**"}}