{"cell_type":{"0885ec10":"code","6bc26dd9":"code","08e8f524":"code","d99c6548":"code","ef7ab828":"markdown","6762d223":"markdown"},"source":{"0885ec10":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\nimport pickle\nimport os\nimport gc\nfrom joblib import dump, load\nimport time\nimport random\nfrom keras.preprocessing import text, sequence\nimport torch\nfrom torch import nn\nfrom torch.utils import data\nfrom torch.nn import functional as F\nfrom tqdm import tqdm\n\n# Import utility script\nfrom cpe882_utils import *\n\nsns.set()\n\n# Define paths\nKAGGLE_PATH = '\/kaggle\/input\/jigsaw-unintended-bias-preprocessed-dataset\/'\n\n# Importing data\ntrain = pd.read_csv(KAGGLE_PATH + 'train.csv').drop(columns=['comment_text'])\n#test = pd.read_csv(KAGGLE_PATH + 'test.csv')\n\n# Checking formats\n#train.comment_text = train.comment_text.astype(str)\n#test.comment_text = test.comment_text.astype(str)\n\n# Setting all seeds to 0\nseed_everything()\n\n# Define torch device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define aux dict to get embedding path\ndict_embedd = {\n    'fasttext':'\/kaggle\/input\/jigsaw-bias-ready-embedding-matrices\/embedding_matrix_fasttext_400000.pkl',\n    'glove':'\/kaggle\/input\/jigsaw-bias-ready-embedding-matrices\/embedding_matrix_glove_400000.pkl',\n    'glove_fasttext_avg':'\/kaggle\/input\/jigsaw-bias-ready-embedding-matrices\/embedding_matrix_glove_fasttext_avg_400000.pkl',\n    'glove_fasttext_concat':'\/kaggle\/input\/jigsaw-bias-ready-embedding-matrices\/embedding_matrix_glove_fasttext_concat_400000.pkl'\n}\n\n# Define aux dict to get padded sentences path\ndict_padded_x = {\n    '200':'\/kaggle\/input\/jigsaw-bias-ready-padded-train-set\/x_padded_sentences_200.pkl',\n    '250':'\/kaggle\/input\/jigsaw-bias-ready-padded-train-set\/x_padded_sentences_250.pkl',\n    '300':'\/kaggle\/input\/jigsaw-bias-ready-padded-train-set\/x_padded_sentences_300.pkl'\n}","6bc26dd9":"class SpatialDropout(nn.Dropout2d):\n    def forward(self, x):\n        x = x.unsqueeze(2)    # (N, T, 1, K)\n        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n        x = x.squeeze(2)  # (N, T, K)\n        return x\n\n\nclass NeuralNet(nn.Module):\n    def __init__(self, embedding_matrix, lstm_units=128, spatial_dropout=0.3, linear_dropout=0.1, finetune_embedding=False):\n        super(NeuralNet, self).__init__()\n        \n        # Define embeddings\n        embed_shape = embedding_matrix.shape\n        self.embedding = nn.Embedding(embed_shape[0], embed_shape[1])\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n        self.embedding.weight.requires_grad = finetune_embedding\n        \n        # Define spatial dropout 2d\n        self.embedding_dropout = SpatialDropout(spatial_dropout)\n        \n        # Define linear dropout\n        self.dropout = nn.Dropout(linear_dropout)\n        \n        # Define LSTM layer\n        self.lstm = nn.LSTM(embed_shape[1], lstm_units, bidirectional=True, batch_first=True)\n    \n        # Define linear layers after LSTM\n        self.linear = nn.Linear(lstm_units*2, lstm_units)\n        self.dropout = nn.Dropout(linear_dropout)\n        self.out = nn.Linear(lstm_units, 1)\n        \n    # https:\/\/github.com\/prakashpandey9\/Text-Classification-Pytorch\/blob\/master\/models\/LSTM_Attn.py\n    # https:\/\/github.com\/wabyking\/TextClassificationBenchmark\/blob\/master\/models\/LSTMwithAttention.py\n        \n    def attention_net(self, lstm_output, final_state):\n        merged_state = torch.cat([s for s in final_state],1)\n        merged_state = merged_state.unsqueeze(2)\n        attn_weights = torch.bmm(lstm_output, merged_state).squeeze(2)\n        soft_attn_weights = F.softmax(attn_weights, 1)\n        new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n        return new_hidden_state\n        \n    def forward(self, x):\n        h_embedding = self.embedding(x)\n        h_embedding = self.embedding_dropout(h_embedding)\n        \n        h_lstm,  (final_hidden_state, final_cell_state) = self.lstm(h_embedding)\n        attn_output = self.attention_net(h_lstm, final_hidden_state)\n        \n        attn_output_linear  = F.relu(self.linear(attn_output))        \n        attn_output_linear_dropout = self.dropout(attn_output_linear)\n        \n        #max_pool, _ = torch.max(h_lstm, 1)\n        #max_pool_linear  = F.relu(self.linear(max_pool))        \n        #max_pool_linear_dropout = self.dropout(max_pool_linear)\n        #max_pool_linear_dropout_attention = torch.cat((max_pool_linear_dropout, attn_output), 1)\n        \n        output = torch.sigmoid(self.out(attn_output_linear_dropout))\n\n        return output","08e8f524":"def train_model_all_folds(DF_OUTPUT_FILENAME, EMBEDDING_TYPE, MODEL_PARAMS=None, MAX_LEN='250', PATIENCE=np.inf, LR=0.001, N_EPOCHS=10):\n    \n    print('Training Fold 0\\n')\n    epoch_info_0 = train_model_fold_i(0, max_len=MAX_LEN, embedding_type=EMBEDDING_TYPE, model_params=MODEL_PARAMS, patience=PATIENCE, lr=LR, n_epochs=N_EPOCHS)\n    print('\\nTraining Fold 1\\n')\n    epoch_info_1 = train_model_fold_i(1, max_len=MAX_LEN, embedding_type=EMBEDDING_TYPE, model_params=MODEL_PARAMS, patience=PATIENCE, lr=LR, n_epochs=N_EPOCHS)\n    print('\\nTraining Fold 2\\n')\n    epoch_info_2 = train_model_fold_i(2, max_len=MAX_LEN, embedding_type=EMBEDDING_TYPE, model_params=MODEL_PARAMS, patience=PATIENCE, lr=LR, n_epochs=N_EPOCHS)\n    print('\\nTraining Fold 3\\n')\n    epoch_info_3 = train_model_fold_i(3, max_len=MAX_LEN, embedding_type=EMBEDDING_TYPE, model_params=MODEL_PARAMS, patience=PATIENCE, lr=LR, n_epochs=N_EPOCHS)\n    print('\\nTraining Fold 4\\n')\n    epoch_info_4 = train_model_fold_i(4, max_len=MAX_LEN, embedding_type=EMBEDDING_TYPE, model_params=MODEL_PARAMS, patience=PATIENCE, lr=LR, n_epochs=N_EPOCHS)\n    \n    epoch_info_avg = (epoch_info_0+epoch_info_1+epoch_info_2+epoch_info_3+epoch_info_4)\/5\n    epoch_info_avg['Fold'] = -1\n    \n    epoch_info = pd.concat([epoch_info_0, epoch_info_1, epoch_info_2, epoch_info_3, epoch_info_4, epoch_info_avg])\n    \n    epoch_info.to_csv(DF_OUTPUT_FILENAME + '.csv', index=False)\n    \n    return epoch_info\n\n\ndef train_model_fold_i(fold_i, max_len, embedding_type, model_params, patience, lr, n_epochs):\n    \n    # Prepare dataset    \n    x = np.load(dict_padded_x[max_len])\n    x_train = torch.tensor(x[train.kfold!=fold_i], dtype=torch.long).to(device)\n    x_valid = torch.tensor(x[train.kfold==fold_i], dtype=torch.long).to(device)\n    del x\n    gc.collect()\n    \n    y = train.target.values\n    y_train = torch.tensor(y[train.kfold!=fold_i], dtype=torch.float32).to(device)\n    y_valid = torch.tensor(y[train.kfold==fold_i], dtype=torch.float32).to(device)\n    del y\n    gc.collect()\n    \n    train_dataset = data.TensorDataset(x_train, y_train)\n    valid_dataset = data.TensorDataset(x_valid, y_valid)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=False)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=512, shuffle=False)\n    gc.collect()\n  \n    # Define model\n    embedding_matrix = np.load(dict_embedd[embedding_type])\n    model = NeuralNet(embedding_matrix)\n    model.to(device)\n    del embedding_matrix\n    gc.collect()\n    \n    loss_fn = nn.BCELoss().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    best_valid_loss = np.inf \n    epoch_info = []\n    current_patience = 0\n    epoch = 0\n    while (epoch < n_epochs) and (current_patience < patience):\n        \n        start_time = time.time()\n        \n        # Train\n        model.train()\n        avg_train_loss = 0.0\n        avg_train_auc = 0.0\n        y_pred_train = np.array([])\n        for data_batch in tqdm(train_loader, disable=False):\n            x_batch = data_batch[:-1]\n            y_batch = data_batch[-1]\n            y_pred = model(*x_batch).squeeze()            \n            loss = loss_fn(y_pred, y_batch)\n            auc = roc_auc_score(y_batch.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            avg_train_loss += loss.item() \/ len(train_loader)\n            avg_train_auc += auc \/ len(train_loader)\n            y_pred_train = np.concatenate((y_pred_train, y_pred.cpu().detach().numpy()))\n        bias_auc_train = JigsawEvaluator(train[train.kfold!=fold_i]['target'].values, train[train.kfold!=fold_i][identity_columns].values).get_final_metric(y_pred_train)\n        \n        # Validation\n        model.eval()\n        avg_valid_loss = 0.0\n        avg_valid_auc = 0.0\n        y_pred_valid = np.array([])\n        for data_batch in tqdm(valid_loader, disable=False):\n            x_batch = data_batch[:-1]\n            y_batch = data_batch[-1]\n            y_pred = model(*x_batch).squeeze()            \n            loss = loss_fn(y_pred, y_batch)\n            auc = roc_auc_score(y_batch.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n            avg_valid_loss += loss.item() \/ len(valid_loader)\n            avg_valid_auc += auc \/ len(valid_loader)\n            y_pred_valid = np.concatenate((y_pred_valid, y_pred.cpu().detach().numpy()))\n        bias_auc_valid = JigsawEvaluator(train[train.kfold==fold_i]['target'].values, train[train.kfold==fold_i][identity_columns].values).get_final_metric(y_pred_valid)\n        \n        # Print epoch metrics\n        elapsed_time = int(time.time() - start_time)\n        mins = elapsed_time \/ 60\n        secs = elapsed_time % 60\n        print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n        print(f'\\tLoss: {avg_train_loss:.4f}(train) | Auc: {avg_train_auc :.4f}%(train) | Bias_auc: {bias_auc_train :.4f}%(train)')\n        print(f'\\tLoss: {avg_valid_loss:.4f}(valid) | Auc: {avg_valid_auc :.4f}%(valid) | Bias_auc: {bias_auc_valid :.4f}%(valid)')\n        \n        epoch_info.append([fold_i, epoch, avg_train_loss, avg_train_auc, bias_auc_train, avg_valid_loss, avg_valid_auc, bias_auc_valid, elapsed_time])\n        \n        if avg_valid_loss < best_valid_loss:\n            best_valid_loss = avg_valid_loss\n            #torch.save({'state_dict': model.state_dict()}, 'checkpoint_epoch.pth.tar')\n            #print('\\tBest validation loss achieved. Saving model...')\n            print('\\tBest validation loss achieved.')\n        else:\n            current_patience += 1\n            print(f'\\tValidation loss did not improve. Patience hits {current_patience}')\n            \n        epoch+=1\n        \n    epoch_info = pd.DataFrame(epoch_info, columns=['Fold', 'Epoch', 'Train_loss', 'Train_auc', 'Train_bias_auc', 'Valid_loss', 'Valid_auc', 'Valid_bias_auc', 'Time'])\n    gc.collect()\n    \n    return epoch_info","d99c6548":"train_model_all_folds('bi_lstm_attention_glove_fasttext_avg', 'glove_fasttext_avg', N_EPOCHS=15)","ef7ab828":"# Jigsaw Unintended Bias in Toxicity Classification\n\nThe embeddings preprocessing pipeline was almost all copied from this excellent [kernel](https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-for-glove-part2-usage). Thank very much, [christofhenkel](https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-for-glove-part2-usage)!","6762d223":"## 1) Importing libraries and datasets"}}