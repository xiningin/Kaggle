{"cell_type":{"128d7720":"code","03c4579b":"code","0be4bb2b":"code","168af4e5":"code","645e1f58":"code","6ada3a3c":"code","f16baae7":"code","691befd5":"code","1a63caee":"code","dad062ea":"code","d46cb7d5":"code","f05e0c59":"code","bffa3474":"code","6ecc846d":"code","3f385ce4":"code","d4c54edf":"code","0ae6590d":"code","bf76cc18":"code","a4383a0c":"code","580d4c9c":"code","71ff936c":"code","574fe173":"code","41e49283":"code","bbabc7b8":"code","9a2a5b84":"code","68793610":"code","092eddb8":"code","019d79eb":"code","768418db":"code","9b4465e5":"code","0dbd6971":"code","88e5679f":"code","cd74aa5f":"code","69bdeabb":"code","f510138c":"code","44a3c75d":"markdown","3937ebce":"markdown","566a1c0f":"markdown","3ae66885":"markdown","cd371054":"markdown","ee51b040":"markdown","795c583b":"markdown","49ac4039":"markdown","0bba3f8f":"markdown","2774bf9e":"markdown","83cbf356":"markdown","176406e4":"markdown","136d1dde":"markdown","2f1d5a14":"markdown"},"source":{"128d7720":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier","03c4579b":"train = pd.read_csv(\"..\/input\/reducing-commercial-aviation-fatalities\/train.csv\")","0be4bb2b":"train.sample(10)","168af4e5":"print(train.shape)","645e1f58":"test_iterator = pd.read_csv('..\/input\/reducing-commercial-aviation-fatalities\/test.csv', chunksize=5)\ntest_top = next(test_iterator)\ntest_top","6ada3a3c":"sample_submission = pd.read_csv(\"..\/input\/reducing-commercial-aviation-fatalities\/sample_submission.csv\")\nsample_submission.sample(10)","f16baae7":"pd.crosstab(train.experiment, train.event)","691befd5":"pd.crosstab(train.experiment, train.crew)","1a63caee":"pd.crosstab(train.experiment, train.seat)","dad062ea":"print(list(enumerate(train.columns)))","d46cb7d5":"crew = 3\nseat = 0\nexp = 'DA'\nev = 'D'\n\nsel = (train.crew == crew) & (train.experiment == exp) & (train.seat == seat)\npilot_info = train.loc[sel,:].sort_values(by='time')\n\n\nplt.figure(figsize=[16,12])\nfor i in range(4, 27):\n    plt.subplot(6,4,i-3)\n    plt.plot(pilot_info.time, \n             pilot_info.iloc[:,i], zorder=1)\n    plt.scatter(pilot_info.loc[pilot_info.event ==  ev,:].time, \n             pilot_info.loc[pilot_info.event == ev,:].iloc[:,i], c='red', zorder=2, s=1)\n    plt.title(pilot_info.columns[i])\n\nplt.tight_layout()\nplt.show()","f05e0c59":"y_train_full = train.event\nX_train_full = train.iloc[:,4:27]\nX_train_full.head()","bffa3474":"pd.DataFrame({\n    'min_val':X_train_full.min(axis=0).values,\n    'max_val':X_train_full.max(axis=0).values\n}, index = X_train_full.columns\n)","6ecc846d":"y_train_full.value_counts() ","3f385ce4":"y_train_full.value_counts() \/ len(y_train_full)","d4c54edf":"X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.98, stratify=y_train_full, random_state=1)\n\nprint(X_train.shape)","0ae6590d":"%%time\nlr_mod = LogisticRegression(solver='lbfgs', n_jobs=-1)\nlr_mod.fit(X_train, y_train)\n\nprint('Training Accuracy:  ', lr_mod.score(X_train, y_train))\nprint('Validation Accuracy:', lr_mod.score(X_valid, y_valid))","bf76cc18":"%%time \n\nlr_pipe = Pipeline(\n    steps = [\n        ('scaler', StandardScaler()),\n        ('classifier', LogisticRegression(solver='lbfgs', n_jobs=-1))\n    ]\n)\n\nlr_param_grid = {\n    'classifier__C': [0.0001, 0.001, 0.1, 1.0],\n}\n\n\nnp.random.seed(1)\ngrid_search = GridSearchCV(lr_pipe, lr_param_grid, cv=5, refit='True')\ngrid_search.fit(X_train, y_train)\n\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)","a4383a0c":"%%time \n\nrf_mod = RandomForestClassifier(n_estimators=10, max_depth=32, n_jobs=-1)\nrf_mod.fit(X_train, y_train)\n\nprint('Training Accuracy:  ', rf_mod.score(X_train, y_train))\nprint('Validation Accuracy:', rf_mod.score(X_valid, y_valid))","580d4c9c":"%%time\nrf_pipe = Pipeline(\n    steps = [\n        ('scaler', StandardScaler()),\n        ('classifier', RandomForestClassifier(n_estimators=10, n_jobs=-1))\n    ]\n)\n\nlr_param_grid = {\n    'classifier__max_depth': [8, 16, 32, 64, 128]\n}\n\n\nnp.random.seed(1)\ngrid_search = GridSearchCV(rf_pipe, lr_param_grid, cv=5, refit='True')\ngrid_search.fit(X_train, y_train)\n\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)","71ff936c":"grid_search.cv_results_['mean_test_score']","574fe173":"%%time \nrf_mod = RandomForestClassifier(n_estimators=100, max_depth=32, n_jobs=-1)\nrf_mod.fit(X_train, y_train)\n\nprint('Training Accuracy:  ', rf_mod.score(X_train, y_train))\nprint('Validation Accuracy:', rf_mod.score(X_valid, y_valid))","41e49283":"rf_mod.predict_proba(X_train)","bbabc7b8":"from sklearn.metrics import log_loss\n\nlog_loss(y_train, rf_mod.predict_proba(X_train))","9a2a5b84":"log_loss(y_valid, rf_mod.predict_proba(X_valid))","68793610":"%%time \n\nxbg_mod = XGBClassifier()\nxbg_mod.fit(X_train, y_train)\n\nxbg_mod.score(X_train, y_train)","092eddb8":"xbg_mod.score(X_valid, y_valid)","019d79eb":"log_loss(y_train, xbg_mod.predict_proba(X_train))","768418db":"log_loss(y_valid, xbg_mod.predict_proba(X_valid))","9b4465e5":"%%time\nxgd_pipe = Pipeline(\n    steps = [\n        ('classifier', XGBClassifier(learning_rate=0.3, max_depth=6, alpha=1, n_estimators=50, subsample=0.5))\n    ]\n)\n\nxgd_param_grid = {\n    'classifier__learning_rate' : [0.1, 0.3, 0.5, 0.7, 0.9],\n    'classifier__alpha' : [0, 1, 10, 100]\n    #'classifier__max_depth': [8, 16, 32, 64, 128]\n    \n}\n\n\n#np.random.seed(1)\n#xgd_grid_search = GridSearchCV(xgd_pipe, xgd_param_grid, cv=5, refit='True')\n#xgd_grid_search.fit(X_train, y_train)\n\n#print(xgd_grid_search.best_score_)\n#print(xgd_grid_search.best_params_)","0dbd6971":"test_iterator = pd.read_csv('..\/input\/reducing-commercial-aviation-fatalities\/test.csv', chunksize=5)\ntest_top = next(test_iterator)\ntest_top","88e5679f":"print(xbg_mod.predict_proba(test_top.iloc[:,5:]))","cd74aa5f":"%%time \n\ncs = 1000000\ni = 0\n\nfor test in pd.read_csv('..\/input\/reducing-commercial-aviation-fatalities\/test.csv', chunksize=cs):\n  \n    print('--Iteration',i, 'is started')\n    \n    test_pred = xbg_mod.predict_proba(test.iloc[:,5:])\n    \n    partial_submission = pd.DataFrame({\n        'id':test.id,\n        'A':test_pred[:,0],\n        'B':test_pred[:,1],\n        'C':test_pred[:,2],\n        'D':test_pred[:,3]\n    })\n        \n    if i == 0:\n        submission = partial_submission.copy()\n    else:\n        submission = submission.append(partial_submission, ignore_index=True)\n        \n\n    del test\n    print('++Iteration', i, 'is done!')\n    i +=1","69bdeabb":"submission.head()","f510138c":"submission.to_csv(\"submission.csv\", index=False)","44a3c75d":"# Logistic Regression","3937ebce":"# Explore Training Data","566a1c0f":"**Test Score: 0.61190**","3ae66885":"**Test Score: 0.88456**","cd371054":"# Notebooks to Explore\n* [Introduction to phyiological data](https:\/\/www.kaggle.com\/stuartbman\/introduction-to-physiological-data)\n  * Contains information about using signal processing to de-noise the data. \n  * Provides some suggestions for engineering new features. \n* [Reducing Commercial Aviation Fatalities (11th)](https:\/\/www.kaggle.com\/shahaffind\/reducing-commercial-aviation-fatalities-11th)\n  * Uses ideas from above notebook with gradient boosting to get really good results.\n  * I believe this notebook creates a different model for each pilot.\n* [Starter Code : EDA and LGBM Baseline](https:\/\/www.kaggle.com\/theoviel\/starter-code-eda-and-lgbm-baseline)\n  * Contains interesting data visualizations.","ee51b040":"# Gradient Boosting Tree","795c583b":"# Things to Try\n\n* Use the montage information in the \"Introduction to physiological data\" notebook to engineer new features. \n* Use methods from the first two notebooks above to de-noise the data. \n* Create a variable that identifies the pilot. Include this variable in the model. \n* Create a separate model for each pilot. \n* Attempt to train a model on the complete training set. \n* Perform hyperparameter tuning on XGBCLassifier Model. Information about the parameters can be found [here](https:\/\/xgboost.readthedocs.io\/en\/latest\/parameter.html) and [here](https:\/\/www.analyticsvidhya.com\/blog\/2016\/03\/complete-guide-parameter-tuning-xgboost-with-codes-python\/). ","49ac4039":"# Sample Training Set for Faster Training","0bba3f8f":"# Random Forest Classifier","2774bf9e":"# Import Packages","83cbf356":"# Create Feature and Label Arrays","176406e4":"# Load Data","136d1dde":"# Generate Test Predictions","2f1d5a14":"# Hyperparameter Tuning for Gradient Boosting"}}