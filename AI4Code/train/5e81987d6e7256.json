{"cell_type":{"43a951b5":"code","e7dad7c7":"code","93d8ed38":"code","a6c028c7":"code","07af3f61":"code","556c64b1":"code","e1ea6126":"code","a619088f":"code","64a0cc2b":"code","3c633c00":"code","d5dd2ed4":"code","11bb5b55":"code","123bf169":"code","0faf0393":"code","92a3be15":"code","47bb100a":"code","32ba8b1d":"code","f97e6892":"code","217b07bd":"code","86aa701c":"code","ae98cf3d":"code","5881e30e":"code","ec4eee8b":"code","a83c7919":"code","088fdf0e":"code","ad298753":"code","4c622d16":"code","d0022ef5":"code","16771d7c":"code","7c235c3c":"code","78e06f05":"code","4c08cdb3":"code","74148ee9":"code","c448bd8c":"code","c4783662":"code","bf922376":"code","c96ec817":"code","0f9aebd5":"code","b38b4b25":"code","41b27247":"code","af8987b4":"code","548fdb16":"code","41af6ec0":"markdown","8e8750a1":"markdown","4d6f4b61":"markdown","43511252":"markdown","26f098e0":"markdown","ed31abc2":"markdown"},"source":{"43a951b5":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom operator import itemgetter\nfrom collections import OrderedDict\nimport os\nimport torch \nimport torch.nn.functional as F\nfrom PIL import Image\nfrom torch import optim,nn\nfrom torchvision import transforms as T,models\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision.utils import make_grid\nfrom tqdm import tqdm \n\n\npd.options.plotting.backend = \"plotly\"\n\n\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.figure_factory as ff\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\nimport plotly.graph_objs as go\nimport plotly\nfrom plotly import tools\n","e7dad7c7":"data = pd.read_csv('..\/input\/sample\/sample_labels.csv')\ndata.head()","93d8ed38":"# see how many observations there are\nnum_obs = len(data)\nprint('Number of observations:',num_obs)","a6c028c7":"from glob import glob\n\nmy_glob = glob('..\/input\/sample\/sample\/sample\/images\/*.png')\nprint('Number of Observations: ', len(my_glob)) ","07af3f61":"full_img_paths = {os.path.basename(x): x for x in my_glob}\n#data['full_path'] = data['Image Index'].map(full_img_paths.get)","556c64b1":"fig = plt.figure(figsize=(10, 10))\ni = 1\nfor ii in data['Image Index'].values[:9]:\n    img = plt.imread(full_img_paths[ii])\n    fig.add_subplot(3,3,i)\n    plt.imshow(img , cmap='Greys_r')\n    i+=1\n    \nfig.tight_layout(pad=2)\nfig.show()","e1ea6126":"pathology_list = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax','Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation','Infiltration','Fibrosis','Pneumonia']\n\nfor pathology in pathology_list :\n    data[pathology] = data['Finding Labels'].apply(lambda x: 1 if pathology in x else 0)\n    \ndata['No Findings'] = data['Finding Labels'].apply(lambda x: 1 if 'No Finding' in x else 0)","a619088f":"data = data.drop(list(data.iloc[:,1:11].columns.values),axis = 1)","64a0cc2b":"data","3c633c00":"data.iloc[:,1:].sum().iplot(kind='bar', orientation='h')","d5dd2ed4":"data = data.drop(['No Findings'],axis = 1)","11bb5b55":"data.iloc[:,1:].sum().iplot(kind='bar', orientation='h')","123bf169":"data.iloc[:,1:].mean().iplot(kind='bar', orientation='h')","0faf0393":"def compute_class_freqs(labels):\n    \n    labels = np.array(labels)\n    \n    N = labels.shape[0]\n    \n    positive_frequencies = np.sum(labels,axis = 0) \/ N\n    negative_frequencies = 1 - positive_frequencies\n    \n    return positive_frequencies, negative_frequencies","92a3be15":"freq_pos, freq_neg = compute_class_freqs(data.iloc[:,1:])","47bb100a":"#Avoid Data Imbalance using Weighted Loss\n#Plot the freqencies to each class, in order to check the data balance-imbalance\n\ndf = pd.DataFrame({\"Class\": pathology_list, \"Label\": \"Positive\", \"Value\": freq_pos})\ndf = df.append([{\"Class\": pathology_list[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\n\nplt.xticks(rotation=90)\nf = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=df, palette=\"pastel\", alpha=.6)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","32ba8b1d":"df = pd.DataFrame({\"Class\": pathology_list, \"Label\": \"Positive\", \"Value\": freq_pos})\ndf = df.append([{\"Class\": pathology_list[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\n\nplt.xticks(rotation=90)\nf = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=df)","f97e6892":"pos_weights = freq_neg\nneg_weights = freq_pos\npos_contribution = freq_pos * pos_weights \nneg_contribution = freq_neg * neg_weights","217b07bd":"df = pd.DataFrame({\"Class\": pathology_list, \"Label\": \"Positive\", \"Value\": pos_contribution})\ndf = df.append([{\"Class\": pathology_list[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(neg_contribution)], ignore_index=True)\n\nplt.xticks(rotation=90)\nf = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=df)","86aa701c":"def weighted_loss(pos_weights,neg_weights,y_pred,y_true,epsilon = 1e-7):\n    \n    loss = 0.0\n    for i in range(len(pos_weights)):\n        loss_pos = -1 * torch.mean(pos_weights[i] * y_true[:,i] * torch.log(y_pred[:,i] + epsilon))\n        loss_neg = -1 * torch.mean(neg_weights[i] * (1-y_true[:,i]) * torch.log((1-y_pred[:,i]) + epsilon))\n        loss += loss_pos + loss_neg\n        \n    return loss","ae98cf3d":"class NIH_Dataset(Dataset):\n    \n    def __init__(self,data,img_dir,transform = None):\n        self.data = data\n        self.img_dir = img_dir \n        self.transform = transform \n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        \n        img_file = self.img_dir + self.data.iloc[:,0][idx]\n        img = Image.open(img_file).convert('RGB')\n        label = np.array(self.data.iloc[:,1:].iloc[idx])\n        \n        if self.transform:\n            img = self.transform(img)\n            \n        return img,label","5881e30e":"data_transform = T.Compose([\n    T.RandomRotation((-20,+20)),\n    T.Resize((224,224)),\n    T.ToTensor(),\n    T.Normalize(mean=[0.480, 0.450, 0.400],std=[0.220, 0.220, 0.220])\n])","ec4eee8b":"trainds = NIH_Dataset(data,'..\/input\/sample\/sample\/sample\/images\/',transform = data_transform)","a83c7919":"def deprocess(img):\n    img = img.permute(1,2,0)\n    img = img * torch.Tensor([0.229, 0.224, 0.225]) + torch.Tensor([0.485, 0.456, 0.406])\n    return img","088fdf0e":"image, label = trainds[0]\nclass_labels = list(np.where(label==1)[0])\nplt.imshow(deprocess(image))\nplt.title(itemgetter(*class_labels)(pathology_list));","ad298753":"trainset, validset, testset = random_split(trainds, [5000,303,303])\n\nprint(\"Length of trainset : {}\".format(len(trainset)))\nprint(\"Length of testset : {}\".format(len(testset)))\nprint(\"Length of validset : {}\".format(len(validset)))","4c622d16":"def get_dataloader(dataset):\n    return DataLoader(dataset,batch_size = 32,shuffle = True)","d0022ef5":"trainloader, testloader, validloader = get_dataloader(trainset),get_dataloader(testset),get_dataloader(validset)","16771d7c":"model = models.vgg19_bn()\nmodel.load_state_dict(torch.load(\"..\/input\/pretrained-model-weights-pytorch\/vgg19_bn-c79401a0.pth\"))","7c235c3c":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","78e06f05":"for param in model.parameters():\n    param.requires_grad = False\n\n\n\n\nclassifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 4096)),\n                                         ('relu', nn.ReLU()),\n                                         ('dropout',nn.Dropout(0.3)),\n                                         ('fc2', nn.Linear(4096, 4096)),\n                                         ('relu', nn.ReLU()),\n                                         ('drop', nn.Dropout(0.3)),\n                                         ('fc3', nn.Linear(4096, 14)), \n                                         ('output', nn.Sigmoid())]))\n\nmodel.classifier = classifier\nmodel.to(device)","4c08cdb3":"optimizer = optim.Adam(model.parameters(),lr = 0.001)\nschedular = optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor = 0.1,patience = 5)\nepochs = 30\nvalid_loss_min = np.Inf","74148ee9":"   \nfor i in range(epochs):\n    \n    train_loss = 0.0\n    valid_loss = 0.0\n    train_acc = 0.0\n    valid_acc = 0.0 \n    \n    \n    model.train()\n    \n\n    for images,labels in tqdm(trainloader):\n        \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        \n        ps = model(images)\n        loss = weighted_loss(pos_weights,neg_weights,ps,labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n#         correct = 0\n#         correct += (ps == labels).float().sum()\n#         train_accuracy = 10 * correct \/ len(trainloader)\n        \n        train_loss += loss.item()\n        \n    avg_train_loss = train_loss \/ len(trainloader)\n\n    \n    model.eval()\n    with torch.no_grad():\n        \n        for images,labels in tqdm(validloader):\n            \n            images = images.to(device)\n            labels = labels.to(device)\n        \n            ps = model(images)\n#             correct = 0\n#             optimizer.step()\n#             correct += (ps == labels).float().sum()\n#             valid_accuracy = 10 * correct \/ len(validloader)\n            \n            loss = weighted_loss(pos_weights,neg_weights,ps,labels)\n            valid_loss += loss.item()\n            \n        avg_valid_loss = valid_loss \/ len(validloader)\n        \n        schedular.step(avg_valid_loss)\n        \n           \n        \n        if avg_valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).   Saving model ...'.format(valid_loss_min,avg_valid_loss))\n            torch.save({\n                'epoch' : i,\n                'model_state_dict' : model.state_dict(),\n                'optimizer_state_dict' : optimizer.state_dict(),\n                'valid_loss_min' : avg_valid_loss\n            },'Pneumonia_model.pt')\n            \n            valid_loss_min = avg_valid_loss\n            \n            \n    print(\"Epoch : {} Train Loss : {:.6f} \".format(i+1,avg_train_loss))\n   # print(\"Epoch : {} Train Accuracy : {:.6f} \".format(i+1,train_accuracy))\n    print(\"Epoch : {} Valid Loss : {:.6f} \".format(i+1,avg_valid_loss))\n    #print(\"Epoch : {} valid Accuracy : {:.6f} \".format(i+1,valid_accuracy))","c448bd8c":"def class_accuracy(dataloader, model):\n    \n    per_class_accuracy = [0 for i in range(len(pathology_list))]\n    total = 0.0\n    \n    with torch.no_grad():\n        \n        for images,labels in dataloader:\n            \n            ps = model(images.to(device))\n            labels = labels.to(device)\n            ps = (ps >= 0.5).float()\n        \n            for i in range(ps.shape[1]):\n                \n                x1 = ps[:,i:i+1]\n                x2 = labels[:,i:i+1]\n                per_class_accuracy[i] += int((x1 == x2).sum())\n                \n        per_class_accuracy = [(i\/len(dataloader.dataset))*100.0 for i in per_class_accuracy]\n        \n    return per_class_accuracy     \n\n\ndef get_acc_data(class_names,acc_list):\n    df = pd.DataFrame(list(zip(class_names, acc_list)), columns =['Labels', 'Acc']) \n    return df \n","c4783662":"print(\"Train Dataset Accuracy Report\")\nacc_list = class_accuracy(trainloader,model)\nget_acc_data(pathology_list,acc_list)\n","bf922376":"print(\"Test Dataset Accuracy Report\")\nacc_list = class_accuracy(testloader,model)\nget_acc_data(pathology_list,acc_list)","c96ec817":"print(\"Valid Dataset Accuracy Report\")\nacc_list = class_accuracy(validloader,model)\nget_acc_data(pathology_list,acc_list)","0f9aebd5":"def view_classify(img,ps,label):\n    \n    class_name = pathology_list\n    classes = np.array(class_name)\n\n    ps = ps.cpu().data.numpy().squeeze()\n    img = deprocess(img)\n    class_labels = list(np.where(label==1)[0])\n\n    if not class_labels :\n        title = 'No Findings'\n    else : \n        title = itemgetter(*class_labels)(class_name)\n    \n    \n\n    fig, (ax1, ax2) = plt.subplots(figsize=(8,12), ncols=2)\n    ax1.imshow(img)\n    ax1.set_title('Ground Truth : {}'.format(title))\n    ax1.axis('off')\n    ax2.barh(classes, ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(classes)\n    ax2.set_yticklabels(classes)\n    ax2.set_title('Predicted Class')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n\n    return None","b38b4b25":"image,label = testset[127]\n\nps = model(image.unsqueeze(0).to(device))\n\nview_classify(image,ps,label)","41b27247":"image,label = validset[234]\n\nps = model(image.unsqueeze(0).to(device))\n\nview_classify(image,ps,label)","af8987b4":"nb_classes = 14\n\nconfusion_matrix = torch.zeros(nb_classes, nb_classes)\nwith torch.no_grad():\n    for i, (inputs, classes) in enumerate(validloader):\n        inputs = inputs.to(device)\n        classes = classes.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        for t, p in zip(classes.view(-1), preds.view(-1)):\n                confusion_matrix[t.long(), p.long()] += 1\n\nprint(confusion_matrix)","548fdb16":"#print(confusion_matrix.diag()\/confusion_matrix.sum(1))\nplt.figure(figsize=(12,7))\n\nclass_names = list(pathology_list)\ndf_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\nheatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\nheatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n;","41af6ec0":"# $\\texttt{Train Model}$ ","8e8750a1":"# $\\texttt{Plot Results}$","4d6f4b61":"# $\\texttt{Split Dataset and create dataloaders}$","43511252":"# $\\texttt{Each Class Accuracy}$","26f098e0":"# $\\texttt{Define Pre-trained Model}$","ed31abc2":"# $\\texttt{Loading Dataset and Applying Transforms}$"}}