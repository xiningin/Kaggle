{"cell_type":{"cb4807f0":"code","9eff08cc":"code","7e99fa9a":"code","3f0816f6":"code","4c027cf6":"code","21b87b30":"code","3e20c002":"code","047a8d92":"code","1ed7a4a7":"code","14463198":"code","a61a468e":"code","7ec28acd":"code","ab27683e":"code","ac853da4":"code","669e5d1c":"code","95c4d579":"code","734d411c":"code","1c721d58":"code","35b6f367":"code","25f88546":"code","c473321b":"code","2011cdb8":"code","600a4f66":"code","e23a69ab":"code","ab7e527c":"code","67ab427f":"code","c4831c7f":"code","813437fe":"code","5ff79d3f":"code","822edf20":"code","65b7e589":"code","4b0f6430":"code","65c9f1f2":"code","f78a5d52":"code","3301b049":"code","a77df24e":"code","bcc83b31":"code","3a83c87e":"code","3e02da0b":"code","926c1912":"code","5f51e6af":"code","cecfb72f":"code","827da7f1":"code","e4cf017e":"code","b60cb885":"code","7149f155":"code","d2f6002e":"code","43fcf77a":"code","00d13473":"code","a7aa1e95":"code","f284b476":"code","a5117ad1":"code","5d8097dd":"code","df36f7f4":"code","8c7cf18f":"code","bbf59f01":"code","accb0ee7":"code","6fa8755c":"markdown","8ceaacae":"markdown","0d37ea9d":"markdown","1193cef3":"markdown","9d5bba54":"markdown","1961457e":"markdown","3233bf30":"markdown","7d7da7b0":"markdown","fe0a5ec9":"markdown","b973103d":"markdown"},"source":{"cb4807f0":"\nimport numpy as np\nimport pandas as pd\nimport pickle\n\nimport cv2\nimport os\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.applications import MobileNetV2\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\n\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras import backend as K\n\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.applications import MobileNetV2\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n\n\n# gr\u00e1fico\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","9eff08cc":"print('Tensorflow version: ', tf.version.VERSION)\nprint('Keras version: ', tf.keras.__version__)","7e99fa9a":"!nvidia-smi","3f0816f6":"INIT_LR = 1e-4\nALPHA = 1e-5\nBATCH_SIZE = 64\nIMG_SHAPE = (224, 224, 3)\nEPOCHS = 25\nSAMPLE_QTD = 0.005\nRANDOM_STATE = 42","4c027cf6":"path_train_json = '..\/input\/celeba-spoof-for-face-antispoofing\/CelebA_Spoof_\/CelebA_Spoof\/metas\/intra_test\/train_label.json'\npath_test_json = '..\/input\/celeba-spoof-for-face-antispoofing\/CelebA_Spoof_\/CelebA_Spoof\/metas\/intra_test\/test_label.json'\npath_local = '..\/input\/celeba-spoof-for-face-antispoofing\/CelebA_Spoof_\/CelebA_Spoof\/'","21b87b30":"col = ['C{}'.format(n) for n in range(44)]","3e20c002":"df_train = pd.read_json(path_train_json, orient='index')\ndf_train.columns = col","047a8d92":"df_test = pd.read_json(path_test_json, orient='index')\ndf_test.columns = col","1ed7a4a7":"trainSample, testSample = int(df_train.shape[0] * SAMPLE_QTD), int(df_test.shape[0] * SAMPLE_QTD)\nprint('Total de treino: {}'.format(trainSample))\nprint('Total de teste: {}'.format(testSample))","14463198":"df_train = df_train.sample(trainSample, random_state=RANDOM_STATE)\ndf_test = df_test.sample(testSample, random_state=RANDOM_STATE)","a61a468e":"df_train = df_train.reset_index()\ndf_test = df_test.reset_index()","7ec28acd":"df_train.rename(columns={'index': 'Filepath'}, inplace=True)\ndf_test.rename(columns={'index': 'Filepath'}, inplace=True)","ab27683e":"df_train.head()","ac853da4":"df_train.info()","669e5d1c":"def showInfo(data, classe, lables):\n    print('Total de Imagem {:8}: {:7}'.format('', len(data)))\n    for ix, label in zip(range(11), lables):\n        print('Total de {:15}: {:7} - {:6.2%}'.format(label, \n                                                      len(data[data[classe] == ix]),\n                                                      len(data[data[classe] == ix]) \/ len(data)\n                                                     ))\n    fig = plt.figure(figsize=(15,5))\n    sns.countplot(x=classe, data=data)","95c4d579":"spoof_type = ['Live', 'Photo', 'Poster', 'A4', 'Face Mask', 'Upper Body Mask',\n              'Region Mask', 'PC', 'Pad', 'Phone', '3D Mask']\n\nshowInfo(df_train, 'C40', spoof_type)","734d411c":"showInfo(df_test, 'C40', spoof_type)","1c721d58":"illumination_Condition = ['Live', 'Normal', 'Strong', 'Back', 'Dark']\nshowInfo(df_train, 'C41', illumination_Condition)","35b6f367":"showInfo(df_test, 'C41', illumination_Condition)","25f88546":"environment = ['Live', 'Indoor', 'Ourdoor']\nshowInfo(df_train, 'C42', environment)","c473321b":"showInfo(df_test, 'C42', environment)","2011cdb8":"live_spoof = ['Live', 'Spoof']\nshowInfo(df_train, 'C43', live_spoof)","600a4f66":"showInfo(df_test, 'C43', live_spoof)","e23a69ab":"df_train","ab7e527c":"df_train_final = df_train[['Filepath', 'C40']]\ndf_test_final = df_test[['Filepath', 'C40']]","67ab427f":"def get_Class(classe):\n    if classe == 0:\n        return 'live'\n    elif classe == 1:\n        return 'photo'\n    elif classe == 2:\n        return 'poster'\n    elif classe == 3:\n        return 'a4'\n    elif classe == 4:\n        return 'faceMask'\n    elif classe == 5:\n        return 'upperBodyMask'\n    elif classe == 6:\n        return 'regionMask'\n    elif classe == 7:\n        return 'pc'\n    elif classe == 8:\n        return 'pad'\n    elif classe == 9:\n        return 'phone'\n    elif classe == 10:\n        return '3dMask'\n    return 'other'\n\ndef set_Filepath(filepath):\n    return filepath.replace('Data', 'preprocessing')","c4831c7f":"df_train_final['Class'] = df_train_final['C40'].apply(get_Class)\ndf_test_final['Class'] = df_test_final['C40'].apply(get_Class)","813437fe":"df_train_final.Class.unique()","5ff79d3f":"df_train_final.head(15)","822edf20":"fig = plt.figure(figsize=(15,5))\nsns.countplot(x=\"Class\", data=df_train_final)","65b7e589":"train_datagen = ImageDataGenerator(rescale=1.0\/255, validation_split=0.1)\ntest_datagen = ImageDataGenerator(rescale = 1.0\/255)    ","4b0f6430":"train_generator = train_datagen.flow_from_dataframe(df_train_final,\n                                                    directory=path_local, x_col='Filepath', y_col='Class',\n                                                    target_size=IMG_SHAPE[:-1],\n                                                    label_mode='category',\n                                                    batch_size=BATCH_SIZE, \n                                                    shuffle=True,\n                                                    subset='training')\n\nval_generator = train_datagen.flow_from_dataframe(df_train_final,\n                                                  directory=path_local, x_col='Filepath', y_col='Class',\n                                                  target_size=IMG_SHAPE[:-1],\n                                                  label_mode='category',\n                                                  batch_size=BATCH_SIZE,\n                                                  shuffle=True,\n                                                  subset='validation')\n\ntest_generator = test_datagen.flow_from_dataframe(df_test_final,\n                                                  directory=path_local, x_col='Filepath', y_col='Class',\n                                                  target_size = IMG_SHAPE[:-1], \n                                                  label_mode='category',\n                                                  shuffle = False)","65c9f1f2":"test_generator.class_indices","f78a5d52":"with open('celeba_labels.pickle', 'wb') as handle:\n    pickle.dump(test_generator.class_indices, handle, protocol=pickle.HIGHEST_PROTOCOL)","3301b049":"with open('celeba_labels.pickle', 'rb') as handle:\n    celeba_labels = pickle.load(handle)","a77df24e":"celeba_labels","bcc83b31":"mobilenet = MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')","3a83c87e":"model = tf.keras.models.Sequential([mobilenet,\n                                    GlobalAveragePooling2D(),\n                                    Dense(512, activation='relu'),\n                                    BatchNormalization(),\n                                    Dropout(0.3),\n                                    Dense(128, activation = \"relu\"),\n                                    Dropout(0.1),\n                                    Dense(len(celeba_labels), activation='softmax')\n                                   ], name='rica_MobileNetV2')\nmodel.layers[0].trainable = True","3e02da0b":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","926c1912":"filepath=\"transferlearning_weights.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')","5f51e6af":"lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_delta=ALPHA, patience=3, verbose=1)","cecfb72f":"callbacks = [checkpoint, lr_reduce]","827da7f1":"#filepathModel = '.\/transferlearning_weights.hdf5'\n#model.load_weights(filepath)","e4cf017e":"hist = model.fit(train_generator,\n                 validation_data=val_generator,\n                 callbacks = callbacks,\n                 epochs=EPOCHS)","b60cb885":"plt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nplt.plot(hist.history['accuracy'])\nplt.title('Precis\u00e3o vs Epoca')\nplt.xlabel('Epoca')\nplt.ylabel('Precis\u00e3o')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(hist.history['loss'])\nplt.title('Perda vs Epoca')\nplt.xlabel('Epoca')\nplt.ylabel('Perda')\nplt.legend()\nplt.show()","7149f155":"epochs = EPOCHS\ntrain_loss = hist.history['loss']\nval_loss = hist.history['val_loss']\ntrain_acc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\nxc = range(epochs)\n\nplt.figure(1,figsize=(7,5))\nplt.plot(xc,train_loss)\nplt.plot(xc,val_loss)\nplt.xlabel('num of Epochs')\nplt.ylabel('loss')\nplt.title('train_loss vs val_loss')\nplt.grid(True)\nplt.legend(['train','val'])\n#print plt.style.available # use bmh, classic,ggplot for big pictures\n#plt.style.use(['classic'])\n\nplt.figure(2,figsize=(7,5))\nplt.plot(xc,train_acc)\nplt.plot(xc,val_acc)\nplt.xlabel('num of Epochs')\nplt.ylabel('accuracy')\nplt.title('train_acc vs val_acc')\nplt.grid(True)\nplt.legend(['train','val'],loc=4)\n#print plt.style.available # use bmh, classic,ggplot for big pictures\n#plt.style.use(['default'])","d2f6002e":"loss, accuracy  = model.evaluate(train_generator)\nprint('Loss: {}'.format(loss))\nprint('Accuracy: {:.2%}'.format(accuracy))","43fcf77a":"loss, accuracy  = model.evaluate(test_generator)\nprint('Loss: {}'.format(loss))\nprint('Accuracy: {:.2%}'.format(accuracy))","00d13473":"predict = model.predict(test_generator, verbose=1)","a7aa1e95":"y_pred = predict.argmax(axis=1)","f284b476":"y_test = test_generator.classes","a5117ad1":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","5d8097dd":"print(classification_report(y_test, y_pred, target_names=celeba_labels))","df36f7f4":"import itertools\n\n# Criei um grafico para mostrar a matrix de confus\u00e3o\n# link de referencia: https:\/\/scikit-learn.org\/0.16\/auto_examples\/model_selection\/plot_confusion_matrix.html\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Matriz de confus\u00e3o', cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '{:.2%}' if normalize else '{:d}'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, \n                 fmt.format(cm[i, j]),\n                 horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('Real')\n    plt.xlabel('Predi\u00e7\u00e3o')\n    plt.tight_layout()","8c7cf18f":"cm = confusion_matrix(y_test, y_pred)\ncm","bbf59f01":"plot_confusion_matrix(cm, classes=celeba_labels, normalize=False)\nplt.show()","accb0ee7":"model.save('CelebA_Spoof_MobileNetV2_11_class.h5')","6fa8755c":"### Load Labels","8ceaacae":"### Callback","0d37ea9d":"### Save Labels","1193cef3":"### Spoofing Type","9d5bba54":"### Treino","1961457e":"### build model MobileNetV2","3233bf30":"### EDA","7d7da7b0":"### Live\/Spoof","fe0a5ec9":"### Illumination Condition","b973103d":"### Environment"}}