{"cell_type":{"df86f037":"code","edda21b1":"code","f9b20c3d":"code","5735f141":"code","efacc863":"code","b20317c8":"code","cab7eb85":"code","dde1ed76":"code","8d65ac96":"code","2859b2a1":"code","2fe19aef":"code","acbff85a":"code","e659e7eb":"code","d5a6a5f2":"code","40107adc":"code","de142bd6":"code","7f63d2af":"code","d9f9e844":"code","423ff789":"code","ca8279a9":"code","956697e0":"code","21a7e863":"code","efdcfe70":"markdown","bcbe7944":"markdown","26e256ed":"markdown","55d033ea":"markdown","fb6779a2":"markdown"},"source":{"df86f037":"!pip install pyfpgrowth","edda21b1":"import cv2\nimport time\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm_notebook\nimport pyfpgrowth as fpg\nimport matplotlib.pyplot as plt","f9b20c3d":"path = '..\/input\/understanding_cloud_organization\/'","5735f141":"train = pd.read_csv('{}\/\/train.csv'.format(path))","efacc863":"tr_image_path = '{}\/\/train_images\/\/'.format(path)","b20317c8":"print('Training Data shape {}'.format(train.shape))","cab7eb85":"train.head()","dde1ed76":"train[['Image_ID','Image_Label']] = train.Image_Label.str.split('_', expand=True) ","8d65ac96":"train.head()","2859b2a1":"train.to_csv('train_processsed.csv')","2fe19aef":"# creating another dataframe with redudant label entries removed\nlabelcount = train[['Image_ID', 'Image_Label', 'EncodedPixels']].groupby('Image_ID').apply(lambda x: x.dropna()['Image_Label'].values).reset_index()\nlabelcount = labelcount.rename(columns = {0: 'labels'})\nlabelcount['label_counts'] = labelcount['labels'].apply(lambda x: len(x))            ","acbff85a":"labelcount.head()","e659e7eb":"def get_hist(df, col):\n    ax = df[col].value_counts().plot(kind = 'bar', figsize=(10,7),\n                                        fontsize=10);\n    ax.set_alpha(0.8)\n\n    # create a list to collect the plt.patches data\n    totals = []\n\n    # find the values and append to list\n    for i in ax.patches:\n        totals.append(i.get_width())\n\n    # set individual bar lables using above list\n    total = sum(totals)\n\n    # set individual bar lables using above list\n    for i in ax.patches:\n        # get_width pulls left or right; get_y pushes up or down\n        ax.text(i.get_x()+.1, i.get_height()+.5, str(i.get_height()), fontsize=15,\n    color='black')\n        \n    return ax","d5a6a5f2":"ax = get_hist(labelcount, 'label_counts')\nax.set_title(\"Histogram of Label Counts per Image\", fontsize=18)\nax.set_xlabel(\"Number of occurrences\", fontsize=18)\nplt.show()","40107adc":"ax = get_hist(train.dropna(), 'Image_Label')\nax.set_title(\"Histogram of Labels (with valid masks)\", fontsize=18)\nax.set_xlabel(\"Label\", fontsize=18);","de142bd6":"patterns = fpg.find_frequent_patterns(labelcount['labels'], 2)\npatternsdf = pd.DataFrame({'Label Association': list(patterns.keys()), 'Occurrences': list(patterns.values())})","7f63d2af":"f = plt.figure(figsize = (15,10))\nax = patternsdf.plot(x = 'Label Association', y = 'Occurrences', kind = 'bar')\nfor i in ax.patches:\n    ax.text(i.get_x()-0.2, i.get_height()+.5, str(i.get_height()), fontsize=10, color='black')\nplt.show()","d9f9e844":"rules = fpg.generate_association_rules(patterns, 0.3)\nrulesdf = pd.DataFrame({'Association Rules': list(rules.keys()), \n                        'Labels': [0]*len(list(rules.keys())), 'Probabilities': list(rules.values())})\nrulesdf.loc[:, 'Labels'] = rulesdf['Probabilities'].apply(lambda x: x[0][0])\nrulesdf.loc[:, 'Probabilities'] = rulesdf['Probabilities'].apply(lambda x: x[1])\nrulesdf = rulesdf.sort_values('Probabilities', ascending = False)","423ff789":"rulesdf","ca8279a9":"# run length encoding function\ndef rle_decode(mask,shape=(1400,2100)):\n    \n    s=mask.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts-=1\n    end=starts+lengths\n    img=np.zeros(shape[0]*shape[1],dtype=np.uint8)\n    for l,m in zip(starts,end):\n        img[l:m]=1\n    return img.reshape(shape[0],shape[1],order='F')","956697e0":"train.loc[:, 'MaskArea'] = train['EncodedPixels'].apply(lambda x: np.sum(rle_decode(str(x))) if not pd.isna(x) else 0)","21a7e863":"# distribution plots for mask areas for different labels\nf, ax = plt.subplots(1, 1, figsize = (10, 7))\nsns.distplot(train[(train['Image_Label'] == 'Fish') & \n                   (train['MaskArea'] > 0)]['MaskArea'], kde=True, hist=False, ax = ax, color = 'red')\nsns.distplot(train[(train['Image_Label'] == 'Flower') & \n                   (train['MaskArea'] > 0)]['MaskArea'], kde=True, hist=False, ax = ax, color = 'blue')\nsns.distplot(train[(train['Image_Label'] == 'Gravel') & \n                   (train['MaskArea'] > 0)]['MaskArea'], kde=True, hist=False, ax = ax, color = 'green')\nsns.distplot(train[(train['Image_Label'] == 'Sugar') & \n                   (train['MaskArea'] > 0)]['MaskArea'], kde=True, hist=False, ax = ax, color = 'black')\nax.legend(labels=['Fish', 'Flower', 'Gravel', 'Sugar'])\nplt.show()","efdcfe70":"### Label Associations","bcbe7944":"### Image Analysis","26e256ed":"### Importing Libraries","55d033ea":"# Exploratory Analysis of Satellite Cloud Data","fb6779a2":"### References:\n\n1. https:\/\/www.kaggle.com\/ekhtiar\/eda-find-me-in-the-clouds"}}