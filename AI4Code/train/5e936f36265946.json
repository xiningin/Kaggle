{"cell_type":{"8b49b091":"code","a62b48cd":"code","38b6d3dd":"code","34ac446b":"code","00e2a6d3":"code","aa09432a":"code","b5f35685":"code","6cfdde00":"code","f81afb14":"code","83c26f07":"code","e94686b8":"code","de6bf807":"code","7fa7324c":"code","68f3946f":"code","e1532188":"code","2682081d":"code","dec83f78":"code","fad0a6e1":"code","9877fb47":"code","ba062283":"code","ef5dda7e":"code","cf1545d5":"code","c321342f":"code","6ef8cc5a":"code","86baa793":"code","1096cd91":"code","9bd77c48":"code","625d33a8":"code","e72e3430":"code","9273fd1d":"markdown","9519ff94":"markdown","9d375eef":"markdown","2aa15ec3":"markdown","79d22748":"markdown","7bb70777":"markdown"},"source":{"8b49b091":"# Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","a62b48cd":"df = pd.read_csv(\"..\/input\/insurance.csv\")","38b6d3dd":"print (df.head())\nprint (df.info())","34ac446b":"df.shape","00e2a6d3":"sns.kdeplot(df[df['sex']=='female']['charges'], shade=True, label = 'Female charge')\nsns.kdeplot(df[df['sex']=='male']['charges'], shade=True, label = 'Male charge')\n","aa09432a":"sns.swarmplot(x='sex', y='charges', data=df)","b5f35685":"#The impact of smoke on charges\n\ndf.groupby(\"smoker\")['charges'].agg('mean').plot.bar()","6cfdde00":"sns.scatterplot(x='bmi', y='charges',hue='smoker',data=df)","f81afb14":"sns.regplot(x='bmi',y='charges',data=df)","83c26f07":"sns.lmplot(x='bmi',y='charges',hue='sex',data=df)","e94686b8":"sns.scatterplot(x='age', y='charges', hue='sex',data=df)","de6bf807":"sns.lineplot(x='children', y='charges',  estimator=np.median, data=df);","7fa7324c":"#sns.lineplot(x='children', y='charges', data=df);\n#sns.scatterplot(x='children', y='charges', data=df)\ndf.groupby('children')['charges'].agg('median')","68f3946f":"df.info()","e1532188":"df_dummies = pd.get_dummies(df)\ndf_dummies.head()","2682081d":"from sklearn.model_selection import train_test_split","dec83f78":"X = df_dummies.drop('charges', axis= 1)\ny = df_dummies.charges\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","fad0a6e1":"from sklearn.linear_model import LinearRegression","9877fb47":"lm = LinearRegression()\nlm.fit(X_train, y_train)","ba062283":"from sklearn.metrics import mean_absolute_error\n\nmean_absolute_error(y_test, lm.predict(X_test))","ef5dda7e":"avg_charges = pd.Series([y_test.mean()]* y_test.shape[0])\navg_charges\nmean_absolute_error(y_test, avg_charges)","cf1545d5":"from sklearn.linear_model import Lasso,Ridge, ElasticNet","c321342f":"ridge = Ridge()\nridge.fit(X_train, y_train)\nmean_absolute_error(y_test, ridge.predict(X_test))","6ef8cc5a":"lasso = Lasso(alpha=0.1)\nlasso.fit(X_train, y_train)\nmean_absolute_error(y_test, lasso.predict(X_test))","86baa793":"elasticnet = ElasticNet()\nelasticnet.fit(X_train,y_train)\nmean_absolute_error(y_test, elasticnet.predict(X_test))","1096cd91":"from sklearn.model_selection import GridSearchCV","9bd77c48":"params = {'alpha': [0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}\n\nparams_elastic ={'alpha': [0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n                'l1_ratio': [0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}","625d33a8":"# Ridge\nridge_cv = GridSearchCV(ridge, params, scoring = 'neg_mean_absolute_error')\nridge_cv.fit(X_train,y_train)\n\n# Lasso\nlasso_cv = GridSearchCV(lasso, params, scoring = 'neg_mean_absolute_error')\nlasso_cv.fit(X_train,y_train)\n\n# Elastic Net\nelasticnet_cv = GridSearchCV(elasticnet, params_elastic, scoring = 'neg_mean_absolute_error')\nelasticnet_cv.fit(X_train,y_train)","e72e3430":"print (ridge_cv.best_params_)\nprint (lasso_cv.best_params_)\nprint (elasticnet_cv.best_params_)\nprint (mean_absolute_error(y_test, ridge_cv.predict(X_test)))\nprint (mean_absolute_error(y_test, lasso_cv.predict(X_test)))\nprint (mean_absolute_error(y_test, elasticnet_cv.predict(X_test)))","9273fd1d":"# Ridge, Lasso and Elastic Net Regression\n\nWe are going to implement Ridge and Lasso regressions to test the improvement of these models. Especially we wish to see a huge improvement compared to our baseline model (Mean_absolute_error : 9596.63)","9519ff94":"# Baseline Model\n\nTo compare the models, we need to have a baseline model.\n\nIn our baseline model, the predicted values (^y) are the average of response values (y).","9d375eef":"# Missing values\n\nGood news: 0 missing data in this dataset","2aa15ec3":"# Future Consideration\n\n1. Feature Selection\n2. Feature Extraction\n3. Cross validation\n4. Other Models: DecisionTreeRegressor, RandomForestRegressor and many more ensemble models","79d22748":"# Hyperparameter Tuning\n\nThe improvements can be observed from the Ridge and Lasso regressions. Next, we are going to take this to the next level by tuning the hyperparameter. **GridSearchCV** is the best function in sklearn library to test these tweaks.","7bb70777":"## Conclusion\n\n**Lasso regression** is a superior model as it gives the lowest mean absolute error."}}