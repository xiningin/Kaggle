{"cell_type":{"415ab35b":"code","6b3f57f6":"code","22531bd9":"code","f141dce4":"code","3327eed8":"code","1e590c3c":"code","7c8f9963":"code","4be268ec":"code","e47808b3":"code","0f732e4c":"code","69a4d2a4":"code","dc16e8ed":"code","d3bda2ba":"code","4dd1f022":"code","d83d9e35":"code","c67e90c0":"code","dabc79b2":"code","41110a90":"markdown","f5869d74":"markdown","5471d721":"markdown","33debdf8":"markdown","7cc705c2":"markdown","414d6698":"markdown","53ef7579":"markdown","7956edca":"markdown","c012b1b6":"markdown","929aac08":"markdown"},"source":{"415ab35b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pylab as plt\nimport tensorflow as tf\n\nSEED = 123                 # to be able to rerun the same NN\nnp.random.seed(SEED)\ntf.set_random_seed(SEED)\n\nnp.set_printoptions(precision=4, suppress=True, floatmode='fixed')\n\n%matplotlib inline","6b3f57f6":"!nvidia-smi","22531bd9":"!lscpu","f141dce4":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n!ls -lh ..\/input\/\n\n# Any results you write to the current directory are saved as output.","3327eed8":"import scipy.io as sio\n\ntrain_data = sio.loadmat('..\/input\/train_32x32.mat')\ntest_data = sio.loadmat('..\/input\/\/test_32x32.mat')\nextra_data = sio.loadmat('..\/input\/extra_32x32.mat')\n\nX_train, y_train = train_data['X'], train_data['y']\nX_test, y_test = test_data['X'], test_data['y']\nX_extra, y_extra = extra_data['X'], extra_data['y']\n\nclasses = [0,1,2,3,4,5,6,7,8,9]\nnb_classes = 10\n\nprint(X_train.shape, X_test.shape, X_extra.shape)","1e590c3c":"# on r\u00e9ordonne pour correspondre \u00e0 l'ordre de Tensorflow\nX_train = np.transpose(X_train,(3,0,1,2))\nX_test = np.transpose(X_test,(3,0,1,2))\nX_extra = np.transpose(X_extra,(3,0,1,2))\n\n# on fusionne les donn\u00e9es de base avec les extras\nX_train = np.concatenate([X_train, X_extra])\ny_train = np.concatenate([y_train, y_extra])\n\n# et on normalise\nX_train = X_train.astype('float32') \/ 255\nX_test = X_test.astype('float32') \/ 255","7c8f9963":"from keras.utils import to_categorical\n\nprint(y_train[:4])\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\ny_train[:4]","4be268ec":"i = np.random.randint(1, len(X_train))\nprint(\"Label %d is\" % i, y_train[i])\nplt.imshow(X_train[i])","e47808b3":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n\nmodel = Sequential()\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=X_train[0].shape))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(len(y_train[0]), activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',      \n              metrics=['accuracy'])","0f732e4c":"model.summary()","69a4d2a4":"model_history = model.fit(X_train, y_train, batch_size=128, epochs=5, validation_split = 0.1)","dc16e8ed":"score = model.evaluate(X_test, y_test, verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])","d3bda2ba":"res_test = model.predict(X_test)","4dd1f022":"res_test = pd.DataFrame({'true':np.argmax(y_test, axis=1), 'guess':np.argmax(res_test, axis=1), 'trust':np.max(res_test, axis=1)})\nres_test.head(10)","d83d9e35":"errors = res_test[res_test.true != res_test.guess].sort_values('trust', ascending=False)\nerrors.head(10)","c67e90c0":"print('Percentage of error %4.2f %%' % (100 * len(errors)\/len(X_test))) # on v\u00e9rifie que c'est bien le r\u00e9sultat donn\u00e9 ci-dessus","dabc79b2":"i = 15700 #1318\nres = model.predict(X_test[i][None,:,:])  # None permet d'augmenter la dimension du tableau (sans on a un message d'erreur clair)\nprint(\"Image\", i)\nprint(f\"Model says it is a {np.argmax(res)} while it is a {np.argmax(y_test[i])}\")\nprint(\"Stats are\", np.array(res))\nplt.imshow(X_test[i])","41110a90":"## Le mod\u00e8le\n\nOn fait un r\u00e9seau neuronal convolutif.\n","f5869d74":"## Les donn\u00e9es\n\nOn a ajout\u00e9 \u00e0 notre r\u00e9pertoire `input` un jeux de donn\u00e9e trouv\u00e9 sur Kaggle via `Add Data` puis la recherche de `svhn dataset` (icone orange et noire).","5471d721":"# Google Street View House Number\n\nVoici une base d'image de qualit\u00e9 tr\u00e8s variable qui propose des chiffres \u00e0 reconnaitre. Elle a \u00e9t\u00e9 largement \u00e9tudi\u00e9e et est un bon exemple\nde ce que savent faire les r\u00e9seaux neuronaux convolutifs.","33debdf8":"### Notre environnement\n\nRegardons la machine que l'on a (il y a aussi des informations dans le cadre en haut \u00e0 droite `Sessions`).\n\nAttention, pour cette feuille Jupyter le GPU a \u00e9t\u00e9 activ\u00e9 mais ce n'est pas le cas par d\u00e9faut, aussi lorsque vous cr\u00e9ez une nouvelle feuille, penser \u00e0 mettre le GPU \u00e0 `on` dans `Settings` (si vous en avez besoin).\nInternet n'est n\u00e9cessaire que si vous d\u00e9sirez y r\u00e9cup\u00e9rer des donn\u00e9es qui ne sont pas sur Kaggle.","7cc705c2":"### Exercice\n\nC'est pas mal pour un r\u00e9seau aussi simple mais bizarrement le test est nettement moins bon que les donn\u00e9es de validation. Regardez ce qui existe sur la toile pour faire un r\u00e9seau avec plus de couches de convolution et autres astuces pour obtenir un bien meilleur r\u00e9sultat. Faites\nles modifications n\u00e9cessaire pour am\u00e9rliorer les r\u00e9sultats.","414d6698":"On note que bizarrement il y a 11 cat\u00e9gories. En fait `to_categorical` s'attend \u00e0 ce que les cat\u00e9gories soient num\u00e9rot\u00e9es \u00e0 partir de 0 or SVHN num\u00e9rote \u00e0 partir de 1. On a donc une cat\u00e9gorie qui sert \u00e0 rien.\n\nPour contourner ce probl\u00e8me il faudrait mettre les 0 dans la cat\u00e9rogie 0 et non dans la cat\u00e9gorie 10 comme c'est le cas actuellement (`y_train[y_train == 10] = 0` et pareil pour `y_test`).","53ef7579":"Tient, des donn\u00e9es fausses ?","7956edca":"## Analyse des r\u00e9sultats","c012b1b6":"Il est plus simple pour le r\u00e9seau de donner une estimation pour chaque cat\u00e9gorie et donc d'avoir autant de sorties qu'il y a de cat\u00e9gories que de donner le num\u00e9ro de la cat\u00e9gorie. Donc on convertit les Y.","929aac08":"Regardons les mauvais r\u00e9sultats :"}}