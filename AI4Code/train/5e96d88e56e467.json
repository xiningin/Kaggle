{"cell_type":{"b1c1497a":"code","bb051aa8":"code","4c36fa3a":"code","49631841":"code","6bac1c87":"code","a425e5f0":"code","47ee760b":"code","c8a60206":"markdown","d2083860":"markdown","7955361f":"markdown","77d1f81b":"markdown","948241a6":"markdown","b5fb6bf3":"markdown","3b11b726":"markdown"},"source":{"b1c1497a":"import numpy as np\nimport pandas as pd\n\n\nraw_training_data = pd.read_csv('..\/input\/titanic\/train.csv')\nraw_test_data = pd.read_csv('..\/input\/titanic\/test.csv')","bb051aa8":"print(raw_training_data.columns)\nprint(raw_training_data.shape)\nraw_training_data.describe()","4c36fa3a":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.countplot(x=raw_training_data['Sex'], hue=raw_training_data['Survived'])\nplt.show()\nsns.countplot(x=raw_training_data['Embarked'], hue=raw_training_data['Survived'])\n","49631841":"features = [\"Sex\", \"SibSp\", \"Parch\"]\ntemp_train = raw_training_data[\"Pclass\"].astype('object')\ntemp_train = pd.concat([temp_train, raw_training_data[features]], axis=1)\nfiltered_training = pd.get_dummies(temp_train)\n","6bac1c87":"from sklearn.linear_model import LinearRegression, SGDClassifier, LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score,train_test_split, GridSearchCV\n\nfrom sklearn.metrics import mean_squared_error\n\nprint(filtered_training.columns)\nX = filtered_training\ny = raw_training_data['Survived']\n\n# This was semi useful in determining which model was best, but I ended up needing to use all the test data\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state=114)\n\n# Models\nlr = LinearRegression()\nlogreg = LogisticRegression()\nsgd = SGDClassifier(alpha=0.1)\nknn = KNeighborsClassifier(n_neighbors=4)\ndtc = DecisionTreeClassifier(max_depth=6)\nrf = RandomForestClassifier()\n\n# Fit models\nlr.fit(X,y)\nsgd.fit(X,y)\nknn.fit(X,y)\ndtc.fit(X,y)\nrf.fit(X, y)\n","a425e5f0":"# Help choose params\n\n# knn_params = {'n_neighbors':[1,2,3,4,5,6,7]}\n# sgd_params = {'alpha': [1, 0.1,0.01,0.001,0.0001]}\n# logreg_params = {'C': [1, 0.1,0.01,0.001,0.0001]}\n\n# knn_gscv = GridSearchCV(knn, knn_params)\n# knn_gscv.fit(X,y)\n# print(knn_gscv.best_params_)\n\n# sgd_gscv = GridSearchCV(sgd, sgd_params)\n# sgd_gscv.fit(X,y)\n# print(sgd_gscv.best_params_)\n\n# logreg_gscv = GridSearchCV(logreg, logreg_params)\n# logreg_gscv.fit(X,y)\n# print(logreg_gscv.best_params_)\n\n# LogReg and RF for funsies, \n# super insane score compared to the ones we were allowed to use\nlr_sum = 0\nsgd_sum = 0\nknn_sum = 0\ndtc_sum = 0\nrf_sum = 0\nlogreg_sum = 0\nfor i in range(1000):\n    lr_sum += lr.score(X,y)\n    sgd_sum += sgd.score(X,y)\n    knn_sum += knn.score(X,y)\n    dtc_sum += lr.score(X,y)\n    rf_sum += rf.score(X,y)\n    logreg_sum += rf.score(X,y)\n\nlr_avg = lr_sum \/ 1000\nsgd_avg = sgd_sum \/ 1000\nknn_avg = knn_sum \/ 1000\ndtc_avg = dtc_sum \/ 1000\nrf_avg = rf_sum \/ 1000\nlogreg_avg = logreg_sum \/ 1000\nprint(\"lr avg: \",lr_avg)\nprint(\"sgd avg: \",sgd_avg)\nprint(\"knn avg: \",knn_avg)\nprint(\"dtc: avg\",dtc_avg)\nprint(\"rf: avg\",rf_avg)\nprint(\"logreg: avg\",logreg_avg)","47ee760b":"features = [\"Sex\", \"SibSp\", \"Parch\"]\ntemp_test = raw_test_data[\"Pclass\"].astype('object')\ntemp_test = pd.concat([temp_test, raw_test_data[features]], axis=1)\nfiltered_test = pd.get_dummies(temp_test)\nprint(filtered_test.dtypes)\n\npredictions = sgd.predict(filtered_test)\n\ndf_predictions = pd.DataFrame(raw_test_data['PassengerId'])\ndf_predictions['Survived'] = predictions\n\ndf_predictions.to_csv('sgd.csv', index=False)\n","c8a60206":"# Loading Data\n\nHere I import the basic libraries I will need as well as load the Titanic data into DataFrames","d2083860":"Here's some general info and statistics about the raw data for reference later.","7955361f":"# Exploratory Data Analysis","77d1f81b":"# Generate Submission Data\nHere I prepare the given test data for prediction","948241a6":"# Model Selection and Test Split\n\nHere's where I split the test data and run my own tests on several models to determine which is the best.\n\n","b5fb6bf3":"# Feature Engineering","3b11b726":"# Evaluate Models"}}