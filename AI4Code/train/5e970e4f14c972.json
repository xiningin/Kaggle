{"cell_type":{"50772ce0":"code","c5f86cba":"code","e9232707":"code","45ebd0ee":"code","3ee63625":"code","2145b2c1":"code","b59e352d":"code","a0cd64a5":"code","41d48215":"code","9a4861c5":"code","a37ef1f8":"code","cf0f2cca":"code","9f36195b":"code","2f670dc7":"code","e76db9db":"code","1c4ca8e0":"code","c5c437d6":"code","56782943":"code","dc655aae":"code","70eaf3a8":"code","415581ee":"code","aea7282b":"code","bae46b9e":"code","380dfe02":"code","9fbb77b9":"code","a45d2047":"code","e677f309":"code","4dee11d4":"code","827cfb14":"code","eaaf2bf9":"code","6a069536":"code","c4ba6451":"code","8294f257":"code","4d044e80":"code","b0a91fdd":"code","dd2e7e21":"code","fa6fb4e6":"code","143221d4":"code","4155737d":"code","4a71438a":"code","05525c76":"code","d3185ec0":"code","3236bef3":"code","2719bc06":"code","bc84dfe3":"code","bdb45aaa":"code","114bd2a6":"code","ef2b76c7":"code","c38201c3":"code","e54e4618":"code","4bcf59dd":"code","b83476c0":"code","d011471d":"code","f61cf5ac":"code","633704ca":"code","761d6f04":"code","70d7c8ca":"code","d610a833":"markdown","b28dd0fd":"markdown","29b9c4bd":"markdown","b3048e83":"markdown","cfcc4e31":"markdown","41454a4a":"markdown","29fd2db7":"markdown","afcc8df6":"markdown","1c27def1":"markdown","f014cd95":"markdown","b79f20e0":"markdown","4449b60a":"markdown","95a69c8a":"markdown","f0f2f161":"markdown","fbf9e2d9":"markdown","7e8531af":"markdown","cef76808":"markdown","461e532b":"markdown","776fd84a":"markdown","97711eb0":"markdown","132b425f":"markdown","dff7f17f":"markdown","15ca8dc3":"markdown"},"source":{"50772ce0":"import os\nimport datetime","c5f86cba":"import pandas as pd\nimport numpy as np","e9232707":"from tqdm import tqdm","45ebd0ee":"from scipy.signal import find_peaks\nfrom scipy.integrate import cumtrapz","3ee63625":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nplt.style.use('ggplot')","2145b2c1":"DATA_PATH = '..\/input\/data-for-activity-recognition\/data\/data\/'","b59e352d":"running_folder = 'running'\nidle_folder = 'idle'\nwalking_folder = 'walking'\nstairs_folder = 'stairs'\n\nactivity_list = [running_folder, idle_folder, walking_folder, stairs_folder]","a0cd64a5":"# checking\n\nfor activity in activity_list:\n    file_names_list = os.listdir(os.path.join(DATA_PATH, activity))\n    print(activity, ': ', len(file_names_list))","41d48215":"def plot_3d_trajectory(x, y, z):\n    \"\"\" \n    Plot 3D Trajectory\n    Next we will calculate the phone\u2019s motion \n    by integrating the linear-accelerations, \n    and plot the results.\n    \"\"\"\n    x = cumtrapz(x)\n    y = cumtrapz(y)\n    z = cumtrapz(z)\n    \n    fig3,ax = plt.subplots()\n    fig3.suptitle('3D Trajectory of phone',fontsize=20)\n    ax = plt.axes(projection='3d')\n    ax.plot3D(x,y,z,c='red',lw=1,label='phone trajectory')\n    ax.set_xlabel('X position')\n    ax.set_ylabel('Y position')\n    ax.set_zlabel('Z position')\n    plt.show()","9a4861c5":"def plot_frequency_spectrum(x, y, z):\n    \"\"\" Plot Frequency spectrum \"\"\"\n    fig4,[ax1,ax2,ax3] = plt.subplots(3,1,sharex=True,sharey=True)\n    fig4.suptitle('Spectrum',fontsize=20)\n    ax1.plot(x,c='r',label='x')\n    ax1.legend()\n    ax2.plot(y,c='b',label='y')\n    ax2.legend()\n    ax3.plot(z,c='g',label='z')\n    ax3.legend()\n    ax3.set_xlabel('Freqeuncy (Hz)')\n    plt.show()","a37ef1f8":"def select_random_df(folder_name):\n    custom_path = os.path.join(DATA_PATH, folder_name)\n    data = pd.read_csv(os.path.join(custom_path, os.listdir(custom_path)[0]))\n    x = data.accelerometer_X.values\n    y = data.accelerometer_Y.values\n    z = data.accelerometer_Z.values\n    return x, y, z","cf0f2cca":"# running\nx,y,z = select_random_df(running_folder)\nplot_3d_trajectory(x, y, z)","9f36195b":"plot_frequency_spectrum(x, y, z)","2f670dc7":"# idle\nx,y,z = select_random_df(idle_folder)\nplot_3d_trajectory(x, y, z)","e76db9db":"plot_frequency_spectrum(x, y, z)","1c4ca8e0":"# walking\nx,y,z = select_random_df(walking_folder)\nplot_3d_trajectory(x, y, z)","c5c437d6":"plot_frequency_spectrum(x, y, z)","56782943":"# stairs\nx,y,z = select_random_df(stairs_folder)\nplot_3d_trajectory(x, y, z)","dc655aae":"plot_frequency_spectrum(x, y, z)","70eaf3a8":"def mean_calculator(three_axis):\n    \"\"\" Return mean of each vectors \"\"\"\n    three_axis = np.array(three_axis)\n    vector_x = three_axis[:, 0]\n    vector_y = three_axis[:, 1]\n    vector_z = three_axis[:, 2]\n    x_mean = np.mean(vector_x)\n    y_mean = np.mean(vector_y)\n    z_mean = np.mean(vector_z)\n    return x_mean, y_mean, z_mean","415581ee":"def std_calculator(three_axis):\n    \"\"\" Return standart deviation of each vectors \"\"\"\n    three_axis = np.array(three_axis)\n    vector_x = three_axis[:, 0]\n    vector_y = three_axis[:, 1]\n    vector_z = three_axis[:, 2]\n    x_std = np.std(vector_x)\n    y_std = np.std(vector_y)\n    z_std = np.std(vector_z)\n    return x_std, y_std, z_std","aea7282b":"def peaks_calculator(three_axis):\n    \"\"\" Return number of peaks of each vectors \"\"\"\n    three_axis = np.array(three_axis)\n    vector_x = three_axis[:, 0]\n    vector_y = three_axis[:, 1]\n    vector_z = three_axis[:, 2]\n    x_peaks = len(find_peaks(vector_x)[0])\n    y_peaks = len(find_peaks(vector_y)[0])\n    z_peaks = len(find_peaks(vector_z)[0])\n    return x_peaks, y_peaks, z_peaks","bae46b9e":"def feature_engineer(action, target, df):\n    try:\n        x_mean, y_mean, z_mean = mean_calculator(action)\n        x_std, y_std, z_std = std_calculator(action)\n        x_peaks, y_peaks, z_peaks = peaks_calculator(action)\n    except:\n        print(action.shape, target)\n    dictionary = {\n        'x_mean': x_mean,\n        'y_mean': y_mean, \n        'z_mean': z_mean,\n        'x_std': x_std, \n        'y_std': y_std,\n        'z_std': z_std,\n        'x_peaks': x_peaks, \n        'y_peaks': y_peaks, \n        'z_peaks': z_peaks,\n        'target': target\n    }\n    df = df.append(\n        dictionary, \n        ignore_index=True\n    )\n    return df","380dfe02":"columns = [\n    'x_mean', 'y_mean', 'z_mean', \n    'x_std', 'y_std', 'z_std', \n    'x_peaks', 'y_peaks', 'z_peaks',\n    'target'\n]\ndataframe = pd.DataFrame(columns=columns)","9fbb77b9":"for activity in activity_list:\n    activity_files = os.listdir(os.path.join(DATA_PATH, activity))\n    for file in activity_files:\n        try:\n            df = pd.read_csv(os.path.join(DATA_PATH, activity, file))\n            array = df.to_numpy()\n            dataframe = feature_engineer(\n                action=array, \n                target=activity, \n                df=dataframe\n            )\n        except:\n            print('some error')","a45d2047":"print(dataframe.shape)\ndataframe.head()","e677f309":"dataframe.target.unique()","4dee11d4":"dataframe['target'].value_counts()","827cfb14":"dataframe['target'].value_counts().plot(kind='barh')","eaaf2bf9":"# data frame to csv\n# dataframe.to_csv('data\/final_data.csv', index=False)","6a069536":"import sys","c4ba6451":"import numpy as np\nimport pandas as pd","8294f257":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","4d044e80":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier","b0a91fdd":"import seaborn as sns\nimport matplotlib.pyplot as plt","dd2e7e21":"df = dataframe","fa6fb4e6":"df.shape","143221d4":"df.head()","4155737d":"df = df.sample(frac=1).reset_index(drop=True)","4a71438a":"df.shape","05525c76":"df.head()","d3185ec0":"x_columns = [\n    'x_mean', 'y_mean', 'z_mean', \n    'x_std', 'y_std', 'z_std', \n    'x_peaks', 'y_peaks', 'z_peaks'\n]\nX = df[x_columns]\ny = df.target","3236bef3":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42\n)","2719bc06":"print('X tran shape:', X_train.shape)\nprint('X test shape:', X_test.shape)\nprint('y tran shape:', y_train.shape)\nprint('y test shape:', y_test.shape)","bc84dfe3":"labels = df.target.unique()","bdb45aaa":"def train_model(model):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(classification_report(y_test, y_pred))\n    return confusion_matrix(y_test, y_pred)","114bd2a6":"def visualize_confusion_matrix(cm, labels=labels):\n    df_cm = pd.DataFrame(cm, columns=labels, index=labels)\n    df_cm.index.name = 'Actual'\n    df_cm.columns.name = 'Predicted'\n    plt.figure(figsize = (10,7))\n    sns.set(font_scale=1.4)#for label size\n    sns.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16}, fmt='g')","ef2b76c7":"lr = LogisticRegression()\nlr_cm = train_model(lr)","c38201c3":"visualize_confusion_matrix(lr_cm)","e54e4618":"rf = RandomForestClassifier()\nrf_cm = train_model(rf)","4bcf59dd":"visualize_confusion_matrix(rf_cm)","b83476c0":"svc = SVC()\nsvc_cm = train_model(svc)","d011471d":"visualize_confusion_matrix(svc_cm)","f61cf5ac":"dt = DecisionTreeClassifier()\ndt_cm = train_model(dt)","633704ca":"visualize_confusion_matrix(dt_cm)","761d6f04":"gb = GradientBoostingClassifier()\ngb_cm = train_model(gb)","70d7c8ca":"visualize_confusion_matrix(gb_cm)","d610a833":"### Content\n1. [Import Modules](#1.-Import-for-ML)\n2. [Read data](#2.-Read-data)\n3. [Data preparation](#3.-Data-preparation)\n4. [Split data](#4.-Split-data)\n5. [Modeling](#5.-Modeling)\n\n - 5.1. [Logistic Regression](#5.1.-Logistic-Regression)\n - 5.2. [Random Forest](#5.2.-Random-Forest)\n - 5.3. [Support Vector Classification](#5.3.-Support-Vector-Classification)\n - 5.4. [Decision Tree](#5.4.-Decision-Tree-Classifier)\n - 5.5. [Gradient Boosting Classifier](#5.5.-Gradient-Boosting-Classifier)","b28dd0fd":"### 5. Modeling","29b9c4bd":"### [To start of ML](#Accelerometer-Signals-Classification-for-Activity-and-Movement-Recognition)","b3048e83":"**What is my goal?**\n\nI want to collect accelerometer data from my smart phone. And after that i want to create model, which will predict class of my activity (*for example: running or walking*).\n\n\n**How will I do it?**\n\nI will collect data with [AndroSensor](https:\/\/play.google.com\/store\/apps\/details?id=com.fivasim.androsensor). And I will use this data for modeling.\n\n![app screen](https:\/\/github.com\/OleksandrKosovan\/activity-recognition\/blob\/master\/img\/andro-sensor.png?raw=true)","cfcc4e31":"###### 5.3. Support Vector Classification","41454a4a":"### 4. Split data","29fd2db7":"###### 5.1. Logistic Regression","afcc8df6":"**What is accelerometer?**\n\nAn **accelerometer** is a device that measures proper acceleration. Proper acceleration, being the acceleration (or rate of change of velocity) of a body in its own instantaneous rest frame, is not the same as coordinate acceleration, being the acceleration in a fixed coordinate system. For example, an accelerometer at rest on the surface of the Earth will measure an acceleration due to Earth's gravity, straight upwards (by definition) of g \u2248 9.81 m\/s2. By contrast, accelerometers in free fall (falling toward the center of the Earth at a rate of about 9.81 m\/s2) will measure zero. [More...](https:\/\/en.wikipedia.org\/wiki\/Accelerometer)","1c27def1":"Path to metadata of data collection: **data\/metadata\/AndroSensorSettings.xml**","f014cd95":"**Schema of data preparation:**\n\n![img](https:\/\/github.com\/OleksandrKosovan\/activity-recognition\/blob\/master\/img\/data-preparation.jpg?raw=true)","b79f20e0":"### 4. Visualization of Accelerometer Signals","4449b60a":"###### 5.4. Decision Tree Classifier","95a69c8a":"##### 5.5. Gradient Boosting Classifier","f0f2f161":"###### 5.2. Random Forest","fbf9e2d9":"### 3. Research data\n","7e8531af":"### 3. Data preparation\n\nWe need to randomize the data","cef76808":"### 1. Introdaction","461e532b":"### Content\n\n1. [Introdaction](#1.-Introdaction)\n2. [Import](#2.-Import)\n3. [Research data](#3.-Research-data)\n4. [Visualization of Accelerometer Signals](#4.-Visualization-of-Accelerometer-Signals)\n5. [Feature engineering](#5.-Feature-engineering)","776fd84a":"### 2. Import ","97711eb0":"# Accelerometer Signals Classification for Activity and Movement Recognition\n\n![img](https:\/\/camo.githubusercontent.com\/ec2708af7a740e1a2396b777cf336b7c9804dc28\/68747470733a2f2f7777772e616e64726f6964686976652e696e666f2f77702d636f6e74656e742f75706c6f6164732f323031372f31322f616e64726f69642d757365722d61637469766974792d7265636f676e6974696f6e2d7374696c6c2d77616c6b696e672d72756e6e696e672d64726976696e672e6a7067)","132b425f":"### 2. Read data","dff7f17f":"### 1. Import for ML","15ca8dc3":"### 5. Feature engineering\n\nIn this section we report the notation and the preliminary definitions that we use throughout the paper. For sake of readability they have also be summarized in Table I. We denote $f$ as the index of a frame containing $N$ threeaxis accelerometer samples $s_{j, n}^{f},$ which is the $n$ -th sample, $n \\in[1, N],$ of the $j$ -th axis, $j \\in\\{x, y, z\\}$ for the $f$ -th frame. In the remaining of the paper, when it is not strictly necessary to distinguish among the three axes components, we omit the axis index $j .$ Consequently, the accelerometer sample containing the three axis components $\\left\\{s_{x, n}^{f}, s_{y, n}^{f}, s_{z, n}^{f}\\right\\}$ is denoted with $\\mathbf{s}_{n}^{f}$\nThe employed features for each $j$ -th axis are: $i$ ) mean $\\left(\\mu_{j}^{f}\\right),$ ii) standard deviation $\\left(\\sigma_{j}^{f}\\right),$ and iii number of peaks $\\left(P_{j}^{f}\\right) .$ Being well-known the formulae for $\\mu_{j}^{f}$ and $\\sigma_{j}^{f},$ we only report the definition of $P_{j}^{f}:$\n$$\n\\begin{array}{c}\nP_{j}^{f}=\\sum_{n} \\rho_{j, n}^{f} \\\\\n\\rho_{j, n}^{f}=\\left\\{\\begin{array}{ll}\n1, & \\text { if }\\left(s_{j, n+1}^{f}-s_{j, n}^{f}\\right)\\left(s_{j, n}^{f}-s_{j, n-1}^{f}\\right)<0,\\left\\|s_{j, n}^{f}\\right\\| \\geq \\epsilon \\\\\n0, & \\text { otherwise }\n\\end{array}\\right.\n\\end{array}\n$$\n\nThe quantity $\\epsilon$ is a threshold employed to define a signal peak, empirically set to $\\epsilon=0.75$ by of means of practical trials."}}