{"cell_type":{"5ccff72b":"code","8371fd9a":"code","c9d89cb0":"code","e13e478e":"code","97359fe7":"code","89eab413":"code","879c814d":"code","dbd09954":"code","dbdf983c":"code","81124f38":"code","580bdf43":"code","34d503db":"code","b5c6f2fb":"code","f1e98823":"code","738eaa12":"code","50b84528":"code","ddc89174":"code","cb87f913":"code","a9bec50a":"code","f7d72cb2":"code","2a459ad3":"code","c5e2d787":"code","ae0ed16b":"code","59f37afd":"code","093030ef":"code","c14e4c00":"code","496efb80":"code","d646e74e":"code","92c74075":"code","58198427":"code","96087026":"code","c729406e":"code","2513fba7":"code","e34e5326":"code","96199783":"code","51fe7634":"code","8724761a":"code","036309a9":"code","eb39148f":"code","7dfb937d":"code","b4cfd6dd":"code","a2cea84a":"code","ff1d002c":"code","1696febd":"code","7eecb232":"code","ea3c0242":"code","15a13fec":"code","91c9cf2a":"code","8d02a0f1":"code","55840690":"code","461f82fe":"code","41b500a5":"code","62cbc230":"code","0b0c3a41":"code","f8201933":"code","6f34040a":"code","e3e2fd80":"code","786aa723":"code","0083c70b":"code","fef7da34":"code","e2946169":"code","660aa4d5":"code","7c576c99":"code","9f7e343c":"code","72ff405c":"code","91b23268":"code","b3817f18":"code","895dae2d":"code","614a60b8":"code","2c6c850c":"markdown","2b51a05a":"markdown","8777e238":"markdown","ac9351a9":"markdown","6b9d551c":"markdown","a3e5fe96":"markdown","5767dd59":"markdown","6fc40029":"markdown","78e026b0":"markdown","4a84e08b":"markdown","5cc23573":"markdown","0b6f843e":"markdown","af91d614":"markdown","8a71b40e":"markdown","d857b350":"markdown","cf9109fa":"markdown","0e001008":"markdown","8d42bde2":"markdown","4d57ea90":"markdown","1236a641":"markdown","7dca6d68":"markdown","95eda140":"markdown","2b3a55a2":"markdown"},"source":{"5ccff72b":"# Import Library\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n\n# Set style\nplt.style.use('seaborn')\nsns.set(font_scale=2.5) \n\n# ignore Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","8371fd9a":"# Load Data\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\n\n# Check Train Data\ntrain.head(3)","c9d89cb0":"# Find Outliers\n\ndef detect_outliers(df,n,features):\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n# detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])\n\ntrain = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)","e13e478e":"# Concatenate train & test\nX_train = train.drop(['PassengerId'], axis=1)\nX_test = test.drop(['PassengerId'], axis=1)\ny_train = train.drop(['Survived'], axis=1)\n\ndataset = pd.concat([X_train, X_test]).reset_index(drop=True)","97359fe7":"# Info\ndataset.info()","89eab413":"# FInd null values\ndataset.isnull().sum()","879c814d":"# Null Ratio\nfor feature in dataset.columns :\n    print('\\'{}\\' Feature have {:.2f}% Null Ratio'.format(feature, dataset[feature].isnull().sum() \/ len(dataset[feature])))","dbd09954":"dataset.drop('Cabin', axis=1, inplace=True)","dbdf983c":"# Check Target Label\nf, ax = plt.subplots(1, 2, figsize=(13, 8))\n\nsns.countplot('Survived', data=train, ax=ax[0])\nax[0].set_title('Count Survived')\n\ntrain['Survived'].value_counts().plot.pie(explode=[0, 0.1],\n                                         autopct='%1.1f%%', ax=ax[1], shadow=True)\nax[1].set_title('Survival Probability')\n\nplt.show()","81124f38":"# Pclass\n\nf, ax = plt.subplots(1, 2, figsize=(15,8))\n\nsns.countplot('Pclass', data=train, ax=ax[0])\nax[0].set_title('Count Pclass passengers')\n\nsns.barplot('Pclass', 'Survived', data=train, ax=ax[1])\nax[1].set_title('Survival Probability')\n\nplt.show()","580bdf43":"# Crosstab & groupby\nprint(pd.crosstab(train['Survived'], train['Pclass'], margins=True))\nprint('-' * 50)\nprint(train[['Pclass', 'Survived']].groupby('Pclass').mean())","34d503db":"# factorplot\nsns.factorplot('Pclass', 'Survived', data=train)\nplt.ylabel('Survival Probablity')\nplt.show()","b5c6f2fb":"# Sex\nf, ax = plt.subplots(1, 2, figsize=(15,8))\n\nsns.countplot('Sex', data=train, ax=ax[0])\nax[0].set_title('Count passengers\\'s sex')\n\nsns.barplot('Sex', 'Survived', data=train, ax=ax[1])\nax[1].set_title('Survival Probability')\n\nplt.show()","f1e98823":"train[['Sex', 'Survived']].groupby('Sex').mean()","738eaa12":"sns.factorplot('Sex', 'Survived', data=train)\nplt.title('Survival Probablity')\nplt.show()","50b84528":"pd.crosstab(train['Sex'], train['Survived'], margins=True).style.background_gradient(cmap='summer_r')","ddc89174":"pd.crosstab([train['Sex'], train['Pclass']], train['Survived'], margins=True).style.background_gradient(cmap='summer_r')","cb87f913":"f, ax = plt.subplots(1, 1, figsize=(13, 8))\n\nsns.barplot('Pclass', 'Survived', hue='Sex', data=train, ax=ax)\nplt.legend(loc='best')\nplt.show()","a9bec50a":"# Embarked\ndataset['Embarked'].isnull().sum()","f7d72cb2":"dataset[dataset['Embarked'].isnull()]","2a459ad3":"dataset[dataset['Ticket'] == '113572']","c5e2d787":"dataset['Embarked'].value_counts()","ae0ed16b":"dataset['Embarked'] = dataset['Embarked'].fillna('S')","59f37afd":"f, ax = plt.subplots(1, 2, figsize=(15,8))\n\nsns.countplot('Embarked', data=train, ax=ax[0])\nax[0].set_title('Count Embarked')\n\nsns.barplot('Embarked', 'Survived', data=train, ax=ax[1])\nax[1].set_title('Survival Probability')\n\nplt.show()","093030ef":"pd.crosstab(dataset['Sex'], dataset['Embarked']).style.background_gradient(cmap='summer_r')","c14e4c00":"f, ax = plt.subplots(1, 1, figsize=(15,8))\npd.crosstab(dataset['Sex'], dataset['Embarked']).plot.bar(ax=ax)\nplt.show()","496efb80":"pd.crosstab(dataset['Pclass'], dataset['Embarked']).style.background_gradient(cmap='summer_r')","d646e74e":"f, ax = plt.subplots(1, 1, figsize=(15,8))\npd.crosstab(dataset['Pclass'], dataset['Embarked']).plot.bar(ax=ax)\nplt.show()","92c74075":"# SibSp\nf, ax = plt.subplots(1, 2, figsize=(15,8))\n\nsns.countplot('SibSp', data=dataset, ax=ax[0])\nax[0].set_title('Count SibSp')\n\nsns.barplot('SibSp', 'Survived', data=train, ax=ax[1])\nax[1].set_title('Survival Probability')\n\nplt.show()","58198427":"sns.factorplot('SibSp', 'Survived', data=train)\nplt.show()","96087026":"# Parch\nf, ax = plt.subplots(1, 2, figsize=(15,8))\n\nsns.countplot('Parch', data=dataset, ax=ax[0])\nax[0].set_title('Count Parch')\n\nsns.barplot('Parch', 'Survived', data=train, ax=ax[1])\nax[1].set_title('Survival Probability')\n\nplt.show()","c729406e":"sns.factorplot('Parch', 'Survived', data=train)\nplt.show()","2513fba7":"# Age\ntrain['Age'].describe()","e34e5326":"f, ax = plt.subplots(1, 2, figsize=(15,8))\n\nsns.distplot(train['Age'][train['Survived'] == 0], ax=ax[0], color='Red')\nax[0].set_title('Survived == 0')\nsns.distplot(train['Age'][train['Survived'] == 1], ax=ax[1])\nax[1].set_title('Survived == 1')\n\nplt.show()","96199783":"f, ax = plt.subplots(1, 1, figsize=(15,8))\n\nsns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 0) & (train[\"Age\"].notnull())], ax=ax, color='Red', label='Survived == 0')\nsns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 1) & (train[\"Age\"].notnull())], ax=ax, label='Survived == 1')\n\nplt.legend(loc='best')\nplt.show()","51fe7634":"f, ax = plt.subplots(1, 1, figsize=(15,8))\n\nsns.kdeplot(train[\"Age\"][(train[\"Sex\"] == 'male') & (train[\"Age\"].notnull())], ax=ax, color='Red', label='male')\nsns.kdeplot(train[\"Age\"][(train[\"Sex\"] == 'female') & (train[\"Age\"].notnull())], ax=ax, label='female')\n\nplt.legend(loc='best')\nplt.show()","8724761a":"f, ax = plt.subplots(1, 1, figsize=(18,8))\n\nsns.kdeplot(train[\"Age\"][train[\"Pclass\"] == 1], ax=ax, color='Red', label='First')\nsns.kdeplot(train[\"Age\"][train[\"Pclass\"] == 2], ax=ax, color='Green', label='Second')\nsns.kdeplot(train[\"Age\"][train[\"Pclass\"] == 3], ax=ax, label='Third')\n\n\nplt.legend(loc='best')\nplt.show()","036309a9":"# Fare\ndataset['Fare'].describe()","eb39148f":"dataset[['Fare', 'Pclass']].corr()","7dfb937d":"f, ax = plt.subplots(1, 2, figsize=(18,8))\n\nsns.distplot(train['Fare'][train['Survived'] == 0], ax=ax[0], color='Red',\n             label='Skewness : %.2f'%(train['Fare'].skew()))\nax[0].set_title('Survived == 0')\nsns.distplot(train['Fare'][train['Survived'] == 1], ax=ax[1],\n            label='Skewness : %.2f'%(train['Fare'].skew()))\nax[1].set_title('Survived == 1')\n\nplt.legend(loc='best')\nplt.show()","b4cfd6dd":"dataset[\"Fare\"] = dataset[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)","a2cea84a":"sns.kdeplot(dataset['Fare'])\nplt.show()","ff1d002c":"# Find NaN by Initial\ndataset['Initial']=0\nfor i in dataset:\n    dataset['Initial']=dataset.Name.str.extract('([A-Za-z]+)\\.')","1696febd":"dataset['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Other'],inplace=True)","7eecb232":"dataset.groupby('Initial')['Age'].mean()","ea3c0242":"f, ax = plt.subplots(2, 2, figsize=(20,20))\n\nsns.boxplot(y='Age', x='Sex', data=dataset, ax=ax[0,0])\nax[0,0].set_title('Age & Sex', size=20)\nsns.boxplot(y='Age', x='Pclass', data=dataset, ax=ax[0,1])\nax[0,1].set_title('Age & Pclass', size=20)\nsns.boxplot(y='Age', x='Embarked', data=dataset, ax=ax[1,0])\nax[1,0].set_title('Age & Embarked', size=20)\nsns.boxplot(y='Age', x='SibSp', data=dataset, ax=ax[1, 1])\nax[1, 1].set_title('Age & SibSp',size=20)\n\nplt.show()","15a13fec":"# Change 'Sex' into Num\ndataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})\n\n# FInd a correlationship\nsns.heatmap(dataset[['Age', 'Pclass', 'SibSp', 'Parch', 'Sex']].corr(), cmap='RdYlGn',annot=True)\nplt.show()","91c9cf2a":"train['Initial']=0\nfor i in train:\n    train['Initial']=train.Name.str.extract('([A-Za-z]+)\\.')\n\ntrain['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Other'],inplace=True)","8d02a0f1":"f, ax = plt.subplots(1,1,figsize=(15,10))\nsns.barplot('Initial', 'Survived', data=train, ax=ax)\nplt.show()","55840690":"index_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\n\nfor i in index_NaN_age :\n    age_pred = dataset[\"Age\"][(dataset['Initial'] == dataset.iloc[i]['Initial'])\n                               &(dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) \n                               & (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) \n                               & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"])].mean()\n    \n    age_pred2 = dataset[\"Age\"][(dataset['Initial'] == dataset.iloc[i]['Initial'])\n                                 &(dataset['SibSp'] == dataset.iloc[i][\"SibSp\"])  \n                                 & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"])].mean()\n    \n    age_pred3 = dataset[\"Age\"][(dataset['Initial'] == dataset.iloc[i]['Initial']) \n                               & (dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) \n                               & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"])].mean()\n    \n    age_pred4 = dataset[\"Age\"][(dataset['Initial'] == dataset.iloc[i]['Initial'])  \n                               & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"])].mean()\n    \n    if not np.isnan(age_pred) :\n        dataset['Age'].iloc[i] = age_pred\n        \n    elif not np.isnan(age_pred2):\n        dataset['Age'].iloc[i] = age_pred2\n        \n    elif not np.isnan(age_pred3):\n        dataset['Age'].iloc[i] = age_pred3\n        \n    else :\n        dataset['Age'].iloc[i] = age_pred4","461f82fe":"dataset['Age'].isnull().sum()","41b500a5":"# Family_Size\ndataset['Family_Size'] = dataset['SibSp'] + dataset['Parch'] + 1","62cbc230":"sns.factorplot(x=\"Family_Size\",y=\"Survived\",data = dataset)\nplt.show()","0b0c3a41":"dataset['Alone'] = dataset['Family_Size'].map(lambda s: 1 if s == 1 else 0)\ndataset['Small_Family'] = dataset['Family_Size'].map(lambda s: 1 if  s == 2  else 0)\ndataset['Med_Family'] = dataset['Family_Size'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ndataset['Large_Family'] = dataset['Family_Size'].map(lambda s: 1 if s >= 5 else 0)","f8201933":"dataset.drop(['Name', 'SibSp', 'Parch', 'Ticket', 'Family_Size'], axis=1, inplace=True)","6f34040a":"dataset = pd.get_dummies(dataset, columns=['Embarked'], prefix='Embark')\ndataset = pd.get_dummies(dataset, columns=['Sex'], prefix='Sex')\ndataset = pd.get_dummies(dataset, columns = ['Initial'], prefix=\"Initial\")\ndataset = pd.get_dummies(dataset, columns = ['Pclass'], prefix=\"Pclass\")\n\ndataset.head()","e3e2fd80":"# Seperate train\/test\ntrain_len = len(train)\ntrain = dataset[:train_len]\ntest = dataset[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","786aa723":"train.head()","0083c70b":"test.head()","fef7da34":"train[\"Survived\"] = train[\"Survived\"].astype(int)\n\nY_train = train[\"Survived\"]\nX_train = train.drop(labels = [\"Survived\"],axis = 1)","e2946169":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve","660aa4d5":"kfold = StratifiedKFold(n_splits=10)\n\nrandom_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train, y = Y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","7c576c99":"GBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1] \n              }\n\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsGBC.fit(X_train,Y_train)\n\nGBC_best = gsGBC.best_estimator_\n\ngsGBC.best_score_","9f7e343c":"DTC = DecisionTreeClassifier()\n\nadaDTC = AdaBoostClassifier(DTC, random_state=7)\n\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n              \"n_estimators\" :[1,2],\n              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n\ngsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsadaDTC.fit(X_train,Y_train)\n\nada_best = gsadaDTC.best_estimator_","72ff405c":"ExtC = ExtraTreesClassifier()\n\n\n## Search grid for optimal parameters\nex_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\n\ngsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsExtC.fit(X_train,Y_train)\n\nExtC_best = gsExtC.best_estimator_\n\n# Best score\ngsExtC.best_score_","91b23268":"RFC = RandomForestClassifier()\n\n\n## Search grid for optimal parameters\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\n\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsRFC.fit(X_train,Y_train)\n\nRFC_best = gsRFC.best_estimator_\n\n# Best score\ngsRFC.best_score_","b3817f18":"### SVC classifier\nSVMC = SVC(probability=True)\nsvc_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [1, 10, 50, 100,200,300, 1000]}\n\ngsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsSVMC.fit(X_train,Y_train)\n\nSVMC_best = gsSVMC.best_estimator_\n\n# Best score\ngsSVMC.best_score_","895dae2d":"votingC = VotingClassifier(estimators=[('rfc', RFC_best), ('extc', ExtC_best),\n('svc', SVMC_best), ('adac',ada_best),('gbc',GBC_best)], voting='soft', n_jobs=4)\n\nvotingC = votingC.fit(X_train, Y_train)","614a60b8":"test_Survived = pd.Series(votingC.predict(test), name=\"Survived\")\n\nId = pd.read_csv('..\/input\/titanic\/test.csv')\nIDtest = Id[\"PassengerId\"]\nresults = pd.concat([IDtest,test_Survived],axis=1)\n\nresults.to_csv(\"I_am_ready_to_go.csv\",index=False)","2c6c850c":"I think that 'High Fare = High Pclass'","2b51a05a":"Box plot and heatmap show what features have a correlation with age. <br>\nWith this information, i will change the NaN values.\n\nHigh Pclass \u2192 High age <br>\nLarge SibSP \u2192 Low age <br>\nLarge Parch \u2192 Low age <br>","8777e238":"And we can find that First and Second class women were nearly 100% Survived. <br>\nBut thrid class women were not.","ac9351a9":"'Age' Feature have 20% null ratio and 'Cabin' Feature have 77% Null ratio. <br>\nWe need to dispose of them.","6b9d551c":"Operate OneHotEncoding","a3e5fe96":"Pclass \u2191 = Age \u2191","5767dd59":"'SibSP' and 'Parch' have similar result (except Parch '3', but that have higest std)","6fc40029":"Family_Size was made by number of 'SibSp' + 'Parch + 1. <br>\nIf Family_size features has only one, they're alone. <br>","78e026b0":"Outlier is \"Silent Killer\". <br>\nI choose the Turkey method, delete them by function. <br>\nThx to Yassine Ghouzam! <br>\nhttps:\/\/www.kaggle.com\/yassineghouzam\/titanic-top-4-with-ensemble-modeling","4a84e08b":"Features [Initial, SibSp, Parch, Pclass] is the hint of age. <br>","5cc23573":"I want find NaN values by same Ticket number or Cabin. but i can't. <br>\nOnly 2 datas isn't important role in the prediction. <br>\nTherefore, change it to the most frequently displayed value.","0b6f843e":"Unlike Korea, initials have information. <br>\nPassengers age, sex... etc","af91d614":"Category : Sex, Cabin, Embarked <br>\nOrdinal : Pclass <br>\nDiscrete : SibSp, Parch <br>\nContinious : Age, Fare","8a71b40e":"Port 'C' is the highest Survival probability. But Why? <br>\nI have a 2 Hypothesis. <br>\n\n1. Port 'C' have high women ratio <br>\n2. Port 'C' have high Pclass ratio ","d857b350":"Obiously, women have a many survival chance.","cf9109fa":"Check the distplot of Fare, but skewness is too high.\nwe need to log function.","0e001008":"Why train data and test data are Concateanted? <br>\nFor classfiys 'Family' Feature <br>\nSome passenger's are same Family, but someone in the train data and someone in the test data. <br>\nSo we need to preprocessing concatenate data.","8d42bde2":"Two graphs seems almost same. <br>\nBut age 0~10 passengers have high survival ratio! <br>\nWomen and Childrens First.","4d57ea90":"Only one class is survivor more than non-survivor. <br>\nFirst class. <br>\nI can think that 'Pclass' will be the Important role in the prediction.","1236a641":"crosstab shows me that Port 'C' proportion of women is irrelevant. <br>\nBut i think that Port 'S' largest number of male passenger effect on survival ratio.","7dca6d68":"Survived == 0 : 61.6% <br>\nSurvived == 1 : 38.4% <br>\nData is balanced.","95eda140":"Port with the largest number of First Class passengers is S, but Third Class passengers are also the largest. <br>\nand Port 'C' have second largest number of First Class passengers.","2b3a55a2":"Large proportion of passenger is Alone that they have low survival ratio. <br>\nSibSp 1 or 2 passengers have high survival ratio. <br>\nover the 2 SibSp passengers lowest survival ratio."}}