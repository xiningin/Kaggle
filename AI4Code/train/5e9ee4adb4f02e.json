{"cell_type":{"56204560":"code","1909fb3a":"code","f85f7627":"code","ed2ccce9":"code","c18ad4a9":"code","92e67d4f":"code","73879afd":"markdown","5f5f1312":"markdown","8ca49aa6":"markdown","79f8865d":"markdown","4c26e71d":"markdown","ef78e420":"markdown","c320b2f5":"markdown","33e34d7d":"markdown"},"source":{"56204560":"import numpy as np\nimport pandas as pd\nimport os \nimport keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D, MaxPooling1D, Dense, Flatten, Dropout, SeparableConv1D\nimport matplotlib.pyplot as plt\nimport librosa","1909fb3a":"addresses=[]\nlabel=[]\nfor i in os.listdir('..\/input\/recordings\/'):\n  addresses.append('..\/input\/recordings\/'+i)\n  label.append(i[0])","f85f7627":"data=[]\nfor i in addresses:\n  sound, sample_rate = librosa.load(i,sr=4800)\n  stft = np.abs(librosa.stft(sound))  \n  mfccs = np.mean(librosa.feature.mfcc(y=sound, sr=sample_rate, n_mfcc=128),axis=1)\n  data.append(mfccs)\n\n# convert list to numpy array\ndata=np.asarray(data)\ndata=data.reshape((2500,128,1))\n\n# make one hot labels\nlabel=keras.utils.to_categorical(label,num_classes=10)\nprint(label.shape,data.shape)","ed2ccce9":"# train test split\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(data, label, test_size=0.2, random_state=42)","c18ad4a9":"#1D CNN model\nmodel = Sequential()\nmodel.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(128, 1)))\n\nmodel.add(Conv1D(128, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling1D(2)) \nmodel.add(Dropout(0.5))\n\nmodel.add(SeparableConv1D(256, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling1D(2)) \nmodel.add(Dropout(0.5))\n\nmodel.add(SeparableConv1D(256, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling1D(2)) \nmodel.add(Dropout(0.5))\n\nmodel.add(SeparableConv1D(512, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling1D(2)) \n\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\n\nmodel.add(Dense(1024, activation='relu'))   \nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss=['categorical_crossentropy'], optimizer='adam', metrics=['acc'])\nhistory = model.fit(x_train, y_train ,validation_data=(x_test,y_test), epochs=100, batch_size=8,verbose=1)\n","92e67d4f":"acc=history.history['acc']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\nval_acc=history.history['val_acc']\n\nplt.figure(figsize=(15,6))\nplt.subplot(1,2,1)\nplt.plot(loss)\nplt.plot(val_loss)\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.subplot(1,2,2)\nplt.plot(acc)\nplt.plot(val_acc)\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","73879afd":"### now we use librosa.feature.mfcc to exteract features from the files","5f5f1312":"### train test split","8ca49aa6":"## Conclusion\nAs you see, I've got 92% accuracy of classification the audio files. Getting higher accuracy leads to overfitting (I mean 99% on the train set and 95% on test). Share with me if you build more accurate model than mine without overfitting.","79f8865d":"## Introduction\nhere we want to build a CNN model and train the data of speech mnist recorded by 5 people and has 2500 audio files. the number of 0 to 9 is recorded on this files. first I used librosa to exteract features from the audio files and then train the cnn 1d model with them.","4c26e71d":"### first the libraries","ef78e420":"### here we put file addresses in a list","c320b2f5":"### now the CNN model","33e34d7d":"### ploting the accuracy and loss using matplotlib.pyplot"}}