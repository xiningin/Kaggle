{"cell_type":{"c003f55a":"code","efc1d315":"code","8af8edd9":"code","a3e16cf0":"code","911a0f59":"code","77757884":"code","e6087a92":"code","2225126b":"code","03d6ccf8":"code","80db8ebb":"markdown","85597927":"markdown","589ddfb1":"markdown","09f0b6d7":"markdown","8a378d47":"markdown","637fd2ea":"markdown"},"source":{"c003f55a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport os\n%matplotlib inline","efc1d315":"import hashlib\nfrom io import BytesIO\nfrom PIL import Image, ImageFont, ImageDraw\nARTAXOR_PATH = '\/kaggle\/input\/arthropod-taxonomy-orders-object-detection-dataset\/'\n\npickles='\/kaggle\/input\/starter-arthropod-taxonomy-orders-data-exploring\/'\nobjectdf=pd.read_pickle(pickles+'ArTaxOr_objects.pkl')\nlabels=pd.read_pickle(pickles+'ArTaxOr_labels.pkl')\nobjectdf.sample(5)","8af8edd9":"# Fetch attribution string from image EXIF data\ndef get_attribution(file):\n    with Image.open(file) as img:\n        exif_data = img._getexif()\n    s='Photo: unknown'\n    if exif_data is not None:\n        if 37510 in exif_data:\n            if len(exif_data[37510]) > 0:\n                s = exif_data[37510][8:].decode('ascii')\n        if 315 in exif_data:\n            if len(exif_data[315]) > 0:\n                s = 'Photo: ' + exif_data[315]\n    return s\n\n# Create example for TensorFlow Object Detection API\ndef create_tf_example(imagedf, longest_edge=1024):  \n    fname = ARTAXOR_PATH+imagedf.file.iloc[0]\n    filename=fname.split('\/')[-1] # exclude path\n    by = get_attribution(fname)\n    img = Image.open(fname, \"r\")\n    # resize image if larger that longest edge while keeping aspect ratio\n    if max(img.size) > longest_edge:\n        img.thumbnail((longest_edge, longest_edge), Image.ANTIALIAS)\n    height = img.size[1] # Image height\n    width = img.size[0] # Image width\n    buf= BytesIO()\n    img.save(buf, format= 'JPEG') # encode to jpeg in memory\n    encoded_image_data= buf.getvalue()\n    image_format = b'jpeg'\n    source_id = filename.split('.')[0]\n    license = 'CC BY-NC-SA 4.0'\n    # A hash of the image is used in some frameworks\n    key = hashlib.sha256(encoded_image_data).hexdigest()   \n    # object bounding boxes \n    xmins = imagedf.left.values # List of normalized left x coordinates in bounding box (1 per box)\n    xmaxs = imagedf.right.values # List of normalized right x coordinates in bounding box\n    ymins = imagedf.top.values # List of normalized top y coordinates in bounding box (1 per box)\n    ymaxs = imagedf.bottom.values # List of normalized bottom y coordinates in bounding box\n    # List of string class name & id of bounding box (1 per box)\n    object_cnt = len(imagedf)\n    classes_text = []\n    classes = []\n    for i in range(object_cnt):\n        classes_text.append(imagedf.label.iloc[i].encode())\n        classes.append(1+imagedf.label_idx.iloc[i])\n    # unused features from Open Image \n    depiction = np.zeros(object_cnt, dtype=int)\n    group_of = np.zeros(object_cnt, dtype=int)\n    occluded = imagedf.occluded.values #also Pascal VOC\n    truncated = imagedf.truncated.values # also Pascal VOC\n    # Pascal VOC\n    view_text = []\n    for i in range(object_cnt):\n        view_text.append('frontal'.encode())\n    difficult = np.zeros(object_cnt, dtype=int)\n\n    tf_record = tf.train.Example(features=tf.train.Features(feature={\n        'image\/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n        'image\/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n        'image\/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode()])),\n        'image\/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[source_id.encode()])),\n        'image\/license': tf.train.Feature(bytes_list=tf.train.BytesList(value=[license.encode()])),\n        'image\/by': tf.train.Feature(bytes_list=tf.train.BytesList(value=[by.encode()])),\n        'image\/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image_data])),\n        'image\/key\/sha256': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode()])),\n        'image\/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_format])),\n        'image\/object\/bbox\/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n        'image\/object\/bbox\/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n        'image\/object\/bbox\/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n        'image\/object\/bbox\/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n        'image\/object\/class\/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n        'image\/object\/class\/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n        'image\/object\/depiction': tf.train.Feature(int64_list=tf.train.Int64List(value=depiction)),\n        'image\/object\/group_of': tf.train.Feature(int64_list=tf.train.Int64List(value=group_of)),\n        'image\/object\/occluded': tf.train.Feature(int64_list=tf.train.Int64List(value=occluded)),\n        'image\/object\/truncated': tf.train.Feature(int64_list=tf.train.Int64List(value=truncated)),\n        'image\/object\/difficult': tf.train.Feature(int64_list=tf.train.Int64List(value=difficult)),\n        'image\/object\/view': tf.train.Feature(bytes_list=tf.train.BytesList(value=view_text))\n    }))\n    return tf_record","a3e16cf0":"# Some helper functions to draw image with object boundary boxes\nfontname = '\/usr\/share\/fonts\/truetype\/dejavu\/DejaVuSans.ttf'\nfont = ImageFont.truetype(fontname, 40) if os.path.isfile(fontname) else ImageFont.load_default()\n\ndef bbox(img, xmin, ymin, xmax, ymax, color, width, label, score):\n    draw = ImageDraw.Draw(img)\n    xres, yres = img.size[0], img.size[1]\n    box = np.multiply([xmin, ymin, xmax, ymax], [xres, yres, xres, yres]).astype(int).tolist()\n    txt = \" {}: {}%\" if score >= 0. else \" {}\"\n    txt = txt.format(label, round(score, 1))\n    ts = draw.textsize(txt, font=font)\n    draw.rectangle(box, outline=color, width=width)\n    if len(label) > 0:\n        if box[1] >= ts[1]+3:\n            xsmin, ysmin = box[0], box[1]-ts[1]-3\n            xsmax, ysmax = box[0]+ts[0]+2, box[1]\n        else:\n            xsmin, ysmin = box[0], box[3]\n            xsmax, ysmax = box[0]+ts[0]+2, box[3]+ts[1]+1\n        draw.rectangle([xsmin, ysmin, xsmax, ysmax], fill=color)\n        draw.text((xsmin, ysmin), txt, font=font, fill='white')\n\ndef plot_img(img, axes, xmin, ymin, xmax, ymax, classes, class_label, by):\n    for i in range(len(xmin)):\n        color=labels.color[class_label[i]-1]\n        bbox(img, xmin[i], ymin[i], xmax[i], ymax[i], color, 5, classes[i].decode(), -1)\n    plt.setp(axes, xticks=[], yticks=[])\n    axes.set_title(by)\n    plt.imshow(img)","911a0f59":"filelist=pd.read_pickle(pickles+'ArTaxOr_filelist.pkl')\nfilelist=filelist.sample(frac=1)\nfilelist.head()","77757884":"%%time\nimport contextlib2\n\ndef open_sharded_tfrecords(exit_stack, base_path, num_shards):\n    tf_record_output_filenames = [\n        '{}-{:03d}-of-{:03d}.tfrecord'.format(base_path, idx, num_shards)\n        for idx in range(num_shards)\n        ]\n    tfrecords = [\n        exit_stack.enter_context(tf.io.TFRecordWriter(file_name))\n        for file_name in tf_record_output_filenames\n    ]\n    return tfrecords\n\nnum_shards=10\noutput_filebase='.\/ArTaxOr'\n\nwith contextlib2.ExitStack() as tf_record_close_stack:\n    output_tfrecords = open_sharded_tfrecords(tf_record_close_stack, output_filebase, num_shards)\n    for i in range(len(filelist)):\n        ldf=objectdf[objectdf.id == filelist.id.iloc[i]].reset_index()\n        tf_record = create_tf_example(ldf, longest_edge=768)\n        output_shard_index = i % num_shards\n        output_tfrecords[output_shard_index].write(tf_record.SerializeToString())","e6087a92":"!ls -lh ArTaxOr*.tfrecord","2225126b":"labels=pd.read_pickle(pickles+'ArTaxOr_labels.pkl')\npbfile=open('.\/ArTaxOr.pbtxt', 'w') \nfor i in range (len(labels)): \n    pbfile.write('item {{\\n id: {}\\n name:\\'{}\\'\\n}}\\n\\n'.format(i+1, labels.name[i])) \npbfile.close()","03d6ccf8":"fname='.\/ArTaxOr-009-of-010.tfrecord' \ndataset3 = tf.data.TFRecordDataset(fname)\nfig = plt.figure(figsize=(16,18))\nidx=1\nfor raw_record in dataset3.take(6):\n    axes = fig.add_subplot(3, 2, idx)\n    example = tf.train.Example()\n    example.ParseFromString(raw_record.numpy())\n    xmin=example.features.feature['image\/object\/bbox\/xmin'].float_list.value[:]\n    xmax=example.features.feature['image\/object\/bbox\/xmax'].float_list.value[:]\n    ymin=example.features.feature['image\/object\/bbox\/ymin'].float_list.value[:]\n    ymax=example.features.feature['image\/object\/bbox\/ymax'].float_list.value[:]\n    by=example.features.feature['image\/by'].bytes_list.value[0].decode()\n    classes=example.features.feature['image\/object\/class\/text'].bytes_list.value[:]\n    class_label=example.features.feature['image\/object\/class\/label'].int64_list.value[:]\n    img_encoded=example.features.feature['image\/encoded'].bytes_list.value[0]\n    img = Image.open(BytesIO(img_encoded))\n    plot_img(img, axes, xmin, ymin, xmax, ymax, classes, class_label, by)\n    idx=idx+1","80db8ebb":"## Sharding large datasets\nSharding is a method of splitting and storing a large dataset into multiple files. The last part of this kernel we will convert the entire ArTaxOr dataset into TFRecords.","85597927":"If we are going to use TF Object Detection API, a label definition file is also needed:","589ddfb1":"The `contextlib2` library is used to automatically close all TFRecords files after writing is finished.","09f0b6d7":"# TensorFlow TFRecords Scaled to 768pix\nThis notebook is a cut-down version of [TensorFlow TFRecords Demystified](https:\/\/www.kaggle.com\/mistag\/tensorflow-tfrecords-demystified). Rather than 1280pix images, this one creates 768pix images specifically for a EfficientDetD2 model.","8a378d47":"Again, read a few records from one of the `.tfrecord` files to check that everything is OK.","637fd2ea":"## References\n*  [Protocol buffers](https:\/\/developers.google.com\/protocol-buffers\/)  \n*  [TensorFlow TFRecord tutorial](https:\/\/www.tensorflow.org\/tutorials\/load_data\/tfrecord)"}}