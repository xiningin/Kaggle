{"cell_type":{"67714665":"code","96cbf279":"code","88919d2f":"code","3adc4202":"code","c3729d90":"code","a37d6cc0":"code","0b04cb93":"code","1545f256":"code","8d91487b":"code","e3ddefd4":"code","0c093261":"code","ddc3eed2":"code","6cefa0b3":"code","7b9b6a97":"code","1685573a":"code","4c49b676":"markdown","9f956fe9":"markdown","186cb3f9":"markdown","49b8445c":"markdown","e810f603":"markdown","f8489d78":"markdown","1fc17c1c":"markdown","eaf8d1d6":"markdown","09bcfe11":"markdown","1c3bffa6":"markdown","2fe603cc":"markdown","eda77f0d":"markdown","43e40792":"markdown","6dc60d7b":"markdown","37237ccd":"markdown","f2e1bb1b":"markdown"},"source":{"67714665":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport random\n\nimport os\nimport datetime\n\n\nprint(\"Version: \", tf.__version__)\nprint(\"Eager mode: \", tf.executing_eagerly())\nprint(\"GPU: \", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")","96cbf279":"img_data = np.load('\/kaggle\/input\/fingerprint-dataset-for-fvc2000-db4-b\/dataset_FVC2000_DB4_B\/dataset\/np_data\/img_train.npy')\nlabel_data = np.load('\/kaggle\/input\/fingerprint-dataset-for-fvc2000-db4-b\/dataset_FVC2000_DB4_B\/dataset\/np_data\/label_train.npy')\nimg_real = np.load('\/kaggle\/input\/fingerprint-dataset-for-fvc2000-db4-b\/dataset_FVC2000_DB4_B\/dataset\/np_data\/img_real.npy')\nlabel_real = np.load('\/kaggle\/input\/fingerprint-dataset-for-fvc2000-db4-b\/dataset_FVC2000_DB4_B\/dataset\/np_data\/label_real.npy')\n\nprint(img_data.shape, label_data.shape)\nprint(img_real.shape, label_real.shape)","88919d2f":"def hist_stretch(img_buf, width, height, shift):\n    tmp1 = 0\n    tmp2 = 0\n    w_pHistBuf = np.zeros(256, dtype=np.uint32)\n    total = 0\n    ret_buf = np.zeros((width, height, 1), dtype=np.uint8)\n\n    # get brightness\n    for i in range(height):\n        for j in range(width):\n            total = total + img_buf[i][j][0]\n            w_pHistBuf[img_buf[i][j][0]] += 1\n    diff = (int)(shift - (total \/ (width * height)))\n    w_pHistBuf = np.zeros(256, dtype=np.uint32)\n\n    # move histogram\n    for i in range(height):\n        for j in range(width):\n            tmp = img_buf[i][j][0] + diff\n            if (tmp > 255):\n                tmp = 255\n            elif (tmp < 0):\n                tmp = 0\n            ret_buf[i][j][0] = tmp\n            w_pHistBuf[tmp] += 1\n\n    # stretch histogram\n    for i in range(256):\n        if (w_pHistBuf[i] != 0):\n            tmp1 = i\n            break\n    for i in range(255, 0, -1):\n        if (w_pHistBuf[i] != 0):\n            tmp2 = i\n            break\n    for i in range(height):\n        for j in range(width):\n            ret_buf[i][j][0] = (int)((255 * (ret_buf[i][j][0] - tmp1) \/ (tmp2 - tmp1)))\n    \n    return ret_buf\n\nfor i in range(img_data.shape[0]):\n    img_tmp = hist_stretch(img_data[i], 160, 160, 128)\n    img_data[i] = img_tmp\n    \nfor i in range(img_real.shape[0]):\n    img_tmp = hist_stretch(img_real[i], 160, 160, 128)\n    img_real[i] = img_tmp","3adc4202":"img_train, img_val, label_train, label_val = train_test_split(img_data, label_data, test_size = 0.1)\nprint(img_data.shape, label_data.shape)\nprint(img_train.shape, label_train.shape)\nprint(img_val.shape, label_val.shape)","c3729d90":"def build_model():\n    x1 = layers.Input(shape = (160, 160, 1))\n    x2 = layers.Input(shape = (160, 160, 1))\n\n    # share weights both inputs\n    inputs = layers.Input(shape = (160, 160, 1))\n    feature = layers.Conv2D(32, kernel_size = 3, activation = 'relu')(inputs)\n    feature = layers.MaxPooling2D(pool_size = 2)(feature)\n    feature = layers.Conv2D(64, kernel_size = 3, activation = 'relu')(feature)\n    feature = layers.MaxPooling2D(pool_size = 2)(feature)\n    feature = layers.Conv2D(128, kernel_size = 3, activation = 'relu')(feature)\n    feature = layers.MaxPooling2D(pool_size = 2)(feature)\n    feature_model = Model(inputs = inputs, outputs = feature)\n\n    # show feature model summary\n    feature_model.summary()\n\n    # two feature models that sharing weights\n    x1_net = feature_model(x1)\n    x2_net = feature_model(x2)\n\n    # subtract features\n    net = layers.Subtract()([x1_net, x2_net])\n    net = layers.Conv2D(128, kernel_size = 3, activation = 'relu')(net)\n    net = layers.MaxPooling2D(pool_size = 2)(net)\n    net = layers.Flatten()(net)\n    net = layers.Dropout(0.3)(net)\n    net = layers.Dense(512, activation = 'relu')(net)\n    net = layers.Dense(1, activation = 'sigmoid')(net)\n    model = Model(inputs = [x1, x2], outputs = net)\n\n    # compile\n    model.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr=1e-4), metrics = ['acc'])\n\n    # show summary\n    model.summary()\n\n    return (model, feature_model)","a37d6cc0":"class DataGenerator(keras.utils.Sequence):\n    def __init__(self, img_data, label_data, img_real, label_real, batch_size = 32, shuffle = True):\n        'Initialization'\n        self.img_data = img_data\n        self.label_data = label_data\n        self.img_real = img_real\n        self.label_real = label_real\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.img_data) \/ self.batch_size) * 2)\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        real_idx = index\n        index = int(np.floor(index \/ 2))\n        img1_batch = self.img_data[index * self.batch_size : (index + 1) * self.batch_size]\n        label1_batch = self.label_data[index * self.batch_size : (index + 1) * self.batch_size]\n        img2_batch = np.empty((self.batch_size, 160, 160, 1), dtype = np.float32)\n        label2_batch = np.zeros((self.batch_size, 1), dtype = np.float32)\n\n        for i, idx in enumerate(label1_batch):\n            if random.random() > 0.5:\n                # put matched image\n                img2_batch[i] = self.img_real[idx]\n                label2_batch[i] = 1.\n            else:\n                # put unmatched image\n                while True:\n                    unmatch_idx = random.choice(list(self.label_real))\n                    if (unmatch_idx != idx):\n                        break\n\n                img2_batch[i] = self.img_real[unmatch_idx]\n                label2_batch[i] = 0.\n                \n        index = real_idx\n        if (index < int(np.floor(len(self.img_data) \/ self.batch_size))):\n            return [img1_batch.astype(np.float32) \/ 255., img2_batch.astype(np.float32) \/ 255.], label2_batch\n        \n        return [img2_batch.astype(np.float32) \/ 255., img1_batch.astype(np.float32) \/ 255.], label2_batch\n\n    def on_epoch_end(self):\n        if self.shuffle == True:\n            self.img_data, self.label_data = shuffle(self.img_data, self.label_data)","0b04cb93":"train_gen = DataGenerator(img_train, label_train, img_real, label_real, shuffle = True)\nval_gen = DataGenerator(img_val, label_val, img_real, label_real, shuffle = True)","1545f256":"checkpoint_path = '\/kaggle\/working\/model\/checkpoint\/cp.ckpt'\ncheckpoint_dir = os.path.dirname(checkpoint_path)\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path, save_weights_only = True, verbose = 1)","8d91487b":"tfb_log_dir = '\/kaggle\/working\/logs\/train\/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = tfb_log_dir, histogram_freq = 1)","e3ddefd4":"(model, feature_model) = build_model()\nif (os.path.exists(checkpoint_path + '.index')):\n    print('continue training')\n    model.load_weights(checkpoint_path)","0c093261":"history = model.fit(train_gen, epochs = 200, validation_data = val_gen, callbacks = [cp_callback, tensorboard_callback])\n#history = model.fit(train_gen, epochs = 200, validation_data = val_gen)","ddc3eed2":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","6cefa0b3":"model_path = '\/kaggle\/working\/model\/fp160.h5'\nmodel_feature_path = '\/kaggle\/working\/model\/fp160_feature.h5'\nmodel.save(model_path)\nfeature_model.save(model_feature_path)","7b9b6a97":"input_idx = 0\ndb_idx = 1\ninput_img = img_real[input_idx].reshape((1, 160, 160, 1)).astype(np.float32) \/ 255.\ndb_img = img_real[db_idx].reshape((1, 160, 160, 1)).astype(np.float32) \/ 255.\npred_right = model.predict([input_img, db_img])\n\n# show result\nplt.figure(figsize=(8, 4))\nplt.subplot(1, 2, 1)\nplt.title('Input: %s' %input_idx)\nplt.imshow(input_img.squeeze(), cmap='gray')\nplt.subplot(1, 2, 2)\nif (pred_right > 0.5):\n    plt.title('O: %.02f, %s' % (pred_right, db_idx))\nelse:\n    plt.title('X: %.02f, %s' % (pred_right, db_idx))\nplt.imshow(db_img.squeeze(), cmap='gray')","1685573a":"total_count = 0\nerror_count = 0\nerror_rage = 0.5\nfor input_idx in range(label_real.shape[0]):\n    print('Processing #', input_idx, '')\n    for db_idx in range(label_real.shape[0]):\n        input_img = img_real[input_idx].reshape((1, 160, 160, 1)).astype(np.float32) \/ 255.\n        db_img = img_real[db_idx].reshape((1, 160, 160, 1)).astype(np.float32) \/ 255.\n        pred_right = model.predict([input_img, db_img])\n        if (input_idx == db_idx):\n            if (pred_right < error_rage):\n                print('False Reject = ', pred_right)\n                error_count += 1\n        if (input_idx != db_idx):\n            if (pred_right > error_rage):\n                print('False Accept = ', pred_right, ', ID = ', db_idx)\n                error_count += 1\n        total_count += 1\n\n# show result\nprint('Evaluation Finished')\nprint('Total Count = ', total_count)\nprint('Error Count = ', error_count)\nprint('Error Rate = ', (error_count \/ total_count) * 100)","4c49b676":"## Load Train Data\n\nLoad train and real data.\nIt opens preprocessed npy files.","9f956fe9":"## Train\n\nTrain model","186cb3f9":"## Make Data Generator\n\nPrepare data generator for training","49b8445c":"### Split Loaded Data\n\nSplit loaded data with 0.1 test size.","e810f603":"# Evaluation\n\n## Match Two Image\n\nMatch sample real two images.","f8489d78":"## Prepare Training\n\nPrepare training","1fc17c1c":"## Prepare Tensorboard\n\nPrepare tensorboard for monitor training","eaf8d1d6":"# Train Model\n\nTrain model.\n\n## Configure Checkpoint\n\nPrepare checkpoint data","09bcfe11":"## Save Model\n\nSave trained model as h5 file","1c3bffa6":"# Introduce\n\nThis notebook is created for training fingerprint recognition model.\n\nThis project is in Github. (https:\/\/github.com\/JinZhuXing\/Fingerprint_TF)","2fe603cc":"# Prepare Network\n\n## Make Model Network\n\nMake function for build model.","eda77f0d":"### Prepare Generator for train and validation\n\nPrepare generator for train and validation","43e40792":"## Evaluate with Real Image\n\nEvaluate with all real images and calculate accuracy.","6dc60d7b":"# Preprocess\n\n## Environment Check\n\nThis notebook uses tensorflow(>= v2.0) for training.\nFirst load python packages and check version.","37237ccd":"## Show Result\n\nDraw trained history graph.","f2e1bb1b":"### Histogram Stretch\n\nHistogram Stretch for all train and real images."}}