{"cell_type":{"f423cbcf":"code","9fed5408":"code","5228f8a9":"code","fb9662b8":"code","c8b36d81":"code","31f51092":"code","0fcffb74":"code","653d61b6":"code","27a8e0d3":"code","df9bbb9a":"code","f792964b":"code","37f2e102":"code","bd3fe681":"code","fe4d068a":"code","23e67b0b":"markdown","60aeb45a":"markdown","89dc365e":"markdown","6a74f2b4":"markdown","97037fd3":"markdown"},"source":{"f423cbcf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport os                                   # Iterate over dataset directories\nimport numpy as np                          # Linear algebra\nimport pandas as pd                         # Data processing (read labels CSV)\nimport cv2 as cv                            # Opencv for image files\nimport pydicom                              # Read dcm files\nfrom sklearn.cluster import MiniBatchKMeans # Create bag of visual words\nfrom sklearn.svm import SVC                 # Classifier\nimport pickle                               # Serialize and save features extracted from dataset images","9fed5408":"# Function to convert dcm pixel array to 8-bit grayscale image\ndef dcmToGray(dcm):\n    image = dcm.pixel_array\n    if np.amax(image) != 0:\n        gray = np.uint8(image\/np.amax(image)*255)\n    else:\n        gray = np.uint8(image)\n    return gray","5228f8a9":"# Paths to training and test data\ntrain_path =  \"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\"\ntest_path  = \"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\"\n\n# Subdirectories inside each directory of dataset\nsubdirs = [\"\/FLAIR\", \"\/T1w\", \"\/T1wCE\", \"\/T2w\"]\n\n# Sizes of training and test set\ntrain_size = len(next(os.walk(train_path))[1])\ntest_size  = len(next(os.walk(test_path))[1])\n\n# Size of an image descriptor (e.g. 128 for SIFT, 32 for ORB)\ndescriptor_size = 32\n\n# Feature detector\ndetector = cv.ORB_create(64)\n\n# Size of visual vocabulary\nvocab_size = 2000","fb9662b8":"# Populating array of visual features with the descriptors computed by the defined detector\n\n# Each element of this list is an array of all the descriptor arrays\n# computed by the detector for every image of each sample.\nfeatures_per_sample = []\n\ni = 0\nwhile(len(features_per_sample) < train_size):\n    # Current directory\n    curr_dir = train_path + '\/{0:05d}'.format(i)\n    \n    i += 1\n    \n    # If the there is no such directory, continue to the next one\n    if not os.path.exists(curr_dir):\n        continue\n        \n    # Array of descriptor array for each image of current sample\n    curr_features = np.array([]).reshape(0,descriptor_size)\n        \n    # Process the images from each subdirectory in the current dir\n    for subdir in subdirs:\n        curr_subdir = curr_dir+subdir\n        for filename in os.listdir(curr_subdir):\n            dcm  = pydicom.dcmread(curr_subdir+'\/'+filename)\n            gray = dcmToGray(dcm)\n            keypoints, descriptors = detector.detectAndCompute(gray,None)\n            if descriptors is not None:\n                curr_features = np.vstack([curr_features, descriptors])\n                \n    features_per_sample.append(curr_features)","c8b36d81":"# Group all features to run clustering in order to get bag of visual words\nall_features = np.array([]).reshape(0,descriptor_size)\nfor sample_features in features_per_sample:\n    all_features = np.vstack([all_features, sample_features])","31f51092":"# Clustering all the features obtained with the detector\n# The centroids will be the visual words of the vocabulary\nkmeans = MiniBatchKMeans(n_clusters = vocab_size,\n                         batch_size = vocab_size\/\/10,\n                         verbose    = False, \n                         init       = 'k-means++',\n                         n_init     = 3,\n                         max_iter   = 1)\n\nvocab = kmeans.fit(all_features)","0fcffb74":"# Training set\nhistograms = []\nfor sample_features in features_per_sample:\n    \n    sample_hist = np.zeros(vocab_size)\n    n_features  = sample_features.shape[0]\n    \n    visual_word_indexes = vocab.predict(sample_features)\n    for index in visual_word_indexes:\n        sample_hist[index] += 1\/n_features\n        \n    histograms.append(sample_hist)\n\nX_train = np.array(histograms)","653d61b6":"# Test set\nhistograms = []\ntest_sample_ids = []\ni = 0\nwhile(len(histograms) < test_size):\n    # Current directory\n    curr_dir = test_path + '\/{0:05d}'.format(i)\n    \n    i += 1\n    \n    # If the there is no such directory, continue to the next one\n    if not os.path.exists(curr_dir):\n        continue\n        \n    test_sample_ids.append('{0:05d}'.format(i-1))\n        \n    # Array of descriptor array for each image of current sample\n    curr_features = np.array([]).reshape(0,descriptor_size)\n        \n    # Process the images from each subdirectory in the current dir\n    for subdir in subdirs:\n        curr_subdir = curr_dir+subdir\n        for filename in os.listdir(curr_subdir):\n            dcm  = pydicom.dcmread(curr_subdir+'\/'+filename)\n            gray = dcmToGray(dcm)\n            keypoints, descriptors = detector.detectAndCompute(gray,None)\n            if descriptors is not None:\n                curr_features = np.vstack([curr_features, descriptors])\n                \n    sample_hist = np.zeros(vocab_size)\n    n_features  = curr_features.shape[0]\n    \n    visual_word_indexes = vocab.predict(curr_features)\n    for index in visual_word_indexes:\n        sample_hist[index] += 1\/n_features\n        \n    histograms.append(sample_hist)\n    \nX_test = np.array(histograms)\ntest_sample_ids = np.array(test_sample_ids)","27a8e0d3":"# Reading labels\nlabels = pd.read_csv(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv\")\nlabels = labels.iloc[:,1].values\n\ntrain_labels = labels[0:int(0.8*train_size)]\nvalid_labels = labels[int(0.8*train_size):train_size]","df9bbb9a":"# Reading training, validation and test data\nX_valid = X_train[int(0.8*train_size):train_size,:]\nX_train = X_train[0:int(0.8*train_size),:]","f792964b":"# Fitting classifier\nsvc = SVC(probability=True)\nsvc.fit(X_train, train_labels)","37f2e102":"# Validating\nscore = svc.score(X_valid, valid_labels)\nprint(score)","bd3fe681":"# Predictions\npred = svc.predict_proba(X_test)\nprint(pred)","fe4d068a":"# Write submission file\nsubmission = pd.DataFrame({\"BraTS21ID\": test_sample_ids, \"MGMT_value\": pred[:,1]})\nsubmission.to_csv(\".\/submission.csv\", index=False)","23e67b0b":"# Classifier","60aeb45a":"# Create the visual words histogram for each sample","89dc365e":"# Helper function","6a74f2b4":"# Important constants","97037fd3":"# Creating vocabulary of visual words"}}