{"cell_type":{"2d92ca4c":"code","e075cf0c":"code","1bb3b0aa":"code","33fd418f":"code","c63721ff":"code","6a6f4d49":"code","834ecb45":"code","e400b9f8":"code","eff0e5fe":"code","2cf634c0":"code","ce92257c":"code","4197c475":"code","32b7af66":"markdown","a7687f53":"markdown","b847534e":"markdown","e6636abd":"markdown","7466a0ba":"markdown","f9a2929c":"markdown","202ccaa4":"markdown"},"source":{"2d92ca4c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# !pip3 install -q tensorflow==2.0.0-beta1\nimport tensorflow as tf\nprint(tf.__version__)\n\nprint(os.listdir(\"..\/input\"))\n\n\n# Any results you write to the current directory are saved as output.","e075cf0c":"dataset_train = pd.read_csv(\"..\/input\/train.csv\")\ndataset_test = pd.read_csv(\"..\/input\/test.csv\")\ndataset_train.head()","1bb3b0aa":"# show distirbution of sale price\nsns.distplot(dataset_train['SalePrice'])","33fd418f":"#find all category features\ncolumns_numberic = dataset_train.dtypes[dataset_train.dtypes != 'object'].index\n# print(columns_numberic)\ncolumns_string = dataset_train.columns.difference(columns_numberic)\ndataset_train[columns_string].head(10)","c63721ff":"#encode category feature \"neighborhood\", 'CentralAir' and show the relative between features\ncolumns_string=['Neighborhood', 'CentralAir']\nfor column in columns_string:\n    label_encoder = preprocessing.LabelEncoder()\n    dataset_train[column] = label_encoder.fit_transform(dataset_train[column])\n    \ncorrmat = dataset_train.corr()\nf, ax = plt.subplots(figsize=(20, 9))\nsns.heatmap(corrmat, vmax=0.8, square=True)","6a6f4d49":"#concat train and test , and remove column 'id' and 'SalePrice'\ndataset_all = pd.concat([dataset_train.iloc[:,1:-1], dataset_test.iloc[:,1:]], axis=0, ignore_index=True)\n\n#normalize numberic features\nfeatures_numberic = dataset_all.dtypes[dataset_all.dtypes != 'object'].index\ndataset_all[features_numberic] = dataset_all[features_numberic].apply(lambda x : ((x - x.mean()) \/ x.std()))\ndataset_all[features_numberic] = dataset_all[features_numberic].fillna(0)\n\n#hot-encode discreted varaibale\ndataset_all = pd.get_dummies(dataset_all, dummy_na=True)\n\n#show samples\ndataset_all.head()","834ecb45":"#split train and label dataset\ntrain_labels_origin = dataset_train['SalePrice']\n\ntrain_labels_mean = train_labels_origin.mean()\ntrain_labels_std = train_labels_origin.std()\n\n#normalize train label\ntrain_labels = (train_labels_origin - train_labels_mean ) \/ train_labels_std\n\nn_train = train_labels.shape[0]\nprint(\"train_labels.shape=\", n_train)\ntrain_X = dataset_all.iloc[0:n_train, :]\nprint(\"train_X.shape=\", train_X.shape)\n\ntest_X = dataset_all.iloc[n_train: , :]\nprint(\"test_X.shape=\", test_X.shape)","e400b9f8":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Dense(64, input_shape=(train_X.shape[1], ), activation=\"relu\"))\nmodel.add(tf.keras.layers.Dropout(0.72))\nmodel.add(tf.keras.layers.Dense(1))\n\noptimizer = tf.keras.optimizers.Adam()\nmodel.compile(optimizer, loss=\"mse\")\n# model.compile(optimizer, loss=tf.keras.losses.MeanSquaredLogarithmicError()) #rmsle\nmodel.summary()","eff0e5fe":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=2)\nhistory = model.fit(train_X, train_labels, batch_size=128, epochs=100, validation_split=0.4, callbacks=[early_stopping])","2cf634c0":"df_his = pd.DataFrame(history.history)\ndf_his.plot()\nplt.show()","ce92257c":"#output normalized value\nresults = model.predict(test_X) \n#restore real value\nresults  = results * train_labels_std + train_labels_mean ","4197c475":"#show predicated values of \"Id, SalePrice\"\nresults = results.reshape(1,-1)[0]\ndataset_test[\"SalePrice\"] = pd.Series(results)\nsubmission = pd.concat([dataset_test['Id'], dataset_test['SalePrice']], axis = 1)\nsubmission.head()","32b7af66":"# define model","a7687f53":"# predict test dataset","b847534e":"# train dataset","e6636abd":"# preprocess dataset","7466a0ba":"# check dataset","f9a2929c":"# load dataset","202ccaa4":"# import modules"}}