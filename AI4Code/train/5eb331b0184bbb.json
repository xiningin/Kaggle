{"cell_type":{"0139c165":"code","6630f2fa":"code","d82c0224":"code","fd22e067":"code","3a9ccd0c":"code","e0c5c603":"code","b0f461aa":"code","dc70bdaf":"code","42353755":"code","d39a6af6":"code","1a530f29":"code","45e2e9ab":"code","c4776ab7":"code","26b9e009":"code","ab8a5600":"code","ffff90be":"code","2508b643":"code","8ffe6c80":"code","ef67531e":"code","87ed97df":"code","303ad9fb":"code","9c5b3e8f":"code","358146d3":"code","7cb2981f":"code","882a9338":"code","dc545956":"code","28cb68d5":"code","0cc52f59":"code","f9a4022e":"code","a9b539ba":"code","f53eb278":"code","34f498a7":"markdown","ab2db941":"markdown","a8f6160c":"markdown","cc3b907d":"markdown","62942b94":"markdown","fde7893e":"markdown","edfbe8e0":"markdown","16e73e81":"markdown"},"source":{"0139c165":"# This is my first notebook on Kaggle, ever, any advice or support would be much appreciated :)\n# I will be trying different ML models such as LogisticRegression, RandomForestClassifier, as well as KNN to figure out which works better\n# Python 3.9.7\n\n# Data science and visualization\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Models\nimport sklearn\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Model evaluations\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\nfrom sklearn.metrics import precision_score, recall_score, f1_score, plot_roc_curve, accuracy_score\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","6630f2fa":"# Importing & Exploring the dataset\ndf = pd.read_csv('\/kaggle\/input\/heart-disease-health-indicators-dataset\/heart_disease_health_indicators_BRFSS2015.csv')\ndf.head()","d82c0224":"len(df)","fd22e067":"# All features are in a numeric format so we don't have to transform any of our data\ndf.dtypes.value_counts()","3a9ccd0c":"# Checking for missing values\ndf.isna().sum().sum()","e0c5c603":"# Checking how imbalance our target column is\ndf.HeartDiseaseorAttack.value_counts()","b0f461aa":"print(f'Percentage of No Heart Disease\/Attack: {round(df[\"HeartDiseaseorAttack\"].value_counts()[0] \/ len(df) * 100, 2)}%')\nprint(f'Percentage of Heart Disease\/Attacks:   {round(df[\"HeartDiseaseorAttack\"].value_counts()[1] \/ len(df) * 100, 2)}%')","dc70bdaf":"# Let's draw some graphs and understand our dataset a little bit\ndf.corr()","42353755":"corr_matrix = df.corr()\nfig, ax = plt.subplots(figsize=(15,10))\nax = sns.heatmap(corr_matrix,\n                 annot=True,\n                 linewidth=0.5,\n                 fmt='.2f',\n                 cmap='PuRd')\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5)","d39a6af6":"# Let's make the models for our data\n# Defining our X and y and splitting them into a training set and a testing set\n\nX = df.drop('HeartDiseaseorAttack', axis=1)\ny = df['HeartDiseaseorAttack']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# The 3 models I've chosen for this dataset\n\nmodels = {'Logistic Regression': LogisticRegression(solver='liblinear'),\n          'KNN': KNeighborsClassifier(),\n          'Random Forest': RandomForestClassifier()}\n\n\ndef fit_and_score_models(models, X_train, X_test, y_train, y_test):\n    \"\"\"\n    A function to fit and evaluate the specified ML models\n    \"\"\"\n    model_scores = {}\n    \n    for name, model in models.items():\n        model.fit(X_train, y_train)\n        model_scores[name] = model.score(X_test, y_test)\n    return model_scores","1a530f29":"model_scores = fit_and_score_models(models, X_train, X_test, y_train, y_test)\nmodel_scores","45e2e9ab":"# Let's visualize the data\naccuray_comparison_graph = pd.DataFrame(model_scores, index=['Accuracy']).T.plot.bar(figsize=(15,10))\nplt.xticks(rotation=0);","c4776ab7":"# I'm not quite satistifed with the scores, let's adjust the hyperparameters to see how the models perform\n# Creating a grid for the LogisticRegression hyperparameters\nlogistic_grid = {'C': np.logspace(-4, 4, 20),\n                 'solver': ['liblinear']}\n\n# Creating a grid for the RandomForestClassifier hyperparameters\nrandom_forest_grid = {'n_estimators': np.arange(10, 250, 50),\n                      'max_depth': [None, 3, 5, 10],\n                      'min_samples_split': np.arange(2, 10, 2),\n                      'min_samples_leaf': np.arange(1, 10, 2)}\n\n# Using RandomSearchCV to search for random hyperparameters in LogisticRegression\nrs_logistic_reg = RandomizedSearchCV(LogisticRegression(),\n                                     param_distributions=logistic_grid,\n                                     cv=5,\n                                     n_iter=20,\n                                     verbose=True)\n\n# Fit the model using the new search hyperparams\nrs_logistic_reg.fit(X_train, y_train)","26b9e009":"# Checking the best parameters for Logistic Regression\nrs_logistic_reg.best_params_","ab8a5600":"# Let's check the (Hopefully improved) performance\nrs_logistic_reg.score(X_test, y_test)","ffff90be":"# Using RandomSearchCV to search for random hyperparameters in RandomForestClassifier\nrs_random_forest = RandomizedSearchCV(RandomForestClassifier(),\n                                      param_distributions=random_forest_grid,\n                                      cv=5,\n                                      n_iter=5,\n                                      verbose=True)\n\n# Fit the model using the new search hyperparams\nrs_random_forest.fit(X_train, y_train)","2508b643":"# Checking the best parameters for RandomForestRegression\nrs_random_forest.best_params_","8ffe6c80":"# Not much improvement for either models\nrs_random_forest.score(X_test, y_test)","ef67531e":"logistic_reg_grid = {'C': np.logspace(-4,4,20),\n                     'solver': ['liblinear']}\n\ngs_logistic_reg = GridSearchCV(LogisticRegression(),\n                               param_grid=logistic_reg_grid,\n                               cv=5,\n                               verbose=True)\n\ngs_logistic_reg.fit(X_train, y_train)","87ed97df":"gs_logistic_reg.best_params_","303ad9fb":"# We got the same results...\ngs_logistic_reg.score(X_test, y_test)","9c5b3e8f":"# Let's plot a ROC curve which is the comparison of TPR (True Positive Rate) VS FPR (False Positive Rate)\n\nplot_roc_curve(gs_logistic_reg, X_test, y_test);","358146d3":"# Let's experiment with the confusion matrix\ny_preds = gs_logistic_reg.predict(X_test)\ncm = confusion_matrix(y_test, y_preds, labels=gs_logistic_reg.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap='viridis');\n","7cb2981f":"# Let's make a Classification report which gives us a combination of evaluation metrics such as (Precision, Recall, F1-score, Support)\n\nprint(classification_report(y_test, y_preds))","882a9338":"gs_logistic_reg.best_params_","dc545956":"# Creating a new model based on the best params\nclf = LogisticRegression(C=0.23357214690901212,\n                         solver='liblinear')","28cb68d5":"# To see a list of scoring parameters, you could do 'sklearn.metrics.SCORERS.keys()'\nparams = ['accuracy', 'precision', 'recall', 'f1']\ndef scoring_params(params):\n    for metric in params:\n        cv_accuracy = np.mean(cross_val_score(clf, X, y, cv=5, scoring=f'{metric}'))\n        print(f'{metric}: {cv_accuracy:.3f}')\n    \nscoring_params(params)","0cc52f59":"# Let's see which features are the most important for our model\nclf = LogisticRegression(C=0.23357214690901212,\n                         solver='liblinear')\n\nclf.fit(X_train, y_train);","f9a4022e":"# How much each feature contributes to predicting our 'target' column which in this case is 'HeartDiseaseorAttack'\nclf.coef_","a9b539ba":"features = dict(zip(df.columns, list(clf.coef_[0])))\nfeatures","f53eb278":"# Let's visualize the data\nfeatures_df = pd.DataFrame(features, index=[0]).T.plot.bar(figsize=(20,10), title='Feature Importance')\n","34f498a7":"## Conclusion:\n\n* As we can see that certain features aren't contributing to our 'target' column so to save time in the future while collecting data for a similar purpose, we could elimintate said features that are not contributing as much or at all\n\n* The dataset was very imbalanced and we tried using different classification models but ultimately realized that **LogisticRegresson** gave us the best results\n\n* We also tried adjusting the hyperparameters in order to improve our model which didn't turn out as well as we had hoped","ab2db941":"### The evaluation metrics for those who don't have a heart disease seems solid but if you divert your attention to the patients who do have a heart disease, you can see that we have a recall score of 0.13 which is super low. **Recall** Indicates the proportion of actual positives which were correctly classified. \n\n* So a model which produces **no false negatives has a recall of 1.0** but as we saw previously, our model has 4083 false negative predictions\n* We can pay attention to the **macro average** which is the average precision, recall, and f1-score. If you have class imbalances, which we do in this case, this is the number you want to pay attention to because macro average doesn't take class inbalance into account\n\n## BUT\n\n* The numbers in the **classification report** are calculated on 1 single test split. We will now be performing a cross-validation which means training the model on 5 different versions of training data and also evaluating it on those 5 different versions.","a8f6160c":"# *** Logistic Regression seems to have scored the highest accuracy**","cc3b907d":"# I will take the best performing model which is the Logistic Regression model and do a GridSearchCV on the hyperparameters to try and improve our model","62942b94":"## So according to our confusion matrix we have *497* false positives and *4082* false negatives which is something we don't want while classifing whether someone has a heart disease or not","fde7893e":"* We can see that certain columns such as **Income** & **Education** have a *strong negative correlation* with our target (HeartDiseaseorAttack) column","edfbe8e0":"# Now that we've tried to better the model's accuracy score, let's experiment with different evaluation metrics such as:\n**1. Confusion_matrix**\n\n**2. Precision**\n\n**3. Recall**\n\n**4. ROC and AUC**\n\n**5. F1**\n\n**6. Classification_report**","16e73e81":"### A quick note: [Parallel(n_jobs=1)] as you see above is how many processors the model will use to get trained. The default value is n_jobs=1. If you want it to use ALL processors, set n_jobs=-1 and if you want it to use all but ONE then use n_jobs=-2\n\nFor more info refer to the scikit-learn documentation"}}