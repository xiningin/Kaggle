{"cell_type":{"268c9703":"code","84f88dd1":"code","8b3a9b8a":"code","86f8f354":"code","ab37d4da":"code","2272d303":"code","f33fe999":"code","5e2c71fb":"code","fe7de735":"code","594ab4f5":"code","2fe88c84":"code","296c9614":"code","9c841b86":"code","f279fe0b":"code","7d7d9eb0":"code","0ae94846":"code","676295b9":"code","8714e6fc":"code","65cbbd91":"code","c9caaa9e":"code","db5e6bea":"code","28e5c9ad":"code","0a099af3":"code","26d337cc":"code","2d8a34ae":"code","ce35d6bf":"code","76445485":"code","46eaa086":"code","1841f124":"code","63b03a92":"code","58227cfa":"code","1e0deb3d":"code","2309e649":"code","008cf41d":"code","2f5066dc":"code","6868ea80":"code","842d216f":"code","7833de3f":"code","3cc044f4":"code","8d78a09a":"code","0bc3d941":"code","6cc9aac4":"code","e02758b5":"code","f827e2c1":"code","bc41a02e":"code","f885b288":"code","664c222e":"code","33d0abc1":"code","42c26c58":"code","4fc8c3e4":"code","8761cd3f":"code","22ee207e":"code","df9668f3":"code","ee16d95d":"code","be12a912":"code","02c453f7":"code","9aeb081e":"code","bb7be76a":"code","5e1bd393":"code","1535e76a":"code","0b739b1f":"code","bc2b873f":"code","14533040":"code","945cf678":"code","2e9ebd09":"code","a1a1ec99":"code","bcc604f4":"code","4ac5d55b":"code","21d323fe":"code","4c288818":"code","16e4efc1":"code","30c304b4":"code","083218b9":"code","02ea13d5":"code","f53dfc01":"code","b0e3c2cb":"code","443718d7":"code","3e42dc8f":"code","ee4ab4a0":"code","4e8768df":"code","3ca19bad":"code","7d506887":"code","aa1ebaff":"code","671e6f8a":"code","be0ff43e":"code","fb62c099":"code","221bb244":"code","f8cad5b9":"code","c6cc4211":"code","11297c4d":"code","7e32fc62":"code","40cd70a0":"code","fe0617bc":"code","0d018444":"code","49716980":"code","4715f257":"code","58c2e811":"code","dd75349c":"code","b6dc6f1d":"code","64a6e1c6":"code","ba13be1e":"code","2c95e178":"code","e11546b6":"code","54346078":"code","f16c3a5c":"code","3b9fdfff":"code","ef290b19":"code","afc0e3f7":"code","c5126781":"markdown","0a77b636":"markdown","c4c9e108":"markdown"},"source":{"268c9703":"# Import Dependencies\n%matplotlib inline\n\n# Start Python Imports\nimport math, time, random, datetime\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n# Visualization \nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n# Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n\n# Machine learning\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier, Pool, cv\n\n# Let's be rebels and ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')","84f88dd1":"# Import train & test data \ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ngender_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv') # example of what a submission should look like","8b3a9b8a":"train.head()","86f8f354":"train.Age.plot.hist()","ab37d4da":"test.head() ","2272d303":"gender_submission.head()","f33fe999":"train.describe()","5e2c71fb":"missingno.matrix(train, figsize = (30,10))","fe7de735":"train.isnull().sum()","594ab4f5":"df_bin = pd.DataFrame() \ndf_con = pd.DataFrame() ","2fe88c84":"train.dtypes","296c9614":"train.head()","9c841b86":"fig = plt.figure(figsize=(20,1))\nsns.countplot(y='Survived', data=train);\nprint(train.Survived.value_counts())","f279fe0b":"df_bin['Survived'] = train['Survived']\ndf_con['Survived'] = train['Survived']","7d7d9eb0":"df_bin.head()","0ae94846":"df_con.head()","676295b9":"sns.distplot(train.Pclass)","8714e6fc":"train.Pclass.isnull().sum()","65cbbd91":"df_bin['Pclass'] = train['Pclass']\ndf_con['Pclass'] = train['Pclass']","c9caaa9e":"train.Name.value_counts()","db5e6bea":"plt.figure(figsize=(20, 5))\nsns.countplot(y=\"Sex\", data=train);","28e5c9ad":"train.Sex.isnull().sum()","0a099af3":"train.Sex.head()","26d337cc":"df_bin['Sex'] = train['Sex']\ndf_bin['Sex'] = np.where(df_bin['Sex'] == 'female', 1, 0) \n\ndf_con['Sex'] = train['Sex']","2d8a34ae":"df_bin.head()","ce35d6bf":"df_con.head()","76445485":"# How does the Sex variable look compared to Survival?\n# We can see this because they're both binarys.\nfig = plt.figure(figsize=(10, 10))\ntry:\n    sns.distplot(df_bin.loc[df_bin['Survived'] == 1]['Sex'])\nexcept RuntimeError as re:\n    if str(re).startswith(\"Selected KDE bandwidth is 0. Cannot estimate density.\"):\n        sns.distplot(df_bin.loc[df_bin['Survived'] == 1]['Sex'], kde_kws={'bw': 0.1, 'label': 'survived'})\n    else:\n        raise re\n# sns.distplot(df_bin.loc[df_bin['Survived'] == 1]['Sex'], kde_kws={'label': 'Survived'});\n\ntry:\n    sns.distplot(df_bin.loc[df_bin['Survived'] == 0]['Sex'])\nexcept RuntimeError as re:\n    if str(re).startswith(\"Selected KDE bandwidth is 0. Cannot estimate density.\"):\n        sns.distplot(df_bin.loc[df_bin['Survived'] == 0]['Sex'], kde_kws={'bw': 0.1, 'label': 'Did not survive'})\n    else:\n        raise re\n# sns.distplot(df_bin.loc[df_bin['Survived'] == 0]['Sex'], kde_kws={'label': 'Did not survive'});","46eaa086":"sns.distplot(df_bin.loc[df_bin['Survived'] == 1]['Sex'], kde_kws={'bw': 0.1, 'label': 'survived'})\nsns.distplot(df_bin.loc[df_bin['Survived'] == 0]['Sex'], kde_kws={'bw': 0.1, 'label': 'Did not survive'});","1841f124":"# How many missing values does age have?\ntrain.Age.isnull().sum()","63b03a92":"def plot_count_dist(data, bin_df, label_column, target_column, figsize=(20, 5), use_bin_df=False):\n    \n    if use_bin_df: \n        fig = plt.figure(figsize=figsize)\n        plt.subplot(1, 2, 1)\n        sns.countplot(y=target_column, data=bin_df);\n        plt.subplot(1, 2, 2)\n        sns.distplot(data.loc[data[label_column] == 1][target_column], \n                     kde_kws={'bw' : 0.1, \"label\": \"Survived\"});\n        sns.distplot(data.loc[data[label_column] == 0][target_column], \n                     kde_kws={'bw' : 0.1,\"label\": \"Did not survive\"});\n    else:\n        fig = plt.figure(figsize=figsize)\n        plt.subplot(1, 2, 1)\n        sns.countplot(y=target_column, data=data);\n        plt.subplot(1, 2, 2)\n        sns.distplot(data.loc[data[label_column] == 1][target_column], \n                     kde_kws={'bw' : 0.1,\"label\": \"Survived\"});\n        sns.distplot(data.loc[data[label_column] == 0][target_column], \n                     kde_kws={'bw' : 0.1,\"label\": \"Did not survive\"});","58227cfa":"# How many missing values does SibSp have?\ntrain.SibSp.isnull().sum()","1e0deb3d":"# What values are there?\ntrain.SibSp.value_counts()","2309e649":"df_bin['SibSp'] = train['SibSp']\ndf_con['SibSp'] = train['SibSp']","008cf41d":"plot_count_dist(train, \n                bin_df=df_bin, \n                label_column='Survived', \n                target_column='SibSp', \n                figsize=(20, 10))","2f5066dc":"# How many missing values does Parch have?\ntrain.Parch.isnull().sum()","6868ea80":"train.Parch.value_counts()","842d216f":"df_bin['Parch'] = train['Parch']\ndf_con['Parch'] = train['Parch']","7833de3f":"plot_count_dist(train, \n                bin_df=df_bin,\n                label_column='Survived', \n                target_column='Parch', \n                figsize=(20, 10))","3cc044f4":"train.head()","8d78a09a":"df_con.head()","0bc3d941":"train.Ticket.isnull().sum()","6cc9aac4":"\nsns.countplot(y=\"Ticket\", data=train);","e02758b5":"train.Ticket.value_counts()","f827e2c1":"print(\"There are {} unique Ticket values.\".format(len(train.Ticket.unique())))","bc41a02e":"df_bin.head()","f885b288":"df_con.head()","664c222e":"train.Fare.isnull().sum()","33d0abc1":"sns.countplot(y=\"Fare\", data=train);","42c26c58":"train.Fare.dtype","4fc8c3e4":"print(\"There are {} unique Fare values.\".format(len(train.Fare.unique())))","8761cd3f":"# Add Fare to sub dataframes\ndf_con['Fare'] = train['Fare'] \ndf_bin['Fare'] = pd.cut(train['Fare'], bins=5) # discretised ","22ee207e":"df_bin.Fare.value_counts()","df9668f3":"plot_count_dist(data=train,\n                bin_df=df_bin,\n                label_column='Survived', \n                target_column='Fare', \n                figsize=(20,10), \n                use_bin_df=True)","ee16d95d":"# How many missing values does Cabin have?\ntrain.Cabin.isnull().sum()","be12a912":"train.head()","02c453f7":"train.Cabin.value_counts()","9aeb081e":"train.Embarked.isnull().sum()","bb7be76a":"train.Embarked.value_counts()","5e1bd393":"sns.countplot(y='Embarked', data=train);","1535e76a":"df_bin['Embarked'] = train['Embarked']\ndf_con['Embarked'] = train['Embarked']","0b739b1f":"print(len(df_con))\ndf_con = df_con.dropna(subset=['Embarked'])\ndf_bin = df_bin.dropna(subset=['Embarked'])\nprint(len(df_con))","bc2b873f":"df_bin.head()","14533040":"# One-hot encode binned variables\none_hot_cols = df_bin.columns.tolist()\none_hot_cols.remove('Survived')\ndf_bin_enc = pd.get_dummies(df_bin, columns=one_hot_cols)\n\ndf_bin_enc.head()","945cf678":"df_con.head(10)","2e9ebd09":"\ndf_embarked_one_hot = pd.get_dummies(df_con['Embarked'], \n                                     prefix='embarked')\n\ndf_sex_one_hot = pd.get_dummies(df_con['Sex'], \n                                prefix='sex')\n\ndf_plcass_one_hot = pd.get_dummies(df_con['Pclass'], \n                                   prefix='pclass')","a1a1ec99":"df_con_enc = pd.concat([df_con, \n                        df_embarked_one_hot, \n                        df_sex_one_hot, \n                        df_plcass_one_hot], axis=1)\n\n\ndf_con_enc = df_con_enc.drop(['Pclass', 'Sex', 'Embarked'], axis=1)","bcc604f4":"df_con_enc.head(20)","4ac5d55b":"\nselected_df = df_con_enc","21d323fe":"selected_df.head()","4c288818":"# Split the dataframe into data and labels\nX_train = selected_df.drop('Survived', axis=1) # data\ny_train = selected_df.Survived # labels","16e4efc1":"# Shape of the data (without labels)\nX_train.shape","30c304b4":"X_train.head()","083218b9":"# Shape of the labels\ny_train.shape","02ea13d5":"def fit_ml_algo(algo, X_train, y_train, cv):\n    \n    # One Pass\n    model = algo.fit(X_train, y_train)\n    acc = round(model.score(X_train, y_train) * 100, 2)\n    \n    # Cross Validation \n    train_pred = model_selection.cross_val_predict(algo, \n                                                  X_train, \n                                                  y_train, \n                                                  cv=cv, \n                                                  n_jobs = -1)\n    # Cross-validation accuracy metric\n    acc_cv = round(metrics.accuracy_score(y_train, train_pred) * 100, 2)\n    \n    return train_pred, acc, acc_cv","f53dfc01":"# Logistic Regression\nstart_time = time.time()\ntrain_pred_log, acc_log, acc_cv_log = fit_ml_algo(LogisticRegression(), \n                                                               X_train, \n                                                               y_train, \n                                                                    10)\nlog_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_log)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_log)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=log_time))","b0e3c2cb":"# k-Nearest Neighbours\nstart_time = time.time()\ntrain_pred_knn, acc_knn, acc_cv_knn = fit_ml_algo(KNeighborsClassifier(), \n                                                  X_train, \n                                                  y_train, \n                                                  10)\nknn_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_knn)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_knn)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=knn_time))","443718d7":"# Gaussian Naive Bayes\nstart_time = time.time()\ntrain_pred_gaussian, acc_gaussian, acc_cv_gaussian = fit_ml_algo(GaussianNB(), \n                                                                      X_train, \n                                                                      y_train, \n                                                                           10)\ngaussian_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_gaussian)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_gaussian)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=gaussian_time))","3e42dc8f":"# Linear SVC\nstart_time = time.time()\ntrain_pred_svc, acc_linear_svc, acc_cv_linear_svc = fit_ml_algo(LinearSVC(),\n                                                                X_train, \n                                                                y_train, \n                                                                10)\nlinear_svc_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_linear_svc)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_linear_svc)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=linear_svc_time))","ee4ab4a0":"# Stochastic Gradient Descent\nstart_time = time.time()\ntrain_pred_sgd, acc_sgd, acc_cv_sgd = fit_ml_algo(SGDClassifier(), \n                                                  X_train, \n                                                  y_train,\n                                                  10)\nsgd_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_sgd)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_sgd)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=sgd_time))","4e8768df":"# Decision Tree Classifier\nstart_time = time.time()\ntrain_pred_dt, acc_dt, acc_cv_dt = fit_ml_algo(DecisionTreeClassifier(), \n                                                                X_train, \n                                                                y_train,\n                                                                10)\ndt_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_dt)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_dt)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=dt_time))","3ca19bad":"# Gradient Boosting Trees\nstart_time = time.time()\ntrain_pred_gbt, acc_gbt, acc_cv_gbt = fit_ml_algo(GradientBoostingClassifier(), \n                                                                       X_train, \n                                                                       y_train,\n                                                                       10)\ngbt_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_gbt)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_gbt)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=gbt_time))","7d506887":"X_train.head()","aa1ebaff":"y_train.head()","671e6f8a":"# Define the categorical features for the CatBoost model\ncat_features = np.where(X_train.dtypes != np.float)[0]\ncat_features","be0ff43e":"train_pool = Pool(X_train, \n                  y_train,\n                  cat_features)","fb62c099":"y_train.head()","221bb244":"# CatBoost model definition\ncatboost_model = CatBoostClassifier(iterations=1000,\n                                    custom_loss=['Accuracy'],\n                                    loss_function='Logloss')\n\n# Fit CatBoost model\ncatboost_model.fit(train_pool,\n                   plot=True)\n\n# CatBoost accuracy\nacc_catboost = round(catboost_model.score(X_train, y_train) * 100, 2)","f8cad5b9":"start_time = time.time()\n\ncv_params = catboost_model.get_params()\n\ncv_data = cv(train_pool,\n             cv_params,\n             fold_count=10,\n             plot=True)\n\ncatboost_time = (time.time() - start_time)\n\n\nacc_cv_catboost = round(np.max(cv_data['test-Accuracy-mean']) * 100, 2)","c6cc4211":"# Print out the CatBoost model metrics\nprint(\"---CatBoost Metrics---\")\nprint(\"Accuracy: {}\".format(acc_catboost))\nprint(\"Accuracy cross-validation 10-Fold: {}\".format(acc_cv_catboost))\nprint(\"Running Time: {}\".format(datetime.timedelta(seconds=catboost_time)))","11297c4d":"models = pd.DataFrame({\n    'Model': ['KNN', 'Logistic Regression', 'Naive Bayes', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree', 'Gradient Boosting Trees',\n              'CatBoost'],\n    'Score': [\n        acc_knn, \n        acc_log,  \n        acc_gaussian, \n        acc_sgd, \n        acc_linear_svc, \n        acc_dt,\n        acc_gbt,\n        acc_catboost\n    ]})\nprint(\"---Reuglar Accuracy Scores---\")\nmodels.sort_values(by='Score', ascending=False)","7e32fc62":"cv_models = pd.DataFrame({\n    'Model': ['KNN', 'Logistic Regression', 'Naive Bayes', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree', 'Gradient Boosting Trees',\n              'CatBoost'],\n    'Score': [\n        acc_cv_knn, \n        acc_cv_log,      \n        acc_cv_gaussian, \n        acc_cv_sgd, \n        acc_cv_linear_svc, \n        acc_cv_dt,\n        acc_cv_gbt,\n        acc_cv_catboost\n    ]})\nprint('---Cross-validation Accuracy Scores---')\ncv_models.sort_values(by='Score', ascending=False)","40cd70a0":"# Feature Importance\ndef feature_importance(model, data):\n    \"\"\"\n    Function to show which features are most important in the model.\n    ::param_model:: Which model to use?\n    ::param_data:: What data to use?\n    \"\"\"\n    fea_imp = pd.DataFrame({'imp': model.feature_importances_, 'col': data.columns})\n    fea_imp = fea_imp.sort_values(['imp', 'col'], ascending=[True, False]).iloc[-30:]\n    _ = fea_imp.plot(kind='barh', x='col', y='imp', figsize=(20, 10))\n    return fea_imp\n    #plt.savefig('catboost_feature_importance.png') ","fe0617bc":"feature_importance(catboost_model, X_train)","0d018444":"metrics = ['Precision', 'Recall', 'F1', 'AUC']\n\neval_metrics = catboost_model.eval_metrics(train_pool,\n                                           metrics=metrics,\n                                           plot=True)\n\nfor metric in metrics:\n    print(str(metric)+\": {}\".format(np.mean(eval_metrics[metric])))","49716980":"X_train.head()","4715f257":"test.head()","58c2e811":"test_embarked_one_hot = pd.get_dummies(test['Embarked'], \n                                       prefix='embarked')\n\ntest_sex_one_hot = pd.get_dummies(test['Sex'], \n                                prefix='sex')\n\ntest_plcass_one_hot = pd.get_dummies(test['Pclass'], \n                                   prefix='pclass')","dd75349c":"test = pd.concat([test, \n                  test_embarked_one_hot, \n                  test_sex_one_hot, \n                  test_plcass_one_hot], axis=1)","b6dc6f1d":"test.head()","64a6e1c6":"wanted_test_columns = X_train.columns\nwanted_test_columns","ba13be1e":"predictions = catboost_model.predict(test[wanted_test_columns])","2c95e178":"predictions[:20]","e11546b6":"submission = pd.DataFrame()\nsubmission['PassengerId'] = test['PassengerId']\nsubmission['Survived'] = predictions \nsubmission.head()","54346078":"gender_submission.head()","f16c3a5c":"submission['Survived'] = submission['Survived'].astype(int)\nprint('Converted Survived column to integers.')","3b9fdfff":"submission.head()","ef290b19":"submission.to_csv('..\/catboost_submission.csv', index=False)\nprint('Submission CSV is ready!')","afc0e3f7":"submissions_check = pd.read_csv(\"..\/catboost_submission.csv\")\nsubmissions_check.head()","c5126781":"### Regular accuracy scores","0a77b636":"# <font color='blue'> Solution-2...<font>","c4c9e108":"# <font color='green'> Solution-1... <font>"}}