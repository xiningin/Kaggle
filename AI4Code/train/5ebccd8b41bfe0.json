{"cell_type":{"b912b1fb":"code","69023728":"code","a758e5b6":"code","8d602dde":"code","93ed9557":"code","8faa31b5":"code","ddd8635d":"code","7e35ed53":"code","7d58851f":"code","27925c06":"code","09b6e46c":"code","b5b54353":"code","30d1d49b":"code","0d37adbb":"code","2e20748e":"code","61231890":"code","4d298873":"markdown"},"source":{"b912b1fb":"!pip install pytorch-tabnet","69023728":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import KFold\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nfrom pytorch_tabnet.metrics import Metric\nfrom sklearn.metrics import mean_squared_error\nimport torch\nimport os\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import train_test_split\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns","a758e5b6":"class Config:\n    use_tabnet = True\n    use_xgb = True\n    use_lgb = False\n    training = True\n    max_epochs=20","8d602dde":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/sample_submission.csv')","93ed9557":"train.head()","8faa31b5":"feats_cols = ['cont'+str(i) for i in range(1,train.shape[1]-1)]","ddd8635d":"# fig, axs = plt.subplots(14,1, figsize=)\nfor col in feats_cols:\n    plt.figure(figsize=(10,8))\n    sns.distplot(train[col])\n    plt.title(f'distribution plot for {col}')\n    plt.show()","7e35ed53":"plt.figure(figsize=(10,8))\nsns.heatmap(train.iloc[:,1:].corr())\nplt.title(f'correlation plot')\nplt.show()","7d58851f":"target_col = 'target'","27925c06":"to_drop = ['comp_id', target_col]\nX = train.drop(['id',target_col], axis=1)\nY = train[target_col]\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, )\nprint(f\"train size: {X_train.shape[0]} \")\nprint(f'test size: {X_test.shape[0]}')","09b6e46c":"clf = TabNetRegressor()                     ","b5b54353":"%%time\n# increase Config.max_epochs as per your need\n\nif Config.use_tabnet & Config.training:\n    \n    clf.fit(\n\n        X_train=X_train.values, y_train=Y_train.values.reshape(-1,1),\n        eval_set=[(X_train.values, Y_train.values.reshape(-1,1)), (X_test.values,Y_test.values.reshape(-1,1))],\n        eval_name=['train', 'valid'],\n        eval_metric=[ 'rmse'],\n        max_epochs=Config.max_epochs,\n        patience=50,\n        batch_size=1024, virtual_batch_size=128,\n        num_workers=0,\n\n    )","30d1d49b":"## source : https:\/\/www.kaggle.com\/jyotmakadiya\/ensemble-using-xgboost-and-lgbm-with-eda\n\nBest_trial = {'lambda': 0.0030282073258141168, 'alpha': 0.01563845128469084, 'colsample_bytree': 0.5,\n             'subsample': 0.7,'n_estimators': 4000, 'learning_rate': 0.01,'max_depth': 15,\n             'random_state': 2020, 'min_child_weight': 257,'tree_method':'gpu_hist'\n             ,'predictor': 'gpu_predictor'}\n\npreds = np.zeros(test.shape[0])\n#creating 7 folds\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\nrmse=[]\nn=0\nfeatures = [f'cont{x}'for x in range(1,15)]\ntrain,target = X, Y\nfor trn_idx, test_idx in kf.split(train[features],target):\n    #separating training and validation data from training columns\n    X_tr,X_val=train[features].iloc[trn_idx],train[features].iloc[test_idx]\n    #separating training and validation data from target values\n    y_tr,y_val=target.iloc[trn_idx],target.iloc[test_idx]\n    \n    #xgboost regressor with optimized parameters \n    model = XGBRegressor(**Best_trial)\n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n    \n    #predicting on test data provided in separate file(actual test data not validation)\n    preds+=model.predict(test[features])\/kf.n_splits\n    rmse.append(mean_squared_error(y_val, model.predict(X_val), squared=False))\n    print(n+1,rmse[n])\n    n+=1\nprint(f\"mean RMSE for all the folds is {np.mean(rmse)}\")","0d37adbb":"submission = pd.DataFrame()\nsubmission['id'] = test.id","2e20748e":"# preds1 = np.zeros(test.shape[0])\n# if Config.use_tabnet:\n#     preds1 = clf.predict(test.drop(['id'], axis=1).values)\n#     submission['target'] = preds1\n#     submission.head()\n# elif Config.use_xgb:\n#     preds1 = xgb.predict(test.drop(['id'], axis=1).values)\n#     submission['target'] = preds1\n#     submission.head()","61231890":"results = clf.predict(test.drop(['id'], axis=1).values)\nfinal_results = [x*0.30 + y*0.70 for x, y in zip(results, preds)]\nsubmission['target']=np.array(final_results)\nfilename = f'submission_tabnet_xgb_{time.time()}.csv' \nsubmission.to_csv(filename, index=False)\nprint(f'submission file: {filename}')\nsubmission.head()","4d298873":"# Submission"}}