{"cell_type":{"f18c7ccf":"code","fa7c44c8":"code","d11c29a5":"code","de81c1da":"code","3f4d39a1":"code","4e95d94e":"code","aab4dcf1":"code","7421409c":"code","51042239":"code","e96f8b75":"code","4d03f4d5":"code","42e5369b":"code","71b6c803":"code","8599cd45":"code","185baadf":"code","76c55657":"code","7c1b6494":"code","dd963eb9":"code","3552d796":"code","16b06020":"code","a0ef175d":"code","b821a6ed":"code","f145553e":"code","3c40045f":"code","6900f8d7":"code","561a5118":"code","42df7c70":"code","7e482991":"code","b1c9337f":"code","72ebd24a":"code","a137d188":"code","f1b74c9c":"code","9df655fb":"code","2603175f":"code","d33f8d35":"code","46a8f63b":"code","0e51743a":"code","9ad271ef":"code","dd21741c":"code","1ae5b587":"code","bdfa86b6":"code","7317865d":"code","93c8fe00":"code","bb0e0d31":"code","c445e305":"code","0c389eeb":"code","7cd2aa08":"code","8719604e":"code","d1143007":"code","244e2d5d":"code","11af1f7e":"code","e57c7f2e":"code","14c873e2":"code","2369c5a3":"code","995ec764":"code","7bbe1d69":"code","37fb1172":"code","5fcd03ac":"code","8479a748":"code","83d66ff7":"code","be434a72":"code","e136bf1a":"code","4614b4c9":"code","4c72035d":"code","a21baa6e":"code","42686ba2":"code","4c0226d1":"code","1a2ef2d7":"code","8c7c1c1d":"code","d84be6fd":"code","6ef7967c":"code","5ee433eb":"code","fe0c77a6":"code","a021d8a2":"code","a432b3b0":"code","ea9a57b5":"code","8cbd85d9":"code","3f80bbcd":"code","52697049":"code","65b2eb44":"code","c3709e04":"code","ece83ae8":"code","827e6df6":"markdown"},"source":{"f18c7ccf":"import numpy as np\nimport cv2\nimport pandas as pd\nimport keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import *\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport itertools \nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox\nimport glob\nimport os\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import svm\nfrom sklearn.cluster import KMeans\nimport itertools \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nimport seaborn as sns\n","fa7c44c8":"simpson_images = []\nlabels = [] \nfor simpson_dir_path in glob.glob(\"\/Users\/hshen\/Dropbox\/data2\/train\/*\"):\n    simpson_label = simpson_dir_path.split(\"\/\")[-1]\n    for image_path in glob.glob(os.path.join(simpson_dir_path, \"*.jpg\")):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        \n        image = cv2.resize(image, (45, 45))\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n        \n        simpson_images.append(image)\n        labels.append(simpson_label)\nsimpson_images = np.array(simpson_images)\nlabels = np.array(labels)","d11c29a5":"label_to_id_dict = {v:i for i,v in enumerate(np.unique(labels))}\nid_to_label_dict = {v: k for k, v in label_to_id_dict.items()}","de81c1da":"id_to_label_dict","3f4d39a1":"def plot_image_grid(images, nb_rows, nb_cols, figsize=(5, 5)):\n    assert len(images) == nb_rows*nb_cols, \"Number of images should be the same as (nb_rows*nb_cols)\"\n    fig, axs = plt.subplots(nb_rows, nb_cols, figsize=figsize)\n    \n    n = 0\n    for i in range(0, nb_rows):\n        for j in range(0, nb_cols):\n            # axs[i, j].xaxis.set_ticklabels([])\n            # axs[i, j].yaxis.set_ticklabels([])\n            axs[i, j].axis('off')\n            axs[i, j].imshow(images[n])\n            n += 1        ","4e95d94e":"plot_image_grid(simpson_images[0:100], 10, 10)","aab4dcf1":"label_ids = np.array([label_to_id_dict[x] for x in labels])","7421409c":"scaler = StandardScaler()","51042239":"images_scaled = scaler.fit_transform([i.flatten() for i in simpson_images])","e96f8b75":"pca = PCA(n_components=50)\npca_result = pca.fit_transform(images_scaled)","4d03f4d5":"#Train Random Forest Classifier\nX_train, X_test, y_train, y_test = train_test_split(pca_result, label_ids, test_size=0.25, random_state=42)","42e5369b":"#Define confusion matrix\n\ndef plot_confusion_matrix(cm, classes,\n                         normalize=False,\n                         title='Confusion matrix',\n                         cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n        \n    print(cm)\n    \n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                horizontalalignment=\"center\",\n                color=\"white\" if cm[i, j] > thresh else \"black\")\n    \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","71b6c803":"forest = RandomForestClassifier(n_estimators=10)\nforest = forest.fit(X_train, y_train)","8599cd45":"test_predictions = forest.predict(X_test)","185baadf":"precision = accuracy_score(test_predictions, y_test) * 100\nprint(\"Accuracy with RandomForest: {0:.6f}\".format(precision))","76c55657":"auc_test = roc_auc_score(y_test,  test_predictions)\nprint('AUC Test: %.2f' % auc_test)","7c1b6494":"probs=forest.predict_proba(X_test)\npreds=probs[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, preds)\nplt.plot(fpr, tpr, color='orange', label='ROC')\nplt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve of Random Forest')\nplt.legend()\nplt.show()","dd963eb9":"cm = confusion_matrix(y_test, test_predictions)","3552d796":"cm_plot_labels = ['homer_simpson', 'lisa_simpson']\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')","16b06020":"#train svm\nsvm_clf = svm.SVC(gamma='auto', kernel='linear', probability=True)\nsvm_clf = svm_clf.fit(X_train, y_train) ","a0ef175d":"test_predictions1 = svm_clf.predict(X_test)","b821a6ed":"precision = accuracy_score(test_predictions1, y_test) * 100\nprint(\"Accuracy with SVM: {0:.6f}\".format(precision))","f145553e":"auc_test = roc_auc_score(y_test,  test_predictions1)\nprint('AUC Test of SVM: %.2f' % auc_test)","3c40045f":"probs=svm_clf.predict_proba(X_test)\npreds=probs[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, preds)\nplt.plot(fpr, tpr, color='orange', label='ROC')\nplt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve of SVM')\nplt.legend()\nplt.show()","6900f8d7":"cm = confusion_matrix(y_test, test_predictions1)","561a5118":"cm_plot_labels = ['homer_simpson', 'lisa_simpson']\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')","42df7c70":"train_path = '\/Users\/hshen\/Dropbox\/data2\/train'\nvalid_path = '\/Users\/hshen\/Dropbox\/data2\/val'\ntest_path = '\/Users\/hshen\/Dropbox\/data2\/test'","7e482991":"train_data_gen = ImageDataGenerator(rescale=1.\/255).flow_from_directory(train_path, target_size=(224,224), classes=['homer_simpson', 'lisa_simpson'], batch_size=500)\nvalid_data_gen = ImageDataGenerator(rescale=1.\/255).flow_from_directory(valid_path, target_size=(224,224), classes=['homer_simpson', 'lisa_simpson'], batch_size=100)\ntest_data_gen = ImageDataGenerator(rescale=1.\/255).flow_from_directory(test_path, target_size=(224,224), classes=['homer_simpson', 'lisa_simpson'], batch_size=100)","b1c9337f":"# plots images with Labels within jupyter notebook\ndef plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3):\n            ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    cols = len(ims)\/\/rows if len(ims) % 2 == 0 else len(ims)\/\/rows + 1\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, cols, i+1)\n        sp.axis('Off')\n        if titles is not None:\n            sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n","72ebd24a":"sample_training_images, labels = next(train_data_gen)","a137d188":"plots(sample_training_images, titles=labels)","f1b74c9c":"# Build and train CNN","9df655fb":"total_train=2880\ntotal_val=359\nepochs=15","2603175f":"model = Sequential([\n    Conv2D(16, 3, padding='same', activation='relu', input_shape=(224, 224 ,3)),\n    MaxPooling2D(),\n    Conv2D(32, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(2, activation='sigmoid')\n])\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","d33f8d35":"history1 = model.fit_generator(\n    train_data_gen,\n    steps_per_epoch=total_train \/\/700,\n    epochs=5,\n    validation_data=valid_data_gen,\n    validation_steps=total_val \/\/100\n)","46a8f63b":"acc = history1.history['accuracy']\nval_acc = history1.history['val_accuracy']\n\nloss = history1.history['loss']\nval_loss = history1.history['val_loss']\n\nepochs_range = range(5)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","0e51743a":"model1 = Sequential([\n    Conv2D(16, 3, padding='same', activation='relu', input_shape=(224, 224 ,3)),\n    MaxPooling2D(),\n    Conv2D(32, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(2, activation='sigmoid')\n])\nmodel1.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","9ad271ef":"history2 = model1.fit_generator(\n    train_data_gen,\n    steps_per_epoch=total_train \/\/700,\n    epochs=15,\n    validation_data=valid_data_gen,\n    validation_steps=total_val \/\/100\n)","dd21741c":"acc = history2.history['accuracy']\nval_acc = history2.history['val_accuracy']\n\nloss = history2.history['loss']\nval_loss = history2.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","1ae5b587":"#underfitting","bdfa86b6":"#Visualize training images","7317865d":"sample_training_images, _ = next(train_data_gen)","93c8fe00":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","bb0e0d31":"plotImages(sample_training_images[:5])","c445e305":"#Apply horizontal flip","0c389eeb":"train_data_gen = ImageDataGenerator(rescale=1.\/255, horizontal_flip=True).flow_from_directory(train_path, target_size=(224,224), classes=['homer_simpson', 'lisa_simpson'], batch_size=500,shuffle=True)\nvalid_data_gen = ImageDataGenerator(rescale=1.\/255, horizontal_flip=True).flow_from_directory(valid_path, target_size=(224,224), classes=['homer_simpson', 'lisa_simpson'], batch_size=100,shuffle=True)\ntest_data_gen = ImageDataGenerator(rescale=1.\/255, horizontal_flip=True).flow_from_directory(test_path, target_size=(224,224), classes=['homer_simpson', 'lisa_simpson'], batch_size=100,shuffle=True)","7cd2aa08":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]","8719604e":"# Re-use the same custom plotting function defined and used\n# above to visualize the training images\nplotImages(augmented_images)","d1143007":"model2 = Sequential([\n    Conv2D(16, 3, padding='same', activation='relu', input_shape=(224, 224 ,3)),\n    MaxPooling2D(),\n    Conv2D(32, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(2, activation='sigmoid')\n])\nmodel2.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","244e2d5d":"history3 = model2.fit_generator(\n    train_data_gen,\n    steps_per_epoch=total_train \/\/700,\n    epochs=15,\n    validation_data=valid_data_gen,\n    validation_steps=total_val \/\/100\n)","11af1f7e":"acc = history3.history['accuracy']\nval_acc = history3.history['val_accuracy']\n\nloss = history3.history['loss']\nval_loss = history3.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","e57c7f2e":"#Put it all together","14c873e2":"image_gen_train = ImageDataGenerator(rescale=1.\/255,\n                                    rotation_range=45,\n                                    width_shift_range=.15,\n                                    height_shift_range=.15,\n                                    horizontal_flip=True,\n                                    zoom_range=0.5)","2369c5a3":"train_data_gen = image_gen_train.flow_from_directory(batch_size=700,\n                                                    directory=train_path,\n                                                    shuffle=True,\n                                                    target_size=(224,224),\n                                                    )","995ec764":"valid_data_gen=image_gen_train.flow_from_directory(batch_size=700,\n                                                    directory=valid_path,\n                                                    shuffle=True,\n                                                    target_size=(224,224),\n                                                    )","7bbe1d69":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]\nplotImages(augmented_images)","37fb1172":"model3 = Sequential([\n    Conv2D(16, 3, padding='same', activation='relu', input_shape=(224, 224 ,3)),\n    MaxPooling2D(),\n    Conv2D(32, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(2, activation='sigmoid')\n])\nmodel3.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","5fcd03ac":"history4 = model3.fit_generator(\n    train_data_gen,\n    steps_per_epoch=total_train \/\/700,\n    epochs=15,\n    validation_data=valid_data_gen,\n    validation_steps=total_val \/\/100\n)","8479a748":"acc = history4.history['accuracy']\nval_acc = history4.history['val_accuracy']\n\nloss = history4.history['loss']\nval_loss = history4.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","83d66ff7":"#Build Fine-tuned VGG16 model","be434a72":"vgg16_model = keras.applications.vgg16.VGG16()","e136bf1a":"vgg16_model.summary()","4614b4c9":"type(vgg16_model)","4c72035d":"model4 = Sequential()\nfor layer in vgg16_model.layers:\n    if layer.name != 'predictions':\n        model4.add(layer)","a21baa6e":"model4.summary()","42686ba2":"for layer in model4.layers:\n    layer.trainable = False","4c0226d1":"model4.add(Dense(2, activation='softmax'))","1a2ef2d7":"model4.summary()","8c7c1c1d":"#Train the fine-tuned VGG16 model","d84be6fd":"model4.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])","6ef7967c":"history=model4.fit_generator(train_data_gen, steps_per_epoch=5,\n                   validation_data=valid_data_gen, validation_steps=2, epochs=5, verbose=2)","5ee433eb":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(5)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","fe0c77a6":"#Predict using fine-tuned VGG16 model by picture","a021d8a2":"image='\/Users\/hshen\/Dropbox\/kaggle_simpson_testset\/homer_simpson_2.jpg'","a432b3b0":"my_image1=plt.imread(image)\nimg=plt.imshow(my_image1)","ea9a57b5":"from skimage.transform import resize\nmy_image_resized1 = resize(my_image1, (224,224,3)) \nimg1= plt.imshow(my_image_resized1) ","8cbd85d9":"import numpy as np\nprobabilities1 = model3.predict(np.array( [my_image_resized1,] ))","3f80bbcd":"probabilities1","52697049":"number_to_class=['homer_simpson','lisa_simpson']","65b2eb44":"index = np.argsort(probabilities1[0,:])","c3709e04":"print(\"Most likely class:\", number_to_class[index[1]], \"-- Probability:\", probabilities1[0,index[1]])\nprint(\"Most likely class:\", number_to_class[index[0]], \"-- Probability:\", probabilities1[0,index[0]])","ece83ae8":"#To save this model \nmodel.save('my_model.h5')","827e6df6":"#CNN"}}