{"cell_type":{"f94ab752":"code","dc9b7ba5":"code","72ef9f5a":"code","f9b4c708":"code","b26e69e9":"code","6fb91cd7":"code","1465609d":"code","6b0c2c26":"code","e2981035":"code","c1056586":"code","87e0dfa7":"code","c0aea5fa":"code","28f6398c":"code","b5fc4deb":"code","d28a00a0":"code","ebe9284c":"code","c8f7d721":"code","42672c85":"code","ccd37456":"code","47b39b13":"code","a250771e":"code","2ed37dc3":"code","94a70df6":"code","6abfa4ed":"code","e432614f":"code","cc60f075":"code","594c879b":"code","f7edc89f":"code","f016cc02":"code","c736b5c9":"code","64276d0a":"code","d1b71519":"code","e6505238":"code","a9341a31":"code","14022ed8":"code","2cb7de3a":"code","dfb77925":"code","7c0039d4":"code","39b27eb9":"code","9ff07dee":"code","9e3a2011":"code","6ad15e9c":"code","04d72390":"code","acb6d71d":"code","0f63c841":"code","0f7b7e67":"code","f276179e":"code","60d2f8a2":"code","df14e36e":"code","65d09e29":"code","3e19e077":"code","db67b74c":"code","0985eb8e":"code","5174dff7":"code","efdd98f7":"code","9f731574":"code","2b50355b":"code","296d83fe":"code","ba3367e2":"code","fe851252":"code","4f038df6":"code","38b0d166":"code","75ef88c1":"code","65b256c7":"code","76a256f3":"code","87021924":"code","085b2377":"code","3fbf9b07":"code","7875c39d":"code","ec0cea7a":"code","705d170c":"code","3b110b07":"code","beb33fb4":"code","9e46eecd":"code","7a6f38c4":"code","d626d3bb":"code","bcb1b312":"code","27f9f135":"markdown","3876a995":"markdown","f901b35c":"markdown","1c059b90":"markdown","a2eb1158":"markdown","01824b15":"markdown","d149eef0":"markdown","52d9053c":"markdown","3f464053":"markdown","b65689c4":"markdown","7c469152":"markdown","5630e6c2":"markdown","36f0e63e":"markdown","56cfe804":"markdown","94bd4aa0":"markdown","e8225c7e":"markdown","330ab7b7":"markdown"},"source":{"f94ab752":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns","dc9b7ba5":"# path to dataset folder\ndataset_path = \"..\/input\/tabular-playground-series-jul-2021\"","72ef9f5a":"os.listdir(dataset_path)","f9b4c708":"train_csv = pd.read_csv(os.path.join(dataset_path, \"train.csv\"))\ntrain_csv.head()","b26e69e9":"test_csv = pd.read_csv(os.path.join(dataset_path, \"test.csv\"))\ntest_csv.head()","6fb91cd7":"submission_csv = pd.read_csv(os.path.join(dataset_path, \"sample_submission.csv\"))\nsubmission_csv.head()","1465609d":"# train data shape\ntrain_csv.shape","6b0c2c26":"# check if any value in dataframe is null\ntrain_csv.isnull().sum()","e2981035":"train_csv.describe()","c1056586":"train_csv.columns","87e0dfa7":"print(\"Range of datetime in training data\")\nprint(train_csv[\"date_time\"].min())\nprint(\"to\")\nprint(train_csv[\"date_time\"].max())","c0aea5fa":"print(\"Range of datetime in test data\")\nprint(test_csv[\"date_time\"].min())\nprint(\"to\")\nprint(test_csv[\"date_time\"].max())","28f6398c":"train_csv.plot(x=\"date_time\", y=\"target_carbon_monoxide\", rot=50)","b5fc4deb":"train_csv.plot(x=\"date_time\", y=\"target_benzene\", rot=50)","d28a00a0":"train_csv.plot(x=\"date_time\", y=\"target_nitrogen_oxides\", rot=50)","ebe9284c":"train_csv.plot(x=\"date_time\", y=\"sensor_1\", rot=50)","c8f7d721":"train_csv.plot(x=\"date_time\", y=\"sensor_2\", rot=50)","42672c85":"train_csv.plot(x=\"date_time\", y=\"sensor_3\", rot=50)","ccd37456":"train_csv.plot(x=\"date_time\", y=\"sensor_4\", rot=50)","47b39b13":"train_csv.plot(x=\"date_time\", y=\"sensor_5\", rot=50)","a250771e":"# changing dtype of columns\ndef change_dtypes(df):\n    df[\"date_time\"] = pd.to_datetime(df[\"date_time\"])","2ed37dc3":"change_dtypes(train_csv)","94a70df6":"# extracting features using datetime\ndef datetime2features(df):\n    time_col = \"date_time\"\n    df[\"year\"] = df[time_col].dt.year\n    df[\"month\"] = df[time_col].dt.month\n    df[\"day\"] = df[time_col].dt.day\n    df[\"hour\"] = df[time_col].dt.hour\n    df[\"dayofweek\"] = df[time_col].dt.dayofweek\n    df[\"year\"] = df[time_col].dt.year\n    df['weekend'] = df[time_col].dt.dayofweek.apply(lambda x: 1 if (x>4)  else 0)","6abfa4ed":"'''\n    which phase of day the time denotes [morning, afternoon, evening, night] \n'''\ndef time_phase(df):\n    def which_phase(hour):\n        if hour >= 0 and hour <= 5:\n            return 1\n        elif hour >=6 and hour <= 11:\n            return 2\n        elif hour >=12  and hour <= 17:\n            return 3\n        elif hour >=18 and hour <= 23:\n            return 4\n        return NaN \n    time_col = \"date_time\"\n    df[\"phase\"] = df[time_col].dt.hour.apply(lambda x : which_phase(x))","e432614f":"datetime2features(train_csv)\ntime_phase(train_csv)\ntrain_csv.head()","cc60f075":"train_csv.describe()","594c879b":"'''\n    which season of year the time denotes [summer, rainy, winter] \n'''\ndef season(df):\n    def which_season(month):\n        if month >= 3 and month <= 6:\n            return 1\n        elif month >= 7 and month <= 9:\n            return 2\n        elif month >= 10  and month <= 12:\n            return 3\n        elif month < 3:\n            return 3\n        return NaN\n    time_col = \"date_time\"\n    df[\"season\"] = df[time_col].dt.month.apply(lambda x : which_season(x))","f7edc89f":"season(train_csv)\ntrain_csv.head()","f016cc02":"train_csv.describe()","c736b5c9":"'''\nratio between relative humidity and temperature\n'''\ndef ratio_rh_temp(df):\n    df[\"r_rh_temp\"] = df[\"relative_humidity\"]\/(df[\"deg_C\"]+1e-9)","64276d0a":"ratio_rh_temp(train_csv)\ntrain_csv.head()","d1b71519":"train_csv.describe()","e6505238":"plt.figure(figsize=(10,8))\nsns.heatmap(train_csv.corr())","a9341a31":"model_save_folder = \"models\"\ncsv_folder = \"csv\"","14022ed8":"os.makedirs(model_save_folder, exist_ok=True)\nos.makedirs(csv_folder, exist_ok=True)","2cb7de3a":"train_csv.to_csv(os.path.join(csv_folder, \"train_edit.csv\"), index=False)","dfb77925":"test_csv.describe()","7c0039d4":"change_dtypes(test_csv)\ndatetime2features(test_csv)\ntime_phase(test_csv)\nseason(test_csv)\nratio_rh_temp(test_csv)","39b27eb9":"test_csv.describe()","9ff07dee":"test_csv.to_csv(os.path.join(csv_folder, \"test_edit.csv\"), index=False)","9e3a2011":"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge, BayesianRidge, LogisticRegression\nfrom sklearn.svm import SVR\nfrom mlxtend.regressor import StackingCVRegressor\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cbt\nimport sklearn.metrics as metrics\nimport sklearn.model_selection as ms\nimport pickle","6ad15e9c":"# Cross validation utility\nclass CrossValidation:\n    def __init__(self, df, shuffle,random_state=None):\n        self.df = df\n        self.random_state = random_state\n        self.shuffle = shuffle\n        if shuffle is True:\n            self.df = df.sample(frac=1,\n                random_state=self.random_state).reset_index(drop=True)\n        if not shuffle:\n            self.random_state = None\n\n    def hold_out_split(self,percent,stratify=None):\n        if stratify is not None:\n            y = self.df[stratify]\n            train,val = ms.train_test_split(self.df, test_size=percent\/100,\n                stratify=y, random_state=self.random_state)\n            return train,val\n        size = len(self.df) - int(len(self.df)*(percent\/100))\n        train = self.df.iloc[:size,:]\n        val = self.df.iloc[size:,:]\n        return train,val\n\n    def kfold_split(self, splits, stratify=None):\n        if stratify is not None:\n            kf = ms.StratifiedKFold(n_splits=splits, \n                random_state=self.random_state)\n            y = self.df[stratify]\n            for train, val in kf.split(X=self.df,y=y):\n                t = self.df.iloc[train,:]\n                v = self.df.iloc[val, :]\n                yield t,v\n        else:\n            kf = ms.KFold(n_splits=splits, shuffle=self.shuffle,\n                random_state=self.random_state)\n            for train, val in kf.split(X=self.df):\n                t = self.df.iloc[train,:]\n                v = self.df.iloc[val, :]\n                yield t,v","04d72390":"# calculate rmsle of predicted data \ndef mse(y_true, y_pred):\n    return metrics.mean_squared_error(y_true, y_pred)","acb6d71d":"folds = 5\nseed = 48","0f63c841":"features_exclude = [\"date_time\"]\ntargets = ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']","0f7b7e67":"features = [col for col in train_csv.columns if col not in features_exclude+targets]\nprint(features)","f276179e":"cv = CrossValidation(train_csv, shuffle=True, random_state=seed)","60d2f8a2":"fold_models = {tar:[] for tar in targets}\nprint(fold_models)","df14e36e":"m_rfg = RandomForestRegressor(n_estimators=100)\nm_gb = GradientBoostingRegressor(n_estimators=100)\nm_lgb = lgb.LGBMRegressor(seed=seed)\nm_ctb = cbt.CatBoostRegressor(random_seed=seed, verbose=False)\nm_xgb = xgb.XGBRegressor(random_state=seed)\n\nlearners = (m_rfg, m_gb ,m_lgb, m_ctb, m_xgb)\n\nmeta_model = BayesianRidge(normalize=True)","65d09e29":"def train_step(X, Y, evalX, evalY, learners, meta_model, verbose=True):\n    reg = StackingCVRegressor(regressors=learners, \n                            meta_regressor = meta_model,\n                            n_jobs = -1,\n                            verbose = int(verbose)\n                           )\n    trainX = X.values\n    trainY = Y.values\n    \n    model = reg.fit(trainX, trainY)\n    \n    predY_train = model.predict(trainX)\n    \n    train_rmsle = mse(trainY, predY_train)\n    train_r2 = metrics.r2_score(trainY, predY_train)\n    \n    if verbose:\n        print(\"Training mse: \", train_rmsle)\n        print(\"Training r2: \", train_r2)\n\n    valX = evalX.values\n    valY = evalY.values\n    \n    predY_val = model.predict(valX)\n    \n    val_rmsle = mse(valY, predY_val)\n    val_r2 = metrics.r2_score(valY, predY_val)\n    \n    if verbose:\n        print(\"Validation mse: \", val_rmsle)\n        print(\"Validation r2: \", val_r2)\n        \n    return {\"model\": model,\n            \"train_scores\":{\"r2\": train_r2, \"mse\": train_rmsle},\n            \"val_scores\":{\"r2\": val_r2, \"mse\": val_rmsle}\n           }","3e19e077":"def train_folds(cv, feature_cols, target_col, num_folds, learners, meta_model,\n                verbose=True):\n    fold_train_rmsle = []\n    fold_train_r2 = []\n    fold_val_rmsle = [] \n    fold_val_r2 = []\n    fold_models = []\n\n    for fold, (train_, val_) in enumerate(cv.kfold_split(splits=num_folds)):\n        result = train_step(X=train_[feature_cols],\n                            Y=train_[target_col],\n                            evalX=val_[feature_cols],\n                            evalY=val_[target_col],\n                            learners=learners,\n                            meta_model=meta_model,\n                            verbose=verbose\n                           )\n        fold_train_rmsle.append(result[\"train_scores\"][\"mse\"])\n        \n        fold_train_r2.append(result[\"train_scores\"][\"r2\"])\n\n        fold_val_rmsle.append(result[\"val_scores\"][\"mse\"])\n        fold_val_r2.append(result[\"val_scores\"][\"r2\"])\n\n        fold_models.append(result[\"model\"])\n        \n    return {\"models\":fold_models,\n            \"train_scores\":{\"r2\": np.mean(fold_train_r2), \"mse\": np.mean(fold_train_rmsle)},\n            \"val_scores\":{\"r2\":np.mean(fold_val_r2), \"mse\":np.mean(fold_val_rmsle)}\n           }","db67b74c":"target = \"target_carbon_monoxide\"\nresults = train_folds(cv, features, target, folds, learners, meta_model)\nfold_models[target] = results[\"models\"]\n\nprint(\"=\"*50)\nprint(\"Training MSE: \", results[\"train_scores\"][\"mse\"])\nprint(\"Training R2: \", results[\"train_scores\"][\"r2\"])\nprint(\"Validation MSE: \", results[\"val_scores\"][\"mse\"])\nprint(\"Validation R2: \", results[\"val_scores\"][\"r2\"])","0985eb8e":"target = \"target_benzene\"\nresults = train_folds(cv, features, target, folds, learners, meta_model)\nfold_models[target] = results[\"models\"]\nprint(\"=\"*50)\nprint(\"Training MSE: \", results[\"train_scores\"][\"mse\"])\nprint(\"Training R2: \", results[\"train_scores\"][\"r2\"])\nprint(\"Validation MSE: \", results[\"val_scores\"][\"mse\"])\nprint(\"Validation R2: \", results[\"val_scores\"][\"r2\"])","5174dff7":"target = \"target_nitrogen_oxides\"\nresults = train_folds(cv, features, target, folds, learners, meta_model)\nfold_models[target] = results[\"models\"]\nprint(\"=\"*50)\nprint(\"Training MSE: \", results[\"train_scores\"][\"mse\"])\nprint(\"Training R2: \", results[\"train_scores\"][\"r2\"])\nprint(\"Validation MSE: \", results[\"val_scores\"][\"mse\"])\nprint(\"Validation R2: \", results[\"val_scores\"][\"r2\"])","efdd98f7":"def get_weights(predictions, targets, apply_softmax=True):\n    def softmax(x):\n        f_x = np.exp(x) \/ np.sum(np.exp(x))\n        return f_x\n    lnr = LinearRegression()\n    lnr_model = lnr.fit(predictions, targets)\n    if apply_softmax:\n        return softmax(lnr_model.coef_)\n    return lnr_model.coef_","9f731574":"def weighted_sum(predictions, weights):\n    return np.dot(predictions, weights)","2b50355b":"trainX = train_csv[features].values\ntrainY = train_csv[targets]","296d83fe":"predictions = []","ba3367e2":"preds = []\nfor model in fold_models[targets[0]]:\n    preds.append(model.predict(trainX))\n\npreds = np.array(preds)\n\nweights_0 = get_weights(preds.transpose(), trainY[targets[0]].values)\nprint(\"Fold Predictions Weightings\")\nprint(weights_0)\n\npreds = weighted_sum(preds.transpose(), weights_0)\npredictions.append(preds)","fe851252":"preds = []\nfor model in fold_models[targets[1]]:\n    preds.append(model.predict(trainX))\n\npreds = np.array(preds)\nweights_1 = get_weights(preds.transpose(), trainY[targets[1]].values)\nprint(\"Fold Predictions Weightings\")\nprint(weights_1)\n\npreds = weighted_sum(preds.transpose(), weights_1)\npredictions.append(preds)","4f038df6":"preds = []\nfor model in fold_models[targets[2]]:\n    preds.append(model.predict(trainX))\n\npreds = np.array(preds)\nweights_2 = get_weights(preds.transpose(), trainY[targets[2]].values)\nprint(\"Fold Predictions Weightings\")\nprint(weights_2)\n\npreds = weighted_sum(preds.transpose(), weights_2)\npredictions.append(preds)","38b0d166":"predictions = np.array(predictions).transpose()\nprint(predictions.shape)\nprint(trainY.shape)","75ef88c1":"predictions = np.where(predictions<0, 0, predictions)","65b256c7":"print(\"R2 score: \", metrics.r2_score(trainY, predictions))\nprint(\"RMSLE score: \", np.sqrt(metrics.mean_squared_log_error(trainY, predictions)))","76a256f3":"testX = test_csv[features].values","87021924":"predictions = []","085b2377":"preds = []\nfor model in fold_models[targets[0]]:\n    preds.append(model.predict(testX))\n\npreds = np.array(preds)\n\npreds = weighted_sum(preds.transpose(), weights_0)\npredictions.append(preds)","3fbf9b07":"preds = []\nfor model in fold_models[targets[1]]:\n    preds.append(model.predict(testX))\n\npreds = np.array(preds)\n\npreds = weighted_sum(preds.transpose(), weights_1)\npredictions.append(preds)","7875c39d":"preds = []\nfor model in fold_models[targets[2]]:\n    preds.append(model.predict(testX))\n\npreds = np.array(preds)\n\npreds = weighted_sum(preds.transpose(), weights_2)\npredictions.append(preds)","ec0cea7a":"predictions = np.array(predictions).transpose()","705d170c":"predictions.shape","3b110b07":"predictions = np.where(predictions<0, 0, predictions)","beb33fb4":"submission_csv[targets] = predictions","9e46eecd":"submission_csv.to_csv(\"submission.csv\", index=False)","7a6f38c4":"submission_csv.head()","d626d3bb":"for key, models in fold_models.items():\n    for fold, model in enumerate(models):\n        with open(os.path.join(model_save_folder, f\"{key}_fold_{fold+1}.pkl\"), 'wb') as pckl:\n            pickle.dump(model, pckl)","bcb1b312":"!ls models","27f9f135":"# Tabular Playground JULY 2021\n\nThe goal of competitions is to provide a fun, and approachable for anyone, tabular dataset.\n\n## Evaluation Scheme\nThe RMSLE for a single column calculated as:\n\n$$\\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\log(p_i + 1) - \\log(a_i+1))^2 }$$\n\nwhere:\n\n$n$ is the total number of observations\n\n$p_i$ is your prediction\n\n$a_i$ is the actual value\n\n$log(x)$ is the natural logarithm of \n","3876a995":"### Ploting correlations between columns","f901b35c":"- changing datatypes of date column to pd datetime\n- convert datetime to features\n- extracting phase of day with respect to time\n- extracting season of the year using month\n- ratio of relative humidity and temperature","1c059b90":"# Data Visualization\n- plot time series targets values\n- plot time series sensor data","a2eb1158":"### Plotting sensor data","01824b15":"# Importing Dependencies\n\n- pandas : for csv reading and data analysis\n- numpy :  for array manipulation\n- matplotlib.pyplot : for plotting graphs\n- os : os level commands\n- seaborn : for better looking plots","d149eef0":"### Carbon Monoxide","52d9053c":"# Training","3f464053":"### Nitrogen Oxides","b65689c4":"### Benzene","7c469152":"# Inference on test dataset","5630e6c2":"### Prediction blending from folds","36f0e63e":"# Basic Data Analysis","56cfe804":"# Model Training","94bd4aa0":"### Splitting data into folds for cross validation","e8225c7e":"# Feature Engineering","330ab7b7":"### Plotting targets"}}