{"cell_type":{"012980c0":"code","cb18374a":"code","70a0567c":"code","5252e284":"code","442ef8f1":"code","55993ccf":"code","98f060d6":"code","a4742da8":"code","01b67dcc":"code","cdace7a7":"code","37ffe4ec":"code","6e4aa5a9":"code","bbac799a":"code","9d40b0f8":"code","ca9c31ae":"code","dc4438ba":"code","0d34c279":"code","3a65d03a":"code","03f392b2":"code","f31caf04":"code","2319aaef":"code","ddb0f567":"code","3aedbeb1":"code","e40f983e":"code","524af53d":"code","78bb1807":"code","4d0b52a0":"code","63b69059":"code","80a9c8b6":"code","90904739":"code","7680d7b7":"code","ee0923f7":"code","c864589d":"code","4e285620":"code","1f7e3d49":"code","912905ee":"code","e226f2ff":"code","bbebdf75":"code","eef0a01f":"code","b25a4f80":"code","41079aff":"code","4797b438":"code","fe199042":"code","421e705a":"code","9cef8d9f":"code","aa92a398":"code","946cda64":"code","6effc127":"code","20ec3e4f":"code","b378341e":"code","31848800":"code","f530b684":"code","68b280e5":"code","f5651d17":"code","57375339":"code","54bef3b7":"code","21299ce5":"code","8ef2d802":"code","f1ed65f8":"markdown","c7192316":"markdown","44509155":"markdown","2a0f2163":"markdown","0d1ec8ce":"markdown","7f097070":"markdown","92691ed5":"markdown","c3472ed5":"markdown","e49aaf5c":"markdown","864d368e":"markdown","477e3a8b":"markdown","c2cfb6ee":"markdown","c6b51842":"markdown","7f4ef304":"markdown","08d4090b":"markdown","87091879":"markdown","ca756ca5":"markdown","d23c19a8":"markdown","aa2e4ffa":"markdown","2fe7a962":"markdown","291fadcd":"markdown","adfb9aaa":"markdown","a0a50251":"markdown","791fd869":"markdown"},"source":{"012980c0":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport time\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\nfrom skimage.transform import resize\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nimport zipfile\nfrom io import BytesIO\nfrom nibabel import FileHolder\nfrom nibabel.analyze import AnalyzeImage\nimport PIL\nfrom IPython import display\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","cb18374a":"Art_Path = Path(\"..\/input\/art-movements\/dataset\/train\/cubism\")\nHuman_Face_Path = Path(\"..\/input\/extyalebcroppedpng\/CroppedYalePNG\")\nFoot_Print_Left_Path = Path(\"..\/input\/footprintdatabase\/Dactyloscopic\/Left\")\nFoot_Print_Right_Path = Path(\"..\/input\/footprintdatabase\/Dactyloscopic\/Right\")\nGoblin_Path = Path = Path(\"..\/input\/goblin-portraits\/images\")","70a0567c":"Art_Images = list(Art_Path.glob(r\"*.jpg\"))\nHuman_Face_Images = list(Human_Face_Path.glob(r\"*.png\"))\nFoot_Left_Images = list(Foot_Print_Left_Path.glob(r\"*.jpeg\"))\nFoot_Right_Images = list(Foot_Print_Right_Path.glob(r\"*.jpeg\"))\nGoblin_Images = list(Goblin_Path.glob(r\"*.jpg\"))","5252e284":"R_Goblin = Goblin_Images[0:600]\nR_Human = Human_Face_Images[0:100]","442ef8f1":"print(len(R_Goblin))\nprint(len(R_Human))","55993ccf":"Goblin_Human_Images = []\n\nfor G_images in R_Goblin:\n    Goblin_Human_Images.append(G_images)\n    \nfor H_images in R_Human:\n    Goblin_Human_Images.append(H_images)","98f060d6":"print(len(Goblin_Human_Images))","a4742da8":"Total_FootPrint_Images = []\n\nfor RF_images,LF_images in zip(Foot_Left_Images,Foot_Right_Images):\n    Total_FootPrint_Images.append(RF_images)\n    Total_FootPrint_Images.append(LF_images)","01b67dcc":"print(len(Total_FootPrint_Images))","cdace7a7":"Art_Series = pd.Series(Art_Images,name=\"ART\").astype(str)\nGoblin_Human_Series = pd.Series(Goblin_Human_Images,name=\"GOBLIN_HUMAN\").astype(str)\nFoot_Print_Series = pd.Series(Total_FootPrint_Images,name=\"FOOT_PRINT\").astype(str)","37ffe4ec":"print(Art_Series.head(-1))","6e4aa5a9":"print(Goblin_Human_Series.head(-1))","bbac799a":"print(Foot_Print_Series.head(-1))","9d40b0f8":"Goblin_Human_Series = Goblin_Human_Series.sample(frac=1).reset_index(drop=True)\nFoot_Print_Series = Foot_Print_Series.sample(frac=1).reset_index(drop=True)","ca9c31ae":"def reading_function(image):\n    \n    Picking_Image = cv2.cvtColor(cv2.imread(image),cv2.COLOR_BGR2RGB)\n    \n    return Picking_Image","dc4438ba":"figure,axis = plt.subplots(1,3,figsize=(10,10))\n\naxis[0].imshow(reading_function(Art_Series[55]))\naxis[0].set_title(\"ART\")\naxis[0].set_xlabel(reading_function(Art_Series[55]).shape)\n\naxis[1].imshow(reading_function(Goblin_Human_Series[55]))\naxis[1].set_title(\"GOBLIN_HUMAN\")\naxis[1].set_xlabel(reading_function(Goblin_Human_Series[55]).shape)\n\naxis[2].imshow(reading_function(Foot_Print_Series[55]))\naxis[2].set_title(\"FOOT_PRINT\")\naxis[2].set_xlabel(reading_function(Foot_Print_Series[55]).shape)","0d34c279":"figure,axis = plt.subplots(1,3,figsize=(10,10))\n\naxis[0].imshow(reading_function(Art_Series[1]))\naxis[0].set_title(\"ART\")\naxis[0].set_xlabel(reading_function(Art_Series[1]).shape)\n\naxis[1].imshow(reading_function(Goblin_Human_Series[1]))\naxis[1].set_title(\"GOBLIN_HUMAN\")\naxis[1].set_xlabel(reading_function(Goblin_Human_Series[1]).shape)\n\naxis[2].imshow(reading_function(Foot_Print_Series[1]))\naxis[2].set_title(\"FOOT_PRINT\")\naxis[2].set_xlabel(reading_function(Foot_Print_Series[1]).shape)","3a65d03a":"figure,axis = plt.subplots(4,4,figsize=(10,10))\n\nfor indexing,operations in enumerate(axis.flat):\n    Reading_IMG = cv2.imread(Art_Series[indexing])\n    Reading_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n    \n    operations.set_xlabel(Reading_IMG.shape)\n    operations.imshow(Reading_IMG)\n    \nplt.tight_layout()\nplt.show()","03f392b2":"figure,axis = plt.subplots(4,4,figsize=(10,10))\n\nfor indexing,operations in enumerate(axis.flat):\n    Reading_IMG = cv2.imread(Goblin_Human_Series[indexing])\n    Reading_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n    \n    operations.set_xlabel(Reading_IMG.shape)\n    operations.imshow(Reading_IMG)\n    \nplt.tight_layout()\nplt.show()","f31caf04":"figure,axis = plt.subplots(4,4,figsize=(10,10))\n\nfor indexing,operations in enumerate(axis.flat):\n    Reading_IMG = cv2.imread(Foot_Print_Series[indexing])\n    Reading_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n    \n    operations.set_xlabel(Reading_IMG.shape)\n    operations.imshow(Reading_IMG)\n    \nplt.tight_layout()\nplt.show()","2319aaef":"Art_Train = []\n\nfor images_from_series in Art_Series:\n    \n    X_Image = reading_function(images_from_series)\n    X_Image = cv2.resize(X_Image,(180,180))\n    X_Image = X_Image \/ 255.0\n    Art_Train.append(X_Image)","ddb0f567":"plt.imshow(Art_Train[0])","3aedbeb1":"print(np.shape(np.array(Art_Train)))","e40f983e":"Goblin_Human_Train = []\n\nfor images_from_series in Goblin_Human_Series:\n    \n    X_Image = reading_function(images_from_series)\n    X_Image = cv2.resize(X_Image,(180,180))\n    X_Image = X_Image \/ 255.0\n    Goblin_Human_Train.append(X_Image)","524af53d":"plt.imshow(Goblin_Human_Train[0])","78bb1807":"print(np.shape(np.array(Goblin_Human_Train)))","4d0b52a0":"Foot_Train = []\n\nfor images_from_series in Foot_Print_Series:\n    \n    X_Image = reading_function(images_from_series)\n    X_Image = cv2.resize(X_Image,(180,180))\n    X_Image = X_Image \/ 255.0\n    Foot_Train.append(X_Image)","63b69059":"plt.imshow(Foot_Train[0])","80a9c8b6":"print(np.shape(np.array(Foot_Train)))","90904739":"Art_Train = np.array(Art_Train,dtype=\"float32\")\nGoblin_Human_Train = np.array(Goblin_Human_Train,dtype=\"float32\")\nFoot_Train = np.array(Foot_Train,dtype=\"float32\")","7680d7b7":"print(Art_Train.shape)\nprint(Goblin_Human_Train.shape)\nprint(Foot_Train.shape)","ee0923f7":"iterations = 80\nvector_noise_shape = 180\ncount_example = 10\nbatch_size = 3\ncount_buffer_time = 60000","c864589d":"seed = tf.random.normal([count_example,vector_noise_shape])","4e285620":"Data_ART = tf.data.Dataset.from_tensor_slices(Art_Train).shuffle(count_buffer_time).batch(batch_size)\nData_HUMAN_GOBLIN = tf.data.Dataset.from_tensor_slices(Goblin_Human_Train).shuffle(count_buffer_time).batch(batch_size)\nData_FOOT_PRINT = tf.data.Dataset.from_tensor_slices(Foot_Train).shuffle(count_buffer_time).batch(batch_size)","1f7e3d49":"print(Data_ART.element_spec)\nprint(Data_HUMAN_GOBLIN.element_spec)\nprint(Data_FOOT_PRINT.element_spec)","912905ee":"def Generator_Model():\n    \n    \n    Model = Sequential()\n    #\n    Model.add(Dense(90*90*128,use_bias=False,input_shape=(180,)))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Reshape((90,90,128)))\n    #\n    Model.add(Conv2DTranspose(128,(3,3),padding=\"same\",use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Conv2DTranspose(3,(3,3),padding=\"same\",use_bias=False,activation=\"tanh\"))\n    \n    \n    return Model","e226f2ff":"Generator = Generator_Model()\n\nprint(Generator.summary())","bbebdf75":"plot_model(Generator, to_file='Model_Generator.png', show_shapes=True, show_layer_names=True)","eef0a01f":"def Discriminator_Model():\n    \n    Model = Sequential()\n    #\n    Model.add(Conv2D(64,(3,3),padding=\"same\",input_shape=[180,180,3]))\n    Model.add(Dropout(0.2))\n    Model.add(LeakyReLU())\n    #\n    Model.add(Conv2D(128,(3,3),padding=\"same\",kernel_initializer='he_normal'))\n    Model.add(Dropout(0.2))\n    Model.add(LeakyReLU())\n\n    Model.add(Conv2D(256,(3,3),padding=\"same\",kernel_initializer='he_normal'))\n    Model.add(Dropout(0.2))\n    Model.add(LeakyReLU())\n    \n    #\n    Model.add(layers.Flatten())\n    Model.add(layers.Dense(3))\n    \n    return Model","b25a4f80":"Discriminator = Discriminator_Model()\n\nprint(Discriminator.summary())","41079aff":"plot_model(Generator, to_file='Model_Discriminator.png', show_shapes=True, show_layer_names=True)","4797b438":"Generator_Optimizer = RMSprop(lr=0.0001,clipvalue=1.0,decay=1e-8)\nDiscriminator_Optimizer = RMSprop(lr=0.0001,clipvalue=1.0,decay=1e-8)","fe199042":"Loss_Function = tf.keras.losses.BinaryCrossentropy(from_logits=True)","421e705a":"def Discriminator_Loss(real_out,fake_out):\n    \n    real_loss_function = Loss_Function(tf.ones_like(real_out),real_out)\n    fake_loss_function = Loss_Function(tf.zeros_like(fake_out),fake_out)\n    total_loss = real_loss_function + fake_loss_function\n    \n    return total_loss","9cef8d9f":"def Generator_Loss(fake_output):\n    \n    return Loss_Function(tf.ones_like(fake_output),fake_output)","aa92a398":"def generate_and_save_images(model, epoch, test_input):\n    \n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(11, 11))\n    \n    for i in range(predictions.shape[0]):\n        plt.subplot(6, 6, i+1)\n        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n        plt.axis('off')\n\n    plt.savefig('footprint_{:04d}.png'.format(epoch))\n    plt.show()","946cda64":"def Train_Step(images):\n    \n    random_noise_vector = tf.random.normal([batch_size,vector_noise_shape])\n    \n    with tf.GradientTape() as Generator_Tape, tf.GradientTape() as Discriminator_Tape:\n        \n        Generator_Fake_Image = Generator(random_noise_vector,training=False)\n        \n        real_output = Discriminator(images,training=True)\n        fake_output = Discriminator(Generator_Fake_Image,training=True)\n        \n        Generator_Loss_Output = Generator_Loss(fake_output)\n        Discriminator_Loss_Output = Discriminator_Loss(real_output,fake_output)\n        \n    Generator_Gradients = Generator_Tape.gradient(Generator_Loss_Output,Generator.trainable_variables)\n    Discriminator_Gradients = Discriminator_Tape.gradient(Discriminator_Loss_Output,Discriminator.trainable_variables)\n    \n    Generator_Optimizer.apply_gradients(zip(Generator_Gradients,Generator.trainable_variables))\n    Discriminator_Optimizer.apply_gradients(zip(Discriminator_Gradients,Discriminator.trainable_variables))","6effc127":"def Training(dataset,iterations):\n    \n    for epoch in range(iterations):\n        start = time.time()\n        \n        for image_batch in dataset:\n            Train_Step(image_batch)\n            \n        display.clear_output(wait=True)\n        generate_and_save_images(Generator,epoch+1,seed)\n    \n    display.clear_output(wait=True)\n    generate_and_save_images(Generator,epoch,seed)  ","20ec3e4f":"Training(Data_ART,iterations)","b378341e":"Predict_Noise = tf.random.normal(shape=[50,vector_noise_shape])","31848800":"Generator_Predict = Generator(Predict_Noise)","f530b684":"figure, axes = plt.subplots(nrows=3,ncols=3,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    IMG_Prediction_Output = Generator_Predict[i]\n    ax.imshow(IMG_Prediction_Output)\n    ax.set_xlabel(Generator_Predict[i].shape)\nplt.tight_layout()\nplt.show()","68b280e5":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[25])\nplt.show()","f5651d17":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[10])\nplt.show()","57375339":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[1])\nplt.show()","54bef3b7":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[49])\nplt.show()","21299ce5":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[45])\nplt.show()","8ef2d802":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[49])\nplt.show()","f1ed65f8":"#### TRAINING STEP","c7192316":"# TRAIN PROCESS","44509155":"#### DISCRIMINATOR MDDEL","2a0f2163":"#### DATA MAIN PATH","0d1ec8ce":"#### OPTIMIZERS","7f097070":"#### QUANTITY DETERMINATION FOR GOBLIN-HUMAN","92691ed5":"#### GENERATING AND SAVING IMAGE","c3472ed5":"#### GENERATOR MODEL","e49aaf5c":"# DATA EXPORTING & TRANSFORMATION PROCESS","864d368e":"#### TO SERIES","477e3a8b":"#### LOSS FUNCTION","c2cfb6ee":"#### EXPORTATION","c6b51842":"#### TRAINING FUNCTION","7f4ef304":"![](https:\/\/www.datasciencearth.com\/wp-content\/uploads\/2020\/09\/Whole-net.png)","08d4090b":"# DC-GAN STEPS","87091879":"#### TRANSFORMATION","ca756ca5":"#### TO SHUFFLE","d23c19a8":"# PACKAGES AND LIBRARIES","aa2e4ffa":"#### TRANSFORMATION TENSOR SLICE","2fe7a962":"#### IMAGES PATH","291fadcd":"# IMAGE EXPORTATION AND TRANSFORMATION","adfb9aaa":"#### Please switch between versions.\n\n\n* Footprint creation\n* Goblin-human creation\n* Geometrically difficult painting creation\n\n\n> Some versions were saved for testing. Follow the code pattern carefully.\n\n* VERSION I - FOOT PRINT\n* VERSION II - GOBLIN\/HUMAN CREATION\n* VERSION III - TESTING \/ IF YOU WANT, IGNORE THAT VERSION\n* VERSION IV - ART\n* VERSION V - TESTING \/ LAST DOCUMENT\n\n\n---------------------------------------------\n* Also, data prep is the same in all of them.\n* You will see the effect of a single loop and model design on various data.\n\n**In addition, layer regularization was applied in the last study.**","a0a50251":"#### VISION","791fd869":"#### PARAMETERS"}}