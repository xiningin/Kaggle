{"cell_type":{"ddfdc7a0":"code","6c497980":"code","08db747b":"code","cb23de37":"code","38af37c2":"code","e81fbdaa":"code","7af09630":"code","9b2f568e":"code","74633d0e":"code","c6bd2fc6":"code","25867b68":"code","5dc401df":"code","bf1f4b1e":"code","74851740":"code","fada73b6":"code","21db4a5e":"code","42852a5d":"code","70acbf42":"code","2cced0a2":"code","29a14b69":"code","ccfd0df0":"code","69ec8d1e":"code","b16e536c":"code","3bdc1e82":"code","82a3571f":"code","7266c99e":"code","5bde14b1":"code","f5064773":"code","de871da7":"code","2d3cb8c4":"code","bdcec283":"code","17715a20":"code","568d136f":"code","7ad1ad1e":"code","36c0007f":"code","82b229ee":"code","912aeb39":"markdown"},"source":{"ddfdc7a0":"# import important library \nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport tensorflow as tf\n%matplotlib inline","6c497980":"# load data \ntrain = pd.read_csv(r\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(r\"..\/input\/digit-recognizer\/test.csv\")","08db747b":"X_train = train.drop(\"label\" , axis = 1)\ntrain_label =train[\"label\"]","cb23de37":"# check null value in train \nX_train.isnull().any().describe()","38af37c2":"# check null value in test \ntest.isnull().any().describe()","e81fbdaa":"# visualize data \nsns.countplot(train_label)\npd.Series(train_label).value_counts()","7af09630":"X_train = X_train.values.reshape(-1 , 28 , 28 , 1)","9b2f568e":"X_train.shape","74633d0e":"# visualize mnist data \nlabels=[\"zero\" , \"one\" , \"two\" , \"three\" , \"four\" , \"five\" , \"six\" , \"seven\" , \"eight\" , \"nine\"]\nindcis = np.random.randint(0 , X_train.shape[0] , 14)\nplt.figure(figsize=(20 , 20))\nfor i ,  index in enumerate(indcis):\n    plt.subplot(7 , 7 , i+1)\n    plt.imshow(X_train[index][: , : , 0] , cmap=plt.cm.binary)\n    plt.title(str(labels[train_label[index]]))\nplt.show()\n    ","c6bd2fc6":"# check shape of image \nshapes =[]\nfor i in range(X_train.shape[0]):\n    shape = X_train[i].shape\n    shapes.append(shape)\npd.Series(shapes).value_counts()\n       ","25867b68":"# data normalization \nX_train = X_train \/255.0\ntest = test.values \/255.0\n\n","5dc401df":"# important callbacks function\nclass metricsloss(tf.keras.callbacks.Callback):\n    def on_train_begin(self , epoch):\n        print(\"Training : strat training\")\n    def on_epoch_end(self , epoch , logs = None):\n        if (logs[\"accuracy\"]>0.995):\n            print(\"\\ntraining is cancalled because accuracy reached at 99.5%\")\n            self.model.stop_training =True","bf1f4b1e":"# make early stopping \nearly_stopping = tf.keras.callbacks.EarlyStopping(\npatience=3 , \n    monitor=\"val_accuracy\" , \n    mode=\"max\" , \n    min_delta=0.0001\n)","74851740":"# saving models \ncheck_point_path =\"check_point_path\/best_model_in_epoch{epoch}\"\ncheck_point = tf.keras.callbacks.ModelCheckpoint(\n  filepath= check_point_path , \n    save_weights_only=True , \n    save_best_only=True , \n    \n    monitor=\"val_accuracy\" , \n    verbose=1,\n    period=2,\n    mode =\"max\"\n    \n)","fada73b6":"# make learning rate decay\nlearning_rate_decay =tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_accuracy', \n            factor=0.1, \n            patience=3, \n            verbose=0, \n            mode='max', \n            min_delta=0.0001, \n            cooldown=0, \n            min_lr=0.00001)","21db4a5e":"# build model \ndef build_model(input_shape):\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Conv2D(filters=120 ,input_shape = input_shape , kernel_size=(3 , 3)  , strides=(1 , 1) , activation=\"relu\" ))\n    model.add(tf.keras.layers.MaxPool2D((2 , 2)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Conv2D(130 , (3 , 3) , activation=tf.nn.relu))\n    model.add(tf.keras.layers.MaxPool2D((2 , 2)))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(140 , activation=tf.nn.relu , kernel_initializer=\"he_uniform\"))\n    model.add(tf.keras.layers.Dropout(0.2))\n    model.add(tf.keras.layers.Dense(140 , activation=tf.nn.relu , kernel_initializer=\"random_uniform\"))\n    model.add(tf.keras.layers.Dense(50 , activation=tf.nn.relu ,\n                                    kernel_initializer=tf.keras.initializers.RandomNormal(mean = 0.0001 , stddev=0.005)))\n    model.add(tf.keras.layers.Dropout(0.2))\n    model.add(tf.keras.layers.Dense(10 , activation=tf.nn.softmax))\n    return model","42852a5d":"# compile model \ndef compile_model(model):\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n    model.compile(optimizer=optimizer , loss =\"sparse_categorical_crossentropy\" , metrics=[\"accuracy\"])","70acbf42":"# split train data into train and validation and test \nfrom sklearn.model_selection import train_test_split\nX_train , X_val , train_label , val_label = train_test_split(X_train , train_label , \n                                                            shuffle = True , random_state =33 , \n                                                            test_size = 0.2)\n","2cced0a2":"X_train.shape","29a14b69":"X_val.shape","ccfd0df0":"# split validation into val nd test \nX_val , X_test , val_label , test_label = train_test_split(X_val , val_label , random_state=33 , \n                                                          shuffle = True , test_size =0.5)","69ec8d1e":"# fit model \nmodel = build_model(input_shape=(28 , 28 , 1))","b16e536c":"model.summary()","3bdc1e82":"#combile model \ncompile_model(model)","82a3571f":"history =model.fit(X_train , train_label , epochs=15 , validation_data=(X_val , val_label) , \n         batch_size=50 , callbacks=[ metricsloss(),early_stopping , check_point , learning_rate_decay])","7266c99e":"pd.DataFrame(history.history)","5bde14b1":"# visualize model training for training\nplt.plot(history.epoch , history.history[\"accuracy\"]  , \"r\" , label=\"accuracy\")\nplt.plot(history.epoch , history.history[\"loss\"] , \"g\" , label =\"loss\")\nplt.xlabel(\"epochs\")\nplt.title(\"loss and accuracy in training\")\nplt.legend()\nplt.show()\n","f5064773":"# visualize model training for validation\nplt.plot(history.epoch , history.history[\"val_accuracy\"]  , \"r\" , label=\"val_accuracy\")\nplt.plot(history.epoch , history.history[\"val_loss\"] , \"g\" , label =\"val_loss\")\nplt.xlabel(\"epochs\")\nplt.title(\"loss and accuracy in validation\")\nplt.legend()\nplt.show()","de871da7":"# make prediction \ny_pred = model.predict(X_test)","2d3cb8c4":"# predict test data \nplt.figure(figsize=(30 , 30))\nindecis = np.random.randint(0 , X_test.shape[0] , 25)\nfor j , i in enumerate(indecis):\n    plt.subplot(5 , 5 , j+1)\n    plt.imshow(X_test[i].reshape(28 , 28 ) , cmap=plt.cm.binary)\n    plt.title(labels[y_pred[i].argmax()])\nplt.show()","bdcec283":"\ny_predicted =[y_pred[i].argmax() for i in range(y_pred.shape[0])]\n","17715a20":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(test_label , y_predicted)\nsns.heatmap(cm)","568d136f":"pd.DataFrame(data=cm , index=[f\"actual {i}\"  for i in labels ], columns =[f\"prdicted {j}\" for j in labels])","7ad1ad1e":"# mislead value \nmislead =test_label-y_predicted\nindex_of_mislead=[]\nx = 0\nfor i in mislead:\n    if i !=0:\n        index_of_mislead.append(x)\n    x+=1","36c0007f":"# number of mislead value \nlen(index_of_mislead)","82b229ee":"# visualize mislead value \nplt.figure(figsize=(50 , 50))\nfor i , j in enumerate(index_of_mislead[0:25]):\n    plt.subplot(5 , 5 , i+1 )\n    plt.imshow(X_test[j].reshape(28 , 28) , cmap=plt.cm.binary)\n    plt.title(f\"actual {labels[list(test_label)[j]]} , but bredicted {labels[y_predicted[j]]}\",fontdict={\"fontsize\":31} )\nplt.show()","912aeb39":"no null value on train so data is ready"}}