{"cell_type":{"8e94aa92":"code","e5b2cf66":"code","73571c8d":"code","ae287d73":"code","1582c0be":"code","896003fe":"code","4261a733":"code","799ba3aa":"code","7e18bbc7":"code","9d649644":"code","01bb756a":"code","00f9c270":"code","fd0ef11f":"code","ed0d8d19":"code","c7f80c39":"code","88591688":"code","92a31324":"code","566234a6":"markdown","c0d8f314":"markdown"},"source":{"8e94aa92":"# Import modules\n\nimport os\nimport zipfile\nimport random\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport cv2\nfrom tensorflow import keras\nimport tensorflow as tf\nimport keras.backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, Activation\nfrom tensorflow.keras.layers import BatchNormalization, Reshape, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nprint(os.listdir(\"..\/input\/aerial-cactus-identification\/\"))","e5b2cf66":"with zipfile.ZipFile(\"..\/input\/aerial-cactus-identification\/train.zip\",\"r\") as z:\n    z.extractall(\"\/kaggle\/temp\/\")\nwith zipfile.ZipFile(\"..\/input\/aerial-cactus-identification\/test.zip\",\"r\") as z:\n    z.extractall(\"\/kaggle\/temp\/test\/\")\n\nprint(len(os.listdir(\"..\/temp\/train\")))\nprint(len(os.listdir(\"..\/temp\/test\/test\")))","73571c8d":"train = \"..\/temp\/train\"\ntest = \"..\/temp\/test\"\nlabels = pd.read_csv('..\/input\/aerial-cactus-identification\/train.csv')\n\nlabels.has_cactus = labels.has_cactus.astype(str)\nprint(labels['has_cactus'].value_counts())","ae287d73":"# Plot random sample of training images\n\nrand_images = random.sample(os.listdir(train), 16)\n\nfig = plt.figure(figsize=(20,4))\nfor i, im in enumerate(rand_images):\n    plt.subplot(2, 8, i+1)\n    im = cv2.imread(os.path.join(train, im))\n    plt.imshow(im)\n    plt.axis('off')\nplt.show()","1582c0be":"# Split training data into training and validation sets\n\n# Could use sklearn.model_selection.train_test_split instead\n\nvalidation_split = 0.8\nidxs = np.random.permutation(range(len(labels))) < validation_split*len(labels)\n\ntrain_labels = labels[idxs]\nval_labels = labels[~idxs]\nprint(len(train_labels), len(val_labels))","896003fe":"train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1\/255, horizontal_flip=True, \n                                                             rotation_range=5,\n                                                             shear_range=0.2,\n                                                             height_shift_range=0.2,\n                                                             width_shift_range=0.2,\n                                                             vertical_flip=True,\n                                                            fill_mode='nearest')\n\nbatch_size = 64\n\ntrain_generator = train_datagen.flow_from_dataframe(train_labels,directory=train,x_col='id',\n                                                    y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                                    target_size=(150,150))\nval_generator = train_datagen.flow_from_dataframe(val_labels,directory=train,x_col='id',\n                                                    y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                                    target_size=(150,150))","4261a733":"base_model = tf.keras.applications.InceptionV3(input_shape=(150,150,3),include_top=False,weights=\"imagenet\")","799ba3aa":"# Freezing Layers\n\nfor layer in base_model.layers[:-10]:\n    layer.trainable=False","7e18bbc7":"model=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","9d649644":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\nImage(filename='convnet.png')","01bb756a":"def f1_score(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)\/(precision+recall+K.epsilon())\n    return f1_val","00f9c270":"METRICS = [\n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),  \n      tf.keras.metrics.AUC(name='auc'),\n        f1_score,\n]","fd0ef11f":"lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 3,verbose = 1,factor = 0.50, min_lr = 1e-6)\n\nmcp = ModelCheckpoint('model.h5')\n\nes = EarlyStopping(verbose=1, patience=3)","ed0d8d19":"model.compile(optimizer='Adam', loss = keras.losses.binary_crossentropy,metrics=METRICS)","c7f80c39":"%time\nhistory=model.fit(train_generator,validation_data=val_generator,epochs = 10,verbose = 1,callbacks=[lrd,mcp,es])","88591688":"# Use trained model to make predication on test data\n\ntest_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1\/255)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory = test,\n    target_size = (150,150),\n    batch_size = 1,\n    class_mode = None,\n    shuffle = False)\n\nodds = model.predict(test_generator)","92a31324":"# Create submission file\n\nsubmission = pd.read_csv('..\/input\/aerial-cactus-identification\/sample_submission.csv')\ndf = pd.DataFrame({'id': submission['id']})\ndf['has_cactus'] = odds\ndf.to_csv(\"submission.csv\", index=False)","566234a6":"\n<h1 style='background-color:Green; font-family:newtimeroman; font-size:180%; text-align:center; border-radius: 15px 50px;' > Aerial Cactus Identification <\/h1>\n\n### Data Description\nThis dataset contains a large number of 32 x 32 thumbnail images containing aerial photos of a columnar cactus (Neobuxbaumia tetetzo). Kaggle has resized the images from the original dataset to make them uniform in size. The file name of an image corresponds to its id.\n\n\nYou must create a classifier capable of predicting whether an images contains a cactus.\n\n\n\n\n\n<img src=\"https:\/\/miro.medium.com\/max\/1000\/0*vyjWB63YjS-qZyGC\" width=\"800px\">\n\n\n\n\n### Files\n* train\/ - the training set images\n* test\/ - the test set images (you must predict the labels of these)\n* train.csv - the training set labels, indicates whether the image has a cactus (has_cactus = 1)\n* sample_submission.csv - a sample submission file in the correct format\n\n\n#### Dataset Link\n\n##### [Here](https:\/\/www.kaggle.com\/c\/aerial-cactus-identification\/data)","c0d8f314":"\n<h1 style='background-color:Green; font-family:newtimeroman; font-size:180%; text-align:center; border-radius: 15px 50px;' >What is Inception v3 model? <\/h1>\n\n##### Inception v3 is a widely-used image recognition model that has been shown to attain greater than 78.1% accuracy on the ImageNet dataset. The model is the culmination of many ideas developed by multiple researchers over the years.\n\n<img src=\"https:\/\/www.researchgate.net\/profile\/Masoud-Mahdianpari\/publication\/326421398\/figure\/fig6\/AS:649353890889730@1531829440919\/Schematic-diagram-of-InceptionV3-model-compressed-view.png\" width=\"800px\">\n\n"}}