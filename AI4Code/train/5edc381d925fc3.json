{"cell_type":{"e3967c4b":"code","19cf7e8e":"code","8545c3a3":"code","fecc99e4":"code","8e0a2d85":"code","8e3befca":"code","b977c58d":"code","e3147fae":"code","4b61fa23":"code","a59c8b14":"code","fd3032bf":"code","95d4d7bc":"code","ebb3e213":"code","5ff1cfd6":"code","1d97a35c":"code","ff762f37":"code","25de629a":"code","009679ab":"code","bfaf7306":"code","1883839e":"code","2888f3a4":"code","d9ee6401":"code","b74ec7c2":"code","9980251b":"code","4e498686":"code","859cc4be":"markdown","f0907fcf":"markdown","bafbaea5":"markdown","c7ad6c68":"markdown","c2dc22b6":"markdown","ca855b69":"markdown","67caad8e":"markdown","eea5fc6f":"markdown","cdaa3a6a":"markdown","aa0ae802":"markdown","70b5a000":"markdown","3021a83b":"markdown","a294410c":"markdown","96a931a8":"markdown"},"source":{"e3967c4b":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras import Sequential,layers,models\nimport pathlib\nimport PIL\nimport numpy as np\nimport matplotlib.pyplot as plt \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image_dataset_from_directory","19cf7e8e":"folder='..\/input\/flowers-recognition\/flowers\/flowers'","8545c3a3":"import os\nclasses=[]\nfor i in os.listdir(folder):\n    classes.append(i)","fecc99e4":"classes","8e0a2d85":"folder_path=pathlib.Path(folder)\nimages=list(folder_path.glob('*\/*'))\nlen(images)\n","8e3befca":"roses=list(folder_path.glob('rose*\/*'))\nlen(roses)","b977c58d":"PIL.Image.open(roses[5])","e3147fae":"train_ds=image_dataset_from_directory(folder_path,validation_split=0.2,batch_size=32,subset='training',image_size=(180,180),seed=123)","4b61fa23":"for images,labels in train_ds.take(1):\n    first_set=images\n    print(type(images))\nfirst_set.shape","a59c8b14":"target=train_ds.class_names\ntarget","fd3032bf":"validation_ds=image_dataset_from_directory(folder_path,validation_split=0.2,seed=123,batch_size=32,image_size=(180,180),subset='validation')","95d4d7bc":"plt.figure(figsize=(12,10))\nfor i in range(20):\n    plt.subplot(4,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(first_set[i].numpy().astype('uint8'))\n    plt.xlabel(target[labels[i]])\nplt.show()","ebb3e213":"model=Sequential()","5ff1cfd6":"model.add(layers.experimental.preprocessing.Rescaling(1.\/255,input_shape=(180,180,3)))\nmodel.add(layers.Conv2D(filters=32,kernel_size=(3,3),padding='same',activation='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(layers.Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(layers.Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))","1d97a35c":"model.summary()","ff762f37":"model.add(layers.Flatten())\nmodel.add(layers.Dense(units=80,activation='relu'))\nmodel.add(layers.Dense(units=len(target),activation='softmax'))\nmodel.summary()","25de629a":"model.compile(optimizer='adam',loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])","009679ab":"result=model.fit(train_ds,validation_data=validation_ds,epochs=10)","bfaf7306":"plt.figure(figsize=(8,6))\nplt.subplot(1,2,1)\nplt.plot(result.history['accuracy'],label='training')\nplt.plot(result.history['val_accuracy'],label='validation')\nplt.xlabel('Accuracy')\n\nplt.subplot(1,2,2)\nplt.plot(result.history['loss'],label='training')\nplt.plot(result.history['val_loss'],label='validation')\nplt.xlabel('Loss')\n\nplt.show()","1883839e":"data_augmentation=Sequential([\n    layers.experimental.preprocessing.RandomFlip('horizontal',input_shape=(180,180,3)),\n    layers.experimental.preprocessing.RandomFlip('vertical',input_shape=(180,180,3)),\n    layers.experimental.preprocessing.RandomZoom(0.3),\n    layers.experimental.preprocessing.RandomRotation(0.4)\n])","2888f3a4":"model=models.Sequential([\n                         data_augmentation,\n                         layers.experimental.preprocessing.Rescaling(1.\/255),\n                         layers.Conv2D(filters=32,kernel_size=(3,3),padding='same',activation='relu'),\n                         layers.MaxPool2D(pool_size=(2,2)),\n                         layers.Dropout(0.2),\n                         layers.Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu'),\n                         layers.MaxPool2D(pool_size=(2,2)),\n                         layers.Dropout(0.3),\n                         layers.Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu'),\n                         layers.MaxPool2D(pool_size=(2,2)),\n                         layers.Dropout(0.2),\n                         layers.Flatten(),\n                         layers.Dense(units=128,activation='relu'),\n                         layers.Dense(units=80,activation='relu'),\n                         layers.Dense(units=5,activation='softmax')\n])","d9ee6401":"model.summary()","b74ec7c2":"model.compile(optimizer='adam',loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])","9980251b":"result=model.fit(train_ds,validation_data=validation_ds,epochs=10)","4e498686":"plt.figure(figsize=(8,6))\nplt.subplot(1,2,1)\nplt.plot(result.history['accuracy'],label='training')\nplt.plot(result.history['val_accuracy'],label='validation')\nplt.xlabel('Accuracy')\n\nplt.subplot(1,2,2)\nplt.plot(result.history['loss'],label='training')\nplt.plot(result.history['val_loss'],label='validation')\nplt.xlabel('Loss')\n\nplt.show()","859cc4be":"### Now the Model is working perfetly","f0907fcf":"### Plotting few images from the training dataset","bafbaea5":"# Understanding the Dataset","c7ad6c68":"### Dropout\n\n#### Another technique to reduce overfitting is to introduce Dropout to the network, a form of regularization.\n\n#### When you apply Dropout to a layer it randomly drops out (by setting the activation to zero) a number of output units from the layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n\n#### Let's create a new neural network using layers.Dropout, then train it using augmented images.","c2dc22b6":"### Data Augmentation\n\n#### Overfitting generally occurs when there are a small number of training examples. Data augmentation takes the approach of generating additional training data from your existing examples by augmenting them using random transformations that yield believable-looking images. This helps expose the model to more aspects of the data and generalize better.","ca855b69":"### Total number of rose images","67caad8e":"# Creating the model\n\n### 1.First will add one layer to rescale the values of the pixels between 0 to 1\n### 2.Then will start adding convolution layer and pooling layers\n### 3.Next will add one Flatten layer\n### 4.Finally will create one fully connected layer","eea5fc6f":"### Total number of images in the folder","cdaa3a6a":"#### In the plots above, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 60% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable\u2014a sign of overfitting.\n\n#### There are multiple ways to fight overfitting in the training process. In this tutorial, you'll use data augmentation and add Dropout to your model.","aa0ae802":"# Visualization","70b5a000":"### Plotting a rose image","3021a83b":"### Target Class names ","a294410c":"# Converting the Images into DataSets","96a931a8":"# Importing Libraries"}}