{"cell_type":{"33fb9fb1":"code","1ba30c82":"code","47ffe492":"code","c74a4892":"code","35757aa7":"code","4fcfa4e8":"code","4fe3ed2f":"code","445e40de":"code","36ab68e9":"code","4eb11968":"code","6416a1c6":"code","bc670fed":"code","954b01cd":"code","9e31eeb4":"code","448e882a":"code","7572052d":"code","fee885bc":"code","c14ac5fa":"code","73047baf":"code","e12e2da1":"code","baae23f4":"code","5d534f78":"code","f1c98015":"code","ba79851c":"code","ed105db1":"code","25d96004":"code","c86f8c24":"code","7c48be9e":"code","0752e1d8":"code","82d4b9b3":"code","15520a99":"code","6d8f833f":"code","e4999445":"code","69c77c29":"code","5b449227":"markdown"},"source":{"33fb9fb1":"import re\nimport gc\nimport os\nimport cv2\nimport glob\nimport keras\nimport shutil\nimport pathlib\nimport PIL\nimport numpy as np\nimport pandas as pd\nimport seaborn as sb\nimport networkx as nx\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom shutil import copyfile\nimport tensorboard\nfrom datetime import datetime\nfrom packaging import version\nfrom tensorflow import keras as ks\nfrom tensorflow.keras import datasets, layers, models\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import imread, imshow, imsave, imread_collection\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import img_to_array, array_to_img\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","1ba30c82":"# Show versions\nprint('TensorFlow Version: {}'.format(tf.__version__))\nprint('Eager execution: {}'.format(tf.executing_eagerly()))\nprint('OpenCV Version:{}'.format(cv2.__version__))\nprint('Keras Version:{}'.format(ks.__version__))\nprint('Numpy Version:{}'.format(np.__version__))\nprint('Pandas Version:{}'.format(pd.__version__))","47ffe492":"# Settings\nepochs = 10\nimg_height = 312\nimg_width = 312\nbatch_size = 64","c74a4892":"# Check if GPU is ready\nprint(tf.test.is_gpu_available())","35757aa7":"# Check the number of GPU's that are ready\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","4fcfa4e8":"# Read in CSV\ntrain=pd.read_csv(\"..\/input\/plant-pathology-2020-fgvc7\/train.csv\")\nprint(train)","4fe3ed2f":"train.shape","445e40de":"train.describe()","36ab68e9":"# Read in CSV\ntest=pd.read_csv(\"..\/input\/plant-pathology-2020-fgvc7\/test.csv\")\nprint(test)","4eb11968":"# Read in CSV\nsample_submission=\"..\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv\"\nsubmission=pd.read_csv(sample_submission)","6416a1c6":"# Create training folder \npathto=\".\/Train\/\"\nshutil.os.mkdir(pathto)","bc670fed":"# Create testing folder\npathto=\".\/Test\/\"\nshutil.os.mkdir(pathto)","954b01cd":"# Split images based on name\nfor path in glob.iglob(r'..\/input\/plant-pathology-2020-fgvc7\/images\/*.jpg'):\n    match = re.search(r'\\bTest_',path)\n    if match:\n        shutil.copy(path, \".\/Test\")\n        print(\"Sent to test folder -\",path)\n    else:\n        shutil.copy(path, \".\/Train\")\n        print(\"Sent to train folder -\",path)","9e31eeb4":"# Grab a sample image\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/'):\n    for filename in filenames[1:2]:\n        picture = imread('..\/input\/plant-pathology-2020-fgvc7\/images\/'+filename)\n        plt.figure(figsize=(20, 15))\n        plt.title(filename)\n        plt.grid()\n        plt.ylabel('Height {}'.format(picture.shape[0]))\n        plt.xlabel('Width {}'.format(picture.shape[1]))\n        plt.imshow(picture);","448e882a":"# View all images\ncol_dir = '..\/input\/plant-pathology-2020-fgvc7\/images\/*.jpg'\nimages = imread_collection(col_dir)\nfig, axes = plt.subplots(nrows=5, ncols=5, figsize=(20,20))\n\nfor i, image in enumerate(images):\n    if (i == 25) : break\n    row = i \/\/ 5\n    col = i % 5\n    axes[row, col].axis(\"off\")\n    axes[row, col].imshow(image, aspect=\"auto\")\nplt.subplots_adjust(wspace=.05, hspace=.05)","7572052d":"# View all training images\ncol_dir = '.\/Train\/*.jpg'\nimages = imread_collection(col_dir)\nfig, axes = plt.subplots(nrows=5, ncols=5, figsize=(20,20))\n\nfor i, image in enumerate(images):\n    if (i == 25) : break\n    row = i \/\/ 5\n    col = i % 5\n    axes[row, col].imshow(image, aspect=\"auto\")\nplt.subplots_adjust(wspace=0.3, hspace=0.3)","fee885bc":"# View all testing images\ncol_dir = '.\/Test\/*.jpg'\nimages = imread_collection(col_dir)\nfig, axes = plt.subplots(nrows=5, ncols=5, figsize=(20,20))\n\nfor i, image in enumerate(images):\n    if (i == 25) : break\n    row = i \/\/ 5\n    col = i % 5\n    axes[row, col].imshow(image, aspect=\"auto\")\nplt.subplots_adjust(wspace=0.3, hspace=0.3)","c14ac5fa":"# View all images as negatives\ncol_dir = '..\/input\/plant-pathology-2020-fgvc7\/images\/*.jpg'\nimages = imread_collection(col_dir)\nfig, axes = plt.subplots(nrows=5, ncols=5, figsize=(20,20))\n\nfor i, image in enumerate(images):\n    if (i == 25) : break\n    row = i \/\/ 5\n    col = i % 5\n    negative = 255 - image\n    axes[row, col].imshow(negative, aspect=\"auto\")\nplt.subplots_adjust(wspace=0.3, hspace=0.3)","73047baf":"next(train.iterrows())[1]","e12e2da1":"# Row data in pandas are returned as a series\nfor index, row in train.head(n=5).iterrows():\n    print(index,row)","baae23f4":"# Row data in pandas are returned as a series\nfor index2, row2 in test.head(n=5).iterrows():\n    print(index2,row2)","5d534f78":"# Append filetype to each image\nfor i in tqdm(range(train.shape[0])):\n    img=(train['image_id'])\nadd = img.astype(str)+\".jpg\"\ntrain['image_id'] = add ","f1c98015":"image_id=add\nimage_id.unique()","ba79851c":"# Append filetype to each image\nfor i in tqdm(range(test.shape[0])):\n    img=(test['image_id'][:])\nadd = img.astype(str)+\".jpg\"\ntest['image_id'] = add","ed105db1":"image_id=test['image_id']\nimage_id.unique()","25d96004":"# Classification labels\ncolumn_names=[\"healthy\",\"multiple_diseases\",\"rust\",\"scab\"]\n\n# Assign each image a condition\nhealthy=(1,0,0,0)\nmultiple_diseases = (0,1,0,0)\nrust=(0,0,1,0)\nscab=(0,0,0,1)\n\n# Count the amount of conditions\nhealth_count=0\nmd_count=0\nrust_count=0\nscab_count=0\n\nfor index, row in train.iterrows():\n    condition=index, row['image_id'],row['healthy'],row['multiple_diseases'],row['rust'],row['scab']\n    if condition[2:6]==healthy:\n        health_count+=1\n        print(condition[1]+\"- This leaf is healthy:\",healthy)\n    if condition[2:6]==multiple_diseases:\n        md_count+=1\n        print(condition[1]+\"- This leaf has multiple diseases:\",multiple_diseases)\n    if condition[2:6]==rust:\n        rust_count+=1\n        print(condition[1]+\"- This leaf has rust:\",rust)       \n    if condition[2:6]==scab:\n        scab_count+=1\n        print(condition[1]+\"- This leaf has a scab:\",scab)","c86f8c24":"# Display the amount of conditions for each category\nprint(\"The amount of healthy leaves:\",health_count)\nprint(\"The amount of multiple diseased leaves:\",md_count)\nprint(\"The amount of rust leaves:\",rust_count)\nprint(\"The amount of scab leaves:\",scab_count)","7c48be9e":"# Display the total amount\namount = health_count+md_count+rust_count+scab_count\nprint(\"Total amount of conditions:\",amount)","0752e1d8":"# ImageGenerator\n# https:\/\/keras.io\/preprocessing\/image\/\ndatagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=45,\n      zca_whitening=False,\n      zca_epsilon=1e-06,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      brightness_range=(0.1,1.0),\n      channel_shift_range=5.0,\n      shear_range=0.2,\n      validation_split=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      vertical_flip=True,\n      fill_mode='nearest')\n\ntest_datagen=ImageDataGenerator(rescale=1.\/255)\n\ntrain_image_generator=datagen.flow_from_dataframe(\n    dataframe=train[:1460],\n    directory='..\/input\/plant-pathology-2020-fgvc7\/images\/',\n    x_col=\"image_id\",\n    y_col=column_names,\n    batch_size=batch_size,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\",\n    target_size=(img_height,img_width))\n\nvalid_image_generator=test_datagen.flow_from_dataframe(\n    dataframe=train[1460:],\n    directory='..\/input\/plant-pathology-2020-fgvc7\/images\/',\n    x_col=\"image_id\",\n    y_col=column_names,\n    batch_size=batch_size,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\",\n    target_size=(img_height,img_width))\n\ntest_image_generator=test_datagen.flow_from_dataframe(\n    dataframe=test[:],\n    directory='..\/input\/plant-pathology-2020-fgvc7\/images\/',\n    x_col=\"image_id\",\n    batch_size=1,\n    seed=42,\n    shuffle=False,\n    class_mode=None,\n    target_size=(img_height,img_width))","82d4b9b3":"# Apply two dimensional convolutional layer over images that is convolved with the current layer to produce tensor outputs\nmodel=keras.Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(img_height,img_width,3)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4, activation='softmax'))\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])","15520a99":"# Display model\nmodel.summary()","6d8f833f":"%%time\nhistory=model.fit_generator(generator=train_image_generator,\n                            validation_data=valid_image_generator,\n                            epochs=epochs)","e4999445":"# https:\/\/www.tensorflow.org\/tutorials\/images\/classification?hl=da\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(20, 10))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","69c77c29":"# Reset CNN\ntest_image_generator.reset()\nprediction=model.predict_generator(test_image_generator,verbose=1)\n\n# Submit Submission\nsubmission.loc[:, 'healthy':] = prediction\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","5b449227":"# \ud83c\udf31\ud83c\udf4e Beginner Plant Pathology EDA w\/Keras\n\n\n\n***Problem Statement:*** Misdiagnosis of the many diseases impacting agricultural crops can lead to misuse of chemicals leading to the emergence of resistant pathogen strains, increased input costs, and more outbreaks with significant economic loss and environmental impacts. Current disease diagnosis based on human scouting is time-consuming and expensive, and although computer-vision based models have the promise to increase efficiency, the great variance in symptoms due to age of infected tissues, genetic variations, and light conditions within trees decreases the accuracy of detection.\nSpecific Objectives\n\nObjectives of \u2018Plant Pathology Challenge\u2019 are to train a model using images of training dataset to 1) Accurately classify a given image from testing dataset into different diseased category or a healthy leaf; 2) Accurately distinguish between many diseases, sometimes more than one on a single leaf; 3) Deal with rare classes and novel symptoms; 4) Address depth perception\u2014angle, light, shade, physiological age of the leaf; and 5) Incorporate expert knowledge in identification, annotation, quantification, and guiding computer vision to search for relevant features during learning.\n\nPlease upvote and share \u2764\ufe0f\n\nBooks: \n* Pandas 1.x Cookbook by Matt Harrison and Theodore Petrou\n* Practical Computer Vision: Extract Insightful Information from Images Using TensorFlow, Keras, and OpenCV by Abhinav Dadhich"}}