{"cell_type":{"ad070a5e":"code","3d86ee38":"code","56732b48":"code","f3e74b46":"code","1155f4a6":"code","f4c8d772":"code","c6b021b7":"code","9b3011e0":"code","b6172526":"code","da23a8ea":"code","1daf29e1":"code","57311f80":"code","1edd9f88":"code","802421ad":"code","e1bf4e6d":"code","3e9fb45a":"markdown","b7fd8f65":"markdown","3602755d":"markdown","eb78270a":"markdown","a214bd5c":"markdown","fd68fa5f":"markdown","eca713be":"markdown"},"source":{"ad070a5e":"!pip install transformers","3d86ee38":"import pandas as pd\nimport numpy as np\nfrom transformers import TrainingArguments, Trainer","56732b48":"train=pd.read_csv('..\/input\/qa-intents-dataset-university-domain\/dataset_train.tsv',delimiter='\\t',encoding=\"utf-8\",names=['text', 'intent'])\ntest =pd.read_csv('..\/input\/qa-intents-dataset-university-domain\/dataset_test.tsv',delimiter='\\t',encoding=\"utf-8\",names=['text', 'intent'])\ndata = result = pd.concat([train,test])\nNUM_LABELS=len(set(data['intent']))\nlabels=set(data['intent'])\nid2label = {i:label for i,label in enumerate(labels) if label != None}\nlabel2id = {label:i for i,label in enumerate(labels) if label != None}\nprint(data['intent'].value_counts())\nprint('examples:\\n',data['text'].iloc[2]+'\\n'+data['text'].iloc[929]+'\\n'+data['text'].iloc[24]+'\\n'+data['text'].iloc[1224])","f3e74b46":"from transformers import AutoTokenizer,AutoModelForSequenceClassification\nMODEL_NAME = 'DeepPavlov\/rubert-base-cased-sentence'\nN_MODELS = 3\ntokenizers = []\nmodels = []\nfor i in range(N_MODELS):\n    tokenizers.append(AutoTokenizer.from_pretrained(MODEL_NAME))\n    models.append(AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,label2id=label2id,id2label=id2label,num_labels =NUM_LABELS))","1155f4a6":"tokenizer = AutoTokenizer.from_pretrained('DeepPavlov\/rubert-base-cased-sentence')\n\ndef make_dataset(df):\n    labels = [label2id[label] for label in df['intent']]\n    texts = [tokenizer(text,padding='max_length', max_length = 32, truncation=True) for text in df['text']]\n    \n    result = []\n    for idx,(text,label) in enumerate(zip(texts,labels)):\n        result.append({\"input_ids\" : text['input_ids'], 'attention_mask' : text['attention_mask'], \"label\" : label})\n    return result\n\ntrain_dataset = make_dataset(train)\ntest_dataset = make_dataset(test)","f4c8d772":"train_dataset[0]","c6b021b7":"from sklearn.metrics import accuracy_score\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return {'accuracy' : accuracy_score(predictions, labels)}","9b3011e0":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\nfor model in models:\n    args = TrainingArguments(\n    \"test-glue\",\n    evaluation_strategy = \"steps\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=5,\n    weight_decay=0.05,\n    load_best_model_at_end=False,\n    report_to=None,\n    metric_for_best_model = 'accuracy'\n    )\n    trainer = Trainer(\n    model,\n    args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n    )\n    trainer.train()","b6172526":"class ClassifierLanguageModel():\n\tdef __init__(self, model,tokenizer):\n\t\tself.model = model\n\t\tself.tokenizer = tokenizer\n\n\tdef run(self, text):\n\t\tmodel_input = self.tokenizer.encode(text, return_tensors='pt').cuda()\n\t\tmodel_output = self.model.bert.config.id2label[self.model(model_input)['logits'].argmax().item()]\n\t\treturn model_output\n\nclass Ensemble():\n    def __init__(self,predictors):\n        self.predictors = predictors\n            \n    def run(self,string):\n        predictions = []\n        for predictor in self.predictors:\n            predictions.append(predictor.run(string))\n        counter = {}\n        for p_i in predictions:\n            if p_i not in counter.keys():\n                counter[p_i] = 0\n            counter[p_i] += 1\n        \n        # check what is the majority have voted for\n        for key in counter.keys():\n            if counter[key] > 0.5*len(predictions):\n                return key\n            \n        return 'out_of_class'","da23a8ea":"predictors = []\nfor model, tokenizer in zip(models,tokenizers):\n    predictors.append(ClassifierLanguageModel(model,tokenizer))\nensemble = Ensemble(predictors)","1daf29e1":"reference = []\npredictions = []\nfor text,label in zip(test['text'],test['intent']):\n    output = ensemble.run(text)\n    predictions.append(output)\n    reference.append(label)","57311f80":"reference[:10]","1edd9f88":"predictions[:10]","802421ad":"from sklearn.metrics import f1_score\n\nfor average_type in ['macro','micro','weighted']:\n    print(f'{average_type} F1 = {f1_score(reference, predictions, average=average_type)}')","e1bf4e6d":"test = [['\u0433\u0434\u0435 \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u0433\u0443\u043b\u044f\u0442\u044c \u0432 \u0410\u043a\u0430\u0434\u0435\u043c\u0433\u043e\u0440\u043e\u0434\u043a\u0435?','loc_walk']\\\n        ,['\u0433\u0434\u0435 \u043d\u0435\u0434\u043e\u0440\u043e\u0433\u043e \u043f\u043e\u0435\u0441\u0442\u044c \u043d\u0430 3 \u044d\u0442\u0430\u0436\u0435 \u043d\u043e\u0432\u043e\u0433\u043e \u043a\u043e\u0440\u043f\u0443\u0441\u0430?','loc_cafeteria_new_building_3_etage'],\\\n        ['\u043a\u0430\u043a \u043f\u043e\u043c\u0435\u043d\u044f\u0442\u044c \u043a\u043e\u043b\u0435\u0441\u043e \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0434\u043e\u043c\u043a\u0440\u0430\u0442\u0430?','out_of_classes']] # offtopic question\n\nfor phrase in test:\n    label = ensemble.run(phrase[0])\n    print(label,phrase[1])","3e9fb45a":"# TRAIN MODELS","b7fd8f65":"# TESTING\n\ncompute f1 metric","3602755d":"check that the ensemble is able to handle offtopic questions ","eb78270a":"# MAKE ENSEMBLE","a214bd5c":"# GET MODELS AND TOKENIZERS\n\nI am going to use an ensemble of models to handle situations where it needs to refuse prediction (out of classes)","fd68fa5f":"# EXPLORE DATA","eca713be":"# PREPARE DATASETS"}}