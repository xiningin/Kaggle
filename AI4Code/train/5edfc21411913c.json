{"cell_type":{"0d02430a":"code","fd08b974":"code","da43646e":"code","7ea0a3d9":"code","eb34ebb9":"code","d70cdc31":"code","6cbcb5af":"code","fbb0346f":"code","a7ec396a":"code","29dfa07e":"code","32717f63":"code","e622731f":"markdown","6ae42382":"markdown","55999982":"markdown","3035cf6d":"markdown","50d24eae":"markdown","58b8b388":"markdown","487331fc":"markdown"},"source":{"0d02430a":"import pandas as pd\nimport numpy as np\n\ndef get_train(howManyLines):\n    train = pd.read_csv(\"..\/input\/train.csv\", nrows=howManyLines)\n    print(\"Rows read: \", howManyLines)\n    print(\"Insincere ratio: \", np.mean(train.target))\n    return train\n    \ntrain = get_train(10000)","fd08b974":"def get_coefs(word,*arr): \n    return word, np.asarray(arr, dtype='float32')\n\ndef get_embedding(embeddingFile):\n    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(embeddingFile))\n    print(\"Loaded keys: \", len(set(embeddings_index.keys())))\n    return embeddings_index\n\nembeddings_index = get_embedding('..\/input\/embeddings\/glove.840B.300d\/glove.840B.300d.txt')\nembedding_size = len(embeddings_index[\"The\"])","da43646e":"def get_sentences_list(questions):\n    return [[j for j in i\\\n             .replace(\"?\", \" ? \")\\\n             .replace(\"\u2026\", \" \u2026 \")\\\n             .replace(\"\/\", \" \/ \")\\\n             .replace(\":\", \" : \")\\\n             .replace(\",\", \" , \")\\\n             .replace(\"(\", \" ( \")\\\n             .replace(\")\", \" ) \")\\\n             .replace(\"%\", \" % \")\\\n             .replace(\"$\", \" $ \")\\\n             .replace(\"'s\", \" 's \")\\\n             .replace(\"\u2019s\", \" \u2019s \")\\\n             .replace(\"!!!\", \" !!! \")\\\n             .replace(\"I\u2019m\", \" I'm \")\\\n             .replace('\"The', \" The \")\\\n             .replace('don\u2019t', \" con't \")\\\n             .replace(\"What's\", \" What is \")\\\n             .replace(\" so, \", \" so , \")\\\n             .replace(\" you've \", \" you have \")\\\n             .replace(\" aren't \", \" are not \")\\\n             .replace(\" won't \", \" will not \")\\\n             .replace(\" me, \", \" me , \")\\\n             .replace(\" Isn't \", \" Is not \")\\\n             .replace(\" they're \", \" they are \")\\\n             .replace(\"haven't\", ' have not ')\\\n             .replace(\"can\u2019t\", \" can't \")\\\n             .replace(\"isn't\", \" is not \")\\\n             .replace(\"con't\", \" can't \")\\\n             .replace(\"India,\", \" India , \")\\\n             .replace(\"win,\", \" win , \")\\\n             .replace(\"life,\", \" life , \")\\\n             .replace(\"time,\", \" time , \")\\\n             .replace(\"better,\", \" better , \")\\\n             .replace(\"math]\", \" math ] \")\\\n             .replace(\"people,\", \" people, \")\\\n             .replace('doesn\u2019t', \" doesn't \")\\\n             .replace(\"shouldn't\", \" should not \")\\\n             .replace(\"them,\", \" them , \")\\\n             .replace('\"I', ' \" I ')\\\n             .replace(\"shouldn't\", \" should not \")\\\n             .replace(\"shouldn't\", \" should not \")\\\n             .replace(\"Isn't\", \" Is not \")\\\n             .replace(\"years,\", \" years , \")\\\n             .replace(\"wasn't\", \" was not \")\\\n             .replace(\"couldn't\", \" could not \")\\\n             .replace(\"wouldn't\", \" would not \")\\\n             .replace(\"Quora,\", \" Quora , \")\\\n             .replace(\"I\u2019ve\", \" I've \")\\\n             .replace(\"world,\", \" world , \")\\\n             .replace(\"now,\", \" now , \")\\\n             .replace(\"US,\", \" US , \")\\\n             .replace(\"country,\", \" country , \")\\\n             .replace(\"person,\", \" person , \")\\\n             .replace('you\u2019ve', \" you have \")\\\n             .replace('didn\u2019t', \" didn't \")\\\n             .replace('do,', \" do , \")\\\n             .replace('fight,', \" fight , \")\\\n             .replace('day,', \" day , \")\\\n             .replace('\"the', ' \" the ')\\\n             .replace('school,', ' school , ')\\\n             .replace('China,', ' China , ')\\\n             .replace(\"Shouldn't\", \" Should not \")\\\n             .replace(\"Trump,\", \" Trump , \")\\\n             .replace(\"year,\", \" year , \")\\\n             .replace(\"him,\", \" him , \")\\\n             .replace(\"Also,\", \" Also , \")\\\n             .replace(\"isn\u2019t\", \" is not \")\\\n             .replace(\"work,\", \" work , \")\\\n             .replace(\"today,\", \" today , \")\\\n             .replace(\"that,\", \" that , \")\\\n             .replace(\"Wouldn't\", \" Would not \")\\\n             .replace(\"Aren't\", \" Are not \")\\\n             .replace(\"Doesn't\", \" Does not \")\\\n             .replace(\"money,\", \" money , \")\\\n             .replace(\"ago,\", \" ago , \")\\\n             .replace(\"say,\", \" say , \")\\\n             .replace(\"is,\", \" is , \")\\\n             .replace(\"(if\", \" ( if \")\\\n             .replace(\"up,\", \" up , \")\\\n             .replace(\"we're\", \" we are \")\\\n             .replace(\"Can't\", \" Can not \")\\\n             .replace(\"weren't\", \" were not \")\\\n             .replace('won\u2019t', ' will not ')\\\n             .replace(\"aren\u2019t\", \" are not \")\\\n             .replace(\"2017.\", \" 2017 . \")\\\n             .replace('Quorans', ' Quoran ')\\\n             .replace(\"hasn't\", ' has not ')\\\n             .replace(\"cryptocurrencies\", ' cryptocurrency ')\\\n             .replace(\"Brexit\", ' British exit ')\\\n             .replace(\"Redmi\", \"Xiaomi \")\\\n             .replace(\"they\u2019re\", \" they are \")\\\n             .replace(\"you\u2019re\", \" you're \")\\\n             .replace(\"they've\", \" they have\")\\\n             .replace('\"', ' \" ')\\\n             .replace('C#', ' C++ ')\\\n             .replace('Isn\u2019t', ' Is not ')\\\n             .replace('haven\u2019t', ' have not ')\\\n             .replace(\"'The\", \" ' The \")\\\n             .replace(\"they've\", \" they have\")\\\n             .replace('\"', ' \" ')\\\n             .replace('Isn\u2019t', ' Is not ')\\\n             .replace('haven\u2019t', ' have not ')\\\n             .replace(\"'The\", \" ' The \")\\\n             .replace(\"hadn't\", \" had not \")\\\n             .replace(\"2018.\", \" 2018 . \")\\\n             .replace(\"^2\", \" squared \")\\\n             .replace(\"OnePlus\", \" Chinese Smartphone \")\\\n             .replace('\"what', ' \" what')\\\n             .replace('UCEED', ' CEED ')\\\n             .replace('engineering.', ' engineering .')\\\n             .replace('wouldn\u2019t', ' would not ')\\\n             .replace(\"We're\", \"We are\")\\\n             .replace('it\"', ' it \" ')\\\n             .replace(\"wasn\u2019t\", \"was not\")\\\n             .replace(\"GDPR\", \" General Data Protection Regulation \")\\\n             .replace(\"we've\", \" we have \")\\\n             .replace(\"Blockchain\", \" blockchain \")\\\n             .replace('\"Why', ' \" Why ')\\\n             .replace('Coinbase', ' cryptocurrency ')\\\n             .replace('shouldn\u2019t', ' should not ')\\\n             .replace('Adityanath', ' yogi ')\\\n             .replace('Don\u2019t', \" Don't \")\\\n             .replace('Machedo', \" Strategist Influencer \")\\\n             .replace('BNBR', \" Be Nice, Be Respectful \")\\\n             .replace(\"'I\", \" ' I \")\\\n             .replace(\"'the\", \" ' the \")\\\n             .replace('\u201cThe', ' \" The ')\\\n             .replace('Boruto', ' Naruto ')\\\n             .replace('\"You', ' \" You ')\\\n             .replace(\"would've\", \" would have \")\\\n             .replace(\"You're\", \" You are \")\\\n             .replace(\"ethereum\", \" cryptocurrency \")\\\n             .replace(\"ethereum\", \" cryptocurrency \")\\\n             .replace(\"DCEU\", \" DC Extended Universe \")\\\n             .replace('\"in', ' \" in ')\\\n             .replace('\u201cI', ' \" I')\\\n             .replace('\"to\"', ' \" to')\\\n             .replace('IIEST', \"Indian Institute of Engineering Science and Technology\")\\\n             .replace('couldn\u2019t', ' could not')\\\n             .replace(\"they'll\", \" they will \")\\\n             .replace(\"Wasn't\", \" Was not \")\\\n             .replace('\"My', ' \" My')\\\n             .replace('Qoura', ' Quora ')\\\n             .replace('up\"', ' up \" ')\\\n             .replace('10+2', ' 10 + 2 ')\\\n             .replace('\"no', ' \" no ')\\\n             .replace(\"parents'\", \" parents 's \")\\\n             .replace(\"SJWs\", \" SJW \")\\\n             .replace('life\"', ' life \" ')\\\n             .replace('\\\\frac\"', ' fraction ')\\\n             .replace('\"not', ' not ')\\\n             .replace(\"Qur'an\", \"Quran\")\\\n             .replace('\"When', ' \" When ')\\\n             .replace('people\"', ' people \" ')\\\n             .replace('depression.', ' depression . ')\\\n             .replace('..', ' ... ')\\\n             .replace('x+1', ' x + 1 ')\\\n             .replace('we\u2019re', ' we are ')\\\n             .replace('\"good', ' \" good ')\\\n             .replace('Trump.', ' Trump . ')\\\n             .replace('to\"', ' to \" ')\\\n             .replace(\"he'll\", \" he will \")\\\n             .replace('time\"', ' time \"')\\\n             .replace('\"No', ' \" No')\\\n             .replace('10+', ' 10 +')\\\n             .replace('LNMIIT', ' Institute Of Information Technology ')\\\n             .replace(\"Won't\", ' Will not ')\\\n             .replace(\"Upwork\", ' Freelancing Platform ')\\\n             .replace('out\"', ' out \" ')\\\n             .replace(\"We've\", ' We have ')\\\n             .replace('\"We', ' \" We ')\\\n             .replace('anti-Trump', ' anti Trump ')\\\n             .replace('Kavalireddi', ' Market Expert ')\\\n             .replace('C#', ' dot net ')\\\n             .replace('.net', ' dot net ')\\\n             .replace('.NET', ' dot net ')\\\n             .replace('\"This', ' \" This ')\\\n             .replace('I\u2019ll', \"I'll\")\\\n             .replace('Zerodha', \" discount broker \")\\\n             .replace('university.', \" university . \")\\\n             .replace(\"They're\", \" They are \")\\\n             .replace('world\"', ' world \" ')\\\n             .replace('bhakts', ' bhakt ')\\\n             .replace(\"you'd\", \"you could\")\\\n             .replace(\"Quora.\", \" Quora .\")\\\n             .replace(\"Smartphone\", \" smartphone \")\\\n             .replace('hasn\u2019t', \" has not \")\\\n             .replace('demonetisation', \" demonetization \")\\\n             .replace('Nice,', \" Nice , \")\\\n             .replace('Strategist', \" strategist \")\\\n             .replace(\"Didn't\", \" Did not \")\\\n             .replace(\"alt right\", \" Alt Right \")\\\n             .replace(\"\\\\frac\", \" fraction \")\\\n             .replace(\"Freelancing\", \" freelancing \")\\\n             .replace(\"A+\", \" A + \")\\\n             .replace(\"100+\", \" 100 + \")\\\n             .replace(\"Wouldn\u2019t\", \" Would not \")\\\n             .replace(\"Unacademy\", \" Indian learning platform \")\\\n             .replace(\"anxiety.\", \" anxiety . \")\\\n             .replace(\"Vajiram\", \" Indian institute \")\\\n             .replace(\"Doklam\", \" disputed territory \")\\\n             .replace(\"Delhi.\", \" Dehli . \")\\\n             .replace(\"NICMAR\", \" Indian National Institute of Construction Management and Research \")\\\n             .replace(\"Couldn't\", \" Could not \")\\\n             .replace(\"engineer.\", \" engineer . \")\\\n             .replace(\"I\u2019d\", \" I'd \")\\\n             .replace(\"others'\", \" others 's \")\\\n             .replace(\"countries'\", \" countries 's \")\\\n             .replace('Shouldn\u2019t', 'Should not')\\\n             .replace('chsl', 'Combined Higher Secondary Level')\\\n             .replace('AlShamsi', ' Investor on Quora ')\\\n             .replace(\"they'd\", \"they would\")\\\n             .replace(\"HackerRank\", \"Hacker Rank\")\\\n             .replace(\"visa.\", \" visa . \")\\\n             .replace(\"^3\", \" ^ 3 \")\\\n             .replace(\"weren\u2019t\", \" were not \")\\\n             .replace(\"Doesn\u2019t\", \" Does not \")\\\n             .replace(\"MUOET\", \" Manipal University Online Entrance Test \")\\\n             .replace(\"Help!\", \" Help ! \")\\\n             .replace(\"Awdhesh\", \" Indian writer on Quora \")\\\n             .replace(\"\u201cthe\", ' \" the ')\\\n             .replace(\"A2A'd\", ' asked to answer ')\\\n             .replace(\"Litecoin\", ' cryptocurrency ')\\\n             .replace(\"suicide.\", ' suicide . ')\\\n             .replace(\"eLitmus\", ' Indian recruiter company ')\\\n             .replace(\"Jiren\", ' Dragonball character ')\\\n             .replace(\"it'll\", ' it will ')\\\n             .replace(\"Bhakts\", ' bhakt ')\\\n             .replace(\"he'd\", ' he would ')\\\n             .replace(\"abroad.\", ' abroad . ')\\\n             .replace(\"Cryptocurrency\", ' cryptocurrency ')\\\n             .replace(\"b.SC\", ' BSc ')\\\n             .replace(\"could've\", ' could have ')\\\n             .replace(\"#1\", ' # 1 ')\\\n             .replace(\"Ryzen\", ' AMD processors')\\\n             .replace(\"[\\\\\", ' [ \\\\ ')\\\n             .replace(\"+y\", ' + y ')\\\n             .replace(\"=1\", ' = 1 ')\\\n             .replace(\"Jesus'\", \" Jesus ' \")\\\n             .replace(\"[\\\\\", ' [ \\\\ ')\\\n             .replace(\"+y\", ' + y ')\\\n             .replace(\"=1\", ' = 1 ')\\\n             .replace(\"Jesus'\", \" Jesus ' \")\\\n             .replace(\"5'4\", \" 5 inches 4 \")\\\n             .replace(\"you'\", \" you ' \")\\\n             .replace(\"altcoins\", \" cryptocurrency \")\\\n             .replace(\"altcoin \", \" cryptocurrency \")\\\n             .replace(\"Mumbai.\", \" Mumbai . \")\\\n             .replace(\"developer.\", \" developer . \")\\\n             .replace(\"2+\", \" 2 + \")\\\n             .replace(\"disorder.\", \" disorder . \")\\\n             .replace('they\u2019ve', \" they have \")\\\n             .replace('Baahubali', \" Indian epic action film \")\\\n             .replace('-x', \" - x \")\\\n             .replace('1+x', \" 1 + x \")\\\n             .replace(\"US'\", \" US ' \")\\\n             .replace(\"r-aping\", \" raping \")\\\n             .replace(\"SRMJEE\", \" Indian university level entrance test \")\\\n             .replace(\"=0\", \" = 0 \")\\\n             .replace(\"B+\", \" B + \")\\\n             .replace(\"SGSITS\", \" Indian public engineering institution \")\\\n             .replace(\"B+\", \" B + \")\\\n             .replace(\"Thanks!\", \" Thanks + \")\\\n             .replace(\"90+\", \" 90 + \")\\\n             .replace(\"e^\", \" exp ^ \")\\\n             .replace(\"MU-OET\", \" Indian Manipal University Online Entrance Test \")\\\n             .replace(\"Pakistan.\", \" Pakistan . \")\\\n             .replace(\"Beerus\", ' Dragonball character ')\\\n             .replace(\"Skripal\", ' Russian military intelligence ')\\\n             .replace(\"it!\", ' it ! ')\\\n             .replace(\"coinbase\", ' cryptocurrency ')\\\n             .replace(\"me !\", ' me ! ')\\\n             .replace(\"Hons.\", ' honors degree ')\\\n             .replace(\"hons.\", ' honors degree ')\\\n             .replace(\"don't.\", \" don't. \")\\\n             .replace(\"000.\", \" 0 0 0 . \")\\\n             .replace(\"20+\", \" 20 + \")\\\n             .replace(\"{x\", \" { x \")\\\n             .replace(\"5+\", \" 5 + \")\\\n             .replace(\"1+\", \" 1 + \")\\\n             .replace(\"{1}\", \" { 1 } \")\\\n             .replace(\"you\u2019d\", \" you would \")\\\n             .replace(\"we'll\", \" we will \")\\\n             .replace(\"ain't\", \" be not \")\\\n             .replace(\"BMSCE\", \" Indian College of Engineering \")\\\n             .replace(\"Aren\u2019t\", \" Are not \")\\\n             .replace(\"you!\", \" you ! \")\\\n             .replace(\"a+b\", \" a + b \")\\\n             .replace(\"Gurugram\", \" Gurgaon \")\\\n             .replace(\"2016.\", \" 2016 . \")\\\n             .replace(\"+c\", \" + c \")\\\n             .replace(\"Amazon.in\", \" Amazon India \")\\\n             .replace(\"\\\\sqrt\", \" \\\\ sqrt \")\\\n             .replace(\"me!\", \" me ! \")\\\n             .replace(\"don't.\", \" don't . \")\\\n             .replace(\"3+\", \" 3 + \")\\\n             .replace('bahubali', \" Indian epic action film \")\\\n             .replace(\"200+\", \" 200 + \")\\\n             .replace(\"What\\u200b\", \" What \")\\\n             .replace(\"=x\", \" = x \")\\\n             .replace(\"Zebpay\", \" cryptocurrency \")\\\n             .replace(\"litecoin\", \" cryptocurrency \")\\\n             .replace(\"5'10\", \" 5 inches 10 \")\\\n             .replace(\"5'11\", \" 5 inches 11 \")\\\n             .replace(\"5'5\", \" 5 inches 5 \")\\\n             .replace(\"5'6\", \" 5 inches 6 \")\\\n             .replace(\"5'7\", \" 5 inches 7 \")\\\n             .replace(\"5'8\", \" 5 inches 8 \")\\\n             .replace(\"5'9\", \" 5 inches 9 \")\\\n             .replace(\"5'3\", \" 5 inches 3 \")\\\n             .replace(\"5'2\", \" 5 inches 2 \")\\\n             .replace(\"5'\", \" 5 inches \")\\\n             .replace(\"graduate.\", \" graduate . \")\\\n             .replace(\"Alshamsi\", \" investor in Quora \")\\\n             .replace(\"Ravula\", \" trainer on youtube \")\\\n             .replace(\"Binance\", \" cryptocurrency \")\\\n             .replace(\"C#\", \" C++ \")\\\n             .replace(\"Instagram.\", \" Instagram . \")\\\n             .replace(\"Golang\", \" Google programming language \")\\\n             .replace(\"BIPC\", \" university course \")\\\n             .replace(\"x^\", \" x ^ \")\\\n             .replace(\"^1\", \" ^ 1 \")\\\n             .replace(\"^n\", \" ^ n \")\\\n             .replace(\"You've\", \" You have \")\\\n             .replace(\"OBC-NCL\", \" Indian cast religion income \")\\\n             .replace(\"1+1\", \" 1 + 1 \")\\\n             .replace(\"\\\\to\", \" \\\\ to \")\\\n             .replace(\"graduation.\", \" graduation . \")\\\n             .replace(\"}[\", \" } [ \")\\\n             .replace(\".I\", \" . I \")\\\n             .replace(\"\\\\lim_\", \" \\\\ limit \")\\\n             .replace(\"Swachh\", \" Indian campaign \")\\\n             .replace(\"MHCET\", \" Indian University Entrance Test \")\\\n             .replace(\"Bangalore.\", \" Bangalore . \")\\\n             .replace(\"who've\", \" who have \")\\\n             .replace(\"josaa\", \" Indian University Entrance Test \")\\\n             .replace(\"passport.\", \" passport . \")\\\n             .replace(\"'a\", \" ' a \")\\\n             .replace(\"\\\\displaystyle\", \" \\\\ display \")\\\n             .replace(\".How\", \" . How \")\\\n             .replace(\"Truecaller\", \" mobile app \")\\\n             .replace(\"non-\", \" non - \")\\\n             .replace(\"studying.\", \" studying . \")\\\n             .replace(\"startup.\", \" startup . \")\\\n             .replace(\"EVM'S\", \" Indian Electronic Voting Machines 's \")\\\n             .replace(\"divorce.\", \" divorce . \")\\\n             .replace(\"50+\", \" 50 + \")\\\n             .replace(\"40+\", \" 40 + \")\\\n             .replace(\"salary.\", \" salary . \")\\\n             .replace(\"OBOR\", \" One Belt One Road \")\\\n             .replace(\"300+\", \" 300 + \")\\\n             .replace(\"m.SC\", \" MSc \")\\\n             .replace(\"Google+\", \" Google + \")\\\n             .replace(\"\\\\int\", \" \\\\ integral \")\\\n             .replace(\"upwork\", \" Freelancing Platform \")\\\n             .replace(\"\\\\right\", \" \\\\ right \")\\\n             .replace(\"Chromecast\", \" Google digital media player \")\\\n             .replace(\"500+\", \" 500 + \")\\\n             .replace(\"TensorFlow\", \" Google machine learning platform \")\\\n             .replace(\"n+1\", \" n + 1 \")\\\n             .replace(\"#MeToo\", \" Movement against sexual harassment \")\\\n             .replace(\"Indian.\", \" Indian . \")\\\n             .replace(\"60+\", \" 60 + \")\\\n             .replace(\"friends'\", \" friends 's \")\\\n             .replace(\"iisc\", \" Indian public institute \")\\\n             .replace(\"'to\", \" ' to \")\\\n             .replace(\"What're\", \" What are \")\\\n             .replace(\"0+\", \" 0 + \")\\\n             .replace(\"Muslim.\", \" Muslim . \")\\\n             .replace(\".what\", \" . what \")\\\n             .replace(\"adhaar\", \" Indian identity number \")\\\n             .replace(\"Adhaar\", \" Indian identity number \")\\\n             .replace(\"y'all\", \" you all \")\\\n             .replace(\"engg.\", \" engineering \")\\\n             .replace(\"Islam.\", \" Islam . \")\\\n             .replace(\"\\\\left\", \" \\\\ left \")\\\n             .replace(\"+b\", \" + b \")\\\n             .replace(\"Pune.\", \" Pune . \")\\\n             .replace(\"clickbait\", \" attention grabbing \")\\\n             .replace(\"USICT\", \" Indian University \")\\\n             .replace(\"8+\", \" 8 + \")\\\n             .replace(\"Explain.\", \" Explain . \")\\\n             .replace(\"major.\", \" major . \")\\\n             .replace(\"PESSAT\", \" Indian University \")\\\n             .replace(\"demonitisation\", \" demonetization \")\\\n             .replace(\"Muslims.\", \" Muslims . \")\\\n             .replace(\"help!\", \" help ! \")\\\n             .replace(\"\\u200b\", \" \")\\\n             .replace(\"Hyderabad.\", \" Hyderabad . \")\\\n             .replace(\"30+\", \" 30 + \")\\\n             .replace(\"Patreon\", \" membership platform \")\\\n             .replace(\"'a'\", \" ' a ' \")\\\n             .replace(\"maths.\", \" mathematics . \")\\\n             .replace(\"x[\", \" x [ \")\\\n             .replace(\"racist.\", \" racist . \")\\\n             .replace(\"dx[\", \" dx [\")\\\n             .replace(\"Dies\u2122\", \" Dies trademark \")\\\n             .replace(\"microservices\", \" micro services \")\\\n             .replace(\"400+\", \" 400 + \")\\\n             .replace(\"LGBT+\", \" LGBT \")\\\n             .replace(\"unacademy\", \" Indian learning platform \")\\\n             .replace(\"'not\", \" ' not \")\\\n             .replace(\"teenager.\", \" teenager . \")\\\n             .replace(\"pro-Trump\", \" pro Trump \")\\\n             .replace(\"A-\", \" A - \")\\\n             .replace(\"Whst\", \" What \")\\\n             .replace(\"Demonetization\", \" demonetization \")\\\n             .replace(\"y=\", \" y = \")\\\n             .replace(\"{1\", \" 1 { \")\\\n             .replace(\"{2}\", \" { 2 } \")\\\n             .replace(\"{n\", \" { n \")\\\n             .replace(\"c#\", \" c++ \")\\\n             .replace(\"4+\", \" 4 + \")\\\n             .replace(\"O+\", \" O + \")\\\n             .replace(\"O+\", \" O + \")\\\n             .replace(\"\\\\dfrac\", \" \\\\ fraction \")\\\n             .replace(\"would\u2019ve\", \" would have \")\\\n             .replace(\"Koinex\", \" cryptocurrency \")\\\n             .replace(\"Alt-Right\", \" Alt Right \")\\\n             .replace(\"IISERs\", \" Indian Institute of Science Education and Research \")\\\n             .replace(\"}}\", \" } } \")\\\n             .replace(\"fortnite\", \" Fortnite \")\\\n             .replace(\"Williams'\", \" Williams 's \")\\\n             .replace(\"hyperloop\", \" Hyperloop \")\\\n             .replace(\"ReactJS\", \" JavaScript Library \")\\\n             .replace(\"worthless.\", \" worthless . \")\\\n             .replace(\"Didn\u2019t\", \" Did not \")\\\n             .replace(\"Bittrex\", \" blockchain \")\\\n             .replace(\"LGBTQ+\", \" LGBTQ + \")\\\n             .replace(\"Java.\", \" Java . \")\\\n             .replace(\"dating.\", \" dating . \")\\\n             .replace(\"Byju\", \" learning app \")\\\n             .replace(\"\u201cWhat\", ' \" What ')\\\n             .replace(\"MBA.\", \" MBA . \")\\\n             .replace(\"x+2\", \" x + 2 \")\\\n             .replace(\"LBSNAA\", \" Indian research and training institute \")\\\n             .replace(\"\\\\infty}\", \" \\\\ infinity } \")\\\n             .replace(\"=3\", \" = 3 \")\\\n             .replace(\"2015.\", \" 2015 . \")\\\n             .replace(\"H+\", \" Transhumanist party \")\\\n             .replace(\"Zamasu\", \" Dragonball character \")\\\n             .replace(\"UPSE\", \" UPSC \")\\\n             .replace(\".What\", \" . What \")\\\n             .replace(\"Irodov\", \" Difficult Physics book \")\\\n             .replace(\"tensorflow\", \" Google machine learning platform \")\\\n             .replace(\"FTRE\", \" FIITJEE \")\\\n             .replace(\"Fiitjee\", \" FIITJEE \")\\\n             .replace(\"SSC-CGL\", \" Indian Graduate Level Exam \")\\\n             .replace(\"CSE.\", \" CSE .\")\\\n             .replace(\"uncomfortable.\", \" uncomfortable . \")\\\n             .replace(\"{2\", \" { 2 \")\\\n             .replace(\"'white\", \" ' white \")\\\n             .replace(\"JoSAA\", \"  Indian University Entrance Test  \")\\\n             .replace(\"overweight.\", \" overweight . \")\\\n             .replace(\"[0\", \" [ 0 \")\\\n             .replace(\"Chennai.\", \" Chennai . \")\\\n             .replace(\"\u20b9\", \" Indian Rupee \")\\\n             .replace(\"=2\", \" = 2 \")\\\n             .replace(\"Kalpit\", \" best participant to JEE \")\\\n             .replace(\"Haven't\", \" Have not \")\\\n             .replace(\"crush.\", \" crush . \")\\\n             .replace(\"suicidal.\", \" suicidal . \")\\\n             .replace(\"grades.\", \" grades . \")\\\n             .replace(\"IIITH\", \" Indian Research University \")\\\n             .replace(\"Trump-Russia\", \" Trump - Russia \")\\\n             .replace(\"Codeforces\", \" website for competive programming contests \")\\\n             .replace(\"NLUs\", \" NLU \")\\\n             .replace(\"\u00a31000\", \" \u00a3 1000 \")\\\n             .replace(\"hadn\u2019t\", \" had not \")\\\n             .replace(\"\\\\sin\", \" \\\\ sin \")\\\n             .split(\" \") if j != \"\"] for i in questions]\n\ndef get_vocab(sentences):\n    words = set([item for sublist in sentences for item in sublist])\n    print(\"Number of words:\", len(words))\n    return words\n\nsentences = get_sentences_list(train.question_text)\nmax_words = np.max([len(i) for i in sentences])\nwords = get_vocab(sentences)\nvocab_size = len(words)","7ea0a3d9":"def get_embedding_matrix(words_training):\n    embedding_matrix = np.zeros((len(words_training), 300))\n    mapping = {}\n    for index, word in enumerate(words_training):\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[index] = embedding_vector\n            mapping[word] = index\n    return (mapping, embedding_matrix)\n           \nmapping, embedding_matrix = get_embedding_matrix(words)\ninput_sequences = [[mapping[j] for j in i if j in mapping.keys()] for i in sentences]\nvocab_size = len(set([item for sublist in sentences for item in sublist]))","eb34ebb9":"print(\"Number of words with embedding:\", len(mapping.keys()))\nprint(\"Percentage of embedded:\", len(mapping.keys())\/vocab_size)","d70cdc31":"from math import ceil\n\nlabels = train.target\nhalf = ceil(len(labels)\/2)\nprint(\"Size training:\", half)\nprint(\"Insincere train:\", np.sum(labels[0:half]))\nprint(\"Insincere validation:\", np.sum(labels[half+1:len(labels)]))\n\ntrain_sentences = input_sequences[0:half]\nvalidation_sentences = input_sequences[half+1:len(labels)]\ntrain_labels = train.target[0:half]\nvalidation_labels = train.target[half+1:len(labels)]","6cbcb5af":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Embedding\nfrom keras.layers import Dropout\nfrom keras.layers import Conv1D\nfrom keras.layers import MaxPooling1D\nfrom keras.layers import LSTM\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef create_model(vocab_size, embedding_size, max_words, embedding_matrix, input_sequences, labels):\n    padded_docs = pad_sequences(input_sequences, maxlen=max_words, padding='post')\n    model = Sequential()\n    model.add(Embedding(vocab_size, embedding_size, input_length=max_words, \n                        weights=[embedding_matrix], trainable=False))   \n    model.add(Dropout(0.2))\n    model.add(Conv1D(64, 5, activation='relu'))\n    model.add(MaxPooling1D(pool_size=4))\n    model.add(LSTM(300))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.fit(padded_docs, labels, epochs=10)\n    return model\n\nmodel = create_model(vocab_size, embedding_size, max_words, embedding_matrix, \n                     train_sentences, train_labels)","fbb0346f":"from sklearn.metrics import f1_score\n\ntrainset = pad_sequences(train_sentences, maxlen=max_words, padding='post')\nvalidationset = pad_sequences(validation_sentences, maxlen=max_words, padding='post')\npredictions_train = model.predict(trainset)\npredictions_validation = model.predict(validationset)","a7ec396a":"threshold = np.linspace(0, 0.6, 1000)\nscore_train = [f1_score(train_labels, \n                        (predictions_train > t).astype(int)) \n               for t in threshold]\nscore_validation = [f1_score(validation_labels, \n                             (predictions_validation > t).astype(int)) \n                    for t in threshold]","29dfa07e":"%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\n\nplt.plot(threshold, score_train, threshold, score_validation)","32717f63":"print(\"F1 score best:\", np.max(score_validation))\nprint(\"Threshold:\", threshold[np.argmax(score_validation)])","e622731f":"## Get embedding","6ae42382":"# Train the model","55999982":"## Make the embedding","3035cf6d":"## Get vocabulary","50d24eae":"# Assess coverage","58b8b388":"# Refactoring\n\nThis is a refactory and clean up of the [previous kernel](https:\/\/www.kaggle.com\/marcocarnini\/a-minimalistic-approach).\n\n## Read Input","487331fc":"# Prepare train\/validation split"}}