{"cell_type":{"de8df61c":"code","8d65ac1a":"code","644869af":"code","f92c2c4d":"code","2df088d4":"code","5dac18db":"code","b7d63fa8":"code","e8253f62":"code","ccb3ca54":"code","c7a72107":"code","d300d8d5":"code","6247bae8":"code","d04fecb2":"code","21ab8cee":"code","6e33cc07":"code","620bedf6":"code","849f30dd":"code","ad31a418":"code","2d1ea429":"code","b3fdaff6":"code","3e6c8ae1":"code","a9bfe32e":"code","79a75ac8":"code","d083ee35":"code","ec74faed":"code","d54a73b9":"code","90d7e68c":"code","e28e6e59":"code","a426869f":"code","7dfb8137":"code","b7b26170":"code","e2575365":"code","d55fe0b4":"code","6203e67d":"code","186ad9d8":"code","69349eb4":"code","caa98aa4":"code","fc0f28d1":"code","05eed949":"code","78d48961":"code","65e9dcaf":"code","db29e774":"code","3e58529f":"code","b2a6ebed":"code","1f353a70":"code","7bedd911":"code","64afa821":"code","f77f2467":"code","5d559b61":"code","de1df89b":"code","00fd2eb9":"code","9faa29d1":"code","d92ef90a":"code","6403544f":"code","a8fa5f63":"code","e06e9184":"code","7dfd46b2":"code","65e81b77":"code","9f45a521":"code","a0fcc95a":"code","32bae2c2":"code","5c98d98e":"code","3d095cd8":"code","ca68ca8a":"code","4bd71980":"code","d79240c7":"markdown","4508313d":"markdown","1bdc498d":"markdown","49e379bb":"markdown","7b0aa137":"markdown","befea970":"markdown","2e3eac0a":"markdown","a52cd694":"markdown","f2fd35a7":"markdown","dbfa1b52":"markdown","777bc531":"markdown","1fd93f1f":"markdown","03b1b3aa":"markdown","fd0aad39":"markdown","c2343f87":"markdown","bfcbfaa8":"markdown","b008c69e":"markdown","5df86999":"markdown","2582b256":"markdown","2f373971":"markdown","2e51a3e6":"markdown","69fea9d6":"markdown"},"source":{"de8df61c":"# importing Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","8d65ac1a":"# Read the Traing and Test DataSet\ntrain_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')","644869af":"train_data.head()","f92c2c4d":"train_data.info()","2df088d4":"# Check the shape of Train Data\nprint('Shape of Train Data',train_data.shape)","5dac18db":"# Check the shape of Test Data\nprint('Shape of Test Data',test_data.shape)","b7d63fa8":"# Descriptive Analysis of Numerical Data\ntrain_data.describe()","e8253f62":"# Descriptive Analysis of Categorical Data\ntrain_data.describe(include='object')","ccb3ca54":"# Checking the Null values present in Training Data\ntrain_data.isnull().sum()","c7a72107":"# Check the percetage of missing values in columns\nx= train_data.isnull().sum()\ny= (train_data.isnull().sum()\/train_data.shape[0])*100\nz={'No. of Missing Values':x,'Percentage of Missing Values':y}\ndf= pd.DataFrame(z,columns=['No. of Missing Values','Percentage of Missing Values'])\ndf.sort_values(by='Percentage of Missing Values',ascending=False)","d300d8d5":"# Cabin feature has no relation with Survived feature so lets drop the column\ntrain_data.drop('Cabin',axis=1,inplace=True)\ntest_data.drop('Cabin',axis=1,inplace=True)","6247bae8":"# Fill the missing values with Median\ntrain_data['Age'].fillna(train_data['Age'].median(),inplace=True)","d04fecb2":"# Drop the remaining null values \ntrain_data.dropna(inplace=True)","21ab8cee":"# Check if there ara null values ramains in data\ntrain_data.isnull().sum().sum()","6e33cc07":"# Check the null values in Test data\ntest_data.isnull().sum()","620bedf6":"# Fill the missing value with Median\ntest_data['Age'].fillna(test_data['Age'].median(),inplace=True)","849f30dd":"# Fill the missing value with Mean\ntest_data['Fare'].fillna(test_data['Fare'].mean(),inplace=True)","ad31a418":"# Check if null values present in Test Data \ntest_data.isnull().sum().sum()","2d1ea429":"train_data.columns","b3fdaff6":"# Univariant Analysis of Survived column\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (5,5)\nsns.countplot(x='Survived',data=train_data)\nplt.show()","3e6c8ae1":"plt.rcParams['figure.figsize'] = (5,5)\nsns.countplot(x='Survived',hue='Sex',data=train_data)","a9bfe32e":"women=train_data.loc[train_data.Sex=='female']['Survived']\nrate_women=sum(women)\/len(women) * 100\nprint(' % of women survivers : ', rate_women)\n","79a75ac8":"men=train_data.loc[train_data.Sex=='male']['Survived']\nrate_men=sum(men)\/len(men) * 100\nprint(' % of men survivers : ', rate_men)\n","d083ee35":"sns.countplot(x='Survived',hue='Pclass',data=train_data)","ec74faed":"class1=train_data.loc[train_data.Pclass==1]['Survived']\nrate_class1=sum(class1)\/len(class1) * 100\nprint(' % of class1 survivers : ', rate_class1)\n","d54a73b9":"class2=train_data.loc[train_data.Pclass==2]['Survived']\nrate_class2=sum(class2)\/len(class2) * 100\nprint(' % of class2 survivers : ', rate_class2)\n","90d7e68c":"class3=train_data.loc[train_data.Pclass==3]['Survived']\nrate_class3=sum(class3)\/len(class3) * 100\nprint(' % of class3 survivers : ', rate_class3)\n","e28e6e59":"sns.countplot(x='Survived',hue='SibSp',data=train_data)","a426869f":"sns.countplot(x='Survived',hue='Parch',data=train_data)","7dfb8137":"sns.violinplot(x='Survived',y='Age',data=train_data)","b7b26170":"sns.countplot(x='Survived',hue='Embarked',data=train_data)","e2575365":"train_data.head()","d55fe0b4":"#  Add a Flag to Identify the Train and Test Data Set\ntrain_data['Type']=1\ntest_data['Type']= 0\n\nprint('Shape of Train Data',train_data.shape)\nprint('Shape of Test Data',test_data.shape)","6203e67d":"# Concat the Data sets\nfull_data=pd.concat([train_data,test_data],axis=0)\nprint('Shape of Full Data',full_data.shape)\nfull_data.head()","186ad9d8":"print('Unique Values are:')\nprint(' Sex:',full_data['Sex'].unique())\nprint(' Embarked:',full_data['Embarked'].unique())","69349eb4":"# Convert Categorical values to Numerical Values\nfull_data['Sex'].replace(('male','female'),(0,1),inplace=True)\nfull_data['Embarked'].replace(('S','C','Q'),(0,1,2),inplace=True)","caa98aa4":"drop_cols=['PassengerId','Name','Ticket','Fare']\nfull_data=full_data.drop(drop_cols,axis=1)","fc0f28d1":"# Age data Bining\nfull_data.loc[ full_data['Age'] <= 16, 'Age'] = 0\nfull_data.loc[(full_data['Age'] > 16) & (full_data['Age'] <= 36), 'Age'] = 1\nfull_data.loc[(full_data['Age'] > 36) & (full_data['Age'] <= 50), 'Age'] = 2\nfull_data.loc[(full_data['Age'] > 50) & (full_data['Age'] <= 64), 'Age'] = 3\nfull_data.loc[ full_data['Age'] > 64, 'Age'] = 4","05eed949":"full_data.head()","78d48961":"# Seperate the Train and Test Data Sets using flages created earlier\ntrain_Modified= full_data[full_data['Type']==1]\ntest_Modified= full_data[full_data['Type']==0]\n\n# Drop the 'Type' column\ntrain_Modified = train_Modified.drop('Type',axis=1)\ntest_Modified = test_Modified.drop('Type',axis=1)","65e9dcaf":"# Set Target Column\nX = train_Modified.drop(['Survived'],axis=1)\nY = train_Modified['Survived']","db29e774":"# Split the Target column from the Data\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=0,\n                                               shuffle= True, stratify=Y)","3e58529f":"# Here we will go with the Accuracy metric for our predicted values because we have already balanced our dataset. \n# So, accuracy is the best metric to evaluate any binary classification problem if it is performed on a balanced dataset.","b2a6ebed":"# Formula to get accuracy\ndef get_accuracy(y_true, y_preds):\n    # Getting score of confusion matrix\n    from sklearn.metrics import confusion_matrix\n    true_negative, false_positive, false_negative, true_positive = confusion_matrix(y_true, y_preds).ravel()\n    # Calculating accuracy\n    accuracy = (true_positive + true_negative)\/(true_negative + false_positive + false_negative + true_positive)\n    return accuracy","1f353a70":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(random_state=0)\nLR.fit(x_train, y_train)","7bedd911":"from sklearn.naive_bayes import GaussianNB\nGNB = GaussianNB()\nGNB.fit(x_train, y_train)","64afa821":"from sklearn.ensemble import RandomForestClassifier\nRF = RandomForestClassifier(random_state=0)\nRF.fit(x_train, y_train)","f77f2467":"from sklearn.neighbors import KNeighborsClassifier\nKNN = KNeighborsClassifier(n_neighbors=2)\nKNN.fit(x_train, y_train)","5d559b61":"from sklearn.tree import DecisionTreeClassifier\nDT = DecisionTreeClassifier()\nDT.fit(x_train,y_train)","de1df89b":"from sklearn.svm import SVC\nSVM = SVC(kernel='linear', random_state=0)  \nSVM.fit(x_train, y_train)","00fd2eb9":"from sklearn.ensemble import GradientBoostingClassifier\nGBC = GradientBoostingClassifier(random_state=0)\nGBC.fit(x_train, y_train)","9faa29d1":"models = [LR, GNB, RF, KNN, DT, SVM, GBC]\nacc = []\nfor model in models:\n    preds_val = model.predict(x_test)\n    accuracy = get_accuracy(y_test, preds_val)\n    acc.append(accuracy*100)","d92ef90a":"model_name = ['Logistic Regression', 'Naive Bayes', 'Random Forest', 'KNN', 'Decision Tree', 'SVM', 'GradientBoost']\naccuracy = dict(zip(model_name, acc))","6403544f":"sorted_accuracy = dict(sorted(accuracy.items(), key=lambda x: x[1], reverse=True))","a8fa5f63":"plt.figure(figsize=(10,6))\nax = sns.barplot(x = list(sorted_accuracy.values()), y = list(sorted_accuracy.keys()), palette= 'magma')\nfor p, value in zip(ax.patches, list(sorted_accuracy.values())):\n    _x = p.get_x() + p.get_width()+1\n    _y = p.get_y() + p.get_height()\/2\n    ax.text(_x, _y, round(value, 2), ha=\"left\",va='center')\nplt.xlabel(\"Accuracy\")\nplt.ylabel(\"Models\")\nplt.title(\"Model vs. Accuracy\")\nplt.show()","e06e9184":"# We tried to fit our data on default parameters of different algorithms for binary classification.\n# Surprisingly, Gradient Boost Classifier turned out to best in terms of validation set accuracy.","7dfd46b2":"GBC = GradientBoostingClassifier(learning_rate= 0.07, n_estimators= 50, max_depth=3, random_state=0)\nGBC.fit(x_train, y_train) \ny_pred = GBC.predict(x_test)","65e81b77":"from sklearn.metrics import accuracy_score\nprint('Accuracy : %s '%'{0:.2%}'.format(accuracy_score(y_test, y_pred)))","9f45a521":"from sklearn.metrics import confusion_matrix\nConf_Matrix = confusion_matrix(y_test, y_pred)\n\n# Visualize the Confusion Matrix\nplt.rcParams['figure.figsize'] = (4,4)\nsns.heatmap(Conf_Matrix, annot = True, fmt = '.8g',center=30,cmap=\"rocket\")\nplt.show()","a0fcc95a":"# Check the Classification report for performance analysis\n\nfrom sklearn.metrics import  classification_report\nClass_Report = classification_report(y_test, y_pred)\nprint(Class_Report)","32bae2c2":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(GBC, x_train, y_train, cv=10)\nprint(scores)\nprint('\\n Cross-Validation Score :%s '%'{0:.2%}'.format(scores.mean()))","5c98d98e":"test_Modified.head()","3d095cd8":"import warnings\nwarnings.simplefilter(action=\"ignore\")\ntest_Modified.drop('Survived',axis=1,inplace=True)","ca68ca8a":"# Predict Target Variable and Store it\nresult = GBC.predict(test_Modified)\n\n# Convert to pandas DataFrame\nresult=pd.DataFrame(result,columns={'Survived'})\nresult['Survived'] = result['Survived'].apply(np.int64)\nresult['PassengerId']= test_data['PassengerId']\nresult = result.reindex(columns = ['PassengerId','Survived'])\nresult.head()","4bd71980":"# Store the Final result\nresult.to_csv(r'final_Submission.csv',index=False)","d79240c7":"## **Applying Gradient Boost Classifier**","4508313d":"#### **Logistic Regression Classifier**","1bdc498d":"#### **Naive Bayes Classifier**","49e379bb":"### **Cross Validation**","7b0aa137":"## **Data Cleaning**","befea970":"## **Machine Learning Model**","2e3eac0a":"## **Descriptive Analysis**","a52cd694":"### **Creating some baseline models**","f2fd35a7":"### **Data Spliting**","dbfa1b52":"## **Exploratory Data Analysis**","777bc531":"#### **SVM Classifier**","1fd93f1f":"# **Predicting the Survival of Titanic Passengers**","03b1b3aa":"#### **Gradient Boosting Classifier**","fd0aad39":"#### **Random Forest Classifier**","c2343f87":"### **Confusion Matrix**","bfcbfaa8":"### **Classification Report**","b008c69e":"#### **Decision Tree Classifier**","5df86999":"## **Apply ML Model on Test Data**","2582b256":"### **Evaluation of accuracy on validation data**","2f373971":"# Feature Enginering","2e51a3e6":"#### **KNN Classifier**","69fea9d6":"### **Choosing the evaluation metric**"}}