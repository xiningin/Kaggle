{"cell_type":{"80afbb80":"code","81d89d30":"code","e06a19c1":"code","1e564e12":"code","a1b526fa":"code","67b7ffe2":"code","1ae60b93":"code","032e4848":"code","17f3f100":"code","4c0e266f":"code","103c2f5b":"code","f7971053":"code","26182bf1":"code","87ade2a3":"code","9270e245":"code","60a1342f":"code","ea278637":"code","9db9ecd1":"code","45205c8a":"code","824180da":"code","22d69143":"code","300e2238":"code","43273447":"code","4eea38b2":"code","34813a85":"code","d977d671":"code","a0a316ca":"code","83ed3fc2":"code","8c4def5c":"code","eceddca6":"code","e641b4ad":"code","d5eb6e52":"code","72d7c188":"code","e3ee4ae1":"code","4e8c6ef1":"markdown","bc433ee0":"markdown","3f92c188":"markdown","4b99ac2f":"markdown","6f8cf269":"markdown","cbcf0d8b":"markdown","d34fcae9":"markdown","e1a13ec1":"markdown","ff83e681":"markdown","49939451":"markdown","f8f70f42":"markdown","bdf539ac":"markdown","3614e6e2":"markdown","7766117b":"markdown","cfed89b0":"markdown","58b3ff58":"markdown","f3199293":"markdown","cf4a7869":"markdown","5f88f564":"markdown","9f325bcd":"markdown","90c53f9b":"markdown","08b5a670":"markdown"},"source":{"80afbb80":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import tree\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81d89d30":"data=pd.read_csv(\"\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")\ndata.head()","e06a19c1":"data.isnull().sum()","1e564e12":"import matplotlib.pyplot as plt\nimport seaborn as sns\ndata[\"DEATH_EVENT\"].value_counts()","a1b526fa":"data.dtypes","67b7ffe2":"data.describe()","1ae60b93":"print(set(data[\"smoking\"]))\nprint(set(data[\"DEATH_EVENT\"]))","032e4848":"data[[\"smoking\",\"DEATH_EVENT\"]].corr()","17f3f100":"data[[\"smoking\",\"DEATH_EVENT\"]]","4c0e266f":"data[[\"high_blood_pressure\",\"DEATH_EVENT\"]].corr()","103c2f5b":"data[[\"diabetes\",\"DEATH_EVENT\"]].corr()","f7971053":"data[[\"age\",\"DEATH_EVENT\"]].corr()","26182bf1":"for column in data.select_dtypes([np.number]).columns:\n    try:\n        print(column,\": \",data[[column,\"DEATH_EVENT\"]].corr()[column][1])\n    except:\n        print(\"Problem in: \",column)","87ade2a3":"x_with_corr=data[[\"age\",\"ejection_fraction\",\"serum_creatinine\",\"serum_sodium\",\"time\"]]\ny=data[\"DEATH_EVENT\"]","9270e245":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_with_corr, y, test_size=0.33, random_state=1071)","60a1342f":"from sklearn.tree import DecisionTreeClassifier\ndtree= DecisionTreeClassifier(max_depth=3)\ndtree.fit(x_train,y_train)\nypred=dtree.predict(x_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","ea278637":"import graphviz\ndot_data = tree.export_graphviz(dtree, out_file=None, \n                     feature_names=x_train.columns,class_names=[\"zero\",\"one\"],\n                         filled=True, rounded=True,special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph ","9db9ecd1":"dot_data = tree.export_graphviz(dtree, out_file=None, \n                     feature_names=x_train.columns,class_names=[\"one\",\"zero\"],\n                         filled=True, rounded=True,special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph ","45205c8a":"from  xgboost import XGBClassifier\nxgbo = XGBClassifier(learning_rate=0.01)\n\n\nxgbo.fit(x_train,y_train)\nypred=xgbo.predict(x_test)\n\n\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","824180da":"from  xgboost import XGBClassifier\nxgbo = XGBClassifier(learning_rate=0.1)\n\n\nxgbo.fit(x_train,y_train)\nypred=xgbo.predict(x_test)\n\n\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","22d69143":"from  xgboost import XGBClassifier\nxgbo = XGBClassifier(learning_rate=0.1,n_estimators=100,gamma=4,subsample=0.8,)\n\n\nxgbo.fit(x_train,y_train)\nypred=xgbo.predict(x_test)\n\n\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","300e2238":"import xgboost\nxgboost.plot_importance(xgbo, importance_type=\"cover\")","43273447":"xgboost.plot_tree(xgbo,num_trees=4)","4eea38b2":"mybooster = xgbo.get_booster()    \nmodel_bytearray = mybooster.save_raw()[4:]\ndef myfun(self=None):\n    return model_bytearray\nmybooster.save_raw = myfun\n#https:\/\/stackoverflow.com\/questions\/61928198\/getting-unicodedecodeerror-when-using-shap-on-xgboost solution in this page is used\nimport shap\nexplainer = shap.TreeExplainer(mybooster)\nshap_values = explainer.shap_values(x_train)\n","34813a85":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[0,:], x_train.iloc[0,:])","d977d671":"shap.force_plot(explainer.expected_value, shap_values[0,:], x_train.iloc[1,:])","a0a316ca":"shap.force_plot(explainer.expected_value, shap_values[0,:], x_train.iloc[25,:])","83ed3fc2":"shap.force_plot(explainer.expected_value, shap_values[0,:], x_train.iloc[40,:])","8c4def5c":"X=data.iloc[:,0:12]\nY=data.iloc[:,12:]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1071)","eceddca6":"from  xgboost import XGBClassifier\nxgbo = XGBClassifier()\n\n\nxgbo.fit(X_train,y_train)\nypred=xgbo.predict(X_test)\n\n\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","e641b4ad":"from  xgboost import XGBClassifier\nxgbo = XGBClassifier(learning_rate=0.1,n_estimators=100,gamma=4,subsample=0.8,)\n\n\nxgbo.fit(X_train,y_train)\nypred=xgbo.predict(X_test)\n\n\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","d5eb6e52":"from  xgboost import XGBClassifier\nxgbo = XGBClassifier(learning_rate=0.1,n_estimators=1000,gamma=5,subsample=0.8,)\n\n\nxgbo.fit(X_train,y_train)\nypred=xgbo.predict(X_test)\n\n\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","72d7c188":"xgboost.plot_importance(xgbo, importance_type=\"cover\")","e3ee4ae1":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[0,:], x_train.iloc[1,:])","4e8c6ef1":"Okay we have some meaningful correlation values. First create a model with only with these columns:","bc433ee0":"Some values are just meaningless. For example left of tree serum sodium is meaningless. All values is goes to zero. ALso in Right age is meaningless.","3f92c188":"All Feature looks important especially ejection_fraction, age, and time.","4b99ac2f":"Some Contradiction is here. Some values is wrong I guess.","6f8cf269":"I don't know anything about some of these columns.","cbcf0d8b":"Okay models is looks similar.","d34fcae9":"Okay nearly nothing is changed.","e1a13ec1":"Okay we use all features.","ff83e681":"Okay. Age is a important parameter. ","49939451":"Okay this model is look simple. Ejection fraction time and serum creatinine is explain in 5 second.","f8f70f42":"Interesting smoking habit and DEath have small negative correlation. It is interesting.","bdf539ac":"This classification result is good.","3614e6e2":"Very Very Small Correlation, Nearly Zero. ","7766117b":"Interesting!","cfed89b0":"Okay now we can corr test between smoking and Death_Event:","58b3ff58":"## Result:\n1. Most important features is time,serum_creatininie,ejection_fraction,serum_sodium  and age.\n2. With less Feature models also be have good performance and easy to understand.\n3. Decision Tree Visualization is sometimes not useful. ","f3199293":"I think age have to be different.","cf4a7869":"Okay model is little changed but ejection fraction, age, time and serum creatine is still the most important feautre. ","5f88f564":"We don't have any null values.","9f325bcd":"High blood Pressure and Death_Event maybe have strong correlation:","90c53f9b":"What about Diabeties:","08b5a670":"It is horrifying. Correlations is so small!,"}}