{"cell_type":{"55bfa226":"code","0b947993":"code","20ac0a4e":"code","4db9196a":"code","eafee387":"code","7bdb4b02":"code","c8e9276c":"code","dea1bdc7":"code","fe72b0bd":"code","803d1d47":"code","e063fdf1":"code","737509f6":"code","c14cd7af":"code","13dec989":"code","dfc33fc2":"code","7d57bd0d":"code","4e6498ee":"code","494f8b3e":"code","62369864":"code","f223f14a":"code","0d7af9c0":"code","39d4af1d":"code","f123de5d":"code","d266f846":"code","19e771a6":"code","e044bfef":"code","82a1cefc":"code","f7e5ab5b":"markdown","23b413ca":"markdown","a5fe487e":"markdown","50de87b1":"markdown","f5825505":"markdown","a2313e3a":"markdown","756f8a16":"markdown","bc7f86d3":"markdown","6d4a7226":"markdown","864e2019":"markdown","5300761c":"markdown","c66bbedb":"markdown","43d861a7":"markdown","0b9d1df1":"markdown","56f98fd3":"markdown","00d614ae":"markdown","5e188c20":"markdown","5f5998bf":"markdown","23846203":"markdown","b8ab0c71":"markdown","fadc5d0d":"markdown","31ce0f8c":"markdown","c5932517":"markdown","983c1fa0":"markdown","1010a9e6":"markdown","7f8f4c85":"markdown","6a319714":"markdown","c3a0bb45":"markdown","326ebaac":"markdown","65c200d5":"markdown","9114ad36":"markdown","120b27fd":"markdown","58ef4202":"markdown","dc9c3b7e":"markdown","dce802b7":"markdown","de8d9e67":"markdown","59f156bc":"markdown","f351fe01":"markdown","7b10b066":"markdown","b1770a6c":"markdown","a10b80b7":"markdown","55cd59e3":"markdown","6328fa18":"markdown","61b31192":"markdown","05a9a3a7":"markdown","b0ff57bf":"markdown"},"source":{"55bfa226":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#sklearn\nfrom sklearn.model_selection import train_test_split, cross_val_score,KFold\nfrom sklearn import datasets, linear_model\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LassoCV\nfrom sklearn import preprocessing, svm\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","0b947993":"df_train=pd.read_csv('..\/input\/demand-forecasting-kernels-only\/train.csv')","20ac0a4e":"df_test= pd.read_csv('..\/input\/demand-forecasting-kernels-only\/test.csv', index_col='id')","4db9196a":"df_smple=  pd.read_csv('..\/input\/demand-forecasting-kernels-only\/sample_submission.csv', index_col='id')","eafee387":"df_train.head()","7bdb4b02":"df_train.info()","c8e9276c":"df_train.shape","dea1bdc7":"df_test.head()","fe72b0bd":"df_test.info()","803d1d47":"df_test.shape","e063fdf1":"fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (18, 6))\nsns.heatmap(df_train.isnull(), yticklabels=False, ax = ax[0], cbar=False, cmap='viridis')\nax[0].set_title('Trian data')\n\nsns.heatmap(df_test.isnull(), yticklabels=False, ax = ax[1], cbar=False, cmap='viridis')\nax[1].set_title('Test data');","737509f6":"# change date to DateTime\ndf_train['date'] = pd.to_datetime(df_train['date'])\ndf_train.dtypes","c14cd7af":"# change date to DateTime\ndf_test['date'] = pd.to_datetime(df_test['date'])\ndf_test.dtypes","13dec989":"#train data\ndf_train['year'] = df_train['date'].dt.year\ndf_train['month'] = df_train['date'].dt.month\ndf_train['day'] = df_train['date'].dt.day\ndf_train['week'] = df_train['date'].dt.week\ndf_train['weekofyear'] = df_train['date'].dt.weekofyear\ndf_train['dayofweek'] = df_train['date'].dt.dayofweek\ndf_train['weekday'] = df_train['date'].dt.weekday\ndf_train['dayofyear'] = df_train['date'].dt.dayofyear\ndf_train['quarter'] = df_train['date'].dt.quarter\n\ndf_train['is_month_start'] = df_train['date'].dt.is_month_start\ndf_train['is_month_end'] =df_train['date'].dt.is_month_end\ndf_train['is_quarter_start'] = df_train['date'].dt.is_quarter_start\ndf_train['is_quarter_end'] = df_train['date'].dt.is_quarter_end\ndf_train['is_year_start'] = df_train['date'].dt.is_year_start\ndf_train['is_year_end'] = df_train['date'].dt.is_year_end\n\n# To convert data type from bool to int\n# df_train['is_month_start'] = (df_train.date.dt.is_month_start).astype(int)","dfc33fc2":"#Test data\n\ndf_test['year'] = df_test['date'].dt.year\ndf_test['month'] = df_test['date'].dt.month\ndf_test['day'] = df_test['date'].dt.day\ndf_test['week'] = df_test['date'].dt.week\ndf_test['weekofyear'] = df_test['date'].dt.weekofyear\ndf_test['dayofweek'] = df_test['date'].dt.dayofweek\ndf_test['weekday'] = df_test['date'].dt.weekday\ndf_test['dayofyear'] = df_test['date'].dt.dayofyear\ndf_test['quarter'] = df_test['date'].dt.quarter\n\ndf_test['is_month_start'] = df_test['date'].dt.is_month_start\ndf_test['is_month_end']= df_test['date'].dt.is_month_end\ndf_test['is_quarter_start'] = df_test['date'].dt.is_quarter_start\ndf_test['is_quarter_end'] = df_test['date'].dt.is_quarter_end\ndf_test['is_year_start'] = df_test['date'].dt.is_year_start\ndf_test['is_year_end'] = df_test['date'].dt.is_year_end\n","7d57bd0d":"df_train.info()","4e6498ee":"df_test.info()","494f8b3e":"del df_train['date']\ndel df_test['date']","62369864":"plt.figure(figsize=(33,30))\ncor = df_train.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","f223f14a":"y = df_train['sales']\nX = df_train.drop('sales', axis=1)","0d7af9c0":"ss = StandardScaler()\nXs =ss.fit_transform(X)\nX_test_ss = ss.transform(df_test)","39d4af1d":"randomF = RandomForestRegressor()\nrandomF.fit(Xs, y)\nprint('Score :',randomF.score(Xs, y))","f123de5d":"pred_f = randomF.predict(X_test_ss)","d266f846":"submission = df_smple.drop(['sales'],axis=1)","19e771a6":"submission['sales'] = pred_f","e044bfef":"submission.head()","82a1cefc":"submission.to_csv('submission.csv')","f7e5ab5b":"In this chart, we can see the sales of each store from 2013 to 2017, and store 2 was the highest amount of sales then 8 and 3 respectively.","23b413ca":"- ### Preprocessing: Date Column","a5fe487e":"![2014.png](attachment:2014.png)","50de87b1":"## Importing packages\n","f5825505":"---","a2313e3a":"## Loading  Data\n","756f8a16":"The common items in all months that had the highest numbers of sales were 15 and 28, on the other hand, the common items in all months that had the lowest numbers of sales was 5. ","bc7f86d3":"![Download%20Image-6.png](attachment:Download%20Image-6.png)","6d4a7226":"- ### Drop Columns","864e2019":"![Screen%20Shot%202020-06-13%20at%2010.33.24%20AM.png](attachment:Screen%20Shot%202020-06-13%20at%2010.33.24%20AM.png)","5300761c":"## Modeling","c66bbedb":"---","43d861a7":"## Clean Data ","0b9d1df1":"The common items in all years that had the highest numbers of sales were 15 and 28, on the other hand, the common items in all years that had the lowest numbers of sales was 5. ","56f98fd3":"![Download%20Image-2.png](attachment:Download%20Image-2.png)","00d614ae":"AS we see above, March recorded the highest sales by 823K , February and January almost 600K ","5e188c20":"![2017.png](attachment:2017.png)","5f5998bf":"### Group members:\n- Khwla Alsafri\n- Ahmad Fatani \n- Doaa Alsenani\n---","23846203":"![Screen%20Shot%202020-06-20%20at%2011.15.35%20AM.png](attachment:Screen%20Shot%202020-06-20%20at%2011.15.35%20AM.png)","b8ab0c71":"![Download%20Image-9.png](attachment:Download%20Image-9.png)","fadc5d0d":"We notice that the sales grew yearly, and between 2013 and 2014 the growth was bigger than others.","31ce0f8c":"Tableau link :\n\nhttps:\/\/public.tableau.com\/profile\/doaa8325#!\/vizhome\/StoreItemDemandForecastingfor3Monthsin2018\/TopSalesofItemsinFebruary2018?publish=yes","c5932517":"---","983c1fa0":"## Kaggle Score ","1010a9e6":"![Download%20Image.png](attachment:Download%20Image.png)","7f8f4c85":"![Download%20Image-3.png](attachment:Download%20Image-3.png)","6a319714":"![Download%20Image-7.png](attachment:Download%20Image-7.png)","c3a0bb45":"### We used Tableau to do the Visualizations \nTableau link :\n\nhttps:\/\/public.tableau.com\/profile\/doaa8325#!\/vizhome\/CompetitionSalesofItemsin2017\/SalesofItemsin2017?publish=yes","326ebaac":"![Download%20Image-4.png](attachment:Download%20Image-4.png)","65c200d5":"![2015.png](attachment:2015.png)","9114ad36":"![Download%20Image-8.png](attachment:Download%20Image-8.png)","120b27fd":"### Submission","58ef4202":"## Visualizations","dc9c3b7e":"![Screen%20Shot%202020-06-13%20at%2010.59.10%20AM.png](attachment:Screen%20Shot%202020-06-13%20at%2010.59.10%20AM.png)","dce802b7":"### Build RandomForest Model","de8d9e67":"In this chart, we can see the sales of each store from Jan to Mar, and store 2 was the highest amount of sales then 8 and 3 respectively.","59f156bc":"---","f351fe01":"![Download%20Image.png](attachment:Download%20Image.png)","7b10b066":"## Visualizing Sales Prediction for 2018 \n We used Tableau to do the Visualizations ","b1770a6c":"![Download%20Image-5.png](attachment:Download%20Image-5.png)","a10b80b7":"# Store Item Demand Forecasting Challenge","55cd59e3":"### Check Missing Values","6328fa18":"- ### Data Types","61b31192":"### Plotting Histograms\n","05a9a3a7":"## EDA","b0ff57bf":"## Introduction\n\n- In this Kaggle competition, we aim to predict 3 months of sales for 50 different items at 10 different stores.\n"}}