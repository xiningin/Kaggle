{"cell_type":{"c12eab84":"code","ddb5d527":"code","bf809912":"code","0aec3283":"code","a30fe5ea":"code","5c811b60":"code","21001658":"code","3e469237":"code","f88dcbf7":"code","7c16eeec":"code","cce78d8b":"code","7784a519":"code","ea46fbbd":"code","038b390f":"code","220ec0f4":"code","0905bc09":"code","18697bbf":"code","8a281db7":"code","2dd65f9b":"code","65cf7b2b":"code","381d25cd":"code","37382eea":"code","78626ab6":"code","25991fc0":"code","73cc098d":"markdown","20c9c2c8":"markdown","c9bb6a7c":"markdown","fce92ca4":"markdown"},"source":{"c12eab84":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport gc\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mplimg\nfrom matplotlib.pyplot import imshow\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport random\nfrom IPython.display import Image\n\nfrom keras import layers\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout\nfrom keras.models import Model\n\nimport keras.backend as K\nfrom keras.models import Sequential\n\n%matplotlib inline\nimport warnings\nwarnings.simplefilter(\"ignore\", category=DeprecationWarning)","ddb5d527":"os.listdir(\"..\/input\")","bf809912":"# load image data\ndf = pd.read_csv('..\/input\/train.csv')\ndf.head()","0aec3283":"df.tail()","a30fe5ea":"#show sample image\nImage(filename=\"..\/input\/train\/\"+random.choice(df['Image'])) ","5c811b60":"# lets find total number of different whales present\nprint(f'Training examples: {len(df)}')\nprint(\"Unique whales: \",df['Id'].nunique()) # it includes new_whale as a separate type.","21001658":"training_pts_per_class = df.groupby('Id').size()\ntraining_pts_per_class","3e469237":"print(\"Min example a class can have: \",training_pts_per_class.min())\nprint(\"0.99 quantile: \",training_pts_per_class.quantile(0.99))\nprint(\"Max example a class can have: \\n\",training_pts_per_class.nlargest(5))    ","f88dcbf7":"data = training_pts_per_class.copy()\ndata.loc[data > data.quantile(0.99)] = '22+'\nplt.figure(figsize=(15,10))\nsns.countplot(data.astype('str'))\nplt.title(\"#classes with different number of images\",fontsize=15)\nplt.show()","7c16eeec":"# new_whales is addes as a new class.\n# above graph shows that there are more than 2000 classes with just one training example.\n# and around 1300 classes with 2 training examples.\n# it also shows that around 50 classes have more than 22 training examples.\n\ndata","cce78d8b":"def prepare_images(data, m, dataset):\n    print(\"Preparing images\")\n    X_train = np.zeros((m, 100, 100, 3))\n    count = 0\n    \n    for fig in data['Image']:\n        #load images into images of size 100x100x3\n        img = image.load_img(\"..\/input\/\"+dataset+\"\/\"+fig, target_size=(100, 100, 3))\n        x = image.img_to_array(img)\n        x = preprocess_input(x)\n\n        X_train[count] = x\n        if (count%500 == 0):\n            print(\"Processing image: \", count+1, \", \", fig)\n        count += 1\n    \n    return X_train","7784a519":"def prepare_labels(y):\n    values = np.array(y)\n    label_encoder = LabelEncoder()\n    integer_encoded = label_encoder.fit_transform(values)\n    # print(integer_encoded)\n\n    onehot_encoder = OneHotEncoder(sparse=False)\n    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n    # print(onehot_encoded)\n\n    y = onehot_encoded\n    # print(y.shape)\n    return y, label_encoder","ea46fbbd":"X = prepare_images(df, df.shape[0], \"train\")\nX \/= 255","038b390f":"y, label_encoder = prepare_labels(df['Id'])","220ec0f4":"model = Sequential()\n\nmodel.add(Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0', input_shape = (100, 100, 3)))\n\nmodel.add(BatchNormalization(axis = 3, name = 'bn0'))\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPooling2D((2, 2), name='max_pool'))\nmodel.add(Conv2D(64, (3, 3), strides = (1,1), name=\"conv1\"))\nmodel.add(Activation('relu'))\nmodel.add(AveragePooling2D((3, 3), name='avg_pool'))\n\nmodel.add(Flatten())\nmodel.add(Dense(500, activation=\"relu\", name='rl'))\nmodel.add(Dropout(0.8))\nmodel.add(Dense(y.shape[1], activation='softmax', name='sm'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])","0905bc09":"model.summary()","18697bbf":"history = model.fit(X, y, epochs=100, batch_size=100, verbose=1)\ngc.collect()","8a281db7":"plt.plot(history.history['acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()","2dd65f9b":"test = os.listdir(\"..\/input\/test\/\")\nprint(len(test))","65cf7b2b":"col = ['Image']\ntest_df = pd.DataFrame(test, columns=col)\ntest_df['Id'] = ''","381d25cd":"X_test = prepare_images(test_df, test_df.shape[0], \"test\")\nX_test \/= 255","37382eea":"predictions = model.predict(np.array(X_test), verbose=1)","78626ab6":"for i, pred in enumerate(predictions):\n    test_df.loc[i, 'Id'] = ' '.join(label_encoder.inverse_transform(pred.argsort()[-5:][::-1]))","25991fc0":"\n\ntest_df.head(10)\ntest_df.to_csv('submission.csv', index=False)","73cc098d":"Preparing the labels, by converting them into one-hot vectors.","20c9c2c8":"The next set of code is meant to prepare the images to be used for the training. It changes their shape and converts it into an array.","c9bb6a7c":"# Whale Identification using CNN","fce92ca4":"Now let's open one of the images in the training set to see how they look like."}}