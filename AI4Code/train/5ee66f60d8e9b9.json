{"cell_type":{"95f11b65":"code","8903c4e2":"code","686f4ccd":"code","7b7944ea":"code","9c529bd6":"code","d548a1c8":"code","aec446b4":"code","97d772a6":"code","befe15c1":"code","e4c09471":"code","bf4e5cce":"code","ca904973":"code","73aff591":"code","36c120ce":"code","2604f478":"code","9893c1eb":"code","7937d021":"code","fb5c2801":"code","6fa2f9c6":"code","c5c138af":"code","0717b267":"code","a7054a60":"code","bff0c430":"code","38e032bb":"code","187b5872":"code","b65025eb":"code","76bebff6":"code","2e7a4661":"code","f51f9fe4":"code","905f109e":"code","556ea4b1":"code","abea8ee8":"code","1a26ee54":"code","40219cab":"code","a64c273a":"code","d448516b":"code","a59b0787":"code","53144ad9":"code","fff4d98c":"code","4a94ec14":"code","7304bb8d":"code","4dbaf0f9":"code","d82f0799":"code","66cff507":"code","56303fad":"code","ee5eb670":"code","1e271a00":"code","84063d09":"code","c6bd8762":"code","332a28e4":"code","11e64143":"code","e183364a":"code","f0f72ed2":"code","eca61717":"code","a49d319d":"code","ccd6dcbc":"code","fc75bc7e":"code","2ade4ae6":"code","2b68f777":"code","b66cb323":"code","c96489c0":"code","8249a479":"code","4d055e82":"code","7581c5d2":"code","452e6501":"code","e11dc3be":"code","df666dd5":"code","af82cf0b":"code","b86c1760":"code","61d9e34e":"code","d5aadaef":"code","f6fa9fe2":"code","3de6512b":"code","fd736fbd":"code","ae247416":"code","915dfeca":"code","257981ab":"code","ddf2e54a":"code","a0842c21":"markdown","877d7b78":"markdown","d72c95b4":"markdown","953b2027":"markdown","7dedbb77":"markdown","459bc63a":"markdown","9f3c24cc":"markdown","d38cc5ab":"markdown","3dbe3103":"markdown","64ad0397":"markdown","f601b8c3":"markdown","f4ee7f48":"markdown","7587b9ef":"markdown","45353d43":"markdown","7718d575":"markdown","8ea52d07":"markdown","6d350f6b":"markdown","e25b512d":"markdown","cc07ef55":"markdown","c2f51b38":"markdown"},"source":{"95f11b65":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8903c4e2":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report, roc_auc_score, make_scorer, accuracy_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC \nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom kmodes.kmodes import KModes\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform as sp_uniform\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.metrics.pairwise import pairwise_kernels\nfrom sklearn.metrics.pairwise  import cosine_similarity\nfrom sklearn.metrics.pairwise import chi2_kernel\nfrom sklearn.feature_selection import SelectFromModel","686f4ccd":"pd.set_option('display.max_rows', None)","7b7944ea":"train= pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv', sep=',')\nsub_sample = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/sample_submission.csv', sep=',')\ntest= pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv', sep=',')","9c529bd6":"test.info()","d548a1c8":"print(train.shape, test.shape, sub_sample.shape)","aec446b4":"train.info()","97d772a6":"train.head()","befe15c1":"train.isna().sum()","e4c09471":"train.describe()","bf4e5cce":"train = train.set_index('PassengerId')","ca904973":"#Df with train + test data\ndfg = pd.concat([train, test], axis=0)","73aff591":"dfg['Age'].median()","36c120ce":"train['Age'] = train['Age'].replace(np.nan, dfg['Age'].median())","2604f478":"train['Age'] = round(train['Age'],0)","9893c1eb":"bins = ['Y1', 'Y2', 'Y3', 'Y4', 'M1', 'M2', 'E']\ntrain['Age_Bin'] = pd.cut(x=train['Age'],\n                            bins=[0, 5 , 10, 15, 20, 30, 50,1000],\n                            labels=bins,right=False)\ntrain['Age_Bin'] = train['Age_Bin'].astype('str')\ntrain['Age_Bin'] = train['Age_Bin']+train['Sex']\ndf_Age_bin = pd.get_dummies(train['Age_Bin'], prefix='Age_bin')","7937d021":"dfg['Age_Bin'] = pd.cut(x=dfg['Age'],\n                            bins=[0, 5 , 10, 15, 20, 30, 50,1000],\n                            labels=bins,right=False)\ndfg.groupby(by=['Sex','Pclass'])['Fare'].median()","fb5c2801":"train.loc[(train['Fare'].isna()) & (train['Pclass']==1) & (train['Sex']=='female'), 'Fare']=85.40\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==2) & (train['Sex']=='female'), 'Fare']=24.75\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==3) & (train['Sex']=='female'), 'Fare']=12.54\n\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==1) & (train['Sex']=='male'), 'Fare']=64.51\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==2) & (train['Sex']=='male'), 'Fare']=14.23\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==3) & (train['Sex']=='male'), 'Fare']=11.02","6fa2f9c6":"bins2 = ['L1', 'L2', 'L3', 'L4']\ntrain['Fare_Bin'] = pd.cut(x=train['Fare'],\n                            bins=[0,11, 30 , 60, 10000],\n                            labels=bins2,right=False)","c5c138af":"train['Fare_Bin'] = train['Fare_Bin'].astype('str')\ndf_Fare_bin = pd.get_dummies(train['Fare_Bin'], prefix='Fare_bin')\ndf_Fare_bin.head()","0717b267":"dfg['Cabin'] =dfg['Cabin'].str[0]","a7054a60":"dfg['Cabin'].value_counts()","bff0c430":"train['Cabin'] =train['Cabin'].str[0]","38e032bb":"train['Cabin'] = train['Cabin'].fillna('Z')","187b5872":"train.groupby(by=['Cabin'])['Survived'].mean()","b65025eb":"train.loc[(train['Cabin']=='T'), 'Cabin']='Z'","76bebff6":"df_cabin = pd.get_dummies(train['Cabin'], prefix='Cabin')","2e7a4661":"train.groupby(by=['Embarked'])[['Fare','Survived']].mean()","f51f9fe4":"train[train['Embarked'].isna()].groupby(by=['Pclass'])['Survived'].mean()","905f109e":"#Used the most frequent caracter\ntrain['Embarked'] = train['Embarked'].fillna('S')","556ea4b1":"df_embarked = pd.get_dummies(train['Embarked'], prefix='Embark')","abea8ee8":"train['Ticket'] = train['Ticket'].str.replace('[^a-zA-Z]', '').str[:1]\ntrain['Ticket'] = train['Ticket'].str.strip()","1a26ee54":"train['Ticket'] = train['Ticket'].fillna('ZZ')","40219cab":"train.loc[train['Ticket']=='', 'Ticket']='ZZ'","a64c273a":"train.loc[train['Ticket']=='L', 'Ticket']='ZZ'","d448516b":"train.groupby(by=['Ticket'])['Survived'].mean()","a59b0787":"train['Ticket'].value_counts()","53144ad9":"df_tiket = pd.get_dummies(train['Ticket'], prefix='ticket')","fff4d98c":"df_name = pd.concat([train['Name'], test['Name']], axis=0)\ndf_name = pd.DataFrame(df_name, columns=['Name'])","4a94ec14":"df_name['FirstName'] = df_name['Name'].apply(lambda x:x.split(', ')[0])\ndf_name['SecondName'] = df_name['Name'].str.split(', ', 1, expand=True)[1]","7304bb8d":"le = LabelEncoder()\nle1 = LabelEncoder()\ndf_name['FirstName'] = le.fit_transform(df_name['FirstName'])\ndf_name['SecondName'] = le1.fit_transform(df_name['SecondName'])","4dbaf0f9":"train['FirstName'] = train['Name'].apply(lambda x:x.split(', ')[0])\ntrain['SecondName'] = train['Name'].str.split(', ', 1, expand=True)[1]","d82f0799":"train['FirstName'] = le.transform(train['FirstName'])\ntrain['SecondName'] = le1.transform(train['SecondName'])","66cff507":"train['Sex'] = train['Sex'].apply(lambda x: 1 if x=='female' else 0)","56303fad":"train['Sex'].value_counts()","ee5eb670":"train['Pclass'] = train['Pclass'].astype('str')\ndf_pclass = pd.get_dummies(train['Pclass'], prefix='class')","1e271a00":"df_pclass.head()","84063d09":"# introducing a new feature : the size of families (including the passenger)\ntrain['FamilySize'] = train['Parch'] + train['SibSp'] + 1","c6bd8762":"# introducing other features based on the family size\ntrain['Singleton'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallFamily'] = train['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\ntrain['LargeFamily'] = train['FamilySize'].map(lambda s: 1 if 5 <= s else 0)","332a28e4":"df = pd.concat([train['Fare'], train['Age'],train['FamilySize'], train['Singleton'], train['SmallFamily'], train['LargeFamily'],train['Sex'], df_cabin,df_tiket, df_pclass, df_embarked ,train['FirstName'],train['SecondName'],df_Age_bin,df_Fare_bin,train['Survived']], axis=1)","11e64143":"df.columns","e183364a":"plt.figure(figsize=(15,10))\nsns.heatmap(data=df.corr())","f0f72ed2":"df = df.drop(columns='Survived')","eca61717":"km = KMeans(n_clusters=3, random_state=22, n_init=20)\ndf_km = km.fit_predict(df)\ndf_km = pd.DataFrame(df_km, index=df.index)\ndf_km = df_km.astype('str')\ndf_km = pd.get_dummies(df_km)","a49d319d":"df_km.head()","ccd6dcbc":"df = pd.concat([df, df_km], axis=1)","fc75bc7e":"df_target = train['Survived']","2ade4ae6":"clf = RandomForestClassifier(n_estimators=200, max_features='sqrt')\nclf = clf.fit(df, df_target)","2b68f777":"features = pd.DataFrame()\nfeatures['feature'] = df.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(25, 25))","b66cb323":"import optuna","c96489c0":"def objective(trial , data = df , target = df_target):\n    train_x , test_x , train_y , test_y = train_test_split(data , target , \\\n            test_size = 0.028059109276941666 , random_state = 2)\n\n    #test_size = 0.028059109276941666\n    params = {\n        'reg_alpha' : trial.suggest_loguniform('reg_alpha' , 1e-5 , 12),\n        'reg_lambda' : trial.suggest_loguniform('reg_lambda' , 1e-5 , 12),\n        'num_leaves' : trial.suggest_int('num_leaves' , 11 , 900),\n        'learning_rate' : trial.suggest_uniform('learning_rate' , 0.0000001 , 0.2),\n        'max_depth' : trial.suggest_int('max_depth' , 5 , 400),\n        'n_estimators' : trial.suggest_int('n_estimators' , 1 , 9999),\n        'min_child_samples' : trial.suggest_int('min_child_samples' , 1 , 110),\n        'min_child_weight' : trial.suggest_loguniform('min_child_weight' , 1e-5 , 1),\n        'subsample' : trial.suggest_uniform('subsample' , 1e-5 , 1.0),\n        'colsample_bytree' : trial.suggest_loguniform('colsample_bytree' , 1e-5 , 1),\n        'random_state' : trial.suggest_categorical('random_state' , [2,22,222,2222]),\n        'metric' : 'accuracy',\n        'device_type' : 'cpu',\n    }\n    model = lightgbm.LGBMClassifier(**params)\n    model.fit(train_x , train_y , eval_set = [(test_x , test_y)] ,eval_metric='logloss', early_stopping_rounds = 3000 , \\\n             verbose = False)\n    preds = model.predict(test_x)\n    acc = accuracy_score(test_y , preds)\n    return acc","8249a479":"study = optuna.create_study(direction = 'maximize' , study_name = 'lgbm')\nstudy.optimize(objective , n_trials = 1)\nprint('numbers of the finished trials:' , len(study.trials))\nprint('the best params:' , study.best_trial.params)\nprint('the best value:' , study.best_value)","4d055e82":"#the best value: 0.7808267997148967\nparams= {'reg_alpha': 0.000493095633250276, 'reg_lambda': 0.2799468729577344, 'num_leaves': 220, 'learning_rate': 0.058683299033376934, 'max_depth': 97, 'n_estimators': 9161, 'min_child_samples': 108, 'min_child_weight': 1.7359084365325016e-05, 'subsample': 0.7381682823837273, 'colsample_bytree': 0.29845810314125426, 'random_state': 1509}","7581c5d2":"#the best value: 0.7811831789023521\nparams2 = {'reg_alpha': 0.02242367265240423, 'reg_lambda': 0.0006085533155144086, 'num_leaves': 238, 'learning_rate': 0.03240605916351265, 'max_depth': 65, 'n_estimators': 5361, 'min_child_samples': 27, 'min_child_weight': 0.00011308353926700071, 'subsample': 0.5688435861948473, 'colsample_bytree': 0.06746586089945723, 'random_state': 22}","452e6501":"#the best value: 0.7804704205274412\nparams1= {'reg_alpha': 0.009415444471348289, 'reg_lambda': 1.2556528225033043, 'num_leaves': 25, 'learning_rate': 0.00835886426230468, 'max_depth': 230, 'n_estimators': 3653, 'min_child_samples': 9, 'min_child_weight': 0.0002224399318225647, 'subsample': 0.9780174338845454, 'colsample_bytree': 0.7969641118752326, 'random_state': 1}","e11dc3be":"test = test.set_index('PassengerId')\n\n#Age\ntest['Age'] = test['Age'].replace(np.nan, dfg['Age'].median())\ntest['Age_Bin'] = pd.cut(x=test['Age'],\n                            bins=[0, 5 , 10, 15, 20, 30, 50,1000],\n                            labels=bins,right=False)\ntest['Age_Bin'] = test['Age_Bin'].astype('str')\ntest['Age_Bin'] = test['Age_Bin']+test['Sex']\ndft_Age_bin = pd.get_dummies(test['Age_Bin'], prefix='Age_bin')\n\n\n#Fare\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==1) & (test['Sex']=='female'), 'Fare']=85.40\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==2) & (test['Sex']=='female'), 'Fare']=24.75\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==3) & (test['Sex']=='female'), 'Fare']=12.54\n\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==1) & (test['Sex']=='male'), 'Fare']=64.51\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==2) & (test['Sex']=='male'), 'Fare']=14.23\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==3) & (test['Sex']=='male'), 'Fare']=11.02\n\ntest['Fare_Bin'] = pd.cut(x=test['Fare'],\n                            bins=[0,11, 30 , 60, 10000],\n                            labels=bins2,right=False)\n\ntest['Fare_Bin'] = test['Fare_Bin'].astype('str')\ndft_Fare_bin = pd.get_dummies(test['Fare_Bin'], prefix='Fare_bin')\n\n\n#Cabin\ntest['Cabin'] =test['Cabin'].str[0]\ntest['Cabin'] = test['Cabin'].fillna('Z')\ntest.loc[(test['Cabin']=='T'), 'Cabin']='Z'\ndft_cabin = pd.get_dummies(test['Cabin'], prefix='Cabin')\n\n#Embarked\ntest['Embarked'] = test['Embarked'].fillna('S')\ndft_embarked = pd.get_dummies(test['Embarked'], prefix='Embark')\n\n#Ticket\ntest['Ticket'] = test['Ticket'].str.replace('[^a-zA-Z]', '').str[:1]\ntest['Ticket'] = test['Ticket'].str.strip()\ntest['Ticket'] = test['Ticket'].fillna('ZZ')\ntest.loc[test['Ticket']=='', 'Ticket']='ZZ'\ntest.loc[test['Ticket']=='L', 'Ticket']='ZZ'\ndft_tiket = pd.get_dummies(test['Ticket'], prefix='ticket')\n\n#Name\ntest['FirstName'] = test['Name'].apply(lambda x:x.split(', ')[0])\ntest['SecondName'] = test['Name'].str.split(', ', 1, expand=True)[1]\n\ntest['FirstName'] = le.transform(test['FirstName'])\ntest['SecondName'] = le1.transform(test['SecondName'])\n\n#Sex\ntest['Sex'] = test['Sex'].apply(lambda x: 1 if x=='female' else 0)\n\n#Pclass\ntest['Pclass'] = test['Pclass'].astype('str')\ndft_pclass = pd.get_dummies(test['Pclass'], prefix='class')\n\n#Family Size\ntest['FamilySize'] = test['Parch'] + test['SibSp'] + 1\n\ntest['Singleton'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallFamily'] = test['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\ntest['LargeFamily'] = test['FamilySize'].map(lambda s: 1 if 5 <= s else 0)","df666dd5":"dft = pd.concat([test['Fare'], test['Age'],test['FamilySize'], test['Singleton'], test['SmallFamily'], test['LargeFamily'], test['Sex'],dft_cabin,dft_tiket, dft_pclass, dft_embarked, test['FirstName'],test['SecondName'], dft_Age_bin, dft_Fare_bin], axis=1)","af82cf0b":"dft_km = km.predict(dft)\ndft_km = pd.DataFrame(dft_km, index=dft.index)\ndft_km = dft_km.astype('str')\ndft_km = pd.get_dummies(dft_km)","b86c1760":"dft = pd.concat([dft, dft_km], axis=1)","61d9e34e":"len(dft.columns)","d5aadaef":"len(df.columns)","f6fa9fe2":"list(set(df.columns)-set(dft.columns))","3de6512b":"df_target.head()","fd736fbd":"params1['metric'] = 'accuracy'\nparams1['device'] = 'cpu'\npreds = np.zeros(dft.shape[0])\noof_preds = np.zeros(df.shape[0])\nkf = StratifiedKFold(n_splits = 50 , random_state = 22 , shuffle = True)\nroc = []\nn = 0\nfor trn_idx , val_idx in kf.split(df , df_target):\n    train_x = df.iloc[trn_idx]\n    train_y = df_target.iloc[trn_idx]\n    val_x = df.iloc[val_idx]\n    val_y = df_target.iloc[val_idx]\n    \n    model = lightgbm.LGBMClassifier(**params1)\n    model.fit(train_x , train_y , eval_set = [(val_x , val_y)] ,eval_metric='logloss', early_stopping_rounds = 8000 , verbose = False)\n    clf = CalibratedClassifierCV(model, cv='prefit', method='sigmoid')\n    clf.fit(train_x , train_y)\n    preds += clf.predict_proba(dft)[:,1]\/kf.n_splits\n    oof_preds += clf.predict_proba(df)[:,1]\/kf.n_splits\n    roc.append(accuracy_score(val_y , clf.predict(val_x)))\n    fpr, tpr, thresholds = roc_curve(val_y , clf.predict_proba(val_x)[:,1])\n    gmeans = np.sqrt(tpr * (1-fpr))\n    ix = np.argmax(gmeans)\n    print(n+1 , roc[n], 'Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n    n+=1","ae247416":"fpr, tpr, thresholds = roc_curve(df_target , oof_preds)\ngmeans = np.sqrt(tpr * (1-fpr))\nix = np.argmax(gmeans)\nthresholds[ix]","915dfeca":"sub_sample['Survived'] = preds","257981ab":"#simple threshold 0.405749\nsub_sample['Survived'] = sub_sample['Survived'].apply(lambda x: 1 if x>0.43147162440098286 else 0)","ddf2e54a":"sub_sample.to_csv('submission.csv',index=False)","a0842c21":"Handling \"Name\"","877d7b78":"Get the Fatures related to Family size. An idea taken from:\nhttps:\/\/medium.datadriveninvestor.com\/start-with-kaggle-a-comprehensive-guide-to-solve-the-titanic-challenge-8ac5815b0473","d72c95b4":"Analysis of possible strategy to fillna for Embarked field.\nSince the Passenger Class seems to be correlated to the possibility to Survive. 3 different embark classes will be created to fillna","953b2027":"## Load Data","7dedbb77":"### Utils","459bc63a":"Encoding the sex feature","9f3c24cc":"Removed L because of few instances","d38cc5ab":"# Using Optuna with Lgbm","3dbe3103":"Handle missing data in \"Fare\" field","64ad0397":"Remove T because of few instances","f601b8c3":"Convert '' with NN","f4ee7f48":"#Create a complex Feature that includes Age_bin, Sex","7587b9ef":"For Cabin Feature, estract only the first letter, then fillna with Z","45353d43":"using the Median to fill all the NAN for Age","7718d575":"Convert NAN to ZZ","8ea52d07":"Keep only the first letter for ticket and replace space with N and nan wi1th ZZ","6d350f6b":"### Data Preprocessing","e25b512d":"## Preprocessing the Test_set","cc07ef55":"One Hot encoder for Pclass","c2f51b38":"Adding 3 more features with Kmeans"}}