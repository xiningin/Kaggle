{"cell_type":{"ae3a5b3f":"code","7684f3ba":"code","fe1ef97f":"code","281bed3b":"code","026e590a":"code","16092326":"code","201564f5":"code","5a4597e3":"code","345b156d":"code","882235d2":"code","9871db53":"code","7682aea6":"code","a0fea78e":"code","fdc301fa":"code","773fc8f3":"code","346bfa91":"code","fcca0017":"code","c275a2fc":"code","d10240ae":"code","74f01ef3":"code","da9494cf":"code","52b1ecc7":"code","59735d27":"code","6709d2c0":"code","40b785c7":"code","b973d51f":"markdown","fb901e99":"markdown","459d9576":"markdown","1a20b264":"markdown"},"source":{"ae3a5b3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7684f3ba":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","fe1ef97f":"data=pd.read_csv('..\/input\/graduate-admissions\/Admission_Predict.csv')\ndata.head()","281bed3b":"# check the shape\ndata.shape","026e590a":"# check the datatypes\ndata.info()","16092326":"# let's drop Serial no. column\ndata.drop('Serial No.', axis=1, inplace=True)","201564f5":"data.head()","5a4597e3":"# let's check missing values\ndata.isnull().sum()","345b156d":"data.describe()","882235d2":"for feature in data.columns:\n    plt.figure(figsize=(16,5))\n    sns.distplot(data[feature])\n    plt.show()","9871db53":"from sklearn.linear_model import LinearRegression\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","7682aea6":"data.head()","a0fea78e":"data.columns=[x.strip(\" \") for x in data.columns]","fdc301fa":"X=data.drop('Chance of Admit', axis=1)\ny=data['Chance of Admit']\n","773fc8f3":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","346bfa91":"# Let's apply transformation\nsc=StandardScaler()\nX_train_tx=sc.fit_transform(X_train)\nX_test_tx=sc.transform(X_test)","fcca0017":"pca=PCA(n_components=2)\nX_train_tx_pca=pca.fit_transform(X_train_tx)\nX_test_tx_pca=pca.transform(X_test_tx)","c275a2fc":"X_train_tx_pca=pd.DataFrame(X_train_tx_pca, columns=['PC1', 'PC2'])\nX_train_tx_pca.head()","d10240ae":"sns.scatterplot(X_train_tx_pca['PC1'], X_train_tx_pca['PC2'])","74f01ef3":"pca_max=np.argmax(X_train_tx_pca['PC1'])\npca_min=np.argmin(X_train_tx_pca['PC2'])","da9494cf":"pca_max, pca_min","52b1ecc7":"X_train.loc[pca_max, :]","59735d27":"X_train.iloc[pca_min, :]","6709d2c0":"X_train_tx_pca","40b785c7":"lin_reg=LinearRegression()\nlin_reg.fit(X_train_tx, y_train)\ny_pred=lin_reg.predict(X_test_tx)\n\nprint(\"Score: \", lin_reg.score(X_test_tx, y_test))","b973d51f":"It seems there are some spaces in the column names, let's remove them","fb901e99":"No null values :)","459d9576":"It clearly shows PC1 minimum implies high GRE scores and high PC1 implies low GRE scores ","1a20b264":":) so all numerical columns hence no need for categorical encoding"}}