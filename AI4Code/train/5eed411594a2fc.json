{"cell_type":{"1f6ee365":"code","0ff16c65":"code","cdb1c5ac":"code","dfc24d74":"code","685d0aff":"code","d90d67e7":"code","b7b31d68":"code","4c7fa6d8":"code","41b8a8cd":"code","1a92b131":"markdown","129e26f9":"markdown","4572ebde":"markdown"},"source":{"1f6ee365":"!pip install loguru\n!pip install nlpaug","0ff16c65":"import random\nimport os\nimport logging\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport nlpaug.augmenter.word as naw\nimport nlpaug.augmenter.sentence as nas\nfrom tqdm.notebook import tqdm\nfrom loguru import logger\nrandom.seed(13)\n\nlogger.add(\"commonlit_nlp_aug.log\")","cdb1c5ac":"train = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/train.csv\", nrows=None)\ntest = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/test.csv\", nrows=None)\n\ntrain_aug = train[['id','excerpt','target','standard_error']].copy()\ntest_aug =  test[['id','excerpt']].copy()\ntrain_aug['id'] = train_aug['id'].apply(lambda x : \"aug_\"+str(x))\ntest_aug['id'] = test_aug['id'].apply(lambda x : \"aug_\"+str(x))","dfc24d74":"aug_word = naw.ContextualWordEmbsAug(model_path='bert-base-cased', verbose=1)","685d0aff":"class CommonLitWordAugmentor:\n    \"\"\"Augments sentences in paragraph with given probabilty\"\"\"\n    \n    def __init__(self, corpus=None):\n        self.para = None\n        self.corpus = None\n    \n    def augment(self, para, prob=0.4, verbose=False):\n        sentences = para.split(\".\")\n        count = 0\n        for idx in tqdm(range(0, len(sentences))):\n            randNum = random.random()\n            if randNum <= prob:\n                augmented_line = aug_word.augment(sentences[idx])\n                if verbose:\n                    logger.info(f\"Original : {sentences[idx]}\")\n                sentences[idx] = augmented_line\n                if verbose:\n                    logger.info(f\"Augmented : {sentences[idx]}\")\n                count+=1\n        if verbose:\n            print(f\">> Augmented {count} sentences\")\n        return \".\".join(sentences)\n    \n    def augment_corpus(self, corpus=None, prob=0.4, verbose=True):\n        self.corpus = corpus\n        augmented_paras = []\n        for para in tqdm(corpus, desc=\"Total Corpus Augmented\"):\n            sentences = para.split(\".\")\n            count = 0\n            for idx in range(0, len(sentences)):\n                randNum = random.random()\n                if randNum <= prob:\n                    augmented_line = aug_word.augment(sentences[idx])\n                    if verbose:\n                        logger.info(f\"Sent idx {idx} | Original : {sentences[idx]}\")\n                    sentences[idx] = augmented_line\n                    if verbose:\n                        logger.info(f\"Sent idx {idx} | Augmented : {sentences[idx]}\")\n                    count+=1\n            if verbose:\n                logger.info(f\">> Augmented {count} sentences\")\n            augmented_paras.append(\".\".join(sentences))\n        return augmented_paras","d90d67e7":"augmentor = CommonLitWordAugmentor()","b7b31d68":"train_augmented = augmentor.augment_corpus(train['excerpt'], prob=0.6)\ntest_augmented = augmentor.augment_corpus(test['excerpt'], prob=0.6)\n\ntrain_aug['aug_excerpt'] = train_augmented\ntest_aug['aug_excerpt'] = test_augmented","4c7fa6d8":"cols = ['id', 'excerpt','aug_excerpt','target', 'standard_error']\ntrain_aug[cols].head()","41b8a8cd":"train_aug[cols].to_csv(\"train_word_augmented.csv\", index=None)\ntest_aug.to_csv(\"test_word_augmented.csv\", index=None)","1a92b131":"## Loading Augmentator","129e26f9":"## Generating Word Augmentations On Sentence Splits","4572ebde":"## Original Data "}}