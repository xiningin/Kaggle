{"cell_type":{"e626c7c6":"code","3a23d92f":"code","bb723c4b":"code","ac7775b9":"code","64bfa8ac":"code","f4cc34b6":"code","21cafd4d":"code","63b96908":"code","6ce97c43":"code","4d40474a":"code","03938020":"code","5310d6ee":"code","596fbf67":"code","cf6dbdda":"code","8504b4bf":"code","9ece6798":"code","069fa024":"code","bc1d3c85":"code","0c3eac9e":"code","1c67f68c":"code","19ca2d59":"code","613c5af7":"code","24707981":"code","35490c47":"code","0afa9cc6":"code","11cc57dd":"code","1a11d363":"code","f5325bc5":"code","cbcc53ff":"code","716b0f53":"code","5604c66c":"code","92d5eaf8":"code","08a66ed0":"code","2a3fd036":"code","089d9504":"code","1cb238fd":"code","283ed77d":"code","72a242a4":"code","95fa9da8":"code","36b33ebf":"code","d22e651e":"code","ba4b234c":"code","8d147057":"code","823b0f44":"code","0c9c8c7d":"code","7e7af3dc":"code","06615bc4":"code","30102b4b":"code","f1cf9048":"code","87bbf267":"code","4df161c5":"code","0e8bf10e":"code","bc1d35d6":"code","05b5bcde":"code","b53ad755":"code","7236f44a":"code","5b523cff":"code","fd83b7f4":"code","6a7b0b61":"code","34f2c91b":"code","59654ea9":"code","a7d0eb32":"code","2d771020":"code","00641461":"code","7005463f":"code","34c2d0e6":"code","4d5944ce":"code","3cfde68e":"code","9a276f2d":"code","ebfe6dc1":"code","bcddcb5d":"code","525dbdf0":"code","dfe61c81":"code","2710b94c":"code","f86ca48e":"code","d1335dfd":"code","a1752770":"code","39b1dbf0":"markdown","9d65c26d":"markdown","dddd788b":"markdown","2370f375":"markdown","d3caf5fb":"markdown","20100f5c":"markdown","081f5642":"markdown","6ceecca6":"markdown","2fa922b3":"markdown","d209988e":"markdown","cff710dc":"markdown","d9c9bea7":"markdown","7ecb758e":"markdown","6bfba07e":"markdown","e136530c":"markdown","c2fa93c7":"markdown","0b673ab5":"markdown","6d3a28c8":"markdown","1f25d476":"markdown","ffdf88a3":"markdown","5d90374c":"markdown"},"source":{"e626c7c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3a23d92f":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport statsmodels\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso, Ridge\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import scale, RobustScaler","bb723c4b":"# Printin the version of the libraries used so that the replication of the notebook can be done easily\nprint(f\"Numpy version : Numpy {np.__version__}\")\nprint(f\"Statsmodel version : Statsmodels {statsmodels.__version__}\")\nprint(f\"Pandas version : Pandas {pd.__version__}\")\nprint(f\"Matplotlib version : Matplotlib {matplotlib.__version__}\")\nprint(f\"Seaborn version : Seaborn {sns.__version__}\")","ac7775b9":"# Setting the pandas to display the maximum column avaliable\npd.set_option('display.max_columns', None)\n# Setting the style to the plot which will be plotted using Seaborn\nsns.set_style(\"darkgrid\")","64bfa8ac":"data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","f4cc34b6":"data.head()","21cafd4d":"test.head()","63b96908":"def detailed(data, threshold = 1):\n    '''\n    input:\n        data: the data for which we need to find the details and it should be in df form\n        threshold: the maximum premissble missing value in an column\n        \n    returns:\n            detailed_data, to_drop, imbalance_cols\n            the complete EDA of the dataset provided, and list of columns who have all values nan\n    \n    '''\n    ddata = pd.DataFrame(index=['total', '% missing' , 'data Type', 'range'])\n    to_drop = []\n    imbalance_cols = []\n    for cols in data.columns:\n        size = data[cols].size\n        # Finding the number of null present in the column         \n        pnul=round(data[cols].isna().sum()\/size,2)\n        nul_val = f\"{pnul*100}% - {data[cols].isna().sum()}\/{size}\"\n        if data[cols].isna().sum() == size:\n            to_drop.append(cols)\n        elif data[cols].isna().sum() >= int(size*threshold):\n            to_drop.append(cols)\n        # finding the Varibale type of the column\n        dtype = 'categorical' if data[cols].dtype == object else 'Numerical' \n        # Findig the range of the Data if numerical else finding the count of different labels        \n        rng = f\"{len(data[cols].unique())} labels\"\\\n        if dtype == 'categorical' else\\\n        f\"{round(data[cols].min(),2)}-{round(data[cols].max(),2)}\"\n        # Finding the most repeating value         \n#         max_value = data[cols].value_counts().index[0]\n        max_count = data[cols].value_counts().max()\n        # if there is same value all acroos the dataframe then we should drop it as it will cause baising\n        if max_count> int(size*0.85):\n            imbalance_cols.append(cols)\n        ddata[cols] = [size,nul_val,dtype,rng]\n    return ddata, to_drop, imbalance_cols","6ce97c43":"det,to_drop, imbalance_cols = detailed(data, threshold=0.9)","4d40474a":"det","03938020":"# dropping columns with most NaN's\ndata.drop(to_drop, axis=1, inplace=True)\ntest.drop(to_drop, axis=1, inplace=True)","5310d6ee":"def printing_repeating_values(data, imbalance_cols):\n    \n    for columns in imbalance_cols:\n        \n        print(data[columns].value_counts())\n    ","596fbf67":"printing_repeating_values(data, imbalance_cols)","cf6dbdda":"round(data.isna().sum()\/len(data),3).sort_values(ascending=False).head(20)","8504b4bf":"round(data.select_dtypes(include='object').isnull().sum()[data.select_dtypes(include='object').isnull().sum()>0]\/len(data),3)","9ece6798":"# These are the cols which have nan values and are categorical in nature\nnan_cols_cats = ['MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu', \n            'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'Fence', 'Electrical']","069fa024":"data[nan_cols_cats]=data[nan_cols_cats].fillna('None')","bc1d3c85":"data[nan_cols_cats].head()","0c3eac9e":"# Finding the columns which have repearing values\n_,_,imbalance_cols = detailed(data,0.9)","1c67f68c":"# Selecting only those columns which are categorical in nature\nrep_cols = data[imbalance_cols].select_dtypes(include='object').columns","19ca2d59":"# Dropping the repearing values cols which are categorical in nature\ndata.drop(rep_cols, axis=1, inplace=True)","613c5af7":"data.select_dtypes(include=['int64','float']).isnull().sum()[data.select_dtypes(include=['int64','float']).isnull().sum()>0]","24707981":"data.LotFrontage.fillna(data.LotFrontage.median(), inplace=True)\ndata.MasVnrArea.fillna(data.MasVnrArea.median(), inplace=True)\ndata.GarageYrBlt.fillna(0, inplace=True)","35490c47":"data.GarageYrBlt=data.GarageYrBlt.astype(int)","0afa9cc6":"# We will create a derived column which will help us captur more information from the GarageYrBlt column\ndef process_garage(row):\n    \n    if row == 0 or (row>=1900 and row<2000):\n        return 0 \n    return 1","11cc57dd":"data['NeworOldGarage'] = data.GarageYrBlt.apply(process_garage)","1a11d363":"# we will create a derived column Remodelled which will tell us if the house is remodelled or not\ndef remodelled_check(row):\n    if row['YearBuilt'] == row['YearRemodAdd']:\n        return 0\n    elif row['YearBuilt']<row['YearRemodAdd']:\n        return 1\n    else:\n        return 2","f5325bc5":"data['Remodelled'] = data.apply(remodelled_check, axis=1)","cbcc53ff":"#  We will derive the column BuiltRemodelAge to find the age \ndef getAge(row):\n\n    if(row['YearBuilt'] == row['YearRemodAdd']):\n        return row['YrSold'] - row['YearBuilt']\n    else:\n        return row['YrSold'] - row['YearRemodAdd']","716b0f53":"data['BuiltRemodelAge']=data.apply(getAge, axis=1)\ndata = data[data['BuiltRemodelAge']>=0]","5604c66c":"data.drop(['YearBuilt', 'YearRemodAdd', 'YrSold', 'GarageYrBlt'], axis = 1, inplace=True)","92d5eaf8":"_,_,imb = detailed(data)","08a66ed0":"# we can see that all these coulms are of numerical type and have 85% simialr data so to reduce skewness we will drop them also we will drop MoSold\ndata[imb].select_dtypes(include=['float','int64'])","2a3fd036":"data.drop(imb, axis=1,inplace=True)","089d9504":"data['MoSold'].value_counts()","1cb238fd":"data.isna().sum()","283ed77d":"data[data.duplicated()]","72a242a4":"data.describe(percentiles=[.25,.5,.75,.95,.99])","95fa9da8":"plt.figure(figsize=(17, 20), dpi=120)\nplt.subplot(5,3,1)\nsns.boxplot(y = 'LotArea', data=data )\nplt.subplot(5,3,2)\nsns.boxplot(y = 'MasVnrArea', data=data )\nplt.subplot(5,3,3)\nsns.boxplot(y = 'TotalBsmtSF', data=data)\nplt.subplot(5,3,4)\nsns.boxplot(y = 'WoodDeckSF', data=data )\nplt.subplot(5,3,5)\nsns.boxplot(y = 'OpenPorchSF', data=data)\nplt.subplot(5,3,6)\nsns.boxenplot(y='LotFrontage', data=data)\nplt.show()","36b33ebf":"plt.figure(figsize=(17, 20), dpi=120)\nplt.subplot(5,3,1)\nsns.histplot(data['LotArea'],  kde=True)\nplt.subplot(5,3,2)\nsns.histplot(data['MasVnrArea'],  kde=True)\nplt.subplot(5,3,3)\nsns.histplot(data['TotalBsmtSF'],  kde=True)\nplt.subplot(5,3,4)\nsns.histplot(data['WoodDeckSF'],  kde=True)\nplt.subplot(5,3,5)\nsns.histplot(data['OpenPorchSF'],  kde=True)\nplt.subplot(5,3,6)\nsns.histplot(data['LotFrontage'],  kde=True)\nplt.show()","d22e651e":"# Removing Outliers\n\n# Removing values beyond 98% for LotArea\n\nnn_quartile_LotArea = data['LotArea'].quantile(0.98)\ndata = data[data[\"LotArea\"] < nn_quartile_LotArea]\n\n# Removing values beyond 98% for MasVnrArea\n\nnn_quartile_MasVnrArea = data['MasVnrArea'].quantile(0.98)\ndata = data[data[\"MasVnrArea\"] < nn_quartile_MasVnrArea]\n\n# Removing values beyond 99% for TotalBsmtSF\n\nnn_quartile_TotalBsmtSF = data['TotalBsmtSF'].quantile(0.99)\ndata = data[data[\"TotalBsmtSF\"] < nn_quartile_TotalBsmtSF]\n\n# Removing values beyond 99% for WoodDeckSF\n\nnn_quartile_WoodDeckSF = data['WoodDeckSF'].quantile(0.99)\ndata = data[data[\"WoodDeckSF\"] < nn_quartile_WoodDeckSF]\n\n# Removing values beyond 99% for OpenPorchSF\n\nnn_quartile_OpenPorchSF = data['OpenPorchSF'].quantile(0.99)\ndata = data[data[\"OpenPorchSF\"] < nn_quartile_OpenPorchSF]","ba4b234c":"plt.figure(figsize=(17, 20), dpi=120)\nplt.subplot(5,3,1)\nsns.boxplot(y = 'LotArea', data=data )\nplt.subplot(5,3,2)\nsns.boxplot(y = 'MasVnrArea', data=data )\nplt.subplot(5,3,3)\nsns.boxplot(y = 'TotalBsmtSF', data=data)\nplt.subplot(5,3,4)\nsns.boxplot(y = 'WoodDeckSF', data=data )\nplt.subplot(5,3,5)\nsns.boxplot(y = 'OpenPorchSF', data=data)\nplt.subplot(5,3,6)\nsns.boxenplot(y='LotFrontage', data=data)\nplt.show()","8d147057":"plt.figure(figsize=(17, 20), dpi=120)\nplt.subplot(5,3,1)\nsns.histplot(data['LotArea'],  kde=True)\nplt.subplot(5,3,2)\nsns.histplot(data['MasVnrArea'],  kde=True)\nplt.subplot(5,3,3)\nsns.histplot(data['TotalBsmtSF'],  kde=True)\nplt.subplot(5,3,4)\nsns.histplot(data['WoodDeckSF'],  kde=True)\nplt.subplot(5,3,5)\nsns.histplot(data['OpenPorchSF'],  kde=True)\nplt.subplot(5,3,6)\nsns.histplot(data['LotFrontage'],  kde=True)\nplt.show()","823b0f44":"# visulizing the SalesPrice\nplt.figure(dpi=90)\nsns.histplot(np.log1p(data['SalePrice']), kde=True, bins=15)","0c9c8c7d":"# convering the price into natural log \ndata['SalePrice']=np.log1p(data['SalePrice'])","7e7af3dc":"qualitative = [f for f in data.columns if data.dtypes[f] == 'object']\ndef boxplot(x, y, **kwargs):\n    sns.boxplot(x=x, y=y)\n    x=plt.xticks(rotation=90)\nf = pd.melt(data, id_vars=['SalePrice'], value_vars=qualitative)\nplt.figure(dpi=90)\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False, height=5)\ng = g.map(boxplot, \"value\", \"SalePrice\")","06615bc4":"plt.figure(figsize=[20,20], dpi=90)\nsns.heatmap(data.corr(), annot=True)","30102b4b":"data.drop(['TotRmsAbvGrd', 'GarageArea'], axis = 1, inplace = True)","f1cf9048":"data['d_LotShape'] = data['LotShape'].map({'Reg': 3, 'IR1': 2, 'IR2': 1, 'IR3': 0})\ndata['d_ExterQual'] = data['ExterQual'].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'None': 0 })\ndata['d_BsmtQual'] = data['BsmtQual'].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'None': 0})\ndata['d_BsmtExposure'] = data['BsmtExposure'].map({'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'None': 0})\ndata['d_BsmtFinType1'] = data['BsmtFinType1'].map({'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, \n                                                                 'None': 0})\ndata['d_HeatingQC'] = data['HeatingQC'].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'None': 0})\ndata['d_KitchenQual'] = data['KitchenQual'].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'None': 0})\ndata['d_FireplaceQu'] = data['FireplaceQu'].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'None': 0})\ndata['d_GarageFinish'] = data['GarageFinish'].map({'Fin': 3, 'RFn': 2, 'Unf': 1, 'None': 0 })\ndata['d_BldgType'] = data['BldgType'].map({'Twnhs': 5, 'TwnhsE': 4, 'Duplex': 3, '2fmCon': 2, '1Fam': 1, \n                                                                 'None': 0 })\ndata['d_HouseStyle'] = data['HouseStyle'].map({'SLvl': 8, 'SFoyer': 7, '2.5Fin': 6, '2.5Unf': 5, '2Story': 4, \n                                                                 '1.5Fin': 3, '1.5Unf': 2, '1Story': 1, 'None': 0 })\ndata['d_Fence'] = data['Fence'].map({'GdPrv': 4, 'GdWo': 3, 'MnPrv': 2, 'MnWw': 1, 'None': 0 })\ndata['d_LotConfig'] = data['LotConfig'].map({'Inside': 5, 'Corner': 4, 'CulDSac': 3, 'FR2': 2, 'FR3': 1, \n                                                           'None': 0  })\ndata['d_MasVnrType'] = data['MasVnrType'].map({'BrkCmn': 1, 'BrkFace': 1, 'CBlock': 1, 'Stone': 1, 'None': 0 })\ndata['d_SaleCondition'] = data['SaleCondition'].map({'Normal': 1, 'Partial': 1, 'Abnorml': 0, 'Family': 0, \n                                                                   'Alloca': 0, 'AdjLand': 0, 'None': 0})\ndata.head()","87bbf267":"data = data.drop(['Id', 'LotShape', 'ExterQual', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'HeatingQC', \n                                'KitchenQual', 'FireplaceQu', 'GarageFinish', 'BldgType', 'HouseStyle', 'Fence', \n                                'LotConfig', 'MasVnrType', 'SaleCondition'], axis=1)","4df161c5":"# Creating dummies for MSZoning\n\nd_MSZoning = pd.get_dummies(data['MSZoning'], prefix='MSZoning', drop_first = True)\n\n\n# Creating dummies for GarageType\n\nd_GarageType = pd.get_dummies(data['GarageType'], prefix='GarageType', drop_first = True)\n\n# Creating dummies for Neighborhood\n\nd_Neighborhood = pd.get_dummies(data['Neighborhood'], prefix='Neighborhood', drop_first = True)\n\n# Creating dummies for RoofStyle\n\nd_RoofStyle = pd.get_dummies(data['RoofStyle'], prefix='RoofStyle', drop_first = True)\n\n\n# Creating dummies for Exterior1st\n\nd_Exterior1st = pd.get_dummies(data['Exterior1st'], prefix='Exterior1st', drop_first = True)\n\n\n# Creating dummies for Exterior2nd\n\nd_Exterior2nd = pd.get_dummies(data['Exterior2nd'], prefix='Exterior2nd', drop_first = True)\n\n\n# Creating dummies for Foundation\n\nd_Foundation = pd.get_dummies(data['Foundation'], prefix='Foundation', drop_first = True)\n\n# Appending these dummy varibles to the main dataframe\n\ndata = pd.concat([data, d_MSZoning, d_Neighborhood, d_RoofStyle, d_Exterior1st, d_Exterior2nd, d_Foundation, d_GarageType], axis = 1)","0e8bf10e":"data.head()","bc1d35d6":"data = data.drop(['MSZoning', 'Neighborhood', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'Foundation', \n                                'GarageType'], axis=1)","05b5bcde":"data.info()","b53ad755":"detailed_new,_,_ = detailed(data)","7236f44a":"detailed_new","5b523cff":"X = data.drop(['SalePrice'], axis=1)\ny = data.SalePrice","fd83b7f4":"rs = RobustScaler()","6a7b0b61":"cols = X.columns\nX = pd.DataFrame(rs.fit_transform(X))\nX.columns = cols\nX.columns","34f2c91b":"np.random.seed(111)\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size = 0.3, random_state=42)","59654ea9":"LR = LinearRegression()","a7d0eb32":"rfe = RFE(LR)","2d771020":"rfe.fit(X_train, y_train)","00641461":"cols_selected = X_train.columns[rfe.support_]","7005463f":"temp_df = pd.DataFrame(list(zip(X_train.columns,rfe.support_,rfe.ranking_)), columns=['Variable', 'rfe_support', 'rfe_ranking'])\ntemp_df = temp_df.loc[temp_df['rfe_support'] == True]\ntemp_df.reset_index(drop=True, inplace=True)","34c2d0e6":"temp_df","4d5944ce":"X_train=X_train[cols_selected]\nX_test = X_test[cols_selected]","3cfde68e":"!pip install pycaret","9a276f2d":"from pycaret.regression import *","ebfe6dc1":"exp_1= setup(data= data, target = 'SalePrice', html = False, silent=True, session_id = 122)","bcddcb5d":"compare_models()","525dbdf0":"br = create_model('br')","dfe61c81":"tune_br = tune_model(br)","2710b94c":"plot_model(tune_br)","f86ca48e":"plot_model(tune_br, plot = 'error')","d1335dfd":"plot_model(tune_br, plot='feature')","a1752770":"predict_model(tune_br)","39b1dbf0":"### Treating outliers","9d65c26d":"### Scaling Feautures ","dddd788b":"#### Checking the duplicated values","2370f375":"###  Plotting Box plots to see the relationship between different variables and sale price","d3caf5fb":"### Feature Selection and elimination ","20100f5c":"## Now as we have derived the values from the above columns we will be dropping them","081f5642":"#### Selecting  only useful features ","6ceecca6":"## CREATING DATA FOR MODEL ","2fa922b3":"#### We can clearly see that Garage Area and Garage Cars show .89 and TotRmsAbvGrd and GrLivArea show .83 correlation","d209988e":"# MODEL BUIDLING AND EXPERIMENTING","cff710dc":"# DATA TRANSFORMATION ","d9c9bea7":"### We can cleary see that even after processing the data not all atributes are normally distributed, we shall handel them later in the analysis ","7ecb758e":"#### Now we can drop the columns from which we have extracted data","6bfba07e":"#### Checking missing values ","e136530c":"# DATA PREPROCESSING ","c2fa93c7":"#### We have create numrical values for the categorical variables and now we will drop these as we have extracted information out of them","0b673ab5":"### From the above data we can see that all the columns have been coverted into numerical ","6d3a28c8":"#### Error Rate ","1f25d476":"#### Feature importance Plot ","ffdf88a3":"### Now we will check the numerical value which have more than 85% similar values","5d90374c":"#### PLotting residuals of models "}}