{"cell_type":{"266b53a0":"code","411a5d52":"code","b22ec5d6":"code","e2568714":"code","5ef9b28c":"code","c1a6369e":"code","7c37e954":"code","ea9acfa0":"code","fb4d2878":"code","7a7be0d3":"markdown","62697f4d":"markdown","1f86e178":"markdown","b0242c58":"markdown","98c954ca":"markdown","8b0d7c12":"markdown","3728a260":"markdown","ebdecc89":"markdown","4399a7f3":"markdown","c06eca50":"markdown"},"source":{"266b53a0":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf.head()","411a5d52":"print ('Number of Rows :', df.shape[0])\nprint ('Number of Columns :', df.shape[1])\nprint ('Number of Patients with outcome 1 :', df.Outcome.sum())\nprint ('Event Rate :', round(df.Outcome.mean()*100,2) ,'%')","b22ec5d6":"df.describe()","e2568714":"from sklearn.model_selection import train_test_split\nX = df.to_numpy()[:,0:8] \nY = df.to_numpy()[:,8]\nseed = 42\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = seed)\nprint (f'Shape of Train Data : {X_train.shape}')\nprint (f'Shape of Test Data : {X_test.shape}')","5ef9b28c":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nmodel = Sequential([\n    Dense(24, input_dim = (8), activation = 'relu'),\n    Dense(12, activation = 'relu'),\n    Dense(1, activation = 'sigmoid'),\n])","c1a6369e":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nmodel.summary()","7c37e954":"history = model.fit(X_train, y_train, epochs=150, batch_size=32, verbose = 1)","ea9acfa0":"scores = model.evaluate(X_test, y_test)\nprint (f'{model.metrics_names[1]} : {round(scores[1]*100, 2)} %')","fb4d2878":"import matplotlib.pyplot as plt\n\n# Plotting loss\nplt.plot(history.history['loss'])\nplt.title('Binary Cross Entropy Loss on Train dataset')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()\n\n# Plotting accuracy metric\nplt.plot(history.history['accuracy'])\nplt.title('Accuracy on the train dataset')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.show()","7a7be0d3":"### Step 4: Fit Model\nWe can fit the model using the `fit()` method. We can also set the number of instances that are evaluated before a weight update in the network is performed called the **batch size** and set using the `batch_size` argument","62697f4d":"### 1.2 Splitting data in train and test\nHere we can use powerful `sklearn` library to randomly split the observations in the dataset into test and train. We'll also set the `seed` parameter to make splits reproducible","1f86e178":"## Step 2: Define the Model\n* Models in Keras are defined as a sequence of layers. We create a `Sequential` model and add layers one at a time. The first thing to get right is to ensure the input layer has the right number of inputs\n*  Fully connected layers are defined using the `Dense` class. We can specify the number of neurons in the layer as the first argument, specify the activation function using the `activation` argument","b0242c58":"#### Visualizing the defined architecture\nThis image was generated using [NN SVG](http:\/\/alexlenail.me\/NN-SVG\/index.html)","98c954ca":"### Step 5: Evaluate model\nWe can evaluate our model on validation dataset using the `evaluation()` function. This will generate a prediction for each input and output pair and collect scores, including the average loss and any metrics you have configured, such as accuracy","8b0d7c12":"### Bonus Step\nPlot the journey of loss and accuracy metric over epochs","3728a260":"# Building a simple NN model using Keras & TensorFlow\nThis notebook builds a very basic neural network model in five simple steps\n1. First we load the dataset and split it into train and validation datasets\n2. Next we define our model using Keras with TensorFlow as backend\n3. Then we compile our model by specifying loss function and optimizer\n4. Then we'll fit our model to the train dataset \n5. Lastly, we evaluate our model on the validation dataset","ebdecc89":"![NN Topology](https:\/\/lh3.googleusercontent.com\/AJVGX6WZOBaBKgMMa1FbYf63PToYEaQkaEzmHIiHPEmxyYVUOsUIjMfFj_ngLG-0h2ru9ZPzb6lY3kRObwg1Gj772nejf0HAt3R_AFeGAfa26ITViY9cl569XoS5SvhzNFu5oiiBOYp_Z5WGLsd54jL-po2VKuKsjXHJD0hmPONCysj1FAZFxR5FztCuLPLtN8KFsfpdWGh6MP7GSmWN0z8AH02RcRDePVNUxqhFb7SbKHVdD6qoRYy5UwwcixY9OnA5dsZ0VIkMBLRavzoMqjIUVwEr32XjG_NYTJgxPqYm_618Q-yC7caZuwo76-SdMwCRnLVkQvukkdf5l_OaYADRyjgA4SmAkHxrhxAD_ydIoIpqMSirOK-UH6ntvrfiAh5JD7r7vo_9kLDlxGGFGBKX2bFeZtb18FpaDEbJ08cg5PMNcjUDtVDmm8msXYd_rs4Hz1TirnWNPmkMQzEUTBaGTQxJFa4JasZoVrL2XQPfwIQGXJEL9Fwmyy63jSb-4ZRFvWekN4sqBSccNeLfnovY2VUlxSylAGKUmQng2pt9E_lxyEvjaXkU7ow-vH2C398q-U0_09GeZOZmjhohSfy9LyORw6s5qbGqDrFSLBytW5LrOrM57jGTYxYq-3P3bfGIGgexYkHmpkwSC46OT-OLOnmuR9yq78Lo0vvNn0iXsJ1gzQ9QI32nAXkFsHg=w1840-h676-no?authuser=0)","4399a7f3":"## Step 1: Data Prep\n\n### 1.1 Loading and describing dataset\nUsing `pandas` we'll load the dataset. We also see that all variables are numeric, so, will go ahead and generate basic stats like\n* the shape of dataset we are dealing with using `df.shape`\n* number of outcomes to total number of observations also called event rate\n* distribution of variables using `df.describe`","c06eca50":"## Step 3: Compile the model\nWe specify the loss function to use to evaluate a set of weights. We will use `binary_crossentropy` which is defined in Keras for binary classification problem. We also specify the optimizer used to search through different weights for the network. Here we will use `adam` optimizer"}}