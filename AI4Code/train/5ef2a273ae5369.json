{"cell_type":{"b90d875b":"code","1e9974ae":"markdown","d1b41400":"markdown","f3faee39":"markdown","d7f32ae3":"markdown","cba51ece":"markdown"},"source":{"b90d875b":"import torch\nfrom numpy import random\ndef create_db(quantity,probability):\n        return torch.rand(quantity)<probability\noriginal_db = create_db(10000,0.70)\nx = torch.mean(original_db.float())\nprint(\"Mean of original database is: \",x)\nprint()\nfirst_coin = (torch.rand(len(original_db))>0.5).float()\nsecond_coin = (torch.rand(len(original_db))>0.5).float()\ntricked_db = (original_db.float() * first_coin) + (1 - first_coin) * second_coin\nx = torch.mean(tricked_db.float())\nprint(\"Mean of tricked database is: \",x*2-0.5) #de-skewing","1e9974ae":"We got more or less accurate results, without affecting individual's privacy.","d1b41400":"Before asking a question, you ask them to flip a coin and you tell them you are not watching them. If the first flip of coin comes head, they should answer honestly, otherwise if there is tail, they should again flip the coin. And in the second flip of coin, if there comes head, Say yes, otherise No.","f3faee39":"The interesting thing here is that if people says yes, they cheated in their last exam and data gets leaked and teacher knows they did cheating, people have certain degree of plausible deniability, that they are only answering because of the coin flip.**","d7f32ae3":"Suppose you are doing a sensitive survey, say asking people if they cheated in the last exam at school, people may not answer honestly because it is a crime and if the data gets leaked and teacher knows they cheated in exam, teacher may fail them or punish them. So, there is an amazing technique called Randomized Response which adds noise to the database, without really affecting the accuracy much. ","cba51ece":"<h1>Randomized Response in Differential Privacy<\/h1>"}}