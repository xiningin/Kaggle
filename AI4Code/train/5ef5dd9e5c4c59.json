{"cell_type":{"7a1d3868":"code","fac5ac31":"code","2dfa1630":"code","8b3aa6ba":"code","51f5c8b1":"code","9f46eb2f":"code","ebc7f908":"code","c1874d3d":"code","ec3b2f77":"code","c789c5b2":"code","cf2250e6":"code","3a108020":"code","fb5abca7":"code","1b8b9fd2":"code","e36b630e":"code","fc039283":"code","127f2633":"markdown","88b525fa":"markdown"},"source":{"7a1d3868":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fac5ac31":"train_df = pd.read_csv(\"..\/input\/santander-customer-satisfaction\/train.csv\",encoding='latin-1')\nprint('dataset shape:', train_df.shape)\ntrain_df.head(3)","2dfa1630":"test_df = pd.read_csv(\"..\/input\/santander-customer-satisfaction\/test.csv\",encoding='latin-1')\nprint('dataset shape:', test_df.shape)\ntest_df.head(3)","8b3aa6ba":"train_df.info()","51f5c8b1":"print(train_df['TARGET'].value_counts())\n\nunsatisfied_cnt = train_df[train_df['TARGET'] == 1]['TARGET'].count()\ntotal_cnt = train_df['TARGET'].count()\n\nprint('unsatisfied Ratio {0:.2f}'.format((unsatisfied_cnt \/ total_cnt)))","9f46eb2f":"train_df.describe( )","ebc7f908":"print(train_df['var3'].value_counts( )[:10])","c1874d3d":"print(test_df['var3'].value_counts( )[:10])","ec3b2f77":"# var3 value replace -999999 to 2, Drop ID feature\ntrain_df['var3'].replace(-999999, 2, inplace=True)\ntrain_df.drop('ID',axis=1 , inplace=True)\n\ntest_df['var3'].replace(-999999, 2, inplace=True)\ntest_df.drop('ID',axis=1 , inplace=True)\n\n# Split feature, lable. \nX_features = train_df.iloc[:, :-1]\ny_labels = train_df.iloc[:, -1]\nprint('Feature data shape:{0}'.format(X_features.shape))\n\nX_test = test_df","c789c5b2":"from sklearn.model_selection import train_test_split\n# Split train, validation set \nX_train, X_val, y_train, y_val = train_test_split(X_features, y_labels,\n                                                    test_size=0.2, random_state=0)\ntrain_cnt = y_train.count()\nval_cnt = y_val.count()\nprint('train set Shape:{0}, val set Shape:{1}'.format(X_train.shape , X_val.shape))\n\nprint(' ratio of train set label')\nprint(y_train.value_counts()\/train_cnt)\nprint('\\n ratio of validation set label')\nprint(y_val.value_counts()\/val_cnt)","cf2250e6":"from xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\n# n_estimators: 500 \nxgb_clf = XGBClassifier(n_estimators=500, random_state=156)\n\n# evaluation: auc, early_stopping_roubnds: 100. \nxgb_clf.fit(X_train, y_train, early_stopping_rounds=100,\n            eval_metric=\"auc\", eval_set=[(X_train, y_train), (X_val, y_val)])\n\nxgb_roc_score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:,1],average='macro')\nprint('ROC AUC: {0:.4f}'.format(xgb_roc_score))","3a108020":"# n_estimators: 1000, learning_rate=0.02, reg_alpha=0.03. \nxgb_clf = XGBClassifier(n_estimators=1000, random_state=156, learning_rate=0.02, max_depth=7,\\\n                        min_child_weight=1, colsample_bytree=0.75, reg_alpha=0.03)\n\n# evaluation metric: auc, early stopping: 200  \nxgb_clf.fit(X_train, y_train, early_stopping_rounds=200, \n            eval_metric=\"auc\",eval_set=[(X_train, y_train), (X_val, y_val)])\n\nxgb_roc_score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:,1],average='macro')\nprint('ROC AUC: {0:.4f}'.format(xgb_roc_score))","fb5abca7":"from xgboost import plot_importance\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfig, ax = plt.subplots(1,1,figsize=(10,8))\nplot_importance(xgb_clf, ax=ax , max_num_features=20,height=0.4)","1b8b9fd2":"submission = pd.read_csv('..\/input\/santander-customer-satisfaction\/sample_submission.csv')\nsubmission.head()\n#finals_pred = xgb_clf.predict(X_test)\n\n#finals_pred","e36b630e":"target = xgb_clf.predict(X_test)\n\nsubmission['TARGET'] = target","fc039283":"submission.to_csv('submission.csv', index=False)","127f2633":"> Data Preprocessing","88b525fa":"> -999999 is a NaN -> Should replace or Drop it "}}