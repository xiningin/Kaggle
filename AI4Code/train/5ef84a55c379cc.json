{"cell_type":{"372c71b4":"code","689f8d02":"code","0e2b30a2":"code","83a6e99e":"code","0d69371b":"code","bcf26cdd":"code","318eba9b":"code","8cdb7666":"code","fd028296":"code","76d779b7":"code","f327d036":"code","dcd393c0":"code","c4a9d23c":"code","43a67011":"code","3bfe1688":"code","5a0504a4":"code","abfff2e9":"code","6d402898":"code","7ed22097":"code","5ee85a9d":"code","cb159b55":"code","e1908586":"code","74a8e685":"code","fdcbbd65":"code","4b5d945a":"code","a906dbbd":"code","0c024da4":"code","25407ead":"code","7fe2e698":"code","8b81f418":"code","202ff19b":"code","c90d8b84":"code","35aecd8a":"code","4308b38c":"code","0e2a1100":"code","a012812e":"code","10ae4215":"code","cfaa78c9":"code","9ec658f8":"code","81651146":"code","67b75b59":"code","2c91a879":"code","696e48fb":"code","b8f2359b":"code","1ebdc7f0":"code","6866dbe9":"code","0cc9b902":"code","7ddf2869":"code","66084971":"code","82eaabe2":"code","99c4cb4e":"code","0b0ce3d1":"code","5e011a7e":"code","7ca1aebd":"code","b1042de4":"code","93030f5d":"code","d56a4193":"code","98b9a839":"code","39de8a3c":"code","3c298f17":"code","0afebf76":"code","5000ba7c":"code","04776532":"code","3ac428fc":"code","31b93316":"code","e56c29b2":"code","b334c643":"code","876b1f53":"code","3c6593fa":"code","4b1ec378":"code","60fa4dc1":"code","4487c63e":"code","f6c539cc":"code","1535af3e":"code","93aef28d":"code","7cf8bd24":"code","10f15a48":"code","5f2d0d03":"code","aa7337d1":"code","d48d4a71":"code","29745155":"code","a3e0669d":"code","aaa1e6d8":"code","a7e0cbcc":"code","ad5319b6":"code","ec2f9fb9":"code","1c6059e1":"code","7999274a":"code","cebbe94d":"code","973d1548":"code","6fd44b9a":"code","c08c6b48":"code","aa079e31":"code","6ffcef48":"code","12c695b9":"code","986c76fe":"code","4b3fd798":"code","38792dd6":"code","7099808d":"code","5f918545":"code","e2307f64":"code","6d12f6c8":"code","52f3b45e":"code","69cc4582":"code","55a56b45":"code","4fb0e611":"code","150994ff":"code","724fa4a3":"code","729536d3":"code","232a279e":"markdown","47cb8cba":"markdown","ab7eb4b7":"markdown","aa8dac4e":"markdown","bf2af25d":"markdown","f98de642":"markdown","773a8575":"markdown","d664b59a":"markdown","3d06301a":"markdown","64a45d19":"markdown","6733039a":"markdown","ed833526":"markdown","de0bcf5e":"markdown","281e83f1":"markdown","e16ccd88":"markdown","0df6cc8d":"markdown","64881fb4":"markdown","6429f486":"markdown","6604f613":"markdown","a7eb2e5d":"markdown","6169f9ee":"markdown","c3113c97":"markdown","f61b3b84":"markdown","f0f64d10":"markdown","626a7408":"markdown","60cce443":"markdown","0585afbc":"markdown","4fa09ac1":"markdown","71634617":"markdown","57d9c8f9":"markdown","5ac4ba33":"markdown","a00bd53e":"markdown","7cedbec1":"markdown","cdb34bfb":"markdown","66451d69":"markdown","1e49eae2":"markdown","ca3f30f1":"markdown","6c612939":"markdown","ccbdf290":"markdown","1e1937d1":"markdown","3b6f4703":"markdown","4e3b6971":"markdown","96a5a5d5":"markdown","692e0358":"markdown","33fc88f1":"markdown","c4de1a6b":"markdown","e11de087":"markdown","5b322b48":"markdown","34c55ef6":"markdown","28bd2543":"markdown","231d1283":"markdown","61b3ae41":"markdown","b67267a1":"markdown","097e4a0d":"markdown","3bfdc4f3":"markdown","bef2e852":"markdown","f43d01e9":"markdown","b4f546f2":"markdown","ba49a117":"markdown","d32db018":"markdown","60fab3a9":"markdown","2c289c73":"markdown","95b22d46":"markdown","a5f0aef1":"markdown","394ae5c1":"markdown","38ea2ccb":"markdown","f81d81b6":"markdown","2a4dcfda":"markdown","8df3acf2":"markdown","6724c5f4":"markdown","46120b2f":"markdown","fda2f90b":"markdown","3ad415eb":"markdown","7fdd47b5":"markdown","dc64b2f9":"markdown","f741c8f5":"markdown","bfec33d5":"markdown","8ec5f6a6":"markdown","cae6170a":"markdown","0ecaa0fc":"markdown","f779137b":"markdown","c1a3aed9":"markdown","51d582d2":"markdown","2af27e3c":"markdown","3ded9211":"markdown","f219229e":"markdown","b8aa8e4a":"markdown","e1f5b810":"markdown","59e3ca0b":"markdown","9715e9ae":"markdown","b1656ab7":"markdown","3f830eaf":"markdown","93ab3226":"markdown","ce73684b":"markdown","eeeefa29":"markdown","e2956ff3":"markdown","d2612afb":"markdown","e7ccbdb5":"markdown","3992cb4a":"markdown","fac18cfe":"markdown","82106656":"markdown","aec0075f":"markdown","76151e9d":"markdown","8d5cf504":"markdown","dac49f3a":"markdown","538602ab":"markdown","cd7e389c":"markdown","98c00dfb":"markdown","bf9aa171":"markdown","cd6a69c8":"markdown","123bf0d8":"markdown","b9869123":"markdown","b8276b1c":"markdown","b593fa51":"markdown","7fbbf48f":"markdown","e772f8d9":"markdown","4673e819":"markdown","64c3e3b5":"markdown","105c5a9a":"markdown","7b7a0cbd":"markdown","461ef6ef":"markdown","4201a2c6":"markdown","da2a6e59":"markdown","35ec6c85":"markdown","ac212fee":"markdown","d8d6a99c":"markdown","806ce5c8":"markdown","8fe81fb4":"markdown","634aa9ba":"markdown","ef48dc32":"markdown","cc9d8f27":"markdown","159cf03f":"markdown","441ea8a1":"markdown","8d61a3fa":"markdown","8f57c06c":"markdown","a56da766":"markdown","f86e2313":"markdown"},"source":{"372c71b4":"import torch","689f8d02":"a = [1.0, 2.0, 1.0]","0e2b30a2":"a[0]","83a6e99e":"a[2] = 3.0\na","0d69371b":"a = torch.ones(3)  # Creates a one-dimensional tensor of size 3 filled with ones\na","bcf26cdd":"a[1]","318eba9b":"float(a[1])","8cdb7666":"a[2] = 2.0\na","fd028296":"points = torch.zeros(6)  # Using .zeros is just a way to get an appropriately sized array.\npoints[0] = 4.0          # We overwrite those zeros with the values we actually want.\npoints[1] = 1.0\npoints[2] = 5.0\npoints[3] = 3.0\npoints[4] = 2.0\npoints[5] = 1.0\npoints","76d779b7":"points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\npoints","f327d036":"float(points[0]), float(points[1])","dcd393c0":"points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\npoints","c4a9d23c":"points.shape","43a67011":"points = torch.zeros(3, 2)\npoints","3bfe1688":"points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\npoints","5a0504a4":"points[0, 1]","abfff2e9":"points[0]","6d402898":"some_list = list(range(6))\nsome_list[:]               # All elements in the list\nsome_list[1:4]             # From element 1 inclusive to element 4 exclusive\nsome_list[1:]              # From element 1 inclusive to the end of the list\nsome_list[:4]              # From the start of the list to element 4 exclusive\nsome_list[:-1]             # From the start of the list to one before the last element\nsome_list[1:4:2]           # From element 1 inclusive to element 4 exclusive, in steps of 2\nsome_list","7ed22097":"points[1:]                # All rows after the first; implicitly all columns\npoints[1:, :]             # All rows after the first; all columns\npoints[1:, 0]             # All rows after the first; first column\npoints[None]              # Adds a dimension of size 1 , just like unsqueeze","5ee85a9d":"img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\nweights = torch.tensor([0.2126, 0.7152, 0.0722])\nimg_t, weights","cb159b55":"batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]\nbatch_t","e1908586":"img_gray_naive = img_t.mean(-3)\nbatch_gray_naive = batch_t.mean(-3)\nimg_gray_naive.shape, batch_gray_naive.shape","74a8e685":"unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\nimg_weights = (img_t * unsqueezed_weights)\nbatch_weights = (batch_t * unsqueezed_weights)\nimg_gray_weighted = img_weights.sum(-3)\nbatch_gray_weighted = batch_weights.sum(-3)\nbatch_weights.shape, batch_t.shape, unsqueezed_weights.shape","fdcbbd65":"img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\nbatch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\nbatch_gray_weighted_fancy.shape","4b5d945a":"weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\nweights_named","a906dbbd":"img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\nbatch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\nprint(\"img named:\", img_named.shape, img_named.names)\nprint(\"batch named:\", batch_named.shape, batch_named.names)","0c024da4":"weights_aligned = weights_named.align_as(img_named)\nweights_aligned.shape, weights_aligned.names","25407ead":"gray_named = (img_named * weights_aligned).sum('channels')\ngray_named.shape, gray_named.names","7fe2e698":"# gray_named = (img_named[..., :3] * weights_named).sum('channels')","8b81f418":"gray_plain = gray_named.rename(None)\ngray_plain.shape, gray_plain.names","202ff19b":"double_points = torch.ones(10, 2, dtype=torch.double)\nshort_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)","c90d8b84":"short_points.dtype","35aecd8a":"double_points = torch.zeros(10, 2).double()\nshort_points = torch.ones(10, 2).short()","4308b38c":"double_points = torch.zeros(10, 2).to(torch.double)\nshort_points = torch.ones(10, 2).to(dtype=torch.short)","0e2a1100":"points_64 = torch.rand(5, dtype=torch.double)  # rand initializes the tensor elements to random numbers between 0 and 1 .\npoints_short = points_64.to(torch.short)\npoints_64 * points_short                       # works from PyTorch 1.3 onwards","a012812e":"a = torch.ones(3, 2)\na_t = torch.transpose(a, 0, 1)\n\na.shape, a_t.shape","10ae4215":"a = torch.ones(3, 2)\na_t = a.transpose(0, 1)\n\na.shape, a_t.shape","cfaa78c9":"points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\npoints.storage()","9ec658f8":"points_storage = points.storage()\npoints_storage[0]","81651146":"points.storage()[1]","67b75b59":"points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\npoints_storage = points.storage()\npoints_storage[0] = 2.0\npoints","2c91a879":"a = torch.ones(3, 2)\na","696e48fb":"a.zero_()\na","b8f2359b":"points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\nsecond_point = points[1]\nsecond_point.storage_offset()","1ebdc7f0":"second_point.size()","6866dbe9":"second_point.shape","0cc9b902":"points.stride()","7ddf2869":"second_point = points[1]\nsecond_point.size()","66084971":"second_point.storage_offset()","82eaabe2":"second_point.stride()","99c4cb4e":"points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\nsecond_point = points[1]\nsecond_point[0] = 10.0\npoints","0b0ce3d1":"points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\nsecond_point = points[1].clone()\nsecond_point[0] = 10.0\npoints","5e011a7e":"second_point","7ca1aebd":"points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\npoints","b1042de4":"points_t = points.t()\npoints_t","93030f5d":"id(points.storage()) == id(points_t.storage())","d56a4193":"points.stride()","98b9a839":"points_t.stride()","39de8a3c":"some_t = torch.ones(3, 4, 5)\ntranspose_t = some_t.transpose(0, 2)\nsome_t.shape","3c298f17":"some_t","0afebf76":"transpose_t.shape","5000ba7c":"transpose_t","04776532":"some_t.stride()","3ac428fc":"transpose_t.stride()","31b93316":"points.is_contiguous()","e56c29b2":"points_t.is_contiguous()","b334c643":"points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\npoints_t = points.t()\npoints_t","876b1f53":"points_t.storage()","3c6593fa":"points_t.stride()","4b1ec378":"points_t_cont = points_t.contiguous()\npoints_t_cont","60fa4dc1":"points_t_cont.stride()","4487c63e":"points_t_cont.storage()","f6c539cc":"points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')","1535af3e":"points_gpu = points.to(device='cuda')","93aef28d":"points_gpu","7cf8bd24":"points_gpu = points.to(device='cuda:0')","10f15a48":"points = 2 * points                        # Multiplication performed on the CPU\npoints_gpu = 2 * points.to(device='cuda')  # Multiplication performed on the ! GPU","5f2d0d03":"points_gpu = points_gpu + 4","aa7337d1":"points_cpu = points_gpu.to(device='cpu')","d48d4a71":"points_gpu = points.cuda()      # Defaults to GPU index 0\npoints_gpu = points.cuda(0)\npoints_cpu = points_gpu.cpu()","29745155":"points = torch.ones(3, 4)\npoints_np = points.numpy()\npoints_np","a3e0669d":"points = torch.from_numpy(points_np)\npoints","aaa1e6d8":"torch.save(points, '.\/ourpoints.t')","a7e0cbcc":"with open('.\/ourpoints.t','wb') as f:\n    torch.save(points, f)","ad5319b6":"points = torch.load('.\/ourpoints.t')","ec2f9fb9":"with open('.\/ourpoints.t','rb') as f:\n    points = torch.load(f)","1c6059e1":"# !conda install h5py","7999274a":"import h5py","cebbe94d":"f = h5py.File('.\/ourpoints.hdf5', 'w')\ndset = f.create_dataset('coords', data=points.numpy())\nf.close()","973d1548":"f = h5py.File('.\/ourpoints.hdf5', 'r')\ndset = f['coords']\nlast_points = dset[-2:]\nlast_points","6fd44b9a":"last_points = torch.from_numpy(dset[-2:])\nf.close()","c08c6b48":"# creating tensor a\na = torch.tensor(list(range(9)))\na","aa079e31":"# size of tensor a\na.size()","6ffcef48":"a.shape","12c695b9":"# offset of tensor a\na.storage_offset()","986c76fe":"# stride of tensor a\na.stride()","4b3fd798":"# creating new tensor b\nb = a.view(3, 3)\nb","38792dd6":"# tensors a and b share the same storage\na.storage().data_ptr() == b.storage().data_ptr()","7099808d":"id(a.storage()) == id(b.storage())","5f918545":"# create tensor c\nc = b[1:,1:]\nc","e2307f64":"# size of tensor c\nc.size()","6d12f6c8":"c.shape","52f3b45e":"# offset of tensor c\nc.storage_offset()","69cc4582":"# stride of tensor c\nc.stride()","55a56b45":"# torch.cos(a)\n# # cos_vml_cpu not implemented for 'Long'","4fb0e611":"# torch.sqrt(a)\n# # sqrt_vml_cpu not implemented for 'Long'","150994ff":"# we need to change dtype\n# dtype=torch.float64\n# a = torch.tensor(a, dtype=torch.float64)\na = a.to(dtype=torch.float64)\na","724fa4a3":"torch.cos(a)","729536d3":"torch.sqrt(a)","232a279e":"s we can see, there is quite a lot of bookkeeping involved. This is error-prone, espe-\ncially when the locations where tensors are created and used are far apart in our code.\nThis has caught the eye of practitioners, and so it has been suggested 3 that the dimen-\nsion be given a name instead.","47cb8cba":"https:\/\/www.kaggle.com\/dmisky\/dlwpt-p1ch2-dog-detection\n\nhttps:\/\/www.kaggle.com\/dmisky\/dlwpt-p1ch2-gan-horse-zebra","ab7eb4b7":"## Transposing without copying","aa8dac4e":"cosine https:\/\/pytorch.org\/docs\/master\/generated\/torch.cos.html\n\nsquare root https:\/\/pytorch.org\/docs\/master\/generated\/torch.sqrt.html","bf2af25d":"Creating a tensor on the fly is all well and good, but if the data inside is valuable, we will\nwant to save it to a file and load it back at some point. After all, we don\u2019t want to have\nto retrain a model from scratch every time we start running our program! PyTorch uses\npickle under the hood to serialize the tensor object, plus dedicated serialization code\nfor the storage. Here\u2019s how we can save our points tensor to an ourpoints.t file:","f98de642":"![image.png](attachment:image.png)","773a8575":"or, equivalently,","d664b59a":"Now we have covered everything we need to get started with representing everything in\nfloats. We\u2019ll cover other aspects of tensors\u2014such as creating views of tensors; indexing\ntensors with other tensors; and broadcasting, which simplifies performing element-wise\noperations between tensors of different sizes or shapes\u2014as needed along the way.","3d06301a":"This is OK, although it would be practical to have the first index refer to individual 2D\npoints rather than point coordinates. For this, we can use a 2D tensor:","64a45d19":"![image.png](attachment:image.png)","6733039a":"In addition to dtype , a PyTorch Tensor also has the notion of device , which is where\non the computer the tensor data is placed. Here is how we can create a tensor on the\nGPU by specifying the corresponding argument to the constructor:","ed833526":"We can also use the shorthand methods cpu and cuda instead of the to method to\nachieve the same goal:","de0bcf5e":"So far in this chapter, when we\u2019ve talked about storage, we\u2019ve meant memory on the\nCPU. PyTorch tensors also can be stored on a different kind of processor: a graphics\nprocessing unit (GPU). Every PyTorch tensor can be transferred to (one of) the\nGPU(s) in order to perform massively parallel, fast computations. All operations that\nwill be performed on the tensor will be carried out using GPU-specific routines that\ncome with PyTorch.","281e83f1":"or as a method of the a tensor:","e16ccd88":"Here, we pass a list of lists to the constructor. We can ask the tensor about its shape:","0df6cc8d":"# Tensors: Scenic views of storage","64881fb4":"![image.png](attachment:image.png)","6429f486":"Under the hood, to checks whether the conversion is necessary and, if so, does it. The\ndtype -named casting methods like float are shorthands for to , but the to method\ncan take additional arguments.","6604f613":"As an alternative, we can pass a file descriptor in lieu of the filename:","a7eb2e5d":"![image.png](attachment:image.png)","6169f9ee":"It\u2019s also worth mentioning that by using the to method, we can change the placement\nand the data type simultaneously by providing both device and dtype as arguments.","c3113c97":"Every use case is unique, but we suspect needing to save tensors interoperably will be\nmore common when introducing PyTorch into existing systems that already rely on\ndifferent libraries. New projects probably won\u2019t need to do this as often.","f61b3b84":"We can also pass a Python list to the constructor, to the same effect:","f0f64d10":"## Modifying stored values: In-place operations","626a7408":"# Conclusion","60cce443":"At this point, any operation performed on the tensor, such as multiplying all elements\nby a constant, is carried out on the GPU:","0585afbc":"## Serializing to HDF5 with h5py","4fa09ac1":"In chapter 4, we will learn how to represent real-world data in PyTorch. We will\nstart with simple tabular data and move on to something more elaborate. In the pro-\ncess, we will get to know more about tensors.","71634617":"Here 'coords' is a key into the HDF5 file. We can have other keys\u2014even nested ones.\nOne of the interesting things in HDF5 is that we can index the dataset while on disk\nand access only the elements we\u2019re interested in. Let\u2019s suppose we want to load just\nthe last two points in our dataset:","57d9c8f9":"Accessing an element i, j in a 2D tensor results in accessing the storage_offset + stride[0] * i + stride[1] * j element in the storage. The offset will usually be zero; if this tensor is a view of a storage created to hold a larger tensor, the offset might be a positive value.","5ac4ba33":"Notice that the storage has been reshuffled in order for elements to be laid out row-\nby-row in the new storage. The stride has been changed to reflect the new layout.\nAs a refresher, figure 3.7 shows our diagram again. Hopefully it will all make sense\nnow that we\u2019ve taken a good look at how tensors are built.","a00bd53e":"When mixing input types in operations, the inputs are converted to the larger type\nautomatically. Thus, if we want 32-bit computation, we need to make sure all our\ninputs are (at most) 32-bit:","7cedbec1":"![image.png](attachment:image.png)","cdb34bfb":"# Named tensors","66451d69":"To achieve our goal, we can use the same notation for PyTorch tensors, with the added\nbenefit that, just as in NumPy and other Python scientific libraries, we can use range\nindexing for each of the tensor\u2019s dimensions:","1e49eae2":"Given the experimental nature of this feature at the time of writing, and to avoid\nmucking around with indexing and alignment, we will stick to unnamed in the\nremainder of the book. Named tensors have the potential to eliminate many sources\nof alignment errors, which\u2014if the PyTorch forum is any indication\u2014can be a source\nof headaches. It will be interesting to see how widely they will be adopted.","ca3f30f1":"# Exercises","6c612939":"A tensor whose values are laid out in the storage starting from the rightmost dimen-\nsion onward (that is, moving along rows for a 2D tensor) is defined as contiguous .\nContiguous tensors are convenient because we can visit them efficiently in order with-\nout jumping around in the storage (improving data locality improves performance\nbecause of the way memory access works on modern CPUs). This advantage of course\ndepends on the way algorithms visit.","ccbdf290":"PyTorch 1.3 added named tensors as an experimental feature (see https:\/\/pytorch.org\/tutorials\/intermediate\/named_tensor_tutorial.html and https:\/\/pytorch.org\/docs\/stable\/named_tensor.html). Tensor factory functions such as tensor and rand\ntake a names argument. The names should be a sequence of strings:","1e1937d1":"We can access the first element of the list using the corresponding zero-based index:","3b6f4703":"This informs us about the size of the tensor along each dimension. We could also use\nzeros or ones to initialize the tensor, providing the size as a tuple:","4e3b6971":"# Moving tensors to the GPU","96a5a5d5":"We can obtain a new contiguous tensor from a non-contiguous one using the contigu-\nous method. The content of the tensor will be the same, but the stride will change, as\nwill the storage:","692e0358":"# Indexing tensors","33fc88f1":"All data from book **Deep Learning with PyTorch** https:\/\/pytorch.org\/deep-learning-with-pytorch","c4de1a6b":"As with many things, the number of kinds of tensors has grown as PyTorch supports a\nbroader range of hardware and applications. We can expect new kinds to continue to\narise as people explore new ways to express and perform computations with PyTorch.","e11de087":"PyTorch will cause the right computation functions to be called regardless of\nwhether our tensor is on the CPU or the GPU. This is accomplished through a dis-\npatching mechanism, and that mechanism can cater to other tensor types by hooking\nup the user-facing API to the right backend functions. Sure enough, there are other\nkinds of tensors: some are specific to certain classes of hardware devices (like Google\nTPUs), and others have data-representation strategies that differ from the dense array\nstyle we\u2019ve seen so far. For example, sparse tensors store only nonzero entries, along\nwith index information. The PyTorch dispatcher on the left in figure 3.8 is designed\nto be extensible; the subsequent switching done to accommodate the various numeric\ntypes of figure 3.8 shown on the right is a fixed aspect of the implementation coded\ninto each backend.","5b322b48":"# Tensor metadata: Size, offset, and stride","34c55ef6":"For those cases when you need to, however, you can use the HDF5 format and\nlibrary (www.hdfgroup.org\/solutions\/hdf5). HDF5 is a portable, widely supported\nformat for representing serialized multidimensional arrays, organized in a nested key-\nvalue dictionary. Python supports HDF5 through the h5py library (www.h5py.org),\nwhich accepts and returns data in the form of NumPy arrays.\nWe can install h5py using","28bd2543":"## The essence of tensors","231d1283":"Transposing in PyTorch is not limited to matrices. We can transpose a multidimen-\nsional array by specifying the two dimensions along which transposing (flipping shape\nand stride) should occur:","61b3ae41":"## Managing a tensor\u2019s dtype attribute","b67267a1":"In order to allocate a tensor of the right numeric type, we can specify the proper\ndtype as an argument to the constructor. For example:","097e4a0d":"The stride is a tuple indicating the number of elements in the storage that have to be\nskipped when the index is increased by 1 in each dimension. For instance, our points\ntensor has a stride of (2, 1) :","3bfdc4f3":"![image.png](attachment:image.png)","bef2e852":"At this point, we know what PyTorch tensors are and how they work under the hood.\nBefore we wrap up, it is worth taking a look at the tensor operations that PyTorch\noffers. It would be of little use to list them all here. Instead, we\u2019re going to get a gen-\neral feel for the API and establish a few directions on where to find things in the\nonline documentation at http:\/\/pytorch.org\/docs.","f43d01e9":"The dtype argument is deliber-ately similar to the standard NumPy argument of the same name. Here\u2019s a list of the possible values for the dtype argument:\n* torch.float32 or torch.float: 32-bit floating-point\n* torch.float64 or torch.double: 64-bit, double-precision floating-point\n* torch.float16 or torch.half: 16-bit, half-precision floating-point\n* torch.int8: signed 8-bit integers\n* torch.uint8: unsigned 8-bit integers\n* torch.int16 or torch.short: signed 16-bit integers\n* torch.int32 or torch.int: signed 32-bit integers\n* torch.int64 or torch.long: signed 64-bit integers\n* torch.bool: Boolean","b4f546f2":"Let\u2019s try transposing now. Let\u2019s take our points tensor, which has individual points in\nthe rows and X and Y coordinates in the columns, and turn it around so that individ-\nual points are in the columns. We take this opportunity to introduce the t function, a\nshorthand alternative to transpose for two-dimensional tensors:","ba49a117":"In addition to using ranges, PyTorch features a powerful form of indexing, called\nadvanced indexing","d32db018":"At this point, we can save our points tensor by converting it to a NumPy array (at no\ncost, as we noted earlier) and passing it to the create_dataset function:","60fab3a9":"We also often want our code to generalize\u2014for example, from grayscale images repre-\nsented as 2D tensors with height and width dimensions to color images adding a third\nchannel dimension (as in RGB), or from a single image to a batch of images. In sec-\ntion 2.1.4, we introduced an additional batch dimension in batch_t ; here we pretend\nto have a batch of 2:","2c289c73":"This indirection between Tensor and Storage makes some operations inexpensive, like transposing a tensor or extracting a subtensor, because they do not lead to memory reallocations. Instead, they consist of allocating a new Tensor object with a different value for size, storage offset, or stride.","95b22d46":"# The world as floating-point numbers","a5f0aef1":"Owing to this fact, we can pass the returned object to the torch.from_numpy func-\ntion to obtain a tensor directly. Note that in this case, the data is copied over to the\ntensor\u2019s storage:","394ae5c1":"We will meet quantized tensors in chapter 15, which are implemented as another\ntype of tensor with a specialized computational backend. Sometimes the usual tensors\nwe use are called dense or strided to differentiate them from tensors using other mem-\nory layouts.","38ea2ccb":"While we can quickly save tensors this way if we only want to load them with PyTorch,\nthe file format itself is not interoperable: we can\u2019t read the tensor with software other\nthan PyTorch. Depending on the use case, this may or may not be a limitation, but we\nshould learn how to save tensors interoperably for those times when it is. We\u2019ll look\nnext at how to do so.","f81d81b6":"In addition to the operations on tensors introduced in the previous section, a small\nnumber of operations exist only as methods of the Tensor object. They are recogniz-\nable from a trailing underscore in their name, like zero_ , which indicates that the\nmethod operates in place by modifying the input instead of creating a new output tensor\nand returning it. For instance, the zero_ method zeros out all the elements of the input.\nAny method without the trailing underscore leaves the source tensor unchanged and\ninstead returns a new tensor:","2a4dcfda":"We can\u2019t index a storage of a 2D tensor using two indices. The layout of a storage is\nalways one-dimensional, regardless of the dimensionality of any and all tensors that\nmight refer to it.","8df3acf2":"https:\/\/github.com\/deep-learning-with-pytorch\/dlwpt-code","6724c5f4":"We\u2019ve mentioned NumPy here and there. While we do not consider NumPy a prereq-\nuisite for reading this book, we strongly encourage you to become familiar with\nNumPy due to its ubiquity in the Python data science ecosystem. PyTorch tensors can\nbe converted to NumPy arrays and vice versa very efficiently. By doing so, we can take\nadvantage of the huge swath of functionality in the wider Python ecosystem that has\nbuilt up around the NumPy array type. This zero-copy interoperability with NumPy\narrays is due to the storage system working with the Python buffer protocol\n(https:\/\/docs.python.org\/3\/c-api\/buffer.html).\nTo get a NumPy array out of our points tensor, we just call","46120b2f":"which will return a NumPy multidimensional array of the right size, shape, and\nnumerical type. Interestingly, the returned array shares the same underlying buffer\nwith the tensor storage. This means the numpy method can be effectively executed at\nbasically no cost, as long as the data sits in CPU RAM. It also means modifying the\nNumPy array will lead to a change in the originating tensor. If the tensor is allocated\non the GPU, PyTorch will make a copy of the content of the tensor into a NumPy array\nallocated on the CPU.\nConversely, we can obtain a PyTorch tensor from a NumPy array this way","fda2f90b":"We can get the second point in the tensor by providing the corresponding index:","3ad415eb":"The resulting tensor has offset 2 in the storage (since we need to skip the first point, which has two items), and the size is an instance of the Size class containing one element, since the tensor is one-dimensional. It\u2019s important to note that this is the\nsame information contained in the shape property of tensor objects:","7fdd47b5":"1. Create a tensor a from list(range(9)) . Predict and then check the size, offset, and stride.\n\n    * a Create a new tensor using b = a.view(3, 3) . What does view do? Check that a and b share the same storage.\n    * b Create a tensor c = b[1:,1:] . Predict and then check the size, offset, and stride.","dc64b2f9":"To get the coordinates of the first point, we do the following:","f741c8f5":"Let\u2019s see list indexing in action so we can compare it to tensor indexing. Take a list of three numbers in Python","bfec33d5":"## Views of another tensor\u2019s storage","8ec5f6a6":"# NumPy interoperability","cae6170a":"We could instead copy a tensor created on the CPU onto the GPU using the to\nmethod:","0ecaa0fc":"the addition is still performed on the GPU, and no information flows to the CPU\n(unless we print or access the resulting tensor). In order to move the tensor back to\nthe CPU, we need to provide a cpu argument to the to method, such as","f779137b":"The output is another tensor that presents a different view of the same underlying data.\nThe new tensor is a 1D tensor of size 2, referencing the values of the first row in the\npoints tensor. Does this mean a new chunk of memory was allocated, values were copied\ninto it, and the new memory was returned wrapped in a new tensor object? No, because\nthat would be very inefficient, especially if we had millions of points.","c1a3aed9":"![image.png](attachment:image.png)","51d582d2":"For operations with two inputs, in addition to the usual dimension checks\u2014whether\nsizes are the same, or if one is 1 and can be broadcast to the other\u2014PyTorch will now\ncheck the names for us. So far, it does not automatically align dimensions, so we need\nto do this explicitly. The method align_as returns a tensor with missing dimensions\nadded and existing ones permuted to the right order:","2af27e3c":"But now we have the weight, too. PyTorch will allow us to multiply things that are the\nsame shape, as well as shapes where one operand is of size 1 in a given dimension. It\nalso appends leading dimensions of size 1 automatically. This is a feature called broad-\ncasting. batch_t of shape (2, 3, 5, 5) is multiplied by unsqueezed_weights of shape (3,\n1, 1), resulting in a tensor of shape (2, 3, 5, 5), from which we can then sum the third\ndimension from the end (the three channels):","3ded9211":"Doing so returns a new tensor that has the same numerical data, but stored in the\nRAM of the GPU, rather than in regular system RAM. Now that the data is stored\nlocally on the GPU, we\u2019ll start to see the speedups mentioned earlier when perform-\ning mathematical operations on the tensor. In almost all cases, CPU- and GPU-based\ntensors expose the same user-facing API, making it much easier to write code that is\nagnostic to where, exactly, the heavy number crunching is running.","f219229e":"To make things concrete, imagine that we have a 3D tensor like img_t from section\n2.1.4 (we will use dummy data for simplicity here), and we want to convert it to gray-\nscale. We looked up typical weights for the colors to derive a single brightness value: 1","b8aa8e4a":"# Summary","e1f5b810":"2. Pick a mathematical operation like cosine or square root. Can you find a corresponding function in the torch library?\n\n    * a Apply the function element-wise to a . Why does it return an error?\n    * b What operation is required to make the function work?\n    * c Is there a version of your function that operates in place?","59e3ca0b":"Let\u2019s see how indexing into the storage works in practice with our 2D points. The stor-\nage for a given tensor is accessible using the .storage property:","9715e9ae":"We already extracted a subtensor when we indexed a specific point and saw the\nstorage offset increasing. Let\u2019s see what happens to the size and stride as well:","b1656ab7":"Once we\u2019re finished loading data, we close the file. Closing the HDFS file invalidates\nthe datasets, and trying to access dset afterward will give an exception. As long as we\nstick to the order shown here, we are fine and can now work with the last_points\ntensor.","3f830eaf":"This returns the Y-coordinate of the zeroth point in our dataset. We can also access\nthe first element in the tensor as we did before to get the 2D coordinates of the first\npoint:","93ab3226":"Let\u2019s construct our first PyTorch tensor and see what it looks like. It won\u2019t be a particularly meaningful tensor for now, just three ones in a column:","ce73684b":"which will use the same buffer-sharing strategy we just described.\n\nWhile the default numeric type in PyTorch is 32-bit floating-point, for\nNumPy it is 64-bit. As discussed in section 3.5.2, we usually want to use 32-bit\nfloating-points, so we need to make sure we have tensors of dtype torch\n.float after converting.","eeeefa29":"## Managing a tensor\u2019s device attribute","e2956ff3":"# The tensor API","d2612afb":"To help build a solid understanding of the mechanics of tensors, it may\nbe a good idea to grab a pencil and a piece of paper and scribble diagrams\nlike the one in figure 3.5 as we step through the code in this section.","e7ccbdb5":"At this point, it shouldn\u2019t come as a surprise that changing the value of a storage\nleads to changing the content of its referring tensor:","3992cb4a":"This tells us that increasing the first index by one in points \u2014for example, going from\npoints[0,0] to points[1,0] \u2014will skip along the storage by two elements, while increas-\ning the second index\u2014from points[0,0] to points[0,1] \u2014will skip along the storage by\none. In other words, the storage holds the elements in the tensor sequentially row by row.","fac18cfe":"## Constructing our first tensors","82106656":"We can also cast the output of a tensor creation function to the right type using the\ncorresponding casting method, such as","aec0075f":"## Contiguous tensors","76151e9d":"We can find out about the dtype for a tensor by accessing the corresponding attribute:","8d5cf504":"!conda install h5py","dac49f3a":"So sometimes the RGB channels are in dimension 0, and sometimes they are in dimen-\nsion 1. But we can generalize by counting from the end: they are always in dimension\n\u20133, the third from the end. The lazy, unweighted mean can thus be written as follows:","538602ab":"## From Python lists to PyTorch tensors","cd7e389c":"Say we have a list of coordinates we\u2019d like to use to represent a geometrical object:\nperhaps a 2D triangle with vertices at coordinates (4, 1), (5, 3), and (2, 1). The\nexample is not particularly pertinent to deep learning, but it\u2019s easy to follow. Instead\nof having coordinates as numbers in a Python list, as we did earlier, we can use a\none-dimensional tensor by storing Xs in the even indices and Ys in the odd indices,\nlike this:","98c00dfb":"or the more convenient to method:","bf9aa171":"The default data type for tensors is 32-bit floating-point.","cd6a69c8":"Functions accepting dimension arguments, like sum , also take named dimensions:","123bf0d8":"First, the vast majority of operations on and between tensors are available in the\ntorch module and can also be called as methods of a tensor object. For instance, the\ntranspose function we encountered earlier can be used from the torch module","b9869123":"We can easily verify that the two tensors share the same storage","b8276b1c":"The dimensions (or axes) of our tensors usually index something like pixel locations\nor color channels. This means when we want to index into a tensor, we need to\nremember the ordering of the dimensions and write our indexing accordingly. As\ndata is transformed through multiple tensors, keeping track of which dimension con-\ntains what data can be error-prone.","b593fa51":"# Serializing tensors","7fbbf48f":"Because this gets messy quickly\u2014and for the sake of efficiency\u2014the PyTorch function\neinsum (adapted from NumPy) specifies an indexing mini-language 2 giving index\nnames to dimensions for sums of such products. As often in Python, broadcasting\u2014a\nform of summarizing unnamed things\u2014is done using three dots '...' ; but don\u2019t worry\ntoo much about einsum , because we will not use it in the following:","e772f8d9":"* Neural networks transform floating-point representations into other floating-point representations. The starting and ending representations are typically human interpretable, but the intermediate representations are less so.\n* These floating-point representations are stored in tensors.\n* Tensors are multidimensional arrays; they are the basic data structure in PyTorch.\n* PyTorch has a comprehensive standard library for tensor creation, manipulation, and mathematical operations.\n* Tensors can be serialized to disk and loaded back.\n* All tensor operations in PyTorch can execute on the CPU as well as on the GPU, with no change in the code.\n* PyTorch uses a trailing underscore to indicate that a function operates in place on a tensor (for example, Tensor.sqrt_ ).","4673e819":"When we already have a tensor and want to add names (but not change existing\nones), we can call the method refine_names on it. Similar to indexing, the ellipsis ( ...)\nallows you to leave out any number of dimensions. With the rename sibling method,\nyou can also overwrite or drop (by passing in None ) existing names:","64c3e3b5":"The data is not loaded when the file is opened or the dataset is required. Rather, the\ndata stays on disk until we request the second and last rows in the dataset. At that\npoint, h5py accesses those two columns and returns a NumPy array-like object\nencapsulating that region in that dataset that behaves like a NumPy array and has the\nsame API.","105c5a9a":"# Tensor element types","7b7a0cbd":"and that they differ only in shape and stride:","461ef6ef":"Some tensor operations in PyTorch only work on contiguous tensors, such as view ,\nwhich we\u2019ll encounter in the next chapter. In that case, PyTorch will throw an infor-\nmative exception and require us to call contiguous explicitly. It\u2019s worth noting that\ncalling contiguous will do nothing (and will not hurt performance) if the tensor is\nalready contiguous.\nIn our case, points is contiguous, while its transpose is not:","4201a2c6":"The bottom line is that the subtensor has one less dimension, as we would expect,\nwhile still indexing the same storage as the original points tensor. This also means\nchanging the subtensor will have a side effect on the original tensor:","da2a6e59":"In chapter 4, we will learn how to represent real-world data in PyTorch. We will\nstart with simple tabular data and move on to something more elaborate. In the pro-\ncess, we will get to know more about tensors.","35ec6c85":"If we want to use tensors outside functions that operate on named tensors, we need to\ndrop the names by renaming them to None . The following gets us back into the world\nof unnamed dimensions:","ac212fee":"If we try to combine dimensions with different names, we get an error:","d8d6a99c":"Even though the tensor reports itself as having three rows and two columns, the stor-\nage under the hood is a contiguous array of size 6. In this sense, the tensor just knows\nhow to translate a pair of indices into a location in the storage.\nWe can also index into a storage manually. For instance:","806ce5c8":"Loading our points back is similarly a one-liner","8fe81fb4":"## Specifying the numeric type with dtype","634aa9ba":"What if we need to obtain a tensor containing all points but the first? That\u2019s easy using\nrange indexing notation, which also applies to standard Python lists.","ef48dc32":"## Indexing into storage","cc9d8f27":"Note that the points_gpu tensor is not brought back to the CPU once the result has\nbeen computed. Here\u2019s what happened in this line:\n1. The points tensor is copied to the GPU.\n2. A new tensor is allocated on the GPU and used to store the result of the multiplication.\n3. A handle to that GPU tensor is returned.\n\nTherefore, if we also add a constant to the result","159cf03f":"# Generalized tensors are tensors, too","441ea8a1":"Now we can access an individual element in the tensor using two indices:","8d61a3fa":"For the purposes of this book, and for the vast majority of applications in general, ten-\nsors are multidimensional arrays, just as we\u2019ve seen in this chapter. If we risk a peek\nunder the hood of PyTorch, there is a twist: how the data is stored under the hood is\nseparate from the tensor API we discussed in section 3.6. Any implementation that\nmeets the contract of that API can be considered a tensor!","8f57c06c":"## Transposing in higher dimensions","a56da766":"about tensor view https:\/\/pytorch.org\/docs\/stable\/tensor_view.html","f86e2313":"After importing the torch module, we call a function that creates a (one-dimensional) tensor of size 3 filled with the value 1.0 . We can access an element using its zero-based index or assign a new value to it. Although on the surface this example doesn\u2019t differ much from a list of number objects, under the hood things are completely different."}}