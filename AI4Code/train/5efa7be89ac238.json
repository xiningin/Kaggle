{"cell_type":{"0e18db40":"code","22f37056":"code","27c60ea0":"code","e4e48aea":"code","e5c7ae61":"code","f40cb56d":"code","d6643982":"code","afe3cf06":"code","7d815eb9":"code","49e08e87":"code","8374c4db":"code","ec59ec73":"code","98227b98":"code","78eec9ef":"code","3c45a7ab":"code","6586c69a":"code","a50f4a13":"code","9074d39f":"code","ca2c2653":"markdown","30b32e66":"markdown","e691fbdd":"markdown","9f8a8120":"markdown","b19a208e":"markdown","55043079":"markdown","17415afb":"markdown"},"source":{"0e18db40":"########## Imports ##########\n\nimport os \nfrom tqdm import tqdm \nimport datetime \n\nimport imageio\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#for 3D plots\nimport plotly.express as px\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 8\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchmetrics\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.metrics import Accuracy\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nif torch.cuda.is_available():  \n    print('Wohooo, GPU found!!')\n    dev = \"cuda:0\" \nelse:  \n    dev = \"cpu\"  \n    \ndevice = torch.device(dev)\n\n### In order to allow truncated images\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\ntorch.manual_seed(0)\nnp.random.seed(0)","22f37056":"########## Preparing Metrics ##########\n\nfrom torchmetrics import Accuracy, F1\nfrom sklearn.metrics import f1_score","27c60ea0":"########## Setting the filepath and checking the labels  ##########\n\ndir = '\/kaggle\/input\/mushrooms\/Mushrooms'\n\nlabels = list(os.listdir(dir))\nlabels.sort()\nlabel_count = []\n\nfor i in labels:\n  label_count.append(len(os.listdir(dir + '\/' + i)))\n\nlabel_count = np.array(label_count, dtype = np.float32)\n\n#prints out labels\nos.listdir(dir)","e4e48aea":"########## Instantiating the Data Loader ##########\n\n\naugment = torchvision.transforms.Compose([\n                                    torchvision.transforms.RandomRotation(90),\n                                    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n                                    torchvision.transforms.RandomVerticalFlip(p=0.5),\n                                    torchvision.transforms.RandomPerspective(),\n                                    torchvision.transforms.RandomCrop(128),\n            ])\n\nprocess = torchvision.transforms.Compose([\n                                    torchvision.transforms.ToTensor(),                                              \n                                    torchvision.transforms.Resize((128,128)),\n                                    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225]),\n            ])\n\ndataset = torchvision.datasets.ImageFolder(dir, transform=process)\n\ntrain_set, val_set = torch.utils.data.random_split(dataset, [5372, 1342])\n\ndata_params = {\n    'batch_size': 32,\n    'shuffle': True,\n    'num_workers': 8,\n    'drop_last': True,\n    'pin_memory': True\n}\n\ntrain_loader = torch.utils.data.DataLoader(train_set, **data_params)\n\nval_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=False,  pin_memory=True)","e5c7ae61":"########## Plotting Amount of data per label ##########\n\nlabel_count = np.array(label_count, dtype = np.float32)\n\nfig, ax = plt.subplots()\nax.set_title(\"Amount of data per label\")\n\n\nsns.barplot(x = labels, y = label_count, ax = ax)\nplt.show()","f40cb56d":"########## Inspecting train and validation sets ##########\n\ntrain_labels_dict = {0 : 0, 1 : 0, 2 : 0, 3 : 0, 4 : 0, 5 : 0, 6 : 0, 7 : 0, 8 : 0}\nval_labels_dict = {0 : 0, 1 : 0, 2 : 0, 3 : 0, 4 : 0, 5 : 0, 6 : 0, 7 : 0, 8 : 0}\n\ndef make_barplot(dataset, dict, title ):\n\n\n    for i in range(len(dataset)):\n        label = dataset[i][1]\n        if label in dict.keys():\n          dict[label] += 1\n    keys = dict.keys()\n    counts = []\n    for i in keys:\n        counts.append(dict[i])\n    fig, ax = plt.subplots()\n    ax.set_title(title)\n    \n    sns.barplot(x = labels, y = counts, ax = ax)\n\n        \n    plt.show()\n\n    \nmake_barplot(train_set, train_labels_dict, \"Amount of training data per label\")    \nmake_barplot(val_set, val_labels_dict, \"Amount of validation data per label\")","d6643982":"########## Checks the augmentations behave as expected ##########\n\n\nplt.imshow(augment(dataset[10][0]).permute(1, 2, 0))\n\nplt.show()\n","afe3cf06":"########## Preparing weights to pass to loss function ##########\n\n#since the data is imbalanced a tensor containing weights for each class can be passed to nn.CrossEntropyLoss() in order to penalise\n#inaccurately predicting a bigger class more\n\nlabel_weights = label_count\/np.sum(label_count)\n\nfor i in range(len(labels)):\n    print(labels[i], round(label_weights[i],3))\n    \nlabel_weights = torch.from_numpy(label_weights)    ","7d815eb9":"!pip install pytorch_metric_learning","49e08e87":"########## Preparing Triplet entropy loss##########\n\n\nfrom pytorch_metric_learning import miners, losses\nclass TripletEntropyLoss(nn.Module):\n    def __init__(self, cel_weigth_tensor=None, margin=0.5, triplet_type='semihard', cel_weigth=1, te_weight=1):\n        super().__init__()\n        self.margin = margin\n        self.cel_weight = cel_weigth\n        self.te_weight = te_weight\n        self.triplet_type = triplet_type\n        self.triplet_miner = miners.TripletMarginMiner(margin=self.margin, type_of_triplets=self.triplet_type)\n        self.triplet_loss_fn = losses.TripletMarginLoss(margin=self.margin, swap=False)\n        if not cel_weigth_tensor is None:\n            self.cel_weight_tensor = cel_weigth_tensor\n            self.cross_entropy_loss_fn = nn.CrossEntropyLoss(weight=cel_weigth_tensor)\n        else:\n            self.cross_entropy_loss_fn = nn.CrossEntropyLoss()\n    def forward(self, logits, embeddings, labels, categories):\n        # calculate triplet loss\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n        triplets = self.triplet_miner(embeddings, labels)\n        triplet_loss = self.triplet_loss_fn(embeddings, labels, triplets)\n        #calculate cross entropy loss\n        cross_entropy_loss = self.cross_entropy_loss_fn(logits, categories)\n        loss = self.cel_weight * cross_entropy_loss + self.te_weight * triplet_loss\n        return loss\n    \n","8374c4db":"########## Model Selection ##########\n\n### resnet18 has been chosen\n\nclass MushroomRepresenter(pl.LightningModule):\n    def __init__(self, pretrained, weights):\n        super().__init__()\n\n        # load predefined model\n        self.mushroom_representer = torchvision.models.resnet18(pretrained=pretrained)\n        self.mushroom_representer.fc = nn.Linear(in_features=512, out_features=128, bias=True)\n        self.out = nn.Linear(in_features=128, out_features=9, bias=True)  \n        \n        # create metrics\n        self.loss_func = TripletEntropyLoss()\n        self.acc = Accuracy()\n        self.F1 = F1(num_classes = 9)\n        \n        #setup embedding plotter\n        self.storage = torch.zeros(1, 128 + 1).to(device = 'cpu') \n\n    def forward(self, image):\n        # produce embeddings\n        emb = self.mushroom_representer(image)\n        logits = self.out(emb)\n        return logits, emb\n\n    def configure_optimizers(self):        \n        params = list(self.parameters())\n        optimizer = torch.optim.SGD(params, lr=0.001, momentum = 0.9)\n        #The learning rate will be divided by 10 every 70 epochs\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 70, gamma=0.1, last_epoch=-1, verbose=False)\n\n        return [optimizer],[scheduler]\n    \n    def training_step(self, train_batch, batch_idx):\n        images, labels = train_batch\n       \n        #Augments images during training\n        images = augment(images)\n        \n        logits, embs = self.forward(images)\n        \n        # calculate metrics\n        \n        acc = self.acc(F.softmax(logits), labels)\n        f1 = self.F1(torch.argmax(F.softmax(logits), dim = 1), labels)\n        loss = self.loss_func(logits, embs, labels, labels)\n        \n        self.log('train_loss', loss)\n        self.log('train_acc', acc, on_epoch=True, prog_bar=True, sync_dist=True)\n        self.log('train_f1', f1, on_epoch=True, prog_bar=True)\n        return loss\n        \n    def validation_step(self, val_batch, batch_idx):\n        images, labels = val_batch\n        \n        logits, embs = self.forward(images)\n\n        acc = self.acc(F.softmax(logits), labels)\n        \n        # calculate metrics\n        \n        f1 = self.F1(torch.argmax(F.softmax(logits), dim = 1), labels)\n        loss = self.loss_func(logits, embs, labels, labels)\n        \n        new_storage = torch.cat((embs.to('cpu'), torch.transpose(labels.unsqueeze(0), 0, 1).to('cpu')), 1)\n        self.storage = torch.cat((self.storage, new_storage), 0)\n        \n        self.log('val_loss', loss, on_epoch=True, prog_bar=True, sync_dist=True)\n        self.log('val_acc', acc, on_epoch=True, prog_bar=True, sync_dist=True)\n        self.log('val_f1', f1, on_epoch=True, prog_bar=True)","ec59ec73":"########## Preparing Callbacks ##########\n\n#Saves the 5 best modesl (with respect to F1 score) and the last model\ncheckpoint = pl.callbacks.model_checkpoint.ModelCheckpoint(dirpath='models\/',\n                                                                    filename='{epoch}-{val_f1:.3f}-{val_acc:.3f}-MushroomClassifier',\n                                                                    monitor='val_f1',\n                                                                    save_top_k=5,\n                                                                    save_weights_only=False,\n                                                                    save_last = True)\n\nfrom pytorch_lightning.callbacks import Callback\nimport plotly.express as px\nfrom sklearn.decomposition import PCA\n\nclass EmbeddingPlotterCallback(Callback):\n    \"\"\"\n    Callback to plot embeddings every n_epochs at the end of the train\/validation\/test epoch. \n    By default it plots 2D and 3D after every 10th validation epoch.\n    To setup the callback (with labelled data): \n    The following must be present in the model's init (n is the dimension of the embeddings):\n        self.storage = torch.zeros(1, n + 1).to(device = 'cpu') \n    In each step definition (train\/val\/test) the folowing must be present after calculting the embeddings:\n        #labels is your target, embs is the tensor containing the embeddings\n        \n        new_storage = torch.cat((embs.to('cpu'), torch.transpose(labels.unsqueeze(0), 0, 1).to('cpu')), 1)\n        self.storage = torch.cat((self.storage, new_storage), 0)\n    To setup the callback (with unlabelled data):\n    \n    The following must be present in the model's init (n is the dimension of the embeddings):\n        self.storage = torch.zeros(1, n).to(device = 'cpu') \n    \n    In each step definition (train\/val\/test) the folowing must be present after calculting the embeddings:\n        #embs is the tensor containing the embeddings\n        self.storage = torch.cat((self.storage, embs.to('cpu')), 0)    \n        \n    Arguments:\n    train (bool, default = False)                   If set to True embeddings will be plotted after every n_epochs training epochs\n    val (bool, default = True)                      If set to True embeddings will be plotted after every n_epochs validation epochs\n    test (bool, default = False)                    If set to True embeddings will be plotted after every n_epochs testing epochs\n    dim_2 (bool, default = True)                    If set to True 2 dimensional embeddings will be plotted every n_epochs after the chose steps\n    \n    dim_3 (bool, default = True)                    If set to True 3 dimensional embeddings will be plotted every n_epochs after the chose steps\n    n_epochs (int, default = 10)                    Plot will be produced every n_epochs\n    labeled (bool, default = True)                  If true the callback will expect the data to be labelled, else the callback \n                                                    will expect the embeddings to be unlabeled   \n    labels (list, default = None)                   Labels expects an ordered list of the class names (so the first entry corresponds to \n                                                    the label 0, etc). If passed the plot will distunguish the embeddings by string label\n                                                    instead of by int label (makes the plot much better).\n    \"\"\" \n    def __init__(self, train = False, val = True, test = False, dim_2 = True, dim_3 = True,  n_epochs = 10, labeled = True, labels = None):\n        self.train = train      \n        self.val = val\n        self.test = test\n        self.dim_2 = dim_2\n        self.dim_3 = dim_3\n        self.n_epochs = n_epochs\n        self.labeled = labeled\n        self.labels = labels\n        \n        \n    def _plot_embeddings(self, storage, step_title):\n        if self.labeled:\n            embs, targets = self._unpack_storage(storage)\n            \n            # 2D case:\n            if self.dim_2:\n                pca2 = PCA(n_components=2)\n\n                reduced_embs_2 = pca2.fit_transform(embs)\n\n                xs = reduced_embs_2[:,0]\n                ys = reduced_embs_2[:,1] \n                \n                fig, ax = plt.subplots(figsize = (12, 12))\n                sns.scatterplot(xs, ys, hue = targets, ax = ax)\n                plt.show()\n                \n                #fig = px.scatter(x = xs, y = ys, color = targets, title = '2D '+ step_title)\n                #fig.show()\n            \n            # 3D case:\n            if self.dim_3:\n                pca3 = PCA(n_components=3)\n                reduced_embs_3 = pca3.fit_transform(embs)\n\n                xs = reduced_embs_3[:,0]\n                ys = reduced_embs_3[:,1]\n                zs = reduced_embs_3[:,2] \n\n                fig = px.scatter_3d(x = xs, y = ys, z = zs, color = targets, title = '3D ' + step_title)\n                fig.show()\n        else:\n            embs = self._unpack_storage(storage)\n            # 2D case:\n            if self.dim_2:\n                pca2 = PCA(n_components=2)\n\n                reduced_embs_2 = pca2.fit_transform(embs)\n\n                xs = reduced_embs_2[:,0]\n                ys = reduced_embs_2[:,1] \n\n                fig = px.scatter(x = xs, y = ys, title = '2D '+ step_title)\n                fig.show()\n            \n            # 3D case:\n            if self.dim_3:\n                pca3 = PCA(n_components=3)\n                reduced_embs_3 = pca3.fit_transform(embs)\n\n                xs = reduced_embs_3[:,0]\n                ys = reduced_embs_3[:,1]\n                zs = reduced_embs_3[:,2] \n\n                fig = px.scatter_3d(x = xs, y = ys, z = zs, title = '3D ' + step_title)\n                fig.show()         \n      \n    \n    def _unpack_storage(self, storage):\n        if self.labeled:\n            if self.labels:\n                storage = storage[1:].detach().numpy()\n                embs = storage[:,0:-1]\n                targets = storage[:, -1]\n                target_labels = []\n\n                for i in targets:\n                    target_labels.append(self.labels[int(i)])\n                return embs, target_labels    \n            \n            else:\n                storage = storage[1:].cpu().detach().numpy()\n                return storage[:,0:-1], storage[:, -1]\n        else:\n            embs = storage[1:].detach().numpy()\n            return embs\n\n        \n        \n    def on_train_epoch_start(self, trainer, pl_module):\n         if self.train and pl_module.current_epoch % self.n_epochs == 0:\n                pl_module.storage = pl_module.storage[0].unsqueeze(0)\n                \n    def on_train_epoch_end(self, trainer, pl_module, unused=None):\n        if self.train and pl_module.current_epoch % self.n_epochs == 0:\n            \n            self._plot_embeddings(pl_module.storage, f'Plot of embeddings after training epoch {pl_module.current_epoch}')\n            \n               \n    def on_validation_epoch_start(self, trainer, pl_module):\n         if self.val and pl_module.current_epoch % self.n_epochs == 0:\n                pl_module.storage = pl_module.storage[0].unsqueeze(0)\n    \n    def on_validation_epoch_end(self, trainer, pl_module, unused=None):\n        if self.val and pl_module.current_epoch % self.n_epochs == 0:\n            \n            self._plot_embeddings(pl_module.storage, f'Plot of embeddings after validation epoch {pl_module.current_epoch}')\n            \n            \n    def on_test_epoch_start(self, trainer, pl_module):\n         if self.test and pl_module.current_epoch % self.n_epochs == 0:\n                pl_module.storage = pl_module.storage[0].unsqueeze(0)\n    \n    def on_test_epoch_end(self, trainer, pl_module, unused=None):\n        if self.test and pl_module.current_epoch % self.n_epochs == 0:\n            \n            self._plot_embeddings(pl_module.storage, f'Plot of embeddings after testing epoch {pl_module.current_epoch}')\n\nembedding_plotter = EmbeddingPlotterCallback(dim_3 = False, n_epochs = 20, labels = labels)\n","98227b98":"########## Training ##########\n\n# instantiating the model\nmodel = MushroomRepresenter(pretrained = True, weights = label_weights)  \n\n# instantiating the trainer\ntrainer = pl.Trainer(gpus=1,\n                     num_nodes=1, \n                     precision=32,\n                     max_epochs=100,\n                     callbacks = [checkpoint, embedding_plotter]\n\n                     )\n\n\ntrainer.fit(model, train_loader, val_loader)","78eec9ef":"########## Producing model outputs ##########\nmodel.eval()\nmodel.to('cpu')\n\n### producing storage for outputs\npreds = []\nembs = []\ntargets = torch.zeros(6714, dtype=torch.int8)\n\nfor i in range(len(dataset)):\n    logit , emb = model(dataset[i][0].unsqueeze(0))\n    preds.append( torch.argmax(F.softmax(logit), dim = 1).cpu().numpy()[0])\n    embs.append(emb.detach().cpu().numpy()[0])\n    targets[i] = dataset[i][1]\n \n\npreds = torch.tensor(preds)\nembs = torch.tensor(embs)\n\n \ntarget_labels = []\n\nfor i in targets:\n    target_labels.append(labels[i])\n","3c45a7ab":"########## Plotting Confusion Matrix ##########\n\nconfusion_matrix = torchmetrics.ConfusionMatrix(num_classes = 9)\n\nconf_matrix = confusion_matrix(preds, targets)\n\ncf_matrix = conf_matrix.numpy()\n\nfig, ax = plt.subplots(figsize=(12, 12))\n\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues', ax = ax)\n\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nax.set_xlabel(\"Predicted\")\nax.set_ylabel(\"True Value\")\n\nplt.show()         ","6586c69a":"preds = preds.numpy()\nembs = embs.numpy()","a50f4a13":"########## Plotting embeddings in 2 dimensions ##########\n\nfrom sklearn.decomposition import PCA\npca2 = PCA(n_components=2)\n\nreduced_embs_2 = pca2.fit_transform(embs)\n\nxs = reduced_embs_2[:,0]\nys = reduced_embs_2[:,1] \n\nfig = px.scatter(x = xs, y = ys, color = target_labels)\nfig.show()","9074d39f":"########## Plotting embeddings in 3 dimensions ##########\n\npca3 = PCA(n_components=3)\nreduced_embs_3 = pca3.fit_transform(embs)\n\nxs = reduced_embs_3[:,0]\nys = reduced_embs_3[:,1]\nzs = reduced_embs_3[:,2] \n\nfig = px.scatter_3d(x = xs, y = ys, z = zs, color = target_labels)\nfig.show()\n\n","ca2c2653":"# Preparing data","30b32e66":"# Inspecting the trained model","e691fbdd":"# Preparing the model","9f8a8120":"# Training","b19a208e":"# Introduction \n\nThe purpose of this notebook will be to gain some familiarity with pytorch and pytorch lightning. An instance of resnet18 will be trained on the mushrooms dataset to learn to classify the mushrooms. The model will also learn embeddings. The embeddings will be plotted in both 2 and 3 dimensions. The embeddings will be learned in 128 dimensions and then PCA will be used to reduce the dimensions of the embeddings to 2 and 3 dimesnions.","55043079":"# Inspecting the Data","17415afb":"# Producing model outputs\n\nThe model's predictions and learned embeddings from all the data will be produced and stored so that the model's performance can be analysed."}}