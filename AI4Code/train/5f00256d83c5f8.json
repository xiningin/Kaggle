{"cell_type":{"b9d5711a":"code","c4f79d64":"code","2279fe1f":"code","08e0ffef":"code","1dd17eff":"code","c03c670b":"code","11bf7e0f":"code","4760d12d":"code","59f72f38":"code","fbb2d383":"code","ccc2a915":"code","814c58fd":"code","8c2e6d75":"code","bb380339":"code","5e7d8d10":"code","44da4b6d":"code","ce57f345":"code","c6899916":"code","c50c7441":"code","162b6322":"code","fb1e39d4":"code","d5516ea2":"code","aef8dabd":"code","51959da3":"code","3bfbb808":"code","920f632e":"code","2b4c063a":"code","79484085":"code","46f1049d":"code","a30683a5":"code","4f35c545":"markdown","004321b9":"markdown","6cf0c055":"markdown","a6e8eed6":"markdown","f704bade":"markdown","460b6dbf":"markdown","87174d8d":"markdown","097122e8":"markdown","538f64b3":"markdown","61f17080":"markdown","bc76b512":"markdown","bfad6b94":"markdown","ffaa383f":"markdown","fbe997ab":"markdown","d0c976da":"markdown","64d1778e":"markdown","973e0556":"markdown","d8882f57":"markdown","55c05df9":"markdown"},"source":{"b9d5711a":"%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow_hub as hub\n\nimport re\nimport pickle\nfrom nltk.stem import PorterStemmer\nimport math\n","c4f79d64":"question = \"what is machine learning\"\n\nactual_answer = \"Machine learning is an application of artificial intelligence (AI) that provides\\\nsystems the ability to automatically learn and improve from experience without being explicitly programmed. \\\nMachine learning focuses on the development of computer programs that can access data and use it learn for \\\nthemselves. \\ The process of learning begins with observations or data, such as examples, \\\ndirect experience, or instruction, in order to look for patterns in data and make better \\\ndecisions in the future based on the examples that we provide. The primary aim is to allow the computers\\\nlearn automatically without human intervention or assistance and adjust actions accordingly.\"\n\n\n## Below are the answers written by the students\n\nhighly_accurate_answer = \"Machine learning (ML) is the study of computer algorithms that\\\nimprove automatically through experience. It is seen as a subset of artificial intelligence.\\\nMachine learning algorithms build a mathematical model based on sample data, known as training data, \\\nin order to make predictions or decisions without being explicitly programmed to do so.\\\nMachine learning algorithms are used in a wide variety of applications, such as email filtering and \\\ncomputer vision, where it is difficult or infeasible to develop conventional algorithms to perform the \\\nneeded tasks.\"\n\n\nmedium_accurate_answer = \"At a very high level, machine learning is the process of teaching a computer system how to \\\nmake accurate predictions when fed data. We can do a lot of things using this technique. It learns by itself. It is invented \\\nby father of the computer and since then it is very widely used. We can use it in many other feilds like medicine\\\neducation etc. It will define the new mordern age tech. In future this is going to be one of the major catalyst in every feild be it\\\nbe defence, education, communication.\"\n\nvery_poor_answer = \"Adolf Hitler, byname Der F\u00fchrer (German: \u201cThe Leader\u201d), (born April 20, 1889, Braunau am Inn,\\\nAustria\u2014died April 30, 1945, Berlin, Germany),\\\nleader of the Nazi Party (from 1920\/21) and chancellor (Kanzler) and F\u00fchrer of Germany (1933\u201345). \\\nHe was chancellor from January 30, 1933, and, after President Paul von Hindenburg\u2019s death, assumed \\\nthe twin titles of F\u00fchrer and chancellor (August 2, 1934).\"","2279fe1f":"## preprocessed Data Variables\n\npre_question      = \"\"\npre_actual_answer = \"\"\n\n## Below are the preprocessed answers written by the students\n\npre_highly_accurate_answer = \"\"\npre_medium_accurate_answer = \"\"\npre_very_poor_answer       = \"\"","08e0ffef":"# https:\/\/gist.github.com\/sebleier\/554280\n# we are removing the words from the stop words list\nstopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"]","1dd17eff":"## Defining the utility functions\n\ndef remove_URL(text):\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'',str(text))\n\n\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\n\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\n\ndef remove_punctuation(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)\n\ndef decontracted(phrase):\n    # specific\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase\n\ndef final_preprocess(text):\n    text = text.replace('\\\\r', ' ')\n    text = text.replace('\\\\\"', ' ')\n    text = text.replace('\\\\n', ' ')\n    text = re.sub('[^A-Za-z0-9]+', ' ', text)\n    text = ' '.join(e for e in text.split() if e.lower() not in stopwords)\n    text = text.lower()\n    ps = PorterStemmer()\n    text = ps.stem(text)\n    return text\n    ","c03c670b":"# Removing the URL\n\npre_question               = remove_URL(question)\npre_actual_answer          = remove_URL(actual_answer)\npre_highly_accurate_answer = remove_URL(highly_accurate_answer)\npre_medium_accurate_answer = remove_URL(medium_accurate_answer)\npre_very_poor_answer       = remove_URL(very_poor_answer)","11bf7e0f":"# Removing the Emoji\n\npre_question               = remove_emoji(pre_question)\npre_actual_answer          = remove_emoji(pre_actual_answer)\npre_highly_accurate_answer = remove_emoji(pre_highly_accurate_answer)\npre_medium_accurate_answer = remove_emoji(pre_medium_accurate_answer)\npre_very_poor_answer       = remove_emoji(pre_very_poor_answer)","4760d12d":"# Removing the Html tags\n\npre_question               = remove_html(pre_question)\npre_actual_answer          = remove_html(pre_actual_answer)\npre_highly_accurate_answer = remove_html(pre_highly_accurate_answer)\npre_medium_accurate_answer = remove_html(pre_medium_accurate_answer)\npre_very_poor_answer       = remove_html(pre_very_poor_answer)","59f72f38":"# Removing the puntutations\n\npre_question               = remove_punctuation(pre_question)\npre_actual_answer          = remove_punctuation(pre_actual_answer)\npre_highly_accurate_answer = remove_punctuation(pre_highly_accurate_answer)\npre_medium_accurate_answer = remove_punctuation(pre_medium_accurate_answer)\npre_very_poor_answer       = remove_punctuation(pre_very_poor_answer)","fbb2d383":"# Decontracting the abbrevations\n\npre_question               = decontracted(pre_question)\npre_actual_answer          = decontracted(pre_actual_answer)\npre_highly_accurate_answer = decontracted(pre_highly_accurate_answer)\npre_medium_accurate_answer = decontracted(pre_medium_accurate_answer)\npre_very_poor_answer       = decontracted(pre_very_poor_answer)","ccc2a915":"#Doing the extra preprocessing \n\npre_question               = final_preprocess(pre_question)\npre_actual_answer          = final_preprocess(pre_actual_answer)\npre_highly_accurate_answer = final_preprocess(pre_highly_accurate_answer)\npre_medium_accurate_answer = final_preprocess(pre_medium_accurate_answer)\npre_very_poor_answer       = final_preprocess(pre_very_poor_answer)","814c58fd":"## Making a dictionary of the words and their vector representation\n\nembeddings_index = {}\nf = open('\/kaggle\/input\/glove840b300dtxt\/glove.840B.300d.txt')\nfor line in f:\n    values = line.split(' ')\n    word = values[0] ## The first entry is the word\n    coefs = np.asarray(values[1:], dtype='float32') ## These are the vectors representing the embedding for the word\n    embeddings_index[word] = coefs\nf.close()\n\n\nprint('GloVe data loaded')","8c2e6d75":"glove_words =  set(embeddings_index.keys())\n\n'''\nBelow is a uliity function that takes sentenes as a input and return the vector representation of the same\nMethod adopted is similar to average word2vec. Where i am summing up all the vector representation of the words from the glove and \nthen taking the average by dividing with the number of words involved\n'''\n\ndef convert_sen_to_vec(sentence):\n    vector = np.zeros(300) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence\n    for word in sentence.split():\n        if word in glove_words:\n            vector += embeddings_index[word]\n            cnt_words += 1\n    if cnt_words != 0:\n        vector \/= cnt_words\n    return vector\n","bb380339":"# Now converting the text into vectors\n\nquestion_vec               = convert_sen_to_vec(pre_question)\nactual_answer_vec          = convert_sen_to_vec(pre_actual_answer)\nhighly_accurate_answer_vec = convert_sen_to_vec(pre_highly_accurate_answer)\nmedium_accurate_answer_vec = convert_sen_to_vec(pre_medium_accurate_answer)\npoor_ans_vec               = convert_sen_to_vec(pre_very_poor_answer)","5e7d8d10":"def square_rooted(x):\n    return math.sqrt(sum([a*a for a in x]))\n\n\ndef cosine_similarity(x,y):\n    numerator = sum(a*b for a,b in zip(x,y))\n    denominator = square_rooted(x)*square_rooted(y)\n    return numerator\/float(denominator)","44da4b6d":"# Measuring the similarity using cosine similarity\n\nsim11 = round(cosine_similarity(actual_answer_vec, highly_accurate_answer_vec),3)\nsim12 = round(cosine_similarity(actual_answer_vec, medium_accurate_answer_vec),3)\nsim13 = round(cosine_similarity(actual_answer_vec, poor_ans_vec),3)\n\nprint(\"The cosine similarity between actual answer and accurate answer given by the student is {}\".format(sim11))\nprint(\"The cosine similarity between actual answer and medium accurate answer answer given by the student is {}\".format(sim12))\nprint(\"The cosine similarity between actual answer and poor answer answer given by the student is {}\".format(sim13))","ce57f345":"# We will use the official tokenization script created by the Google team\n!wget --quiet https:\/\/raw.githubusercontent.com\/tensorflow\/models\/master\/official\/nlp\/bert\/tokenization.py","c6899916":"import tokenization","c50c7441":"'''\nWe are preparing out data in such a way that bert model can understand it\n\nWe have to give three sequences as input to the BERT\n\nall_tokens : It basically performs the tokenization of the input sentences\nall_masks  : This is done to make every input of the same length. We choose the maximum length of the vector and pad other vectors accordingly. We padd them \n             with the help of '0' which tells tells the model not to give attension to this token\nsegment Ids: This is used when we are giving multiple sentences as the input. Since we are only giving one sentence as the input we set the value of the \n             segment ids as 0 for all the tokens.\n'''\n\ndef bert_encode(text, tokenizer, max_len=128):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    text = tokenizer.tokenize(text)\n\n    text = text[:max_len-2]\n    input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n    pad_len = max_len - len(input_sequence)\n\n    tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n    tokens += [0] * pad_len\n    pad_masks = [1] * len(input_sequence) + [0] * pad_len\n    segment_ids = [0] * max_len\n\n    all_tokens.append(tokens)\n    all_masks.append(pad_masks)\n    all_segments.append(segment_ids)\n    \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)","162b6322":"%%time\n\n# We are importing the pretrained BERT parameters using TF-Hub\nmodule_url = \"https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_L-24_H-1024_A-16\/2\"\nbert_layer = hub.KerasLayer(module_url, trainable=False)","fb1e39d4":"#Setting up the tokenizer\n\nvocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)","d5516ea2":"#Encoding the text using the our defined bert_encode function above\n\nques_en = bert_encode(question, tokenizer)\nansw_en = bert_encode(actual_answer, tokenizer)\n\ncorrect_answ_en       = bert_encode(highly_accurate_answer, tokenizer)\nmedium_corect_answ_en = bert_encode(medium_accurate_answer, tokenizer)\npoor_answ_en          = bert_encode(very_poor_answer, tokenizer)","aef8dabd":"#Defination of the model\n\nmax_len = 128\n\ninput_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\ninput_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\nsegment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n\npooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    \nmodel = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])","51959da3":"'''\nPredection happens here. After prediction we will be able to extract the [CLS] output as the sentence embedding \nmodel.predict returns two parameters(pooled output and sequence output). Our [CLS] output is contained in the sequence output so we are \nassiging the '_vec' notation for the second parameter and later on we will extract the information using this \n'''\n\npooled_output, ques_vec = model.predict([ques_en[0], ques_en[1], ques_en[2]])\npooled_output, answ_vec = model.predict([answ_en[0], answ_en[1], answ_en[2]])\n\npooled_output, correct_answ_vec = model.predict([correct_answ_en[0], correct_answ_en[1], correct_answ_en[2]])\npooled_output, medium_corect_answ_vec = model.predict([medium_corect_answ_en[0], medium_corect_answ_en[1], medium_corect_answ_en[2]])\npooled_output, poor_answ_vec = model.predict([poor_answ_en[0], poor_answ_en[1], poor_answ_en[2]])","3bfbb808":"## Extracting the [CLS] output from the corresponding vectors\n\nques_vec = ques_vec[0,0,:]\nansw_vec = answ_vec[0,0,:]\ncorrect_answ_vec = correct_answ_vec[0,0,:]\nmedium_corect_answ_vec = medium_corect_answ_vec[0,0,:]\npoor_answ_vec = poor_answ_vec[0,0,:]","920f632e":"# Measuring the similarity using cosine similarity\n\nsim21 = round(cosine_similarity(answ_vec, correct_answ_vec),3)\nsim22 = round(cosine_similarity(answ_vec, medium_corect_answ_vec),3)\nsim23 = round(cosine_similarity(answ_vec, poor_answ_vec),3)\n\nprint(\"The cosine similarity between actual answer and accurate answer given by the student is {}\".format(sim21))\nprint(\"The cosine similarity between actual answer and medium accurate answer answer given by the student is {}\".format(sim22))\nprint(\"The cosine similarity between actual answer and poor answer answer given by the student is {}\".format(sim23))","2b4c063a":"'''\nLoading the pretrained model\nPaper ref - https:\/\/arxiv.org\/pdf\/1803.11175.pdf\n'''\nembed = hub.load(\"https:\/\/tfhub.dev\/google\/universal-sentence-encoder\/4\")","79484085":"#Now using the embed method to convert evert text sentences into numnerical vectors\n\nembeddings = embed([\n    question,\n    actual_answer,\n    highly_accurate_answer,\n    medium_accurate_answer,\n    very_poor_answer])","46f1049d":"# Measuring the similarity using cosine similarity\n\nsim31 = round(cosine_similarity(np.array(embeddings[1]), np.array(embeddings[2])),3)\nsim32 = round(cosine_similarity(np.array(embeddings[1]), np.array(embeddings[3])),3)\nsim33 = round(cosine_similarity(np.array(embeddings[1]), np.array(embeddings[4])),3)\n\nprint(\"The cosine similarity between actual answer and accurate answer given by the student is {}\".format(sim31))\nprint(\"The cosine similarity between actual answer and medium accurate answer answer given by the student is {}\".format(sim32))\nprint(\"The cosine similarity between actual answer and poor answer answer given by the student is {}\".format(sim33))","a30683a5":"#Credits - https:\/\/matplotlib.org\/examples\/api\/barchart_demo.html\n\n\"\"\"\n========\nBarchart\n========\n\nA bar plot with errorbars and height labels on individual bars\n\"\"\"\n\nN = 3\nbest_ans = (sim11, sim12, sim13)\nmed_ans = (sim21, sim22, sim23)\npoor_ans = (sim31, sim32, sim33)\n\nind = np.arange(N)  # the x locations for the groups\nwidth = 0.25     # the width of the bars\n\nfig, ax = plt.subplots(figsize = (10, 5))\n\nax.set_ylim([0,1.3])\n\nrects1 = ax.bar(ind, best_ans, width, color='r')\nrects2 = ax.bar(ind + width, med_ans, width, color='g')\nrects3 = ax.bar(ind + 2*width, poor_ans, width, color='b')\n\n\n# add some text for labels, title and axes ticks\nax.set_ylabel('Scores')\nax.set_title('Scores by Different Models')\nax.set_xticks(ind + 2*width \/ 2)\nax.set_xticklabels(('Best Answer', 'Medium Correct Ans', 'Poor Ans'))\n\nax.legend((rects1[0], rects2[0], rects3[0]), ('Glove Model', 'BERT Model', 'universal-sentence-encoder Model'))\n\n\nplt.show()","4f35c545":"### 5.2 Converting text to vector","004321b9":"### 4.1 Preprocessing the data","6cf0c055":"### 6.1 Modelling","a6e8eed6":"### 6.2 Performance Evaluation","f704bade":"### Conclusion:\n* The cosine similarity score of the best answer, medium correct answer and poor answer respectively of the different models is given below\n\n   * GLOVE                      -- [0.946, 0.917, 0.227]\n   * BERT                       -- [0.843, 0.764, 0.808]\n   * Universal-sentence-encoder -- [0.76, 0.515, 0.065]\n   \n   \n* The best performing model is universal-sentence encoder and the worst performing model is BERT (a little strange)\n\n* Glove is also giving the good results but in the medium correct answer it is giving a very high score which is not correct\n\n* BERT performed a little strange, may be due the fact that we did not fine tune the BERT for our task, had we tuned the BERT then it may be the best performing model. So by only using the pretrained embeddings rom TF-Hub, BERT performed extremely poorly\n\n* No comes our best performing model which did exactly what we expected, good high score for best answer, medium high score for medium correct answer and very low score for poor answer","460b6dbf":"## 6. universal-sentence-encoder Model","87174d8d":"## Objective : Given two sentences find how similar (semantic wise) those two sentences are  ","097122e8":"## 5. Second Approach (BERT) Implementation","538f64b3":"## 7. Overall Comparision of three models","61f17080":"## 3. Solution Approach In Detail","bc76b512":"## 2. Creating a Test Data","bfad6b94":"### 4.2 Building the Glove Embedding for text","ffaa383f":"## 1. Importing The Libraries","fbe997ab":"## 4. First Approach (GloVE) Implementation","d0c976da":"### 5.1 Preparing The Data for BERT","64d1778e":"### 4.3 Evaluating The Model","973e0556":"### 5.4 Evaluation of BERT","d8882f57":"1. Our final objective is to compare the semantic meaning of two different sentences. \n2. We have the text data as input, so we need to use embedding to convert our text data into nummerical vectors\n3. There are three solution proposed to solve this problem. One using average-WordtoVec using GloVe embedding, second using BERT and third using universal-sentence-encoder, Let's see which works best.\n\n\n### First Approach (GloVE)\n1. Since we will be using GloVe embedding to convert our text data into numerical vectors covering the semantic meaning, and since GloVe assign one vector (100 dimensional, 200 dimensional depending upon the GloVe used) to each word. So it makes sense to remove stopwords, do stemming, remove unnecessary symbols, puntuations to improve the model. So we do this process first for all the text data available \n2. When we are ready with the embeddings, now the task reduces to the fact on how to compare those embedding vectors. For this we will use \"Cosine Similarity\" as a metric\n3. Finally we are ready with the consine similarity of the vectors. A cosine similarity of 1 indicates higest similarity and 0 indicates lowest similarity.\n\n### Second Approach (BERT)\n1. Tranformer models in the NLP is giving state of art results now a days. So we will be using BERT for text embedding.\n2. The beauty of the BERT is that you dont need to preprocess too much because BERT is pre-trained on large text data corpus that even captures the sequence information of commas, any special symbol etc. So in case of BERT we will not preprocess the data\n3. We will the using [CLS] output of the BERT model and will use this as the embedding vector\n4. Finally we will use \"Cosine Similarity\" as a metric to compare the sentences\n\n### Third Approach (universal-sentence-encoder)\n1. This is also a transformer based model, and is a hybrid model of transformers and DAN.\n2. For every sentence it will give us the 512 dimensions vector representation of the same.\n3. Using this we will evalute our model using same cosine similarity\n\n### Assumption:\n* Suppose we are giving 100 words as the correct answer to a question. So if we write let say 10 words as \"our\" (written by student) answer then the score will be low irrespective of the fact that the answer written by the students is a subset of the correct answer ","55c05df9":"### 5.3 Model and Predictions"}}