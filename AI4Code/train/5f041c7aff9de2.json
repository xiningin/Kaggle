{"cell_type":{"3c0a7319":"code","32b7cbff":"code","110beff8":"code","cf06ac4f":"code","d669c2d8":"code","d390be16":"code","5b387421":"code","e7b01ff2":"code","f407d3c1":"code","f9992be1":"code","04084341":"code","ab7d02b2":"code","9ad9c686":"code","b8e1d8dc":"code","0afd5ac9":"markdown","c0e1f13a":"markdown","3e9c43c0":"markdown","3d516a97":"markdown","2551e8ad":"markdown","4fed04ab":"markdown"},"source":{"3c0a7319":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score, f1_score","32b7cbff":"image_dir=Path(\"..\/input\/dandelionimages\/Images\")","110beff8":"Filepath=list(image_dir.glob(\"**\/*.jpg\"))\nLabels=list(map(lambda x:os.path.split(os.path.split(x)[0])[1],Filepath))","cf06ac4f":"Filepath=pd.Series(Filepath,name=\"Filepath\" ).astype(str)\nLabels=pd.Series(Labels,name=\"Labels\")\nImage_df=pd.concat([Filepath,Labels],axis=1)\nImage_df","d669c2d8":"train_df,test_df=train_test_split(Image_df,train_size=0.7, shuffle=True,random_state=1)","d390be16":"print(train_df.shape)\nprint(test_df.shape)","5b387421":"train_generator=ImageDataGenerator(\npreprocessing_function=tf.keras.applications.mobilenet.preprocess_input ,\n    validation_split=0.2\n)\n\ntest_generator=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input )","e7b01ff2":"train_images=train_generator.flow_from_dataframe(\ndataframe=train_df,\n    x_col='Filepath',\n    y_col=\"Labels\",\n    traget_size=(224,224),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n    \n    \n)\n\n\nval_images=train_generator.flow_from_dataframe(\ndataframe=train_df,\n    x_col='Filepath',\n    y_col=\"Labels\",\n    target_size=(224,224),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n    \n    \n)\n\ntes_images=test_generator.flow_from_dataframe(\ndataframe=test_df,\n        x_col='Filepath',\n    y_col=\"Labels\",\n    target_size=(224,224),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=False,\n\n)","f407d3c1":"feature_extractor=tf.keras.applications.MobileNet(\ninput_shape=(224,224,3),\n    weights='imagenet',\n    include_top=False,\n    pooling='avg'\n)\nfeature_extractor.trainable=False","f9992be1":"inputs=feature_extractor.input\nx=tf.keras.layers.Dense(128,activation='relu')(feature_extractor.output)\nx=tf.keras.layers.Dense(128,activation='relu')(x)\noutputs=tf.keras.layers.Dense(1,activation='sigmoid')(x)\n\nmodel=tf.keras.Model(inputs=inputs,outputs=outputs)\nmodel.compile(\noptimizer='adam',\n    loss=\"binary_crossentropy\",\n    metrics=['accuracy']\n)\n\n\nmodel.summary()","04084341":"history=model.fit(\n\ntrain_images,\nvalidation_data=val_images,\nepochs=10,\ncallbacks=[tf.keras.callbacks.EarlyStopping(\nmonitor='val_loss',\npatience=3,\n    restore_best_weights=True\n)])","ab7d02b2":"predictions=np.squeeze(model.predict(tes_images))\npredictions=(predictions>=0.5).astype(int)\npredictions","9ad9c686":"acc= accuracy_score(tes_images.labels,predictions)\nf1_Score=f1_score(tes_images.labels,predictions)\nprint(\"Accuracy: {:.2f}%\".format(acc * 100))\nprint(\"F1-Score: {:.5f}\".format(f1))\n","b8e1d8dc":"print(\"Accuracy: {:.2f}%\".format(acc*100))\nprint(\"F1 Score:  {:.2f}\".format(f1_Score))","0afd5ac9":"# Dandelion Image Classification- TransferLearning","c0e1f13a":"## Training","3e9c43c0":"## Results","3d516a97":"## Creating file dataframe","2551e8ad":"## Preprocessing","4fed04ab":"## Downloading the Feature Extractor"}}