{"cell_type":{"436dc7d2":"code","4c8eb0a5":"code","2bbc8b48":"code","e3ef0d74":"code","b6463fa7":"code","669864dd":"code","b15086a8":"code","d5fa107f":"code","186420c8":"code","dba50fcd":"code","75f39426":"code","58d3fa0b":"code","190c0075":"code","d62e4606":"code","c7415896":"markdown","2f13ab54":"markdown"},"source":{"436dc7d2":"# import libraries\nimport tensorflow as tf\nimport tensorflow.keras as keras\n \nimport matplotlib.pyplot as plt\nimport numpy as np","4c8eb0a5":"from IPython import display","2bbc8b48":"# generated images plotting function\ndef plot_results(images, n_cols=None):\n    '''visualizes fake images'''\n    display.clear_output(wait=False)  \n    \n    n_cols = n_cols or len(images)\n    n_rows = (len(images) - 1) \/\/ n_cols + 1\n    \n    if images.shape[-1] == 1:\n        images = np.squeeze(images, axis=-1)\n    \n    plt.figure(figsize=(n_cols*2, n_rows*2))\n    \n    for index, image in enumerate(images):\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(image)\n        plt.axis(\"off\")","e3ef0d74":"# generative constants\nIMAGE_SIZE = 64\nBATCH_SIZE = 32","b6463fa7":"data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1.\/255,\n    zoom_range = 0.08,\n    width_shift_range = 0.05,\n    height_shift_range = 0.05,\n    shear_range = 0.05,\n    horizontal_flip = True\n)","669864dd":"image_dataset_generator = data_generator.flow_from_directory(\n    target_size = (IMAGE_SIZE, IMAGE_SIZE),\n    color_mode = 'rgb',\n    class_mode = None,\n    batch_size = BATCH_SIZE,\n    directory = '..\/input\/minecraft-player-faces\/'\n)","b15086a8":"# plot example image\nfor i in image_dataset_generator:\n  plt.imshow(i[4])\n  print(type(i[4]))\n  print(i[4].shape)\n  break","d5fa107f":"#create basic DCGAN generator\nrandom_dimensions = 32\ngenerator = keras.models.Sequential([\nkeras.layers.Dense(2*2*1024, input_shape = [random_dimensions]),\nkeras.layers.Reshape([2, 2, 1024]),\nkeras.layers.BatchNormalization(momentum = 0.5),\nkeras.layers.Conv2DTranspose(512, 5, 2, 'same', activation = 'selu'), # 4*4*512\nkeras.layers.Conv2DTranspose(256, 5, 2, 'same', activation = 'selu'), # 8*8*256\nkeras.layers.Conv2DTranspose(128, 5, 2, 'same', activation = 'selu'), # 16*16*128\nkeras.layers.Conv2DTranspose(64, 5, 2, 'same', activation = 'selu'), # 32*32*128\nkeras.layers.Conv2DTranspose(3, 5, 2, 'same', activation = 'tanh'), # output (64*64*3)\n])","186420c8":"discriminator = keras.models.Sequential([\nkeras.layers.Conv2D(32, 5, 2, 'same', input_shape = [64, 64, 3], activation = keras.layers.LeakyReLU(alpha = 0.2)), # 64*32*32\nkeras.layers.Conv2D(128, 5, 2, 'same', activation = keras.layers.LeakyReLU(alpha = 0.2)), #16*16*128\nkeras.layers.Conv2D(256, 5, 2, 'same', activation = keras.layers.LeakyReLU(alpha = 0.2)), # 8*8*256\nkeras.layers.Conv2D(512, 5, 2, 'same', activation = keras.layers.LeakyReLU(alpha = 0.2)), # 4*4*512\nkeras.layers.Conv2D(512, 5, 2, 'same', activation = keras.layers.LeakyReLU(alpha = 0.2)), # 2*2*512\nkeras.layers.Flatten(),\nkeras.layers.Dense(1, activation = 'sigmoid')\n])","dba50fcd":"# compile and freeze the discriminator\ndiscriminator.compile(optimizer = keras.optimizers.Adam(lr = 0.0001, beta_1=0.5), loss = 'binary_crossentropy')\ndiscriminator.trainable = False","75f39426":"# compile all of the layers\ngan = keras.models.Sequential([generator, discriminator])\ngan.compile(loss = 'binary_crossentropy', optimizer = keras.optimizers.Adam(lr = 0.0001, beta_1=0.5))","58d3fa0b":"def train_gan(gan, dataset, random_normal_dimensions, n_epochs=50):\n    # get the two sub networks from the GAN model\n    generator, discriminator = gan.layers\n    for epoch in range(n_epochs):\n        print(\"Epoch {}\/{}\".format(epoch + 1, n_epochs))       \n        for i in range(len(dataset)):\n            real_images = dataset.next()\n            real_batch_size = real_images.shape[0]\n            # random noise\n            noise = tf.random.normal(shape = [real_batch_size, random_normal_dimensions])\n          # Use the noise to generate fake images\n            fake_images = generator(noise)\n            mixed_images = tf.concat([fake_images, real_images], axis = 0)\n            discriminator_labels = tf.constant([[0.]]*real_batch_size + [[1.]]*real_batch_size)\n            # Ensure that the discriminator is trainable\n            discriminator.trainable = True\n            discriminator.train_on_batch(mixed_images, discriminator_labels)\n            # PHASE 2 OF TRAINING\n            noise = tf.random.normal([real_batch_size, random_normal_dimensions])\n            # label all generated images to be \"real\"\n            generator_labels = tf.constant([[1.]]*real_batch_size)\n            # Freeze the discriminator\n            discriminator.trainable = False\n            # Train the GAN on the noise with the labels all set to be true\n            gan.train_on_batch(noise, generator_labels)\n        plot_results(np.array(fake_images), 16)                     \n        plt.show()\n    return fake_images","190c0075":"# you can change the number of epochs\nEPOCHS = 60\n \n# run the training loop and collect images\nfake_images = train_gan(gan, image_dataset_generator, random_dimensions, EPOCHS)","d62e4606":"# generate example minecraft skin face\nseed = np.random.normal(size = (1, 32))\ngen_image = generator.predict((seed))\n# plot the image\nplt.axis(False)\nplt.imshow(np.reshape(gen_image, (64, 64, 3)))","c7415896":"# Starter Notebook\n## MinecraftGAN\nThis Notebook includes a basic DCGAN implementation on this dataset, but remarks the lack of images, which overfit the discriminator.","2f13ab54":"## Results\nAs you can see, because of the size of this dataset, even when using SeLU for the generator or Batch Normalization, the results aren't as good because of the small size of the dataset. This is when advanced techniques like fine-tuning or transfer learning come in handy!"}}