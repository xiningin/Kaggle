{"cell_type":{"033a46cb":"code","16991836":"code","3412b4d9":"code","bd0e7ad6":"code","2c358808":"code","64fbcf03":"code","f8c55282":"code","cd61cc73":"code","b4afd95c":"code","efa8d430":"code","51501374":"code","718aaeae":"code","a6e91a33":"code","a8add288":"code","0fdb71b5":"code","4cac85eb":"code","6a4c758c":"code","88051d16":"code","79bc1fbf":"markdown","146e6a2f":"markdown"},"source":{"033a46cb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","16991836":"import seaborn as sns\nimport matplotlib.pyplot as plt\n","3412b4d9":"data = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')","bd0e7ad6":"data.head()","2c358808":"data.describe()","64fbcf03":"plt.figure(1 , figsize = (17 , 8))\nn = 0 \nfor x in ['Age' , 'Annual Income (k$)' , 'Spending Score (1-100)']:\n    n += 1\n    plt.subplot(1 , 3 , n)\n    sns.distplot(data[x] , bins = 20)\n    plt.title('Distplot of {}'.format(x))\nplt.show()","f8c55282":"x = data.iloc[:,[3,4]].values","cd61cc73":"plt.figure(1,figsize = (12,6))\nplt.scatter(x[:,0], x[:,1])\nplt.title('Before KMeans')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","b4afd95c":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(x)\n","efa8d430":"plt.figure(1 , figsize = (12 , 6))\nplt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], c = 'red', label = 'Cluster 1')\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], c = 'yellow', label = 'Cluster 2')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], c = 'aqua', label = 'Cluster 3')\nplt.scatter(x[y_kmeans == 3, 0], x[y_kmeans == 3, 1], c = 'violet', label = 'Cluster 4')\nplt.scatter(x[y_kmeans == 4, 0], x[y_kmeans == 4, 1], c = 'lightgreen', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 200, c = 'navy', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","51501374":"wcss = []\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","718aaeae":"kmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42)\ny_preds = kmeans.fit_predict(x)","a6e91a33":"y_preds","a8add288":"x[0,1]","0fdb71b5":"plt.figure(1 , figsize = (12 , 6))\nplt.scatter(x[y_preds == 0, 0], x[y_preds == 0, 1], c = 'red', label = 'Cluster 1')\nplt.scatter(x[y_preds == 1, 0], x[y_preds == 1, 1], c = 'yellow', label = 'Cluster 2')\nplt.scatter(x[y_preds == 2, 0], x[y_preds == 2, 1], c = 'aqua', label = 'Cluster 3')\nplt.scatter(x[y_preds == 3, 0], x[y_preds == 3, 1], c = 'violet', label = 'Cluster 4')\nplt.scatter(x[y_preds == 4, 0], x[y_preds == 4, 1], c = 'lightgreen', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 200, c = 'navy', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","4cac85eb":"from sklearn.cluster import DBSCAN\ndbscan = DBSCAN(eps=5,min_samples=4).fit(x)\n","6a4c758c":"dbscan.labels_","88051d16":"plt.figure(1 , figsize = (12 , 6))\nplt.scatter(x[dbscan.labels_ == 0, 0], x[dbscan.labels_ == 0, 1], c = 'red', label = 'Cluster 1')\nplt.scatter(x[dbscan.labels_ == 1, 0], x[dbscan.labels_ == 1, 1], c = 'yellow', label = 'Cluster 2')\nplt.scatter(x[dbscan.labels_ == 2, 0], x[dbscan.labels_ == 2, 1], c = 'aqua', label = 'Cluster 3')\nplt.scatter(x[dbscan.labels_ == 3, 0], x[dbscan.labels_ == 3, 1], c = 'violet', label = 'Cluster 4')\nplt.scatter(x[dbscan.labels_ == 4, 0], x[dbscan.labels_ == 4, 1], c = 'lightgreen', label = 'Cluster 5')\nplt.scatter(x[dbscan.labels_ == 5, 0], x[dbscan.labels_ == 5, 1], c = 'green', label = 'Cluster 6')\nplt.scatter(x[dbscan.labels_ == 6, 0], x[dbscan.labels_ == 6, 1], c = 'orange', label = 'Cluster 7')\nplt.scatter(x[dbscan.labels_ == -1, 0], x[dbscan.labels_ == -1, 1], c = 'black', label = 'Outliers')\n#plt.scatter(dbscan.cluster_centers_[:, 0], dbscan.cluster_centers_[:, 1], s = 300, c = 'navy', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","79bc1fbf":"Using Elbow Method to find a optimal cluster number","146e6a2f":"From the graph it is evident that the error stops decreasing at a very low rate after 5 clusters. So choose k = 5"}}