{"cell_type":{"b9bce654":"code","bb19b339":"code","4d63ee2b":"code","cc4be1f2":"code","212c9fd0":"code","1530e5c6":"code","21f8926a":"code","746aef9f":"code","c77810ac":"code","159d089b":"code","e18dcb29":"code","ac9f5fec":"code","2881cf71":"code","e5e19693":"code","2c4cf06b":"markdown","4fc8dda2":"markdown","f39ede18":"markdown"},"source":{"b9bce654":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bb19b339":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cluster import KMeans","4d63ee2b":"data = pd.read_csv(\"..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")","cc4be1f2":"data","212c9fd0":"data.Gender.value_counts()","1530e5c6":"data.Age.value_counts()","21f8926a":"data.info()","746aef9f":"data.isnull().sum()","c77810ac":"X = data.iloc[:,[3,4]].values\nX","159d089b":"# WCSS: Within Clusters Sum of Square\n\nwcss=[]\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters=i, init='k-means++',random_state=42)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)","e18dcb29":"sns.set()\nplt.figure(figsize=(12,6))\nplt.plot(range(1,11),wcss)\nplt.title(\"Elbow Graph\")\nplt.xlabel(\"Number of clusters\")\nplt.ylabel(\"wcss\")\nplt.show()","ac9f5fec":"kmeans = KMeans(n_clusters=5, init='k-means++',random_state=42)","2881cf71":"y = kmeans.fit_predict(X)\ny","e5e19693":"plt.figure(figsize=(12,10))\n\nplt.scatter(X[y==0,0],X[y==0,1], s=50,c='green',label='Cluster 1')\nplt.scatter(X[y==1,0],X[y==1,1], s=50,c='blue',label='Cluster 2')\nplt.scatter(X[y==2,0],X[y==2,1], s=50,c='yellow',label='Cluster 3')\nplt.scatter(X[y==3,0],X[y==3,1], s=50,c='red',label='Cluster 4')\nplt.scatter(X[y==4,0],X[y==4,1], s=50,c='orange',label='Cluster 5')\n\n#plotting centroids\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=100,c='black',label='Centroids')","2c4cf06b":"optimum number of clusters=5","4fc8dda2":"Visualizing the clusters","f39ede18":"Training the kmeans clustering model"}}