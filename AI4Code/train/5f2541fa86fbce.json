{"cell_type":{"9e4f5017":"code","abe27c86":"code","334ce132":"code","d06c73d9":"code","06b109ef":"code","2f57e644":"code","f13095c2":"code","cb102eac":"code","d8885a75":"code","34a2f72e":"code","f31bacf6":"code","6bb49bc6":"code","edc02b24":"code","2eb6f3d1":"code","0cbe41e7":"code","e89ba726":"code","0cd99af4":"code","c66521a4":"code","55b167cf":"code","ff78850f":"code","82021fbe":"code","f5ee0eb8":"code","1a46d1e2":"code","77e32030":"code","965b972c":"code","7c6b4767":"code","886b3a2e":"code","2fb8c8fe":"code","fc5cc086":"code","278e6951":"code","97dabc5d":"code","42b4ffd4":"code","93c0d0cf":"code","7b6d16c6":"code","10767939":"code","9006f081":"code","ed556fd1":"code","5cf11e62":"code","43d5ca17":"code","3833fb95":"code","ca6a928b":"code","0e84837c":"code","0784fa2d":"code","7a72e7d3":"code","d2f0a980":"code","2a3c6e3e":"code","19dd0219":"code","cca3457b":"code","e5ccd08d":"code","0f27ca08":"code","c118b329":"code","a5df91c4":"code","a788a360":"code","f1d3c942":"markdown","6f96f891":"markdown","91c2fd53":"markdown","c0d643a3":"markdown","7b58f18e":"markdown","8bd2c8f9":"markdown","b654d660":"markdown","2ab7bf59":"markdown","1935984b":"markdown","9d728e5a":"markdown","dd3c3cff":"markdown","dc8e58f2":"markdown","0222c427":"markdown","a31acfb7":"markdown","e298062e":"markdown","79502de2":"markdown","84ec11cc":"markdown","d35ed687":"markdown","18338a6d":"markdown","f1758cbc":"markdown","b431d242":"markdown","2c450533":"markdown","6b1f240b":"markdown","278dc552":"markdown","30ef98ed":"markdown","9bbb199c":"markdown","18e96002":"markdown","0c77fc84":"markdown"},"source":{"9e4f5017":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","abe27c86":"df = pd.read_csv(\"\/kaggle\/input\/others\/daily-total-female-births-CA.csv\")\ndf.head()","334ce132":"type(df)\ndf.info()","d06c73d9":"df = pd.read_csv(\"\/kaggle\/input\/others\/daily-total-female-births-CA.csv\", parse_dates=[0])\ndf.head()","06b109ef":"df.info()","2f57e644":"# Index is our time series date data and vales are births columns.\n\nseries = pd.read_csv(\"\/kaggle\/input\/others\/daily-total-female-births-CA.csv\", parse_dates=[0], index_col=[0], squeeze=True)\nseries.head()","f13095c2":"print(series.shape)\ntype(series)","cb102eac":"series","d8885a75":"print(series['1959-05'])","34a2f72e":"series.describe()","f31bacf6":"import matplotlib.pyplot as plt\ndf['births'].plot()","6bb49bc6":"df.index = df.date # X-axis is date column now\nprint(df.head())\ndf['births'].plot()","edc02b24":"dfplot = df[(df['date']>'1959-03-01') & (df['date']<'1959-06-01')]\ndfplot.births.plot()","2eb6f3d1":"import seaborn as sns\ndf = pd.read_csv(\"\/kaggle\/input\/others\/daily-total-female-births-CA.csv\", parse_dates=[0])\nsns.regplot(x=df.index.values, y=df.births)\n\n### Increasing Trend","0cbe41e7":"### Quadratic TL\nsns.regplot(x=df.index.values, y=df.births, order=2)","e89ba726":"### Cubic TL\nsns.regplot(x=df.index.values, y=df.births, order=3)","0cd99af4":"us_miles = pd.read_csv('..\/input\/others\/us-airlines-monthly-aircraft-miles-flown.csv', parse_dates=[0])\nus_miles.head()","c66521a4":"us_miles['MilesMM'].plot() # This shows seasonality, peak during end of the year","55b167cf":"sns.regplot(x=us_miles.index.values, y=us_miles['MilesMM'])","ff78850f":"us_miles['year'] = us_miles['Month'].dt.year\nus_miles.head()","82021fbe":"us_miles.groupby('year')['year','MilesMM'].head(5)","f5ee0eb8":"print(us_miles.groupby('year')['MilesMM'].mean())\nus_miles.groupby('year')['MilesMM'].mean().plot()\nplt.title('Seasonality Removed - MilesMM')","1a46d1e2":"us_miles['lags']= us_miles['MilesMM'].shift(1)\nus_miles.head()","77e32030":"sns.scatterplot(x=us_miles['lags'], y=us_miles['MilesMM'])\nplt.title('Positive Correlation is exhibited')","965b972c":"# Also you can use\nfrom pandas.plotting import lag_plot\nlag_plot(us_miles['MilesMM'])","7c6b4767":"from pandas.plotting import autocorrelation_plot\nautocorrelation_plot(us_miles['MilesMM'])\n\n# X-axis is lag value +1 (like previous plt) , +2, +3, ...90 lags and \\\n# Y-axis is correlation of actual MilesMM and it's lagged values, +ve means positive correlation and -ve vice versa.\n\n# From the plot we see the first 5 lags are highly correlated with actual MilesMM feature.","886b3a2e":"df = pd.read_csv('..\/input\/others\/daily-total-female-births-CA.csv', parse_dates=[0])\ndf.head()","2fb8c8fe":"features = df.copy()\nfeatures['Year'] = df['date'].dt.year\nfeatures['Month'] = df['date'].dt.month\nfeatures['Days'] = df['date'].dt.day\n\n# New features (year, month, days from date)\nfeatures.head()","fc5cc086":"features['lag1'] = df['births'].shift(1)\nfeatures['lag2'] = df['births'].shift(365)\n\nfeatures.head()","278e6951":"# Take n and n-1 values of all date values and averages them into a single unit (window = 2)\n# Take n , n-1, and n-2 values of all date values and averages them into a single unit (window = 3)\n\nfeatures['Roll_mean'] = df['births'].rolling(window=2).mean() \nfeatures['Roll_Max'] = df['births'].rolling(window=3).max() # Mean or Max or Min\n\nfeatures.head(10)","97dabc5d":"features['Expanding_Max'] = df['births'].expanding().max()\nfeatures.head(10)","42b4ffd4":"df = pd.read_csv('..\/input\/others\/us-airlines-monthly-aircraft-miles-flown.csv', parse_dates=[0])\ndf.head()","93c0d0cf":"# Downsampling (12 months = 4 Quarters)\n# 'Q' - Quaterly, 'A' - Annually\nquaterly_miles = df.resample('Q', on='Month').mean() # Quarter has 3 sets and taking mean out of it\nquaterly_miles.head()","7b6d16c6":"yearly_miles = df.resample('A', on='Month').sum()\nyearly_miles.head()","10767939":"daily_miles = df.resample('D', on='Month').mean() # Only creates structure, later fill them\ndaily_miles.head(50)","9006f081":"# To fill the data between day 1 and day 30, we can interpolate a linear function to fill those values\ninterpolated_df = daily_miles.interpolate(method='linear')\ninterpolated_df.head(50)","ed556fd1":"interpolated_df.plot()","5cf11e62":"# For smoothing , we replace linear with polynomial function (quadratic= order=2, third degree polynomial order=4)\npoly_interpolated_df = daily_miles.interpolate(method='spline', order=2)\npoly_interpolated_df.head(50)","43d5ca17":"poly_interpolated_df.plot()","3833fb95":"# Comparing the two plots for smoothening\ninterpolated_df.plot()\npoly_interpolated_df.plot()","ca6a928b":"from statsmodels.tsa.seasonal import seasonal_decompose\ndf = pd.read_csv('..\/input\/others\/us-airlines-monthly-aircraft-miles-flown.csv', parse_dates=[0])\ndf.index = df.Month\ndf.head()","0e84837c":"results_add = seasonal_decompose(df['MilesMM'], model='additive')\nresults_add.plot()\n# Original, Trend, Seasonality, Noise (Residual vales)","0784fa2d":"results_mul = seasonal_decompose(df['MilesMM'], model='multiplicative')\nresults_mul.plot()\n# Original, Trend, Seasonality, Noise (Residual vales)","7a72e7d3":"df['lags'] = df['MilesMM'].shift(1)\ndf.head()","d2f0a980":"df['MilesMM-lags'] = df['MilesMM'].diff(periods=1)\ndf.head()","2a3c6e3e":"# Check for those 3 patterns in the original dataset\ndf.index = df.Month\nresult_1 = seasonal_decompose(df['MilesMM'], model='additive')\nresult_1.plot()","19dd0219":"# The differencing must have removed the trend, but not the seasonality. let's check\n# Refer the y-axis, the range is less which means there's no trend\nresult_2 = seasonal_decompose(df.iloc[1:,3], model='additive')\nresult_2.plot()","cca3457b":"df.head()","e5ccd08d":"df['MilesMM'].plot()","0f27ca08":"df['MilesMM-lags'].plot() # Seasonality for first 3 values","c118b329":"df['MilesMM-lags12'] = df['MilesMM'].diff(periods=12)\ndf['MilesMM-lags12'].plot()","a5df91c4":"df.head(20)","a788a360":"# The second differencing must have removed the seasonality. let's check\n# Refer the y-axis, the range is less which means there's no seasonality and trend\nresult_3 = seasonal_decompose(df.iloc[12:,4], model='additive')\nresult_3.plot()","f1d3c942":"## Let's take the mean value of milesMM for each year","6f96f891":"## Auto-Correlation Plots\nTo check the correlation of the feature variable with itself with delayed values of itself","91c2fd53":"## Time Series - Visualization","c0d643a3":"## Data Analysis","7b58f18e":"## Lag Features","8bd2c8f9":"## Expanding Features (It consider all the values before a particular date value and performs operations)","b654d660":"# 3. Resampling \n## Changing Frequency of the data to our convenient format (year-->month, month-->week, week-->day)\n## simply changing the frequency of the available data to match the frequency of the required forecast\n\n1. Upsampling (Quaterly data --> Monthly)\n2. Downsampling (Quaterly data --> Yearly)","2ab7bf59":"## Window Features","1935984b":"## A time series data must be transformed to be modeled into a supervised learning problem.\n\n## The process of creating or inventing new features from the time series dataset is also called feature engineering (date --> Insights)","9d728e5a":"# 2. Feature Engineering","dd3c3cff":"## Plotting Trend lines using seaborn","dc8e58f2":"##  Date-time Features","0222c427":"## Descriptive Analysis","a31acfb7":"## For efficiency we import data as time-series","e298062e":"## Types of Features\n\n1. Date-time Features --> These are the components of the time step itself for each observations (Date --> Day, Month, Year)\n\n2. Lag Features --> These are values at prior time steps\n\n3. Window Features --> Summary of values over a fixed window\n\n_______________________________________________________________\n\n## Window Features :\n* Rolling Window : Add a summary of the values for the previous time steps\n* Expanding Window : Include all previous data in the series","79502de2":"## Let's zoom in","84ec11cc":"## Downsampling","d35ed687":"## But the date column is identified as object, we need to specify to look it as date type using one of pandas functions","18338a6d":"# 1. Time-Series Data - Load, Clean, Visualize","f1758cbc":"## Polynomial Trendline","b431d242":"# 4. Decomposing Time Series Model - For Detection\n\n1. Additive Model -->\npred(t) = Level(Avg value) + Trend(+ve \/ -ve trend) + Seasonality(short term cycles in series) + noise(random variation)\n2. Multiplicative Model -->\npred(t) = Level(Avg value) * Trend(+ve \/ -ve trend) * Seasonality(short term cycles in series) * noise(random variation)","2c450533":"# 5. Differencing Time Series (For removing trend and seasonality from the data)","6b1f240b":"## End of TS - Data - Load, Clean, Visualize","278dc552":"## Creating Lag Plots\nUsed to check whether a single column feature values are dependent on each other, like daily temperature is +\/- (3 to 5)C of previous day's value","30ef98ed":"## EDA of us-airlines-monthly-aircraft-miles-flown.csv","9bbb199c":"## Filtering by Time","18e96002":"## Seasonality Removal - Aggregated by year and taking mean of milesMM|","0c77fc84":"## Upsampling"}}