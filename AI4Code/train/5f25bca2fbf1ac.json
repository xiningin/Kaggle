{"cell_type":{"ef613bb7":"code","cb55d2bf":"code","30d80b2a":"code","8da98c8f":"code","9bdc5f59":"code","9443d892":"code","1cabc510":"code","ac6cbb7e":"code","ec573660":"code","43860b30":"code","0f76a7fd":"code","3b5dde93":"code","63c626c2":"code","57fdc57f":"code","605bfe97":"code","dc796751":"code","43a55dac":"code","eaad365b":"code","650b69c7":"code","da700ce4":"code","e129957a":"code","ce92714f":"code","5d40115c":"code","ef76b67b":"code","b1fb3002":"code","55f3a2c6":"code","3ad37469":"code","8823d2fe":"code","6a374ef3":"code","14fd5370":"code","fc9e6d75":"code","cbbff08b":"code","9e9d5e22":"code","127e1eb6":"code","65cb5887":"code","8574c327":"code","56b83708":"code","438f6282":"code","af06bb62":"code","3ab79e20":"code","1b949c20":"code","0e5d8f82":"code","c22bf7ea":"code","ad1f06ba":"markdown","c2a37fca":"markdown"},"source":{"ef613bb7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n'''\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        '''\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb55d2bf":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras import backend as K\n\nfrom keras.models import load_model","30d80b2a":"data = pd.read_csv('\/kaggle\/input\/data\/Data_Entry_2017.csv')","8da98c8f":"data.loc[data['Patient ID']==8270]\ndata.head(10)","9bdc5f59":"data['Finding Labels'].values","9443d892":"def counting_labels(column, df):\n    count_list= []\n    for label in df['Finding Labels'].values:\n        if column in label:\n            count_list.append(1)\n        else:\n            count_list.append(0)\n    return count_list\n        ","1cabc510":"real_df= pd.DataFrame({'image': data['Image Index'].values,\n                  'Cardiomegaly' : counting_labels('Cardiomegaly', data),\n                  'Emphysema' : counting_labels('Emphysema', data), \n                  'Effusion' : counting_labels('Effusion', data), \n                  'Hernia' : counting_labels('Hernia', data), \n                  'Infiltration' : counting_labels('Infiltration', data), \n                  'Mass' : counting_labels('Mass', data), \n                  'Nodule' : counting_labels('Nodule', data), \n                  'Atelectasis' : counting_labels('Atelectasis', data),\n                  'Pneumothorax' : counting_labels('Pneumothorax', data),\n                  'Pleural_Thickening' : counting_labels('Pleural_Thickening', data), \n                  'Pneumonia' : counting_labels('Pneumonia', data), \n                  'Fibrosis' : counting_labels('Fibrosis', data), \n                  'Edema' : counting_labels('Edema', data), \n                  'Consolidation': counting_labels('Consolidation', data),\n                       'Patient_Id':  data['Patient ID']\n                  \n})","ac6cbb7e":"real_df.loc[real_df['Patient_Id']== 29855]","ec573660":"real_df.to_csv('\/kaggle\/working\/train_test.csv', index = False)","43860b30":"real_df","0f76a7fd":"csv_dir = '\/kaggle\/working\/'\ndf = pd.read_csv(csv_dir + 'train_test.csv')","3b5dde93":"df","63c626c2":"percent = 0.7\ntrain_percent = int(len(df)*percent)\ntrain_percent","57fdc57f":"sample_data = df.head(10000)","605bfe97":"sample_data","dc796751":"percent = 0.7\npercent_2 = 1 - percent\ntrain_percent = int(len(sample_data)*percent)\ntest_percent = int(len(sample_data)*percent_2)\ntrain_percent\ntest_percent","43a55dac":"train_data = sample_data.head(train_percent)\nval_data = sample_data.tail(test_percent)","eaad365b":"train_data","650b69c7":"val_data","da700ce4":"train_data.to_csv(csv_dir + 'train.csv')\nval_data.to_csv(csv_dir + 'test.csv')","e129957a":"def check_for_leakage(df1, df2, patient_col):\n    '''\n    Return True if there are same patients in both df1 and df2\n    '''\n    \n    df1_patients_unique = set(df1[patient_col].values)\n    print(df1_patients_unique)\n    df2_patients_unique = set(df2[patient_col].values)\n    print(df2_patients_unique)\n    \n    patients_in_both_groups = list(df1_patients_unique.intersection(df2_patients_unique))\n    \n    leakage = len(patients_in_both_groups) > 0\n    \n    return leakage","ce92714f":"print('Leakage between traing and valid: {}'.format(check_for_leakage(train_data, val_data, 'Patient_Id')))","5d40115c":"def remove_leakage(df1, df2, patient_col):\n    '''\n    Return True if there are same patients in both df1 and df2\n    '''\n    \n    df1_patients_unique = set(df1[patient_col].values)\n    #print(df1_patients_unique)\n    df2_patients_unique = set(df2[patient_col].values)\n    #print(df2_patients_unique)\n    \n    patients_in_both_groups = list(df1_patients_unique.intersection(df2_patients_unique))\n    \n    #leakage = len(patients_in_both_groups) > 0\n    for patient in patients_in_both_groups:\n        df1= df1[df1[patient_col] != patient]\n        df2= df2[df2[patient_col] != patient]\n        \n    return df1, df2","ef76b67b":"train_data, val_data = remove_leakage(train_data, val_data ,'Patient_Id')","b1fb3002":"print('Leakage between traing and valid: {}'.format(check_for_leakage(train_data, val_data, 'Patient_Id')))","55f3a2c6":"train_data","3ad37469":"val_data","8823d2fe":"labels = ['Cardiomegaly', \n          'Emphysema', \n          'Effusion', \n          'Hernia', \n          'Infiltration', \n          'Mass', \n          'Nodule', \n          'Atelectasis',\n          'Pneumothorax',\n          'Pleural_Thickening', \n          'Pneumonia', \n          'Fibrosis', \n          'Edema', \n          'Consolidation']","6a374ef3":"def get_train_generator(df, image_dir, x_col, y_col, shuffle=True, batch_size=32, seed=1, target_w=320, target_h=320):\n    image_generator = ImageDataGenerator(\n    samplewise_center=True,\n    samplewise_std_normalization= True)\n    \n    generator = image_generator.flow_from_dataframe(\n    dataframe = df,\n    directory = image_dir,\n    x_col = x_col,\n    y_col = y_col,\n    class_mode='raw',\n    batch_size = batch_size,\n    shuffle = shuffle,\n    seed = seed,\n    targe_size = (target_w, target_h))\n    \n    return generator","14fd5370":"def get_test_and_valid_generator(valid_df, train_df, image_dir, x_col, y_col, sample_size = 100, batch_size = 32, seed = 1, target_w = 320, target_h = 320):\n    \n    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n        dataframe=train_df,\n        directory = image_dir,\n        x_col= 'image',\n        y_col = labels, \n        class_mode='raw',\n        batch_size = sample_size,\n        shuffle = True,\n        target_size = (target_w, target_h)\n    )\n    \n    batch = raw_train_generator.next()\n    data_sample = batch[0]\n    \n    image_generator = ImageDataGenerator(\n        featurewise_center = True,\n        featurewise_std_normalization = True\n    )\n    \n    image_generator.fit(data_sample)\n    \n    valid_generator = image_generator.flow_from_dataframe(\n        dataframe = val_data,\n        directory = image_dir,\n        x_col = x_col,\n        y_col = y_col,\n        class_mode = 'raw',\n        batch_size = batch_size,\n        shuffle = False,\n        seed = seed,\n        target_size = (target_w, target_h)\n        \n    )\n    \n    return valid_generator","fc9e6d75":"IMAGE_DIR = '..\/input\/data\/images'","cbbff08b":"import os\nimport shutil","9e9d5e22":"#os.makedirs('\/kaggle\/working\/images\/')\nlist1 = os.listdir('..\/input\/data\/images_001\/images')\ncurrent = IMAGE_DIR + '_00' + str(1) + '\/images'\nlist12 = os.listdir(current)\nlist12","127e1eb6":"for i in train_data:\n    print(i)","65cb5887":"list1 = train_data.image.values\nfor i in range(10):\n    print(list1[i])\nlen(list1)","8574c327":"current = IMAGE_DIR + '_00' + str(1) + '\/images\/' + list1[0]\nprint(current)","56b83708":"## The Cell to move images to a new folder\ndestination = '\/kaggle\/working\/images\/'\nfor i in range(2,3):\n    current_dir = IMAGE_DIR + '_00' + str(i) + '\/images'\n    list12 = os.listdir(current)\n    for j in list12: ## here the problem was we had to add the second folder checkcheck manually instead of it being automatic, first it was list12\n        current_file = current_dir + '\/' + j\n        shutil.copy(current_file, destination)","438f6282":"files = os.listdir('\/kaggle\/working\/images')","af06bb62":"len(files)\nprint(IMAGE_DIR)\n","3ab79e20":"flag = False\ncheckcheck= os.listdir(IMAGE_DIR + '_002\/images\/')\nif '00001075_003.png' in checkcheck:\n    flag = True\n    \n\ncheckcheck","1b949c20":"IMAGE_DIR = \"\/kaggle\/working\/images\"\ntrain_generator = get_train_generator(train_data, IMAGE_DIR, \"image\", labels)\nvalid_generator= get_test_and_valid_generator(val_data, train_data, IMAGE_DIR, \"image\", labels)","0e5d8f82":"x, y = train_generator.__getitem__(0)\nplt.imshow(x[0]);","c22bf7ea":"## The images have been successfully transfered for the training into the working directory. They have been preprocess using ImageDataGenerator and ready to be fed into \n## the model after class imbalance and Weighted Loss Solution","ad1f06ba":"# Before proceeding, move the images to one folder for accessing","c2a37fca":"# Moving Images into a single folder for easy access"}}