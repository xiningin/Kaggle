{"cell_type":{"55604518":"code","d14ec2eb":"code","511aad58":"code","4c2c23bc":"code","bde4b9f5":"code","a52af168":"code","75eb8e65":"code","04776162":"code","567be873":"code","7419c51d":"markdown","9fb3095a":"markdown","5813afc2":"markdown","6b6688e7":"markdown","a552e5b9":"markdown","5450aff3":"markdown","de37f0ec":"markdown","5b1f5779":"markdown"},"source":{"55604518":"import os\nimport cv2\nimport random\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\n\ntf.__version__, np.__version__","d14ec2eb":"# Setting random seeds to enable consistency while testing.\nrandom.seed(5)\nnp.random.seed(5)\ntf.random.set_seed(5)\n\nROOT = \"..\/input\/face-recognition-dataset\/Extracted Faces\/Extracted Faces\"\n\ndef read_image(index):\n    path = os.path.join(ROOT, index[0], index[1])\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return image","511aad58":"from tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications import Xception\n\ndef get_encoder(input_shape):\n    \"\"\" Returns the image encoding model \"\"\"\n\n    pretrained_model = Xception(\n        input_shape=input_shape,\n        weights=None,\n        include_top=False,\n        pooling='avg',\n    )\n\n    encode_model = Sequential([\n        pretrained_model,\n        layers.Flatten(),\n        layers.Dense(512, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dense(256, activation=\"relu\"),\n        layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n    ], name=\"Encode_Model\")\n    encode_model.load_weights(\"..\/input\/face-recognition-siamese-w-triplet-loss\/encoder\")\n    \n    return encode_model\n\nencoder = get_encoder((128, 128, 3))\nencoder.summary()","4c2c23bc":"def split_dataset(directory, split=0.9):\n    folders = os.listdir(directory)\n    num_train = int(len(folders)*split)\n    \n    random.shuffle(folders)\n    \n    train_list, test_list = {}, {}\n    \n    # Creating Train-list\n    for folder in folders[:num_train]:\n        num_files = len(os.listdir(os.path.join(directory, folder)))\n        train_list[folder] = num_files\n    \n    # Creating Test-list\n    for folder in folders[num_train:]:\n        num_files = len(os.listdir(os.path.join(directory, folder)))\n        test_list[folder] = num_files  \n    \n    return train_list, test_list\n\ntrain_list, test_list = split_dataset(ROOT, split=0.9)\nprint(\"Length of training list:\", len(train_list))\nprint(\"Length of testing list :\", len(test_list))\n\n# train_list, test list contains the folder names along with the number of files in the folder.\nprint(\"\\nTest List:\", test_list)","bde4b9f5":"def encode_dataset(directory, folder_list):\n    encoded_dataset = {}\n    \n    for folder in folder_list.keys():\n        folder_path = os.path.join(directory, folder)\n        files = list(os.listdir(folder_path))\n        \n        images = []\n        for file in files:\n            images.append(read_image((folder, file)))\n        images = preprocess_input(np.array(images))\n        encodings = encoder.predict(images)\n        encoded_dataset[folder] = encodings\n        \n    return encoded_dataset\n\ntrain_encodings = encode_dataset(ROOT, train_list)","a52af168":"def calc_distance(encoding1, encoding2):\n    return np.sum(np.square(encoding1-encoding2), axis=-1)","75eb8e65":"def create_all_triplets(directory, folder_list):\n    triplets = []\n    folders = list(folder_list.keys())\n    \n    for folder in folders:\n        path = os.path.join(directory, folder)\n        files = list(os.listdir(path))\n        num_files = len(files)\n        \n        for i in range(num_files-1):\n            for j in range(i+1, num_files):\n                anchor = (folder, i)\n                positive = (folder, j)\n\n                neg_folder = folder\n                while neg_folder == folder:\n                    neg_folder = random.choice(folders)\n                neg_file = random.randint(0, folder_list[neg_folder]-1)\n                negative = (neg_folder, neg_file)\n\n                triplets.append((anchor, positive, negative))\n            \n    random.shuffle(triplets)\n    return triplets\n\nall_triplets = create_all_triplets(ROOT, train_list)","04776162":"def get_semihard_triplets(triplet_list):\n    dist_vals = []\n    new_triplets = []\n    for a, p, n in triplet_list:\n        # Extracting encodings of anchor, positive, negative\n        encoding_a = train_encodings[a[0]][a[1]]\n        encoding_p = train_encodings[p[0]][p[1]]\n        encoding_n = train_encodings[n[0]][n[1]]\n\n        # Calculating distance between anchor, positive and anchor, negative\n        ap_dist = calc_distance(encoding_a, encoding_p)\n        an_dist = calc_distance(encoding_a, encoding_n)\n\n        # Append if the triplet is semi-hard.\n        if  ap_dist<an_dist and an_dist<(ap_dist+1.0):\n            new_triplets.append((a, p, n))\n    return new_triplets\n\nnew_triplets = get_semihard_triplets(all_triplets)","567be873":"np.array(new_triplets, dtype='object').dump(\"triplets.npy\")","7419c51d":"## Creating all triplets","9fb3095a":"## Distance Function\n\nWe'll be defining a function to compute the distance between 2 encodings.\n\n**Distance Formula**:\n\n<img src=\"https:\/\/www.oreilly.com\/library\/view\/hands-on-image-processing\/9781789343731\/assets\/303feb25-c74c-4ef0-872f-cb2af8c96136.png\" alt=\"Distance Formula\" width=\"400\"\/>\n","5813afc2":"## Saving the triplets\n\nWe'll be saving the triplets as a numpy files so that it can be used later","6b6688e7":"## Reading the encoder\n\nThe **Encoder** is responsible for converting the passed images into their feature vectors. We'll create the encoder and load weights from a model which was trained before.\n\nThe encoder will be used to encode the images and calculate the distance between images.","a552e5b9":"## Siamese Networks\n\nUnlike a conventional CNN, the **Siamese Network** does not classify the images into certain categories or labels, rather it only finds out the distance between the given images. If the images have the same label, then the network should learn the parameters, i.e. the weights and the biases in such a way that it should produce a smaller distance between the images, and if they belong to different labels, then the distance should be larger.\n\n![Siamese Network](https:\/\/miro.medium.com\/max\/2000\/1*05hUCDHhnl4hdjqvdVTHtw.png)\n\n\nSiamese Networks uses Triplet Loss to compute the loss. Triplet Ranking Loss requires, as the name suggests, three inputs which we call a triplet. The Anchor is data of some class C and Positive is another example of the class C. The Negative is a data-point of some class which is not C. \n\nThese embeddings are passed to the Triplet Loss Function, which is defined as:\n\n<img src=\"https:\/\/miro.medium.com\/max\/1838\/0*AX2TSZNk19_gDgTN.png\" alt=\"Loss Formula\" width=\"400\"\/>\n\nThe purpose of this function is to minimise the distance between the Anchor and the Positive, whilst maximising the distance between the Anchor and the Negative.\n\nBecause of the importance of the triplet components, it is imperative that our SNN is provided only with triplets which will enable it to learn. More specifically, we want to provide Negatives such that our triplets allow the model to learn, but not be so difficult that learning takes too long.","5450aff3":"## Reading the Dataset","de37f0ec":"## Encoding all images of the dataset","5b1f5779":"## Triplet Selection\n\nBecause of the importance of the triplet components, it is imperative that our SNN is provided only with triplets which will enable it to learn. More specifically, we want to provide Negatives such that our triplets allow the model to learn, but not be so difficult that learning takes too long.\n\nAn easy way to do this is through a process known as Semi-Hard Triplet Mining. To perform this, we first define three categories of triplet:\n- **Easy Triplets** are those where *D(A,P) + margin < D(A,N)*, thus L = 0.\n- **Hard Triplets** are those where *D(A,N) < D(A,P)*.\n- **Semi-Hard Triplets** are those where *D(A,P) < D(A,N) < D(A,P) + margin*."}}