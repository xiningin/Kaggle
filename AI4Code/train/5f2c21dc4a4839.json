{"cell_type":{"2c28c627":"code","4e6b91e3":"code","d24e48b2":"code","d562a89d":"code","feaaedf7":"code","c79e253c":"code","d2de6698":"code","891a1359":"code","c05d99d7":"code","40bbcdc4":"code","650aaabe":"code","30cff0c3":"code","3bb53c46":"code","e2ba7837":"code","148d9343":"code","ede6487d":"code","9db69851":"code","d8e5e53b":"markdown","47ce43c5":"markdown","c7d884d2":"markdown","ed266dcb":"markdown","e140d806":"markdown","c0087845":"markdown","c6657489":"markdown","b1277d37":"markdown","8c3361b0":"markdown","32c0532a":"markdown","c1a98af2":"markdown","8ef41ff6":"markdown"},"source":{"2c28c627":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom gplearn.genetic import SymbolicRegressor,SymbolicTransformer\nfrom gplearn.functions import make_function\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_selection import RFE\nfrom sklearn.feature_selection import RFECV\n\nimport os\n\nprint(os.listdir(\"..\/input\"))\nprint(os.listdir(\"..\/input\/LANL-Earthquake-Prediction\"))\nprint(os.listdir(\"..\/input\/lanl-features\"))","4e6b91e3":"X = pd.read_csv('..\/input\/lanl-features\/train_features_denoised.csv')\nX_test = pd.read_csv('..\/input\/lanl-features\/test_features_denoised.csv')\ny = pd.read_csv('..\/input\/lanl-features\/y.csv')\nsubmission = pd.read_csv('..\/input\/LANL-Earthquake-Prediction\/sample_submission.csv',index_col='seg_id')","d24e48b2":"X.drop('seg_id',axis=1,inplace=True)\nX_test.drop('seg_id',axis=1,inplace=True)\nX.drop('target',axis=1,inplace=True)\nX_test.drop('target',axis=1,inplace=True)\n\nalldata = pd.concat([X, X_test])\n\nscaler = StandardScaler()\n\nalldata = pd.DataFrame(scaler.fit_transform(alldata), columns=alldata.columns)\n\nX = alldata[:X.shape[0]]\nX_test = alldata[X.shape[0]:]","d562a89d":"%%time\ncorr_matrix = X.corr()\ncorr_matrix = corr_matrix.abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nto_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n\nX = X.drop(to_drop, axis=1)\nX_test = X_test.drop(to_drop, axis=1)\nprint(X.shape)\nprint(X_test.shape)","feaaedf7":"%%time\nrf = RandomForestRegressor(n_estimators=10)\nrfecv = RFECV(estimator=rf, step=1, cv=5, scoring='neg_mean_absolute_error', verbose=0, n_jobs=4) #4-fold cross-validation with mae\nrfecv = rfecv.fit(X, y.values)\nprint('Optimal number of features :', rfecv.n_features_)\nprint('Best features :', X.columns[rfecv.support_])\n\nX = X[X.columns[rfecv.support_].values]\nX_test = X_test[X_test.columns[rfecv.support_].values]\nprint(X.shape)\nprint(X_test.shape)","c79e253c":"X[\"mean_y\"] = np.full(len(y), y.values.mean())\nX[\"max_y\"] = np.full(len(y), y.values.max())\nX[\"min_y\"] = np.full(len(y), y.values.min())\nX[\"std_y\"] = np.full(len(y), y.values.std())\n\nX_test[\"mean_y\"] = np.full(len(X_test), y.values.mean())\nX_test[\"max_y\"] = np.full(len(X_test), y.values.max())\nX_test[\"min_y\"] = np.full(len(X_test), y.values.min())\nX_test[\"std_y\"] = np.full(len(X_test), y.values.std())\n\nprint(X.shape)\nprint(X_test.shape)","d2de6698":"list(X.columns)","891a1359":"def tanh(x):\n    return np.tanh(x)\ndef sinh(x):\n    return np.sinh(x)\ndef cosh(x):\n    return np.cosh(x)\ndef arctan(x):\n    return np.arctan(x)\ndef arcsin(x):\n    return np.arcsin(x)\ndef arccos(x):\n    return np.arccos(x)\ndef arctanh(x):\n    return np.arctan(x)\ndef arcsinh(x):\n    return np.arcsin(x)\ndef arccosh(x):\n    return np.arccos(x)\ndef exp(x):\n    return np.exp(x)\ndef exp2(x):\n    return np.exp2(x)\ndef expm1(x):\n    return np.expm1(x)\ndef log2(x):\n    return np.log2(x)\ndef log1p(x):\n    return np.log1p(x)\n \n\ngp_tanh = make_function(tanh,\"tanh\",1)\ngp_sinh = make_function(sinh,\"sinh\",1)\ngp_cosh = make_function(cosh,\"cosh\",1)\n\ngp_arctan = make_function(arctan,\"arctan\",1)\ngp_arcsin = make_function(arcsin,\"arcsin\",1)\ngp_arccos = make_function(arccos,\"arccos\",1)\n\ngp_arctanh = make_function(arctanh,\"arctanh\",1)\ngp_arcsinh = make_function(arcsinh,\"arcsinh\",1)\ngp_arccosh = make_function(arccosh,\"arccosh\",1)\n\ngp_exp = make_function(exp,\"exp\",1)\ngp_exp2 = make_function(exp2,\"exp2\",1)\ngp_expm1 = make_function(expm1,\"expm1\",1)\n#gp_log2 = make_function(log2,\"log2\",1)\n#gp_log1p = make_function(log1p,\"log1p\",1)","c05d99d7":"%%time\nest_gp = SymbolicRegressor(population_size=X.shape[1]*17*10,\n                           tournament_size=X.shape[1]*17\/\/1,\n                           generations=50, stopping_criteria=1.79,\n                           p_crossover=0.9, p_subtree_mutation=0.0001, p_hoist_mutation=0.0001, p_point_mutation=0.0001,\n                           max_samples=0.8, verbose=1,\n                           function_set = ('add', 'sub', 'mul', 'div', \n                                           'sqrt', 'log', 'abs', 'neg', 'inv','max', 'min', \n                                           'tan', 'cos', 'sin', \n                                           gp_tanh, #gp_sinh, gp_cosh,\n                                           gp_arctan, #gp_arcsin, gp_arccos,\n                                           gp_arctanh, #gp_arcsinh, gp_arccosh,\n                                           #gp_exp,\n                                           #gp_exp2,\n                                           #gp_expm1,\n                                           #gp_log1p,                                           \n                                          ),\n                           #function_set = (gp_tanh, 'add', 'sub', 'mul', 'div'),\n                           metric = 'mean absolute error', warm_start=True,\n                           n_jobs = 4, parsimony_coefficient=0.00001, random_state=11)\n'''\n\nest_gp = SymbolicTransformer(population_size=1000, \n                             hall_of_fame=100, \n                             n_components=10, \n                             generations=20, \n                             tournament_size=20, \n                             stopping_criteria=1.0, \n                             const_range=(-1.0, 1.0), \n                             init_depth=(2, 6), \n                             init_method='half and half', \n                             function_set=('add', 'sub', 'mul', 'div'), \n                             metric='pearson', \n                             parsimony_coefficient=0.001, p_crossover=0.9, p_subtree_mutation=0.01, p_hoist_mutation=0.01, p_point_mutation=0.01, p_point_replace=0.05, max_samples=1.0, \n                             feature_names=None, warm_start=False, low_memory=False, n_jobs=4, verbose=1, random_state=11)\n '''\n\nest_gp.fit(X, y)","40bbcdc4":"#print(\"gpLearn Program:\", est_gp._program)\ngenetic_formula = str(est_gp._program)\nfor i in range(len(X.columns)):\n    genetic_formula = genetic_formula.replace(f'X{i}', X.columns[i])\n    \nprint(\"Genetic Formula: \", genetic_formula)","650aaabe":"y_gp = est_gp.predict(X)\ngpLearn_MAE = mean_absolute_error(y, y_gp)\nprint(\"gpLearn MAE:\", gpLearn_MAE)","30cff0c3":"df_result = pd.DataFrame()\ndf_result[\"predict\"] = y_gp\ndf_result[\"real\"] = y","3bb53c46":"df_result[:1500].plot()","e2ba7837":"df_result[-1500:].plot()","148d9343":"df_result.plot()","ede6487d":"submission.time_to_failure = est_gp.predict(X_test)\nsubmission.to_csv('submission.csv', index=True)","9db69851":"submission.head(10)","d8e5e53b":"Give training data some insight of the time range of this experiment. Little bit cheating","47ce43c5":"# Scaling","c7d884d2":"# Setup","ed266dcb":"## Recursive feature elimination with cross validation and random forest regression","e140d806":"# Define More Genetic Functions","c0087845":"## Drop highly correlated features","c6657489":"## Prediction","b1277d37":"## Formula","8c3361b0":"## Submission","32c0532a":"# Read Data","c1a98af2":"# Feature Selection","8ef41ff6":"# Define Symbolic Regressor and Train"}}