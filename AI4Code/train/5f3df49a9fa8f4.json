{"cell_type":{"618c0f25":"code","a60deb54":"code","a411a47e":"code","f495623b":"code","35d67892":"code","62c9dfe3":"code","6cc37b8b":"code","a9121e73":"markdown","fb16fe13":"markdown","a4b89a1d":"markdown","7bf12088":"markdown","91d010d8":"markdown"},"source":{"618c0f25":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils import data\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport torchvision.transforms.functional as TF\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\nimport torch.optim as optim\n\nimport numpy as np\nimport os\nfrom pathlib import Path\nfrom skimage.io import imread\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","a60deb54":"class LargeScaleFishDataset(data.Dataset):\n    def __init__(self, inputs : list, targets : list, transform=None):\n        super().__init__() \n        self.inputs = inputs\n        self.targets = targets\n        self.transform = transform\n        \n    def __len__(self,):\n        return len(self.inputs)\n    \n    def __getitem__(self, idx : int):\n        \n        input_image = self.inputs[idx]\n        target_image = self.targets[idx]\n\n        image = np.array(Image.open(input_image).convert(\"RGB\"))\n        mask = np.array(Image.open(target_image).convert(\"L\"), dtype=np.float32)\n        mask[mask == 255.0] = 1.0\n\n        if self.transform is not None:\n            augmentations = self.transform(image=image, mask=mask)\n            image = augmentations[\"image\"]\n            mask = augmentations[\"mask\"]\n\n        return image, mask","a411a47e":"data_dir =  '..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\/'\npath = Path(data_dir)\npath_images = path.glob('**\/*.png')\ngt_images = [str(path_image) for path_image in path_images if 'GT' in str(path_image)]\nprint(f'Number of GT images :{len(gt_images)}')\npath_images = path.glob('**\/*.png')\ntrain_images = [str(path_image) for path_image in path_images if 'GT' not in str(path_image)]\nprint(f'Number of training images :{len(train_images)}')\nlabels = [os.path.split(os.path.split(name)[0])[1] for name in train_images]\nprint(f'Number of labels :{len(labels)}')\nprint(train_images[0], gt_images[0],labels[0])\n\n\nx_train, x_val ,y_train, y_val = train_test_split(\n    train_images,\n    gt_images,\n    test_size=0.05, \n    random_state=42, \n    shuffle=True)\n\ndef get_loaders(\n    train_dir,\n    train_maskdir,\n    val_dir,\n    val_maskdir,\n    batch_size,\n    train_transform,\n    val_transform,\n    num_workers=4,\n    pin_memory=True,\n):\n    train_ds = LargeScaleFishDataset(\n        inputs=train_dir,\n        targets=train_maskdir,\n        transform=train_transform,\n    )\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        shuffle=True,\n    )\n\n    val_ds = LargeScaleFishDataset(\n        inputs=val_dir,\n        targets=val_maskdir,\n        transform=val_transform,\n    )\n\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        shuffle=False,\n    )\n\n    return train_loader, val_loader","f495623b":"def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)\n\ndef load_checkpoint(checkpoint, model):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])\n\ndef check_accuracy(loader, model, device=\"cuda\"):\n    num_correct = 0\n    num_pixels = 0\n    dice_score = 0\n    model.eval()\n\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device)\n            y = y.to(device).unsqueeze(1)\n            preds = torch.sigmoid(model(x))\n            preds = (preds > 0.5).float()\n            num_correct += (preds == y).sum()\n            num_pixels += torch.numel(preds)\n            dice_score += (2 * (preds * y).sum()) \/ (\n                (preds + y).sum() + 1e-8\n            )\n\n    print(\n        f\"Got {num_correct}\/{num_pixels} with acc {num_correct\/num_pixels*100:.2f}\"\n    )\n    print(f\"Dice score: {dice_score\/len(loader)}\")\n    model.train()\n\ndef save_predictions_as_imgs(\n    loader, model, folder=\"saved_images\/\", device=\"cuda\"\n):\n    model.eval()\n    for idx, (x, y) in enumerate(loader):\n        x = x.to(device=device)\n        with torch.no_grad():\n            preds = torch.sigmoid(model(x))\n            preds = (preds > 0.5).float()\n        torchvision.utils.save_image(\n            preds, f\"{folder}\/pred_{idx}.png\"\n        )\n        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n\n    model.train()\n    \n!mkdir saved_images","35d67892":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass UNET(nn.Module):\n    def __init__(\n            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n    ):\n        super(UNET, self).__init__()\n        self.ups = nn.ModuleList()\n        self.downs = nn.ModuleList()\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Down part of UNET\n        for feature in features:\n            self.downs.append(DoubleConv(in_channels, feature))\n            in_channels = feature\n\n        # Up part of UNET\n        for feature in reversed(features):\n            self.ups.append(\n                nn.ConvTranspose2d(\n                    feature*2, feature, kernel_size=2, stride=2,\n                )\n            )\n            self.ups.append(DoubleConv(feature*2, feature))\n\n        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n\n    def forward(self, x):\n        skip_connections = []\n\n        for down in self.downs:\n            x = down(x)\n            skip_connections.append(x)\n            x = self.pool(x)\n\n        x = self.bottleneck(x)\n        skip_connections = skip_connections[::-1]\n\n        for idx in range(0, len(self.ups), 2):\n            x = self.ups[idx](x)\n            skip_connection = skip_connections[idx\/\/2]\n\n            if x.shape != skip_connection.shape:\n                x = TF.resize(x, size=skip_connection.shape[2:])\n\n            concat_skip = torch.cat((skip_connection, x), dim=1)\n            x = self.ups[idx+1](concat_skip)\n\n        return self.final_conv(x)","62c9dfe3":"# Hyperparameters etc.\nLEARNING_RATE = 1e-4\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nBATCH_SIZE = 32\nNUM_EPOCHS = 3\nNUM_WORKERS = 2\nIMAGE_HEIGHT = 160  # 1280 originally\nIMAGE_WIDTH = 240  # 1918 originally\nPIN_MEMORY = True\nLOAD_MODEL = False\n\ndef train_fn(loader, model, optimizer, loss_fn, scaler):\n    loop = tqdm(loader)\n\n    for batch_idx, (data, targets) in enumerate(loop):\n        data = data.to(device=DEVICE)\n        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n\n        # forward\n        with torch.cuda.amp.autocast():\n            predictions = model(data)\n            loss = loss_fn(predictions, targets)\n\n        # backward\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        # update tqdm loop\n        loop.set_postfix(loss=loss.item())\n\n\ndef main():\n    train_transform = A.Compose(\n        [\n            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n            A.Rotate(limit=35, p=1.0),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.1),\n            A.Normalize(\n                mean=[0.0, 0.0, 0.0],\n                std=[1.0, 1.0, 1.0],\n                max_pixel_value=255.0,\n            ),\n            ToTensorV2(),\n        ],\n    )\n\n    val_transforms = A.Compose(\n        [\n            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n            A.Normalize(\n                mean=[0.0, 0.0, 0.0],\n                std=[1.0, 1.0, 1.0],\n                max_pixel_value=255.0,\n            ),\n            ToTensorV2(),\n        ],\n    )\n\n    model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n    loss_fn = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n    train_loader, val_loader = get_loaders(\n        x_train,\n        y_train,\n        x_val,\n        y_val,\n        BATCH_SIZE,\n        train_transform,\n        val_transforms,\n        NUM_WORKERS,\n        PIN_MEMORY,\n    )\n\n    if LOAD_MODEL:\n        load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n\n\n    check_accuracy(val_loader, model, device=DEVICE)\n    scaler = torch.cuda.amp.GradScaler()\n\n    for epoch in range(NUM_EPOCHS):\n        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n\n        # save model\n        checkpoint = {\n            \"state_dict\": model.state_dict(),\n            \"optimizer\":optimizer.state_dict(),\n        }\n        save_checkpoint(checkpoint)\n\n        # check accuracy\n        check_accuracy(val_loader, model, device=DEVICE)\n\n        # print some examples to a folder\n        save_predictions_as_imgs(\n            val_loader, model, folder=\"saved_images\/\", device=DEVICE\n        )","6cc37b8b":"main()","a9121e73":"# 2)Make Custom Dataset,train and validation dataloader","fb16fe13":"# 5) Training our custom UNet","a4b89a1d":"# 4) Make custom UNet from scratch","7bf12088":"# 1)Imports\n","91d010d8":"# 3) Define service function"}}