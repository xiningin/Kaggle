{"cell_type":{"4744b073":"code","e5661908":"code","2ee872e5":"code","fa15ff8c":"code","c246291b":"code","6917bd49":"code","6ab6436a":"code","e92b6797":"code","9d78ea2b":"code","8b98c564":"code","5ac7a3f3":"code","ac26f320":"code","d56cf7e6":"code","0b00e768":"code","15d36412":"code","769a4fd9":"code","3e5de0df":"code","77ec05df":"code","aeff07b5":"markdown"},"source":{"4744b073":"# Config\nbatch_size = 1\nmin_tokens = 5\ntok_checkpoint = '..\/input\/longformer\/model'\nmodel_checkpoint = '..\/input\/feedback-prize-huggingface-baseline-training\/longformer-base-4096-4\/pytorch_model.bin'","e5661908":"# Load data\nimport pandas as pd\n\ntrain = pd.read_csv('..\/input\/feedback-prize-2021\/train.csv')\ntrain.head(1)\n\ntest = pd.read_csv('..\/input\/feedback-prize-2021\/sample_submission.csv')\ntest.head(1)","2ee872e5":"# Setup dictionaries\nclasses = train.discourse_type.unique().tolist()\n\nfrom collections import defaultdict\n\ntags = defaultdict()\nfor i, c in enumerate(classes):\n    tags[f'B-{c}'] = i\n    tags[f'I-{c}'] = i + len(classes)\ntags[f'O'] = len(classes) * 2\ntags[f'Special'] = -100\nl2i = dict(tags)\n\ni2l = defaultdict()\nfor k, v in l2i.items(): \n    i2l[v] = k\ni2l[-100] = 'Special'\ni2l = dict(i2l)","fa15ff8c":"# Helper functions\nfrom pathlib import Path\n\ntest_path = Path('..\/input\/feedback-prize-2021\/test')\n\ndef get_test_text(ids):\n    with open(test_path\/f'{ids}.txt', 'r') as file: data = file.read()\n    return data","c246291b":"# Tokenizer\nfrom transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(tok_checkpoint, add_prefix_space=True)","6917bd49":"# Load model\nfrom transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\nimport torch\n\nmodel = AutoModelForTokenClassification.from_pretrained(tok_checkpoint, num_labels=len(i2l)-1)\n\nmodel.load_state_dict(torch.load(model_checkpoint))\nmodel.eval();","6ab6436a":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer)","e92b6797":"# We'll use trainer with the loaded model to run inference on test set\ntrainer = Trainer(\n    model,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","9d78ea2b":"# code that will convert our predictions into prediction strings. we'll skip visualization here. \n# this most likely requires some refactoring\n\ndef get_class(c):\n    if c == 14: return 'Other'\n    else: return i2l[c][2:]\n\ndef pred2span(pred, example, viz=False, test=False):\n    example_id = example['id']\n    n_tokens = len(example['input_ids'])\n    classes = []\n    all_span = []\n    for i, c in enumerate(pred.tolist()):\n        if i == n_tokens-1:\n            break\n        if i == 0:\n            cur_span = example['offset_mapping'][i]\n            classes.append(get_class(c))\n        elif i > 0 and (c == pred[i-1] or (c-7) == pred[i-1]):\n            cur_span[1] = example['offset_mapping'][i][1]\n        else:\n            all_span.append(cur_span)\n            cur_span = example['offset_mapping'][i]\n            classes.append(get_class(c))\n    all_span.append(cur_span)\n    \n    if test: text = get_test_text(example_id)\n    else: text = get_raw_text(example_id)\n        \n    # map token ids to word (whitespace) token ids\n    predstrings = []\n    for span in all_span:\n        span_start = span[0]\n        span_end = span[1]\n        before = text[:span_start]\n        token_start = len(before.split())\n        if len(before) == 0: token_start = 0\n        elif before[-1] != ' ': token_start -= 1\n        num_tkns = len(text[span_start:span_end+1].split())\n        tkns = [str(x) for x in range(token_start, token_start+num_tkns)]\n        predstring = ' '.join(tkns)\n        predstrings.append(predstring)\n                    \n    rows = []\n    for c, span, predstring in zip(classes, all_span, predstrings):\n        e = {\n            'id': example_id,\n            'discourse_type': c,\n            'predictionstring': predstring,\n            'discourse_start': span[0],\n            'discourse_end': span[1],\n            'discourse': text[span[0]:span[1]+1]\n        }\n        rows.append(e)\n\n\n    df = pd.DataFrame(rows)\n    df['length'] = df['discourse'].apply(lambda t: len(t.split()))\n    \n    # short spans are likely to be false positives, we can choose a min number of tokens based on validation\n    df = df[df.length > min_tokens].reset_index(drop=True)\n\n    return df","8b98c564":"# Load test data\nimport os \n\nfiles = os.listdir('..\/input\/feedback-prize-2021\/test')\nids = [x.split('.')[0] for x in files]\n\ndf_test = pd.DataFrame()\ndf_test['id'] = ids\ndf_test['text'] = df_test['id'].apply(get_test_text)\ndf_test","5ac7a3f3":"from datasets import Dataset\n\ntest_ds = Dataset.from_pandas(df_test)\ntest_ds","ac26f320":"def tokenize_for_test(examples):\n\n    o = tokenizer(examples['text'], truncation=True, return_offsets_mapping=True, max_length=4096)\n  \n    return o","d56cf7e6":"tokenized_test = test_ds.map(tokenize_for_test)\ntokenized_test","0b00e768":"predictions, _, _ = trainer.predict(tokenized_test)","15d36412":"import numpy as np\n\npreds = np.argmax(predictions, axis=-1)\npredictions.shape, preds.shape","769a4fd9":"dfs = []\nfor i in range(len(tokenized_test)):\n    dfs.append(pred2span(preds[i], tokenized_test[i], test=True))\n\npred_df = pd.concat(dfs, axis=0)\npred_df['class'] = pred_df['discourse_type']","3e5de0df":"sub = pred_df[['id', 'class', 'predictionstring']]","77ec05df":"sub.to_csv('submission.csv', index=False)","aeff07b5":"# HuggingFace Inference Baseline\n\nTraining notebook: https:\/\/www.kaggle.com\/thedrcat\/feedback-prize-huggingface-baseline-training"}}