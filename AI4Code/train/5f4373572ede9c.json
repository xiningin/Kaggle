{"cell_type":{"e4ba3415":"code","397e885f":"code","5b3beb40":"code","3d7aa6de":"code","6ea6e929":"code","4ff683d6":"code","33a9918a":"code","2d87ec72":"code","ecae9fd6":"code","6c4653ed":"code","20ea5078":"code","0723e4b0":"code","30e42fd3":"code","30e46fe9":"code","f50344c2":"code","8294aed3":"code","74ba309b":"code","f6db58f3":"code","2b7cd009":"code","a3c88bbe":"code","b9c98ce1":"code","c27a82df":"code","ca28f9fb":"code","159e292f":"code","365cf91d":"code","8e4d410c":"code","8d9a49a2":"code","888f87b9":"code","d3af05b0":"code","4bf9738f":"code","3835fbca":"code","a2a21b9d":"code","4bed4cf3":"code","fc07aba2":"code","5a3e29fe":"markdown","9b0c3110":"markdown","5cb7ccd3":"markdown","ff3d40bf":"markdown","fdab4128":"markdown","223fa9fd":"markdown","56491641":"markdown","d219aa2f":"markdown","03d769e6":"markdown","770e8f40":"markdown"},"source":{"e4ba3415":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","397e885f":"!pip install dlib\n!pip install imutils","5b3beb40":"import numpy as np\nimport os\nimport imutils\nimport dlib # run \"pip install dlib\"\nimport cv2 # run \"pip install opencv-python\"\n\nimport imageio\nfrom imutils import face_utils","3d7aa6de":"def rect_to_bb(rect):\n    # take a bounding predicted by dlib and convert it\n    # to the format (x, y, w, h) as we would normally do\n    # with OpenCV\n    x = rect.left()\n    y = rect.top()\n    w = rect.right() - x\n    h = rect.bottom() - y\n\n    # return a tuple of (x, y, w, h)\n    return (x, y, w, h)\n\ndef shape_to_np(shape, dtype=\"int\"):\n    # initialize the list of (x, y)-coordinates\n    coords = np.zeros((68, 2), dtype=dtype)\n\n    # loop over the 68 facial landmarks and convert them\n    # to a 2-tuple of (x, y)-coordinates\n    for i in range(0, 68):\n    \tcoords[i] = (shape.part(i).x, shape.part(i).y)\n\n    # return the list of (x, y)-coordinates\n    return coords","6ea6e929":"def crop_and_save_image(img, img_path, write_img_path, img_name):\n    detector = dlib.get_frontal_face_detector()\n    predictor = dlib.shape_predictor('..\/input\/miraclvc1\/shape_predictor_68_face_landmarks.dat')\n    # load the input image, resize it, and convert it to grayscale\n\n    image = cv2.imread(img_path)\n    image = imutils.resize(image, width=500)\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # detect faces in the grayscale image\n    rects = detector(gray, 1)\n    if len(rects) > 1:\n    \tprint( \"ERROR: more than one face detected\")\n    \treturn\n    if len(rects) < 1:\n    \tprint( \"ERROR: no faces detected\")\n    \treturn\n\n    for (i, rect) in enumerate(rects):\n        shape = predictor(gray, rect)\n        shape = face_utils.shape_to_np(shape)\n        name, i, j = 'mouth', 48, 68\n        # clone = gray.copy()\n\n        (x, y, w, h) = cv2.boundingRect(np.array([shape[i:j]]))        \n        roi = gray[y:y+h, x:x+w]\n        roi = imutils.resize(roi, width = 250, inter=cv2.INTER_CUBIC)        \n#         print('cropped\/' + write_img_path)\n#         cv2.imwrite('cropped\/' + write_img_path, roi)\n","4ff683d6":"# os.listdir('..\/input\/miraclvc1\/dataset\/dataset')\n# predictor = dlib.shape_predictor('..\/input\/miraclvc1\/shape_predictor_68_face_landmarks.dat')","33a9918a":"people = ['F01','F02','F04','F05','F06','F07','F08','F09', 'F10','F11','M01','M02','M04','M07','M08']\ndata_types = ['words']\nfolder_enum = ['01','02','03','04','05','06','07','08', '09', '10']\ninstances = ['01','02','03','04','05','06','07','08', '09', '10']\n\nwords = ['Begin', 'Choose', 'Connection', 'Navigation', 'Next', 'Previous', 'Start', 'Stop', 'Hello', 'Web']          \nwords_di = {i:words[i] for i in range(len(words))}","2d87ec72":"# if not os.path.exists('cropped'):\n#     os.mkdir('cropped')","ecae9fd6":"import shutil\n\ndef crop_one_person():      \n    os.mkdir('cropped')\n    people = ['F01']\n    data_types = ['words']\n    folder_enum = ['01']\n    instances = ['01']\n\n    i = 1\n    for person_ID in people:\n        if not os.path.exists('cropped\/' + person_ID ):\n            os.mkdir('cropped\/' + person_ID + '\/')\n\n        for data_type in data_types:\n            if not os.path.exists('cropped\/' + person_ID + '\/' + data_type):\n                os.mkdir('cropped\/' + person_ID + '\/' + data_type)\n\n            for phrase_ID in folder_enum:\n                if not os.path.exists('cropped\/' + person_ID + '\/' + data_type + '\/' + phrase_ID):\n                    # F01\/phrases\/01\n                    os.mkdir('cropped\/' + person_ID + '\/' + data_type + '\/' + phrase_ID)\n\n                for instance_ID in instances:\n                    # F01\/phrases\/01\/01\n                    directory = '..\/input\/miraclvc1\/dataset\/dataset\/' + person_ID + '\/' + data_type + '\/' + phrase_ID + '\/' + instance_ID + '\/'\n                    dir_temp = person_ID + '\/' + data_type + '\/' + phrase_ID + '\/' + instance_ID + '\/'\n    #                 print(directory)\n                    filelist = os.listdir(directory)\n                    if not os.path.exists('cropped\/' + person_ID + '\/' + data_type + '\/' + phrase_ID + '\/' + instance_ID):\n                        os.mkdir('cropped\/' + person_ID + '\/' + data_type + '\/' + phrase_ID + '\/' + instance_ID)\n\n                        for img_name in filelist:\n                            if img_name.startswith('color'):\n                                image = imageio.imread(directory + '' + img_name)\n                                crop_and_save_image(image, directory + '' + img_name,\n                                                    dir_temp + '' + img_name, img_name)\n\n    print(f'Iteration : {i}')\n    i += 1\n    shutil.rmtree('cropped')","6c4653ed":"# import time\n\n# times = 0\n# for _ in range(7):\n#     t1 = time.time()\n#     crop_one_person()\n#     t2 = time.time()\n#     times += (t2 - t1)\n\n# print(\"Average time over 7 iterations : \", times\/7)","20ea5078":"# os.listdir('..\/input\/cropped-data\/cropped')","0723e4b0":"max_seq_length = 22\n\nX_train = []\ny_train = []\nX_val = []\ny_val = []\nX_test = []\ny_test = []\n\n\nMAX_WIDTH = 100\nMAX_HEIGHT = 100","30e42fd3":"from skimage.transform import resize\nimport time","30e46fe9":"t1 = time.time()\nUNSEEN_VALIDATION_SPLIT = ['F07', 'M02']\nUNSEEN_TEST_SPLIT = ['F04']\n\ndirectory = \"..\/input\/cropped-data\/cropped\"\n\nfor person_id in people:\n    tx1 = time.time()\n    for data_type in data_types:\n        for word_index, word in enumerate(folder_enum):\n#             print(f\"Word : '{words[word_index]}'\")\n            for iteration in instances:\n                path = os.path.join(directory, person_id, data_type, word, iteration)\n                filelist = sorted(os.listdir(path + '\/'))\n                sequence = [] \n                for img_name in filelist:\n                    if img_name.startswith('color'):\n                        image = imageio.imread(path + '\/' + img_name)\n                        image = resize(image, (MAX_WIDTH, MAX_HEIGHT))\n                        image = 255 * image\n                        # Convert to integer data type pixels.\n                        image = image.astype(np.uint8)\n                        sequence.append(image)                        \n                pad_array = [np.zeros((MAX_WIDTH, MAX_HEIGHT))]                            \n                sequence.extend(pad_array * (max_seq_length - len(sequence)))\n                sequence = np.array(sequence)\n                                \n                if person_id in UNSEEN_TEST_SPLIT:\n                    X_test.append(sequence)\n                    y_test.append(word_index)\n                elif person_id in UNSEEN_VALIDATION_SPLIT:\n                    X_val.append(sequence)\n                    y_val.append(word_index)\n                else:\n                    X_train.append(sequence)\n                    y_train.append(word_index)    \n    tx2 = time.time()\n    print(f'Finished reading images for person {person_id}. Time taken : {tx2 - tx1} secs.')    \n    \nt2 = time.time()\nprint(f\"Time taken for creating constant size 3D Tensors from those cropped lip regions : {t2 - t1} secs.\")","f50344c2":"X_train = np.array(X_train)\nX_val = np.array(X_val)\nX_test = np.array(X_test)","8294aed3":"print(X_train.shape)\nprint(X_val.shape)\nprint(X_test.shape)","74ba309b":"y_train = np.array(y_train)\ny_val = np.array(y_val)\ny_test = np.array(y_test)","f6db58f3":"print(y_train.shape)\nprint(y_val.shape)\nprint(y_test.shape)","2b7cd009":"def normalize_it(X):\n    v_min = X.min(axis=(2, 3), keepdims=True)\n    v_max = X.max(axis=(2, 3), keepdims=True)\n    X = (X - v_min)\/(v_max - v_min)\n    X = np.nan_to_num(X)\n    return X","a3c88bbe":"from keras.utils import np_utils, generic_utils","b9c98ce1":"X_train = normalize_it(X_train)\nX_val = normalize_it(X_val)\nX_test = normalize_it(X_test)\n\ny_train = np_utils.to_categorical(y_train, 10)\ny_test = np_utils.to_categorical(y_test, 10)\ny_val = np_utils.to_categorical(y_val, 10)\n\nfrom sklearn.utils import shuffle\nX_train, y_train = shuffle(X_train, y_train, random_state=0)\nX_test, y_test = shuffle(X_test, y_test, random_state=0)\nX_val, y_val = shuffle(X_val, y_val, random_state=0)","c27a82df":"X_train = np.expand_dims(X_train, axis=4)\nX_val = np.expand_dims(X_val, axis=4)\nX_test = np.expand_dims(X_test, axis=4)","ca28f9fb":"print(X_train.shape)\nprint(X_val.shape)\nprint(X_test.shape)","159e292f":"from keras.layers.convolutional import Conv3D, MaxPooling3D\nfrom keras.layers.core import Dense, Dropout, Flatten\nfrom keras.models import Sequential\nfrom keras.layers import Activation, ZeroPadding3D, TimeDistributed, LSTM, GRU, Reshape\nfrom keras.utils import plot_model\nfrom keras.layers.normalization import BatchNormalization\nimport matplotlib.pyplot as plt","365cf91d":"# model = Sequential()\n\n# # 1st layer group\n# model.add(Conv3D(64, (3, 3, 3), strides = 1, input_shape=(22, 100, 100, 1), activation='relu', padding='valid'))\n# model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n\n# model.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1))\n# model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n\n# model.add(Conv3D(256, (2, 2, 2), activation='relu', strides=1))\n# model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n\n# model.add((Flatten()))\n\n# # # FC layers group\n# model.add(Dense(4096, activation='relu'))\n# model.add(Dropout(.5))\n# model.add(Dense(2048, activation='relu'))\n# model.add(Dropout(.5))\n\n# model.add(Dense(10, activation='softmax'))\n\n# model.compile(loss='categorical_crossentropy', optimizer='Adagrad', metrics=['accuracy'])\n# model.summary()","8e4d410c":"model = Sequential()\n\n# 1st layer group\nmodel.add(Conv3D(32, (3, 3, 3), strides = 1, input_shape=(22, 100, 100, 1), activation='relu', padding='valid'))\nmodel.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n\nmodel.add(Conv3D(64, (3, 3, 3), activation='relu', strides=1))\nmodel.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n\nmodel.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1))\nmodel.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n\nshape = model.get_output_shape_at(0)\nmodel.add(Reshape((shape[-1],shape[1]*shape[2]*shape[3])))\n\n# LSTMS - Recurrent Network Layer\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(.5))\n\nmodel.add((Flatten()))\n\n# # FC layers group\nmodel.add(Dense(2048, activation='relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(.5))\n\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n# model.summary()","8d9a49a2":"# model = Sequential()\n\n# # 1st layer group\n# model.add(Conv3D(32, (3, 3, 3), strides = 1, input_shape=(22, 100, 100, 1), activation='relu', padding='valid'))\n# model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n\n# model.add(Conv3D(64, (3, 3, 3), activation='relu', strides=1))\n# model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n\n# model.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1))\n# model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n\n# shape = model.get_output_shape_at(0)\n# model.add(Reshape((shape[-1],shape[1]*shape[2]*shape[3])))\n\n# # Gated Recurrent Unit - Recurrent Network Layer\n# model.add(GRU(32, return_sequences=True))\n# model.add(Dropout(.5))\n\n# model.add((Flatten()))\n\n# # # FC layers group\n# model.add(Dense(2048, activation='relu'))\n# model.add(Dropout(.5))\n# model.add(Dense(1024, activation='relu'))\n# model.add(Dropout(.5))\n\n# model.add(Dense(10, activation='softmax'))\n\n# model.compile(loss='categorical_crossentropy', optimizer='Adagrad', metrics=['accuracy'])\n# model.summary()","888f87b9":"t1 = time.time()\nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=45)\nt2 = time.time()\nprint()\nprint(f\"Training time : {t2 - t1} secs.\")","d3af05b0":"# from keras.utils import plot_model\n# plot_model(model, show_shapes=True, show_layer_names=True)","4bf9738f":"# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","3835fbca":"# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.xlim(1, 40)\n# plt.ylim(0, 3)\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","a2a21b9d":"ypred = model.predict(X_test)","4bed4cf3":"predicted_words = [words[i] for i in np.argmax(ypred, axis=1)]\nactual_words = [words[i] for i in np.argmax(y_test, axis=1)] ","fc07aba2":"correct = 0\nfor p, a in zip(predicted_words, actual_words):\n    if p == a:\n        correct += 1\n#     print(f\"Predicted : {p} \\t Actual : {a}\")\n\naccuracy = correct\/len(actual_words)\nprint(f\"Accuracy = {accuracy} on completely unseen data\")","5a3e29fe":"### Training & Validation loss values","9b0c3110":"### Uncomment for creating a cropped version of the dataset\n\nJust to be clear, this is what cropped version for each instance looks like :\n\n![Demo](https:\/\/i.imgur.com\/z6YIvFL.png)\n\nNote : This will take some time to execute depending on the number of users. ","5cb7ccd3":"## Model Building and predicting","ff3d40bf":"* ### 3D CNNs + LSTM","fdab4128":"### Vanilla 3D CNNs","223fa9fd":"* ### 3D CNNs + GRUs","56491641":"Checking whether the cropped sequences are in the right directory","d219aa2f":"### Training & Validation accuracy values","03d769e6":"## Normalization and stuff","770e8f40":"### I've  model trained on a small part of data with a few convulation layers. This is just to get started with. Feel free to fork it or point out any bugs or improvements."}}