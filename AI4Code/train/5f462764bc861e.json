{"cell_type":{"a06d49b1":"code","b5ed5707":"code","ef70c6c9":"code","4e6a04c0":"code","6507ba93":"code","6ac1ae78":"code","537b095c":"code","9ca73787":"code","640e17a0":"code","5f727fb6":"code","2e1c26f3":"code","da123cd7":"code","6b181335":"code","c324b972":"code","a7ae7f81":"code","88b97a50":"code","83ef7791":"code","247b18e9":"code","fc686b31":"code","c7b3c3e9":"code","a7a4aae8":"markdown","9b7b90a6":"markdown","498fcb75":"markdown","bb95bf5b":"markdown","419129ae":"markdown","5943c9ab":"markdown","c8578b89":"markdown","210db987":"markdown","59fb3c33":"markdown","d59aabf6":"markdown","3e0d64eb":"markdown","c6274fe8":"markdown","ea569de0":"markdown","7cc70757":"markdown","61a99539":"markdown","c8a210c9":"markdown","72065b81":"markdown","80ed0dba":"markdown"},"source":{"a06d49b1":"import os\nimport cv2 # image handling\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\nimport sklearn\nfrom sklearn.cross_validation import train_test_split\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","b5ed5707":"lables = pd.read_csv('..\/input\/dog-breed-identification\/labels.csv')\nprint (lables.head(5))\nbreed_count = lables['breed'].value_counts()\nprint (breed_count.head())\nprint (breed_count.shape)","ef70c6c9":"targets = pd.Series(lables['breed'])\none_hot = pd.get_dummies(targets, sparse = True)\none_hot_labels = np.asarray(one_hot)","4e6a04c0":"img_rows=128\nimg_cols=128\nnum_channel=1# 3 colour channes","6507ba93":"img_1 = cv2.imread('..\/input\/dog-breed-identification\/train\/000bec180eb18c7604dcecc8fe0dba07.jpg', 0)\nplt.title('Original Image')\nplt.imshow(img_1)","6ac1ae78":"img_1_resize= cv2.resize(img_1, (img_rows, img_cols)) \nprint (img_1_resize.shape)\nplt.title('Resized Image')\nplt.imshow(img_1_resize)","537b095c":"x_feature = []\ny_feature = []\n\ni = 0 # initialisation\nfor f, img in tqdm(lables.values): # f for format ,jpg\n    train_img = cv2.imread('..\/input\/dog-breed-identification\/train\/{}.jpg'.format(f),0)\n    label = one_hot_labels[i]\n    train_img_resize = cv2.resize(train_img, (img_rows, img_cols)) \n    x_feature.append(train_img_resize)\n    y_feature.append(label)\n    i += 1","9ca73787":"x_train_data = np.array(x_feature, np.float32) \/ 255.   # \/= 255 for normolisation\nprint (x_train_data.shape)\nx_train_data = np.expand_dims(x_train_data, axis = 3)\nprint (x_train_data.shape)","640e17a0":"y_train_data = np.array(y_feature, np.uint8)\nprint (y_train_data.shape)","5f727fb6":"x_train, x_val, y_train, y_val = train_test_split(x_train_data, y_train_data, test_size=0.2, random_state=2)\nprint (x_train.shape)\nprint (x_val.shape)","2e1c26f3":"submission = pd.read_csv('..\/input\/dog-breed-identification\/sample_submission.csv')\ntest_img = submission['id']\nprint (test_img.head(5))","da123cd7":"x_test_feature = []\n\ni = 0 # initialisation\nfor f in tqdm(test_img.values): # f for format ,jpg\n    img = cv2.imread('..\/input\/dog-breed-identification\/test\/{}.jpg'.format(f), 0)\n    img_resize = cv2.resize(img, (img_rows, img_cols)) \n    x_test_feature.append(img_resize)","6b181335":"x_test_data = np.array(x_test_feature, np.float32) \/ 255. \nprint (x_test_data.shape)\nx_test_data = np.expand_dims(x_test_data, axis = 3)\nprint (x_test_data.shape)","c324b972":"from keras.models import Sequential  # initial NN\nfrom keras.layers import Dense, Dropout # construct each layer\nfrom keras.layers import Convolution2D # swipe across the image by 1\nfrom keras.layers import MaxPooling2D # swipe across by pool size\nfrom keras.layers import Flatten","a7ae7f81":"model = Sequential()","88b97a50":"# retifier ensure the non-linearity in the processing \nmodel.add(Convolution2D (filters = 64, kernel_size = (4,4),padding = 'Same', \n                         activation ='relu', input_shape = (img_rows, img_cols, num_channel))) \nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Convolution2D (filters = 64, kernel_size = (4,4),padding = 'Same', \n                         activation ='relu')) \nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten()) \n# fully connected ANN \nmodel.add(Dense(units = 120, activation = 'relu')) \n# output layer\nmodel.add(Dense(units = 120, activation = 'softmax')) ","83ef7791":"model.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"]) \nmodel.summary()","247b18e9":"batch_size = 128 \nnb_epochs = 2\nhistory = model.fit(x_train, y_train,\n                    batch_size=batch_size,\n                    epochs=nb_epochs,\n                    verbose=2, \n                    validation_data=(x_val, y_val),\n                    initial_epoch=0)","fc686b31":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","c7b3c3e9":"results = model.predict(x_test_data)\nprediction = pd.DataFrame(results)\n\n# Set column names to those generated by the one-hot encoding earlier\ncol_names = one_hot.columns.values\nprediction.columns = col_names\n# Insert the column id from the sample_submission at the start of the data frame\nprediction.insert(0, 'id', submission['id'])\n\nsubmission = prediction\nsubmission.to_csv('new_submission.csv', index=False)","a7a4aae8":"**Initialising model**","9b7b90a6":"**Thank you for reading**","498fcb75":"**Libraries that you need for image data preprocessing**","bb95bf5b":"**Fit the model into data**","419129ae":"**Testing on a single image, first read in the image file in graysalce, then resize it**","5943c9ab":"**The data frames need to be the form of arrays and normolised. Becuase I'm dealing with grayscale here, I needed to add the dimension at the end of the array else it keras would raise an exception**","c8578b89":"**This kernel is created to show the standard step-by-step process in handling image data. However, given the time limit of an hour, the kernel can only reach a low validation accuracy. Another way  of trainning the model from scratch is to run the script on a very powerful computer or using cloud computing. If you want to save time and computational power, you can also pre-process the data in the same manner and use [ImageNet pre-trained models](https:\/\/www.pyimagesearch.com\/2017\/03\/20\/imagenet-vggnet-resnet-inception-xception-keras\/). Now let's begin and hope you enjoy it. **","210db987":"**Now loop the proceedure through the train folder, and keep adding each new image data onto the existing data frame (x_feature) **","59fb3c33":"**Predict results**","d59aabf6":"**Spliting the training and validation sets**","3e0d64eb":"**One hot encoding the lables**","c6274fe8":"**Examine the breeds, and we found out there are 120 breeds in total**","ea569de0":"**Plot the loss and accuracy curves for training and validation**","7cc70757":"**I have a rather simple CNN here**\n1. Convetional layer (detect features in image matrix)\n2. Pooling layer (recongise features in different angle and\/or size)\n3. Convetional layer\n4. Pooling laye\n5. Flattening layer (flatten layers in array of imput)\n6. Full connected layer (full connected ANN)\n7. Output layer","61a99539":"**Set image parameters to be used later, I'm using grayscale here so the number of channel is 1**","c8a210c9":"**Compile the model**","72065b81":"**After we have done the trainning data, now we are doing the test data, do the same thing to prepare the test data**","80ed0dba":"**Now we have prepared: x_train, y_train, x_val, y_val and x_test. Time to build our CNN model. First import keras**"}}