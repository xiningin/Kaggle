{"cell_type":{"06398d84":"code","02ecd583":"code","9d920665":"code","6abe7837":"code","6c92ebac":"code","2074385a":"code","07bf6316":"code","48146c90":"code","db17b016":"code","0820995d":"code","81e0d3aa":"code","def4d3fa":"code","8b32422d":"code","473ef3ed":"code","c71e97f5":"code","a8af67d7":"code","d018064a":"code","863b27bf":"code","be5be3b1":"code","7b870e0b":"code","5ce95271":"code","ad74516c":"code","4ce2e2f3":"code","2f19507d":"code","fff9ff64":"code","c8f1d9d2":"code","77428f3c":"code","f0a504c5":"code","9d590967":"code","968c560d":"code","e51f9f70":"code","3b2ab271":"code","42bf4a48":"code","cfdd4bdb":"code","76ade597":"code","80f0ed51":"markdown","080759ad":"markdown","3bacdfa5":"markdown","a9093cc0":"markdown","90dfa380":"markdown","013041f6":"markdown","039ed7a8":"markdown","c2970ced":"markdown","f0dc92ec":"markdown","4b790c0c":"markdown","707fbe71":"markdown","7f85158b":"markdown","174c4958":"markdown","195561ca":"markdown","7f71e3b4":"markdown","92d8bcc5":"markdown","4361ec77":"markdown","f4eadafc":"markdown","759bce5d":"markdown","dd9b5b45":"markdown","9b6bedfa":"markdown","ab0d752a":"markdown","b5d8e99d":"markdown","c584e532":"markdown","b2dba451":"markdown","5d0f3254":"markdown","e3c9ae1f":"markdown","5e9c6c21":"markdown","79f349a3":"markdown","fddd1625":"markdown"},"source":{"06398d84":"# linear algebra and data processing\nimport numpy as np\nimport pandas as pd \n\n#visualisations\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# data preprocessing\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n# math and statistics\nfrom scipy import stats\nfrom scipy.stats import skew, norm\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n# ignnore warnings\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\n\n# data paths\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","02ecd583":"# data\ntrain = pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/test.csv')\nstore = pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/store.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/sample_submission.csv')\n\nprint('train set shape:', train.shape)\nprint('test set shape:', test.shape)\nprint('store set shape:', store.shape)","9d920665":"# quick peak\n\ntrain.info()","6abe7837":"test.info()","6c92ebac":"store.info()","2074385a":"# merge the train\/test sets with the stores set\nfull_train = pd.merge(left = train, right = store, how = 'inner', left_on = 'Store', right_on = 'Store')\nfull_test = pd.merge(left = test, right = store, how = 'inner', left_on = 'Store', right_on = 'Store')\nprint(full_train.shape)\nprint(full_test.shape)","07bf6316":"full_train.isna().any()","48146c90":"def preprocess_data(full_train, full_test):\n\n    # dependent and independent variables\n    global train_features, train_target, test_features\n    train_features = full_train.drop(['Sales'], axis = 1) #drop the target feature + customers (~ will not be used for prediction)\n    train_target  = full_train[['Sales']]\n    test_features = full_test.drop(['Id'], axis = 1) #drop id, it's required only during submission\n    test_features['Customers'] = 0\n    \n    #feature generation + transformations\n    def feature_generation(data):\n        data['Date'] = pd.to_datetime(data.Date)\n        data['Month'] = data.Date.dt.month.to_list()\n        data['Year'] = data.Date.dt.year.to_list()\n        data['Day'] = data.Date.dt.day.to_list()\n        data['WeekOfYear'] = data.Date.dt.weekofyear.to_list()\n        data['DayOfWeek'] = data.Date.dt.dayofweek.to_list()\n        data['weekday'] = 1        # Initialize the column with default value of 1\n        data.loc[data['DayOfWeek'] == 5, 'weekday'] = 0\n        data.loc[data['DayOfWeek'] == 6, 'weekday'] = 0\n#         data = data.drop(['Date'], axis = 1)\n        \n        return data\n    \n    train_features = feature_generation(train_features)\n    test_features = feature_generation(test_features)\n\n\n    # numerical and categorical columns\n    global categorical, numerical, timestamp\n    categorical = []\n    numerical = []\n    timestamp = []\n\n    for col in train_features.columns:\n        if train_features[col].dtype == object:\n            categorical.append(col)\n        elif train_features[col].dtype in ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']:\n            numerical.append(col)\n        else:\n            timestamp.append(col)\n\n    # Keep selected columns only\n    my_cols = categorical + numerical + timestamp\n    train_features = train_features[my_cols].copy()\n    test_features = test_features[my_cols].copy()\n    features = pd.concat([train_features, test_features]) #merge the features columns for uniform preprocessing\n\n    # change dtypes for uniformity in preprocessing\n    features.CompetitionOpenSinceMonth = features.CompetitionOpenSinceMonth.astype('Int64') \n    features.CompetitionOpenSinceYear = features.CompetitionOpenSinceYear.astype('Int64')\n    features.Promo2SinceWeek = features.Promo2SinceWeek.astype('Int64') \n    features.Promo2SinceYear = features.Promo2SinceYear.astype('Int64')\n    features[\"StateHoliday\"].loc[features[\"StateHoliday\"] == 0] = \"0\"\n#     features = features.drop(['Store'], axis = 1)\n\n\n    # ''' actual preprocessing: '''\n    \n    # null values\n    # numerical null values\n    for col in ['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear']:\n        features[col] = features[col].fillna((int(features[col].mean()))) \n\n    # categorical null values\n    for col in ['Open', 'PromoInterval']:\n        features[col] = features[col].fillna(features[col].mode()[0])\n        \n#     # categorical null values\n#     features.PromoInterval = features.PromoInterval.fillna((features.PromoInterval.mode()))\n#     features.Open = features.Open.fillna((features.Open.mode()))\n\n    return features","db17b016":"features = preprocess_data(full_train, full_test)\nprint(features.shape)\nfeatures.head()","0820995d":"features.info()","81e0d3aa":"numerical","def4d3fa":"train_feat = features.iloc[:len(train_features), ]\ntest_feat = features.iloc[len(train_features):, :]\ntrain_set = train_feat.copy()\ntrain_set['Sales'] = train_target\ntrain_target.shape, train_feat.shape, train_set.shape, test_feat.shape","8b32422d":"train_set.describe().transpose()","473ef3ed":"def correlation_map(f_data, f_feature, f_number):\n    f_most_correlated = f_data.corr().nlargest(f_number,f_feature)[f_feature].index\n    f_correlation = f_data[f_most_correlated].corr()\n    \n    f_mask = np.zeros_like(f_correlation)\n    f_mask[np.triu_indices_from(f_mask)] = True\n    with sns.axes_style(\"white\"):\n        f_fig, f_ax = plt.subplots(figsize=(8, 6))\n        f_ax = sns.heatmap(f_correlation, mask=f_mask, vmin=0, vmax=1, square=True,\n                           annot=True, annot_kws={\"size\": 10}, cmap=\"BuPu\")\n        f_fig.savefig('heatmap.svg', format='svg', dpi=1200)\n\n    plt.show()\n\nprint('top 6 features with highest correlation with sales')\ncorrelation_map(train_set, 'Sales', 6)","c71e97f5":"# state holiday + Sales + Customers\n\n# merge '0' and 0\ntrain_set[\"StateHoliday\"].loc[train_set[\"StateHoliday\"] == 0] = \"0\"\nsns.countplot(x='StateHoliday', data=train_set).set_title('State holidays value counts')\n\n\n# holidays + no_holidays\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(12,4))\n\nsns.barplot(x='StateHoliday', y='Sales', data=train_set, ax=axis1).set_title('comparison of sales during StateHolidays and ordinary days')\n# holidays only\nmask = (train_set[\"StateHoliday\"] != \"0\") & (train_set[\"Sales\"] > 0)\nsns.barplot(x='StateHoliday', y='Sales', data=train_set[mask], ax=axis2).set_title('sales during Stateholidays')\nfig.savefig('holidays.svg', format='svg', dpi=1200)\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(12,4))\nsns.barplot(x='StateHoliday', y='Customers', data=train_set, ax=axis1).set_title('comparison of customers during StateHolidays and ordinary days')\n# holidays only\nmask = (train_set[\"StateHoliday\"] != \"0\") & (train_set[\"Customers\"] > 0)\nsns.barplot(x='StateHoliday', y='Customers', data=train_set[mask], ax=axis2).set_title('customers during Stateholidays')\nfig.savefig('holidays1.svg', format='svg', dpi=1200)","a8af67d7":"# store type\nsns.countplot(x='StoreType', data=train_set, order=['a','b','c', 'd'], palette = [\"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]).set_title('a count plot of StoreTypes')\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\nsns.barplot(x='StoreType', y='Sales', data=train_set, ax=axis1, palette = [\"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"], order=['a','b','c', 'd']).set_title('sales across different StoreType')\nsns.barplot(x='StoreType', y='Customers', data=train_set, ax=axis2, palette = [\"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"], order=['a','b','c', 'd']).set_title('no of customers across diffrent StoreType')\nfig.savefig('store.svg', format='svg', dpi=1200)","d018064a":"# assortment\nsns.countplot(x='Assortment', data=train_set, order=['a','b','c'], palette = 'husl').set_title('assortment types counts')\n\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\n\nsns.barplot(x='Assortment', y='Sales', data=train_set, palette = 'husl', order=['a','b','c'], ax=axis1).set_title('sales across different assortment types')\nsns.barplot(x='Assortment', y='Customers', data=train_set, palette = 'husl', order=['a','b','c'], ax=axis2).set_title('customers across different assortment types')\nfig.savefig('assortment.svg', format='svg', dpi=1200)","863b27bf":"# dayofweek + open\n\n#let's explore open in relation to day of week\nfig, (axis1) = plt.subplots(1,1,figsize=(12,4))\nsns.countplot(x='Open',hue='DayOfWeek', data=train_set, ax=axis1, palette = 'RdBu_r')\nplt.title(\"store's open status in relation to day of the week\")\nfig.savefig('dayofweek.svg', format='svg', dpi=1200)\n\n# sales across dayofweek\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\nsns.barplot(x='DayOfWeek', y='Sales', data=train_set, palette = 'RdBu_r', ax=axis1).set_title('sales across different days of the week ')\nsns.barplot(x='DayOfWeek', y='Sales', data=train_set, palette = 'RdBu_r', ax=axis2).set_title('customers across different days of the week ')\nfig.savefig('dayofweek1.svg', format='svg', dpi=1200)","be5be3b1":"# weekday\nflatui = [ \"#e74c3c\", \"#34495e\"]\nsns.countplot(x='weekday', data=train_set, palette = flatui).set_title('a count plot of weekday')\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\n\nsns.barplot(x='weekday', y='Sales', data=train_set, ax=axis1, palette = flatui).set_title('sales during weekends vs weekdays')\nsns.barplot(x='weekday', y='Customers', data=train_set, ax=axis2, palette = flatui).set_title('customers during weekends and weekdays')\nfig.savefig('weekday.svg', format='svg', dpi=1200)","7b870e0b":"#Promo\nflatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\nsns.countplot(x='Promo', data=train_set, palette = flatui).set_title('Promo counts')\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\n\nsns.barplot(x='Promo', y='Sales', data=train_set, palette = flatui, ax=axis1).set_title('sales across different Promo')\nsns.barplot(x='Promo', y='Customers', data=train_set, ax=axis2,  palette = flatui).set_title('customers across different Promo')\nfig.savefig('promo.svg', format='svg', dpi=1200)","5ce95271":"#Promo2\nflatui = [ \"#34495e\", \"#2ecc71\"]\n\nsns.countplot(x='Promo2', data=train_set, palette = flatui).set_title('Promo2 counts')\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\n\nsns.barplot(x='Promo2', y='Sales', data=train_set, ax=axis1, palette = flatui).set_title('sales across different Promo2')\nsns.barplot(x='Promo2', y='Customers', data=train_set, ax=axis2, palette = flatui).set_title('customers across different Promo2')\nfig.savefig('promo2.svg', format='svg', dpi=1200)","ad74516c":"# PromoInterval\nflatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\nsns.countplot(x='PromoInterval', data=train_set, palette = flatui).set_title('PromoInterval value counts')\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\n\nsns.barplot(x='PromoInterval', y='Sales', data=train_set, ax=axis1, palette = flatui).set_title('sales across different promo intervals')\nsns.barplot(x='PromoInterval', y='Customers', data=train_set, ax=axis2, palette = flatui).set_title('customers across different promo intervals')\nfig.savefig('PromoInterval.svg', format='svg', dpi=1200)","4ce2e2f3":"#SchoolHoliday\nsns.countplot(x='SchoolHoliday', data=train_set, palette = 'Set2').set_title('a count plot of school holidays')\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\n\nsns.barplot(x='SchoolHoliday', y='Sales', data=train_set, ax=axis1, palette = 'Set2').set_title('sales across ordinary school days and school holidays')\nsns.barplot(x='SchoolHoliday', y='Customers', data=train_set, ax=axis2, palette = 'Set2').set_title('no of customers across ordinary school days and school holidays')\nfig.savefig('schoolholiday.svg', format='svg', dpi=1200)","2f19507d":"# stateholiday\n\n# merge '0' and 0\ntrain_set[\"StateHoliday\"].loc[train_set[\"StateHoliday\"] == 0] = \"0\"\n# value counts\nsns.countplot(x='StateHoliday', data=train_set, palette = 'Paired').set_title('State holidays value counts')\n\n# holidays + no_holidays\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(12,4))\nsns.barplot(x='StateHoliday', y='Sales', data=train_set, ax=axis1, palette = 'Paired').set_title('comparison of sales during StateHolidays and ordinary days')\n# holidays only\nmask = (train_set[\"StateHoliday\"] != \"0\") & (train_set[\"Sales\"] > 0)\nsns.barplot(x='StateHoliday', y='Sales', data=train_set[mask], ax=axis2, palette = 'Paired').set_title('sales during Stateholidays')\nfig.savefig('stateholiday.svg', format='svg', dpi=1200)","fff9ff64":"# observing all the holidays as one\ntrain_set[\"StateHoliday\"] = train_set[\"StateHoliday\"].map({0: 0, \"0\": 0, \"a\": 1, \"b\": 1, \"c\": 1})\n# test_df[\"StateHoliday\"]     = test_df[\"StateHoliday\"].map({0: 0, \"0\": 0, \"a\": 1, \"b\": 1, \"c\": 1})\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\nsns.barplot(x='StateHoliday', y='Sales', data=train_set, ax=axis1, palette = 'Paired')\nsns.barplot(x='StateHoliday', y='Customers', data=train_set, ax=axis2, palette = 'Paired')\nfig.savefig('stateholiday1.svg', format='svg', dpi=1200)","c8f1d9d2":"# competition distance +Sales + Customers\n\n# adding Decile_rank column to the DataFrame \ntrain_set['Decile_rank'] = pd.qcut(train_set['CompetitionDistance'], 5, labels = False) \nnew_df = train_set[['Decile_rank', 'Sales']]\n# a = new_df.groupby('Decile_rank').sum()\na = new_df.groupby('Decile_rank').mean()\nlabels = a.index.to_list()\nsizes = a.Sales.to_list()\nfig = plt.figure(figsize =(10, 7)) \ncolors = ['gold', 'yellowgreen', 'purple', 'lightcoral', 'lightskyblue']\nexplode = (0.1, 0.03, 0.03, 0.03, 0.03)  # explode 1st slice\n\n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, shadow=True, autopct='%.2f', startangle=140)\nplt.title('A piechart indicating mean sales in the 5 CompetitioDIstance decile classes')\nfig.savefig('salesdeciles.svg', format='svg', dpi=1200)\n\n# adding Decile_rank column to the DataFrame \ntrain_set['Decile_rank'] = pd.qcut(train_set['CompetitionDistance'], 5, labels = False) \nnew_df = train_set[['Decile_rank', 'Customers']]\n# a = new_df.groupby('Decile_rank').sum()\na = new_df.groupby('Decile_rank').mean()\nlabels = a.index.to_list()\nsizes = a.Customers.to_list()\nfig = plt.figure(figsize =(10, 7)) \ncolors = ['gold', 'yellowgreen', 'purple', 'lightcoral', 'lightskyblue']\nexplode = (0.1, 0.03, 0.03, 0.03, 0.03)  # explode 1st slice\n\n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, shadow=True, autopct='%.2f', startangle=140)\nplt.title('A piechart indicating mean number of customers in the 5 CompetitioDistance decile classes')\nfig.savefig('distancedeciles.svg', format='svg', dpi=1200)","77428f3c":"#CompetitionDistance\nfig = plt.figure(figsize = (8,6))\nsns.distplot(train_set.CompetitionDistance, color = 'violet')\nfig.savefig('compedist.svg', format='svg', dpi=1200)","f0a504c5":"# Seasonality\n#Date train\n'''Data is from Jan 2013 to July 2015'''\ntime_data = train_set[['Date', 'Sales']]\ntime_data['datetime'] = pd.to_datetime(time_data['Date'])\ntime_data = time_data.set_index('datetime')\ntime_data = time_data.drop(['Date'], axis = 1)","9d590967":"# daily train\ndaily_time_data = time_data.Sales.resample('D').mean() \nfig = plt.figure(figsize = (12,5))\n# plt.figure(figsize = (12,5))\nplt.title('Seasonality plot averaged daily')\ndaily_time_data.plot()\nplt.grid()\nfig.savefig('dailytrend.svg', format='svg', dpi=1200)","968c560d":"# weekly train\nweekly_time_data = time_data.Sales.resample('W').mean() \nfig = plt.figure(figsize = (12,5))\nplt.title('Seasonality plot averaged weekly')\nplt.ylabel('average sales')\nweekly_time_data.plot()\nplt.grid()\nfig.savefig('weeklytrend.svg', format='svg', dpi=1200)","e51f9f70":"# Monthly train\nmonthly_time_data = time_data.Sales.resample('M').mean() \nfig = plt.figure(figsize = (12,5))\nplt.title('Seasonality plot averaged monthly')\nplt.ylabel('average sales')\nmonthly_time_data.plot()\nplt.grid()\nfig.savefig('monthlytrend.svg', format='svg', dpi=1200)","3b2ab271":"# Monthly percentage\nmonthly_time_data = time_data.Sales.resample('M').sum().pct_change()\nfig = plt.figure(figsize = (12,5))\nplt.title('Seasonality plot monthly percentages change')\nplt.ylabel('sales percentage change')\nmonthly_time_data.plot()\n# pct_change_sales = rossmann_df.groupby('Date')[\"Sales\"].sum().pct_change()\nplt.grid()\nfig.savefig('monthly%trend.svg', format='svg', dpi=1200)","42bf4a48":"# yearly train\nyearly_time_data = time_data.Sales.resample('Y').mean() \nfig = plt.figure(figsize = (12,5))\nplt.title('Seasonality plot averaged yearly')\nplt.ylabel('average sales')\nyearly_time_data.plot()\nplt.grid()\nfig.savefig('yearlytrend.svg', format='svg', dpi=1200)","cfdd4bdb":"f, axs = plt.subplots(2,figsize=(12,8))\nplt.ylabel('average sales')\n# daily_time_data.plot(ax = axs[0])\nweekly_time_data.plot(ax=axs[0])\nmonthly_time_data.plot(ax=axs[1])\nprint('Seasonality plots averaged weekly and monthly')\nf.savefig('week_month_avg.svg', format='svg', dpi=1200)","76ade597":"#sales\n\n'''The target variable'''\nf, ax = plt.subplots(figsize=(9, 8))\nsns.distplot(train_set['Sales'], bins = 20, color = 'Magenta')\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"sales\")\nax.set(title=\"sales distribution\")\nf.savefig('sales.svg', format='svg', dpi=1200)","80f0ed51":"## Reconstruct Train and Test sets","080759ad":"Not most stores run daily promotions.\nThe sales and customers are higher in the less stores that run daily promotions","3bacdfa5":"#### Sales","a9093cc0":"## Libraries","90dfa380":"#### Date (Day\/Week\/Month\/Year ~ Seasonality)","013041f6":"#### weekday","039ed7a8":"The length of competition distances increase with decile classes. The total number of sales across the decile classes is somewhat balanced, apart from the first class which has a bit higher values compared to the rest. We expect it to have a lower volume considering the competition aspect but another argument that could explain the opposite behavior is the stores location. They could be located in big cities where population is dense thus proximity to competitive stores has a minor influence.","c2970ced":"store type b is the least popular while a is the most popular. but b's sales are higher compared to the rest.","f0dc92ec":"## Non-Graphical Analysis","4b790c0c":"Sales and Customers have a high correlation. \nIn the follow up plots, we'll explore how the 2 variables relate with the others.","707fbe71":"#### Correlation","7f85158b":"#### SchoolHoliday","174c4958":"## Data","195561ca":"All good now.","7f71e3b4":"> 0 represents no holidays. Its counts are higher given that holidays are normally few.\n> a reps public holiday, b - easter and c - christmas","92d8bcc5":"there's a balance in the stores that run continous promotions. The sales and the customers in the promotion group is slightly lower.","4361ec77":"#### CompetitionDistance","f4eadafc":"#### Promo2","759bce5d":"Most stores are open in the first 6 days and close on the 7th (Sunday).\n\nThe amount of sales and number of customers align with the trend across the week.","dd9b5b45":"## Preprocessing\n* Handling null values\n* General house keeping\n\n**PS**: Categorical features are not encoded in this kernel since we wanna explore the relationships between the columns and not build models.  Numerical features aren't scaled either","9b6bedfa":"Not so much preprocessing required in the train and test sets. Nevertheless, the'll be joined with the stores df, so the preprocessing will be uniform.","ab0d752a":"#### DayOfWeek + Open","b5d8e99d":"#### PromoInterval","c584e532":"## Graphical Analysis","b2dba451":"#### StateHoliday","5d0f3254":"#### Promo","e3c9ae1f":"#### Assortment","5e9c6c21":"#### StateHoliday","79f349a3":"#### StoreType","fddd1625":"Most of the stores are closely spaced."}}