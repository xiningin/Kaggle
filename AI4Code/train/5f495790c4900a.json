{"cell_type":{"9786b5ca":"code","38966250":"code","fa478fe3":"code","ff5ac91c":"code","5f847a4c":"code","15b3963c":"code","11c49987":"code","caaf88a7":"markdown"},"source":{"9786b5ca":"import numpy as np\nimport pandas as pd\nfrom sklearn import model_selection\nfrom sklearn import preprocessing\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom sklearn.model_selection import train_test_split","38966250":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fa478fe3":"df_train=pd.read_csv('\/kaggle\/input\/30-days-of-ml\/train.csv')\ndf_test=pd.read_csv('\/kaggle\/input\/30-days-of-ml\/test.csv')\nsample_submission = pd.read_csv(\"\/kaggle\/input\/30-days-of-ml\/sample_submission.csv\")\n","ff5ac91c":"df_train[\"kfold\"] = -1\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=42)\nfor fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=df_train)):\n    df_train.loc[valid_indicies, \"kfold\"] = fold\n","5f847a4c":"\nuseful_features = [c for c in df_train.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []","15b3963c":"for fold in range(10):\n    xtrain =  df_train[df_train.kfold != fold].reset_index(drop=True)\n    xvalid = df_train[df_train.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    min_depth = 2\n    min_learning = 0.1\n    min_estimators = 3000\n    min_subsample = 0.7\n    min_colsample = 10.0\n\n\n    model=XGBRegressor(max_depth=min_depth,learning_rate=min_learning,n_estimators=min_estimators,subsample=min_subsample, random_state=42, verbosity=0, objective = 'reg:squarederror')\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\nprint(np.mean(scores), np.std(scores))","11c49987":"sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.to_csv(\"submission.csv\", index=False)","caaf88a7":"\n# **Make 10 Folds**"}}