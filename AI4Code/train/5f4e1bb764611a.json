{"cell_type":{"ec45b641":"code","dad8da17":"code","507e356f":"code","de951f8c":"code","b8bb3290":"code","dfeb1dc4":"code","59252a63":"code","cb7754b5":"code","0ae715f7":"code","721c25d1":"code","27fb42fa":"code","654542f7":"code","e587e069":"code","da193773":"code","94e2b210":"code","6d924fc7":"code","897f3168":"code","8bef28a2":"code","ff9ccfba":"code","a21e49d4":"code","ae359635":"code","214f9f10":"code","59d57e3a":"code","9bf66c15":"code","066d28e1":"code","98508b84":"code","71304e33":"code","7014d598":"code","d95e4a01":"code","4a6c0c16":"code","47a6deb2":"code","2b4b30d6":"code","36a7f133":"code","702c7cd6":"code","2bd49ba7":"code","494aeb62":"code","b5041ff3":"code","8b8337c0":"code","69030d5c":"code","ef8c51c3":"code","7d6fb23d":"code","224266f2":"code","41c06697":"code","63590459":"code","f5fb0bb0":"code","2fb03f81":"code","b40a833f":"code","a1e9226c":"code","b51973d7":"code","d903e2d6":"code","094e1ed9":"code","4b25f407":"code","43a283dc":"code","d7a1c5d7":"code","71030c41":"code","08a15e00":"code","126f79a9":"code","e693b8f0":"code","78965bb4":"code","4f84ccbb":"code","e86f5738":"code","170af00c":"code","63574c97":"code","19396648":"code","8ca2f0d9":"code","1c55aac0":"code","722fe6ab":"code","5828a73f":"code","bdad649c":"code","5a17ec9f":"code","07f3fd01":"code","2b38423f":"code","00782cbf":"code","0c07e9e5":"code","87f2a858":"code","568c857d":"code","e7e80150":"code","51f6cdd5":"code","aac7ae10":"code","ab2f38f2":"code","04855d99":"code","d4b20c1a":"code","c409eee7":"code","157c666a":"code","cba35ecb":"code","23943fae":"code","607e91d4":"code","bc16677a":"markdown","b60f6ea5":"markdown","38e00eb3":"markdown","86aa9683":"markdown","7dc11681":"markdown","fb5151dd":"markdown","53744b1a":"markdown","cf17986a":"markdown","e034bc3f":"markdown","22116d9a":"markdown","e6827672":"markdown","566db7c5":"markdown","a8207cbf":"markdown","5bcde5b0":"markdown","7d8371fd":"markdown","a8f2f952":"markdown","f3d33435":"markdown","4af0bbe2":"markdown"},"source":{"ec45b641":"import socket\nimport sys\n\nis_kaggle = True\nif not is_kaggle:\n    from my_utils import get_notebook_path\n    get_notebook_path().split('\/')[-1].split('.')[0]\n    NB = get_notebook_path().split('\/')[-1].split('.')[0]\n    HOST = socket.gethostname()\n    import mlflow\n    from logzero import logger\n    DELIMITER = '\\\\'\n\nelse:\n    NB = 'exp0093'\n    HOST = 'DESKTOP-M3SEAIN'\n    sys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\n    DELIMITER = '\/'\ndescription = '256'\n\nprint(f'{HOST}_{NB}')\n\nNB, HOST","dad8da17":"#from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport glob\nfrom sklearn.model_selection import StratifiedKFold, KFold\nif not is_kaggle:\n    from sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom collections import OrderedDict\nimport random\nimport os\nimport gc\nimport shutil\nimport timm\n\n\nimport torch.optim as optim\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport albumentations as albu\n\nimport pickle\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nif is_kaggle:\n    DATA_DIR = Path('..\/input\/petfinder-pawpularity-score')\n    OUTPUT_DIR = Path('.\/')\n    CP_DIR = Path('..\/input') \/ Path('DESKTOP-M3SEAIN_exp0093'.lower().replace('-', '').replace('_', '-'))\nelse:\n    ROOT_DIR = Path('..\/..\/')\n    DATA_DIR = ROOT_DIR \/ 'data'\n    OUTPUT_DIR = Path('..\/') \/ 'output'\n    CP_DIR = OUTPUT_DIR \/ 'checkpoint'\n\ndef to_pickle(filename, obj):\n    with open(filename, mode='wb') as f:\n        pickle.dump(obj, f)\n        \ndef unpickle(filename):\n    with open(filename, mode='rb') as fo:\n        p = pickle.load(fo)\n    return p ","507e356f":"\nclass Config:\n    N_LABEL = 1\n    N_FOLD = 5\n    RANDOM_SATE = 42\n    LR = 1.0e-05\n    MAX_LR = 1e-5\n    PATIENCE = 18\n    EPOCH = 10\n    BATCH_SIZE = 32\n    SKIP_EVALUATE_NUM = 0\n    BACK_BONE = 'swin_large_patch4_window7_224'\n    RUN_FOLD_COUNT = 10\n    IMG_SIZE=224\n    T_MAX=20\n    ETA_MIN=3.0e-7\n    SCHEDULER_GAMMA=1.0\n    ACCUMULATION_STEMP=1 \n    \nif is_kaggle:\n    Config.BATCH_SIZE = 24\n    \ndef seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(seed=Config.RANDOM_SATE)","de951f8c":"glob.glob('..\/input\/*')","b8bb3290":"test_img_map = {}\nfor img_path in tqdm(glob.glob(str(DATA_DIR \/  'test\/*'))):\n    test_img_map[img_path.split(DELIMITER)[-1].split('.')[0]] = img_path","dfeb1dc4":"test_df = pd.read_csv(DATA_DIR \/ 'test.csv')","59252a63":"from fastai.vision.all import *","cb7754b5":"SEED = 46\nBATCH_SIZE = 16\nset_seed(SEED, reproducible=True)\ndataset_path = Path('..\/input\/petfinder-pawpularity-score\/')\ndataset_path.ls()","0ae715f7":"if not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n    os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/swin-transformer\/swin_large_patch4_window7_224_22kto1k.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/swin_large_patch4_window7_224_22kto1k.pth'","721c25d1":"set_seed(SEED, reproducible=True)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","27fb42fa":"def petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))","654542f7":"test_df = pd.read_csv(DATA_DIR \/ 'test.csv')\n\ntest_path_list = []\nfor f in glob.glob('..\/input\/petfinder-pawpularity-score\/test\/*'):\n    test_path_list.append(\n        {\n            'Id':f.split('\/')[-1].split('.')[0],\n            'path':f\n        }\n    )\ntest_df = test_df.merge(pd.DataFrame(test_path_list), how='left', on='Id')\ntest_df['norm_score'] = -1\ntest_df","e587e069":"%%time\nall_preds = []\n\nfor i in range(10):\n    \n    print(f'===={i}====')\n    \n    path = '..\/input\/johannyjm-1790651\/'\n        \n    learn = load_learner(path + f'model_fold_{i}.pkl', cpu=False)\n        \n    dls = ImageDataLoaders.from_df(test_df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               seed=SEED, #seed\n                               fn_col='path', #filename\/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=4,\n                               item_tfms=Resize(224), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n    \n    test_dl = dls.test_dl(test_df)\n    \n    preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n    \n    all_preds.append(preds)\n    \n    del learn, test_dl\n\n    torch.cuda.empty_cache()\n\n    gc.collect()","da193773":"y_johannyjm_1790651 = np.mean(np.stack(all_preds), axis=0).reshape(-1) * 100\ny_johannyjm_1790651","94e2b210":"%%time\nfast_ai_004_all_preds = []\n\nfor i in range(5):\n    print(f'===={i}====')\n    \n    path = '..\/input\/fastai-004\/'\n    learn = load_learner(path + f'fastai_fastai_0004_{i}.pkl', cpu=False)\n    dls = ImageDataLoaders.from_df(test_df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               seed=SEED, #seed\n                               fn_col='path', #filename\/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=4,\n                               item_tfms=Resize(224), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n    \n    test_dl = dls.test_dl(test_df)\n    \n    preds, _ = learn.tta(dl=test_dl, n=10, beta=0)\n    \n    fast_ai_004_all_preds.append(preds)\n    \n    del learn, test_dl\n\n    torch.cuda.empty_cache()\n\n    gc.collect()","6d924fc7":"fast_ai_004_preds = np.mean(np.stack(fast_ai_004_all_preds), axis=0).reshape(-1) * 100\nfast_ai_004_preds","897f3168":"class Config:\n    N_LABEL = 1\n    N_FOLD = 5\n    RANDOM_SATE = 42\n    LR = 1.0e-05\n    MAX_LR = 1e-5\n    PATIENCE = 18\n    EPOCH = 10\n    BATCH_SIZE = 32\n    SKIP_EVALUATE_NUM = 0\n    BACK_BONE = 'swin_large_patch4_window7_224'\n    RUN_FOLD_COUNT = 10\n    IMG_SIZE=224\n    T_MAX=20\n    ETA_MIN=3.0e-7\n    SCHEDULER_GAMMA=1.0\n    ACCUMULATION_STEMP=1 \nseed_everything(seed=Config.RANDOM_SATE)","8bef28a2":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","ff9ccfba":"def get_test_augmentation(IM_SZ=384):\n    train_transform = [\n        albu.Resize(height=IM_SZ, width=IM_SZ),\n        albu.Normalize(),\n    ]\n    return albu.Compose(train_transform)\n\ndef get_fllsize_augmentation(IM_SZ=256):\n    train_transform = [\n        albu.LongestMaxSize(max_size=IM_SZ, always_apply=False),\n        albu.PadIfNeeded(always_apply=True, min_height=IM_SZ, min_width=IM_SZ, border_mode=2),\n        albu.Normalize(),\n    ]\n    return albu.Compose(train_transform)","a21e49d4":"class PetfinderDataSet_base(Dataset):\n    def __init__(self, df, img_map, transforms, data_type=None):\n        self.df = df\n        self.img_map = img_map\n        self.data_type = data_type\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        if self.data_type in ['train', 'valid']:\n            pawpularity = self.df.iloc[idx]['Pawpularity']\n            object_id = self.df.iloc[idx]['Id']\n            img = self.img_map[object_id]\n        else:\n            pawpularity = -1\n            object_id = self.df.iloc[idx]['Id']\n            file_path = self.img_map[object_id]\n            img = cv2.imread(file_path)\n            \n        height = img.shape[0]\n        width = img.shape[1]\n            \n        if height > width:\n            center = int(height\/2)\n            half = int(width\/2)\n            img = img[center - half:center + half, :]\n\n        elif width > height:\n            center = int(width\/2)\n            half = int(height\/2)\n            img = img[:, center - half:center + half]\n        \n        augmented = self.transforms(image=img)\n        img = augmented['image']\n        img = np.moveaxis(img, 2, 0)\n\n        return img, pawpularity \/ 100","ae359635":"class PetfinderDataSet_fllsize(Dataset):\n    # default fllsize_transforms --> get_fllsize_augmentation(IM_SZ=256)\n    def __init__(self, df, img_map, transforms, data_type=None, fllsize_transforms=get_fllsize_augmentation(IM_SZ=256)):\n        self.df = df\n        self.img_map = img_map\n        self.data_type = data_type\n        self.transforms = transforms\n        self.fllsize_transforms = fllsize_transforms\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        if self.data_type in ['train', 'valid']:\n            pawpularity = self.df.iloc[idx]['Pawpularity']\n            object_id = self.df.iloc[idx]['Id']\n            img = self.img_map[object_id]\n        else:\n            pawpularity = -1\n            object_id = self.df.iloc[idx]['Id']\n            file_path = self.img_map[object_id]\n            img = cv2.imread(file_path)\n            \n        full_augmented = self.fllsize_transforms(image=img)\n        full_img = full_augmented['image']\n        full_img = np.moveaxis(full_img, 2, 0)\n            \n        height = img.shape[0]\n        width = img.shape[1]\n            \n        if height > width:\n            center = int(height\/2)\n            half = int(width\/2)\n            img = img[center - half:center + half, :]\n\n        elif width > height:\n            center = int(width\/2)\n            half = int(height\/2)\n            img = img[:, center - half:center + half]\n        \n        augmented = self.transforms(image=img)\n        img = augmented['image']\n        img = np.moveaxis(img, 2, 0)\n\n        return img, full_img, pawpularity","214f9f10":"class PetfinderNet(nn.Module):\n    # for 0080, c0007, 0097, 0101, Age\n    def __init__(self, model_name):\n        super(PetfinderNet, self).__init__()\n\n        self.base_model = timm.create_model(model_name, num_classes=0, pretrained=False, in_chans=3)\n        num_features = self.base_model.num_features\n\n        self.cls = nn.Sequential(\n            nn.Linear(num_features, int(num_features \/ 2)),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(int(num_features \/ 2), int(num_features \/ 4)),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(int(num_features \/ 4), Config.N_LABEL)\n        )\n\n    def forward(self, x):\n        x = self.base_model(x)\n        x = self.cls(x)\n        return x","59d57e3a":"class PetfinderDoubleBaseNet(nn.Module):\n    # for 0030, 0095\n    def __init__(self):\n        super(PetfinderDoubleBaseNet, self).__init__()\n\n        self.base_model1 = timm.create_model('tf_efficientnet_b1_ns', num_classes=0, pretrained=False, in_chans=3)\n        self.base_model2 = timm.create_model('tf_efficientnet_b1_ns', num_classes=0, pretrained=False, in_chans=3)\n        num_features = self.base_model1.num_features\n\n        self.cls = nn.Sequential(\n            nn.Linear(num_features * 2, int(num_features)),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(int(num_features), int(num_features \/ 2)),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(int(num_features \/ 2), Config.N_LABEL)\n        )\n\n    def forward(self, x1, x2):\n        x1 = self.base_model1(x1)\n        x2 = self.base_model1(x2)\n        \n        x = torch.cat([x1, x2], dim=1)\n        x = self.cls(x)\n        return x","9bf66c15":"class PetfinderRealDoubleBaseNet(nn.Module):\n    # 0149\n    def __init__(self):\n        super(PetfinderRealDoubleBaseNet, self).__init__()\n\n        self.base_model1 = timm.create_model('tf_efficientnet_b0_ns', num_classes=0, pretrained=False, in_chans=3)\n        self.base_model2 = timm.create_model('tf_efficientnet_b0_ns', num_classes=0, pretrained=False, in_chans=3)\n        num_features = self.base_model1.num_features\n\n        self.cls = nn.Sequential(\n            nn.Linear(num_features * 2, int(num_features)),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(int(num_features), int(num_features \/ 2)),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(int(num_features \/ 2), Config.N_LABEL)\n        )\n\n    def forward(self, x1, x2):\n        x1 = self.base_model1(x1)\n        x2 = self.base_model2(x2)\n        \n        x = torch.cat([x1, x2], dim=1)\n        x = self.cls(x)\n        return x","066d28e1":"class PetfinderMSENet(nn.Module):\n    # for 0087\n    def __init__(self, fold):\n        super(PetfinderMSENet, self).__init__()\n        \n        model = PetfinderNet('swin_large_patch4_window12_384')\n        \n        self.base_model = model.base_model\n        num_features = self.base_model.num_features\n\n        self.cls = nn.Sequential(\n            nn.Linear(num_features, int(num_features \/ 2)),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(int(num_features \/ 2), int(num_features \/ 4)),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(int(num_features \/ 4), 1)\n        )\n\n    def forward(self, x):\n        x = self.base_model(x)\n        x = self.cls(x)\n        return x","98508b84":"CP_DIR = Path('..\/input') \/ Path('DESKTOP-M3SEAIN_exp0080'.lower().replace('-', '').replace('_', '-'))","71304e33":"y_preds_0080 = np.zeros(len(test_df))\n\ntest_dataset = PetfinderDataSet_base(test_df, test_img_map, get_test_augmentation(IM_SZ=384), data_type='test')\ntestloader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, num_workers=4)\n\nfor fold in range(10):\n\n    net = PetfinderNet('swin_large_patch4_window12_384')\n    net.to(device)\n    print(CP_DIR \/ f'checkpoint_DESKTOP-M3SEAIN_exp0080_{fold}.pt')\n    net.load_state_dict(torch.load(CP_DIR \/ f'checkpoint_DESKTOP-M3SEAIN_exp0080_{fold}.pt'))\n\n    fold_preds = []\n    for i, (inputs, pawpularities) in tqdm(enumerate(testloader), total=len(testloader)):\n        net.eval()\n\n        with torch.no_grad():\n            \n            inputs, pawpularities = inputs.to(device).float(), pawpularities.to(device).reshape(-1, 1).float()\n            outputs = net(inputs)\n            outputs_np = outputs.sigmoid().to('cpu').detach().numpy().copy().reshape(-1) * 100\n            \n            print(outputs_np)\n            \n            fold_preds.append(outputs_np)\n    \n    y_preds_0080 += np.hstack(fold_preds).reshape(-1) \/ 10","7014d598":"CP_DIR = Path('..\/input') \/ Path('DESKTOP-M3SEAIN_exp0158'.lower().replace('-', '').replace('_', '-'))","d95e4a01":"y_preds_0158 = np.zeros(len(test_df))\n\ntest_dataset = PetfinderDataSet_base(test_df, test_img_map, get_test_augmentation(IM_SZ=384), data_type='test')\ntestloader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, num_workers=4)\n\nfor fold in range(8):\n\n    net = PetfinderNet('swin_large_patch4_window12_384')\n    net.to(device)\n    print(CP_DIR \/ f'checkpoint_DESKTOP-M3SEAIN_exp0158_{fold}.pt')\n    net.load_state_dict(torch.load(CP_DIR \/ f'checkpoint_DESKTOP-M3SEAIN_exp0158_{fold}.pt'))\n\n    fold_preds = []\n    for i, (inputs, pawpularities) in tqdm(enumerate(testloader), total=len(testloader)):\n        net.eval()\n\n        with torch.no_grad():\n            \n            inputs, pawpularities = inputs.to(device).float(), pawpularities.to(device).reshape(-1, 1).float()\n            outputs = net(inputs)\n            outputs_np = outputs.sigmoid().to('cpu').detach().numpy().copy().reshape(-1) * 100\n            \n            print(outputs_np)\n            \n            fold_preds.append(outputs_np)\n    \n    y_preds_0158 += np.hstack(fold_preds).reshape(-1) \/ 8","4a6c0c16":"CP_DIR1 = Path('..\/input') \/ Path('colab3_0007'.lower().replace('-', '').replace('_', '-'))\nCP_DIR2 = Path('..\/input') \/ Path('DESKTOP-M3SEAIN_exp0030'.lower().replace('-', '').replace('_', '-'))","47a6deb2":"y_preds_c0007 = np.zeros(len(test_df))\n\ntest_dataset1 = PetfinderDataSet_base(test_df, test_img_map, get_test_augmentation(IM_SZ=384), data_type='test')\ntestloader1 = DataLoader(test_dataset1, batch_size=Config.BATCH_SIZE, num_workers=4)\n\nfor fold in range(4):\n\n    net1 = PetfinderNet('vit_large_r50_s32_384')\n    net1.to(device)\n    net1.load_state_dict(torch.load(CP_DIR1 \/ f'checkpoint_colab3_pet_exp0007_{fold}.pt'))\n\n    fold_preds1 = []\n    for i, (inputs1, _) in tqdm(enumerate(testloader1), total=len(testloader1)):\n        net1.eval()\n\n        with torch.no_grad():\n            \n            inputs1 = inputs1.to(device).float()\n            \n            outputs1 = net1(inputs1)\n            outputs_np1 = outputs1.sigmoid().to('cpu').detach().numpy().copy().reshape(-1) * 100\n\n            print(outputs_np1)\n            \n            fold_preds1.append(outputs_np1)\n    \n    y_preds_c0007 += np.hstack(fold_preds1).reshape(-1) \/ 4","2b4b30d6":"CP_DIR1 = Path('..\/input') \/ Path('DESKTOP-M3SEAIN_exp0087'.lower().replace('-', '').replace('_', '-'))\n#CP_DIR2 = Path('..\/input') \/ Path('DESKTOP-M3SEAIN_exp0095'.lower().replace('-', '').replace('_', '-'))\nCP_DIR3 = Path('..\/input') \/ Path('DESKTOP-M3SEAIN_exp0097'.lower().replace('-', '').replace('_', '-'))\nCP_DIR4 = Path('..\/input') \/ Path('DESKTOP-M3SEAIN_exp0101'.lower().replace('-', '').replace('_', '-'))\nCP_DIR5 = Path('..\/input') \/ Path('DESKTOP-M3SEAIN_exp0126'.lower().replace('-', '').replace('_', '-'))\nCP_DIR6 = Path('..\/input') \/ Path('DESKTOP-M3SEAIN_exp0149'.lower().replace('-', '').replace('_', '-'))","36a7f133":"y_preds_0087 = np.zeros(len(test_df))\n#y_preds_0095 = np.zeros(len(test_df))\ny_preds_0097 = np.zeros(len(test_df))\ny_preds_0101 = np.zeros(len(test_df))\ny_preds_0126 = np.zeros(len(test_df))\ny_preds_0149 = np.zeros(len(test_df))\n\ntest_dataset_384 = PetfinderDataSet_base(test_df, test_img_map, get_test_augmentation(IM_SZ=384), data_type='test')\ntestloader_384 = DataLoader(test_dataset_384, batch_size=Config.BATCH_SIZE\/\/2, num_workers=4)\n\ntest_dataset_fll_256 = PetfinderDataSet_fllsize(test_df, test_img_map, get_test_augmentation(IM_SZ=256), data_type='test', fllsize_transforms=get_fllsize_augmentation(IM_SZ=256))\ntestloader_fll_256 = DataLoader(test_dataset_fll_256, batch_size=Config.BATCH_SIZE\/\/2, num_workers=4)\n\ntest_dataset_224 = PetfinderDataSet_base(test_df, test_img_map, get_test_augmentation(IM_SZ=224), data_type='test')\ntestloader_224 = DataLoader(test_dataset_224, batch_size=Config.BATCH_SIZE\/\/2, num_workers=4)\n\ntest_dataset_fll_300 = PetfinderDataSet_fllsize(test_df, test_img_map, get_test_augmentation(IM_SZ=300), data_type='test', fllsize_transforms=get_fllsize_augmentation(IM_SZ=300))\ntestloader_fll_300 = DataLoader(test_dataset_fll_300, batch_size=Config.BATCH_SIZE\/\/2, num_workers=4)\n\nfor fold in range(5):\n\n    #net1 = PetfinderMSENet(fold)\n    #net1.to(device)\n    #net1.load_state_dict(torch.load(CP_DIR1 \/ f'checkpoint_DESKTOP-M3SEAIN_exp0087_{fold}.pt'))\n\n    #net2 = PetfinderDoubleBaseNet()\n    #net2.to(device)\n    #net2.load_state_dict(torch.load(CP_DIR2 \/ f'checkpoint_DESKTOP-M3SEAIN_exp0095_{fold}.pt'))\n  \n    #net3 = PetfinderNet('resnet18d')\n    #net3.to(device)\n    #net3.load_state_dict(torch.load(CP_DIR3 \/ f'checkpoint_DESKTOP-M3SEAIN_exp0097_{fold}.pt'))\n\n    net4 = PetfinderNet('swin_large_patch4_window12_384')\n    net4.to(device)\n    net4.load_state_dict(torch.load(CP_DIR4 \/ f'checkpoint_DESKTOP-M3SEAIN_exp0101_{fold}.pt'))\n    \n    net5 = PetfinderNet('densenet121')\n    net5.to(device)\n    net5.load_state_dict(torch.load(CP_DIR5 \/ f'checkpoint_DESKTOP-M3SEAIN_exp0126_{fold}.pt'))\n    \n    net6 = PetfinderRealDoubleBaseNet()\n    net6.to(device)\n    net6.load_state_dict(torch.load(CP_DIR6 \/ f'checkpoint_DESKTOP-M3SEAIN_exp0149_{fold}.pt'))\n    \n    fold_preds1 = []\n    #fold_preds2 = []\n    fold_preds3 = []\n    fold_preds4 = []\n    fold_preds5 = []\n    fold_preds6 = []\n    #for i, ((inputs384, _), (inputs256, full_img256, _), (inputs224, _), (inputs300, full_img300, _)) in tqdm(enumerate(zip(testloader_384, testloader_fll_256, testloader_224, testloader_fll_300)), total=len(testloader_384)):\n    for i, ((inputs384, _), (inputs224, _), (inputs300, full_img300, _)) in tqdm(enumerate(zip(testloader_384, testloader_224, testloader_fll_300)), total=len(testloader_384)):\n        #net1.eval()\n        #net2.eval()\n        #net3.eval()\n        net4.eval()\n        net5.eval()\n        net6.eval()\n\n        with torch.no_grad():\n            \n            inputs384 = inputs384.to(device).float()\n            \n            #outputs1 = net1(inputs384)\n            #outputs_np1 = outputs1.to('cpu').detach().numpy().copy().reshape(-1)\n            \n            #inputs256, full_img256 = inputs256.to(device).float(), full_img256.to(device).float()\n            #outputs2 = net2(inputs256, full_img256)\n            #outputs_np2 = outputs2.to('cpu').detach().numpy().copy().reshape(-1)\n         \n            inputs224 = inputs224.to(device).float()\n            #outputs3 = net3(inputs224)\n            #outputs_np3 = outputs3.sigmoid().to('cpu').detach().numpy().copy().reshape(-1) * 100    \n    \n            outputs4 = net4(inputs384)\n            outputs_np4 = outputs4.sigmoid().to('cpu').detach().numpy().copy().reshape(-1) * 100\n    \n            outputs5 = net5(inputs224)\n            outputs_np5 = outputs5.sigmoid().to('cpu').detach().numpy().copy().reshape(-1) * 100\n    \n            inputs300, full_img300 = inputs300.to(device).float(), full_img300.to(device).float()\n            outputs6 = net6(inputs300, full_img300)\n            outputs_np6 = outputs6.to('cpu').detach().numpy().copy().reshape(-1)\n    \n            #fold_preds1.append(outputs_np1)\n            #fold_preds2.append(outputs_np2)\n            #fold_preds3.append(outputs_np3)\n            fold_preds4.append(outputs_np4)\n            fold_preds5.append(outputs_np5)\n            fold_preds6.append(outputs_np6)\n    \n    #y_preds_0087 += np.hstack(fold_preds1).reshape(-1) \/ 5\n    #y_preds_0095 += np.hstack(fold_preds2).reshape(-1) \/ 5\n    #y_preds_0097 += np.hstack(fold_preds3).reshape(-1) \/ 5\n    y_preds_0101 += np.hstack(fold_preds4).reshape(-1) \/ 5\n    y_preds_0126 += np.hstack(fold_preds5).reshape(-1) \/ 5\n    y_preds_0149 += np.hstack(fold_preds6).reshape(-1) \/ 5","702c7cd6":"base_model = timm.create_model('efficientnet_b0', num_classes=0, pretrained=False, in_chans=3)\nbase_model.load_state_dict(torch.load('..\/input\/efficientnet-b0\/efficientnet_b0.pt'))\nbase_model = base_model.to(device)","2bd49ba7":"org_test_img_paths = glob.glob(str(DATA_DIR \/  'test\/*'))\n#pre_train_img_paths = glob.glob('..\/input\/prepetfinder\/pre_petfinder\/train_images\/*')\npre_img_paths = glob.glob('..\/input\/prepetfinder\/pre_petfinder\/train_images\/*') + glob.glob('..\/input\/prepetfinder\/pre_petfinder_test\/test_images\/*')","494aeb62":"def get_augmentation():\n    train_transform = [\n        albu.Resize(height=224, width=224)\n    ]\n    return albu.Compose(train_transform)\n\nclass DataSet(Dataset):\n    def __init__(self, image_paths):\n        self.image_paths = image_paths\n        self.transforms = get_augmentation()\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        img = cv2.imread(img_path)\n        img = self.transforms(image=img)['image']\n        img = np.moveaxis(img, 2, 0)\n\n        return img\n","b5041ff3":"#pre_train_vectors = np.load('..\/input\/pet2-sim-tensor-calc-challenge\/pre_train_vectors.npy')\npre_vectors = np.load('..\/input\/pre-pet-vectors\/pre_pet_vectors.npy')","8b8337c0":"dataset = DataSet(org_test_img_paths)\nloader = DataLoader(dataset, batch_size=64, shuffle=False, drop_last=False, num_workers=4)\n\noutputs = []\nfor img in tqdm(loader, total=len(loader)):\n    img = img.to(device).float()\n    output = base_model(img)\n    outputs_np = output.to('cpu').detach().numpy().copy()\n    outputs.append(outputs_np)\n\norg_test_vectors = np.vstack(outputs)","69030d5c":"def cos_sim_matrix(matrix1, matrix2):\n    \"\"\"\n    item-feature \u884c\u5217\u304c\u4e0e\u3048\u3089\u308c\u305f\u969b\u306b\n    item \u9593\u30b3\u30b5\u30a4\u30f3\u985e\u4f3c\u5ea6\u884c\u5217\u3092\u6c42\u3081\u308b\u95a2\u6570\n    \"\"\"\n    # d = matrix @ matrix.T  # item-vector \u540c\u58eb\u306e\u5185\u7a4d\u3092\u8981\u7d20\u3068\u3059\u308b\u884c\u5217\n    # matrix1 : M * V, matrix2 : V * N\n    d = matrix1 @ matrix2\n\n    # \u30b3\u30b5\u30a4\u30f3\u985e\u4f3c\u5ea6\u306e\u5206\u6bcd\u306b\u5165\u308c\u308b\u305f\u3081\u306e\u3001\u5404 item-vector \u306e\u5927\u304d\u3055\u306e\u5e73\u65b9\u6839\n    # V \u306e\u6b21\u5143\u3067 sum : (M * V)\n    norm1 = (matrix1 * matrix1).sum(axis=1, keepdims=True) ** .5\n    # V \u306e\u6b21\u5143\u3067 sum : (V * N)\n    norm2 = (matrix2 * matrix2).sum(axis=0, keepdims=True) ** .5\n\n    # \u305d\u308c\u305e\u308c\u306e item \u306e\u5927\u304d\u3055\u306e\u5e73\u65b9\u6839\u3067\u5272\u3063\u3066\u3044\u308b\uff08\u306a\u3093\u3060\u304b\u30b9\u30de\u30fc\u30c8\uff01\uff09\n    return d \/ norm1 \/ norm2","ef8c51c3":"%%time\n\n# \u884c\u5217\u6f14\u7b97\u3067 test_img_num * pre_train_img_num \u306e\u985e\u4f3c\u5ea6\u884c\u5217\u3092\u7372\u5f97\u3059\u308b\nd = cos_sim_matrix(org_test_vectors, pre_vectors.T)\nprint(d.shape)\nprint(d)\n\n# argmax \u3067 test_img \u3068\u6700\u3082\u985e\u4f3c\u3057\u3066\u3044\u308b pre_train_img \u304c,\n# max \u3067\u305d\u306e\u985e\u4f3c\u5ea6\u3092\u7372\u5f97\u3067\u304d\u308b\nprint(np.argmax(d, 1), np.max(d, 1))\n\n# \u2191 \u3053\u308c\u3089\u3092\u5bfe\u5fdc\u3055\u305b\u305f\u8f9e\u66f8\u306b\u3057\u3066\u5b8c\u6210\nimg_pair = [\n    (org_test, pre_img_paths[sim_argmax], sim_max) for org_test, sim_argmax, sim_max in zip(org_test_img_paths, np.argmax(d, 1), np.max(d, 1))\n]\n\nimg_pair","7d6fb23d":"import albumentations as A\nimport cv2\nimport gc\nimport os\nimport math\nimport random\nimport time\nimport warnings\nimport sys\n\nimport numpy as np\nimport pandas as pd\nimport transformers\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torch.optim import Adam, SGD\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nfrom pathlib import Path\nfrom typing import List\nfrom PIL import Image\n\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error, roc_auc_score\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nfrom tqdm import tqdm","224266f2":"class CFG:\n    ######################\n    # Globals #\n    ######################\n    seed = 71\n    epochs = 20\n    folds = [0, 1, 2, 3, 4]\n    N_FOLDS = 5\n    LR = 1e-4\n    train_bs = 16\n    valid_bs = 32\n    train_root = '..\/input\/petfinder-pawpularity-score\/train\/'\n    test_root = '..\/input\/petfinder-pawpularity-score\/test\/'\n    in_chans = 3\n    ID_COL = 'Id'\n    TARGET_COL = 'Pawpularity'\n    TARGET_DIM = 1\n    FEATURE_COLS = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action',\n        'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', \n        'Info', 'Blur',\n    ]","41c06697":"def set_seed(seed=42):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False","63590459":"class Pet2Dataset:\n    def __init__(self, X, y=None, Meta_features=None, transforms=None):\n        self.X = X\n        self.y = y\n        self.Meta_features = Meta_features\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, item):\n        path = CFG.test_root + self.X[item] + '.jpg'\n        features = cv2.imread(path)\n        features = cv2.cvtColor(features, cv2.COLOR_BGR2RGB)\n        features = self.transforms['valid'](image=features)['image']\n        features = np.transpose(features, (2, 0, 1)).astype(np.float32)\n\n        return {\n            'x': torch.tensor(features, dtype=torch.float32),\n            'meta': torch.tensor(self.Meta_features[item], dtype=torch.float32),\n        }","f5fb0bb0":"class Pet2Model(nn.Module):\n    def __init__(self, model_name):\n        super(Pet2Model, self).__init__()    \n        \n        # Model Encoder\n        self.model = timm.create_model(model_name, pretrained=False, num_classes=0, in_chans=CFG.in_chans)\n        self.model.head = nn.Linear(self.model.num_features, 128)\n        self.dense = nn.Linear(128, CFG.TARGET_DIM)\n\n    def forward(self, features):\n        x = self.model(features)\n        output = self.dense(x)\n        return output.squeeze(-1)","2fb03f81":"class Pet2CNNModel(nn.Module):\n    def __init__(self, model_name):\n        super(Pet2CNNModel, self).__init__()    \n        \n        # Model Encoder\n        self.model = timm.create_model(model_name, pretrained=False, num_classes=0, in_chans=CFG.in_chans)\n        self.model.fc = nn.Linear(self.model.num_features, 128)\n        self.dense = nn.Linear(128, CFG.TARGET_DIM)\n\n    def forward(self, features):\n        x = self.model(features)\n        output = self.dense(x)\n        return output.squeeze(-1)","b40a833f":"class Pet2VitCNNModel(nn.Module):\n    def __init__(self, model_name):\n        super(Pet2VitCNNModel, self).__init__()    \n        \n        # Model Encoder\n        self.model = timm.create_model(model_name, pretrained=False, num_classes=0, in_chans=CFG.in_chans)\n        self.model.head = nn.Linear(self.model.num_features, 128)\n        self.dense = nn.Linear(128, CFG.TARGET_DIM)\n\n    def forward(self, features):\n        x = self.model(features)\n        output = self.dense(x)\n        return output.squeeze(-1)","a1e9226c":"def make_preds(model_dict1, model_dict2, model_dict3, model_dict4, model_dict5, model_dict6, model_dict7):    \n    df = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/test.csv\")\n    y_pred1 = []\n    y_pred2 = []\n    y_pred3 = []\n    y_pred4 = []\n    y_pred5 = []\n    y_pred6 = []\n    y_pred7 = []\n    for fold in CFG.folds:\n        model1 = Pet2Model(model_dict1['MODEL_NAME'])\n        model1.to(device)\n        model1.load_state_dict(torch.load(f'..\/input\/kaerururu-petfinder2-{model_dict1[\"EXP_ID\"]}\/fold-{fold}.bin'))\n        model1.eval()\n        \n        model2 = Pet2Model(model_dict2['MODEL_NAME'])\n        model2.to(device)\n        model2.load_state_dict(torch.load(f'..\/input\/kaerururu-petfinder2-{model_dict2[\"EXP_ID\"]}\/fold-{fold}.bin'))\n        model2.eval()\n        \n        model3 = Pet2Model(model_dict3['MODEL_NAME'])\n        model3.to(device)\n        model3.load_state_dict(torch.load(f'..\/input\/kaerururu-petfinder2-{model_dict3[\"EXP_ID\"]}\/fold-{fold}.bin'))\n        model3.eval()\n        \n        model4 = Pet2CNNModel(model_dict4['MODEL_NAME'])\n        model4.to(device)\n        model4.load_state_dict(torch.load(f'..\/input\/kaerururu-petfinder2-{model_dict4[\"EXP_ID\"]}\/fold-{fold}.bin'))\n        model4.eval()\n        \n        model5 = Pet2VitCNNModel(model_dict5['MODEL_NAME'])\n        model5.to(device)\n        model5.load_state_dict(torch.load(f'..\/input\/kaerururu-petfinder2-{model_dict5[\"EXP_ID\"]}\/fold-{fold}.bin'))\n        model5.eval()\n        \n        model6 = Pet2Model(model_dict6['MODEL_NAME'])\n        model6.to(device)\n        model6.load_state_dict(torch.load(f'..\/input\/kaerururu-petfinder2-{model_dict6[\"EXP_ID\"]}\/fold-{fold}.bin'))\n        model6.eval()\n        \n        model7 = Pet2Model(model_dict7['MODEL_NAME'])\n        model7.to(device)\n        model7.load_state_dict(torch.load(f'..\/input\/kaerururu-petfinder2-{model_dict7[\"EXP_ID\"]}\/fold-{fold}.bin'))\n        model7.eval()\n        \n        dataset1 = Pet2Dataset(X=df[CFG.ID_COL].values, y=None, Meta_features=df[CFG.FEATURE_COLS].values, transforms=model_dict1['TRANSFORM'])\n        data_loader1 = torch.utils.data.DataLoader(\n            dataset1, batch_size=CFG.valid_bs\/\/4, num_workers=0, pin_memory=True, shuffle=False\n        )\n        \n        dataset2 = Pet2Dataset(X=df[CFG.ID_COL].values, y=None, Meta_features=df[CFG.FEATURE_COLS].values, transforms=model_dict2['TRANSFORM'])\n        data_loader2 = torch.utils.data.DataLoader(\n            dataset2, batch_size=CFG.valid_bs\/\/4, num_workers=0, pin_memory=True, shuffle=False\n        )\n        \n        del dataset1, dataset2; gc.collect()\n\n        final_output1 = []\n        final_output2 = []\n        final_output3 = []\n        final_output4 = []\n        final_output5 = []\n        final_output6 = []\n        final_output7 = []\n        for b_idx, (data1, data2) in tqdm(enumerate(zip(data_loader1, data_loader2))):\n            with torch.no_grad():\n                inputs384 = data1['x'].to(device)\n                inputs224 = data2['x'].to(device)\n                                          \n                output1 = model1(inputs384)\n                output2 = model2(inputs224)\n                output3 = model3(inputs224)\n                output4 = model4(inputs384)\n                output5 = model5(inputs384)\n                output6 = model6(inputs224)\n                output7 = model7(inputs224)\n                \n                output1 = torch.sigmoid(output1) * 100.\n                output1 = output1.detach().cpu().numpy().tolist()\n                final_output1.extend(output1)\n                \n                output2 = torch.sigmoid(output2) * 100.\n                output2 = output2.detach().cpu().numpy().tolist()\n                final_output2.extend(output2)\n                \n                output3 = torch.sigmoid(output3) * 100.\n                output3 = output3.detach().cpu().numpy().tolist()\n                final_output3.extend(output3)\n                \n                output4 = torch.sigmoid(output4) * 100.\n                output4 = output4.detach().cpu().numpy().tolist()\n                final_output4.extend(output4)\n                \n                output5 = torch.sigmoid(output5) * 100.\n                output5 = output5.detach().cpu().numpy().tolist()\n                final_output5.extend(output5)\n                \n                output6 = torch.sigmoid(output6) * 100.\n                output6 = output6.detach().cpu().numpy().tolist()\n                final_output6.extend(output6)\n                \n                output7 = torch.sigmoid(output7) * 100.\n                output7 = output7.detach().cpu().numpy().tolist()\n                final_output7.extend(output7)\n                \n        y_pred1.append(np.array(final_output1))\n        y_pred2.append(np.array(final_output2))\n        y_pred3.append(np.array(final_output3))\n        y_pred4.append(np.array(final_output4))\n        y_pred5.append(np.array(final_output5))\n        y_pred6.append(np.array(final_output6))\n        y_pred7.append(np.array(final_output7))\n        torch.cuda.empty_cache()\n        \n    y_pred1 = np.mean(y_pred1, 0)\n    y_pred2 = np.mean(y_pred2, 0)\n    y_pred3 = np.mean(y_pred3, 0)\n    y_pred4 = np.mean(y_pred4, 0)\n    y_pred5 = np.mean(y_pred5, 0)\n    y_pred6 = np.mean(y_pred6, 0)\n    y_pred7 = np.mean(y_pred7, 0)\n    \n    del model1, model2, model3, model4, model5, model6, model7; gc.collect()\n    del final_output1, final_output2, final_output3, final_output4, final_output5, final_output6, final_output7; gc.collect()\n    return y_pred1, y_pred2, y_pred3, y_pred4, y_pred5, y_pred6, y_pred7","b51973d7":"# environment\nset_seed(CFG.seed)\n\nmodel_dict1 = {\n    'EXP_ID' : '042', \n    'MODEL_NAME' : 'swin_large_patch4_window12_384',\n    'TRANSFORM' : {\n        'valid' : A.Compose([\n            A.Resize(384, 384, p=1),\n            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0,),\n        ], p=1.0),    \n    }\n}\n\nmodel_dict2 = {\n    'EXP_ID' : '044', \n    'MODEL_NAME' : 'swin_large_patch4_window7_224',\n    'TRANSFORM' : {\n        'valid' : A.Compose([\n            A.Resize(224, 224, p=1),\n            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0,),\n        ], p=1.0),    \n    }\n}\n\nmodel_dict3 = {\n    'EXP_ID' : '055', \n    'MODEL_NAME' : 'swin_large_patch4_window7_224',\n    'TRANSFORM' : {\n        'valid' : A.Compose([\n            A.Resize(224, 224, p=1),\n            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0,),\n        ], p=1.0),    \n    }\n}\n\nmodel_dict4 = {\n    'EXP_ID' : '084', \n    'MODEL_NAME' : 'resnext101_32x8d',\n    'TRANSFORM' : {\n        'valid' : A.Compose([\n            A.Resize(384, 384, p=1),\n            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0,),\n        ], p=1.0),    \n    }\n}\n\nmodel_dict5 = {\n    'EXP_ID' : '062', \n    'MODEL_NAME' : 'vit_base_r50_s16_384',\n    'TRANSFORM' : {\n        'valid' : A.Compose([\n            A.Resize(384, 384, p=1),\n            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0,),\n        ], p=1.0),    \n    }\n}\n\nmodel_dict6 = {\n    'EXP_ID' : '074', \n    'MODEL_NAME' : 'swin_large_patch4_window7_224',\n    'TRANSFORM' : {\n        'valid' : A.Compose([\n            A.Resize(224, 224, p=1),\n            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0,),\n        ], p=1.0),    \n    }\n}\n\nmodel_dict7 = {\n    'EXP_ID' : '085', \n    'MODEL_NAME' : 'swin_large_patch4_window7_224',\n    'TRANSFORM' : {\n        'valid' : A.Compose([\n            A.Resize(224, 224, p=1),\n            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0,),\n        ], p=1.0),    \n    }\n}\n\nsub = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')\npreds_042, preds_044, preds_055, preds_084, preds_062, preds_074, preds_085 = make_preds(model_dict1, model_dict2, model_dict3, model_dict4, model_dict5, model_dict6, model_dict7)","d903e2d6":"pre_sim_df = pd.DataFrame(img_pair, columns=['org_path', 'pre_path', 'sim'])\npre_sim_df","094e1ed9":"#pre_train_df = pd.read_csv('..\/input\/prepetfinder\/pre_petfinder\/train\/train.csv')\n# pre_df = pd.concat([pd.read_csv('..\/input\/prepetfinder\/pre_petfinder\/train\/train.csv'), pd.read_csv('..\/input\/prepetfinder\/pre_petfinder_test\/test\/test.csv')])\n\npre_df = pd.read_csv('..\/input\/pp-stacking-avg-v019-nlp-feature\/prepetfinder_add_emoji.csv')\npre_df.head(2)","4b25f407":"pre_sim_list = []\nfor idx, (org_path, pre_path, sim) in tqdm(enumerate(zip(pre_sim_df['org_path'].values, pre_sim_df['pre_path'].values, pre_sim_df['sim'].values))): \n    org_id = org_path.split('\/')[-1].split('.')[0]\n    pre_id = pre_path.split('\/')[-1].split('-')[0]\n    \n    adoptionSpeed = pre_df[pre_df['PetID'] == pre_id].iloc[0]['AdoptionSpeed']\n    \n    pre_sim_list.append(\n        {\n            'org_path':org_path,\n            'pre_path':pre_path,\n            'sim':sim,\n            'org_id':org_id,\n            'pre_id':pre_id,\n            'adoptionSpeed':adoptionSpeed\n            \n        }\n    )\npwup_speed_df = pd.DataFrame(pre_sim_list)\npwup_speed_df","43a283dc":"test_df = test_df.merge(pwup_speed_df[['org_id', 'adoptionSpeed', 'sim', 'pre_id']], how='left', left_on='Id', right_on='org_id').reset_index()\ndisplay(test_df)\n# test_df = test_df.merge(pd.concat([pd.read_csv('..\/input\/prepetfinder\/pre_petfinder\/train\/train.csv'), pd.read_csv('..\/input\/prepetfinder\/pre_petfinder_test\/test\/test.csv')]), how='left', left_on='pre_id', right_on='PetID')\ntest_df = test_df.merge(pd.read_csv('..\/input\/pp-stacking-avg-v019-nlp-feature\/prepetfinder_add_emoji.csv'), how='left', left_on='pre_id', right_on='PetID')\n\ntest_df['Breed_205'] = (test_df['Breed1'] == 205).astype(int)\ntest_df['Breed_307'] = (test_df['Breed1'] == 307).astype(int)\ntest_df['Breed_266'] = (test_df['Breed1'] == 266).astype(int)\ntest_df['Breed_265'] = (test_df['Breed1'] == 265).astype(int)\ntest_df['Breed_299'] = (test_df['Breed1'] == 299).astype(int)\ntest_df['Breed_264'] = (test_df['Breed1'] == 264).astype(int)\ntest_df['Breed_292'] = (test_df['Breed1'] == 292).astype(int)\n\ntest_df['Breed_285'] = (test_df['Breed1'] == 285).astype(int)\ntest_df['Breed_141'] = (test_df['Breed1'] == 141).astype(int)\ntest_df['Breed_218'] = (test_df['Breed1'] == 218).astype(int)\ntest_df['Breed_205'] = (test_df['Breed1'] == 205).astype(int)\n\ntest_df['Breed_179'] = (test_df['Breed1'] == 179).astype(int)\ntest_df['Breed_103'] = (test_df['Breed1'] == 103).astype(int)\n\ntest_df['RescuerID_1'] = (test_df['RescuerID'] == 'fa90fa5b1ee11c86938398b60abc32cb').astype(int)\ntest_df['RescuerID_2'] = (test_df['RescuerID'] == 'aa66486163b6cbc25ea62a34b11c9b91').astype(int)\ntest_df['RescuerID_3'] = (test_df['RescuerID'] == 'c00756f2bdd8fa88fc9f07a8309f7d5d').astype(int)\ntest_df['RescuerID_4'] = (test_df['RescuerID'] == 'b53c34474d9e24574bcec6a3d3306a0d').astype(int)\ntest_df['RescuerID_5'] = (test_df['RescuerID'] == 'b770bac0ca797cf1433c48a35d30c4cb').astype(int)\n\ntest_df['Name_word_len'] = test_df['Name'].fillna('').apply(lambda x : len(x.split(' ')))\ntest_df['Description_len'] = test_df['Description'].fillna('').apply(lambda x : len(x.split(' ')))\n\n\ntest_df['num_name_&'] = test_df['Name'].fillna('').apply(lambda x: sum(x.count(w) for w in '&'))\n\n_df = pre_df['RescuerID'].value_counts().reset_index()\ntest_df['RescuerID_new_entry'] = test_df['RescuerID'].isin(_df[_df['RescuerID'] <= 6]['index']).astype(int)\n\ntest_df['Breed_266_265_299'] = test_df['Breed1'].map(lambda x: 1 if x in [266, 265, 299] else 0)\ntest_df['Breed_292_179'] = test_df['Breed1'].map(lambda x: 1 if x in [292, 179] else 0)\ntest_df['Breed_285_103'] = test_df['Breed1'].map(lambda x: 1 if x in [285, 103] else 0)","d7a1c5d7":"_df","71030c41":"test_df = test_df.merge(pd.read_csv('..\/input\/pp-stacking-avg-v021-bert-sentiment\/prepetfinder_add_bert_sentiment.csv')[['PetID', 'sentiment_name_label_roberta']], how='left', on='PetID')","08a15e00":"# st_models = unpickle('..\/input\/fork-of-pp-stacking-avg-v016-reduce-pp-features2\/pp_models_stacking.pkl')\nst_models = unpickle('..\/input\/offense-pp-stacking-avg-v030-mendokusakunai\/pp_models_stacking.pkl')","126f79a9":"test_df['y_preds_0126'] = y_preds_0126\ntest_df['y_preds_0101'] = y_preds_0101\n#test_df['y_preds_0095'] = y_preds_0095\ntest_df['y_preds_0080'] = y_preds_0080\ntest_df['y_preds_0158'] = y_preds_0158\ntest_df['y_preds_c0007'] = y_preds_c0007\ntest_df['y_johannyjm_1790651'] = y_johannyjm_1790651\ntest_df['preds_042'] = preds_042\ntest_df['preds_044'] = preds_044\ntest_df['preds_055'] = preds_055\n# test_df['preds_060'] = preds_060\ntest_df['preds_084'] = preds_084\ntest_df['preds_085'] = preds_085\ntest_df['preds_062'] = preds_062\ntest_df['preds_074'] = preds_074\ntest_df['y_preds_0149'] = y_preds_0149\n\ntest_df['fast_ai_004_preds'] = fast_ai_004_preds","e693b8f0":"#test_df['sim'] = 1\n#test_df['adoptionSpeed'] = 0","78965bb4":"pp_stacking_dfs = []\n\nfor c, model_as in enumerate(st_models):\n    \n    pred_stack = model_as[0].predict(test_df[['y_preds_0158', 'y_preds_0149', 'y_preds_0080', 'y_preds_c0007', 'y_johannyjm_1790651', \n                                              'preds_042', 'preds_044', 'preds_055', 'fast_ai_004_preds', \n                                              'preds_084', 'preds_062', 'y_preds_0126']])\n    \n    test_df['Pawpularity'] = pred_stack\n\n    under_threshold_df = test_df[test_df['sim'] < 0.65].copy()\n    over_threshold_df = test_df[test_df['sim'] >= 0.65].copy()\n    \n    if len(over_threshold_df) > 0:\n        over_threshold_df['Pawpularity'] = model_as[6].predict(over_threshold_df[['Pawpularity', 'Breed_307', 'Breed_266_265_299', 'Breed_292_179', 'Breed_285_103', 'Age', 'RescuerID_3', 'RescuerID_5', 'Description_len', 'PhotoAmt', 'Name_word_len', 'is_emoji', 'RescuerID_new_entry']])\n        print('over_threshold_df')\n    \n    over_threshold_df_as0 = over_threshold_df[over_threshold_df['adoptionSpeed'] == 0].copy()\n    over_threshold_df_as1 = over_threshold_df[over_threshold_df['adoptionSpeed'] == 1].copy()\n    over_threshold_df_as2 = over_threshold_df[over_threshold_df['adoptionSpeed'] == 2].copy()\n    over_threshold_df_as3 = over_threshold_df[over_threshold_df['adoptionSpeed'] == 3].copy()\n    over_threshold_df_as4 = over_threshold_df[over_threshold_df['adoptionSpeed'] == 4].copy()\n    over_threshold_df_other = over_threshold_df[~(over_threshold_df['adoptionSpeed'].isin([i for i in range(5)]))].copy()\n    \n    if len(over_threshold_df_as0) > 0:\n        over_threshold_df_as0['Pawpularity'] = model_as[1].predict(over_threshold_df_as0[['Pawpularity', 'Age']])\n        print('over_threshold_df_as0')\n    if len(over_threshold_df_as1) > 0:\n        over_threshold_df_as1['Pawpularity'] = model_as[2].predict(over_threshold_df_as1[['Pawpularity', 'Age']])\n        print('over_threshold_df_as1')\n    if len(over_threshold_df_as2) > 0:\n        over_threshold_df_as2['Pawpularity'] = model_as[3].predict(over_threshold_df_as2[['Pawpularity', 'Breed_205', 'Breed_307', 'Breed_266_265_299', 'Age']])\n        print('over_threshold_df_as2')\n    if len(over_threshold_df_as3) > 0:\n        over_threshold_df_as3['Pawpularity'] = model_as[4].predict(over_threshold_df_as3[['Pawpularity', 'Breed_307', 'Breed_266_265_299', 'Age']])\n        print('over_threshold_df_as3')\n    if len(over_threshold_df_as4) > 0:\n        over_threshold_df_as4['Pawpularity'] = model_as[5].predict(over_threshold_df_as4[['Pawpularity', 'Breed_307', 'Breed_266_265_299', 'Age']])\n        print('over_threshold_df_as4')\n        \n    test_adjust_df = pd.concat([under_threshold_df, over_threshold_df_as0, over_threshold_df_as1, over_threshold_df_as2, over_threshold_df_as3, over_threshold_df_as4, over_threshold_df_other]).sort_values('index')\n\n    pp_stacking_dfs.append(test_adjust_df.copy())","4f84ccbb":"pp_stacking_df = pd.concat(pp_stacking_dfs)\npp_stacking_df.head(2)","e86f5738":"# avg_models = unpickle('..\/input\/fork-of-pp-stacking-avg-v016-reduce-pp-features2\/pp_models_avg.pkl')\navg_models = unpickle('..\/input\/offense-pp-stacking-avg-v030-mendokusakunai\/pp_models_avg.pkl')","170af00c":"pp_avg_dfs = []\n\nfor c, model_as in enumerate(avg_models):\n    \n    pred_avg =  test_df[['y_preds_0158', 'y_preds_0149', 'y_preds_0080', 'y_preds_c0007', 'y_johannyjm_1790651', \n                         'preds_042', \n                         'preds_044',\n                         'preds_055', 'fast_ai_004_preds', \n                         'preds_084', 'preds_062', 'y_preds_0126']].mean(axis=1)\n    \n    test_df['Pawpularity'] = pred_avg\n\n    under_threshold_df = test_df[test_df['sim'] < 0.65].copy()\n    over_threshold_df = test_df[test_df['sim'] >= 0.65].copy()\n    \n    if len(over_threshold_df) > 0:\n        over_threshold_df['Pawpularity'] = model_as[6].predict(over_threshold_df[['Pawpularity', 'Breed_307', 'Breed_266_265_299', 'Breed_292_179', 'Breed_285_103', 'Age', 'RescuerID_3', 'RescuerID_5', 'Description_len', 'PhotoAmt', 'Name_word_len', 'is_emoji', 'RescuerID_new_entry']])\n        print('over_threshold_df')\n    \n    over_threshold_df_as0 = over_threshold_df[over_threshold_df['adoptionSpeed'] == 0].copy()\n    over_threshold_df_as1 = over_threshold_df[over_threshold_df['adoptionSpeed'] == 1].copy()\n    over_threshold_df_as2 = over_threshold_df[over_threshold_df['adoptionSpeed'] == 2].copy()\n    over_threshold_df_as3 = over_threshold_df[over_threshold_df['adoptionSpeed'] == 3].copy()\n    over_threshold_df_as4 = over_threshold_df[over_threshold_df['adoptionSpeed'] == 4].copy()\n    over_threshold_df_other = over_threshold_df[~(over_threshold_df['adoptionSpeed'].isin([i for i in range(5)]))].copy()\n    \n    if len(over_threshold_df_as0) > 0:\n        over_threshold_df_as0['Pawpularity'] = model_as[1].predict(over_threshold_df_as0[['Pawpularity', 'Age']])\n        print('over_threshold_df_as0')\n    if len(over_threshold_df_as1) > 0:\n        over_threshold_df_as1['Pawpularity'] = model_as[2].predict(over_threshold_df_as1[['Pawpularity', 'Age']])\n        print('over_threshold_df_as1')\n    if len(over_threshold_df_as2) > 0:\n        over_threshold_df_as2['Pawpularity'] = model_as[3].predict(over_threshold_df_as2[['Pawpularity', 'Breed_205', 'Breed_307', 'Breed_266_265_299', 'Age']])\n        print('over_threshold_df_as2')\n    if len(over_threshold_df_as3) > 0:\n        over_threshold_df_as3['Pawpularity'] = model_as[4].predict(over_threshold_df_as3[['Pawpularity', 'Breed_307', 'Breed_266_265_299', 'Age']])\n        print('over_threshold_df_as3')\n    if len(over_threshold_df_as4) > 0:\n        over_threshold_df_as4['Pawpularity'] = model_as[5].predict(over_threshold_df_as4[['Pawpularity', 'Breed_307', 'Breed_266_265_299', 'Age']])\n        print('over_threshold_df_as4')\n        \n    test_adjust_df = pd.concat([under_threshold_df, over_threshold_df_as0, over_threshold_df_as1, over_threshold_df_as2, over_threshold_df_as3, over_threshold_df_as4, over_threshold_df_other]).sort_values('index')\n\n    pp_avg_dfs.append(test_adjust_df.copy())","63574c97":"pp_avg_df = pd.concat(pp_avg_dfs)\npp_avg_df.head(2)","19396648":"pp_avg_mean_df = pp_avg_df.groupby('Id')['Pawpularity'].mean().to_frame().reset_index().sort_values('Id')\npp_avg_mean_df","8ca2f0d9":"pp_stacking_mean_df = pp_stacking_df.groupby('Id')['Pawpularity'].mean().to_frame().reset_index().sort_values('Id')\npp_stacking_mean_df","1c55aac0":"weight_average_pred = np.average([pp_stacking_mean_df['Pawpularity'].to_numpy(), pp_avg_mean_df['Pawpularity'].to_numpy()], weights=[0.75, 0.25], axis=0)\npp_df = pp_avg_mean_df.copy()\npp_df['Pawpularity'] = weight_average_pred\npp_df","722fe6ab":"\"\"\"pp_df = pd.concat([pp_avg_mean_df, pp_stacking_mean_df])\npp_df\"\"\"","5828a73f":"\"\"\"pp_df = pp_df.groupby('Id')['Pawpularity'].mean().to_frame().reset_index()\npp_df\"\"\"","bdad649c":"# y_preds_0101","5a17ec9f":"y_preds_0158","07f3fd01":"y_preds_c0007","2b38423f":"# y_preds_0030","00782cbf":"#y_preds_0095","0c07e9e5":"y_johannyjm_1790651","87f2a858":"preds_042","568c857d":"preds_044","e7e80150":"preds_055","51f6cdd5":"preds_084 # preds_060","aac7ae10":"preds_085","ab2f38f2":"fast_ai_004_preds","04855d99":"preds_062","d4b20c1a":"y_preds_0126","c409eee7":"preds_074","157c666a":"y_preds_0149","cba35ecb":"y_preds_0158","23943fae":"y_preds_0080","607e91d4":"submission_df = pp_df[['Id', 'Pawpularity']]\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df","bc16677a":"## 0087, 0095, 0097, 0101, 0126, 0149","b60f6ea5":"## yuki Models","38e00eb3":"### 42, 44","86aa9683":"## 5 fold models","7dc11681":"## johannyjm_1790651","fb5151dd":"## c0007, 0030","53744b1a":"## kaeru","cf17986a":"## fast_ai_0004\n","e034bc3f":"### \u985e\u4f3c\u5ea6\u7b97\u51fa","22116d9a":"## 8fold models","e6827672":"## 10fold models\n### 0080","566db7c5":"## 4 fold models","a8207cbf":"## Stacking","5bcde5b0":"## yuki DataAugmentations","7d8371fd":"## 0158","a8f2f952":"## yuki Datasets","f3d33435":"## \u524d\u56de\u30b3\u30f3\u30da\u3068\u540c\u3058\u753b\u50cf\u62bd\u51fa","4af0bbe2":"## Average"}}