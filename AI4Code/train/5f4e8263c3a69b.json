{"cell_type":{"ffc80f4c":"code","87548684":"code","2b38905b":"code","68fb73df":"code","11defda7":"code","8549434e":"code","b657fc53":"code","7aa265ef":"code","1bf288e4":"code","f35bad45":"code","3bfa591b":"code","8e2f99e5":"code","280a7223":"code","c5e00d7f":"code","b1b45078":"code","06d836bd":"code","4d8e2299":"code","20310485":"code","8987e863":"code","5ba84baa":"code","4dc927a1":"code","e7625f7c":"code","0e7c7113":"code","34e24823":"code","ddec5738":"code","4c3971b4":"code","17351337":"code","d38a46aa":"code","4d4bde5f":"code","950df953":"code","c1655eaf":"code","2ee85200":"code","6520a4bc":"code","3fff22e6":"code","16191a5e":"markdown","739dfcff":"markdown","a8733989":"markdown","00471e94":"markdown","cbf27da8":"markdown","0e85d821":"markdown","a37bc932":"markdown","b90952b2":"markdown","1eb73f96":"markdown","d9c7e3ef":"markdown","e553f8a3":"markdown","571e5fd5":"markdown","e934057d":"markdown","a755c95b":"markdown","19cb9db1":"markdown","36db8759":"markdown","c0206d38":"markdown","c8bae31d":"markdown","c3595de7":"markdown","71c402a7":"markdown","87681937":"markdown","1ec4613e":"markdown"},"source":{"ffc80f4c":"import pandas as pd\nimport numpy as np\nimport os\nfrom itertools import product\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor\nfrom math import sqrt\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers import Input, Embedding, Dense, Dropout, concatenate, Flatten, LSTM, BatchNormalization\nfrom keras.regularizers import l2\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom sklearn.linear_model import LinearRegression","87548684":"def plt_model(model_hist):\n        acc = model_hist.history['mean_squared_error']\n        val_acc = model_hist.history['val_mean_squared_error']\n        loss = model_hist.history['loss']\n        val_loss = model_hist.history['val_loss']\n\n        epochs = range(1, len(acc) + 1)\n\n        plt.figure(figsize=(15, 6));\n        plt.subplot(1, 2, 1)\n        plt.plot(epochs, acc, color='green', label='Training MSE')\n        plt.plot(epochs, val_acc, color='blue', label='Validation MSE')\n        plt.title('Training and Validation MSE')\n        plt.legend(loc='best')\n        plt.xlabel('Epochs')\n        plt.ylabel('MSE')\n\n        plt.subplot(1, 2, 2)\n        plt.plot(epochs, loss, color='green', label='Training loss')\n        plt.plot(epochs, val_loss, color='blue', label='Validation loss')\n        plt.title('Training and Validation loss')\n        plt.legend(loc='best')\n        plt.xlabel('Epochs')\n        plt.ylabel('Loss')\n\n        plt.show()","2b38905b":"df_sales = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ndf_item_categories = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\ndf_items = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\ndf_sample_submission=pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")\ndf_shops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ndf_test = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\n","68fb73df":"print(f'df_sales shape: {df_sales.shape}')\nprint(f'df_items shape: {df_items.shape}')\nprint(f'df_item_categories shape: {df_item_categories.shape}')\nprint(f'df_shops shape: {df_shops.shape}')\nprint(f'df_test shape: {df_test.shape}')","11defda7":"print(f'df_sales structure\\n\\n{df_sales.head(3)}\\n\\n\\n')\nprint(f'df_items structure\\n\\n{df_items.head(3)}\\n\\n\\n')\nprint(f'df_item_categories structure\\n\\n{df_item_categories.head(3)}\\n\\n\\n')\nprint(f'df_shops structure\\n\\n{df_shops.head(3)}\\n\\n\\n')\nprint(f'df_test structure\\n\\n{df_test.head(3)}\\n\\n\\n')\nprint(f'df_test structure\\n\\n{df_sample_submission.head(3)}\\n\\n\\n')","8549434e":"df_month_sales = df_sales.groupby(['date_block_num', \"shop_id\", \"item_id\"]).agg({\"item_cnt_day\" : 'sum'}).reset_index()\ndf_month_sales = df_month_sales.rename(columns={'item_cnt_day': 'sales_per_month'})\n","b657fc53":"df_total_month_sales = df_month_sales.groupby(['date_block_num']).agg({'sales_per_month' : 'sum'}).reset_index()\ndf_total_month_sales = df_total_month_sales.rename(columns={'sales_per_month': 'total_sales_per_month'})\nplt.figure(num=None, figsize=(10, 8), dpi=80)\nplt.bar(df_total_month_sales['date_block_num'], df_total_month_sales['total_sales_per_month'])\n","7aa265ef":"df_month_sales['sales_per_month'] = df_month_sales['sales_per_month'].clip(0,20)\n","1bf288e4":"cols = [\"date_block_num\", \"shop_id\", \"item_id\"]\n\nall_months = pd.DataFrame(np.array(list(product(range(34), df_sales['shop_id'].unique(), df_sales['item_id'].unique()))), columns = cols)\n\ndf_month_sales = pd.merge(all_months, df_month_sales, on=cols, how='left').fillna(0)\n\n\n\n","f35bad45":"df_month_sales = df_month_sales.sort_values(by=cols)","3bfa591b":"sales_for_month_0 = df_month_sales[df_month_sales['date_block_num'] == 0]\nsales_for_month_0['sales_for_previous_month'] = 0\nsales_for_month_0 = pd.merge(sales_for_month_0, df_items[['item_id', 'item_category_id']], on=['item_id'], how='left')\ndfs = [sales_for_month_0]\nfor i in range(1,34):\n    sales_for_month_i = df_month_sales[df_month_sales['date_block_num'] == i]\n    sales_for_month_i['sales_for_previous_month'] = dfs[i-1]['sales_per_month'].to_numpy()\n    sales_for_month_i = pd.merge(sales_for_month_i, df_items[['item_id', 'item_category_id']], on=['item_id'], how='left').reset_index()\n    dfs.append(sales_for_month_i)\n    \ndf_month_sales = pd.concat(dfs)\ndf_month_sales\n","8e2f99e5":"fixed_test = df_test[['shop_id', 'item_id']]\nfixed_test = pd.merge(fixed_test, df_items[['item_id', 'item_category_id']], on=['item_id'], how='left')\nsales_for_month_33 = df_month_sales[df_month_sales['date_block_num'] == 33][['item_id', 'shop_id', 'sales_per_month']]\nsales_for_month_33.rename(columns={'sales_per_month':'sales_for_previous_month'}, inplace=True)\nfixed_test = pd.merge(fixed_test, sales_for_month_33, on=['item_id', 'shop_id'], how='left').fillna(0)\nfixed_test.insert(0, 'date_block_num', 34) \n\n\n\n","280a7223":"cols = [\"date_block_num\", \"shop_id\", \"item_id\", \"item_category_id\", \"sales_for_previous_month\"]\ndata_train = df_month_sales[df_month_sales['date_block_num']%5 != 0]\ndata_val = df_month_sales[df_month_sales['date_block_num']%5 == 0]\n\nX_train = data_train[cols]\ny_train = data_train['sales_per_month']\n\nX_val = data_val[cols]\ny_val = data_val['sales_per_month']","c5e00d7f":"dt = DecisionTreeRegressor()\ndt.fit(X_train,y_train)","b1b45078":"preds = dt.predict(X_val)\nrmse = sqrt(mean_squared_error(y_val, preds))\nprint(rmse)","06d836bd":"preds_test = dt.predict(fixed_test)\n","4d8e2299":"df_sample_submission['item_cnt_month'] = preds_test\ndf_sample_submission.to_csv('.\/data\/first_submission.csv', index=False)","20310485":"item_input = Input(shape=(1,), dtype='int64', name='item_input')\nmonths_input = Input(shape=(1,), dtype='int64', name='months_input')\nshops_input = Input(shape=(1,), dtype='int64', name='shops_input')\nitem_category_input = Input(shape=(1,), dtype='int64', name='item_category_input')\nprevious_month_input = Input(shape=(1,), dtype='int64', name='previous_month_input')\n\n","8987e863":"We will use a simple model, without LSTM ","5ba84baa":"num_of_items = max(data_train['item_id'])+1\nnum_of_months = max(data_train['date_block_num'])+1\nnum_of_shops = max(data_train['shop_id'])+1\nnum_of_categories = max(data_train['item_category_id'])+1\ni = Embedding(num_of_items,int(sqrt(num_of_items)), input_length=1, embeddings_regularizer=l2(1e-4))(item_input)\nm = Embedding(num_of_months, int(sqrt(num_of_months)), input_length=1, embeddings_regularizer=l2(1e-4))(months_input)\ns = Embedding(num_of_shops, int(sqrt(num_of_shops)), input_length=1, embeddings_regularizer=l2(1e-4))(shops_input)\nic = Embedding(num_of_categories, int(sqrt(num_of_categories)), input_length=1, embeddings_regularizer=l2(1e-4))(item_category_input)\npm = Embedding(20, int(sqrt(20)), input_length=1, embeddings_regularizer=l2(1e-4))(previous_month_input)\nx = concatenate([m,s,i,ic, pm])\nx = Flatten()(x)\nx = Dropout(0.4)(x)\nx = Dense(1)(x)\nnn = Model([months_input,shops_input,item_input,item_category_input, previous_month_input],x)\nnn.compile(optimizer=Adam(0.001), loss='mse',metrics=[\"mean_squared_error\"])\nes = EarlyStopping(monitor='val_mean_squared_error', mode='min', verbose=1, patience=2)\ncheckpoint = ModelCheckpoint('model3.hdf5' , monitor='val_mean_squared_error', mode='min', save_best_only=True)\nhistory = nn.fit([X_train['date_block_num'],X_train['shop_id'],X_train['item_id'],X_train['item_category_id'], X_train['sales_for_previous_month']], y_train, batch_size=4096, epochs=8, \n          validation_data=([X_val['date_block_num'],X_val['shop_id'],X_val['item_id'],X_val['item_category_id'], X_val['sales_for_previous_month']], y_val),callbacks=[es, checkpoint])","4dc927a1":"nn.summary()","e7625f7c":"plt_model(history)","0e7c7113":"preds = nn.predict([fixed_test['date_block_num'],fixed_test['shop_id'],fixed_test['item_id'],fixed_test['item_category_id'], fixed_test['sales_for_previous_month']])\n","34e24823":"df_sample_submission['item_cnt_month'] = preds\ndf_sample_submission.to_csv('second_submission.csv', index=False)","ddec5738":"item_input = Input(shape=(1,), dtype='int64', name='item_input')\nmonths_input = Input(shape=(1,), dtype='int64', name='months_input')\nshops_input = Input(shape=(1,), dtype='int64', name='shops_input')\nitem_category_input = Input(shape=(1,), dtype='int64', name='item_category_input')\nprevious_month_input = Input(shape=(1,), dtype='int64', name='previous_month_input')","4c3971b4":"num_of_items = max(data_train['item_id'])+1\nnum_of_months = max(data_train['date_block_num'])+1\nnum_of_shops = max(data_train['shop_id'])+1\nnum_of_categories = max(data_train['item_category_id'])+1\ni = Embedding(num_of_items,int(sqrt(num_of_items)), input_length=1, embeddings_regularizer=l2(1e-4))(item_input)\nm = Embedding(num_of_months, int(sqrt(num_of_months)), input_length=1, embeddings_regularizer=l2(1e-4))(months_input)\ns = Embedding(num_of_shops, int(sqrt(num_of_shops)), input_length=1, embeddings_regularizer=l2(1e-4))(shops_input)\nic = Embedding(num_of_categories, int(sqrt(num_of_categories)), input_length=1, embeddings_regularizer=l2(1e-4))(item_category_input)\npm = Embedding(20, int(sqrt(20)), input_length=1, embeddings_regularizer=l2(1e-4))(previous_month_input)\nx = concatenate([m,s,i,ic,pm])\nx = BatchNormalization()(x)\nx = LSTM(32)(x)\nx = Dropout(0.2)(x)\nx = Dense(1)(x)\nnn = Model([months_input,shops_input,item_input,item_category_input, previous_month_input],x)\nnn.compile(optimizer=Adam(0.0001), loss='mse',metrics=[\"mean_squared_error\"])\n","17351337":"es = EarlyStopping(monitor='val_mean_squared_error', mode='min', verbose=1, patience=2)\ncheckpoint = ModelCheckpoint('model4.hdf5' , monitor='val_mean_squared_error', mode='min', save_best_only=True)\nhistory1 = nn.fit([X_train['date_block_num'],X_train['shop_id'],X_train['item_id'],X_train['item_category_id'], X_train['sales_for_previous_month']], y_train, batch_size=4096, epochs=8, \n          validation_data=([X_val['date_block_num'],X_val['shop_id'],X_val['item_id'],X_val['item_category_id'], X_val['sales_for_previous_month']], y_val),callbacks=[es, checkpoint])","d38a46aa":"nn.load_weights('model4.hdf5')","4d4bde5f":"nn.summary()","950df953":"plt_model(history1)","c1655eaf":"preds = nn.predict([fixed_test['date_block_num'],fixed_test['shop_id'],fixed_test['item_id'],fixed_test['item_category_id'], fixed_test['sales_for_previous_month']])\ndf_sample_submission['item_cnt_month'] = preds\ndf_sample_submission.to_csv('final_submission.csv', index=False)","2ee85200":"item_input = Input(shape=(1,), dtype='int64', name='item_input')\nmonths_input = Input(shape=(1,), dtype='int64', name='months_input')\nshops_input = Input(shape=(1,), dtype='int64', name='shops_input')\nitem_category_input = Input(shape=(1,), dtype='int64', name='item_category_input')\nprevious_month_input = Input(shape=(1,), dtype='int64', name='previous_month_input')","6520a4bc":"extractor = Model(input=nn.input, output=nn.get_layer(\"lstm_1\").output)\n\nlr = LinearRegression(n_jobs=-1)\nprint('predicting training features')\ntrain_preds = extractor.predict([X_train['date_block_num'],X_train['shop_id'],X_train['item_id'],X_train['item_category_id'], X_train['sales_for_previous_month']])\n\nprint(\"Training ml model with features\")\nlr.fit(train_preds, y_train)\n\n","3fff22e6":"print(\"Predicting features for validation\")\nval_preds = extractor.predict([X_val['date_block_num'],X_val['shop_id'],X_val['item_id'],X_val['item_category_id'], X_val['sales_for_previous_month']])\nprint(\"Predicting validation data\")\npreds = lr.predict(val_preds)\nrmse = sqrt(mean_squared_error(y_val, preds))\nprint(rmse)","16191a5e":"We will use a regressor to set the ML benchmark","739dfcff":"Loading the data from CSV files\n","a8733989":"Inputs","00471e94":"![third_submission.PNG](attachment:third_submission.PNG)\n","cbf27da8":"Since the data we have shows the sales per day, we would like to aggregate it into sales pre month","0e85d821":"Lets try improving our results by using embedding","a37bc932":"Lets perform some data preproccessing prior to training our model","b90952b2":"![second_submission.PNG](attachment:second_submission.PNG)\n","1eb73f96":"We add item category and previous month sales aggregation for better results","d9c7e3ef":"We can see that our orignal data does not include days in which 0 items were sold.\nThis is a problem because we might be missing some months where there were no items sold, we would like to add those months.","e553f8a3":"Lets see how many total sales per month we have","571e5fd5":"Changing the test data to match the training","e934057d":"![first_submission.PNG](attachment:first_submission.PNG)","a755c95b":"[](http:\/\/)Now lets add LSTM layer and wee if it improves our results\n","19cb9db1":"1. We split our training data to train and validation, 20% for validation","36db8759":"# THIS ISNT THE FINAL VERSION!!!!!\n# We were unable to revert to the final version , to see the running outcome please look at version 3","c0206d38":"A method to plot the model information\n","c8bae31d":"Now we will use feature extraction","c3595de7":"We would also like to see the columns in each data frame","71c402a7":"Since we will predict a number between 0 to 20, we will clip all values to match that range","87681937":"# Final thoughts\n1. We were able to improve out rmse greatly by adding extra data by filling all of the months with sales (in the original dataset, months with no sales had no corresponding rows)\n   This change, on the other hand, led to big differences between the train+validation results to the test results. (thats because calculating mse when having lows of zeros in our\n   data makes it a lo).\n   We decided to keep this change, even though it messes with the training rmse, because eventually the test rmse was much better.\n2. At first we only used the basic categorical features but then we realized that adding features like sales for previous month and item category improve our results.\n   We also believe that adding more features like sales per month (not per store) and year could improve our results even further.\n   The most important part is finding the correct categorical features to rely upon.\n3. We saw an improvement using LSTM layer, which yielded our best result:\n![best.PNG](attachment:best.PNG)\n","1ec4613e":"Lets see the shape of our data frames\n"}}