{"cell_type":{"71e5af38":"code","a9b5fb57":"code","7bfc248f":"code","758a2000":"code","cac9e648":"code","9133b7c9":"code","2f65120d":"code","23268687":"code","e251c426":"code","214193f6":"code","e5309a26":"code","f78c86cc":"code","58745476":"code","9a41143d":"code","f0432b48":"code","de845ba3":"code","7e5aa250":"code","3e930049":"code","731d1d30":"code","42779653":"code","3332ea56":"code","5af9ef5f":"code","d5f4d26f":"code","ffbf8dd1":"code","3894d7e2":"code","1bdc3cde":"code","f6718653":"code","0996dd76":"code","f992dbc8":"code","1756b9ea":"code","aa2efd69":"code","caaa9831":"code","284f0ba7":"code","0c58f2a8":"markdown","f4a54e05":"markdown","58df3457":"markdown","e4541082":"markdown","33f1bd59":"markdown","50a3fd94":"markdown","b7f59761":"markdown","91c81fc5":"markdown","c78df3b8":"markdown","bcca3a44":"markdown","29e159c4":"markdown","bd32b50d":"markdown","e91ac4f1":"markdown","0cfca40f":"markdown","35151033":"markdown","b6c223fe":"markdown","bbbccd5f":"markdown"},"source":{"71e5af38":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a9b5fb57":"##importing required libraries\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n##Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n##Performance metrics\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, recall_score,accuracy_score, make_scorer\n","7bfc248f":"##reading the bank data\ndf1=pd.read_csv('\/kaggle\/input\/personal-loan-modeling\/Bank_Personal_Loan_Modelling.csv')\ndf1.head()","758a2000":"df1.tail()","cac9e648":"#Removing ID column which is of no relevance\ndf1.drop(columns =['ID', 'ZIP Code'],inplace=True)","9133b7c9":"df1.info()\ndf1.shape","2f65120d":"df1.isnull().sum()##checking missing values","23268687":"df1.describe()","e251c426":"##Lets see the distribution of target column- Personal Loan\nprint(df1.groupby('Personal Loan').size())\nsns.countplot(df1['Personal Loan'],label=\"Count\")\nplt.title(\"Distribution of Target Variable\")\nplt.show()","214193f6":"plt.figure(figsize=(15,10))\nplt.subplot(2,3,1)\ndf1.groupby('Personal Loan')['Income'].mean().plot(kind='bar',title='Income')\nplt.subplot(2,3,2)\ndf1.groupby('Personal Loan')['CCAvg'].mean().plot(kind='bar', title='Average CC Spend')\nplt.subplot(2,3,3)\ndf1.groupby('Personal Loan')['Age'].mean().plot(kind='bar', title='Age')\nplt.subplot(2,3,4)\ndf1.groupby('Personal Loan')['Experience'].mean().plot(kind='bar', title='Experience')\nplt.subplot(2,3,5)\ndf1.groupby('Personal Loan')['Mortgage'].mean().plot(kind='bar', title='Mortagage')","e5309a26":"sns.heatmap(df1.corr())\nplt.show()","f78c86cc":"sns.lmplot(x='Income',y='CCAvg',data=df1,fit_reg=False,hue='Personal Loan') \nsns.lmplot(x='Income',y='Mortgage',data=df1,fit_reg=False,hue='Personal Loan') \nplt.show()","58745476":"##Binning the age since mean is not giving any insight\nbin=[23,35,55,67]\ngroup=['Young','Middle','Old']\ndf1['Age_bin']=pd.cut(df1['Age'],bin,labels=group) #converting numeric into categorical\nage= pd.crosstab(df1['Age_bin'],df1['Personal Loan'])\nage.plot(kind='bar',stacked=True,title='Age Group')\nage.div(age.sum(1).astype(float),axis=0).plot(kind='bar',\n                                              stacked=True,title='% Age Group')","9a41143d":"df1.drop(columns =['Age_bin'],inplace=True)","f0432b48":"pd.crosstab(df1['Securities Account'],df1['Personal Loan']).plot(kind='bar',stacked=True,title='Securities')\npd.crosstab(df1['CD Account'],df1['Personal Loan']).plot(kind='bar',stacked=True,title='CD Account')","de845ba3":"pd.crosstab(df1['Online'],df1['Personal Loan']).plot(kind='bar',stacked=True,title='Online')\npd.crosstab(df1['CreditCard'],df1['Personal Loan']).plot(kind='bar',stacked=True,title='Credit Card')","7e5aa250":"##Plotting family\nedu=pd.crosstab(df1['Family'],df1['Personal Loan'])\nedu.div(edu.sum(1).astype(float),axis=0).plot(kind='bar',\n                                              stacked=True,title='% Family')","3e930049":"##Plotting education\nedu=pd.crosstab(df1['Education'],df1['Personal Loan'])\nedu.div(edu.sum(1).astype(float),axis=0).plot(kind='bar',\n                                              stacked=True,title='% Education')","731d1d30":"##splitting the data into train-test in 80-20 ratio\nX_train, X_test, y_train, y_test = train_test_split(df1.loc[:, df1.columns != 'Personal Loan'], df1['Personal Loan'], \n                                                    stratify=df1['Personal Loan'], \n                                                    random_state=66, test_size =0.2)\nprint(\"Training Data: \",X_train.shape, y_train.shape)\nprint(\"Test Data: \",X_test.shape, y_test.shape)","42779653":"#Building the model\nmodel_ct = DecisionTreeClassifier(criterion='gini',random_state=1)\nmodel_ct.fit(X_train,y_train) ## training the model\n## checking the accuracy of model on training\/test data\nacc_ct=round(model_ct.score(X_test, y_test)*100,2)\nprint(\"Accuracy on training set: {:.3f}\".format(model_ct.score(X_train, y_train)))\nprint(\"Accuracy on test data: \",acc_ct)","3332ea56":"##Tuning the model\nmodel_t = DecisionTreeClassifier(random_state=1,max_depth=5)\nmodel_t.fit(X_train,y_train) ## training the model\n## checking the accuracy of model on test data\nacc_t=round(model_t.score(X_test, y_test)*100,2)\nprint(\"Accuracy on test data: \",acc_t)","5af9ef5f":"##Predicting on test data\n\npredictions_t = model_t.predict(X_test)","d5f4d26f":"#### Since the data is imbalance, we should not only rely on accuracy and check other metrics as well\nprint(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test, predictions_t))\nprint('\\n')\nprint(\"=== Classification Report ===\")\nprint(classification_report(y_test, predictions_t))\nprint('\\n')\nauc_t = round(roc_auc_score(y_test, predictions_t)*100,2)\nprint(\"AUC: \",  auc_t)\nrecall_t = round(recall_score(y_test, predictions_t)*100,2)\nprint(\"Recall: \",  recall_t)","ffbf8dd1":"##Plotting the tree\nplt.figure(figsize=(25,10))\na= plot_tree(model_t, \n             feature_names=X_train.columns,\n             filled=True, \n              rounded=True, \n              fontsize=14)","3894d7e2":"#### Building RF model with 101 tress\nrf = RandomForestClassifier(n_estimators=101, random_state=1)\nrf.fit(X_train, y_train)\n## checking the accuracy of model on training\/test data\nacc_rf=round(rf.score(X_test, y_test)*100,2)\nprint(\"Accuracy on training set: {:.3f}\".format(rf.score(X_train, y_train)))\nprint(\"Accuracy on test data: \",acc_rf)","1bdc3cde":"##Predicting on test data\npredictions_rf = rf.predict(X_test)\nauc_rf = round(roc_auc_score(y_test, predictions_rf)*100,2)\nprint(\"AUC: \",  auc_rf)\nrecall_rf = round(recall_score(y_test, predictions_rf)*100,2)\nprint(\"Recall: \",  recall_rf)","f6718653":"param_grid = {'n_estimators': [101,201,251], 'max_features': [4,5,6,7], 'max_depth':[6,7,8]}\nrf1 = GridSearchCV(RandomForestClassifier(), param_grid, cv=10, \n                   scoring=make_scorer(accuracy_score))\nrf1.fit(X_train, y_train)\nacc_rf1=round(rf1.score(X_test, y_test)*100,2)\nprint(\"Accuracy on training set: {:.3f}\".format(rf1.score(X_train, y_train)))\nprint(\"Accuracy on test data: \",acc_rf1)","0996dd76":"best=rf1.best_params_\nprint(best)","f992dbc8":"##Building the model using best estimators from the result of GridSerachCV\nrf2 = RandomForestClassifier(max_depth=8, n_estimators=101, random_state=1,max_features=6)\nrf2.fit(X_train, y_train)\nacc_rf2=round(rf2.score(X_test, y_test)*100,2)\nprint(\"Accuracy on training set: {:.3f}\".format(rf1.score(X_train, y_train)))\nprint(\"Accuracy on test data: \",acc_rf2)","1756b9ea":"##Predicting on test data\npredictions_rf2 = rf2.predict(X_test)","aa2efd69":"print(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test, predictions_rf))\nprint('\\n')\nprint(\"=== Classification Report ===\")\nprint(classification_report(y_test, predictions_rf))\nprint('\\n')\nauc_rf2 = round(roc_auc_score(y_test, predictions_rf)*100,2)\nprint(\"AUC: \",  auc_rf)\nrecall_rf2 = round(recall_score(y_test, predictions_rf)*100,2)\nprint(\"Recall: \",  recall_rf)","caaa9831":"featureImportances = pd.Series(rf2.feature_importances_).sort_values(ascending=False)\n\nsns.barplot(x=round(featureImportances,4), y=X_train.columns, color='y')\nplt.xlabel('Features Importance')\nplt.show()","284f0ba7":"print('---Comparison Of both Models---')\nprint('Cart Model Accuracy:',acc_t,',Auc:',auc_t,', Recall:',recall_t)\nprint('RF Model Accuracy:',acc_rf2,',Auc:',auc_rf2,', Recall:',recall_rf2)","0c58f2a8":"## 2. Random Forest Model","f4a54e05":"From the data we can say that the variables types are-\nNumeric: Age, Experience, Income, CCAvg, Mortgage\nCategorical: Family, Personal Loan, Securities Account, CD Account, Online, Education,Credit Card","58df3457":"* Experience and Age mean are similar for personal Loan -ve and +ve\n* Higher income, cc spent and mortgage have responded +ve to loan","e4541082":"Finding distribution of Categorical variable with respect to Personal Loan","33f1bd59":"## Summary for EDA -\nSo  to  summarize  our  basic  EDA  we  can  conclude  the  below  strategy  for  the  bank  to  select  the  target audience\n* Higher Income more loan\n* Lower mortgage has more chances for personal loan. Exception-Exclude zero Mortgage candidates\n* Age and Experience do not much effect loan preference.\n* In all Education levels, maximum population located in 20 to 100 income range\n* Low Income and Low Mortgage-Less loan- New scheme for such peoples\n* Higher  income  and  higher  mortgage  have  better  conversion  ratio-Different  marketing  for  easy pickers\n* Higher Credit spend and higher Income-more chances of conversion\n* Good income but less Credit spend(Income 50k~100K, and CCavg<2500)- Bright spot to increase the loan \n* The distribution  of  No  personal  loan  compared  to  education  reveals  that  we  have  mostly  equal distribution of no-loan takers in all the 3 education levels. Higher eductaion has responding slighly more +ves but nor very big difference.","50a3fd94":"### To tune the model we'll use GridsearchCV function to find best hyperparameter","b7f59761":"## 1. CART Model","91c81fc5":"Similar pattern we can see from this graph also, higher Income+ CC spent and higher Income+Mortgage have responded +ve to loan.","c78df3b8":"It can be inferred that the Applicant age does not affect the chances of buying the personal loan. So dropping the age_bin ","bcca3a44":"There are no missing values. lets proceed with EDA","29e159c4":"## Model Evaluation","bd32b50d":"## Model Building","e91ac4f1":"Conclusion: Age and experience are highly correlated, quite obviously. Income and CC average spent are also significantly correlated.","0cfca40f":"Personal Loan is the feature we are going to predict. 0 means gave -ve response to the campaign, 1 means took personal loan as result of the campaign. We have to check what features influence 1. In the dataset we have only 480 (~9.6%), highly imbalance dataset.","35151033":"### We can conclude from the performance metrics comparison that Decision Tree is giving better value of Recall. ","b6c223fe":"## EDA","bbbccd5f":"The tuned model is giving better accuracy on test data, so taking this as final CART model."}}