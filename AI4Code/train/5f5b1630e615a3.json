{"cell_type":{"e63a5400":"code","7d81f71b":"code","e2c10326":"code","aed830c0":"code","60ae46d1":"code","31d664d2":"code","290107fe":"code","73bb8fca":"code","05e88bb7":"code","dd58b50a":"code","608c4bf9":"code","95dd5359":"code","590d80b6":"code","f498e6d7":"code","d0cc7631":"code","302f8df7":"code","de3d2457":"code","b1d63002":"code","6c47d426":"code","a54b9fd2":"code","c0de5447":"code","bfc09294":"code","dff898b3":"code","38ffbbc4":"code","2e75558b":"markdown"},"source":{"e63a5400":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport os\nfrom scipy.interpolate import interp1d\nimport gc\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GroupKFold\n\nimport soundfile as sf\n# Librosa Libraries\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.metrics import roc_auc_score, label_ranking_average_precision_score","7d81f71b":"trainfiles = glob.glob( '..\/input\/rfcx-species-audio-detection\/train\/*.flac' )\ntestfiles = glob.glob( '..\/input\/rfcx-species-audio-detection\/test\/*.flac' )\nlen(trainfiles), len(testfiles), trainfiles[0]","e2c10326":"traint = pd.read_csv( '..\/input\/rfcx-species-audio-detection\/train_tp.csv' )\ntraint['t_dif'] = traint['t_max'] - traint['t_min']\ntraint['f_dif'] = traint['f_max'] - traint['f_min']\n\ntrainf = pd.read_csv( '..\/input\/rfcx-species-audio-detection\/train_fp.csv' )\ntrainf['t_dif'] = trainf['t_max'] - trainf['t_min']\ntrainf['f_dif'] = trainf['f_max'] - trainf['f_min']\n\ntraint.shape, trainf.shape","aed830c0":"traint.head()","60ae46d1":"trainf.head()","31d664d2":"trainf.t_min.hist(bins=100)\ntrainf.t_max.hist(bins=100, alpha=0.5)","290107fe":"trainf.f_min.hist(bins=20)\ntrainf.f_max.hist(bins=20, alpha=0.5)","73bb8fca":"trainf.t_dif.hist(bins=100)\n","05e88bb7":"trainf.f_dif.unique()","dd58b50a":"trainf.nunique()","608c4bf9":"traint.nunique()","95dd5359":"data, samplerate = sf.read(trainfiles[0]) \nprint( data.shape, samplerate )\nlibrosa.display.waveplot(y = data, sr = samplerate, color = \"#B14D\")","590d80b6":"traint.describe()","f498e6d7":"trainf.describe()","d0cc7631":"TRAIN = []\nTARGET = []\nfor i in tqdm(range(traint.shape[0])):\n\n    fn = traint.recording_id.values[i]\n    tmin = traint.t_min.values[i]\n    tmax = traint.t_max.values[i]\n    fmin = traint.f_min.values[i]\n    fmax = traint.f_max.values[i]\n    #print(tmin,tmax, fmin,fmax )\n\n    data, samplerate = sf.read( '..\/input\/rfcx-species-audio-detection\/train\/'+fn+'.flac')\n    #print( data.shape, samplerate )\n    var_time = np.arange(0,data.shape[0]) \/ samplerate\n\n    data = data[ np.where( (var_time>=tmin)&(var_time<=tmax) )[0] ]\n\n    varfft = np.abs( np.fft.fft(data)[:(len(data)\/\/2)] )\n    x = np.linspace(0, len(varfft), num=len(varfft), endpoint=True)\n    f1 = interp1d(x, varfft, kind='cubic')\n    x = np.linspace(0, len(varfft), num=1000, endpoint=True)\n    varfft = f1(x)\n    \n    TRAIN.append( varfft )\n    TARGET.append( traint.species_id.values[i] )\n    \nFT = np.stack(TRAIN)\nTARGET = np.array(TARGET)\nFT.shape, len(TARGET)","302f8df7":"np.unique(TARGET, return_counts=True)","de3d2457":"from joblib import Parallel, delayed\n\ndef extract_features( fn ):\n    data, samplerate = sf.read( '..\/input\/rfcx-species-audio-detection\/train\/'+fn+'.flac')\n\n    varfft = np.abs( np.fft.fft(data)[:(len(data)\/\/2)] )\n    x = np.linspace(0, len(varfft), num=len(varfft), endpoint=True)\n    f1 = interp1d(x, varfft, kind='cubic')\n    x = np.linspace(0, len(varfft), num=1000, endpoint=True)\n    varfft = f1(x)\n    \n    return varfft\n    \nFP = Parallel(n_jobs=4)(delayed(extract_features)(fn) for i in tqdm(trainf.recording_id.values))\nFP = np.stack(FP)\ngc.collect()\nFP.shape","b1d63002":"def extract_features( fn ):\n    data, samplerate = sf.read(fn)\n\n    varfft = np.abs( np.fft.fft(data)[:(len(data)\/\/2)] )\n    x = np.linspace(0, len(varfft), num=len(varfft), endpoint=True)\n    f1 = interp1d(x, varfft, kind='cubic')\n    x = np.linspace(0, len(varfft), num=1000, endpoint=True)\n    varfft = f1(x)\n    \n    return varfft\n    \nTEST = Parallel(n_jobs=4)(delayed(extract_features)(fn) for fn in tqdm(testfiles))\nTEST = np.stack(TEST)\ngc.collect()\nTEST.shape","6c47d426":"TRAIN = np.vstack( (FT, FP) )\nTRAIN.shape","a54b9fd2":"tt = traint[['recording_id','species_id']].copy()\ntf = trainf[['recording_id','species_id']].copy()\n\ntf['species_id'] = -1\n\nTRAIN_TAB = pd.concat( (tt, tf) )\n\nfor i in range(24):\n    TRAIN_TAB['s'+str(i)] = 0\n    TRAIN_TAB.loc[TRAIN_TAB.species_id==i,'s'+str(i)] = 1\n\nTRAIN_TAB.shape","c0de5447":"TRAIN_TAB.head()","bfc09294":"sub = pd.DataFrame({'recording_id': [f.split('\/')[-1].split('.')[0] for f in testfiles] })\ngkf = GroupKFold(5)\n\ngroups = TRAIN_TAB['recording_id'].values\nfor tgt in range(24):\n    target = TRAIN_TAB['s'+str(tgt)].values\n\n    ytrain = np.zeros(TRAIN.shape[0])\n    ytest = np.zeros(TEST.shape[0])\n    for ind_train, ind_valid in gkf.split( TRAIN, target, groups ):\n        model = LogisticRegression( C=1, max_iter=5000 )\n        model.fit( TRAIN[ind_train], target[ind_train] )\n        \n        ytrain[ind_valid] = model.predict_proba(TRAIN[ind_valid])[:,1]\n        ytest += model.predict_proba(TEST)[:,1] \/ 5.\n\n    print( 'Target AUC', tgt, roc_auc_score(target, ytrain) )\n    \n    TRAIN_TAB['y'+str(tgt)] = ytrain\n    sub['s'+str(tgt)] = ytest","dff898b3":"sub.head()","38ffbbc4":"sub.to_csv('submission.csv', index=False)","2e75558b":"# Min and Max frequencies are: 93 and 10687"}}