{"cell_type":{"c1e722c3":"code","67fed3d1":"code","2d2e3e29":"code","a513a44d":"code","7a6b7a56":"code","239cbed0":"code","cb8a5283":"code","12182e62":"code","10e53806":"code","5905ba00":"code","2c7ae3e9":"code","327c708d":"code","94b3c852":"code","900e4a29":"markdown","78e6025f":"markdown","642047f1":"markdown","e74a8742":"markdown","50548ceb":"markdown","d8ccd1a9":"markdown","155f0fb7":"markdown","bbc6ab36":"markdown","ca48b1a6":"markdown","792edeb1":"markdown","de7be8a0":"markdown","eb9e9f04":"markdown","fe4042e5":"markdown"},"source":{"c1e722c3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","67fed3d1":"import pandas as pd\nsample_submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")","2d2e3e29":"train.head()","a513a44d":"x_test = test.values\nx_train, x_val, y_train, y_val = train_test_split(\n    train.values[:,1:], train.values[:,0], test_size=0.2)","7a6b7a56":"fig, ax = plt.subplots(4, 4, figsize=(8,8))\nfor i in range(4):\n    for j in range(4):\n        ax[i, j].imshow(x_train[i*4+j*4].reshape(28,28), cmap='gray')\n        ax[i, j].set_title('label = %s' % (y_train[i*4 + j*4]))\n        ax[i, j].set_xticks([])\n        ax[i, j].set_yticks([])","239cbed0":"lr = LogisticRegression()","cb8a5283":"lr.fit(x_train, y_train)","12182e62":"from sklearn.metrics import accuracy_score\ny_val_pred = lr.predict(x_val)","10e53806":"print(\"Model accuracy is %0.3f\" % (accuracy_score(y_val, y_val_pred)))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_val, y_val_pred))","5905ba00":"print(\"Correctly predicted images:\")\nx_val_correct = x_val[y_val==y_val_pred,:]\ny_val_correct = y_val[y_val==y_val_pred]\ny_val_pred_correct = y_val_pred[y_val==y_val_pred]\n\nfig, ax = plt.subplots(4, 4, figsize=(10,10))\nfor i in range(4):\n    for j in range(4):\n        ax[i, j].imshow(x_val_correct[i*4+j*4].reshape(28,28), cmap='gray')\n        ax[i, j].set_title('Label:%s, pred:%s' % (y_val_correct[i*4+j*4], y_val_pred_correct[i*4+j*4]))\n        ax[i, j].set_xticks([])\n        ax[i, j].set_yticks([])\n","2c7ae3e9":"print(\"Incorrectly predicted images:\")\nx_val_incorrect = x_val[y_val!=y_val_pred,:]\ny_val_incorrect = y_val[y_val!=y_val_pred]\ny_val_pred_incorrect = y_val_pred[y_val!=y_val_pred]\n\nfig, ax = plt.subplots(4, 4, figsize=(10,10))\nfor i in range(4):\n    for j in range(4):\n        ax[i, j].imshow(x_val_incorrect[i*4+j*4].reshape(28,28), cmap='gray')\n        ax[i, j].set_title('Label:%s, pred:%s' % (y_val_incorrect[i*4+j*4], y_val_pred_incorrect[i*4+j*4]))\n        ax[i, j].set_xticks([])\n        ax[i, j].set_yticks([])\n","327c708d":"preds = lr.predict(x_test)","94b3c852":"sample_submission['Label'] = preds\nsample_submission.to_csv('submission.csv', index=False)","900e4a29":"# Make predictions on test dataset","78e6025f":"# Make your very first Kaggle submission","642047f1":"# Visualize some images","e74a8742":"# Create a Logistic Regression model","50548ceb":"# Make predictions on validation dataset","d8ccd1a9":"# Show correctly classified images","155f0fb7":"# Train\/validation splitting\n\nIn Machine Learning, it's extremely important to validate the trained model against a dataset that has never been \"seen\" by the model. Here we will randomly split the train dataset into two sets: one for training and one for validation using a 80:20 ratio.","bbc6ab36":"Take a look at the data.","ca48b1a6":"# Show validation results\n\nWe will be using two tools to show the validation results.\n\nA ** confusion matrix ** is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. The confusion matrix itself is relatively simple to understand, but the related terminology can be confusing.\n\n** Classification accuracy ** is defined as the correctely predicted images \/ total images.","792edeb1":"The first columns is the label of the data indicating the actual digit. Pixel0 to pixel783 are the values of the flattened 784 pixels.","de7be8a0":"# Train it","eb9e9f04":"# Load data\n\nWe are going to load the data from files into dataframes using Pandas.\n","fe4042e5":"# Show incorrectly classified images"}}