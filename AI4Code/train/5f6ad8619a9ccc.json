{"cell_type":{"d76802e8":"code","86dc6073":"code","42971370":"code","94a5505c":"code","c8a8629a":"code","07d29c3d":"markdown","e96f1c6b":"markdown"},"source":{"d76802e8":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import KBinsDiscretizer\nimport transformers\nfrom transformers import AutoModel, BertTokenizerFast\nimport random\nfrom torch.utils.tensorboard import SummaryWriter\nimport os \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# specify GPU\ndevice = torch.device(\"cuda\")\nseed = 1000\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \n    \ndef show_hist(df):\n    hist_df = df.bins.value_counts()*100\/df.shape[0]\n    hist_df = hist_df.sort_index()\n    ax = sns.barplot(list(map(str,hist_df.index)),hist_df.values) \n    ax.set_xlabel(\"bin num\")\n    ax.set_ylabel(\"size\")\n    plt.show()\n    \nseed_everything(seed=seed)\n\ntrain_data = pd.read_csv('..\/input\/commonlitreadabilityprize\/train.csv')\n## https:\/\/onlinestatbook.com\/glossary\/sturgiss_rule.html\nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'], bins=num_bins,labels=False)\nbins = train_data.bins.to_numpy()\ntarget = train_data.target.to_numpy()\n# print(train_data.bins.value_counts())\nshow_hist(train_data)\n","86dc6073":"\n# train_data['val'] = 0\n# kfold = StratifiedShuffleSplit(n_splits=1, random_state=seed, test_size=0.2)\n# for k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data, y=bins)):\n#     train_data.loc[valid_idx,'val'] = 1\n    \n#     train_df = train_data.loc[train_idx]\n#     val_df = train_data.loc[valid_idx]\n    \n# print(train_df.shape, val_df.shape)\n# # print(len(set(train_df.id) | set(val_df.id)), len(train_data))\n\n\n# ##\n# # np.vstack([train_data[train_data.val==0].bins.value_counts(), train_data[train_data.val==1].bins.value_counts()]).T\n\n# train_df.to_csv('train.csv', index=False)\n# val_df.to_csv('val.csv', index=False)\n# !ls\n\n","42971370":"# train_df.target.plot.kde(label='train')\n# val_df.target.plot.kde(label='val')\n# ax = train_data.target.plot.kde(label='all data')\n# ax.legend()\n# ax.set_title('data distribution')\n\n# show_hist(train_df)\n# show_hist(val_df)","94a5505c":"# k folds\ntrain_data['fold'] = 0\nkfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=seed)\nfor fold, (train_idx,valid_idx) in enumerate(kfold.split(X=train_data, y=bins)):\n    train_data.loc[valid_idx,'fold'] = fold\n    show_hist(train_data.loc[valid_idx])\ntrain_data.fold.value_counts()\n\ntrain_data.to_csv('kfold.csv', index=False)\n","c8a8629a":"!date '+%A %W %Y %X' > execution_time","07d29c3d":"# **Notebooks sequence;)**\n* Train-val split notebook [*CURRENT ONE*].<br>\n* Pretrain roberta-base on mlm with the competition data notebook [here](https:\/\/www.kaggle.com\/chamecall\/clrp-pretrain).<br>\n* Finetune pretrained roberta-base on readability task notebook [here](https:\/\/www.kaggle.com\/chamecall\/clrp-finetune).<br>\n* Inference model notebook [here](https:\/\/www.kaggle.com\/chamecall\/clrp-inference).<br>","e96f1c6b":"## K Folds"}}