{"cell_type":{"4edc5690":"code","cdffc581":"code","1f7ffe90":"code","9e243b84":"code","39989ebd":"code","78560757":"code","935922b2":"code","4f2b5873":"code","fc9f8731":"code","0007820c":"code","9dacb8a7":"code","7398952a":"code","05c1e31e":"code","cedc5ab9":"code","dfed66db":"code","809e3fda":"code","a232520a":"code","b9febb03":"code","f707f716":"code","135a8c18":"code","8823e7ac":"code","045d73df":"code","d9f050b0":"code","f448aee4":"code","cbe015b5":"code","5350fe03":"markdown","6e9e1a50":"markdown","2e6dbedb":"markdown","d4bd1914":"markdown","e768a8af":"markdown","7adef11c":"markdown","81f9ee2c":"markdown","63fc0f42":"markdown","f70d32db":"markdown","a4b31c8d":"markdown","7a98527d":"markdown","6817eae8":"markdown","43341828":"markdown","bdbc5397":"markdown","d86b8432":"markdown","de19e122":"markdown","d68ae12e":"markdown","88de3522":"markdown","7f096842":"markdown","f73c2fb2":"markdown","dddf6a66":"markdown","d372e9d7":"markdown"},"source":{"4edc5690":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nfrom sklearn.model_selection import train_test_split","cdffc581":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ntrain.shape","1f7ffe90":"y_train = train['label']\ntrain.drop(axis=1, labels=['label'], inplace=True)","9e243b84":"train.head()","39989ebd":"y_train.value_counts()    ## Images of 1's is maximum & Images of 5's is minimum","78560757":"train \/= 255.\ntest \/= 255.","935922b2":"test = np.array(test).astype(np.float32)\nX = np.array(train).astype(np.float32)\ndel train","4f2b5873":"X = X.reshape(-1,28,28,1)\ntest = test.reshape(-1,28,28,1)","fc9f8731":"plt.imshow(X[0][:,:,0], cmap='gray')\nprint('label = '+str(y_train[0]))","0007820c":"yOHE = keras.utils.to_categorical(y_train, num_classes=10)","9dacb8a7":"X_train, X_val, Y_train, Y_val = train_test_split(X, yOHE, test_size=0.1, random_state=2)","7398952a":"model = keras.models.Sequential()\n\nmodel.add(keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='relu', padding='Same', input_shape=(28,28,1)))\nmodel.add(keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='relu', padding='Same'))\nmodel.add(keras.layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(keras.layers.Dropout(0.5))\n\nmodel.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='Same'))\nmodel.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='Same'))\nmodel.add(keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(keras.layers.Conv2D(filters=96, kernel_size=(3,3), activation='relu', padding='Same'))\nmodel.add(keras.layers.Conv2D(filters=96, kernel_size=(3,3), activation='relu', padding='Same'))\nmodel.add(keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(keras.layers.Dropout(0.5))\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(256, activation='relu'))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.Dense(10, activation='softmax'))","05c1e31e":"#optim = keras.optimizers.RMSprop(lr=0.001,rho=0.9, epsilon=1e-08, decay=0.0)\n#optim = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0001) ---> val_acc = 99.59\noptim = keras.optimizers.Adadelta()\nlr_reducer = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=0.00001)\nmodel.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])","cedc5ab9":"datagen = keras.preprocessing.image.ImageDataGenerator(\n        featurewise_center=False,                         # set input mean to 0 over the dataset\n        samplewise_center=False,                          # set each sample mean to 0\n        featurewise_std_normalization=False,              # divide inputs by std of the dataset\n        samplewise_std_normalization=False,               # divide each input by its std\n        zca_whitening=False,                              # apply ZCA whitening\n        rotation_range=10,                                # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.15,                                # Randomly zoom image \n        width_shift_range=0.1,                            # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,                           # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,                            # randomly flip images\n        vertical_flip=False)                              # randomly flip images\n\ndatagen.fit(X_train)","dfed66db":"filepath=\"BestWeights_Adadelta.h5\"\ncheckpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\ncallbacks_list.append(lr_reducer)","809e3fda":"batch_size = 64\nhistory = model.fit_generator(  datagen.flow(X_train, Y_train, batch_size=batch_size), \n                             epochs=30, \n                             validation_data=(X_val, Y_val),\n                             steps_per_epoch=X_train.shape[0] \/\/ batch_size, \n                             callbacks=callbacks_list, \n                             verbose=1\n                          )","a232520a":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","b9febb03":"model.load_weights('BestWeights_Adadelta.h5')","f707f716":"preds = model.predict(test, batch_size=batch_size, verbose = 1)","135a8c18":"final_preds = np.argmax(preds, axis=1)","8823e7ac":"final_preds","045d73df":"plt.imshow(test[7,:,:,0], cmap='gray')\nprint(final_preds[7])","d9f050b0":"dictionary = {'Label':final_preds}","f448aee4":"pred_df = pd.DataFrame(data=dictionary, index=list(range(1,len(final_preds)+1)))","cbe015b5":"pred_df.to_csv('submission.csv')\n\"\"\"Accuracy on kaggle :- 99.66% ----> Top 10% \"\"\"","5350fe03":"## Splitting data into train data & test data","6e9e1a50":"# Training Keras network for Digit Recognition - Acc 0.996 (top 10%)","2e6dbedb":"## Separating labels from image pixels from train dataset","d4bd1914":"## Visualising our train data","e768a8af":"## Checking if label of each image is separated from its pixels","7adef11c":"## One-hot-encoding labels for training","81f9ee2c":"## You can achieve upto 99.66% of accuracy using this kernel on Kaggle - Digit Recognizer","63fc0f42":"## Predicting test data","f70d32db":"## Loading best weights saved in file while training","a4b31c8d":"## Changing data-tpe of our feature's to float32","7a98527d":"## Callbacks","6817eae8":"## Model Training","43341828":"## Getting insights from our train dataset","bdbc5397":"## Creating our model using Keras","d86b8432":"## Data Augmentation","de19e122":"## Normalization","d68ae12e":"## Setting optimizer & annealer","88de3522":"## Importing python modules","7f096842":"## Loading train & test data","f73c2fb2":"## Visualising loss & accuracy curves","dddf6a66":"## Reshaping our Images - converting them into 2D images","d372e9d7":"## Creating file for submission"}}