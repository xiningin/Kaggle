{"cell_type":{"9bf92e28":"code","da5e4efa":"code","a4bb2dbe":"code","a4ec7d16":"code","c975f4db":"code","f5f289d2":"code","2926b95d":"code","68599454":"code","6288cb6e":"code","2389b3f8":"code","425ef7d8":"code","59e36f86":"code","5fce254e":"code","dce2ada0":"code","82289bfc":"code","a0fb91da":"code","d7685a2f":"code","048539a7":"code","e243f242":"code","b81b3a46":"code","9130184d":"code","6e00d8c6":"code","eb0106a4":"markdown","ed5defae":"markdown"},"source":{"9bf92e28":"def warn(*args, **kwargs):\n    pass\n\nimport warnings\nwarnings.warn = warn\nfrom kaggle.competitions import twosigmanews\nimport json\nimport re\nimport time\nimport datetime\nimport multiprocessing\nfrom datetime import date, timedelta\nfrom dateutil.relativedelta import relativedelta\nfrom sklearn.linear_model import LogisticRegression\nimport pandas as pd\nimport numpy as np\n\nmaster_s_time = time.time()\nenv = twosigmanews.make_env()","da5e4efa":"MY_LOG = open('my_log.txt', 'w+')\nMY_LOG.write('start_time: {0}'.format(datetime.datetime.now()))\nmarket_train_df, news_train_df = env.get_training_data()\nfeatures = ['day', 'totalNumArticles','numAssetArticles',\n            'portionOfAssetArticles','relevance','negSentiment',\n            'neutralSentiment', 'posSentiment', 'noveltyCount24H',\n            'volumeCount24H']\ninput_features = list(set(features + ['open', 'close', 'returnsOpenPrevMktres1']) - {'day'})","a4bb2dbe":"MY_MAX_TIME = pd.Timestamp('2007-06-01 22:00:00+0000', tz='UTC')\nmarket_train_df = market_train_df.loc[market_train_df['time'] < MY_MAX_TIME].copy()\nnews_train_df = news_train_df.loc[news_train_df['time'] < MY_MAX_TIME].copy()","a4ec7d16":"def output(s): \n    print(s)\n    MY_LOG.write(s)","c975f4db":"def get_next_trading_date(df, current_date, date_col='time'):\n    return df.loc[df[date_col] > current_date, date_col].min()\n\ndef get_prev_trading_date(df, current_date, date_col='time'):\n    return df.loc[df[date_col] < current_date, date_col].max()","f5f289d2":"def add_day_feature_to_market_data(market_df, asset_codes): \n    market_df['day'] = np.NaN\n    market_df.sort_values('time')\n    for i, asset_code in enumerate(asset_codes):\n        market_df.loc[market_df['assetCode'] == asset_code, 'day'] = list(range(1, len(market_df.loc[market_df['assetCode'] == asset_code]) + 1))\n        ","2926b95d":"def add_curr_day_news_features(market_df, news_df, asset_name, ind):\n    market_df.loc[ind, 'totalNumArticles'] = len(news_df)\n    news_df = news_df.loc[news_df['assetName'] == asset_name].copy()\n    market_df.loc[ind, 'numAssetArticles'] = len(news_df)\n    if market_df.loc[ind, 'numAssetArticles'] == 0: \n        market_df.loc[ind, ['portionOfAssetArticles',\n                            'relevance',\n                            'negSentiment',\n                            'neutralSentiment', \n                            'posSentiment', \n                            'noveltyCount24H', \n                            'volumeCount24H']] = 0\n    else: \n        market_df.loc[ind, 'portionOfAssetArticles'] = market_df.loc[ind, 'numAssetArticles'] \/ market_df.loc[ind, 'totalNumArticles']\n        market_df.loc[ind, 'relevance'] = news_df['relevance'].sum() \/ market_df.loc[ind,'numAssetArticles']\n        market_df.loc[ind, 'negSentiment'] = news_df['sentimentNegative'].sum() \/ market_df.loc[ind,'numAssetArticles']\n        market_df.loc[ind, 'neutralSentiment'] = news_df['sentimentNeutral'].sum() \/ market_df.loc[ind,'numAssetArticles']\n        market_df.loc[ind, 'posSentiment'] = news_df['sentimentPositive'].sum() \/ market_df.loc[ind, 'numAssetArticles']\n        market_df.loc[ind, 'noveltyCount24H'] = news_df['noveltyCount24H'].sum() \/ market_df.loc[ind,'numAssetArticles']\n        market_df.loc[ind, 'volumeCount24H'] = news_df['volumeCounts24H'].sum() \/ market_df.loc[ind,'numAssetArticles']\n                  \ndef add_news_features(market_df, news_df, asset_codes): \n    s_time = time.time()\n    name = multiprocessing.current_process().name\n    for i, asset_code in enumerate(asset_codes): \n        if i % 100 == 0: \n            e_time = timedelta(seconds=(time.time() - s_time))\n            name = multiprocessing.current_process().name\n            print('On assetCode: {0}\/{1} | Thread {2}'.format(i,len(asset_codes), name))\n        tmp_market_df = market_df.loc[market_df['assetCode'] == asset_code].copy()\n        tmp_market_df.sort_values(by=['day'], inplace=True)\n        prev_date = news_df['time'].min()\n        curr_date = None\n        counter = 0\n        for ind, row in tmp_market_df.iterrows():\n            if row['day'] == 1: \n                prev_date = row['time']\n                continue\n            else: \n                curr_date = row['time']\n                tmp_news_df = news_df.loc[(news_df['time'] > prev_date) &\n                                          (news_df['time'] < curr_date)].copy()\n                # Assigns values to market_df by ref\n                add_curr_day_news_features(market_df, tmp_news_df, row['assetName'], ind)\n                prev_date = curr_date","68599454":"def worker(from_date, to_date, min_date, l): \n    multiprocessing.current_process().name += ' |' + str(from_date) + ' - ' + str(to_date) \n    name = multiprocessing.current_process().name\n    print('indexing...')\n    s_time = time.time()\n    tmp_market_df = market_train_df.loc[(market_train_df['time'] >= from_date) &\n                                        (market_train_df['time'] < to_date)].copy()\n    if from_date > min_date:\n        from_date = get_prev_trading_date(market_train_df, from_date)\n    tmp_news_df = news_train_df.loc[(news_train_df['time'] >= from_date) &\n                                    (news_train_df['time'] < to_date)].copy()\n    asset_codes = tmp_market_df['assetCode'].unique().tolist()\n    asset_names = tmp_news_df['assetName'].unique().tolist()\n    e_time = time.time() - s_time\n    print('Took: {0} | thread {1}'.format(str(timedelta(seconds=e_time)), name))\n    print('add_news_feature_to_market_data...')\n    s_time = time.time()\n    add_news_features(tmp_market_df, tmp_news_df, asset_codes)\n    e_time = time.time() - s_time\n    print('Took: {0} | thread {1}'.format(str(timedelta(seconds=e_time)), name))\n    l.append(tmp_market_df)\n    print('appended to list')\n\ndef callback(tmp_market_df): \n    print('callback fn...')\n    name = multiprocessing.current_process().name\n    s_time = time.time()\n    inds = tmp_market_df.index\n    market_train_df.loc[inds, features] = tmp_market_df.loc[inds, features]\n    e_time = time.time() - s_time\n    print('Took: {0} | thread {1}'.format(str(timedelta(seconds=e_time)), name))\n    \ndef add_features_cols(): \n    for feature in features: \n        market_train_df[feature] = np.NaN\n    news_train_df['day'] = np.NaN\n\ndef add_features_to_training_data(): \n    MONTHS_RANGE = 1\n    NUM_PROCESSES = 4\n    with multiprocessing.Manager() as manager:\n        min_date = market_train_df['time'].min()\n        prev_date = min_date\n        curr_date = prev_date + relativedelta(months=MONTHS_RANGE)\n        max_date = market_train_df['time'].max()\n        p = multiprocessing.Pool(processes=NUM_PROCESSES)\n        l = manager.list()\n        process_counter = 1\n        while prev_date < max_date: \n            p.apply_async(worker, args=(prev_date, curr_date, min_date, l))\n            prev_date = curr_date\n            curr_date += relativedelta(months=MONTHS_RANGE)\n            process_counter += 1\n        p.close()\n        p.join()\n        \n        for tmp_market_df in l: \n            callback(tmp_market_df)","6288cb6e":"def add_large_return_features(market_train_df,\n                              num_std=1, target='returnsOpenNextMktres10'):\n    market_train_df['large_pos_target'] = 0\n    market_train_df['large_neg_target'] = 0\n    mean = market_train_df[target].mean()\n    std = market_train_df[target].std()\n    market_train_df.loc[market_train_df[target] > mean + std * num_std, 'large_pos_target'] = 1\n    market_train_df.loc[market_train_df[target] < mean - std * num_std, 'large_neg_target'] = 1","2389b3f8":"def add_pos_neg_return_features(market_train_df, target='returnsOpenNextMktres10'):\n    market_train_df['pos_target'] = 0\n    market_train_df['neg_target'] = 0\n    market_train_df.loc[market_train_df[target] > 0, 'pos_target'] = 1\n    market_train_df.loc[market_train_df[target] < 0, 'neg_target'] = 1","425ef7d8":"def train_models(enhanced_market_df, asset_codes):\n    models = dict.fromkeys(asset_codes)\n    for i, asset_code in enumerate(asset_codes):\n        if i % 100 == 0: \n            print(\"Training assetCode: {0}\/{1}\".format(i, len(asset_codes)))\n        X = market_train_df.loc[market_train_df['assetCode'] == asset_code, input_features]\n        y_pos = market_train_df.loc[market_train_df['assetCode'] == asset_code, 'pos_target']\n        y_neg = market_train_df.loc[market_train_df['assetCode'] == asset_code, 'neg_target']\n        if len(y_pos.unique()) < 2: \n            print('{0} has less than 2 y_pos classes '.format(asset_code))\n            continue\n        if len(y_neg.unique()) < 2: \n            print('{0} has less than 2 y_neg classe'.format(asset_code))\n            continue\n        pos_return_classifier = LogisticRegression(random_state=0, solver='lbfgs',\n                                                   multi_class='multinomial', n_jobs=-1).fit(X, y_pos)\n        neg_return_classifier = LogisticRegression(random_state=0, solver='lbfgs',\n                                                   multi_class='multinomial', n_jobs=-1).fit(X, y_neg)\n        models[asset_code] = {\n            'pos_return_classifier': pos_return_classifier,\n            'neg_return_classifier': neg_return_classifier\n        }\n    return models","59e36f86":"def fill_market_df(market_df, asset_codes):\n    for asset_code in asset_codes: \n        market_train_df.loc[market_train_df['assetCode'] == asset_code,\n                            'returnsOpenPrevMktres1'] = market_train_df.loc[market_train_df['assetCode'] == asset_code,\n                                                                            'returnsOpenPrevMktres1'].interpolate(method='linear')\n    market_train_df.dropna(subset=input_features, inplace=True)\n    return market_train_df","5fce254e":"def fill_and_train_worker(asset_codes, l):\n    market_df = market_train_df.loc[market_train_df['assetCode'].isin(asset_codes)].copy()\n    filled_market_df = fill_market_df(market_df, asset_codes)\n    models = train_models(filled_market_df, asset_codes)\n    l.append(models)\n    \ndef fill_and_train_models(market_train_df, asset_codes): \n    div_asset_code = round(len(asset_codes) \/ 4)\n    NUM_PROCESSES = 4\n    models = {}\n    with multiprocessing.Manager() as manager: \n        p = multiprocessing.Pool(processes=NUM_PROCESSES)\n        l = manager.list()\n        for i in range(NUM_PROCESSES):\n            if i == (NUM_PROCESSES - 1): \n                portion_asset_codes = asset_codes[(i * div_asset_code):]\n            else: \n                portion_asset_codes = asset_codes[(i * div_asset_code): ((i+1) * div_asset_code)]\n            p.apply_async(fill_and_train_worker, args=(portion_asset_codes, l))\n        p.close()\n        p.join()\n        models = {**l[0], **l[1], **l[2], **l[3]}\n        \n    return models","dce2ada0":"def train_my_model(market_train_df, news_train_df):\n    asset_codes = market_train_df['assetCode'].unique().tolist()\n    asset_names = market_train_df['assetName'].unique().tolist()\n    add_features_cols()\n    \n    output('add_day_feature_to_market_data... |  start_time: {0}'.format(datetime.datetime.now()))\n    s_time = time.time()\n    add_day_feature_to_market_data(market_train_df, asset_codes)\n    e_time = time.time() - s_time\n    output('Took: {0} to add_day_feature_to_market_data'.format(str(timedelta(seconds=e_time))))\n    \n    output('add_features_to_market_data... | start_time: {0}'.format(datetime.datetime.now()))\n    s_time = time.time()\n    add_features_to_training_data()\n    e_time = time.time() - s_time\n    output('Finished adding features to training data. Took: {0}'.format(str(timedelta(seconds=e_time))))\n    output('End time: {0}'.format(datetime.datetime.now()))\n    output('add_large_return_features... |  start_time: {0}'.format(datetime.datetime.now()))\n    s_time = time.time()\n    add_large_return_features(market_train_df, num_std=1)\n    e_time = time.time() - s_time\n    output('Took: {0} to add large return features'.format(str(timedelta(seconds=e_time))))\n    output('add_pos_neg_return_features... |  start_time: {0}'.format(datetime.datetime.now()))\n    s_time = time.time()\n    add_pos_neg_return_features(market_train_df)\n    e_time = time.time() - s_time\n    output('Took: {0} to add pos_neg_return features'.format(str(timedelta(seconds=e_time))))\n    output('fill_market_df & Train... |  start_time: {0}'.format(datetime.datetime.now()))\n    s_time = time.time()\n    models = fill_and_train_models(market_train_df, asset_codes)\n    #filled_market_df = fill_market_df(market_train_df, asset_codes) # parralelize\n    #e_time = time.time() - s_time\n    #print('Took: {0}'.format(str(timedelta(seconds=e_time))))\n    #print('Train Models...')\n    #s_time = time.time()\n    #models = train_models(filled_market_df, asset_codes) # parralelize\n    e_time = time.time() - s_time\n    output('Took: {0} to train models'.format(str(timedelta(seconds=e_time))))\n    output('done! train_my_model()')\n    return models","82289bfc":"models = train_my_model(market_train_df, news_train_df)","a0fb91da":"class tmp_classifier():\n    def predict_proba(X): \n        return [[0, 0]]","d7685a2f":"for asset_code, classifiers in models.items(): \n    if classifiers is None: \n        models[asset_code] = {\n            'pos_return_classifier': tmp_classifier, \n            'neg_return_classifier': tmp_classifier\n        }","048539a7":"def make_my_predictions(market_obs_df, news_obs_df, predictions_template_df): \n    global market_train_df\n    output('On date {0} |  current_time: {1}'.format(market_obs_df['time'].iloc[0], datetime.datetime.now()))\n    output('{0} | {1} | {2}'.format(len(predictions_template_df), len(market_obs_df), len(news_obs_df)))\n    for feature in features: \n        market_obs_df[feature] = np.NaN\n    for ind, row in market_obs_df.iterrows():\n        #market_obs_df.loc[ind, 'day'] = market_train_df.loc[market_train_df['assetCode'] == row['assetCode'],\n        #                                                    'day'].max() + 1\n        add_curr_day_news_features(market_obs_df, news_obs_df, row['assetName'], ind)\n        market_obs_df.loc[ind, 'returnsOpenPrevMktres1'] = market_obs_df.loc[ind, 'returnsOpenPrevMktres1'] if not np.isnan(market_obs_df.loc[ind, 'returnsOpenPrevMktres1']) else 0\n        X = market_obs_df.loc[[ind], input_features]\n        pred_ind = predictions_template_df.loc[predictions_template_df['assetCode'] == row['assetCode']].index\n        if row['assetCode'] in models: \n            predictions_template_df.loc[pred_ind, 'confidenceValue'] = models[row['assetCode']]['pos_return_classifier'].predict_proba(X)[0][0]\n        else: \n            predictions_template_df.loc[pred_ind, 'confidenceValue'] = 0\n    return predictions_template_df\n    # when I'm ready to add Moving avgs    \n    # market_obs_missing_cols = ['neg_target', 'large_neg_target', 'larget_pos_target', 'pos_target',\n    #                           'returnsOpenNextMktres10', 'universe']\n    # for missing_col in market_obs_missing_cols: \n    #     market_obs_df[missing_col] = np.NaN\n    # market_train_df = pd.concat([market_train_df, market_obs_df])\n    \n    # change to ffill with prev day data\n    # market_obs_df['returnsOpenPrevMktres1'] = market_obs_df['returnsOpenPrevMktres1'].fillna(0)\n    # for ind, row in predictions_template_df.iterrows(): \n    #    X = market_obs_df.loc[market_obs_df['assetCode'] == row['assetCode'], input_features]\n    #    if row['assetCode'] in models: \n    #        predictions_template_df.loc[ind, 'confidenceValue'] = models[row['assetCode']]['pos_return_classifier'].predict_proba(X)[0][0]\n    #    else: \n    #        predictions_template_df.loc[ind, 'confidenceValue'] = 0\n    # return predictions_template_df\n    ","e243f242":"days = env.get_prediction_days()\n#market_obs_df, news_obs_df, predictions_template_df = next(days)","b81b3a46":"#predictions_df = make_my_predictions(market_obs_df, news_obs_df, predictions_template_df)\n#predictions_df\n#env.predict(predictions_df)","9130184d":"for (market_obs_df, news_obs_df, predictions_template_df) in days:\n    predictions_df = make_my_predictions(market_obs_df, news_obs_df, predictions_template_df)\n    env.predict(predictions_df)\n    \nenv.write_submission_file()","6e00d8c6":"e_time = time.time() - master_s_time\nprint('Total time: {0}'.format(e_time))\nMY_LOG.close()","eb0106a4":"```\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n\n(market_train_df, news_train_df) = env.get_training_data()\ntrain_my_model(market_train_df, news_train_df)\n\nfor (market_obs_df, news_obs_df, predictions_template_df) in env.get_prediction_days():\n  predictions_df = make_my_predictions(market_obs_df, news_obs_df, predictions_template_df)\n  env.predict(predictions_df)\n  \nenv.write_submission_file()\n```\nNote that `train_my_model` and `make_my_predictions` are functions you need to write for the above example to work.","ed5defae":"\n* `day` column is used when calculating 10-day prev market return"}}