{"cell_type":{"7e036cb7":"code","e8634af7":"code","392b60a3":"code","db8e79ef":"code","73629306":"code","722ee541":"code","dfcf3a54":"code","9a992654":"code","4419b7db":"code","a44d8e08":"code","096ed0eb":"code","4d2dba55":"code","252b04f4":"code","45956f17":"code","5876061b":"code","f3c39531":"code","8ea1a6dc":"code","d121e2c9":"code","ff14d18a":"code","45dc09df":"code","5b024ecd":"markdown","07c6ba68":"markdown","f67908d8":"markdown","b4dd6165":"markdown","588b9b10":"markdown","2c5d70ec":"markdown","861c81c8":"markdown","09d35ad2":"markdown","7425ddc2":"markdown","cddb226a":"markdown","9ad0e80c":"markdown","7dcbd8fb":"markdown","8325a3c0":"markdown","32a97c9e":"markdown","9eca74ab":"markdown","e0a92a76":"markdown","e61cebf7":"markdown","4d2a5620":"markdown"},"source":{"7e036cb7":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, AveragePooling2D, Dense, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","e8634af7":"# Set parameters\nIMAGE_SIZE = (512, 512)","392b60a3":"train_files = []\nmask_files = glob('..\/input\/lgg-mri-segmentation\/kaggle_3m\/*\/*_mask*')\n\nfor i in mask_files:\n    train_files.append(i.replace('_mask', ''))","db8e79ef":"df = pd.DataFrame({\"image_path\": train_files, \"mask_path\":mask_files})\n\ndef diagnosis(mask_path):\n    value = np.max(cv2.imread(mask_path))\n    if value:\n        return 1\n    else:\n        return 0\n\ndf['mask'] = df[\"mask_path\"].apply(lambda x: diagnosis(x))","73629306":"df.head()","722ee541":"df['mask'].value_counts()","dfcf3a54":"fig, ax = plt.subplots(10,3,figsize=(20,45))\nfor x in range(10):\n    i = random.randint(0, len(df))\n    img = cv2.imread(df['image_path'][i])\n    mask = cv2.imread(df['mask_path'][i])\n    ax[x][0].title.set_text(\"Brain MRI\")\n    ax[x][0].imshow(img)\n    ax[x][1].title.set_text(\"Mask - \" + str(df['mask'][i]))\n    ax[x][1].imshow(mask)\n    ax[x][2].title.set_text(\"Brain MRI with Mask\")\n    ax[x][2].imshow(img)\n    ax[x][2].imshow(mask, alpha=0.4)\nplt.tight_layout()","9a992654":"df['mask'] = df['mask'].apply(lambda x: str(x))\ndf.info()","4419b7db":"from sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df, test_size=0.15)\ndf_train, df_val = train_test_split(df_train, test_size=0.15)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","a44d8e08":"def train_generator(data_frame, batch_size, aug_dict,\n        image_color_mode=\"rgb\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(512,512),\n        seed=1):\n\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"image_path\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask_path\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img \/ 255.\n    mask = mask \/ 255.\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","096ed0eb":"smooth=100\n\ndef dice_coef(y_true, y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n    And=K.sum(y_truef* y_predf)\n    return((2* And + smooth) \/ (K.sum(y_truef) + K.sum(y_predf) + smooth))\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac\n\ndef jac_distance(y_true, y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n\n    return - iou(y_true, y_pred)","4d2dba55":"def unet(input_size=(512,512,3)):\n    inputs = Input(input_size)\n    \n    \n    conv0 = Conv2D(32, (3, 3), padding='same')(inputs)\n    bn0 = Activation('relu')(conv0)\n    conv0 = Conv2D(32, (3, 3), padding='same')(bn0)\n    bn0 = BatchNormalization(axis=3)(conv0)\n    bn0 = Activation('relu')(bn0)\n    pool0 = MaxPooling2D(pool_size=(2, 2))(bn0)\n    \n    conv1 = Conv2D(64, (3, 3), padding='same')(pool0)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(512, (3, 3), padding='same')(pool3)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)\n    bn5 = Activation('relu')(conv5)\n    conv5 = Conv2D(1024, (3, 3), padding='same')(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation('relu')(bn5)\n\n    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)\n    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(512, (3, 3), padding='same')(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n\n    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)\n    conv7 = Conv2D(256, (3, 3), padding='same')(up7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n\n    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)\n    conv8 = Conv2D(128, (3, 3), padding='same')(up8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n\n    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)\n    conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n    \n    up10 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(bn9), conv0], axis=3)\n    conv10 = Conv2D(32, (3, 3), padding='same')(up10)\n    bn10 = Activation('relu')(conv10)\n    conv10 = Conv2D(32, (3, 3), padding='same')(bn10)\n    bn10 = BatchNormalization(axis=3)(conv10)\n    bn10 = Activation('relu')(bn10)\n\n    conv11 = Conv2D(1, (1, 1), activation='sigmoid')(bn10)\n\n    return Model(inputs=[inputs], outputs=[conv11])","252b04f4":"# Set parameters\nEPOCHS = 80\nBATCH_SIZE = 16\nlearning_rate = 1e-4","45956f17":"train_generator_args = dict(rotation_range=0.2,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\ntrain_gen = train_generator(df_train, BATCH_SIZE,\n                                train_generator_args,\n                                target_size=IMAGE_SIZE)\n    \ntest_gener = train_generator(df_val, BATCH_SIZE,\n                                dict(),\n                                target_size=IMAGE_SIZE)\n    \nmodel = unet(input_size=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n\n\n\ndecay_rate = learning_rate \/ EPOCHS\nopt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\nmodel.compile(optimizer=opt, loss=dice_coef_loss, metrics=[\"binary_accuracy\", iou, dice_coef])\n\ncallbacks = [ModelCheckpoint('a_seg.hdf5', verbose=1, save_best_only=True)]\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(df_train) \/ BATCH_SIZE, \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                    validation_data = test_gener,\n                    validation_steps=len(df_val) \/ BATCH_SIZE)","5876061b":"traindice = history.history['dice_coef'] \ntestdice = history.history['val_dice_coef']\ntrainjaccard = history.history['iou'] \ntestjaccard = history.history['val_iou']\n\ntrainloss = history.history['loss']\ntestloss = history.history['val_loss']\nplt.figure(1)\nplt.plot(testloss, 'b-')\nplt.plot(trainloss,'r-')\nplt.xlabel('iteration')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize = 15)\nplt.figure(2)\nplt.plot(traindice, 'r-')\nplt.plot(testdice, 'b-')\nplt.xlabel('iteration')\nplt.ylabel('accuracy')\nplt.title('accuracy graph', fontsize = 15)\nplt.show()","f3c39531":"#saving model to drive\nmodel.save(\"kaggle_model.h5\")","8ea1a6dc":"model.save(\"kaggle_model2.hdf5\")","d121e2c9":"test_gen = train_generator(df_test, BATCH_SIZE,\n                                dict(),\n                                target_size=IMAGE_SIZE)\nresults = model.evaluate(test_gen, steps=len(df_test) \/ BATCH_SIZE)\nprint(\"Test lost: \",results[0])\nprint(\"Test IOU: \",results[1])\nprint(\"Test Dice Coefficent: \",results[2])","ff14d18a":"for i in range(30):\n    index=np.random.randint(1,len(df_test.index))\n    img = cv2.imread(df_test['image_path'].iloc[index])\n    img = cv2.resize(img ,IMAGE_SIZE)\n    img = img \/ 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask_path'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","45dc09df":"import os \nos.chdir(r'\/kaggle\/working')\n%cd \/kaggle\/working\n\n","5b024ecd":"### Loading Image path and Mask path","07c6ba68":"### Evaluate the model","f67908d8":"* Mask = 0 -> no tumor\n* Mask = 1 -> tumor","b4dd6165":"### Split data into Train, Validation and Test Set","588b9b10":"### Create Data Frame","2c5d70ec":"### Data Generator, Data Augmentation and Adjust Data","861c81c8":"Visualize some random images with their tumor (if exist)","09d35ad2":"### Visualize MRI with Mask","7425ddc2":"### This notebook includes 2 tasks: a Classifier to detect if tumor exist or not, and a Segmentation model to localize tumor\n\nIf you find this work useful, please upvote for me :))","cddb226a":"### If you find this work useful, please don't forget upvoting","9ad0e80c":"### Define UNet Model","7dcbd8fb":"### Import necessary libraries","8325a3c0":"* Using UNet Model for Brain MRI Segmentation","32a97c9e":"### Visualize the Result","9eca74ab":"### Training","e0a92a76":"### Define Loss function and Metrics","e61cebf7":"## Model 2: Segementaion Model to localize tumor","4d2a5620":"### Visualize the model performance"}}