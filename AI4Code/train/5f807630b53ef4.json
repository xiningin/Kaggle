{"cell_type":{"b6b08758":"code","88535e70":"code","db5da4f6":"code","b0524d94":"code","645c5303":"code","6d80519e":"code","431da88d":"code","25065e02":"code","e066dd7d":"code","8c688ff0":"code","ee43170b":"code","9764e768":"code","be9dc989":"code","ffef8612":"code","e6f70213":"markdown","83c87658":"markdown","1772b6fa":"markdown","73ed4329":"markdown","9212984a":"markdown","2b466882":"markdown","46f5ebae":"markdown","e5ec1cfc":"markdown","d1e99791":"markdown"},"source":{"b6b08758":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.datasets import reuters\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","88535e70":"(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000) \n# num_words = 10000 parametresi verilen en s\u0131k kar\u015f\u0131la\u015f\u0131lan 10000 kelime ile s\u0131n\u0131rl\u0131 olmas\u0131n\u0131 sa\u011flar.","db5da4f6":"len(train_data)","b0524d94":"len(test_data)","645c5303":"def vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1\n    return results\n\n# e\u011fitim verisinin vekt\u00f6re d\u00f6n\u00fc\u015ft\u00fcr\u00fclmesi \nX_train = vectorize_sequences(train_data)\n\n# Test verisinin vekt\u00f6re d\u00f6n\u00fc\u015ft\u00fcr\u00fclmesi\nX_test = vectorize_sequences(test_data)","6d80519e":"# E\u011fitim etiketlerinin vekt\u00f6re d\u00f6n\u00fc\u015ft\u00fcr\u00fclmesi\none_hot_train_labels = to_categorical(train_labels)\none_hot_test_labels = to_categorical(test_labels)","431da88d":"# Model Tan\u0131m\u0131\nmodel = Sequential()\nmodel.add(Dense(64, activation='relu', input_shape=(10000,)))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(46, activation='softmax'))","25065e02":"# Modeli derlemek \nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","e066dd7d":"# Do\u011frulama veri seti olu\u015fturma \nX_val = X_train[:1000]\npartial_X_train = X_train[1000:]\n\ny_val = one_hot_train_labels[:1000]\npartial_y_train = one_hot_train_labels[1000:]","8c688ff0":"# Model E\u011fitmek\nhistory = model.fit(partial_X_train, \n                    partial_y_train,\n                    epochs=20, \n                    batch_size=512,\n                    validation_data=(X_val, y_val))","ee43170b":"# E\u011fitim ve Do\u011frulama kay\u0131plar\u0131n\u0131 \u00e7izdirmek\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'bo', label='E\u011fitim Kayb\u0131')\nplt.plot(epochs, val_loss, 'b', label='Do\u011frulama Kayb\u0131')\nplt.title('E\u011fitim ve Do\u011frulama Kayb\u0131')\nplt.xlabel('Epoklar')\nplt.ylabel('Kay\u0131p')\nplt.legend()\n\nplt.show()\n\nplt.clf()\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epok')\nplt.ylabel('Ba\u015far\u0131m')\nplt.legend()\nplt.show()","9764e768":"# Modeli en ba\u015ftan e\u011fitmek\nmodel = Sequential()\nmodel.add(Dense(64, activation='relu', input_shape=(10000,)))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(46, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(partial_X_train, \n          partial_y_train, \n          epochs=9,\n          batch_size=512,\n          validation_data=(X_val, y_val))\n\nresults = model.evaluate(X_test, one_hot_test_labels)","be9dc989":"results","ffef8612":"predictions = model.predict(X_test)","e6f70213":"# Yakla\u015f\u0131m\u0131 Do\u011frulamak\nDo\u011frulama veri seti olarak kullanmak \u00fczere 1000 \u00f6rne\u011fi ay\u0131ral\u0131m.","83c87658":"# A\u011f\u0131 in\u015fa etmek\n\nDaha \u00f6nce kulland\u0131\u011f\u0131m\u0131z \u00fcst \u00fcste Dense katmanlar\u0131nda her katman kendisinden \u00f6ncesi katman\u0131n \u00e7\u0131kt\u0131lar\u0131ndaki bilgiye ula\u015fabiliyor. E\u011fer bir katman gerekli bilgiyi \u00f6\u011frenemezse sonraki katmanlar\u0131n bunu telafi etme \u015fans\u0131 yok ve katmanlar\u0131n bir darbo\u011faz haline gelme ihtimali bulunmaktad\u0131r. \u00d6nceki \u00f6rnekte(IMDB) 16 boyutlu katmanlar kullanm\u0131\u015ft\u0131m. 16 boyutlu katmanlar 46 farkl\u0131 s\u0131n\u0131f\u0131 \u00f6\u011frenmek i\u00e7in \u00e7ok yetersiz kalacakt\u0131r. B\u00f6yle k\u00fc\u00e7\u00fck katmanlar ileriye gerekli bilgiyi ta\u015f\u0131yamad\u0131klar\u0131 i\u00e7in darbo\u011faz olu\u015fturacaklard\u0131r. ","1772b6fa":"\u015eimdi a\u011f\u0131m\u0131z\u0131 20 epok e\u011fitelim.","73ed4329":"A\u011f 9.epoktan sonra a\u015f\u0131r\u0131 uydurmaya ba\u015flad\u0131. \u015eimdi a\u011f\u0131 en ba\u015ftan 9 epok e\u011fitip test veri seti \u00fczerinde de\u011ferlendirelim.","9212984a":"* A\u011f\u0131n\u0131z\u0131n sonunda katman\u0131 46 boyutlu bir Dense katman kulland\u0131n\u0131z. Bu her girdi \u00f6rne\u011fi i\u00e7in 46 boyutlu bir vekt\u00f6r \u00e7\u0131kt\u0131s\u0131 \u00fcretilece\u011fi anlam\u0131na geliyor. Bu vekt\u00f6r\u00fcn her bir girdisi farkl\u0131 bir s\u0131n\u0131fa ait \u00e7\u0131kt\u0131y\u0131 kodlamaktad\u0131r.\n\n* Son katman aktivasyon fonksiyonu olarak 'softmax' kullanmaktad\u0131r. Bunu MNIST \u00f6rne\u011finde de g\u00f6rm\u00fc\u015ft\u00fcn\u00fcz. Bu da a\u011f\u0131n \u00e7\u0131kt\u0131s\u0131n\u0131n 46 farkl\u0131 s\u0131n\u0131fa ait olas\u0131l\u0131k da\u011f\u0131l\u0131m\u0131 olaca\u011f\u0131 anlam\u0131na gelmektedir: Her girdi i\u00e7in 46 boyutlu bir vekt\u00f6r \u00e7\u0131kacak ve output[i] i'inci s\u0131n\u0131fa ait olma olas\u0131l\u0131\u011f\u0131n\u0131 g\u00f6sterecektir. Bu 46 de\u011ferin toplam\u0131 1 olacakt\u0131r. \n\nBu durumda 'categorical_crossentropy' kullan\u0131labilecek en iyi kay\u0131p fonksiyonu olacakt\u0131r. 'categorical_crossentropy' iki olas\u0131l\u0131k da\u011f\u0131l\u0131m\u0131 aras\u0131ndaki mesafeyi \u00f6l\u00e7er: Burada birinci olas\u0131l\u0131k da\u011f\u0131l\u0131m\u0131 a\u011f\u0131n \u00e7\u0131kt\u0131s\u0131 di\u011feri ise etiketlerin do\u011fru da\u011f\u0131l\u0131m\u0131d\u0131r. Bu mesafeyi en aza indirerek a\u011f\u0131, m\u00fcmk\u00fcn oldu\u011funca do\u011fru etiketleri \u00f6\u011frenmesi i\u00e7in e\u011fiteceksiniz.","2b466882":"# Verileri Haz\u0131rlamak","46f5ebae":"Son olarak kay\u0131p ve ba\u015far\u0131m e\u011frilerini \u00e7izdirelim","e5ec1cfc":"# Giri\u015f\nBu notebook Fran\u00e7ois Chollet'in Python ile Derin \u00d6\u011frenme Kitab\u0131ndan notlar\u0131m\u0131 i\u00e7ermektedir.\n\n\nBu b\u00f6l\u00fcmde, Reuters haberlerini 46 farkl\u0131 s\u0131n\u0131ftan birine s\u0131n\u0131fland\u0131ran a\u011f\u0131 in\u015fa edeceksiniz.","d1e99791":"# Yeni Verilerde Tahmin Olu\u015fturma"}}