{"cell_type":{"8a99aa34":"code","23e4b01b":"code","d23ba711":"code","ba1ef982":"code","ce9582fc":"code","9e1d4b59":"code","1d653dc6":"code","5f9c91c2":"code","4813b094":"code","fcebb04c":"code","bb917daf":"code","ddcb4198":"code","9b5e8683":"code","a4c55637":"code","de1eea49":"code","d35d0754":"code","8a5f490f":"code","e665d81e":"code","2050725a":"code","4787d980":"code","4082beee":"markdown","7ae624d2":"markdown","c221e96e":"markdown","7b26bd91":"markdown","59870601":"markdown","c047ca95":"markdown","21956978":"markdown","567b7777":"markdown","c1254355":"markdown","a9fb3f21":"markdown","900786ae":"markdown","d68962cd":"markdown","870d6c2d":"markdown","a7d220be":"markdown","14111f62":"markdown","48198cad":"markdown","bc7e35f2":"markdown","614b12ab":"markdown"},"source":{"8a99aa34":"!nvidia-smi","23e4b01b":"!wget -O casia_webface.zip https:\/\/www.dropbox.com\/s\/wpx6tqjf0y5mf6r\/faces_ms1m-refine-v2_112x112.zip?dl=1","d23ba711":"!unzip casia_webface.zip\n!rm casia_webface.zip\n\n!pip install mxnet\n!pip install -U efficientnet==1.1.0\n!pip install bcolz","ba1ef982":"%tensorflow_version 2.x","ce9582fc":"import math\nimport mxnet as mx\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport efficientnet.tfkeras as efn \n\nfrom shutil import rmtree","9e1d4b59":"# This function taken from https:\/\/github.com\/auroua\/InsightFace_TF\/blob\/master\/data\/mx2tfrecords.py\n\ndef mx2tfrecords(imgidx, imgrec):\n    output_path = f\"faces_emore\/tran.tfrecords\"\n    writer = tf.compat.v1.python_io.TFRecordWriter(output_path)\n    for i in imgidx:\n        img_info = imgrec.read_idx(i)\n        header, img = mx.recordio.unpack(img_info)\n        label = int(header.label)\n        example = tf.train.Example(features=tf.train.Features(feature={\n            'image_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img])),\n            \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n        }))\n        writer.write(example.SerializeToString())  # Serialize To String\n        if i % 10000 == 0:\n            print('%d num image processed' % i)\n    writer.close()\n\nimgrec = mx.recordio.MXIndexedRecordIO(f\"faces_emore\/train.idx\", f\"faces_emore\/train.rec\", 'r')\ns = imgrec.read_idx(0)\nheader, _ = mx.recordio.unpack(s)\nprint(header.label)\nimgidx = list(range(1, int(header.label[0])))\n\nmx2tfrecords(imgidx, imgrec)\n\n!rm faces_emore\/train.idx\n!rm faces_emore\/train.rec","1d653dc6":"from pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nfrom google.colab import auth\nfrom oauth2client.client import GoogleCredentials\n\nauth.authenticate_user()\ngauth = GoogleAuth()\ngauth.credentials = GoogleCredentials.get_application_default()\ndrive = GoogleDrive(gauth)\n\nfile_obj = drive.CreateFile({'id': \"1WO5Meh_yAau00Gm2Rz2Pc0SRldLQYigT\"})\nfile_obj.GetContentFile('lfw_align_112.zip')","5f9c91c2":"!unzip -q lfw_align_112.zip\n!rm lfw_align_112.zip","4813b094":"class ArcFaceLayer(tf.keras.layers.Layer):\n\tdef __init__(self, num_classes, arc_m=0.5, arc_s=64., regularizer_l: float = 5e-4, **kwargs):  # has been set to it's defaults according to arcface paper\n\t\tsuper(ArcFaceLayer, self).__init__(**kwargs)\n\t\tself.num_classes = num_classes\n\t\tself.regularizer_l = regularizer_l\n\t\tself.arc_m = arc_m\n\t\tself.arc_s = arc_s\n\n\t\tself.cos_m = tf.identity(math.cos(self.arc_m))\n\t\tself.sin_m = tf.identity(math.sin(self.arc_m))\n\t\tself.th = tf.identity(math.cos(math.pi - self.arc_m))\n\t\tself.mm = tf.multiply(self.sin_m, self.arc_m)\n\n\tdef build(self, input_shape):\n\t\tself.kernel = self.add_weight(name=\"kernel\", shape=[512, self.num_classes], initializer=tf.keras.initializers.glorot_normal(),\n\t\t                              trainable=True, regularizer=tf.keras.regularizers.l2(self.regularizer_l))\n\n\t\tsuper(ArcFaceLayer, self).build(input_shape)\n\n\tdef call(self, features, labels):\n\t\tembedding_norm = tf.norm(features, axis=1, keepdims=True)\n\t\tembedding = tf.divide(features, embedding_norm, name='norm_embedding')\n\t\tweights_norm = tf.norm(self.kernel, axis=0, keepdims=True)\n\t\tweights = tf.divide(self.kernel, weights_norm, name='norm_weights')\n\n\t\tcos_t = tf.matmul(embedding, weights, name='cos_t')\n\t\tcos_t2 = tf.square(cos_t, name='cos_2')\n\t\tsin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n\t\tsin_t = tf.sqrt(sin_t2, name='sin_t')\n\t\tcos_mt = self.arc_s * tf.subtract(tf.multiply(cos_t, self.cos_m), tf.multiply(sin_t, self.sin_m), name='cos_mt')\n\n\t\tcond_v = cos_t - self.th\n\t\tcond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n\n\t\tkeep_val = self.arc_s*(cos_t - self.mm)\n\t\tcos_mt_temp = tf.where(cond, cos_mt, keep_val)\n\n\t\tmask = tf.one_hot(labels, depth=self.num_classes, name='one_hot_mask')\n\t\tinv_mask = tf.subtract(1., mask, name='inverse_mask')\n\n\t\ts_cos_t = tf.multiply(self.arc_s, cos_t, name='scalar_cos_t')\n\n\t\toutput = tf.add(tf.multiply(s_cos_t, inv_mask), tf.multiply(cos_mt_temp, mask), name='arcface_loss_output')\n\n\t\treturn output","fcebb04c":"class TensorBoardCallback:\n\tdef delete_graphs(self):\n\t\tif tf.io.gfile.exists(self.logdir):\n\t\t\trmtree(self.logdir)\n\t\t\tprint(f\"[*] {self.logdir} has deleted with shutil's rmtree\")\n\n\tdef initialize(self, delete_if_exists: bool = False):\n\t\tif delete_if_exists:\n\t\t\tself.delete_graphs()\n\n\t\tself.file_writer = tf.summary.create_file_writer(logdir=self.logdir)\n\n\tdef __init__(self, logdir: str = \"graphs\/\"):\n\t\tself.logdir = logdir\n\t\tself.file_writer = None\n\n\t\tself.initial_step = 0\n\n\tdef __call__(self, data_json: dict, description: str = None, **kwargs):\n\t\twith self.file_writer.as_default():\n\t\t\tfor key in data_json:\n\t\t\t\ttf.summary.scalar(key, data_json[key], step=self.initial_step, description=description)\n\n\t\tself.initial_step += 1\n\n\tdef add_with_step(self, data_json: dict, description: str = None, step: int = 0):\n\t\twith self.file_writer.as_default():\n\t\t\tfor key in data_json:\n\t\t\t\ttf.summary.scalar(key, data_json[key], step=step, description=description)\n\n\tdef add_text(self, name: str, data: str, step: int, **kwargs):\n\t\twith self.file_writer.as_default():\n\t\t\ttf.summary.text(name, data, step=step)\n\n\tdef add_images(self, name: str, data, step: int, max_outputs: int = None, **kwargs):\n\t\tif max_outputs is None:\n\t\t\tmax_outputs = data.shape[0]\n\n\t\twith self.file_writer.as_default():\n\t\t\ttf.summary.image(name, data, max_outputs=max_outputs, step=step)\n","bb917daf":"import sys\nimport os\nimport mxnet as mx\nimport tensorflow as tf\n\n\ndef Conv(data, **kwargs):\n\t# name = kwargs.get('name')\n\t# _weight = mx.symbol.Variable(name+'_weight')\n\t# _bias = mx.symbol.Variable(name+'_bias', lr_mult=2.0, wd_mult=0.0)\n\t# body = mx.sym.Convolution(weight = _weight, bias = _bias, **kwargs)\n\tkwargs[\"kernel_size\"] = kwargs[\"kernel\"]\n\tkwargs[\"filters\"] = kwargs[\"num_filter\"]\n\tkwargs[\"strides\"] = kwargs[\"stride\"]\n\tpadding=\"valid\"\n\ttry:\n\t\t# data = tf.keras.layers.ZeroPadding2D(kwargs[\"pad\"])(data)\n\t\tpadding=\"same\"\n\t\tdel kwargs[\"pad\"]\n\texcept KeyError:\n\t\tpass\n\n\tdel kwargs[\"kernel\"]\n\tdel kwargs[\"num_filter\"]\n\tdel kwargs[\"stride\"]\n\tbody = tf.keras.layers.Conv2D(padding=padding, **kwargs)(data)\n\treturn body\n\n\ndef Act(data, act_type, name):\n\tif act_type == 'prelu':\n\t\tbody = tf.keras.layers.PReLU(name=name)(data)\n\telse:\n\t\tbody = tf.keras.layers.Activation(act_type, name=name)(data)\n\treturn body\n\n\ndef residual_unit_v1(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs):\n\t\"\"\"Return ResNet Unit symbol for building ResNet\n\tParameters\n\t----------\n\tdata : str\n\t\tInput data\n\tnum_filter : int\n\t\tNumber of output channels\n\tbnf : int\n\t\tBottle neck channels factor with regard to num_filter\n\tstride : tuple\n\t\tStride used in convolution\n\tdim_match : Boolean\n\t\tTrue means channel number between input and output is the same, otherwise means differ\n\tname : str\n\t\tBase name of the operators\n\tworkspace : int\n\t\tWorkspace used in convolution operator\n\t\"\"\"\n\tuse_se = kwargs.get('version_se', 1)\n\tbn_mom = kwargs.get('bn_mom', 0.9)\n\tworkspace = kwargs.get('workspace', 256)\n\tmemonger = kwargs.get('memonger', False)\n\tact_type = kwargs.get('version_act', 'prelu')\n\t# print('in unit1')\n\tif bottle_neck:\n\t\tconv1 = Conv(data=data, num_filter=int(num_filter * 0.25), kernel=(1, 1), stride=stride, pad=(0, 0),\n\t\t\t\t\t use_bias=False, name=name + '_conv1')\n\t\tbn1 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn1')(conv1)\n\t\tact1 = Act(data=bn1, act_type=act_type, name=name + '_relu1')\n\t\tconv2 = Conv(data=act1, num_filter=int(num_filter * 0.25), kernel=(3, 3), stride=(1, 1), pad=(1, 1),\n\t\t\t\t\t use_bias=False, name=name + '_conv2')\n\t\tbn2 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn2')(conv2)\n\t\tact2 = Act(data=bn2, act_type=act_type, name=name + '_relu2')\n\t\tconv3 = Conv(data=act2, num_filter=num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0), use_bias=False, name=name + '_conv3')\n\t\tbn3 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn3')(conv3)\n\n\t\tif use_se:\n\t\t\t# se begin\n\t\t\tbody = tf.keras.layers.AveragePooling2D(pool_size=(7, 7), name=name + '_se_pool1')(bn3)\n\t\t\tbody = Conv(data=body, num_filter=num_filter \/\/ 16, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv1\")\n\t\t\tbody = Act(data=body, act_type=act_type, name=name + '_se_relu1')\n\t\t\tbody = Conv(data=body, num_filter=num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv2\")\n\t\t\tbody = tf.keras.layers.Activation('sigmoid', name=name + \"_se_sigmoid\")(body)\n\t\t\tbn3 = tf.keras.layers.Multiply()([bn3, body])\n\t\t# se end\n\n\t\tif dim_match:\n\t\t\tshortcut = data\n\t\t\tx = tf.keras.layers.Add()([bn3, shortcut])\n\t\telse:\n\t\t\tconv1sc = Conv(data=data, num_filter=num_filter, kernel=(1, 1), stride=stride, use_bias=False, name=name + '_conv1sc')\n\t\t\tshortcut = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_sc')(conv1sc)\n\t\t\tx = tf.keras.layers.Add()([bn3, shortcut])\n\t\treturn Act(data=x, act_type=act_type, name=name + '_relu3')\n\telse:\n\t\tconv1 = Conv(data=data, num_filter=num_filter, kernel=(3, 3), stride=stride, pad=(1, 1),\n\t\t\t\t\t use_bias=False, name=name + '_conv1')\n\t\tbn1 = tf.keras.layers.BatchNormalization(momentum=bn_mom, epsilon=2e-5, name=name + '_bn1')(conv1)\n\t\tact1 = Act(data=bn1, act_type=act_type, name=name + '_relu1')\n\t\tconv2 = Conv(data=act1, num_filter=num_filter, kernel=(3, 3), stride=(1, 1), pad=(1, 1),\n\t\t\t\t\t use_bias=False, name=name + '_conv2')\n\t\tbn2 = tf.keras.layers.BatchNormalization(momentum=bn_mom, epsilon=2e-5, name=name + '_bn2')(conv2)\n\t\tif use_se:\n\t\t\t# se begin\n\t\t\tbody = tf.keras.layers.AveragePooling2D(pool_size=(7, 7), name=name + '_se_pool2')(bn2)\n\t\t\tbody = Conv(data=body, num_filter=int(num_filter \/\/ 16), kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv1\")\n\t\t\tbody = Act(data=body, act_type=act_type, name=name + '_se_relu1')\n\t\t\tbody = Conv(data=body, num_filter=num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv2\")\n\t\t\tbody = tf.keras.layers.Activation('sigmoid', name=name + \"_se_sigmoid\")(body)\n\t\t\tbn2 = tf.keras.layers.Multiply()([bn2, body])\n\t\t# se end\n\n\t\tif dim_match:\n\t\t\tshortcut = data\n\t\t\tx = tf.keras.layers.Add()([bn2 + shortcut])\n\t\telse:\n\t\t\tconv1sc = Conv(data=data, num_filter=num_filter, kernel=(1, 1), stride=stride, use_bias=False,\n\t\t\t\t\t\t   name=name + '_conv1sc')\n\t\t\tshortcut = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_sc')(conv1sc)\n\t\t\tx = tf.keras.layers.Add()([bn2 + shortcut])\n\t\treturn Act(data=x, act_type=act_type, name=name + '_relu3')\n\n\ndef residual_unit_v1_L(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs):\n\t\"\"\"Return ResNet Unit symbol for building ResNet\n\tParameters\n\t----------\n\tdata : str\n\t\tInput data\n\tnum_filter : int\n\t\tNumber of output channels\n\tbnf : int\n\t\tBottle neck channels factor with regard to num_filter\n\tstride : tuple\n\t\tStride used in convolution\n\tdim_match : Boolean\n\t\tTrue means channel number between input and output is the same, otherwise means differ\n\tname : str\n\t\tBase name of the operators\n\tworkspace : int\n\t\tWorkspace used in convolution operator\n\t\"\"\"\n\tuse_se = kwargs.get('version_se', 1)\n\tbn_mom = kwargs.get('bn_mom', 0.9)\n\tworkspace = kwargs.get('workspace', 256)\n\tmemonger = kwargs.get('memonger', False)\n\tact_type = kwargs.get('version_act', 'prelu')\n\t# print('in unit1')\n\tif bottle_neck:\n\t\tconv1 = Conv(data=data, num_filter=int(num_filter * 0.25), kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t use_bias=False, name=name + '_conv1')\n\t\tbn1 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn1')(conv1)\n\t\tact1 = Act(data=bn1, act_type=act_type, name=name + '_relu1')\n\t\tconv2 = Conv(data=act1, num_filter=int(num_filter * 0.25), kernel=(3, 3), stride=(1, 1), pad=(1, 1),\n\t\t\t\t\t use_bias=False, name=name + '_conv2')\n\t\tbn2 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn2')(conv2)\n\t\tact2 = Act(data=bn2, act_type=act_type, name=name + '_relu2')\n\t\tconv3 = Conv(data=act2, num_filter=num_filter, kernel=(1, 1), stride=stride, pad=(0, 0), use_bias=False, name=name + '_conv3')\n\t\tbn3 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn3')(conv3)\n\n\t\tif use_se:\n\t\t\t# se begin\n\t\t\tbody = tf.keras.layers.AveragePooling2D(pool_size=(7, 7), name=name + '_se_pool1')(bn3)\n\t\t\tbody = Conv(data=body, num_filter=int(num_filter \/\/ 16), kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv1\")\n\t\t\tbody = Act(data=body, act_type=act_type, name=name + '_se_relu1')\n\t\t\tbody = Conv(data=body, num_filter=num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv2\")\n\t\t\tbody = tf.keras.layers.Activation('sigmoid', name=name + \"_se_sigmoid\")(body)\n\t\t\tbn3 = tf.keras.layers.Multiply()([bn3, body])\n\t\t# se end\n\n\t\tif dim_match:\n\t\t\tshortcut = data\n\t\t\tx = tf.keras.layers.Add()([bn3, shortcut])\n\t\telse:\n\t\t\tconv1sc = Conv(data=data, num_filter=num_filter, kernel=(1, 1), stride=stride, use_bias=False, name=name + '_conv1sc')\n\t\t\tshortcut = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_sc')(conv1sc)\n\t\t\tx = tf.keras.layers.Add()([bn3, shortcut])\n\t\treturn Act(data=x, act_type=act_type, name=name + '_relu3')\n\telse:\n\t\tconv1 = Conv(data=data, num_filter=num_filter, kernel=(3, 3), stride=(1, 1), pad=(1, 1),\n\t\t\t\t\t use_bias=False, name=name + '_conv1')\n\t\tbn1 = tf.keras.layers.BatchNormalization(momentum=bn_mom, epsilon=2e-5, name=name + '_bn1')(conv1)\n\t\tact1 = Act(data=bn1, act_type=act_type, name=name + '_relu1')\n\t\tconv2 = Conv(data=act1, num_filter=num_filter, kernel=(3, 3), stride=stride, pad=(1, 1),\n\t\t\t\t\t use_bias=False, name=name + '_conv2')\n\t\tbn2 = tf.keras.layers.BatchNormalization(momentum=bn_mom, epsilon=2e-5, name=name + '_bn2')(conv2)\n\t\tif use_se:\n\t\t\t# se begin\n\t\t\tbody = tf.keras.layers.AveragePooling2D(pool_size=(7, 7), name=name + '_se_pool1')(bn2)\n\t\t\tbody = Conv(data=body, num_filter=num_filter \/\/ 16, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv1\")\n\t\t\tbody = Act(data=body, act_type=act_type, name=name + '_se_relu1')\n\t\t\tbody = Conv(data=body, num_filter=num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv2\")\n\t\t\tbody = tf.keras.layers.Activation('sigmoid', name=name + \"_se_sigmoid\")(body)\n\t\t\tbn2 = tf.keras.layers.Multiply()([bn2, body])\n\t\t# se end\n\n\t\tif dim_match:\n\t\t\tshortcut = data\n\t\t\tx = tf.keras.layers.Add()([bn2 + shortcut])\n\t\telse:\n\t\t\tconv1sc = Conv(data=data, num_filter=num_filter, kernel=(1, 1), stride=stride, use_bias=False,\n\t\t\t\t\t\t\tname=name + '_conv1sc')\n\t\t\tshortcut = tf.keras.layers.BatchNormalization(momentum=bn_mom, epsilon=2e-5, name=name + '_sc')(conv1sc)\n\t\t\tx = tf.keras.layers.Add()([bn2 + shortcut])\n\t\treturn Act(data=x, act_type=act_type, name=name + '_relu3')\n\n\ndef residual_unit_v2(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs):\n\t\"\"\"Return ResNet Unit symbol for building ResNet\n\tParameters\n\t----------\n\tdata : str\n\t\tInput data\n\tnum_filter : int\n\t\tNumber of output channels\n\tbnf : int\n\t\tBottle neck channels factor with regard to num_filter\n\tstride : tuple\n\t\tStride used in convolution\n\tdim_match : Boolean\n\t\tTrue means channel number between input and output is the same, otherwise means differ\n\tname : str\n\t\tBase name of the operators\n\tworkspace : int\n\t\tWorkspace used in convolution operator\n\t\"\"\"\n\tuse_se = kwargs.get('version_se', 1)\n\tbn_mom = kwargs.get('bn_mom', 0.9)\n\tworkspace = kwargs.get('workspace', 256)\n\tmemonger = kwargs.get('memonger', False)\n\tact_type = kwargs.get('version_act', 'prelu')\n\t# print('in unit2')\n\tif bottle_neck:\n\t\t# the same as https:\/\/github.com\/facebook\/fb.resnet.torch#notes, a bit difference with origin paper\n\t\tbn1 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn1')(data)\n\t\tact1 = Act(data=bn1, act_type=act_type, name=name + '_relu1')\n\t\tconv1 = Conv(data=act1, num_filter=int(num_filter * 0.25), kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t use_bias=False, name=name + '_conv1')\n\t\tbn2 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn2')(conv1)\n\t\tact2 = Act(data=bn2, act_type=act_type, name=name + '_relu2')\n\t\tconv2 = Conv(data=act2, num_filter=int(num_filter * 0.25), kernel=(3, 3), stride=stride, pad=(1, 1),\n\t\t\t\t\t use_bias=False, name=name + '_conv2')\n\t\tbn3 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn3')(conv2)\n\t\tact3 = Act(data=bn3, act_type=act_type, name=name + '_relu3')\n\t\tconv3 = Conv(data=act3, num_filter=num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0), use_bias=False, name=name + '_conv3')\n\t\tif use_se:\n\t\t\t# se begin\n\t\t\tbody = tf.keras.layers.AveragePooling2D(pool_size=(7, 7), name=name + '_se_pool1')(conv3)\n\t\t\tbody = Conv(data=body, num_filter=num_filter \/\/ 16, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv1\")\n\t\t\tbody = Act(data=body, act_type=act_type, name=name + '_se_relu1')\n\t\t\tbody = Conv(data=body, num_filter=num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv2\")\n\t\t\tbody = tf.keras.layers.Activation('sigmoid', name=name + \"_se_sigmoid\")(body)\n\t\t\tconv3 = tf.keras.layers.Multiply()([conv3, body])\n\t\tif dim_match:\n\t\t\tshortcut = data\n\t\t\tx = tf.keras.layers.Add()([conv3 + shortcut])\n\t\telse:\n\t\t\tshortcut = Conv(data=act1, num_filter=num_filter, kernel=(1, 1), stride=stride, use_bias=False,\n\t\t\t\t\t\t\tname=name + '_sc')\n\t\t\tx = tf.keras.layers.Add()([conv3 + shortcut])\n\t\treturn x\n\telse:\n\t\tbn1 = tf.keras.layers.BatchNormalization( momentum=bn_mom, epsilon=2e-5, name=name + '_bn1')(data)\n\t\tact1 = Act(data=bn1, act_type=act_type, name=name + '_relu1')\n\t\tconv1 = Conv(data=act1, num_filter=num_filter, kernel=(3, 3), stride=stride, pad=(1, 1),\n\t\t\t\t\t use_bias=False, name=name + '_conv1')\n\t\tbn2 = tf.keras.layers.BatchNormalization(momentum=bn_mom, epsilon=2e-5, name=name + '_bn2')(conv1)\n\t\tact2 = Act(data=bn2, act_type=act_type, name=name + '_relu2')\n\t\tconv2 = Conv(data=act2, num_filter=num_filter, kernel=(3, 3), stride=(1, 1), pad=(1, 1),\n\t\t\t\t\t use_bias=False, name=name + '_conv2')\n\t\tif use_se:\n\t\t\t# se begin\n\t\t\tbody = tf.keras.layers.AveragePooling2D(pool_size=(7, 7), name=name + '_se_pool1')(conv2)\n\t\t\tbody = Conv(data=body, num_filter=num_filter \/\/ 16, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv1\")\n\t\t\tbody = Act(data=body, act_type=act_type, name=name + '_se_relu1')\n\t\t\tbody = Conv(data=body, num_filter=num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv2\")\n\t\t\tbody = tf.keras.layers.Activation('sigmoid', name=name + \"_se_sigmoid\")(body)\n\t\t\tconv2 = tf.keras.layers.Multiply()([conv2, body])\n\t\tif dim_match:\n\t\t\tshortcut = data\n\t\telse:\n\t\t\tshortcut = Conv(data=act1, num_filter=num_filter, kernel=(1, 1), stride=stride, use_bias=False,\n\t\t\t\t\t\t\tname=name + '_sc')\n\t\tx = tf.keras.layers.Add()([conv2 + shortcut])\n\t\treturn x\n\n\ndef residual_unit_v3(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs):\n\t\"\"\"Return ResNet Unit symbol for building ResNet\n\tParameters\n\t----------\n\tdata : str\n\t\tInput data\n\tnum_filter : int\n\t\tNumber of output channels\n\tbnf : int\n\t\tBottle neck channels factor with regard to num_filter\n\tstride : tuple\n\t\tStride used in convolution\n\tdim_match : Boolean\n\t\tTrue means channel number between input and output is the same, otherwise means differ\n\tname : str\n\t\tBase name of the operators\n\tworkspace : int\n\t\tWorkspace used in convolution operator\n\t\"\"\"\n\tuse_se = kwargs.get('version_se', 1)\n\tbn_mom = kwargs.get('bn_mom', 0.9)\n\tworkspace = kwargs.get('workspace', 256)\n\tmemonger = kwargs.get('memonger', False)\n\tact_type = kwargs.get('version_act', 'prelu')\n\t# print('in unit3')\n\tif bottle_neck:\n\t\tbn1 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn1')(data)\n\t\tconv1 = Conv(data=bn1, num_filter=int(num_filter * 0.25), kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t use_bias=False, name=name + '_conv1')\n\t\tbn2 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn2')(conv1)\n\t\tact1 = Act(data=bn2, act_type=act_type, name=name + '_relu1')\n\t\tconv2 = Conv(data=act1, num_filter=int(num_filter * 0.25), kernel=(3, 3), stride=(1, 1), pad=(1, 1),\n\t\t\t\t\t use_bias=False, name=name + '_conv2')\n\t\tbn3 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn3')(conv2)\n\t\tact2 = Act(data=bn3, act_type=act_type, name=name + '_relu2')\n\t\tconv3 = Conv(data=act2, num_filter=num_filter, kernel=(1, 1), stride=stride, pad=(0, 0), use_bias=False, name=name + '_conv3')\n\t\tbn4 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn4')(conv3)\n\n\t\tif use_se:\n\t\t\t# se begin\n\t\t\tbody = tf.keras.layers.AveragePooling2D(pool_size=(7, 7), name=name + '_se_pool1')(bn4)\n\t\t\tbody = Conv(data=body, num_filter=num_filter \/\/ 16, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv1\")\n\t\t\tbody = Act(data=body, act_type=act_type, name=name + '_se_relu1')\n\t\t\tbody = Conv(data=body, num_filter=num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv2\")\n\n\t\t\tbody = tf.keras.layers.Activation('sigmoid', name=name + \"_se_sigmoid\")(body)\n\t\t\tbn4 = tf.keras.layers.Multiply()([bn4, body])\n\t\t# se end\n\n\t\tif dim_match:\n\t\t\tshortcut = data\n\t\telse:\n\t\t\tconv1sc = Conv(data=data, num_filter=num_filter, kernel=(1, 1), stride=stride, use_bias=False,\n\t\t\t\t\t\t   name=name + '_conv1sc')\n\t\t\tshortcut = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_sc')(conv1sc)\n\n\t\tx = tf.keras.layers.Add()([bn4 + shortcut])\n\t\treturn x\n\telse:\n\t\tbn1 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn1')(data)\n\t\tconv1 = Conv(data=bn1, num_filter=num_filter, kernel=(3, 3), stride=(1, 1), pad=(1, 1),\n\t\t\t\t\t use_bias=False, name=name + '_conv1')\n\t\tbn2 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn2')(conv1)\n\t\tact1 = Act(data=bn2, act_type=act_type, name=name + '_relu1')\n\t\tconv2 = Conv(data=act1, num_filter=num_filter, kernel=(3, 3), stride=stride, pad=(1, 1),\n\t\t\t\t\t use_bias=False, name=name + '_conv2')\n\t\tbn3 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn3')(conv2)\n\t\tif use_se:\n\t\t\t# se begin\n\t\t\tbody = tf.keras.layers.AveragePooling2D(pool_size=(7, 7), name=name + '_se_pool1')(bn3)\n\t\t\tbody = Conv(data=body, num_filter=num_filter \/\/ 16, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv1\")\n\t\t\tbody = Act(data=body, act_type=act_type, name=name + '_se_relu1')\n\t\t\tbody = Conv(data=body, num_filter=num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\t\tname=name + \"_se_conv2\")\n\t\t\tbody = tf.keras.layers.Activation('sigmoid', name=name + \"_se_sigmoid\")(body)\n\t\t\tbn3 = tf.keras.layers.Multiply()([bn3, body])\n\t\t# se end\n\n\t\tif dim_match:\n\t\t\tshortcut = data\n\t\telse:\n\t\t\tconv1sc = Conv(data=data, num_filter=num_filter, kernel=(1, 1), stride=stride, use_bias=False,\n\t\t\t\t\t\t   name=name + '_conv1sc')\n\t\t\tshortcut = tf.keras.layers.BatchNormalization(momentum=bn_mom, epsilon=2e-5, name=name + '_sc')(conv1sc)\n\n\t\tx = tf.keras.layers.Add()([bn3, shortcut])\n\t\treturn x\n\n\ndef residual_unit_v3_x(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs):\n\t\"\"\"Return ResNeXt Unit symbol for building ResNeXt\n\tParameters\n\t----------\n\tdata : str\n\t\tInput data\n\tnum_filter : int\n\t\tNumber of output channels\n\tbnf : int\n\t\tBottle neck channels factor with regard to num_filter\n\tstride : tuple\n\t\tStride used in convolution\n\tdim_match : Boolean\n\t\tTrue means channel number between input and output is the same, otherwise means differ\n\tname : str\n\t\tBase name of the operators\n\tworkspace : int\n\t\tWorkspace used in convolution operator\n\t\"\"\"\n\tassert (bottle_neck)\n\tuse_se = kwargs.get('version_se', 1)\n\tbn_mom = kwargs.get('bn_mom', 0.9)\n\tworkspace = kwargs.get('workspace', 256)\n\tmemonger = kwargs.get('memonger', False)\n\tact_type = kwargs.get('version_act', 'prelu')\n\tnum_group = 32\n\t# print('in unit3')\n\tbn1 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn1')(data)\n\tconv1 = Conv(data=bn1, num_group=num_group, num_filter=int(num_filter * 0.5), kernel=(1, 1), stride=(1, 1),\n\t\t\t\t pad=(0, 0),\n\t\t\t\t use_bias=False, name=name + '_conv1')\n\tbn2 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn2')(conv1)\n\tact1 = Act(data=bn2, act_type=act_type, name=name + '_relu1')\n\tconv2 = Conv(data=act1, num_group=num_group, num_filter=int(num_filter * 0.5), kernel=(3, 3), stride=(1, 1),\n\t\t\t\t pad=(1, 1),\n\t\t\t\t use_bias=False, name=name + '_conv2')\n\tbn3 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn3')(conv2)\n\tact2 = Act(data=bn3, act_type=act_type, name=name + '_relu2')\n\tconv3 = Conv(data=act2, num_filter=num_filter, kernel=(1, 1), stride=stride, pad=(0, 0), use_bias=False, name=name + '_conv3')\n\tbn4 = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_bn4')(conv3)\n\n\tif use_se:\n\t\t# se begin\n\t\tbody = tf.keras.layers.AveragePooling2D(pool_size=(7, 7), name=name + '_se_pool1')(bn4)\n\t\tbody = Conv(data=body, num_filter=num_filter \/\/ 16, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\tname=name + \"_se_conv1\")\n\t\tbody = Act(data=body, act_type=act_type, name=name + '_se_relu1')\n\t\tbody = Conv(data=body, num_filter=num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\tname=name + \"_se_conv2\")\n\t\tbody = tf.keras.layers.Activation('sigmoid', name=name + \"_se_sigmoid\")(body)\n\t\tbn4 = tf.keras.layers.Multiply()([bn4, body])\n\t# se end\n\n\tif dim_match:\n\t\tshortcut = data\n\telse:\n\t\tconv1sc = Conv(data=data, num_filter=num_filter, kernel=(1, 1), stride=stride, use_bias=False, name=name + '_conv1sc')\n\t\tshortcut = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name=name + '_sc')(conv1sc)\n\n\tx = tf.keras.layers.Add()([bn4 + shortcut])\n\treturn x\n\n\ndef residual_unit(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs):\n\tuv = kwargs.get('version_unit', 3)\n\tversion_input = kwargs.get('version_input', 1)\n\tif uv == 1:\n\t\tif version_input == 0:\n\t\t\treturn residual_unit_v1(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs)\n\t\telse:\n\t\t\treturn residual_unit_v1_L(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs)\n\telif uv == 2:\n\t\treturn residual_unit_v2(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs)\n\telif uv == 4:\n\t\treturn residual_unit_v4(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs)\n\telse:\n\t\treturn residual_unit_v3(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs)\n\n\ndef get_fc1(last_conv, num_classes, fc_type, input_channel=512):\n\tbn_mom = 0.9\n\tbody = last_conv\n\n\treturn body\n\n\ndef resnet(units, num_stages, filter_list, num_classes, bottle_neck):\n\tbn_mom = 0.9\n\tkwargs = {'version_se': 0,\n\t\t\t  'version_input': 1,\n\t\t\t  'version_output': \"E\",\n\t\t\t  'version_unit': 3,\n\t\t\t  'version_act': \"prelu\",\n\t\t\t  'bn_mom': bn_mom,\n\t\t\t  }\n\t\"\"\"Return ResNet symbol of\n\tParameters\n\t----------\n\tunits : list\n\t\tNumber of units in each stage\n\tnum_stages : int\n\t\tNumber of stage\n\tfilter_list : list\n\t\tChannel size of each stage\n\tnum_classes : int\n\t\tOuput size of symbol\n\tdataset : str\n\t\tDataset type, only cifar10 and imagenet supports\n\tworkspace : int\n\t\tWorkspace used in convolution operator\n\t\"\"\"\n\tversion_se = kwargs.get('version_se', 1)\n\tversion_input = kwargs.get('version_input', 1)\n\tassert version_input >= 0\n\tversion_output = kwargs.get('version_output', 'E')\n\tfc_type = version_output\n\tversion_unit = kwargs.get('version_unit', 3)\n\tact_type = kwargs.get('version_act', 'prelu')\n\tmemonger = kwargs.get('memonger', False)\n\tprint(version_se, version_input, version_output, version_unit, act_type, memonger)\n\tnum_unit = len(units)\n\tassert (num_unit == num_stages)\n\tdata = tf.keras.layers.Input((112, 112, 3))\n\tbody = Conv(data=data, num_filter=filter_list[0], kernel=(3, 3), stride=(1, 1), pad=(1, 1),\n\t\t\t\tuse_bias=False, name=\"conv0\")\n\tbody = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name='bn0')(body)\n\tbody = Act(data=body, act_type=act_type, name='relu0')\n\n\tfor i in range(num_stages):\n\t\t# if version_input==0:\n\t\t#  body = residual_unit(body, filter_list[i+1], (1 if i==0 else 2, 1 if i==0 else 2), False,\n\t\t#                       name='stage%d_unit%d' % (i + 1, 1), bottle_neck=bottle_neck, **kwargs)\n\t\t# else:\n\t\t#  body = residual_unit(body, filter_list[i+1], (2, 2), False,\n\t\t#    name='stage%d_unit%d' % (i + 1, 1), bottle_neck=bottle_neck, **kwargs)\n\t\tbody = residual_unit(body, filter_list[i + 1], (2, 2), False,\n\t\t\t\t\t\t\t name='stage%d_unit%d' % (i + 1, 1), bottle_neck=bottle_neck, **kwargs)\n\t\tfor j in range(units[i] - 1):\n\t\t\tbody = residual_unit(body, filter_list[i + 1], (1, 1), True, name='stage%d_unit%d' % (i + 1, j + 2),\n\t\t\t\t\t\t\t\t bottle_neck=bottle_neck, **kwargs)\n\n\tif bottle_neck:\n\t\tbody = Conv(data=body, num_filter=512, kernel=(1, 1), stride=(1, 1), pad=(0, 0),\n\t\t\t\t\tuse_bias=False, name=\"convd\")\n\t\tbody = tf.keras.layers.BatchNormalization(epsilon=2e-5, momentum=bn_mom, name='bnd')(body)\n\t\tbody = Act(data=body, act_type=act_type, name='relu')  # relud?\n\n\tbody = get_fc1(body, num_classes, fc_type)\n\treturn data, body\n\n\ndef get_symbol(num_layers: int = 100):\n\t\"\"\"\n\tAdapted from https:\/\/github.com\/tornadomeet\/ResNet\/blob\/master\/train_resnet.py\n\tOriginal author Wei Wu\n\t\"\"\"\n\tnum_classes = 85000\n\tif num_layers >= 500:\n\t\tfilter_list = [64, 256, 512, 1024, 2048]\n\t\tbottle_neck = True\n\telse:\n\t\tfilter_list = [64, 64, 128, 256, 512]\n\t\tbottle_neck = False\n\tnum_stages = 4\n\tif num_layers == 18:\n\t\tunits = [2, 2, 2, 2]\n\telif num_layers == 34:\n\t\tunits = [3, 4, 6, 3]\n\telif num_layers == 49:\n\t\tunits = [3, 4, 14, 3]\n\telif num_layers == 50:\n\t\tunits = [3, 4, 14, 3]\n\telif num_layers == 74:\n\t\tunits = [3, 6, 24, 3]\n\telif num_layers == 90:\n\t\tunits = [3, 8, 30, 3]\n\telif num_layers == 98:\n\t\tunits = [3, 4, 38, 3]\n\telif num_layers == 99:\n\t\tunits = [3, 8, 35, 3]\n\telif num_layers == 100:\n\t\tunits = [3, 13, 30, 3]\n\telif num_layers == 134:\n\t\tunits = [3, 10, 50, 3]\n\telif num_layers == 136:\n\t\tunits = [3, 13, 48, 3]\n\telif num_layers == 140:\n\t\tunits = [3, 15, 48, 3]\n\telif num_layers == 124:\n\t\tunits = [3, 13, 40, 5]\n\telif num_layers == 160:\n\t\tunits = [3, 24, 49, 3]\n\telif num_layers == 101:\n\t\tunits = [3, 4, 23, 3]\n\telif num_layers == 152:\n\t\tunits = [3, 8, 36, 3]\n\telif num_layers == 200:\n\t\tunits = [3, 24, 36, 3]\n\telif num_layers == 269:\n\t\tunits = [3, 30, 48, 8]\n\telse:\n\t\traise ValueError(\"no experiments done on num_layers {}, you can do it yourself\".format(num_layers))\n\n\tinput_layer, body = resnet(units=units,\n\t\t\t\t num_stages=num_stages,\n\t\t\t\t filter_list=filter_list,\n\t\t\t\t num_classes=num_classes,\n\t\t\t\t bottle_neck=bottle_neck)\n\n\tmodel = tf.keras.models.Model(input_layer, body)\n\tmodel.summary()\n\n\treturn model","ddcb4198":"class BatchNormalization(tf.keras.layers.BatchNormalization):\n\t\"\"\"Make trainable=False freeze BN for real (the og version is sad).\n\t   ref: https:\/\/github.com\/zzh8829\/yolov3-tf2\n\t\"\"\"\n\n\tdef call(self, x, training=False):\n\t\tif training is None:\n\t\t\ttraining = tf.constant(False)\n\t\ttraining = tf.logical_and(training, self.trainable)\n\t\treturn super().call(x, training)\n\n\nclass MainModel:\n\t@tf.function\n\tdef test_step_reg(self, x, y):\n\t\tlogits, features = self.model([x, y], training=False)\n\t\tloss = self.loss_function(y, logits)\n\n\t\treg_loss = tf.add_n(self.model.losses)\n\n\t\treturn logits, features, loss, reg_loss\n\n\t@tf.function\n\tdef train_step_reg(self, x, y):\n\t\twith tf.GradientTape() as tape:\n\t\t\tlogits, features = self.model([x, y], training=True)\n\n\t\t\tloss = self.loss_function(y, logits)\n\t\t\treg_loss = tf.add_n(self.model.losses)\n\n\t\t\tloss_all = tf.add(loss, reg_loss)\n\n\t\tgradients = tape.gradient(loss_all, self.model.trainable_variables)\n\t\tself.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n\n\t\treturn logits, features, loss, reg_loss\n\n\tdef change_learning_rate_of_optimizer(self, new_lr: float):\n\t\tself.optimizer.learning_rate = new_lr\n\t\tself.last_lr = new_lr\n\n\t\tassert self.optimizer.learning_rate == self.optimizer.lr\n\n\t\treturn True\n\n\tdef __init__(self):\n\t\tself.loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\t\tself.last_lr = None\n\n\t@tf.function\n\tdef train_step(self, x, y):\n\t\twith tf.GradientTape() as tape:\n\t\t\tlogits, features = self.model([x, y], training=True)\n\t\t\tloss = self.loss_function(y, logits)\n\n\t\tgradients = tape.gradient(loss, self.model.trainable_variables)\n\t\tself.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n\n\t\treturn logits, features, loss\n\n\t@tf.function\n\tdef test_step(self, x, y):\n\t\tlogits, features = self.model([x, y], training=False)\n\t\tloss = self.loss_function(y, logits)\n\n\t\treturn logits, features, loss\n\n\tdef turn_softmax_into_arcface(self, num_classes: int):\n\t\tlabel_input_layer = tf.keras.layers.Input((None,), dtype=tf.int64)\n\n\t\tx = ArcFaceLayer(num_classes=num_classes, name=\"arcfaceLayer\")(self.model.layers[-3].output, label_input_layer)\n\n\t\tself.model = tf.keras.models.Model([self.model.layers[0].input, label_input_layer], [x, self.model.layers[-3].output])\n\t\tself.model.summary()\n\n\tdef change_regularizer_l(self, new_value: float = 5e-4):\n\t\tfor layer in self.model.layers:\n\t\t\tif \"Conv\" in str(layer):\n\t\t\t\tlayer.kernel_regularizer = tf.keras.regularizers.l2(new_value)\n\n\t\t\telif \"BatchNorm\" in str(layer):\n\t\t\t\tlayer.gamma_regularizer = tf.keras.regularizers.l2(new_value)\n\t\t\t\tlayer.momentum = 0.9\n\t\t\t\tlayer.epsilon = 2e-5\n\n\t\t\telif \"PReLU\" in str(layer):\n\t\t\t\tlayer.alpha_regularizer = tf.keras.regularizers.l2(new_value)\n\n\t\t\telif \"Dense\" in str(layer):\n\t\t\t\tlayer.kernel_regularizer = tf.keras.regularizers.l2(new_value)\n\n\t\t\telif \"arcfaceLayer\" in str(layer):\n\t\t\t\tlayer.kernel_regularizer = tf.keras.regularizers.l2(new_value)\n\n\t\tself.model = tf.keras.models.model_from_json(self.model.to_json())  # To apply regularizers\n\t\tprint(f\"[*] Kernel regularizer value set to --> {new_value}\")\n\n\tdef __call__(self, input_shape, weights: str = None, num_classes: int = 10, learning_rate: float = 0.1,\n\t             regularizer_l: float = 5e-4, weight_path: str = None,\n\t             pooling_layer: tf.keras.layers.Layer = tf.keras.layers.GlobalAveragePooling2D,\n\t             create_model: bool = True, use_arcface: bool = True,\n\t             optimizer=\"ADAM\"):\n\n\t\tself.last_lr = learning_rate\n\n\t\tif optimizer == \"ADAM\":\n\t\t\tself.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=0.1)\n\t\t\tprint(\"[*] ADAM chosen as optimizer\")\n\t\telif optimizer == \"SGD\":\n\t\t\tself.optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n\t\t\tprint(\"[*] SGD chosen as optimizer\")\n\t\telif optimizer == \"MOMENTUM\":\n\t\t\tself.optimizer = tf.compat.v1.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n\t\t\t# MomentumOptimizer is not recommended, it is from TF 1.x makes problem at learning rate change, i will update if TF 2.x version comes out\n\t\t\tprint(\"[*] MomentumOptimizer chosen as optimizer\")\n\t\telse:\n\t\t\traise Exception(f\"{optimizer} is not a valid name! Go with either ADAM, SGD or MOMENTUM\")\n\n\t\tif create_model:\n\t\t\tlabel_input_layer = tf.keras.layers.Input((None,), dtype=tf.int64)\n\t\t\tself.model = self.get_model(input_shape=input_shape, weights=weights)\n\t\t\tself.model.trainable = True\n\n\t\t\tself.change_regularizer_l(regularizer_l)\n\t\t\t# ACCORDING TO ARCFACE PAPER\n\t\t\tx = pooling_layer()(self.model.layers[-1].output)\n\t\t\tx = BatchNormalization(momentum=0.9, epsilon=2e-5)(x)\n\t\t\tx = tf.keras.layers.Dropout(0.4)(x)\n\t\t\tx1 = tf.keras.layers.Dense(512, activation=None, name=\"features_without_bn\", use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(regularizer_l))(x)\n\t\t\tx = BatchNormalization(momentum=0.9, scale=False, epsilon=2e-5)(x1)\n\n\t\t\tif use_arcface:\n\t\t\t\tx = ArcFaceLayer(num_classes=num_classes, arc_m=0.5, arc_s=64., regularizer_l=regularizer_l, name=\"arcfaceLayer\")(x, label_input_layer)\n\t\t\telse:\n\t\t\t\tx = tf.keras.layers.Dense(num_classes, activation=None, name=\"classificationLayer\", kernel_regularizer=tf.keras.regularizers.l2(regularizer_l))(x)\n\n\t\t\tself.model = tf.keras.models.Model([self.model.layers[0].input, label_input_layer], [x, x1], name=f\"{self.__name__}-ArcFace\")\n\t\t\tself.model.summary()\n\n\t\t\ttry:\n\t\t\t\tself.model.load_weights(weight_path)\n\t\t\t\tprint(\"[*] WEIGHTS FOUND FOR MODEL, LOADING...\")\n\t\t\texcept Exception as e:\n\t\t\t\tprint(e)\n\t\t\t\tprint(\"[*] THERE IS NO WEIGHT FILE FOR MODEL, INITIALIZING...\")\n\n\nclass ResNet50(MainModel):\n\t@property\n\tdef __name__(self):\n\t\treturn \"ResNet50\"\n\n\tdef __init__(self, **kwargs):\n\t\tsuper(ResNet50, self).__init__(**kwargs)\n\n\tdef get_model(self, input_shape, weights: str = None, **kwargs):\n\t\treturn get_symbol(50)\n\n\nclass ResNet101(MainModel):\n\t@property\n\tdef __name__(self):\n\t\treturn \"ResNet101\"\n\n\tdef __init__(self, **kwargs):\n\t\tsuper(ResNet101, self).__init__(**kwargs)\n\n\tdef get_model(self, input_shape, weights: str = None, **kwargs):\n\t\treturn get_symbol(100)\n\n\nclass ResNet152(MainModel):\n\t@property\n\tdef __name__(self):\n\t\treturn \"ResNet101\"\n\n\tdef __init__(self, **kwargs):\n\t\tsuper(ResNet152, self).__init__(**kwargs)\n\n\tdef get_model(self, input_shape, weights: str = None, **kwargs):\n\t\treturn get_symbol(152)\n\n\nclass EfficientNetFamily(MainModel):\n\tall_models = [\n\t\tefn.EfficientNetB0,\n\t\tefn.EfficientNetB1,\n\t\tefn.EfficientNetB2,\n\t\tefn.EfficientNetB3,\n\t\tefn.EfficientNetB4,\n\t\tefn.EfficientNetB5,\n\t\tefn.EfficientNetB6,\n\t\tefn.EfficientNetB7,\n\t]\n\n\t@property\n\tdef __name__(self):\n\t\treturn f\"EfficientNetB{self.model_id}\"\n\n\tdef __init__(self, model_id: int, **kwargs):\n\t\tself.model_id = model_id\n\t\tif not 0 <= self.model_id <= 7:\n\t\t\traise ValueError(f\"model_id must be \\\"0 <= model_id <=7\\\", yours({self.model_id}) is not valid!\")\n\n\t\tsuper(EfficientNetFamily, self).__init__(**kwargs)\n\n\tdef get_model(self, input_shape, weights: str = None, **kwargs):\n\t\treturn self.all_models[self.model_id](input_shape=input_shape, weights=weights, include_top=False)\n\n\nclass Xception(MainModel):\n\t@property\n\tdef __name__(self):\n\t\treturn \"Xception\"\n\n\tdef __init__(self, **kwargs):\n\t\tsuper(Xception, self).__init__(**kwargs)\n\n\tdef get_model(self, input_shape, weights: str = None, **kwargs):\n\t\treturn tf.keras.applications.Xception(input_shape=input_shape, weights=weights, include_top=False)\n","9b5e8683":"class DataEngineTypical:\n\tdef make_label_map(self):\n\t\tself.label_map = {}\n\n\t\tfor i, class_name in enumerate(tf.io.gfile.listdir(self.main_path)):\n\t\t\tself.label_map[class_name] = i\n\n\t\tself.reverse_label_map = {v: k for k, v in self.label_map.items()}\n\n\tdef path_yielder(self):\n\t\tfor class_name in tf.io.gfile.listdir(self.main_path):\n\t\t\tif not \"tfrecords\" in class_name:\n\t\t\t\tfor path_only in tf.io.gfile.listdir(self.main_path + class_name):\n\t\t\t\t\tyield (self.main_path + class_name + \"\/\" + path_only, self.label_map[class_name])\n\n\tdef image_loader(self, image):\n\t\timage = tf.io.read_file(image)\n\t\timage = tf.io.decode_jpeg(image, channels=3)\n\t\timage = tf.image.resize(image, (112, 112), method=\"nearest\")\n\t\timage = tf.image.random_flip_left_right(image)\n\n\t\treturn (tf.cast(image, tf.float32) - 127.5) \/ 128.\n\n\tdef mapper(self, path, label):\n\t\treturn (self.image_loader(path), label)\n\n\tdef __init__(self, main_path: str, batch_size: int = 16, buffer_size: int = 10000, epochs: int = 1,\n\t             reshuffle_each_iteration: bool = False, test_batch=64,\n\t             map_to: bool = True):\n\t\tself.main_path = main_path.rstrip(\"\/\") + \"\/\"\n\t\tself.make_label_map()\n\n\t\tself.dataset_test = None\n\t\tif test_batch > 0:\n\t\t\treshuffle_each_iteration = False\n\t\t\tprint(f\"[*] reshuffle_each_iteration set to False to create a appropriate test set, this may cancelled if tf.data will fixed.\")\n\n\t\tself.dataset = tf.data.Dataset.from_generator(self.path_yielder, (tf.string, tf.int64))\n\t\tif buffer_size > 0:\n\t\t\tself.dataset = self.dataset.shuffle(buffer_size, reshuffle_each_iteration=reshuffle_each_iteration, seed=42)\n\n\t\tif map_to:\n\t\t\tself.dataset = self.dataset.map(self.mapper, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\t\tself.dataset = self.dataset.batch(batch_size, drop_remainder=True)\n\n\t\tif test_batch > 0:\n\t\t\tself.dataset_test = self.dataset.take(int(test_batch))\n\t\t\tself.dataset = self.dataset.skip(int(test_batch))\n\n\t\tself.dataset = self.dataset.repeat(epochs)\n\n\nclass DataEngineTFRecord:\n\tdef image_loader(self, image_raw):\n\t\timage = tf.image.decode_jpeg(image_raw, channels=3)\n\t\timage = tf.image.resize(image, (112, 112), method=\"nearest\")\n\t\timage = tf.image.random_flip_left_right(image)\n\n\t\treturn (tf.cast(image, tf.float32) - 127.5) \/ 128.\n\n\tdef mapper(self, tfrecord_data):\n\t\tfeatures = {'image_raw': tf.io.FixedLenFeature([], tf.string), 'label': tf.io.FixedLenFeature([], tf.int64)}\n\t\tfeatures = tf.io.parse_single_example(tfrecord_data, features)\n\n\t\treturn self.image_loader(features['image_raw']), tf.cast(features['label'], tf.int64)\n\n\tdef __init__(self, tf_record_path: str, batch_size: int = 16, epochs: int = 10, buffer_size: int = 50000,\n\t             reshuffle_each_iteration: bool = True,\n\t             test_batch=64, map_to: bool = True):\n\t\tself.dataset_test = None\n\t\tif test_batch > 0:\n\t\t\treshuffle_each_iteration = False\n\t\t\tprint(\n\t\t\t\tf\"[*] reshuffle_each_iteration set to False to create a appropriate test set, this may cancelled if tf.data will fixed.\")\n\t\tself.tf_record_path = tf_record_path\n\n\t\tself.dataset = tf.data.TFRecordDataset(self.tf_record_path)\n\t\tif buffer_size > 0:\n\t\t\tself.dataset = self.dataset.shuffle(buffer_size, reshuffle_each_iteration=reshuffle_each_iteration, seed=42)\n\n\t\tif map_to:\n\t\t\tself.dataset = self.dataset.map(self.mapper, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\t\tself.dataset = self.dataset.batch(batch_size, drop_remainder=True)\n\n\t\tif test_batch > 0:\n\t\t\tself.dataset_test = self.dataset.take(int(test_batch))\n\t\t\tself.dataset = self.dataset.skip(int(test_batch))\n\n\t\tself.dataset = self.dataset.repeat(epochs)","a4c55637":"import os\nimport cv2\nimport bcolz\nimport numpy as np\nimport tensorflow as tf\nimport tqdm\nfrom sklearn.model_selection import KFold\n\n\ndef l2_norm(x, axis=1):\n    \"\"\"l2 norm\"\"\"\n    norm = np.linalg.norm(x, axis=axis, keepdims=True)\n    output = x \/ norm\n\n    return output\n\n\ndef get_val_pair(path, name):\n    carray = bcolz.carray(rootdir=os.path.join(path, name), mode='r')\n    issame = np.load('{}\/{}_list.npy'.format(path, name))\n\n    return carray, issame\n\n\ndef get_lfw_data(data_path):\n    \"\"\"get validation data\"\"\"\n    _lfw, _lfw_issame = get_val_pair(data_path, 'lfw_align_112\/lfw')\n\n    return _lfw, _lfw_issame\n\n\ndef get_val_data(data_path):\n    \"\"\"get validation data\"\"\"\n    _lfw, _lfw_issame = get_val_pair(data_path, 'lfw_align_112\/lfw')\n    _agedb_30, _agedb_30_issame = get_val_pair(data_path, 'AgeDB\/agedb_30')\n    _cfp_fp, _cfp_fp_issame = get_val_pair(data_path, 'cfp_align_112\/cfp_fp')\n\n    return _lfw, _agedb_30, _cfp_fp, _lfw_issame, _agedb_30_issame, _cfp_fp_issame\n\n\ndef hflip_batch(imgs):\n    return imgs[:, :, ::-1, :]\n\n\ndef calculate_accuracy(threshold, dist, actual_issame):\n    predict_issame = np.less(dist, threshold)\n    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n    tn = np.sum(np.logical_and(np.logical_not(predict_issame),\n                               np.logical_not(actual_issame)))\n    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n\n    tpr = 0 if (tp + fn == 0) else float(tp) \/ float(tp + fn)\n    fpr = 0 if (fp + tn == 0) else float(fp) \/ float(fp + tn)\n    _acc = float(tp + tn) \/ dist.size\n    return tpr, fpr, _acc\n\n\ndef calculate_roc(thresholds, embeddings1, embeddings2, actual_issame,\n                  nrof_folds=10):\n    assert (embeddings1.shape[0] == embeddings2.shape[0])\n    assert (embeddings1.shape[1] == embeddings2.shape[1])\n    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n    nrof_thresholds = len(thresholds)\n    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n\n    tprs = np.zeros((nrof_folds, nrof_thresholds))\n    fprs = np.zeros((nrof_folds, nrof_thresholds))\n    accuracy = np.zeros((nrof_folds,))\n    best_thresholds = np.zeros((nrof_folds,))\n    indices = np.arange(nrof_pairs)\n\n    diff = np.subtract(embeddings1, embeddings2)\n    dist = np.sum(np.square(diff), 1)\n\n    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n        # Find the best threshold for the fold\n        acc_train = np.zeros((nrof_thresholds,))\n        for threshold_idx, threshold in enumerate(thresholds):\n            _, _, acc_train[threshold_idx] = calculate_accuracy(\n                threshold, dist[train_set], actual_issame[train_set])\n        best_threshold_index = np.argmax(acc_train)\n\n        best_thresholds[fold_idx] = thresholds[best_threshold_index]\n        for threshold_idx, threshold in enumerate(thresholds):\n            tprs[fold_idx, threshold_idx], fprs[fold_idx, threshold_idx], _ = \\\n                calculate_accuracy(threshold,\n                                   dist[test_set],\n                                   actual_issame[test_set])\n        _, _, accuracy[fold_idx] = calculate_accuracy(\n            thresholds[best_threshold_index],\n            dist[test_set],\n            actual_issame[test_set])\n\n    tpr = np.mean(tprs, 0)\n    fpr = np.mean(fprs, 0)\n    return tpr, fpr, accuracy, best_thresholds\n\n\ndef evaluate(embeddings, actual_issame, nrof_folds=10):\n    # Calculate evaluation metrics\n    thresholds = np.arange(0, 4, 0.01)\n    embeddings1 = embeddings[0::2]\n    embeddings2 = embeddings[1::2]\n    tpr, fpr, accuracy, best_thresholds = calculate_roc(\n        thresholds, embeddings1, embeddings2, np.asarray(actual_issame),\n        nrof_folds=nrof_folds)\n\n    return tpr, fpr, accuracy, best_thresholds\n\n\ndef perform_val_arcface(embedding_size, batch_size, model,\n                        carray, issame, nrof_folds=10, is_ccrop=False, is_flip=True):\n    \"\"\"perform val\"\"\"\n    embeddings = np.zeros([len(carray), embedding_size])\n\n    for idx in tqdm.tqdm(range(0, len(carray), batch_size)):\n        batch = carray[idx:idx + batch_size]\n        batch = np.transpose(batch, [0, 2, 3, 1])\n        b, g, r = tf.split(batch, 3, axis=-1)\n        batch = tf.concat([r, g, b], -1)\n        if is_flip:\n            flipped = hflip_batch(batch)\n            emb_batch = model([batch, tf.ones((batch.shape[0],), dtype=tf.int64)], training=False)[-1] + model([flipped, tf.ones((batch.shape[0],), dtype=tf.int64)], training=False)[-1]\n            embeddings[idx:idx + batch_size] = l2_norm(emb_batch)\n        else:\n            emb_batch = model([batch, tf.ones((batch.shape[0],), dtype=tf.int64)], training=False)[-1]\n            embeddings[idx:idx + batch_size] = l2_norm(emb_batch)\n\n    tpr, fpr, accuracy, best_thresholds = evaluate(\n        embeddings, issame, nrof_folds)\n\n    return accuracy.mean(), best_thresholds.mean()\n\n\ndef perform_val(embedding_size, batch_size, model,\n                carray, issame, nrof_folds=10, is_ccrop=False, is_flip=True):\n    \"\"\"perform val\"\"\"\n    embeddings = np.zeros([len(carray), embedding_size])\n\n    for idx in tqdm.tqdm(range(0, len(carray), batch_size)):\n        batch = carray[idx:idx + batch_size]\n        batch = np.transpose(batch, [0, 2, 3, 1])\n        b, g, r = tf.split(batch, 3, axis=-1)\n        batch = tf.concat([r, g, b], -1)\n        if is_flip:\n            flipped = hflip_batch(batch)\n            emb_batch = model(batch, training=False) + model(flipped, training=False)\n            embeddings[idx:idx + batch_size] = l2_norm(emb_batch)\n        else:\n            emb_batch = model(batch, training=False)\n            embeddings[idx:idx + batch_size] = l2_norm(emb_batch)\n\n    tpr, fpr, accuracy, best_thresholds = evaluate(\n        embeddings, issame, nrof_folds)\n\n    return accuracy.mean(), best_thresholds.mean()","de1eea49":"class Trainer:\n\t@staticmethod\n\tdef get_wrong(y_real, y_pred):\n\t\treturn tf.where(tf.cast(tf.equal(tf.argmax(tf.nn.softmax(y_pred), -1), y_real), tf.float32) == 00)\n\n\t@staticmethod\n\tdef calculate_accuracy(y_real, y_pred):\n\t\treturn tf.reduce_mean(tf.cast(tf.equal(tf.argmax(tf.nn.softmax(y_pred), axis=1), y_real), dtype=tf.float32))\n\n\tdef only_test(self, dataset_test=None, display_wrong_images: bool = False):\n\t\tif dataset_test is None:\n\t\t\tif self.dataset_engine.dataset_test is None:\n\t\t\t\traise Exception(\"there is no defined test dataset\")\n\n\t\t\tdataset_test = self.dataset_engine.dataset_test\n\n\t\tacc_mean = tf.keras.metrics.Mean()\n\t\tloss_mean = tf.keras.metrics.Mean()\n\t\twrong_images = []\n\n\t\tfor i, (x, y) in enumerate(dataset_test):\n\t\t\tlogits, features, loss, reg_loss = self.model_engine.test_step_reg(x, y)\n\t\t\taccuracy = self.calculate_accuracy(y, logits)\n\t\t\tif accuracy < 1.0:\n\t\t\t\timages = x.numpy()[self.get_wrong(y, logits).numpy()][0]\n\t\t\t\t[wrong_images.append(image) for image in images]\n\n\t\t\tacc_mean(accuracy)\n\t\t\tloss_mean(loss)\n\n\t\t\tprint(f\"[*] Step {i}, Accuracy --> %{accuracy} || Loss --> {loss} || Reg Loss --> {reg_loss}\")\n\n\t\tif display_wrong_images and len(wrong_images) > 0:\n\t\t\tself.tensorboard_engine.initialize(delete_if_exists=False)\n\t\t\tprint(f\"[*] TensorBoard initialized on {self.tensorboard_engine.logdir}\")\n\n\t\t\tself.tensorboard_engine.add_images(f\"wrong images from 'only_test' function\", tf.convert_to_tensor(wrong_images), 0)\n\t\t\tprint(f\"[*] Wrong images({len(wrong_images)}) added to TensorBoard\")\n\n\t\tprint(f\"\\n\\n[*] Accuracy Mean --> %{acc_mean.result().numpy()} || Loss Mean --> {loss_mean.result().numpy()}\")\n\n\t\treturn acc_mean, loss_mean, wrong_images\n\n\tdef __init__(self, model_engine, dataset_engine, tensorboard_engine, use_arcface: bool,\n\t             learning_rate: float = 0.01,\n\t             model_path: str = \"classifier_model.tf\",\n\t             pooling_layer: tf.keras.layers.Layer = tf.keras.layers.GlobalAveragePooling2D,\n\t             lr_step_dict: dict = None,\n\t             optimizer: str = \"ADAM\", test_only_lfw: bool = True):\n\t\tself.model_path = model_path\n\t\tself.model_engine = model_engine\n\t\tself.dataset_engine = dataset_engine\n\t\tself.tensorboard_engine = tensorboard_engine\n\t\tself.use_arcface = use_arcface\n\t\tself.lr_step_dict = lr_step_dict\n\n\t\tself.num_classes = 85742  # 85742 for MS1MV2, 10575 for Casia, 105 for MINE\n\t\ttf.io.gfile.makedirs(\"\/\".join(self.model_path.split(\"\/\")[:-1]))\n\n\t\tself.tb_delete_if_exists = True\n\t\tif self.use_arcface:\n\t\t\tif not test_only_lfw:\n\t\t\t\tself.lfw, self.agedb_30, self.cfp_fp, self.lfw_issame, self.agedb_30_issame, self.cfp_fp_issame = get_val_data(\"..\/datasets\/\")\n\t\t\telse:\n\t\t\t\tself.lfw, self.lfw_issame = get_lfw_data(\"\/content\/\")\n\n\t\tif self.lr_step_dict is not None:\n\t\t\tprint(\"[*] LEARNING RATE WILL BE CHECKED WHEN step\\\\alfa_divided_ten == 0\")\n\t\t\tlearning_rate = list(self.lr_step_dict.values())[0]\n\n\t\tself.model_engine(\n\t\t\tinput_shape=(112, 112, 3),\n\t\t\tweights=None,  # \"imagenet\" or None, not available for InceptionResNetV1\n\t\t\tnum_classes=self.num_classes,  # 85742 for MS1MV2, 10575 for Casia, 105 for MINE\n\t\t\tlearning_rate=learning_rate,\n\t\t\tregularizer_l=5e-4,  # weight decay, train once with 5e-4 and then try something lower such 1e-5\n\t\t\tpooling_layer=pooling_layer,  # Recommended: Flatten\n\t\t\tcreate_model=True,  # if you have a H5 file with config set this to zero and load model to self.model_engine.model\n\t\t\tuse_arcface=self.use_arcface,  # set False if you want to train it as regular classification\n\t\t\tweight_path=self.model_path,  # paths of weights file(h5 or tf), it is okay if doesn't exists\n\t\t\toptimizer=optimizer  # Recommended: SGD\n\t\t)\n\n\tdef test_on_val_data(self, is_ccrop: bool = False, step_i: int = 1, alfa_multiplied_ten: int = 1):\n\t\tstep = int(alfa_multiplied_ten \/ step_i)\n\n\t\tprint(\"-----------------------------------\")\n\t\tacc_lfw, best_th = perform_val_arcface(512, 64, self.model_engine.model, self.lfw, self.lfw_issame, is_ccrop=is_ccrop)\n\t\tprint(f\"[*] Results on LFW, Accuracy --> {acc_lfw} || Best Threshold --> {best_th}\")\n\t\tprint(\"-----------------------------------\")\n\t\tself.tensorboard_engine.add_with_step({\"LFW\": acc_lfw}, step=step)\n\n\tdef __call__(self, max_iteration: int = None, alfa_step=1000, qin: int = 10):\n\t\tif max_iteration is not None and max_iteration <= 0:\n\t\t\tmax_iteration = None\n\n\t\talfa_divided_ten = int(alfa_step \/ 10)\n\t\talfa_multiplied_qin = int(alfa_step * qin)\n\n\t\tprint(f\"[*] Possible maximum step: {tf.data.experimental.cardinality(self.dataset_engine.dataset)}\\n\")\n\n\t\tacc_mean = tf.keras.metrics.Mean()\n\t\tloss_mean = tf.keras.metrics.Mean()\n\n\t\tself.tensorboard_engine.initialize(\n\t\t\tdelete_if_exists=self.tb_delete_if_exists\n\t\t)\n\t\tprint(f\"[*] TensorBoard initialized on {self.tensorboard_engine.logdir}\")\n\n\t\tfor i, (x, y) in enumerate(self.dataset_engine.dataset):\n\t\t\tlogits, features, loss, reg_loss = self.model_engine.train_step_reg(x, y)\n\t\t\taccuracy = self.calculate_accuracy(y, logits)\n\t\t\tacc_mean(accuracy)\n\t\t\tloss_mean(loss)\n\n\t\t\tself.tensorboard_engine({\"loss\": loss, \"reg_loss\": reg_loss, \"accuracy\": accuracy})\n\n\t\t\tif i % alfa_divided_ten == 0:\n\t\t\t\tif i % alfa_step == 0 and i > 10:\n\t\t\t\t\tself.model_engine.model.save_weights(self.model_path)\n\t\t\t\t\tprint(f\"[{i}] Model saved to {self.model_path}\")\n\n\t\t\t\tprint(f\"[{i}] Loss: {loss_mean.result().numpy()} || Reg Loss: {reg_loss.numpy()} || Accuracy: %{acc_mean.result().numpy()} || LR: {self.model_engine.optimizer.learning_rate.numpy()}\")\n\t\t\t\tacc_mean.reset_states()\n\t\t\t\tloss_mean.reset_states()\n\t\t\t\tif self.lr_step_dict is not None:\n\t\t\t\t\tlower_found = False\n\t\t\t\t\tfor key in self.lr_step_dict:\n\t\t\t\t\t\tif i < int(key):\n\t\t\t\t\t\t\tlower_found = True\n\t\t\t\t\t\t\tlr_should_be = self.lr_step_dict[key]\n\t\t\t\t\t\t\tif lr_should_be != self.model_engine.last_lr:\n\t\t\t\t\t\t\t\tself.model_engine.change_learning_rate_of_optimizer(lr_should_be)\n\t\t\t\t\t\t\t\tprint(f\"[{i}] Learning Rate set to --> {lr_should_be}\")\n\n\t\t\t\t\t\t\tbreak\n\n\t\t\t\t\tif not lower_found:\n\t\t\t\t\t\tprint(f\"[{i}] Reached to given maximum steps in 'lr_step_dict'({list(self.lr_step_dict.keys())[-1]})\")\n\t\t\t\t\t\tself.model_engine.model.save_weights(self.model_path)\n\t\t\t\t\t\tprint(f\"[{i}] Model saved to {self.model_path}, end of training.\")\n\t\t\t\t\t\tbreak\n\n\t\t\t\tif i % alfa_multiplied_qin == 0 and self.dataset_engine.dataset_test is not None and i > 10:\n\t\t\t\t\tfor x_test, y_test in self.dataset_engine.dataset_test:\n\t\t\t\t\t\tlogits, features, loss, reg_loss = self.model_engine.test_step_reg(x_test, y_test)\n\t\t\t\t\t\taccuracy = self.calculate_accuracy(y, logits)\n\n\t\t\t\t\t\tself.tensorboard_engine({\"val. loss\": loss, \"val. accuracy\": accuracy})\n\n\t\t\t\t\t\tacc_mean(accuracy)\n\t\t\t\t\t\tloss_mean(loss)\n\n\t\t\t\t\tprint(f\"[{i}] Val. Loss --> {loss_mean.result().numpy()} || Val. Accuracy --> %{acc_mean.result().numpy()}\")\n\t\t\t\t\tacc_mean.reset_states()\n\t\t\t\t\tloss_mean.reset_states()\n\n\t\t\t\tif i % alfa_multiplied_qin == 0 and self.use_arcface and i > 10:\n\t\t\t\t\tself.test_on_val_data(False, i, alfa_multiplied_qin)\n\t\t\t\t\tself.save_final_model()\n\t\t\t\t\tprint(\"[*] Final model saved\")\n\n\t\t\t\tif max_iteration is not None and i >= max_iteration:\n\t\t\t\t\tprint(f\"[{i}] Reached to given maximum iteration({max_iteration})\")\n\t\t\t\t\tself.model_engine.model.save_weights(self.model_path)\n\t\t\t\t\tprint(f\"[{i}] Model saved to {self.model_path}, end of training.\")\n\t\t\t\t\tbreak\n\n\t\tif max_iteration is None:\n\t\t\tprint(f\"[*] Reached to end of dataset\")\n\t\t\tself.model_engine.model.save_weights(self.model_path)\n\t\t\tprint(f\"[*] Model saved to {self.model_path}, end of training.\")\n\n\tdef save_final_model(self, path: str = \"arcface_final.h5\", n: int = -4):\n\t\tm = tf.keras.models.Model(self.model_engine.model.layers[0].input, self.model_engine.model.layers[n].output)\n\n\t\tm.save(path)\n\t\tprint(f\"[*] Final feature extractor saved to {path}\")","d35d0754":"%load_ext tensorboard.notebook\n%tensorboard --logdir classifier_tensorboard --port 8008","8a5f490f":"TDOM = DataEngineTFRecord(\n  \"faces_emore\/tran.tfrecords\",\n  batch_size=128,\n  epochs=-1,  # set to -1 so it can stream forever\n  buffer_size=30000,\n  reshuffle_each_iteration=True,\n  test_batch=0  # set to 0 if you are using ArcFace\n)  # TDOM for \"Tensorflow Dataset Object Manager\"","e665d81e":"TBE = TensorBoardCallback(\n  logdir=\"classifier_tensorboard\"\n)  # TBE for TensorBoard Engine","2050725a":"ME = ResNet50()  # Model architecture, ResNet50 Recommended","4787d980":"k_value: float = 4.  # recommended --> (512 \/ TDOM.batch_size)\ntrainer = Trainer(\n  model_engine=ME,\n  dataset_engine=TDOM,\n  tensorboard_engine=TBE,\n  use_arcface=True,\n  learning_rate=0.004,\n  model_path=\"my_ms1m_arcResnetIR50\/model.tf\",\n  optimizer=\"SGD\",\n  lr_step_dict={\n    int(60000 * k_value): 0.004,\n    int(80000 * k_value): 0.0005,\n    int(100000 * k_value): 0.0003,\n    int(110000 * k_value): 0.0001,\n  },\n  pooling_layer=tf.keras.layers.Flatten\n)\n\ntrainer(max_iteration=-1, alfa_step=5000, qin=2)\ntrainer.save_final_model(path=\"my_ms1m_arcResnetIR50_arcface_final.h5\")","4082beee":"## The Right GPU\n\n  - It is better if you train with *Tesla P100*, Kaggle provides this GPU alongside worse ones. You will need some luck. You re-set the session(**Run -> Restart Session**) until you get *Tesla P100*. With ```!nvidia-smi``` command you can see the given GPU \ud83e\udd16\ud83e\udd16\ud83e\udd16\n\n  - The main reason we need *Tesla P100* is because it has 16GB VRAM \ud83d\ude35 ","7ae624d2":"# **ArcFace Training From Scratch**\n\n*Created by [Burak Toy](https:\/\/twitter.com\/tyburakk) in 2020*\n\n<br>\n\nArcFace is a *facial recognition* method that published with [this](https:\/\/arxiv.org\/abs\/1801.07698) paper. The original repository shared on [this GitHub page](https:\/\/github.com\/deepinsight\/insightface). It was written in MxNet and lots of third party implementations with different frameworks published since then. This is an implementation with TensorFlow 2.x and GitHub repository for this implementation can be found [here](https:\/\/github.com\/aangfanboy\/deepface\/tree\/master\/face_recognition)\n\n**With this kernel, anyone can understand the concept of face recognition and train a state-of-the-art(%99.7 LFW Accuracy) facial recogniton model in 48 hours.**\n\n**Code will be explanined step by step  \ud83d\ude07\ud83d\ude07\ud83d\ude07**\n\n---\n\n## **Results**\n\n<p align=\"center\">\ud83e\udd70If you finish training, you will get the same model as shown in below\ud83e\udd70<\/p>\n\n| Download Link                                                        | Architecture                                                 | Epochs | LFW Acc | AgeDB Acc | CFP Acc |\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ------ | ------- | --------- | ------- |\n| [Google Drive](https:\/\/drive.google.com\/open?id=1qUtjhrYDMRqc2lRPNBV1ftkbyIPmTJYp) | L_Resnet50_E_IR                | 7      | %99.70  | %96.75    | %97.34  |\n\n<br>\n<br>\n\n- In this gif I tested model for my favourite professor [Gilbert Strang](https:\/\/en.wikipedia.org\/wiki\/Gilbert_Strang) and my favourite podcaster [Lex Fridman](https:\/\/lexfridman.com\/)  \ud83d\ude0b\n\n<div align=\"center\">\n  <img src=\"https:\/\/raw.githubusercontent.com\/aangfanboy\/deepface\/master\/images-and-figures\/gil_lex_gif.gif\">\n<\/div>\n\n<br>\n\n\n- I made an applicaton that creates a database with faces you upload. App also can detect age, sex, ethnicity and the possibilty that image could be a [deepfake](https:\/\/en.wikipedia.org\/wiki\/Deepfake). It is all open-source [on GitHub](https:\/\/github.com\/aangfanboy\/deepface)  \ud83e\udd73 \ud83e\udd73 \ud83e\udd73 \n\n\n<div align=\"center\">\n  <img src=\"https:\/\/raw.githubusercontent.com\/aangfanboy\/deepface\/master\/images-and-figures\/liyana_1-2-0.png\">\n<\/div>\n\n<br>\n\n\n- In [this](https:\/\/www.kaggle.com\/hereisburak\/arcface-face-recognition) Kaggle Kernel, I use trained model on [Pins Face Recognition Dataset](https:\/\/www.kaggle.com\/hereisburak\/pins-face-recognition) to visualize 17472 different faces that belongs 105 different celebrity on 3D Space. See how great that works \ud83d\ude0d  Please visit the kernel for more details.\n\n<div align=\"center\">\n  <img src=\"https:\/\/raw.githubusercontent.com\/aangfanboy\/deepface\/master\/images-and-figures\/pins_tb_mf_example.jpg\">\n<\/div>\n\n<br>\n<br>\n\n\n<b><p align=\"center\"> \ud83e\udd17 Let's start then! \ud83e\udd17 <\/p><\/b>","c221e96e":"## Downloading LFW Dataset\n\n- We will use LFW as test dataset. LFW is the main criteria for the evaluation of face recognition models.\n\n- We will use google drive while downloading dataset so code will ask you to login with your Google account.\n\n- After downloading code will unzip the dataset and delete the zip file.","7b26bd91":"## Defining a Test Script for LFW\n\n- This code will test our face recognition model on LFW dataset that we downloaded earlier \ud83e\uddea\ud83e\uddea\ud83e\uddea","59870601":"## Defining a Main Trainer\n\n- This is the piece of code that will optimize everything and train the model. \n\n<br>\n\n**PS:** Parameters supported with comments in ```__init__``` function.","c047ca95":"# Training Scripts\n\nWe will write the necesarry code for training an ArcFace Model \u2328\ufe0f\u2328\ufe0f\u2328\ufe0f","21956978":"## Creating TFRecord\n\n- I will use [TFRecord](https:\/\/www.tensorflow.org\/tutorials\/load_data\/tfrecord) dataset type, because it is fast \ud83d\udca8\ud83d\udca8\ud83d\udca8","567b7777":"## Defining TensorBoard\n\n- We will use TensorBoard to graph the change in loss and accuracy","c1254355":"## UnZipping and Installing Libraries\n\n- First 2 lines of code below will unzip dataset and delete *.zip* file.\n\n- Other 3 lines of code will install libraries needed \ud83d\udcda\ud83d\udcda\ud83d\udcda\n\n<br>\n\n**PS:** *MxNet* will be used for dataset processing, this is an implementation with *TensorFlow* ","a9fb3f21":"## Defining LResNet-x-IR Model Architecture\n\n- We will use a slightly different version of typical ResNet. The cells below will create model architectures \ud83d\udcd0\ud83d\udcd0\ud83d\udcd0","900786ae":"I use TensorFlow 2.x and the command below will load last available version of TensorFlow 2","d68962cd":"## Defining ArcFace Layer\n\n**Yes, ArcFace is *not* a loss function. It is a layer!**\n\nPlease visit [paper](https:\/\/arxiv.org\/abs\/1801.07698) for more details on ArcFace \ud83e\uddee\ud83e\uddee\ud83e\uddee\n\n<br>\n\n![ArcFace](https:\/\/d3i71xaburhd42.cloudfront.net\/9fc17fa5708584fa848164461f82a69e97f6ed69\/1-Figure1-1.png)\n\n\n<br>\n\nBut simply, that is what ArcFace method does. It creates a gap between inter-classes. This way, model gets better as a discriminator and be the perfect choice for [one shot learning](https:\/\/en.wikipedia.org\/wiki\/One-shot_learning)","870d6c2d":"\n## Downloading the Dataset\n\n  - I recommend **ms1m-arcface** but you are welcome to choose another dataset. Visit this [page](https:\/\/github.com\/aangfanboy\/deepface\/tree\/master\/datasets) for more options. \n\n  - The command ```!wget -O casia_webface.zip https:\/\/www.dropbox.com\/s\/wpx6tqjf0y5mf6r\/faces_ms1m-refine-v2_112x112.zip?dl=1``` will download **ms1m-arcface** but if you want to download another dataset; get its dropbox link, replace *dl=0* with *dl=1* at the end of url. Here is your new link  \ud83d\udc4c \ud83d\udc4c \n\n","a7d220be":"# Setting the Environment\n\nThere are couple of things we need to do for training process \ud83d\udd0b\ud83d\udd0b\ud83d\udd0b\n\n<br>\n\n**PS:** Make sure Internet is on and Accelerator chosen as GPU\n\n","14111f62":"## Starting TensorBoard\n\n- I mentioned that we will be using TensorBoard to graph loss and accuracy values. The code below will run TensorBoard and you will be able to see graphs when main trainer starts working.","48198cad":"Everything is ready! \ud83d\ude80\ud83d\ude80\ud83d\ude80\n\nThe cell below will start training. Model will be tested on LFW dataset at every 10K step and results will be both printed and displayed in TensorBoard. \n\n**If you have a question\/problem, visit the [main repo of project](https:\/\/github.com\/aangfanboy\/deepface) and create an issue \ud83d\ude00\ud83d\ude00\ud83d\ude00**","bc7e35f2":"## Starting the Training Process\n\n- Cells below will start the training with given parameters. Parameters supported with comments so you are welcome to change. But if you want to get the same results that I did, leave them be. ","614b12ab":"## Defining a Data Pipeline\n\n- We will need a data pipeline to stream face images to model for both training and testing. We will use TFRecord data type and [TensorFlow Dataset Object](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/data\/Dataset) for this task.\n\n<br>\n\n**PS:** TensorFlow Dataset Object is a great choice because since we train our model with also TensorFlow it will optimize the data flow and won't waste a single time.\n\n<br>\n\n![](https:\/\/cdn.evrimagaci.org\/cijSuJJlXRqWQYmIqiu4KudlAv4=\/2000x0\/filters:no_upscale():format(webp)\/evrimagaci.org%2Fpublic%2Fcontent_media%2Fe009f74bd09a8f70926a1f6fcf9c116c.png)"}}