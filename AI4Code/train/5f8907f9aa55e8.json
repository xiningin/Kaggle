{"cell_type":{"bec9f169":"code","1010c735":"code","f88856ff":"code","7713f2c7":"code","1d2573a8":"code","2c5682ef":"code","e63dfecb":"code","b3506f96":"code","d918901e":"code","b0ce9c1e":"code","1b6314bd":"code","3ef40c70":"code","3cbf03c2":"code","4320cf7e":"code","2d5f5b42":"code","c76054ee":"code","3a376c61":"code","17eadcb4":"code","c1de9816":"code","5b30214c":"code","00775c56":"code","d7dfc1f3":"code","5bef6ab1":"code","d39ac47a":"code","a174d5b9":"code","82b7d364":"code","6496bac0":"code","c59212b7":"code","de99c8a1":"code","c0493bf6":"code","c605a37f":"code","697461b3":"code","496477a4":"code","f5dbc3e2":"code","dbf4ee15":"code","672334c2":"code","1debd956":"code","9df3bcec":"code","9972b7ad":"code","2ee978b6":"code","e902295e":"code","7f9a9965":"code","d7c58825":"code","5aeb5419":"code","1019185f":"code","ad6ca94e":"code","7f01cc2a":"code","8104735b":"code","1a4a6f52":"code","93a3fa26":"code","1b239cd4":"code","a5fdca39":"code","09ef71ed":"code","342b8bbc":"code","d4e81d56":"code","09e20e6b":"code","d84df493":"markdown","2818ba96":"markdown","1b3119bf":"markdown","dec2cb29":"markdown","f30ef9f9":"markdown","b12501fc":"markdown","20e9cba6":"markdown","420805e5":"markdown","eff4f8bd":"markdown","16ad614b":"markdown","ad699d4c":"markdown","7607acd9":"markdown","61a6add7":"markdown","a4b107d2":"markdown","a2e8b693":"markdown","84ca2a26":"markdown","6345d332":"markdown","39fc152d":"markdown","fc77cf4c":"markdown","671c808c":"markdown","8880f5a8":"markdown","f8bfb963":"markdown","bcdcc14a":"markdown"},"source":{"bec9f169":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1010c735":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing","f88856ff":"happy = pd.read_csv(\"\/kaggle\/input\/world-happiness-report-2021\/world-happiness-report-2021.csv\")","7713f2c7":"happy.head()","1d2573a8":"happy.isna().sum()","2c5682ef":"# how many countries?\nhappy['Country name'].value_counts()","e63dfecb":"sns.set_theme()\n\nsns.relplot(\n    data=happy,\n    x='Ladder score', \n    y='Healthy life expectancy', \n    hue='Regional indicator')","b3506f96":"# seperate out the top 25\ntop_25 = happy[:25]\n\ng = sns.relplot(\n    data=top_25,\n    x='Ladder score', \n    y='Healthy life expectancy',\n    hue='Regional indicator')","d918901e":"print(top_25['Regional indicator'].value_counts())\nprint(happy['Regional indicator'].value_counts())","b0ce9c1e":"g = sns.lmplot(x='Logged GDP per capita',\n              y='Social support',\n              hue='Regional indicator', \n              col='Regional indicator',\n              col_wrap=3,\n              data=happy, \n              height=6)","1b6314bd":"sns.set_theme(style=\"white\")\nax = sns.heatmap(happy[happy.columns[13:19]].corr()).set_title(\"All Countries\")","3ef40c70":"sns.set_theme(style=\"white\")\nax = sns.heatmap(top_25[top_25.columns[13:19]].corr()).set_title(\"'Happiest' 25 Countries\")","3cbf03c2":"train_dataset = happy.sample(frac=0.8, random_state=0)\ntest_dataset = happy.drop(train_dataset.index)","4320cf7e":"sns.pairplot(train_dataset[['Logged GDP per capita', 'Social support', \n                            'Healthy life expectancy', 'Freedom to make life choices', \n                           'Generosity', 'Perceptions of corruption']], diag_kind='kde')","2d5f5b42":"train_dataset.describe().transpose()","c76054ee":"train_features = train_dataset.copy()\ntest_features = test_dataset.copy()\n\n# we'll also drop these values that we don't need and will skew the results\ntrain_features.drop(columns=['Country name', 'Regional indicator', \n                             'Standard error of ladder score', 'upperwhisker', 'lowerwhisker',\n                            'Ladder score in Dystopia', 'Dystopia + residual'], inplace=True)\ntest_features.drop(columns=['Country name', 'Regional indicator', \n                             'Standard error of ladder score', 'upperwhisker', 'lowerwhisker',\n                            'Ladder score in Dystopia', 'Dystopia + residual'], inplace=True)\n\ntrain_labels = train_features.pop('Ladder score')\ntest_labels = test_features.pop('Ladder score')","3a376c61":"# first, let's get a whole dataset normalizer\nnormalizer = preprocessing.Normalization()\nnormalizer.adapt(np.array(train_features))","17eadcb4":"print(normalizer.mean.numpy())","c1de9816":"first = np.array(train_features[:1])","5b30214c":"with np.printoptions(precision=2, suppress=True):\n    print('First example:', first)\n    print()\n    print('Normalized:', normalizer(first).numpy())","00775c56":"life_exp = np.array(train_features['Explained by: Healthy life expectancy'])\n\nlife_exp_normalizer = preprocessing.Normalization(input_shape=[1,])\nlife_exp_normalizer.adapt(life_exp)","d7dfc1f3":"#and now the sequential model build\n\nlife_exp_model = tf.keras.Sequential([\n    life_exp_normalizer, \n    layers.Dense(units=1)\n])\n\nlife_exp_model.summary()","5bef6ab1":"life_exp_model.predict(life_exp[:10])","d39ac47a":"life_exp_model.compile(\n    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n    loss='mean_absolute_error')","a174d5b9":"%%time\nhistory = life_exp_model.fit(\n    train_features['Explained by: Healthy life expectancy'], train_labels, \n    epochs=100, \n    verbose=0, \n    validation_split=0.2)","82b7d364":"hist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist.tail()","6496bac0":"def plot_loss(history):\n    plt.plot(history.history['loss'], label='loss')\n    plt.plot(history.history['val_loss'], label='val_loss')\n    plt.ylim([0, 10])\n    plt.xlabel('Epoch')\n    plt.ylabel('Error [Life Expectancy]')\n    plt.legend()\n    plt.grid(True)","c59212b7":"plot_loss(history)","de99c8a1":"test_results = {}\n\ntest_results['life_exp_model'] = life_exp_model.evaluate(\n    test_features['Explained by: Healthy life expectancy'], \n    test_labels, verbose=0)","c0493bf6":"x = tf.linspace(0.0, 1, 150)\ny = life_exp_model.predict(x)","c605a37f":"def plot_life_exp(x, y):\n    plt.scatter(train_features['Explained by: Healthy life expectancy'], train_labels, label='Data')\n    plt.plot(x, y, color='k', label='Predictions')\n    plt.xlabel('Life Expectancy')\n    plt.ylabel('Happiness Score')\n    plt.legend()\n","697461b3":"plot_life_exp(x,y)","496477a4":"linear_model = tf.keras.Sequential([\n    normalizer, \n    layers.Dense(units=1)\n])","f5dbc3e2":"linear_model.predict(train_features[:10])","dbf4ee15":"linear_model.layers[1].kernel","672334c2":"linear_model.compile(\n    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n    loss='mean_absolute_error')","1debd956":"%%time\nhistory = linear_model.fit(\n    train_features, \n    train_labels,\n    epochs=100,\n    verbose=0,\n    validation_split=0.2)","9df3bcec":"plot_loss(history)","9972b7ad":"test_results['linear_model'] = linear_model.evaluate(\ntest_features, test_labels, verbose=0)","2ee978b6":"def build_and_compile_model(norm):\n    model = keras.Sequential([\n        norm,\n        layers.Dense(64, activation='relu'),\n        layers.Dense(64, activation='relu'),\n        layers.Dense(1)\n  ])\n    model.compile(loss='mean_absolute_error',\n                  optimizer=tf.keras.optimizers.Adam(0.001))\n    return model","e902295e":"dnn_life_exp_model = build_and_compile_model(life_exp_normalizer)","7f9a9965":"dnn_life_exp_model.summary()","d7c58825":"%%time\nhistory = dnn_life_exp_model.fit(\n    train_features['Explained by: Healthy life expectancy'], train_labels, \n    validation_split=0.2,\n    verbose=0, \n    epochs=100)","5aeb5419":"plot_loss(history)","1019185f":"x = tf.linspace(0.0, 1, 150)\ny = dnn_life_exp_model.predict(x)","ad6ca94e":"plot_life_exp(x,y)","7f01cc2a":"test_results['dnn_life_exp_model'] = dnn_life_exp_model.evaluate(\n    test_features['Explained by: Healthy life expectancy'], \n    test_labels, \n    verbose=0)","8104735b":"dnn_model = build_and_compile_model(normalizer)\ndnn_model.summary()","1a4a6f52":"%%time\nhistory = dnn_model.fit(\n    train_features, \n    train_labels, \n    validation_split=0.2,\n    verbose=0,\n    epochs=100)","93a3fa26":"plot_loss(history)","1b239cd4":"test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)","a5fdca39":"pd.DataFrame(test_results, index=['Mean Absolute Error [Ladder score]']).T","09ef71ed":"group = ['yes', 'no', 'see']\n\nfor x in group: \n    print(x)","342b8bbc":"test_predictions = dnn_model.predict(test_features).flatten()\na = plt.axes(aspect='equal')\nplt.scatter(test_labels, test_predictions)\nplt.xlabel('True Values [Happiness Score]')\nplt.ylabel('Predictions [Happiness Score]')\nplt.title('DNN Model')\nlims = [2, 9]\nplt.xlim(lims)\nplt.ylim(lims)\n_ = plt.plot(lims, lims)","d4e81d56":"test_predictions = linear_model.predict(test_features).flatten()\n\na = plt.axes(aspect='equal')\nplt.scatter(test_labels, test_predictions)\nplt.xlabel('True Values [Happiness Score]')\nplt.ylabel('Predictions [Happiness Score]')\nplt.title('Linear Model')\nlims = [2, 9]\nplt.xlim(lims)\nplt.ylim(lims)\n_ = plt.plot(lims, lims)","09e20e6b":"error = test_predictions - test_labels\nplt.hist(error, bins=25)\nplt.xlabel('Prediction Error [Happiness Score]')\n_ = plt.ylabel('Count')","d84df493":"<h1> TensorFlow: Basic Regression <\/h1>\n\nWe'll test a few models to see which one does the best in this situation. We'll take the attributes and use a regression to predict the output of the \"happiness\" scale. I chose the \"Ladder score\" as the output variable. \n- single input\n- linear model\n- dnn model (single input)\n- dnn model (multiple input)","2818ba96":"This model predicts the <code> Ladder Score <\/code> from <code> Life Expectancy <\/code>","1b3119bf":"***","dec2cb29":"Western Europe looks like quite a nice place to be, but we'll have to compare the total countries versus the top_25 countries. 4 out of 4 is just as good as 15 out of 15. ","f30ef9f9":"<h2> 1. Linear Regression Model <\/h2>\n\nI'm choosing Life Expectancy as our single-variable linear regression. It seems to be an okay indicator of happiness. ","b12501fc":"It sure appears that the linear model has the best mean absolute error score here. Sometimes a DNN model can overfit, and I think that's what has happened here. The data only include 119 countries, so it's not a lot of data for a machine learning algorithm. ","20e9cba6":"<h3> Let's take a look at the data <\/h3>","420805e5":"<h1>Any missing values?<\/h1>","eff4f8bd":"![laughing-girl-showing-thumbs-up-picture-id505175324.jpg](attachment:7efd03f9-a493-47c0-9a5d-52f0dc986fb3.jpg)","16ad614b":"The report primarily uses data from the Gallup World Poll. Each annual report is available to the public to download on the World Happiness Report website. (Wikipedia)\n \n\nThe World Happiness Report uses markers to indicate the happiness of each country. It is collected to create a \"Ladder Score\" and then it is eventually changed to include a \"Dystopia + residual\" score. The main indicators include...\n\n- GDP per capita\n- Social Support\n- Life Expectancy\n- Freedom of Life Choices\n- Generosity\n- Perception of Corruption\n\n\nThe 2020 World Happiness Report, released on March 20, 2020, ranks 156 countries based on an average of three years of surveys between 2017 and 2019. The 2020 report especially focuses on the environment \u2013 social, urban, and natural, and includes links between happiness and sustainable development. (Wikipedia)","ad699d4c":"It appears the Columns have already been normalized by using the \"Explained by:\" characteristic. We'll take that at face value and move onto the next parts. However, we'll run a Normalization through the data as well to make sure we've done our part. It shouldn't affect the predictions. ","7607acd9":"The scores in both East Asia and North America and ANZ of **Social Support actually goes down when the GDP per capita increases.** That's a bit strange. I guess it's shows us that money will \"buy happiness\" up to a certain amount. But that also doesn't help us identify why Western Europe is doing so well. ","61a6add7":"<h2> Multiple Inputs (Linear Regression) <\/h2>","a4b107d2":"Well, this is clear. Western Europe does a great job as a happiness indicator. However, i fyou look closely you can see that North America and ANZ probably have a better overall happiness score. ","a2e8b693":"<h2> DNN Regression Model <\/h2>","84ca2a26":"I wanna take a closer look at who the top 25 countries are in terms of <code> Healthy life expectancy <\/code> and the <code> Ladder score <\/code>","6345d332":"<h2> Separate the Target Value <code>'Ladder score'<\/code> from the labels","39fc152d":"<h3> Full Model - using all the inputs <\/h3> \nHopefully this will improve the performance. ","fc77cf4c":"<h1 style=\"text-align:center;\"> The World Happiness Report <\/h1>","671c808c":"![maslow-pyramid.jpg](attachment:1b167658-51ba-4c3e-a1fa-e6e904aabf89.jpg)","8880f5a8":"# Some *GRAPHS* to get us started","f8bfb963":"A quick look at these graphs shows us that once the GDP, Healthy Life Style, and Social Interactions are met, then people tend to focus more on extrernal things like **Perceptions of corruption**. That fits nicely into...\n- Maslow's Hierarchy of Needs","bcdcc14a":"Sources: \n\nhttps:\/\/en.wikipedia.org\/wiki\/World_Happiness_Report"}}