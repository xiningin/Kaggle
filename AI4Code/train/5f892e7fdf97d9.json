{"cell_type":{"6cd9f782":"code","216633ad":"code","1de3966b":"code","6324bbb8":"code","ca56df9c":"code","630777ae":"code","650e6628":"code","74592d2d":"code","8e3d0806":"code","10648b5c":"code","dc51b3c5":"code","dc583337":"code","642f507a":"code","935fb148":"code","536534cd":"code","defebdba":"code","005ec021":"code","0f3567fa":"code","ab641c06":"code","c316aadd":"code","0f54cc36":"code","5bf5dfbb":"code","619e2a30":"code","a4020c9a":"code","405c8122":"code","b424037c":"code","859bb09f":"code","fb2c1b8f":"code","44e8deb3":"code","9150d8b9":"markdown","7542ca2d":"markdown","a1f3622b":"markdown","b9f22da2":"markdown","884fc1d8":"markdown","3a55e96d":"markdown","b66985e9":"markdown","63d2f11a":"markdown","de85523d":"markdown"},"source":{"6cd9f782":"import os\nimport random\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn.metrics\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img","216633ad":"base_dir = os.path.join(\"\/kaggle\/input\/kermany2018\/oct2017\/OCT2017 \/\")\nprint('Base directory --> ', os.listdir(base_dir))","1de3966b":"train_dir = os.path.join(base_dir + \"train\/\")\nprint(\"Train Directory --> \", os.listdir(train_dir))\n\nvalidation_dir = os.path.join(base_dir + \"val\/\")\nprint(\"Validation Directory --> \", os.listdir(validation_dir))\n\ntest_dir = os.path.join(base_dir + \"test\/\")\nprint(\"Test Directory --> \", os.listdir(test_dir))","6324bbb8":"vgg19 = tf.keras.applications.VGG19(\n    include_top = False, \n    weights = 'imagenet', \n    input_tensor = None,\n    input_shape = (150,150,3), \n    pooling = None, \n    classes = 1000\n)","ca56df9c":"mobile_net_v2 = tf.keras.applications.MobileNetV2(\n    include_top = False, \n    weights = 'imagenet', \n    input_tensor = None,\n    input_shape = (150,150,3), \n    pooling = None, \n    classes = 1000\n)","630777ae":"vgg19.trainable = False\nmobile_net_v2.trainable = False # locking initial layer weights of the imported models","650e6628":"model_vgg = tf.keras.models.Sequential([\n    \n    vgg19,\n    tf.keras.layers.Conv2D(128, kernel_size = (3, 3), padding = 'same'),\n    tf.keras.layers.PReLU(alpha_initializer='zeros'),# modifying final layers of VGG-19\n    tf.keras.layers.Conv2D(64, kernel_size = (3, 3), padding = 'same'),\n    tf.keras.layers.PReLU(alpha_initializer='zeros'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100),\n    tf.keras.layers.PReLU(alpha_initializer='zeros'),\n    tf.keras.layers.Dense(4, activation = 'softmax')\n])","74592d2d":"model_mobile = tf.keras.models.Sequential([\n    \n    mobile_net_v2,\n    tf.keras.layers.Conv2D(128, kernel_size = (3, 3), padding = 'same'),\n    tf.keras.layers.PReLU(alpha_initializer='zeros'),# modifying final layers of VGG-19\n    tf.keras.layers.Conv2D(64, kernel_size = (3, 3), padding = 'same'),\n    tf.keras.layers.PReLU(alpha_initializer='zeros'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100),\n    tf.keras.layers.PReLU(alpha_initializer='zeros'),\n    tf.keras.layers.Dense(4, activation = 'softmax')\n])","8e3d0806":"metrics = ['accuracy',\n                tf.keras.metrics.AUC(),\n                tfa.metrics.CohenKappa(num_classes = 4),\n                tfa.metrics.F1Score(num_classes = 4),\n                tf.keras.metrics.Precision(), \n                tf.keras.metrics.Recall()]","10648b5c":"model_vgg.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = metrics)\nmodel_vgg.summary()","dc51b3c5":"model_mobile.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = metrics)\nmodel_mobile.summary()","dc583337":"train_datagen = ImageDataGenerator(rescale = 1.\/255)\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 500)","642f507a":"validation_datagen = ImageDataGenerator(rescale = 1.\/255)\nvalidation_generator = validation_datagen.flow_from_directory(validation_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 16)","935fb148":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_generator = test_datagen.flow_from_directory(test_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 50)","536534cd":"!nvidia-smi","defebdba":"history_vgg = model_vgg.fit(\n    train_generator,\n    steps_per_epoch = (83484\/500),\n    epochs = 20,\n    validation_data = validation_generator,\n    validation_steps = (32\/16),\n    max_queue_size=100,\n    workers = 4 ,\n    use_multiprocessing=True,\n    verbose = 1)","005ec021":"history_mobile = model_mobile.fit(\n    train_generator,\n    steps_per_epoch = (83484\/500),\n    epochs = 20,\n    validation_data = validation_generator,\n    validation_steps = (32\/16),\n    max_queue_size=100,\n    workers = 4 ,\n    use_multiprocessing=True,\n    verbose = 1)","0f3567fa":"print(\"Values for VGG-19 based ConvNet\")\nacc = history_vgg.history['accuracy']\nval_acc = history_vgg.history['val_accuracy']\nloss = history_vgg.history['loss']\nval_loss = history_vgg.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.figure(figsize=(12,12))\n\nplt.plot(epochs, acc, 'r', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\nplt.title('Training & validation accuracy')\nplt.legend()\n\nplt.figure(figsize = (12,12))\n\nplt.plot(epochs, loss, 'r', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training $ validation loss')\nplt.legend()\n\nplt.show()","ab641c06":"print(\"Values for MobileNet-V2 based ConvNet\")\nacc = history_mobile.history['accuracy']\nval_acc = history_mobile.history['val_accuracy']\nloss = history_mobile.history['loss']\nval_loss = history_mobile.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.figure(figsize=(12,12))\n\nplt.plot(epochs, acc, 'r', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\nplt.title('Training & validation accuracy')\nplt.legend()\n\nplt.figure(figsize = (12,12))\n\nplt.plot(epochs, loss, 'r', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training & validation loss')\nplt.legend()\n\nplt.show()","c316aadd":"model_vgg.evaluate(test_generator)","0f54cc36":"model_mobile.evaluate(test_generator)","5bf5dfbb":"test_steps_per_epoch = np.math.ceil(test_generator.samples \/ test_generator.batch_size)\n\npredictions = model_vgg.predict_generator(test_generator, steps = test_steps_per_epoch)\n\npredicted_classes = np.argmax(predictions, axis=1)","619e2a30":"true_classes = test_generator.classes\nclass_labels = list(test_generator.class_indices.keys())  ","a4020c9a":"report = sklearn.metrics.classification_report(true_classes, predicted_classes, target_names = class_labels)\nprint(report) ","405c8122":"cm = sklearn.metrics.confusion_matrix(true_classes, predicted_classes)\nplt.figure(figsize=(8,8))\nsns.heatmap(cm, fmt='.0f', annot=True, linewidths=0.2, linecolor='purple')\nplt.xlabel('predicted value')\nplt.ylabel('Truth value')\nplt.show()","b424037c":"test_steps_per_epoch = np.math.ceil(test_generator.samples \/ test_generator.batch_size)\n\npredictions = model_mobile.predict_generator(test_generator, steps = test_steps_per_epoch)\n\npredicted_classes = np.argmax(predictions, axis=1)","859bb09f":"true_classes = test_generator.classes\nclass_labels = list(test_generator.class_indices.keys()) ","fb2c1b8f":"report = sklearn.metrics.classification_report(true_classes, predicted_classes, target_names = class_labels)\nprint(report) ","44e8deb3":"cm = sklearn.metrics.confusion_matrix(true_classes, predicted_classes)\nplt.figure(figsize=(8,8))\nsns.heatmap(cm, fmt='.0f', annot=True, linewidths=0.2, linecolor='purple')\nplt.xlabel('predicted value')\nplt.ylabel('Truth value')\nplt.show()","9150d8b9":"# Defining transfer learning models VGG-19 and Mobilenet-V2","7542ca2d":"# Loading training, validation and test data","a1f3622b":"# Importing dataset ","b9f22da2":"# Loss and accuracy vs epochs","884fc1d8":"# Training the models","3a55e96d":"# VGG19 model classification report","b66985e9":"# Defining the models","63d2f11a":"# Mobilenet model classification report","de85523d":"# Models evaluated"}}