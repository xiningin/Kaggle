{"cell_type":{"b100b332":"code","7b15a34c":"code","f806c997":"code","522d27af":"code","5e76276a":"code","eb7199a1":"code","25e42026":"markdown","8977b423":"markdown"},"source":{"b100b332":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7b15a34c":"#code part 4\nimg_rows, img_cols = 224, 224 #number of rows and columns to convert the images to\ninput_shape = (img_rows, img_cols, 3)#format to store the images (rows, columns,channels) called channels last\n\ndef url_to_image(url):\n    # download the image, convert it to a NumPy array, and then read\n    # it into OpenCV format\n    resp = urllib.request.urlopen(url)\n    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n\n    # return the image\n    return image\n\n#%clear base_model\n\nimport tensorflow as tf\n\nbase_model = tf.keras.applications.ResNet50(input_shape=(224,224, 3),weights='imagenet', include_top = False)\nx = base_model.output\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\nx = tf.keras.layers.Dense(512, activation='relu')(x)\npreds = tf.keras.layers.Dense(2, activation ='softmax')(x)\n\nmodel = tf.keras.models.Model(inputs=base_model.input, outputs=preds)\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\ntrain_datagen = ImageDataGenerator()\nvalid_datagen = ImageDataGenerator()\n    \ntrain_generator = train_datagen.flow_from_directory(\n        '..\/input\/autistic-children-data-set-traintestvalidate\/train',\n        classes=['autistic','non_autistic'],\n        target_size=(img_rows, img_cols),#The target_size is the size of your input images,every image will be resized to this size\n        batch_size=32,\n        class_mode='categorical')\n\nvalid_generator = valid_datagen.flow_from_directory(\n        '..\/input\/autistic-children-data-set-traintestvalidate\/valid',\n        classes=['autistic','non_autistic'],        \n        target_size=(img_rows, img_cols),#The target_size is the size of your input images,every image will be resized to this size\n        batch_size=32,\n        class_mode='categorical')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\n\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\nprint(\"***********train****\")\n\nhistory = model.fit(\n      train_generator,\n      steps_per_epoch=train_generator.n\/\/train_generator.batch_size,\n      epochs=5,\n      validation_data=valid_generator,\n      validation_steps=25)\n\nprint(\"***********test****\")\ntest_datagen = ImageDataGenerator()\n\ntest_generator = test_datagen.flow_from_directory(\n        '..\/input\/autistic-children-data-set-traintestvalidate\/test',\n        classes=['autistic','non_autistic'],\n        target_size=(374, 374),#The target_size is the size of your input images,every image will be resized to this size\n        batch_size=32,\n        class_mode='categorical')\n_,accuracy =model.evaluate(test_generator)\nprint('Accuracy test: %.2f' % (accuracy*100))  \n","f806c997":"_,accuracyT =model.evaluate(train_generator)\nprint('Accuracy train: %.2f' % (accuracyT*100))  \n","522d27af":"from matplotlib import pyplot as plt\n\n# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.show()","5e76276a":"history2 = model.fit(\n      train_generator,\n      steps_per_epoch=train_generator.n\/\/train_generator.batch_size,\n      epochs=5,\n      validation_data=test_generator,\n      validation_steps=25)\n\nprint(\"***********test****\")\ntest_datagen = ImageDataGenerator()\n\ntest_generator = test_datagen.flow_from_directory(\n        '..\/input\/autistic-children-data-set-traintestvalidate\/test',\n        classes=['autistic','non_autistic'],\n        target_size=(374, 374),#The target_size is the size of your input images,every image will be resized to this size\n        batch_size=32,\n        class_mode='categorical')\n_,accuracy =model.evaluate(test_generator)\nprint('Accuracy test: %.2f' % (accuracy*100))  \n\nfrom matplotlib import pyplot as plt\n\n# list all data in history\n#print(history.keys())\n# summarize history for accuracy\nplt.plot(history2.history['accuracy'])\nplt.plot(history2.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history2.history['loss'])\nplt.plot(history2.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","eb7199a1":"history.history.keys()","25e42026":"https:\/\/github.com\/mueedhafiz1982\/CNNTreeEnsemble\/blob\/master\/code\/4Class-Classification\/ImageNet\/baseline_resnet50.py","8977b423":"# train test"}}