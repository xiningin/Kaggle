{"cell_type":{"7af3ae8f":"code","48470e3e":"code","b805a0e6":"code","d9efdf05":"code","975ea1a7":"code","0894ce06":"code","b741c19d":"code","eabf347e":"code","f5227f46":"code","c3250ccb":"code","e90cbf34":"code","2ad15eba":"code","674776fb":"code","412f286c":"code","54bfcc0c":"code","fe94f2a7":"code","1e08cdaf":"code","ace4b8d4":"code","e9f904a2":"code","2ce714b9":"code","594dcf12":"code","661a5b05":"markdown","8cd82d51":"markdown","9e5ada06":"markdown","e73acfed":"markdown"},"source":{"7af3ae8f":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport glob\nimport cv2\nimport random\nfrom tqdm import notebook\nfrom multiprocessing import Pool\nfrom PIL import Image\nimport imageio\n\nfrom tensorflow import keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import *\nfrom keras.callbacks import ModelCheckpoint\nimport keras.backend as K\nimport tensorflow as tf\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator \nfrom sklearn.model_selection import train_test_split","48470e3e":"HEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nN_CLASSES = 13\nBATCH_SIZE = 32\nEPOCHS = 100","b805a0e6":"src_dir = '..\/input\/lyft-udacity-challenge'","d9efdf05":"input_imgs_names = []\nmask_names = []\n\nfor i in ['A', 'B', 'C', 'D', 'E']:\n    input_imgs_names += glob.glob(os.path.join(src_dir, f'data{i}\/data*\/CameraRGB\/*.png'))\n    mask_names += glob.glob(os.path.join(src_dir, f'data{i}\/data*\/CameraSeg\/*.png'))\n\nnum_samples = len(mask_names)\n\ntrain_imgs, val_imgs, train_masks, val_masks = train_test_split(input_imgs_names, mask_names, train_size=0.8, random_state=0) ","975ea1a7":"def split_img(mask_img):    \n    new_mask_img = np.zeros((mask_img.shape[0], mask_img.shape[1], 13))\n    \n    for j in range(13):\n        for k in range(mask_img.shape[0]):\n            for l in range(mask_img.shape[1]):\n                if mask_img[k,l,2] == j:\n                    new_mask_img[k,l,j] = j\n    return new_mask_img\n\ndef give_color_to_seg_img(seg, n_classes=N_CLASSES):\n    seg_img = np.zeros( (seg.shape[0],seg.shape[1], 3) ).astype('float')\n    colors = sns.color_palette(\"hls\", n_classes)\n    \n    for c in range(n_classes):\n        segc = (seg == c)\n        seg_img[:,:,0] += (segc*( colors[c][0] ))\n        seg_img[:,:,1] += (segc*( colors[c][1] ))\n        seg_img[:,:,2] += (segc*( colors[c][2] ))\n\n    return(seg_img)","0894ce06":"index = random.randint(0, num_samples-1)\n\nimg = cv2.imread(input_imgs_names[index])\nmask = cv2.imread(mask_names[index])[:, :, 2]\nmask_color = give_color_to_seg_img(mask)\n\nplt.figure(figsize=(20, 6))\nplt.subplot(131)\nplt.imshow(img)\nplt.title('Original')\nplt.axis('off')\n\nplt.subplot(132)\nplt.imshow(mask)\nplt.title('Mask')\nplt.axis('off')\n\nplt.subplot(133)\nplt.imshow(img \/ 255. + mask_color * 0.5)\nplt.title('Mask Image')\nplt.axis('off')","b741c19d":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, img_filenames,\n                 mask_filenames,\n                 batch_size=BATCH_SIZE,\n                 shuffle=True):\n\n        self.img_filenames = img_filenames\n        self.mask_filenames = mask_filenames\n        self.filenames = list(zip(img_filenames, mask_filenames))\n        self.batch_size = BATCH_SIZE\n        self.shuffle= shuffle\n        self.n = len(self.img_filenames)\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            random.shuffle(self.filenames)\n\n    def __get_data(self, batches):\n        imgs=[]\n        segs=[]\n        for img_file, mask_file in batches:\n            image = cv2.imread(img_file)\n            image = cv2.resize(image, (WIDTH, HEIGHT))\n            image = image \/ 255.\n            \n            mask = cv2.imread(mask_file)\n            mask = cv2.resize(mask, (WIDTH, HEIGHT))[:, :, 2]\n\n            imgs.append(image)\n            segs.append(mask)\n\n        return np.array(imgs), np.array(segs)\n    \n    def __getitem__(self, index):\n\n        batches = self.filenames[index * self.batch_size:(index + 1) * self.batch_size]\n\n        X, y = self.__get_data(batches)\n\n        return (X, y)\n\n    def __len__(self):\n\n        return self.n \/\/ self.batch_size","eabf347e":"train_gen = DataGenerator(train_imgs, train_masks)\nval_gen = DataGenerator(val_imgs, val_masks)","f5227f46":"for x, y in train_gen:\n    break\nx.shape, y.shape","c3250ccb":"plt.figure(figsize=(12, 6))\nplt.subplot(121)\nplt.imshow(x[0])\nplt.title('Original')\nplt.axis('off')\n\nplt.subplot(122)\nplt.imshow(y[0])\nplt.title('Mask')\nplt.axis('off')","e90cbf34":"def UNet():\n\n    main_input = Input(shape=(HEIGHT, WIDTH, CHANNELS), name = 'img_input')\n\n    ''' ~~~~~~~~~~~~~~~~~~~ ENCODING LAYERS ~~~~~~~~~~~~~~~~~~~ '''\n\n    c1 = Conv2D(32, kernel_size=(3,3), padding = 'same')(main_input)\n    c1 = LeakyReLU(0.2)(c1)\n    c1 = BatchNormalization()(c1)\n    c1 = Conv2D(32, kernel_size=(3,3), padding = 'same')(c1)\n    c1 = LeakyReLU(0.2)(c1)\n    c1 = BatchNormalization()(c1)\n\n    p1 = MaxPooling2D((2,2))(c1)\n\n    c2 = Conv2D(32*2, kernel_size=(3,3), padding = 'same')(p1)\n    c2 = LeakyReLU(0.2)(c2)\n    c2 = BatchNormalization()(c2)\n    c2 = Conv2D(32*2, kernel_size=(3,3), padding = 'same')(c2)\n    c2 = LeakyReLU(0.2)(c2)\n    c2 = BatchNormalization()(c2)\n\n    p2 = MaxPooling2D((2,2))(c2)\n\n    c3 = Conv2D(32*4, kernel_size=(3,3), padding = 'same')(p2)\n    c3 = LeakyReLU(0.2)(c3)\n    c3 = BatchNormalization()(c3)\n    c3 = Conv2D(32*2, kernel_size=(1,1), padding = 'same')(c3)\n    c3 = LeakyReLU(0.2)(c3)\n    c3 = BatchNormalization()(c3)\n    c3 = Conv2D(32*4, kernel_size=(3,3), padding = 'same')(c3)\n    c3 = LeakyReLU(0.2)(c3)\n    c3 = BatchNormalization()(c3)\n\n    p3 = MaxPooling2D((2,2))(c3)\n\n    c4 = Conv2D(32*6, kernel_size=(3,3), padding = 'same')(p3)\n    c4 = LeakyReLU(0.2)(c4)\n    c4 = BatchNormalization()(c4)\n    c4 = Conv2D(32*4, kernel_size=(1,1), padding = 'same')(c4)\n    c4 = LeakyReLU(0.2)(c4)\n    c4 = BatchNormalization()(c4)\n    c4 = Conv2D(32*6, kernel_size=(3,3), padding = 'same')(c4)\n    c4 = LeakyReLU(0.2)(c4)\n    c4 = BatchNormalization()(c4)\n\n    p4 = MaxPooling2D((2,2))(c4)\n\n    c5 = Conv2D(32*6, kernel_size=(3,3), padding = 'same')(p4)\n    c5 = LeakyReLU(0.2)(c5)\n    c5 = BatchNormalization()(c5)\n\n\n    ''' ~~~~~~~~~~~~~~~~~~~ DECODING LAYERS ~~~~~~~~~~~~~~~~~~~ '''\n\n    u1 = UpSampling2D((2,2))(c5)\n    concat1 = concatenate([c4, u1])\n\n    c6 = Conv2D(32*4, kernel_size=(3,3), padding = 'same')(concat1)\n    c6 = LeakyReLU(0.2)(c6)\n    c6 = BatchNormalization()(c6)\n    c6 = Conv2D(32*4, kernel_size=(3,3), padding = 'same')(c6)\n    c6 = LeakyReLU(0.2)(c6)\n    c6 = BatchNormalization()(c6)\n\n\n    u2 = UpSampling2D((2,2))(c6)\n    concat2 = concatenate([c3, u2])\n\n    c7 = Conv2D(32*2, kernel_size=(3,3), padding = 'same')(concat2)\n    c7 = LeakyReLU(0.2)(c7)\n    c7 = BatchNormalization()(c7)\n    c7 = Conv2D(32*2, kernel_size=(3,3), padding = 'same')(c7)\n    c7 = LeakyReLU(0.2)(c7)\n    c7 = BatchNormalization()(c7)\n\n    u3 = UpSampling2D((2,2))(c7)\n    concat3 = concatenate([c2, u3])\n\n    c8 = Conv2D(32, kernel_size=(3,3), padding = 'same')(concat3)\n    c8 = LeakyReLU(0.2)(c8)\n    c8 = BatchNormalization()(c8)\n    c8 = Conv2D(32, kernel_size=(3,3), padding = 'same')(c8)\n    c8 = LeakyReLU(0.2)(c8)\n    c8 = BatchNormalization()(c8)\n\n    u4 = UpSampling2D((2,2))(c8)\n    concat4 = concatenate([c1, u4])\n\n    c9 = Conv2D(16, kernel_size = (1,1), padding = 'same')(concat4)\n    c9 = LeakyReLU(0.2)(c9)\n    c9 = BatchNormalization()(c9)\n\n    mask_out = Conv2D(13, (1,1), padding = 'same', activation = 'sigmoid', name = 'mask_out')(c9)\n\n    model = Model(inputs = [main_input], outputs = [mask_out])\n    \n    return model","2ad15eba":"model = UNet()\nmodel.summary()","674776fb":"plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","412f286c":"def lrfn(epoch):\n    if epoch > 15:\n        return 2e-4\n    elif epoch > 25:\n        return 1e-4\n    return 1e-3","54bfcc0c":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])","fe94f2a7":"# Learning rate callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: lrfn(step))\n# Model checkpoint, saves weights if val loss reduces\ncheckpoint =tf.keras.callbacks.ModelCheckpoint('model.h5', 'val_loss', save_best_only=True, save_weights_only=True, verbose=1)","1e08cdaf":"train_steps = len(train_gen)\nval_steps = len(val_gen)\n\nhistory = model.fit(train_gen, validation_data=val_gen, \n                    steps_per_epoch=train_steps, validation_steps=val_steps, \n                    epochs = 30, verbose=1, callbacks=[checkpoint, lr_callback])","ace4b8d4":"plt.figure()\nplt.plot(history.history['accuracy'], label = 'Train acc')\nplt.plot(history.history['val_accuracy'], label = 'Val acc')\nplt.title('Accuracy')\nplt.legend()\n\nplt.figure()\nplt.plot(history.history['loss'], label = 'Train loss')\nplt.plot(history.history['val_loss'], label = 'Val loss')\nplt.title('loss')\nplt.legend()","e9f904a2":"model.save_weights('lastest.h5')\nmodel.load_weights('model.h5')","2ce714b9":"test_gen = DataGenerator(val_imgs, val_masks, 1)","594dcf12":"max_show = 12\ntest_iter = iter(test_gen)\nfor i in range(max_show):\n    images, masks = next(test_iter)\n    mask_color = give_color_to_seg_img(masks[0])\n\n    preds = model.predict(images)\n    pred_masks = np.argmax(preds, axis = 3)\n    pred_mask_color = give_color_to_seg_img(pred_masks[0])\n    fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n    \n    for a in ax:\n        a.axis('off')\n\n    ax[0].imshow(images[0])\n    ax[0].set_title('Original')\n    \n    ax[1].imshow(images[0] * 0.5 + pred_mask_color * 0.5)\n    ax[1].set_title('Prediction')\n    \n    ax[2].imshow(images[0] * 0.5 + mask_color * 0.5)\n    ax[2].set_title('Ground truth')\n    plt.savefig(f\"pred_{i}.jpg\", dpi=150)\n    plt.show()","661a5b05":"# Training","8cd82d51":"# Training history","9e5ada06":"# Prepare dataset","e73acfed":"# Validations"}}