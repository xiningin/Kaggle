{"cell_type":{"39e62471":"code","bd015ecd":"code","dc2bef03":"code","026c7d1c":"code","0c550ddd":"code","3f05bb20":"code","67ce847d":"code","c6ea4886":"code","20714e69":"code","a63ad43e":"code","c986f25e":"code","bdb551ee":"code","c6ef7f43":"code","bca103de":"code","99b3b344":"code","15955e31":"code","0c8bc18c":"code","a6919edb":"code","9921a58f":"code","d5be2cfe":"code","7224bb40":"code","319d6f86":"code","697b5d24":"code","c0092f61":"code","a5840863":"code","357cf0cd":"code","9bf309a9":"code","e6f999cf":"code","8f5247e5":"code","69e9f4ae":"code","cb4dcf83":"code","21da2230":"code","ddf08fb4":"code","f18dc21d":"code","49e048f1":"code","5659f477":"code","02655e28":"code","786c894e":"code","babc4b4b":"code","cb4b28f2":"code","7ccc8dd5":"code","cf1f57e4":"code","280befb9":"code","b7ebadd6":"code","d8332a45":"code","1b9c5fb7":"code","3e2f59cc":"markdown","97632207":"markdown","3daedf30":"markdown","fbc304b9":"markdown","0ae6ef32":"markdown","7add68ce":"markdown","25d47b57":"markdown","8bf71973":"markdown","2b618bb3":"markdown","169fe1ac":"markdown","0f9977b9":"markdown","d2da745d":"markdown","e6360ca6":"markdown","acd55a97":"markdown","19ecf1e5":"markdown","5ab06282":"markdown","bd052f96":"markdown","adc5fb8a":"markdown","bd2caae6":"markdown","4e99e304":"markdown","4394d514":"markdown","04201c3b":"markdown","f52545c2":"markdown","bfe1e821":"markdown","1e8d43e1":"markdown","6ff3b007":"markdown","fcd6f361":"markdown"},"source":{"39e62471":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten,GlobalAveragePooling2D,BatchNormalization, Activation\nimport glob\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\n\n\nimport os\n\n# from tensorflow.compat.v1 import ConfigProto\n# from tensorflow.compat.v1 import InteractiveSession\n# config = ConfigProto()\n# config.gpu_options.allow_growth = True\n# session = InteractiveSession(config=config)\n","bd015ecd":"from tensorflow.keras.mixed_precision import experimental as mixed_precision\npolicy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\nmixed_precision.set_policy(policy)","dc2bef03":"SEED = 42\nDEBUG = False\n\nos.environ['PYTHONHASHSEED'] = str(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","026c7d1c":"df = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\ndf.head()","0c550ddd":"df.label.unique()","3f05bb20":"df['path'] = '..\/input\/cassava-leaf-disease-classification\/train_images\/' + df['image_id']\ndf.label.value_counts(normalize=True) * 100\n","67ce847d":"if DEBUG:\n    _, df = train_test_split(df, test_size = 0.1, random_state=SEED, shuffle=True, stratify=df['label'])\n","c6ea4886":"X_train, X_valid = train_test_split(df, test_size = 0.1, random_state=SEED, shuffle=True)","20714e69":"train_ds = tf.data.Dataset.from_tensor_slices((X_train.path.values, X_train.label.values))\nvalid_ds = tf.data.Dataset.from_tensor_slices((X_valid.path.values, X_valid.label.values))","a63ad43e":"for path, label in train_ds.take(5):\n    print ('Path: {}, Label: {}'.format(path, label))","c986f25e":"for path, label in valid_ds.take(5):\n    print ('Path: {}, Label: {}'.format(path, label))","bdb551ee":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntarget_size_dim = 512","c6ef7f43":"def process_data_train(image_path, label):\n    # load the raw data from the file as a string\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.random_brightness(img, 0.3)\n    img = tf.image.random_flip_left_right(img, seed=None)\n    img = tf.image.random_flip_up_down(img)\n    #img = tf.image.random_crop(img, size=[target_size_dim, target_size_dim, 3])\n    return img, label\n\ndef process_data_valid(image_path, label):\n    # load the raw data from the file as a string\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [target_size_dim,target_size_dim])\n    return img, label\n","bca103de":"# Set `num_parallel_calls` so multiple images are loaded\/processed in parallel.\ntrain_ds = train_ds.map(process_data_train, num_parallel_calls=AUTOTUNE)\nvalid_ds = valid_ds.map(process_data_valid, num_parallel_calls=AUTOTUNE)","99b3b344":"for image, label in train_ds.take(1):\n    plt.imshow(image.numpy().astype('uint8'))\n    plt.show()\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","15955e31":"def configure_for_performance(ds, batch_size = 32):\n    ds = ds.cache('\/kaggle\/dump.tfcache') \n    \n    ds = ds.shuffle(buffer_size=1024)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n    return ds\n\nbatch_size = 8\n\ntrain_ds_batch = configure_for_performance(train_ds, batch_size)\nvalid_ds_batch = valid_ds.batch(batch_size)","0c8bc18c":"image_batch, label_batch = next(iter(train_ds_batch))","a6919edb":"\nplt.figure(figsize=(10, 10))\nfor i in range(8):\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n    label = label_batch[i].numpy()\n    plt.title(label)\n    plt.axis(\"off\")","9921a58f":"data_augmentation = keras.Sequential(\n    [\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2, interpolation='nearest'),\n        tf.keras.layers.experimental.preprocessing.RandomContrast((0.2 ))\n    ]\n)","d5be2cfe":"\nplt.figure(figsize=(10, 10))\nfor i in range(8):\n    augmented_images = data_augmentation(image_batch)\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(augmented_images[i].numpy().astype(\"uint8\"))\n    label = label_batch[i].numpy()\n    plt.title(label)\n    plt.axis(\"off\")","7224bb40":"## Only available in tf2.3+\n\nfrom tensorflow.keras.applications import EfficientNetB5\n","319d6f86":"def load_pretrained_model(weights_path, drop_connect, target_size_dim, layers_to_unfreeze=5):\n    model = EfficientNetB5(\n            weights=None, \n            include_top=False, \n            drop_connect_rate=0.2\n        )\n    \n    model.load_weights(weights_path)\n    \n    model.trainable = True\n\n    # for layer in model.layers[-layers_to_unfreeze:]:\n    #     if not isinstance(layer, tf.keras.layers.BatchNormalization): \n    #         layer.trainable = True\n\n    if DEBUG:\n        for layer in model.layers:\n            #print(layer.name, layer.trainable)\n            pass\n\n    return model\n\ndef build_my_model(base_model, optimizer, loss='sparse_categorical_crossentropy', metrics = ['sparse_categorical_accuracy']):\n    \n    inputs = tf.keras.layers.Input(shape=(target_size_dim, target_size_dim, 3))\n    x = data_augmentation(inputs)\n    outputs_eff = base_model(x)\n    global_avg_pooling = GlobalAveragePooling2D()(outputs_eff)\n    dense_1= Dense(256)(global_avg_pooling)\n    bn_1 = BatchNormalization()(dense_1)\n    activation = Activation('relu')(bn_1)\n    dropout = Dropout(0.3)(activation)\n    dense_2 = Dense(5)(dropout)\n    outputs = Activation('softmax', dtype='float32', name='predictions')(dense_2)\n\n    my_model = tf.keras.Model(inputs, outputs)\n    \n    my_model.compile(\n        optimizer=optimizer,\n        loss=loss,\n        metrics=metrics\n        \n    )\n    return my_model\n\n","697b5d24":"#!wget https:\/\/storage.googleapis.com\/keras-applications\/efficientnetb3_notop.h5\n## to get model weights","c0092f61":"#model_weights_path = '..\/input\/effnetb4-ns\/effnetb4_ns.h5'\nmodel_weights_path = '..\/input\/tfkerasefficientnetimagenetnotop\/efficientnetb5_notop.h5'\nmodel_weights_path","a5840863":"drop_rate = 0.2 ## value of dropout to be used in loaded network\nbase_model = load_pretrained_model( model_weights_path, drop_rate, target_size_dim )\n\noptimizer = tf.keras.optimizers.Adam(lr = 1e-3)\nmy_model = build_my_model(base_model, optimizer)\nmy_model.summary()","357cf0cd":"weight_path_save = 'best_model.hdf5'\nlast_weight_path = 'last_model.hdf5'\n\ncheckpoint = ModelCheckpoint(weight_path_save, \n                             monitor= 'val_loss', \n                             verbose=1, \n                             save_best_only=True, \n                             mode= 'min', \n                             save_weights_only = False)\ncheckpoint_last = ModelCheckpoint(last_weight_path, \n                             monitor= 'val_loss', \n                             verbose=1, \n                             save_best_only=False, \n                             mode= 'min', \n                             save_weights_only = False)\n\n\nearly = EarlyStopping(monitor= 'val_loss', \n                      mode= 'min', \n                      patience=5)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.00001)\ncallbacks_list = [checkpoint, checkpoint_last, early, reduceLROnPlat]","9bf309a9":"print('Compute dtype: %s' % policy.compute_dtype)\nprint('Variable dtype: %s' % policy.variable_dtype)","e6f999cf":"if DEBUG:\n    epochs = 3\nelse:\n    epochs = 12\n    \nprint(f\"Model will train for {epochs} epochs\")","8f5247e5":"if DEBUG:\n    history = my_model.fit(train_ds_batch, \n                              validation_data = valid_ds_batch, \n                              epochs = epochs, \n                              callbacks = callbacks_list,\n                               steps_per_epoch = 1,\n                               \n                           \n                              )\nelse:\n    history = my_model.fit(train_ds_batch, \n                              validation_data = valid_ds_batch, \n                              epochs = epochs, \n                              callbacks = callbacks_list\n                               \n                            \n                              )","69e9f4ae":"\ndef plot_hist(hist):\n    plt.figure(figsize=(15,5))\n    local_epochs = len(hist.history[\"sparse_categorical_accuracy\"])\n    plt.plot(np.arange(local_epochs, step=1), hist.history[\"sparse_categorical_accuracy\"], '-o', label='Train Accuracy',color='#ff7f0e')\n    plt.plot(np.arange(local_epochs, step=1), hist.history[\"val_sparse_categorical_accuracy\"], '-o',label='Val Accuracy',color='#1f77b4')\n    plt.xlabel('Epoch',size=14)\n    plt.ylabel('Accuracy',size=14)\n    plt.legend(loc=2)\n    \n    plt2 = plt.gca().twinx()\n    plt2.plot(np.arange(local_epochs, step=1) ,history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n    plt2.plot(np.arange(local_epochs, step=1) ,history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n    plt.legend(loc=3)\n    plt.ylabel('Loss',size=14)\n    plt.title(\"Model Accuracy and loss\")\n    \n    plt.savefig('loss.png')\n    plt.show()","cb4dcf83":"plot_hist(history)","21da2230":"from sklearn.metrics import confusion_matrix, classification_report","ddf08fb4":"my_model.load_weights(weight_path_save) ## load the best model or all your metrics would be on the last run not on the best one","f18dc21d":"pred_valid_y = my_model.predict(valid_ds_batch, workers=4, verbose = True)\npred_valid_y_labels = np.argmax(pred_valid_y, axis=-1)","49e048f1":"valid_labels = np.concatenate([y.numpy() for x, y in valid_ds_batch], axis=0)","5659f477":"\nprint(classification_report(valid_labels, pred_valid_y_labels ))","02655e28":"print(confusion_matrix(valid_labels, pred_valid_y_labels ))","786c894e":"import glob","babc4b4b":"test_images = glob.glob('..\/input\/cassava-leaf-disease-classification\/test_images\/*.jpg')\n#test_images = test_images * 5\nprint(test_images)","cb4b28f2":"df_test = pd.DataFrame(np.array(test_images), columns=['Path'])\ndf_test.head()","7ccc8dd5":"test_ds = tf.data.Dataset.from_tensor_slices((df_test.Path.values))\n\n\ndef process_test(image_path):\n    # load the raw data from the file as a string\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.random_brightness(img, 0.3)\n    img = tf.image.random_flip_left_right(img, seed=None)\n    img = tf.image.random_flip_up_down(img)\n    img = tf.image.random_crop(img, size=[target_size_dim, target_size_dim, 3])\n    return img\n    \ntest_ds = test_ds.map(process_test, num_parallel_calls=AUTOTUNE).batch(batch_size*2)","cf1f57e4":"preds = []\nfor i in range(5):\n    \n    pred_test = my_model.predict(test_ds, workers=16, verbose=1)\n    preds.append(pred_test)\n    ","280befb9":"pred_y = np.mean(preds, axis=0)","b7ebadd6":"#pred_y = my_model.predict(test_ds, workers=4)\npred_y_argmax = np.argmax(pred_y, axis=-1)","d8332a45":"df_test['image_id'] = df_test.Path.str.split('\/').str[-1]\ndf_test['label'] = pred_y_argmax\ndf_test= df_test[['image_id','label']]\ndf_test.head()","1b9c5fb7":"df_test.to_csv('submission.csv', index=False)","3e2f59cc":"## Data Augmentation","97632207":"## Creating Model","3daedf30":"changed reducelronplateau from facto 0.8 to 0.2.","fbc304b9":"Need to try out [ohem loss](https:\/\/github.com\/GXYM\/OHEM-loss).","0ae6ef32":"## Predictions + Test Time Augmentation","7add68ce":"Adding Seed helps to reproduce results. Setting Debug Parameter will run the model on smaller number of epochs to validate the architecture.","25d47b57":"## Update: 24\/11\n\n* Using EfficientNetB4\n* Using TTA * 5","8bf71973":"### Improving Performance","2b618bb3":"## Train Model","169fe1ac":"### Data Generator","0f9977b9":"## Update: 15\/11\n\n* Using Mixed Precision Training\n* Storing data cache in \/kaggle folder as it has more memory available","d2da745d":"increasing epoch number from 12 to 20. so finally this failed at 13th epoch. Sounds about right why it had 12 epochs!<br\/>","e6360ca6":"## Data Loader using tf.Data","acd55a97":"## Update: 14\/11\n\n* I was shuffling the validation dataset too, hence that was a bug. \n* Trying out NS.","19ecf1e5":"Distribution of dataset:","5ab06282":"## Evaluating Model on Validation Set","bd052f96":"My other Notebooks in this competition:\n\n1. EfficientNetB3 Training with Pure Keras\/tf2 ImageDataGenerator Method: [Link](https:\/\/www.kaggle.com\/harveenchadha\/efficientnetb3-keras-tf2-baseline-training)\n2. EfficientNetB3 Inference with Pure Keras\/tf2 ImageDataGenerator Method: [Link](https:\/\/www.kaggle.com\/harveenchadha\/efficientnetb3-baseline-inference-keras-tf2)","adc5fb8a":"## Mixed Precision Training","bd2caae6":"so there is a high imbalance in the dataset as we can see.","4e99e304":"### Callbacks","4394d514":"drop connect rate has been changed to 0.2 from 0.4 and now changing drop_rate also to 0.2.<br\/>\nusing b5 instead of b4.<br\/>\nincreased lr from 1e-4 to 1e-3.<br\/>","04201c3b":"![dia%20%281%29.png](attachment:dia%20%281%29.png)","f52545c2":"### Spliting Dataset","bfe1e821":"In this kernel I would use tf.data plus Keras to build a baseline, this type of baseline can be helpful to you in solving similar problems as well.","1e8d43e1":"## Important Points:\n\n1. ~~Due to Kaggle's space and RAM limitation, I could not make use of cache~~\n2. ~~With the use of Cache, I can confirm I have achieved a 5x speed than ImageDataGenerator. Maybe I will do a kernel will small subset of the data confirming the same.~~\n\nI am using cache now!","6ff3b007":"## Prepare Data","fcd6f361":"\n\n### If you learnt something from this kernel kindly upvote :) This keeps me motivated to produce more kernels."}}