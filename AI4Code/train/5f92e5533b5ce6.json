{"cell_type":{"3ce3d4d1":"code","8e4a791c":"code","47be412e":"code","8fa93b6f":"code","8a20ca10":"code","e7c17fe6":"code","b0d9d75e":"code","b65a4ae9":"code","bab07305":"code","3ec2b527":"code","f1907326":"code","4ebfcd26":"code","88fbb2dd":"code","e0ad18c2":"code","23842f08":"markdown"},"source":{"3ce3d4d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8e4a791c":"!pip install --upgrade pip\n!pip install torchsummary\n!pip install timm\n!pip install pytorch-lightning\n","47be412e":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torchvision\nfrom torch import nn\nimport torch.optim as optim\nfrom torchvision.transforms import transforms\nfrom torchvision.io import read_image\nfrom torch.utils import data\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torch.nn.functional as F\nfrom torchvision import models\nfrom torchsummary import summary\n\nfrom PIL import Image\nimport argparse\nimport matplotlib.image as mpimg\nimport glob\n\nimport timm\nfrom timm import create_model\n\nimport pytorch_lightning as pl\nfrom  pytorch_lightning import trainer","8fa93b6f":"BATCH_SIZE = 64\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(DEVICE)\nNUM_EPOCHS = 50\nlearning_rate = 1e-5\nNUM_WORKERS = 0","8a20ca10":"train_dir = '..\/input\/petfinder-pawpularity-score\/train\/'\ntest_dir = '..\/input\/petfinder-pawpularity-score\/test\/'\n\ntrain_csv = \"..\/input\/petfinder-pawpularity-score\/train.csv\"\ntest_csv = \"..\/input\/petfinder-pawpularity-score\/test.csv\"","e7c17fe6":"# Creating a dataframe for train data\ntrain_dataframe = pd.read_csv(train_csv)\ntrain_dataframe['Image Path'] =train_dataframe['Id'].astype(str) +'.jpg'\ntrain_dataframe['Image Path'] = train_dir + train_dataframe['Image Path'].astype(str)\n\ncat_features = train_dataframe.drop(['Pawpularity'], axis=1)\nstacking_order =[train_dataframe['Subject Focus'],train_dataframe['Eyes'],train_dataframe['Face'],train_dataframe['Near'],train_dataframe['Action'],train_dataframe['Accessory'],\n              train_dataframe['Group'],train_dataframe['Collage'],train_dataframe['Human'],train_dataframe['Occlusion'],train_dataframe['Info'],train_dataframe['Blur']]\n\n\n# Creating a dataframe for test data\ntest_dataframe = pd.read_csv(test_csv)\ntest_dataframe['Image Path'] =test_dataframe['Id'].astype(str) +'.jpg'\ntest_dataframe['Image Path'] = test_dir + test_dataframe['Image Path'].astype(str)\nstacking_order =[test_dataframe['Subject Focus'],test_dataframe['Eyes'],test_dataframe['Face'],test_dataframe['Near'],test_dataframe['Action'],test_dataframe['Accessory'],\n              test_dataframe['Group'],test_dataframe['Collage'],test_dataframe['Human'],test_dataframe['Occlusion'],test_dataframe['Info'],test_dataframe['Blur']]\n","b0d9d75e":"# Converting the categorical features into a tensor\ncat_features = np.stack(stacking_order,1)\ntrain_cat = torch.tensor(cat_features,dtype=torch.int64)\n\n\n# Converting the target values\nnum_classes = np.unique(train_dataframe['Pawpularity'].values).shape[0]\ntarget = train_dataframe['Pawpularity']\ntarget = torch.tensor(target,dtype = torch.float)\nnum_classes, target.size(0)","b65a4ae9":"mean = [0.485, 0.456, 0.406]\nstandard_dev = [0.229, 0.224, 0.225]\ntransformer = transforms.Compose([transforms.RandomHorizontalFlip(),\n                                  transforms.RandomVerticalFlip(),\n                                  transforms.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n                                  transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                                  transforms.ConvertImageDtype(torch.float),\n                                  transforms.Normalize(mean=mean, std=standard_dev),\n                                  transforms.ToTensor()\n                                 ])\n            ","bab07305":"class CustomDataset(Dataset):\n    def __init__(self,df):\n        self.df = df\n        self.transform = transforms.Resize([180,180])\n        self.y = df['Pawpularity']\n        self.image_path = df['Image Path']\n        \n    def __len__(self):\n        return self.y.shape[0]\n    \n    def __getitem__(self,index):        \n        # Images as a Tensor\n        img = read_image(self.image_path[index])\n        tensor_image = self.transform(img).float()\n\n        # Labels as a tensor\n        labels = self.y[index]\n    \n        return tensor_image,labels\n\nclass CustomTestDataset(Dataset):\n    def __init__(self,df):\n        self.df = df\n        self.transform = transforms.Resize([180,180])\n        self.image_path = df['Image Path']\n        \n    def __len__(self):\n        return self.image_path.shape[0]\n    \n    def __getitem__(self,index):\n        # Images as a Tensor\n        img = Image.open(self.image_path[index])\n        tensor_image = self.transform(img)\n          \n        # Labels as a tensor\n        labels = 0\n        \n        return tensor_image,labels","3ec2b527":"class LightningDataLoader(pl.LightningDataModule):\n    def __init__(self,df):\n        super().__init__()\n        self.df = df\n\n    \n    def create_dataloader(self,df,train):\n        if train:\n            images = CustomDataset(df)\n            return DataLoader(images,BATCH_SIZE,pin_memory=True,shuffle=False)\n        else :\n            images = CustomTestDataset(df)\n            return DataLoader(images,BATCH_SIZE,pin_memory=True,shuffle = False)\n    \n    def train_dataset(self):\n        return self.create_dataloader(self.df,train = True)\n    \n    def test_dataset(self):\n        return self.create_dataloader(self.df,train = False)\n    \n    \n        ","f1907326":"train_dataloader = LightningDataLoader(train_dataframe).train_dataset()\nimage, labels = iter(train_dataloader).next()\nprint(\"Shape of the input:\",image.shape)\nprint(\"Shape of the output labels:\",labels.shape)\nlosses = nn.BCEWithLogitsLoss()\n","4ebfcd26":"def mixup(x: torch.Tensor, y: torch.Tensor, alpha: float = 1.0):\n    assert alpha > 0, \"alpha should be larger than 0\"\n    assert x.size(0) > 1, \"Mixup cannot be applied to a single instance.\"\n\n    lam = np.random.beta(alpha, alpha)\n    rand_index = torch.randperm(x.size()[0])\n    mixed_x = lam * x + (1 - lam) * x[rand_index, :]\n    target_a, target_b = y, y[rand_index]\n    return mixed_x, target_a, target_b, lam\n\nclass Pawpularity_Model(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.build_model()\n        self.losses = losses\n        # init a pretrained resnet\n    def build_model(self):\n        self.backbone = create_model('resnet34',pretrained=True,num_classes =0, in_chans =3)\n        num_features = self.backbone.num_features\n        self.fc = nn.Sequential(nn.Dropout(0.5), nn.Linear(num_features,1))\n        \n\n    def forward(self, x):\n        f = self.backbone(x)\n        out = self.fc(f)\n        return out\n    \n    def training_step(self, dataloader, batch_idx):\n        loss, pred, labels = self.step(dataloader,mode = 'train')\n        return {'loss' : loss, 'pred' : pred, 'labels': labels}\n    \n    def configure_optimizers(self):\n        optimizer = optim.AdamW(self.parameters(),  1e-5)\n        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,20,eta_min=1e-4)\n        return [optimizer], [scheduler]\n    \n    def step(self, dataloader, mode):\n        images,labels = dataloader\n        labels = labels.float()\/100.0\n        mix_images, target_a, target_b, lam = mixup(images, labels, alpha=0.5)\n        logits = self.forward(mix_images).squeeze(1)\n        loss = self.losses(logits,target_a) * lam + \\\n        (1-lam)*self.losses(logits, target_b)\n        \n        pred = logits.sigmoid().detach().cpu()*100\n        labels = labels.detach().cpu()*100\n        return loss, pred, labels\n    ","88fbb2dd":"lightning_model = Pawpularity_Model().cuda()\nsummary(lightning_model,input_size =(3,180,180),batch_size=BATCH_SIZE)","e0ad18c2":"trainer = pl.Trainer(logger = True, max_epochs = NUM_EPOCHS,gpus =1)\n\ntrainer.fit(lightning_model,train_dataloaders =train_dataloader)","23842f08":"# Properties"}}