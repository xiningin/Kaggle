{"cell_type":{"566b1d95":"code","9403d240":"code","fa7e784e":"code","d9ce8019":"code","8e24e886":"code","66edc0be":"code","4b6519e9":"code","103dc68c":"code","d8e94dc2":"code","2abbb043":"code","ebdbb178":"code","3e1c81be":"code","9976daea":"code","ce2e7f61":"code","302da9fc":"code","ae3045ad":"code","4e89ff0b":"code","8d3e85c9":"code","181e6827":"code","625ac987":"code","14dda108":"code","cebeedc2":"code","117ca5a0":"code","6af52fa6":"code","9915b405":"code","d37f52f7":"code","89748f89":"code","bee31a86":"markdown","3323d282":"markdown","d972f39b":"markdown","b1837670":"markdown","78217dde":"markdown","e88bf909":"markdown","392ed31a":"markdown","ea701c9f":"markdown","06df24b7":"markdown","2e0d35e6":"markdown","da234fb6":"markdown","eae56b3c":"markdown","3f68e491":"markdown","244240f2":"markdown","a362d144":"markdown","3bac1e51":"markdown","c8846611":"markdown","e39dc602":"markdown"},"source":{"566b1d95":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns #plotting\nimport calendar\nfrom datetime import date\n\n","9403d240":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","fa7e784e":"# Distribution graphs (histogram\/bar graph) of column data\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) \/ nGraphPerRow\n    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()\n","d9ce8019":"# Correlation matrix\ndef plotCorrelationMatrix(df, graphWidth):\n    filename = df.dataframeName\n    df = df.dropna('columns') # drop columns with NaN\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n        return\n    corr = df.corr()\n    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n    corrMat = plt.matshow(corr, fignum = 1)\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.gca().xaxis.tick_bottom()\n    plt.colorbar(corrMat)\n    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n    plt.show()\n","8e24e886":"# Scatter and density plots\ndef plotScatterMatrix(df, plotSize, textSize):\n    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    df = df.dropna('columns')\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    columnNames = list(df)\n    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    df = df[columnNames]\n    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n    corrs = df.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()\n","66edc0be":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# Kerala-Rainfall-Historical.csv may have more rows in reality, but we are only loading\/previewing the first 1000 rows\ndf1 = pd.read_csv('\/kaggle\/input\/Kerala-Rainfall-Historical.csv', delimiter=',', nrows = nRowsRead)\ndf1.dataframeName = 'Kerala-Rainfall-Historical.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","4b6519e9":"df1.head(5)","103dc68c":"df1.columns","d8e94dc2":"plotPerColumnDistribution(df1, 10, 5)","2abbb043":"cols = df1.columns.tolist()\n# print(cols[2:14])\ndf2 = df1[cols[1:14]]\ndf2.dataframeName = 'Rainfall-Monthly'\nplotCorrelationMatrix(df2, 8)","ebdbb178":"plotScatterMatrix(df1, 20, 10)","3e1c81be":"df3  = pd.melt(df2, \n               id_vars = ['YEAR'], \n               value_vars = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL','AUG', 'SEP', 'OCT', 'NOV', 'DEC'], \n               var_name='MONTH_ABBR', value_name='VALUE')\n\n\ndf3.head(20)","9976daea":"def month_abbr_to_num(abbr_month):\n    return {month: index for index, month in enumerate(calendar.month_abbr) if month}[abbr_month.title()]\n","ce2e7f61":"\ndf3['MONTH'] = df3['MONTH_ABBR'].apply(lambda x: month_abbr_to_num(x))\n\n#Add a new column for Date with year and month information\n#set date as 1st of the month since we do not know the exact day\nDATE = []\nfor y, m in zip(df3['YEAR'],df3['MONTH']):\n    DATE.append(date(y, m, 1))\n\n\ndf3['DATE'] = DATE\ndf3\n","302da9fc":"df4 = df3[['DATE','VALUE','YEAR','MONTH']].copy(deep=True)\ndf4['DATE'] = pd.to_datetime(df4['DATE'])\ndf4.sort_values(by='DATE',inplace=True)      \ndf4","ae3045ad":"# sns.set_theme(style=\"darkgrid\")\nplt.style.use('ggplot') # style of plots\nplt.figure(figsize=(20,6))\nplt.plot(df4.DATE[-200:], df4.VALUE[-200:])\n# g= sns.relplot(x=\"DATE\", y=\"VALUE\",kind='line',data=df4[-20:])\n# g.fig.autofmt_xdate()\nplt.xlabel('Date')\nplt.ylabel('Rainfall value')\nplt.title('Rainfall')\nplt.xticks(rotation=45)\nplt.show()\n","4e89ff0b":"# lets create time series from rainfall data\ntimeSeries = df4.loc[:, [\"DATE\",\"VALUE\"]]\ntimeSeries.index = timeSeries.DATE\nts = timeSeries.drop(\"DATE\",axis=1)\n\n# Moving average method\nwindow_size = 12\nmoving_avg = ts.rolling(window_size).mean()\nplt.figure(figsize=(22,10))\nplt.plot(ts, color = \"red\",label = \"Original\")\nplt.plot(moving_avg, color='black', label = \"moving_avg_mean\")\nplt.title(\"Mean Rainfall in Kerala (12-month rolling average)\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Mean Rainfall\")\nplt.legend()\nplt.show()","8d3e85c9":"print('Mean', df4.VALUE.mean())\nprint('Std Deviation', df4.VALUE.std())","181e6827":"#Any value above 3 Std deviations from mean?\noutlier1 = df4.VALUE > df4.VALUE.mean()+3*df4.VALUE.std()\ndf_outlier = df4[outlier1].copy()\ndf_outlier","625ac987":"#Years with heaviest rainfall\nfig, ax = plt.subplots(figsize = (8,6))    \nfig = sns.barplot(x = \"DATE\", y = \"VALUE\", data = df_outlier, \n                  ci = None, ax=ax)\nx_dates = df_outlier.DATE.dt.strftime('%Y-%m-%d').sort_values().unique()\nax.set_xticklabels(labels=x_dates, rotation=45, ha='right')\n\nplt.show()","14dda108":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\nsns.boxplot(data=df4, x='MONTH', y=df4.VALUE, ax=ax)\nax.set_ylabel('Rainfall Value')\nax.set_title('Rainfall - KERALA - monthly')\nplt.show()","cebeedc2":"#remember to turn on internet to install\n!pip install neuralprophet\n# to see what is installed\n# pip list","117ca5a0":"from neuralprophet import NeuralProphet","6af52fa6":"df = df4.rename(columns = {'DATE':'ds', 'VALUE':'y'})\ndf = df.drop(columns = ['YEAR','MONTH'])\ndf","9915b405":"m = NeuralProphet(\n    n_lags=3*12,\n    n_forecasts=3*12,\n    changepoints_range=0.95,\n    n_changepoints=10,\n    weekly_seasonality=False,\n    batch_size=50,\n    epochs=40,    \n    learning_rate=0.3)\n\nmetrics = m.fit(df, freq='MS',validate_each_epoch=True,valid_p=0.2)\nfuture = m.make_future_dataframe(df, periods=3*12, n_historic_predictions=len(df))\nforecast = m.predict(future)\nfig = m.plot(forecast[-10*12:])\n\nfig_param = m.plot_parameters()","d37f52f7":"fig_comp = m.plot_components(forecast[-10*12:], residuals=True)","89748f89":"%matplotlib inline\nfig, ax = plt.subplots(figsize=(10,6))\nax.plot(metrics[\"MAE\"], 'ob', linewidth= 6, label = \"Training Loss\")\nax.plot(metrics[\"MAE_val\"], '-r', linewidth= 2, label = \"Validation Loss\")\nax.legend()","bee31a86":"## Let's change the way the data looks so that we can do more analysis","3323d282":"These are the years with rainfall that far exceeded normal levels.","d972f39b":"Distribution graphs (histogram\/bar graph) of sampled columns:","b1837670":"## Introduction\nThis notebook aims to explore the rainfall data for the state of Kerala in India from 1901-2017. Apart from being known for the highest literacy rate for any state in India, it is also known for its natural beauty. Tourism industry is a lifeline for many and climate change is starting to affect the life there in the past few years. \n\nYou can read more about Kerala here: [Kerala](https:\/\/en.wikipedia.org\/wiki\/Kerala)\n\nThis notebook will explore the data that was downloaded from data.gov.in. I also used this notebook as a way to practice some of the data munging skills. The hope is that some of you might find it useful for your own examples. We also look at how to model and forecast the time series data using [NeuralProphet](https:\/\/ourownstory.github.io\/neural_prophet\/).","78217dde":"Monsoon season starts in June and July typically sees the most amount of rain. We can also see that there are couple of outliers in July, with several outliers also showing in the shoulder months of May and August.","e88bf909":"Let's take a quick look at what the data looks like:","392ed31a":"Create a function to convert month abbreviation to corresponding number","ea701c9f":"## Exploratory Analysis\n\nStart by importing all the libraries that we will be using","06df24b7":"### Let's check 1st file: \/kaggle\/input\/Kerala-Rainfall-Historical.csv","2e0d35e6":"Scatter and density plots:","da234fb6":"There is 1 csv file in the current version of the dataset:\n","eae56b3c":"![Kerala](https:\/\/images.unsplash.com\/photo-1605531321045-59731b348442?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80)\n<span>Photo by <a href=\"https:\/\/unsplash.com\/@avincp?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Avin CP<\/a> on <a href=\"https:\/\/unsplash.com\/s\/photos\/%23kerala-%23malayalam?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash<\/a><\/span>","3f68e491":"# NeuralProphet forecasting","244240f2":"Now you're ready to read in the data and use the plotting functions to visualize the data.","a362d144":"Correlation matrix:","3bac1e51":"## Conclusion\nThere were couple of years in the 1920s where the rainfall exceeded normal range. It will be interesting to see if that happens again in this century. In 2018, Kerala was ravaged by floods due to heavy rains and flooding in main cities have become a common occurrence.The forecasting model above does not really catch that. Additional regressors will need to be investigated to improve the model.","c8846611":"## Explore seasonality","e39dc602":"The next hidden code cells define functions for plotting data. Click on the \"Code\" button in the published kernel to reveal the hidden code."}}