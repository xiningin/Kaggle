{"cell_type":{"517e372b":"code","97e6ff1a":"code","fb8d9c62":"code","f8e3c402":"code","f146712e":"code","263000b2":"code","ef12b70e":"code","3d00c0a8":"code","89e7f2bc":"code","42268b26":"code","f3f26ee2":"code","68a43948":"code","f0b11ece":"code","3a8f2f7c":"code","e95a7bf0":"code","03a465ee":"code","7a5d6db1":"code","f9f576bc":"code","c20c45f3":"markdown","eb45e7d3":"markdown","bd2ddf70":"markdown","2309e6f3":"markdown","50325498":"markdown","92508658":"markdown"},"source":{"517e372b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","97e6ff1a":"mainFolder = '\/kaggle\/input\/g-research-crypto-forecasting\/'","fb8d9c62":"%%time \n# datatable installation with internet\n!pip install datatable==0.11.0 > \/dev\/null","f8e3c402":"import datatable as dt","f146712e":"# Optimize reading speed of csv with datatable library\ndef read_csv_strict(fullPath='\/kaggle\/input\/g-research-crypto-forecasting\/train.csv'):\n    csvDT = dt.fread(fullPath)\n    df = csvDT.to_pandas()\n    df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n    df = df[df['datetime'] < '2021-06-13 00:00:00']\n    return df","263000b2":"%%time\ndf = read_csv_strict()","ef12b70e":"df.shape","3d00c0a8":"df.head(10)","89e7f2bc":"asset_details = pd.read_csv(mainFolder + 'asset_details.csv')\nasset_details.sort_values(by='Weight', ascending=False)","42268b26":"bitcoinAsset = asset_details[asset_details['Asset_Name'] == 'Bitcoin']\nbitcoinWeight = bitcoinAsset.Weight\nbitcoinWeight","f3f26ee2":"# Get all bitcoin asset data\nbitcoin = df[df['Asset_ID'] == 1]","68a43948":"# Checking there is only bitcoin asset\nbitcoin['Asset_ID'].nunique()","f0b11ece":"bitcoin.head()","3a8f2f7c":"from sklearn.metrics import mean_absolute_error","e95a7bf0":"def VWAP(df, period=1):\n    df['VWAP_Pre'] = ((df['High']+df['Low']+ df['Close'])\/3) * df['Volume']\n    df['VWAP_Source'] = pd.Series(df['VWAP_Pre'].rolling(period,min_periods=period).mean())\n    df['VolumeSMA'] = pd.Series(df['Volume'].rolling(period, min_periods=period).mean())\n    df['VWAP2'] =  df['VWAP_Source']\/df['VolumeSMA']\n    return df['VWAP2']","03a465ee":"VWAP(bitcoin)","7a5d6db1":"bitcoin.head(10)","f9f576bc":"mean_absolute_error(bitcoin['VWAP'], bitcoin['VWAP2'])","c20c45f3":"As seen in the data tab of the competition (https:\/\/www.kaggle.com\/c\/g-research-crypto-forecasting\/data) an explanation of each file and it's contents.\n### Files and features:\n* train.csv - The training set\n * timestamp - A timestamp for the minute covered by the row.\n * Asset_ID - An ID code for the cryptoasset.\n * Count - The number of trades that took place this minute.\n * Open - The USD price at the beginning of the minute.\n * High - The highest USD price during the minute.\n * Low - The lowest USD price during the minute.\n * Close - The USD price at the end of the minute.\n * Volume - The number of cryptoasset units traded during the minute.\n * VWAP - The volume weighted average price for the minute.\n * Target - 15 minute residualized returns. See the '[Prediction and Evaluation](https:\/\/www.kaggle.com\/cstein06\/tutorial-to-the-g-research-crypto-competition)' section of this notebook for details of how the target is calculated.\n\n\n* example_test.csv - An example of the data that will be delivered by the time series API. The data is just copied from train.csv.\n\n* example_sample_submission.csv - An example of the data that will be delivered by the time series API. The data is just copied from train.csv.\n\n* asset_details.csv - Provides the real name and of the cryptoasset for each Asset_ID and the weight each cryptoasset receives in the metric.\n\n* gresearch_crypto - An unoptimized version of the time series API files for offline work. You may need Python 3.7 and a Linux environment to run it without errors.\n\n* supplemental_train.csv - After the submission period is over this file's data will be replaced with cryptoasset prices from the submission period. The current copy, which is just filled approximately the right amount of data from train.csv is provided as a placeholder.","eb45e7d3":"## Let's explore assets details","bd2ddf70":"But it was some error. ","2309e6f3":"As [@abdelghanibelgaid](https:\/\/www.kaggle.com\/abdelghanibelgaid) suggested I tried this function to recreate VWAP:","50325498":"As suggested by [@julian3833](https:\/\/www.kaggle.com\/julian3833) in this [notebook](https:\/\/www.kaggle.com\/julian3833\/s-proposal-for-a-meaningful-lb) I will leave the test data out of the training data (as he said Only keep data from before 2021-06-13 00:00:00.). ","92508658":"### If someone wants to collaborate I can share the notebook\nThis notebook is born from the desire of undestanding how VWAP is implemented\/calculated. I started a discussion with this topic which can be found in this [link](https:\/\/www.kaggle.com\/c\/g-research-crypto-forecasting\/discussion\/286491) \n"}}