{"cell_type":{"60515bc8":"code","ccaa676b":"code","623c9ce8":"code","110f7b7a":"code","236498d8":"code","9711464e":"code","441bf52d":"code","b02371a5":"markdown","0cba25ea":"markdown","8e4f09c0":"markdown"},"source":{"60515bc8":"# importing necessary libraries :\nimport pandas as pd\nfrom selenium import webdriver\nimport pandas as pd \nimport time\nfrom selenium.webdriver.support.ui import Select\nfrom bs4 import BeautifulSoup\nimport requests\nimport itertools\nimport pickle","ccaa676b":"# We need to define a driver (automatic browser) and we will control it with the selenium library from the first \n#                                                                       page till the page we are interested in :\nEdge_driver = webdriver.Edge(executable_path= 'msedgedriver.exe')\nEdge_driver.get('https:\/\/www.imdb.com')\n\n\n# to access the final page there is a path we need to go throw: \n#1st : the dropdown menu\ndd_menu = Edge_driver.find_element_by_class_name('ipc-icon--arrow-drop-down')\ndd_menu.click()\n\ntime.sleep(1)\n\n#2nd : select the advanced search option from the dropdown menu\nad_search = Edge_driver.find_element_by_link_text('Advanced Search')\nad_search.click()\n\n#3rd : select the Advanced Title Search from the search page\nad_search_title = Edge_driver.find_element_by_link_text('Advanced Title Search')\nad_search_title.click()\n\n#4th : select title type (video games)\ntitle_type = Edge_driver.find_element_by_id('title_type-8')\ntitle_type.click()\n\n#5th : setting minimum number of votes to 50 :\nn_votes = Edge_driver.find_element_by_name('num_votes-min')\nn_votes.click()\nn_votes.send_keys('50')\n\n#6th : Select nombre of results titles (250 per page)\nresults = Edge_driver.find_element_by_id('search-count')\nselect = Select(results)\nselect.select_by_index(2)\n\n#7th : Select type of sorting (by rating desc)\nsorting = Edge_driver.find_element_by_name('sort')\nselect_2 = Select(sorting)\nselect_2.select_by_index(5)\n\n#8th select submit botton :\nsubmit = Edge_driver.find_element_by_xpath('(\/\/button[@type=\"submit\"])[2]')\nsubmit.click()\n\n#9th Save the link in a variable \n#url = Edge_driver.current_url\n\n#10th loop of saving the link and clicking next for all the result pages :\n# We will define a loop of 20 iterations to have 5000 titles (250 for each page * 20 = 5000)\nurl = []\ni = 0\nwhile i < 20:\n    url.append(Edge_driver.current_url)\n    time.sleep(1)\n    next_page = Edge_driver.find_element_by_class_name('next-page')\n    next_page.click()\n    i += 1\n","623c9ce8":"print('Number of pages collected is =' , len(url))","110f7b7a":"# Preparing the soup object :\nsoup = []\ni = 0\nwhile i < len(url):\n    soup.append(BeautifulSoup(requests.get(url[i]).content , 'html.parser'))\n    i += 1\n\nGames_list = [ sp.find_all('div' , {'class' : 'lister-item'}) for sp in soup ]\nGames_list = list(itertools.chain(*Games_list))\n\n# Now that we have access, we need to start scraping the name, release date, rate, number of votes and genre for each game :\n\n# Names :\ngames_title = [name.find('h3').find('a').get_text() for name in Games_list]\n\n# Release dates :\nRelease_Year = [date.find('h3').find('span' , {'class' : 'lister-item-year'}).get_text().replace('(' , '').replace(')' , '').split()[0] for date in Games_list]\n\n# Users rates :\nUsers_rate = [rate.find('div' , {'class' : 'ratings-imdb-rating'}).find('strong').get_text() for rate in Games_list]\n\n# Games genre :\nGenre = [genre.find('div' , {'class' : 'lister-item-content'}).find('p' , {'class' : 'text-muted'}).get_text().strip() for genre in Games_list]\n\n# Number of votes :\nVotes = [vote.find('p' , {'class' : 'sort-num_votes-visible'}).find('span' , {'name' : 'nv'}).get_text() for vote in Games_list]","236498d8":"# Creating the database :\nImdb_Games = pd.DataFrame({'Title' : games_title , 'Realese Date' : Release_Year, 'Users Rate' : Users_rate,\n                           'Genre' : Genre , 'Number of Votes' : Votes})","9711464e":"Imdb_Games","441bf52d":"# Saving the database in an excel file :\nImdb_Games.to_excel('IMDB_Games.xlsx' , index=False)","b02371a5":"#### Firt we will crowl to the link from wich we want to scrap the data, and for that we will use selenium library :","0cba25ea":"####  Now that we arrived to the page we are interested and we saved the path in variable we are ready to start the scraping part with beautiful Soup","8e4f09c0":"#### After finishing the process of crawling and scraping all the data we want it's time for saving it in a database :"}}