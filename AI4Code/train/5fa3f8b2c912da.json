{"cell_type":{"aaba602a":"code","983d6420":"code","f643f22f":"code","f31d5112":"code","d3745211":"code","8d509f2b":"code","9778b7da":"code","0a08f324":"code","ad25df3b":"code","61462d8f":"code","cfe2df79":"code","da7cb3d6":"code","86d017e7":"code","0e2db7a3":"code","14a57e9c":"code","3e449b46":"code","1a09a1f0":"code","6e0b91d8":"code","eadeb82a":"code","c112eac6":"code","c2e2cbfa":"code","91363b62":"code","16998e3f":"code","04ebb6c4":"markdown","fb1617df":"markdown","10414214":"markdown","9e822689":"markdown","fdea0efc":"markdown"},"source":{"aaba602a":"%%time\n\nimport os, psutil\nimport gc\n\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport itertools\n\nfrom sklearn.model_selection import cross_validate,cross_val_score,train_test_split, KFold, GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score, log_loss, roc_auc_score,make_scorer, precision_score, recall_score,f1_score, roc_curve,auc\nfrom sklearn import ensemble,metrics,model_selection,neighbors,preprocessing, svm, tree\nfrom sklearn.preprocessing import MinMaxScaler\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nimport optuna\nfrom optuna.integration import LightGBMPruningCallback,XGBoostPruningCallback\n\nimport scikitplot.metrics as skplot\nimport datatable as dt\n\nfrom sklearn.cluster import KMeans\nfrom pickle import *\n\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 1000)\n# from IPython.core.interactiveshell import InteractiveShell\n# InteractiveShell.ast_node_interactivity = 'all'\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","983d6420":"def cpu_usage():\n    pid = os.getpid()\n    py = psutil.Process(pid)\n    return f'Memory Usage : {round(py.memory_info()[0]\/2**30,2)}'","f643f22f":"# function to reduce data memory size\ndef reduce_memory_usage(df):\n    start_mem = df.memory_usage().sum()\/1024**2\n    numerics = ['int8', 'int16', 'int32','int64', 'float16','float32','float64']\n    for col in df.columns:\n        col_type = df[col].dtype\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(df[col].dtype)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum()\/1024**2\n    print(f'Memory reduced from {round(start_mem,2)} -> {round(end_mem,2)}.\\nReduction in memory size by {round(((start_mem - end_mem)\/start_mem)*100,2)}%')\n    cpu_usage()","f31d5112":"def get_data_info():\n    print(str.center(' Train Info ',40, '-'))\n    print(f'Rows : {train.shape[0]}, Columns : {train.shape[1]}')\n    temp = train.dtypes.value_counts()\n    print([f'{temp.index[i]} : {temp[i]}' for i in range(0,len(temp))])\n    print(f'Target {train.target.value_counts(normalize = True).index[0]} : {train.target.value_counts(normalize = True)[0]*100}%')\n    print(f'Target {train.target.value_counts(normalize = True).index[1]} : {train.target.value_counts(normalize = True)[1]*100}%')\n    \n    print(str.center(' Test Info ',40, '-'))\n    print(f'Rows : {test.shape[0]}, Columns : {test.shape[1]}')\n    temp = test.dtypes.value_counts()\n    print([f'{temp.index[i]} : {temp[i]}' for i in range(0,len(temp))])","d3745211":"cols_to_remove = ['id']","8d509f2b":"%%time\ntrain = dt.fread('..\/input\/tabular-playground-series-nov-2021\/train.csv').to_pandas()\ntest = dt.fread('..\/input\/tabular-playground-series-nov-2021\/test.csv').to_pandas()","9778b7da":"train.drop(cols_to_remove, axis = 1, inplace = True)\ntest.drop(cols_to_remove, axis = 1, inplace = True)","0a08f324":"reduce_memory_usage(train)\nreduce_memory_usage(test)","ad25df3b":"train['target'] = train['target'].astype(int).astype(object)","61462d8f":"cat_cols = test.select_dtypes(include = bool).columns\ncont_cols = test.select_dtypes(include = 'float16').columns","cfe2df79":"def create_cluster_features(imp_features = ['f50', 'f41', 'f97', 'f91', 'f27', 'f43', 'f34', 'f8', 'f80', 'f55', 'f71'],\n                           n_clusters = 12,\n                           train = train,\n                           test = test):\n    n_clusters = 12\n    cd_feature = True # cluster distance instead of cluster number\n    cluster_cols = [f\"f{i+100}\" for i in range(n_clusters)]\n    kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", max_iter=500, random_state=42)\n    \n    # train impute\n    X_cd = kmeans.fit_transform(train[imp_features])\n    imp_cluster_values_train = pd.DataFrame(X_cd, columns = cluster_cols)\n    train = pd.concat([train,imp_cluster_values_train], axis = 1)\n    \n    # test impute\n    X_cd = kmeans.transform(test[imp_features])\n    imp_cluster_values_test = pd.DataFrame(X_cd, columns = cluster_cols)\n    test = pd.concat([test,imp_cluster_values_test], axis = 1)\n    return train, test","da7cb3d6":"train, test = create_cluster_features()","86d017e7":"mm_scaler = MinMaxScaler()\nX = train.drop(columns = 'target', axis = 1)\ny = train['target'].astype(int)","0e2db7a3":"X = pd.DataFrame(mm_scaler.fit_transform(X), columns = X.columns)\ntest = pd.DataFrame(mm_scaler.transform(test),columns = test.columns)","14a57e9c":"def objective(trial, X = X, y = y):\n    \n    param_grid = {\n        'bootstrap_type':'Poisson',\n        'iterations' : trial.suggest_int('iterations', 50, 300),    \n        'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 1.0),\n        'subsample': trial.suggest_float(\"subsample\",0.2, 1.0),\n        'min_data_in_leaf': trial.suggest_int(\"min_data_in_leaf\",10, 100),\n        'depth' : trial.suggest_int('depth', 4, 10),                                       \n        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.3),               \n        'random_strength' :trial.suggest_int('random_strength', 0, 100),                       \n        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n        'learning_rate' :trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter'])\n    }\n    \n    cv = StratifiedKFold(shuffle= True, random_state= 42)\n    cv_scores = np.empty(5)\n    \n    for idx, (train_idx, test_idx) in enumerate(cv.split(X,y)):\n        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n        y_train, y_test = y[train_idx], y[test_idx]\n    \n    \n        model = CatBoostClassifier(\n        loss_function=\"Logloss\",\n        eval_metric=\"AUC\",\n        task_type=\"GPU\",\n        random_seed=42,\n        verbose= 0,\n        border_count=64,\n        **param_grid)    \n\n        model.fit(X_train, y_train, eval_set=[(X_test, y_test)],early_stopping_rounds=400,verbose=False)\n\n        y_preds = model.predict(X_test)\n        auc_score = roc_auc_score(y_test, y_preds)\n        cv_scores[idx] = auc_score\n    \n    return np.mean(cv_scores)","3e449b46":"# %%time\n# from optuna.samplers import TPESampler\n# import multiprocessing\n# study = optuna.create_study(direction = \"maximize\", sampler = TPESampler(seed= 42))\n# study.optimize(objective, n_trials = 100)","1a09a1f0":"# import pickle\n# pickle.dump(study.best_trial.params, open('CatBoost_Hyperparameter.pickle', 'wb'))\n# print('CatBoost Hyperparameter:', study.best_trial.params)","6e0b91d8":"# chosen from optuna 100 trials\ncb_best_params =  {'iterations': 296, \n                   'reg_lambda': 0.053207743382150924, \n                   'subsample': 0.9427230636303613, \n                   'min_data_in_leaf': 26, \n                   'depth': 4, \n                   'learning_rate': 0.23100537129565457, \n                   'random_strength': 25, \n                   'bagging_temperature': 15.108913990665142, \n                   'od_type': 'Iter',\n                  'bootstrap_type':'Poisson'}","eadeb82a":"cb_model = CatBoostClassifier(\n        loss_function=\"Logloss\",\n        eval_metric=\"AUC\",\n        task_type=\"GPU\",\n        random_seed=42,\n        border_count=64,\n        **cb_best_params)","c112eac6":"cv = StratifiedKFold(shuffle= True, random_state= 42, n_splits = 5)\nroc_score_all = np.empty(5)\ncat_oof = np.zeros(X.shape[0])\nfor idx, (train_idx, valid_idx) in enumerate(cv.split(X,y)):\n    X_train, X_test = X.iloc[train_idx],X.iloc[valid_idx]\n    y_train, y_test = y.iloc[train_idx],y.iloc[valid_idx]\n    \n    cb_model.fit(X_train, y_train,eval_set=[(X_test, y_test)],\n              early_stopping_rounds=400,\n              verbose=False )\n    y_pred = cb_model.predict(X_test)\n    y_pred_proba = cb_model.predict_proba(X_test)[:,1]\n    cat_oof[valid_idx] = y_pred_proba\n    roc_score = roc_auc_score(y_test,y_pred)\n    roc_score_all[idx] = roc_score\n    print(f'Fold : {idx}')\n    print(f'ROC: {roc_score}')\n    print('--'*40)\nprint(f'Overall ROC : {np.mean(roc_score_all)}')    ","c2e2cbfa":"cat_oof","91363b62":"predictions = np.zeros(len(test))\npredictions += cb_model.predict_proba(test)[:,1]\/cv.n_splits","16998e3f":"# making baseline submission\nss = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")\nss['target'] = predictions\nss.to_csv('.\/catboost_submission.csv', index=False)\nnp.savez_compressed('oof_catboost.npz', cat_oof)","04ebb6c4":"### Catboost Parameter tuning with Optuna","fb1617df":"## Feature engg with top 10 imp features","10414214":"## Get data and compress ","9e822689":"## Helper functions","fdea0efc":"## Scaling data"}}