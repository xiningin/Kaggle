{"cell_type":{"54928e76":"code","90154e9e":"code","c64191c9":"code","aa5d9490":"code","c239f226":"code","b704e5fe":"code","42cddb32":"code","94dafd59":"code","a1556795":"code","d4a46942":"code","021077ce":"code","bfbb7c72":"code","09d598b7":"code","71dabb9c":"code","7fc84b67":"code","dca276af":"code","952c3419":"code","7b29939f":"code","ba40bbec":"code","d8ea43f8":"code","27c9f4aa":"code","e4518ab7":"code","100b83fe":"code","a9127cd8":"code","e215bbf9":"code","21f92899":"markdown","07b75524":"markdown","25be3e10":"markdown","4a4859fe":"markdown","3c5719cb":"markdown","055bb115":"markdown","64aa7118":"markdown","69f0c381":"markdown","2cf2cfc0":"markdown","b654230a":"markdown","4032e27e":"markdown","36d5e348":"markdown","35e4e448":"markdown","58747ed8":"markdown","7500b743":"markdown","67c07c78":"markdown","d2e83344":"markdown","25da7382":"markdown","a658c6ad":"markdown","64955267":"markdown","049e0716":"markdown","32e790ff":"markdown","c9d9b58c":"markdown","a99f8183":"markdown","6acda510":"markdown","30a02f1f":"markdown","9e62932b":"markdown","0d0ee9b5":"markdown"},"source":{"54928e76":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom scipy.sparse import csr_matrix\nfrom sklearn.neighbors import NearestNeighbors\nimport warnings","90154e9e":"user_ratings = pd.read_csv('\/kaggle\/input\/movielens-100k-dataset\/ml-100k\/u.data',\n                            sep='\\t',names=['user_id','movie_id','rating'], \n                           usecols=[0,1,2])\n\nmovie_info =  pd.read_csv('..\/input\/movielens-100k-dataset\/ml-100k\/u.item', \n                          sep='|', names=['movie_id','title'], usecols=[0,1],\n                          encoding=\"ISO-8859-1\")","c64191c9":"user_ratings = pd.merge(movie_info, user_ratings)\n\nuser_ratings.head()","aa5d9490":"user_ratings = user_ratings.pivot_table(index=['user_id'],\n                                        columns=['title'],\n                                        values='rating')\nuser_ratings.head()","c239f226":"user_ratings.shape","b704e5fe":"def df_fill_percentage(data):\n    return round( data.notna().sum().sum() \/ (data.shape[0] * data.shape[1]) * 100, 2)","42cddb32":"df_fill_percentage(user_ratings)","94dafd59":"user_ratings.count(axis=0).plot(kind='box')","a1556795":"user_ratings.count(axis=0).plot(kind='hist')","d4a46942":"def itemcf_predict_rating_closure(user_ratings, neighborhoods):\n    # creates the predict rating function\n    def itemcf_predict_rating_using_nmean(column):\n        # for movie of the column \n        # calculate a rating based on average ratings \n        # of the neighbors-movies which the user has rated\n        # round the result (because ratings are whole values)\n        neighbors_titles = neighborhoods.loc[column.name][0]\n        return round(user_ratings[neighbors_titles].mean(axis=1))\n    \n    return itemcf_predict_rating_using_nmean","021077ce":"# set a min_periods argument for the minimum number of observations required \n# per pair of columns to have a valid result.\n# set the number of nearest neighbors to search\ndef recommendation_system_item_model(minperiods, nneighbors, user_ratings):\n    # 1\n    # movie_distances = movie similarity matrix. \n    # Similarity of each movie with every other movie.\n    movie_distances = user_ratings.corr(method='pearson', \n                                        min_periods=minperiods)\n    # Keep only the columns with at least nneighbors+1 number non-NA values.\n    movie_distances = movie_distances.dropna(axis=0, \n                                             thresh=nneighbors+1).dropna(axis=1, \n                                                                         thresh=nneighbors+1)\n    # Make the matrix square (dropping the rows as well)\n    movie_distances = movie_distances.loc[movie_distances.columns]\n    # from PCC ranging [-1,+1] to Pearson's distance [0,2]\n    movie_distances = 1 - movie_distances\n    # replace negative values with zero (solving float precision issue)\n    movie_distances[movie_distances < 0] = 0\n    # 2\n    # define model\n    # metric is \u201cprecomputed\u201d, \n    # X is assumed to be a distance matrix and must be square during fit\n    model_knn = NearestNeighbors(metric='precomputed', algorithm='brute', \n                                 n_neighbors=nneighbors, n_jobs=-1)\n    # fit\n    # X may be a sparse graph, \n    # in which case only \u201cnonzero\u201d elements may be considered neighbors\n    model_knn.fit(csr_matrix(movie_distances.fillna(0).values))\n    # get nearest neighbors\n    similarity, indexes = model_knn.kneighbors(csr_matrix(movie_distances.fillna(0).values), \n                                               n_neighbors=nneighbors)\n    # 3\n    # dataframe with list of nns per movie\n    neighborhoods = pd.DataFrame({'neighborhood_titles':\n                                  [movie_distances.iloc[neighbors].index.to_list() \n                                                for neighbors in indexes.tolist()]}, \n                                 index=movie_distances.index)\n    # Combine ratings using mean\n    pred = user_ratings.reindex(columns=neighborhoods.index)\\\n                        .apply(itemcf_predict_rating_closure(user_ratings, neighborhoods))\n    return pred, neighborhoods","bfbb7c72":"# because of NaNs, custom MAE calculation function is created\ndef mae(user_ratings, predicted_ratings):\n    # absolute difference of actual and predicted rating\n    abs_dif = abs(user_ratings - predicted_ratings)\n    # number of non-nan values\n    n = np.sum(user_ratings.count()) \n    return abs_dif.sum().sum()\/ n","09d598b7":"# Read user ratings for each movie from the `u.data` file \n# and get the names of the movies from the `u.item` file\nuser_ratings_train = pd.read_csv('\/kaggle\/input\/movielens-100k-dataset\/ml-100k\/u1.base',\n                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n\nuser_ratings_test = pd.read_csv('\/kaggle\/input\/movielens-100k-dataset\/ml-100k\/u1.test',\n                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n\nmovie_info =  pd.read_csv('..\/input\/movielens-100k-dataset\/ml-100k\/u.item', \n                          sep='|', names=['movie_id','title'], usecols=[0,1],\n                          encoding=\"ISO-8859-1\")\n\n# Merge the information in one DataFrame\nuser_ratings_train = pd.merge(movie_info, user_ratings_train)\nuser_ratings_test = pd.merge(movie_info, user_ratings_test)\n\n# Create the user-item rating matrix. \n# Each row is a user, and the values are the user's ratings for each movie. \n# The movie titles are found in the columns\nuser_ratings_train = user_ratings_train.pivot_table(index=['user_id'],\n                                        columns=['title'],\n                                        values='rating')\n\nuser_ratings_test = user_ratings_test.pivot_table(index=['user_id'],\n                                        columns=['title'],\n                                        values='rating')\n\nprint(user_ratings_train.shape)\nprint(user_ratings_test.shape)","71dabb9c":"user_ratings_train = user_ratings_train.reindex(\n                            index=user_ratings_train.index.union(user_ratings_test.index), \n                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n\nuser_ratings_test = user_ratings_test.reindex(\n                            index=user_ratings_train.index.union(user_ratings_test.index), \n                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n\nprint(user_ratings_train.shape)\nprint(user_ratings_test.shape)","7fc84b67":"scoreboard = []\nfor min_periods in [6, 10, 50, 100]:\n    for n_neighbors in [2, 5, 10, 20]:\n        # temporarily supress warnings\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            pred, neighborhoods = recommendation_system_item_model(min_periods, \n                                                                   n_neighbors, \n                                                                   user_ratings_train)\n        # reindex predictions to include all movies \n        # (some get filtered for not having enough neigbors)\n        pred = pred.reindex(columns=user_ratings_train.columns)\n        # MAE\n        error = mae(user_ratings_test, pred)\n        # percentage of movies not recommended to anyone (Only Nan ratings)\n        m_not_rec = (pred.notna().sum(axis=0) == 0).sum() \/ pred.columns.size * 100\n        # percentage of users without any recommendations\n        u_not_rec = (pred.notna().sum(axis=1) == 0).sum() \/ pred.index.size * 100\n        d = {\"Min Periods\": min_periods, \n             \"KNN\":n_neighbors,\"MAE\": error, \n             \"% of movies ignored\": m_not_rec, '% of users ignored': u_not_rec,\n            \"fill %\": df_fill_percentage(pred)}\n        scoreboard.append(d)\nscores = pd.DataFrame(scoreboard)\nscores","dca276af":"sns.catplot(data=scores, kind=\"bar\", x=\"KNN\", y=\"MAE\", hue=\"Min Periods\")","952c3419":"sns.catplot(data=scores, kind=\"bar\", x=\"KNN\", y=\"fill %\", hue=\"Min Periods\")","7b29939f":"sns.catplot(data=scores, kind=\"bar\", x=\"KNN\", y=\"% of movies ignored\", hue=\"Min Periods\")","ba40bbec":"pred_item, neighborhoods_item = recommendation_system_item_model(6, 10, user_ratings_train)\npred_item = pred_item.reindex(columns=user_ratings_train.columns)\n# compare to the test set using MAE\nerror = mae(user_ratings_test, pred_item)\nerror","d8ea43f8":"pred_item","27c9f4aa":"df_fill_percentage(pred_item) - df_fill_percentage(user_ratings_train)","e4518ab7":"sns.boxplot(data=[user_ratings_train.count(axis=0), pred_item.count(axis=0)])","100b83fe":"neighborhoods_item.loc['Young Guns II (1990)'][0]","a9127cd8":"user_ratings_test.loc[373].sort_values(ascending=False)[:20]","e215bbf9":"pred_item[user_ratings_test.loc[373].sort_values(ascending=False)[:20].index].loc[373]","21f92899":"There are 943 users and 1664 movies in our data","07b75524":"Let's check the number of ratings for the movies before and after running the recommendation system.","25be3e10":"The function to aggregate ratings","4a4859fe":"# Testing and Evaluation","3c5719cb":"A great challenge when building a recommendation system is finding ways to measure the quality of it's predictions.\n\nAccording to Herlocker et al. in [Evaluating collaborative filtering recommender systems](https:\/\/dl.acm.org\/doi\/10.1145\/963770.963772), we can define some metrics for that, such as **coverage** and **accuracy**.\n\n- Coverage: A measure of the percentage of items for which the recommendation system can provide predictions.\n\n- Accuracy: A measure of the accuracy of predictions\n\nFor the coverage, we will be checking the percetage of users and the percentage of movies for which the system was not able to generate any predictions.\n\nWe will be using Mean Absolute Error (MAE) as a prediction accuracy metric, one of the most frequently used for evaluation of Collaborative Filtering","055bb115":"# Getting Data\nRead user ratings for each movie from the `u.data` file and get the names of the movies from the `u.item` file","64aa7118":"Nice! The recommendation system has given a high rating (>3) to the user's liked movies<br>\n\nFor example, (looking at the result above) it would recommend, among others, to the user 373:\n- Strictly Ballroom (1992)\n- Grease (1978)\n- Circle of Friends (1995)\n- Blade Runner (1982)\n- Full Monty, The (1997) \n\nall of which (looking at the test set), they will end up enjoying and rating 5 stars ","69f0c381":"# Creating a Item-Item Neighborhood Based Collaborative Filtering Recommendation System","2cf2cfc0":"Example of a neighborhood","b654230a":"# Item - Item Collaborative Filtering\n\nworks by finding a set of movies that are similar to the movie we want to predict ratings for.\nThe similarity is not found through the content of the movies, but through the ratings the users have provided for them.\n\nThis can be broken down into 3 steps:\n1. Calculation of the similarity Matrix for all movies\n2. Finding the K Nearest Neighbors of each movie\n3. Combine the ratings a given user has provided for items in the neighborhood of that movie to predict a rating","4032e27e":"## Evaluating Predictions","36d5e348":"Because of the memory based approach, the input of the system needs to include all the movies and users available. <br>\nThis is why we must reindex the train and test data to include the whole dataset","35e4e448":"Merge the information in one DataFrame","58747ed8":"Below we can see the percentage of computed values in the user-item rating matrix <br>\nOf course the computed values are only predictions of how the system thinks the user will rate the movies.","7500b743":"# Intro\n\nIn this notebook we will build a Recommendation System using the Movielens 100K Dataset. <br>\n\n - **Collaborative Filtering** is a method which relies on the preferences of the users to come up with recommendations. <br>\n - The Recommendation System will be using a **memory based** algorithm, meaning statistical calculations will be performed on  the entire dataset in order to make predictions on the user's preferences. <br>\n - A **Item-Based** approach will be followed, meaning that similarity between items will be calculated. <br>\n - Finally, the **Neighborhood-Based** method of choice will be K-NearestNeighbors: Ratings from the list of nearest neighbors will be combined to predict unknown ratings","67c07c78":"## Get testing and training data","d2e83344":"The dataset includes some testing and training slices of the entire dataset. We will use the training set to generate predictions, then compare them to the ratings of the test set. ","25da7382":"We will run a test using the parameters selected","a658c6ad":"## Putting it all together","64955267":"### Example of recommendations for a specific user\n\nWe can see below, for a specific user (for example user with id 373), how the highest uknown ratings (those in the test data) compare to the ratings the system predicted","049e0716":"When analyzing only the MAE, it appears as though the best recommendation system is one where the movies need to have at least 100 common ratings to be considered as neighbors, and the larger the neighborhood of a movie, the better.\n\nBut, in a recommendation system it is very important to analyze the coverage as well.\nLooking at he plots below, for min_periods=100 and a neighborhood size of 30, the system is unable to generate a prediction for 95% of it's movies!<br>\nThis would mean that unpopular movies (those that don't have many ratings) are not going to be recommended to anyone","32e790ff":"Average number of ratings of a movie:","c9d9b58c":"Test different values of min_periods argument = the minimum number of common ratings required per pair of movies to consider their distance.<br>\nTest different values of n_neighbors argument = the size of a movie's neighborhood","a99f8183":"We create a function which returns the percentage of non-Nan values a dataframe has.","6acda510":"## Hyperparameter Tuning","30a02f1f":"From the above analysis we will compromise in coverage and accuracy by selecting the following parameters:\n- min_periods = 6\n- n_neighbors = 10","9e62932b":"Looking at the filled matrix","0d0ee9b5":"Create the user-item rating matrix. Each row is a user, and the values are the user's ratings for each movie. The movie titles are found in the columns"}}