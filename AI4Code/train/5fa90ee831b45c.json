{"cell_type":{"ac3a27df":"code","521e091d":"code","c95357e3":"code","5e80b104":"code","bc859759":"code","c1c91797":"code","c4266ff3":"code","bfadcbf3":"code","921917e3":"code","7eb8e336":"code","190d491e":"code","742f7ced":"code","e2e9ba5f":"code","6da1d137":"code","cce83cc3":"code","6781ee2c":"code","e861e3d1":"code","ac371123":"code","61adecea":"code","7aa1b773":"code","63f47713":"code","993cc228":"code","0ba5ea42":"code","a47054aa":"code","748f41f1":"code","6f9a1eb8":"code","3dff571f":"code","73e10e76":"code","0bf29a5a":"code","743be0a3":"code","ebd1801c":"code","d6b89223":"code","98fcce83":"code","7d260deb":"code","8b01d448":"code","140b0452":"code","07de503f":"code","b1a75d4b":"code","e6592bfe":"code","b8a1ab1f":"code","27ebe781":"code","c0484ac4":"code","a2c76c6f":"code","f7d682a5":"code","b1cc7a0b":"code","2ccfe518":"code","9424df4b":"code","def22c5c":"code","b6a725fb":"code","ed04a888":"code","e77e1490":"code","e0389d79":"code","2df6e9a1":"code","2305f646":"code","64063eeb":"code","29d42281":"code","5b3434d0":"code","a9500bf8":"code","b3b8f41d":"code","7443f82f":"code","8521397a":"markdown","2adfdcbd":"markdown","73498610":"markdown","cefedecc":"markdown","734b5a1a":"markdown","a2297a76":"markdown","8b02e6f3":"markdown","bdaf568f":"markdown","c1f90b7c":"markdown","e8bac3b9":"markdown","e3e2026f":"markdown","02f507af":"markdown","5d2a6ceb":"markdown","3f81008f":"markdown","4b879de2":"markdown","1705a12a":"markdown","b2d2da5e":"markdown","fe543e01":"markdown","4b16c0d6":"markdown","f1c871ce":"markdown","06f1523f":"markdown","231cd25a":"markdown","179ea3dd":"markdown","e523ac0c":"markdown","4c927be9":"markdown","f6858759":"markdown","c532a65f":"markdown","417de1d5":"markdown","5362460c":"markdown","711c5100":"markdown","b291ae9c":"markdown","e96aaef0":"markdown","cd77f586":"markdown"},"source":{"ac3a27df":"import pandas as pd\nimport re\nimport nltk\nimport spacy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","521e091d":"import spacy.cli\nspacy.cli.download(\"pt_core_news_sm\")","c95357e3":"import pt_core_news_sm\n\nspc_pt = pt_core_news_sm.load()","5e80b104":"# Lendo o dataset, primeiramente\ndata = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv\")","bc859759":"data.head(15)","c1c91797":"data.drop(['order_id', 'review_creation_date', 'review_answer_timestamp'],\n          1, inplace = True)","c4266ff3":"data.info()","bfadcbf3":"duplicados = round(sum(data.duplicated(\"review_id\"))\/len(data)*100, 2)\nprint(f\"Reviews com id duplicado: {duplicados}%.\")","921917e3":"data[data.duplicated(\"review_id\", keep =  False)].sort_values(by = \"review_id\")","7eb8e336":"data.drop_duplicates(\"review_id\", inplace = True) # remove os duplicados","190d491e":"data.fillna('', inplace = True) # para nao ter problemas com nulos na concatenacao","742f7ced":"# concatenando as duas colunas\ndata['review'] = data['review_comment_title'] + ' ' + data['review_comment_message']","e2e9ba5f":"# removendo entradas sem texto\ndata = data[data['review'] != ' ']","6da1d137":"data.info()","cce83cc3":"data.head()","6781ee2c":"data['review_score'].value_counts()","e861e3d1":"labels = []\n\nfor score in data['review_score']:\n  if score > 3:\n    labels.append(1)\n  else:\n    labels.append(0)\n\ndata['label'] = labels","ac371123":"data.head(10)","61adecea":"plt.figure(figsize=(8,6))\nsns.countplot(data['label'])\nplt.show()","7aa1b773":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords","63f47713":"stopwords_pt = stopwords.words(\"portuguese\")","993cc228":"stopwords_pt","0ba5ea42":"stopwords_pt.remove('n\u00e3o')\nstopwords_pt.remove('nem')","a47054aa":"def limpa_texto(texto):\n  '''(str) -> str\n  Essa funcao recebe uma string, deixa tudo em minusculo, filtra apenas letras,\n  retira stopwords, lemmatiza e retorna a string resultante.\n  '''\n  texto = texto.lower()\n\n  texto = re.sub(r\"[\\W\\d_]+\", \" \", texto)\n\n  texto = [pal for pal in texto.split() if pal not in stopwords_pt]\n\n  spc_texto = spc_pt(\" \".join(texto))\n  tokens = [word.lemma_ if word.lemma_ != \"-PRON-\" else word.lower_ for word in spc_texto]\n  \n  return \" \".join(tokens)","748f41f1":"data['review'] = data['review'].apply(limpa_texto)","6f9a1eb8":"data.info()","3dff571f":"data.head(10)","73e10e76":"data[data['review'] == '']","0bf29a5a":"data = data[data['review'] != '']","743be0a3":"data.info()","ebd1801c":"# rode essa celula se quiser salvar o dataset pre-processado\ndata.to_csv('olist_preprocessado.csv', index= False, columns= ['review_id', 'review', 'label'])","d6b89223":"# Importando o CountVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer","98fcce83":"# Instanciando o CountVectorizer, binary=True faz a codificacao binaria\nvectorizer = CountVectorizer(binary=True, max_features=5000)\n\ntexto = data['review']\n\n# Vetorizando o texto\nX_bow = vectorizer.fit_transform(texto)","7d260deb":"X_bow.toarray()","8b01d448":"print(X_bow.shape, type(X_bow))","140b0452":"from sklearn.feature_extraction.text import TfidfVectorizer","07de503f":"# Instanciando o TfidfVectorizer\ntfidf_vect = TfidfVectorizer(max_features=5000)\n\n# Vetorizando\nX_tfidf = tfidf_vect.fit_transform(texto)","b1a75d4b":"print(X_tfidf)","e6592bfe":"from sklearn.model_selection import train_test_split","b8a1ab1f":"X1_train, X1_test, y1_train, y1_test = train_test_split(X_bow, data['label'],\n                                                        test_size=0.3, random_state = 10)\n\nX2_train, X2_test, y2_train, y2_test = train_test_split(X_tfidf, data['label'],\n                                                        test_size=0.3, random_state = 10)","27ebe781":"from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score","c0484ac4":"def mostra_metricas(y_true, y_pred):\n  ''' Fun\u00e7\u00e3o que recebe o y real, o y predito e mostra as\n  principais metricas.\n  '''\n  print(\"Acur\u00e1cia: \", accuracy_score(y_true, y_pred))\n  print(\"\\nAUROC:\", roc_auc_score(y_true, y_pred))\n  print(\"\\nF1-Score:\", f1_score(y_true, y_pred, average='weighted'))\n  print(\"\\nMatriz de confus\u00e3o:\")\n  sns.heatmap(confusion_matrix(y_true, y_pred), annot=True)\n  plt.show()","a2c76c6f":"from sklearn.linear_model import LogisticRegression","f7d682a5":"# Instanciando a reg. logistica\nreglog = LogisticRegression()\n\n# Aplicando o modelo\nreglog.fit(X1_train, y1_train)","b1cc7a0b":"# Predicao\ny1_reglog_pred = reglog.predict(X1_test)","2ccfe518":"mostra_metricas(y1_test, y1_reglog_pred)","9424df4b":"reglog2 = LogisticRegression()\n\nreglog2.fit(X2_train, y2_train)\n\ny2_reglog_pred = reglog2.predict(X2_test)","def22c5c":"mostra_metricas(y2_test, y2_reglog_pred)","b6a725fb":"from sklearn.naive_bayes import MultinomialNB","ed04a888":"nb1 = MultinomialNB()\n\nnb1.fit(X1_train.toarray(), y1_train)\n\ny1_gnb_pred = nb1.predict(X1_test.toarray())\n\nmostra_metricas(y1_test, y1_gnb_pred)","e77e1490":"nb2 = MultinomialNB()\n\nnb2.fit(X2_train.toarray(), y2_train)\n\ny2_gnb_pred = nb2.predict(X2_test.toarray())\n\nmostra_metricas(y2_test, y2_gnb_pred)","e0389d79":"from sklearn.ensemble import RandomForestClassifier","2df6e9a1":"rf1 = RandomForestClassifier()\n\nrf1.fit(X1_train, y1_train)\n\ny1_dt_pred = rf1.predict(X1_test)\n\nmostra_metricas(y1_test, y1_dt_pred)","2305f646":"rf2 = RandomForestClassifier()\n\nrf2.fit(X2_train, y2_train)\n\ny2_dt_pred = rf2.predict(X2_test)\n\nmostra_metricas(y2_test, y2_dt_pred)","64063eeb":"def nova_predicao(texto):\n  '''Funcao que recebe uma string e printa a pedicao feita\n  pelo modelo reglog2.'''\n  texto_vetorizado = tfidf_vect.transform([texto])\n  pred = reglog2.predict(texto_vetorizado)\n\n  if pred == 0:\n    print(\"Essa \u00e9 uma review negativa.\")\n  else:\n    print(\"Essa \u00e9 uma review positiva.\")","29d42281":"nova_predicao(\"Demorou muito n\u00e3o gostei\")","5b3434d0":"nova_predicao(\"Achei cheirosinho\")","a9500bf8":"nova_predicao(\"Nossa que produto ruim \u00e9 esse parece que encontrei no lixo\")","b3b8f41d":"nova_predicao(\"Gostei\")","7443f82f":"nova_predicao(\"N\u00e3o gostei\")","8521397a":"### BoW","2adfdcbd":"### Texto vetorizado com tf-idf","73498610":"Como nosso foco \u00e9 a an\u00e1lise de sentimentos, n\u00e3o precisamos das colunas `order_id`, `review_creation_date` e `review_answer_timestamp`.","cefedecc":"Palavras como 'n\u00e3o' e 'nem' podem ser importantes na an\u00e1lise de sentimentos, por isso vamos tir\u00e1-las da lista de stopwords.","734b5a1a":"Primeiro, \u00e9 preciso dividir os dados em base de treino (70%) e teste (30%).","a2297a76":"### Tf-idf","8b02e6f3":"Vamos checar se h\u00e1 dados duplicados.","bdaf568f":"### Importando as bibliotecas necess\u00e1rias","c1f90b7c":"# Feature extraction\n","e8bac3b9":"Como tinham reviews com apenas n\u00fameros ou s\u00edmbolos, ainda h\u00e1 dados faltantes na coluna `review`, vamos remov\u00ea-los.","e3e2026f":"## Regress\u00e3o Log\u00edstica","02f507af":"Vamos testar dois m\u00e9todos: Bag of Words com um vetor de componentes bin\u00e1rios ou TF-IDF.","5d2a6ceb":"### Review scores","3f81008f":"Vamos agora analisar as m\u00e9tricas:","4b879de2":"# An\u00e1lise de Sentimentos - Reviews do site Olist\n\nO objetivo desse notebook \u00e9 treinar um modelo de an\u00e1lise de sentimentos com o dataset [Brazilian E-Commerce Public Dataset by Olist](https:\/\/www.kaggle.com\/olistbr\/brazilian-ecommerce), comparando duas t\u00e9cnicas cl\u00e1ssicas de feature extraction: Bag of Words e TF-IDF.\n\nSobre o dataset: foi usado o arquivo `olist_order_reviews_dataset.csv`, que cont\u00e9m reviews de compras feitas no site Olist.\n\nO notebook pode ser facilmente acompanhado por iniciantes em NLP, mas os seguintes materias podem ajudar em caso de d\u00favidas:\n  - [Pr\u00e9-processamento](https:\/\/medium.com\/turing-talks\/introdu%C3%A7%C3%A3o-ao-processamento-de-linguagem-natural-com-baco-exu-do-blues-17cbb7404258)\n  - [Bag of Words e TF-IDF](https:\/\/medium.com\/turing-talks\/introdu%C3%A7%C3%A3o-a-bag-of-words-e-tf-idf-43a128151ce9?source=collection_detail----a9511cd63c8b-----24-----------------------)\n  - [M\u00e9tricas de classifica\u00e7\u00e3o](https:\/\/medium.com\/turing-talks\/como-avaliar-seu-modelo-de-classifica%C3%A7%C3%A3o-acd2a03690e?source=collection_detail----a9511cd63c8b-----37-----------------------)\n  - [Regress\u00e3o log\u00edstica](https:\/\/medium.com\/turing-talks\/turing-talks-14-modelo-de-predi%C3%A7%C3%A3o-regress%C3%A3o-log%C3%ADstica-7b70a9098e43), [Naive Bayes](https:\/\/medium.com\/turing-talks\/turing-talks-16-modelo-de-predi%C3%A7%C3%A3o-naive-bayes-6a3e744e7986?source=collection_detail----a9511cd63c8b-----66-----------------------) e [Random Forest](https:\/\/medium.com\/turing-talks\/turing-talks-18-modelos-de-predi%C3%A7%C3%A3o-random-forest-cfc91cd8e524)\n\nFeedbacks s\u00e3o bem-vindos! :)","1705a12a":"H\u00e1 bem mais reviews positivas do que negativas.","b2d2da5e":"Importando as m\u00e9tricas que ser\u00e3o usadas para avalia\u00e7\u00e3o de cada modelo:","fe543e01":"### Com TF-IDF","4b16c0d6":"### Com Bag of Words","f1c871ce":"Temos pouco menos de 100000 datapoints, todos possundo um score de review, mas nem todos possuem review escrita.\n\nComo estamos interessados justamente no texto, vamos juntar as colunas `review_comment_title` e `review_comment_message` em uma s\u00f3 e tirar entradas que n\u00e3o possuem texto.","06f1523f":"## Resultados","231cd25a":"### Limpando o dataset","179ea3dd":"# Modelos","e523ac0c":"# Pr\u00e9-processamento\n","4c927be9":"## Random Forest","f6858759":"### Texto vetorizado com Bag of Words","c532a65f":"## Naive Bayes Multinomial","417de1d5":"### Tf-idf","5362460c":"H\u00e1 5 valores de score diferentes (indo de 1 - pior at\u00e9 5 - melhor), por\u00e9m, para facilitar nossa tarefa, vamos classificar as reviews apenas como positiva ou negativa. Se o score for menor ou igual a 3, consideraremos negativa (0) e caso contr\u00e1rio, positiva (1). ","711c5100":"### Pr\u00e9-processamento do texto","b291ae9c":"### BoW","e96aaef0":"Para todos os modelos, a diferen\u00e7a entre usar Bag of Words ou TF-IDF foi bem pequena. Os modelos apresentaram melhores m\u00e9tricas com TF-IDF, com exce\u00e7\u00e3o do Naive Bayes.\n\nO melhor modelo foi a regress\u00e3o log\u00edstica (com TF-IDF), com acur\u00e1cia e F1 de 90% e AUROC de 89% (arredondando).\nVamos test\u00e1-lo com um novo texto:","cd77f586":"A diferen\u00e7a do desempenho do modelo com os 2 m\u00e9todos de feature extraction \u00e9 pouca, mas todas as m\u00e9tricas apontam ele foi melhor com tf-idf."}}