{"cell_type":{"e12caa86":"code","0079b7b8":"code","99a930df":"code","f7fb4994":"code","108d774c":"code","9b7744a4":"code","1569a698":"code","00024198":"code","1f8e0cae":"code","a9ae51eb":"code","a2b82043":"code","dedaa87a":"code","d6a78dfb":"code","39564605":"code","a02a3bb2":"code","3fe90245":"code","5fc2f0ae":"code","7d6450e3":"code","3df8f95d":"code","83b6f6d5":"code","fd4e9505":"code","b0917007":"code","5844e7d8":"code","0e7d6edb":"code","4aab3e88":"code","06fb2480":"code","7d4c94e8":"code","5e4324d2":"code","546ed853":"code","af111942":"code","d2113261":"code","6fd819c4":"markdown","dcc0bbd0":"markdown","3d189d61":"markdown","ccf388b4":"markdown","807c0680":"markdown","342c0c93":"markdown","99423a45":"markdown","e91f8d26":"markdown","a7348bac":"markdown","c452f637":"markdown","ff96a431":"markdown"},"source":{"e12caa86":"from sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom math import sqrt\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')","0079b7b8":"train = pd.read_csv('\/kaggle\/input\/food-demand-forecasting\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/food-demand-forecasting\/test.csv')\nmeal = pd.read_csv('\/kaggle\/input\/food-demand-forecasting\/meal_info.csv')\ncenterinfo = pd.read_csv('\/kaggle\/input\/food-demand-forecasting\/fulfilment_center_info.csv')","99a930df":"train.head()","f7fb4994":"centerinfo.head()","108d774c":"meal.head()","9b7744a4":"train.describe()","1569a698":"train.info()","00024198":"train_cat = train[['center_id','meal_id','emailer_for_promotion','homepage_featured']]\ntrain_num = train[['week','checkout_price']]\n","1f8e0cae":"for i in train_num.columns:\n    plt.hist(train_num[i])\n    plt.title(i)\n    plt.show()","a9ae51eb":"sns.heatmap(train_num.corr())","a2b82043":"for i in train_cat.columns:\n    plt.xticks(rotation=90)\n    sns.barplot(train_cat[i].value_counts().index,train_cat[i].value_counts()).set_title(i)\n    plt.show()\n    ","dedaa87a":"for i in train_num.columns:\n    sns.boxplot(train_num[i])\n    plt.title(i)\n    plt.show()","d6a78dfb":"def outlinefree(dataCol):     \n      \n    sorted(dataCol)                          # sort column\n    Q1,Q3 = np.percentile(dataCol,[25,75])   # getting 25% and 75% percentile\n    IQR = Q3-Q1                              # getting IQR \n    LowerRange = Q1-(1.5 * IQR)              # getting Lowrange\n    UpperRange = Q3+(1.5 * IQR)              # getting Upperrange \n    \n    colname = dataCol.tolist()               # convert column into list  \n    newlist =[]                              # empty list for store new values\n    for i in range(len(colname)):\n        \n        if colname[i] > UpperRange:          # list number > Upperrange \n            colname[i] = UpperRange          # then number = Upperrange\n            newlist.append(colname[i])       # append value to empty list\n        elif colname[i] < LowerRange:        # list number < Lowrange \n            colname[i] = LowerRange          # then number = Lowrange\n            newlist.append(colname[i])       # append value to empty list \n        else:\n            colname[i]                       # list number\n            newlist.append(colname[i])       # append value to empty list\n            \n        \n\n    return newlist","39564605":"for i in range(len(train_num.columns)):\n    new_list =  outlinefree(train.loc[:,train_num.columns[i]]) # retrun new list\n    train.loc[:,train_num.columns[i]] = new_list ","a02a3bb2":"def center_id(datacol):\n    center_id_val_index_n = []\n    for i in datacol:\n        if i >= 10 and i <= 30:\n            center_id_val_index_n.append(\"10-30\")\n        elif i >= 31 and i <=50:\n            center_id_val_index_n.append(\"31-50\")\n        elif i >= 51 and i <=70:\n            center_id_val_index_n.append(\"51-70\")  \n        elif i >= 71 and i <=90:\n            center_id_val_index_n.append(\"71-90\")\n        elif i >= 91 and i <=110:\n            center_id_val_index_n.append(\"91-110\") \n        elif i >= 111 and i <=130:\n            center_id_val_index_n.append(\"111-130\")\n        elif i >= 131 and i <=150:\n            center_id_val_index_n.append(\"131-150\")          \n        else:\n            center_id_val_index_n.append(\"151-190\")\n    \n    return  center_id_val_index_n \ncenter_id_val_index_n = center_id(train.center_id) \ntrain.center_id = center_id_val_index_n","3fe90245":"def meal_id(datacol):        \n    meal_id_val_index_n = []\n    for i in datacol:\n        if i >= 1000 and i <= 1300:\n            meal_id_val_index_n.append(\"1000-1300\")\n        elif i >= 1301 and i <=1600:\n            meal_id_val_index_n.append(\"1301-1600\")\n        elif i >= 1601 and i <=1900:\n            meal_id_val_index_n.append(\"1601-1900\")  \n        elif i >= 1901 and i <=2200:\n            meal_id_val_index_n.append(\"1901-2200\")\n        elif i >= 2201 and i <=2500:\n            meal_id_val_index_n.append(\"2201-2500\") \n        elif i >= 2501 and i <=2800:\n            meal_id_val_index_n.append(\"2501-2800\")          \n        else:\n            meal_id_val_index_n.append(\"2801-3000\") \n    return  meal_id_val_index_n\n\nmeal_id_val_index_n = meal_id(train.meal_id)\ntrain.meal_id = meal_id_val_index_n","5fc2f0ae":"sns.pairplot(train)","7d6450e3":"f_train = train.loc[:,['num_orders','week','center_id','meal_id','checkout_price','base_price','emailer_for_promotion',\n                 'homepage_featured']]\nfinal_train = pd.get_dummies(f_train)","3df8f95d":"features = final_train.iloc[:,1:].values\nlabel = final_train.iloc[:,:1].values","83b6f6d5":"#------------------------------------ LinearRegression ---------------------------------------------\nX_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.20,random_state=1705)\nmodel = LinearRegression()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)","fd4e9505":"print(\"R2 score  :\",r2_score(y_test, y_pred))\nprint(\"MSE score  :\",mean_squared_error(y_test, y_pred))\nprint(\"RMSE: \",sqrt(mean_squared_error(y_test, y_pred)))","b0917007":"#------------------------------------ DecisionTreeRegressor---------------------------------------------\nX_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.20,random_state=1956)\nDTRmodel = DecisionTreeRegressor(max_depth=3,random_state=0)\nDTRmodel.fit(X_train,y_train)\ny_pred = DTRmodel.predict(X_test)","5844e7d8":"print(\"R2 score  :\",r2_score(y_test, y_pred))\nprint(\"MSE score  :\",mean_squared_error(y_test, y_pred))\nprint(\"RMSE: \",sqrt(mean_squared_error(y_test, y_pred)))","0e7d6edb":"#------------------------------------ RandomForestRegressor ---------------------------------------------\nX_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.20,random_state=33)\nRFRmodel = RandomForestRegressor(max_depth=3, random_state=0)\nRFRmodel.fit(X_train,y_train)\ny_pred = RFRmodel.predict(X_test)","4aab3e88":"print(\"R2 score  :\",r2_score(y_test, y_pred))\nprint(\"MSE score  :\",mean_squared_error(y_test, y_pred))\nprint(\"RMSE: \",sqrt(mean_squared_error(y_test, y_pred)))","06fb2480":"center_id_val_index_n = center_id(test.center_id) \ntest.center_id = center_id_val_index_n\n\nmeal_id_val_index_n = meal_id(test.meal_id)\ntest.meal_id = meal_id_val_index_n","7d4c94e8":"f_test = test.loc[:,['week','center_id','meal_id','checkout_price','base_price','emailer_for_promotion',\n                 'homepage_featured']]\nfinal_test = pd.get_dummies(f_test)","5e4324d2":"test_predict = RFRmodel.predict(final_test)","546ed853":"test['num_orders'] = test_predict","af111942":"sample =  test.loc[:,['id','num_orders']]","d2113261":"sample.to_csv('sample_submission.csv',index=False)","6fd819c4":"## Feature Selection\n1. seaborn.pairplot(): It is help to figure-out relation between features and label.","dcc0bbd0":"## Applying Algorithm\nbefore applying the algorithm to the test dataset. we should make it a complete numeric dataset. the following setups are below mentioned.\n1. columns center_id and meal_id has many categorical values.\n2. to manage categorical columns we using function their create new few sub-categories.\n3. using get_dummies() function.\n4. here our data is ready to apply an algorithm on it.","3d189d61":"## Data Normalization\n1. for-loop: here we checked outliers occur or not? \"checkout_price\" column has occurred an outlier. \n2. outlinefree() : It is a customise function that help us to figureout and work on outlier values in columns. meanly, it is used to **remove outlires** values from dataset.\n3. for-loop: with the help of for-loop, we are checking the **outlinefree()** function worked properly or not.\n4. columns **center_id** and **meal_id** has many categorical values.\n5. to manage categorical columns we using function their create new few sub-categories.\n","ccf388b4":"## Overview \n### 1) Context\n\n### 2) Content\n\n### 3) Used Python Libraries\n\n### 4 ) Know Dataset Nature\n\n### 5) Light Data Exploration\n\n### 6) Data Normalization\n\n### 7) Light Data Exploration\n\n### 8) Data Normalization\n\n### 6) Feature Selection\n\n### 7) Model Buliding \n\n### 8) Conclusion\n\n### 9) Applying Algorithm \n\n","807c0680":"## Context\nIt is a meal delivery company which operates in multiple cities. They have various fulfillment centers in these cities for dispatching meal orders to their customers. The client wants you to help these centers with demand forecasting for upcoming weeks so that these centers will plan the stock of raw materials accordingly.\n\n## Content\nThe replenishment of majority of raw materials is done on weekly basis and since the raw material is perishable, the procurement planning is of utmost importance. Secondly, staffing of the centers is also one area wherein accurate demand forecasts are really helpful. Given the following information, the task is to predict the demand for the next 10 weeks (Weeks: 146-155) for the center-meal combinations in the test set\n\n## Acknowledgements\nAnalytics Vidhya\n\n## Inspiration\nForecasting accurately could male the business growth in well directed direction.\n","342c0c93":"## Model Buliding\nhere we will be using many algorithms and compare all of them. which algorithm will be giving us a Better result. The following algorithms are below.\n\n1. LinearRegression (RMSE: 334.45162241353864)\n2. DecisionTreeRegressor (RMSE:  332.8261160204239)\n3. **RandomForestRegressor (RMSE: 331.0142032987282)**","99423a45":"## Conclusion\nI will choose a **RandomForestRegressor algorithm** for this dataset.\n\n**RandomForestRegressor score**:\n\n1. **RMSE score : 331.0142032987282** \n","e91f8d26":"## Used Python Libraries","a7348bac":"# Food Demand Forecasting\nPredict the number of orders for upcoming 10 weeks","c452f637":"## Know Dataset Nature\n1. head() : It is used to get the first 5 rows of the dataframe.\n2. tail() : It is used to get the last 5 rows of the dataframe.\n3. describe() : It is used to view some basic statistical details like percentile, mean, std etc.\n4. info() : It is used to print a concise summary of a DataFrame. including the index dtype and column dtypes, non-null values and memory usage","ff96a431":"## Light Data Exploration\n### 1) For numeric data\n  * Made histograms to understand distributions\n  * Corrplot\n\n### 2) For Categorical Data\n   * Made bar charts to understand balance of classes"}}