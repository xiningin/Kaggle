{"cell_type":{"0cb7eb9d":"code","da03d28e":"code","e7f14f0b":"code","4c70311e":"code","aa80fbc4":"code","d3f856fd":"code","aa816911":"code","b9de1e86":"code","07861c59":"code","e8b35440":"code","7594c4b8":"code","d262c8b6":"code","6f307810":"code","284d2ab2":"code","51145b1c":"code","839fb1ed":"code","f6a784b6":"code","5be57eb5":"code","b587a72c":"code","643202bc":"code","5a712b31":"code","f3243db4":"code","66e54b7e":"code","c863706d":"code","523a148d":"code","4bea32c2":"code","76aecc56":"code","e94cb2a6":"code","c76eb89c":"code","d84fdd62":"code","3d29e5cc":"code","12b9b558":"markdown","f1bdc2b3":"markdown","af45aa26":"markdown","4ec7b8e9":"markdown","c5e38c98":"markdown","15f7087e":"markdown","49ffdefb":"markdown","dda3b1e8":"markdown","ccdd8c8a":"markdown","b17a5276":"markdown"},"source":{"0cb7eb9d":"#importing dependencies\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler","da03d28e":"#loading the dataset to pandas dataframe\ncredit_card_data = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","e7f14f0b":"#first five rows\ncredit_card_data.head()","4c70311e":"#last 5 rows\ncredit_card_data.tail()","aa80fbc4":"credit_card_data.info()","d3f856fd":"credit_card_data.isnull().sum()","aa816911":"#distribution of legit and fraudulent data transactions\ncredit_card_data['Class'].value_counts()","b9de1e86":"# seperating the data for analysis\nlegit = credit_card_data[credit_card_data.Class == 0]\nfraud = credit_card_data[credit_card_data.Class == 1]","07861c59":"print(legit.shape)\nprint(fraud.shape)","e8b35440":"#statstical measures of the data\nlegit.Amount.describe()","7594c4b8":"fraud.Amount.describe()","d262c8b6":"#compare the values of both transactions\ncredit_card_data.groupby('Class').mean()","6f307810":"legit_sample = legit.sample(n=492)","284d2ab2":"new_dataset = pd.concat([legit_sample,fraud], axis = 0)","51145b1c":"new_dataset.head()","839fb1ed":"new_dataset.tail()","f6a784b6":"new_dataset['Class'].value_counts()","5be57eb5":"new_dataset.groupby('Class').mean()","b587a72c":"X = new_dataset.drop(columns='Class',axis = 1)\nY = new_dataset['Class']","643202bc":"print(X)","5a712b31":"print(Y)","f3243db4":"X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2,stratify = Y,random_state = 2)","66e54b7e":"print(X.shape,X_train.shape,X_test.shape)","c863706d":"model = LogisticRegression(max_iter=100)\n","523a148d":"#training the LogisticRegression model with training data\nmodel.fit(X_train,Y_train)\n\n","4bea32c2":"#Accuracy on training data\nX_train_prediction = model.predict(X_train)","76aecc56":"training_data_accuracy = accuracy_score(X_train_prediction,Y_train)","e94cb2a6":"print('Accuracy on training data', training_data_accuracy)","c76eb89c":"#Accuracy on test data\nX_test_prediction = model.predict(X_test)","d84fdd62":"test_data_accuracy = accuracy_score(X_test_prediction, Y_test)","3d29e5cc":"print('Accuracy score on test data', test_data_accuracy)","12b9b558":"This dataset is highly unbalanced\n0---> normal transaction\n1---> fraudulent transaction\n","f1bdc2b3":"Model training","af45aa26":"Accuracy score","4ec7b8e9":"Splitting the data into features and targets","c5e38c98":"concatenating two data frames","15f7087e":"split the data into training data and testing data","49ffdefb":"Undersampling\nBuild a sample dataset containing the similar distribution of normal transaction and fraudulent transactions.","dda3b1e8":"Model evaluation","ccdd8c8a":"Number of fraudulent transactions ---> 492","b17a5276":"LogisticRegression"}}