{"cell_type":{"7e5cc86b":"code","4233aa20":"code","d1f33540":"code","32c1fe2c":"code","d10fe8f5":"code","4f51714d":"code","d62a80f4":"code","41d19e9b":"code","36bc56b3":"code","4719a295":"code","46882926":"markdown","dde8ea61":"markdown","f028bb35":"markdown"},"source":{"7e5cc86b":"!pip install --upgrade pip > \/dev\/null\n!pip install --upgrade transformers > \/dev\/null\n!pip install nlp > \/dev\/null","4233aa20":"import os\nimport gc\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport plotly.express as px\n\n# NN\nfrom tensorflow.keras.layers import Dense, Input, GlobalAveragePooling1D, GlobalMaxPooling1D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\nfrom transformers import TFAutoModel, AutoTokenizer\nimport nlp","d1f33540":"def init_strategy():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Init TPU strategy\")\n    except ValueError:\n        strategy = tf.distribute.get_strategy() # for CPU and single GPU\n        print(\"Init CPU\/GPU strategy\")\n    return strategy\n\ndef build_model(model_name, maxlen, head=\"avg_pooling\"):\n    input_ids = Input(shape=(maxlen,), dtype=tf.int32, name=\"input_ids\")\n    encoder = TFAutoModel.from_pretrained(model_name)\n    encoder_output = encoder(input_ids)[0]\n    \n    # convert transformer encoding to vector\n    if head == \"cls\":\n        features = encoder_output[:, 0, :] # using first token as encoder feature map\n    elif head == \"avg_pooling\":\n        features = GlobalAveragePooling1D()(encoder_output)\n    elif head == \"max_pooling\":\n        features = GlobalMaxPooling1D()(encoder_output)\n    else:\n        raise NotImplementedError\n    \n    # 3class softmax\n    out = Dense(3, activation='softmax')(features)\n    \n    # define model\n    model = Model(inputs=input_ids, outputs=out)\n    model.compile(\n        Adam(lr=1e-5), \n        loss='sparse_categorical_crossentropy', \n        metrics=['accuracy']\n    )\n    return model\n\ndef tokenize_dataframe(df, tokenizer, max_length):\n    # tokenize\n    text = df[['premise', 'hypothesis']].values.tolist()\n    encoded = tokenizer.batch_encode_plus(text, padding=True, max_length=max_length, truncation=True)\n    # features\n    x = encoded['input_ids']\n    # labels\n    y = None\n    if 'label' in df.columns:\n        y = df.label.values\n    return x, y\n\ndef build_dataset(x, y, mode, batch_size):\n    if mode == \"train\":\n        dataset = (\n            tf.data.Dataset\n            .from_tensor_slices((x, y))\n            .repeat()\n            .shuffle(2048)\n            .batch(batch_size)\n            .prefetch(auto)\n        )\n    elif mode == \"valid\":\n        dataset = (\n            tf.data.Dataset\n            .from_tensor_slices((x, y))\n            .batch(batch_size)\n            .cache()\n            .prefetch(auto)\n        )\n    elif mode == \"test\":\n        dataset = (\n            tf.data.Dataset\n            .from_tensor_slices(x)\n            .batch(batch_size)\n        )\n    else:\n        raise NotImplementedError\n    return dataset\n\ndef load_mnli(use_validation=True):\n    result = []\n    dataset = nlp.load_dataset(path='glue', name='mnli')\n    keys = ['train', 'validation_matched','validation_mismatched'] if use_validation else ['train']\n    for k in keys:\n        for record in dataset[k]:\n            c1, c2, c3 = record['premise'], record['hypothesis'], record['label']\n            if c1 and c2 and c3 in {0,1,2}:\n                result.append((c1,c2,c3,'en'))\n    result = pd.DataFrame(result, columns=['premise','hypothesis','label','lang_abv'])\n    return result\n\ndef load_xnli():\n    result = []\n    dataset = nlp.load_dataset(path='xnli')\n    for k in dataset.keys():\n        for record in dataset[k]:\n            hp, pr, lb = record['hypothesis'], record['premise'], record['label']\n            if hp and pr and lb in {0,1,2}:\n                for lang, translation in zip(hp['language'], hp['translation']):\n                    pr_lang = pr.get(lang, None)\n                    if pr_lang is None:\n                        continue\n                    result.append((pr_lang, translation, lb,lang))\n    result = pd.DataFrame(result, columns=['premise','hypothesis','label','lang_abv'])\n    return result\n","32c1fe2c":"MODEL = 'jplu\/tf-xlm-roberta-large'\nMAXLEN = 120\nstrategy = init_strategy()\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\nauto = tf.data.experimental.AUTOTUNE\n\ndef preprocess(df):\n    return tokenize_dataframe(df, tokenizer, MAXLEN)","d10fe8f5":"# load data\ntrain = pd.read_csv('\/kaggle\/input\/contradictory-my-dear-watson\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/contradictory-my-dear-watson\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/contradictory-my-dear-watson\/sample_submission.csv')\n\n# preprocess\nx, y = preprocess(train)\nx_test, _ = preprocess(test)\ntest_dataset = build_dataset(x_test, None, \"test\", BATCH_SIZE)\n\n# load external datasets for interpretation purpose\nmnli = load_mnli()\nxnli = load_xnli()","4f51714d":"import re\nimport string\npunct = '[' + ''.join([c for c in string.punctuation if c != \"'\"]) + ']'\n\ndef preprocess_query(q):\n    q = q.lower()\n    q = re.sub(punct, ' ', q)\n    q = re.sub('[ ]{2,}', ' ', q)\n    return q\n\ndef search_in_base(q, kb):\n    q = preprocess_query(q)\n    return int(q in kb)\n","d62a80f4":"premises = pd.concat([train[['premise', 'lang_abv']], test[['premise', 'lang_abv']]])","41d19e9b":"knowledge_base = set(mnli['premise'].apply(preprocess_query))\npremises['mnli'] = premises['premise'].apply(lambda q: search_in_base(q, knowledge_base))\nprint(f\"fraction of train set english premises occurence in MNLI = {premises.loc[premises.lang_abv=='en', 'mnli'].mean() * 100}%\")","36bc56b3":"knowledge_base = set(xnli['premise'].apply(preprocess_query))\npremises['xnli'] = premises['premise'].apply(lambda q: search_in_base(q, knowledge_base))\nprint(f\"fraction of train set non-english premises occurence in XNLI = {premises.loc[premises.lang_abv!='en', 'xnli'].mean() * 100}%\")","4719a295":"# save results \nstrategy = init_strategy()\nwith strategy.scope():\n    model = build_model(MODEL, MAXLEN)\n    model.load_weights(\"..\/input\/watson-xlmr-models\/XLMR_mnlixnli_ep6.h5\")\n    \ndataset = build_dataset(x, y, \"valid\", BATCH_SIZE)\npr = np.argmax(model.predict(dataset), axis=1)\nprint(f\"accuracy {accuracy_score(y, pr):.4f}\")\n\ntest_preds = model.predict(test_dataset, verbose=0)\nsubmission['prediction'] = test_preds.argmax(axis=1)\nsubmission.to_csv('submission.csv', index=False)","46882926":"#### Let's build toy search engine: it's looking for a full match of query and knowledge base.","dde8ea61":"#### As we can see, external datasets completely include train and test data, and it's obvious overfitting :)","f028bb35":"Hello!\n\nThis is inference notebook from this [train notebook](https:\/\/www.kaggle.com\/alturutin\/watson-xml-r-nli-train).\n\nAlso, I interpeted results and showed why the accuracy in this competition is so high.\n"}}