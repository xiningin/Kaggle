{"cell_type":{"d940eb09":"code","9c946be8":"code","8643e49b":"code","ff8bb3d6":"code","c4161139":"code","003ebee4":"code","eaf5ca03":"code","0b32cf99":"code","19476bf2":"code","cb1a0ee9":"code","fb244e19":"code","43a54301":"code","eebb46ae":"code","fe386c47":"code","436866de":"code","75d9d17c":"code","e84919fa":"code","c93fce73":"code","c06ff8c5":"code","5b9eb1af":"code","057f753b":"code","6534d834":"code","d0dbc6e2":"code","a0b61445":"code","fa0d79f2":"code","29ac8f51":"code","3c535b58":"code","18e3ebd5":"code","b0c8bbf5":"code","e68b8dc7":"code","ac68ae98":"code","fdde8364":"code","cd102152":"code","f73840cd":"code","ce33a577":"code","f13e2725":"code","e8d611f7":"code","33537435":"code","e8af4d0c":"code","afd66e75":"code","005af6ef":"code","50ab0c42":"code","b81ae47c":"code","d05714ba":"code","5b0ed127":"code","7aa5fdcb":"code","e5fada19":"code","e8e89c21":"code","010a6c79":"code","b2cfc692":"code","9939d854":"code","1b8dccf0":"code","a057527c":"code","3c4387cb":"code","b75f64e9":"code","67df4cd1":"code","9a7745fc":"code","9d72c430":"code","9389faa3":"code","c8a01ff8":"code","0131545b":"code","74769123":"code","b7e5d108":"code","2e043225":"code","1fa95e62":"code","cc1f83c0":"code","9cbb618a":"code","0efa0b78":"code","54d0f4ec":"code","260ceff9":"code","e4d99cad":"code","d33e71c0":"code","c8965075":"code","1ac0442b":"code","ca751386":"code","6f946999":"code","4a89967e":"code","c7513e3d":"code","11163e2b":"code","40fb1eea":"code","5a69d188":"code","cc23a84b":"code","f7ae2c24":"code","07af346e":"code","8b471fcd":"code","9b212a11":"code","0047388c":"code","587da556":"code","a32a7995":"code","cd0ffcdb":"code","821d3c0b":"code","075eb9a4":"code","e837425a":"code","152a0ee7":"code","d4f1ec22":"code","87cb0e6f":"code","4554e467":"markdown","08b687af":"markdown","49d30dfc":"markdown","520e1bdd":"markdown","07d8b38a":"markdown","edb90f80":"markdown","24fc00bd":"markdown","0a47c4e3":"markdown","5e05e62e":"markdown","3388b5db":"markdown","c34c6982":"markdown","e99126c2":"markdown","36e4dd89":"markdown","8df4e2a6":"markdown","8c1f4df1":"markdown","3faac91d":"markdown","12147b84":"markdown","a15a22f6":"markdown","413bf063":"markdown","2ccc6041":"markdown","5a73fe51":"markdown","8c10cfba":"markdown","9ab9d295":"markdown","baee46fb":"markdown","c8cf9453":"markdown","ce094ce5":"markdown","aacfd1a1":"markdown","8145c818":"markdown","6b2a45f1":"markdown","093b4fea":"markdown","2c2fcc36":"markdown","cad2dc6a":"markdown","41170d82":"markdown","4cf8ee92":"markdown","ba58b13f":"markdown","81e35cb9":"markdown","37da1557":"markdown","f7e9731c":"markdown","b1deb80b":"markdown","e0500267":"markdown","bcfa4611":"markdown","ce279bed":"markdown","dd3278e3":"markdown","4d52182a":"markdown","07edbc9c":"markdown","6e41ee08":"markdown","956d8e8c":"markdown","bf351def":"markdown","e9989421":"markdown","37d4ab07":"markdown","a5d46cc1":"markdown","03a964b9":"markdown"},"source":{"d940eb09":"#!pip install mglearn","9c946be8":"#!pip install pingouin","8643e49b":"# Importamos librerias necesarias\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\n#import pingouin as pg\n\n# Para preprocesamiento de datos\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.preprocessing import PolynomialFeatures\n\n\nfrom sklearn.decomposition import PCA\n\n# para entrenamientos de modelo\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error","ff8bb3d6":"# Celda para Kaggle\n# Load the data, and separate the target\ntrain_file_path = '..\/input\/train.csv'\ntest_data_path = '..\/input\/test.csv'\n\ndata_housing = pd.read_csv(train_file_path)\ndata_housing_test = pd.read_csv(test_data_path)\ny = data_housing.SalePrice","c4161139":"# Creacion de dataset para contener Id de test csv\ndata_housing = data_housing.drop('Id',axis=1)\ndata_to_predict = pd.DataFrame(columns=['Id','SalePrice'])\n\n\n# Eliminando columna Id de dataset test para posterior uso de prediccion\ndata_to_predict.Id = data_housing_test.Id\ndata_housing_test = data_housing_test.drop('Id',axis=1)","003ebee4":"data_to_predict.info()","eaf5ca03":"# Ver info del dataset de train\n\ndata_housing.info()","0b32cf99":"# ver info dataset de test\n\ndata_housing_test.info()","19476bf2":"# ver la descripcion de los numericos\n\n# guardar columnas numericas\ndata_housing_number_columns = list(data_housing.describe().columns)\n\ndisplay(data_housing_number_columns)\n\ndata_housing.describe()","cb1a0ee9":"# Ver la descripcion de los object\n\n# Guaradar columnas categoricas\ndata_housing_object_columns = list(data_housing.describe(include='object').columns)\n\ndisplay(data_housing_object_columns)\n\ndata_housing.describe(include='object')","fb244e19":"# Nos dimos cuenta que valores NA de categoricos eran tomados como nulos, pero si representan un valor en la caracteristica \n\ndata_housing2 = data_housing[data_housing_object_columns].replace(to_replace=np.nan,value='NA')\ndata_housing_test2 = data_housing_test[data_housing_object_columns].replace(to_replace=np.nan,value='NA')\ndisplay(data_housing2.info())\ndisplay(data_housing_test2.info())","43a54301":"# Reemplazamos en el dataset original las conversiones de tipo\n\ndata_housing[data_housing_object_columns] = data_housing2\ndata_housing_test[data_housing_object_columns] = data_housing_test2","eebb46ae":"# Visualizamos algunas filas del dataset\n\ndata_housing.head()","fe386c47":"# Visualizamos algunas filas del dataset\n\ndata_housing_test.head()","436866de":"# Observamos de forma general que valores pueden faltar\n# De acuerdo a la descripcion de los datos, el valor NA presente en varias caracteristicas numericas\n# Significa la ausencia de esa caracteristica, mas no como que es un valor faltante.\ndata_housing_test = data_housing_test.fillna(0)\ndata_housing_test.info()","75d9d17c":"# Visualizando correlacion de linealidad entre caracteristicas numericas\nn=6\nprint('Correlacion Pearson\\n')\nnumeric_features=data_housing.select_dtypes(include=[np.number])\ncorrP=numeric_features.corr(method='pearson')\nprint (corrP.SalePrice.sort_values(ascending=False)[:n],'\\n') # Cogemos las cinco con mayor corrlaci\u00f3n con SalesPrice\nprint (corrP.SalePrice.sort_values(ascending=True)[:n]) # Cogemos las cinco con menor correlacion con SalesPrice\n","e84919fa":"print('\\n')\nprint('Correlacion Spearman\\n')\ncorrS=numeric_features.corr(method='spearman')\nprint (corrS.SalePrice.sort_values(ascending=False)[:n],'\\n') # Cogemos las cinco con mayor corrlaci\u00f3n con SalesPrice\nprint (corrS.SalePrice.sort_values(ascending=True)[:n]) # Cogemos las cinco con menor correlacion con SalesPrice\nprint('\\n')\n","c93fce73":"print('Correlacion Kendall\\n')\ncorrK=numeric_features.corr(method='kendall')\nprint (corrK.SalePrice.sort_values(ascending=False)[:n],'\\n') # Cogemos las cinco con mayor corrlaci\u00f3n con SalesPrice\nprint (corrK.SalePrice.sort_values(ascending=True)[:n]) # Cogemos las cinco con menor correlacion con SalesPrice\nprint('\\n')","c06ff8c5":"pearson_corr_cols = list(corrP.SalePrice.sort_values(ascending=False)[1:n].index)\npearson_corr_cols\n\nspearman_corr_cols = list(corrS.SalePrice.sort_values(ascending=False)[1:n].index)\nspearman_corr_cols\n\nkendall_corr_cols = list(corrK.SalePrice.sort_values(ascending=False)[1:n].index)\nkendall_corr_cols","5b9eb1af":"# Columnas seleccionadas para el Scaler\n\nscaler_columns = list(['LotFrontage',\n                      'LotArea',\n                      'OverallQual',\n                      'OverallCond',\n                      'MasVnrArea',\n                      'BsmtFinSF1',\n                      'BsmtFinSF2',\n                      'BsmtUnfSF',\n                      'TotalBsmtSF',\n                      '1stFlrSF',\n                      '2ndFlrSF',\n                      'LowQualFinSF',\n                      'GrLivArea',\n                      'BsmtFullBath',\n                      'BsmtHalfBath',\n                      'FullBath',\n                      'HalfBath',\n                      'BedroomAbvGr',\n                      'KitchenAbvGr',\n                      'TotRmsAbvGrd',\n                      'Fireplaces',\n                      'GarageCars',\n                      'GarageArea',\n                      'WoodDeckSF',\n                      'OpenPorchSF',\n                      'EnclosedPorch',\n                      '3SsnPorch',\n                      'ScreenPorch',\n                      'PoolArea',\n                      'MiscVal',\n                      ])","057f753b":"# Columnas Seleccionadas para One Hot Encoding\nohe_columns = list(['MSSubClass',\n                    'GarageYrBlt',\n                    'YearBuilt',\n                    'YearRemodAdd',\n                    'MoSold',\n                    'YrSold',\n                    'MSZoning',\n                    'Street',\n                    'Alley',\n                    'LotShape',\n                    'LandContour',\n                    'Utilities',\n                    'LotConfig',\n                    'LandSlope',\n                    'Neighborhood',\n                    'Condition1',\n                    'Condition2',\n                    'BldgType',\n                    'HouseStyle',\n                    'RoofStyle',\n                    'RoofMatl',\n                    'Exterior1st',\n                    'Exterior2nd',\n                    'MasVnrType',\n                    'Foundation',\n                    'Heating',\n                    'CentralAir',\n                    'Electrical',\n                    'Functional',\n                    'GarageType',\n                    'PavedDrive',\n                    'MiscFeature',\n                    'SaleType',\n                    'SaleCondition'])","6534d834":"# Columnas Seleccionadas para Ordinal Encoder\n\noe_columns = list([ 'ExterQual',\n                    'ExterCond',\n                    'BsmtQual',\n                    'BsmtCond',\n                    'BsmtExposure',\n                    'BsmtFinType1',\n                    'BsmtFinType2',\n                    'HeatingQC',\n                    'KitchenQual',\n                    'FireplaceQu',\n                    'GarageFinish',\n                    'GarageQual',\n                    'GarageCond',\n                    'PoolQC',\n                    'Fence'])","d0dbc6e2":"\n\nlistPFTGE = ['Po','Fa','TA','Gd','Ex']\nlistNPFTGE = ['NA','Po','Fa','TA','Gd','Ex']\nlistNULR = ['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ']\n\nexterQualCat    = listPFTGE\nexterCondCat    = listPFTGE\nbsmtQualCat     = listNPFTGE\nbsmtCondCat     = listNPFTGE\nbsmtExposureCat = ['NA','No','Mn','Av','Gd']\nbsmtFinType1Cat = listNULR\nbsmtFinType2Cat = listNULR\nheatingQCCat    = listPFTGE\nkitcheQualCat   = listPFTGE\nfireplaceQuCat  = listNPFTGE\ngarageFinishCat = ['NA','Unf','RFn','Fin']\ngarageQualCat   = listNPFTGE\ngarageCondCat   = listNPFTGE\npoolQCCat       = ['NA','Fa','TA','Gd','Ex']\nfenceCat        = ['NA','MnWw','GdWo','MnPrv','GdPrv']\n\n#creando lista\noe_cat_list = [ exterQualCat,   \n                exterCondCat,   \n                bsmtQualCat,    \n                bsmtCondCat,    \n                bsmtExposureCat,\n                bsmtFinType1Cat,\n                bsmtFinType2Cat,\n                heatingQCCat,   \n                kitcheQualCat,  \n                fireplaceQuCat, \n                garageFinishCat,\n                garageQualCat,  \n                garageCondCat,  \n                poolQCCat,      \n                fenceCat       ]","a0b61445":"# dataset ordenado\nX = data_housing[scaler_columns+ohe_columns+oe_columns]\nX_val = data_housing_test[scaler_columns+ohe_columns+oe_columns]\n\nprint(X.info(),'\\n\\n')\nprint(X_val.info())","fa0d79f2":"\n\n#X_new = X.drop(['LotFrontage','MasVnrArea','GarageYrBlt'],axis=1)\n#X_new = X.dropna()\nX_new = data_housing.fillna(0) # Limpiar dataset de NA y guardarlo en nuevo dataset\ny = X_new.SalePrice # Obtener el valor de precios despues de dropna\nX_new = X_new.drop('SalePrice',axis=1) # Quitar sales price del dataset para entrenamiento\nX_new_cols = X_new.columns # Obtencion de nombres caracteristicas del dataset\n\n#X_new_num_cols = X_new.describe().columns # nombres caracteristicas solo numeros\n\n# Uso de caracteristicas por correlacion con SalePrice\n\n#X_new_num_cols = pearson_corr_cols # prueba con caracteristicas obtenidas por la correlacion\nX_new_num_cols = spearman_corr_cols # prueba con caracteristicas obtenidas por la correlacion\n#X_new_num_cols = kendall_corr_cols # prueba con caracteristicas obtenidas por la correlacion\n\nX_new_cat_cols = X_new.describe(include='object').columns # nombres caracteristicas solo objetos\n\nX_new.info()\ny.shape","29ac8f51":"testSize = 0.33\ny_log = np.log(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X_new[X_new_num_cols], y, test_size=testSize,random_state=0)\n_,_, y_train_log, y_test_log = train_test_split(X_new[X_new_num_cols], y_log, test_size=testSize,random_state=0)\n\nprint('X_train:\\t', X_train.shape)\nprint('y_train_log:\\t', y_train_log.shape)\nprint('y_train:\\t', y_train.shape)\nprint('X_test:\\t\\t', X_test.shape)\nprint('y_test_log:\\t', y_test_log.shape)\nprint('y_test:\\t\\t', y_test.shape)\n","3c535b58":"X_train","18e3ebd5":"\nlr_orig = LinearRegression()\nlr_orig.fit(X_train,y_train)\ny_pred = lr_orig.predict(X_test)\n\nlr_orig_log = LinearRegression()\nlr_orig_log.fit(X_train,y_train_log)\ny_pred_log = lr_orig_log.predict(X_test)\n\n#SCORE\nlr_orig_score_train = lr_orig.score(X_train,y_train)\nlr_orig_score_test = lr_orig.score(X_test,y_test)\n\n\nlr_orig_score_train_log = lr_orig_log.score(X_train,y_train_log)\nlr_orig_score_test_log = lr_orig_log.score(X_test,y_test_log)\n\n#MSE\nmse_lr_orig = mean_squared_error(y_test,y_pred)\nmse_lr_orig_log = mean_squared_error(y_test_log,y_pred_log)\n\n","b0c8bbf5":"# Score obtenido con solo datos originales\nprint('Score train:\\t\\t',lr_orig.score(X_train,y_train))\nprint('Score test:\\t\\t',lr_orig.score(X_test,y_test))\nprint('Mean Squared Error:\\t',mean_squared_error(y_test,y_pred))\nprint(\"\")\nprint('Score train log:\\t',lr_orig_log.score(X_train,y_train_log))\nprint('Score test log:\\t\\t',lr_orig_log.score(X_test,y_test_log))\nprint('Mean Squared Error Log:\\t',mean_squared_error(y_test_log,y_pred_log))","e68b8dc7":"# Comprobando con un valor de X_test y y_test\nprint('Prediccion sin transformar:\\t',lr_orig.predict(X_test)[0])\nprint('Prediccion transformado:\\t',lr_orig_log.predict(X_test)[0])\nprint('Actual sin transformar:\\t\\t',np.array(y_test)[0])\nprint('Actual transformado:\\t\\t',np.array(y_test_log)[0])","ac68ae98":"# Aqui usamos solo los valores numericos sin dummies usando standar scaler y robust scaler\n\n#Scaler entrenado con X_train solo numerico\n\nstdScaler = StandardScaler().fit(X_train)\nX_train_std = stdScaler.transform(X_train)\nX_test_std = stdScaler.transform(X_test)\n\nprint('X_train_std:\\t', X_train_std.shape)\nprint('y_train_log:\\t', y_train_log.shape)\nprint('y_train:\\t', y_train.shape)\nprint('X_test_std:\\t', X_test_std.shape)\nprint('y_test_log:\\t', y_test_log.shape)\nprint('y_test:\\t\\t', y_test.shape)","fdde8364":"print('Muestra X_train_std:\\n\\n', X_train_std[0,:])","cd102152":"# Se realizar\u00e1 entrenamiento solo con valores num\u00e9ricos\n# tambien se comparar\u00e1 el efecto de hacer la transformacion logaritmica a la salida\n\nlr_orig_std = LinearRegression()\nlr_orig_std.fit(X_train_std,y_train)\ny_pred_std = lr_orig_std.predict(X_test_std)\n\nlr_orig_log_std = LinearRegression()\nlr_orig_log_std.fit(X_train_std,y_train_log)\ny_pred_log_std = lr_orig_log_std.predict(X_test_std)\n\nlr_orig_std_score_train = lr_orig_std.score(X_train_std,y_train)\nlr_orig_std_score_test = lr_orig_std.score(X_test_std,y_test)\nmse_orig_std = mean_squared_error(y_test,y_pred_std)\n\nlr_orig_std_score_train_log = lr_orig_log_std.score(X_train_std,y_train_log)\nlr_orig_std_score_test_log = lr_orig_log_std.score(X_test_std,y_test_log)\nmse_orig_std_log = mean_squared_error(y_test_log,y_pred_log_std)","f73840cd":"# Score obtenido con solo datos originales\n\nprint('Score train:\\t\\t',lr_orig_std.score(X_train_std,y_train))\nprint('Score test:\\t\\t',lr_orig_std.score(X_test_std,y_test))\nprint('Mean Squared Error:\\t',mean_squared_error(y_test,y_pred_std))\nprint(\"\")\nprint('Score train log:\\t',lr_orig_log_std.score(X_train_std,y_train_log))\nprint('Score test log:\\t\\t',lr_orig_log_std.score(X_test_std,y_test_log))\nprint('Mean Squared Error Log:\\t',mean_squared_error(y_test_log,y_pred_log_std))\n","ce33a577":"# Comprobando con un valor de X_test y y_test\n\nprint('Prediccion sin transformar:\\t',lr_orig_std.predict(X_test_std)[0])\nprint('Prediccion transformado:\\t',lr_orig_log_std.predict(X_test_std)[0])\nprint('Actual sin transformar:\\t\\t',np.array(y_test)[0])\nprint('Actual transformado:\\t\\t',np.array(y_test_log)[0])","f13e2725":"# Aqui usamos solo los valores numericos sin dummies usando standar scaler y robust scaler\n\n#Scaler entrenado con X_train solo numerico\n\nrobScaler = RobustScaler().fit(X_train)\nX_train_rob = robScaler.transform(X_train)\nX_test_rob = robScaler.transform(X_test)\n\nprint('X_train_rob:\\t', X_train_rob.shape)\nprint('y_train_log:\\t', y_train_log.shape)\nprint('y_train:\\t', y_train.shape)\nprint('X_test_rob:\\t', X_test_rob.shape)\nprint('y_test_log:\\t', y_test_log.shape)\nprint('y_test:\\t\\t', y_test.shape)","e8d611f7":"print('Muestra X_train_rob:\\n\\n', X_train_rob[0,:])","33537435":"# Se realizar\u00e1 entrenamiento solo con valores num\u00e9ricos\n# tambien se comparar\u00e1 el efecto de hacer la transformacion logaritmica a la salida\n\nlr_orig_rob = LinearRegression()\nlr_orig_rob.fit(X_train_rob,y_train)\ny_pred_rob = lr_orig_rob.predict(X_test_rob)\n\nlr_orig_log_rob = LinearRegression()\nlr_orig_log_rob.fit(X_train_rob,y_train_log)\ny_pred_log_rob = lr_orig_log_rob.predict(X_test_rob)\n\n\n#Scores\nlr_orig_rob_score_train = lr_orig_rob.score(X_train_rob,y_train)\nlr_orig_rob_score_test = lr_orig_rob.score(X_test_rob,y_test)\n\nlr_orig_rob_score_train_log = lr_orig_log_rob.score(X_train_rob,y_train_log)\nlr_orig_rob_score_test_log = lr_orig_log_rob.score(X_test_rob,y_test_log)\n\n\n#MSE\nmse_orig_rob = mean_squared_error(y_test,y_pred_rob)\nmse_orig_rob_log = mean_squared_error(y_test_log,y_pred_log_rob)\n","e8af4d0c":"# Score obtenido con datos escalados con RobustScaler\n\nprint('Score train:\\t\\t',lr_orig_rob.score(X_train_rob,y_train))\nprint('Score test:\\t\\t',lr_orig_rob.score(X_test_rob,y_test))\nprint('Mean Squared Error:\\t',mean_squared_error(y_test_log,y_pred_rob))\nprint(\"\")\nprint('Score train log:\\t',lr_orig_log_rob.score(X_train_rob,y_train_log))\nprint('Score test log:\\t\\t',lr_orig_log_rob.score(X_test_rob,y_test_log))\nprint('Mean Squared Error Log:\\t',mean_squared_error(y_test_log,y_pred_log_rob))","afd66e75":"# Comprobando con un valor de X_test y y_test\n\nprint('Prediccion sin transformar:\\t',lr_orig_std.predict(X_test_std)[0])\nprint('Prediccion transformado:\\t',lr_orig_log_std.predict(X_test_std)[0])\nprint('Actual sin transformar:\\t\\t',np.array(y_test)[0])\nprint('Actual transformado:\\t\\t',np.array(y_test_log)[0])","005af6ef":"# Se define cuantos componentes princpales se van a obtener, se usa luego de un Scaler\ncomponente=2\npcaORIG = PCA(n_components=componente, random_state=0) \npcaSTD = PCA(n_components=componente, random_state=0)\npcaROB = PCA(n_components=componente, random_state=0)","50ab0c42":"# Usando PCA sin Scalers\npcaORIG.fit(X_train)\nX_train_pca = pcaORIG.transform(X_train)\nX_test_pca = pcaORIG.transform(X_test)\n\nprint(X_train_pca.shape)\nprint(X_test_pca.shape)","b81ae47c":"# Entrenando modelo con PCA STD\n# Se realizar\u00e1 entrenamiento solo con valores num\u00e9ricos\n# tambien se comparar\u00e1 el efecto de hacer la transformacion logaritmica a la salida\n\nlr_pca = LinearRegression()\nlr_pca.fit(X_train_pca,y_train)\ny_pred_pca = lr_pca.predict(X_test_pca)\n\nlr_pca_log = LinearRegression()\nlr_pca_log.fit(X_train_pca,y_train_log)\ny_pred_pca_log = lr_pca_log.predict(X_test_pca)\n\n# Scores\nlr_pca_score_train = lr_pca.score(X_train_pca,y_train)\nlr_pca_score_test = lr_pca.score(X_test_pca,y_test)\n\nlr_pca_score_train_log = lr_pca_log.score(X_train_pca,y_train_log)\nlr_pca_score_test_log = lr_pca_log.score(X_test_pca,y_test_log)\n\n#MSE\nmse_pca_orig = mean_squared_error(y_test,y_pred_pca)\nmse_pca_orig_log = mean_squared_error(y_test_log,y_pred_pca_log)","d05714ba":"# Score obtenido con datos escalados con StandarScaler y PCA\n\nprint('Score train:\\t\\t',lr_pca.score(X_train_pca,y_train))\nprint('Score test:\\t\\t', lr_pca.score(X_test_pca,y_test))\nprint('Mean Squared Error:\\t',mean_squared_error(y_test,y_pred_pca))\nprint(\"\")\nprint('Score train log:\\t', lr_pca_log.score(X_train_pca,y_train_log))\nprint('Score test log:\\t\\t',lr_pca_log.score(X_test_pca,y_test_log))\nprint('Mean Squared Error Log:\\t',mean_squared_error(y_test_log,y_pred_pca_log))","5b0ed127":"# Visualizar matriz de correlacion\nplt.matshow(pcaORIG.components_, cmap='viridis')\nplt.yticks([0, 1], [\"First component\", \"Second component\"])\nplt.colorbar()\nplt.xticks(range(len(X_train.columns)),\n           X_train.columns, rotation=60, ha='left')\nplt.xlabel(\"Feature\")\nplt.ylabel(\"Principal components\")","7aa5fdcb":"# Usando PCA con StandardScaler\npcaSTD.fit(X_train_std)\nX_train_pca_std = pcaSTD.transform(X_train_std)\nX_test_pca_std = pcaSTD.transform(X_test_std)\n\nprint(X_train_pca_std.shape)\nprint(X_test_pca_std.shape)","e5fada19":"# Entrenando modelo con PCA STD\n# Se realizar\u00e1 entrenamiento solo con valores num\u00e9ricos\n# tambien se comparar\u00e1 el efecto de hacer la transformacion logaritmica a la salida\n\nlr_pca_std = LinearRegression()\nlr_pca_std.fit(X_train_pca_std,y_train)\ny_pred_pca_std = lr_pca_std.predict(X_test_pca_std)\n\nlr_pca_std_log = LinearRegression()\nlr_pca_std_log.fit(X_train_pca_std,y_train_log)\ny_pred_pca_std_log = lr_pca_std_log.predict(X_test_pca_std)\n\n# Scores\nlr_pca_std_score_train =  lr_pca_std.score(X_train_pca_std,y_train)\nlr_pca_std_score_test =   lr_pca_std.score(X_test_pca_std,y_test)\n\nlr_pca_std_score_train_log = lr_pca_std_log.score(X_train_pca_std,y_train_log)\nlr_pca_std_score_test_log = lr_pca_std_log.score(X_test_pca_std,y_test_log)\n\n#MSE\n\nmse_pca_std = mean_squared_error(y_test,y_pred_pca_std)\nmse_pca_std_log = mean_squared_error(y_test_log,y_pred_pca_std_log)","e8e89c21":"# Score obtenido con datos escalados con StandarScaler y PCA\n\nprint('Score train:\\t\\t',lr_pca_std.score(X_train_pca_std,y_train))\nprint('Score test:\\t\\t', lr_pca_std.score(X_test_pca_std,y_test))\nprint('Mean Squared Error:\\t',mean_squared_error(y_test,y_pred_pca_std))\nprint(\"\")\nprint('Score train log:\\t', lr_pca_std_log.score(X_train_pca_std,y_train_log))\nprint('Score test log:\\t\\t',lr_pca_std_log.score(X_test_pca_std,y_test_log))\nprint('Mean Squared Error Log:\\t',mean_squared_error(y_test_log,y_pred_pca_std_log))","010a6c79":"# Visualizar matriz de correlacion\nplt.matshow(pcaSTD.components_, cmap='viridis')\nplt.yticks([0, 1], [\"First component\", \"Second component\"])\nplt.colorbar()\nplt.xticks(range(len(X_train.columns)),\n           X_train.columns, rotation=60, ha='left')\nplt.xlabel(\"Feature\")\nplt.ylabel(\"Principal components\")","b2cfc692":"# Usando PCA con StandardScaler\npcaROB.fit(X_train_rob)\nX_train_pca_rob = pcaROB.transform(X_train_rob)\nX_test_pca_rob =  pcaROB.transform(X_test_rob)\n\nprint(X_train_pca_rob.shape)\nprint(X_test_pca_rob.shape)","9939d854":"# Entrenando modelo con PCA ROB\n# Se realizar\u00e1 entrenamiento solo con valores num\u00e9ricos\n# tambien se comparar\u00e1 el efecto de hacer la transformacion logaritmica a la salida\n\nlr_pca_rob = LinearRegression()\nlr_pca_rob.fit(X_train_pca_rob,y_train)\ny_pred_pca_rob = lr_pca_rob.predict(X_test_pca_rob)\n\nlr_pca_rob_log = LinearRegression()\nlr_pca_rob_log.fit(X_train_pca_rob,y_train_log)\ny_pred_pca_rob_log = lr_pca_rob_log.predict(X_test_pca_rob)\n\n# Scores\nlr_pca_rob_score_train =  lr_pca_rob.score(X_train_pca_rob,y_train)\nlr_pca_rob_score_test =   lr_pca_rob.score(X_test_pca_rob,y_test)\n\nlr_pca_rob_score_train_log = lr_pca_rob_log.score(X_train_pca_rob,y_train_log)\nlr_pca_rob_score_test_log = lr_pca_rob_log.score(X_test_pca_rob,y_test_log)\n\n#MSE\n\nmse_pca_rob = mean_squared_error(y_test,y_pred_pca_rob)\nmse_pca_rob_log = mean_squared_error(y_test_log,y_pred_pca_rob_log)","1b8dccf0":"# Score obtenido con datos escalados con StandarScaler y PCA\n\nprint('Score train:\\t\\t',lr_pca_rob.score(X_train_pca_rob,y_train))\nprint('Score test:\\t\\t', lr_pca_rob.score(X_test_pca_rob,y_test))\nprint('Mean Squared Error:\\t',mean_squared_error(y_test,y_pred_pca_rob))\nprint(\"\")\nprint('Score train log:\\t', lr_pca_rob_log.score(X_train_pca_rob,y_train_log))\nprint('Score test log:\\t\\t',lr_pca_rob_log.score(X_test_pca_rob,y_test_log))\nprint('Mean Squared Error Log:\\t',mean_squared_error(y_test_log,y_pred_pca_rob_log))","a057527c":"# Visualizar matriz de correlacion\nplt.matshow(pcaROB.components_, cmap='viridis')\nplt.yticks([0, 1], [\"First component\", \"Second component\"])\nplt.colorbar()\nplt.xticks(range(len(X_train.columns)),\n           X_train.columns, rotation=60, ha='left')\nplt.xlabel(\"Feature\")\nplt.ylabel(\"Principal components\")","3c4387cb":"# uso de bins\nn_bins=5\nkbORIG = KBinsDiscretizer(n_bins=n_bins, strategy='uniform')\nkbSTD = KBinsDiscretizer(n_bins=n_bins, strategy='uniform')\nkbROB = KBinsDiscretizer(n_bins=n_bins, strategy='uniform')","b75f64e9":"# Usando Bins sin Scalers\nkbORIG.fit(X_train)\nX_train_kb = kbORIG.transform(X_train)\nX_test_kb = kbORIG.transform(X_test)\n\nprint(X_train_kb.shape)\nprint(X_test_kb.shape)","67df4cd1":"X_train_kb.toarray()","9a7745fc":"# Entrenando Modelo Bin\n\nlr_kb = LinearRegression()\nlr_kb.fit(X_train_kb,y_train)\ny_pred_kb = lr_kb.predict(X_test_kb)\n\nlr_kb_log = LinearRegression()\nlr_kb_log.fit(X_train_kb,y_train_log)\ny_pred_kb_log = lr_kb_log.predict(X_test_kb)\n\n# Scores\nlr_kb_score_train =  lr_kb.score(X_train_kb,y_train)\nlr_kb_score_test =   lr_kb.score(X_test_kb,y_test)\n\nlr_kb_score_train_log = lr_kb_log.score(X_train_kb,y_train_log)\nlr_kb_score_test_log = lr_kb_log.score(X_test_kb,y_test_log)\n\n#MSE\n\nmse_kb_orig = mean_squared_error(y_test,y_pred_kb)\nmse_kb_orig_log = mean_squared_error(y_test_log,y_pred_kb_log)","9d72c430":"print('Score train:\\t\\t',lr_kb.score(X_train_kb,y_train))\nprint('Score test:\\t\\t', lr_kb.score(X_test_kb,y_test))\nprint('Mean Squared Error:\\t',mean_squared_error(y_test,y_pred_kb))\nprint(\"\")\nprint('Score train log:\\t', lr_kb_log.score(X_train_kb,y_train_log))\nprint('Score test log:\\t\\t',lr_kb_log.score(X_test_kb,y_test_log))\nprint('Mean Squared Error Log:\\t',mean_squared_error(y_test_log,y_pred_kb_log))","9389faa3":"# Usando Bins sin Scalers\nkbSTD.fit(X_train_std)\nX_train_kb_std = kbSTD.transform(X_train_std)\nX_test_kb_std = kbSTD.transform(X_test_std)\n\nprint(X_train_kb_std.shape)\nprint(X_test_kb_std.shape)","c8a01ff8":"X_train_kb_std.toarray()","0131545b":"# Entrenando Modelo Bin\n\nlr_kb_std = LinearRegression()\nlr_kb_std.fit(X_train_kb_std,y_train)\ny_pred_kb_std = lr_kb_std.predict(X_test_kb_std)\n\nlr_kb_log_std = LinearRegression()\nlr_kb_log_std.fit(X_train_kb_std,y_train_log)\ny_pred_kb_log_std = lr_kb_log_std.predict(X_test_kb_std)\n\n# Scores\nlr_kb_std_score_train =  lr_kb_std.score(X_train_kb_std,y_train)\nlr_kb_std_score_test =   lr_kb_std.score(X_test_kb_std,y_test)\n\nlr_kb_std_score_train_log = lr_kb_log_std.score(X_train_kb_std,y_train_log)\nlr_kb_std_score_test_log = lr_kb_log_std.score(X_test_kb_std,y_test_log)\n\n#MSE\n\nmse_kb_std = mean_squared_error(y_test,y_pred_kb_std)\nmse_kb_std_log = mean_squared_error(y_test_log,y_pred_kb_log_std)","74769123":"print('Score train:\\t\\t',lr_kb_std.score(X_train_kb_std,y_train))\nprint('Score test:\\t\\t', lr_kb_std.score(X_test_kb_std,y_test))\nprint('Mean Squared Error:\\t',mean_squared_error(y_test,y_pred_kb_std))\nprint(\"\")\nprint('Score train log:\\t', lr_kb_log_std.score(X_train_kb_std,y_train_log))\nprint('Score test log:\\t\\t',lr_kb_log_std.score(X_test_kb_std,y_test_log))\nprint('Mean Squared Error Log:\\t',mean_squared_error(y_test_log,y_pred_kb_log_std))","b7e5d108":"# Usando Bins sin Scalers\nkbROB.fit(X_train_rob)\nX_train_kb_rob = kbROB.transform(X_train_rob)\nX_test_kb_rob = kbROB.transform(X_test_rob)\n\nprint(X_train_kb_rob.shape)\nprint(X_test_kb_rob.shape)","2e043225":"X_train_kb_rob.toarray()","1fa95e62":"# Entrenando Modelo Bin\n\nlr_kb_rob = LinearRegression()\nlr_kb_rob.fit(X_train_kb_rob,y_train)\ny_pred_kb_rob = lr_kb_rob.predict(X_test_kb_rob)\n\nlr_kb_log_rob = LinearRegression()\nlr_kb_log_rob.fit(X_train_kb_rob,y_train_log)\ny_pred_kb_log_rob = lr_kb_log_rob.predict(X_test_kb_rob)\n\n# Scores\nlr_kb_rob_score_train =  lr_kb_rob.score(X_train_kb_rob,y_train)\nlr_kb_rob_score_test =   lr_kb_rob.score(X_test_kb_rob,y_test)\n\nlr_kb_rob_score_train_log = lr_kb_log_rob.score(X_train_kb_rob,y_train_log)\nlr_kb_rob_score_test_log = lr_kb_log_rob.score(X_test_kb_rob,y_test_log)\n\n#MSE\n\nmse_kb_rob = mean_squared_error(y_test,y_pred_kb_rob)\nmse_kb_rob_log = mean_squared_error(y_test_log,y_pred_kb_log_rob)","cc1f83c0":"print('Score train:\\t\\t',lr_kb_rob.score(X_train_kb_rob,y_train))\nprint('Score test:\\t\\t', lr_kb_rob.score(X_test_kb_rob,y_test))\nprint('Mean Squared Error:\\t',mean_squared_error(y_test,y_pred_kb_rob))\nprint(\"\")\nprint('Score train log:\\t', lr_kb_log_rob.score(X_train_kb_rob,y_train_log))\nprint('Score test log:\\t\\t',lr_kb_log_rob.score(X_test_kb_rob,y_test_log))\nprint('Mean Squared Error Log:\\t',mean_squared_error(y_test_log,y_pred_kb_log_rob))","9cbb618a":"# Combinando los Bin\n\nX_train_combined_orig = np.hstack([X_train,X_train_kb.toarray()])\nX_train_combined_std = np.hstack([X_train_std,X_train_kb_std.toarray()])\nX_train_combined_rob = np.hstack([X_train_rob,X_train_kb_rob.toarray()])\n\nprint('X_train_combined_orig:\\t\\t',X_train_combined_orig.shape)\nprint('X_train_combined_std:\\t\\t',X_train_combined_std.shape)\nprint('X_train_combined_rob:\\t\\t',X_train_combined_rob.shape)\n\n\nX_test_combined_orig = np.hstack([X_test,X_test_kb.toarray()])\nX_test_combined_std = np.hstack([X_test_std,X_test_kb_std.toarray()])\nX_test_combined_rob = np.hstack([X_test_rob,X_test_kb_rob.toarray()])\n\nprint('X_test_combined_orig:\\t\\t',X_test_combined_orig.shape)\nprint('X_test_combined_std:\\t\\t',X_test_combined_std.shape)\nprint('X_test_combined_rob:\\t\\t',X_test_combined_rob.shape)","0efa0b78":"# Modelos lineales \n\n# Datos originales\n\nlr_co_orig = LinearRegression()\nlr_co_orig.fit(X_train_combined_orig,y_train)\ny_pred_co_orig = lr_co_orig.predict(X_test_combined_orig)\n\nlr_co_log_orig = LinearRegression()\nlr_co_log_orig.fit(X_train_combined_orig,y_train_log)\ny_pred_co_log_orig = lr_co_log_orig.predict(X_test_combined_orig)\n\n#score\nlr_co_orig_score_train = lr_co_orig.score(X_train_combined_orig,y_train)\nlr_co_orig_score_test = lr_co_orig.score(X_test_combined_orig,y_test)\n\nlr_co_orig_score_train_log = lr_co_log_orig.score(X_train_combined_orig,y_train_log)\nlr_co_orig_score_test_log = lr_co_log_orig.score(X_test_combined_orig,y_test_log)\n\n#mse\nmse_co_orig = mean_squared_error(y_test,y_pred_co_orig)\nmse_co_orig_log = mean_squared_error(y_test_log,y_pred_kb_log_std)\n\n# Datos STD\n\nlr_co_std = LinearRegression()\nlr_co_std.fit(X_train_combined_std,y_train)\ny_pred_co_std = lr_co_std.predict(X_test_combined_std)\n\nlr_co_log_std = LinearRegression()\nlr_co_log_std.fit(X_train_combined_std,y_train_log)\ny_pred_co_log_std = lr_co_log_std.predict(X_test_combined_std)\n\n#score\nlr_co_std_score_train = lr_co_std.score(X_train_combined_std,y_train)\nlr_co_std_score_test = lr_co_std.score(X_test_combined_std,y_test)\n\nlr_co_std_score_train_log = lr_co_log_std.score(X_train_combined_std,y_train_log)\nlr_co_std_score_test_log = lr_co_log_std.score(X_test_combined_std,y_test_log)\n\n#mse\nmse_co_std = mean_squared_error(y_test,y_pred_co_std)\nmse_co_std_log = mean_squared_error(y_test_log,y_pred_co_log_std)\n\n# Datos ROB\n\nlr_co_rob = LinearRegression()\nlr_co_rob.fit(X_train_combined_rob,y_train)\ny_pred_co_rob = lr_co_rob.predict(X_test_combined_rob)\n\nlr_co_log_rob = LinearRegression()\nlr_co_log_rob.fit(X_train_combined_rob,y_train_log)\ny_pred_co_log_rob = lr_co_log_rob.predict(X_test_combined_rob)\n\n#score\nlr_co_rob_score_train = lr_co_rob.score(X_train_combined_rob,y_train)\nlr_co_rob_score_test = lr_co_rob.score(X_test_combined_rob,y_test)\n\nlr_co_rob_score_train_log = lr_co_log_rob.score(X_train_combined_rob,y_train_log)\nlr_co_rob_score_test_log = lr_co_log_rob.score(X_test_combined_rob,y_test_log)\n\n#mse\nmse_co_rob = mean_squared_error(y_test,y_pred_co_rob)\nmse_co_rob_log = mean_squared_error(y_test_log,y_pred_co_log_rob)\n","54d0f4ec":"# observando los resultados\n\n# original\n\nprint('orig Score train:\\t\\t',lr_co_orig.score(X_train_combined_orig,y_train))\nprint('orig Score test:\\t\\t', lr_co_orig.score(X_test_combined_orig,y_test))\nprint('orig Mean Squared Error:\\t',mse_co_orig)\nprint(\"\")\nprint('Orig Score train log:\\t\\t', lr_co_log_orig.score(X_train_combined_orig,y_train_log))\nprint('Orig Score test log:\\t\\t',lr_co_log_orig.score(X_test_combined_orig,y_test_log))\nprint('Orig Mean Squared Error Log:\\t',mse_co_orig_log)\n\n# STD\nprint(\"\")\nprint('STD Score train:\\t\\t',lr_co_std.score(X_train_combined_std,y_train))\nprint('STD Score test:\\t\\t\\t', lr_co_std.score(X_test_combined_std,y_test))\nprint('STD Mean Squared Error:\\t\\t',mse_co_std)\nprint(\"\")\nprint('STD Score train log:\\t\\t', lr_co_log_std.score(X_train_combined_std,y_train_log))\nprint('STD Score test log:\\t\\t',lr_co_log_std.score(X_test_combined_std,y_test_log))\nprint('STD Mean Squared Error Log:\\t',mse_co_std_log)\n\n# ROB\nprint(\"\")\nprint('ROB Score train:\\t\\t',   lr_co_rob.score(X_train_combined_rob,y_train))\nprint('ROB Score test:\\t\\t\\t',  lr_co_rob.score(X_test_combined_rob,y_test))\nprint('ROB Mean Squared Error:\\t\\t',mse_co_rob)\nprint(\"\")\nprint('ROB Score train log:\\t\\t', lr_co_log_rob.score(X_train_combined_rob,y_train_log))\nprint('ROB Score test log:\\t\\t',  lr_co_log_rob.score(X_test_combined_rob,y_test_log))\nprint('ROB Mean Squared Error Log:\\t',mse_co_rob_log)","260ceff9":"# creando contructores de polinomical\n\nn_degree = 2\n\npoly_orig = PolynomialFeatures(degree = n_degree,include_bias=False)\npoly_std = PolynomialFeatures(degree = n_degree,include_bias=False)\npoly_rob = PolynomialFeatures(degree = n_degree,include_bias=False)\n","e4d99cad":"# creando X train y X test\n\npoly_orig.fit(X_train)\npoly_std.fit(X_train_std)\npoly_rob.fit(X_train_rob)\n\nX_train_poly_orig = poly_orig.transform(X_train)\nX_train_poly_std = poly_std.transform(X_train_std)\nX_train_poly_rob = poly_rob.transform(X_train_rob)\n\nprint('X_train_poly_orig:\\t\\t',X_train_poly_orig.shape)\nprint('X_train_poly_std:\\t\\t',X_train_poly_std.shape)\nprint('X_train_poly_rob:\\t\\t',X_train_poly_rob.shape)\n\n\nX_test_poly_orig = poly_orig.transform(X_test)\nX_test_poly_std = poly_std.transform(X_test_std)\nX_test_poly_rob = poly_rob.transform(X_test_rob)\n\nprint('X_test_poly_orig:\\t\\t',X_test_poly_orig.shape)\nprint('X_test_poly_std:\\t\\t',X_test_poly_std.shape)\nprint('X_test_poly_rob:\\t\\t',X_test_poly_rob.shape)","d33e71c0":"# Entrenando modelo con Poly\n# Se realizar\u00e1 entrenamiento solo con valores num\u00e9ricos\n# tambien se comparar\u00e1 el efecto de hacer la transformacion logaritmica a la salida\n\n# originales\n\nlr_poly_orig = LinearRegression()\nlr_poly_orig.fit(X_train_poly_orig,y_train)\ny_pred_poly_orig = lr_poly_orig.predict(X_test_poly_orig)\n\nlr_poly_orig_log = LinearRegression()\nlr_poly_orig_log.fit(X_train_poly_orig,y_train_log)\ny_pred_poly_orig_log = lr_poly_orig_log.predict(X_test_poly_orig)\n\n#score\nlr_poly_orig_score_train = lr_poly_orig.score(X_train_poly_orig,y_train)\nlr_poly_orig_score_test =  lr_poly_orig.score(X_test_poly_orig,y_test)\n\nlr_poly_orig_score_train_log =  lr_poly_orig_log.score(X_train_poly_orig,y_train_log)\nlr_poly_orig_score_test_log =   lr_poly_orig_log.score(X_test_poly_orig,y_test_log)\n\n#MSE\nmse_poly_orig = mean_squared_error(y_test,y_pred_poly_orig)\nmse_poly_orig_log = mean_squared_error(y_test_log,y_pred_poly_orig_log)\n\n# STD\n\nlr_poly_std = LinearRegression()\nlr_poly_std.fit(X_train_poly_std,y_train)\ny_pred_poly_std = lr_poly_std.predict(X_test_poly_std)\n\nlr_poly_std_log = LinearRegression()\nlr_poly_std_log.fit(X_train_poly_std,y_train_log)\ny_pred_poly_std_log = lr_poly_std_log.predict(X_test_poly_std)\n\n#score\nlr_poly_std_score_train = lr_poly_std.score(X_train_poly_std,y_train)\nlr_poly_std_score_test =  lr_poly_std.score(X_test_poly_std,y_test)\n\nlr_poly_std_score_train_log =  lr_poly_std_log.score(X_train_poly_std,y_train_log)\nlr_poly_std_score_test_log =   lr_poly_std_log.score(X_test_poly_std,y_test_log)\n\n\n#MSE\nmse_poly_std = mean_squared_error(y_test,y_pred_poly_std)\nmse_poly_std_log = mean_squared_error(y_test_log,y_pred_poly_std_log)\n\n# ROB\n\nlr_poly_rob = LinearRegression()\nlr_poly_rob.fit(X_train_poly_rob,y_train)\ny_pred_poly_orig = lr_poly_rob.predict(X_test_poly_rob)\n\nlr_poly_rob_log = LinearRegression()\nlr_poly_rob_log.fit(X_train_poly_rob,y_train_log)\ny_pred_poly_rob_log = lr_poly_rob_log.predict(X_test_poly_rob)\n\n#score\nlr_poly_rob_score_train = lr_poly_std.score(X_train_poly_std,y_train)\nlr_poly_rob_score_test =  lr_poly_std.score(X_test_poly_std,y_test)\n\nlr_poly_rob_score_train_log =  lr_poly_std_log.score(X_train_poly_std,y_train_log)\nlr_poly_rob_score_test_log =   lr_poly_std_log.score(X_test_poly_std,y_test_log)\n\n\n#MSE\nmse_poly_rob = mean_squared_error(y_test,y_pred_poly_orig)\nmse_poly_rob_log = mean_squared_error(y_test_log,y_pred_poly_orig_log)\n","c8965075":"# observando los resultados\n\n# original\n\nprint('orig Score train:\\t\\t', lr_poly_orig_score_train)\nprint('orig Score test:\\t\\t',  lr_poly_orig_score_test)\nprint('orig Mean Squared Error:\\t',mse_poly_orig)\nprint(\"\")\nprint('Orig Score train log:\\t\\t',lr_poly_orig_score_train_log) \nprint('Orig Score test log:\\t\\t', lr_poly_orig_score_test_log)\nprint('Orig Mean Squared Error Log:\\t',mse_poly_orig_log)\n\n# STD\nprint(\"\")\nprint('STD Score train:\\t\\t',   lr_poly_std_score_train)\nprint('STD Score test:\\t\\t\\t',  lr_poly_std_score_test)\nprint('STD Mean Squared Error:\\t\\t',  mse_poly_std)\nprint(\"\")\nprint('STD Score train log:\\t\\t',   lr_poly_std_score_train_log)\nprint('STD Score test log:\\t\\t',    lr_poly_std_score_test_log)\nprint('STD Mean Squared Error Log:\\t', mse_poly_std_log)\n\n# ROB\nprint(\"\")\nprint('ROB Score train:\\t\\t',   lr_poly_rob_score_train)\nprint('ROB Score test:\\t\\t\\t',  lr_poly_rob_score_test)\nprint('ROB Mean Squared Error:\\t\\t',mse_poly_orig)\nprint(\"\")\nprint('ROB Score train log:\\t\\t',   lr_poly_rob_score_train_log)\nprint('ROB Score test log:\\t\\t',    lr_poly_rob_score_test_log)\nprint('ROB Mean Squared Error Log:\\t', mse_poly_rob_log)","1ac0442b":"# lISTA DE COLUMNAS CON MAYOR CORRELACION NMUMERICA\nscaler_columns = X_new_num_cols","ca751386":"testSize = 0.33\ny2_log = np.log(y)\n\nX2_train, X2_test, y2_train_log, y2_test_log = train_test_split(X_new, y2_log, test_size=testSize,random_state=0)\n_,_, y2_train, y2_test = train_test_split(X_new, y, test_size=testSize,random_state=0)\n\nprint('X2_train:\\t', X2_train.shape)\nprint('y2_train_log:\\t', y2_train_log.shape)\nprint('y2_train:\\t', y2_train.shape)\nprint('X2_test:\\t',  X2_test.shape)\nprint('y2_test_log:\\t',  y2_test_log.shape)\nprint('y2_test:\\t',  y2_test.shape)","6f946999":"# usando transformacion de columnas y StandardScaler\n\nctSTD = ColumnTransformer([(\"scaling\",StandardScaler(),scaler_columns),\n                        (\"onehot\",OneHotEncoder(sparse=False, handle_unknown='ignore'),data_housing_object_columns[:5])])#,\n#                        (\"ordinal\",OrdinalEncoder(categories=oe_cat_list),oe_columns)], verbose=True)\n\n# Los comandos siguientes permiten obtener los features names del ohe\n#display(ctSTD.named_transformers_['onehot'].get_feature_names())\n#display(ctSTD.get_feature_names)","4a89967e":"# Crear y transfomar los X train  y X test\n\nctSTD.fit(X2_train)\nX_train_trans_std = ctSTD.transform(X2_train)\nX_test_trans_std = ctSTD.transform(X2_test)\n\nprint(X_train_trans_std.shape)\nprint(X_test_trans_std.shape)","c7513e3d":"# Creacion de Modelo lineal con Columntransformer y STD\n\n# STD\n\nlr_ct_std = LinearRegression()\nlr_ct_std.fit(X_train_trans_std,y_train)\ny_pred_ct_std = lr_ct_std.predict(X_test_trans_std)\n\nlr_ct_std_log = LinearRegression()\nlr_ct_std_log.fit(X_train_trans_std,y_train_log)\ny_pred_ct_std_log = lr_ct_std_log.predict(X_test_trans_std)\n\n#score\nlr_ct_std_score_train = lr_ct_std.score(X_train_trans_std,y_train)\nlr_ct_std_score_test =  lr_ct_std.score(X_test_trans_std,y_test)\n\nlr_ct_std_score_train_log =  lr_ct_std_log.score(X_train_trans_std,y_train_log)\nlr_ct_std_score_test_log =   lr_ct_std_log.score(X_test_trans_std,y_test_log)\n\n\n#MSE\nmse_ct_std = mean_squared_error(y_test,y_pred_ct_std)\nmse_ct_std_log = mean_squared_error(y_test_log,y_pred_ct_std_log)","11163e2b":"# Observar scores y mse\n# STD\nprint(\"\")\nprint('STD Score train:\\t\\t',   lr_ct_std_score_train)\nprint('STD Score test:\\t\\t\\t',  lr_ct_std_score_test)\nprint('STD Mean Squared Error:\\t\\t',  mse_ct_std)\nprint(\"\")\nprint('STD Score train log:\\t\\t',   lr_ct_std_score_train_log)\nprint('STD Score test log:\\t\\t',    lr_ct_std_score_test_log)\nprint('STD Mean Squared Error Log:\\t', mse_ct_std_log)","40fb1eea":"ctROB = ColumnTransformer([(\"scaling\",RobustScaler(),scaler_columns),\n                        (\"onehot\",OneHotEncoder(sparse=False, handle_unknown='ignore'),data_housing_object_columns[:5])])\n\n#ColumnTransformer([(\"scaling\",RobustScaler(),scaler_columns),\n#                        (\"onehot\",OneHotEncoder(sparse=False),ohe_columns),\n#                        (\"ordinal\",OrdinalEncoder(categories=oe_cat_list),oe_columns)])\n","5a69d188":"ctROB.fit(X2_train)\nX_train_trans_rob = ctROB.transform(X2_train)\nX_test_trans_rob = ctROB.transform(X2_test)\n\nprint(X_train_trans_rob.shape)\nprint(X_test_trans_rob.shape)","cc23a84b":"# Creacion de Modelo lineal con Columntransformer y rob\n\n# rob\n\nlr_ct_rob = LinearRegression()\nlr_ct_rob.fit(X_train_trans_rob,y_train)\ny_pred_ct_rob = lr_ct_rob.predict(X_test_trans_rob)\n\nlr_ct_rob_log = LinearRegression()\nlr_ct_rob_log.fit(X_train_trans_rob,y_train_log)\ny_pred_ct_rob_log = lr_ct_rob_log.predict(X_test_trans_rob)\n\n#score\nlr_ct_rob_score_train = lr_ct_rob.score(X_train_trans_rob,y_train)\nlr_ct_rob_score_test =  lr_ct_rob.score(X_test_trans_rob,y_test)\n\nlr_ct_rob_score_train_log =  lr_ct_rob_log.score(X_train_trans_rob,y_train_log)\nlr_ct_rob_score_test_log =   lr_ct_rob_log.score(X_test_trans_rob,y_test_log)\n\n\n#MSE\nmse_ct_rob = mean_squared_error(y_test,y_pred_ct_rob)\nmse_ct_rob_log = mean_squared_error(y_test_log,y_pred_ct_rob_log)","f7ae2c24":"# Observar scores y mse\n# rob\nprint(\"\")\nprint('rob Score train:\\t\\t',   lr_ct_rob_score_train)\nprint('rob Score test:\\t\\t\\t',  lr_ct_rob_score_test)\nprint('rob Mean Squared Error:\\t\\t',  mse_ct_rob)\nprint(\"\")\nprint('rob Score train log:\\t\\t',   lr_ct_rob_score_train_log)\nprint('rob Score test log:\\t\\t',    lr_ct_rob_score_test_log)\nprint('rob Mean Squared Error Log:\\t', mse_ct_rob_log)","07af346e":"#@title Creando dataset de score y mse a mostrar en grafica mediante diccionario\n# Creacion de diccionarios\n\ndata_score = {\n    'Modelo_Usado' : [\n              'Datos_originales',\n              'Datos_escalados_STD',\n              'Datos_escalados_ROBUST',\n              'PCA_Datos_originales',\n              'PCA_Datos_escalados_STD',\n              'PCA_Datos_escalados_ROBUST',\n              'Bin_Datos_originales',\n              'Bin_Datos_escalados_STD',\n              'Bin_Datos_escalados_ROBUST',\n              'Combined_Datos_originales',\n              'Combined_Datos_escalados_STD',\n              'Combined_Datos_escalados_ROBUST',\n              'Polynomial_Datos_originales',\n              'Polynomial_Datos_escalados_STD',\n              'Polynomial_Datos_escalados_ROBUST',\n              'Column_transform__Datos_escalados_STD',\n              'Column_transform__Datos_escalados_ROBUST'\n            ],\n    'Score_Train':[\n                  lr_orig_score_train, \n                  lr_orig_std_score_train,\n                  lr_orig_rob_score_train, \n                  lr_pca_score_train,\n                  lr_pca_std_score_train,\n                  lr_pca_rob_score_train,\n                  lr_kb_score_train,\n                  lr_kb_std_score_train,\n                  lr_kb_rob_score_train,\n                  lr_co_orig_score_train,\n                  lr_co_std_score_train,\n                  lr_co_rob_score_train,\n                  lr_poly_orig_score_train,\n                  lr_poly_std_score_train,\n                  lr_poly_rob_score_train,\n                  lr_ct_std_score_train,\n                  lr_ct_rob_score_train\n                  ],\n    'Score_Test':[\n                  lr_orig_score_test, \n                  lr_orig_std_score_test,\n                  lr_orig_rob_score_test, \n                  lr_pca_score_test,\n                  lr_pca_std_score_test,\n                  lr_pca_rob_score_test,\n                  lr_kb_score_test,\n                  lr_kb_std_score_test,\n                  lr_kb_rob_score_test,\n                  lr_co_orig_score_test,\n                  lr_co_std_score_test,\n                  lr_co_rob_score_test,\n                  lr_poly_orig_score_test,\n                  lr_poly_std_score_test,\n                  lr_poly_rob_score_test,\n                  lr_ct_std_score_test,\n                  lr_ct_rob_score_test\n                  ],\n    'MSE':[\n            mse_lr_orig,\n            mse_orig_std,\n            mse_orig_rob,\n            mse_pca_orig,\n            mse_pca_std,\n            mse_pca_rob,\n            mse_kb_orig,\n            mse_kb_std,\n            mse_kb_rob,\n            mse_co_orig,\n            mse_co_std,            \n            mse_co_rob,\n            mse_poly_orig,\n            mse_poly_std,\n            mse_poly_rob,\n            mse_ct_std,\n            mse_ct_rob\n            ],\n    'Log_Score_Train':[\n                      lr_orig_score_train_log,\n                      lr_orig_std_score_train_log,\n                      lr_orig_rob_score_train_log,\n                      lr_pca_score_train_log,\n                      lr_pca_std_score_train_log,\n                      lr_pca_rob_score_train_log,\n                      lr_kb_score_train_log,\n                      lr_kb_std_score_train_log,\n                      lr_kb_rob_score_train_log,\n                      lr_co_orig_score_train_log,\n                      lr_co_std_score_train_log,\n                      lr_co_rob_score_train_log,\n                      lr_poly_orig_score_train_log,\n                      lr_poly_std_score_train_log,\n                      lr_poly_rob_score_train_log,\n                      lr_ct_std_score_train_log,\n                      lr_ct_rob_score_train_log\n                      ],\n    'Log_Score_Test':[\n                      lr_orig_score_test_log, \n                      lr_orig_std_score_test_log,\n                      lr_orig_rob_score_test_log, \n                      lr_pca_score_test_log,\n                      lr_pca_std_score_test_log,\n                      lr_pca_rob_score_test_log,\n                      lr_kb_score_test_log,\n                      lr_kb_std_score_test_log,\n                      lr_kb_rob_score_test_log,\n                      lr_co_orig_score_test_log,\n                      lr_co_std_score_test_log,\n                      lr_co_rob_score_test_log,\n                      lr_poly_orig_score_test_log,\n                      lr_poly_std_score_test_log,\n                      lr_poly_rob_score_test_log,\n                      lr_ct_std_score_test_log,\n                      lr_ct_rob_score_test_log\n                      ],\n    'Log_MSE':[\n                mse_lr_orig_log,\n                mse_orig_std_log,\n                mse_orig_rob_log,\n                mse_pca_orig_log,\n                mse_pca_std_log,\n                mse_pca_rob_log,\n                mse_kb_orig_log,\n                mse_kb_std_log,\n                mse_kb_rob_log,\n                mse_co_orig_log,\n                mse_co_std_log,            \n                mse_co_rob_log,\n                mse_poly_orig_log,\n                mse_poly_std_log,\n                mse_poly_rob_log,\n                mse_ct_std_log,\n                mse_ct_rob_log\n                ]\n}\n\n","8b471fcd":"score_pd = pd.DataFrame(data_score)\n\nscore_pd.describe()","9b212a11":"score_pd.info()","0047388c":"score_pd.plot(x='Modelo_Usado',y = ['Score_Train','Log_Score_Train'], kind='barh', \n              figsize = (20,8), title='Desempe\u00f1o del Entrenamiento',\n              xlabel='Modelo usado: Regresion Lineal',\n              ylabel='Porcentaje Obtenido', grid=True, ylim=[0,1])\nplt.show()","587da556":"score_pd.plot(x='Modelo_Usado',y = ['Score_Test','Log_Score_Test'], kind='barh', \n              figsize = (20,8), title='Desempe\u00f1o del Entrenamiento',\n              xlabel='Modelo usado: Regresion Lineal',\n              ylabel='Porcentaje Obtenido', grid=True, ylim=[0,1])\nplt.show()","a32a7995":"score_pd.plot(x='Modelo_Usado',y = ['MSE'], kind='barh',\n              figsize = (20,4), title='Desempe\u00f1o del Entrenamiento',\n              xlabel='Modelo usado: Regresion Lineal', sharey = False,\n              ylabel='Porcentaje Obtenido', grid=True, subplots=True)\nscore_pd.plot(x='Modelo_Usado',y = ['Log_MSE'], kind='barh', color='darkorange',\n              figsize = (20,4), title='Desempe\u00f1o del Entrenamiento',\n              xlabel='Modelo usado: Regresion Lineal', sharey = False,\n              ylabel='Porcentaje Obtenido', grid=True, subplots=True)\nplt.show()","cd0ffcdb":"score_pd.plot(x='Modelo_Usado',y = ['Score_Train','Score_Test'], kind='barh', \n              figsize = (20,8), title='Desempe\u00f1o del Entrenamiento',\n              xlabel='Modelo usado: Regresion Lineal',\n              ylabel='Porcentaje Obtenido', grid=True, ylim=[0,1])\nplt.show()","821d3c0b":"score_pd.plot(x='Modelo_Usado',y = ['Log_Score_Train','Log_Score_Test'], kind='barh', \n              figsize = (20,8), title='Desempe\u00f1o del Entrenamiento',\n              xlabel='Modelo usado: Regresion Lineal',\n              ylabel='Porcentaje Obtenido', grid=True, ylim=[0,1])\nplt.show()","075eb9a4":"score_pd.plot(x='Modelo_Usado',y = ['Score_Train','Score_Test','Log_Score_Train','Log_Score_Test'], kind='barh', \n              figsize = (20,10), title='Desempe\u00f1o del Entrenamiento',\n              xlabel='Modelo usado: Regresion Lineal',\n              ylabel='Porcentaje Obtenido', grid=True, ylim=[0,1])\nplt.show()","e837425a":"# Creando ya valores de resultados para competencia de Kaggle\n# Se requiere que tenga la misma transformacion usada en el preprocesamiento polinomial\n\n# usando transformador de robust scaler\nX_val2 = X_val[X_new_num_cols]\nX_val_rob = robScaler.transform(X_val2)\n\n# Usanbdo transformador de polynomial\nX_val_poly_rob = poly_rob.transform(X_val_rob)\n\nprint('X_val_poly_rob:\\t\\t',X_val_poly_rob.shape)","152a0ee7":"# Usando modelo lineal con escalar robusto y transformacion logaritmica\n\n# ROB\n\ny_val_pred_poly_rob_log = lr_poly_rob_log.predict(X_val_poly_rob)\ny_val_pred_poly_rob     = np.exp(y_val_pred_poly_rob_log)\n\nprint('y_val_pred_poly_rob_log:\\t',y_val_pred_poly_rob_log.shape)\nprint('Resultados con Logaritmos:\\n\\n',y_val_pred_poly_rob_log[:5])\nprint('\\ny_val_pred_poly_rob:\\t',y_val_pred_poly_rob.shape)\nprint('Resultados con valores ajustados:\\n\\n',y_val_pred_poly_rob[:5])\nprint('\\nValores entrenamiento Y train originales:\\n\\n',y[:10])","d4f1ec22":"data_to_predict['SalePrice'] = y_val_pred_poly_rob\ndata_to_predict.head()","87cb0e6f":"data_to_predict.to_csv('submission.csv',index=False)","4554e467":"Seccion para kaggle","08b687af":"Usando Las caracteristicas con transformacione spolinomicas, se puede deducir que este metodo no es util para este dataset usando todas las caracteristicas numericas, pues se obtienen valores negativos en el test.\n\nSi se usan solo caracterisitcas de correlacion, se obtienen resultados positivos pero muy por debajo de las anteriores transformaciones, ademas al usar un grado mayor a 2 se obtienen resultados de test negativos","49d30dfc":">Tenemos un resultado de 84% contra 64% en los datos de testeo y 89% contra 75% con los datos aplicados a una tranformacion logaritmica.\n\n>procedemos a realizar una validacion del modelo lineal con un dto de prueba.","520e1bdd":"#### Transformacion con StandardScaler","07d8b38a":"## 4. Uso de Caracter\u00edsticas Polin\u00f3micas","edb90f80":"### Solo original","24fc00bd":"> Se realizar\u00e1 entrenamiento en un modelo de regresion lineal  con valores originales.\n> tambien se comparar\u00e1 el efecto de hacer la transformaci\u00f3n logar\u00edtmica a la salida\n","0a47c4e3":"### Uso de Standard Scaler","5e05e62e":"#### Usando robust scaler y pca","3388b5db":"## 1. Dataset original\n\nAqui se prueba el modelo Lineal usando el dataset original sin escalamientos a las variables independientes\n\nPero si se hace un escalamiento a la variable dependientes o transformacion usando la funcion logaritmica","c34c6982":"Se puede observar que el PCA con los valores originales tiene un desempe\u00f1o regular, ya que solo hay un acaracteristica que aporta buenos datos.","e99126c2":"### Uso de datos original con Robust Scaler","36e4dd89":"> categorias para ordinal encoder, se requiere definir que valor es menor y cual es mayor.Se toman los rangos acorde a la descripcion del dataset","8df4e2a6":"### Uso de datos original con Standard scaler","8c1f4df1":"### Nuevo dataset ordenado respecto a las columnas anteriores\n\nEsto se hizo para tener mas ordenado el dataset a procesar con Column transformer, para una facil lectura, pues los primeros 30 caracteristicas perteneceran a los num\u00e9ricos","3faac91d":"### Dividiendo dataset\n#### Segun algunas fuentes, es mejor realizar una transformaci\u00f3n logaritmica a la salida de los precios para que el entrenamiento sea mas efectivo.","12147b84":"## 6. uso de modelo para generar salida de predicciones a usar en kaggle\n\nAl comprobar varios modelos y obser var la grafica de barras con los desempe\u00f1os obtenidos, se observa que el modelo lineal con procesado polin\u00f3mico tiene mejor desempe\u00f1o tanto en su entrenamiento como en su test. Procedemos a usar ese modelo de **Regresi\u00f3n Lineal con preprocesamiento Polin\u00f3mico y un escalado Robusto**, ademas se usara la transformaci\u00f3n Logaritmica para la salida con posterior transformacion exponecial para obtener el precio.","a15a22f6":"Se observa que al usar una transformacion logaritmica al target de precios, debido a que son valores que varian mucho, **mejora** los Resultados de la **Prediccion**.","413bf063":"En estos modelos, podemos ver que el que tiene mejor desempe\u00f1o es el que usa scaler ROB con salida logaritmica, ya que a pesar de que el score test es menor que el usado sin scalers, el mse es mucho menor","2ccc6041":"### Uso de datos original sin scaler","5a73fe51":"#### Usando standard scaler y pca","8c10cfba":"### Preparando columnas","9ab9d295":"Se puede observar que los resultados con bin mejoran mucho el modelo lineal, con o sin scalers incluidos","baee46fb":"## 3. Uso de Binning y Caracter\u00edsticas de Interacci\u00f3n","c8cf9453":"## 2. Caracteristicas Escaladas y Proyectadas con PCA","ce094ce5":"Se puede observar que el PCA con el StandardScaler tiene un desempe\u00f1o mas estable, varias de sus caracteristicas aportan positivamente, aun asi es un rendimiento mas bajo que usando solo el StandardScaler","aacfd1a1":"Se nota tano para el score del train y test, que mejora su desemepe\u00f1o al usar salidas lograritmicas en la mayoria de los metodos usados con Regresion Lineal.","8145c818":"### Segunda comparacion: Score train, Test vs Score Train, Test Log","6b2a45f1":"#### Transformacion con RobustScaler","093b4fea":"### Acomodando lista de columnas para  las transformaciones","2c2fcc36":"Aqui se puede apreciar la comparativa entre los diferentes metodos usados (usando data original o escalada) asi como las diferentes transformaciones realizadas a la salida, aunque esa transformacion mejora el desempe\u00f1o general de los metodos usados, la tendencia de varianza no cambia, para el modelo de Regresion lineal.\n\nMas en concreto, aunque el desempe\u00f1o del metodo Bin en entrenamiento es menor al del Combinado, tiene una mejor relacion con respecto a la etapa de test, de igual forma, usando una salida logaritmica mejora considerablemente el error MSE.\n","cad2dc6a":"### Uso del PCA","41170d82":">generamos el score en el modelo:","4cf8ee92":"### Visualizacion correlacion de caracteristicas numericas\n>verificamos el porcentaje de  correlacion Pearson","ba58b13f":"### Revisando que modelo tuvo mejor desempe\u00f1o","81e35cb9":">Validamos correlacion Kendall","37da1557":"### Uso de Robust Scaler","f7e9731c":"### Seleccionamos las columnas numericas con mejor porcentaje de correlacion","b1deb80b":"Se observa que en la mayoria de metodos usados, puede haber un sesgo de varianza, teniendo el entrenamiento un buen desempe\u00f1o, pero el test en ocasiones es muy bajo, mas de 9 puntos de diferencia, los unicos metodos en que la diferencia no es mucha, es con los datos Bin y Combinados","e0500267":"#### Usando Original y pca","bcfa4611":"### Primera comparacion: Score, MSE vs Score, MSE Log","ce279bed":"### Organizando dataset","dd3278e3":"Se puede observar que el uso de PCA con RobustScaler es la peor combinacion con las caracteristicas seleccionadas","4d52182a":">validaci\u00f3n con algunas caracteristicas que poseen valores NA","07edbc9c":"### Tercera comparacion: Scores vs Scores Log","6e41ee08":"## 5. Uso de Column Transform para preprocesar dataset con One Hot Encoding","956d8e8c":"### Uso combinado","bf351def":"# Tarea 3. Housing Price\n","e9989421":"Para los errores MSE, es dificil ponerlos en una misma figura, debido a que tienen limites muy diferentes, pero se puede observar que los MSE usando las salidas Logs tienen un error muy peque\u00f1o, ya que la variacion entre la salida SalePrice es menor","37d4ab07":">validamos correlacion Spearman","a5d46cc1":"## Importando librerias necesarias","03a964b9":"### Uso de Scalers, Dummies y Ordinals"}}