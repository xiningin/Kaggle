{"cell_type":{"97513f34":"code","1cf06526":"code","2f09d56e":"code","dd5ecc30":"code","ac9f9358":"code","779db301":"code","00b55582":"code","2417000c":"code","1a1a436f":"code","3732c0be":"code","0b5cce37":"code","c6ccce80":"code","035879fd":"code","a9746357":"code","09482416":"code","1482089f":"code","339f3cd5":"code","8f8a4a35":"code","079413fa":"markdown","4cd0ef4b":"markdown","8733a682":"markdown","49f99090":"markdown","aa9cd385":"markdown","7f295a44":"markdown","f0c78e70":"markdown","47210d37":"markdown","66e5a4bc":"markdown","d8f8dcfb":"markdown","07d75940":"markdown","38dbea7e":"markdown","446be8f0":"markdown","704cda48":"markdown","f1068940":"markdown","16505f2e":"markdown","470fe7d2":"markdown"},"source":{"97513f34":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix","1cf06526":"wine_data = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\nwine_data.shape","2f09d56e":"wine_data.head()","dd5ecc30":"wine_data.describe()","ac9f9358":"wine_data.info()","779db301":"wine_data.isnull().sum()","00b55582":"# Let's check the number of values under each quality classification\nsns.catplot(x='quality',data= wine_data,  kind='count')","2417000c":"# volatile acidity vs quality\nplot = plt.figure(figsize=(5,5))\nplt.title('Volatile acidity vs Quality')\nsns.barplot(x='quality', y='volatile acidity', data=wine_data)","1a1a436f":"# citric acid vs quality\nplot = plt.figure(figsize=(5,5))\nplt.title('Citric acid vs Quality')\nsns.barplot(x='quality', y='citric acid', data=wine_data)","3732c0be":"corr = wine_data.corr()\n# Let's create a heatmap!\nplot = plt.figure(figsize=(10,10))\nplt.title('Correlation heatmap!')\nsns.heatmap(corr,cbar=True,square=True,fmt='.1f',annot=True,annot_kws={'size':8},cmap='Blues')","0b5cce37":"X = wine_data.drop(columns='quality',axis=1)\nX.head()","c6ccce80":"y = wine_data['quality'].apply(lambda y_value: 1 if y_value>=7 else 0 )\ny","035879fd":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)","a9746357":"classifier = RandomForestClassifier()\nclassifier.fit(X_train,y_train)","09482416":"y_pred_train = classifier.predict(X_train)\naccuracy = accuracy_score(y_pred_train, y_train)\nprint(\"Accuracy of the model on training data is:\", accuracy)\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier,X = X_train,y= y_train , cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f}\".format(accuracies.std()*100))","1482089f":"y_pred_test = classifier.predict(X_test)\naccuracy = accuracy_score(y_pred_test, y_test)\nprint(\"Accuracy: {:.2f} %\".format(accuracy*100))\ncf_matrix = confusion_matrix(y_pred_test,y_test)","339f3cd5":"#.  visualizing the confusion matrix!\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Reds')","8f8a4a35":"from sklearn.model_selection import GridSearchCV\nparameters = [{'bootstrap': [True], 'max_depth': [10, 20], 'max_features': ['auto', 'sqrt'], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100,200]}]\ngrid_search = GridSearchCV(estimator=classifier,\n                          param_grid=parameters,\n                          scoring='accuracy',\n                          cv=10)\ngrid_search.fit(X_train,y_train)\nprint(\"Best Accuracy: {:.2f} %\".format(grid_search.best_score_*100))\nprint(\"Best Parameters: \", grid_search.best_params_)","079413fa":"Data Analysis and Visualization","4cd0ef4b":"Let's compare some features with the quality !","8733a682":"Now that we've come to an end let's look back upon what we did in this project! <br>\n* imported the required libraries!\n* read our data from the **Red Wine Quality** dataset!\n* Checked for any missing values!\n* Found some useful information between different features using plots and graphs!\n* Made a heatmap to find the correlation between different features!\n* Split the data into training and test sets!\n* Trained our model using supervised learning algorithm - Random forest classification ! \n* Used KFold cross validation to get the accuracy !\n* With a little bit of hyper parameter tuning we we're able to get a good accuracy score of **92**% !\n<br>\nHope you all enjoyed this notebook! <br>\nHappy Learning!!","49f99090":"Now let's train our model using random forest classifier!","aa9cd385":"Now that we have our data and labels, let's split the data into train and test split!","7f295a44":"Let's find the correlation! <br>\nAbout the heatmap!\n* corr - correlation calculated\n* cbar - color bar to indicate the values range\n* square - To get a square form\n* fmt - we need one floating point value\n* annot - annotations on the sides!\n* annot_kws - size of annotations\n* cmap - color of the heatmap!","f0c78e70":"Now let's import our data!\nWe're gonna use the wine quality dataset from the UCI ML Dataset! ","47210d37":"Model evaluation using K-fold cross validation! <br>\nWhy k-fold cross validation ? To be sure that we didn't get lucky on the train test!","66e5a4bc":"As we can see we have a clean dataset without any missing values!","d8f8dcfb":"Now let's check if there is a better hyperparameter we can tune to improve over all accuracy. We use **Grid Search CV** here","07d75940":"Let's start by importing the required libraries! <br>\nA little about the libraries!\n* numpy - for numpy arrays, useful for processing and scientific computing\n* pandas - helpful for creating dataframes and storing data\n* matplotlib.pyplot - useful for creating plots and charts\n* seaborn - useful for data visualization like matplotlib\n* train_test_split - to split the data into training and test set\n* Random forest Classifier - An ensemble model which we'll use to train our model on\n* accuracy_score - to check the accuracy of our model\n\nStandardScalar - in this project we're using support vector machine classification and this class cannot process the data given to it unless the data is standardized.\nsvm - the suport vector machine class in the sklearn package","38dbea7e":"Let's explore the dataset further! <br>\nEploratory data analysis!","446be8f0":"Doesn't look like there's any missing values! Let's be sure! <br>\nChecking for missing values","704cda48":"As we can see that's a pretty good accuracy! <br>\nLet's check our model performance on the test set!","f1068940":"Data Preprocessing! <br>\nLet's seperate the data and the labels!","16505f2e":"# Wine Quality Prediction!\nHey everyone! In this project we're gonna be looking at the wine quality dataset! <br>\nWe'll be looking at supervised learning machine learning algorithm Random Forest and try to improve the accuracy as we'll tune the hyper parameters! <br>\nHappy Learning!","470fe7d2":"For the quality values, we're gonna binarize the values to either good wine quality **1** or bad wine **0**"}}