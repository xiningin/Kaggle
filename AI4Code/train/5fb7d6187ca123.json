{"cell_type":{"1816fb86":"code","18211a62":"code","0195ac2b":"code","2493ed8e":"code","1daf3816":"code","802cd0a5":"code","c0324ed7":"code","f665cc24":"code","b5feef88":"code","9eb17ab7":"code","b6f6fa09":"code","8f747f8e":"code","a9308ae1":"code","d68b2f24":"code","6823044d":"code","293c2808":"code","4ac436a1":"code","aeefbbcf":"code","10cff38b":"code","fcb3054a":"code","6cacb395":"code","5e2280e1":"code","b1cfd177":"markdown","e2def1fd":"markdown","016e5802":"markdown","88a5135c":"markdown","52f5000b":"markdown","8045093e":"markdown"},"source":{"1816fb86":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","18211a62":"import os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import StratifiedKFold","0195ac2b":"NOM_DIR = '\/kaggle\/input\/eye-disease-dataset\/normals-20210613T185906Z-001\/normals\/'\nCAT_DIR = '\/kaggle\/input\/eye-disease-dataset\/cataracts-20210529T195148Z-001\/cataracts\/'\nCSC_DIR = '\/kaggle\/input\/eye-disease-dataset\/corneal scar-20210613T182413Z-001\/corneal scar\/'","2493ed8e":"normal_ids = os.listdir(NOM_DIR)\ncat_ids = os.listdir(CAT_DIR)\ncsc_ids = os.listdir(CSC_DIR)","1daf3816":"normal_paths = [ os.path.join(NOM_DIR,normal_id) for normal_id in normal_ids]\ncat_paths = [ os.path.join(CAT_DIR,cat_id) for cat_id in cat_ids]\ncsc_paths = [ os.path.join(CSC_DIR,csc_id) for csc_id in csc_ids]","802cd0a5":"# 0 - Normal\n# 1 - cataracts\n# 2 - corneal scar\nnormal_labels = [0]*len(normal_ids)\ncat_labels = [1]*len(cat_ids)\ncsc_labels = [2]*len(csc_ids)","c0324ed7":"image_path = normal_paths + cat_paths + csc_paths\nlabel = normal_labels + cat_labels + csc_labels","f665cc24":"train = pd.DataFrame(list(zip(image_path, label)),columns =['image_path', 'label'])","b5feef88":"train","9eb17ab7":"class CFG:\n    debug=False\n    size=64\n    epochs=10\n    batch_size=4\n    val_batch_size=4\n    seed=42\n    target_size=3\n    target_col='label'\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","b6f6fa09":"train['label'] = train['label'].astype(str)\nfolds = train.copy()\nFold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_col])):\n    folds.loc[val_index, 'fold'] = int(n)\nfolds['fold'] = folds['fold'].astype(int)\nprint(folds.groupby(['fold', CFG.target_col]).size())","8f747f8e":"folds","a9308ae1":"# folds.to_csv('folds.csv')","d68b2f24":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","6823044d":"train_datagen = ImageDataGenerator(rescale=1.\/225,\n                                   rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.1,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\nval_datagen = ImageDataGenerator(rescale=1.\/255)","293c2808":"generator = train_datagen.flow_from_dataframe(dataframe = train,\n                                              x_col = 'image_path',\n                                              y_col = 'label',\n                                              target_size = (CFG.size, CFG.size),\n                                              color_mode = \"rgb\",\n                                              class_mode = \"categorical\",\n                                              batch_size = 1,\n                                              shuffle = True,\n                                              subset = 'training')","4ac436a1":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model,load_model\nfrom tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom sklearn.metrics import accuracy_score","aeefbbcf":"def vgg16_model(num_classes=None):\n\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(CFG.size, CFG.size, 3), pooling='avg')\n    output = Dense(num_classes, activation='softmax')(base_model.output)\n    model = Model(base_model.input, output)\n    \n    return model","10cff38b":"model=vgg16_model(CFG.target_size)\nmodel.summary()","fcb3054a":"!ls ","6cacb395":"def train_loop(folds, fold):\n\n    print(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # train data, validation data\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n\n    # ====================================================\n    # generator\n    # ====================================================\n    \n    train_datagen = ImageDataGenerator(rescale=1.\/225,\n                                   rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n    val_datagen = ImageDataGenerator(rescale=1.\/255)\n    \n    train_generator = train_datagen.flow_from_dataframe(dataframe = train_folds,\n                                                        x_col = 'image_path',\n                                                        y_col = 'label',\n                                                        target_size = (CFG.size, CFG.size),\n                                                        color_mode = \"rgb\",\n                                                        class_mode = \"categorical\",\n                                                        batch_size = CFG.batch_size,\n                                                        shuffle = True)\n    \n\n    val_generator = val_datagen.flow_from_dataframe(dataframe = valid_folds,\n                                                    x_col = 'image_path',\n                                                    y_col = 'label',\n                                                    target_size = (CFG.size, CFG.size),\n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    batch_size = CFG.val_batch_size,\n                                                    shuffle = False)\n \n    # ====================================================\n    # callbacks\n    # ====================================================  \n    save_model = tf.keras.callbacks.ModelCheckpoint(\n                    f'fold-{fold}.h5', monitor='val_loss', verbose=0, save_best_only=True,\n                    save_weights_only=True, mode='min', save_freq='epoch')\n\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5, min_delta = 0.0001,\n                                                      verbose=1, mode='min'),\n    \n    reduce_lr_op = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 2,\n                                     verbose = 1, min_delta = 0.0001, mode = 'min')\n    \n    callbacks = [save_model, early_stopping, reduce_lr_op]\n\n    # ====================================================\n    # optimizer\n    # ====================================================   \n    optimizer = Adam(lr=0.0001)\n    \n    # ====================================================\n    # loss\n    # ====================================================\n    loss = tf.keras.losses.CategoricalCrossentropy(from_logits = False, label_smoothing=0.0001,name='categorical_crossentropy' )\n    \n    # ====================================================\n    # model\n    # ====================================================\n    model = vgg16_model(num_classes=CFG.target_size)    \n    model.compile(optimizer = optimizer, loss = loss, metrics = ['categorical_accuracy'])\n\n    # ====================================================\n    # training\n    # ====================================================\n    train_steps = train_generator.n\/\/train_generator.batch_size\n    val_steps = val_generator.n\/\/val_generator.batch_size\n    \n    \n    history = model.fit(\n                    train_generator,\n                    steps_per_epoch=train_steps,\n                    epochs=CFG.epochs,\n                    validation_data=val_generator,\n                    callbacks=callbacks,\n                    validation_steps=val_steps\n                    )\n\n    # ====================================================\n    # predict\n    # ====================================================\n    print('Loading best model...')\n    model.load_weights(f'fold-{fold}.h5')\n    \n    print('Predicting OOF...')\n    pred = model.predict(val_generator, verbose=1)\n    \n    valid_folds[[str(c) for c in range(3)]] = pred\n    valid_folds['preds'] = pred.argmax(1) \n    \n    # ====================================================\n    # plot\n    # ====================================================   \n    plt.figure(figsize=(10,3))\n    plt.plot(np.arange(len(history.history['categorical_accuracy'])),history.history['categorical_accuracy'],'-o',label='Train ACC',color='#ff7f0e')\n    plt.plot(np.arange(len(history.history['val_categorical_accuracy'])),history.history['val_categorical_accuracy'],'-o',label='Val ACC',color='#1f77b4')\n    x = np.argmax( history.history['val_categorical_accuracy'] ); y = np.max( history.history['val_categorical_accuracy'] )\n    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n    plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max acc\\n%.2f'%y,size=14)\n    plt.ylabel('ACC',size=14); plt.xlabel('Epoch',size=14)\n    plt.legend(loc=2)\n    plt2 = plt.gca().twinx()\n    plt2.plot(np.arange(len(history.history['loss'])),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n    plt2.plot(np.arange(len(history.history['val_loss'])),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n    x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n    ydist = plt.ylim()[1] - plt.ylim()[0]\n    plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n    plt.ylabel('Loss',size=14)\n    plt.title(f'FOLD {fold} - Image Size {CFG.size}',size=16)\n    plt.legend(loc=3)\n    plt.show()\n\n    return valid_folds","5e2280e1":"def get_score(y_true, y_pred):\n    return accuracy_score(y_true, y_pred)\n\n\ndef get_result(result_df):\n    preds = result_df['preds'].values\n    labels = result_df[CFG.target_col].astype(int).values\n    score = get_score(labels, preds)\n    print(f'Score: {score:<.5f}')\n\n\n# train \noof_df = pd.DataFrame()\nfor fold in range(CFG.n_fold):\n    if fold in CFG.trn_fold:\n        _oof_df = train_loop(folds, fold)\n        oof_df = pd.concat([oof_df, _oof_df])\n        print(f\"========== fold: {fold} result ==========\")\n        get_result(_oof_df)\n# CV result\nprint(f\"========== CV ==========\")\nget_result(oof_df)\n# save result\noof_df.to_csv('oof_df.csv', index=False)","b1cfd177":"#### Training","e2def1fd":"### Create Cross Validation Dataset","016e5802":"### Model Training","88a5135c":"### Model Definition","52f5000b":"### Create training dataset","8045093e":"### Image Preprocessing"}}