{"cell_type":{"e6825f1b":"code","e475665c":"code","a2543768":"code","f937a044":"code","21cc1968":"code","8cab0f06":"code","f70c651c":"code","76a7eb78":"code","158cef48":"code","82a08290":"code","9e63cbc2":"code","76799c2b":"code","f1198f1d":"code","f78d37b6":"code","28e2c8ff":"code","0c7f4ba3":"markdown","3711352b":"markdown","8814191c":"markdown","8d217819":"markdown","6bc1ebe0":"markdown","e3d9a9d8":"markdown","d2471a6c":"markdown","56e090ee":"markdown","5b569abc":"markdown","7247b5c8":"markdown","eef78dcd":"markdown","80789087":"markdown","897aa964":"markdown","7ffcd338":"markdown","17f792d7":"markdown"},"source":{"e6825f1b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\n\nwarnings.filterwarnings('ignore')\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e475665c":"# Fisrt thing first, lets load the dataset\n\ndf = pd.read_csv('\/kaggle\/input\/car-evaluation-data-set\/car_evaluation.csv')\ndf.head()","a2543768":"# reloading datasetbby ignoring the headings\ndata=pd.read_csv('\/kaggle\/input\/car-evaluation-data-set\/car_evaluation.csv',header=None)\ndata.head()","f937a044":"#adding headings to the dataset.\n\n# creating a list of necessay headings\nheader=['buying','maint_cost','total_doors','seater','boot_space','safety','decision']\ndata.columns=header\ndata.head()","21cc1968":"#lets explore the given dataset\nprint(data.shape)\n\nprint('\\n',data.info())\n\n#checking for any missing value in the given dataset\nprint('\\n',data.isnull().sum())","8cab0f06":"data.decision.value_counts()","f70c651c":"#Segregating datasets into features and target datasets \n\n#dropping last column(target label) and selecting rest\nX=data.drop('decision',axis=1)\n\n#selecting only target variable\nY=data['decision']\n\nprint(X.shape,Y.shape)","76a7eb78":"# importing necessary package for encoding our categorial features\nimport category_encoders as ce\n\nencoder = ce.OrdinalEncoder(cols=['buying','maint_cost','total_doors','seater','boot_space','safety'])\nx= encoder.fit_transform(X)","158cef48":"print(x.head())\nprint(x.shape)","82a08290":"print('Original dataset')\nprint('\\n\\n',X.head())\nprint('\\n Encoded dataset')\nprint('\\n',x.head())","9e63cbc2":"#importing necessary packages and modules\nfrom sklearn.model_selection import train_test_split\n\nx_1,xtest,y_1,ytest=train_test_split(x,Y,test_size=0.3,random_state=2)\n\nxtrain,x_cv,ytrain,y_cv=train_test_split(x_1,y_1,test_size=0.3,random_state=2)\n\n\n# Exploring class distribution under train ,crossvalidation and test dataset\nprint('Training Dataset',xtrain.shape,ytrain.shape)\nprint('\\n Class label distribution in Training Set\\n',ytrain.value_counts())\nprint('\\n***********')\nprint(\"\\n CrossValidation Dataset\",x_cv.shape,y_cv.shape)\nprint('\\nClass label distribution in Cross Validation Set\\n',y_cv.value_counts())\nprint('\\n***********')\nprint(\"\\n Test Dataset\",xtest.shape,ytest.shape)\nprint('\\nClass label distribution in Test Set\\n',ytest.value_counts())","76799c2b":"# importing necessary packages\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nimport scikitplot.metrics as skplt\nimport matplotlib.pyplot as plt\nfrom sklearn import tree","f1198f1d":"from sklearn.model_selection import GridSearchCV\n\nparameters={'max_depth': list(range(1,30)),\n            'min_samples_leaf' : list(range(5,200,20)),\n            'min_samples_split': list(range(5,200,20))\n            }\nmodel=GridSearchCV(DecisionTreeClassifier(class_weight='balanced'),parameters,n_jobs=-1,cv=10,scoring='accuracy')\nmodel.fit(xtrain,ytrain)\nprint(model.best_estimator_)\nprint(\"\\n\",model.best_params_)\nprint(\"\\n\",model.score(x_cv,y_cv))\n\nypredict=model.predict(x_cv)\naccuracy=accuracy_score(y_cv,ypredict,normalize=True)*float(100)\nprint('\\n\\n classification report')\nprint(classification_report(y_cv,ypredict))\nskplt.plot_confusion_matrix(y_cv,ypredict)","f78d37b6":"clf=tree.DecisionTreeClassifier(class_weight='balanced',max_depth=9,min_samples_leaf=5,min_samples_split=5)\nclf.fit(xtrain,ytrain)\nypredict=clf.predict(xtest)\naccuracy=accuracy_score(ytest,ypredict,normalize=True)*float(100)\nprint('\\n Accuracy score is',accuracy)\nprint('\\n classification report')\nprint(classification_report(ytest,ypredict))\nskplt.plot_confusion_matrix(ytest,ypredict)","28e2c8ff":"# Visualising Decision Tree\ncols=['buying','maint_cost','total_doors','seater','boot_space','safety']\ntrgt=[' acc','good','unacc ',' vgood']\n\nfig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=300)\ntree.plot_tree(clf,feature_names = cols, class_names=trgt,filled = True);","0c7f4ba3":"## DECISION TREE CLASSIFIER\n\n### Introduction\n\nIn this python notebook I have tried to built a classification model using Decision trees. The model utilizes the car evaluation dataset and tries to predict its target label. Grid Search is used to find the best hyperparameters. Finally confusion matrics and classification reports are used to bring the model performance on train and test datasets.","3711352b":"There is a class imbalance particularly in crossvalidation dataset for class label \"good\". Let us try to **reduce this imbalance by giving weights to class labels while training our model**.","8814191c":"### Results & Conclusions\n\n1. In this project I have made a modest attempt to build a classification model based on the Decision Trees. \n2.The present model utilises GridSearch so as to find the optimum Hyperparameters. Gini impurity is use as a default criterion for splitting of node as it is computationally less efficient.\n3.The model shows appreciable results and comes up with a train acuracy of around 90% and a test acuracy of 92%. The model utilises cross validation technique in order to avoid data leakage and thus brings a more generalized model. \n4. As both the test and train accuracy are consistents so it can be inferred that the model avoids overfitting.\n5. As it was a tutorial mainly on the implementation of Decision trees so less emphasis was given on data exploration techniques.\n\n\n\nAs i am new to this field so I know there will be lots of instances where improvements will be required.\n\nYour feedback matters a lot and hence are welcomed.\n\nHope u like this post.\n\nThanks & Regards to the person who provided this dataset.","8d217819":"#### Testing model accuracy on Unseen Data (Test Dataset)\nUsing optimal value of hyper parameters that we got via Grid search, predicting the class labels for the trest dataset and getting its classification report","6bc1ebe0":"### Inference\n1. So, we have 1728 datapoints with 6 columns (features) and 1 class label(target) column.\n2. Data set contains categorical features.\n3. There are no missing value in the dataset.","e3d9a9d8":"Just see the \"safety\" column in both the datasets for comparision\nLOW in original data set is encoded as 1,\nMED as 2 and \nHigh as 3\n\nHIGH>MED>LOW  similarly 3>2>1  i.e **order of the categorical features are entact**, similarly we can check for other columns","d2471a6c":"To remove data imbalance we can **either UPSAMPLE** (in case when datapoints belonging to a particular class label are very low) or **DOWNSAMPLE**  (where number of data points belonging to a particular class label are very large in number).Each has its own advantages and disadvantages.\nAnother way to remove any decision biasness in the prediction is the use of  **appropriate evaluation metrices** ","56e090ee":"**Lets explore** all the given features and **especially the target variable** and see whether there is any **CLASS IMBALANCE**  or not. This is an important step as **class imbalance can turn the decision in favour of dominant class label** and thus can hamper the results of our predictions","5b569abc":"#### Comparing some of the datapoints before and after encoding just to check that their orders are retained or not.\n","7247b5c8":"#### Lets begin some data exploration and data cleaning","eef78dcd":"### Feature engineering\n\nAs the dataset has categorical features and hence they needs to be encoded in the appropriate form.\nThere are two main method of encodig:\n1. One hot encoding\n2. Label encoding\n\nAs we have categorial features that are ordinal in nature i.e that can be ranked (ordered) hence label encoding will solve our purpose.Had there been nominal features we could have preferred one hot encoding.","80789087":"Lets break the dataset into 3 parts **Train,Crossvalidation and Test datasets.** One can simply split the dataset into train and test data sets only but **splitting into two is prone to data leakage**. So, the idea behined **splitting** the data sets **into three parts** is to **avoid data leakage** and **to make our test data totally unseen from the model**.This brings more **generlization to our model accuracy**.","897aa964":"***As we can see that the dataset(features)is without headings hence the pandas is treating its first row as heading.Simplest way to resolve this problem is to avoid header while loading the dataset and then provide the necessary headings by ourselves(obviously after reading the decription related to the datatset)***.","7ffcd338":"## Inference drawn from Accuracy score and clasification report\n\n### Accuracy Score\nModel Accuracy on Training dataset= 90% \n, Model Accuracy on Test Dataset=92%\n\nThus the present model has shown consistant results on both Training and Test Datasets and hence can be considered as a generalised model.\n### Classification Report\nIt is advisable to not just rely on accuracy score as accuracy score sometimes doesnot tell the true picture related to the model, especially in the case of imbalanced dataset. Classification  Report is an efective metric that makes us doubly sure regarding the performance of our model.\n\nInference from classification report : As we can see that the **diagonal elements of confusion martix have the maximum value for both Train and Test data set**, it can therefore be concluded that the model has shown appreciable results. F1 score for each class label also tells the same story except for **class label \"good\" in training dataset** for which F1 score is very low(43% only). **One reason could be its very less presence in the crossvalidation dataset** on which the training accuracy was measured. \n","17f792d7":"**USING GRID SEARCH** FOR FINDING THE BEST PARAMETERS FOR OUR DECISION TREE MODEL & checking for model classification accuracy on Cross Validation Dataset"}}