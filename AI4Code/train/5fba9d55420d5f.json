{"cell_type":{"8fe9f619":"code","294c27dc":"code","ed127143":"code","81f419ef":"code","7fa98cd7":"code","b97d4565":"code","10c4600b":"code","b6d84199":"code","c3140eb1":"code","94e6cab9":"code","970d0a26":"code","9aaa81e2":"code","ad8d3743":"code","28ea4586":"code","571b0de7":"code","3b7f572a":"code","6230159b":"code","a79a04df":"code","79a7cdc3":"code","1716b01f":"code","192aa6e2":"code","c28a4d2a":"code","30af417f":"code","bf332109":"code","e136ebe1":"code","345939fd":"code","76569799":"code","a9a0bcdb":"code","24b0b1a6":"code","30692d34":"code","273a19f5":"code","ab8bbfd7":"code","133e2ee2":"code","699110f2":"code","0dbdba1f":"code","a7e3058a":"code","fc1ae6f6":"code","acc60172":"code","449727b5":"code","18b9181a":"code","8afe1d2e":"code","8138f694":"code","dc81ad31":"code","b9c89bb9":"code","114b82f7":"code","3a475844":"markdown","479a4051":"markdown"},"source":{"8fe9f619":"import os\nimport numpy as np\nimport pandas as pd","294c27dc":"df=pd.read_csv(\"..\/input\/gender-rec2\/df_larger (1).csv\")\ndf[\"gender\"].value_counts()","ed127143":"import librosa\ndef extract_feature(file_name, **kwargs):\n    \"\"\"\n    Extract feature from audio file `file_name`\n        Features supported:\n            - MFCC (mfcc)\n            - Chroma (chroma)\n            - MEL Spectrogram Frequency (mel)\n            - Contrast (contrast)\n            - Tonnetz (tonnetz)\n        e.g:\n        `features = extract_feature(path, mel=True, mfcc=True)`\n    \"\"\"\n    mfcc = kwargs.get(\"mfcc\")\n    chroma = kwargs.get(\"chroma\")\n    mel = kwargs.get(\"mel\")\n    contrast = kwargs.get(\"contrast\")\n    tonnetz = kwargs.get(\"tonnetz\")\n    \n  \n    # convert mp3 to wav file\n    \n    X, sample_rate = librosa.load(file_name)\n    if chroma or contrast:\n        stft = np.abs(librosa.stft(X))\n    result = np.array([])\n    if mfcc:\n        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n        result = np.hstack((result, mfccs))\n    if chroma:\n        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n        result = np.hstack((result, chroma))\n    if mel:\n        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n        result = np.hstack((result, mel))\n    if contrast:\n        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n        result = np.hstack((result, contrast))\n    if tonnetz:\n        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n        result = np.hstack((result, tonnetz))\n    return result","81f419ef":"((extract_feature(\"..\/input\/gender-rec2\/features\/sample-000019.wav\",mel=True)))","7fa98cd7":"target_name=\"\/kaggle\/working\/output\"\nos.mkdir(target_name)","b97d4565":"df","10c4600b":"df[\"filename\"]=(df.filename.replace({'cv-valid-train\/':'..\/input\/gender-rec2\/features\/'}, regex=True))\ndf","b6d84199":"audio_files=df[\"filename\"]\n#audio_files","c3140eb1":"df[\"filename\"]=(df.filename.replace({'mp3':'wav'}, regex=True))\ndf","94e6cab9":"str(df[\"filename\"][0])[30:]","970d0a26":"rm -r \"\/kaggle\/working\/output\/features\"","9aaa81e2":"target_name=\"\/kaggle\/working\/output\/features\"\nos.mkdir(target_name)","ad8d3743":"#Finding features for all\nfrom tqdm.notebook import tqdm_notebook as tqdm\nfor i in tqdm((df.index)):\n    path=df[\"filename\"][i]\n    features=extract_feature(path,mel=True)\n    file_name=str(df[\"filename\"][i])[30:]\n    #print (file_name)\n    target=os.path.join(target_name,file_name)\n    #print (target)\n    np.save(target, features)","28ea4586":"os.mkdir(\"\/kaggle\/working\/vals\")\nimport shutil\nshutil.make_archive(\"\/kaggle\/working\/vals\", 'zip', \"\/kaggle\/working\/output\/features\")","571b0de7":"df","3b7f572a":"df=pd.read_csv(\"..\/input\/gender-rec2\/df_larger (1).csv\")\ndf[\"feature_path\"]=df[\"feature_path\"]=df[\"filename\"]=(df.filename.replace({'cv-valid-train\/':'..\/input\/spec-vals\/'}, regex=True))\n","6230159b":"df[\"feature_path\"]=(df.feature_path.replace({'.mp3' : '.wav.npy'},regex=True))\ndf","a79a04df":"os.mkdir(\"\/kaggle\/working\/X\")\nos.mkdir(\"\/kaggle\/working\/y\")","79a7cdc3":"label2int = {\n    \"male\": 1,\n    \"female\": 0\n}","1716b01f":"def load_data(vector_length = 128):\n    # get total samples\n    n_samples = len(df)\n    # get total male samples\n    n_male_samples = len(df[df['gender'] == 'male'])\n    # get total female samples\n    n_female_samples = len(df[df['gender'] == 'female'])\n    print(\"Total samples:\", n_samples)\n    print(\"Total male samples:\", n_male_samples)\n    print(\"Total female samples:\", n_female_samples)\n    # initialize an empty array for all audio features\n    X = np.zeros((n_samples, vector_length))\n    # initialize an empty array for all audio labels (1 for male and 0 for female)\n    y = np.zeros((n_samples, 1))\n    for i, (filename, gender) in tqdm(enumerate(zip(df['filename'], df['gender'])), \"Loading data\", total=n_samples):\n        feature=np.load(df[\"feature_path\"][i],allow_pickle=True)\n        #print (feature)\n        X[i] = feature\n        y[i] = label2int[gender]\n    np.save(\"\/kaggle\/working\/X\", X)\n    np.save(\"\/kaggle\/working\/y\", y)\n    return X, y\n    ","192aa6e2":"from tqdm.notebook import tqdm_notebook as tqdm\nX,y=load_data()","c28a4d2a":"def split_data(X, y, test_size=0.1, valid_size=0.1):\n    # split training set and testing set\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=7)\n    # split training set and validation set\n    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size, random_state=7)\n    # return a dictionary of values\n    return {\n        \"X_train\": X_train,\n        \"X_valid\": X_valid,\n        \"X_test\": X_test,\n        \"y_train\": y_train,\n        \"y_valid\": y_valid,\n        \"y_test\": y_test\n    }","30af417f":"\nfrom tensorflow import keras \nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\n","bf332109":"# load the dataset\n# split the data into training, validation and testing sets\nfrom sklearn.model_selection import train_test_split\ndata = split_data(X, y, test_size=0.1, valid_size=0.1)","e136ebe1":"# Define the model\ndef create_model(vector_length=128):\n    model = Sequential()\n    model.add(Dense(256, input_shape=(vector_length,)))\n    model.add(Dropout(0.3))\n    model.add(Dense(256, activation=\"relu\"))\n    model.add(Dropout(0.3))\n    model.add(Dense(128, activation=\"relu\"))\n    model.add(Dropout(0.3))\n    model.add(Dense(128, activation=\"relu\"))\n    model.add(Dropout(0.3))\n    model.add(Dense(64, activation=\"relu\"))\n    model.add(Dropout(0.3))\n    # one output neuron with sigmoid activation function, 0 means female, 1 means male\n    model.add(Dense(1, activation=\"sigmoid\"))\n    # using binary crossentropy as it's male\/female classification (binary)\n    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n    # print summary of the model\n    model.summary()\n    return model","345939fd":"\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *","76569799":"model = create_model()","a9a0bcdb":"#model.summary()","24b0b1a6":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n# use tensorboard to view metrics\ntensorboard = TensorBoard(log_dir=\"logs\")\n# define early stopping to stop training after 5 epochs of not improving\nearly_stopping = EarlyStopping(mode=\"min\", patience=5, restore_best_weights=True)\n\nbatch_size = 64\nepochs = 100\n# train the model using the training set and validating using validation set\nmodel.fit(data[\"X_train\"], data[\"y_train\"], epochs=epochs, batch_size=batch_size, validation_data=(data[\"X_valid\"], data[\"y_valid\"]),\n          callbacks=[tensorboard, early_stopping])","30692d34":"print(f\"Evaluating the model using {len(data['X_test'])} samples...\")\nloss, accuracy = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\nprint(f\"Loss: {loss:.4f}\")\nprint(f\"Accuracy: {accuracy*100:.2f}%\")","273a19f5":"#with lstm model\ndef create_model_LSTM():\n    model = Sequential()\n    model.add(LSTM(128, return_sequences=False, input_shape=(40, 1)))\n    model.add(Dense(64))\n    model.add(Dropout(0.4))\n    model.add(Activation('relu'))\n    model.add(Dense(32))\n    model.add(Dropout(0.4))\n    model.add(Activation('relu'))\n    model.add(Dense(8))\n    model.add(Activation('relu'))\n    model.add(Dense(2))\n    model.add(Activation('softmax'))\n    \n    \n    # Configures the model for training\n    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n    return model","ab8bbfd7":"model_lstm=create_model_LSTM()","133e2ee2":"#changing shape of data for lstm model\nX.shape","699110f2":"data[\"X_valid\"] = np.reshape(data[\"X_valid\"], (data[\"X_valid\"].shape[0],data[\"X_valid\"].shape[1],1))\ndata[\"X_valid\"].shape","0dbdba1f":"data[\"y_train\"].shape","a7e3058a":"from tensorflow.keras.utils import to_categorical\ndata[\"y_train\"]= to_categorical(data[\"y_train\"]) # converts a class vector (integers) to binary class matrix\ndata[\"y_train\"].shape","fc1ae6f6":"data[\"X_test\"] = np.reshape(data[\"X_test\"], (data[\"X_test\"].shape[0],data[\"X_test\"].shape[1],1))\ndata[\"X_test\"].shape","acc60172":"data[\"y_valid\"]= to_categorical(data[\"y_valid\"]) # converts a class vector (integers) to binary class matrix\ndata[\"y_valid\"].shape","449727b5":"data[\"X_train\"] = np.reshape(data[\"X_train\"], (data[\"X_train\"].shape[0],data[\"X_train\"].shape[1],1))\ndata[\"X_train\"].shape","18b9181a":"import tensorflow\ntensorflow.config.run_functions_eagerly(True)\nhistory= model_lstm.fit(data[\"X_train\"], data[\"y_train\"],validation_data=(data[\"X_valid\"],data[\"y_valid\"]), epochs=100, shuffle=True)","8afe1d2e":"### loss plots using LSTM model\nimport matplotlib.pyplot as plt # visualizing data\nimport seaborn as sns \nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'ro', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","8138f694":"### accuracy plots using LSTM model\nplt.clf()                                                \n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.plot(epochs, acc, 'ro', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","dc81ad31":"#testing with test data\ndata[\"X_test\"] = np.reshape(data[\"X_test\"], (data[\"X_test\"].shape[0],data[\"X_test\"].shape[1],1))\ndata[\"X_test\"].shape","b9c89bb9":"data[\"y_test\"]= to_categorical(data[\"y_test\"]) # converts a class vector (integers) to binary class matrix\ndata[\"y_test\"].shape","114b82f7":"#testing\nmodel_lstm.evaluate(data[\"X_test\"],data[\"y_test\"])","3a475844":"The below snippet finds the associated vector with each .wav file.","479a4051":"The data has been first pre processed by converting MP3 files to .wav files."}}