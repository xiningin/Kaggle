{"cell_type":{"0fad4a27":"code","b285cc3a":"code","481100a0":"code","20539f55":"code","ee6cd4a8":"code","c80c7059":"code","5e317171":"markdown","7da0f995":"markdown","3887f4cd":"markdown","4e51da69":"markdown","38961fb0":"markdown"},"source":{"0fad4a27":"import pandas as pd\nimport numpy as np\nimport glob\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\n#CNN\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\nfrom keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n\n#Data Augmentation\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#predict\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\n\n#other\nimport warnings\nwarnings.simplefilter('ignore')","b285cc3a":"#prepare dataset\nphotos_A = '..\/input\/satellite-dataset\/A\/*.jpg'\nphotos_B = '..\/input\/satellite-dataset\/B\/*.jpg'\n\nlist_A = []\nlist_B = []\n\n#A\nfor x in glob.glob(photos_A):\n    img = Image.open(x)\n    resize_img = img.resize((n, m))#resize(n,m)\n    im  = np.array(resize_img)\n    im = im.reshape(-1)\n    list_A.append(im\/255)\n#B  \nfor x in glob.glob(photos_B):\n    img = Image.open(x)\n    resize_img = img.resize((n, m))#resize(n,m)\n    im  = np.array(resize_img)\n    im = im.reshape(-1)\n    list_B.append(im\/255)","481100a0":"#make dataframe\ndf_A = pd.DataFrame(list_A)\ndf_A['label'] = np.zeros(len(list_A))\ndf_B = pd.DataFrame(list_B)\ndf_B['label'] = np.ones(len(list_B))\ndf =  pd.concat([df_A, df_B], axis=0).reset_index(drop=True)\ndf","20539f55":"#make train-valid dataset\nX = df.drop('label',axis=1) # Features\ny = df.label #Objective\n\nX_ = X.values.reshape(-1, m, n, 3)#(m,n), not (n,m)\nX_train, X_valid, y_train, y_valid = train_test_split(X_, y, stratify=y, test_size=0.3)","ee6cd4a8":"##model_CNN\nmodel = keras.Sequential([\n    layers.Conv2D(filters = 64, kernel_size = (2,2), padding = 'Same', activation ='relu', input_shape = (m,n,3)),#(m,n), not (n,m)\n    layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n    layers.Dropout(0.3),\n    \n    layers.Conv2D(filters = 128, kernel_size = (2,2), padding = 'Same', activation ='relu'),\n    layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n    layers.Dropout(0.3),\n    \n    layers.Conv2D(filters = 256, kernel_size = (2,2), padding = 'Same', activation ='relu'),\n    layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n    layers.Dropout(0.3),\n    \n    layers.Flatten(),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(1, activation='sigmoid'),\n])\n\nmodel.compile(\n    optimizer = 'Adam',\n    loss = 'binary_crossentropy',\n    metrics = ['acc']\n)\n\n#f1-score_callback\nclass F1Callback(Callback):\n    def __init__(self, model, X_val, y_val):\n        self.model = model\n        self.X_val = X_val\n        self.y_val = y_val\n        self.f1s = []\n\n    def on_epoch_end(self, epoch, logs):\n        pred = self.model.predict(self.X_val)\n        f1_val = f1_score(self.y_val, np.round(pred))\n        self.f1s.append(f1_val)\nf1cb = F1Callback(model, X_valid, y_valid)\n\n#early_stop\nearly_stopping = EarlyStopping(\n    patience=30,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\n\n#checkpoint\ncp = ModelCheckpoint(\"weights.hdf5\", monitor=\"val_loss\", verbose=0,\n                     save_best_only=True, save_weights_only=True)\n\n#Data_Augmentation\ndatagen = ImageDataGenerator(\n        horizontal_flip=True,\n        vertical_flip=True\n)\n\nbatch_size=80\n\n#study\nhistory = model.fit(\n    datagen.flow(X_train, y_train, batch_size=batch_size, shuffle=True),\n    validation_data=(X_valid, y_valid),\n    steps_per_epoch=X_train.shape[0] \/\/ batch_size,\n    epochs=300,\n    callbacks=[f1cb, early_stopping, cp],\n    verbose=1\n)\n\n#plot\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['acc', 'val_acc']].plot(title=\"Accuracy-F1\")\nplt.plot(np.arange(len(f1cb.f1s)) + 1, np.array(f1cb.f1s), label=\"val_f1\")\nplt.legend()\nplt.xlabel(\"epoch\")\nplt.show()\n\n#predict validation data with best\nmodel.load_weights('.\/weights.hdf5')\ny_pred = model.predict(X_valid).round()\n#valid_score\nprint(\"valid_f1-score-best:\", f1_score(y_valid, y_pred))\nprint(\"valid_confusion_matrix-best:\\n\", confusion_matrix(y_valid, y_pred))","c80c7059":"#predict test data with best\npred_test = model.predict(X_test).round()\npred_test","5e317171":"# **2.prepare dataset**  \nSeparate the photos into 2 different datasets and place them in folders A and B  \nYou need set your datasets file paths and pixel size","7da0f995":"# **How do you classify the photos into 2 categories?**\n# - Binary Image Classification using CNN -  \nIf you need to classify the dataset composed of photos that may have 2 features  \n(e.g. datasets composed of satellite photos that have 2 features(residential area or nonresidential area)),   \nmaybe this memo can help you.\n  \nYou can replace your datasets with the sample.  ","3887f4cd":"# **4.predict test data**  \nYou need to prepare test dataset with the same way as train-valid dataset","4e51da69":"# **1.Prepare libraries**","38961fb0":"# **3. study CNN model**  \nYou can change the parameters used in the model"}}