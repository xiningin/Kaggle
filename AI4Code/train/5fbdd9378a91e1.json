{"cell_type":{"abc8c115":"code","4d4210ff":"code","530d2273":"code","8ef7e44e":"code","0b16bae4":"code","56b04624":"code","2d88b88a":"code","4743af1a":"code","dac88fe7":"code","fb5fbe75":"code","0b3602ca":"code","0f93f846":"code","3e87e55f":"code","62025bda":"code","f8a07217":"code","9fa28948":"code","d41a1b21":"code","11ddae57":"code","6510e2a0":"code","90716bf7":"code","a2dd0e5b":"code","36939ef9":"code","d82022cd":"code","b61cf8a6":"code","cfb022e5":"code","7578d084":"code","27444321":"code","f9c67731":"code","53d91a11":"code","2b594f1d":"code","88dca2ae":"code","bd5f6f81":"code","fe100b80":"code","136825fd":"code","40098379":"code","e13605d5":"markdown","15f07c80":"markdown","657033aa":"markdown","97a98b3c":"markdown","d3554a08":"markdown","7e35f770":"markdown","f502c0f0":"markdown","ce5df31c":"markdown","960ab5fb":"markdown","8eee794d":"markdown","13b31e13":"markdown","3dcebf21":"markdown","c038174a":"markdown","1799c095":"markdown","279a1f92":"markdown","318ba1d0":"markdown","05d7aff3":"markdown","8d44fb93":"markdown","9d372ddf":"markdown","15201e1d":"markdown","99404e9a":"markdown","ded98ebe":"markdown"},"source":{"abc8c115":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline \nimport warnings\nwarnings.simplefilter(\"ignore\")\nfrom wordcloud import WordCloud, STOPWORDS\n\n","4d4210ff":"df = pd.read_csv(\"..\/input\/breaking-news-from-twitter-20102021\/tweets_bbc.csv\", parse_dates=[['date', 'time']])\ndf.head()","530d2273":"df['date_time'] = pd.to_datetime(df['date_time'], errors='coerce')\n\ndf['year'] = df['date_time'].dt.year\ndf['month'] = df['date_time'].dt.month\ndf['day'] = df['date_time'].dt.day\ndf['dayofweek'] = df['date_time'].dt.dayofweek\ndf['hour'] = df['date_time'].dt.hour\ndf['minute'] = df['date_time'].dt.minute\ndf['dayofyear'] = df['date_time'].dt.dayofyear\ndf['date_only'] = df['date_time'].dt.date","8ef7e44e":"print(f\"data shape: {df.shape}\")\nprint(\"--------------------\")\ndf.info()","0b16bae4":"df['cashtags'].value_counts()","56b04624":"df['hashtags'].value_counts()","2d88b88a":"df['hashtags']=df['hashtags'].replace({'[]':np.nan})","4743af1a":"df.hashtags.value_counts()","dac88fe7":"df.columns","fb5fbe75":"data = df.drop(['retweet_date', 'translate', 'trans_src','trans_dest', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n       'retweet_id', 'place', 'thumbnail', 'quote_url', 'id', 'conversation_id', 'link', 'urls', 'photos', 'user_id', 'cashtags'],\n               axis =  1)","0b3602ca":"data.head()","0f93f846":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    dataframe = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    dataframe['Types'] = types\n    return(np.transpose(dataframe))","3e87e55f":"missing_data(data)","62025bda":"def unique_values(data):\n    total = data.count()\n    dataframe = pd.DataFrame(total)\n    dataframe.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n    dataframe['Uniques'] = uniques\n    return(np.transpose(dataframe))","f8a07217":"unique_values(data)","9fa28948":"def most_frequent_values(data):\n    total = data.count()\n    dataframe = pd.DataFrame(total)\n    dataframe.columns = ['Total']\n    items = []\n    vals = []\n    for col in data.columns:\n        itm = data[col].value_counts().index[0]\n        val = data[col].value_counts().values[0]\n        items.append(itm)\n        vals.append(val)\n    dataframe['Most frequent values'] = items\n    dataframe['Frequency'] = vals\n    dataframe['Percent from total'] = np.round(vals \/ total * 100, 2)\n    return(np.transpose(dataframe))","d41a1b21":"most_frequent_values(data)","11ddae57":"# Helper function by GM Gabriel Preda\ndef plot_count(feature, title, df, size=1, ordered=True):\n    f, ax = plt.subplots(1,1, figsize=(5*size,5))\n    total = float(len(data))\n    if ordered:\n        g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set2')\n    else:\n        g = sns.countplot(df[feature], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()  ","6510e2a0":"plot_count(\"language\", \"Language\", data,4)","90716bf7":"plot_count(\"hashtags\", \"Hashtags\", data,4)","a2dd0e5b":"plot_count(\"year\", \"tweets \/ year\", data, size=3, ordered=False)","36939ef9":"plot_count(\"month\", \"tweets \/ month\", data, size=3, ordered=False)","d82022cd":"plot_count(\"dayofweek\", \"tweets \/ day of week\", data, size=3, ordered=False)","b61cf8a6":"plot_count(\"hour\", \"tweets \/ hour\", data,size=4, ordered=False)","cfb022e5":"plot_count(\"minute\", \"tweets \/ minute\", data,size=5, ordered=False)","7578d084":"plot_count(\"timezone\", \"Timezone\", data,4)","27444321":"from wordcloud import WordCloud, STOPWORDS\ndef show_wordcloud(data, title=\"\"):\n    text = \" \".join(t for t in data.dropna())\n    stopwords = set(STOPWORDS)\n    stopwords.update([\"t\", \"co\", \"https\", \"say\", \"says\", \"amp\"])\n    wordcloud = WordCloud(stopwords=stopwords, scale=4, max_font_size=50, max_words=500,background_color=\"black\").generate(text)\n    fig = plt.figure(1, figsize=(16,16))\n    plt.axis('off')\n    fig.suptitle(title, fontsize=20)\n    fig.subplots_adjust(top=2.3)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.show()","f9c67731":"\nshow_wordcloud(data['tweet'], title = 'Most common words in tweets')","53d91a11":"from nltk.sentiment import SentimentIntensityAnalyzer\n","2b594f1d":"sa = SentimentIntensityAnalyzer()\ndef sentiment(news):\n    if sa.polarity_scores(news)[\"compound\"] > 0:\n        return \"Positive\"\n    elif sa.polarity_scores(news)[\"compound\"] < 0:\n        return \"Negative\"\n    else:\n        return \"Neutral\" ","88dca2ae":"#Helpful function by Gabriel Preda https:\/\/www.kaggle.com\/gpreda\/tokyo-2020-tweets-sentiment-analysis\n\ndef plot_sentiment(df, feature, title):\n    counts = df[feature].value_counts()\n    percent = counts\/sum(counts)\n\n    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n\n    counts.plot(kind='bar', ax=ax1, color='green')\n    percent.plot(kind='bar', ax=ax2, color='blue')\n    ax1.set_ylabel(f'Counts : {title} sentiments', size=12)\n    ax2.set_ylabel(f'Percentage : {title} sentiments', size=12)\n    plt.suptitle(f\"Sentiment analysis: {title}\")\n    plt.tight_layout()\n    plt.show()","bd5f6f81":"data['text_sentiment'] = data['tweet'].apply(lambda x: sentiment(x))\nplot_sentiment(data, 'text_sentiment', 'Text')","fe100b80":"show_wordcloud(data.loc[data['text_sentiment']=='Positive', 'tweet'], \n               title = 'Most common words in texts (Positive sentiment)')","136825fd":"show_wordcloud(data.loc[data['text_sentiment']=='Negative', 'tweet'], \n               title = 'Most common words in texts (Negative sentiment)')","40098379":"show_wordcloud(data.loc[data['text_sentiment']=='Neutral', 'tweet'], \n               title = 'Most common words in texts (Neutral sentiment)')","e13605d5":"### '[]' in hashtags columns doesn't contribute to anything, so replacing it with null value","15f07c80":"### Tweets according to month, March has got the highest number of tweets.","657033aa":"### Above dataframe shows the most unique values in the dataset","97a98b3c":"# Data info and cleaning","d3554a08":"### Tweets according to day of week, Thursday has got the highest number of tweets followed by wednesday.","7e35f770":"# Data visualisation","f502c0f0":"### Percentage of missing data in hashtags is 65.7539%","ce5df31c":"![](https:\/\/thumbs.dreamstime.com\/b\/word-writing-text-news-analysis-business-concept-measurement-various-qualitative-quantitative-magnifying-glass-138955945.jpg)","960ab5fb":"### Above dataframe shows the unique values in the dataset","8eee794d":"### Top Hashtags are Syria, Ukraine, ge2015","13b31e13":"### Most common words are Police, Killed, died, London, UK, Syria, Details, report, shooting, jailed. so that's not good.","3dcebf21":"### English language tweets counts for 99.57%","c038174a":"![](https:\/\/www.journal-leader.com\/wp-content\/uploads\/2021\/04\/Thumbs-up-masked-image.jpg)","1799c095":"# Sentiment Analysis with NLTK SentimentIntensityAnalyzer","279a1f92":"# Exploratory data analysis","318ba1d0":"Another great source of sentiment analysis and text analytics is done by Grandmaster Gabriel Preda\nhttps:\/\/www.kaggle.com\/gpreda\/tokyo-2020-monitor-tweets-frequency\n\nBy Master Thomas Konstantin\nhttps:\/\/www.kaggle.com\/thomaskonstantin\/exploring-internet-news-headlines","05d7aff3":"## Upvote if you like it or fork it","8d44fb93":"![](https:\/\/www.kdnuggets.com\/images\/sentiment-fig-1-689.jpg)","9d372ddf":"### Lots of columns are null so we can drop them","15201e1d":"### Tweets according to year, 2013 got the highest.","99404e9a":"### Cashtags column doesn't contribute anything to the dataset, so we can delete them","ded98ebe":"### Tweets according to hour, 15th hour or 3 p.m has got the highest number of tweets"}}