{"cell_type":{"41d0c58b":"code","c67a1313":"code","3686ec8a":"code","b410f5df":"code","df0b039b":"code","1f0c03fb":"code","68af193c":"code","3ef78c96":"code","03a824bc":"code","85cde4a8":"code","345927b7":"code","c76a5d2f":"code","36e74eba":"code","3423ca00":"code","8cd90266":"code","9c2eaf9a":"code","6def6049":"code","1b16060a":"code","d06abd27":"code","aa2bb5c1":"code","eafedaba":"code","1bd7c00e":"code","289df5aa":"code","61989e5f":"code","0e89c9c4":"code","c3f45db1":"code","42ed0c57":"code","531c1973":"markdown","6ce370d4":"markdown","11e21b97":"markdown","94c79ff9":"markdown","574d9228":"markdown"},"source":{"41d0c58b":"#import library\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport nltk\nnltk.download('stopwords')\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport re\nimport string\nstring.punctuation\nimport matplotlib.pyplot as plt\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer","c67a1313":"tweet = pd.read_csv('..\/input\/valorant-agents-tweets\/valorant_tweets.csv')","3686ec8a":"tweet.shape","b410f5df":"tweet.head()","df0b039b":"tweet.describe()","1f0c03fb":"tweet.info()","68af193c":"#selection data\ndf1 = tweet[['tweet']]\ndf1.head()","3ef78c96":"#setting lower case\ndf1['tweet_lower'] = df1['tweet'].apply(lambda x: x.lower())\ndf1.head()","03a824bc":"#defining the function to remove punctuation\ndef remove_punctuation(text):\n    punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n    return punctuationfree\n\n#storing the puntuation free text\ndf1['tweet_punctual'] = df1['tweet_lower'].apply(lambda x:remove_punctuation(x))\ndf1.head()","85cde4a8":"#defining the function to remove emoji\ndef remove_emoji(string):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  \n                           u\"\\U0001F300-\\U0001F5FF\"  \n                           u\"\\U0001F680-\\U0001F6FF\" \n                           u\"\\U0001F1E0-\\U0001F1FF\"  \n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', string)\n\n#applying the function\ndf1['no_emoji'] = df1['tweet_punctual'].apply(lambda x: remove_emoji(x))\ndf1.head()","345927b7":"#defining the function to remove html\ndef remove_html(text):\n    html_pattern = re.compile('<.*?>')\n    return html_pattern.sub(r'', text)\n\n#applying function to the column\ndf1['tweet_clean'] = df1['no_emoji'].apply(lambda x: remove_html(x))\ndf1.head()","c76a5d2f":"#defining function for tokenization\ndef tokenization(text):\n    tokens = re.split('W+', text)\n    return tokens\n\n#applying function to the column\ndf1['tweet_tokenied'] = df1['no_emoji'].apply(lambda x: tokenization(x))\ndf1.head()","36e74eba":"#stop words present in the library\nstopwords = nltk.corpus.stopwords.words('english')\nstopwords[0:10]","3423ca00":"#defining the function to remove stopwords from tokenized text\ndef remove_stopwords(text):\n    output= [i for i in text if i not in stopwords]\n    return output\n\n#applying the function\ndf1['no_stopwords'] = df1['tweet_tokenied'].apply(lambda x:remove_stopwords(x))\ndf1.head()","8cd90266":"#defining the object for stemming\nporter_stemmer = PorterStemmer()\n\n#defining a function for stemming\ndef stemming(text):\n    stem_text = [porter_stemmer.stem(word) for word in text]\n    return stem_text\n\n#applying the function\ndf1['tweet_stemmed'] = df1['no_stopwords'].apply(lambda x: stemming(x))\ndf1.head()","9c2eaf9a":"#selection data\ndf2 = df1[['tweet_clean']]\ndf2.head()","6def6049":"#create function to get subjectivity\ndef getSubjectivity(text):\n    return TextBlob(text).sentiment.subjectivity\n\n#create function to get polarity\ndef getPolarity(text):\n    return TextBlob(text).sentiment.polarity\n\n#apply function to data \ndf2['subjectivity'] = df2['tweet_clean'].apply(getSubjectivity)\ndf2['polarity'] = df2['tweet_clean'].apply(getPolarity)\ndf2.head()","1b16060a":"#create function to get sentiment data\ndef getSentiment(score):\n    if score < 0:\n        return 'Negative'\n    elif score == 0:\n        return 'Neutral'\n    else:\n        return 'Positive'\n\n#apply function to data\ndf2['sentiment'] = df2['polarity'].apply(getSentiment)\ndf2.head()","d06abd27":"positive = \" \".join(df2[df2.sentiment == 'Positive']['tweet_clean'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, background_color = 'white').generate(positive)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Positive Tweet\")\nplt.axis('off')\nplt.show()","aa2bb5c1":"neutral = \" \".join(df2[df2.sentiment == 'Neutral']['tweet_clean'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, background_color = 'white').generate(neutral)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Neutral Tweet\")\nplt.axis('off')\nplt.show()","eafedaba":"negative = \" \".join(df2[df2.sentiment == 'Negative']['tweet_clean'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, background_color = 'white').generate(negative)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Negative Tweet\")\nplt.axis('off')\nplt.show()","1bd7c00e":"#visualize sentiment\nplt.figure(figsize = (10,6))\nplt.xlabel('Sentiment')\nplt.ylabel('Count')\ndf2['sentiment'].value_counts().plot(kind = 'bar')\nplt.title(\"Sentiment Analysis of Tweet\")\nplt.show()","289df5aa":"#selection data\njoin = (tweet['Agent'], tweet['Role'], df2['sentiment'])\ndf3 = pd.concat(join, axis = True)\ndf3.head()","61989e5f":"#group agent & sentiment\nagent_sentiment = df3.groupby(['Agent', 'sentiment']).size().reset_index(name = 'Count')\nprint(agent_sentiment)","0e89c9c4":"#visualize agent ~ sentiment\nplt.figure(figsize = (15,7))\nchart = sns.barplot(x = 'Agent', y = 'Count', hue = 'sentiment', data = agent_sentiment)\nchart.set_xticklabels(chart.get_xticklabels(), rotation = 45)\nplt.title(\"Agent ~ Sentiment\")\nplt.show()","c3f45db1":"#group role & sentiment\nrole_sentiment = df3.groupby(['Role', 'sentiment']).size().reset_index(name = 'Count')\nprint(role_sentiment)","42ed0c57":"#visualize role ~ sentiment\nplt.figure(figsize = (9,6))\nchart = sns.barplot(x = 'Role', y = 'Count', hue = 'sentiment', data = role_sentiment)\nchart.set_xticklabels(chart.get_xticklabels(), rotation = 45)\nplt.title(\"Role ~ Sentiment\")\nplt.show()","531c1973":"## Data Extraction","6ce370d4":"# Sentimental Analysis on Valorant Agents Tweets","11e21b97":"## Text Processing","94c79ff9":"## Visualization","574d9228":"## Sentiment Analysis"}}