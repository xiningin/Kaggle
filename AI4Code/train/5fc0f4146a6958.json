{"cell_type":{"7dfba3cd":"code","fd82ce18":"code","7743c3bf":"code","7ea8aaf9":"code","f29ae43c":"code","d7cbae3e":"code","2e2f4748":"code","518e76bc":"code","a560632c":"code","a8b598fc":"code","a9dfc0b0":"code","e458f99a":"code","093a3566":"code","64e7af1c":"code","a5fae39b":"code","fcc83a91":"code","d46b32d3":"code","bbb728a8":"code","c79f1360":"code","f3e21436":"code","ad31cc4d":"markdown","23baf580":"markdown","c6f154c6":"markdown","d0315ab7":"markdown","ea27257f":"markdown","2956f4bc":"markdown","48193320":"markdown","f9dba816":"markdown"},"source":{"7dfba3cd":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (6,6)\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.layers import Dense, Input, Activation, Conv1D\nfrom keras.layers import Dropout, MaxPooling1D, Flatten, Concatenate, Reshape\nfrom keras.models import Sequential, Model, load_model\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.utils import np_utils\n\nimport re\nimport random\nimport os\nprint(os.listdir(\"..\/input\"))","fd82ce18":"train_df = pd.read_json(\"..\/input\/train.json\")\ntrain_df.head()","7743c3bf":"test_df = pd.read_json(\"..\/input\/test.json\")\ntest_df.head()","7ea8aaf9":"# concat all\n\ntest_df[\"cuisine\"] = \"unknown\"\n\ndf = pd.concat([train_df, test_df], ignore_index=True)\ndf.head()","f29ae43c":"print(df.shape)","d7cbae3e":"df.ingredients = df.ingredients.apply(lambda x: (\" \".join(x)).lower())\ndf.ingredients = df.ingredients.apply(lambda x: re.sub(r'[^\\w\\d ,]', '', x))\ndf.head()","2e2f4748":"train_set = df[df.cuisine != 'unknown']\ntest_set = df[df.cuisine == 'unknown']","518e76bc":"tfidf = TfidfVectorizer(binary=True)\n\nx = tfidf.fit_transform(train_set.ingredients).todense()\nx_test = tfidf.transform(test_set.ingredients).todense()","a560632c":"print(x.shape, x_test.shape)","a8b598fc":"lb = LabelEncoder()\ny = lb.fit_transform(train_set.cuisine)\ny = np_utils.to_categorical(y)\nprint(y.shape)","a9dfc0b0":"seed = 29\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=seed)\n\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)","e458f99a":"MLP = Sequential()\nMLP.add(Dense(512, input_shape=(3073, ), activation='relu'))\nMLP.add(Dropout(0.5))\nMLP.add(Dense(y_train.shape[1], activation='softmax'))\nMLP.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nMLP.summary()","093a3566":"file_path = \"mlp.hdf5\"\ncheck_point = ModelCheckpoint(file_path, monitor=\"val_acc\", verbose=1, save_best_only=True, mode=\"max\")\nearly_stop = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n\nmlp_history = MLP.fit(x_train, \n                      y_train, \n                      batch_size=128, \n                      epochs=50, \n                      validation_data=(x_val, y_val),\n                      callbacks=[check_point, early_stop])","64e7af1c":"mlp_best = load_model('mlp.hdf5')","a5fae39b":"inp = Input(shape=(3073,), dtype='float32')\nreshape = Reshape(target_shape=(7,439))(inp)\n\nstacks = []\nfor kernel_size in [2, 3, 4]:\n    conv = Conv1D(128, kernel_size, padding='same', activation='relu', strides=1)(reshape)\n    pool = MaxPooling1D(pool_size=3)(conv)\n    drop = Dropout(0.5)(pool)\n    stacks.append(drop)\n\nmerged = Concatenate()(stacks)\nflatten = Flatten()(merged)\ndrop = Dropout(0.5)(flatten)\noutp = Dense(y_train.shape[1], activation='softmax')(drop)\n\nTextCNN = Model(inputs=inp, outputs=outp)\nTextCNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nTextCNN.summary()","fcc83a91":"file_path = \"textcnn.hdf5\"\ncheck_point = ModelCheckpoint(file_path, monitor=\"val_acc\", verbose=1, save_best_only=True, mode=\"max\")\nearly_stop = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n\ntextcnn_history = TextCNN.fit(x_train, \n                              y_train, \n                              batch_size=128, \n                              epochs=50, \n                              validation_data=(x_val, y_val),\n                              callbacks=[check_point, early_stop])","d46b32d3":"textcnn_best = load_model('textcnn.hdf5')","bbb728a8":"mlp_pred = mlp_best.predict(x_test)\ntextcnn_pred = textcnn_best.predict(x_test)\n\nensemble_pred = (mlp_pred + textcnn_pred).argmax(axis=1)\nfinal = lb.inverse_transform(ensemble_pred)","c79f1360":"sub = pd.DataFrame({'id': test_df.id, 'cuisine': final})\nsub.to_csv('tfidf-textcnn.csv', index = False)","f3e21436":"!head tfidf-textcnn.csv","ad31cc4d":"Just a test on building MLP and TextCNN model using the TF-IDF data. The result is about 0.79.","23baf580":"# split training dataset","c6f154c6":"# submission","d0315ab7":"# TF IDF","ea27257f":"# loading data","2956f4bc":"# import modules","48193320":"# MLP","f9dba816":"# TextCNN"}}