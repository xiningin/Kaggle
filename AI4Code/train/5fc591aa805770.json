{"cell_type":{"448f96c4":"code","137d4932":"code","5ed4cc97":"code","50837c49":"code","2c1ff973":"code","a936b6ba":"code","3c5cddac":"code","8fb84b52":"code","f74ce639":"code","963bfc16":"code","331923b8":"code","0929f0f8":"code","c8cc1ae3":"code","1957903c":"code","fa1c4646":"code","815d417f":"code","0716b1ef":"code","6ae07982":"code","8ccd8f35":"code","59c39365":"code","281ccf01":"markdown"},"source":{"448f96c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","137d4932":"#Import liblary\nimport numpy as np\nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models, callbacks\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split","5ed4cc97":"#Import training data and show first 5 lines\ntrain_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntrain_data.head()","50837c49":"#Show the number of each label data\nsns.countplot(x=\"label\", data=train_data)","2c1ff973":"#Show first 25 data\nplt.subplots(5,5)\nfor i in range(1,26):\n    plt.subplot(5,5,i)\n    plt.imshow(train_data.iloc[i,1:].to_numpy().reshape(28,28))\n    plt.axis(\"off\")","a936b6ba":"#Split training data into training and valid data\nX_train = train_data.drop(columns=[\"label\"])\nY_train = train_data[\"label\"]\nX_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.3)\nprint(X_train.shape)\nprint(Y_train.shape)\nprint(X_valid.shape)\nprint(Y_valid.shape)","3c5cddac":"#Reshape the input data 28x28x1\nX_train = X_train.to_numpy().reshape(len(X_train), 28, 28, 1)\nX_valid = X_valid.to_numpy().reshape(len(X_valid), 28, 28, 1)\nprint(X_train.shape)\nprint(Y_train.shape)\nprint(X_valid.shape)\nprint(Y_valid.shape)","8fb84b52":"#Create the CNN model.\nmodel_1 = models.Sequential()\n\n#First Unit\n#Convolutional layer with 32 filters\n#Pooling layer\nmodel_1.add(layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)))\nmodel_1.add(layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n\n#Second Unit\n#Convolutional layer with 64 filters\n#Pooling layer\nmodel_1.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\nmodel_1.add(layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n\n#Third Unit\n#Convert to 1-D array\n#Fully connected layer x 3\nmodel_1.add(layers.Flatten())\nmodel_1.add(layers.Dense(784, activation=\"relu\"))\nmodel_1.add(layers.Dense(256, activation=\"relu\"))\nmodel_1.add(layers.Dense(64, activation=\"relu\"))\nmodel_1.add(layers.Dense(10, activation=\"softmax\"))","f74ce639":"model_1.summary()","963bfc16":"model_1.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                 metrics=[\"accuracy\"])\nlog_1 = model_1.fit(X_train, Y_train, epochs=100, validation_data=(X_valid, Y_valid),\n                callbacks=[callbacks.EarlyStopping(monitor='val_loss',min_delta=0, patience=10,verbose=1)])","331923b8":"plt.plot(log_1.history['accuracy'], label='accuracy')\nplt.plot(log_1.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.9, 1])\nplt.legend(loc='lower right')","0929f0f8":"plt.plot(log_1.history['loss'], label='loss')\nplt.plot(log_1.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\n#plt.ylim([0.9, 1])\nplt.legend(loc='lower right')","c8cc1ae3":"#Create the CNN model including Dropout layers.\nmodel_2 = models.Sequential()\n\n#First Unit\n#Convolutional layer with 32 filters\n#Pooling layer\n#Dropout layer (25%)\nmodel_2.add(layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)))\nmodel_2.add(layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\nmodel_2.add(layers.Dropout(0.25))\n\n#Second Unit\n#Convolutional layer with 64 filters\n#Pooling layer\n#Dropout layer (50%)\nmodel_2.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\nmodel_2.add(layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\nmodel_2.add(layers.Dropout(0.5))\n\n#Third Unit\n#Convert to 1-D array\n#Fully connected layer x 3\nmodel_2.add(layers.Flatten())\nmodel_2.add(layers.Dense(784, activation=\"relu\"))\nmodel_2.add(layers.Dense(256, activation=\"relu\"))\nmodel_2.add(layers.Dense(64, activation=\"relu\"))\nmodel_2.add(layers.Dense(10, activation=\"softmax\"))","1957903c":"model_2.summary()","fa1c4646":"model_2.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                 metrics=[\"accuracy\"])\nlog_2 = model_2.fit(X_train, Y_train, epochs=100, validation_data=(X_valid, Y_valid),\n                callbacks=[callbacks.EarlyStopping(monitor='val_loss',min_delta=0, patience=10,verbose=1)])","815d417f":"plt.plot(log_1.history['accuracy'], label='accuracy_CNN')\nplt.plot(log_1.history['val_accuracy'], label = 'val_accuracy_CNN')\nplt.plot(log_2.history['accuracy'], label='accuracy_CNN+Dropout')\nplt.plot(log_2.history['val_accuracy'], label = 'val_accuracy_CNN+Dropout')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.9, 1])\nplt.legend(loc='lower right')","0716b1ef":"plt.plot(log_1.history['loss'], label='loss_CNN')\nplt.plot(log_1.history['val_loss'], label = 'val_loss_CNN')\nplt.plot(log_2.history['loss'], label='loss_CNN+Dropout')\nplt.plot(log_2.history['val_loss'], label = 'val_loss_CNN+Dropout')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\n#plt.ylim([0.9, 1])\nplt.legend(loc='upper right')","6ae07982":"#predict test data by using model_2\ntest_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\nX_test = test_data.to_numpy().reshape(len(test_data), 28, 28, 1)\nY_pred = model_2.predict(X_test)","8ccd8f35":"#Extract the index where the max value is stored (0-9)\nY_pred_1 = np.argmax(Y_pred, axis=1)","59c39365":"df_submission = pd.DataFrame(data = {\"ImageId\" : test_data.index.values + 1, \"Label\" : Y_pred_1})\ndf_submission.to_csv(\"submission.csv\", index=False)","281ccf01":"**About the Notebook**\n\nI have tried to classify the images in 10 class with tensorflow CNN.\nIn this notebook, I have created two models. One is CNN only and the other is CNN with Dropout layers. I am a quite new to machine learning, so I don't use the complicated models. However, the prediction seems to enough. Please leave any comments you have! Thank you.\n\nThe following are the steps in this notebook;\n1. Import liblary\n2. Loading and data visualization\n3. Split dataset into test and validation data\n4. Create the model with CNN only (model_1)\n5. Create the model with CNN + Dropout layers (model_2)\n6. Model Comparison"}}