{"cell_type":{"17285b67":"code","b435e21e":"code","6baaa0f0":"code","a872ed6d":"code","d54ae563":"code","51b1c9c3":"code","34b012c6":"code","fb393b20":"code","00fba28b":"code","33a84fa3":"code","5ac921fc":"code","37070856":"code","1b12df43":"code","6941634f":"code","072af6f6":"code","b9971b20":"code","95cabfc7":"code","8f8fbc9c":"code","cddd90bc":"code","b9dc1a8a":"code","cd8efcdf":"code","22d900d0":"code","b5e5bad0":"code","36157de0":"code","e4136473":"code","c0408682":"code","ae6e7140":"code","2857ca3f":"code","24aa8679":"code","bf17934c":"code","c1bd7ec6":"code","5247510e":"code","c2a8f729":"code","63ebd7b0":"code","9406a9a0":"code","6b061ffe":"code","3a04675d":"code","6bd690e5":"code","a1bf4bb5":"code","e69ea4c4":"code","85daa566":"code","a58cd7cb":"code","1e74e8a3":"code","56df25bb":"code","9ea17d1c":"code","ff8ea199":"code","62585df1":"code","d69a27aa":"code","1121a575":"code","845ba932":"code","010c7280":"code","f0be2591":"code","a6fb6daf":"code","c413e435":"code","d1ae830e":"code","528253e2":"code","37f3bdb3":"code","f800d8b1":"code","2345f6c1":"code","c56179f3":"code","a9f3a248":"code","ecf934a3":"code","fe4c9931":"code","1462002e":"code","f6168b34":"code","0d0d96dc":"code","81826590":"code","67bc2150":"code","5732873c":"code","87f5428d":"code","0923edc4":"code","8151812c":"code","696afa47":"code","e0895b4b":"code","83a28627":"code","7e903073":"code","daa00695":"code","9b7bdd56":"code","2375ae73":"code","b51ede8e":"code","0f234c4a":"code","c12d6806":"code","71380912":"code","9ad1924f":"code","25126eb7":"code","f89fe038":"code","c86799c7":"markdown","aa000917":"markdown","8f688064":"markdown","db0aaf49":"markdown","2f910086":"markdown","88069715":"markdown","5092f1cb":"markdown","f8136c59":"markdown","da7db3c1":"markdown","3f4e05b4":"markdown","80fd3496":"markdown","cc557020":"markdown","15b2d525":"markdown","d924cec7":"markdown","57ee93b1":"markdown","5294bd0c":"markdown","de763768":"markdown","65acc6e4":"markdown","1b0ef303":"markdown","611b9c27":"markdown","cdfd2bf5":"markdown","f7f66eea":"markdown","bc861c04":"markdown","00d27b59":"markdown","366c0006":"markdown","aabbe26d":"markdown"},"source":{"17285b67":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","b435e21e":"import warnings\nwarnings.filterwarnings('ignore')","6baaa0f0":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nIDtest = test[\"PassengerId\"]","a872ed6d":"# concat all data to analyze\ndataset = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\nlen(dataset)","d54ae563":"train_len = len(train)","51b1c9c3":"dataset.head()","34b012c6":"dataset.info()","fb393b20":"# null includes: Age, Cabin, Embarked\ndataset.isnull().sum()","00fba28b":"dataset.describe()","33a84fa3":"dataset[dataset['Survived'] == 1]","5ac921fc":"plt.figure(figsize=(12, 8))\nplt.title('Pearson correlation of Features')\nsns.heatmap(train.drop(labels=['PassengerId'], axis=1).corr(), cmap=plt.cm.RdBu, annot=True)","37070856":"import re\ndef get_title(name):\n    title_search = re.search(r'([A-Za-z]+)\\.', name)\n    if title_search:\n        return title_search.group(1)\n    \n    return ''\n\ndataset['Title'] = dataset['Name'].apply(get_title)","1b12df43":"dataset['Title'].value_counts()","6941634f":"#replacing all titles with mr, mrs, miss, master, rare\ndef replace_titles(title):\n    if title in ['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']:\n        return 'Rare'\n    elif title in ['Countess', 'Mme']:\n        return 'Mrs'\n    elif title in ['Mlle', 'Ms']:\n        return 'Miss'\n    elif title =='Dr':\n        if x['Sex']=='Male':\n            return 'Mr'\n        else:\n            return 'Mrs'\n    else:\n        return title\n\ndataset['Title'] = dataset['Title'].apply(replace_titles)","072af6f6":"dataset['Title'].value_counts()","b9971b20":"# Mapping titles\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\ndataset['Title'] = dataset['Title'].map(title_mapping)","95cabfc7":"sns.factorplot(x='Title', y='Survived', data=dataset, kind='bar')","8f8fbc9c":"dataset['HasCabin'] = dataset['Cabin'].apply(lambda x: 0 if type(x) == float else 1)","cddd90bc":"sns.factorplot(x='HasCabin', y='Survived', data=dataset, kind='bar')","b9dc1a8a":"dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1","cd8efcdf":"dataset['FamilySize'].value_counts()","22d900d0":"sns.factorplot(x='FamilySize', y='Survived', data=dataset)","b5e5bad0":"dataset['Embarked'].value_counts()","36157de0":"dataset['Embarked'].fillna('S', inplace=True)","e4136473":"sns.factorplot(x='Embarked', y='Survived', data=dataset, kind='bar')","c0408682":"dataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 1, \"female\": 0})","ae6e7140":"sns.factorplot(x='Sex', y='Survived', data=dataset, kind='bar')","2857ca3f":"plt.figure(figsize=(8, 6))\nplt.title('Pearson correlation of Age')\nsns.heatmap(dataset[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(), cmap=plt.cm.RdBu, annot=True)","24aa8679":"# Explore Age vs Survived\ng = sns.FacetGrid(train, col='Survived')\ng = g.map(sns.distplot, \"Age\")","bf17934c":"# Explore Age vs Parch , Pclass and SibSP\ng = sns.factorplot(y=\"Age\",x=\"Pclass\", data=dataset,kind=\"box\")\ng = sns.factorplot(y=\"Age\",x=\"Parch\", data=dataset,kind=\"box\")\ng = sns.factorplot(y=\"Age\",x=\"SibSp\", data=dataset,kind=\"box\")","c1bd7ec6":"# Filling missing value of Age \n\n## Fill Age with the median age of similar rows according to Pclass, Parch and SibSp\n# Index of NaN age rows\nindex_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\n\nage_med = dataset[\"Age\"].median()\nfor i in index_NaN_age :\n    age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) &\n                                (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) &\n                                (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred) :\n        dataset['Age'].iloc[i] = age_pred\n    else :\n        dataset['Age'].iloc[i] = age_med\n","5247510e":"dataset[:len(train)][['Age', 'Survived']].groupby(by=['Age']).sum()","c2a8f729":"dataset.head()","63ebd7b0":"dataset['NameParenthesis'] = dataset['Name'].apply(lambda x: 1 if re.search(r'\\(.*?\\)', x) else 0)","9406a9a0":"dataset[:train_len][['NameParenthesis', 'Survived']].groupby(by=['NameParenthesis']).sum()","6b061ffe":"dataset[:train_len]['NameParenthesis'].value_counts()","3a04675d":"sns.factorplot(x='NameParenthesis', y='Survived', data=dataset, kind='bar')","6bd690e5":"dataset['NameLength']= dataset['Name'].apply(len)","a1bf4bb5":"sns.factorplot(x='NameLength', y='Survived', data=dataset, kind='bar')","e69ea4c4":"dataset[:train_len][['NameLength', 'NameParenthesis', 'Survived']].groupby(by=['NameLength'], as_index=False).mean()","85daa566":"plt.figure(figsize=(12, 8))\nsns.heatmap(dataset.corr(), cmap=plt.cm.RdBu, annot=True)","a58cd7cb":"dataset.head(3)","1e74e8a3":"#dataset = dataset.drop(labels=['PassengerId', 'Name', 'Cabin', 'Parch', 'SibSp', 'Ticket'], axis=1)","56df25bb":"dataset = dataset.drop(['Cabin', 'Name', 'PassengerId', 'Ticket', ], axis=1)","9ea17d1c":"dataset.head()","ff8ea199":"# Mapping Fare\ndataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ndataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\ndataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\ndataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\ndataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\ndataset['Fare'] = dataset['Fare'].astype(int)\n\n# Mapping Age\ndataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\ndataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\ndataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\ndataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\ndataset.loc[ dataset['Age'] > 64, 'Age'] = 4\ndataset['Age'] = dataset['Age'].astype(int)\n\n# Mapping Embarked\ndataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})","62585df1":"# dataset['IsAlone'] = dataset['FamilySize'].map(lambda s: 1 if s == 1 else 0)","d69a27aa":"# sns.factorplot(x='IsAlone', y='Survived', data=dataset, kind='bar')","1121a575":"# Create new feature of family size\ndataset['Single'] = dataset['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ndataset['SmallFamily'] = dataset['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ndataset['MedFamily'] = dataset['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ndataset['LargeFamily'] = dataset['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","845ba932":"# one-hot values Title and Embarked \ndataset = pd.get_dummies(dataset, columns = [\"Title\"])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"])\ndataset = pd.get_dummies(dataset, columns = [\"Fare\"])\ndataset = pd.get_dummies(dataset, columns = [\"Age\"])","010c7280":"dataset.head()","f0be2591":"## Separate train dataset and test dataset\ntrain = dataset[:len(train)]\ntest = dataset[len(train):]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","a6fb6daf":"## Separate train features and label \ntrain[\"Survived\"] = train[\"Survived\"].astype(int)\nX_train = train.drop(labels = [\"Survived\"],axis = 1)\ny_train = train[\"Survived\"]","c413e435":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import (GradientBoostingClassifier, RandomForestClassifier, \\\n                              ExtraTreesClassifier,AdaBoostClassifier,\\\n                              BaggingClassifier, VotingClassifier)\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\nfrom pprint import pformat","d1ae830e":"random_state = 2","528253e2":"cv = StratifiedShuffleSplit(n_splits=10,)","37f3bdb3":"clf_list = [\n    GradientBoostingClassifier(),\n    RandomForestClassifier(),\n    ExtraTreesClassifier(),\n    AdaBoostClassifier(),\n    BaggingClassifier(),\n    DecisionTreeClassifier(),\n    SVC(),\n    KNeighborsClassifier(),\n    LogisticRegression(),\n    GaussianNB(),\n    LGBMClassifier(),\n    XGBClassifier(),\n]\n","f800d8b1":"accuracy_dict = {}\nfor clf in clf_list:\n    acc = cross_val_score(clf, X_train, y=y_train, cv=cv, scoring = \"accuracy\")    \n    accuracy_dict[clf.__class__.__name__] = [acc.min(), acc.mean(), acc.max()]","2345f6c1":"accuracy_df = pd.DataFrame(accuracy_dict).transpose()\naccuracy_df","c56179f3":"accuracy_df.plot(kind='bar',rot=60)","a9f3a248":"gbm = LGBMClassifier(num_leaves=20,\n                        learning_rate=0.5,\n                        n_estimators=100)\ngbm.fit(X_train, y_train,\n        eval_metric='l1')\nprint('Feature importances:', list(gbm.feature_importances_))","ecf934a3":"from sklearn.metrics import accuracy_score\npredictions = gbm.predict(X_train)\naccuracy_score(predictions, y_train)","fe4c9931":"from sklearn.model_selection import GridSearchCV, cross_validate, StratifiedKFold","1462002e":"cv = StratifiedKFold(n_splits=10)","f6168b34":"grid_seed = [2]","0d0d96dc":"# GradientBoostingClassifier\ngbc = GradientBoostingClassifier()\ngbc_params = {\n    'n_estimators': [100, 200, 300], #default=100\n    'learning_rate': [0.01, 0.03, 0.1, 0.3], #default=0.1\n    'random_state': grid_seed,\n    'max_depth': [4, 8],\n    'min_samples_leaf': [1, 3, 10],\n}\n\ngbc_search = GridSearchCV(gbc, param_grid=gbc_params, n_jobs=-1, cv=cv, verbose=1)\ngbc_search.fit(X_train, y_train)\ngbc_best = gbc_search.best_estimator_\nprint(gbc_search.best_params_)\ngbc_search.best_score_","81826590":"# RandomForestClassifier\nrf = RandomForestClassifier()\nrf_params = {\n    \"max_features\": [1, 3, 10],\n    \"min_samples_split\": [2, 3, 10],\n    \"min_samples_leaf\": [1, 3, 10],\n    \"bootstrap\": [False],\n    \"n_estimators\" :[100, 300],\n    \"criterion\": [\"gini\"],\n    'random_state': grid_seed,\n}\n\nrf_search = GridSearchCV(rf, param_grid=rf_params, n_jobs=-1, cv=cv, verbose=1)\nrf_search.fit(X_train, y_train)\nrf_best = rf_search.best_estimator_\nprint(rf_search.best_params_)\nrf_search.best_score_","67bc2150":"# BaggingClassifier\nbagging = BaggingClassifier()\nbagging_params = {\n    'n_estimators': [100, 300], \n    'max_samples': [0.1, 0.3],\n    'random_state': grid_seed,\n}\n\nbagging_search = GridSearchCV(bagging, param_grid=bagging_params, n_jobs=-1, cv=cv, verbose=1)\nbagging_search.fit(X_train, y_train)\nbagging_best = bagging_search.best_estimator_\nprint(bagging_search.best_params_)\nbagging_search.best_score_","5732873c":"# AdaBoostClassifier\nDTC = DecisionTreeClassifier()\nada = AdaBoostClassifier(DTC)\nada_params = {\n    \"base_estimator__criterion\": [\"gini\", \"entropy\"],\n    \"base_estimator__splitter\": [\"best\", \"random\"],\n    \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n    \"n_estimators\" :[100, 300],\n    \"learning_rate\":  [0.001, 0.003, 0.01, 0.03, 0.1],\n    'random_state': grid_seed,\n}\n\nada_search = GridSearchCV(ada, param_grid=ada_params, n_jobs=-1, cv=cv, verbose=1)\nada_search.fit(X_train, y_train)\nada_best = ada_search.best_estimator_\nprint(ada_search.best_params_)\nada_search.best_score_","87f5428d":"# ExtraTreesClassifier\next = ExtraTreesClassifier()\next_params = {\n    \"max_features\": [1, 3, 10],\n    \"min_samples_split\": [2, 3, 10],\n    \"min_samples_leaf\": [1, 3, 10],\n    \"bootstrap\": [False],\n    \"n_estimators\": [100, 300],\n    \"criterion\": [\"gini\"],\n    'random_state': grid_seed,\n}\n\next_search = GridSearchCV(ext, param_grid=ext_params, n_jobs=-1, cv=cv, verbose=1)\next_search.fit(X_train, y_train)\next_best = ext_search.best_estimator_\nprint(ext_search.best_params_)\next_search.best_score_","0923edc4":"# XGBClassifier\nxgb = XGBClassifier()\nxgb_params = {\n    'learning_rate': [0.01, 0.03, 0.1], \n    'max_depth': [1, 3, 4, 6], \n    'n_estimators': [100, 300], \n    'seed': grid_seed \n}\n\nxgb_search = GridSearchCV(xgb, param_grid=xgb_params, n_jobs=-1, cv=cv, verbose=1)\nxgb_search.fit(X_train, y_train)\nxgb_best = xgb_search.best_estimator_\nprint(xgb_search.best_params_)\nxgb_search.best_score_","8151812c":"# LGBMClassifier\nlgbm = LGBMClassifier()\nlgbm_params = {\n    'num_leaves': [10, 20, 30],\n    'learning_rate': [0.001, 0.01, 0.03, 0.1], \n    'max_depth': [1, 3, 6, 10], \n    'n_estimators': [100, 300], \n    'seed': grid_seed \n}\n\nlgbm_search = GridSearchCV(lgbm, param_grid=lgbm_params, n_jobs=-1, cv=cv, verbose=1)\nlgbm_search.fit(X_train, y_train)\nlgbm_best = lgbm_search.best_estimator_\nprint(lgbm_search.best_params_)\nlgbm_search.best_score_","696afa47":"# KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn_params = {\n    'n_neighbors': [1,2,3,4,5,6,7], #default: 5\n    'weights': ['uniform', 'distance'], #default = \u2018uniform\u2019\n    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n}\n\nknn_search = GridSearchCV(knn, param_grid=knn_params, n_jobs=-1, cv=cv, verbose=1)\nknn_search.fit(X_train, y_train)\nknn_best = knn_search.best_estimator_\nprint(knn_search.best_params_)\nknn_search.best_score_","e0895b4b":"### SVC\nsvc = SVC(probability=True)\nsvc_params = {'kernel': ['rbf'], \n              'gamma': [ 0.001, 0.01, 0.1, 1],\n              'C': [1, 10, 50, 100, 200, 300, 1000]}\n\nsvc_search = GridSearchCV(svc, param_grid=svc_params, cv=cv, scoring=\"accuracy\", n_jobs=-1, verbose=1)\nsvc_search.fit(X_train,y_train)\n\nsvc_best = svc_search.best_estimator_\nprint(svc_search.best_params_)\nsvc_search.best_score_","83a28627":"ensemble_clfs = {\n    'gbc': gbc_best,\n    'rf': rf_best,\n    'ada': ada_best,\n    'bag': bagging_best,\n    'ext': ext_best,\n    'xgb': xgb_best,\n    'lgbm': lgbm_best,\n    'svc': svc_best,\n    'knn': knn_best,\n}","7e903073":"pred_dict = {}\nfor clf in ensemble_clfs.values():\n    pred_dict[clf.__class__.__name__] = clf.predict(test)\n","daa00695":"sns.heatmap(pd.DataFrame(pred_dict).corr(),annot=True)","9b7bdd56":"voting_soft = VotingClassifier(estimators=ensemble_clfs.items(), voting='soft', n_jobs=-1)","2375ae73":"voting_soft.fit(X_train, y_train)\naccuracy_score(voting_soft.predict(X_train), y_train)","b51ede8e":"# voting_hard = VotingClassifier(estimators=ensemble_clfs.items(), voting='hard', n_jobs=-1)","0f234c4a":"# voting_hard.fit(X_train, y_train)\n# accuracy_score(voting_hard.predict(X_train), y_train)","c12d6806":"# lgbm = LGBMClassifier(num_leaves=20, learning_rate=0.01, n_estimators=300, max_depth=6)\n# print(cross_val_score(lgbm, X_train, y_train, cv=cv))\n# # print(cross_validate(lgbm, X_train, y_train, cv=cv))\n","71380912":"#lgbm.fit(X_train, y_train)","9ad1924f":"# xgbt = XGBClassifier(learning_rate=0.03, max_depth=3, n_estimators=300)\n# cross_val_score(xgbt, X_train, y_train, cv=cv)","25126eb7":"#xgbt.fit(X_train, y_train)","f89fe038":"test_Survived = pd.Series(voting_soft.predict(test), name=\"Survived\")\n\nresults = pd.concat([IDtest, test_Survived],axis=1)\n\nresults.to_csv(\"titanic_with_ensemble.csv\",index=False)","c86799c7":"### Seperate data back to train test","aa000917":"### Remove Features\n- Use `Title` instead of `Name`\n- Use `HasCabin` instead of `Cabin`\n- Categorize `FamilySize` instead of `Parch` `SibSp`\n- `PassengerId` is random variable\n- `Ticket` might be a random variable","8f688064":"#### Title\nClassify to Mr. Miss. Mrs. Master Rare","db0aaf49":"### Load data","2f910086":"### Feature Correlation","88069715":"### GridSearchCV \nfind best parameters","5092f1cb":"got 177 passengers with `age_pred` according to this startegy, amazing!","f8136c59":"### Basic Feature Engineering with the Titanic Data\nrefer to\uff1a[Feature Engineering](https:\/\/triangleinequality.wordpress.com\/2013\/09\/08\/basic-feature-engineering-with-the-titanic-data\/)","da7db3c1":"Variable |\tDefinition |Key\n--| -- | --\nsurvival| \tSurvival|\t0 = No, 1 = Yes\npclass\t|Ticket class|\t1 = 1st, 2 = 2nd, 3 = 3rd\nsex\t|Sex|\t\nAge\t|Age in years\t|\nsibsp\t|# of siblings \/ spouses aboard the Titanic\t|\nparch\t|# of parents \/ children aboard the Titanic\t|\nticket\t|Ticket number\t|\nfare\t|Passenger fare\t|\ncabin\t|Cabin number\t|\nembarked|\tPort of Embarkation|","3f4e05b4":"Theres is a peek for young passengers who are survived\n\nPassengers with age between 60-80 were less survived","80fd3496":"survival probability is highly related to survival probability\n\ncreate 4 categories for `FamilySize`\n- 1\n- 2\n- 3,4\n- \\>=5","cc557020":"Age is more related to: Pclass, SibSp, Parch, FamilySize, IsAlone ","15b2d525":"### Models","d924cec7":"### Name","57ee93b1":"#### Family Size\nsibsp: The dataset defines family relations in this way...\n- Sibling = brother, sister, stepbrother, stepsister\n- Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\n- Parent = mother, father\n- Child = daughter, son, stepdaughter, stepson","5294bd0c":"### Feature Importance","de763768":"### Vote","65acc6e4":"refer to: https:\/\/www.kaggle.com\/yassineghouzam\/titanic-top-4-with-ensemble-modeling\n        \nAge is negatively correlated with Pclass, Parch and SibSp.\n\nUse SibSP, Parch and Pclass in order to impute the missing ages.\nThe strategy is to fill Age with the median age of similar rows according to Pclass, Parch and SibSp.","1b0ef303":"### Fill Null Values","611b9c27":"#### Embark\n2 null values","cdfd2bf5":"### Inspect data","f7f66eea":"#### Cabin\nonly 1st class tickets have cabins\n\nfind that 1st class tickets has much higher survival proberblity","bc861c04":"Survived passengers Age: \n\n1st Class > 2nd Class > 3rd Class\n\nolder if have more Parents\/childre and siblings\/spouses","00d27b59":"### Submit","366c0006":"#### Age\n263 null values in train set","aabbe26d":"#### Sex\nConvert to categorical value"}}