{"cell_type":{"5b8461a0":"code","de661a6a":"code","31d885c8":"code","bd322c83":"code","55e5241b":"code","b09023e8":"code","bcdc07be":"code","32ad10cd":"code","e285f369":"code","dc972689":"code","a4463ddb":"code","68391ff0":"code","907bd222":"code","79bdad9b":"code","9819d4e3":"code","7befb60b":"code","d0c93214":"code","7a58c897":"code","763bda08":"code","86789fa6":"code","3e0c52a7":"code","a58a3275":"code","e972e758":"code","332cbb0b":"code","72fed6e1":"code","2715a58c":"code","80a5a813":"code","11ea7291":"code","897dc04e":"markdown","6c66a8e3":"markdown","7a12bcfd":"markdown","6f43201e":"markdown","e51062f2":"markdown","4755be84":"markdown","b43e98c5":"markdown","087385c6":"markdown","5c375d29":"markdown","008a0647":"markdown"},"source":{"5b8461a0":"import os\nimport PIL\nimport torch\nimport torchvision\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as tt\nimport torchvision.models as models\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import random_split\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid\n%matplotlib inline","de661a6a":"train_data = \"..\/input\/gemstones-images\/train\"","31d885c8":"tsf_ds = tt.Compose([\n    tt.Resize((128, 128)),\n    tt.RandomHorizontalFlip(),\n    tt.VerticalRandomFlip(),\n    #tt.RandomCrop(32, padding=4, padding_mode=\"reflect\"),\n    tt.ToTensor()\n])\n\nds = torchvision.datasets.ImageFolder(root=\"..\/input\/gemstones-images\/train\", transform=tsf_ds)","bd322c83":"images, labels = ds[8]\nprint(images.size())\nplt.imshow(images.permute(1,2,0))\nprint(labels)","55e5241b":"val_ds_size = int(len(ds) * 0.2)\ntrain_ds_size = len(ds) - val_ds_size\ntrain_ds, val_ds = random_split(ds, [train_ds_size, val_ds_size])\nlen(train_ds), len(val_ds)","b09023e8":"batch_size = 128\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=3, pin_memory=True)","bcdc07be":"def show_batch(train_dl):\n    for images, labels in train_dl:\n        fig, ax = plt.subplots(figsize=(16,16))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[:64], nrow=8).permute(1,2,0))\n        break","32ad10cd":"show_batch(train_dl)","e285f369":"def accuracy(out, labels):\n    _, preds = torch.max(out, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n        return {\"val_loss\": loss.detach(), \"val_acc\": acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_loss = [x[\"val_loss\"] for x in outputs]\n        epoch_loss = torch.stack(batch_loss).mean()\n        batch_acc = [x[\"val_acc\"] for x in outputs]\n        epoch_acc = torch.stack(batch_acc).mean()\n        return {\"val_loss\": epoch_loss.item(), \"val_acc\": epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr {:.6f}, train_loss {:.4f}, val_loss {:.4f}, val_acc {:.4f}\".format(\n            epoch, result[\"lrs\"][-1], result[\"train_loss\"], result[\"val_loss\"], result[\"val_acc\"]))\n        ","dc972689":"alexnet = models.alexnet()\nalexnet","a4463ddb":"class Gemsalexnet(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = models.alexnet(pretrained=True)\n        number_of_features = self.network.classifier[6].in_features\n        self.network.classifier[6] = nn.Linear(number_of_features, 87)\n        \n    def forward(self, xb):\n        return self.network(xb)\n    \n    def freeze(self):\n        for param in self.network.parameters():\n            param.require_grad = False\n        for param in self.network.classifier[6].parameters():\n            param.require_grad = True\n            \n    def unfreeze(self):\n        for param in self.network.parameters():\n            param.require_grad = True","68391ff0":"def conv_block(in_channels, out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=1),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU()]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n\nclass ResNet9(ImageClassificationBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        self.conv1 = conv_block(in_channels, 64) #128, 64, 128, 128\n        self.conv2 = conv_block(64, 128, pool=True) #128, 128, 64, 64\n        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n        \n        self.conv3 = conv_block(128, 256, pool=True) #128, 256, 32, 32\n        self.conv4 = conv_block(256, 512, pool=True) #128, 512, 16, 16\n        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512)) #128, 512, 16, 16\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(16), nn.Flatten(), nn.Linear(512, num_classes))\n        \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.conv2(out)\n        out = self.res1(out) + out\n        out = self.conv3(out)\n        out = self.conv4(out)\n        out = self.res2(out) + out\n        out = self.classifier(out)\n        return out\n    \nmodel = ResNet9(in_channels=3, num_classes=31)\nmodel","907bd222":"def get_device():\n    if torch.cuda.is_available():\n        return torch.device(\"cuda\")\n    else:\n        return torch.device(\"cpu\")\n    \ndef to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        for x in self.dl:\n            yield to_device(x, self.device)\n            \n    def __len__(self):\n        return len(self.dl)\n    \ndevice = get_device()\ndevice","79bdad9b":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)","9819d4e3":"@torch.no_grad()\ndef evaluate(model, val_dl):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_dl]\n    return model.validation_epoch_end(outputs)\n    \ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group[\"lr\"]\n    \ndef fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, weight_decay=None, \n                  grad_clip=0, opt_func=torch.optim.Adam):\n    \n    history = []\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n                                               steps_per_epoch=len(train_dl))\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss = []\n        lrs = []\n        for batch in tqdm(train_dl):\n            loss = model.training_step(batch)\n            train_loss.append(loss)\n            loss.backward()\n            \n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n        result = evaluate(model, val_dl)\n        result[\"train_loss\"] = torch.stack(train_loss).mean().item()\n        result[\"lrs\"] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","7befb60b":"model = to_device(Gemsalexnet(), device)","d0c93214":"history = [evaluate(model, val_dl)]\nhistory","7a58c897":"model.freeze()","763bda08":"epochs = 10\nmax_lr = 10e-5\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","86789fa6":"%%time\n\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,\n                        grad_clip=grad_clip, weight_decay=weight_decay,\n                        opt_func=opt_func)","3e0c52a7":"model.unfreeze()","a58a3275":"epochs = 10\nmax_lr = 0.0005\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","e972e758":"%%time\n\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,\n                        grad_clip=grad_clip, weight_decay=weight_decay,\n                        opt_func=opt_func)","332cbb0b":"def plot_losses(history):\n    val_loss = [x[\"val_loss\"] for x in history]\n    train_loss = [x.get(\"train_loss\") for x in history]\n    plt.plot(val_loss, \"-rx\")\n    plt.plot(train_loss, \"-bx\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Losses\")\n    plt.legend([\"Validation loss\", \"Train loss\"])\n    plt.title(\"Loss vs number of epochs\")\n    \nplot_losses(history)","72fed6e1":"def plot_accuracy(history):\n    accuracy = [x[\"val_acc\"] for x in history]\n    plt.plot(accuracy, \"-x\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(\"Accuracy vs number of epochs\")\n    \nplot_accuracy(history)","2715a58c":"def prediction(images, model):\n    xb = to_device(images.unsqueeze(0), device)\n    out = model(xb)\n    _,preds = torch.max(out, dim=1)\n    prediction = ds.classes[preds[0].item()]\n    return prediction","80a5a813":"test_ds = torchvision.datasets.ImageFolder(\nroot = \"..\/input\/gemstones-images\/test\", transform=tt.ToTensor())","11ea7291":"images, labels = test_ds[2]\nprint(\"Label:\", test_ds.classes[labels])\nprint(\"Prediction:\", prediction(images, model))\nplt.imshow(images.permute(1,2,0))","897dc04e":"## Moving the model to the GPU","6c66a8e3":"## Training","7a12bcfd":"Do not forget to move the model to the GPU","6f43201e":"## Predictions","e51062f2":"## Importing the modules","4755be84":"## Defining the model","b43e98c5":"# Gemstones classification","087385c6":"## Model Performance","5c375d29":"Foremost let's freeze all the layaers but the last one, thus warming it up","008a0647":"## Transforming and uploading the data"}}