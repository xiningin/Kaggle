{"cell_type":{"8a790263":"code","4cb24f49":"code","9434f074":"code","75304ee3":"code","867d7712":"code","d4fc178f":"code","1576d503":"code","2ea5e3c3":"code","2f9336ef":"code","506f2ed2":"code","578cfacc":"code","9d68ecb9":"code","d7539dd5":"code","427fff6d":"code","494c1b9c":"code","f42b7ab2":"code","d54ea530":"code","a128c91a":"code","c128807a":"code","409bbda5":"code","718f4f99":"code","ea035261":"code","5640d95a":"code","ced94b48":"code","f2181fbd":"markdown","9accaab7":"markdown","61d20015":"markdown","227f86db":"markdown","e1728a2e":"markdown","cd88afc8":"markdown","aec52b49":"markdown"},"source":{"8a790263":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4cb24f49":"import matplotlib.pyplot as plt\nfrom keras import preprocessing\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,Dropout,Dense,Flatten,Conv2DTranspose,BatchNormalization,LeakyReLU,Reshape\nimport tensorflow as tf","9434f074":"train_data = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ntrain_data.head()","75304ee3":"X_train = train_data.drop('label',axis=1)\nX_train.head()","867d7712":"X_train=X_train.values\nprint(X_train.shape)","d4fc178f":"X_train=X_train.reshape(-1,28,28,1)\nprint(X_train.shape)","1576d503":"fig,axe=plt.subplots(2,5)\nidx = 0\nfor i in range(2):\n    for j in range(5):\n        axe[i,j].imshow(X_train[idx].reshape(28,28),cmap='gray')\n        idx+=1","2ea5e3c3":"X_train =  X_train.astype('float32')","2f9336ef":"X_train = X_train\/255\nX_train = X_train*2 - 1.    # normalization 1 ile 1 aras\u0131na \u00e7evirdik.","506f2ed2":"print(X_train.max(),X_train.min())\n","578cfacc":"generator = Sequential()\ngenerator.add(Dense(512,input_shape=[100]))\ngenerator.add(LeakyReLU(alpha=0.2))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Dense(256))\ngenerator.add(LeakyReLU(alpha=0.2))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Dense(128))\ngenerator.add(LeakyReLU(alpha=0.2))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Dense(784))\ngenerator.add(Reshape([28,28,1]))","9d68ecb9":"generator.summary()","d7539dd5":"discriminator = Sequential()\ndiscriminator.add(Dense(1,input_shape=[28,28,1]))\ndiscriminator.add(Flatten())\ndiscriminator.add(Dense(256))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.5))\ndiscriminator.add(Dense(128))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.5))\ndiscriminator.add(Dense(64))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.5))\ndiscriminator.add(Dense(1,activation='sigmoid'))","427fff6d":"discriminator.summary()\n","494c1b9c":"GAN =Sequential([generator,discriminator])\ndiscriminator.compile(optimizer='adam',loss='binary_crossentropy')\ndiscriminator.trainable = False","f42b7ab2":"GAN.compile(optimizer='adam',loss='binary_crossentropy')\n","d54ea530":"GAN.layers","a128c91a":"GAN.summary()","c128807a":"epochs = 30\nbatch_size = 100\nnoise_shape=100","409bbda5":"for epoch in range(epochs):\n    for __ in range(X_train.shape[0]\/\/batch_size):\n    \n        noise=np.random.normal(size = [batch_size,noise_shape]) \n        gen_image = generator.predict_on_batch(noise)\n        train_dataset = X_train[i*batch_size:(i+1)*batch_size]\n        \n        #training discriminator on real images\n        train_label=np.ones(shape=(batch_size,1))\n        discriminator.trainable = True\n        d_loss_real=discriminator.train_on_batch(train_dataset,train_label)\n        \n        #training discriminator on fake images\n        train_label=np.zeros(shape=(batch_size,1))\n        d_loss_fake=discriminator.train_on_batch(gen_image,train_label)\n        \n        \n        #training generator \n        noise=np.random.normal(size=[batch_size,noise_shape])\n        train_label=np.ones(shape=(batch_size,1))\n        discriminator.trainable = False #while training the generator as combined model,discriminator training should be turned off\n        \n        d_g_loss_batch =GAN.train_on_batch(noise, train_label)\n        \n    print(\"epoch: \",epoch)\n\n","718f4f99":"noise=np.random.normal(size=[10,noise_shape])\n\ngen_image = generator.predict(noise)","ea035261":"plt.imshow(noise)\nplt.title('How the noise looks')","5640d95a":"fig,axe=plt.subplots(2,5)\nfig.suptitle(\"Actual Images\")\nidx = 0\nfor i in range(2):\n    for j in range(5):\n        axe[i,j].imshow(X_train[idx].reshape(28,28),cmap='gray')\n        idx+=10","ced94b48":"fig,axe=plt.subplots(2,5)\nfig.suptitle('Generated Images from Noise using GANs')\nidx=0\nfor i in range(2):\n     for j in range(5):\n         axe[i,j].imshow(gen_image[idx].reshape(28,28),cmap='gray')\n         idx+=1","f2181fbd":"<font color='red'>\n<br>Content:\n    \n* [Introduction](#1)\n    * [What are GANs ?](#2)\n* [Generative Adversarial Networks](#3)\n    * [Loading Dataset](#4)\n    * [Generative Part](#5)\n    * [Discriminatory Part](#6)\n    * [Create GANs Model](#7)\n    * [Visualization](#8)\n    ","9accaab7":"<a id=\"7\"><\/a> <br>\n## Create GANs Model","61d20015":"<a id=\"1\"><\/a> <br>\n## Introduction\n<a id=\"2\"><\/a> <br>\n## What are GANs ?\n\nGenerative Adversarial Networks, or GANs for short, are an approach to generative modeling using deep learning methods, such as convolutional neural networks.\n\nGenerative modeling is an unsupervised learning task in machine learning that involves automatically discovering and learning the regularities or patterns in input data in such a way that the model can be used to generate or output new examples that plausibly could have been drawn from the original dataset.\n\nGANs are a clever way of training a generative model by framing the problem as a supervised learning problem with two sub-models: the generator model that we train to generate new examples, and the discriminator model that tries to classify examples as either real (from the domain) or fake (generated). The two models are trained together in a zero-sum game, adversarial, until the discriminator model is fooled about half the time, meaning the generator model is generating plausible examples.\n\nGANs are an exciting and rapidly changing field, delivering on the promise of generative models in their ability to generate realistic examples across a range of problem domains, most notably in image-to-image translation tasks such as translating photos of summer to winter or day to night, and in generating photorealistic photos of objects, scenes, and people that even humans cannot tell are fake.\n\nIn this post, you will discover a gentle introduction to Generative Adversarial Networks, or GANs.\n\nAfter reading this post, you will know:\n- Context for GANs, including supervised vs. unsupervised learning and discriminative vs. generative modeling.\n- GANs are an architecture for automatically training a generative model by treating the unsupervised problem as supervised and using both a generative and a discriminative model.\n- GANs provide a path to sophisticated domain-specific data augmentation and a solution to problems that require a generative solution, such as image-to-image translation.","227f86db":"<a id=\"3\"><\/a> <br>\n## Generative Adversarial Networks\n<a id=\"4\"><\/a> <br>\n## Loading Dataset","e1728a2e":"<a id=\"6\"><\/a> <br>\n## Discriminatory Part","cd88afc8":"<a id=\"8\"><\/a> <br>\n## Visualization","aec52b49":"<a id=\"5\"><\/a> <br>\n## Generative Part"}}