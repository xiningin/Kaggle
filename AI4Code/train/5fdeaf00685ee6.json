{"cell_type":{"3999d084":"code","0e7218f6":"code","f9a54667":"code","4116d96b":"code","9fa3c105":"code","1df7ba76":"code","6f8866e3":"code","7a8e10ab":"code","3c989a89":"code","a1555f50":"code","6d7f10d4":"code","564249b0":"code","f882cb95":"code","354890e5":"code","5a74fbc3":"code","872db2b8":"code","35b71b15":"code","bf8538ac":"code","641105cf":"code","fe65d248":"code","27a6e2ce":"code","3e54c297":"code","abf16275":"markdown","294f6282":"markdown","2cf32e38":"markdown","8c04c9da":"markdown","6f3b5709":"markdown","4eb8cc84":"markdown","08085421":"markdown","3461f4df":"markdown","81831a82":"markdown","de6164f0":"markdown","831b7cfc":"markdown","b401b5a8":"markdown","1824f030":"markdown","99bd889f":"markdown","6d241cf5":"markdown","e3001366":"markdown","c976ef0a":"markdown","26649209":"markdown","69cdd904":"markdown","bb6ad3ec":"markdown","5bce9d98":"markdown","a3d485b7":"markdown"},"source":{"3999d084":"from minimization_toolkit import *\n%matplotlib inline","0e7218f6":"f_ = x**2 + y**2\nf = sp.lambdify((x,y),f_)\n\nsurface(*field(f,-1,1,100),darkgraph(),ax3D())","f9a54667":"# random search\ndef rs(f, n, Bx, By, index=None, cm=np.inf):\n    if index is None:\n        index = range(n)\n    S = np.array(range(n))\n    X = np.array([rand(*Bx) for _ in S])\n    Y = np.array([rand(*By) for _ in S])\n    Z = f(X, Y)\n    M = []\n    for s in S:\n        if Z[s] < cm:\n            cm = Z[s]\n        M.append(cm)\n    return pd.DataFrame({\n        'x': X, 'y': Y, 'z': Z,\n        'm': M, 'Search': ['Random'] * n }, index=index)","4116d96b":"# zooming random search\ndef zrs(f, n, Bx, By, zooms, Pf=0.8):\n    N = [n \/\/ zooms] * zooms\n    N[-1] += n % zooms\n    SS = []\n    elapsed = 0\n    cm = np.inf\n    for i in range(zooms):\n        S = rs(f, N[i], Bx, By, index=range(elapsed, elapsed+N[i]), cm=cm)\n        A = np.abs(Bx[1]-Bx[0]) * np.abs(By[1]-By[0])\n        D = np.sqrt(-A * np.log(1-Pf) \/ n \/ np.pi)\n        X, Y, M = np.array(S['x']), np.array(S['y']), np.array(S['m'])\n        cx, cy, cm = X[-1], Y[-1], M[-1]\n        for j in range(N[i])[:0:-1]:\n            if not M[j] == M[j-1]:\n                cx = X[j]\n                cy = Y[j]\n                cm = M[j]\n                break\n        Bx = (cx-D,cx+D)\n        By = (cy-D,cy+D)\n        SS.append(S)\n        elapsed += N[i]\n    SS = pd.concat(SS, ignore_index=False)\n    SS['Search'] = ['Zooming Random'] * n\n    return SS","9fa3c105":"n=200 ; B=(-1,1) ; z=10 ; Pf=0.8\n\ntranslucent(*field(f,-1,1,100), darkgraph(), ax3D(), alpha=0.2)\nplt.plot(*zdescend(*unbox(rs(f,n,B,B),'x','y','z')),color='red',linewidth=2)\nplt.plot(*zdescend(*unbox(zrs(f,n,B,B,z,Pf),'x','y','z')),color='blue',linewidth=2);","1df7ba76":"N=300 ; n=100 ; B=(-1,1) ; z=2; Pf=0.8\n\n(compare(singles(rs, f, n, B, B),\n    singles(zrs, f, n, B, B, z, Pf)) +\np9.scales.scale_color_manual(unbox(COLORS,'blue','orange'))\n).draw();\n\n(comparesd(meanssd(rs, N, f, n, B, B),\n    meanssd(zrs, N, f, n, B, B, z, Pf))+\np9.scales.scale_color_manual(unbox(COLORS,'blue','orange'))+\np9.scales.ylim(-0.02,0.5)).draw();","6f8866e3":"h_ = 5*x**2 + y**2\nh = sp.lambdify((x,y), h_)\nsurface(*field(h,-1,1,100), darkgraph(), ax3D())","7a8e10ab":"g = sp.lambdify([x,y], \n    np.array([sp.diff(h_, x),sp.diff(h_, y)]))\n\ngradplot(field(h,-1,1,100),field(g,-1,1,10),\n        darkgraph(), ax2D())\nsp.vector.gradient(h_)","3c989a89":"# fixed gradient descend search\ndef fgds(f, g, n, D, Bx, By, cm=np.inf):\n    p = [rand(*Bx),rand(*Bx)]\n    X,Y,Z,G,M = [],[],[],[],[]\n    for _ in range(n):\n        p = p - (g(*p) \/ np.linalg.norm(g(*p))) * D\n        X.append(p[0])\n        Y.append(p[1])\n        z = f(*p)\n        Z.append(z)\n        G.append(g(*p))\n        if z<cm: cm=z\n        M.append(cm)\n    return pd.DataFrame({\n        'x':X,'y':Y,'z':Z,'g':G,'m':M,\n        'Search':['Fixed Gradient Descend']*n\n    })","a1555f50":"D=0.1 ; n=30 ; B=(-1,1)\n\nbfield = field(h,-1,1,100)\ngfield = field(g,-1,1,10)\npath = unbox(fgds(h,g,n,D,B,B),'x','y','z')\n\ntravelplot3D(bfield,path,darkgraph(),ax3D())\ntravelplotgrad(bfield,gfield,path[:-1],darkgraph(),ax2D())","6d7f10d4":"# dinamic gradient descend search\ndef dgds(f, g, n, D0, Bx, By, cm=np.inf):\n    p = [rand(*Bx),rand(*Bx)]\n    X,Y,Z,G,M = [],[],[],[],[]\n    for s in range(n):\n        Ds = D0 *  (1 - s\/n)\n        p = p - (g(*p) \/ np.linalg.norm(g(*p))) * Ds\n        X.append(p[0])\n        Y.append(p[1])\n        z = f(*p)\n        Z.append(z)\n        G.append(g(*p))\n        if z<cm: cm=z\n        M.append(cm)\n    return pd.DataFrame({\n        'x':X,'y':Y,'z':Z,'g':G,'m':M,\n        'Search':['Dinamic Gradient Descend']*n})","564249b0":"D=0.1 ; n=30 ; B=(-1,1)\n\nbfield = field(h,-1,1,100)\ngfield = field(g,-1,1,10)\npath = unbox(dgds(h,g,n,D,B,B),'x','y','z')\n\ntravelplot3D(bfield,path,darkgraph(),ax3D())\ntravelplotgrad(bfield,gfield,path[:-1],darkgraph(),ax2D())","f882cb95":"N=200 ; n=30 ; B=(-1,1) ; D = 0.1\n(comparesd(\n    meanssd(rs, N, h, n, B, B),\n    meanssd(zrs, N, h, n, B, B, zooms=2, Pf=0.8),\n    meanssd(fgds, N, h, g, n, D, B, B),\n    meanssd(dgds, N, h, g, n, D, B, B),\n    res=3) +\np9.scales.scale_color_manual(unbox(COLORS,'red','green','blue','orange')) +\np9.scales.ylim(-0.1,1.3)).draw();\n\n(comparesd(\n    meanssd(fgds, N, h, g, n, D, B, B),\n    meanssd(dgds, N, h, g, n, D, B, B),\n    res=8) +\n p9.scales.scale_color_manual(unbox(COLORS,'red','green')) +\n p9.scales.ylim(-0.02,0.041) +\n p9.scales.xlim(12.5,30)).draw();","354890e5":"psi_ = -sp.exp(-((x-1)**2+(y-1)**2)\/0.3**2)-1.5*sp.exp(-16*((x-2)**2+(y-2)**2))\npsi  = sp.lambdify((x,y),psi_)\ntranslucent(*field(psi,-1,5,300), darkgraph(), ax3D())","5a74fbc3":"gpsi = sp.lambdify([x,y], np.array([sp.diff(psi_, x),sp.diff(psi_, y)]))\nsp.vector.gradient(psi_)","872db2b8":"# simulated annealing search\ndef sas(f, g, n, D0, Bx, By, T0, cm=np.inf, d=3):\n    T = np.linspace(T0, 0, n)[::-1]\n    d = np.array([(rand(-d,d),rand(-d,d)) for _ in T])\n    p = [rand(*Bx),rand(*Bx)]\n    X, Y, Z, G, M = [], [], [], [], []\n    for s in range(n):\n        Ds = D0 *  (1 - s\/n)\n        grad = g(*p) + d[s]\n        p1 = p - ((grad \/ np.linalg.norm(grad)) * Ds)\n        f0 = f(*p)\n        f1 = f(*p1)\n        if f1 < f0 or rand(0,1) > np.exp((f0-f1)*T[s]) :\n            p = p1\n        X.append(p[0]); Y.append(p[1])\n        z = f(*p)\n        Z.append(z); G.append(g(*p))\n        if z < cm:\n            cm = z\n        M.append(cm)\n    return pd.DataFrame({\n        'x':X,'y':Y,'z':Z,'g':G,'m':M,\n        'Search':['Simulated Anealing']*n\n    })","35b71b15":"D0=0.6 ; n=150 ; B=(-1,5) ; T0=1000\n\ntranslucent(*field(psi,-1,5,500), darkgraph(), ax3D(), alpha=0.2)\nfor color in ['red','green','blue', 'yellow']:\n    plt.plot(*unbox(sas(psi,gpsi,n,D0,B,B,T0),'x','y','z'),\n            color=color,linewidth=2)","bf8538ac":"N=100 ; n=150 ; B=(-1,5) ; D=0.6\nz=2 ; Pf=0.8 ; T0=100\n\n(compare(\n    means(zrs,N,psi,n,B,B,z,Pf),\n    means(fgds,N,psi,gpsi,n,D,B,B),\n    means(dgds,N,psi,gpsi,n,D,B,B),\n    means(sas,N,psi,gpsi,n,D,B,B,T0)) +\np9.scales.scale_color_manual(unbox(COLORS,'green','orange','red','blue'))\n).draw();","641105cf":"N=100 ; n=150 ; B=(-1,5) ; D=0.6\nz=4 ; Pf=0.8 ; T0=100\n\n(comparesd(\n    meanssd(dgds,N,psi,gpsi,n,D,B,B), \n    meanssd(sas,N,psi,gpsi,n,D,B,B,T0))+\n p9.scales.scale_color_manual(unbox(COLORS,'green','red'))\n).draw();","fe65d248":"N=100 ; n=2000 ; B=(-1,5) ; D=0.6\nz=2 ; Pf=0.8 ; T0=100 ; d=3\n\ndfzrs = meanssd(zrs,N,psi,n,B,B,z,Pf)\ndfdgds = meanssd(dgds,N,psi,gpsi,n,D,B,B)\ndfsas = meanssd(sas,N,psi,gpsi,n,D,B,B,T0,d)","27a6e2ce":"(comparesd(dfsas,dfdgds, dfzrs, res=4) +\np9.scales.scale_color_manual(unbox(COLORS,'green','red','orange'))).draw();","3e54c297":"N=50 ; n=10**4 ; B=(-1,5)\nz=2 ; Pf=0.8\n\n(comparesd(\n    meanssd(rs,N,psi,n,B,B),\n    meanssd(zrs,N,psi,n,B,B,z,Pf))  +\np9.scales.scale_color_manual(unbox(COLORS,'blue','orange'))+\np9.scales.ylim(-1.6,-1)).draw();","abf16275":"Now, we can visualize a search done with this method:","294f6282":"## Simulated Annealing\n\nA much more challenging quest aproaches! This is our next scalar field:\n\n$$ \\psi_{(x,y)} = -e^{\\frac{(x-1)^2+(y-1)^2}{0.09}} - \\frac{3}{2} e^{-16\\left[(x-2)^2+(y-2)^2\\right]} $$","2cf32e38":"# Minimization (with python)\n\nBased on Costa Didatic Text #18 ([CDT-18](https:\/\/www.researchgate.net\/publication\/338115440_Down_the_Road_to_Minimization_CDT-18)).\n\n\nThe [Dark Reader](http:\/\/https:\/\/darkreader.org\/) browser extension is sugested for reading this notebook. I passed the heftier parts of the code, except the minimization algorithms, to [this](https:\/\/www.kaggle.com\/jaorcovre\/minimization-toolkit) utility script. This was made as the 2nd project for my Mathematic-Computational Modeling classes here at [IFSC](https:\/\/www2.ifsc.usp.br\/), for my Computational Physics major.","8c04c9da":"We can see here how it starts oscilating back and forth close to the bottom, and never gets to the center. One could argue that the descend could be better made if every step was not only in the oposite direction as the gradient, but multiplied by the norm of the gradient. In this particular case, they would be correct, but this is far from a universal rule.\n\nTo get a more consistant redution of step length, we can do it independently of the gradient. My version of this function is a little bit diferent from the one in the [source](https:\/\/www.researchgate.net\/publication\/338115440_Down_the_Road_to_Minimization_CDT-18). It does a linear decay, and managed do yeld great results. Defining $s$ as the current step, $n$ as the total number of steps and $D_0$ as the starting step length:\n\n$$D_{(s)} = D_0 \\left(1 - \\frac{s}{n}\\right)$$","6f3b5709":"In this case, it's dificult to see a diference. Latter, we will see a case where the zooming random does much better. For now, let's see another method:","4eb8cc84":"I won't be showing the gradient quiver plot for this one, since it's very extreme and my plotting abilities arent suficient for that yet.\n\nSo lets proceed to the new method! We are using the same concept as the tempering of steel on the workshop of a medieval swordsman for getting a better chance at not being trapped at that pesky local minimum (the smaller hole). Being more precise, it's most similar to normalizing, or anealing.\n\nWhen tempering, a lot of disturbancy in the form of heat is added, the particles assume random positions. Then, the metal is quickly cooled down, freezing the particles at that high energy state, making the metal much less bendable, but better for cutting or making pans. But the normalization process cools down the steel slowly, so that the particles can vibrate gradualy into nicely low energy states for a more flexible structure.\n\nJust like the temperature, we will add disturbancy to our gradient field and decrease it slowly. Also, we will keep decreasing the step lengths gradually as we did before.\n\nAlso, as explained in the [source material](https:\/\/www.researchgate.net\/publication\/338115440_Down_the_Road_to_Minimization_CDT-18), we have a method to decide if we will take the next step or not. The probability of taking a step is given by:\n\n$$\nP_{\\psi^{(i)} \\rightarrow \\psi^{(i+1)}} = \\begin{cases} \n1, & \\Longleftrightarrow \\psi^{(i+1)} < \\psi^{(i)} \\\\ \ne^{\\frac{-\\left(\\psi^{(i+1)}-\\psi^{(i)}\\right)}{T}}, & \\Longleftrightarrow \\psi^{(i+1)} \\geq \\psi^{(i)}\n\\end{cases}\n$$\n\nWhere $i$ is the step, $P$ is the probability of taking that step, and $T$ is the \"temperature\" that controls the probability of taking an upwards step.\n","08085421":"Above we can see how the path takes progressively smaller steps closer to the midle. Now, we compare the means of all the previous methods, 500 samples of each type of search, on the field $h_{(x,y)}$. Each search starts at a random point $(x,y)$ where $-1 \\leq x \\leq 1$ and $-1 \\leq y \\leq 1$ and performs 30 search steps. Most of the parameters are the same for all the methods:","3461f4df":"You can see above our robot chickens will sometimes jump from one hole to the other. Then, as the temperature decreases, they are less likely to jump up, an their steps are shorter. Some converge at the smaller hole, some at the deeper one. Still, not exactly enough to tell how much better this approach is. Now, let's see how it compares to the other ones on the $\\psi$ field using the same parameters. Using mostly the same rules from the last comparison, but starting on random points where $-1 \\leq x \\leq 5$ and $-1 \\leq y \\leq 5$.","81831a82":"## Gradient Descend\n\nNow we take a different aproach. Imagine I am a blind chicken walking around this field. It may be very unconfortable to stand still in one of the steep walls, so I might try to walk down to the bottom. But remember, I'm a ***blind*** chicken. So I don't see the bottom. But, I can feel with my feet that the ground is raising to my left, so I take a step in the oposite direction. I still feel unconfortable, the ground is still crooked below your feet, so I take another step down, and so on. This is mostly the idea of gradient descend.\n\nWe could use the idea of a ball rolling downhill, but the ball can roll, we can only take ***discrete steps***.\n\nBut how do we know this slope mathematicaly? The ***gradient field***! We can use calculus to find, for every pair $(x, y)$ a [vector](https:\/\/en.wikipedia.org\/wiki\/Euclidean_vector) that tells us in what direction this field is sloped, and how much it is sloped.\n\nFor our example, we will use the field $h$:\n\n$$h_{(x,y)}=5x^2+y^2$$","de6164f0":"Lets start finding $\\nabla \\psi_{(x, y)}$, the gradient of our new field $\\psi_{(x, y)}$:","831b7cfc":"There are more interesting methods to look at, but that's it for today. Please leave a comment if you have a sugestion for better parameters or algorithms. Have a nice day, and thanks for reading!","b401b5a8":"Let us try some searches! To ilustrate what is happening next: we will send a little army of robot blind chickens to try an find the deepest hole they can find and fall into it. In the beginning, they will have a lot of energy, so they may jump up out of a hole and fall into another. Then, they will get progressively more tired, and will not be as likely jump, so they will probably just fall down where they are or walk around a bit more before stopping. Let's see how they do.","1824f030":"Considering their standard deviation, the annealing simulation and the gradient descend are pratically equivalent. But then, if we perform much more steps (and loose our \"tempereture\" way slowlier) we can get even better results, as it would be a better simulation of actual annealing and not tempering. It is much more hardware expensive, takes much longer to do, and would be best done in a high performance language like C++ or Julia.","99bd889f":"Lets pretend we don't know that the bottom of this field is exactly $f_{(0,0)} = 0$ and let's try some search methods to find it. First we can try to randomly select a bunch of points in the field and just get the smallest one. Also, while we look through the points, every time we find a smaller value we save it to see how low we can get over time.\n\nWe will call $n$ the number of random points to be searched and $B$ the boundaries of x and y. We will define a function that we can reuse latter. We can also do this search zooming gradually in the area, so that we don't waste too much steps in the search, more about that in the [source material](https:\/\/www.researchgate.net\/publication\/338115440_Down_the_Road_to_Minimization_CDT-18).","6d241cf5":"\nLet us take a look at $\\nabla h_{(x,y)}$, or the gradient of the field $h_{(x,y)}$.\n\n$$\\vec{g}_{(x,y)} = \\nabla h_{(x,y)} = \\frac{\\partial h}{\\partial x}\\hat{i}+\\frac{\\partial h}{\\partial y}\\hat{j}$$\n\nWe use $\\vec{g}_{(x,y)}$ because we can easily write the letter **g** in python, $\\nabla h_{(x,y)}$ is not very code friendly.","e3001366":"Now we may choose a random point $P_0=(x_0,y_0)$ and use the gradient to guide our path. First we define a fixed $D$ length for every step and an also fixed $n$ number of search steps. Again, we define boundaries $B_x$ and $B_y$. $f$ and $g$ in the following function represent a scalar field function and it's gradient.","c976ef0a":"Slowly cooling down, the annealing simulation is able to explore both holes . Not having that much temperature to jump up, it tends to converge to the global minima, as shown by the error bars. With more steps and a more gradual cooldown, we could make this result even better, at the cost of more processing power and time.\n\nThe zooming random searches perform quite well too, having so many points to use. The dinamic descend approaches the target, but many times gets stuck at the local minima. The annealer is the only one able to converge to the true minima in the end. Now, we can revisit the random methods, we may be able to adjust the parameters to make the zooming search perform a little better, but really, it is such an inexpensive method that it works best to just pump up the number of points until it's nearly impossible to miss the minima.","26649209":"Looks like our simulated anealing is already beating the performance of the other descenders, and the fixed descend is not very good at this particular problem. Let us look at them closely.","69cdd904":"Already better than the random methods. But we will take a look at a case were the gradient information doesn't help as much, and a method that has that in mind.","bb6ad3ec":"## Random Search\n\nLet us take a look at a very simple scalar field, a *paraboloid*. It has a $z$ value for every pair $(x, y)$, and it is ***continuous***. This, along with other characteristics (like the fact that we already know lowest point), makes it super easy to search for the bottom. So, it may be a good example to start with.\n\n$$f_{(x,y)}=x^2+y^2$$","5bce9d98":"In the plot above, we see an example of the usual random search in red and a zooming random search in blue. They start at random points and move towards the minimum, but its hard to access the difference.\n\nTo get a grasp of this method's eficiency, let's execute this search many times and get a mean of the minimums found over time. We will call $N$ the number of searches executed.","a3d485b7":"If you are familiar whith the world of statistics, or maybe artificial inteligence, you probably are also familiar with ***minimization***. But I didn't, until a couple of weaks ago. So, if you are like my recent past self, let me give you a very breaf explanation.\n\nFor exemple, we may have a program that tries to solve a particular problem, and it might not know for sure how to do it. Maybe, it receives some input to decide how to proceed. Changing this input also changes this program's ability to solve that problem.\n\nNow we can try to find the best input to give this program so that its problem solving abilities are maximized, and it's ***error*** is ***minimized***. How do we do that?\n\nLet's say, for a more specific example, that this program receives 2 numbers as input, $x$ and $y$. For every pair $(x, y)$, it tries to solve that problem a little bit differently, and it not always works too well. If we can measure how far our program is from the ideal solution, we may call this diference $z$.\n\nThen, we can imagine our inputs and error as a surface, that for every coordinate $(x, y)$ has a height $z$, that represents our error. If we want to find the best inputs, we want to find the pair $(x, y)$ that gives the lowest value of $z$, or the deepest point in that surface.\n\nIf we don't know this surface very well, it might not be easy to find the deepest point. In this notebook we will run through some strategies to figure that out, this is minimization."}}