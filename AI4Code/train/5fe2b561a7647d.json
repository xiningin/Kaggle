{"cell_type":{"691455b9":"code","e44d59a7":"code","0c9c46e0":"code","e4f0b7dd":"code","12870b34":"code","08edcce9":"code","dc656f23":"code","01856dd6":"code","5efb89cf":"code","171c0fbd":"code","7ee0fe6b":"code","6d9cf4a3":"code","dcd44d79":"code","426bb359":"code","f5182929":"code","e738f5a0":"code","9158066d":"code","e6d180a6":"code","e00c01cd":"code","a56a0a63":"markdown","b9af1990":"markdown"},"source":{"691455b9":"\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats as st\nimport math \nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","e44d59a7":"data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","0c9c46e0":"data.head()","e4f0b7dd":"data.info()","12870b34":"data_test.head()","08edcce9":"data_test.info()","dc656f23":"data[['name','status']] = pd.DataFrame(data.Name.str.split(', ',1).tolist(),columns = ['name','status'])\ndata[['status','surname']] = pd.DataFrame(data.status.str.split('. ',1).tolist(),columns = ['status','surname'])\ndata.loc[data['status'] == 'th', 'status'] = 'Countess'\ndata['Age'] = data['Age'].fillna(data.groupby(data['status'])['Age'].transform('median'))\ndata = data.drop(['Cabin'], axis = 1)\ndata = data[data.Embarked.notnull()]\ndata.info()","01856dd6":"data_test[['name','status']] = pd.DataFrame(data_test.Name.str.split(', ',1).tolist(),columns = ['name','status'])\ndata_test[['status','surname']] = pd.DataFrame(data_test.status.str.split('. ',1).tolist(),columns = ['status','surname'])\n\ndata_test['Age'] = data_test['Age'].fillna(data_test.groupby(data_test['status'])['Age'].transform('median'))\ndata_test = data_test.drop(['Cabin'], axis = 1)\n\ndata_test['Age'] = data_test['Age'].fillna(data.groupby(data['status'])['Age'].transform('median'))\ndata_test['Fare'] = data_test['Fare'].fillna(data.groupby(data['status'])['Fare'].transform('median'))\n\ndata_test.info()","5efb89cf":"sns.pairplot(data[['Fare',  'Age', 'Survived']], hue = 'Survived', plot_kws = {'alpha' : .2}, palette = 'seismic_r')\nplt.show","171c0fbd":"mask = np.triu(np.ones_like(data.corr(), dtype=np.bool)) \nheatmap = sns.heatmap(data.corr(), annot = True, mask=mask, cmap=\"YlGnBu\",vmin=-1, vmax=1)\nheatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':18}, pad=16)","7ee0fe6b":"data = data.drop(['PassengerId', 'Name', 'Ticket', 'name', 'surname'], axis = 1)\ndata_ohe = pd.get_dummies(data, drop_first=True)\n\ndata_id_test = data_test['PassengerId']","6d9cf4a3":"data_test = data_test.drop(['PassengerId', 'Name', 'Ticket', 'name', 'surname'], axis = 1)\ndata_test_ohe = pd.get_dummies(data_test, drop_first=True)\n\ndata_test_ohe = data_test_ohe.rename(columns={'status_Dona': 'status_Don'})\ndata_test_ohe[['status_Col','status_Countess' , 'status_Jonkheer', 'status_Lady', 'status_Major', 'status_Mlle', 'status_Mme','status_Ms', 'status_Sir' ]] = 0\n\n\ndata_test_ohe.info()","dcd44d79":"pd.DataFrame(data_id_test)","426bb359":"data_ohe.info()","f5182929":"data_features = data_ohe.drop(['Survived'], axis = 1)\ndata_target = data_ohe['Survived']\n\nfeatures_train, features_valid, target_train, target_valid = train_test_split(\n        data_features, data_target, test_size=0.25, random_state=12345) \n\nnumeric = ['Fare', 'SibSp', 'Age', 'Parch']\nscaler = StandardScaler()\nfeatures_train[numeric] = scaler.fit_transform(features_train[numeric]) \nfeatures_valid[numeric] = scaler.fit_transform(features_valid[numeric]) \ndata_test_ohe[numeric] = scaler.fit_transform(data_test_ohe[numeric]) \n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(features_train.shape, target_train.shape)\nprint(features_valid.shape, target_valid.shape)\nprint(data_test_ohe.shape)\n\nwarnings.filterwarnings('ignore')","e738f5a0":"scores = []\ndef search(model, parametrs, model_name):\n    search = RandomizedSearchCV(model, parametrs, cv=5)\n    search.fit(features_train, target_train)\n    predicted_valid = search.predict(features_valid)\n    print(model_name, search.best_params_)\n    scores.append(pd.Series({\n        'Estimator' : model_name, \n        'best_parameter': search.best_params_, \n        'best_score': search.best_score_\n    }))\n    return search.best_params_\n    warnings.filterwarnings('ignore')\n\ndecision_param = search(DecisionTreeClassifier(random_state = 12345),{'max_depth': range (1,13, 1),'criterion': ['gini', 'entropy']} , 'DecisionTreeClassifier')\n\nparam_random = search(RandomForestClassifier(random_state = 12345),{  \n              'n_estimators': range (1, 51, 5),\n              'max_depth': range (1,13, 2),\n              'min_samples_leaf': range (1,8),\n              'min_samples_split': range (2,10,2),\n              'criterion': ['gini', 'entropy'] ,\n              'max_features': ['auto', 'sqrt', 'log2']} , 'RandomForestClassifier')\n\nparam_XGBClassifier = search(XGBClassifier(random_state = 12345), { 'eval_metric' : ['mlogloss'],\n    'max_depth': range (1,13, 1),\n    'n_estimators': range(1, 400, 20)}, 'XGBClassifier')\nwarnings.filterwarnings('ignore')\n\nparam_kn = search(KNeighborsClassifier(), {\n    'n_neighbors': range (1,20, 1), 'weights': ['distance', 'uniform']\n    }, 'KNeighborsClassifier')\n\nsearch(AdaBoostClassifier(base_estimator = DecisionTreeClassifier(random_state = 12345)),{\n    'base_estimator__criterion' : [\"gini\", \"entropy\"],\n    \"base_estimator__splitter\" :   [\"best\", \"random\"],\n    }, 'AdaBoostClassifier' )","9158066d":"results = pd.concat(scores, axis=1).T.set_index('Estimator')   \nresults","e6d180a6":"def roc(model, model_name):\n  model.fit(features_train, target_train)\n  probabilities_valid = model.predict_proba(features_valid)\n  probabilities_one_valid = probabilities_valid[:, 1]\n  print(model_name)\n  print('auc_roc: ', roc_auc_score(target_valid, probabilities_one_valid).round(4))\n  fpr, tpr, thresholds = roc_curve(target_valid,probabilities_one_valid)\n  \n  plt.figure()\n  plt.plot([0, 1], [0, 1], linestyle = '--')\n  plt.plot(fpr, tpr)\n  plt.xlim([0,1]) \n  plt.ylim([0,1])\n  plt.xlabel('False Positive Rate')\n  plt.ylabel('True Positive Rate')\n  plt.title('ROC')\n  plt.show()\n\nroc(RandomForestClassifier( **param_random, random_state = 12345), 'RandomForestClassifier')\n\nroc(XGBClassifier(**param_XGBClassifier, random_state = 12345), 'XGBClassifier')\n\nroc(KNeighborsClassifier(**param_kn), 'KNeighborsClassifier')\n\nroc(DecisionTreeClassifier(**decision_param, random_state = 12345), 'DecisionTreeClassifier')","e00c01cd":"model = RandomForestClassifier( **param_random, random_state = 12345)\nmodel.fit(features_train, target_train)\n\npredicts = model.predict(data_test_ohe)\n\noutput = pd.DataFrame({'PassengerId': data_id_test, 'Survived': predicts})\n\noutput.to_csv('my_submission_titanik.csv', index=False)\nprint(output)\nprint(\"Your submission was successfully saved!\")","a56a0a63":"# 2. ML","b9af1990":"# 1. Exploring the data"}}