{"cell_type":{"fc9c569f":"code","1c6c5c63":"code","249529f4":"code","847aa215":"code","d575185b":"code","9341cef9":"code","f7f2476c":"code","8f5aa712":"code","8c996aee":"code","0ebf998b":"code","2d5450c7":"code","1ea51c61":"code","2f1ec9b3":"code","95866116":"code","243d8aed":"code","1237c810":"code","7eda5756":"code","eb33d0f4":"code","a0a82cac":"code","b1adf09c":"code","56b2d6db":"code","dfce307b":"code","ee4c1815":"code","9c35aae8":"code","44e8b3a6":"code","92ac436e":"code","eff802f3":"code","de6a747b":"code","e1e956d8":"code","c1ea8e75":"code","c6be893c":"code","e8ca5703":"code","04c8bc8e":"code","1b086de2":"code","e357ae11":"code","3f9ed9f7":"code","62012f6c":"code","1e2e82d8":"code","473fbbf9":"code","e56f518c":"code","c8f99606":"code","2a541740":"code","e13ae342":"code","39fc3ec9":"code","988e1247":"markdown","4d1cf6a3":"markdown","ccb0dc5d":"markdown","e9e07f4a":"markdown","81ff69bd":"markdown","2eb5bcf0":"markdown","8cb77230":"markdown","150ec2ed":"markdown","34b3d0a0":"markdown","f64367c7":"markdown","8a0e109b":"markdown","5649a82e":"markdown","13ffc1c9":"markdown","e010a6c7":"markdown","3704d0bb":"markdown","3e681a88":"markdown"},"source":{"fc9c569f":"import sklearn \nimport pandas as pd \nimport matplotlib as plt\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')","1c6c5c63":"df=pd.read_excel(\"..\/input\/german credit dataset.xls\",header=0)","249529f4":"df.head()","847aa215":"print(df.shape)\ndf.dtypes","d575185b":"\ndata=df.as_matrix()","9341cef9":"X = data[:,0:20] #la matrice des variables explicatives\nY = data[:,20] #la variable a predire","f7f2476c":"from sklearn import model_selection #\n\nX_app,X_test,y_app,y_test=model_selection.train_test_split(X,Y,test_size = 300,random_state=0)","8f5aa712":"print(X_app.shape, X_test.shape, y_app.shape, y_test.shape)","8c996aee":"from sklearn.linear_model import LogisticRegression","0ebf998b":"LR=LogisticRegression()","2d5450c7":"modele_LR=LR.fit(X_app,y_app) #ex\u00e9cution de l'instance sur les donn\u00e9es d'apprentissage\n                       #c.\u00e0 d . construction du mod\u00e8le pr\u00e9dictif","1ea51c61":"print(modele_LR.coef_)","2f1ec9b3":"print(modele_LR.intercept_)","95866116":"y_pred=modele_LR.predict(X_test) #Prediction sur l'echantillon test\n","243d8aed":"#importation de metrics utilis\u00e9 pour les mesures de performances\nfrom sklearn import metrics","1237c810":"#matrice de confusion\n#confrontation entre Y obs. sur l\u2019\u00e9ch . test et la pr\u00e9diction\ncm =metrics.confusion_matrix(y_test, y_pred)\n\ncf = pd.DataFrame(cm, columns=['pr\u00e9dit ' + \"0\", 'predit'+\"1\"])\ncf.index = ['vrai ' + \"0\",'vrai'+\"1\"]\ncf","7eda5756":"acc= metrics.accuracy_score(y_test,y_pred)\nprint(acc )","eb33d0f4":"err= 1.0 - acc\nprint(err)","a0a82cac":"se=metrics.recall_score(y_test,y_pred)\nprint(se)","b1adf09c":"def specificity(y,y_hat):\n    \n    #matrice de confusion un objet numpy .ndarray\n    mc = metrics.confusion_matrix(y,y_hat)\n    #\u2019\u2019non solvable est sur l'indice 0\n    import numpy\n    res = mc [0,0]\/numpy.sum(mc[0,:])\n    #retour\n    return res\n#","56b2d6db":"specificite = metrics.make_scorer(specificity,greater_is_better=True)","dfce307b":"sp = specificite(modele_LR,X_test,y_test)\nprint(sp)","ee4c1815":"probas=LR.predict_proba(X_test) #calcul des probas d'affectation sur ech . test\nprint(probas)\n## Probas d'affectation aux classe \"Non solvable\" ~ 0 \"Solvable\" ~ 1","9c35aae8":"#score de presence\n\nscore = probas[:,1]\nprint(score)\n","44e8b3a6":"pos = pd.get_dummies(y_test).as_matrix()","92ac436e":"print(pos)","eff802f3":"pos=pos[:,1]","de6a747b":"print(pos)","e1e956d8":"import numpy as np\nnpos=np.sum(pos)","c1ea8e75":"print(npos) # il y a 214 indiv solvable dans l'echantillon test","c6be893c":"# indexe pour tri de slection \nindex = np.argsort (score)\nprint(index)","e8ca5703":"index=index[::-1]","04c8bc8e":"# tri des individus\nsort_pos=pos[index]\nsort_pos","1b086de2":"#somme cumul\u00e9 \ncpos=np.cumsum(sort_pos)\nprint(cpos)","e357ae11":"# Rappel\nrappel=cpos\/npos\nrappel","3f9ed9f7":"#nombre d observation dans l echantillon test\nn=y_test.shape[0]\nn","62012f6c":"taille = np.arange(start =1,stop=301,step =1)","1e2e82d8":"#passer en proportion\ntaille = taille \/ n","473fbbf9":"#titre et en t\u00eates\nplt.title ('Courbe de gain (lift cumul\u00e9)')\nplt.xlabel ('Taille de cible')\nplt.ylabel ('Rappel')\n#limites en abscisse et ordonn\u00e9e\nplt.xlim (0,1)\nplt.ylim (0,1)\n#astuce pour tracer la diagonale\nplt.scatter(taille,taille,marker='.', color= 'blue')\n#insertion du couple (taille, rappel)\nplt.scatter(taille,rappel,marker='.', color='red')\n#affichage\nplt.show","e56f518c":"from sklearn.metrics import roc_auc_score, roc_curve, auc\n\nfpr0, tpr0, thresholds0 = roc_curve(y_test, probas[:, 0], pos_label=modele_LR.classes_[0], drop_intermediate=False)\nfpr0.shape","c8f99606":"dftp = pd.DataFrame(dict(fpr=fpr0, tpr=tpr0, threshold=thresholds0)).copy()\ndftp.head(n=2)","2a541740":"ax = dftp.plot(x=\"threshold\", y=['fpr', 'tpr'], figsize=(10, 10))\nax.set_title(\"Evolution de FPR, TPR\\nen fonction du seuil au del\u00e0 duquel\\n\" +\n             \"la r\u00e9ponse du classifieur est valid\u00e9e\");","e13ae342":"fig, ax = plt.subplots(1, 1, figsize=(10,9))\nax.plot([0, 1], [0, 1], 'k--')\naucf = roc_auc_score(y_test == modele_LR.classes_[0], probas[:, 0]) # premi\u00e8re fa\u00e7on\n#aucf = auc(fpr0, tpr0)  # seconde fa\u00e7on\nax.plot(fpr0, tpr0, label=str(modele_LR.classes_[0] ) + '  ||| auc=%1.5f' % aucf)\nax.set_title('Courbe ROC - classifieur Solvabilit\u00e9 des client de Deutsh-Bank')\nax.text(0.5, 0.1, \"plus mauvais que\\nle hasard dans\\ncette zone\")\nax.legend();","39fc3ec9":"aucf","988e1247":"# taux de succ\u00e8s","4d1cf6a3":"### 0.26 = 1- 0.74","ccb0dc5d":"## Matrice de confusion \n                                Ligne : observ\u00e9\n                                Colonne : pr\u00e9diction","e9e07f4a":"![Capture.PNG](attachment:Capture.PNG)\n## 0.8504= 182\/(182+32)","81ff69bd":"## Classe d'appartenance \"Non solvable\" \"Solvable\"","2eb5bcf0":"#### on ne recupere que la deuxieme colonne (indice 1)","8cb77230":"# Specificit\u00e9","150ec2ed":"````\n### l'individus 202 a le score le plus faible suivi par l'individu 10 etc... l'individu 246 a le score le plus elev\u00e9 ","34b3d0a0":"# sensibilit\u00e9 (ou rappel)","f64367c7":"### la rendre utilisable transformation en objet scorer","8a0e109b":"fpr d\u00e9signe le False Positive Rate autrement dit le taux de faux positive, si la t\u00e2che est d\u00e9terminer si un individu est solvable i.e 1, le taux d\u00e9signe la proportion des individus non solvables class\u00e9s par le classifieur parmi les individus solvable. C\u2019est l\u2019erreur de classification. tpr d\u00e9signe le nombre de True Positive Rate. C\u2019est\u2026 A vrai dire, cette d\u00e9nomination est toujours aussi absconce pour moi. Je leur pr\u00e9f\u00e8re les formules math\u00e9matiques. On souhaite toujours classer les individus solvable. True et False ne sont pas vrai ou faux mais le nom de deux classes.\n\n\\begin{array}{rcl}FPR(s) &=& \\sum_{i=1}^n \\mathbf{1\\!\\!1}_{score(X_i) \\geqslant s}\\mathbf{1\\!\\!1}_{y_i == 0}\\\\ TPR(s) &=& \\sum_{i=1}^n \\mathbf{1\\!\\!1}_{score(X_i) \\geqslant s}\\mathbf{1\\!\\!1}_{y_i == 1}\\end{array}","5649a82e":"# ****taux d'erreur****","13ffc1c9":"### 0.74 = (182+40)\/(182+32+46+40)","e010a6c7":"``\n## utilisation de l\u2019objet scorer\n## remarque : modele est le mod\u00e8le \u00e9labor\u00e9 sur l\u2019 \u00e9ch . d\u2019apprentissage\n``","3704d0bb":"### taille de cible s\u00e9quence de valeurs de 1 \u00e0 300 avec un pas de 1","3e681a88":"###### inverser pour score decroissant -- on s\u2019int\u00e9resse \u00e0 forte proba . en priorit\u00e9"}}