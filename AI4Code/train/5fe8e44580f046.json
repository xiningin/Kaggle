{"cell_type":{"d8ff9f9e":"code","debf1e00":"code","00c9342b":"code","874a1de9":"code","e2af10f7":"code","332d7dfd":"code","5acb7325":"code","e073facb":"code","47dc5d6a":"code","5eb2e7fc":"code","55fd7c73":"code","11cbd9ed":"code","c44662b8":"code","619f69c4":"code","ad4142c9":"code","da8f25a9":"code","98df0ea6":"code","d39d9262":"code","278508d6":"code","768b1763":"markdown","896539e4":"markdown","6dc8ce38":"markdown","d63a3890":"markdown","05e59462":"markdown","0ee3354e":"markdown","68624a04":"markdown","fca70a57":"markdown","db21007e":"markdown","58bbe5da":"markdown","76544930":"markdown","9bf52c2d":"markdown","03ba067d":"markdown","e6bd14cf":"markdown","962e4d94":"markdown","e4a389ab":"markdown","d87d77c4":"markdown","e223e896":"markdown"},"source":{"d8ff9f9e":"import numpy as np \nimport pandas as pd \nimport os\nimport lightgbm as lgb\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","debf1e00":"df = pd.read_csv(\"..\/input\/credit-card-transactions\/credit_card_transactions-ibm_v2.csv\",nrows=19999999)\ndf.head()","00c9342b":"df['Zip'] = df['Zip'].fillna(0)\ndf['Amount'] = df['Amount'].apply(lambda value: float(value.split(\"$\")[1]))\ndf['Hour'] = df['Time'].apply(lambda value: int(value.split(\":\")[0]))\ndf['Minutes'] = df['Time'].apply(lambda value: int(value.split(\":\")[1]))\ndf.drop(['Time'], axis=1, inplace=True)\ndf['Merchant Name'] = df['Merchant Name'].astype(\"object\")\ndf['Card'] = df['Card'].astype(\"object\")\ndf['Use Chip'] = df['Use Chip'].astype(\"object\")\ndf['MCC'] = df['MCC'].astype(\"object\")\ndf['Zip'] = df['Zip'].astype(\"object\")","874a1de9":"for col in df.columns:\n    col_type = df[col].dtype\n    if col_type == 'object':\n        df[col] = df[col].fillna(\"\")\n        ","e2af10f7":"#Label: Binary: 0\/1\ny = df['Is Fraud?']","332d7dfd":"#Features\nX = df.drop(['Is Fraud?'],axis=1)","5acb7325":"categorical_column_names = []\ncategorical_cols = []\nfor idx,col in enumerate(X.columns):\n    col_type = X[col].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        categorical_column_names.append(col)\n        categorical_cols.append(idx)","e073facb":"categorical_column_names.append(\"Zip\")\ncategorical_column_names.append(\"MCC\")\ncategorical_column_names.append(\"Card\")\ncategorical_column_names.append(\"Merchant Name\")\n","47dc5d6a":"categorical_names = {}\nfor feature in categorical_column_names:\n    le = sklearn.preprocessing.LabelEncoder()\n    le.fit(X.loc[:, feature])\n    X.loc[:, feature] = le.transform(X.loc[:, feature])\n    categorical_names[feature] = le.classes_\n","5eb2e7fc":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0, stratify=y)","55fd7c73":"model = lgb.LGBMClassifier()\nmodel.fit(X_train, y_train, feature_name='auto', categorical_feature = categorical_column_names, verbose=50)","11cbd9ed":"y_pred=model.predict(X_test)","c44662b8":"print(classification_report(y_test, y_pred))","619f69c4":"from lightgbm import plot_importance\nplot_importance(model)","ad4142c9":"#Import the library\nimport lime.lime_tabular","da8f25a9":"predict_fn = lambda x: model.predict_proba(x)","98df0ea6":"explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values ,feature_names = list(X_train.columns), class_names=['No','Yes'],\n                                                   categorical_features=categorical_cols, \n                                                   categorical_names=categorical_column_names, kernel_width=3)","d39d9262":"exp = explainer.explain_instance(X_test.values[1], predict_fn)\nexp.show_in_notebook()","278508d6":"y_test.values[1]","768b1763":"The explain instance shows the contribution of the features for the input example","896539e4":"### Training a LightGBM Classifier","6dc8ce38":"## Explainabilty for Credit Card Fraud Detection","d63a3890":"To ensure things run smoothly on kaggle, lets subset the data and load one less than 20 million rows in a dataframe","05e59462":"### Data Understanding and Feature Engineering","0ee3354e":"LIME takes in the prediction function as it creates perturbed examples in the vicinity of a given input.","68624a04":"Even though LightGBM can convert categorical variables into appropriate representations conducive to training, LIME requires categorical data to be encoded in one hot encoded\/label encoded form. Since LightGBM is a tree based method label encoding will not add to an artifical ranking and a viable and less data exppanding technique","fca70a57":"The LIME explainer:\n\n1. Creates samples similar to the seed instance \n2. Generates predictions for these samples using the predict_fn\n3. Use a distance measure to weight the samples with respect to the seed instance\n4. Train a local interpretable model using these samples and explain the result based on the model","db21007e":"### LightGBM Model Importance\n\nThe LightGBM model importance plot shows the count by which a feature was used for a split in all weak learners. From the feature importance figure we can see that LightGBM can probably identify users which are likely to cause fraudulent transactions along with numeric columns like Amount, Time of the day and so on","58bbe5da":"### Creating Training and Test Sets\n\nTrain and test sets are created with the stratification option to maintain the proportion of fraudulent to successful true transactions in both train and test.","76544930":"From the data sneak peak, I change the data-types to match the data description and do fill missing values since that is necessary for the explainability component.","9bf52c2d":"The true class is similar to the predicted class","03ba067d":"This notebook shows the use of a machine learning model explainability library called LIME to explain credit card fraud detection.\n> This notebook goes through all of the steps leading to building a classfier for fraud prediction. Then shows an overview of how to use LIME(Locally Interpretable Model-Agnostic Explanations) to understand why a transaction was deemed fraudulent or not by the LightGBM Classifier. \n\n![explain](https:\/\/media.giphy.com\/media\/WhTC5v5qQP4yAUvGKz\/giphy.gif)","e6bd14cf":"## LIME (Locally Interpretable Model-Agnostic Explanations)\n\nThis framework tries to explain individual results of different classifiers\/regressors by approximating it with a locally interpretable model. LIME assumes that within the vicinity of an example an interpretable model like a linear classifier can approximate any black box model. ","962e4d94":"### Looking at the Classification Report\n\nThe dataset is imbalanced and LightGBM performs better than random predictions and can be further tuned to enhance performance.","e4a389ab":"Identifying the categorical column names which will be needed as a parameter when training a LightGBM model","d87d77c4":"### Loading Required Libraries","e223e896":"Separating out the label and the features from the dataset"}}