{"cell_type":{"e209df5c":"code","4e7908f5":"code","c44bb006":"code","9f0d3114":"code","43bedbf5":"code","e9bd2b99":"code","cef6f37b":"code","d19047ac":"code","82b4988e":"code","66669b4b":"code","a07e6688":"code","08f750f5":"code","986c8fa2":"code","ce3acb77":"code","bda2f8b0":"code","45b6b1e7":"code","68bfd6a0":"markdown","85bfbfa2":"markdown","865819f9":"markdown","9cd2e129":"markdown","9cbff3f1":"markdown","e956305a":"markdown","db252770":"markdown","4131a9b0":"markdown","5321d559":"markdown","f8de7617":"markdown","1e6d4264":"markdown","3e055c86":"markdown","f6307caa":"markdown","33433e80":"markdown","1efe99d8":"markdown","366f180a":"markdown","0c17186f":"markdown","17febcd4":"markdown","8533ae6e":"markdown","216c55af":"markdown","038df439":"markdown","783157bd":"markdown","597dd7d5":"markdown","f1b9c291":"markdown"},"source":{"e209df5c":"import tensorflow as tf\nprint(tf.__version__)","4e7908f5":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.models import Model","c44bb006":"cifar10 = tf.keras.datasets.cifar10\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n#Split them into train & test\nx_train, x_test = x_train \/ 255.0, x_test \/ 255.0\ny_train, y_test = y_train.flatten(), y_test.flatten()","9f0d3114":"print(\"x_train.shape:\", x_train.shape)\nprint(\"y_train.shape\", y_train.shape)","43bedbf5":"# number of classes\nK = len(set(y_train))\nprint(\"number of classes:\", K)","e9bd2b99":"i = Input(shape=x_train[0].shape)\n\nx = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\nx = BatchNormalization()(x)\nx = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\n\nx = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\n\nx = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\n\nx = Flatten()(x)\nx = Dropout(0.2)(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.2)(x)\nx = Dense(K, activation='softmax')(x)\n\nmodel = Model(i, x)","cef6f37b":"# Note: make sure you are using the GPU for this.\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","d19047ac":"r = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50)","82b4988e":"batch_size = 32\ndata_generator = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\ntrain_generator = data_generator.flow(x_train, y_train, batch_size)\nsteps_per_epoch = x_train.shape[0] \/\/ batch_size\nr = model.fit_generator(train_generator, validation_data=(x_test, y_test), steps_per_epoch=steps_per_epoch, epochs=50)","66669b4b":"# Plot loss per iteration\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [10,5]\nplt.plot(r.history['loss'], label='loss')\nplt.plot(r.history['val_loss'], label='val_loss')\nplt.legend()","a07e6688":"# Plot accuracy per iteration\nplt.plot(r.history['accuracy'], label='acc')\nplt.plot(r.history['val_accuracy'], label='val_acc')\nplt.legend()","08f750f5":"# Plot confusion matrix\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nplt.rcParams['figure.figsize'] = [10,7]\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n\n  if normalize:\n      cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n      print(\"Normalized confusion matrix\")\n  else:\n      print('Confusion matrix, without normalization')\n\n  print(cm)\n\n  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n  plt.title(title)\n  plt.colorbar()\n  tick_marks = np.arange(len(classes))\n  plt.xticks(tick_marks, classes, rotation=45)\n  plt.yticks(tick_marks, classes)\n\n  fmt = '.2f' if normalize else 'd'\n  thresh = cm.max() \/ 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n      plt.text(j, i, format(cm[i, j], fmt),\n               horizontalalignment=\"center\",\n               color=\"white\" if cm[i, j] > thresh else \"black\")\n\n  plt.tight_layout()\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\n  plt.show()\n\n\np_test = model.predict(x_test).argmax(axis=1)\ncm = confusion_matrix(y_test, p_test)\nplot_confusion_matrix(cm, list(range(10)))","986c8fa2":"labels = '''airplane\nautomobile\nbird\ncat\ndeer\ndog\nfrog\nhorse\nship\ntruck'''.split()","ce3acb77":"misclassified_idx = np.where(p_test == y_test)[0]\ni = np.random.choice(misclassified_idx)\nplt.imshow(x_test[i], cmap='gray')\nplt.title(\"True label: %s Predicted: %s\" % (labels[y_test[i]], labels[p_test[i]]));","bda2f8b0":"misclassified_idx = np.where(p_test != y_test)[0]\ni = np.random.choice(misclassified_idx)\nplt.imshow(x_test[i], cmap='gray')\nplt.title(\"True label: %s Predicted: %s\" % (labels[y_test[i]], labels[p_test[i]]));","45b6b1e7":"# Now that the model is so large, it's useful to summarize it\nmodel.summary()","68bfd6a0":"# Retrain data with augmentation","85bfbfa2":"# Check the Right predictions","865819f9":"# Check the Tensorflow version","9cd2e129":"# Check the wrong predictions","9cbff3f1":"# Check the shape","e956305a":"# Upvote it & comment down your questions and opinions","db252770":"**The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.**","4131a9b0":"![](https:\/\/raw.githubusercontent.com\/dmlc\/web-data\/master\/gluoncv\/datasets\/cifar10.png)","5321d559":"# We did Batch Normalization, See this to understand easily\ud83d\udc47","f8de7617":"## Note: if you run this AFTER calling the previous model.fit(), it will CONTINUE training where it left off.\n","1e6d4264":"# Check the model summary","3e055c86":"# It's time to Training","f6307caa":"# Let's plot Accuracy","33433e80":"# Define the Labels","1efe99d8":"# Data is very confusing but you can see the result","366f180a":"# Let's plot Loss","0c17186f":"# Now plot the confusion matrix","17febcd4":"# Import required Libraries","8533ae6e":"# Build the Model","216c55af":"![](https:\/\/pbs.twimg.com\/media\/DpN0VplXcAAoBjy.jpg)","038df439":"# Load the CIFAR-10 Dataset from keras","783157bd":"![](https:\/\/i1.wp.com\/csmoon-ml.com\/wp-content\/uploads\/2019\/04\/1WRio7MD4JDeLww-CyrxEbg.png?fit=709%2C412)","597dd7d5":"# Check the number of classes in dataset","f1b9c291":"# CIFAR-10 Dataset"}}