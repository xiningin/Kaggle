{"cell_type":{"57739504":"code","e47fadd2":"code","cac85ce4":"code","3a32d1f9":"code","c6fd6bc1":"code","aef385af":"code","b9d0d31f":"code","aa0f3e10":"code","63cb6e78":"code","3e53ae8b":"code","5621dbbf":"code","e8bbd929":"code","92139018":"code","b0475c37":"code","e47850f0":"code","68ce2138":"code","bf7277b5":"code","84bb25fd":"code","f0b1333f":"code","f4a39b48":"code","9103e2de":"code","33f23747":"code","9a59bef1":"code","f7ff9380":"code","b8939721":"code","dcdc9ed2":"code","a6549bd9":"code","ce1cfa6b":"code","087d3a83":"code","5c58141c":"code","4d74e234":"code","f9ef2f6b":"code","7fdd9c4f":"markdown","4fca6c97":"markdown","f283dc9d":"markdown","43a87bf7":"markdown","567d1314":"markdown","59175182":"markdown","50f0f1f5":"markdown","43f735be":"markdown","42c130a0":"markdown","df281dec":"markdown","be4f8eb9":"markdown","279380d2":"markdown","1b62f6b3":"markdown","09af983b":"markdown","443635d8":"markdown","85d36442":"markdown","22c69437":"markdown","0e406eb6":"markdown","a528f561":"markdown"},"source":{"57739504":"import sys\nIN_COLAB = 'google.colab' in sys.modules","e47fadd2":"# model-specific constants:\n\n# image w\/h :\n#     ResNet50 : (224, 224)\n#     Xception : (299, 299)\nIMAGE_WIDTH, IMAGE_HEIGHT = (299, 299)","cac85ce4":"# \uc804\uccb4\uc801\uc73c\ub85c \ubb38\uc81c\uc5c6\uc774 \ub3cc\uc544\uac00\ub294\uc9c0\ub9cc \ud655\uc778\ud560 \ub54c \uc0ac\uc6a9.\nTESTFLIGHT = False\n\n# train\uc744 \ud1b5\ud574 weight\ub97c \ub9cc\ub4e4\ub824 \ud560 \ub54c \uc0ac\uc6a9\nGENERATE_WEIGHTS = False\n\nBATCH_SIZE = 32\nEPOCHS = 40\nK_FOLDS = 5\nPATIENCE = 6\n\n# \uc624\ub958 \uc5c6\uc774 \ub3cc\uc544\uac00\ub294\uc9c0 \ud655\uc778\ud558\ub824 \ud560 \ub54c \uc0ac\uc6a9\ud55c\ub2e4:\nif TESTFLIGHT:\n    EPOCHS = 3\n    K_FOLDS = 3\n\nASSIGNED_FOLD_JOBS = [x for x in range(K_FOLDS)]","3a32d1f9":"import pandas as pd\nimport os\nfrom pathlib import Path\nimport shutil\n\nDATA_PATH = \"..\/input\"\nCROPPED_DATA_PATH = \"..\/cropped\"\nMODEL_PATH = \"..\/models\"\n\nif IN_COLAB:\n    DATA_PATH = \".\/input\"\n    CROPPED_DATA_PATH = \".\/cropped\"\n    MODEL_PATH = \".\/models\"\nelse:\n    # path \ubaa9\ub85d\n    DATA_PATH = \"..\/input\"            # input \ub370\uc774\ud130 \uacbd\ub85c\n    CROPPED_DATA_PATH = \".\/cropped\"  # crop\ud55c \uc774\ubbf8\uc9c0\ub97c \uc800\uc7a5\ud560 \uacbd\ub85c\n    MODEL_PATH = \".\/\"          # training \uc644\ub8cc\ub41c weight \ud30c\uc77c\uc774 \uc800\uc7a5\ub420 \uacbd\ub85c\n    \n    if os.path.exists(MODEL_PATH) == False:\n        Path(MODEL_PATH).mkdir(parents=True, exist_ok=True)\n    \n    # \uc9c1\uc811 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\ub294\ub2e4:\n    PRE_MODEL_NAME = \"kakr-3rd-xception\"\n    INPUT_DATA_NAME = \"2019-3rd-ml-month-with-kakr\"\n    \n    pre_models_path = os.path.join(DATA_PATH, PRE_MODEL_NAME)\n    \n    # weight\ub97c \uc0dd\uc131\ud558\ub824\ub294 \ubaa9\uc801\uc774 \uc544\ub2c8\uba74 weight\ud30c\uc77c\uc744 \ubbf8\ub9ac \ubcf5\uc0ac\ud574 \ub454\ub2e4.\n\n    if os.path.exists(pre_models_path):\n        for fname in os.listdir(pre_models_path):\n            filepath = os.path.join(pre_models_path, fname)\n            if os.path.isfile(filepath):\n                if GENERATE_WEIGHTS == True:\n                    if fname.find(\"h5\") > 0:\n                        continue\n                destfilepath = os.path.join(MODEL_PATH, fname)\n                print(\"copy file \", filepath, \" to \", destfilepath)\n                shutil.copy(filepath, destfilepath)\n\n    if os.path.exists(os.path.join(DATA_PATH, INPUT_DATA_NAME)):\n        DATA_PATH = os.path.join(DATA_PATH, INPUT_DATA_NAME)\n        \nprint(\"Paths : \")\nprint(\"----------------------------------\")\nprint(\"DATA_PATH         : \", DATA_PATH)\nprint(\"CROPPED_DATA_PATH : \", CROPPED_DATA_PATH)\nprint(\"MODEL_PATH        : \", MODEL_PATH)","c6fd6bc1":"# colab\uc5d0\uc11c \uad6c\ub3d9\uc744 \uc704\ud55c \uac83\uc774\ubbc0\ub85c \ucf54\ub4dc \ucc38\uace0 \uc2dc\uc5d0\ub294 \ubb34\uc2dc\ud558\uba74 \ub429\ub2c8\ub2e4.\ndef tmp_copy_weights_to_model_path():\n    for fname in os.listdir(\".\/\"):\n\n        if fname.find(\"h5\") > -1:\n            dstpath = os.path.join(MODEL_PATH, fname)\n            shutil.copy(fname, dstpath)\n\nif IN_COLAB == True:\n    tmp_copy_weights_to_model_path()","aef385af":"# csv \ud30c\uc77c\uc744 \uc77d\uc5b4\uc11c DataFrame\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.\ndf_train = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\ndf_test = pd.read_csv(os.path.join(DATA_PATH, \"test.csv\"))\ndf_class = pd.read_csv(os.path.join(DATA_PATH, \"class.csv\"))\n\nclasses = df_class['id'].values.astype('str').tolist()\nnum_classes_out = len(classes)\n\nif os.path.exists(MODEL_PATH) == False:\n    Path(MODEL_PATH).mkdir(parents=True, exist_ok=True)\n    \n    \nimport zipfile\nz = zipfile.ZipFile(os.path.join(DATA_PATH, \"train.zip\"))\nz.extractall(\".\/train\")\nz.close()\n\nimport zipfile\nz = zipfile.ZipFile(os.path.join(DATA_PATH, \"test.zip\"))\nz.extractall(\".\/test\")\nz.close()","b9d0d31f":"df_train.head()","aa0f3e10":"df_test.head()","63cb6e78":"df_class.head()","3e53ae8b":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(2, 1, figsize=(24, 5))\ndef check_count_by_class():\n    df_merged = df_train.append(df_test, ignore_index=True, sort=False)\n    sns.countplot(x='class', data=df_merged, ax=ax[0])\n    ax[1].set_xlim([0, 300])\n    df_merged['class'].plot.kde(ax=ax[1])\n    print(\"max count = \", df_merged['class'].value_counts().index[0], \":\", df_merged['class'].value_counts()[df_merged['class'].value_counts().index[0]])\n    \n    a = df_merged['class'].value_counts()\n    print(\"MAX count : \", a.idxmax().astype('int'), a[a.idxmax()])\n    print(\"MIN count : \", a.idxmin().astype('int'), a[a.idxmin()])    \n\ncheck_count_by_class()\n","5621dbbf":"from PIL import Image, ImageDraw\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n\nwidths = []\nheights = []\n\nfor idx, row in df_train.iterrows():    \n    im = Image.open(os.path.join(\".\/train\", row['img_file']))\n    w, h = im.size\n    widths.append(w)\n    heights.append(h)\n    \nwidths = np.array(widths)\nheights = np.array(heights)\nprint(\"width  min\/max\/mean : \", np.min(widths), np.max(widths), np.mean(widths))\nprint(\"height min\/max\/mean : \", np.min(heights), np.max(heights), np.mean(heights))\n\nbins = [x for x in range(-1, 6000, 200)]\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfig, ax = plt.subplots(2, 2, figsize=(16, 10))\n\n# draw as hist:\nax[0][0].hist(widths, bins=bins)\nax[0][0].set_title(\"width hist\")\nax[0][1].hist(heights, bins=bins)\nax[0][1].set_title(\"height hist\")\n\n# draw as kde:\nsns.kdeplot(np.array(widths), ax=ax[1][0])\nax[1][0].set_title(\"width kde\")\nsns.kdeplot(np.array(heights), ax=ax[1][1])\nax[1][1].set_title(\"height kde\")\n    \n","e8bbd929":"from PIL import Image, ImageDraw\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nn = 5\n\nfix, ax = plt.subplots(n, 1, figsize = (10, 40))\naxidx = 0\n\ndf_sample = df_train.sample(n)\nfor idx, row in df_sample.iterrows():\n    im = Image.open(os.path.join(\".\/train\", row['img_file']))\n    \n    # \uc774\ubbf8\uc9c0 \ub0b4\uc5d0 \ubc15\uc2a4\ub97c \uadf8\ub9b0\ub2e4.\n    draw = ImageDraw.Draw(im)\n    #draw.rectangle((row['bbox_x1'], row['bbox_y1'], row['bbox_x2'], row['bbox_y2']), outline='blue', width=2)\n    \n    print(\"bbox:\", row['bbox_x1'], row['bbox_y1'], row['bbox_x2'], row['bbox_y2'])\n    width = row['bbox_x2'] - row['bbox_x1']\n    height = row['bbox_y2'] - row['bbox_y1']\n    rect = patches.Rectangle((row['bbox_x1'], row['bbox_y1']), width, height, linewidth=3, edgecolor='r',facecolor='none')\n    ax[axidx].add_patch(rect)\n    ax[axidx].imshow(im)\n    \n    axidx += 1\n\n","92139018":"def checkratio(df):\n    df['ratio'] = (df['bbox_x2'] - df['bbox_x1']) \/ (df['bbox_y2'] - df['bbox_y1'])\n    return df\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 8))\n\ndf_merged = df_train.append(df_test, ignore_index=True, sort=False)\ndf_tmp = checkratio(df_merged)\ndf_tmp['ratio'].plot.kde()","b0475c37":"image_width, image_height = IMAGE_WIDTH, IMAGE_HEIGHT\n\n# crop\ud574\uc11c \ub9cc\ub4e4 \uc774\ubbf8\uc9c0\uc758 W\/H \ube44\uc728\uc744 1:1\ub85c \ud55c\ub2e4.\n# \ubaa8\ub378\uc758 \uc774\ubbf8\uc9c0 \uc785\ub825\uc740 width,height\uac00 \ub3d9\uc77c\ud558\ubbc0\ub85c 1:1\ub9cc\uc774 \uac00\ub2a5\ud568.\ndefault_ratio = 1.0\n\nfrom pathlib import Path\n    \ndef get_fixed_img(filename, area, ratio, output_size):\n    debug = False\n    im = Image.open(filename)\n    cropIm = im.crop(area)\n    \n    if debug:\n        print(\"crop w\/h=\", cropIm.width, cropIm.height)\n    \n    w, h = cropIm.width, cropIm.height\n    # w : h = w\/h ratio : 1\n    fixedW, fixedH = w, h\n    if w\/h >= ratio:\n        fixedH = w \/ ratio\n    else:\n        fixedW = h * ratio\n    fixedW, fixedH = int(fixedW), int(fixedH)\n\n    if debug:\n        print(\"fixed w\/h=\", fixedW, fixedH, \"ratio=\", fixedW\/fixedH)\n    \n    newIm = Image.new(\"RGB\", (fixedW, fixedH))\n    newIm.paste(cropIm, ((fixedW - w)\/\/2, (fixedH - h)\/\/2))\n    \n    #newIm = newIm.resize(output_size, resample=Image.NEAREST)\n    return newIm\n\ndef img_from_row(row, path, ratio, w, h):\n    filepath = os.path.join(path, row['img_file'])\n    area = (row['bbox_x1'], row['bbox_y1'], row['bbox_x2'], row['bbox_y2'])\n    return get_fixed_img(filepath, area, ratio, (w, h))    \n\ndef make_crop_img(df, dirname):\n    # \uc800\uc7a5\ub420 \ub514\ub809\ud1a0\ub9ac\ubd80\ud130 \uc0dd\uc131\n    dirpath_crop = os.path.join(CROPPED_DATA_PATH, dirname)\n    if os.path.exists(dirpath_crop) == False:\n        Path(dirpath_crop).mkdir(parents=True, exist_ok=True)\n\n    for idx, row in df.iterrows():\n        src_path = dirname\n        target_img_path = os.path.join(dirpath_crop, row['img_file'])\n        \n        # \ud30c\uc77c\uc774 \uc5c6\uac70\ub098, \uc0ac\uc774\uc988\uac00 0\uc774\uba74 \uc0c8\ub85c \ub9cc\ub4e0\ub2e4.\n        isvalid = os.path.exists(target_img_path)\n        isvalid = (isvalid and (os.path.getsize(target_img_path) > 0))\n        if isvalid == False:\n            im = img_from_row(row, src_path, default_ratio, image_width, image_height)\n            im.save(target_img_path)\n\ndef make_cropped_imgs():\n    dirpath_crop = os.path.join(CROPPED_DATA_PATH, \"train\")\n    print(dirpath_crop)\n    make_crop_img(df_train, \"train\")\n    \n    dirpath_crop = os.path.join(CROPPED_DATA_PATH, \"test\")\n    print(dirpath_crop)\n    make_crop_img(df_test, \"test\")\n\nmake_cropped_imgs()","e47850f0":"# show cropped image\ndef show_cropped_imgs():\n    dirpath_crop = os.path.join(CROPPED_DATA_PATH, \"train\")    \n    n = 4\n    fix, ax = plt.subplots(n, 1, figsize = (10, 40))\n    axidx = 0\n    df_sample = df_train.sample(n)\n    for idx, row in df_sample.iterrows():\n        im = Image.open(os.path.join(dirpath_crop, row['img_file']))\n\n        # \uc774\ubbf8\uc9c0 \ub0b4\uc5d0 \ubc15\uc2a4\ub97c \uadf8\ub9b0\ub2e4.\n        draw = ImageDraw.Draw(im)\n        ax[axidx].imshow(im)\n        axidx += 1\n    plt.show()\n    \nshow_cropped_imgs()","68ce2138":"epochs = EPOCHS\nbatch_size = BATCH_SIZE\n\ndef get_total_batch(num_samples, batch_size):    \n    if (num_samples % batch_size) > 0 :\n        return (num_samples \/\/ batch_size) + 1\n    else :\n        return num_samples \/\/ batch_size","bf7277b5":"from keras import backend as K\ndef recall(y_target, y_pred):\n    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max \uc774\uc678 \uac00\uc7a5\uc790\ub9ac\ub97c \uae4e\uc544 \ub0b8\ub2e4\n    # round : \ubc18\uc62c\ub9bc\ud55c\ub2e4\n    y_target_yn = K.round(K.clip(y_target, 0, 1)) # \uc2e4\uc81c\uac12\uc744 0(Negative) \ub610\ub294 1(Positive)\ub85c \uc124\uc815\ud55c\ub2e4\n    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # \uc608\uce21\uac12\uc744 0(Negative) \ub610\ub294 1(Positive)\ub85c \uc124\uc815\ud55c\ub2e4\n\n    # True Positive\ub294 \uc2e4\uc81c \uac12\uacfc \uc608\uce21 \uac12\uc774 \ubaa8\ub450 1(Positive)\uc778 \uacbd\uc6b0\uc774\ub2e4\n    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n\n    # (True Positive + False Negative) = \uc2e4\uc81c \uac12\uc774 1(Positive) \uc804\uccb4\n    count_true_positive_false_negative = K.sum(y_target_yn)\n\n    # Recall =  (True Positive) \/ (True Positive + False Negative)\n    # K.epsilon()\ub294 'divide by zero error' \uc608\ubc29\ucc28\uc6d0\uc5d0\uc11c \uc791\uc740 \uc218\ub97c \ub354\ud55c\ub2e4\n    recall = count_true_positive \/ (count_true_positive_false_negative + K.epsilon())\n\n    # return a single tensor value\n    return recall\n\n\ndef precision(y_target, y_pred):\n    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max \uc774\uc678 \uac00\uc7a5\uc790\ub9ac\ub97c \uae4e\uc544 \ub0b8\ub2e4\n    # round : \ubc18\uc62c\ub9bc\ud55c\ub2e4\n    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # \uc608\uce21\uac12\uc744 0(Negative) \ub610\ub294 1(Positive)\ub85c \uc124\uc815\ud55c\ub2e4\n    y_target_yn = K.round(K.clip(y_target, 0, 1)) # \uc2e4\uc81c\uac12\uc744 0(Negative) \ub610\ub294 1(Positive)\ub85c \uc124\uc815\ud55c\ub2e4\n\n    # True Positive\ub294 \uc2e4\uc81c \uac12\uacfc \uc608\uce21 \uac12\uc774 \ubaa8\ub450 1(Positive)\uc778 \uacbd\uc6b0\uc774\ub2e4\n    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n\n    # (True Positive + False Positive) = \uc608\uce21 \uac12\uc774 1(Positive) \uc804\uccb4\n    count_true_positive_false_positive = K.sum(y_pred_yn)\n\n    # Precision = (True Positive) \/ (True Positive + False Positive)\n    # K.epsilon()\ub294 'divide by zero error' \uc608\ubc29\ucc28\uc6d0\uc5d0\uc11c \uc791\uc740 \uc218\ub97c \ub354\ud55c\ub2e4\n    precision = count_true_positive \/ (count_true_positive_false_positive + K.epsilon())\n\n    # return a single tensor value\n    return precision\n\n\ndef f1score(y_target, y_pred):\n    _recall = recall(y_target, y_pred)\n    _precision = precision(y_target, y_pred)\n    # K.epsilon()\ub294 'divide by zero error' \uc608\ubc29\ucc28\uc6d0\uc5d0\uc11c \uc791\uc740 \uc218\ub97c \ub354\ud55c\ub2e4\n    _f1score = ( 2 * _recall * _precision) \/ (_recall + _precision+ K.epsilon())\n    \n    # return a single tensor value\n    return _f1score","84bb25fd":"from sklearn.model_selection import StratifiedKFold, KFold\nskfold = StratifiedKFold(n_splits=K_FOLDS, random_state=2019)","f0b1333f":"#ref: https:\/\/github.com\/yu4u\/cutout-random-erasing\/blob\/master\/cifar10_resnet.py\ndef get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1\/0.3, v_l=0, v_h=255, pixel_level=False):\n    def eraser(input_img):\n        img_h, img_w, img_c = input_img.shape\n        p_1 = np.random.rand()\n\n        if p_1 > p:\n            return input_img\n\n        while True:\n            s = np.random.uniform(s_l, s_h) * img_h * img_w\n            r = np.random.uniform(r_1, r_2)\n            w = int(np.sqrt(s \/ r))\n            h = int(np.sqrt(s * r))\n            left = np.random.randint(0, img_w)\n            top = np.random.randint(0, img_h)\n\n            if left + w <= img_w and top + h <= img_h:\n                break\n\n        if pixel_level:\n            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n        else:\n            c = np.random.uniform(v_l, v_h)\n\n        input_img[top:top + h, left:left + w, :] = c\n\n        return input_img\n\n    return eraser","f4a39b48":"from keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen_train = ImageDataGenerator(\n    rescale=1.\/255,\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.3, # Randomly zoom image \n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=True,  # randomly flip images\n    vertical_flip=False,  # randomly flip images\n    preprocessing_function = get_random_eraser(v_l=0, v_h=255),\n    )\n\ndatagen_val = ImageDataGenerator(\n    rescale=1.\/255,\n#     featurewise_center=False,  # set input mean to 0 over the dataset\n#     samplewise_center=False,  # set each sample mean to 0\n#     featurewise_std_normalization=False,  # divide inputs by std of the dataset\n#     samplewise_std_normalization=False,  # divide each input by its std\n#     zca_whitening=False,  # apply ZCA whitening\n#     rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n#     zoom_range = 0.2, # Randomly zoom image \n#     width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n#     height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n#     horizontal_flip=True,  # randomly flip images\n#     vertical_flip=False,  # randomly flip images\n#     preprocessing_function = preprocess_input\n)\n\n\n# \uc544\ub798 \uc548\ud574\uc8fc\uba74 \uc5d0\ub7ec\ub0a8. categorical\uc774\uc5b4\uc11c \uae30\uc900 col\uc774 \uc22b\uc790\uac12\uc774\uba74 \uc548\ub418\ub294 \uac83\uc778\ub4ef.\ndf_train['class'] = df_train['class'].astype('str')","9103e2de":"from keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.applications.xception import Xception\nfrom keras import optimizers\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, GlobalAveragePooling2D\n\n__models = {}\n\ndef get_model(base_model, show_summary=False):\n    base_model = base_model(weights='imagenet', include_top=False, input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT,3))\n\n    model = Sequential()\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n\n    # \uc911\uac04 layer \ucd94\uac00(dropout)\n    model.add(Dense(2048, activation='relu', kernel_initializer='he_normal'))\n    model.add(Dropout(0.15))\n\n    model.add(Dense(196, activation='softmax', kernel_initializer='lecun_normal'))\n    if show_summary:\n        model.summary()\n\n    optimizer = optimizers.Nadam(lr=0.0002)\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc', recall, precision, f1score])\n    \n    return model\n    \n__models = {\"Xception\" : Xception}","33f23747":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LambdaCallback\n\ndef get_callbacks(model_save_filename, patience):\n    es = EarlyStopping(monitor='val_f1score', min_delta=0, patience=patience, verbose=1, mode='max')\n\n    rr = ReduceLROnPlateau(monitor = 'val_f1score', factor = 0.5, patience = patience \/ 2,\n                           min_lr=0.000001,\n                           verbose=1,\n                           mode='max')\n\n    mc = ModelCheckpoint(filepath=model_save_filename, monitor='val_f1score', verbose=1,\n                           save_best_only=True, mode='max')\n\n    return [es, rr, mc]\n    \n    ","9a59bef1":"#aaa = skfold.split(X=df_train['img_file'], y=df_train['class'])\nimport ssl\nfrom keras.models import model_from_json\n\nssl._create_default_https_context = ssl._create_unverified_context\nhistory_list = {}\nfor _m in __models:\n    print(\"Model : \", _m)\n        \n    # \ubbf8\ub9ac fold\ub97c \ub098\ub204\uc5b4 \uc0dd\uc0dd\ud574 \ub454 dataframe \ud30c\uc77c\uc744 \uc0ac\uc6a9\ud55c\ub2e4.\n    for fold_index in ASSIGNED_FOLD_JOBS:\n\n        # \ubaa8\ub378 \uc0dd\uc131\n        model = get_model(__models[_m], fold_index == 0)\n\n        # weight\ub97c \uc800\uc7a5\ud560 \ud30c\uc77c\uba85\uc744 \uc0dd\uc131\n        model_save_filename = (\"%s_%d.h5\" % (_m , fold_index))\n        model_save_filepath = os.path.join(MODEL_PATH, model_save_filename)\n\n        # \ub098\ub220\uc9c4 dataframe\uc744 load\n        df_train_filename = (\"fold_%d_train.csv\" % fold_index)\n        df_val_filename = (\"fold_%d_val.csv\" % fold_index)\n\n        dataframe_train = pd.read_csv(os.path.join(MODEL_PATH, df_train_filename))\n        dataframe_val = pd.read_csv(os.path.join(MODEL_PATH, df_val_filename))\n\n        # \uc544\ub798 \uc548\ud574\uc8fc\uba74 \uc5d0\ub7ec\ub0a8. categorical\uc774\uc5b4\uc11c \uae30\uc900 col\uc774 \uc22b\uc790\uac12\uc774\uba74 \uc548\ub418\ub294 \uac83\uc778\ub4ef.\n        dataframe_train['class'] = dataframe_train['class'].astype('str')\n        dataframe_val['class'] = dataframe_val['class'].astype('str')\n\n        # ImageDataGenerator \uc0dd\uc131(train\/val)\n        datagen_train_flow = datagen_train.flow_from_dataframe(dataframe=dataframe_train,\n                                                   directory=os.path.join(CROPPED_DATA_PATH, \"train\"),\n                                                   x_col='img_file',\n                                                   y_col=\"class\",\n                                                   classes = classes,\n                                                   target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n                                                   color_mode='rgb',\n                                                   class_mode='categorical',\n                                                   batch_size=batch_size,\n                                                   shuffle = True)\n\n        datagen_val_flow = datagen_val.flow_from_dataframe(dataframe=dataframe_val,\n                                                   directory=os.path.join(CROPPED_DATA_PATH, \"train\"),\n                                                   x_col='img_file',\n                                                   y_col=\"class\",\n                                                   classes = classes,\n                                                   target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n                                                   color_mode='rgb',\n                                                   class_mode='categorical',\n                                                   batch_size=batch_size,\n                                                   shuffle = True)\n        \n        if GENERATE_WEIGHTS == True:\n            if os.path.exists(model_save_filepath) == True:\n                os.remove(model_save_filepath)\n\n        # \ub3d9\uc77c \uc774\ub984\uc758 weight \ud30c\uc77c\uc774 \uc788\uc73c\uba74 \ub118\uc5b4\uac04\ub2e4.\n        if os.path.exists(model_save_filepath) == True:\n            print(\">>>\", model_save_filepath, \" already trained... skip!\")\n            continue\n        \n        train_steps = get_total_batch(dataframe_train.shape[0], batch_size)\n        val_steps = get_total_batch(dataframe_val.shape[0], batch_size)\n        \n        if TESTFLIGHT:\n            train_steps = 10\n            val_steps = 10\n            \n        history = model.fit_generator(datagen_train_flow,\n            epochs=epochs,\n            steps_per_epoch = train_steps,\n            validation_data = datagen_val_flow,\n            validation_steps = val_steps,\n            callbacks = get_callbacks(model_save_filepath, PATIENCE),\n            verbose=0)\n        \n        history_list[model_save_filename] = history\n        \n        model = None\n        \n    ","f7ff9380":"if GENERATE_WEIGHTS == True:\n    fig, ax = plt.subplots(1, 1, figsize=(12,8 * len(__models)))\n    from cycler import cycler\n\n    # set color cycle : \uadf8\ub798\ud504 \uc0c9\uae54\uc744 \uc54c\uc544\uc11c cycling\ud574\uc900\ub2e4.\n    x = np.linspace(0, 1, 10)\n    number = 5\n    cmap = plt.get_cmap('gnuplot')\n    colors = [cmap(i) for i in np.linspace(0, 1, number)]\n    ax.set_prop_cycle(cycler('color', colors))\n\n    for hname in history_list:\n        history = history_list[hname]\n        plot_label = \"val_score : \" + hname\n        ax.plot(history.history['val_f1score'], label=plot_label)        \n    ax.legend()        \n    plt.show()","b8939721":"datagen_submit = ImageDataGenerator(\n    rescale=1.\/255,\n)\n\ndef load_sub_models():\n    sub_models = []\n    for _m in __models:\n        print(\"Model \", _m, \" : \")\n        for _, _, filenames in os.walk(MODEL_PATH):\n            for fname in filenames:\n                if fname.find(_m) >= 0 and fname.find(\".h5\") >= 0:        \n                    print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> loading \", fname)\n                    model = get_model(__models[_m])\n\n                    # model\uc5d0 \ub370\uc774\ud130\ud30c\uc77c\uc744 \uc62c\ub9b0\ub2e4.\n                    # model \uba85\uc774 \uc788\ub294 \uac83\ub4e4 \uc911\uc5d0\uc11c\ub9cc \uc62c\ub9b0\ub2e4.\n\n                    fpath = os.path.join(MODEL_PATH, fname)\n                    print(\"model weight fpath:\", fpath)\n                    model.load_weights(fpath)\n\n                    sub_models.append(model)\n    return sub_models\n\nsubmodels = load_sub_models()","dcdc9ed2":"from numpy import dstack\n\ndef make_meta_learner_dataset(submodels, df, imgdirname, tta = False):\n    datagen_submit = ImageDataGenerator(rescale=1.\/255)\n    stackX = None\n    for model in submodels:\n\n\t\t# make prediction :\n        datagen_metalearner_flow = datagen_submit.flow_from_dataframe(\n            dataframe=df,\n            directory=os.path.join(CROPPED_DATA_PATH, imgdirname),\n            x_col='img_file',\n            y_col=None,\n            target_size= (IMAGE_WIDTH, IMAGE_HEIGHT),\n            color_mode='rgb',\n            class_mode=None,\n            batch_size=batch_size,\n            shuffle=False)\n        \n        datagen_metalearner_augmented_flow = datagen_train.flow_from_dataframe(\n            dataframe=df,\n            directory=os.path.join(CROPPED_DATA_PATH, imgdirname),\n            x_col='img_file',\n            y_col=None,\n            target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n            color_mode='rgb',\n            class_mode=None,\n            batch_size=batch_size,\n            shuffle=False)\n        \n        datagen_flow = datagen_metalearner_flow\n        if tta == True:\n            print(\"select tta flow\")\n            datagen_flow = datagen_metalearner_augmented_flow\n\n        datagen_flow.reset()\n        pred = model.predict_generator(generator = datagen_flow,\n                                       steps = get_total_batch(df.shape[0], batch_size),\n                                       verbose=1)\n        \n        if stackX is None:\n            stackX = pred\n        else:\n            stackX = dstack((stackX, pred))\n   \n    print(\"stackX.shape = \", stackX.shape)\n        \n    # flatten predictions to [rows, members x probabilities]\n    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n    return stackX","a6549bd9":"import keras\nfrom keras import layers, models","ce1cfa6b":"def make_meta_learner_model(input_shape, output_class_count, dropout):\n    print(input_shape)\n    print(output_class_count)\n    print(dropout)\n    print(input_shape[1] * 2)\n    \n    model = models.Sequential()\n\n    model.add(layers.Dense(units=input_shape[1] * 2, activation='relu', kernel_initializer='he_normal'))\n    model.add(layers.Dropout(dropout))\n    \n    model.add(layers.Dense(units=int(input_shape[1] \/ 2), activation='relu', kernel_initializer='he_normal'))\n    model.add(layers.Dropout(dropout))\n\n    model.add(layers.Dense(units=int(input_shape[1] \/ 4), activation='relu', kernel_initializer='he_normal'))\n    model.add(layers.Dropout(dropout))\n    \n    model.add(layers.Dense(units=output_class_count, activation='softmax', kernel_initializer='he_normal'))\n    \n    model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['acc', recall, precision, f1score])\n    \n    return model\n\n\ndef get_callbacks_for_meta_learner(model_save_filename, patience):\n    es = EarlyStopping(monitor='f1score', min_delta=0, patience=patience, verbose=1, mode='max')\n\n    rr = ReduceLROnPlateau(monitor = 'f1score', factor = 0.5, patience = patience \/ 2,\n                           min_lr=0.000001,\n                           verbose=1, \n                           mode='max')\n\n    mc = ModelCheckpoint(filepath=model_save_filename, monitor='f1score', verbose=1,\n                           save_best_only=True, mode='max')\n\n    return [es, rr, mc]","087d3a83":"from keras.utils import to_categorical\n\nprint(\"Build dataset for meta-learner...\")\nmeta_train_X = None\n\nMETA_LEARNER_DATA_EPOCHS = 1\nfor epoch in range(META_LEARNER_DATA_EPOCHS):\n    print(\"Epoch \", epoch)\n    epochs_x = make_meta_learner_dataset(submodels, df_train, \"train\")\n    if meta_train_X is None:\n        meta_train_X = epochs_x\n    else:\n        meta_train_X = vstack([meta_train_X, epochs_x])\nprint(\"meta_train_X.shape=\", meta_train_X.shape)\n","5c58141c":"from numpy import vstack\n\n# \ubaa8\ub378\uc774 \ud6c8\ub828\ub41c label\uac12\uc5d0 \ub9de\uac8c Y\uac12\uc744 \ub9cc\ub4e4\uc5b4\uc57c \ud55c\ub2e4.\nmeta_train_Y = None\nlabels = (datagen_train_flow.class_indices)\ny = df_train['class'].values\ny = [labels[x] for x in y]\ny = to_categorical(y)\nfor i in range(META_LEARNER_DATA_EPOCHS):\n    if meta_train_Y is None:\n        meta_train_Y = y\n    else:\n        meta_train_Y = vstack([meta_train_Y, y])\nprint(\"meta_train_Y.shape=\", meta_train_Y.shape)","4d74e234":"def train_meta_learner(X, Y):\n    \n    meta_learner_model_save_filename = (\"meta_learner_model.h5\")\n    meta_learner_model_save_filepath = os.path.join(MODEL_PATH, meta_learner_model_save_filename)\n    \n    print(\"Training meta-learner model...\")\n    meta_learner_model = make_meta_learner_model(X.shape, len(classes), dropout=0.3)\n    meta_learner_model.fit(X, Y, epochs=20, verbose=1, batch_size=128, callbacks=get_callbacks_for_meta_learner(meta_learner_model_save_filepath, 6))\n    \n    meta_learner_model.load_weights(meta_learner_model_save_filepath)\n    \n    return meta_learner_model\n\nmeta_learner_model = train_meta_learner(meta_train_X, meta_train_Y)\n\n","f9ef2f6b":"tta_len = 4\n\npreds = []\nfor i in range(tta_len):\n    meta_submit_X = make_meta_learner_dataset(submodels, df_test, \"test\", tta=True)\n    pred = meta_learner_model.predict(meta_submit_X, batch_size=32)\n    preds.append(pred)\n    \npred = np.mean(np.array(preds), axis=0)\n\nsubmit_Y = np.argmax(pred, axis=1)\nlabels = (datagen_train_flow.class_indices)\nlabels = dict((v,k) for k, v in labels.items())\n\npredictions = [labels[k] for k in submit_Y]\n\nsubmission = pd.DataFrame()\nsubmission['img_file'] = df_test['img_file']\nsubmission[\"class\"] = predictions\nsubmission.to_csv(\"submission.csv\", index=False)","7fdd9c4f":"\uc774\ubbf8\uc9c0\uc758 width\/height min\/max \uac12\uacfc \ubd84\ud3ec\ub97c \ud655\uc778","4fca6c97":"# **2. \ub370\uc774\ud130 \ud3b8\uc9d1:**\n\n\uc774\ubbf8\uc9c0 \ub0b4 \uc790\ub3d9\ucc28\uc758 \uc704\uce58\uac00 csv\ud30c\uc77c\uc5d0 \ub4e4\uc5b4 \uc788\uc73c\ubbc0\ub85c, \uc704\uce58\uc5d0 \ub9de\uac8c crop\ud558\uace0 crop\ub41c \uc774\ubbf8\uc9c0\uc758 width\/height\ub97c 1:1\ub85c \ub9de\ucdb0\uc57c \ud569\ub2c8\ub2e4. <br>\n\uc774\ubbf8\uc9c0\ub97c \uadf8\ub300\ub85c resize\ud558\uba74 \uc790\ub3d9\ucc28\uc758 \ud615\ud0dc\uac00 \ubcc0\ud615\ub418\uc5b4 shape\uc744 \ud1b5\ud55c \ud310\ubcc4\uc5d0 \ubb38\uc81c\uac00 \uc0dd\uae38 \uac83\uc73c\ub85c \ud310\ub2e8\ud558\uc600\uc2b5\ub2c8\ub2e4. resize\uc804\uc5d0 \uba3c\uc800 \uc774\ubbf8\uc9c0\uc758 \uc88c\/\uc6b0 \ud639\uc740 \uc704\/\uc544\ub798\uc5d0 padding\uc744 \ucd94\uac00\ud558\uc5ec ratio\ub97c \uc720\uc9c0\ud558\ub3c4\ub85d \ucf54\ub4dc\ub97c \uc791\uc131\ud558\uc600\uc2b5\ub2c8\ub2e4.","f283dc9d":"### \uc0c1\uc218 \/ \ud30c\ub77c\uba54\ud130 \uc124\uc815","43a87bf7":"\ub2e4\uc74c \ucee4\ub110\uc5d0\uc11c random_eraser \ud568\uc218\ub97c \uac00\uc838\uc640\uc11c \uc0ac\uc6a9\n\nhttps:\/\/www.kaggle.com\/seriousran\/what-0-95121-model-failed","567d1314":"# **1. \ub370\uc774\ud130 \ubd84\uc11d:**","59175182":"## Weighted averaging model\n\nsub-model \uac01\uac01\uc758 \uacb0\uacfc\uac00 weight \uac12\uc5d0 \ub530\ub77c \ub2e4\ub974\uac8c \uc0ac\uc6a9\ub418\ub3c4\ub85d \ud558\ub294 \ubc29\ubc95\uc73c\ub85c, \uc5ec\uae30\uc11c\ub294 \uae30\uc874 output \uac12\uc758 \ud569\uc744 \uc785\ub825\uc73c\ub85c, \uae30\uc874 label\uc744 \uadf8\ub300\ub85c \uc0ac\uc6a9\ud558\ub294 \ubcc4\ub3c4\uc758 \ubaa8\ub378\uc744 \uc0dd\uc131\ud574\uc11c \ucd5c\uc885 \uacb0\uacfc\ub97c \uad6c\ud558\ub294 \ub370 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.<br>\nfold\ub85c \uc0dd\uc131\ub41c sub-model\uc758 \uc608\uce21\uacb0\uacfc\ub97c dstack\uc73c\ub85c \ud569\ud558\uc5ec meta learner\uc6a9 dataset\uc73c\ub85c \uc0dd\uc131\ud558\uace0 meta learner \ubaa8\ub378\uc744 \ud6c8\ub828\uc2dc\ud0b5\ub2c8\ub2e4.","50f0f1f5":"training history \uc9c4\ud589\uacfc\uc815\uc5d0 \ub300\ud574 \uadf8\ub798\ud504\ub97c \uadf8\ub824 \ubcf8\ub2e4.","43f735be":"CV\ub97c \uc704\ud574 KFold\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. <br>\n\uc804\uccb4 \ub370\uc774\ud130\uc5d0\uc11c\uc758 class \uac04 \ube44\uc728\uc744 fold\uc5d0\uc11c\ub3c4 \ub3d9\uc77c\ud558\uac8c \uc720\uc9c0\ud558\uae30 \uc704\ud574 StratifiedKFold\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.","42c130a0":"# **4. Weighted averaging\uc744 \ud1b5\ud55c ensemble & submission**\n\n\ucd5c\ub300 F1 Score\ub97c \ub0b8 \ubaa8\ub378\ub4e4\uc740 ModelCheckpoint callback\uc73c\ub85c \ud30c\uc77c\ub85c \uc800\uc7a5\ub418\ubbc0\ub85c, \uc800\uc7a5\ub41c weight\ub97c load\ud574\uc11c \ubaa8\ub378\uc744 \uc900\ube44\ud55c\ub2e4.","df281dec":"ratio\uc758 \ubd84\ud3ec\ub97c \ud559\uc778\ud569\ub2c8\ub2e4.","be4f8eb9":"<a id=\"modelling\"><\/a> <br> \n# **3. \ubaa8\ub378 \uc0dd\uc131:**\n\nXception\uc744 base model\ub85c \uc0ac\uc6a9\ud558\uace0 \ub05d\uc5d0 \uac04\ub2e8\ud55c fc \ub808\uc774\uc5b4\ub4e4\uc744 \ubd99\uc5ec\uc11c \uc0ac\uc6a9\ud560 \ubaa8\ub378\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.","279380d2":"# 2019 3rd ML month with KaKR\n\n\uc790\ub3d9\ucc28 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc14b\uc744 \uc774\uc6a9\ud55c \uc790\ub3d9\ucc28 \ucc28\uc885 \ubd84\ub958 <br>\n\n\n### Preprocessing \n\n- \uc774\ubbf8\uc9c0 ratio\ub97c \uc720\uc9c0\ud558\uba74\uc11c crop\/resizing\uc744 \uc218\ud589.\n  - \uc790\ub3d9\ucc28\uc758 \ud615\ud0dc\uac00 \ud310\ubcc4\uc5d0 \ub3c4\uc6c0\uc774 \ub420 \uac83\uc73c\ub85c \uc0dd\uac01\ud574\uc11c ratio\ub97c \uc720\uc9c0\ud558\uace0 \uac80\uc740\uc0c9 padding\uc744 \ucd94\uac00\ud568.\n  - \uadf8\ub300\ub85c resizing\uc744 \ud55c \uac83\uc5d0 \ube44\ud574 \uc88b\uc740 \uacb0\uacfc\ub97c \uc5bb\uc9c0 \ubabb\ud558\uc600\uc74c.\n\n### \uc0ac\uc6a9 \ubaa8\ub378\n- Xception <br>\n- 5 Fold cross validation\n\n### Ensemble\n- weighted averaging model + TTA\n  - cv model\ub4e4\uc758 output\ub4e4\uc744 dstack\uc73c\ub85c \ud569\ud55c \uac12\uc744 \uc785\ub825\uc73c\ub85c \ubc1b\ub294 meta learner \ubaa8\ub378\uc744 \ub9cc\ub4e4\uace0 train\ud558\uc5ec \uac01\uac01\uc758 \ubaa8\ub378\ub9c8\ub2e4 \ub2e4\ub978 \uac00\uc911\uce58\ub85c ensemble\uc774 \uc774\ub8e8\uc5b4\uc9c0\ub3c4\ub85d \ud55c\ub2e4.\n  - test prediction\uc2dc TTA(train\uc6a9 generator\ub97c \uc0ac\uc6a9)","1b62f6b3":"train\uc774 \uc644\ub8cc\ub41c \ubaa8\ub378\ub85c test dataset\uc744 predict\ud574\uc11c submission\uc744 \ub9cc\ub4e0\ub2e4.","09af983b":"class\ubcc4 \ub370\uc774\ud130 \uc218 \ud655\uc778","443635d8":"model \ud6c8\ub828\uc2dc \uc0ac\uc6a9\ud560 callback \ubaa9\ub85d\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.","85d36442":"\ud574\ub2f9 competition\uc758 \ud3c9\uac00\ub294 F1 Score\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n    Precision : TP \/ (TP + FP)\n    Recall : TP \/ (TP + FN) \n    \n    F1 Score = (2 X Recall X Precision) \/ (Recall + Precision)\n    \nearly stopping \ub4f1\uc758 \uacb0\uc815\uc744 \uc704\ud55c F1 Score \ud568\uc218\ub97c \uc815\uc758\ud569\ub2c8\ub2e4.","22c69437":"- img_file : \uc774\ubbf8\uc9c0 \ud30c\uc77c\uba85, train.zip\uc5d0 \uc788\ub294 \uc774\ubbf8\uc9c0 \ud30c\uc77c \uc774\ub984.\n- (bbox_x1, bbox_y1) : \uc790\ub3d9\ucc28 \uc704\uce58 \uc88c\uce21 \uc0c1\ub2e8 \uc88c\ud45c\n- (bbox_x2, bbox_y2) : \uc790\ub3d9\ucc28 \uc704\uce58 \uc6b0\uce21 \ud558\ub2e8 \uc88c\ud45c\n- class : \ud574\ub2f9 \uc774\ubbf8\uc9c0\uc758 \uc790\ub3d9\ucc28 class index\n","0e406eb6":"train\/eval\uc5d0 \uc0ac\uc6a9\ud560 ImageDataGenerator\ub97c \uc0dd\uc131\ud55c\ub2e4. <br>\nvalidation generator\uc758 \uacbd\uc6b0 \ub3d9\uc77c\ud55c \uc774\ubbf8\uc9c0\ub85c \ud3c9\uac00\ub97c \ud574\uc57c \uac1c\uc120 \uc5ec\ubd80 \ud655\uc778\uc774 \uac00\ub2a5\ud558\ubbc0\ub85c ImageDataGenerator\uc758 augmentation\uc744 \ubaa8\ub450 off \ud558\uc600\uc2b5\ub2c8\ub2e4.","a528f561":"\ubaa8\ub378\uc744 train \ud569\ub2c8\ub2e4.\n\nStratifiedKFold\uc740 label\uc758 \uad6c\uc131\ube44\uc728\uc744 \uc720\uc9c0\ud558\uba74\uc11c fold\ub97c \ub9cc\ub4e4\uc5b4\ub0b4\ubbc0\ub85c split() \ud638\ucd9c \uc2dc, y(label)\ub3c4 \ub118\uaca8\uc57c \ud569\ub2c8\ub2e4."}}