{"cell_type":{"8f02aaec":"code","e0dedb58":"code","acfaf287":"code","a4b54e7b":"code","f10bea70":"code","7dc8f98f":"code","4c43d8a7":"code","8bfa3afa":"code","81702570":"code","a7311c1f":"code","925a71ae":"code","ecc09a47":"code","f69110a9":"code","2f52ec34":"code","193f09c5":"code","b43b3416":"code","41ed1006":"markdown"},"source":{"8f02aaec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nparser = lambda date: pd.to_datetime(date, format='%d.%m.%Y')\n\ntrain = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv', parse_dates=['date'], date_parser=parser)\ntest = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitem_cats = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\n\ntrain.head()\n","e0dedb58":"test.head()","acfaf287":"items.head()","a4b54e7b":"item_cats.head()","f10bea70":"shops.head()","7dc8f98f":"# tekrar eden verileri siliyoruz\nsubset = ['date','date_block_num','shop_id','item_id','item_cnt_day']\nprint(train.duplicated(subset=subset).value_counts())\ntrain.drop_duplicates(subset=subset, inplace=True)","4c43d8a7":"# test datas\u0131nda yer almayan datalar\u0131 e\u011fitimden siliyoruz\ntest_shops = test.shop_id.unique()\ntest_items = test.item_id.unique()\ntrain = train[train.shop_id.isin(test_shops)]\ntrain = train[train.item_id.isin(test_items)]\n","8bfa3afa":"from itertools import product\n\n# datalar\u0131 birle\u015ftiriyoruz\nblock_shop_combi = pd.DataFrame(list(product(np.arange(34), test_shops)), columns=['date_block_num','shop_id'])\nshop_item_combi = pd.DataFrame(list(product(test_shops, test_items)), columns=['shop_id','item_id'])\nall_combi = pd.merge(block_shop_combi, shop_item_combi, on=['shop_id'], how='inner')\nprint(len(all_combi), 34 * len(test_shops) * len(test_items))\n\n# Ayl\u0131k veriler i\u00e7in grupluyoruz\ntrain_base = pd.merge(all_combi, train, on=['date_block_num','shop_id','item_id'], how='left')\ntrain_base['item_cnt_day'].fillna(0, inplace=True)\ntrain_grp = train_base.groupby(['date_block_num','shop_id','item_id'])\ntrain_grp.head()","81702570":"train_monthly = pd.DataFrame(train_grp.agg({'item_cnt_day':['sum','count']})).reset_index()\n#print(train_monthly)\ntrain_monthly.columns = ['date_block_num','shop_id','item_id','item_cnt','item_order']\n#print(train_monthly[['item_cnt','item_order']].describe())\n\nprint(train_monthly.loc[:,['item_cnt']].describe())\n\n# item_cnt -> G\u00fcr\u00fclt\u00fc verilerinden kurtuluyoruz.\n\ntrain_monthly['item_cnt'].clip(0, 20, inplace=True)\nprint(train_monthly.loc[:,['item_cnt']].describe())\n\n\ntrain_monthly.head()\n\nlast_train = train_monthly[['date_block_num','shop_id','item_id','item_order']]","a7311c1f":"X = last_train.iloc[:, :3]\ny = last_train.iloc[:, 3:4]\n\nfrom sklearn.model_selection import train_test_split\n\n# Datay\u0131 test ve e\u011fiti\u00f6 i\u00e7in 2'ye b\u00f6l\u00fcyoruz\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)","925a71ae":"#Model e\u011fitimi\nfrom numpy import loadtxt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n\nmodel = Sequential()\nmodel.add(Dense(8, input_dim=3, activation='relu'))\nmodel.add(Dense(12, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nhistory = model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n\nmodel.fit(X_train, y_train, epochs=10, batch_size=64)\n\n_, accuracy = model.evaluate(X_train, y_train)\nprint('Accuracy: %.2f' % (accuracy*100))\n","ecc09a47":"y_pred = model.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\n\nacc = accuracy_score(y_pred,y_test)\nprint('Test Accuracy:', acc*100)","f69110a9":"history = model.fit(X_train, y_train,validation_data = (X_test,y_test), epochs=10, batch_size=64)","2f52ec34":"print(history.history)\nimport matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","193f09c5":"plt.plot(history.history['loss']) \nplt.plot(history.history['val_loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Test'], loc='upper left') \nplt.show()","b43b3416":"from keras.utils.vis_utils import plot_model\nplot_model(model, show_shapes=True, show_layer_names=True)","41ed1006":"# Preproccess"}}