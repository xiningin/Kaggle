{"cell_type":{"e25a3c44":"code","ecd69874":"code","760cd8bf":"code","6978d179":"code","e6c0d0bc":"code","86af4b76":"code","3ca0fe1a":"code","8e76c0fe":"code","543fb4d5":"code","efdfebd3":"code","1a14b960":"code","9ef26bfd":"code","5cde7304":"code","e4ca99fc":"code","57f2af0a":"code","42a42220":"code","2849842f":"code","d5ae1e7e":"code","4f9d96f7":"code","e74e5d51":"code","f57dfdb4":"code","8d753efc":"code","d7f50edf":"code","35c2f384":"code","4c289fe9":"code","82d06474":"code","305cb6e0":"code","af2ac1eb":"code","f15d934a":"code","7c063e43":"code","ec905c5f":"code","b5b04835":"code","74eccbab":"code","df9d1f9e":"code","d15ee3ab":"code","2449b825":"code","52aa589e":"code","2ee49591":"code","d9b7e2dd":"code","ac2d5d91":"code","af69e0ec":"code","681f4467":"code","baa0850d":"code","68d90a40":"code","3e7e39b9":"code","58987429":"code","3e0949f4":"code","4d85430c":"code","40250f3d":"code","3c635a31":"code","b9eb9549":"code","4a5ccd88":"code","19a207e4":"code","03dc4f2d":"code","6e968962":"code","ba015f1a":"code","a87e96b3":"code","84b60fce":"code","4dfd3ed4":"code","13e6cf3c":"code","9f4c0ba4":"code","f3728206":"code","b894badc":"code","448c8154":"code","891e466b":"code","01459066":"code","672016b0":"code","bd9400e7":"code","7123fbe5":"code","0679954e":"code","58211b96":"code","c7a62991":"code","3a42b398":"code","0b5bac39":"code","e7d92f03":"code","0f75b83b":"code","5dac7c08":"code","4df2e6ba":"code","5f0e961a":"code","762c1964":"code","2b7da405":"code","255ee68f":"code","41ab1331":"code","b0a357eb":"code","321b68f0":"code","4e468221":"code","27effee6":"code","8deaf34a":"code","f63c27a7":"code","eaa0ca1a":"code","e1390f57":"markdown","5a7a9066":"markdown","ba480791":"markdown","db1d3a8e":"markdown","408e51bc":"markdown","c74bdfcc":"markdown","19435b0e":"markdown","d376f637":"markdown","d5044b44":"markdown","e9217490":"markdown","e379ae16":"markdown","a689c050":"markdown","efe3afaa":"markdown","15e5cbc0":"markdown","8008fb7f":"markdown","18b92ac5":"markdown","01a870c2":"markdown","5340299d":"markdown","a2da9f6b":"markdown","22a9c00b":"markdown","6a8a80b6":"markdown","8b636d0b":"markdown","a236ae83":"markdown","d83b006b":"markdown","58017e89":"markdown","30bd3072":"markdown","59d645a2":"markdown"},"source":{"e25a3c44":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ecd69874":"import seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport copy\nimport matplotlib.pyplot as plt\n","760cd8bf":"os.getcwd()","6978d179":"train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","e6c0d0bc":"train.head()","86af4b76":"train.isnull().sum()","3ca0fe1a":"test","8e76c0fe":"test.isnull().sum()","543fb4d5":"all_data = pd.concat([train,test],ignore_index=True)\nall_data","efdfebd3":"all_data.dtypes","1a14b960":"all_data.isnull().sum()","9ef26bfd":"pd.crosstab(all_data.Age,all_data.Survived).plot.bar(stacked=True,figsize=(16,5),color=['tomato','#3d9973'])\nplt.xticks(rotation=60)\nplt.tight_layout()","5cde7304":"age_null = all_data['Age'].apply(lambda x: 'unknown_age' if pd.isnull(x) else 'known')\nage_null\npd.crosstab(age_null,all_data.Survived).plot.bar(stacked=True,figsize=(8,5),color=['tomato','#3d9973'])\nplt.xticks(rotation=60)","e4ca99fc":"all_data['Cabin'].head()\n# pd.pivot_table(all_data,index=['Cabin'],values=['Survived']).plot.bar(figsize=(8,5))","57f2af0a":"all_data['Cabin'].isnull().sum(),all_data['Cabin'].shape[0]","42a42220":"DeckCapital = all_data['Cabin'].apply(lambda x: 'U' if pd.isnull(x) else x[0])\n\npd.crosstab(DeckCapital,all_data.Survived).plot.bar(stacked=True,figsize=(16,5),color=['tomato','#3d9973'])\nplt.xticks(rotation=60)\n\n# plt.figure()\n# cs = pd.crosstab(deck,all_data.Survived)\n# plt.bar(cs.index,cs[:][:],color=['tomato','#3d9973'])\n\nplt.xticks(rotation=60)\nall_data['DeckCapital'] = DeckCapital","2849842f":"deck_exsist = all_data['Cabin'].apply(lambda x: 'unknown' if pd.isnull(x) else 'known')\ndeck_exsist\npd.crosstab(deck_exsist,all_data.Survived).plot.bar(stacked=True,figsize=(8,5),color=['tomato','#3d9973'])\nplt.xticks(rotation=60)\nall_data['DeckExist'] = deck_exsist","d5ae1e7e":"embarked = all_data['Embarked']\nembarked\nprint(embarked.value_counts().index)\npd.crosstab(embarked,all_data.Survived).plot.bar(stacked=True,figsize=(8,5),color=['tomato','#3d9973'])","4f9d96f7":"# fig,axes=plt.subplots(9,3,figsize=(15,8))\n# Sex=['male','female']\n# Embarked = embarked.value_counts().index\n# deckCap =deckCapitial.value_counts().index\n# full = copy.deepcopy(data_dict['o'])\n\n# feature1 = deckCap\n# for i,ax in zip(Sex,axes):\n#     for j,pp in zip(range(1,4),ax):\n#         Combination=full[(full.DeckCapital==i)&(full.Pclass==j)]['Survived'].value_counts().sort_index(ascending=False)\n#         pp.bar(range(len(Combination)),Combination,label=(i,'Class'+str(j)))\n#         pp.set_xticks((0,1))\n#         pp.set_xticklabels(('Survived','Dead'))\n#         pp.legend(bbox_to_anchor=(0.6,1.1))\n# #         plt.tight_layout()","e74e5d51":"pd.crosstab(all_data.Sex,all_data.Survived).plot.bar(stacked=True,figsize=(8,5),color=['tomato','#3d9973'])\nplt.xticks(rotation=0,size='large')\nplt.legend(bbox_to_anchor=(0.55,0.9))","f57dfdb4":"all_data['Pclass'].value_counts()","8d753efc":"pclass = all_data['Pclass'].value_counts()\nplt.bar(range(len(pclass)),pclass,color='tomato')","d7f50edf":"pclass = all_data['Pclass'].value_counts()\npd.crosstab(all_data.Pclass,all_data.Survived).plot.bar(stacked=True,figsize=(8,5),color=['tomato','#3d9973'])","35c2f384":"# plt.bar(all_data['Pclass'],all_data['Survived'],color='tomato')\nsns.countplot(x=\"Pclass\",hue=\"Survived\", data=all_data,palette='bone')\n","4c289fe9":"fig,axes=plt.subplots(2,3,figsize=(15,8))\nSex1=['male','female']\nfor i,ax in zip(Sex1,axes):\n    for j,ax_p in zip(range(1,4),ax):\n        PclassSex=all_data[(all_data.Sex==i)&(all_data.Pclass==j)]['Survived'].value_counts().sort_index(ascending=False)\n        ax_p.bar(range(len(PclassSex)),PclassSex,label=(i,'Class'+str(j)),color=['#3d9973','salmon'])\n        ax_p.set_xticks((0,1))\n        ax_p.set_xticklabels(('Survived','Dead'))\n        ax_p.legend(bbox_to_anchor=(0.6,1.1))\nplt.tight_layout()","82d06474":"def SexPclassConverter(x):\n    ans = '_'.join([str(i) for i in x])\n    return ans\n\ncombine_features = 'Sex:'+ all_data['Sex'].map(str) + '_'+ 'Pclass:'+all_data['Pclass'].map(str)\n\nall_data['SexPclass'] =  combine_features\nprint('ok')\nall_data['SexPclass'].apply(SexPclassConverter)\n# features_dummies = pd.get_dummies(combine_features)\n# features_dummies.loc[0]\nall_data['SexPclass']\ncombine_features","305cb6e0":"all_data['Name'].value_counts()","af2ac1eb":"all_data['Name']","f15d934a":"all_data['Name'][0].split(',')[0]","7c063e43":"LastName = all_data['Name'].apply(lambda x: x.split(',')[1].split('.')[1])\nLastNameValueCnts = LastName.value_counts()\nLastNameCntDict = {key:value for key,value in zip(LastNameValueCnts.index,LastNameValueCnts)}\n\ndef convertLastName(x):\n    return \"small\" if LastNameCntDict[x] <=1 \\\n            else \"medium\" if LastNameCntDict[x] <=4 \\\n            else \"big\" if LastNameCntDict[x] <=6 \\\n            else \"large\"\nLastNameSize = LastName.apply(convertLastName)\nall_data['LastNameSize'] = LastNameSize","ec905c5f":"all_data.loc[(all_data['Parch'] == 0) & (all_data['SibSp'] == 0) & (all_data['Age'] > 14),'LastNameSize'] = 'single'","b5b04835":"pd.crosstab(all_data.LastNameSize,all_data.Survived).plot.bar(stacked=True,figsize=(25,5),color=['tomato','#3d9973'])\nplt.xticks(rotation=60)\nplt.legend(bbox_to_anchor=(0.55,0.9))","74eccbab":"firstName = all_data['Name'].apply(lambda x:x.split(',')[0])\nfirstName.value_counts()\npd.crosstab(firstName,all_data.Survived).plot.bar(stacked=True,figsize=(25,5),color=['tomato','#3d9973'])\nplt.xticks([])\nplt.legend(bbox_to_anchor=(0.55,0.9))","df9d1f9e":"DuplicatedNameValueCnts = all_data['Name'].apply(lambda x:x.split(',')[0]).value_counts()\nFirstNameCntDict = {key:value for key,value in zip(DuplicatedNameValueCnts.index,DuplicatedNameValueCnts)}\nFirstNameCntDict\n\ndef ConvertFirstNameCnt(x):\n    return FirstNameCntDict[x]\n            \nDuplicatedNameCnt = all_data['Name'].apply(lambda x:x.split(',')[0]).apply(ConvertFirstNameCnt)\nall_data['DuplicatedNameCnt'] = DuplicatedNameCnt\npd.crosstab(all_data.DuplicatedNameCnt,all_data.Survived).plot.bar(stacked=True,figsize=(20,5),color=['tomato','#3d9973'])\nplt.xticks(rotation=0)\nplt.legend(bbox_to_anchor=(0.55,0.9))","d15ee3ab":"def splitTitle(x):\n    return x.split(',')[1].split('.')[0][1:]\nTitle = all_data['Name'].apply(splitTitle)\nall_data['Title'] = Title","2449b825":"pd.crosstab(all_data.Title,all_data.Survived).plot.bar(stacked=True,figsize=(16,5),color=['tomato','#3d9973'])\nplt.xticks(rotation=0,size='large')\nplt.legend(bbox_to_anchor=(0.55,0.9))","52aa589e":"all_data.Title[0]","2ee49591":"def ProjectName(x):\n    projects = {'Mlle': 'Miss', \n           'Ms': 'Miss', \n           'Mme': 'Mrs',\n           'Major': 'Other', \n           'Col': 'Other', \n           'Dr' : 'Other', \n           'Rev' : 'Other',\n           'Capt': 'Other', \n           'Jonkheer': 'Royal',\n           'Sir': 'Royal', \n           'Lady': 'Royal', \n           'Don': 'Royal',\n           'Countess': 'Royal', \n           'Dona': 'Royal'}\n    return  projects[x] if x in projects.keys() else x\n\nall_data['Title'] = all_data['Title'].apply(ProjectName)\nprint('done')","d9b7e2dd":"pd.crosstab(all_data.Title,all_data.Survived).plot.bar(stacked=True,figsize=(16,5),color=['tomato','#3d9973'])\nplt.xticks(rotation=0,size='large')\nplt.legend(bbox_to_anchor=(0.55,0.9))","ac2d5d91":"all_data['Last_Name'] = all_data['Name'].apply(lambda x: str.split(x, \",\")[0])\nall_data['Last_Name'].value_counts()\n# AddColumn(data_dict,all_data['Last_Name'],'Last_Name')","af69e0ec":"# ticket_agg = all_data['Ticket'].unique()\n# ticket_agg.shape\nticket = all_data['Ticket']\npd.crosstab(ticket,all_data.Survived).plot.bar(stacked=True,figsize=(16,5),color=['tomato','#3d9973'])\nplt.xticks([])\nplt.legend(bbox_to_anchor=(0.55,0.9))","681f4467":"ticket_agg = all_data['Ticket'].value_counts()\nticket_agg.index\nticket_agg_dict = {key:value for key,value in zip(ticket_agg.index,ticket_agg)}\nlist(ticket_agg_dict.items())[:5]","baa0850d":"ticket_agg = all_data['Ticket'].value_counts()\n# ticket_agg.shape\nticket_common = all_data['Ticket'].apply(lambda x:ticket_agg_dict[x])\npd.crosstab(ticket_common,all_data.Survived).plot.bar(stacked=True,figsize=(16,5),color=['tomato','#3d9973'])\nplt.xlabel('Common Tickets')\nplt.xticks()\nplt.legend(bbox_to_anchor=(0.55,0.9))\nall_data['Common Tickets'] = ticket_common","68d90a40":"FamilySize = all_data['SibSp'] + all_data['Parch'] + 1\npd.crosstab(FamilySize,all_data.Survived).plot.bar(stacked=True,figsize=(16,5),color=['tomato','#3d9973'])\nplt.xlabel('Family Size')","3e7e39b9":"all_data['FamilySize'] = FamilySize","58987429":"from sklearn.impute import KNNImputer,SimpleImputer\n\nselect_columns = ['Title','Age','Cabin','Sex','SibSp','Fare']\nimpute_col = ['Age']\n\nto_fill_X = pd.get_dummies(pd.DataFrame(all_data,columns=select_columns))\nto_fill_Y = pd.DataFrame(all_data,columns=['Survived'])\n\nage_imputer = KNNImputer(n_neighbors=10)\nsimple_imputer = SimpleImputer()\n\nfilled = age_imputer.fit_transform(to_fill_X,to_fill_Y)\n\nfilled = pd.get_dummies(pd.DataFrame(filled,columns=to_fill_X.columns))\n\n# plt.figure(figsize=(16,5))\n# sns.kdeplot(data_dict['o'].Age,color='r')\n# sns.kdeplot(data_dict['s'].Age)\n\n# plt.legend()\nall_data['Age'] = filled['Age']\nall_data['Fare'] = filled['Fare']\n\nprint('null:',all_data.drop(columns=['Survived']).isnull().values.any())\nall_data.isnull().sum()","3e0949f4":"pd.cut(all_data['Age'],bins=5).value_counts()","4d85430c":"k = 10\nAgeSameRange = pd.cut(all_data['Age'],k,labels=range(0,k))\nAgeSameRange\nall_data['AgeSameRange'] = AgeSameRange\nall_data['AgeSameRange']","40250f3d":"MayBeGirlIndex = all_data[(all_data['Age'] < 14) & (all_data['Parch'] !=0) | (all_data['SibSp'] !=0) & (all_data['Sex'] == 'female')].index\nprint(MayBeGirlIndex[0])\nGirls = all_data.loc[MayBeGirlIndex,:] \nGirls['Title'] = 'Girl'\npd.crosstab(all_data.Title,all_data.Survived).plot.bar(stacked=True,figsize=(16,5),color=['tomato','#3d9973'])\n\n# all_data[all_data['Title'] == 'Girl']","3c635a31":"plt.figure(figsize=(16,5))\nsns.histplot(all_data['Fare'],color='orange')","b9eb9549":"q = 8\nFareSameFreq = pd.qcut(np.log(all_data['Fare']),q=q,labels=range(0,q))\n# AddColumn(data_dict,FareSameFreq,'FareSameFreq')\nprint('done')\nall_data['FareSameFreq'] = FareSameFreq","4a5ccd88":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\n\nclass GrakerModel(object):\n    def __init__(self):\n        self.models = {}\n    \n    def ch_current_model(self,name):\n        self.current_model_name = name\n        self.current_model = self.models[self.current_model_name]\n        \n    def fit(self,*args,**kwargs):\n        return self.current_model.fit(*args,**kwargs)\n    \n    def predict(self,*args,**kwargs):\n        return self.current_model.predict(*args,**kwargs)\n    \n    def getCurrentModel(self):\n        return self.current_model\nmodels = GrakerModel()\nmodels.models['kNN'] = KNeighborsClassifier(n_neighbors=10)\n\n# models.models['LR'] = LogisticRegression()\n\nmodels.models['RF'] = RandomForestClassifier(n_estimators=700,max_depth=4,max_leaf_nodes=300)\n\nmodels.models['GBDT'] = GradientBoostingClassifier(n_estimators=1000,max_depth=5)\n\ncatboost_param = dict(n_estimators=100,\n                      depth=3,\n                     learning_rate=0.01,\n                      early_stopping_rounds=200,\n                     verbose=False)\nmodels.models['catboost'] = CatBoostClassifier(**catboost_param)\n\nxgb_param = dict(n_estimators=500,\n                max_depth =8,\n                eta=0.1,\n                use_label_encoder=False)\nmodels.models['xgb'] = XGBClassifier(**xgb_param)\nmodels.models.keys()","19a207e4":"# SSE = []  # \u5b58\u653e\u6bcf\u6b21\u7ed3\u679c\u7684\u8bef\u5dee\u5e73\u65b9\u548c\n# K = range(1, 20)\n# data = data_dict['s'].drop(columns=['Survived'])\n\n# for k in K:\n#     estimator = KMeans(n_clusters=k)  # \u6784\u9020\u805a\u7c7b\u5668\n#     estimator.fit(data)\n#     SSE.append(estimator.inertia_)\n# plt.xlabel('k')\n# plt.ylabel('SSE')\n# plt.plot(K, SSE, 'o-')\n# plt.show()","03dc4f2d":"# from sklearn.cluster import KMeans\n# k_cls = KMeans(n_clusters=6)\n# k_cls.fit(data)\n# k_cls.cluster_centers_\n# cluster_pred =k_cls.predict(data).reshape(-1)\n# cluster_pred.shape\n# AddColumn(data_dict,cluster_pred,'Cluster')\n# print('done')","6e968962":"all_data.isnull().sum()","ba015f1a":"all_data['FamilySize']","a87e96b3":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\n\ndef getFromAll(data,sets=\"train\",tensorlize=False):\n    if sets == 'train':\n        Sets = data[data['Survived'].notnull()]\n        X = Sets.drop(columns=[\"Survived\"])\n    else:\n        Sets = data[data['Survived'].isnull()]\n        X = Sets.copy()\n        print(X.head())\n    \n    print(Sets.columns)\n    \n    Id = all_data['PassengerId']\n    \n    Y = np.array(Sets['Survived']).reshape(-1)\n    if tensorlize == True:\n        Y = Y.reshape(-1,1)\n    return (X,Y),Id\n\ndef ConvertAllData(data):\n    dataSet = pd.get_dummies(data)\n    return dataSet\n\n\n_features = [\"Survived\",\"Pclass\", \n             \"Age\",'AgeSameRange',\n             'Title','SexPclass','Embarked','FareSameFreq',\n             'DeckCapital',\n             'FamilySize',\n             'DuplicatedNameCnt',\n             'LastNameSize',\n             'Common Tickets']\n\nDataset = ConvertAllData(all_data[_features])\n\nTrain_data,Train_Id = getFromAll(Dataset)\n\nX,Y = Train_data\nX.shape","84b60fce":"X","4dfd3ed4":"from sklearn.preprocessing import StandardScaler\n\n\n# X_test_scaled=scaler.fit(X).transform(test_X)\n\n# from imblearn.over_sampling import SMOTE\n\n# \u5b9a\u4e49SMOTE\u6a21\u578b\uff0crandom_state\u76f8\u5f53\u4e8e\u968f\u673a\u6570\u79cd\u5b50\u7684\u4f5c\u7528\n# smo = SMOTE(random_state=42)\n# X_smo, y_smo = smo.fit_resample(X, Y)\n# X = X_smo\n# Y = y_smo\n# Y\nY = Y.reshape(-1)\nprint(Y.shape)\n\nX_train,X_val,Y_train,Y_val = train_test_split(X,Y,test_size=0.0001,random_state=32,shuffle=True)\n\nx_scaler = StandardScaler()\n\nx_scaler.fit(X_train)\nX_train_scaled = x_scaler.transform(X_train)\nX_val_scaled = x_scaler.transform(X_val)\n\n# print(np.sum(y_val==1),y_val.shape[0])\n# print(np.sum(y_train==1),y_train.shape[0])\n# print(y_val.shape)","13e6cf3c":"x_scaler.transform(X_train)","9f4c0ba4":"def showMetricsOnClassify(model,X_to_pred,y_true):\n    y_pred = model.predict(X_to_pred)\n    \n    print('validation accuracy:',accuracy_score(y_true, y_pred))  \n    c = confusion_matrix(y_true,y_pred)\n    sns.heatmap(c,annot=True)\n\n    scores = cross_val_score(model, x_scaler.transform(X), Y, cv=5)\n    \n    print(f'cross score:\\n{scores},\\nmean:%0.3f +-%0.3f' % (scores.mean(),scores.std()))\n    print ('ROC AUC on validaiton: %0.3f' % model.score(X_to_pred, y_true))","f3728206":"from sklearn.model_selection import cross_val_score\n\nmodels.ch_current_model('RF')\nmodel = models.getCurrentModel()\n\nmodel.fit(X_train_scaled,Y_train)\n\n%time\n\nshowMetricsOnClassify(model,X_val_scaled,Y_val)\n\nrf_train_pred = model.predict(X_train_scaled).reshape(-1,1)\nrf_val_pred = model.predict(X_val_scaled).reshape(-1,1)","b894badc":"print ('ROC AUC on train: %0.3f' % model.score(X_train_scaled, Y_train))\nprint ('ROC AUC on validaiton: %0.3f' % model.score(X_val_scaled, Y_val))\nprint ('ROC AUC on all: %0.3f' % model.score(x_scaler.transform(X), Y))","448c8154":"from sklearn.model_selection import GridSearchCV\n# \u9700\u8c03\u53c2\u6570\u53ca\u5019\u9009\u503c\n\nmodel = RandomForestClassifier()\nparameters = {\n    'max_depth': list(range(3,8)), \n    'n_estimators': list(range(500,1000,200))\n}\n\n# \u8bc4\u4ef7\u4f9d\u636e\n# https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html#scoring-parameter\nscores = {\n    'acc': 'accuracy',         # \u51c6\u786e\u7387\n}\n\n# \u7f51\u683c\u641c\u7d22\u5b9e\u4f8b\ngs = GridSearchCV(\n    model,\n    parameters,\n    cv=5,                      # \u4ea4\u53c9\u9a8c\u8bc1\u6570\n    scoring=scores,            # \u8bc4\u4ef7\u6307\u6807\n    refit=False,             # \u5728\u6b64\u6307\u6807\u4e0b\uff0c\u7528\u6700\u4f18\u8868\u73b0\u7684\u53c2\u6570\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\n    return_train_score=True,   # gs.cv_results_\u989d\u5916\u4fdd\u5b58\u8bad\u7ec3\u96c6\u7684\u8bc4\u4ef7\u7ed3\u679c\n    verbose=1,                 # \u65e5\u5fd7\u4fe1\u606f\uff0c\u9ed8\u8ba40\u4e0d\u8f93\u51fa\n    n_jobs=3                   # \u5e76\u884c\u52a0\u901f\n)\n\n# \u4e00\u5171\u8981\u8dd1\u7684\u4efb\u52a1\u6570=\u53c2\u65701\u5019\u9009\u503c*...*\u53c2\u6570i\u5019\u9009\u503c*\u4ea4\u53c9\u9a8c\u8bc1\u6570\n# \u8fd9\u91cc\u5c31\u662f3*2*5=30\ngs.fit(X_train_scaled, Y_train)","891e466b":"gs.cv_results_","01459066":"new_X_val = model.apply(X_val)\nnew_X_train = model.apply(X_train)\n\nnew_X_val.shape\nx_train = new_X_train\nx_val = new_X_val","672016b0":"from sklearn.tree import DecisionTreeClassifier\ndc_clf = DecisionTreeClassifier(random_state=30,\n                                max_depth=5,min_samples_leaf=10,\n                               min_samples_split=19)\nmodels.models['DT'] = dc_clf\ndc_clf.fit(X_train_scaled,Y_train)\ntrain_score = dc_clf.score(X_val_scaled,Y_val)\ntrain_score\n","bd9400e7":"import tensorflow as tf\nimport tensorflow.keras.backend as K\ndef binary_focal_loss(gamma=2, alpha=0.25):\n    \"\"\"\n    Binary form of focal loss.\n    \u9002\u7528\u4e8e\u4e8c\u5206\u7c7b\u95ee\u9898\u7684focal loss\n    \n    focal_loss(p_t) = -alpha_t * (1 - p_t)**gamma * log(p_t)\n        where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n    References:\n        https:\/\/arxiv.org\/pdf\/1708.02002.pdf\n    Usage:\n     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n    \"\"\"\n    alpha = tf.constant(alpha, dtype=tf.float32)\n    gamma = tf.constant(gamma, dtype=tf.float32)\n\n    def binary_focal_loss_fixed(y_true, y_pred):\n        \"\"\"\n        y_true shape need be (None,1)\n        y_pred need be compute after sigmoid\n        \"\"\"\n        y_true = tf.cast(y_true, tf.float32)\n        alpha_t = y_true*alpha + (K.ones_like(y_true)-y_true)*(1-alpha)\n    \n        p_t = y_true*y_pred + (K.ones_like(y_true)-y_true)*(K.ones_like(y_true)-y_pred) + K.epsilon()\n        focal_loss = - alpha_t * K.pow((K.ones_like(y_true)-p_t),gamma) * K.log(p_t)\n        return K.mean(focal_loss)\n    return binary_focal_loss_fixed","7123fbe5":"from sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.utils import to_categorical\n\nminmax_scaler = MinMaxScaler()\n\nx_train = X_train_scaled\nx_val = X_val_scaled\n\n\ny_train = to_categorical(Y_train)\ny_val = to_categorical(Y_val)\n\ny_train.shape","0679954e":"FillAgeX_data = all_data[all_data['AgeSameRange'].notnull()][['AgeSameRange',\n                                                              'Title',\n                                                     'SibSp','Parch',\n                                                     'Sex','Pclass',\n                                                     'Embarked','Common Tickets']]\nFillAge = FillAgeX_data['AgeSameRange']\nFillAge = to_categorical(FillAge)\n\n\nFillAgeX = ConvertAllData(FillAgeX_data.drop(columns=['AgeSameRange']))\nx_scaler = MinMaxScaler()\nFillAgeX_scaled = x_scaler.fit_transform(FillAgeX)\n\nFillAgeX_train,FillAgeX_val,Age_train,Age_val = train_test_split(FillAgeX_scaled,FillAge,test_size=0.2)\ninput_shape = FillAgeX_train.shape[1]","58211b96":"# from sklearn.model_selection import cross_val_score\n# from sklearn.metrics import mean_absolute_error\n\n# from catboost import CatBoostRegressor\n# from xgboost import XGBRegressor\n# from sklearn.tree import DecisionTreeRegressor\n\n# model =  CatBoostClassifier(n_estimators=500,depth=5,early_stopping_rounds=50,verbose=0)# DecisionTreeRegressor(max_depth=50,splitter='random',min_samples_leaf=1)\n# # models.ch_current_model('RF')\n# # model = models.getCurrentModel()\n\n# model.fit(FillAgeX_train,Age_train)\n# y_pred = model.predict(FillAgeX_val)\n# y_true = Age_val\n\n# print('acc:',accuracy_score(y_true, y_pred))  \n# # c = confusion_matrix(y_true,y_pred)\n# # sns.heatmap(c,annot=True)\n\n# # scores = cross_val_score(model, X, Y, cv=10)\n# # print('mean score:',scores.mean())\n# print ('MAE: %0.3f' % mean_absolute_error(y_pred, y_true))\n# # y_pred,y_true","c7a62991":"# def predictAgeModel(input_shape):\n#     inputs = Input((input_shape))\n#     x = BatchNormalization()(inputs)\n    \n#     x = Dropout(0.5)(x)\n    \n#     x = Dense(300,kernel_initializer='he_uniform',activation='relu')(x)\n\n#     x = Dense(300,kernel_initializer='he_uniform',activation='relu')(x)\n#     x = BatchNormalization()(x)\n#     x = Dropout(0.5)(x)\n    \n#     x = Dense(500,kernel_initializer='he_uniform',activation='relu')(x)\n#     x = BatchNormalization()(x)\n#     x = Dropout(0.5)(x)\n    \n#     output = Dense(10,activation='softmax')(x)\n    \n#     nn_model =  keras.Model(inputs=inputs,outputs=output)\n    \n#     nn_model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adam(),metrics=['acc']) \n#     # 'categorical_crossentropy'\n#     # [binary_focal_loss(gamma=3, alpha=0.6)]\n#     return nn_model\n# AgeFillmodel = predictAgeModel(input_shape)\n# AgeFillmodel.summary()","3a42b398":"# AgeFillmodel.fit(FillAgeX_train,Age_train,validation_data=(FillAgeX_val,Age_val),\n#                  epochs=200,batch_size=32,\n#                  callbacks=[early_stopping,reduce_lr])","0b5bac39":"class ResidualDense(keras.layers.Layer):\n    def __init__(self,units,strides=2,hidden_units=50,activation='relu',**kwargs):\n        super().__init__(**kwargs)\n        self.activation = keras.activations.get(activation)\n        self.main_layers = [\n            keras.layers.Dense(hidden_units,kernel_initializer='he_uniform',use_bias=False),\n            keras.layers.BatchNormalization(),\n            self.activation,\n            keras.layers.Dense(units,use_bias=False,kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l1(0.001)),\n            keras.layers.BatchNormalization()\n        ]\n        self.skip_layers = []\n        if strides > 1:\n            self.skip_layers = [\n                keras.layers.Dense(units,use_bias=False),\n                keras.layers.BatchNormalization()\n            ]\n    \n    def call(self,inputs):\n        Z = inputs\n        for layer in self.main_layers:\n            Z = layer(Z)\n        skip_Z = inputs\n        for layer in self.skip_layers:\n            skip_Z = layer(skip_Z)\n        return self.activation(Z + skip_Z)","e7d92f03":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import *\n\n\ndef baseModel(output_shape=None):\n    if output_shape is None:\n        output_shape = 2\n    inputs = Input((x_train.shape[1]))\n    inputs2 = Input((1))\n\n    x = LayerNormalization()(inputs)\n#     x = Dense(500,kernel_initializer='he_uniform',activation='sigmoid',\n#               kernel_regularizer=keras.regularizers.l1(0.001))(x)\n#     x = Dropout(0.5)(x)\n\n#     x = ResidualDense(100)(x)\n#     x = Dropout(0.5)(x)\n\n\n# #     x = Dense(100,kernel_initializer='he_uniform',activation='relu',kernel_regularizer=keras.regularizers.l1(0.001))(x)\n#     x = ResidualDense(50)(x)\n\n\n#     x = ResidualDense(30,activation='sigmoid')(x)\n#     x = BatchNormalization()(x)\n\n#     x = Dropout(0.7)(x)\n    \n#     x = Flatten()(x)\n    x = Dense(100,activation='relu',kernel_regularizer=keras.regularizers.l1(0.001))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(1,activation='relu')(x)\n    x = Add()([inputs2,x])\n    x = Dense(100,activation='relu',kernel_regularizer=keras.regularizers.l1(0.001))(x)\n\n    output = Dense(1,activation='sigmoid')(x)\n     \n    nn_model =  keras.Model(inputs=[inputs,inputs2],outputs=output)\n    \n    nn_model.compile(loss='binary_crossentropy',optimizer=keras.optimizers.Adam(),metrics=['acc']) \n    # 'categorical_crossentropy'\n    # [binary_focal_loss(gamma=3, alpha=0.6)]\n    return nn_model\nnn_model = baseModel()\nnn_model.summary()","0f75b83b":"y_train","5dac7c08":"early_stopping = tf.keras.callbacks.EarlyStopping(patience=100, monitor='val_loss')\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n                        patience=5, mode='auto',\n                        verbose=1)\n\nhistory = nn_model.fit((x_train,rf_train_pred),Y_train,validation_data=((x_val,rf_val_pred),Y_val),\n                       batch_size=128,\n                       epochs=500,\n                      callbacks=[early_stopping,reduce_lr])","4df2e6ba":"plt.figure(figsize=(16,5))\nplt.subplot(121)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.subplot(122)\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.tight_layout()\nprint(nn_model.evaluate(x_val,y_val))\nprint(nn_model.evaluate(x_train,y_train))","5f0e961a":"# from sklearn.model_selection import StratifiedKFold\n# split = 10\n# accuracy = []\n# losses = []\n# for train_idx,test_idx in StratifiedKFold(split,shuffle=True).split(X,Y):\n# #     print(train_idx)\n#     x_train,x_test = X.loc[train_idx],X.loc[test_idx]\n#     x_train = minmax_scaler.transform(X_train)\n#     x_test = minmax_scaler.transform(X_test)\n#     y_train,y_test = YY[train_idx],YY[test_idx]\n#     Kmodel = create_model()\n#     Kmodel.fit(X_train,y_train,batch_size=32,epochs=200,verbose=False)\n#     loss = Kmodel.evaluate(X_test,y_test)[0]\n\n#     acc = Kmodel.evaluate(X_test,y_test)[1]\n#     losses.append(loss)\n#     accuracy.append(acc)\n#     print(f'current accuracy:{acc},label 1:{np.sum(np.argmax(y_test,axis=1) == 1)}\/{y_test.shape[0]}')\n# plt.plot(losses)\n# plt.plot(accuracy)\n# print(f'average score:{np.mean(accuracy)}')","762c1964":"def metrics(y_true,y_pred):\n    y_true = y_true.reshape(-1,1)\n    y_pred = y_pred.reshape(-1,1)\n    print('acc:',accuracy_score(y_true, y_pred))  \n    c = confusion_matrix(y_true,y_pred)\n    sns.heatmap(c,annot=True)","2b7da405":"def convertLabel(y_val_pred):\n    if len(y_val_pred.shape) == 1:\n        return np.array(y_val_pred >= 0.5,dtype=int)\n    else:\n        return np.argmax(y_val_pred,axis=1)\n","255ee68f":"\ny_pred = nn_model.predict(x_val)\ny_pred = convertLabel(y_pred)\ny_true = convertLabel(y_val)\n\nmetrics(y_true,y_pred)","41ab1331":"models.models.keys()","b0a357eb":"Y_train","321b68f0":"from sklearn.ensemble import AdaBoostClassifier\n\nada = AdaBoostClassifier(n_estimators=500,learning_rate=0.5)\nada.fit(X_train,Y_train)\ntrain_score = ada.score(X_val,Y_val)\ntrain_score\nmodels.models['ada']= ada","4e468221":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import cross_val_score\n\nvote_clfs = VotingClassifier(estimators=[(key,model) for key,model in models.models.items()], voting='hard')\nvote_clfs.fit(X_train_scaled,Y_train)\n\nfor label,clf in zip([*models.models.keys(),'vote'],[*models.models.values(),vote_clfs]):\n    scores = cross_val_score(clf, X_val_scaled, Y_val, cv=5, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+\/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n","27effee6":"# X_test = minmax_scaler.transform(X_test)","8deaf34a":"pred","f63c27a7":"# models\nmodels.ch_current_model('RF')\nsubmit_model =  models.getCurrentModel() # vote_clfs #  #nn_model # vote_clfs # #  \n\n\ntest = Dataset[Dataset['Survived'].isnull()]\nX_test = test.drop(columns=['Survived'])\nTest_Id = all_data[all_data['Survived'].isnull()]['PassengerId']\n\nX_test = x_scaler.transform(X_test)\n\npred = submit_model.predict(X_test)\npredictions = convertLabel(pred).reshape(-1)\nsubmission = pd.DataFrame({'PassengerId': Test_Id, 'Survived': predictions}).astype(int)","eaa0ca1a":"submission.to_csv('.\/submission.csv',index=False)\nprint(np.sum(submission['Survived'] == 1))\nsubmission","e1390f57":"\u4e70\u5355\u7968\u7684\u4eba\u6bd4\u8f83\u591a\uff0c\u6b7b\u7684\u4e5f\u6bd4\u8f83\u591a\u3002","5a7a9066":"## Cabin\u7279\u5f81\uff08\u7532\u677f\u53f7\uff09","ba480791":"## \u67e5\u770b\u7279\u5f81\u7c7b\u578b","db1d3a8e":"## Fare\u7279\u5f81","408e51bc":"## \u586b\u8865Age","c74bdfcc":"\u5229\u7528value_counts\u5f97\u5230\u6240\u6709\u53d6\u503c","19435b0e":"## \u6570\u636e\u5206\u6790","d376f637":"\u6ca1\u6709\u91cd\u540d\u7684\u4eba\u6b7b\u7684\u5f88\u591a\uff1f","d5044b44":"\u90a3\u4e48\u53ef\u4ee5\u5bf9Cabin\u7684\u6709\u65e0\u4f5c\u4e3a\u7279\u5f81","e9217490":"\u90a3\u4e48\u8fd9\u4e2a\u7ec4\u5408\u7279\u5f81\u4e0d\u9519","e379ae16":"\u5973\u4eba\u7684\u5e78\u5b58\u6570\u5927\u4e8e\u7537\u4eba","a689c050":"\u4f7f\u7528KNNimputer\u5bf9\u5e74\u9f84\u7f3a\u5931\u503c\u586b\u8865","efe3afaa":"# \u8bfb\u5165\u6570\u636e","15e5cbc0":"countplot\u7684palette\u53c2\u6570\u8bbe\u7f6e\u8c03\u8272\u677f\uff0chue\u4e3a\u76ee\u6807\uff08y)","8008fb7f":"# \u5efa\u6a21","18b92ac5":"\u53ef\u89c1\u5ba2\u8231\u7b49\u7ea7\u5bf9\u4e8e\u5b58\u6d3b\u4e0e\u5426\u8fd8\u662f\u6709\u533a\u5206\u5ea6\u7684","01a870c2":"\u90a3\u4e48Pclass\u5bf9survived\u9884\u6d4b\u6709\u4e00\u5b9a\u533a\u5206\u5ea6\u3002","5340299d":"# Submit","a2da9f6b":"## \u8f6c\u6362\u540d\u5b57","22a9c00b":"## \u6a21\u578b\u7ec4","6a8a80b6":"![image.png](attachment:09d55437-8140-45d0-a8c7-4956d21d51f8.png)","8b636d0b":"\u6211\u8ba4\u4e3a\u7532\u677f\u5e76\u4e0d\u662f\u6709\u7f3a\u5931\u503c\u3002\u800c\u662f\u7f3a\u5931\u503c\u4e5f\u662f\u4e00\u79cd\u7279\u5f81","a236ae83":"\u79c1\u8ba4\u4e3a\uff0c\u5e74\u9f84\u4e0e\u6027\u522b\u5e94\u8be5\u662f\u8d77\u751f\u8fd8\u7684\u4e3b\u5bfc\u4f5c\u7528","d83b006b":"Fare\u504f\u5cf0\u4e25\u91cd\uff0c\u79bb\u6563\u5316\u65f6\uff0c\u5e94\u6309\u9891\u6570\u5212\u5206\uff0c\u800c\u4e0d\u662f\u503c\u7b49\u8ddd\u3002\u4e8b\u5b9e\u4e5f\u8bc1\u660e\uff0c\u5bf9\u5176\u4f7f\u7528cut\u6548\u679c\u5e76\u4e0d\u597d","58017e89":"## \u5171\u7968","30bd3072":"1309\u6761\u6570\u636e\uff0c\u7532\u677f\u67091014\u6761\u7f3a\u5931\u503c\u3002","59d645a2":"\u90a3\u4e48\u7532\u677f\u53f7\uff08\u533a\u57df\uff09\u8fd8\u662f\u6709\u4e00\u5b9a\u533a\u5206\u5ea6\u7684"}}