{"cell_type":{"979d2afd":"code","c4f9466f":"code","4ae2074b":"code","1ca4049c":"code","23487b73":"code","c0aeaa16":"code","b4e8f7ba":"code","5af515f7":"code","532c4c28":"code","2cda04e9":"code","63955ea6":"code","b0aea4f9":"code","a2353ec3":"code","9f20a7c5":"code","f34ea429":"code","8d5ea752":"code","21cbbfd6":"markdown","209c9b41":"markdown","9d892531":"markdown","4e716608":"markdown","ba75912f":"markdown","e1874431":"markdown","cef63da4":"markdown","bbf81d87":"markdown","61860507":"markdown","5ec9cf87":"markdown","e5307dc0":"markdown","d57ba2f1":"markdown","91c97d40":"markdown","ef38a1bf":"markdown","41ce5f7a":"markdown","6b83c8b7":"markdown","d9768211":"markdown","5877d12d":"markdown","1479c3c4":"markdown","5c813a75":"markdown","300bbc54":"markdown","4f56d876":"markdown","5419cf2f":"markdown","d80e94bb":"markdown","4ec339d3":"markdown"},"source":{"979d2afd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\nimport requests\nimport json\nfrom shapely import geometry\nfrom datetime import datetime\nfrom ipywidgets import interactive\nimport warnings\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.cluster import KMeans\nimport plotly.express as px\nimport random\n\n\nwarnings.filterwarnings('ignore')\nplt.style.use(\"ggplot\")","c4f9466f":"survey = pd.read_csv('\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv').iloc[1:,:]\nsurvey.head(2)","4ae2074b":"survey['Q15'] = survey['Q15'].fillna(0)\n\nQ15_dict = {'1-2 years':'3. 1-2 years', \n 'I do not use machine learning methods':'1. No ML', \n '3-4 years':\"5. 3-4 years\",\n  0:\"No Answer\", \n 'Under 1 year':'2. <1 year', \n '2-3 years':\"4. 2-3 years\", \n '4-5 years':\"6. 4-5 years\", \n '5-10 years':\"7. 5-10 years\",\n '20 or more years':\"9: 20+ years\", \n '10-20 years':\"8. 10-20 years\"}\n\nsurvey['Q15'] = [Q15_dict[k] for k in survey['Q15']]\n\nsurvey['Q6'] = survey['Q6'].fillna(0)\n\nQ6_dict = {'5-10 years': '5. 5-10 years', \n           '10-20 years': '6. 10-20 years', \n           '3-5 years': '4. 3-5 years', \n           '< 1 years': '2. <1 years', \n           '1-2 years': '3. 1-2 years',\n           '20+ years': '7. 20+ years', \n           'I have never written code':'1. No Coding', \n           0: '8. No Answer'}\n\nsurvey['Q6'] = [Q6_dict[k] for k in survey['Q6']]\n\nQ15_cnt = survey[['Q15','Q3']].groupby('Q15').count()\nQ6_cnt = survey[['Q6','Q3']].groupby('Q6').count()\nQ6_Q15_cnt = survey[['Q15','Q6','Q3']].groupby(['Q6', 'Q15']).count().reset_index().pivot('Q6', 'Q15', 'Q3').fillna(0)","1ca4049c":"fig, ax = plt.subplots(1, 3, figsize=[24,5], dpi=100)\n\nax[0].bar(Q15_cnt.index, Q15_cnt.Q3, color='#35D3DE')\nax[0].tick_params('x', rotation=90)\nax[0].title.set_text(\"Coding experience\")\n\nax[1].bar(Q6_cnt.index, Q6_cnt.Q3, color='#00A8BA')\nax[1].tick_params('x', rotation=90)\nax[1].title.set_text(\"Machine Learning experience\")\n\nax[2].matshow(Q6_Q15_cnt, cmap='GnBu')\nax[2].set_xticks(np.arange(len(Q6_Q15_cnt.columns)))\nax[2].set_yticks(np.arange(len(Q6_Q15_cnt.index)))\nax[2].set_xticklabels(Q6_Q15_cnt.columns, rotation=90)\nax[2].set_yticklabels(Q6_Q15_cnt.index)\nax[2].set_ylabel(\"Coding experience\")\nax[2].set_xlabel(\"ML experience\")\nax[2].grid(False)\n\nplt.show()","23487b73":"survey['Q5'] = survey['Q5'].fillna(\"Unknown\")\n\nQ5_dict = {'Student': '02. Student', \n           'Data Engineer':\"11. Data Engineer\", \n           'Software Engineer':\"09. Software Engineer\", \n           'Data Scientist':\"10. Data Scientist\",\n           'Data Analyst': '05. Data Analyst', \n           'Research Scientist': \"08. Research Scientist\", \n           'Other':\"13. Other\",\n           'Currently not employed': '01. Not employed', \n           'Statistician': \"06. Statistician\",\n           'Product\/Project Manager': \"04. Product\/Project Manager\", \n           'Machine Learning Engineer':\"12. ML Engineer\", \n           'Unknown':\"14. Unknown\",\n           'Business Analyst': \"03. Business Analyst\", \n           'DBA\/Database Engineer':\"07. DBA\"}\n\nsurvey['Q5'] = [Q5_dict[k] for k in survey['Q5']]\n\nQ5_Q6_Q15 = survey[['Q5', 'Q15', 'Q6','Q3']].dropna()\n\ncur_roles = np.delete(Q5_Q6_Q15.Q5.unique(), [6, 7, 11])\n\nfig, ax = plt.subplots(4,3, figsize=(18,20), dpi=100)\n\naxis = [(j, i) for j in range(4) for i in range(3)]\n\nfor a, i in zip(axis, cur_roles):\n    data = Q5_Q6_Q15[Q5_Q6_Q15.Q5 == i].groupby(['Q15','Q6']).count().reset_index().pivot('Q6','Q15','Q3').fillna(0).astype('int')\n    \n    ax[a[0]][a[1]].matshow(data, cmap='GnBu')\n    ax[a[0]][a[1]].set_xticks(np.arange(len(data.columns)))\n    ax[a[0]][a[1]].set_yticks(np.arange(len(data.index)))\n    ax[a[0]][a[1]].grid(False)\n    ax[a[0]][a[1]].set_title(i, y=-0.1)\n        \n    if a in [(0,0)]:\n        ax[a[0]][a[1]].set_xticklabels(data.columns, rotation=90)\n        ax[a[0]][a[1]].set_yticklabels(data.index)\n\n    elif a in [(0,1), (0,2)]:\n        ax[a[0]][a[1]].set_xticklabels(data.columns, rotation=90)\n        ax[a[0]][a[1]].set_yticklabels([])\n        \n    elif a in [(1,0), (2,0), (3,0)]:\n        ax[a[0]][a[1]].set_xticklabels([])\n        ax[a[0]][a[1]].set_yticklabels(data.index)\n    \n    else:\n        ax[a[0]][a[1]].set_xticklabels([])\n        ax[a[0]][a[1]].set_yticklabels([])\n        \n\nplt.show()","c0aeaa16":"recom = ['Q5']\n\nfor q in ['Q7','Q8']:\n    cols = survey.columns[survey.columns.str.find(q,0) == 0]\n    recom += list(cols)\nsurvey_lan = survey[recom]\nsurvey_lan.rename(columns={'Q7_Part_1':'Python', \n                       'Q7_Part_2':'R', \n                       'Q7_Part_3':'SQL', \n                       'Q7_Part_4':'C', \n                       'Q7_Part_5':'C++', \n                       'Q7_Part_6':'Java', \n                       'Q7_Part_7':'Javascript', \n                       'Q7_Part_8':'Julia', \n                       'Q7_Part_9':'Swift', \n                       'Q7_Part_10':'Bash', \n                       'Q7_Part_11':'MATLAB', \n                       'Q7_Part_12':'None', \n                       'Q7_OTHER':'Other'}, inplace=True)\n\nsurvey_lan.drop(['None','Other'],inplace=True, axis=1)\n\nsank = survey_lan.groupby(['Q5','Q8']).count().reset_index()\nsank = sank[(sank.Q8 !='None') &(sank.Q8 != 'Other')]","b4e8f7ba":"lan_num = survey_lan.drop('Q8', axis=1)\\\n.set_index('Q5')\\\n.count(axis=1)\\\n.reset_index()\\\n.rename(columns={0:\"#prog\"})\\\n.dropna()\n\ncut_bins = [0, 1, 2, 3, 4, 11]\nbin_label = [\"1 PL\", \"2 PLs\", \"3 PLs\", \"4 PLs\",\"5< PLs\"]\nlan_num['prog_interval'] = pd.cut(lan_num['#prog'], bins=cut_bins, labels=bin_label)\n\nlan_num = lan_num.groupby(['Q5', 'prog_interval']).count().reset_index().pivot('Q5','prog_interval', '#prog').dropna()\n\ndef perc(x):\n    return (x*2000\/sum(x)).astype('int')\n\nfor row in range(lan_num.shape[0]):\n    lan_num.iloc[row,:] = perc(lan_num.iloc[row,:])\n    \nplt.style.use('seaborn-white')\n\nfig = plt.figure(figsize=(6, 13), dpi=200)\n\ngs = fig.add_gridspec(5, 4)\n\nax_plot = fig.add_subplot(gs[1:4, 0:4]) \nfor cur in lan_num.index[::-1]:\n    for bl in bin_label:\n        val = lan_num.loc[cur, bl]\n        if val > 500:\n            ax_plot.scatter(bl, cur, s=val, color='#35D3DE')\n        else:\n            ax_plot.scatter(bl, cur, s=val, color='#C0C0C0')\n        \nax_plot.grid(linewidth=0.2, zorder=0)","5af515f7":"current_role = ['02. Student', \"03. Business Analyst\", \"04. Product\/Project Manager\",'05. Data Analyst', \"06. Statistician\",\"07. DBA\",\"08. Research Scientist\", \"09. Software Engineer\", \"10. Data Scientist\",\"11. Data Engineer\", \"12. ML Engineer\"]\nfig = make_subplots(\n    rows=3, cols=4,\n    specs=[[{\"type\": \"sankey\"}, {\"type\": \"sankey\"},{\"type\": \"sankey\"}, {\"type\": \"sankey\"}], \n       [{\"type\": \"sankey\"},{\"type\": \"sankey\"}, {\"type\": \"sankey\"}, {\"type\": \"sankey\"}],\n       [{\"type\": \"sankey\"}, {\"type\": \"sankey\"}, {\"type\": \"sankey\"}, {\"type\": \"sankey\"}]\n      ],\n    subplot_titles=(current_role),\n)\n\naxis = [(j, i) for j in range(1,4) for i in range(1,5)]\n\nfor ax, role in zip(axis,range(len(current_role))):\n\n    sank_ba = sank[sank.Q5 == current_role[role]].drop('Q5',axis=1).set_index('Q8')\n\n    source = []\n    target = []\n    value = []\n    color_link = []\n\n    color= [\"rgba(31, 119, 180, 0.4)\",\n            \"rgba(255, 127, 14, 0.4)\",\n            \"rgba(44, 160, 44, 0.4)\",\n            \"rgba(214, 39, 40, 0.4)\",\n            \"rgba(148, 103, 189, 0.4)\",\n            \"rgba(140, 86, 75, 0.4)\",\n            \"rgba(227, 119, 194, 0.4)\",\n            \"rgba(127, 127, 127, 0.4)\",\n            \"rgba(188, 189, 34, 0.4)\",\n            \"rgba(23, 190, 207, 0.4)\",\n            \"rgba(31, 119, 180, 0.4)\"]\n\n    for row in sank_ba.iterrows():\n        ind_t = row[0]\n        row_values = row[1]\n        ind_s = row_values.index\n\n        for c in range(len(row_values)):\n            if row_values[c] > 0:\n                source.append(ind_s[c])\n                value.append(row_values[c])\n                target.append(ind_t)\n                color_link.append(color[c])\n\n    source_dict = {'Python':0, 'R':1, 'SQL':2, 'C':3, 'C++':4, 'Java':5, 'Javascript':6, 'Julia':7, 'Swift':8, 'Bash':9, 'MATLAB':10}\n\n    target_dict = {'Python':11, 'R':12, 'SQL':13, 'C':14, 'C++':15, 'Java':16, 'Javascript':17, 'Julia':18, 'Swift':19, 'Bash':20, 'MATLAB':21}\n\n    color= [\"rgba(31, 119, 180, 0.8)\",\n            \"rgba(255, 127, 14, 0.8)\",\n            \"rgba(44, 160, 44, 0.8)\",\n            \"rgba(214, 39, 40, 0.8)\",\n            \"rgba(148, 103, 189, 0.8)\",\n            \"rgba(140, 86, 75, 0.8)\",\n            \"rgba(227, 119, 194, 0.8)\",\n            \"rgba(127, 127, 127, 0.8)\",\n            \"rgba(188, 189, 34, 0.8)\",\n            \"rgba(23, 190, 207, 0.8)\",\n            \"rgba(31, 119, 180, 0.8)\"]\n\n    source = [source_dict[k] for k in source]\n    target = [target_dict[k] for k in target]\n    color_node = color*2\n    labels = list(source_dict.keys())*2\n\n    link = dict(source = source,\n                target = target,\n                value = value,\n                label = labels,\n                color = color_link\n               )\n\n    node = dict(pad = 15,\n                thickness = 20,\n                line = dict(color = \"black\", width = 0.5),\n                label = labels,\n                color = color_node)\n\n    data = go.Sankey(link=link,\n                  node=node)\n\n    fig.add_trace(data, row=ax[0], col=ax[1])\n        \nfig.update_layout(width=1200, height=1000)\n    \nfig.show()\n","532c4c28":"prospect = ['Q5']\n\nfor q in np.arange(17, 20):\n    cols = survey.columns[survey.columns.str.find(\"Q\" + str(q)) == 0]\n    for col in cols:\n        prospect.append(col)\n\nsurvey_concept = survey.loc[:,prospect]\nsurvey_concept['ML'] = survey_concept[['Q17_Part_1','Q17_Part_2','Q17_Part_3','Q17_Part_4','Q17_Part_5']].count(axis=1)\nsurvey_concept['DL'] = survey_concept[['Q17_Part_6','Q17_Part_7','Q17_Part_8','Q17_Part_9','Q17_Part_10']].count(axis=1)\nsurvey_concept['CV'] = survey_concept[['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5']].count(axis=1)\nsurvey_concept['NLP'] = survey_concept[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4']].count(axis=1)\nsurvey_concept['CV_other'] = survey_concept[['Q18_OTHER']].count(axis=1)\nsurvey_concept['ML_other'] = survey_concept[['Q17_OTHER']].count(axis=1)\nsurvey_concept['NLP_other'] = survey_concept[['Q19_OTHER']].count(axis=1)\nsurvey_concept['all'] = survey_concept[['ML','DL','CV','NLP','CV_other','ML_other','NLP_other']].sum(axis=1)\nsurvey_concept = survey_concept[survey_concept['all']!=0]\n\ncurrent_role = ['02. Student', \"03. Business Analyst\", \"04. Product\/Project Manager\",'05. Data Analyst', \"06. Statistician\",\"07. DBA\",\"08. Research Scientist\", \"09. Software Engineer\", \"10. Data Scientist\",\"11. Data Engineer\", \"12. ML Engineer\"]\n\ndf = pd.DataFrame()\nrandom.seed(123)\n\nsurvey_cs = survey_concept[['Q5','ML','DL','CV','NLP']]\n\nkm = KMeans(n_clusters = 5)\nkm.fit(survey_cs.drop('Q5',axis=1))\nsurvey_cs['clusters'] = km.labels_\ndf = pd.concat([df, \n                pd.concat([survey_cs.groupby(['clusters']).mean().astype('int'), \n                           survey_cs.groupby(['clusters']).agg({'ML':'count'}).rename(columns={'ML':'cnt'})], axis=1)],\n               axis=0)","2cda04e9":"current_role = [1,2,3,4,5]\nx = list(df.columns[:4])\nfig = make_subplots(\n    rows=5, cols=2,\n    specs=[[{}, {\"rowspan\":5}],\n           [{}, None],\n           [{}, None],\n           [{}, None],\n           [{}, None]],\n    subplot_titles=(\"Group 1\",\"Number of people in each group\", \"Group 2\", \"Group 3\", \"Group 4\", \"Group 5\")\n)\n\nfig.add_trace(go.Bar(x=x, y=np.array(df.iloc[0,:4])),\n                 row=1, col=1)\n\nfig.add_trace(go.Bar(x=x, y=np.array(df.iloc[1,:4])),\n                 row=2, col=1)\n\nfig.add_trace(go.Bar(x=x, y=np.array(df.iloc[2,:4])),\n                 row=3, col=1)\n\nfig.add_trace(go.Bar(x=x, y=np.array(df.iloc[3,:4])),\n                 row=4, col=1)\n\nfig.add_trace(go.Bar(x=x, y=np.array(df.iloc[4,:4])),\n                 row=5, col=1)\n\nx = ['Group 1', 'Group 2','Group 3','Group 4','Group 5']\n\nfig.add_trace(go.Bar(x=x, y=np.array(df.iloc[:,4])),\n                 row=1, col=2)\n\nfig.update_layout(showlegend=False, width=800, height=700, font_size=10)\n#fig.update_yaxes(showticklabels=False)\n\nfig['layout']['yaxis1'].update(title=\"Level of concepts\",title_font_size=8, range=[0, 3], autorange=False, tick0=0, dtick=1)\nfig['layout']['yaxis2'].update(title='',title_font_size=8, autorange=True, showticklabels=True)\nfig['layout']['yaxis3'].update(title=\"Level of concepts\",title_font_size=8, range=[0, 3], autorange=False, tick0=0, dtick=1)\nfig['layout']['yaxis4'].update(title=\"Level of concepts\",title_font_size=8, range=[0, 3], autorange=False, tick0=0, dtick=1)\nfig['layout']['yaxis5'].update(title=\"Level of concepts\",title_font_size=8, range=[0, 3], autorange=False, tick0=0, dtick=1)\nfig['layout']['yaxis6'].update(title=\"Level of concepts\",title_font_size=8, range=[0, 3], autorange=False, tick0=0, dtick=1)\n\n\n\nfig.show()","63955ea6":"survey_concept_ml = survey_concept[['Q5','Q17_Part_1','Q17_Part_2','Q17_Part_3','Q17_Part_4','Q17_Part_5']]\\\n.groupby('Q5')\\\n.count()\\\n.reset_index()\\\n.rename(columns={'Q17_Part_1':\"Linear\/Logistic Reg\",'Q17_Part_2':\"DT, RF\",'Q17_Part_3':\"Boosting\",'Q17_Part_4':\"Bayesian\",'Q17_Part_5':\"Evolutionary Approaches\"})\\\n.melt(id_vars='Q5')\\\n.rename(columns={'variable':'methods', 'value':'number of people','Q5':'Job position'})\n\nsurvey_concept_dl = survey_concept[['Q5','Q17_Part_6','Q17_Part_7','Q17_Part_8','Q17_Part_9','Q17_Part_10']]\\\n.groupby('Q5')\\\n.count()\\\n.reset_index()\\\n.rename(columns={'Q17_Part_6':\"DNN\",'Q17_Part_7':\"CNN\",'Q17_Part_8':\"GAN\",'Q17_Part_9':\"RNN\",'Q17_Part_10':\"Trans. Network\"})\\\n.melt(id_vars='Q5')\\\n.rename(columns={'variable':'methods', 'value':'number of people','Q5':'Job position'})\n\nsurvey_concept_cv = survey_concept[['Q5','Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5']]\\\n.groupby('Q5')\\\n.count()\\\n.reset_index()\\\n.rename(columns={'Q18_Part_1':\"Gen. Purpose\",'Q18_Part_2':\"Img. Segm.\",'Q18_Part_3':\"Object detection\",'Q18_Part_4':\"Img. Class.\",'Q18_Part_5':\"GANs\"})\\\n.melt(id_vars='Q5')\\\n.rename(columns={'variable':'methods', 'value':'number of people','Q5':'Job position'})\n\nsurvey_concept_nlp = survey_concept[['Q5','Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4']]\\\n.groupby('Q5')\\\n.count()\\\n.reset_index()\\\n.rename(columns={'Q19_Part_1':\"Word embed\",'Q19_Part_2':\"Encode\/decode\",'Q19_Part_3':\"Context embed\",'Q19_Part_4':\"Transformer\"})\\\n.melt(id_vars='Q5')\\\n.rename(columns={'variable':'methods', 'value':'number of people','Q5':'Job position'})\n\nconcept_all = pd.concat([survey_concept_ml,survey_concept_dl,survey_concept_cv,survey_concept_nlp],axis=0)\n\nfig = px.bar(concept_all, x=\"methods\", y=\"number of people\", color=\"Job position\", title=\"Algorithms and methods to learn\")\nfig.update_layout(template='simple_white')\nfig.show()","b0aea4f9":"colors = [\n'#9fe2bf',\n'#FF6347',  \n'#32CD32',  \n'#d62728',  # brick red\n'#ff7f0e',  # safety orange\n'#1f77b4',  # muted blue\n'#e377c2',  # raspberry yogurt pink\n'#17becf',   # blue-teal\n'#2ca02c',  # cooked asparagus green\n'#FFA500',  \n         ]\n\n\ncolumns = {'Q26_A_Part_1':'AWS',\n           'Q26_A_Part_2':'MS Azure',\n           'Q26_A_Part_3':'Google Cloud', \n           'Q26_A_Part_4':'IBM\/Redhat',\n           'Q26_A_Part_5':'Oracle',\n           'Q26_A_Part_6':'SAP Cloud',\n           'Q26_A_Part_7':'Salesforce Cloud',\n           'Q26_A_Part_8':'VMware Cloud',\n           'Q26_A_Part_9':'Alibab Cloud',\n           'Q26_A_Part_10':'Tencent Cloud',\n           'Q26_A_Part_11':'None',\n           'Q26_A_OTHER':'Other',\n          'Q27_A_Part_1':'Amazon EC2',\n           'Q27_A_Part_2':'AWS Lambda', \n           'Q27_A_Part_3':\"Amazon Elastic Container\",\n           'Q27_A_Part_4':\"Azure Cloud Services\",\n           'Q27_A_Part_5':\"MS Azure Container\",\n           'Q27_A_Part_6':\"Azure functions\",\n           'Q27_A_Part_7':\"Google Cloud engine\",\n           'Q27_A_Part_8':\"Google Cloud functions\",\n           'Q27_A_Part_9':\"Google Cloud run\",\n           'Q27_A_Part_10':\"Google Cloud app engine\",\n           'Q27_A_Part_11':\"None\",\n           'Q27_A_OTHER':\"Other\",\n          'Q28_A_Part_1':'Amazon SageMaker',\n           'Q28_A_Part_2':\"Amazon Forecast\",\n           'Q28_A_Part_3':\"Amazon Rekognition\",\n           'Q28_A_Part_4':\"Azure ML Studio\",\n           'Q28_A_Part_5':\"Azure Cognitive Services\",\n           'Q28_A_Part_6':\"Google AI Platform\",\n           'Q28_A_Part_7':\"Google Video AI\",\n           'Q28_A_Part_8':\"Google Natural Language\",\n           'Q28_A_Part_9':\"Google Vision AI\",\n           'Q28_A_Part_10':\"None\",\n           'Q28_A_OTHER':\"Other\",\n          'Q29_A_Part_1':'MySQL',\n           'Q29_A_Part_2':\"PostgreSQL\",\n           'Q29_A_Part_3':\"SQLite\",\n           'Q29_A_Part_4':\"Oracle DB\",\n           'Q29_A_Part_5':\"MongoDB\",\n           'Q29_A_Part_6':\"Snowflake\",\n           'Q29_A_Part_7':\"IBM DB2\",\n           'Q29_A_Part_8':\"MS SQL server\",\n           'Q29_A_Part_9':\"MS Access\",\n           'Q29_A_Part_10':\"MS Azure Datalake\",\n           'Q29_A_Part_11':\"Amazon Redshift\",\n           'Q29_A_Part_12':\"Amazon Athena\",\n           'Q29_A_Part_13':\"Amazon DynamoDB\",\n           'Q29_A_Part_14':\"Google Cloud BigQuery\",\n           'Q29_A_Part_15':\"Google Cloud SQL\",\n           'Q29_A_Part_16':\"Google Cloud Firestore\",\n           'Q29_A_Part_17':\"None\",\n           'Q29_A_OTHER':\"Other\",\n          'Q31_A_Part_5':'Tableau',\n           'Q31_A_Part_1':\"Amazon QuickSight\",\n           'Q31_A_Part_2':\"MS Power BI\",\n           'Q31_A_Part_3':\"Google Data Studio\",\n           'Q31_A_Part_4':\"Looker\",\n           'Q31_A_Part_6':\"Salesforce\",\n           'Q31_A_Part_7':\"Einstein Analytics\",\n           'Q31_A_Part_8':\"Qlik\",\n           'Q31_A_Part_9':\"Domo\",\n           'Q31_A_Part_10':\"TIBCO spotfire\",\n           'Q31_A_Part_11':\"Alteryx\",\n           'Q31_A_Part_12':\"Sisense\",\n           'Q31_A_Part_13':\"SAP Analytics Cloud\",\n           'Q31_A_Part_14':\"None\",\n           'Q31_A_OTHER':\"Other\"\n           }\n\nQ26 = ['Q5','Q26_A_Part_1','Q26_A_Part_2','Q26_A_Part_3', 'Q26_A_Part_4','Q26_A_Part_5']\nQ27 = ['Q27_A_Part_1','Q27_A_Part_2', 'Q27_A_Part_7','Q27_A_Part_4','Q27_A_Part_3']\nQ28 = ['Q28_A_Part_1','Q28_A_Part_6','Q28_A_Part_4','Q28_A_Part_8','Q28_A_Part_9']\nQ29 = ['Q29_A_Part_1','Q29_A_Part_2','Q29_A_Part_8','Q29_A_Part_5','Q29_A_Part_3']\nQ31 = ['Q31_A_Part_5','Q31_A_Part_2','Q31_A_Part_3','Q31_A_Part_8','Q31_A_Part_1']\n\nprod_type = {'AWS':'Cloud platforms',\n           'MS Azure':'Cloud platforms',\n           'Google Cloud':'Cloud platforms', \n           'IBM\/Redhat':'Cloud platforms',\n           'Oracle':'Cloud platforms',\n          'Amazon EC2':'Cloud products',\n           'AWS Lambda':'Cloud products', \n           \"Google Cloud engine\":'Cloud products',\n           \"Azure Cloud Services\":'Cloud products',\n           \"Amazon Elastic Container\":'Cloud products',\n          'Amazon SageMaker':'ML products',\n           \"Google AI Platform\":'ML products',\n           \"Azure ML Studio\":'ML products',\n           \"Google Natural Language\":'ML products',\n           \"Google Vision AI\":'ML products',\n          'MySQL':'Big Data products',\n           \"PostgreSQL\":'Big Data products',\n           \"MS SQL server\":'Big Data products',\n           \"MongoDB\":'Big Data products',\n           \"SQLite\":'Big Data products',\n          'Tableau':'BI products',\n           \"MS Power BI\":'BI products',\n           \"Google Data Studio\":'BI products',\n           \"Qlik\":'BI products',\n           \"Amazon QuickSight\":'BI products'}","a2353ec3":"df = survey[list(Q26+Q27+Q28+Q29+Q31)]\\\n.groupby('Q5')\\\n.count()\\\n.rename(columns=columns)\\\n.drop(['01. Not employed','02. Student','13. Other','14. Unknown'],axis=0)\\\n.reset_index()\\\n.melt(id_vars = 'Q5')\\\n.rename(columns = {'Q5':'Job positions','variable':'Products','value':'Number of people'})\n\ndf['type'] = [prod_type[i] for i in df.Products]\n\n# https:\/\/medium.com\/@moritzkoerber\/how-to-plot-a-grouped-stacked-bar-chart-in-plotly-df1685b83460\n\nfig = go.Figure()\n\nfig.update_layout(\n    #template=\"simple_white\",\n    xaxis=dict(title_text=\"Products\"),\n    yaxis=dict(title_text=\"Number of people\"),\n    barmode=\"stack\",\n)\n\nfor r, c in zip(df['Job positions'].unique(), colors):\n    plot_df = df[df['Job positions'] == r]\n    fig.add_trace(\n        go.Bar(x=[plot_df.type, plot_df.Products], y=plot_df['Number of people'], name=r, marker_color=c),\n    )\n    \nfig.update_layout(title='Top 5 cloud, big data and BI products to learn', template='simple_white')\n\nfig.show()","9f20a7c5":"fig = make_subplots(\n    rows=3, cols=2,\n    specs = [[{},{}],\n            [{},{}],\n            [{},{}]],\n    subplot_titles = (\"Cloud platforms\",\"Cloud services\",\"ML Products\",\"Big Data products\",\"BI Products\")\n)\n\nind = [(i, j) for i in range(1,4) for j in range(1,3)]\nfor xy, j in zip(ind, [26,27,28,29,31]):\n    df = survey[survey.columns[survey.columns.str.find(str(j),0)==1]].count(axis=0).reset_index().rename(columns={'index':'Products',0:'Number of people'})\n    df['type'] = ['A' if 'A' in i else 'B' for i in df['Products']]\n    df['Products'] = [columns[i.replace('_B','_A')] for i in df['Products']]\n    df = df[(df['Products'] != 'None') & (df['Products'] != 'Other')]\n    df\n\n\n    fig.add_trace(go.Scatter(mode='markers',\n                             x=df['Products'][df['type'] == 'A'], y=df['Number of people'][df['type'] == 'A'],\n                             name='Current',\n                             legendgroup=\"A\",\n                            marker=dict(\n                                    color='#ff7f0e',\n                                    size=10,\n                                    line=dict(\n                                        color='black',\n                                        width=1),\n                            opacity=0.7)),\n                 row=xy[0], col=xy[1])\n\n    fig.add_trace(go.Scatter(mode='markers',\n                             x=df['Products'][df['type'] == 'B'], y=df['Number of people'][df['type'] == 'B'],\n                             name='In 2 years',\n                             legendgroup=\"B\",\n                            marker=dict(\n                                    color='#17becf',\n                                    size=15,\n                                    line=dict(\n                                        color='black',\n                                        width=1),\n                            opacity=0.7)),\n                 row=xy[0], col=xy[1])\n\nfig.update_layout(width=900, height=1000, title=\"Products to learn in the next 2 years\",  title_font_size=14, font_size=10)\nfig.show()","f34ea429":"cost = survey[['Q5','Q25','Q3']].groupby(['Q5','Q25']).count().reset_index().pivot('Q5','Q25','Q3')\ncost.columns = ['0', '1-99', '100-999', '1000-9999','10,000-99,999','100,000<']\n\nfig = plt.figure(figsize=(6, 13), dpi=200)\n\ngs = fig.add_gridspec(5, 4)\n\nlabels = ['0', '1-99', '100-999', '1000-9999','10,000-99,999','100,000<']\n\nax_plot = fig.add_subplot(gs[1:4, 0:4]) \nfor cur in cost.index[::-1]:\n    for bl in labels:\n        val = cost.loc[cur, bl]\n        ax_plot.scatter(bl, cur, s=val, color='#17becf')\n        \nax_plot.grid(linewidth=0.2, zorder=0)\n\nplt.title('Money spent on machine learning or cloud computing services', size=12)","8d5ea752":"source = survey[['Q37_Part_1', 'Q37_Part_2', 'Q37_Part_3', 'Q37_Part_4', 'Q37_Part_5',\n       'Q37_Part_6', 'Q37_Part_7', 'Q37_Part_8', 'Q37_Part_9', 'Q37_Part_10']]\\\n.count(axis=0).reset_index().rename({'index':'source',0:'Number of people'}, axis=1)\nsource\nsid={'Q37_Part_1':'Coursera', 'Q37_Part_2':'EdX', 'Q37_Part_3':'Kaggle Courses', 'Q37_Part_4':'DataCamp', 'Q37_Part_5':'Fast.ai',\n'Q37_Part_6':'Udacity', 'Q37_Part_7':'Udemy', 'Q37_Part_8':'Linkedin Learn', 'Q37_Part_9':'Cloud Certification programs', 'Q37_Part_10':'University course'}\nsource['source'] = [sid[i] for i in source['source']]\n\nfig = go.Figure()\n\nfig.add_trace(go.Bar(x=source['source'],y=source['Number of people']))\nfig.update_traces(marker_color='#17becf', marker_line_color='rgb(8,48,107)',\n                  marker_line_width=1.5, opacity=0.6)\nfig.update_layout(title=\"Sources to learn data science\", width=800, height=500)\nfig.show()","21cbbfd6":"`Coursera`, `Kaggle Courses`, `Udemy` and `DataCamp` are the platforms that people use to study data science. `University courses` or `University Degrees` are also another popular way to gain knowledge about data science.","209c9b41":"## Daily used programming languages and recommended languages of each position (Q8, Q26, Q29, Q31, Q33, Q34, Q35)","9d892531":"Based on the chart of daily used programming languages and recommended languages plots, `Python` is the most recommended language to learn which is followed by `SQL` and `R`. Especially for data analysis related position such as `Data Analyst` and `Data Scientist`, these 3 languages are must, and for more technical position such as `DBA`, `Data Engineer` and `ML Engineer`, `Python` and `SQL` are must to learn.\n\n### Now, let's look at what type of concepts and methods that someone should know.","4e716608":"## The cost of becoming a Data Scientist (Q5, Q25)","ba75912f":"The end of the notebook","e1874431":"## Coding and Machine learning experience (Q15, Q6)","cef63da4":"# Becoming a Data Scientist\n\nData Science (DS) is a fresh field in the country that I live in, Mongolia, and it is true for most of the developing countries. These countries share similar characteristics such as very few experts in this field, very few, almost non existent degree or courses offered by the universities on the topic and not many contents are made available in the native language, which are the main challenges that the people who want to pursue data science face.\n\nThose who aspire to become data scientists often ask questions like how to self-study data science, where to start and what career path to take. Nowadays, with overload of information and awesome examples others' work with data, we can easily become overwhelmed, distracted and get confused about what career path to take or what skillset to hone because everything looks attractive in Artificial Intelligence (AI) and Data science.\n\nTherefore, I decided to approach this survey analysis from an angle that can assist people to create and plan their learning path about AI and DS and hopefully help people to plan and choose their career paths.","bbf81d87":"On average, the most data related jobs require 2 programming language knowledge. The most of data engineers, data scientists, DBAs and software engineers know 3 programming languages on average. It looks like knowing at least 2 languages is a minimun requirement for data related profession. \n\n### Let's look at which languages are recommended by people to begin learning.","61860507":"If you're looking to change your career path to data science or want to pursue data science but don't know where to start and who to become, I hope that this analysis helped you to shed little light to the direction. The survey didn't ask about the how the respondents started with data, but I think it offered enough information give some pointers to those who aspire to become data scientists. Although it feels overwhelming at times, once you start learning, it's fun to work on data.\n\nThank you for taking the time to read my analysis.","5ec9cf87":"## Coding and Machine Learning experience of each position (Q15, Q5, Q6)","e5307dc0":"## The concepts and algorithms to learn (Q5, Q17, Q18, Q19)","d57ba2f1":"## Data products and tools to look out (Q26AB, Q27AB, Q28AB, Q29AB, Q31AB)","91c97d40":"## Number of AI areas to have knowledge about (Q8, Q17, Q18, Q19)","ef38a1bf":"## Additional data tools to learn (Q5, Q26A, Q27A, Q28A, Q29A, Q31A)","41ce5f7a":"People often think that they need to have prior coding experience to specialize in machine learning. It's true that coding is required for machine learning but let's see that whether you can acquire coding and machine learning skills simultaneously. ","6b83c8b7":"## Conclusion","d9768211":"Most people who participated in this survey have less than 3 years of coding experience. As for Machine learning experience, most people have less than 5 years of experience. Based on the heatmap above, it's interesting to see that the people who have less than 2 year of coding experience have less than 2 years of ML experience. This suggests that large number of people dive straight into ML and coding without any coding experience. This doesn't necessarily mean that people don't need prior coding experience. Experienced coder will have relatively easy time to transition to become data scientist or other related field because some skills that they acquired as a coder are transferable.\n\n### Now let's dive little bit more detail into coding and machine learning experiences of each job position.","5877d12d":"## Each position's daily used programming languages. How many do you need to know? (Q8, Q7)","1479c3c4":"As you can see from the plot, the most people don't spend much money to learn to work on data. The most people spent less than $100 in the last 5 years. Although the question asked about how much money people spent at work and home on machine learning or cloud services, this question was the closest to the meaning that I could use to make this point.\n\nThere are many great and free resources to study coding and machine learning concepts. Some people pursue professional degree or certifications to validate their knowledge, but that doesn't mean that everyone has to have a data degree to become a Data Scientist.\n\n### Now, let's see what sources that people use to learn data science.","5c813a75":"In the next 2 years, `AWS`, `Google Cloud`, and `Azure` will still be in demand and the cloud services and cloud based machine learning products are the most attractive products to learn. As for Big data products, `MySQL`, `MongoDB`, `Google Cloud BigQuery` and `Google Cloud SQL` are the ones that are popular among data professionals. For BI products, `Tableau` has the highest demand along with `Amazon QuickSight` and `Google Data Studio`.\n\n### Now, we know which programming languages, machine learning algorithms and additional data products to learn. The big question is how much money does it require to build the skillset?","300bbc54":"- `Students` have less coding experience in general, but their ML experience doesn't have much time lag to general coding experience which suggests that they learn coding and ML methods almost at the same time.\n- `Data Engineers` and `Software Engineers` have more coding experience and less ML experience which makes perfect sense because both positions are code heavy and it's possible that with the current rapidly growing trend of data, their daily tasks started to include data related tasks and require them to transition to machine learning.\n- `Data Scientist`, `Machine Learning Engineer` and `Research Scientist` have almost proportional coding and ML experiences which suggest that they also learned machine learning method and coding simultaneously.\n- `Data Analyst`,`Statistician` and `Business Analyst` tend to have less coding and ML experiences.\n- `Product\/Project Managers` have less than 3 years of ML experience\n- `DBA\/Database Engineer`, the most of them have less than 1 or no machine learning experience. Their coding and ML experience proportion is very random.\n\nBased on the outcome, it looks like someone who is aspiring to become one of `Data Analyst`, `Statistician`, `Business Analyst`, `Data Scientist`, `Machine Learning Engineer` and `Research Scientist` doesn't necessarily need to have prior coding experience before started learning machine learning and data science. People who work in these positions started learning machine learning and coding almost at the same time, in other words, coding can be acquired by studying machine learning concepts and vice versa.\n\n### Then, let's see which and how many programming languages to acquire in order to comfortably work on data?","4f56d876":"## Which sources to use and study about data science (Q37)","5419cf2f":"(Tap twice on `position` to see popular methods of each job position)\n\nOn top of learning `Python` and programming languages, the data professionals need to learn additional tools that are used on day to day basis. The most popular tools are `AWS`, `Google Cloud`, `MySQL`, `Tableau` and `MS Power BI`.\n- `Business Analyst` and `Data Analyst` mostly use AWS, Google cloud platforms, relational database SQL tools and BI tools.\n- `Statistician`, `DBA` less likely to use machine learning products and cloud products.\n- `Data Scientist`, `Data Engineer`, `ML Engineer` positions use all 5 types of products regularly.\n\nTherefore, someone who's aspiring to become a Data Scientist is recommended to learn to use at least one cloud platform and a tool from each product type.\n\n### Now, let's see for the next couple of years, what type of products will become trend.","d80e94bb":"(Tap twice on `position` to see popular methods of each job position)\n\nOverall, `Linear\/ logistic regression`, `Decision tree\/ Random forest`, `Boosting methods` and `Convolutional NN` are essential to learn. Each data related position requires different sets of algorithms and methods.\n- `Business Analyst`, `Data Analyst`, `Statistician` and `DBA` positions mostly require knowledge of machine learning algorithms and methods.\n- `Research scientists` and `ML Engineer` positions require diverse knowledge in all 4 areas (`ML`, `DL`, `CV`, `NLP`)\n- `Product manager`, `Data Scientist`, `Software engineer` and `Data Engineer` positions require knowledge of machine learning and deep learning algorithms and some knowledge in other areas.\n\nIf someone is aspiring to work in data field and doesn't have much experience, then following could be a potential career path. (the positions are ranked in terms of required knowledge of algorithms and methods)\n\n`Data Analyst\/ Business Analyst\/ Statistician` -> `Data Scientist\/ Data Engineer` -> `Research Scientist\/ ML Engineer`\n\n### Now, let's look at other big data and business intelligence products and tools to be familiar with.","4ec339d3":"There are many methods and concepts in AI to learn. `Machine Learning (ML)`, `Deep Learning (DL)`, `Computer Vision (CV)` and `Natural Language Processing (NLP)` are sub sections of AI that some people specialize in. Not everyone is required to know all the concepts in those fields to work on data. The number of people who know only machine learning concepts is higher than the number of people who know the concepts of more than 2 sub sections. This means that if someone knows the concepts of `Machine learning` to certain extent, he\/she will be able to work on data and find data related jobs. This doesn't necessarily mean that by only knowing machine learning concepts, you can handle all data related problems. Therefore, it's recommended to learn concepts other than machine learning such as deep learning to work on more complex data.\n\n### Now, let's look at what type of algorithms and methods to learn in each sub section of AI."}}