{"cell_type":{"1461d043":"code","8d93d530":"code","42c07b28":"code","dfc3f399":"code","27741e8b":"code","8cbf04ee":"code","6218723d":"code","0e0f3dd9":"code","1c8ffd2a":"code","eba4c035":"code","65a235e0":"code","c7370338":"code","79f50549":"code","e1a24bfc":"code","fedee7d4":"code","e6e1cd96":"code","3fa79a64":"markdown","0874d99d":"markdown","0c2d06a2":"markdown","08d4c63a":"markdown","2b70bd2b":"markdown","dd79e1fc":"markdown","2fdd7240":"markdown","e019d14e":"markdown","fe62ca0f":"markdown","26f8a6da":"markdown","a6879b48":"markdown","35c1762b":"markdown","ebb6f4bd":"markdown","4117160e":"markdown"},"source":{"1461d043":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8d93d530":"import keras\nimport matplotlib.pyplot as plt\nfrom glob import glob \nfrom keras.models import Sequential \nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Flatten, ZeroPadding2D, Conv2D, MaxPooling2D,Input,SeparableConv2D\nfrom keras.preprocessing.image import ImageDataGenerator #Data augmentation and preprocessing\nfrom keras.utils import to_categorical \nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\nfrom keras.layers.normalization import BatchNormalization\nimport cv2\nfrom PIL import Image\nfrom pathlib import Path\nfrom sklearn.metrics import roc_auc_score,roc_curve,accuracy_score,recall_score,confusion_matrix,classification_report\n","42c07b28":"print(os.listdir(\"..\/input\/chest_xray\/chest_xray\"))","dfc3f399":"path_train = \"..\/input\/chest_xray\/chest_xray\/train\"\npath_val = \"..\/input\/chest_xray\/chest_xray\/val\"\npath_test = \"..\/input\/chest_xray\/chest_xray\/test\"","27741e8b":"plt.figure(1, figsize = (15 , 7))\nplt.subplot(1 , 2 , 1)\nimg = glob(path_train+\"\/PNEUMONIA\/*.jpeg\") #Getting an image in the PNEUMONIA folder\nimg = np.asarray(plt.imread(img[0]))\nplt.title('PNEUMONIA X-RAY')\nplt.imshow(img)\n\nplt.subplot(1 , 2 , 2)\nimg = glob(path_train+\"\/NORMAL\/*.jpeg\") #Getting an image in the NORMAL folder\nimg = np.asarray(plt.imread(img[0]))\nplt.title('NORMAL CHEST X-RAY')\nplt.imshow(img)\n\nplt.show()\n","8cbf04ee":"\ntrain_gen = ImageDataGenerator(rescale = 1.\/255,\n                             shear_range = 0.2,\n                             zoom_range = 0.2,\n                             horizontal_flip=True)\n\nval_gen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_batch = train_gen.flow_from_directory(path_train,\n                                            target_size = (224, 224),\n                                            classes = [\"NORMAL\", \"PNEUMONIA\"],\n                                            class_mode = \"categorical\")\nval_batch = val_gen.flow_from_directory(path_val,\n                                        target_size = (224, 224),\n                                        classes = [\"NORMAL\", \"PNEUMONIA\"],\n                                        class_mode = \"categorical\")\ntest_batch = val_gen.flow_from_directory(path_test,\n                                         target_size = (224, 224),\n                                         classes = [\"NORMAL\", \"PNEUMONIA\"],\n                                         class_mode = \"categorical\")\n\nprint(train_batch.image_shape)","6218723d":"def build_model():\n    input_img = Input(shape=train_batch.image_shape, name='ImageInput')\n    x = Conv2D(64, (3,3), activation='relu', padding='same')(input_img)\n    x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2,2))(x)\n    \n    x = SeparableConv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = SeparableConv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2,2))(x)\n    \n    x = SeparableConv2D(256, (3,3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = SeparableConv2D(256, (3,3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = SeparableConv2D(256, (3,3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2,2))(x)\n    \n    x = SeparableConv2D(512, (3,3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = SeparableConv2D(512, (3,3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = SeparableConv2D(512, (3,3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2,2))(x)\n    \n    x = Flatten(name='flatten')(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.7)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(2, activation='softmax')(x)\n    \n    model = Model(inputs=input_img, outputs=x)\n    \n    return model","0e0f3dd9":"def create_plots(history):\n    \n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\n    # Plot training & validation loss values\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()","1c8ffd2a":"model= build_model()\nmodel.summary()\n","eba4c035":"batch_size = 16\nepochs = 50\nearly_stop = EarlyStopping(patience=25,\n                           verbose = 2,\n                           monitor='val_loss',\n                           mode='auto')\n\ncheckpoint = ModelCheckpoint(\n    filepath='best_model',\n    save_best_only=True,\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='auto',\n    verbose = 1)\n\nreduce = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.8,\n    patience=5,\n    verbose=1, \n    mode='auto',\n    min_delta=0.0001, \n    cooldown=1, \n    min_lr=0.0001\n)\n\nmodel.compile(loss='binary_crossentropy',\n              metrics=['accuracy'],\n              optimizer=Adam(lr=0.0001))\n\nhistory = model.fit_generator(epochs=epochs,\n                              callbacks=[early_stop,checkpoint,reduce],\n                              shuffle=True,\n                              validation_data=val_batch,\n                              generator=train_batch,\n                              steps_per_epoch=500,\n                              validation_steps=10,\n                              verbose=2)\n","65a235e0":"create_plots(history)","c7370338":"original_test_label=[]\nimages=[]\n\ntest_normal=Path(\"..\/input\/chest_xray\/chest_xray\/test\/NORMAL\") \nnormal = test_normal.glob('*.jpeg')\nfor i in normal:\n    img = cv2.imread(str(i))\n#     print(\"normal\",img)\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    else:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    try:\n        img = cv2.resize(img, (224,224))\n    except Exception as e:\n        print(str(e))\n    images.append(img)\n    label = to_categorical(0, num_classes=2)\n    original_test_label.append(label)\n\ntest_pneumonia = Path(\"..\/input\/chest_xray\/chest_xray\/test\/PNEUMONIA\")\npneumonia = test_pneumonia.glob('*.jpeg')\nfor i in pneumonia:\n    img = cv2.imread(str(i))\n#     print(\"pneumonia\",img)\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    else:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    try:\n        img = cv2.resize(img, (224,224))\n    except Exception as e:\n        print(str(e))\n    images.append(img)\n    label = to_categorical(1, num_classes=2)\n    original_test_label.append(label)    \n\n    \nimages = np.array(images)\noriginal_test_label = np.array(original_test_label)\nprint(original_test_label.shape)\n\n\norig_test_labels = np.argmax(original_test_label, axis=-1)\n# print(orig_test_labels)\n# print(p)\n\n\n","79f50549":"p = model.predict(images, batch_size=16)\npreds = np.argmax(p, axis=-1)\nprint(preds.shape)\n","e1a24bfc":"test_loss, test_score = model.evaluate_generator(test_batch,steps=100)\nprint(\"Loss on test set: \", test_loss)\nprint(\"Accuracy on test set: \", test_score)","fedee7d4":"print(\"Accuracy: \" + str(history.history['val_acc'][-1:]))","e6e1cd96":"recall_score(orig_test_labels,preds)\n","3fa79a64":"### Here I have used 4 callbacks to get the best model\nYou can experiment by changing the number of epochs and changing the monitoring parameters. However, increasing the number of epochs increases the computation time but gives better results in visualizing the plots and getting the best model.","0874d99d":"Data augmentation is a powerful technique which helps in almost every case for improving the robustness of a model. But augmentation can be much more helpful where the dataset is imbalanced. You can generate different samples of undersampled class in order to try to balance the overall distribution.","0c2d06a2":"\n\n### Breakdown of this notebook:\n\n1. Loading the dataset: Load the data and import the libraries.\n2. Data Preprocessing:\n     * Reading the images stored in 3 folders(Train,Val,Test).\n     * Plotting the NORMAL and PNEUMONIA images with their respective labels.\n3. Data Augmentation: Augment the train,validation and test data using ImageDataGenerator\n4. Creating and Training the Model: Create a CNN model in KERAS.\n5. Evaluation: Display the plots from the training history.\n6. Prediction: Run predictions with model.predict\n7. Conclusion: Comparing original labels with predicted labels and calculating recall score","08d4c63a":"### Example plots of images in NORMAL and PNEOMONIA folder","2b70bd2b":"### Function for getting accuracy and loss plots ","dd79e1fc":"### Validation Accuracy and Recall score","2fdd7240":"### Getting the images and labels from test data","e019d14e":"## This is the KERAS CNN implementation for the CHEST X RAY IMAGES with > 93% validation accuracy and >85% test set accuracy**\n\n#### ANY FEEDBACK IN THE COMMENTS WILL BE HIGHLY APPRECIATED.","fe62ca0f":"### Creating the CNN model\n\n* I have used Keras's Functional API to build the Sequential model.I find it to be a better and easier way to deine a Convolutional Neural Net Model.Below is the reference to Functional API documentation by KERAS:-\nhttps:\/\/keras.io\/getting-started\/functional-api-guide\/\n\n* In the model, use Depthwise \"SeparableConv\" layer,which is less computationally expensive than standard \"CONV2D\" layer.The convolution operation in \"SeparableConv2D\" layer is applied to a single channel at a time, unlike normal convolution where the operation is applied to all the channels at once. With that, the number of parameters and multiplications to be done are reduced, making it faster than normal convolution. In practice that's the advantage of using it, it's really helpful in large neural net structures, MobileNet and Xception for example are based on this type of convolution. I'll recommend you watch this video, helped me a lot when I was studying. https:\/\/www.youtube.com\/watch?v=T7o3xvJLuHk\n\n","26f8a6da":"### Loss and accuracy plots","a6879b48":"### Exploring the directories in our dataset","35c1762b":"### Evaluation of model on test set","ebb6f4bd":"### AUGMENTATION ON TRAINING, VALIDATION, TEST DATA","4117160e":"### Prediction on test set images"}}