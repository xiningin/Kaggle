{"cell_type":{"e09ce94c":"code","db503b47":"code","2a149166":"code","2509df98":"code","54216868":"code","edefbf1c":"code","babea470":"code","1df60955":"code","f7db154a":"code","16cdfb69":"code","f4751913":"code","f3b317c6":"code","9bfa3a74":"code","ec57f9ac":"code","da8a5a73":"code","3eba50b6":"code","329702ca":"code","72b8f0a2":"code","5d646006":"code","1cfe86da":"code","3df5f3fc":"code","1b245db5":"code","c5f99886":"code","f68bf7aa":"code","6c610b66":"code","6ac528d2":"code","b5cbf2c5":"code","1d5db7bb":"code","a3ebbb24":"code","7479828b":"code","3c465aa0":"code","490e4415":"code","0cb0691d":"code","1246fcb8":"code","ebff2d11":"code","02e3a3e1":"code","8739cea2":"code","bf8431fd":"code","18865d34":"markdown","691c0944":"markdown","22b3b1c5":"markdown","6159825d":"markdown","d4584482":"markdown","108d30fc":"markdown","c414a2fd":"markdown","76906218":"markdown","c3c1a142":"markdown","8b883c47":"markdown","6beba072":"markdown","92fb7d7c":"markdown","98c4a467":"markdown","8f994287":"markdown","7f9fb375":"markdown","7c390313":"markdown","83368442":"markdown","39a3ddea":"markdown","fa712732":"markdown","0511626d":"markdown","e7edd286":"markdown","10f1c2a3":"markdown","60994727":"markdown","8f7b2c68":"markdown","f978b104":"markdown","ce439ddf":"markdown","40bbc4c6":"markdown","008df3dc":"markdown","f7d5fe6e":"markdown","53a8e89f":"markdown","2a478329":"markdown","924a02c1":"markdown","ee8fcc09":"markdown","a24435c9":"markdown","bdb0254f":"markdown","3f5441fc":"markdown","f50ddd2d":"markdown","c5e02a7c":"markdown","5257285e":"markdown","bb1d2301":"markdown","41b0e53b":"markdown","5c9442f9":"markdown","81d21311":"markdown","c4d26abe":"markdown","fe21c989":"markdown","d637e9a3":"markdown","107ec4b7":"markdown","c783d694":"markdown","7ae465dc":"markdown","be125375":"markdown","797dfe1a":"markdown","1422ffd1":"markdown","34f0e305":"markdown"},"source":{"e09ce94c":"# make imports\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import stats","db503b47":"# read datasets (disasters)\ncarbon_df = pd.read_csv('..\/input\/carbon-emissions\/MER_T12_06.csv')\ndisasters_df = pd.read_csv('..\/input\/natural-disaster-data\/number-of-natural-disaster-events.csv')\necon_df = pd.read_csv('..\/input\/natural-disaster-data\/economic-damage-from-natural-disasters.csv')","2a149166":"# Look at the data for natural disasters\ndisasters_df.head()","2509df98":"# drop NaN values\ndisasters_df = disasters_df.drop(columns='Code')\necon_df = econ_df.drop(columns='Code')","54216868":"disasters_df['Entity'].unique()","edefbf1c":"(disasters_df['Year'].min(), disasters_df['Year'].max())","babea470":"def grab_decade(start_yr, y_c_data, interval=10):\n    '''Return years and counts for only a specific interval length.'''\n    end_yr = int(start_yr) + interval - 1\n    years = y_c_data[(y_c_data['years'] <= end_yr) & (y_c_data['years'] >= start_yr)]\n    return years\n\ndef compute_decade_mean(start_yr, y_c_data):\n    '''Sum the number of total disasters over a given period of 10 years, returns the mean.'''\n    years = grab_decade(start_yr, y_c_data)\n    # compute and return the mean\n    return years['counts'].sum() \/ 10","1df60955":"def compute_means(y_c_data):\n    '''Returns a dict of all mean number of disasters that occurred for every decade, 1900-2010.'''\n    # compute the amount of decades in our data\n    start_yr, end_yr = y_c_data['years'].min(), y_c_data['years'].max()\n    decades = (end_yr - start_yr) \/\/ 10\n    # store all the means in a dict\n    decade_means = dict()\n    for i in range(start_yr, end_yr, 10):\n        decade_means[f'{i}'] = compute_decade_mean(i, y_c_data)\n    return decade_means\n\n# Calling the function\nALL_DIS = 'All natural disasters'\nCOUNT = 'Number of reported natural disasters (reported disasters)'\ncounts = disasters_df[(disasters_df['Entity'] == ALL_DIS)][COUNT]  # just the counts of all natural disasters, all years\nyears = disasters_df[(disasters_df['Entity'] == ALL_DIS)]['Year']  # just the years\ny_c_data = pd.DataFrame(data={\n                        'years':years, \n                        'counts':counts})\nmeans_by_decade = compute_means(y_c_data)","f7db154a":"plt.plot(list(means_by_decade.keys()), list(means_by_decade.values()))\nplt.xlabel('Decade Start Year')\nplt.ylabel('Annual Mean Disaster Count')\nplt.title('Change in Decade Mean for Natural Disasters, 1900-2010')\nplt.show()","16cdfb69":"def compute_decade_median(start_yr, y_c_data):\n    '''Return the median of total disasters over a given period of 10 years.'''\n    years = grab_decade(start_yr, y_c_data)\n    # compute and return the median\n    return years['counts'].median()\n\ndef compute_medians(y_c_data):\n    '''Returns a dict of all mean number of disasters that occurred for every decade, 1900-2010.'''\n    # compute the amount of decades in our data\n    start_yr, end_yr = y_c_data['years'].min(), y_c_data['years'].max()\n    decades = (end_yr - start_yr) \/\/ 10\n    # store all the medians in a dict\n    decade_medians = dict()\n    for i in range(start_yr, end_yr, 10):\n        decade_medians[f'{i}'] = compute_decade_median(i, y_c_data)\n    return decade_medians\n\nmedians_by_decade = compute_medians(y_c_data)","f4751913":"plt.plot(list(medians_by_decade.keys()), list(medians_by_decade.values()))\nplt.xlabel('Decade Start Year')\nplt.ylabel('Median Disaster Count')\nplt.title('Change in Decade Median for Natural Disasters, 1900-2010')\nplt.show()","f3b317c6":"counts = disasters_df[(disasters_df['Entity'] == 'All natural disasters') & (disasters_df['Year'] >= 2000) & (disasters_df['Year'] <= 2010)]['Number of reported natural disasters (reported disasters)']\nplt.plot(list(range(2000, 2011)), counts)\nplt.xlabel('Year')\nplt.ylabel('Annual Mean Disaster Count')\nplt.title('Change in Natural Disaster Count, 2000-2010')\nplt.show()","9bfa3a74":"# find all rows reporting \"all natural disasters\"\nCOUNT = 'Number of reported natural disasters (reported disasters)'\nall_disasters = disasters_df[disasters_df['Entity'] == 'All natural disasters'][COUNT]\n# sum them together, divide by their number\nmean_disasters = np.sum(all_disasters) \/ len(all_disasters)\n# print the mean\nmean_disasters","ec57f9ac":"count = 0\nfor num in all_disasters:\n    if num > mean_disasters:\n        count += 1\ncount","da8a5a73":"all_disasters_years_and_counts = disasters_df[(disasters_df['Entity'] == 'All natural disasters')]\nyears_2000_2018 = all_disasters_years_and_counts.tail(19)\ncount = 0\nfor num in years_2000_2018['Number of reported natural disasters (reported disasters)']:\n    if num > mean_disasters:\n        count += 1\n        \npercent_val = round((count\/19) * 100, 2)  \nprint(f'{percent_val}%')  # have all these years surpassed the mean we calculated?","3eba50b6":"print(f'{round((19\/42) * 100, 2)}%')","329702ca":"# slice the DataFrame by century\ndisasters_20th = disasters_df[(disasters_df['Entity'] == 'All natural disasters') & (disasters_df['Year'] <= 1999) & (disasters_df['Year'] >= 1900)]\ndisasters_21st = disasters_df[(disasters_df['Entity'] == 'All natural disasters') & (disasters_df['Year'] >= 2000) & (disasters_df['Year'] <= 2018)]\n\n# find the mean annual number of disasters in the 20th century\nmean_20th = disasters_20th[COUNT].values.mean()\n\n# compute the percent of years in the 21st century which is greater than this value\npercent_over = len(disasters_21st[disasters_21st[COUNT] > mean_20th]) \/ len(disasters_21st) * 100\nprint(f'{percent_over}%')","72b8f0a2":"# find the total number of years with counts above the mean_20th\ncount_above_mean = len(all_disasters[all_disasters > mean_20th])\nprint(f'{round((18\/count_above_mean) * 100, 2)}%')","5d646006":"# let's take another look at that data\nall_disasters_years_and_counts","1cfe86da":"y_c_data","3df5f3fc":"plt.plot(y_c_data['years'], y_c_data['counts'])\nplt.title('All Natural Disasters Globally, From 1900-2018')\nplt.ylabel('Total Count')\nplt.xlabel('Year')\nplt.show()","1b245db5":"def probability_for_interval(start_year, end_year):\n    # take the sum of all natural disasters that occurred 1900-2018\n    sum_all = y_c_data['counts'].sum()\n    # take the sum that happen over the interval\n    yrs_in_range = y_c_data[(y_c_data['years'] < end_year) & (y_c_data['years'] > start_year)]\n    sum_yrs = yrs_in_range['counts'].sum()\n    # return the probability\n    percent = round((sum_yrs\/sum_all) * 100, 2)\n    return percent\n    \nprob_20th = probability_for_interval(1900, 2000)\nprint(f'{prob_20th}%')","c5f99886":"prob_21st = probability_for_interval(2000, 2018)\nprint(f'{prob_21st}%')","f68bf7aa":"plt.pie([prob_20th, prob_21st], labels=['20th', '21st'])\nplt.title('Relative Frequency of Natural Disasters in 20th & 21st Centuries')\nplt.show()","6c610b66":"def find_remove_outlier_iqr(disaster_counts):\n    '''Remove the outliers from the dataset of annual total nautral disasters.'''\n    # calculate interquartile range\n    q25, q75 = np.percentile(disaster_counts, 25), np.percentile(disaster_counts, 75)\n    iqr = q75 - q25\n    print(f'This is the IQR: {iqr}')\n    # calculate the outlier cutoff\n    cut_off = iqr * 1.5\n    lower, upper = q25 - cut_off, q75 + cut_off\n    # identify outliers\n    outliers = [x for x in disaster_counts if x < lower or x > upper]\n    # remove outliers\n    outliers_removed = [x for x in disaster_counts if x > lower and x < upper]\n    return outliers\n\nprint(f'Number of outliers removed from the data: {len(find_remove_outlier_iqr(counts))}')","6ac528d2":"# show box plot\ncounts = all_disasters_years_and_counts['Number of reported natural disasters (reported disasters)']\nplt.boxplot(counts)\nplt.title(\"Box Plot of Annual Natural Disasters, 1900-2018\")\nplt.ylabel(\"Count of Natural Disasters\")\nplt.xlabel(\"Years 1900-2018\")\nplt.show()","b5cbf2c5":"carbon_df.head()\ncarbon_df['Description'].values","1d5db7bb":"carbon_df.tail()","a3ebbb24":"# store the annual emissions count in a dict\nyears_emissions = dict()\n# just look at emissions from total electric output\ncarbon_total = carbon_df[carbon_df['Description'] == 'Total Energy Electric Power Sector CO2 Emissions']\n# traverse through the years\nfor i in range(197300, 201700, 100):\n    # find all the rows in the data for the year we're currently on\n    year = carbon_total[(carbon_total['YYYYMM'] >= i) & (carbon_total['YYYYMM'] <= i + 12)]\n    # sum the emissisons for that one year\n    sum = 0.0\n    for value in year['Value']:\n        # handle the invalid values\n        if value == 'Not Available':\n            value = 0.0\n        sum += float(value)\n    # store it in the dict\n    years_emissions[int(i\/100)] = sum\n# Voila! A dict of all years and their emissions counts, 1973-2016\nprint(years_emissions)\n# One of the things to note in this data is that NaN values were replaced 0, but this is likely far from the\n# true number of emissions made that month","7479828b":"plt.plot(list(years_emissions.keys()), list(years_emissions.values()))\nplt.title('Annual Carbon Emissions from Electricity Generation, 1973-2016')\nplt.xlabel('Year')\nplt.ylabel('Million Metric Tons of Carbon Dioxide')\nplt.show()","3c465aa0":"econ_df.head()","490e4415":"# combining datasets\ndf = disasters_df.rename(columns={'Number of reported natural disasters (reported disasters)': 'Disaster Count'})\ndf2 = econ_df.rename(columns={'Total economic damage from natural disasters (US$)':'Cost'})\ndf['Cost'] = df2['Cost']\ndf.head()\n","0cb0691d":"dollars = df[df['Entity'] == 'All natural disasters']['Cost']\nplt.plot(years, dollars)\nplt.title('Cost of Nautral Disasters Globally, 1900-2018')\nplt.ylabel('Total Cost (USD)')\nplt.xlabel('Year')\nplt.show()","1246fcb8":"# Credit to the Seaborn Documentation for inspiring this cell: https:\/\/seaborn.pydata.org\/examples\/many_pairwise_correlations.html\nsns.set(style=\"white\")\n# Compute the correlation matrix\ncorr = df.corr()\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(8, 8))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\nplt.title('Covariance Between Costs Against Counts')\nplt.show()","ebff2d11":"def pearson_corr(x, y):\n    '''Given two lists of numbers x and y, return the value of their Pearson correlation coefficient.'''\n    x_mean = np.mean(x)\n    y_mean = np.mean(y)\n    num = [(i - x_mean)*(j - y_mean) for i,j in zip(x,y)]\n    den_1 = [(i - x_mean)**2 for i in x]\n    den_2 = [(j - y_mean)**2 for j in y]\n    correlation_x_y = np.sum(num)\/np.sqrt(np.sum(den_1))\/np.sqrt(np.sum(den_2))\n    return correlation_x_y\n\n# get a lists of the counts and the costs\ncounts = df[(df['Entity'] == 'All natural disasters') & (df['Year'] <= 2018) & (df['Year'] >= 1900)]['Disaster Count']\ncosts = df[(df['Entity'] == 'All natural disasters') & (df['Year'] <= 2018) & (df['Year'] >= 1900)]['Cost']\ncorr_cost_count = pearson_corr(costs, counts)\nprint(f'Correlation between cost of damages and disaster count: {corr_cost_count}.')","02e3a3e1":"# 1-sample t-test\n# get a list of the costs of disasters for just the 21st century\ncosts = df[df['Entity'] == 'All natural disasters']['Cost'].values\ncosts_21 = df[(df['Entity'] == 'All natural disasters') & (df['Year'] <= 2018) & (df['Year'] >= 2000)]['Cost'].values\n\n# calculate the mean cost annually due to disasters, for whole population (1900-2018)\npop_mean = costs.mean()\n\n# run the test\nt, p = stats.ttest_1samp(costs_21, pop_mean)\n\n# see the results\nprint(f\"The t-statistic is {t} and the p-value is {p}.\")","8739cea2":"import pandas as pd\neconomic_damage_from_natural_disasters = pd.read_csv(\"..\/input\/natural-disaster-data\/economic-damage-from-natural-disasters.csv\")\nnumber_of_natural_disaster_events = pd.read_csv(\"..\/input\/natural-disaster-data\/number-of-natural-disaster-events.csv\")","bf8431fd":"import pandas as pd\nMER_T12_06 = pd.read_csv(\"..\/input\/carbon-emissions\/MER_T12_06.csv\")","18865d34":"## Which Years Do We Have Data For?","691c0944":"# Stats By the Decade: Measures of Central Tendency","22b3b1c5":"# Summary of Findings","6159825d":"# Watch out! For people who only show you the data for the last decade, there's more if we look closely (at the annual data)!","d4584482":"# 4: Distribution of Disasters\n\n# What is the distribution of natural disasters over the years 1900-1999? 2000-2018?","108d30fc":"# Null Hypothesis\n\n### We know that both the count and cost of total natural disasters annually, rises around the turn of the century.\n\n## Someone may claim,\n\n# The higher mean count of total natural disasters globally in the 21st century, will not cause more expensive costs due to disasters in this century than the one prior.\n\n## Do we accept or reject this?","c414a2fd":"# So, What's the Chance that a Year has an Above Average Number of Natural Disasters, given the year is 2000-2018, than the mean of all 118 years?","76906218":"# 5: What Happens if We Remove Outliers?","c3c1a142":"# 1 Sample T-Test\n\n**Why?**\n\nThis is 1 sample because as I'm sure you realize, Earth is the only planet like Earth for which we humans can calculate economic challenges due to natural disasters..\n\n\"The 1-sample t-test is used when we want to compare a sample mean to a population mean (which we already know).\" [quote from iaingallagher blog, \"t-tests in python\"](https:\/\/iaingallagher.tumblr.com\/post\/50980987285\/t-tests-in-python).\n\nIn our scenario we can already calculate the mean cost of natural disasters for all years 1900-2018, and then use the t-test to conclude whether the years in the 21st century are exceptionally high, when there were higher numbers of natural disasters (as shown earlier).\n","8b883c47":"# Let's Combine This DataFrame with the Disasters Data!","6beba072":"# Change in Economic Cost Over Time - Is it Normal?","92fb7d7c":"# Plot the Change in Carbon Emissions Annually, from 1973-2016\n","98c4a467":"## Correlations","8f994287":"# 1: Getting a \"Feel\" For the Data\n\n[Link to natural disasters dataset.](https:\/\/www.kaggle.com\/dataenergy\/natural-disaster-data)","7f9fb375":"# Given a year is between 2000-2018, what is the chance that it's number of total disasters is greater than the average number of disasters for all years 1900-2018?","7c390313":"# 3: Bayes' Theorem\n## $ P(A|B) = \\frac{P(A and B)}{P(A)} $","83368442":"# Wait, what? \n## Why the drop around 2000?","39a3ddea":"# Breaking it Down Even Further\n## Years and Counts","fa712732":"# Function to Perform This Step for all Decades 1900-2010","0511626d":"# Is Climate Change Real? How Do You Know?","e7edd286":"# 2. Disasters in the 21st Century\n\n## The population subset of years 2000-2018 make up:\n- about 45% of all years that have above average number of total natural disasters (1900-2018)\n- and approximately 37.5% of those years that have above average number of total natural disasters, compared to the annual mean of the 20th century (1900-2000).\n","10f1c2a3":"# What's the probability that any given natural disaster between 1900-2018, happened 1900-1999? ","60994727":"# Getting a Feel for the Economic Data\n[Link to dataset, same as for the natural disasters data.](https:\/\/www.kaggle.com\/dataenergy\/natural-disaster-data)","8f7b2c68":"# Plot of Changing Mean of Disaster Counts, By Decade","f978b104":"# 1. Rising Above (and Below) the Mean\n\n## By the decade, the mean and median count of natural disasters rises throughout the 20th century, and have dropped (so far) during the 21st century.\n## Reason why? Possibly due to regression to the mean, because truly the natural disaster counts of the 2000's decade fluctuates up and down.","ce439ddf":"# We need* to take a lot at our IQR!\n\n### **because we don't have a normal distribution*\n","40bbc4c6":"# How does the mean number of natural disasters change by the decade?","008df3dc":"# What About 2000-2018?","f7d5fe6e":"# Functions to Compute Mean Amount of Disasters Annually, for a Given Decade","53a8e89f":"## What Kinds of Values are There for \"Entity\"?","2a478329":"# How does the median number of natural disasters change by decade?\u00b6","924a02c1":"# 7: The (Economic) Cost of Natural Disasters","ee8fcc09":"# Plot the Change in Disaster Count Median, By Decade","a24435c9":"# Time Series Plot","bdb0254f":"# 6: Correlation to Economic Damages\n## Because the p-value of t-test  is less than 0.05, we can accept that as disasters go up, so will their costliness! \n\n## Perhaps we would already have expected this?\n\n## The amount that inflation factors into the cost is currently unknown.","3f5441fc":"##  Do all years 2000-2018 have more total disasters than the mean?","f50ddd2d":"# So how does the probability we're looking for, differ from the one before?","c5e02a7c":"# Our Data is Subject to Regression to the Mean!\n## How can we reach better conclusions*?\n### **Without just getting more data*","5257285e":"# Wait, emissions are going down?\n## Remember, this Data was Only for the Emissions Produced for Electricity in the U.S.!\n\n[Globally, emissions are up](https:\/\/www.wri.org\/blog\/2018\/12\/new-global-co2-emissions-numbers-are-they-re-not-good).","bb1d2301":"### Warning About the Above Time Series!\n I **do not** currently know whether or not the costs reported in the dataset are **adjusted for inflation.**\n\nIf it turns out the costs are not, we can only take the distribution with a grain of salt. **We don't really know if the disasters are costlier in terms of value, or if it's just inflation making everything more expensive over time.**","41b0e53b":"# 2: How Are the Natural Disasters Changing Over Time?\n## Is Climate Change Real? ","5c9442f9":"# Getting a Feel of the Carbon Emissions Data\n\n## This provides the monthly carbon emissions from electricity generation, by the Energy Information Administration.\n\n[Link to the dataset](https:\/\/www.kaggle.com\/txtrouble\/carbon-emissions).","81d21311":"# Is the Distribution of Disasters \"Balanced\" Between the Centuries?","c4d26abe":"### In our scenario:\n\n### $ P(A|B) $ = P(Year Has More Natural Disasters than the Mean for All Years 1900-2018, Given Year is 2000-2018)\n\n### $ P(A) $ = P(Year is Between 2000-2018) ","fe21c989":"# Heatmap","d637e9a3":"# 6: How Has the Amount of Carbon Emissions Looked Over the Turn of the Century?","107ec4b7":"# Bayes' Theorem, pt. 2\n### Do we really need to set 2000 as our checkpoint?\n\n# Given a year is between 2000-2018, what is the chance that it's number of total disasters is greater than the average number of disasters for all years 1900-2000?","c783d694":"# 4. Skewing Our Data?\n## None of the natural diaster counts in our dataset constitute as outliers, suggesting some correlation is possible between how the counts have changed over time, with other variables.","7ae465dc":"# Analogous Functions for the Medians By Decade","be125375":"# 3. Distribution Across Centuries\n## The relative frequency of natural disasters within the first 18 years of this century, is nearly half to that of the entirety of the previous century.","797dfe1a":"# What is the mean number of total natural disasters annually, for all years 1900-2018?","1422ffd1":"# How Many Years Between 1900-2018 Have More Than This Mean?","34f0e305":"# 5: Correlation to Carbon Emissions\n\n## According to the data provided by the EIA, over the turn of the century the number of carbon emissions due to total electricity generation in the U.S. has decreased annually."}}