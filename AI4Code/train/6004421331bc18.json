{"cell_type":{"601eb3c9":"code","2dcc435e":"code","7f3a2d2d":"code","2d71fbe7":"code","332604a8":"code","5e3315ec":"code","0fac9c34":"code","06f6aed6":"code","c1ba9d52":"code","81ceba02":"code","eff0339d":"code","42dbe6d6":"code","5b4a94c1":"code","596d2cb6":"code","660e04f5":"markdown","74d2f20e":"markdown","0b1c2d82":"markdown","fcb81b17":"markdown","2d3f2521":"markdown","2dc41d99":"markdown","bdae1bbb":"markdown","d354e41d":"markdown","f28e1800":"markdown","7f8c90a1":"markdown","6ab049b0":"markdown"},"source":{"601eb3c9":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\nfrom pathlib import Path\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\n\n\"\"\"\n         Own libraries\n\"\"\"\nfrom sliderunnerdatabase import Database\nfrom objectdetectiontools import get_slides, PascalVOCMetric, create_anchors,ObjectItemListSlide, SlideObjectCategoryList, bb_pad_collate_min, show_anchors_on_images, slide_object_result \nfrom retinanet import RetinaNet,RetinaNetFocalLoss","2dcc435e":"path = Path('\/kaggle\/input\/mitosis-wsi-ccmct-training-set\/')\n\ndatabase = Database()\ndatabase.open(str(path\/'MITOS_WSI_CCMCT_ODAEL_train_dcm.sqlite'))\n\n\ngetslides = \"\"\"SELECT filename FROM Slides\"\"\"\nall_slides = database.execute(getslides).fetchall()\n\n","7f3a2d2d":"lbl_bbox, train_slides,val_slides,files = get_slides(slidelist_test=[1,2,3,4,5,6,7,8,9,10,11,12,13,14], size=512, positive_class=2, negative_class=7, database=database,basepath=str(path))\n            ","2d71fbe7":"bs = 16\ntrain_images = 5000\nval_images = 5000\nsize=512\n\nimg2bbox = dict(zip(files, np.array(lbl_bbox)))\nget_y_func = lambda o:img2bbox[o]\n\ntfms = get_transforms(do_flip=True,\n                      flip_vert=True,\n                      max_rotate=90,\n                      max_lighting=0.0,\n                      max_zoom=1.,\n                      max_warp=0.0,\n                      p_affine=0.5,\n                      p_lighting=0.0,\n                      #xtra_tfms=xtra_tfms,\n                     )\ntrain_files = list(np.random.choice([files[x] for x in train_slides], train_images))\nvalid_files = list(np.random.choice([files[x] for x in val_slides], val_images))\n\n\ntrain =  ObjectItemListSlide(train_files, path=path)\nvalid = ObjectItemListSlide(valid_files, path=path)\nvalid = ObjectItemListSlide(valid_files, path=path)\nitem_list = ItemLists(path, train, valid)\nlls = item_list.label_from_func(get_y_func, label_cls=SlideObjectCategoryList) #\nlls = lls.transform(tfms, tfm_y=True, size=size)\ndata = lls.databunch(bs=bs, collate_fn=bb_pad_collate_min, num_workers=4).normalize()","332604a8":"data.show_batch(rows=2, ds_type=DatasetType.Train, figsize=(15,15))","5e3315ec":"anchors = create_anchors(sizes=[(32,32)], ratios=[1], scales=[0.6, 0.7,0.8])\nnot_found = show_anchors_on_images(data, anchors)","0fac9c34":"crit = RetinaNetFocalLoss(anchors)\nencoder = create_body(models.resnet18, True, -2)\nmodel = RetinaNet(encoder, n_classes=data.train_ds.c, n_anchors=3, sizes=[32], chs=128, final_bias=-4., n_conv=3)\n\n\nvoc = PascalVOCMetric(anchors, size, [str(i-1) for i in data.train_ds.y.classes[1:]])\nlearn = Learner(data, model, loss_func=crit, callback_fns=[ShowGraph], #BBMetrics, ShowGraph\n                metrics=[voc]\n               )","06f6aed6":"learn.split([model.encoder[6], model.c5top5])\nlearn.freeze_to(-2)\nlearn.model_dir='\/kaggle\/working\/'\n\nlearn.lr_find()\nlearn.recorder.plot()","c1ba9d52":"learn.fit_one_cycle(1, 1e-4)","81ceba02":"slide_object_result(learn, anchors, detect_thresh=0.3, nms_thresh=0.2, image_count=10)","eff0339d":"learn.unfreeze()","42dbe6d6":"learn.fit_one_cycle(10,1e-4)","5b4a94c1":"slide_object_result(learn, anchors, detect_thresh=0.3, nms_thresh=0.2, image_count=10)","596d2cb6":"learn.export('\/kaggle\/working\/RetinaNetMitoticFigures')","660e04f5":"And now let's fit the network using the cyclic learning rate scheme for 10 \"epochs\"","74d2f20e":"Let's have a look at the data - from the data set, only mitotic figure cells are selected. Additionally, the training provides images with a high probability of mitotic-figure-lookalikes (see the paper).","0b1c2d82":"Looks cool. \n\nNow create the network. Note that for this step, internet access is required, since fast.ai wants to download the pre-trained weights for the ResNet18 stem.","fcb81b17":"Create anchors for object detection and show them on the image.","2d3f2521":"# Train RetinaNet model on CCMCT data set\n\nTrain a RetinaNet model for mitotic figure detection on the MITOS_WSI_CCMCT data set. Note that this kaggle-version of the data set was converted to the DICOM format, and for the sake of dataset size only the lowest (i.e., highest resolution) layer of data was exported.\n\nAs of writing, the MITOS_WSI_CCMCT data set is the only set providing mitotic figure annotations and mitotic figure look-alikes for the complete microscopy slide image (in total, 44k mitotic figures on 32 WSI).\n\nThis is an excerpt of the data set. For the complete set and more information about it, please see our publication in Scientific Data:\n- Bertram, C.A., Aubreville, M., Marzahl, C. et al. A large-scale dataset for mitotic figure assessment on whole slide images of canine cutaneous mast cell tumor. Sci Data 6, 274 (2019) doi:10.1038\/s41597-019-0290-4\n\nCredits to some of the library code:\n- https:\/\/github.com\/ChristianMarzahl\/ObjectDetection\n- https:\/\/github.com\/rafaelpadilla\/Object-Detection-Metrics\n\nAdditionally, some of my code:\n- https:\/\/github.com\/maubreville\/MITOS_WSI_CCMCT\n- https:\/\/github.com\/maubreville\/SlideRunner\n\n","2dc41d99":"Our model was trained vor several more epochs, but GPU time on kaggle is rare so we stop here with our proof of principle.","bdae1bbb":"Let's see how the network performs now.","d354e41d":"1e-4 seems to be a good value. Let's fit the (frozen, except the heads) network for a cycle of 1 epoch (5000 randomly cropped images)","f28e1800":"Let's have a quick peek at the preliminary state ...","7f8c90a1":"Not great, but a good start. Let's now unfreeze the network (i.e., allow all layers to train)","6ab049b0":"Let's now find the optimal learning rate."}}