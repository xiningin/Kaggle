{"cell_type":{"dc0cf786":"code","47266ba9":"code","81d37e0a":"code","f0da4a3c":"code","1dc3b281":"code","fa54aff6":"code","3c5e8164":"code","4a830d95":"code","b0f039ab":"code","025544fc":"code","6b762204":"code","8e7d6c13":"code","1253ac77":"code","ec5a1e18":"code","0c836fd2":"code","c0f4db9c":"code","28c15a06":"code","2fd5c46c":"code","3142b39e":"code","b888aa8f":"markdown","24663b98":"markdown","feefbd26":"markdown","51fd3c2e":"markdown","af5f13b2":"markdown","9838958a":"markdown","6a9a6431":"markdown","d8a21851":"markdown","dbe0a2a5":"markdown","cb35a1a9":"markdown","33baf1cc":"markdown","6e96941b":"markdown","7b8ae1d0":"markdown","28a4b004":"markdown","37ce921a":"markdown","589e86d4":"markdown","ec1f111e":"markdown"},"source":{"dc0cf786":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport sklearn.preprocessing\nfrom sklearn.metrics import r2_score\n\nfrom keras.layers import Dense,Dropout,SimpleRNN,LSTM\nfrom keras.models import Sequential\n\n#check all the files in the input dataset\nprint(os.listdir(\"..\/input\/\"))","47266ba9":"#choosing DOM_hourly.csv data for analysis\nfpath='..\/input\/DOM_hourly.csv'\n\ndf=pd.read_csv(fpath)\ndf.head()","81d37e0a":"#Let's use datetime(2012-10-01 12:00:00,...) as index instead of numbers(0,1,...)\n#This will be helpful for further data analysis as we are dealing with time series data\ndf = pd.read_csv(fpath, index_col='Datetime', parse_dates=['Datetime'])\ndf.head()","f0da4a3c":"#checking missing data\ndf.isna().sum()","1dc3b281":"df.plot(figsize=(16,4),legend=True)\n\nplt.title('DOM hourly power consumption data - BEFORE NORMALIZATION')\n\nplt.show()","fa54aff6":"def normalize_data(df):\n    scaler = sklearn.preprocessing.MinMaxScaler()\n    df['DOM_MW']=scaler.fit_transform(df['DOM_MW'].values.reshape(-1,1))\n    return df\n\ndf_norm = normalize_data(df)\ndf_norm.shape","3c5e8164":"df_norm.plot(figsize=(16,4),legend=True)\n\nplt.title('DOM hourly power consumption data - AFTER NORMALIZATION')\n\nplt.show()","4a830d95":"df_norm.shape","b0f039ab":"def load_data(stock, seq_len):\n    X_train = []\n    y_train = []\n    for i in range(seq_len, len(stock)):\n        X_train.append(stock.iloc[i-seq_len : i, 0])\n        y_train.append(stock.iloc[i, 0])\n    \n    #1 last 6189 days are going to be used in test\n    X_test = X_train[110000:]             \n    y_test = y_train[110000:]\n    \n    #2 first 110000 days are going to be used in training\n    X_train = X_train[:110000]           \n    y_train = y_train[:110000]\n    \n    #3 convert to numpy array\n    X_train = np.array(X_train)\n    y_train = np.array(y_train)\n    \n    X_test = np.array(X_test)\n    y_test = np.array(y_test)\n    \n    #4 reshape data to input into RNN models\n    X_train = np.reshape(X_train, (110000, seq_len, 1))\n    \n    X_test = np.reshape(X_test, (X_test.shape[0], seq_len, 1))\n    \n    return [X_train, y_train, X_test, y_test]","025544fc":"#create train, test data\nseq_len = 20 #choose sequence length\n\nX_train, y_train, X_test, y_test = load_data(df, seq_len)\n\nprint('X_train.shape = ',X_train.shape)\nprint('y_train.shape = ', y_train.shape)\nprint('X_test.shape = ', X_test.shape)\nprint('y_test.shape = ',y_test.shape)","6b762204":"rnn_model = Sequential()\n\nrnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\nrnn_model.add(Dropout(0.15))\n\nrnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True))\nrnn_model.add(Dropout(0.15))\n\nrnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=False))\nrnn_model.add(Dropout(0.15))\n\nrnn_model.add(Dense(1))\n\nrnn_model.summary()","8e7d6c13":"rnn_model.compile(optimizer=\"adam\",loss=\"MSE\")\nrnn_model.fit(X_train, y_train, epochs=10, batch_size=1000)","1253ac77":"rnn_predictions = rnn_model.predict(X_test)\n\nrnn_score = r2_score(y_test,rnn_predictions)\nprint(\"R2 Score of RNN model = \",rnn_score)","ec5a1e18":"def plot_predictions(test, predicted, title):\n    plt.figure(figsize=(16,4))\n    plt.plot(test, color='blue',label='Actual power consumption data')\n    plt.plot(predicted, alpha=0.7, color='orange',label='Predicted power consumption data')\n    plt.title(title)\n    plt.xlabel('Time')\n    plt.ylabel('Normalized power consumption scale')\n    plt.legend()\n    plt.show()\n    \nplot_predictions(y_test, rnn_predictions, \"Predictions made by simple RNN model\")","0c836fd2":"lstm_model = Sequential()\n\nlstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\nlstm_model.add(Dropout(0.15))\n\nlstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=True))\nlstm_model.add(Dropout(0.15))\n\nlstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=False))\nlstm_model.add(Dropout(0.15))\n\nlstm_model.add(Dense(1))\n\nlstm_model.summary()","c0f4db9c":"lstm_model.compile(optimizer=\"adam\",loss=\"MSE\")\nlstm_model.fit(X_train, y_train, epochs=10, batch_size=1000)","28c15a06":"lstm_predictions = lstm_model.predict(X_test)\n\nlstm_score = r2_score(y_test, lstm_predictions)\nprint(\"R^2 Score of LSTM model = \",lstm_score)","2fd5c46c":"plot_predictions(y_test, lstm_predictions, \"Predictions made by LSTM model\")","3142b39e":"plt.figure(figsize=(15,8))\n\nplt.plot(y_test, c=\"orange\", linewidth=3, label=\"Original values\")\nplt.plot(lstm_predictions, c=\"red\", linewidth=3, label=\"LSTM predictions\")\nplt.plot(rnn_predictions, alpha=0.5, c=\"green\", linewidth=3, label=\"RNN predictions\")\nplt.legend()\nplt.title(\"Predictions vs actual data\", fontsize=20)\nplt.show()","b888aa8f":"- **Let's check r2 score for the values predicted by the above trained LSTM model**","24663b98":"- **Let's compare the actual values vs predicted values by plotting a graph**\n- We see that the predcited values are close to the actual values meaning the RNN model is performing well in predicting the sequence.","feefbd26":"## 3. Prepare data for training the RNN models","51fd3c2e":"- **Check if there are missing values in the data loaded**","af5f13b2":"## 5. Build an LSTM model","9838958a":"- In this kernel I will provide all the steps required for doing time series analysis using time series data and simple RNN, LSTM models.\n- You can see the performance of simple RNN model, LSTM model and compare their performance.\n\n## 1. Basic step","6a9a6431":"## 2. Data loading and data exploration\n\n- **Load the data file**","d8a21851":"## 6. Compare predictions made by simple RNN, LSTM model by plotting data in a single graph","dbe0a2a5":"## 4. Build a SIMPLE RNN model","cb35a1a9":"- **Change the index of rows in the dataframe from 0,1,2... to datetime (2005-12-31 01:00:00,...)**\n\n**Why should we change the index of rows?**<br>\nBecause we are dealing with time series data and we will need the datetime data to recognize a particular record.","33baf1cc":"**To get an understanding on how sequence length is useful in training RNN models refer to the following links:**\n- https:\/\/stackoverflow.com\/questions\/49573242\/what-is-sequence-length-in-lstm\n- https:\/\/stats.stackexchange.com\/questions\/158834\/what-is-a-feasible-sequence-length-for-an-rnn-to-model","6e96941b":"- **Let's check r2 score for the values predicted by the above trained SIMPLE RNN model**\n- For more info on r2 score refer [this](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.r2_score.html)","7b8ae1d0":"- **Let's compare the actual values vs predicted values by plotting a graph**","28a4b004":"**References:**\n- https:\/\/www.kaggle.com\/thebrownviking20\/everything-you-can-do-with-a-time-series\n- https:\/\/www.kaggle.com\/thebrownviking20\/intro-to-recurrent-neural-networks-lstm-gru","37ce921a":"- **Normalize data**\n- Before proceeding with further data analysis we must ensure that the data is normalized. \n- For this we will be using [sklearn MinMaxScaler](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.MinMaxScaler.html)","589e86d4":"- **Visualize data after normalization**\n- After normalization the range of power consumption values changes which we can observe on the **y-axis** of the graph. In the earlier graph that was displayed it was in the range **0 - 22500**\n- Now after normalization we can observe that the data range on **y-axis** is **0.0 - 1.0**","ec1f111e":"Since there is no missing data in the data loaded we will not be dropping the missing value records or will not be imputing the data. We will proceed with the further data analysis.\n\n- **Data visualization**"}}