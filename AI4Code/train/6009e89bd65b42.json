{"cell_type":{"640683bb":"code","cf28f999":"code","2e2bce7a":"code","6bd7643b":"code","2b4795f2":"code","854d40d6":"code","b1b70b23":"code","045de998":"code","1443f7f8":"code","6c7c719e":"code","ccf07b65":"markdown","c711a79a":"markdown","3cb36bb4":"markdown","edb25f13":"markdown","38e0e81e":"markdown","8be6e069":"markdown","e4b6c19c":"markdown","e4c4cf83":"markdown","f7d17335":"markdown","cdd9913a":"markdown"},"source":{"640683bb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","cf28f999":"data = pd.read_csv('..\/input\/predictingese\/AttendanceMarksSA.csv')\ndata.head()","2e2bce7a":"X= data['MSE']\nY=data['ESE']\nsns.scatterplot(X,Y)","6bd7643b":"theta0=0\ntheta1=0\nalpha=0.01\ncount =10000\nm=len(X) # m is number of example s i.e number of students here","2b4795f2":"for i in range(count): \n    Y_hat = theta1*X + theta0    \n    theta0 = theta0 - (alpha\/m)*sum(Y_hat-Y)\n    theta1 = theta1 - (alpha\/m)*sum(X*(Y_hat-Y))\n    \nprint(theta0,theta1)","854d40d6":"Y_hat = theta1*X + theta0\n\nplt.scatter(X, Y) \nplt.plot([min(X), max(X)], [min(Y_hat), max(Y_hat)], color='red')  # regression line\nplt.show()","b1b70b23":"import math\ndef RSE(y_true, y_predicted):\n   \n    y_true = np.array(y_true)\n    y_predicted = np.array(y_predicted)\n    RSS = np.sum(np.square(y_true - y_predicted))\n\n    rse = math.sqrt(RSS \/ (len(y_true) - 2))\n    return rse\n\n\nrse= RSE(data['ESE'],Y_hat)\nprint(rse)","045de998":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n ","1443f7f8":"x = np.array(data['MSE']).reshape(-1,1)\ny = np.array(data['ESE']).reshape(-1,1)\n \n\nmodel = LinearRegression()\nmodel.fit(x,y)\n\n\nprint(model.coef_)\nprint(model.intercept_)\n\ny_predict = model.predict(x)\nrse = RSE(y,y_predict)\n\nprint(rse)\n\n \n","6c7c719e":"marks = [17]\nresult = model.predict([marks])\nprint(result)","ccf07b65":"predicting score","c711a79a":"Calculating Residual standard Error","3cb36bb4":"Simple Linear Regression with Gradient Descent and Scikit method","edb25f13":"1.Gradient Descent\n  importing Libary Functions","38e0e81e":"if my marks are 17 in Mid semster Examination,my score for End Semster Examination would be 58","8be6e069":"2.Using Scikit-Learn","e4b6c19c":"Plotting Regression line","e4c4cf83":"> Implementation \nCalculating Residual Standard Error","f7d17335":"> Gradient Descent","cdd9913a":"Implementing Gradient Descent"}}