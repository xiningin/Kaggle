{"cell_type":{"51031b7a":"code","0ddeb975":"code","cf563fd7":"code","850fee55":"code","61a549f4":"code","70554ba7":"code","2c551118":"code","bddd80a9":"code","2fdc470e":"code","2d05c79d":"code","069d606f":"code","7c46a357":"code","886d29ae":"code","ec7771d7":"code","03202f20":"code","fd733397":"code","d9988932":"code","22a4f7ae":"markdown","eb34b351":"markdown","9b279911":"markdown","86fe7e60":"markdown","fb095332":"markdown","41c65051":"markdown"},"source":{"51031b7a":"!git clone --branch inference-tf-2.x https:\/\/github.com\/steubk\/White-box-Cartoonization.git\n!pip install --upgrade tf_slim","0ddeb975":"import sys\nsys.path.append('.\/White-box-Cartoonization\/test_code')\n\nimport os\nimport matplotlib.pyplot as plt\nimport cartoonize\n\nfrom PIL import Image","cf563fd7":"!mkdir -p .\/source\n!wget https:\/\/raw.githubusercontent.com\/pratapvardhan\/cartoonizer-with-tfjs\/master\/assets\/messi-ronaldo.jpg  -O .\/source\/image.jpg","850fee55":"model_path = '.\/White-box-Cartoonization\/test_code\/saved_models'\nload_folder = '.\/source'\nsave_folder = '.\/cartoonized_images'\nif not os.path.exists(save_folder): os.mkdir(save_folder)\n\ncartoonize.cartoonize(load_folder, save_folder, model_path)\nsource_image = plt.imread('.\/source\/image.jpg')\ncartoonized_image = plt.imread('.\/cartoonized_images\/image.jpg')\n\nfig, ax = plt.subplots(1, 2, figsize=(15, 5))\nax[0].imshow(source_image)\nax[0].set_title('Source image')\nax[1].imshow(cartoonized_image)\nax[1].set_title('Cartoonized image')\n[x.set_axis_off() for x in ax]\nplt.show()","61a549f4":"# Directory where SavedModel is to be saved\n!mkdir -p models\/CartoonGAN\/saved_model","70554ba7":"# Comes with the GitHub repo\n# These will be needed to instantiate the model\nimport network\nimport guided_filter","2c551118":"# We will be using TensorFlow session\nimport tensorflow.compat.v1 as tf\ntf.disable_eager_execution()","bddd80a9":"tf.__version__","2fdc470e":"tf.reset_default_graph()\n  \nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\n\nwith tf.Session(config=config) as sess:\n  # Create placeholder for the input\n  input_photo = tf.placeholder(tf.float32, [1, None, None, 3], name='input_photo')\n  \n  # Run the input placeholder through the generator, and then apply a \n  # filter to process the generator output\n  network_out = network.unet_generator(input_photo)\n  final_out = guided_filter.guided_filter(input_photo, network_out, r=1, eps=5e-3)\n  final_out = tf.identity(final_out, name='final_output') # Create an identical filtering layer \n \n  # The above process is basically needed to construct the computation graph for the\n  # current session\n  \n  # Get the generator variables and restore the pre-trained checkpoints in the \n  # current session\n  all_vars = tf.trainable_variables()\n  gene_vars = [var for var in all_vars if 'generator' in var.name]\n  saver = tf.train.Saver(var_list=gene_vars)\n  sess.run(tf.global_variables_initializer())\n  saver.restore(sess, tf.train.latest_checkpoint(model_path))\n  \n  # Export to SavedModel\n  tf.saved_model.simple_save(\n      sess,\n      '\/content\/models\/CartoonGAN\/saved_model',\n      inputs={input_photo.name: input_photo},\n      outputs={final_out.name: final_out})","2d05c79d":"ls -lah models\/CartoonGAN\/saved_model","069d606f":"# Install tensorflowjs for tensorflowjs_converter\n!pip install tensorflowjs --quiet","7c46a357":"!tensorflowjs_converter --input_format=tf_saved_model --output_node_names='final_output' \\\n    models\/CartoonGAN\/saved_model models\/CartoonGAN\/web","886d29ae":"!tensorflowjs_converter --quantize_float16 \\\n    --input_format=tf_saved_model --output_node_names='final_output' \\\n    models\/CartoonGAN\/saved_model models\/CartoonGAN\/web-float16","ec7771d7":"!tensorflowjs_converter --quantize_uint8 \\\n    --input_format=tf_saved_model --output_node_names='final_output' \\\n    models\/CartoonGAN\/saved_model models\/CartoonGAN\/web-uint8","03202f20":"!du -sh models\/CartoonGAN\/*","fd733397":"!zip -r models.zip models","d9988932":"from google.colab import files\nfiles.download('models.zip')","22a4f7ae":"**Check model sizes**","eb34b351":"**Quantize the weights (Float 16)**","9b279911":"**Quantize the weights (unit 8)**","86fe7e60":"## Original paper presented by Xinrui Wang and Jinze Yu. Find it [here](https:\/\/openaccess.thecvf.com\/content_CVPR_2020\/html\/Wang_Learning_to_Cartoonize_Using_White-Box_Cartoon_Representations_CVPR_2020_paper.html)","fb095332":"**Download models**","41c65051":"## TensorFlow.js conversion"}}