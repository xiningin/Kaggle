{"cell_type":{"c55b8b1d":"code","b2d98c0b":"code","26538135":"code","d0e7a3f7":"code","066b8e38":"code","3e87d9ce":"code","abd0b999":"code","dd369e76":"code","c0267a42":"code","09c53e24":"code","00e13023":"code","1ad31510":"code","86f24f3d":"code","0960798e":"code","971c22ee":"markdown","b9bffd04":"markdown","7a49b996":"markdown","0025c490":"markdown","f2434a70":"markdown","17968853":"markdown","c56db98b":"markdown","fc064010":"markdown","74e26e22":"markdown","66cc0895":"markdown","1e0a0809":"markdown","d6fa4fd3":"markdown"},"source":{"c55b8b1d":"# Import packages\nimport numpy as np\nimport pandas as pd\n\n# Read the data\ndata_df = pd.read_csv(\"\/kaggle\/input\/gender-classification\/Transformed Data Set - Sheet1.csv\")\n\n# Take a look at some data examples\ndata_df.head(10)","b2d98c0b":"# Describe the data\ndata_df.describe()","26538135":"# Turn male into 1 and female 0\ndata_df['Gender'].replace(to_replace = 'F', value = 0, inplace = True)\ndata_df['Gender'].replace(to_replace = 'M', value = 1, inplace = True)","d0e7a3f7":"# Create one hot encoding\nfav_color_df = pd.get_dummies(data_df[[\"Favorite Color\"]], prefix = \"color\")\nfav_music_df = pd.get_dummies(data_df[[\"Favorite Music Genre\"]], prefix = \"music\")\nfav_beverage_df = pd.get_dummies(data_df[[\"Favorite Beverage\"]], prefix = \"beverage\")\nfav_drink_df = pd.get_dummies(data_df[[\"Favorite Soft Drink\"]], prefix = \"drink\")","066b8e38":"# Merging one hot encoding and create new dataframe\ntransformed_df = pd.merge(fav_color_df, fav_music_df, left_index = True, right_index = True)\ntransformed_df = pd.merge(transformed_df, fav_beverage_df, left_index = True, right_index = True)\ntransformed_df = pd.merge(transformed_df, fav_drink_df, left_index = True, right_index = True)\n\n# Take a look at some data examples\ntransformed_df.head(10)","3e87d9ce":"# Choose feature (Manual)\nfeature = [\n    \"music_Electronic\",\n    \"music_Hip hop\",\n    \"music_Jazz\/Blues\",\n    \"music_Pop\",\n    \"music_R&B and soul\",\n    \"beverage_Vodka\",\n    \"drink_Other\"\n]","abd0b999":"# Choose all feature\n# feature = []\n# for col in transformed_df.columns:\n#     feature.append(col)","dd369e76":"# Choose feature (By rule)\n# feature = []\n# analyze_df = pd.merge(transformed_df, data_df[\"Gender\"], left_index = True, right_index = True)\n# for index, row in analyze_df.corr().iterrows():\n#     if abs(row[\"Gender\"]) > 0.08 and index != \"Gender\":\n#         feature.append(index)","c0267a42":"# Import packages related to training model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score\n\n# Turn into numpy array\nX = np.asarray(transformed_df[feature])\ny = np.asarray(data_df['Gender'])\n\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","09c53e24":"# Preprocess train data\nheader = []\nfor col in transformed_df[feature].columns:\n    header.append(col)\nheader = np.array(header)\n\nx_df = pd.DataFrame(\n    X_train,\n    columns = header\n)\n\ny_df = pd.DataFrame(\n    y_train,\n    columns = [\"gender\"]\n)\n\ntrain_df = pd.merge(x_df, y_df, left_index = True, right_index = True)\n\n# Look at the correlation\ncorr_df = train_df.corr()\ncorr_df.head(len(feature))","00e13023":"# Create logistic regression\nLR = LogisticRegression().fit(X_train, y_train)","1ad31510":"# Predict result\ny_predict = LR.predict(X_test)\n\n# Evaluate the accuracy\nscore = accuracy_score(y_predict, y_test)\n\n# Print result\nprint(\"The accuracy is \" + str(score))","86f24f3d":"# Using NN model\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Create callback\nclass myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs = {}):\n        if ((logs.get('val_accuracy') > 0.72 and logs.get('val_loss') <= 0.5931) or logs.get('val_accuracy') >= 0.9):\n            self.model.stop_training = True\n            print(\"Stop here\")\ncallback = myCallback()\n\n# Build model\ntf.random.set_seed(42)\nmodel = keras.Sequential([\n    keras.layers.Dense(128, activation = 'relu', input_shape = [len(feature)]),\n    keras.layers.Dropout(0.4),\n    keras.layers.Dense(2, activation = 'softmax')\n])\n\n# Compile model\nmodel.compile(\n    loss = 'binary_crossentropy',\n    optimizer = keras.optimizers.Adam(0.001),\n    metrics = ['accuracy']\n)\n\n# Fit the model\nmodel.fit(\n    X_train, y_train,\n    epochs = 200,\n    batch_size = 1,\n    verbose = 1,\n    validation_split = 0.2,\n    callbacks = [callback]\n)","0960798e":"# Predict result (If the last layer using softmax)\ny_predict = model.predict(X_test)\nresult = []\nfor index in range(len(y_predict)):\n  each_result = np.argmax(y_predict[index])\n  result.append(each_result)\n\n# Formatting\nresult = np.array(result)\n    \n# Evaluate the accuracy\nscore = accuracy_score(result, y_test)\n\n# Print result\nprint(\"The accuracy is \" + str(score))","971c22ee":"## **Preprocessing the Data**  \nNext, we will do some pre-processing to the data, such as turn categorical variables into one-hot-encoding form.","b9bffd04":"# **GENDER CLASSIFICATION**\n**By : Garry Ariel**\n\nThis notebook contains the steps of processing given information, build and train the model, and use it to predict gender. The model used here are Logistic Regression (LR) and Neural Network (NN).","7a49b996":"Take a look some statistics about the data using following syntax.","0025c490":"## **Preparing Data**\nIn the following step, we will format the data so that the data can be feed into the model. We will also split the data into train and test dataset with the comparison of 4:1.","f2434a70":"2. Choose all features without filter it.","17968853":"## **Build and Train Neural Network**\n\nThe model we used here are as the following.\n1. Fully connected layer with 128 neurons using ReLU activation function.\n2. Dropout layer with probability 0.4.\n3. Fully connected layer with 2 neurons (as output) using softmax activation function.","c56db98b":"## **Build and Train Logistic Regression Model**\n\nWe will just simply feed the model with the data using any default parameters. After trained, we use the model to predict the gender, and evaluate the accuracy. To experiment with the accuracy, we can change the features we used in previous steps.","fc064010":"## **Feature Selection**\nNext, we will select some features which will be used to feed the model later. We specified 3 ways to select the features.","74e26e22":"Then we used the trained NN model to predict the gender and evaluate the accuracy. As before, we can experiment with the accuracy by change the features we used, or changing some parameters.","66cc0895":"1. Choose the feature manually.\nWe can experiment about which features give higher accuracy.","1e0a0809":"3. Choose features based on its correlation to gender variable. Specify a threshold, such that every features which have correlation to gender variable greater than threshold will be chosen as a feature.","d6fa4fd3":"First thing to do is import some necessary packages and read the data in."}}