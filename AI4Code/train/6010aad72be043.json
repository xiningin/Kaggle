{"cell_type":{"87a48d53":"code","94c83af1":"code","a0b7c36e":"code","95cf5bcd":"code","db81b17c":"code","819868ec":"code","19e82da2":"code","a815132a":"code","07135b32":"code","5e9bfc9a":"code","da7ef7e9":"markdown"},"source":{"87a48d53":"import numpy as np\nimport pandas as pd\nfrom numpy import mean\nfrom numpy import std\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import KFold\nfrom keras.datasets import fashion_mnist\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Flatten\nfrom keras.optimizers import SGD","94c83af1":"def load_dataset():\n  (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n  print(\"Some Example images: \")\n  for i in range(9):\n\t  pyplot.subplot(330 + 1 + i)\n\t  pyplot.imshow(trainX[i], cmap=pyplot.get_cmap('gray'))\n  pyplot.show()\n  trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n  testX = testX.reshape((testX.shape[0], 28, 28, 1))\n  trainY = to_categorical(trainY)\n  testY = to_categorical(testY)\n\n  print(\"\\n\\nDataset loaded\")\n  print(\"Shape of TrainX: \" , trainX.shape)\n  print(\"Shape of TrainY: \" , trainY.shape)\n  print(\"Shape of TestX: \" , testX.shape)\n  print(\"Shape of TestY: \" , testY.shape)\n  print(\"Maximum in trainX \" , np.max(trainX) )\n\n  return trainX, trainY, testX, testY","a0b7c36e":"def prepare_pixels(train, test):\n  train_in_float = train.astype('float32')\n  train_norm = train_in_float \/ 255.0\n  test_in_float = test.astype('float32')\n  test_norm = test_in_float \/ 255.0\n\n  print(\"\\n\\nNormalised in [0,1]\")\n  print(\"Maximum in training data \", np.max(train_norm) )\n  \n  return train_norm, test_norm","95cf5bcd":"def make_model():\n  model = Sequential()\n  model.add(Conv2D(64, (3,3), padding='same', activation='relu', \\\n                      kernel_initializer='he_uniform', input_shape = (28, 28, 1)))\n  model.add(MaxPooling2D(2,2))\n  model.add(Flatten())\n  model.add(Dense(units=100, activation='relu', kernel_initializer='he_uniform'))\n  model.add(Dense(units=10, activation='softmax'))\n\n  opt = SGD(learning_rate=0.01, momentum=0.90)\n\n  model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n\n  return model","db81b17c":"def evaluate_model(dataX, dataY, n_folds):\n  scores, histories = list(), list()\n  kfold = KFold(n_splits=n_folds, shuffle=True, random_state=1)\n\n  for train_ix, test_ix in kfold.split(dataX):\n    model = make_model()\n    trainX_curr_fold, trainY_curr_fold, testX_curr_fold, testY_curr_fold \\\n    = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n\n    history = model.fit(trainX_curr_fold, trainY_curr_fold, epochs=10, batch_size=32,\\\n              validation_data=(testX_curr_fold, testY_curr_fold), verbose=2)\n    losss, accc = model.evaluate(testX_curr_fold, testY_curr_fold, verbose=2)\n    print(\"Accuracy here: %.3f\" % (accc*100.0))\n\n    scores.append(accc)\n    histories.append(history)\n\n  return scores, histories, model","819868ec":"def summarise_diagnostics(histories):\n  for i in range (len(histories)):\n    pyplot.subplot(211)\n    pyplot.title(\"Cross Entropy Loss\")\n    pyplot.plot(histories[i].history['loss'], color = 'blue', label = 'train')\n    pyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n\n    pyplot.subplot(212)\n    pyplot.title(\"Classification Accuracy\")\n    pyplot.plot(histories[i].history['loss'], color='blue', label='train')\n    pyplot.plot(histories[i].history['val_loss'], color = 'orange', label = 'test')\n  pyplot.show()","19e82da2":"def summarise_performance(scores):\n  print(\"Mean of train accuracy: %.2f\\n Std dev of train accuracy: %.2f\" \\\n        % (100*mean(scores), 100*std(scores)))\n  pyplot.boxplot(scores)\n  pyplot.show()","a815132a":"def driver():\n  trainX, trainY, testX, testY = load_dataset()\n  trainX, testX = prepare_pixels(train=trainX, test=testX)\n  model = make_model()\n  print(\"\\n\\nSummary of the prepared model:\")\n  model.summary()\n  scores, histories, model = evaluate_model(dataX=trainX, dataY=trainY, n_folds=5)\n  summarise_diagnostics(histories)\n  summarise_performance(scores)\n  test_loss, test_acc = model.evaluate(testX, testY, verbose = 2)\n  print(\"Test loss = %.3f\" % test_loss)\n  print(\"Test accuracy = %.3f\" % (test_acc*100))","07135b32":"driver()","5e9bfc9a":"%%html\n<h3><u> Reference<\/u><\/h3>\n<a href = \"https:\/\/machinelearningmastery.com\/how-to-develop-a-cnn-from-scratch-for-fashion-mnist-clothing-classification\/\">\nJason Brownlee PhD, How to Develop a Deep CNN for Fashion-MNIST Clothing Classification\n<\/a>\n\n<h3> <u>Implemented for practice by <\/u> <\/h3>\n<h4> Md. Al Siam <\/h4>\n<p> Dept of CSE <\/p>\n<a href = \"https:\/\/www.ruet.ac.bd\/\">\nRUET\n<\/a>","da7ef7e9":"<a href=\"https:\/\/colab.research.google.com\/github\/MdAlSiam\/Machine_Learning\/blob\/master\/Fashion_MNIST_with_CNN.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>"}}