{"cell_type":{"35f55ab9":"code","c7c3a10a":"code","212167af":"code","d7cd1a64":"code","613b7219":"code","749062ff":"code","1bc969cc":"code","88e965a3":"code","bbbedd7d":"code","723627dc":"code","eb8ef344":"code","087dc9e5":"code","36dba4d1":"code","f0a962b6":"code","0f604a2c":"code","eea95d91":"code","f44e8b74":"code","4a8b614a":"code","e33935f2":"code","2f3de0b2":"code","630bfced":"code","9e3461f7":"code","2a8a001c":"code","c986cd3a":"code","bbc460eb":"code","1e4c412a":"code","ad7ed724":"code","ff40556e":"code","70d6f173":"code","d99ffc2d":"code","bcd4a741":"markdown","e69d30d4":"markdown"},"source":{"35f55ab9":"import pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt \nimport numpy as np ","c7c3a10a":"df = pd.read_csv('..\/input\/body-performance-data\/bodyPerformance.csv')\ndf.head().style.background_gradient(axis = 0)","212167af":"df.info()","d7cd1a64":"# Now we transformed df['Gender'] column to numeric : \n\nfrom sklearn.preprocessing import LabelEncoder\nlab = LabelEncoder()\ndf['gender'] = lab.fit_transform(df['gender'])\ndf.head()","613b7219":"# Now we want to check if there is any missing data on the data that we will work on it :\n\nimport missingno as msg\nmsg.matrix(df)\n\n# As we see there is no missing data : ","749062ff":"df.head()","1bc969cc":"sns.countplot(data = df , x = 'gender')","88e965a3":"sns.countplot(data = df , x = 'class')","bbbedd7d":"sns.scatterplot(data = df , x = 'class' , y = 'body fat_%' ,hue = 'gender')","723627dc":"sns.scatterplot(data = df , x = 'class' , y = 'weight_kg' ,hue = 'gender')","eb8ef344":"sns.scatterplot(data = df , x = 'weight_kg' , y = 'body fat_%',hue ='gender')","087dc9e5":"sns.scatterplot(data = df , x = 'weight_kg' , y = 'height_cm',hue ='gender',alpha = 0.5)","36dba4d1":"plt.figure(figsize=(8,6),dpi = 150)\nsns.heatmap(df.corr(),annot = True , cmap = 'ocean')","f0a962b6":"X = df.drop('class' , axis = 1)\ny = df['class']","0f604a2c":"from sklearn.model_selection import train_test_split","eea95d91":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)","f44e8b74":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","4a8b614a":"scaled_X_train = scaler.fit_transform(X_train)\nscaled_X_test = scaler.transform(X_test)","e33935f2":"from sklearn.linear_model import LogisticRegressionCV\nlog_model = LogisticRegressionCV()\nlog_model.fit(scaled_X_train , y_train)","2f3de0b2":"# Now model fit on training data , and now will predict data that has never seen before : \n\ny_pred = log_model.predict(scaled_X_test)","630bfced":"# Now we are going to evaluate the model : \nfrom sklearn.metrics import accuracy_score , plot_confusion_matrix,roc_curve,auc","9e3461f7":"plot_confusion_matrix(log_model , scaled_X_test ,y_test)","2a8a001c":"def plot_multiclass_roc(clf, X_test, y_test, n_classes, figsize=(5,5)):\n    y_score = clf.decision_function(X_test)\n\n    # structures\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    # calculate dummies once\n    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # roc for each class\n    fig, ax = plt.subplots(figsize=figsize)\n    ax.plot([0, 1], [0, 1], 'k--')\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel('False Positive Rate')\n    ax.set_ylabel('True Positive Rate')\n    ax.set_title('Receiver operating characteristic example')\n    for i in range(n_classes):\n        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n    ax.legend(loc=\"best\")\n    ax.grid(alpha=.4)\n    sns.despine()\n    plt.show()","c986cd3a":"plot_multiclass_roc(log_model , scaled_X_test , y_test,n_classes=4)","bbc460eb":"X = scaler.transform(X)","1e4c412a":"y_hat = log_model.predict(X)\ndf['model_predection'] = y_hat\ndf","ad7ed724":"sns.countplot(data = df , x = 'class',hue = 'model_predection')","ff40556e":"df.head(2)","70d6f173":"campaign = [[25.0,1,165.0,55.80,15.7,77.0,126.0,36.4,16.3,53.0,229.0]]\ncampaign = scaler.transform(campaign)\ncampaign","d99ffc2d":"log_model.predict(campaign)","bcd4a741":"# Now as we see on the below info Gender column is object so we have to convert it to numeric \n# And for class column we will work on it like this because Sklearn can handle Outbut as object : ","e69d30d4":"# Data Visualization : "}}