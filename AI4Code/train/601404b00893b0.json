{"cell_type":{"a1605abc":"code","ecd78495":"code","06f31f91":"code","1aac8490":"code","38fe0eeb":"code","d99ee8c4":"code","0652f3b0":"code","28a9392c":"code","2a8cdd94":"code","ee42f510":"code","1a3a0f28":"code","fc306080":"code","81390231":"code","c5b1b0e6":"code","45af12a2":"code","9a77c276":"code","28542966":"code","d72f241f":"code","ba94e72d":"code","2417072a":"code","d905200d":"code","ea3568a5":"code","5939088f":"code","63b4d790":"code","b814a34c":"code","7d2716c5":"code","8bdb584f":"code","aa401ef2":"code","3a1efc07":"code","bde65f7c":"code","7b53afa1":"code","efe59c2b":"code","039cce0d":"code","a718ca83":"code","0db7bcea":"code","8e495e7f":"code","e61393f1":"code","5003a5cb":"code","c3eb80e4":"code","13a523ad":"code","f4d1b75f":"code","18ff0a95":"code","146f4d7a":"code","9e9070c6":"code","344cae2b":"markdown","dd276a97":"markdown","86b330e7":"markdown","0a46fced":"markdown","8526d319":"markdown","c4a56ab9":"markdown","eb04648f":"markdown","386ff393":"markdown","97de0618":"markdown"},"source":{"a1605abc":"import tensorflow as tf\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","ecd78495":"train_data = pd.read_csv(\"..\/input\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/test.csv\")","06f31f91":"# Checking the train dataframe\ntrain_data.head()","1aac8490":"train_data.info()","38fe0eeb":"# Separating the Input value as X_train and output value as Y_train\nY_train = train_data[\"label\"]\nX_train = train_data.drop(\"label\", axis=1)","d99ee8c4":"# Plotting the frequency of different numbers \nplt.figure(figsize=(10,5))\nsns.set_style(\"dark\")\nsns.countplot(x=Y_train)","0652f3b0":"X_train.head()","28a9392c":"X_train.head().values.shape","2a8cdd94":"Y_train.head(10)","ee42f510":"# Showing the output of One Hot Encoding of output values\npd.get_dummies(Y_train.head(25))","1a3a0f28":"Y_train = pd.get_dummies(Y_train)","fc306080":"# Output value after one hot encoded\nY_train.head()","81390231":"Y_train.head().values.shape","c5b1b0e6":"def init_weights(shape):\n    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(init_random_dist)","45af12a2":"def init_bias(shape):\n    init_random_bias = tf.constant(0.1, shape=shape)\n    return tf.Variable(init_random_bias)","9a77c276":"def conv2d(x,W):\n    # Creating a convolutional Neural Network\n    # x ----> [batch, H, W, Channel]\n    # W ----> [filter H, filter w, channels IN, channel out]\n    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=\"SAME\")","28542966":"def max_pool_2by2(x):\n    # function for max pooling\n    # x ----> [batch, H, W, Channel]\n    return tf.nn.max_pool(x, ksize=[1,2,2,1] , strides = [1,2,2,1], padding=\"SAME\")","d72f241f":"def convolutional_layer(input_x, shape):\n    # returning the output after passing the Convolutional Neural Network to Relu Activation Function\n    W = init_weights(shape)\n    b = init_bias([shape[3]])\n    return tf.nn.relu(conv2d(input_x, W) + b)","ba94e72d":"def normal_full_layer(input_layer, size):\n    # Fully connected layer for last\n    input_size = int(input_layer.get_shape()[1])\n    W = init_weights([input_size, size])\n    b = init_bias([size])\n    return tf.matmul(input_layer, W) + b","2417072a":"# Placeholders for our input x and output y\nx = tf.placeholder(tf.float32, shape=[None, 784])\ny_true = tf.placeholder(tf.float32, shape=[None,10])","d905200d":"# Reshaping our input x (2-D) into our accepted input for CNN Network that is 4-D\nx_image = tf.reshape(x, shape=[-1,28,28,1]) # 784 = 28*28","ea3568a5":"convo1 = convolutional_layer(x_image, shape = [5,5,1,32])\nconvo_1_pooling = max_pool_2by2(convo1)\n\nconvo_2 = convolutional_layer(convo_1_pooling,shape=[6,6,32,64])\nconvo_2_pooling = max_pool_2by2(convo_2)\n\n# After first max pooling : 28\/2 = 14\n# After second max pooling : 14\/2 = 7\nconvo_2_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])\nfull_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))\n#1024 is the nos. of neurons we want in our fully connected layer\n\nhold_prob = tf.placeholder(tf.float32)\nfull_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)\n\ny_pred = normal_full_layer(full_one_dropout,10)","5939088f":"print(\"input Size: \", x.get_shape())\nprint(\"After reshaping, input Size: \", x_image.get_shape())\nprint(\"After first conolution: \", convo1.get_shape())\nprint(\"After first Pooling: \", convo_1_pooling.get_shape())\nprint(\"After second conolution: \", convo_2.get_shape())\nprint(\"After second Pooling: \", convo_2_pooling.get_shape())\nprint(\"After flatening: \",convo_2_flat.get_shape())\nprint(\"After first fully dense NN: \",full_layer_one.get_shape())\nprint(\"After first dropout: \",full_one_dropout.get_shape())\nprint(\"Prediction: \", y_pred.get_shape())","63b4d790":"cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))\noptimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\ntrain = optimizer.minimize(cross_entropy)","b814a34c":"init = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)","7d2716c5":"total = int(train_data.shape[0]\/100)\ntotal","8bdb584f":"epochs = 100\nfor i in tqdm(range(epochs)):\n    for j in range(total):\n        batch_x = X_train.iloc[i*100:(i+1)*100].values\n        batch_y = Y_train.iloc[i*100:(i+1)*100].values\n\n        sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5})","aa401ef2":"# Accuracy on training data\nmatches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\nacc = tf.reduce_mean(tf.cast(matches,tf.float32))\nprint(sess.run(acc*100,feed_dict={x:X_train.values,y_true:Y_train.values,hold_prob:1.0}))","3a1efc07":"saver = tf.train.Saver()","bde65f7c":"saver.save(sess, \".\/Digit Model\/\")","7b53afa1":"# saver.restore(sess, \".\/input\/Digit Model\/\")","efe59c2b":"test_data.head()","039cce0d":"test_data.info()","a718ca83":"result = sess.run(tf.math.argmax(y_pred,1),feed_dict={x:test_data.values,hold_prob:1.0})","0db7bcea":"result.shape","8e495e7f":"result = result.reshape(-1,1)","e61393f1":"result.shape","5003a5cb":"final_result = pd.DataFrame(result, columns=[\"Label\"],index=np.arange(1,28001))","c3eb80e4":"final_result.head()","13a523ad":"final_result.reset_index(inplace=True)","f4d1b75f":"final_result.head()","18ff0a95":"final_result.columns = [\"ImageId\", \"Label\"]","146f4d7a":"final_result.head()","9e9070c6":"# Final submission file\nfinal_result.to_csv(\"digit_recognition_submission.csv\",index=False)","344cae2b":"**I have used epochs = 15000+ then I got the accuracy on training data 99.96 and on the test data 99.185 (as You can see on the competition's leaderboard)\nLeaderBoard link : https:\/\/www.kaggle.com\/c\/digit-recognizer\/leaderboard**","dd276a97":"## Reading the Training and Testing files","86b330e7":"# Dimensions after different layers","0a46fced":"# Functions to Create Layers","8526d319":"#  Network","c4a56ab9":"# Loss","eb04648f":"## Checking our model on test file ","386ff393":"Notebook link on Kaggle :\nhttps:\/\/www.kaggle.com\/ujjwalguptanith\/digit-recognizer-by-cnn","97de0618":"## Importing libraries"}}