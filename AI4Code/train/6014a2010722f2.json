{"cell_type":{"d7f4cc74":"code","abe45646":"code","6cc092c4":"code","faaae698":"code","b97e6d32":"code","fc0c405c":"code","5ccd10e4":"code","47f665d6":"code","e311682d":"code","97338e4d":"code","56a0b5a9":"code","8aa2c18d":"code","40600b66":"code","e0930ac9":"code","558dc23d":"markdown","e7294415":"markdown","97e54350":"markdown"},"source":{"d7f4cc74":"# If You use Google Colab, install this first\n# !pip3 install -qq twint\n!pip install -qq whatthelang","abe45646":"# If You use Kaggle's notebook, install this\n!pip3 install --user --upgrade git+https:\/\/github.com\/twintproject\/twint.git@origin\/master#egg=twint","6cc092c4":"# Additional library\n!pip install nest_asyncio","faaae698":"# Import Library\nimport twint\nimport nest_asyncio","b97e6d32":"# Additional library for get rids of some errors\nnest_asyncio.apply()\n\n# Instantiate and configure the twint-object\nc = twint.Config()\nc.Store_object = True\nc.Pandas =True\nc.Search = \"pemindahan ibu kota\"\n\n# Range\n# First day\nc.Since = '2020-10-15'\nc.Until = '2021-11-16'\n\n# Second day\n# c.Since = '2021-10-16'\n# c.Until = '2021-11-17'\n\n# Third day\n# c.Since = '2021-10-17'\n# c.Until = '2021-11-18'\n\nc.Limit = 300\nc.Lang = 'id'","fc0c405c":"# Run search\ntwint.run.Search(c)","5ccd10e4":"# Quick check\ntwint.storage.panda.Tweets_df.head()","47f665d6":"# Cleanup\ntweets = twint.storage.panda.Tweets_df.drop_duplicates(subset=['id'])","e311682d":"# Reindex\ntweets.index = range(len(tweets))","97338e4d":"# Remove non-Indonesian\nfrom whatthelang import WhatTheLang\nwtl = WhatTheLang()","56a0b5a9":"# This function makes easy to handle exceptions (e.g. no text where text should be)\n# Not really needed but can be useful \n\ndef detect_lang(text):\n    try: \n        return wtl.predict_lang(text)\n    except Exception:\n        return 'exp'","8aa2c18d":"# Added performance measure here\ntweets['lang'] = tweets['tweet'].map(lambda t: detect_lang(t))","40600b66":"# keep only Indonesian\ntweets = tweets[tweets.lang == 'id']","e0930ac9":"# Exporting\n# tweets.to_json('dataset.json')\ntweets.to_csv('dataset.csv')","558dc23d":"### The End (of the data extraction)\n\nNext, we will do some cleanup.","e7294415":"# Getting Twitter Data and Create Dataset - Without API\n\n<center><img src=\"https:\/\/help.twitter.com\/content\/dam\/help-twitter\/brand\/logo.png\" alt=\"Twitter Image\"><\/center>\n\nIn this simple notebook, i am gonna use Twint - https:\/\/pypi.org\/project\/twint\/ to get Twitter data.\n\nDifferent from Tweepy, this is a relatively new package that manages to get around Twitter's API.\n\nIf you want to implement this library, i recommend you to use it carefully\n\nIn this notebook, i will cover:\n\n- Searching for tweets\n- Extracting it's data and then save it\n\nAccording to Twint's team, some of the benefits of using Twint vs Twitter API:\n\n- Can fetch almost all Tweets (Twitter API limits to last 3200 Tweets only);\n- Fast initial setup;\n- Can be used anonymously and without Twitter sign up;","97e54350":"## Getting tweets data\n\nIn this steps, i want to create a dataset that contain tweets of a topic."}}