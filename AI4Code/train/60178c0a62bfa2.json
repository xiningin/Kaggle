{"cell_type":{"af4a6810":"code","f928b0b6":"code","5921da90":"code","a13491c4":"code","79d94766":"code","e82f72fd":"code","4e5d5ba6":"code","f68346c2":"code","08c48a1c":"code","22cd9646":"code","63f89d73":"code","66ba3299":"code","03192452":"code","40111e79":"code","69db687f":"code","4c6166bf":"code","f4156088":"code","5461cb20":"code","e26eb775":"code","26f1dbb0":"code","0e6dba29":"code","73ff2185":"code","406dc5ba":"code","f29b9a4a":"code","882e33ff":"code","786abb01":"code","5c160a1f":"code","89c4eae6":"code","b4501825":"code","0a2da4b9":"code","28868dfb":"code","8d349c2c":"code","33f9da88":"code","1e11e9ad":"code","e08ac581":"code","70d2cdca":"code","4102abd1":"code","ef687af8":"code","666ef945":"code","2db278b9":"code","27de4d25":"code","68378974":"code","396e466a":"code","c2025e12":"code","c1543a33":"code","5ab9fcf1":"code","26307a63":"code","ef217c6e":"code","8ea5169c":"code","68369267":"code","fed40c60":"code","113dad35":"code","37e237b4":"code","c6b63b38":"code","9af277df":"code","33eab0b8":"code","383157ec":"code","d3f77056":"code","d7838520":"code","d5885585":"code","323c9f6d":"code","d8e629fa":"code","041a1925":"code","7a72988e":"code","85ff13db":"code","20d12954":"code","13fc41ce":"code","cb7b0389":"code","18981451":"code","d72dbf3d":"code","fb8e32c3":"code","e1116dc5":"code","1fb44e83":"code","50d751c8":"code","cd23f675":"code","a1dfd7ab":"code","1c2c0051":"code","3f748d6e":"code","015c1764":"code","8571bdc3":"code","40b810c4":"code","e4503aa7":"code","0efc1b29":"code","4db42052":"code","da84b595":"code","919a74a0":"markdown","86e8fa69":"markdown","e2db9aca":"markdown","c48baf95":"markdown","383390f4":"markdown","7a4e70b5":"markdown","1c286d2c":"markdown","6e075c9a":"markdown","f87fbbed":"markdown","37bf7ec0":"markdown","7fe5a626":"markdown","ee42dcb6":"markdown","95afccc7":"markdown","575e6c6a":"markdown","963bf923":"markdown","9a12f130":"markdown","d9be7e08":"markdown","bcb103b7":"markdown","d95d4a5c":"markdown","339703ac":"markdown","7c4db8a3":"markdown","6582a831":"markdown","fb0da9f0":"markdown","6bc4a88d":"markdown","f2a8787b":"markdown","8a786776":"markdown","b299db77":"markdown","17f36ea0":"markdown","fb68e84e":"markdown","de11f1ef":"markdown","381942c0":"markdown","92bbca02":"markdown","72f36966":"markdown","c5e295ff":"markdown","22ac75a9":"markdown","4fc8de4d":"markdown","9b35736a":"markdown","57b24da4":"markdown","1a1cfa7c":"markdown","83267904":"markdown","e4774a01":"markdown","b25321c2":"markdown","27ce6f3f":"markdown","eee3fca8":"markdown","19f58d84":"markdown","000a9d73":"markdown","4644272b":"markdown","713f8bc0":"markdown"},"source":{"af4a6810":"import numpy as np #libreria calculos de algebra lineal\nimport pandas as pd  #libreria para hacer dataframes y preprocesar columnas y datos\nimport matplotlib.pyplot as plt #libreria para graficar\nimport seaborn as sns #visualizacion de estadisticas\nsns.set() \n%matplotlib inline\n\n","f928b0b6":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n#junto ambos dataframes en uno solo. Para aplicar las mismas modificaciones en ambos y luego cuando hacemos la red neuronal los volvemos a separar.\ndf = train.append(test , ignore_index = True)\n\n#ver dimensiones y columnas\nprint(train.shape, test.shape, train.columns.values)","5921da90":"train.head(10) #muestro los diez primeros datos del dataset train","a13491c4":"test.head(10)  #muestro los diez primeros datos del dataset test","79d94766":"df ","e82f72fd":"df.info()","4e5d5ba6":"df.isnull().sum()","f68346c2":"train.isnull().sum()","08c48a1c":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set() # setting seaborn default for plots\n\n","22cd9646":"def bar_chart(feature):\n    survived = df[df['Survived']==1][feature].value_counts()\n    dead = df[df['Survived']==0][feature].value_counts()\n    df2 = pd.DataFrame([survived,dead])\n    df2.index = ['Survived','Dead']\n    df2.plot(kind='bar',stacked=True, figsize=(10,5))","63f89d73":"# Se mapea a una variable booleana, si es hombre o mujer, no hizo falta usarla como categorica.\ndf.Sex = df.Sex.map({'male':0, 'female':1})","66ba3299":"bar_chart('Sex') #Graficar sexo vs supervivencia.","03192452":"bar_chart('Pclass')","40111e79":"# Agrupo por media la Supervivencia y la Clase de la persona\ndf[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()","69db687f":"df.Name.head(10)","4c6166bf":"#los t\u00edtulos siempre se encuentran entre uba coma y un punto, buscamos los strings entre esos dos y lo guardamos en una nueva columna llamada Title.\ndf['Title'] = df.Name.map( lambda x: x.split(',')[1].split( '.' )[0].strip())\n\n# inspect the amount of people for each title\ndf['Title'].value_counts()","f4156088":"df['Title'] = df['Title'].replace('Mlle', 'Miss')\ndf['Title'] = df['Title'].replace(['Mme','Lady','Ms'], 'Mrs')\ndf.Title.loc[ (df.Title !=  'Master') & (df.Title !=  'Mr') & (df.Title !=  'Miss') \n             & (df.Title !=  'Mrs')] = 'Others'\n\n# correlacion del titulo con los sobrevivientes\ndf[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","5461cb20":"bar_chart('Title') #En la grafica se ve mejor que los Mr fueron los que mas murieron, pero los miss y mrs fueron los que mas sobrevivieron tambien","e26eb775":"df['Title'].value_counts() #Contar numero de filas con los titulos","26f1dbb0":"df = pd.concat([df, pd.get_dummies(df['Title'])], axis=1).drop(labels=['Name'], axis=1) #One hot enconding con las columnas","0e6dba29":"df.head() #Ver cambios en el dataframe","73ff2185":"# Para crear una familia creo una nueva columna con los datos de los hermanos\/esposos y padres\/hijos mas la persona\ndf['Family'] = df['SibSp'] + df['Parch'] + 1","406dc5ba":"df.head() # ver la familia en el dataset","f29b9a4a":"bar_chart('Family') ","882e33ff":"# inspect the amount of people for each Family size\ndf['Family'].value_counts()","786abb01":"df.Family = df.Family.map(lambda x: 0 if x > 4 else x)\n#Correlacion y media de familiariees que sobrevivieron por cantidad de familiares\ndf[['Family', 'Survived']].groupby(['Family'], as_index=False).mean()","5c160a1f":"df['Family'].value_counts()","89c4eae6":"df.Family.head(10) #ver dataset con la cantidad de miembros en las familias ","b4501825":"df.Ticket.head(20)","0a2da4b9":"df.Ticket = df.Ticket.map(lambda x: x[0])\n\n# Ver la correlacion entre ticket y supervivencia, tambien lo vemos en la grafica\ndf[['Ticket', 'Survived']].groupby(['Ticket'], as_index=False).mean()","28868dfb":"# Ver la cantidad de personas por cada tipo de entrada\ndf['Ticket'].value_counts()","8d349c2c":"# la media y correlacion del precio por cada tipo de tickets\ndf[['Ticket', 'Fare']].groupby(['Ticket'], as_index=False).mean()","33f9da88":"#la media  y correlacion de la clase si es 1,2 o 3 por cada tipo de tickets\ndf[['Ticket', 'Pclass']].groupby(['Ticket'], as_index=False).mean()","1e11e9ad":"# revisar si tiene valores nulos el precio\ndf.Fare.isnull().sum(axis=0)","e08ac581":"# revisar cual ticket tiene ese precio nulo\ndf.Ticket[df.Fare.isnull()]","70d2cdca":"# revisar cual clase tienen ese precio nulo\ndf.Pclass[df.Fare.isnull()]","4102abd1":"# revisar cual cabinas tienen ese precio nulo\ndf.Cabin[df.Fare.isnull()]","ef687af8":"# revisar cual embarque tienen ese precio nulo\ndf.Embarked[df.Fare.isnull()]","666ef945":"#con loc puedo hacer la consula de los datos que necesito y le pongo la media\nadivinarFare = df.Fare.loc[ (df.Ticket == '3') & (df.Pclass == 3) & (df.Embarked == 'S')].median()\ndf.Fare.fillna(adivinarFare , inplace=True)","2db278b9":"# visualize los precios por las personas que murieron y sobrevivieron\ngrid = sns.FacetGrid(df, hue='Survived', size=4, aspect=1.5)\ngrid.map(plt.hist, 'Fare', alpha=.5, bins=range(0,210,10))\ngrid.add_legend()\nplt.show()","27de4d25":"# Dividir los precios en 5 intervalos\ndf['Fare-intervalo'] = pd.qcut(df.Fare,5,labels=[1,2,3,4,5]).astype(int)\n\n# Calcular la media entre los sobrevientes por cada intervalo de precio\ndf[['Fare-intervalo', 'Survived']].groupby(['Fare-intervalo'], as_index=False).mean()","68378974":"df.head()","396e466a":"#df = df.drop(labels=['Cabin'], axis=1)","c2025e12":"df.Cabin.isnull().sum(axis=0)","c1543a33":"df.Cabin.value_counts()","5ab9fcf1":"train_test_data = [df]\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","26307a63":"Pclass1 = df[df['Pclass']==1]['Cabin'].value_counts()\nPclass2 = df[df['Pclass']==2]['Cabin'].value_counts()\nPclass3 = df[df['Pclass']==3]['Cabin'].value_counts()\ndf2 = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf2.index = ['1st class','2nd class', '3rd class']\ndf2.plot(kind='bar',stacked=True, figsize=(10,5))","ef217c6e":"#Se procedio a mapear las categorias a una variable numerica y luego hacemos one hot encoding de ellas.\nmapeo = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"T\": 8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(mapeo)","8ea5169c":"#Para los valores null, se utilzo los promedios de cada clase para las cabinas faltantes\ndf[\"Cabin\"].fillna(df.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\n","68369267":"df.Cabin","fed40c60":"df.Cabin.isnull().sum(axis=0)","113dad35":"# ver si hay valores nulos, hay 2 nulos\ndf.Embarked.isnull().sum(axis=0)","37e237b4":"df.describe(include=['O']) # S is es el embarque mas comun","c6b63b38":"# Voy a llenar los Valores nulos con S, que es el mas comun\ndf.Embarked.fillna('S' , inplace=True )","9af277df":"# ver la media y correlacion entre embarque y supervivencia y la clase, precio, edad y sexo\ndf[['Embarked', 'Survived','Pclass','Fare', 'Age', 'Sex']].groupby(['Embarked'], as_index=False).mean()","33eab0b8":"Pclass1 = df[df['Pclass']==1]['Embarked'].value_counts()\nPclass2 = df[df['Pclass']==2]['Embarked'].value_counts()\nPclass3 = df[df['Pclass']==3]['Embarked'].value_counts()\ndf3 = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf3.index = ['1st class','2nd class', '3rd class']\ndf3.plot(kind='bar',stacked=True, figsize=(10,5))","383157ec":"df.Age.isnull().sum(axis=0)","d3f77056":"# Ver la correlacion de la edad con los titulos\ngrid = sns.FacetGrid(df, col='Title', size=3, aspect=0.8, sharey=False)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=range(0,105,5))\nplt.show()","d7838520":"# inspect the mean Age for each Title\ndf[['Title', 'Age']].groupby(['Title']).mean()","d5885585":"# los valores nulos los llenamos con la media de la edad de los titulos each title (Mr, Mrs, Miss, Master, Others)\ndf[\"Age\"].fillna(df.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","323c9f6d":"df.head(30)\ndf.groupby(\"Title\")[\"Age\"].transform(\"median\")","d8e629fa":"df.Age.isnull().sum(axis=0) #ya no tengo variables nulas en la edad","041a1925":"bins = [ 0, 4, 12, 18, 30, 50, 65, 100] # Edades \nage_index = (1,2,3,4,5,6,7)  # ('bebe','nino','adolescente','joven','adulto','mayor','3raedad')\ndf['Age-intervalo'] = pd.cut(df.Age, bins, labels=age_index).astype(int)\n\n#ver la correlacion si sobrevivio con los intervalos de edad\ndf[['Age-intervalo', 'Survived']].groupby(['Age-intervalo'],as_index=False).mean()","7a72988e":"df[['Ticket', 'Survived']].groupby(['Ticket'], as_index=False).mean()","85ff13db":"df['Ticket'].value_counts()","20d12954":"df['Ticket'] = df['Ticket'].replace(['A','W','F','L','5','6','7','8','9'], '4')\n\n# ver la media y correlacion con el cambio\ndf[['Ticket', 'Survived']].groupby(['Ticket'], as_index=False).mean()","13fc41ce":"df = df.drop(labels=['Embarked'], axis=1)\ndf = df.drop(labels=['Cabin'], axis=1)","cb7b0389":"\n#One hot encoding\n#df = pd.get_dummies(df,columns=['Family'])\ndf = pd.get_dummies(df,columns=['Fare-intervalo'])\ndf = pd.get_dummies(df,columns=['Age-intervalo'])\ndf = pd.get_dummies(df,columns=['Pclass'])\ndf = pd.get_dummies(df,columns=['Ticket'])\n#df = pd.get_dummies(df,columns=['Cabin'])\n#df = pd.get_dummies(df,columns=['Embarked'])\n\n","18981451":"df.head() #dataset definitivo","d72dbf3d":"df.isnull().sum(axis=0) #ver si quedaron todos los campos sin datos nulos","fb8e32c3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.layers import Input, Dense, BatchNormalization, Add, GaussianNoise, Dropout\nfrom keras.models import Model\nfrom sklearn.metrics import roc_auc_score\nfrom keras.layers import Wrapper\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nimport matplotlib.pyplot as plt\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\n\nfrom matplotlib.pyplot import *","e1116dc5":"precisiones_globales=[]\nepochs = 100\ndef graf_model(train_history):\n    f = plt.figure(figsize=(15,10))\n    ax = f.add_subplot(121)\n    ax2 = f.add_subplot(122)\n    # summarize history for accuracy\n    ax.plot(train_history.history['binary_accuracy'])\n    ax.plot(train_history.history['val_binary_accuracy'])\n    ax.set_title('model accuracy')\n    ax.set_ylabel('accuracy')\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(train_history.history['loss'])\n    ax2.plot(train_history.history['val_loss'])\n    ax2.set_title('model loss')\n    ax2.set_ylabel('loss')\n    ax2.set_xlabel('epoch')\n    ax2.legend(['train', 'test'], loc='upper left')\n    plt.show()\ndef precision(model, registrar=False):\n    y_pred = model.predict(X_train)\n    train_auc = roc_auc_score(y_train, y_pred)\n    y_pred = model.predict(val_dfX)\n    val_auc = roc_auc_score(val_dfY, y_pred)\n    print('Train AUC: ', train_auc)\n    print('Vali AUC: ', val_auc)\n    if registrar:\n        precisiones_globales.append([train_auc,val_auc])","1fb44e83":"df = df.drop(labels=['SibSp','Parch','Age','Fare','Title'], axis=1) #borramos lo que no necesitamos, tengo los intervalos de edad e intervalos de fare\ny_train = df[0:891]['Survived'].values\nX_train = df[0:891].drop(['Survived','PassengerId'], axis=1).values\nX_test  = df[891:].drop(['Survived','PassengerId'], axis=1).values","50d751c8":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","cd23f675":"print(\"Entrnamiento: \",X_train.shape)\nprint(\"Test : \",X_test.shape)","a1dfd7ab":"X_train,val_dfX,y_train, val_dfY = train_test_split(X_train,y_train , test_size=0.20, stratify=y_train)\nprint(\"Entrenamiento: \",X_train.shape)\nprint(\"Validacion : \",val_dfX.shape)","1c2c0051":"def func_model():   \n    inp = Input(shape=(29,))\n    x=Dense(12, activation=\"relu\", kernel_initializer='glorot_normal', bias_initializer='zeros')(inp)\n    x=Dense(12, activation=\"relu\", kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n    x=Dense(14, activation=\"relu\", kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n    x=Dense(12, activation=\"relu\", kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n    x=Dense(1, activation=\"sigmoid\", kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['binary_accuracy'])\n    return model\nmodel = func_model()\nprint(model.summary())","3f748d6e":"\ntrain_history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(val_dfX, val_dfY))","015c1764":"graf_model(train_history)\nprecision(model, True)","8571bdc3":"#np.random.seed(0) \n\ndef func_model_reg():   \n    inp = Input(shape=(29,))\n    \n    x=Dropout(0.1)(inp)\n    \n    x=Dense(12, activation=\"relu\", kernel_initializer='glorot_normal', bias_initializer='zeros')(inp)\n    x=Dropout(0.3)(x)\n    \n    x=Dense(12, activation=\"relu\", kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n    x=Dropout(0.3)(x)\n    \n    x=Dense(14, activation=\"relu\", kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n    x=Dropout(0.3)(x)\n    \n    x=Dense(12, activation=\"relu\", kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n    x=Dropout(0.1)(x)\n    \n    x=Dense(1, activation=\"sigmoid\", kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['binary_accuracy'])\n    return model\nmodel = func_model_reg()\nprint(model.summary())\n\n\n","40b810c4":"model1 = func_model_reg()\nentrenadofinal = model1.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(val_dfX, val_dfY), verbose=0)","e4503aa7":"graf_model(entrenadofinal)\nprecision(model1)","0efc1b29":"## Ver la prediccion de los datos","4db42052":"y_pred = model1.predict(X_test)\ny_final = (y_pred > 0.5).astype(int).reshape(X_test.shape[0])\n\noutput = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': y_final})\noutput.to_csv('prediction.csv', index=False)","da84b595":"pred = pd.read_csv('prediction.csv')\npred.head()","919a74a0":"## Estudio de los datos\n","86e8fa69":"### Variable Ticket","e2db9aca":"### Variable Cabina o Cabin","c48baf95":"Se puede ver que la clase 1 es la que mayor probabilidad tiene de sobrevivir, pero la clase 3 fue la que mas muri\u00f2 tambi\u00e8n, este es un dato muy importante que vamos a usar despu\u00e9s. Al final hago el one hot encoding, si lo hago ahorita pierdo la variable Pclass.","383390f4":"Para calcular ese valor, lo podemos sacar del ticket, la clase, donde embarco, o la cabina. Veamos los valores de ellas. ","7a4e70b5":"# Proyecto 1 Deteccion Titanic","1c286d2c":"La diferencia entre el dataset train y el test, es que el test no incluye la columna survived ya que va ser usado para ser predecido posteriormente, por lo cual, el dataset train cuenta con 12 columnas, mientras que el dataset test con 11 columnas. Al juntar los dos dataset en uno solo. Las columnas de test de survived quedarian nulas. ","6e075c9a":"Exist\u00eda la problematica que en el test existian t\u00edtulos que no habian en el dataset de train, pero esto se resolvi\u00f3 al pegarlo todo en un solo dataframe","f87fbbed":"### Modelo Regularizado","37bf7ec0":"### Set de entrenamiento y validacion","7fe5a626":"## Variable Edad\/Age","ee42dcb6":"### Variable Fare o Precio","95afccc7":"### Carga de datasets a dataframes","575e6c6a":"### Importaci\u00f3n de Librer\u00edas de Preprocesamiento","963bf923":"\nLos tickes con mas personas son los tickets que comienzan por 1,2,3\nTambi\u00e9n en la gr\u00e1fica y la correlaci\u00f3n se ve una alta tasa de sobrevivencia en los tickets que comienzan por 1,2,3.\nTambien los tickets que comienzan por 9, C, F, P y S tienen probabilidad significativa de sobrevivir. Pero 9 tiene solo 2 personas y F tiene 13 personas, no es significativa esa muestra. Entonces para entender bien como se comparta el precio, luego evaluamos la relaci\u00f3n que tiene con el precio y con la clase. Que siempre va ser dependientes. \n","9a12f130":"Tenemos 1014 valores de null","d9be7e08":"## One Hot Encoding","bcb103b7":"Hay dos tipos de tickets como se puede ver los que son puro numero y los que comienzan por letras y luego numeros.\nInvestigamos y conseguimos que los nombres de los boletos con letras  representan algunas clases especiales del barco. Para los n\u00fameros, la mayor\u00eda de los boletos tienen su primer d\u00edgito = 1, 2 o 3, que probablemente tambi\u00e9n representan diferentes clases. As\u00ed que solo conservo el primer elemento (una letra o un n\u00famero de un solo d\u00edgito)","d95d4a5c":"### Importacion de Librerias de la NN","339703ac":"#Como cabina tiene tantos datos nulos, para esta entrega no tomamos en cuenta esa variable, ya que sacar un promedio con los pocos datos que hay puede afectar el resultado.Si la entrega se extiende podemos a\u00f1adirle al modelo estos datos de cabina.","7c4db8a3":"### Arquitectura de la NN","6582a831":"### Varible Sexo","fb0da9f0":"todav\u00eda tenemos que agrupar los datos en diferentes intervalos de edad, por el mismo motivo que Fare","6bc4a88d":"### Variable Familia: Uniendo Hermanos o Pareja e Hijos o Padres (SipSp y Parch)","f2a8787b":"### Variable Pclass (1ra, 2da o 3ra clase del barco)","8a786776":"Se puede ver que murieron mas hombres, pero sobrevivieron m\u00e1s mujeres. Input importante en la red","b299db77":"los principales t\u00edtulos con mayor cantidad de datos son Master, Miss, Mr, Mrs. Algunos de los otros se pueden combinar en algunas de estas cuatro categor\u00edas. Por lo dem\u00e1s, los llamamamos Others.","17f36ea0":"Podemos ver que las personas con tarifas m\u00e1s bajas tienen menos probabilidades de sobrevivir. P. La forma ideal es pasarlo a la red neuronal con intervalos de tarifa. Ya que si lo pasamos asi como esta a la red causaria un ajuste excesivo","fb68e84e":"### Cantidad de datos nulos","de11f1ef":"### Informacion de los tipos de datos","381942c0":"## Gr\u00e1ficas: Nos va a permitir ver las relaciones de varibles vs Supervivencia","92bbca02":"### Graficar modelo y ver precision","72f36966":"## Ticket final","c5e295ff":"existen relaciones de la letra y numero del boleto inicial con la clase del barco y si es boleto caro o barato. Asi que el ticket es una caracteristica muy util, que la vamos a acomodar al final en intervalos","22ac75a9":"### Variable Embarque Embarked","4fc8de4d":"### Normalizacion de los inputs","9b35736a":"## Modelo de Red Neuronal","57b24da4":" No hay un valor correspondiente para Cabin, as\u00ed que vimos la relaci\u00f3n entre Fare y las tres caracter\u00edsticas ticket, pclass y embarked.Fare tiene correlaci\u00f3n con estas tres caracter\u00edsticas. Se adivino el valor faltante utilizando la media de (Pcalss = 3) & (Ticket = 3) & (Embarked = S)","1a1cfa7c":"## Extraer el titulo de los nombres","83267904":"* ### Entrenamiento","e4774a01":"\nLas categor\u00edas principales de Ticket son 1, 2, 3, P, S y C, as\u00ed que combinamos todas las dem\u00e1s en 4","b25321c2":"Podemos ver que la cantidad de personas en las familias grandes de 7,6,11 integrantes es mucho menor que en las familias peque\u00f1as de 2 o 3 integrantes por ejemplo. Por lo cual no vale la pena tener tantas variables categoricas y combinamos todos los datos con Familia de 4 o mayor en una categor\u00eda. Dado que las personas en familias grandes tienen una tasa de supervivencia a\u00fan m\u00e1s baja que las que est\u00e1n solas, decidimos mapear los datos con Familia mayor a 4 a Familia = 0.","27ce6f3f":"Podemos ver que el campo edad tiene valores nulos. De 891 filas, 714 hay datos y 177 son nulas. Tambi\u00e9n de manera similar el campo cabina hay solo 204 datos y 687 se perdieron. Y en embarques solo hay 2 datos nulos. Por lo cual se va a modificar el dataframe para cubrir esos campos nulos.","eee3fca8":"La tasa de supervivencia cambia entre los diferentes valores de Embarked. Sin embargo, se debe a los cambios las otras caracteristicas que ya evaluamos Por ejemplo, las personas de Embarked = C tienen m\u00e1s probabilidades de sobrevivir porque generalmente son m\u00e1s ricas (Pclass, Fare). Las personas de Embarked = S tienen la tasa de supervivencia m\u00e1s baja porque tienen la fracci\u00f3n m\u00e1s baja de pasajeros mujeres, aunque son un poco m\u00e1s ricas que las personas de Embarked = Q. Por lo tanto, decid\u00edmos quitar esta caracter\u00edstica tambi\u00e9n.","19f58d84":"Hay 263 valores nulos.La edad probablemente se puede inferir de otras caracter\u00edsticas como T\u00edtulo, Tarifa, SibSp, Parch. ","000a9d73":"Se elegio un 0.3 porciento para test, porque los datos totales 800, son pocos para tocar 1%. Tomando lo dicho por Andrew Ng en sus cursos.","4644272b":"El cambio de Age como funci\u00f3n de Title  es bastante significativo, los valores nulos los llenamos con la media de la edad de los titulos each title (Mr, Mrs, Miss, Master, Others)","713f8bc0":"Cada nombre tiene un t\u00edtulo, que es claramente lo que importa, ya que contiene informaci\u00f3n del status. Extrajimos los t\u00edtulos de estos nombres.\n"}}