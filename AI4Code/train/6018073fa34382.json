{"cell_type":{"27f6c8a9":"code","555177a2":"code","b8f12123":"code","7e67170a":"code","4573af3e":"code","e3b91390":"code","80b41ef2":"code","da13b5d0":"code","445297a7":"code","7db8e4d5":"code","3138c11f":"markdown","50a77eb2":"markdown","b7a23cc3":"markdown","25382cc7":"markdown","738f43fe":"markdown","fae6395f":"markdown","f1af3928":"markdown","4f955abf":"markdown","6e4c6bbb":"markdown"},"source":{"27f6c8a9":"import pandas as pd\nimport numpy as np\nimport pylab as plt\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tqdm import tqdm\nimport random\nrandom.seed(0)\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, Input\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, Activation\nfrom tensorflow.keras.layers import BatchNormalization, Reshape, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau","555177a2":"batch_size = 64\ntarget_size = (32, 32)\nclass_mode = 'binary'\nepochs = 100\ninput_shape = (32,32,3)\nnum_classes = 2\ndata_dir =  \"..\/input\/train\/train\/\"\nvalidation_split = 0.8\ncolor_mode='rgb'\nx_col = 'id'\ny_col='has_cactus'\ndropout_dense_layer = 0.5","b8f12123":"df = pd.read_csv('..\/input\/train.csv')\ndf.has_cactus = df.has_cactus.astype(str) # Classes must be str and not int\nmsk = np.random.rand(len(df)) < validation_split\ntrain = df[msk]\nvalidation = df[~msk]","7e67170a":"train_datagen = ImageDataGenerator(rescale=1\/255, horizontal_flip=True, vertical_flip=True)\ntrain_generator = train_datagen.flow_from_dataframe(train, directory=data_dir, x_col=x_col, y_col=y_col, target_size=target_size, color_mode=color_mode, class_mode=class_mode, batch_size=batch_size, shuffle=True)\nvalidation_generator = train_datagen.flow_from_dataframe(validation, directory=data_dir, x_col=x_col, y_col=y_col, target_size=target_size, color_mode=color_mode, class_mode=class_mode, batch_size=batch_size, shuffle=True)","4573af3e":"from sklearn.utils import class_weight\nclass_weights = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)\nclass_weights","e3b91390":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64, (3, 3),padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout_dense_layer))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss=keras.losses.binary_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel.summary()\n\ncallbacks = [EarlyStopping(monitor='val_loss', patience=20),\n             ReduceLROnPlateau(patience=10, verbose=1),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', verbose=0, save_best_only=True)]\n\nhistory = model.fit_generator(train_generator,\n          validation_data=validation_generator,\n          epochs=epochs,\n          verbose=1,\n          shuffle=True,\n          callbacks=callbacks,\n          class_weight=class_weights)","80b41ef2":"plt.figure(figsize=(15,5))\n\nplt.subplot(141)\nplt.plot(history.history['loss'], label='training')\nplt.plot(history.history['val_loss'], label='validation')\nplt.xlabel('# Epochs')\nplt.legend()\nplt.ylabel(\"Loss - Binary Cross Entropy\")\nplt.title('Loss Evolution')\n\nplt.subplot(142)\nplt.plot(history.history['loss'], label='training')\nplt.plot(history.history['val_loss'], label='validation')\nplt.ylim(0,0.1)\nplt.xlabel('# Epochs')\nplt.legend()\nplt.ylabel(\"Loss - Binary Cross Entropy\")\nplt.title('Zoom Near Zero - Loss Evolution')\n\nplt.subplot(143)\nplt.plot(history.history['acc'], label='training')\nplt.plot(history.history['val_acc'], label='validation')\nplt.xlabel('# Epochs')\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title('Accuracy Evolution')\n\nplt.subplot(144)\nplt.plot(history.history['acc'], label='training')\nplt.plot(history.history['val_acc'], label='validation')\nplt.ylim(0.98,1)\nplt.xlabel('# Epochs')\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title('Zoom Near One - Accuracy Evolution')","da13b5d0":"model.load_weights(\"best_model.h5\")\n\nhistory.history['val_acc'][np.argmin(history.history['val_loss'])]","445297a7":"test_folder = \"..\/input\/test\/\"\ntest_datagen = ImageDataGenerator(\n    rescale=1. \/ 255)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory=test_folder,\n    target_size=target_size,\n    batch_size=1,\n    class_mode=None,\n    shuffle=False)","7db8e4d5":"sample_submission = pd.read_csv('..\/input\/sample_submission.csv')\nfilenames = [path.split('\/')[-1] for path in test_generator.filenames]\nprobabilities = list(model.predict_generator(test_generator)[:,0])\n\nsample_submission.id = filenames\nsample_submission.has_cactus = probabilities\n\nsample_submission.to_csv('sample_submission.csv', index=False)","3138c11f":"# Fight Classes Imbalance","50a77eb2":"# Design CNN","b7a23cc3":"# Load best model","25382cc7":"# Classify images in test folder","738f43fe":"# Parameters","fae6395f":"# Prepare Submission File","f1af3928":"# Split training and validation into 80\/20%","4f955abf":"# Minimal Data Augmentation","6e4c6bbb":"# Plot Training Performances"}}