{"cell_type":{"ffa5d8a5":"code","0d6749a7":"code","1ad17ad5":"code","93eb4fb3":"code","57348662":"code","51a82f61":"code","1d3a265b":"code","1fbbe07a":"code","74d4b7a4":"code","e1966f05":"code","5b4a987d":"code","96056a03":"code","21fe7b33":"code","8ef1617e":"code","82ee4753":"code","401ec433":"code","44876cb5":"code","05a2dc28":"code","712fe76c":"code","5d24e3db":"code","5c9404ce":"code","b7df7ee5":"code","e97837dc":"code","ae324447":"code","0713cd6a":"code","5eae19ea":"code","ac3a590e":"code","968e2120":"code","604e3181":"code","b582e6d3":"code","64dfe55c":"code","94173886":"markdown","5d539d92":"markdown","81db643f":"markdown","de2f99b0":"markdown","ded18ff9":"markdown","dd10de7e":"markdown","836fa3bf":"markdown","fbaec4e3":"markdown","7eeaf014":"markdown","6681c6bc":"markdown","745886bf":"markdown","bcbca2e6":"markdown","9b866c3a":"markdown","148fee86":"markdown","2299434b":"markdown","43f8c191":"markdown","b9ff67f8":"markdown","3fb749ce":"markdown","0dc56404":"markdown"},"source":{"ffa5d8a5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/\"))\n\n# Any results you write to the current directory are saved as output.","0d6749a7":"ratings  = pd.read_csv('..\/input\/ratings_small.csv')\nratings.head()","1ad17ad5":"print(ratings.shape)","93eb4fb3":"from sklearn.model_selection import train_test_split\ntrain_df,test_df = train_test_split(ratings, test_size = 0.3, random_state = 42)\nprint(train_df.shape, '\\t\\t', test_df.shape)","57348662":"train_df.head()","51a82f61":"df_movies_as_features = train_df.pivot(index = 'userId', columns = 'movieId',values = 'rating' )\ndf_movies_as_features.shape","1d3a265b":"df_movies_as_features.head()","1fbbe07a":"df_movies_as_features.fillna(0, inplace = True)\ndf_movies_as_features.head()","74d4b7a4":"dummy_train=train_df.copy()\ndummy_test =test_df.copy()","e1966f05":"dummy_train.rating.value_counts()","5b4a987d":"dummy_test.rating.value_counts()","96056a03":"dummy_train['rating'] =dummy_train.rating.apply(lambda x : 0  if x >=1 else 1)\ndummy_test['rating'] =dummy_test.rating.apply(lambda x : 1  if x >=1 else 0)\ndummy_train.head()","21fe7b33":"def pivot_by_movie(df):\n    df = df.pivot(index='userId', columns = 'movieId', values = 'rating')\n    df.fillna(0, inplace = True)\n    return df","8ef1617e":"dummy_train = pivot_by_movie(dummy_train)\ndummy_test = pivot_by_movie(dummy_test)\n","82ee4753":"dummy_train.head()","401ec433":"from sklearn.metrics.pairwise import pairwise_distances","44876cb5":"user_correlation  = 1- pairwise_distances(df_movies_as_features,metric = 'cosine')\nuser_correlation.shape","05a2dc28":"user_correlation","712fe76c":"np.sum(np.isnan(user_correlation))","5d24e3db":"user_correlation[np.isnan(user_correlation)]=0\nuser_correlation","5c9404ce":"train_movies_as_feature = train_df.pivot(index='userId', columns = 'movieId', values = 'rating')\ntrain_movies_as_feature.head()","b7df7ee5":"train_movies_as_feature.shape","e97837dc":"mean = np.nanmean(train_movies_as_feature, axis = 1)\nprint(mean.shape)","ae324447":"normalised_df = (train_movies_as_feature.T-mean).T\nnormalised_df.head()","0713cd6a":"user_correlation =  1 - pairwise_distances(normalised_df.fillna(0), metric ='cosine')\nuser_correlation[np.isnan(user_correlation)]=0\nprint(user_correlation)\n","5eae19ea":"user_correlation.shape","ac3a590e":"user_correlation[user_correlation<0]=0","968e2120":"user_predicted_ratings = np.dot(user_correlation, train_movies_as_feature.fillna(0))\nuser_predicted_ratings","604e3181":"user_predicted_ratings.shape","b582e6d3":"user_final_rating = np.multiply(user_predicted_ratings, dummy_train)\nuser_final_rating.head()","64dfe55c":"user_final_rating.iloc[670].sort_values(ascending =False)[-6:]","94173886":"### Let's create User Similarity Matrix\nUsing Cosine Similarities= dot_product of each row with Other rows to calculate simialarity scores between users","5d539d92":"#### Why did we Normalized it?\nThe Reason being a lot of guys give high scores to even bad movies and very Good score to Good movies while others give a very low score to bad ones. So it would be better we subtracted the mean score given by each guy to all movies from score given by that guy to each movie.","81db643f":"> **Similary we can find Ratings for other users as well.\n> This marks the end of User Based Collaborative Filtering.**","de2f99b0":"### Let's calculate cosine similarity between users again","ded18ff9":"#### Before we use User Correlation and start Calcuting predicted ratings we have to remove user who are negatively correlated as we don't need them.\nWe want only users who are similar for our predicting Ratings","dd10de7e":"let's Normalize it as well","836fa3bf":"#### Finding Top 5 recommendation for User 1","fbaec4e3":"Now we have to remove predicted scores for movies which the user himself has already given score i.e He has watched.\n\nThis is where Dummy_train and Test come in picture.\nWe will use element wise multiplication of predcited_score_matrix with Dummy_train and Dummy_test in order to Nullify movies which has already been watched","7eeaf014":"### Loading and Reading Dataset","6681c6bc":"### But to find cosine similarity we have considered all the rating but 0 should have been not Considered for calculating similarity.\nSo let's load the Training data again and not replace NaN with zero ","745886bf":"#### As MovieID column stores, movies and our first task is to build a recommendation engine based on USER COLLABORATIVE approach, we want our data in tabular format such that: userID as index, Data i.e Unique MovieID's as Columns\/features and Ratings as Values","bcbca2e6":"### We can achieve this using dataframe's Pivot Method","9b866c3a":"As we calculated mean row wise let's deduct mean rating from each value and normalize by taking transpose ","148fee86":"Note: Movie No 10 userid 2 has rating as 1 in dummy_train as this movie was not reviewed by this particular user. See  Movie No 10 userid 2 has rating as 1 in Features_movie_df","2299434b":"**In this matrix each column corresponds to One user and values in column corresponds to how is he correlated with other users. \nFor example, let's take 1st column. the value 1 signifies he is 100% related to user 1 (obviously as he is himself User 1) while next value signifies how much he is related to second user**","43f8c191":"  ####  Copy Train and Test DATASET\n  This will be used for Evaluation and","b9ff67f8":"### Now we need to calculate how much rating a user will give to Movies that he has not Rated. For this purpose we will use a dot product on user_correlation with movie_score_feature_matrix so that user's correlation with him and others will be used to calulate average user score he should have given to Movies.","3fb749ce":"## Splitting Data into Train and Test Set","0dc56404":"Now we have predicted ratings for each movie by a user represented by each row in one columns"}}