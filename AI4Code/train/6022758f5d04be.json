{"cell_type":{"5d94387c":"code","48f643ab":"code","3758ed32":"code","7dbcb280":"code","c4eb5bce":"code","9866ab71":"code","2a805dd3":"code","9695156a":"code","c24cab9d":"code","95694386":"code","145f206d":"code","76dfa3c6":"code","f9e6667d":"code","90a69ed5":"code","54e1a9ff":"code","ccf8c118":"markdown","54d9791c":"markdown","3704346e":"markdown","795969ae":"markdown","1207357a":"markdown","1055d13d":"markdown","0ae3b5fd":"markdown","033974ef":"markdown","cf58735a":"markdown","413e9a15":"markdown","b06fc7e4":"markdown","16ff896a":"markdown","d295b472":"markdown"},"source":{"5d94387c":"#STEP 1: Get right arrows in quiver\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import KMeans\nfrom yellowbrick.cluster import SilhouetteVisualizer\nfrom yellowbrick.cluster import InterclusterDistance\n\nimport seaborn as sns\nfrom sklearn.metrics import silhouette_score,silhouette_samples\n\nimport warnings #To hide warnings\nimport re  #RegEx\n\n\n#1.1: Set the stage\nfrom IPython.core.interactiveshell import InteractiveShell\nfrom IPython.core.display import display, HTML\n\nInteractiveShell.ast_node_interactivity = \"all\"\npd.options.display.max_rows = 200\npd.options.display.max_columns = 300\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","48f643ab":"#STEP 2: Load Data\ndf_sec = pd.read_csv('\/kaggle\/input\/nyse\/securities.csv')\ndf_fn = pd.read_csv('\/kaggle\/input\/nyse\/fundamentals.csv')\n\n#STEP 2.1:Analyse data structure\ndisplay(HTML('The fundamentals dataset has <b>' +str(df_fn.shape[1])+' features <\/b>and <b>'+str(df_fn.shape[0])\n             +' observations<\/b>'))\n\ndf_fn.info()","3758ed32":"# Check for NaN values\ndisplay(HTML(' <h2>Features having NaN values<\/h2>'))\ndf_fn[df_fn.columns[df_fn.isna().any()]].isna().sum().to_frame().T\n#View Data sample(Random sample rather than head for better understanding)\ndisplay(HTML(' <h2>Random Sample of 5 observations<\/h2>'))\ndf_fn.sample(n = 5).T","7dbcb280":"#2.2 Renaming Features\nf_dct = {n : re.sub('[^A-Za-z0-9]+','',n) for n in df_fn.columns.values}\ndf_fn.rename(columns = f_dct,inplace=True)\ndf_fn['PeriodEnding'] = pd.to_datetime(df_fn['PeriodEnding'])\ndf_fn['ForYear'] = df_fn['PeriodEnding'].dt.year.astype('category')\n#2.3 Clean it!\nfwm = [\"TickerSymbol\",\"ForYear\",\"AccountsPayable\",\"AccountsReceivable\",\"GrossProfit\",\"Liabilities\",\"NetCashFlow\",\"OperatingIncome\",\"TotalAssets\",\"TotalEquity\",\"TotalLiabilities\",\"TotalLiabilities&Equity\",\"TotalRevenue\",\"EarningsPerShare\"]\nto_drop= [x for x in df_fn.columns.values if x not in fwm]\ndf_fn.drop(columns = to_drop,inplace = True)\n\ndisplay(HTML('<h2>Remaining NaN Columns after reduction<\/h2>'))\ndf_fn.isna().sum().sort_values(ascending=False).to_frame().head().T\n\ndisplay(HTML('<b> The reduced shape of dataset is '+str(df_fn.shape)))","c4eb5bce":"df_fn.head()","9866ab71":"print(\"The dataset has \",len(df_fn['TickerSymbol'].unique()),\" unique tickers\")\ngrp_tick = df_fn.groupby('TickerSymbol')\nt_agg = grp_tick.agg(np.nanmean)\nt_agg.head()","2a805dd3":"t_agg['Ticker'] = t_agg.index\nbottom30 = t_agg.sort_values(by = 'EarningsPerShare').head(30)\ntop30 = t_agg.dropna().sort_values(by = 'EarningsPerShare',ascending=False).head(30)\n\nfig = plt.figure(figsize = (20,15))\nplt.subplot(1,2,1)\nplt.title('Top 30 Tickers as per Earning\/share')\nsns.barplot(y = 'Ticker', x = 'EarningsPerShare', data = top30)\nplt.subplot(1,2,2)\nplt.title('Bottom 30 Tickers as per Earning\/share')\nsns.barplot(y = 'Ticker', x = 'EarningsPerShare', data = bottom30)","9695156a":"#top30.loc[:,['TotalAssets','TotalLiabilities','TotalEquity']]\ntop30.sort_values(by = 'TotalAssets',\n                  ascending=False).plot(x='Ticker',y=['TotalAssets','TotalLiabilities','TotalEquity']\n                                        ,kind='bar',figsize = (20,8),title='Asset-Liabilty composure'\n                                        +' of Top30 companies')","c24cab9d":"sns.pairplot(t_agg)","95694386":"#tick = df_fn[:,['TickerSymbol','ForYear']] #for future use\ndf_fn.drop(columns = ['TickerSymbol','ForYear'],inplace=True)\ny_col = df_fn.columns[df_fn.isna().any(axis =0)]\nfn_pred = df_fn[df_fn.isna().any(axis =1)]\nfn_prem = df_fn[~df_fn.isna().any(axis =1)]\ny = fn_prem[y_col]\nfn_prem.drop(columns = y_col)\nss = StandardScaler()\nX = ss.fit_transform(fn_prem)\nX_train, X_test, y_train, y_test = train_test_split( X,y, test_size = 0.2)","145f206d":"distortions = []\nsil_sc = []\nfor i in range(1, 11):\n    km = KMeans(n_clusters=i)\n    km.fit(X_train)\n    distortions.append(km.inertia_)\n    if(i>1) : \n        sil_sc.append(silhouette_score(X_train, km.labels_))\n        \n# plot\nplt.title('Scree Plot')\nplt.plot(range(1, 11), distortions, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Distortion')\nplt.show()\n\nfor i in range(0,9): print('\\nFor ',(i+2),' clusters avg silhoutte score is #',sil_sc[i])\nplt.plot(range(0, 10), distortions, marker='o')\nplt.title('Silhouette Plot')\nplt.xlabel('Number of clusters')\nplt.ylabel('Silhouette Score')\nplt.show()","76dfa3c6":"for i in range(2,11):\n    model = SilhouetteVisualizer(KMeans(i),title = 'Silhouette for n_cluster = '+str(i))\n    model.fit(X_train)\n    model.show()","f9e6667d":"colors = ['orange', 'blue']\nkm = KMeans(n_clusters=2)\nclusters = km.fit(X_train)\nlabels = clusters.labels_\nctr = clusters.cluster_centers_\n\nfig = plt.figure(figsize = (10,10))\nfig.suptitle('K-mean clusters formed with n_cluster = 2',fontsize = 16)\nfor k, col in zip(range(X_train.shape[0]), colors):\n    my_members = (labels == k)\n    cluster_center = ctr[k]\n    plt.plot(X_train[my_members, 0], X_train[my_members, 1], 'w', markerfacecolor=col, marker='.')\n    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,  markeredgecolor='k', markersize=6)","90a69ed5":"from sklearn.manifold import TSNE\ntsne = TSNE()\nX_embedded = tsne.fit_transform(X_train)\nX_embedded\nsns.scatterplot(X_embedded[:,0], X_embedded[:,1], legend='full',hue = np.sign(y_train['EarningsPerShare']))","54e1a9ff":"visualizer = InterclusterDistance(km, embedding= 'tsne')\nvisualizer.fit(X_train)        \nvisualizer.show()              ","ccf8c118":"## Analysis of tickers\nNow to get basic idea we would try to measure the dataset by tickers available. To so we will have to check the tickers and correcponding summary for its each value.","54d9791c":"## Identification of number of clusters for the data\nWe are using here k-means clustering for which the number of clusters is to be predetermined. In order to achieve that we can draw a Scree Chart or check silhouette Plot.","3704346e":"### All these plots strongly recommend the number of clusters should be set at 2.","795969ae":"# Prepare data for model","1207357a":"In this phase all features have been renamed and we have also reduced it to minimal shape for preliminary analysis. Now EarningsPershare has 219 null values\n\nNow let us check a data sample again.","1055d13d":"The preliminary data analysis shows that there are **1781 observations and 79 features in dataset in which *SIX* columns are holding some NaN values.** \n- The null values are atmost 299 while in case of 'For Year' such occurance is 173.\n- 'Period Ending' feature has date values and none of them is nan thus we can directly parse the column to date.\n- 'For Year' feature is having year value of 'Period Ending', thus for nulls it can be calculated. It also suggests that we can use either of 'Period Ending' and 'For Year' but not both required.\n### Jobs to do\n- We can can verify the occurance of nan is in same observations or is in random.\n- __ANOTHER JOB TO BE DONE IS RENAMING THE FEATURES TO REMOVE all PERIODS AND DOTS__\n- Reduce the shape of dataset","0ae3b5fd":"The asset-liablity chart shows that the second best returning ticker __AZO__ is having negative equity which is not a good sign while __4th best earning ticker AAPL__ has a good composure of asset-liability.\nWe can alternatively check the possible pair plots for finding the structure. ","033974ef":"# New York Stock Exchange Data Analysis\n\nThe data used here is S&P 500 companies historical prices with fundamental data which consists of four csv files namely,\n\n\n- **prices.csv:** raw, as-is daily prices. Most of data spans from 2010 to the end 2016, for companies new on stock market date range is shorter. There have been approx. 140 stock splits in that time, this set doesn't account for that.\n- **prices-split-adjusted.csv:** same as prices, but there have been added adjustments for splits.\n- **securities.csv:** general description of each company with division on sectors\n- **fundamentals.csv:** metrics extracted from annual SEC 10K fillings (2012-2016), should be enough to derive most of popular fundamental indicators.\n\nThis notebook deals with preliminary data data analysis that includes preprocessing of data, DatViz and clustering. The basic goal is to create an unsupervised model ofr data analysis using **fundamentals and securities vectors.** \n\n## Fundamentals\nThe fundamentals vectors have companies' fundamental financial statement indicators including **Balance Sheet, Cash-Flow Statement** and **Income-Expense Statement**. In most of the cases all the ratios are present, but in some cases the liquidity indicators like current liability or some other may not be present thus ratios are not valid.\n\n## Securities\nThis vector has stationery data related to *'Ticker Symbol'* like security name, sector, segment and address etc. It can be used to identify status of particular industry segment.","cf58735a":"*After summarization we can now check for the performance by plotting some basic features like Earning\/share, operating Income, asset-liablity etc.*","413e9a15":"Now we can read the data and check its basic structure like data types,Null values and shape etc","b06fc7e4":"# **Please upvote if you like my work and give comments\/suggestions for improvement**","16ff896a":"Here the plot suggests that who had invested in PCLN or AZO must have got huge profits while on other side, investor of APA and DYN have faced huge losses.\nThe plot ***actually*** does not suggests the health of company itself, for which we can check its asset-liability and Payable-Receivable etc","d295b472":"At last we check for the inter cluster distance map for our model."}}