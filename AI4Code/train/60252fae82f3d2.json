{"cell_type":{"09e48ba0":"code","0f917200":"code","f36027f9":"code","562981c5":"code","7b2357a4":"code","9cacedf9":"code","b89398fb":"code","38d9c328":"code","006cb985":"code","3a677fb4":"code","4637fbe7":"code","8bec9504":"code","cdd99db0":"code","4e273e7b":"code","14325e44":"code","7368b940":"code","c31464ad":"code","4adf9c54":"code","4468d6a2":"code","761a9350":"code","4810f15e":"code","7fbe28c5":"code","99e02b12":"code","b881af0c":"code","494ab3d4":"code","69898f12":"code","fb654454":"code","002a2967":"code","1a5e4bb5":"code","8f460015":"code","25ce878a":"code","d080ff9f":"code","06f67c09":"code","aab16145":"code","1fab1af7":"code","4b07943a":"code","4c778a88":"code","bc685bb6":"code","f1270838":"code","227c4389":"code","62580935":"code","e8dd794c":"code","09f5141a":"markdown","3b6f498c":"markdown","7b513bbc":"markdown","f211ecb4":"markdown","bc60ae1e":"markdown"},"source":{"09e48ba0":"import re\nimport string\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential, Model\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Activation, Dropout\nfrom tensorflow.keras.layers import Conv1D, Embedding, GlobalAveragePooling1D \nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.preprocessing import image","0f917200":"df = pd.read_csv('..\/input\/memotion-dataset-7k\/memotion_dataset_7k\/labels.csv')\ndf.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\ndf = df.drop(columns = ['text_ocr'])\ndf.head()","f36027f9":"df[df.isnull().any(axis=1)]","562981c5":"full_df = df.copy()\nfull_df.isnull().any()","7b2357a4":"clean_df = df.copy()\nclean_df.dropna(inplace=True)\nclean_df.isnull().any()","9cacedf9":"df = df.replace({'humour': {'not_funny': 0, 'funny': 1, 'very_funny': 2, 'hilarious':3},\n            'sarcasm': {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 2, 'very_twisted': 3},\n            'offensive': {'not_offensive': 0, 'slight': 1, 'very_offensive': 2, 'hateful_offensive': 3},\n            'motivational': {'not_motivational': 0, 'motivational': 1},\n            'overall_sentiment': {'very_negative': 0, 'negative': 1, 'neutral': 2, 'positive': 3, 'very_positive': 4}})","b89398fb":"from PIL import ImageFile, ImageOps\nImageFile.LOAD_TRUNCATED_IMAGES = True","38d9c328":"width = 100\nheight = 100\nX_full = []\nX_full_path = []\nfor i in tqdm(range(full_df.shape[0])):\n    path = '..\/input\/memotion-dataset-7k\/memotion_dataset_7k\/images\/'+full_df['image_name'][i]\n    img = image.load_img(path,target_size=(width,height,3))\n    img = image.img_to_array(img)\n    img = img\/255.0\n    X_full.append(img)\n    X_full_path.append(path)","006cb985":"width = 100\nheight = 100\nX_cleaned = []\nX_cleaned_path = []\nfor i in tqdm(range(clean_df.shape[0])):\n    if i in [119, 4799, 6781, 6784, 6786]:\n        pass\n    else:\n        path = '..\/input\/memotion-dataset-7k\/memotion_dataset_7k\/images\/'+clean_df['image_name'][i]\n        img = image.load_img(path,target_size=(width,height,3))\n        img = image.img_to_array(img)\n        img = img\/255.0\n        X_cleaned.append(img)\n        X_cleaned_path.append(path)","3a677fb4":"deleted_paths = [paths for paths in X_full_path + X_cleaned_path if paths not in X_full_path or paths not in X_cleaned_path]\ndeleted_paths","4637fbe7":"delete_var = [full_df, clean_df, X_cleaned, X_full, X_cleaned_path, X_full_path]\nfor i in delete_var:\n    del i","8bec9504":"width = 100\nheight = 100\nX = []\nfor i in tqdm(range(clean_df.shape[0])):\n    if i in [119, 4799, 6781, 6784, 6786]:\n        pass\n    else:\n        path = '..\/input\/memotion-dataset-7k\/memotion_dataset_7k\/images\/'+clean_df['image_name'][i]\n        img = image.load_img(path,target_size=(width,height,3))\n        img = image.img_to_array(img)\n        img = img\/255.0\n        X.append(img)","cdd99db0":"X = np.array(X)","4e273e7b":"X.shape","14325e44":"rows_to_drop = ['image_120.jpg',\n              'image_4800.jpg',\n              'image_6782.jpg',\n              'image_6785.jpg',\n              'image_6787.jpg',\n              'image_6988.jpg',\n              'image_6989.jpg',\n              'image_6990.png',\n              'image_6991.jpg',\n              'image_6992.jpg']","7368b940":"cleaner_df = df\ncleaner_df.head()","c31464ad":"for images in rows_to_drop:\n    cleaner_df.drop(cleaner_df[cleaner_df['image_name'] == images].index, inplace=True)","4adf9c54":"cleaner_df.shape","4468d6a2":"np.save('image_array', X)","761a9350":"Y = cleaner_df.iloc[:,2:]\nY.shape","4810f15e":"fig, axes = plt.subplots(5,5, figsize=(12, 12))\n\nfor i in range(5):\n    for j in range(5):\n        index = np.random.randint(X.shape[0])\n        axes[i][j].imshow(X[index,:,:,0])\n        #axes[i][j].set_title(f'Label={y_train[index]}')\n        #axes[i][j].axis('off')\n        plt.tight_layout()","7fbe28c5":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n])\n\npreprocess_input = tf.keras.applications.resnet_v2.preprocess_input\n\nrescale = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/127.5, offset= -1)","99e02b12":"base_model_1 = tf.keras.applications.ResNet50(input_shape=X[0].shape,\n                                               include_top=False,\n                                               weights='imagenet')\nbase_model_2 = tf.keras.applications.VGG16(input_shape=X[0].shape,\n                                               include_top=False,\n                                               weights='imagenet')","b881af0c":"base_model_1.trainable = False\nbase_model_2.trainable = False","494ab3d4":"global_average_layer = GlobalAveragePooling2D()","69898f12":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)","fb654454":"del X","002a2967":"image_input = tf.keras.Input(shape=(100, 100, 3), name = 'image_input')\niamge_layers = data_augmentation(image_input)\niamge_layers = preprocess_input(iamge_layers)\nlayer_bm_1 = base_model_1(image_input, training=False)\nlayer_bm_1 = Conv2D(2048, kernel_size=2,padding='valid')(layer_bm_1)\nlayer_bm_1 = Dense(512)(layer_bm_1)\nlayer_bm_2 = base_model_2(image_input, training=False)\nlayer_bm_2 = Dense(512)(layer_bm_2)\nlayers = tf.keras.layers.concatenate([layer_bm_1, layer_bm_2])\niamge_layers = global_average_layer(layer_bm_1)\nimage_layers = Dropout(0.2, name = 'dropout_layer')(iamge_layers)","1a5e4bb5":"def standardization(data):\n    data = data.apply(lambda x: x.lower())\n    data = data.apply(lambda x: re.sub(r'\\d+', '', x))\n    data = data.apply(lambda x: re.sub(r'.com', '', x, flags=re.MULTILINE))\n    data = data.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n    return data\n\ndf['text_corrected'] = standardization(df.text_corrected)","8f460015":"from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\nvocab_size = 10000\nsequence_length = 100\n\nvectorize_layer = TextVectorization(\n    max_tokens=vocab_size,\n    output_mode='int',\n    output_sequence_length=sequence_length)\n\ntext_ds = np.asarray(df['text_corrected'])\nvectorize_layer.adapt(tf.convert_to_tensor(text_ds))","25ce878a":"X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(cleaner_df.text_corrected, Y, test_size = 0.2)","d080ff9f":"embedding_dim=16\n\ntext_input = tf.keras.Input(shape=(None,), dtype=tf.string, name='text')\ntext_layers = vectorize_layer(text_input)\ntext_layers = tf.keras.layers.Embedding(vocab_size, embedding_dim, name=\"embedding\")(text_layers)\ntext_layers = tf.keras.layers.Dropout(0.5)(text_layers)\n\ntext_layers = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, activation='relu', return_sequences=True))(text_layers)\n\ntext_layers = tf.keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(text_layers)\ntext_layers = tf.keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(text_layers)\ntext_layers = tf.keras.layers.GlobalMaxPooling1D()(text_layers)\n\n# We add a vanilla hidden layer:\ntext_layers = tf.keras.layers.Dense(2048, activation=\"relu\")(text_layers)\ntext_layers = tf.keras.layers.Dropout(0.5)(text_layers)","06f67c09":"concatenate = tf.keras.layers.concatenate([image_layers, text_layers], axis=1)","aab16145":"overall_layer = tf.keras.layers.Dense(2048, activation='softmax')(concatenate)","1fab1af7":"prediction_layer_1 = tf.keras.layers.Dense(4, activation='softmax', name = 'sarcasm')\nprediction_layer_2 = tf.keras.layers.Dense(4, activation='softmax', name = 'humuor')\nprediction_layer_3 = tf.keras.layers.Dense(4, activation='softmax', name = 'offensive')\nprediction_layer_4 = tf.keras.layers.Dense(1, activation='sigmoid', name = 'motivational')\nprediction_layer_5 = tf.keras.layers.Dense(5, activation='softmax', name = 'overall')","4b07943a":"output_1 = prediction_layer_1(overall_layer)\noutput_2 = prediction_layer_2(overall_layer)\noutput_3 = prediction_layer_3(overall_layer)\noutput_4 = prediction_layer_4(overall_layer)\noutput_5 = prediction_layer_5(overall_layer)\nmodel = tf.keras.Model(inputs = [image_input, text_input] , outputs = [output_1, output_2, output_3, output_4, output_5])","4c778a88":"pip install tensorflow-addons","bc685bb6":"import tensorflow_addons as tfa","f1270838":"base_learning_rate = 0.01\nlosses = {\n      \"humuor\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n      \"sarcasm\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n      \"offensive\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n      \"motivational\": tf.keras.losses.BinaryCrossentropy(from_logits=False),\n      \"overall\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n}\nlossWeights = {\n      \"humuor\": 1.0, \n      \"sarcasm\": 1.0, \n      \"offensive\": 1.0, \n      \"motivational\": 1.0,\n      \"overall\": 1.0\n}\nmetric = {\n    \"humuor\": ['acc',tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.9)],\n    \"sarcasm\": ['acc',tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.9)],\n    \"offensive\": ['acc',tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.9)],\n    \"motivational\": ['acc',tfa.metrics.F1Score(num_classes=1, average=\"micro\", threshold = 0.9)],\n    \"overall\": ['acc',tfa.metrics.F1Score(num_classes=5, average=\"micro\", threshold = 0.9)]\n}\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss = losses,\n              loss_weights= lossWeights,\n              metrics=metric)","227c4389":"learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001]\nfor i in learning_rates:\n    model.compile(optimizer=tf.keras.optimizers.RMSprop(i),\n              loss = losses,\n              loss_weights= lossWeights,\n              metrics=['accuracy'])\n    \n    history = model.fit(x = {\"image_input\": X_train, \"text_input\": X_text_train},\n                    y = {\"sarcasm\": y_train.sarcasm, \n                         \"humuor\": y_train.humour, \n                         \"offensive\": y_train.offensive, \n                         \"motivational\": y_train.motivational, \n                         \"overall\": y_train.overall_sentiment},\n                    batch_size=32,\n                    epochs=50,\n                    verbose=2\n                   )","62580935":"pd.DataFrame(history.history)","e8dd794c":"evaluate = model.evaluate(x = {\"image_input\": X_test, \"text_input\": X_text_test},\n                    y = {\"sarcasm\": y_test.sarcasm, \n                         \"humuor\": y_test.humour, \n                         \"offensive\": y_test.offensive, \n                         \"motivational\": y_test.motivational, \n                         \"overall\": y_test.overall_sentiment},\n                    batch_size=32,\n                    verbose=2\n                   )","09f5141a":"### **Image Preprocessing**","3b6f498c":"**Loading Datasets**","7b513bbc":"**Loading Basic Libraries**","f211ecb4":"# Memotion Analysis: Sentiment Analysis of Memes","bc60ae1e":"### **Base Model for Transfer Learning**"}}