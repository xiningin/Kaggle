{"cell_type":{"27761f19":"code","ab3b45af":"code","0a311ee6":"code","431359f5":"code","67768bf8":"code","6deacd8b":"code","4e717d2e":"code","adcf4f26":"code","58ba85d4":"code","165434b0":"code","7a5c78e5":"code","a750dc34":"code","88d8c3b5":"code","b57f6f4a":"markdown","69914b93":"markdown","dc7e9ead":"markdown","6d0208ee":"markdown","150cad50":"markdown","2333eef4":"markdown","0cee71fc":"markdown","15eea5eb":"markdown","d8c729bb":"markdown","5e156845":"markdown"},"source":{"27761f19":"!pip install -U lightautoml","ab3b45af":"# Standard python libraries\nimport os\nimport time\nimport re\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, f1_score\nimport torch\n\n# Imports from our package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.dataset.roles import DatetimeRole\nfrom lightautoml.tasks import Task","0a311ee6":"N_THREADS = 4 # threads cnt for lgbm and linear models\nN_FOLDS = 5 # folds cnt for AutoML\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 5*3600 # Time in seconds for automl run","431359f5":"np.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","67768bf8":"train_data = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/train.csv\")","6deacd8b":"test = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/test.csv\")","4e717d2e":"sample_submission = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv\")","adcf4f26":"task = Task('binary')","58ba85d4":"roles = {\n    'target': 'target',\n    'drop': 'Id',\n}","165434b0":"%%time \n\nautoml = TabularUtilizedAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params={'use_algos': [['lgb', 'cb'], ['lgb_tuned'],]},\n                       reader_params = {'n_jobs': N_THREADS})\noof_pred = automl.fit_predict(train_data, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))","7a5c78e5":"%%time\n\ntest_pred = automl.predict(test)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))","a750dc34":"sample_submission['target'] = test_pred.data[:, 0]\nsample_submission.head()","88d8c3b5":"sample_submission.to_csv('TPS10_21_LightAutoML.csv', index = False)","b57f6f4a":"Step 0.2. Parameters","69914b93":"Step 3. Create AutoML from preset","dc7e9ead":"Step 4. Predict to test data and check scores","6d0208ee":"Step 0.0. Install LightAutoML","150cad50":"Step 0.1. Import necessary libraries","2333eef4":"Step 0.4. Data load","0cee71fc":"Step 2. Setup columns roles","15eea5eb":"========= AutoML preset usage =========                              \nStep 1. Create Task","d8c729bb":"\nStep 5. Generate submission","5e156845":"Step 0.3. Fix torch number of threads and numpy seed"}}