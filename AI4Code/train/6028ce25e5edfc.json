{"cell_type":{"82771b15":"code","0cd3dd89":"code","ca2d65e9":"code","84a95596":"code","de489db4":"code","bd922ecb":"code","37d7c552":"code","23e39ceb":"code","7fe5783a":"code","96c347fc":"code","2576d3e6":"code","bde9108d":"code","a1c26cbb":"code","2edd7753":"code","62bc7836":"code","b9f95a8f":"code","c58999a5":"code","10a1dec1":"code","ced162ba":"code","c3333e8d":"code","d1f165a8":"code","4df57b40":"code","6692c5f6":"code","dd200ebc":"code","910da53f":"code","5ea2e504":"code","030d1c84":"code","2c2ab790":"code","e5579f78":"code","0fccfcd2":"code","ea7a1539":"code","da32b0d1":"code","147ba936":"code","b8013873":"code","3957464f":"code","731fdd78":"code","335d56f2":"code","298ac499":"code","c73e10ac":"code","7c922912":"code","2a6b73f8":"code","42a4cc9d":"code","f2347978":"code","45d8026f":"code","a4322202":"code","6bc1c23d":"code","f91f0bf4":"code","7103f79b":"code","31796bc3":"code","c13d45fc":"code","86687883":"code","6a623ae9":"code","dee64e33":"code","b413bb88":"code","ab7df7f3":"code","4a555b51":"code","b308c088":"code","0d15de31":"code","532aa65e":"code","6c489666":"code","fa855350":"code","85f82594":"code","f9df608d":"code","98d63632":"code","3ea7e23e":"code","c6c48eb5":"code","2b2d8bde":"markdown","2840b7aa":"markdown","7539b2aa":"markdown","24158c58":"markdown","83015742":"markdown","5a6cdce0":"markdown","7918c2b2":"markdown","172ea528":"markdown","ce4e3910":"markdown","9a1d5624":"markdown","c76af044":"markdown","b14863da":"markdown","96fd21bf":"markdown","6b7fde51":"markdown","d3933576":"markdown","3292e348":"markdown","78dc286b":"markdown","4d607f06":"markdown","822e5989":"markdown","b67c004c":"markdown","e709439c":"markdown","aca1ce6f":"markdown","fb940f47":"markdown","cefe14c4":"markdown","f5aeb061":"markdown","5818fb57":"markdown","d349e57c":"markdown","276d563b":"markdown","d4ccbdbb":"markdown","20a8b895":"markdown","f390cbe8":"markdown","033b0549":"markdown","6a4b99bf":"markdown","b98f9635":"markdown","ea4ba3e4":"markdown","345dd0f4":"markdown","eae812d0":"markdown","10fe21cc":"markdown","85ae0dd9":"markdown","f0ffc068":"markdown","fbe0e1de":"markdown","4fe9d781":"markdown","0a3de70b":"markdown","33a656b3":"markdown","c0ad696a":"markdown"},"source":{"82771b15":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0cd3dd89":"import glob\nimport os\nnp.random.seed(1111)","ca2d65e9":"from pathlib import Path ","84a95596":"import tensorflow as tf\nfrom tensorflow.keras import layers, models \nfrom keras.utils.vis_utils import plot_model","de489db4":"from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_curve, PrecisionRecallDisplay","bd922ecb":"target = 'running'\nfilename = f'{target}-1'\npath = f\"\/kaggle\/input\/data-for-activity-recognition\/data\/data\/{target}\/{filename}.csv\"\ndf_example = pd.read_csv(path)","37d7c552":"df_example.head()","23e39ceb":"list_samples_example = df_example.to_dict('records')","7fe5783a":"list_samples_example[0]","96c347fc":"dict_samples_example = {\n    'filename': filename,\n    'fullpath': path,\n    'target' : target,\n    'samples': list_samples_example\n} ","2576d3e6":"dict_samples_example","bde9108d":"files = np.sort(glob.glob(\"\/kaggle\/input\/data-for-activity-recognition\/data\/data\/*\/*\"))\nnp.random.shuffle(files)\nprint(\"Total number of files: \", len(files))\nprint(\"Showing first 10 files...\")\nfiles[:10]","a1c26cbb":"output_list = []\n\nfor file in files:\n    print(file, end='\\r')\n    parts = Path(file).parts\n    target = parts[-2]\n    filename = parts[-1]\n    \n    df_cur = pd.read_csv(file)\n    \n    list_samples_cur = df_cur.to_dict('records')\n    \n    dict_samples_cur = {\n        'filename': filename,\n        'fullpath': file,\n        'target' : target,\n        'samples': list_samples_cur\n    } \n    \n    output_list.append(dict_samples_cur)","2edd7753":"len(output_list)","62bc7836":"output_list[6000]","b9f95a8f":"output_list_df = pd.DataFrame(output_list)","c58999a5":"output_list_df.shape","10a1dec1":"output_list_df.tail()","ced162ba":"output_list_df.to_parquet(\"\/kaggle\/working\/parquet_data.parquet\")","c3333e8d":"full_dataset_parquet = pd.read_parquet(\"\/kaggle\/working\/parquet_data.parquet\")","d1f165a8":"mapping = {item:i for i, item in enumerate(full_dataset_parquet['target'].unique())}\nfull_dataset_parquet[\"target_id\"] = full_dataset_parquet[\"target\"].apply(lambda x: mapping[x])","4df57b40":"mapping","6692c5f6":"full_dataset_parquet['id'] = full_dataset_parquet['filename'].str.extract(\"\\w+-(\\d+).csv\").astype(int)","dd200ebc":"full_dataset_parquet['unique_id'] = full_dataset_parquet['id'] + ((1+full_dataset_parquet[\"target_id\"])*1e7).astype(int)","910da53f":"full_dataset_parquet","5ea2e504":"full_dataset_parquet['samples'][0]","030d1c84":"[x['accelerometer_X'] for x in full_dataset_parquet['samples'][0]]","2c2ab790":"def bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n\n\ndef float_feature(value):\n    \"\"\"Returns a float_list from a float \/ double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\n\ndef int64_feature(value):\n    \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef float_feature_list(value):\n    \"\"\"Returns a list of float_list from a float \/ double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))","e5579f78":"def create_example(example):\n    feature = {\n        \"acc_x\": float_feature_list([x['accelerometer_X'] for x in example['samples']]),\n        \"acc_y\": float_feature_list([x['accelerometer_Y'] for x in example['samples']]),\n        \"acc_z\": float_feature_list([x['accelerometer_Z'] for x in example['samples']]),\n        \"acc_matrix\": float_feature_list(\n            pd.DataFrame.from_records([x for x in example['samples']]).values.reshape(-1)\n        ),\n        \"target_id\": int64_feature(example[\"target_id\"]),\n        \"fullpath\": bytes_feature(example[\"fullpath\"]),\n        \"id\": int64_feature(example['unique_id']),\n        \"target_id_onehot\": float_feature_list(tf.keras.utils.to_categorical(example[\"target_id\"], \n                                                                        num_classes=len(mapping.keys())\n                                                                       )\n                                         )\n    }\n    return tf.train.Example(features=tf.train.Features(feature=feature))","0fccfcd2":"create_example(full_dataset_parquet.loc[0])","ea7a1539":"full_dataset_parquet.shape[0]","da32b0d1":"num_samples = 128\nnum_tfrecords = full_dataset_parquet.shape[0] \/\/ num_samples\nif full_dataset_parquet.shape[0] % num_samples:\n    num_tfrecords += 1  # add one record if there are any remaining samples\n\nprint(num_tfrecords)\n\ntfrecords_dir = '\/kaggle\/working\/tfrecords'\n\nif not os.path.exists(tfrecords_dir):\n    os.makedirs(tfrecords_dir)  # creating TFRecords output folder","147ba936":"for tfrec_num in range(num_tfrecords):\n    samples = full_dataset_parquet.loc[(tfrec_num * num_samples) : ((tfrec_num + 1) * num_samples)]\n\n    with tf.io.TFRecordWriter(\n        tfrecords_dir + \"\/file_%.2i-%i.tfrec\" % (tfrec_num, len(samples)-1)\n    ) as writer:\n        for index, row_sample in samples.iterrows():\n            example = create_example(row_sample)\n            writer.write(example.SerializeToString())","b8013873":"tfrecords_dir","3957464f":"filenames = tf.io.gfile.glob(f\"{tfrecords_dir}\/*.tfrec\")\n#filenames\n\nshuffled_filenames = filenames.copy()\nnp.random.shuffle(shuffled_filenames)\n\nprint(f\"Total: {len(shuffled_filenames)}\")\nprint(\"---------\")\n\ntrain_val_size = 0.7\ntrain_size = 0.7\n\ntrain_val_len = int(len(shuffled_filenames)*train_val_size)\ntrain_val_filenames, test_filenames = shuffled_filenames[:train_val_len], shuffled_filenames[train_val_len:]\n\ntrain_len = int(len(train_val_filenames)*train_size)\ntrain_filenames, val_filenames = train_val_filenames[:train_len], train_val_filenames[train_len:]\n\nprint(f\"Train: {len(train_filenames)}\")\nprint(f\"Validation: {len(val_filenames)}\")\nprint(f\"Test: {len(test_filenames)}\")\n","731fdd78":"for batch in tf.data.TFRecordDataset(filenames):\n    print(batch)\n    break","335d56f2":"def parse_tfrecord_fn(example):\n    \n    feature_description = {\n        \"acc_x\": tf.io.VarLenFeature(tf.float32),\n        \"acc_y\": tf.io.VarLenFeature(tf.float32),\n        \"acc_z\": tf.io.VarLenFeature(tf.float32),\n        \"acc_matrix\": tf.io.VarLenFeature(tf.float32),\n        \"id\": tf.io.FixedLenFeature([], tf.int64),\n        \"fullpath\": tf.io.FixedLenFeature([], tf.string),\n        \"target_id\": tf.io.FixedLenFeature([], tf.int64),\n        'target_id_onehot': tf.io.VarLenFeature(tf.float32)\n    }\n    example = tf.io.parse_single_example(example, feature_description)\n    example[\"acc_x\"] = tf.sparse.to_dense(example[\"acc_x\"])\n    example[\"acc_y\"] = tf.sparse.to_dense(example[\"acc_y\"])\n    example[\"acc_z\"] = tf.sparse.to_dense(example[\"acc_z\"])\n    example[\"acc_matrix\"] = tf.reshape(tf.sparse.to_dense(example[\"acc_matrix\"]), (30,3,1))\n    example[\"target_id_onehot\"] = tf.sparse.to_dense(example[\"target_id_onehot\"])\n    return example","298ac499":"for batch in tf.data.TFRecordDataset(filenames).map(parse_tfrecord_fn):\n    display(batch)\n    break\n    ","c73e10ac":"def prepare_sample(features):\n    #image = tf.image.resize(features[\"image\"], size=(224, 224))\n    #return image, features[\"category_id\"]\n    acc_all = features[\"acc_matrix\"]\n    target = features['target_id_onehot']\n    \n    return acc_all, target","7c922912":"(tf.data.TFRecordDataset(filenames)\n .map(parse_tfrecord_fn)\n .map(prepare_sample)\n)","2a6b73f8":"AUTOTUNE = tf.data.AUTOTUNE\nbatch_size = 32\n\ndef get_dataset(filenames, batch_size):\n    dataset = (\n        tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n        .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n        .map(prepare_sample, num_parallel_calls=AUTOTUNE)\n        .shuffle(batch_size * 10)\n        .batch(batch_size)\n        .prefetch(AUTOTUNE)\n    )\n    return dataset","42a4cc9d":"get_dataset(filenames, batch_size)","f2347978":"len(mapping.keys())","45d8026f":"mapping","a4322202":"multiclass_problem = True\n\nfinal_activation = 'sigmoid'\nfinal_layer_size = 1\nif multiclass_problem:\n    final_activation = 'softmax'\n    final_layer_size = len(mapping.keys())\n\nmodel = tf.keras.Sequential([\n    layers.Conv2D(16, 3, activation = \"relu\", input_shape = (30,3,1)),\n    #layers.MaxPool2D(2),\n    layers.Reshape((28,16,1)),\n    layers.Conv2D(32, 3, activation = \"relu\"),\n    layers.MaxPool2D(2),\n    layers.Flatten(),\n    layers.Dense(16, activation = \"relu\"),\n    layers.Dense(final_layer_size, activation = final_activation) # softmax va bene per i multiclass, altrimenti uso sigmoid\n])\nmodel.summary()","6bc1c23d":"loss_to_use = tf.keras.losses.BinaryCrossentropy()\nif multiclass_problem:\n    loss_to_use = 'categorical_crossentropy'\n\nmodel.compile(loss = loss_to_use, \n              optimizer = \"adam\", \n              metrics = [\"accuracy\", \n                         tf.keras.metrics.AUC(curve = 'ROC'),\n                         tf.keras.metrics.AUC(curve = 'PR'),\n                         tf.keras.metrics.Precision(),\n                         tf.keras.metrics.Recall(),\n                         tf.keras.metrics.PrecisionAtRecall(0.8) \n                        ]) #tf.keras.metrics.AUC(from_logits=True)","f91f0bf4":"get_dataset(filenames, batch_size)","7103f79b":"examples_per_file = 128\n\nsteps_per_epoch = np.int(np.ceil(examples_per_file*len(train_filenames)\/batch_size))\nvalidation_steps = np.int(np.ceil(examples_per_file*len(val_filenames)\/batch_size))\nsteps = np.int(np.ceil(examples_per_file*len(test_filenames)\/batch_size))\nprint(\"steps_per_epoch = \", steps_per_epoch)\nprint(\"validation_steps = \", validation_steps)\nprint(\"steps = \", steps)","31796bc3":"train_dataset = get_dataset(train_filenames, batch_size)\nval_dataset = get_dataset(val_filenames, batch_size)\ntest_dataset = get_dataset(test_filenames, batch_size)","c13d45fc":"epochs = 10\nsteps_per_epoch = steps_per_epoch\n\nmodel.fit(train_dataset,\n          validation_data = val_dataset, \n          steps_per_epoch = steps_per_epoch,\n          validation_steps = validation_steps, \n          epochs = epochs\n         )","86687883":"model.evaluate(test_dataset, steps = len(test_filenames))","6a623ae9":"steps_to_take = len(test_filenames)\n\npred_values_list = []\npred_list = []\ntrue_list = []\ntrue_list_onehot = []\n\nfor x, y in test_dataset.take(steps_to_take):\n    \n    pred_value = model.predict(x)\n    if multiclass_problem:\n        pred = pred_value.argmax(1)\n    else:\n        threshold = 0.5\n        pred = pred_value > threshold\n    \n    pred_values_list = pred_values_list + list(pred_value)\n    pred_list = pred_list + list(pred)\n    true_list = true_list + list(y.numpy().argmax(axis=1).astype(int))\n    true_list_onehot = true_list_onehot + list(y.numpy().astype(int))","dee64e33":"print('Accuracy')\nprint(accuracy_score(true_list, [x.astype(int) for x in pred_list]))\n\nprint('Confusion Matrix')\nprint(confusion_matrix(true_list, [x.astype(int) for x in pred_list]))","b413bb88":"m = tf.keras.metrics.AUC(curve = 'PR')\nm.update_state(true_list_onehot, pred_values_list)\nm.result().numpy()","ab7df7f3":"def prepare_sample_multipleinputs(features):\n    #image = tf.image.resize(features[\"image\"], size=(224, 224))\n    #return image, features[\"category_id\"]\n    acc_x = features[\"acc_x\"]\n    acc_y = features[\"acc_y\"]\n    target = features['target_id_onehot']\n    \n    return (acc_x, acc_y), target","4a555b51":"def get_dataset_multipleinputs(filenames, batch_size):\n    dataset = (\n        tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n        .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n        .map(prepare_sample_multipleinputs, num_parallel_calls=AUTOTUNE)\n        .shuffle(batch_size * 10)\n        .batch(batch_size)\n        .prefetch(AUTOTUNE)\n    )\n    return dataset","b308c088":"get_dataset_multipleinputs(train_filenames, batch_size)","0d15de31":"\n\nmulticlass_problem = True\n\nfinal_activation = 'sigmoid'\nfinal_layer_size = 1\nif multiclass_problem:\n    final_activation = 'softmax'\n    final_layer_size = len(mapping.keys())\n\n### Can't use Sequential API with multiple inputs\n    \n# model = tf.keras.Sequential([\n#     layers.Conv2D(16, 1, activation = \"relu\", input_shape = (30,1,1)),\n#     #layers.MaxPool2D(2),\n#     layers.Reshape((30,16,1)),\n#     layers.Conv2D(32, 3, activation = \"relu\"),\n#     layers.MaxPool2D(2),\n#     layers.Flatten(),\n#     layers.Dense(16, activation = \"relu\"),\n#     layers.Dense(final_layer_size, activation = final_activation) # softmax va bene per i multiclass, altrimenti uso sigmoid\n# ])\n\ninput_x = layers.Input(shape=(30, 1, 1), name = 'input_x')\ninput_y = layers.Input(shape=(30, 1, 1), name = 'input_y')\n\nreshape_input_x = layers.Reshape((1,30,1), name = 'reshape_input_x')(input_x)\nreshape_input_y = layers.Reshape((1,30,1), name = 'reshape_input_y')(input_y)\n\nconv1d_x = layers.Conv1D(16, 3, activation = 'relu', name = 'conv1d_x')(reshape_input_x) # output: 28x1x16\nreshape_x = layers.Reshape((28, 16, 1), name = 'reshape_x')(conv1d_x)\nconv2d_x = layers.Conv2D(32, 3, activation = 'relu', name = 'conv2d_x')(reshape_x) # output: 26x14x32\nmaxpool_x = layers.MaxPool2D(2, name = 'maxpool_x')(conv2d_x) # output:\nflatten_x = layers.Flatten(name = 'flatten_x')(maxpool_x)\n\nconv1d_y = layers.Conv1D(16, 3, activation = 'relu', name = 'conv1d_y')(reshape_input_y) # output: 28x1x16\nreshape_y = layers.Reshape((28, 16, 1), name = 'reshape_y')(conv1d_y)\nconv2d_y = layers.Conv2D(32, 3, activation = 'relu', name = 'conv2d_y')(reshape_y) # output: 26x14x32\nmaxpool_y = layers.MaxPool2D(2, name = 'maxpool_y')(conv2d_y)\nflatten_y = layers.Flatten(name = 'flatten_y')(maxpool_y)\n\nconcat_x_y = layers.Concatenate(name = 'concat_x_y')([flatten_x, flatten_y])\n\ndense1 = layers.Dense(16, activation = 'relu', name = 'dense1')(concat_x_y)\noutput = layers.Dense(final_layer_size, activation = final_activation, name = 'output')(dense1)\n\nmodel_mi = models.Model(inputs=[input_x, input_y], outputs=[output])\n\nmodel_mi.summary()","532aa65e":"plot_model(model_mi, show_shapes=True, show_layer_names=True)","6c489666":"loss_to_use = tf.keras.losses.BinaryCrossentropy()\nif multiclass_problem:\n    loss_to_use = 'categorical_crossentropy'\n\nmodel_mi.compile(loss = loss_to_use, \n              optimizer = \"adam\", \n              metrics = [\"accuracy\", \n                         tf.keras.metrics.AUC(curve = 'ROC'),\n                         tf.keras.metrics.AUC(curve = 'PR'),\n                         tf.keras.metrics.Precision(),\n                         tf.keras.metrics.Recall(),\n                         tf.keras.metrics.PrecisionAtRecall(0.8) \n                        ]) #tf.keras.metrics.AUC(from_logits=True)","fa855350":"train_dataset_mi = get_dataset_multipleinputs(train_filenames, batch_size)\nval_dataset_mi = get_dataset_multipleinputs(val_filenames, batch_size)\ntest_dataset_mi = get_dataset_multipleinputs(test_filenames, batch_size)","85f82594":"train_dataset_mi","f9df608d":"epochs = 10\nsteps_per_epoch = steps_per_epoch\n\nmodel_mi.fit(train_dataset_mi,\n          validation_data = val_dataset_mi, \n          steps_per_epoch = steps_per_epoch,\n          validation_steps = validation_steps, \n          epochs = epochs\n         )","98d63632":"model.evaluate(test_dataset, steps = len(test_filenames))","3ea7e23e":"steps_to_take = len(test_filenames) #1100\n\npred_values_list = []\npred_list = []\ntrue_list = []\ntrue_list_onehot = []\n\nfor x, y in test_dataset_mi.take(steps_to_take):\n    \n    pred_value = model_mi.predict(x)\n    if multiclass_problem:\n        pred = pred_value.argmax(1) ## solo per multiclasse\n    else:\n        threshold = 0.5\n        pred = pred_value > threshold\n    # TODO aggiungere una if per determinare se il problema \u00e8 multiclasse o binario\n    #print(pred)\n    #print(y)\n    \n    pred_values_list = pred_values_list + list(pred_value)\n    pred_list = pred_list + list(pred)\n    true_list = true_list + list(y.numpy().argmax(axis=1).astype(int))\n    true_list_onehot = true_list_onehot + list(y.numpy().astype(int))\n    \n#print(pred_list)\n#print(true_list)","c6c48eb5":"print('Accuracy')\nprint(accuracy_score(true_list, [x.astype(int) for x in pred_list]))\n\nprint('Confusion Matrix')\nprint(confusion_matrix(true_list, [x.astype(int) for x in pred_list]))","2b2d8bde":"And, if required, we can extract the acceleration values for a single axis:","2840b7aa":"Let's update the overall *get_dataset* function as well:","7539b2aa":"Now, the next question: how can we load TFRecords data when the model requires more than one input?\n\nAs an example, let's train a model where x-axis and y-axis accelerometric data are loaded and treated separately.\n\nThe parser function (*parse_tfrecord_fn*) is unchanged - we already prepared acceleration data split by axis.\n\nHowever, we need to update the *prepare_sample* function:","24158c58":"Then, we define the loss and the metrics, and we compile the model.","83015742":"Let's roll!","5a6cdce0":"The rest of the dictionary keys will represent the target and other useful info (such as the original file path)","7918c2b2":"For several purposes, including training the model, we need to convert our \"folder name\" target into a numerical one. Let's define the mapping:","172ea528":"Now we can create a function that will convert our data into Examples.\n\nWe define features containing:\n* Acceleration time series, split by axis (x-y-z)\n* Acceleration time series, all axis - this will require to be reshaped into a 1-dimensional array\n* The target id\n* The target id, but one hot encoded - this will be useful later for our Keras model\n* Some other info, such as the id and the original file path","ce4e3910":"However, not everything is needed for our toy model. \n\nWe define a function to prepare our sample - i.e. we select our input (the acceleration time series matrix) and our output (the one-hot encoded target)","9a1d5624":"Once parsed, the content of a TFRecord file is much more readable:","c76af044":"# Create TFRecords","b14863da":"Let's plot the model, to better understand the new structure:","96fd21bf":"We select the best number of steps per epoch","6b7fde51":"### TODO:\n* [X] Read activity recognition data from csv files\n* [X] Retrieve only accelerometer data (required for training the model) and convert to JSON (dict)\n    * [X] Add target to the dictionary\n* [X] Save data in a parquet file\n* [X] Reload parquet file\n* [X] Convert each entry into a TFRecord (or, should I say, TFExample)\n* [X] Save each TFExample entry in a different TFRecord file - or, as suggested here (https:\/\/www.tensorflow.org\/tutorials\/load_data\/tfrecord), save TFExamples in chunks of reasonable size:\n> Note: In general, you should shard your data across multiple files so that you can parallelize I\/O (within a single host or across multiple hosts). The rule of thumb is to have at least 10 times as many files as there will be hosts reading data. At the same time, each file should be large enough (at least 10 MB+ and ideally 100 MB+) so that you can benefit from I\/O prefetching. For example, say you have X GB of data and you plan to train on up to N hosts. Ideally, you should shard the data to ~10*N files, as long as ~X\/(10*N) is 10 MB+ (and ideally 100 MB+). If it is less than that, you might need to create fewer shards to trade off parallelism benefits and I\/O prefetching benefits.\n* [X] Train a toy model reading data from TFRecord files\n* [X] Train another toy model with multiple inputs","d3933576":"Activity data is organized in folders (where the folder name is the target), and each file contains a single example.\n\nFirst we get all files, then we shuffle them - this will be useful later, to avoid bias when training the model.","3292e348":"In order to save the whole list of dictionaries (in a json-like structure) as a parquet file, we first need to convert it into a pandas Dataframe.","78dc286b":"Let's reload the parquet data first.","4d607f06":"Then, we need to add the target to the accelerometer data.\n\nA possible way is just to add a new column with the target value:\n\n> df_example['target'] = 'running' \n\nHowever, this is not a good choice - the target represents a behaviour (running\/idle\/etc.) that is expressed by the whole time series, not by the single samples.\n\n","822e5989":"In order to create a TFRecord file, we need to define ***TF Examples***.\n\nA TF Example is basically a list of TF Features, containing any value we want - targets, list of samples, other info.\n\nWe define some helper functions first:","b67c004c":"Now, we can save the result into a single parquet file:","e709439c":"Before working with TFRecords, we need to convert each csv file to a dictionary structure that contains both input and target.\n\nLet's try it on a single csv file. First, we load a single example in a pandas Dataframe.","aca1ce6f":"Let's compute the whole confusion matrix, to see where our model fails:","fb940f47":"Let's see what we can find in a raw TFRecord file:","cefe14c4":"Let's take a random entry, to see if it worked correctly:","f5aeb061":"# Toy model for activity recognition using TFRecords\n\n**Objective**:\n* Learn to convert a dataset from parquet files to TFRecord files\n* Train a toy model by reading TFRecord files from disk (thus reducing memory usage)\n* Train another, more complex toy model with multiple inputs","5818fb57":"A better solution is to create a dictionary, where the overall time series is considered an entry.\n\nTherefore, we must first convert the Dataframe into a dictionary:","d349e57c":"From a single entry, we can retrieve all the acceleration samples:","276d563b":"Let's try first on a single entry:","d4ccbdbb":"# Train model with multiple inputs","20a8b895":"To avoid issues later, it may be useful to have a unique id for each entry.\n\nWe can extract a progressive number from the filename. But to create a truly unique id, we need to combine it with the target.","f390cbe8":"As we said before, we need to split our dataset into train\/validation\/test sets.\n\nHaving several TFRecord files, this will be quite easy:","033b0549":"Let's check the output of this function:","6a4b99bf":"Let's see the full result:","b98f9635":"Finally, we can define the overall function that will convert our whole dataset into samples that can be feed to our toy model.","ea4ba3e4":"A TFRecord file, as clearly seen above, is a raw binary file. \n\nWe need to define a parser function.\n\nN.B. this is a good place where we can restore the acceleration matrix that was reshaped into a 1d-array.","345dd0f4":"For each example\/file, we create the same structure shown in the previous section:","eae812d0":"And we define the train, validation and test datasets","10fe21cc":"# Train a simple model using TFRecords files","85ae0dd9":"We have to update our train\/val\/test dataset so that they will provide two inputs:","f0ffc068":"# Convert all files to json-like data and save to parquet","fbe0e1de":"Let's run the model!","4fe9d781":"Before creating all Examples, we need to know how many entries will be saved in each TFRecord file.\n\nIdeally we should have TFRecord files ranging from 10 to 100 MB each.\n\nGiven that the current dataset is quite small, we will instead focus on having a reasonable number of samples for each TFRecord file, while having a number of files high enough to be split into train\/validation\/test later.","0a3de70b":"Now we have to update our model architecture: we cannot use Sequential API anymore, so we move to Functional Keras API for defining our two input model: ","33a656b3":"# Convert data to a json-like structure (test on a single file)","c0ad696a":"Let's define our toy model architecture:"}}