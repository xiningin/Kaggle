{"cell_type":{"884742e3":"code","fc2eb139":"code","6409d77c":"code","ea58095c":"code","9746c2dc":"code","7234bc84":"code","7e40b700":"code","6e3a8790":"code","208c00a8":"code","7923831a":"code","c23b9331":"code","0da7653e":"code","4afa30ed":"code","9a98f959":"code","bba17757":"code","e0f97dae":"code","4bc981cf":"markdown","ff6b5d74":"markdown"},"source":{"884742e3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import Model","fc2eb139":"data = pd.read_csv('..\/input\/iris\/Iris.csv')","6409d77c":"data","ea58095c":"data.drop('Id', axis=1, inplace=True)","9746c2dc":"\nX = data.drop('Species', axis=1)y = data['Species']\n","7234bc84":"encoder = LabelEncoder()\n\ny = encoder.fit_transform(y)\nspecies_mappings = {index: label for index, label in enumerate(encoder.classes_)}\n\nspecies_mappings","7e40b700":"pd.DataFrame(X)","6e3a8790":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","208c00a8":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.25)","7923831a":"inputs = Input(shape=(4,)) #shape of X(4)\nx = Dense(16, activation='relu')(inputs)\noutputs = Dense(3, activation='softmax')(x)#shape of y(3)\n\nmodel = Model(inputs=inputs, outputs=outputs)","c23b9331":"model.summary()\ntf.keras.utils.plot_model(model)","0da7653e":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","4afa30ed":"batch_size = 32\nepochs = 300","9a98f959":"plot = model.fit(X_train, y_train, validation_split=0.2, batch_size=batch_size, epochs=epochs)","bba17757":"plt.figure(figsize=(14, 10))\nplt.plot(range(epochs), plot.history['loss'], color='blue')\nplt.plot(range(epochs), plot.history['val_loss'], color='red')\nplt.title(\"Learning Curves for Training\/Testing Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend(['Training Loss', 'Testing Loss'])\nplt.show()","e0f97dae":"model.evaluate(X_test, y_test)","4bc981cf":"# Relu\n> Relu(x, alpha=0.0, max_value=None, threshold=0).\n\n**Arguments**\n\n1. x : Input tensor or variable.\n1. alpha : A float that governs the slope for values lower than the threshold.\n1. max_value : A float that sets the saturation threshold (the largest value the function will return).\n1. threshold : A float giving the threshold value of the activation function below which values will be damped or set to zero.\n\n**Returns**\n    A Tensor representing the input tensor, transformed by the relu activation function. Tensor will be of the same shape and dtype of input x.","ff6b5d74":"# Softmax\n> softmax(x, axis=-1)\n\n**Arguments**\n\n1. x : Input tensor.\n1. axis: Integer, axis along which the softmax normalization is applied.\n\n**Returns**\n    Tensor, output of softmax transformation (all values are non-negative and sum to 1)."}}