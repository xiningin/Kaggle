{"cell_type":{"bb72dde5":"code","7393326a":"code","dd2d9138":"code","2b0e4bf6":"code","4e958371":"code","234151a8":"code","d7d4c66c":"code","7ad6d773":"code","c4a07da0":"markdown","a3c4c421":"markdown","362f8a3f":"markdown","1005d5a2":"markdown","efdc2ed5":"markdown","f073beda":"markdown","04614956":"markdown"},"source":{"bb72dde5":"import torchvision\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport time\nimport pandas as pd\nimport torchvision.datasets as datasets\nfrom IPython import display\nimport matplotlib.pyplot as plt","7393326a":"batch_size = 64\ntransform = transforms.Compose([\n    transforms.Resize(64),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_ds = DataLoader(datasets.CIFAR10(\"data\", train=True, transform=transform, download=True), batch_size=batch_size)\nvalid_ds = DataLoader(datasets.CIFAR10(\"data\", train=False, transform=transform, download=True), batch_size=batch_size)","dd2d9138":"class CNNModel(nn.Module):\n    \n    def __init__(self, num_classes):\n        super(CNNModel, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(),\n            nn.Linear(4096, num_classes)\n        )\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x","2b0e4bf6":"model = CNNModel(num_classes=10)\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")\nmodel.to(device)","4e958371":"def display_message_and_metrics(message, metrics):\n    display.clear_output(wait=False) \n    if len(metrics[\"loss\"]) > 0:\n        pd.DataFrame(metrics).plot()\n        plt.show()\n    print(message)","234151a8":"epochs = 5\ntrain_steps = len(train_ds)\nvalid_steps = len(valid_ds)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\nloss_fn = torch.nn.CrossEntropyLoss()\nmetrics = {\"loss\": [], \"val_loss\": [], \"val_accuracy\": []}\nfor epoch in range(epochs):\n    train_losses = []\n    valid_losses = []\n    model.train()\n    begin = time.time()\n    for batch in train_ds:\n        optimizer.zero_grad()\n        inputs, targets = batch\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        output = model(inputs)\n        loss = loss_fn(output, targets)\n        loss.backward()\n        optimizer.step()\n        train_losses.append(loss.data.item())\n        if len(train_losses) > 0 and len(train_losses) % 50 == 0:\n            current = time.time()\n            elapsed = current - begin\n            display_message_and_metrics(\n                \"Epoch %d: [Training] %.2fs\/%.2fs\"%(epoch + 1, elapsed, elapsed \/ float(len(train_losses)) * train_steps), \n                metrics\n            )\n    model.eval()\n    num_correct = 0\n    num_samples = 0\n    begin = time.time()\n    for batch in valid_ds:\n        optimizer.zero_grad()\n        inputs, targets = batch\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        output = model(inputs)\n        loss = loss_fn(output, targets)\n        valid_losses.append(loss.data.item())\n        correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n        num_correct += torch.sum(correct).item()\n        num_samples += correct.shape[0]\n        if len(valid_losses) > 0 and len(valid_losses) % 50 == 0:\n            current = time.time()\n            elapsed = current - begin\n            display_message_and_metrics(\n                \"Epoch %d: [Validation] %.2fs\/%.2fs\"%(epoch + 1, elapsed, elapsed \/ float(len(valid_losses)) * valid_steps), \n                metrics\n            )\n    train_loss = torch.mean(torch.Tensor(train_losses)).item()\n    valid_loss = torch.mean(torch.Tensor(valid_losses)).item()\n    accuracy = num_correct \/ num_samples if num_samples > 0 else 0\n    metrics[\"loss\"].append(train_loss)\n    metrics[\"val_loss\"].append(valid_loss)\n    metrics[\"val_accuracy\"].append(accuracy)\n    display.clear_output(wait=False) \n    pd.DataFrame(metrics).plot()\n    plt.show()\n    display_message_and_metrics(\n        \"Training Loss: %.2f Validation Loss: %.2f accuracy: %.2f\" %(train_loss, valid_loss, accuracy), \n        metrics\n    )","d7d4c66c":"path = \"model\"\ntorch.save(model, path)","7ad6d773":"model = torch.load(path)\nlabels = np.array(train_ds.dataset.classes)\nfor batch in valid_ds:\n    images, targets = batch\n    images = images.to(device)\n    targets = targets.to(device)\n    prediction = model(images).argmax(dim=1)\n    print(\"Prediction:\", prediction)\n    print(\"Actual result:\", targets)\n    break","c4a07da0":"### 3.2 Training","a3c4c421":"## 4. Save the Model","362f8a3f":"# Cifar10 Image Classification with PyTorch\n## Table of Contents\n* 1. Set up\n* 2. Import datasets\n* 3. Model Development & Evaluation\n* 5. Save the Model\n* 6. Load the Model and Make Predictions\n\n## 1. Set up","1005d5a2":"### 3.1 The CNN Model","efdc2ed5":"## 5. Load the Model and make predicitons","f073beda":"## 2. Import datasets","04614956":"## 3. Model Development & Evaluation"}}