{"cell_type":{"3931f06c":"code","dd48d44b":"code","ae83df9d":"code","cc174564":"code","94b9a3e7":"code","27075e7e":"code","bb12320b":"code","90267ded":"code","a58c6e73":"code","0216b0d8":"code","e434d32a":"code","e042282c":"code","244c29de":"code","8469f67c":"code","56dca3b3":"code","9831bf0e":"code","540aa64c":"code","1c7b75fb":"code","af401dac":"code","c30fc040":"code","bdf4e254":"code","7351987c":"code","0181b434":"code","74136bb4":"code","b66add00":"code","5b2ca231":"code","498c34ff":"code","614ae66f":"code","35009640":"code","a0eead26":"code","cf1b1f6e":"code","c6d10f6c":"code","b240d29d":"code","f63e2f1a":"code","e1df288d":"code","2adc3719":"code","2f24e1b6":"code","01d896b1":"markdown","df8f3b59":"markdown","c7c7b194":"markdown","ef5931e5":"markdown","222bdddd":"markdown","69958163":"markdown","689193ec":"markdown","249197fc":"markdown","c23f0af9":"markdown","671482cf":"markdown","24adcda2":"markdown","034188df":"markdown","deebf9de":"markdown","c1a37510":"markdown","111cf031":"markdown","dc92bd01":"markdown","a4d8e8dc":"markdown","cd956a0a":"markdown","2ca0ff7e":"markdown","5c7332e8":"markdown","906b22de":"markdown","073164a1":"markdown","09742d49":"markdown","e7c26d74":"markdown","7ba840f9":"markdown","27832063":"markdown"},"source":{"3931f06c":"import pandas as pd\nimport numpy as np\nimport csv\nimport re\nimport string\n\nimport nltk\n\nfrom nltk.corpus import stopwords as sw\nfrom nltk.tokenize import RegexpTokenizer\n\nfrom unicodedata import normalize\nfrom datetime import datetime, timedelta\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom statistics import mean","dd48d44b":"# Vetorizador\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Clssificadores\nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import ComplementNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom catboost import CatBoostClassifier\nfrom xgboost.sklearn import XGBClassifier","ae83df9d":"nltk.download('stopwords')\nnltk.download('punkt')","cc174564":"# Desliga warnings desnecess\u00e1rios\npd.set_option('mode.chained_assignment',None)","94b9a3e7":"import numpy as np\nfrom sklearn.base import BaseEstimator\n\n# Vetorizador \"dummy\": n\u00e3o realiza nenhuma transforma\u00e7\u00e3o de dados\n# Mant\u00e9m apenas a interface de um Vetorizador b\u00e1sico\n\nclass DummyVectorizer(BaseEstimator):\n    \n    def __init__(self):\n        pass\n    \n    def fit(self, raw_documents, y=None):\n        return self\n    \n    def transform(self, raw_documents):\n        return np.array(raw_documents).reshape(-1, 1)\n    \n    def fit_transform(self,raw_documents, y=None):\n        self.fit(raw_documents, y)\n        return self.transform(raw_documents)","27075e7e":"import numpy as np\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nfrom sklearn.utils.multiclass import unique_labels\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import RSLPStemmer\nfrom unicodedata import normalize\n\n# Classificador por palavras-chave (keywords).\n# Este classificador foi construido com a mesma interface de um classificador do sklearn.\n# O m\u00e9todo fit() recebe um array de palavras-chave e classes a que se referem, em ordem de prioridade.\n# Se uma classe n\u00e3o cont\u00e9m palavras-chave (array vazio), ser\u00e1 usada como padr\u00e3o para registros que n\u00e3o forem classificados.\n# O m\u00e9todo predict() classifica frases de acordo com as palavras-chave treinadas com fit().\n# Usa um stemmer de l\u00edngua portuguesa para corresponder palavras similares (com mesma raiz).\n# Par\u00e2metros:\n# verbose (default = True): indica se deve exibir informa\u00e7\u00f5es detalhadas do progresso da classifica\u00e7\u00e3o.\n\nclass KeywordClassifier(BaseEstimator, ClassifierMixin):\n    \n    verbose = True # verboso por padrao\n    classes_, X_, y_ = [], [], [] # classes, X e y\n\n    _cache = [] # classes e palavras-chave aprendidas com fit()\n    _y_default = None # classe default, caso n\u00e3o saiba classificar\n    \n    _tokenizer = RegexpTokenizer(r'\\w+') # tokenizador\n    _stemmer = RSLPStemmer() # stemmer de lingua portuguesa\n    \n    # construtor\n    def __init__(self,verbose=True):\n        self.verbose = verbose\n        if self.verbose:\n            print('KeywordClassifier: verbose mode started.')\n    \n    # fit(X,y): preenche _cache com as classes\/keywords\n    def fit(self, X, y, sample_weight=None):\n        # check that X and y have correct shape\n        X, y = check_X_y(X, y, dtype=['object','int64','float64'])\n        # store the classes seen during fit\n        self.classes_ = unique_labels(y) # classes ordenadas\n        self.X_ = X # palavras-chave\n        self.y_ = y # classes\n        self._cache = []\n        for i in range(len(y)):\n            y_data = y[i]\n            X_data = X[i][0]\n            if len(X_data) == 0: self._y_default = y_data # pega classe default\n            self._cache.append({'y':y_data,'X':X_data}) # memoriza keywords\/classes em _cache\n            if self.verbose:\n                print(f'fitting keywords {i+1}\/{len(y)} ...')\n        return self\n\n    # predict(X): retorna classes (y) baseado na matriz de probabilidades\n    # retornada por predict_proba(X)\n    def predict(self, X):\n        # calcula matriz de probabilidades \n        _proba = self.predict_proba(X)\n        _predict = []\n        # varre cada sample da matriz e retorna classe correspondente para cada sample\n        for sample in _proba:\n            _cidx = -1\n            _cmax = 0.0\n            for i in range(len(sample)):\n                if sample[i] > _cmax:\n                    _cmax = sample[i]\n                    _cidx = i\n            _predict.append(self.classes_[_cidx]) # retorna classe (a de maior probabilidade na matriz)\n        return _predict\n    \n    # predict_proba(X): retorna matriz de probabilidades de cada sample, para\n    # cada classe inferida\n    # 0.0 = n\u00e3o h\u00e1 correspond\u00eancia nos keywords (0% de probabilidade de ser da classe)\n    # 1.0 = h\u00e1 correspond\u00eancia nos keywords (100% de probabilidade de ser da classe)\n    def predict_proba(self, X):\n        # check is fit had been called\n        check_is_fitted(self)\n        # input validation\n        X = check_array(X,dtype=['object','int64','float64'])\n        _proba = []\n        _count = []\n        _total = 0\n        # inicializa contador de samples\/classe\n        for j in range(len(self.classes_)):\n            _count.append(0)\n        # varre cada sample de entrada\n        for i in range(len(X)):\n            phrase = X[i][0]  # uma frase de entrada\n            # inicializa matriz de probabilidades do sample\n            _proba_sample = []\n            for j in range(len(self.classes_)):\n                _proba_sample.append(0.0)\n            # procura correspond\u00eancia de keywords\n            y = self._search_keywords(phrase)\n            if y == None: y = self._y_default  # se n\u00e3o encontrou, retorna classe default\n            # varre classes ordenadas\n            for j in range(len(self.classes_)):\n                if y == self.classes_[j]: # se a classe coincide\n                    _proba_sample[j] = 1.0  # registra na matriz a probabilidade 1.0 (100%)\n                    _count[j] = _count[j] + 1  # incrementa contagem de samples\n                    if y != self._y_default: _total = _total + 1  # incrementa total de samples classificados\n                    break\n            _proba.append(_proba_sample)\n            if self.verbose and ((i+1) == 1 or (i+1) % 100 == 0 or (i+1) == len(X)):\n                print(f'predict sample {i+1}\/{len(X)} ...')\n        # exibe relat\u00f3rio, se verboso\n        if self.verbose and _total != 0:\n            print(f'{_total}\/{len(X)} ({round(_total*100\/len(X),1)}%) samples predicted.')\n            print('-----------------')\n            print(' class | samples ')\n            print('-----------------')\n            for j in range(len(self.classes_)): \n                print(f'{self.classes_[j]:^7}|{_count[j]:^9}')\n            print('-----------------')\n        return _proba\n    \n    # predict_log_proba(X): mesmo que predict_proba(X), por\u00e9m resultados em log (base e)\n    def predict_log_proba(self, X):\n        return np.log(self.predict_proba(X))\n    \n    # partial_fit(X,y): implementado como o mesmo que fit(X,y)\n    def partial_fit(self, X, y, classes=None, sample_weight=None):\n        return self.fit(X, y, sample_weight)\n\n    # busca palavras no _cache de keywords, e retorna a classe (y), se encontrada correspond\u00eancia,\n    # ou None se n\u00e3o.\n    def _search_keywords(self, text):\n        tokens = self._tokenizer.tokenize(text.lower())\n        found = []\n        kwparts = []\n        for i in range(len(self._cache)): # keywords classificados por prioridade\n            data = self._cache[i]\n            X = data['X']\n            y = data['y']\n            if len(X) == 0: X = [''] # sem keywords\n            for kword_phrase in X:\n                kword_phrase = kword_phrase.strip()\n                kwparts = []\n                found = []\n                if kword_phrase == '': # classe default (sem keywords)\n                    found.append(y)\n                    kwparts.append('')\n                    break\n                if kword_phrase.find(' ') != -1: # opera\u00e7\u00e3o and\n                    kwparts = kword_phrase.split()\n                else:\n                    kwparts.append(kword_phrase)\n                for kwitem in kwparts:\n                    as_is = kwitem[0].isupper()\n                    if as_is: # keyword como \u00e9 (sem stemmer)\n                        skw = kwitem.lower()\n                    else:\n                        skw = self._stem(kwitem) # keyword flexionada (stemmer para achar raiz da palavra)\n                    # remove acentos\n                    skw = self._ascii(skw)\n                    for word in tokens:\n                        if word == '': continue\n                        # remove acentos\n                        word = self._ascii(word)\n                        if (as_is and word == skw) or (not as_is and word.startswith(skw)):\n                            found.append(y)\n                            break\n                if len(kwparts) != 0 and len(found) == len(kwparts):\n                    break\n            if len(kwparts) != 0 and len(found) == len(kwparts):\n                break\n        if len(found) != 0 and len(found) == len(kwparts):\n            return found[0]\n        else:\n            return None\n    \n    # retorna a raiz (flex\u00e3o) das palavras\n    def _stem(self, text):\n        _phrase = []\n        _tokens = self._tokenizer.tokenize(text)\n        for word in _tokens:\n            _phrase.append(self._stemmer.stem(word))\n        return \" \".join(_phrase)\n    \n    # remove acentos\n    def _ascii(self, text):\n        return normalize('NFKD', text).encode('ASCII', 'ignore').decode('ASCII')\n","bb12320b":"# Realiza uma limpeza bem b\u00e1sica de um texto, preparando-o para classifica\u00e7\u00e3o. \ndef limpar_texto(texto):\n    # Converte para min\u00fasculas\n    texto = texto.lower()\n    # Remove n\u00fameros\n    texto = re.sub(r'[0-9]+',' ',texto)\n    # Remove pontuacao\n    texto = texto.translate(str.maketrans(string.punctuation,' '*len(string.punctuation)))\n    # Remove espacos extras\n    texto = re.sub(r'\\s+',' ',texto)\n    # Remove stopwords\n    tokens = tokenizer.tokenize(texto)\n    tokens = [palavra.strip() for palavra in tokens if palavra not in stopwords]\n    texto = ' '.join(tokens)  \n    # Remove acentos\n    texto = normalize('NFKD',texto).encode('ASCII','ignore').decode('ASCII')\n    # cria dict de palavras unicas\n    # remove palavras menores que 2 caracteres\n    tokens = tokenizer.tokenize(texto)\n    fdist = nltk.FreqDist(tokens)\n    tokens = [palavra.strip() for palavra, freq in fdist.items() if len(palavra) >= 2]\n    texto = ' '.join(tokens)  \n    return texto","90267ded":"# Calcula m\u00e9tricas de desempenho do classificador. Fique \u00e0 vontade para incluir outras m\u00e9tricas que julgar \u00fateis.\n# Lembre-se, todavia, que o desafio utiliza a m\u00e9trica F1 (macro) para avalia\u00e7\u00e3o dos resultados. \n# Refer\u00eancia: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.f1_score.html\n\ndef get_metrics(y_test, y_predicted, average='macro'):  \n    precision = round(precision_score(y_test, y_predicted, pos_label=1, average=average, zero_division=0),4)             \n    recall = round(recall_score(y_test, y_predicted, pos_label=1, average=average, zero_division=0),4)\n    f1 = round(f1_score(y_test, y_predicted, pos_label=1, average=average, zero_division=0),4)\n    accuracy = round(accuracy_score(y_test, y_predicted),4)\n    return accuracy, precision, recall, f1","a58c6e73":"# Treina um classificador, otimiza hiperpar\u00e2metros,\n# avalia performance e retorna m\u00e9tricas de desempenho\ndef build(X,y,vec,est,grid=None,n_splits=5,fit=True):\n    y_preds = []\n    scores_accuracy = []\n    scores_precision = []\n    scores_recall = []\n    scores_f1 = []\n    est_name = est.__class__.__name__\n    vec_name = vec.__class__.__name__\n    print(f'Testando o classificador {est_name} - {vec_name} ...')\n    # massa de dados\n    try:\n        X_data = vec.transform(X.tolist()).toarray()\n    except:\n        X_data = vec.transform(X.tolist())\n    y_data = y\n    # divida massa em folds\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n    if grid != None:\n        # faz o gridsearch\n        # uso F1 Macro como m\u00e9trica\n        clf = GridSearchCV(est,grid,scoring='f1_macro',n_jobs=-1,cv=n_splits,verbose=100)\n        clf.fit(X_data,y_data)\n        estimator = clf.best_estimator_\n    else:\n        estimator = est\n        class DummyCLF: best_params_ = {}\n        clf = DummyCLF() \n    # faz validacao cruzada com kfold\n    for fold, (tr_idx, ts_idx) in enumerate(kf.split(X_data,y_data)):\n        # separa massas de treino\/teste\n        X_tr, X_ts = X_data[tr_idx], X_data[ts_idx]\n        y_tr, y_ts = y_data[tr_idx], y_data[ts_idx]\n        if fit:\n            # treina\n            estimator.fit(X_tr, y_tr)\n        # avalia a performance\n        y_pr = estimator.predict(X_ts)\n        accuracy, precision, recall, f1 = get_metrics(y_ts, y_pr)\n        scores_accuracy.append(accuracy)\n        scores_precision.append(precision)\n        scores_recall.append(recall)\n        scores_f1.append(f1)\n\n    # obt\u00e9m as m\u00e9tricas de desempenho - o quanto nosso classificador acertou?\n    accuracy = sum(scores_accuracy) \/ len(scores_accuracy);\n    precision = sum(scores_precision) \/ len(scores_precision);\n    recall = sum(scores_recall) \/ len(scores_recall);\n    f1 = sum(scores_f1) \/ len(scores_f1);\n\n    return estimator, est_name, vec_name, accuracy, precision, recall, f1, clf.best_params_","0216b0d8":"bots = [\n    {'id':0, 'nome':'Nenhum'},\n    {'id':1, 'nome':'Alistamento Militar'},\n    {'id':2, 'nome':'COVID'},\n    {'id':3, 'nome':'Login \u00danico'},\n    {'id':4, 'nome':'IRPF - Pergunt\u00e3o 2020'},\n    {'id':5, 'nome':'PGMEI - Programa Gerador de DAS do Microempreendedor Individual'},\n    {'id':6, 'nome':'POC Selo Turismo Respons\u00e1vel'},\n    {'id':7, 'nome':'Cadastur - Cadastro dos Prestadores de Servi\u00e7os Tur\u00edsticos'},\n    {'id':8, 'nome':'Tuberculose'}\n]","e434d32a":"# Matriz de palavras-chave\n#\n# ordem: prioridade de avalia\u00e7\u00e3o\n# quaisquer palavras dentro de 'palavras' servem para classificar\n# palavras em MAI\u00daSCULO s\u00e3o avaliadas da forma como s\u00e3o (sem flex\u00e3o)\n# palavras em min\u00fasculo s\u00e3o flexionadas (exemplo: 'declarar' => 'declar')\n# express\u00f5es com mais de uma palavra, separadas por espa\u00e7o, s\u00e3o avaliadas em conjunto (\u00e9 necess\u00e1rio encontrar TODAS palavras-chave da express\u00e3o para classificar)\nkeywords = [\n    {'id': 0, 'palavras': [ # Assuntos n\u00e3o-relacionados: LGPD, INSS, Elei\u00e7\u00f5es, Tr\u00e2nsito\/Detran\n        'LGPD',\n        'PROVA VIDA',\n        'TITULO eleitor','eleitor','votar','URNA','TRE','TSE',\n        'DETRAN','DENATRAN','CNH','CARTEIRA MOTORISTA','CARTEIRA HABILITACAO','primeira HABILITACAO','HABILITACAO PROVISORIA','CARTEIRA PROVISORIA',\n        'AUTO ESCOLA','RENAVAM','RENACH','AGENTE TRANSITO','aula pratica','dirigir','condutor'\n    ]},\n    {'id': 1, 'palavras': [ # Alistamento Militar\n        'alistamento','militar','EXERCITO','AERONAUTICA','MARINHA','FORCAS ARMADAS','FORCA servir','FORCA aerea','reservista','CTSM','juramento BANDEIRA',\n        'INCORPORACAO','CERTIFICADO DISPENSA','EXCESSO CONTINGENTE','SELECAO GERAL','CPOR','NPOR','CRDI','CERTIDAO REGISTRO DADOS INDIVIDUAIS',\n        'SELECAO dispensa','documento dispensa','TIRO GUERRA','TG'\n    ]},\n    {'id': 6, 'palavras': [ # Selo Turismo Respons\u00e1vel\n        'SELO turismo','SELO responsavel','SELO servico','SELO declarar','SELO higiene','SELO empreendimento','SELO atividade','SELO estabelecimento',\n        'SELO cadastro','SELO EMBRATUR','SELO CADASTUR','turismo RESPONSAVEL'\n    ]},\n    {'id': 7, 'palavras': [ # Cadastur\n        'CADASTUR','EMBRATUR','servico turismo','GUIA turismo'\n    ]},\n    {'id': 3, 'palavras': [ # Login \u00danico\n        'LOGIN','LOGIN UNICO','CADASTRO UNICO','SENHA PROVISORIA'\n    ]},\n    {'id': 5, 'palavras': [ # PGMEI\n        'ICMS','IPI','ISS','GUIA DAS','gerar DAS','imprimir DAS'\n    ]},\n    {'id': 4, 'palavras': [ # IRPF 2020\n        'DIRPF','IRPF','RFB','SRF','GCAP','ECAC','CAC','DARF','MAED','IMPOSTO','RENDA','RERCT','PESSOA FISICA','RECEITA FEDERAL','DEPENDENTE','DEPENDENTES',\n        'restituir','declarar','isento','isencao','isencoes','deduzir','deducao','deducoes','dedutivel','abater',\n        'entregar DECLARACAO','entregar IRPF','entregar IMPOSTO','dispensa entregar',\n        'PRAZO estendido','PRAZO prorrogar','PRAZO adiar','PRAZO entregar','ATRASO entregar','PRAZO OUTRO PAIS','PRAZO FORA PAIS',\n        'CARNE LEAO','GANHO CAPITAL','valor BENS','valor BEM','relacionar BENS','SAIDA DEFINITIVA','PROGRAMA GERADOR IR','IMPOSTO FONTE','MALHA FINA','atividade RURAL',\n        'rendimentos recebidos ACUMULADAMENTE','NUMERO RECIBO','RECIBO ENTREGA','patrimonio','pagamento operadora','fonte pagadora',\n        'valor doacao','valor doacoes','limite doacao','limite doacoes','despesa instrucao','despesa educacao','despesa medica','despesa saude',\n        'desconto empregada','desconto diarista','rendimento','valor propriedade','retificar valor','retificar declaracao','valor recebido'\n    ]},\n    {'id': 5, 'palavras': [ # PGMEI\n        'PGMEI','MEI','microempreendedor','SISMEI','DASN','CNAE','NOME FANTASIA','EMPREENDEDOR INDIVIDUAL'\n    ]},\n    {'id': 2, 'palavras': [ # COVID-19\n        'COVID','CORONA','CORONAVIRUS','PANDEMIA','comorbidade',\n        'distancia contaminar','distancia contagio','distancia SOCIAL','ALCOOL GEL'\n    ]},\n    {'id': 8, 'palavras': [ # Tuberculose\n        'tuberculose','BACILO','KOCH','bacteria pulmonar'\n    ]},\n    {'id': 2, 'palavras': [ # COVID-19\n        'risco','china','MASCARA','lavar embalagem'\n    ]},\n    {'id': 0, 'palavras': [ # Assuntos n\u00e3o-relacionados: INSS, AIDS, Dengue, Lombriga, Hipertens\u00e3o, Ansiedade\n        'INSS','aposentar','grupo TRANSICAO','regra TRANSICAO',\n        'HIV','AIDS','ATO SEXUAL','IMUNODEFICIENCIA',\n        'DENGUE','MOSQUITO',\n        'lombriga','verme',\n        'PRESSAO ALTA','hipertenso','PRESSAO ARTERIAL',\n        'ANSIEDADE'\n    ]},\n    {'id': 2, 'palavras': [ # COVID-19\n        'virus','contaminar','contagio','infectar'\n    ]},\n    {'id': 3, 'palavras': [ # Login \u00danico\n        'SENHA','LOGAR','TERMO USO','GOV BR','PORTAL GOVERNO','PORTAL servico',\n        'DADOS apagar','DADOS remover','DADOS bloquear','DADOS desautorizar','DADOS desativar','DADOS utilizacao','DADOS PESSOAIS','autorizar DADOS'\n    ]},\n    {'id': 6, 'palavras': [ # Selo Turismo Respons\u00e1vel\n        'SELO','SELOS','hospedagem','resort','pousada','hotel','HOTEIS','albergue',\n        'turismo protocolo','viagem protocolo','empreendimento protocolo','servico protocolo','ANVISA protocolo','MTUR protocolo','DESTINO SEGURO',\n        'higiene','sanitarias',\n        'CGU','CONTROLADORIA GERAL UNIAO'\n    ]},\n    {'id': 1, 'palavras': [ # Alistamento Militar\n        'ARRIMO','SOLDO','dispensa'\n    ]},\n    {'id': 7, 'palavras': [ # Cadastur\n        'MARCA promocao','MARCA promover','MARCA divulgar','MARCA evento','USO MARCA','USAR MARCA'\n    ]},\n    \n    {'id':-1, 'palavras': []}, # Representa registro sem classifica\u00e7\u00e3o\n]","e042282c":"random_state=112020","244c29de":"# Tokenizador: utilizado para separar uma frase em palavras.\ntokenizer = RegexpTokenizer(r'\\w+')\n\n# stopwords do portugu\u00eas\nstopwords = nltk.corpus.stopwords.words('portuguese')\n\n# retira keywords da lista de stopwords\nfor item in keywords:\n    for phrase in item['palavras']:\n        for keyword in phrase.split():\n            kword = keyword.strip().lower()\n            if kword in stopwords:\n                stopwords.remove(kword)\n","8469f67c":"# Caminho dos arquivos de entrada\ninput_path = '..\/input\/desafio-ia-2020-pln-chatbots\/'\n\n# Caminho dos arquivos de sa\u00edda\noutput_path = '..\/working\/'\n\n# Nome do arquivo CSV onde est\u00e3o armazenadas as perguntas rotuladas, para treino e teste.\narquivo_treino_testes = input_path + 'treino_testes.csv'\n\n# Nome do arquivo CSV onde ser\u00e3o armazenadas as perguntas n\u00e3o rotuladas, para classifica\u00e7\u00e3o e submiss\u00e3o.\n# Cada pergunta aqui conter\u00e1 um identificador que dever\u00e1 ser mantido.\narquivo_submissao = input_path + 'submissao.csv'\n\n# Nome do arquivo que ser\u00e1 criado com os r\u00f3tulos gerados pelo classificador.\n# Este \u00e9 o arquivo que ser\u00e1 submetido \u00e0 p\u00e1gina do desafio e que gerar\u00e1 um score.\n# Ele dever\u00e1 conter apenas os identificadores das perguntas e os identificadores dos respectivos bots.\narquivo_submissao_classificado = output_path + 'submissao_equipe_{}.csv'\n\n# Nome do arquivo CSV de dados de submiss\u00e3o processados, para depura\u00e7\u00e3o\narquivo_dados_processados = output_path + 'processado_{}.csv'\n\n# Nome do arquivo CSV de dados classificados por keywords, para depura\u00e7\u00e3o\narquivo_dados_classificados = output_path + 'classificado_{}.csv'\n\n# Nome do arquivo CSV de dados n\u00e3o-classificados por keywords, para depura\u00e7\u00e3o\narquivo_dados_nao_classificados = output_path + 'nao_classificado_{}.csv'\n","56dca3b3":"# Apaga arquivos CSV de sess\u00f5es anteriores no diret\u00f3rio de sa\u00edda\nimport os\nfrom os import walk\n\nfor (dirpath, dirnames, filenames) in walk(output_path):\n    for filename in filenames:\n        if filename.endswith('.csv'):\n            os.remove(output_path + filename)\n            print(f'delete: {filename} ok.')","9831bf0e":"# Carrega o arquivo CSV\ndf = pd.read_csv(arquivo_treino_testes, index_col=None, engine='python', sep =',', encoding=\"utf-8\")\nprint('Total de registros carregados:',len(df))\n\n# Exibe uma amostra dos dados carregados\ndf.tail(-1)","540aa64c":"# Distribui\u00e7\u00e3o das classes nos dados fornecidos. Note que n\u00e3o h\u00e1 nenhum pergunta rotulada como \"0\".\ndf.bot_id.value_counts()","1c7b75fb":"# Carrega o arquivo CSV\ndf_subm = pd.read_csv(arquivo_submissao, index_col=None, engine='python', sep =',', encoding=\"utf-8\")\nprint('Total de registros carregados:',len(df))\n\n# Exibe uma amostra dos dados carregados\ndf_subm.tail(-1)","af401dac":"# Limpa os dados, preparando-os para classifica\u00e7\u00e3o.\ndf['pergunta_original'] = df['pergunta']\ndf['pergunta'] = df['pergunta'].apply(limpar_texto)\ndf.tail(-1)","c30fc040":"# Limpa os dados, preparando-os para classifica\u00e7\u00e3o.\ndf_subm['pergunta_original'] = df_subm['pergunta']\ndf_subm['pergunta'] = df_subm['pergunta'].apply(limpar_texto)\ndf_subm.tail(-1)","bdf4e254":"tfidfVectorizer = TfidfVectorizer()\ntfidfVectorizer.fit_transform(df['pergunta'].tolist())","7351987c":"# Combina\u00e7\u00f5es de classificador\/vetorizador\n# Vetorizador TfidfVectorizer\nestimators = [\n  {'est': LinearSVC(), \n   'grid':{\n       'random_state':[random_state],\n       'C':[1],\n   },\n   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n  {'est': SVC(), \n   'grid':{\n       'random_state':[random_state],\n       'C':[10],\n       'gamma':[1],\n       'kernel':['linear'],\n   },\n   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n  {'est': SGDClassifier(), \n   'grid':{\n       'random_state':[random_state],\n       'max_iter':[10000],\n       'loss': ['modified_huber'],\n       'class_weight':[None],\n       'tol':[1e-3],\n   },\n   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n#  {'est': ComplementNB(), \n#   'grid':{\n#       'norm':[True],\n#       'alpha':[1.3],\n#   },\n#   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n#  {'est': LogisticRegression(), \n#   'grid':{\n#       'random_state':[random_state],\n#       'max_iter':[10000],\n#   },\n#   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n#  {'est': XGBClassifier(), \n#   'grid':{ \n#      'random_state': [random_state],\n#      'nthread':[4],\n#      'objective':['reg:squarederror'],\n#      'learning_rate': [.03],\n#      'max_depth': [8],\n#      'min_child_weight': [4],\n#      'subsample': [.7],\n#      'colsample_bytree': [.7],\n#      'n_estimators': [80],\n#   },\n#   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n#  {'est': CatBoostClassifier(), \n#   'grid':{ \n#      'random_state':[random_state],\n#      'iterations':[100],\n#      'silent':[False],\n#      'learning_rate': [.03],\n#   },\n#   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n#  {'est': NearestCentroid(), \n#   'grid':{ \n#      'metric': ['euclidean'], \n#      'shrink_threshold': [None],\n#   },\n#   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n#  {'est': DecisionTreeClassifier(), \n#   'grid':{ \n#      'random_state':[random_state],\n#   },\n#   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n]","0181b434":"%%time\n# Treina\/testa classificador\/vetorizador\nn_splits = 5\nfor estimator in estimators:\n    estimator['est'], estimator['est_name'], estimator['vec_name'], estimator['accurracy'], estimator['precision'], estimator['recall'], estimator['f1'], estimator['params'] = build(df['pergunta'],df['bot_id'],estimator['vec'],estimator['est'],estimator['grid'],n_splits)\n","74136bb4":"# Sele\u00e7\u00e3o do melhor classificador\/vetorizador\ndef get_f1(estimator):\n    return estimator.get('f1')\n\nestimators.sort(key=get_f1, reverse=True)\n\nfor estimator in estimators:\n    e_name, v_name, f1, acc, prec, rc, e_params = estimator['est_name'], estimator['vec_name'], round(estimator['f1'],4), round(estimator['accurracy'],4), round(estimator['precision'],4), round(estimator['recall'],4), estimator['params']\n    print(f\"{e_name} - {v_name} - F1: {f1}, Acc: {acc}, Prec: {prec}, Rec: {rc} - Params: {e_params}\")\n\n# escolhe melhor classificador\/vetorizador\nclf = estimators[0]['est']\nvectorizer = estimators[0]['vec']\nprint('\\nSelecionado: ',estimators[0]['est_name'],'-',estimators[0]['vec_name'])","b66add00":"# escolhe manualmente classificador\/vetorizador\n#index = 1\n#clf = estimators[index]['est']\n#vectorizer = estimators[index]['vec']\n#print('\\nSelecionado: ',estimators[index]['est_name'],'-',estimators[index]['vec_name'])","5b2ca231":"%%time\n# Treina o classificador KeywordClassifier\ndummyVectorizer = DummyVectorizer()\nkwClassifier = KeywordClassifier()\ndf_keywords = pd.DataFrame(keywords,columns=['id','palavras'])\n\nX_train = dummyVectorizer.transform(df_keywords['palavras'].tolist())\ny_train = df_keywords['id']\nkwClassifier.fit(X_train, y_train)","498c34ff":"%%time\n# Testa performance do classificador\/vetorizador\nn_splits = 5\ne, e_name, v_name, acc, prec, rc, f1, e_params = build(df['pergunta'],df['bot_id'],dummyVectorizer,kwClassifier,None,n_splits,False)\n\nprint(f\"{e_name} - {v_name} - F1: {round(f1,4)}, Acc: {round(acc,4)}, Prec: {round(prec,4)}, Rec: {round(rc,4)} - Params: {e_params}\")","614ae66f":"%%time\n# Classifica registros se encontrar palavras-chave correspondentes\nX_test = dummyVectorizer.transform(df_subm['pergunta'].tolist())\ny_predicted = kwClassifier.predict(X_test)\ndf_subm['bot_id'] = y_predicted\n\n# Reordena registros\ndf_subm.sort_values('bot_id',inplace=True)\ndf_subm.reset_index(inplace=True,drop=True)\n\n# Nomeia registros para facilitar depuracao\ndf_subm['bot_nome'] = ''\nfor i in df_subm.index:\n    if df_subm['bot_id'][i] != -1:\n        df_subm['bot_nome'][i] = bots[df_subm['bot_id'][i]]['nome']\n# Exibe registros\ndf_subm.head(-1)","35009640":"# salva registros dos dados classificados, para an\u00e1lise\ndf_test = df_subm[df_subm['bot_id'] != -1]\ndf_test.to_csv(arquivo_dados_classificados.format((datetime.now() - timedelta(hours=3)).strftime('%Y-%m-%d_%H-%M-%S')), index=False, encoding=\"utf-8\", columns=['id','pergunta_original','bot_id','bot_nome'])\n\n# salva registros dos dados n\u00e3o-classificados, para an\u00e1lise\ndf_test = df_subm[df_subm['bot_id'] == -1]\ndf_test.to_csv(arquivo_dados_nao_classificados.format((datetime.now() - timedelta(hours=3)).strftime('%Y-%m-%d_%H-%M-%S')), index=False, encoding=\"utf-8\", columns=['id','pergunta_original','pergunta'])","a0eead26":"%%time\n# Treina o classificador com toda a base fornecida.\nX_train = vectorizer.transform(df['pergunta'].tolist()).toarray()\ny_train =  df['bot_id']\nclf.fit(X_train, y_train)","cf1b1f6e":"# Vetoriza os textos que ser\u00e3o classificados.\n# Somente os que j\u00e1 n\u00e3o foram classificados anteriormente\ndf_test = df_subm[df_subm['bot_id'] == -1]\nX_test = vectorizer.transform(df_test['pergunta'].tolist()).toarray()","c6d10f6c":"# Executa a classifica\u00e7\u00e3o dos registros n\u00e3o rotulados.\n# Somente os que j\u00e1 n\u00e3o foram classificados anteriormente\ny_predicted = clf.predict(X_test)\ndf_test['bot_id'] = y_predicted\nfor i in df_test.index:\n    df_subm['bot_id'][i] = df_test['bot_id'][i]\n\n# Nomeia registros para facilitar depuracao\ndf_subm['bot_nome'] = ''\nfor i in df_subm.index:\n    df_subm['bot_nome'][i] = bots[df_subm['bot_id'][i]]['nome']\n# Exibe registros\ndf_subm.head(-1)","b240d29d":"# Gera matriz de probabilidades\ny_proba = []\ntry:\n    y_proba = clf.predict_proba(X_test)\nexcept:\n    try:\n        y_proba = clf.decision_function(X_test)\n    except:\n        pass\n\ndf_proba = pd.DataFrame()   \n\nif len(y_proba) > 0:\n    df_proba = pd.DataFrame(y_proba,columns=[1,2,3,4,5,6,7,8])\n    # normaliza para 0..1\n    pmin = df_proba.min().min()\n    pmax = df_proba.max().max()\n    df_proba = (df_proba - pmin) \/ (pmax - pmin)\n    probas = []\n    for i in df_proba.index:\n        # pega a dist\u00e2ncia entre min e max\n        n = [df_proba.iloc[i].min(), df_proba.iloc[i].max()]\n        proba = abs(n[1] - n[0])\n        probas.append(proba)\n    df_proba = pd.concat([df_proba,pd.DataFrame(probas,columns=['proba'])],axis=1)\n    \n# Exibe matriz\ndf_proba.head(-1)","f63e2f1a":"# Corrige classificacao de baixa probabilidade\n# Provavelmente, esses registros pertencem a classe Nenhum (0)\n\n# considerei um valor de probabilidade m\u00ednimo aceit\u00e1vel\nproba_min = 0.2\ndf_subm['proba'] = df_proba['proba']\nbid_zero = bots[0]['id'] # classe zero\ncount = 0\nfor i in df_proba.index:\n    proba = df_proba['proba'][i]\n    if proba < proba_min: \n        df_subm['bot_id'][i] = bid_zero\n        count = count + 1\n\nprint(f'Desclassificados {count}\/{len(df_subm.index)} registros com probabilidade abaixo de {proba_min*100.0}%.')\ndf_subm['proba'] = df_subm['proba'].fillna(1.0) # preenche NaN com 1.0","e1df288d":"# Nomeia registros para facilitar depuracao\ndf_subm['bot_nome'] = ''\nfor i in df_subm.index:\n    df_subm['bot_nome'][i] = bots[df_subm['bot_id'][i]]['nome']\n# Exibe registros\ndf_subm.head(-1)","2adc3719":"# salva registros dos dados processados, para an\u00e1lise\ndf_subm.to_csv(arquivo_dados_processados.format((datetime.now() - timedelta(hours=3)).strftime('%Y-%m-%d_%H-%M-%S')), index=False, encoding=\"utf-8\")","2f24e1b6":"# salva registros classificados\ndf_subm.to_csv(arquivo_submissao_classificado.format((datetime.now() - timedelta(hours=3)).strftime('%Y-%m-%d_%H-%M-%S')), index=False, encoding=\"utf-8\", columns=['id','bot_id'])","01d896b1":"# Escolher um modelo preditivo, treinar e testar o modelo\n","df8f3b59":"### DummyVectorizer\n\nVetorizador \"dummy\": n\u00e3o realiza nenhuma transforma\u00e7\u00e3o de dados. Mant\u00e9m apenas a interface de um vetorizador b\u00e1sico, padr\u00e3o do sklearn.","c7c7b194":"# Preparar os textos para classifica\u00e7\u00e3o\n\nA prepara\u00e7\u00e3o dos dados \u00e9 uma das etapas mais importantes para se obter uma boa performance na classifica\u00e7\u00e3o de textos, e pode significar a diferen\u00e7a entre o sucesso e o fracasso de um projeto.","ef5931e5":"# Carregar os dados de treino e teste\n\nCarrega os dados do arquivo CSV com as perguntas rotuladas com os *ids* dos bots aos quais pertencem. Os r\u00f3tulos variam de **1** a **8**, como pode ser conferido na lista de bots definida na se\u00e7\u00e3o **inicializa\u00e7\u00e3o**. Estas perguntas ser\u00e3o usadas para treinamento e teste do(s) classificador(es).\n\nTodas as perguntas deste arquivo est\u00e3o relacionadas a um (e apenas um) dos bots listados acima. Ou seja, n\u00e3o h\u00e1 nenhuma pergunta rotulada como **0** (zero). Este tipo de pergunta (n\u00e3o relacionada a nenhum dos bots) aparecer\u00e1 **apenas no arquivo de submiss\u00e3o**.","222bdddd":"### Gera matriz de probabilidades\n\nA matriz de probabilidades permite avaliar o quanto o estimador acertou a classifica\u00e7\u00e3o de cada amostra, e assim, invalidar o resultado para classifica\u00e7\u00f5es de baixa probabilidade (provavelmente deveriam ser da classe 0, 'Nenhum')","69958163":"### Dados de treino\/teste","689193ec":"### Semente Aleat\u00f3ria\n\nSemente aleat\u00f3ria a ser usada ao longo desse notebook.\n\nProcure manter sempre a mesma semente aleat\u00f3ria (ou sementes aleat\u00f3rias, caso utilize mais de uma). Deste modo, poder\u00e1 comparar a evolu\u00e7\u00e3o entre diferentes t\u00e9cnicas e tamb\u00e9m obter a reprodutibilidade exigida pelo regulamento do desafio.\n\nO valor da semente abaixo \u00e9 apenas ilustrativo, fique \u00e0 vontade para alter\u00e1-lo.","249197fc":"# Classes","c23f0af9":"# Obter um vetorizador\nNessa etapa, vamos obter um *vetorizador*. Seu objetivo \u00e9 converter os textos em **vetores num\u00e9ricos**, para ent\u00e3o submet\u00ea-los aos algoritmos de classifica\u00e7\u00e3o.","671482cf":"# Salvar os registros classificados.\n\nApenas os identificadores das perguntas e os identificadores dos respectivos bots devem armazenados!","24adcda2":"# Bibliotecas utilizadas","034188df":"## Download de M\u00f3dulos","deebf9de":"### Dados de Treino e Teste","c1a37510":"# Submeter os resultados \u00e0 p\u00e1gina do desafio\n\nEntre na p\u00e1gina do desafio e fa\u00e7a o upload do arquivo *csv* obtido acima, com as classifica\u00e7\u00f5es realizadas pelo seu modelo. Esse arquivo deve conter apenas as colunas \"*id*\" e \"*id_bot*\". O site ir\u00e1 calcular automaticamente sua m\u00e9trica de acerto.\n\nSe o score obtido estiver nas tr\u00eas primeiras posi\u00e7\u00f5es, fa\u00e7a um versionamento do c\u00f3digo. Se esta posi\u00e7\u00e3o se mantiver at\u00e9 o final da competi\u00e7\u00e3o, ele ser\u00e1 auditado para verifica\u00e7\u00e3o de reprodutibilidade.\n\nVoc\u00ea pode fazer quantas tentativas desejar, at\u00e9 atingir um limite di\u00e1rio (consulte o regulamento). Use isso para melhorar suas m\u00e9tricas.","111cf031":"### Classifica\u00e7\u00e3o por palavras-chave\n\nEste tipo de classifica\u00e7\u00e3o visa melhorar a performance do estimador quando uma frase possui uma palavra-chave que define j\u00e1 classe automaticamente.","dc92bd01":"### Elementos de NLP","a4d8e8dc":"### Chatbots Dispon\u00edvels para Treinamento\n\nA seguir a rela\u00e7\u00e3o dos chatbots disponibilizados para o desafio.\n\nO \"*id*\"  \u00e9 o identificador do chatbot. Ele est\u00e1 expl\u00edcito aqui para evitar quaisquer d\u00favidas. O(s) classificador(es) deve(m) ser treinado(s) usando **ESTES** identificadores espec\u00edficos. \n\nO identificador **0** (zero) dever\u00e1 ser atribu\u00eddo \u00e0s perguntas que forem consideradas como **n\u00e3o** direcionadas a nenhum dos bots abaixo. Isso visa simular um ambiente real de orquestra\u00e7\u00e3o, onde esse tipo de situa\u00e7\u00e3o ocorre com frequ\u00eancia. Tais perguntas existir\u00e3o apenas no arquivo de submiss\u00e3o, sem r\u00f3tulos.","cd956a0a":"# Desafio PLN e Chatbots - SERPRO\n\n**P\u00e1gina do Desafio:** [https:\/\/www.kaggle.com\/c\/desafio-ia-2020-pln-chatbots\/overview](https:\/\/www.kaggle.com\/c\/desafio-ia-2020-pln-chatbots\/overview)\n\n---\n### Skynet\n\nRobson de Sousa Martins<br>\n[https:\/\/www.robsonmartins.com](https:\/\/www.robsonmartins.com)\n\n___\n\nEste desafio foi solucionado com a implementa\u00e7\u00e3o da classifica\u00e7\u00e3o das frases (perguntas de chatbot) em tr\u00eas etapas:\n\n1. **Pr\u00e9-classifica\u00e7\u00e3o das frases por palavras-chave**: Nesta etapa, as frases s\u00e3o classificadas atrav\u00e9s de compara\u00e7\u00e3o de suas palavras com um banco de palavras-chave prestabelecido. Assim, j\u00e1 s\u00e3o identificadas frases de assuntos n\u00e3o-relacionados aos grupos de bots sugeridos (e classificadas como `0: Nenhum`), e frases de assuntos amplamente conhecidos, como por exemplo as que cont\u00e9m a palavra `COVID-19` (classe `2: Covid`).\n\n2. **Classifica\u00e7\u00e3o das frases restantes atrav\u00e9s de algoritmo**: Nessa fase, um algoritmo de classifica\u00e7\u00e3o \u00e9 selecionado, e realiza a classifica\u00e7\u00e3o das frases restantes, baseado no aprendizado realizado com a massa de dados de treino.\n\n3. **Remo\u00e7\u00e3o de classifica\u00e7\u00e3o de baixa probabilidade**: Frases classificadas com probabilidade mais baixa que um n\u00famero m\u00ednimo definido, s\u00e3o desclassificadas, ou seja, clasificadas para `0: Nenhum`. Isso elimina alguns dos equ\u00edvocos produzidos pelo algoritmo classificador e aumenta a qualidade do resultado.\n\n\n\u00c9 importante que o conjunto de palavras-chave seja bem escolhido para que reflita fortemente cada uma das classes\/assuntos propostos.\n\nPara este desafio, o classificador por palavras-chave foi implementado de maneira simples, sem realizar c\u00e1lculo probabil\u00edstico da frequ\u00eancia ou peso de palavras-chave (ou seja, se ele simplesmente encontrar a palavra-chave na primeira classe avaliada, atribui uma probabilidade de 1.0 ou 100%, sem avaliar as outras classes subsequentes).\n\nNuma aplica\u00e7\u00e3o real, o conjunto de palavras-chave poderia ser din\u00e2mico, atualizado periodicamente, alimentado por um banco de dados de palavras mais citadas por cada assunto, tal como numa nuvem de palavras, ou *trend topics* oriundos de um *data mining* de redes sociais, por exemplo.","2ca0ff7e":"### KeywordClassifier\n\nUm Classificador por palavras-chave (keywords). Este classificador foi construido com a mesma interface de um classificador do sklearn.\n\nO m\u00e9todo fit() recebe um array de palavras-chave e classes a que se referem, em ordem de prioridade.\nO m\u00e9todo predict() classifica frases de acordo com as palavras-chave treinadas com fit().\nUsa um stemmer de l\u00edngua portuguesa para corresponder palavras similares (com mesma raiz).","5c7332e8":"### Dados para submiss\u00e3o","906b22de":"### Dados de Submiss\u00e3o","073164a1":"### Nomes dos Arquivos Utilizados\n\nNomes dos arquivos que ser\u00e3o utilizados ao longo deste notebook.","09742d49":"### Palavras-chave\n\nAs palavras-chave fortemente relacionadas aos assuntos (classes) s\u00e3o uma boa fonte de dados para uma classifica\u00e7\u00e3o pr\u00e9via.","e7c26d74":"# Classificar os registros n\u00e3o rotulados para o desafio\n\nDe forma c\u00edclica, repita os passos acima testando outras prepara\u00e7\u00f5es de dados, outros vetorizadores, outros par\u00e2metros e outras t\u00e9cnicas de classifica\u00e7\u00e3o. Quando estiver satisfeito com a performance do seu modelo, siga os passos abaixo.\n\nVamos agora treinar o classificador com **todos** os registros pr\u00e9-rotulados. Este classificador ser\u00e1 ent\u00e3o utilizado para inferir os bots das perguntas n\u00e3o rotuladas do desafio, como veremos a seguir.","7ba840f9":"# Inicializa\u00e7\u00e3o","27832063":"# Fun\u00e7\u00f5es"}}