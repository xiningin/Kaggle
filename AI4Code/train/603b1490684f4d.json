{"cell_type":{"b69f1a28":"code","88374c44":"code","2feaec39":"code","87584320":"code","ced84bec":"code","8aef3ea1":"code","dc535a91":"code","47a372b7":"code","b990386d":"code","84dc5f75":"code","42cebc8c":"code","8d84d832":"code","bc5fc682":"code","d61bdf96":"code","853765e4":"code","593a4e3b":"code","d8df6da8":"code","faefb621":"code","b5cd8c45":"code","cd00e1ae":"code","23201837":"code","1d1d8262":"code","402f5e6d":"code","203f5a7e":"code","81199520":"code","39d9d34c":"code","c0774595":"code","25939ad6":"code","f434acac":"code","77a4a651":"code","77d80805":"code","168b139e":"code","69e34355":"code","735a1278":"code","a15eb000":"code","23672d05":"code","ce84cff9":"code","fbd52803":"code","4b4e2ba9":"code","c449dac4":"code","4aeeaf2a":"code","d24f4970":"code","fce9e184":"code","3d5d7a0d":"code","d09d4038":"code","de5eabcc":"code","494eeb55":"code","aa8b997e":"code","7c2a2aa3":"code","3b7bb50b":"code","c0dc797a":"code","67bbac9a":"code","6362e127":"code","12dee631":"code","d7bc89f0":"markdown","22c87433":"markdown","459ba4d9":"markdown","4b6686bd":"markdown","0900556c":"markdown","a682ea10":"markdown","57ff1a93":"markdown","a07dd18a":"markdown","e4be8183":"markdown","fd930a17":"markdown","86586b14":"markdown","788a700f":"markdown","ebf55fe6":"markdown","cefe255f":"markdown","c3257651":"markdown","0b3c2576":"markdown","7c8848bd":"markdown","0191e8c6":"markdown","71b00b3d":"markdown","30f8d57b":"markdown","55477b85":"markdown","ddd24b64":"markdown","53dc83c4":"markdown","e1eb979c":"markdown","839c3d2e":"markdown","1e6c8247":"markdown","c4334d7c":"markdown","0165eacb":"markdown","0d3e3c4d":"markdown","6ebf6109":"markdown","768d4284":"markdown","6377b45f":"markdown","1ec02165":"markdown"},"source":{"b69f1a28":"# Basic imports for the entire Kernel\nimport numpy as np\nimport pandas as pd","88374c44":"# import mask function\nimport sys\nsys.path.insert(0, '..\/input\/siim-acr-pneumothorax-segmentation')\nfrom mask_functions import rle2mask, mask2rle","2feaec39":"# imports for loading data\nimport pydicom\nfrom glob import glob\nfrom tqdm import tqdm","87584320":"# load rles\nrles_df = pd.read_csv('..\/input\/siim-train-test\/siim\/train-rle.csv')\n# the second column has a space at the start, so manually giving column name\nrles_df.columns = ['ImageId', 'EncodedPixels']","ced84bec":"def dicom_to_dict(dicom_data, file_path, rles_df, encoded_pixels=True):\n    \"\"\"Parse DICOM dataset and returns a dictonary with relevant fields.\n\n    Args:\n        dicom_data (dicom): chest x-ray data in dicom format.\n        file_path (str): file path of the dicom data.\n        rles_df (pandas.core.frame.DataFrame): Pandas dataframe of the RLE.\n        encoded_pixels (bool): if True we will search for annotation.\n        \n    Returns:\n        dict: contains metadata of relevant fields.\n    \"\"\"\n    \n    data = {}\n    \n    # Parse fields with meaningful information\n    data['patient_name'] = dicom_data.PatientName\n    data['patient_id'] = dicom_data.PatientID\n    data['patient_age'] = int(dicom_data.PatientAge)\n    data['patient_sex'] = dicom_data.PatientSex\n    data['pixel_spacing'] = dicom_data.PixelSpacing\n    data['file_path'] = file_path\n    data['id'] = dicom_data.SOPInstanceUID\n    \n    # look for annotation if enabled (train set)\n    if encoded_pixels:\n        encoded_pixels_list = rles_df[rles_df['ImageId']==dicom_data.SOPInstanceUID]['EncodedPixels'].values\n       \n        pneumothorax = False\n        for encoded_pixels in encoded_pixels_list:\n            if encoded_pixels != ' -1':\n                pneumothorax = True\n        \n        # get meaningful information (for train set)\n        data['encoded_pixels_list'] = encoded_pixels_list\n        data['has_pneumothorax'] = pneumothorax\n        data['encoded_pixels_count'] = len(encoded_pixels_list)\n        \n    return data","8aef3ea1":"# create a list of all the files\ntrain_fns = sorted(glob('..\/input\/siim-train-test\/siim\/dicom-images-train\/*\/*\/*.dcm'))\n# parse train DICOM dataset\ntrain_metadata_df = pd.DataFrame()\ntrain_metadata_list = []\nfor file_path in tqdm(train_fns):\n    dicom_data = pydicom.dcmread(file_path)\n    train_metadata = dicom_to_dict(dicom_data, file_path, rles_df)\n    train_metadata_list.append(train_metadata)\ntrain_metadata_df = pd.DataFrame(train_metadata_list)","dc535a91":"# create a list of all the files\ntest_fns = sorted(glob('..\/input\/siim-train-test\/siim\/dicom-images-test\/*\/*\/*.dcm'))\n# parse test DICOM dataset\ntest_metadata_df = pd.DataFrame()\ntest_metadata_list = []\nfor file_path in tqdm(test_fns):\n    dicom_data = pydicom.dcmread(file_path)\n    test_metadata = dicom_to_dict(dicom_data, file_path, rles_df, encoded_pixels=False)\n    test_metadata_list.append(test_metadata)\ntest_metadata_df = pd.DataFrame(test_metadata_list)","47a372b7":"import matplotlib.pyplot as plt\nfrom matplotlib import patches as patches","b990386d":"num_img = 4\nsubplot_count = 0\nfig, ax = plt.subplots(nrows=1, ncols=num_img, sharey=True, figsize=(num_img*10,10))\nfor index, row in train_metadata_df.sample(n=num_img).iterrows():\n    dataset = pydicom.dcmread(row['file_path'])\n    ax[subplot_count].imshow(dataset.pixel_array, cmap=plt.cm.bone)\n    # label the x-ray with information about the patient\n    ax[subplot_count].text(0,0,'Age:{}, Sex: {}, Pneumothorax: {}'.format(row['patient_age'],row['patient_sex'],row['has_pneumothorax']),\n                           size=26,color='white', backgroundcolor='black')\n    subplot_count += 1","84dc5f75":"def bounding_box(img):\n    # return max and min of a mask to draw bounding box\n    rows = np.any(img, axis=1)\n    cols = np.any(img, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n\n    return rmin, rmax, cmin, cmax\n\ndef plot_with_mask_and_bbox(file_path, mask_encoded_list, figsize=(20,10)):\n    \n    import cv2\n    \n    \"\"\"Plot Chest Xray image with mask(annotation or label) and without mask.\n\n    Args:\n        file_path (str): file path of the dicom data.\n        mask_encoded (numpy.ndarray): Pandas dataframe of the RLE.\n        \n    Returns:\n        plots the image with and without mask.\n    \"\"\"\n    \n    pixel_array = pydicom.dcmread(file_path).pixel_array\n    \n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n    clahe_pixel_array = clahe.apply(pixel_array)\n    \n    # use the masking function to decode RLE\n    mask_decoded_list = [rle2mask(mask_encoded, 1024, 1024).T for mask_encoded in mask_encoded_list]\n    \n    fig, ax = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(20,10))\n    \n    # print out the xray\n    ax[0].imshow(pixel_array, cmap=plt.cm.bone)\n    # print the bounding box\n    for mask_decoded in mask_decoded_list:\n        # print out the annotated area\n        ax[0].imshow(mask_decoded, alpha=0.3, cmap=\"Reds\")\n        rmin, rmax, cmin, cmax = bounding_box(mask_decoded)\n        bbox = patches.Rectangle((cmin,rmin),cmax-cmin,rmax-rmin,linewidth=1,edgecolor='r',facecolor='none')\n        ax[0].add_patch(bbox)\n    ax[0].set_title('With Mask')\n    \n    # plot image with clahe processing with just bounding box and no mask\n    ax[1].imshow(clahe_pixel_array, cmap=plt.cm.bone)\n    for mask_decoded in mask_decoded_list:\n        rmin, rmax, cmin, cmax = bounding_box(mask_decoded)\n        bbox = patches.Rectangle((cmin,rmin),cmax-cmin,rmax-rmin,linewidth=1,edgecolor='r',facecolor='none')\n        ax[1].add_patch(bbox)\n    ax[1].set_title('Without Mask - Clahe')\n    \n    # plot plain xray with just bounding box and no mask\n    ax[2].imshow(pixel_array, cmap=plt.cm.bone)\n    for mask_decoded in mask_decoded_list:\n        rmin, rmax, cmin, cmax = bounding_box(mask_decoded)\n        bbox = patches.Rectangle((cmin,rmin),cmax-cmin,rmax-rmin,linewidth=1,edgecolor='r',facecolor='none')\n        ax[2].add_patch(bbox)\n    ax[2].set_title('Without Mask')\n    plt.show()","42cebc8c":"# lets take 10 random samples of x-rays with \ntrain_metadata_sample = train_metadata_df[train_metadata_df['has_pneumothorax']==1].sample(n=10)\n# plot ten xrays with and without mask\nfor index, row in train_metadata_sample.iterrows():\n    file_path = row['file_path']\n    mask_encoded_list = row['encoded_pixels_list']\n    print('image id: ' + row['id'])\n    plot_with_mask_and_bbox(file_path, mask_encoded_list)","8d84d832":"# plotly offline imports\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, iplot\nfrom plotly import tools\nfrom plotly.graph_objs import *\nfrom plotly.graph_objs.layout import Margin, YAxis, XAxis\ninit_notebook_mode()","bc5fc682":"# print missing annotation\nmissing_vals = train_metadata_df[train_metadata_df['encoded_pixels_count']==0]['encoded_pixels_count'].count()\nprint(\"Number of x-rays with missing labels: {}\".format(missing_vals))","d61bdf96":"nok_count = train_metadata_df['has_pneumothorax'].sum()\nok_count = len(train_metadata_df) - nok_count\nx = ['No Pneumothorax','Pneumothorax']\ny = [ok_count, nok_count]\ntrace0 = Bar(x=x, y=y, name = 'Ok vs Not OK')\nnok_encoded_pixels_count = train_metadata_df[train_metadata_df['has_pneumothorax']==1]['encoded_pixels_count'].values\ntrace1 = Histogram(x=nok_encoded_pixels_count, name='# of annotations')\nfig = tools.make_subplots(rows=1, cols=2)\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\nfig['layout'].update(height=400, width=900, title='Pneumothorax Instances')\niplot(fig)","853765e4":"pneumo_pat_age = train_metadata_df[train_metadata_df['has_pneumothorax']==1]['patient_age'].values\nno_pneumo_pat_age = train_metadata_df[train_metadata_df['has_pneumothorax']==0]['patient_age'].values","593a4e3b":"pneumothorax = Histogram(x=pneumo_pat_age, name='has pneumothorax')\nno_pneumothorax = Histogram(x=no_pneumo_pat_age, name='no pneumothorax')\nfig = tools.make_subplots(rows=1, cols=2)\nfig.append_trace(pneumothorax, 1, 1)\nfig.append_trace(no_pneumothorax, 1, 2)\nfig['layout'].update(height=400, width=900, title='Patient Age Histogram')\niplot(fig)","d8df6da8":"trace1 = Box(x=pneumo_pat_age, name='has pneumothorax')\ntrace2 = Box(x=no_pneumo_pat_age[no_pneumo_pat_age <= 120], name='no pneumothorax')\ndata = [trace1, trace2]\niplot(data)","faefb621":"train_male_df = train_metadata_df[train_metadata_df['patient_sex']=='M']\ntrain_female_df = train_metadata_df[train_metadata_df['patient_sex']=='F']","b5cd8c45":"male_ok_count = len(train_male_df[train_male_df['has_pneumothorax']==0])\nfemale_ok_count = len(train_female_df[train_female_df['has_pneumothorax']==0])\nmale_nok_count = len(train_male_df[train_male_df['has_pneumothorax']==1])\nfemale_nok_count = len(train_female_df[train_female_df['has_pneumothorax']==1])","cd00e1ae":"ok = Bar(x=['male', 'female'], y=[male_ok_count, female_ok_count], name='no pneumothorax')\nnok = Bar(x=['male', 'female'], y=[male_nok_count, female_nok_count], name='has pneumothorax')\n\ndata = [ok, nok]\nlayout = Layout(barmode='stack', height=400)\n\nfig = Figure(data=data, layout=layout)\niplot(fig, filename='stacked-bar')","23201837":"m_pneumo_labels = ['no pneumothorax','has pneumothorax']\nf_pneumo_labels = ['no pneumothorax','has pneumothorax']\nm_pneumo_values = [male_ok_count, male_nok_count]\nf_pneumo_values = [female_ok_count, female_nok_count]\ncolors = ['#FEBFB3', '#E1396C']","1d1d8262":"# original source code: https:\/\/plot.ly\/python\/pie-charts\/#donut-chart\n\nfig = {\n  \"data\": [\n    {\n      \"values\": m_pneumo_values,\n      \"labels\": m_pneumo_labels,\n      \"domain\": {\"column\": 0},\n      \"name\": \"Male\",\n      \"hoverinfo\":\"label+percent\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    },\n    {\n      \"values\": f_pneumo_values,\n      \"labels\": f_pneumo_labels,\n      \"textposition\":\"inside\",\n      \"domain\": {\"column\": 1},\n      \"name\": \"Female\",\n      \"hoverinfo\":\"label+percent\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    }],\n  \"layout\": {\n        \"title\":\"Pneumothorax - Male vs Female\",\n        \"grid\": {\"rows\": 1, \"columns\": 2},\n        \"annotations\": [\n            {\n                \"font\": {\n                    \"size\": 20\n                },\n                \"showarrow\": False,\n                \"text\": \"Male\",\n                \"x\": 0.20,\n                \"y\": 0.5\n            },\n            {\n                \"font\": {\n                    \"size\": 20\n                },\n                \"showarrow\": False,\n                \"text\": \"Female\",\n                \"x\": 0.8,\n                \"y\": 0.5\n            }\n        ]\n    }\n}\niplot(fig)","402f5e6d":"def get_affected_area(encoded_pixels_list, pixel_spacing):\n    \n    # take the encoded mask, decode, and get the sum of nonzero elements\n    pixel_sum = 0\n    \n    for encoded_mask in encoded_pixels_list:\n        mask_decoded = rle2mask(encoded_mask, 1024, 1024).T\n        pixel_sum += np.count_nonzero(mask_decoded)\n        \n    area_per_pixel = pixel_spacing[0] * pixel_spacing[1]\n    \n    return pixel_sum * area_per_pixel","203f5a7e":"# create a subset of dataframe for pneumothorax patients\npneumothorax_df = train_metadata_df[train_metadata_df['has_pneumothorax']==1].copy()\n# get sum of non zero elements in mask\npneumothorax_df['pneumothorax_area'] = pneumothorax_df.apply(lambda row: get_affected_area(row['encoded_pixels_list'], row['pixel_spacing']),axis=1)","81199520":"pneumothorax_df_m = pneumothorax_df[pneumothorax_df['patient_sex']=='M']\npneumothorax_df_f = pneumothorax_df[pneumothorax_df['patient_sex']=='F']\npneumo_size_m = pneumothorax_df_m['pneumothorax_area'].values\npneumo_size_f = pneumothorax_df_f['pneumothorax_area'].values","39d9d34c":"pneumo_size_m_trace = Box(x = pneumo_size_m, name='M')\npneumo_size_f_trace = Box(x = pneumo_size_f, name='F')\nlayout = Layout(title='Pneumothorax Affected Area for Male and Female Population', \n               xaxis = XAxis(title='Area (in sq mm)'))\n\ndata = [pneumo_size_m_trace, pneumo_size_f_trace]\nfig = Figure(data=data, layout=layout)\niplot(fig)","c0774595":"pneumo_size_m_trace = Scatter(x=pneumothorax_df_m['patient_age'].values, \n                              y=pneumothorax_df_m['pneumothorax_area'].values, \n                              mode='markers', name='Male')\n\npneumo_size_f_trace = Scatter(x=pneumothorax_df_f['patient_age'].values, \n                              y=pneumothorax_df_f['pneumothorax_area'].values, \n                              mode='markers', name='Female')\n\nlayout = Layout(title='Pneumothorax Affected Area vs Age for Male and Female Population', \n                yaxis=YAxis(title='Area (in sq mm)'), xaxis=XAxis(title='Age'))\n\ndata = [pneumo_size_m_trace, pneumo_size_f_trace]\nfig = Figure(data=data, layout=layout)\niplot(fig)","25939ad6":"size_m = pneumothorax_df_m['pneumothorax_area'].values\nsize_ref_m = 2.*max(size_m)\/(40.**2)\nsize_f = pneumothorax_df_f['pneumothorax_area'].values\nsize_ref_f = 2.*max(size_f)\/(40.**2)\n\npneumo_size_m_trace = Scatter(x=pneumothorax_df_m['patient_age'].values, \n                              y=pneumothorax_df_m['encoded_pixels_count'].values,\n                              marker=dict(size= size_m, sizemode='area', sizeref=size_ref_m, sizemin=4), \n                              mode='markers', name='Male')\n\npneumo_size_f_trace = Scatter(x=pneumothorax_df_f['patient_age'].values, \n                              y=pneumothorax_df_f['encoded_pixels_count'].values,\n                              marker=dict(size=size_f, sizemode='area', sizeref=size_ref_f, sizemin=4), \n                              mode='markers', name='Female')\n\nlayout = Layout(title='Pneumothorax Affected Area vs Age for Male and Female Population', yaxis=YAxis(title='Area (in sq mm)'), xaxis=XAxis(title='Age'))\n\ndata = [pneumo_size_m_trace, pneumo_size_f_trace]\nfig = Figure(data=data, layout=layout)\niplot(fig)","f434acac":"def age_categories(age):\n    # take age as input and return age category\n    if age <= 14:\n        return 'Child'\n    if age >=15 and age <= 24:\n        return 'Youth'\n    if age >=25 and age <=64:\n        return 'Adult'\n    if age >= 65:\n        return 'Senior'\n\n# get age categories\npneumothorax_df['age_category'] = pneumothorax_df['patient_age'].apply(age_categories)","77a4a651":"# here we loop over the different age categories and M and F genders to create a subplot\ndata = []\nfig = tools.make_subplots(rows=2, cols=2, subplot_titles=('Child','Youth','Adult','Senior'))\nsubplot_positions = [(1,1),(1,2),(2,1),(2,2)]\n\n# loop over each age category\nfor i, cat in enumerate(['Child','Youth','Adult','Senior']):\n    # and gender\n    for gender in ['M','F']:\n        # get affected area for given age group and gender\n        values = pneumothorax_df[(pneumothorax_df['patient_sex']==gender) \n                        & (pneumothorax_df['age_category']==cat)]['pneumothorax_area'].values\n        # add to the respective trace\n        trace = Box(x=values, name=gender)\n        # add to figure\n        fig.append_trace(trace, subplot_positions[i][0], subplot_positions[i][1])\n    ","77d80805":"fig['layout'].update(height=600, width=900, title='Pneumothorax Size in Different Age Categories', showlegend=False)\niplot(fig)","168b139e":"# defining configuration parameters\nimg_size = 512 # image resize size\nbatch_size = 16 # batch size for training unet\nk_size = 3 # kernel size 3x3\nval_size = .25 # split of training set between train and validation set\nno_pneumo_drop = 0 # dropping some data to balance the class a little bit better","69e34355":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate\nfrom sklearn.model_selection import train_test_split\nimport cv2","735a1278":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, file_path_list, labels, batch_size=32, \n                 img_size=256, channels=1, shuffle=True):\n        self.file_path_list = file_path_list\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.channels = channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n    \n    def __len__(self):\n        'denotes the number of batches per epoch'\n        return int(np.floor(len(self.file_path_list)) \/ self.batch_size)\n    \n    def __getitem__(self, index):\n        'generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # get list of IDs\n        file_path_list_temp = [self.file_path_list[k] for k in indexes]\n        # generate data\n        X, y = self.__data_generation(file_path_list_temp)\n        # return data \n        return X, y\n    \n    def on_epoch_end(self):\n        'update ended after each epoch'\n        self.indexes = np.arange(len(self.file_path_list))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def __data_generation(self, file_path_list_temp):\n        'generate data containing batch_size samples'\n        X = np.empty((self.batch_size, self.img_size, self.img_size, self.channels))\n        y = np.empty((self.batch_size, self.img_size, self.img_size, self.channels))\n        \n        for idx, file_path in enumerate(file_path_list_temp):\n            \n            id = file_path.split('\/')[-1][:-4]\n            rle = self.labels.get(id)\n            image = pydicom.read_file(file_path).pixel_array\n            image_resized = cv2.resize(image, (self.img_size, self.img_size))\n            image_resized = np.array(image_resized, dtype=np.float64)\n            \n            X[idx,] = np.expand_dims(image_resized, axis=2)\n            \n            # if there is no mask create empty mask\n            # notice we are starting of with 1024 because we need to use the rle2mask function\n            if rle is None:\n                mask = np.zeros((1024, 1024))\n            else:\n                if len(rle) == 1:\n                    mask = rle2mask(rle[0], 1024, 1024).T\n                else: \n                    mask = np.zeros((1024, 1024))\n                    for r in rle:\n                        mask =  mask + rle2mask(r, 1024, 1024).T\n                        \n            mask_resized = cv2.resize(mask, (self.img_size, self.img_size))\n            y[idx,] = np.expand_dims(mask_resized, axis=2)\n            \n        # normalize \n        X = X \/ 255\n        y = y \/ 255\n            \n        return X, y","a15eb000":"masks = {}\nfor index, row in train_metadata_df[train_metadata_df['has_pneumothorax']==1].iterrows():\n    masks[row['id']] = list(row['encoded_pixels_list'])","23672d05":"bad_data = train_metadata_df[train_metadata_df['encoded_pixels_count']==0].index\nnew_train_metadata_df = train_metadata_df.drop(bad_data)","ce84cff9":"drop_data = new_train_metadata_df[new_train_metadata_df['has_pneumothorax'] == False].sample(no_pneumo_drop).index\nnew_train_metadata_df = new_train_metadata_df.drop(drop_data)","fbd52803":"# split the training data into train and validation set (stratified)\nX_train, X_val, y_train, y_val = train_test_split(new_train_metadata_df.index, new_train_metadata_df['has_pneumothorax'].values, test_size=val_size, random_state=42)\nX_train, X_val = new_train_metadata_df.loc[X_train]['file_path'].values, new_train_metadata_df.loc[X_val]['file_path'].values","4b4e2ba9":"params = {'img_size': img_size,\n          'batch_size': batch_size,\n          'channels': 1,\n          'shuffle': True}\n\n# Generators\ntraining_generator = DataGenerator(X_train, masks, **params)\nvalidation_generator = DataGenerator(X_val, masks, **params)","c449dac4":"x, y = training_generator.__getitem__(2)\nprint(x.shape, y.shape)","4aeeaf2a":"fig = plt.figure()\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\nax = fig.add_subplot(1, 2, 1)\nax.imshow(x[0].reshape(img_size, img_size), cmap=plt.cm.bone)\nax = fig.add_subplot(1, 2, 2)\nax.imshow(np.reshape(y[0], (img_size, img_size)), cmap=\"gray\")","d24f4970":"def down_block(x, filters, kernel_size=3, padding='same', strides=1, activation='relu'):\n    'down sampling block of our UNet'\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(x)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(conv)\n    pool = MaxPool2D((2,2), (2,2))(conv)\n    return conv, pool","fce9e184":"def up_block(x, skip, filters, kernel_size=3, padding='same', strides=1, activation='relu'):\n    'up sampling block of our UNet'\n    up_sample = UpSampling2D((2,2))(x)\n    concat = Concatenate()([up_sample, skip])\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(concat)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(conv)\n    return conv","3d5d7a0d":"def bottleneck(x, filters, kernel_size=3, padding='same', strides=1, activation='relu'):\n    'bottle neck that sits inbetween the down sampling side and the up sampling side'\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(x)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(conv)\n    return conv","d09d4038":"def UNet(img_size):\n    'constructing UNet using the blocks defined above'\n    \n    # number of filters per block\n    f = [32,64,128,256,512]\n    inputs = Input((img_size, img_size, 1))\n    \n    p0 = inputs\n    c1, p1 = down_block(p0, f[0])\n    c2, p2 = down_block(p1, f[1])\n    c3, p3 = down_block(p2, f[2])\n    c4, p4 = down_block(p3, f[3])\n    \n    bn = bottleneck(p4, f[4])\n    \n    u1 = up_block(bn, c4, f[3])\n    u2 = up_block(u1, c3, f[2])\n    u3 = up_block(u2, c2, f[1])\n    u4 = up_block(u3, c1, f[0])\n    \n    outputs = Conv2D(1, (1,1), padding='same', activation='sigmoid')(u4)\n    model = Model(inputs, outputs)\n    return model","de5eabcc":"# defining the loss function and metrics\n\nsmooth = 1.\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = tf.keras.layers.Flatten()(y_true)\n    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","494eeb55":"model = UNet(img_size)\nmodel.compile(optimizer='adam', loss=dice_coef_loss, metrics=[dice_coef])\n# model.summary() # enable to see the summary of the model we built","aa8b997e":"model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=50, verbose=2)","7c2a2aa3":"def plot_train(img, mask, pred):\n    \n    fig, ax = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(15,5))\n    \n    ax[0].imshow(img, cmap=plt.cm.bone)\n    ax[0].set_title('Chest X-Ray')\n    \n    ax[1].imshow(mask, cmap=plt.cm.bone)\n    ax[1].set_title('Mask')\n    \n    ax[2].imshow(pred, cmap=plt.cm.bone)\n    ax[2].set_title('Pred Mask')\n    \n    plt.show()","3b7bb50b":"# lets loop over the predictions and print some good-ish results\ncount = 0\nfor i in range(0,30):\n    if count <= 15:\n        x, y = validation_generator.__getitem__(i)\n        predictions = model.predict(x)\n        for idx, val in enumerate(x):\n            if y[idx].sum() > 0 and count <= 15: \n                img = np.reshape(x[idx]* 255, (img_size, img_size))\n                mask = np.reshape(y[idx]* 255, (img_size, img_size))\n                pred = np.reshape(predictions[idx], (img_size, img_size))\n                pred = pred > 0.5\n                pred = pred * 255\n                plot_train(img, mask, pred)\n                count += 1","c0dc797a":"def get_test_tensor(file_path, batch_size, img_size, channels):\n    \n        X = np.empty((batch_size, img_size, img_size, channels))\n\n        # Store sample\n        pixel_array = pydicom.read_file(file_path).pixel_array\n        image_resized = cv2.resize(pixel_array, (img_size, img_size))\n        image_resized = np.array(image_resized, dtype=np.float64)\n        image_resized -= image_resized.mean()\n        image_resized \/= image_resized.std()\n        X[0,] = np.expand_dims(image_resized, axis=2)\n\n        return X","67bbac9a":"submission = []\n\nfor i, row in test_metadata_df.iterrows():\n\n    test_img = get_test_tensor(test_metadata_df['file_path'][i],1,img_size,1)\n    \n    pred_mask = model.predict(test_img).reshape((img_size,img_size))\n    prediction = {}\n    prediction['ImageId'] = str(test_metadata_df['id'][i])\n    pred_mask = (pred_mask > .5).astype(int)\n    \n    \n    if pred_mask.sum() < 1:\n        prediction['EncodedPixels'] =  -1\n    else:\n        prediction['EncodedPixels'] = mask2rle(pred_mask * 255, img_size, img_size)\n    submission.append(prediction)","6362e127":"submission_df = pd.DataFrame(submission)\nsubmission_df = submission_df[['ImageId','EncodedPixels']]\nsubmission_df.head()","12dee631":"submission_df.to_csv('.\/submission.csv', index=False)","d7bc89f0":"## Section 2: Visualizing The Chest X-Ray \n\nIn this section, we will print out a few x-rays to the output, to get a feel for what we are dealing with. To get a better feel, we will also use the mask and print out annotated area with pneumothorax. ","22c87433":"### Annotation \/ Mask \/ Label","459ba4d9":"Run-length encoding (RLE) is a very simple form of lossless data compression. This [video](https:\/\/www.youtube.com\/watch?v=Yl50cJScObI) on YouTube explains how it works. This competition provides a seperate csv file with encodings for each image, which annotates or labels the segment of the image consisting pneumothorax. However, images without pneumothorax have a mask value of -1.","4b6686bd":"Few observations:\n* There are two anomalies for the age value in the dataset.\n* The median age for people who has pneumothorax is not considerably but is slightly lower.","0900556c":"First thing first, let's take a look at the annotation and see how our data is distributed over positive and negative instances.","a682ea10":"**Before we can dive deep into our data, we need to structure the data provided. In this section, we will create a pandas dataframe with metadata and filepath of our x-rays.**\n\nThe competition organizers are hosting this data in Google Cloud Platform. Downloading this data is very simple, and full instruction is provided [here](https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/siim\/SIIM%20Cloud%20Healthcare%20API%20Documentation.pdf). However, we are allowed to download the data and upload it for the sake of this competition. To help us all out, this [kernel](https:\/\/www.kaggle.com\/seesee\/full-dataset) uploads the full dataset. I forked this kernel to have a quick start.\n\nAfter you download the dataset, it is important to understand the hierarchy or folder structure of the images. We have images seperated in a test and train folder. Python has a great utility library called *glob*, which makes pealing these oninion like file structures effortless. \n\nWithin these folders, for every dataset, we have two more folders encapsulating it. The data itself is in a format called DICOM (Digital Imaging and Communications in Medicine), which is the international standard to transmit, store, retrieve, print, process, and display medical imaging information. This format can store these images with metadata (patient id, age, sex, etc.) in one file with .dcm extension. Parsing this is also super easy with *pydicom*, which we will also use.","57ff1a93":"In this section we will explore the metadata that is associated with the x-rays. Although there isn't a lot of metadata, but it is always good to understand how the data is distributed before we dive deep into the images. For this section we will use plotly in offline mode. I still can't believe sometimes that plotly is open sourced to work offline as well!","a07dd18a":"#### Checking out our model\n\nWe can visually inspect how our model is doing for our model in the following way.","e4be8183":"## Section 5: UNet\n\nIn this section we will create a Convolutional Neural Network to try to predict Pneumothorax. We will use a well known architecture for bio-medical image segmentation called UNet. The original authors of UNet published the webpage [U-Net: Convolutional Networks for Biomedical Image Segmentation\n](https:\/\/lmb.informatik.uni-freiburg.de\/people\/ronneber\/u-net\/), which is a good read in my opinion. You will notice that we resize the image from 1024x1024 to 256x256. It's because the image size otherwise is too big for us to process in a decent batch size.","fd930a17":"## Introduction\n\nThe purpose of this competition is to identify \"Pneumothorax\" or a collapsed lung from chest x-rays. Pneumothorax is a condition that is responsible for making people suddenly gasp for air, and feel helplessly breathless for no apparent reason. Pneumothorax is visually diagnosed by radiologist, and even for a professional with years of experience; it is difficult to confirm. Neural networks and advanced data science techniques can hopefully help capture all the latent features and detect pneumothorax consistently.\n\nSo ultimately, we want to develop a model to identify and segment pneumothorax from a set of chest radiographic images.\n\n**I feel that this is an important competition, with potential of making a huge amount of impact, and we (the Kaggle community) should give it our best shot. The lines of python codes we write staying up a few nights and sacrificing a few leisure activity can help save someone's life one day.**\n\nTherefore, I wanted to create a Kernel that lowers the barrier to enter this competition. For those who are new, I will try to add as much explanation in the comment section as possible. For those who has very little time outside their professional and personal responsibilities, I hope this serves you a quick gateway to get started.\n\n#### Credits\n\nI very often see plagiarism in Kaggle community. I really find it difficult to understand why as \"a candle loses nothing by lighting another candle\". We should always credit original authors and upvote their work before using it. Below is the list of great Kernels I had the good fortune of taking help from while building this Kernel:\n\n* [Chest xray, DICOM, viz, U-nets](https:\/\/www.kaggle.com\/jesperdramsch\/intro-chest-xray-dicom-viz-u-nets-full-data) by [Jesper](https:\/\/www.kaggle.com\/jesperdramsch)\n* [Full Dataset](https:\/\/www.kaggle.com\/seesee\/full-dataset) by [See--](https:\/\/www.kaggle.com\/seesee)\n* [Keras Data Generator 1024x1024 (unet)](https:\/\/www.kaggle.com\/ppepijn\/keras-data-generator-1024x1024-unet) by [pepijn](https:\/\/www.kaggle.com\/ppepijn)\n* [EDA Can you see the Pneumothorax?](https:\/\/www.kaggle.com\/freeman89\/eda-can-you-see-the-pneumothorax) by [Kostadinov](https:\/\/www.kaggle.com\/freeman89)\n* [Image Pre-processing for Chest X-ray](https:\/\/www.kaggle.com\/seriousran\/image-pre-processing-for-chest-x-ray) by [Chanran Kim\n](https:\/\/www.kaggle.com\/seriousran)\n\n\n#### PS: I am still working on this competition, but in a different Kernel: https:\/\/www.kaggle.com\/ekhtiar\/finding-pneumo-part-2-resunet. If you like the extension of this work and find it useful, please upvote it or leave a comment to let me know that what I am doing is indeed useful :)","86586b14":"From the scatter plot we observe that size of the area and number of zones are not exactly correlated. However the graph above is too zoomed in. Perhaps, if we categorize age into four age groups (child, youth, adult, and senior) and look into the difference in area per age group and gender, we may observe something interesting. Let's do that!","788a700f":"For most of us, we are not a radiologist, who are trained to catch Pneumothorax in the xray. So we will use the masking data and visualize the spot where Pneumothorax is on the xray.\n\nI feel in this competition, our ability to use different filters will play a big role. In [Image Pre-processing for Chest X-ray notebook](https:\/\/www.kaggle.com\/seriousran\/image-pre-processing-for-chest-x-ray)  there is an example of using CLAHE [(Contrast Limited Adaptive Histogram Equalization)](https:\/\/docs.opencv.org\/3.1.0\/d5\/daf\/tutorial_py_histogram_equalization.html). I am also visualizing a version of the x-ray with CLAHE applied.","ebf55fe6":"This is more like it. The following things we observe is interesting:\n\n\n* For children, the affected area is typically very small.\n* Affected area for Youth seems to be the largest! Median for youth female is 110 sqmm, and for male is 242 sqmm.\n* In terms of size, for adults and youth we have a lot of outliers, and specially in adults.\n* Gap between median and q3 is bigger in male over females, for all age groups, except for seniors.\n* However, for male seniors and female seniors almost have the same median. \n\nSo in summary, males typically developes gas built up over a larger area than female. But that is understandable, as men typically tend to have larger lungs than women.","cefe255f":"From the scatter plot we see the point between size of the affected area being large in male than female. However for the different age groups, I don't observe something super interesting. To zoom in even more, we will do a bubble chart, where x axis is the age, y axis is the number of bounding boxes or annotated  labeled area, and the size of the bubble or marker is the total area of the affected parts of the chest.","c3257651":"## Section 3: Explore The Metadata","0b3c2576":"We can verify that our generator class is working and is passing the right data visually in the following way.","7c8848bd":"### Age, Sex, and Pneumothorax","0191e8c6":"## Section 1: Down\/loading The Data","71b00b3d":"What the! There is a patient who is like 400 plus, and there is another patient who suspiciously looks too old to be true. I will remove these two anomalies and do a box plot below.","30f8d57b":"#### Making Predictions\n\nIn this section, we predict using our model and create a submission without taking advantage of the leak.","55477b85":"This competition provides a library for masking. I will go more in depth into what masking is in later part of this competition. For now, we import this library in a hacky way below, by adding the path into our system.","ddd24b64":"Now we have the data in a format we can plot, let's do a boxplot to see if there is a difference in the size of affected area between male and female.","53dc83c4":"Observations:\n* We have slightly more instanes of male x-rays.\n* Male and female are equally likely to have Pneumothorax (at least according to our dataset)","e1eb979c":"## Section 4: Analysing The Affected Area\n\nIn the metadata, we don't have an attribute explicitly describing how big the area in patient's chest where gas has built up. However, we do have the masking information. In this section, I will propose a rather naive and simple solution to convert this to an approximate area. All the masks are in a 1024x1024 matrix. First we will count the non zero elements in this array to count the number of pixels we have. Pixel spacing gives us the length and width of patient's chest per pixel. We will multiply the area per pixel driven of pixel spacing by total number of pixels to get an estimation of the affected area in sq mm.","839c3d2e":"#### Net TensorFlow Keras Implementation\n\nLets build the UNet model in this section. Actually, I found a nice implementation of UNet on [Github](https:\/\/github.com\/nikhilroxtomar\/UNet-Segmentation-in-Keras-TensorFlow), which I am using for this section of the Kernel.","1e6c8247":"In the pandas dataframe we created earlier, we created a column to contain the path to the DICOM data. We did this because fitting and keeping the entire image data also in pandas dataframe would be a waste of resource. Below, we use that path to load the dataset and use retrieve the image data.","c4334d7c":"Wow, this is very difficult to spot pneumothorax in chest x-ray. For some cases, a poorly visible contour is in the x-ray, but more often than not, I just can't see how they spot it. It feels like Clahe helps it make it more visible, but I don't know for sure. Our network result will give us the final verdict later.","0165eacb":"My first curiosity is to see if there is a relationship with the patient's age and this condition. To investigate, let's plot a histogram of the age for people who has pneumothorax and doesn't have pneumothorax.","0d3e3c4d":"That's interesting! The size of affected area is clearly larger in male population vs female population. There is a considerable amount of difference for the median, q3, and upper fence for both of the groups. Also, there are a lot of outliers in the data. Let's do a scatter plot between age and size of the affected area to zoom into our data more.","6ebf6109":"Our network is not working at all! Either the network architecture is too vanilla, or the data is too imbalanced, or we need to define a better loss function. However, the code is working and serves as a good boiler plate for someone starting out. So I will leave this as it is. In the other Kernel, [Finding Pneumo Part 2](https:\/\/www.kaggle.com\/ekhtiar\/finding-pneumo-part-2-resunet), we see that adding residual elements to UNet does provide results.","768d4284":"Now let's plot two donut chart next to each other, to show the portion of people with pneumothorax and without pneomothorax between male and female.","6377b45f":"* We do have small amount of x-rays where the patient has pneumothorax\n* There are 37 instance of x-rays without any annotation\n* For most of the x-rays, there is only one mask \/ area that is labeled\n* There are a considerable amount of images with more than one area where you can see pneumothorax\n* It is good to keep in mind that an image can have more than one annotation","1ec02165":"#### Data Generator\n\nTo push the data to our model, we will create a custom data generator. A generator lets us load data progressively, instead of loading it all into memory at once. A custom generator allows us to also fit in more customization during the time of loading the data. As the model is being procssed in the GPU, we can use a custom generator to pre-process images via a generator. At this time, we can also take advantage multiple processors to parallelize our pre-processing."}}