{"cell_type":{"899c0353":"code","0e4a3354":"code","43910836":"code","cf196dd3":"code","c3fb75c3":"code","0203236f":"code","5674737e":"code","a2e26881":"code","f5f07920":"code","1b9e379e":"code","cf4b5d51":"code","56f88811":"code","d3737157":"code","0d8ba25f":"code","bf2b1b28":"code","08357d5b":"code","88b5d460":"code","b5d4c2ee":"code","a954f6c7":"code","b111376d":"code","108101fa":"code","f3c30691":"code","886a6cfa":"code","5e708808":"code","417ed229":"code","5ea65010":"code","71ebcba0":"code","a3f14d85":"code","dbc5ec8b":"code","915f4f5e":"code","7a371746":"code","7f913fe6":"code","a1229cae":"code","5d1bd567":"code","938d7331":"markdown","8480e4bf":"markdown","8f82fadf":"markdown","2253bccf":"markdown","1d1910d4":"markdown","dbfa6009":"markdown","4fcc7b98":"markdown","72cb7505":"markdown","3db95047":"markdown"},"source":{"899c0353":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e4a3354":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn import metrics \n%matplotlib inline\nfrom sklearn.model_selection import train_test_split \n\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense","43910836":"#import datafile\ndf = pd.read_csv('..\/input\/bank-customer-churn-modeling\/Churn_Modelling.csv')\ndf.head(10)","cf196dd3":"#drop unique columns such as row number and id \ndf1= df.drop(['RowNumber','CustomerId','Surname'], axis=1)\ndf1.head()","c3fb75c3":"(df1==0).sum()","0203236f":"df1.info()","5674737e":"df1.duplicated().sum()","a2e26881":"# Pairplot using sns\nimport seaborn as sns\nsns.pairplot(df1 , diag_kind = 'kde')\nplt.show()","f5f07920":"corr = abs(df1.corr()) # correlation matrix\nlower_triangle = np.tril(corr, k = -1)  # select only the lower triangle of the correlation matrix\nmask = lower_triangle == 0  # to mask the upper triangle in the following heatmap\n\nplt.figure(figsize = (15,8))  # setting the figure size\nsns.set_style(style = 'white')  # Setting it to white so that we do not see the grid lines\nsns.heatmap(lower_triangle, center=0.5, cmap= 'Blues', annot= True, xticklabels = corr.index, yticklabels = corr.columns,\n            cbar= False, linewidths= 1, mask = mask)   # Da Heatmap\nplt.xticks(rotation = 50)   # Aesthetic purposes\nplt.yticks(rotation = 20)   # Aesthetic purposes\nplt.show()","1b9e379e":"df1.corr()","cf4b5d51":"df1.drop(['IsActiveMember'], axis=1, inplace=True)","56f88811":"ax = sns.countplot('Exited', data=df1)","d3737157":"ax = sns.boxplot(x='Exited', y='EstimatedSalary', data=df1)","0d8ba25f":"df1['Exited'].value_counts()","bf2b1b28":"df1.dtypes","08357d5b":"catcals = ['Geography', 'Gender','NumOfProducts', 'HasCrCard']","88b5d460":"for col in catcals:\n    df1[col] = df1[col].astype('category')","b5d4c2ee":"df1.dtypes","a954f6c7":"#creating dummies for the categorical datatypes\ndf1 = pd.get_dummies(df1, columns=catcals)","b111376d":"df1.head()","108101fa":"# Separating dependent and independent variables\nx = df1.drop('Exited',axis=1)\ny = df1['Exited']","f3c30691":"# Splitting the data into train and test\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=10)","886a6cfa":"#Normalize\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_train= scaler.fit_transform(x_train)\nx_test = scaler.fit_transform(x_test)","5e708808":"x_train.shape","417ed229":"#Initializing the model\nmodel = Sequential()","5ea65010":"# Define model architecture\n\nmodel.add(Dense(9, input_dim=16,activation='relu'))\nmodel.add(Dense(9, activation ='relu'))\nmodel.add(Dense(1,activation='sigmoid'))","71ebcba0":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","a3f14d85":"model.fit(x_train, y_train, epochs=200, batch_size=200, verbose=1) ","dbc5ec8b":"loss, acc = model.evaluate(x_test, y_test, verbose=0)\nprint('Accuracy: %.3f'  % acc)\nprint('Loss: %.3f' % loss)","915f4f5e":"y_predict = model.predict(x_test)       #default threshold of model.predict is 0.5","7a371746":"y_predict = (y_predict > 0.5)\nprint(y_predict)","7f913fe6":"y_pred = []\nfor val in y_predict:\n    y_pred.append(np.argmax(val))\n#print(y_pred)    \n#convert 0 1 to 1 and 1 0 as 0\ncm = metrics.confusion_matrix(y_test,y_pred)\nprint(cm)","a1229cae":"acc = ((cm[0][0]+cm[1][1])*100)\/(cm[0][0]+cm[1][1]+cm[0][1]+cm[1][0])\nprint(acc,'% of testing was classified correctly')","5d1bd567":"cr=metrics.classification_report(y_test,y_pred)\nprint(cr)","938d7331":"Bi-variate Data Analysis","8480e4bf":"**Changing categorical data**","8f82fadf":"**Optimizing the model**\n\nTo optimize the model we can consider some parameters, such as \n\n- The type of Architecture \n- Number of Layers \n- Number of neurons\n- Regularization parameters \n- Learning Rate\n- Weight sharing \n- Dropout rate \nTuning these parameters can\/would give us a better accuracy score. \n\n\n","2253bccf":"# **EXPLORATORY DATA ANALYSIS**","1d1910d4":"**In this project, we aim to predict the churn for a bank, i.e, given a Bank customer, can we build a classifier which can determine whether they will leave or not using Neural networks**","dbfa6009":"Predict the result using 0.5 threshold","4fcc7b98":"**Normalizing the train and test data**","72cb7505":"**Initialize and build model**","3db95047":"**Distinguishing the feature and target dataset**"}}