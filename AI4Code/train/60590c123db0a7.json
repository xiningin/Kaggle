{"cell_type":{"9091667e":"code","cce3dbb1":"code","b7a5dbbf":"code","74cc4f3b":"code","56892e2e":"code","c81cf43f":"code","bd86532a":"code","d2d22a03":"code","a8170455":"code","16e542bd":"code","bac6bd2a":"code","e54a4361":"code","2b7814bc":"code","fdd6256c":"code","146b4a50":"markdown","0c3079ed":"markdown","b6eea50e":"markdown","474ace97":"markdown","40fa5954":"markdown","f7c6b0aa":"markdown","e16b0bf9":"markdown","4808badf":"markdown","b2966098":"markdown","e6804201":"markdown"},"source":{"9091667e":"import os\nimport numpy as np\nimport pandas as pd\nimport glob\nimport matplotlib.pyplot as plt\nimport random\nimport skimage","cce3dbb1":"# load dataset\ndf= pd.read_csv(\"\/kaggle\/input\/chinese-mnist\/chinese_mnist.csv\", low_memory = False)\ndf.head()","b7a5dbbf":"print(\"dataframe rows:\", df.shape[0]) \nprint(\"image files :\", len(os.listdir(\"\/kaggle\/input\/chinese-mnist\/data\/data\/\")))","74cc4f3b":"# Matchin image names\ndef file_path_col(df):    \n    file_path = f\"input_{df[0]}_{df[1]}_{df[2]}.jpg\" #input_1_1_10.jpg    \n    return file_path\n\n# Create file_path column\ndf[\"file_path\"] = df.apply(file_path_col, axis = 1)\ndf.head()","56892e2e":"from sklearn.model_selection import train_test_split\ntrain_df, test_df = train_test_split(df, test_size = 0.2, random_state = 42, shuffle = True, stratify = df.code.values)\nval_df, test_df   = train_test_split(df, test_size = 0.5, random_state = 42, shuffle = True, stratify = df.code.values)\n\nprint(train_df.shape[0])\nprint(val_df.shape[0])\nprint(test_df.shape[0])","c81cf43f":"import skimage.io\nimport skimage.transform\n\nfile_paths = list(df.file_path)\ndef read_image(file_paths):\n    image = skimage.io.imread(\"\/kaggle\/input\/chinese-mnist\/data\/data\/\" + file_paths)\n    image = skimage.transform.resize(image, (64, 64, 1), mode=\"reflect\") \n    # THe mode parameter determines how the array borders are handled.    \n    return image[:, :, :]\n\n# One hot encoder, but in 15 classes\ndef character_encoder(df, var = \"character\"):\n    x = np.stack(df[\"file_path\"].apply(read_image))\n    y = pd.get_dummies(df[var], drop_first = False)\n    return x, y","bd86532a":"x_train, y_train = character_encoder(train_df)\nx_val, y_val = character_encoder(val_df)\nx_test, y_test = character_encoder(test_df)\n\nprint(x_train.shape, \",\", y_train.shape)\nprint(x_val.shape, \",\", y_val.shape)\nprint(x_test.shape, \",\", y_test.shape)","d2d22a03":"input_shape = (64,64,1) # img_rows, img_colums, color_channels\nnum_classes = y_train.shape[1] # charactors = 15 ","a8170455":"from tensorflow.keras import models, layers\n\nmodel = models.Sequential()\n# 1st Conv layer\nmodel.add(layers.Conv2D(32, kernel_size = (3, 3), padding = 'same', activation = 'relu', input_shape = input_shape))\nmodel.add(layers.MaxPool2D(pool_size = (2, 2)))\n# 2nd Conv layer        \nmodel.add(layers.Conv2D(64, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(layers.MaxPool2D(pool_size = (2, 2)))\n# 3nd Conv layer        \nmodel.add(layers.Conv2D(128, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(layers.MaxPool2D(pool_size = (2, 2)))\n# Fully Connected layer        \nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation = 'relu'))\nmodel.add(layers.Dense(num_classes, activation = 'softmax'))\n\nmodel.summary()","16e542bd":"model.compile(loss = 'categorical_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])","bac6bd2a":"history = model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))","e54a4361":"model.save('chinese-mnist.h5')","2b7814bc":"# Evaluate Model\nscore = model.evaluate(x_test, y_test, verbose = 0)\nprint('Test loss: ', score[0])\nprint('Test accuracy: ', score[1])","fdd6256c":"# Show Train History\nkeys=history.history.keys()\nprint(keys)\n\ndef show_train_history(hisData,train,test): \n    plt.plot(hisData.history[train])\n    plt.plot(hisData.history[test])\n    plt.title('Training History')\n    plt.ylabel(train)\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()\n\nshow_train_history(history, 'loss', 'val_loss')\nshow_train_history(history, 'accuracy', 'val_accuracy')","146b4a50":"# Handwritten Chinese Digit Recognizer","0c3079ed":"## Build Model","b6eea50e":"### save model","474ace97":"## Train Model","40fa5954":"## Evaluate Model","f7c6b0aa":"### split dataset","e16b0bf9":"### show training history","4808badf":"## Prepare Dataset","b2966098":"### charactors\n![image.png](attachment:image.png)","e6804201":"## [Dataset](https:\/\/www.kaggle.com\/gpreda\/chinese-mnist) 15000 64x64 .jpg\n"}}