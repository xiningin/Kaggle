{"cell_type":{"8b286fcb":"code","c7379621":"code","ebb951af":"code","97ff71e3":"code","9c11ce26":"code","1f08e559":"code","7b4c6fb6":"code","b1f90856":"code","b9e1abbf":"code","96838a49":"code","97b23dba":"code","5cb361f0":"code","3f04978a":"code","48aba37f":"code","1faa7661":"markdown","c4bc5853":"markdown","07bd1216":"markdown","22bb1de8":"markdown","31a7ca30":"markdown","1419a4d9":"markdown","4c8dc09e":"markdown","6f2f7cb0":"markdown"},"source":{"8b286fcb":"# Basics\nimport numpy as np\nimport pandas as pd\nimport os\nimport time\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras import callbacks\n\n# Metrics\nfrom sklearn.metrics import accuracy_score\n\n# Graphs\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport seaborn as sns\n\nprint(\"Numpy: \" + np.__version__)\nprint(\"Tensorflow: \" + tf.__version__)","c7379621":"WORK_DIR = os.path.dirname(\"..\/input\/mednist-mizujou\/MedNIST Training Dataset\/data\/\")\nBATCH_SIZE = 512\nLEARNING_RATE = 1e-4\nDROPOUT_RATE = 0.5\nIMG_SIZE = 64\nINPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\nINITIAL_EPOCHS = 30\nFINE_TUNE_EPOCHS = 30\n\nCLASSES = [\n    \"AbdomenCT\",\n    \"BreastMRI\",\n    \"ChestCT\",\n    \"CXR\",\n    \"Hand\",\n    \"HeadCT\"\n]","ebb951af":"%%time\n\ntrain_datagen = keras.preprocessing.image.ImageDataGenerator(\n    validation_split = 0.2,\n    rotation_range = 45,\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    vertical_flip = True,\n    shear_range = 0.2,\n    height_shift_range = 0.2,\n    width_shift_range = 0.2\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    WORK_DIR,  \n    subset=\"training\",\n    shuffle=True,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode=\"sparse\"\n)","97ff71e3":"valid_datagen = keras.preprocessing.image.ImageDataGenerator(\n    validation_split=0.2\n)\n\nvalid_generator = valid_datagen.flow_from_directory(\n    WORK_DIR, \n    subset=\"validation\",\n    shuffle=True,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode=\"sparse\"\n)","9c11ce26":"base_model = tf.keras.applications.EfficientNetB0(\n    input_shape=INPUT_SHAPE,\n    include_top=False\n)","1f08e559":"# Freeze the base\nbase_model.trainable = True\n\n# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Extra Layers\nflatten_layer = keras.layers.Flatten()\ndrop_layer = keras.layers.Dropout(DROPOUT_RATE)","7b4c6fb6":"inputs = tf.keras.Input(shape=INPUT_SHAPE)\nx = base_model(inputs, training=False) # training=False comes from the requirement of the BatchNormalization layer\nx = flatten_layer(x)\nx = layers.Dense(512, activation=\"relu\")(x)\nx = drop_layer(x)\nx = layers.Dense(128, activation=\"relu\")(x)\nx = drop_layer(x)\noutputs = layers.Dense(6, activation=\"softmax\")(x)\nmodel = keras.Model(inputs, outputs)\n\nmodel.summary()","b1f90856":"early_stopping = keras.callbacks.EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement, default=0.001\n    patience=7, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)\n\nreduce_lr = keras.callbacks.ReduceLROnPlateau( \n    patience=5,\n    min_delta=0.01, \n    verbose=1\n)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    metrics=[\"accuracy\"]\n)","b9e1abbf":"history = model.fit(\n    train_generator,\n    epochs=INITIAL_EPOCHS,\n    callbacks=[early_stopping, reduce_lr],\n    validation_data=valid_generator\n)","96838a49":"df_his = pd.DataFrame(history.history)\n\nfig = go.Figure()\n# Create and style traces\nfig.add_trace(go.Scatter(x=df_his.index, y=df_his[\"loss\"], name=\"Loss\"))\nfig.add_trace(go.Scatter(x=df_his.index, y=df_his[\"val_loss\"], name=\"Validation Loss\"))\n\n# Edit the layout\nfig.update_layout(title=\"Fully Fine Tuned EffNetB0 Model's Loss\", xaxis_title=\"Epochs\", yaxis_title=\"%\")\n\nfig.show()","97b23dba":"fig = go.Figure()\n# Create and style traces\nfig.add_trace(go.Scatter(x=df_his.index, y=df_his[\"accuracy\"], name=\"Accuracy\"))\nfig.add_trace(go.Scatter(x=df_his.index, y=df_his[\"val_accuracy\"], name=\"Validation Accuracy\"))\n\n# Edit the layout\nfig.update_layout(title=\"Fully Fine Tuned EffNetB0 Model's Accuracy\", xaxis_title=\"Epochs\", yaxis_title=\"%\")\n\nfig.show()","5cb361f0":"test_generator = valid_datagen.flow_from_directory(\n    WORK_DIR, \n    subset=\"validation\",\n    shuffle=False,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode=\"sparse\"\n)\n\npred = model.predict(test_generator, verbose=1)\ny_pred = np.argmax(pred, axis=1)","3f04978a":"accuracy = accuracy_score(test_generator.classes, y_pred)\ntf_cm = tf.math.confusion_matrix(test_generator.classes, y_pred)\n\nsns.heatmap(\n    tf_cm, \n    annot=True,\n    cmap=\"Blues\",\n    fmt=\".4g\",\n    xticklabels=CLASSES,\n    yticklabels=CLASSES\n)\n\nplt.title(\"Confusion Matrix on our Best Model, \\n using the EfficientNetB0, \\n Validation Accuracy Score: {:.4f}\".format(accuracy), size=16)\nplt.xlabel(\"Predicted Values\", size=13)\nplt.ylabel(\"True Values\", size=13)\nplt.show()","48aba37f":"#model.save(\"4.0_EffNetB0_Stan\")","1faa7661":"---\n\n# 6. Plot Performances","c4bc5853":"## Confusion Matrix","07bd1216":"## Save our Model","22bb1de8":"---\n\n# 4. Build our Model","31a7ca30":"---\n\n# 2. Parameters","1419a4d9":"---\n\n# 5. Training","4c8dc09e":"# Final Project - Computer Vision - MedNIST\n## with Seb\n\n## Notes about this notebook\n\n* Save Version 1:\n    * Efficient Net B7\n    * Accuracy of 99,60% on the Validation Set\n    * Made just a few mistakes but for each label.\n    \nThis is very different with the previous results we got from Efficient Net B0 and B2 Models.\n\n* Save Version 2:\n    * Took the Efficient Net B0 to try to get back our best model\n    * The difference is that we unfroze all the base_model\n    * We finished with a Validation Accuracy of 100%\n    \n---\n\n# 1. Import Librairies","6f2f7cb0":"---\n\n# 3. Build Image Generators"}}