{"cell_type":{"a0a5ce01":"code","c355c6b7":"code","26fdbd69":"code","eb93a5b1":"code","4d1b763e":"code","79ab8a28":"code","ff22d94f":"code","a61a705b":"code","1ea7439a":"code","61761577":"code","297c07ae":"code","220e55cd":"code","d5700d2d":"code","eca0121e":"code","77e29099":"code","bf7862c4":"code","a741c4ff":"code","99e3d69c":"code","34ace08d":"code","07de599b":"code","930e42d6":"code","7010bb1c":"code","992d0ffb":"code","10a5c858":"code","6b65fa94":"code","4dd316fc":"code","fd7bd6ee":"code","5cbde7ae":"code","94642ca2":"code","018ab8a2":"code","81fd7d28":"code","07b6177b":"code","a458fcde":"code","d1751545":"code","f2522513":"code","16cd3161":"code","8355c147":"code","601b6e31":"code","6b6dd3bc":"code","423c716c":"code","7af22638":"code","2f75bcd8":"code","90774426":"code","76e5da0c":"code","79444337":"code","d13d6607":"code","e981ae23":"code","4da3b4c8":"code","acdbb1ac":"code","7f451277":"code","343f5505":"code","2253f5c5":"code","74448d32":"code","82c6d247":"code","ec5c60c5":"code","35d05dd5":"code","5503966d":"code","fe7dbb42":"code","7d309ce2":"code","a837ce48":"code","392e1aae":"code","544563b5":"code","496f55d9":"code","9bb7a407":"code","289a8d0a":"code","56f51c60":"code","adab49b3":"code","692a2bf0":"code","af327770":"code","22f046ac":"code","4f1c5684":"code","321e3089":"code","17bc515f":"code","f4106341":"code","34c96d68":"code","1648bb8a":"code","727a6941":"code","bef0b895":"markdown","f0e8aafb":"markdown","17be98b8":"markdown","e2670278":"markdown","1e9afa0a":"markdown","c2d5732e":"markdown","0a299649":"markdown","23b42c7b":"markdown"},"source":{"a0a5ce01":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c355c6b7":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\n\nfrom sklearn.model_selection import train_test_split\nfrom math import sqrt\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nimport warnings","26fdbd69":"train_df = pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/train.csv.zip')\ntest_df = pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/test.csv.zip')\nfeatures_df = pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/features.csv.zip')\nstores_df = pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/stores.csv')\ndf = pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/sampleSubmission.csv.zip')","eb93a5b1":"train_df.head()","4d1b763e":"train_df.columns","79ab8a28":"train_df.shape","ff22d94f":"train_df.info()","a61a705b":"train_df.describe()","1ea7439a":"train_df.isnull()","61761577":"train_df.isnull().sum()","297c07ae":"test_df.head()","220e55cd":"test_df.columns","d5700d2d":"test_df.shape","eca0121e":"test_df.info()","77e29099":"test_df.describe()","bf7862c4":"test_df.isnull()","a741c4ff":"test_df.isnull().sum()","99e3d69c":"features_df.head()","34ace08d":"features_df.columns","07de599b":"features_df.shape","930e42d6":"features_df.info()","7010bb1c":"features_df.describe()","992d0ffb":"features_df.isnull()","10a5c858":"features_df.isnull().sum()","6b65fa94":"stores_df.head()","4dd316fc":"stores_df.columns","fd7bd6ee":"stores_df.shape","5cbde7ae":"stores_df.info()","94642ca2":"stores_df.describe()","018ab8a2":"stores_df.isnull()","81fd7d28":"stores_df.isnull().sum()","07b6177b":"dataset = features_df.merge(stores_df, how= 'inner', on = 'Store')\ndataset.head()","a458fcde":"train_df.head()","d1751545":"dataset.info()","f2522513":"# Handling The Datetime\n\nfrom datetime import datetime\n\ndataset['Date'] = pd.to_datetime(dataset['Date'])\ntrain_df['Date'] = pd.to_datetime(train_df['Date'])\ntest_df['Date'] = pd.to_datetime(test_df['Date'])","16cd3161":"dataset['week'] = dataset.Date.dt.isocalendar().week\ndataset['year'] = dataset.Date.dt.isocalendar().year","8355c147":"dataset.head()","601b6e31":"train_df.head()","6b6dd3bc":"# Merge dataset with train_df\n\ntrain_df = train_df.merge(dataset, how='inner', on=['Store', 'Date', 'IsHoliday']).sort_values(by=['Store','Dept','Date']).reset_index(drop=True)","423c716c":"# Merge dataset with test_df\n\ntest_df = test_df.merge(dataset, how='inner', on=['Store', 'Date', 'IsHoliday']).sort_values(by=['Store','Dept','Date']).reset_index(drop=True)","7af22638":"train_df.head()","2f75bcd8":"test_df.head()","90774426":"def scatter(train_df, column):\n    plt.figure()\n    plt.scatter(train_df[column], train_df['Weekly_Sales'])\n    plt.ylabel('Weekly_Sales')\n    plt.xlabel(column)","76e5da0c":"scatter(train_df, 'Store')\nscatter(train_df, 'Dept')\nscatter(train_df, 'IsHoliday')\nscatter(train_df, 'Temperature')\nscatter(train_df, 'Fuel_Price')\nscatter(train_df, 'CPI')\nscatter(train_df, 'Unemployment')\nscatter(train_df, 'Type')\nscatter(train_df, 'Size')","79444337":"# Average Weekly Sales for the year 2010\nweekly_sales_2010 = train_df[train_df['year'] ==  2010]['Weekly_Sales'].groupby(train_df['week']).mean()\nsns.lineplot(weekly_sales_2010.index, weekly_sales_2010.values)","d13d6607":"# Average Weekly Sales for the year 2011\nweekly_sales_2011 = train_df[train_df['year']== 2011]['Weekly_Sales'].groupby(train_df['week']).mean()\nsns.lineplot(weekly_sales_2011.index, weekly_sales_2011.values)","e981ae23":"# Average Weekly Sales for the year 2012\nweekly_sales_2012 = train_df[train_df['year']== 2012]['Weekly_Sales'].groupby(train_df['week']).mean()\nsns.lineplot(weekly_sales_2012.index, weekly_sales_2012.values)","4da3b4c8":"# Plotting the above three plot together\n\nplt.figure(figsize= (20, 10))\nsns.lineplot(weekly_sales_2010.index, weekly_sales_2010.values)\nsns.lineplot(weekly_sales_2011.index, weekly_sales_2011.values)\nsns.lineplot(weekly_sales_2012.index, weekly_sales_2012.values)\nplt.grid()\nplt.xticks(np.arange(1,60, step= 1))\nplt.title('Average Weekly Sales Per Year', fontsize = 20)\nplt.xlabel('Week', fontsize = 16)\nplt.ylabel('Sales', fontsize = 16)\nplt.legend(['2010', '2011', '2012'], loc = 'best', fontsize = 16)\nplt.show()","acdbb1ac":"# Average Sales per Department\nweekly_sales = train_df['Weekly_Sales'].groupby(train_df['Dept']).mean()\nplt.figure(figsize= (25, 12))\nsns.barplot(weekly_sales.index, weekly_sales.values)\nplt.grid()\nplt.title('Average Weekly Sales Per Department', fontsize = 20)\nplt.xlabel('Department', fontsize = 16)\nplt.ylabel('Sales', fontsize = 16)\nplt.show()","7f451277":"# Average Sales per Store\nweekly_sales = train_df['Weekly_Sales'].groupby(train_df['Store']).mean()\nplt.figure(figsize= (25, 12))\nsns.barplot(weekly_sales.index, weekly_sales.values)\nplt.grid()\nplt.title('Average Weekly Sales Per Department', fontsize = 20)\nplt.xlabel('Store', fontsize = 16)\nplt.ylabel('Sales', fontsize = 16)\nplt.show()","343f5505":"sns.set(style = 'white')\ncorr = train_df.corr()\nmask = np.triu(np.ones_like(corr, dtype = np.bool))\nfig, ax = plt.subplots(figsize= (25, 15))\ncmap = sns.diverging_palette(220, 10, as_cmap= True)\nsns.heatmap(corr, mask = mask, cmap = cmap, vmax = 0.3, center = 0, square = True, linewidth= 0.5, cbar_kws = {'shrink': 0.5}, annot = True)","2253f5c5":"# Dropping down the variables that have weak correlation\ntrain_df.drop(columns = ['Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'], inplace = True)\ntest_df.drop(columns = ['Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'], inplace = True)","74448d32":"train_df.head()","82c6d247":"test_df.head()","ec5c60c5":"# Splitting Data into Train and Test\nX = train_df[['Store', 'Dept', 'IsHoliday','Size','week','year']]\ny = train_df['Weekly_Sales']","35d05dd5":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","5503966d":"X_train.info()","fe7dbb42":"# Performing GridSearchCV on Ridge Regression\nparams = {'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]}\nridge_regressor = GridSearchCV(Ridge(), params, cv = 7, scoring = 'neg_mean_absolute_error', n_jobs = -1)\nridge_regressor.fit(X_train, y_train)","7d309ce2":"# Predicting train and test results\ny_train_pred = ridge_regressor.predict(X_train)\ny_test_pred = ridge_regressor.predict(X_test)","a837ce48":"print(\"Train Results for Ridge Regressor Model:\")\nprint(\"Root Mean Squared Error: \", sqrt(mse(y_train.values, y_train_pred)))\nprint(\"R-Squared: \", r2_score(y_train.values, y_train_pred))","392e1aae":"print(\"Test Results for Ridge Regressor Model:\")\nprint(\"Root Mean Squared Error: \", sqrt(mse(y_test.values, y_test_pred)))\nprint(\"R-Squared: \", r2_score(y_test.values, y_test_pred))","544563b5":"# Performing GridSearchCV on Lasso Regression\nparams = {'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]}\nlasso_regressor = GridSearchCV(Lasso(), params ,cv = 15,scoring = 'neg_mean_absolute_error', n_jobs = -1)\nlasso_regressor.fit(X_train, y_train)","496f55d9":"# Predicting train and test results\ny_train_pred = lasso_regressor.predict(X_train)\ny_test_pred = lasso_regressor.predict(X_test)","9bb7a407":"print(\"Train Results for Lasso Regressor Model:\")\nprint(\"Root Mean Squared Error: \", sqrt(mse(y_train.values, y_train_pred)))\nprint(\"R-Squared: \", r2_score(y_train.values, y_train_pred))","289a8d0a":"print(\"Test Results for Lasso Regressor Model:\")\nprint(\"Root Mean Squared Error: \", sqrt(mse(y_test.values, y_test_pred)))\nprint(\"R-Squared: \", r2_score(y_test.values, y_test_pred))","56f51c60":"# Performing GridSearchCV on Decision Tree Regression\nfrom sklearn.tree import DecisionTreeRegressor\n\ndepth = list(range(3,30))\nparam_grid = dict(max_depth = depth)\ntree = GridSearchCV(DecisionTreeRegressor(), param_grid, cv = 10)\ntree.fit(X_train,y_train)","adab49b3":"# Predicting train and test results\ny_train_pred = tree.predict(X_train)\ny_test_pred = tree.predict(X_test)","692a2bf0":"print(\"Train Results for Decision Tree Regressor Model:\")\nprint(\"Root Mean squared Error: \", sqrt(mse(y_train.values, y_train_pred)))\nprint(\"R-Squared: \", r2_score(y_train.values, y_train_pred))","af327770":"print(\"Test Results for Decision Tree Regressor Model:\")\nprint(\"Root Mean squared Error: \", sqrt(mse(y_test.values, y_test_pred)))\nprint(\"R-Squared: \", r2_score(y_test.values, y_test_pred))","22f046ac":"# Performing RandomsearchCV on Random Forest Regression\nfrom sklearn.ensemble import RandomForestRegressor\ntuned_params = {'n_estimators': [100, 200], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}  \nrandom_regressor = RandomizedSearchCV(RandomForestRegressor(), tuned_params, n_iter = 3, scoring = 'neg_mean_absolute_error', cv = 3, n_jobs = -1)\nrandom_regressor.fit(X_train, y_train)","4f1c5684":"# Predicting train and test results\ny_train_pred = random_regressor.predict(X_train)\ny_test_pred = random_regressor.predict(X_test)","321e3089":"print(\"Train Results for Random Forest Regressor Model:\")\nprint(\"Root Mean squared Error: \", sqrt(mse(y_train.values, y_train_pred)))\nprint(\"R-Squared: \", r2_score(y_train.values, y_train_pred))","17bc515f":"print(\"Test Results for Random Forest Regressor Model:\")\nprint(\"Root Mean squared Error: \", sqrt(mse(y_test.values, y_test_pred)))\nprint(\"R-Squared: \", r2_score(y_test.values, y_test_pred))","f4106341":"prediction = lasso_regressor.predict(test_df[['Store', 'Dept', 'IsHoliday','Size','week','year']])\nprediction","34c96d68":"df.head()","1648bb8a":"df.Weekly_Sales = prediction","727a6941":"df.to_csv('weekly_sales.csv', index = False)","bef0b895":"<b> By using these data we have to Predict the walmart sales forecasting based on different parameters<\/b>","f0e8aafb":"## Business Problem","17be98b8":"# Problem Statemtent","e2670278":"In this project, students are provided with historical sales data for 45 Walmart stores located in different regions. Each store contains many departments, and participants must project the sales for each department in each store. To add to the challenge, selected holiday markdown events are included in the dataset. These markdowns are known to affect sales, but it is challenging to predict which departments are affected and the extent of the impact.\n\n","1e9afa0a":"### Correlation Matrix\nLet's have a look at the Average Weekly Sales per Year and find out if there is any other holiday peak sales that were not considered by 'IsHoliday' filed","c2d5732e":"## Importing Dataset","0a299649":"### Importing Libraries","23b42c7b":"<h1>Walmart Sales Forecasting <\/h1>"}}