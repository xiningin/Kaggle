{"cell_type":{"e015d2e4":"code","8614048c":"code","a73eb758":"code","87a9ba82":"code","dad8fb78":"code","d5e3a0d7":"code","90724da3":"code","f29a3a9d":"code","afa2a728":"code","9a6815c5":"code","26b28986":"code","1d00b5e6":"code","7846aeb0":"code","87754bb1":"code","ebe26e1a":"code","22827fa8":"code","f13ca6f7":"code","6cb0b1a5":"code","e40d6d10":"code","afc98aae":"code","1d023a5c":"code","5a8c393a":"code","4b76c5d1":"code","a67dfe74":"code","70451410":"code","560bd8ef":"code","14ad54a3":"code","39c1fb38":"code","3d5b4c12":"code","1bc1c1a9":"code","36a5c552":"code","849c44ac":"code","a73638a6":"code","25b0f5f2":"code","fccd2a16":"code","edc61a5d":"code","e43f4a21":"code","4e42352b":"code","33074906":"code","7bb89837":"code","a59797f3":"code","96409324":"code","dbaaf289":"code","654876d9":"code","2b6becbf":"code","e58071a3":"code","0788e85e":"code","977c4cae":"code","caf1e120":"code","cf79d004":"code","a5439a37":"code","92aaf3ae":"code","25842676":"code","263d5fcc":"code","0681fd45":"code","f6a9955a":"code","29deed83":"code","233d5db9":"code","ff5ae7b4":"code","77abcf8c":"code","68c05663":"code","16126cef":"code","bd598420":"code","039d242b":"code","80038d65":"code","02da634e":"code","06afb83c":"code","57ba5418":"code","2cf457c8":"code","5c272719":"code","59aacbd6":"code","e4bf2dd1":"code","34b60bd1":"code","ca911915":"code","802f3d71":"code","21475cf0":"code","d8b82d48":"code","afda13d1":"code","e4fb2f10":"code","32e98985":"code","1c32e738":"code","da62826c":"code","ca961609":"code","0cd96af6":"code","dcb9b269":"code","51d3a899":"code","6b5753dd":"code","f9d3ce96":"code","5f8bebd3":"code","fe08b8b4":"code","362ca9f2":"code","47d5ef76":"code","5f938926":"code","9d09ebc9":"code","9cc19e88":"code","bc8c7e5b":"code","c678600e":"code","b4e2f937":"code","c2a59d35":"code","7a10e1e3":"code","0b26b52a":"code","d6d58b64":"code","bbba22fe":"code","00975d65":"code","65866e53":"code","d513a54f":"code","7cb2e7dc":"code","451165d6":"code","95f3a34d":"code","ab12f6e2":"code","dd0bf8a4":"code","1ec17916":"code","9b2b5e95":"code","b0882f3d":"code","bf1e090f":"code","b1985614":"code","37cda874":"code","d7e6f06b":"code","7ee17642":"code","900bada7":"code","1012556c":"code","0ea6e4c4":"markdown","f9a8f23b":"markdown","0b424da3":"markdown","963ebeaf":"markdown","652211e8":"markdown","832265fd":"markdown","db39839e":"markdown","cc978998":"markdown","5e6c081b":"markdown","2bb11e39":"markdown","b66f4c6f":"markdown","ddec6252":"markdown","c1d98ac7":"markdown","4aaba6e9":"markdown","5353edcd":"markdown","833ce49a":"markdown","64e770ae":"markdown","6fb3e489":"markdown","3a2f9715":"markdown","1f7b57c8":"markdown","eafff413":"markdown","a252bc15":"markdown","db1a5083":"markdown","1989fcad":"markdown","a1fc04ef":"markdown","2849a469":"markdown"},"source":{"e015d2e4":"!pip install tensorflow==2.0.0-beta1 \nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\nimport re\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV, KFold\nimport lightgbm as lgb\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\nsns.set()\npy.init_notebook_mode(connected=True)","8614048c":"os.listdir(\"..\/input\")","a73eb758":"df = pd.read_csv('..\/input\/pmsm_temperature_data.csv')\ndf.head()","87a9ba82":"df.describe()","dad8fb78":"df.columns","d5e3a0d7":"df.isnull().sum()","90724da3":"df.info()","f29a3a9d":"exp_time_count = df.profile_id.value_counts().sort_values()\nexp_time_count","afa2a728":"fig = plt.figure(figsize=(10, 12))\nsns.barplot(y=exp_time_count.index, x=exp_time_count.values, order=exp_time_count.index, orient=\"h\")\nplt.title(\"Experiment time per profile_id\", fontsize=16)\nplt.ylabel(\"Profile ID\",fontsize=14)\nplt.xlabel(\"Experiment time\", fontsize=14)","9a6815c5":"df_20 = df[df.profile_id==20].drop(\"profile_id\", axis=1).reset_index(drop=True)\ndf_20.head()","26b28986":"corr_matrix = df_20.corr()\nfigure = ff.create_annotated_heatmap(z=corr_matrix.values,\n                                     x=list(corr_matrix.columns),\n                                     y=list(corr_matrix.index), \n                                     annotation_text=np.round(corr_matrix.values, 2),\n                                    colorscale=\"YlOrRd\",\n                                    showscale=True)\nfigure[\"layout\"][\"yaxis\"].update({\"tickangle\": -45})\nfigure[\"layout\"][\"xaxis\"].update({\"tickangle\": -45})\npy.iplot(figure)","1d00b5e6":"list_cor = list(df_20.corr()[df_20.corr() >= 0.5].stack().index)\nfor elem in list_cor:\n    if elem[0] == elem[1]:\n        list_cor.pop(list_cor.index(elem))\nlist_cor","7846aeb0":"list(df_20.corr()[df_20.corr() <= -0.3].stack().index)","87754bb1":"# with sns.plotting_context(font_scale=12):\n#     sns.pairplot(df_20)","ebe26e1a":"df_20.describe()","22827fa8":"fig = tls.make_subplots(rows=1, cols=len(df_20.columns), horizontal_spacing=0.05)\nfor i, var in enumerate(df_20.columns):\n    fig.append_trace(go.Box(y=df_20[var].values, name=var), 1, i+1)\nfig[\"layout\"].update(height=400, width=2000)\npy.iplot(fig)","f13ca6f7":"df.head()","6cb0b1a5":"group_df = df.groupby(by=\"profile_id\").cumcount()\ndf = pd.concat([df, group_df], axis=1)\ndf = df.rename(columns={0: \"time_idx\"})\ndf.head()","e40d6d10":"df[\"exp_time\"] = df[\"time_idx\"]*0.5\ndf = df.drop(\"time_idx\", axis=1)\ndf.head()","afc98aae":"plt.figure(figsize=(10, 8))\nsns.heatmap(df.drop(\"profile_id\", axis=1).corr(), annot=True)","1d023a5c":"target_vars = re.findall(r\"stator_\\w*|torque|pm\", \" \".join(df.columns))\ntarget_df = df[target_vars]\nattr_df = df.drop(target_vars, axis=1)","5a8c393a":"target_df.head()","4b76c5d1":"attr_df.head()","a67dfe74":"corr_vars = [\"i_q\", \"i_d\", \"u_d\", \"u_q\"]","70451410":"sns.distplot(df[\"torque\"], bins=10, kde=False)","560bd8ef":"fig, ax = plt.subplots(nrows=1, ncols=len(corr_vars), figsize=(10, 6))\nfor i, var in enumerate(corr_vars):\n    sns.distplot(df[var], ax=ax[i], bins=8, kde=False)\nplt.show()","14ad54a3":"plot_acf(df_20[\"torque\"], title=\"Auto correlation (Torque) for profile_id = 20\", lags=1250)\n_ = plt.show()","39c1fb38":"plot_pacf(df_20[\"torque\"], title=\" Partial auto correlation (Torque) for profile_id = 20\", lags=5)\n_ = plt.show()","3d5b4c12":"vars_ = corr_vars[:]\nvars_.append(\"torque\")\n# sns.pairplot(vars=vars_, hue=\"profile_id\", data=df)\nsns.pairplot(vars=vars_, data=df)\n_ = plt.show()","1bc1c1a9":"df_analysis = df[vars_]\ncorr_matrix = df_analysis.corr()\nfigure = ff.create_annotated_heatmap(z=corr_matrix.values,\n                                     x=list(corr_matrix.columns),\n                                     y=list(corr_matrix.index), \n                                     annotation_text=np.round(corr_matrix.values, 2),\n                                    colorscale=\"YlOrRd\",\n                                    showscale=True)\nfigure[\"layout\"][\"yaxis\"].update({\"tickangle\": -45})\nfigure[\"layout\"][\"xaxis\"].update({\"tickangle\": -45})\npy.iplot(figure)","36a5c552":"X_train, X_test, y_train, y_test = train_test_split(attr_df, target_df, test_size=.2, shuffle=True)\nprofile_train = X_train[\"profile_id\"]\nprofile_test = X_test[\"profile_id\"]\nX_train = X_train.drop(\"profile_id\", axis=1)\nX_test = X_test.drop(\"profile_id\", axis=1)","849c44ac":"def ols(target, corr_vars, add_const):\n    target_train = y_train[\"torque\"].values.reshape(-1, 1)\n    y_scaler = StandardScaler().fit(target_train)\n    target_train = y_scaler.transform(target_train)\n    var_train = X_train[corr_vars]\n    var_names = var_train.columns\n    x_scaler = StandardScaler().fit(var_train)\n    var_train = pd.DataFrame(x_scaler.transform(var_train), columns=var_names)\n    if add_const:\n        var_train = sm.add_constant(var_train)\n    model = sm.OLS(target_train, var_train, ).fit()\n    return model, y_scaler, x_scaler, var_names","a73638a6":"model, _, _, _ = ols(\"torque\", corr_vars, True)\nmodel.summary()","25b0f5f2":"model, y_scaler, x_scaler, var_names = ols(\"torque\", corr_vars, False)\nmodel.summary()","fccd2a16":"y_20 = y_scaler.transform(df.loc[df[\"profile_id\"]==20, \"torque\"].values.reshape(-1, 1))\nX_20 = x_scaler.transform(df.loc[df[\"profile_id\"]==20, corr_vars])\nX_20 = pd.DataFrame(X_20, columns=var_names)","edc61a5d":"model_20 = sm.OLS(y_20, X_20).fit()\nmodel_20.summary()","e43f4a21":"ols_params = model.params","4e42352b":"profiles = df[\"profile_id\"].unique()\nprofile_lens = {profile: df[df[\"profile_id\"]==profile].shape[0] for profile in profiles}\nprofile_series = pd.Series()\n\nfor profile_len in profile_lens.items():\n    profile_series.at[profile_len[0]] = profile_len[1]\nprofile_series.head()","33074906":"yhat = lambda X: X[corr_vars[0]]*ols_params[0] - X[corr_vars[1]]*ols_params[1] \\\n    - X[corr_vars[2]]*ols_params[2] - X[corr_vars[3]]*ols_params[3]","7bb89837":"# trace1 = go.Scatter3d(x=df_sample[corr_vars[0]],\n#                      y=df_sample[corr_vars[1]],\n#                      z=yhat(df_sample),\n#                      mode=\"lines\",\n#                      name=\"Regression Line\")\n\n# trace2 = go.Scatter3d(x=df_sample[corr_vars[0]],\n#                      y=df_sample[corr_vars[1]],\n#                      z=df_sample[\"torque\"],\n#                      mode=\"markers\",\n#                      name=\"True Values\")\n\n# data=[trace1, trace2]\n\n# layout = go.Layout(title={\"text\": \"Regression (Torque)\"},\n#                   scene=go.layout.Scene(xaxis=go.layout.scene.XAxis(title=corr_vars[0]),\n#                                 yaxis=go.layout.scene.YAxis(title=corr_vars[1]),\n#                                 zaxis=go.layout.scene.ZAxis(title=\"Torque\")))\n\n# fig = go.Figure(data=data, layout=layout)\n\n# py.iplot(fig)","a59797f3":"var_names","96409324":"y_test_scaled = y_scaler.transform(y_test[\"torque\"].values.reshape(-1, 1))\nX_test_scaled = pd.DataFrame(x_scaler.transform(X_test[corr_vars]), columns=var_names)","dbaaf289":"mae = mean_absolute_error(y_test_scaled, yhat(X_test_scaled))\nmae","654876d9":"mse = mean_squared_error(y_test_scaled, yhat(X_test_scaled))\nmse","2b6becbf":"r2 = r2_score(y_test_scaled, yhat(X_test_scaled))\nr2","e58071a3":"error_df = y_scaler.inverse_transform(yhat(X_test_scaled)) - y_test[\"torque\"]\nerror_df.describe()","0788e85e":"sns.distplot(error_df)","977c4cae":"error_df_perc = error_df \/ y_test[\"torque\"] * 100\nerror_df_perc.describe()","caf1e120":"sns.distplot(error_df_perc)","cf79d004":"X_test_scaled = x_scaler.transform(X_test[[\"i_q\", \"i_d\", \"u_d\", \"u_q\"]])\nvar_pca = PCA(n_components=1).fit(X_test_scaled)\nvar_pca.explained_variance_ratio_","a5439a37":"sample = df.sample(n=1000)\nsample_X_scaled = pd.DataFrame(x_scaler.transform(sample[corr_vars]), columns=var_names)","92aaf3ae":"x_plot = var_pca.transform(sample[corr_vars]).ravel()","25842676":"y_plot = y_scaler.inverse_transform(yhat(sample_X_scaled).values)","263d5fcc":"y_true = sample[\"torque\"]","0681fd45":"plt.plot(x_plot, y_plot, alpha=0.8)\nplt.scatter(x_plot, y_true, c=\"red\")","f6a9955a":"# kfold = KFold(n_splits=5).split(X=X_train, y=y_train[\"torque\"])","29deed83":"# params_grid = {\"num_leaves\": [10, 20, 30],\n#               \"learning_rate\": 0.1,\n#               \"n_estimators\": [100, 150],\n#               \"boosting_type\": [\"gbdt\", \"dart\"],\n#               \"reg_alpha\": [1, 1.2],\n#               \"reg_lambda\": [1, 1.2, 1.4]}","233d5db9":"# gbm = lgb.LGBMRegressor()","ff5ae7b4":"# gbm_cv = GridSearchCV(gbm, param_grid=params_grid,\n#                       cv=kfold, return_train_score=True,\n#                       scoring=\"neg_mean_squared_error\")","77abcf8c":"# gbm_cv.fit(X_train, y_train[\"torque\"])","68c05663":"# gbm_cv.best_score_","16126cef":"# gbm_cv.best_params_","bd598420":"params = {'boosting_type': 'gbdt',\n         'learning_rate': 0.1,\n         'n_estimators': 150,\n         'num_leaves': 30,\n         'reg_alpha': 1,\n         'reg_lambda': 1.2}","039d242b":"x_scaler = StandardScaler().fit(X_train)\nX_train_scaled = x_scaler.transform(X_train)\ny_train_scaled = y_scaler.transform(y_train[\"torque\"].values.reshape(-1, 1))","80038d65":"# gbm = lgb.LGBMRegressor(**gbm_cv.best_params_)\ngbm = lgb.LGBMRegressor(**params)","02da634e":"gbm.fit(X_train_scaled, y_train_scaled)","06afb83c":"sns.barplot(x=gbm.feature_importances_, y=X_train.columns)\nplt.xlabel(\"Feature Importance\", fontsize=12)\nplt.ylabel(\"Label\", fontsize=12)\nplt.title(\"Feature Importance (Torque)\", fontsize=16)\n_ = plt.show()","57ba5418":"X_test_scaled = x_scaler.transform(X_test)","2cf457c8":"pred_gbm = y_scaler.inverse_transform(gbm.predict(X=X_test_scaled))\nmae = mean_absolute_error(y_test[\"torque\"], pred_gbm)\nmse = mean_squared_error(y_test[\"torque\"], pred_gbm)\nr2 = r2_score(y_test[\"torque\"], pred_gbm)\nprint(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2)","5c272719":"error_df = pd.Series(pred_gbm) - y_test[\"torque\"].reset_index(drop=True)\nerror_df.describe()","59aacbd6":"sns.distplot(error_df)","e4bf2dd1":"pca_x = PCA(n_components=1).fit(X_test_scaled)\npca_x.explained_variance_ratio_","34b60bd1":"sns.lineplot(x=pca_x.transform(X_test_scaled).reshape(-1), y=pred_gbm, color=\"red\", alpha=0.8)\nsns.scatterplot(x=pca_x.transform(X_test_scaled).reshape(-1), y=y_test[\"torque\"], color=\"blue\")","ca911915":"def prepare_series(profile_id, df, target_var, test_size, series_size):\n    df_profile = df[df[\"profile_id\"]==profile_id].drop(\"profile_id\", axis=1)\n    dependent_vars = re.findall(r\"stator_\\w*|pm|torque\", \" \".join(df.columns))\n    df_target = df_profile[target_var]\n    df_vars = df_profile.drop(dependent_vars, axis=1)\n    target_train = df_target.values[:int((1-test_size)*df_target.shape[0])][series_size-1:]\n    target_test = df_target.values[int((1-test_size)*df_target.shape[0]):][series_size-1:]\n    train = df_vars.values[:int((1-test_size)*df_vars.shape[0]), ...]\n    test = df_vars.values[int((1-test_size)*df_vars.shape[0]):, ...]\n    train_series = np.zeros(shape=(train.shape[0]-series_size+1, series_size, train.shape[-1]))\n    test_series = np.zeros(shape=(test.shape[0]-series_size+1, series_size, test.shape[-1]))\n    for i in range(train.shape[0]-series_size+1):\n        train_series[i, ...] = train[i:i+series_size, ...]\n    for i in range(test.shape[0]-series_size):\n        test_series[i, ...] = test[i:i+series_size, ...]\n        \n    return train_series, test_series, target_train, target_test","802f3d71":"df.head()","21475cf0":"gru_model = tf.keras.models.Sequential()\ngru_model.add(tf.keras.layers.GRU(units=60, \n                                  return_sequences=True, \n                                  use_bias=True, \n                                  input_shape=(60, X_train.shape[1]-1),\n                                  dropout=0.3))\n\ngru_model.add(tf.keras.layers.GRU(units=60, \n                                  return_sequences=False, \n                                  use_bias=True, \n                                  dropout=0.3,\n                                  activation=\"linear\"))\n\n\ngru_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\", use_bias=True))\n\ngru_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\", \"mse\"])\n\ngru_model.summary()","d8b82d48":"train_series, test_series, target_train, target_test = prepare_series(20, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      \"torque\", 0.3, 60)","afda13d1":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)","e4fb2f10":"history_gru = gru_model.fit(x=train_series, y=target_train,\n                            batch_size=512, epochs=50, \n                            validation_data=(test_series, target_test), callbacks=[callback])","32e98985":"history_gru.history.keys()","1c32e738":"epochs = np.arange(len(history_gru.history[\"loss\"]))+1","da62826c":"trace1 = go.Scatter(x=epochs, y=history_gru.history[\"loss\"], mode=\"lines\", name=\"Train Loss (MSE)\")\n\ntrace2 = go.Scatter(x=epochs, y=history_gru.history[\"val_loss\"], mode=\"lines\", name=\"Validation Loss (MSE)\")\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(title={\"text\": \"Loss Curves (GRU)\"},\n                  scene=go.layout.Scene(xaxis=go.layout.scene.XAxis(title=\"Epoch\"),\n                                       yaxis=go.layout.scene.YAxis(title=\"Mean Absolute Error (LOSS)\")))\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig)","ca961609":"pred_gru = gru_model.predict(test_series)\nmae = mean_absolute_error(target_test, pred_gru.reshape(-1))\nmse = mean_squared_error(target_test, pred_gru.reshape(-1))\nr2_gru = r2_score(target_test, pred_gru.reshape(-1))","0cd96af6":"print(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2_gru)","dcb9b269":"error = pred_gru.reshape(-1) - target_test\nprint(\"MAX error: %f\" %error.max())\nprint(\"MIN error: %f\" %error.min())","51d3a899":"sns.distplot(error, kde=False)","6b5753dd":"lstm_model = tf.keras.models.Sequential()\nlstm_model.add(tf.keras.layers.LSTM(units=60, \n                                  return_sequences=True, \n                                  use_bias=True, \n                                  input_shape=(60, X_train.shape[1]-1),\n                                  dropout=0.3))\n\nlstm_model.add(tf.keras.layers.LSTM(units=60, \n                                  return_sequences=False, \n                                  use_bias=True, \n                                  dropout=0.3,\n                                  activation=\"linear\"))\n\nlstm_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\", use_bias=True))\n\nlstm_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\", \"mse\"])\n\nlstm_model.summary()","f9d3ce96":"train_series, test_series, target_train, target_test = prepare_series(20, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      \"torque\", 0.3, 60)","5f8bebd3":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)","fe08b8b4":"history_lstm = lstm_model.fit(x=train_series, y=target_train,\n                             batch_size=512, epochs=50, \n                              validation_data=(test_series, target_test), callbacks=[callback])","362ca9f2":"epochs = np.arange(len(history_lstm.history[\"loss\"]))+1","47d5ef76":"trace1 = go.Scatter(x=epochs, y=history_lstm.history[\"loss\"], mode=\"lines\", name=\"Train Loss (MSE)\")\n\ntrace2 = go.Scatter(x=epochs, y=history_lstm.history[\"val_loss\"], mode=\"lines\", name=\"Validation Loss (MSE)\")\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(title={\"text\": \"Loss Curves (LSTM)\"},\n                  scene=go.layout.Scene(xaxis=go.layout.scene.XAxis(title=\"Epoch\"),\n                                       yaxis=go.layout.scene.YAxis(title=\"Mean Absolute Error (LOSS)\")))\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig)","5f938926":"pred_lstm = lstm_model.predict(test_series)\nmae = mean_absolute_error(target_test, pred_lstm.reshape(-1))\nmse = mean_squared_error(target_test, pred_lstm.reshape(-1))\nr2_lstm = r2_score(target_test, pred_lstm.reshape(-1))","9d09ebc9":"print(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2_lstm)","9cc19e88":"error = pred_lstm.reshape(-1) - target_test\nprint(\"MAX error: %f\" %error.max())\nprint(\"MIN error: %f\" %error.min())","bc8c7e5b":"sns.distplot(error, kde=False)","c678600e":"def predict_and_evaluate_profiles(model, df, target_var):\n    mae_array = np.array([], dtype=np.float32)\n    mse_array = np.array([], dtype=np.float32)\n    error = np.array([], dtype=np.float32)\n    for profile in df[\"profile_id\"].unique():\n        train_series, test_series, target_train, target_test = prepare_series(profile, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      target_var, 0.3, 60)\n        prediction = model.predict(test_series).reshape(-1)\n        error = np.concatenate([error, prediction-target_test], axis=0)\n        r2 = r2_score(target_test, prediction).reshape(-1)\n        mae = mean_absolute_error(target_test, prediction).reshape(-1)\n        mse = mean_squared_error(target_test, prediction).reshape(-1)\n        mae_array = np.concatenate([mae_array, mae], axis=0)\n        mse_array = np.concatenate([mse_array, mse], axis=0)\n        print(\"Model fitted to profile: %d ----VAL STATS >> R2: %f | MAE: %f | MSE: %f\" %(profile, r2, mae, mse))\n    print(\"\\n---------------------------------\\n\")\n    print(\"Average MAE: %f\" %np.mean(mae_array))\n    print(\"Average MSE: %f\" %np.mean(mse_array))\n    return error","b4e2f937":"def steps_per_epoch(df, series_size, batch_size, test_size):\n    total_size_train, total_size_test = (0, 0)\n    for profile_id in df.profile_id.unique():\n        total_size_train += (1-test_size)*df[df[\"profile_id\"]==profile_id].shape[0] - series_size\n        total_size_test += test_size*df[df[\"profile_id\"]==profile_id].shape[0] - series_size\n    return total_size_train\/\/batch_size, total_size_test\/\/batch_size","c2a59d35":"def train_gen(series_size, test_size, target_var=\"torque\", df=df.drop(\"exp_time\", axis=1)):\n    dep_vars = re.findall(r\"stator_\\w*|pm|torque\", \" \".join(df.columns))\n    for profile_id in df.profile_id.unique():\n        train_len = int((1-test_size)*df[df[\"profile_id\"]==profile_id].shape[0]) - series_size\n        X_profile = df[df[\"profile_id\"]==profile_id].drop(dep_vars, axis=1).drop(\"profile_id\", axis=1).values\n        y_profile = df.loc[df[\"profile_id\"]==profile_id, target_var].values\n        for i in range(train_len):\n            X = X_profile[i:i+series_size, :]\n            y = np.array([y_profile[i+series_size-1]])\n            yield X, y","7a10e1e3":"def test_gen(series_size, test_size, target_var=\"torque\", df=df.drop(\"exp_time\", axis=1)):\n    dep_vars = re.findall(r\"stator_\\w*|pm|torque\", \" \".join(df.columns))\n    for profile_id in df.profile_id.unique():\n        test_begin = int((1-test_size)*df[df[\"profile_id\"]==profile_id].shape[0])\n        test_end = df[df[\"profile_id\"]==profile_id].shape[0] - series_size\n        X_profile = df[df[\"profile_id\"]==profile_id].drop(dep_vars, axis=1).drop(\"profile_id\", axis=1).values\n        y_profile = df.loc[df[\"profile_id\"]==profile_id, target_var].values\n        for i in range(test_begin, test_end+1):\n            X = X_profile[i:i+series_size, :]\n            y = np.array([y_profile[i+series_size-1]])\n            yield X, y","0b26b52a":"gru_model = tf.keras.models.Sequential()\ngru_model.add(tf.keras.layers.GRU(units=50, \n                                  return_sequences=True, \n                                  use_bias=True, \n                                  input_shape=(60, X_train.shape[1]-1),\n                                  dropout=0.3))\n\ngru_model.add(tf.keras.layers.GRU(units=50, \n                                  return_sequences=False, \n                                  use_bias=True, \n                                  dropout=0.3,\n                                  activation=\"linear\"))\n\n\ngru_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\", use_bias=True))\n\ngru_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\", \"mse\"])\n\ngru_model.summary()","d6d58b64":"steps_train_val = steps_per_epoch(df, series_size=60, batch_size=512, test_size=.3)","bbba22fe":"train_dataset = tf.data.Dataset.from_generator(generator=train_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                              args=([60, .3]))\ntrain_dataset = train_dataset.shuffle(500).batch(512).repeat(10)\n\ntest_dataset = tf.data.Dataset.from_generator(generator=test_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                             args=([60, .3]))\ntest_dataset = test_dataset.shuffle(500).batch(512).repeat(10)","00975d65":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nhistory_gru = gru_model.fit_generator(generator=train_dataset,\n                                 steps_per_epoch=int(steps_train_val[0]),\n                                 callbacks=[callback],\n                                 validation_data=test_dataset,\n                                 validation_steps=int(steps_train_val[1]),\n                                 epochs=10)","65866e53":"epochs = np.arange(len(history_gru.history[\"loss\"]))+1\ntrace1 = go.Scatter(x=epochs, y=history_gru.history[\"loss\"], mode=\"lines\", name=\"Train Loss (MSE)\")\n\ntrace2 = go.Scatter(x=epochs, y=history_gru.history[\"val_loss\"], mode=\"lines\", name=\"Validation Loss (MSE)\")\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(title={\"text\": \"Loss Curves (GRU)\"},\n                  scene=go.layout.Scene(xaxis=go.layout.scene.XAxis(title=\"Epoch\"),\n                                       yaxis=go.layout.scene.YAxis(title=\"Mean Absolute Error (LOSS)\")))\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig)","d513a54f":"train_series, test_series, target_train, target_test = prepare_series(20, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      \"torque\", 0.3, 60)\ngru_model.evaluate(x=test_series, y=target_test)","7cb2e7dc":"pred_gru = gru_model.predict(x=test_series)\nmae = mean_absolute_error(target_test, pred_gru.reshape(-1))\nmse = mean_squared_error(target_test, pred_gru.reshape(-1))\nr2 = r2_score(target_test, pred_gru.reshape(-1))\nprint(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2)","451165d6":"train_series, test_series, target_train, target_test = prepare_series(4, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      \"torque\", 0.3, 60)","95f3a34d":"pred_gru = gru_model.predict(x=test_series)\nmae = mean_absolute_error(target_test, pred_gru.reshape(-1))\nmse = mean_squared_error(target_test, pred_gru.reshape(-1))\nr2 = r2_score(target_test, pred_gru.reshape(-1))\nprint(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2)","ab12f6e2":"error_gru = predict_and_evaluate_profiles(gru_model, df, \"torque\")","dd0bf8a4":"sns.distplot(error_gru)","1ec17916":"lstm_model = tf.keras.models.Sequential()\nlstm_model.add(tf.keras.layers.LSTM(units=50, \n                                  return_sequences=True, \n                                  use_bias=True, \n                                  input_shape=(60, X_train.shape[1]-1),\n                                  dropout=0.3))\n\nlstm_model.add(tf.keras.layers.LSTM(units=50, \n                                  return_sequences=False, \n                                  use_bias=True, \n                                  dropout=0.3,\n                                  activation=\"linear\"))\n\nlstm_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\", use_bias=True))\n\nlstm_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\", \"mse\"])\n\nlstm_model.summary()","9b2b5e95":"train_dataset = tf.data.Dataset.from_generator(generator=train_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                              args=([60, .3]))\ntrain_dataset = train_dataset.shuffle(500).batch(512).repeat(10)\n\ntest_dataset = tf.data.Dataset.from_generator(generator=test_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                             args=([60, .3]))\ntest_dataset = test_dataset.shuffle(500).batch(512).repeat(10)","b0882f3d":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nhistory_lstm = lstm_model.fit_generator(generator=train_dataset,\n                                 steps_per_epoch=int(steps_train_val[0]),\n                                 callbacks=[callback],\n                                 validation_data=test_dataset,\n                                 validation_steps=int(steps_train_val[1]),\n                                 epochs=10)","bf1e090f":"epochs = np.arange(len(history_lstm.history[\"loss\"]))+1\ntrace1 = go.Scatter(x=epochs, y=history_lstm.history[\"loss\"], mode=\"lines\", name=\"Train Loss (MSE)\")\n\ntrace2 = go.Scatter(x=epochs, y=history_lstm.history[\"val_loss\"], mode=\"lines\", name=\"Validation Loss (MSE)\")\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(title={\"text\": \"Loss Curves (LSTM)\"},\n                  scene=go.layout.Scene(xaxis=go.layout.scene.XAxis(title=\"Epoch\"),\n                                       yaxis=go.layout.scene.YAxis(title=\"Mean Absolute Error (LOSS)\")))\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig)","b1985614":"train_series, test_series, target_train, target_test = prepare_series(20, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      \"torque\", 0.3, 60)\nlstm_model.evaluate(x=test_series, y=target_test)","37cda874":"pred_lstm = lstm_model.predict(x=test_series)\nmae = mean_absolute_error(target_test, pred_lstm.reshape(-1))\nmse = mean_squared_error(target_test, pred_lstm.reshape(-1))\nr2 = r2_score(target_test, pred_lstm.reshape(-1))\nprint(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2)","d7e6f06b":"train_series, test_series, target_train, target_test = prepare_series(4, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      \"torque\", 0.3, 60)","7ee17642":"pred_lstm = lstm_model.predict(x=test_series)\nmae = mean_absolute_error(target_test, pred_lstm.reshape(-1))\nmse = mean_squared_error(target_test, pred_lstm.reshape(-1))\nr2 = r2_score(target_test, pred_lstm.reshape(-1))\nprint(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2)","900bada7":"error_lstm = predict_and_evaluate_profiles(lstm_model, df, \"torque\")","1012556c":"sns.distplot(error_lstm)","0ea6e4c4":"As seem before in the correlation matrix and the OLS regression, the `i_q` variable is the most important predictor of `torque`.","f9a8f23b":"#### Checking for autocorrelation","0b424da3":"#### ALL `profile_id`","963ebeaf":"### LightGBM (`torque`)","652211e8":"The p-value for the `const` variable is considerably high, meaning that the null hypothesis should be accepted, that is, it's coefficient is equal to 0. So we'll discard the `const` variable (constant) and fit the model again.","832265fd":"#### `Profile_id = 4`","db39839e":"It seems that, the LightGBM has fitted well the data through bruteforce.","cc978998":"#### `Profile_id = 4`","5e6c081b":"### GRU Model","2bb11e39":"### Multivariate Analysis (`torque`)","b66f4c6f":"Choosing only one `profile_id`, the __Durbin-Watson__ test scored a considerable small value, suggesting there is a strong postive autocorrelation.","ddec6252":"The amount of timesteps will be equal to 60, representing 0.5 minute of experiment time.","c1d98ac7":"The errors are mainly located close to 0, but it presents a considerable variance relative to the true values.","4aaba6e9":"## Case Study (`torque`)","5353edcd":"#### `Profile_id = 20`","833ce49a":"## Training the models for all profile_id's","64e770ae":"### Univariate Analysis (`torque`)","6fb3e489":"### GRU (`torque`) using `profile_id = 20` for training","3a2f9715":"As can be observed in the graph above, the lightGBM model has fitted well the data.","1f7b57c8":"### LSTM Model","eafff413":"## OLS (`torque`)","a252bc15":"#### `Profile_id = 20`","db1a5083":"A strong autocorrelation can be noticed between the series of the `torque` variable. Noticing that the PACF crosses the x axis at `lag = 5` and the ACF has a geometric decay, an AR(4) could be used to model the time series data (if it is __stationary__) ","1989fcad":"#### ALL `profile_id`","a1fc04ef":"### LSTM (`torque`) using `profile_id = 20` for training","2849a469":"### Create `exp_time` variable"}}