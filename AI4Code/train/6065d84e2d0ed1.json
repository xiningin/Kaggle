{"cell_type":{"c1c533e2":"code","bc954e99":"code","5bf92312":"code","2db630f0":"code","6426fa1e":"code","296ae42a":"code","617ff067":"code","7498508d":"code","f98ebbd5":"code","40d35ff5":"code","4dc5015d":"code","b7704651":"code","69252be4":"code","4e2d5316":"code","48d84a20":"code","73608de8":"code","a6cc184e":"markdown"},"source":{"c1c533e2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bc954e99":"data=pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\ndata.head()","5bf92312":"data.columns","2db630f0":"dummies = pd.get_dummies(data.Species)\ndummies.head(3)","6426fa1e":"df11 = pd.concat([data,dummies],axis='columns')\ndf11.head()","296ae42a":"df12 = df11.drop('Species',axis='columns')\ndf12.head(2)","617ff067":"X = df12.drop(['PetalWidthCm'],axis='columns')\nX.head(3)","7498508d":"y = df12.PetalWidthCm\ny.head(3)","f98ebbd5":"len(y)","40d35ff5":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)","4dc5015d":"#Linear Regression model\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\n# fit the model\nmodel.fit(X, y)\n\n# evaluate the model\nyhat = model.predict(X_test)\nmodel.score(X_test,y_test)\n","b7704651":"#Decision Tree Regressor\nfrom sklearn.tree import DecisionTreeRegressor\n# define the model\nmodel = DecisionTreeRegressor()\n# fit the model\nmodel.fit(X, y)\n# evaluate the model\nyhat = model.predict(X_test)\nmodel.score(X_test,y_test)\n","69252be4":"# Random Forest Regressor\nfrom sklearn.ensemble import RandomForestRegressor\n# define the model\nmodel = RandomForestRegressor()\n# fit the model\nmodel.fit(X, y)\n# evaluate the model\nyhat = model.predict(X_test)\nmodel.score(X_test,y_test)\n","4e2d5316":"#XGBRegressor\nfrom xgboost import XGBRegressor\n# define the model\nmodel = XGBRegressor()\n# fit the model\nmodel.fit(X, y)\nmodel.score(X_test,y_test)","48d84a20":"#KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\n# define the model\nmodel = KNeighborsRegressor()\n# fit the model\nmodel.fit(X, y)\n# evaluate the model\nyhat = model.predict(X_test)\nmodel.score(X_test,y_test)","73608de8":"from sklearn.model_selection import ShuffleSplit\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef find_best_model_using_gridsearchcv(X,y):\n    algos = {\n        'linear_regression' : {\n            'model': LinearRegression(),\n            'params': {\n                'normalize': [True, False]\n            }\n        },\n        \n        'DecisionTreeRegressor' : {\n            'model': DecisionTreeRegressor(),\n            'params': {\n                \n                'max_features': ['auto']\n            }\n        },\n        \n        'RandomForestRegressor' : {\n            'model': RandomForestRegressor(),\n            'params': {\n                'n_estimators': [100, 200, 300, 1000],\n                'max_features': ['auto']              \n                              \n            }\n        },\n        \n        'XGBRegressor' : {\n            'model': XGBRegressor(),\n            'params': {\n                'booster': ['gbtree']             \n                              \n            }\n        },\n        \n        'KNeighborsRegressor' : {\n            'model': KNeighborsRegressor(),\n            'params': {\n                \n                'algorithm' : ['kd_tree']              \n                              \n            }\n        },\n        \n        'decision_tree': {\n            'model': DecisionTreeRegressor(),\n            'params': {\n                'criterion' : ['mse','friedman_mse'],\n                'splitter': ['best','random']\n            }\n        }\n    }\n    scores = []\n    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n    for algo_name, config in algos.items():\n        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n        gs.fit(X,y)\n        scores.append({\n            'model': algo_name,\n            'best_score': gs.best_score_,\n            'best_params': gs.best_params_\n        })\n\n    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n\nfind_best_model_using_gridsearchcv(X,y)","a6cc184e":"Measuring the score of Best Regression model by using the GridSearchCV\n1. Linear Regression model\n2. Decision Tree Regressor\n3. Random Forest Regressor\n4. XGBRegressor\n5. KNeighborsRegressor\n"}}