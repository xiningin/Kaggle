{"cell_type":{"fc2943d3":"code","42225972":"code","39bf15f8":"code","43eff05f":"code","8c581b75":"code","2c9d4307":"code","23dd48f2":"code","9da86053":"code","548509ee":"code","92dea3ea":"code","0b942e26":"code","79052a3c":"code","1315194c":"code","02ef4452":"code","f85763a2":"code","c64d7747":"code","7b1ed081":"code","79d772c2":"code","6e6199eb":"code","81e836b4":"code","58919649":"code","314ad346":"markdown","f6d24784":"markdown","6694895b":"markdown","f182f503":"markdown","e4409f4d":"markdown","51d7340f":"markdown","1d69a387":"markdown","02f646f6":"markdown","a36db28c":"markdown","5d43380e":"markdown","9e2498c6":"markdown","3becb58f":"markdown","1af0bd41":"markdown"},"source":{"fc2943d3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\ndf = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip')\ndf_test = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv.zip')\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42225972":"print('Size of dataset: ',df.shape)\nprint(df.columns)","39bf15f8":"display(df.describe())","43eff05f":"print('Count of cases positive:')\npositive = []\npositive_perc = []\nlabel_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\nfor i in label_cols:\n    print(i,'-',len(df[df[i]==1]),',',str(round(100*len(df[df[i]==1])\/len(df),2))+'%')\n    positive.append(len(df[df[i]==1]))\n    positive_perc.append(len(df[df[i]==1])\/len(df))","8c581b75":"temp = df\ntemp['length'] = temp.comment_text.apply(lambda x: len(x))\ntemp['length'] = temp.length.apply(lambda x: np.log(x))\nplt.figure(figsize=(20,16))\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\nprint('Comments that are flagged tend to have shorter length')\n\nlabel_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\nfor i in range(len(label_cols)):\n    plt.subplot(2,3,i+1)\n    sns.kdeplot(temp[temp[label_cols[i]]==0]['length'],label='ntf')\n    sns.kdeplot(temp[temp[label_cols[i]]==1]['length'],label='flagged')\n    plt.title(label_cols[i])","2c9d4307":"label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\nfor j in range(len(label_cols)):\n    print(label_cols[j],'comments:')\n    for i in range(len(df)):\n        print(str(i+1),':',list(df[df[label_cols[j]]==1].comment_text)[i],'\\n')\n        if i == 1: break","23dd48f2":"from nltk.corpus import wordnet\nfrom collections import Counter\n\ndef get_part_of_speech(word):\n  probable_part_of_speech = wordnet.synsets(word)\n  pos_counts = Counter()\n  pos_counts[\"n\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"n\"]  )\n  pos_counts[\"v\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"v\"]  )\n  pos_counts[\"a\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"a\"]  )\n  pos_counts[\"r\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"r\"]  )\n  \n  most_likely_part_of_speech = pos_counts.most_common(1)[0][0]\n  return most_likely_part_of_speech","9da86053":"print('checking')\nprint(list(df[df[label_cols[j]]==1].comment_text)[0])\nprint(list(df[df[label_cols[j]]==1].comment_text)[1])\nprint(list(df[df[label_cols[j]]==1].comment_text)[2])","548509ee":"import re\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nprint('BEFORE:\\n',list(df[df[label_cols[j]]==1].comment_text)[0],'\\n')\n\ncleaned = re.sub('\\W+',' ',list(df[df[label_cols[j]]==1].comment_text)[0]) \nprint('AFTER clearing non-words:\\n',cleaned,'\\n')\n\nlowered = cleaned.lower()\nprint('AFTER setting lowercase:\\n',lowered,'\\n')\n\ntokenized = word_tokenize(lowered)\nprint('AFTER tokenizing:\\n',tokenized,'\\n')\n\nfiltered_stopwords = [w for w in tokenized if not w in stopwords.words('english')]\nprint('AFTER removing stopwords:\\n',filtered_stopwords)\n\nlemmatizer = WordNetLemmatizer()\nlemmatized = [lemmatizer.lemmatize(i,get_part_of_speech(i)) for i in filtered_stopwords]\nprint('AFTER lemmatizing:\\n',lemmatized)\n\nregroup = \" \".join(lemmatized)\nprint('AFTER regrouping:\\n',regroup)","92dea3ea":"lemmatizer = WordNetLemmatizer()\n\ndef text_processing(text_list):\n    processed_text = []\n    for text in text_list:\n        cleaned = re.sub('\\W+',' ',text)\n        lowered = cleaned.lower()\n        tokenized = word_tokenize(lowered)\n        filtered_stopwords = [w for w in tokenized if not w in stopwords.words('english')]\n        lemmatized = [lemmatizer.lemmatize(i,get_part_of_speech(i)) for i in filtered_stopwords]\n        processed_text.append(\" \".join(lemmatized))\n    return processed_text","0b942e26":"from datetime import datetime\nfrom datetime import timedelta\nimport time\n\nbefore = datetime.now()\nprocessed_text = text_processing(df['comment_text'][0:1000])\nafter = datetime.now()\ntime_delta = after - before\nseconds = time_delta.total_seconds()\nminutes = seconds\/60\nprint(1000,'rows takes:',round(minutes,4),'minutes')\nprint(len(df)+len(df_test),'rows takes:',round((len(df)+len(df_test))*minutes\/1000,4),'minutes')","79052a3c":"processed_text = text_processing(df['comment_text'])\ntest_processed_text = text_processing(df_test['comment_text'])","1315194c":"no_positive = len(df[df['toxic'] == 1])\nnegative_indices = df[df['toxic']==0].index\nrandom_negative_indices = np.random.choice(negative_indices,no_positive, replace=False)\npositive_indices = df[df['toxic'] == 1].index\nunder_sample_indices = np.concatenate([positive_indices,random_negative_indices])\nunder_sample = df.loc[under_sample_indices]\n\nretained_processed_text = []\nfor i in under_sample.index:\n    retained_processed_text.append(processed_text[i])","02ef4452":"#split train document with X_Test_y_test\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(retained_processed_text, under_sample.toxic, test_size = 0.2, random_state = 6)\nprint(len(x_train))\nprint(len(x_test))","f85763a2":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_creator = TfidfVectorizer(max_df=0.60)\nx_train_tfidf = tfidf_creator.fit_transform(x_train)\nx_test_tfidf = tfidf_creator.transform(x_test)","c64d7747":"#not used for now CountVectorizer\n# option = 2 #1, 2\n# if option == 1:\n#     from sklearn.feature_extraction.text import CountVectorizer\n#     counter = CountVectorizer()\n#     counter.fit(processed_text) \n#     counter.vocabulary_\n#     vectorized_text = counter.transform(processed_text).toarray()\n# else:\n#     pass","7b1ed081":"from sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB()\nclassifier.fit(x_train_tfidf,np.array(y_train))","79d772c2":"y_pred = classifier.predict(x_train_tfidf)\nclassifier.predict_proba(x_train_tfidf)\n\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\nprint('Train dataset:')\n \nresult = pd.DataFrame(confusion_matrix(y_train, y_pred))\ndisplay(result)\nprint('accuracy:\\t',round(accuracy_score( y_train , y_pred),2))\nprint('recall:\\t\\t',round(recall_score( y_train , y_pred),2))\nprint('precision:\\t',round(precision_score( y_train , y_pred),2))\nprint('f1:\\t\\t',round(f1_score( y_train , y_pred),2))","6e6199eb":"y_pred = classifier.predict(x_test_tfidf)\nclassifier.predict_proba(x_test_tfidf)\n\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n\nprint('Test dataset:')\nresult = pd.DataFrame(confusion_matrix(y_test, y_pred))\ndisplay(result)\nprint('accuracy:\\t',round(accuracy_score( y_test , y_pred),2))\nprint('recall:\\t\\t',round(recall_score( y_test , y_pred),2))\nprint('precision:\\t',round(precision_score( y_test , y_pred),2))\nprint('f1:\\t\\t',round(f1_score( y_test , y_pred),2))","81e836b4":"label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\nsubmissions = df_test[['id']]\n\n#6 nb models to predict 6 flags\nfor i in label_cols:\n    \n    #undersampling for each nb model\n    no_positive = len(df[df[i] == 1])\n    negative_indices = df[df[i] == 0].index\n    random_negative_indices = np.random.choice(negative_indices,no_positive, replace=False)\n    positive_indices = df[df[i] == 1].index\n    under_sample_indices = np.concatenate([positive_indices,random_negative_indices])\n    under_sample = df.loc[under_sample_indices]\n\n    retained_processed_text = []\n    for j in under_sample.index:\n        retained_processed_text.append(processed_text[j])\n    \n    #vectorized for each nb model\n    tfidf_creator = TfidfVectorizer(max_df=0.60,binary=True)\n    x_train_tfidf = tfidf_creator.fit_transform(retained_processed_text)\n    x_test_tfidf = tfidf_creator.transform(test_processed_text)\n        \n    #nb model for each flags\n    classifier = MultinomialNB()\n    classifier.fit(x_train_tfidf,np.array(under_sample[i]))\n    y_pred = classifier.predict(x_test_tfidf)\n    submissions[i] = y_pred.reshape(-1,1)\n    print('done for',i)\n    \ndisplay(submissions.head(15))","58919649":"submissions.to_csv('submission.csv',index=False)","314ad346":"* Option 1: Vectorize the training dataset\n* Option 2: Tdidf the training dataset\n\n** Future work: We run into memory problems with Option1. Use tdidf for now to ignore too frequent words","f6d24784":"Do it on whole training dataset and then test dataset for submission","6694895b":"# Read and Analyze Data...","f182f503":"* build tf-idf vectorizer","e4409f4d":"# Modelling: Multinomial Naive Bayes...","51d7340f":"* model of nb","1d69a387":"* splitting train set and test set within the 'train.csv'","02f646f6":"* undersampling","a36db28c":"# Compiling Submission...","5d43380e":"Testing preprocessing computational time:","9e2498c6":"Testing preprocessing methods on a sample:\n\n1. Remove non-words: punctuations\n2. tokenize - break up by individual words\n3. lowercase - no capital letters\n4. lemmatize - reduce to base form\n5. remove stopwords - reduce insignificant words(i, you, to)\n6. un-tokenize","3becb58f":"# **Preprocessing Text...**","1af0bd41":"An NLP attempt at predicting toxic, obscene, threats, insults, identity hatred comments. First Text Processing, then Vectorized with Tf-Idf, then model with NB. \n\nThe score of the model on the test.csv dataset was 0.88."}}