{"cell_type":{"da9d72ac":"code","de4680e0":"code","b50c33db":"code","592f19f7":"code","34dbb415":"code","1a256633":"code","083dadd3":"code","41b6376f":"code","5a1d72fb":"code","7f8f6b53":"code","180831eb":"code","216b2ba4":"code","9ffba1be":"code","c769a463":"code","9afa8309":"code","83ebef0d":"code","e82ae6c7":"code","3654c941":"code","0f8f034a":"code","46a6f80f":"markdown","a4d5b33a":"markdown","776b6c6d":"markdown"},"source":{"da9d72ac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","de4680e0":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport matplotlib.pyplot as plt","b50c33db":"train_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train'\nvalidation_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val'\ntest_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test'","592f19f7":"from tensorflow.keras.applications.densenet import preprocess_input","34dbb415":"BATCH_SIZE = 64\nIMG_SHAPE  = 100\n\n\nimage_gen_train = ImageDataGenerator(preprocessing_function=preprocess_input)\n# image_gen_train = ImageDataGenerator(rescale=1.\/255)\n\ntrain_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n                                                     directory=train_dir,\n                                                     shuffle=True,\n                                                     target_size=(IMG_SHAPE,IMG_SHAPE),\n                                                     class_mode='binary')\n\n\ntest_image_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n# test_image_generator = ImageDataGenerator(rescale=1.\/255) \n\ntest_data_gen = test_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n                                                              directory=test_dir,\n                                                              shuffle=False,\n                                                              target_size=(IMG_SHAPE,IMG_SHAPE), \n                                                              class_mode='binary')\n\n\nvalidation_image_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n# validation_image_generator = ImageDataGenerator(rescale=1.\/255)  \n\nval_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n                                                              directory=validation_dir,\n                                                              shuffle=False,\n                                                              target_size=(IMG_SHAPE,IMG_SHAPE), \n                                                              class_mode='binary')","1a256633":"# names =  {0: \"NORMAL\", 1: \"PNEUMONIA\"}\n# train_images, train_labels = next(train_data_gen)\n\n# plt.figure(figsize = (5,5))\n# plt.imshow(train_images[3], cmap='gray')\n# plt.title(f\"Real label: {names[train_labels[3]]}\")\n\n# plt.figure(figsize = (5,5))\n# plt.imshow(train_images[1], cmap='gray')\n# plt.title(f\"Real label: {names[train_labels[1]]}\")","083dadd3":"cpt_filename = 'checkpoint_best.hdf5'\n\nmcp = tf.keras.callbacks.ModelCheckpoint(filepath=cpt_filename, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')","41b6376f":"input_tensor = tf.keras.Input(shape=(IMG_SHAPE,IMG_SHAPE,3))\n\nbase_model = tf.keras.applications.DenseNet201(\n                                            input_tensor = input_tensor, \n                                            include_top = False, \n                                            pooling = 'average'\n                                            )","5a1d72fb":"model = tf.keras.models.Sequential([\n            base_model,\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(1920, activation='relu'),\n            tf.keras.layers.Dense(1, activation='sigmoid')\n            ])\n\nmodel.compile(\n              optimizer='Adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","7f8f6b53":"%time\n\nEPOCHS = 100\n\nhistory = model.fit(\n                    train_data_gen,\n                    validation_data=test_data_gen,\n                    epochs = EPOCHS,   \n                    callbacks=[mcp]\n                    )","180831eb":"def plotLearningCurve(history,epochs):\n    epochRange = range(1,epochs+1)\n    plt.plot(epochRange,history.history['accuracy'])\n    plt.plot(epochRange,history.history['val_accuracy'])\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend(['Train','Validation'],loc='upper left')\n    plt.show()\n\n    plt.plot(epochRange,history.history['loss'])\n    plt.plot(epochRange,history.history['val_loss'])\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(['Train','Validation'],loc='upper left')\n    plt.show()","216b2ba4":"plotLearningCurve(history, EPOCHS)","9ffba1be":"model_eval = tf.keras.models.load_model(cpt_filename)\n\n# \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0432 \u043f\u0440\u043e\u0446\u0435\u043d\u0442\u0430\u0445\nprint(\"Loss val_data_gen - \" , model_eval.evaluate_generator(val_data_gen)[0])\nprint(\"Accuracy val_data_gen - \" , model_eval.evaluate_generator(val_data_gen)[1]*100 , \"%\")\n\nprint(\"Loss test_data_gen - \" , model_eval.evaluate_generator(test_data_gen)[0])\nprint(\"Accuracy test_data_gen - \" , model_eval.evaluate_generator(test_data_gen)[1]*100 , \"%\")","c769a463":"image_gen_train = ImageDataGenerator(\n                                      preprocessing_function=preprocess_input,\n                                      featurewise_center=False,  # set input mean to 0 over the dataset\n                                      samplewise_center=False,   # set each sample mean to 0\n                                      featurewise_std_normalization=False,  # divide inputs by std of the dataset\n                                      samplewise_std_normalization=False,   # divide each input by its std\n                                      zca_whitening=False,      # apply ZCA whitening\n                                      rotation_range = 30,      # randomly rotate images in the range (degrees, 0 to 180) \/ \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u0443\u0433\u043e\u043b \u043f\u043e\u0432\u043e\u0440\u043e\u0442\u0430\n                                      zoom_range = 0.2,         # Randomly zoom image \/ \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0430 \u0431\u0443\u0434\u0435\u0442 \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0430 \u0438\u043b\u0438 \u0443\u043c\u0435\u043d\u044c\u0448\u0435\u043d\u0430 \u043d\u0435 \u0431\u043e\u043b\u0435\u0435 \u0447\u0435\u043c \u043d\u0430 20% \n                                      width_shift_range=0.1,    # randomly shift images horizontally (fraction of total width) \/ \u0441\u043c\u0435\u0449\u0435\u043d\u0438\u0435 \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c \u043d\u0430 20% \u0448\u0438\u0440\u0438\u043d\u044b \u043f\u043e \u0433\u043e\u0440\u0438\u0437\u043e\u043d\u0442\u0430\u043b\u0438\n                                      height_shift_range=0.1,   # randomly shift images vertically (fraction of total height) \/ \u0441\u043c\u0435\u0449\u0435\u043d\u0438\u0435 \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c \u043d\u0430 20% \u0432\u044b\u0441\u043e\u0442\u044b \u043f\u043e \u0432\u0435\u0440\u0442\u0438\u043a\u0430\u043b\u0438\n                                      horizontal_flip = True,   # randomly flip images \/ \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0435 \u043e\u0442\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043f\u043e \u0433\u043e\u0440\u0438\u0437\u043e\u043d\u0442\u0430\u043b\u0438\n                                      vertical_flip=False,      # randomly flip images \/ \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0435 \u043e\u0442\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043f\u043e \u0432\u0435\u0440\u0442\u0438\u043a\u0430\u043b\u0438\n                                      fill_mode=\"nearest\",       # \u0447\u0435\u043c \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u043f\u0440\u043e\u0431\u0435\u043b\u044b -- \u0441\u043d\u0430\u0447\u0430\u043b\u0430 \u0432\u044b\u0431\u0435\u0440\u0435\u043c \u0447\u0435\u0440\u043d\u044b\u0439 \u0446\u0432\u0435\u0442, \u0430 \u043f\u043e\u0442\u043e\u043c \u0438\u0437\u043c\u0435\u043d\u0438\u043c \u043d\u0430 \"nearest\"\n                                      )     \n\ntrain_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n                                                     directory=train_dir,\n                                                     shuffle=True,\n                                                     target_size=(IMG_SHAPE,IMG_SHAPE),\n                                                     class_mode='binary')","9afa8309":"model_DD = model_eval","83ebef0d":"%time\n\nEPOCHS = 100\n\nhistory = model_DD.fit(\n                        train_data_gen,\n                        validation_data=test_data_gen,\n                        epochs = EPOCHS,   \n                        callbacks=[mcp]\n                        )","e82ae6c7":"model_eval = tf.keras.models.load_model(cpt_filename)\n\n# \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0432 \u043f\u0440\u043e\u0446\u0435\u043d\u0442\u0430\u0445\nprint(\"Loss val_data_gen - \" , model_eval.evaluate_generator(val_data_gen)[0])\nprint(\"Accuracy val_data_gen - \" , model_eval.evaluate_generator(val_data_gen)[1]*100 , \"%\")\n\nprint(\"Loss test_data_gen - \" , model_eval.evaluate_generator(test_data_gen)[0])\nprint(\"Accuracy test_data_gen - \" , model_eval.evaluate_generator(test_data_gen)[1]*100 , \"%\")","3654c941":"def show_PNEUMONIA_NORMAL(images, labels, predicted_labels=None):\n    names =  {0: \"NORMAL\", 1: \"PNEUMONIA\"}   #train_data_gen.class_indices\n    plt.figure(figsize=(15,15))\n    for i in range(16):\n        plt.subplot(4,4, i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.gray)\n        if predicted_labels is not None:\n            title_obj = plt.title(f\"Real: {names[labels[i]]}.\\n Pred: {names[predicted_labels[i]]}\")\n            if labels[i] != predicted_labels[i]:\n                plt.setp(title_obj, color='r')\n        else:\n            plt.title(f\"Real label: {names[labels[i]]}\")","0f8f034a":"sample_val_images, sample_val_labels = next(val_data_gen)\npredicted = model_eval.predict_classes(sample_val_images).flatten()\nshow_PNEUMONIA_NORMAL(sample_val_images, sample_val_labels, predicted)","46a6f80f":"# data augmentation","a4d5b33a":"# Load data","776b6c6d":"# Conclusion"}}