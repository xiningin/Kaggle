{"cell_type":{"090df193":"code","a60ca681":"code","9ba5ca13":"code","d5bc95f8":"code","f9828bba":"code","f97a967a":"code","7d4d05b1":"code","15b5e55f":"code","465763c5":"code","23acdace":"code","0d92d7ca":"code","b78e170f":"code","9f8275e8":"code","4d379c25":"code","9640ef0c":"code","04a542ff":"markdown","e6829c4a":"markdown","fc354700":"markdown","5cc64d86":"markdown","10277392":"markdown","1aa3e49c":"markdown","e587eb1b":"markdown","0ae2ada8":"markdown"},"source":{"090df193":"import os\nimport gc\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nfrom catboost import Pool, CatBoostRegressor\npd.set_option('display.max_columns', None)\nfrom catboost.utils import get_gpu_device_count\nfrom tqdm.notebook import tqdm\nprint('available GPU devices catboost:', get_gpu_device_count())","a60ca681":"DATA_DIR = '\/kaggle\/input\/m5-forecasting-accuracy'\nMODEL_VER = 'v0'\nBACKWARD_LAGS = 60\nEND_D = 1913\nCUT_D = END_D - int(365 * 1.2)\nEND_DATE = '2016-04-24'\nprint(datetime.strptime(END_DATE, '%Y-%m-%d'))","9ba5ca13":"CALENDAR_DTYPES = {\n    'date':             'str',\n    'wm_yr_wk':         'int16', \n    'weekday':          'object',\n    'wday':             'int16', \n    'month':            'int16', \n    'year':             'int16', \n    'd':                'object',\n    'event_name_1':     'object',\n    'event_type_1':     'object',\n    'event_name_2':     'object',\n    'event_type_2':     'object',\n    'snap_CA':          'int16', \n    'snap_TX':          'int16', \n    'snap_WI':          'int16'\n}\nPARSE_DATES = ['date']\nSPRICES_DTYPES = {\n    'store_id':    'object', \n    'item_id':     'object', \n    'wm_yr_wk':    'int16',  \n    'sell_price':  'float32'\n}","d5bc95f8":"def get_df(is_train=True, backward_lags=None):\n    strain = pd.read_csv('{}\/sales_train_validation.csv'.format(DATA_DIR))\n    print('read train:', strain.shape)\n    cat_cols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n    last_day = int(strain.columns[-1].replace('d_', ''))\n    print('first day is:', CUT_D)\n    print('last day is:', last_day)\n    if not is_train:\n        for day in range(last_day + 1, last_day + 28 + 28 + 1):\n            strain['d_{}'.format(day)] = np.nan\n        value_vars = [col for col in strain.columns \n                      if (col.startswith('d_') and (int(col.replace('d_', '')) >= END_D - backward_lags))]\n    else:\n        value_vars = [col for col in strain.columns \n                      if (col.startswith('d_') and (int(col.replace('d_', '')) >= CUT_D))]\n    strain = pd.melt(\n        strain,\n        id_vars = cat_cols,\n        value_vars = value_vars,\n        var_name = 'd',\n        value_name = 'sales'\n    )\n    print('melted train:', strain.shape)\n    calendar = pd.read_csv('{}\/calendar.csv'.format(DATA_DIR), dtype=CALENDAR_DTYPES, parse_dates=PARSE_DATES)\n    print('read calendar:', calendar.shape)\n    strain = strain.merge(calendar, on='d', copy=False)\n    del calendar\n    gc.collect()\n    print('calendar merge done')\n    sprices = pd.read_csv('{}\/sell_prices.csv'.format(DATA_DIR), dtype=SPRICES_DTYPES)\n    print('read prices:', sprices.shape)\n    strain = strain.merge(\n        sprices, \n        on=['store_id', 'item_id', 'wm_yr_wk'], \n        copy=False\n    )\n    del sprices\n    gc.collect()\n    print('prices merge done')\n    print('begin train date:', strain['date'].min())\n    print('end train date:', strain['date'].max())\n    if not is_train:\n        strain = strain.loc[\n            strain['date'] >= (datetime.strptime(END_DATE, '%Y-%m-%d') - timedelta(days=backward_lags))\n        ]\n    print('date cut train:', strain.shape)\n    print('cut train date:', strain['date'].min())\n    print('end train date:', strain['date'].max())\n    return strain","f9828bba":"def make_features(strain):\n    print('in dataframe:', strain.shape)\n    lags = [7, 28]\n    windows= [7, 28]\n    wnd_feats = ['id', 'item_id']\n    lag_cols = ['lag_{}'.format(lag) for lag in lags ]\n    for lag, lag_col in zip(lags, lag_cols):\n        strain[lag_col] = strain[['id', 'sales']].groupby('id')['sales'].shift(lag)\n    print('lag sales done')\n    for wnd_feat in wnd_feats:\n        for wnd in windows:\n            for lag_col in lag_cols:\n                wnd_col = '{}_{}_rmean_{}'.format(lag_col, wnd_feat, wnd)\n                strain[wnd_col] = strain[[wnd_feat, lag_col]].groupby(wnd_feat)[lag_col].transform(\n                    lambda x: x.rolling(wnd).mean()\n                )\n        print('rolling mean sales for feature done:', wnd_feat)\n    date_features = {\n        'week_num': 'weekofyear',\n        'quarter': 'quarter',\n        'mday': 'day'\n    }\n    for date_feat_name, date_feat_func in date_features.items():\n        strain[date_feat_name] = getattr(strain['date'].dt, date_feat_func).astype('int16')\n    print('date features done')\n    strain['d'] = strain['d'].apply(lambda x: int(x.replace('d_', '')))  \n    print('out dataframe:', strain.shape)\n    return strain","f97a967a":"%%time\nstrain = get_df(is_train=True, backward_lags=None)\nstrain = make_features(strain)","7d4d05b1":"drop_cols = ['id', 'sales', 'date', 'wm_yr_wk', 'weekday']\ntrain_cols = strain.columns[~strain.columns.isin(drop_cols)]\ncat_cols = [\n    'item_id', 'dept_id', 'store_id', 'cat_id', 'state_id', \n    'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2'\n]\nstrain[cat_cols] = strain[cat_cols].fillna(0)","15b5e55f":"%%time\nval_size = int(strain.shape[0] * .15)\nval_idxs = np.random.choice(strain.index.values, val_size, replace=False)\ntrain_idxs = np.setdiff1d(strain.index.values, val_idxs)\ntrain_pool = Pool(\n    strain.loc[train_idxs][train_cols], \n    strain.loc[train_idxs]['sales'],\n    cat_features=cat_cols\n)\nval_pool = Pool(\n    strain.loc[val_idxs][train_cols], \n    strain.loc[val_idxs]['sales'],\n    cat_features=cat_cols\n)\ndel strain\ngc.collect()","465763c5":"model = CatBoostRegressor(\n    iterations=1000,\n    task_type='GPU',\n    verbose=0,\n    loss_function='RMSE',\n    boosting_type='Plain', #use to overcome the \u201cOut of memory\u201d error when training on GPU \n    depth=8,\n    #gpu_cat_features_storage='CpuPinnedMemory', #use to overcome the \u201cOut of memory\u201d error when training on GPU \n    #max_ctr_complexity=2 #use to overcome the \u201cOut of memory\u201d error when training on GPU \n)\nmodel.fit(\n    train_pool,\n    eval_set = val_pool,\n    plot=True   \n)\ndel train_pool, val_pool\ngc.collect()","23acdace":"model.save_model('model_{}.cbm'.format(MODEL_VER))","0d92d7ca":"feat_importances = sorted(\n    [(f, v) for f, v in zip(train_cols, model.get_feature_importance())],\n    key=lambda x: x[1],\n    reverse=True\n)\nthreshold = .25\nlabels = [x[0] for x in feat_importances if x[1] > threshold]\nvalues = [x[1] for x in feat_importances if x[1] > threshold]\nfig, ax = plt.subplots(figsize=(8, 8))\ny_pos = np.arange(len(labels))\nax.barh(y_pos, values)\nax.set_yticks(y_pos)\nax.set_yticklabels(labels)\nax.invert_yaxis()\nax.set_xlabel('Performance')\nax.set_title('feature importances')\nplt.show()","b78e170f":"%%time\nspred = get_df(is_train=False, backward_lags=BACKWARD_LAGS)\nfor pred_day in tqdm(range(1, 28 + 28 + 1)):\n    pred_date = datetime.strptime(END_DATE, '%Y-%m-%d') + timedelta(days=pred_day)\n    pred_date_back = pred_date - timedelta(days=BACKWARD_LAGS + 1)\n    print('-' * 70)\n    print('forecast day forward:', pred_day, '| forecast date:', pred_date) \n    spred_data = spred[(spred['date'] >= pred_date_back) & (spred['date'] <= pred_date)].copy()\n    spred_data = make_features(spred_data)\n    spred_data = spred_data.loc[spred['date'] == pred_date, train_cols]\n    spred_data[cat_cols] = spred_data[cat_cols].fillna(0)\n    spred.loc[spred['date'] == pred_date, 'sales'] = model.predict(spred_data)\ndel spred_data\ngc.collect()","9f8275e8":"spred_subm = spred.loc[spred['date'] > END_DATE, ['id', 'd', 'sales']].copy()\nlast_d = int(spred.loc[spred['date'] == END_DATE, 'd'].unique()[0].replace('d_', ''))\nprint('last d num:', last_d)\nspred_subm['d'] = spred_subm['d'].apply(lambda x: 'F{}'.format(int(x.replace('d_', '')) - last_d))\nspred_subm.loc[spred_subm['sales'] < 0, 'sales'] = 0","4d379c25":"f_cols = ['F{}'.format(x) for x in range(1, 28 + 28 + 1)]\nspred_subm = spred_subm.set_index(['id', 'd']).unstack()['sales'][f_cols].reset_index()\nspred_subm.fillna(0, inplace=True)\nspred_subm.sort_values('id', inplace=True)\nspred_subm.reset_index(drop=True, inplace=True)","9640ef0c":"f_cols_val = ['F{}'.format(x) for x in range(1, 28 + 1)]\nf_cols_eval = ['F{}'.format(x) for x in range(28 + 1, 28 + 28 + 1)]\nspred_subm_eval = spred_subm.copy()\nspred_subm.drop(columns=f_cols_eval, inplace=True)\nspred_subm_eval.drop(columns=f_cols_val, inplace=True)\nspred_subm_eval.columns = spred_subm.columns\nspred_subm_eval['id'] = spred_subm_eval['id'].str.replace('validation', 'evaluation')\nspred_subm = pd.concat([spred_subm, spred_subm_eval], axis=0, sort=False)\nspred_subm.reset_index(drop=True, inplace=True)\nspred_subm.to_csv('submission.csv', index=False)\nprint('submission saved:', spred_subm.shape)","04a542ff":"## Submission","e6829c4a":"# M5 CatBoost Demo","fc354700":"## Feature Importances","5cc64d86":"CatBoost is RAM expensive so I prefer to utilize GPU:","10277392":"## Prediction Loop","1aa3e49c":"## CatBoost Pool and Regression","e587eb1b":"## Data load and process functions","0ae2ada8":"This notebook is highly inspired by this work [M5 First Public Notebook Under 0.50](https:\/\/www.kaggle.com\/kneroma\/m5-first-public-notebook-under-0-50), but with [CatBoost](https:\/\/catboost.ai\/)"}}