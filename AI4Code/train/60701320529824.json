{"cell_type":{"c9358361":"code","16602caa":"code","42e6af60":"code","68b17120":"code","0e5b95d8":"code","2c6916b9":"code","29121814":"code","f634bf7a":"code","501ed464":"code","b4700e68":"code","994b79cc":"code","3eb81600":"code","7b236e0d":"code","300cae65":"code","15e8e0f7":"code","c2a3c3c5":"code","945beded":"code","34dfd0cf":"code","8e092c35":"code","069aabd6":"code","96d11c98":"code","78345ff7":"code","80aa95ac":"code","cc1c6a73":"code","e3e3970f":"code","72150b2e":"code","820b85c5":"code","86198273":"code","05499c37":"code","0879ddc8":"code","3643077e":"code","8b3619f0":"code","ff9122de":"code","5109e4b6":"code","6ad34d2c":"code","3caf182c":"code","3e394f62":"code","5a577162":"code","0ff0d52f":"code","269e0566":"code","f865e264":"code","40dd7c9b":"code","069846f5":"code","b854ef43":"code","7c2dec1f":"code","c89b08e6":"code","b3750eaa":"code","f2062ed2":"code","91e84fa4":"code","5dc2c3e6":"code","d67aa847":"code","ad3f78b5":"code","1d127d49":"code","41f4fb7f":"code","d8be8b68":"markdown","50e8b9a6":"markdown"},"source":{"c9358361":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np \nimport pandas as pd \n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","16602caa":"FILEPATH = '\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv'","42e6af60":"df = pd.read_csv(FILEPATH, encoding='iso-8859-1', engine = 'c') # engine 'c' used instead of 'python' for higher performance\ndf.sample(10)","68b17120":"# delete unnecessary cols\ncols = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n\ndf.drop(cols, axis = 1, inplace = True)","0e5b95d8":"df.head()","2c6916b9":"# Title change v1 = result, v2 = input\n\ndf.columns = ['result', 'input']\n\n# we can also use df.rename() option here","29121814":"df.head()","f634bf7a":"# reorder options - must be applicable for all cols\ndf = df[['input','result']]\n ","501ed464":"df.head()","b4700e68":"# Rename cols by using .rename - can be used for selected cols\n\ndf.rename(columns = {'input' : 'my_new_input', 'result' : 'my_new_result'}, inplace = True)","994b79cc":"df.head()","3eb81600":"df.count()","7b236e0d":"# print first string\n\ndf.iloc[1]","300cae65":"df.iloc[2][1]","15e8e0f7":"def find_message_length(msg):\n    \n    msg_words = msg.split(' ')\n    \n    msg_len = len(msg_words)\n    \n    return msg_len","c2a3c3c5":"print(find_message_length('spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.'))","945beded":"# Create a new col called 'message_word_length' showing how many words in the message\ndf['input_words_count'] = df['my_new_input'].apply(find_message_length)\ndf.head()\n\n# ref: https:\/\/rajacsp.github.io\/mlnotes\/python\/data-wrangling\/advanced-custom-lambda\/","34dfd0cf":"# show the unique labels\n\nset(df['my_new_result'])","8e092c35":"def find_length(msg):\n    \n    msg_len = len(msg)\n    \n    return msg_len","069aabd6":"print(find_length(df.iloc[0][0]))","96d11c98":"# Create a new col called 'message_word_length' showing how many words in the message\ndf['input_char_length'] = df['my_new_input'].apply(find_length)\ndf.head()","78345ff7":"# History words count\n\nimport matplotlib.pyplot as plt\n\n# to avoid popups use inline\n%matplotlib inline ","80aa95ac":"# plt.hist(data['label'], bins=3, weights=np.ones(len(data['label'])) \/ len(data['label']))\n\nimport numpy as np\n\nplt.hist(df['input_words_count'], bins = 100, weights = np.ones(len(df['input_words_count'])) \/ len(df['input_words_count']))\n\nplt.xlabel('Word Length')\nplt.ylabel('Group Count')\nplt.title('Word Length Histogram')","cc1c6a73":"# Find more than 80 words\ndf['input_words_count']","e3e3970f":"df_above_80 = df[df['input_words_count'] > 80]","72150b2e":"df_above_80.sort_values(by='input_words_count')","820b85c5":"import numpy as np\n\nplt.hist(df['input_char_length'], bins = 100, weights = np.ones(len(df['input_char_length'])) \/ len(df['input_char_length']))\n\nplt.xlabel('Char Length')\nplt.ylabel('Group Count')\nplt.title('Char Length Histogram')","86198273":"df.my_new_result.value_counts()","05499c37":"spams = df[df['my_new_result']=='spam'].iloc[: ,0]\nspams[:5]","0879ddc8":"hams = df[df['my_new_result']=='ham'].iloc[:,0]\nhams[:5]","3643077e":"plt.hist(spams.apply(lambda msg : len(msg)),bins = 100,label = 'Spams')\n\nplt.hist(hams.apply(lambda msg : len(msg)),bins=100,label='Hams',alpha=0.3)\n\nplt.xlabel('Message length')\n\nplt.ylabel('Count')\n\nplt.title('String lengths')\n\nplt.legend()\n\nplt.show()","8b3619f0":"import spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nnlp = spacy.load('en')","ff9122de":"def normalize(msg):\n    doc = nlp(msg)\n    res=[]\n    \n    for token in doc:\n        if(token.is_stop or token.is_digit or token.is_punct or not(token.is_oov)):\n            pass\n        else:\n            res.append(token.lemma_.lower())\n    return res","5109e4b6":"normalize('spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its 23 main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.')","6ad34d2c":"spam_tokens = []\nfor spam in spams:\n    spam_tokens += normalize(spam)\n    \nham_tokens = []\nfor ham in hams:\n    ham_tokens += normalize(ham)","3caf182c":"from collections import Counter","3e394f62":"most_common_tokens_in_spams = Counter(spam_tokens).most_common(20)\nmost_common_tokens_in_hams = Counter(ham_tokens).most_common(20)\n\nprint(most_common_tokens_in_spams,end=\"\\n\\n\")\nprint(most_common_tokens_in_hams)","5a577162":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer","0ff0d52f":"binary_vectorizer = CountVectorizer(binary=True)\ncount_vectorizer = CountVectorizer()\ntfidf_vectorizer = TfidfVectorizer()","269e0566":"def feature_extraction(msg):\n    \n    mat = pd.DataFrame(tfidf_vectorizer.fit_transform(msg).toarray(),columns=tfidf_vectorizer.get_feature_names(),index=None)\n    return mat","f865e264":"from sklearn.model_selection import train_test_split","40dd7c9b":"df['my_new_result']=df['my_new_result'].map({\"ham\":0,\"spam\":1})","069846f5":"k=feature_extraction(df['my_new_input'])\nprint(k.shape,df['my_new_result'].shape)","b854ef43":"train_x,train_y, test_x,test_y = train_test_split(k,df['my_new_result'], test_size=0.3)\n","7c2dec1f":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score, confusion_matrix","c89b08e6":"clfs = {\n    'mnb': MultinomialNB(),\n    'gnb': GaussianNB(),\n    'svm1': SVC(kernel='linear'),\n    'svm2': SVC(kernel='rbf'),\n    'svm3': SVC(kernel='sigmoid'),\n    'mlp1': MLPClassifier(),\n    'mlp2': MLPClassifier(hidden_layer_sizes=[100, 100]),\n    'ada': AdaBoostClassifier(),\n    'dtc': DecisionTreeClassifier(),\n    'rfc': RandomForestClassifier(),\n    'gbc': GradientBoostingClassifier(),\n    'lr': LogisticRegression()\n}","b3750eaa":"f1_scores = dict()\nfor clf_name in clfs:\n    clf = clfs[clf_name]\n    clf.fit(train_x, test_x)\n    y_pred = clf.predict(train_y)\n    f1_scores[clf_name] = f1_score(y_pred, test_y)\n    print(clf_name, f1_scores[clf_name])","f2062ed2":"solver=['lbfgs', 'sgd', 'adam']","91e84fa4":"max_f1_score = float('-inf')\nbest_solver = None\n\nfor s in solver:\n    \n    clf = MLPClassifier(solver = s)\n    clf.fit(train_x, test_x)\n    y_pred = clf.predict(train_y)\n    current_f1_score = f1_score(y_pred, test_y)\n    if current_f1_score > max_f1_score:\n        max_f1_score = current_f1_score\n        best_solver = s\n        \nprint('Best Solver: {0}'.format(best_solver))","5dc2c3e6":"alpha_values = [i * 0.1 for i in range(11)]\nmax_f1_score = float('-inf')\nbest_alpha = None\nfor alpha in alpha_values:\n    clf = MLPClassifier(solver = 'adam')\n    clf.fit(train_x, test_x)\n    y_pred = clf.predict(train_y)\n    current_f1_score = f1_score(y_pred, test_y)\n    if current_f1_score > max_f1_score:\n        max_f1_score = current_f1_score\n        best_alpha = alpha\n        \nprint('Best f1-score: {0}'.format(max_f1_score))","d67aa847":"print('Best alpha: {0}'.format(best_alpha))","ad3f78b5":"clf = MLPClassifier(solver = 'lbfgs', alpha=0.4)\nclf.fit(train_x, test_x)\ny_pred = clf.predict(train_y)\nprint(confusion_matrix(y_pred, test_y))","1d127d49":"import seaborn as sns","41f4fb7f":"sns.regplot(x=test_y,y=y_pred,marker=\"*\")","d8be8b68":"Source:\n\nhttps:\/\/docs.python.org\/3\/library\/codecs.html#standard-encodings\n\nhttps:\/\/www.kaggle.com\/devghiles\/step-by-step-solution-with-f1-score-as-a-metric\n\nTo rename:\nhttps:\/\/stackoverflow.com\/questions\/11346283\/renaming-columns-in-pandas\n\nTo change cols:\nhttps:\/\/stackoverflow.com\/questions\/12329853\/how-to-rearrange-pandas-column-sequence\/23741704\n","50e8b9a6":"# Final"}}