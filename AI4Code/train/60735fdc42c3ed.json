{"cell_type":{"0e8425ff":"code","c3439332":"code","8a8595af":"code","32b5b4e5":"code","77a31bf3":"code","1a1caca7":"code","79b02f87":"code","aac5fbd3":"code","390fe25e":"code","eb84a73a":"code","391e5b9f":"code","80a1c468":"code","c4805f63":"code","0177167d":"code","290c79d2":"code","a46fac6a":"code","23e10592":"code","be749005":"code","d35f6df0":"code","135fd4a6":"code","bacb3848":"code","9bb2937f":"code","e95a2646":"code","fbec42fb":"code","de5965ea":"code","6dc19dcb":"code","f93d9286":"code","5d7456aa":"code","83df3b75":"code","7483eb5f":"code","7386e6b6":"code","1b24ad8f":"code","41d7b987":"code","0771b48a":"code","95c51a8a":"code","3a4c91c5":"markdown","4b80d493":"markdown","276af893":"markdown","28414869":"markdown","f2e5a8ea":"markdown","03a8bd3c":"markdown","1b838090":"markdown","b9b1897b":"markdown","60b65daf":"markdown","4c3e2677":"markdown","f428be98":"markdown","f52d3564":"markdown","f09aaeb7":"markdown"},"source":{"0e8425ff":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","c3439332":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","8a8595af":"train.head()","32b5b4e5":"train.shape","77a31bf3":"train.columns","1a1caca7":"train.describe()","79b02f87":"train.info()","aac5fbd3":"train.dtypes","390fe25e":"train.notnull().sum()","eb84a73a":"train.notnull().sum()\/len(train)*100","391e5b9f":"train.notnull().sum()*100\/len(train) > 30","80a1c468":"train.columns[train.notnull().sum()*100\/len(train) > 30] #selecting 30% filled column","c4805f63":"train.Sex.value_counts()","0177167d":"train.Age.value_counts(dropna=False)","290c79d2":"train.Age.isnull().sum()","a46fac6a":"train.Age.notnull().sum()\n","23e10592":"survived = train[train.Survived == 1]\nprint('Total Survived :', len(survived))\nprint('Female Survived :', len(survived[survived.Sex == 'female']))\nprint('Male Survived : ', len(survived[survived.Sex == 'male']))","be749005":"died = train[train.Survived == 0]\nprint('Toatal died :', len(died))\nprint('Female died :', len(died[died.Sex == 'female']))\nprint('male died :', len(died[died.Sex == 'male']))","d35f6df0":"f,ax=plt.subplots(1,2,figsize=(10,5))\ntrain['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Survived')\nax[0].set_ylabel('')\nsns.countplot('Survived',data=train,ax=ax[1])\nax[1].set_title('Survived')\nplt.show()","135fd4a6":"!pip install pycaret","bacb3848":"# we should do this step at the beginning but for understaning I'm Installing & Importing Pycaret.classification\nfrom pycaret import classification","9bb2937f":"classification_setup = classification.setup(data=train,target='Survived')","e95a2646":"classification.compare_models()","fbec42fb":"# Create Xgboost model\nclassification_dt = classification.create_model('dt')","de5965ea":"# Tune the model\ntune_dt = classification.tune_model(classification_xgb)","6dc19dcb":"# build the lightgbm model\nclassification_catboost = classification.create_model('catboost')","f93d9286":"# Tune lightgbm model\ntune_catboost = classification.tune_model(classification_catboost)","5d7456aa":"# Residual Plot\nclassification.plot_model(tune_catboost)","83df3b75":"# Error Plot\nclassification.plot_model(tune_catboost, plot = 'error')","7483eb5f":"# Feature Important plot\nclassification.plot_model(tune_catboost, plot='feature')","7386e6b6":"# Evaluate model\nclassification.evaluate_model(tune_catboost)","1b24ad8f":"# make predictions\npredictions = classification.predict_model(tune_dt, data=test)\n# view the predictions\npredictions","41d7b987":"# make predictions\npredictions = classification.predict_model(tune_catboost, data=test)\n# view the predictions\npredictions","0771b48a":"submissions=pd.DataFrame({\"PassengerId\": predictions['PassengerId'],\n                         \"Survived\": predictions['Label']})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)","95c51a8a":"submissions","3a4c91c5":"As PyCaret module is not preinstalled we'll install it using ***!pip install pycaret***","4b80d493":"<p><center> <h3>More code is coming Soon. Please upvote you will get notifications with additions.<\/h3><\/center> <\/p>\n\n<center><img src=\"https:\/\/cdn.dribbble.com\/users\/32897\/screenshots\/3564812\/1.gif\" width= 600px length=600px><\/center>","276af893":"## Loading the data \ud83d\udcc1 ","28414869":"## Importing Python Libraries  \ud83d\udcd8\n- Libraries are important and we call them to perform the different actions on our data and for training the models.\n- Its a first step to load the library to perform the specific task","f2e5a8ea":"<div class=\"alert alert-block alert-info\">  \n \n<hr>\n<b>Data Description: <\/b> \n<hr> \n    <p>The data has been split into two groups:\n\n<li>training set (train.csv)\n<li>test set (test.csv)<br>\n    \nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the \u201cground truth\u201d) for each passenger. Your model will be based on \u201cfeatures\u201d like passengers\u2019 gender and class. You can also use feature engineering to create new features.\n\nThe test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n\nWe also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like..<\/p>\n <a href=\"https:\/\/www.kaggle.com\/c\/titanic\/data\">https:\/\/www.kaggle.com\/c\/titanic\/data<\/a>  \n<\/div>","03a8bd3c":"\n<p><center> <h1>Predictive Analysis using PyCaret .<\/h1><\/center> <\/p>\n<center><img src= \"https:\/\/miro.medium.com\/max\/1024\/1*Cku5-rqmqSIuhUyFkIAdIA.png\" width = 600px height=300px> <\/center>","1b838090":"## Data Exploration \/ Exploratory data analysis \ud83d\udd0e","b9b1897b":"<div class=\"alert alert-block alert-success\">  \n \n<hr>\n<b>Source of Data: <\/b> \n<hr> \n <a href=\"https:\/\/www.kaggle.com\/c\/titanic\/data\">https:\/\/www.kaggle.com\/c\/titanic\/data<\/a>\n   \n<\/div>","60b65daf":"<div class=\"alert alert-block alert-info\">  \n    <h3><strong>\ud83d\udcd6 Titanic - Machine Learning from Disaster \ud83d\ude37<\/strong><\/h3>\n    <h4><strong><li>Start here! Predict survival on the Titanic and get familiar with ML basics<\/strong><\/h4>\n<\/div>","4c3e2677":"<center><img src = \"https:\/\/i.gifer.com\/5SlH.gif\"><\/center>","f428be98":"It is evident that not many passengers survived the accident. \n\nOut of 891 passengers in training set, only around 350 survived i.e Only **38.4%** of the total training set survived the crash. We need to dig down more to get better insights from the data and see which categories of the passengers did survive and who didn't.\n\nWe will try to check the survival rate by using the different features of the dataset. Some of the features being Sex, Port Of Embarcation, Age,etc.\n\nFirst let us understand the different types of features.","f52d3564":"<div class=\"alert alert-block alert-info\">  \n \n<hr>\n<b>Objectives: <\/b> \n<hr> \n    <p> \n<li> Uncover the insights in the data using <strong>Data exploration<\/strong><\/li>\n<li> Visualize those insights using <strong>Data visulaization<\/strong> <\/li>\n<li> The main thing we'll do is use <strong>PyCaret<\/strong> which is a low level Open source library to use different algo with small piece of code <\/li><\/p>\n   \n<\/div>","f09aaeb7":"## Data Visualization  \ud83d\udcca\nLet's start with the data visualization from the same insights that we had found about survived people's"}}