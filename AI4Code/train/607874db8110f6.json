{"cell_type":{"924e380d":"code","72bcc45f":"code","c4d4f97e":"code","ee75ceb7":"code","2203eb45":"code","af536ef8":"code","d5f4d06a":"markdown","7685da47":"markdown"},"source":{"924e380d":"!pip install nlpaug\nimport nlpaug.augmenter.word as naw","72bcc45f":"import os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport random\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\n\nimport warnings\nwarnings.filterwarnings('ignore')","c4d4f97e":"def seed_everything(seed = 0):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 0\nseed_everything(seed)\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_colwidth', 150)","ee75ceb7":"base_dir = '..\/input\/step-1-create-folds'\ntrain = pd.read_csv(f'{base_dir}\/train_folds.csv')\ntrain.head()","2203eb45":"actions = ['insert', 'substitute']\nmodel_paths = ['bert-base-cased', 'distilbert-base-cased', 'roberta-base', 'xlnet-base-cased']\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodels = []\nfor action in actions:\n    for model_path in model_paths:\n        print(f'Model: {model_path} - Action: {action}')\n        models.append(naw.ContextualWordEmbsAug(model_path = model_path, action = action, device = 'cuda'))","af536ef8":"train_augmented = []\nfor fold in range(5):\n    print('*' * 50)\n    print(f'Fold: {fold}')\n    \n    data = train[train['kfold'] == fold]\n\n    for i, model in enumerate(tqdm(models)):\n        data[f'excerpt_augmented_{i}'] = data['excerpt'].apply(lambda x: model.augment(x))\n        \n    train_augmented.append(data)\n\ntrain_augmented = pd.concat(train_augmented).to_csv('train_augmented.csv', index = None)","d5f4d06a":"# Import data","7685da47":"# Augmentation"}}