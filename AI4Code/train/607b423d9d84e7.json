{"cell_type":{"df205701":"code","c31d131b":"code","ad2866fb":"code","6c8ba570":"code","a079a426":"code","f573f107":"code","5a9e9b89":"code","e89ebe1a":"code","5085d585":"code","ffa4fe4b":"code","a9c4c478":"code","94def320":"code","5c3e3695":"markdown","82bced54":"markdown","eefc1a23":"markdown","f102be01":"markdown","544d4846":"markdown","dc290c33":"markdown","c0732cc5":"markdown","0e75316a":"markdown","802d2eaf":"markdown","60b52fd3":"markdown","3cea5471":"markdown"},"source":{"df205701":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import ElasticNet\n\nprint(os.listdir(\"..\/input\"))","c31d131b":"def read_data(file_name):\n    df = pd.read_csv(file_name)    \n    Y = df['target']\n    X = df.drop(columns=['target','id'])\n    return X, Y\n\n# load training data\nX_train, Y_train = read_data('..\/input\/train.csv')\n\n# load testing data\nX_test = pd.read_csv('..\/input\/test.csv').drop(columns=['id'])\n\nprint(X_train.shape, Y_train.shape, X_test.shape)","ad2866fb":"X_train.head()","6c8ba570":"sns.countplot(Y_train)","a079a426":"X_train.isnull().values.any()","f573f107":"X_test.isnull().values.any()","5a9e9b89":"X_train.describe()","e89ebe1a":"sc = StandardScaler()\n\n# convert to numpy array\nX_train = X_train.values\nY_train = Y_train.values\nX_test = X_test.values\n\n# transform\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.fit_transform(X_test)","5085d585":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(6, 5))\n\nax1.set_title('Before Scaling')\nfor i in range(2):\n    sns.kdeplot(X_train[i], ax=ax1)\n\nax2.set_title('After Standard Scaler')\nfor i in range(2):\n    sns.kdeplot(X_train_scaled[i], ax=ax2)\nplt.show()","ffa4fe4b":"best_parameters = { \n                    'alpha': 0.198, \n                    'l1_ratio': 0.3, \n                    'precompute': True, \n                    'selection': 'random', \n                    'tol': 0.001,\n                    'random_state': 19\n                }\n\nnet = ElasticNet(**best_parameters)\nnet.fit(X_train_scaled, Y_train)","a9c4c478":"submission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['target'] = net.predict(X_test_scaled)\nsubmission.to_csv('submission.csv', index=False)","94def320":"submission.head(10)","5c3e3695":"Let's display some rows","82bced54":"# 3. Standardize the training\/test data","eefc1a23":"As can be seen from above table, training examples are zero-centered (**mean**)  and have one standard deviation (**std**). In this case, there is no need to standardize the training data (Step 3 can be skipped somehow).","f102be01":"# 4. Train the model","544d4846":"And let's plot the target's frequency","dc290c33":"Let's plot the training data distribution before\/after scaling (only 2 rows)","c0732cc5":"# Contents\n1. Load the training\/test data\n2. Checking missing values\n3. Standardize the training\/test data\n4. Train the model\n5. Predict the test data","0e75316a":"# **1. Load the training\/test data**","802d2eaf":"# 5. Predict the test data","60b52fd3":"# 2. Checking missing values","3cea5471":"## Please upvote if you like this kernel. Thank you :)"}}