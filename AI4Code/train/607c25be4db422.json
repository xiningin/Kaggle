{"cell_type":{"72df827a":"code","48e7e4f3":"code","797f698f":"code","e08eb201":"code","e92bba9a":"code","579a173d":"code","d73e4a2d":"code","4338c141":"code","cc91d82f":"code","ba136ecf":"code","ad6d4efb":"code","f7d3b899":"code","140250cf":"code","328bd891":"code","d69794e2":"code","23b85148":"code","dc93eb60":"code","039b2e38":"code","565f7c19":"markdown","dd0e4d10":"markdown","40cd0f07":"markdown","b2b6e3c1":"markdown","536ff0e6":"markdown","c94added":"markdown","66065540":"markdown","47b7d69d":"markdown","afe7408e":"markdown","0275e72a":"markdown","88fbdd3b":"markdown","c0e176c7":"markdown","fbfc7f99":"markdown","ad09beff":"markdown","07ec0d14":"markdown","08eb8d43":"markdown","401b1fa2":"markdown","938cb5b9":"markdown","b6828c65":"markdown","af8c4569":"markdown"},"source":{"72df827a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","48e7e4f3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","797f698f":"data = pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","e08eb201":"data.head(3)","e92bba9a":"data.info()","579a173d":"data.describe().T","d73e4a2d":"sns.pairplot(data, hue='quality', palette='husl')","4338c141":"sns.pairplot(data, kind='reg')","cc91d82f":"plt.figure(figsize=(14,12))\nsns.heatmap(data.corr(), linewidth=0.2, cmap=\"YlGnBu\", annot=True)","ba136ecf":"plt.figure(figsize=(24,6))\nsns.boxplot(data=data)","ad6d4efb":"fig,axes = plt.subplots(3,2, figsize=(20,12))\nsns.barplot(x='quality', y='volatile acidity', data=data, ax=axes[0][0])\nsns.barplot(x='quality', y='citric acid', data=data, ax=axes[0][1])\nsns.barplot(x='quality', y='chlorides', data=data, ax=axes[1][0])\nsns.barplot(x='quality', y='sulphates', data=data, ax=axes[1][1])\nsns.barplot(x='quality', y='alcohol', data=data, ax=axes[2][0])\n","f7d3b899":"x = data.loc[:,data.columns != 'quality']\ny = data.loc[:,data.columns == 'quality']\nx = np.array(x)\ny = np.array(y)\n\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=100,max_depth=300,random_state=42)\nclf.fit(x_train, y_train)\npredict = clf.predict(x_test)\n\nfrom sklearn import metrics\nprint('Accuracy :: ',metrics.accuracy_score(y_test,predict)*100, ' Percent ')","140250cf":"data1 = data","328bd891":"data1['quality'].values[data1['quality']<6] = 0 \ndata1['quality'].values[data1['quality']>5] = 1","d69794e2":"data1.quality.value_counts()","23b85148":"data1.quality = data1.quality.astype('category')","dc93eb60":"data1.dtypes","039b2e38":"x = data1.loc[:,data1.columns != 'quality']\ny = data1.loc[:,data1.columns == 'quality']\nx = np.array(x)\ny = np.array(y)\n\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.29,random_state=7)\n\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=1000,max_depth=1700,random_state=7)\nclf.fit(x_train, y_train)\npredict = clf.predict(x_test)\n\nfrom sklearn import metrics\nprint('Accuracy :: ',metrics.accuracy_score(y_test,predict)*100, ' Percent ')","565f7c19":"## BOXPLOT\n_FOR POINTING OUTLIERS_","dd0e4d10":"# EDA","40cd0f07":"### HEATMAP","b2b6e3c1":"<div id=\"\">","536ff0e6":"_IMPORTING NECESSARY LIBRARIES_","c94added":"<div id=\"pre-processing\">\n    <h2> Pre-Processing <\/h2>\n<\/div>\n_PEEKING INTO DATAFRAME_","66065540":"#### INFORMATION ABOUT COLUMNS OF DATAFRAME'S\n_Checking COLUMN NAMES, NUMBER OF OBSERVATIONS, NULL VALUES and DATATYPES_","47b7d69d":"#### List of Input Files","afe7408e":"<h1>Table of contents<\/h1>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ol>\n        <li><a href=\"#about_dataset\">About the dataset<\/a><\/li>\n        <li><a href=\"#import_data\">Importing the Data<\/a><\/li>\n        <li><a href=\"#pre-processing\">Pre-processing<\/a><\/li>\n        <li><a href=\"#visualization\">Visualization<\/a><\/li>\n        <li><a href=\"#modeling\">Modeling, Prediction, Evaluation<\/a><\/li> \n    <\/ol>\n<\/div>\n<br>\n<hr>","0275e72a":"Changing numerical value into Category","88fbdd3b":"### Analysing effects of various _COMPONENTS_ On _QUALITY_ of the Wine","c0e176c7":" Converting __wine_quality > 5 as 1__ (GOOD) and\n            __wine_quality <= 5 as 0__ (BAD)\n\n#### This will enable us to categories test_samples into GOOD or BAD","fbfc7f99":"<div id=\"about_dataset\">\n    <h2> About The Dataset <\/h2>\nThe two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine. For more details, consult the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\n\nThese datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are much more normal wines than excellent or poor ones).\n\nThis dataset is also available from the UCI machine learning repository, https:\/\/archive.ics.uci.edu\/ml\/datasets\/wine+quality\n\n<\/div>","ad09beff":"### PAIRPLOT SHOWING RELATION AMONG ATTRIBUTES OF THE DATA","07ec0d14":"<div id=\"modeling\"> <\/div>\n# Random Forest Classifier","08eb8d43":"_STASTISTICAL ANALYSIS OF THE DataFrame_","401b1fa2":"### PAIRPLOTS OF ATTRIBUTES WITH LINEAR REGRESSION","938cb5b9":"<div id=\"import_data\">\n    <h2> Import Data <\/h2>\n    _READING THE DATA INTO A PANDAS DATAFRAME_\n<\/div>\n","b6828c65":"### Observation :-\n\n> 1. QUALITY increases as Volatile Acidity decreases.\n> 2. QUALITY increases as Citric Acid increases.\n> 3. QUALITY increases as Chlorides decreases.\n> 4. QUALITY increases as Sulphates' quantity increases.\n> 5. QUALITY increases as Alcohal quantity increases.__","af8c4569":"<div id= \"visualization\">\n    <h2> Visualization <\/h2>\n<\/div>"}}