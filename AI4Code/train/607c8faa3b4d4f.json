{"cell_type":{"5d42ac7f":"code","747a73da":"code","01dcbb34":"code","da28dbc4":"code","4c28c25b":"code","34270459":"code","114dcba6":"code","c5074265":"code","2f424f2f":"code","c6e767d5":"code","1a0d9a15":"code","6e625692":"code","392f4736":"code","240fa38c":"code","a5cc8d2c":"code","0d1b0b24":"code","61e1e300":"code","10a20865":"code","e6c788bd":"code","9b551e72":"code","b5f10532":"code","d118967c":"code","938efcbf":"code","337d3796":"code","f9220119":"code","298df270":"code","bb3f9f6c":"code","adc65e05":"code","f0608049":"code","4e23e28f":"code","293f9d0f":"code","fdaad822":"code","f5e42b09":"code","9902146a":"code","adf913db":"code","9c6d9f94":"code","f709fa8f":"code","0991b9c1":"code","70671cd7":"code","606ac6ad":"code","6420db87":"code","a2eec335":"code","e646e1c1":"code","322280ec":"code","f7ed1179":"code","4ce54941":"code","eeb130ee":"code","1927ccf2":"code","61fdf390":"code","aac7829f":"code","abddd597":"code","ba43721b":"code","eaa58a40":"code","fbe666ef":"code","5adb95d1":"code","229594c3":"code","d59f2b03":"code","a1f45a0d":"code","040a872a":"code","beb6cb68":"code","e0b1bd92":"code","11dea3d7":"code","d3137a9b":"code","097192be":"code","cd1c8ae2":"code","39d1878a":"code","06f7ebe9":"code","51448c95":"code","a7f5e70f":"code","5b9f9f77":"code","ceb29232":"code","d27eca9b":"code","3c44821a":"code","fe58cf67":"code","dfbdca2e":"code","14b28e19":"code","6999dccb":"code","3273f792":"code","730716ef":"code","3619af78":"code","59031d6b":"code","cdd23e0a":"code","9a0510ac":"code","253f5588":"code","ce08afa0":"code","f15c50ed":"code","4ff47d4c":"code","eaab5dce":"code","d2c649db":"code","93d392b3":"code","3494b65f":"markdown","b3be782f":"markdown","33561aa8":"markdown","7b18238a":"markdown","7865351c":"markdown","cff2a2c1":"markdown","201817dd":"markdown","396fed75":"markdown","f8b21cbc":"markdown","b8d0ec42":"markdown","0dbc90d5":"markdown","28dc4174":"markdown","99c51406":"markdown","54cd6b81":"markdown","16c61c6e":"markdown","e640563b":"markdown","c6d81f4c":"markdown","24fad3a1":"markdown","90ac2221":"markdown","5c7991ab":"markdown","b1678926":"markdown","9a3fd789":"markdown","bf366c93":"markdown","eaf27bd2":"markdown","45b00112":"markdown","17bf48f0":"markdown","1adcb97e":"markdown","de038bad":"markdown","f2aa616d":"markdown","cc4e61a4":"markdown","88c5a23a":"markdown","9f3f5032":"markdown"},"source":{"5d42ac7f":"%matplotlib inline\n\nimport math, time, random, datetime\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns","747a73da":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize, StandardScaler","01dcbb34":"from sklearn.metrics import mean_absolute_error as MAE\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.preprocessing import OneHotEncoder","da28dbc4":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier","4c28c25b":"from catboost import CatBoostClassifier, Pool, cv","34270459":"# Voting Classifier\nfrom sklearn.ensemble import VotingClassifier","114dcba6":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV","c5074265":"train_data_path = \"..\/input\/titanic\/train.csv\"\ntest_data_path = \"..\/input\/titanic\/test.csv\"","2f424f2f":"train_data = pd.read_csv(train_data_path)\ntest_data = pd.read_csv(test_data_path)","c6e767d5":"train_data.head(20)","1a0d9a15":"test_data.head(10)","6e625692":"len(train_data)","392f4736":"train_data.info()","240fa38c":"test_data.info()","a5cc8d2c":"train_data.describe()","0d1b0b24":"train_data.columns","61e1e300":"num_var = ['Age', 'SibSp', 'Parch', 'Fare']\ncat_var = ['Survived', 'Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked']","10a20865":"df_num = train_data[num_var]\ndf_cat = train_data[cat_var]","e6c788bd":"df_num.head()","9b551e72":"df_cat.head()","b5f10532":"for i in df_num.columns:\n    plt.hist(df_num[i])\n    plt.title(i)\n    plt.show()","d118967c":"# Correlations\nprint(df_num.corr())\nsns.heatmap(df_num.corr());","938efcbf":"train_data[['Survived'] + num_var]","337d3796":"# Correlations with 'Survived'\nprint(train_data[['Survived']+num_var].corr())\nsns.heatmap(train_data[['Survived']+num_var].corr());","f9220119":"# Pivot Table num variables\npd.pivot_table(train_data, index='Survived', values = num_var)","298df270":"for i in df_cat.columns:\n    sns.barplot(df_cat[i].value_counts().index,\n               df_cat[i].value_counts()).set_title(i)\n    plt.show()","bb3f9f6c":"[i for i in cat_var if i not in ['Survived', 'Ticket']]","adc65e05":"# Pivot Table for categorical variables\nfor cat in [i for i in cat_var if i not in ['Survived', 'Ticket']]:\n    print('\\033[1m' + cat + ':\\033[0m')\n    print(pd.pivot_table(train_data, index='Survived', columns=cat, values='Ticket', aggfunc='count'))\n    print()","f0608049":"# Multiple Cabins\ntrain_data['cabin_count'] = train_data.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split()))\ntrain_data['cabin_count'].value_counts()","4e23e28f":"train_data.head()","293f9d0f":"# Pivot Table Cabin Count\npd.pivot_table(train_data, index='Survived', columns='cabin_count', values='Ticket', aggfunc='count')","fdaad822":"# Create categories based on Cabin letters (n stands for null)\ntrain_data['cabin_adv'] = train_data.Cabin.apply(lambda x: str(x)[0])\ntrain_data['cabin_adv'].value_counts()","f5e42b09":"# Pivot Table for cabin adverb\npd.pivot_table(train_data, index='Survived', columns='cabin_adv', values='Ticket', aggfunc='count')","9902146a":"# numeric vs non numeric ticket\ntrain_data['numeric_ticket'] = train_data.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\ntrain_data['numeric_ticket']","adf913db":"pd.pivot_table(train_data, index='Survived', columns='numeric_ticket', values='Ticket', aggfunc='count')","9c6d9f94":"print(142\/88, 407\/254)","f709fa8f":"# name title\ntrain_data['name_title'] = train_data.Name.apply(lambda x: x.split(',', 1)[1].split('.', 1)[0])\ntrain_data['name_title']","0991b9c1":"train_data['name_title'].value_counts()","70671cd7":"def feature_engineer_df(df):\n    '''\n    This function will apply Feature Engineering on given dataframe.\n    '''\n    \n    # Multiple Cabins\n    print(\"adding column 'cabin_count'...\")\n    df['cabin_count'] = df.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split()))\n    \n    # Create categories based on Cabin letters (n stands for null)\n    print(\"adding column 'cabin_adv'...\")\n    df['cabin_adv'] = df.Cabin.apply(lambda x: str(x)[0])\n    \n    # numeric vs non numeric ticket\n    print(\"adding column 'numeric_ticket'...\")\n    df['numeric_ticket'] = df.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\n    \n    # name title\n    print(\"adding column 'name_title'...\")\n    df['name_title'] = df.Name.apply(lambda x: x.split(',', 1)[1].split('.', 1)[0])\n    \n    \n    # impute null values for continuos data\n    print('imputing null values...')\n    \n    print(\"adding column 'age missing'...\")\n    df['age_missing'] = df.Age.apply(lambda x: 1 if pd.isnull(x) else 0)\n    df.Age = df.Age.fillna(df.Age.mean())\n    \n    print(\"adding column 'fare_missing'...\")\n    df['fare_missing'] = df.Fare.apply(lambda x: 1 if pd.isnull(x) else 0)\n    df.Fare = df.Fare.fillna(df.Fare.median())\n    \n    # drop missing 'embarked' rows (there are only 2 rows with missing 'embarked' in train_data and 0 in test_data)\n    print(\"dropping rows with missing 'Embarked'...\")\n    print(f\"{np.count_nonzero(df['Embarked'].isnull().values)} rows with missing 'Embarked' will be dropped\")\n    df.Embarked = df.dropna(subset=['Embarked'])\n    \n    # normalize sibsp\n    print(\"normalizing 'sibsp'...\")\n    df['norm_sibsp'] = np.log(df.SibSp+1)\n    \n    # normalize fare\n    print(\"normalizing 'fare'...\")\n    df['norm_fare'] = np.log(df.Fare+1)","606ac6ad":"def solve_mismatch(df_train, df_test):\n    # combine train and test dataframes\n    df_train['train_data'] = 1\n    df_test['train_data'] = 0\n    df_test['Survived'] = 0\n    combined_df = pd.concat([df_train, df_test])\n    \n    # convert fare to category for pd.get_dummies()\n    combined_df.Pclass = combined_df.Pclass.astype(str)\n    \n    # create dummy variables from categories\n    combined_dummy = pd.get_dummies(combined_df[['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'norm_fare', 'Embarked', 'cabin_adv',\n                                  'cabin_count', 'numeric_ticket', 'name_title', 'age_missing', 'fare_missing', 'train_data']])\n    \n    # seperate datasets\n    new_train = combined_dummy[combined_dummy['train_data']==1]\n    new_test = combined_dummy[combined_dummy['train_data']==0]\n    new_train.drop(['train_data'], axis=1, inplace=True)\n    new_test.drop(['train_data', 'Survived'], axis=1, inplace=True)\n    \n    return(new_train, new_test)","6420db87":"def ft_splitted(df, drop=['Survived', 'PassengerId']):\n    X = df.drop(drop, axis=1)\n    y = df[drop[0]]\n    return([X, y])","a2eec335":"feature_engineer_df(train_data)","e646e1c1":"train_data.head()","322280ec":"train_data['age_missing'].value_counts()","f7ed1179":"feature_engineer_df(test_data)","4ce54941":"test_data.head()","eeb130ee":"test_data['age_missing'].value_counts()","1927ccf2":"train_data, test_data = solve_mismatch(train_data, test_data)","61fdf390":"train_data.head()","aac7829f":"test_data.head()","abddd597":"X_train, y_train = ft_splitted(train_data)","ba43721b":"X_train.head()","eaa58a40":"y_train.head()","fbe666ef":"def scale_data(X):\n    scale = StandardScaler()\n    X_scaled = X.copy()\n    X_scaled[['Age', 'SibSp', 'Parch', 'norm_fare']] = scale.fit_transform(X_scaled[['Age', 'SibSp', 'Parch', 'norm_fare']])\n    return(X_scaled)","5adb95d1":"X_train_scaled = scale_data(X_train)\nX_train_scaled.head()","229594c3":"X_test_scaled = scale_data(test_data.drop(['PassengerId'], axis=1))\nX_test_scaled.head()","d59f2b03":"def get_model_accuracy(model, cv=5):\n    cv_score = cross_val_score(model, X_train_scaled,  y_train, cv=cv)\n    print(cv_score)\n    print(f\"{model.__class__.__name__} ({format(cv_score.mean()*100, '.2f')}%)\")\n    return(cv_score.mean())","a1f45a0d":"# Naive Bayes \/ GaussianNB algorithm\nGNB = GaussianNB()\nget_model_accuracy(GNB)","040a872a":"# Logistic Regression\nLR = LogisticRegression()\nget_model_accuracy(LR)","beb6cb68":"# Support Vector Classifier\nSVC = svm.SVC(probability=True)\nget_model_accuracy(SVC)","e0b1bd92":"# KNeighborsClassifier\nKNN = KNeighborsClassifier()\nget_model_accuracy(KNN)","11dea3d7":"# RandomForestClassifier\nRFC = RandomForestClassifier(random_state=42)\nget_model_accuracy(RFC)","d3137a9b":"# GradientBoostingClassifier\nGB = GradientBoostingClassifier(random_state=42)\nget_model_accuracy(GB)","097192be":"voting_clf_all = VotingClassifier(\n    estimators=[('GNB', GNB), ('LR', LR), ('SVC', SVC), ('KNN', KNN), ('RFC', RFC), ('GB', GB)],\n    voting='soft')\nget_model_accuracy(voting_clf_all)","cd1c8ae2":"voting_clf_best_3 = VotingClassifier(\n    estimators=[('SVC', SVC), ('RFC', RFC), ('KNN', KNN)],\n    voting='soft')\nget_model_accuracy(voting_clf_best_3)","39d1878a":"def clf_performance(classifier):\n    print(classifier.__class__.__name__)\n    print(f\"Best Score: {classifier.best_score_}\")\n    print(f\"Best Parameters: {classifier.best_params_}\")","06f7ebe9":"def print_valid_params(params):\n    '''\n    String input of params;\n    all the single quotes will be removed so String values will have to be quotes again;\n    '''\n    print(params.replace(':', '=').replace('\\'', ''))","51448c95":"param_grid = {\n    'random_state': [42],\n    'max_iter': [100, 500, 2000],\n    'penalty': ['l1', 'l2'],\n    'C': np.logspace(-4, 4, 20),\n    'solver': ['liblinear', 'lbfgs']\n}\nclf_LR = GridSearchCV(LR, param_grid=param_grid, cv=5, verbose=True, n_jobs=-1)\nbest_clf_LR = clf_LR.fit(X_train_scaled, y_train)\nclf_performance(best_clf_LR)","a7f5e70f":"print_valid_params(\"'C': 11.288378916846883, 'max_iter': 100, 'penalty': 'l1', 'random_state': 42, 'solver': 'liblinear'\")","5b9f9f77":"tuned_LR = LogisticRegression(C= 11.288378916846883, max_iter= 100, penalty= 'l1', random_state= 42, solver= 'liblinear')\nget_model_accuracy(tuned_LR)","ceb29232":"# param_grid = {\n#     'random_state': [42],\n#     'C': [.1, 1, 10, 100],\n#     'kernel': ['rbf', 'linear', 'poly'],\n#     'gamma': ['scale', 'auto']\n# }\n# Result: Best Score: 0.8282781997363632; Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf', 'random_state': 42};\nparam_grid = {\n    'random_state': [42],\n    'C': [.1, .3, 1, 3],\n    'kernel': ['rbf'],\n    'gamma': [.03, .1, .3, 1]\n}\nclf_SVC = GridSearchCV(SVC, param_grid=param_grid, cv=5, verbose=True, n_jobs=-1)\nbest_clf_SVC = clf_SVC.fit(X_train_scaled, y_train)\nclf_performance(best_clf_SVC)","d27eca9b":"print_valid_params(\"'C': 3, 'gamma': 0.03, 'kernel': 'rbf', 'random_state': 42\")","3c44821a":"tuned_SVC = svm.SVC(C= 3, gamma= 0.03, kernel= 'rbf', random_state= 42, probability=True)\nget_model_accuracy(tuned_SVC)","fe58cf67":"param_grid = {\n    'n_neighbors': [3, 5, 7, 9],\n    'weights': ['uniform', 'distance'],\n    'algorithm': ['auto', 'ball_tree', 'kd_tree'],\n    'p': [1, 2]\n}\nclf_KNN = GridSearchCV(KNN, param_grid=param_grid, cv=5, verbose=True, n_jobs=-1)\nbest_clf_KNN = clf_KNN.fit(X_train_scaled, y_train)\nclf_performance(best_clf_KNN)","dfbdca2e":"print_valid_params(\"'algorithm': 'auto', 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'\")","14b28e19":"tuned_KNN = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 7, p= 2, weights= 'uniform')\nget_model_accuracy(tuned_KNN)","6999dccb":"param_grid = {\n    'random_state': [42],\n    'n_estimators': [10, 30, 100, 300, 1000],\n    'bootstrap': [True, False],\n    'max_depth': [1, 3, 10, 30, 100, None],\n    'max_features': ['auto', 'sqrt'],\n    'min_samples_leaf': [1, 3, 10, 30],\n    'min_samples_split': [2, 4, 7, 10]\n}\nclf_RFC = RandomizedSearchCV(RFC, param_distributions=param_grid, n_iter=100, cv=5, verbose=True, n_jobs=-1)\nbest_clf_RFC = clf_RFC.fit(X_train_scaled, y_train)\nclf_performance(best_clf_RFC)","3273f792":"print_valid_params(\"'random_state': 42, 'n_estimators': 30, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False\")","730716ef":"tuned_RFC = RandomForestClassifier(random_state= 42, n_estimators= 30, min_samples_split= 7, min_samples_leaf= 1, max_features= 'sqrt', max_depth= None, bootstrap= False)\nget_model_accuracy(tuned_RFC)","3619af78":"tuned_RFC.fit(X_train_scaled, y_train)\nfeature_importances = pd.Series(tuned_RFC.feature_importances_, index=X_train_scaled.columns)\nfeature_importances.nlargest(20).plot(kind='barh')","59031d6b":"param_grid = {\n    'random_state': [42],\n    'n_estimators': [100, 300],\n    'learning_rate': [.1, .3, 1],\n    'max_depth': [1, 2, 3, 10],\n    'min_samples_split': [.1, .3, 1, 3, 10],\n    'min_samples_leaf': [.1, .3, 1, 3]\n}\nclf_GB = GridSearchCV(GB, param_grid=param_grid, cv=5, verbose=True, n_jobs=-1)\nbest_clf_GB = clf_GB.fit(X_train_scaled, y_train)\nclf_performance(best_clf_GB)","cdd23e0a":"print_valid_params(\"'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 0.1, 'n_estimators': 300, 'random_state': 42\")","9a0510ac":"tuned_GB = GradientBoostingClassifier(learning_rate= 0.1, max_depth= 3, min_samples_leaf= 3, min_samples_split= 0.1, n_estimators= 300, random_state= 42)\nget_model_accuracy(tuned_GB)","253f5588":"params = {\n    'weights': [[1, 1, 1], [1, 1, 2], [1, 2, 1], [2, 1, 1], [1, 2, 2], [2, 1, 2], [2, 2, 1]]\n}\nvote_weight = GridSearchCV(voting_clf_best_3, param_grid=params, cv=5, verbose=True, n_jobs=-1)\nbest_clf_weight = vote_weight.fit(X_train_scaled, y_train)\nclf_performance(best_clf_weight)","ce08afa0":"print_valid_params(\"'weights': [1, 1, 2]\")","f15c50ed":"weighted_voting_clf_best_3 = VotingClassifier(\n    estimators=[('SVC', SVC), ('RFC', RFC), ('KNN', KNN)],\n    voting='soft',\n    weights= [1, 1, 2]\n)\nget_model_accuracy(weighted_voting_clf_best_3)","4ff47d4c":"def submission_to_csv(y_preds, filename='submission.csv'):\n    submission = {'PassengerId': test_data.PassengerId, 'survived': y_preds}\n    submission_df = pd.DataFrame(data=submission)\n    submission_csv = submission_df.to_csv(filename, index=False)\n    return(submission_csv)","eaab5dce":"# Random Forest Classifier\ntuned_RFC.fit(X_train_scaled, y_train)\ntuned_RFC_preds = tuned_RFC.predict(X_test_scaled)\nsubmission_to_csv(tuned_RFC_preds, 'RFC_submission.csv')","d2c649db":"# Gradient Boosting\ntuned_GB.fit(X_train_scaled, y_train)\ntuned_GB_preds = tuned_GB.predict(X_test_scaled)\nsubmission_to_csv(tuned_GB_preds, 'GB_clf_submission.csv')","93d392b3":"# Weighted Soft Voting Classifier\nweighted_voting_clf_best_3.fit(X_train_scaled, y_train)\nweighted_voting_clf_best_3_preds = weighted_voting_clf_best_3.predict(X_test_scaled)\nsubmission_to_csv(weighted_voting_clf_best_3_preds, 'soft_voting_clf_submission.csv')","3494b65f":"## Tuning Different Models","b3be782f":"## Model Score before and after Tuning\n\n| Model Name | Before Tuning | After Tuning |\n|------------|---------------|--------|\n| GaussianNB | 39.06% | N\/A |\n| LogisticRegression| 81.93% | 82.49% |\n| SVC | 82.83% | 83.05% |\n| KNeighborsClassifier | 82.50% | 82.72% |\n| RandomForestClassifier | 83.05% | 83.50% |\n| GradientBoostingClassifier | 82.38% | 84.29% |","33561aa8":"## Data Dictionary\n|Variable|Definition|key|\n---|---|---\nsurvival|Survival|0 = No, 1 = Yes\npclass|Ticket class|1 = 1st, 2 = 2nd, 3 = 3rd\nsex|Sex\t\nAge|Age in years\t\nsibsp|# of siblings \/ spouses aboard the Titanic\t\nparch|# of parents \/ children aboard the Titanic\t\nticket|Ticket number\t\nfare|Passenger fare\t\ncabin|Cabin number\t\nembarked|Port of Embarkation|C = Cherbourg, Q = Queenstown, S = Southampton\n","7b18238a":"### Random Forest Classifier","7865351c":"## libraries for feature tuning","cff2a2c1":"### Logistic Regression","201817dd":"### Soft Voting Classifier","396fed75":"## Function for features-target split","f8b21cbc":"# Choosing the Algorithm\nHere's the list of algorithms that I tried out (before tuning) and their accuracy:\n* GaussianNB (39.06%)\n* LogisticRegression (81.93%)\n* SVC (82.83%) (2nd Best)\n* KNeighborsClassifier (82.50%) (3rd Best)\n* **RandomForestClassifier (83.05%) (Best so far)**\n* GradientBoostingClassifier (82.38%)\n\nVoting Classfiers:\n* VotingClassifier [All Models] [soft] (82.38%)\n* **VotingClassifier [SVC, RFC, KNN] [soft] (82.83%)**","b8d0ec42":"## Function for Feature Engineering","0dbc90d5":"## Function for getting algorithm accuracy","28dc4174":"## Function for converting predictions into CSV","99c51406":"## Model Tuning","54cd6b81":"# Scaling Data","16c61c6e":"## Function for Classifier Performance","e640563b":"# Passenger Survival Probability on Titanic\nThis notebook is for [Titanic - Machine Learning from Disaster | Kaggle](https:\/\/www.kaggle.com\/c\/titanic). This is the first time I am joining a Kaggle Competition. I am very excited. I am learning a lot along this journey. I am reviewing a lot on this journey. I am also learning things that I should learn in future.\n\nThe Datas are from [This Source](https:\/\/www.kaggle.com\/c\/titanic\/data)\n\n\nThe Youtube videos that helped me along this journey are:\n* [Beginner Kaggle Data Science Project Walk-Through (Titanic) - YouTube](https:\/\/www.youtube.com\/watch?v=I3FBJdiExcg&t=919s)\n* [Code with me (live): How to make your first Kaggle submission from scratch! - YouTube](https:\/\/www.youtube.com\/watch?v=f1y9wDDxWnA&t=6557s)\n\n[StackOverflow](http:\/\/www.stackoverflow.com) and [Reddit](http:\/\/old.reddit.com) are very helpful.","c6d81f4c":"## Importing Algorithms for training Models","24fad3a1":"## Tuning Voting Classifiers","90ac2221":"# Data Exploration","5c7991ab":"### Gradient Boosting Classifier","b1678926":"### K-Nearest Neighbors Classifier","9a3fd789":"# Import libraries","bf366c93":"### Support Vector Classifier","eaf27bd2":"## Voting Classifier","45b00112":"# Feature Engineering","17bf48f0":"## Submitting","1adcb97e":"## Function for solving mismatches","de038bad":"## Function for Param Names","f2aa616d":"## Different Algorithms","cc4e61a4":"## Function for Scaling Data","88c5a23a":"# Submit","9f3f5032":"# Import Data"}}