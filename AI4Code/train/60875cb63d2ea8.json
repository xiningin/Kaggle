{"cell_type":{"9b50be31":"code","4e023605":"code","fab7ed40":"code","1cda4eaf":"code","1dc144e9":"code","781ee498":"code","c1bf23b8":"code","2a09630c":"code","4ac14af3":"code","19ef54bd":"code","d25330ea":"code","1195faea":"code","69411249":"code","735526d1":"code","6cc05dce":"code","eafc01af":"code","3c910f06":"code","761b12be":"code","7fcd6077":"code","f421efc4":"code","b2f5afa4":"code","b6948396":"markdown","5808e9cd":"markdown","f55fabfe":"markdown","7d47fdda":"markdown","cf0f8251":"markdown","e123697f":"markdown","945d5ac9":"markdown","e118f5e3":"markdown","e57867ff":"markdown","2fa3b512":"markdown","6e2f0454":"markdown","90480c8c":"markdown","f6b95a58":"markdown","0f565aa0":"markdown","029e1934":"markdown","b4395757":"markdown","6896366c":"markdown","d9d882e4":"markdown","cac26468":"markdown","2fcbe6ca":"markdown"},"source":{"9b50be31":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4e023605":"df_train=pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ndf_test=pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ndf_train.head()  ","fab7ed40":"train_label=np.array([img[0] for img in df_train.values])\ntrain_img = np.array([img[1:] for img in df_train.values])\ntest_img=np.array([img for img in df_test.values])\n\nprint(train_img.shape, train_label.shape)\nprint(test_img.shape)\n","1cda4eaf":"from collections import Counter\n\nCounter(train_label)","1dc144e9":"print(train_img[0])","781ee498":"train_img = np.array([np.array_split(img, 28) for img in train_img])\ntest_img = np.array([np.array_split(img, 28) for img in test_img])\nprint(train_img.shape)\n","c1bf23b8":"\nfrom sklearn.model_selection import train_test_split\n\ndata_training, data_testing, response_training, response_testing = train_test_split(train_img, train_label, test_size=0.1, random_state=42)","2a09630c":"print(data_training.shape, response_training.shape)\nprint(data_testing.shape, response_testing.shape)","4ac14af3":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","19ef54bd":"response_training = np.array(tf.keras.utils.to_categorical(response_training, 10))\nresponse_testing = tf.keras.utils.to_categorical(response_testing, 10)","d25330ea":"data_training = np.expand_dims(data_training, axis=-1)\ndata_testing = np.expand_dims(data_testing, axis=-1)\nprint(data_testing.shape)","1195faea":"train_datagen = ImageDataGenerator(rescale=1\/255)\ntest_datagen = ImageDataGenerator(rescale=1\/255)\n\ntrain_datagen.fit(data_training)\ntest_datagen.fit(data_testing) ","69411249":"METRICS = [\n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),\n      tf.keras.metrics.AUC(name='auc'),\n]\n\ndef make_model(metrics = METRICS, output_bias=None):\n  if output_bias is not None:\n    output_bias = tf.keras.initializers.Constant(output_bias)\n  model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28,1)),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(10, activation='softmax')\n  ])\n\n  model.compile(\n      optimizer='rmsprop',\n      loss='categorical_crossentropy',\n      metrics=metrics)\n\n  return model","735526d1":"model = make_model()\nmodel.summary()","6cc05dce":"EPOCHS = 5","eafc01af":"history = model.fit_generator(train_datagen.flow(data_training,response_training),\n    epochs=EPOCHS,\n    validation_data=(data_testing, response_testing))","3c910f06":"def plot_metrics(history):\n  metrics =  ['loss', 'auc', 'precision', 'accuracy']\n  for n, metric in enumerate(metrics):\n    name = metric.replace(\"_\",\" \").capitalize()\n    plt.subplot(2,2,n+1)\n    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n    plt.plot(history.epoch, history.history['val_'+metric],\n             color=colors[0], linestyle=\"--\", label='Val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    plt.legend()","761b12be":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nmpl.rcParams['figure.figsize'] = (12, 10)\ncolors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n\nplot_metrics(history)","7fcd6077":"test_img = np.expand_dims(test_img, axis=-1)","f421efc4":"prediction = model.predict_classes(test_img)\n\nid=['ImageId']\nl=['Label']\n\nfor i in range(28000):\n    id.append(i+1)\n    l.append(prediction[i])\n\n\ncombined=np.vstack((id, l)).T\nprint(combined[0:4])","b2f5afa4":"np.savetxt('Submission.csv', combined, delimiter=',', fmt='%s')","b6948396":"<a id=\"3\"><\/a>\n<h2>3. Modeling<h2>","5808e9cd":"We need to add one dimension to our data that will represent color depth. In our dataset, the dataset contain only gray-scale images so the new format will be (28, 28, 1).\n","f55fabfe":"<IMG align=\"center\" width = \"400\" src=\"https:\/\/miro.medium.com\/max\/1600\/1*RyC_BeesbcWEzEqvBDcWLA.png\" alt=\"Digit recognizer\">\n","7d47fdda":"Conclusion : The 10 digits are present in our training dataset and the data is overall well balanced.","cf0f8251":"For the purposes of training our model, we need to change the labels into vectors of boolean values.","e123697f":"It will be useful for our model if we can normalise the values of those elements.","945d5ac9":"![](http:\/\/)<a id=\"2\"><\/a>\n<h2>EDA : Exploratory Data Analysis<\/center><h2>","e118f5e3":"* Now that we achieved a 0.995 accuracy in our validation data. Let's use this model for the testing datatest","e57867ff":"Let's split out training dataset into two datasets : the first one will train our model and the seconde one will validate our model. \nThe reason behind this split is that the testing dataset provided doesn't contain labels so that we can't know how our model will react to new data.","2fa3b512":"[](http:\/\/)<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2>Quick navigation<\/h2>\n\n[1. Introduction](#1)\n    \n[2. EDA : Exploratory Data Analysis](#2) \n    \n&nbsp;&nbsp;&nbsp;&nbsp;[2.1. Setup and examine the train dataset](#2_1)    \n&nbsp;&nbsp;&nbsp;&nbsp;[2.2. Compare training and testing sets](#2_3)   \n    \n[3. Modeling (In progress)](#3)\n    \n&nbsp;&nbsp;&nbsp;&nbsp;[3.1. Define the model and the metrics](#3_1)    \n&nbsp;&nbsp;&nbsp;&nbsp;[3.2. Set the correct initial bias](#3_2)   \n&nbsp;&nbsp;&nbsp;&nbsp;[3.3. Class weight](#3_3)  \n&nbsp;&nbsp;&nbsp;&nbsp;[3.4. Over sampling](#3_4)      \n    \n[4. Output](#4)    ","6e2f0454":"# Competition Description\n\nMNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n\n# Goal\n\n\nIn this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We\u2019ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare.","90480c8c":"Now, we will import tensorflow","f6b95a58":"Each image is represented by an array with a length of 784 (one element represent one pixel). We have to reshape the images to a 28x28 format :","0f565aa0":"# Labels \n\nLet's check how many values are in the labels and their occurances. One way to find out is to use \"Counter\" from the collections module (to know more about the use of Count****er, check the [python docs here](https:\/\/docs.python.org\/3\/library\/collections.html#collections.Counter)) ","029e1934":"<a id=\"2_1\"><\/a>\n\n# 2.1. Setup and examine the train dataset\n \nWe  will first import the libraries needed.","b4395757":"<a id=\"1\"><\/a>\n<h2> Introduction<h2>","6896366c":"As we can see below, our training data contain 42 000 images with 784 pixel size (each image is 28 pixels in height and 28 pixels in width).\n\n\nLet's see how the first image look like :","d9d882e4":"We imported the data as a Dataframe but in order to work with our data, we need to split the data into labels (first column) and images and convert them to numpy arrays.","cac26468":"# Images \n","2fcbe6ca":"<a id=\"4\"><\/a>\n# Output"}}