{"cell_type":{"8619328b":"code","6d951252":"code","942dde48":"code","5c838878":"code","14465865":"code","7b282dfb":"code","a9694f09":"code","7bd1fb2d":"code","2949dc24":"code","89497855":"code","7dfc4a9d":"code","98aec8f0":"code","3f7a9471":"code","7b86727e":"code","b6fc755a":"code","0c8f8941":"code","5ca82dab":"code","b5fe28d9":"code","ed67836a":"code","2500b35a":"code","c2feaae9":"code","e7bdd8f5":"code","4f6d57b6":"code","10cecbf3":"code","e202024b":"code","482df9b9":"code","111b24f5":"code","6b1a1bf8":"code","622d946b":"code","8bb4bcb7":"code","a1d3f5ee":"code","78169de7":"code","46d7590c":"code","750b8bc0":"code","9ccbccd1":"code","d73b01b0":"code","1db5f9ea":"code","fd1ec719":"code","840a49c2":"code","68d05523":"code","d8f3cdb4":"code","483dd2d1":"code","b117d432":"code","a0263a21":"markdown","b11b4413":"markdown","0b3c0915":"markdown","129f0f0d":"markdown","719a881b":"markdown","e47eca80":"markdown","b1c478ae":"markdown","404f9e9c":"markdown","b7b764ff":"markdown","9c534f3a":"markdown","11eb312f":"markdown","05cfd5f6":"markdown","f1727381":"markdown","74e7820f":"markdown","01ba00f0":"markdown","06a52aeb":"markdown","08620b8e":"markdown","402609e6":"markdown","8c7253fa":"markdown","94b07e7e":"markdown","5358469b":"markdown","3b239ea0":"markdown","e7f7537b":"markdown","49b6ac26":"markdown","b2dbd9fc":"markdown","6944952b":"markdown","3fe04837":"markdown","5cd7f51b":"markdown","361403da":"markdown","cdd9fbec":"markdown","69233c12":"markdown","1d83e7c1":"markdown"},"source":{"8619328b":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix, log_loss, plot_roc_curve, auc, precision_recall_curve\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import StandardScaler","6d951252":"# read csv file\ndf = pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')","942dde48":"# first few rows\ndf.head()","5c838878":"# shape\nprint('Shape of train is {}'.format(df.shape))","14465865":"# basic info\ndf.info()","7b282dfb":"# null values\ndf.isnull().sum()","a9694f09":"sns.countplot(df['gender'])","7bd1fb2d":"gender = df[df['target'] == 1]['gender']\ntemp = gender.value_counts()\nlabels = temp.keys()\nbar,ax = plt.subplots(figsize=(8,8))\nplt.pie(x = temp, labels = labels , colors = ['blue','yellow','red'], autopct=\"%.2f%%\",pctdistance=0.7)\nplt.title('Gender % looking for new job', fontsize=20)","2949dc24":"male_newjob = df[(df['gender']=='Male') & df['target']==1]\nfemale_newjob = df[(df['gender']=='Female') & df['target']==1]\n\n# print\nprint('{} % of male who are looking for a new job'.format(len(male_newjob)\/len(df['gender']=='Male')*100))\nprint('{} % of female who are looking for a new job'.format(len(female_newjob)\/len(df['gender']=='Female')*100))","89497855":"plt.figure(figsize=(8,5))\nsns.countplot(df['company_type'])\nplt.show()","7dfc4a9d":"company_type = df[df['target'] == 1]['company_type']\ntemp = company_type.value_counts()\nlabels = temp.keys()\nbar,ax = plt.subplots(figsize=(8,8))\nplt.pie(x = temp, labels = labels, autopct=\"%.1f%%\",pctdistance=0.7)\nplt.title('People leaving company', fontsize=20)","98aec8f0":"for i in df['company_type'].unique():\n    company_newjob = df[(df['company_type']==i) & df['target']==1]\n    print('{} % of {} who are looking for a new job'.format(len(company_newjob)\/len(df['company_type']==i)*100,i))","3f7a9471":"sns.countplot(df['relevent_experience'])","7b86727e":"sns.countplot(df['relevent_experience'],hue=df['target'])\nplt.xlabel('target')\nplt.ylabel('count')\nplt.title('Relevent experience on the basis of target')","b6fc755a":"yes_newjob = df[(df['relevent_experience']=='Has relevent experience') & df['target']==1]\nno_newjob = df[(df['relevent_experience']=='No relevent experience') & df['target']==1]\n\n# print\nprint('{} % of having relevant experience who are looking for a new job'.format(len(yes_newjob)\/len(df['relevent_experience']=='Has relevent experience')*100))\nprint('{} % of not havinf relevant experience who are looking for a new job'.format(len(no_newjob)\/len(df['relevent_experience']=='No relevent experience')*100))","0c8f8941":"sns.countplot(df['education_level'])","5ca82dab":"people_withoutdegree = df[(df['education_level'] == 'Primary School')& (df['education_level']=='High School') & (df['enrolled_university'] == \"no_enrollment\")]\nprint(\"People who have got into the data science world without graduation are\", len(people_withoutdegree))","b5fe28d9":"sns.countplot(df['last_new_job'])","ed67836a":"fig, ax = plt.subplots(figsize=(10, 10))\ncount = Counter(df['last_new_job'])\nplt.pie(count.values(), labels=count.keys(), labeldistance=0.75, autopct=lambda p:f'{p:.2f}%',\n       explode=[0.05]+[0]*6, shadow=True)\nplt.title('Number of years between last and current job', fontsize=20)\nplt.show()","2500b35a":"df.drop(['enrollee_id','city'],axis=1,inplace=True)","c2feaae9":"sns.countplot(df['enrolled_university'])","e7bdd8f5":"sns.countplot(df['major_discipline'])","4f6d57b6":"sns.countplot(df['experience'])","10cecbf3":"df.replace(to_replace = 'Has relevent experience',value = 'Yes',inplace = True)\ndf.replace(to_replace = 'No relevent experience',value='No',inplace = True )\n\ndf.replace(to_replace = '<1',value = '0',inplace = True)\ndf.replace(to_replace = '>20',value = '21',inplace=True)\ndf.replace(to_replace = 'never',value = '0',inplace=True)\ndf.replace(to_replace = '>4',value = '5',inplace=True)\n\ndf.replace(to_replace = '<10',value = 'around_10',inplace=True)\ndf.replace(to_replace = '10\/49',value = 'around_50',inplace=True)\ndf.replace(to_replace = '50-99',value = 'around_100',inplace=True)\ndf.replace(to_replace = '100-500',value = 'around_500',inplace=True)\ndf.replace(to_replace = '500-999',value = 'around_1000',inplace=True)\ndf.replace(to_replace = '1000-4999',value = 'around_5000',inplace=True)\ndf.replace(to_replace = '5000-9999',value = 'around_10000',inplace=True)\ndf.replace(to_replace = '10000+',value = 'more_than_10000',inplace=True)\n\ndf.replace(to_replace = 'Full time course',value = 'Full_time_course',inplace=True)\ndf.replace(to_replace = 'Part time course',value = 'Part_time_course',inplace=True)\n\ndf.replace(to_replace = 'Primary School',value = 'Primary_School',inplace=True)\ndf.replace(to_replace = 'High School',value = 'High_School',inplace=True)\n\ndf.replace(to_replace = 'Business Degree',value = 'Business_Degree',inplace=True)\ndf.replace(to_replace = 'No Major',value = 'No_Major',inplace=True)\n\ndf.replace(to_replace = 'Pvt Ltd',value = 'Pvt_Ltd',inplace=True)\ndf.replace(to_replace = 'Funded Startup',value = 'Funded_Startup',inplace=True)\ndf.replace(to_replace = 'Public Sector',value = 'Public_Sector',inplace=True)\ndf.replace(to_replace = 'Early Stage Startup',value = 'Early_Stage_Startup',inplace=True)\n\ndf['major_discipline'].replace('Other','Other_major',inplace=True)\ndf['company_type'].replace('Other','Other_type',inplace=True)","e202024b":"# null value\npercent_null = df.isnull().sum()\/df.shape[0]*100\nprint(percent_null)","482df9b9":"df.dropna(subset=['enrolled_university','education_level','experience','last_new_job'], axis=0, inplace=True)","111b24f5":"# after dropping those null values\ndf.shape","6b1a1bf8":"col_mode = ['gender','company_size','major_discipline','company_type','relevent_experience']\nfor col in col_mode:\n    df[col].fillna(df[col].mode()[0],inplace=True)","622d946b":"df = df.astype({'experience':int,'last_new_job':int})","8bb4bcb7":"# get dummies\n\neducation_df = pd.get_dummies(df[['education_level']],drop_first=True,prefix=[None])\ncompany_size_df = pd.get_dummies(df[['company_size']],drop_first=True,prefix=[None])\ncompany_type_df = pd.get_dummies(df[['company_type']],drop_first=True,prefix=[None])\nmajor_df = pd.get_dummies(df[['major_discipline']],drop_first=True,prefix=[None])\nuniversity_df = pd.get_dummies(df[['enrolled_university']],drop_first=True,prefix=[None])\nexperience_df = pd.get_dummies(df[['relevent_experience']],drop_first=True,prefix=[None])\ngender_df = pd.get_dummies(df[['gender']],drop_first=True,prefix=[None])","a1d3f5ee":"# drop original columns\ndf.drop(['education_level','company_size','company_type','major_discipline','enrolled_university','relevent_experience','gender'],axis=1,inplace=True)","78169de7":"final_df = pd.concat([df,education_df,company_size_df,company_type_df,major_df,university_df,experience_df,gender_df],axis=1) ","46d7590c":"final_df.head()","750b8bc0":"final_df.to_csv('final_df.csv')","9ccbccd1":"X = final_df.drop(['target'], axis = 1)\nY = final_df['target']","d73b01b0":"sns.countplot(df['target'])","1db5f9ea":"smote = SMOTE(random_state = 402)\nX_smote, Y_smote = smote.fit_resample(X,Y)\n\n\nsns.countplot(Y_smote)","fd1ec719":"X_train, X_val, y_train, y_val = train_test_split(X_smote, Y_smote, test_size = 0.2 ,random_state = 42)","840a49c2":"sc=StandardScaler()\nX_train=sc.fit_transform(X_train)\nX_val=sc.fit(X_val)","68d05523":"clf = XGBClassifier()\n\n# A parameter grid for XGBoost\nparams = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }\n\nrandom_cv=RandomizedSearchCV(estimator=clf,param_distributions=params,\n                             cv=5,n_iter=5,scoring='roc_auc',n_jobs=1,verbose=3,return_train_score=True,random_state=121)\nrandom_cv.fit(X_train,y_train)","d8f3cdb4":"#best parameter \nrandom_cv.best_params_","483dd2d1":"clf = XGBClassifier(colsample_bytree= 0.8,\n gamma= 1.5,\n max_depth= 5,\n min_child_weigh= 1,\n subsample= 0.6)\n\nclf.fit(X_train, y_train)","b117d432":"# score\nclf.score(X_train,y_train)","a0263a21":"## Hyperparameter Tuning and RandomCV","b11b4413":"So their is not a single person who get into this field without graduation.","0b3c0915":"### If you like this notebook don't forget to upvote it","129f0f0d":"### Years between last and current job?","719a881b":"## Train","e47eca80":"### Countplot for some categorical feature","b1c478ae":"We need to normalize our dataset so it will not get bias towards only particular feature","404f9e9c":"### People with relevant experience are looking for a new job?","b7b764ff":"Replace some row value just for looking it great","9c534f3a":"Columns in which we have 2% or less than 2% null values we can drop those null values","11eb312f":"So if you are a HR and wanted to predict weather a person will going to leave a new job or he\/she is looking for a new job just click on this link:https:\/\/looking-for-job-change.herokuapp.com\/","05cfd5f6":"# Heroku App","f1727381":"# Data Visalization","74e7820f":"So it's seems like most people wjo are currently doing job haven't enrolled in any university","01ba00f0":"### Deal with Null values","06a52aeb":"### Which gender is more likely to move for a new job?","08620b8e":"Let's see weather our dataset is balanced or imbalanced","402609e6":"First of all we are going to drop unnecessary columns,so we don't require enrollee_id and city column","8c7253fa":"### Did any people got into data science field without having graduation degree?","94b07e7e":"We already have seen countplot for various features.Now,we are going to see countplot for the features we haven't seen yet","5358469b":"# Model","3b239ea0":"\nWe can see that our dataset is imbalanced dataset.We are going to use smote technique to deal with our imablanced dataset","e7f7537b":"### From which company type people are looking for new job?","49b6ac26":"So from above we can see that the maximum number of people who are looking for new job are from private companies","b2dbd9fc":"Now we are going to fill null values with their mode as all the columns left have dtype as 'object'","6944952b":"From above we can see that most people work in private companies","3fe04837":"Import all the required libraries","5cd7f51b":"## Data Preprocessing","361403da":"Let's find what type of people are going to left the company","cdd9fbec":"Let's change the dtype of experience and last_new_job column","69233c12":"# Import Libraries","1d83e7c1":"### Handling Categorical Values"}}