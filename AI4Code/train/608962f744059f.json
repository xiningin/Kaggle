{"cell_type":{"81611d0b":"code","3786241c":"code","296a294d":"code","a2253425":"code","810df630":"code","f57df40e":"code","e9aff527":"code","f1f5cb93":"code","e51a835e":"code","b6abbab0":"code","6425b038":"code","7cdbba0f":"code","15f4cacb":"code","9f7e12d5":"code","a808b2a7":"code","b930b32e":"code","2a574da9":"code","3753694b":"code","1fec8c1e":"code","d724ea00":"code","97d914aa":"code","9a286077":"code","bbd3858a":"code","ebd8559c":"code","1f0d1210":"code","edc05b8a":"code","36cfd4df":"code","88771091":"code","8b0bbb39":"code","b072f4d1":"code","0fe9615d":"code","693ed7bd":"code","ad7db91d":"code","a8fd8efd":"code","d280ff69":"code","6b68b3ca":"code","09a33c03":"code","42852436":"code","9902d476":"code","31f07ec7":"code","c885f369":"code","13a7145b":"code","257860cb":"code","95d745ea":"code","29e7f786":"code","1835ff57":"code","0fd48139":"code","ceaaffd9":"code","ccd2aa85":"code","d3daaa78":"code","f7678f12":"code","7f5769e8":"code","4597d11f":"code","6c4965c4":"code","6b148a51":"code","4fd7a409":"code","3d2bb2e0":"code","aa77571f":"code","6fd93672":"markdown","c96bb074":"markdown","5b90e5df":"markdown","6214d068":"markdown","73b4a4fe":"markdown","2a75ffb6":"markdown","9bda4fab":"markdown","51e1bc99":"markdown","3aa7ebd4":"markdown","035af1f4":"markdown","36f7806b":"markdown","a401fcf4":"markdown","742d789e":"markdown","de078e1d":"markdown","6773b69e":"markdown","c866f393":"markdown","8b914ef9":"markdown","e5b38cdf":"markdown","d60a8250":"markdown","6d0f8334":"markdown","922f3212":"markdown"},"source":{"81611d0b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","3786241c":"# reading train data\ntrain=pd.read_csv('..\/input\/titanic\/train.csv')\n\n# reading test data\ntest=pd.read_csv('..\/input\/titanic\/test.csv') ","296a294d":"# printing first five rows of the data set\ntrain.head()","a2253425":"# number of rows and columns\ntrain.shape ","810df630":"# column names\ntrain.columns ","f57df40e":"# number of null values in dataset\ntrain.isnull().sum() ","e9aff527":"train['Sex'].value_counts()","f1f5cb93":"# countplot\nsns.countplot(x='Sex', data=train)","e51a835e":"train['Pclass'].value_counts()","b6abbab0":"sns.countplot(x='Pclass', data=train)","6425b038":"train['Embarked'].value_counts()","7cdbba0f":"sns.countplot(x='Embarked', data=train)","15f4cacb":"train['SibSp'].value_counts()","9f7e12d5":"sns.countplot(x='SibSp', data=train)","a808b2a7":"# new feature\ntrain['Died'] = 1 - train['Survived']","b930b32e":"train.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar',\n                                                           figsize=(10, 5),\n                                                           stacked=True)","2a574da9":"train.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar',\n                                                            figsize=(10, 5),\n                                                            stacked=True)","3753694b":"figure = plt.figure(figsize=(16, 7))\nplt.hist([train[train['Survived'] == 1]['Fare'], train[train['Survived'] == 0]['Fare']], \n         stacked=True, bins = 50, label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nplt.legend()","1fec8c1e":"titles = set()\nfor name in train['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\nprint(titles)","d724ea00":"Title_Dictionary = {\"Capt\": \"Officer\",\"Col\": \"Officer\",\"Major\": \"Officer\",\"Jonkheer\": \"Royalty\",\"Don\": \"Royalty\",\"Sir\" : \"Royalty\",\"Dr\": \"Officer\",\"Rev\": \"Officer\",\"the Countess\":\"Royalty\",\"Mme\": \"Mrs\",\"Mlle\": \"Miss\",\"Ms\": \"Mrs\",\"Mr\" : \"Mr\",\"Mrs\" : \"Mrs\",\"Miss\" : \"Miss\",\"Master\" : \"Master\",\"Lady\" : \"Royalty\"}","97d914aa":"train['Title'] = train['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\ntrain['Title'] = train.Title.map(Title_Dictionary)\ntrain.head()","9a286077":"# dropping umwanted columns\ndf1=train.drop(['Name','Ticket','Cabin','PassengerId','Died'], axis=1)\ndf1.head()","bbd3858a":"train.Title.value_counts()","ebd8559c":"# Converting categorical feature to numeric\ndf1.Sex=df1.Sex.map({'female':0, 'male':1})\ndf1.Embarked=df1.Embarked.map({'S':0, 'C':1, 'Q':2,'nan':'NaN'})\ndf1.Title=df1.Title.map({'Mr':0, 'Miss':1, 'Mrs':2,'Master':3,'Officer':4,'Royalty':5})\ndf1.head()","1f0d1210":"# median age of each sex\nmedian_age_men=df1[df1['Sex']==1]['Age'].median()\nmedian_age_women=df1[df1['Sex']==0]['Age'].median()","edc05b8a":"# filling null values in 'Age' with respective median age\ndf1.loc[(df1.Age.isnull()) & (df1['Sex']==0),'Age']=median_age_women\ndf1.loc[(df1.Age.isnull()) & (df1['Sex']==1),'Age']=median_age_men","36cfd4df":"# checking for null values\ndf1.isnull().sum()","88771091":"# dropping rows with null value\ndf1.dropna(inplace=True)","8b0bbb39":"# Data is cleaned to have no null value\ndf1.isnull().sum()","b072f4d1":"# cleaned dataset\ndf1.head()","0fe9615d":"df1.Age = (df1.Age-min(df1.Age))\/(max(df1.Age)-min(df1.Age))\ndf1.Fare = (df1.Fare-min(df1.Fare))\/(max(df1.Fare)-min(df1.Fare))","693ed7bd":"df1.describe()","ad7db91d":"from sklearn.model_selection import train_test_split","a8fd8efd":"X_train, X_test, y_train, y_test = train_test_split(\n    df1.drop(['Survived'], axis=1),\n    df1.Survived,\n    test_size= 0.2,\n    random_state=0,\n    stratify=df1.Survived\n)","d280ff69":"# Logistic regression\nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression()\nclf.fit(X_train, y_train)\n\nfrom sklearn.metrics import accuracy_score\n\nY_pred = clf.predict(X_test)\naccuracy_score(y_test, Y_pred)","6b68b3ca":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test, Y_pred)\ncm","09a33c03":"sns.heatmap(cm,annot=True)","42852436":"# test dataset\ntest.head()","9902d476":"titles = set()\nfor name in test['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\nprint(titles)","31f07ec7":"test['Title'] = test['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\ntest['Title'] = test.Title.map(Title_Dictionary)\ntest.head()","c885f369":"# dropping unwanted columns\ndf2=test.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)","13a7145b":"# Converting categorical feature to numeric\ndf2.Sex=df2.Sex.map({'female':0, 'male':1})\ndf2.Embarked=df2.Embarked.map({'S':0, 'C':1, 'Q':2,'nan':'nan'})\ndf2.Title=df2.Title.map({'Mr':0, 'Miss':1, 'Mrs':2,'Master':3,'Officer':4,'Royalty':5})\ndf2.head()","257860cb":"# Checking for null values\ndf2.isnull().sum()","95d745ea":"# median age of each sex\nmedian_age_men2=df2[df2['Sex']==1]['Age'].median()\nmedian_age_women2=df2[df2['Sex']==0]['Age'].median()","29e7f786":"# filling null values with respective median age\ndf2.loc[(df2.Age.isnull()) & (df2['Sex']==0),'Age']=median_age_women2\ndf2.loc[(df2.Age.isnull()) & (df2['Sex']==1),'Age']=median_age_men2","1835ff57":"# filling null values with median fare\ndf2['Fare']=df2['Fare'].fillna(df2['Fare'].median())","0fd48139":"df2.isnull().sum()","ceaaffd9":"# Null value in the title column\ndf2[df2.Title.isnull()]","ccd2aa85":"df2=df2.fillna(2)","d3daaa78":"# Data is cleaned to have no null value\ndf2.isnull().sum()","f7678f12":"# cleaned dataset\ndf2.head()","7f5769e8":"# feature scaling\ndf2.Age = (df2.Age-min(df2.Age))\/(max(df2.Age)-min(df2.Age))\ndf2.Fare = (df2.Fare-min(df2.Fare))\/(max(df2.Fare)-min(df2.Fare))","4597d11f":"# test dataset\ndf2.head()","6c4965c4":"pred = clf.predict(df2)","6b148a51":"pred","4fd7a409":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": pred\n    })\nsubmission.to_csv('submission.csv', index=False)","3d2bb2e0":"pred_df = pd.read_csv('submission.csv')","aa77571f":"# visualizing predicted values\nsns.countplot(x='Survived', data=pred_df)","6fd93672":"## Cleaning the  train dataset","c96bb074":"## Prediction","5b90e5df":"Plotting the same graph but with ratio instead.","6214d068":"#### Thank You","73b4a4fe":"## Confusion Matrix","2a75ffb6":"The Sex variable seems to be a discriminative feature. Women are more likely to survive.","9bda4fab":"## Cleaning test dataset","51e1bc99":"Visualizing survival based on the gender.","3aa7ebd4":"## Feature Scaling","035af1f4":"## Importing libraries","36f7806b":"## Introduction","a401fcf4":"- **Logistic Regression**","742d789e":"Two null values in Embarked column","de078e1d":"## Data Modelling","6773b69e":"Passengers with cheaper ticket fares are more likely to die. Put differently, passengers with more expensive tickets, and therefore a more important social status, seem to be rescued first.","c866f393":"## Exploratory Data Analysis","8b914ef9":"**The Titanic challenge** on Kaggle is a competition in which the task is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat. \n\nI have recently achieved an accuracy score of **0.78708** on the public leaderboard. I have used **Logistic regression** for prediction. As I'm writing this post, I am ranked among the **top 9%** of all Kagglers.","e5b38cdf":"Now, visualizing survival based on the fare.","d60a8250":"## Feature Engineering","6d0f8334":"Since the person is a woman with age 39, filling the title with 2 (mapped value for the title 'Mrs')","922f3212":"Different titles in the train set are:"}}