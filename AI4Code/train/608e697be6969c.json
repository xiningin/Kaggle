{"cell_type":{"f18c0162":"code","0e3335f2":"code","1ac5aae6":"code","0810d4b9":"code","f8478fa7":"code","98aa2275":"code","d07d9384":"code","3309e9c0":"code","e8731065":"code","44d69fd6":"code","26f576c6":"code","56970f07":"code","365bba5c":"code","76c5280c":"code","8ae5fa76":"code","de487bab":"code","a19d9859":"markdown"},"source":{"f18c0162":"# Importing libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","0e3335f2":"# Configuring visualizations\n%matplotlib inline\nplt.rcParams['figure.figsize'] = 12, 8","1ac5aae6":"# Loading datasets\ntrain_set = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_set = pd.read_csv('..\/input\/titanic\/test.csv')\nX_train = train_set.iloc[:, [2, 4, 5, 6, 7, 9, 11]].values\nX_test = test_set.iloc[:, [1, 3, 4, 5, 6, 8, 10]].values\ny_train = train_set.iloc[:, 1].values","0810d4b9":"# Exploring train set\ntrain_set.info()\ntrain_set.describe(include='all')","f8478fa7":"# Exploring test set\ntest_set.info()\ntest_set.describe(include='all')","98aa2275":"# Taking care of missing data (Age, Embarked, Fare)\nfrom sklearn.impute import SimpleImputer\nimputer_age = SimpleImputer(missing_values=np.nan, strategy='mean')\nX_train[:, 2:3] = imputer_age.fit_transform(X_train[:, 2:3])\nX_test[:, 2:3] = imputer_age.fit_transform(X_test[:, 2:3])\nimputer_embarked = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nX_train[:, 6:7] = imputer_embarked.fit_transform(X_train[:, 6:7])\nimputer_fare = SimpleImputer(missing_values=np.nan, strategy='median')\nX_test[:, 5:6] = imputer_fare.fit_transform(X_test[:, 5:6])","d07d9384":"# Encoding categorical data (Sex)\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\nX_train[:, 1] = labelencoder.fit_transform(X_train[:, 1])\nX_test[:, 1] = labelencoder.transform(X_test[:, 1])","3309e9c0":"# Encoding categorical data (PClass, Embarked)\nfrom sklearn.preprocessing import OneHotEncoder\nonehotencoder_pclass = OneHotEncoder(categories='auto', drop='first', sparse=False)\npclass_train = onehotencoder_pclass.fit_transform(X_train[:, 0:1])\npclass_test = onehotencoder_pclass.transform(X_test[:, 0:1])\nonehotencoder_embarked = OneHotEncoder(categories='auto', drop='first', sparse=False)\nembarked_train = onehotencoder_embarked.fit_transform(X_train[:, 6:7])\nembarked_test = onehotencoder_embarked.transform(X_test[:, 6:7])\nX_train = np.concatenate((pclass_train, X_train[:, 1:6], embarked_train), axis=1)\nX_test = np.concatenate((pclass_test, X_test[:, 1:6], embarked_test), axis=1)\ndel pclass_train, pclass_test, embarked_train, embarked_test","e8731065":"# Feature scaling\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler(with_mean=True, with_std=True)\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","44d69fd6":"# Building a SVM model\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel='rbf', C=1.0, gamma='auto', probability=False, \n                 decision_function_shape='ovr')\nclassifier.fit(X_train, y_train)","26f576c6":"# Cross validation\nfrom sklearn.model_selection import cross_validate\nresults = cross_validate(classifier, X_train, y_train, cv=10, scoring='accuracy',\n                         return_train_score=True, return_estimator=False, n_jobs=-1)\nprint('train score:', results['train_score'].mean())\nprint('test score:', results['test_score'].mean())","56970f07":"# Plotting learning curves\nfrom sklearn.model_selection import learning_curve\nm_range = np.linspace(.05, 1.0, 20)\ntrain_sizes, train_scores, test_scores = learning_curve(classifier, X_train, y_train, cv=10,  \n                                                        train_sizes=m_range, shuffle=False,\n                                                        scoring='accuracy', n_jobs=-1)\nplt.figure()\nplt.title('Learning Curves')\nplt.ylim(.69, .92)\nplt.xlabel('Training examples')\nplt.ylabel('Score')\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\nplt.grid()\nplt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\nplt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')\nplt.fill_between(train_sizes, train_scores_mean - train_scores_std, \n                 train_scores_mean + train_scores_std, alpha=0.1, color='r')\nplt.fill_between(train_sizes, test_scores_mean - test_scores_std, \n                 test_scores_mean + test_scores_std, alpha=0.1, color='g')\nplt.legend(loc='best')\nplt.show()","365bba5c":"# Plotting validation curves against C\nfrom sklearn.model_selection import validation_curve\nC_range = np.geomspace(1e-2, 1e+2, 41)\ntrain_scores, test_scores = validation_curve(classifier, X_train, y_train, cv=10,\n                                             param_name='C', param_range=C_range,\n                                             scoring='accuracy', n_jobs=-1)\nplt.figure()\nplt.title('Validation Curves')\nplt.ylim(.5, .9)\nplt.xlabel('C')\nplt.ylabel('Score')\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\nplt.grid()\nplt.semilogx(C_range, train_scores_mean, label='Training score', color='darkorange', lw=2)\nplt.semilogx(C_range, test_scores_mean, label='Cross-validation score', color='navy', lw=2)\nplt.fill_between(C_range, train_scores_mean - train_scores_std, \n                 train_scores_mean + train_scores_std, alpha=0.2, color='darkorange', lw=2)\nplt.fill_between(C_range, test_scores_mean - test_scores_std,\n                 test_scores_mean + test_scores_std, alpha=0.2, color='navy', lw=2)\nplt.legend(loc='best')\nplt.show()","76c5280c":"# Plotting validation curves against gamma\nfrom sklearn.model_selection import validation_curve\ngamma_range = np.geomspace(1e-4, 1e+1, 51)\ntrain_scores, test_scores = validation_curve(classifier, X_train, y_train, cv=10,\n                                             param_name='gamma', param_range=gamma_range,\n                                             scoring='accuracy', n_jobs=-1)\nplt.figure()\nplt.title('Validation Curves')\nplt.ylim(.5, 1)\nplt.xlabel(r'$\\gamma$')\nplt.ylabel('Score')\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\nplt.grid()\nplt.semilogx(gamma_range, train_scores_mean, label='Training score', color='darkorange', lw=2)\nplt.semilogx(gamma_range, test_scores_mean, label='Cross-validation score', color='navy', lw=2)\nplt.fill_between(gamma_range, train_scores_mean - train_scores_std, \n                 train_scores_mean + train_scores_std, alpha=0.2, color='darkorange', lw=2)\nplt.fill_between(gamma_range, test_scores_mean - test_scores_std,\n                 test_scores_mean + test_scores_std, alpha=0.2, color='navy', lw=2)\nplt.legend(loc='best')\nplt.show()","8ae5fa76":"# Grid search\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {'kernel': ['rbf'], 'C': list(np.geomspace(1e-1, 1e+1, 21)), \n              'gamma': list(np.geomspace(1e-2, 1e+0, 21))}\ngrid_search = GridSearchCV(classifier, param_grid, iid=False, refit=True, cv=10, \n                           return_train_score=True, scoring='accuracy', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\nprint('best parameters:', grid_search.best_params_)\nprint('best score:', grid_search.best_score_)","de487bab":"# Making predictions and submitting outputs\ny_pred = grid_search.predict(X_test)\nsubmission = pd.DataFrame({'PassengerId': test_set.iloc[:, 0].values,\n                           'Survived': y_pred})\nsubmission.to_csv('submission_logistic.csv', index=False)","a19d9859":"References:\n\n[Support Vector Machines](https:\/\/scikit-learn.org\/stable\/modules\/svm.html#svm-classification)\n\n[Plotting Learning Curves](https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py)\n\n[Plotting Validation Curves](https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_validation_curve.html#sphx-glr-auto-examples-model-selection-plot-validation-curve-py)"}}