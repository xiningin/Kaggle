{"cell_type":{"8f7c0ed8":"code","4304893a":"code","63834444":"code","ea8180b4":"code","70369c02":"code","87fb73b3":"code","abf289ce":"code","f67c1273":"code","4e35ac47":"code","5c4b260b":"code","f72e2542":"code","330766f9":"code","1da0088a":"code","cc38b24d":"code","fb59f04d":"code","8d809bd4":"code","2d88c24c":"code","dfa5d007":"code","7493f11c":"code","9fd898e1":"code","d74878c6":"code","31fe39a7":"code","e4024cb2":"code","58bfe9fe":"code","61eb2974":"code","96a3b6cc":"code","11790825":"code","4f8964e3":"code","b86c3a1d":"code","6f94896f":"code","1089d118":"code","6233b30f":"code","22b20fa6":"code","e202fbbb":"code","25201630":"code","95e95bc8":"code","e23bf5c9":"code","d42f06b1":"markdown","d0803a8e":"markdown","194d2029":"markdown","42fe13b0":"markdown","28955826":"markdown","32d5f56d":"markdown","d23e2244":"markdown","b09bcd0e":"markdown","4841233e":"markdown","0aff5e0d":"markdown","363c5ca4":"markdown","4723d6f5":"markdown","1e6ce5e7":"markdown","01f120e3":"markdown","c28c1d99":"markdown"},"source":{"8f7c0ed8":"import os\n","4304893a":"os.listdir()","63834444":"os.chdir('\/kaggle\/input')","ea8180b4":"os.listdir()","70369c02":"import pandas as pd","87fb73b3":"traindatafile = pd.read_csv('train.csv')\ntestdatafile = pd.read_csv('test.csv')","abf289ce":"traindatafile.head()\n","f67c1273":"y = traindatafile.pop('label')","4e35ac47":"import numpy as np # linear algebra\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","5c4b260b":"x_train, x_val, y_train, y_val = train_test_split(traindatafile, y, test_size=0.1, random_state=42)","f72e2542":"traindatafile.shape","330766f9":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nx_train = x_train.values.reshape(-1,28,28,1)\nx_val = x_val.values.reshape(-1,28,28,1)\nx_test= testdatafile.values.reshape(-1,28,28,1)","1da0088a":"print(x_train.shape)\nprint(x_val.shape)","cc38b24d":"x_train[0]","fb59f04d":"x_train = x_train.astype(\"float32\")\/255.\nx_val = x_val.astype(\"float32\")\/255.\nx_test = x_test.astype(\"float32\")\/255.","8d809bd4":"x_train[0]","2d88c24c":"print(x_train.shape)\nx_val.shape","dfa5d007":"x_test.shape","7493f11c":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.callbacks import TensorBoard","9fd898e1":"y_train = to_categorical(y_train) \ny_val = to_categorical(y_val) ","d74878c6":"print(y_train.shape)\ny_val.shape","31fe39a7":"import matplotlib.pyplot as plt\n%matplotlib inline \n\ng = plt.imshow(x_train[0][:,:,0])","e4024cb2":"# Set the CNN model \n# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","58bfe9fe":"model.summary()","61eb2974":"datagen = ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n                    samplewise_center=False,  # set each sample mean to 0\n                                 featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n                               zca_whitening=False,  # apply ZCA whitening\n        rotation_range=15, # randomly rotate images in the range (degrees, 0 to 180)\n                              zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n                               height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n                               vertical_flip=False)  # randomly flip images)","96a3b6cc":"model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-4), metrics=[\"accuracy\"]) #1e-4, means the 1 is four digits the other way, so 1e-4 = 0.0001.","11790825":"learning_rate_min = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n#tensor= TensorBoard(log_dir='.\/logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq=1000)","4f8964e3":"hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=16),\n                           steps_per_epoch=500,\n                           epochs=20, #Increase this when not on Kaggle kernel\n                           verbose=2,  #1 for ETA, 0 for silent\n                           validation_data=(x_val[:400,:], y_val[:400,:]), #For speed\n                           callbacks=[learning_rate_min]) ","b86c3a1d":"final_loss, final_acc = model.evaluate(x_val, y_val, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))","6f94896f":"plt.plot(hist.history['loss'], color='r',label='Training loss')\nplt.plot(hist.history['acc'], color='b',label='Training accuracy')\nplt.title('Training loss and Training accuracy')\nplt.show()\n\nplt.plot(hist.history['val_loss'], color='r', label='Validation loss')\nplt.plot(hist.history['val_acc'], color='b', label='Validation accuracy')\nplt.title('validation loss and validation accuracy')\nplt.show()","1089d118":"y_predicted = model.predict(x_val)\ny_predictedint = np.argmax(y_predicted, axis=1)\ny_true = np.argmax(y_val, axis=1)\ncm = confusion_matrix(y_true, y_predictedint)\nprint(cm)","6233b30f":"y_hat = model.predict(x_test ,batch_size=64)","22b20fa6":"print(y_hat)","e202fbbb":"y_pred = np.argmax(y_hat,axis=1)","25201630":"y_pred","95e95bc8":"print(y_pred)","e23bf5c9":"y_pred.shape","d42f06b1":"<img src=\"https:\/\/s3-ap-south-1.amazonaws.com\/av-blog-media\/wp-content\/uploads\/2018\/03\/confusion-matrix-mercari.png\" \/>","d0803a8e":"submissions=pd.DataFrame({\"ImageId\": list(range(1,len(y_pred)+1)),\n                         \"Label\": y_pred})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)\n","194d2029":"<img src=\"https:\/\/i.ytimg.com\/vi\/tRsSi_sqXjI\/maxresdefault.jpg\" \/>","42fe13b0":"### Model CNN ","28955826":"#####  another way to submit \nwith open(\"submission.csv\", 'w') as f :\n    f.write('ImageId,Label\\n')\n    for i in range(len(y_pred)) :\n        f.write(\"\".join([str(i+1),',',str(y_pred[i]),'\\n']))","32d5f56d":"this is to for changing images properties ","d23e2244":"# MNIST Dataset","b09bcd0e":"### Importing data and libraries","4841233e":"#### Importing Keras libraries","0aff5e0d":"### Data Wrangling","363c5ca4":"<img src= \"https:\/\/iq.opengenus.org\/content\/images\/2018\/11\/cnn.png\" \/>","4723d6f5":"Train and test images (28px x 28px) has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.\n\nKeras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices.","1e6ce5e7":"<img src=\"https:\/\/www.katacoda.com\/basiafusinska\/courses\/deep-learning-with-tensorflow\/mnist-dataset\/assets\/MNIST.png\" \/>","01f120e3":"Confusion matrix example","c28c1d99":"## Fitting the data in model"}}