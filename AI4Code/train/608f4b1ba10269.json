{"cell_type":{"c833bb15":"code","9a04df91":"code","c1a37b9f":"code","fd7d4cce":"code","0c74edc8":"code","d637cabc":"code","ce8daf9e":"code","5b4407b1":"code","905be271":"code","9b11f1b8":"code","3de9d8e1":"code","bd82dba0":"code","7641ef14":"code","2be4bd88":"code","f2f43a17":"code","c3b886dc":"code","dff311ce":"code","8c9583dc":"code","15176b77":"code","36e82c87":"code","7ccfefe8":"code","6a73f7c2":"code","82a8de87":"code","ee09eebb":"code","091cda41":"code","0bf7d3e9":"code","7cab6ad1":"code","81f1d86b":"code","41a4e4d6":"code","090471e1":"code","99b32340":"code","9c56eae4":"code","535e509d":"code","d3f3d7ed":"code","254e17c6":"code","3de69109":"code","14a3c98f":"code","d320ff07":"code","7d34cd9a":"code","3aa06f27":"code","a3ab4405":"code","783c24dc":"code","d4322860":"code","077c8495":"code","72a939c2":"code","342c654a":"code","b5790c8a":"code","1036440d":"code","8a0d92c3":"code","c5a5d4d4":"code","a23284bf":"code","e5e3e6d5":"code","58dcb3e4":"code","8fef7e62":"code","de42f2db":"code","2349c739":"code","10a91b58":"markdown","5fe3c9ac":"markdown","6eda148a":"markdown","87512a93":"markdown","d1dfb0fd":"markdown","e3be3d33":"markdown","35f06b5d":"markdown","d8378bd7":"markdown","baa1b042":"markdown","666dd54f":"markdown","1e734493":"markdown","feecfa7f":"markdown","7a0b6814":"markdown","579cd70a":"markdown","d40ec624":"markdown","45e72417":"markdown","e211519f":"markdown","98102b46":"markdown","1f775c66":"markdown","5048cbd1":"markdown","47231b14":"markdown","4d9fa7a8":"markdown","717fd9cb":"markdown","ae4729e5":"markdown","4aef0f99":"markdown","0a2390a8":"markdown","2890cd63":"markdown","ac22ea1b":"markdown","3eb3072c":"markdown","e2677679":"markdown","c76621f5":"markdown","c38ef25d":"markdown","14d44bd1":"markdown","46249fd8":"markdown","83b461ec":"markdown","38b90ebb":"markdown","b8445c95":"markdown"},"source":{"c833bb15":"# linear algebra\nimport numpy as np \n\n# data processing\nimport pandas as pd \n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# kaggle directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# machine learning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler","9a04df91":"# load data for training\ntrain_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_df.head()","c1a37b9f":"# get an overview of training data\ntrain_df.info()","fd7d4cce":"# load data for testing\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_df.head()","0c74edc8":"# distribution of numerical features\ntrain_df.describe()","d637cabc":"# distribution of categorical features\ntrain_df.describe(include='O') # include object type","ce8daf9e":"# sex of passengers\ntrain_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","5b4407b1":"# class of passengers\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","905be271":"# sibling and spouse\ntrain_df[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","9b11f1b8":"# parents and children\ntrain_df[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","3de9d8e1":"# embark location\ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n","bd82dba0":"# variable containing both train & test dataset\nall_df = [train_df, test_df]","7641ef14":"# convert Sex categorical feature to numerical.\nfor df in all_df:\n    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1}).astype(int)\n\ntrain_df.head()","2be4bd88":"# relationship between Pclass, Embarked, Sex\ngrid3 = sns.FacetGrid(train_df, col='Embarked')\ngrid3.map(sns.pointplot, 'Pclass', 'Survived', 'Sex')\ngrid3.add_legend()","f2f43a17":"# fill missing values with the mode\ncommon_Pclass = 'S'\ntrain_df['Embarked'].fillna(common_Pclass, inplace=True)\n\n# convert Embarked categorical feature to numerical.\ntrain_df['Embarked'] = train_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\ntest_df['Embarked'] = test_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n\ntrain_df.head()","c3b886dc":"# overview of Cabin feature\ntrain_df['Cabin'].describe()","dff311ce":"# cleaning\ntrain_df['Cabin'].isna().sum()","8c9583dc":"# fill missing values with X\ntrain_df['Cabin'].fillna('X', inplace=True)\ntest_df['Cabin'].fillna('X', inplace=True)","15176b77":"train_df['Cabin'].value_counts()","36e82c87":"for df in all_df:\n    df['Cabin'] = df['Cabin'].astype(str).str[0]\n\ntest_df['Cabin']","7ccfefe8":"g = sns.factorplot(y=\"Survived\", x=\"Cabin\", data=train_df,\\\n                   kind=\"bar\", order=['A','B','C','D','E','F','G','T','X'])\ng = g.set_ylabels(\"Survival Probability\")","6a73f7c2":"train_df.groupby(['Survived', 'Cabin'])['PassengerId'].sum()","82a8de87":"# transform Age in the main dataset into bands\nfor df in all_df:\n    df.loc[(df['Cabin'] == 'A'), 'Cabin'] = 0\n    df.loc[(df['Cabin'] == 'B'), 'Cabin'] = 0\n    df.loc[(df['Cabin'] == 'C'), 'Cabin'] = 0\n    df.loc[(df['Cabin'] == 'D'), 'Cabin'] = 1\n    df.loc[(df['Cabin'] == 'E'), 'Cabin'] = 1\n    df.loc[(df['Cabin'] == 'F'), 'Cabin'] = 2\n    df.loc[(df['Cabin'] == 'G'), 'Cabin'] = 2\n    df.loc[(df['Cabin'] == 'T'), 'Cabin'] = 0\n    df.loc[(df['Cabin'] == 'X'), 'Cabin'] = 3\n\ntrain_df.head()  ","ee09eebb":"# relationship between Age and survival.\ngrid1 = sns.FacetGrid(train_df, col='Survived')\ngrid1.map(plt.hist, 'Age')","091cda41":"# prepare empty array to contain guessed Age based on Pclass x Sex\nguess_df = np.zeros((3,2))\nguess_df","0bf7d3e9":"for df in all_df:\n    \n    # generate a list of guesses of age\n    for i in range(0,3):\n        for j in range(0,2):\n            guess = df[(df['Pclass']==i+1) & (df['Sex']==j)]['Age'].dropna()\n            guess_df[i,j] = guess.median()\n    \n    # apply the guesses to the main data\n    for i in range (0,3):\n        for j in range (0,2):\n            df.loc[(df['Age'].isna()) & (df['Pclass']==i+1) & (df['Sex']==j), 'Age'] = guess_df[i,j]\n    \n    df['Age'] = df['Age'].dropna().astype(int)\n\ntrain_df.head()","7cab6ad1":"# group Age into bands (bins)\ntrain_df['AgeBand'] = pd.qcut(train_df['Age'], 10)\ntrain_df.groupby('AgeBand', as_index=False)['Survived'].mean().sort_values(by='AgeBand', ascending=True)","81f1d86b":"# transform Age in the main dataset into bands\nfor df in all_df:\n    df.loc[(df['Age'] <= 16), 'Age'] = 0 # children 1\n    df.loc[(df['Age'] > 16) & (df['Age'] <= 20), 'Age'] = 1 # children 2\n    df.loc[(df['Age'] > 20) & (df['Age'] <= 22), 'Age'] = 2 # teen 1\n    df.loc[(df['Age'] > 22) & (df['Age'] <= 25), 'Age'] = 3 # teen 2\n    df.loc[(df['Age'] > 25) & (df['Age'] <= 26), 'Age'] = 4 # young adult 1\n    df.loc[(df['Age'] > 26) & (df['Age'] <= 30), 'Age'] = 5 # young adult 2\n    df.loc[(df['Age'] > 30) & (df['Age'] <= 34), 'Age'] = 6 # middle age 1\n    df.loc[(df['Age'] > 34) & (df['Age'] <= 40), 'Age'] = 7 # middle age 2\n    df.loc[(df['Age'] > 40) & (df['Age'] <= 47), 'Age'] = 8 # old adullt\n    df.loc[(df['Age'] > 47), 'Age'] = 9 # elder\n\ntrain_df.head()  ","41a4e4d6":"train_df.groupby('Age', as_index=False)['Survived'].mean().sort_values(by='Age', ascending=True)","090471e1":"train_df.isna().sum()","99b32340":"# remove AgeBand feature\ntrain_df.drop(['AgeBand'], axis=1, inplace=True)","9c56eae4":"test_df.head()","535e509d":"# relationship between Fare and Embarked\ngrid4 = sns.FacetGrid(train_df, col='Survived')\ngrid4.map(sns.barplot, 'Embarked', 'Fare')","d3f3d7ed":"# check missing value\ntrain_df.isna().sum()","254e17c6":"test_df.isna().sum()","3de69109":"# fill missing value with the mean\ntest_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)","14a3c98f":"# group Fare into bands (quartiles)\ntrain_df['FareBand'] = pd.qcut(train_df['Fare'], 13)\ntrain_df.groupby('FareBand', as_index=False)['Survived'].mean().sort_values('FareBand', ascending=True)","d320ff07":"# transform the Fare in the main dataset into bands\nfor df in all_df:\n    df.loc[df['Fare'] <= 7.229, 'Fare'] = 0\n    df.loc[(df['Fare'] > 7.229) & (df['Fare'] <= 7.75), 'Fare'] = 1\n    df.loc[(df['Fare'] > 7.896) & (df['Fare'] <= 8.05), 'Fare'] = 2\n    df.loc[(df['Fare'] > 8.05) & (df['Fare'] <= 10.5), 'Fare'] = 3\n    df.loc[(df['Fare'] > 10.5) & (df['Fare'] <= 13.0), 'Fare'] = 4\n    df.loc[(df['Fare'] > 13.0) & (df['Fare'] <= 15.85), 'Fare'] = 5\n    df.loc[(df['Fare'] > 15.85) & (df['Fare'] <= 24.0), 'Fare'] = 6\n    df.loc[(df['Fare'] > 24.0) & (df['Fare'] <= 26.55), 'Fare'] = 7\n    df.loc[(df['Fare'] > 26.55) & (df['Fare'] <= 33.308), 'Fare'] = 8\n    df.loc[(df['Fare'] > 33.308) & (df['Fare'] <= 55.9), 'Fare'] = 9\n    df.loc[(df['Fare'] > 55.9) & (df['Fare'] <= 83.158), 'Fare'] = 10\n    df.loc[(df['Fare'] > 83.158), 'Fare'] = 11\n    df['Fare'] = df['Fare'].astype(int)\n\ntrain_df.head()","7d34cd9a":"# drop FareBand feature\ntrain_df.drop('FareBand', axis=1, inplace=True)","3aa06f27":"for df in all_df:\n    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n\ntrain_df.groupby('FamilySize', as_index=False)['Survived'].mean().sort_values('Survived', ascending=False)","a3ab4405":"for df in all_df:\n    df['Family'] = 0 # alone\n    df.loc[(df['FamilySize'] > 1) & (df['FamilySize'] < 5), 'Family'] = 1 # small family\n    df.loc[(df['FamilySize'] >= 5) & (df['FamilySize'] < 7), 'Family'] = 2 # medium family\n    df.loc[(df['FamilySize'] >= 7), 'Family'] = 3 # large family\n\n\ntrain_df.groupby('Family', as_index=False)['Survived'].mean().sort_values('Survived', ascending=False)","783c24dc":"# drop FamilySize\ntrain_df.drop('FamilySize', axis=1, inplace=True)\ntest_df.drop('FamilySize', axis=1, inplace=True)","d4322860":"for df in all_df:\n    title = df['Name'].apply(lambda x:x.split(',')[1].split('.')[0]).copy()\n    df['Title'] = title.str.strip()\n\ntrain_df.groupby(['Title', 'Survived'])['PassengerId'].count().sort_values(ascending=False)","077c8495":"train_df.groupby(['Title', 'Survived'])['PassengerId'].count().sort_values(ascending=False)","72a939c2":"for df in all_df:\n    df['Married'] = 0\n    df['Married'].loc[df['Title'] == 'Mrs'] = 1\n    \ntrain_df.head()","342c654a":"Noble = ['Major','Col','Capt','Don','Dr','Rev','Sir','Jonkheer']\nFemale = ['Mrs','Miss','Ms','Mlle', 'Dona', 'Mme','Lady','the Countess']\n\nfor df in all_df:\n    df['Title'] = df['Title'].replace(Noble, 'Noble')\n    df['Title'] = df['Title'].replace(Female, 'Ms\/Mrs')\n\nall_df = [train_df, test_df]    \ntrain_df.groupby('Title', as_index=False)['Survived'].mean().sort_values('Survived', ascending=True)","b5790c8a":"title_map = {\"Mr\": 0, \"Ms\/Mrs\": 1, \"Master\": 2, \"Noble\": 3}\n\nfor df in all_df:\n    df['Title'] = df['Title'].map(title_map)\n    df['Title'] = df['Title'].fillna(0)\n    df['Title'] = df['Title'].astype(int)\n\nall_df = [train_df, test_df]    \ntrain_df.head()","1036440d":"for df in all_df:\n    df['TicketF'] = df.groupby('Ticket')['Ticket'].transform('count')","8a0d92c3":"# drop Name feature\ntrain_df.drop(['Name', 'Ticket'], axis=1, inplace=True)\ntest_df.drop(['Name', 'Ticket'], axis=1, inplace=True)","c5a5d4d4":"# get an overview of dataset\ntrain_df.head(10)","a23284bf":"# prepare train and test dataset\ny_train = train_df['Survived']\n\nfeatures = ['Pclass', 'Sex', 'Age', 'Fare', 'TicketF',\\\n            'Family',  'Title', 'Cabin', 'SibSp', 'Parch', 'Embarked']\n\nX_train_raw = train_df[features]\nX_test_raw = test_df[features]","e5e3e6d5":"sc = StandardScaler()\n\n## transform X_train\nX_train = sc.fit_transform(X_train_raw)\n\n## transform X_test\nX_test = sc.transform(X_test_raw)","58dcb3e4":"# train Random Forest\nforest = RandomForestClassifier(criterion='gini', \n                                n_estimators=1100,\n                                max_depth=5,\n                                min_samples_split=4,\n                                min_samples_leaf=5,\n                                max_features='auto',\n                                oob_score=True,\n                                random_state=42,\n                                n_jobs=-1,\n                                verbose=1)\nforest.fit(X_train, y_train)\n\n# predict\ny_pred = forest.predict(X_train)\n\n# evaluate\nprint('Accuracy Score: ', forest.score(X_train, y_train))\nprint('\\nConfusion Matric: ', confusion_matrix(y_train, y_pred))\nprint('\\nClassification Report: ', classification_report(y_train, y_pred))","8fef7e62":"# obtain importance value of each feature\nimportances = forest.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\nindices = np.argsort(importances)[::-1]\nfeature_df = pd.DataFrame(X_train_raw.columns)\nfeature_df.columns = ['Importance']\n\n# print feature ranking\nfeature_df['Feature'] = pd.Series(importances)\nfeature_df.sort_values(by='Feature', ascending=False, inplace=True)\nprint(feature_df)","de42f2db":"# plot feature ranking\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(feature_df['Importance'], feature_df['Feature'],\n        color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(rotation=45)\nplt.show()","2349c739":"# final prediction\npredict = forest.predict(X_test)\n\n# report\nreport = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': predict})\nreport.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","10a91b58":"Let's look into Cabin feeature.","5fe3c9ac":"We will engineer SibSp and Parch feature into Family(Size) feature. ","6eda148a":"<a id='5'><\/a>\n# 4. Model and Predict","87512a93":"To start, apply pivot table on categorical (Sex, Embarked), ordinal (Pclass) and discrete (SibSp, Parch) features against Survived.","d1dfb0fd":"Numerical features can be classified into two types as followed.\n* Continuous :  Age, Fare\n* Discrete : SibSp, Parch\n\nCategorical features can be classified into two types as followed:\n* Categorical : Survive, Sex, Embarked\n* Ordinal : Pclass","e3be3d33":"> # Content\n\n<a href='#1'>1. Define Problem<\/a>\n\n<a href='#2'>2. Obtain and Load Data<\/a>\n\n<a href='#4'>3. Methodology<\/a>\n\n<a href='#5'>4. Model and Predict<\/a>\n\n<a href='#6'>5. Conclusion<\/a>","35f06b5d":"Let's explore Age and survival.","d8378bd7":"In this notebook, we will explore all of the features given in the data and engineer relevant features to build a machine learning model for predicting survival.","baa1b042":"Correlating: \n* Pclass=1 passengers are most likely to survive.\n* Pclass=3 passengers who are young are least likely to survive\n\n","666dd54f":"Correlating:\n\n* Passengers who paid higher fare are significantly more likely to survive, except for Embarked=Q","1e734493":"### Decision 5: \n\ngroup Age into bands and add Age to model training","feecfa7f":"The question or problem definition for Titanic Survival competition is described here at [Kaggle](https:\/\/www.kaggle.com\/c\/titanic):\n\n> The sinking of the Titanic is one of the most infamous shipwrecks in history.\n> \n> On April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n> \n> While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n> \n> The challenge is to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data, such as name, age, gender, socio-economic class, etc.","7a0b6814":"First step is to import relevant libraries","579cd70a":"### Decision 3: add Embarked to model training","d40ec624":"# Titanic: Beginner's Simple Guide with Random Forest\n\nTopp Theeralerttham\n\n\nUpdated 17\/01\/2021","45e72417":"Correlating:\n* Passenger Embarked=C and =S are more likely to survive.\n* female passengers are more likely to survive, except Embarked=C and Pclass=3.\n* male passengers are less likely to survive, except for Embarked=C.","e211519f":"<a id='1'><\/a>\n# 1. Define Problem","98102b46":"<a id='4'><\/a>\n# 4. Methodology","1f775c66":"### Decision 7: \n\ncreate a new feature Family(Size).","5048cbd1":"Now we can use the above features to train our model.","47231b14":"<a id='2'><\/a>\n# 2. Obtain and Load Data","4d9fa7a8":"Let's now define methodology for analysis and model building.\n\nThe problem is a classification task. Our approach is to transform all of the relevant features into discrete categorical type so they are most compatible with classification algorithm. We hypothesize that this approach will produce the most accurate prediction. \n\nLet's put this into test with 3C framework.\n\n**Correlating (C1)** :\n* females are more likely to survive.\n* younger passengers are more likely to survive.\n* Pclass=1 passengers are most likely to survive.\n* passengers with higher fare are more likely to survive.\n\n**Cleaning (C2)** : \n* fill in missing values for Age and Embark data as they may have correlation.\n* drop Name feature as it is highly non-standard and may not directly contribute to survival.\n* drop PassengerId feature as it does not contribute to survival.\n\n\n**Creating (C3)** :\n* create a new feature Fare range (continuous numerical -> ordinal categorical -> discrete categorical).\n* create a new feature Age range (continuous numerical -> ordinal categorical -> discrete categorical).\n* create a new feature Family(Size) from SibSp and Parch feature.\n* create a new feature Title from Name feature.","717fd9cb":"Let's save into csv for submission.","ae4729e5":"### Decision 2:\n\nadd Pclass to model training","4aef0f99":"Load and get an overview of data","0a2390a8":"First let's perform feature scaling.","2890cd63":"### Decision 4:\n\nadd Cabin to train model","ac22ea1b":"### Decision 6: \n\ngroup Fare into bands and add to model training.","3eb3072c":"Correlating: \n* younger passengers are more likely to survive","e2677679":"### Decision 9: \n\ncreate TicketF(requency) feature from Ticket feature.","c76621f5":"### Decision 1: \n\nmap Sex feature to numbers and add to model training","c38ef25d":"### Decision 8: \n\ncreate two new features, one is Married and another is Title, from Name feature.","14d44bd1":"<a id='6'><\/a>\n# 5. Conclusion","46249fd8":"Correlating:\n* The overview of data above shows that Sex feature correlates with survival.\n* Pclass may have a correlation, but need further analysis.","83b461ec":"Correlating:\n* Passenger in B, D, E Cabin have highest survival rate.\n* Passenger with missing Cabin value have significantly lower survival rate.\n\n","38b90ebb":"Next, we will look at the relationship between Fare and Embarked","b8445c95":"Now let's apply visualization on Embarked, Pclass, Sex, and Embarked to explore potential correlations with Survived."}}