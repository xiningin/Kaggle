{"cell_type":{"03bdd1a9":"code","b71e21b2":"code","fce8a416":"code","391ff895":"code","52ae77d9":"code","2e85db26":"code","97029d75":"code","0631d039":"code","7efc0e0b":"code","6494dab2":"code","20284e4c":"code","720e0049":"code","c9bac75b":"code","e878ae8d":"code","e57e6a50":"code","34be5247":"code","abe8554d":"code","1c1361bd":"code","4a8178a2":"code","49ecbba5":"markdown","e3ee5418":"markdown","1c57666f":"markdown","abaaa0d7":"markdown","034c3348":"markdown","54e2ccb3":"markdown","88e96523":"markdown","2dcefcfe":"markdown"},"source":{"03bdd1a9":"\n\n# ## IMPORT\n\n# In[ ]:\n\n\nimport numpy as np\nimport pandas as pd\nimport datetime\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nimport time\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.metrics import confusion_matrix\nimport pdb\nimport re\nfrom sklearn.preprocessing import LabelEncoder\nimport gc\nimport json, warnings\nfrom lightgbm import LGBMRegressor\nfrom matplotlib import pyplot as plt \nimport seaborn as sns\nimport random as rn\nimport tensorflow as tf\nfrom keras import backend as K\nfrom collections import Counter\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error\nwarnings.filterwarnings('ignore')\ndef init_seeds(seed):\n\n    # The below is necessary for starting Numpy generated random numbers\n    # in a well-defined initial state.\n\n    np.random.seed(seed)\n\n    # The below is necessary for starting core Python generated random numbers\n    # in a well-defined state.\n\n    rn.seed(seed)\n\n    tf.random.set_seed(seed)\n\nSEED = 666\ninit_seeds(SEED)\non_kaggle = True\ntest_code = False\ntest_for_training = True\nnull_importance_cut = -0.3\n\n\n# In[ ]:\n\n\nfrom sklearn.metrics import confusion_matrix\ndef qwk(act,pred,n=4,hist_range=(0,3), weights = None):\n    O = confusion_matrix(act,pred,sample_weight = weights)\n    O = np.divide(O,np.sum(O)) #Agreement Actual\n\n    W = np.zeros((n,n))\n    for i in range(n):\n        for j in range(n):\n            W[i][j] = ((i-j)**2)\/((n-1)**2)\n\n    act_hist = np.histogram(act,bins=n,range=hist_range, weights=weights)[0]\n    prd_hist = np.histogram(pred,bins=n,range=hist_range, weights= weights)[0]\n\n    E = np.outer(act_hist,prd_hist)\n    E = np.divide(E,np.sum(E)) #Agreement Expectation\n\n    num = np.sum(np.multiply(W,O)) #Weighted Agreement Actual\n    den = np.sum(np.multiply(W,E)) #Weighted Agreement Expectation\n\n    return 1-np.divide(num,den)\n\nclass softkappaObjective(object):\n    def calc_ders_range(self, approxes, targets, weights):\n        assert len(approxes) == len(targets)\n        if weights is not None:\n            assert len(weights) == len(approxes)\n        \n        y = targets\n        p = approxes\n        norm = np.dot(p, p) + np.dot(y, y) \n        grad = -np.multiply(2, y) \/ norm + np.multiply(4,  p) * np.dot(y, p) \/ (np.power(norm, 2))\n        hess = np.multiply(8, p) * y \/  (np.power(norm, 2)) + 4 * np.dot(y, p) \/ (np.power(norm, 2))        - (np.multiply(16,  (np.power(p, 2))) * np.dot(y, p)) \/ (np.power(norm, 3))\n        return zip(-grad, -hess)\n    \n\ndef qwk_lgb(y_true, y_pred):\n\n    \"\"\"\n    from https:\/\/www.kaggle.com\/nikhilpraveen\/convert-to-regression\n    Fast cappa eval function for lgb.\n    \"\"\"\n    dist = Counter(new_train['accuracy_group'])\n    for k in dist:\n        dist[k] \/= len(new_train)\n    new_train['accuracy_group'].hist()\n    \n    acum = 0\n    bound = {}\n    for i in range(3):\n        acum += dist[i]\n        bound[i] = np.percentile(y_pred, acum * 100)\n\n    def classify(x):\n        if x <= bound[0]:\n            return 0\n        elif x <= bound[1]:\n            return 1\n        elif x <= bound[2]:\n            return 2\n        else:\n            return 3\n\n    y_pred = np.array(list(map(classify, y_pred))).reshape(y_true.shape)\n\n    return 'cappa', cohen_kappa_score(y_true, y_pred, weights='quadratic'), True\n\nclass qwk_catboost(object):\n    def get_final_error(self, error, weight):\n        return error\n\n    def is_max_optimal(self):\n        return True\n\n    def evaluate(self, approxes, target, weight):\n        assert len(approxes) == 1\n        assert len(target) == len(approxes[0])\n\n        pred = np.array(approxes).flatten()\n        act = np.array(target).flatten()\n        weights = None\n        n=4\n        hist_range=(0,3)\n        cut1 = np.sort(pred)[np.int(np.round(len(act) * 0.239062))] \n        cut2 = np.sort(pred)[np.int(np.round(len(act) * 0.375353))] \n        cut3 = np.sort(pred)[np.int(np.round(len(act) * 0.500000))] \n        pred[pred <= cut1] = 0\n        pred[(pred >= cut1) & (pred <= cut2)] = 1\n        pred[(pred >= cut2) & (pred <= cut3)] = 2\n        pred[(pred >= cut3)] = 3\n        \n        O = confusion_matrix(act,pred,sample_weight = weights)\n        O = np.divide(O,np.sum(O)) #Agreement Actual\n\n        W = np.zeros((n,n))\n        for i in range(n):\n            for j in range(n):\n                W[i][j] = ((i-j)**2)\/((n-1)**2)\n\n        act_hist = np.histogram(act,bins=n,range=hist_range, weights=weights)[0]\n        prd_hist = np.histogram(pred,bins=n,range=hist_range, weights= weights)[0]\n\n        E = np.outer(act_hist,prd_hist)\n        E = np.divide(E,np.sum(E)) #Agreement Expectation\n\n        num = np.sum(np.multiply(W,O)) #Weighted Agreement Actual\n        den = np.sum(np.multiply(W,E)) #Weighted Agreement Expectation\n\n        return 1-np.divide(num,den), 1\n\n    \n\n\n\nclass LabelEncoderExt(object):\n    def __init__(self):\n        \"\"\"\n        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n        \"\"\"\n        self.label_encoder = LabelEncoder()\n        # self.classes_ = self.label_encoder.classes_\n\n    def fit(self, data_list):\n        \"\"\"\n        This will fit the encoder for all the unique values and introduce unknown value\n        :param data_list: A list of string\n        :return: self\n        \"\"\"\n        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n        self.classes_ = self.label_encoder.classes_\n\n        return self\n\n    def transform(self, data_list):\n        \"\"\"\n        This will transform the data_list to id list where the new values get assigned to Unknown class\n        :param data_list:\n        :return:\n        \"\"\"\n        new_data_list = list(data_list)\n        set_ = set(self.label_encoder.classes_)\n        new_data_list = [x if x in set_ else 'Unknown' for x in new_data_list]\n\n        return self.label_encoder.transform(new_data_list)\n\n\n# In[ ]:\n\n\nif on_kaggle:\n    train = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train.csv')\n    train_labels = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train_labels.csv')\n    specs = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/specs.csv')\n    test = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/test.csv')\n    submission = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/sample_submission.csv')\nelse:\n    train = pd.read_csv('..\/DSB\/train.csv')\n    train_labels = pd.read_csv('..\/DSB\/train_labels.csv')\n    specs = pd.read_csv('..\/DSB\/specs.csv')\n    test = pd.read_csv('..\/DSB\/test.csv')\n    submission = pd.read_csv('..\/DSB\/sample_submission.csv')","b71e21b2":"# In[ ]:\n\nimport psutil\nimport os\ndef cpu_stats():\n    pid = os.getpid()\n    py = psutil.Process(pid)\n    memory_use = py.memory_info()[0] \/ 2. ** 30\n    return 'memory GB:' + str(np.round(memory_use, 2))\n\ntrain['timestamp'] = pd.to_datetime(train['timestamp'])\ntest['timestamp'] = pd.to_datetime(test['timestamp'])\ntrain['timestamp'] = train['timestamp'].map(lambda x: x.timestamp()).astype(np.float32)\ntest['timestamp'] = test['timestamp'].map(lambda x: x.timestamp()).astype(np.float32)\n\n\n# In[ ]:\n\n\n### \u7528test\u4e2d\u7684\u6570\u636etraining\n\nmemorytest = False\nif test_for_training:\n    train_cols = list(train.columns)\n    test['index_'] = list(test.sort_values(['installation_id', 'timestamp']).index)\n    assess_index_  = set(test.groupby('installation_id')['index_'].max().values)\n    test_for_train = test.loc[~test['index_'].isin(assess_index_), :].copy()\n    \n    if memorytest:\n        test_for_train_copy = test_for_train.copy()\n        for i in range(9):\n            test_for_train2 = test_for_train_copy.copy()\n            test_for_train2['installation_id'] += str(i)\n            test_for_train2['game_session'] += str(i)\n            test_for_train = pd.concat([test_for_train, test_for_train2.copy()], axis= 0)\n            del test_for_train2\n        del test_for_train_copy\n    \n\n    print(cpu_stats())\n    print(test_for_train.shape)\n    \n    test_for_train.drop(columns=['index_'], inplace= True)\n    test.drop(columns=['index_'], inplace= True)\n\n    train = train[train_cols ]\n    test_for_train = test_for_train[train_cols]\n\n    del assess_index_\n    print(train.shape)\n    print(cpu_stats())    \n\n\n# In[ ]:\n\n\n## hard enconde title to \u9632\u6b62\u56e0\u4e3a\u968f\u673a\u7f16\u7801\u53d8\u5316\nactivities_map = {'Dino Drink': 0, 'Ordering Spheres': 1, 'Tree Top City - Level 1': 2, 'Chicken Balancer (Activity)': 3, 'Scrub-A-Dub': 4, \"Pirate's Tale\": 5, 'Honey Cake': 6, 'Flower Waterer (Activity)': 7, 'All Star Sorting': 8, 'Tree Top City - Level 2': 9, 'Pan Balance': 10, 'Bird Measurer (Assessment)': 11, 'Bottle Filler (Activity)': 12, 'Air Show': 13, 'Fireworks (Activity)': 14, 'Slop Problem': 15, 'Magma Peak - Level 2': 16, 'Dino Dive': 17, 'Leaf Leader': 18, 'Costume Box': 19, 'Mushroom Sorter (Assessment)': 20, 'Chest Sorter (Assessment)': 21, 'Tree Top City - Level 3': 22, '12 Monkeys': 23, 'Crystal Caves - Level 2': 24, 'Treasure Map': 25, 'Rulers': 26, 'Crystals Rule': 27, 'Magma Peak - Level 1': 28, 'Cart Balancer (Assessment)': 29, 'Egg Dropper (Activity)': 30, 'Bug Measurer (Activity)': 31, 'Sandcastle Builder (Activity)': 32, 'Bubble Bath': 33, 'Crystal Caves - Level 1': 34, 'Welcome to Lost Lagoon!': 35, 'Watering Hole (Activity)': 36, 'Crystal Caves - Level 3': 37, 'Heavy, Heavier, Heaviest': 38, 'Lifting Heavy Things': 39, 'Balancing Act': 40, 'Cauldron Filler (Assessment)': 41, 'Chow Time': 42, 'Happy Camel': 43}\ntrain['title'] = train['title'].map(activities_map)\ntest['title'] = test['title'].map(activities_map)\ntrain_labels['title'] = train_labels['title'].map(activities_map)\ntest_for_train['title'] = test_for_train['title'].map(activities_map)\n\n# In[ ]:\n\n\neventid_map = {'3393b68b': '0', '1575e76c': '1', '6c930e6e': '2', '3bfd1a65': '3', 'ac92046e': '4', '01ca3a3c': '5', '2dc29e21': '6', 'acf5c23f': '7', 'd51b1749': '8', '47026d5f': '9', 'f56e0afc': '10', 'ea296733': '11', 'bb3e370b': '12', 'e64e2cfd': '13', 'c51d8688': '14', 'd185d3ea': '15', 'a2df0760': '16', 'daac11b0': '17', '93edfe2e': '18', '4901243f': '19', 'd02b7a8e': '20', '9554a50b': '21', '7423acbc': '22', 'b7dc8128': '23', '04df9b66': '24', 'a1e4395d': '25', '9de5e594': '26', 'ad148f58': '27', '15f99afc': '28', '33505eae': '29', '3d0b9317': '30', '565a3990': '31', '9d4e7b25': '32', 'ab4ec3a4': '33', '736f9581': '34', '56817e2b': '35', 'abc5811c': '36', 'cc5087a3': '37', '90efca10': '38', 'cb6010f8': '39', '44cb4907': '40', 'a76029ee': '41', '6f8106d9': '42', '3a4be871': '43', '2230fab4': '44', '4074bac2': '45', '14de4c5d': '46', '15eb4a7d': '47', '1b54d27f': '48', '30df3273': '49', 'bd701df8': '50', '3ee399c3': '51', '9b23e8ee': '52', '29f54413': '53', 'd45ed6a1': '54', '47f43a44': '55', '5348fd84': '56', '7525289a': '57', '611485c5': '58', 'b80e5e84': '59', '1325467d': '60', '77ead60d': '61', '7fd1ac25': '62', '55115cbd': '63', '3dfd4aa4': '64', '5e109ec3': '65', '89aace00': '66', 'a6d66e51': '67', '3d8c61b0': '68', 'a0faea5d': '69', 'c74f40cd': '70', '4c2ec19f': '71', 'f7e47413': '72', 'b012cd7f': '73', 'ad2fc29c': '74', '8d7e386c': '75', '0330ab6a': '76', 'de26c3a6': '77', '5dc079d8': '78', 'c1cac9a2': '79', '7dfe6d8a': '80', 'e720d930': '81', '77c76bc5': '82', '93b353f2': '83', '804ee27f': '84', '828e68f9': '85', 'f54238ee': '86', 'e9c52111': '87', '53c6e11a': '88', '003cd2ee': '89', '1beb320a': '90', '8f094001': '91', 'e37a2b78': '92', '6cf7d25c': '93', '71e712d8': '94', 'e080a381': '95', '0ce40006': '96', '26fd2d99': '97', 'fcfdffb6': '98', '6f445b57': '99', 'f71c4741': '100', 'f5b8c21a': '101', '2a444e03': '102', 'bdf49a58': '103', '5c2f29ca': '104', '5d042115': '105', 'd2e9262e': '106', '587b5989': '107', 'd3268efa': '108', '7040c096': '109', 'eb2c19cd': '110', '9d29771f': '111', '363d3849': '112', '5290eab1': '113', '46b50ba8': '114', '9ee1c98c': '115', 'b5053438': '116', 'a8cc6fec': '117', '2fb91ec1': '118', '29bdd9ba': '119', '5154fc30': '120', 'c2baf0bd': '121', '87d743c1': '122', '06372577': '123', '00c73085': '124', 'b88f38da': '125', 'c7f7f0e1': '126', 'a52b92d5': '127', '47efca07': '128', 'dcaede90': '129', '5b49460a': '130', 'beb0a7b9': '131', '85d1b0de': '132', '598f4598': '133', '05ad839b': '134', '5be391b5': '135', 'e694a35b': '136', 'd2278a3b': '137', '1af8be29': '138', 'a44b10dc': '139', 'fbaf3456': '140', '4a4c3d21': '141', '532a2afb': '142', '90d848e0': '143', 'e04fb33d': '144', 'ecaab346': '145', '16dffff1': '146', 'a592d54e': '147', '4d911100': '148', 'd3640339': '149', 'b74258a0': '150', 'a16a373e': '151', '8b757ab8': '152', '65a38bf7': '153', '6aeafed4': '154', '3babcb9b': '155', '25fa8af4': '156', 'e7561dd2': '157', '83c6c409': '158', 'b2e5b0f1': '159', '19967db1': '160', '29a42aea': '161', '9e4c8c7b': '162', '17113b36': '163', 'f50fc6c1': '164', '363c86c9': '165', 'e3ff61fb': '166', 'dcb1663e': '167', '1340b8d7': '168', '51311d7a': '169', 'bc8f2793': '170', '16667cc5': '171', '9e34ea74': '172', '67439901': '173', '7d093bf9': '174', 'e79f3763': '175', '02a42007': '176', '91561152': '177', '2c4e6db0': '178', 'c189aaf2': '179', '3ccd3f02': '180', '795e4a37': '181', '7d5c30a2': '182', '65abac75': '183', '28f975ea': '184', '3bf1cf26': '185', '756e5507': '186', '71fe8f75': '187', '3afb49e6': '188', '0413e89d': '189', '28a4eb9a': '190', 'a8876db3': '191', '69fdac0a': '192', '7ab78247': '193', '0d1da71f': '194', '709b1251': '195', '3bb91ced': '196', '76babcde': '197', 'a29c5338': '198', '30614231': '199', '0a08139c': '200', 'db02c830': '201', 'e4d32835': '202', '9ed8f6da': '203', '56cd3b43': '204', 'f3cd5473': '205', 'd88e8f25': '206', '51102b85': '207', 'a8a78786': '208', 'cf7638f3': '209', '5f5b2617': '210', '070a5291': '211', '4d6737eb': '212', '84b0e0c8': '213', '3323d7e9': '214', '0db6d71d': '215', 'c7128948': '216', '84538528': '217', 'f6947f54': '218', 'cf82af56': '219', 'b2dba42b': '220', '1cc7cfca': '221', '08fd73f3': '222', 'df4940d3': '223', '4ef8cdd3': '224', '58a0de5c': '225', 'dcb55a27': '226', 'e57dd7af': '227', 'd2659ab4': '228', 'a1bbe385': '229', 'ca11f653': '230', 'd38c2fd7': '231', '155f62a4': '232', '2b9272f4': '233', '022b4259': '234', 'cdd22e43': '235', '6f4adc4b': '236', 'bbfe0445': '237', 'cfbd47c8': '238', '0086365d': '239', 'f32856e4': '240', '88d4a5be': '241', '37db1c2f': '242', '884228c8': '243', '5e3ea25a': '244', 'f93fc684': '245', '85de926c': '246', 'e4f1efe6': '247', '7cf1bc53': '248', '2b058fe3': '249', '1375ccb7': '250', 'ab3136ba': '251', '763fc34e': '252', 'ecc6157f': '253', 'c54cf6c5': '254', '28ed704e': '255', '2dcad279': '256', '2a512369': '257', 'd9c005dd': '258', '8d748b58': '259', '1996c610': '260', '0d18d96c': '261', '832735e1': '262', '7da34a02': '263', 'd06f75b5': '264', 'f806dc10': '265', '222660ff': '266', '5859dfb6': '267', '77261ab5': '268', '67aa2ada': '269', 'e7e44842': '270', '17ca3959': '271', 'bfc77bd6': '272', 'fd20ea40': '273', 'b7530680': '274', '37c53127': '275', '461eace6': '276', '6088b756': '277', 'c277e121': '278', 'f28c589a': '279', '262136f4': '280', '99ea62f3': '281', '37ee8496': '282', '8fee50e2': '283', '4bb2f698': '284', '119b5b02': '285', '28520915': '286', '5de79a6a': '287', '38074c54': '288', '31973d56': '289', '857f21c0': '290', '923afab1': '291', 'cb1178ad': '292', 'b1d5101d': '293', 'b120f2ac': '294', '36fa3ebe': '295', '6bf9e3e1': '296', 'ec138c1c': '297', '5e812b27': '298', 'a8efe47b': '299', '86c924c4': '300', 'bcceccc6': '301', '562cec5f': '302', '48349b14': '303', '392e14df': '304', 'e5c9df6f': '305', '26a5a3dd': '306', 'ea321fb1': '307', '6d90d394': '308', '7372e1a5': '309', '3edf6747': '310', '6c517a88': '311', '3ddc79c3': '312', '99abe2bb': '313', '9b4001e4': '314', '74e5f8a7': '315', '5c3d2b2f': '316', 'a5be6304': '317', '3d63345e': '318', 'b738d3d3': '319', '4b5efe37': '320', '3b2048ee': '321', 'a5e9da97': '322', 'c952eb01': '323', '9b01374f': '324', '7f0836bf': '325', '37937459': '326', '9e6b7fb5': '327', '13f56524': '328', '73757a5e': '329', '15ba1109': '330', '08ff79ad': '331', '1bb5fbdb': '332', '45d01abe': '333', '2ec694de': '334', 'a1192f43': '335', 'ecc36b7f': '336', '250513af': '337', 'e5734469': '338', '3bb91dda': '339', 'c58186bf': '340', '15a43e5b': '341', '6077cc36': '342', '3afde5dd': '343', '8d84fa81': '344', '86ba578b': '345', '6f4bd64e': '346', '1c178d24': '347', '6043a2b4': '348', '499edb7c': '349', 'c7fe2a55': '350', '907a054b': '351', 'd3f1e122': '352', '5f0eb72c': '353', '92687c59': '354', '9565bea6': '355', 'c0415e5c': '356', '7ad3efc6': '357', '4a09ace1': '358', '63f13dd7': '359', '49ed92e9': '360', '1f19558b': '361', '90ea0bac': '362', '8ac7cce4': '363', '160654fd': '364', '895865f3': '365', '7961e599': '366', '4e5fc6f5': '367', '9ce586dd': '368', '731c0cbe': '369', '9c5ef70c': '370', '8af75982': '371', 'd122731b': '372', '7ec0c298': '373', '56bcd38d': '374', '3dcdda7f': '375', 'bd612267': '376', 'd88ca108': '377', '46cd75b4': '378', 'c6971acf': '379', '792530f8': '380', '1cf54632': '381', 'a7640a16': '382', '5a848010': '383', 'df4fe8b6': '384', '27253bdc': '385'}\ntrain['event_id'] = train['event_id'].map(eventid_map)\ntest['event_id'] = test['event_id'].map(eventid_map)\nspecs['event_id'] = specs['event_id'].map(eventid_map)\ntest_for_train['event_id'] = test_for_train['event_id'].map(eventid_map)\n\n# In[ ]:\n\n\nwin_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\nwin_code[activities_map['Bird Measurer (Assessment)']] = 4110\n\n\n# In[ ]:\n\n\nclip_length_map = {\"Costume Box\":61,\n\"12 Monkeys\":109,\n\"Tree Top City - Level 2\":25,\n\"Lifting Heavy Things\":118,\n\"Crystal Caves - Level 3\":19,\n\"Rulers\":126,\n\"Ordering Spheres\":61,\n\"Balancing Act\":72,\n\"Welcome to Lost Lagoon!\":19,\n\"Magma Peak - Level 1\":20,\n\"Tree Top City - Level 1\":17,\n\"Treasure Map\":156,\n\"Heavy, Heavier, Heaviest\":61,\n\"Crystal Caves - Level 2\":24,\n\"Tree Top City - Level 3\":26,\n\"Honey Cake\":142,\n\"Magma Peak - Level 2\":22,\n\"Pirate's Tale\": 80,\n\"Crystal Caves - Level 1\":18,\n\"Slop Problem\":60}\nclip_length_map = {activities_map[e]: clip_length_map[e] for e in clip_length_map}\n\n\n# In[ ]:\n\n\nstart_time = pd.Timestamp('2019-01-01 00:00:00', tz='UTC').timestamp()\ntitles = train.title.unique()\ntitles_noclip = train.loc[train.type != 'Clip','title'].unique()\nactivities = train.type.unique()\nworlds = train.world.unique()\nevent_codes = train.event_code.unique()\ntypes= train.type.unique()\neventids = specs.event_id.unique()\n# title_events = train['title_events'].unique()\ndrug_duration_events = set(specs.loc[specs['info'].str.contains('drag') & (specs['args'].str.contains('coordinate')) &(specs['args'].str.contains('duration')) ,'event_id'])\n\n\n# ##  miscliking heatmap\nheatmaps = {}\nw = 500\nh = 400\nfor e in types:\n    if e == 'Clip':\n        continue\n    titles_ = train.loc[ train.type == e, :].title.unique()\n    print(f'{e} has event4070 ', len(train.loc[(train['type'] == e)&(train['event_code'] == 4070), 'event_data'].map(lambda x: json.loads(x))))\n    for i in titles_:\n        df_tmp  =train.loc[(train['type'] == e)&(train['event_code'] == 4070)&(train['title']==i), 'event_data']\n        df_tmp_test  =test.loc[(test['type'] == e)&(test['event_code'] == 4070)&(test['title']==i), 'event_data']\n        \n        print(f'{e} title{i} {4070} has', len(df_tmp))\n\n        coordinates =df_tmp.map(lambda x: json.loads(x)['coordinates'])\n        coordinates_test =  df_tmp_test.map(lambda x: json.loads(x)['coordinates'])\n        \n        x = (coordinates.map(lambda d:d['x']) \/ coordinates.map(lambda d:d['stage_width']) * w).map(np.floor).map(int)\n        y = (coordinates.map(lambda d:d['y']) \/ coordinates.map(lambda d:d['stage_height'])* h).map(np.floor).map(int)\n       \n        x_test = (coordinates_test.map(lambda d:d['x']) \/ coordinates_test.map(lambda d:d['stage_width']) * w).map(np.floor).map(int)\n        y_test = (coordinates_test.map(lambda d:d['y']) \/ coordinates_test.map(lambda d:d['stage_height'])* h).map(np.floor).map(int)        \n        \n        x = x.clip(0,w-1)\n        y = y.clip(0,h -1)\n        \n        x_test = x_test.clip(0, w-1)\n        y_test = y_test.clip(0,h -1)\n        \n        heatmap_ = np.ones((h, w))\n        for y0, x0 in zip(x,y):\n            heatmap_[x0,y0] += 1\n        \n        for y0, x0 in zip(x_test,y_test):\n            heatmap_[x0,y0] += 1\n        heatmaps[f'{i}_4070'] = 1 \/ heatmap_\n#         heatmap_ = np.clip(heatmap_,0,50)\n#         f , ax = plt.subplots(figsize = (14,12))\n#         plt.title(f'{e} title{i} {4070} has {len(df_tmp)}')\n#         sns.heatmap(heatmap_)\n        try:\n            del df_tmp, df_tmp_test, x_test, y_test\n        except:\n            pass\n       \n\n\n##\n\nheatmaps4035 = {}\nw2 = 250\nh2 = 200\nfor e in types:\n    if e == 'Clip':\n        continue\n    titles_ = train.loc[ train.type == e, :].title.unique()\n    print(f'{e} has event4035 ', len(train.loc[(train['type'] == e)&(train['event_code'] == 4035), 'event_data'].map(lambda x: json.loads(x))))\n    for i in titles_:\n        df_tmp  =train.loc[(train['type'] == e)&(train['event_code'] == 4035)&(train['title']==i), 'event_data']\n        df_tmp_test  =test.loc[(test['type'] == e)&(test['event_code'] == 4035)&(test['title']==i), 'event_data']\n        \n        print(f'{e} title{i} {4035} has', len(df_tmp))\n\n        coordinates =df_tmp.map(lambda x: json.loads(x)['coordinates'])\n        coordinates_test =  df_tmp_test.map(lambda x: json.loads(x)['coordinates'])\n        \n        x = (coordinates.map(lambda d:d['x']) \/ coordinates.map(lambda d:d['stage_width']) * w2).map(np.floor).map(int)\n        y = (coordinates.map(lambda d:d['y']) \/ coordinates.map(lambda d:d['stage_height'])* h2).map(np.floor).map(int)\n       \n        x_test = (coordinates_test.map(lambda d:d['x']) \/ coordinates_test.map(lambda d:d['stage_width']) * w2).map(np.floor).map(int)\n        y_test = (coordinates_test.map(lambda d:d['y']) \/ coordinates_test.map(lambda d:d['stage_height'])* h2).map(np.floor).map(int)        \n        \n        x = x.clip(0,w2-1)\n        y = y.clip(0,h2 -1)\n        \n        x_test = x_test.clip(0, w2-1)\n        y_test = y_test.clip(0,h2 -1)\n        \n        heatmap_ = np.ones((h2, w2))\n        for y0, x0 in zip(x,y):\n            heatmap_[x0,y0] += 1\n        \n        for y0, x0 in zip(x_test,y_test):\n            heatmap_[x0,y0] += 1\n        heatmaps4035[f'{i}_4035'] = 1 \/ heatmap_\n#         heatmap_ = np.clip(heatmap_,0,20)\n#         f , ax = plt.subplots(figsize = (14,12))\n#         plt.title(f'{e} title{i} {4035} has {len(df_tmp)}')\n#         sns.heatmap(heatmap_)\n        try:\n            del df_tmp, df_tmp_test, x_test, y_test\n        except:\n            pass\n        \n        \n# In[ ]:\ntest.to_csv('test.csv', index = False)\ndel test\ngc.collect()\n\n\ntrain = pd.concat([train, test_for_train], axis= 0)\ntrain.reset_index(drop = True, inplace = True)\ndel test_for_train\ngc.collect()\n\n\n\ntrain_41004110 = train.loc[((train.title == 11) & (train.event_code == 4110)) | ((train.title.isin([20, 21, 29, 41])) & (train.event_code == 4100)), ]\ntrain_41004110['attemps'] = train_41004110['event_data'].str.contains('true') + train_41004110['event_data'].str.contains('false')\nattemp_dict = train_41004110['attemps']  > 0 \ntrain['attemps']  = pd.Series(train.index).map(attemp_dict).fillna(False)\ndel train_41004110, attemp_dict\n\n\n# In[ ]:\n\n\ntrain_41004110 = train.loc[((train.title == 11) & (train.event_code == 4110)) | ((train.title.isin([20, 21, 29, 41])) & (train.event_code == 4100)), ]\ntrain_41004110['attemps'] = train_41004110['event_data'].str.contains('true') + train_41004110['event_data'].str.contains('false')\nattemp_dict = train_41004110['attemps']  > 0 \ntrain['attemps']  = pd.Series(train.index).map(attemp_dict).fillna(False)\ntrain['attemps'] = train.groupby('game_session')['attemps'].transform('sum') >0 #\u5982\u679c\u662f17690\u4e2a\u4e2d\u7684 \u4e3aTRUE\ndel train_41004110,attemp_dict\n\n\n\n\n# In[ ]:\n\n","fce8a416":"\n\n# In[ ]:\n\n\n##title_duration mean min max std\n##title_bag,  like word bagging\n##event_bagging,  like word bagging\n\n##null importance fe selection\n##recursive selection with cv and plot\n\ntest_code = False\nif test_code:\n    id_ = set(list(train.installation_id.unique())[300:600])\n    train = train.loc[train.installation_id.isin(id_ ), :]\n    \ndef session_setup(session, test_set,features):\n    kid_id = session['installation_id'].iloc[0]\n    session_type = session['type'].iloc[0]\n    session_title = session['title'].iloc[0]\n    session_world = session['world'].iloc[0]\n    features['kid_id'] = kid_id\n    features['game_session'] = session['game_session'].iloc[0]\n    if test_set == True:\n        second_condition = True\n    else:\n        if len(session)>1:\n            second_condition = True\n        else:\n            second_condition= False\n    return kid_id, session_type, session_title, session_world, second_condition, features\n\ndef append_all_assessments(all_assessments, features,session, test_set, counter):\n    if test_set == True:\n        all_assessments.append(features.copy())\n    else:\n        if session['attemps'].iloc[0]:\n            all_assessments.append(features.copy())            \n    counter += 1\n    return all_assessments, features, counter\n\ndef compile_data(train, function,test_set =  False):\n    compiled_data = []\n    for i, (ins_id, user_sample) in enumerate(train.groupby('installation_id', sort=False)):\n        if  test_set:\n            compiled_data += [function(user_sample.copy(), test_set = test_set)]\n        else:\n            compiled_data += function(user_sample.copy(), test_set = test_set)\n        del i, (ins_id, user_sample)\n    return pd.DataFrame(compiled_data.copy())\n","391ff895":"# ### get_data_XXX (fuction)\n\n# In[ ]:\n\ndef get_data_distraction(user_sample, test_set=False):\n    all_assessments = []\n    features = {}\n    distraction_total = np.array([])\n    distraction = {title: np.array([])  for title in  titles}  \n    counter = 0    \n    for i, session in user_sample.groupby('game_session', sort=False):\n        kid_id, session_type, session_title, session_world, second_condition, features= session_setup(session, test_set, features)\n        if (session_type == 'Assessment') & (second_condition):\n            features['distraction_mean'] = np.mean(distraction_total)\n            distraction_title_mean = {f'distraction_title{title_}': np.mean(distraction[title_]) for title_ in titles}\n            distraction_title_count = {f'distraction_count_title{title_}': len(distraction[title_]) for title_ in titles}\n            features.update(distraction_title_mean)\n            features.update(distraction_title_count)    \n            all_assessments, features, counter = append_all_assessments(all_assessments,  features, session,test_set, counter)\n        \n        if (session_type != 'Clip')& (second_condition):\n            df_tmp  =session.loc[session['event_code'] == 4070, 'event_data']\n            coordinates =df_tmp.map(lambda x: json.loads(x)['coordinates']).copy()\n            x = (coordinates.map(lambda d:d['x']) \/ coordinates.map(lambda d:d['stage_width']) * w).map(np.floor).map(int)\n            y = (coordinates.map(lambda d:d['y']) \/ coordinates.map(lambda d:d['stage_height'])* h).map(np.floor).map(int)        \n            x = x.clip(0,w-1)\n            y = y.clip(0,h-1)\n            session_title_ = [session_title] * len(x)\n            distraction_= np.array([heatmaps[str(session_title_2) + '_4070'][x_, y_] for x_, y_, session_title_2 in zip(y, x,session_title_)])\n            distraction_total = np.concatenate([distraction_total, distraction_.copy()])\n            distraction[session_title]  = np.concatenate([distraction[session_title], distraction_.copy()])            \n            del df_tmp, coordinates, x, y,distraction_,session_title_\n        del i, session\n    del distraction_total,distraction, features\n    if test_set:\n        return all_assessments[-1]\n    return all_assessments\n\ndef get_data_4035(user_sample, test_set=False):\n    all_assessments = []\n    features = {}\n    distraction_total = np.array([])\n    distraction = {title: np.array([])  for title in  titles}  \n    counter = 0    \n    for i, session in user_sample.groupby('game_session', sort=False):\n        kid_id, session_type, session_title, session_world, second_condition, features= session_setup(session, test_set, features)\n        if (session_type == 'Assessment') & (second_condition):\n            features['4035_mean'] = np.mean(distraction_total)\n            distraction_title_mean = {f'4035_title{title_}': np.mean(distraction[title_]) for title_ in titles}\n            distraction_title_count = {f'4035_count_title{title_}': len(distraction[title_]) for title_ in titles}\n            features.update(distraction_title_mean)\n            features.update(distraction_title_count)    \n            all_assessments, features, counter = append_all_assessments(all_assessments,  features, session,test_set, counter)\n        \n        if (session_type != 'Clip')& (second_condition):\n            df_tmp  =session.loc[session['event_code'] == 4035, 'event_data']\n            coordinates =df_tmp.map(lambda x: json.loads(x)['coordinates'])\n            x = (coordinates.map(lambda d:d['x']) \/ coordinates.map(lambda d:d['stage_width']) * w2).map(np.floor).map(int)\n            y = (coordinates.map(lambda d:d['y']) \/ coordinates.map(lambda d:d['stage_height'])* h2).map(np.floor).map(int)        \n            x = x.clip(0,w2-1)\n            y = y.clip(0,h2-1)\n            session_title_ = [session_title] * len(x)\n            distraction_= np.array([heatmaps4035[str(session_title_2) + '_4035'][x_, y_] for x_, y_, session_title_2 in zip(y, x,session_title_)])\n            distraction_total = np.concatenate([distraction_total, distraction_])\n            distraction[session_title]  = np.concatenate([distraction[session_title], distraction_])            \n    \n    if test_set:\n        return all_assessments[-1]\n    return all_assessments\n\n\ndef get_data_basic(user_sample, test_set=False):\n    all_assessments = []\n    features = {}\n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    user_activities_count.update({'title_' + str(title): 0 for title in titles})\n    user_activities_count.update({'event_' + str(event): 0 for event in event_codes})\n    user_activities_count.update({'eventid_' + str(eventid): 0 for eventid in eventids})\n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    accumulated_accuracy_group = 0\n    accumulated_accuracy=0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0 \n    accumulated_actions = 0\n    counter = 0    \n    world_title = {'CRYSTALCAVES':set([34, 42, 40, 24, 37,  3, 39, 10, 43,  6, 29, 38, 30, 21, 18]),\n    'MAGMAPEAK':set([28, 32,  4, 16,  0, 36, 15, 33, 12, 17, 41]), \n    'TREETOPCITY':set([2,  1,  8, 19, 14, 23,  9,  7,  5, 20, 13, 25, 22, 27, 26, 31, 11])}\n    title_order = []\n    for i, session in user_sample.groupby('game_session', sort=False):\n        kid_id, session_type, session_title, session_world, second_condition, features= session_setup(session, test_set, features)\n        if (session_type == 'Assessment') & (second_condition):\n            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n            features.update(user_activities_count.copy())\n            features['session_title'] = session['title'].iloc[0] \n            features['session_world'] = session['world'].iloc[0]\n            features['nunique_title'] = len(set(title_order))\n            features['nunique_title_in_this_world']  = len(set(title_order) & world_title[session_world])\n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n            features['accumulated_accuracy'] = accumulated_accuracy\/counter if counter > 0 else -9\n            accuracy = true_attempts\/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            accumulated_accuracy += accuracy\n            if accuracy == 0:\n                features['accuracy_group'] = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2 # the assessment was solved on the second attempt\n            else:\n                features['accuracy_group'] = 1 # the assessment was solved after 3 or more attempts\n            features.update(accuracy_groups.copy())\n            features['accuracy'] = accuracy\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group\/counter if counter > 0 else -9\n            features['accumulated_actions'] = accumulated_actions\n            accumulated_accuracy_group += features['accuracy_group']\n            accuracy_groups[features['accuracy_group']] += 1\n            all_assessments, features, counter = append_all_assessments(all_assessments,  features, session,test_set, counter)\n        \n        dict_ = session['event_code'].value_counts().to_dict()\n        dict_ =  {f'event_{str(e)}': user_activities_count[f'event_{str(e)}'] + dict_[e] for e in dict_}\n        user_activities_count.update(dict_.copy())\n        dict_ = session['event_id'].value_counts().to_dict()\n        dict_ =  {f'eventid_{str(e)}': user_activities_count[f'eventid_{str(e)}'] + dict_[e] for e in dict_}\n        user_activities_count.update(dict_.copy())      \n        user_activities_count[session_type] += 1\n        user_activities_count['title_' + str(session_title)] += 1\n        accumulated_actions += len(session)\n        \n        title_order += [session_title]\n    if test_set:\n        return all_assessments[-1] \n    return all_assessments\n\ndef get_data_duration(user_sample, test_set=False):\n    user_sample_copy  = user_sample.copy()\n    user_sample_copy['time_till_next_action'] = -user_sample_copy['timestamp'].diff(-1)\n    all_assessments = []\n    features = {}\n    clip_durations = []\n    activity_durations = []\n    assessment_durations = []\n    game_durations = []\n    title_duration = {title: []  for title in  titles}\n    counter = 0    \n    for i, session in user_sample_copy.groupby('game_session', sort=False):\n        kid_id, session_type, session_title, session_world, second_condition, features= session_setup(session, test_set, features)\n        sessoion_duration = np.clip(session.iloc[-1, 2] - session.iloc[0, 2],0,1000)\n        if (session_type == 'Clip'):        \n            sessoion_duration = session['time_till_next_action'].fillna(0).clip(0, clip_length_map[session_title]).sum()\n            clip_durations.append(sessoion_duration)\n        if (session_type == 'Game')& (second_condition):\n            game_durations.append(session.iloc[-1, 2] - session.iloc[0, 2] )\n        if (session_type == 'Activity')& (second_condition):\n            activity_durations.append(session.iloc[-1, 2] - session.iloc[0, 2] )\n        if (session_type == 'Assessment') & (second_condition):\n            features['clip_duration_mean'] = pd.Series(clip_durations).mean()\n            features['clip_duration_max'] = pd.Series(clip_durations).max()\n            features['clip_duration_sum'] = pd.Series(clip_durations).sum() if  clip_durations != [] else 0   \n            features['activity_duration_mean'] = pd.Series(activity_durations).mean()\n            features['activity_duration_max'] = pd.Series(activity_durations).max()\n            features['activity_duration_sum'] = pd.Series(activity_durations).sum()  if  activity_durations != [] else 0   \n            features['assessment_duration_mean'] = pd.Series(assessment_durations).mean()\n            features['assessment_duration_max'] = pd.Series(assessment_durations).max()\n            features['assessment_duration_sum'] = pd.Series(assessment_durations).sum()  if  assessment_durations != [] else 0   \n            features['game_duration_mean'] = pd.Series(game_durations).mean() \n            features['game_duration_max'] = pd.Series(game_durations).max() \n            features['game_duration_sum'] = pd.Series(game_durations).sum() if  game_durations != [] else 0\n            title_duration_mean = {f'title{title}_duration_mean': np.mean(title_duration[title]) if title_duration[title] != [] else -9 for title in  titles}\n            title_duration_max = {f'title{title}_duration_max': np.std(title_duration[title]) if title_duration[title] != [] else -9 for title in  titles}\n            title_duration_sum = {f'title{title}_duration_sum': np.sum(title_duration[title]) if title_duration[title] != [] else 0 for title in  titles}\n            features.update(title_duration_mean.copy())\n            features.update(title_duration_max.copy())\n            features.update(title_duration_sum.copy())\n            #\u66f4\u65b0\n            assessment_durations.append(np.clip(session.iloc[-1, 2] - session.iloc[0, 2], 0, 1000))\n            all_assessments, features, counter = append_all_assessments(all_assessments,  features, session,test_set, counter)\n        \n        #record this title_duration for later use\n        title_duration[session_title].append(sessoion_duration)\n    if test_set:\n        return all_assessments[-1] \n    return all_assessments\n\ndef get_data_correcy(user_sample, test_set=False):\n    user_sample_copy  = user_sample.copy()\n    user_sample_copy['time_till_next_action'] = -user_sample_copy['timestamp'].diff(-1)\n    all_assessments = []\n    features = {}\n    correcy_assessment = []\n    correcy_game =  []\n    correcy_all =  []\n    game_assessment = [0, 4, 8, 10, 11, 13, 17, 18, 20, 21, 27, 29, 33, 41, 42, 43]\n    games =[0, 4, 8, 10, 13, 17, 18, 27, 33, 42, 43]\n    assessments = [11, 20, 21, 29, 41]\n    correcy_title = {e: [] for e in  game_assessment} #game assessment \n    counter = 0    \n    for i, session in user_sample_copy.groupby('game_session', sort=False):\n        kid_id, session_type, session_title, session_world, second_condition, features= session_setup(session, test_set, features)\n        if (session_type == 'Assessment') & (second_condition):\n            features['correcy_all_mean'] = np.mean(np.concatenate(correcy_all)) if correcy_all != [] else -1\n            features['correcy_all_count'] = len(np.concatenate(correcy_all)) if correcy_all != [] else 0\n            features['correcy_all_mean_mean'] =  np.mean([np.mean(e) for e in correcy_all if e != []])  \n            features['correcy_all_mean_std'] =  np.mean([np.mean(e) for e in correcy_all if e != []])  \n                \n            features['correcy_game_mean'] = np.mean(np.concatenate(correcy_game)) if correcy_game != [] else -1\n            features['correcy_game_count'] =  len(np.concatenate(correcy_game))   if correcy_game != [] else 0\n            features['correcy_game_mean_mean'] =  np.mean([np.mean(e) for e in correcy_game if e != []])  \n \n            \n            \n            features['correcy_assessment_mean'] = np.mean(np.concatenate(correcy_assessment)) if correcy_assessment != [] else -1\n            features['correcy_assessment_count'] = len(np.concatenate(correcy_assessment))  if correcy_assessment != [] else 0\n            features['correcy_assessment_mean_mean'] =  np.mean([np.mean(e) for e in correcy_assessment if e != []])  \n            \n            correcy_title_mean = {f'correcy_mean_title{title}': np.mean(np.concatenate(correcy_title[title])) if correcy_title[title] != [] else -9 for title in  assessments}\n            correcy_title_count = {f'correcy_count_title{title}': len(np.concatenate(correcy_title[title]))  if correcy_title[title] != [] else 0 for title in  assessments}\n            correcy_title_mean_mean = {f'correcy_mean_mean_title{title}': np.mean([np.mean(e) for e in correcy_title[title] if e != []]) for title in  assessments}\n            correcy_title_max= {f'correcy_max_title{title}': np.max([np.mean(e) for e in correcy_title[title] if e != []])                                                                                             if len([np.mean(e) for e in correcy_title[title] if e != []]) != 0 else -9 \n                                                                                            for title in  assessments}\n            features.update(correcy_title_mean.copy())\n            features.update(correcy_title_count.copy())\n            features.update(correcy_title_mean_mean.copy())\n            features.update(correcy_title_max.copy())\n        \n            features['assessment_tried_ratio'] = sum([0 if e == [] else 1 for e in correcy_assessment]) \/ len(correcy_assessment) if  len(correcy_assessment) !=0 else -9\n            features['game_tried_ratio'] = sum([0 if e == [] else 1 for e in correcy_game]) \/ len(correcy_game)  if  len(correcy_game) !=0 else -9\n            all_assessments, features, counter = append_all_assessments(all_assessments,  features, session,test_set, counter)\n        if session_type in ['Assessment', 'Game']:\n            correct = session.loc[:, 'event_data'].map(lambda x: json.loads(x)['correct'] if 'correct' in  json.loads(x) else -1)\n            correct = list(correct[correct != -1].replace([True, False], [1, 0]))\n            correcy_all.append(correct.copy())\n            correcy_title[session_title].append(correct.copy())\n            if session_type == 'Game': \n                correcy_game.append(correct.copy())\n            else:\n                correcy_assessment.append(correct.copy())\n    if test_set:\n        return all_assessments[-1] \n    return all_assessments\n\ndef get_data_lag(user_sample, test_set=False):\n    all_assessments = []\n    features = {}\n    title_lasttime = {title: start_time  for title in  titles} #time since last this title\n    title_acc_lasttime = {title: -1  for title in  titles}\n    title_acc_group_lasttime = {title: -1  for title in  titles}\n    title_attemp_lasttime = {title: -1  for title in  titles}\n    world_name_lasttime = 'start'\n    title_trace = [-1]   \n    try:\n        first_session_world = user_sample.loc[user_sample['world'] != 'NONE','world'].values[0]\n    except:\n        first_session_world = 'NONE'\n    try:\n        first_session_title = user_sample.loc[user_sample['title'] != 35,'title'].values[0]    \n    except:\n        first_session_title = 35  \n    try:\n        first_session_type = user_sample.loc[user_sample['title'] != 35,'type'].values[0]    \n    except:\n        first_session_type = 'Clip'  \n    first_session_type = user_sample['type'].values[0]\n    \n    counter = 0    \n    for i, session in user_sample.groupby('game_session', sort=False):\n        kid_id, session_type, session_title, session_world, second_condition, features= session_setup(session, test_set, features)\n        sessoion_duration =session.iloc[-1, 2] - session.iloc[0, 2]\n        if (session_type == 'Assessment') & (second_condition):\n            features['title_lasttime'] = session.iloc[0, 2] - title_lasttime[session_title]\n            features['title_acc_lasttime'] = title_acc_lasttime[session_title]\n            features['title_attemp_lasttime'] = title_attemp_lasttime[session_title]  \n            features['title_name_lag2'] = f'{title_trace[-1]}_{session_title}'\n            features['title_name_lag3'] = f'{title_trace[-2]}_{title_trace[-1]}_{session_title}' if len(title_trace)>=3 else 'NAN'\n            features['title_name_lag4'] = f'{title_trace[-3]}_{title_trace[-2]}_{title_trace[-1]}_{session_title}' if len(title_trace)>=4 else 'NAN'\n            features['title_name_lasttime'] = title_trace[-1]\n            features['world_name_lasttime'] = world_name_lasttime\n            features['first_session_world'] = first_session_world\n            features['first_session_title'] = first_session_title\n            features['first_session_type'] = first_session_type\n            features['hour'] = pd.Timestamp.fromtimestamp(session['timestamp'].iloc[0]).hour\n            features['dow'] = pd.Timestamp.fromtimestamp(session['timestamp'].iloc[0]).weekday()\n            all_assessments, features, counter = append_all_assessments(all_assessments,  features, session,test_set, counter)\n            \n        if session_type == 'Assessment':\n            correct = session.loc[:, 'event_data'].map(lambda x: json.loads(x)['correct'] if 'correct' in  json.loads(x) else -1)\n            correct = list(correct[correct != -1].replace([True, False], [1, 0]))\n            title_acc_lasttime[session_title] = np.mean(correct) if correct != [] else -9\n            title_attemp_lasttime[session_title]  = len(correct)\n        title_lasttime[session_title] = session.iloc[-1,2] \n        title_trace.append(session_title)           \n        world_name_lasttime= session_world\n    if test_set:\n        return all_assessments[-1] \n    return all_assessments\n\n\n\ndef get_data_MissRoundLevel(user_sample, test_set=False):\n    all_assessments = []\n    features = {}\n    games = [] # game with misses \n    assessments = []\n    title_misses_sum = {f'title_misses_sum' + str(title): 0 for title in titles}\n    title_misses_order = {f'title_misses_order' + str(title): [] for title in titles}\n    title_misses_duration_order =  {f'title_misses_duration_order' + str(title): [] for title in titles}\n    title_attemps_sum = {f'title_attemps_sum' + str(title): 0 for title in titles}\n    title_rounds_sum = {f'title_rounds_sum' + str(title): 0 for title in titles}\n    title_level_max = {f'title_level_max' + str(title): 0 for title in titles}\n    counter = 0   \n    def cnt_(df):\n        cnt_miss = 0\n        cnt_miss_order = []\n        cnt_miss_duration =  []\n        cnt_attmpts = 0\n        cnt_rounds = 0\n        cnt_level = 0\n        for e in range(len(df)):\n            x = df['event_data'].iloc[e]\n            try:\n                y = json.loads(x)['misses']\n                cnt_miss_order.append(y)\n                cnt_miss_duration.append(np.clip(json.loads(x)['duration'], 0, 300000))\n                cnt_miss += y\n            except:\n                pass\n            try:\n                y = json.loads(x)['correct']\n                cnt_attmpts += y\n            except:\n                pass\n            try:\n                y = json.loads(x)['round']\n                cnt_rounds = np.max([cnt_rounds, y])\n            except:\n                pass\n            try:\n                y = json.loads(x)['level']\n                cnt_level = np.max([cnt_level, y])\n            except:\n                pass\n        return {'cnt_miss': cnt_miss,\n                      'cnt_miss_order':cnt_miss_order,\n                      'cnt_miss_duration': cnt_miss_duration,\n                      'cnt_attmpts':cnt_attmpts,\n                      'cnt_rounds':cnt_rounds, \n                      'cnt_level':cnt_level}\n    for i, session in user_sample.groupby('game_session', sort=False):\n        kid_id, session_type, session_title, session_world, second_condition, features= session_setup(session, test_set, features)\n\n        if (session_type == 'Assessment') & (second_condition):\n            features.update(title_misses_sum.copy())\n            features.update( {e + '_mean': np.mean(title_misses_order[e]) for e in title_misses_order})\n            features.update( {e + '_std': np.std(title_misses_order[e]) for e in title_misses_order})\n            features.update( {e + '_mean': np.mean(title_misses_duration_order[e]) for e in title_misses_duration_order})\n            features.update(title_attemps_sum.copy())\n            features.update(title_rounds_sum.copy())\n            features.update(title_level_max.copy())\n            all_assessments, features, counter = append_all_assessments(all_assessments,  features, session,test_set, counter)          \n        \n        counts_ = cnt_(session)\n        title_misses_sum[f'title_misses_sum' + str(session_title)] += counts_['cnt_miss']\n        title_misses_order[f'title_misses_order' + str(session_title)] += (counts_['cnt_miss_order'])\n        title_misses_duration_order[f'title_misses_duration_order' + str(session_title)] += (counts_['cnt_miss_duration'])\n        title_attemps_sum[f'title_attemps_sum'  + str(session_title)] += counts_['cnt_attmpts']\n        title_rounds_sum[f'title_rounds_sum'  + str(session_title)]+= counts_['cnt_rounds']\n        title_level_max[f'title_level_max' + str(session_title)] = np.max([title_level_max[f'title_level_max' + str(session_title)], counts_['cnt_level']])\n        \n    if test_set:\n        return all_assessments[-1] \n    return all_assessments","52ae77d9":"# ### compile train\n# In[ ]:\n","2e85db26":"if True:\n    new_train_distraction = compile_data(train, get_data_distraction)\n    new_train_4035 = compile_data(train, get_data_4035)\n    new_train_basic = compile_data(train, get_data_basic)\n    new_train_duration = compile_data(train, get_data_duration)\n    new_train_correcy = compile_data(train, get_data_correcy)\n    new_train_lag = compile_data(train, get_data_lag)\n    new_train_MissRoundLevel = compile_data(train, get_data_MissRoundLevel)\n\n    new_train_distraction.to_csv('new_train_distraction.csv', index = False)\n    new_train_4035.to_csv('new_train_4035.csv', index = False)\n    new_train_basic.to_csv('new_train_basic.csv', index = False)\n    new_train_duration.to_csv('new_train_duration.csv', index = False)\n    new_train_correcy.to_csv('new_train_correcy.csv', index = False)\n    new_train_lag.to_csv('new_train_lag.csv', index = False)\n    new_train_MissRoundLevel.to_csv('new_train_MissRoundLevel.csv', index = False)\n\n    print(new_train_distraction.shape)\n    print(new_train_basic.shape)\n    print(new_train_duration.shape)\n    print(new_train_correcy.shape)\n    print(new_train_lag.shape)\n    print(new_train_MissRoundLevel.shape)","97029d75":"# ### add more features (fuction)\n\n# In[ ]:\n\n\nassessments = [11, 20, 21, 29, 41]\ngames =[0, 4, 8, 10, 13, 17, 18, 27, 33, 42, 43]\n#add more feasture\ndef add_more_feature(df, test = False):\n    df['event_sum'] = df[['event_' + str(event) for event in event_codes]].sum(axis = 1)\n    df['event_4070_ratio'] = (df['event_4070'] \/ df['event_sum']).replace(float('inf'), -9)\n    df['123'] = df['1'] + df['2']+ df['3']\n    df['123ratio'] = (df['123'] \/ (df['123'] + df['0'])).replace(float('inf'), -9)\n    df['session_sum'] = df['Clip'] + df['Game'] + df['Activity']+ df['Assessment']\n    \n    for e in assessments:\n        df['max_correcy_bin1_title' + str(e)] = np.where(df['correcy_max_title'  + str(e)] == 1, 1, 0) \n        df['max_correcy_bin2_title' + str(e)]= np.where(df['correcy_max_title'  + str(e)] > 0, 1, 0) \n        df['title_count_bin_title' + str(e)]= np.where(df['title_'  + str(e)] > 0, 1, 0) \n        df['assessments_speed_acc' + str(e)]= df['correcy_mean_mean_title21'] \/ df['title' + str(e)+ '_duration_mean']\n        \n    for e in games:\n        df['speed_acc_' + str(e)] = new_train['title_misses_order'+str(e)+'_mean'] \/new_train['title_misses_duration_order' +  str(e) + '_mean'] \n    df['assessments_speed_acc'] = new_train['correcy_assessment_mean_mean']\/ new_train['assessment_duration_mean']\n    df['game_speed_acc'] = new_train['correcy_game_mean_mean']\/ new_train['game_duration_mean']\n    print(df.shape)\n    return df\n\n\n# #","0631d039":"# In[ ]:\n\n\nif not on_kaggle:\n    new_train_distraction= pd.read_csv('new_train_distraction.csv')\n    new_train_4035 =  pd.read_csv('new_train_4035.csv')\n    new_train_basic= pd.read_csv('new_train_basic.csv')\n    new_train_duration= pd.read_csv('new_train_duration.csv')\n    new_train_correcy= pd.read_csv('new_train_correcy.csv')\n    new_train_lag= pd.read_csv('new_train_lag.csv')\n    new_train_MissRoundLevel= pd.read_csv('new_train_MissRoundLevel.csv')\nelse:\n    new_train_distraction = pd.read_csv('\/kaggle\/working\/new_train_distraction.csv')\n    new_train_4035 =  pd.read_csv('\/kaggle\/working\/new_train_4035.csv')\n    new_train_basic = pd.read_csv('\/kaggle\/working\/new_train_basic.csv')\n    new_train_duration = pd.read_csv('\/kaggle\/working\/new_train_duration.csv')\n    new_train_correcy = pd.read_csv('\/kaggle\/working\/new_train_correcy.csv') \n    new_train_lag =  pd.read_csv('\/kaggle\/working\/new_train_lag.csv')\n    new_train_MissRoundLevel =  pd.read_csv('\/kaggle\/working\/new_train_MissRoundLevel.csv')\n    \nnew_train  =  pd.concat([new_train_distraction,\n                   new_train_basic,\n                   new_train_duration,\n                   new_train_correcy,\n                   new_train_lag,\n                   new_train_MissRoundLevel,\n                   new_train_4035], axis= 1)\nprint(new_train.shape)\nnew_train = new_train.loc[:,~new_train.columns.duplicated()]\nprint(new_train.shape)\n\n\n# In[ ]:\n\n\nnew_train  =  pd.concat([new_train_distraction,\n                   new_train_basic,\n                   new_train_duration,\n                   new_train_correcy,\n                   new_train_lag,\n                   new_train_MissRoundLevel,\n                   new_train_4035], axis= 1)\nprint(new_train.shape)\nnew_train = new_train.loc[:,~new_train.columns.duplicated()]\nprint(new_train.shape)\nnew_train = add_more_feature(new_train)\n\nnew_train = new_train.fillna(-9)\ntry: \n    del train\nexcept:\n    pass\ngc.collect()\ntry: \n    new_train.drop(columns = 'Unnamed: 0', inplace = True)\nexcept:\n    pass            \ncats = ['session_world', 'first_session_world','first_session_type', 'title_name_lag2', 'title_name_lag3', 'title_name_lag4', 'world_name_lasttime']\nles = {col:LabelEncoderExt() for col in cats}\nfor col in cats:\n    les[col].fit(new_train[col])\n    new_train[col] = les[col].transform(new_train[col])\n\nfor e in list(new_train.columns):\n    if new_train[e].dtypes == np.float64:\n        new_train[e] = new_train[e].astype(np.float32)\n        \nall_features = [x for x in new_train.columns if x not in ['accuracy_group', 'kid_id', 'game_session', 'accuracy']]\ncat_features = ['first_session_world', 'first_session_title', 'first_session_type',\n'session_title', 'session_world', 'title_name_lag2', 'title_name_lag3', 'title_name_lag4', 'hour', 'dow',\n'world_name_lasttime', 'title_name_lasttime']\nall_features_lgbm = all_features.copy()\ncat_features_lgbm =  cat_features.copy()\nall_features_catboost = all_features.copy()\ncat_features_catboost  =  cat_features.copy()","7efc0e0b":"# #\n\n# In[ ]:\ntest = pd.read_csv('test.csv')\n\nif True:\n#     print(cpu_stats())\n    new_test_distraction = compile_data(test, get_data_distraction, test_set=True)\n#     print(cpu_stats())\n    new_test_4035 = compile_data(test, get_data_4035, test_set=True)\n#     print(cpu_stats())\n    new_test_basic = compile_data(test, get_data_basic, test_set=True)\n#     print(cpu_stats())\n    new_test_duration = compile_data(test, get_data_duration, test_set=True)\n    new_test_correcy = compile_data(test, get_data_correcy, test_set=True)\n    new_test_lag = compile_data(test, get_data_lag, test_set=True)\n    new_test_MissRoundLevel = compile_data(test, get_data_MissRoundLevel, test_set=True)\n    \n    new_test_distraction.to_csv('new_test_distraction.csv', index = False)\n    new_test_4035.to_csv('new_test_4035.csv', index = False)\n    new_test_basic.to_csv('new_test_basic.csv', index = False)\n    new_test_duration.to_csv('new_test_duration.csv', index = False)\n    new_test_correcy.to_csv('new_test_correcy.csv', index = False)\n    new_test_lag.to_csv('new_test_lag.csv', index = False)\n    new_test_MissRoundLevel.to_csv('new_test_MissRoundLevel.csv', index = False)","6494dab2":"# ### concat X_test\n\n# In[ ]:\n\n\nnew_test_distraction= pd.read_csv('new_test_distraction.csv')\nnew_test_4035= pd.read_csv('new_test_4035.csv')\nnew_test_basic= pd.read_csv('new_test_basic.csv')\nnew_test_duration= pd.read_csv('new_test_duration.csv')\nnew_test_correcy= pd.read_csv('new_test_correcy.csv')\nnew_test_lag= pd.read_csv('new_test_lag.csv')\nnew_test_MissRoundLevel= pd.read_csv('new_test_MissRoundLevel.csv')\nnew_test  =  pd.concat([new_test_distraction,\n                   new_test_basic,\n                   new_test_duration,\n                   new_test_correcy,\n                   new_test_lag,\n                   new_test_MissRoundLevel,\n                   new_test_4035], axis= 1)\nnew_test = new_test.loc[:,~new_test.columns.duplicated()]\nprint(new_test.shape)\n\n\n# In[ ]:\n\n\nnew_test  =  pd.concat([new_test_distraction,\n                   new_test_basic,\n                   new_test_duration,\n                   new_test_correcy,\n                   new_test_lag,\n                   new_test_MissRoundLevel,\n                   new_test_4035], axis= 1)\nnew_test = new_test.loc[:,~new_test.columns.duplicated()]\nprint(new_test.shape)\n\nnew_test = add_more_feature(new_test, test = True)\nnew_test = new_test.fillna(-9)\ntry: \n    del test\nexcept:\n    pass\nif  'Unnamed: 0' in new_test.columns:\n    new_test.drop(columns = 'Unnamed: 0', inplace = True)\nfor col in cats:\n    new_test[col] = les[col].transform(new_test[col])   \nfor e in list(new_test.columns):\n    if new_test[e].dtypes == np.float64:\n        new_test[e] = new_test[e].astype(np.float32)\n        \n\n\n# In[ ]:\n\n\ncols = ['title_name_lag2']\nfor e in cols:\n    dict_ = pd.concat([new_test[e] ,new_train[e]]).value_counts().to_dict()\n    new_train[f'{e}_freq'] = new_train[e].map(dict_)\n    new_test[f'{e}_freq'] = new_test[e].map(dict_)\nall_features += [f'{e}_freq' for e in cols]\n\nif_skip = set([119, 187, 116, 180 , 47])\nif_repeat = set([14, 63, 69, 108, 171])\nnew_train['if_skip'] = np.where(new_train['title_name_lag2'].isin(if_skip).values,1,0)\nnew_train['if_repeat'] = np.where(new_train['title_name_lag2'].isin(if_repeat).values,1,0)\nnew_test['if_skip'] = np.where(new_test['title_name_lag2'].isin(if_skip).values,1,0)\nnew_test['if_repeat'] = np.where(new_test['title_name_lag2'].isin(if_repeat).values,1,0)\n\nnew_train['if_skip'].value_counts()\nnew_train['if_repeat'].value_counts()\nprint(new_test['if_skip'].value_counts())\nprint(new_test['if_repeat'].value_counts())\n\n\nall_features += ['if_skip', 'if_repeat']\n['title_name_lag2_freq', 'if_skip', 'if_repeat']\n\n\n# In[ ]:\n\n\nX, y = new_train[all_features], new_train['accuracy_group']        \nX_test = new_test[all_features].copy()\n\n\n\n# In[ ]:","20284e4c":"new_train_nn = new_train.copy()\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder,MinMaxScaler, StandardScaler","720e0049":"all_features =['session_title', 'world_name_lasttime', 'eventid_188', 'title_acc_lasttime', 'correcy_all_mean_mean', 'session_world', 'correcy_all_mean_std', 'eventid_247', 'event_2000', 'Clip', 'accumulated_accuracy_group', 'eventid_385', 'eventid_343', 'eventid_113', 'session_sum', 'correcy_mean_title20', 'eventid_73', 'correcy_max_title20', 'correcy_mean_title11', 'eventid_317', 'accumulated_accuracy', 'title_misses_order21_std', '123ratio', 'correcy_max_title11', '4035_count_title31', 'correcy_mean_mean_title11', 'accumulated_uncorrect_attempts', 'title_name_lag2', 'eventid_134', 'eventid_154', 'correcy_assessment_mean', 'event_4070_ratio', 'distraction_count_title42', 'eventid_351', 'eventid_24', 'title_attemps_sum21', 'title_attemps_sum11', 'correcy_game_mean_mean', 'game_tried_ratio', 'title_misses_duration_order21_mean', 'correcy_mean_title21', 'eventid_54', 'title_14', 'nunique_title', 'correcy_assessment_mean_mean', 'event_2010', 'title34_duration_mean', 'eventid_86', 'correcy_mean_title41', 'correcy_all_mean', 'title42_duration_sum', 'eventid_283', 'correcy_mean_mean_title20', 'eventid_165', 'Game', 'eventid_337', '0', 'correcy_game_mean', 'eventid_101', 'title_misses_order41_mean', 'title34_duration_sum', 'eventid_215', 'event_4010', 'eventid_218', 'distraction_title41', 'clip_duration_sum', 'event_2035', 'eventid_305', 'title_7', 'eventid_296', 'distraction_title4', 'title_4', 'correcy_mean_mean_title29', 'correcy_max_title29', 'correcy_mean_title29', 'event_4070', 'event_3121', 'title1_duration_sum', 'eventid_304', 'title32_duration_max', 'correcy_mean_mean_title21', 'eventid_278', 'title22_duration_sum', 'eventid_185', 'title24_duration_sum', 'eventid_14', 'title_24', '4035_count_title8', 'event_4031', 'eventid_349', 'eventid_326', 'eventid_350', 'eventid_217', 'eventid_15', 'event_3120', 'eventid_309', 'eventid_72', 'nunique_title_in_this_world', 'title_misses_order10_mean', 'title41_duration_sum', 'title_name_lasttime', 'game_duration_max', 'distraction_mean', 'distraction_title17', 'eventid_212', 'title_rounds_sum4', 'title0_duration_mean', 'title0_duration_sum', 'event_3110', 'title_34', 'distraction_count_title41', 'title_misses_order27_mean', 'eventid_216', 'title_misses_order18_std', 'eventid_242', 'title_misses_duration_order8_mean', 'title21_duration_mean', 'correcy_count_title41', 'title4_duration_max', 'title_37', 'eventid_109', 'title7_duration_sum', 'eventid_380', 'title_misses_sum27', 'eventid_297', 'eventid_299', 'eventid_56', 'event_4020', 'distraction_count_title20', 'title8_duration_sum', 'eventid_175', 'eventid_219', 'eventid_112', 'title26_duration_sum', 'eventid_2', 'title_misses_order8_mean', 'correcy_max_title21', 'title21_duration_sum', 'Activity', 'title_9', 'eventid_194', 'title_1', 'title_misses_duration_order41_mean', 'title_35', 'title8_duration_mean', 'eventid_222', 'event_4090', 'event_3021', 'eventid_237', 'event_4025', 'accumulated_actions', 'title40_duration_mean', 'eventid_174', 'eventid_340', 'distraction_title7', 'eventid_249', 'event_2040', 'title_name_lag3', 'eventid_302', 'event_3020', 'eventid_192', 'correcy_count_title21', 'eventid_311', 'eventid_103', 'distraction_count_title12', 'title42_duration_max', 'eventid_140', 'eventid_120', 'eventid_277', 'event_4030', 'title9_duration_sum', 'title_misses_order42_std', 'distraction_count_title31', 'eventid_375', 'event_3010', 'event_4035', 'title35_duration_sum', 'eventid_177', 'event_2020', 'eventid_9', 'title34_duration_max', 'title_misses_order41_std', 'distraction_title14', 'title_41', 'eventid_282', 'title43_duration_mean', 'title4_duration_sum', 'title8_duration_max', 'distraction_title0', 'distraction_count_title30', 'eventid_220', 'title42_duration_mean', 'title_6', 'title28_duration_max', 'title_misses_order4_mean', 'title9_duration_max', 'title_misses_sum42', 'eventid_125', 'eventid_92', 'title_misses_order43_mean', 'title_lasttime', 'title_misses_sum41', 'eventid_383', 'activity_duration_mean']\nall_features += ['title_name_lag2_freq', 'max_correcy_bin1_title11',\n 'max_correcy_bin2_title11',\n 'title_count_bin_title11',\n 'max_correcy_bin1_title20',\n 'max_correcy_bin2_title20',\n 'title_count_bin_title20',\n 'max_correcy_bin1_title21',\n 'max_correcy_bin2_title21',\n 'title_count_bin_title21',\n 'max_correcy_bin1_title29',\n 'max_correcy_bin2_title29',\n 'title_count_bin_title29',\n 'max_correcy_bin1_title41',\n 'max_correcy_bin2_title41',\n 'title_count_bin_title41','if_skip', 'if_repeat']\ncat_features = ['first_session_world', 'first_session_title', 'first_session_type',\n'session_title', 'session_world', 'hour', 'dow', 'title_name_lag2', 'title_name_lag3',\n'world_name_lasttime', 'title_name_lasttime']\nall_features = [e for e in all_features if e not in cat_features]\ncat_features = ['session_title', 'session_world']\nnum_features = [e for e in all_features if e not in cat_features]\n\nprint(len(all_features))\nprint(all_features)\nprint(cat_features)","c9bac75b":"# In[ ]:\n\n\ndef num_feature_process(df, num_features):\n    df_copy = df.copy()\n    negtive9_array = np.array([])\n    negtive1_array = np.array([])\n    invalid_features = []\n    for e in num_features:\n        # -9\u7f3a\u5931 \n        if np.isin(-9, df_copy[e].values):\n            print(e)\n            if len(negtive9_array) == 0:\n                negtive9_array = np.where(df_copy[e] == -9, 1,0).reshape(-1,1)\n            else:\n                negtive9_array = np.concatenate([negtive9_array, np.where(df_copy[e] == -9, 1,0).reshape(-1,1)],axis = 1)\n\n        # -1\u7f3a\u5931 \n        if np.isin(-1, df_copy[e].values):\n            if len(negtive1_array) == 0:\n                negtive1_array = np.where(df_copy[e] == -1, 1,0).reshape(-1,1)\n            else:\n                negtive1_array = np.concatenate([negtive9_array, np.where(df_copy[e] == -1, 1,0).reshape(-1,1)],axis = 1)\n\n        #\u586b\u8865\u7f3a\u5931\n        df_copy[e][(df_copy[e] < 0 )] = -9   \n        _mean = df_copy[e][(df_copy[e] > 0 )].mean()\n        df_copy[e] = df_copy[e].replace(-9, 0)\n#         df_copy[e] = df_copy[e].replace(-9, _mean)\n        df_copy[e] = np.log1p(df_copy[e])    \n        if df_copy[e].nunique() in [1, 0]:\n            invalid_features.append(e)\n    X_num = df_copy[[e for e in num_features if e not in invalid_features]].values\n    del df_copy\n    return X_num, negtive9_array, negtive1_array\n\n\n# cat_features \ndef cat_feature_preprocess(df, cat_features, test_set = False, les2= None, onehot_dict2 = None):\n    #label enconding\n    if not test_set:\n        les2 = {col:LabelEncoderExt() for col in cat_features}\n        for e in cat_features:\n            df[e]= df[e].map(str)\n        for col in cat_features:\n            les2[col].fit(df[col])\n            df[col] = les2[col].transform(df[col])\n        #one-hot\n        onehot_dict2 = {cat_col: OneHotEncoder(n_values= df[cat_col].nunique(), sparse= False,  handle_unknown='ignore') for cat_col in cat_features}\n        X_cat = np.array([])\n        for e in cat_features:\n            print(e)\n            onehot_dict2[e].fit(np.array(df[e]).reshape(-1,1))\n            if len(X_cat) == 0:\n                X_cat = onehot_dict2[e].transform(np.array(df[e]).reshape(-1,1))\n            else:\n                X_cat = np.concatenate([X_cat, onehot_dict2[e].transform(np.array(df[e]).reshape(-1,1))] , axis = 1)    \n        return X_cat, les2, onehot_dict2\n    if test_set:\n        for e in cat_features:\n            df[e]= df[e].map(str)\n        for col in cat_features:\n            df[col] = les2[col].transform(df[col])\n        X_cat = np.array([])\n        for e in cat_features:\n            if len(X_cat) == 0:\n                X_cat = onehot_dict2[e].transform(np.array(df[e]).reshape(-1,1))\n            else:\n                X_cat = np.concatenate([X_cat, onehot_dict2[e].transform(np.array(df[e]).reshape(-1,1))] , axis = 1)            \n        return X_cat\n        \n    \nX_num, negtive9_array, negtive1_array  = num_feature_process(new_train, num_features) \nX_cat, les2, onehot_dict2 = cat_feature_preprocess(new_train_nn, cat_features, test_set = False)    \n\nprint(negtive9_array.shape)\nprint(negtive1_array.shape)\nprint(X_cat.shape)\nprint(X_num.shape)\nsds = StandardScaler(copy=True, with_mean=False, with_std=True)\nsds.fit(X_num)\nX = np.concatenate([sds.transform(X_num), X_cat, negtive1_array, negtive9_array], axis = 1)\ny = new_train['accuracy_group'].values\ny2 = np.sqrt(new_train['accuracy']) *3\nprint(X.shape)\nprint(y.shape)\nprint(y2.shape)\n\n\n# In[ ]:\n\n\ntest_num, test_negtive9_array, test_negtive1_array  = num_feature_process(X_test, num_features) \ntest_cat= cat_feature_preprocess(X_test, cat_features, test_set = True, les2= les2, onehot_dict2 = onehot_dict2 )  \nX_test_array = np.concatenate([sds.transform(test_num), test_cat, test_negtive1_array, test_negtive9_array], axis = 1)\nprint(X_test_array.shape)\n\n\n# In[ ]:\n\n\nfrom keras.layers import LSTM, Dropout, Input, Dense, concatenate,Flatten, BatchNormalization, Softmax, Add,LeakyReLU\nfrom keras.models import Model,Sequential,load_model\nfrom keras import optimizers\nfrom keras_tqdm import TQDMNotebookCallback\nfrom sklearn.model_selection import train_test_split\n\n\ndef NN_model():\n    Input_main = Input(shape=((X.shape[1],)), name=\"main\")\n    main_input = Dense(256)(Input_main)\n    main_input = LeakyReLU(alpha=0.3)(main_input)\n    main_input = BatchNormalization()(main_input)\n    main_input = Dropout(0.3)(main_input) \n    \n    main_input = Dense(256)(main_input)\n    main_input = LeakyReLU(alpha=0.3)(main_input)\n    main_input = BatchNormalization()(main_input)   \n    main_input = Dropout(0.3)(main_input)    \n\n    main_input = Dense(256)(main_input)    \n    main_input = LeakyReLU(alpha=0.3)(main_input)\n    main_input = BatchNormalization()(main_input)\n    main_input = Dropout(0.3)(main_input)   \n\n\n    output = Dense(1)(main_input)\n    output2 = Dense(1)(main_input)\n    adam = optimizers.Adam(learning_rate=0.0003, beta_1=0.9, beta_2=0.999, amsgrad=False)\n    model = Model(inputs=[Input_main], outputs=[output, output2])\n    model.compile(optimizer=adam, loss=['mean_squared_error','mean_squared_error'])\n    return model\n\nmodel = NN_model()\nmodel.summary()\n\n\n# In[ ]:\n\n\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nimport keras\noof = np.zeros(len(X))\nNFOLDS = 5\nfolds = GroupKFold(n_splits=NFOLDS)\n\n\nweights = 1\/ (new_train.groupby('kid_id')['Clip'].transform('count')).values\nweights = weights\/ np.sum(weights) *len(new_train)\nmodels = []\nfor fold, (tr_index, val_index) in enumerate(folds.split(list(range(X.shape[0])), groups = new_train_nn['kid_id'])):\n    print(f'Training on fold {fold+1}')\n    model = NN_model()\n    tr_index_copy = tr_index.copy()\n    for n in range(1):\n\n#         new_train['index_'] =  list(new_train.index)\n#         index_ = new_train.loc[tr_index_copy,:].groupby(['kid_id', 'session_title', 'accuracy_group'], as_index = False)['index_']\\\n#             .apply(lambda x:x.sample(8) if len(x) >= 8 else x)  \n#         tr_index = sorted(list(index_))\n#         print(len(tr_index))\n#         new_train.drop(columns='index_',inplace= True)\n        \n        X_tr, X_val = X[tr_index, :], X[val_index, :]\n\n        y_tr, y_val  = y[tr_index], y[val_index]\n        y2_tr, y2_val = y2[tr_index], y2[val_index]\n#         y3_tr, y3_val = y3[tr_index], y3[val_index]\n        model_checkpoint = ModelCheckpoint(\"model_\" + str(fold) + \".hdf5\",\n                                           save_best_only=True, verbose=1, monitor='val_loss', mode='min')\n        early_stopping = EarlyStopping(monitor='val_loss', patience=15, verbose=2)\n#         lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=0, mode='min', min_delta=0.00001)\n        def lr_decay(index_):\n            if index_ < 15:\n                return 0.0003\n            elif  index_ < 30:\n                if  index_ % 2 ==0:\n                    return 0.00008\n                else:\n                    return 0.0002                    \n            elif  index_ < 40:\n                if  index_ % 2 ==0:\n                    return 0.00008\n                else:\n                    return 0.00003          \n            else:\n                return 0.00003\n        lr = keras.callbacks.LearningRateScheduler(lr_decay)\n        model.fit([X_tr], [y_tr, y2_tr], batch_size = 128,\n                  validation_data  = ([X_val], [y_val,y2_val], \n                  [weights[val_index],weights[val_index]]), \n                  epochs=60,\n                            verbose=2, callbacks=[model_checkpoint, lr])\n#         model = load_model(\"model_\" + str(fold) + \".hdf5\")    \n        models.append(model)\n        oof[val_index] +=model.predict([X_val])[0].flatten()\n        oof[val_index] += model.predict([X_val])[1].flatten()\n#         oof[val_index] += model.predict(X_val)[2].flatten()\n    \nfrom scipy import stats\n#weighted validation\nweights = 1\/ (new_train.groupby('kid_id')['Clip'].transform('count'))\nfrom scipy import stats\ncum = (train_labels['accuracy_group'].value_counts(sort=False)\/ len(train_labels['accuracy_group'])).cumsum()\nprint(cum)\npred_percentile = np.array([stats.percentileofscore(oof, a) for a in oof]) \/100\nbins_percentile = [0] + list(cum)\npreds = np.digitize(pred_percentile, bins_percentile, right=True) -1\nprint('-' * 30)\nprint('OOF QWK:', qwk(y, preds, weights = weights.values))\nprint('OOF QWK:', qwk(y, preds))\nprint('-' * 30)\n\n\n# In[ ]:","e878ae8d":"from scipy import stats\n#weighted validation\nweights = 1\/ (new_train.groupby('kid_id')['Clip'].transform('count'))\nfrom scipy import stats\ncum = (train_labels['accuracy_group'].value_counts(sort=False)\/ len(train_labels['accuracy_group'])).cumsum()\nprint(cum)\npred_percentile = np.array([stats.percentileofscore(oof, a) for a in oof]) \/100\nbins_percentile = [0] + list(cum)\npreds = np.digitize(pred_percentile, bins_percentile, right=True) -1\nprint('-' * 30)\nprint('OOF QWK:', qwk(y, preds, weights = weights.values))\nprint('OOF QWK:', qwk(y, preds))\nprint('-' * 30)\n\n\n# In[ ]:","e57e6a50":"from scipy import stats\n#weighted validation\nweights = 1\/ (new_train.groupby('kid_id')['Clip'].transform('count'))\nfrom scipy import stats\ncum = (train_labels['accuracy_group'].value_counts(sort=False)\/ len(train_labels['accuracy_group'])).cumsum()\nprint(cum)\n\ncum[2] += 0.05\npred_percentile = np.array([stats.percentileofscore(oof, a) for a in oof]) \/100\nbins_percentile = [0] + list(cum)\npreds = np.digitize(pred_percentile, bins_percentile, right=True) -1\nprint('-' * 30)\nprint('OOF QWK:', qwk(y, preds, weights = weights.values))\nprint('OOF QWK:', qwk(y, preds))\nprint('-' * 30)","34be5247":"# In[ ]:\n\n\nfor e in [20,29,41 ,11 ,21 ]:\n    print(f'{e}: ##############')\n    index_ = list(new_train.loc[(new_train.session_title == e),:].index)\n    print(pd.DataFrame(confusion_matrix(preds[index_], y[[index_]])))","abe8554d":"from functools import partial\nimport scipy as sp\nclass OptimizedRounder(object):\n    \"\"\"\n    An optimizer for rounding thresholds\n    to maximize Quadratic Weighted Kappa (QWK) score\n    # https:\/\/www.kaggle.com\/naveenasaithambi\/optimizedrounder-improved\n    \"\"\"\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        \"\"\"\n        Get loss according to\n        using current coefficients\n        \n        :param coef: A list of coefficients that will be used for rounding\n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n\n        return -qwk(y, X_p)\n\n    def fit(self, X, y,  initial_coef = None):\n        \"\"\"\n        Optimize rounding thresholds\n        \n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        if initial_coef == None:\n            initial_coef = init_threshold\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        \"\"\"\n        Make predictions with specified thresholds\n        \n        :param X: The raw predictions\n        :param coef: A list of coefficients that will be used for rounding\n        \"\"\"\n        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n\n\n    def coefficients(self):\n        \"\"\"\n        Return the optimized coefficients\n        \"\"\"\n        return self.coef_['x']\n    \ncum = (train_labels['accuracy_group'].value_counts(sort=False)\/ len(train_labels['accuracy_group'])).cumsum()\ninit_threshold  = [ sorted(oof)[int(round(len(oof) * cum[0]))],  sorted(oof)[int(round(len(oof) * cum[1]))], sorted(oof)[int(round(len(oof) * cum[2]))]]\n\ncut_df = pd.DataFrame()\nqwk_1,qwk_2,coefficients_list = [],[],[]\nfor i in range(25):\n#     initial_coef_ = [0.4 + np.random.sample()* 0.6, 1.4 + np.random.sample()* 0.6, 2 + np.random.sample()* 0.4]\n    initial_coef_ = init_threshold.copy()\n    initial_coef_[0] += (np.random.sample() - 0.5)* 0.1 \n    initial_coef_[1] += (np.random.sample() - 0.5)* 0.1 \n    initial_coef_[2] += (np.random.sample() - 0.5)* 0.1 \n    optR = OptimizedRounder()\n    optR.fit(oof.reshape(-1,), y, initial_coef = initial_coef_)\n    coefficients = optR.coefficients()\n    preds = oof.copy()\n    preds[preds <coefficients[0]] = 0\n    preds[(preds >coefficients[0])&(preds <coefficients[1]) ] = 1\n    preds[(preds >coefficients[1])&(preds <coefficients[2]) ] =2\n    preds[(preds >coefficients[2])] = 3\n    coefficients_list.append(coefficients)\n    qwk_1.append(qwk(new_train['accuracy_group'], preds, weights = weights.values))\n    qwk_2.append(qwk(new_train['accuracy_group'], preds))\ncut_df['qwk1'] = qwk_1\ncut_df['qwk2'] =qwk_2\ncut_df['coefficients_list'] = coefficients_list\n\ncut_df['qwk3'] = cut_df['qwk1'] + cut_df['qwk2'] * 0.2\ncut_df = cut_df.sort_values('qwk3', ascending= False)\ncoefficients = cut_df.iloc[0,2]\ncut_df.head(5)\n\n\n# In[ ]:\n\n\ns1 = np.sum((train_labels['accuracy_group'] == 0) * weights) *  (len(oof)) \/sum(weights)\ns2 =np.sum((train_labels['accuracy_group'] == 1) * weights) *  (len(oof)) \/sum(weights)\ns3 =np.sum((train_labels['accuracy_group'] == 2) * weights) *  (len(oof)) \/sum(weights)\ns4 =np.sum((train_labels['accuracy_group'] == 3) * weights) *  (len(oof)) \/sum(weights)\ncum_weighted = [0]*int(round(s1)) +  [1]*int(round(s2))+  [2]*int(round(s3))+  [3]*int(round(s4))\nfor e in range(20):\n    try:\n        print('###########################best ' +  str(e) )\n        print('##########################')\n        plt.hist(np.digitize(oof,   [-99] + list(cut_df.iloc[e,2]) + [99], right=True) -1, align = 'right')\n        plt.hist(cum_weighted,  align='mid')\n        plt.hist(np.digitize(oof,   [-99] + init_threshold + [99], right=True) -1, align='left' )\n        cum_ =  (pd.Series(np.digitize(oof,   [-99] + list(cut_df.iloc[e,2]) + [99], right=True) -1).value_counts(sort=False) \/ len(oof)).cumsum()\n        print('qwk1 ' + str(round(cut_df.iloc[e,0],3)) +  ', qwk2 '+  str(round(cut_df.iloc[e,1],3)))\n        print('cum:', (pd.Series(np.digitize(oof,   [-99] + list(cut_df.iloc[e,2]) + [99], right=True) -1).value_counts(sort=False) \/ len(oof)).cumsum())\n        plt.legend(['opt', 'weighted_train', 'train'])\n        plt.figure(figsize=(2,1))\n        plt.show()\n    except:\n        pass\n\n\n# In[ ]:\n\n\ncum = (pd.Series(np.digitize(oof,   [-99] + list(cut_df.iloc[0,2]) + [99], right=True) -1).value_counts(sort=False) \/ len(oof)).cumsum()\ncum[3] += 0.5\nprint(cum)\npred_percentile = np.array([stats.percentileofscore(oof, a) for a in oof]) \/100\nbins_percentile = [0] + list(cum)\npreds = np.digitize(pred_percentile, bins_percentile, right=True) -1\nprint('-' * 30)\nprint('OOF QWK:', qwk(y, preds, weights = weights.values))","1c1361bd":"# train once\ndef lr_decay(index_):\n    if index_ < 15:\n        return 0.0003\n    elif  index_ < 30:\n        if  index_ % 2 ==0:\n            return 0.00008\n        else:\n            return 0.0002                    \n    elif  index_ < 40:\n        if  index_ % 2 ==0:\n            return 0.00008\n        else:\n            return 0.00003          \n    else:\n        return 0.00003\nNmodel = 9\nlr = keras.callbacks.LearningRateScheduler(lr_decay)\ninit_seeds(SEED+1)\nmodel1 = NN_model()\nmodel1.fit(X, [y, y2], batch_size = 128 , epochs=63,verbose=5, callbacks=[lr])\ninit_seeds(SEED+2)\nmodel2 = NN_model()\nmodel2.fit(X, [y, y2], batch_size = 128 , epochs=65,verbose=5, callbacks=[lr])\ninit_seeds(SEED+3)\nmodel3 = NN_model()\nmodel3.fit(X, [y, y2], batch_size = 128 , epochs=68,verbose=5, callbacks=[lr])\n\ninit_seeds(SEED+1000)\nmodel1_seed1 = NN_model()\nmodel1_seed1.fit(X, [y, y2], batch_size = 128 , epochs=63,verbose=5, callbacks=[lr])\ninit_seeds(SEED+1001)\nmodel2_seed1 = NN_model()\nmodel2_seed1.fit(X, [y, y2], batch_size = 128 , epochs=65,verbose=5, callbacks=[lr])\ninit_seeds(SEED+1002)\nmodel3_seed1 = NN_model()\nmodel3_seed1.fit(X, [y, y2], batch_size = 128 , epochs=68,verbose=5, callbacks=[lr])\n\ninit_seeds(SEED+2000)\nmodel1_seed2 = NN_model()\nmodel1_seed2.fit(X, [y, y2], batch_size = 128 , epochs=63,verbose=5, callbacks=[lr])\ninit_seeds(SEED+2001)\nmodel2_seed2 = NN_model()\nmodel2_seed2.fit(X, [y, y2], batch_size = 128 , epochs=65,verbose=5, callbacks=[lr])\ninit_seeds(SEED+2002)\nmodel3_seed2 = NN_model()\nmodel3_seed2.fit(X, [y, y2], batch_size = 128 , epochs=68,verbose=5, callbacks=[lr])\n\n\n# In[ ]:\n\n\npreds_nn_raw  = model1.predict(X_test_array)[0].flatten()\npreds_nn_raw  += model1.predict(X_test_array)[1].flatten()\npreds_nn_raw  += model2.predict(X_test_array)[0].flatten()\npreds_nn_raw  += model2.predict(X_test_array)[1].flatten()\npreds_nn_raw  += model3.predict(X_test_array)[0].flatten()\npreds_nn_raw  += model3.predict(X_test_array)[1].flatten()\npreds_nn_raw  += model1_seed1.predict(X_test_array)[0].flatten()\npreds_nn_raw  += model1_seed1.predict(X_test_array)[1].flatten()\npreds_nn_raw  += model2_seed1.predict(X_test_array)[0].flatten()\npreds_nn_raw  += model2_seed1.predict(X_test_array)[1].flatten()\npreds_nn_raw  += model3_seed1.predict(X_test_array)[0].flatten()\npreds_nn_raw  += model3_seed1.predict(X_test_array)[1].flatten()\npreds_nn_raw  += model1_seed2.predict(X_test_array)[0].flatten()\npreds_nn_raw  += model1_seed2.predict(X_test_array)[1].flatten()\npreds_nn_raw  += model2_seed2.predict(X_test_array)[0].flatten()\npreds_nn_raw  += model2_seed2.predict(X_test_array)[1].flatten()\npreds_nn_raw  += model3_seed2.predict(X_test_array)[0].flatten()\npreds_nn_raw  += model3_seed2.predict(X_test_array)[1].flatten()\n\n\n# from scipy import stats\n# preds = preds_nn_raw\n# cum = (train_labels['accuracy_group'].value_counts(sort=False)\/ len(train_labels['accuracy_group'])).cumsum()\n# pred_percentile = np.array([stats.percentileofscore(preds, a) for a in preds]) \/100\n# bins_percentile = [0] + list(cum)\n# print(cum)\n# preds = np.digitize(pred_percentile, bins_percentile, right=True) -1\n# preds_nn = preds.copy()\n\nfrom scipy import stats\npreds = preds_nn_raw.copy()\npreds = preds \/ Nmodel\npreds = np.digitize(preds,   [-99] + list(cut_df.iloc[0,2]) + [99], right=True) -1\npreds_nn = preds.copy()\n\n\n# In[ ]:\n\n\nplt.hist(preds_nn_raw)","4a8178a2":"# ## Make submission\n\n# In[ ]:\n\n\nsubmission['accuracy_group'] = np.round(preds_nn).astype('int')\nsubmission.to_csv('submission.csv', index=None)\nsubmission.head()\n\n\n# In[ ]:\n\n\nsubmission['accuracy_group'].plot(kind='hist')\n\n\n# In[ ]:\n\n\ntrain_labels['accuracy_group'].plot(kind='hist')\n\n\n# In[ ]:\n\n\npd.Series(oof).plot(kind='hist')\n\n\n# In[ ]:","49ecbba5":"## NN model","e3ee5418":"## train model on all data once","1c57666f":"## Make submission","abaaa0d7":"## concat X_test","034c3348":"## add more features (fuction)\n","54e2ccb3":"## concat new_train","88e96523":"## FE AND TRAIN","2dcefcfe":"## compile test"}}