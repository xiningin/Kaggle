{"cell_type":{"525a09c3":"code","1d22eb69":"code","5f12c412":"code","b831010a":"code","0204c8df":"code","76455488":"code","6c795509":"code","042e54a4":"code","502e8bf0":"code","c2d68d71":"code","c5e73989":"code","eabf4ac8":"code","5b6b3048":"code","10ae38aa":"code","b206c4ab":"code","9ecce2b2":"code","33022829":"code","ac490880":"code","fab6f855":"code","bc9d5045":"code","0512334f":"code","69b0cd56":"code","7769e683":"code","c235507c":"code","739c759f":"code","60b66286":"code","19fc89e7":"code","22956785":"code","aebefca6":"code","006a962d":"code","304a4fde":"code","6c55ac03":"code","b45a82e2":"code","b7de6765":"code","26418218":"code","9e309b90":"code","da2a1f94":"code","143bd7a7":"code","d03bdb61":"markdown","a9ec80aa":"markdown","17e7aba5":"markdown","2bb2c496":"markdown","b8f34135":"markdown","14723467":"markdown","74421e29":"markdown","1b75c66e":"markdown","c5ebd926":"markdown","5ab9f70d":"markdown","0aaf7811":"markdown","df4b8dcf":"markdown","4baa2e1f":"markdown","a1bf0a9e":"markdown","80ecdf94":"markdown"},"source":{"525a09c3":"!conda config --env --set always_yes true\n!conda install -c conda-forge arabic_reshaper\n!conda install -c conda-forge python-bidi ","1d22eb69":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport random # Generate pseudo-random numbers\nfrom random import randint\n\nfrom sklearn.utils import shuffle # Shuffle arrays or sparse matrices in a consistent way\nfrom sklearn.model_selection import train_test_split # Split arrays or matrices into random train and test subsets\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport sklearn\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec # Specifies the geometry of the grid that a subplot can be placed in.\n\nimport keras\nfrom keras import models as Models\nfrom keras import layers as Layers\nfrom keras.preprocessing import image\nfrom keras.models import Sequential,Model\nfrom keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization\nfrom keras.layers import Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom keras import utils as Utils\nfrom keras.utils import to_categorical # Converts a class vector (integers) to binary class matrix.\n\nfrom keras.utils.vis_utils import model_to_dot\n\nimport seaborn as sns\n\n# from IPython.display import SVG\n\nimport arabic_reshaper # Reconstruct Arabic sentences to be used in applications that don't support Arabic\nfrom bidi.algorithm import get_display","5f12c412":"# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","b831010a":"# global variables\nLanguage = \"Ar\"\nImageClassMapping_path = \"..\/input\/Labels\/ImagesClassPath.csv\"\nClassLabels_path = \"..\/input\/Labels\/ClassLabels.xlsx\"\nImagesRoot_path = \"..\/input\/\"\n\nModelFileName ='Model_255.h5'","0204c8df":"# load 54k image path mapping\ndf_ImageClassPath = pd.read_csv(ImageClassMapping_path)\ndisplay(df_ImageClassPath.head())","76455488":"# load Class Labels\ndf_Classes = pd.read_excel(ClassLabels_path)\ndisplay(df_Classes.head())","6c795509":"df_ImageClassPath.groupby(\"ClassId\").size().describe()","042e54a4":"\nddata = {\"samples destribution\":df_ImageClassPath.groupby(\"ClassId\").size()}\niindex = range(32)\n\nddataframe = pd.DataFrame(data=ddata, index= iindex)\nddataframe.plot.bar(stacked= True, rot= 15, title='samples destribution')\nplt.show(block= True)","502e8bf0":"# Split 54K Images into 3 groups of Fixed Prediction, training and test\n# the dataset is 32 class,split is maintaind as per class \ndef SplitData(predictions,testsize):\n    \n    min = df_ImageClassPath.groupby(\"ClassId\").size().min()\n    print('{0} Samples per Class'.format(min))\n    \n    # empty dataframes with same column difinition\n    df_TrainingSet = df_ImageClassPath[0:0].copy()\n    df_TestSet = df_ImageClassPath[0:0].copy()\n    df_PredSet = df_ImageClassPath[0:0].copy()\n\n    # Create the sets by loop thru classes and append\n    for index,row in df_Classes.iterrows():\n        # make sure all class are same size \n        df_FullSet = df_ImageClassPath[df_ImageClassPath['ClassId'] == row['ClassId']].sample(min,random_state= 42)\n        \n#         df_FullSet = df_ImageClassPath[df_ImageClassPath['ClassId'] == row['ClassId']]\n        \n        df_PredSet = df_PredSet.append(df_FullSet.sample(n=predictions, random_state=1))\n        df_FullSet = pd.merge(df_FullSet,df_PredSet, indicator=True, \n                              how='left').query('_merge==\"left_only\"').drop('_merge', axis=1)\n        \n        trainingSet, testSet = train_test_split(df_FullSet, test_size= testsize)        \n        \n        df_TrainingSet = df_TrainingSet.append(trainingSet)\n        df_TestSet = df_TestSet.append(testSet)\n    \n    return df_TrainingSet,df_TestSet,df_PredSet\n","c2d68d71":"# retrive class Label (Arabic or English) using class id \ndef get_classlabel(class_code,lang= 'Ar'):\n    if lang== 'Ar':\n        text_to_be_reshaped = df_Classes.loc[df_Classes['ClassId'] == class_code, \n                                             'ClassAr'].values[0]\n        reshaped_text = arabic_reshaper.reshape(text_to_be_reshaped)\n        return get_display(reshaped_text)\n    elif lang== 'En':\n        return df_Classes.loc[df_Classes['ClassId'] == class_code, 'Class'].values[0]\n    ","c5e73989":"# prepare Images, and class Arrays\ndef getDataSet(setType,isDL): # 'Training' for Training dataset , 'Testing' for Testing data set\n    imgs = []\n    lbls = []\n    df = pd.DataFrame(None)\n    \n    if setType =='Training':\n        df = dtTraining.copy()\n    elif setType=='Test':\n        df = dtTest.copy()\n    elif setType=='Prediction':\n        df = dtPred.copy()\n\n    for index,row in df.iterrows():\n        lbls.append(row['ClassId'])\n        try:\n            imageFilePath = os.path.join(ImagesRoot_path, row['ImagePath'])\n            img = image.load_img(imageFilePath, target_size=(64,64,1), \n                                 color_mode = \"grayscale\")\n            img = image.img_to_array(img) # to array\n            img = img\/255 # Normalize\n            if isDL == False:\n                img = img.flatten() # for knn_classifier Model\n            imgs.append(img)\n\n        except Exception as e:\n            print(e)\n            \n    shuffle(imgs,lbls,random_state=255) #Shuffle the dataset\n\n    imgs = np.array(imgs)\n    lbls = np.array(lbls)\n    if isDL ==True:\n        lbls = to_categorical(lbls) # for keras CNN Model\n    return imgs, lbls","eabf4ac8":"def display_prediction(col_size, row_size,XPred,yPred): \n    img_index=0\n    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n    for row in range(0,row_size):\n        for col in range(0,col_size):\n            ax[row][col].imshow(XPred[img_index][:,:,0], cmap='gray')\n            ax[row][col].set_title(\"({}) {}\".format(yPred[img_index],get_classlabel(yPred[img_index],'Ar')))\n            ax[row][col].set_xticks([])\n            ax[row][col].set_yticks([])\n            img_index += 1","5b6b3048":"# Split our Dataset into Training, Test and Prediction\n# take 3 images per class for later prediction (96 images 3 x 32 class category)\n# split the remaining into 20% test and 80% Training\n\ndtTraining, dtTest,dtPred = SplitData(3,0.3)","10ae38aa":"print('Pred     {} \\t # {} per class'.format(dtPred.shape[0], dtPred.shape[0] \/\/32))\nprint('Training {} \\t # {} per class'.format(dtTraining.shape[0], dtTraining.shape[0] \/\/32))\nprint('Test     {} \\t # {} per class'.format(dtTest.shape[0], dtTest.shape[0] \/\/32))\nprint('---------------')\nprint('Sum      {}'.format(dtTraining.shape[0] + dtTest.shape[0] + dtPred.shape[0]))","b206c4ab":"ddata = {\"Training\":dtTraining.groupby(\"ClassId\").size(),\"Test\":dtTest.groupby(\"ClassId\").size()}\niindex = range(32)\n\nddataframe = pd.DataFrame(data=ddata, index= iindex)\nddataframe.plot.bar(stacked= True, rot= 15, title='Training vs Test data')\nplt.show(block= True)","9ecce2b2":"X_train,y_train = getDataSet('Training',False)\nX_Valid,y_valid = getDataSet('Test',False)\nX_pred,_ = getDataSet('Prediction',False)","33022829":"print(\"Shape of Train Images:{} , Train Labels: {}\".format(X_train.shape,y_train.shape))","ac490880":"from sklearn.neighbors import KNeighborsClassifier\n# knn_classifier = KNeighborsClassifier(algorithm=, n_jobs=-1)\nknn_classifier = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                                      metric_params=None, n_jobs=-1, n_neighbors=5, p=2,weights='uniform')\nknn_classifier.fit(X_train, y_train)","fab6f855":"knnScore = knn_classifier.score(X_train, y_train)\nprint(knnScore)","bc9d5045":"from sklearn.metrics import confusion_matrix\ny_ValidPrediction = knn_classifier.predict(X_Valid)\n# Convert predictions classes to one hot vectors \nY_pred_classes = y_ValidPrediction\n\nY_true = y_valid\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n\nplt.figure(figsize=(10,8))\nsns.heatmap(confusion_mtx, annot=True, fmt=\"d\");","0512334f":"knn_predictions = knn_classifier.predict(X_pred)\nprint(knn_predictions)","69b0cd56":"X_train,y_train = getDataSet('Training',True)\nX_valid,y_valid = getDataSet('Test',True)\nX_pred,_ = getDataSet('Prediction',True)","7769e683":"print(\"Shape of Train Images:{} , Train Labels: {}\".format(X_train.shape,y_train.shape))\nprint(\"Shape of Test Images:{} , Test Labels: {}\".format(X_valid.shape,y_valid.shape))\nprint(\"Shape of Prediction Images:{} , Prediction Labels: {}\".format(X_pred.shape,\"?\"))","c235507c":"model = Models.Sequential()\n\nmodel.add(Layers.Conv2D(64, kernel_size=(3, 3),activation='relu',input_shape=(64,64,1)))\nmodel.add(Layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Layers.Dropout(0.25))\nmodel.add(Layers.Flatten())\nmodel.add(Layers.Dense(128, activation='relu'))\nmodel.add(Layers.Dropout(0.5))\nmodel.add(Layers.Dense(32, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n\nmodel.summary()\nUtils.plot_model(model,to_file='model.png',show_shapes=True, show_layer_names=True, dpi=80)\n","739c759f":"# model = Sequential(name='Predict')\n# model.add(Layers.Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(64,64,1), name='layer_conv2',strides = (1,1), padding='same'))\n# model.add(Layers.BatchNormalization())\n# model.add(Layers.MaxPooling2D((2,2),name='maxPool2'))\n# model.add(Layers.Conv2D(32,(3,3),strides = (1,1),name='conv3',padding='same'))\n# model.add(Layers.BatchNormalization())\n# model.add(Layers.MaxPooling2D((2,2),name='maxPool3'))\n# model.add(Layers.Flatten())\n# model.add(Layers.Dense(32,activation = 'relu',name='fc0'))\n# model.add(Layers.Dropout(0.25))\n# model.add(Layers.Dense(32,activation = 'relu',name='fc1'))\n# model.add(Layers.Dropout(0.25))\n# model.add(Layers.Dense(32,activation = 'softmax',name='fc2'))\n\n# model.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])\n\n","60b66286":"# model = Sequential(name='Predict')\n# model.add(Layers.Conv2D(32, kernel_size=(3, 3), activation='relu',input_shape=(64,64,1), name='layer_conv2'))\n# model.add(Layers.Conv2D(32, kernel_size=(3, 3), activation='relu', name='conv3'))\n# model.add(Layers.MaxPooling2D((2,2),name='maxPool1'))\n# model.add(Layers.Dropout(0.25))\n# model.add(Layers.Flatten())\n# model.add(Layers.Dense(128,activation = 'relu',name='fc0'))\n# model.add(Layers.Dropout(0.5))\n# model.add(Layers.Dense(32,activation = 'softmax',name='fc2'))\n\n# model.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])","19fc89e7":"# model = Sequential(name='Predict')\n# model.add(Layers.Conv2D(64, kernel_size=(3, 3), activation='relu',input_shape=(64,64,1), name='conv2'))\n# model.add(Layers.MaxPooling2D((2,2),name='maxPool1'))\n# model.add(Layers.Flatten())\n# model.add(Dense(128, activation='relu'))\n# model.add(Layers.Dropout(0.2))\n# model.add(Layers.Dense(32,activation = 'softmax',name='dns1'))\n\n# model.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])","22956785":"callbacks_list =[EarlyStopping(monitor='val_loss', patience=10), ModelCheckpoint(\n    filepath='model_255.h5', monitor='val_loss', save_best_only= True),]\n\ntrained = model.fit(X_train, y_train, epochs=35, validation_data=(X_valid, y_valid), \n                    callbacks= callbacks_list)\n","aebefca6":"plt.plot(trained.history['accuracy'])\nplt.plot(trained.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nplt.plot(trained.history['loss'])\nplt.plot(trained.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","006a962d":"print(\"on Validation data\")\npred1=model.evaluate(X_valid,y_valid)\nprint(\"accuaracy\", str(pred1[1]*100))\nprint(\"Total loss\",str(pred1[0]*100))","304a4fde":"from sklearn.metrics import confusion_matrix\nY_prediction = model.predict(X_valid)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_prediction,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_valid,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n\nplt.figure(figsize=(10,8))\nplt.title('Validation confusion_matrix', fontsize = 16) \nsns.heatmap(confusion_mtx, annot=True, fmt=\"d\");\n","6c55ac03":"cnn_Y_pred = model.predict(X_pred)\ncnn_Y_pred = np.argmax(cnn_Y_pred,axis = 1)\nprint(cnn_Y_pred)","b45a82e2":"def display_prediction(col_size, row_size,XPred,yPred): \n    img_index=0\n    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n    for row in range(0,row_size):\n        for col in range(0,col_size):\n            ax[row][col].imshow(X_pred[img_index][:,:,0], cmap='gray')\n            ax[row][col].set_title(\"({}) {}\".format(yPred[img_index],get_classlabel(yPred[img_index],'Ar')))\n            ax[row][col].set_xticks([])\n            ax[row][col].set_yticks([])\n            img_index += 1","b7de6765":"display_prediction(12,8,X_pred,cnn_Y_pred)","26418218":"# layer_outputs = [layer.output for layer in model.layers[:9]] # Extracts the outputs of the top 12 layers\n# activation_model = Models.Model(inputs=model.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input\n\nlayer_outputs = [layer.output for layer in model.layers]\nactivation_model = Model(inputs=model.input, outputs=layer_outputs)\nactivations = activation_model.predict(X_train[10].reshape(1,64,64,1))\n \ndef display_activation(activations, col_size, row_size, act_index): \n    activation = activations[act_index]\n    activation_index=0\n    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n    for row in range(0,row_size):\n        for col in range(0,col_size):\n            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n            activation_index += 1","9e309b90":"plt.imshow(X_train[10][:,:,0],cmap='gray');","da2a1f94":"display_activation(activations, 8, 8, 1)","143bd7a7":"display_activation(activations, 8, 8, 2)","d03bdb61":"**6- Model Training**","a9ec80aa":"**8- Reports**","17e7aba5":"**3- Define Functions**\n\n**SplitData(predictions,testsize):** *to split the data into Fixed number of samples for prediction(predictions) and rest will be splited by percentage of test and training (testsize)*<br><br>\n**get_classlabel(class_code,lang= 'Ar'):** *to return Class Label for a class (class_code) in arabic of English , default is arabic*<br><br>\n**getDataSet(setType,isDL):** *prepaer images and class to be used by model setType: Data type is training, validation or prediction, isDL: True for Keras CNN, False for skLearn KNN*<br><br>\n**display_prediction(col_size, row_size,XPred,yPred):** *Generally to display images <br><br>","2bb2c496":"**4- Preparing Data**","b8f34135":"**5.B- Keras Convolutional Neural Network (CNN)**","14723467":"**1- Import needed libraries**","74421e29":"**7- Model Evaluation**","1b75c66e":"**ArASL\nArabic Arm Sign Language Image Classification**","c5ebd926":"* <a href=\".\/model_255.h5\"> Download Model File <\/a>","5ab9f70d":"**9- Model Prediction**","0aaf7811":"**2- Load Data**\n","df4b8dcf":"**5- Model Definition**","4baa2e1f":"** - Visualize CNN Layers**","a1bf0a9e":"**1- Import needed libraries**<br>\n**2- Load Data**<br>\n**3- Define Functions**<br>\n**4- Preparing Data**<br>\n**5- Model Definition**<br>\n**5.A- Model Definition**<br>\n**5.B- Model Definition**<br>\n**6- Model Training**<br>\n**7- Model Evaluation**<br>\n**8- Reports**<br>\n**9- Model Prediction**<br><br>\n** - Visualize CNN Layers**\n\n\n","80ecdf94":"**5.A- sklearn k Nearest Neighbors(KNN)**"}}