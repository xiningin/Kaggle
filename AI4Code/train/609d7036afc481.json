{"cell_type":{"2aa3660a":"code","35e23083":"code","2e17ecda":"code","7ec0d10c":"code","ba0abc5e":"code","da34ffe4":"code","8923dcc0":"code","7c36eee5":"code","c7b45612":"code","c1828bbb":"code","021f93e2":"code","121f7641":"code","26da968f":"code","0a57f1f9":"code","590c02ca":"code","9c04f62f":"code","c101e929":"code","37ec6707":"markdown"},"source":{"2aa3660a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","35e23083":"# Load Train and Competition Dataset\ntrain_raw_dataset = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\n\ny_train_raw = tf.keras.utils.to_categorical(train_raw_dataset.pop('label'), num_classes=10, dtype='uint8')\nX_train_raw = train_raw_dataset \/ 255.0\ncompetition_raw_dataset = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv') \/ 255.0","2e17ecda":"# Resize image  \nIMG_SIZE = 28\nX_train_raw = X_train_raw.values.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\ncompetition_raw_dataset = competition_raw_dataset.to_numpy().reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\nprint(\"Training set (images) shape: {shape}\".format(shape=X_train_raw.shape))\nprint(\"Training set (labels) shape: {shape}\".format(shape=y_train_raw.shape))\nprint(\"Competition set (images) shape: {shape}\".format(shape=competition_raw_dataset.shape))","7ec0d10c":"# Plot Images\nPLOT_SIZE = 5\nplt.figure(figsize=(10,10))\nfor i in range(PLOT_SIZE * PLOT_SIZE):\n    plt.subplot(PLOT_SIZE, PLOT_SIZE, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_train_raw[i][:, :, 0], cmap=plt.cm.binary)\n    plt.xlabel(y_train_raw[i].tolist().index(1))\nplt.show()","ba0abc5e":"# Split Training and Testing Set\nRANDOM_STATE = 7\nTEST_SIZE = 0.1\n\nX_train, X_test, y_train, y_test = train_test_split(X_train_raw, y_train_raw, \n                                                    test_size=TEST_SIZE, random_state = RANDOM_STATE)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((tf.dtypes.cast(X_train, tf.float64), tf.dtypes.cast(y_train, tf.uint8)))\ntest_dataset = tf.data.Dataset.from_tensor_slices((tf.dtypes.cast(X_test, tf.float64), tf.dtypes.cast(y_test, tf.uint8)))\ncompetition_dataset = tf.data.Dataset.from_tensor_slices(tf.dtypes.cast(competition_raw_dataset, tf.float64))\n\nprint(\"Training set ({shape}): {data}\".format(shape=len(train_dataset), data=train_dataset))\nprint(\"Test set ({shape}): {data}\".format(shape=len(test_dataset), data=test_dataset))\nprint(\"Competition set ({shape}): {data}\".format(shape=len(competition_dataset), data=competition_dataset))","da34ffe4":"## Performance Tunning\n# .batch() divides data into sets\n# .shuffle() randomize data\n# .cache() loads data into memory\n# .prefetch() decouples loading and training process\n# https:\/\/www.tensorflow.org\/guide\/data_performance\n\nBATCH_SIZE = 64\nSHUFFLE_BUFFER_SIZE = 100\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(AUTOTUNE)\ntest_dataset = test_dataset.batch(BATCH_SIZE).cache().prefetch(AUTOTUNE)\ncompetition_dataset = competition_dataset.batch(BATCH_SIZE).cache().prefetch(AUTOTUNE)","8923dcc0":"# Construct a Standard CNN model for training\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', padding = 'same', input_shape=(28, 28, 1)),\n    tf.keras.layers.Conv2D(64, (5, 5), activation='relu', padding = 'same'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.summary()\ntf.keras.utils.plot_model(model, \"model.png\", show_shapes=True)","7c36eee5":"# Define the optimizer\n# https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\noptimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-7, centered=False)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Data augmentation to prevent overfitting\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ndatagen.fit(X_train)\n\n# Progressively reduce learning rate\nlearning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, \n                                                               factor=0.5, min_lr=0.00001)\nearlystopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0,\n                             patience=1, verbose=1, mode='auto')","c7b45612":"history = model.fit(datagen.flow(X_train,y_train, batch_size=BATCH_SIZE), \n                    epochs=20, callbacks=[learning_rate_reduction, earlystopper])","c1828bbb":"# Evaluate the model\nmodel.evaluate(test_dataset)","021f93e2":"# Predict for competition\npredictions = model.predict_classes(competition_dataset)\nindices = np.arange(1, competition_raw_dataset.shape[0]+1)\n\n# Save output\nfrom datetime import datetime\ntimestamp = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n\noutput = pd.DataFrame({'ImageId': indices, 'Label': predictions})\noutput.to_csv('submission_CNN_' + timestamp + '.csv', index=False)\nprint(\"Your submission was successfully saved!\")","121f7641":"# Construct an one-layer NN model for training\nmodelNN = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\n# Define the optimizer\n# https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\noptimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-7, centered=False)\nmodelNN.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodelNN.summary()\n\nhistoryNN = modelNN.fit(datagen.flow(X_train,y_train, batch_size=BATCH_SIZE), epochs=5, \n                        callbacks=[learning_rate_reduction, earlystopper])\n\n# Evaluate NN model\nmodelNN.evaluate(test_dataset)","26da968f":"# Predict for competition using single layer NN\npredictions = modelNN.predict_classes(competition_dataset)\nindices = np.arange(1, competition_raw_dataset.shape[0]+1)\n\n# Save output\nfrom datetime import datetime\ntimestamp = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n\noutput = pd.DataFrame({'ImageId': indices, 'Label': predictions})\noutput.to_csv('submission_random_forest_' + timestamp + '.csv', index=False)\nprint(\"Your submission was successfully saved!\")","0a57f1f9":"inputs = tf.keras.Input(shape=(28, 28, 1), name=\"image_input\")\n\nx = tf.keras.layers.Conv2D(32, (5, 5), activation=\"relu\", padding='same')(inputs)\nx = tf.keras.layers.Conv2D(64, (5, 5), activation=\"relu\", padding='same')(x)\nx = tf.keras.layers.Dropout(0.25)(x)\nblock_1_output = tf.keras.layers.MaxPooling2D((2, 2))(x)\n\nx = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding = 'same')(x)\nx = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding = 'same')(x)\nx = tf.keras.layers.Dropout(0.25)(x)\nblock_2_output = tf.keras.layers.add([tf.keras.layers.MaxPooling2D((2, 2))(x), block_1_output])\n\nx = tf.keras.layers.Flatten()(block_2_output)\nx = tf.keras.layers.Dense(3136, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.5)(x)\n\noutputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n\nmodelCINN = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"toy_ResNet\")\nmodelCINN.summary()\n\n# Plot the layers\ntf.keras.utils.plot_model(modelCINN, \"CINN.png\", show_shapes=True)","590c02ca":"# Define the optimizer\n# https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\noptimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-7, centered=False)\nmodelCINN.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Data augmentation to prevent overfitting\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ndatagen.fit(X_train)\n\n# Progressively reduce learning rate\nlearning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, \n                                                               factor=0.5, min_lr=0.00001)\nearlystopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0,\n                             patience=1, verbose=1, mode='auto')\n\nhistory = modelCINN.fit(datagen.flow(X_train,y_train, batch_size=BATCH_SIZE), \n                    epochs=20, callbacks=[learning_rate_reduction, earlystopper])","9c04f62f":"modelCINN.evaluate(test_dataset)","c101e929":"# Predict for competition\npredictions = np.argmax(modelCINN.predict(competition_dataset), axis = 1)\nindices = np.arange(1, competition_raw_dataset.shape[0]+1)\n\n# Save output\nfrom datetime import datetime\ntimestamp = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n\noutput = pd.DataFrame({'ImageId': indices, 'Label': predictions})\noutput.to_csv('submission_RestNet_' + timestamp + '.csv', index=False)\nprint(\"Your submission was successfully saved!\")","37ec6707":"## Alternatively, use keras functional api to build an inter-connected CNN (ResNet)"}}