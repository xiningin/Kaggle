{"cell_type":{"124de039":"code","676d7358":"code","a252db8b":"code","c38ce76a":"code","32af0b03":"code","29fd9d0c":"code","c70256bf":"code","2ae5d606":"code","18ad18b9":"code","35d3b7e7":"code","dd401942":"code","3773d4fb":"code","0d992c9b":"code","16fa0c4b":"markdown","1e7c4a99":"markdown","a6c8f48e":"markdown","20f2c4f1":"markdown"},"source":{"124de039":"import os\nimport pandas as pd\nimport numpy as np\nimport gc\ngc.enable()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport cv2\nimport PIL\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nimport tensorflow as tf\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, regularizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, Dropout, Activation, BatchNormalization, concatenate\nfrom tensorflow.keras.models import Sequential\n\nimgSize = 299\n\npath = '\/kaggle\/input\/petfinder-pawpularity-score\/'\nos.listdir(path)","676d7358":"train_data = pd.read_csv(path+'train.csv')\nprint(train_data.shape)\ntrain_data.sample(1)","a252db8b":"len(os.listdir(path+'train'))","c38ce76a":"id_ = train_data.loc[1234, 'Id']\n# Create file\nfile = id_+'.jpg'\n\nimg = cv2.imread(path+'train\/'+file)\nimg = cv2.resize(img, (imgSize,imgSize), interpolation = cv2.INTER_AREA)\nprint('Image shape:', img.shape)\n\nfig, axs = plt.subplots(1, 1, figsize=(7, 7))\naxs.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\naxs.set_xticklabels([])\naxs.set_yticklabels([])\nplt.show()","32af0b03":"train_data = train_data[['Id', 'Pawpularity']]\ntrain_data.sample(1)","29fd9d0c":"FileLoc = []\n\nfor j in range(train_data.shape[0]):\n    id_ = train_data.loc[j, 'Id']\n    file = id_+'.jpg'\n    file = path+'train\/'+file\n    FileLoc.append(file)\n\ntrain_data['FileLoc'] = FileLoc  \ntrain_data.sample(1)","c70256bf":"data = train_data.FileLoc\nlabels = train_data.Pawpularity\n\n# Split arrays or matrices into random TRAIN and TEST subsets\nX_trainV, X_test, y_trainV, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n\n# Split the validation \nX_train, X_valid, y_train, y_valid = train_test_split(X_trainV, y_trainV, test_size=0.2, random_state=42)\n\n# Create the dataframes for the Keras generator \/ iterator: train valid and test\nTestDF = pd.concat([X_test,y_test],axis=1)\nprint('Test ', TestDF.shape)\n\nTrainDF = pd.concat([X_train,y_train],axis=1)\nprint('Train ',TrainDF.shape)\n\nValidDF = pd.concat([X_valid,y_valid],axis=1)\nprint('Valid ',ValidDF.shape)\n","2ae5d606":"%%time\n\nbatch_size=8\n\ndatagen=ImageDataGenerator(rescale=1.\/255)\n\ntrainGen = datagen.flow_from_dataframe(\n    TrainDF,\n    x_col=\"FileLoc\",\n    y_col='Pawpularity',\n    target_size=(imgSize, imgSize),\n    color_mode=\"rgb\",\n    class_mode=\"raw\",\n    batch_size=batch_size,\n    shuffle=True,\n    seed=42,\n    interpolation=\"nearest\",\n    #crop_to_aspect_ratio=True,\n    validate_filenames=True\n)\n\ntestGen = datagen.flow_from_dataframe(\n    TestDF,\n    x_col=\"FileLoc\",\n    y_col='Pawpularity',\n    target_size=(imgSize, imgSize),\n    color_mode=\"rgb\",\n    class_mode=\"raw\",\n    batch_size=batch_size,\n    shuffle=True,\n    seed=42,\n    interpolation=\"nearest\",\n    #crop_to_aspect_ratio=True,\n    validate_filenames=True\n)\n\nvalidGen = datagen.flow_from_dataframe(\n    ValidDF,\n    x_col=\"FileLoc\",\n    y_col='Pawpularity',\n    target_size=(imgSize, imgSize),\n    color_mode=\"rgb\",\n    class_mode=\"raw\",\n    batch_size=batch_size,\n    shuffle=True,\n    seed=42,\n    interpolation=\"nearest\",\n    #crop_to_aspect_ratio=True,\n    validate_filenames=True\n)\n","18ad18b9":"# Load the conv_base trained image model\n\nconv_base = tf.keras.applications.EfficientNetB2(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(imgSize, imgSize, 3))","35d3b7e7":"# Make the conv_base NOT trainable:\nfor layer in conv_base.layers[:]:\n    layer.trainable = False\n\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.BatchNormalization())\nmodel.add(Dense(4, activation='relu'))\nmodel.add(Dense(1, activation='linear'))\n\nmodel.compile('Adam', loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])\nmodel.summary()","dd401942":"# Fit\n\nSTEP_SIZE_TRAIN=trainGen.n\/\/trainGen.batch_size\nSTEP_SIZE_VALID=validGen.n\/\/validGen.batch_size\n\nhistory = model.fit_generator(generator=trainGen,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=validGen,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs = 10)","3773d4fb":"# Learning curves\n\nacc = history.history['root_mean_squared_error']\nval_acc = history.history['val_root_mean_squared_error']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training rmse')\nplt.plot(epochs, val_acc, 'r', label='Validation rmse')\nplt.title('Training and validation RMSE')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","0d992c9b":"# Predict on test\n\ny_test = np.array(y_test)\n\n\nPreds = model.predict_generator(generator=testGen,\n)\n\nPreds = Preds.flatten()\nprint(Preds.shape)\nprint(y_test.shape)\n\n# RMSE on test\nnp.sqrt(np.mean((Preds-y_test)**2))","16fa0c4b":"# Model","1e7c4a99":"# Keras image generator","a6c8f48e":"# Goal: Compare several, pre-trained Keras image analysis models\n\n### Based on data from\nhttps:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\n\n### Simple model\n* conv_base from https:\/\/keras.io\/api\/applications\/\n* conv_base (not trainable) -> Flatten -> BatchNormalization -> Dense\n\n### Results after 10 epochs ... RMSE on a 20% test - Not Kaggle submit: \n* EfficientNetB0 = 21.24\n* EfficientNetB1 = 21.43\n* EfficientNetB2 = **21.03**\n* EfficientNetB3 = 21.05\n* EfficientNetB4 = 21.20\n* EfficientNetB5 = 21.04\n* EfficientNetB6 = 21.10\n* EfficientNetB7 = 21.15 \n\n### Following models overfit from epoch 1... even w Dropout \n* ResNet50\n* VGG16\n* InceptionResNetV2\n* MobileNet\n* DenseNet121\n\nI guess these NN are too big for the data. Most probably, the train generator needs image augmentation in order to prevent overfitting. \n\n","20f2c4f1":"# Data"}}