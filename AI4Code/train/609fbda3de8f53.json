{"cell_type":{"4b0b31de":"code","de6fed78":"code","af45fd88":"code","82311a6a":"code","37128b98":"code","dd8cf959":"code","f8483056":"code","6f74911b":"code","a4497039":"code","fc58dcd2":"code","08010bf1":"code","cf682c1c":"code","48c4226a":"code","9e2d9ace":"code","df6be3b1":"code","c81e6102":"code","ad99053e":"code","9584ea52":"code","6deec88a":"code","4121fdc7":"code","8558c97f":"code","0b2249ee":"code","ebcfccbb":"code","5830601c":"code","b344b183":"code","21f1bafe":"code","03f017e6":"code","c20728bf":"code","d6c915cc":"code","d9c207c6":"markdown","46d449e5":"markdown","b1c4c598":"markdown","87d94592":"markdown","f0378911":"markdown","6db98b59":"markdown","70101462":"markdown","4a37a03a":"markdown","97298b9e":"markdown","00e106c7":"markdown"},"source":{"4b0b31de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ntotal_files = 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    total_files += len(filenames)\n    # for filename in filenames:\n    #    print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","de6fed78":"print(\"COVID-19 Research Analysis - checksum, total files = \" + str(total_files))","af45fd88":"metadata = pd.read_csv('\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv')\nmetadata.head()","82311a6a":"len(metadata.journal.unique())","37128b98":"!pip install scispacy\n!pip install https:\/\/s3-us-west-2.amazonaws.com\/ai2-s2-scispacy\/releases\/v0.2.4\/en_core_sci_lg-0.2.4.tar.gz","dd8cf959":"import spacy","f8483056":"import scispacy","6f74911b":"from tqdm import tqdm","a4497039":"def cosine_similarity(u, v):\n    \"\"\"\n    Coded this as part of deeplearning.ai sequence modeling course\n    Cosine similarity reflects the degree of similariy between u and v\n        \n    Arguments:\n        u -- a word vector of shape (n,)          \n        v -- a word vector of shape (n,)\n\n    Returns:\n        cosine_similarity -- the cosine similarity between u and v defined by the formula above.\n    \"\"\"\n    \n    distance = 0.0\n\n    # Compute the dot product between u and v (\u22481 line)\n    dot = np.dot(u, v)\n    # Compute the L2 norm of u (\u22481 line)\n    norm_u = np.sqrt(np.sum(u * u))\n    \n    # Compute the L2 norm of v (\u22481 line)\n    norm_v = np.sqrt(np.sum(v * v))\n    # Compute the cosine similarity defined by formula (1) (\u22481 line)\n    cosine_similarity = dot \/ (norm_u * norm_v)\n    \n    return cosine_similarity","fc58dcd2":"nlp_lg = spacy.load(\"en_core_sci_lg\")","08010bf1":"vector_dict_lg = {}\nfor sha, abstract in tqdm(metadata[[\"sha\",\"abstract\"]].values):\n    if isinstance(abstract, str):\n        vector_dict_lg[sha] = nlp_lg(abstract).vector","cf682c1c":"keys_lg = list(vector_dict_lg.keys())\nvalues_lg = list(vector_dict_lg.values())","48c4226a":"print(\"top 5 keys = {keys}, and values = {values}\".format(keys = keys_lg[0:5], values = values_lg[0:5]))","9e2d9ace":"valarray_lg = np.asarray(values_lg, dtype=np.float32)","df6be3b1":"cosine_sim_matrix_lg = cosine_similarity(valarray_lg, valarray_lg.T)","c81e6102":"print(type(cosine_sim_matrix_lg))","ad99053e":"# same SHA as before\ninput_sha = \"aecbc613ebdab36753235197ffb4f35734b5ca63\"\nn_sim_articles = 5\n\n\nsha_index_lg = keys_lg.index(input_sha)\nsim_indexes_lg = np.argsort(cosine_sim_matrix_lg[sha_index_lg])[::-1][1:n_sim_articles+1]\nsim_shas_lg = [keys_lg[i] for i in sim_indexes_lg]\nmeta_info_lg = metadata[metadata.sha.isin(sim_shas_lg)]","9584ea52":"print(\"=====QUERY ABSTRACT=====\")\nprint(metadata[metadata.sha == input_sha][\"abstract\"].values[0])","6deec88a":"print(f\"=====TOP {n_sim_articles} SIMILAR ABSTRACTS USING LARGE MODEL=====\")\nfor abst in meta_info_lg.abstract.values:\n    print(abst)\n    print(\"=======\")","4121fdc7":"n_return = 5\nnl_query_statement = \"Studies showing discrepancy between humoral and cellular immunity in genetically similar subjects may be significant in the pathogenesis of systemic lupus erythematosus (SLE).\"\nquery_vector_lg = nlp_lg(nl_query_statement).vector\ncosine_sim_matrix_query_lg = cosine_similarity(valarray_lg, query_vector_lg)\nquery_sim_indexes_lg = np.argsort(cosine_sim_matrix_query_lg.reshape(1,-1)[0])[::-1][:n_return]\nquery_shas_lg = [keys_lg[i] for i in query_sim_indexes_lg]\nmeta_info_query_lg = metadata[metadata.sha.isin(query_shas_lg)]","8558c97f":"print(\"=====QUERY ABSTRACT=====\" + nl_query_statement)","0b2249ee":"print(f\"=====TOP {n_sim_articles} SIMILAR ABSTRACTS USING LARGE MODEL=====\")\nfor abst in meta_info_query_lg.abstract.values:\n    print(abst)\n    print(\"=======\")","ebcfccbb":"n_return = 5\ngn_query_statement = \"Effectiveness of drugs being developed and tried to treat COVID-19 patients.\"\ngn_query_vector = nlp_lg(gn_query_statement).vector\ngn_cosine_sim_matrix_query = cosine_similarity(valarray_lg, gn_query_vector)\ngn_query_sim_indexes = np.argsort(gn_cosine_sim_matrix_query.reshape(1,-1)[0])[::-1][:n_return]\ngn_query_shas = [keys_lg[i] for i in gn_query_sim_indexes]\ngn_meta_info_query = metadata[metadata.sha.isin(gn_query_shas)]","5830601c":"print(\"=====QUERY ABSTRACT=====\" + gn_query_statement)","b344b183":"print(f\"=====TOP {n_sim_articles} SIMILAR ABSTRACTS USING LARGE MODEL=====\")\nfor sha, abst in zip(gn_query_shas, gn_meta_info_query.abstract.values):\n    print(\"sha: \" + sha)\n    print(\"abstract:\" + abst)\n    print(\"=======\")","21f1bafe":"from sklearn.manifold import TSNE","03f017e6":"t_sne = TSNE(verbose=1, perplexity=5)\nabstractsvec = t_sne.fit_transform(valarray_lg)","c20728bf":"from sklearn.cluster import MiniBatchKMeans\n\nk = 10\nmini_batch_kmeans = MiniBatchKMeans(n_clusters=k)\ncat_pred = mini_batch_kmeans.fit_predict(valarray_lg)\ncat = cat_pred","d6c915cc":"from matplotlib import pyplot as plt\nimport seaborn as sns\nimport random \n\n# seaboarn settings\nsns.set(color_codes=True)\nsns.set(rc={'figure.figsize':(12,12), 'axes.facecolor':'0.25'})\n\ncolors = sns.hls_palette(10, l = .5, s = .75)\nrandom.shuffle(colors)\n\n# plot\nsns.scatterplot(abstractsvec[:,0], abstractsvec[:,1], hue = cat, legend = 'full', palette = colors)\nplt.title(\"Plot of the clusterings of the abstracts from COVID-19 challenge dataset (wordvec model = scispaCy large, Clustering = MiniBatchKMeans )\")\nplt.show()","d9c207c6":"## Query: Immunity in genetically similar subjects","46d449e5":"## Test Large sci model\n> 1. Small model gave highly unsatisfactory results. Let's try large model that is trained on large body of corpora.\n> 2. A thought, if I can use a query formed by creating sentences with similar meaning as the original query, will it retrieve relevant results.\n","b1c4c598":"## Visualization\n### t-SNE and clustering","87d94592":"## Let's try to use a more natural query statement","f0378911":"## Clustering plot\n> ### Use MiniBatchKMeans for speed (as it turns out KMeans is not vastly different) ","6db98b59":"# Plan of action\n**1.Dataset analysis - similarity\/pcs\/t-sne. No supervision in this stage.**\n> 1. Vectorize abstracts - currently trying scispaCy en_core_sci_sm\/en_core_sci_lg models.\n> 2. First trying out cosine similarity between abstract vectors.\n> 3. Later on visualize by PCA and t-SNE.\n> 4. Eventually, I want to get the SHA from these abstracts so I can focus on the relevant (to my tasks) papers.\n> 5. So feed through softmax to classify into categories.\n\n**2.Train**\n> 1. Pick m abstracts to train, .2 * m to test.\n> 2. Model == pre-trained scispacy + softmax layer\n> 3. Train the softmax layer\n> 4. Generate stats\n\n**3. Test**\n> 1. Test on .2 * m abstracts\n> 2. Generate stats\n\n**4. Predict**\n> 1. The output of this stage is that SHAs predicted by the model are appropriate for my task(s).\n\n**5. NEXT -> can I develop a question and answer system on the papers with SHAs from the above step? Maybe like ADAM qas**","70101462":"Count of all the unique publication journals","4a37a03a":"# Citing for ScispaCy\nNeumann, Mark et al. \u201cScispaCy: Fast and Robust Models for Biomedical Natural Language Processing.\u201d BioNLP@ACL (2019).","97298b9e":"Expected output = COVID-19 Research Analysis - checksum, total files = 52101 (as of 4\/4\/2020)","00e106c7":"**Inspired from other sources such as** [this](https:\/\/towardsdatascience.com\/how-to-get-started-analyzing-covid-19-data-808822437c32). The idea of this approach is to convert the abstracts to vectors and analyse the cosine similarity (to get a sense of the direction of the abstracts)"}}