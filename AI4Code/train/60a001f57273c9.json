{"cell_type":{"b6fe6c36":"code","a7f10d2d":"code","ea2e5a96":"code","b76415f3":"code","30aebb07":"code","b6f54b98":"code","36a51a91":"code","b43c0bea":"code","a3d73b47":"code","54ba794f":"code","98f6200e":"code","10273b2d":"code","c97032d6":"code","9f63a824":"code","867b532b":"code","51e6fa06":"code","f86fbe88":"code","9f1699f1":"code","e902f100":"code","d048fe6b":"code","10142127":"code","1c2972b4":"code","29fe3a0b":"code","c3dda9ef":"code","ab4ced89":"code","e7835da2":"code","b68b82fd":"code","99abbbe9":"code","aee15b2a":"code","9ace1a8e":"code","67216788":"code","ed0de359":"code","23dae62e":"markdown","2a77713b":"markdown","7a1b3295":"markdown","6b60284e":"markdown","8911972d":"markdown","7db959e9":"markdown","f237f144":"markdown","41bfe24b":"markdown","d4d24ca2":"markdown","8b650fff":"markdown","ecd84aae":"markdown","21c122d6":"markdown","7e472bb5":"markdown","774a85d0":"markdown","3261f9a8":"markdown","10c56340":"markdown","fba20d7d":"markdown","f31167cf":"markdown","7fab3658":"markdown","8c821e05":"markdown","3a13c103":"markdown","f3f09d4a":"markdown","d584ce94":"markdown","e07e80b9":"markdown","65b21095":"markdown","4c2f6874":"markdown","33df037f":"markdown","98047a86":"markdown","145936ce":"markdown","b6d0e399":"markdown","6100f0a6":"markdown","f861e12a":"markdown","a5f6c9b9":"markdown","e04c9826":"markdown","0533e8ca":"markdown"},"source":{"b6fe6c36":"from IPython.display import display\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport optuna\nimport os\nimport pandas as pd\nimport random\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer, KNNImputer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold, train_test_split\nfrom sklearn.preprocessing import PowerTransformer, KBinsDiscretizer, PolynomialFeatures, StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport seaborn as sns\nimport shap\nimport xgboost as xgb\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('ggplot')","a7f10d2d":"data_path = '\/kaggle\/input\/song-popularity-prediction\/'\ntrain = pd.read_csv(data_path+'train.csv', index_col='id')\ntest = pd.read_csv(data_path+'test.csv', index_col='id')","ea2e5a96":"print('Train size: ', len(test), ' rows.')\nprint('Columns: ', train.shape[1])\ntrain.head()","b76415f3":"def dataset_stats(df):\n    \"\"\"\n    Generates a summary of basic statistics based on a dataframe using numeric columns.\n    \n    The statistics include:\n        - dtype: column dtype\n        - row #: number of rows in column.\n        - null #: number of null values in column.\n        - null %: percentage of null values in column.\n        - mean: arithmetic mean of column values.\n        - std: standard deviation of column values.\n        - min: minimum value of column.\n        - Q1: first quantile of column (25%).\n        - Q2: second quantile of column (50%) or median.\n        - Q3: third quantile of column (75%).\n        - max: maximum value of column.\n    ---------------\n    Args:\n        df (pandas.DataFrame): DataFrame to use as a basis for the summary.\n    ---------------\n    Returns:\n        pandas.DataFrame: summary statistics.\n    \"\"\"\n\n    numeric_cols = list(df.select_dtypes(include=np.number).columns)\n\n    stats = pd.DataFrame(columns=numeric_cols,\n                         index=[\n                             'dtype', 'row #', 'null #', 'null %', 'mean',\n                             'unique #', 'std', 'min', 'Q1', 'Q2', 'Q3', 'max'\n                         ])\n\n    for col in numeric_cols:\n\n        stats.loc['dtype', col] = df[col].dtype\n        stats.loc['row #', col] = df[col].shape[0]\n        stats.loc['null #', col] = df[col].isnull().sum()\n        stats.loc['null %', col] = df[col].isnull().sum() \/ df[col].shape[0]\n        stats.loc['unique #', col] = df[col].nunique()\n        stats.loc['mean', col] = df[col].mean()\n        stats.loc['std', col] = df[col].std()\n        stats.loc['min', col] = df[col].min()\n        stats.loc['Q1', col] = df[col].quantile(q=0.25)\n        stats.loc['Q2', col] = df[col].quantile(q=0.5)\n        stats.loc['Q3', col] = df[col].quantile(q=0.75)\n        stats.loc['max', col] = df[col].max()\n\n    cell_hover = {  # for row hover use <tr> instead of <td>\n        'selector': 'td:hover',\n        'props': [('background-color', '#ffffb3'), ('color', '#000000')]\n    }\n    index_names = {\n        'selector': '.index_name',\n        'props': 'font-style: italic; color: darkgrey; font-weight:normal;'\n    }\n    headers = {\n        'selector': 'th:not(.index_name)',\n        'props': 'background-color: #000000; color: white;'\n    }\n\n    stats = stats.style\\\n                .format(formatter=\"{:.2%}\",subset=pd.IndexSlice['null %', :])\\\n                .set_sticky(axis='index')\\\n                .set_table_styles([cell_hover, index_names, headers])\n\n    return stats\n","30aebb07":"dataset_stats(train)","b6f54b98":"# change dtypes for categorical variables\nfor var in ['key', 'audio_mode', 'time_signature']:\n    train[var] = pd.Categorical(train[var])\ntrain['song_popularity'] = train['song_popularity'].astype('bool').astype('category')","36a51a91":"num_cols_size = train.select_dtypes(include=np.number).shape[1]\nnum_cols = list(train.select_dtypes(include=np.number).columns)\ncat_cols_size = train.select_dtypes(exclude=np.number).shape[1]\ncat_cols = list(train.select_dtypes(exclude=np.number).columns)\nfeatures = num_cols + cat_cols\nfeatures.remove('song_popularity')\n\nprint('Numerical columns: ', num_cols_size, ' | ',\n      round(num_cols_size \/ train.shape[1] * 100, 0), '%')\nprint(num_cols, '\\n')\nprint('Categorical columns: ', cat_cols_size, ' | ',\n      round(cat_cols_size \/ train.shape[1] * 100, 0), '%')\nprint(cat_cols)\n","b43c0bea":"print('Test size: ', len(test), ' rows.')\nprint('Columns: ', test.shape[1], ' | Missing columns from the training dataset: ', set(train.columns) - set(test.columns))","a3d73b47":"# classes - binary classification\nfor idx, val in train.song_popularity.value_counts(normalize=True).iteritems():\n    print('Class ', idx, ': ', val * 100, '% | ', round(train.shape[0] * val, 0), ' examples')\nprint('Total examples: ', train.shape[0])\n\n\nsns.countplot(data=train, x='song_popularity')\nsns.despine()","54ba794f":"color_ = ['#7b03fc', '#0328fc', '#03bafc', '#136613', '#fca903', '#fc2803']\ncmap_ = ['magma', 'viridis', 'crest']\n\nplt.figure(figsize=(20, 20))\nfor i, col in enumerate(train[features].columns):\n    rand_col = color_[random.sample(range(6), 1)[0]]\n    plt.subplot(5, 3, i + 1)\n    if col in num_cols:\n\n        sns.kdeplot(train[col], color=rand_col, fill=rand_col)\n        plt.title(col, weight='bold', color=rand_col)\n        plt.ylabel(\" \")\n        plt.xlabel(\" \")\n        plt.tight_layout()\n    else:\n        sns.countplot(data=train,\n                      x=col,\n                      palette=cmap_[random.sample(range(3), 1)[0]])\n        plt.title(col, weight='bold', color='black')\n        plt.ylabel(\" \")\n        plt.xlabel(\" \")\n        plt.tight_layout()\nplt.subplot(5, 3, 14)\nsns.kdeplot(np.log(train['instrumentalness']), color=rand_col, fill=rand_col)\nplt.title('instrumentalness (log transformed)',\n          weight='bold',\n          color=rand_col,\n          size=17)\nplt.ylabel(\"\")\nplt.xlabel(\"\")\nplt.tight_layout()\nplt.show()","98f6200e":"quantiles = pd.DataFrame(train.instrumentalness.quantile([.1,.2,.3,.4,.5,.6,.7,.8,.9])).T\nquantiles['min'] = train.instrumentalness.min()\nquantiles['max'] = train.instrumentalness.max()\nquantiles[['min', .1, .2, .3, .4, .5, .6, .7, .8, .9, 'max']]\n","10273b2d":"inst = train[['instrumentalness', 'song_popularity']].copy()\ninst['thresh'] = inst.instrumentalness.map(lambda x: 'Above 0.01'\n                                           if x > 0.01 else 'Below 0.01')\n\nfig, axes = plt.subplots(2, 2, figsize=(25, 10))\nfor ncol, val in enumerate(['Below 0.01', 'Above 0.01']):\n    sns.boxplot(data=inst[inst.thresh == val],\n                x='instrumentalness',\n                ax=axes[0, ncol]).set_title(val, fontsize=14)\n    axes[0, ncol].set_xlabel('')\nfor ncol, val in enumerate(['Below 0.01', 'Above 0.01']):\n    sns.histplot(data=inst[inst.thresh == val],\n                 x='instrumentalness',\n                 hue='song_popularity',\n                 kde=True,\n                 ax=axes[1, ncol])\nplt.suptitle('Instrumentalness: Decomposed Distribution', fontsize=17)\nplt.tight_layout()\nplt.show()","c97032d6":"ncols = 5\nnrows = 2\n\nfig, ax = plt.subplots(nrows, ncols, figsize=(30,12))\n\nfor r in range(nrows):\n    for c in range(ncols):\n        col = num_cols[r*ncols+c]\n        sns.kdeplot(data=train, x=col, hue='song_popularity', ax=ax[r,c], fill=True, legend=True)\n        ax[r,c].set_ylabel('')\n        ax[r,c].set_xlabel(col, fontsize=10)\n        ax[r, c].tick_params(labelsize=5, width=0.5)\n        sns.despine()\nplt.suptitle('Target Impact - Numerical Features', fontsize=17)\nplt.tight_layout()\nplt.show()","9f63a824":"plt.figure(figsize=(15, 10))\ncorr_matrix = train.corr()\ncorr = np.tril(corr_matrix)\n\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\nsns.set(rc={'axes.facecolor': 'white', 'figure.facecolor': 'white'})\nsns.heatmap(data=corr_matrix.T,\n            mask=corr,\n            cmap=cmap,\n            vmax=.3,\n            center=0,\n            square=True,\n            linewidths=.5,\n            cbar_kws={\n                \"shrink\": .5\n            },\n            annot=True).set_title('Correlation Plot', fontsize=17)\nplt.xticks(size=13, color='grey')\nplt.yticks(size=13, color='grey')\nplt.tight_layout()\nplt.show()","867b532b":"plt.style.use('ggplot')\nplt.figure(figsize=(20, 20))\nsns.pairplot(data=train, hue='song_popularity', vars=num_cols)\nplt.suptitle('Feature Interactions', fontsize=17)\nplt.tight_layout()\nplt.show()","51e6fa06":"X = train.drop(labels='song_popularity', axis=1)\ny = train['song_popularity'].astype('int64').astype('category')","f86fbe88":"# create features from high correlation\ntrain['energy_loud_log'] = train['energy'] + np.exp(train['loudness']) * 100\ntrain['acoustic_denormed'] = train['acousticness'] * train['energy_loud_log']\n\n# create binary columns to account for null values\nmissing = train.isna()\nmissing.columns = [colname + '_isna' for colname in missing.columns]\ntrain = pd.concat([train, missing], axis=1)\n# change dtype as categorical\nfor col in train.select_dtypes(include='bool').columns:\n    train[col] = train[col].astype('int64').astype('category')\n\n# discretize tempo, usually music genres have a range of bpm associated to them\ndiscretizer = KBinsDiscretizer(n_bins=7, encode='ordinal', strategy='uniform')\ntrain['tempo_bin'] = discretizer.fit_transform(np.array(train.tempo).reshape(-1,1))\ntrain['tempo_bin'] = train['tempo_bin'].astype('int64').astype('category')\n\n# extract minutes, seconds and milliseconds\ntrain['song_minutes'] = train['song_duration_ms'].apply(\n    lambda x: divmod(divmod(x, 1000)[0], 60)[0])\n\n# create binary column to differentiate between instrumentalness distributions\ntrain['instrumental'] = train['instrumentalness'].apply(\n    lambda x: 0 if x < 0.01 else 1).astype('int64').astype('category')","9f1699f1":"# visualize training dataframe\ndisplay(train.head())","e902f100":"# create features from high correlation\ntest['energy_loud_log'] = test['energy'] + np.exp(test['loudness']) * 100\ntest['acoustic_denormed'] = test['acousticness'] * test['energy_loud_log']\n\n# create binary columns to account for null values\nmissing = test.isna()\nmissing.columns = [colname + '_isna' for colname in missing.columns]\ntest = pd.concat([test, missing], axis=1)\n# change dtype as categorical\nfor col in test.select_dtypes(include='bool').columns:\n    test[col] = test[col].astype('int64').astype('category')\n\n# discretize tempo, usually music genres have a range of bpm associated to them\ntest['tempo_bin'] = discretizer.transform(np.array(test.tempo).reshape(-1,1))\ntest['tempo_bin'] = test['tempo_bin'].astype('int64').astype('category')\n\n# extract minutes, seconds and milliseconds\ntest['song_minutes'] = test['song_duration_ms'].apply(\n    lambda x: divmod(divmod(x, 1000)[0], 60)[0])\n\n# create binary column to differentiate between instrumentalness distributions\ntest['instrumental'] = test['instrumentalness'].apply(\n    lambda x: 0 if x < 0.01 else 1).astype('int64').astype('category')\n\n# visualize test dataframe\ndisplay(test.head())","d048fe6b":"# separate categorical and numerical columns\nnum_cols = X.select_dtypes(exclude='category').columns\ncat_cols = X.select_dtypes(include='category').columns","10142127":"# Transformations\ncat_pipe = Pipeline(steps=[\n    ('imputer', KNNImputer(n_neighbors=5, weights='distance'))\n])\nnum_pipe = Pipeline(steps=[\n    ('imputer', IterativeImputer(max_iter=100, initial_strategy='median')),\n    ('transform', PowerTransformer(method='yeo-johnson', standardize=True)),\n    ('polynomial', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False))\n])\n\n# Data Preprocessing\npreprocessor = ColumnTransformer(transformers=[\n    ('categorical', cat_pipe, cat_cols),\n    ('numerical', num_pipe, num_cols)\n])","1c2972b4":"rng = np.random.RandomState(16)","29fe3a0b":"X_transf = preprocessor.fit_transform(X)","c3dda9ef":"#def run_trial(trial, data=X_transf, target=y):\n#    \"\"\"\n#    Runs a train-test split and training trial of hyper-parameter optimization.\n#    ---------------\n#    Args:\n#        trial (optuna.trial.Trial): instance of trial object to evaluate the objective function.\n#        data (pandas.DataFrame): predictor variables.\n#        target (pandas.Series): targer variable to predict.\n#    \"\"\"\n#    X_train, X_valid, y_train, y_valid = train_test_split(data, target, test_size=0.1, shuffle=True, stratify=target, random_state=rng)\n#    \n#    params = {\n#        #fixed\n#        'objective': 'binary:logistic',\n#        'eval_metric': 'auc',\n#        'tree_method': 'gpu_hist',\n#        'use_label_encoder': False,\n#        'random_state': rng,\n#        'booster': 'gbtree',\n#        'sampling_method': 'gradient_based',\n#        'scale_pos_weight': y_train[y_train == 0].count() \/ y_train[y_train == 1].count(), # sum(negative instances) \/ sum(positive instances)\n#        #searchable\n#        'n_estimators': trial.suggest_int('n_estimators', 100, 10000, step=100),\n#        'max_depth': trial.suggest_int('max_depth', 5, 15, step=1),\n#        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.5),\n#        'subsample': trial.suggest_discrete_uniform('subsample', 0.3, 1.0, 0.05),\n#        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.4, 1.0, 0.05),\n#        'colsample_bylevel': trial.suggest_discrete_uniform('colsample_bylevel', 0.2, 0.9, 0.1),\n#        'min_child_weight': trial.suggest_discrete_uniform('min_child_weight', 2, 32, 2),\n#        'reg_lambda':  trial.suggest_loguniform('reg_lambda', 1e-3, 1e3),\n#        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 1e3),\n#        'gamma': trial.suggest_float('gamma', 1.0, 50.0),\n#        'max_bin': trial.suggest_int('max_bin', 50, 300, step=25)\n#    }\n#   \n#    clf = xgb.XGBClassifier(**params)\n#    \n#    clf.fit(\n#        X_train,\n#        y_train,\n#        eval_set=[(X_valid, y_valid)],\n#        early_stopping_rounds=300,\n#        verbose=500\n#    )\n#    pred = clf.predict(X_valid)\n#    \n#    return roc_auc_score(y_valid, pred)\n    ","ab4ced89":"# Run Optimization Study\n#study = optuna.create_study(direction='maximize')\n#study.optimize(run_trial, n_trials=150)","e7835da2":"# best parameters\n#study.best_params","b68b82fd":"# Model set-up\n\nxgb_params = {\n    #fixed\n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'booster':'gbtree',\n    'tree_method': 'gpu_hist',\n    'use_label_encoder': False,\n    'random_state': rng,\n    'booster': 'gbtree',\n    'sampling_method': 'gradient_based',\n    'scale_pos_weight': y[y == 0].count() \/ y[y == 1].count(), # sum(negative instances) \/ sum(positive instances)\n    #optimized\n    'n_estimators': 4000,\n    'max_depth': 7,\n    'learning_rate': 0.13438936935511794,\n    'subsample': 0.55,\n    'colsample_bytree': 0.7000000000000001,\n    'colsample_bylevel': 0.7,\n    'min_child_weight': 10.0,\n    'reg_lambda': 162.5065281886699,\n    'reg_alpha': 27.21649495077816,\n    'gamma': 15.330345292116224,\n    'max_bin': 175\n}\n\nclf = xgb.XGBClassifier(\n    **xgb_params,\n    verbosity=1,\n    \n)\n\nmodel_pipe = Pipeline([\n    ('preprocessing', preprocessor),\n    ('classifier', clf)\n])","99abbbe9":"%%time\n# Cross-validation\n\n## stratified k-fold\nrskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=rng)\n\n## Fit model pipeline\nscores = []\ni = 1\nfor train_index, valid_index in rskf.split(X, y):\n    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n    X_valid, y_valid = X.iloc[valid_index], y.loc[valid_index]\n        \n    #Train the model\n    model_pipe.fit(X_train, y_train)\n    score = roc_auc_score(model_pipe.predict(X_valid), y_valid)\n    print(f\"AUC for the fold no. {i} on the validation set: {score}\")\n    scores.append(score)\n    i += 1\nprint(f\"\\nAUC: {np.mean(scores)}\\n\")","aee15b2a":"explainer = shap.Explainer(clf)\nshap_values = explainer(pd.DataFrame(X_transf), y=y)","9ace1a8e":"shap.summary_plot(shap_values, X_transf)","67216788":"predict = model_pipe.predict(test)\nsubmission = pd.DataFrame(zip(test.index, predict), columns=['id','song_popularity'])\nsubmission.head()","ed0de359":"submission.to_csv('submission.csv', encoding='utf-8', index=False)","23dae62e":"<a id=\"2-train-set\"><\/a>\n### **3.A.** Train Set\n\n[Back to Table of Contents](#table-of-contents)","2a77713b":"**Findings**\n- Data is not linearly separable.","7a1b3295":"**Findings**\n- None of the features share a strong correlation with song_popularity.\n- There is a strong inverse correlation between acousticness vs energy and loudness respectively.\n- At the same time, there is a strong direct correlation between energy and loudness.","6b60284e":"<a id=\"modelling\"><\/a>\n## **4.** Modelling\n\n[Back to Table of Contents](#table-of-contents)","8911972d":"<a id=\"exploratory-data-analysis\"><\/a>\n## **2.** Exploratory Data Analysis\n\n[Back to Table of Contents](#table-of-contents)","7db959e9":"<a id=\"1-train-set\"><\/a>\n#### **2.A.a.** Train Set\n\n[Back to Table of Contents](#table-of-contents)","f237f144":"**Findings**\n- *Acousticness*, *liveness* and *speechiness* are skewed to the left, while *loudness* is skewed to the right.\n- *Instrumentalness* shows a heavy left-skewed distribution, where even applying a log-transformation over the feature does not achieve a well-behaved shape.\n- *Key*, *audio_mode* and *time_signature* are all categorica features.","41bfe24b":"**Findings**\n- There are two distinct distributions within this feature.\n- The values below 0.01, which amass above 90% of observations shows a rather symmetrical distribution centered slightly above zero with long tails, the lower one trailing slightly below zero. It resembles very closely in shape to a normal distribution.\n- Values above the threshold show a distribution closely resembling other features, such as *acousticness*.\n- Considering this, it might be useful to treat this feature in a special way to account for this particular status.","d4d24ca2":"<a id=\"correlation-analysis\"><\/a>\n#### **2.C.c.** Correlation Analysis\n\n[Back to Table of Contents](#table-of-contents)","8b650fff":"The test dataset contains 10000 rows and the same features as the train set, except for the target variable (*song_popularity*).","ecd84aae":"<a id=\"train-best-params\"><\/a>\n### **4.C.** Training with best parameters\n\n[Back to Table of Contents](#table-of-contents)","21c122d6":"<a id=\"deep-dive-instrumentalness\"><\/a>\n##### **2.C.a.i.** Deep dive: Instrumentalness\n\n[Back to Table of Contents](#table-of-contents)","7e472bb5":"<a id=\"1-test-set\"><\/a>\n#### **2.A.b.** Test Set\n\n[Back to Table of Contents](#table-of-contents)","774a85d0":"<a id=\"preparations\"><\/a>\n## **1.** Preparations\n\n[Back to Table of Contents](#table-of-contents)","3261f9a8":"### **2.B.** Target variable\n\n[Back to Table of Contents](#table-of-contents)\n\nThe target variable (*song_popularity*) shows this is a binary classification task where there is an imbalance between the two classes:","10c56340":"<a id=\"feature-distributions\"><\/a>\n#### **2.C.a.** Feature Distributions\n\n[Back to Table of Contents](#table-of-contents)","fba20d7d":"From the basic statistics drawn from the dataset, it is possible to see that 90% of the observations (decile 9) that make the *instrumentalness* variable are below 0.005, while the max value is above 1.\n\nTherefore, using a threshold to divide the values could show insights into the heavily skewed distribution.","f31167cf":"<a id=\"feature-importance\"><\/a>\n### **4.D.** Feature Importance\n\n[Back to Table of Contents](#table-of-contents)","7fab3658":"<a id=\"feature-engineering\"><\/a>\n## **3.** Feature Engineering\n\n[Back to Table of Contents](#table-of-contents)","8c821e05":"<a id=\"load-data\"><\/a>\n### **1.B.** Load Data\n\n[Back to Table of Contents](#table-of-contents)","3a13c103":"<a id=\"feature-analysis\"><\/a>\n### **2.C.** Feature Analysis\n\n[Back to Table of Contents](#table-of-contents)","f3f09d4a":"**Findings**\n- None of the features show a significant difference between the classes in the target variable. Popular and unpopular songs show a similar distribution across all features.","d584ce94":"<a id=\"2-test-set\"><\/a>\n### **3.B.** Test Set\n\n[Back to Table of Contents](#table-of-contents)","e07e80b9":"<a id=\"dataset-overview\"><\/a>\n### **2.A.** Dataset Overview: structure and data\n\n[Back to Table of Contents](#table-of-contents)","65b21095":"This needs to be taken into account when splitting the training set into training and validation by stratifying on the target variable to preserve the proportions.","4c2f6874":"Both the train and test datasets contain the same columns describing *Audio Features*, except for **song_popularity** which is the target variable present only in the train dataset.\n\nThe following descriptions of each of these features are available on Spotify's API Dev Documentation: [Reference Guide](https:\/\/developer.spotify.com\/documentation\/web-api\/reference\/#\/operations\/get-several-audio-features).\n\n<br>\n\n> **id**\n> \n> _string_\n> \n> The Spotify ID for the track.\n\n<br>\n\n> **song_duration_ms**\n> \n> _integer_\n> \n> The duration of the track in milliseconds.\n\n<br>\n\n> **acousticness** \n> \n> _number (float)_\n> \n> A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.\n\n<br>\n\n> **danceability**\n> \n> _number (float)_\n> \n> Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\n\n<br>\n\n> **energy**\n> \n> _number (float)_\n> \n> Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n\n<br>\n\n> **instrumentalness**\n> \n> _number (float)_\n> \n> Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n\n<br>\n\n> **key**\n> \n> _integer_\n> \n> The key the track is in. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C\u266f\/D\u266d, 2 = D, and so on. If no key was detected, the value is -1.\n\n<br>\n\n> **liveness**\n> \n> _number (float)_\n> \n> Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.\n\n<br>\n\n> **loudness**\n> \n> _number (float)_\n> \n> The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typically range between -60 and 0 db.\n\n<br>\n\n> **audio_mode**\n> \n> _integer_\n> \n> Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n\n<br>\n\n> **speechiness**\n> \n> _number (float)_\n> \n> Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.\n\n<br>\n\n> **tempo**\n> \n> _number (float)_\n> \n> The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.\n\n<br>\n\n> **time_signature**\n> \n> _integer_\n> \n> An estimated time signature. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure). The time signature ranges from 3 to 7 indicating time signatures of \"3\/4\", to \"7\/4\".\n\n<br>\n\n> **audio_valence**\n> \n> _number (float)_\n> \n> A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).","33df037f":"<a id=\"import-libraries\"><\/a>\n### **1.A.** Import Libraries\n\n[Back to Table of Contents](#table-of-contents)","98047a86":"# Song Popularity Prediction","145936ce":"<a id=\"hyper-param-opt\"><\/a>\n### **4.B.** Hyper-Parameter Optimization\n\n[Back to Table of Contents](#table-of-contents)","b6d0e399":"<a id=\"pipeline-set-up\"><\/a>\n### **4.A.** Pipeline Set-Up\n\n[Back to Table of Contents](#table-of-contents)","6100f0a6":"<a id=\"feature-interactions\"><\/a>\n#### **2.C.d.** Feature Interactions\n\n[Back to Table of Contents](#table-of-contents)","f861e12a":"**Findings**\n- All 14 columns are numerical and most of them show a range of continuous values, except for three of them which appear to be categorical: *key, audio_mode, time_signature*.\n- 8 columns contain null values (*song_duration_ms*, *acousticness*, *danceability*, *energy*, *instrumentalness*, *key*, *liveness*, *loudness*)), most of them around 10%.\n- Many features are bounded between values around 0 and 1: *acousticness*, *danceability*, *energy*, *liveness*, *speechiness* and *audio_valence*.\n- Categorical features like *key*, *audio_mode* and *time_signature* are tightly related to musical concepts and could benefit from domain knowledge.","a5f6c9b9":"<a id=\"submission\"><\/a>\n## **5.** Submission\n\n[Back to Table of Contents](#table-of-contents)","e04c9826":"<a id=\"table-of-contents\"><\/a>\n## Table of Contents\n1. [Preparations](#preparations)\n    1. [Import Libraries](#import-libraries)\n    2. [Load Data](#load-data)\n    3. [Custom Functions](#custom-functions)\n2. [Exploratory Data Analysis](#-data-analysis)\n    1. [Dataset Overview: structure and data](#dataset-overview)\n        1. [Train Set](#1-train-set)\n        2. [Test Set](#1-test-set)\n    2. [Target Variable](#target-variable)\n    3. [Feature Analysis](#feature-analysis)\n        1. [Feature Distributions](#feature-distributions)\n            1. [Deep Dive: Instrumentalness](#deep-dive-instrumentalness)\n        2. [Target Impact](#target-impact)\n        3. [Correlation Analysis](#correlation-analysis)\n        4. [Feature Interactions](#feature-interactions)\n3. [Feature Engineering](#feature-engineering)\n    1. [Train Set](#2-train-set)\n    2. [Test Set](#2-test-set)\n4. [Modelling](#modelling)\n    1. [Pipeline Set-Up](#pipeline-set-up)\n    2. [Hyper-Parameter Optimization](#hyper-param-opt)\n    3. [Training with best parameters](#train-best-params)\n    4. [Feature Importance](#feature-importance)\n5. [Submission](#submission)","0533e8ca":"<a id=\"target-impact\"><\/a>\n#### **2.C.b.** Target Impact\n\n[Back to Table of Contents](#table-of-contents)"}}