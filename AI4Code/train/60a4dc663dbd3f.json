{"cell_type":{"e3aa8134":"code","0fa3d225":"code","4dc4f74a":"code","d0296d7c":"code","69639410":"code","ead425b2":"code","6e24390d":"code","99b6f7d6":"code","6ecec99c":"code","928442a1":"markdown","7d11e0f0":"markdown","ab546455":"markdown","70f3ad1a":"markdown","124b9d0d":"markdown","30490ff5":"markdown","7abed434":"markdown","814a44c9":"markdown","6bf73a84":"markdown"},"source":{"e3aa8134":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom itertools import cycle\nimport gc\n\nplt.style.use(\"ggplot\")\ncolor_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\ncolor_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])","0fa3d225":"!ls -GFlash ..\/input\/ubiquant-market-prediction\/","4dc4f74a":"train = pd.read_parquet('..\/input\/ubiquant-parquet\/train.parquet',\n               columns=['time_id','investment_id','target','f_1','f_2','f_3'])\ntest = pd.read_parquet('..\/input\/ubiquant-parquet\/example_test.parquet')\nss = pd.read_parquet('..\/input\/ubiquant-parquet\/example_sample_submission.parquet')","d0296d7c":"unique_time_ids = train['time_id'].nunique()\nunique_inv_ids = train['investment_id'].nunique()\n\nprint(f'There are {unique_inv_ids} unique investment ids and {unique_time_ids} unique time ids')","69639410":"example = pd.read_parquet('..\/input\/ubiquant-parquet\/investment_ids\/1.parquet')\nexample.head()","ead425b2":"for investment_id in range(5):\n    d = train.query('investment_id == @investment_id')\n    d.set_index('time_id')['target'] \\\n        .plot(figsize=(15, 5),\n              title=f'Investment_id {investment_id}',\n              color=next(color_cycle),\n              style='.-')\n    plt.show()","6e24390d":"example_id = train.query('investment_id == 529')\nsns.pairplot(example_id,\n             vars=['f_1','f_2','f_3','target'],\n            hue='time_id')","99b6f7d6":"# Take the last 50 known targets for each invesment_id and predict as the mean\ninv_pred_dict = train.groupby('investment_id') \\\n    .tail(50).groupby('investment_id')['target'].mean().to_dict()","6ecec99c":"import ubiquant\nenv = ubiquant.make_env()\niter_test = env.iter_test()\nfor (test_df, spdf) in iter_test:\n    spdf['target'] = test_df['investment_id'].map(inv_pred_dict)\n    env.predict(spdf)","928442a1":"## Read in a single invesment_id","7d11e0f0":"# Ubiquant Market Prediction\nTwitch Stream EDA.\n\n1. This notebook was create during a live coding session on twitch. follow for past and future broadcasts here: [here](https:\/\/www.twitch.tv\/medallionstallion_) ","ab546455":"# Example of Features for a Single Investment ID\n- We are only looking at 3 of the features.","70f3ad1a":"# Example Target for some investment ids","124b9d0d":"# The Data\nNote that the training data is roughly 18.55 Gb in size. This is too large to load into memory directly in kaggle notebook.\n\nSome things to note when exploring the entire dataset on a local machine:\n- There are 3579 unique `investment_id`s\n- There are 1211 unique `time_id`s - we are told these are not equally spaced and could be different in the test set.\n- The features columns are mostly normalized with a mean value close to 0 and standard deviation of ~1.\n","30490ff5":"# Make Some Dummy Predictions","7abed434":"# Reading the Parquet Version\nReading in csvs can be slow. Instead read from the parquet version here:\n- https:\/\/www.kaggle.com\/robikscube\/ubiquant-parquet","814a44c9":"# Train Data Fields\n\ntl;dr - we have time series data but don't know the exact time periods being provided. We also have investment_ids that are not unique. Everything is anonymized so it's not easy to create features.\n\n- `row_id` - A unique identifier for the row.\n- `time_id` - The ID code for the time the data was gathered. The time IDs are in order, but the real time between the time IDs is not constant and will likely be shorter for the final private test set than in the training set.\n- `investment_id` - The ID code for an investment. Not all investment have data in all time IDs.\n- `target` - The target.\n- `features` - [f_0:f_299] - Anonymized features generated from market data.","6bf73a84":"# How to Make Predictions"}}