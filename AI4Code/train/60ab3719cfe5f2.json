{"cell_type":{"ad1f5582":"code","b69b7473":"code","d13943cc":"code","c8e8ab74":"code","a857f720":"code","84378884":"code","446f8fb3":"code","023f57d6":"code","57f5fd79":"code","b9a28344":"markdown","cb3940f1":"markdown","d267e261":"markdown","118b14b8":"markdown","58ebd915":"markdown","4924d802":"markdown","e147c39f":"markdown"},"source":{"ad1f5582":"!pip install kaggle-environments --upgrade -q","b69b7473":"%%writefile ucb_decay.py\n\nimport numpy as np\n\ndecay = 0.97\ntotal_reward = 0\nbandit = None\n\ndef agent(observation, configuration):\n    global reward_sums, n_selections, total_reward, bandit\n    \n    n_bandits = configuration.banditCount\n\n    if observation.step == 0:\n        n_selections, reward_sums = np.full((2, n_bandits), 1e-32)\n    else:\n        reward_sums[bandit] += decay * (observation.reward - total_reward)\n        total_reward = observation.reward\n\n    avg_reward = reward_sums \/ n_selections    \n    delta_i = np.sqrt(2 * np.log(observation.step + 1) \/ n_selections)\n    bandit = int(np.argmax(avg_reward + delta_i))\n\n    n_selections[bandit] += 1\n\n    return bandit","d13943cc":"%%writefile bayesian_ucb.py\n\nimport numpy as np\nfrom scipy.stats import beta\n\npost_a, post_b, bandit = [None] * 3\ntotal_reward = 0\nc = 3\n\ndef agent(observation, configuration):\n    global total_reward, bandit, post_a, post_b, c\n\n    if observation.step == 0:\n        post_a, post_b = np.ones((2, configuration.banditCount))\n    else:\n        r = observation.reward - total_reward\n        total_reward = observation.reward\n        # Update Gaussian posterior\n        post_a[bandit] += r\n        post_b[bandit] += 1 - r\n    \n    bound = post_a \/ (post_a + post_b) + beta.std(post_a, post_b) * c\n    bandit = int(np.argmax(bound))\n    \n    return bandit","c8e8ab74":"from kaggle_environments import make\n\nenv = make(\"mab\", debug=True)","a857f720":"env.reset()\nenv.run([\"..\/input\/santa-2020\/submission.py\", \"ucb_decay.py\"])\nenv.render(mode=\"ipython\", width=800, height=500)","84378884":"env.reset()\nenv.run([\"..\/input\/santa-2020\/submission.py\", \"bayesian_ucb.py\"])\nenv.render(mode=\"ipython\", width=800, height=500)","446f8fb3":"def print_rounds(file1, file2, N=5):\n    env = make(\"mab\", debug=True)\n\n    for i in range(N):\n        env.run([file1, file2])\n        p1_score = env.steps[-1][0]['reward']\n        p2_score = env.steps[-1][1]['reward']\n        env.reset()\n        print(f\"Round {i+1}: {p1_score} - {p2_score}\")","023f57d6":"print('Default vs UCB+decay')\nprint_rounds(\"..\/input\/santa-2020\/submission.py\", \"ucb_decay.py\")","57f5fd79":"print('Default vs BayesianUCB')\nprint_rounds(\"..\/input\/santa-2020\/submission.py\", \"bayesian_ucb.py\")","b9a28344":"## Bayesian UCB\n\nBased on Lilian's blog post.","cb3940f1":"## Simulations","d267e261":"Default vs UCB+Decay:","118b14b8":"References:\n* [Santa 2020 starter](https:\/\/www.kaggle.com\/isaienkov\/santa-2020-starter\/): Re-used writefile magic command and make_env function for creating a simulation.  \n* [Lilian's blog post](https:\/\/lilianweng.github.io\/lil-log\/2018\/01\/23\/the-multi-armed-bandit-problem-and-its-solutions.html): Bayesian Implementation of UCB","58ebd915":"## 5-round comparison","4924d802":"## UCB with Decay\n\nThe classic UCB implementation (derived from the original implementation) with a decay factor.","e147c39f":"Default vs bayesian UCB:"}}