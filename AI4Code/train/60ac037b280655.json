{"cell_type":{"7270225b":"code","8bf14006":"code","07ce9c2e":"code","e74a906a":"code","0992ff0a":"code","e66dbcdc":"code","a145b899":"code","f1c13ee4":"code","145a5ca0":"code","a9e6093e":"code","b7aaecb6":"code","68528ea1":"code","9e6b4da9":"code","9d1f272e":"code","856a937c":"code","28ce105c":"code","680f9b17":"code","b7aa9723":"code","c8dd4e92":"code","47a08a16":"code","e6e5a5ef":"code","7339547a":"code","b7e17ec0":"code","1a48cac1":"code","98265f2a":"code","e49df16c":"code","88d79950":"code","9b17cbff":"code","ab7dd828":"code","ceebf19b":"code","1e8b33bd":"code","40ecfd3e":"code","489187cd":"code","ea6e396f":"code","b49b444d":"code","76cc6e3b":"code","ce4c48ff":"code","22353c06":"markdown","8a42b9fa":"markdown","6cc5d8b6":"markdown","d8785fae":"markdown","928cf838":"markdown","d7aaf4f1":"markdown"},"source":{"7270225b":"import warnings\nwarnings.filterwarnings(\"ignore\")","8bf14006":"import pandas as pd\ncolumns = ['Age','Workclass','fnlgwt','Education','Education Num','Marital Status','Occupation',\n           'Relationship','Race','Sex','Capital Gain','Capital Loss','Hours\/Week','Native Country','Target']\norig_data = pd.read_csv(\"..\/input\/adult-training.csv\", \n                        header=None, na_values='?', sep=', ', engine='python', names=columns)\norig_data.head()","07ce9c2e":"test_data = pd.read_csv(\"..\/input\/adult-test.csv\", \n                        header = None, skiprows=1, na_values='?', sep=', ', engine='python', names=columns)\ntest_data.head()","e74a906a":"data = orig_data.copy()\ndata.shape","0992ff0a":"data.info()","e66dbcdc":"data.describe().T","a145b899":"import matplotlib.pyplot as plt\nimport numpy as np\nfor column in data.columns:\n    if data.dtypes[column] == np.object:\n        data[column].value_counts().plot(kind=\"bar\", title=column)\n    else:\n        data[column].hist()\n        plt.title(column)\n    plt.show()","f1c13ee4":"import matplotlib.pyplot as plt\nimport missingno as msno\nmsno.bar(data)\nplt.show()","145a5ca0":"modes = data.mode().iloc[0]\ndata.fillna(modes, inplace=True)\n\n#Verifying\nmsno.bar(data)\nplt.show()","a9e6093e":"cols_to_encode = [data.columns[i] for i in range(data.shape[1]) if data.dtypes[i] == np.object]\ncols_to_encode","b7aaecb6":"data.groupby('Education').nunique()['Education Num']","68528ea1":"data.drop('Education', axis = 1, inplace = True)\ncols_to_encode.remove('Education')\ndata.head()","9e6b4da9":"data = pd.get_dummies(data, drop_first = True)\ndata.head()","9d1f272e":"from sklearn.model_selection import KFold, GridSearchCV, cross_val_score, cross_val_predict\ncv = KFold(5, random_state = 1)\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n                             classification_report, confusion_matrix)\nModel = []\nAccuracy = []\nPrecision = []\nRecall = []\nF1 = []\nAUC = []","856a937c":"x = data[data.columns[:-1]]\ny = data[data.columns[-1]]\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(x)\nx_scaled = scaler.transform(x)","28ce105c":"from sklearn.dummy import DummyClassifier\nclf = DummyClassifier(strategy = 'most_frequent',random_state = 1)\nModel.append(\"Dummy\")\nAccuracy.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='accuracy').mean())\nPrecision.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='precision').mean())\nRecall.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='recall').mean())\nF1.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='f1').mean())\nAUC.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='roc_auc').mean())","680f9b17":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nparam_grid = {'C': [0.1, 0.4, 0.7, 1, 4, 7, 10]}\ngrid1 = GridSearchCV(lr, param_grid, cv=cv).fit(x_scaled, y)\nprint(\"Grid Logistic Regression: \", grid1.best_score_, grid1.best_params_)","b7aa9723":"#Appending results from the best of all above models\nfrom sklearn.linear_model import LogisticRegression\nclf = grid1.best_estimator_\nModel.append(\"Logistic Regression\")\nAccuracy.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='accuracy').mean())\nPrecision.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='precision').mean())\nRecall.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='recall').mean())\nF1.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='f1').mean())\nAUC.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='roc_auc').mean())","c8dd4e92":"from sklearn.svm import SVC\nsvc = SVC()\nparam_grid = {'C': [0.1, 0.4, 0.7, 1, 4, 7, 10],\n              'kernel': ['linear', 'rbf']}\ngrid1 = GridSearchCV(svc, param_grid, cv=cv).fit(x_scaled, y)\nprint(\"Grid SVC: \", grid1.best_score_, grid1.best_params_)","47a08a16":"#Appending results from the best of all above models\nfrom sklearn.svm import SVC\nclf = grid1.best_estimator_\nModel.append(\"SVC\")\nAccuracy.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='accuracy').mean())\nPrecision.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='precision').mean())\nRecall.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='recall').mean())\nF1.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='f1').mean())\nAUC.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='roc_auc').mean())","e6e5a5ef":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier()\nparam_grid = {'max_depth': [10, 40, 70, 100, 400, 700, None],\n              'criterion': ['gini','entropy']}\ngrid1 = GridSearchCV(dtc, param_grid, cv=cv).fit(x_scaled, y)\nprint(\"Grid DTC: \", grid1.best_score_, grid1.best_params_)","7339547a":"#Appending results from the best of all above models\nfrom sklearn.tree import DecisionTreeClassifier\nclf = grid1.best_estimator_\nModel.append(\"Decision Tree Classifier\")\nAccuracy.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='accuracy').mean())\nPrecision.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='precision').mean())\nRecall.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='recall').mean())\nF1.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='f1').mean())\nAUC.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='roc_auc').mean())","b7e17ec0":"#finding the optimum number of trees first in Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=1)\nparam_grid = {'n_estimators': [10,40,70,100,400,700,1000]}\ngrid1 = GridSearchCV(rfc, param_grid, cv=cv).fit(x_scaled, y)\nprint(\"Grid RFC: \", grid1.best_score_, grid1.best_params_)","1a48cac1":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=1)\nparam_grid = {'n_estimators': [250,300,350,400,450,500,550]}\ngrid2 = GridSearchCV(rfc, param_grid, cv=cv).fit(x_scaled, y)\nprint(\"Grid RFC: \", grid2.best_score_, grid2.best_params_)","98265f2a":"from sklearn.ensemble import RandomForestClassifier\nrfc = grid2.best_estimator_\nparam_grid = {'criterion': ['gini','entropy'],\n              'max_depth': [5, 10, 15, 20, 25, 30, None]}\ngrid3 = GridSearchCV(rfc, param_grid, cv=cv).fit(x_scaled, y)\nprint(\"Grid RFC: \", grid3.best_score_, grid3.best_params_)","e49df16c":"#Appending results from the best of all above models\nfrom sklearn.ensemble import RandomForestClassifier\nclf = grid3.best_estimator_\nModel.append(\"Random Forest Classifier\")\nAccuracy.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='accuracy').mean())\nPrecision.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='precision').mean())\nRecall.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='recall').mean())\nF1.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='f1').mean())\nAUC.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='roc_auc').mean())","88d79950":"from sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(random_state=1)\nparam_grid = {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n              'activation': ['tanh', 'relu'],\n              'solver': ['sgd', 'adam'],\n              'alpha': [0.0001, 0.05],\n              'learning_rate': ['constant','adaptive']}\ngrid1 = GridSearchCV(mlp, param_grid, cv=cv).fit(x_scaled, y)\nprint(\"Grid MLP: \", grid1.best_score_, grid1.best_params_)","9b17cbff":"#Appending results from the best of all above models\nfrom sklearn.neural_network import MLPClassifier\nclf = grid1.best_estimator_\nModel.append(\"MLP Classifier\")\nAccuracy.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='accuracy').mean())\nPrecision.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='precision').mean())\nRecall.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='recall').mean())\nF1.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='f1').mean())\nAUC.append(cross_val_score(clf, x_scaled, y, cv=cv, scoring='roc_auc').mean())","ab7dd828":"evaluation = pd.DataFrame({'Model': Model, \n                           'Accuracy': Accuracy, \n                           'Precision': Precision, \n                           'Recall': Recall,\n                           'F1 Score': F1, \n                           'AUC': AUC})\nprint(\"FOLLOWING ARE THE TRAINING SCORES: \")\nevaluation","ceebf19b":"#applying model on test set\ntest_data.drop('Education', axis = 1, inplace = True)\ntest_data.shape","1e8b33bd":"#imputing missing test data values with same values as train\ntest_data.fillna(modes, inplace=True) \ntest_data.shape","40ecfd3e":"test_data = pd.get_dummies(test_data, drop_first = True)\ntest_data.shape","489187cd":"#since get_dummies gave number of columns mismatch\nmissing_cols = set(data.columns) - set(test_data.columns )\nfor col in missing_cols:\n    test_data[col] = 0\ntest_data.head()","ea6e396f":"#Because of the dot (.) in target value in test data, new column 'Target_ >50K' is added from training data\ntest_data['Target_>50K'] = test_data['Target_>50K.']\ntest_data.drop('Target_>50K.', axis = 1, inplace = True)","b49b444d":"#to ensure same column placement as train data\ntest_data = test_data[data.columns]\ntest_data.head()","76cc6e3b":"x_test = scaler.transform(test_data[test_data.columns[:-1]])\ny_test = test_data[test_data.columns[-1]].values\nx_test.shape","ce4c48ff":"clf = RandomForestClassifier(random_state = 1, criterion = 'gini', \n                             max_depth = 20, n_estimators = 400)\nprint(\"Test Accuracy:\",cross_val_score(clf, x_test, y_test, cv=cv, scoring='accuracy').mean())\nprint(\"Test Precision:\",cross_val_score(clf, x_test, y_test, cv=cv, scoring='precision').mean())\nprint(\"Test Recall:\",cross_val_score(clf, x_test, y_test, cv=cv, scoring='recall').mean())\nprint(\"Test F1 Score:\",cross_val_score(clf, x_test, y_test, cv=cv, scoring='f1').mean())\nprint(\"Test AUC:\",cross_val_score(clf, x_test, y_test, cv=cv, scoring='roc_auc').mean())","22353c06":"### HIGHEST ACCURACY 86.46%\n\n### So the best model is RandomForestClassifier(criterion = 'gini', max_depth = 20, n_estimators = 700)","8a42b9fa":"###### Note: Target variable is imbalanced","6cc5d8b6":"###### There are very little values missing in the data. Since the three columns where there are missing values are categorical, looking at their distribution plots we can go for Mode value imputation.","d8785fae":"###### Rather than splitting to validation set, we will perform cross validation in all our training models.","928cf838":"###### This implies Education and Education Num are the same; Education is already encoded","d7aaf4f1":"###### We can now start building some models."}}