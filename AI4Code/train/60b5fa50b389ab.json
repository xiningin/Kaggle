{"cell_type":{"df17a009":"code","49a4d7a3":"code","8f422633":"code","e7e541e1":"code","a01afeba":"code","40b7fea5":"code","95de7114":"code","d4df94a3":"code","5b5d8ab8":"code","01bccbe5":"markdown","12b81dfe":"markdown","1ff471dd":"markdown","a8f8c932":"markdown","dc63cfff":"markdown","c1df1808":"markdown","0771e7ea":"markdown","39decdf8":"markdown","bfe0e824":"markdown","56101b6a":"markdown","6febfcda":"markdown"},"source":{"df17a009":"import os\nimport io\nimport urllib.request as request\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\n#Khai b\u00e1o params\nIRIS_TRAIN = 'iris_training.csv'\nIRIS_TRAIN_PATH = 'https:\/\/raw.githubusercontent.com\/phamdinhkhanh\/Tensorflow\/master\/iris_training.csv'\nIRIS_TEST = 'iris_testing.csv'\nIRIS_TEST_PATH  = 'https:\/\/raw.githubusercontent.com\/phamdinhkhanh\/Tensorflow\/master\/iris_testing.csv'\nCOLUMNS = ['SepWid', 'SepLen', 'PenWid', 'PenLen', 'Species']\nBATCH_SIZE = 100\nN_STEPS = 1000\nLEARNING_RATE = 0.2\n\ndef get_data(url, filename, is_get_train = True):\n    if not os.path.exists(filename):\n        raw = request.urlopen(url).read().decode('utf-8')\n        with io.open(filename, 'w') as f:\n            f.write(raw)\n            \n    data = pd.read_csv(filename, header = 0, names = COLUMNS, encoding = 'utf-8')\n    features, labels = data, data.pop('Species')\n    \n    #T\u1ea1o Class Dataset trong tensorflow\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n    if is_get_train: \n        dataset = dataset.shuffle(1000).repeat().batch(batch_size = BATCH_SIZE)\n        return dataset.make_one_shot_iterator().get_next()\n    else:\n        return dataset.batch(batch_size = BATCH_SIZE)\n\nget_data(IRIS_TRAIN_PATH, IRIS_TRAIN, is_get_train = True)\nget_data(IRIS_TEST_PATH, IRIS_TEST,  is_get_train = False)","49a4d7a3":"with tf.Session() as sess:\n    test = get_data(IRIS_TEST_PATH, IRIS_TEST, is_get_train = False)\n    print(sess.run(test.make_one_shot_iterator().get_next()))","8f422633":"def my_model(features, labels, mode, params):\n   \n    # 0. X\u00e2y d\u1ef1ng m\u1ea1ng n\u01a1 ron\n    # Kh\u1edfi t\u1ea1o input_layer. H\u00e0m input_layer s\u1ebd map d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o l\u00e0 features v\u1edbi c\u00e1c estimators th\u00f4ng qua params['features_columns']\n    nn = tf.feature_column.input_layer(features, params['feature_columns'])\n    # X\u00e2y d\u1ef1ng c\u00e1c hidden layer ti\u1ebfp theo\n    for n_units in params['hidden_units']:\n        nn = tf.layers.dense(nn, n_units, activation = tf.nn.relu)\n    # H\u00e0m logits d\u1ef1 b\u00e1o x\u00e1c xu\u1ea5t c\u00e1c classes (ch\u00ednh l\u00e0 output layer)\n    logits = tf.layers.dense(nn, params['n_classes'], activation = tf.nn.softmax)\n    if labels is not None:\n        # H\u00e0m loss function\n        loss = tf.losses.sparse_softmax_cross_entropy(\n            labels = labels, \n            logits = logits)\n    \n    #---------------------------------------------------------------------------------\n    # 1. Hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        # H\u00e0m t\u1ed1i \u01b0u h\u00f3a ki\u1ec3m so\u00e1t thu\u1eadt to\u00e1n gradient descent:\n        optimizer = tf.train.AdagradOptimizer(learning_rate = LEARNING_RATE)\n        # H\u00e0m k\u00edch ho\u1ea1t qu\u00e1 tr\u00ecnh training m\u00f4 h\u00ecnh:\n        train_op = optimizer.minimize(\n                   loss, \n                   global_step = tf.train.get_global_step())\n        # Estimator tr\u1ea3 v\u1ec1 \n        return tf.estimator.EstimatorSpec(\n            mode = mode, \n            loss = loss, \n            train_op = train_op)\n    \n    #---------------------------------------------------------------------------------\n    # 2. \u0110\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh\n    elif mode == tf.estimator.ModeKeys.EVAL:\n        # L\u1edbp \u0111\u01b0\u1ee3c d\u1ef1 b\u00e1o \n        prediction_classes = tf.argmax(logits, 1)\n        # M\u1ee9c \u0111\u1ed9 ch\u00ednh x\u00e1c \n        accuracy = tf.metrics.accuracy(\n            labels = labels,\n            predictions = prediction_classes\n        )\n        # Estimator tr\u1ea3 v\u1ec1\n        return tf.estimator.EstimatorSpec(\n            mode = tf.estimator.ModeKeys.EVAL,\n            loss = loss,\n            eval_metric_ops = {'accuracy': accuracy}\n        )\n    #----------------------------------------------------------------------------------\n    # 3. D\u1ef1 b\u00e1o m\u00f4 h\u00ecnh\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        #T\u00ednh class d\u1ef1 b\u00e1o.\n        predicted_class = tf.argmax(logits, 1)\n        # Estimator tr\u1ea3 v\u1ec1\n        return tf.estimator.EstimatorSpec(\n            mode = mode, \n            predictions = {\n                'class_id': predicted_class,\n                'logits': logits,\n                'probabilities': tf.nn.softmax(logits)\n            })","e7e541e1":"my_features = []\nfor column in COLUMNS[:-1]:\n    my_features.append(tf.feature_column.numeric_column(column))\nmy_features","a01afeba":"classifier = tf.estimator.Estimator(\n    model_fn = my_model,\n    params = {\n        'feature_columns': my_features, # List t\u00ean c\u00e1c feature s\u1eed d\u1ee5ng \u0111\u1ec3 map d\u1eef li\u1ec7u t\u1eeb Dataset v\u1edbi c\u00e1c estimator\n        'hidden_units':[10, 20, 10], # S\u1ed1 \u0111\u01a1n v\u1ecb m\u1ed7i layer\n        'n_classes': 3 # S\u1ed1 l\u01b0\u1ee3ng nh\u00f3m c\u1ea7n ph\u00e2n lo\u1ea1i\n    }\n)","40b7fea5":"classifier.train(\n    input_fn = lambda:get_data(IRIS_TRAIN_PATH, IRIS_TRAIN),\n    steps = N_STEPS\n)","95de7114":"classifier.evaluate(\n    input_fn = lambda:get_data(IRIS_TEST_PATH, IRIS_TEST, is_get_train = False)\n)","d4df94a3":"classifier.evaluate(\n    input_fn = lambda:get_data(IRIS_TRAIN_PATH, IRIS_TRAIN, is_get_train = False)\n)","5b5d8ab8":"expected = ['Setosa', 'Versicolor', 'Virginica']\npredict_x = {\n    'SepLen': [3.1, 5.9, 6.9],\n    'SepWid': [2.3, 3.0, 3.1],\n    'PenLen': [1.7, 2.2, 5.4],\n    'PenWid': [0.5, 1.5, 2.1],\n}\n\ndef input_fn(features, labels, batch_size):\n    \"\"\"An input function for evaluation or prediction\"\"\"\n    features=dict(features)\n    if labels is None:\n        # No labels, use only features.\n        inputs = features\n    else:\n        inputs = (features, labels)\n\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n\n    # Batch the examples\n    assert batch_size is not None, \"batch_size must not be None\"\n    dataset = dataset.batch(batch_size)\n\n    # Return the dataset.\n    return dataset\n\ndef pred(input_features):\n    predictions = classifier.predict(\n        input_fn=lambda:input_fn(input_features, labels = None, batch_size = BATCH_SIZE))\n    template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n    for pred in list(predictions):\n        class_id = pred['class_id']\n        exp = expected[class_id]\n        prob = pred['probabilities'][class_id]*100\n        print(template.format(class_id, prob, exp))\n\npred(predict_x)","01bccbe5":"# 6. D\u1ef1 b\u00e1o quan s\u00e1t m\u1edbi.\nGi\u1ea3 s\u1eed b\u00ean d\u01b0\u1edbi ch\u00fang ta c\u00f3 3 quan s\u00e1t v\u1ec1 k\u00edch th\u01b0\u1edbc d\u00e0i, r\u1ed9ng c\u1ee7a c\u00e1nh hoa v\u00e0 \u0111\u00e0i hoa. Ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng h\u00e0m predict c\u1ee7a object classifier \u0111\u1ec3 d\u1ef1 b\u00e1o nh\u00e3n v\u00e0 x\u00e1c xu\u1ea5t c\u1ee7a 3 quan s\u00e1t m\u1edbi n\u00e0y. L\u01b0u \u00fd h\u00e0m predict, train, evaluate \u0111\u1ec1u c\u00f3 chung m\u1ed9t \u0111\u1eb7c \u0111i\u1ec3m \u0111\u00f3 l\u00e0 c\u00f3 m\u1ed9t tham s\u1ed1 l\u00e0 h\u00e0m s\u1ed1 tr\u1ea3 v\u1ec1 Dataset c\u1ee7a tensorflow ho\u1eb7c Iterator Dataset.","12b81dfe":"# 1. X\u00e2y d\u1ef1ng m\u1ea1ng n\u01a1 ron tr\u00ean tensorflow\n\nTrong b\u00e0i [gi\u1edbi thi\u1ec7u tensorflow](https:\/\/www.kaggle.com\/phamdinhkhanh\/tensorflow-turtorial?scriptVersionId=6702388) ch\u00fang ta \u0111\u00e3 h\u1ecdc \u0111\u01b0\u1ee3c c\u00e1ch t\u1ea1o ra m\u1ed9t m\u1ea1ng n\u01a1 ron theo ph\u01b0\u01a1ng ph\u00e1p code b\u1eadc th\u1ea5p. Qu\u00e1 tr\u00ecnh x\u00e2y d\u1ef1ng c\u00e1c layer ch\u00fang ta ph\u1ea3i x\u00e2y d\u1ef1ng nh\u1eefng b\u01b0\u1edbc c\u01a1 b\u1ea3n nh\u1ea5t nh\u01b0 kh\u1edfi t\u1ea1o h\u1ec7 s\u1ed1, ph\u00e9p nh\u00e2n ma tr\u1eadn chuy\u1ec3n h\u00f3a layer, t\u00ednh to\u00e1n x\u00e1c xu\u1ea5t \u0111\u1ea7u ra, x\u00e2y d\u1ef1ng h\u00e0m loss function,.... \u0110i\u1ec1u \u0111\u00f3 g\u00e2y ra kh\u00f3 kh\u0103n cho c\u00e1c data scientist r\u1ea5t nhi\u1ec1u v\u00ec qu\u00e1 tr\u00ecnh kh\u1edfi t\u1ea1o m\u1ed9t m\u1ea1ng n\u01a1 ron n\u00f4ng l\u00e0 kh\u1ea3 thi nh\u01b0ng nh\u1eefng m\u1ea1ng n\u01a1 ron s\u00e2u v\u1edbi v\u00e0i tr\u0103m ng\u00e0n t\u1ea7ng \u1ea9n vi\u1ec7c code chay m\u1ed7i layer l\u00e0 b\u1ea5t kh\u1ea3 thi. Ch\u00ednh v\u00ec th\u1ebf ch\u00fang ta c\u1ea7n s\u1ef1 h\u1ed7 tr\u1ee3 c\u1ee7a c\u00e1c th\u01b0 vi\u1ec7n b\u1eadc cao \u0111\u1ec3 kh\u1edfi t\u1ea1o c\u00e1c layer v\u00e0 hu\u1ea5n luy\u1ec7n, \u0111\u00e1nh gi\u00e1 v\u00e0 d\u1ef1 b\u00e1o m\u00f4 h\u00ecnh m\u1ed9t c\u00e1ch d\u1ec5 d\u00e0ng h\u01a1n. Th\u00f4ng qua b\u00e0i vi\u1ebft n\u00e0y ch\u00fang ta s\u1ebd bi\u1ebft c\u00e1ch kh\u1edfi t\u1ea1o m\u1ed9t m\u1ea1ng n\u01a1 ron nh\u01b0 th\u1ebf th\u00f4ng qua m\u1ed9t class r\u1ea5t to\u00e0n n\u0103ng. \u0110\u00f3 ch\u00ednh l\u00e0 Estimator.\nB\u00ean d\u01b0\u1edbi l\u00e0 c\u00e1c b\u01b0\u1edbc x\u00e2y d\u1ef1ng m\u1ea1ng n\u01a1 ron.\n\n# 2. H\u00e0m x\u1eed l\u00fd d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o.\n\n\u1ede h\u00e0m n\u00e0y ta s\u1ebd tr\u1ea3 v\u1ec1 m\u1ed9t Dataset ho\u1eb7c m\u1ed9t Iterator Dataset c\u1ee7a tensorflow t\u1eeb \u0111\u01b0\u1eddng link v\u00e0 t\u00ean file d\u1eef li\u1ec7u c\u1ee7a t\u1eadp train v\u00e0 test. \n\n* **Dataset** s\u1ebd c\u00f3 t\u00e1c d\u1ee5ng qu\u1ea3n l\u00fd qu\u00e1 tr\u00ecnh input d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o g\u1ed3m c\u00e1c th\u00e0nh ph\u1ea7n l\u00e0 m\u1ed9t ho\u1eb7c nhi\u1ec1u Tensors ch\u1eb3ng h\u1ea1n nh\u01b0: K\u00edch th\u01b0\u1edbc batch_size, s\u1ed1 l\u1ea7n shuffle m\u1eabu, l\u1ea5y m\u1eabu t\u00e1i l\u1eb7p hay kh\u00f4ng?.... \n* **Iterator Dataset** c\u0169ng g\u1ea7n gi\u1ed1ng nh\u01b0 enumerate cho ph\u00e9p ch\u00fang ta truy c\u1eadp v\u00e0o c\u00e1c th\u00e0nh ph\u1ea7n trong Dataset \u0111\u1ec3 th\u1ef1c hi\u1ec7n c\u00e1c v\u00f2ng l\u1eb7p khi hu\u1ea5n luy\u1ec7n qua c\u00e1c batches kh\u00e1c nhau \u0111\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh qua c\u00e1c t\u1eadp d\u1eef li\u1ec7u kh\u00e1c nhau.\n\nTrong tr\u01b0\u1eddng h\u1ee3p t\u1eadp d\u1eef li\u1ec7u l\u00e0 t\u1eadp train ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng Iterator Dataset do qu\u00e1 tr\u00ecnh hu\u1ea5n luy\u1ec7n v\u00e0 \u0111\u00e1nh gi\u00e1 thu\u1eadt to\u00e1n gradient descent c\u1ea7n th\u1ef1c hi\u1ec7n tr\u00ean nhi\u1ec1u batches kh\u00e1c nhau. T\u1eadp d\u1eef li\u1ec7u test l\u00e0 m\u1ed9t t\u1eadp d\u1eef li\u1ec7u c\u1ed1 \u0111\u1ecbnh s\u1eed d\u1ee5ng cho d\u1ef1 b\u00e1o n\u00ean kh\u00f4ng c\u1ea7n ph\u1ea3i l\u00e0 m\u1ed9t Iterator Dataset.","1ff471dd":"H\u00e0m tf.feature_column.numeric_column() s\u1ebd t\u1ea1o ra c\u00e1c ph\u1ea7n t\u1eed \u0111\u1ecbnh d\u1ea1ng numeric trong list danh s\u00e1ch features. X\u00e2y d\u1ef1ng object classifier thu\u1ed9c class Estimator s\u1eed d\u1ee5ng \u0111\u1ec3 hu\u1ea5n luy\u1ec7n, \u0111\u00e1nh gi\u00e1 v\u00e0 d\u1ef1 b\u00e1o.","a8f8c932":"\u0110\u1ecdc d\u1eef li\u1ec7u t\u1eeb Dataset c\u1ee7a tensorflow th\u00f4ng qua m\u1ed9t session.","dc63cfff":"V\u1edbi m\u1ed9t m\u1ea1ng n\u01a1 ron ch\u1ec9 3 t\u1ea7ng \u1ea9n k\u1ebft qu\u1ea3 ch\u00ednh x\u00e1c \u0111\u00e3 > 95%. \u0110\u00e2y l\u00e0 m\u1ed9t k\u1ebft qu\u1ea3 kh\u00e1 t\u1ed1t m\u00e0 nh\u1eefng m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y kh\u00e1c nh\u01b0 `H\u1ed3i qui Logistic, kNN, SVM, Random forest, Decesion Tree,...` kh\u00f3 \u0111\u1ea1t \u0111\u01b0\u1ee3c. N\u1ebfu b\u1ea1n \u0111\u1ecdc kh\u00f4ng tin \u0111i\u1ec1u n\u00e0y c\u00f3 th\u1ec3 search th\u00f4ng tin k\u1ebft qu\u1ea3 c\u00e1c thu\u1eadt to\u00e1n h\u1ecdc m\u00e1y \u00e1p d\u1ee5ng tr\u00ean b\u1ed9 d\u1eef li\u1ec7u iris \u0111\u1ec3 ki\u1ec3m ch\u1ee9ng.","c1df1808":"# 5. \u0110\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh.\nTa s\u1ebd \u0111\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh l\u1ea7n l\u01b0\u1ee3t tr\u00ean t\u1eadp train v\u00e0 t\u1eadp test. H\u00e0m \u0111\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh s\u1ebd tr\u1ea3 v\u1ec1 m\u1ee9c \u0111\u1ed9 d\u1ef1 b\u00e1o ch\u00ednh x\u00e1c c\u1ee7a m\u1ea1ng n\u01a1 ron tr\u00ean t\u1eebng t\u1eadp d\u1eef li\u1ec7u. Tham s\u1ed1 \u0111\u1ea7u v\u00e0o input_fn l\u00e0 m\u1ed9t h\u00e0m tr\u1ea3 v\u1ec1 m\u1ed9t Dataset ho\u1eb7c Iterator Dataset c\u1ee7a features v\u00e0 labels.","0771e7ea":"# 7. T\u00e0i li\u1ec7u tham kh\u1ea3o.\n\n1. [Estimator - tensorflow](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/estimator)\n2. [Dataset - tensorflow](https:\/\/www.tensorflow.org\/guide\/datasets)\n3. [Layer - tensorflow](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/layers)\n4. [H\u01b0\u1edbng d\u1eabn tensorflow - Pham Dinh Khanh](https:\/\/www.kaggle.com\/phamdinhkhanh\/tensorflow-turtorial?scriptVersionId=6702388)\n5. [Qu\u00e1 tr\u00ecnh lan truy\u1ec1n ng\u01b0\u1ee3c v\u00e0 lan truy\u1ec1n thu\u1eadn - Blog Machine learning c\u01a1 b\u1ea3n](https:\/\/machinelearningcoban.com\/2017\/02\/24\/mlp\/)\n6. [C\u00e1c thu\u1eadt to\u00e1n Gradient Descent - tensorflow](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/train\/Optimizer)\n7. [Lo\u1ea1t b\u00e0i v\u1ec1 tensorflow - Nguy\u1ec5n V\u0103n Hi\u1ebfu](https:\/\/nguyenvanhieu.vn\/xay-dung-mo-hinh-neural-network\/)","39decdf8":"Ch\u00fang ta t\u01b0\u1edfng t\u01b0\u1ee3ng Dataset c\u1ee7a tensorflow nh\u01b0 m\u1ed9t kho ch\u1ee9a nguy\u00ean li\u1ec7u trong \u0111\u00f3 g\u1ed3m 2 nguy\u00ean li\u1ec7u ch\u00ednh l\u00e0 c\u00e1c features v\u00e0 labels. C\u00e1c estimator trong m\u1ea1ng n\u01a1 ron nh\u01b0 m\u1ed9t \u0111\u01b0\u1eddng \u1ed1ng d\u1eabn nguy\u00ean li\u1ec7u. \u0110\u1ec3 n\u1ed1i \u0111\u00fang lo\u1ea1i nguy\u00ean li\u1ec7u v\u1edbi \u0111\u00fang \u0111\u01b0\u1eddng \u1ed1ng ch\u00fang ta c\u1ea7n m\u1ed9t danh s\u00e1ch c\u00e1c features \u0111\u1ec3 map gi\u1eefa Dataset v\u00e0 c\u00e1c estimator trong m\u1ea1ng n\u01a1 ron trong input_layer. ","bfe0e824":"# 3. X\u00e2y d\u1ef1ng m\u1ea1ng n\u01a1 ron.\n\nTa s\u1ebd x\u00e2y d\u1ef1ng 1 h\u00e0m `my_model` c\u00f3 3 ch\u1ee9c n\u0103ng g\u1ed3m: `hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh, \u0111\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh v\u00e0 d\u1ef1 b\u00e1o m\u00f4 h\u00ecnh`. Class \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 kh\u1edfi t\u1ea1o m\u00f4 h\u00ecnh n\u00e0y l\u00e0 `tf.estimator.Estimator`.","56101b6a":"Ta nh\u1eadn th\u1ea5y classifier s\u1eed d\u1ee5ng model function l\u00e0 my_model \u0111\u1ec3 x\u00e2y d\u1ef1ng m\u1ea1ng n\u01a1 ron, hu\u1ea5n luy\u1ec7n, \u0111\u00e1nh gi\u00e1 v\u00e0 d\u1ef1 b\u00e1o m\u00f4 h\u00ecnh. Tham s\u1ed1 params c\u1ee7a h\u00e0m Estimator s\u1ebd \u0111\u01b0\u1ee3c truy\u1ec1n v\u00e0o trong h\u00e0m my_model \u0111\u1ec3 khai th\u00e1c c\u00e1c th\u00f4ng s\u1ed1 bao g\u1ed3m: \n* feature_columns: Danh s\u00e1ch c\u00e1c bi\u1ebfn d\u1ef1 b\u00e1o \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 map d\u1eef li\u1ec7u t\u1eeb Dataset v\u1edbi features \u0111\u1ea7u v\u00e0o c\u1ee7a m\u00f4 h\u00ecnh.\n* hidden_units: S\u1ed1 l\u01b0\u1ee3ng units m\u1ed7i t\u1ea7ng \u1ea9n. M\u1ea1ng n\u01a1 ron c\u1ee7a ch\u00fang ta s\u1ebd \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf g\u1ed3m 3 t\u1ea7ng \u1ea9n v\u1edbi s\u1ed1 units l\u1ea7n l\u01b0\u1ee3t l\u00e0 10, 20, 10.\n* n_classes: S\u1ed1 nh\u00f3m ph\u00e2n lo\u1ea1i. \nTi\u1ebfp theo ch\u00fang ta s\u1ebd hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh\n\n# 4. Hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh.\n\nH\u00e0m hu\u1ea5n luy\u1ec7n s\u1ebd c\u1ea7n truy\u1ec1n v\u00e0o 2 tham s\u1ed1 ch\u00ednh \u0111\u00f3 l\u00e0 h\u00e0m kh\u1edfi t\u1ea1o Dataset \u0111\u1ec3 truy\u1ec1n d\u1eef li\u1ec7u v\u00e0 s\u1ed1 b\u01b0\u1edbc h\u1ecdc t\u1eadp.","6febfcda":"\u0110\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh tr\u00ean t\u1eadp train"}}