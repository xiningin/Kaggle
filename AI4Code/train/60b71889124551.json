{"cell_type":{"9e4b7d61":"code","f6c07144":"code","90f21c3c":"code","76028654":"code","51052dd8":"code","bab8f185":"code","c239e4c4":"code","933d6eeb":"code","4ee7b8cf":"code","6e2d2481":"code","2188c782":"code","cab72a33":"code","12c2b559":"code","8c026863":"code","928d4f97":"code","067b4881":"code","e7a9ca15":"code","f584f8f9":"code","bd9aa4aa":"code","3e4eeb25":"markdown","3465882d":"markdown","cbe99c67":"markdown"},"source":{"9e4b7d61":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))","f6c07144":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression as LR\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV","90f21c3c":"import warnings\nwarnings.filterwarnings(\"ignore\")","76028654":"# Relative Strength Index\n# Avg(PriceUp)\/(Avg(PriceUP)+Avg(PriceDown)*100\n# Where: PriceUp(t)=1*(Price(t)-Price(t-1)){Price(t)- Price(t-1)>0};\n#        PriceDown(t)=-1*(Price(t)-Price(t-1)){Price(t)- Price(t-1)<0};\n\ndef rsi(values):\n    up = values[values>0].mean()\n    down = -1*values[values<0].mean()\n    return 100 * up \/ (up + down)\n","51052dd8":"def bbands(price, length=30, numsd=2):\n    \"\"\" returns average, upper band, and lower band\"\"\"\n    #ave = pd.stats.moments.rolling_mean(price,length)\n    ave = price.rolling(window = length, center = False).mean()\n    #sd = pd.stats.moments.rolling_std(price,length)\n    sd = price.rolling(window = length, center = False).std()\n    upband = ave + (sd*numsd)\n    dnband = ave - (sd*numsd)\n    return np.round(ave,3), np.round(upband,3), np.round(dnband,3)","bab8f185":"def aroon(df, tf=25):\n    aroonup = []\n    aroondown = []\n    x = tf\n    while x< len(df):\n        aroon_up = ((df['high'][x-tf:x].tolist().index(max(df['high'][x-tf:x])))\/float(tf))*100\n        aroon_down = ((df['low'][x-tf:x].tolist().index(min(df['low'][x-tf:x])))\/float(tf))*100\n        aroonup.append(aroon_up)\n        aroondown.append(aroon_down)\n        x+=1\n    return aroonup, aroondown","c239e4c4":"def abands(df):\n    #df['AB_Middle_Band'] = pd.rolling_mean(df['Close'], 20)\n    df['AB_Middle_Band'] = df['close'].rolling(window = 20, center=False).mean()\n    # High * ( 1 + 4 * (High - Low) \/ (High + Low))\n    df['aupband'] = df['high'] * (1 + 4 * (df['high']-df['low'])\/(df['high']+df['low']))\n    df['AB_Upper_Band'] = df['aupband'].rolling(window=20, center=False).mean()\n    # Low *(1 - 4 * (High - Low)\/ (High + Low))\n    df['adownband'] = df['low'] * (1 - 4 * (df['high']-df['low'])\/(df['high']+df['low']))\n    df['AB_Lower_Band'] = df['adownband'].rolling(window=20, center=False).mean()","933d6eeb":"def STOK(df, n):\n    df['STOK'] = ((df['close'] - df['low'].rolling(window=n, center=False).mean()) \/ (df['high'].rolling(window=n, center=False).max() - df['low'].rolling(window=n, center=False).min())) * 100\n    df['STOD'] = df['STOK'].rolling(window = 3, center=False).mean()","4ee7b8cf":"def psar(df, iaf = 0.02, maxaf = 0.2):\n    length = len(df)\n#     dates = (df['Date'])\n    high = (df['high'])\n    low = (df['low'])\n    close = (df['close'])\n    psar = df['close'][0:len(df['close'])]\n    psarbull = [None] * length\n    psarbear = [None] * length\n    bull = True\n    af = iaf\n    ep = df['low'][0]\n    hp = df['high'][0]\n    lp = df['low'][0]\n    for i in range(2,length):\n        if bull:\n            psar[i] = psar[i - 1] + af * (hp - psar[i - 1])\n        else:\n            psar[i] = psar[i - 1] + af * (lp - psar[i - 1])\n        reverse = False\n        if bull:\n            if df['low'][i] < psar[i]:\n                bull = False\n                reverse = True\n                psar[i] = hp\n                lp = df['low'][i]\n                af = iaf\n        else:\n            if df['high'][i] > psar[i]:\n                bull = True\n                reverse = True\n                psar[i] = lp\n                hp = df['high'][i]\n                af = iaf\n        if not reverse:\n            if bull:\n                if df['high'][i] > hp:\n                    hp = df['high'][i]\n                    af = min(af + iaf, maxaf)\n                if df['low'][i - 1] < psar[i]:\n                    psar[i] = df['low'][i - 1]\n                if df['low'][i - 2] < psar[i]:\n                    psar[i] = df['low'][i - 2]\n            else:\n                if df['low'][i] < lp:\n                    lp = df['low'][i]\n                    af = min(af + iaf, maxaf)\n                if df['high'][i - 1] > psar[i]:\n                    psar[i] = df['high'][i - 1]\n                if df['high'][i - 2] > psar[i]:\n                    psar[i] = df['high'][i - 2]\n        if bull:\n            psarbull[i] = psar[i]\n        else:\n            psarbear[i] = psar[i]\n    #return {\"dates\":dates, \"high\":high, \"low\":low, \"close\":close, \"psar\":psar, \"psarbear\":psarbear, \"psarbull\":psarbull}\n    #return psar, psarbear, psarbull\n    df['psar'] = psar\n    #df['psarbear'] = psarbear\n    #df['psarbull'] = psarbull","6e2d2481":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nwindow = 12\n# starting_ids = [0, 7275, 14550,21765, 29040]\ndef preprocess (data_in):\n    starting_ids = []\n    data = data_in.copy()\n    for k in range(5):\n        starting_ids.append(data[data.asset == k]['id'].min())\n    # data['asset'] = data['asset'].astype('int')\n    data['diff'] = data['high'] - data['low']\n    data['diff*volume'] = data['diff'] * data['volume']\n    data ['vol\/trades'] = data.volume \/ data.trades\n#     id_diff = []\n#     for index, row in data.iterrows():\n#         id_diff.append(row.id - starting_ids[int(row.asset)])\n        \n#     data['idd_diff'] = id_diff\n    #data = pd.get_dummies(data, columns=['asset'])\n    data.drop('id',axis = 1, inplace = True)\n    data.drop('asset',axis = 1, inplace = True)\n    #data.drop('macd_signal',axis = 1, inplace = True)\n#     poly = PolynomialFeatures(2)\n#     data = poly.fit_transform(data)\n#     rolling_12_min  = data.rolling(window=12).min().add_suffix('_12_min')\n#     rolling_12_max  = data.rolling(window=12).max().add_suffix('_12_max')\n#     rolling_12_mean  = data.rolling(window=12).mean().add_suffix('_12_mean')\n    \n#     rolling_1_min  = data.rolling(window=1).min().add_suffix('_1_min')\n#     #print (rolling_1_min.head().T)\n#     rolling_1_max  = data.rolling(window=1).max().add_suffix('_1_max')\n#     rolling_1_mean  = data.rolling(window=12).mean().add_suffix('_1_mean')\n    \n#     data = pd.concat([data,rolling_12_min,rolling_12_max, rolling_12_mean, rolling_1_min,rolling_1_max, rolling_1_mean ], axis = 1)\n    data['Momentum_1D'] = (data['close']-data['close'].shift(1)).fillna(0)\n    data['RSI_14D'] = data['Momentum_1D'].rolling(center=False, window=14).apply(rsi).fillna(0)\n    data['RSI_1D'] = data['Momentum_1D'].rolling(center=False, window=1).apply(rsi).fillna(0)\n    data['RSI_2D'] = data['Momentum_1D'].rolling(center=False, window=2).apply(rsi).fillna(0)\n    data['RSI_4D'] = data['Momentum_1D'].rolling(center=False, window=4).apply(rsi).fillna(0)\n    data['RSI_8D'] = data['Momentum_1D'].rolling(center=False, window=8).apply(rsi).fillna(0)\n    \n    data['BB_Middle_Band'], data['BB_Upper_Band'], data['BB_Lower_Band'] = bbands(data['close'], length=20, numsd=1)\n    data['BB_Middle_Band'] = data['BB_Middle_Band'].fillna(0)\n    data['BB_Upper_Band'] = data['BB_Upper_Band'].fillna(0)\n    data['BB_Lower_Band'] = data['BB_Lower_Band'].fillna(0)\n    \n    listofzeros = [0] * 25\n    up, down = aroon(data)\n    aroon_list = [x - y for x, y in zip(up,down)]\n    if len(aroon_list)==0:\n        aroon_list = [0] * data.shape[0]\n        data['Aroon_Oscillator'] = aroon_list\n    else:\n        data['Aroon_Oscillator'] = listofzeros+aroon_list\n        \n    data[\"PVT\"] = (data['Momentum_1D']\/ data['close'].shift(1))*data['volume']\n    data[\"PVT\"] = data[\"PVT\"] - data[\"PVT\"].shift(1)\n    data[\"PVT\"] = data[\"PVT\"].fillna(0)\n    \n    abands(data)\n    data.fillna(0)\n    \n    STOK(data, 4)\n    data.fillna(0)\n    \n#     psar(data)\n#     data.fillna(0)\n    \n    data['ROC'] = ((data['close'] - data['close'].shift(12))\/(data['close'].shift(12)))*100\n    data.fillna(0)\n    \n#     for stock in range(len(data)):\n    data['VWAP'] = np.cumsum(data['volume'] * (data['high'] + data['low'])\/2) \/ np.cumsum(data['volume'])\n    data.fillna(0)\n    \n    scaler = StandardScaler(with_std=False)\n    data = scaler.fit_transform(data)\n    return data","2188c782":"data = pd.read_csv('..\/input\/train.csv')\ntarget = data.pop('y')\ndata_test = pd.read_csv('..\/input\/test.csv')","cab72a33":"target_by_asset = []\ntest_by_asset = []\ntrain_by_asset = []\nPredID = []\npreds_df = []\nscores = []\nbest_params = []\ngrid_scores = []\ngrid_preds_df = []\nfor k in range(5):\n    train_by_asset.append( data[data['asset']==k])\n    target_by_asset.append( target[data['asset']==k])\n    PredID.append(data_test[data_test['asset']==k]['id'])\n    train_by_asset[k] = preprocess(train_by_asset[k])\n    test_by_asset.append(data_test[data_test['asset']==k])\n    test_by_asset[k] = preprocess(test_by_asset[k])\n    \n    #print(train_by_asset[k])\n    \n   # print(train_by_asset,target_by_asset,PredID,test_by_asset)\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(train_by_asset[k], target_by_asset[k], test_size=0.33, random_state=777, shuffle=False) \n\n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n\n    # specify your configurations as a dict\n    params = {\n        'boosting_type': 'gbdt',\n        'colsample_bytree': 0.65,\n        'learning_rate': 0.005,\n        'n_estimators': 40,\n        'num_leaves': 16,\n        'objective': 'regression',\n        'random_state': 501,\n        'reg_alpha': 1,\n        'reg_lambda': 0,\n        'subsample': 0.7,\n        'max_depth' : -1,\n        'max_bin': 512,\n        'subsample_for_bin': 200,\n        'subsample_freq': 1,\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 5,\n        'scale_pos_weight': 1,\n    }\n    \n    gbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=20,\n                valid_sets=lgb_eval,\n                early_stopping_rounds=5)\n    \n    mdl = lgb.LGBMRegressor(boosting_type= 'gbdt',\n          objective = 'regrssion',\n          n_jobs = -1, # Updated from 'nthread'\n          silent = True,\n          max_depth = params['max_depth'],\n          max_bin = params['max_bin'],\n          subsample_for_bin = params['subsample_for_bin'],\n          subsample = params['subsample'],\n          subsample_freq = params['subsample_freq'],\n          min_split_gain = params['min_split_gain'],\n          min_child_weight = params['min_child_weight'],\n          min_child_samples = params['min_child_samples'],\n          scale_pos_weight = params['scale_pos_weight'])\n    \n    gridParams = {\n        'learning_rate': [0.005],\n        'n_estimators': [40],\n        'num_leaves': [6,8,12,16],\n        'boosting_type' : ['gbdt'],\n        'objective': ['regression'],\n        'random_state' : [501], # Updated from 'seed'\n        'colsample_bytree' : [0.65, 0.66],\n        'subsample' : [0.7,0.75],\n        'reg_alpha' : [0,1,1.2],\n        'reg_lambda' : [0,1,1.2,1.4],\n    }\n\n    grid = RandomizedSearchCV(mdl, gridParams,\n                    verbose=0,\n                    cv=4,\n                    n_jobs=-1)\n    \n    grid.fit(train_by_asset[k], target_by_asset[k])\n\n    # Print the best parameters found\n    \n    print(grid.best_params_)\n    print(grid.best_score_)\n    best_params.append(grid.best_params_)\n    grid_scores.append(grid.best_score_)\n    \n    grid_pred = grid.predict(test_by_asset[k])\n    grid_pred[:12] = np.zeros(12)\n    out = pd.DataFrame(PredID[k])\n    out['expected'] = grid_pred\n    #print(out)\n    grid_preds_df.append(out)\n    \n    y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n    # eval\n    print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n    scores.append(mean_squared_error(y_test, y_pred) ** 0.5)\n    \n    \n    preds = gbm.predict(test_by_asset[k], num_iteration=gbm.best_iteration)\n    preds[:12] = np.zeros(12)\n    out = pd.DataFrame(PredID[k])\n    out['expected'] = preds\n    #print(out)\n    preds_df.append(out)","12c2b559":"print(scores)\nprint(np.mean(scores),np.std(scores))","8c026863":"print(grid_scores)\nprint(np.mean(grid_scores),np.std(grid_scores))","928d4f97":"out_df = pd.DataFrame(np.concatenate(preds_df), columns=['id','expected'])\nout_df.id = out_df.id.astype('int')\nout_df.to_csv('by_asset_lgbm.csv',index = False)","067b4881":"out_df = pd.DataFrame(np.concatenate(grid_preds_df), columns=['id','expected'])\nout_df.id = out_df.id.astype('int')\nout_df.to_csv('grid_by_asset.csv',index = False)","e7a9ca15":"from sklearn.linear_model import ElasticNetCV\nregr = ElasticNetCV(cv=5, random_state=0, l1_ratio = [.1, .5, .7, .9, .95, .99, 1])\nscores = []\ntarget_by_asset = []\ntest_by_asset = []\ntrain_by_asset = []\nPredID = []\npreds_df = []\nscores = []\nbest_params = []\ngrid_scores = []\ngrid_preds_df = []\nfor k in range(5):\n    train_by_asset.append( data[data['asset']==k])\n    target_by_asset.append( target[data['asset']==k])\n    PredID.append(data_test[data_test['asset']==k]['id'])\n    train_by_asset[k] = preprocess(train_by_asset[k])\n    test_by_asset.append(data_test[data_test['asset']==k])\n    test_by_asset[k] = preprocess(test_by_asset[k])\n    \n    from sklearn.model_selection import train_test_split\n    \n    X_train, X_test, y_train, y_test = train_test_split(np.nan_to_num(train_by_asset[k],0), target_by_asset[k], test_size=0.33, random_state=777, shuffle=False) \n    \n    regr.fit(X_train,y_train)\n    y_pred = regr.predict (X_test)\n#     \n    print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n    scores.append(mean_squared_error(y_test, y_pred) ** 0.5)\n    \n    preds = regr.predict(np.nan_to_num(test_by_asset[k],0))\n    out = pd.DataFrame(PredID[k])\n    out['expected'] = preds\n    #print(out)\n    preds_df.append(out)","f584f8f9":"print(scores)\nprint(np.mean(scores),np.std(scores))","bd9aa4aa":"out_df = pd.DataFrame(np.concatenate(preds_df), columns=['id','expected'])\nout_df.id = out_df.id.astype('int')\nout_df.to_csv('Elastic_net.csv',index = False)","3e4eeb25":"[0.0034013447836041366, -0.007779764770281005, 0.00025671830563126283, -0.008346788122561203, -0.010524651325048163]\n-0.004598628225730994 0.005419594822320587\n\nrolling (wrong?)\n\n[0.00474713090944534, -0.006542880441062967, 0.0010371953974309812, -0.007956894859394197, -0.011771988264293598]\n-0.004097487451574888 0.006072317136793158\n\nrolling\n\n[-0.0007421783216381947, -0.005759116230089936, 0.0029404735897728, -0.0099340629682664, -0.013260140730498344]\n-0.005351004932144015 0.005894324451129263","3465882d":"Elastic without windows\n\n[0.7843381203753828, 0.6991611658363793, 0.72681852540914, 0.7244268066276227, 0.7605812564714087]\n0.7390651749439867 0.02989706857530931","cbe99c67":"[0.786891395468127, 0.6973549079908655, 0.7254750063290656, 0.7244248036717815, 0.759813275450325]\n0.738791877782033 0.031164842726449895\n\nrollig (wrong?)\n\n[0.7868569153648659, 0.6965938932773268, 0.7253140229115677, 0.7244046020382962, 0.7591281367246425]\n0.7384595140633399 0.031281224748745236\n\nusing bands\n\n[0.7865777258814584, 0.6956495616477514, 0.7261818906168533, 0.7245652742462407, 0.757114859842344]\n0.7380178624469296 0.031109133441386192\n\n\n"}}