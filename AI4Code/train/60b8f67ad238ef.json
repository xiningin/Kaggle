{"cell_type":{"09b3846d":"code","87c45fd8":"code","0321b720":"code","702fce14":"code","0cc9dd85":"code","cfbeabab":"code","c88d307f":"code","56aba84f":"code","3d04b2f9":"code","cd7dfc8e":"code","4d7de839":"code","93c8232f":"code","19458b81":"code","d1e57145":"code","5d5621e8":"code","a9409b2c":"code","23d7009f":"code","a24e9f14":"code","c744856c":"code","dffc7362":"code","85d0ff01":"code","5228c712":"code","a2df8f53":"code","6fa90748":"code","b9db5c36":"code","5c818b7a":"code","ce2544be":"code","0b9e3df1":"code","6bed44e4":"code","cd937f24":"code","7be3477c":"code","d92da783":"code","02a4928d":"code","7a49bf37":"code","90f805a1":"code","5b65c73e":"code","0bb60e6e":"code","06907823":"code","c279e593":"code","61fe6409":"code","5f9a49ab":"code","d237109b":"code","cfd2b005":"code","08d680a0":"code","a315f79f":"code","69c00789":"code","69c0d794":"code","48ff21e7":"code","f87a3a9a":"code","c340a348":"code","acce1372":"code","9157a25f":"code","d37d0d0b":"code","a21d275b":"code","d51bc8ce":"code","b882b249":"code","d5866a15":"code","416389c8":"code","4acb46f1":"code","f338ea1f":"code","9e01c153":"code","80f1d9b4":"code","b1356350":"code","e1ca1b06":"code","4fd0dd95":"code","171a6af8":"code","9bd56d08":"code","020a98ed":"code","ab37e111":"code","c5dc4fab":"code","d3bbdd61":"code","61191d6c":"code","131e23ea":"code","efd6f48b":"code","41037bf0":"code","ce652e12":"code","66487b84":"code","93efa1f3":"code","315bc142":"code","9e51b3cf":"code","8ffe0250":"code","55ae58ba":"code","f5cd0c02":"code","36185176":"code","0ce3a982":"code","59bc9d57":"code","299e1395":"code","2e82ed11":"code","84cc86d0":"code","6437bdda":"code","7d290430":"code","a7035dce":"code","fa650afa":"code","ae74455f":"code","eb5413db":"code","e2753e26":"code","7c84f98e":"code","4edd1afc":"code","ddfccc6d":"code","5e0276ff":"code","9cec8722":"code","2fe50b33":"code","fcbf8b78":"code","de71ecca":"code","164eac39":"code","39696a04":"code","1926a2b0":"code","9993d389":"code","96a6e2c0":"code","f44af0f0":"code","93ecda5b":"code","ac1c482c":"code","9e5b304d":"code","91de5902":"code","880c02ba":"code","43661d45":"code","e7689ca5":"code","b1587733":"markdown","0778b0d1":"markdown","a063d599":"markdown","aa1b2bbc":"markdown","22852477":"markdown","436e15ef":"markdown","81bb3f28":"markdown","cda1c67e":"markdown","57ce9189":"markdown","f3994d37":"markdown","09577a53":"markdown","b0ae6082":"markdown","918d5c19":"markdown","b4964719":"markdown","d8d62dd9":"markdown","ea830e5c":"markdown","4ec1b932":"markdown","76f28b4e":"markdown","61e02d5a":"markdown","ec0c860e":"markdown","fc4ddbcd":"markdown","12df939a":"markdown","ee6b60d6":"markdown","478fab49":"markdown","2211906f":"markdown","69650701":"markdown","3eafacda":"markdown","495e6248":"markdown","11ad20a4":"markdown","51d5f806":"markdown","7fd5c041":"markdown","152ece3c":"markdown","05578406":"markdown","2d41875f":"markdown","aefb2abd":"markdown","aa5925fe":"markdown","18edfefe":"markdown","6da5a268":"markdown","d619d203":"markdown","b1f87494":"markdown","0e53abe3":"markdown","deb626bb":"markdown","b0df7a94":"markdown","f1aaa298":"markdown","bad5d6f3":"markdown","8165b0f3":"markdown","3a788c14":"markdown","6998bc4d":"markdown","117d2104":"markdown","08b4bc42":"markdown","f408028d":"markdown","8aba6b96":"markdown","1db53bfe":"markdown","08cef475":"markdown","e00f5512":"markdown","d2ab74bd":"markdown","c1c6a4a9":"markdown","d35ab9ff":"markdown","c0c15e27":"markdown","b0ffd44a":"markdown","0fe81851":"markdown","ee1cb7f3":"markdown","0f7c93ea":"markdown","57e811c5":"markdown","571e21ef":"markdown","bcfcf985":"markdown","789173fe":"markdown","2439038d":"markdown","8a692e6a":"markdown","7c554461":"markdown","d0ec222c":"markdown"},"source":{"09b3846d":"import os\nimport numpy as np \nimport pandas as pd \nimport missingno as msno\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nplt.style.use('seaborn')\n\n\nfrom scipy.stats import norm\n\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder,StandardScaler\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,cross_val_score,GridSearchCV\nfrom sklearn.metrics import f1_score,confusion_matrix,accuracy_score,classification_report,roc_auc_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","87c45fd8":"data = pd.read_csv(\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\n","0321b720":"data.head()","702fce14":"data.info()","0cc9dd85":"data.shape","cfbeabab":"data.describe().T","c88d307f":"# create list of columns with numerical datatype and categorical data type\ncat = [x for x in data.columns if data[x].dtype == \"O\"]\nnum = [x for x in data.columns if x not in cat]\n","56aba84f":"\nmsno.bar(data,color=['magenta'])\nplt.show()\n","3d04b2f9":"percentage = data['bmi'].isnull().sum()\/len(data.bmi)\nprint('Missing value ',percentage*100)","cd7dfc8e":"data['bmi_null'] = np.where(data['bmi'].isnull(),1,0)\ndata['bmi'].fillna(data['bmi'].mean(),inplace=True)","4d7de839":"# confirm missing values\ndata.isnull().sum()","93c8232f":"labels=[\"stroke\",\"not stroke\"]\ndata.stroke.value_counts().plot(kind='pie',labels=labels,subplots=True,autopct='%1.0f%%',labeldistance=1.1, figsize=(8,8),colors=['olive','magenta'])","19458b81":"sns.countplot(data.stroke)","d1e57145":"sns.countplot(x='gender',data=data,palette='Set2')","5d5621e8":"# since other is just a outlier for our future model so we will drop it\ndata = data.drop(data[data['gender'] == 'Other'].index)","a9409b2c":"label=[x for x in data.gender.unique()]\nvalue = [x for x in data.gender.value_counts()]\nfig = go.Figure(data=[go.Pie(labels=label, values=value, hole=.6)])\nfig.show()","23d7009f":"\n\nax1=sns.countplot(data=data,x='gender',hue='stroke',palette='Set2')\nplt.title('gender vs stroke')","a24e9f14":"sns.catplot(x='gender',y='age',col='stroke',data=data)\nplt.show()","c744856c":"sns.catplot(col='gender',hue='heart_disease',x='stroke',data=data,\n            kind=\"count\")\nplt.show()","dffc7362":"sns.catplot(col='heart_disease',x='gender',hue='stroke',data=data,palette={0: \"g\", 1: \"m\"},\n            kind=\"count\")\nplt.show()","85d0ff01":"\nsns.catplot(x='gender',col='stroke',hue='Residence_type',data=data,kind='count',palette='husl')\nplt.show()","5228c712":"sns.catplot(x='gender',col='stroke',hue='work_type',data=data,kind='count')\nplt.show()","a2df8f53":"sns.catplot(x='gender',col='stroke',y='avg_glucose_level',data=data,kind='swarm',palette='husl')\nplt.show()\n\n","6fa90748":"sns.catplot(x='gender',col='stroke',y='bmi',data=data,kind='boxen',palette='husl')\nplt.show()\n\n","b9db5c36":"sns.catplot(x='gender',hue='smoking_status',data=data,col='stroke',kind='count',palette='husl')","5c818b7a":"data.groupby(['gender','stroke'])['stroke'].count()","ce2544be":"sns.countplot(x='ever_married',data=data,palette='plasma')","0b9e3df1":"label=[x for x in data.ever_married.unique()]\ndata.ever_married.value_counts().plot(kind='pie',labels=label,subplots=True,autopct='%1.0f%%',labeldistance=1.2, figsize=(4,4),colors=['lime','plum'])","6bed44e4":"\nsns.countplot(data=data,x='ever_married',hue='stroke',palette='Accent')\nplt.title('ever_married vs stroke')","cd937f24":"sns.catplot(data=data,x='ever_married',hue='stroke',palette='Accent',col='work_type',kind='count')\nplt.title('ever_married vs stroke')","7be3477c":"sns.countplot(x='work_type',data=data,palette='Set1')","d92da783":"label=[x for x in data.work_type.unique()]\nvalue = [x for x in data.work_type.value_counts()]\nfig = go.Figure(data=[go.Pie(labels=label, values=value, hole=.3)])\nfig.show()\n","02a4928d":"data.groupby(['work_type','stroke'])['stroke'].count()","7a49bf37":"plt.figure(figsize=(8,6))\n\nsns.countplot(data=data,y='work_type',hue='stroke',palette=\"pastel\", edgecolor=\".6\")\nplt.xticks(rotation=45)\nplt.title('work_type vs stroke')","90f805a1":"sns.countplot(x='Residence_type',data=data,palette='twilight')","5b65c73e":"label=[x for x in data.Residence_type.unique()]\ndata.Residence_type.value_counts().plot(kind='pie',labels=label,subplots=True,autopct='%1.0f%%',labeldistance=1.2, figsize=(5,5),colors=['Blue','hotpink'])","0bb60e6e":"\n\nsns.countplot(data=data,x='Residence_type',hue='stroke',palette='Reds')\nplt.xticks(rotation=45)\nplt.title('Residence_type vs stroke')\nplt.show()","06907823":"sns.catplot(data=data,x='Residence_type',hue='stroke',col='ever_married',palette='inferno',kind='count')","c279e593":"sns.catplot(data=data,x='Residence_type',hue='stroke',y='bmi',palette='inferno',kind='boxen')","61fe6409":"sns.countplot(x='smoking_status',data=data,palette='coolwarm')","5f9a49ab":"label=[x for x in data.smoking_status.unique()]\nvalue = [x for x in data.smoking_status.value_counts()]\nfig = go.Figure(data=[go.Pie(labels=label, values=value, hole=.4)])\nfig.show()","d237109b":"sns.countplot(data=data,x='smoking_status',hue='stroke',palette='Pastel1')\nplt.title('smoking_status vs stroke')\nplt.xticks(rotation=45)\nplt.show()\n","cfd2b005":"plt.figure(figsize=(18,4))\nplt.subplot(1,2,1)\nsns.distplot(data.age,color='mediumorchid',rug=True)\nplt.title('Distribution of Age')\n\nplt.subplot(1,2,2)\nsns.distplot(data.age,color='firebrick',rug=True,fit=norm)\nplt.title('Normalization w.r.t Age')\nplt.show()","08d680a0":"# age\nfig = px.box(data, x=\"stroke\", y=\"age\", points=\"all\")\nfig.show()","a315f79f":"sns.catplot(y='age',data=data,x='smoking_status',col='stroke')","69c00789":"sns.catplot(y='age',data=data,x='smoking_status',hue='hypertension',col='stroke')","69c0d794":"sns.catplot(y='age',data=data,x='ever_married',hue='stroke',kind='point')\nsns.catplot(y='age',data=data,x='ever_married',col='stroke',kind='boxen')\n\n","48ff21e7":"sns.catplot(y='age',data=data,x='stroke',col='Residence_type',kind='boxen')\n\n","f87a3a9a":"sns.catplot(y='age',data=data,hue='stroke',col='Residence_type',x='heart_disease',kind='box',palette='husl')","c340a348":"plt.figure(figsize=(18,4))\nplt.subplot(1,2,1)\nsns.distplot(data.avg_glucose_level,color='hotpink',rug=True)\nplt.title('Distribution of avg_glucose_level')\n\nplt.subplot(1,2,2)\nsns.distplot(data.avg_glucose_level,color='dodgerblue',rug=True,fit=norm)\nplt.title('Normalization w.r.t avg_glucose_level')\nplt.show()","acce1372":"\nfig = px.box(data, x=\"stroke\", y=\"avg_glucose_level\", points=\"all\")\nfig.show()","9157a25f":"sns.boxplot(x='stroke',y='avg_glucose_level',data=data)","d37d0d0b":"sns.kdeplot(data=data,y='avg_glucose_level',hue='stroke',x='bmi',palette='inferno')","a21d275b":"sns.jointplot(data=data,y='avg_glucose_level',hue='stroke',x='bmi',palette='gnuplot')","d51bc8ce":"sns.catplot(y='avg_glucose_level',x='smoking_status',hue='stroke',palette='gnuplot',data=data,kind='violin')","b882b249":"sns.countplot(data=data,x='hypertension',palette='cividis')","d5866a15":"\nsns.countplot(data=data,x='hypertension',hue='stroke',palette='plasma')\nplt.title('hypertension vs stroke')","416389c8":"sns.catplot(data=data,x='work_type',hue='stroke',col='hypertension',kind='count',palette='husl')","4acb46f1":"sns.swarmplot(data=data,y='avg_glucose_level',hue='stroke',x='hypertension',palette='rainbow')","f338ea1f":"sns.catplot(data=data,y='avg_glucose_level',col='stroke',x='hypertension',kind='box',palette='rainbow')","9e01c153":"sns.countplot(data=data,x='heart_disease',palette='terrain')","80f1d9b4":"plt.figure(figsize=(12,4))\nplt.subplot(1,2,1)\nsns.countplot(data=data,x='heart_disease',hue='stroke',palette='Set1')\nplt.title('heart_disease vs stroke')","b1356350":"plt.figure(figsize=(18,4))\nplt.subplot(1,2,1)\nsns.distplot(data.bmi,color='olive',rug=True)\nplt.title('Distribution of bmi')\n\nplt.subplot(1,2,2)\nsns.distplot(data.bmi,color='darkgray',rug=True,fit=norm)\nplt.title('Normalization w.r.t bmi')\nplt.show()","e1ca1b06":"sns.catplot(y='bmi',data=data,x='stroke',kind='point',height = 6, aspect =2)\nplt.show()","4fd0dd95":"sns.catplot(y='bmi',data=data,x='stroke',kind='bar',height = 6, aspect =2)","171a6af8":"sns.catplot(y='bmi',data=data,x='stroke',hue='ever_married',kind='bar',height = 6, aspect =2)","9bd56d08":"data.head()","020a98ed":"data.drop('id',inplace=True,axis=1)","ab37e111":"le =LabelEncoder()\nle.fit(data.gender)\ndata['gender']=le.transform(data.gender)\ndata['ever_married']=le.fit_transform(data.ever_married)\ndata['work_type']=le.fit_transform(data.work_type)\ndata['Residence_type']=le.fit_transform(data.Residence_type)\ndata['smoking_status']=le.fit_transform(data.smoking_status)\n","c5dc4fab":"feat = ['age','avg_glucose_level','bmi']\nss=StandardScaler()\ndata[feat]=ss.fit_transform(data[feat])\n","d3bbdd61":"data[feat]","61191d6c":"feat_dummy = [x for x in data.columns if x not in feat ]\nfeat_dummy.remove('stroke')\ndata = pd.get_dummies(data=data,columns=feat_dummy,drop_first=True)\n","131e23ea":"data.shape\n","efd6f48b":"x=data.drop('stroke',axis=1)\ny=data.stroke","41037bf0":"# Train-test split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=31)\nprint('x train shape: ',x_train.shape)\nprint('x test shape: ',x_test.shape)\nprint('y train shape: ',y_train.shape)\nprint('y test shape: ',y_test.shape)","ce652e12":"skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)","66487b84":"# lists for storing model scores\nnc=[]    # normal classifier\nhpr=[]   # Hyperparameter Tuning score\nskfc=[]  # stratified kfold score","93efa1f3":"# Using Train test split\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\ny_lr_pred = lr.predict(x_test)\nscore_lr=accuracy_score(y_test,y_lr_pred)*100\nprint(\"accuracy score: \",accuracy_score(y_train,lr.predict(x_train))*100)\nprint(\"accuracy score: \",score_lr)\n\nprint(f\"Confusion Matrix :- \\n {confusion_matrix(y_test,y_lr_pred)}\")\nprint(f\"Classiication Report : -\\n {classification_report(y_test, y_lr_pred)}\")\n","315bc142":"# hyper parameter tuning of logistic regression\n\ngrid_param = {\n    'penalty': ['l1', 'l2'],\n    'C' : [0.001, 0.01, 0.1, 0.005, 0.5, 1, 10]\n}\n\ngrid_search_lr = GridSearchCV(lr, grid_param, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_lr.fit(x_train, y_train)\n","9e51b3cf":"# best parameters and best score\n\nprint(grid_search_lr.best_params_)\nprint(grid_search_lr.best_score_)\n","8ffe0250":"# best estimator\n\nlr = grid_search_lr.best_estimator_\n\n# accuracy score, confusion matrix and classification report of logistic regression\n\nlr_acc = accuracy_score(y_test, lr.predict(x_test))\n\nprint(f\"Training Accuracy of Logistic Regression is {accuracy_score(y_train, lr.predict(x_train))}\")\nprint(f\"Test Accuracy of Logistic Regression is {lr_acc}\")\n\nprint(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, lr.predict(x_test))}\")\nprint(f\"Classofocation Report : -\\n {classification_report(y_test, lr.predict(x_test))}\")\nnc.append(lr_acc*100)","55ae58ba":"# define function\ndef train_skf(model):\n    pred_test_full =0\n    cv_score =[]\n    i=1\n    for train_index,test_index in skf.split(x,y):\n        print('{} of KFold {}'.format(i,skf.n_splits))\n        xtr,xvl = x.iloc[train_index],x.iloc[test_index]\n        ytr,yvl = y.iloc[train_index],y.iloc[test_index]\n\n        #model\n        \n        model.fit(xtr,ytr)\n        score = accuracy_score(yvl,model.predict(xvl))*100\n        print('accuracy score:',score)\n        cv_score.append(score)    \n        pred_test = model.predict_proba(x_test)[:,1]\n        pred_test_full +=pred_test\n        i+=1\n    \n    return np.mean(cv_score)\n    \n    \n    \n","f5cd0c02":"#print(np.mean(cv_score))\nlr=LogisticRegression(C=0.001)\nskfc.append(train_skf(lr))","36185176":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(x_train, y_train)\n\n# accuracy score, confusion matrix and classification report of knn\n\nknn_acc = accuracy_score(y_test, knn.predict(x_test))\n\nprint(f\"Training Accuracy of KNN is {accuracy_score(y_train, knn.predict(x_train))}\")\nprint(f\"Test Accuracy of KNN is {knn_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, knn.predict(x_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, knn.predict(x_test))}\")\n\nnc.append(knn_acc*100)","0ce3a982":"# skfold knn\nskfc.append(train_skf(knn))\nhpr.append('No hpr')","59bc9d57":"from sklearn.tree import DecisionTreeClassifier\n\ndtc = DecisionTreeClassifier()\ndtc.fit(x_train, y_train)\n\n# accuracy score, confusion matrix and classification report of decision tree\n\ndtc_acc = accuracy_score(y_test, dtc.predict(x_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, dtc.predict(x_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {dtc_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, dtc.predict(x_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, dtc.predict(x_test))}\")\n\n","299e1395":"# hyper parameter tuning\n# hyper parameter tuning of decision tree \n\ngrid_param = {\n    'criterion' : ['gini', 'entropy'],\n    'max_depth' : [3, 5, 7, 10],\n    'splitter' : ['best', 'random'],\n    'min_samples_leaf' : [1, 2, 3, 5, 7],\n    'min_samples_split' : [1, 2, 3, 5, 7],\n    'max_features' : ['auto', 'sqrt', 'log2']\n}\n\ngrid_search_dtc = GridSearchCV(dtc, grid_param, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_dtc.fit(x_train, y_train)\n","2e82ed11":"# best parameters and best score\n\nprint(grid_search_dtc.best_params_)\nprint(grid_search_dtc.best_score_)","84cc86d0":"# best estimator\n\ndtc = grid_search_dtc.best_estimator_\n\n# accuracy score, confusion matrix and classification report of decision tree\n\ndtc_acc = accuracy_score(y_test, dtc.predict(x_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, dtc.predict(x_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {dtc_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, dtc.predict(x_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, dtc.predict(x_test))}\")\nnc.append(dtc_acc*100)","6437bdda":"# skfold for Dt\n\nskfc.append(train_skf(dtc))","7d290430":"from sklearn.ensemble import RandomForestClassifier\n\nrd_clf = RandomForestClassifier()\nrd_clf.fit(x_train, y_train)\n\n# accuracy score, confusion matrix and classification report of random forest\n\nrd_clf_acc = accuracy_score(y_test, rd_clf.predict(x_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, rd_clf.predict(x_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {rd_clf_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, rd_clf.predict(x_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, rd_clf.predict(x_test))}\")\n\nnc.append(rd_clf_acc*100)","a7035dce":"skfc.append(train_skf(rd_clf))\nhpr.append('no hpr')","fa650afa":"from sklearn.ensemble import AdaBoostClassifier\n\nada = AdaBoostClassifier(base_estimator = dtc)\nada.fit(x_train, y_train)\n\n# accuracy score, confusion matrix and classification report of ada boost\n\nada_acc = accuracy_score(y_test, ada.predict(x_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, ada.predict(x_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {ada_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, ada.predict(x_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, ada.predict(x_test))}\")\n\n","ae74455f":"# hyper parameter tuning ada boost\n\ngrid_param = {\n    'n_estimators' : [100, 120, 150, 180, 200],\n    'learning_rate' : [0.01, 0.1, 1, 10],\n    'algorithm' : ['SAMME', 'SAMME.R']\n}\n\ngrid_search_ada = GridSearchCV(ada, grid_param, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_ada.fit(x_train, y_train)","eb5413db":"# best parameter and best score\n\nprint(grid_search_ada.best_params_)\nprint(grid_search_ada.best_score_)\n","e2753e26":"ada = grid_search_ada.best_estimator_\n\n# accuracy score, confusion matrix and classification report of ada boost\n\nada_acc = accuracy_score(y_test, ada.predict(x_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, ada.predict(x_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {ada_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, ada.predict(x_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, ada.predict(x_test))}\")\n\nnc.append(ada_acc*100)","7c84f98e":"skfc.append(train_skf(ada))","4edd1afc":"from sklearn.ensemble import GradientBoostingClassifier\n\ngb = GradientBoostingClassifier()\ngb.fit(x_train, y_train)\n\n# accuracy score, confusion matrix and classification report of gradient boosting classifier\n\ngb_acc = accuracy_score(y_test, gb.predict(x_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, gb.predict(x_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {gb_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, gb.predict(x_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, gb.predict(x_test))}\")\nnc.append(gb_acc*100)","ddfccc6d":"skfc.append('no Skfold')","5e0276ff":"sgb = GradientBoostingClassifier(subsample = 0.90, max_features = 0.70)\nsgb.fit(x_train, y_train)\n\n# accuracy score, confusion matrix and classification report of stochastic gradient boosting classifier\n\nsgb_acc = accuracy_score(y_test, sgb.predict(x_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, sgb.predict(x_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {sgb_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, sgb.predict(x_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, sgb.predict(x_test))}\")\nnc.append(sgb_acc*100)\nhpr.append('no hpr')","9cec8722":"skfc.append(train_skf(sgb))","2fe50b33":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier(booster = 'gbtree', learning_rate = 0.1, max_depth = 5, n_estimators = 180)\nxgb.fit(x_train, y_train)\n\n# accuracy score, confusion matrix and classification report of xgboost\n\nxgb_acc = accuracy_score(y_test, xgb.predict(x_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, xgb.predict(x_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {xgb_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, xgb.predict(x_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, xgb.predict(x_test))}\")\nnc.append(xgb_acc*100)\nhpr.append('no hpr')","fcbf8b78":"# skfold \nskfc.append(train_skf(xgb))","de71ecca":"from catboost import CatBoostClassifier\n\ncat = CatBoostClassifier(iterations=10)\ncat.fit(x_train, y_train)","164eac39":"# accuracy score, confusion matrix and classification report of cat boost\n\ncat_acc = accuracy_score(y_test, cat.predict(x_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, cat.predict(x_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {cat_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, cat.predict(x_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, cat.predict(x_test))}\")\nnc.append(cat_acc*100)\nhpr.append('no hpr')","39696a04":"skfc.append(train_skf(cat))","1926a2b0":"from sklearn.ensemble import ExtraTreesClassifier\n\netc = ExtraTreesClassifier()\netc.fit(x_train, y_train)\n\n# accuracy score, confusion matrix and classification report of extra trees classifier\n\netc_acc = accuracy_score(y_test, etc.predict(x_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, etc.predict(x_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {etc_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, etc.predict(x_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, etc.predict(x_test))}\")\n\nnc.append(etc_acc*100)\nhpr.append('no hpr')","9993d389":"skfc.append(train_skf(etc))","96a6e2c0":"from lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(learning_rate = 1)\nlgbm.fit(x_train, y_train)\n\n# accuracy score, confusion matrix and classification report of lgbm classifier\n\nlgbm_acc = accuracy_score(y_test, lgbm.predict(x_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, lgbm.predict(x_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {lgbm_acc} \\n\")\n\nprint(f\"{confusion_matrix(y_test, lgbm.predict(x_test))}\\n\")\nprint(classification_report(y_test, lgbm.predict(x_test)))\nnc.append(lgbm_acc*100)\nhpr.append('no hpr')","f44af0f0":"skfc.append(train_skf(lgbm))","93ecda5b":"from sklearn.ensemble import VotingClassifier\n\nclassifiers = [('Gradient Boosting Classifier', gb), ('Stochastic Gradient Boosting', sgb),  ('Cat Boost Classifier', cat), \n               ('XGboost', xgb),  ('Decision Tree', dtc), ('Extra Tree', etc), ('Light Gradient', lgbm),\n               ('Random Forest', rd_clf), ('Ada Boost', ada), ('Logistic', lr)]\nvc = VotingClassifier(estimators = classifiers)\nvc.fit(x_train, y_train)\n","ac1c482c":"#accuracy score, confusion matrix and classification report of voting classifier\n\nvc_acc = accuracy_score(y_test, vc.predict(x_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, vc.predict(x_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {vc_acc} \\n\")\n\nprint(f\"{confusion_matrix(y_test, vc.predict(x_test))}\\n\")\nprint(classification_report(y_test, vc.predict(x_test)))\nnc.append(vc_acc*100)\nhpr.append('no hpr')\n","9e5b304d":"\nskfc.append('no skfold')","91de5902":"hpr.append('hpr')","880c02ba":"models = pd.DataFrame({\n    'Model' : ['Logistic Regression', 'KNN', 'Decision Tree Classifier', 'Random Forest Classifier','Ada Boost Classifier',\n             'Gradient Boosting Classifier', 'Stochastic Gradient Boosting', 'XgBoost', 'Cat Boost', 'Extra Trees Classifier','LGBM', 'Voting Classifier'],\n})\nmodels['normal_score']= nc\nmodels['S-kfold']=skfc\n\n\n\n\n#models.sort_values(by = 'Score', ascending = False)","43661d45":"models","e7689ca5":"plt.figure(figsize=(12,6))\nsns.barplot(y='Model',x='normal_score',palette='inferno',data=models)","b1587733":"<p style=\"font-size:180%; font-family:Verdana;color:peru;\"><b>Now both training and test data is cleaned and preprocessed, let's start with model building. <\/b><\/p>","0778b0d1":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Cat Boost Classifier <\/b><\/h4><center>","a063d599":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> One-hot encoding<\/b><\/h4>\n","aa1b2bbc":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Skfold <\/b><\/h4>\n","22852477":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> LGBM Classifier <\/b><\/h4><center>","436e15ef":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Decision Tree <\/b><\/h4><center>","81bb3f28":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> BMI <\/b><\/h3><\/center>","cda1c67e":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Train test split <\/b><\/h4>\n","57ce9189":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Handle the Columns with Missing values<\/b><\/h3><\/center>","f3994d37":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Train test split <\/b><\/h4>\n","09577a53":"<h2 style=\"font-size:250%; font-family:cursive; color:lightcoral;\"><b>Problem Statement:<\/b><h2>\n<p style=\"font-size:100%; font-family:Verdana\">According to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.<\/p>\n \n<p style=\"font-size:100%; font-family:Verdana\"> So the objective of this project is to predict  whether a patient is likely to get stroke  or not<\/p>\n    \n    \n<h2 style=\"font-size:250%; font-family:cursive; color:lightcoral;\"><b>About Dataset:<\/b><h2>\n<ul>\n    <li style=\"font-size:80%; font-family:Courier New\"><b>id:<\/b> unique identifier<\/li>\n    <li style=\"font-size:80%; font-family:Courier New\"><b>gender:<\/b> \"Male\", \"Female\" or \"Other\"<\/li>  \n    <li style=\"font-size:80%; font-family:Courier New\"><b>age:<\/b>age of the patient<\/li>\n    <li style=\"font-size:80%; font-family:Courier New\"><b>hypertension:<\/b>0 if the patient doesn't have hypertension, 1 if the patient has hypertension<\/li>\n    <li style=\"font-size:80%; font-family:Courier New\"><b>heart_disease:<\/b> 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease<\/li>\n    <li style=\"font-size:80%; font-family:Courier New\"><b>ever_married:<\/b> \"No\" or \"Yes\"<\/li>\n    <li style=\"font-size:80%; font-family:Courier New\"><b>work_type:<\/b> \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"<\/li>\n    <li style=\"font-size:80%; font-family:Courier New\"><b>Residence_type:<\/b>\"Rural\" or \"Urban\".<\/li>\n    <li style=\"font-size:80%; font-family:Courier New\"><b>bmi:<\/b>  body mass index.<\/li>\n    <li style=\"font-size:80%; font-family:Courier New\"><b>smoking_status:<\/b> \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"(means information is unavailable for this patient).<\/li>\n    <li style=\"font-size:80%; font-family:Courier New\"><b>stroke:<\/b> 1 if the patient had a stroke or 0 if not.<\/li>\n<\/ul>    ","b0ae6082":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Adaboost Classifier <\/b><\/h4><center>","918d5c19":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Hyperparameter tuning<\/b><\/h4>\n","b4964719":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Heart disease  <\/b><\/h3><\/center>","d8d62dd9":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Train test split <\/b><\/h4>\n","ea830e5c":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using skfold <\/b><\/h4>\n","4ec1b932":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> EDA <\/b><\/h3><\/center>","76f28b4e":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Train test split <\/b><\/h4>\n","61e02d5a":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Feature Scaling <\/b><\/h4>\n","ec0c860e":"**We already know that our dataset is imbalanced so we will also use Stratified Kfold with normal score**\n\n**Stratified-Kfold: It is a cross validation technique which helps us to split our dataset in folds for training and Validation purpose for imbalance dataset.**","fc4ddbcd":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Skfold <\/b><\/h4>\n","12df939a":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Train test split <\/b><\/h4>\n","ee6b60d6":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Descriptive Statistics of Data<\/b><\/h3><\/center>","478fab49":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Age <\/b><\/h3><\/center>","2211906f":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Import Libraries & Load Dataset<\/b><\/h3><\/center>","69650701":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Train test split <\/b><\/h4>\n","3eafacda":"<ul>\n    <li style=\"font-size:180%; font-family:Verdana;\">In our dataset,we have columns with int,object and float datatypes and there are some missing values in bmi column also<\/li>\n<\/ul>","495e6248":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Skfold <\/b><\/h4>\n","11ad20a4":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Gender <\/b><\/h3><\/center>","51d5f806":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Gradient Boosting Classifier <\/b><\/h4><center>","7fd5c041":"<h1 style=\"font-size:300%; font-family:cursive; background:lightcoral; color:white; text-align:center; border:10px solid ; padding:25px;\">Stroke Prediction<\/h1>\n\n![image.png](attachment:24c9a7d3-f88c-4803-982e-c1164eb4e092.png)","152ece3c":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Skfold <\/b><\/h4>\n","05578406":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Average Glucose level <\/b><\/h3><\/center>","2d41875f":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Work Type <\/b><\/h3><\/center>","aefb2abd":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> KNN <\/b><\/h4><center>","aa5925fe":"<p style=\"font-size:180%; font-family:Verdana;\"><b>Id column is not useful so we will drop it <\/b><\/p>","18edfefe":"<p style=\"font-size:180%; font-family:Verdana; text-align:center;\"><b>\"MISSING VALUES ARE HANDLED\"<\/b><\/p>","6da5a268":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Train test split <\/b><\/h4>\n","d619d203":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Skfold <\/b><\/h4>\n","b1f87494":"<h4 style=\"font-size:150%; font-family:cursive; color:lightcoral;\"><b> Handle bmi Column<\/b><\/h4>","0e53abe3":"**A Voting Classifier is a machine learning model that trains on an ensemble of numerous models and predicts an output (class) based on their highest probability of chosen class as the output.**","deb626bb":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Train test split <\/b><\/h4>\n","b0df7a94":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Extra Trees Classifier <\/b><\/h4><center>","f1aaa298":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Voting Classifier<\/b><\/h4><center>","bad5d6f3":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Smoking status <\/b><\/h3><\/center>\n","8165b0f3":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Train test split <\/b><\/h4>\n","3a788c14":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> XgBoost <\/b><\/h4><center>","6998bc4d":"<center><h3 style=\"font-size:250%; font-family:cursive; color:lightcoral;\"><b> Models <\/b><\/h3><\/center>\n","117d2104":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Dataset split<\/b><\/h4>\n","08b4bc42":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Logistic Regression<\/b><\/h4><center>\n","f408028d":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Hyperparameter <\/b><\/h4>\n","8aba6b96":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Skfold <\/b><\/h4>\n","1db53bfe":"<center><h3 style=\"font-size:250%; font-family:cursive; color:lightcoral;\"><b> Thanks...If you like my work. Please give Upvote and Feel free to give your opinion and suggestions <\/b><\/h3><\/center>\n","08cef475":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Skfold <\/b><\/h4>\n","e00f5512":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Residence type <\/b><\/h3><\/center>","d2ab74bd":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Data Pre-processing <\/b><\/h3><\/center>\n","c1c6a4a9":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Skfold<\/b><\/h4>\n","d35ab9ff":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Hypertension <\/b><\/h3><\/center>","c0c15e27":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Stochastic Gradient Boosting (SGB) <\/b><\/h4><center>","b0ffd44a":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Skfold <\/b><\/h4>\n","0fe81851":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Label Encoding <\/b><\/h4>\n","ee1cb7f3":"<center><h3 style=\"font-size:200%; font-family:cursive; color:lightcoral;\"><b> Ever Married <\/b><\/h3><\/center>","0f7c93ea":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Random Forest Classifier <\/b><\/h4><center>","57e811c5":"<center><h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Model Comparison<\/b><\/h4><center>","571e21ef":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Train test split <\/b><\/h4>\n","bcfcf985":"<h4 style=\"font-size:150%; font-family:cursive; color:teal;\"><b>Findings from EDA<\/b><\/h4>\n\n<ul>\n     <li style=\"font-size:130%; font-family:Verdana;color:navy;\">Female and male both have equal number of stroke cases while there is not any single case of stroke in other gender type.<\/li>\n     <li style=\"font-size:130%; font-family:Verdana;color:navy;\">There are more number of stroke cases found in married person comparibly to unmarried<\/li>\n    <li style=\"font-size:130%; font-family:Verdana;color:navy;\">Patient with private job have more number stroke cases then self employed and govt. job<\/li>\n     <li style=\"font-size:130%; font-family:Verdana;color:navy;\">There are few cases of strokes in children and those who are unemployed having no case<\/li>\n        <li style=\"font-size:130%; font-family:Verdana;color:navy;\">Both Urban and rural have equal number of stroke cases.so this is not a useful feature .<\/li>\n    <li style=\"font-size:130%; font-family:Verdana;color:navy;\">Most of stroke cases belong to 60-80 age group that means most of patients are in their older age.<\/li>\n    <li style=\"font-size:130%; font-family:Verdana;color:navy;\">Patients with stroke having heigher avg_glucose_level then 120.<\/li>\n    <li style=\"font-size:130%; font-family:Verdana;color:navy;\">normaly person who smoke are more likely have a chance of stroke but in our dataset smoking doesn't have much impact on stroke.but we combine the smoker type in dataset then we can get some useful information <\/li>\n<\/ul>","789173fe":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Hyperparameter <\/b><\/h4>\n","2439038d":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Train test split <\/b><\/h4>\n","8a692e6a":"<p style=\"font-size:180%; font-family:Verdana;\"><b>Target feature is completely imbalanced <\/b><\/p>","7c554461":"<h4 style=\"font-size:150%; font-family:cursive; color:lightcoral;\"><b> Target variable (stroke)<\/b><\/h4>","d0ec222c":"<h4 style=\"font-size:200%; font-family:cursive; color:olive;\"><b> Using Skfold <\/b><\/h4>\n"}}