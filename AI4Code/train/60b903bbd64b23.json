{"cell_type":{"a5c277a8":"code","37508996":"code","f16e2a7c":"code","40555f18":"code","75ea57a6":"code","b0b4b237":"code","7ef5b232":"code","b99ea35e":"code","4ff75c3a":"code","5f9765ec":"code","5cb3302a":"code","2b5f227f":"code","3e77629e":"code","4ad0773e":"code","2e398a07":"code","604840dc":"code","11a575fb":"code","2519a270":"code","5fa065f1":"code","bc00f181":"code","4028d21e":"code","94dfbd1a":"code","91c9bcff":"code","ec07a02f":"code","6a5d797d":"code","76eae935":"code","5781649f":"code","9f16688e":"code","a99b58e2":"markdown","794e6bb0":"markdown","9804cb69":"markdown"},"source":{"a5c277a8":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\n\n#For Preprocessing\nimport re    # RegEx for removing non-letter characters\nimport nltk  # natural language processing\nnltk.download(\"stopwords\")\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import *\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# For Building the model\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport seaborn as sns\n\n#For data visualization\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n%matplotlib inline\n\npd.options.plotting.backend = \"plotly\"","37508996":"# Load Tweet dataset\ndf0 = pd.read_csv('..\/input\/customer-support-on-twitter\/twcs\/twcs.csv')\ndf0","f16e2a7c":"df=df0[['text']][0:10000]\ndf","40555f18":"def tweet_to_words(tweet):\n    ''' Convert tweet text into a sequence of words '''\n    \n    # convert to lowercase\n    text = tweet.lower()\n    # remove non letters\n    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n    # tokenize\n    words = text.split()\n    # remove stopwords\n    words = [w for w in words if w not in stopwords.words(\"english\")]\n    # apply stemming\n    words = [PorterStemmer().stem(w) for w in words]\n    # return list\n    return words","75ea57a6":"cleantext=[]\nfor item in tqdm(df['text']):\n    words=tweet_to_words(str(item))\n    cleantext+=[words]\ndf['cleantext']=cleantext\ndf","b0b4b237":"# Apply data processing to each tweet\n# X = list(map(tweet_to_words, df['content']))\n# print(X==cleantext) #True","7ef5b232":"def unlist(list):\n    words=''\n    for item in list:\n        words+=item+' '\n    return words","b99ea35e":"def compute_vader_scores(df, label):\n    sid = SentimentIntensityAnalyzer()\n    df[\"vader_neg\"] = df[label].apply(lambda x: sid.polarity_scores(unlist(x))[\"neg\"])\n    df[\"vader_neu\"] = df[label].apply(lambda x: sid.polarity_scores(unlist(x))[\"neu\"])\n    df[\"vader_pos\"] = df[label].apply(lambda x: sid.polarity_scores(unlist(x))[\"pos\"])\n    df[\"vader_comp\"] = df[label].apply(lambda x: sid.polarity_scores(unlist(x))[\"compound\"])\n    df['cleantext2'] = df[label].apply(lambda x: unlist(x))\n    return df","4ff75c3a":"df2 = compute_vader_scores(df,'cleantext')\ndf2","5f9765ec":"sns.jointplot(data=df2, x='vader_pos', y='vader_neg', kind=\"kde\")","5cb3302a":"sns.jointplot(data=df2, x='vader_pos', y='vader_neu', kind=\"kde\")","2b5f227f":"df2","3e77629e":"class0=[]\nfor i in range(len(df2)):\n    if df2.loc[i,'vader_neg']>0.02:\n        class0+=[0]\n    elif df2.loc[i,'vader_pos']>0.1:\n        class0+=[2]        \n    else:\n        class0+=[1]     ","4ad0773e":"print(len(df))\nprint(len(df2))","2e398a07":"df2['class']=class0\ndf2['class'].value_counts()","604840dc":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nmax_words = 5000\nmax_len=50\n\ndef tokenize_pad_sequences(text):\n    '''\n    This function tokenize the input text into sequnences of intergers and then\n    pad each sequence to the same length\n    '''\n    # Text tokenization\n    tokenizer = Tokenizer(num_words=max_words, lower=True, split=' ')\n    tokenizer.fit_on_texts(text)\n    X = tokenizer.texts_to_sequences(text)\n    X = pad_sequences(X, padding='post', maxlen=max_len)\n    return X, tokenizer\n\nprint('Before Tokenization & Padding \\n', df['cleantext2'][0])\nX, tokenizer = tokenize_pad_sequences(df['cleantext2'])\nprint('After Tokenization & Padding \\n', X[0])","11a575fb":"print(X.shape)","2519a270":"y = pd.get_dummies(df['class'])\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n\nprint('Train Set: ', X_train.shape, y_train.shape)\nprint('Validation Set: ', X_val.shape, y_val.shape)\nprint('Test Set: ', X_test.shape, y_test.shape)","5fa065f1":"import tensorflow.keras.backend as K\n\ndef f1_score(precision, recall):\n    ''' Function to calculate f1 score '''\n    \n    f1_val = 2*(precision*recall)\/(precision+recall+K.epsilon())\n    return f1_val","bc00f181":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras import datasets\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.callbacks import History\nfrom tensorflow.keras import losses","4028d21e":"vocab_size = 5000\nembedding_size = 32\nepochs = 10\nlearning_rate = 0.1\ndecay_rate = learning_rate \/ epochs\nmomentum = 0.8","94dfbd1a":"sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n# Build model\nmodel= Sequential()\nmodel.add(Embedding(vocab_size, embedding_size, input_length=max_len))\nmodel.add(Conv1D(filters=32, kernel_size=1, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Bidirectional(LSTM(32)))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(3, activation='softmax'))","91c9bcff":"import tensorflow as tf\ntf.keras.utils.plot_model(model, show_shapes=True)","ec07a02f":"model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy', Precision(), Recall()])","6a5d797d":"history = model.fit(X_train,y_train,validation_data=(X_val, y_val),batch_size=64,epochs=epochs,verbose=1)","76eae935":"loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n\nprint('Accuracy  : {:.4f}'.format(accuracy))\nprint('Precision : {:.4f}'.format(precision))\nprint('Recall    : {:.4f}'.format(recall))\nprint('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))","5781649f":"def plot_training_hist(history):\n    '''Function to plot history for accuracy and loss'''\n    \n    fig, ax = plt.subplots(1,2, figsize=(10,4))\n    # first plot\n    ax[0].plot(history.history['accuracy'])\n    ax[0].plot(history.history['val_accuracy'])\n    ax[0].set_title('Model Accuracy')\n    ax[0].set_xlabel('epoch')\n    ax[0].set_ylabel('accuracy')\n    ax[0].legend(['train', 'validation'], loc='best')\n    \n    # second plot\n    ax[1].plot(history.history['loss'])\n    ax[1].plot(history.history['val_loss'])\n    ax[1].set_title('Model Loss')\n    ax[1].set_xlabel('epoch')\n    ax[1].set_ylabel('loss')\n    ax[1].legend(['train', 'validation'], loc='best')\n    \nplot_training_hist(history)","9f16688e":"from sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(model, X_test, y_test):\n    '''Function to plot confusion matrix for the passed model and the data'''\n    \n    sentiment_classes =   ['Negative','Neutral', 'Positive']\n    # use model to do the prediction\n    y_pred = model.predict(X_test)\n    # compute confusion matrix\n    cm = confusion_matrix(np.argmax(y_pred, axis=1),np.argmax(np.array(y_test),axis=1))\n\n    print(pd.Series(np.argmax(np.array(y_test),axis=1)).value_counts())\n    print(pd.Series(np.argmax(y_pred, axis=1)).value_counts())\n    \n    # plot confusion matrix\n    plt.figure(figsize=(8,6))\n    sns.heatmap(cm, cmap=plt.cm.Blues, annot=True, fmt='d', \n                xticklabels=sentiment_classes,\n                yticklabels=sentiment_classes)\n    plt.title('Confusion matrix', fontsize=16)\n    plt.xlabel('Actual label', fontsize=12)\n    plt.ylabel('Predicted label', fontsize=12)\n    \nplot_confusion_matrix(model, X_test, y_test)","a99b58e2":"# Model","794e6bb0":"# def tokenize_pad_sequences(text):","9804cb69":"# Evaluate"}}