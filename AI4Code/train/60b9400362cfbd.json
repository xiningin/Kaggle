{"cell_type":{"a9320065":"code","f73f617e":"code","8b0b44af":"code","f6cc53be":"code","d5d6676e":"code","c5ad1d31":"code","eba41ffc":"code","f7098349":"code","74936b01":"code","6c65aa20":"code","b3d4327b":"code","fb2d0e80":"code","84e3f5d0":"code","2f62c795":"code","317f5a0b":"code","94fc0916":"code","1a8e9dac":"code","f03d032f":"code","c08bdd90":"code","f17fa7ac":"code","dd2477a5":"code","2388ecfd":"code","cb68242c":"code","66fffe6c":"code","578eac76":"code","049ba415":"code","9f66a22e":"code","8e5e01af":"code","3b65f8a4":"code","ca78dd51":"code","3ee16ce9":"code","67be61f7":"code","ecc4db33":"code","8349f59c":"code","dd0fb0ca":"code","e14f318b":"code","62154319":"code","aac9e8ca":"code","5088705a":"code","1118a0bc":"code","a2490581":"code","164d16fa":"code","c9be8352":"code","0471cab8":"code","56839eb4":"code","e296d987":"code","530541dd":"code","8e1df030":"markdown","92602a91":"markdown","b6708fa7":"markdown","7a5eba12":"markdown","0aef12f9":"markdown"},"source":{"a9320065":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f73f617e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","8b0b44af":"df= pd.read_csv(\"\/kaggle\/input\/guess-the-product\/train_set.csv\")","f6cc53be":"df.shape","d5d6676e":"df.head() #to visualize the data","c5ad1d31":"df.info() # to get detailed information ,type of data and check the null values\n# data","eba41ffc":"#to identify unique Vendor Code count\ndf['Vendor_Code'].value_counts().count()","f7098349":"#to identify unique GL_Code\ndf['GL_Code'].unique()","74936b01":"fig_dims = (40, 8)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.countplot(x='Product_Category',data=df)","6c65aa20":"#to identify Product_Category count that we want to predict\ndf['Product_Category'].value_counts().count()","b3d4327b":"df['Product_Category'].value_counts()","fb2d0e80":"fig_dims = (20, 4)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.countplot(x='GL_Code',data=df)","84e3f5d0":"fig_dims = (30, 7)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.boxplot(x=\"Product_Category\", y=\"Inv_Amt\", data=df,palette='rainbow')","2f62c795":"#To apply NLP we have text converted all the string to Lowercase\ndf[\"Item_Description\"]=df[\"Item_Description\"].str.lower()","317f5a0b":"textData=df[\"Item_Description\"]","94fc0916":"import string\ndef remove_punctuation(text):\n    return text.translate(str.maketrans('','',string.punctuation))\ntext_clean=textData.apply(lambda text:remove_punctuation(text))","1a8e9dac":"from nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))","f03d032f":"def stopwords_(text):\n    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\ntext_clean = text_clean.apply(lambda text: stopwords_(text))","c08bdd90":"text_clean.head()","f17fa7ac":"from nltk.stem import WordNetLemmatizer\nlemmatizer=WordNetLemmatizer()\ndef lemma(text):\n    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])","dd2477a5":"import nltk\nfrom nltk.stem import WordNetLemmatizer   \nlemmatizer = WordNetLemmatizer() \ntext_clean=text_clean.apply(lambda text: lemma(text))","2388ecfd":"text_clean.head()","cb68242c":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer()\ntfidf = TfidfVectorizer(stop_words = 'english')","66fffe6c":"tfidf.fit(text_clean)","578eac76":"X = tfidf.transform(text_clean)","049ba415":"text_df = pd.DataFrame(X.toarray())","9f66a22e":"text_df = pd.DataFrame(X.toarray())","8e5e01af":"text_df = pd.DataFrame(X.toarray())","3b65f8a4":"text_df.head()","ca78dd51":"from sklearn import preprocessing\n# encode categorical variables using Label Encoder\n\n# select all categorical variables\ndf_categorical = df[['Vendor_Code','GL_Code']]\ndf_categorical.head()","3ee16ce9":"# apply Label encoder to df_categorical\n\nle = preprocessing.LabelEncoder()\ndf_categorical = df_categorical.apply(le.fit_transform)\ndf_categorical.head()","67be61f7":"df.drop(['Inv_Id','Item_Description','Vendor_Code','GL_Code'], axis=1, inplace=True)\ndf.head()","ecc4db33":"# concat df_categorical with original df\ndf = pd.concat([df_categorical,text_df,df], axis=1)\ndf.head()","8349f59c":"# Importing train-test-split \nfrom sklearn.model_selection import train_test_split","dd0fb0ca":"X = df.drop(['Product_Category'],axis=1)\n\n# Putting response variable to y\ny = df['Product_Category']","e14f318b":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30,random_state = 99)\nX_train.head()","62154319":"# Importing decision tree classifier from sklearn library\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Fitting the decision tree with default hyperparameters, apart from\n# max_depth which is 5 so that we can plot and read the tree.\nClassifier = DecisionTreeClassifier()\nClassifier.fit(X_train, y_train)","aac9e8ca":"Classifier.feature_importances_","5088705a":"# Let's check the evaluation metrics of our default model for train\n\n# Importing classification report and confusion matrix from sklearn metrics\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Making predictions\ny_pred = Classifier.predict(X_train)\n\nprint(confusion_matrix(y_train,y_pred))\nprint(accuracy_score(y_train,y_pred))","1118a0bc":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Making predictions\ny_pred_default = Classifier.predict(X_test)\n\n# Printing confusion matrix and accuracy\nprint(confusion_matrix(y_test,y_pred_default))\nprint(accuracy_score(y_test,y_pred_default))","a2490581":"from sklearn.ensemble import RandomForestClassifier","164d16fa":"Regressor = RandomForestClassifier(n_estimators = 100, random_state = 0)","c9be8352":"Regressor.fit(X_train, y_train) ","0471cab8":"Regressor.feature_importances_","56839eb4":"# Let's check the evaluation metrics of our default model for train\n\n# Importing classification report and confusion matrix from sklearn metrics\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Making predictions\ny_pred = Regressor.predict(X_train)\n\nprint(confusion_matrix(y_train,y_pred))\nprint(accuracy_score(y_train,y_pred))","e296d987":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Making predictions\ny_pred_default = Regressor.predict(X_test)\n\n# Printing confusion matrix and accuracy\nprint(confusion_matrix(y_test,y_pred_default))\nprint(accuracy_score(y_test,y_pred_default))","530541dd":"# Accuracy Achieved is nearly 99.43 %","8e1df030":"# Guess the Product -machine learning model that could predict the product category(Response variable) based on certain features.","92602a91":"# To cross verify the model acurracy result we will apply RandomForestClassifier","b6708fa7":"# Exploratory Data Analysis of variables","7a5eba12":"# Vectorization for item description using NLP","0aef12f9":"# Preprocessing features of the data"}}