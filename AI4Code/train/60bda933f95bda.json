{"cell_type":{"9c736023":"code","dcee9fd5":"code","5a1b87e3":"code","bf555598":"code","579f8319":"code","8b5280e7":"code","9f6b7da3":"code","1b48bc35":"code","f25adcc0":"code","24b5bc8a":"code","863e9bc3":"code","91e1d1c0":"code","33cc139a":"code","aa8b7ade":"code","b1f385a7":"code","77245056":"code","f9bb2c0b":"markdown","72c1b413":"markdown","33e1b3ae":"markdown","82442239":"markdown","f21d2077":"markdown","c70e785a":"markdown","7d709e46":"markdown","3fa11211":"markdown","4fc8957d":"markdown","aa6e1534":"markdown","14980003":"markdown","94d011b8":"markdown","1df2d0d3":"markdown","d5afc1a2":"markdown","2e6d0667":"markdown"},"source":{"9c736023":"!pip install -U layoutparser ","dcee9fd5":"!pip install layoutparser[ocr]","5a1b87e3":"!pip install 'git+https:\/\/github.com\/facebookresearch\/detectron2.git@v0.4#egg=detectron2' ","bf555598":"!git clone https:\/\/github.com\/Layout-Parser\/layout-parser.git\n%cd layout-parser\/","579f8319":"pip install pycocotools","8b5280e7":"def load_coco_annotations(annotations, coco=None):\n    \"\"\"\n    Args:\n        annotations (List):\n            a list of coco annotaions for the current image\n        coco (`optional`, defaults to `False`):\n            COCO annotation object instance. If set, this function will\n            convert the loaded annotation category ids to category names\n            set in COCO.categories\n    \"\"\"\n    layout = lp.Layout()\n\n    for ele in annotations:\n\n        x, y, w, h = ele['bbox']\n\n        layout.append(\n            lp.TextBlock(\n                block = lp.Rectangle(x, y, w+x, h+y),\n                type  = ele['category_id'] if coco is None else coco.cats[ele['category_id']]['name'],\n                id = ele['id']\n            )\n        )\n\n    return layout","9f6b7da3":"import pandas as pd\nimport numpy as np\nimport cv2\nimport random\nimport json\nimport pandas as pd \nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n\nfrom pycocotools.coco import COCO\nimport layoutparser as lp\n","1b48bc35":"imgdir=\"kaggle\/input\/papers-images\/train\/train\"\nimage = cv2.imread('\/kaggle\/input\/papers-images\/train\/train\/PMC3777717_00006.jpg')\nplt.imshow(image)","f25adcc0":"f = open('\/kaggle\/input\/papers-images\/train\/train\/samples.json',)\nthing_classes  = []\ncategory_name_to_id = {}\ndata_annotations=[]\ndata = json.load(f)\n#----Images----\ndata_images=data['images']\n#---annotations-\nfor i in data['annotations']:\n    annot_obj ={\"id\": i['id'],\"image_id\": i['image_id'],\"category_id\":i['category_id'],\n          \"x_min\":i['bbox'][0], #left\n          \"y_min\":i['bbox'][1], #top\n          \"x_max\":i['bbox'][0]+i['bbox'][2], #left+width\n          \"y_max\":i['bbox'][1]+i['bbox'][3] #top+hieght\n         }\n    data_annotations.append(annot_obj) \n#---categories-\nfor i in data['categories']:\n    thing_classes.append(i['name'])\n    category_name_to_id[i['name']]=i['id']\nf.close()\nprint(\"thing_classes=\",thing_classes)\nprint(\"category_name_to_id=\",category_name_to_id)","24b5bc8a":"train_meta = pd.DataFrame(data_images)\ntrain_meta = train_meta[['id', 'file_name', 'width', 'height']]\ntrain_meta = train_meta.rename(columns={\"id\":\"image_id\"})\nprint(\"train_meta size=\",len(train_meta))\ntrain_meta.head(3)","863e9bc3":"train_df = pd.DataFrame(data_annotations)\nprint(\"train_df size=\",len(train_df))\ntrain_df.head(3)","91e1d1c0":"COCO_ANNO_PATH = '\/kaggle\/input\/papers-images\/train\/train\/samples.json'\nCOCO_IMG_PATH  = '\/kaggle\/input\/papers-images\/train\/train'\n\ncoco = COCO(COCO_ANNO_PATH)","33cc139a":"color_map = {\n    'text':   'red',\n    'title':  'blue',\n    'list':   'green',\n    'table':  'yellow',\n    'figure': 'pink',\n}\n\n\nfor image_id in random.sample(coco.imgs.keys(), 1):\n    image_info = coco.imgs[image_id]\n    annotations = coco.loadAnns(coco.getAnnIds([image_id]))\n\n    image = cv2.imread(f'{COCO_IMG_PATH}\/{image_info[\"file_name\"]}')\n    layout = load_coco_annotations(annotations, coco)\n\n    viz = lp.draw_box(image, layout, color_map=color_map)\n    display(viz) # show the results","aa8b7ade":"model = lp.Detectron2LayoutModel('lp:\/\/PubLayNet\/faster_rcnn_R_50_FPN_3x\/config',\n                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n                                 label_map={0: \"text\", 1: \"title\", 2: \"list\", 3:\"table\", 4:\"figure\"})","b1f385a7":"layout_predicted = model.detect(image)\nlp.draw_box(image,\n              [b.set(id=f'{b.type}\/{b.score:.2f}') for b in layout_predicted],\n              color_map=color_map,\n              show_element_id=True, id_font_size=10,\n              id_text_background_color='black',\n              id_text_color='white')","77245056":"text_blocks = lp.Layout([b for b in layout_predicted if b.type==\"figure\"])\n\nlp.draw_box(image,\n              [b.set(id=f'{b.type}\/{b.score:.2f}') for b in text_blocks ],\n              color_map=color_map,\n              show_element_id=True, id_font_size=10,\n              id_text_background_color='black',\n              id_text_color='white')\n","f9bb2c0b":"# Preparing Dataset","72c1b413":"# Load COCO Layout Annotations","33e1b3ae":"# Model Predictions on Loaded Data","82442239":"## Visualizing Layouts","f21d2077":"# Importing Libraries","c70e785a":"# Detecting Layouts","7d709e46":"# **Layout Parsing starter**","3fa11211":"# Install the LayoutParser library","4fc8957d":"If we would like to use the Detectron2 models for layout detection, we might need to run the following command:","aa6e1534":"Layout Parser also comes with supports for OCR functions. In order to use them, you need to install the OCR utils via:","14980003":"# References\n* https:\/\/layout-parser.readthedocs.io\/en\/latest\/notes\/installation.html","94d011b8":"## Understading Dataset","1df2d0d3":"LayoutParser provides various functionalities and deep learning models from different backends.","d5afc1a2":"LayoutParer uses the COCO format to load and virsualize the layout annotation.","2e6d0667":"# Detecting The Figure Part of Our Image"}}