{"cell_type":{"23141e8c":"code","84f87ca8":"code","74828080":"code","40443e1b":"code","85561b74":"code","16991716":"code","ee6efd60":"code","53cd42c1":"code","e3ab0af7":"code","143b8222":"code","052c147d":"code","682b77f4":"code","273f4dd9":"code","26dc9139":"code","a08226ff":"code","8e5724dc":"code","76424d1e":"code","ef27809f":"code","7789d568":"code","8f7399cd":"code","5368353e":"code","d355b776":"code","9c840279":"code","6087b4e7":"code","ad5bb735":"code","de6a82a2":"code","578ff8cb":"code","b26e7871":"code","2d75064b":"code","59ea708f":"code","36d4732e":"markdown","71e02085":"markdown","a91c8f1b":"markdown"},"source":{"23141e8c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score","84f87ca8":"# Load the train data\ntrain_transaction = pd.read_csv(\"..\/input\/ieee-fraud-detection\/train_transaction.csv\")\ntrain_id = pd.read_csv(\"..\/input\/ieee-fraud-detection\/train_identity.csv\")\n","74828080":"# Print the shape and sizee of data\nprint(\"Number of rows in train_transaction data {:,} and number of columns in train_transaction data {:,} \".format(train_transaction.shape[0], train_transaction.shape[1]))\nprint(\"Number of rows in train_id data {:,} and number of columns in train_id data {:,} \".format(train_id.shape[0], train_id.shape[1]))\n","40443e1b":"train_id.head()","85561b74":"# Check for NaN values\ntrain_id.isnull().sum()","16991716":"# Print %age of null values\ntotal_rows = train_id.shape[0]\ncolumns_to_drop = []\nfor cols in train_id.columns:\n  # check null values\n  null_count = train_id[cols].isnull().sum()\n  if null_count > 0:\n    perc_null_values = float(null_count)*100\/total_rows\n    print(\"{} column has {:.3f}% null values\".format(cols, perc_null_values))\n\n    if perc_null_values > 50:\n      columns_to_drop.append(cols)","ee6efd60":"columns_to_drop","53cd42c1":"# drop the columns to drop\ntrain_id.drop(columns_to_drop, axis=1, inplace=True)","e3ab0af7":"# fill  the rest of nan with default values\ntrain_id.fillna(-999, inplace=True)","143b8222":"train_id.info()","052c147d":"# label encode the categorical columns\ncat_cols = [cols for cols in train_id.columns if train_id[cols].dtype == 'object']\n\n# Label Encoder object\nle = LabelEncoder()\nfor col in cat_cols:\n  train_id[col] = train_id[col].astype('str')\n  train_id[col] = le.fit_transform(train_id[col])","682b77f4":"train_id.shape","273f4dd9":"# print percentage of null values in the transaction data\n# Print %age of null values\ntotal_rows = train_transaction.shape[0]\ncolumns_to_drop = []\nfor cols in train_transaction.columns:\n  # check null values\n  null_count = train_transaction[cols].isnull().sum()\n  if null_count > 0:\n    perc_null_values = float(null_count)*100\/total_rows\n    print(\"{} column has {:.3f}% null values\".format(cols, perc_null_values))\n\n    if perc_null_values > 50:\n      columns_to_drop.append(cols)","26dc9139":"len(columns_to_drop)","a08226ff":"# drop the columns to drop\ntrain_transaction.drop(columns_to_drop, axis=1, inplace=True)","8e5724dc":"# Substitute default values in the rest of the null values\ntrain_transaction.fillna(-999, inplace=True)","76424d1e":"# Encode the categorical cols\ncat_cols2 = [cols for cols in train_transaction.columns if train_transaction[cols].dtype == 'object']\nfor cols in cat_cols2:\n  le = LabelEncoder()\n  train_transaction[cols] = train_transaction[cols].astype('str')\n  train_transaction[cols] = le.fit_transform(train_transaction[cols])","ef27809f":"train_transaction.isnull().sum()","7789d568":"train_transaction.head()","8f7399cd":"train_id.head()","5368353e":"# merge both the dataset\nfinal_data = pd.merge(left = train_id, right = train_transaction, on='TransactionID', how='inner')","d355b776":"final_data.head()","9c840279":"# split the dataset into train features and target varaible\nX = final_data.drop('isFraud', axis=1)\ny = final_data['isFraud']","6087b4e7":"X.head()","ad5bb735":"# split the tdata\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","de6a82a2":"xgb_clf = XGBClassifier()\nxgb_clf.fit(X_train, y_train)","578ff8cb":"# Print the accuracy score\nprint(xgb_clf.score(X_test, y_test))","b26e7871":"# Compute ROC AUC Score\nprediction_probability = xgb_clf.predict_proba(X_test)\nprint(roc_auc_score(y_test, prediction_probability[ : , 1]))","2d75064b":"# Compute ROC AUC Score\nprediction = xgb_clf.predict(X_test)\nprint(f1_score(y_test, prediction))","59ea708f":"# print the feature importance\nfeatures = X.columns\nfeature_imp = xgb_clf.feature_importances_\n\nfeat_imp_df = pd.DataFrame({'Features' : features, 'Feature_Importance' : feature_imp}).sort_values(by='Feature_Importance', ascending=False)\n\n# Plot the feature_importance : only top 10\nplt.figure(figsize=(12,10))\nplt.barh(y=feat_imp_df['Features'].iloc[ : 10], width=feat_imp_df['Feature_Importance'].iloc[ : 10])\nplt.xlabel(\"Feature Importance\")\nplt.ylabel(\"Features\")\nplt.show()","36d4732e":"# Data Analysis","71e02085":"# Import Libraries","a91c8f1b":"**Almost every column has NaN values.**"}}