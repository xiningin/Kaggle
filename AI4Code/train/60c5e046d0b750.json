{"cell_type":{"36547519":"code","89af3fe2":"code","6c7b2a00":"code","aa84cd0b":"code","f461e225":"code","059435b6":"code","b16a42fa":"code","0b80ad2c":"code","cf137d37":"code","2c80f3d7":"code","deedb890":"code","7231196e":"code","3126e3e1":"code","6d19de88":"code","6a720cbc":"code","b06379d4":"code","c7948001":"code","5bb92c27":"code","c88f3901":"code","758d389f":"code","5bdb9e36":"code","b46ca602":"code","b825ec2b":"code","c499e689":"code","ad472936":"code","6235f00f":"code","54857863":"code","366dda12":"code","f5f4b6e4":"code","82c52912":"code","94f00b48":"code","61cecf19":"markdown","30e91dca":"markdown","8106e3bc":"markdown","f75042af":"markdown","3811ba93":"markdown","b967019d":"markdown","0d0b3e85":"markdown","bd80302e":"markdown","2c8665b4":"markdown","a076609a":"markdown","c9493e3c":"markdown","8fc2b285":"markdown","1e38442b":"markdown","79418f40":"markdown","fbd63c6e":"markdown","c992c5dc":"markdown"},"source":{"36547519":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom pandas import DataFrame\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nimport datetime as dt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom hpsklearn import HyperoptEstimator\nfrom hpsklearn import any_regressor\nfrom hpsklearn import any_preprocessing\nfrom hyperopt import tpe","89af3fe2":"data=pd.read_csv('..\/input\/walmart-dataretail-analysis\/Walmart_Store_sales.csv')","6c7b2a00":"data.head()","aa84cd0b":"data['Date']=pd.to_datetime(data['Date'])","f461e225":"# which store has the best Weekly _ Sales from this data \ndata[data['Weekly_Sales']==max(data['Weekly_Sales'])]","059435b6":"st=[]\nfor i in range(1,46):\n    df=data[data['Store']==i]['Weekly_Sales'].values\n    st.append(np.std(df))\n    ","b16a42fa":"print('We can see that the maximum standard deviation was in store :', st.index(max(st))+1)","0b80ad2c":"plt.figure(figsize=(18,8))\nsns.barplot(x=[i for i in range(1,46)],y=st)\nplt.xticks(rotation=90)\nplt.show()","cf137d37":"pr=[]\nfor i in range(1,46):\n    df=data[(data['Store']==i) & (data['Date']>dt.datetime(2012, 6, 1)) & (data['Date']<dt.datetime(2012,9,1))]['Weekly_Sales'].values\n    pr.append(np.mean(df))\n    ","2c80f3d7":"plt.figure(figsize=(18,8))\nsns.barplot(x=[i for i in range(1,46)],y=pr)\nplt.xticks(rotation=90)\nplt.show()","deedb890":"hol=data[data['Holiday_Flag']==1]\ngp=hol.groupby('Date').mean()\n","7231196e":"plt.figure(figsize=(18,8))\nsns.barplot(x=gp.index,y=gp['Weekly_Sales'])\nplt.xticks(rotation=90)\nplt.show()","3126e3e1":"data.isna().sum()","6d19de88":"fig=px.line(x='Date',y='Weekly_Sales',data_frame=data,animation_frame='Store')\nfig[\"layout\"].pop(\"updatemenus\") # optional, drop animation buttons\nfig.show()","6a720cbc":"# Working with the store 1 here....\nstore1=data[data['Store']==1][['Date','Weekly_Sales']]\nstore1=store1.set_index('Date')","b06379d4":"model = ARIMA(store1, order=(5,1,0))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())\n# plot residual errors\nresiduals = DataFrame(model_fit.resid)\nresiduals.plot()\nplt.xticks(rotation=90)\nplt.show()\nresiduals.plot(kind='kde')\nplt.show()\nprint(residuals.describe())","c7948001":"X = store1.values\nsize = int(len(X) * 0.66)\ntrain, test = X[0:size], X[size:len(X)]\nhistory = [x for x in train]\npredictions = list()\nfor t in range(len(test)):\n    model = ARIMA(history, order=(6,2,0))\n    model_fit = model.fit(disp=0)\n    output = model_fit.forecast()\n    yhat = output[0]\n    predictions.append(yhat)\n    obs = test[t]\n    history.append(obs)\n    print('predicted=%f, expected=%f' % (yhat, obs))\nerror = mean_squared_error(test, predictions)\nprint('Test MSE: %.3f' % error)","5bb92c27":"# Plotting the Graph\nplt.plot(test)\nplt.plot(predictions, color='red')\nred_patch = mpatches.Patch(color='red', label='The predicted data')\nblue_patch = mpatches.Patch(color='blue', label='The expected data')\nplt.legend(handles=[blue_patch,red_patch])\nplt.show()","c88f3901":"data.head()","758d389f":"data['Date']=pd.to_datetime(data['Date'])","5bdb9e36":"data['Day']=data['Date'].dt.day\ndata['Month']=data['Date'].dt.month\ndata['Year']=data['Date'].dt.year","b46ca602":"data.drop(columns=['Date'],axis=1,inplace=True)","b825ec2b":"data.head()","c499e689":"# define store 1 again since we changed data\nstore1=data[data['Store']==1]","ad472936":"X=store1.drop(columns=['Weekly_Sales'],axis=1).values\ny=store1['Weekly_Sales'].values","6235f00f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","54857863":"reg=LinearRegression()","366dda12":"reg.fit(X_train,y_train)","f5f4b6e4":"pred=reg.predict(X_test)","82c52912":"print('the score using the model is :',mean_squared_error(y_test,pred))","94f00b48":"# Well we got a better score than arima here :)","61cecf19":"### Well from this we can easily see that we get the highest sale on the date of 25th nov 2011 :) on holiday :)","30e91dca":"## Checking if there is any NA values in the data","8106e3bc":"From this graph we can clearly see that the data is seasonal and usually takes a peak arounf December . Let's check out why December is when the sales are the highest in every store ....","f75042af":"Haha so store 14 is too random too :)","3811ba93":"### Over here the red lines is the predicted values and the blue line is the expected lines that we needed .... Close enough .... :)","b967019d":"## since this is seasonal Data Arima Model should work ","0d0b3e85":"We can also see that each of the store have different sales record but seasonality is pretty much the same so safe model will work for each of the store","bd80302e":"## Importing Packages","2c8665b4":"## Let's have some comparisons :)","a076609a":"Store 14 looks like the one with the maximmum weekly sale . Wow (3818686) this is high :p","c9493e3c":"Least deviation was shown bt store 30  :)","8fc2b285":"## Highest Quaterly profit was of store 3 :)","1e38442b":"### Since we can't use Date directly in linear regression i will seperate the data column","79418f40":"### Now let's  try linear regression model which will use the other factors","fbd63c6e":"## Trying out Linear Regression on this data","c992c5dc":"## Average Quaterly Profit Of Different Stores  For 3rd Quater of 2012:)"}}