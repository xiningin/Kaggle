{"cell_type":{"06780f85":"code","c4fdf0ee":"code","58a9f208":"code","778d40ad":"code","f9be5210":"code","4d413be3":"code","15da235b":"code","12796fcd":"code","3668955c":"code","6c87b68c":"code","720ec5a6":"code","ff3048ca":"code","26508850":"code","9b3b1f06":"code","d09e884d":"code","0f7a0b4b":"code","a61053d0":"code","f36b3aa1":"code","fd5f0593":"code","d5c9ffd1":"code","16b9f94e":"code","480785a7":"code","63086c23":"code","ba106e12":"code","4682db8d":"code","5d3ccc1a":"code","992557d6":"code","596f63ff":"markdown","7a5ceaab":"markdown","0cc07afb":"markdown","fda92f38":"markdown","5a01b577":"markdown","99c88b56":"markdown"},"source":{"06780f85":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c4fdf0ee":"!pip install pycaret","58a9f208":"from pycaret.classification import *","778d40ad":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('..\/input\/cusersmarildownloadsgermancsv\/german.csv', delimiter=';', encoding = \"ISO-8859-2\", nrows = nRowsRead)\ndf.dataframeName = 'german.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf.head()","f9be5210":"#Code by Firat Gonen https:\/\/www.kaggle.com\/frtgnn\/pycaret-introduction-classification-regression\n\nclf1 = setup(data = df, \n             target = 'Creditability',\n             numeric_imputation = 'mean',\n             #categorical_features = ['Sex','Embarked'], \n             ignore_features = ['Telephone','Instalment_per_cent','Value_Savings_Stocks'],\n             silent = True)","4d413be3":"compare_models()","15da235b":"#Create a model. Use Catboost, which has a high accuracy. And can apply interpret model function below\n\nCatBoost  = create_model('catboost')","12796fcd":"tuned_catboost = tune_model(CatBoost)","3668955c":"plot_model(estimator = tuned_catboost, plot = 'learning')","6c87b68c":"plot_model(estimator = tuned_catboost, plot = 'auc')","720ec5a6":"plot_model(estimator = tuned_catboost, plot = 'confusion_matrix')","ff3048ca":"#Feature Importance\n\nplot_model(estimator=tuned_catboost, plot='feature')","26508850":"evaluate_model(tuned_catboost)","9b3b1f06":"#This function only supports tree based models for binary classification: et, catboost, rf, xgboost, lightgbm, dt.\n\ninterpret_model(tuned_catboost)","d09e884d":"#Predictions\n\npredict_model(tuned_catboost, data=df)","0f7a0b4b":"#Make a prediction.\n\npredictions = predict_model(tuned_catboost, data=df)\npredictions.head()","a61053d0":"df['Creditability'] = round(predictions['Score']).astype(int)\ndf.to_csv('submission.csv',index=False)\ndf.head()","f36b3aa1":"from pycaret.regression import *","fd5f0593":"#Code by Firat Gonen https:\/\/www.kaggle.com\/frtgnn\/pycaret-introduction-classification-regression\nreg2 = setup(data = df,\n             target = 'Creditability',\n             numeric_imputation = 'mean',\n             #categorical_features = ['Participant_ID', 'GUID', 'Case_Control'],\n            normalize = True,\n             silent = True)","d5c9ffd1":"#Compare Regression models.\n\ncompare_models()","16b9f94e":"PAR = create_model('par')","480785a7":"#Tun the model.\n\ntuned_par = tune_model(PAR)","63086c23":"plot_model(estimator = tuned_par, plot = 'learning')","ba106e12":"#Feature Importance\n\nplot_model(estimator=tuned_par, plot='feature')","4682db8d":"evaluate_model(tuned_par)","5d3ccc1a":"from sklearn.linear_model import PassiveAggressiveRegressor\nfrom sklearn.datasets import make_regression","992557d6":"#Just to illustrate Passive Aggressive Regressor\n\n#https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.PassiveAggressiveRegressor.html\n\nX, y = make_regression(n_features=4, random_state=0)\nregr = PassiveAggressiveRegressor(max_iter=100, random_state=0,\ntol=1e-3)\nregr.fit(X, y)\n\nprint(regr.coef_)\n\nprint(regr.intercept_)\n\nprint(regr.predict([[0, 0, 0, 0]]))","596f63ff":"References (On Scikit-learn)\n\n#Online Passive-Aggressive Algorithms \n\n#<http:\/\/jmlr.csail.mit.edu\/papers\/volume7\/crammer06a\/crammer06a.pdf> K. Crammer, O. Dekel, \n\n#J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)","7a5ceaab":"#For plotting Passive Agressive Regressor AUC and Confusion Matrix: \nValueError: Plot Not Available. Please see docstring for list of available Plots.\n\n#For interpret_model: This function only supports tree based models for binary classification: et, catboost, rf, xgboost, lightgbm, dt.","0cc07afb":"\"The update taken by PA (Passive Agressive) algorithms is aggressive in the sense that even a small loss forces an update of the hypothesis. When using kernels, this property often results in the use of many examples for representing the learned predictor. Thus, the memory requirements imposed when using kernels can be quite demanding. The authors are currently pursuing extensions of the PA framework that operate in the realm of bounded memory constraints.\"\n\nhttps:\/\/jmlr.csail.mit.edu\/papers\/volume7\/crammer06a\/crammer06a.pdf","fda92f38":"![](https:\/\/i.ytimg.com\/vi\/uxGDwyPWNkU\/hqdefault.jpg)youtube.com","5a01b577":"# **<span style=\"color:#DC143C;\">Passive-Aggressive Algorithms<\/span>**\n\n\n\"Passive-Aggressive algorithms are generally used for large-scale learning. It is one of the few \u2018online-learning algorithms\u2018. In online machine learning algorithms, the input data comes in sequential order and the machine learning model is updated step-by-step, as opposed to batch learning, where the entire training dataset is used at once. This is very useful in situations where there is a huge amount of data and it is computationally infeasible to train the entire dataset because of the sheer size of the data.\"\n\n\"Passive-Aggressive algorithms are somewhat similar to a Perceptron model, in the sense that they do not require a learning rate. However, they do include a regularization parameter.\"\n\nPassive-Aggressive algorithms are called so because :\n\n\"PASSIVE: If the prediction is correct, keep the model and do not make any changes. i.e., the data in the example is not enough to cause any changes in the model.\"\n\n\"AGGRESSIVE: If the prediction is incorrect, make changes to the model. i.e., some change to the model may correct it. Understanding the mathematics behind this algorithm is not very simple and is beyond the scope of a single article.\"\n\n\"For practical usage of this algorithm, huge streams of data are required.\"\n\nhttps:\/\/www.geeksforgeeks.org\/passive-aggressive-classifiers\/","99c88b56":"#Passive Agressive Regressor?!!\n\nReally? Passive Agressive Regressor? Any relation issues while they created that algorithm?"}}