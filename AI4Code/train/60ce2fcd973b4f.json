{"cell_type":{"54c030d0":"code","bc84b1b6":"code","46970747":"code","f15879de":"code","6df7a74e":"code","8753afda":"code","290fff7e":"code","49346b31":"code","4de66ad3":"code","1b20438b":"code","d8ca3cba":"code","6f27d8cd":"code","2b276eba":"code","b7ca34b7":"code","54bc7f85":"code","a9958463":"code","8f903865":"code","b74fa719":"code","47ebdc56":"markdown","3677f6de":"markdown","3d416c0c":"markdown","debd67a0":"markdown","a311bf97":"markdown","ad181880":"markdown"},"source":{"54c030d0":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.utils import shuffle\n\nimport re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import LancasterStemmer\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostClassifier\n\nimport keras \nfrom keras.models import Sequential, Model \nfrom keras import layers\nfrom keras.layers import Dense, Dropout, Input, Embedding\nimport time","bc84b1b6":"dataset_cols = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\ndf = pd.read_csv('..\/input\/sentiment140\/training.1600000.processed.noemoticon.csv', header=None, encoding='ISO-8859-1', names=dataset_cols)","46970747":"df.head()","f15879de":"word_bank = []\n\ndef preprocessing(text):\n    review = re.sub('[^a-zA-Z]',' ',text) \n    review = review.lower()\n    review = review.split()\n    ps = LancasterStemmer()\n    all_stopwords = stopwords.words('english')\n    all_stopwords.remove('not')\n    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n    return ' '.join(review)","6df7a74e":"df = shuffle(df,random_state=42)\ndf = df[1:600000]","8753afda":"df['text'] = df['text'].apply(lambda x: preprocessing(x))","290fff7e":"y = df['target']\nle = LabelEncoder()\ny = le.fit_transform(y)","49346b31":"X_train_1, X_test_1, y_train, y_test = train_test_split(df['text'], y, test_size = 0.20, random_state = 45)","4de66ad3":"tfidf = TfidfVectorizer(max_features = 600)\nX_train = tfidf.fit_transform(X_train_1).toarray() \nX_test = tfidf.transform(X_test_1).toarray()","1b20438b":"classifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train) \n\ny_pred = classifier.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","d8ca3cba":"rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nstart_time = time.time()\nrf.fit(X_train, y_train)\nprint(\"Execution Time:\", time.time()-start_time,\"secs\")","6f27d8cd":"y_pred_rf = rf.predict(X_test)\nprint(\"Accuracy:\\n\", accuracy_score(y_test, y_pred_rf))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))","2b276eba":"catb = CatBoostClassifier(verbose=0, n_estimators=100)\ncatb.fit(X_train, y_train)","b7ca34b7":"y_pred_catb = catb.predict(X_test)\ny_pred_catb[y_pred_catb > 0.5] = 1\ny_pred_catb[y_pred_catb <= 0.5] = 0\nprint(\"Accuracy:\\n\", accuracy_score(y_test, y_pred_catb))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_catb))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_catb))","54bc7f85":"y_pred = (y_pred_catb + y_pred_rf)\/2\ny_pred[y_pred > 0.5] = 1\ny_pred[y_pred <= 0.5] = 0\nprint(\"Accuracy:\\n\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","a9958463":"from keras.models import Sequential\nfrom keras.layers import Dense\nmodel = Sequential()\nmodel.add(Dense(512, activation='relu', input_dim=600))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(12, input_dim=8, activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nmodel.summary()","8f903865":"history = model.fit(X_train, y_train, epochs=20, batch_size=32,validation_data=(X_test,y_test))\nloss, accuracy = model.evaluate(X_train, y_train, verbose=False)\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))","b74fa719":"y_pred_new = model.predict(X_test)\ny_pred_nn = np.where(y_pred_new>0.5,1,0)\nprint(\"Accuracy:\\n\", accuracy_score(y_test, y_pred_nn))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nn))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_nn))","47ebdc56":"## **Ensemble Learning**","3677f6de":"## **CAT BOOST**","3d416c0c":"## **Neural Network**","debd67a0":"## **Random Forest**","a311bf97":"# **Sentiment140 dataset with 1.6 million tweets** ","ad181880":"## **Logistic regression**"}}