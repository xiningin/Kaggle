{"cell_type":{"c9370f1e":"code","96d8e202":"code","0a91dcfb":"code","012255a9":"code","1af00033":"code","794160ae":"code","406709a9":"code","d422d20d":"code","99ba609c":"code","ac556fc1":"code","24d172c5":"code","ad23687e":"code","77d42f40":"code","23fa29a8":"code","91902e05":"code","a37d6b63":"code","9d014ae6":"code","25bdfdb3":"code","fa0be40d":"code","63f5efc4":"code","a19709e8":"code","1c379cb3":"code","015c0736":"code","d3b8c436":"code","e69e2b4d":"code","d3e55db2":"code","8bee78f5":"code","4d384787":"code","37ed990a":"code","30a54b19":"code","26051ea3":"code","20321bc4":"markdown","7724fd36":"markdown","3166e3f9":"markdown","ae98033d":"markdown","1909388b":"markdown","305fea2f":"markdown","d9c51db7":"markdown","022f8dee":"markdown","24ab053c":"markdown","1c9f8375":"markdown","1648da86":"markdown","142ce93f":"markdown","4fa56977":"markdown","78ce9078":"markdown","4fba0303":"markdown"},"source":{"c9370f1e":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\nfrom sklearn.metrics import f1_score\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom keras import optimizers\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dropout, Dense, Flatten, GlobalAveragePooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.utils import np_utils\nfrom keras.optimizers import SGD","96d8e202":"from IPython.core.display import display, HTML\nfrom PIL import Image\nfrom io import BytesIO\nimport base64\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nimport tensorflow as tf\nprint(tf.__version__)","0a91dcfb":"main_folder = \"..\/input\/celeba-dataset\/\"\nimages_folder = main_folder + \"img_align_celeba\/img_align_celeba\/\"\n\nexample_pic = images_folder + \"000506.jpg\"\n\ntraining_sample = 10000\nvalidation_sample = 2000\ntest_sample = 2000\nimg_width = 178\nimg_height = 218\nbatch_size = 16\nnum_epochs = 5","012255a9":"df_attr = pd.read_csv(main_folder + 'list_attr_celeba.csv')\ndf_attr.set_index('image_id', inplace=True)\ndf_attr.replace(to_replace=-1, value=0, inplace=True)","1af00033":"df_attr.head(5)","794160ae":"df_attr.describe()","406709a9":"df_attr.columns","d422d20d":"df_attr.isnull().sum()","99ba609c":"df_attr.shape","ac556fc1":"for i,j in enumerate(df_attr.columns):\n    print(i+1, j)","24d172c5":"# load a example image\n\nimg = load_img(example_pic)\nplt.grid(False)\nplt.imshow(img)\ndf_attr.loc[example_pic.split('\/')[-1]][['Smiling','Male',\"Young\"]]","ad23687e":"sns.countplot(df_attr[\"Male\"])\nplt.show()","77d42f40":"df_partition = pd.read_csv(main_folder + \"list_eval_partition.csv\")\ndf_partition.head(5)","23fa29a8":"df_partition.sample(100)","91902e05":"df_partition[\"partition\"].value_counts().sort_index()","a37d6b63":"df_partition.set_index('image_id', inplace=True)\ndf_par_attr = df_partition.join(df_attr[\"Male\"], how=\"inner\")\n\ndf_par_attr.head(5)","9d014ae6":"df_par_attr.shape","25bdfdb3":"def load_reshape_img(fname):\n    img = load_img(fname)\n    x = img_to_array(img)\/255.\n    x = x.reshape((1,)+x.shape)\n    return x","fa0be40d":"def generate_df(partition, attr, num_samples):\n    \n    df_ = df_par_attr[(df_par_attr['partition'] == partition) \n                           & (df_par_attr[attr] == 0)].sample(int(num_samples\/2))\n    df_ = pd.concat([df_,\n                      df_par_attr[(df_par_attr['partition'] == partition) \n                                  & (df_par_attr[attr] == 1)].sample(int(num_samples\/2))])\n\n    # for Train and Validation\n    if partition != 2:\n        x_ = np.array([load_reshape_img(images_folder + fname) for fname in df_.index])\n        x_ = x_.reshape(x_.shape[0], 218, 178, 3)\n        y_ = np_utils.to_categorical(df_[attr],2)\n        \n    # for Test\n    else:\n        x_ = []\n        y_ = []\n\n        for index, target in df_.iterrows():\n            im = cv2.imread(images_folder + index)\n            im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (img_width, img_height)).astype(np.float32) \/ 255.0\n            im = np.expand_dims(im, axis =0)\n            x_.append(im)\n            y_.append(target[attr])\n\n    return x_, y_","63f5efc4":"# generate image generator for data augmentation\n\ndatagen = ImageDataGenerator(rotation_range=30, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n\n# load one image and reshape\n\nimg = load_img(example_pic)\nx = img_to_array(img)\/255.\nx = x.reshape((1,) + x.shape)\n\n# plot 10 augmented images of the loaded image\n\nplt.figure(figsize=(20,10))\nplt.suptitle(\"Data augmentation\", fontsize=28)\n\ni = 0\n\nfor batch in datagen.flow(x, batch_size=1):\n    plt.subplot(3,5,i+1)\n    plt.grid(False)\n    plt.imshow(batch.reshape(218,178, 3))\n    \n    if i==9:\n        break\n    i = i+1\n    \nplt.show()","a19709e8":"# build data generators\n\n# train data\n\nx_train, y_train = generate_df(0, \"Male\", training_sample)\n\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rotation_range=30, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n\ntrain_datagen.fit(x_train)\n\ntrain_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)","1c379cb3":"# validation data\n\nx_valid, y_valid = generate_df(1, \"Male\", validation_sample)","015c0736":"# import inceptionv3 model\n\ninc_model = InceptionV3(weights=\"..\/input\/inceptionv3\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\", include_top=False, input_shape=(img_height,img_width,3))\n\nprint(\"number of layers in the model : \", len(inc_model.layers))","d3b8c436":"x = inc_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\npredictions = Dense(2, activation='softmax')(x)","e69e2b4d":"# creating the final model\n\nmodel_ = Model(inputs=inc_model.input, outputs=predictions)\n\n# lock initial layers to not to be trained\n\nfor layer in model_.layers[:52]:\n    layer.trainable = False\n    \n# compile the model\n\nmodel_.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])","d3e55db2":"# train the model\n\ncheckpointer = ModelCheckpoint(filepath='weights.best.inc.male.hdf5', verbose=1, save_best_only=True)","8bee78f5":"hist = model_.fit_generator(train_generator, validation_data=(x_valid, y_valid), steps_per_epoch=training_sample\/batch_size, epochs=num_epochs, callbacks=[checkpointer], verbose=1)","4d384787":"# plot loss with epochs\n\nplt.figure(figsize=(18,4))\nplt.plot(hist.history['loss'], label='train')\nplt.plot(hist.history['val_loss'], label='validation')\nplt.legend()\nplt.title('loss function')\nplt.show()","37ed990a":"# Plot accuracy through epochs\nplt.figure(figsize=(18, 4))\nplt.plot(hist.history['acc'], label = 'train')\nplt.plot(hist.history['val_acc'], label = 'valid')\nplt.legend()\nplt.title('Accuracy')\nplt.show()","30a54b19":"# load the best model\n\nmodel_.load_weights('weights.best.inc.male.hdf5')","26051ea3":"# test data\n\nx_test, y_test = generate_df(2, 'Male', test_sample)\n\n# generate predictions\n\nmodel_prediction = [np.argmax(model_.predict(feature)) for feature in x_test]\n\n# report test accuracy\n\ntest_accuracy = 100 * (np.sum(np.array(model_prediction)==y_test)\/len(model_prediction))\nprint('model evaluation')\nprint(\"test accuracy : \", test_accuracy)\nprint('f1 score : ', f1_score(y_test, model_prediction))","20321bc4":"We will be using the CelebA Dataset, which includes images of 178 x 218 px.","7724fd36":"\n\nPre-processing Images: Data Augmentation\n\nGenerates Data Augmentation for images.","3166e3f9":"\n\nWith the data generator created and data for validation, we are ready to start modeling.\n\nBuild the Model - Gender Recognition\n\nSet the Model\n","ae98033d":"Let's start with an example: Data Augmentation\n\nThis is how an image will look like after data augmentation (based in the giving parameters below).","1909388b":"**Step 2: Split Dataset into Training, Validation and Test**","305fea2f":"**1.  Data Exploration**","d9c51db7":"The results are pretty good with an accuracy of 91% and an f1-score of nearly 0.9. The outputs are modelled into a DataFrame (refer to the output files).","022f8dee":"\nLoad the attributes of every picture\n\nFile: list_attr_celeba.csv","24ab053c":"\n\nThe top layers (including classification) are not included. These layers will be replaced for the following layers:\n\nadding custom layers\n","1c9f8375":"Now, lets see how the male and female attributes are distributed in the dataset.","1648da86":"\n\n0 =====> training\n\n1 =====> validation\n\n2 =====> testing\n","142ce93f":"The result is a new set of images with modifications from the original one, that allows to the model to learn from these variations in order to take this kind of images during the learning process and predict better never seen images.","4fa56977":"\n\nGenerate Partitions (Train, Validation, Test)","78ce9078":"\n\nmodel evaluation\n","4fba0303":"\n\nJoin the partition and the attributes in the same data frame\n"}}