{"cell_type":{"6f1ee27e":"code","b6cb44fa":"code","0d841461":"code","193a59eb":"code","11433d17":"code","7e48f47f":"code","c32f997f":"code","e68acc9d":"code","41e5dcd0":"code","50f528cc":"code","86abdfab":"code","45c728f9":"code","52eb2741":"code","0910f077":"code","bf566229":"code","1d3fe169":"code","7ea3fa3a":"code","05217132":"code","07021037":"markdown","cd80afc1":"markdown","62d86589":"markdown","8d1f549b":"markdown","c08106e5":"markdown","36571ca9":"markdown","a3e44958":"markdown","69fb3d60":"markdown","9fe92e4a":"markdown","d146ca83":"markdown"},"source":{"6f1ee27e":"%pylab inline\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.layers import Flatten, Conv2D, Activation, Dense, Dropout, MaxPooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nprint(\"tensorflow\", tf.__version__)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport numpy as np\nimport pandas as pd\nimport cv2 # for resizing images\n\n# visulaization package\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport random","b6cb44fa":"DIR = os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray')\nprint(DIR)","0d841461":"train_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/train'\ntest_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/test'\nval_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/val'","193a59eb":"labels = [\"NORMAL\", \"PNEUMONIA\"] # each folder has two subfolders called \"PNEUMONIA\" and \"NORMAL\"\nIMG_SIZE = 50\n\ndef get_data_train(data_dir):\n    data = []\n    for label in labels:\n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n                data.append([new_array, class_num])\n    return np.array(data)","11433d17":"train = get_data_train(train_folder)\ntest = get_data_train(test_folder)\nval = get_data_train(val_folder)","7e48f47f":"listing = []\nfor i in train:\n    if(i[1] == 0):\n        listing.append(\"Normal\")\n    else:\n        listing.append(\"Pneumonia\")\n        \nsns.countplot(listing)","c32f997f":"X_train = []\ny_train = []\n\nX_val = []\ny_val = []\n\nX_test = []\ny_test = []\n\nfor feature, label in train:\n    X_train.append(feature)\n    y_train.append(label)\n\nfor feature, label in test:\n    X_test.append(feature)\n    y_test.append(label)\n    \nfor feature, label in val:\n    X_val.append(feature)\n    y_val.append(label)","e68acc9d":"X_train = np.array(X_train) \/ 255\nX_val = np.array(X_val) \/ 255\nX_test = np.array(X_test) \/ 255","41e5dcd0":"X_test.shape","50f528cc":"X_train = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\ny_train = np.array(y_train)\n\nX_val = X_val.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\ny_val = np.array(y_val)\n\nX_test = X_test.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\ny_test = np.array(y_test)","86abdfab":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=X_train.shape[1:]))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\n\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nhistory = model.fit(X_train, y_train, epochs=25, validation_data=(X_val, y_val), shuffle=True)\nscores = model.evaluate(X_test, y_test)\n\nmodel.save(\"cnn.model\")","45c728f9":"# Scores\nprint(\"Test loss {}\".format(scores[0]))\nprint(\"Test accuracy {}\".format(scores[1]))","52eb2741":"# Visualization\n\nimport matplotlib.pyplot as plt\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\n\nplt.plot(epochs, accuracy, \"b\", label=\"trainning accuracy\")\nplt.plot(epochs, val_accuracy, \"r\", label=\"validation accuracy\")\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, \"b\", label=\"trainning loss\")\nplt.plot(epochs, val_loss, \"r\", label=\"validation loss\")\nplt.legend()\nplt.show()","0910f077":"# predict classes\n\nprediction = model.predict_classes(X_test)\nprediction = prediction.reshape(1, -1)[0]\nprediction[:15]","bf566229":"# correct and incorrect\n# you can check tensorflow website\n\ncorrect = np.nonzero(prediction == y_test)[0]\nincorrect = np.nonzero(prediction != y_test)[0]","1d3fe169":"# Add confusion matrix!!!\n\nreport = classification_report(correct, prediction) # Fehlermedlung correct: 501, prediction 624 (siehe l.28)\nprint(report)    \ncm = confusion_matrix(correct, predictions)\nprint(cm)\nsensitivity = cm[0][0] \/ (cm[0][0] + cm[1][0])\nspecificity = cm[1][1] \/ (cm[0][1] + cm[1][1])\n\nprint(\"Sensitivity:\", sensitivity)\nprint(\"Specificity:\", specificity)\n","7ea3fa3a":"j = 0\nfor i in correct[:6]:\n    plt.subplot(3,2,j+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_test[i].reshape(50,50), cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted Class {},Actual Class {}\".format(prediction[i], y_test[i]))\n    plt.xlabel(labels[prediction[i]])\n    plt.tight_layout()\n    j += 1","05217132":"j = 0\nfor i in incorrect[:6]:\n    plt.subplot(3,2,j+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_test[i].reshape(50,50), cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted Class {},Actual Class {}\".format(prediction[i], y_test[i]))\n    plt.xlabel(labels[prediction[i]])\n    plt.tight_layout()\n    j += 1","07021037":"## Training the model","cd80afc1":"## Setup","62d86589":"## Noramalization","8d1f549b":"## Dataset","c08106e5":"The following notebook is based on ideas from this source:<br>\n[Kaggle - 95% accuracy Chest X-Ray Images (Pneumonia)](https:\/\/www.kaggle.com\/adinishad\/95-accuracy-chest-x-ray-images-pneumonia)","36571ca9":"# Some inccorect visualization","a3e44958":"# Case 2 with Kaggle\nNeural Networks for Health Technology Applications<br>\n**18.02.2021, Group number: 6: Kimmo Per\u00e4l\u00e4, Jorma M\u00e4nnist\u00f6, Riku Isola, Eva Forster**<br>\n[Information Technology](https:\/\/metropolia.fi\/en\/academics\/bachelors-degrees\/information-technology)<br>\n[Metropolia University of Applied Sciences](https:\/\/metropolia.fi\/en)","69fb3d60":"# Visualize some correct","9fe92e4a":"## Reshaping train-, test- and validation-set","d146ca83":"## Introduction\n\nThis report is created for testing out which CNN model would be best to use for detecting chest x-ray pneumonia.\nMain objectives for this task was to achieve at least 90% sensivity and 90% specifity in results. \nWe adjusted these cnn models to get best possible accuracy.\nIn this task we used Paul Mooney's library called Chest X-Ray images (Pneumonia).\nOur main point of this task is to find best model and by comparing and explaining diffrent parts we tell you why we got this result."}}