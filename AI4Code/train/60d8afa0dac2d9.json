{"cell_type":{"2708c0ee":"code","d1a746b2":"code","dc28b101":"code","db0e5d50":"code","20c3ff4c":"code","609ef902":"code","80fb04ec":"code","51e9a4f3":"code","00fb9ccd":"code","00750b4a":"code","9332782d":"code","526cd442":"code","d712516a":"code","2be2873a":"code","76c4f9bc":"code","59d31a84":"code","ec92191e":"code","89c1a90b":"code","830e723f":"code","fad4a39d":"code","da0da2e4":"code","c9699ed1":"code","2af3f619":"code","3801bdd0":"code","10a1128d":"code","5fdafb2b":"code","0dc995cf":"code","92447c41":"code","837dbfd9":"code","b0fb0c6c":"code","264d84c0":"code","6246b61b":"code","ca238ffc":"code","59be7805":"code","cb9a4967":"code","d6dcaf6b":"code","d793e714":"code","0c407ab7":"code","180d3512":"code","05a7c11a":"code","a9a61cb0":"code","3e8c0ec5":"code","0e757d9a":"code","b7dc40e2":"code","2724938f":"code","9a58dd42":"code","44c833cd":"code","6069bdb1":"code","4c89d2e8":"code","691bb254":"code","3e9382c1":"code","8689b948":"code","27258519":"code","91f90cbe":"code","fbf1c63b":"code","3a777469":"code","4c9c5095":"code","cf5324e9":"code","39552feb":"code","d04900cd":"code","42038587":"code","c88ad1de":"code","e06801fe":"code","445d8fd8":"code","67176840":"code","3fe425ab":"code","1dd791b6":"code","97246f13":"code","9429e2e4":"code","c0bb1461":"code","82aaa09d":"code","c41b3ef7":"code","4aed4372":"code","bf72b53f":"code","161a9f0c":"code","85117730":"markdown","7dcf8ae1":"markdown","a41a08ab":"markdown","8011a93e":"markdown","d3b6a96f":"markdown","0ab19bd0":"markdown","7573346c":"markdown","bc40b5fe":"markdown"},"source":{"2708c0ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d1a746b2":"\nimport matplotlib.pyplot as plt","dc28b101":"\nimport tqdm","db0e5d50":"\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom gensim.models import Word2Vec \nfrom gensim.models.doc2vec import TaggedDocument\nfrom gensim.models import Doc2Vec\nfrom sklearn.naive_bayes import GaussianNB\nimport re\nimport spacy\nfrom sklearn.utils import shuffle\n\nfrom keras.utils.np_utils import to_categorical  \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer","20c3ff4c":"\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import precision_score, confusion_matrix, recall_score\nfrom sklearn.metrics import classification_report\n\nfrom xgboost import XGBClassifier","609ef902":"\nimport keras","80fb04ec":"\ndrugsComTrain_raw = pd.read_csv('..\/input\/drugsComTrain_raw.csv')\ndrugsComTest_raw = pd.read_csv('..\/input\/drugsComTest_raw.csv')","51e9a4f3":"\ndrugsComTrain_raw.shape","00fb9ccd":"\n# show number of samples per class\ndrugsComTrain_raw.rating.value_counts()","00750b4a":"\nplt.hist(drugsComTrain_raw.rating)\nplt.show()","9332782d":"\nd = {1: 1, \n     2: 2, 3:2, \n     4: 3, 5: 3,\n     6: 4, 7: 4,\n     8: 5, 9: 5,\n     10: 6}\n\ndrugsComTrain_raw['new_ratings'] = drugsComTrain_raw.rating.map(d)\ndrugsComTest_raw['new_ratings'] = drugsComTest_raw.rating.map(d)","526cd442":"\n# We will  not remove stop words for this case\n'not' in set(stopwords.words('english'))\n","d712516a":"\n# # # https:\/\/www.kaggle.com\/shashanksai\/text-preprocessing-using-python\n# snow = nltk.stem.SnowballStemmer('english')\nall_reviews = []\nfor item in drugsComTrain_raw.review:\n    temp = item\n    temp = temp.lower()\n    cleanr = re.compile('<.*?>')\n    temp = re.sub(cleanr, ' ', temp)\n    temp = re.sub(r'[?|!|\\'|\"|#]',r'',temp)\n    temp = re.sub(r'[.|,|)|(|\\|\/]',r'',temp) \n#     temp = [word for word in temp.split(' ') if word not in set(stopwords.words('english'))]\n    all_reviews.append(temp)\n    \nall_reviews_test = []\nfor item in drugsComTest_raw.review:\n    temp = item\n    temp = temp.lower()\n    cleanr = re.compile('<.*?>')\n    temp = re.sub(cleanr, ' ', temp)\n    temp = re.sub(r'[?|!|\\'|\"|#]',r'',temp)\n    temp = re.sub(r'[.|,|)|(|\\|\/]',r'',temp) \n#     temp = [word for word in temp.split(' ') if word not in set(stopwords.words('english'))]\n    all_reviews_test.append(temp)","2be2873a":"\nX = all_reviews\nY = drugsComTrain_raw.new_ratings\nx_train, x_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)","76c4f9bc":"\nx_test = all_reviews_test\ny_test = drugsComTest_raw.new_ratings","59d31a84":"\nvectorizer = TfidfVectorizer(ngram_range=(1,2))\n\nx_train_vectors = vectorizer.fit_transform(x_train)\nx_valid_vectors = vectorizer.transform(x_valid)\nx_test_vectors = vectorizer.transform(x_test)\n\nselector = SelectKBest(f_classif, k=min(1000, x_train_vectors.shape[1]))\nselector.fit(x_train_vectors, y_train)\nx_train_vectors = selector.transform(x_train_vectors).astype('float32')\n\nx_valid_vectors = selector.transform(x_valid_vectors).astype('float32')\nx_test_vectors = selector.transform(x_test_vectors).astype('float32')","ec92191e":"\nx_train_vectors.shape, y_train.shape","89c1a90b":"\nround(drugsComTrain_raw.new_ratings.value_counts() * 10 \/ drugsComTrain_raw.shape[0])","830e723f":"\nfew_classes = list(map(lambda x: x in list(range(2, 6)), y_train.tolist()))","fad4a39d":"\nmore_classes = list(map(lambda x: x in [1, 6], y_train.tolist()))","da0da2e4":"\nnp.sum(few_classes)","c9699ed1":"\nfew_classes = np.array(few_classes)\nmore_classes = np.array(more_classes)\n\nx_train_few = x_train_vectors[few_classes]\ny_train_few = y_train[few_classes]\n\nx_train_more = x_train_vectors[more_classes]\ny_train_more = y_train[more_classes]","2af3f619":"\nall_x_train = list(x_train_few)\nall_y_train = list(y_train_few)\n\nfor i in range(2):\n    all_x_train.extend(x_train_few)\n    all_y_train.extend(y_train_few)\n    \nall_x_train.extend(x_train_more)\nall_y_train.extend(y_train_more)","3801bdd0":"\nall_x_train = np.concatenate([x_train_more.toarray(), x_train_few.toarray(), x_train_few.toarray(), x_train_few.toarray()], axis=0)\nall_y_train = np.concatenate([y_train_more, y_train_few, y_train_few, y_train_few], axis=0)","10a1128d":"\nall_y_train.shape","5fdafb2b":"\nnew_x_train, new_y_train = shuffle(all_x_train, all_y_train)","0dc995cf":"\nnew_x_train.shape","92447c41":"\n\n# clf = ExtraTreesClassifier(n_estimators=100, random_state=0, class_weight='balanced')\n\n# clf.fit(x_train_vectors, y_train)","837dbfd9":"\n# print('Accuracy of classifier on training set: {:.2f}'.format(clf.score(x_train_vectors, y_train) * 100))\n# print('Accuracy of classifier on test set: {:.2f}'.format(clf.score(x_test_vectors, y_test) * 100))","b0fb0c6c":"# y_pred = clf.predict(x_test_vectors)\n# precision_score(y_test, y_pred, average='macro')","264d84c0":"\n# precision_score(y_test, y_pred, average='micro')","6246b61b":"\n# recall_score(y_test, y_pred, average='macro')","ca238ffc":"\n# recall_score(y_test, y_pred, average='micro')","59be7805":"\n# classification_report(y_test, y_pred2, target_names=[\"class 1\", \"class 2\", \"class 3\", \"class 4\", \"class 5\", \"class 6\"])","cb9a4967":"\n# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n# plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n# plt.title('ExtraTreesClassifier')\n# plt.colorbar()\n# tick_marks = np.arange(1, 11)\n# plt.xticks(tick_marks, np.arange(1, 11))\n# plt.yticks(tick_marks, np.arange(1, 11))","d6dcaf6b":"\n# np.sum(y_pred == y_test) \/ len(y_test)","d793e714":"\nnew_x_train.shape","0c407ab7":"\n# https:\/\/www.kaggle.com\/grfiv4\/plot-a-confusion-matrix\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    \"\"\"\n    given a sklearn confusion matrix (cm), make a nice plot\n\n    Arguments\n    ---------\n    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n\n    target_names: given classification classes such as [0, 1, 2]\n                  the class names, for example: ['high', 'medium', 'low']\n\n    title:        the text to display at the top of the matrix\n\n    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n                  see http:\/\/matplotlib.org\/examples\/color\/colormaps_reference.html\n                  plt.get_cmap('jet') or plt.cm.Blues\n\n    normalize:    If False, plot the raw numbers\n                  If True, plot the proportions\n\n    Usage\n    -----\n    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n                                                              # sklearn.metrics.confusion_matrix\n                          normalize    = True,                # show proportions\n                          target_names = y_labels_vals,       # list of names of the classes\n                          title        = best_estimator_name) # title of graph\n\n    Citiation\n    ---------\n    http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","180d3512":"\nmodel_mlp = keras.models.Sequential()\n\nmodel_mlp.add(keras.layers.Dense(200, input_shape=(1000,)))\nmodel_mlp.add(keras.layers.BatchNormalization())\nmodel_mlp.add(keras.layers.Activation('relu'))\nmodel_mlp.add(keras.layers.Dropout(0.5))\n\nmodel_mlp.add(keras.layers.Dense(300))\nmodel_mlp.add(keras.layers.BatchNormalization())\nmodel_mlp.add(keras.layers.Activation('relu'))\nmodel_mlp.add(keras.layers.Dropout(0.5))\n\nmodel_mlp.add(keras.layers.Dense(100, activation='relu'))\nmodel_mlp.add(keras.layers.Dense(7, activation='sigmoid'))\n\nmodel_mlp.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","05a7c11a":"\nmodel_mlp.summary()","a9a61cb0":"\ny_train_one_hot = to_categorical(new_y_train)","3e8c0ec5":"\ny_valid_one_hot = to_categorical(y_valid)\ny_test_one_hot = to_categorical(y_test)","0e757d9a":"\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=3, min_lr=0.00001)\nhistory = model_mlp.fit(new_x_train, y_train_one_hot, epochs=25, batch_size=64, validation_data=(x_valid_vectors, y_valid_one_hot), callbacks=[reduce_lr])","b7dc40e2":"\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.show()","2724938f":"\ny_pred2 = model_mlp.predict_classes(x_test_vectors)","9a58dd42":"\nclassification_report(y_test, y_pred2, target_names=[\"class 1\", \"class 2\", \"class 3\", \"class 4\", \"class 5\", \"class 6\"])","44c833cd":"\nprint(precision_score(y_test, y_pred2, average='macro'))","6069bdb1":"\nprint(recall_score(y_test, y_pred2, average='macro'))","4c89d2e8":"\ncm2 = confusion_matrix(y_pred=y_pred2, y_true=y_test)\nplot_confusion_matrix(cm           = cm2, \n                      normalize    = False,\n                      target_names = [\"class 1\", \"class 2\", \"class 3\", \"class 4\", \"class 5\", \"class 6\"],\n                      title        = \"Confusion Matrix\")","691bb254":"\nprint('Accuracy = {}'.format(np.sum(y_pred2 == y_test) \/ len(y_test)))","3e9382c1":"\nmodel_mlp2 = keras.models.Sequential()\n\nmodel_mlp2.add(keras.layers.Dense(200, input_shape=(1000,)))\nmodel_mlp2.add(keras.layers.BatchNormalization())\nmodel_mlp2.add(keras.layers.Activation('relu'))\nmodel_mlp2.add(keras.layers.Dropout(0.2))\n\nmodel_mlp2.add(keras.layers.Dense(300))\nmodel_mlp2.add(keras.layers.BatchNormalization())\nmodel_mlp2.add(keras.layers.Activation('relu'))\nmodel_mlp2.add(keras.layers.Dropout(0.2))\n\nmodel_mlp2.add(keras.layers.Dense(100, activation='relu'))\nmodel_mlp2.add(keras.layers.Dense(7, activation='sigmoid'))\n\nmodel_mlp2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","8689b948":"\nreduce_lr2 = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=3, min_lr=0.00001)\nhistory2 = model_mlp2.fit(new_x_train, y_train_one_hot, epochs=25, batch_size=64, validation_data=(x_valid_vectors, y_valid_one_hot), callbacks=[reduce_lr2])","27258519":"\nplt.plot(history2.history['acc'])\nplt.plot(history2.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history2.history['loss'])\nplt.plot(history2.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.show()","91f90cbe":"\ny_pred2_2 = model_mlp2.predict_classes(x_test_vectors)","fbf1c63b":"\nclassification_report(y_test, y_pred2_2, target_names=[\"class 1\", \"class 2\", \"class 3\", \"class 4\", \"class 5\", \"class 6\"])","3a777469":"\nprint(precision_score(y_test, y_pred2_2, average='macro'))","4c9c5095":"\nprint(recall_score(y_test, y_pred2_2, average='macro'))","cf5324e9":"\ncm2_2 = confusion_matrix(y_pred=y_pred2_2, y_true=y_test)\n\nplot_confusion_matrix(cm           = cm2_2, \n                      normalize    = False,\n                      target_names = [\"class 1\", \"class 2\", \"class 3\", \"class 4\", \"class 5\", \"class 6\"],\n                      title        = \"Confusion Matrix\")","39552feb":"\nprint('Accuracy = {}'.format(np.sum(y_pred2_2 == y_test) \/ len(y_test)))","d04900cd":"\nmodel_mlp3 = keras.models.Sequential()\n\nmodel_mlp3.add(keras.layers.Dense(200, input_shape=(1000,)))\nmodel_mlp3.add(keras.layers.Activation('relu'))\n\nmodel_mlp3.add(keras.layers.Dense(300))\nmodel_mlp3.add(keras.layers.Activation('relu'))\n\nmodel_mlp3.add(keras.layers.Dense(100, activation='relu'))\nmodel_mlp3.add(keras.layers.Dense(7, activation='sigmoid'))\n\nmodel_mlp3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","42038587":"\nhistory3 = model_mlp3.fit(new_x_train, y_train_one_hot, epochs=25, batch_size=64, validation_data=(x_valid_vectors, y_valid_one_hot))","c88ad1de":"\nplt.plot(history3.history['acc'])\nplt.plot(history3.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history3.history['loss'])\nplt.plot(history3.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.show()","e06801fe":"\ny_pred2_3 = model_mlp3.predict_classes(x_test_vectors)","445d8fd8":"\nclassification_report(y_test, y_pred2_3, target_names=[\"class 1\", \"class 2\", \"class 3\", \"class 4\", \"class 5\", \"class 6\"])","67176840":"\nprint(precision_score(y_test, y_pred2_3, average='macro'))","3fe425ab":"\nprint(recall_score(y_test, y_pred2_3, average='macro'))","1dd791b6":"\ncm2_3 = confusion_matrix(y_pred=y_pred2_3, y_true=y_test)\n\nplot_confusion_matrix(cm           = cm2_3, \n                      normalize    = False,\n                      target_names = [\"class 1\", \"class 2\", \"class 3\", \"class 4\", \"class 5\", \"class 6\"],\n                      title        = \"Confusion Matrix\")","97246f13":"\nprint('Accuracy = {}'.format(np.sum(y_pred2_3 == y_test) \/ len(y_test)))","9429e2e4":"\ny_valid_pred = model_mlp3.predict_classes(x_valid_vectors)","c0bb1461":"\n\ncm4 = confusion_matrix(y_pred=y_valid_pred, y_true=y_valid)\n\nplot_confusion_matrix(cm           = cm4, \n                      normalize    = False,\n                      target_names = [\"class 1\", \"class 2\", \"class 3\", \"class 4\", \"class 5\", \"class 6\"],\n                      title        = \"Confusion Matrix\")","82aaa09d":"\ntemp = []\nfor i in range(len(x_valid)):\n    if y_valid_pred.tolist()[i] == 6 and y_valid.tolist()[i]==1:\n        temp.append(i)","c41b3ef7":"\ntemp2 = []\nfor i in range(len(x_valid)):\n    if y_valid_pred.tolist()[i] == 1 and y_valid.tolist()[i]==6:\n        temp2.append(i)","4aed4372":"\nprint(len(temp))\nprint(len(temp2))","bf72b53f":"\nind = 9\nx_valid[temp[ind]], y_valid_pred.tolist()[temp[ind]], y_valid.tolist()[temp[ind]]","161a9f0c":"\nind = 11\nx_valid[temp2[ind]], y_valid_pred.tolist()[temp2[ind]], y_valid.tolist()[temp2[ind]]","85117730":"## The last model is the best","7dcf8ae1":"## Start Selecting the model","a41a08ab":"\n## since the rating values are very similar, we can cluster them into 6 categories","8011a93e":"**We will decrease the dropout value**","d3b6a96f":"## MLPClassifier","0ab19bd0":"### Oversampling","7573346c":"## 1. Use tfidf\n## 2. get k best features\n## 3. oversample the minority class\n### We will do tfidf first then oversampling not to affect the result of tfidf","bc40b5fe":"## Explore the data"}}