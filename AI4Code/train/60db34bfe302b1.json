{"cell_type":{"b78e5880":"code","3aac4409":"code","76738412":"code","485d5c3a":"code","fc560797":"code","ea5ad43c":"code","67a5a724":"code","2ba71020":"code","bdd56cae":"code","9d04b1d6":"code","533dc050":"code","e3695e5b":"markdown"},"source":{"b78e5880":"import numpy as np\nimport pandas as pd\n\nimport optuna\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display","3aac4409":"DEBUG = False\n\ntrain = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\nsubmission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\n\nif DEBUG:\n    train = train[:80*10000]","76738412":"def add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n     \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df = pd.get_dummies(df)\n    return df\n\ntrain = add_features(train)\ntest = add_features(test)","485d5c3a":"groups = train.breath_id.values\ngroups = groups.reshape(-1, 80)\ngroups = groups[:,0]\ngroups","fc560797":"targets = train.pressure.values\ntargets = targets.reshape(-1, 80)\ntargets","ea5ad43c":"train.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id'], axis=1)","67a5a724":"RS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)","2ba71020":"train = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","bdd56cae":"EPOCH = 1\nBATCH_SIZE = 1024\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n    kf = GroupKFold(n_splits=5)\n    test_preds = []\n    for fold, (train_idx, test_idx) in enumerate(kf.split(X=train, y=targets, groups=groups)):\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        model = keras.models.Sequential([\n            keras.layers.Input(shape=train.shape[-2:]),\n            keras.layers.Bidirectional(keras.layers.LSTM(300, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(250, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(150, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(100, return_sequences=True)),\n            keras.layers.Dense(50, activation='selu'),\n            keras.layers.Dense(1),\n        ])\n        model.compile(optimizer=\"adam\", loss=\"mae\")\n\n        scheduler = ExponentialDecay(1e-3, 400*((len(train)*0.8)\/BATCH_SIZE), 1e-5)\n        lr = LearningRateScheduler(scheduler, verbose=1)\n\n        #es = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1, mode=\"min\", restore_best_weights=True)\n\n        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr])\n        #model.save(f'Fold{fold+1} RNN Weights')\n        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())","9d04b1d6":"train_pd = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\n\nunique_pressures = train_pd[\"pressure\"].unique()\nsorted_pressures = np.sort(unique_pressures)\ntotal_pressures_len = len(sorted_pressures)\n\ndef find_nearest(prediction):\n    insert_idx = np.searchsorted(sorted_pressures, prediction)\n    if insert_idx == total_pressures_len:\n        # If the predicted value is bigger than the highest pressure in the train dataset,\n        # return the max value.\n        return sorted_pressures[-1]\n    elif insert_idx == 0:\n        # Same control but for the lower bound.\n        return sorted_pressures[0]\n    lower_val = sorted_pressures[insert_idx - 1]\n    upper_val = sorted_pressures[insert_idx]\n    return lower_val if abs(lower_val - prediction) < abs(upper_val - prediction) else upper_val","533dc050":"submission[\"pressure\"] = sum(test_preds)\/5\nsubmission[\"pressure\"] = submission[\"pressure\"].apply(find_nearest)\nsubmission.to_csv('submission.csv', index=False)","e3695e5b":"# Notebooks\/discussions I owe to...\nhttps:\/\/www.kaggle.com\/tolgadincer\/tensorflow-bidirectional-lstm-0-234\n\nhttps:\/\/www.kaggle.com\/abhishek\/always-splitting-data-first\n\nhttps:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/discussion\/274137\n\nThank you."}}