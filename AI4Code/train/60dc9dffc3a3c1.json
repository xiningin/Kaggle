{"cell_type":{"a2d5c20c":"code","3329eeb1":"code","55af0164":"code","4da0e909":"code","c4f5c8ba":"code","828f1751":"code","d76669b7":"code","31fdfc0a":"code","45dfdccd":"code","3fd19bd5":"code","4c7fb726":"code","83a90d61":"code","1b2d952f":"code","a9448758":"code","0ccd1b9a":"code","e9e68250":"code","d6a6d140":"code","d7f06650":"code","45e2d84b":"code","9a6d1750":"code","227096f7":"code","89056b5c":"code","e52618b7":"code","944ceedf":"code","03c119fb":"code","4eb94979":"code","22a4ca3d":"code","9e096a1b":"code","145eb01a":"code","5a052c3d":"code","96bccab7":"code","0da92aa2":"code","721c0770":"code","72a392c4":"code","01e14463":"code","e214297c":"code","821527a0":"code","76672a36":"code","4ece018a":"code","d7acf871":"code","feda5544":"code","b3340ecb":"markdown","8a45f31f":"markdown","75decec7":"markdown","b3cfde6c":"markdown","d4f8328d":"markdown","88f5e9d2":"markdown","cc18c434":"markdown","99881d40":"markdown","abf87aba":"markdown"},"source":{"a2d5c20c":"#import these libraries","3329eeb1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings(\"ignore\")","55af0164":"#Load the dataset we will use this dataset(GP Orders - 4.csv) as it contains correct values ","4da0e909":"\ndf2 = pd.read_csv(\"..\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 5.csv\")\n","c4f5c8ba":"#Understanding the data\ndf2.shape","828f1751":"#Let's see first five values of our data\ndf2.head()","d76669b7":"#Lats five values of our data\ndf2.tail()","31fdfc0a":"df2.shape","45dfdccd":"df2.describe()","3fd19bd5":"#see the column name and if necessary change the name of columns","4c7fb726":"df2.columns","83a90d61":"#change the name of columns for our ease","1b2d952f":"df2.columns = ['order_num', 'order_status', 'book_name', 'order_date', 'city', 'payment_method', 'items', 'weight']","a9448758":"df2.head()","0ccd1b9a":"#Now we check the unique values in our dataset","e9e68250":"df2.nunique()","d6a6d140":"#We can check for the unique values sepratly ","d7f06650":"df2['order_status'].unique()","45e2d84b":"#Info about our data, int64 = represent integer values, object = represent the string value","9a6d1750":"df2.info()","227096f7":"#Data Cleaning","89056b5c":"df2.isnull().sum().sort_values(ascending = False)","e52618b7":"# We see that book_name has 2 missing values and City has 1, Now we locate where exactly these values are in our dataset","944ceedf":"df2[df2['book_name'].isna()]","03c119fb":"df2[df2['city'].isna()]","4eb94979":"#Now we drop these values ","22a4ca3d":"df2.dropna(inplace=True)","9e096a1b":"df2.isnull().sum()","145eb01a":"#Now we see details of order_staus","5a052c3d":"df2.order_status.value_counts()","96bccab7":"#Here we split our orders on the basis of \"\/\"","0da92aa2":"from itertools import chain\n\n# return list from series of comma-separated strings\ndef chainer(s):\n    return list(chain.from_iterable(s.str.split('\/')))\n\n# calculate lengths of splits\nlens = df2['book_name'].str.split('\/').map(len)\n\n# create new dataframe, repeating or chaining as appropriate\ndf2 = pd.DataFrame({'order_num': np.repeat(df2['order_num'], lens),\n                    'order_status': np.repeat(df2['order_status'], lens),\n                    'book_name': chainer(df2['book_name']),\n                    'order_date': np.repeat(df2['order_date'], lens),\n                    'city': np.repeat(df2['city'], lens)})","721c0770":"#Now see our total rows increase from 19187 to 33091","72a392c4":"df2.shape","01e14463":"from matplotlib.pyplot import figure\nfigure(num=None, figsize=(10, 10))\ndf2[df2[\"order_status\"]==\"Completed\"][\"book_name\"].value_counts()[:10].sort_values().plot.barh()\nplt.title(\"Top 10 purchased books\")\nplt.xlabel(\"Number of orders\")\nplt.ylabel(\"Name of books \")\nplt.show()","e214297c":"#Using bar plot","821527a0":"sns.countplot(data = df2, x = 'order_status')","76672a36":"#As we see upper charts did not show the canceled order properly so see it with pie plot","4ece018a":"pal=['#349d6e','#faff00',\"#ff0000\"]\nsns.set_palette(pal)\nplt.figure(figsize=(10,10))\nplt.pie(df2['order_status'].value_counts())\nplt.legend(df2['order_status'].unique(),bbox_to_anchor=(0.00, 1))","d7acf871":"df2['date'] = pd.to_datetime(df2['order_date']).dt.date\ndf2['time'] = pd.to_datetime(df2['order_date']).dt.time\n#other way to do this is bellow\n#data['Date'] = data.Order_Date.apply(lambda x: str(x).split(' ')[0])\n#data['Time'] = data.Order_Date.apply(lambda x: str(x).split(' ')[1])\n","feda5544":"df2.head()","b3340ecb":"# Topics to be covered in this notebook\n\u2022 Which one is the best-selling book? <br>\n\u2022 Visualize order status frequency<br>\n\u2022 Find a correlation between date and time with order status<br>\n\u2022 Find a correlation between city and order status<br>\n\u2022 Find any hidden patterns that are counter-intuitive for a layman<br>\n\u2022 Can we predict number of orders, or book names in advance?<br>","8a45f31f":"# Task 1: Which one is the best-selling book?","75decec7":"# Task 2: Visualize order status frequency","b3cfde6c":"**Observation & tasks so far**\nWe see our data contains 19187 rows\/observation and 5 columns\/variables <br>\nWe rename our columns and gives user friendly name <br>\nWe check the unique values from every column togather and seprately as well <br>\nWe also check the info of our data types","d4f8328d":"# Task 3: correlation between date and time with order status","88f5e9d2":"# Please Upvote if you find the notebook interesting.\n# Follow me & let's rock together \n# Thank you.","cc18c434":"## Next steps <br>\n**-Find a correlation between date and time with order status<br>\n-Find a correlation between city and order status<br>\n-Find any hidden patterns that are counter-intuitive for a layman <br>\n-Can we predict number of orders, or book names in advance? <br>**","99881d40":"### Check the missing values in the data set. If you want to sort the data you cab use this sort_values(ascending = False)  otherwise you can use simple function df2.isnull().sum()","abf87aba":"# We have to follow these steps for this task\n* Load the data set\n* Understanding the data\n* Clean the data and removed null values \n* Split data order that contains multiple order in one order on the basis of \/"}}