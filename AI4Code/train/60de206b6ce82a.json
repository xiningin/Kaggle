{"cell_type":{"d0811763":"code","99a67831":"code","9021d793":"code","5c1b1c9b":"code","61043dc5":"code","91ff7701":"code","dc3e4cee":"code","ced70238":"code","274d3313":"code","166b3b9a":"code","b5b488e7":"code","4c2fa9f5":"code","a1b36789":"code","aaeed9e2":"markdown"},"source":{"d0811763":"import numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport xgboost\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom IPython.display import clear_output\nimport warnings\n\ndef fxn():\n    warnings.warn(\"deprecated\", DeprecationWarning)\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fxn()","99a67831":"df = pd.read_csv(\"..\/input\/maternal-health-risk-data\/Maternal Health Risk Data Set.csv\")","9021d793":"df.head()","5c1b1c9b":"sns.pairplot(df, hue=\"RiskLevel\")\nplt.show()","61043dc5":"plt.figure(figsize=(15,12))\nsns.heatmap(df.corr(), annot=True)\nplt.show()","91ff7701":"print(\"Missing values:\")\nprint(df.isna().sum())","dc3e4cee":"X_dev = df.iloc[:,:-1]\ny_dev = df.iloc[:,-1]","ced70238":"print(\"Number of each label in the dataset:\")\nprint(np.unique(y_dev, return_counts=True))","274d3313":"y_dev[np.where(y_dev == \"low risk\")[0]] = 0\ny_dev[np.where(y_dev == \"mid risk\")[0]] = 1\ny_dev[np.where(y_dev == \"high risk\")[0]] = 2","166b3b9a":"skf = StratifiedKFold(n_splits=10)\nskf.get_n_splits(X_dev, y_dev)\n\n\nfor train_index, val_index in skf.split(X_dev, y_dev.astype(\"category\")):\n    X_train, X_val = X_dev.iloc[train_index], X_dev.iloc[val_index]\n    y_train, y_val = y_dev[train_index], y_dev[val_index]\n    scaler = MinMaxScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_val_scaled = scaler.transform(X_val)\n    \n    model = xgboost.XGBClassifier(n_estimators=750, max_depth=7, eta=0.1, subsample=0.3, colsample_bytree=0.4,objective=\"multi:softmax\",verbosity=0, use_label_encoder=False)\n    model.fit(X_train_scaled, y_train)\n    y_val_hat = model.predict(X_val_scaled)\n    y_prob = model.predict_proba(X_val_scaled)\n    print(\"Accuracy:\")\n    print(accuracy_score(tf.keras.utils.to_categorical(y_val),tf.keras.utils.to_categorical(np.argmax(y_prob,axis=1))))\n    print(\"Confusion matrix:\")\n    sns.heatmap(confusion_matrix(np.asarray(y_val, dtype=int),np.argmax(y_prob,axis=1)), annot=True)\n    plt.show()\n    ","b5b488e7":"def neural_network(input_dim,output_dim,dropout_frac=0.2, number_neurons1=512,number_neurons2=1024,number_neurons3=512):\n    model = Sequential()\n    model.add(Dense(units=number_neurons1, activation='relu', input_dim=input_dim))\n    model.add(Dropout(dropout_frac))  # Preventing overfitting\n    model.add(Dense(units=number_neurons2, activation='relu'))\n    model.add(Dropout(dropout_frac))  # Preventing overfitting\n    model.add(Dense(units=number_neurons3, activation='relu', ))\n    model.add(Dropout(dropout_frac))  # Preventing overfitting\n    model.add(Dense(units=output_dim, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n    \n    return model","4c2fa9f5":"class PlotLosses(tf.keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.i = 0\n        self.x = []\n        self.losses = []\n        self.val_losses = []\n\n        self.fig = plt.figure()\n\n        self.logs = []\n\n    def on_epoch_end(self, epoch, logs={}):\n\n        self.logs.append(logs)\n        self.x.append(self.i)\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n        self.i += 1\n\n        clear_output(wait=True)\n        plt.plot(self.x, self.losses, label=\"loss\")\n        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n        plt.legend()\n        plt.show();\n\nplot_losses = PlotLosses()","a1b36789":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport xgboost\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler\nimport time\n\n\n\nskf = StratifiedKFold(n_splits=10)\n#kf = KFold(n_splits=10)\nskf.get_n_splits(X_dev, y_dev)\n\n\nfor train_index, val_index in skf.split(X_dev, y_dev.astype(\"category\")):\n    y_dev_ohe = tf.keras.utils.to_categorical(y_dev)\n    X_train, X_val = X_dev.iloc[train_index], X_dev.iloc[val_index]\n    y_train, y_val = y_dev_ohe[train_index], y_dev_ohe[val_index]\n    scaler = MinMaxScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_val_scaled = scaler.transform(X_val)\n    \n    model = neural_network(X_train.shape[1],y_dev_ohe.shape[1])\n    training_history = model.fit(X_train_scaled, y_train, \n                             validation_data=(X_val_scaled, y_val), \n                             epochs=150,                  \n                             batch_size=64, callbacks = [plot_losses])\n\n    y_val_hat = model.predict(X_val_scaled)\n    \n\n    print(accuracy_score(np.argmax(y_val,axis=1),np.argmax(y_val_hat,axis=1)))\n    sns.heatmap(confusion_matrix(np.argmax(y_val,axis=1),np.argmax(y_val_hat,axis=1)), annot=True)\n    plt.show()\n    time.sleep(3)\n    ","aaeed9e2":"# <center>Predicting health risks for pregnant patients<\/center>\n### This notebook uses a dataset comprising 1014 patients who have consented to share data such as age, systolic blood pressure, diastolic blood pressure, blood glucose levels, heart rate, body temperature and finally a risk score of having pregnancy complications. The risk is quantified into low, medium and high. In this notebook, we use age, systolic blood pressure, diastolic blood pressure, blood glucose levels, heart rate and body temperature to classify the patients with a low, medium or high risk of having pregnancy complications using XGboost and Neural Networks\n\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/miro.medium.com\/max\/2400\/1*fvqTLSCSJzr0E8fEzIvWHg.jpeg\" alt=\"AI pregnancy\" style=\"height:500px;margin-top:3rem;\"> <\/div>\n"}}