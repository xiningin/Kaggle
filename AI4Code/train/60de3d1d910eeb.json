{"cell_type":{"9dbe73d1":"code","eadadc36":"code","b5479e85":"code","6b55b13d":"code","998493f6":"code","da548159":"code","5c9d37a7":"code","85dc6ac5":"code","2d39f127":"code","e9bfb438":"code","4d9223e7":"code","f229f459":"code","408c62bc":"code","872d2bc1":"code","fd3fe316":"code","9ffb7d4e":"code","773c25be":"code","90d4758e":"code","e0a23470":"code","29611d63":"code","2d605af2":"code","e26128b7":"code","f99a5d82":"code","052c608a":"code","fc718eb5":"code","37268bd5":"code","927b1887":"code","7143368b":"markdown","407bd4b4":"markdown","ca307110":"markdown","e1d21d9d":"markdown","b0817ab1":"markdown","5a2e8399":"markdown","4fe4a74c":"markdown","b538117d":"markdown","d9eca1b5":"markdown","5e64dbea":"markdown","324bcd56":"markdown","390039e8":"markdown","a3859172":"markdown","e9579588":"markdown","e47f5381":"markdown","1fa66155":"markdown","b85d24a3":"markdown","699cb605":"markdown","961e535b":"markdown","a14c0a2e":"markdown","c50778e5":"markdown","428c3b7c":"markdown","d4612e4a":"markdown"},"source":{"9dbe73d1":"import math\nimport numpy as np\nimport pandas as pd\nimport warnings\nimport wandb\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras.layers import StringLookup\n\n#ignore warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","eadadc36":"try:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"api_key\")\n    wandb.login(key=secret_value_0)\n    anony=None\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https:\/\/wandb.ai\/authorize')\n    \nCONFIG = dict(competition = 'VariableSelectionNetworks',_wandb_kernel = 'tensorgirl')","b5479e85":"train = pd.read_csv(\"..\/input\/widsdatathon2022\/train.csv\")\ntest = pd.read_csv(\"..\/input\/widsdatathon2022\/test.csv\")\nprint(\"Number of train samples are\",train.shape)\nprint(\"Number of test samples are\",test.shape)\ncategorical_features = ['State_Factor', 'building_class', 'facility_type']\nNUMERIC_FEATURE_NAMES=['Year_Factor','floor_area','year_built','energy_star_rating','ELEVATION']\nTARGET_FEATURE_NAME = \"site_eui\"\nall_features = ['Year_Factor','State_Factor', 'building_class', 'facility_type','floor_area','year_built','energy_star_rating','ELEVATION','site_eui']\ntrain = train[all_features]","6b55b13d":"def count_plot(feature,num) :\n    plt.figure(figsize=(12,7))\n    count = sns.countplot(y=feature,data=train,color=\"salmon\", facecolor=(0, 0, 0, 0),linewidth=5,edgecolor=sns.color_palette(\"BrBG\", num))\n    count.set_title('Train')\n    plt.show()","998493f6":"count_plot('Year_Factor',6)","da548159":"count_plot('State_Factor',7)","5c9d37a7":"count_plot('building_class',2)\n","85dc6ac5":"plt.figure(figsize=(12,12))\ncount = sns.countplot(y='facility_type',data=train,color=\"salmon\", facecolor=(0, 0, 0, 0),linewidth=5,edgecolor=sns.color_palette(\"BrBG\", 15))\ncount.set_title('Train')\nplt.show()","2d39f127":"#scatter plot\ndef scatter_plot(feature,color):\n    fig = plt.figure(figsize=(12,7))\n    fig.set_facecolor(\"#fff\")\n    sns.scatterplot(data=train, x=feature, y=\"site_eui\",color =color,s=200, alpha = 0.8,ec='white')\n    plt.title(' Floor Area vs site EUI')\n    plt.show()","e9bfb438":"scatter_plot(\"floor_area\",\"darkgoldenrod\")","4d9223e7":"scatter_plot(\"energy_star_rating\",\"seagreen\")","f229f459":"scatter_plot(\"ELEVATION\",\"seagreen\")","408c62bc":"scatter_plot(\"year_built\",\"darkgoldenrod\")","872d2bc1":"fig = plt.figure(figsize=(12,7))\nsns.boxplot(x=\"Year_Factor\", y=\"site_eui\", data=train,palette=sns.color_palette(\"BrBG\"))\n","fd3fe316":"#correlation plot\nplt.figure(figsize=(12,7))\nheatmap = sns.heatmap(train.corr(), vmin=-1, vmax=1, annot=True ,cmap=sns.color_palette(\"BrBG\",4))\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)\n","9ffb7d4e":"# Log Plots to W&B environment\n\ndef create_wandb_scatter(x_data=None, x_name=None, title=None, log=None):\n    '''Create and save scatter plot in W&B Environment.\n    x_data: Pandas Series containing x values\n    x_name: strings containing axis name\n    title: title of the graph\n    log: string containing name of log'''\n    y = \"site_eui\"\n    data = [[x] for x in x_data]\n    data = data.append(y)\n    table = wandb.Table(data=data, columns=[x_name ,y])\n    wandb.log({log : wandb.plot.scatter(table, x_name,y, title=title)})\n\n\n\ntitle = \"Distribution of Numerical features\"\nrun = wandb.init(project='VariableSelectionNetworks', name=title,anonymous=anony,config=CONFIG)\nfor feature in NUMERIC_FEATURE_NAMES:\n   title = \"Distribution of Numerical \"+feature    \n   create_wandb_scatter(x_data=train[feature],x_name=feature , title=title,log=\"scatter\")    \nwandb.finish()\n\n\n\ntitle = \"Countplot Distribution\"\nrun = wandb.init(project='VariableSelectionNetworks', name=title,anonymous=anony,config=CONFIG)    \nfor feature in categorical_features:\n    #fig = countplot_features(train, feature=feature, title = feature + \" countplot distribution\")\n    wandb.log({feature + \" countplot distribution\": fig})\nwandb.finish()","773c25be":"#dropping null values\ntrain = train.dropna()\ntest = test.dropna()\n\n# random sampling to create train and validation data\nrandom_selection = np.random.rand(len(train.index)) <= 0.85\ntrain_data = train[random_selection]\nvalid_data = train[~random_selection]\n\n#converting training and validation data to csv file\ntrain_data_file = \"train_data.csv\"\nvalid_data_file = \"valid_data.csv\"\ntrain_data.to_csv(train_data_file, index=False, header=False)\nvalid_data.to_csv(valid_data_file, index=False, header=False)\n","90d4758e":"# Save train data to W&B Artifacts\nrun = wandb.init(project='VariableSelectionNetworks', name='training_data', anonymous=anony,config=CONFIG) \nartifact = wandb.Artifact(name='training_data',type='dataset')\nartifact.add_file(\".\/train_data.csv\")\n\nwandb.log_artifact(artifact)\nwandb.finish()","e0a23470":"CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n    feature_name: sorted([str(value) for value in list(train[feature_name].unique())])\n    for feature_name in all_features\n    if feature_name\n    not in list(NUMERIC_FEATURE_NAMES + [TARGET_FEATURE_NAME])\n}\n# All features names.\nFEATURE_NAMES = NUMERIC_FEATURE_NAMES + list(\n    CATEGORICAL_FEATURES_WITH_VOCABULARY.keys()\n)\n\n\ndef process(features, target):\n    for feature_name in features:\n        if feature_name in CATEGORICAL_FEATURES_WITH_VOCABULARY:\n            # Cast categorical feature values to string.\n            features[feature_name] = tf.cast(features[feature_name], tf.dtypes.string)\n    \n    return features, target","29611d63":"def get_dataset_from_csv(csv_file_path, shuffle=False, batch_size=128):\n\n    dataset = tf.data.experimental.make_csv_dataset(\n        csv_file_path,\n        batch_size=batch_size,\n        column_names=all_features,\n        label_name=TARGET_FEATURE_NAME,\n        num_epochs=1,\n        header=False,\n        shuffle=shuffle,\n    ).map(process)\n\n    return dataset\n","2d605af2":"\ndef create_model_inputs():\n    inputs = {}\n    for feature_name in FEATURE_NAMES:\n        if feature_name in NUMERIC_FEATURE_NAMES:\n            inputs[feature_name] = layers.Input(\n                name=feature_name, shape=(), dtype=tf.float32\n            )\n        else:\n            inputs[feature_name] = layers.Input(\n                name=feature_name, shape=(), dtype=tf.string\n            )\n    return inputs\n","e26128b7":"\ndef encode_inputs(inputs, encoding_size):\n    encoded_features = []\n    for feature_name in inputs:\n        if feature_name in CATEGORICAL_FEATURES_WITH_VOCABULARY:\n            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n            # Create a lookup to convert a string values to an integer indices.\n            # Since we are not using a mask token nor expecting any out of vocabulary\n            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n            index = StringLookup(\n                vocabulary=vocabulary, mask_token=None, num_oov_indices=0\n            )\n            # Convert the string input values into integer indices.\n            value_index = index(inputs[feature_name])\n            # Create an embedding layer with the specified dimensions\n            embedding_ecoder = layers.Embedding(\n                input_dim=len(vocabulary), output_dim=encoding_size\n            )\n            # Convert the index values to embedding representations.\n            encoded_feature = embedding_ecoder(value_index)\n        else:\n            # Project the numeric feature to encoding_size using linear transformation.\n            encoded_feature = tf.expand_dims(inputs[feature_name], -1)\n            encoded_feature = layers.Dense(units=encoding_size)(encoded_feature)\n        encoded_features.append(encoded_feature)\n    return encoded_features\n","f99a5d82":"\nclass GatedLinearUnit(layers.Layer):\n    def __init__(self, units):\n        super(GatedLinearUnit, self).__init__()\n        self.linear = layers.Dense(units)\n        self.sigmoid = layers.Dense(units, activation=\"sigmoid\")\n\n    def call(self, inputs):\n        return self.linear(inputs) * self.sigmoid(inputs)\n","052c608a":"\nclass GatedResidualNetwork(layers.Layer):\n    def __init__(self, units, dropout_rate):\n        super(GatedResidualNetwork, self).__init__()\n        self.units = units\n        self.elu_dense = layers.Dense(units, activation=\"elu\")\n        self.linear_dense = layers.Dense(units)\n        self.dropout = layers.Dropout(dropout_rate)\n        self.gated_linear_unit = GatedLinearUnit(units)\n        self.layer_norm = layers.LayerNormalization()\n        self.project = layers.Dense(units)\n\n    def call(self, inputs):\n        x = self.elu_dense(inputs)\n        x = self.linear_dense(x)\n        x = self.dropout(x)\n        if inputs.shape[-1] != self.units:\n            inputs = self.project(inputs)\n        x = inputs + self.gated_linear_unit(x)\n        x = self.layer_norm(x)\n        return x\n","fc718eb5":"\nclass VariableSelection(layers.Layer):\n    def __init__(self, num_features, units, dropout_rate):\n        super(VariableSelection, self).__init__()\n        self.grns = list()\n        # Create a GRN for each feature independently\n        for idx in range(num_features):\n            grn = GatedResidualNetwork(units, dropout_rate)\n            self.grns.append(grn)\n        # Create a GRN for the concatenation of all the features\n        self.grn_concat = GatedResidualNetwork(units, dropout_rate)\n        self.softmax = layers.Dense(units=num_features, activation=\"softmax\")\n\n    def call(self, inputs):\n        v = layers.concatenate(inputs)\n        v = self.grn_concat(v)\n        v = tf.expand_dims(self.softmax(v), axis=-1)\n\n        x = []\n        for idx, input in enumerate(inputs):\n            x.append(self.grns[idx](input))\n        x = tf.stack(x, axis=1)\n\n        outputs = tf.squeeze(tf.matmul(v, x, transpose_a=True), axis=1)\n        return outputs\n","37268bd5":"\ndef create_model(encoding_size):\n    inputs = create_model_inputs()\n    feature_list = encode_inputs(inputs, encoding_size)\n    num_features = len(feature_list)\n\n    features = VariableSelection(num_features, encoding_size, dropout_rate)(\n        feature_list\n    )\n\n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(features)\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    return model\n","927b1887":"learning_rate = 0.001\ndropout_rate = 0.15\nbatch_size = 265\nnum_epochs = 20\nencoding_size = 16\n\nmodel = create_model(encoding_size)\nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n    loss='mean_squared_error',metrics=tf.keras.metrics.RootMeanSquaredError('rmse')  \n)\n\n\n# Create an early stopping callback.\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\", patience=5, restore_best_weights=True\n)\n\nprint(\"Start training the model...\")\ntrain_dataset = get_dataset_from_csv(\n    train_data_file, shuffle=True, batch_size=batch_size\n)\nvalid_dataset = get_dataset_from_csv(valid_data_file, batch_size=batch_size)\nmodel.fit(\n    train_dataset,\n    epochs=num_epochs,\n    validation_data=valid_dataset,\n    callbacks=[early_stopping],\n)\nprint(\"Model training finished.\")\n\n","7143368b":"# **<span style=\"color:#e76f51;\">Model Inputs<\/span>**","407bd4b4":"# **<span style=\"color:#e76f51;\">W & B Artifacts<\/span>**\n\nAn artifact as a versioned folder of data.Entire datasets can be directly stored as artifacts .\n\nW&B Artifacts are used for dataset versioning, model versioning . They are also used for tracking dependencies and results across machine learning pipelines.Artifact references can be used to point to data in other systems like S3, GCP, or your own system.\n\nYou can learn more about W&B artifacts [here](https:\/\/docs.wandb.ai\/guides\/artifacts)\n\n![](https:\/\/drive.google.com\/uc?id=1JYSaIMXuEVBheP15xxuaex-32yzxgglV)","ca307110":"# **<span style=\"color:#e76f51;\">Categorical Feature Transformation<\/span>**","e1d21d9d":"# **<span style=\"color:#e76f51;\">Preprocessing<\/span>**","b0817ab1":"# **<span style=\"color:#e76f51;\">Feature Correlation<\/span>**","5a2e8399":"# **<span style=\"color:#e76f51;\">Log Plots to W&B environment<\/span>**","4fe4a74c":"### \ud83c\udfaffloor_area vs site_eui","b538117d":"\n![](https:\/\/drive.google.com\/uc?id=1GqvaYUf35Llup7-ZwkpGiQQSMTSMZrh1)\n\n\n[Image Source](https:\/\/www.news-medical.net\/life-sciences\/How-Could-Microbes-Help-to-Solve-Climate-Change.aspx)\n\n\nClimate change is a globally relevant, urgent, and multi-faceted issue heavily impacted by energy policy and infrastructure. Addressing climate change involves mitigation (i.e. mitigating greenhouse gas emissions) and adaptation (i.e. preparing for unavoidable consequences). Mitigation of GHG emissions requires changes to electricity systems, transportation, buildings, industry, and land use.\n\nAccording to a report issued by the International Energy Agency (IEA), the lifecycle of buildings from construction to demolition were responsible for 37% of global energy-related and process-related CO2 emissions in 2020. Yet it is possible to drastically reduce the energy consumption of buildings by a combination of easy-to-implement fixes and state-of-the-art strategies. For example, retrofitted buildings can reduce heating and cooling energy requirements by 50-90 percent. Many of these energy efficiency measures also result in overall cost savings and yield other benefits, such as cleaner air for occupants. This potential can be achieved while maintaining the services that buildings provide.\n\n# **<span style=\"color:#F7B2B0;\">Goal<\/span>**\n \nThe goal of this competition is to predict the energy consumption using building characteristics and climate and weather variables .\n\n# **<span style=\"color:#F7B2B0;\">Data<\/span>**\n\nThe WiDS Datathon 2022 focuses on a prediction task involving roughly 100k observations of building energy usage records collected over 7 years and a number of states within the United States. The dataset consists of building characteristics (e.g. floor area, facility type etc), weather data for the location of the building (e.g. annual average temperature, annual total precipitation etc) as well as the energy usage for the building and the given year, measured as Site Energy Usage Intensity (Site EUI). Each row in the data corresponds to the a single building observed in a given year. Your task is to predict the Site EUI for each row, given the characteristics of the building and the weather data for the location of the building.\n\n\n**Files**\n> - ``` train.csv``` - the training dataset where the observed values of the Site EUI for each row is provided\n> - ```test.csv``` - the test dataset where we withhold the observed values of the Site EUI for each row. \n> - ```sample_submission.csv``` - a sample submission file in the correct format\n\n**Columns**\n\n> - ```id:``` building id\n\n> - ```Year_Factor:``` anonymized year in which the weather and energy usage factors were observed\n\n> - ```State_Factor:``` anonymized state in which the building is located\n\n> - ```building_class:``` building classification\n\n> - ```facility_type:``` building usage type\n\n> - ```floor_area:``` floor area (in square feet) of the building\n\n> - ```year_built:``` year in which the building was constructed\n\n> - ```energy_star_rating:``` the energy star rating of the building\n\n> - ```ELEVATION:``` elevation of the building location\n\n> - ```january_min_temp:``` minimum temperature in January (in Fahrenheit) at the location of the building\n\n> - ```january_avg_temp:``` average temperature in January (in Fahrenheit) at the location of the building\n\n> - ```january_max_temp:``` maximum temperature in January (in Fahrenheit) at the location of the building\n\n> - ```cooling_degree_days:``` cooling degree day for a given day is the number of degrees where the daily average temperature exceeds 65 degrees Fahrenheit. Each month is summed to produce an annual total at the location of the building.\n\n> - ```heating_degree_days:``` heating degree day for a given day is the number of degrees where the daily average temperature falls under 65 degrees Fahrenheit. Each month is summed to produce an annual total at the location of the building.\n\n> - ```precipitation_inches:``` annual precipitation in inches at the location of the building\n\n> - ```snowfall_inches:``` annual snowfall in inches at the location of the building\n\n> - ```snowdepth_inches:``` annual snow depth in inches at the location of the building\n\n> - ```avg_temp:``` average temperature over a year at the location of the building\n\n> - ```days_below_30F:``` total number of days below 30 degrees Fahrenheit at the location of the building\n\n> - ```days_below_20F:``` total number of days below 20 degrees Fahrenheit at the location of the building\n\n> - ```days_below_10F:``` total number of days below 10 degrees Fahrenheit at the location of the building\n\n> - ```days_below_0F:``` total number of days below 0 degrees Fahrenheit at the location of the building\n\n> - ```days_above_80F:``` total number of days above 80 degrees Fahrenheit at the location of the building\n\n> - ```days_above_90F:``` total number of days above 90 degrees Fahrenheit at the location of the building\n\n> - ```days_above_100F:``` total number of days above 100 degrees Fahrenheit at the location of the building\n\n> - ```days_above_110F:``` total number of days above 110 degrees Fahrenheit at the location of the building\n\n> - ```direction_max_wind_speed:``` wind direction for maximum wind speed at the location of the building. Given in 360-degree compass point directions (e.g. 360 = north, 180 = south, etc.).\n\n> - ```direction_peak_wind_speed:``` wind direction for peak wind gust speed at the location of the building. Given in 360-degree compass point directions (e.g. 360 = north, 180 = south, etc.).\n\n> - ```max_wind_speed:``` maximum wind speed at the location of the building\n\n> - ```days_with_fog:``` number of days with fog at the location of the building\n\n\n# **<span style=\"color:#F7B2B0;\">Evaluation Metric<\/span>**\n\nThe evaluation metric for this competition is Root Mean Squared Error (RMSE). The RMSE is commonly used measure of the differences between predicted values provided by a model and the actual observed values. \n\n","d9eca1b5":"\n### Acknowledgements : \n\nGoogle supported this work by providing Google Cloud credit\n\n### References\n\nhttps:\/\/colab.research.google.com\/github\/keras-team\/keras-io\/blob\/master\/examples\/structured_data\/ipynb\/classification_with_grn_and_vsn.ipynb\n\nhttps:\/\/www.kaggle.com\/kamaljp\/building-energy-usage-edanmodeling\n\n### Work in progress \ud83d\udea7\n\nhttps:\/\/www.kaggle.com\/ccollado7\/wids-complete-eda","5e64dbea":"### \ud83c\udfafYear_Factor vs site_eui","324bcd56":"`building_class:` denotes the kind of building classification - Residential or Commercial .\n\n\ud83d\udccc There are more observations for Residential buildings compared to Commercial buildings .\n","390039e8":"# **<span style=\"color:#e76f51;\">Categorical Features Exploration<\/span>**","a3859172":"### \ud83c\udfafenergy_star_rating vs site_eui","e9579588":"In this tutorial , we will be considering only features which had high feature importance using LightGBM Model\n","e47f5381":"# **<span style=\"color:#e76f51;\">tf.data.Dataset<\/span>**\n\n[Source](https:\/\/www.tensorflow.org\/guide\/data)\n\n# **<span style=\"color:#e76f51;\">\ud83c\udfaftf.data<\/span>**\n\ntf.data API is used for building efficient input pipelines which can handle large amounts of data and perform complex data transformations . tf.data API has provisions for handling different data formats .\n\n<img src=\"https:\/\/storage.googleapis.com\/jalammar-ml\/tf.data\/images\/tf.data.png\" \/>\n\n[Image Source](https:\/\/www.kaggle.com\/jalammar\/intro-to-data-input-pipelines-with-tf-data)\n\nData source is essential for building any input pipeline and tf.data.Dataset.from_tensors() or tf.data.Dataset.from_tensor_slices can be used to construct a dataset from data in memory .The recommended format for the iput data stored in file is TFRecord which can be created using TFRecordDataset() .The different data source formats supported are numpy arrays , python generators , csv files ,image , TFRecords , csv and text files. \n\n<img src=\"https:\/\/storage.googleapis.com\/jalammar-ml\/tf.data\/images\/tf.data-read-data.png\" \/>\n\n[Image Source](https:\/\/www.kaggle.com\/jalammar\/intro-to-data-input-pipelines-with-tf-data)\n\nConstruction of tf.data input pipeline consists of three phases namely Extract , Transform and Load . The extraction involves the loading of data from different file format and converting it in to tf.data.Dataset object .\n\n## **<span style=\"color:#e76f51;\">\ud83c\udfaftf.data.Dataset<\/span>**\n\ntf.data.Dataset is an abstraction introduced by tf.data API and consists of sequence of elements where each element has one or more components . For example , in a tabular data pipeline , an element might be a single training example , with a pair of tensor components representing the input features and its label \n\ntf.data.Dataset can be created using two distinct ways\n\nConstructing a dataset using data stored in memory by a data source\n\nConstructing a dataset from one or more tf.data.Dataset objects by a data transformation\n\n<img src=\"https:\/\/storage.googleapis.com\/jalammar-ml\/tf.data\/images\/tf.data-simple-pipeline.png\" \/>\n\n[Image Source](https:\/\/www.kaggle.com\/jalammar\/intro-to-data-input-pipelines-with-tf-data)\n\n\nBasic input data pipeline constructed using tf.data API consists of the following steps .\n\n\ud83d\udccc Reading input data\n\n\ud83d\udccc Processing multiple epochs using **Dataset.repeat()**\n\n\ud83d\udccc Randomly shuffling using **Dataset.shuffle()**\n\n\ud83d\udccc Batching dataset elements using **Dataset.batch()**\n\nAdditionally preprocessing of dataset can be done using **Dataset.map()** transformation .\n\n\n<img src=\"https:\/\/storage.googleapis.com\/jalammar-ml\/tf.data\/images\/tf.data-pipeline-1.png\" \/>\n\n[Image Source](https:\/\/www.kaggle.com\/jalammar\/intro-to-data-input-pipelines-with-tf-data)\n\nIn the first step, tf.data reads the CSV file and creates a Dataset object representing the dataset. If we're to pass this Dataset to the model, it would take one of the rows in each training iteration. It's important to note that the Dataset object does not make these transformations right away -- if the a dataset is 2 TB in size and the CPU tf.data is running on only has 32GBs of RAM available, we'd be in trouble. The Dataset object acknowledges the processing plan and the transformations required, and then applies them when needed on a batch-by-batch basis.\n\n\n## **<span style=\"color:#e76f51;\">Randomly shuffling using Dataset.shuffle()<\/span>**\n\nDataset.shuffle() transformation shuffles the order of elements in the dataset and uniformly chooses the next element from the buffer.\n\n<img src=\"https:\/\/storage.googleapis.com\/jalammar-ml\/tf.data\/images\/tf.data-pipeline-2.png\" \/>\n\n[Image Source](https:\/\/www.kaggle.com\/jalammar\/intro-to-data-input-pipelines-with-tf-data)\n\n## **<span style=\"color:#e76f51;\">Repeating for several epochs<\/span>**\n\nNow, models are trained over multiple epochs -- with the training dataset being fed to the model in each epoch. So let's tell tf.data that we want to use the Dataset for two epochs. That's done using the repeat() method:\n\n<img src=\"https:\/\/storage.googleapis.com\/jalammar-ml\/tf.data\/images\/tf.data-pipeline-3.png\" \/>\n\n[Image Source](https:\/\/www.kaggle.com\/jalammar\/intro-to-data-input-pipelines-with-tf-data)\n\nYou can see that we now have double the number of rows -- the first half would be epoch #1 and the second half is epoch number #2.\n\n## **<span style=\"color:#e76f51;\">Creating batches using Dataset.batch()<\/span>**\n\n\nThe dataset can be broken down in to stacks or batches of consecutive elements using Dataset.batch() API\n\n<img src=\"https:\/\/storage.googleapis.com\/jalammar-ml\/tf.data\/images\/tf.data-pipeline-4.png\" \/>\n\n[Image Source](https:\/\/www.kaggle.com\/jalammar\/intro-to-data-input-pipelines-with-tf-data)\n\n","1fa66155":"### \ud83c\udfafyear_built vs site_eui","b85d24a3":"`Year_Factor:` is the year in which the weather and energy usage factors were observed . \n\n\ud83d\udccc There are more number of observations for Year6 and Year5 in comparison with other years","699cb605":"`State_Factor:`  is the state in which the building is located .\n\n\ud83d\udccc While state 6 has the highest number of observations and there are very observations for state 10\n","961e535b":"<img src=\"https:\/\/camo.githubusercontent.com\/dd842f7b0be57140e68b2ab9cb007992acd131c48284eaf6b1aca758bfea358b\/68747470733a2f2f692e696d6775722e636f6d2f52557469567a482e706e67\">\n\n> I will be integrating W&B for visualizations and logging artifacts!\n> \n> [Variable Selection Networks](https:\/\/wandb.ai\/usharengaraju\/VariableSelectionNetworks)\n> \n> - To get the API key, create an account in the [website](https:\/\/wandb.ai\/site) .\n> - Use secrets to use API Keys more securely ","a14c0a2e":"# **<span style=\"color:#e76f51;\"> Numerical Features VS Target <\/span>**","c50778e5":"`facility_type:` is the building usage type .\n\n\ud83d\udccc There are more number of observations for 'Multifamily Uncategorized'","428c3b7c":"## **<span style=\"color:#e76f51;\">Feature representation using Keras Preprocessing Layers<\/span>**\n\nFeature representations can be one of the crucial aspect in model developement workflows . It is a experimental process and there is no perfect solution . Keras preprocessing Layers helps us create more flexible preprocessing pipeline where new data transformations can be applied while changing the model architecture .\n\n![](https:\/\/drive.google.com\/uc?id=1248y8JYTwjnxZnIEaTQHr1xV5jUZotLm)\n\n[ImageSource](https:\/\/blog.tensorflow.org\/2021\/11\/an-introduction-to-keras-preprocessing.html)\n\n## **<span style=\"color:#e76f51;\">Keras Preprocessing Layers - Numerical Features<\/span>**\n\nThe Keras preprocessing layers available for numerical features are below \n\n`tf.keras.layers.Normalization`: performs feature-wise normalization of input features.\n  \n`tf.keras.layers.Discretization`: turns continuous numerical features into integer categorical features.\n\n`adapt():`\n\nAdapt is an optional utility function which helps in setting the internal state of layers from input data . adapt() is available on all stateful processing layerrs and it computes mean and variance for the layerrs and stores them as layers weights . adapt() is called before fit() , evaluate or predict()\n\n\n## **<span style=\"color:#e76f51;\">Keras Preprocessing Layers - Categorical Features<\/span>**\n\nThe various keras preprocessing layers available for categorical variables are below .\n\n`tf.keras.layers.CategoryEncoding:` turns integer categorical features into one-hot, multi-hot, or count dense representations.\n\n`tf.keras.layers.Hashing:` performs categorical feature hashing, also known as the \"hashing trick\".\n\n`tf.keras.layers.StringLookup:` turns string categorical values an encoded representation that can be read by an Embedding layer or Dense layer.\n\n`tf.keras.layers.IntegerLookup:` turns integer categorical values into an encoded representation that can be read by an Embedding layer or Dense layer.","d4612e4a":"### \ud83c\udfafELEVATION vs site_eui"}}