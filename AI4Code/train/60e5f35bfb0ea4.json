{"cell_type":{"a974a1b5":"code","1dc0b96d":"code","848c9f7d":"code","bef89e6b":"code","46f2651a":"code","7fa147ef":"code","08bc0eaf":"code","26a8470c":"code","52c942f9":"code","6b990be4":"code","d835e565":"code","2a4ad95c":"code","df63fcb0":"code","35f47f7c":"code","680ad216":"code","79972b8b":"code","d6ea1b6c":"code","e8c51eab":"code","76eefacd":"code","5b130243":"code","8b3cdee3":"code","6bdfaed8":"code","0f844367":"code","f96049ba":"code","56e647ba":"code","33447990":"code","900993f5":"code","588ef894":"code","c7ccd887":"code","9ba3e826":"code","9c4146bf":"code","c8e18152":"code","d1107fdd":"code","9b79e011":"code","6723631a":"code","95050cdb":"code","613474b2":"code","b36a4f76":"code","b0ba0073":"code","2bb609a2":"code","d1cad8e0":"code","73090b81":"code","b4970ea4":"code","5fcee17b":"code","627a0403":"code","a5a01c4a":"code","92d12fbe":"code","f8274beb":"markdown","49afb60d":"markdown","219a5d05":"markdown","ca1fdb2d":"markdown","e25547b7":"markdown","0d9201b3":"markdown","67123f6f":"markdown","ad4968c4":"markdown","b316668d":"markdown","e8632024":"markdown","f54a3523":"markdown","c41a97b9":"markdown","b5bb6fce":"markdown","29d3a68a":"markdown","46cd630f":"markdown","f75006e6":"markdown"},"source":{"a974a1b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1dc0b96d":"import pandas as pd\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.graph_objects as go\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom xgboost import XGBClassifier\nimport time\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\n#from google.colab import files\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier","848c9f7d":"# load the datasets\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n\nprint(\"Train size: {0}\\nTest size: {1}\".format(train.shape,test.shape))","bef89e6b":"train.info()","46f2651a":"aux = train.copy()\nprint(aux.Fare.isnull().sum())","7fa147ef":"plt.hist(train['Fare'],bins=20)","08bc0eaf":"# divide fare column into a range of values\n    cut_points = [0,50,100,150,200]\n    label_names = [\"F1\",\"F2\",\"F3\",\"F4\"]\n    aux[\"Fare_categories\"] = pd.cut(aux[\"Fare\"],\n                                 cut_points,\n                                 labels=label_names)","26a8470c":"# Create dimensions\nembarked_dim = go.parcats.Dimension(values=aux.Embarked, label=\"Embarked\")\n\ngender_dim = go.parcats.Dimension(values=aux.Sex, label=\"Gender\")\n\nclass_dim = go.parcats.Dimension(\n    values=aux.Pclass,\n    categoryorder='category ascending', label=\"Class\"\n)\n\nfare_dim = go.parcats.Dimension(values=aux.Fare_categories, label=\"Fare_categories\")\n\nsurvival_dim = go.parcats.Dimension(\n    values=aux.Survived, label=\"Outcome\", categoryarray=[0, 1], \n    ticktext=['perished', 'survived']\n)\n\n# Create parcats trace\ncolor = aux.Survived\ncolorscale = [[0, 'lightsteelblue'], [1, 'mediumseagreen']]\n\nfig = go.Figure(data = [go.Parcats(dimensions=[gender_dim, class_dim, fare_dim, survival_dim],\n        line={'color': color, 'colorscale': colorscale},\n        hoveron='color', hoverinfo='all',\n        labelfont={'size': 18, 'family': 'Times'},\n        tickfont={'size': 16, 'family': 'Times'},bundlecolors=True, \n        arrangement='freeform')])\nfig.update_layout(width=800,height=500)\n\nfig.show()","52c942f9":"aux['Age'].isnull().sum()\/aux.shape[0]","6b990be4":"aux['title'] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n\naux['title'].unique()","d835e565":"newtitles={\n    \"Capt\":       \"Officer\",\n    \"Col\":        \"Officer\",\n    \"Major\":      \"Officer\",\n    \"Jonkheer\":   \"Royalty\",\n    \"Don\":        \"Royalty\",\n    \"Sir\" :       \"Royalty\",\n    \"Dr\":         \"Officer\",\n    \"Rev\":        \"Officer\",\n    \"Countess\":   \"Royalty\",\n    \"Dona\":       \"Royalty\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Royalty\"\n    }\n\naux['title'] = aux.title.map(newtitles)","2a4ad95c":"# Create dimensions\nembarked_dim = go.parcats.Dimension(values=aux.Embarked, label=\"Embarked\")\n\ngender_dim = go.parcats.Dimension(values=aux.Sex, label=\"Gender\")\n\nclass_dim = go.parcats.Dimension(\n    values=aux.Pclass,\n    categoryorder='category ascending', label=\"Class\"\n)\n\ntitle_dim = go.parcats.Dimension(values=aux.title, label=\"Title\")\n\nsurvival_dim = go.parcats.Dimension(\n    values=aux.Survived, label=\"Outcome\", categoryarray=[0, 1], \n    ticktext=['perished', 'survived']\n)\n\n# Create parcats trace\ncolor = aux.Survived\ncolorscale = [[0, 'lightsteelblue'], [1, 'mediumseagreen']]\n\nfig = go.Figure(data = [go.Parcats(dimensions=[gender_dim, class_dim, title_dim, survival_dim],\n        line={'color': color, 'colorscale': colorscale},\n        hoveron='color', hoverinfo='all',\n        labelfont={'size': 18, 'family': 'Times'},\n        tickfont={'size': 16, 'family': 'Times'},bundlecolors=True, \n        arrangement='freeform')])\nfig.update_layout(width=800,height=500)\n\nfig.show()","df63fcb0":"aux.groupby(['title','Sex']).Age.mean()","35f47f7c":"def newage (cols):\n    title=cols[0]\n    Sex=cols[1]\n    Age=cols[2]\n    if pd.isnull(Age):\n        if title=='Master' and Sex==\"male\":\n            return 4.57\n        elif title=='Miss' and Sex=='female':\n            return 21.8\n        elif title=='Mr' and Sex=='male': \n            return 32.37\n        elif title=='Mrs' and Sex=='female':\n            return 35.72\n        elif title=='Officer' and Sex=='female':\n            return 49\n        elif title=='Officer' and Sex=='male':\n            return 46.56\n        elif title=='Royalty' and Sex=='female':\n            return 40.50\n        else:\n            return 42.33\n    else:\n        return Age","680ad216":"aux['Age'] = aux[['title','Sex','Age']].apply(newage, axis=1)\nnp.dtype(aux['Age'])","79972b8b":"aux['Ticket'].isnull().sum()","d6ea1b6c":"aux[\"Ticket\"].unique()","e8c51eab":"## Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X. \nTicket = []\nfor i in list(aux.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) # Take prefix\n    else:\n        Ticket.append(\"X\")\n        \naux[\"Ticket1\"] = Ticket\naux[\"Ticket1\"].unique()\n#aux[\"Ticket1\"].unique().shape","76eefacd":"aux2 = test.copy()\n\n## Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X. \nTicket = []\nfor i in list(aux2.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) # Take prefix\n    else:\n        Ticket.append(\"X\")\n        \naux2[\"Ticket1\"] = Ticket\naux2[\"Ticket1\"].unique()\n#aux2[\"Ticket1\"].unique().shape","5b130243":"# Create dimensions\nembarked_dim = go.parcats.Dimension(values=aux.Embarked, label=\"Embarked\")\n\ngender_dim = go.parcats.Dimension(values=aux.Sex, label=\"Gender\")\n\nclass_dim = go.parcats.Dimension(\n    values=aux.Pclass,\n    categoryorder='category ascending', label=\"Class\"\n)\n\nticket_dim = go.parcats.Dimension(values=aux.Ticket1, label=\"Ticked1\")\n\nsurvival_dim = go.parcats.Dimension(\n    values=aux.Survived, label=\"Outcome\", categoryarray=[0, 1], \n    ticktext=['perished', 'survived']\n)\n\n# Create parcats trace\ncolor = aux.Survived\ncolorscale = [[0, 'lightsteelblue'], [1, 'mediumseagreen']]\n\nfig = go.Figure(data = [go.Parcats(dimensions=[gender_dim, class_dim, ticket_dim, survival_dim],\n        line={'color': color, 'colorscale': colorscale},\n        hoveron='color', hoverinfo='all',\n        labelfont={'size': 18, 'family': 'Times'},\n        tickfont={'size': 16, 'family': 'Times'},bundlecolors=True, \n        arrangement='freeform')])\nfig.update_layout(width=800,height=500)\n\nfig.show()","8b3cdee3":"def create_dummies(df,column_name):\n    # drop_first = True to avoid colinearity\n    dummies = pd.get_dummies(df[column_name],\n                             prefix=column_name,\n                             drop_first=True)\n    df = pd.concat([df,dummies],axis=1)\n    return df","6bdfaed8":"#Custom Transformer that extracts columns passed as argument to its constructor \nclass FeatureSelector(BaseEstimator, TransformerMixin ):\n  #Class Constructor \n  def __init__( self, feature_names ):\n    self.feature_names = feature_names \n    \n  #Return self nothing else to do here    \n  def fit( self, X, y = None ):\n    return self \n    \n  #Method that describes what we need this transformer to do\n  def transform(self, X, y = None):\n    return X[self.feature_names]","0f844367":"#converts certain features to categorical\nclass CategoricalTransformer(BaseEstimator, TransformerMixin):\n  def __init__(self, model=0):\n    \"\"\"Class constructor method that take: \n    model: \n      - 0: Sex column (categorized), Pclass (raw)\n      - 1: Sex column (get_dummies(drop_first=True)), Pclass (raw)\n      - 2: Sex column (get_dummies(drop_first=True)), Pclass (get_dummies(drop_first=False))\n      - 3: Sex column (get_dummies(drop_first=True)), Pclass (raw), Age (get_dummies(drop_first=False))\n      - 4: Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (categorized)\n      - 5: Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n      - 6: New Sex column (get_dummies(drop_first=False)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n      - 7: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n      - 8: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Family_Size\n      - 9: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Family_Size, Embarked (get_dummies(drop_first=False))\n      - 10: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Fare (get_dummies(drop_first=False))\n      - 11: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False)), Fare (get_dummies(drop_first=False))\n      - 12: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False)), Fare2 (scaled)\n      - 13: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False)), ticket(encoded) \n      - 14: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False)), ticket(get_dummies(drop_first=True)) \n      - 15: genderModel(get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n    \"\"\"\n    self.model = model\n\n  #Return self nothing else to do here    \n  def fit( self, X, y = None ):\n    return self \n\n  def create_dummies(self, df, column_name, drop_first_col):\n    \"\"\"Create Dummy Columns from a single Column\n    \"\"\"\n    dummies = pd.get_dummies(df[column_name], prefix=column_name, drop_first=drop_first_col)\n    return dummies\n    \n  def apply_one_hot_encoder(self, df_fit, df_transform, col):\n      \n    labeler = LabelEncoder()\n    labeler.fit( df_fit[col] )    \n  \n    npa_encoded_fit = labeler.transform( df_fit[col] )\n    npa_encoded = labeler.transform( df_transform[col] )\n      \n    encoder = OneHotEncoder( categories='auto', drop='first', dtype=np.uint8 )   \n    encoder.fit( npa_encoded_fit.reshape(-1,1) )\n      \n    npa_hot = encoder.transform( npa_encoded.reshape(-1,1) )   \n    df_hot = pd.DataFrame( npa_hot.toarray(), index=df_transform.index )\n      \n    cols = [ col + '_' + str(num) for num in df_hot.columns.tolist() ]\n    df_hot.columns = cols\n      \n    return df_hot\n  \n  def apply_encoder(self, df_fit, df_transform, col):\n    labeler = LabelEncoder()\n    labeler.fit( df_fit[col] )    \n  \n    npa_encoded = labeler.transform( df_transform[col] )\n      \n    df_encoded = pd.DataFrame( npa_encoded, columns=[col], index=df_transform.index)\n        \n    return df_encoded\n\n  def process_family(self, df):\n         \n    # create sex column\n    df[\"Title\"] = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n\n    titles = {\n        \"Mr\" :         \"man\",\n        \"Mme\":         \"woman\",\n        \"Ms\":          \"woman\",\n        \"Mrs\" :        \"woman\",\n        \"Master\" :     \"boy\",\n        \"Mlle\":        \"woman\",\n        \"Miss\" :       \"woman\",\n        \"Capt\":        \"man\",\n        \"Col\":         \"man\",\n        \"Major\":       \"man\",\n        \"Dr\":          \"man\",\n        \"Rev\":         \"man\",\n        \"Jonkheer\":    \"man\",\n        \"Don\":         \"man\",\n        \"Sir\" :        \"man\",\n        \"Countess\":    \"woman\",\n        \"Dona\":        \"woman\",\n        \"Lady\" :       \"woman\"\n    }\n    \n    df[\"Sex\"]    = df[\"Title\"].map(titles)\n\n    # get surname\n    df[\"Surname\"]    = df[\"Name\"].str.extract('([A-Za-z]*),.',expand=False)\n\n    # if man: no group\n    df.loc[df[\"Sex\"]    == 'man', 'Surname'] = 'NoGroup'\n\n    # if alone: no group\n    df['SurnameFreq'] = df['Surname'].map(df['Surname'].value_counts().to_dict())\n    df.loc[df[\"SurnameFreq\"] <= 1, 'Surname'] = 'NoGroup'\n    \n    df.loc[ df[\"Surname\"] != 'NoGroup', 'Surname'] = 'woman-child-groups'\n\n    if self.model == 15:\n      # encode\n      df_encoded = self.create_dummies(df, \"Surname\", True)\n      return df_encoded\n    else:\n      return None\n\n  # need column survived\n  def process_survivalRate(self, df): \n    ## survival family rate\n    # man and loners dies\n    df['SurvivalRate'] = 0\n  \n    # survival family rate = mean of survived status in each worman-boy-family group\n    surnames_list = df.Surname.unique().tolist()\n    surnames_list.remove('NoGroup')\n    for s in surnames_list:\n      df.loc[ df['Surname'] == s, 'SurvivalRate'] = df[ df['Surname'] == s].Survived.mean()\n\n    # adjust survival rates for use on training set \n    # discount yourself\n    #df['SurvivalRateAjusted'] = (df['SurvivalRate']*df['SurnameFreq'] - df['Survived']) \/ (df['SurnameFreq'] - 1)\n\n    if self.model == 15:\n      return df\n    else:\n      return None\n\n  def process_family_size(self, df):\n    df[\"Title\"] = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n    titles = {\n        \"Mr\" :         \"man\",\n        \"Mme\":         \"woman\",\n        \"Ms\":          \"woman\",\n        \"Mrs\" :        \"woman\",\n        \"Master\" :     \"boy\",\n        \"Mlle\":        \"woman\",\n        \"Miss\" :       \"woman\",\n        \"Capt\":        \"man\",\n        \"Col\":         \"man\",\n        \"Major\":       \"man\",\n        \"Dr\":          \"man\",\n        \"Rev\":         \"man\",\n        \"Jonkheer\":    \"man\",\n        \"Don\":         \"man\",\n        \"Sir\" :        \"man\",\n        \"Countess\":    \"woman\",\n        \"Dona\":        \"woman\",\n        \"Lady\" :       \"woman\"\n    } \n\n    # new gender: man, woman, boy\n    df[\"Gender\"] = df[\"Title\"].map(titles)\n\n    # family surname\n    df[\"family\"] = df[\"Name\"].str.extract('([A-Za-z]+)\\,',expand=False)\n\n    # count the number of boy and women by family\n    boy_women = df[df[\"Gender\"] != \"man\"].groupby(by=[\"family\"])[\"Name\"].agg(\"count\")\n\n    # fill with zero that passengers are traveling alone or with family without boy and women\n    df[\"family_size\"] = df[\"family\"].map(boy_women).fillna(0.0)\n\n    if self.model in [8,9]:\n      return pd.DataFrame(df[\"family_size\"],columns=[\"family_size\"])\n    else:\n      return None\n\n  def process_sex(self, df):\n    df[\"Title\"] = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n    titles = {\n        \"Mr\" :         \"man\",\n        \"Mme\":         \"woman\",\n        \"Ms\":          \"woman\",\n        \"Mrs\" :        \"woman\",\n        \"Master\" :     \"boy\",\n        \"Mlle\":        \"woman\",\n        \"Miss\" :       \"woman\",\n        \"Capt\":        \"man\",\n        \"Col\":         \"man\",\n        \"Major\":       \"man\",\n        \"Dr\":          \"man\",\n        \"Rev\":         \"man\",\n        \"Jonkheer\":    \"man\",\n        \"Don\":         \"man\",\n        \"Sir\" :        \"man\",\n        \"Countess\":    \"woman\",\n        \"Dona\":        \"woman\",\n        \"Lady\" :       \"woman\"\n    }\n    \n    if self.model == 0:\n      df[\"Sex\"] = pd.Categorical(df.Sex).codes\n      return pd.DataFrame(df[\"Sex\"],columns=[\"Sex\"])\n    elif self.model in [1,2,3,4,5]:  \n      sex_dummies = self.create_dummies(df,\"Sex\",True)\n      return sex_dummies\n    elif self.model == 6:\n      df[\"Sex\"] = df[\"Title\"].map(titles)\n      sex_dummies = self.create_dummies(df,\"Sex\",False)\n      return sex_dummies\n    elif self.model in [7,8,9,10,11,12,13,14]:\n      df[\"Sex\"] = df[\"Title\"].map(titles)\n      sex_dummies = self.create_dummies(df,\"Sex\",False)\n      sex_dummies.drop(labels=\"Sex_woman\",axis=1,inplace=True)\n      return sex_dummies\n    else:\n      return None\n\n  def process_embarked(self, df):\n    if self.model in [0,1,2,3,8,10]:\n      return None\n    elif self.model == 4:\n      # fill null values using the mode\n      df[\"Embarked\"].fillna(\"S\",inplace=True)\n      df[\"Embarked\"] = pd.Categorical(df.Embarked).codes\n      return pd.DataFrame(df[\"Embarked\"],columns=[\"Embarked\"])\n    elif self.model in [5,6,7,9,11,12,13,14,15]:\n      df[\"Embarked\"].fillna(\"S\",inplace=True)\n      embarked_dummies = self.create_dummies(df,\"Embarked\",False)\n      return embarked_dummies\n\n  def process_ticket(self, df):\n    ## Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X. \n\n    # extracting prefic from fit df\n    Ticket = []\n    for i in list(train.Ticket):\n      if not i.isdigit():\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) # Take prefix\n      else:\n        Ticket.append(\"X\")\n        \n    train[\"Ticket\"] = Ticket\n\n    Ticket = []\n    for i in list(test.Ticket):\n      if not i.isdigit():\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) # Take prefix\n      else:\n        Ticket.append(\"X\")\n        \n    test[\"Ticket\"] = Ticket\n\n    #  extracting prefic from transform df\n    Ticket = []\n    for i in list(df.Ticket):\n      if not i.isdigit():\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) # Take prefix\n      else:\n        Ticket.append(\"X\")\n        \n    df[\"Ticket\"] = Ticket\n\n    if self.model == 13:\n      ticket_encoded = self.apply_encoder(pd.concat([train, test], sort=False), df, \"Ticket\")\n      return ticket_encoded\n    elif self.model == 14:\n      ticket_dummyfied = self.apply_one_hot_encoder(pd.concat([train, test], sort=False), df, \"Ticket\")\n      return ticket_dummyfied\n    else:\n      return None\n\n  #Transformer method we wrote for this transformer \n  def transform(self, X , y = None ):\n    df = X.copy()\n    sex = self.process_sex(df)\n    embarked = self.process_embarked(df)\n    family_size = self.process_family_size(df)\n    ticket = self.process_ticket(df)\n    genderModel = self.process_family(df)\n\n    if self.model in [0,1,2,3]:\n      return sex\n    elif self.model in [4,5,6,7,11,12]:\n      return pd.concat([sex,embarked],axis=1)\n    elif self.model == 8:\n      return pd.concat([sex,family_size],axis=1)\n    elif self.model == 9:\n      return pd.concat([sex,family_size,embarked],axis=1)\n    elif self.model == 10:\n      return pd.concat([sex],axis=1)\n    elif self.model in [13, 14]:\n      return pd.concat([sex,embarked,ticket],axis=1) \n    elif self.model == 15:\n      return pd.concat([genderModel,embarked],axis=1)   \n    else:\n      return None","f96049ba":"# for validation purposes only\nselect = FeatureSelector(train.select_dtypes(include=[\"object\"]).columns).transform(train)\n\n# change the value of model 0,1,2,3,....9\nmodel = CategoricalTransformer(model=15)\ndf_cat = model.transform(select)\ncat_cols_final = df_cat.columns\ndf_cat.head()","56e647ba":"cat_cols_final","33447990":"# converts certain features to numerical \nclass NumericalTransformer(BaseEstimator, TransformerMixin):\n  def __init__(self, model=0):\n    \"\"\"Class constructor method that take: \n    model: \n      - 0: Sex column (categorized), Pclass (raw)\n      - 1: Sex column (get_dummies(drop_first=True)), Pclass (raw)\n      - 2: Sex column (get_dummies(drop_first=True)), Pclass (get_dummies(drop_first=False))\n      - 3: Sex column (get_dummies(drop_first=True)), Pclass (raw), Age (get_dummies(drop_first=False))\n      - 4: Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (categorized)\n      - 5: Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n      - 6: New Sex column (get_dummies(drop_first=False)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n      - 7: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n      - 8: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Family_Size\n      - 9: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Family_Size, Embarked (get_dummies(drop_first=False))\n      - 10: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Fare (get_dummies(drop_first=False))\n      - 11: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False)), Fare (get_dummies(drop_first=False))\n      - 12: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False)), Fare2 (scaled)\n      - 13: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False)), ticket(encoded) \n      - 14: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False)), ticket(get_dummies(drop_first=True)) \n      - 15: genderModel(get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n    \"\"\"\n    self.model = model\n\n  #Return self nothing else to do here    \n  def fit( self, X, y = None ):\n    return self \n\n  def create_dummies(self, df, column_name, drop_first_col):\n    \"\"\"Create Dummy Columns from a single Column\n    \"\"\"\n    dummies = pd.get_dummies(df[column_name],prefix=column_name, drop_first=drop_first_col)\n    return dummies\n\n  # manipulate column \"Age\"\n  def process_age(self, df):\n    # fill missing values with -0.5\n    #df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n\n    # impute missing value using title information\n    df['Title2'] = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n\n    newtitles={\n    \"Capt\":       \"Officer\",\n    \"Col\":        \"Officer\",\n    \"Major\":      \"Officer\",\n    \"Jonkheer\":   \"Royalty\",\n    \"Don\":        \"Royalty\",\n    \"Sir\" :       \"Royalty\",\n    \"Dr\":         \"Officer\",\n    \"Rev\":        \"Officer\",\n    \"Countess\":   \"Royalty\",\n    \"Dona\":       \"Royalty\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Royalty\"\n    }\n\n    df['Title2'] = df.Title2.map(newtitles)\n\n    df['Age'] = df[['Title2','Sex','Age']].apply(newage, axis=1)\n\n    # divide age column into a range of values\n    cut_points = [-1,0,5,12,18,35,60,100]\n    label_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n    df[\"Age_categories\"] = pd.cut(df[\"Age\"],\n                                 cut_points,\n                                 labels=label_names)\n          \n    if self.model == 3:\n      return self.create_dummies(df,\"Age_categories\",False)\n    else:\n      return None\n   \n  def process_fare(self, df):\n    # divide fare column into a range of values\n    cut_points = [0,50,100,150,200]\n    label_names = [\"F1\",\"F2\",\"F3\",\"F4\"]\n    df[\"Fare_categories\"] = pd.cut(df[\"Fare\"],\n                                 cut_points,\n                                 labels=label_names)\n         \n    if self.model in [10,11]:\n      return self.create_dummies(df,\"Fare_categories\",True)\n    else:\n      return None\n\n  def process_fare2(self, df):\n    # Apply log to Fare to reduce skewness distribution\n    df[\"Fare_norm\"] = df[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n    return pd.DataFrame(df[\"Fare_norm\"],columns=[\"Fare_norm\"])\n\n  def process_pclass(self, df):\n    if self.model in [0,1,3,4,5,6,7,8,9,10,11,12,13,14,15]:\n      return pd.DataFrame(df[\"Pclass\"],columns=[\"Pclass\"])\n    elif self.model == 2:\n      return self.create_dummies(df,\"Pclass\",False) \n    else:\n      return None\n        \n  #Transformer method we wrote for this transformer \n  def transform(self, X , y = None ):\n    df = X.copy()\n\n    age = self.process_age(df)  \n    pclass = self.process_pclass(df)\n    fare = self.process_fare(df)\n    fare2 = self.process_fare2(df)\n\n    \n    if self.model in [0,1,2,4,5,6,7,8,9,13,14,15]:\n      return pclass\n    elif self.model == 3:\n      return pd.concat([pclass,age],axis=1)\n    elif self.model in [10,11]:\n      return pd.concat([pclass,fare],axis=1)\n    elif self.model in [12]:\n      return pd.concat([pclass,fare2],axis=1)  \n    else:\n      return None","900993f5":"# for validation purposes only\nselect = FeatureSelector(pd.concat([train.drop(labels=[\"Survived\"],axis=1).select_dtypes(include=[\"int64\",\"float64\"])\n                                   ,train[['Name','Sex']]],axis=1).columns).transform(train)\n\n# change model to 0,1,2,3, ..., 15\nmodel = NumericalTransformer(model=15)\ndf = model.transform(select)\nnum_cols_final = df.columns\ndf.head()","588ef894":"num_cols_final","c7ccd887":"plt.figure(figsize = (10,10))\nsns.heatmap(pd.concat([df.select_dtypes(include=[\"int64\",\"uint8\",\"float64\"]),\n                       df_cat.select_dtypes(include=[\"int64\",\"uint8\"]),\n                       train.Survived],axis=1).corr(),cmap=(\"RdBu_r\"),annot=True,fmt='.2f')\nplt.xticks(rotation=90) \nplt.show()","9ba3e826":"pd.concat([df.select_dtypes(include=[\"int64\",\"uint8\",\"float64\"]),\n                       df_cat.select_dtypes(include=[\"int64\",\"uint8\"]),\n                       train.Survived],axis=1).corr()[\"Survived\"].abs().sort_values()","9c4146bf":"# global varibles\nseed = 42\nnum_folds = 10\nscoring = {'Accuracy': make_scorer(accuracy_score)}","c8e18152":"# load the datasets\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n\n# split-out train\/validation and test dataset\nX_train, X_test, y_train, y_test = train_test_split(train.drop(labels=\"Survived\",axis=1),\n                                                    train[\"Survived\"],\n                                                    test_size=0.20,\n                                                    random_state=seed,\n                                                    shuffle=True,\n                                                    stratify=train[\"Survived\"])","d1107fdd":"# Categrical features to pass down the categorical pipeline \ncategorical_features = X_train.select_dtypes(include=[\"object\"]).columns\n\n# Numerical features to pass down the numerical pipeline \nnumerical_features = pd.concat([X_train.select_dtypes(include=[\"int64\",\"float64\"]),\n                                X_train[['Name','Sex']] ], axis=1).columns\n\n\n# Defining the steps in the categorical pipeline \ncategorical_pipeline = Pipeline(steps = [('cat_selector', FeatureSelector(categorical_features)),\n                                         ('cat_transformer', CategoricalTransformer(model=15)), \n                                         ]\n                                )\n# Defining the steps in the numerical pipeline     \nnumerical_pipeline = Pipeline(steps = [('num_selector', FeatureSelector(numerical_features)),\n                                       ('num_transformer', NumericalTransformer(model=15)) \n                                       ]\n                              )\n\n# Combining numerical and categorical piepline into one full big pipeline horizontally \n# using FeatureUnion\nfull_pipeline_preprocessing = FeatureUnion(transformer_list = [('categorical_pipeline', categorical_pipeline),\n                                                               ('numerical_pipeline', numerical_pipeline)\n                                                               ]\n                                           )","9b79e011":"# for validate purposes\nnew_data = full_pipeline_preprocessing.fit_transform(X_train)\nnew_data_df = pd.DataFrame(new_data,)#columns=cat_cols_final.tolist() + num_cols_final.tolist())\nnew_data_df.head()","6723631a":"\"\"\"\n    model: \n      - 0: Sex column (categorized), Pclass (raw)\n      - 1: Sex column (get_dummies(drop_first=True)), Pclass (raw)\n      - 2: Sex column (get_dummies(drop_first=True)), Pclass (get_dummies(drop_first=False))\n      - 3: Sex column (get_dummies(drop_first=True)), Pclass (raw), Age (get_dummies(drop_first=False))\n      - 4: Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (categorized)\n      - 5: Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n      - 6: New Sex column (get_dummies(drop_first=False)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n      - 7: New Sex column (get_dummies(drop_first=False)+drop(Sex_woman)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n      - 8: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Family_Size\n      - 9: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Family_Size, Embarked (get_dummies(drop_first=False))\n      - 10: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Fare (get_dummies(drop_first=False))\n      - 11: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False)), Fare (get_dummies(drop_first=False))\n      - 12: New Sex column (get_dummies(drop_first=True)+drop(Sex_woman)), Pclass (raw), Embarked (get_dummies(drop_first=False)), Fare2 (scaled)\n      - 13: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False)), ticket(encoded) \n      - 14: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False)), ticket(get_dummies(drop_first=True)) \n\"\"\"\n\n# The full pipeline as a step in another pipeline with an estimator as the final step\npipe = Pipeline(steps = [('full_pipeline', full_pipeline_preprocessing),\n                         #(\"fs\",SelectKBest()),\n                         (\"clf\",XGBClassifier())])\n\n# create a dictionary with the hyperparameters\nsearch_space = [\n                {\"clf\":[RandomForestClassifier()],\n                 \"clf__n_estimators\": [100],\n                 \"clf__criterion\": [\"entropy\"],\n                 \"clf__max_leaf_nodes\": [64],\n                 \"clf__random_state\": [seed],\n                 \"full_pipeline__numerical_pipeline__num_transformer__model\":[14],\n                 \"full_pipeline__categorical_pipeline__cat_transformer__model\":[14]                \n                 },\n                {\"clf\":[LogisticRegression()],\n                 \"clf__solver\": [\"liblinear\"],\n                 \"full_pipeline__numerical_pipeline__num_transformer__model\":[14],\n                 \"full_pipeline__categorical_pipeline__cat_transformer__model\":[14]\n                 },\n                {\"clf\":[GradientBoostingClassifier()],\n                 \"clf__max_depth\": [2],\n                 \"clf__n_estimators\": [3],\n                 \"clf__learning_rate\": [1.0],\n                 \"clf__random_state\": [seed],\n                 \"full_pipeline__numerical_pipeline__num_transformer__model\":[14],\n                 \"full_pipeline__categorical_pipeline__cat_transformer__model\":[14]                 \n                 },\n                {\"clf\":[XGBClassifier()],\n                 \"clf__n_estimators\": [50],\n                 \"clf__max_depth\": [3],\n                 'clf__min_child_weight': [1],\n                 \"clf__learning_rate\": [0.01],\n                 \"clf__random_state\": [seed],\n                 \"clf__subsample\": [0.7],\n                 \"clf__colsample_bytree\": [1.0],\n                 \"full_pipeline__numerical_pipeline__num_transformer__model\":[14],\n                 \"full_pipeline__categorical_pipeline__cat_transformer__model\":[14]\n                 },\n                {\"clf\":[AdaBoostClassifier()],\n                 \"clf__base_estimator\": [DecisionTreeClassifier(max_depth=2)],\n                 \"clf__algorithm\": [\"SAMME.R\"],\n                 \"clf__n_estimators\": [200],\n                 \"clf__learning_rate\": [1.0],\n                 \"clf__random_state\": [seed],\n                 \"full_pipeline__numerical_pipeline__num_transformer__model\":[14],\n                 \"full_pipeline__categorical_pipeline__cat_transformer__model\":[14]\n                 }\n                ]\n\n# create grid search\nkfold = StratifiedKFold(n_splits=num_folds,random_state=seed)\n\n# return_train_score=True\n# official documentation: \"computing the scores on the training set can be\n# computationally expensive and is not strictly required to\n# select the parameters that yield the best generalization performance\".\ngrid = GridSearchCV(estimator=pipe, \n                    param_grid=search_space,\n                    cv=kfold,\n                    scoring=scoring,\n                    return_train_score=True,\n                    n_jobs=-1,\n                    refit=\"Accuracy\")\n\ntmp = time.time()\n\n# fit grid search\nbest_model = grid.fit(X_train,y_train)\n\nprint(\"CPU Training Time: %s seconds\" % (str(time.time() - tmp)))","95050cdb":"print(\"Best: %f using %s\" % (best_model.best_score_,best_model.best_params_))","613474b2":"result = pd.DataFrame(best_model.cv_results_)\nresult.head()","b36a4f76":"result_acc = result[['mean_train_Accuracy', 'std_train_Accuracy','mean_test_Accuracy', 'std_test_Accuracy','rank_test_Accuracy']].copy()\nresult_acc[\"std_ratio\"] = result_acc.std_test_Accuracy\/result_acc.std_train_Accuracy\nresult_acc.sort_values(by=\"rank_test_Accuracy\",ascending=True)","b0ba0073":"# best model\npredict_first = best_model.best_estimator_.predict(X_test)\nprint(accuracy_score(y_test, predict_first))","2bb609a2":"predict_final = best_model.best_estimator_.predict(test)","d1cad8e0":"holdout_ids = test[\"PassengerId\"]\nsubmission_df = {\"PassengerId\": holdout_ids,\n                 \"Survived\": predict_final}\nsubmission = pd.DataFrame(submission_df)\n\nsubmission.to_csv(\"submission.csv\",index=False)","73090b81":"# load the datasets\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")","b4970ea4":"def process_sex(df):\n    df[\"Title\"] = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n    \n    titles = {\n        \"Mr\" :         \"man\",\n        \"Mme\":         \"woman\",\n        \"Ms\":          \"woman\",\n        \"Mrs\" :        \"woman\",\n        \"Master\" :     \"boy\",\n        \"Mlle\":        \"woman\",\n        \"Miss\" :       \"woman\",\n        \"Capt\":        \"man\",\n        \"Col\":         \"man\",\n        \"Major\":       \"man\",\n        \"Dr\":          \"man\",\n        \"Rev\":         \"man\",\n        \"Jonkheer\":    \"man\",\n        \"Don\":         \"man\",\n        \"Sir\" :        \"man\",\n        \"Countess\":    \"woman\",\n        \"Dona\":        \"woman\",\n        \"Lady\" :       \"woman\"\n    }\n    \n    df[\"Sex\"] = df[\"Title\"].map(titles)\n    \n    return df","5fcee17b":"# create sex and surname column\ndef process_family(df):\n  ## create sex column\n  df = process_sex(df)\n\n  ## get surname\n  df[\"Surname\"] = df[\"Name\"].str.extract('([A-Za-z]*),.',expand=False)\n  \n  ## creating worman-boy-family-groups\n  # if man: no group\n  df.loc[df[\"Sex\"] == 'man', 'Surname'] = 'NoGroup'\n  \n  # if alone: no group\n  df['SurnameFreq'] = df['Surname'].map(df['Surname'].value_counts().to_dict())\n  df.loc[df[\"SurnameFreq\"] <= 1, 'Surname'] = 'NoGroup'\n\n  return df\n\ndef process_survivalRate(df):\n  ## survival family rate\n  # man and loners dies\n  df['SurvivalRate'] = 0\n  \n  # survival family rate = mean of survived status in each worman-boy-family group\n  surnames_list = df.Surname.unique().tolist()\n  surnames_list.remove('NoGroup')\n  for s in surnames_list:\n    df.loc[ df['Surname'] == s, 'SurvivalRate'] = df[ df['Surname'] == s].Survived.mean()\n\n  # adjust survival rates for use on training set \n  # discount yourself\n  df['SurvivalRateAjusted'] = (df['SurvivalRate']*df['SurnameFreq'] - df['Survived']) \/ (df['SurnameFreq'] - 1)\n\n  return df","627a0403":"aux = process_family(train)\n\nsurnames_list = aux.Surname.unique().tolist()\nsurnames_list.remove('NoGroup')\n\nfor s in surnames_list:\n  aux.loc[ aux['Surname'] == s, 'SurvivalRate'] = aux[ aux['Surname'] == s].Survived.mean()","a5a01c4a":"# load the datasets\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n\n# create  worman-boy-family-groups for all dataset\naux = process_family( pd.concat([train,test], sort=False, keys=['train','test']) )\nnew_train = aux.loc['train'].copy()\nnew_test = aux.loc['test'].copy()\n\n## survival family rate\nnew_train = process_survivalRate(new_train)\n\n\n# survival family rate = mean of survived status in each worman-boy-family group\nnew_test['SurvivalRate'] = 0\n\nfor i in new_test.index:\n  if not new_train[new_test.iloc[i-1,:].Surname == new_train['Surname']].empty:\n    new_test.iloc[i-1, 15] = new_train[new_test.iloc[i-1,:].Surname == new_train['Surname']].SurvivalRateAjusted.mean()\n\n# apply gender model to test dataset\nnew_test['Survived'] = 0\nnew_test.loc[ (new_test['Sex'] == 'boy') & (new_test['SurvivalRate'] == 1), 'Survived']  = 1\nnew_test.loc[ (new_test['Sex'] == 'woman') , 'Survived']  = 1\nnew_test.loc[ (new_test['Sex'] == 'woman') & (new_test['SurvivalRate'] == 0), 'Survived'] = 0\n\nprint(new_test.Survived.value_counts())","92d12fbe":"holdout_ids = new_test[\"PassengerId\"]\nsubmission_df = {\"PassengerId\": holdout_ids,\n                 \"Survived\": new_test[\"Survived\"]}\nsubmission = pd.DataFrame(submission_df)\n\nsubmission.to_csv(\"submission_genderModel_vs2.csv\",index=False)","f8274beb":"Age have 20% of missing values, we can imput with a good guess this data. (tip from source: https:\/\/www.kaggle.com\/goldens\/titanic-on-the-top-with-a-simple-model)","49afb60d":"### 3.1.2 Numerical Pipeline","219a5d05":"## 3 Clean, prepare and manipulate Data (feature engineering)","ca1fdb2d":"Gender model vs 2 (without ticket correction, but doing SurvivalRate correction)\n\nScore: 0.83253","e25547b7":"# 3.1 Pipelines","0d9201b3":"## 1 Load Libraries","67123f6f":"## 4 Modeling","ad4968c4":"## 5 Algorithm Tuning","b316668d":"## 7 Non-ML Models","e8632024":"Useful functions.","f54a3523":"### 3.1.1 Categorical Pipeline","c41a97b9":"## 6 Submission File","b5bb6fce":"Checking if we can extract some correlation with tickets so maybe the cabin information can be retrieved. (Tip from: https:\/\/www.kaggle.com\/yassineghouzam\/titanic-top-4-with-ensemble-modeling)","29d3a68a":"Gender model, following: https:\/\/www.kaggle.com\/cdeotte\/titanic-using-name-only-0-81818.\n\nHypothesis: woman and children were prioritized in rescue + woman and children from the same family survived or perished together.","46cd630f":"Cabin might be a relevant feature, since its location could be determinant to the survival rate of their occupant. However, more than 70% of the data is missing. We may try to retrive indirectly this information using fare feature.","f75006e6":"## 2 Get data, including EDA"}}