{"cell_type":{"06242f4a":"code","ac54fd72":"code","6b112cac":"code","2242ccd2":"code","7cac2eba":"code","f9b81b95":"code","3fb3bd7f":"code","76cc0881":"code","6700d582":"code","af467027":"code","e18d8707":"code","80c12112":"code","455a4453":"code","72cbad90":"code","311884da":"code","d3e06575":"code","62dd4ced":"code","6a6ba074":"code","4c1e01c5":"code","ef43b7b4":"code","2eed76a1":"code","51b0fe1a":"code","5b206a6e":"code","597d29c8":"code","136846e1":"code","dd7b6dcd":"code","d7a15c2d":"code","42dd5c91":"code","208df6ec":"code","ae018794":"code","d084a10d":"code","a1b94995":"code","0717f9a7":"code","b1cb61a7":"code","b6ccf965":"code","6071017a":"code","7e9f950f":"code","36c3dd39":"code","77d04b6c":"code","ff432ff7":"code","c891ca9e":"code","5c835de9":"markdown"},"source":{"06242f4a":"# initiating gpu using tensorflow.\nimport tensorflow as tf\nfrom keras.backend.tensorflow_backend import set_session\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.log_device_placement = True\nsess = tf.Session(config=config)\nset_session(sess)","ac54fd72":"#importing libraries for the data processing and model.\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport random\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.datasets import cifar10\nfrom keras.utils import np_utils\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import EarlyStopping\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import misc\nfrom keras.models import load_model\n%matplotlib inline","6b112cac":"# defining the path and classes.\ndirectory = '..\/input\/state-farm-distracted-driver-detection\/imgs\/train'\ntest_directory = '..\/input\/state-farm-distracted-driver-detection\/imgs\/test\/'\nrandom_test = '..\/input\/driver\/'\nclasses = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']","2242ccd2":"# defining a shape to be used for our models.\nimg_size1 = 240\nimg_size2 = 240","7cac2eba":"# Train class image for display.\nfor i in classes:\n    path = os.path.join(directory,i)\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n        plt.imshow(img_array, cmap='gray')\n        plt.show()\n        break\n    break","f9b81b95":"# Test class image for display.\ntest_array = []\nfor img in os.listdir(test_directory):\n    img_array = cv2.imread(os.path.join(test_directory,img),cv2.IMREAD_GRAYSCALE)\n    test_array = img_array\n    plt.imshow(img_array, cmap='gray')\n    plt.show()\n    break","3fb3bd7f":"# checkking image size using shape.\nprint(img_array.shape)","76cc0881":"# trying out the resize image functionality\nnew_img = cv2.resize(test_array,(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","6700d582":"# creating a training dataset.\ntraining_data = []\ni = 0\ndef create_training_data():\n    for category in classes:\n        path = os.path.join(directory,category)\n        class_num = classes.index(category)\n        \n        for img in os.listdir(path):\n            img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n            new_img = cv2.resize(img_array,(img_size2,img_size1))\n            training_data.append([\n                new_img,class_num])","af467027":"# Creating a test dataset.\ntesting_data = []\ni = 0\ndef create_testing_data():        \n    for img in os.listdir(test_directory):\n        img_array = cv2.imread(os.path.join(test_directory,img),cv2.IMREAD_GRAYSCALE)\n        new_img = cv2.resize(img_array,(img_size2,img_size1))\n        testing_data.append([img,\n            new_img])","e18d8707":"create_training_data()","80c12112":"create_testing_data()","455a4453":"print(len(training_data))\nprint(len(testing_data))","72cbad90":"random.shuffle(training_data)","311884da":"x = []\ny = []","d3e06575":"for features, label in training_data:\n    x.append(features)\n    y.append(label)","62dd4ced":"x[0].shape","6a6ba074":"len(x)","4c1e01c5":"#X  = np.array(x[1]).reshape(-1,img_size2,img_size1,1)\n#i = 1\n#for i in range(len(x)):\nX = np.array(x).reshape(-1,img_size2,img_size1,1)\n#    X = np.append(X,Y,axis = 0)\nX.shape,X[0].shape","ef43b7b4":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=50)","2eed76a1":"Y_train = np_utils.to_categorical(y_train,num_classes=10)\nY_test = np_utils.to_categorical(y_test,num_classes=10)","51b0fe1a":"model = Sequential()","5b206a6e":"model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(240,240,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.3))","597d29c8":"model.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.3))","136846e1":"model.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.5))","dd7b6dcd":"model.add(Flatten())\nmodel.add(Dense(units = 512,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units = 128,activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10,activation='softmax'))","d7a15c2d":"model.summary()","42dd5c91":"model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')","208df6ec":"callbacks = [EarlyStopping(monitor='val_acc',patience=5)]","ae018794":"batch_size = 50\nn_epochs = 20","d084a10d":"results = model.fit(x_train,Y_train,batch_size=batch_size,epochs=n_epochs,verbose=1,validation_data=(x_test,Y_test),callbacks=callbacks)","a1b94995":"# Plot training & validation accuracy values\nplt.plot(results.history['acc'])\nplt.plot(results.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(results.history['loss'])\nplt.plot(results.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","0717f9a7":"preds = model.predict(np.array(testing_data[0][1]).reshape(-1,img_size2,img_size1,1))","b1cb61a7":"model.save_weights('.\/driverdistraction_lr_weights.h5', overwrite=True)","b6ccf965":"model.save('.\/driverdistraction_lr_weights.h5')","6071017a":"loaded_model = load_model('..\/input\/driver-distraction\/driverdistraction_lr_weights.h5')","7e9f950f":"test_data = np.array(testing_data[1001][1]).reshape(-1,img_size2,img_size1,1)","36c3dd39":"preds = model.predict(test_data)\npreds= np.argmax(preds)\npreds","77d04b6c":"\n\nclasses = {0: \"safe driving\",\n1: \"texting - right\",\n2: \"talking on the phone - right\",\n3: \"texting - left\",\n4: \"talking on the phone - left\",\n5: \"operating the radio\",\n6: \"drinking\",\n7: \"reaching behind\",\n8: \"hair and makeup\",\n9: \"talking to passenger\",\n}\n\n\nfor key,value in classes.items():\n    if preds==key:\n        predicted = value\n\npredicted     ","ff432ff7":"print(predicted)\nnew_img = cv2.resize(testing_data[1001][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","c891ca9e":"def create_submission(predictions, test_id, info):\n    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n    now = datetime.datetime.now()\n    if not os.path.isdir('subm'):\n        os.mkdir('subm')\n    suffix = info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n    result1.to_csv(sub_file, index=False)","5c835de9":"\n    c0: safe driving\n    c1: texting - right\n    c2: talking on the phone - right\n    c3: texting - left\n    c4: talking on the phone - left\n    c5: operating the radio\n    c6: drinking\n    c7: reaching behind\n    c8: hair and makeup\n    c9: talking to passenger\n"}}