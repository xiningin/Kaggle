{"cell_type":{"9e1adabf":"code","8625ddab":"code","413781f3":"code","6cfc729f":"code","ec923ddf":"code","1bfd93a6":"code","fd2eafb6":"code","f6d41fc9":"code","de0d7a41":"code","ac629773":"code","3a30d507":"code","6b219af2":"code","ce5c8bed":"markdown","3178bdba":"markdown","6ba77e92":"markdown","cb997e0f":"markdown","ef985611":"markdown","15cf82ad":"markdown","cf5773c9":"markdown"},"source":{"9e1adabf":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nimport cv2\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\nfrom sklearn.utils import shuffle \n\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, Dropout, Dense, Flatten, Input\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping","8625ddab":"train_labels = pd.read_csv(r'..\/input\/arabic-hwr-ai-pro-intake1\/train.csv')\ntrain_im = np.array([cv2.imread(file) for file in sorted(glob.glob(r\"..\/input\/arabic-hwr-ai-pro-intake1\/train\/*.png\"))]).astype(\"float32\")\/255\n\ntest_labels = pd.read_csv(r'..\/input\/arabic-hwr-ai-pro-intake1\/test.csv')\ntest_im = np.array([cv2.imread(file) for file in sorted(glob.glob(r\"..\/input\/arabic-hwr-ai-pro-intake1\/test\/*.png\"))]).astype(\"float32\")\/255\n\nprint(f\"Training set size: {len(train_labels)}, Images per letter: {len(train_labels[train_labels['label'] == 1])}\")\nprint(f\"Testing set size : {len(test_labels)}\")\nprint(f\"Image Shape: {train_im[0].shape}\")","413781f3":"fig, ax = plt.subplots(4, 12, figsize=(20, 8))\nnp.random.seed(42)\nrandom_indices = list(np.random.randint(0, 13439, 48))\n\nfor i, ax in zip(random_indices, ax.flatten()):\n    ax.imshow(train_im[i,...])\n    ax.set_title(f'label = {train_labels.iloc[i][\"label\"]}')\n    ax.set(xticks=[], yticks=[])\n    plt.axis(\"off\")\n    ","6cfc729f":"train_y = to_categorical(train_labels[\"label\"] - 1, num_classes=28).astype(int)\ntrain_y.shape","ec923ddf":"#Shuffle the data:\nX_train, y_train = shuffle(train_im, train_y,random_state = 42)","1bfd93a6":"model = Sequential([\n                    Input(shape=X_train[0].shape, name=\"Input\"),\n                    \n                    Conv2D(32, (3,3), padding='same', activation='relu', kernel_initializer=\"uniform\", name=\"Conv_1\"),\n                    MaxPooling2D(pool_size=(2,2),name=\"Pool_1\"),\n                    BatchNormalization(name=\"BN_1\"),\n\n                    Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer=\"uniform\", name=\"Conv_2\"),\n                    MaxPooling2D(pool_size=(2,2),name=\"Pool_2\"),\n                    Dropout(0.2, name=\"Dropout_1\"),\n                    BatchNormalization(name=\"BN_2\"),\n\n                    Conv2D(128, (3,3), padding='same', activation='relu', kernel_initializer=\"uniform\", name=\"Conv_3\"),\n                    MaxPooling2D(pool_size=(2,2),name=\"Pool_3\"),\n                    Dropout(0.2, name=\"Dropout_2\"),\n                    BatchNormalization(name=\"BN_3\"),\n\n                    Flatten(),\n    \n                    Dense(128, activation=\"relu\",  kernel_initializer=\"uniform\", name=\"Dense_1\"),\n    \n                    Dense(64, activation=\"relu\",  kernel_initializer=\"uniform\", name=\"Dense_2\"),\n    \n                    Dense(32, activation='relu',  kernel_initializer=\"uniform\", name=\"Dense_3\"),\n                    BatchNormalization(name=\"BN_4\"),\n                    Dropout(0.2, name=\"Dropout_3\"),\n    \n                    Dense(28, activation='softmax', name=\"Dense_4\")\n                   ]\n#                    ,name=\"Initial_Model\"\n)\n\nmodel.compile(optimizer=\"adam\",\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","fd2eafb6":"early_stopping_cb = EarlyStopping(patience=20, restore_best_weights=True)\ncheckpoint = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)\n\nhistory = model.fit(X_train, y_train,\n                    epochs=200,\n                    batch_size=64,\n                    validation_split=0.2,\n                    callbacks=[early_stopping_cb, checkpoint]) ","f6d41fc9":"fig,ax = plt.subplots(1, 2, figsize=(15,5))\n\nax[0].set_title('Training and validation loss')\nax[0].plot(history.history['loss'])\nax[0].plot(history.history['val_loss'])\nax[0].legend(['train', 'val'], loc='upper left')\n\nax[1].set_title('Training and validation accuracy')\nax[1].plot(history.history['accuracy'])\nax[1].plot(history.history['val_accuracy'])\nax[1].legend(['train', 'val'], loc='upper left')\n\nplt.show()","de0d7a41":"def estimate_model(model, X_train, y_train):\n    y_pred = np.argmax(model.predict(X_train), axis=-1) + 1\n    y_true = np.argmax(y_train, axis=-1) + 1\n    \n    labels=['\u0623', '\u0628', '\u062a', '\u062b', '\u062c', '\u062d', '\u062e', '\u062f', '\u0630', '\u0631', '\u0632', '\u0633', '\u0634', '\u0635',\n            '\u0636', '\u0637', '\u0638', '\u0639', '\u063a', '\u0641', '\u0642', '\u0643', '\u0644', '\u0645', '\u0646', '\u0647', '\u0648', '\u0649']\n    \n    print(f\"  Training set Accuracy = {accuracy_score(y_true, y_pred):.4%}\\n\")\n    print(\"  Training set Classification Report:\")\n    print(classification_report(y_true, y_pred, digits=4,))\n    \n    fig, ax = plt.subplots(figsize = (12, 12))\n    ax.set_title(\"Training Set Confusion Matrix\")\n    cm = confusion_matrix(y_true, y_pred)\n    ConfusionMatrixDisplay(cm, display_labels=labels).plot(ax=ax, values_format='d')\n\nestimate_model(model, X_train, y_train) ","ac629773":"y_preds = np.argmax(model.predict(test_im), axis=-1) + 1\ntest_labels['label'] = y_preds","3a30d507":"test_labels","6b219af2":"test_labels[['id', 'label']].to_csv('\/kaggle\/working\/submission.csv', index=False)","ce5c8bed":"### Data Visualisation:","3178bdba":"## **Preprocessing:**","6ba77e92":"## **Importing Libararies:**","cb997e0f":"## **Loading Data:**","ef985611":"## **Building Neural Network Model:**","15cf82ad":"### Model Evaluation:","cf5773c9":"## **Test Set Prediction:**"}}