{"cell_type":{"fad5e170":"code","81a407e3":"code","2c9d9a53":"code","a05f7732":"code","47b8197d":"code","5cceb4d2":"code","520e14d0":"code","be983f58":"code","b5e7db7f":"code","dab0cd8b":"code","7d37ed80":"code","91ea44c9":"code","9933fa6a":"code","0bf42a00":"code","35625ffb":"code","cdbe0859":"code","5edd51e5":"code","77f2c325":"code","b6ac9776":"code","162f1e54":"code","505961fc":"code","166ef8c0":"code","bd2f481a":"code","ba9b07ad":"code","fdb28df9":"code","118429e2":"code","7125e2e7":"code","2453fcbc":"code","75430a51":"code","47724f64":"markdown","0c9a99b3":"markdown","05e20988":"markdown","05520040":"markdown","b864984b":"markdown","a41ec04c":"markdown","d1cb0724":"markdown","772925cd":"markdown","e607d9dc":"markdown","f955df50":"markdown","1e01f1ea":"markdown","274b9b0b":"markdown","96849417":"markdown","a7691abe":"markdown","eda59277":"markdown","6a3ae40a":"markdown"},"source":{"fad5e170":"gpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\nif gpu_info.find('failed') >= 0:\n    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n    print('and then re-execute this cell.')\nelse:\n    print(gpu_info)","81a407e3":"!pip install -q git+https:\/\/github.com\/rwightman\/pytorch-image-models.git\n!pip install -q torchsummary\n!pip install -q -U git+https:\/\/github.com\/albu\/albumentations --no-cache-dir\n!pip install -q neptune-client \n\nfrom IPython.display import clear_output \nclear_output()","2c9d9a53":"import math\nimport os\nfrom torchsummary import summary\nimport warnings\nimport random\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom typing import *\nimport albumentations\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nimport cv2\nimport neptune.new as neptune\nimport numpy as np\nimport pandas as pd\nimport timm\nimport torch\nimport torch.nn.functional as F\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.optim.optimizer import Optimizer\nfrom torchsummary import summary\nfrom torchvision import models\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nwarnings.filterwarnings(\"ignore\")\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nfrom IPython.display import clear_output \nclear_output()\n","a05f7732":"torch.cuda.empty_cache()","47b8197d":"import albumentations as A\n\nCONFIG = {\n    \"COMPETITION_NAME\": \"SETI\",\n    \"MODEL\": {\"MODEL_FACTORY\": \"timm\", \"MODEL_NAME\": \"efficientnet_b0\"},\n    \"WORKSPACE\": \"Kaggle\",\n    \"DATA\": {\n        \"TARGET_COL_NAME\": \"target\",\n        \"IMAGE_COL_NAME\": \"id\",\n        \"NUM_CLASSES\": 1,\n        \"CLASS_LIST\": [0, 1],\n        \"IMAGE_SIZE\": 384,\n        \"CHANNEL_MODE\": \"spatial_3ch\",\n        \"USE_MIXUP\": True\n    },\n    \"CROSS_VALIDATION\": {\"SCHEMA\" : 'StratifiedKFold', \"NUM_FOLDS\": 5},\n    \"TRAIN\": {\n        \"DATALOADER\": {\n            \"batch_size\": 32,\n            \"shuffle\": True, #using random sampler\n            \"num_workers\": 4,\n            \"drop_last\": False,\n        },\n        \"SETTINGS\": {\n            \"IMAGE_SIZE\": 384,\n            \"NUM_EPOCHS\": 25,\n            \"USE_AMP\": True,\n            \"USE_GRAD_ACCUM\": False,\n            \"ACCUMULATION_STEP\": 1,\n            \"DEBUG\": False,\n            \"VERBOSE\": True,\n            \"VERBOSE_STEP\": 10,\n        },\n    },\n    \"VALIDATION\": {\n        \"DATALOADER\": {\n            \"batch_size\": 32,\n            \"shuffle\": False,\n            \"num_workers\": 4,\n            \"drop_last\": False,\n        }\n    },\n    \"TEST\": {\n        \"DATALOADER\": {\n            \"batch_size\": 32,\n            \"shuffle\": False,\n            \"num_workers\": 4,\n            \"drop_last\": False,\n        }\n    },\n    \"OPTIMIZER\": {\n        \"NAME\": \"AdamW\",\n        \"OPTIMIZER_PARAMS\": {\"lr\": 3e-4, \"eps\": 1.0e-8, \"weight_decay\": 0},\n    },\n    \"SCHEDULER\": {\n        \"NAME\": \"CosineAnnealingLR\",\n        \"SCHEDULER_PARAMS\": {\n            \"T_max\": 25,\n            \"eta_min\": 1.0e-7,\n            \"last_epoch\": -1,\n            \"verbose\": False,\n        },\n        \"CUSTOM\": \"GradualWarmupScheduler\",\n        \"CUSTOM_PARAMS\": {\"multiplier\": 1, \"total_epoch\": 2},\n        \"VAL_STEP\": False,\n    },\n    \"CRITERION_TRAIN\": {\n        \"NAME\": \"BCEWithLogitsLoss\",\n        \"LOSS_PARAMS\": {\n            \"weight\": None,\n            \"size_average\": None,\n            \"reduce\": None,\n            \"reduction\": \"mean\",\n            \"pos_weight\": None\n        },\n    },\n    \"CRITERION_VALIDATION\": {\n        \"NAME\": \"BCEWithLogitsLoss\",\n        \"LOSS_PARAMS\": {\n            \"weight\": None,\n            \"size_average\": None,\n            \"reduce\": None,\n            \"reduction\": \"mean\",\n            \"pos_weight\": None\n        },\n    },\n    \"TRAIN_TRANSFORMS\": {        \n        \"VerticalFlip\": {\"p\": 0.2},\n        \"HorizontalFlip\": {\"p\": 0.2},\n        \"ShiftScaleRotate\": {\"rotate_limit\":0, \"p\":0.2},\n        \"MotionBlur\": {\"p\":0.2},\n        \n        \"Resize\": {\"height\": 384, \"width\": 384, \"p\": 1},\n    },\n    \"VALID_TRANSFORMS\": {\n        \"Resize\": {\"height\": 384, \"width\": 384, \"p\": 1},\n    },\n    \"TEST_TRANSFORMS\": {\n        \"Resize\": {\"height\": 384, \"width\": 384, \"p\": 1},\n    },\n    \"PATH\": {\n        \"DATA_DIR\": \"\/content\/\",\n        \"TRAIN_CSV\": \"..\/input\/seti-breakthrough-listen\/train_labels.csv\",\n        \"TRAIN_PATH\": \"\/content\/jpeg-melanoma-384x384\/train\",\n        \n        \"TEST_CSV\": \"..\/input\/seti-breakthrough-listen\/sample_submission.csv\",\n        \"TEST_PATH\": \"..\/input\/seti-breakthrough-listen\/test\",\n        \"SAVE_WEIGHT_PATH\": \".\/\",\n        \"OOF_PATH\": \".\/\",\n        \"LOG_PATH\": \".\/log.txt\"\n    },\n    \"SEED\": 19921930,\n    \"DEVICE\": \"cuda\",\n    \"GPU\": \"V100\",\n}\n\nconfig = CONFIG","5cceb4d2":"def seed_all(seed: int = 1930):\n    \"\"\"Seed all random number generators.\"\"\"\n    print(\"Using Seed Number {}\".format(seed))\n\n    os.environ[\"PYTHONHASHSEED\"] = str(\n        seed\n    )  # set PYTHONHASHSEED env var at fixed value\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.cuda.manual_seed(seed)  # pytorch (both CPU and CUDA)\n    np.random.seed(seed)  # for numpy pseudo-random generator\n    random.seed(seed)  # set fixed value for python built-in pseudo-random generator\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.enabled = False\n\n\ndef seed_worker(_worker_id):\n    \"\"\"Seed a worker with the given ID.\"\"\"\n    worker_seed = torch.initial_seed() % 2 ** 32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)","520e14d0":"seed_all(config['SEED'])","be983f58":"train = pd.read_csv(CONFIG['PATH']['TRAIN_CSV'])\n\ndef get_train_file_path(image_id):\n    if config['WORKSPACE'] == 'Kaggle':\n\n        return \"..\/input\/seti-breakthrough-listen\/train\/{}\/{}.npy\".format(image_id[0], image_id)\n    elif config['WORKSPACE'] == 'Colab':\n        return \"\/content\/seti-breakthrough-listen\/{}\/{}.npy\".format(image_id[0], image_id)\n\n\ntrain['file_path'] = train['id'].apply(get_train_file_path)\n\n\ndisplay(train.head())\n","b5e7db7f":"plt.figure(figsize=(10, 8))\nfor i in range(10):\n    image = np.load(train.loc[i, 'file_path']) # (6, 273, 256)\n    image = image[::2].astype(np.float32) # (3, 273, 256)\n    image = np.vstack(image).transpose((1, 0)) # (1638, 256) -> (256, 1638)\n    plt.subplot(5, 2, i + 1)\n    plt.tight_layout()\n    plt.imshow(image)\nplt.show()","dab0cd8b":"def make_folds(train_csv: pd.DataFrame, config) -> pd.DataFrame:\n    \"\"\"Split the given dataframe into training folds.\"\"\"\n    # TODO: add options for cv_scheme as it is cumbersome here.\n    if config['CROSS_VALIDATION']['SCHEMA'] == \"StratifiedKFold\":\n        df_folds = train_csv.copy()\n        skf = StratifiedKFold(\n            n_splits=config['CROSS_VALIDATION']['NUM_FOLDS'], shuffle=True, random_state=config['SEED']\n        )\n\n        for fold, (train_idx, val_idx) in enumerate(\n            skf.split(\n                X=df_folds[config['DATA']['IMAGE_COL_NAME']], y=df_folds[config['DATA']['TARGET_COL_NAME']]\n            )\n        ):\n            df_folds.loc[val_idx, \"fold\"] = int(fold + 1)\n        df_folds[\"fold\"] = df_folds[\"fold\"].astype(int)\n        print(df_folds.groupby([\"fold\", config['DATA']['TARGET_COL_NAME']]).size())\n\n    elif config.cv_schema == \"GroupKfold\":\n        df_folds = train_csv.copy()\n        gkf = GroupKFold(n_splits=config.num_folds)\n        groups = df_folds[config.group_kfold_split].values\n        for fold, (train_index, val_index) in enumerate(\n            gkf.split(X=df_folds, y=df_folds[config.class_col_name], groups=groups)\n        ):\n            df_folds.loc[val_index, \"fold\"] = int(fold + 1)\n        df_folds[\"fold\"] = df_folds[\"fold\"].astype(int)\n        try:\n            print(df_folds.groupby([\"fold\", config.class_col_name]).size())\n        except:\n            display(df_folds)\n\n    else:  # No CV Schema used in this file, but custom one\n        df_folds = train_csv.copy()\n        try:\n            print(df_folds.groupby([\"fold\", config.class_col_name]).size())\n        except:\n            display(df_folds)\n\n    return df_folds\n","7d37ed80":"df_folds =  make_folds(train, config)","91ea44c9":"def mixup_data(x, y, alpha=1.0, use_cuda=True):\n    '''Returns mixed inputs, pairs of targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","9933fa6a":"class Transform:\n\n    def __init__(self, aug_kwargs: Dict):\n        albu_augs = [getattr(A, name)(**kwargs)\n                     for name, kwargs in aug_kwargs.items()]\n        albu_augs.append(ToTensorV2(p=1))\n\n        self.transform = A.Compose(albu_augs)\n\n    def __call__(self, image):\n        image = self.transform(image=image)[\"image\"]\n        return image","0bf42a00":"def mixup_data(x, y, alpha=1.0, use_cuda=True):\n    '''Returns mixed inputs, pairs of targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","35625ffb":"class AlienTrainDataset(Dataset):\n    def __init__(self, df, config, transform=None, mode = 'train'):\n        self.df = df\n        self.config = config\n        self.file_names = df['file_path'].values\n        self.labels = df[config['DATA']['TARGET_COL_NAME']].values\n        self.transform = transform\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image = np.load(self.file_names[idx])\n        # print(image.shape) -> (6, 273, 256)\n        if self.config['DATA']['CHANNEL_MODE'] == 'spatial_6ch':\n            image = image.astype(np.float32)\n            image = np.vstack(image) # no transpose here (1638, 256) \n            # image = np.vstack(image).transpose((1, 0))\n            # print(image.shape) -> (256, 1638)\n\n        elif self.config['DATA']['CHANNEL_MODE'] == 'spatial_3ch':\n            image = image[::2].astype(np.float32)\n            image = np.vstack(image).transpose((1, 0))\n        elif self.config['DATA']['CHANNEL_MODE'] == '6_channel':\n            image = image.astype(np.float32)\n            image = np.transpose(image, (1,2,0))\n        elif self.config['DATA']['CHANNEL_MODE'] == '3_channel':\n            image = image[::2].astype(np.float32)\n            image = np.transpose(image, (1,2,0))\n        \n        if self.transform:\n            image = self.transform(image)\n  \n        else:\n            image = torch.from_numpy(image).float()\n\n        if self.mode == 'test':\n            return image    \n        else:\n            label = torch.tensor(self.labels[idx]).float()\n            return image, label\n            ","cdbe0859":"train_dataset = AlienTrainDataset(train, config, transform=Transform(config[\"TRAIN_TRANSFORMS\"]))\n\nfor i in range(2):\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show()\nimage.shape","5edd51e5":"class AverageLossMeter:\n    \"\"\"\n    Computes and stores the average and current loss\n    \"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.curr_batch_avg_loss = 0\n        self.avg = 0\n        self.running_total_loss = 0\n        self.count = 0\n\n    def update(self, curr_batch_avg_loss: float, batch_size: str):\n        self.curr_batch_avg_loss = curr_batch_avg_loss\n        self.running_total_loss += curr_batch_avg_loss * batch_size\n        self.count += batch_size\n        self.avg = self.running_total_loss \/ self.count","77f2c325":"import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport warnings\nfrom functools import wraps\nimport weakref\n\n\nclass GradualWarmupScheduler(_LRScheduler):\n    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n    Args:\n        optimizer (Optimizer): Wrapped optimizer.\n        multiplier: target learning rate = base lr * multiplier if multiplier > 1.0. if multiplier = 1.0, lr starts from 0 and ends up with the base_lr.\n        total_epoch: target learning rate is reached at total_epoch, gradually\n        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n    \"\"\"\n\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        self.multiplier = multiplier\n        if self.multiplier < 1.:\n            raise ValueError(\n                'multiplier should be greater thant or equal to 1.')\n        self.total_epoch = total_epoch\n        self.after_scheduler = after_scheduler\n        self.finished = False\n        super(GradualWarmupScheduler, self).__init__(optimizer)\n\n    def get_lr(self):\n        if not self._get_lr_called_within_step:\n            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n                          \"please use `get_last_lr()`.\")\n\n        # change 4: This fixes many issues.\n        if self.last_epoch >= self.total_epoch:\n\n            if self.after_scheduler:\n\n                if not self.finished:\n                    # at this step, we are\n                    self.after_scheduler.base_lrs = [\n                        base_lr * self.multiplier for base_lr in self.base_lrs]\n\n                    self.finished = True\n                    # Change 1\n                return self.after_scheduler.get_lr()\n\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n\n        if self.multiplier == 1.0:\n            # change 3: self.last_epoch+1\n            return [base_lr * (float(self.last_epoch+1) \/ self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch \/ self.total_epoch + 1.) for base_lr in self.base_lrs]\n\n    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n        if epoch is None:\n            epoch = self.last_epoch + 1\n        # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n        self.last_epoch = epoch if epoch != 0 else 1\n        if self.last_epoch <= self.total_epoch:\n            # Change 2: Fixed a bug see pull requests.\n            warmup_lr = self.get_lr()\n            for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n                param_group['lr'] = lr\n        else:\n            if epoch is None:\n                self.after_scheduler.step(metrics, None)\n            else:\n                self.after_scheduler.step(metrics, epoch - self.total_epoch)\n\n    def step(self, epoch=None, metrics=None):\n        if type(self.after_scheduler) != ReduceLROnPlateau:\n            if self.finished and self.after_scheduler:\n                if epoch is None:\n                    self.after_scheduler.step(None)\n                else:\n                    self.after_scheduler.step(epoch - self.total_epoch)\n                # get last lr\n                self._last_lr = self.after_scheduler.get_last_lr()\n            else:\n                return super(GradualWarmupScheduler, self).step(epoch)\n        else:\n            self.step_ReduceLROnPlateau(metrics, epoch)\n","b6ac9776":"sigmoid = torch.nn.Sigmoid()\n\n\nclass Swish(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, i):\n        result = i * sigmoid(i)\n        ctx.save_for_backward(i)\n        return result\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n        sigmoid_i = sigmoid(i)\n        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n\n\nclass Swish_Module(torch.nn.Module):\n    def forward(self, x):\n        return Swish.apply(x)","162f1e54":"class AlienSingleHead(torch.nn.Module):\n    \"\"\"A custom model.\"\"\"\n\n    def __init__(\n        self,\n        config: type,\n        pretrained: bool = True,\n    ):\n        \"\"\"Construct a custom model.\"\"\"\n        super().__init__()\n        self.config = config\n        self.pretrained = pretrained\n        print(\"Pretrained is {}\".format(self.pretrained))\n        # self.activation = Swish_Module()\n        self.activation = Swish_Module()\n        self.architecture = {\n            \"backbone\": None,\n            \"bottleneck\": None,\n            \"classifier_head\": None,\n        }\n\n        def __setattr__(self, name, value):\n            self.model.__setattr__(self, name, value)\n\n        _model_factory = (\n            timm.create_model\n            if self.config[\"MODEL\"][\"MODEL_FACTORY\"] == \"timm\"\n            else geffnet.create_model\n        )\n        if config['DATA']['CHANNEL_MODE'] == 'spatial_6ch' or config['DATA']['CHANNEL_MODE'] == 'spatial_3ch':\n\n            self.model = _model_factory(\n                model_name=self.config[\"MODEL\"][\"MODEL_NAME\"],\n                pretrained=self.pretrained, in_chans=1) # set channel = 1 since we using spatial\n\n        else:\n            self.model = _model_factory(\n                            model_name=self.config[\"MODEL\"][\"MODEL_NAME\"],\n                            pretrained=self.pretrained, in_chans=3) # set channel = 1 since we using spatial\n\n        # reset head\n        self.model.reset_classifier(num_classes=0, global_pool=\"avg\")\n        # after resetting, there is no longer any classifier head, therefore it is the backbone now.\n        self.architecture[\"backbone\"] = self.model\n        # get out features of the last cnn layer from backbone, which is also the in features of the next layer\n\n        self.in_features = self.architecture[\"backbone\"].num_features\n\n        self.single_head_fc = torch.nn.Sequential(\n            torch.nn.Linear(self.in_features, self.in_features),\n            self.activation,\n            torch.nn.Dropout(p=0.5),\n            torch.nn.Linear(self.in_features, self.config[\"DATA\"][\"NUM_CLASSES\"]),\n        )\n        self.architecture[\"classifier_head\"] = self.single_head_fc\n\n\n    # feature map after cnn layer\n    def extract_features(self, x):\n        feature_logits = self.architecture[\"backbone\"](x)\n        # TODO: caution, if you use forward_features, then you need reshape. See test.py\n        return feature_logits\n\n    def forward(self, x):\n        feature_logits = self.extract_features(x)\n        classifier_logits = self.architecture[\"classifier_head\"](feature_logits)\n        return classifier_logits\n","505961fc":"model = AlienSingleHead(config,pretrained=False)\ntrain_dataset = AlienTrainDataset(train, config, transform=Transform(config[\"TRAIN_TRANSFORMS\"]))\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True,\n                          num_workers=4, pin_memory=True, drop_last=True)\n\nfor image, label in train_loader:\n    output = model(image)\n    print(output)\n    break","166ef8c0":"\ndef torchsummary_wrapper(model, image_size: Tuple):\n    model_summary = summary(model, image_size)\n    return model_summary","bd2f481a":"\"\"\"Model training.\"\"\"\n\nimport datetime\nimport os\nimport random\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport pytz\nimport sklearn\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import GroupKFold\nfrom torch.utils.data import DataLoader\n\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_auc_score\n\n\nclass Trainer:\n\n    \"\"\"A class to perform model training.\"\"\"\n\n    def __init__(self, model, config, early_stopping=None, neptune=None):\n        \"\"\"Construct a Trainer instance.\"\"\"\n        self.model = model\n        self.patience = 3\n        self.config = config\n        self.neptune = neptune\n        self.early_stopping = early_stopping\n        self.epoch = 0\n        self.best_auc = 0\n        self.log_path = self.config[\"PATH\"][\"LOG_PATH\"]\n        self.best_loss = np.inf\n        self.num_epochs = self.config[\"TRAIN\"][\"SETTINGS\"][\"NUM_EPOCHS\"]\n        self.save_path = self.config[\"PATH\"][\"SAVE_WEIGHT_PATH\"]\n        if not os.path.exists(self.save_path):\n            os.makedirs(self.save_path)\n        self.device = self.config[\"DEVICE\"]\n        \"\"\"scaler is only used when use_amp is True, use_amp is inside config.\"\"\"\n        if self.config[\"TRAIN\"][\"SETTINGS\"][\"USE_AMP\"]:\n            self.scaler = torch.cuda.amp.GradScaler()\n        self.date = datetime.datetime.now(pytz.timezone(\"Asia\/Singapore\")).strftime(\n            \"%Y-%m-%d\"\n        )\n        self.log(f\"Fitter prepared. Device is {self.device}\")\n\n        self.criterion_train = getattr(\n            torch.nn, self.config[\"CRITERION_TRAIN\"][\"NAME\"]\n        )(**self.config[\"CRITERION_TRAIN\"][\"LOSS_PARAMS\"]).to(self.device)\n        \n        self.criterion_val = getattr(\n            torch.nn, self.config[\"CRITERION_VALIDATION\"][\"NAME\"]\n        )(**self.config[\"CRITERION_VALIDATION\"][\"LOSS_PARAMS\"])\n\n        self.optimizer = getattr(torch.optim, self.config[\"OPTIMIZER\"][\"NAME\"])(\n            self.model.parameters(), **self.config[\"OPTIMIZER\"][\"OPTIMIZER_PARAMS\"]\n        )\n        self.scheduler = getattr(\n            torch.optim.lr_scheduler, self.config[\"SCHEDULER\"][\"NAME\"]\n        )(optimizer=self.optimizer, **self.config[\"SCHEDULER\"][\"SCHEDULER_PARAMS\"])\n\n        self.scheduler_warmup = GradualWarmupScheduler(\n            self.optimizer,\n            **self.config[\"SCHEDULER\"][\"CUSTOM_PARAMS\"],\n            after_scheduler=self.scheduler,\n        )  # total epoch = warmup epoch\n        self.val_predictions = None\n        self.date = datetime.datetime.now(pytz.timezone(\"Asia\/Singapore\")).strftime(\n            \"%Y-%m-%d\"\n        )\n\n        self.log(\n            \"Trainer prepared. We are using {} device.\".format(self.config[\"DEVICE\"])\n        )\n\n    def fit(self, train_loader, val_loader, fold: int):\n        \"\"\"Fit the model on the given fold.\"\"\"\n        self.log(\n            \"Training on Fold {} and using {}\".format(\n                fold, self.config[\"MODEL\"][\"MODEL_NAME\"]\n            )\n        )\n\n        for _epoch in range(1, self.num_epochs+1):\n            # Getting the learning rate after each epoch!\n            current_lr = self.optimizer.param_groups[0][\"lr\"]\n\n            timestamp = datetime.datetime.now(pytz.timezone(\"Asia\/Singapore\")).strftime(\n                \"%Y-%m-%d %H-%M-%S\"\n            )\n            # printing the lr and the timestamp after each epoch.\n            self.log(\"\\n{}\\nLR: {}\".format(timestamp, current_lr))\n\n            # start time of training on the training set\n            train_start_time = time.time()\n\n            # train one epoch on the training set\n            avg_train_loss = self.train_one_epoch(train_loader)\n            # end time of training on the training set\n            train_end_time = time.time()\n\n            # formatting time to make it nicer\n            train_elapsed_time = time.strftime(\n                \"%H:%M:%S\", time.gmtime(train_end_time - train_start_time)\n            )\n            self.log(\n                \"[RESULT]: Train. Epoch {} | Avg Train Summary Loss: {:.3f} | \"\n                \"Time Elapsed: {}\".format(\n                    self.epoch + 1,\n                    avg_train_loss,\n                    train_elapsed_time,\n                )\n            )\n\n            val_start_time = time.time()\n\n            (\n                avg_val_loss,\n                avg_val_roc,\n                val_predictions,\n            ) = self.valid_one_epoch(val_loader)\n            # here we get oof preds\n            self.val_predictions = val_predictions\n            val_end_time = time.time()\n            val_elapsed_time = time.strftime(\n                \"%H:%M:%S\", time.gmtime(val_end_time - val_start_time)\n            )\n            # self.neptune[\"Metrics\/AUC\"].log(avg_val_roc)\n            self.log(\n                \"[RESULT]: Validation. Epoch: {} | \"\n                \"Avg Validation Summary Loss: {:.3f} | \"\n                \"Validation ROC: {:.3f} | Time Elapsed: {}\".format(\n                    self.epoch + 1,\n                    avg_val_loss,\n                    avg_val_roc,\n                    val_elapsed_time,\n                )\n            )\n\n            # added this flag right before early stopping to let user\n            # know which metric im monitoring.\n            self.monitored_metrics = avg_val_roc\n\n            if self.early_stopping is not None:\n\n                best_score, early_stop = self.early_stopping.should_stop(\n                    curr_epoch_score=self.monitored_metrics\n                )\n                self.best_loss = best_score\n                self.save(\n                    \"{}_best_loss_fold_{}.pt\".format(\n                        self.config[\"MODEL\"][\"MODEL_NAME\"], fold\n                    )\n                )\n                if early_stop:\n                    break\n\n            else:\n\n                if avg_val_loss < self.best_loss:\n                    self.best_loss = avg_val_loss\n\n            if self.best_auc < avg_val_roc:\n                self.best_auc = avg_val_roc\n                self.save(\n                    os.path.join(\n                        self.save_path,\n                        \"{}_{}_best_auc_fold_{}.pt\".format(\n                            self.date, self.config[\"MODEL\"][\"MODEL_NAME\"], fold\n                        ),\n                    )\n                )\n                self.patience = 3\n            else:\n                self.patience -= 1\n                if self.patience == 0:\n                    print(\"Early Stopping\")\n                    break\n\n            '''\n            CosineAnnealingWarmRestart\n            '''\n            self.scheduler_warmup.step()\n            if _epoch == 2: self.scheduler_warmup.step()\n\n\n            if self.config[\"SCHEDULER\"][\"VAL_STEP\"]:\n                if isinstance(\n                    self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau\n                ):\n                    self.scheduler.step(self.monitored_metrics)\n                else:\n                    self.scheduler.step()\n\n            # end of training, epoch + 1 so that self.epoch can be updated.\n            self.epoch += 1\n\n        curr_fold_best_checkpoint = self.load(\n            os.path.join(\n                self.save_path,\n                \"{}_{}_best_auc_fold_{}.pt\".format(\n                    self.date, self.config[\"MODEL\"][\"MODEL_NAME\"], fold\n                ),\n            )\n        )\n        return curr_fold_best_checkpoint\n\n    def train_one_epoch(self, train_loader):\n        \"\"\"Train one epoch of the model.\"\"\"\n        # set to train mode\n        self.model.train()\n\n        # log metrics\n        train_summary_loss = AverageLossMeter()\n        # TODO: use Alex's ROC METER?\n\n        # timer\n        start_time = time.time()\n        train_bar = train_loader\n        # looping through train loader for one epoch, steps is the\n        # number of times to go through each epoch\n        for step, (images, labels) in enumerate(train_bar):\n            if self.config['DATA']['USE_MIXUP']:\n\n                images, labels = (\n                    images.float(),\n                    labels,\n                )\n                images, targets_a, targets_b, lam = mixup_data(images, labels.view(-1, 1), use_cuda=True)\n                images, targets_a, targets_b = images.to(self.device), targets_a.to(self.device), targets_b.to(self.device)\n            else:\n                images, labels = (\n                    images.to(self.device).float(),\n                    labels.to(self.device),\n                )\n\n \n            batch_size = labels.shape[0]\n\n            if (\n                self.config[\"TRAIN\"][\"SETTINGS\"][\"USE_AMP\"] is True\n                and self.config[\"TRAIN\"][\"SETTINGS\"][\"USE_GRAD_ACCUM\"] is False\n            ):\n\n                \"\"\"I would think clearing gradients here is the correct way, as opposed to calling it last.\"\"\"\n                self.optimizer.zero_grad()\n                with torch.cuda.amp.autocast():\n                    logits = self.model(images)\n                    if self.config[\"DATA\"][\"USE_MIXUP\"]:\n                        train_loss = mixup_criterion(self.criterion_train, logits, targets_a, targets_b, lam)\n                    else:\n                        train_loss = self.criterion_train(input=logits.view(-1), target=labels) # use view here for BCELogitLoss\n\n                loss_value = train_loss.item()\n                self.scaler.scale(train_loss).backward()\n                self.scaler.step(self.optimizer)\n                self.scaler.update()\n\n            elif (\n                self.config[\"TRAIN\"][\"SETTINGS\"][\"USE_AMP\"] is True\n                and self.config[\"TRAIN\"][\"SETTINGS\"][\"USE_GRAD_ACCUM\"] is True\n            ):\n\n                with torch.cuda.amp.autocast():\n                    logits = self.model(images)\n                    train_loss = self.criterion_train(input=logits, target=labels)\n                    train_loss = (\n                        train_loss\n                        \/ self.config[\"TRAIN\"][\"SETTINGS\"][\"ACCUMULATION_STEP\"]\n                    )\n                loss_value = train_loss.item()\n                self.scaler.scale(train_loss).backward()\n                if (step + 1) % self.config[\"TRAIN\"][\"SETTINGS\"][\n                    \"ACCUMULATION_STEP\"\n                ] == 0:\n                    self.scaler.step(self.optimizer)\n                    self.scaler.update()\n                    self.optimizer.zero_grad()\n            else:\n                logits = self.model(images)\n                train_loss = self.criterion_train(input=logits, target=labels)\n                loss_value = train_loss.item()\n                self.optimizer.zero_grad()\n                train_loss.backward()\n                self.optimizer.step()\n            train_summary_loss.update(train_loss.item(), batch_size)\n            # here onwards, we have already completed the necessary forward pass and backprop, so we can come out of the if else loop.\n\n            y_true = labels.cpu().numpy()\n\n            softmax_preds = torch.nn.Softmax(dim=1)(input=logits).cpu().detach().numpy()\n            y_preds = np.argmax(a=softmax_preds, axis=1)\n\n            # measure elapsed time\n            end_time = time.time()\n            #train_bar.set_description(f\"loss: {train_summary_loss.avg:.3f}\")\n\n            if self.config[\"TRAIN\"][\"SETTINGS\"][\"VERBOSE\"]:\n                if (step % self.config[\"TRAIN\"][\"SETTINGS\"][\"VERBOSE_STEP\"]) == 0:\n                    print(\n                        f\"Train Steps {step}\/{len(train_loader)}, \"\n                        f\"summary_loss: {train_summary_loss.avg:.3f}, \"\n                        f\"time: {(end_time - start_time):.3f}\",\n                        end=\"\\r\",\n                    )\n\n        return train_summary_loss.avg\n\n    # @torch.no_grad\n    def valid_one_epoch(self, val_loader):\n        \"\"\"Validate one training epoch.\"\"\"\n        # set to eval mode\n        self.model.eval()\n\n        # log metrics\n        valid_summary_loss = AverageLossMeter()\n\n        # timer\n        start_time = time.time()\n\n        LOGITS = []\n        Y_TRUE = []\n        Y_PROBS = []\n        POSITIVE_CLASS_PROBS = []\n\n        with torch.no_grad():\n            for step, (images, labels) in enumerate(val_loader):\n\n                images, labels = (\n                    images.to(self.device).float(),\n                    labels.to(self.device),\n                )\n\n                batch_size = labels.shape[0]\n\n                logits = self.model(images)\n                val_loss = self.criterion_val(input=logits.view(-1), target=labels) # use view here for BCELogitLoss\n                loss_value = val_loss.item()\n                valid_summary_loss.update(loss_value, batch_size)\n                sigmoid_preds = torch.sigmoid(logits)\n                y_preds = np.argmax(a=sigmoid_preds.detach().cpu(), axis=1)\n                LOGITS.append(logits.detach().cpu())\n                Y_TRUE.append(labels.detach().cpu())\n                Y_PROBS.append(sigmoid_preds.detach().cpu())\n\n                end_time = time.time()\n\n                if self.config[\"TRAIN\"][\"SETTINGS\"][\"VERBOSE\"]:\n                    if (step % self.config[\"TRAIN\"][\"SETTINGS\"][\"VERBOSE_STEP\"]) == 0:\n                        print(\n                            f\"Validation Steps {step}\/{len(val_loader)}, \"\n                            + f\"summary_loss: {valid_summary_loss.avg:.3f},\"\n                            + f\"time: {(end_time - start_time):.3f}\",\n                            end=\"\\r\",\n                        )\n\n            LOGITS = torch.cat(LOGITS).numpy()\n            Y_TRUE = torch.cat(Y_TRUE).numpy()\n            Y_PROBS = torch.cat(Y_PROBS).numpy()\n            \n\n            if self.config[\"DATA\"][\"NUM_CLASSES\"] > 2:\n                val_roc_auc_score = sklearn.metrics.roc_auc_score(\n                    y_true=Y_TRUE, y_score=Y_PROBS, multi_class=\"ovr\"\n                )\n            else:\n                val_roc_auc_score = sklearn.metrics.roc_auc_score(\n                    y_true=Y_TRUE, y_score=Y_PROBS\n                )\n\n        return (valid_summary_loss.avg, val_roc_auc_score, Y_PROBS)\n\n    def save_model(self, path):\n        \"\"\"Save the trained model.\"\"\"\n        self.model.eval()\n        torch.save(self.model.state_dict(), path)\n\n    # will save the weight for the best val loss and corresponding oof preds\n    def save(self, path):\n        \"\"\"Save the weight for the best evaluation loss.\"\"\"\n        self.model.eval()\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"scheduler_state_dict\": self.scheduler.state_dict(),\n                \"best_auc\": self.best_auc,\n                \"best_loss\": self.best_loss,\n                \"epoch\": self.epoch,\n                \"oof_preds\": self.val_predictions,\n            },\n            path,\n        )\n\n    def load(self, path):\n        \"\"\"Load a model checkpoint from the given path.\"\"\"\n        checkpoint = torch.load(path)\n        return checkpoint\n\n    def log(self, message):\n        \"\"\"Log a message.\"\"\"\n        if self.config[\"TRAIN\"][\"SETTINGS\"][\"VERBOSE\"]:\n            print(message)\n        with open(self.config[\"PATH\"][\"LOG_PATH\"], \"a+\") as logger:\n            logger.write(f\"{message}\\n\")","ba9b07ad":"def train_on_fold(model, df_folds: pd.DataFrame, config, fold: int, neptune=None):\n    \"\"\"Train the model on the given fold.\"\"\"\n\n    model.to(config[\"DEVICE\"])\n    \n    try:\n        model_summary = torchsummary_wrapper(\n            model, (1, config[\"DATA\"][\"IMAGE_SIZE\"], config[\"DATA\"][\"IMAGE_SIZE\"])\n        )\n    except RuntimeError:\n        print(\"Check the channel number.\")\n\n    print(\"Model Summary: \\n{}\".format(model_summary))\n\n    if config[\"TRAIN\"][\"SETTINGS\"][\"DEBUG\"]:\n        # args.n_epochs = 5\n        df_train = df_folds[df_folds[\"fold\"] != fold].sample(\n            config[\"TRAIN\"][\"DATALOADER\"][\"batch_size\"] * 128\n        )\n        df_valid = df_folds[df_folds[\"fold\"] == fold].sample(\n            config[\"TRAIN\"][\"DATALOADER\"][\"batch_size\"] * 128\n        )\n    else:\n        df_train = df_folds[df_folds[\"fold\"] != fold].reset_index(drop=True)\n        df_valid = df_folds[df_folds[\"fold\"] == fold].reset_index(drop=True)\n\n    dataset_train = AlienTrainDataset(\n        config=config,\n        df=df_train,\n        mode=\"train\",\n        transform=Transform(config[\"TRAIN_TRANSFORMS\"]),\n    )\n    dataset_valid = AlienTrainDataset(\n        config=config,\n        df=df_valid,\n        mode=\"valid\",\n        transform=Transform(config[\"VALID_TRANSFORMS\"]),\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        dataset_train,\n        # sampler=RandomSampler(dataset_train),\n        **config[\"TRAIN\"][\"DATALOADER\"],\n    )\n    valid_loader = torch.utils.data.DataLoader(\n        dataset_valid, **config[\"VALIDATION\"][\"DATALOADER\"]\n    )\n\n    hongnan_classifier = Trainer(model=model, config=config, neptune=neptune)\n\n    curr_fold_best_checkpoint = hongnan_classifier.fit(train_loader, valid_loader, fold)\n    # print(len(curr_fold_best_checkpoint[\"oof_preds\"]))\n    df_valid[\n        [str(c) for c in range(config[\"DATA\"][\"NUM_CLASSES\"])]\n    ] = curr_fold_best_checkpoint[\"oof_preds\"]\n    # val_df[\"preds\"] = curr_fold_best_checkpoint[\"oof_preds\"].argmax(1)\n\n    return df_valid\n\n\ndef train_loop(\n    model,\n    df_folds: pd.DataFrame,\n    config,\n    fold_num: int = None,\n    train_one_fold=False,\n    neptune=None,\n):\n    \"\"\"Perform the training loop on all folds. Here The CV score is the average of the validation fold metric.\n    While the OOF score is the aggregation of all validation folds.\"\"\"\n\n    cv_score_list = []\n    oof_df = pd.DataFrame()\n    if train_one_fold:\n        _oof_df = train_on_fold(\n            model, df_folds=df_folds, config=config, fold=fold_num, neptune=neptune\n        )\n        _oof_df.to_csv(os.path.join(config[\"PATH\"][\"OOF_PATH\"], \"_oof.csv\"))\n        # curr_fold_best_score = get_oof_roc(config, _oof_df)\n        # print(\"Fold {} OOF Score is {}\".format(fold_num, curr_fold_best_score))\n    else:\n        \"\"\"The below for loop code guarantees fold starts from 1 and not 0. https:\/\/stackoverflow.com\/questions\/33282444\/pythonic-way-to-iterate-through-a-range-starting-at-1\"\"\"\n        for fold in (\n            number + 1 for number in range(config[\"CROSS_VALIDATION\"][\"NUM_FOLDS\"])\n        ):\n            _oof_df = train_on_fold(\n                model, df_folds=df_folds, config=config, fold=fold, neptune=neptune\n            )\n            oof_df = pd.concat([oof_df, _oof_df])\n            curr_fold_best_score_dict, curr_fold_best_score = get_oof_roc(\n                config, _oof_df\n            )\n            cv_score_list.append(curr_fold_best_score)\n            print(\n                \"\\n\\n\\nOOF Score for Fold {}: {}\\n\\n\\n\".format(\n                    fold, curr_fold_best_score\n                )\n            )\n\n        print(\"CV score\", np.mean(cv_score_list))\n        print(\"Variance\", np.var(cv_score_list))\n        print(\"Five Folds OOF\", get_oof_roc(config, oof_df))\n        oof_df.to_csv(os.path.join(config[\"PATH\"][\"OOF_PATH\"], \"oof.csv\"))\n","fdb28df9":"model_pretrained = AlienSingleHead(config=config, pretrained=True)\ntrain_loop(\n    model_pretrained, df_folds, config, fold_num=2, train_one_fold=True, neptune=None\n)","118429e2":"test = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\ntest['file_path'] = test['id'].apply(lambda x: f'..\/input\/seti-breakthrough-listen\/test\/{x[0]}\/{x}.npy')\ndisplay(test.head())","7125e2e7":"device = config['DEVICE']","2453fcbc":"def inference_by_fold(config, model, state_dicts, test_loader):\n    model.to(device)\n    model.eval()\n    probs = []\n\n    with torch.no_grad():\n        all_folds_preds = []\n        for fold_num, state in enumerate(state_dicts):\n            if \"model_state_dict\" not in state:\n                model.load_state_dict(state)\n            else:\n                model.load_state_dict(state[\"model_state_dict\"])\n\n            current_fold_preds = []\n            for data in tqdm(test_loader, position=0, leave=True):\n                images = data\n                images = images.to(device)\n                logits = model(images)\n\n                sigmoid_preds = logits.sigmoid().detach().cpu().numpy()\n                current_fold_preds.append(sigmoid_preds)\n\n            current_fold_preds = np.concatenate(current_fold_preds, axis=0)\n            all_folds_preds.append(current_fold_preds)\n        avg_preds = np.mean(all_folds_preds, axis=0)\n    return avg_preds\n\ndef LoadTestSet(test_df: pd.DataFrame, config):\n    \"\"\"Train the model on the given fold.\"\"\"\n    model = AlienSingleHead(config,pretrained=False)\n    model.to(device)\n\n\n\n    def ET_TEST_AUG(image_size=384):\n\n        transforms_test = Transform(config[\"TEST_TRANSFORMS\"])\n    \n        transforms_tta_test = Transform(config[\"TEST_TRANSFORMS\"])\n        \n        return transforms_test, transforms_tta_test\n\n    transforms_test, transforms_tta_test = ET_TEST_AUG(image_size=config['DATA']['IMAGE_SIZE'])\n\n    \n    test_dataset = AlienTrainDataset(df=test,config=config, mode='test', transform=transforms_test)\n    tta_test_dataset = AlienTrainDataset(df=test,config=config, mode='test', transform=transforms_tta_test)\n    \n    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, \n                             num_workers=4, pin_memory=True)\n    tta_test_loader = torch.utils.data.DataLoader(\n        tta_test_dataset, batch_size=64, shuffle=False, num_workers=4\n    )\n\n    \n    weights = [\"2021-08-10_efficientnet_b0_best_auc_fold_1.pt\"]\n    \n\n    state_dicts = [torch.load(path)['model_state_dict'] for path in weights]\n\n    predictions = inference_by_fold(config=config, model=model, state_dicts = state_dicts, test_loader=test_loader)\n    test['target'] = predictions\n    test[['id', 'target']].to_csv('submission.csv', index=False)\n    test.head()\n\n    import matplotlib.pyplot as plt\n\n    plt.figure(figsize=(12,6))\n    plt.hist(test.target,bins=100)","75430a51":"LoadTestSet(test, config)","47724f64":"# Data Loading","0c9a99b3":"# Meters","05e20988":"# Train","05520040":"# Warmup Scheduler","b864984b":"# Dataset","a41ec04c":"# Training in progress","d1cb0724":"# Augmentations","772925cd":"# Inference","e607d9dc":"# Cross Validation","f955df50":"# Forewords\n\n### You can also check my other notebook on [Forward Selection to get 0.98](https:\/\/www.kaggle.com\/reighns\/lb-0-98-cv-0-9915-forward-ensembling-technique?scriptVersionId=65419326).","1e01f1ea":"# Model","274b9b0b":"# Install Dependencies and Import Libraries","96849417":"# Train on Folds","a7691abe":"# Config","eda59277":"This notebook fixes the bugs in Gradual Warmup, hopefully.\n","6a3ae40a":"# Seed"}}