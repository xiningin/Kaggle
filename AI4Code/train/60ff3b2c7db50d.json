{"cell_type":{"03736f15":"code","ef787b87":"code","e728c4aa":"code","bf218d04":"code","4d0d6626":"code","428c145c":"code","c7fe97ca":"code","af3fb39a":"code","068ae829":"code","ef9ae9d9":"code","d31b9a9e":"code","331128f5":"code","23d7a996":"code","d92405e8":"code","f3561154":"code","cede9ba6":"code","fa315bb9":"code","012b5741":"code","8db75a4e":"code","12d2e8d3":"code","30d94645":"code","9390d5df":"code","99dd1b27":"code","ac67b14c":"code","0cc8998d":"code","c64f9155":"code","bba2c502":"code","5a50793f":"code","ecbe1893":"code","33208540":"code","7d96f8cd":"code","237a100c":"code","8f68835d":"code","461c43b2":"code","2239e318":"code","edf07b52":"code","d6ad2bd8":"code","14d7fd9c":"code","668f03b8":"code","29ac6584":"code","97736c37":"code","74ff4da6":"code","769b264e":"code","f651765b":"code","cc01c0e2":"code","3aa2a1a1":"code","09582d72":"code","5251cebd":"code","2ed6a17c":"code","feb233d5":"code","b1ee421b":"code","52887066":"code","046e317f":"code","9b793491":"code","1089625f":"code","3911c421":"code","3817789f":"code","42c5699e":"code","84e7a28c":"code","3ffcfd4b":"code","f1e05886":"code","c4bdfd83":"code","6fcd1566":"code","ebd093d5":"code","603993b2":"code","9d420335":"code","5c8dde4f":"code","14878a1b":"code","a4e6ab4a":"code","d3cc40cd":"code","4d49ac27":"code","135fe84e":"code","f778df55":"code","bcad7189":"code","744b7de3":"code","b5225156":"code","c3653c96":"code","d8beaf27":"code","5c007aaa":"code","d5d7fb13":"code","4335045e":"code","052e16f6":"code","f02dc930":"code","e25b2e50":"code","9687c1fe":"code","c0bdf496":"code","5fe81915":"code","59748c7b":"code","480e516b":"code","e355c2bb":"code","ce7908de":"code","cabc369b":"code","5f6f3498":"code","fd6efc64":"code","caa3a3a1":"code","6ddcfc2e":"code","f65fd80b":"code","f79b2a6b":"code","28b08a33":"code","29913063":"code","76f8ec54":"code","cf499c94":"code","cc972f1d":"code","b149aeeb":"code","5846202e":"code","956c5588":"code","f3ac9461":"code","13a88bab":"code","eba3edff":"code","782f5b4e":"code","7c15a22b":"code","55b3e63a":"code","14b74ff5":"code","776b4319":"code","58869c5b":"code","c1d8ca2a":"code","197cb27e":"code","4bb6f026":"code","7177f870":"code","9e34cf36":"code","f053ca0c":"code","e77d4931":"code","88cd93a9":"code","5a38c7a4":"code","30b874b4":"code","a526eca8":"code","bd41cd65":"code","0af2bb13":"code","cf16999d":"code","ff7f8546":"code","dc0b5bc1":"code","ff580498":"code","02b77fc2":"code","0cab2a07":"code","61f203fa":"code","b8df569c":"code","1dea6483":"code","dfd43ab7":"code","90c5a940":"code","8ca41e49":"code","2b78aff4":"code","03f89fca":"code","236dd4df":"code","ea3a6c1b":"code","e6735022":"code","323e99f6":"code","e922880a":"code","e2cc205f":"code","e99bd2fa":"code","9214f451":"code","e5d9fd49":"code","0f26b511":"code","47467060":"code","1f470160":"code","d91fcfe2":"code","28ada2b6":"code","d8068640":"code","d6044d7a":"code","1640ebf7":"code","6606fd52":"code","06f52646":"code","39d2f060":"code","465f6991":"code","b53de506":"code","28422faa":"code","6d81b43f":"code","e7864f28":"code","9003334f":"code","16a63fea":"code","1e20f043":"code","6115b7d5":"code","4185e4ef":"code","f33f23e0":"code","23e6a4e4":"code","f6b28ee8":"code","ff2768ff":"code","32e60403":"code","1ba6de74":"code","b8c1a76c":"code","29984a06":"code","fac0c8bf":"code","6ebe255c":"code","5f27abd9":"code","dcf037ca":"code","d1384ef7":"code","2b0a3110":"code","b5a64a73":"code","03dea5fa":"code","1f4bb5f3":"code","f9a4463e":"code","6df1ba53":"code","fab67b56":"code","91080997":"code","5ed0d1c7":"code","5816d866":"code","0d11c993":"code","98cbff8a":"code","38d9d231":"code","c99ac7ff":"code","9f9c211e":"code","68427261":"code","d88dbb79":"code","32bd8c11":"code","8e0b6481":"code","f8f5abe8":"code","7cd22911":"code","9b28d71f":"code","02f6dcc8":"code","fb69b3b4":"code","2fe6ecc9":"code","aca199ef":"code","63e6393f":"code","f8542377":"code","6f9e90e9":"code","e9b2cc24":"code","3d1c468f":"code","780b6e0a":"code","f8c2d4de":"code","f8907f9f":"code","a4721c72":"code","9d7999dd":"code","66a49685":"code","33c176df":"code","47289716":"code","a5e4e931":"code","e33fd16f":"code","0729e732":"code","52f5d993":"code","f37c78b1":"code","e16087d3":"code","0fca48af":"code","547ec812":"code","f474a406":"code","c4696dc1":"code","18cabacd":"code","59e8a0c0":"code","4527b25b":"code","2ed28819":"code","e10da3fd":"code","6e4650f5":"code","74f51851":"code","9c951b1b":"code","cb7ff910":"code","4c523df5":"code","862b7f41":"code","b0c5ec7d":"code","3ebae568":"code","161b882a":"code","27f16620":"code","d74c4dd3":"code","62cae3d8":"code","83153939":"code","1ddd9102":"code","a4cc3d87":"code","861399b0":"code","ecafff60":"code","4257e889":"code","cb13594b":"code","730110ec":"code","7b3fbf93":"code","4adbacbe":"code","3606f39c":"code","7142ffa5":"code","ef856017":"code","ff9f29fe":"code","dd6a240b":"code","d8be51b1":"code","7b505031":"code","7834166f":"code","1c93e90d":"code","164ad8c6":"code","08b623d3":"code","53eeea3a":"code","20dcf71c":"code","4031f521":"code","e969fa88":"code","a19e5515":"code","b228bfd9":"code","daf601de":"code","84a030cd":"code","38f55008":"code","5702b592":"code","0cf4eeb5":"code","74363b00":"code","8fadcb02":"code","f6c338d8":"code","3b3f313f":"code","6d87213b":"code","a76fd39c":"code","17885d23":"code","a83ed366":"code","3185ded5":"code","a6568164":"code","e675743d":"code","15c4261b":"code","069efb77":"code","08a02270":"code","fe431633":"code","001c9927":"code","e2dfb81d":"code","17c71e00":"markdown","8bf943ea":"markdown","3c85232d":"markdown","531bf4ec":"markdown","4fd5deb6":"markdown","105a7c55":"markdown","0d1cc942":"markdown","802170f0":"markdown","925eedcf":"markdown","e41fcb2c":"markdown","0b2004fb":"markdown","3197c3e6":"markdown","bccb507d":"markdown","e39728a0":"markdown","a17cd079":"markdown","2ada44be":"markdown","3871ae90":"markdown","1aab2ae8":"markdown","f8905f34":"markdown","1f6a9950":"markdown","f22d8ae9":"markdown","8db4e613":"markdown","4d63dc18":"markdown","d13f0f7c":"markdown","ce713fc6":"markdown","227c43db":"markdown","44ccc0e9":"markdown","274ce72e":"markdown","aa1212cf":"markdown","3c813c18":"markdown","384c1b01":"markdown","d9669101":"markdown","4a1af6ee":"markdown","eeff3e03":"markdown","186d2e9d":"markdown","40cb1537":"markdown","24967c51":"markdown","0aafd832":"markdown","e566bbd7":"markdown","f1dc1e05":"markdown","0ac9ca36":"markdown","676d28a4":"markdown","8b47aa84":"markdown","d243713d":"markdown","38f5454b":"markdown","78a8dce4":"markdown","e03a30a5":"markdown","64cb0c61":"markdown","95301292":"markdown","8753d1b3":"markdown","b70212d9":"markdown","20f28c96":"markdown","9dc08c86":"markdown","9bec79d8":"markdown","b66f5798":"markdown","f45913f5":"markdown","1ad59d60":"markdown","a8b3ad71":"markdown","9ec990da":"markdown","28249a4b":"markdown","86c01c14":"markdown","4a1e9796":"markdown","5a8ce1f2":"markdown","5bbb40f6":"markdown","bb253eae":"markdown","670472c6":"markdown","141126f4":"markdown","ef5e4a4b":"markdown","0baa6c29":"markdown","5ddb09ac":"markdown","2000a8fe":"markdown","845b0b00":"markdown","f3c39f97":"markdown","607f1005":"markdown","08e7f6d3":"markdown","f65aa0b4":"markdown","2e592c67":"markdown","a897ab39":"markdown","377f3534":"markdown","4d4faa63":"markdown","2c5aea0d":"markdown","070ac889":"markdown","c536ec29":"markdown","72d03689":"markdown","8cff2ac8":"markdown","82df058a":"markdown","ee6be609":"markdown","dbba2ce5":"markdown","01974d43":"markdown","b94ca9fc":"markdown","bafa0901":"markdown","33efdc5a":"markdown","29462e18":"markdown","99e7792f":"markdown","9a37a682":"markdown","069e6a33":"markdown","8308fdff":"markdown","e65d80c3":"markdown","5267cb5b":"markdown","e329dd6e":"markdown","e8800b0b":"markdown","08537a55":"markdown","7b6f351e":"markdown","1a310b30":"markdown","814b31f3":"markdown","a21f3d51":"markdown","611cc542":"markdown","139b0414":"markdown","e05ee9ef":"markdown","18c1b6e9":"markdown","7b5b3f24":"markdown","d0652462":"markdown","4f9e73dd":"markdown","d68dd091":"markdown","f999f25b":"markdown","b7e51171":"markdown","190bda25":"markdown","7eb0b1ce":"markdown","3116262a":"markdown","ce784ca2":"markdown","47944a8f":"markdown","2623a404":"markdown","8f0bc51b":"markdown","67d0d691":"markdown","e13c7948":"markdown","f9364fbf":"markdown","e94893ec":"markdown","d4ae85d4":"markdown","1780cdbc":"markdown","850e7ad9":"markdown","28e93248":"markdown","0eb44294":"markdown","f82ec781":"markdown","c961fd83":"markdown","48755c9a":"markdown","0381e654":"markdown","2e12c73e":"markdown","d00c003b":"markdown","e344f47a":"markdown","0844b903":"markdown","d4249bd4":"markdown","4d7c9f05":"markdown","3c051f05":"markdown","4e7bcb2a":"markdown","f64a1450":"markdown","9ede754b":"markdown","81abe0d7":"markdown","095666bf":"markdown","3cee3b70":"markdown"},"source":{"03736f15":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib\n\nmatplotlib.rcParams['figure.dpi'] = 200\nmatplotlib.rcParams['figure.figsize'] = (15, 5)\n\nsns.set_style(\"darkgrid\")","ef787b87":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e728c4aa":"train_original = pd.read_csv('\/kaggle\/input\/train_LZdllcl.csv')\ntest_original = pd.read_csv('\/kaggle\/input\/test_2umaH9m.csv')","bf218d04":"train_original.head()","4d0d6626":"train_original.shape","428c145c":"%%time\ntrain_original.isna().sum()","c7fe97ca":"%%time\nnull_vals = train_original['education'].value_counts(dropna = False)\nnull_vals[null_vals.index.isnull()]","af3fb39a":"%%time\ntrain_original['education'].isna().sum()","068ae829":"train_original.info()","ef9ae9d9":"X_train, X_test, Y_train, Y_test = train_test_split(\n    train_original.drop(['is_promoted'], axis = 1), \n    train_original['is_promoted'], \n    test_size = 0.3, random_state = 42)","d31b9a9e":"print(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","331128f5":"X_train.head()","23d7a996":"X_train, X_val, Y_train, Y_val = train_test_split(\n    X_train, \n    Y_train, \n    test_size = 0.3)","d92405e8":"print(X_train.shape)\nprint(X_val.shape)\nprint(Y_train.shape)\nprint(Y_val.shape)","f3561154":"X_train.info()","cede9ba6":"print(\"\\033[1mColumns with NULL values: \\033[0m\")\nX_train.isnull().sum().to_frame().style.background_gradient('Oranges')","fa315bb9":"null_education = X_train[X_train['education'].isnull()]\nnull_education","012b5741":"def beauty_print(df, columns = None, cmap = \"Blues\"):\n    if columns == None:\n        columns = df.columns\n    return df.style.background_gradient(cmap, subset = columns)","8db75a4e":"beauty_print(null_education['region'].value_counts().to_frame())","12d2e8d3":"beauty_print(null_education['department'].value_counts().to_frame())","30d94645":"beauty_print(null_education['department'].value_counts().to_frame(), cmap = 'YlOrRd')","9390d5df":"for group, item in X_train.groupby(['education']):\n    print(group)\n    print(item['department'].value_counts(dropna = False).to_frame())","99dd1b27":"beauty_print(X_train['education'].value_counts(dropna = False, normalize = True).to_frame(), cmap = 'plasma')","ac67b14c":"beauty_print(X_train['previous_year_rating'].value_counts(dropna = False, normalize = True).to_frame(), cmap = 'plasma')","0cc8998d":"X_train['education'].fillna(value = 'Unknown', inplace = True)\nX_val['education'].fillna(value = 'Unknown', inplace = True)\nX_test['education'].fillna(value = 'Unknown', inplace = True)\ntest_original['education'].fillna(value = 'Unknown', inplace = True)","c64f9155":"X_train","bba2c502":"Y_train","5a50793f":"null_rating = X_train[X_train['previous_year_rating'].isna()]\nbeauty_print(null_rating['length_of_service'].value_counts(dropna = False, normalize = True).to_frame(), cmap = 'plasma')","ecbe1893":"null_rating.head()","33208540":"X_train[['no_of_trainings', 'previous_year_rating', 'avg_training_score', 'KPIs_met >80%', 'awards_won?']].corr().style.background_gradient(cmap = 'Blues')","7d96f8cd":"X_train.groupby('previous_year_rating')[['age', 'no_of_trainings', 'avg_training_score', 'KPIs_met >80%', 'awards_won?']].mean().style.bar()","237a100c":"X_train['previous_year_rating'].fillna(value = 0, inplace = True, axis = 0)\nX_val['previous_year_rating'].fillna(value = 0, inplace = True, axis = 0)\nX_test['previous_year_rating'].fillna(value = 0, inplace = True, axis = 0)\ntest_original['previous_year_rating'].fillna(value = 0, inplace = True, axis = 0)","8f68835d":"X_train.isnull().sum()","461c43b2":"X_train.duplicated().sum()","2239e318":"X_train.T","edf07b52":"X_train.T.duplicated().sum()","d6ad2bd8":"X_train.drop('employee_id', axis = 1).var().to_frame()","14d7fd9c":"X_train['awards_won?'].value_counts(normalize = True)","668f03b8":"X_train.info()","29ac6584":"X_train['gender'].value_counts().plot(kind='bar',title = \"Gender distribution\")","97736c37":"X_train['gender'].value_counts(normalize = True)","74ff4da6":"combine = X_train.merge(Y_train, left_index=True, right_index=True)\ncombine","769b264e":"promoted_gender = combine.groupby(['is_promoted','gender'])['is_promoted'].count()\nc1 = (promoted_gender[1]\/(promoted_gender[0] + promoted_gender[1])).plot.bar(color='green')\nc2 = (promoted_gender[0]\/(promoted_gender[0] + promoted_gender[1])).plot.bar(color='lightgreen', bottom=(promoted_gender[1]\/(promoted_gender[0] + promoted_gender[1])))\nhandles, labels = c2.get_legend_handles_labels()\nplt.axhline(y=(promoted_gender[1]\/(promoted_gender[0] + promoted_gender[1])).max())\nplt.legend(handles, ['promoted', 'not promoted'])","f651765b":"X_train['education'].value_counts().plot(kind = 'bar', color = \"Red\", title = \"Education distribution\")","cc01c0e2":"(X_train['education'].value_counts()\/len(X_train)).plot(kind = 'bar', color = \"Red\", title = \"Education distribution percentage\")","3aa2a1a1":"plt.title('Education distribution across genders')\nsns.countplot(x = X_train['education'], hue = X_train['gender'])","09582d72":"plt.figure(figsize=(14, 7))\nplt.title('Promoted employees across Education groups')\nax = combine.groupby('is_promoted')['education'].value_counts()\nc1 = (ax[1]*100\/(ax[0] + ax[1])).plot.bar(color='orange')\nc2 = (ax[0]*100\/(ax[0] + ax[1])).plot.bar(color='blue', bottom = (ax[1]*100\/(ax[0] + ax[1])))\nplt.axhline(y=(ax[1]*100\/(ax[0] + ax[1])).max(), color='red', linewidth=0.7)\nplt.axhline(y=(ax[1]*100\/(ax[0] + ax[1])).min(), color='red', linewidth=0.5)\nhandles, labels = c2.get_legend_handles_labels()\nplt.legend(handles, ['promoted', 'not promoted'])\nplt.show()","5251cebd":"plt.figure(figsize=(16, 8))\nplt.title('Age distribution')\nsns.distplot(X_train['age'], rug = True,\n             color = 'green', hist_kws={\n    'color' : \"red\",\n})","2ed6a17c":"plt.title('Count of ratings')\nsns.countplot(x=X_train['previous_year_rating'])","feb233d5":"sns.countplot(x = combine['previous_year_rating'], hue = combine['is_promoted'])","b1ee421b":"promoted_ratings = combine.groupby(['is_promoted', 'previous_year_rating'])['is_promoted'].count()\npromoted_ratings.xs(1, level='is_promoted').plot(kind='pie', y='is_promoted', autopct='%1.1f%%', shadow=True, startangle=90, legend=False, title='Percentage of employees promoted', explode=(0, 0, 0, 0, 0, 0.2))","52887066":"promoted_ratings[1]\/(promoted_ratings[0]+promoted_ratings[1])","046e317f":"c1 = (promoted_ratings[1]\/(promoted_ratings[0]+promoted_ratings[1])).plot.bar()\nc2 = (promoted_ratings[0]\/(promoted_ratings[0]+promoted_ratings[1])).plot.bar(color='red', bottom=(promoted_ratings[1]\/(promoted_ratings[0]+promoted_ratings[1])))\nhandles, labels = c2.get_legend_handles_labels()\nplt.legend(handles, ['promoted', 'not promoted'])\nplt.axhline(y=(promoted_ratings[1]\/(promoted_ratings[0]+promoted_ratings[1])).max(), color='blue')","9b793491":"plt.title('Award counts')\nsns.countplot(x=X_train['awards_won?'])","1089625f":"plt.title('Rating across award receivers')\nplt.ylabel('Rating')\nX_train.groupby(by=['awards_won?'])['previous_year_rating'].mean().plot(kind = 'bar')","3911c421":"promoted_awards = combine.groupby(['is_promoted','awards_won?'])['is_promoted'].count()\npromoted_awards","3817789f":"c1 = (promoted_awards[1]\/(promoted_awards[0] + promoted_awards[1])).plot.bar()\nc2 = (promoted_awards[0]\/(promoted_awards[0] + promoted_awards[1])).plot.bar(color='yellow', bottom=(promoted_awards[1]\/(promoted_awards[0] + promoted_awards[1])))\nhandles, labels = c2.get_legend_handles_labels()\nplt.axhline(y=(promoted_awards[1]\/(promoted_awards[0] + promoted_awards[1])).max())\nplt.legend(handles, ['promoted', 'not promoted'])","42c5699e":"plt.title('Training score distribution')\nsns.distplot(X_train['avg_training_score'], bins=10, color = 'yellow', hist_kws={\n    'color' : \"blue\"\n})","84e7a28c":"X_train.info()","3ffcfd4b":"X_train.head(10)","f1e05886":"sns.countplot(x=X_train['recruitment_channel'])","c4bdfd83":"sns.countplot(x=combine['recruitment_channel'], hue=combine['is_promoted'])","6fcd1566":"promoted_recruitment = combine.groupby(['is_promoted','recruitment_channel'])['is_promoted'].count()\nc1 = (promoted_recruitment[1]\/(promoted_recruitment[0] + promoted_recruitment[1])).plot.bar()\nc2 = (promoted_recruitment[0]\/(promoted_recruitment[0] + promoted_recruitment[1])).plot.bar(color='pink', bottom=(promoted_recruitment[1]\/(promoted_recruitment[0] + promoted_recruitment[1])))\nhandles, labels = c2.get_legend_handles_labels()\nplt.axhline(y=(promoted_recruitment[1]\/(promoted_recruitment[0] + promoted_recruitment[1])).max())\nplt.legend(handles, ['promoted', 'not promoted'])","ebd093d5":"plt.figure(figsize=(14, 7))\nchart = sns.countplot(x=X_train['region'], order = X_train['region'].value_counts().index)\nchart = chart.set_xticklabels(labels=chart.get_xticklabels(), rotation=70)","603993b2":"plt.figure(figsize=(14, 7))\nchart = sns.countplot(x=X_train['region'], order = X_train['region'].value_counts().index)\nchart.set_yscale('log')\nchart.set_xticklabels(labels=chart.get_xticklabels(), rotation=70)\nchart.set_ylabel('log(count)')","9d420335":"sns.distplot(a=X_train['length_of_service'], bins=15)","5c8dde4f":"sns.countplot(combine['no_of_trainings'])","14878a1b":"sns.countplot(combine['no_of_trainings'], hue=combine['is_promoted'])","a4e6ab4a":"chart = sns.countplot(combine['no_of_trainings'], hue=combine['is_promoted'])\nchart = chart.set_yscale('log')","d3cc40cd":"ax = sns.countplot(combine['KPIs_met >80%'], hue=combine['is_promoted'])","4d49ac27":"promoted_KPI = combine.groupby(['is_promoted','KPIs_met >80%'])['is_promoted'].count()\nc1 = (promoted_KPI[1]\/(promoted_KPI[0] + promoted_KPI[1])).plot.bar(color='red')\nc2 = (promoted_KPI[0]\/(promoted_KPI[0] + promoted_KPI[1])).plot.bar(color='pink', bottom=(promoted_KPI[1]\/(promoted_KPI[0] + promoted_KPI[1])))\nhandles, labels = c2.get_legend_handles_labels()\nplt.axhline(y=(promoted_KPI[1]\/(promoted_KPI[0] + promoted_KPI[1])).max())\nplt.legend(handles, ['promoted', 'not promoted'])","135fe84e":"sns.lmplot(x='age', y='avg_training_score', hue='is_promoted', \n           markers=['x', 'o'],\n           fit_reg=False, data=combine, scatter_kws={\"s\": 50, \"linewidth\":2}, height=7,\n           palette=\"Reds\",\n          )\nplt.axvline(x=25)\nplt.axvline(x=45)\nplt.axhline(y=90)","f778df55":"plt.figure(figsize=(16, 8))\nsns.heatmap(data=combine.corr(), cmap='coolwarm', annot=True)","bcad7189":"sns.boxplot(X_train['age'])","744b7de3":"sns.boxplot(X_train['length_of_service'], color='orange')","b5225156":"sns.boxplot(X_train['avg_training_score'], color='pink')","c3653c96":"chart = sns.distplot(X_train['no_of_trainings'], color='blue', kde=False)\nchart.set_yscale('log')","d8beaf27":"more_trainings = (X_train['no_of_trainings'] > 1).astype(np.int)","5c007aaa":"training_feature_table = combine.merge(more_trainings, left_index=True, right_index=True)\ntraining_feature_table = training_feature_table.groupby(['is_promoted','no_of_trainings_y'])['is_promoted'].count()\nc1 = (training_feature_table[1]\/(training_feature_table[0] + training_feature_table[1])).plot.bar(color='blue')\nc2 = (training_feature_table[0]\/(training_feature_table[0] + training_feature_table[1])).plot.bar(color='green', bottom=(training_feature_table[1]\/(training_feature_table[0] + training_feature_table[1])))\nhandles, labels = c2.get_legend_handles_labels()\nplt.axhline(y=(training_feature_table[1]\/(training_feature_table[0] + training_feature_table[1])).max())\nplt.legend(handles, ['promoted', 'not promoted'])","d5d7fb13":"print(\"Skew in training_feature_table: {}\".format(training_feature_table.skew(axis=0)))\nprint(\"Kurtosis in training_feature_table: {}\".format(training_feature_table.kurt(axis=0)))","4335045e":"X_train.skew(axis=0).to_frame()","052e16f6":"# This is Fisher's Kutrosis, where Normal Distribution has a kurtosis of 0,\n# whereas in Pearson's Kurtosis has a kurtosis of 3.\nX_train.kurt(axis=0).to_frame().sort_values(by=0, ascending = False)","f02dc930":"upper_boundary = X_train['length_of_service'].mean() + 3*X_train['length_of_service'].std()\nlower_boundary = X_train['length_of_service'].mean() - 3*X_train['length_of_service'].std()\nprint(upper_boundary, lower_boundary)","e25b2e50":"outlier_removed = X_train[(X_train['length_of_service'] > lower_boundary) & (X_train['length_of_service'] < upper_boundary)]['length_of_service']\nprint(\"There are {} outliers.\".format(X_train.shape[0] - len(outlier_removed)))\nsns.distplot(a=outlier_removed, bins=15)","9687c1fe":"outliers = combine[(combine['length_of_service'] < lower_boundary) | (combine['length_of_service'] > upper_boundary)]","c0bdf496":"sns.countplot(outliers['length_of_service'], hue=outliers['is_promoted'])","5fe81915":"combine.info()","59748c7b":"from sklearn.utils import resample","480e516b":"combine = pd.concat([X_train, Y_train], axis = 1)","e355c2bb":"promoted = combine[combine['is_promoted'] == 1]\nnot_promoted = combine[combine['is_promoted'] != 1]\nprint(len(promoted), len(not_promoted))","ce7908de":"promoted_upsampled = resample(promoted, replace = True, n_samples = len(not_promoted), random_state = 42)","cabc369b":"upsampled = pd.concat([promoted_upsampled, not_promoted])\nupsampled['is_promoted'].value_counts()","5f6f3498":"X_train_unsampled = X_train.copy()\nY_train_unsampled = Y_train.copy()\n\nX_train = upsampled.drop('is_promoted', axis = 1)\nY_train = upsampled['is_promoted']","fd6efc64":"more_trainings = pd.DataFrame()\nmore_trainings['extra_trainings?'] = np.where(X_train['no_of_trainings'] > 1, 1, 0)","caa3a3a1":"more_trainings['extra_trainings?'].value_counts()","6ddcfc2e":"combine.merge(more_trainings['extra_trainings?'], left_index=True, right_index=True).corr()","f65fd80b":"combine.corr()","f79b2a6b":"combine.describe()","28b08a33":"combine.info()","29913063":"sns.catplot(x='KPIs_met >80%', y='is_promoted', hue='awards_won?', data=combine, kind='point')","76f8ec54":"awards_or_KPI = pd.DataFrame()\nawards_or_KPI['good_performer?'] = combine['KPIs_met >80%'] | combine['awards_won?']\nawards_or_KPI","cf499c94":"awards_or_KPI.merge(Y_train, left_index=True, right_index=True).corr()","cc972f1d":"X_train['good_performer?'] = X_train['KPIs_met >80%'] | X_train['awards_won?']\nX_test['good_performer?'] = X_test['KPIs_met >80%'] | X_test['awards_won?']\nX_val['good_performer?'] = X_val['KPIs_met >80%'] | X_val['awards_won?']\ncombine['good_performer?'] = combine['KPIs_met >80%'] | combine['awards_won?']\ntest_original['good_performer?'] = test_original['KPIs_met >80%'] | test_original['awards_won?']\n\nX_train_unsampled['good_performer?'] = X_train_unsampled['KPIs_met >80%'] | X_train_unsampled['awards_won?']","b149aeeb":"sns.distplot(X_train['avg_training_score'])","5846202e":"def grades(x):\n    if x >= 90:\n        return 'A'\n    if x >= 80:\n        return 'B'\n    if x >= 70:\n        return 'C'\n    if x >= 60:\n        return 'D'\n    if x >= 50:\n        return 'E'\n    return 'F'\ncombine['training_score_grade'] = combine['avg_training_score'].apply(grades)","956c5588":"sns.catplot(x='training_score_grade', y='is_promoted', hue='good_performer?', data=combine, kind='point')","f3ac9461":"combine.info()","13a88bab":"combine.head()","eba3edff":"combine['training_score_grade'].value_counts()","782f5b4e":"X_train['training_score_grade'] = X_train['avg_training_score'].apply(grades)\nX_test['training_score_grade'] = X_test['avg_training_score'].apply(grades)\nX_val['training_score_grade'] = X_val['avg_training_score'].apply(grades)\ntest_original['training_score_grade'] = test_original['avg_training_score'].apply(grades)\n\nX_train_unsampled['training_score_grade'] = X_train_unsampled['avg_training_score'].apply(grades)","7c15a22b":"combine['education'].value_counts()","55b3e63a":"def degrees(x):\n    if x == 'Below Secondary':\n        return 1\n    if x == \"Bachelor's\":\n        return 2\n    if x == \"Master's & above\":\n        return 3\n    return 0\ncombine[\"degrees\"] = combine['education'].apply(degrees)","14b74ff5":"sns.catplot(x='degrees', y='is_promoted', hue='good_performer?', data=combine, kind='point')","776b4319":"X_train['no_of_degrees'] = X_train['education'].apply(degrees)\nX_test['no_of_degrees'] = X_test['education'].apply(degrees)\nX_val['no_of_degrees'] = X_val['education'].apply(degrees)\ntest_original['no_of_degrees'] = test_original['education'].apply(degrees)\n\nX_train_unsampled['no_of_degrees'] = X_train_unsampled['education'].apply(degrees)","58869c5b":"import scipy.stats as ss\ndef cramers_v(x, y):\n    confusion_matrix = pd.crosstab(x,y)\n    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2\/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0, phi2-((k-1)*(r-1))\/(n-1))\n    rcorr = r-((r-1)**2)\/(n-1)\n    kcorr = k-((k-1)**2)\/(n-1)\n    return np.sqrt(phi2corr\/min((kcorr-1),(rcorr-1)))\ncramers_v(combine['degrees'], combine['is_promoted'])","c1d8ca2a":"X_train","197cb27e":"def hasBachelors(x):\n    if (x == \"Bachelor's\") | (x == \"Master's & above\"):\n        return 1\n    return 0\ndef hasMasters(x):\n    if (x == \"Master's & above\"):\n        return 1\n    return 0\ndef hasSecondary(x):\n    if (x != \"Unknown\"):\n        return 1\n    return 0\n\ncombine['has_Bachelors'] = combine['education'].apply(hasBachelors)\ncombine['has_Master'] = combine['education'].apply(hasMasters)\ncombine['has_Secondary'] = combine['education'].apply(hasSecondary)","4bb6f026":"combine","7177f870":"combine.corr()","9e34cf36":"Y_train.to_frame().merge(pd.get_dummies(combine['education']), left_index = True, right_index = True).corr()","f053ca0c":"combine.drop(['has_Bachelors', 'has_Master', 'has_Secondary'], axis = 1, inplace = True)\ncombine.head()","e77d4931":"out, age_bins = pd.qcut(x = combine['age'], q = 4, retbins=True)\nout","88cd93a9":"[*age_bins]","5a38c7a4":"X_train['age_bin'] = pd.cut(x=X_train['age'], bins = age_bins, include_lowest=True)\nX_test['age_bin'] = pd.cut(x=X_test['age'], bins = age_bins, include_lowest=True)\nX_val['age_bin'] = pd.cut(x=X_val['age'], bins = age_bins, include_lowest=True)\ncombine['age_bin'] = pd.cut(x=combine['age'], bins = age_bins, include_lowest=True)\ntest_original['age_bin'] = pd.cut(x=test_original['age'], bins = age_bins, include_lowest=True)\n\nX_train_unsampled['age_bin'] = pd.cut(x=X_train_unsampled['age'], bins = age_bins, include_lowest=True)","30b874b4":"X_train","a526eca8":"cramers_v(combine['is_promoted'], combine['age_bin'])","bd41cd65":"sns.countplot(X_train['age_bin'])","0af2bb13":"sns.countplot(combine['length_of_service'])","cf16999d":"out, service_bins = pd.cut(x = combine['length_of_service'], bins = [0, 3, 5, 7, 40], retbins=True)\nprint(*service_bins)\ncombine['service_bin'] = pd.cut(x = combine['length_of_service'], bins = service_bins, include_lowest=True, labels=['beginner', 'intermediate', 'expert', 'senior expert'])","ff7f8546":"combine['service_bin'].value_counts().plot.bar()","dc0b5bc1":"combine","ff580498":"X_train['service_bin'] = pd.cut(x = X_train['length_of_service'], bins = service_bins, include_lowest=True, labels=['beginner', 'intermediate', 'expert', 'senior expert'])\nX_val['service_bin'] = pd.cut(x = X_val['length_of_service'], bins = service_bins, include_lowest=True, labels=['beginner', 'intermediate', 'expert', 'senior expert'])\nX_test['service_bin'] = pd.cut(x = X_test['length_of_service'], bins = service_bins, include_lowest=True, labels=['beginner', 'intermediate', 'expert', 'senior expert'])\ntest_original['service_bin'] = pd.cut(x = test_original['length_of_service'], bins = service_bins, include_lowest=True, labels=['beginner', 'intermediate', 'expert', 'senior expert'])\n\nX_train_unsampled['service_bin'] = pd.cut(x = X_train_unsampled['length_of_service'], bins = service_bins, include_lowest=True, labels=['beginner', 'intermediate', 'expert', 'senior expert'])","02b77fc2":"sns.catplot(x='service_bin', y='is_promoted', data=combine, kind='point')","0cab2a07":"combine.merge(combine.groupby(['department', 'recruitment_channel', 'training_score_grade'])['avg_training_score'].agg('mean'), on=['department', 'recruitment_channel', 'training_score_grade'], right_index=True)","61f203fa":"cramers_v(combine.merge(combine.groupby(['department','training_score_grade'])['avg_training_score'].agg('mean'), on=['department', 'training_score_grade'], right_index=True)['avg_training_score_y'], combine['is_promoted'])","b8df569c":"combine.groupby(['department', 'recruitment_channel', 'training_score_grade'])['avg_training_score'].agg('mean')","1dea6483":"cramers_v(combine['department'], combine['is_promoted'])","dfd43ab7":"combine.groupby(['department','training_score_grade'])['age'].agg('count')","90c5a940":"sns.countplot(x='department', data=combine)\nplt.xticks(rotation=45)","8ca41e49":"combine_copy = combine.copy()\n\ndef group_dep(x):\n    if (x == \"HR\") or (x == \"Legal\") or (x == \"Finance\") or (x == \"R&D\"):\n        return \"Others\"\n    return x\ncombine_copy['department'] = combine_copy['department'].apply(group_dep)","2b78aff4":"sns.catplot(x='department', y='is_promoted', hue='training_score_grade', data=combine, kind='point')\nplt.xticks(rotation=90)","03f89fca":"department_promotion = pd.crosstab(combine['department'], combine['is_promoted'])\ndepartment_promotion['%promoted'] = department_promotion[1]*100\/(department_promotion[0] + department_promotion[1])\ndepartment_promotion","236dd4df":"department_promotion = pd.crosstab(combine_copy['department'], combine_copy['is_promoted'])\n\ndepartment_promotion['%promoted'] = department_promotion[1]*100\/(department_promotion[0] + department_promotion[1])\ndepartment_promotion","ea3a6c1b":"combine_copy['department'].value_counts().plot.bar()","e6735022":"sns.catplot(x='department', y='is_promoted', data=combine_copy, kind='point')","323e99f6":"X_train['department'] = X_train['department'].apply(group_dep)\nX_test['department'] = X_test['department'].apply(group_dep)\nX_val['department'] = X_val['department'].apply(group_dep)\ntest_original['department'] = test_original['department'].apply(group_dep)\ncombine['department'] = combine['department'].apply(group_dep)\n\nX_train_unsampled['department'] = X_train_unsampled['department'].apply(group_dep)","e922880a":"combine['department'].value_counts()","e2cc205f":"combine.info()","e99bd2fa":"combine.groupby(by=['department', 'good_performer?'])['avg_training_score'].mean()","9214f451":"combine.groupby(by=['department', 'recruitment_channel'])['avg_training_score'].mean()","e5d9fd49":"combine.groupby(by=['department', 'education'])['avg_training_score'].mean()","0f26b511":"combine['service_bin'].value_counts(dropna=False)","47467060":"combine['age_bin'].value_counts()","1f470160":"combine.groupby(['age_bin', 'training_score_grade'])['age'].count()","d91fcfe2":"pd.crosstab(combine['age_bin'], combine['training_score_grade'], normalize=True).style.background_gradient(cmap='cool')","28ada2b6":"pd.crosstab(combine['service_bin'], combine['training_score_grade'], normalize=True).style.background_gradient(cmap='cool')","d8068640":"combine","d6044d7a":"print(cramers_v(combine['service_bin'], combine['is_promoted']), cramers_v(combine['length_of_service'], combine['is_promoted']))","1640ebf7":"combine['avg_training_score']\/combine['length_of_service']","6606fd52":"cramers_v((combine['avg_training_score']\/combine['length_of_service']), combine['is_promoted'])","06f52646":"combine['age_bin'].value_counts()","39d2f060":"import datetime\nprint(datetime.datetime.today().year)","465f6991":"combine['joining_year'] = 2020 - combine['length_of_service'] + 1","b53de506":"combine","28422faa":"X_train['joining_year'] = 2020 - X_train['length_of_service'] + 1\nX_test['joining_year'] = 2020 - X_test['length_of_service'] + 1\nX_val['joining_year'] = 2020 - X_val['length_of_service'] + 1\ntest_original['joining_year'] = 2020 - test_original['length_of_service'] + 1\n\nX_train_unsampled['joining_year'] = 2020 - X_train_unsampled['length_of_service'] + 1","6d81b43f":"sns.distplot(combine['joining_year'])\nprint(combine['joining_year'].min(), combine['joining_year'].max())","e7864f28":"sns.boxplot(combine['joining_year'])","9003334f":"upper_boundary = combine['joining_year'].mean() + 3*combine['joining_year'].std()\nlower_boundary = combine['joining_year'].mean() - 3*combine['joining_year'].std()\nprint(upper_boundary, lower_boundary)","16a63fea":"sns.distplot(combine[combine['joining_year'] > lower_boundary]['joining_year'])","1e20f043":"sns.boxplot(combine[combine['joining_year'] > lower_boundary]['joining_year'])","6115b7d5":"combine[combine['joining_year'] < lower_boundary]['is_promoted'].value_counts()","4185e4ef":"X_train.info()","f33f23e0":"from sklearn.preprocessing import LabelEncoder\ngender_encode = LabelEncoder()\ngender_encode.fit(combine['gender'])","23e6a4e4":"gender_dict = {key : value for (key, value) in zip(gender_encode.classes_, gender_encode.transform(gender_encode.classes_))}","f6b28ee8":"gender_dict","ff2768ff":"combine['gender_encoded'] = gender_encode.transform(combine['gender'])\nX_train['gender_encoded'] = gender_encode.transform(X_train['gender'])\nX_test['gender_encoded'] = gender_encode.transform(X_test['gender'])\nX_val['gender_encoded'] = gender_encode.transform(X_val['gender'])\ntest_original['gender_encoded'] = gender_encode.transform(test_original['gender'])\n\nX_train_unsampled['gender_encoded'] = gender_encode.transform(X_train_unsampled['gender'])","32e60403":"X_train['gender_encoded']","1ba6de74":"department_encode = LabelEncoder()\ndepartment_encode.fit(X_train['department'])","b8c1a76c":"department_encode.classes_","29984a06":"department_dict = {\n    key : value for (key, value) in zip(department_encode.classes_, department_encode.transform(department_encode.classes_))\n}\ndepartment_dict","fac0c8bf":"combine['department_encode'] = department_encode.transform(combine['department'])\nX_train['department_encode'] = department_encode.transform(X_train['department'])\nX_test['department_encode'] = department_encode.transform(X_test['department'])\nX_val['department_encode'] = department_encode.transform(X_val['department'])\ntest_original['department_encode'] = department_encode.transform(test_original['department'])\n\nX_train_unsampled['department_encode'] = department_encode.transform(X_train_unsampled['department'])\n\nX_train['department_encode']","6ebe255c":"region_encode = LabelEncoder()\nregion_encode.fit(X_train['region'])\n\nregion_dict = {\n    key : value for (key, value) in zip(region_encode.classes_, region_encode.transform(region_encode.classes_))\n}\n\ncombine['region_encode'] = region_encode.transform(combine['region'])\nX_train['region_encode'] = region_encode.transform(X_train['region'])\nX_test['region_encode'] = region_encode.transform(X_test['region'])\nX_val['region_encode'] = region_encode.transform(X_val['region'])\ntest_original['region_encode'] = region_encode.transform(test_original['region'])\n\nX_train_unsampled['region_encode'] = region_encode.transform(X_train_unsampled['region'])\n\nX_train['region_encode']","5f27abd9":"test_original","dcf037ca":"education_encode = LabelEncoder()\neducation_encode.fit(X_train['education'])\n\neducation_dict = {\n    key : value for (key, value) in zip(education_encode.classes_, education_encode.transform(education_encode.classes_))\n}\n\ncombine['education_encode'] = education_encode.transform(combine['education'])\nX_train['education_encode'] = education_encode.transform(X_train['education'])\nX_test['education_encode'] = education_encode.transform(X_test['education'])\nX_val['education_encode'] = education_encode.transform(X_val['education'])\ntest_original['education_encode'] = education_encode.transform(test_original['education'])\n\nX_train_unsampled['education_encode'] = education_encode.transform(X_train_unsampled['education'])\n\nX_train['education_encode']","d1384ef7":"recruitment_channel_encode = LabelEncoder()\nrecruitment_channel_encode.fit(X_train['recruitment_channel'])\n\nrecruitment_dict = {\n    key : value for (key, value) in zip(recruitment_channel_encode.classes_, recruitment_channel_encode.transform(recruitment_channel_encode.classes_))\n}\n\ncombine['recruitment_channel_encode'] = recruitment_channel_encode.transform(combine['recruitment_channel'])\nX_train['recruitment_channel_encode'] = recruitment_channel_encode.transform(X_train['recruitment_channel'])\nX_test['recruitment_channel_encode'] = recruitment_channel_encode.transform(X_test['recruitment_channel'])\nX_val['recruitment_channel_encode'] = recruitment_channel_encode.transform(X_val['recruitment_channel'])\ntest_original['recruitment_channel_encode'] = recruitment_channel_encode.transform(test_original['recruitment_channel'])\n\nX_train_unsampled['recruitment_channel_encode'] = recruitment_channel_encode.transform(X_train_unsampled['recruitment_channel'])\n\nX_train['recruitment_channel_encode']","2b0a3110":"grade_encode = LabelEncoder()\ngrade_encode.fit(X_train['training_score_grade'])\n\ngrage_table = {\n    key : value for (key, value) in zip(grade_encode.classes_, grade_encode.transform(grade_encode.classes_))\n}\n\ncombine['grade_encode'] = grade_encode.transform(combine['training_score_grade'])\nX_train['grade_encode'] = grade_encode.transform(X_train['training_score_grade'])\nX_test['grade_encode'] = grade_encode.transform(X_test['training_score_grade'])\nX_val['grade_encode'] = grade_encode.transform(X_val['training_score_grade'])\ntest_original['grade_encode'] = grade_encode.transform(test_original['training_score_grade'])\n\nX_train_unsampled['grade_encode'] = grade_encode.transform(X_train_unsampled['training_score_grade'])\n\nX_train['grade_encode']","b5a64a73":"X_val[X_val['service_bin'].isnull()]","03dea5fa":"service_bins","1f4bb5f3":"service_bin_encode = LabelEncoder()\nservice_bin_encode.fit(X_train['service_bin'])\n\nservice_bin_dict = {\n    key : value for (key, value) in zip(service_bin_encode.classes_, service_bin_encode.transform(service_bin_encode.classes_))\n}\n\ncombine['service_bin_encode'] = service_bin_encode.transform(combine['service_bin'])\nX_train['service_bin_encode'] = service_bin_encode.transform(X_train['service_bin'])\nX_test['service_bin_encode'] = service_bin_encode.transform(X_test['service_bin'])\nX_val['service_bin_encode'] = service_bin_encode.transform(X_val['service_bin'])\ntest_original['service_bin_encode'] = service_bin_encode.transform(test_original['service_bin'])\n\nX_train_unsampled['service_bin_encode'] = service_bin_encode.transform(X_train_unsampled['service_bin'])\n\nX_train['service_bin_encode']","f9a4463e":"age_bin_encode = LabelEncoder()\nage_bin_encode.fit(X_train['age_bin'])\n\nage_bin_dict = {\n    key : value for (key, value) in zip(age_bin_encode.classes_, age_bin_encode.transform(age_bin_encode.classes_))\n}\n\ncombine['age_bin_encode'] = age_bin_encode.transform(combine['age_bin'])\nX_train['age_bin_encode'] = age_bin_encode.transform(X_train['age_bin'])\nX_test['age_bin_encode'] = age_bin_encode.transform(X_test['age_bin'])\nX_val['age_bin_encode'] = age_bin_encode.transform(X_val['age_bin'])\ntest_original['age_bin_encode'] = age_bin_encode.transform(test_original['age_bin'])\n\nX_train_unsampled['age_bin_encode'] = age_bin_encode.transform(X_train_unsampled['age_bin'])\n\nX_train['age_bin_encode']","6df1ba53":"object_types = combine.select_dtypes(exclude=np.number).dtypes.index\nobject_types","fab67b56":"X_train.drop(object_types, inplace = True, axis = 1)\nX_test.drop(object_types, inplace = True, axis = 1)\nX_val.drop(object_types, inplace = True, axis = 1)\ncombine.drop(object_types, inplace = True, axis = 1)\ntest_original.drop(object_types, inplace = True, axis = 1)\n\nX_train_unsampled.drop(object_types, inplace = True, axis = 1)","91080997":"sns.heatmap(X_train.corr(method = 'spearman'))","5ed0d1c7":"corr_features = set()\n\ncorr_matrix = X_train.corr()\n\nsns.heatmap(corr_matrix)\n\nfor i in range(len(corr_matrix .columns)):\n    for j in range(i):\n        if abs(corr_matrix.iloc[i, j]) > 0.85:\n            colname = corr_matrix.columns[i]\n            corr_features.add(colname)\nprint(corr_features)","5816d866":"X_train.drop(corr_features, axis = 1, inplace = True)\nX_test.drop(corr_features, axis = 1, inplace = True)\nX_val.drop(corr_features, axis = 1, inplace = True)\ntest_original.drop(corr_features, axis = 1, inplace = True)\n\nX_train_unsampled.drop(corr_features, axis = 1, inplace = True)","0d11c993":"X_train.shape","98cbff8a":"X_train.drop('employee_id', axis = 1, inplace = True)\nX_test.drop('employee_id', axis = 1, inplace = True)\nX_val.drop('employee_id', axis = 1, inplace = True)\n#test_original.drop('employee_id', axis = 1, inplace = True)\n\nX_train_unsampled.drop('employee_id', axis = 1, inplace = True)","38d9d231":"combine.drop([*corr_features, 'employee_id'], axis = 1, inplace = True)","c99ac7ff":"X_train","9f9c211e":"from sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestClassifier","68427261":"classifier = RandomForestClassifier(criterion='gini',n_estimators = 100, verbose=1)\nselector = RFE(classifier, n_features_to_select=6, step=1, verbose=2)","d88dbb79":"selector.fit(X_train, Y_train)","32bd8c11":"X_train.columns[selector.get_support()]","8e0b6481":"X_train.columns","f8f5abe8":"selector.ranking_","7cd22911":"pd.DataFrame((key, value) for (key, value) in zip(X_train.columns, selector.ranking_)).sort_values(1)","9b28d71f":"X_train.education_encode.value_counts()","02f6dcc8":"X_train.var()","fb69b3b4":"from mlxtend.feature_selection import SequentialFeatureSelector as sfs","2fe6ecc9":"model = sfs(classifier,k_features=6,forward=True,verbose=2,cv=5,n_jobs=-1,scoring='f1')","aca199ef":"model.fit(X_train, Y_train)","63e6393f":"model.k_feature_names_","f8542377":"model.k_score_","6f9e90e9":"features = [*model.k_feature_names_]","e9b2cc24":"features","3d1c468f":"classifier.fit(X_train[features], Y_train)","780b6e0a":"Y_val_pred = classifier.predict(X_val[features])","f8c2d4de":"from sklearn.metrics import confusion_matrix, f1_score, classification_report","f8907f9f":"confusion_matrix(Y_val, Y_val_pred)","a4721c72":"f1_score(y_true=Y_val, y_pred=Y_val_pred)","9d7999dd":"pd.DataFrame((key,value) for (key, value) in zip(features, classifier.feature_importances_)).sort_values(1, ascending = False).style.background_gradient(cmap='Reds')","66a49685":"print(classification_report(Y_val, Y_val_pred))","33c176df":"X_train_unsampled","47289716":"Y_train_unsampled","a5e4e931":"from sklearn.utils.class_weight import compute_class_weight \n\nclass_weights = compute_class_weight('balanced', [0, 1], Y_train_unsampled)","e33fd16f":"classifier_with_cw = RandomForestClassifier(criterion='gini',n_estimators = 100, verbose=1, class_weight={key: value for (key, value) in enumerate(class_weights)})\nselector_with_cw = RFE(classifier_with_cw, n_features_to_select=6, step=1, verbose=2)","0729e732":"selector_with_cw.fit(X_train_unsampled, Y_train_unsampled)","52f5d993":"feature_list = [*X_train_unsampled.columns[selector_with_cw.get_support()]]\nfeature_list","f37c78b1":"selector_with_cw.ranking_","e16087d3":"classifier_with_cw.fit(X_train_unsampled[feature_list], Y_train_unsampled)","0fca48af":"Y_val_unsampled_pred = classifier_with_cw.predict(X_val[feature_list])","547ec812":"confusion_matrix(Y_val, Y_val_unsampled_pred)","f474a406":"f1_score(y_true=Y_val, y_pred=Y_val_unsampled_pred)","c4696dc1":"pd.DataFrame((key,value) for (key, value) in zip(feature_list, classifier_with_cw.feature_importances_)).sort_values(1, ascending = False).style.background_gradient(cmap='Reds')","18cabacd":"{key: value for (key, value) in enumerate(class_weights)}","59e8a0c0":"print(classification_report(Y_val, Y_val_unsampled_pred))","4527b25b":"from imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state = 42)\nX_train_smote, Y_train_smote = sm.fit_sample(X_train_unsampled, Y_train_unsampled)","2ed28819":"print(X_train_smote.shape, Y_train_smote.shape)","e10da3fd":"Y_train_smote.value_counts()","6e4650f5":"classifier.fit(X_train_smote[feature_list], Y_train_smote)","74f51851":"classifier.predict(X_val[feature_list])","9c951b1b":"print(classification_report(Y_val, classifier.predict(X_val[feature_list])))","cb7ff910":"from sklearn import *","4c523df5":"tree_classifier_cw = tree.DecisionTreeClassifier(criterion='gini', \n                                                 splitter='best', \n                                                 min_samples_split = 0.1, \n                                                 class_weight={key:value for (key, value) in enumerate(class_weights)}, \n                                                 random_state = 42)","862b7f41":"tree_classifier_cw.fit(X_train_unsampled, Y_train_unsampled)","b0c5ec7d":"tree_pred = tree_classifier_cw.predict(X_val)","3ebae568":"tree_classifier_cw.predict_proba(X_val)","161b882a":"plt.figure(figsize = (30, 10), dpi=200)\ntree.plot_tree(tree_classifier_cw)","27f16620":"tree_classifier_cw.score(X_val, Y_val)","d74c4dd3":"print(classification_report(Y_val, tree_classifier_cw.predict(X_val)))","62cae3d8":"classifier_with_cw","83153939":"classifier_with_cw = RandomForestClassifier(criterion='gini',  \n                                             n_estimators = 1000,\n                                             #min_samples_split = 0.1,\n                                             class_weight={key:value for (key, value) in enumerate(class_weights)}, \n                                             n_jobs = -1,\n                                             random_state = 42,\n                                             verbose=1)","1ddd9102":"classifier_with_cw.fit(X_train_unsampled[feature_list], Y_train_unsampled)","a4cc3d87":"print(classification_report(Y_val, classifier_with_cw.predict(X_val[feature_list])))","861399b0":"feature_list","ecafff60":"search_params = {\n    'criterion' : ['gini', 'entropy'],\n    'max_depth' : list(np.linspace(10, 500, 5, dtype = int, endpoint = True)) + [None],\n    'max_features' : ['auto', 'sqrt', 'log2', None],\n    'min_samples_leaf' : list(np.linspace(1, 500, 5, dtype = int, endpoint = True)),\n    'min_samples_split' : list(np.linspace(0.1, 1, 5, dtype = float, endpoint = True)),\n    'n_estimators' : list(np.linspace(100, 1000, 10, dtype = int, endpoint = True)),\n}","4257e889":"hyper_classifier_RF = RandomForestClassifier(class_weight = {key: value for (key, value) in enumerate(class_weights)})","cb13594b":"hyper_model = model_selection.RandomizedSearchCV(estimator = hyper_classifier_RF, \n                                                param_distributions = search_params,\n                                                n_iter = 30,\n                                                cv = 5,\n                                                verbose = 5,\n                                                random_state = 42,\n                                                n_jobs = -1,\n                                                scoring = 'f1')","730110ec":"hyper_model.fit(X_train_unsampled[feature_list], Y_train_unsampled)","7b3fbf93":"hyper_model.cv_results_.keys()","4adbacbe":"sns.heatmap(pd.pivot_table(pd.DataFrame(hyper_model.cv_results_),\n              values = 'mean_test_score', index = 'param_max_features', columns = 'param_criterion'), annot = True)","3606f39c":"sns.heatmap(pd.pivot_table(pd.DataFrame(hyper_model.cv_results_),\n              values = 'mean_test_score', index = 'param_min_samples_split', columns = 'param_criterion'), annot=True)","7142ffa5":"sns.heatmap(pd.pivot_table(pd.DataFrame(hyper_model.cv_results_),\n              values = 'mean_test_score', index = 'param_min_samples_leaf', columns = 'param_criterion'), annot=True)","ef856017":"sns.heatmap(pd.pivot_table(pd.DataFrame(hyper_model.cv_results_),\n              values = 'mean_test_score', index = 'param_n_estimators', columns = 'param_criterion'), annot = True)","ff9f29fe":"hyper_model.best_estimator_","dd6a240b":"hyper_pred_val = hyper_model.best_estimator_.predict(X_val[feature_list])\nprint(confusion_matrix(Y_val,hyper_pred_val))\nprint(classification_report(Y_val,hyper_pred_val))","d8be51b1":"search_params = {\n    'criterion' : ['gini', 'entropy'],\n    'max_depth' : list(np.linspace(10, 1000, 4, dtype = int, endpoint = True)) + [None],\n    'max_features' : ['auto', 'sqrt', 'log2'],\n    'min_samples_leaf' : list(np.linspace(1, 500, 5, dtype = int, endpoint = True)),\n    'min_samples_split' : list(np.linspace(0.1, 1, 4, dtype = float, endpoint = True)),\n    'n_estimators' : list(np.linspace(100, 1000, 5, dtype = int, endpoint = True)),\n}","7b505031":"# hyper_classifier_RF = RandomForestClassifier(class_weight = {key: value for (key, value) in enumerate(class_weights)})\n\n# hyper_model_grid = model_selection.GridSearchCV(estimator = hyper_classifier_RF, \n#                                                 param_grid = search_params,\n#                                                 cv = 3,\n#                                                 verbose = 5,\n#                                                 n_jobs = -1,\n#                                                 scoring = 'f1')","7834166f":"# hyper_model_grid.fit(X_train_unsampled[feature_list], Y_train_unsampled)","1c93e90d":"import pickle\n\nwith open('\/kaggle\/input\/GridSearchRandomforest.pkl', 'rb') as handle:\n    hyper_model_grid = pickle.load(handle)\n\nprint(hyper_model_grid)\n\nprint(hyper_model_grid.cv_results_.keys())","164ad8c6":"sns.heatmap(pd.pivot_table(pd.DataFrame(hyper_model_grid.cv_results_),\n              values = 'mean_test_score', index = 'param_max_features', columns = 'param_criterion'), annot = True)","08b623d3":"sns.heatmap(pd.pivot_table(pd.DataFrame(hyper_model_grid.cv_results_),\n              values = 'mean_test_score', index = 'param_min_samples_split', columns = 'param_criterion'), annot=True)","53eeea3a":"sns.heatmap(pd.pivot_table(pd.DataFrame(hyper_model_grid.cv_results_),\n              values = 'mean_test_score', index = 'param_min_samples_leaf', columns = 'param_criterion'), annot=True)","20dcf71c":"sns.heatmap(pd.pivot_table(pd.DataFrame(hyper_model_grid.cv_results_),\n              values = 'mean_test_score', index = 'param_n_estimators', columns = 'param_criterion'), annot = True)","4031f521":"hyper_model_grid.best_estimator_","e969fa88":"hyper_pred_val_grid = hyper_model_grid.best_estimator_.predict(X_val[feature_list])\nprint(confusion_matrix(Y_val,hyper_pred_val_grid))\nprint(classification_report(Y_val,hyper_pred_val_grid))","a19e5515":"# import pickle\n\n# with open('GridSearchRandomforest.pkl', 'wb') as handle:\n#     pickle.dump(hyper_model_grid, handle, protocol=pickle.HIGHEST_PROTOCOL)","b228bfd9":"# with open('GridSearchRandomforest.pkl', 'rb') as handle:\n#     b = pickle.load(handle)\n\n# print(b)","daf601de":"print(classification_report(Y_val, hyper_model_grid.best_estimator_.predict(X_val[feature_list])))","84a030cd":"print(classification_report(Y_val, classifier_with_cw.predict(X_val[feature_list])))","38f55008":"param_dict = hyper_model_grid.best_estimator_.get_params()\nparam_dict['class_weight'] = None;\nparam_dict['verbose'] = 1\nparam_dict['n_estimators'] = 1000\nparam_dict","5702b592":"classifier_hyper_smote = RandomForestClassifier(**param_dict)","0cf4eeb5":"classifier_hyper_smote.fit(X_train_smote[feature_list], Y_train_smote)","74363b00":"print(classification_report(Y_val, classifier_hyper_smote.predict(X_val[feature_list])))","8fadcb02":"import lightgbm as lgbm","f6c338d8":"lgbm_train = lgbm.Dataset(X_train_unsampled[feature_list], label = Y_train_unsampled, free_raw_data=False)","3b3f313f":"lgbm_model = lgbm.train({\n    'learning_rate': 0.001,\n    'metric' : ['f1', 'recall'],\n    'objective' : 'binary',\n    'criterion' : 'entropy',\n    'boosting_type' : 'gbdt', \n    'n_estimators' : 5000,\n    'class_weight' : 'balanced'\n    }, \n    lgbm_train, \n    1000, \n    feature_name=feature_list, \n    verbose_eval=True)","6d87213b":"lgbm_model","a76fd39c":"y_pred = lgbm_model.predict(X_val[feature_list])\ny_pred","17885d23":"for i, v in enumerate(y_pred):\n    if(v >= 0.4):\n        y_pred[i] = 1\n    else:\n        y_pred[i] = 0","a83ed366":"print(classification_report(Y_val, y_pred))","3185ded5":"y_test_pred = lgbm_model.predict(X_test[feature_list])\n\nfor i, v in enumerate(y_test_pred):\n    if(v >= 0.4):\n        y_test_pred[i] = 1\n    else:\n        y_test_pred[i] = 0\nprint(classification_report(Y_test, y_test_pred))","a6568164":"original_train_pred = lgbm_model.predict(test_original[feature_list])\n\nfor i, v in enumerate(original_train_pred):\n    if(v >= 0.4):\n        original_train_pred[i] = 1\n    else:\n        original_train_pred[i] = 0\noriginal_train_pred","e675743d":"test_original_copy = test_original.copy()\n\ntest_original_copy['is_promoted'] = original_train_pred\ntest_original_copy['is_promoted'] = test_original_copy['is_promoted'].astype(int)\n\ntest_original_copy.to_csv('submission.csv', columns = ['employee_id', 'is_promoted'], index = False)\n","15c4261b":"train_original[:]","069efb77":"y_pred_original_rf = classifier_with_cw.predict(test_original[feature_list])","08a02270":"test_original_copy['is_promoted'] = y_pred_original_rf","fe431633":"test_original_copy","001c9927":"test_original_copy.to_csv('submission_rf.csv', columns = ['employee_id', 'is_promoted'], index = False)","e2dfb81d":"y_test_pred = lgbm_model.predict(X_test[feature_list])\n\nfor i, v in enumerate(y_test_pred):\n    if(v >= 0.4):\n        y_test_pred[i] = 1\n    else:\n        y_test_pred[i] = 0\nprint(classification_report(Y_test, y_test_pred))","17c71e00":"<div class='alert alert-block alert-info'>\n    As we can see, more than 40% of all the employees who got promoted have a previous year rating of 5, and almost 60% of the employees comprise the top 2 ratings\n<\/div>            ","8bf943ea":"<div class  = 'alert alert-block alert-info'>\n    We create a model with the class weights with 10 best features found using recursive backward feature elimination<\/div>","3c85232d":"<div class=\"alert alert-block alert-warning\">\nThis is just a utility function to pretty print dataframes with background gradient:\n<\/div>","531bf4ec":"__Using LightGBM__","4fd5deb6":"__Encoding training_score_grade__","105a7c55":"***","0d1cc942":"As we can observe, people with trainings above 1 are scarse. Let us categorize them all into categories.","802170f0":"__Using the smoting technique to compare the Results__","925eedcf":"<div class = 'alert alert-block alert-warning'>\nEncoding categorical columns to numerical ones to be used in sklearn<\/div>","e41fcb2c":"The LGBM model was selected because it has a high f1 score, and does not seem to overfit on the data. It gave a high precision for both the classes, minority and majority, and performed comparative to the train and the validation set","0b2004fb":"*Storing the Grid Search parameters so that it can be used again, and the algorithm does not have to run.*","3197c3e6":"__As we can see, the Decision Tree does not have a very high accuracy score. Let us implement an ensemble method to improve the score. Using the Random Forest Classifier used to create the base model in the previous section:__","bccb507d":"Visualizing the results of the Grid Search","e39728a0":"<b>Analysing NULL values in `previous_year_rating` column<\/b>","a17cd079":"<div class='alert alert-block alert-success'>\nThe test set gave similar scores to validation set. With a relatively better f1 score and accuracy.\nWe can say that, of all employees that were labelled 1 by the model, 93% were actually 1 and of all records that were truly labelled 1 we predicted 33% correctly.\n    <\/div>","2ada44be":"<div class = 'alert alert-block alert-info'>\n        As we can observe, the frequency of employees having a lower rating is less.\n    There is a majority of employees having average (3.0) rating\n<\/div>","3871ae90":"__Sampling the imbalanced dataset__","1aab2ae8":"<div class='alert alert-block alert-info'>\n    As we can see, most people were recruited from other sources.\n    Among those who are promoted, there is little difference among those who were recruited through sourcing, and those recuited through other mediums.<br>\n    Among all the recruitment channels, those who were referred had a higher conversion rate than the other two channels\n<\/div>","f8905f34":"Splitting train into new train and validation sets","1f6a9950":"<div class=\"alert alert-block alert-info\">\n    We replace all the null values in the <b>previous_year_rating<\/b> to 0, since the employees are new to the company with less than or equal to 1 year of experience\n<\/div>","f22d8ae9":"<div class=\"alert alert-block alert-success\">\nThere are no duplicate rows\n<\/div>","8db4e613":"<div class=\"alert alert-block alert-success\">\n    There are no constant features. There is the column for <b>awards won?<\/b> with a variance of 0.022. But I choose to keep it since the number of awards play a role in deciding the promotion of a candidate in corporate\n<\/div>","4d63dc18":"<div class = 'alert alert-block alert-info'>\nUsing Backward Feature selection, and selecting the 10 best features.\n    <\/div>","d13f0f7c":"***","ce713fc6":"Visualizing the results of the Randomized search","227c43db":"Null counts in train","44ccc0e9":"<div class='alert alert-block alert-success'>\n    It is clearly understandable from the above plot that most of the employees who got a promotion are densely scattered around the age group 25 to 40.<br>\n    Also, there is a high density of employees with a avg_training_score of above 90, being promoted\n<\/div>","274ce72e":"<div class = 'alert alert-block alert-info'>\nAs we can observe, there are columns which are highly correlated features with other existing features, so we will remove those \n    <\/div>","aa1212cf":"<b>Analysing null values in `education` column<\/b>","3c813c18":"### *Analysing the <code>no_of_trainings<\/code> column*","384c1b01":"### *Analysing the <code>region<\/code> column*","d9669101":"<div class='alert alert-block alert-success'>\n    As we can see, the new feature has good correlation with the target variable. So we will keep it.\n<\/div>","4a1af6ee":"<div class = 'alert alert-block alert-warning'>\n    Grid Search takes 9 hours here. It is not advised to run the following block of code\n    <\/div>","eeff3e03":"__Encoding the age_bin and service_bin columns__","186d2e9d":"<div class=\"alert alert-block alert-success\">\nNow we are done with the null imputations, we will go forward with the analysis of other columns.\n<\/div>","40cb1537":"<div class='alert alert-block alert-success'>\n    The column <code>awards_won?<\/code> is a categorical column.\n    The column <code>length_of_service<\/code> is positively skewed and is Leptokurtic. This means the column has outliers<br>\n    In our data, the no_of_training values range from 1 to 10, with a high number of employees having values for this column = 1. Since these values are important to us, we will not remove the outliers in that column\n    <\/div>","24967c51":"<a id=\"null\"><\/a>\n## Analysing NULL values in columns","0aafd832":"The last 4 departments are scarcely represented, so we will group them into one category, \"Others\"","e566bbd7":"__The model with class weights has an edge in terms of recall__","f1dc1e05":"<a id='correlation'><\/a>\n## Correlation and outliers","0ac9ca36":"# Contents:\n> ### Links to sections:\n1. Reading data [Jump](#read)\n2. Splitting into test and train [Jump](#split)\n3. NULL value imputation [Jump](#null)\n4. Duplicate columns\/rows [Jump](#duplicate)\n5. Constant\/Quasi constant features [Jump](#constant)\n6. EDA [Jump](#eda)\n7. Correlation and Outlier identification [Jump](#correlation)\n8. Feature Engineering [Jump](#engg)\n9. Feature Selection [Jump](#sel)\n10. Model Building [Jump](#model)\n11. Conclusion [Jump](#con)","676d28a4":"<div class = 'alert alert-block alert-info'>\nEvaluating our model using the best esimator\n    <\/div>","8b47aa84":"<div class = 'alert alert-block alert-info'>\nInteresting observation: Although 'senior experts' are supposed to know more, it is expected that they will perform better, yet the top grades are dominated by 'beginner'\n    <\/div>","d243713d":"<a id='con'><\/a>\n## Conclusion","38f5454b":"<a id='model'><\/a>\n## Model Building","78a8dce4":"<div class='alert alert-block alert-info'>\n    Since the education details of a few employees are NULL, we construct a new category called <code>Unknown<\/code> to compensate for the NULL values in the column\n<\/div>","e03a30a5":"### *Analysing the <code>recruitment_channel<\/code> column*","64cb0c61":"The class weight is passed as a dictionary of key:value pairs","95301292":"<div class='alert alert-block alert-info'>\n    The people who have won an award have a slightly higher rating than those who haven't received an award\n<\/div>","8753d1b3":"<div class = 'alert alert-block alert-info'>\nThe column <code>good_performer?<\/code> has the value 1 if either the employee has <code>KPIs_met >80%<\/code> = 1 or <code>awards_won?<\/code> = 1\n<\/div>","b70212d9":"### *Analyzing the <code>previous_year_rating<\/code> column*","20f28c96":"<div class = 'alert alert-block alert-info'>\n    Since the output of the LGBM is in terms of probability, I defined the probability of 40% to be the cut-off. Model returning  40% probability, will be predicted as promoted.\n    <\/div>","9dc08c86":"<div class = 'alert alert-block alert-info'>\nUsing forward feature selection to select the 6 best features<\/div>","9bec79d8":"<div class='alert alert-block alert-warning'>\n    Let us bin the values of the column <code>avg_training_score<\/code> into grades\n<\/div>","b66f5798":"__Building a Decision Tree from the data__","f45913f5":"We can clearly see that the LightGBM model performs better, so we keep that model and perform testing on it.","1ad59d60":"The mean_test_score showed am incresae in param_max_features = sqrt","a8b3ad71":"Visualizing a Decision Tree","9ec990da":"__Anaysing the trends in people who got promoted__","28249a4b":"<div class='alert alert-block alert-info'>\n    Most of the employees have been 10 years or less into the service\n\n<\/div>","86c01c14":"The data that we have is labeled, so this is a case of supervised learning. We have to predict if the employee will be promoted based on their details. So, this is a single-class classification problem.","4a1e9796":"Using the SMOTE technique to sample our data","5a8ce1f2":"<div class= 'alert alert-block alert-warning'>\n    Creating a new column by binning the values of the column <code>length_of_service<\/code> into 4 bins.\n<\/div>","5bbb40f6":"<div class='alert alert-block alert-info'>\n    It can be clearly observed that people who have a KPI higher than 80% have a higher chance of being promoted\n<\/div>","bb253eae":"<div class = 'alert alert-block alert-warning'>\nCreating a new feature to bin the number of trainings. 1 stands for those having gone through mroe than 1 trainings, and 0 stands for those who have gone through only 1 training.\n<\/div>","670472c6":"It is difficult to analyse this graph. Let us look at the graph with log(count) values","141126f4":"Original train in split into train and test","ef5e4a4b":"### __*Analysing the <code>gender<\/code> column*__","0baa6c29":"I am oversampling the minority label.","5ddb09ac":"__Encoding education__","2000a8fe":"<div class = 'alert alert-block alert-info'>\n    Observation: There is no significant difference between the average training scores across the difference groups of each department\n    <\/div>","845b0b00":"<div class = 'alert alert-block alert-warning'>\n    Creating a new feature for the joining date of the employee. Assuming that the data is of the present year, subtracting the <code>length_od_service<\/code> from the current year will give the joining year<\/div>","f3c39f97":"<div class='alert alert-block alert-info'>\n    The people who have won an award have a conversion rate of almost 50%<br>\n    This clearly states that people with an award were more likely to be promoted\n<\/div>","607f1005":"<div class = 'alert alert-block alert-warning'>\nBase Model Prediction: Using Random Forest Classifier.\n    <\/div>","08e7f6d3":"***","f65aa0b4":"<div class='alert alert-block alert-success'>\n    We can make the following observations:\n    <ul>\n        <li><code>department<\/code>, <code>region<\/code>, <code>education<\/code>, <code>gender<\/code>, <code>recruitment_channel<\/code>, <code>previous_year_rating<\/code>, <code>KPIs_met >80%<\/code>, <code>awards_won?<\/code> are all columns with categorical values<\/li>\n        <li>Out of those categorical columns, <code>education<\/code> and <code>previous_year_rating<\/code> are ordinal, rest are nominal.<\/li>\n    <\/ul>\n<\/div>","2e592c67":"<div class=\"alert alert-block alert-info\">\n    All the employees who have null in the <b>previous_year_rating<\/b> column, have a <b>length_of_service<\/b> = 1. Which means they just joined the company and do not have a previous year of experience for them to be judged with rating\n<\/div>","a897ab39":"<a id='constant'><\/a>\n## Checking for constant and quasi-constant columns","377f3534":"__Encoding department__","4d4faa63":"<div class=\"alert alert-block alert-success\">\nThere are no duplicate columns\n<\/div>","2c5aea0d":"<div class='alert alert-block alert-info'>\n    The <code>more_trainings?<\/code> feature is not correlated with our target variable, so we drop it.\n<\/div>","070ac889":"<div class=\"alert alert-block alert-info\">\nThere are more number of male employees than female employees<br>\n    Almost equal proportion of male and female employees get promoted\n<\/div>","c536ec29":"The evaluation metric for the LGBM used is f1-score and recall","72d03689":"__Removing object column types to keep only numeric__","8cff2ac8":"***","82df058a":"__Dropping employee_id, since it is a primary key__","ee6be609":"Evaluating the RegresionTreeClassifier with class weights on the original test set","dbba2ce5":"<a id='eda'><\/a>\n## EDA:Analysing the data in different columns","01974d43":"Using class weights of each class","b94ca9fc":"**Analysing the minority with the awards**","bafa0901":"<div class='alert alert-block alert-info'>\n    There is a small minority of people having an award.\n<\/div>            ","33efdc5a":"__These outliers cannot be removed since they are important for the prediction perspective__","29462e18":"<div class='alert alert-block alert-info'>\n    The heatmap gives an idea about the correlation between the numerical values in the dataframe. It can only identify linear relationship.<br>\n    As we can see, our target variable, <code>is_promoted<\/code> is correlated to <code>avg_training_score<\/code>, <code>awards_won<\/code>, <code>KPIs_met >80%<\/code> and <code>previous_year_rating<\/code>\n<\/div>","99e7792f":"<div class='alert alert-block alert-info'>\n    This feature is based on the <code>education<\/code> column. For a value of Unknown, the number of degrees are 0, for a values of Below Secondary, it is 1, for Bachelor's, it is 2, and for Master's it is 3.\n<\/div>","9a37a682":"<div class='alert alert-block alert-info'>\n    As we can see, most people are from region_2.\n    The majority of the employees are from regions region_2, region_22, region_7.\n    The graph looks like an <b>exponentially decreasing<\/b> one\n<\/div>","069e6a33":"<a id='duplicate'><\/a>\n## Checking for duplicated rows\/columns","8308fdff":"<div class='alert alert-block alert-info'>\n    The <code>age<\/code> and the <code>length_of_service<\/code> columns has outliers\n<\/div>","e65d80c3":"<div class='alert alert-block alert-info'>\n    Most people have an average training score in the range of 45-65\n<\/div>","5267cb5b":"<div class='alert alert-block alert-info'>\n    Having separate columns for the value of <code>education<\/code> column doesn't help much, so we remove the columns\n<\/div>","e329dd6e":"The param_min_samples_leaf had more or less constant values","e8800b0b":"<div class=\"alert alert-block alert-info\">\n    The ages of the employees are positively skewed\n    <\/div>","08537a55":"Clearly, gini impurity has an edge here in terms of param_min_samples_split","7b6f351e":"__Using the same model parameters for SMOTE data__","1a310b30":"<div class = 'alert alert-block alert-warning'>\n    Creating a new column by binning the <code>age<\/code> to 4 quartiles.\n<\/div>","814b31f3":"<div class='alert alert-info alert-block'>\nAs we can see, the outliers have employees who have actually been promoted, so we cannot drop these outliers.\n<\/div>","a21f3d51":"### *Analyzing <code>education<\/code> column*","611cc542":"Evaluating our model using the best esimator","139b0414":"__Using Grid Search__","e05ee9ef":"<div class='alert alert-block alert-info'>\n    As the rating of employees increase, their conversion rate for being promoted also increase<br>Rating 0 does not apply in this case, since they are new joinees, and their promotion do not depend on rating\n<\/div>            ","18c1b6e9":"### *Analysing the <code>KPIs_met >80%<\/code> column*","7b5b3f24":"### *Analyzing <code>avg_training_score<\/code> column*","d0652462":"***","4f9e73dd":"__Evaluting on the original test set for submission__","d68dd091":"<div class = 'alert alert-block alert-info'>\nBuilding a single Decision Tree model by assigning class-weight. I did this to visualize the splitting of a Tree Model\n    <\/div>","f999f25b":"### *Analyzing <code>age<\/code> column*","b7e51171":"Using LabelEncoding to encode the categorical columns since Tree Based algorithm will be used.","190bda25":"__Removing correlated features in the train set__","7eb0b1ce":"<div class = 'alert alert-block alert-warning'>\n    Creating features on the <code>department<\/code> column. Grouping the scarcely represented departments into a new category altogether called 'Others'\n<\/div>","3116262a":"__Getting the same features from forward and backward selection, we select these 6 features__","ce784ca2":"__Encoding recruitment_channel__","47944a8f":"#### Null value counts","2623a404":"__Encoding region__","8f0bc51b":"Clearly, the model with the hyper-parameters tuned, with class weights balanced, worked best for the given dataset.","67d0d691":"<div class='alert alert-block alert-info'>\n    The number of employees with higher number of trainings has observed an exponentially decreasing trend.<br>The exponential scaled graph confirms that higher number of trainings do not ensure a promotion\n<\/div>","e13c7948":"<div class='alert alert-block alert-warning'>\n    Let us find out the number of degrees that the person has from the <code>education<\/code> column\n<\/div>","f9364fbf":"<div class='alert alert-block alert-info'>\n    There is no significant difference in terms of promotion for those with number of trainings more than 1, and equal to 1\n<\/div>","e94893ec":"<div class='alert alert-block alert-success'>\n    We can make the following observations:\n    <ul>\n        <li>There are 7 columns having integer values, one with decimal values, and 5 with string type<\/li>\n    <\/ul>\n<\/div>","d4ae85d4":"<div class='alert alert-block alert-warning'>\n    Creating a feature based on the <code>awards_won?<\/code> and <code>KPIs_met >80%<\/code> columns\n<\/div>","1780cdbc":"<div class = 'alert alert-block alert-info'>\n    Creating binary columns based on <code>education<\/code> column. If a person has Master's, then he\/she has Bachelor's and Secondary degree too.\n<\/div>","850e7ad9":"__Using class_weight__","28e93248":"__This is and implementation of the Cramer's V test to find the correlation between categorical and numerical columns__","0eb44294":"__Analysing outliers in <code>length_of_service<\/code>__","f82ec781":"<div class = 'alert alert-block alert-info'>\n    Here, the minority data has been oversampled using the <code>resample<\/code> method from sklearn. A copy of the unsampled data has been kept in the <code>_unsampled<\/code> variables to be explored later\n<\/div>","c961fd83":"<div class = 'alert alert-info alert-block'>\n    As we can see the recall of the minority class is not very good. So we will use class wewights on the unsampled data<\/div>","48755c9a":"__Using Randomized Search to get the optimal hyperparameters__","0381e654":"__Encoding gender__","2e12c73e":"***","d00c003b":"<div class=\"alert alert-block alert-info\">\n    About 10% of the employees from all groups, except <b>Unknown<\/b> category are promoted. Although the percentage of employees are more with Bachelor's degree, Master's and above see a higher conversion rate\n<\/div>","e344f47a":"<a id='split'><\/a>\n## Splitting into train, validation and test sets","0844b903":"As the precision for the minority class is less for the parameters got in Randomized Search, we proceed to Grid Search","d4249bd4":"<a id = 'sel'><\/a>\n## Feature Selection","4d7c9f05":"Observing the outliers of the joining year column","3c051f05":"<div class = 'alert alert-block alert-info'>The classification report gives the intution that the class weights performed better.<\/div>","4e7bcb2a":"<a id='read'><\/a>\n## Reading original train and test data into DataFrame","f64a1450":"<a id='engg'><\/a>\n## Feature Engineering","9ede754b":"### *Analysing <code>awards_won?<\/code> column*","81abe0d7":"The Grid Search is done by using class weight","095666bf":"Combining X and Y to impute the null rows from train, validation, test and the original test sets.","3cee3b70":"### *Analysing <code>length_of_service<\/code> column*"}}